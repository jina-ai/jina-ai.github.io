<!DOCTYPE html><html lang="en"><head><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><meta property="og:title" content="Jina AI - a Neural Search Company"/><meta name="author" content="Jina AI"/><meta property="og:locale" content="en_US"/><meta property="og:site_name" content="Jina AI"/><meta property="og:image" content="https://jina.ai/assets/images/jina_banner_new.png"/><meta name="twitter:card" content="summary"/><meta property="twitter:image" content="https://jina.ai/assets/images/jina_banner_new.png"/><meta property="twitter:title" content="Jina AI - a Neural Search Company"/><meta name="twitter:site" content="@JinaAI_"/><meta name="twitter:creator" content="@Jina AI"/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-96x96.png"/><link rel="icon" href="/favicon.ico"/><link rel="icon" type="image/png" sizes="192x192" href="/android-icon-192x192.png"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700"/><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Open source neural search ecosystem for businesses and developers, allowing anyone to search any kind of data with high availability and scalability."/><meta property="og:url" content="https://jina.ai/"/><meta property="og:title" content="Jina AI | Jina AI is a Neural Search Company"/><meta property="og:description" content="Open source neural search ecosystem for businesses and developers, allowing anyone to search any kind of data with high availability and scalability."/><meta property="og:locale" content="en"/><meta property="og:site_name" content="Jina AI, Ltd"/><link rel="canonical" href="https://jina.ai/"/><title>How to build a production-ready Financial Question Answering system with Jina and BERT | Jina AI</title><meta name="next-head-count" content="29"/><link rel="preload" href="/_next/static/css/d6299e18a01a0ac2808b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d6299e18a01a0ac2808b.css" data-n-g=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/webpack-8f6366ea4b5fafd77e96.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework-94f262366e752bd48d82.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons-4667b98b62a60d7c050b.js" as="script"/><link rel="preload" href="/_next/static/chunks/main-9a4182dc8e7736869bf9.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-afcb035e0413b2214f0f.js" as="script"/><link rel="preload" href="/_next/static/chunks/596-13cdde2fb793b77184ee.js" as="script"/><link rel="preload" href="/_next/static/chunks/522-e45333ebcf36799b860c.js" as="script"/><link rel="preload" href="/_next/static/chunks/373-350caaa5387e56e8b807.js" as="script"/><link rel="preload" href="/_next/static/chunks/93-1a5bac9fdf2b2295fba2.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/blog/%5Bslug%5D-0d67fc13dbd9e7ddf27f.js" as="script"/><style id="__jsx-3792957869">.dropdown.jsx-3792957869{--tw-bg-opacity:1;background-color:rgba(255,255,255,var(--tw-bg-opacity));padding:1.5rem;--tw-text-opacity:1;color:rgba(74,85,104,var(--tw-text-opacity));top:5rem;width:24rem;border-radius:0.75rem;}.dropdown.jsx-3792957869>.jsx-3792957869:not([hidden])~.jsx-3792957869:not([hidden]){--tw-divide-y-reverse:0;border-top-width:calc(1px * calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(1px * var(--tw-divide-y-reverse));border-style:solid;--tw-divide-opacity:1;border-color:rgba(235,235,235,var(--tw-divide-opacity));}.dropdown.jsx-3792957869{box-shadow:3px 6px 33px rgba(205,205,205,0.25);}</style><style id="__jsx-3128403005">.dropdown.jsx-3128403005{--tw-bg-opacity:1;background-color:rgba(255,255,255,var(--tw-bg-opacity));--tw-text-opacity:1;color:rgba(74,85,104,var(--tw-text-opacity));top:5rem;width:100%;border-radius:0.75rem;}.dropdown.jsx-3128403005>.jsx-3128403005:not([hidden])~.jsx-3128403005:not([hidden]){--tw-divide-y-reverse:0;border-top-width:calc(1px * calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(1px * var(--tw-divide-y-reverse));border-style:solid;--tw-divide-opacity:1;border-color:rgba(235,235,235,var(--tw-divide-opacity));}</style><style id="__jsx-3949856645">.btn.jsx-3949856645{text-align:center;}.btn-base.jsx-3949856645{font-size:1.125rem;font-weight:600;}.btn-xl.jsx-3949856645{padding-top:1rem;padding-bottom:1rem;padding-left:1.5rem;padding-right:1.5rem;font-size:1.25rem;font-weight:800;}.btn-full-rounded.jsx-3949856645{border-radius:9999px;}.btn-primary.jsx-3949856645{border-radius:9999px;--tw-bg-opacity:1;background-color:rgba(0,129,129,var(--tw-bg-opacity));--tw-text-opacity:1;color:rgba(255,255,255,var(--tw-text-opacity));}.btn-primary.jsx-3949856645:hover{background-color:#009191;}.btn-secondary.jsx-3949856645{--tw-bg-opacity:1;background-color:rgba(251,203,103,var(--tw-bg-opacity));--tw-text-opacity:1;color:rgba(0,0,0,var(--tw-text-opacity));}.btn-secondary.jsx-3949856645:hover{background-color:#fbd076;}.btn-tertiary.jsx-3949856645{--tw-bg-opacity:1;background-color:rgba(255,255,255,var(--tw-bg-opacity));border:1px solid #999999;}.btn-tertiary.jsx-3949856645:hover{background-color:#f6f6f6;}.btn-outlined.jsx-3949856645{border-width:2px;border-style:solid;--tw-border-opacity:1;border-color:rgba(255,255,255,var(--tw-border-opacity));background-color:transparent;}.btn-outlined.jsx-3949856645:hover{background-color:#f6f6f622;}</style><style id="__jsx-223001487">.navbar.jsx-223001487 a{display:inline-block;width:100%;}.navbar.jsx-223001487 li:not(:first-child){margin-top:0.75rem;}.navbar.jsx-223001487 a .btn{width:100%;}.navbar.jsx-223001487 a:hover{--tw-text-opacity:1;color:rgba(0,129,129,var(--tw-text-opacity));}@media (min-width:640px){.navbar.jsx-223001487 a,.navbar.jsx-223001487 a .btn{width:auto;}.navbar.jsx-223001487 li:not(:first-child){margin-top:0px;}.navbar.jsx-223001487>(li:not(:last-child)){margin-right:1.25rem;}}</style><style id="__jsx-649517993">.top-nav-bar.jsx-649517993{box-shadow:3px 6px 33px 0px #cdcdcd40;z-index:200;position:fixed;width:100vw;background:white;top:0;}</style><style id="__jsx-4055754880">.markdown.jsx-4055754880{font-size:1.125rem;line-height:1.625;}.markdown.jsx-4055754880 p.jsx-4055754880,.markdown.jsx-4055754880 ul.jsx-4055754880,.markdown.jsx-4055754880 ol.jsx-4055754880,.markdown.jsx-4055754880 blockquote.jsx-4055754880{margin-top:1.5rem;margin-bottom:1.5rem;}.markdown.jsx-4055754880 h2.jsx-4055754880{margin-top:3rem;margin-bottom:1rem;font-size:1.875rem;line-height:1.375;}.markdown.jsx-4055754880 h3.jsx-4055754880{margin-top:2rem;margin-bottom:1rem;font-size:1.5rem;line-height:1.375;}</style><style id="__jsx-1324436386">.footer-links.jsx-1324436386 li{margin-top:0.25rem;}.footer-items-title.jsx-1324436386{font-size:1.375rem;line-height:1.5rem;-webkit-letter-spacing:0.22px;-moz-letter-spacing:0.22px;-ms-letter-spacing:0.22px;letter-spacing:0.22px;}</style><style id="__jsx-1956813867">.footer-left-margin.jsx-1956813867{width:20rem;height:inherit;background:no-repeat 40% 20% / 30% url('/assets/images/planet-beige.svg');}.footer-right-margin.jsx-1956813867{width:16rem;height:inherit;background:no-repeat 10% 10% / 50% url('/assets/images/planet-green.svg');}</style><style data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700">@font-face{font-family:'Poppins';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrFJM.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJbecnFHGPezSQ.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJnecnFHGPezSQ.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJfecnFHGPc.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><script async="" src="https://www.googletagmanager.com/gtag/js?id=undefined"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'undefined', {
              page_path: window.location.pathname,
            });
          </script><body><div id="__next"><div class="jsx-649517993 top-nav-bar"><div class="md:max-w-screen-md lg:max-w-screen-lg xl:max-w-screen-2xl mx-auto px-3 py-6 undefined"><div class="jsx-223001487 flex flex-wrap justify-between items-center"><div class="jsx-223001487"><a class="jsx-223001487" href="/"><div class="text-gray-900 flex items-center font-semibold text-3xl"><img src="/assets/images/logo.svg" alt="Jina.ai logo" class="w-24"/></div></a></div><div class="jsx-223001487 sm:hidden"><button type="button" aria-label="show menu" class="jsx-223001487 p-3 text-gray-900 rounded-md hover:bg-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="1.5" fill="none" stroke-linecap="round" stroke-linejoin="round" class="jsx-223001487 stroke-current h-6 w-6"><path d="M0 0h24v24H0z" stroke="none" class="jsx-223001487"></path><path d="M4 6h16M4 12h16M4 18h16" class="jsx-223001487"></path></svg></button></div><nav class="jsx-223001487 w-full sm:w-auto sm:block mt-2 sm:mt-0 hidden"><ul class="jsx-223001487 navbar flex flex-col sm:flex-row sm:items-center font-medium text-xl text-gray-800 pt-3 pb-5 px-5 sm:p-0 bg-white sm:bg-transparent rounded"><li class="jsx-649517993 hidden md:inline-block"><div class="jsx-3792957869 group inline-block relative"><button aria-label="Open Products dropdown" class="jsx-3792957869 text-gray-700 font-semibold py-2 px-4 rounded inline-flex items-center"><span class="jsx-3792957869 mr-1 font-bold">Products</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="jsx-3792957869 fill-current h-4 w-4 mt-2"><path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z" class="jsx-3792957869"></path></svg></button><div class="jsx-3792957869 absolute hidden group-hover:block bg-transparent pt-7"><ul class="jsx-3792957869 dropdown"><li class="jsx-3792957869 hover:bg-gray-200"><a href="/core" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/core-icon.svg" alt="core icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Jina Core</span></div><span class="jsx-3792957869 text-xs text-gray-500">An open-source framework for building multimedia search applications.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/hub" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/hub-icon.svg" alt="hub icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Jina Hub</span></div><span class="jsx-3792957869 text-xs text-gray-500">Jina’s community-driven module marketplace for building your Flow</span></div></a></li></ul></div></div></li><li class="jsx-649517993 hidden md:inline-block"><div class="jsx-3792957869 group inline-block relative"><button aria-label="Open Developers dropdown" class="jsx-3792957869 text-gray-700 font-semibold py-2 px-4 rounded inline-flex items-center"><span class="jsx-3792957869 mr-1 font-bold">Developers</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="jsx-3792957869 fill-current h-4 w-4 mt-2"><path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z" class="jsx-3792957869"></path></svg></button><div class="jsx-3792957869 absolute hidden group-hover:block bg-transparent pt-7"><ul class="jsx-3792957869 dropdown"><li class="jsx-3792957869 hover:bg-gray-200"><a href="/contribute" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/contribute-icon.svg" alt="contribute icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Contribute</span></div><span class="jsx-3792957869 text-xs text-gray-500">Want to shape the future of neural search? Find out how you can contribute to Jina here.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/join" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/join-icon.svg" alt="join icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Join</span></div><span class="jsx-3792957869 text-xs text-gray-500">Join the Jina Slack community to meet the team and get support.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/learn" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/learn-icon.svg" alt="learn icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Learn</span></div><span class="jsx-3792957869 text-xs text-gray-500">Docs, tutorials and examples for developers to get started with Jina. </span></div></a></li></ul></div></div></li><li class="jsx-649517993 hidden md:inline-block"><div class="jsx-3792957869 group inline-block relative"><button aria-label="Open Company dropdown" class="jsx-3792957869 text-gray-700 font-semibold py-2 px-4 rounded inline-flex items-center"><span class="jsx-3792957869 mr-1 font-bold">Company</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="jsx-3792957869 fill-current h-4 w-4 mt-2"><path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z" class="jsx-3792957869"></path></svg></button><div class="jsx-3792957869 absolute hidden group-hover:block bg-transparent pt-7"><ul class="jsx-3792957869 dropdown"><li class="jsx-3792957869 hover:bg-gray-200"><a href="/about" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/about-icon.svg" alt="about icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">About</span></div><span class="jsx-3792957869 text-xs text-gray-500">Learn more about Jina AI as a company.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/careers" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/careers-icon.svg" alt="careers icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Careers</span></div><span class="jsx-3792957869 text-xs text-gray-500">Interested in joining us? Find out what it&#x27;s like to work at Jina AI.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/events" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/events-icon.svg" alt="events icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Events</span></div><span class="jsx-3792957869 text-xs text-gray-500">Online and offline meetups, hackathons, workshops and webinars.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/news" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/news-icon.svg" alt="news icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">News</span></div><span class="jsx-3792957869 text-xs text-gray-500">Check out the latest news about our company and products.</span></div></a></li><li class="jsx-3792957869 hover:bg-gray-200"><a href="/contact" class="jsx-3792957869 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3792957869 leading-4"><div class="jsx-3792957869 flex items-center"><div class=""><img src="/assets/images/icons/contact-icon.svg" alt="contact icon" class="w-full h-full"/></div><span class="jsx-3792957869 text-gray-800 font-semibold text-sm ml-2">Contact</span></div><span class="jsx-3792957869 text-xs text-gray-500">Interested in cooperating with Jina AI? Get in touch!</span></div></a></li></ul></div></div></li><li class="jsx-649517993 hidden md:inline-block mr-1 font-bold text-gray-700"><a href="/blog/">Blog</a></li><div class="jsx-3128403005 md:hidden h-96 overflow-y-scroll"><ul class="jsx-3128403005 dropdown"><div class="jsx-3128403005 linkItem.label divide-solid divide-gray-200 divide-y"><li class="jsx-3128403005 hover:bg-gray-200"><a href="/core" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/core-icon.svg" alt="core icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Jina Core</span></div><span class="jsx-3128403005 text-xs text-gray-500">An open-source framework for building multimedia search applications.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/hub" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/hub-icon.svg" alt="hub icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Jina Hub</span></div><span class="jsx-3128403005 text-xs text-gray-500">Jina’s community-driven module marketplace for building your Flow</span></div></a></li></div><div class="jsx-3128403005 linkItem.label divide-solid divide-gray-200 divide-y"><li class="jsx-3128403005 hover:bg-gray-200"><a href="/contribute" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/contribute-icon.svg" alt="contribute icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Contribute</span></div><span class="jsx-3128403005 text-xs text-gray-500">Want to shape the future of neural search? Find out how you can contribute to Jina here.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/join" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/join-icon.svg" alt="join icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Join</span></div><span class="jsx-3128403005 text-xs text-gray-500">Join the Jina Slack community to meet the team and get support.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/learn" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/learn-icon.svg" alt="learn icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Learn</span></div><span class="jsx-3128403005 text-xs text-gray-500">Docs, tutorials and examples for developers to get started with Jina. </span></div></a></li></div><div class="jsx-3128403005 linkItem.label divide-solid divide-gray-200 divide-y"><li class="jsx-3128403005 hover:bg-gray-200"><a href="/about" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/about-icon.svg" alt="about icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">About</span></div><span class="jsx-3128403005 text-xs text-gray-500">Learn more about Jina AI as a company.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/careers" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/careers-icon.svg" alt="careers icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Careers</span></div><span class="jsx-3128403005 text-xs text-gray-500">Interested in joining us? Find out what it&#x27;s like to work at Jina AI.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/events" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/events-icon.svg" alt="events icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Events</span></div><span class="jsx-3128403005 text-xs text-gray-500">Online and offline meetups, hackathons, workshops and webinars.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/news" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/news-icon.svg" alt="news icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">News</span></div><span class="jsx-3128403005 text-xs text-gray-500">Check out the latest news about our company and products.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/contact" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/contact-icon.svg" alt="contact icon" class="w-full h-full"/></div><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Contact</span></div><span class="jsx-3128403005 text-xs text-gray-500">Interested in cooperating with Jina AI? Get in touch!</span></div></a></li></div></ul><span class="jsx-3128403005 text-gray-700 font-semibold text-sm ml-2 p-4">Blog</span></div><li class="jsx-223001487"><div class="jsx-3949856645 btn cursor-pointer flex items-center justify-center px-6 py-2 md:hidden btn-base btn-primary"><div class="mr-4 w-7"><img src="/assets/images/icons/GitHub-white-icon.svg" alt="GitHub-white icon" class="w-full h-full"/></div><span class="jsx-223001487 mr-4">Try it out!</span></div></li></ul></nav><div class="jsx-3949856645 btn cursor-pointer flex items-center justify-center px-6 py-2 hidden md:flex btn-base btn-primary"><div class="mr-4 w-7"><img src="/assets/images/icons/GitHub-white-icon.svg" alt="GitHub-white icon" class="w-full h-full"/></div><span class="jsx-223001487 mr-4">Try it out!</span></div></div></div></div><div class="mt-24"><div class="min-h-screen"><main><div class="container mx-auto px-5 flex flex-col"><img src="/assets/images/blog/financial-qa.png" alt="How to build a production-ready Financial Question Answering system with Jina and BERT-image" class="mb-4 w-full"/><article class="mb-32 md:max-w-6xl md:shadow-lg xl:rounded-3xl md:px-32 md:py-20 md:mx-auto md:-mt-20 bg-white shadow"><div class="mb-3"></div><h1 class="text-xl md:text-4xl font-bold tracking-tighter leading-tight md:leading-none mb-6 md:text-left">How to build a production-ready Financial Question Answering system with Jina and BERT</h1><div class="flex items-center justify-between text-gray-600 mb-12"><div class="flex items-center"><img src="/assets/images/defaultProfileImg.svg" class="w-8 h-auto rounded-full mr-4" alt="Bithiah Yuan"/><div class="text-gray-600">Bithiah Yuan</div></div><time dateTime="2021-01-07T10:00:39.923Z">7 January, 2021</time></div><div class="jsx-4055754880 mx-auto markdown"><div class="jsx-4055754880"><p>Learn how to use the neural search framework, <strong><a href="https://github.com/jina-ai/jina">Jina</a></strong>, to build a <strong>Financial Question Answering (QA) search application</strong>
using the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset, <a href="https://pytorch.org">PyTorch</a>, and <a href="https://github.com/huggingface/transformers">Hugging Face transformers</a>.</p>
<p>For my master’s thesis, I built a Financial QA system using a fine-tuned BERT model called
<a href="https://github.com/yuanbit/FinBERT-QA">FinBERT-QA</a>. Motivated by the emerging demand in the financial industry for
the automatic analysis of unstructured and structured data at scale, <strong>QA systems can provide lucrative and competitive
advantages</strong> to companies by facilitating the decision making of financial advisers.</p>
<p>The goal of my thesis was to search for a ranked list of relevant answer passages given a question.
Here is an example of a financial domain-based question and a ground truth answer from the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset:</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/sample-qa.png" alt="performance" width="450px">
<figcaption>Sample QA from the financial domain</figcaption>
</figure>
</p>
<p>Here is a list of other questions from <a href="https://sites.google.com/view/fiqa/home">FiQA</a>:</p>
<pre><code>• What does it mean that stocks are “memoryless”?
• What would a stock be worth if dividends did not exist?
• What are the risks of Dividend-yielding stocks?
• Why do financial institutions charge so much to convert currency?
• Is there a candlestick pattern that guarantees any kind of future profit?
• 15 year mortgage vs 30 year paid off in 15
• Why is it rational to pay out a dividend?
• Why do companies have a fiscal year different from the calendar year?
• What should I look at before investing in a start-up?
• Where do large corporations store their massive amounts of cash?
</code></pre>
<p>Financial QA is <strong>hard</strong> because the vocabularies are context specific, for example, a machine would
have a hard time understanding what an <em>ETF</em> is. Nevertheless, <strong>with the power of BERT, I improved the state-of-the-art (SOTA) results by an average of 19% on three
evaluation metrics (Precision, MRR, NDCG)</strong>.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/model-performance.png" alt="performance" width="600px">
<figcaption>Evaluation results from <a href="https://github.com/yuanbit/FinBERT-QA">FinBERT-QA</a></figcaption>
</figure>
</p>
<p>Even though my thesis was about QA in the financial domain, the approach that I have used can be applied to a
<a href="https://github.com/microsoft/MSMARCO-Passage-Ranking">general QA dataset</a> or QA in other domains such as
<a href="https://github.com/shuzi/insuranceQA">insurance</a>.</p>
<p>After finishing my thesis, I realized that <strong>just having a model and SOTA results is not good enough</strong> because there
was a gap between my research and business needs. This was when I discovered <strong>Jina, a framework designed to
help me bridge this gap</strong>. To help people better understand Jina, I prepared this tutorial to demonstrate how
I used Jina to easily <strong>transform my research into a production-ready system</strong>.</p>
<h2>Table of Contents</h2>
<ul>
<li><a href="#background">Background</a>
<ul>
<li><a href="#what-is-jina">What is Jina?</a></li>
<li><a href="#financial-qa-with-bert">Financial QA with BERT</a></li>
<li><a href="#why-jina">Why Jina?</a></li>
</ul>
</li>
<li><a href="#tutorial">Tutorial</a>
<ul>
<li><a href="#set-up">Set Up</a></li>
<li><a href="#index-flow">Index Flow</a>
<ul>
<li><a href="#step-1-define-our-data">Step 1. Define our data</a></li>
<li><a href="#step-2-encode-answer-passages">Step 2. Encode Answer Passages</a></li>
<li><a href="#step-3-indexing">Step 3. Indexing</a></li>
<li><a href="#build-an-indexer-application">Build an Indexer Application</a></li>
</ul>
</li>
<li><a href="#query-flow">Query Flow</a>
<ul>
<li><a href="#step-1-encode-question">Step 1. Encode Question</a></li>
<li><a href="#step-2-search-indexes">Step 2. Seach Indexes</a></li>
<li><a href="#step-3-reranking">Step 3. Reranking</a>
<ul>
<li><a href="#build-a-custom-executor">Build a Custom Executor</a></li>
</ul>
</li>
<li><a href="#build-a-search-application">Build a Search Application</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
<li><a href="#next-steps-evaluation">Next Steps: Evaluation</a></li>
<li><a href="#learn-more">Learn More</a></li>
</ul>
<h2>Background</h2>
<h3>What is Jina?</h3>
<p align="center">
<img src="/assets/images/jina_banner_new.png" width="500">
</p>
<p>Open-source deep learning frameworks such as TensorFlow and PyTorch provide building blocks for designing and quickly implementing
neural network-based applications through a high level programming interface.</p>
<p>Similarly, <strong>Jina</strong> is an <strong>open-source neural search framework</strong> that offers the building blocks for designing and implementing <strong>neural network-based
search applications</strong>.</p>
<p>Co-founded by the creator of <a href="https://github.com/hanxiao/bert-as-service">bert-as-service</a> and
<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a>, Jina enables developers to build
<strong>production-ready cloud-native search systems</strong> using
<strong>SOTA pre-trained deep learning models</strong>, in which each component of the system is a <strong>microservice</strong> that can be deployed, scaled, and maintained independently.</p>
<p align="center">
<img src="/assets/images/blog/financial-qa/cloud.png" width="350">
</p>
<p>If you come from a data science or academic background like me, the terms <strong>cloud-native</strong> and <strong>microservices</strong> may sound
daunting. That's why we will learn by example in this tutorial and use the NLP task, Financial QA, to familiarize ourselves
with Jina's core concepts!</p>
<h3>Financial QA with BERT</h3>
<p>Before we jump into the tutorial, let's first understand how to build a QA system with BERT. Our goal is to
search for the top-k most relevant answer passages when given a question from task 2 of the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset.</p>
<p>In 2018, Google's pre-trained BERT models, used for transfer learning, shook the NLP world and achieved the SOTA
results on numerous tasks, marking NLP's <a href="https://ruder.io/nlp-imagenet/">ImageNet moment</a>.</p>
<p>What is neat about BERT is that we can fine-tune a pre-trained BERT model on our QA task by simply transforming
it into a <strong>binary classification task</strong>, where the input is the <strong>concatenation of a question and an answer</strong> and the
output is a binary label indicating the <strong>relevancy score</strong> of the QA pair. We can then take the softmax scores of
each QA pair to get a probability of relevancy and rank these scores.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/BERT-QA.png" width="400">
<figcaption>Fine-tuning method for our QA task</figcaption>
</figure>
</p>
<p>The <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset has roughly 6,000 questions and 57,000 answers. Instead of
computing a probability for each question 57,000 times, we can adapt a <a href="https://arxiv.org/pdf/1901.04085.pdf">passage reranking</a>
approach. We first use a <strong>Retriever</strong> to return the top-50 candidate answers for each question,
and then use <strong>FinBERT-QA</strong>, a BERT-based model fine-tuned on the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset
as a <strong>Reranker</strong> to compute the relevancy scores and rerank the top-50 QA pairs to get the top-10 answers.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/qa-pipeline-simple.png" width="1000">
<figcaption>QA pipeline with reranking</figcaption>
</figure>
</p>
<p>If you are interested in the details of my thesis, you can learn more <a href="https://github.com/yuanbit/FinBERT-QA">here</a>.</p>
<h2>Why Jina?</h2>
<p>Why is having the SOTA model and results is not good enough?</p>
<h3>Jina as a bridge between research and industry</h3>
<p>The motivation behind my research was to be able to help financial advisor answer questions
from large-scale reports. However, the way I implemented the QA pipeline is not reusable and it won't scale
to business demands. <strong>By industry standards, it is not production-ready.</strong></p>
<p>Since <strong>Jina enables us to build cloud-native systems</strong>, which embrace
microservices, instead of wrapping my entire pipeline in a single Docker container, Jina will break down the pipeline
into components (preprocessor, encoder, indexer, etc.). Moreover, each of these components will be a microservice in its own isolated Docker
container managed by the <a href="https://docs.jina.ai/chapters/flow/index.html">Flow API</a>.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/cloud2.svg" width="350">
<figcaption>Illustration from <a href="https://www.manypixels.co/gallery/">manypixels</a></figcaption>
</figure>
</p>
<p>For those of you new to cloud-native concepts, you can think of a microservice as an independent component of your
application, for example, using FinBERT-QA to encode our questions and answers. You can then create multiple independent components
or microservices to construct an application like a BERT-powered QA system. Since each of the components of the application can be deployed independently,
they can also scale individually and respond to rapid changes and business needs.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/business.svg" width="350">
<figcaption>Illustration from <a href="https://www.manypixels.co/gallery/">manypixels</a></figcaption>
</figure>
</p>
<p>Being cloud-native is a modern design that more and more businesses are adapting to because it can help them save resources
and grow. However, designing such systems is not easy. We need to consider many principles, patterns and best practices,
for example, how will the each component communicate with each other? How can they work in parallel? Luckily, instead of starting
from scratch, <strong>Jina does all the hard work for us by providing us the building blocks so that we can easily construct
a cloud-native BERT-powered QA system using an reranking approach that is ready to serve in production!</strong></p>
<h2>Tutorial</h2>
<p>Now that we have an overview, let's learn how to build a production-ready Financial QA system using the reranking approach and
dive deeper into some new Jina terminologies. We will use <a href="https://github.com/ProsusAI/finBERT">FinBERT</a> to encode our
questions and answer passages into embeddings and <a href="https://github.com/yuanbit/FinBERT-QA">FinBERT-QA</a> to rerank
the top-50 answer matches.</p>
<p><strong>The final code of this tutorial can be found <a href="https://github.com/yuanbit/jina-financial-qa-search">here</a>.</strong></p>
<h3>Set up</h3>
<p><strong>Clone the repository</strong> that we will be working together with here:</p>
<pre><code>git clone https://github.com/yuanbit/jina-financial-qa-search-template.git
</code></pre>
<p>We will use <code>financial-qa-search/</code> as our working directory.</p>
<p><strong>Install the requirements</strong></p>
<pre><code>pip install -r requirements.txt
</code></pre>
<p><strong>Download data and model</strong></p>
<pre><code>bash get_data.sh
</code></pre>
<p>For this tutorial, we won't be searching through all 57,000 answer passages from the
<a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset. We will work with a sample dataset called <code>test_answers.csv</code>,
containing about 800 answer passages. If you want to experiment with the full dataset, you can use <code>answer_collection.tsv</code>.</p>
<p><strong>Flows</strong></p>
<p>In Jina, we will build a Financial QA system with two pipelines, one for indexing our answer passages and
the other for querying. These pipelines are called <strong>Flows</strong>, which also serve to manage the state and context
of the microservices as well as orchestrating them. Let's see what an overview of
the <strong>Index Flow</strong> and <strong>Query Flow</strong>, you can click on the images to see the details:</p>
<p align="center">
<figure>
<a href="https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/index-flow.png">
<img src="/assets/images/blog/financial-qa/index-flow.png" width="1000">
</a>
<figcaption>Index Flow</figcaption>
</figure>
</p>
<p align="center">
<figure>
<a href="https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png">
<img src="/assets/images/blog/financial-qa/query-flow.png" width="1000">
</a>
<figcaption>Query Flow</figcaption>
</figure>
</p>
<p>To understand these Flows, let's start with the <strong>Index Flow</strong> and look into the individual components one by one.</p>
<h3>Index Flow</h3>
<p>The main idea behind the Index Flow is to use a pre-trained BERT model to encode all of our answer
passages into embeddings then indexing these embeddings so that they can be searched in the Query Flow.</p>
<h4>Step 1. Define our data</h4>
<p>We want to index a subset of  the answer passages from the FiQA dataset, <code>dataset/test_answers.csv</code>:</p>
<pre><code>398960	From  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  company's      underlying  value.  Examples  of  business      fundamentals  include  debt,  cash  flow,      supply  of  and  demand  for  the  company's      products,  and  so  forth.  For  instance,      if  a  company  does  not  have  a      sufficient  supply  of  products,  it  will      fail.  Likewise,  demand  for  the  product      must  remain  at  a  certain  level  in      order  for  it  to  be  successful.  Strong      business  fundamentals  are  considered      essential  for  long-term  success  and      stability.  See  also:  Value  Investing,      Fundamental  Analysis.  For  a  stock  the  basic  fundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page,    P/E  ratio,  div/yeild,  EPS,  shares,  beta.      For  the  company  itself  it's  generally  the  stuff  on  the  'financials'  link    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.
19183	If  your  sole  proprietorship  losses  exceed  all  other  sources  of  taxable  income,  then  you  have  what's  called  a  Net  Operating  Loss  (NOL).  You  will  have  the  option  to  "carry  back"  and  amend  a  return  you  filed  in  the  last  2  years  where  you  owed  tax,  or  you  can  "carry  forward"  the  losses  and  decrease  your  taxes  in  a  future  year,  up  to  20  years  in  the  future.  For  more  information  see  the  IRS  links  for  NOL.  Note:  it's  important  to  make  sure  you  file  the  NOL  correctly  so  I'd  advise  speaking  with  an  accountant.  (Especially  if  the  loss  is  greater  than  the  cost  of  the  accountant...)
327002	To  be  deductible,  a  business  expense  must  be  both  ordinary  and  necessary.  An  ordinary  expense  is  one  that  is  common  and  accepted  in  your  trade  or  business.  A  necessary  expense  is  one  that  is  helpful  and  appropriate  for  your  trade  or  business.  An  expense  does  not  have  to  be  indispensable  to  be  considered  necessary.    (IRS,  Deducting  Business  Expenses)  It  seems  to  me  you'd  have  a  hard  time  convincing  an  auditor  that  this  is  the  case.    Since  business  don't  commonly  own  cars  for  the  sole  purpose  of  housing  $25  computers,  you'd  have  trouble  with  the  "ordinary"  test.    And  since  there  are  lots  of  other  ways  to  house  a  computer  other  than  a  car,  "necessary"  seems  problematic  also.
</code></pre>
<p>Our dataset consists of a column of answer id and text, which we will denote as docid and doc respectively in this tutorial.
In order to index our data, we need to first define it in a Jina data type called <strong>Document</strong>.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step1.png" width="400">
<figcaption>Index Flow - Step 1</figcaption>
</figure>
</p>
<p>In programming languages there are data types such as int, float, boolean, and more. In NumPy, TensorFlow, and PyTorch,
we manipulate and pass around objects such as ndarray and tensor, which are referred to as <strong>primitive data types</strong>.
Similarly, a <strong>Document</strong> is a Jina-specific data type for representing data.</p>
<p><strong>Defining our data in a Document</strong></p>
<p>In our project directory <code>financial-qa-search/</code> the <code>app.py</code> file consists of the Financial QA search application
that we will build.  Notice that we set our data path in the <code>config</code> function as follows:</p>
<script src="https://gist.github.com/yuanbit/f8bc065dbba8382b1dadd0c75203cf9e.js"></script>
<p>You can change the path to <code>answer_collection.tsv</code> to index with the full dataset.</p>
<p>Let's first make sure we import <code>Document</code> from jina:</p>
<script src="https://gist.github.com/yuanbit/f0f5d0a43738f50140e47fa2af6e8fcc.js"></script>
<p>After the <code>config</code> function, let's create a Python generator and define the Document to contain the id and text
corresponding to the answer passages:</p>
<script src="https://gist.github.com/yuanbit/91effc3288862727199a13813f5c33a3.js"></script>
<p>A Document is a high-level way for us to <strong>define and view the contents stored in Protobuf</strong>, which is what Jina uses to
<strong>enable the microservices in the Flow to communicate with each other</strong>. It is like an envelope
containing our data and is used to send messages between the microservices of our Flow. Instead of directly
dealing with Protobuf, which serializes our data into bytes, we can simply print our Document and see that a single answer
passage will look as follows:</p>
<pre><code>id: "13755c6081bebe1a"
mime_type: "text/plain"
tags {
  fields {
    key: "id"
    value {
      number_value: 398960.0
    }
  }
}
text: "From  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  
company\'s underlying  value. Examples  of  business fundamentals  include  debt,  cash  flow, supply  of  and  demand  
for  the  company\'s      products,  and  so  forth.  For  instance, if  a  company  does  not  have  a sufficient  
supply  of  products,  it  will      fail.  Likewise,  demand  for  the  product      must  remain  at  a  certain  
level  in      order  for  it  to  be  successful.  Strong      business  fundamentals  are  considered essential  for  
long-term  success  and      stability.  See  also:  Value  Investing, Fundamental  Analysis.  For  a  stock  the  basic
fundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page, P/E  ratio,  
div/yeild,  EPS,  shares,  beta.      For  the  company  itself  it\'s  generally  the  stuff  on  the  \'financials\'  
link    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc."
</code></pre>
<p><strong>As we move along the Index Flow, the contents of the Document will be changed</strong>, for example, we can see in the Index Flow that
the embeddings of the answer passages are added to the Document after the encoding step.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step2-2.png" width="500">
<figcaption>Embeddings of the answer passages are added to the Document after the encoding step1</figcaption>
</figure>
</p>
<p>The encoding step uses an <strong>Executor</strong>, namely the <strong>Encoder</strong>. Let's understand this more next.</p>
<h4>Step 2. Encode Answer Passages</h4>
<p align="center">
<img src="/assets/images/blog/financial-qa/Encoder.png" width="300">
</p>
<p>After defining the Document for the <strong>Index Flow</strong>, the next step is to encode the answer text into embeddings
using a pre-trained BERT model. The logic that does the encoding is called an <strong>Encoder</strong>, which is part of Jina's family
of <strong>Executors</strong>.</p>
<p>We will look at other Executors later and only focus on the Encoder for now. Instead using TensorFlow
or PyTorch with the combination of Hugging Face transformers and implementing the Encoder ourselves, we can simply take advantage
of <a href="https://github.com/jina-ai/jina-hub">Jina Hub</a>, an <strong>open-registry for hosting Jina Executors via container images</strong>.</p>
<p>There are all kinds of Encoders and other types of Executors in Jina Hub for different tasks and data types
(e.g. image, video, audio, multimodal), allowing us to <strong>ship and exchange reusable component and build various
deep learning-based search engines, e.g. text-image, cross-modal, and multi-modal searches.</strong>
Since our task is a text-to-text search, we will use the
<a href="https://github.com/jina-ai/jina-hub/tree/master/encoders/nlp/TransformerTorchEncoder">TransformerTorchEncoder</a> for this tutorial.</p>
<p>Before we talk about how to use the Encoder in our Index Flow, let's understand three more important Jina concepts in this
step:</p>
<p align="center">
<img src="/assets/images/blog/financial-qa/Driver.png" width="300">
</p>
<ul>
<li><strong>Driver:</strong> Recall Jina uses Protobuf to send messages between the microservices in the Flow, which are in the form of bytes.
We would have a problem if we were to pass the Document directly to the Encoder because the Encoder needs the
answer text as input instead of bytes. Instead of dealing directly with Protobuf, Jina uses <strong>Drivers</strong> to <strong>translate
data for an Executor</strong>, so that we only need to work with data types that we are familiar with (e.g. text, image, np,array, etc...).
<strong>The Driver interprets messages in the Flow and passes the appropriate data to the Executor.</strong></li>
</ul>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step2.png" width="550">
<figcaption>Encoder - the Driver receives the Document in byes and passes the text to the Encoder. The Encoder outputs the embeddings of the text and the Driver adds them to the Document.</figcaption>
</figure>
</p>
For example, in the encoding step, the Driver receives the Document in bytes, interprets it as a Document, and passes the text in the Document to the Encoder.
After the Encoder outputs the embeddings for the corresponding text, the Driver 
again interprets the embeddings, and adds them to the Document. The Document below shows how it has be transformed by
the Driver in the encoding step and will serve as the input for the next indexing step.
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step2-2.png" width="500">
<figcaption>The Driver transformed the Document by adding the embeddings in the encoding step.</figcaption>
</figure>
</p>
<ul>
<li><strong>Pea:</strong> Since an Executor needs a Driver to be able to process our data, they are both necessary components of a
microservice in the Flow. Therefore, we use a <strong>Pea</strong> to wrap the Executor and Driver together to get our <strong>Encoder Microservice</strong>.
The Pea is, therefore, a <strong>microservice</strong> that constantly listens for incoming messages from the gateway or other Peas in
the Flow and calls the Driver when it receives a message. As a microservice, <strong>Peas can also run in Docker, containing all dependencies and context in one place.</strong></li>
</ul>
<p align="center">
<img src="/assets/images/blog/financial-qa/Pea.png" width="300">
</p>
<ul>
<li>
<p><strong>Pod:</strong> To optimize our neural search application, <strong>Jina provides parallelization out of the box.</strong> Instead of having a
single Encoder, we can split it into <strong>multiple processes</strong>. The visualization of the Encoding step shows the Encoder being split into three
processes with each process wrapped by a Pea.</p>
<p><strong>In order for our multiple Encoder microservices to behave functionally as one Encoder, we wrap the group of homogeneous (identical) Peas in a Pod</strong>.
The Pod is, therefore, a <strong>group of homogeneous microservices</strong> that is also responsible for load balancing, further control and context management.
The beauty about this design is that a Pod can either run on the local host or on different computers over a network,
making our application <strong>distributed, efficient, and scalable</strong>.</p>
</li>
</ul>
<p align="center">
<img src="/assets/images/blog/financial-qa/Pod.png" width="300">
</p>
<p>Now that we understand these foundational concepts, <strong>how do we create a Pod for the Encoder?</strong></p>
<p>It may all sound extremely
complicated, but with the building blocks provided by Jina we can <strong>(1) design an Index Flow and (2) create an Encoder
Pod with two simple YAML files.</strong> These YAML files will allow us to customize our neural search application without
touching the core of Jina's code.</p>
<p align="center">
<img src="/assets/images/blog/financial-qa/YAML.png" width="300">
</p>
<p><strong>I. Create a Pod for the Encoder</strong></p>
<p>Let's first create a file <code>encode.yml</code> inside the folder called <code>pods</code>. In <code>encode.yml</code>
we first specify the name of the Encoder we want to use from Jina Hub <code>TransformerTorchEncoder</code>. We can
choose the model we want to use, in our case we use <a href="https://github.com/ProsusAI/finBERT">FinBERT</a>, which further
pre-trained <code>bert-base-uncased</code> on a large financial corpus. Since <code>TransformerTorchEncoder</code> was implemented
using Hugging Face transformers, you can also directly use the model by specifying its name if it is available on
the <a href="https://huggingface.co/docs">Hugging Face Model Hub</a>. We can also include other hyperparameters such as the
maximum sequence length or pooling strategy.</p>
<script src="https://gist.github.com/yuanbit/2890f74af6ae9d15bc316cc9ef4ec8aa.js"></script>
<p>Simple as that! 🐣 <strong>We just created a deep learning-based Encoder microservice ready to be parallelized!</strong>
The <code>pods</code> folder will also be the home to other Pods that we will need, which will
also be defined using YAML files.</p>
<p><strong>II. Add the Encoder to the Index Flow</strong></p>
<p>Now that we have our Encoder ready, let's put it in our Index Flow. Let's create a file <code>index.yml</code> inside a
folder called <code>flows</code>. In <code>index.yml</code>, we specify our first Pod in the Index Flow which is the <code>encoder</code> by
giving the path to our <code>pods/encode.yml</code> file. We can specify how many processes we want to split the Encoder into
by using the <code>parallel</code> parameter. This will be an environment variable specified in <code>app.py</code>, which we will
look at in the end. <code>parallel</code> also <strong>determines how many Peas we will have in each Pod.</strong></p>
<script src="https://gist.github.com/yuanbit/e7cbcdcc83c0f03d0582b9cc58b18294.js"></script>
<p>Well done! 💪 You've just created a pipeline for deep learning-powered microservices! Next, let's finish the design of the Index
Flow by adding another Pod containing the Indexer.</p>
<h4>Step 3. Indexing</h4>
<p align="center">
<img src="/assets/images/blog/financial-qa/Indexer.png" width="300">
</p>
<p>After obtaining the embeddings for the answer passages, we will create another Executor called the <strong>Indexer</strong>
to store our data so that they can be retrieved in query time. Similar to the previous step, the Driver receives the
Document and passes the <code>docid</code>, <code>doc</code>, and <code>embeddings</code> to the Indexer.</p>
<p>We will use the <strong>Compound Indexer</strong>,
which acts as a single indexer using both the <strong>(1) Vector</strong> and <strong>(2) Key-Value Indexers</strong> from Jina Hub:</p>
<ol>
<li>
<p><strong>Vector Indexer:</strong> Stores the answer embeddings and is queried by the question embedding to retrieve
the closest answer embeddings using the k-nearest neighbors algorithm.</p>
</li>
<li>
<p><strong>Key-Value (KV) Indexer:</strong> Stores the Document data (text, blob, metadata) and is queried by the Document id (normally
extracted from the Vector Indexer) to retrieve the information of the data such as answer id and text.</p>
</li>
</ol>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step3.png" width="600">
<figcaption>The Indexer will store our data so that they can be retrieved in query time</figcaption>
</figure>
</p>
<p>We again wrap the Driver and Indexer in a Pea, group identical Peas in a Pod, and define them using YAML files.</p>
<p><strong>I. Create a Pod for the Indexer</strong></p>
<p>Let's create the file <code>pods/doc.yml</code> and define our compound indexer as <code>!CompoundIndexer</code> with the components
<code>!NumpyIndexer</code> which is the Vector Indexer and <code>!BinaryPbIndexer</code> which is the KV Indexer. The indexed data
will be stored in <code>vec.gz</code> and <code>doc.gz</code> respectively. The <code>workspace</code>
is the directory where the indexes will be stored, which will be inside our working directory.</p>
<script src="https://gist.github.com/yuanbit/6538a696b012e565d45f960b400e396f.js"></script>
<p><strong>II. Add the Indexer to the Index Flow</strong></p>
<p>Now let's go back to <code>flows/index.yml</code> and add our Indexer to the Index Flow as <code>doc_indexer</code>. If our data is
big, we can also add sharding to our application for optimization. This will also be used as an environment variable
in <code>app.py</code>, which we will see later.</p>
<script src="https://gist.github.com/yuanbit/ba5310ace80201c69e6cff498a1f3905.js"></script>
<p>Great job! 👏 You have just designed a cloud-native pipeline for indexing financial answer passages! We can
also use Jina's <a href="https://docs.jina.ai/chapters/flow/index.html">Flow API</a> to
visualize the Index Flow. First let's set our environment variables in the terminal for parallel and shards:</p>
<pre><code>export JINA_PARALLEL='1'
export JINA_SHARDS='1'
</code></pre>
<p>Next, let's open a <code>jupyter notebook</code> in our working directory and do the following:</p>
<script src="https://gist.github.com/yuanbit/66d4df6a197e107b9be6b4ef495c7fa2.js"></script>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-jina.png" width="1000">
<figurecaption>Index Flow visualzation</figurecaption>
</figure>
</p>
<p>Here we see our Index Flow with two Pods - the Encoder, <code>encoder</code> and Indexer, <code>doc_indexer</code>.</p>
<h4>Build an Indexer Application</h4>
<p>Let's see how we can use the Index Flow as our application. In <code>app.py</code>, we can change
<code>parallel</code> in the <code>config</code> function to indicate how many Peas (processes)
we want to split each microservice in for each Pod. We can also change <code>shards</code>
to indicate parallelization during the indexing step. We will leave both of them unchanged for now.
This means that we will only have one Pea in each Pod.</p>
<p>Let's first import <code>Flow</code> from Jina's <a href="https://docs.jina.ai/chapters/flow/index.html">Flow API</a>:</p>
<script src="https://gist.github.com/yuanbit/752eef2f8355d5243202c00949dbfcb0.js"></script>
<p>After the <code>index_generator</code> function that we added in <a href="#step-1-define-our-data">Step 1. Define our data</a>,
let's add the <code>index</code> function which will first load the Index Flow that we have created in <code>flows/index.yml</code>
and pass the input Document from <code>index_generator</code> to the flow. We set our <code>batch_size=16</code> for encoding
the answer passages into embeddings.</p>
<script src="https://gist.github.com/yuanbit/c2ffa20fbce1a7ce8fc55597d32723e3.js"></script>
<p>We are now ready to index our data. In the our working directory run:</p>
<pre><code>python app.py index
</code></pre>
<p><a href="https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH"><img src="https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH.svg" alt="asciicast"></a></p>
<p>At the end you will see the following:</p>
<pre><code>✅ done in ⏱ 1 minute and 54 seconds 🐎 7.7/s
        gateway@18904[S]:terminated
    doc_indexer@18903[I]:recv ControlRequest from ctl▸doc_indexer▸⚐
    doc_indexer@18903[I]:Terminating loop requested by terminate signal RequestLoopEnd()
    doc_indexer@18903[I]:#sent: 56 #recv: 56 sent_size: 1.7 MB recv_size: 1.7 MB
    doc_indexer@18903[I]:request loop ended, tearing down ...
    doc_indexer@18903[I]:indexer size: 865 physical size: 3.1 MB
    doc_indexer@18903[S]:artifacts of this executor (vecidx) is persisted to ./workspace/doc_compound_indexer-0/vecidx.bin
    doc_indexer@18903[I]:indexer size: 865 physical size: 3.2 MB
    doc_indexer@18903[S]:artifacts of this executor (docidx) is persisted to ./workspace/doc_compound_indexer-0/docidx.bin
</code></pre>
<p>Hooray 🙌 we finished the first part of our application! The embedding indexes and Document data will be stored in a directory called <code>workspace</code>.</p>
<h3>Query Flow</h3>
<p>After indexing our data, we need to create a <strong>Query Flow</strong>. The main idea behind the Query Flow is to use the
same BERT-based model to <strong>encode a given question into an embedding</strong> and use the Indexer to <strong>search for the most
similar answer embeddings</strong>. To further improve the search results, we will use the same reranking technique as my thesis
Therefore, we will need to add another a reranking step using FinBERT-QA to recompute the scores of the answer matches returned by Jina.</p>
<p align="center">
<figure>
<a href="https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png">
<img src="/assets/images/blog/financial-qa/query-flow.png" width="1000">
</a>
<figurecaption>Query Flow</figurecaption>
</figure>
</p>
<p>Let us again walk through the steps one by one.</p>
<h4>Step 1. Encode Question</h4>
<p>Let's assume that the question text will be a user input. Jina will take this input and
define a new Document.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step1.png" width="500">
<figurecaption>Encoder in the Query Flow</figurecaption>
</figure>
</p>
<p><strong>I. Add the Encoder to the Query Flow</strong></p>
<p>Just like the encoding step of the Index Flow, we encode the questions using the same Encoder. Therefore, we can use the same Encoder from <code>pods/encode.yml</code>
in our <strong>Query Flow</strong>. We will create a new <code>query.yml</code> file in the <code>flows</code> folder and
add the Encoder Pod to it:</p>
<script src="https://gist.github.com/yuanbit/768020d68924e16cefeb052602ecf4f2.js"></script>
<h4>Step 2. Search Indexes</h4>
<p>After encoding the questions, the question embeddings will be added to the Document by the Driver. This Document
is then sent to the Indexer in the next Pod and the Driver will pass the question embeddings to the Indexer.
The Indexer will then search for the answers with the most similar embeddings using the k-nearest neighbors algorithm and
pass a list of top-k answer matches to the Driver to be added to the Document.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step2.png" width="500">
<figurecaption>The Indexer will search for the answers with the most similar embeddings</figurecaption>
</figure>
</p>
<p>The matches will contain data
such as the <code>docid</code>, <code>doc</code>, and match <code>scores</code>. Since we are also using the same
Indexer from the Index Flow, all we need to do again is add the Indexer Pod to <code>flows/query.yml</code>:</p>
<script src="https://gist.github.com/yuanbit/f1358c0b825caf2fe406605ec0ae583c.js"></script>
<h4>Step 3. Reranking</h4>
<p align="center">
<img src="/assets/images/blog/financial-qa/Ranker.png" width="300">
</p>
<p>Let's assume that the Indexer returns the top-k answer matches at this point and we want to recompute the match scores to
get better results. Jina has a class of Executors called the <strong>Rankers</strong>, in particular, the <strong>Match2DocRankers</strong>
re-scores the matches for a query by calculating new scores. If you look at the Rankers on Jina Hub, the
<a href="https://github.com/jina-ai/jina-hub/tree/master/rankers/LevenshteinRanker">Levenshtein Ranker</a> uses the
Levenshtein distance to recompute the match scores.</p>
<p>However, instead of using a distance metric to recompute the scores, we want to load our fined-tuned BERT model,
FinBERT-QA, in the Ranker and recompute the scores by using the concatenation of the question and the
current match answers as inputs into a binary classification task.</p>
<p>In order to do this we need to <strong>create our own custom
Executor</strong> and implement our own logic. In this section we will use <strong>PyTorch</strong> and <strong>Hugging Face transformers</strong>
to implement our custom Ranker.</p>
<p>The main idea here is to pass our query text and the matches (containing the answer text and match scores) to the
Ranker to return a reordered list of matches based on the relevancy scores computed by FinBERT-QA. The Driver will
then update the matches in the Document based on this reordered list.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step3.png" width="550">
<figurecaption>The Ranker recomputes the scores of the matches using FinBERT-QA</figurecaption>
</figure>
</p>
<p>Recall that Peas can run in Docker, this means that we can simply <strong>build a Docker image with our implementation
of the Ranker and use the image in the Query Flow.</strong> The Jina Hub API let's use to Cookiecutter to create the templates of all
the files we will need to do this. Let's get started by making sure that the Jina Hub extension is installed:</p>
<pre><code>pip install "jina[hub]"
</code></pre>
<h4>Build a Custom Executor</h4>
<p>Let's first create the templates that we will need to build a Docker image for our custom Ranker.</p>
<p><strong>1.) Set up.</strong></p>
<p>In the
<code>financial-qa-search/</code>
directory type:</p>
<pre><code>jina hub new
</code></pre>
<p>This will pop up a wizard that helps you walk through the process. Let's give our Executor the name <code>FinBertQARanker</code>
and make sure to select <code>4 - Ranker</code> for the Executor type. We will use <code>jinaai/jina</code> as our base image for
the Docker image that we will build.</p>
<pre><code>You've downloaded /Users/bithiah/.cookiecutters/cookiecutter-jina-hub before. Is it okay to delete and re-download it? [yes]: yes
executor_name [The class name of the executor (UpperCamelCase)]: FinBertQARanker
Select executor_type:
1 - Encoder
2 - Crafter
3 - Indexer
4 - Ranker
5 - Evaluator
Choose from 1, 2, 3, 4, 5 [1]: 4
description [What does this executor do?]: recomputes match scores using FinBERT-QA                
keywords [keywords to describe the executor, separated by commas]: 
pip_requirements []: 
base_image [jinaai/jina]: 
author_name [Jina AI Dev-Team (dev-team@jina.ai)]: 
author_url [https://jina.ai]: 
author_vendor [Jina AI Limited]: 
docs_url [https://github.com/jina-ai/jina-hub]: 
version [0.0.1]: 
license [apache-2.0]: 
</code></pre>
<p>After pressing Enter, you will see a new directory called <code>FinBertQARanker</code>. Your file structure should now look
as follows:</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/file-structure.png" width="650">
<figurecaption>Project folder structure</figurecaption>
</figure>
</p>
<p>We will the implement our logic of the Ranker in <code>__init__.py</code>, write some tests in <code>tests/test_finbertqaranker.py</code>, and
change the <code>Dockerfile</code> to contain everything we need to build the image.</p>
<p><strong>The code for the Ranker can be found <a href="https://github.com/jina-ai/examples/tree/example-financial-qa-search/financial-qa-search/FinBertQARanker">here</a>.</strong></p>
<p><strong>2.) Fill in the logic for reranking.</strong></p>
<p>We will now implement our logic in <code>__init__.py</code>, which should look like the following:</p>
<script src="https://gist.github.com/yuanbit/f0fb64b29b46f45c59469fe4ef3495b9.js"></script>
<p>Jina contains different base classes for the Executors with different functionalities. The base Ranker class
that we will use is called <strong>Match2DocRankers</strong>, which has the functionality to recompute the match scores.</p>
<p>Let's first change the base class of <code>BaseRanker</code> to <code>Match2DocRanker</code>.
Let's also import <strong>PyTorch</strong> using Jina and some other modules that we will need as well as define our current directory.</p>
<script src="https://gist.github.com/yuanbit/6969968f9d5a6e4a081347ff272edce0.js"></script>
<p>Our logic will be implemented in the <code>FinBertQARanker</code> class which will use <code>TorchDevice</code> and
<code>Match2DocRanker</code> from Jina. We will download the models that we need in the <code>Dockerfile</code> later.
Let us assume now we have two models in the folder <code>models/</code>: (1) <code>bert-qa/</code> and (2) <code>2_finbert-qa-50_512_16_3e6.pt</code>.</p>
<p>(1) <code>bert-qa</code>: bert-base-uncased fine-tuned on the MS Macro dataset
from <a href="https://github.com/nyu-dl/dl4marco-bert">Passage Re-ranking with BERT</a></p>
<p>(2) <code>2_finbert-qa-50_512_16_3e6.pt</code>: FinBERT-QA model - fine-tuned <code>bert-qa</code> on the FiQA dataset.</p>
<p>We first specify <code>bert-qa/</code> as the the pre-trained model that would be used for initialization,
<code>2_finbert-qa-50_512_16_3e6.pt</code> as the model that would be used to compute the QA relevancy scores,
and the maximum sequence length for the QA pairs:</p>
<script src="https://gist.github.com/yuanbit/47faac3565dda220b71a77fe3a120d61.js"></script>
<p>Then we add a <code>post_init</code> function to the class to load the models for the binary classification task. Make sure to
set the model in evaluation mode.</p>
<script src="https://gist.github.com/yuanbit/5db6428baf752471c4326d1d1e650906.js"></script>
<p>Now let's implement a private <code>_get_score</code> function to compute each of the relevancy scores of the question
and the top-k answer matches. We first concatenate the question and each top-k answer and encode them to get the
inputs (<code>input_ids</code>, <code>token_type_ids</code>, <code>att_mask</code>) that the model needs using the
tokenizer from transformers. We then feed the inputs into the model and get the prediction scores
that the QA pairs are relevant (<code>label = 1</code>). We apply the softmax function to the scores to transform the
prediction scores into probabilities between 0 and 1. The output would then be the relevancy score in the form of a
probability for the QA pair.</p>
<script src="https://gist.github.com/yuanbit/5efb50d17b97f7eb594c7f88ee116c3a.js"></script>
<p>Lastly, let's fill in the scoring function that takes the question from the user and Jina's match scores as input
and uses <code>_get_scores</code> to recompute new scores:</p>
<script src="https://gist.github.com/yuanbit/b2be4165f2151fa69e9c88a21334c898.js"></script>
<p><strong>3.) Write a Unit Test</strong></p>
<p>In order to create a new Executor and build a Docker image with the Jina Hub API, we need to write a unit test. We can
find a template for this in <code>tests/test_finbertqaranker.py</code>. I wrote a simple check to compute the relevance
probability for two answer matches given a query and to check to see if <code>FinBertQARanker</code> computes the same
score as our expectation:</p>
<script src="https://gist.github.com/yuanbit/8ce93efa42f7c56a2a224e7b8c8e86cb.js"></script>
<p><strong>4.) Add Requirements</strong></p>
<p>Other than Jina we are also using PyTorch and transformers for <code>FinBertQARanker</code>, so let's add them
to <code>FinBertQARanker/requirements.txt</code>:</p>
<pre><code>torch==1.7.1
transformers==4.0.1
</code></pre>
<p><strong>5.) Prepare Dockerfile</strong></p>
<p>Let's change our <code>Dockerfile</code> to the contents below, which will download the models into a folder called <code>models/</code>.</p>
<script src="https://gist.github.com/yuanbit/b226b930c0850b92eee9a25852278388.js"></script>
<p><strong>6.) Build Docker image with Jina Hub API</strong></p>
<p>We are finally ready to build <code>FinBertQARanker</code> into a Docker image. In our working directory, let's type:</p>
<pre><code>jina hub build FinBertQARanker/ --pull --test-uses --timeout-ready 60000
</code></pre>
<p><code>--pull</code> downloads our Jina base image if it is not already local.</p>
<p><code>--test-uses</code> adds an extra test to check if the built image can dry-run successfully via Jina's Flow API.
<code>--timeout-ready</code> gives our <code>post_init</code> function time to load the models.</p>
<p>If the build is successful, you will see this message:</p>
<pre><code> HubIO@10240[I]:Successfully built ba3fac0f3a46
 HubIO@10240[I]:Successfully tagged jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.13
 HubIO@10240[I]:building FinBertQARanker/ takes 6 minutes and 12 seconds (372.31s)
 HubIO@10240[S]:🎉 built jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.13 (sha256:ba3fac0f3a) uncompressed size: 3.3 GB
</code></pre>
<p>Congratulations 🥳, you have successfully built a custom Executor in the form of a Docker image with the tag name
<code>jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.23</code>! Let's see how we can use it in the Query Flow next.</p>
<p><strong>I. Create a custom Ranker Pod</strong></p>
<p>To use our custom Ranker, <code>FinBertQARanker</code>, we need to first create a new Pod for the Ranker. Let's create
the file <code>rank.yml</code> in the <code>pods</code> folder. Next, let's copy the contents from <code>FinBertQARanker/config.yml</code>
to <code>pods/rank.yml</code> and you should have the following:</p>
<script src="https://gist.github.com/yuanbit/24c93873f7594ee0a097ea1550cc1d66.js"></script>
<p>This is going to tell the Query Flow to use the logic we have implemented in our Exectuor, <code>FinBertQARanker/__init__.py</code>.
Since the code for this implementation is loaded inside the <code>workspace</code> folder in the Docker image, let's add
<code>workspace/</code> before <code>__init__.py</code>.</p>
<p>The Encoder and Indexer Executors that we have used so far all use default Drivers in the Pods. Since we created our custom
Executor, we need to tell the Ranker Pod which Driver to use. In this case we will use the <code>Matches2DocRankDriver</code> for the
<code>Match2DocRanker</code> base Ranker class. Hence, our <code>rank.yml</code> will look as follows:</p>
<script src="https://gist.github.com/yuanbit/7757c64f850b4dd43c95e56d2f0a2909.js"></script>
<p>Hooray 🎊 we now have a custom Ranker Pod! Let's see next how we can use it in the Query Flow.</p>
<p><strong>II. Use Custom Ranker in the Query Flow</strong></p>
<p>Like the other Executor Pods, we just need to add <code>ranker</code> after the <code>doc_indexer</code> and tell the Query Flow to use
the Docker image and Ranker Pod that we have just created by specifying the prefix <code>docker://</code> in front of the tag name. The final <code>flows/query.yml</code> should look as follows:</p>
<script src="https://gist.github.com/yuanbit/f5e5291f7a30e4c43da63fb9ef537608.js"></script>
<p><strong>Be aware that the tag name of the Docker image might change</strong> depending the current Jina release. Make sure to change the
tag name that accordingly to your build message.</p>
<p>We can again visualize the Query Flow using the Flow API in a  <code>jupyter notebook</code> as follows:</p>
<script src="https://gist.github.com/yuanbit/13e879fa8de427c7b8be8eadfc995ac6.js"></script>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-jina.png" width="1000">
<figurecaption>Query Flow visualization</figurecaption>
</figure>
</p>
<p>Here we see our Query Flow with three Pods containing the Encoder, <code>encoder</code> and Indexer, <code>doc_indexer</code>,
and Ranker, <code>ranker</code>.
At the end of the Query Flow, the Driver from the Ranker Pod will have changed the matches in the Document to an reordered list of
matches based on the probabilities computed by our custom Ranker, <code>FinBertQARanker</code>. Next, we will see how we can
access this list of final matches in our <code>app.py</code>.</p>
<h4>Build a Search Application</h4>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step4.png" width="550">
<figurecaption>Get matches and scores stored in the Document</figurecaption>
</figure>
</p>
<p>Since our final matches and their relevancy probability are stored in the Document, in <code>app.py</code>, we can
write a function to print out the response to a question from the user input. We can loop through the matches in our
Document, <code>d.matches</code>, and print out the values of the scores and the matching answer text.</p>
<script src="https://gist.github.com/yuanbit/1e18bcb2e7dbc77812a94ccefc6d1fcc.js"></script>
<p>We can then write our <code>search</code> method that uses the Query Flow from <code>flows/query.yml</code> and passes
the user inputs into <code>print_resp</code>. In <code>f.search_lines()</code>, we specify the input as our user query,
the output as the response to be printed, and the top-k answers we want to retrieve. The cool thing about
<code>f.search_lines()</code> is that it automatically creates a Document for the user query, like sugar magic 🍬!</p>
<script src="https://gist.github.com/yuanbit/434ef56655bea8daf8b8275348387e36.js"></script>
<p>Hooray! 🎉🎉🎉 We have just finished building our Financial QA search engine! We can now run:</p>
<p><code>python app.py search</code></p>
<p>and try out different questions! The Ranker might take some time to compute the relevancy
scores since it is using a BERT-based model. Here is a list of sample questions:</p>
<pre><code>• What does it mean that stocks are “memoryless”?
• What would a stock be worth if dividends did not exist?
• What are the risks of Dividend-yielding stocks?
• Why do financial institutions charge so much to convert currency?
• Is there a candlestick pattern that guarantees any kind of future profit?
• 15 year mortgage vs 30 year paid off in 15
• Why is it rational to pay out a dividend?
• Why do companies have a fiscal year different from the calendar year?
• What should I look at before investing in a start-up?
• Where do large corporations store their massive amounts of cash?
</code></pre>
<p align="center">
<img src="/assets/images/blog/financial-qa/search-results.png" width="900">
</p>
<h2>Summary</h2>
<p>In this blog, I introduced core Jina concepts and demonstrated how to build a production-ready Financial QA system using Jina.
I also explained how to use the Jina Hub API to create a BERT-powered Ranker Executor. Thanks to
the building blocks that Jina provides, we could easily use the SOTA and powerful model, FinBERT-QA, in production.</p>
<p>The neural search application we have just built with Jina runs locally on our own machines, but can also
be completely distributed and run on multiple machines in a network, making our application highly reusable, scalable,
and efficient. On top of that, common cloud-native features such as persistence, scheduling, chaining, grouping, and
parallelization all come out of the box.</p>
<p>Moreover, there are variants of pre-trained BERT models for other domains such as <a href="https://github.com/dmis-lab/biobert">biomedical</a>,
<a href="https://github.com/allenai/scibert">science</a>, and <a href="https://huggingface.co/nlpaueb/legal-bert-base-uncased">legal</a>.
You can use these models to build a QA search application and experiment with the results!</p>
<h2>Next Step: Evaluation</h2>
<p>If you made it all the way through this tutorial, you might be wondering, <strong>"how do I evaluate the search results?"</strong>.
Great question! Jina has a class of Executors called the <strong>Evaluator</strong> and has implementations of common evaluation
metrics like Precision and Reciprocal Error. Evaluation is an important step and will allow us to optimize
the search results and design the most effective Flows. We will see in the next tutorial how we can add the
Evaluator in our Financial QA application.</p>
<h2>Learn More</h2>
<p>To learn more about Jina, I recommend reading the following articles:</p>
<ul>
<li><a href="https://medium.com/jina-ai/what-is-jina-and-neural-search-7a9e166608ab">What is Jina and Neural Search?</a></li>
<li><a href="https://hanxiao.io/2020/10/19/A-Curated-List-of-Neural-Search-and-Jina-Framework-Designs/">From Then to Now: a Curated List for Neural Search and Jina</a></li>
</ul>
<p>and checking out our <a href="https://github.com/jina-ai/jina">Github</a> page!</p>
<p>If you want to learn Jina by doing, I encourage you to start building your own examples and
sharing them with the community to help us grow our open-source ecosystem! 🚀 For example, check out this
<a href="https://github.com/ArturTan/transformers-for-lawyers">community project - transformers-for-lawyers</a> built with Jina.</p>
<p>We saw how versatile and extensible Jina is and we could create all kinds of search applications using our own
logic and models for NLP, Computer Vision, and other ML search applications.
<strong><a href="https://github.com/jina-ai/jina-hub">Jina Hub</a> is a great place to get started, where you can use
the available Executors to build other types of search engines (for images, videos, etc...) or create your own
Executors using the Jina Hub API!</strong> You can always come back to this tutorial and walk through the process again.</p>
<p><strong>As an open-source company we would also love your help and contributions.️</strong> We have issues labelled as <a href="https://github.com/jina-ai/jina/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">good first issue</a>
to get started! You can read more about our contributing guidelines <a href="https://github.com/jina-ai/jina/blob/master/CONTRIBUTING.md">here</a>.</p>
<p>If you want to know more about Jina's new features or ask any questions, welcome to join our <a href="https://slack.jina.ai/">Slack Community</a>
and our monthly public <a href="https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/">Engineering All Hands</a> via
Zoom or Youtube live stream.</p>
<p>If you are interested in joining us as a full-time AI / Backend / Frontend developer,
please submit your CV to our <a href="jobs.jina.ai">job portal</a>. Let’s build the next open-source neural search ecosystem together!</p>
<h2>Community</h2>
<ul>
<li><a href="slack.jina.ai">Slack channel</a> - a communication platform for developers to discuss Jina</li>
<li><a href="mailto:newsletter+subscribe@jina.ai">Community newsletter</a> - subscribe to the latest update, release and event news of Jina</li>
<li><a href="https://www.linkedin.com/company/jinaai/">LinkedIn</a> - get to know Jina AI as a company and find job opportunities</li>
<li><a href="https://twitter.com/JinaAI_">Twitter</a> - follow us and interact with us using hashtag <code>#JinaSearch</code></li>
<li><a href="https://jina.ai">Company</a> - know more about our company, we are fully committed to open-source!</li>
</ul>
</div><div class="jsx-4055754880 hidden"><p>Learn how to use the neural search framework, <strong><a href="https://github.com/jina-ai/jina">Jina</a></strong>, to build a <strong>Financial Question Answering (QA) search application</strong>
using the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset, <a href="https://pytorch.org">PyTorch</a>, and <a href="https://github.com/huggingface/transformers">Hugging Face transformers</a>.</p>
<p>For my master’s thesis, I built a Financial QA system using a fine-tuned BERT model called
<a href="https://github.com/yuanbit/FinBERT-QA">FinBERT-QA</a>. Motivated by the emerging demand in the financial industry for
the automatic analysis of unstructured and structured data at scale, <strong>QA systems can provide lucrative and competitive
advantages</strong> to companies by facilitating the decision making of financial advisers.</p>
<p>The goal of my thesis was to search for a ranked list of relevant answer passages given a question.
Here is an example of a financial domain-based question and a ground truth answer from the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset:</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/sample-qa.png" alt="performance" width="450px">
<figcaption>Sample QA from the financial domain</figcaption>
</figure>
</p>
<p>Here is a list of other questions from <a href="https://sites.google.com/view/fiqa/home">FiQA</a>:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>• What does it mean that stocks are “memoryless”?
</span><span>• What would a stock be worth </span><span style="color:#fb9e00;font-weight:normal">if</span><span> dividends did </span><span style="color:#fb9e00;font-weight:normal">not</span><span> exist?
</span>• What are the risks of Dividend-yielding stocks?
<!-- -->• Why do financial institutions charge so much to convert currency?
<span>• Is there a candlestick pattern that guarantees </span><span style="color:#fb9e00">any</span><span> kind of future profit?
</span><span>• </span><span style="color:#fa658d">15</span><span> year mortgage vs </span><span style="color:#fa658d">30</span><span> year paid off </span><span style="color:#fb9e00;font-weight:normal">in</span><span> </span><span style="color:#fa658d">15</span><span>
</span><span>• Why </span><span style="color:#fb9e00;font-weight:normal">is</span><span> it rational to pay out a dividend?
</span><span>• Why do companies have a fiscal year different </span><span style="color:#fb9e00;font-weight:normal">from</span><span> the calendar year?
</span><span>• What should I look at before investing </span><span style="color:#fb9e00;font-weight:normal">in</span><span> a start-up?
</span>• Where do large corporations store their massive amounts of cash?
<!-- -->
</code></pre>
<p>Financial QA is <strong>hard</strong> because the vocabularies are context specific, for example, a machine would
have a hard time understanding what an <em>ETF</em> is. Nevertheless, <strong>with the power of BERT, I improved the state-of-the-art (SOTA) results by an average of 19% on three
evaluation metrics (Precision, MRR, NDCG)</strong>.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/model-performance.png" alt="performance" width="600px">
<figcaption>Evaluation results from <a href="https://github.com/yuanbit/FinBERT-QA">FinBERT-QA</a></figcaption>
</figure>
</p>
<p>Even though my thesis was about QA in the financial domain, the approach that I have used can be applied to a
<a href="https://github.com/microsoft/MSMARCO-Passage-Ranking">general QA dataset</a> or QA in other domains such as
<a href="https://github.com/shuzi/insuranceQA">insurance</a>.</p>
<p>After finishing my thesis, I realized that <strong>just having a model and SOTA results is not good enough</strong> because there
was a gap between my research and business needs. This was when I discovered <strong>Jina, a framework designed to
help me bridge this gap</strong>. To help people better understand Jina, I prepared this tutorial to demonstrate how
I used Jina to easily <strong>transform my research into a production-ready system</strong>.</p>
<h2>Table of Contents</h2>
<ul>
<li><a href="#background">Background</a>
<ul>
<li><a href="#what-is-jina">What is Jina?</a></li>
<li><a href="#financial-qa-with-bert">Financial QA with BERT</a></li>
<li><a href="#why-jina">Why Jina?</a></li>
</ul>
</li>
<li><a href="#tutorial">Tutorial</a>
<ul>
<li><a href="#set-up">Set Up</a></li>
<li><a href="#index-flow">Index Flow</a>
<ul>
<li><a href="#step-1-define-our-data">Step 1. Define our data</a></li>
<li><a href="#step-2-encode-answer-passages">Step 2. Encode Answer Passages</a></li>
<li><a href="#step-3-indexing">Step 3. Indexing</a></li>
<li><a href="#build-an-indexer-application">Build an Indexer Application</a></li>
</ul>
</li>
<li><a href="#query-flow">Query Flow</a>
<ul>
<li><a href="#step-1-encode-question">Step 1. Encode Question</a></li>
<li><a href="#step-2-search-indexes">Step 2. Seach Indexes</a></li>
<li><a href="#step-3-reranking">Step 3. Reranking</a>
<ul>
<li><a href="#build-a-custom-executor">Build a Custom Executor</a></li>
</ul>
</li>
<li><a href="#build-a-search-application">Build a Search Application</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
<li><a href="#next-steps-evaluation">Next Steps: Evaluation</a></li>
<li><a href="#learn-more">Learn More</a></li>
</ul>
<h2>Background</h2>
<h3>What is Jina?</h3>
<p align="center">
<img src="/assets/images/jina_banner_new.png" width="500">
</p>
<p>Open-source deep learning frameworks such as TensorFlow and PyTorch provide building blocks for designing and quickly implementing
neural network-based applications through a high level programming interface.</p>
<p>Similarly, <strong>Jina</strong> is an <strong>open-source neural search framework</strong> that offers the building blocks for designing and implementing <strong>neural network-based
search applications</strong>.</p>
<p>Co-founded by the creator of <a href="https://github.com/hanxiao/bert-as-service">bert-as-service</a> and
<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a>, Jina enables developers to build
<strong>production-ready cloud-native search systems</strong> using
<strong>SOTA pre-trained deep learning models</strong>, in which each component of the system is a <strong>microservice</strong> that can be deployed, scaled, and maintained independently.</p>
<p align="center">
<img src="/assets/images/blog/financial-qa/cloud.png" width="350">
</p>
<p>If you come from a data science or academic background like me, the terms <strong>cloud-native</strong> and <strong>microservices</strong> may sound
daunting. That's why we will learn by example in this tutorial and use the NLP task, Financial QA, to familiarize ourselves
with Jina's core concepts!</p>
<h3>Financial QA with BERT</h3>
<p>Before we jump into the tutorial, let's first understand how to build a QA system with BERT. Our goal is to
search for the top-k most relevant answer passages when given a question from task 2 of the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset.</p>
<p>In 2018, Google's pre-trained BERT models, used for transfer learning, shook the NLP world and achieved the SOTA
results on numerous tasks, marking NLP's <a href="https://ruder.io/nlp-imagenet/">ImageNet moment</a>.</p>
<p>What is neat about BERT is that we can fine-tune a pre-trained BERT model on our QA task by simply transforming
it into a <strong>binary classification task</strong>, where the input is the <strong>concatenation of a question and an answer</strong> and the
output is a binary label indicating the <strong>relevancy score</strong> of the QA pair. We can then take the softmax scores of
each QA pair to get a probability of relevancy and rank these scores.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/BERT-QA.png" width="400">
<figcaption>Fine-tuning method for our QA task</figcaption>
</figure>
</p>
<p>The <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset has roughly 6,000 questions and 57,000 answers. Instead of
computing a probability for each question 57,000 times, we can adapt a <a href="https://arxiv.org/pdf/1901.04085.pdf">passage reranking</a>
approach. We first use a <strong>Retriever</strong> to return the top-50 candidate answers for each question,
and then use <strong>FinBERT-QA</strong>, a BERT-based model fine-tuned on the <a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset
as a <strong>Reranker</strong> to compute the relevancy scores and rerank the top-50 QA pairs to get the top-10 answers.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/qa-pipeline-simple.png" width="1000">
<figcaption>QA pipeline with reranking</figcaption>
</figure>
</p>
<p>If you are interested in the details of my thesis, you can learn more <a href="https://github.com/yuanbit/FinBERT-QA">here</a>.</p>
<h2>Why Jina?</h2>
<p>Why is having the SOTA model and results is not good enough?</p>
<h3>Jina as a bridge between research and industry</h3>
<p>The motivation behind my research was to be able to help financial advisor answer questions
from large-scale reports. However, the way I implemented the QA pipeline is not reusable and it won't scale
to business demands. <strong>By industry standards, it is not production-ready.</strong></p>
<p>Since <strong>Jina enables us to build cloud-native systems</strong>, which embrace
microservices, instead of wrapping my entire pipeline in a single Docker container, Jina will break down the pipeline
into components (preprocessor, encoder, indexer, etc.). Moreover, each of these components will be a microservice in its own isolated Docker
container managed by the <a href="https://docs.jina.ai/chapters/flow/index.html">Flow API</a>.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/cloud2.svg" width="350">
<figcaption>Illustration from <a href="https://www.manypixels.co/gallery/">manypixels</a></figcaption>
</figure>
</p>
<p>For those of you new to cloud-native concepts, you can think of a microservice as an independent component of your
application, for example, using FinBERT-QA to encode our questions and answers. You can then create multiple independent components
or microservices to construct an application like a BERT-powered QA system. Since each of the components of the application can be deployed independently,
they can also scale individually and respond to rapid changes and business needs.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/business.svg" width="350">
<figcaption>Illustration from <a href="https://www.manypixels.co/gallery/">manypixels</a></figcaption>
</figure>
</p>
<p>Being cloud-native is a modern design that more and more businesses are adapting to because it can help them save resources
and grow. However, designing such systems is not easy. We need to consider many principles, patterns and best practices,
for example, how will the each component communicate with each other? How can they work in parallel? Luckily, instead of starting
from scratch, <strong>Jina does all the hard work for us by providing us the building blocks so that we can easily construct
a cloud-native BERT-powered QA system using an reranking approach that is ready to serve in production!</strong></p>
<h2>Tutorial</h2>
<p>Now that we have an overview, let's learn how to build a production-ready Financial QA system using the reranking approach and
dive deeper into some new Jina terminologies. We will use <a href="https://github.com/ProsusAI/finBERT">FinBERT</a> to encode our
questions and answer passages into embeddings and <a href="https://github.com/yuanbit/FinBERT-QA">FinBERT-QA</a> to rerank
the top-50 answer matches.</p>
<p><strong>The final code of this tutorial can be found <a href="https://github.com/yuanbit/jina-financial-qa-search">here</a>.</strong></p>
<h3>Set up</h3>
<p><strong>Clone the repository</strong> that we will be working together with here:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>git clone https://github.com/yuanbit/jina-financial-qa-search-template.git
</span>
</code></pre>
<p>We will use <code>financial-qa-search/</code> as our working directory.</p>
<p><strong>Install the requirements</strong></p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>pip install -r requirements.txt
</span>
</code></pre>
<p><strong>Download data and model</strong></p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>bash get_data.sh
</span>
</code></pre>
<p>For this tutorial, we won't be searching through all 57,000 answer passages from the
<a href="https://sites.google.com/view/fiqa/home">FiQA</a> dataset. We will work with a sample dataset called <code>test_answers.csv</code>,
containing about 800 answer passages. If you want to experiment with the full dataset, you can use <code>answer_collection.tsv</code>.</p>
<p><strong>Flows</strong></p>
<p>In Jina, we will build a Financial QA system with two pipelines, one for indexing our answer passages and
the other for querying. These pipelines are called <strong>Flows</strong>, which also serve to manage the state and context
of the microservices as well as orchestrating them. Let's see what an overview of
the <strong>Index Flow</strong> and <strong>Query Flow</strong>, you can click on the images to see the details:</p>
<p align="center">
<figure>
<a href="https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/index-flow.png">
<img src="/assets/images/blog/financial-qa/index-flow.png" width="1000">
</a>
<figcaption>Index Flow</figcaption>
</figure>
</p>
<p align="center">
<figure>
<a href="https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png">
<img src="/assets/images/blog/financial-qa/query-flow.png" width="1000">
</a>
<figcaption>Query Flow</figcaption>
</figure>
</p>
<p>To understand these Flows, let's start with the <strong>Index Flow</strong> and look into the individual components one by one.</p>
<h3>Index Flow</h3>
<p>The main idea behind the Index Flow is to use a pre-trained BERT model to encode all of our answer
passages into embeddings then indexing these embeddings so that they can be searched in the Query Flow.</p>
<h4>Step 1. Define our data</h4>
<p>We want to index a subset of  the answer passages from the FiQA dataset, <code>dataset/test_answers.csv</code>:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span style="color:#fa658d">398960</span><span>	From  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  company</span><span style="color:#4cd213">&#x27;s      underlying  value.  Examples  of  business      fundamentals  include  debt,  cash  flow,      supply  of  and  demand  for  the  company&#x27;</span><span>s      products,  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>  so  forth.  For  instance,      </span><span style="color:#fb9e00;font-weight:normal">if</span><span>  a  company  does  </span><span style="color:#fb9e00;font-weight:normal">not</span><span>  have  a      sufficient  supply  of  products,  it  will      fail.  Likewise,  demand  </span><span style="color:#fb9e00;font-weight:normal">for</span><span>  the  product      must  remain  at  a  certain  level  </span><span style="color:#fb9e00;font-weight:normal">in</span><span>      order  </span><span style="color:#fb9e00;font-weight:normal">for</span><span>  it  to  be  successful.  Strong      business  fundamentals  are  considered      essential  </span><span style="color:#fb9e00;font-weight:normal">for</span><span>  long-term  success  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>      stability.  See  also:  Value  Investing,      Fundamental  Analysis.  For  a  stock  the  basic  fundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page,    P/E  ratio,  div/yeild,  EPS,  shares,  beta.      For  the  company  itself  it</span><span style="color:#4cd213">&#x27;s  generally  the  stuff  on  the  &#x27;</span><span>financials</span><span style="color:#4cd213">&#x27;  link    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.
</span><span style="color:#4cd213">19183	If  your  sole  proprietorship  losses  exceed  all  other  sources  of  taxable  income,  then  you  have  what&#x27;</span><span>s  called  a  Net  Operating  Loss  (NOL).  You  will  have  the  option  to  </span><span style="color:#4cd213">&quot;carry  back&quot;</span><span>  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>  amend  a  </span><span style="color:#fb9e00;font-weight:normal">return</span><span>  you  filed  </span><span style="color:#fb9e00;font-weight:normal">in</span><span>  the  last  </span><span style="color:#fa658d">2</span><span>  years  where  you  owed  tax,  </span><span style="color:#fb9e00;font-weight:normal">or</span><span>  you  can  </span><span style="color:#4cd213">&quot;carry  forward&quot;</span><span>  the  losses  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>  decrease  your  taxes  </span><span style="color:#fb9e00;font-weight:normal">in</span><span>  a  future  year,  up  to  </span><span style="color:#fa658d">20</span><span>  years  </span><span style="color:#fb9e00;font-weight:normal">in</span><span>  the  future.  For  more  information  see  the  IRS  links  </span><span style="color:#fb9e00;font-weight:normal">for</span><span>  NOL.  Note:  it</span><span style="color:#4cd213">&#x27;s  important  to  make  sure  you  file  the  NOL  correctly  so  I&#x27;</span><span>d  advise  speaking  </span><span style="color:#fb9e00;font-weight:normal">with</span><span>  an  accountant.  (Especially  </span><span style="color:#fb9e00;font-weight:normal">if</span><span>  the  loss  </span><span style="color:#fb9e00;font-weight:normal">is</span><span>  greater  than  the  cost  of  the  accountant...)
</span><span></span><span style="color:#fa658d">327002</span><span>	To  be  deductible,  a  business  expense  must  be  both  ordinary  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>  necessary.  An  ordinary  expense  </span><span style="color:#fb9e00;font-weight:normal">is</span><span>  one  that  </span><span style="color:#fb9e00;font-weight:normal">is</span><span>  common  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>  accepted  </span><span style="color:#fb9e00;font-weight:normal">in</span><span>  your  trade  </span><span style="color:#fb9e00;font-weight:normal">or</span><span>  business.  A  necessary  expense  </span><span style="color:#fb9e00;font-weight:normal">is</span><span>  one  that  </span><span style="color:#fb9e00;font-weight:normal">is</span><span>  helpful  </span><span style="color:#fb9e00;font-weight:normal">and</span><span>  appropriate  </span><span style="color:#fb9e00;font-weight:normal">for</span><span>  your  trade  </span><span style="color:#fb9e00;font-weight:normal">or</span><span>  business.  An  expense  does  </span><span style="color:#fb9e00;font-weight:normal">not</span><span>  have  to  be  indispensable  to  be  considered  necessary.    (IRS,  Deducting  Business  Expenses)  It  seems  to  me  yo</span><span style="color:#4cd213">u&#x27;d  have  a  hard  time  convincing  an  auditor  that  this  is  the  case.    Since  business  don&#x27;</span><span>t  commonly  own  cars  </span><span style="color:#fb9e00;font-weight:normal">for</span><span>  the  sole  purpose  of  housing  $</span><span style="color:#fa658d">25</span><span>  computers,  yo</span><span style="color:#4cd213">u&#x27;d  have  trouble  with  the  &quot;ordinary&quot;  test.    And  since  there  are  lots  of  other  ways  to  house  a  computer  other  than  a  car,  &quot;necessary&quot;  seems  problematic  also.
</span><span style="color:#4cd213">
</span></code></pre>
<p>Our dataset consists of a column of answer id and text, which we will denote as docid and doc respectively in this tutorial.
In order to index our data, we need to first define it in a Jina data type called <strong>Document</strong>.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step1.png" width="400">
<figcaption>Index Flow - Step 1</figcaption>
</figure>
</p>
<p>In programming languages there are data types such as int, float, boolean, and more. In NumPy, TensorFlow, and PyTorch,
we manipulate and pass around objects such as ndarray and tensor, which are referred to as <strong>primitive data types</strong>.
Similarly, a <strong>Document</strong> is a Jina-specific data type for representing data.</p>
<p><strong>Defining our data in a Document</strong></p>
<p>In our project directory <code>financial-qa-search/</code> the <code>app.py</code> file consists of the Financial QA search application
that we will build.  Notice that we set our data path in the <code>config</code> function as follows:</p>
<script src="https://gist.github.com/yuanbit/f8bc065dbba8382b1dadd0c75203cf9e.js"></script>
<p>You can change the path to <code>answer_collection.tsv</code> to index with the full dataset.</p>
<p>Let's first make sure we import <code>Document</code> from jina:</p>
<script src="https://gist.github.com/yuanbit/f0f5d0a43738f50140e47fa2af6e8fcc.js"></script>
<p>After the <code>config</code> function, let's create a Python generator and define the Document to contain the id and text
corresponding to the answer passages:</p>
<script src="https://gist.github.com/yuanbit/91effc3288862727199a13813f5c33a3.js"></script>
<p>A Document is a high-level way for us to <strong>define and view the contents stored in Protobuf</strong>, which is what Jina uses to
<strong>enable the microservices in the Flow to communicate with each other</strong>. It is like an envelope
containing our data and is used to send messages between the microservices of our Flow. Instead of directly
dealing with Protobuf, which serializes our data into bytes, we can simply print our Document and see that a single answer
passage will look as follows:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span style="color:#fb9e00">id</span><span>: </span><span style="color:#4cd213">&quot;13755c6081bebe1a&quot;</span><span>
</span><span>mime_type: </span><span style="color:#4cd213">&quot;text/plain&quot;</span><span>
</span>tags {
<!-- -->  fields {
<span>    key: </span><span style="color:#4cd213">&quot;id&quot;</span><span>
</span>    value {
<span>      number_value: </span><span style="color:#fa658d">398960.0</span><span>
</span>    }
<!-- -->  }
<!-- -->}
<span>text: </span><span style="color:#4cd213">&quot;From  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  
</span><span style="color:#4cd213">company\&#x27;s underlying  value. Examples  of  business fundamentals  include  debt,  cash  flow, supply  of  and  demand  
</span><span style="color:#4cd213">for  the  company\&#x27;s      products,  and  so  forth.  For  instance, if  a  company  does  not  have  a sufficient  
</span><span style="color:#4cd213">supply  of  products,  it  will      fail.  Likewise,  demand  for  the  product      must  remain  at  a  certain  
</span><span style="color:#4cd213">level  in      order  for  it  to  be  successful.  Strong      business  fundamentals  are  considered essential  for  
</span><span style="color:#4cd213">long-term  success  and      stability.  See  also:  Value  Investing, Fundamental  Analysis.  For  a  stock  the  basic
</span><span style="color:#4cd213">fundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page, P/E  ratio,  
</span><span style="color:#4cd213">div/yeild,  EPS,  shares,  beta.      For  the  company  itself  it\&#x27;s  generally  the  stuff  on  the  \&#x27;financials\&#x27;  
</span><span style="color:#4cd213">link    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.&quot;</span><span>
</span>
</code></pre>
<p><strong>As we move along the Index Flow, the contents of the Document will be changed</strong>, for example, we can see in the Index Flow that
the embeddings of the answer passages are added to the Document after the encoding step.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step2-2.png" width="500">
<figcaption>Embeddings of the answer passages are added to the Document after the encoding step1</figcaption>
</figure>
</p>
<p>The encoding step uses an <strong>Executor</strong>, namely the <strong>Encoder</strong>. Let's understand this more next.</p>
<h4>Step 2. Encode Answer Passages</h4>
<p align="center">
<img src="/assets/images/blog/financial-qa/Encoder.png" width="300">
</p>
<p>After defining the Document for the <strong>Index Flow</strong>, the next step is to encode the answer text into embeddings
using a pre-trained BERT model. The logic that does the encoding is called an <strong>Encoder</strong>, which is part of Jina's family
of <strong>Executors</strong>.</p>
<p>We will look at other Executors later and only focus on the Encoder for now. Instead using TensorFlow
or PyTorch with the combination of Hugging Face transformers and implementing the Encoder ourselves, we can simply take advantage
of <a href="https://github.com/jina-ai/jina-hub">Jina Hub</a>, an <strong>open-registry for hosting Jina Executors via container images</strong>.</p>
<p>There are all kinds of Encoders and other types of Executors in Jina Hub for different tasks and data types
(e.g. image, video, audio, multimodal), allowing us to <strong>ship and exchange reusable component and build various
deep learning-based search engines, e.g. text-image, cross-modal, and multi-modal searches.</strong>
Since our task is a text-to-text search, we will use the
<a href="https://github.com/jina-ai/jina-hub/tree/master/encoders/nlp/TransformerTorchEncoder">TransformerTorchEncoder</a> for this tutorial.</p>
<p>Before we talk about how to use the Encoder in our Index Flow, let's understand three more important Jina concepts in this
step:</p>
<p align="center">
<img src="/assets/images/blog/financial-qa/Driver.png" width="300">
</p>
<ul>
<li><strong>Driver:</strong> Recall Jina uses Protobuf to send messages between the microservices in the Flow, which are in the form of bytes.
We would have a problem if we were to pass the Document directly to the Encoder because the Encoder needs the
answer text as input instead of bytes. Instead of dealing directly with Protobuf, Jina uses <strong>Drivers</strong> to <strong>translate
data for an Executor</strong>, so that we only need to work with data types that we are familiar with (e.g. text, image, np,array, etc...).
<strong>The Driver interprets messages in the Flow and passes the appropriate data to the Executor.</strong></li>
</ul>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step2.png" width="550">
<figcaption>Encoder - the Driver receives the Document in byes and passes the text to the Encoder. The Encoder outputs the embeddings of the text and the Driver adds them to the Document.</figcaption>
</figure>
</p>
For example, in the encoding step, the Driver receives the Document in bytes, interprets it as a Document, and passes the text in the Document to the Encoder.
After the Encoder outputs the embeddings for the corresponding text, the Driver 
again interprets the embeddings, and adds them to the Document. The Document below shows how it has be transformed by
the Driver in the encoding step and will serve as the input for the next indexing step.
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step2-2.png" width="500">
<figcaption>The Driver transformed the Document by adding the embeddings in the encoding step.</figcaption>
</figure>
</p>
<ul>
<li><strong>Pea:</strong> Since an Executor needs a Driver to be able to process our data, they are both necessary components of a
microservice in the Flow. Therefore, we use a <strong>Pea</strong> to wrap the Executor and Driver together to get our <strong>Encoder Microservice</strong>.
The Pea is, therefore, a <strong>microservice</strong> that constantly listens for incoming messages from the gateway or other Peas in
the Flow and calls the Driver when it receives a message. As a microservice, <strong>Peas can also run in Docker, containing all dependencies and context in one place.</strong></li>
</ul>
<p align="center">
<img src="/assets/images/blog/financial-qa/Pea.png" width="300">
</p>
<ul>
<li>
<p><strong>Pod:</strong> To optimize our neural search application, <strong>Jina provides parallelization out of the box.</strong> Instead of having a
single Encoder, we can split it into <strong>multiple processes</strong>. The visualization of the Encoding step shows the Encoder being split into three
processes with each process wrapped by a Pea.</p>
<p><strong>In order for our multiple Encoder microservices to behave functionally as one Encoder, we wrap the group of homogeneous (identical) Peas in a Pod</strong>.
The Pod is, therefore, a <strong>group of homogeneous microservices</strong> that is also responsible for load balancing, further control and context management.
The beauty about this design is that a Pod can either run on the local host or on different computers over a network,
making our application <strong>distributed, efficient, and scalable</strong>.</p>
</li>
</ul>
<p align="center">
<img src="/assets/images/blog/financial-qa/Pod.png" width="300">
</p>
<p>Now that we understand these foundational concepts, <strong>how do we create a Pod for the Encoder?</strong></p>
<p>It may all sound extremely
complicated, but with the building blocks provided by Jina we can <strong>(1) design an Index Flow and (2) create an Encoder
Pod with two simple YAML files.</strong> These YAML files will allow us to customize our neural search application without
touching the core of Jina's code.</p>
<p align="center">
<img src="/assets/images/blog/financial-qa/YAML.png" width="300">
</p>
<p><strong>I. Create a Pod for the Encoder</strong></p>
<p>Let's first create a file <code>encode.yml</code> inside the folder called <code>pods</code>. In <code>encode.yml</code>
we first specify the name of the Encoder we want to use from Jina Hub <code>TransformerTorchEncoder</code>. We can
choose the model we want to use, in our case we use <a href="https://github.com/ProsusAI/finBERT">FinBERT</a>, which further
pre-trained <code>bert-base-uncased</code> on a large financial corpus. Since <code>TransformerTorchEncoder</code> was implemented
using Hugging Face transformers, you can also directly use the model by specifying its name if it is available on
the <a href="https://huggingface.co/docs">Hugging Face Model Hub</a>. We can also include other hyperparameters such as the
maximum sequence length or pooling strategy.</p>
<script src="https://gist.github.com/yuanbit/2890f74af6ae9d15bc316cc9ef4ec8aa.js"></script>
<p>Simple as that! 🐣 <strong>We just created a deep learning-based Encoder microservice ready to be parallelized!</strong>
The <code>pods</code> folder will also be the home to other Pods that we will need, which will
also be defined using YAML files.</p>
<p><strong>II. Add the Encoder to the Index Flow</strong></p>
<p>Now that we have our Encoder ready, let's put it in our Index Flow. Let's create a file <code>index.yml</code> inside a
folder called <code>flows</code>. In <code>index.yml</code>, we specify our first Pod in the Index Flow which is the <code>encoder</code> by
giving the path to our <code>pods/encode.yml</code> file. We can specify how many processes we want to split the Encoder into
by using the <code>parallel</code> parameter. This will be an environment variable specified in <code>app.py</code>, which we will
look at in the end. <code>parallel</code> also <strong>determines how many Peas we will have in each Pod.</strong></p>
<script src="https://gist.github.com/yuanbit/e7cbcdcc83c0f03d0582b9cc58b18294.js"></script>
<p>Well done! 💪 You've just created a pipeline for deep learning-powered microservices! Next, let's finish the design of the Index
Flow by adding another Pod containing the Indexer.</p>
<h4>Step 3. Indexing</h4>
<p align="center">
<img src="/assets/images/blog/financial-qa/Indexer.png" width="300">
</p>
<p>After obtaining the embeddings for the answer passages, we will create another Executor called the <strong>Indexer</strong>
to store our data so that they can be retrieved in query time. Similar to the previous step, the Driver receives the
Document and passes the <code>docid</code>, <code>doc</code>, and <code>embeddings</code> to the Indexer.</p>
<p>We will use the <strong>Compound Indexer</strong>,
which acts as a single indexer using both the <strong>(1) Vector</strong> and <strong>(2) Key-Value Indexers</strong> from Jina Hub:</p>
<ol>
<li>
<p><strong>Vector Indexer:</strong> Stores the answer embeddings and is queried by the question embedding to retrieve
the closest answer embeddings using the k-nearest neighbors algorithm.</p>
</li>
<li>
<p><strong>Key-Value (KV) Indexer:</strong> Stores the Document data (text, blob, metadata) and is queried by the Document id (normally
extracted from the Vector Indexer) to retrieve the information of the data such as answer id and text.</p>
</li>
</ol>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-step3.png" width="600">
<figcaption>The Indexer will store our data so that they can be retrieved in query time</figcaption>
</figure>
</p>
<p>We again wrap the Driver and Indexer in a Pea, group identical Peas in a Pod, and define them using YAML files.</p>
<p><strong>I. Create a Pod for the Indexer</strong></p>
<p>Let's create the file <code>pods/doc.yml</code> and define our compound indexer as <code>!CompoundIndexer</code> with the components
<code>!NumpyIndexer</code> which is the Vector Indexer and <code>!BinaryPbIndexer</code> which is the KV Indexer. The indexed data
will be stored in <code>vec.gz</code> and <code>doc.gz</code> respectively. The <code>workspace</code>
is the directory where the indexes will be stored, which will be inside our working directory.</p>
<script src="https://gist.github.com/yuanbit/6538a696b012e565d45f960b400e396f.js"></script>
<p><strong>II. Add the Indexer to the Index Flow</strong></p>
<p>Now let's go back to <code>flows/index.yml</code> and add our Indexer to the Index Flow as <code>doc_indexer</code>. If our data is
big, we can also add sharding to our application for optimization. This will also be used as an environment variable
in <code>app.py</code>, which we will see later.</p>
<script src="https://gist.github.com/yuanbit/ba5310ace80201c69e6cff498a1f3905.js"></script>
<p>Great job! 👏 You have just designed a cloud-native pipeline for indexing financial answer passages! We can
also use Jina's <a href="https://docs.jina.ai/chapters/flow/index.html">Flow API</a> to
visualize the Index Flow. First let's set our environment variables in the terminal for parallel and shards:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>export JINA_PARALLEL=</span><span style="color:#4cd213">&#x27;1&#x27;</span><span>
</span><span>export JINA_SHARDS=</span><span style="color:#4cd213">&#x27;1&#x27;</span><span>
</span>
</code></pre>
<p>Next, let's open a <code>jupyter notebook</code> in our working directory and do the following:</p>
<script src="https://gist.github.com/yuanbit/66d4df6a197e107b9be6b4ef495c7fa2.js"></script>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/index-flow-jina.png" width="1000">
<figurecaption>Index Flow visualzation</figurecaption>
</figure>
</p>
<p>Here we see our Index Flow with two Pods - the Encoder, <code>encoder</code> and Indexer, <code>doc_indexer</code>.</p>
<h4>Build an Indexer Application</h4>
<p>Let's see how we can use the Index Flow as our application. In <code>app.py</code>, we can change
<code>parallel</code> in the <code>config</code> function to indicate how many Peas (processes)
we want to split each microservice in for each Pod. We can also change <code>shards</code>
to indicate parallelization during the indexing step. We will leave both of them unchanged for now.
This means that we will only have one Pea in each Pod.</p>
<p>Let's first import <code>Flow</code> from Jina's <a href="https://docs.jina.ai/chapters/flow/index.html">Flow API</a>:</p>
<script src="https://gist.github.com/yuanbit/752eef2f8355d5243202c00949dbfcb0.js"></script>
<p>After the <code>index_generator</code> function that we added in <a href="#step-1-define-our-data">Step 1. Define our data</a>,
let's add the <code>index</code> function which will first load the Index Flow that we have created in <code>flows/index.yml</code>
and pass the input Document from <code>index_generator</code> to the flow. We set our <code>batch_size=16</code> for encoding
the answer passages into embeddings.</p>
<script src="https://gist.github.com/yuanbit/c2ffa20fbce1a7ce8fc55597d32723e3.js"></script>
<p>We are now ready to index our data. In the our working directory run:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>python app.py index
</span>
</code></pre>
<p><a href="https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH"><img src="https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH.svg" alt="asciicast"></a></p>
<p>At the end you will see the following:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>✅ done </span><span style="color:#fb9e00;font-weight:normal">in</span><span> ⏱ </span><span style="color:#fa658d">1</span><span> minute </span><span style="color:#fb9e00;font-weight:normal">and</span><span> </span><span style="color:#fa658d">54</span><span> seconds 🐎 </span><span style="color:#fa658d">7.7</span><span>/s
</span><span>        gateway@</span><span style="color:#fa658d">18904</span><span>[S]:terminated
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[I]:recv ControlRequest </span><span style="color:#fb9e00;font-weight:normal">from</span><span> ctl▸doc_indexer▸⚐
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[I]:Terminating loop requested by terminate signal RequestLoopEnd()
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[I]:</span><span style="color:#ac65ff">#sent: 56 #recv: 56 sent_size: 1.7 MB recv_size: 1.7 MB</span><span>
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[I]:request loop ended, tearing down ...
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[I]:indexer size: </span><span style="color:#fa658d">865</span><span> physical size: </span><span style="color:#fa658d">3.1</span><span> MB
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[S]:artifacts of this executor (vecidx) </span><span style="color:#fb9e00;font-weight:normal">is</span><span> persisted to ./workspace/doc_compound_indexer-</span><span style="color:#fa658d">0</span><span>/vecidx.</span><span style="color:#fb9e00">bin</span><span>
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[I]:indexer size: </span><span style="color:#fa658d">865</span><span> physical size: </span><span style="color:#fa658d">3.2</span><span> MB
</span><span>    doc_indexer@</span><span style="color:#fa658d">18903</span><span>[S]:artifacts of this executor (docidx) </span><span style="color:#fb9e00;font-weight:normal">is</span><span> persisted to ./workspace/doc_compound_indexer-</span><span style="color:#fa658d">0</span><span>/docidx.</span><span style="color:#fb9e00">bin</span><span>
</span>
</code></pre>
<p>Hooray 🙌 we finished the first part of our application! The embedding indexes and Document data will be stored in a directory called <code>workspace</code>.</p>
<h3>Query Flow</h3>
<p>After indexing our data, we need to create a <strong>Query Flow</strong>. The main idea behind the Query Flow is to use the
same BERT-based model to <strong>encode a given question into an embedding</strong> and use the Indexer to <strong>search for the most
similar answer embeddings</strong>. To further improve the search results, we will use the same reranking technique as my thesis
Therefore, we will need to add another a reranking step using FinBERT-QA to recompute the scores of the answer matches returned by Jina.</p>
<p align="center">
<figure>
<a href="https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png">
<img src="/assets/images/blog/financial-qa/query-flow.png" width="1000">
</a>
<figurecaption>Query Flow</figurecaption>
</figure>
</p>
<p>Let us again walk through the steps one by one.</p>
<h4>Step 1. Encode Question</h4>
<p>Let's assume that the question text will be a user input. Jina will take this input and
define a new Document.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step1.png" width="500">
<figurecaption>Encoder in the Query Flow</figurecaption>
</figure>
</p>
<p><strong>I. Add the Encoder to the Query Flow</strong></p>
<p>Just like the encoding step of the Index Flow, we encode the questions using the same Encoder. Therefore, we can use the same Encoder from <code>pods/encode.yml</code>
in our <strong>Query Flow</strong>. We will create a new <code>query.yml</code> file in the <code>flows</code> folder and
add the Encoder Pod to it:</p>
<script src="https://gist.github.com/yuanbit/768020d68924e16cefeb052602ecf4f2.js"></script>
<h4>Step 2. Search Indexes</h4>
<p>After encoding the questions, the question embeddings will be added to the Document by the Driver. This Document
is then sent to the Indexer in the next Pod and the Driver will pass the question embeddings to the Indexer.
The Indexer will then search for the answers with the most similar embeddings using the k-nearest neighbors algorithm and
pass a list of top-k answer matches to the Driver to be added to the Document.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step2.png" width="500">
<figurecaption>The Indexer will search for the answers with the most similar embeddings</figurecaption>
</figure>
</p>
<p>The matches will contain data
such as the <code>docid</code>, <code>doc</code>, and match <code>scores</code>. Since we are also using the same
Indexer from the Index Flow, all we need to do again is add the Indexer Pod to <code>flows/query.yml</code>:</p>
<script src="https://gist.github.com/yuanbit/f1358c0b825caf2fe406605ec0ae583c.js"></script>
<h4>Step 3. Reranking</h4>
<p align="center">
<img src="/assets/images/blog/financial-qa/Ranker.png" width="300">
</p>
<p>Let's assume that the Indexer returns the top-k answer matches at this point and we want to recompute the match scores to
get better results. Jina has a class of Executors called the <strong>Rankers</strong>, in particular, the <strong>Match2DocRankers</strong>
re-scores the matches for a query by calculating new scores. If you look at the Rankers on Jina Hub, the
<a href="https://github.com/jina-ai/jina-hub/tree/master/rankers/LevenshteinRanker">Levenshtein Ranker</a> uses the
Levenshtein distance to recompute the match scores.</p>
<p>However, instead of using a distance metric to recompute the scores, we want to load our fined-tuned BERT model,
FinBERT-QA, in the Ranker and recompute the scores by using the concatenation of the question and the
current match answers as inputs into a binary classification task.</p>
<p>In order to do this we need to <strong>create our own custom
Executor</strong> and implement our own logic. In this section we will use <strong>PyTorch</strong> and <strong>Hugging Face transformers</strong>
to implement our custom Ranker.</p>
<p>The main idea here is to pass our query text and the matches (containing the answer text and match scores) to the
Ranker to return a reordered list of matches based on the relevancy scores computed by FinBERT-QA. The Driver will
then update the matches in the Document based on this reordered list.</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step3.png" width="550">
<figurecaption>The Ranker recomputes the scores of the matches using FinBERT-QA</figurecaption>
</figure>
</p>
<p>Recall that Peas can run in Docker, this means that we can simply <strong>build a Docker image with our implementation
of the Ranker and use the image in the Query Flow.</strong> The Jina Hub API let's use to Cookiecutter to create the templates of all
the files we will need to do this. Let's get started by making sure that the Jina Hub extension is installed:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>pip install </span><span style="color:#4cd213">&quot;jina[hub]&quot;</span><span>
</span>
</code></pre>
<h4>Build a Custom Executor</h4>
<p>Let's first create the templates that we will need to build a Docker image for our custom Ranker.</p>
<p><strong>1.) Set up.</strong></p>
<p>In the
<code>financial-qa-search/</code>
directory type:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>jina hub new
</span>
</code></pre>
<p>This will pop up a wizard that helps you walk through the process. Let's give our Executor the name <code>FinBertQARanker</code>
and make sure to select <code>4 - Ranker</code> for the Executor type. We will use <code>jinaai/jina</code> as our base image for
the Docker image that we will build.</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>Yo</span><span style="color:#4cd213">u&#x27;ve downloaded /Users/bithiah/.cookiecutters/cookiecutter-jina-hub before. Is it okay to delete and re-download it? [yes]: yes
</span><span style="color:#4cd213">executor_name [The class name of the executor (UpperCamelCase)]: FinBertQARanker
</span><span style="color:#4cd213">Select executor_type:
</span><span style="color:#4cd213">1 - Encoder
</span><span style="color:#4cd213">2 - Crafter
</span><span style="color:#4cd213">3 - Indexer
</span><span style="color:#4cd213">4 - Ranker
</span><span style="color:#4cd213">5 - Evaluator
</span><span style="color:#4cd213">Choose from 1, 2, 3, 4, 5 [1]: 4
</span><span style="color:#4cd213">description [What does this executor do?]: recomputes match scores using FinBERT-QA                
</span><span style="color:#4cd213">keywords [keywords to describe the executor, separated by commas]: 
</span><span style="color:#4cd213">pip_requirements []: 
</span><span style="color:#4cd213">base_image [jinaai/jina]: 
</span><span style="color:#4cd213">author_name [Jina AI Dev-Team (dev-team@jina.ai)]: 
</span><span style="color:#4cd213">author_url [https://jina.ai]: 
</span><span style="color:#4cd213">author_vendor [Jina AI Limited]: 
</span><span style="color:#4cd213">docs_url [https://github.com/jina-ai/jina-hub]: 
</span><span style="color:#4cd213">version [0.0.1]: 
</span><span style="color:#4cd213">license [apache-2.0]: 
</span><span style="color:#4cd213">
</span></code></pre>
<p>After pressing Enter, you will see a new directory called <code>FinBertQARanker</code>. Your file structure should now look
as follows:</p>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/file-structure.png" width="650">
<figurecaption>Project folder structure</figurecaption>
</figure>
</p>
<p>We will the implement our logic of the Ranker in <code>__init__.py</code>, write some tests in <code>tests/test_finbertqaranker.py</code>, and
change the <code>Dockerfile</code> to contain everything we need to build the image.</p>
<p><strong>The code for the Ranker can be found <a href="https://github.com/jina-ai/examples/tree/example-financial-qa-search/financial-qa-search/FinBertQARanker">here</a>.</strong></p>
<p><strong>2.) Fill in the logic for reranking.</strong></p>
<p>We will now implement our logic in <code>__init__.py</code>, which should look like the following:</p>
<script src="https://gist.github.com/yuanbit/f0fb64b29b46f45c59469fe4ef3495b9.js"></script>
<p>Jina contains different base classes for the Executors with different functionalities. The base Ranker class
that we will use is called <strong>Match2DocRankers</strong>, which has the functionality to recompute the match scores.</p>
<p>Let's first change the base class of <code>BaseRanker</code> to <code>Match2DocRanker</code>.
Let's also import <strong>PyTorch</strong> using Jina and some other modules that we will need as well as define our current directory.</p>
<script src="https://gist.github.com/yuanbit/6969968f9d5a6e4a081347ff272edce0.js"></script>
<p>Our logic will be implemented in the <code>FinBertQARanker</code> class which will use <code>TorchDevice</code> and
<code>Match2DocRanker</code> from Jina. We will download the models that we need in the <code>Dockerfile</code> later.
Let us assume now we have two models in the folder <code>models/</code>: (1) <code>bert-qa/</code> and (2) <code>2_finbert-qa-50_512_16_3e6.pt</code>.</p>
<p>(1) <code>bert-qa</code>: bert-base-uncased fine-tuned on the MS Macro dataset
from <a href="https://github.com/nyu-dl/dl4marco-bert">Passage Re-ranking with BERT</a></p>
<p>(2) <code>2_finbert-qa-50_512_16_3e6.pt</code>: FinBERT-QA model - fine-tuned <code>bert-qa</code> on the FiQA dataset.</p>
<p>We first specify <code>bert-qa/</code> as the the pre-trained model that would be used for initialization,
<code>2_finbert-qa-50_512_16_3e6.pt</code> as the model that would be used to compute the QA relevancy scores,
and the maximum sequence length for the QA pairs:</p>
<script src="https://gist.github.com/yuanbit/47faac3565dda220b71a77fe3a120d61.js"></script>
<p>Then we add a <code>post_init</code> function to the class to load the models for the binary classification task. Make sure to
set the model in evaluation mode.</p>
<script src="https://gist.github.com/yuanbit/5db6428baf752471c4326d1d1e650906.js"></script>
<p>Now let's implement a private <code>_get_score</code> function to compute each of the relevancy scores of the question
and the top-k answer matches. We first concatenate the question and each top-k answer and encode them to get the
inputs (<code>input_ids</code>, <code>token_type_ids</code>, <code>att_mask</code>) that the model needs using the
tokenizer from transformers. We then feed the inputs into the model and get the prediction scores
that the QA pairs are relevant (<code>label = 1</code>). We apply the softmax function to the scores to transform the
prediction scores into probabilities between 0 and 1. The output would then be the relevancy score in the form of a
probability for the QA pair.</p>
<script src="https://gist.github.com/yuanbit/5efb50d17b97f7eb594c7f88ee116c3a.js"></script>
<p>Lastly, let's fill in the scoring function that takes the question from the user and Jina's match scores as input
and uses <code>_get_scores</code> to recompute new scores:</p>
<script src="https://gist.github.com/yuanbit/b2be4165f2151fa69e9c88a21334c898.js"></script>
<p><strong>3.) Write a Unit Test</strong></p>
<p>In order to create a new Executor and build a Docker image with the Jina Hub API, we need to write a unit test. We can
find a template for this in <code>tests/test_finbertqaranker.py</code>. I wrote a simple check to compute the relevance
probability for two answer matches given a query and to check to see if <code>FinBertQARanker</code> computes the same
score as our expectation:</p>
<script src="https://gist.github.com/yuanbit/8ce93efa42f7c56a2a224e7b8c8e86cb.js"></script>
<p><strong>4.) Add Requirements</strong></p>
<p>Other than Jina we are also using PyTorch and transformers for <code>FinBertQARanker</code>, so let's add them
to <code>FinBertQARanker/requirements.txt</code>:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>torch==</span><span style="color:#fa658d">1.7</span><span style="color:#fa658d">.1</span><span>
</span><span>transformers==</span><span style="color:#fa658d">4.0</span><span style="color:#fa658d">.1</span><span>
</span>
</code></pre>
<p><strong>5.) Prepare Dockerfile</strong></p>
<p>Let's change our <code>Dockerfile</code> to the contents below, which will download the models into a folder called <code>models/</code>.</p>
<script src="https://gist.github.com/yuanbit/b226b930c0850b92eee9a25852278388.js"></script>
<p><strong>6.) Build Docker image with Jina Hub API</strong></p>
<p>We are finally ready to build <code>FinBertQARanker</code> into a Docker image. In our working directory, let's type:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>jina hub build FinBertQARanker/ --pull --test-uses --timeout-ready </span><span style="color:#fa658d">60000</span><span>
</span>
</code></pre>
<p><code>--pull</code> downloads our Jina base image if it is not already local.</p>
<p><code>--test-uses</code> adds an extra test to check if the built image can dry-run successfully via Jina's Flow API.
<code>--timeout-ready</code> gives our <code>post_init</code> function time to load the models.</p>
<p>If the build is successful, you will see this message:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span> HubIO@</span><span style="color:#fa658d">10240</span><span>[I]:Successfully built ba3fac0f3a46
</span><span> HubIO@</span><span style="color:#fa658d">10240</span><span>[I]:Successfully tagged jinahub/pod.ranker.finbertqaranker:</span><span style="color:#fa658d">0.0</span><span style="color:#fa658d">.1</span><span>-</span><span style="color:#fa658d">0.8</span><span style="color:#fa658d">.13</span><span>
</span><span> HubIO@</span><span style="color:#fa658d">10240</span><span>[I]:building FinBertQARanker/ takes </span><span style="color:#fa658d">6</span><span> minutes </span><span style="color:#fb9e00;font-weight:normal">and</span><span> </span><span style="color:#fa658d">12</span><span> seconds (</span><span style="color:#fa658d">372.31</span><span>s)
</span><span> HubIO@</span><span style="color:#fa658d">10240</span><span>[S]:🎉 built jinahub/pod.ranker.finbertqaranker:</span><span style="color:#fa658d">0.0</span><span style="color:#fa658d">.1</span><span>-</span><span style="color:#fa658d">0.8</span><span style="color:#fa658d">.13</span><span> (sha256:ba3fac0f3a) uncompressed size: </span><span style="color:#fa658d">3.3</span><span> GB
</span>
</code></pre>
<p>Congratulations 🥳, you have successfully built a custom Executor in the form of a Docker image with the tag name
<code>jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.23</code>! Let's see how we can use it in the Query Flow next.</p>
<p><strong>I. Create a custom Ranker Pod</strong></p>
<p>To use our custom Ranker, <code>FinBertQARanker</code>, we need to first create a new Pod for the Ranker. Let's create
the file <code>rank.yml</code> in the <code>pods</code> folder. Next, let's copy the contents from <code>FinBertQARanker/config.yml</code>
to <code>pods/rank.yml</code> and you should have the following:</p>
<script src="https://gist.github.com/yuanbit/24c93873f7594ee0a097ea1550cc1d66.js"></script>
<p>This is going to tell the Query Flow to use the logic we have implemented in our Exectuor, <code>FinBertQARanker/__init__.py</code>.
Since the code for this implementation is loaded inside the <code>workspace</code> folder in the Docker image, let's add
<code>workspace/</code> before <code>__init__.py</code>.</p>
<p>The Encoder and Indexer Executors that we have used so far all use default Drivers in the Pods. Since we created our custom
Executor, we need to tell the Ranker Pod which Driver to use. In this case we will use the <code>Matches2DocRankDriver</code> for the
<code>Match2DocRanker</code> base Ranker class. Hence, our <code>rank.yml</code> will look as follows:</p>
<script src="https://gist.github.com/yuanbit/7757c64f850b4dd43c95e56d2f0a2909.js"></script>
<p>Hooray 🎊 we now have a custom Ranker Pod! Let's see next how we can use it in the Query Flow.</p>
<p><strong>II. Use Custom Ranker in the Query Flow</strong></p>
<p>Like the other Executor Pods, we just need to add <code>ranker</code> after the <code>doc_indexer</code> and tell the Query Flow to use
the Docker image and Ranker Pod that we have just created by specifying the prefix <code>docker://</code> in front of the tag name. The final <code>flows/query.yml</code> should look as follows:</p>
<script src="https://gist.github.com/yuanbit/f5e5291f7a30e4c43da63fb9ef537608.js"></script>
<p><strong>Be aware that the tag name of the Docker image might change</strong> depending the current Jina release. Make sure to change the
tag name that accordingly to your build message.</p>
<p>We can again visualize the Query Flow using the Flow API in a  <code>jupyter notebook</code> as follows:</p>
<script src="https://gist.github.com/yuanbit/13e879fa8de427c7b8be8eadfc995ac6.js"></script>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-jina.png" width="1000">
<figurecaption>Query Flow visualization</figurecaption>
</figure>
</p>
<p>Here we see our Query Flow with three Pods containing the Encoder, <code>encoder</code> and Indexer, <code>doc_indexer</code>,
and Ranker, <code>ranker</code>.
At the end of the Query Flow, the Driver from the Ranker Pod will have changed the matches in the Document to an reordered list of
matches based on the probabilities computed by our custom Ranker, <code>FinBertQARanker</code>. Next, we will see how we can
access this list of final matches in our <code>app.py</code>.</p>
<h4>Build a Search Application</h4>
<p align="center">
<figure>
<img src="/assets/images/blog/financial-qa/query-flow-step4.png" width="550">
<figurecaption>Get matches and scores stored in the Document</figurecaption>
</figure>
</p>
<p>Since our final matches and their relevancy probability are stored in the Document, in <code>app.py</code>, we can
write a function to print out the response to a question from the user input. We can loop through the matches in our
Document, <code>d.matches</code>, and print out the values of the scores and the matching answer text.</p>
<script src="https://gist.github.com/yuanbit/1e18bcb2e7dbc77812a94ccefc6d1fcc.js"></script>
<p>We can then write our <code>search</code> method that uses the Query Flow from <code>flows/query.yml</code> and passes
the user inputs into <code>print_resp</code>. In <code>f.search_lines()</code>, we specify the input as our user query,
the output as the response to be printed, and the top-k answers we want to retrieve. The cool thing about
<code>f.search_lines()</code> is that it automatically creates a Document for the user query, like sugar magic 🍬!</p>
<script src="https://gist.github.com/yuanbit/434ef56655bea8daf8b8275348387e36.js"></script>
<p>Hooray! 🎉🎉🎉 We have just finished building our Financial QA search engine! We can now run:</p>
<p><code>python app.py search</code></p>
<p>and try out different questions! The Ranker might take some time to compute the relevancy
scores since it is using a BERT-based model. Here is a list of sample questions:</p>
<pre class="rounded-xl m-2 md:mr-6" style="display:block;overflow-x:auto;padding:0.5em;background:#2d2b57;font-weight:normal;color:#e3dfff" data-reactroot=""><code class="language-python" style="white-space:pre"><span>• What does it mean that stocks are “memoryless”?
</span><span>• What would a stock be worth </span><span style="color:#fb9e00;font-weight:normal">if</span><span> dividends did </span><span style="color:#fb9e00;font-weight:normal">not</span><span> exist?
</span>• What are the risks of Dividend-yielding stocks?
<!-- -->• Why do financial institutions charge so much to convert currency?
<span>• Is there a candlestick pattern that guarantees </span><span style="color:#fb9e00">any</span><span> kind of future profit?
</span><span>• </span><span style="color:#fa658d">15</span><span> year mortgage vs </span><span style="color:#fa658d">30</span><span> year paid off </span><span style="color:#fb9e00;font-weight:normal">in</span><span> </span><span style="color:#fa658d">15</span><span>
</span><span>• Why </span><span style="color:#fb9e00;font-weight:normal">is</span><span> it rational to pay out a dividend?
</span><span>• Why do companies have a fiscal year different </span><span style="color:#fb9e00;font-weight:normal">from</span><span> the calendar year?
</span><span>• What should I look at before investing </span><span style="color:#fb9e00;font-weight:normal">in</span><span> a start-up?
</span>• Where do large corporations store their massive amounts of cash?
<!-- -->
</code></pre>
<p align="center">
<img src="/assets/images/blog/financial-qa/search-results.png" width="900">
</p>
<h2>Summary</h2>
<p>In this blog, I introduced core Jina concepts and demonstrated how to build a production-ready Financial QA system using Jina.
I also explained how to use the Jina Hub API to create a BERT-powered Ranker Executor. Thanks to
the building blocks that Jina provides, we could easily use the SOTA and powerful model, FinBERT-QA, in production.</p>
<p>The neural search application we have just built with Jina runs locally on our own machines, but can also
be completely distributed and run on multiple machines in a network, making our application highly reusable, scalable,
and efficient. On top of that, common cloud-native features such as persistence, scheduling, chaining, grouping, and
parallelization all come out of the box.</p>
<p>Moreover, there are variants of pre-trained BERT models for other domains such as <a href="https://github.com/dmis-lab/biobert">biomedical</a>,
<a href="https://github.com/allenai/scibert">science</a>, and <a href="https://huggingface.co/nlpaueb/legal-bert-base-uncased">legal</a>.
You can use these models to build a QA search application and experiment with the results!</p>
<h2>Next Step: Evaluation</h2>
<p>If you made it all the way through this tutorial, you might be wondering, <strong>"how do I evaluate the search results?"</strong>.
Great question! Jina has a class of Executors called the <strong>Evaluator</strong> and has implementations of common evaluation
metrics like Precision and Reciprocal Error. Evaluation is an important step and will allow us to optimize
the search results and design the most effective Flows. We will see in the next tutorial how we can add the
Evaluator in our Financial QA application.</p>
<h2>Learn More</h2>
<p>To learn more about Jina, I recommend reading the following articles:</p>
<ul>
<li><a href="https://medium.com/jina-ai/what-is-jina-and-neural-search-7a9e166608ab">What is Jina and Neural Search?</a></li>
<li><a href="https://hanxiao.io/2020/10/19/A-Curated-List-of-Neural-Search-and-Jina-Framework-Designs/">From Then to Now: a Curated List for Neural Search and Jina</a></li>
</ul>
<p>and checking out our <a href="https://github.com/jina-ai/jina">Github</a> page!</p>
<p>If you want to learn Jina by doing, I encourage you to start building your own examples and
sharing them with the community to help us grow our open-source ecosystem! 🚀 For example, check out this
<a href="https://github.com/ArturTan/transformers-for-lawyers">community project - transformers-for-lawyers</a> built with Jina.</p>
<p>We saw how versatile and extensible Jina is and we could create all kinds of search applications using our own
logic and models for NLP, Computer Vision, and other ML search applications.
<strong><a href="https://github.com/jina-ai/jina-hub">Jina Hub</a> is a great place to get started, where you can use
the available Executors to build other types of search engines (for images, videos, etc...) or create your own
Executors using the Jina Hub API!</strong> You can always come back to this tutorial and walk through the process again.</p>
<p><strong>As an open-source company we would also love your help and contributions.️</strong> We have issues labelled as <a href="https://github.com/jina-ai/jina/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">good first issue</a>
to get started! You can read more about our contributing guidelines <a href="https://github.com/jina-ai/jina/blob/master/CONTRIBUTING.md">here</a>.</p>
<p>If you want to know more about Jina's new features or ask any questions, welcome to join our <a href="https://slack.jina.ai/">Slack Community</a>
and our monthly public <a href="https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/">Engineering All Hands</a> via
Zoom or Youtube live stream.</p>
<p>If you are interested in joining us as a full-time AI / Backend / Frontend developer,
please submit your CV to our <a href="jobs.jina.ai">job portal</a>. Let’s build the next open-source neural search ecosystem together!</p>
<h2>Community</h2>
<ul>
<li><a href="slack.jina.ai">Slack channel</a> - a communication platform for developers to discuss Jina</li>
<li><a href="mailto:newsletter+subscribe@jina.ai">Community newsletter</a> - subscribe to the latest update, release and event news of Jina</li>
<li><a href="https://www.linkedin.com/company/jinaai/">LinkedIn</a> - get to know Jina AI as a company and find job opportunities</li>
<li><a href="https://twitter.com/JinaAI_">Twitter</a> - follow us and interact with us using hashtag <code>#JinaSearch</code></li>
<li><a href="https://jina.ai">Company</a> - know more about our company, we are fully committed to open-source!</li>
</ul>
</div></div></article></div></main></div></div><div class="jsx-1956813867"><div class="bg-primary-500 pt-20 text-white"><div class="jsx-1956813867 flex flex-col md:flex-row justify-between px-6 md:px-0"><div class="jsx-1956813867 footer-left-margin"></div><div class="jsx-1956813867 pr-4 md:py-16 md:mr-16"><div class="text-center md:text-left"><div class="flex md:justify-start"><div class="text-gray-900 flex items-center font-semibold text-3xl"><img src="/assets/images/logo-white.svg" alt="Jina.ai logo" class="w-24"/></div></div></div></div><div class="jsx-1956813867 grid grid-cols-2 sm:grid-cols-2 md:grid-cols-4 gap-16 py-16"><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Company</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="/about/">About us</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/careers/">Careers</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/contact/">Contact us</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/blog/">Blog</a></li></ul></nav></div><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Products</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="/core/">Core</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/hub/">Hub</a></li></ul></nav></div><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Developers</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="/contribute/">Contribute</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/learn/">Learn</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/join/">Join</a></li></ul></nav></div><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Social</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://github.com/jina-ai/jina/">GitHub</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://www.linkedin.com/company/jinaai/">LinkedIn</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://twitter.com/jinaAI_/">Twitter</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://jina-ai.slack.com/">Slack</a></li></ul></nav></div></div><div class="jsx-1956813867 footer-right-margin"></div></div><div class="text-center bg-primary-400 text-gray-100 text-sm mt-12 py-6"><span class="block md:inline-block">© 2021 Jina AI, Ltd. All rights reserved.</span><span class="mx-4 hidden md:inline-block">|</span><a href="/legal"><span>Terms of Service</span></a><span class="mx-4">|</span><a href="/legal"><span>Privacy Policy</span></a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"How to build a production-ready Financial Question Answering system with Jina and BERT","date":"2021-01-07T10:00:39.923Z","slug":"financial-qa-tutorial","author":"Bithiah Yuan","content":"\u003cp\u003eLearn how to use the neural search framework, \u003cstrong\u003e\u003ca href=\"https://github.com/jina-ai/jina\"\u003eJina\u003c/a\u003e\u003c/strong\u003e, to build a \u003cstrong\u003eFinancial Question Answering (QA) search application\u003c/strong\u003e\nusing the \u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e dataset, \u003ca href=\"https://pytorch.org\"\u003ePyTorch\u003c/a\u003e, and \u003ca href=\"https://github.com/huggingface/transformers\"\u003eHugging Face transformers\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor my master’s thesis, I built a Financial QA system using a fine-tuned BERT model called\n\u003ca href=\"https://github.com/yuanbit/FinBERT-QA\"\u003eFinBERT-QA\u003c/a\u003e. Motivated by the emerging demand in the financial industry for\nthe automatic analysis of unstructured and structured data at scale, \u003cstrong\u003eQA systems can provide lucrative and competitive\nadvantages\u003c/strong\u003e to companies by facilitating the decision making of financial advisers.\u003c/p\u003e\n\u003cp\u003eThe goal of my thesis was to search for a ranked list of relevant answer passages given a question.\nHere is an example of a financial domain-based question and a ground truth answer from the \u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e dataset:\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/sample-qa.png\" alt=\"performance\" width=\"450px\"\u003e\n\u003cfigcaption\u003eSample QA from the financial domain\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eHere is a list of other questions from \u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e• What does it mean that stocks are “memoryless”?\n• What would a stock be worth if dividends did not exist?\n• What are the risks of Dividend-yielding stocks?\n• Why do financial institutions charge so much to convert currency?\n• Is there a candlestick pattern that guarantees any kind of future profit?\n• 15 year mortgage vs 30 year paid off in 15\n• Why is it rational to pay out a dividend?\n• Why do companies have a fiscal year different from the calendar year?\n• What should I look at before investing in a start-up?\n• Where do large corporations store their massive amounts of cash?\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFinancial QA is \u003cstrong\u003ehard\u003c/strong\u003e because the vocabularies are context specific, for example, a machine would\nhave a hard time understanding what an \u003cem\u003eETF\u003c/em\u003e is. Nevertheless, \u003cstrong\u003ewith the power of BERT, I improved the state-of-the-art (SOTA) results by an average of 19% on three\nevaluation metrics (Precision, MRR, NDCG)\u003c/strong\u003e.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/model-performance.png\" alt=\"performance\" width=\"600px\"\u003e\n\u003cfigcaption\u003eEvaluation results from \u003ca href=\"https://github.com/yuanbit/FinBERT-QA\"\u003eFinBERT-QA\u003c/a\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eEven though my thesis was about QA in the financial domain, the approach that I have used can be applied to a\n\u003ca href=\"https://github.com/microsoft/MSMARCO-Passage-Ranking\"\u003egeneral QA dataset\u003c/a\u003e or QA in other domains such as\n\u003ca href=\"https://github.com/shuzi/insuranceQA\"\u003einsurance\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAfter finishing my thesis, I realized that \u003cstrong\u003ejust having a model and SOTA results is not good enough\u003c/strong\u003e because there\nwas a gap between my research and business needs. This was when I discovered \u003cstrong\u003eJina, a framework designed to\nhelp me bridge this gap\u003c/strong\u003e. To help people better understand Jina, I prepared this tutorial to demonstrate how\nI used Jina to easily \u003cstrong\u003etransform my research into a production-ready system\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#background\"\u003eBackground\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#what-is-jina\"\u003eWhat is Jina?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#financial-qa-with-bert\"\u003eFinancial QA with BERT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#why-jina\"\u003eWhy Jina?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#tutorial\"\u003eTutorial\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#set-up\"\u003eSet Up\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#index-flow\"\u003eIndex Flow\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#step-1-define-our-data\"\u003eStep 1. Define our data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#step-2-encode-answer-passages\"\u003eStep 2. Encode Answer Passages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#step-3-indexing\"\u003eStep 3. Indexing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#build-an-indexer-application\"\u003eBuild an Indexer Application\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#query-flow\"\u003eQuery Flow\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#step-1-encode-question\"\u003eStep 1. Encode Question\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#step-2-search-indexes\"\u003eStep 2. Seach Indexes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#step-3-reranking\"\u003eStep 3. Reranking\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#build-a-custom-executor\"\u003eBuild a Custom Executor\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#build-a-search-application\"\u003eBuild a Search Application\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#summary\"\u003eSummary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#next-steps-evaluation\"\u003eNext Steps: Evaluation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#learn-more\"\u003eLearn More\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eBackground\u003c/h2\u003e\n\u003ch3\u003eWhat is Jina?\u003c/h3\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/jina_banner_new.png\" width=\"500\"\u003e\n\u003c/p\u003e\n\u003cp\u003eOpen-source deep learning frameworks such as TensorFlow and PyTorch provide building blocks for designing and quickly implementing\nneural network-based applications through a high level programming interface.\u003c/p\u003e\n\u003cp\u003eSimilarly, \u003cstrong\u003eJina\u003c/strong\u003e is an \u003cstrong\u003eopen-source neural search framework\u003c/strong\u003e that offers the building blocks for designing and implementing \u003cstrong\u003eneural network-based\nsearch applications\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eCo-founded by the creator of \u003ca href=\"https://github.com/hanxiao/bert-as-service\"\u003ebert-as-service\u003c/a\u003e and\n\u003ca href=\"https://github.com/zalandoresearch/fashion-mnist\"\u003eFashion-MNIST\u003c/a\u003e, Jina enables developers to build\n\u003cstrong\u003eproduction-ready cloud-native search systems\u003c/strong\u003e using\n\u003cstrong\u003eSOTA pre-trained deep learning models\u003c/strong\u003e, in which each component of the system is a \u003cstrong\u003emicroservice\u003c/strong\u003e that can be deployed, scaled, and maintained independently.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/cloud.png\" width=\"350\"\u003e\n\u003c/p\u003e\n\u003cp\u003eIf you come from a data science or academic background like me, the terms \u003cstrong\u003ecloud-native\u003c/strong\u003e and \u003cstrong\u003emicroservices\u003c/strong\u003e may sound\ndaunting. That's why we will learn by example in this tutorial and use the NLP task, Financial QA, to familiarize ourselves\nwith Jina's core concepts!\u003c/p\u003e\n\u003ch3\u003eFinancial QA with BERT\u003c/h3\u003e\n\u003cp\u003eBefore we jump into the tutorial, let's first understand how to build a QA system with BERT. Our goal is to\nsearch for the top-k most relevant answer passages when given a question from task 2 of the \u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e dataset.\u003c/p\u003e\n\u003cp\u003eIn 2018, Google's pre-trained BERT models, used for transfer learning, shook the NLP world and achieved the SOTA\nresults on numerous tasks, marking NLP's \u003ca href=\"https://ruder.io/nlp-imagenet/\"\u003eImageNet moment\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWhat is neat about BERT is that we can fine-tune a pre-trained BERT model on our QA task by simply transforming\nit into a \u003cstrong\u003ebinary classification task\u003c/strong\u003e, where the input is the \u003cstrong\u003econcatenation of a question and an answer\u003c/strong\u003e and the\noutput is a binary label indicating the \u003cstrong\u003erelevancy score\u003c/strong\u003e of the QA pair. We can then take the softmax scores of\neach QA pair to get a probability of relevancy and rank these scores.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/BERT-QA.png\" width=\"400\"\u003e\n\u003cfigcaption\u003eFine-tuning method for our QA task\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eThe \u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e dataset has roughly 6,000 questions and 57,000 answers. Instead of\ncomputing a probability for each question 57,000 times, we can adapt a \u003ca href=\"https://arxiv.org/pdf/1901.04085.pdf\"\u003epassage reranking\u003c/a\u003e\napproach. We first use a \u003cstrong\u003eRetriever\u003c/strong\u003e to return the top-50 candidate answers for each question,\nand then use \u003cstrong\u003eFinBERT-QA\u003c/strong\u003e, a BERT-based model fine-tuned on the \u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e dataset\nas a \u003cstrong\u003eReranker\u003c/strong\u003e to compute the relevancy scores and rerank the top-50 QA pairs to get the top-10 answers.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/qa-pipeline-simple.png\" width=\"1000\"\u003e\n\u003cfigcaption\u003eQA pipeline with reranking\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eIf you are interested in the details of my thesis, you can learn more \u003ca href=\"https://github.com/yuanbit/FinBERT-QA\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003eWhy Jina?\u003c/h2\u003e\n\u003cp\u003eWhy is having the SOTA model and results is not good enough?\u003c/p\u003e\n\u003ch3\u003eJina as a bridge between research and industry\u003c/h3\u003e\n\u003cp\u003eThe motivation behind my research was to be able to help financial advisor answer questions\nfrom large-scale reports. However, the way I implemented the QA pipeline is not reusable and it won't scale\nto business demands. \u003cstrong\u003eBy industry standards, it is not production-ready.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSince \u003cstrong\u003eJina enables us to build cloud-native systems\u003c/strong\u003e, which embrace\nmicroservices, instead of wrapping my entire pipeline in a single Docker container, Jina will break down the pipeline\ninto components (preprocessor, encoder, indexer, etc.). Moreover, each of these components will be a microservice in its own isolated Docker\ncontainer managed by the \u003ca href=\"https://docs.jina.ai/chapters/flow/index.html\"\u003eFlow API\u003c/a\u003e.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/cloud2.svg\" width=\"350\"\u003e\n\u003cfigcaption\u003eIllustration from \u003ca href=\"https://www.manypixels.co/gallery/\"\u003emanypixels\u003c/a\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eFor those of you new to cloud-native concepts, you can think of a microservice as an independent component of your\napplication, for example, using FinBERT-QA to encode our questions and answers. You can then create multiple independent components\nor microservices to construct an application like a BERT-powered QA system. Since each of the components of the application can be deployed independently,\nthey can also scale individually and respond to rapid changes and business needs.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/business.svg\" width=\"350\"\u003e\n\u003cfigcaption\u003eIllustration from \u003ca href=\"https://www.manypixels.co/gallery/\"\u003emanypixels\u003c/a\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eBeing cloud-native is a modern design that more and more businesses are adapting to because it can help them save resources\nand grow. However, designing such systems is not easy. We need to consider many principles, patterns and best practices,\nfor example, how will the each component communicate with each other? How can they work in parallel? Luckily, instead of starting\nfrom scratch, \u003cstrong\u003eJina does all the hard work for us by providing us the building blocks so that we can easily construct\na cloud-native BERT-powered QA system using an reranking approach that is ready to serve in production!\u003c/strong\u003e\u003c/p\u003e\n\u003ch2\u003eTutorial\u003c/h2\u003e\n\u003cp\u003eNow that we have an overview, let's learn how to build a production-ready Financial QA system using the reranking approach and\ndive deeper into some new Jina terminologies. We will use \u003ca href=\"https://github.com/ProsusAI/finBERT\"\u003eFinBERT\u003c/a\u003e to encode our\nquestions and answer passages into embeddings and \u003ca href=\"https://github.com/yuanbit/FinBERT-QA\"\u003eFinBERT-QA\u003c/a\u003e to rerank\nthe top-50 answer matches.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe final code of this tutorial can be found \u003ca href=\"https://github.com/yuanbit/jina-financial-qa-search\"\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003eSet up\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eClone the repository\u003c/strong\u003e that we will be working together with here:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/yuanbit/jina-financial-qa-search-template.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe will use \u003ccode\u003efinancial-qa-search/\u003c/code\u003e as our working directory.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eInstall the requirements\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install -r requirements.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDownload data and model\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebash get_data.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor this tutorial, we won't be searching through all 57,000 answer passages from the\n\u003ca href=\"https://sites.google.com/view/fiqa/home\"\u003eFiQA\u003c/a\u003e dataset. We will work with a sample dataset called \u003ccode\u003etest_answers.csv\u003c/code\u003e,\ncontaining about 800 answer passages. If you want to experiment with the full dataset, you can use \u003ccode\u003eanswer_collection.tsv\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlows\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn Jina, we will build a Financial QA system with two pipelines, one for indexing our answer passages and\nthe other for querying. These pipelines are called \u003cstrong\u003eFlows\u003c/strong\u003e, which also serve to manage the state and context\nof the microservices as well as orchestrating them. Let's see what an overview of\nthe \u003cstrong\u003eIndex Flow\u003c/strong\u003e and \u003cstrong\u003eQuery Flow\u003c/strong\u003e, you can click on the images to see the details:\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003ca href=\"https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/index-flow.png\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow.png\" width=\"1000\"\u003e\n\u003c/a\u003e\n\u003cfigcaption\u003eIndex Flow\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003ca href=\"https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow.png\" width=\"1000\"\u003e\n\u003c/a\u003e\n\u003cfigcaption\u003eQuery Flow\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eTo understand these Flows, let's start with the \u003cstrong\u003eIndex Flow\u003c/strong\u003e and look into the individual components one by one.\u003c/p\u003e\n\u003ch3\u003eIndex Flow\u003c/h3\u003e\n\u003cp\u003eThe main idea behind the Index Flow is to use a pre-trained BERT model to encode all of our answer\npassages into embeddings then indexing these embeddings so that they can be searched in the Query Flow.\u003c/p\u003e\n\u003ch4\u003eStep 1. Define our data\u003c/h4\u003e\n\u003cp\u003eWe want to index a subset of  the answer passages from the FiQA dataset, \u003ccode\u003edataset/test_answers.csv\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e398960\tFrom  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  company's      underlying  value.  Examples  of  business      fundamentals  include  debt,  cash  flow,      supply  of  and  demand  for  the  company's      products,  and  so  forth.  For  instance,      if  a  company  does  not  have  a      sufficient  supply  of  products,  it  will      fail.  Likewise,  demand  for  the  product      must  remain  at  a  certain  level  in      order  for  it  to  be  successful.  Strong      business  fundamentals  are  considered      essential  for  long-term  success  and      stability.  See  also:  Value  Investing,      Fundamental  Analysis.  For  a  stock  the  basic  fundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page,    P/E  ratio,  div/yeild,  EPS,  shares,  beta.      For  the  company  itself  it's  generally  the  stuff  on  the  'financials'  link    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.\n19183\tIf  your  sole  proprietorship  losses  exceed  all  other  sources  of  taxable  income,  then  you  have  what's  called  a  Net  Operating  Loss  (NOL).  You  will  have  the  option  to  \"carry  back\"  and  amend  a  return  you  filed  in  the  last  2  years  where  you  owed  tax,  or  you  can  \"carry  forward\"  the  losses  and  decrease  your  taxes  in  a  future  year,  up  to  20  years  in  the  future.  For  more  information  see  the  IRS  links  for  NOL.  Note:  it's  important  to  make  sure  you  file  the  NOL  correctly  so  I'd  advise  speaking  with  an  accountant.  (Especially  if  the  loss  is  greater  than  the  cost  of  the  accountant...)\n327002\tTo  be  deductible,  a  business  expense  must  be  both  ordinary  and  necessary.  An  ordinary  expense  is  one  that  is  common  and  accepted  in  your  trade  or  business.  A  necessary  expense  is  one  that  is  helpful  and  appropriate  for  your  trade  or  business.  An  expense  does  not  have  to  be  indispensable  to  be  considered  necessary.    (IRS,  Deducting  Business  Expenses)  It  seems  to  me  you'd  have  a  hard  time  convincing  an  auditor  that  this  is  the  case.    Since  business  don't  commonly  own  cars  for  the  sole  purpose  of  housing  $25  computers,  you'd  have  trouble  with  the  \"ordinary\"  test.    And  since  there  are  lots  of  other  ways  to  house  a  computer  other  than  a  car,  \"necessary\"  seems  problematic  also.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOur dataset consists of a column of answer id and text, which we will denote as docid and doc respectively in this tutorial.\nIn order to index our data, we need to first define it in a Jina data type called \u003cstrong\u003eDocument\u003c/strong\u003e.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow-step1.png\" width=\"400\"\u003e\n\u003cfigcaption\u003eIndex Flow - Step 1\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eIn programming languages there are data types such as int, float, boolean, and more. In NumPy, TensorFlow, and PyTorch,\nwe manipulate and pass around objects such as ndarray and tensor, which are referred to as \u003cstrong\u003eprimitive data types\u003c/strong\u003e.\nSimilarly, a \u003cstrong\u003eDocument\u003c/strong\u003e is a Jina-specific data type for representing data.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDefining our data in a Document\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn our project directory \u003ccode\u003efinancial-qa-search/\u003c/code\u003e the \u003ccode\u003eapp.py\u003c/code\u003e file consists of the Financial QA search application\nthat we will build.  Notice that we set our data path in the \u003ccode\u003econfig\u003c/code\u003e function as follows:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/f8bc065dbba8382b1dadd0c75203cf9e.js\"\u003e\u003c/script\u003e\n\u003cp\u003eYou can change the path to \u003ccode\u003eanswer_collection.tsv\u003c/code\u003e to index with the full dataset.\u003c/p\u003e\n\u003cp\u003eLet's first make sure we import \u003ccode\u003eDocument\u003c/code\u003e from jina:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/f0f5d0a43738f50140e47fa2af6e8fcc.js\"\u003e\u003c/script\u003e\n\u003cp\u003eAfter the \u003ccode\u003econfig\u003c/code\u003e function, let's create a Python generator and define the Document to contain the id and text\ncorresponding to the answer passages:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/91effc3288862727199a13813f5c33a3.js\"\u003e\u003c/script\u003e\n\u003cp\u003eA Document is a high-level way for us to \u003cstrong\u003edefine and view the contents stored in Protobuf\u003c/strong\u003e, which is what Jina uses to\n\u003cstrong\u003eenable the microservices in the Flow to communicate with each other\u003c/strong\u003e. It is like an envelope\ncontaining our data and is used to send messages between the microservices of our Flow. Instead of directly\ndealing with Protobuf, which serializes our data into bytes, we can simply print our Document and see that a single answer\npassage will look as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eid: \"13755c6081bebe1a\"\nmime_type: \"text/plain\"\ntags {\n  fields {\n    key: \"id\"\n    value {\n      number_value: 398960.0\n    }\n  }\n}\ntext: \"From  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  \ncompany\\'s underlying  value. Examples  of  business fundamentals  include  debt,  cash  flow, supply  of  and  demand  \nfor  the  company\\'s      products,  and  so  forth.  For  instance, if  a  company  does  not  have  a sufficient  \nsupply  of  products,  it  will      fail.  Likewise,  demand  for  the  product      must  remain  at  a  certain  \nlevel  in      order  for  it  to  be  successful.  Strong      business  fundamentals  are  considered essential  for  \nlong-term  success  and      stability.  See  also:  Value  Investing, Fundamental  Analysis.  For  a  stock  the  basic\nfundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page, P/E  ratio,  \ndiv/yeild,  EPS,  shares,  beta.      For  the  company  itself  it\\'s  generally  the  stuff  on  the  \\'financials\\'  \nlink    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eAs we move along the Index Flow, the contents of the Document will be changed\u003c/strong\u003e, for example, we can see in the Index Flow that\nthe embeddings of the answer passages are added to the Document after the encoding step.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow-step2-2.png\" width=\"500\"\u003e\n\u003cfigcaption\u003eEmbeddings of the answer passages are added to the Document after the encoding step1\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eThe encoding step uses an \u003cstrong\u003eExecutor\u003c/strong\u003e, namely the \u003cstrong\u003eEncoder\u003c/strong\u003e. Let's understand this more next.\u003c/p\u003e\n\u003ch4\u003eStep 2. Encode Answer Passages\u003c/h4\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/Encoder.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cp\u003eAfter defining the Document for the \u003cstrong\u003eIndex Flow\u003c/strong\u003e, the next step is to encode the answer text into embeddings\nusing a pre-trained BERT model. The logic that does the encoding is called an \u003cstrong\u003eEncoder\u003c/strong\u003e, which is part of Jina's family\nof \u003cstrong\u003eExecutors\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eWe will look at other Executors later and only focus on the Encoder for now. Instead using TensorFlow\nor PyTorch with the combination of Hugging Face transformers and implementing the Encoder ourselves, we can simply take advantage\nof \u003ca href=\"https://github.com/jina-ai/jina-hub\"\u003eJina Hub\u003c/a\u003e, an \u003cstrong\u003eopen-registry for hosting Jina Executors via container images\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThere are all kinds of Encoders and other types of Executors in Jina Hub for different tasks and data types\n(e.g. image, video, audio, multimodal), allowing us to \u003cstrong\u003eship and exchange reusable component and build various\ndeep learning-based search engines, e.g. text-image, cross-modal, and multi-modal searches.\u003c/strong\u003e\nSince our task is a text-to-text search, we will use the\n\u003ca href=\"https://github.com/jina-ai/jina-hub/tree/master/encoders/nlp/TransformerTorchEncoder\"\u003eTransformerTorchEncoder\u003c/a\u003e for this tutorial.\u003c/p\u003e\n\u003cp\u003eBefore we talk about how to use the Encoder in our Index Flow, let's understand three more important Jina concepts in this\nstep:\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/Driver.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDriver:\u003c/strong\u003e Recall Jina uses Protobuf to send messages between the microservices in the Flow, which are in the form of bytes.\nWe would have a problem if we were to pass the Document directly to the Encoder because the Encoder needs the\nanswer text as input instead of bytes. Instead of dealing directly with Protobuf, Jina uses \u003cstrong\u003eDrivers\u003c/strong\u003e to \u003cstrong\u003etranslate\ndata for an Executor\u003c/strong\u003e, so that we only need to work with data types that we are familiar with (e.g. text, image, np,array, etc...).\n\u003cstrong\u003eThe Driver interprets messages in the Flow and passes the appropriate data to the Executor.\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow-step2.png\" width=\"550\"\u003e\n\u003cfigcaption\u003eEncoder - the Driver receives the Document in byes and passes the text to the Encoder. The Encoder outputs the embeddings of the text and the Driver adds them to the Document.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\nFor example, in the encoding step, the Driver receives the Document in bytes, interprets it as a Document, and passes the text in the Document to the Encoder.\nAfter the Encoder outputs the embeddings for the corresponding text, the Driver \nagain interprets the embeddings, and adds them to the Document. The Document below shows how it has be transformed by\nthe Driver in the encoding step and will serve as the input for the next indexing step.\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow-step2-2.png\" width=\"500\"\u003e\n\u003cfigcaption\u003eThe Driver transformed the Document by adding the embeddings in the encoding step.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePea:\u003c/strong\u003e Since an Executor needs a Driver to be able to process our data, they are both necessary components of a\nmicroservice in the Flow. Therefore, we use a \u003cstrong\u003ePea\u003c/strong\u003e to wrap the Executor and Driver together to get our \u003cstrong\u003eEncoder Microservice\u003c/strong\u003e.\nThe Pea is, therefore, a \u003cstrong\u003emicroservice\u003c/strong\u003e that constantly listens for incoming messages from the gateway or other Peas in\nthe Flow and calls the Driver when it receives a message. As a microservice, \u003cstrong\u003ePeas can also run in Docker, containing all dependencies and context in one place.\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/Pea.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePod:\u003c/strong\u003e To optimize our neural search application, \u003cstrong\u003eJina provides parallelization out of the box.\u003c/strong\u003e Instead of having a\nsingle Encoder, we can split it into \u003cstrong\u003emultiple processes\u003c/strong\u003e. The visualization of the Encoding step shows the Encoder being split into three\nprocesses with each process wrapped by a Pea.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIn order for our multiple Encoder microservices to behave functionally as one Encoder, we wrap the group of homogeneous (identical) Peas in a Pod\u003c/strong\u003e.\nThe Pod is, therefore, a \u003cstrong\u003egroup of homogeneous microservices\u003c/strong\u003e that is also responsible for load balancing, further control and context management.\nThe beauty about this design is that a Pod can either run on the local host or on different computers over a network,\nmaking our application \u003cstrong\u003edistributed, efficient, and scalable\u003c/strong\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/Pod.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cp\u003eNow that we understand these foundational concepts, \u003cstrong\u003ehow do we create a Pod for the Encoder?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIt may all sound extremely\ncomplicated, but with the building blocks provided by Jina we can \u003cstrong\u003e(1) design an Index Flow and (2) create an Encoder\nPod with two simple YAML files.\u003c/strong\u003e These YAML files will allow us to customize our neural search application without\ntouching the core of Jina's code.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/YAML.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eI. Create a Pod for the Encoder\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLet's first create a file \u003ccode\u003eencode.yml\u003c/code\u003e inside the folder called \u003ccode\u003epods\u003c/code\u003e. In \u003ccode\u003eencode.yml\u003c/code\u003e\nwe first specify the name of the Encoder we want to use from Jina Hub \u003ccode\u003eTransformerTorchEncoder\u003c/code\u003e. We can\nchoose the model we want to use, in our case we use \u003ca href=\"https://github.com/ProsusAI/finBERT\"\u003eFinBERT\u003c/a\u003e, which further\npre-trained \u003ccode\u003ebert-base-uncased\u003c/code\u003e on a large financial corpus. Since \u003ccode\u003eTransformerTorchEncoder\u003c/code\u003e was implemented\nusing Hugging Face transformers, you can also directly use the model by specifying its name if it is available on\nthe \u003ca href=\"https://huggingface.co/docs\"\u003eHugging Face Model Hub\u003c/a\u003e. We can also include other hyperparameters such as the\nmaximum sequence length or pooling strategy.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/2890f74af6ae9d15bc316cc9ef4ec8aa.js\"\u003e\u003c/script\u003e\n\u003cp\u003eSimple as that! 🐣 \u003cstrong\u003eWe just created a deep learning-based Encoder microservice ready to be parallelized!\u003c/strong\u003e\nThe \u003ccode\u003epods\u003c/code\u003e folder will also be the home to other Pods that we will need, which will\nalso be defined using YAML files.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eII. Add the Encoder to the Index Flow\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNow that we have our Encoder ready, let's put it in our Index Flow. Let's create a file \u003ccode\u003eindex.yml\u003c/code\u003e inside a\nfolder called \u003ccode\u003eflows\u003c/code\u003e. In \u003ccode\u003eindex.yml\u003c/code\u003e, we specify our first Pod in the Index Flow which is the \u003ccode\u003eencoder\u003c/code\u003e by\ngiving the path to our \u003ccode\u003epods/encode.yml\u003c/code\u003e file. We can specify how many processes we want to split the Encoder into\nby using the \u003ccode\u003eparallel\u003c/code\u003e parameter. This will be an environment variable specified in \u003ccode\u003eapp.py\u003c/code\u003e, which we will\nlook at in the end. \u003ccode\u003eparallel\u003c/code\u003e also \u003cstrong\u003edetermines how many Peas we will have in each Pod.\u003c/strong\u003e\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/e7cbcdcc83c0f03d0582b9cc58b18294.js\"\u003e\u003c/script\u003e\n\u003cp\u003eWell done! 💪 You've just created a pipeline for deep learning-powered microservices! Next, let's finish the design of the Index\nFlow by adding another Pod containing the Indexer.\u003c/p\u003e\n\u003ch4\u003eStep 3. Indexing\u003c/h4\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/Indexer.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cp\u003eAfter obtaining the embeddings for the answer passages, we will create another Executor called the \u003cstrong\u003eIndexer\u003c/strong\u003e\nto store our data so that they can be retrieved in query time. Similar to the previous step, the Driver receives the\nDocument and passes the \u003ccode\u003edocid\u003c/code\u003e, \u003ccode\u003edoc\u003c/code\u003e, and \u003ccode\u003eembeddings\u003c/code\u003e to the Indexer.\u003c/p\u003e\n\u003cp\u003eWe will use the \u003cstrong\u003eCompound Indexer\u003c/strong\u003e,\nwhich acts as a single indexer using both the \u003cstrong\u003e(1) Vector\u003c/strong\u003e and \u003cstrong\u003e(2) Key-Value Indexers\u003c/strong\u003e from Jina Hub:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eVector Indexer:\u003c/strong\u003e Stores the answer embeddings and is queried by the question embedding to retrieve\nthe closest answer embeddings using the k-nearest neighbors algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eKey-Value (KV) Indexer:\u003c/strong\u003e Stores the Document data (text, blob, metadata) and is queried by the Document id (normally\nextracted from the Vector Indexer) to retrieve the information of the data such as answer id and text.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow-step3.png\" width=\"600\"\u003e\n\u003cfigcaption\u003eThe Indexer will store our data so that they can be retrieved in query time\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eWe again wrap the Driver and Indexer in a Pea, group identical Peas in a Pod, and define them using YAML files.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eI. Create a Pod for the Indexer\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLet's create the file \u003ccode\u003epods/doc.yml\u003c/code\u003e and define our compound indexer as \u003ccode\u003e!CompoundIndexer\u003c/code\u003e with the components\n\u003ccode\u003e!NumpyIndexer\u003c/code\u003e which is the Vector Indexer and \u003ccode\u003e!BinaryPbIndexer\u003c/code\u003e which is the KV Indexer. The indexed data\nwill be stored in \u003ccode\u003evec.gz\u003c/code\u003e and \u003ccode\u003edoc.gz\u003c/code\u003e respectively. The \u003ccode\u003eworkspace\u003c/code\u003e\nis the directory where the indexes will be stored, which will be inside our working directory.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/6538a696b012e565d45f960b400e396f.js\"\u003e\u003c/script\u003e\n\u003cp\u003e\u003cstrong\u003eII. Add the Indexer to the Index Flow\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNow let's go back to \u003ccode\u003eflows/index.yml\u003c/code\u003e and add our Indexer to the Index Flow as \u003ccode\u003edoc_indexer\u003c/code\u003e. If our data is\nbig, we can also add sharding to our application for optimization. This will also be used as an environment variable\nin \u003ccode\u003eapp.py\u003c/code\u003e, which we will see later.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/ba5310ace80201c69e6cff498a1f3905.js\"\u003e\u003c/script\u003e\n\u003cp\u003eGreat job! 👏 You have just designed a cloud-native pipeline for indexing financial answer passages! We can\nalso use Jina's \u003ca href=\"https://docs.jina.ai/chapters/flow/index.html\"\u003eFlow API\u003c/a\u003e to\nvisualize the Index Flow. First let's set our environment variables in the terminal for parallel and shards:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport JINA_PARALLEL='1'\nexport JINA_SHARDS='1'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNext, let's open a \u003ccode\u003ejupyter notebook\u003c/code\u003e in our working directory and do the following:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/66d4df6a197e107b9be6b4ef495c7fa2.js\"\u003e\u003c/script\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/index-flow-jina.png\" width=\"1000\"\u003e\n\u003cfigurecaption\u003eIndex Flow visualzation\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eHere we see our Index Flow with two Pods - the Encoder, \u003ccode\u003eencoder\u003c/code\u003e and Indexer, \u003ccode\u003edoc_indexer\u003c/code\u003e.\u003c/p\u003e\n\u003ch4\u003eBuild an Indexer Application\u003c/h4\u003e\n\u003cp\u003eLet's see how we can use the Index Flow as our application. In \u003ccode\u003eapp.py\u003c/code\u003e, we can change\n\u003ccode\u003eparallel\u003c/code\u003e in the \u003ccode\u003econfig\u003c/code\u003e function to indicate how many Peas (processes)\nwe want to split each microservice in for each Pod. We can also change \u003ccode\u003eshards\u003c/code\u003e\nto indicate parallelization during the indexing step. We will leave both of them unchanged for now.\nThis means that we will only have one Pea in each Pod.\u003c/p\u003e\n\u003cp\u003eLet's first import \u003ccode\u003eFlow\u003c/code\u003e from Jina's \u003ca href=\"https://docs.jina.ai/chapters/flow/index.html\"\u003eFlow API\u003c/a\u003e:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/752eef2f8355d5243202c00949dbfcb0.js\"\u003e\u003c/script\u003e\n\u003cp\u003eAfter the \u003ccode\u003eindex_generator\u003c/code\u003e function that we added in \u003ca href=\"#step-1-define-our-data\"\u003eStep 1. Define our data\u003c/a\u003e,\nlet's add the \u003ccode\u003eindex\u003c/code\u003e function which will first load the Index Flow that we have created in \u003ccode\u003eflows/index.yml\u003c/code\u003e\nand pass the input Document from \u003ccode\u003eindex_generator\u003c/code\u003e to the flow. We set our \u003ccode\u003ebatch_size=16\u003c/code\u003e for encoding\nthe answer passages into embeddings.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/c2ffa20fbce1a7ce8fc55597d32723e3.js\"\u003e\u003c/script\u003e\n\u003cp\u003eWe are now ready to index our data. In the our working directory run:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython app.py index\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH\"\u003e\u003cimg src=\"https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH.svg\" alt=\"asciicast\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAt the end you will see the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e✅ done in ⏱ 1 minute and 54 seconds 🐎 7.7/s\n        gateway@18904[S]:terminated\n    doc_indexer@18903[I]:recv ControlRequest from ctl▸doc_indexer▸⚐\n    doc_indexer@18903[I]:Terminating loop requested by terminate signal RequestLoopEnd()\n    doc_indexer@18903[I]:#sent: 56 #recv: 56 sent_size: 1.7 MB recv_size: 1.7 MB\n    doc_indexer@18903[I]:request loop ended, tearing down ...\n    doc_indexer@18903[I]:indexer size: 865 physical size: 3.1 MB\n    doc_indexer@18903[S]:artifacts of this executor (vecidx) is persisted to ./workspace/doc_compound_indexer-0/vecidx.bin\n    doc_indexer@18903[I]:indexer size: 865 physical size: 3.2 MB\n    doc_indexer@18903[S]:artifacts of this executor (docidx) is persisted to ./workspace/doc_compound_indexer-0/docidx.bin\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHooray 🙌 we finished the first part of our application! The embedding indexes and Document data will be stored in a directory called \u003ccode\u003eworkspace\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003eQuery Flow\u003c/h3\u003e\n\u003cp\u003eAfter indexing our data, we need to create a \u003cstrong\u003eQuery Flow\u003c/strong\u003e. The main idea behind the Query Flow is to use the\nsame BERT-based model to \u003cstrong\u003eencode a given question into an embedding\u003c/strong\u003e and use the Indexer to \u003cstrong\u003esearch for the most\nsimilar answer embeddings\u003c/strong\u003e. To further improve the search results, we will use the same reranking technique as my thesis\nTherefore, we will need to add another a reranking step using FinBERT-QA to recompute the scores of the answer matches returned by Jina.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003ca href=\"https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow.png\" width=\"1000\"\u003e\n\u003c/a\u003e\n\u003cfigurecaption\u003eQuery Flow\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eLet us again walk through the steps one by one.\u003c/p\u003e\n\u003ch4\u003eStep 1. Encode Question\u003c/h4\u003e\n\u003cp\u003eLet's assume that the question text will be a user input. Jina will take this input and\ndefine a new Document.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow-step1.png\" width=\"500\"\u003e\n\u003cfigurecaption\u003eEncoder in the Query Flow\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eI. Add the Encoder to the Query Flow\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eJust like the encoding step of the Index Flow, we encode the questions using the same Encoder. Therefore, we can use the same Encoder from \u003ccode\u003epods/encode.yml\u003c/code\u003e\nin our \u003cstrong\u003eQuery Flow\u003c/strong\u003e. We will create a new \u003ccode\u003equery.yml\u003c/code\u003e file in the \u003ccode\u003eflows\u003c/code\u003e folder and\nadd the Encoder Pod to it:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/768020d68924e16cefeb052602ecf4f2.js\"\u003e\u003c/script\u003e\n\u003ch4\u003eStep 2. Search Indexes\u003c/h4\u003e\n\u003cp\u003eAfter encoding the questions, the question embeddings will be added to the Document by the Driver. This Document\nis then sent to the Indexer in the next Pod and the Driver will pass the question embeddings to the Indexer.\nThe Indexer will then search for the answers with the most similar embeddings using the k-nearest neighbors algorithm and\npass a list of top-k answer matches to the Driver to be added to the Document.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow-step2.png\" width=\"500\"\u003e\n\u003cfigurecaption\u003eThe Indexer will search for the answers with the most similar embeddings\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eThe matches will contain data\nsuch as the \u003ccode\u003edocid\u003c/code\u003e, \u003ccode\u003edoc\u003c/code\u003e, and match \u003ccode\u003escores\u003c/code\u003e. Since we are also using the same\nIndexer from the Index Flow, all we need to do again is add the Indexer Pod to \u003ccode\u003eflows/query.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/f1358c0b825caf2fe406605ec0ae583c.js\"\u003e\u003c/script\u003e\n\u003ch4\u003eStep 3. Reranking\u003c/h4\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/Ranker.png\" width=\"300\"\u003e\n\u003c/p\u003e\n\u003cp\u003eLet's assume that the Indexer returns the top-k answer matches at this point and we want to recompute the match scores to\nget better results. Jina has a class of Executors called the \u003cstrong\u003eRankers\u003c/strong\u003e, in particular, the \u003cstrong\u003eMatch2DocRankers\u003c/strong\u003e\nre-scores the matches for a query by calculating new scores. If you look at the Rankers on Jina Hub, the\n\u003ca href=\"https://github.com/jina-ai/jina-hub/tree/master/rankers/LevenshteinRanker\"\u003eLevenshtein Ranker\u003c/a\u003e uses the\nLevenshtein distance to recompute the match scores.\u003c/p\u003e\n\u003cp\u003eHowever, instead of using a distance metric to recompute the scores, we want to load our fined-tuned BERT model,\nFinBERT-QA, in the Ranker and recompute the scores by using the concatenation of the question and the\ncurrent match answers as inputs into a binary classification task.\u003c/p\u003e\n\u003cp\u003eIn order to do this we need to \u003cstrong\u003ecreate our own custom\nExecutor\u003c/strong\u003e and implement our own logic. In this section we will use \u003cstrong\u003ePyTorch\u003c/strong\u003e and \u003cstrong\u003eHugging Face transformers\u003c/strong\u003e\nto implement our custom Ranker.\u003c/p\u003e\n\u003cp\u003eThe main idea here is to pass our query text and the matches (containing the answer text and match scores) to the\nRanker to return a reordered list of matches based on the relevancy scores computed by FinBERT-QA. The Driver will\nthen update the matches in the Document based on this reordered list.\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow-step3.png\" width=\"550\"\u003e\n\u003cfigurecaption\u003eThe Ranker recomputes the scores of the matches using FinBERT-QA\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eRecall that Peas can run in Docker, this means that we can simply \u003cstrong\u003ebuild a Docker image with our implementation\nof the Ranker and use the image in the Query Flow.\u003c/strong\u003e The Jina Hub API let's use to Cookiecutter to create the templates of all\nthe files we will need to do this. Let's get started by making sure that the Jina Hub extension is installed:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install \"jina[hub]\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eBuild a Custom Executor\u003c/h4\u003e\n\u003cp\u003eLet's first create the templates that we will need to build a Docker image for our custom Ranker.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1.) Set up.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn the\n\u003ccode\u003efinancial-qa-search/\u003c/code\u003e\ndirectory type:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ejina hub new\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will pop up a wizard that helps you walk through the process. Let's give our Executor the name \u003ccode\u003eFinBertQARanker\u003c/code\u003e\nand make sure to select \u003ccode\u003e4 - Ranker\u003c/code\u003e for the Executor type. We will use \u003ccode\u003ejinaai/jina\u003c/code\u003e as our base image for\nthe Docker image that we will build.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eYou've downloaded /Users/bithiah/.cookiecutters/cookiecutter-jina-hub before. Is it okay to delete and re-download it? [yes]: yes\nexecutor_name [The class name of the executor (UpperCamelCase)]: FinBertQARanker\nSelect executor_type:\n1 - Encoder\n2 - Crafter\n3 - Indexer\n4 - Ranker\n5 - Evaluator\nChoose from 1, 2, 3, 4, 5 [1]: 4\ndescription [What does this executor do?]: recomputes match scores using FinBERT-QA                \nkeywords [keywords to describe the executor, separated by commas]: \npip_requirements []: \nbase_image [jinaai/jina]: \nauthor_name [Jina AI Dev-Team (dev-team@jina.ai)]: \nauthor_url [https://jina.ai]: \nauthor_vendor [Jina AI Limited]: \ndocs_url [https://github.com/jina-ai/jina-hub]: \nversion [0.0.1]: \nlicense [apache-2.0]: \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter pressing Enter, you will see a new directory called \u003ccode\u003eFinBertQARanker\u003c/code\u003e. Your file structure should now look\nas follows:\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/file-structure.png\" width=\"650\"\u003e\n\u003cfigurecaption\u003eProject folder structure\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eWe will the implement our logic of the Ranker in \u003ccode\u003e__init__.py\u003c/code\u003e, write some tests in \u003ccode\u003etests/test_finbertqaranker.py\u003c/code\u003e, and\nchange the \u003ccode\u003eDockerfile\u003c/code\u003e to contain everything we need to build the image.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe code for the Ranker can be found \u003ca href=\"https://github.com/jina-ai/examples/tree/example-financial-qa-search/financial-qa-search/FinBertQARanker\"\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2.) Fill in the logic for reranking.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWe will now implement our logic in \u003ccode\u003e__init__.py\u003c/code\u003e, which should look like the following:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/f0fb64b29b46f45c59469fe4ef3495b9.js\"\u003e\u003c/script\u003e\n\u003cp\u003eJina contains different base classes for the Executors with different functionalities. The base Ranker class\nthat we will use is called \u003cstrong\u003eMatch2DocRankers\u003c/strong\u003e, which has the functionality to recompute the match scores.\u003c/p\u003e\n\u003cp\u003eLet's first change the base class of \u003ccode\u003eBaseRanker\u003c/code\u003e to \u003ccode\u003eMatch2DocRanker\u003c/code\u003e.\nLet's also import \u003cstrong\u003ePyTorch\u003c/strong\u003e using Jina and some other modules that we will need as well as define our current directory.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/6969968f9d5a6e4a081347ff272edce0.js\"\u003e\u003c/script\u003e\n\u003cp\u003eOur logic will be implemented in the \u003ccode\u003eFinBertQARanker\u003c/code\u003e class which will use \u003ccode\u003eTorchDevice\u003c/code\u003e and\n\u003ccode\u003eMatch2DocRanker\u003c/code\u003e from Jina. We will download the models that we need in the \u003ccode\u003eDockerfile\u003c/code\u003e later.\nLet us assume now we have two models in the folder \u003ccode\u003emodels/\u003c/code\u003e: (1) \u003ccode\u003ebert-qa/\u003c/code\u003e and (2) \u003ccode\u003e2_finbert-qa-50_512_16_3e6.pt\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e(1) \u003ccode\u003ebert-qa\u003c/code\u003e: bert-base-uncased fine-tuned on the MS Macro dataset\nfrom \u003ca href=\"https://github.com/nyu-dl/dl4marco-bert\"\u003ePassage Re-ranking with BERT\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e(2) \u003ccode\u003e2_finbert-qa-50_512_16_3e6.pt\u003c/code\u003e: FinBERT-QA model - fine-tuned \u003ccode\u003ebert-qa\u003c/code\u003e on the FiQA dataset.\u003c/p\u003e\n\u003cp\u003eWe first specify \u003ccode\u003ebert-qa/\u003c/code\u003e as the the pre-trained model that would be used for initialization,\n\u003ccode\u003e2_finbert-qa-50_512_16_3e6.pt\u003c/code\u003e as the model that would be used to compute the QA relevancy scores,\nand the maximum sequence length for the QA pairs:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/47faac3565dda220b71a77fe3a120d61.js\"\u003e\u003c/script\u003e\n\u003cp\u003eThen we add a \u003ccode\u003epost_init\u003c/code\u003e function to the class to load the models for the binary classification task. Make sure to\nset the model in evaluation mode.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/5db6428baf752471c4326d1d1e650906.js\"\u003e\u003c/script\u003e\n\u003cp\u003eNow let's implement a private \u003ccode\u003e_get_score\u003c/code\u003e function to compute each of the relevancy scores of the question\nand the top-k answer matches. We first concatenate the question and each top-k answer and encode them to get the\ninputs (\u003ccode\u003einput_ids\u003c/code\u003e, \u003ccode\u003etoken_type_ids\u003c/code\u003e, \u003ccode\u003eatt_mask\u003c/code\u003e) that the model needs using the\ntokenizer from transformers. We then feed the inputs into the model and get the prediction scores\nthat the QA pairs are relevant (\u003ccode\u003elabel = 1\u003c/code\u003e). We apply the softmax function to the scores to transform the\nprediction scores into probabilities between 0 and 1. The output would then be the relevancy score in the form of a\nprobability for the QA pair.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/5efb50d17b97f7eb594c7f88ee116c3a.js\"\u003e\u003c/script\u003e\n\u003cp\u003eLastly, let's fill in the scoring function that takes the question from the user and Jina's match scores as input\nand uses \u003ccode\u003e_get_scores\u003c/code\u003e to recompute new scores:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/b2be4165f2151fa69e9c88a21334c898.js\"\u003e\u003c/script\u003e\n\u003cp\u003e\u003cstrong\u003e3.) Write a Unit Test\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn order to create a new Executor and build a Docker image with the Jina Hub API, we need to write a unit test. We can\nfind a template for this in \u003ccode\u003etests/test_finbertqaranker.py\u003c/code\u003e. I wrote a simple check to compute the relevance\nprobability for two answer matches given a query and to check to see if \u003ccode\u003eFinBertQARanker\u003c/code\u003e computes the same\nscore as our expectation:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/8ce93efa42f7c56a2a224e7b8c8e86cb.js\"\u003e\u003c/script\u003e\n\u003cp\u003e\u003cstrong\u003e4.) Add Requirements\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eOther than Jina we are also using PyTorch and transformers for \u003ccode\u003eFinBertQARanker\u003c/code\u003e, so let's add them\nto \u003ccode\u003eFinBertQARanker/requirements.txt\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etorch==1.7.1\ntransformers==4.0.1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e5.) Prepare Dockerfile\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLet's change our \u003ccode\u003eDockerfile\u003c/code\u003e to the contents below, which will download the models into a folder called \u003ccode\u003emodels/\u003c/code\u003e.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/b226b930c0850b92eee9a25852278388.js\"\u003e\u003c/script\u003e\n\u003cp\u003e\u003cstrong\u003e6.) Build Docker image with Jina Hub API\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWe are finally ready to build \u003ccode\u003eFinBertQARanker\u003c/code\u003e into a Docker image. In our working directory, let's type:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ejina hub build FinBertQARanker/ --pull --test-uses --timeout-ready 60000\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003e--pull\u003c/code\u003e downloads our Jina base image if it is not already local.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e--test-uses\u003c/code\u003e adds an extra test to check if the built image can dry-run successfully via Jina's Flow API.\n\u003ccode\u003e--timeout-ready\u003c/code\u003e gives our \u003ccode\u003epost_init\u003c/code\u003e function time to load the models.\u003c/p\u003e\n\u003cp\u003eIf the build is successful, you will see this message:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e HubIO@10240[I]:Successfully built ba3fac0f3a46\n HubIO@10240[I]:Successfully tagged jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.13\n HubIO@10240[I]:building FinBertQARanker/ takes 6 minutes and 12 seconds (372.31s)\n HubIO@10240[S]:🎉 built jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.13 (sha256:ba3fac0f3a) uncompressed size: 3.3 GB\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCongratulations 🥳, you have successfully built a custom Executor in the form of a Docker image with the tag name\n\u003ccode\u003ejinahub/pod.ranker.finbertqaranker:0.0.1-0.8.23\u003c/code\u003e! Let's see how we can use it in the Query Flow next.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eI. Create a custom Ranker Pod\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTo use our custom Ranker, \u003ccode\u003eFinBertQARanker\u003c/code\u003e, we need to first create a new Pod for the Ranker. Let's create\nthe file \u003ccode\u003erank.yml\u003c/code\u003e in the \u003ccode\u003epods\u003c/code\u003e folder. Next, let's copy the contents from \u003ccode\u003eFinBertQARanker/config.yml\u003c/code\u003e\nto \u003ccode\u003epods/rank.yml\u003c/code\u003e and you should have the following:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/24c93873f7594ee0a097ea1550cc1d66.js\"\u003e\u003c/script\u003e\n\u003cp\u003eThis is going to tell the Query Flow to use the logic we have implemented in our Exectuor, \u003ccode\u003eFinBertQARanker/__init__.py\u003c/code\u003e.\nSince the code for this implementation is loaded inside the \u003ccode\u003eworkspace\u003c/code\u003e folder in the Docker image, let's add\n\u003ccode\u003eworkspace/\u003c/code\u003e before \u003ccode\u003e__init__.py\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe Encoder and Indexer Executors that we have used so far all use default Drivers in the Pods. Since we created our custom\nExecutor, we need to tell the Ranker Pod which Driver to use. In this case we will use the \u003ccode\u003eMatches2DocRankDriver\u003c/code\u003e for the\n\u003ccode\u003eMatch2DocRanker\u003c/code\u003e base Ranker class. Hence, our \u003ccode\u003erank.yml\u003c/code\u003e will look as follows:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/7757c64f850b4dd43c95e56d2f0a2909.js\"\u003e\u003c/script\u003e\n\u003cp\u003eHooray 🎊 we now have a custom Ranker Pod! Let's see next how we can use it in the Query Flow.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eII. Use Custom Ranker in the Query Flow\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLike the other Executor Pods, we just need to add \u003ccode\u003eranker\u003c/code\u003e after the \u003ccode\u003edoc_indexer\u003c/code\u003e and tell the Query Flow to use\nthe Docker image and Ranker Pod that we have just created by specifying the prefix \u003ccode\u003edocker://\u003c/code\u003e in front of the tag name. The final \u003ccode\u003eflows/query.yml\u003c/code\u003e should look as follows:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/f5e5291f7a30e4c43da63fb9ef537608.js\"\u003e\u003c/script\u003e\n\u003cp\u003e\u003cstrong\u003eBe aware that the tag name of the Docker image might change\u003c/strong\u003e depending the current Jina release. Make sure to change the\ntag name that accordingly to your build message.\u003c/p\u003e\n\u003cp\u003eWe can again visualize the Query Flow using the Flow API in a  \u003ccode\u003ejupyter notebook\u003c/code\u003e as follows:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/13e879fa8de427c7b8be8eadfc995ac6.js\"\u003e\u003c/script\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow-jina.png\" width=\"1000\"\u003e\n\u003cfigurecaption\u003eQuery Flow visualization\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eHere we see our Query Flow with three Pods containing the Encoder, \u003ccode\u003eencoder\u003c/code\u003e and Indexer, \u003ccode\u003edoc_indexer\u003c/code\u003e,\nand Ranker, \u003ccode\u003eranker\u003c/code\u003e.\nAt the end of the Query Flow, the Driver from the Ranker Pod will have changed the matches in the Document to an reordered list of\nmatches based on the probabilities computed by our custom Ranker, \u003ccode\u003eFinBertQARanker\u003c/code\u003e. Next, we will see how we can\naccess this list of final matches in our \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\u003ch4\u003eBuild a Search Application\u003c/h4\u003e\n\u003cp align=\"center\"\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/query-flow-step4.png\" width=\"550\"\u003e\n\u003cfigurecaption\u003eGet matches and scores stored in the Document\u003c/figurecaption\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eSince our final matches and their relevancy probability are stored in the Document, in \u003ccode\u003eapp.py\u003c/code\u003e, we can\nwrite a function to print out the response to a question from the user input. We can loop through the matches in our\nDocument, \u003ccode\u003ed.matches\u003c/code\u003e, and print out the values of the scores and the matching answer text.\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/1e18bcb2e7dbc77812a94ccefc6d1fcc.js\"\u003e\u003c/script\u003e\n\u003cp\u003eWe can then write our \u003ccode\u003esearch\u003c/code\u003e method that uses the Query Flow from \u003ccode\u003eflows/query.yml\u003c/code\u003e and passes\nthe user inputs into \u003ccode\u003eprint_resp\u003c/code\u003e. In \u003ccode\u003ef.search_lines()\u003c/code\u003e, we specify the input as our user query,\nthe output as the response to be printed, and the top-k answers we want to retrieve. The cool thing about\n\u003ccode\u003ef.search_lines()\u003c/code\u003e is that it automatically creates a Document for the user query, like sugar magic 🍬!\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/yuanbit/434ef56655bea8daf8b8275348387e36.js\"\u003e\u003c/script\u003e\n\u003cp\u003eHooray! 🎉🎉🎉 We have just finished building our Financial QA search engine! We can now run:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epython app.py search\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eand try out different questions! The Ranker might take some time to compute the relevancy\nscores since it is using a BERT-based model. Here is a list of sample questions:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e• What does it mean that stocks are “memoryless”?\n• What would a stock be worth if dividends did not exist?\n• What are the risks of Dividend-yielding stocks?\n• Why do financial institutions charge so much to convert currency?\n• Is there a candlestick pattern that guarantees any kind of future profit?\n• 15 year mortgage vs 30 year paid off in 15\n• Why is it rational to pay out a dividend?\n• Why do companies have a fiscal year different from the calendar year?\n• What should I look at before investing in a start-up?\n• Where do large corporations store their massive amounts of cash?\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp align=\"center\"\u003e\n\u003cimg src=\"/assets/images/blog/financial-qa/search-results.png\" width=\"900\"\u003e\n\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this blog, I introduced core Jina concepts and demonstrated how to build a production-ready Financial QA system using Jina.\nI also explained how to use the Jina Hub API to create a BERT-powered Ranker Executor. Thanks to\nthe building blocks that Jina provides, we could easily use the SOTA and powerful model, FinBERT-QA, in production.\u003c/p\u003e\n\u003cp\u003eThe neural search application we have just built with Jina runs locally on our own machines, but can also\nbe completely distributed and run on multiple machines in a network, making our application highly reusable, scalable,\nand efficient. On top of that, common cloud-native features such as persistence, scheduling, chaining, grouping, and\nparallelization all come out of the box.\u003c/p\u003e\n\u003cp\u003eMoreover, there are variants of pre-trained BERT models for other domains such as \u003ca href=\"https://github.com/dmis-lab/biobert\"\u003ebiomedical\u003c/a\u003e,\n\u003ca href=\"https://github.com/allenai/scibert\"\u003escience\u003c/a\u003e, and \u003ca href=\"https://huggingface.co/nlpaueb/legal-bert-base-uncased\"\u003elegal\u003c/a\u003e.\nYou can use these models to build a QA search application and experiment with the results!\u003c/p\u003e\n\u003ch2\u003eNext Step: Evaluation\u003c/h2\u003e\n\u003cp\u003eIf you made it all the way through this tutorial, you might be wondering, \u003cstrong\u003e\"how do I evaluate the search results?\"\u003c/strong\u003e.\nGreat question! Jina has a class of Executors called the \u003cstrong\u003eEvaluator\u003c/strong\u003e and has implementations of common evaluation\nmetrics like Precision and Reciprocal Error. Evaluation is an important step and will allow us to optimize\nthe search results and design the most effective Flows. We will see in the next tutorial how we can add the\nEvaluator in our Financial QA application.\u003c/p\u003e\n\u003ch2\u003eLearn More\u003c/h2\u003e\n\u003cp\u003eTo learn more about Jina, I recommend reading the following articles:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/jina-ai/what-is-jina-and-neural-search-7a9e166608ab\"\u003eWhat is Jina and Neural Search?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hanxiao.io/2020/10/19/A-Curated-List-of-Neural-Search-and-Jina-Framework-Designs/\"\u003eFrom Then to Now: a Curated List for Neural Search and Jina\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eand checking out our \u003ca href=\"https://github.com/jina-ai/jina\"\u003eGithub\u003c/a\u003e page!\u003c/p\u003e\n\u003cp\u003eIf you want to learn Jina by doing, I encourage you to start building your own examples and\nsharing them with the community to help us grow our open-source ecosystem! 🚀 For example, check out this\n\u003ca href=\"https://github.com/ArturTan/transformers-for-lawyers\"\u003ecommunity project - transformers-for-lawyers\u003c/a\u003e built with Jina.\u003c/p\u003e\n\u003cp\u003eWe saw how versatile and extensible Jina is and we could create all kinds of search applications using our own\nlogic and models for NLP, Computer Vision, and other ML search applications.\n\u003cstrong\u003e\u003ca href=\"https://github.com/jina-ai/jina-hub\"\u003eJina Hub\u003c/a\u003e is a great place to get started, where you can use\nthe available Executors to build other types of search engines (for images, videos, etc...) or create your own\nExecutors using the Jina Hub API!\u003c/strong\u003e You can always come back to this tutorial and walk through the process again.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAs an open-source company we would also love your help and contributions.️\u003c/strong\u003e We have issues labelled as \u003ca href=\"https://github.com/jina-ai/jina/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22\"\u003egood first issue\u003c/a\u003e\nto get started! You can read more about our contributing guidelines \u003ca href=\"https://github.com/jina-ai/jina/blob/master/CONTRIBUTING.md\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you want to know more about Jina's new features or ask any questions, welcome to join our \u003ca href=\"https://slack.jina.ai/\"\u003eSlack Community\u003c/a\u003e\nand our monthly public \u003ca href=\"https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/\"\u003eEngineering All Hands\u003c/a\u003e via\nZoom or Youtube live stream.\u003c/p\u003e\n\u003cp\u003eIf you are interested in joining us as a full-time AI / Backend / Frontend developer,\nplease submit your CV to our \u003ca href=\"jobs.jina.ai\"\u003ejob portal\u003c/a\u003e. Let’s build the next open-source neural search ecosystem together!\u003c/p\u003e\n\u003ch2\u003eCommunity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"slack.jina.ai\"\u003eSlack channel\u003c/a\u003e - a communication platform for developers to discuss Jina\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"mailto:newsletter+subscribe@jina.ai\"\u003eCommunity newsletter\u003c/a\u003e - subscribe to the latest update, release and event news of Jina\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.linkedin.com/company/jinaai/\"\u003eLinkedIn\u003c/a\u003e - get to know Jina AI as a company and find job opportunities\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://twitter.com/JinaAI_\"\u003eTwitter\u003c/a\u003e - follow us and interact with us using hashtag \u003ccode\u003e#JinaSearch\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://jina.ai\"\u003eCompany\u003c/a\u003e - know more about our company, we are fully committed to open-source!\u003c/li\u003e\n\u003c/ul\u003e\n","coverImage":"/assets/images/blog/financial-qa.png"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"financial-qa-tutorial"},"buildId":"KJvUyrCoh0MXs5cG--Qn6","runtimeConfig":{},"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-8683bd742a84c1edd48c.js"></script><script src="/_next/static/chunks/webpack-8f6366ea4b5fafd77e96.js" async=""></script><script src="/_next/static/chunks/framework-94f262366e752bd48d82.js" async=""></script><script src="/_next/static/chunks/commons-4667b98b62a60d7c050b.js" async=""></script><script src="/_next/static/chunks/main-9a4182dc8e7736869bf9.js" async=""></script><script src="/_next/static/chunks/pages/_app-afcb035e0413b2214f0f.js" async=""></script><script src="/_next/static/chunks/596-13cdde2fb793b77184ee.js" async=""></script><script src="/_next/static/chunks/522-e45333ebcf36799b860c.js" async=""></script><script src="/_next/static/chunks/373-350caaa5387e56e8b807.js" async=""></script><script src="/_next/static/chunks/93-1a5bac9fdf2b2295fba2.js" async=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0d67fc13dbd9e7ddf27f.js" async=""></script><script src="/_next/static/KJvUyrCoh0MXs5cG--Qn6/_buildManifest.js" async=""></script><script src="/_next/static/KJvUyrCoh0MXs5cG--Qn6/_ssgManifest.js" async=""></script></body></html>