<!DOCTYPE html><html translate="no" dir="ltr" lang="it"><head><title>C'è Ancora Bisogno del Chunking Quando i Modelli Long-Context Possono Fare Tutto?</title><meta charset="utf-8"><meta name="title" content="C'è Ancora Bisogno del Chunking Quando i Modelli Long-Context Possono Fare Tutto?"><meta name="description" content="Confronto delle prestazioni dei modelli di embedding a contesto lungo con diverse strategie di suddivisione per trovare l'approccio ottimale per le tue esigenze."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="og:title" content="C'è Ancora Bisogno del Chunking Quando i Modelli Long-Context Possono Fare Tutto?"><meta property="og:description" content="Confronto delle prestazioni dei modelli di embedding a contesto lungo con diverse strategie di suddivisione per trovare l'approccio ottimale per le tue esigenze."><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="twitter:title" content="C'è Ancora Bisogno del Chunking Quando i Modelli Long-Context Possono Fare Tutto?"><meta property="twitter:description" content="Confronto delle prestazioni dei modelli di embedding a contesto lungo con diverse strategie di suddivisione per trovare l'approccio ottimale per le tue esigenze."><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-DGCQK2WE.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-CRvJtbiE.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-ClvitnaO.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-Bede39Nb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-DM1bOzUP.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-JsXIhsmp.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-BAQAQ6Zw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-BN3-6b-d.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/it-cPZrmCL2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-DSxwy_dx.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-B9hffv3M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-yPNtTmyi.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QToolbar-cotlYAH-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-BnlCP6kZ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-D4PeDprF.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-DBp9X2gk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-CgIHL9N2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-bx_o4dUU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-DclPU7_P.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-5j1poJqo.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-BmqX0Ljl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding-DFcqc6Pf.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-DukYlXxE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-DdciS6DK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-CUbIstTp.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-BfYflfOA.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-D5SGh0x5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-8apMXH2q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-BXjNbbLV.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-B_CyKxBv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-CF90ZxEQ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage---V5pDyt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BxocxklI.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-Pc3LCZel.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-BZTeB02t.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-q765RzAS.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><meta name="author" content="Alex C-G, Michael Günther"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Alex C-G, Michael Günther"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="13 mins read"><meta property="article:published_time" content="2024-12-05T00:55:21.000+01:00"><meta property="article:modified_time" content="2024-12-05T00:55:21.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "C'è Ancora Bisogno del Chunking Quando i Modelli Long-Context Possono Fare Tutto?",
  "description": "Confronto delle prestazioni dei modelli di embedding a contesto lungo con diverse strategie di suddivisione per trovare l'approccio ottimale per le tue esigenze.",
  "image": [
    "https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"
  ],
  "datePublished": "2024-12-05T00:55:21.000+01:00",
  "dateModified": "2024-12-05T00:55:21.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    },
    {
      "@type": "Person",
      "name": "Michael Günther",
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Notizia</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Modelli</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_48c8311e-168e-4ed7-8064-c3a10fd5c47b" aria-label="Espandi &quot;Prodotti&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Prodotti</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_48c8311e-168e-4ed7-8064-c3a10fd5c47b" style="display: none;"><div class="q-list q-list--dark" role="list" label="Prodotti"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lettore</div><div class="q-item__label q-item__label--caption text-caption">Leggi gli URL e cerca sul web per ottenere LLM più approfonditi.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Incorporamenti</div><div class="q-item__label q-item__label--caption text-caption">Incorporamenti multilingue multimodali di livello mondiale.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Riclassificazione</div><div class="q-item__label q-item__label--caption text-caption">Recupero neurale di livello mondiale per massimizzare la pertinenza della ricerca.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Classificatore</div><div class="q-item__label q-item__label--caption text-caption">Classificazione zero-shot e few-shot per immagini e testo.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmentatore</div><div class="q-item__label q-item__label--caption text-caption">Tagliare il testo lungo in blocchi ed effettuare la tokenizzazione.</div></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_9e6f2c66-12c0-4d27-86a2-8cf1e2e84589" aria-label="Espandi &quot;Azienda&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Azienda</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_9e6f2c66-12c0-4d27-86a2-8cf1e2e84589" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Chi siamo</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contatta le vendite</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Programma di stagista</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Unisciti a noi</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Scarica il logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Termini &amp; Condizioni</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Login"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Login</div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_b4179e2b-03b7-4902-ad51-356a654e7e24"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_b4179e2b-03b7-4902-ad51-356a654e7e24" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_b4179e2b-03b7-4902-ad51-356a654e7e24_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-33ef2eff="" class="q-page" style="min-height: 100vh;"><div data-v-33ef2eff="" class="row full-width relative-position justify-end"><div data-v-33ef2eff="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-33ef2eff="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Il Contesto Lungo è Davvero Utile?</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Problemi con gli Embedding a Contesto Lungo</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Contesto Lungo vs. Troncamento</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Segmentazione del testo per migliori prestazioni di recupero</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Il Late Chunking Risolve il Problema del Contesto</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Fare Chunking o No?</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Conclusioni: Quando Usare Cosa?</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Conclusione</div></div></div></div></div><div data-v-33ef2eff="" class="col-12 col-md-10 col-lg-12"><div data-v-33ef2eff="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog tecnico</div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-33ef2eff="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">dicembre 04, 2024</div><h1 data-v-33ef2eff="" class="text-weight-medium text-center q-px-md my-title">C'è Ancora Bisogno del Chunking Quando i Modelli Long-Context Possono Fare Tutto?</h1><div data-v-33ef2eff="" class="col row justify-center"><div data-v-33ef2eff="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Confronto delle prestazioni dei modelli di embedding a contesto lungo con diverse strategie di suddivisione per trovare l'approccio ottimale per le tue esigenze.</div></div><div data-v-33ef2eff="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-33ef2eff="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-33ef2eff="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-33ef2eff="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Michael Günther"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Michael Günther" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-33ef2eff="" class="q-item__label">Alex C-G, Michael Günther • 13 minuti letti</div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-33ef2eff="" class="article"><section data-v-33ef2eff="" class="gh-content"><p>Nell'ottobre 2023, abbiamo introdotto <code>jina-embeddings-v2</code>, la prima famiglia di modelli di embedding open-source in grado di gestire input fino a 8.192 token. Basandoci su questo, quest'anno abbiamo lanciato <code>jina-embeddings-v3</code>, offrendo lo stesso ampio supporto per gli input con ulteriori miglioramenti.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-14.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-4.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>In questo articolo approfondiremo gli embedding con contesto lungo e risponderemo ad alcune domande: Quando è pratico consolidare un volume così grande di testo in un singolo vettore? La segmentazione migliora il recupero e, in caso affermativo, come? Come possiamo preservare il contesto da diverse parti di un documento mentre segmentiamo il testo?</p><p>Per rispondere a queste domande, confronteremo diversi metodi per generare gli embedding:</p><ul><li>Embedding con contesto lungo (codifica fino a 8.192 token in un documento) vs contesto breve (cioè troncamento a 192 token).</li><li>Nessun chunking vs. chunking naive vs. <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">late chunking</a>.</li><li>Diverse dimensioni dei chunk sia con chunking naive che con late chunking.</li></ul><h2 id="is-long-context-even-useful" style="position: relative;"><a href="#is-long-context-even-useful" title="Il Contesto Lungo è Davvero Utile?" id="anchor-is-long-context-even-useful"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Il Contesto Lungo è Davvero Utile?</h2><p>Con la capacità di codificare fino a dieci pagine di testo in un singolo embedding, i modelli di embedding con contesto lungo aprono possibilità per la rappresentazione di testi su larga scala. Ma è davvero utile? Secondo molte persone... no.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 6.35227 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--15-.png" width="559" height="88" alt="" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 5.21368 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png" width="610" height="117" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--16-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png 610w" style="cursor: help;"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 10.2143 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png" width="1430" height="140" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--14-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--14-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png 1430w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 11.0735 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png" width="1506" height="136" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png 1506w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div></div></div><figcaption><p><span style="white-space: pre-wrap;">Fonti: </span><a href="https://www.youtube.com/watch?v=xKR08kDY2q4"><span style="white-space: pre-wrap;">Citazione di Nils Reimer nel podcast How AI Is Built</span></a><span style="white-space: pre-wrap;">, </span><a href="https://x.com/brainlag/status/1717221138483331158"><span style="white-space: pre-wrap;">tweet di brainlag</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38026784"><span style="white-space: pre-wrap;">commento di egorfine su Hacker News</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38020753"><span style="white-space: pre-wrap;">commento di andy99 su Hacker News</span></a></p></figcaption></figure><p>Affronteremo tutte queste preoccupazioni con un'indagine dettagliata sulle capacità del contesto lungo, quando il contesto lungo è utile e quando dovresti (e non dovresti) usarlo. Ma prima, ascoltiamo questi scettici e guardiamo alcuni dei problemi che i modelli di embedding con contesto lungo devono affrontare.</p><h2 id="problems-with-long-context-embeddings" style="position: relative;"><a href="#problems-with-long-context-embeddings" title="Problemi con gli Embedding a Contesto Lungo" id="anchor-problems-with-long-context-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Problemi con gli Embedding a Contesto Lungo</h2><p>Immaginiamo di costruire un sistema di ricerca documenti per articoli, come quelli del nostro <a href="https://jina.ai/news">blog Jina AI</a>. A volte un singolo articolo può coprire più argomenti, come il <a href="https://jina.ai/news/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc">report sulla nostra visita alla conferenza ICML 2024</a>, che contiene:</p><ul><li>Un'introduzione, che cattura informazioni generali su ICML (numero di partecipanti, luogo, scopo, ecc).</li><li>La presentazione del nostro lavoro (<code>jina-clip-v1</code>).</li><li>Riassunti di altri interessanti paper di ricerca presentati all'ICML.</li></ul><p>Se creiamo un solo embedding per questo articolo, quell'embedding rappresenta una miscela di tre argomenti disparati:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png" class="kg-image" alt="" width="2000" height="778" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 1: Quando si fa l'embedding di un documento che copre più argomenti, il vettore risultante rappresenta una miscela di tutti i paragrafi, potenzialmente perdendo le informazioni distinte e specifiche contenute in ogni singolo paragrafo.</span></figcaption></figure><p>Questo porta a diversi problemi:</p><ul><li><strong>Diluizione della Rappresentazione:</strong> Mentre tutti gli argomenti in un dato testo <em>potrebbero</em> essere correlati, solo uno potrebbe essere rilevante per la query di ricerca dell'utente. Tuttavia, un singolo embedding (in questo caso, quello dell'intero post del blog) è solo un punto nello spazio vettoriale. Man mano che più testo viene aggiunto all'input del modello, l'embedding si sposta per catturare l'argomento generale dell'articolo, rendendolo meno efficace nel rappresentare il contenuto trattato in specifici paragrafi.</li><li><strong>Capacità Limitata:</strong> I modelli di embedding producono vettori di dimensione fissa, indipendentemente dalla lunghezza dell'input. Man mano che viene aggiunto più contenuto all'input, diventa più difficile per il modello rappresentare tutte queste informazioni nel vettore. Pensalo come scalare un'immagine a 16×16 pixel — Se ridimensioni l'immagine di qualcosa di semplice, come una mela, puoi ancora ricavare significato dall'immagine scalata. Scalare una mappa stradale di Berlino? Non proprio.</li><li><strong>Perdita di Informazioni:</strong> In alcuni casi, anche i modelli di embedding con contesto lungo raggiungono i loro limiti; Molti modelli supportano la codifica del testo fino a 8.192 token. I documenti più lunghi devono essere troncati prima dell'embedding, portando a una perdita di informazioni. Se l'informazione rilevante per l'utente si trova alla fine del documento, non verrà catturata affatto dall'embedding.</li><li><strong>Potresti <em>Aver Bisogno</em> della Segmentazione del Testo:</strong> Alcune applicazioni richiedono embedding per segmenti specifici del testo ma non per l'intero documento, come identificare il passaggio rilevante in un testo.</li></ul><h2 id="long-context-vs-truncation" style="position: relative;"><a href="#long-context-vs-truncation" title="Contesto Lungo vs. Troncamento" id="anchor-long-context-vs-truncation"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Contesto Lungo vs. Troncamento</h2><p>Per vedere se il contesto lungo è effettivamente utile, diamo un'occhiata alle prestazioni di due scenari di recupero:</p><ul><li>Codifica di documenti fino a 8.192 token (circa 10 pagine di testo).</li><li>Troncamento dei documenti a 192 token e codifica fino a quel punto.</li></ul><p>Confronteremo i risultati utilizzando<code>jina-embeddings-v3</code> con la metrica di recupero nDCG@10. Abbiamo testato i seguenti dataset:</p>

<table>
<thead>
<tr>
<th>Dataset</th>
<th>Descrizione</th>
<th>Esempio di Query</th>
<th>Esempio di Documento</th>
<th>Lunghezza Media Documento (caratteri)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/"><strong>NFCorpus</strong></a></td>
<td>Un dataset di recupero di testi medici completi con 3.244 query e documenti principalmente da PubMed.</td>
<td>"Using Diet to Treat Asthma and Eczema"</td>
<td>"Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland Recent studies have suggested that [...]"</td>
<td>326.753</td>
</tr>
<tr>
<td><a href="https://github.com/Yale-LILY/QMSum"><strong>QMSum</strong></a></td>
<td>Un dataset di riepilogo di riunioni basato su query che richiede il riepilogo di segmenti rilevanti delle riunioni.</td>
<td>"The professor was the one to raise the issue and suggested that a knowledge engineering trick [...]"</td>
<td>"Project Manager: Is that alright now ? {vocalsound} Okay . Sorry ? Okay , everybody all set to start the meeting ? [...]"</td>
<td>37.445</td>
</tr>
<tr>
<td><a href="https://paperswithcode.com/dataset/narrativeqa"><strong>NarrativeQA</strong></a></td>
<td>Dataset QA con lunghe storie e relative domande su contenuti specifici.</td>
<td>"What kind of business Sophia owned in Paris?"</td>
<td>"ï»¿The Project Gutenberg EBook of The Old Wives' Tale, by Arnold Bennett\n\nThis eBook is for the use of anyone anywhere [...]"</td>
<td>53.336</td>
</tr>
<tr>
<td><a href="https://github.com/Alab-NII/2wikimultihop"><strong>2WikiMultihopQA</strong></a></td>
<td>Un dataset QA multi-hop con fino a 5 passaggi di ragionamento, progettato con template per evitare scorciatoie.</td>
<td>"What is the award that the composer of song The Seeker (The Who Song) earned?"</td>
<td>"Passage 1:\nMargaret, Countess of Brienne\nMarguerite d'Enghien (born 1365 - d. after 1394), was the ruling suo jure [...]"</td>
<td>30.854</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2104.07091"><strong>SummScreenFD</strong></a></td>
<td>Un dataset di riassunti di sceneggiature con trascrizioni di serie TV e riassunti che richiedono l'integrazione di trame disperse.</td>
<td>"Penny gets a new chair, which Sheldon enjoys until he finds out that she picked it up from [...]"</td>
<td>"[EXT. LAS VEGAS CITY (STOCK) - NIGHT]\n[EXT. ABERNATHY RESIDENCE - DRIVEWAY -- NIGHT]\n(The lamp post light over the [...]"</td>
<td>1.613</td>
</tr>
</tbody>
</table>

<p>Come possiamo vedere, codificare più di 192 token può portare a notevoli miglioramenti delle prestazioni:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png" class="kg-image" alt="" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 2: Confronto tra le prestazioni dell'embedding con contesto lungo e dell'embedding di testo breve</span></figcaption></figure><p>Tuttavia, su alcuni dataset vediamo miglioramenti maggiori rispetto ad altri:</p><ul><li>Per <strong>NFCorpus</strong>, il troncamento fa a malapena differenza. Questo perché i titoli e gli abstract sono proprio all'inizio dei documenti, e questi sono altamente rilevanti per le tipiche ricerche degli utenti. Che sia troncato o meno, i dati più pertinenti rimangono entro il limite di token.</li><li><strong>QMSum</strong> e <strong>NarrativeQA</strong> sono considerati compiti di "comprensione della lettura", dove gli utenti tipicamente cercano fatti specifici all'interno di un testo. Questi fatti sono spesso incorporati in dettagli sparsi in tutto il documento e possono cadere al di fuori del limite troncato di 192 token. Ad esempio, nel documento NarrativeQA <em>Percival Keene</em>, la risposta alla domanda "Chi è il bullo che ruba il pranzo di Percival?" si trova ben oltre questo limite. Similmente, in <strong>2WikiMultiHopQA</strong>, le informazioni rilevanti sono disperse in tutto il documento, richiedendo ai modelli di navigare e sintetizzare conoscenze da più sezioni per rispondere efficacemente alle query.</li><li><strong>SummScreenFD</strong> è un compito mirato a identificare la sceneggiatura corrispondente a un dato riassunto. Poiché il riassunto comprende informazioni distribuite in tutta la sceneggiatura, codificare più testo migliora l'accuratezza nel far corrispondere il riassunto alla sceneggiatura corretta.</li></ul><h2 id="segmenting-text-for-better-retrieval-performance" style="position: relative;"><a href="#segmenting-text-for-better-retrieval-performance" title="Segmentazione del testo per migliori prestazioni di recupero" id="anchor-segmenting-text-for-better-retrieval-performance"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Segmentazione del testo per migliori prestazioni di recupero</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Andando avanti, discutiamo tre concetti simili. Per evitare confusione, li riferiamo come segue:<br>• <b><strong style="white-space: pre-wrap;">Segmentazione</strong></b>: Rilevamento di segnali di confine in un testo di input, per esempio, frasi o un numero fisso di token.<br>• <b><strong style="white-space: pre-wrap;">Chunking ingenuo</strong></b>: Suddivisione del testo in chunks basata sui segnali di segmentazione, prima di codificarlo.<br>• <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">Late chunking</strong></b></a>: Codifica del documento prima e poi segmentazione (preservando il contesto tra i chunks).</div></div><p>Invece di incorporare un intero documento in un unico vettore, possiamo utilizzare vari metodi per prima segmentare il documento assegnando segnali di confine:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/chunking-animation.gif" class="kg-image" alt="" width="2000" height="492" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/chunking-animation.gif 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/chunking-animation.gif 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/chunking-animation.gif 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/chunking-animation.gif 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 3: Applicazione dei metodi di chunking "a dimensione fissa", "basato su frasi" e "semantico" a un passaggio di testo</span></figcaption></figure><p>Alcuni metodi comuni includono:</p><ul><li><strong>Segmentazione per dimensione fissa:</strong> Il documento viene diviso in segmenti di un numero fisso di token, determinato dal tokenizer del modello di embedding. Questo assicura che la tokenizzazione dei segmenti corrisponda alla tokenizzazione dell'intero documento (segmentare per un numero specifico di caratteri potrebbe portare a una tokenizzazione diversa).</li><li><strong>Segmentazione per frase:</strong> Il documento viene segmentato in frasi, e ogni chunk consiste in <em>n</em> numero di frasi.</li><li><strong>Segmentazione per semantica:</strong> Ogni segmento corrisponde a più frasi e un modello di embedding determina la similarità delle frasi consecutive. Le frasi con alte similarità di embedding vengono assegnate allo stesso chunk.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Puoi facilmente eseguire la segmentazione con <a href="https://jina.ai/segmenter/">Jina Segmenter</a>, la nostra API gratuita per segmentare testi lunghi in chunks e tokenizzazione basata sulla struttura del documento.</div></div><p>Per semplicità, in questo articolo utilizziamo la segmentazione a dimensione fissa.</p><h3 id="document-retrieval-using-naive-chunking" style="position: relative;"><a href="#document-retrieval-using-naive-chunking" title="Recupero di documenti utilizzando il chunking ingenuo" id="anchor-document-retrieval-using-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Recupero di documenti utilizzando il chunking ingenuo</h3><p>Una volta eseguita la segmentazione a dimensione fissa, possiamo ingenuamente suddividere il documento secondo quei segmenti:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png" class="kg-image" alt="" width="960" height="540" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 960w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 4: Chunking ingenuo basato sui segnali di confine rilevati durante la segmentazione.</span></figcaption></figure><p>Usando <code>jina-embeddings-v3</code>, codifichiamo ogni chunk in un embedding che cattura accuratamente la sua semantica, poi memorizziamo questi embedding in un database vettoriale.</p><p>Durante l'esecuzione, il modello codifica la query dell'utente in un vettore di query. Lo confrontiamo con il nostro database vettoriale di embedding dei chunk per trovare il chunk con la più alta similarità del coseno, e poi restituiamo il documento corrispondente all'utente:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--17-.png" class="kg-image" alt="" width="2000" height="847" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--17-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--17-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--17-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/image--17-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 5: Recupero dei documenti implementato con chunking ingenuo: (1) I documenti nella collezione vengono divisi in chunk basati su segnali di confine, (2) il modello di embedding codifica tutti i chunk e memorizza gli embedding risultanti in un database, (3) quando arriva una query, il modello di embedding la codifica e il database determina il chunk più simile. Alla fine identifichiamo il documento rilevante dall'ID del documento memorizzato per il chunk nel database e lo restituiamo all'utente.</span></figcaption></figure><h3 id="problems-with-naive-chunking" style="position: relative;"><a href="#problems-with-naive-chunking" title="Problemi con il Chunking Ingenuo" id="anchor-problems-with-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Problemi con il Chunking Ingenuo</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png" class="kg-image" alt="" width="1774" height="456" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--18-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--18-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--18-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png 1774w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 6: Quando si suddivide un testo in frasi, i riferimenti a parti precedenti del testo non possono essere risolti.</span></figcaption></figure><p>Mentre il chunking ingenuo affronta alcune delle limitazioni dei modelli di embedding a lungo contesto, presenta anche degli svantaggi:</p><ul><li><strong>Perdita del Quadro Generale:</strong> Per quanto riguarda il recupero dei documenti, più embedding di chunk più piccoli potrebbero non riuscire a catturare l'argomento generale del documento. È come non riuscire a vedere la foresta a causa degli alberi.</li><li><strong>Problema del Contesto Mancante:</strong> I chunk non possono essere interpretati accuratamente poiché mancano le informazioni contestuali, come illustrato nella Figura 6.</li><li><strong>Efficienza:</strong> Più chunk richiedono più spazio di archiviazione e aumentano il tempo di recupero.</li></ul><h2 id="late-chunking-solves-the-context-problem" style="position: relative;"><a href="#late-chunking-solves-the-context-problem" title="Il Late Chunking Risolve il Problema del Contesto" id="anchor-late-chunking-solves-the-context-problem"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Il Late Chunking Risolve il Problema del Contesto</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Per risolvere il problema del contesto mancante, abbiamo introdotto un nuovo metodo chiamato "late chunking", descritto nei nostri precedenti post sul blog: <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">parte I</strong></b></a>, <a href="https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/"><b><strong style="white-space: pre-wrap;">parte II</strong></b></a>, <a href="https://jina.ai/news/finding-optimal-breakpoints-in-long-documents-using-small-language-models"><b><strong style="white-space: pre-wrap;">parte III</strong></b></a>, <a href="https://arxiv.org/abs/2409.04701"><b><strong style="white-space: pre-wrap;">paper di ricerca</strong></b></a>.</div></div><p>Il late chunking funziona in due passaggi principali:</p><ol><li>Prima, utilizza le capacità di lungo contesto del modello per codificare l'intero documento in embedding di token. Questo preserva il contesto completo del documento.</li><li>Poi, crea gli embedding dei chunk applicando il mean pooling a specifiche sequenze di embedding di token, corrispondenti ai segnali di confine identificati durante la segmentazione.</li></ol><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png" class="kg-image" alt="" width="1200" height="865" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--19-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--19-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 7: Late chunking vs chunking ingenuo.</span></figcaption></figure><p>Il vantaggio principale di questo approccio è che gli embedding dei token sono contestualizzati - significa che catturano naturalmente riferimenti e relazioni con altre parti del documento. Poiché il processo di embedding avviene prima del chunking, ogni chunk mantiene la consapevolezza del contesto più ampio del documento, risolvendo il problema del contesto mancante che affligge gli approcci di chunking ingenuo.</p><p>Per documenti che superano la dimensione massima di input del modello, possiamo utilizzare il "long late chunking":</p><ol><li>Prima, dividiamo il documento in "macro-chunk" sovrapposti. Ogni macro-chunk è dimensionato per rientrare nella lunghezza massima del contesto del modello (per esempio, 8.192 token).</li><li>Il modello elabora questi macro-chunk per creare gli embedding dei token.</li><li>Una volta ottenuti gli embedding dei token, procediamo con il late chunking standard - applicando il mean pooling per creare gli embedding finali dei chunk.</li></ol><p>Questo approccio ci permette di gestire documenti di qualsiasi lunghezza mantenendo i benefici del late chunking. Pensalo come un processo in due fasi: prima rendere il documento digeribile per il modello, poi applicare la procedura normale di late chunking.</p><p>In breve:</p><ul><li><strong>Chunking ingenuo:</strong> Segmentare il documento in piccoli chunk, poi codificare ogni chunk separatamente.</li><li><strong>Late chunking:</strong> Codificare l'intero documento in una volta per creare gli embedding dei token, poi creare gli embedding dei chunk raggruppando gli embedding dei token basati sui confini dei segmenti.</li><li><strong>Long late chunking:</strong> Dividere documenti grandi in macro-chunk sovrapposti che si adattano alla finestra di contesto del modello, codificarli per ottenere gli embedding dei token, poi applicare il late chunking normalmente.</li></ul><p>Per una descrizione più estesa dell'idea, dai un'occhiata al nostro <a href="https://arxiv.org/abs/2409.04701">paper</a> o ai post del blog menzionati sopra.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2409.04701"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models</div><div class="kg-bookmark-description">Many use cases require retrieving smaller portions of text, and dense vector-based retrieval systems often perform better with shorter text segments, as the semantics are less likely to be over-compressed in the embeddings. Consequently, practitioners often split text documents into smaller chunks and encode them separately. However, chunk embeddings created in this way can lose contextual information from surrounding chunks, resulting in sub-optimal representations. In this paper, we introduce a novel method called late chunking, which leverages long context embedding models to first embed all tokens of the long text, with chunking applied after the transformer model and just before mean pooling - hence the term late in its naming. The resulting chunk embeddings capture the full contextual information, leading to superior results across various retrieval tasks. The method is generic enough to be applied to a wide range of long-context embedding models and works without additional training. To further increase the effectiveness of late chunking, we propose a dedicated fine-tuning approach for embedding models.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-6.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-2.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="to-chunk-or-not-to-chunk" style="position: relative;"><a href="#to-chunk-or-not-to-chunk" title="Fare Chunking o No?" id="anchor-to-chunk-or-not-to-chunk"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Fare Chunking o No?</h2><p>Abbiamo già visto che l'embedding a lungo contesto generalmente supera gli embedding di testi più brevi, e abbiamo dato una panoramica delle strategie di chunking sia ingenuo che tardivo. La domanda ora è: Il chunking è migliore dell'embedding a lungo contesto?</p><p>Per condurre un confronto equo, tronchiamo i valori di testo alla lunghezza massima della sequenza del modello (8.192 token) prima di iniziare a segmentarli. Usiamo una segmentazione a dimensione fissa con 64 token per segmento (sia per la segmentazione ingenua che per il late chunking). Confrontiamo tre scenari:</p><ul><li><strong>Nessuna segmentazione:</strong> Codifichiamo ogni testo in un singolo embedding. Questo porta agli stessi punteggi dell'esperimento precedente (vedi Figura 2), ma li includiamo qui per un migliore confronto.</li><li><strong>Chunking ingenuo:</strong> Segmentiamo i testi, poi applichiamo il chunking ingenuo basato sui segnali di confine.</li><li><strong>Late chunking:</strong> Segmentiamo i testi, poi usiamo il late chunking per determinare gli embedding.</li></ul><p>Sia per il late chunking che per la segmentazione ingenua, utilizziamo il recupero dei chunk per determinare il documento rilevante (come mostrato nella Figura 5, precedentemente in questo post).</p><p>I risultati non mostrano un chiaro vincitore:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png" class="kg-image" alt="" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 8: Nessun chunking vs chunking ingenuo vs late chunking</span></figcaption></figure><ul><li><strong>Per il recupero dei fatti, il chunking ingenuo funziona meglio:</strong> Per i dataset QMSum, NarrativeQA e 2WikiMultiHopQA, il modello deve identificare i passaggi rilevanti nel documento. Qui, il chunking ingenuo è chiaramente migliore rispetto alla codifica di tutto in un singolo embedding, poiché probabilmente solo pochi chunk includono informazioni rilevanti, e tali chunk le catturano molto meglio di un singolo embedding dell'intero documento.</li><li><strong>Il chunking tardivo funziona meglio con documenti coerenti e contesto rilevante:</strong> Per documenti che trattano un argomento coerente dove gli utenti cercano temi generali piuttosto che fatti specifici (come in NFCorpus), il chunking tardivo ha prestazioni leggermente migliori rispetto al non chunking, poiché bilancia il contesto dell'intero documento con i dettagli locali. Tuttavia, mentre il chunking tardivo generalmente si comporta meglio del chunking ingenuo preservando il contesto, questo vantaggio può diventare uno svantaggio quando si cercano fatti isolati all'interno di documenti contenenti per lo più informazioni irrilevanti - come si vede nelle regressioni delle prestazioni per NarrativeQA e 2WikiMultiHopQA, dove il contesto aggiunto diventa più distraente che utile.</li></ul><h3 id="does-chunk-size-make-a-difference" style="position: relative;"><a href="#does-chunk-size-make-a-difference" title="La Dimensione dei Chunk Fa la Differenza?" id="anchor-does-chunk-size-make-a-difference"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>La Dimensione dei Chunk Fa la Differenza?</h3><p>L'efficacia dei metodi di chunking dipende davvero dal dataset, evidenziando come la struttura del contenuto giochi un ruolo cruciale:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png" class="kg-image" alt="" width="1200" height="1800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--21-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--21-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figura 9: Confronto delle dimensioni dei chunk con chunking ingenuo e tardivo.</span></figcaption></figure><p>Come possiamo vedere, il chunking tardivo generalmente supera il chunking ingenuo con chunk di dimensioni minori, poiché i chunk ingenui più piccoli sono troppo ridotti per contenere molto contesto, mentre i chunk tardivi più piccoli mantengono il contesto dell'intero documento, rendendoli più significativi semanticamente. L'eccezione è il dataset NarrativeQA dove c'è semplicemente così tanto contesto irrilevante che il chunking tardivo perde terreno. Con chunk di dimensioni maggiori, il chunking ingenuo mostra un notevole miglioramento (occasionalmente superando il chunking tardivo) grazie all'aumento del contesto, mentre le prestazioni del chunking tardivo diminuiscono gradualmente.</p><h2 id="takeaways-when-to-use-what" style="position: relative;"><a href="#takeaways-when-to-use-what" title="Conclusioni: Quando Usare Cosa?" id="anchor-takeaways-when-to-use-what"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusioni: Quando Usare Cosa?</h2><p>In questo post, abbiamo esaminato diversi tipi di task di recupero documenti per capire meglio quando utilizzare la segmentazione e quando il chunking tardivo è utile. Quindi, cosa abbiamo imparato?</p><h3 id="when-should-i-use-long-context-embedding" style="position: relative;"><a href="#when-should-i-use-long-context-embedding" title="Quando Dovrei Usare l'Embedding con Contesto Lungo?" id="anchor-when-should-i-use-long-context-embedding"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Quando Dovrei Usare l'Embedding con Contesto Lungo?</h3><p>In generale, non danneggia l'accuratezza del recupero includere quanto più testo possibile dei tuoi documenti nell'input del tuo modello di embedding. Tuttavia, i modelli di embedding con contesto lungo spesso si concentrano sull'inizio dei documenti, poiché contengono contenuti come titoli e introduzione che sono più importanti per giudicare la rilevanza, ma i modelli potrebbero perdere contenuti nella parte centrale del documento.</p><h3 id="when-should-i-use-naive-chunking" style="position: relative;"><a href="#when-should-i-use-naive-chunking" title="Quando Dovrei Usare il Chunking Ingenuo?" id="anchor-when-should-i-use-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Quando Dovrei Usare il Chunking Ingenuo?</h3><p>Quando i documenti coprono molteplici aspetti, o le query degli utenti mirano a informazioni specifiche all'interno di un documento, il chunking generalmente migliora le prestazioni di recupero.</p><p>Alla fine, le decisioni sulla segmentazione dipendono da fattori come la necessità di mostrare testo parziale agli utenti (ad esempio come Google presenta i passaggi rilevanti nelle anteprime dei risultati di ricerca), che rende la segmentazione essenziale, o vincoli di calcolo e memoria, dove la segmentazione può essere meno favorevole a causa dell'aumento del sovraccarico di recupero e dell'utilizzo delle risorse.</p><h3 id="when-should-i-use-late-chunking" style="position: relative;"><a href="#when-should-i-use-late-chunking" title="Quando Dovrei Usare il Chunking Tardivo?" id="anchor-when-should-i-use-late-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Quando Dovrei Usare il Chunking Tardivo?</h3><p>Codificando l'intero documento prima di creare i chunk, il chunking tardivo risolve il problema dei segmenti di testo che perdono il loro significato a causa del contesto mancante. Questo funziona particolarmente bene con documenti coerenti, dove ogni parte è correlata al tutto. I nostri esperimenti mostrano che il chunking tardivo è particolarmente efficace quando si divide il testo in chunk più piccoli, come dimostrato nel nostro <a href="https://arxiv.org/abs/2409.04701">paper</a>. Tuttavia, c'è un'avvertenza: se parti del documento non sono correlate tra loro, includere questo contesto più ampio può effettivamente peggiorare le prestazioni di recupero, poiché aggiunge rumore agli embedding.</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusione" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusione</h2><p>La scelta tra embedding con contesto lungo, chunking ingenuo e chunking tardivo dipende dai requisiti specifici del tuo task di recupero. Gli embedding con contesto lungo sono preziosi per documenti coerenti con query generali, mentre il chunking eccelle nei casi in cui gli utenti cercano fatti o informazioni specifiche all'interno di un documento. Il chunking tardivo migliora ulteriormente il recupero mantenendo la coerenza contestuale all'interno di segmenti più piccoli. In definitiva, comprendere i tuoi dati e gli obiettivi di recupero guiderà l'approccio ottimale, bilanciando accuratezza, efficienza e rilevanza contestuale.</p><p>Se stai esplorando queste strategie, considera di provare <code>jina-embeddings-v3</code>—le sue avanzate capacità di contesto lungo, chunking tardivo e flessibilità lo rendono un'eccellente scelta per diversi scenari di recupero.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: Un Modello di Embedding Multilingue all'Avanguardia</div><div class="kg-bookmark-description">jina-embeddings-v3 è un modello di embedding testuale multilingue all'avanguardia con 570M parametri e lunghezza di token di 8192, che supera gli ultimi embedding proprietari di OpenAI e Cohere su MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-15.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-5.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure></section></article><div data-v-33ef2eff="" class="row justify-between items-center q-py-md"><div data-v-33ef2eff=""><span data-v-33ef2eff="" class="text-weight-bold">Categorie:</span><span data-v-33ef2eff="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog tecnico</div></div></div></span></div><div data-v-33ef2eff=""><div data-v-33ef2eff="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-33ef2eff="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fit%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fit%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fit%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fit%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fit%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-33ef2eff="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-33ef2eff="" class="text-h5 q-my-xl">Per saperne di più</div><a data-v-aa70018b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/text-image-global-contrastive-alignment-and-token-patch-local-alignment"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">gennaio 07, 2025 • 6 minuti letti</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Text-Image Global Contrastive Alignment and Token-Patch Local Alignment</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="3D rendered scene with a black-screened laptop on a geometrical pedestal and patterned spheres, against a blue backdrop."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="3D rendered scene with a black-screened laptop on a geometrical pedestal and patterned spheres, against a blue backdrop." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/banner--16-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa70018b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/text-embeddings-fail-to-capture-word-order-and-how-to-fix-it"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">dicembre 17, 2024 • 12 minuti letti</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Text Embeddings Fail to Capture Word Order and How to Fix It</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Bo Wang"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Bo Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Three abstract figures in white, gray, and pink on matching cubes placed on a colorful checkered surface against a green back"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Three abstract figures in white, gray, and pink on matching cubes placed on a colorful checkered surface against a green back" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner-order.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa70018b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/scaling-test-time-compute-for-embedding-models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">dicembre 12, 2024 • 12 minuti letti</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Scaling Test-Time Compute For Embedding Models</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="David Hockney artwork of a hand holding a rod with three colored spheres on a blue-toned background."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="David Hockney artwork of a hand holding a rod with three colored spheres on a blue-toned background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/test-time-compute.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Uffici</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Sunnyvale, California</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, Stati Uniti</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlino, Germania (sede centrale)</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlino, Germania</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Pechino, Cina</div><div class="q-item__label q-item__label--caption text-caption text-dim">Livello 5, Edificio 6, No.48 Haidian West St. Pechino, Cina</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzen, Cina</div><div class="q-item__label q-item__label--caption text-caption text-dim">402 Piano 4, Fu'an Technology Building, Shenzhen, Cina</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fondazione di ricerca</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Lettore</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Incorporamenti</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Riclassificazione</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Classificatore</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Segmentatore</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Ottieni la chiave API Jina AI</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Limite di velocità</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">Stato dell'API</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Azienda</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Chi siamo</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contatta le vendite</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Sala stampa</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Programma di stagista</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Unisciti a noi</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Scarica il logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Termini</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Sicurezza</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Termini &amp; Condizioni</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Privacy</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Gestisci i cookie</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>