<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>What is ColBERT and Late Interaction and Why They Matter in Search?</title><meta charset="utf-8"><meta name="title" content="What is ColBERT and Late Interaction and Why They Matter in Search?"><meta name="description" content="Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search"><meta property="og:title" content="What is ColBERT and Late Interaction and Why They Matter in Search?"><meta property="og:description" content="Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search."><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search"><meta property="twitter:title" content="What is ColBERT and Late Interaction and Why They Matter in Search?"><meta property="twitter:description" content="Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search."><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png">  <script type="module" crossorigin="" src="/assets/index.5863a640.js"></script>
  <link rel="stylesheet" href="/assets/index.7b15faf7.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/register.49ee9544.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip.8852072c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine.808a9dd5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard.2cddc2a0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.5863a640.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout.62d26fe0.js"><link rel="stylesheet" href="/assets/MainLayout.891b970f.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpace.43de493e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSelect.8cbceb51.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge.3140e13c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu.c42d7e58.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format.988231da.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding.7320479b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList.a5fa8f62.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown.b3161ce2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver.3543ea2c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QImg.b66c2073.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem.9b5710b5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollArea.7023375f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan.20c2e616.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch.3df10340.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResponsive.f66e6bef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup.659c179c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TypingText.1c0a75f9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QForm.53449891.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPopupProxy.554a4eed.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/chunk.17bfede8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isArrayLike.a2a00cef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isObject.cef35763.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/toNumber.476d0739.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage.fa1de77d.js"><link rel="stylesheet" href="/assets/NewsPage.b778c313.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/AskAnythingToolTip.7a392864.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs.7db1ccc3.js"><link rel="stylesheet" href="/assets/blogs.0a453c04.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/plugin-vue_export-helper.21dcd24c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge.61b707b9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard.97a67d2c.js"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><script charset="utf-8" src="https://platform.twitter.com/js/tweet.d7aeb21a88e025d2ea5f5431a103f586.js"></script><link prerender-ignore rel=preconnect href=//app.usercentrics.eu><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js></script><script prerender-ignore>// (optional) additional configs for the Smart Data Protector
      uc.reloadOnOptIn('BJz7qNsdj-7'); // reload page on YouTube opt-in</script><style prerender-ignore>.uc-embedding-container {
      min-height: 100% !important;
    }

    .uc-embedding-wrapper p {
      color: black;
    }</style><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top text-white lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none" role="toolbar"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">reorder</i></span></button><hr class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></span></span></a><div class="q-space"></div><label class="q-field row no-wrap items-start q-field--filled q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--float q-field--dark" for="f_311b6b75-933e-427c-8d11-a881976fe3fe"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>English</span><input class="q-select__focus-target" id="f_311b6b75-933e-427c-8d11-a881976fe3fe" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_311b6b75-933e-427c-8d11-a881976fe3fe_lb"></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon fas fa-caret-down q-select__dropdown-icon" aria-hidden="true" role="presentation"> </i></div></div></div></label></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-left" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--left q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(-300px);"><div class="q-drawer__content fit scroll"><div class="q-scrollarea q-scrollarea--dark fit"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark q-list--padding"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><span class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/embedding.fb4bca87.svg"></span></div></div></div><div class="q-item__section column q-item__section--main justify-center">Embeddings</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">notifications</i></div></div></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="79eebb40-1f84-48ee-ac0f-54eda16e1fae" aria-label="Expand &quot;For Enterprises&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Enterprises</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="79eebb40-1f84-48ee-ac0f-54eda16e1fae" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding.fb4bca87.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">Our world-class embeddings for your search and RAG systems</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="1cc58e09-9225-4041-b5c3-dc09f2ad6a20" aria-label="Expand &quot;For Power Users&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Power Users</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="1cc58e09-9225-4041-b5c3-dc09f2ad6a20" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://promptperfect.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://scenex.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://bestbanner.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://chat.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://rationale.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="1d6b26f1-077e-4cd9-be12-9b32f8920a08" aria-label="Expand &quot;For Developers&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Developers</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="1d6b26f1-077e-4cd9-be12-9b32f8920a08" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/docarray/docarray"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/doc-array.35372518.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DocArray</div><div class="q-item__label q-item__label--caption text-caption">The data structure for multimodal data</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jina"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/core.99751891.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jina</div><div class="q-item__label q-item__label--caption text-caption">Build multimodal AI applications on the cloud</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/clip-as-service"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/clip-as-service.f454ca2a.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">CLIP-as-service</div><div class="q-item__label q-item__label--caption text-caption">Embed images and sentences into fixed-length vectors with CLIP</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/finetuner"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetuner.c62eaafa.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Finetuner</div><div class="q-item__label q-item__label--caption text-caption">Fine-tune embeddings on domain specific data for better search quality</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jcloud"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jcloud.669910ba.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JCloud</div><div class="q-item__label q-item__label--caption text-caption">Deploy a local project as a cloud service. Radically easy, no nasty surprises.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/langchain-serve"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/langchain-serve.8cf53254.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">LangChain-Serve</div><div class="q-item__label q-item__label--caption text-caption">Langchain apps on production with Jina &amp; FastAPI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/vectordb"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/VectorDB.46be6cc1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">VectorDB</div><div class="q-item__label q-item__label--caption text-caption">A Python vector database you just need - no more, no less</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/dalle-flow"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dall-e-flow.ea199b2d.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DALL-E Flow</div><div class="q-item__label q-item__label--caption text-caption">A human-in-the-Loop workflow for creating HD images from text</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/discoart"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/disco-art.f21a267f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DiscoArt</div><div class="q-item__label q-item__label--caption text-caption">Create compelling Disco Diffusion artworks in one line of code</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/thinkgpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/think-gpt.0a671280.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ThinkGPT</div><div class="q-item__label q-item__label--caption text-caption">Agent techniques to augment your LLM and push it beyond its limits</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/dev-gpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dev-gpt.a3e55036.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DevGPT</div><div class="q-item__label q-item__label--caption text-caption">Your virtual development team</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/rungpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/run-gpt.5571707e.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">RunGPT</div><div class="q-item__label q-item__label--caption text-caption">An open-source cloud-native of large multimodal models serving framework</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jerboa"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jerboa.af6b308b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jerboa</div><div class="q-item__label q-item__label--caption text-caption">An experimental finetuner for open-source LLMs</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="05d38259-8281-4581-82d0-b24be6444dc8" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><span class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></span></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="05d38259-8281-4581-82d0-b24be6444dc8" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/open-day"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Open day</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://jobs.lever.co/jina-ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px; padding-bottom: 61px;"><main data-v-5839678b="" class="q-page" style="min-height: 100vh;"><div data-v-5839678b="" class="row justify-center q-gutter-lg"><div data-v-5839678b="" class="col q-my-xl q-py-xl"><div data-v-5839678b="" class="q-mx-md q-mx-md-xl q-px-md-md q-px-lg-lg q-px-xl-xl"><div data-v-5839678b="" class="row justify-between items-center q-mt-lg"><a data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch col-auto" tabindex="0" href="/news"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">arrow_circle_left</i><span class="block">Back to Newsroom</span></span></a><div data-v-5839678b="" class="col-auto"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-icons q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Featured</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></div></div><div data-v-5839678b="" class="q-img q-img--menu q-mt-md" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"><div data-v-5839678b="" class="text-white absolute-bottom q-pa-lg lock-blur text-h4" style="background: rgba(0, 0, 0, 0.5);">What is ColBERT and Late Interaction and Why They Matter in Search?</div></div></div><div data-v-5839678b="" class="row justify-center q-mt-lg q-pt-lg"><div data-v-5839678b="" class="box col-10 col-md-6"><i data-v-5839678b="" class="fas fa-quote-left fa2"></i><div data-v-5839678b="" class="text"><i data-v-5839678b="" class="fas fa-quote-right fa1"></i><div data-v-5839678b=""><p data-v-5839678b="">Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search.</p></div></div></div></div><div data-v-5839678b="" class="row justify-center items-center q-mt-lg"><div data-v-5839678b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" data-v-5839678b="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div data-v-5839678b="" class="q-item__section column q-item__section--main justify-center text-grey-6"><div data-v-5839678b="" class="q-item__label">Han Xiao</div><div data-v-5839678b="" class="q-item__label q-item__label--caption text-caption text-grey-6 q-mt-sm">February 20, 2024 • 15 minutes read</div></div></div></div><article data-v-5839678b="" class="article"><section data-v-5839678b="" class="gh-content"><p>Last Friday, the release of the <a href="https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io">ColBERT model by Jina AI on Hugging Face</a> sparked significant excitement across the AI community, particularly on Twitter/X. While many are familiar with the groundbreaking BERT model, the buzz around ColBERT has left some wondering: What makes ColBERT stand out in the crowded field of information retrieval technologies? Why the AI community is excited about 8192-length ColBERT? This article delves into the intricacies of ColBERT and ColBERTv2, highlighting their design, improvements, and the surprising effectiveness of ColBERT's late interaction.</p><figure class="kg-card kg-embed-card"><div class="twitter-tweet twitter-tweet-rendered" style="display: flex; max-width: 550px; width: 100%; margin-top: 10px; margin-bottom: 10px;"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="" style="position: static; visibility: visible; width: 550px; height: 671px; display: block; flex-grow: 1;" title="X Post" src="https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-0&amp;features=eyJ0ZndfdGltZWxpbmVfbGlzdCI6eyJidWNrZXQiOltdLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2ZvbGxvd2VyX2NvdW50X3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9iYWNrZW5kIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19yZWZzcmNfc2Vzc2lvbiI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfZm9zbnJfc29mdF9pbnRlcnZlbnRpb25zX2VuYWJsZWQiOnsiYnVja2V0Ijoib24iLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X21peGVkX21lZGlhXzE1ODk3Ijp7ImJ1Y2tldCI6InRyZWF0bWVudCIsInZlcnNpb24iOm51bGx9LCJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3Nob3dfYmlyZHdhdGNoX3Bpdm90c19lbmFibGVkIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19kdXBsaWNhdGVfc2NyaWJlc190b19zZXR0aW5ncyI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfdXNlX3Byb2ZpbGVfaW1hZ2Vfc2hhcGVfZW5hYmxlZCI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfdmlkZW9faGxzX2R5bmFtaWNfbWFuaWZlc3RzXzE1MDgyIjp7ImJ1Y2tldCI6InRydWVfYml0cmF0ZSIsInZlcnNpb24iOm51bGx9LCJ0ZndfbGVnYWN5X3RpbWVsaW5lX3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9mcm9udGVuZCI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9fQ%3D%3D&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=1758503072999907825&amp;lang=en&amp;origin=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F&amp;sessionId=77ad232c78430be1f8195587db3b5a8d3c14c166&amp;theme=light&amp;widgetsVersion=2615f7e52b7e0%3A1702314776716&amp;width=550px" data-tweet-id="1758503072999907825"></iframe></div>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><h2 id="what-is-colbert">What is ColBERT?</h2><p>The name "ColBERT" stands for <strong>Co</strong>ntextualized <strong>L</strong>ate Interaction over <strong>BERT</strong>, a model stems from the Stanford University, that leverages the deep language understanding of BERT while introducing a novel interaction mechanism. This mechanism, known as <strong>late interaction</strong>, allows for efficient and precise retrieval by processing queries and documents separately until the final stages of the retrieval process. Specifically, there are two versions of the model:</p><ul><li><strong>ColBERT</strong>: The initial model was the brainchild of <a href="https://x.com/lateinteraction?s=20&amp;ref=jina-ai-gmbh.ghost.io"><strong>Omar Khattab</strong></a><strong> and Matei Zaharia</strong>, presenting a novel approach to information retrieval through the "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT" paper. Their work was published in SIGIR 2020.</li></ul><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2004.12832?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT</div><div class="kg-bookmark-description">Recent progress in Natural Language Understanding (NLU) is driving fast-paced advances in Information Retrieval (IR), largely owed to fine-tuning deep language models (LMs) for document ranking. While remarkably effective, the ranking models based on these LMs increase computational cost by orders of magnitude over prior approaches, particularly as they must feed each query-document pair through a massive neural network to compute a single relevance score. To tackle this, we present ColBERT, a novel ranking model that adapts deep LMs (in particular, BERT) for efficient retrieval. ColBERT introduces a late interaction architecture that independently encodes the query and the document using BERT and then employs a cheap yet powerful interaction step that models their fine-grained similarity. By delaying and yet retaining this fine-granular interaction, ColBERT can leverage the expressiveness of deep LMs while simultaneously gaining the ability to pre-compute document representations offline, considerably speeding up query processing. Beyond reducing the cost of re-ranking the documents retrieved by a traditional model, ColBERT’s pruning-friendly interaction mechanism enables leveraging vector-similarity indexes for end-to-end retrieval directly from a large document collection. We extensively evaluate ColBERT using two recent passage search datasets. Results show that ColBERT’s effectiveness is competitive with existing BERT-based models (and outperforms every non-BERT baseline), while executing two orders-of-magnitude faster and requiring four orders-of-magnitude fewer FLOPs per query.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Omar Khattab</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a><figcaption><p dir="ltr"><span style="white-space: pre-wrap;">The original ColBERT paper that introduces the "late interaction".</span></p></figcaption></figure><ul><li><strong>ColBERTv2</strong>: Building on the foundational work, <strong>Omar Khattab</strong> continued his research, collaborating with <strong>Barlas Oguz, Matei Zaharia, and Michael S. Bernstein</strong> to introduce "ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction," presented at SIGIR 2021. This next iteration of ColBERT addressed previous limitations and introduced key improvements, such as <strong>denoised supervision</strong> and <strong>residual compression</strong>, enhancing both the model's retrieval effectiveness and its storage efficiency.</li></ul><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2112.01488?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction</div><div class="kg-bookmark-description">Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce ColBERTv2, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate ColBERTv2 across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 6--10<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6667em; vertical-align: -0.0833em;"></span><span class="mord">×</span></span></span></span></span>.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Keshav Santhanam</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a><figcaption><p dir="ltr"><span style="white-space: pre-wrap;">ColBERTv2 adding </span><b><strong style="white-space: pre-wrap;">denoised supervision</strong></b><span style="white-space: pre-wrap;"> and </span><b><strong style="white-space: pre-wrap;">residual compression</strong></b><span style="white-space: pre-wrap;"> to improve the training data's quality and reduce the space footprint.</span></p></figcaption></figure><h2 id="understand-colberts-design">Understand ColBERT's Design</h2><p>Given that ColBERTv2's architecture remains very similar to that of the original ColBERT, with its key innovations revolving around training techniques and compression mechanisms, we will first delve into the foundational aspects of the original ColBERT.</p><h3 id="what-is-late-interaction-in-colbert">What is late interaction in ColBERT?</h3><p>"Interaction" refers to the process of evaluating the relevance between a query and a document by comparing their representations.</p><p>"<em>Late interaction</em>" is the essence of ColBERT. The term is derived from the model's architecture and processing strategy, where the interaction between the query and document representations occurs late in the process, after both have been independently encoded. This contrasts with "<em>early interaction</em>" models, where query and document embeddings interact at earlier stages, typically before or during their encoding by the model. </p>

<table>
<thead>
<tr>
<th>Interaction Type</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Early Interaction</td>
<td>BERT, ANCE, DPR, Sentence-BERT, DRMM, KNRM, Conv-KNRM, etc.</td>
</tr>
<tr>
<td>Late Interaction</td>
<td>ColBERT, ColBERTv2</td>
</tr>
</tbody>
</table>

<p>Early interaction can increase computational complexity since it requires considering all possible query-document pairs, making it less efficient for large-scale applications. </p><p>Late interaction models like ColBERT optimize for efficiency and scalability by allowing for the pre-computation of document representations and employing a more lightweight interaction step at the end, which focuses on the already encoded representations. This design choice enables faster retrieval times and reduced computational demands, making it more suitable for processing large document collections.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/colbert-blog-interaction.svg" class="kg-image" alt="" width="300" height="143" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Schematic diagrams illustrating query–document interaction paradigms in neural IR, with ColBERT's late interaction on the left-most.</span></figcaption></figure><h3 id="no-interaction-cosine-similarity-of-document-and-query-embeddings">No interaction: cosine similarity of document and query embeddings</h3><p>Many practical vector databases and neural search solutions depend on fast cosine similarity matching between document and query embeddings. While appealing for its straightforwardness and computational efficiency, this method, often referred to as "<em>no interaction</em>" or "<em>not interaction-based</em>" has been found to underperform in comparison to models that incorporate some form of interaction between queries and documents.</p><p>The core limitation of the "no interaction" approach lies in its inability to capture the complex nuances and relationships between query and document terms. Information retrieval, at its heart, is about understanding and matching the intent behind a query with the content within a document. This process often requires a deep, contextual understanding of the terms involved, something that single, aggregated embeddings for documents and queries struggle to provide.</p><h3 id="query-and-document-encoders-in-colbert">Query and document encoders in ColBERT</h3><p>ColBERT's encoding strategy is grounded in the BERT model, known for its deep contextual understanding of language. The model generates dense vector representations for each token in a query or document, <strong>creating a bag of contextualized embeddings for a query and a bag for a document, respectively. </strong>This facilitates a nuanced comparison of their embeddings during the late interaction phase.</p><h4 id="query-encoder-of-colbert"><strong>Query encoder of ColBERT</strong></h4><p>For a query (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>) with tokens (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>q</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">{q_1, q_2, ..., q_l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>), the process begins by tokenizing (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>) into BERT-based WordPiece tokens and prepending a special <code>[Q]</code> token. This <code>[Q]</code> token, positioned right after BERT’s <code>[CLS]</code> token, signals the start of a query. </p><p>If the query is shorter than a predefined number of tokens (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>), it is padded with <code>[mask]</code> tokens up to (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>); otherwise, it's truncated to the first (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>) tokens. The padded sequence is then passed through BERT, followed by a CNN (Convolutional Neural Network) and normalization. The output is a set of embedding vectors termed as <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9722em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> below:<br><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>q</mi></msub><mo>:</mo><mo>=</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">z</mi><mi mathvariant="normal">e</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">N</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo fence="true">(</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">Q</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>q</mi><mi>l</mi></msub><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_q := \mathrm{Normalize}\left(\mathrm{CNN}\left(\mathrm{BERT}\left(\mathtt{[Q]},q_0,q_1,\ldots,q_l\mathtt{[mask]},\mathtt{[mask]},\ldots,\mathtt{[mask]}\right)\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9722em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">Normalize</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">CNN</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">BERT</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">Q</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span></p><h4 id="document-encoder-of-colbert">Document encoder of <strong>ColBERT</strong></h4><p>Similarly, for a document (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span></span></span></span></span>) with tokens (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>d</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{d_1, d_2, ..., d_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>), a <code>[D]</code> token is prepended to indicate the start of a document. This sequence, without the need for padding, undergoes the same process, results in a set of embedding vectors termed as <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8361em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> below:<br><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>d</mi></msub><mo>:</mo><mo>=</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">z</mi><mi mathvariant="normal">e</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">N</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo fence="true">(</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">D</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><msub><mi>d</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>d</mi><mi>n</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_d := \mathrm{Filter}\left(\mathrm{Normalize}\left(\mathrm{CNN}\left(\mathrm{BERT}\left(\mathtt{[D]},d_0,d_1,...,d_n\right)\right)\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8361em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">Filter</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">Normalize</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">CNN</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">BERT</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">D</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span></p><p>The use of <code>[mask]</code> tokens for padding queries (coined as <strong>query augmentation </strong>in the paper) ensures uniform length across all queries, facilitating batch processing. The <code>[Q]</code> and <code>[D]</code> tokens explicitly mark the start of queries and documents, respectively, aiding the model in distinguishing between the two types of inputs.</p><h4 id="comparing-colbert-to-cross-encoders">Comparing <strong>ColBERT</strong> to cross-encoders</h4><p>Cross-encoders process pairs of queries and documents together, making them highly accurate but less efficient for large-scale tasks due to the computational cost of evaluating every possible pair. They excel in specific scenarios where the precise scoring of sentence pairs is necessary, such as in semantic similarity tasks or detailed content comparison. However, this design limits their applicability in situations requiring rapid retrieval from large datasets, where pre-computed embeddings and efficient similarity calculations are paramount.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/ce-vs-colbert.svg" class="kg-image" alt="" width="210" height="150" style="cursor: help;"></figure><p>In contrast, ColBERT’s late interaction model allows for pre-computation of document embeddings, significantly speeding up the retrieval process without compromising the depth of semantic analysis. This method, though seemingly counter-intuitive when compared to the direct approach of cross-encoders, offers a scalable solution for real-time and large-scale information retrieval tasks. It represents a strategic compromise between computational efficiency and the quality of interaction modeling.</p><h3 id="finding-the-top-k-documents-using-colbert">Finding the top-K documents using <strong>ColBERT</strong></h3><p>Once we have embeddings for the query and documents, finding the most relevant top-K documents becomes straightforward (but not as straightforward as computing cosine of two vectors). </p><p>The key operations include a batch dot-product to compute term-wise similarities, max-pooling across document terms to find the highest similarity per query term, and summation across query terms to derive the total document score, followed by sorting the documents based on these scores. The pseudo PyTorch code is described below:</p><pre><code class="language-python hljs"><span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_relevance_scores</span>(<span class="hljs-params">query_embeddings, document_embeddings, k</span>):
    <span class="hljs-string">"""
    Compute relevance scores for top-k documents given a query.
    
    :param query_embeddings: Tensor representing the query embeddings, shape: [num_query_terms, embedding_dim]
    :param document_embeddings: Tensor representing embeddings for k documents, shape: [k, max_doc_length, embedding_dim]
    :param k: Number of top documents to re-rank
    :return: Sorted document indices based on their relevance scores
    """</span>
    
    <span class="hljs-comment"># Ensure document_embeddings is a 3D tensor: [k, max_doc_length, embedding_dim]</span>
    <span class="hljs-comment"># Pad the k documents to their maximum length for batch operations</span>
    <span class="hljs-comment"># Note: Assuming document_embeddings is already padded and moved to GPU</span>
    
    <span class="hljs-comment"># Compute batch dot-product of Eq (query embeddings) and D (document embeddings)</span>
    <span class="hljs-comment"># Resulting shape: [k, num_query_terms, max_doc_length]</span>
    scores = torch.matmul(query_embeddings.unsqueeze(<span class="hljs-number">0</span>), document_embeddings.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
    
    <span class="hljs-comment"># Apply max-pooling across document terms (dim=2) to find the max similarity per query term</span>
    <span class="hljs-comment"># Shape after max-pool: [k, num_query_terms]</span>
    max_scores_per_query_term = scores.<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">2</span>).values
    
    <span class="hljs-comment"># Sum the scores across query terms to get the total score for each document</span>
    <span class="hljs-comment"># Shape after sum: [k]</span>
    total_scores = max_scores_per_query_term.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>)
    
    <span class="hljs-comment"># Sort the documents based on their total scores</span>
    sorted_indices = total_scores.argsort(descending=<span class="hljs-literal">True</span>)
    
    <span class="hljs-keyword">return</span> sorted_indices
</code></pre><p>Note that this procedure is used in both training and re-ranking at inference time. The ColBERT model is trained using a pairwise ranking loss, where the training data consists of triples (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(q, d^+, d^-)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.0213em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>), where (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span>) represents a query, (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">d^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span>) is a relevant (positive) document for the query, and (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">d^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span>) is a non-relevant (negative) document. The model aims to learn representations such that the similarity score between (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span>) and (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">d^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span>) is higher than the score between (q) and (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">d^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span>).</p><p>The training objective can be mathematically represented as minimizing the following loss function: <span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{Loss} = \max(0, 1 - S(q, d^+) + S(q, d^-))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord"><span class="mord mathrm">Loss</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0713em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8213em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0713em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8213em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span></span></p><p>, where (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(q, d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></span>) denotes the similarity score computed by ColBERT between a query (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span>) and a document (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span>). This score is obtained by aggregating the max-similarity scores of the best-matching embeddings between the query and the document, following the late interaction pattern described in the model architecture. This approach ensures that the model is trained to distinguish between relevant and irrelevant documents for a given query, by encouraging a larger margin in the similarity scores for positive and negative document pairs.</p><h3 id="denoised-supervision-in-colbertv2">Denoised supervision in ColBERTv2</h3><p>Denoised supervision in ColBERTv2 refines the original training process by selecting challenging negatives and leveraging a cross-encoder for distillation. This sophisticated method of augmenting training data quality involves several steps:</p><ol><li><strong>Initial Training</strong>: Utilizing the official triples from the MS MARCO dataset, comprising a query, a relevant document, and a non-relevant document.</li><li><strong>Indexing and Retrieval</strong>: Employing ColBERTv2's compression to index training passages, followed by retrieving top-k passages for each query.</li><li><strong>Cross-Encoder Reranking</strong>: Enhancing passage selection through reranking by a MiniLM cross-encoder, distilling its scores into ColBERTv2.</li><li><strong>Forming Training Tuples</strong>: Generating w-way tuples for training, incorporating both high and lower-ranked passages to create challenging examples.</li><li><strong>Iterative Refinement</strong>: Repeating the process to continually improve the selection of hard negatives, thereby enhancing model performance.</li></ol><p>Note, this process represents a sophisticated enhancement to the ColBERT training regime rather than a fundamental change to its architecture.</p><h3 id="hyperparameters-of-colbert">Hyperparameters of ColBERT</h3><p>The hyperparameters of ColBERT is summarized below:</p>

<table>
<thead>
<tr>
<th>Hyperparameter</th>
<th>Best Choice</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Learning Rate</td>
<td>(3 x 10^{-6})</td>
<td>Selected for fine-tuning to ensure stable and effective model updates.</td>
</tr>
<tr>
<td>Batch Size</td>
<td>32</td>
<td>Balances computational efficiency and the ability to capture sufficient information per update.</td>
</tr>
<tr>
<td>Number of Embeddings per Query (Nq)</td>
<td>32</td>
<td>Fixed to ensure a consistent representation size across queries, aiding in efficient processing.</td>
</tr>
<tr>
<td>Embedding Dimension (m)</td>
<td>128</td>
<td>Demonstrated to provide a good balance between representational power and computational efficiency.</td>
</tr>
<tr>
<td>Training Iterations</td>
<td>200k (MS MARCO), 125k (TREC CAR)</td>
<td>Chosen to ensure thorough learning while avoiding overfitting, with adjustments based on dataset characteristics.</td>
</tr>
<tr>
<td>Bytes per Dimension in Embeddings</td>
<td>4 (re-ranking), 2 (end-to-end ranking)</td>
<td>Trade-off between precision and space efficiency, with consideration for the application context (re-ranking vs. end-to-end).</td>
</tr>
<tr>
<td>Vector-Similarity Function</td>
<td>Cosine (re-ranking), (Squared) L2 (end-to-end)</td>
<td>Selected based on performance and efficiency in the respective retrieval contexts.</td>
</tr>
<tr>
<td>FAISS Index Partitions (P)</td>
<td>2000</td>
<td>Determines the granularity of the search space partitioning, impacting search efficiency.</td>
</tr>
<tr>
<td>Nearest Partitions Searched (p)</td>
<td>10</td>
<td>Balances the breadth of the search against computational efficiency.</td>
</tr>
<tr>
<td>Sub-vectors per Embedding (s)</td>
<td>16</td>
<td>Affects the granularity of quantization, influencing both search speed and memory usage.</td>
</tr>
<tr>
<td>Index Representation per Dimension</td>
<td>16-bit values</td>
<td>Chosen for the second stage of end-to-end retrieval to manage the trade-off between accuracy and space.</td>
</tr>
<tr>
<td>Number of Layers in Encoders</td>
<td>12-layer BERT</td>
<td>Optimal balance between depth of contextual understanding and computational efficiency.</td>
</tr>
  <tr>
  <td>Max Query Length</td>
<td>128</td>
<td>The maximum number of tokens processed by the query encoder. <b>This gets extended in Jina-ColBERT model.</b></td>
</tr>
    <tr>
  <td>Max Document Length</td>
<td>512</td>
<td>The maximum number of tokens processed by the document encoder. <b>This gets extended to 8192 in Jina-ColBERT model. </b></td>
</tr>
</tbody>
</table>

<h3 id="the-indexing-strategy-of-colbert">The indexing strategy of ColBERT</h3><p>Unlike representation-based approaches that encode each document into one embedding vector, <strong>ColBERT encodes documents (and queries) into bags of embeddings, with each token in a document having its own embedding.</strong> This approach inherently means that for longer documents, more embeddings will be stored, <strong>which is a pain point of  the original ColBERT, and later addressed by ColBERTv2.</strong></p><p>The key to managing this efficiently lies in ColBERT's use of vector database (e.g. <a href="https://github.com/facebookresearch/faiss?ref=jina-ai-gmbh.ghost.io">FAISS</a>) for indexing and retrieval, and its detailed indexing process which is designed to handle large volumes of data efficiently. The original ColBERT paper mentions several strategies to enhance the efficiency of indexing and retrieval, including:</p><ul><li><strong>Offline Indexing</strong>: Document representations are computed offline, allowing for the pre-computation and storage of document embeddings. This process leverages batch processing and GPU acceleration to handle large document collections efficiently.</li><li><strong>Embedding Storage</strong>: Document embeddings can be stored using 32-bit or 16-bit values for each dimension, offering a trade-off between precision and storage requirements. This flexibility allows ColBERT to maintain a balance between effectiveness (in terms of retrieval performance) and efficiency (in terms of storage and computational costs).</li></ul><p>The introduction of <strong>residual compression</strong> in ColBERTv2, which is a novel approach not present in the original ColBERT, plays a key role in reducing the model's space footprint by 6–10× while preserving quality. This technique compresses the embeddings further by effectively capturing and storing only the differences from a set of fixed reference centroids. </p><h2 id="effectiveness-and-efficiency-of-colbert">Effectiveness and Efficiency of ColBERT</h2><p>One might initially assume that incorporating BERT's deep contextual understanding into search would inherently require significant computational resources, making such an approach less feasible for real-time applications due to high latency and computational costs. However, ColBERT challenges and overturns this assumption through its innovative use of the late interaction mechanism. Here are some noteworthy points:</p><ol><li><strong>Significant Efficiency Gains</strong>: ColBERT achieves an orders-of-magnitude reduction in computational costs (FLOPs) and latency compared to traditional BERT-based ranking models. Specifically, for a given model size (e.g., 12-layer "base" transformer encoder), ColBERT not only matches but in some cases exceeds the effectiveness of BERT-based models with dramatically lower computational demands. For instance, at a re-ranking depth of <em>k</em>=10, BERT requires nearly 180× more FLOPs than ColBERT; this gap widens as <em>k</em> increases, reaching 13900× at <em>k</em>=1000 and even 23000× at <em>k</em>=2000​​.</li><li><strong>Improved Recall and MRR@10 in End-to-End Retrieval</strong>: Contrary to the initial intuition that deeper interaction between query and document representations (as seen in early interaction models) would be necessary for high retrieval performance, ColBERT's end-to-end retrieval setup demonstrates superior effectiveness. For example, its Recall@50 exceeds the official BM25's Recall@1000 and almost all other models' Recall@200, underscoring the model's remarkable ability to retrieve relevant documents from a vast collection without direct comparison of each query-document pair​​.</li><li><strong>Practicality for Real-World Applications</strong>: The experimental results underline ColBERT's practical applicability for real-world scenarios. Its indexing throughput and memory efficiency make it suitable for indexing large document collections like MS MARCO within a few hours, retaining high effectiveness with a manageable space footprint. These qualities highlight ColBERT's suitability for deployment in production environments where both performance and computational efficiency are paramount​​.</li><li><strong>Scalability with Document Collection Size</strong>: Perhaps the most surprising conclusion is ColBERT's scalability and efficiency in handling large-scale document collections. The architecture allows for the pre-computation of document embeddings and leverages efficient batch processing for query-document interaction, enabling the system to scale effectively with the size of the document collection. This scalability is counter-intuitive when considering the complexity and depth of understanding required for effective document retrieval, showcasing ColBERT's innovative approach to balancing computational efficiency with retrieval effectiveness.</li></ol><h2 id="using-jina-colbert-v1-en">Using <code>jina-colbert-v1-en</code></h2><p>Jina-ColBERT is designed for both fast and accurate retrieval, supporting <a href="https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/?ref=jina-ai-gmbh.ghost.io">longer context lengths up to 8192, leveraging the advancements of JinaBERT</a>, which allows for longer sequence processing due to its architecture enhancements.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-colbert-v1-en · Hugging Face</div><div class="kg-bookmark-description">We’re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-colbert-v1-en.png" alt="" style="cursor: help;"></div></a></figure><h3 id="jinas-improvement-over-original-colbert">Jina's improvement over original ColBERT</h3><p>Jina-ColBERT's main advancement is its backbone, <code>jina-bert-v2-base-en</code>, which enables processing of significantly longer contexts (up to 8192 tokens) compared to the original ColBERT that uses <code>bert-base-uncased</code>. This capability is crucial for handling documents with extensive content, providing more detailed and contextual search results.</p><h3 id="jina-colbert-v1-en-performance-comparison-vs-colbertv2"><code>jina-colbert-v1-en</code> performance comparison vs. ColBERTv2</h3>

<table>
<thead>
<tr>
<th>Metric</th>
<th>ColBERTv2</th>
<th>Jina-ColBERT-v1</th>
</tr>
</thead>
<tbody>
<tr>
<td>MRR@10</td>
<td>39.7</td>
<td>39.0</td>
</tr>
<tr>
<td>Recall@50</td>
<td>86.8</td>
<td>85.6</td>
</tr>
<tr>
<td>Recall@1k</td>
<td>97.6</td>
<td>96.2</td>
</tr>
<tr>
<td>Avg. NDCG@10 (LoCo)</td>
<td>74.3</td>
<td>83.7</td>
</tr>
</tbody>
</table>

<p>This table demonstrates <code>jina-colbert-v1-en</code>'s competitive or superior performance, especially in scenarios requiring longer context lengths.</p><h3 id="example-code-snippet">Example code snippet</h3><p>This snippet outlines the indexing process with Jina-ColBERT, showcasing its support for long documents.</p><pre><code class="language-python hljs"><span class="hljs-keyword">from</span> colbert <span class="hljs-keyword">import</span> Indexer
<span class="hljs-keyword">from</span> colbert.infra <span class="hljs-keyword">import</span> Run, RunConfig, ColBERTConfig

n_gpu: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>  <span class="hljs-comment"># Set your number of available GPUs</span>
experiment: <span class="hljs-built_in">str</span> = <span class="hljs-string">""</span>  <span class="hljs-comment"># Name of the folder where the logs and created indices will be stored</span>
index_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">""</span>  <span class="hljs-comment"># The name of your index, i.e. the name of your vector database</span>

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-keyword">with</span> Run().context(RunConfig(nranks=n_gpu, experiment=experiment)):
        config = ColBERTConfig(
          doc_maxlen=<span class="hljs-number">8192</span>  <span class="hljs-comment"># Our model supports 8k context length for indexing long documents</span>
        )
        indexer = Indexer(
          checkpoint=<span class="hljs-string">"jinaai/jina-colbert-v1-en"</span>,
          config=config,
        )
        documents = [
          <span class="hljs-string">"ColBERT is an efficient and effective passage retrieval model."</span>,
          <span class="hljs-string">"Jina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length."</span>,
          <span class="hljs-string">"JinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length."</span>,
          <span class="hljs-string">"Jina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2."</span>,
          <span class="hljs-string">"Jina-ColBERT achieves the competitive retrieval performance with ColBERTv2."</span>,
          <span class="hljs-string">"Jina is an easier way to build neural search systems."</span>,
          <span class="hljs-string">"You can use Jina-ColBERT to build neural search systems with ease."</span>,
          <span class="hljs-comment"># Add more documents here to ensure the clustering work correctly</span>
        ]
        indexer.index(name=index_name, collection=documents)
</code></pre><h3 id="using-jina-colbert-v1-en-in-ragatouille">Using <code>jina-colbert-v1-en</code> in RAGatouille</h3><p>RAGatouille is a new Python library that facilitates the use of advanced retrieval methods within RAG pipelines. It's designed for modularity and easy integration, allowing users to leverage state-of-the-art research seamlessly. The main goal of RAGatouille is to simplify the application of complex models like ColBERT in RAG pipelines, making it accessible for developers to utilize these methods without needing deep expertise in the underlying research. Thanks to <a href="https://twitter.com/bclavie?ref=jina-ai-gmbh.ghost.io">Benjamin Clavié</a>, you can now use <code>jina-colbert-v1-en</code> easily:</p><pre><code class="language-python hljs"><span class="hljs-keyword">from</span> ragatouille <span class="hljs-keyword">import</span> RAGPretrainedModel

<span class="hljs-comment"># Get your model &amp; collection of big documents ready</span>
RAG = RAGPretrainedModel.from_pretrained(<span class="hljs-string">"jinaai/jina-colbert-v1-en"</span>)
my_documents = [
    <span class="hljs-string">"very long document1"</span>,
    <span class="hljs-string">"very long document2"</span>,
    <span class="hljs-comment"># ... more documents</span>
]

<span class="hljs-comment"># And create an index with them at full length!</span>
RAG.index(collection=my_documents,
          index_name=<span class="hljs-string">"the_biggest_index"</span>,
          max_document_length=<span class="hljs-number">8190</span>,)

<span class="hljs-comment"># or encode them in-memory with no truncation, up to your model's max length</span>
RAG.encode(my_documents)
</code></pre><p>For more detailed information and further exploration of Jina-ColBERT, you can visit the <a href="https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io">Hugging Face page</a>.</p><h2 id="conclusion">Conclusion</h2><p>ColBERT represents a significant leap forward in the field of information retrieval. By enabling longer context lengths with Jina-ColBERT and maintaining compatibility with the ColBERT approach to late interaction, it offers a powerful alternative for developers looking to implement state-of-the-art search functionality.</p><p>Coupled with the RAGatouille library, which simplifies the integration of complex retrieval models into RAG pipelines, developers can now harness the power of advanced retrieval with ease, streamlining their workflows and enhancing their applications. The synergy between Jina-ColBERT and RAGatouille illustrates a remarkable stride in making advanced AI search models accessible and efficient for practical use.</p></section></article><hr data-v-5839678b="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-5839678b="" class="row justify-between items-center q-py-md"><div data-v-5839678b=""><span data-v-5839678b="" class="text-weight-bold">Categories:</span><span data-v-5839678b="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-icons q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Featured</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></span></div><div data-v-5839678b=""><div data-v-5839678b="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-5839678b="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-5839678b="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-5839678b="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-5839678b="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-5839678b="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-5839678b="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-5839678b="" class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div data-v-5839678b="" class="text-h6 text-grey-2 text-weight-bold q-mt-lg">Learn more</div><a data-v-5839678b="" class="q-card q-card--dark q-dark q-card--flat no-shadow block cursor-pointer q-hoverable non-selectable q-my-md" href="/news/scenexplain-alt-text-and-better-seo-for-your-ghost-blog-with-just-one-command" style="overflow: hidden; text-decoration: none !important;"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">SceneXplain: Alt Text and Better SEO for Your Ghost Blog With One Command</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">Supercharge your Ghost blog's SEO and accessibility by automatically generating alt texts. All it takes is one command. WordPress/WooCommerce support coming soon!</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Alex C-G</div><div class="q-item__label q-item__label--caption text-caption">February 06, 2024 • 6 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img" aria-label="Futuristic transparent cube with a central chip and copper accents on a dark background, symbolizing cutting-edge technology." style="cursor: help;"><div style="padding-bottom: 56.05%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Frame-378.png" style="object-fit: cover; object-position: 50% 50%;" alt="Futuristic transparent cube with a central chip and copper accents on a dark background, symbolizing cutting-edge technology."></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a><a data-v-5839678b="" class="q-card q-card--dark q-dark q-card--flat no-shadow block cursor-pointer q-hoverable non-selectable q-my-md" href="/news/a-deep-dive-into-tokenization" style="overflow: hidden; text-decoration: none !important;"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">A Deep Dive into Tokenization</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">Tokenization, in LLMs, means chopping input texts up into smaller parts for processing. So why are embeddings billed by the token?</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Scott Martens</div><div class="q-item__label q-item__label--caption text-caption">January 31, 2024 • 17 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img" aria-label="Colorful speckled grid pattern with a mix of small multicolored dots on a black background, creating a mosaic effect." style="cursor: help;"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled-design--25-.png" style="object-fit: cover; object-position: 50% 50%;" alt="Colorful speckled grid pattern with a mix of small multicolored dots on a black background, creating a mosaic effect."></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a><a data-v-5839678b="" class="q-card q-card--dark q-dark q-card--flat no-shadow block cursor-pointer q-hoverable non-selectable q-my-md" href="/news/myscale-jina-ai-unleashing-great-potential-for-your-ai-applications" style="overflow: hidden; text-decoration: none !important;"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">MyScale &amp; Jina AI: Unleashing Great Potential for Your AI Applications</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">With full integration of Jina Embeddings v2 models, MyScale allows users to harness the capabilities of Jina AI within an SQL database.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Scott Martens</div><div class="q-item__label q-item__label--caption text-caption">January 29, 2024 • 1 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img" aria-label="Contrastive black and white design with the text &quot;EMBEDDINGS 2 MYSCALE&quot; centered, creating an artistic academic vibe." style="cursor: help;"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/01/MyScaleBlog.png" style="object-fit: cover; object-position: 50% 50%;" alt="Contrastive black and white design with the text &quot;EMBEDDINGS 2 MYSCALE&quot; centered, creating an artistic academic vibe."></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></a></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow overflow-hidden print-hide"><video autoplay="" loop="" playsinline="" class="non-selectable" poster="/assets/portal-2-poster.44997122.webp" style="width: 100%; height: 420px; object-fit: cover;"><source src="/assets/portal-2.0da13c26.mp4" type="video/mp4"></video><div class="q-card q-card--dark q-dark q-card--flat no-shadow row absolute-left items-center bg-transparent non-selectable fit"><div class="text-white bg-transparent lock-blur fit q-pa-sm"><div class="row justify-between q-gutter-lg"><div class="col-12 col-md-3"><div class="q-list q-list--dark"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><strong>Offices</strong></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption">Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany</div><div class="q-item__label q-item__label--caption text-caption">Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption">Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption">402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div></div><div class="row text-caption justify-center q-mt-xl"> © Jina AI GmbH 2020-2024. All rights reserved.</div></div></div></div><footer class="q-footer q-layout__section--marginal fixed-bottom lock-blur bg-transparent print-hide"><div class="row"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline col-12 col-md-6 justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-discord" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://twitter.com/jinaAI_/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.youtube.com/c/JinaAI" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-youtube" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.meetup.com/jina-community-meetup/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-meetup" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">email</i></span></a></div><div class="row col-12 col-md-6 items-center text-caption justify-center"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--stretch inline" no-caps=""><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="/legal/#privacy-policy" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy Policy</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="/legal/#terms-and-conditions" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Terms and Conditions</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="javascript:UC_UI.showSecondLayer();" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy Settings</span></span></a></div></div></div></footer></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div><script src="https://platform.twitter.com/widgets.js"></script><iframe scrolling="no" frameborder="0" allowtransparency="true" src="https://platform.twitter.com/widgets/widget_iframe.2f70fb173b9000da126c79afe2098f02.html?origin=http%3A%2F%2F127.0.0.1%3A3000" title="Twitter settings iframe" style="display: none;"></iframe><iframe id="rufous-sandbox" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;" title="Twitter analytics iframe"></iframe></body></html>