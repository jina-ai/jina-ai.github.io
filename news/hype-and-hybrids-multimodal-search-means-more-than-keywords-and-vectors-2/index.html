<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>Hype and Hybrids: Search is more than Keywords and Vectors</title><meta charset="utf-8"><meta name="title" content="Hype and Hybrids: Search is more than Keywords and Vectors"><meta name="description" content="Twenty years ago, “hybrid” was a term used only by botanists and chemists. Today, hybrid is booming… even in search. Many search systems are rolling out hybrid search schemes with the latest AI. But is &quot;hybrid search&quot; really more than a buzzword?"><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/hype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2"><meta property="og:title" content="Hype and Hybrids: Search is more than Keywords and Vectors"><meta property="og:description" content="Twenty years ago, “hybrid” was a term used only by botanists and chemists. Today, hybrid is booming… even in search. Many search systems are rolling out hybrid search schemes with the latest AI. But is &quot;hybrid search&quot; really more than a buzzword?"><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Jina-AI-Website-Banners-Templates--21-.png"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/hype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2"><meta property="twitter:title" content="Hype and Hybrids: Search is more than Keywords and Vectors"><meta property="twitter:description" content="Twenty years ago, “hybrid” was a term used only by botanists and chemists. Today, hybrid is booming… even in search. Many search systems are rolling out hybrid search schemes with the latest AI. But is &quot;hybrid search&quot; really more than a buzzword?"><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Jina-AI-Website-Banners-Templates--21-.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><link rel="canonical" href="https://jina.ai/">  <script type="module" crossorigin="" src="/assets/index.6911db9a.js"></script>
  <link rel="stylesheet" href="/assets/index.c974590d.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n.6f52144f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.727ab945.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register.a7ed8f3b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip.554c160a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine.2f29da01.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard.1881d409.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.6911db9a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout.88cdbb9a.js"><link rel="stylesheet" href="/assets/MainLayout.891b970f.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpace.365d19b1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSelect.3244b5f5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge.9dfe8ff0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu.4ae032fc.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format.afd66c59.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding.a010c897.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList.ae778ee7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown.aa9be465.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver.86f76447.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QImg.7006ba58.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem.21854604.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollArea.d3e9537b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan.0e293bba.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch.3df10340.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResponsive.b04ada29.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup.a46a9f36.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TypingText.2c53436f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QForm.4c0be9ae.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPopupProxy.a1bc22a5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/chunk.17bfede8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isArrayLike.a2a00cef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isObject.cef35763.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/toNumber.476d0739.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage.ce91dffe.js"><link rel="stylesheet" href="/assets/NewsPage.acd1f61a.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/AskAnythingToolTip.d00ff61a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs.e1eee012.js"><link rel="stylesheet" href="/assets/blogs.0a453c04.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/plugin-vue_export-helper.21dcd24c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge.89b03e65.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard.dd0d609b.js"><link prerender-ignore rel=preconnect href=//app.usercentrics.eu><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js></script><script prerender-ignore>// (optional) additional configs for the Smart Data Protector
      uc.reloadOnOptIn('BJz7qNsdj-7'); // reload page on YouTube opt-in</script><style prerender-ignore>.uc-embedding-container {
      min-height: 100% !important;
    }

    .uc-embedding-wrapper p {
      color: black;
    }</style><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top text-white lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none" role="toolbar"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">reorder</i></span></button><hr class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><label class="q-field row no-wrap items-start q-field--filled q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--float q-field--dark" for="f_7c916926-7783-4a4e-919a-f4874d4ec4a6"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>English</span><input class="q-select__focus-target" id="f_7c916926-7783-4a4e-919a-f4874d4ec4a6" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_7c916926-7783-4a4e-919a-f4874d4ec4a6_lb"></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon fas fa-caret-down q-select__dropdown-icon" aria-hidden="true" role="presentation"> </i></div></div></div></label></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-left" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--left q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(-300px);"><div class="q-drawer__content fit scroll"><div class="q-scrollarea q-scrollarea--dark fit"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark q-list--padding"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/embedding.fb4bca87.svg"></i></div></div></div><div class="q-item__section column q-item__section--main justify-center">Embeddings</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">notifications</i></div></div></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_4fb65ac2-3d88-40dd-a37a-38876ab8b81b" aria-label="Expand &quot;For Enterprises&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Enterprises</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_4fb65ac2-3d88-40dd-a37a-38876ab8b81b" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding.fb4bca87.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">Our world-class embeddings for your search and RAG systems</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_2efdf824-2c6c-4799-b317-dc7ac3a2ef29" aria-label="Expand &quot;For Power Users&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Power Users</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_2efdf824-2c6c-4799-b317-dc7ac3a2ef29" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://promptperfect.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://scenex.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://bestbanner.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://chat.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://rationale.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_8e7108ea-1e5a-481b-8aa6-fba4532dae0b" aria-label="Expand &quot;For Developers&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Developers</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_8e7108ea-1e5a-481b-8aa6-fba4532dae0b" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/docarray/docarray"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/doc-array.35372518.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DocArray</div><div class="q-item__label q-item__label--caption text-caption">The data structure for multimodal data</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jina"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/core.99751891.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jina</div><div class="q-item__label q-item__label--caption text-caption">Build multimodal AI applications on the cloud</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/clip-as-service"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/clip-as-service.f454ca2a.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">CLIP-as-service</div><div class="q-item__label q-item__label--caption text-caption">Embed images and sentences into fixed-length vectors with CLIP</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/finetuner"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetuner.c62eaafa.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Finetuner</div><div class="q-item__label q-item__label--caption text-caption">Fine-tune embeddings on domain specific data for better search quality</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jcloud"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jcloud.669910ba.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JCloud</div><div class="q-item__label q-item__label--caption text-caption">Deploy a local project as a cloud service. Radically easy, no nasty surprises.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/langchain-serve"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/langchain-serve.8cf53254.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">LangChain-Serve</div><div class="q-item__label q-item__label--caption text-caption">Langchain apps on production with Jina &amp; FastAPI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/vectordb"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/VectorDB.46be6cc1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">VectorDB</div><div class="q-item__label q-item__label--caption text-caption">A Python vector database you just need - no more, no less</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/dalle-flow"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dall-e-flow.ea199b2d.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DALL-E Flow</div><div class="q-item__label q-item__label--caption text-caption">A human-in-the-Loop workflow for creating HD images from text</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/discoart"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/disco-art.f21a267f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DiscoArt</div><div class="q-item__label q-item__label--caption text-caption">Create compelling Disco Diffusion artworks in one line of code</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/thinkgpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/think-gpt.0a671280.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ThinkGPT</div><div class="q-item__label q-item__label--caption text-caption">Agent techniques to augment your LLM and push it beyond its limits</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/dev-gpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dev-gpt.a3e55036.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DevGPT</div><div class="q-item__label q-item__label--caption text-caption">Your virtual development team</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/rungpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/run-gpt.5571707e.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">RunGPT</div><div class="q-item__label q-item__label--caption text-caption">An open-source cloud-native of large multimodal models serving framework</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jerboa"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jerboa.af6b308b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jerboa</div><div class="q-item__label q-item__label--caption text-caption">An experimental finetuner for open-source LLMs</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_eeb09c24-902c-4b0f-a401-0a40266a1c38" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_eeb09c24-902c-4b0f-a401-0a40266a1c38" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/open-day"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Open day</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px; padding-bottom: 61px;"><main data-v-b24d48de="" class="q-page" style="min-height: 100vh;"><div data-v-b24d48de="" class="row justify-center q-gutter-lg"><div data-v-b24d48de="" class="col q-my-xl q-py-xl"><div data-v-b24d48de="" class="q-mx-md q-mx-md-xl q-px-md-md q-px-lg-lg q-px-xl-xl"><div data-v-b24d48de="" class="row justify-between items-center q-mt-lg"><a data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch col-auto" tabindex="0" href="/news"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">arrow_circle_left</i><span class="block">Back to Newsroom</span></span></a><div data-v-b24d48de="" class="col-auto"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></div></div><div data-v-b24d48de="" class="q-img q-img--menu q-mt-md" role="img" aria-label="Abstract geometric background with bold &quot;Hype Hybrids&quot; text in white and colors against a purple backdrop"><div style="padding-bottom: 50%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract geometric background with bold &quot;Hype Hybrids&quot; text in white and colors against a purple backdrop" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Jina-AI-Website-Banners-Templates--21-.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"><div data-v-b24d48de="" class="text-white absolute-bottom q-pa-lg lock-blur text-h4" style="background: rgba(0, 0, 0, 0.5);">Hype and Hybrids: Search is more than Keywords and Vectors</div></div></div><div data-v-b24d48de="" class="row justify-center q-mt-lg q-pt-lg"><div data-v-b24d48de="" class="box col-10 col-md-6"><i data-v-b24d48de="" class="fas fa-quote-left fa2"></i><div data-v-b24d48de="" class="text"><i data-v-b24d48de="" class="fas fa-quote-right fa1"></i><div data-v-b24d48de=""><p data-v-b24d48de="">Twenty years ago, “hybrid” was a term used only by botanists and chemists. Today, hybrid is booming… even in search. Many search systems are rolling out hybrid search schemes with the latest AI. But is "hybrid search" really more than a buzzword?</p></div></div></div></div><div data-v-b24d48de="" class="row justify-center items-center q-mt-lg"><div data-v-b24d48de="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" data-v-b24d48de="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 55px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 25px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div data-v-b24d48de="" class="q-item__section column q-item__section--main justify-center text-grey-6"><div data-v-b24d48de="" class="q-item__label">Michael Günther, Scott Martens</div><div data-v-b24d48de="" class="q-item__label q-item__label--caption text-caption text-grey-6 q-mt-sm">November 04, 2022 • 15 minutes read</div></div></div></div><article data-v-b24d48de="" class="article"><section data-v-b24d48de="" class="gh-content"><p>Many search systems are rolling out hybrid search functionality that combines conventional keywords, traditional text information retrieval techniques, and some kind of “vector” or “neural” search based on recent advances in artificial intelligence. But is “hybrid search” really more than a buzzword? Text-based search is a very old technology, so old that users have now trained themselves to accept its idiosyncrasies and limitations. Do new AI technologies have a lot to add?</p><p>The unsurprising answer is: It depends.</p><p>Modern data stores are multimedia and multi-modal, with texts, images, video and audio stored together in the same databases and on the same computers. This means that to retrieve a picture of, for example, a screwdriver on the website of a hardware store, you can’t just query for the word “<em>screwdriver</em>” and expect that to match some index entry. You must first store and index a text or some kind of label with each picture. Unless you explicitly associate all the pictures of screwdrivers in your database with the label “<em>screwdriver</em>” or some text that says, one way or another, that it’s a picture of a screwdriver, there is no way of using traditional search techniques to find them.</p><p>Adding the best and newest AI technologies to search for texts and labels won’t help if you don’t have useful labels and texts. It doesn’t matter if it’s an improvement on traditional technologies if it has nothing to work with.</p><p>Let’s say we have a large hardware vendor with online shopping that sells potentially hundreds of thousands of different items. They don't have the staff to craft detailed product labels and descriptions or check their accuracy. They may not have pictures for every item and don’t have the time to take good ones. Even the very best text-only search is a flawed solution for them.</p><p>New AI techniques can address these limitations. Deep learning and <a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io">neural search</a> have made it possible to create powerful general purpose neural network models and to apply them to different kinds of media — texts, images, audio, and video — in a common way, so that, even without text labels, a search for “<em>screwdrivers</em>” finds pictures of screwdrivers!</p><p>But these newer technologies often give results that are hard to explain. Customers might reasonably expect that a query like “<em>Phillips screwdriver</em>” would match a product actually called “<em>Slotted and Phillips Screwdrivers, 4" Long</em>”. Users of traditional search technologies can expect that, but the new AI technologies by their very nature can’t guarantee it.</p><p>No single search model is genuinely adequate for this use-case.</p><p>We’re going to show you how construct a hybrid search system that takes advantage of traditional text matching technologies while retaining and even improving on the value of AI-based search methods. The techniques presented here focus on combining scores to improve results. There will be a follow-up post specifically <a href="https://jina.ai/product/nest/?ref=jina-ai-gmbh.ghost.io">implementing hybrid search using Jina AI inside of Elasticsearch</a>.</p><h2 id="search-models">Search Models</h2><p>We’re going to use three specific search models to build a hybrid search engine: BM25, SBERT and CLIP.</p><p>BM25 is the classic text-based information retrieval algorithm. It is widely used, having first been developed in the 1990s. For more information about BM25, see <a href="http://dx.doi.org/10.1561/1500000019?ref=jina-ai-gmbh.ghost.io">Robertson &amp; Zaragoza (2009)</a>, Spärck Jones et al. (<a href="https://doi.org/10.1016/S0306-4573(00)00015-7?ref=jina-ai-gmbh.ghost.io">2000a</a> and <a href="https://doi.org/10.1016/S0306-4573(00)00016-9?ref=jina-ai-gmbh.ghost.io">2000b</a>), or consult the <a href="https://en.wikipedia.org/wiki/Okapi_BM25?ref=jina-ai-gmbh.ghost.io">presentation on BM25 in Wikipedia</a>. We used the <a href="https://pypi.org/project/rank-bm25/?ref=jina-ai-gmbh.ghost.io"><code>rank_bm25</code></a> package for Python, which fully implements the BM25 ranking algorithm.</p><p><a href="https://www.sbert.net/?ref=jina-ai-gmbh.ghost.io">SBERT</a> is a neural network framework that is widely used in textual information retrieval. We used the <strong><a href="https://huggingface.co/sentence-transformers/msmarco-distilbert-base-v3?ref=jina-ai-gmbh.ghost.io">msmarco-distilbert-base-v3</a></strong> model, because it was trained for the <a href="https://microsoft.github.io/msmarco/?ref=jina-ai-gmbh.ghost.io">MS-MARCO</a> passage ranking task, which is more-or-less the same task as the ranking we’re doing here.</p><p><a href="https://openai.com/blog/clip/?ref=jina-ai-gmbh.ghost.io">CLIP</a> is a neural network trained with both images and descriptive texts. Although CLIP has a number of other usages, we will be using it in this article to match images to text queries, and return ranked results. For this work, we used the <a href="https://huggingface.co/openai/clip-vit-base-patch32?ref=jina-ai-gmbh.ghost.io"><strong>clip-vit-base-patch32</strong></a> model from OpenAI, which is the most widely used CLIP model.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/hybrid_search.png" class="kg-image" alt="" width="1471" height="618" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/11/hybrid_search.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/11/hybrid_search.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/11/hybrid_search.png 1471w" sizes="(min-width: 720px) 720px"><figcaption>All three models take a text query and return a user-specified number of results, each with a score. Query results are ranked by that score.</figcaption></figure><p>All three work by scoring and ranking matches in response to text queries, then returning some number of top results, with the number decided by the user. This makes it easier to integrate them. Both SBERT and CLIP produce scores between -1.0 (worst match for query) and 1.0 (best match). The lowest possible BM25 score is 0.0, but there are no upper bounds.</p><p>To make them fully comparable, we took a few measures:</p><ul><li>We reject all matches from CLIP or SBERT with scores less than zero. These are always bad matches anyway.</li><li>We normalize BM25 scores to the range 0.0 to 1.0 by applying a simple formula: Divide the BM25 score by itself plus 10.</li><li>When a match appears in the top results of one or two but not all three search methods, we assign it an interpolated score for the search methods that miss it. If we request the top <em>N</em> matches, we assign the missing match a small, non-zero value that we determined empirically for each model.</li></ul><p>For example, let’s say we search for “screwdriver” and get the twenty best matches from each of BM25, SBERT and CLIP. BM25 and SBERT search both identify a product “6-Piece Magnetic Tip Screwdriver Set, 3 Phillips and 3 Flat” in the top twenty matches, but CLIP does not have this product in its top twenty matches at all because the picture is of the box it ships in. We then find the lowest score CLIP assigned to any of its top 20 matches, and we use that as the score that CLIP gave to “6-Piece Magnetic Tip Screwdriver Set, 3 Phillips and 3 Flat”.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/CodeCogsEqn--2-.svg" class="kg-image" alt="" width="143" height="35"><figcaption>BM25 score normalization</figcaption></figure><h2 id="hybrid-search">Hybrid Search</h2><p>We constructed a hybrid search scheme that combines the results of searches using BM25, SBERT and CLIP. &nbsp;For each query, we performed search using each of the three systems, and retrieved the twenty best matches from each system and adjusted their scores as described in the previous section. The score for each match is a weighted sum the scores given to it by each of the three search systems — SBERT, CLIP, and the normalized BM25.</p><p>Below is a schematization of how the hybrid search scheme works:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/hybrid_search_full.png" class="kg-image" alt="" width="1632" height="1265" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/11/hybrid_search_full.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/11/hybrid_search_full.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/11/hybrid_search_full.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2022/11/hybrid_search_full.png 1632w" sizes="(min-width: 720px) 720px"><figcaption>Hybrid search</figcaption></figure><p>Empirical testing found that the following weights worked fairly well:</p><table>
<thead>
<tr>
<th>Model</th>
<th>Weight</th>
</tr>
</thead>
<tbody>
<tr>
<td>BM25</td>
<td>0.1</td>
</tr>
<tr>
<td>SBERT</td>
<td>0.5</td>
</tr>
<tr>
<td>CLIP</td>
<td>0.4</td>
</tr>
</tbody>
</table>
<p>Intuitively, we can interpret this as placing a bit more than half the weight on text retrieval (SBERT and BM25) and bit less than half on text-to-image retrieval (CLIP), with BM25’s 0.1 weight ensuring a bias in favor of traditional term matches, all else being equal, or acting as a fallback when neural models fail to produce any good results.</p><h2 id="comparing-search-schemes">Comparing Search Schemes</h2><h3 id="test-data">Test Data</h3><p>Ideally, we would have the product database and query log of a real online vendor<em>.</em> However, companies (especially fictional ones) generally don't make their users’ queries available to researchers for commercial and legal reasons. So we are forced to use a substitute.</p><p>We used the closest readily available alternative: the <a href="https://xmrec.github.io/?ref=jina-ai-gmbh.ghost.io">XMarket dataset</a>. This data is drawn from Amazon.com marketplaces in eighteen countries, and consists of product images found on Amazon websites, as well as product names, descriptions, categories and various metadata.</p><p>For this article, we used a subset of the XMarket data: Only entries in the category <em>Electronics</em>, and only from the US Amazon site. This comes to 15,934 products distributed over 837 categories.</p><p>Furthermore, of the information fields available for each item, we used only the following:</p><ul><li>ASIN — &nbsp;A unique product ID assigned by Amazon.</li><li>Title — The name of the product as used by Amazon.</li><li>Description — Free text description of the product, presumably from the manufacturer or vendor.</li><li>Categories — A label within Amazon’s hierarchical product ontology.</li><li>Image — The image or photo Amazon uses on this product’s page.</li></ul><p>You can see an example record below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/example_document_sd_card.png" class="kg-image" alt="" width="1826" height="741" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/11/example_document_sd_card.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/11/example_document_sd_card.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/11/example_document_sd_card.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2022/11/example_document_sd_card.png 1826w" sizes="(min-width: 720px) 720px"><figcaption>An example of an entry in the XMarket dataset</figcaption></figure><p>You can examine the data yourself by <a href="https://docs.jina.ai/jina-ai-cloud/login/?ref=jina-ai-gmbh.ghost.io">logging in to Jina AI</a> (using <code>jina auth login</code> at the command line to access your existing account, or to create one) and downloading it using the DocArray Python module:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/docarray/docarray?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - docarray/docarray: 🧬 The data structure for unstructured multimodal data · Neural Search · Vector Search · Document Store</div><div class="kg-bookmark-description">🧬 The data structure for unstructured multimodal data · Neural Search · Vector Search · Document Store - GitHub - docarray/docarray: 🧬 The data structure for unstructured multimodal data · Neural S...</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://github.com/fluidicon.png" alt=""><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">docarray</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://repository-images.githubusercontent.com/438303578/57aae8cb-5b20-4e35-a46c-9a742af1470c" alt=""></div></a></figure><pre><code class="language-python">from docarray import DocumentArray

xmarket_dataset = DocumentArray.pull('xmarket_dataset')
xmarket_dataset.summary()</code></pre><pre><code>╭────────────────── Documents Summary ───────────────────╮
│                                                        │
│   Type                      DocumentArrayInMemory      │
│   Length                    16934                      │
│   Homogenous Documents      True                       │
│   Has nested Documents in   ('chunks',)                │
│   Common Attributes         ('id', 'tags', 'chunks')   │
│   Multimodal dataclass      True                       │
│                                                        │
╰────────────────────────────────────────────────────────╯
╭──────────────────────── Attributes Summary ────────────────────────╮
│                                                                    │
│   Attribute   Data type         #Unique values   Has empty value   │
│  ────────────────────────────────────────────────────────────────  │
│   chunks      ('ChunkArray',)   16934            False             │
│   id          ('str',)          16934            False             │
│   tags        ('dict',)         16934            False             │
│                                                                    │
╰────────────────────────────────────────────────────────────────────╯</code></pre><h3 id="task-description">Task Description</h3><p>Since we don’t have Amazon’s query logs either, we can’t test systems against a representative sample of queries. &nbsp;So we are forced to choose a similar but different task.</p><p>Amazon has assigned each product in the XMarket dataset is to a category in its product ontology, and those categories have text labels. For example, the <em>“Sandisk MicroSD Card”</em> in the previous section is assigned to the category <em>“Micro SD Cards”</em>.</p><p>The search task that we will use to compare search schemes is to use those category labels as text queries, and then check if the query result returns items belonging to that category. To turn this into a quantitative measure, we look at the <em>mean reciprocal rank</em> (MRR), which we measure as follows:</p><p>We queried search systems with each category label and retrieved the twenty highest-ranked results. We then found the rank of the highest ranked result that was actually in that category. We then assigned that query the score <em>1.0/rank</em>.</p><p>For example, if the first result from the query <em>“Micro SD Cards”</em> was a product that Amazon categorizes as belonging to “<em>Micro SD Cards</em>”, then that query has a score of 1.0. &nbsp;If the first four results were not members of that category but the fifth was, then the score is 0.2. If none of the top twenty belonged to that category, then the score is 0.0.</p><p>For each search system, we average the score for all queries to calculate the <em>mean reciprocal rank</em>. Since this is dependent on how many results we took for each query, we label it as <em>MRR@20</em> because we use the top twenty results for each query.</p><h3 id="preparing-the-search-databases-and-indexes">Preparing the search databases and indexes</h3><p>We selected 1,000 items from the 15,934 to use for testing. These ranged over 296 categories. The remaining data we held out for use in the next section.</p><p>We then prepared a BM25 index by getting the title and description for each item in the test set and using the <code>rank_bm25</code> package, and specifically the <code>BM25Okapi</code> algorithm, to create a text retrieval database. See the <a href="https://github.com/dorianbrown/rank_bm25/blob/master/README.md?ref=jina-ai-gmbh.ghost.io">relevant README on GitHub for specifics</a>.</p><p>For SBERT, we used Jina AI DocArray to create a vector retrieval database, using the title and description of each test set item as input texts. </p><pre><code class="language-python">import finetuner
from docarray import Document, DocumentArray

sbert_model = finetuner.build_model('sentence-transformers/msmarco-distilbert-base-v3')

finetuner.encode(sbert_model, product_categories)
finetuner.encode(sbert_model, product_texts)</code></pre><p>For CLIP, we followed the same procedure, but using product images from the same test set.</p><pre><code class="language-python">import finetuner
from docarray import Document, DocumentArray

clip_text_model = finetuner.build_model('openai/clip-vit-base-patch32', select_model='clip-text')
clip_vision_model = finetuner.build_model('openai/clip-vit-base-patch32', select_model='clip-vision')


finetuner.encode(clip_text_model, product_categories)
finetuner.encode(clip_vision_model, product_images)
</code></pre><h2 id="baseline-results">Baseline Results</h2><p>We evaluated the performance of the three search systems by measuring the <em>mean reciprocal rank</em> for each, querying for the top twenty results:</p><table>
<thead>
<tr>
<th>Search model</th>
<th>Average MMR@20</th>
<th>Implementation</th>
</tr>
</thead>
<tbody>
<tr>
<td>BM25</td>
<td>30.3%</td>
<td>bm25 package</td>
</tr>
<tr>
<td>SBERT</td>
<td>49.1%</td>
<td><code>docarray.find()</code> NN search</td>
</tr>
<tr>
<td>CLIP</td>
<td>29.2%</td>
<td><code>docarray.find()</code> NN search</td>
</tr>
</tbody>
</table>
<p>These results shouldn't be very surprising. CLIP — which compares text queries directly with images, not text descriptions — performs worse than BM25. This isn't surprising, and that it's only a little bit worse is evidence of how good CLIP is. Still, we should expect that purely image-driven search is going to be inadequate.</p><p>SBERT, which uses neural methods to perform searches on texts, works better on the average than BM25 and in this dataset we can see that the textual information provides a better basis for these searches than image information.</p><h2 id="hybrid-results">Hybrid Results</h2><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://colab.research.google.com/drive/1XcpiJT3QOaR8Sk0Sl-d3qGZzbsOzWtQE?usp=sharing&amp;ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Google Colaboratory</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://colab.research.google.com/img/favicon.ico?vrz=colab-20221102-060049-RC00_485557735" alt=""></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://colab.research.google.com/img/colab_favicon_256px.png" alt=""></div></a><figcaption>For a concrete implementation of the hybrid search engine used here, with code, please take a look at this Colab Notebook, which we prepared to accompany this article. You can try it with your own data and use-case and see if this is a solution for you.</figcaption></figure><p>We did the same test, using the same test data, on hybrid search schemes. We tested all three pairs of search systems, and a hybrid that used all three together.</p><p>Hybrid search blows the individual search systems out of the water:</p><table>
<thead>
<tr>
<th>Search model</th>
<th>Average MMR@20</th>
<th>Max of the Baselines</th>    
</tr>
</thead>
<tbody>
<tr>
<td>BM25+CLIP</td>
<td>41.1%</td>
<td>30.3%</td>    
</tr>
<tr>
<td>SBERT+CLIP</td>
<td>51.7%</td>
<td>49.1%</td>    
</tr>
<tr>
<td>BM25+SBERT</td>
<td>51.2%</td>
<td>49.1%</td>      
</tr>
<tr>
<td>BM25+SBERT+CLIP</td>
<td>52.95%</td>
<td>49.1%</td>    
</tr>
</tbody>
</table><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-text">All pairs of search models are better than their individual components.</div></div><p>These results alone show the potential for improving search using hybrid methods. The biggest jump comes from combining the two individually worst-scoring models: BM25 and CLIP, which go from scoring roughly 30% separately to over 40% together. Text and image search are complementary, the one compensating for the shortcomings of the other.</p><p>SBERT, however, is only a bit improved by adding CLIP and BM25, jumping from a score of 49% to 53%. &nbsp;This still represents an 8% relative improvement compared to SBERT alone.</p><h2 id="fine-tuning">Fine-tuning</h2><p>Fine-tuning improves the performance of pre-trained neural networks by adding training data that is more representative of your specific use-case.</p><p>Jina AI Finetuner makes fine-tuning easier, faster and more performant by streamlining the workflow and handling all the operational complexity and physical infrastructure in the cloud. </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/finetuner?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - jina-ai/finetuner: Task-oriented finetuning for better embeddings on neural search</div><div class="kg-bookmark-description">:dart: Task-oriented finetuning for better embeddings on neural search - GitHub - jina-ai/finetuner: Task-oriented finetuning for better embeddings on neural search</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://github.com/fluidicon.png" alt=""><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://repository-images.githubusercontent.com/394994747/b1cc3a87-d80f-4b52-9522-6647d88d0aaa" alt=""></div></a></figure><p>It works by applying <a href="https://finetuner.jina.ai/get-started/how-it-works/?ref=jina-ai-gmbh.ghost.io">contrastive metric learning</a>, which takes pairs of items that belong together, and then adjusts the model so that it makes better distinctions. There is no need to hand-annotate data or identify what products ought to match each query. As long as you have some kind of information about the semantic relatedness of pairs of data items that fit your use-case, you can use the Finetuner to improve performance.</p><p>Having already selected 1,000 items from the XMarket dataset as test data, we used the remaining almost 15,000 entries as training data to fine-tune SBERT and CLIP. </p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-text">The training set contains only <em>some </em>of the categories in the test set and <em>none </em>of the products.</div></div><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Finetuner_before_after.png" class="kg-image" alt="" width="986" height="607" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/11/Finetuner_before_after.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2022/11/Finetuner_before_after.png 986w" sizes="(min-width: 720px) 720px"><figcaption>A highly schematized representation of what fine-tuning does: Jina AI Finetuner works by training neural networks to bring closer together the output vectors of things that belong together, and move apart those that don’t.</figcaption></figure><p>For SBERT, we extracted product titles, product descriptions, and category names from the training set. The logic of fine-tuning is that we want to train SBERT to recognize that product names and descriptions belonging to products in the same category should be relatively good matches for each other and for their category label. Using this information, we reorganized the training data as a <code>DocumentArray</code>object for fine-tuning SBERT, as described in the <a href="https://finetuner.jina.ai/walkthrough/create-training-data/?ref=jina-ai-gmbh.ghost.io">Jina AI Finetuner documentation</a>.</p><pre><code class="language-python">import finetuner

# login to finetuner api
finetuner.login()

# create and submit SBERT finetuning job
sbert_run = finetuner.fit(
    model='sentence-transformers/msmarco-distilbert-base-v3',
    train_data=sbert_train_data,
    epochs=3,
    batch_size=64,
    learning_rate=1e-6,
    cpu=False,
)

# Wait for the run to finish!

finetuned_sbert_model = finetuner.get_model(sbert_run.artifact_id)</code></pre><p>We then extracted pairs of product images and their category names and did the same to construct a <code>DocumentArray</code>object for fine-tuning CLIP. The idea is to train it to place the category names and images closer together.</p><pre><code class="language-python"># create and submit CLIP finetuning job
clip_run = finetuner.fit(
    model='openai/clip-vit-base-patch32',
    loss='CLIPLoss',
    train_data=clip_train_da,
    epochs=3,
    batch_size=128,
    learning_rate=1e-6,
    cpu=False
)

# Wait for the run to finish!

finetuned_clip_text_model = finetuner.get_model(clip_run.artifact_id, select_model='clip-text')
finetuned_clip_vision_model = finetuner.get_model(clip_run.artifact_id, select_model='clip-vision')</code></pre><p>BM25 is not based on neural networks, so naturally, it cannot be fine-tuned. After fine-tuning, it will have a sharp disadvantage compared to SBERT and CLIP because it has no information about categories at all.</p><p>After fine-tuning SBERT and CLIP, we reran the evaluation with only the 1,000 item test set, and achieved the following average scores:</p><table>
<thead>
<tr>
<th>Search model</th>
<th>Average MMR@20 Baseline</th>
<th>Average MMR@20 after running Finetuner</th>
</tr>
</thead>
<tbody>
<tr>
<td>SBERT</td>
<td>49.08%</td>
<td>56.19%</td>
</tr>
<tr>
<td>CLIP</td>
<td>28.22%</td>
<td>41.67%</td>
</tr>
<tr>
<td>BM25+CLIP</td>
<td>41.08%</td>
<td>50.06%</td>
</tr>
<tr>
<td>SBERT+CLIP</td>
<td>51.66%</td>
<td>58.42%</td>
</tr>
<tr>
<td>BM25+SBERT</td>
<td>51.22%</td>
<td>56.80%</td>
</tr>
<tr>
<td>BM25+SBERT+CLIP</td>
<td>52.95%</td>
<td>59.48%</td>
</tr>
</tbody>
</table>
<p>Although we see improvements in all scenarios, CLIP’s performance skyrockets with fine-tuning. And for hybrid search using all three techniques, there is over 12% relative improvement.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-text">A benefit of using neural network-based AI technologies is the ability to fine-tune pre-trained networks to your data.</div></div><h1 id="why-does-this-work">Why Does This Work?</h1><p>Clearly, hybrid searching rocks. But looking at the evaluation numbers alone understates the improvement each component brings.</p><p>For example, for the query "<em>CD-RW Discs</em>", BM25 gives a very high score to a product labeled "<em>Verbatim CD-RW 700MB 2X-12X Rewritable Media Disc - 25 Pack Spindle Style</em>". This is exactly right.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/CD-RW_Discs_BM25-1.png" class="kg-image" alt="" width="233" height="120"><figcaption><em>Verbatim CD-RW 700MB 2X-12X Rewritable Media Disc - 25 Pack Spindle Style</em></figcaption></figure><p>SBERT, however, is misled by a long descriptive text that contains many terms it associates with the search terms:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/CD-RW_Discs_SBERT-1.png" class="kg-image" alt="" width="255" height="173"><figcaption><em>Memorex 4x DVD+RW 25 Pack Spindle. </em>This 25-pack of 4x DVD+RW discs for newer DVD+R/+RW drives (part number 32025541) consists of rewriteable, single-sided discs that store up to 4.7 GB of data and approximately 240 minutes of video (depending on your mastering software; 120 minutes optimal)--that's more than six times as much data as will fit on a recordable CD. You can transfer your home movies from VHS or 8 mm cassettes, back-up computer hard drives and large files, or stuff them chock full of MP3 music files and JPEG image files from your digital camera. Rewritable "plus" discs require no finalizing--you can record, eject, and play them with minimal fuss, thanks to "background formatting." This feature, which lowers total burning time, is an advantage over the "dash" formats. For PC users, DVD+RW also offers advantages over DVD-RW, including on-disc content editing, built-in defect management, and multisession writing. What's in the Box 25 DVD+RW discs, 1 two-piece storage case, and a paper insert with product details.</figcaption></figure><p>CLIP, because it relies on visual similarity, is also poorly able to distinguish “C<em>D-RW Discs</em>” from other kinds of optical disks. They look exactly the same to humans too, if you take away the label text. It gives its highest ranking to this, a product that clearly doesn't match what the user is looking for:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/CD-RW_Discs_CLIP-1.png" class="kg-image" alt="" width="285" height="280"><figcaption><em>Philips 52X 700MB CD-R 50PK Spindle</em></figcaption></figure><p>CLIP excels when query terms are poor matches for descriptions, but good matches for its visual analysis of product pictures. &nbsp;For example, the query “<em>Earbud Headphones</em>” is a poor match for the textual label "<em>Maxell 190329 Portable lightweight Behind The Head Extended Comfort Soft Touch Rubber Memory Neckband Stereo Line Neckband Head Buds - Silver</em>". But it's a good match for the image below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Earbud-Headphones_CLIP.png" class="kg-image" alt="" width="450" height="319"><figcaption><em>Maxell 190329 Portable lightweight Behind The Head Extended Comfort Soft Touch Rubber Memory Neckband Stereo Line Neckband Head Buds - Silver</em></figcaption></figure><p>CLIP gives this product a high score because of its appearance, which it correctly identifies with “earbud”.</p><p>SBERT and BM25 both miss this match, giving their highest rankings to traditional “over-the-ear” headphones like this one:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Earbud-Headphones_SBERT-1.png" class="kg-image" alt="" width="343" height="559"><figcaption><em>Panasonic Headphones On-Ear Lightweight with XBS RP-HT21 (Black &amp; Silver)</em></figcaption></figure><p>SBERT excels where there is good textual information for matching, even if the match is not exact. For example, the query “<em>Fiber Optic Cables</em>” gives us this match from SBERT:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Fiber_Optic_Cables_SBERT-1.png" class="kg-image" alt="" width="261" height="323"><figcaption><em>CNE25969 6-Feet 1.8m PCD Basics Fiber Optic Audio Cable</em></figcaption></figure><p>CLIP, in contrast, is useless with this query because it is unable to visually distinguish fiber optic cables from any other kind of cable, and highly ranks matches like this:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Fiber_Optic_Cables_CLIP.png" class="kg-image" alt="" width="541" height="355"><figcaption><em>C2G 31348 Cat6 Cable - Snagless Unshielded Ethernet Network Patch Cable, Orange</em></figcaption></figure><h2 id="bring-hybrid-vigor-to-your-search">Bring Hybrid Vigor to Your Search</h2><p>Even with clean visual data and expansive descriptions, hybrid search with classical text retrieval technologies and AI-driven neural search is better than relying on just one technology.</p><p>Most use-cases are much less ideal. Descriptions are inaccurate, inadequate, or just plain missing. Photos are of poor quality or absent. And when users put in their queries texts with exact matches, they expect to see those matches in the results. Each of the three technologies is essential to meeting user expectations and providing good results.</p><p>With Jina AI’s framework, combining search results and fine-tuning for your use-case produces high quality retrieval software almost out of the box.</p><p>We are always moving forward at Jina AI, bringing state-of-the-art cloud-native neural AI to users through our intuitive Python framework and NoCode solutions. Feel free to contact us via our <a href="https://jina.ai/slack/?ref=jina-ai-gmbh.ghost.io">Community Slack</a> with comments or to discuss your use-case.</p></section></article><hr data-v-b24d48de="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-b24d48de="" class="row justify-between items-center q-py-md"><div data-v-b24d48de=""><span data-v-b24d48de="" class="text-weight-bold">Categories:</span><span data-v-b24d48de="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></span></div><div data-v-b24d48de=""><div data-v-b24d48de="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-b24d48de="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-b24d48de="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-b24d48de="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-b24d48de="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-b24d48de="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-b24d48de="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-b24d48de="" class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div data-v-b24d48de="" class="text-h6 text-grey-2 text-weight-bold q-mt-lg">Learn more</div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow overflow-hidden print-hide"><video preload="none" autoplay="" loop="" playsinline="" class="non-selectable" poster="/assets/portal-2-poster.44997122.webp" style="width: 100%; height: 420px; object-fit: cover;"><source src="/assets/portal-2.0da13c26.mp4" type="video/mp4"></video><div class="q-card q-card--dark q-dark q-card--flat no-shadow row absolute-left items-center bg-transparent non-selectable fit"><div class="text-white bg-transparent lock-blur fit q-pa-sm"><div class="row justify-between q-gutter-lg"><div class="col-12 col-md-3"><div class="q-list q-list--dark"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><strong>Offices</strong></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption">Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany</div><div class="q-item__label q-item__label--caption text-caption">Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption">Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption">402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div></div><div class="row text-caption justify-center q-mt-xl"> © Jina AI GmbH 2020-2024. All rights reserved.</div></div></div></div><footer class="q-footer q-layout__section--marginal fixed-bottom lock-blur bg-transparent print-hide"><div class="row"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline col-12 col-md-6 justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-discord" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://twitter.com/jinaAI_/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.youtube.com/c/JinaAI" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-youtube" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.meetup.com/jina-community-meetup/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-meetup" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">email</i></span></a></div><div class="row col-12 col-md-6 items-center text-caption justify-center"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--stretch inline" no-caps=""><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="/legal/#privacy-policy" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy Policy</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="/legal/#terms-and-conditions" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Terms and Conditions</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="javascript:UC_UI.showSecondLayer();" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy Settings</span></span></a></div></div></div></footer></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>