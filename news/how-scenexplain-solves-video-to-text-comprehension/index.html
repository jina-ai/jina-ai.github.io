<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>How SceneXplain Solved Video-to-Text Comprehension</title><meta charset="utf-8"><meta name="title" content="How SceneXplain Solved Video-to-Text Comprehension"><meta name="description" content="Pushing the boundaries of video-to-text comprehension, SceneXplain unveils the Inception algorithm: decoding narratives, acknowledging challenges, and inviting firsthand exploration. Dive into the next frontier of video comprehension."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/how-scenexplain-solves-video-to-text-comprehension"><meta property="og:title" content="How SceneXplain Solved Video-to-Text Comprehension"><meta property="og:description" content="Pushing the boundaries of video-to-text comprehension, SceneXplain unveils the Inception algorithm: decoding narratives, acknowledging challenges, and inviting firsthand exploration. Dive into the next frontier of video comprehension."><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2023/08/generativejina_Illustration_showing_a_vintage_movie_projector_c_776167b0-0368-4304-bd82-7452c8e5928a.png"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/how-scenexplain-solves-video-to-text-comprehension"><meta property="twitter:title" content="How SceneXplain Solved Video-to-Text Comprehension"><meta property="twitter:description" content="Pushing the boundaries of video-to-text comprehension, SceneXplain unveils the Inception algorithm: decoding narratives, acknowledging challenges, and inviting firsthand exploration. Dive into the next frontier of video comprehension."><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2023/08/generativejina_Illustration_showing_a_vintage_movie_projector_c_776167b0-0368-4304-bd82-7452c8e5928a.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png">  <script type="module" crossorigin="" src="/assets/index.185b0db0.js"></script>
  <link rel="stylesheet" href="/assets/index.67e85a4c.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/register.3432a504.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip.21c32415.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine.0a6c0ea0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/selection.1fef6e95.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard.e8812861.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.185b0db0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout.62d61aed.js"><link rel="stylesheet" href="/assets/MainLayout.891b970f.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpace.da2f4e45.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSelect.07543ced.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip.b2a69a00.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel.d326fed6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/rtl.b51694b1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format.865294d5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown.cb48e33d.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnGroup.5d385b2b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList.00c0b089.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver.ba8e2198.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QImg.97942762.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem.638b4027.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollArea.ddba9ce3.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan.27057ee2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch.70a9dd44.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResponsive.79ad2e3d.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup.b60ed62b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/common.e573036c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/chunk.17bfede8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isArrayLike.a2a00cef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isObject.cef35763.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/toNumber.476d0739.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage.39a11ab7.js"><link rel="stylesheet" href="/assets/NewsPage.e84092ac.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QParallax.2ff35384.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage.7ac7ad82.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs.97ed80fd.js"><link rel="stylesheet" href="/assets/blogs.b3aadae9.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/plugin-vue_export-helper.21dcd24c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge.734abf87.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard.1447fce8.js"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><link prerender-ignore rel=preconnect href=//app.usercentrics.eu><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js></script><script prerender-ignore>// (optional) additional configs for the Smart Data Protector
      uc.reloadOnOptIn('BJz7qNsdj-7'); // reload page on YouTube opt-in</script><style prerender-ignore>.uc-embedding-container {
      min-height: 100% !important;
    }

    .uc-embedding-wrapper p {
      color: black;
    }</style><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top text-white lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none" role="toolbar"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button" style="padding: 24px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">reorder</i></span></button><hr class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" href="/" style="font-size: 32px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></span></span></a><div class="q-space"></div><label class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--float q-field--dense q-field--dark" for="f_ca541f45-d3fd-4619-965b-a5e3f23f1cab"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>English</span><input class="q-select__focus-target" id="f_ca541f45-d3fd-4619-965b-a5e3f23f1cab" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_ca541f45-d3fd-4619-965b-a5e3f23f1cab_lb"></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon fas fa-caret-down q-select__dropdown-icon" aria-hidden="true" role="presentation"> </i></div></div></div></label></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-left" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--left q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(-300px);"><div class="q-drawer__content fit scroll"><div class="q-scrollarea q-scrollarea--dark fit"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark q-list--padding"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">notifications</i></div></div></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="12d576a8-ff4b-42f9-b3be-029ddc433fa2" aria-label="Expand &quot;For Enterprises&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Enterprises</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="12d576a8-ff4b-42f9-b3be-029ddc433fa2" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">Our world-class embeddings for your search and RAG systems</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="5f55a13b-3176-4fc9-94b9-7a4e27014d0b" aria-label="Expand &quot;For Power Users&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Power Users</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="5f55a13b-3176-4fc9-94b9-7a4e27014d0b" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://promptperfect.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://scenex.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://bestbanner.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://chat.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://rationale.jina.ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="0e8b362d-7c4b-4163-93ca-8691983d4262" aria-label="Expand &quot;For Developers&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">For Developers</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="0e8b362d-7c4b-4163-93ca-8691983d4262" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/docarray/docarray"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/doc-array.35372518.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DocArray</div><div class="q-item__label q-item__label--caption text-caption">The data structure for multimodal data</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jina"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/core.99751891.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jina</div><div class="q-item__label q-item__label--caption text-caption">Build multimodal AI applications on the cloud</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/finetuner"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetuner.c62eaafa.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Finetuner</div><div class="q-item__label q-item__label--caption text-caption">Fine-tune embeddings on domain specific data for better search quality</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/clip-as-service"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/clip-as-service.f454ca2a.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">CLIP-as-service</div><div class="q-item__label q-item__label--caption text-caption">Embed images and sentences into fixed-length vectors with CLIP</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jcloud"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jcloud.669910ba.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JCloud</div><div class="q-item__label q-item__label--caption text-caption">Deploy a local project as a cloud service. Radically easy, no nasty surprises.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/langchain-serve"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/langchain-serve.8cf53254.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">LangChain-Serve</div><div class="q-item__label q-item__label--caption text-caption">Langchain apps on production with Jina &amp; FastAPI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/vectordb"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/VectorDB.46be6cc1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">VectorDB</div><div class="q-item__label q-item__label--caption text-caption">A Python vector database you just need - no more, no less</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://cloud.jina.ai/executors"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/hub.5e89f942.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Executor Hub</div><div class="q-item__label q-item__label--caption text-caption">Share and discover building blocks for multimodal AI applications</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/dalle-flow"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dall-e-flow.ea199b2d.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DALL-E Flow</div><div class="q-item__label q-item__label--caption text-caption">A human-in-the-Loop workflow for creating HD images from text</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/discoart"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/disco-art.f21a267f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DiscoArt</div><div class="q-item__label q-item__label--caption text-caption">Create compelling Disco Diffusion artworks in one line of code</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/thinkgpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/think-gpt.0a671280.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ThinkGPT</div><div class="q-item__label q-item__label--caption text-caption">Agent techniques to augment your LLM and push it beyond its limits</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/dev-gpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dev-gpt.a3e55036.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DevGPT</div><div class="q-item__label q-item__label--caption text-caption">Your virtual development team</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/rungpt"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/run-gpt.5571707e.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">RunGPT</div><div class="q-item__label q-item__label--caption text-caption">An open-source cloud-native of large multimodal models serving framework</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://github.com/jina-ai/jerboa"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jerboa.af6b308b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jerboa</div><div class="q-item__label q-item__label--caption text-caption">An experimental finetuner for open-source LLMs</div></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="cbc0f52a-206d-4fa0-ac55-129dfaf4507f" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><span class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></span></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="cbc0f52a-206d-4fa0-ac55-129dfaf4507f" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://jobs.lever.co/jina-ai"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/open-day"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Open day</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 82px; padding-bottom: 69px;"><main data-v-7478c13a="" class="q-page" style="min-height: 100vh;"><div data-v-7478c13a="" class="row justify-center q-py-xl q-my-xl"><div data-v-7478c13a="" class="col-12 col-xl-10 q-pa-xl"><div data-v-7478c13a="" class="row justify-center"><div data-v-7478c13a="" class="col" style="max-width: 1000px;"><div data-v-7478c13a="" class="q-mx-sm"><div data-v-7478c13a="" class="row justify-between items-center"><a data-v-7478c13a="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense col-auto" tabindex="0" href="/news"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">arrow_circle_left</i><span class="block">Back to Newsroom</span></span></a><div data-v-7478c13a="" class="col-auto"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-icons q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Featured</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></div></div><div data-v-7478c13a="" class="q-parallax q-mt-md" style="height: 500px;"><div class="q-parallax__media absolute-full"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/generativejina_Illustration_showing_a_vintage_movie_projector_c_776167b0-0368-4304-bd82-7452c8e5928a.png" style="display: initial; transform: translate3d(-50%, 117px, 0px);"></div><div class="q-parallax__content absolute-full column flex-center"><div data-v-7478c13a="" class="text-white absolute-bottom q-pa-lg lock-blur text-h4" style="background: rgba(0, 0, 0, 0.5);">How SceneXplain Solved Video-to-Text Comprehension</div></div></div><div data-v-7478c13a="" class="row justify-between items-center q-mt-lg"><div data-v-363418f9="" data-v-7478c13a="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-363418f9="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-363418f9="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-363418f9="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/1.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div data-v-7478c13a=""><a data-v-7478c13a="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><span data-v-7478c13a="" class="q-icon inline-block q-mr-md" aria-hidden="true" role="presentation" style="font-size: 32px;"><img src="/assets/hacker-news.e100deed.svg"></span></a><a data-v-7478c13a="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><span data-v-7478c13a="" class="q-icon inline-block q-mr-md" aria-hidden="true" role="presentation" style="font-size: 32px;"><img src="/assets/linkedin-logo.e0fc6323.svg"></span></a><a data-v-7478c13a="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><span data-v-7478c13a="" class="q-icon inline-block q-mr-md" aria-hidden="true" role="presentation" style="font-size: 32px;"><img src="/assets/twitter-logo.1c6cc30c.svg"></span></a><a data-v-7478c13a="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><span data-v-7478c13a="" class="q-icon inline-block q-mr-md" aria-hidden="true" role="presentation" style="font-size: 32px;"><img src="/assets/facebook-logo.60334dbf.svg"></span></a><a data-v-7478c13a="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><span data-v-7478c13a="" class="q-icon inline-block q-mr-md" aria-hidden="true" role="presentation" style="font-size: 32px;"><img src="/assets/reddit-logo.6852dc89.svg"></span></a><i data-v-7478c13a="" class="q-icon notranslate material-icons q-hoverable cursor-pointer" aria-hidden="true" role="presentation" style="font-size: 32px;">rss_feed</i></div></div><div data-v-7478c13a="" class="q-item__section column q-item__section--main justify-center text-grey-6 q-mt-sm"><div data-v-7478c13a="" class="q-item__label">Engineering Group</div><div data-v-7478c13a="" class="q-item__label q-item__label--caption text-caption text-grey-6 q-mt-sm">August 30, 2023 • 10 minutes read</div></div><article data-v-7478c13a="" class="article"><section data-v-7478c13a="" class="gh-content"><p>In the modern digital age, the line between visuals and the stories they convey is becoming increasingly blurred. SceneXplain has consistently been at the forefront of this transformation, setting <a href="https://jina.ai/news/scenexplain-vs-minigpt4-a-comprehensive-benchmark-of-top-5-image-captioning-algorithms-for-understanding-complex-scenes/?ref=jina-ai-gmbh.ghost.io">new standards in visual comprehension</a>. Starting with innovations in image-to-text and <a href="https://jina.ai/news/beyond-pixels-to-prose-scenexplains-hearth-algorithm-breathes-audible-life-into-images/?ref=jina-ai-gmbh.ghost.io">image-to-audio</a> generations, we've now extended our expertise into the intricate realm of video-to-text! This natural progression marks our latest endeavor, the <code>Inception</code> algorithm.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SceneXplain - Explore image and video storytelling beyond pixels</div><div class="kg-bookmark-description">Leverage GPT-4 &amp; LLMs for the most advanced image storytelling. Explain visuals for content creators, media, &amp; e-commerce with rich captions, multilingual support, and seamless API integration. Experience the future of image description today.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://scenex.jina.ai/icons/apple-icon-180x180.png" alt=""><span class="kg-bookmark-author">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://scenex.jina.ai/banner.png" alt=""></div></a></figure><p>The power of video, with its dynamic interplay of images and sequences, captures narratives that are often richer and deeper than static images. Yet, unlocking these narratives remains a challenge. Here's where SceneXplain steps in. By leveraging advanced multimodal AI techniques, our platform doesn't merely provide superficial descriptions; it delves deeper to unearth and articulate the stories that unfold within videos. Beyond mere captions, SceneXplain strives for contextual understanding, ensuring each narrative is captured with the depth it deserves.</p><p>Developers and enterprises alike will find value in our system. Not only does SceneXplain bring sophisticated video storytelling tools to the table, but its seamless interface and adaptable API ensure that integrating these tools into your platforms or systems is as smooth as possible.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-23.png" class="kg-image" alt="" width="2000" height="984" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/08/image-23.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/08/image-23.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/08/image-23.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2023/08/image-23.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Don't forget to select the "Inception" algorithm from the model list to activate it.</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><a href="https://scenex.jina.ai/share?thread=EWJcZuS3FpcKJ9AyRq9i&amp;ref=jina-ai-gmbh.ghost.io"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-17.png" class="kg-image" alt="" width="1028" height="1828" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/08/image-17.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/08/image-17.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-17.png 1028w" sizes="(min-width: 720px) 720px"></a><figcaption>Click to play the video and view the results on SceneXplain</figcaption></figure><p>Join us as we dive deeper into the inception of the "Inception" algorithm and explore how it’s setting new paradigms in the world of video comprehension.</p><h2 id="the-imperative-of-video-to-text-comprehension-in-a-visual-first-digital-age"><strong>The Imperative of Video-to-Text Comprehension in a Visual-First Digital Age</strong></h2><p>In our digital epoch, the proliferation of visual content has outpaced almost every other medium. Videos, in particular, have mushroomed into the bedrock of content consumption. From short-form social media clips to extensive webinars, the digital ecosystem is awash with moving pixels. And while the explosion of video content signals a seismic shift in how information is shared and consumed, it also presents an intricate challenge: the sheer volume of content and the immediacy of its consumption.</p><h3 id="the-search-dilemma-from-pixels-to-text"><strong><strong>The Search Dilemma: From Pixels to Text</strong></strong></h3><p>Think about it. Every video that gets uploaded is, in essence, a repository of information. But how do search engines understand them? Unlike text, videos don’t lend themselves easily to the parsing and indexing mechanisms that power the modern web. This is where video-to-text transcends from a luxury to a necessity. Translating videos into text allows search engines to index, categorize, and rank them, making content not just accessible but discoverable.</p><h3 id="the-skim-economy-catering-to-the-impatient-user"><strong><strong>The Skim Economy: Catering to the Impatient User</strong></strong></h3><p>Today’s user is not the reader of yesteryears; they're skimmers and scanners. Not everyone has the time (or inclination) to sit through a 30-minute video. A textual summary, however, can be skimmed in mere minutes. Video comprehension caters to this very demographic, ensuring content remains consumable for the fast-paced digital nomad.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.theguardian.com/commentisfree/2018/aug/25/skim-reading-new-normal-maryanne-wolf?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Skim reading is the new normal. The effect on society is profound | Maryanne Wolf</div><div class="kg-bookmark-description">When the reading brain skims texts, we don’t have time to grasp complexity, to understand another’s feelings or to perceive beauty. We need a new literacy for the digital age writes Maryanne Wolf, author of Reader, Come Home</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://static.guim.co.uk/images/favicon-32x32.ico" alt=""><span class="kg-bookmark-author">The Guardian</span><span class="kg-bookmark-publisher">Maryanne Wolf</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://i.guim.co.uk/img/media/f51170cfbfdcb69dd0adf127db5aa79dbe480751/0_0_6667_4000/master/6667.jpg?width=1200&amp;height=630&amp;quality=85&amp;auto=format&amp;fit=crop&amp;overlay-align=bottom%2Cleft&amp;overlay-width=100p&amp;overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMtYWdlLTIwMTgucG5n&amp;enable=upscale&amp;s=6293bd1a0ebd769f7ddbf98255a729aa" alt=""></div></a></figure><h3 id="accessibility-bridging-the-gap"><strong><strong>Accessibility: Bridging the Gap</strong></strong></h3><p>A core tenet of the modern web is inclusivity. While videos are an excellent medium for many, they inadvertently sideline those with visual or auditory impairments. Converting videos to text ensures that content is universally accessible, not just to a select few. Interested readers are strongly recommended to follow our efforts in using SceneXplain to improve digital accessibility in the EU. </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/enhancing-digital-accessibility-scenexplain-transforms-multimedia-content-public-sector-organizations/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Enhancing Digital Accessibility: How SceneXplain Transforms Multimedia Content for Public Sector Organizations</div><div class="kg-bookmark-description">Explore SceneXplain’s impact on digital accessibility, providing exceptional image descriptions and ensuring compliance with European standards for public sector organizations.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt=""><span class="kg-bookmark-publisher">World Health Organization</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/04/Jina-AI-Website-Banners-Templates---2023-04-19T150542.636-1.png" alt=""></div></a></figure><h3 id="the-content-overload-making-sense-of-the-digital-deluge"><strong><strong>The Content Overload: Making Sense of the Digital Deluge</strong></strong></h3><p>Every minute, 500 hours of video are uploaded to platforms like YouTube. In this sea of content, how does one discern value? Automatic video comprehension can help platforms curate and recommend, ensuring users find not just any content, but relevant content.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-16.png" class="kg-image" alt="" width="566" height="562"><figcaption>Source: <a href="https://www.convinceandconvert.com/content-marketing/video-marketing-statistics/?ref=jina-ai-gmbh.ghost.io">12 Video Marketing Statistics You Need to Know in 2020&nbsp;</a></figcaption></figure><p>The pressing need for video comprehension or video-to-text techniques is not just about keeping pace with technological advancements; it's about shaping the future of content consumption. In an increasingly visual-first digital realm, understanding and articulating the stories within videos isn't just desirable — it's imperative.</p><h2 id="delving-into-the-mathematics-of-video-comprehension">Delving into the Mathematics of Video Comprehension</h2>
<p>The modern quest to elucidate video content's narrative essence can be likened to the pursuit of converting a rich tapestry of visual sequences into coherent textual symphonies. To embark on this journey, we must first define our problem in a precise mathematical manner.</p>
<p>Given a video <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span></span></span></span></span>, comprising a series of frames <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>f</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>f</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{f_1, f_2, ... f_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>, our aim is to transform it into a series of textual descriptions or a summary <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span></span></span></span></span>, such that <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mrow><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>s</mi><mi>k</mi></msub></mrow></mrow><annotation encoding="application/x-tex">S = {s_1, s_2, ... s_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span> where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>≤</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \leq n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8304em; vertical-align: -0.136em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span>.</p>
<p>At the heart of this transformation lies the relationship between each frame <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> and its corresponding summary statement <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>. Using Bayesian probabilistic notation, we can express this relationship as the conditional probability <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>f</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(s_j | f_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>. However, given the sequential nature of videos, it's often the case that a summary statement <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> is conditioned on a sequence of frames rather than an individual frame.</p>
<p>Thus, we extend our probability notation to consider a window of frames, leading to:</p>
<p><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>f</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>f</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>f</mi><mrow><mi>i</mi><mo>−</mo><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> P(s_j | f_i, f_{i-1}, ... f_{i-l}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p>
<p>Where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span></span></span></span></span> represents the length of the frame window that influences the summary statement <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>.</p>
<p>Our objective function then aims to maximize the likelihood of our entire summary <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span></span></span></span></span> given the video <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span></span></span></span></span>:</p>
<p><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>S</mi></munder><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>P</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>f</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>f</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>f</mi><mrow><mi>i</mi><mo>−</mo><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> \max_{S} \prod_{j=1}^{k} P(s_j | f_i, f_{i-1}, ... f_{i-l}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 3.2499em; vertical-align: -1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.4306em;"><span class="" style="top: -2.3557em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0576em;">S</span></span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7443em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8361em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∏</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.4138em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1076em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p>
<p>This formulation elegantly captures the essence of video comprehension — weaving a textual narrative from a series of interlinked visual frames, while also accounting for the inherent continuity and interdependence of video content.</p>
<p>In this probablistic framework, our task not only becomes clearer but also lays the foundation for the development of algorithms, like Inception, that can effectively tackle the intricate nuances of the video-to-text conversion process.</p>
<h2 id="tackling-the-challenges-keyframes-context-and-coherence"><strong>Tackling the Challenges: Keyframes, Context, and Coherence</strong></h2><p>In our earlier discussion on the mathematical framework of video comprehension, we highlighted the importance of a narrative continuum and the sequential dependence of frames. This context is vital in comprehending how we approach keyframe insights and descriptions.</p><h3 id="the-keyframe-conundrum-coherence-over-quantity"><strong><strong>The Keyframe Conundrum: Coherence Over Quantity</strong></strong></h3><p>A consistent series of keyframe insights ensures that the video's narrative essence remains undistorted. However, inconsistency in keyframes' details introduces fragmentation, leading to a disjunctive understanding where the context is lost. Instead of a clear narrative thread, you're left with disconnected vignettes, robbing the video of its richness and continuity.</p><p>The most direct approach would be to ascertain the "optimal" number of keyframes, capturing the essence without diluting the narrative. But what's optimal for a fast-paced action clip might differ from an introspective documentary. Additionally, the descriptions for each keyframe should be succinct yet sufficiently detailed to relay the frame's narrative weight.</p><h3 id="towards-an-adaptive-framework-balancing-details-and-density"><strong><strong>Towards an Adaptive Framework: Balancing Details and Density</strong></strong></h3><p>Defining the "right" balance of keyframes and the granularity of their descriptions is a nuanced challenge, with variances across video genres and styles. Taking a probabilistic stance, as per our Bayesian framework, the challenge boils down to maximizing the likelihood of our summarized content given the original video, while maintaining a controlled description density.</p><p>SceneXplain's base video summarization algorithm pragmatically navigates this challenge. Built on the principle that "<em>overloading with details can be more detrimental than being minimally informative,</em>" we've capped the keyframes to a maximum of 6 per minute and limited caption lengths to 20 words. This ensures clarity without overburdening the viewer, offering a distilled yet coherent narrative.</p><h3 id="the-road-ahead-dynamic-adaptations"><strong><strong>The Road Ahead: Dynamic Adaptations</strong></strong></h3><p>Recognizing the dynamic nature of videos and their myriad styles, SceneXplain is also committed to evolving its constraints. Future iterations are primed to make these metrics tunable, adapting to the unique requirements of different content, thus maintaining the Bayesian foundation of context and sequence.</p><h2 id="demonstrating-scenexplain-a-deep-dive-into-inceptions-excellence"><strong>Demonstrating SceneXplain: A Deep Dive into Inception's Excellence</strong></h2><p>As we transition from the theoretical framework and the challenges we navigated to bring SceneXplain to life, it's time to dive into its practical performance. Words, equations, and design philosophies can only convey so much — it's in the real-world application that an algorithm truly proves its mettle. And our Inception algorithm stands tall when subjected to the rigorous tests of Topicality, Details, and Factuality.</p><h3 id="details-not-just-what-meets-the-eye"><strong><strong>Details: Not Just What Meets the Eye</strong></strong></h3><p>Every frame of a video carries an expansive depth of information — from the nuanced expressions of a character to the intricate patterns on a distant artifact. Inception's prowess lies in not merely recognizing these myriad details but artfully weaving them into coherent and engaging narratives. Our demo showcases scenes replete with complexity and depth, and Inception's ability to encapsulate each facet, validating its unparalleled performance in capturing intricate visual information.</p><figure class="kg-card kg-image-card kg-card-hascaption"><a href="https://scenex.jina.ai/share?thread=RuXPznfRGNtqdKJuJVQl&amp;ref=jina-ai-gmbh.ghost.io"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-19.png" class="kg-image" alt="" width="1022" height="1826" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/08/image-19.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/08/image-19.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-19.png 1022w" sizes="(min-width: 720px) 720px"></a><figcaption>Click to play the video and view the results on SceneXplain</figcaption></figure><h3 id="topicality-finger-on-the-pulse"><strong><strong>Topicality: Finger on the Pulse</strong></strong></h3><p>In an age where information flows at breakneck speed and cultural contexts evolve almost daily, it's paramount for an algorithm to remain current and contextual. SceneXplain, powered by Inception, goes beyond just visually describing content. Whether it's referencing a recent global event, alluding to a trending meme, or identifying a breakout celebrity, our algorithm ensures that the generated captions resonate with what's topical, relevant, and engaging. Dive into our demos, and witness how Inception connects the visual narratives with the contemporary cultural zeitgeist.</p><figure class="kg-card kg-image-card kg-card-hascaption"><a href="https://scenex.jina.ai/share?thread=EWJcZuS3FpcKJ9AyRq9i&amp;ref=jina-ai-gmbh.ghost.io"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-20.png" class="kg-image" alt="" width="1018" height="1842" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/08/image-20.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/08/image-20.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-20.png 1018w" sizes="(min-width: 720px) 720px"></a><figcaption>Click to play the video and view the results on SceneXplain</figcaption></figure><h3 id="factuality-the-bedrock-of-trust"><strong><strong>Factuality: The Bedrock of Trust</strong></strong></h3><p>While creativity and engagement are crucial, they should never come at the expense of truthfulness. A tool like SceneXplain holds immense responsibility in ensuring the information it disseminates is accurate. Inception has been crafted with an unwavering commitment to factuality. Every caption it produces is meticulously vetted for accuracy, minimizing hallucinations and misinformation. Our demonstrations will highlight scenes where it's tempting for algorithms to falter, to extrapolate beyond what's present — but Inception stands firm, delivering trustworthy descriptions consistently.</p><figure class="kg-card kg-image-card kg-card-hascaption"><a href="https://scenex.jina.ai/share?thread=rw3NJMGKiM2N9sEWB2TC&amp;ref=jina-ai-gmbh.ghost.io"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-18.png" class="kg-image" alt="" width="1022" height="1822" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/08/image-18.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/08/image-18.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-18.png 1022w" sizes="(min-width: 720px) 720px"></a><figcaption>Click to play the video and view the results on SceneXplain</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><a href="https://scenex.jina.ai/share?thread=3oq0bZmkGezlPThLGyM8&amp;ref=jina-ai-gmbh.ghost.io"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-21.png" class="kg-image" alt="" width="1014" height="1716" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/08/image-21.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/08/image-21.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/08/image-21.png 1014w" sizes="(min-width: 720px) 720px"></a><figcaption>Click to play the video and view the results on SceneXplain</figcaption></figure><p>More examples can be found below:</p><ul><li><a href="https://scenex.jina.ai/share?thread=mFme4ygBpTOkSzpGEDBT&amp;ref=jina-ai-gmbh.ghost.io" rel="noopener noreferrer">https://scenex.jina.ai/share?thread=mFme4ygBpTOkSzpGEDBT</a></li><li><a href="https://scenex.jina.ai/share?thread=RuXPznfRGNtqdKJuJVQl&amp;ref=jina-ai-gmbh.ghost.io" rel="noopener noreferrer">https://scenex.jina.ai/share?thread=RuXPznfRGNtqdKJuJVQl</a></li><li><a href="https://scenex.jina.ai/share?thread=EWJcZuS3FpcKJ9AyRq9i&amp;ref=jina-ai-gmbh.ghost.io" rel="noopener noreferrer">https://scenex.jina.ai/share?thread=EWJcZuS3FpcKJ9AyRq9i</a></li></ul><h2 id="known-limitations-of-the-inception-algorithm-embracing-transparency-and-ethical-responsibility"><strong>Known Limitations of the Inception Algorithm: Embracing Transparency and Ethical Responsibility</strong></h2><p>In the era of machine learning, it's tempting to herald algorithms as faultless, all-seeing entities. At SceneXplain, however, we firmly believe that recognizing and addressing an algorithm's limitations is just as important as celebrating its capabilities. As stewards of technology with potential societal impact, we bear the ethical responsibility of being transparent about the bounds of our creations. Here, we outline some of the known limitations of the Inception algorithm, allowing users to deploy it with a complete understanding of its scope.</p><h3 id="challenges-with-keyframe-detection"><strong><strong>Challenges with Keyframe Detection</strong></strong></h3><ul><li><strong>Small Region Of Interest (ROI)</strong>: In videos taken from a considerable distance without significant movement, the ROI is minimal. This can trip up similarity detection algorithms, causing them to perceive all frames as alike. A potential consequence? A 5-minute video might yield just 1 or 2 keyframes, translating to significant content loss.</li><li><strong>Proliferation of Scenes</strong>: Videos with rapid scene changes, like movie trailers, pose unique challenges. A sub-3-minute trailer could contain over a hundred disparate scenes, leading to a glut of keyframes. This not only increases the computational burden but also risks omitting crucial scenes when we apply a "max keyframe ratio per minute" filter.</li><li><strong>Artistic Interpretations</strong>: Videos with specific artistic styles, such as macro shots, time-lapses, or drone footage, defy conventional detection paradigms. Depending on zoom levels and playback speed, these could either produce an overabundance of keyframes or too few.</li></ul><h3 id="nuances-in-keyframe-captioning"><strong><strong>Nuances in Keyframe Captioning</strong></strong></h3><ul><li><strong>Contextually Dependent Frames</strong>: Frames that are abstract or hinge on an external context can confound the algorithm. This leads to captions that range from slightly off-kilter to downright nonsensical. Computationally generated images, extreme zoom-ins, or artistic interpretations are classic culprits.</li><li><strong>Detecting Subtly Erroneous Captions</strong>: If a caption, while incorrect, aligns with the general context of the video, spotting such errors becomes challenging.</li><li><strong>Detail Disproportionality</strong>: A minor video element that's densely detailed might be accorded undue prominence over the main subject if it's relatively simpler. This can skew the narrative thread.</li><li><strong>Insufficient Details, Incorrect Associations</strong>: A recurring element across several keyframes, if not detailed enough, might be misinterpreted. For instance, the same individual appearing across multiple frames could be erroneously recognized as multiple people.</li></ul><p>Our commitment to transparency and continual improvement means we're always working on these challenges. However, we believe that only by acknowledging these limitations can we truly leverage the Inception algorithm ethically and responsibly.</p><h2 id="in-conclusion-the-journey-and-the-invitation">In Conclusion: The Journey and the Invitation</h2><p>The landscape of video comprehension has been evolving at a dizzying pace, and at SceneXplain, we're excited to be at the forefront of this revolution with our Inception algorithm. From understanding the nuances of complex narratives to grappling with the intricacies of contemporary culture, Inception promises a transformative experience in video-to-text translation.</p><p>However, as with all pioneering technologies, it's not without its challenges. We've approached these not as setbacks, but as opportunities for growth and refinement. Our transparency in sharing these challenges stems from a commitment to ethical and responsible AI development.</p><p>But, words can only convey so much. The true power and potential of Inception is best experienced firsthand. We invite you to try SceneXplain's Inception algorithm for yourself. Dive deep into its capabilities, test its boundaries, and witness how it can redefine your understanding of visual narratives.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SceneXplain - Explore image and video storytelling beyond pixels</div><div class="kg-bookmark-description">Leverage GPT-4 &amp; LLMs for the most advanced image storytelling. Explain visuals for content creators, media, &amp; e-commerce with rich captions, multilingual support, and seamless API integration. Experience the future of image description today.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://scenex.jina.ai/icons/apple-icon-180x180.png" alt=""><span class="kg-bookmark-author">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://scenex.jina.ai/banner.png" alt=""></div></a></figure><p>The future of video comprehension beckons, and with SceneXplain's Inception, you're not just a spectator – you're a part of the narrative. Come, join the story.</p></section></article><hr data-v-7478c13a="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-7478c13a="" class="row justify-between items-center q-py-md"><div data-v-7478c13a=""><span data-v-7478c13a="" class="text-weight-bold">Categories:</span><span data-v-7478c13a="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-icons q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Featured</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></span></div><div data-v-7478c13a=""><a data-v-7478c13a="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><div data-v-7478c13a="" class="q-img q-img--menu inline-block q-mr-md" role="img" size="40px" style="width: 24px; height: 24px;"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" height="0" width="0" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/hacker-news.e100deed.svg" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></a><a data-v-7478c13a="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><div data-v-7478c13a="" class="q-img q-img--menu inline-block q-mr-md" role="img" size="40px" style="width: 24px; height: 24px;"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" height="0" width="0" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/linkedin-logo.e0fc6323.svg" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></a><a data-v-7478c13a="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><div data-v-7478c13a="" class="q-img q-img--menu inline-block q-mr-md" role="img" size="40px" style="width: 24px; height: 24px;"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" height="0" width="0" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/twitter-logo.1c6cc30c.svg" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></a><a data-v-7478c13a="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><div data-v-7478c13a="" class="q-img q-img--menu inline-block q-mr-md" role="img" size="40px" style="width: 24px; height: 24px;"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" height="0" width="0" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/facebook-logo.60334dbf.svg" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></a><a data-v-7478c13a="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fhow-scenexplain-solves-video-to-text-comprehension%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><div data-v-7478c13a="" class="q-img q-img--menu inline-block q-mr-md" role="img" size="40px" style="width: 24px; height: 24px;"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" height="0" width="0" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reddit-logo.6852dc89.svg" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></a></div></div><hr data-v-7478c13a="" class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div data-v-7478c13a="" class="text-h6 text-grey-2 text-weight-bold q-mt-lg">Learn more</div><a data-v-7478c13a="" class="q-card q-card--dark q-dark q-card--flat no-shadow block cursor-pointer q-hoverable non-selectable q-my-md" href="/news/scenexplains-ocr-beats-gpt-4v-hands-down-chinese-japanese-korean-arabic-hindi-and-more" target="_blank" style="overflow: hidden; text-decoration: none !important;"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">SceneXplain's OCR beats GPT-4V hands down: Chinese, Japanese, Korean, Arabic, Hindi, and more!</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">SceneXplain beats GPT-4V by going beyond English, offering multilingual OCR for Chinese, Japanese, Korean, Arabic, Hindi and more</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-363418f9="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-363418f9="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-363418f9="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-363418f9="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Alex C-G</div><div class="q-item__label q-item__label--caption text-caption">November 16, 2023 • 13 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/11/sensex--3-.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></a><a data-v-7478c13a="" class="q-card q-card--dark q-dark q-card--flat no-shadow block cursor-pointer q-hoverable non-selectable q-my-md" href="/news/embeddings-in-depth" target="_blank" style="overflow: hidden; text-decoration: none !important;"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Embeddings in Depth</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">This second article in our series on embedding technology is much more concrete. It explains where embeddings come from and how they are used.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-363418f9="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-363418f9="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-363418f9="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-363418f9="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Scott Martens</div><div class="q-item__label q-item__label--caption text-caption">November 15, 2023 • 17 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/11/Explore-image-storytelling-beyond-pixels--18--1.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></a><a data-v-7478c13a="" class="q-card q-card--dark q-dark q-card--flat no-shadow block cursor-pointer q-hoverable non-selectable q-my-md" href="/news/look-up-in-the-sky-using-scenexplain-to-classify-land-use-from-satellite-data" target="_blank" style="overflow: hidden; text-decoration: none !important;"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Look, Up in the Sky! Using SceneXplain To Classify Land Use From Satellite Data</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">Unlock the Secrets of the Satellites: Leverage SceneXplain's powerful 'Extract JSON from Image' feature for land use classification</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-363418f9="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-363418f9="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-363418f9="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-363418f9="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Alex C-G</div><div class="q-item__label q-item__label--caption text-caption">November 06, 2023 • 9 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/11/Release-banner-DocArray.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></a></div></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow overflow-hidden print-hide"><video autoplay="" loop="" playsinline="" class="non-selectable" poster="/assets/portal-2-poster.44997122.webp" style="width: 100%; height: 420px; object-fit: cover;"><source src="/assets/portal-2.0da13c26.mp4" type="video/mp4"></video><div class="q-card q-card--dark q-dark q-card--flat no-shadow row absolute-left items-center bg-transparent non-selectable fit"><div class="text-white bg-transparent lock-blur fit q-pa-sm"><div class="row justify-between q-gutter-lg"><div class="col-12 col-md-3"><div class="q-list q-list--dark"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><strong>Offices</strong></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption">Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany</div><div class="q-item__label q-item__label--caption text-caption">Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption">Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption">402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div></div><div class="row text-caption justify-center q-mt-xl"> © Jina AI GmbH 2020-2023. All rights reserved.</div></div></div></div><footer class="q-footer q-layout__section--marginal fixed-bottom lock-blur bg-transparent print-hide"><div class="row"><div class="q-btn-group row no-wrap q-btn-group--flat inline col-12 col-md-6 justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-discord" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://twitter.com/jinaAI_/" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-twitter" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" type="button" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://www.youtube.com/c/JinaAI" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-youtube" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="https://www.meetup.com/jina-community-meetup/" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-meetup" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px; padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">email</i></span></a></div><div class="row col-12 col-md-6 items-center text-caption justify-center"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--stretch inline" no-caps=""><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="/legal/#privacy-policy" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy Policy</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="/legal/#terms-and-conditions" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Terms and Conditions</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch text-caption" tabindex="0" href="javascript:UC_UI.showSecondLayer();" style="padding: 8px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy Settings</span></span></a></div></div></div></footer></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>