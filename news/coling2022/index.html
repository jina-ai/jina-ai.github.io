<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>COLING2022 Summary on Multimodal AI</title><meta charset="utf-8"><meta name="title" content="COLING2022 Summary on Multimodal AI"><meta name="description" content="Last week I was in Gyeongju, Korea for the COLING2022 conference. COLING is the premier conference in computational linguistics held every two years. In this article, I will review the multimodal AI-related work in COLING 2022."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/coling2022"><meta property="og:title" content="COLING2022 Summary on Multimodal AI"><meta property="og:description" content="Last week I was in Gyeongju, Korea for the COLING2022 conference. COLING is the premier conference in computational linguistics held every two years. In this article, I will review the multimodal AI-related work in COLING 2022."><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Jina-AI-Website-Banners-Templates--7-.png"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/coling2022"><meta property="twitter:title" content="COLING2022 Summary on Multimodal AI"><meta property="twitter:description" content="Last week I was in Gyeongju, Korea for the COLING2022 conference. COLING is the premier conference in computational linguistics held every two years. In this article, I will review the multimodal AI-related work in COLING 2022."><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Jina-AI-Website-Banners-Templates--7-.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index.f301aac9.js"></script>
  <link rel="stylesheet" href="/assets/index.0ee94ae5.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n.569531fd.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.f5ca18aa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register.ff6bb4bb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip.c7172c86.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine.7e444272.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/selection.0c8a54f6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard.ec7de925.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.f301aac9.js"><link rel="stylesheet" href="/assets/prism-tomorrow.cee05018.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout.f0bdb21a.js"><link rel="stylesheet" href="/assets/MainLayout.8e0f2d87.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTabs.90f094de.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSelect.42144b1a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip.e129ab2f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu.9f115aeb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTabPanels.9da62581.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-panel.949c9215.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup.f376c6a7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnGroup.ce0ff71f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem.6772dbb7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QImg.eaff7e26.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress.c281dca5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QForm.de7740c7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs.b23217a7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage.0049c477.js"><link rel="stylesheet" href="/assets/NewsPage.a2d2d37b.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/plugin-vue_export-helper.8fab680d.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge.cf8997d6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip.19fd163f.js"><link rel="stylesheet" href="/assets/SXTooltip.99e4405e.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard.bfa45b22.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ModelDropDown.386f8207.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/toNumber.c7c40f66.js"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Han Xiao"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="12 mins read"><meta property="article:published_time" content="2022-10-21T11:58:17.000+02:00"><meta property="article:modified_time" content="2024-01-24T19:32:06.000+01:00"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top text-white lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">notifications</i></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e931a967-277f-4a07-bfe0-345785dc0679" aria-label="Expand &quot;Products&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon mdi mdi-package-variant" aria-hidden="true" role="presentation"> </i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Products</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_e931a967-277f-4a07-bfe0-345785dc0679" style="display: none;"><div class="q-list q-list--dark" label="Products"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Enterprises</span><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding.a8bdf010.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">Our world-class embeddings for search, RAG, agent systems.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker.9d8d3b88.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">Maximize the search relevancy and RAG accuracy at ease.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader.2a3a364b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reader</div><div class="q-item__label q-item__label--caption text-caption">Read URLs or search the web, get better grounding for LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/fine-tuning"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetune.2452513f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Auto Fine-Tuning</div><div class="q-item__label q-item__label--caption text-caption">Get fine-tuned embeddings for any domain you want.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Power Users</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_446f5715-31da-4abc-9060-b88529140150" aria-label="Expand &quot;More power user tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More power user tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_446f5715-31da-4abc-9060-b88529140150" style="display: none;"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Developers</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/docarray/docarray" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/doc-array.35372518.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DocArray</div><div class="q-item__label q-item__label--caption text-caption">The data structure for multimodal data</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jina" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/core.99751891.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jina</div><div class="q-item__label q-item__label--caption text-caption">Build multimodal AI applications on the cloud</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_b6529666-6473-417d-b1ad-38e67a8ce1ce" aria-label="Expand &quot;More developer tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More developer tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_b6529666-6473-417d-b1ad-38e67a8ce1ce" style="display: none;"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/clip-as-service" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/clip-as-service.f454ca2a.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">CLIP-as-service</div><div class="q-item__label q-item__label--caption text-caption">Embed images and sentences into fixed-length vectors with CLIP</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/finetuner" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetuner.c62eaafa.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Finetuner</div><div class="q-item__label q-item__label--caption text-caption">Fine-tune embeddings on domain specific data for better search quality</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jcloud" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jcloud.669910ba.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JCloud</div><div class="q-item__label q-item__label--caption text-caption">Deploy a local project as a cloud service. Radically easy, no nasty surprises.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/langchain-serve" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/langchain-serve.8cf53254.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">LangChain-Serve</div><div class="q-item__label q-item__label--caption text-caption">Langchain apps on production with Jina &amp; FastAPI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/vectordb" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/VectorDB.46be6cc1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">VectorDB</div><div class="q-item__label q-item__label--caption text-caption">A Python vector database you just need - no more, no less</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/dalle-flow" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dall-e-flow.ea199b2d.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DALL-E Flow</div><div class="q-item__label q-item__label--caption text-caption">A human-in-the-Loop workflow for creating HD images from text</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/discoart" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/disco-art.f21a267f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DiscoArt</div><div class="q-item__label q-item__label--caption text-caption">Create compelling Disco Diffusion artworks in one line of code</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/thinkgpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/think-gpt.0a671280.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ThinkGPT</div><div class="q-item__label q-item__label--caption text-caption">Agent techniques to augment your LLM and push it beyond its limits</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/dev-gpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dev-gpt.a3e55036.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DevGPT</div><div class="q-item__label q-item__label--caption text-caption">Your virtual development team</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/rungpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/run-gpt.5571707e.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">RunGPT</div><div class="q-item__label q-item__label--caption text-caption">An open-source cloud-native of large multimodal models serving framework</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jerboa" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jerboa.af6b308b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jerboa</div><div class="q-item__label q-item__label--caption text-caption">An experimental finetuner for open-source LLMs</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_ae2f573b-56bf-4929-8dfc-d9823ef93c38" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_ae2f573b-56bf-4929-8dfc-d9823ef93c38" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://jina.ai/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Download logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-639a8fb5="" class="q-page" style="min-height: 100vh;"><div data-v-639a8fb5="" class="row justify-center q-gutter-lg"><div data-v-639a8fb5="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-xl q-mt-xl q-gutter-y-xl"><div data-v-639a8fb5="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">October 21, 2022</div><h1 data-v-639a8fb5="" class="text-weight-light text-center q-px-md text-h4 text-weight-medium">COLING2022 Summary on Multimodal AI</h1><div data-v-639a8fb5="" class="col row justify-center"><div data-v-639a8fb5="" class="col-8 col-sm-7 col-md-6 text-center text-subtitle1">Last week I was in Gyeongju, Korea for the COLING2022 conference. COLING is the premier conference in computational linguistics held every two years. In this article, I will review the multimodal AI-related work in COLING 2022.</div></div><div data-v-639a8fb5="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-639a8fb5="" class="q-img q-img--menu" role="img" aria-label="Group of students posing together at the COLING 2022 event, projecting a sense of camaraderie"><div style="padding-bottom: 50%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Group of students posing together at the COLING 2022 event, projecting a sense of camaraderie" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Jina-AI-Website-Banners-Templates--7-.png" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-639a8fb5="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><div data-v-639a8fb5="" class="col row justify-start items-center q-gutter-x-sm text-overline"><div data-v-945534d6="" data-v-639a8fb5="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-945534d6="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-945534d6="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-639a8fb5="" class="q-item__label">Han Xiao • 12 minutes read</div></div><article data-v-639a8fb5="" class="article"><section data-v-639a8fb5="" class="gh-content"><p>Last week I was in Gyeongju, Korea for the COLING2022 conference. COLING is the premier conference in computational linguistics held every two years. </p><p>The conference was very well organized, and the talks were very interesting. I learned a lot about the latest research in computational linguistics and NLP, such as automated writing evaluation and multi-hop question answering. I also had a chance to meet many old friends and make new ones at the Jina AI dinner event. </p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 1.33333 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9203.jpg" width="1600" height="1200" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/IMG_9203.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/IMG_9203.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9203.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 1.33333 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9214-1.jpg" width="1600" height="1200" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/IMG_9214-1.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/IMG_9214-1.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9214-1.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 0.750117 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9222.jpg" width="1600" height="2133" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/IMG_9222.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/IMG_9222.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9222.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 0.75 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9291.jpg" width="1200" height="1600" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/IMG_9291.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/IMG_9291.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9291.jpg 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 1.33333 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9295.jpg" width="1600" height="1200" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/IMG_9295.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/IMG_9295.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9295.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 1.33333 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9173.jpg" width="1600" height="1200" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/IMG_9173.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/IMG_9173.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/IMG_9173.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div></div></div><figcaption><p><span style="white-space: pre-wrap;">Dinner event hosted by Jina AI at COLING2022</span></p></figcaption></figure><p>In this article, I will review the multimodal AI-related work presented at COLING 2022. Despite being primarily an NLP conference, there were 26 presentations focused on multimodal AI, covering text-image, text-video, and text-speech domains. I would like to highlight three presentations that I found particularly interesting.</p><h2 id="are-visual-linguistic-models-commonsense-knowledge-bases">Are Visual-Linguistic Models Commonsense Knowledge Bases?</h2><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.491/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Are Visual-Linguistic Models Commonsense Knowledge Bases?</div><div class="kg-bookmark-description">Hsiu-Yu Yang, Carina Silberer. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.491.jpg" alt="" style="cursor: help;"></div></a></figure><p>We have all seen the huge potential for pretrained language models (PTLMs) over the last few years. Models such as Transformer and GPT have been widely used in many downstream tasks due to their potential as a commonsense knowledge base. However, the text corpora used to train PTLMs can make them very biased, and this can make them inconsistent and not very robust. In this paper, Yang and Silberer suggest that text corpora alone may be insufficient for knowledge acquisition and raise important questions for visual-linguistic models like UNITER, VILBERT, and CLIP:</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">🤔</div><div class="kg-callout-text">Can a language model with a visual component represent our physical world better?</div></div><p>They address this problem with probing questions like this one:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-8.png" class="kg-image" alt="Educational slide with a quiz asking where a mouse is likely to be found, depicting an attic bedroom, a bridge over the ocean, and a forest" width="704" height="350" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-8.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-8.png 704w" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Prompt-based zero-shot QA with visual input. QA pairs can be categorized into multiple commonsense dimensions to identify what sort of relational knowledge the model has acquired: part-whole, taxonomic, distinctness, similarity, quality, utility, creation, temporal, spatial, and desire. During experiments, the author selectively masks out image input to study the what commonsense knowledge the models have captured.</span></figcaption></figure><h3 id="which-dimensions-of-commonsense-do-visual-linguistic-models-possess-compared-to-text-only-ptlms">Which dimensions of commonsense do v<strong>isual-linguistic</strong> models possess compared to text-only PTLMs?</h3><p>Hsui-Yu shows that visual-linguistic (VL) models such as UNITER and VILBERT are better at <em>part-whole</em>, <em>spatial</em>, and <em>desire</em> dimensions but struggle with <em>taxonomic</em>, <em>distinctness,</em> and <em>temporal</em> dimension. In terms of <em>spatial </em>dimension, VL models consistently outperform RoBERTa by 8%. On non-visual related dimensions such as <em>taxonomic </em>and <em>temporal, </em>VL models underperform by 8%, which is understandable as taxonomy and temporality are rarely represented in images. When using real-world images for training VL, <em>distinctness </em>is also hard to learn because opposite concepts e.g. <em>flood </em>and <em>drought</em>, rarely come together in one picture.</p><h3 id="during-pretraining-does-explicit-visual-information-ie-images-benefit-commonsense-knowledge-encoding">During pretraining, does explicit visual information (i.e., images) benefit commonsense knowledge encoding? </h3><p>When adding a BERT pretrained with image captions, the advantage of VL models becomes less significant, even on the <em>spatial </em>dimension. This shows that image captions can already provide a good proxy for visual information. The only dimension that VL models outperform is <em>part-whole, </em>with a tiny margin though<em>.</em></p><h3 id="during-inference-is-explicit-visual-observation-ie-images-necessary-for-recalling-commonsense-knowledge">During inference, is explicit visual observation (i.e., images) necessary for recalling commonsense knowledge? </h3><p>The above experiments have not used the visual input during the zero-shot QA task, so a natural question is, will adding images help? The answer is no. Visual information just makes everything worse. In fact, experiments show that all dual-stream (textual + visual) models underperform compared to their text-only counterparts on <em>part-whole</em>, <em>spatial, taxonomic</em>, and <em>distinctness </em>dimensions. This suggests that the texts are the driving force for successful inference on purely linguistic tasks. </p><p>What I found interesting about this work is the demystifying of the multimodal model, showing that although state-of-the-art VL models do encode complementary knowledge types to pure language models, the way that they combine visual and textual signals is still very primitive and not human-like at all.</p><h2 id="dual-capsule-attention-mask-network-with-mutual-learning-for-visual-question-answering">Dual Capsule Attention Mask Network with Mutual Learning for Visual Question Answering</h2><p>It is worth mentioning that the probing task from the last work is <strong>not </strong>a visual question-answering (VQA) task, though it contains QA pairs and images. A formal VQA task looks like the following:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-9.png" class="kg-image" alt="Concept map with &quot;VQA Model&quot; central node, &quot;Sleeping&quot; sub-node, and image of dog lying on pavement with bicycle" width="1124" height="578" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-9.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-9.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-9.png 1124w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">The goal of VQA is to answer questions related to the content of images correctly. It has a wide range of practical applications, such as helping people with visual impairments and human-computer Q&amp;A</span></figcaption></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.500/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Dual Capsule Attention Mask Network with Mutual Learning for Visual Question Answering</div><div class="kg-bookmark-description">Weidong Tian, Haodong Li, Zhong-Qiu Zhao. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.500.jpg" alt="" style="cursor: help;"></div></a></figure><p>The challenge of the VQA task is how to leverage fine-grained features with critical information to ensure that feature extraction emphasizes the objects related to the questions. Let's see two examples below:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-10.png" class="kg-image" alt="Split image with a girl on a horse wearing a helmet on the left, and a multi-purpose bedroom with a bed, desk, and electronics on the right" width="1486" height="706" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-10.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-10.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-10.png 1486w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>In the left example, the fine-grained features with attention have the critical information required for the answer inference, which helps the model generate the correct answer by eliminating irrelevant factors that could interfere. In the right example, unattended coarse-grained features contain the richer semantic information needed for a correct answer.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">🤔</div><div class="kg-callout-text">Can we combine global coarse-grained information and local fine-grained information to provide better information for the VQA task?</div></div><p>Weidong et al. address that in their paper. They propose a dual capsule attention mask network (DCAMN) with mutual learning for VQA.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-11.png" class="kg-image" alt="Diagram of a deep learning network with coarse-grained and fine-grained branches, decoders, and fusion blocks labeled" width="2000" height="1115" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-11.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-11.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/10/image-11.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2022/10/image-11.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>DCAMN can process features at different granularities, taking global information into account and focusing on critical information. Combining different perspectives and granularities can improve the generalization capability of the model and make more accurate predictions. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-12.png" class="kg-image" alt="Table displaying text classification performance by method, with columns for Test-dev, Test-std, and All, including numerical scores" width="1450" height="764" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-12.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-12.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-12.png 1450w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">DCAMN performance on three types of VQA: yes/no, number, and others</span></figcaption></figure><p>In addition, the proposed DCAMN can effectively fuse multimodal features and locate evidence, improving the interpretability of the network, as the picture below illustrates:</p><figure class="kg-card kg-gallery-card kg-width-wide"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 0.947955 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-1.png" width="510" height="538" alt="" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 0.840741 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2-1.png" width="454" height="540" alt="" style="cursor: help;"></div></div></div></figure><p>The attention mechanism and the model's interpretability are of particular interest for explainable multimodal AI. </p><h2 id="in-the-wild-video-question-answering">In-the-Wild Video Question Answering</h2><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.496/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">In-the-Wild Video Question Answering</div><div class="kg-bookmark-description">Santiago Castro, Naihao Deng, Pingxuan Huang, Mihai Burzo, Rada Mihalcea. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.496.jpg" alt="" style="cursor: help;"></div></a></figure><p>As a temporal extension of Visual QA, Video QA plays an important role in the development of intelligent AI systems, as it enables the effective processing of modality and temporal information. In the example below, given a long-video and a question, a video QA system first aims to generate open-ended answers. Second, it retrieves visual support for a given question and answer, which is represented by a span.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-13.png" class="kg-image" alt="Man in forest using bow saw and handaxe on tree branch, with timestamps 00:00, 00:37, and 00:51, indicating action progression" width="2000" height="660" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-13.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-13.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/10/image-13.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-13.png 2338w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Finding the relevant frames in a video for a given question-answer pair can help a system in its reasoning process, and is in line with ongoing efforts to build interpretable models</span></figcaption></figure><p>Much of the existing work on Video QA is based on the MovieQA (Tapaswi et al., 2016), and TVQA (Lei et al., 2018) datasets, which focus on common human activities in a multiple-choice setting. These datasets consist primarily of video from cooking videos or movies, making them very limited in domain.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-15.png" class="kg-image" alt="Comparative table of video QA datasets, indicating metrics like video counts, questions, average duration, and annotations" width="2000" height="785" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-15.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-15.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/10/image-15.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2022/10/image-15.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Comparison between WILDQA and other existing datasets. VE?: Whether the dataset provides “Video Evidences”?; MC: “Multiple Choice” question answering; OE: “Open Ended” question answering; ES: “Evidence Selection”.</span></figcaption></figure><p>Santiago et al. propose the WildQA dataset and tasks that focus on scenes recorded in the outside world in an open-ended setting, like the example below:</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://jina-ai-gmbh.ghost.io/content/images/2022/10/media-thumbnail-ember964.jpg" data-kg-custom-thumbnail="">
            <div class="kg-video-container">
                <video src="https://jina-ai-gmbh.ghost.io/content/media/2022/10/Norwegian-Explorer_11-clip-54.mp4" poster="https://img.spacergif.org/v1/640x360/0a/spacer.png" width="640" height="360" playsinline="" preload="metadata" style="background: transparent url('https://jina-ai-gmbh.ghost.io/content/images/2022/10/media-thumbnail-ember964.jpg') 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">1:16</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1×</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"></path>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">Q1: What kinds of bodies of water are there? A1: There are rivers and streams. Evidence: 0:07 - 0:14</span></p></figcaption>
        </figure><h2 id="multi-task-learning-of-t5-model-with-i3d-features">Multi-Task Learning of T5 Model with I3D Features</h2><p>To solve WildQA, Santiago et al. concatenate the text features with the visual features and input the concatenated features to the T5 model. They extract <a href="https://iashin.ai/video_features/models/i3d/?ref=jina-ai-gmbh.ghost.io">I3D video features</a> and take one feature per second.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-16.png" class="kg-image" alt="Diagram of a deep reinforcement learning model for video game question-answering featuring extractors, encoders, and decoders" width="2000" height="1107" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-16.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-16.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/10/image-16.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-16.png 2270w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>T5 encoder outputs a sequence of the encoded states. Santiago et al. treat the subsequence corresponding to the visual features as the encoded hidden sequence for the video frames. They then multiply the sequence with two vectors to get the maximum likelihood prediction of the start and the end of the evidence, respectively.</p><p>The tasks of visual evidence selection and video question-answering can be jointly trained together by simply combining the two losses in a weighted-manner. </p><p>In the experiment, Santiago et al. propose multiple baselines including: randomly choosing answers from the dev set (i.e. Random); always predicting the most common answer in the dev set (i.e. Common); and retrieving the answers for the dev set question whose embedding has the highest cosine similarity to the test question (i.e. Closest).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-17.png" class="kg-image" alt="Table comparing performance metrics like ROUGE scores and IOU-F1 for models including Random, Closest, T5, and Human" width="2000" height="701" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-17.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-17.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/10/image-17.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-17.png 2020w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Performance on video question-answering, measured by ROUGE score (left); and on video evidence selection (right) measured by Intersection-Over-Union. IOU is defined as the length of their intersection divided by the length of their union. The prediction is counted as a match if it overlaps with any of the ground truth spans by more than the threshold. They then use these partial matches to calculate an F1 score (i.e. IOU-F1 scores).</span></figcaption></figure><p>I noticed that introducing video information (T5 T+V) does not improve performance on video question-answering tasks, which confirms what Yang &amp; Silberer said in their work. This may also due to the types of questions in WildQA, which do not match commonsense knowledge. In the video evidence selection task, the T5 model is not even better than the random baseline. Adding multi-task learning does not help. In general, we can conclude WildQA is a pretty challenging task with a significant gap between the state-of-the-art multimodal model and human. </p><h2 id="other-interesting-multimodal-research">Other Interesting Multimodal Research</h2><h3 id="multimodal-social-media">Multimodal Social Media</h3><p>There are multiple research projects focusing on multimodality in the social media. For example, the upswing of text and image sharing on social media platforms during mass emergency situations has led to numerous opportunities to gain timely access to valuable information that can help disaster relief authorities act more quickly and more efficiently.</p><p>Iustin et al. extend the <a href="https://arxiv.org/abs/2001.07685?ref=jina-ai-gmbh.ghost.io">FixMatch algorithm</a> to a multimodal scenario and offer two extensions to the original approach relevant for text and multimodal datasets. They show that multimodal FixMatch can leverage inexpensive unlabeled data to improve performance on diaster classification tasks.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.239/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Multimodal Semi-supervised Learning for Disaster Tweet Classification</div><div class="kg-bookmark-description">Iustin Sirbu, Tiberiu Sosea, Cornelia Caragea, Doina Caragea, Traian Rebedea. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.239.jpg" alt="" style="cursor: help;"></div></a></figure><p>Extracting spatial information from social media and tweets has also received substantial attention recently. Zhaomin et al. propose BERT+VGG16 multimodal model to determine whether people are located in the places they mention in their tweets.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.226/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Are People Located in the Places They Mention in Their Tweets? A Multimodal Approach</div><div class="kg-bookmark-description">Zhaomin Xiao, Eduardo Blanco. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.226.jpg" alt="" style="cursor: help;"></div></a></figure><p>To better understand when the text and image are most beneficial, Zhaomin et al. perform a qualitative analysis of the errors made by the single-stream model, and how these errors are fixed by the dual-stream model. </p><p>Social media is a good place to conduct sentiment analysis. As a popular way to express emotion on social media, stickers &amp; memes in posts can supplement missing sentiments and help identify sentiments precisely. Stickers and memes, despite being represented as images or simple gifs, have very different semantics from real-world photos. Feng et al. point out three challenges when working with stickers/memes:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.591/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Towards Exploiting Sticker for Multimodal Sentiment Analysis in Social Media: A New Dataset and Baseline</div><div class="kg-bookmark-description">Feng Ge, Weizhao Li, Haopeng Ren, Yi Cai. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.591.jpg" alt="" style="cursor: help;"></div></a></figure><ul><li>First, stickers may be inherently multimodal because they are embedded with texts. Same sticker with different sticker texts may vary significantly in sentiment.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/image-18.png" class="kg-image" alt="Collage of Philosoraptor memes depicting philosophical and humorous questions related to the meme genre" width="2000" height="1038" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2022/10/image-18.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2022/10/image-18.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2022/10/image-18.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2022/10/image-18.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Millennial Humor on "Philosoraptor"</span></figcaption></figure><ul><li>Second, stickers are highly varied in style, preventing the models from learning robust representations.</li><li>Third, the way sentiment is fused together from text and stickers is complicated and sometimes inconsistent.</li></ul><p>This work actually reminds me a popular Youtube video explaining Gen Z humor and their meme behaviors:</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-text">Popular = Not Funny<br>Was popular = Funny<br>Ironic = Funny<br>Make no sense = Funny<br>Unfunny = Funny</div></div><p>There's nothing that Gen-Zers like more than changing and hating things. So perhaps our models on sentiment analysis have become obsolete? </p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/oVlspd9hxFA?start=61&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Why is Gen Z Humor So Weird?"></iframe></figure><h3 id="text-gestures-multimodal">Text-Gestures Multimodal</h3><p>Communication is a multimodal process. Information from verbal and non-verbal modalities are mixed into one channel. It has been revealed from a long history of empirical studies that speakers’ expression in the visual modality, including gestures, body poses, eye contacts and other types of non-verbal behaviors, play critical roles in face-to-face communication, because they add subtle information that is hard to convey in verbal language.</p><p>Yang etc. consider gestures as non-verbal communication and prove that non-verbal communication also conforms to the principle of entropy rate constancy (ERC). Under this assumption, communication in any form (written or spoken) should optimize the rate of information transmission rate by keeping the overall entropy rate constant.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.12/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Gestures Are Used Rationally: Information Theoretic Evidence from Neural Sequential Models</div><div class="kg-bookmark-description">Yang Xu, Yang Cheng, Riya Bhatia. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.12.jpg" alt="" style="cursor: help;"></div></a></figure><p>This means that the information encoded in hand gestures, albeit subtle, is actually organized in a rational way that enhances the decoding/understanding of information from a receiver’s perspective.</p><p>Artem etc. consider human gestures together with their corresponding utterances. They explore a multimodal approach to learning gesture embeddings through contrastive learning, and attempt to predict psycholinguistic categories and the language of the speaker from their gesture embeddings.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.488/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Towards Understanding the Relation between Gestures and Language</div><div class="kg-bookmark-description">Artem Abzaliev, Andrew Owens, Rada Mihalcea. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.488.jpg" alt="" style="cursor: help;"></div></a></figure><h3 id="text-image-multimodal-but-via-topic-modelling">Text-Image Multimodal, but via Topic Modelling</h3><p>Perhaps the most surprising work to me is from Elaine et al., who present a novel neural multilingual and multimodal topic model that takes advantage of pretrained document and image embeddings to abstract the complexities between languages and modalities. Their work is based on the contextualized topic model, a family of topic models that uses contextualized document embeddings as input.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aclanthology.org/2022.coling-1.355/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Multilingual and Multimodal Topic Modelling with Pretrained Embeddings</div><div class="kg-bookmark-description">Elaine Zosa, Lidia Pivovarova. Proceedings of the 29th International Conference on Computational Linguistics. 2022.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://aclanthology.org/aclicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">ACL Anthology</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://aclanthology.org/thumb/2022.coling-1.355.jpg" alt="" style="cursor: help;"></div></a></figure><p>It surprises me that after more than 12 years, Latent Dirichlet Allocation (LDA) models still show up in top conferences like COLING. After reading through the paper, I found a lot of adoption has been made over the last few years to make the original LDA more "deep". In fact, it is now called neural topic models (NTMs), which refers to a class of topic models that use neural networks to estimate the parameters of the topic-word and document-topic distributions.</p><h2 id="summary">Summary</h2><p>There has been some great work on multimodal AI presented at COLING this year. It is clear that this is a subject that is only going to continue to grow in importance, as I pointed out in the blog post below.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/paradigm-shift-towards-multimodal-ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">The Paradigm Shift Towards Multimodal AI</div><div class="kg-bookmark-description">We are on the cusp of a new era in AI, one in which multimodal AI will be the norm. At Jina AI, our MLOps platform helps businesses and developers win while they’re right at the starting line of this paradigm shift, and build the applications of the future today.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/android-icon-192x192.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span><span class="kg-bookmark-publisher">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/7.png" alt="" style="cursor: help;"></div></a></figure><p>Multimodal AI allows machines to better understand the world around them by processing data from multiple modalities (e.g. text, images, audio). This is an important step towards true artificial general intelligence, as it allows machines to more closely approximate the way humans process information.</p></section></article><div data-v-639a8fb5="" class="row justify-between items-center q-py-md"><div data-v-639a8fb5=""><span data-v-639a8fb5="" class="text-weight-bold">Categories:</span><span data-v-639a8fb5="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius lock-blur" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Events</div></div></div></span></div><div data-v-639a8fb5=""><div data-v-639a8fb5="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-639a8fb5="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fcoling2022%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-639a8fb5="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-639a8fb5="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fcoling2022%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-639a8fb5="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-639a8fb5="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fcoling2022%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-639a8fb5="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-639a8fb5="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fcoling2022%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-639a8fb5="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-639a8fb5="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fcoling2022%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-639a8fb5="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-639a8fb5="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-639a8fb5="" class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="text-h5 text-grey-2 q-my-xl">Top-5 similar articles</div><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline row full-width"><button class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square col-auto" tabindex="0" type="button" style="padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row no-wrap text-no-wrap"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">play_arrow</i><span class="block">Get top-5</span></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square q-btn-dropdown q-btn-dropdown--simple col" tabindex="0" type="button" aria-expanded="false" aria-haspopup="true" aria-controls="f_3b703c9f-ffe9-45ce-8a22-1126e32c3c14" aria-label="Expand"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row no-wrap text-no-wrap"><i class="q-icon" aria-hidden="true" role="img"><img src="/assets/reranker.9d8d3b88.svg"></i><div class="full-width ellipsis q-pl-md"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label q-item__label--caption text-caption text-grey text-left">Select reranker</div><div class="q-item__label row justify-start">None</div></div></div><i class="q-icon fas fa-caret-down q-btn-dropdown__arrow q-btn-dropdown__arrow-container" aria-hidden="true" role="presentation"> </i></span></button></div><hr data-v-639a8fb5="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-639a8fb5="" class="text-h5 text-grey-2 q-my-xl">Read more</div><a data-v-639a8fb5="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/discover-the-hidden-business-value-in-images-with-scenexplain-martech-online-workshop"><div class="q-focus-helper" tabindex="-1"></div><div class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert col column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__label q-item__label--caption text-caption">January 26, 2024 • 2 minutes read</div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Discover the Hidden Business Value in Images with SceneXplain | MarTech Online Workshop</div><div class="q-item__label q-item__label--caption text-caption text-grey-7" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Discover how SceneXplain, our AI tool, transforms images into valuable assets for marketers, advertisers, and e-commerce pros.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-945534d6="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-945534d6="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-945534d6="" class="q-img q-img--menu" role="img" aria-label="Miruna Nedelcu"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Miruna Nedelcu" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/miru.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div class="col-4 overflow-hidden"><div class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="An advertisement for a MarTech Online Workshop titled &quot;Use AI to Uncover the Business Value Behind Images,&quot; featuring a promi"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="An advertisement for a MarTech Online Workshop titled &quot;Use AI to Uncover the Business Value Behind Images,&quot; featuring a promi" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/01/PP-workshop-slides--260-x-260-px---3000-x-890-px-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></a><a data-v-639a8fb5="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/a-tale-of-two-worlds-emnlp-2023-at-sentosa"><div class="q-focus-helper" tabindex="-1"></div><div class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert col column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__label q-item__label--caption text-caption">December 16, 2023 • 17 minutes read</div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">A Tale of Two Worlds: EMNLP 2023 at Sentosa</div><div class="q-item__label q-item__label--caption text-caption text-grey-7" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Just back from EMNLP2023 and my mind's still reeling! Witnessed NLP's seismic shift firsthand through daring papers and provocative posters that are challenging everything we thought we knew. Check out my take on the conference's boldest ideas.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-945534d6="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-945534d6="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-945534d6="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-945534d6="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-945534d6="" class="q-img q-img--menu" role="img" aria-label="Michael Günther"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" alt="Michael Günther" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div class="col-4 overflow-hidden"><div class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Illuminated sign reading &quot;EMNLP 2023 Entry&quot; mounted above a door, suggesting a conference entrance"><div style="padding-bottom: 52.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Illuminated sign reading &quot;EMNLP 2023 Entry&quot; mounted above a door, suggesting a conference entrance" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/12/Explore-image-storytelling-beyond-pixels--26-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></a><a data-v-639a8fb5="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/discover-the-latest-in-embeddings-at-emnlp-2023-in-person-bof-session"><div class="q-focus-helper" tabindex="-1"></div><div class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert col column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__label q-item__label--caption text-caption">December 01, 2023 • 2 minutes read</div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Discover the Latest in Embeddings at EMNLP 2023 In-Person BoF Session</div><div class="q-item__label q-item__label--caption text-caption text-grey-7" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Mark your calendars for an immersive BoF session on Embeddings at EMNLP 2023. Join us on December 9th from 11:00 AM to 12:30 PM, Singapore time, in the 'Aquarius 1' room for a deep dive into the latest embeddings.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-945534d6="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-945534d6="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-945534d6="" class="q-img q-img--menu" role="img" aria-label="Jina AI"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Jina AI" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div class="col-4 overflow-hidden"><div class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="White birds in flight on a black background with a red and white &quot;EMNLP 2023&quot; logo on the right"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" alt="White birds in flight on a black background with a red and white &quot;EMNLP 2023&quot; logo on the right" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/12/Explore-image-storytelling-beyond-pixels--25--1.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide bg-dark q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Offices</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption">Prinzessinnenstraße 19-20, 10969 Berlin, Germany</div><div class="q-item__label q-item__label--caption text-caption">Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption">Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption">402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dark col"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Enterprise</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Embeddings</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Reranker</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Reader</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/fine-tuning"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Auto Fine-Tuning</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">API Status</div></a></div><div class="q-list q-list--dark col"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Power Users</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">PromptPerfect</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">SceneXplain</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">BestBanner</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">JinaChat</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Rationale</div></a></div><div class="q-list q-list--dark col"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Company</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Newsroom</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="https://jina.ai/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Download logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a></div><div class="q-list q-list--dark col"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Terms</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; Conditions</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Privacy</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-grey-5" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Manage Cookies</div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none q-py-xl"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://twitter.com/jinaAI_/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-discord" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-linkedin" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-between q-gutter-x-sm col-12 col-md"><div class="q-btn-group row no-wrap q-btn-group--outline q-btn-group--square q-btn-group--stretch inline"><label class="q-field row no-wrap items-start q-field--outlined q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--float q-field--dense q-field--dark text-caption" for="f_06cd5125-1ec4-4a7e-b368-c7e19808f2d5"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-icons q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>English</span><input class="q-select__focus-target" id="f_06cd5125-1ec4-4a7e-b368-c7e19808f2d5" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_06cd5125-1ec4-4a7e-b368-c7e19808f2d5_lb"></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon fas fa-caret-down q-select__dropdown-icon" aria-hidden="true" role="presentation"> </i></div></div></div></label><button class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square q-pa-sm text-caption text-grey-5" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons-outlined" aria-hidden="true" role="img">science</i></span></button></div><div class="text-caption text-grey-5"> Jina AI GmbH © 2020-2024. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>