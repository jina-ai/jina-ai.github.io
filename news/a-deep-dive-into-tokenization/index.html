<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>A Deep Dive into Tokenization</title><meta charset="utf-8"><meta name="title" content="A Deep Dive into Tokenization"><meta name="description" content="Tokenization, in LLMs, means chopping input texts up into smaller parts for processing. So why are embeddings billed by the token?"><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/a-deep-dive-into-tokenization"><meta property="og:title" content="A Deep Dive into Tokenization"><meta property="og:description" content="Tokenization, in LLMs, means chopping input texts up into smaller parts for processing. So why are embeddings billed by the token?"><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled-design--25-.png"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/a-deep-dive-into-tokenization"><meta property="twitter:title" content="A Deep Dive into Tokenization"><meta property="twitter:description" content="Tokenization, in LLMs, means chopping input texts up into smaller parts for processing. So why are embeddings billed by the token?"><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled-design--25-.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index.972d0c95.js"></script>
  <link rel="stylesheet" href="/assets/index.23b63892.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n.62ebe3f7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.831150a1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register.13564c88.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip.b1fefeb4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine.635f06d1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard.4ac6927e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.972d0c95.js"><link rel="stylesheet" href="/assets/prism-tomorrow.cee05018.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout.6425e773.js"><link rel="stylesheet" href="/assets/MainLayout.8e0f2d87.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTabPanels.2c8ff90b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-panel.1f0eb05e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch.3df10340.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-cache.b0833c75.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel.f0d2d0ea.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTabs.24e9ca6f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver.9335fbc9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/rtl.4aeb06d5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown.834b8834.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QImg.2f9c79d2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu.3e7015aa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList.5b41d1db.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem.511c5e04.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollArea.e1e1c97a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan.d8eb0681.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding.29c3d233.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup.cfd95640.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSelect.ac524e98.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress.79092b91.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QForm.59e2b095.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs.0c4a61d8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/chunk.17bfede8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isArrayLike.a2a00cef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isObject.cef35763.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/toNumber.476d0739.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage.bc92852c.js"><link rel="stylesheet" href="/assets/NewsPage.735ff46f.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/AskAnythingToolTip.72be5f4c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge.ec94c9b9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip.1ee61b05.js"><link rel="stylesheet" href="/assets/SXTooltip.42218d5a.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard.08c7c20e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ModelDropDown.f3b6bdfb.js"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top text-white lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none" role="toolbar"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">reorder</i></span></button><hr class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-left" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--left q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(-300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">notifications</i></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_171d1a2f-d758-487d-a39e-bb45209240e9" aria-label="Expand &quot;Products&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon mdi mdi-package-variant" aria-hidden="true" role="presentation"> </i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Products</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_171d1a2f-d758-487d-a39e-bb45209240e9" style="display: none;"><div class="q-list q-list--dark" label="Products"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Enterprises</span><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding.a8bdf010.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">Our world-class embeddings for search, RAG, agent systems.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker.9d8d3b88.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">Maximize the search relevancy and RAG accuracy at ease.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader.2a3a364b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reader</div><div class="q-item__label q-item__label--caption text-caption">Read URLs or search the web, get better grounding for LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/fine-tuning"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetune.2452513f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Auto Fine-Tuning</div><div class="q-item__label q-item__label--caption text-caption">Get fine-tuned embeddings for any domain you want.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Power Users</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_7e280c43-257e-401e-9f68-626aee6b82ec" aria-label="Expand &quot;More power user tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More power user tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_7e280c43-257e-401e-9f68-626aee6b82ec" style="display: none;"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Developers</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/docarray/docarray" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/doc-array.35372518.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DocArray</div><div class="q-item__label q-item__label--caption text-caption">The data structure for multimodal data</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jina" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/core.99751891.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jina</div><div class="q-item__label q-item__label--caption text-caption">Build multimodal AI applications on the cloud</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_5f7bf9ac-feb7-46c7-a635-eb256478d726" aria-label="Expand &quot;More developer tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More developer tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_5f7bf9ac-feb7-46c7-a635-eb256478d726" style="display: none;"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/clip-as-service" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/clip-as-service.f454ca2a.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">CLIP-as-service</div><div class="q-item__label q-item__label--caption text-caption">Embed images and sentences into fixed-length vectors with CLIP</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/finetuner" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetuner.c62eaafa.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Finetuner</div><div class="q-item__label q-item__label--caption text-caption">Fine-tune embeddings on domain specific data for better search quality</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jcloud" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jcloud.669910ba.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JCloud</div><div class="q-item__label q-item__label--caption text-caption">Deploy a local project as a cloud service. Radically easy, no nasty surprises.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/langchain-serve" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/langchain-serve.8cf53254.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">LangChain-Serve</div><div class="q-item__label q-item__label--caption text-caption">Langchain apps on production with Jina &amp; FastAPI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/vectordb" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/VectorDB.46be6cc1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">VectorDB</div><div class="q-item__label q-item__label--caption text-caption">A Python vector database you just need - no more, no less</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/dalle-flow" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dall-e-flow.ea199b2d.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DALL-E Flow</div><div class="q-item__label q-item__label--caption text-caption">A human-in-the-Loop workflow for creating HD images from text</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/discoart" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/disco-art.f21a267f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DiscoArt</div><div class="q-item__label q-item__label--caption text-caption">Create compelling Disco Diffusion artworks in one line of code</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/thinkgpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/think-gpt.0a671280.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ThinkGPT</div><div class="q-item__label q-item__label--caption text-caption">Agent techniques to augment your LLM and push it beyond its limits</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/dev-gpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dev-gpt.a3e55036.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DevGPT</div><div class="q-item__label q-item__label--caption text-caption">Your virtual development team</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/rungpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/run-gpt.5571707e.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">RunGPT</div><div class="q-item__label q-item__label--caption text-caption">An open-source cloud-native of large multimodal models serving framework</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jerboa" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jerboa.af6b308b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jerboa</div><div class="q-item__label q-item__label--caption text-caption">An experimental finetuner for open-source LLMs</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_8840f460-e440-40c3-a341-935a37e34acb" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_8840f460-e440-40c3-a341-935a37e34acb" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/open-day"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Open day</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://jina.ai/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Download logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 524px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px;"></div></div><div class="row justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square text-caption q-pa-sm" tabindex="0" href="https://status.jina.ai" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Status</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square text-caption q-pa-sm" tabindex="0" href="/legal/#terms-and-conditions"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Terms</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square text-caption q-pa-sm" tabindex="0" href="/legal/#privacy-policy"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square q-pa-sm" tabindex="0" href="javascript:UC_UI.showSecondLayer();" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons-outlined" aria-hidden="true" role="img">settings</i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square q-pa-sm" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons-outlined" aria-hidden="true" role="img">science</i></span></button><label class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--float q-field--dense q-field--dark text-caption" for="f_43268e2e-1702-4286-b726-59b16df7b8d5"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-icons q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>English</span><input class="q-select__focus-target" id="f_43268e2e-1702-4286-b726-59b16df7b8d5" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_43268e2e-1702-4286-b726-59b16df7b8d5_lb"></div></div></div></div></label></div></div></aside></div><div class="q-page-container" style="padding-top: 56px; padding-bottom: 25px;"><main data-v-7c05b1fa="" class="q-page" style="min-height: 100vh;"><div data-v-7c05b1fa="" class="row justify-center q-gutter-lg"><div data-v-7c05b1fa="" class="col q-my-xl q-py-xl"><div data-v-7c05b1fa="" class="q-mx-md q-mx-md-xl q-px-md-md q-px-lg-lg q-px-xl-xl"><div data-v-7c05b1fa="" class="row justify-between items-center q-mt-lg"><a data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch col-auto" tabindex="0" href="/news"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">arrow_circle_left</i><span class="block">Back to Newsroom</span></span></a><div data-v-7c05b1fa="" class="col-auto"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius lock-blur" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></div></div><div data-v-7c05b1fa="" class="q-img q-img--menu q-mt-md" role="img" aria-label="Colorful speckled grid pattern with a mix of small multicolored dots on a black background, creating a mosaic effect."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Colorful speckled grid pattern with a mix of small multicolored dots on a black background, creating a mosaic effect." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled-design--25-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div><h1 data-v-7c05b1fa="" class="text-white q-pa-lg q-ma-none text-h4" style="background: rgba(0, 0, 0, 0.5);">A Deep Dive into Tokenization</h1><div data-v-7c05b1fa="" class="row justify-center q-mt-lg q-pt-lg"><div data-v-7c05b1fa="" class="box col-10 col-md-6"><i data-v-7c05b1fa="" class="fas fa-quote-left fa2"></i><div data-v-7c05b1fa="" class="text"><i data-v-7c05b1fa="" class="fas fa-quote-right fa1"></i><div data-v-7c05b1fa=""><p data-v-7c05b1fa="">Tokenization, in LLMs, means chopping input texts up into smaller parts for processing. So why are embeddings billed by the token?</p></div></div></div></div><div data-v-7c05b1fa="" class="row justify-center items-center q-mt-lg"><div data-v-7c05b1fa="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" data-v-7c05b1fa="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div data-v-7c05b1fa="" class="q-item__section column q-item__section--main justify-center text-grey-6"><div data-v-7c05b1fa="" class="q-item__label">Scott Martens</div><div data-v-7c05b1fa="" class="q-item__label q-item__label--caption text-caption text-grey-6 q-mt-sm">January 31, 2024 • 17 minutes read</div></div></div></div><article data-v-7c05b1fa="" class="article"><section data-v-7c05b1fa="" class="gh-content"><p>There are a lot of barriers to understanding AI models, some of them pretty big barriers, and they can stand in the way of implementing AI processes. But the first one many people encounter is understanding what we mean when talking about <strong>tokens</strong>. </p><p>One of the most important practical parameters in choosing an AI language model is the size of its context window — the maximum input text size — which is given in tokens, not words or characters or any other automatically recognizable unit.</p><p>Furthermore, embedding services are typically figured “per token,” meaning tokens are important to understanding your bill.</p><p>This can be very confusing if you aren’t clear about what a token is. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/01/Screenshot-2024-01-31-at-15.13.41.png" class="kg-image" alt="Jina Embeddings current price sheet (as of February 2024)." width="2000" height="1036" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/01/Screenshot-2024-01-31-at-15.13.41.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/01/Screenshot-2024-01-31-at-15.13.41.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/01/Screenshot-2024-01-31-at-15.13.41.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/01/Screenshot-2024-01-31-at-15.13.41.png 2000w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Jina Embeddings current price sheet (as of February 2024). Note that prices are stated per “1M tokens”.</span></figcaption></figure><p>But of all the confusing aspects of modern AI, tokens are probably the least complicated. This article will try to clarify what tokenization is, what it does, and why we do it that way.</p><h2 id="tldr">tl;dr</h2><p>For those who want or need a quick answer to figure out how many tokens to buy from Jina Embeddings or an estimate of how many they need to expect to buy, the following statistics are what you're looking for.</p><h3 id="tokens-per-english-word">Tokens per English Word</h3><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">A call to the Jina Embeddings v2 API for English models will use <b><strong style="white-space: pre-wrap;">approximately</strong></b> <b><strong style="white-space: pre-wrap;">10% more</strong></b> tokens than the number of words in your text, <b><strong style="white-space: pre-wrap;">plus two tokens per embedding</strong></b>.</div></div><p>During empirical testing, described further down in this article, a variety of English texts converted into tokens at a rate of about 10% more tokens than words, using Jina Embeddings English-only models. This result was pretty robust. </p><p>Jina Embeddings v2 models have a context window of 8192 tokens. This means that if you pass a Jina model an English text longer than 7,400 words, there is a good chance it will be truncated.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">The maximum size for input to <b><strong style="white-space: pre-wrap;">Jina Embeddings v2 for English</strong></b> is approximately <b><strong style="white-space: pre-wrap;">7,400 words</strong></b>.</div></div><h3 id="tokens-per-chinese-character">Tokens per Chinese Character</h3><p>For Chinese, results are more variable. Depending on the text type, ratios varied from 0.6 to 0.75 tokens per Chinese character (汉字). English texts given to Jina Embeddings v2 for Chinese produce approximately the same number of tokens as Jina Embeddings v2 for English: roughly 10% more than the number of words.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">The maximum size for input in Chinese to <b><strong style="white-space: pre-wrap;">Jina Embeddings v2 for Chinese and English</strong></b> is approximately <b><strong style="white-space: pre-wrap;">10,500 characters</strong></b> (<b><strong style="white-space: pre-wrap;">字数</strong></b>), or <b><strong style="white-space: pre-wrap;">0.6 to 0.75 tokens per Chinese character, plus two per embedding.</strong></b></div></div><h3 id="tokens-per-german-word">Tokens per German Word</h3><p>German word-to-token ratios are more variable than English but less than Chinese. Depending on the genre of the text, I got 20% to 30% more tokens than words on average. Giving English texts to Jina Embeddings v2 for German and English uses a few more tokens than the English-only and Chinese/English models: 12% to 15% more tokens than words.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Jina Embeddings v2 for German and English will count <b><strong style="white-space: pre-wrap;">20% to 30% more tokens than words, plus two per embedding</strong></b>. The maximum size of the input context is approximately <b><strong style="white-space: pre-wrap;">6,300 German words</strong></b>.</div></div><h3 id="caution">Caution!</h3><p>These are simple calculations, but they should be approximately right for most natural language texts and most users. Ultimately, we can only promise that the number of tokens will always be no more than the number of characters in your text, plus two. It will practically always be much less than that, but we cannot promise any specific count in advance.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">⚠️</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Your Mileage May Vary! </strong></b><br><br>These are estimates based on statistically naive calculations. We do not guarantee how many tokens any particular request will take.</div></div><p>If all you need is advice on how many tokens to buy for Jina Embeddings, you can stop here. Other embedding models, from companies other than Jina AI, may not have the same token-to-word and token-to-Chinese-character ratios Jina models have, but they will not generally be very different overall.</p><p>If you want to understand why, the rest of this article is a deeper dive into tokenization for language models.</p><h2 id="words-tokens-numbers">Words, Tokens, Numbers</h2><p>Tokenization has been a part of natural language processing for longer than modern AI models have existed.</p><p>It’s a bit cliché to say that everything in a computer is just a number, but it’s also mostly true. Language, however, is not naturally just a bunch of numbers. It might be speech, made of sound waves, or writing, made of marks on paper, or even an image of a printed text or a video of someone using sign language. But most of the time, when we talk about using computers to process natural language, we mean texts composed of sequences of characters: letters (a, b, c, etc.), numerals (0, 1, 2…), punctuation, and spaces, in different languages and textual encodings.</p><p>Computer engineers call these “strings”.</p><p>AI language models take sequences of numbers as input. So, you might write the sentence:</p><blockquote><em>What is today's weather in Berlin?</em></blockquote><p>But, after tokenization, the AI model gets as input:</p><pre><code class="language-python hljs">[<span class="hljs-number">101</span>, <span class="hljs-number">2054</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">2651</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">4633</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">4068</span>, <span class="hljs-number">1029</span>, <span class="hljs-number">102</span>]
</code></pre><p>Tokenization is the process of converting an input string into a specific sequence of numbers that your AI model can understand.</p><p>When you use an AI model via a web API that charges users per token, each request is converted into a sequence of numbers like the one above. The number of tokens in the request is the length of that sequence of numbers. So, asking Jina Embeddings v2 for English to give you an embedding for “<em>What is today's weather in Berlin?</em>” will cost you 11 tokens because it converted that sentence into a sequence of 11 numbers before passing it to the AI model.</p><p>AI models based on the <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)?ref=jina-ai-gmbh.ghost.io">Transformer architecture</a> have a fixed-size <strong>context window</strong> whose size is measured in tokens. Sometimes this is called an “input window,” “context size,” or “sequence length” (especially on the <a href="https://huggingface.co/spaces/mteb/leaderboard?ref=jina-ai-gmbh.ghost.io">Hugging Face MTEB leaderboard</a>). It means the maximum text size that the model can see at one time.</p><p>So, if you want to use an embedding model, this is the maximum input size allowed.</p><p>Jina Embeddings v2 models all have a context window of 8,192 tokens. Other models will have different (typically smaller) context windows. This means that however much text you put into it, the tokenizer associated with that Jina Embeddings model must convert it into no more than 8,192 tokens.</p><h2 id="mapping-language-to-numbers">Mapping Language to Numbers</h2><p>The simplest way to explain the logic of tokens is this:</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">A token is a number that stands in for a part of a string.</div></div><p>For natural language models, the part of a string that a token stands for is a word, a part of a word, or a piece of punctuation. Spaces are not generally given any explicit representation in tokenizer output.</p><p>Tokenization is part of a group of techniques in natural language processing called <a href="https://en.wikipedia.org/wiki/Text_segmentation?ref=jina-ai-gmbh.ghost.io"><em>text segmentation</em></a>, and the module that performs tokenization is called, very logically, a <strong>tokenizer</strong>.</p><p>To show how tokenization works, we’re going to tokenize some sentences using the smallest Jina Embeddings v2 for English model: <code>jina-embeddings-v2-small-en</code>. Jina Embeddings’ other English-only model — <code>jina-embeddings-v2-base-en</code> — uses the same tokenizer, so there’s no point in downloading extra megabytes of AI model that we won’t use in this article.</p><p>First, install the <code>transformers</code> module in your Python environment or notebook. Use the <code>-U</code> flag to make sure you upgrade to the latest version because this model will not work with some older versions:</p><pre><code class="language-bash hljs">pip install -U transformers
</code></pre><p>Then, download <a href="https://huggingface.co/jinaai/jina-embeddings-v2-small-en?ref=jina-ai-gmbh.ghost.io" rel="noreferrer"><code>jina-embeddings-v2-small-en</code></a> using <code>AutoModel.from_pretrained</code>:</p><pre><code class="language-Python hljs"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

model = AutoModel.from_pretrained(<span class="hljs-string">'jinaai/jina-embeddings-v2-small-en'</span>, trust_remote_code=<span class="hljs-literal">True</span>)
</code></pre><p>To tokenize a string, use the <code>encode</code> method of the <code>tokenizer</code> member object of the model:</p><pre><code class="language-Python hljs">model.tokenizer.encode(<span class="hljs-string">"What is today's weather in Berlin?"</span>)
</code></pre><p>The result is a list of numbers:</p><pre><code class="language-Python hljs">[<span class="hljs-number">101</span>, <span class="hljs-number">2054</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">2651</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">4633</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">4068</span>, <span class="hljs-number">1029</span>, <span class="hljs-number">102</span>]
</code></pre><p>To convert these numbers back to string forms, use the <code>convert_ids_to_tokens</code> method of the <code>tokenizer</code> object:</p><pre><code class="language-Python hljs">model.tokenizer.convert_ids_to_tokens([<span class="hljs-number">101</span>, <span class="hljs-number">2054</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">2651</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">4633</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">4068</span>, <span class="hljs-number">1029</span>, <span class="hljs-number">102</span>])
</code></pre><p>The result is a list of strings:</p><pre><code class="language-Python hljs">[<span class="hljs-string">'[CLS]'</span>, <span class="hljs-string">'what'</span>, <span class="hljs-string">'is'</span>, <span class="hljs-string">'today'</span>, <span class="hljs-string">"'"</span>, <span class="hljs-string">'s'</span>, <span class="hljs-string">'weather'</span>, <span class="hljs-string">'in'</span>,
 <span class="hljs-string">'berlin'</span>, <span class="hljs-string">'?'</span>, <span class="hljs-string">'[SEP]'</span>]
</code></pre><p>Note that the model’s tokenizer has:</p><ol><li>Added <code>[CLS]</code>at the beginning and <code>[SEP]</code> at the end. This is necessary for technical reasons and means that <strong>every request for an embedding will cost two extra tokens</strong>, above however many tokens the text takes.</li><li>Split punctuation from words, turning “<em>Berlin?</em>” into: <code>berlin</code> and <code>?</code>, and “<em>today’s</em>” into <code>today</code>, <code>'</code>, and <code>s</code>.</li><li>Put everything in lowercase. Not all models do this, but this can help with training when using English. It may be less helpful in languages where capitalization has a different meaning.</li></ol><p>Different word-counting algorithms in different programs might count the words in this sentence differently. OpenOffice counts this as six words. The Unicode text segmentation algorithm (<a href="https://unicode.org/reports/tr29/?ref=jina-ai-gmbh.ghost.io">Unicode Standard Annex #29</a>) counts seven words. Other software may come to other numbers, depending on how they handle punctuation and clitics like “’s.”</p><p>The tokenizer for this model produces nine tokens for those six or seven words, plus the two extra tokens needed with every request.</p><p>Now, let’s try with a less common place-name than Berlin:</p><pre><code class="language-Python hljs">token_ids = model.tokenizer.encode(<span class="hljs-string">"I live in Kinshasa."</span>)
tokens = model.tokenizer.convert_ids_to_tokens(token_ids)
<span class="hljs-built_in">print</span>(tokens)
</code></pre><p>The result:</p><pre><code class="language-Python hljs">[<span class="hljs-string">'[CLS]'</span>, <span class="hljs-string">'i'</span>, <span class="hljs-string">'live'</span>, <span class="hljs-string">'in'</span>, <span class="hljs-string">'kin'</span>, <span class="hljs-string">'##sha'</span>, <span class="hljs-string">'##sa'</span>, <span class="hljs-string">'.'</span>, <span class="hljs-string">'[SEP]'</span>]
</code></pre><p>The name “Kinshasa” is broken up into three tokens: <code>kin</code>, <code>##sha</code>, and <code>##sa</code>. The <code>##</code> indicates that this token is not the beginning of a word.</p><p>If we give the tokenizer something completely alien, the number of tokens over the number of words increases even more:</p><pre><code class="language-Python hljs">token_ids = model.tokenizer.encode(<span class="hljs-string">"Klaatu barada nikto"</span>)
tokens = model.tokenizer.convert_ids_to_tokens(token_ids)
<span class="hljs-built_in">print</span>(tokens)

[<span class="hljs-string">'[CLS]'</span>, <span class="hljs-string">'k'</span>, <span class="hljs-string">'##la'</span>, <span class="hljs-string">'##at'</span>, <span class="hljs-string">'##u'</span>, <span class="hljs-string">'bar'</span>, <span class="hljs-string">'##ada'</span>, <span class="hljs-string">'nik'</span>, <span class="hljs-string">'##to'</span>, <span class="hljs-string">'[SEP]'</span>]
</code></pre><p>Three words become eight tokens, plus the <code>[CLS]</code> and <code>[SEP]</code> tokens.</p><p>Tokenization in German is similar. With the <a href="https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Jina Embeddings v2 for German</a> model, we can tokenize a translation of "What is today's weather in Berlin?" the same way as with the English model.</p><pre><code class="language-Python hljs">german_model = AutoModel.from_pretrained(<span class="hljs-string">'jinaai/jina-embeddings-v2-base-de'</span>, trust_remote_code=<span class="hljs-literal">True</span>)
token_ids = german_model.tokenizer.encode(<span class="hljs-string">"Wie wird das Wetter heute in Berlin?"</span>)
tokens = german_model.tokenizer.convert_ids_to_tokens(token_ids)
<span class="hljs-built_in">print</span>(tokens)
</code></pre><p>The result:</p><pre><code class="language-python hljs">[<span class="hljs-string">'&lt;s&gt;'</span>, <span class="hljs-string">'Wie'</span>, <span class="hljs-string">'wird'</span>, <span class="hljs-string">'das'</span>, <span class="hljs-string">'Wetter'</span>, <span class="hljs-string">'heute'</span>, <span class="hljs-string">'in'</span>, <span class="hljs-string">'Berlin'</span>, <span class="hljs-string">'?'</span>, <span class="hljs-string">'&lt;/s&gt;'</span>]
</code></pre><p>This tokenizer is a little bit different from the English one in that <code>&lt;s&gt;</code> and <code>&lt;/s&gt;</code> replace <code>[CLS]</code> and <code>[SEP]</code> but serve the same function. Also, the text is not case-normalized — upper and lower cases remain as written — because capitalization is meaningful in German differently from English.</p><p>(To simplify this presentation, I removed a special character indicating a word's beginning.)</p><p>Now, let’s try a more complex sentence <a href="https://www.welt.de/politik/deutschland/plus249565102/Proteste-der-Landwirte-Die-Krux-mit-den-Foerdermitteln.html?ref=jina-ai-gmbh.ghost.io">from a newspaper text</a>:</p><blockquote>Ein Großteil der milliardenschweren Bauern-Subventionen bleibt liegen – zu genervt sind die Landwirte von bürokratischen Gängelungen und Regelwahn.</blockquote><pre><code class="hljs language-python">sentence = <span class="hljs-string">"""
Ein Großteil der milliardenschweren Bauern-Subventionen
bleibt liegen – zu genervt sind die Landwirte von 
bürokratischen Gängelungen und Regelwahn.
"""</span>
token_ids = german_model.tokenizer.encode(sentence)
tokens = german_model.tokenizer.convert_ids_to_tokens(token_ids)
<span class="hljs-built_in">print</span>(tokens)</code></pre><p>The tokenized result:</p><pre><code class="language-python hljs">[<span class="hljs-string">'&lt;s&gt;'</span>, <span class="hljs-string">'Ein'</span>, <span class="hljs-string">'Großteil'</span>, <span class="hljs-string">'der'</span>, <span class="hljs-string">'mill'</span>, <span class="hljs-string">'iarden'</span>, <span class="hljs-string">'schwer'</span>, 
 <span class="hljs-string">'en'</span>, <span class="hljs-string">'Bauern'</span>, <span class="hljs-string">'-'</span>, <span class="hljs-string">'Sub'</span>, <span class="hljs-string">'ventionen'</span>, <span class="hljs-string">'bleibt'</span>, <span class="hljs-string">'liegen'</span>, 
 <span class="hljs-string">'–'</span>, <span class="hljs-string">'zu'</span>, <span class="hljs-string">'gen'</span>, <span class="hljs-string">'ervt'</span>, <span class="hljs-string">'sind'</span>, <span class="hljs-string">'die'</span>, <span class="hljs-string">'Landwirte'</span>, <span class="hljs-string">'von'</span>, 
 <span class="hljs-string">'büro'</span>, <span class="hljs-string">'krat'</span>, <span class="hljs-string">'ischen'</span>, <span class="hljs-string">'Gän'</span>, <span class="hljs-string">'gel'</span>, <span class="hljs-string">'ungen'</span>, <span class="hljs-string">'und'</span>, <span class="hljs-string">'Regel'</span>, 
 <span class="hljs-string">'wahn'</span>, <span class="hljs-string">'.'</span>, <span class="hljs-string">'&lt;/s&gt;'</span>]
</code></pre><p>Here, you see that many German words were broken up into smaller pieces and not necessarily along the lines licensed by German grammar. The result is that a long German word that would count as just one word to a word counter might be any number of tokens to Jina’s AI model.</p><p>Let’s do the same in Chinese, translating ”What is today's weather in Berlin?” as:</p><blockquote>柏林今天的天气怎么样？</blockquote><pre><code class="hljs language-makefile">chinese_model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)
token_ids = chinese_model.tokenizer.encode(<span class="hljs-string">"柏林今天的天气怎么样？"</span>)
tokens = chinese_model.tokenizer.convert_ids_to_tokens(token_ids)
print(tokens)
</code></pre><p>The tokenized result:</p><pre><code class="language-Python hljs">[<span class="hljs-string">'&lt;s&gt;'</span>, <span class="hljs-string">'柏林'</span>, <span class="hljs-string">'今天的'</span>, <span class="hljs-string">'天气'</span>, <span class="hljs-string">'怎么样'</span>, <span class="hljs-string">'？'</span>, <span class="hljs-string">'&lt;/s&gt;'</span>]
</code></pre><p>In Chinese, there are usually no word breaks in written text, but the Jina Embeddings tokenizer frequently joins multiple Chinese characters together:</p>

<table>
<thead>
<tr>
<th>Token string</th>
<th>Pinyin</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>柏林</td>
<td>Bólín</td>
<td>Berlin</td>
</tr>
<tr>
<td>今天的</td>
<td>jīntiān de</td>
<td>today’s</td>
</tr>
<tr>
<td>天气</td>
<td>tiānqì</td>
<td>weather</td>
</tr>
<tr>
<td>怎么样</td>
<td>zěnmeyàng</td>
<td>how</td>
</tr>
</tbody>
</table>

<p>Let’s use a more complex sentence <a href="https://news.mingpao.com/pns/%e6%b8%af%e8%81%9e/article/20240116/s00002/1705335848777/%e7%81%a3%e5%8d%80%e7%86%b1%e6%90%9c-%e7%a9%97%e5%9c%b0%e9%90%b5%e6%8e%a8%e6%89%8b%e6%a9%9f%e3%80%8c%e9%9d%9c%e9%9f%b3%e4%bb%a4%e3%80%8d-%e7%84%a1%e7%bd%b0%e5%89%87-%e5%b8%82%e6%b0%91%e6%9c%89%e7%a8%b1%e5%85%b7%e8%ad%a6%e7%a4%ba%e4%bd%9c%e7%94%a8-%e6%9c%89%e6%84%9f%e5%af%a6%e6%95%88%e4%b8%8d%e5%a4%a7?ref=jina-ai-gmbh.ghost.io">from a Hong Kong-based newspaper</a>:</p><pre><code class="language-Python hljs">sentence = <span class="hljs-string">"""
新規定執行首日，記者在下班高峰前的下午5時來到廣州地鐵3號線，
從繁忙的珠江新城站啟程，向機場北方向出發。
"""</span>
token_ids = chinese_model.tokenizer.encode(sentence)
tokens = chinese_model.tokenizer.convert_ids_to_tokens(token_ids)
<span class="hljs-built_in">print</span>(tokens)
</code></pre><p>(Translation: <em>“On the first day that the new regulations were in force, this reporter arrived at Guangzhou Metro Line 3 at 5 p.m., during rush hour, having departed the Zhujiang New Town Station heading north towards the airport.”</em>)</p><p>The result:</p><pre><code class="language-python hljs">[<span class="hljs-string">'&lt;s&gt;'</span>, <span class="hljs-string">'新'</span>, <span class="hljs-string">'規定'</span>, <span class="hljs-string">'執行'</span>, <span class="hljs-string">'首'</span>, <span class="hljs-string">'日'</span>, <span class="hljs-string">'，'</span>, <span class="hljs-string">'記者'</span>, <span class="hljs-string">'在下'</span>, <span class="hljs-string">'班'</span>, 
 <span class="hljs-string">'高峰'</span>, <span class="hljs-string">'前的'</span>, <span class="hljs-string">'下午'</span>, <span class="hljs-string">'5'</span>, <span class="hljs-string">'時'</span>, <span class="hljs-string">'來到'</span>, <span class="hljs-string">'廣州'</span>, <span class="hljs-string">'地'</span>, <span class="hljs-string">'鐵'</span>, <span class="hljs-string">'3'</span>, 
 <span class="hljs-string">'號'</span>, <span class="hljs-string">'線'</span>, <span class="hljs-string">'，'</span>, <span class="hljs-string">'從'</span>, <span class="hljs-string">'繁忙'</span>, <span class="hljs-string">'的'</span>, <span class="hljs-string">'珠江'</span>, <span class="hljs-string">'新城'</span>, <span class="hljs-string">'站'</span>, <span class="hljs-string">'啟'</span>, 
 <span class="hljs-string">'程'</span>, <span class="hljs-string">'，'</span>, <span class="hljs-string">'向'</span>, <span class="hljs-string">'機場'</span>, <span class="hljs-string">'北'</span>, <span class="hljs-string">'方向'</span>, <span class="hljs-string">'出發'</span>, <span class="hljs-string">'。'</span>, <span class="hljs-string">'&lt;/s&gt;'</span>]
</code></pre><p>These tokens do not map to any specific dictionary of Chinese words (词典). For example, “啟程” - <em>qǐchéng</em> (depart, set out) would typically be categorized as a single word but is here split into its two constituent characters. Similarly, “在下班” would usually be recognized as two words, but with the split between “在” - <em>zài</em> (in, during) and “下班” - <em>xiàbān</em> (the end of the workday, rush hour), not between “在下” and “班” as the tokenizer has done here.</p><p>In all three languages, the places where the tokenizer breaks the text up are not directly related to the logical places where a human reader would break them.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">The tokenizer algorithm does not use a conventional, language-aware dictionary, so its behavior does not match how humans count words.</div></div><p>This is not a specific feature of Jina Embeddings models. This approach to tokenization is almost universal in AI model development. Although two different AI models may not have identical tokenizers, in the current state of development, they will practically all use tokenizers with this kind of behavior.</p><p>The next section will discuss the specific algorithm used in tokenization and the logic behind it.</p><h2 id="why-do-we-tokenize-and-why-this-way">Why Do We Tokenize? And Why This Way?</h2><p>AI language models take as input sequences of numbers that stand in for text sequences, but a bit more happens before running the underlying neural network and creating an embedding. When presented with a list of numbers representing small text sequences, the model looks each number up in an internal dictionary that stores a unique vector for each number. It then combines them, and that becomes the input to the neural network.</p><p>This means that the tokenizer <strong>must</strong> be able to convert <strong><em>any</em></strong> input text we give it into tokens that appear in the model’s dictionary of token vectors. If we took our tokens from a conventional dictionary, the first time we encountered a misspelling or a rare proper noun or foreign word, the whole model would stop. It could not process that input.</p><p>In natural language processing, this is called the out-of-vocabulary (OOV) problem, and it’s pervasive in all text types and all languages. There are a few strategies for addressing the OOV problem:</p><ol><li>Ignore it. Replace everything not in the dictionary with an “unknown” token.</li><li>Bypass it. Instead of using a dictionary that maps text sequences to vectors, use one that maps <em>individual characters</em> to vectors. English only uses 26 letters most of the time, so this must be smaller and more robust against OOV problems than any dictionary.</li><li>Find frequent subsequences in the text, put them in the dictionary, and use characters (single-letter tokens) for whatever is left.</li></ol><p>The first strategy means that a lot of important information is lost. The model can’t even learn about the data it’s seen if it takes the form of something not in the dictionary. A lot of things in ordinary text are just not present in even the largest dictionaries.</p><p>The second strategy is possible, and researchers have investigated it. However, it means that the model has to accept a lot more input and has to learn a lot more. This means a much bigger model and much more training data for a result that has never proven to be any better than the third strategy.</p><p>AI language models pretty much all implement the third strategy in some form. Most use some variant of the <a href="https://huggingface.co/learn/nlp-course/chapter6/6?ref=jina-ai-gmbh.ghost.io">Wordpiece algorithm</a> <a href="https://ieeexplore.ieee.org/document/6289079?ref=jina-ai-gmbh.ghost.io">[Schuster and Nakajima 2012]</a> or a similar technique called <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding?ref=jina-ai-gmbh.ghost.io">Byte-Pair Encoding</a> (BPE). [<a href="https://www.drdobbs.com/a-new-algorithm-for-data-compression/184402829?ref=jina-ai-gmbh.ghost.io">Gage 1994</a>, <a href="https://aclanthology.org/P16-1162/?ref=jina-ai-gmbh.ghost.io">Senrich et al. 2016</a>] These algorithms are <em>language-agnostic</em>. That means they work the same for all written languages without any knowledge beyond a comprehensive list of possible characters. They were designed for multilingual models like Google’s BERT that take just any input from scraping the Internet — hundreds of languages and texts other than human language like computer programs — so that they could be trained without doing complicated linguistics.</p><p>Some research shows significant improvements using more language-specific and language-aware tokenizers. [<a href="https://aclanthology.org/2021.acl-long.243/?ref=jina-ai-gmbh.ghost.io">Rust et al. 2021</a>] But building tokenizers that way takes time, money, and expertise. Implementing a universal strategy like BPE or Wordpiece is much cheaper and easier.</p><p>However, as a consequence, there is no way to know how many tokens a specific text represents other than to run it through a tokenizer and then count the number of tokens that come out of it. Because the smallest possible subsequence of a text is one letter, you can be sure the number of tokens won’t be larger than the number of characters (minus spaces) plus two.</p><p>To get a good estimate, we need to throw a lot of text at our tokenizer and calculate empirically how many tokens we get on average, compared to how many words or characters we input. In the next section, we’ll do some not-very-systematic empirical measurements for all Jina Embeddings v2 models currently available.</p><h2 id="empirical-estimates-of-token-output-sizes">Empirical Estimates of Token Output Sizes</h2><p>For English and German, I used the Unicode text segmentation algorithm (<a href="https://unicode.org/reports/tr29/?ref=jina-ai-gmbh.ghost.io">Unicode Standard Annex #29</a>) to get word counts for texts. This algorithm is widely used to select text snippets when you double-click on something. It is the closest thing available to a universal objective word counter.</p><p>I installed the <a href="https://pypi.org/project/polyglot/?ref=jina-ai-gmbh.ghost.io">polyglot library</a> in Python, which implements this text segmenter:</p><pre><code class="language-bash hljs">pip install -U polyglot
</code></pre><p>To get the word count of a text, you can use code like this snippet:</p><pre><code class="language-python hljs"><span class="hljs-keyword">from</span> polyglot.text <span class="hljs-keyword">import</span> Text

txt = <span class="hljs-string">"What is today's weather in Berlin?"</span>
<span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(Text(txt).words))
</code></pre><p>The result should be <code>7</code>.</p><p>To get a token count, segments of the text were passed to the tokenizers of various Jina Embeddings models, as described below, and each time, I subtracted two from the number of tokens returned.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">⚠️</div><div class="kg-callout-text">The token counts listed here <b><strong style="white-space: pre-wrap;">do not include</strong></b> the extra two tokens at the beginning and end of each tokenized text.</div></div><h3 id="english-jina-embeddings-v2-small-en-and-jina-embeddings-v2-base-en">English<br>(<code>jina-embeddings-v2-small-en</code> and <code>jina-embeddings-v2-base-en</code>)</h3><p>To calculate averages, I downloaded two English text corpora from <a href="https://wortschatz.uni-leipzig.de/en?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Wortschatz Leipzig</a>, a collection of freely downloadable corpora in a number of languages and configurations hosted by Leipzig University:</p><ul><li>A one-million-sentence corpus of news data in English from 2020 (<code>eng_news_2020_1M</code>)</li><li>A one-million-sentence corpus of <a href="https://en.wikipedia.org/?ref=jina-ai-gmbh.ghost.io">English Wikipedia</a> data from 2016 (<code>eng_wikipedia_2016_1M</code>)</li></ul><p>Both can be found on <a href="https://wortschatz.uni-leipzig.de/en/download/English?ref=jina-ai-gmbh.ghost.io">their English downloads page</a>.</p><p>For diversity, I also downloaded the <a href="https://www.gutenberg.org/ebooks/135?ref=jina-ai-gmbh.ghost.io">Hapgood translation of Victor Hugo’s <em>Les Misérables</em></a> from Project Gutenberg, and a copy of the King James Version of the Bible, translated to English in 1611.</p><p>For each all four texts, I counted the words using the Unicode segmenter implemented in <code>polyglot</code>, then counted the tokens made by <code>jina-embeddings-v2-small-en</code>, subtracting two tokens for each tokenization request. The results are as follows:</p>

<table id="6f07d5d4-ca08-466e-92fc-e784a932e4d0" class="simple-table"><thead class="simple-table-header"><tr id="4b8c4003-8ef9-4ac5-8df3-ef7662ab4d3b"><th id="wvl`" class="simple-table-header-color simple-table-header">Text</th><th id="|<X;" class="simple-table-header-color simple-table-header">Word count<br>(Unicode Segmenter)<br></th><th id="GHal" class="simple-table-header-color simple-table-header">Token count<br>(Jina Embeddings v2 <br>for English)<br></th><th id="h]mu" class="simple-table-header-color simple-table-header">Ratio of tokens to words<br>(to 3 decimal places)<br></th></tr></thead><tbody><tr id="7e9eda1b-54b6-40f3-be6f-b233f161e2b5"><td id="wvl`" class=""><code>eng_news_2020_1M</code></td><td id="|<X;" class="">22,825,712</td><td id="GHal" class="">25,270,581</td><td id="h]mu" class="">1.107</td></tr><tr id="a81dfe1d-9143-4306-9bf3-4891ca8fb019"><td id="wvl`" class=""><code>eng_wikipedia_2016_1M</code></td><td id="|<X;" class="">24,243,607</td><td id="GHal" class="">26,813,877</td><td id="h]mu" class="">1.106</td></tr><tr id="d2fff413-6e0d-4ab2-9626-4d618d99af91"><td id="wvl`" class=""><code>les_miserables_en</code></td><td id="|<X;" class="">688,911</td><td id="GHal" class="">764,121</td><td id="h]mu" class="">1.109</td></tr><tr id="eb304e43-4fd3-4e02-9993-13fb0307f544"><td id="wvl`" class=""><code>kjv_bible</code></td><td id="|<X;" class="">1,007,651</td><td id="GHal" class="">1,099,335</td><td id="h]mu" class="">1.091</td></tr></tbody></table>

<p>The use of precise numbers does not mean this is a precise result. That documents of such different genres would all have between 9% and 11% more tokens than words indicates that you can probably expect somewhere around 10% more tokens than words, as measured by the Unicode segmenter. Word processors often do not count punctuation, while the Unicode Segmenter does, so you can’t expect the word counts from office software to necessarily match this.</p><h3 id="german-jina-embeddings-v2-base-de">German<br>(<code>jina-embeddings-v2-base-de</code>)</h3><p>For German, I downloaded three corpora from <a href="https://wortschatz.uni-leipzig.de/en/download/German?ref=jina-ai-gmbh.ghost.io">Wortschatz Leipzig’s German page</a>:</p><ul><li><code>deu_mixed-typical_2011_1M</code> — One million sentences from a balanced mixture of texts in different genres, dating to 2011.</li><li><code>deu_newscrawl-public_2019_1M</code> — One million sentences of news text from 2019.</li><li><code>deu_wikipedia_2021_1M</code> — One million sentences extracted from the German Wikipedia in 2021.</li></ul><p>And for diversity, I also downloaded all <a href="https://deutschestextarchiv.de/search?q=Kapital&amp;in=metadata&amp;ref=jina-ai-gmbh.ghost.io">three volumes of Karl Marx’s <em>Kapital</em></a> from the <a href="https://www.deutschestextarchiv.de/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Deutsches Textarchiv</a>.</p><p>I then followed the same procedure as for English:</p>

<table id="ad695a91-f35b-4215-bd4d-5d1415bb9812" class="simple-table"><thead class="simple-table-header"><tr id="7786decb-f68d-433d-8f58-3861d0350027"><th id="UGp`" class="simple-table-header-color simple-table-header" style="width:234.2265625px">Text</th><th id="|qln" class="simple-table-header-color simple-table-header">Word count<br>(Unicode Segmenter)<br></th><th id="YXZX" class="simple-table-header-color simple-table-header">Token count<br>(Jina Embeddings v2 <br>for German and English)<br></th><th id="oEoQ" class="simple-table-header-color simple-table-header">Ratio of tokens to words<br>(to 3 decimal places)<br></th></tr></thead><tbody><tr id="9cb48640-64db-4783-8bfe-c78412022a21"><td id="UGp`" class="" style="width:234.2265625px"><code>deu_mixed-typical_2011_1M</code></td><td id="|qln" class="">7,924,024</td><td id="YXZX" class="">9,772,652</td><td id="oEoQ" class="">1.234</td></tr><tr id="32fee905-17dc-4c2c-a32d-5e6508b033bc"><td id="UGp`" class="" style="width:234.2265625px"><code>deu_newscrawl-public_2019_1M</code></td><td id="|qln" class="">17,949,120</td><td id="YXZX" class="">21,711,555</td><td id="oEoQ" class="">1.210</td></tr><tr id="35d0c8c4-7912-4d61-829a-bb39b643aa1c"><td id="UGp`" class="" style="width:234.2265625px"><code>deu_wikipedia_2021_1M</code></td><td id="|qln" class="">17,999,482</td><td id="YXZX" class="">22,654,901</td><td id="oEoQ" class="">1.259</td></tr><tr id="19e10367-e070-4dcc-8cbe-cfc75c43e0f9"><td id="UGp`" class="" style="width:234.2265625px"><code>marx_kapital</code></td><td id="|qln" class="">784,336</td><td id="YXZX" class="">1,011,377</td><td id="oEoQ" class="">1.289</td></tr></tbody></table>

<p>These results have a larger spread than the English-only model but still suggest that German text will yield, on average, 20% to 30% more tokens than words.</p><p>English texts yield more tokens with the German-English tokenizer than the English-only one:</p>

<table id="c31b2079-e921-4e06-a24b-8ed60ae63d8d" class="simple-table"><thead class="simple-table-header"><tr id="fe722fdd-ab88-44b4-9f3b-43c62eb3ccb5"><th id="Nc<l" class="simple-table-header-color simple-table-header" style="width:187.78125px">Text</th><th id="R@A^" class="simple-table-header-color simple-table-header">Word count<br>(Unicode Segmenter)<br></th><th id="UUfl" class="simple-table-header-color simple-table-header">Token count<br>(Jina Embeddings v2 <br>for German and English)<br></th><th id="iTZS" class="simple-table-header-color simple-table-header">Ratio of tokens to words<br>(to 3 decimal places)<br></th></tr></thead><tbody><tr id="3461fd8c-ca39-4670-8f0e-e38a4958464a"><td id="Nc<l" class="" style="width:187.78125px"><code>eng_news_2020_1M</code></td><td id="R@A^" class="">24243607</td><td id="UUfl" class="">27758535</td><td id="iTZS" class="">1.145</td></tr><tr id="48770d4d-5855-4f5f-934f-5b2900aa56c3"><td id="Nc<l" class="" style="width:187.78125px"><code>eng_wikipedia_2016_1M</code></td><td id="R@A^" class="">22825712</td><td id="UUfl" class="">25566921</td><td id="iTZS" class="">1.120</td></tr></tbody></table>

<p>You should expect to need 12% to 15% more tokens than words to embed English texts with the bilingual German/English than with the English-only one.</p><h3 id="chinese-jina-embeddings-v2-base-zh">Chinese<br>(<code>jina-embeddings-v2-base-zh</code>)</h3><p>Chinese is typically written without spaces and had no traditional notion of “words” before the 20th century. Consequently, the size of a Chinese text is typically measured in characters (<strong>字数</strong>). So, instead of using the Unicode Segmenter, I measured the length of Chinese texts by removing all the spaces and then just getting the character length.</p><p>I downloaded three corpora from the <a href="https://wortschatz.uni-leipzig.de/en/download/Chinese?ref=jina-ai-gmbh.ghost.io">Chinese corpus page at Wortschatz Leipzig</a>:</p><ul><li><code>zho_wikipedia_2018_1M</code> — One million sentences from the Chinese language Wikipedia, extracted in 2018.</li><li><code>zho_news_2007-2009_1M</code> — One million sentences from Chinese news sources, collected from 2007 to 2009.</li><li><code>zho-trad_newscrawl_2011_1M</code> — One million sentences from news sources that use exclusively traditional Chinese characters (繁體字).</li></ul><p>In addition, for some diversity, I also used <em>The True Story of Ah Q</em> (阿Q正傳), a novella by Lu Xun (魯迅) written in the early 1920s. I downloaded the <a href="https://www.gutenberg.org/ebooks/25332?ref=jina-ai-gmbh.ghost.io">traditional character version from Project Gutenberg</a>.</p>

<table id="dace0ca3-97c0-481e-98e2-d2724b7bbe66" class="simple-table"><thead class="simple-table-header"><tr id="adc6e6ff-8afd-4915-8884-0894546a13dc"><th id="bCvb" class="simple-table-header-color simple-table-header" style="width:223.6953125px">Text</th><th id="CaUc" class="simple-table-header-color simple-table-header">Character count<br>(字数)<br></th><th id="CQ{d" class="simple-table-header-color simple-table-header">Token count<br>(Jina Embeddings v2 <br>for Chinese and English)<br></th><th id="_};C" class="simple-table-header-color simple-table-header">Ratio of tokens to characters<br>(to 3 decimal places)<br></th></tr></thead><tbody><tr id="e75154ce-a33e-4af1-a983-4c4213f93c0e"><td id="bCvb" class="" style="width:223.6953125px"><code>zho_wikipedia_2018_1M</code></td><td id="CaUc" class="">45,116,182</td><td id="CQ{d" class="">29,193,028</td><td id="_};C" class="">0.647</td></tr><tr id="605560a8-5c77-4add-a3e4-4615779b571a"><td id="bCvb" class="" style="width:223.6953125px"><code>zho_news_2007-2009_1M</code></td><td id="CaUc" class="">44,295,314</td><td id="CQ{d" class="">28,108,090</td><td id="_};C" class="">0.635</td></tr><tr id="6e23944e-a480-4978-8550-a83404b218c4"><td id="bCvb" class="" style="width:223.6953125px"><code>zho-trad_newscrawl_2011_1M</code></td><td id="CaUc" class="">54,585,819</td><td id="CQ{d" class="">40,290,982</td><td id="_};C" class="">0.738</td></tr><tr id="50abbb96-06f7-4308-9c66-7c18f2a67721"><td id="bCvb" class="" style="width:223.6953125px"><code>Ah_Q</code></td><td id="CaUc" class="">41,268</td><td id="CQ{d" class="">25,346</td><td id="_};C" class="">0.614</td></tr></tbody></table>

<p>This spread in token-to-character ratios is unexpected, and especially the outlier for the traditional character corpus merits further investigation. Nonetheless, we can conclude that for Chinese, you should expect to need <em>fewer</em> tokens than there are characters in your text. Depending on your content, you can expect to need 25% to 40% less.</p><p>English texts in Jina Embeddings v2 for Chinese and English yielded roughly the same number of tokens as they do in the English-only model:</p>

<table id="061e7c3f-d109-476d-85fb-db3b369e4f35" class="simple-table"><thead class="simple-table-header"><tr id="1200d074-3353-4815-ab66-a90e93ec349d"><th id="v\xv" class="simple-table-header-color simple-table-header" style="width:184.53125px">Text</th><th id="qlUV" class="simple-table-header-color simple-table-header" style="width:165.3125px">Word count<br>(Unicode Segmenter)<br></th><th id="=]?F" class="simple-table-header-color simple-table-header">Token count<br>(Jina Embeddings v2 for Chinese and English)<br></th><th id="<rlw" class="simple-table-header-color simple-table-header">Ratio of tokens to words<br>(to 3 decimal places)<br></th></tr></thead><tbody><tr id="2fe4e02d-94fd-4513-bfcb-7f85d66b6883"><td id="v\xv" class="" style="width:184.53125px"><code>eng_news_2020_1M</code></td><td id="qlUV" class="" style="width:165.3125px">24,243,607</td><td id="=]?F" class="">26,890,176</td><td id="<rlw" class="">1.109</td></tr><tr id="e7f937f4-b156-4f5d-9e0b-3041d07b1b20"><td id="v\xv" class="" style="width:184.53125px"><code>eng_wikipedia_2016_1M</code></td><td id="qlUV" class="" style="width:165.3125px">22,825,712</td><td id="=]?F" class="">25,060,352</td><td id="<rlw" class="">1.097</td></tr></tbody></table>

<h2 id="taking-tokens-seriously">Taking Tokens Seriously</h2><p>Tokens are an important scaffolding for AI language models, and research is ongoing in this area.</p><p>One of the places where AI models have proven revolutionary is the discovery that they are very robust against noisy data. Even if a particular model does not use the optimal tokenization strategy, if the network is large enough, given enough data, and adequately trained, it can learn to do the right thing from imperfect input.</p><p>Consequently, much less effort is spent on improving tokenization than in other areas, but this may change.</p><p>As a user of embeddings, who buys them via an <a href="https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io">API like Jina Embeddings</a>, you can’t know precisely how many tokens you’ll need for a specific task and may have to do some testing of your own to get solid numbers. But the estimates provided here — circa 110% of the word count for English, circa 125% of the word count for German, and circa 70% of the character count for Chinese — should be enough for basic budgeting.</p><h2 id="learn-more">Learn More</h2><p>For more information about Jina Embeddings, check out the&nbsp;<a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io">Jina AI website</a>&nbsp;or join our&nbsp;<a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io">community on Discord</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI - Best Embeddings and Perfect Prompts</div><div class="kg-bookmark-description">Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Best Embeddings and Perfect Prompts</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina.ai/banner.png" alt="" style="cursor: help;"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4308 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://discord.com/assets/images/favicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="" style="cursor: help;"></div></a></figure></section></article><hr data-v-7c05b1fa="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-7c05b1fa="" class="row justify-between items-center q-py-md"><div data-v-7c05b1fa=""><span data-v-7c05b1fa="" class="text-weight-bold">Categories:</span><span data-v-7c05b1fa="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius lock-blur" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></span></div><div data-v-7c05b1fa=""><div data-v-7c05b1fa="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-7c05b1fa="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fa-deep-dive-into-tokenization%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-7c05b1fa="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fa-deep-dive-into-tokenization%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-7c05b1fa="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fa-deep-dive-into-tokenization%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-7c05b1fa="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fa-deep-dive-into-tokenization%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-7c05b1fa="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fnews%2Fa-deep-dive-into-tokenization%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-7c05b1fa="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-7c05b1fa="" class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div data-v-7c05b1fa="" class="text-h4 text-grey-2 q-my-xl">Learn more</div><a data-v-7c05b1fa="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/implementing-a-chat-history-rag-with-jina-ai-and-milvus-lite"><div class="q-focus-helper" tabindex="-1"></div><div class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert col column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Implementing a Chat History RAG with Jina AI and Milvus Lite</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">Enhance your search applications in Python with Jina Embeddings and Reranker and lightweight, easy-to-deploy Milvus Lite.
</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 55px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 133.4%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Portrait-Picture_Low.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 25px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 121.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Francesco Kruk, Saahil Ognawala</div><div class="q-item__label q-item__label--caption text-caption">June 03, 2024 • 7 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/Blog-images--39-.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></a><a data-v-7c05b1fa="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/bypass-limitations-with-promptperfect-generate-the-images-the-models-dont-want-you-to-see"><div class="q-focus-helper" tabindex="-1"></div><div class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert col column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Bypass Limitations with PromptPerfect: Generate the Images the Models Don’t Want You to See</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">See how PromptPerfect overcomes restrictions and limitations of image generation models like Stable Diffusion XL and DALL-E 3.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Alex C-G</div><div class="q-item__label q-item__label--caption text-caption">May 22, 2024 • 10 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img" aria-label="Colorful digital chain graphic with vibrant bricks against a black background, conveying energy and connectivity."><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Colorful digital chain graphic with vibrant bricks against a black background, conveying energy and connectivity." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/05/break-chain.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></a><a data-v-7c05b1fa="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/air-bench-better-metrics-for-better-search-foundation"><div class="q-focus-helper" tabindex="-1"></div><div class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width"><span class="q-focus-helper"></span><div class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div class="q-card__section q-card__section--vert col column justify-between"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h5 text-weight-light q-mb-lg" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">AIR-Bench: Better Metrics for Better Search Foundation</div><div class="q-item__label q-item__label--caption text-caption" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3;">AIR-Bench is a new approach to AI metrics that uses generative AI to make more realistic and flexible benchmarks. With AIR-Bench, you can create your own benchmarks for your own domain, and know that benchmarks data hasn't leaked into model training data.</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-4736c702="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-4736c702="" class="relative-position" style="height: 30px; width: 30px;"><div data-v-4736c702="" class="q-avatar bg-grey-9 overlapping" style="font-size: 30px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-4736c702="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Scott Martens</div><div class="q-item__label q-item__label--caption text-caption">May 21, 2024 • 11 minutes read</div></div></div></div><div class="q-img q-img--menu col-4" role="img" aria-label="Abstract design with geometric shapes, white clouds, and colorful gradients on a black background, suggesting a futuristic am"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract design with geometric shapes, white clouds, and colorful gradients on a black background, suggesting a futuristic am" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/05/cosmic--1-.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></a></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow overflow-hidden print-hide"><div class="q-img q-img--menu full-width" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/portal-2-poster.44997122.webp" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div><div class="overlay"></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow row absolute-left items-center bg-transparent non-selectable fit"><div class="text-white bg-transparent lock-blur fit q-pa-sm"><div class="row justify-between q-gutter-lg"><div class="col-12 col-md-3"><div class="q-list q-list--dark"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><strong>Offices</strong></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption">Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany</div><div class="q-item__label q-item__label--caption text-caption">Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption">Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption">402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div></div><div class="row text-caption justify-center q-mt-xl"> © Jina AI GmbH 2020-2024. All rights reserved.</div></div></div></div><footer class="q-footer q-layout__section--marginal fixed-bottom lock-blur bg-transparent print-hide"><div class="row"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline col-12 col-md-6 justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-discord" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://twitter.com/jinaAI_/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://podcasts.apple.com/us/podcast/jina-ai-podcast/id1734573793" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-solid fa-podcast" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.youtube.com/c/JinaAI" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-youtube" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">email</i></span></a></div></div></footer></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>