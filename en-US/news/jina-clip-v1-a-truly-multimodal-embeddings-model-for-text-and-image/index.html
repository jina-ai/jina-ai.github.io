<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image</title><meta charset="utf-8"><meta name="title" content="Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image"><meta name="description" content="Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image"><meta property="og:title" content="Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image"><meta property="og:description" content="Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more."><meta property="og:image" content="https://jina.ai/blog-banner/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image"><meta property="twitter:title" content="Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image"><meta property="twitter:description" content="Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more."><meta property="twitter:image" content="https://jina.ai/blog-banner/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-DSyc9Qln.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-Db0tgwFK.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-C0JNxzbi.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-7oi8Duzd.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-CvjzRGd4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-CqFHzYqU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-o0C6pYku.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-De4KU4ci.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-DiJtDiu2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-YiES9e-2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-l8q_zicJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-QFT3abUz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-Bsgy-6xc.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-Dj0c2tpJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-Budt-nHk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-DJ1wh4TY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-ij84kVDt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-JIejfbXZ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-xyPyKILU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-mNt3cPr6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-DbRBXqwz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-CDDZlHVT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-Dn2QzyQn.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-BV236Sh2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-BtGcpv5J.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-DVL_Bysw.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-DwGH-Icl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-DrLB4jyz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-7AeOAFKi.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-CSj0h40z.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-BEYO7a6x.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-__S2BMiv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-CzUwoUqE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-BfAok4Rz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BFDziIVk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-Dr0LiJyP.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-FQtLLxiQ.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-CnEdSINW.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-vSZoRHSY.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Sofia Vasileva, Scott Martens, Susana Guzmán"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Sofia Vasileva, Scott Martens, Susana Guzmán"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="9 mins read"><meta property="article:published_time" content="2024-06-05T11:42:02.000+02:00"><meta property="article:modified_time" content="2024-11-28T08:20:59.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image",
  "description": "Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more.",
  "image": [
    "https://jina.ai/blog-banner/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image.webp"
  ],
  "datePublished": "2024-06-05T11:42:02.000+02:00",
  "dateModified": "2024-11-28T08:20:59.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Sofia Vasileva",
      "url": "https://jina-ai-gmbh.ghost.io/author/sofia/"
    },
    {
      "@type": "Person",
      "name": "Scott Martens",
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    },
    {
      "@type": "Person",
      "name": "Susana Guzmán",
      "url": "https://jina-ai-gmbh.ghost.io/author/susana/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-478b3f77="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-478b3f77="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-478b3f77="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-478b3f77="" class="q-space"></div><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-478b3f77="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-478b3f77="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-478b3f77="" class="q-list q-list--dark" role="list"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">News</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Models</div></a><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_af722ace-1574-4870-b7fb-7083f84e5333" aria-label="Expand &quot;Products&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Products</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_af722ace-1574-4870-b7fb-7083f84e5333" style="display: none;"><div data-v-478b3f77="" class="q-list q-list--dark" role="list" label="Products"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DeepSearch</div><div class="q-item__label q-item__label--caption text-caption">Search, read and reason until best answer found.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reader</div><div class="q-item__label q-item__label--caption text-caption">Convert any URL to Markdown for better grounding LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">World-class multimodal multilingual embeddings.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">World-class neural retriever for maximizing search relevancy.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_23c136a5-46f1-4c00-827a-ec95ef059a2e" aria-label="Expand &quot;More&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_23c136a5-46f1-4c00-827a-ec95ef059a2e" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Classifier</div><div class="q-item__label q-item__label--caption text-caption">Zero-shot and few-shot classification for image and text.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmenter</div><div class="q-item__label q-item__label--caption text-caption">Cut long text into chunks and do tokenization.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">API Docs</div><div class="q-item__label q-item__label--caption text-caption">Auto codegen for your copilot IDE or LLM</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_f9db9627-2a59-4dc2-85a4-521e6191eeb7" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_f9db9627-2a59-4dc2-85a4-521e6191eeb7" style="display: none;"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">About us</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Join us</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Download logo</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Terms &amp; Conditions</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Log in"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Log in</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-478b3f77="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_df0e6d0d-9425-4086-a533-68b095b72493"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_df0e6d0d-9425-4086-a533-68b095b72493" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_df0e6d0d-9425-4086-a533-68b095b72493_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-478b3f77="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">The CLIP Architecture for Multimodal AI</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Introducing Jina CLIP v1</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">New State-of-the-Art in Multimodal Embeddings</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Getting Started with Embeddings API</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Open-Source Jina CLIP v1 on Hugging Face</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Summary</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Featured</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Press release</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">June 05, 2024</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img" aria-label="Abstract 3D render of a neon blue and green grid pattern on a black background, creating a sense of depth."><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract 3D render of a neon blue and green grid pattern on a black background, creating a sense of depth." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/--.jpg" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 68px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Sofia Vasileva"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Sofia Vasileva" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/sofia-profile-pic.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Scott Martens"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Scott Martens" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 36px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Susana Guzmán"><div style="padding-bottom: 66.6875%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Susana Guzmán" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/04/WhatsApp-Image-2022-12-06-at-15.46.39.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Sofia Vasileva, Scott Martens, Susana Guzmán • 9 minutes read</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina CLIP v2: Multilingual Multimodal Embeddings for Text and Images</div><div class="kg-bookmark-description">Jina-CLIP v2, a 0.9B multimodal embedding model with multilingual support of 89 languages, high image resolution at 512x512, and Matryoshka representations.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-12.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span><span class="kg-bookmark-publisher">Your Search Foundation, Supercharged.</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/clipv2.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a><figcaption><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v2" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v2</span></a><span style="white-space: pre-wrap;"> has been released on Nov. 22, 2024!</span></p></figcaption></figure><p>Jina CLIP v1 (<a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>) is a new multimodal embedding model that extends the capabilities of OpenAI’s <a href="https://openai.com/index/clip/">original CLIP model</a>. With this new model, users have a single embedding model that delivers state-of-the-art performance in both text-only and text-image cross-modal retrieval. Jina AI has improved on OpenAI CLIP’s performance by 165% in text-only retrieval, and 12% in image-to-image retrieval, with identical or mildly better performance in text-to-image and image-to-text tasks. This enhanced performance makes Jina CLIP v1 indispensable for working with multimodal inputs.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text"><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> improves on OpenAI CLIP in <a href="#compare_table" rel="noreferrer">every category of retrieval</a>.</div></div><p>In this article, we will first discuss the shortcomings of the original CLIP model and how we have addressed them using a unique co-training method. Then, we will demonstrate the effectiveness of our model on various retrieval benchmarks. Finally, we will provide detailed instructions on how users can get started with Jina CLIP v1 via our Embeddings API and Hugging Face.</p><h2 id="the-clip-architecture-for-multimodal-ai" style="position: relative;"><a href="#the-clip-architecture-for-multimodal-ai" title="The CLIP Architecture for Multimodal AI" id="anchor-the-clip-architecture-for-multimodal-ai"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>The CLIP Architecture for Multimodal AI</h2><p>In January 2021, OpenAI released the <a href="https://openai.com/index/clip/">CLIP</a> (Contrastive Language–Image Pretraining) model. CLIP has a straightforward yet ingenious architecture: it combines two embedding models, one for texts and one for images, into a single model with a single output embedding space. Its text and image embeddings are directly comparable to each other, making the distance between a text embedding and an image embedding proportionate to how well that text describes the image, and vice versa.</p><p>This has proven to be very useful in multimodal information retrieval and zero-shot image classification. Without further special training, CLIP performed well at placing images into categories with natural language labels.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/180-1.jpg" class="kg-image" alt="Diagram illustrating image to text translation using an astronaut on Mars with a red moon as an example." width="1600" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/180-1.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/180-1.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/180-1.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>The text embedding model in the original CLIP was a custom neural network with only 63 million parameters. On the image side, OpenAI released CLIP with a selection of <a href="https://huggingface.co/docs/transformers/model_doc/resnet" rel="noopener noreferrer">ResNet</a> and <a href="https://huggingface.co/docs/transformers/en/model_doc/vit" rel="noopener noreferrer">ViT models</a>. Each model was pre-trained for its individual modality and then trained with captioned images to produce similar embeddings for prepared image-text pairs.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/Blog-images--1-.png" class="kg-image" alt="Flowchart with text &quot;Embedding Space&quot;, linked to &quot;Image Encoder&quot; and &quot;Text Encoder&quot;, with a &quot;Distracted boyfriend&quot; label." width="1600" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Blog-images--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Blog-images--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Blog-images--1-.png 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>This approach yielded impressive results. Particularly notable is its zero-shot classification performance. For example, even though the training data did not include labeled images of <a href="https://docs.vultr.com/zero-shot-image-classification-using-openai-clip">astronauts</a>, CLIP could correctly identify pictures of astronauts based on its understanding of related concepts in texts and images.</p><p>However, OpenAI’s CLIP has two important drawbacks:</p><ul><li>First is its very limited text input capacity. It can take a maximum 77 tokens of input, but <a href="https://arxiv.org/abs/2403.15378">empirical analysis shows</a> that in practice it doesn’t use more than 20 tokens to produce its embeddings. This is because CLIP was trained from images with captions, and captions tend to be very short. This is in contrast to current text embedding models which support several thousand tokens.</li><li>Second, the performance of its text embeddings in text-only retrieval scenarios is very poor. Image captions are a very limited kind of text, and do not reflect the broad array of use cases a text embedding model would be expected to support.</li></ul><p>In most real use cases, text-only and image-text retrieval are combined or at least both are available for tasks. Maintaining a second embeddings model for text-only tasks effectively doubles the size and complexity of your AI framework.</p><p>Jina AI’s new model addresses these issues directly, and <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> takes advantage of the progress made in the last several years to bring state-of-the-art performance to tasks involving all combinations of text and image modalities.</p><h2 id="introducing-jina-clip-v1" style="position: relative;"><a href="#introducing-jina-clip-v1" title="Introducing Jina CLIP v1" id="anchor-introducing-jina-clip-v1"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Introducing Jina CLIP v1</h2><p>Jina CLIP v1 retains the OpenAI’s original CLIP schema: two models co-trained to produce output in the same embedding space.</p><p>For text encoding, we adapted the <a href="https://jina.ai/news/jina-embeddings-2-the-best-solution-for-embedding-long-documents/">Jina BERT v2</a> architecture used in the <a href="https://jina.ai/embeddings/">Jina Embeddings v2 models</a>. This architecture supports a state-of-the-art 8k token input window and outputs 768-dimensional vectors, producing more accurate embeddings from longer texts. This is more than 100 times the 77 token input supported in the original CLIP model.</p><p>For image embeddings, we are using the latest model from the Beijing Academy for Artificial Intelligence: the <a href="https://github.com/baaivision/EVA/tree/master/EVA-02"><code>EVA-02</code> model</a>. We have empirically compared a number of image AI models, testing them in cross-modal contexts with similar pre-training, and <code>EVA-02</code>clearly outperformed the others. It’s also comparable to the Jina BERT architecture in model size, so that compute loads for image and text processing tasks are roughly identical.</p><p>These choices produce important benefits for users:</p><ul><li>Better performance on all benchmarks and all modal combinations, and especially large improvements in text-only embedding performance.</li><li><code>EVA-02</code>'s empirically superior performance both in image-text and image-only tasks, with the added benefit of Jina AI’s additional training, improving image-only performance.</li><li>Support for much longer text inputs. <a href="https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/">Jina Embeddings’ 8k token</a> input support makes it possible to process detailed textual information and correlate it with images.</li><li>A large net savings in space, compute, code maintenance, and complexity because this multimodal model is highly performant even in non-multimodal scenarios.</li></ul><h3 id="training" style="position: relative;"><a href="#training" title="Training" id="anchor-training"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Training</h3><p>Part of our recipe for high-performance multimodal AI is our training data and procedure. We notice that the very short length of texts used in image captions is the major cause of poor text-only performance in CLIP-style models, and our training is explicitly designed to remedy this.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/dark-1.png" class="kg-image" alt="Flowchart illustrating optimization of text and caption-image similarity in three tasks, using a model and encoders, ending i" width="1600" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/dark-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/dark-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/dark-1.png 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Training takes place in three steps:</p><ol><li>Use captioned image data to learn to align image and text embeddings, interleaved with text pairs with similar meanings. This co-training jointly optimizes for the two kinds of tasks. The text-only performance of the model declines during this phase, but not as much as if we had trained with only image-text pairs.</li><li>Train using synthetic data which aligns images with larger texts, generated by an AI model, that describes the image. Continue training with text-only pairs at the same time. During this phase, the model learns to attend to larger texts in conjunction with images.</li><li>Use text triplets with <a href="https://finetuner.jina.ai/advanced-topics/negative-mining/" rel="noreferrer">hard negatives</a> to further improve text-only performance by learning to make finer semantic distinctions. At the same time, continue training using synthetic pairs of images and long texts. During this phase, text-only performance improves dramatically without the model losing any image-text abilities.</li></ol><p>For more information on the details of training and model architecture, please read <a href="https://arxiv.org/abs/2405.20204">our recent paper</a>:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2405.20204"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class="kg-bookmark-description">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Andreas Koukounas</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="new-state-of-the-art-in-multimodal-embeddings" style="position: relative;"><a href="#new-state-of-the-art-in-multimodal-embeddings" title="New State-of-the-Art in Multimodal Embeddings" id="anchor-new-state-of-the-art-in-multimodal-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>New State-of-the-Art in Multimodal Embeddings</h2><p>We evaluated Jina CLIP v1’s performance across text-only, image-only, and cross-modal tasks involving both input modalities. We used the <a href="https://huggingface.co/blog/mteb">MTEB retrieval benchmark</a> to evaluate text-only performance. For image-only tasks, we used the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a> benchmark. For cross-model tasks, we evaluate on <a href="https://www.kaggle.com/datasets/adityajn105/flickr8k">Flickr8k</a>, <a href="https://www.kaggle.com/datasets/adityajn105/flickr30k">Flickr30K</a>, and <a href="https://arxiv.org/abs/1504.00325">MSCOCO Captions</a>, which are included in the <a href="https://arxiv.org/abs/2203.05796">CLIP Benchmark</a>.</p><p>The results are summarized in the table below:</p>

<table id="compare_table">
<thead>
<tr>
<th>Model</th>
<th>Text-Text</th>
<th>Text-to-Image</th>
<th>Image-to-Text</th>
<th>Image-Image</th>
</tr>
</thead>
<tbody>
<tr>
<td><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a></td>
<td>0.429</td>
<td>0.899</td>
<td>0.803</td>
<td>0.916</td>
</tr>
<tr>
<td>openai-clip-vit-b16</td>
<td>0.162</td>
<td>0.881</td>
<td>0.756</td>
<td>0.816</td>
</tr>
<tr style="font-weight:bold">
<td>% increase<br>vs OpenAI CLIP</td>
<td>165%</td>
<td>2%</td>
<td>6%</td>
<td>12%</td>
</tr>
</tbody>
</table>

<p>You can see from these results that <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> outperforms OpenAI’s original CLIP in all categories, and is dramatically better in text-only and image-only retrieval. Averaged over all categories, this is a 46% improvement in performance.</p><p>You can find a more detailed evaluation in <a href="https://arxiv.org/abs/2405.20204">our recent paper</a>.</p><h2 id="getting-started-with-embeddings-api" style="position: relative;"><a href="#getting-started-with-embeddings-api" title="Getting Started with Embeddings API" id="anchor-getting-started-with-embeddings-api"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Getting Started with Embeddings API</h2><p>You can easily integrate Jina CLIP v1 into your applications using the <a href="https://jina.ai/embeddings">Jina Embeddings API</a>.</p><p>The code below shows you how to call the API to get embeddings for texts and images, using the <code>requests</code> package in Python. It passes a text string and a URL to an image to the Jina AI server and returns both encodings.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">☝️</div><div class="kg-callout-text">Remember to replace <code spellcheck="false" style="white-space: pre-wrap;">&lt;YOUR_JINA_AI_API_KEY&gt;</code> with an activated Jina API key. You can get a trial key with a million free tokens from the <a href="https://jina.ai/embeddings/#apiform">Jina Embeddings web page</a>.</div></div><pre class="hljs-copy-wrapper"><code class="language-python hljs"><span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> numpy.linalg <span class="hljs-keyword">import</span> norm

cos_sim = <span class="hljs-keyword">lambda</span> a,b: (a @ b.T) / (norm(a)*norm(b))

url = <span class="hljs-string">'https://api.jina.ai/v1/embeddings'</span>

headers = {
  <span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/json'</span>,
  <span class="hljs-string">'Authorization'</span>: <span class="hljs-string">'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'</span>
}

data = {
  <span class="hljs-string">'input'</span>: [
     {<span class="hljs-string">"text"</span>: <span class="hljs-string">"Bridge close-shot"</span>},
     {<span class="hljs-string">"url"</span>: <span class="hljs-string">"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s"</span>}],
  <span class="hljs-string">'model'</span>: <span class="hljs-string">'jina-clip-v1'</span>,
  <span class="hljs-string">'encoding_type'</span>: <span class="hljs-string">'float'</span>
}

response = requests.post(url, headers=headers, json=data)
sim = cos_sim(np.array(response.json()[<span class="hljs-string">'data'</span>][<span class="hljs-number">0</span>][<span class="hljs-string">'embedding'</span>]), np.array(response.json()[<span class="hljs-string">'data'</span>][<span class="hljs-number">1</span>][<span class="hljs-string">'embedding'</span>]))
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Cosine text&lt;-&gt;image: <span class="hljs-subst">{sim}</span>"</span>)
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copy</button></div></pre><h3 id="integration-with-major-llm-frameworks" style="position: relative;"><a href="#integration-with-major-llm-frameworks" title="Integration with major LLM Frameworks" id="anchor-integration-with-major-llm-frameworks"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Integration with major LLM Frameworks</h3><p>Jina CLIP v1 is already available for <a href="https://www.llamaindex.ai/" rel="noreferrer">LlamaIndex</a> and <a href="https://www.langchain.com/" rel="noreferrer">LangChain</a>:</p><ul><li><a href="https://docs.llamaindex.ai/en/stable/examples/embeddings/jinaai_embeddings/">LlamaIndex</a>: Use <code>JinaEmbedding</code> with the <code>MultimodalEmbedding</code> base class, and invoke <code>get_image_embeddings</code> or <code>get_text_embeddings</code> .</li><li><a href="https://python.langchain.com/v0.1/docs/integrations/text_embedding/jina/">LangChain</a>: Use <code>JinaEmbeddings</code>, and invoke <code>embed_images</code> or <code>embed_documents</code>.</li></ul><h3 id="pricing" style="position: relative;"><a href="#pricing" title="Pricing" id="anchor-pricing"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Pricing</h3><p>Both text and image inputs are charged by token consumption.</p><p>For text in English, <a href="https://jina.ai/news/a-deep-dive-into-tokenization/">we have empirically calculated</a> that on average you will need 1.1 tokens for every word.</p><p>For images, we count the number of 224x224 pixel tiles required to cover your image. Some of these tiles may be partly blank but count just the same. Each tile costs 1,000 tokens to process.</p><p><strong>Example</strong></p><p>For an image with dimensions 750x500 pixels:</p><ol><li>The image is divided into 224x224 pixel tiles.<ol><li>To calculate the number of tiles, take the width in pixels and divide by 224, then round up to the nearest integer. <br>     750/224 ≈ 3.35 → 4</li><li>Repeat for the height in pixels: <br>     500/224 ≈ 2.23 → 3</li></ol></li><li>The total number of tiles required in this example is: <br>           4 (horizontal) x 3 (vertical) = 12 tiles</li><li>The cost will be 12 x 1,000 = 12,000 tokens </li></ol><h3 id="enterprise-support" style="position: relative;"><a href="#enterprise-support" title="Enterprise Support" id="anchor-enterprise-support"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Enterprise Support</h3><p>We are introducing a new benefit for users who purchase the Production Deployment plan with <a href="https://jina.ai/embeddings/#pricing">11 billion tokens</a>. This includes:</p><ul><li>One hours of consultation with our product and engineering teams to discuss your specific use cases and requirements.</li><li>A customized Python notebook designed for your RAG (Retrieval-Augmented Generation) or vector search use case, demonstrating how to integrate Jina AI’s models into your application.</li><li>Assignment to an account executive and priority email support to ensure your needs are met promptly and efficiently.</li></ul><h2 id="open-source-jina-clip-v1-on-hugging-face" style="position: relative;"><a href="#open-source-jina-clip-v1-on-hugging-face" title="Open-Source Jina CLIP v1 on Hugging Face" id="anchor-open-source-jina-clip-v1-on-hugging-face"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Open-Source Jina CLIP v1 on Hugging Face</h2><p>Jina AI is committed to an open-source search foundation, and for that purpose, we are making this model available for free under an <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache 2.0 license</a>, on <a href="https://huggingface.co/jinaai/jina-clip-v1">Hugging Face</a>.</p><p>You can find example code to download and run this model on your own system or cloud installation on the Hugging Face model page for <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> .</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-clip-v1"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-clip-v1 · Hugging Face</div><div class="kg-bookmark-description">We’re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-clip-v1.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="summary" style="position: relative;"><a href="#summary" title="Summary" id="anchor-summary"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Summary</h2><p>Jina AI’s latest model — <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> — represents a significant advance in multimodal embedding models, offering substantial performance gains over OpenAI's CLIP. With notable improvements in text-only and image-only retrieval tasks, as well as competitive performance in text-to-image and image-to-text tasks, it stands as a promising solution for complex embeddings use cases.</p><p>This model currently only supports English-language texts due to resource constraints. We are working to expand its capabilities to more languages.</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Categories:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Featured</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Press release</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-478b3f77="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-478b3f77="" class="col-sm-12 col-md"><div data-v-478b3f77="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Offices</div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Sunnyvale, CA</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, USA</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Berlin, Germany (HQ)</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Germany</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Beijing, China</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Level 5, Building 6, No.48 Haidian West St. Beijing, China</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Shenzhen, China</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">402 Floor 4, Fu'an Technology Building, Shenzhen, China</div></div></div></div></div><div data-v-478b3f77="" class="col-sm-12 col-md row"><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Search Foundation</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">DeepSearch</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Reader</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Embeddings</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Reranker</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Classifier</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Segmenter</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">API Documentation</div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Get Jina API key</div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Rate Limit</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-478b3f77="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">API Status</div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Company</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">About us</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Newsroom</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Join us</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Download logo</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Terms</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Security</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Terms &amp; Conditions</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Privacy</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Manage Cookies</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-478b3f77="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-478b3f77="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-478b3f77="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>