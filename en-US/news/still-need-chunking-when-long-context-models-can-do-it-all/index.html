<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>Still Need Chunking When Long-Context Models Can Do It All?</title><meta charset="utf-8"><meta name="title" content="Still Need Chunking When Long-Context Models Can Do It All?"><meta name="description" content="Comparing how long-context embedding models perform with different chunking strategies to find the optimal approach for your needs."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="og:title" content="Still Need Chunking When Long-Context Models Can Do It All?"><meta property="og:description" content="Comparing how long-context embedding models perform with different chunking strategies to find the optimal approach for your needs."><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="twitter:title" content="Still Need Chunking When Long-Context Models Can Do It All?"><meta property="twitter:description" content="Comparing how long-context embedding models perform with different chunking strategies to find the optimal approach for your needs."><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-BSykyakD.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-CRvJtbiE.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-Bed01o9M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-DADjeAwe.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-Cvk_ae-l.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-CBESzXu-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-DI7YmeFJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-B8UVl1rJ.js"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-Cewi1OJE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-DvVmxiDT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-BX56n8qM.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-O8qDEhEk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format-DyQxkAtJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-CgWlSwau.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QToolbar-C9kfKvL3.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-Dys5cNIH.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-CTkcKvJ3.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-Dn8ZCaa6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-j2Um5S05.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-BfYflfOA.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-Vk8qceDE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-DeldwiJK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-Cedb_dKh.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding-CnE0O2Nz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-Du2Tnw3L.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-DGHaUBtY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-C-d3uTXe.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-CqE0tSVj.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-BMR_OewU.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-be28zKi-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-CwTHyLF-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-a6Jhsx5B.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-Bu7I3dJS.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-BmqKvlND.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-CovHgG0a.css"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-q765RzAS.css"><meta name="author" content="Michael Günther, Alex C-G"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Michael Günther, Alex C-G"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="13 mins read"><meta property="article:published_time" content="2024-12-05T00:55:21.000+01:00"><meta property="article:modified_time" content="2024-12-09T09:51:11.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Still Need Chunking When Long-Context Models Can Do It All?",
  "description": "Comparing how long-context embedding models perform with different chunking strategies to find the optimal approach for your needs.",
  "image": [
    "https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"
  ],
  "datePublished": "2024-12-05T00:55:21.000+01:00",
  "dateModified": "2024-12-09T09:51:11.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Michael Günther",
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_c36fad14-52cc-48e5-8c63-eeac648f0069" aria-label="Expand &quot;Products&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Products</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_c36fad14-52cc-48e5-8c63-eeac648f0069" style="display: none;"><div class="q-list q-list--dark" role="list" label="Products"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Enterprises</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">World-class multimodal multilingual embeddings.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">World-class neural retriever for maximizing search relevancy.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reader</div><div class="q-item__label q-item__label--caption text-caption">Read URLs and search web for better grounding LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Classifier</div><div class="q-item__label q-item__label--caption text-caption">Zero-shot and few-shot classification for image and text.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmenter</div><div class="q-item__label q-item__label--caption text-caption">Cut long text into chunks and do tokenization.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Power Users</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_104abf63-d5ca-456c-bae7-68563c587733" aria-label="Expand &quot;More power user tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More power user tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_104abf63-d5ca-456c-bae7-68563c587733" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_21e3b3f6-f6d6-49b4-87a0-4862d91c6b47" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_21e3b3f6-f6d6-49b4-87a0-4862d91c6b47" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Download logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; Conditions</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Log in"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div><div class="q-item__section column q-item__section--main justify-center">Log in</div></a></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-33ef2eff="" class="q-page" style="min-height: 100vh;"><div data-v-33ef2eff="" class="row full-width relative-position justify-end"><div data-v-33ef2eff="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-33ef2eff="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Is Long Context Even Useful?</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Problems with Long-Context Embeddings</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Long Context vs. Truncation</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Segmenting Text for Better Retrieval Performance</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Late Chunking Solves the Context Problem</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">To Chunk or Not to Chunk?</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Takeaways: When To Use What?</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">Conclusion</div></div></div></div></div><div data-v-33ef2eff="" class="col-12 col-md-10 col-lg-12"><div data-v-33ef2eff="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-33ef2eff="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">December 04, 2024</div><h1 data-v-33ef2eff="" class="text-weight-medium text-center q-px-md my-title">Still Need Chunking When Long-Context Models Can Do It All?</h1><div data-v-33ef2eff="" class="col row justify-center"><div data-v-33ef2eff="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Comparing how long-context embedding models perform with different chunking strategies to find the optimal approach for your needs.</div></div><div data-v-33ef2eff="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-33ef2eff="" class="q-img q-img--menu" role="img" aria-label="Artistic pixel art of two seagulls on colored pipes with speech bubbles; one reads &quot;Too long?&quot; and the other shows math equat"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Artistic pixel art of two seagulls on colored pipes with speech bubbles; one reads &quot;Too long?&quot; and the other shows math equat" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-33ef2eff="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-33ef2eff="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Michael Günther"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Michael Günther" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-33ef2eff="" class="q-item__label">Michael Günther, Alex C-G • 13 minutes read</div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-33ef2eff="" class="article"><section data-v-33ef2eff="" class="gh-content"><p>In October 2023, we introduced <code>jina-embeddings-v2</code>, the first open-source embedding model family capable of handling inputs up to 8,192 tokens. Building on this, this year we launched <code>jina-embeddings-v3</code>, offering the same extensive input support with further enhancements. </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-14.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-4.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>In this post we’ll dig into long context embeddings and answer some questions: When is it practical to consolidate such a large volume of text into a single vector? Does segmentation enhance retrieval, and if so, how? How can we preserve context from different parts of a document while segmenting the text?</p><p>To answer these questions, we’ll compare several methods for generating embeddings:</p><ul><li>Long context embedding (encoding up to 8,192 tokens in a document) vs short context (i.e. truncating at 192 tokens).</li><li>No chunking vs. naive chunking vs. <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">late chunking</a>.</li><li>Different chunk sizes with both naive and late chunking.</li></ul><h2 id="is-long-context-even-useful" style="position: relative;"><a href="#is-long-context-even-useful" title="Is Long Context Even Useful?" id="anchor-is-long-context-even-useful"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Is Long Context Even Useful?</h2><p>With the ability to encode up to ten pages of text in a single embedding, long context embedding models open up possibilities for large-scale text representation. Is that even useful though? According to a lot of people…no.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 6.35227 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--15-.png" width="559" height="88" alt="" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 5.21368 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png" width="610" height="117" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--16-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png 610w" style="cursor: help;"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 10.2143 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png" width="1430" height="140" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--14-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--14-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png 1430w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 11.0735 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png" width="1506" height="136" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png 1506w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div></div></div><figcaption><p><span style="white-space: pre-wrap;">Sources: </span><a href="https://www.youtube.com/watch?v=xKR08kDY2q4"><span style="white-space: pre-wrap;">Quote from Nils Reimer in How AI Is Built podcast</span></a><span style="white-space: pre-wrap;">, </span><a href="https://x.com/brainlag/status/1717221138483331158"><span style="white-space: pre-wrap;">brainlag tweet</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38026784"><span style="white-space: pre-wrap;">egorfine Hacker News comment</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38020753"><span style="white-space: pre-wrap;">andy99 Hacker News comment</span></a></p></figcaption></figure><p>We’re going to address all of these concerns with a detailed investigation of long-context capabilities, when long context is helpful, and when you should (and shouldn’t) use it. But first, let’s hear those skeptics out and look at some of the issues long-context embedding models face.</p><h2 id="problems-with-long-context-embeddings" style="position: relative;"><a href="#problems-with-long-context-embeddings" title="Problems with Long-Context Embeddings" id="anchor-problems-with-long-context-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Problems with Long-Context Embeddings</h2><p>Imagine we’re building a document search system for articles, like those on our <a href="https://jina.ai/news">Jina AI blog</a>. Sometimes a single article may cover multiple topics, like the <a href="https://jina.ai/news/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc">report about our visit to the ICML 2024 conference</a>, which contains:</p><ul><li>An introduction, capturing general information about ICML (number of participants, location, scope, etc).</li><li>The presentation of our work (<code>jina-clip-v1</code>).</li><li>Summaries of other interesting research papers presented at ICML.</li></ul><p>If we create just a single embedding for this article, that one embedding represents a mixture of three disparate topics:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png" class="kg-image" alt="Scientific diagram illustrating the process of incorporating semantic models, including elements like 'Embedding Models' and " width="2000" height="778" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 1: When embedding a document that covers multiple topics, the resulting vector represents a blend of all paragraphs, potentially losing the distinct, specific information contained in each individual paragraph.</span></figcaption></figure><p>This leads to several problems:</p><ul><li><strong>Representation Dilution:</strong> While all topics in a given text <em>could</em> be related, only one may be relevant to a user’s search query. However, a single embedding (in this case, that of the whole blog post) is just one point in the vector space. As more text is added to the model’s input, the embedding shifts to capture the overall topic of the article, making it less effective in representing content covered in specific paragraphs.</li><li><strong>Limited Capacity:</strong> Embedding models produce vectors of a fixed size, independent of input length. As more content is added to the input, it gets harder for the model to represent all this information in the vector. Think of it like scaling an image down to 16×16 pixels — If you scale an image of something simple, like an apple, you can still derive meaning from the scaled image. Scaling down a street map of Berlin? Not so much.</li><li><strong>Information Loss:</strong> In some cases, even long-context embedding models hit their limits; Many models support text encoding with up to 8,192 tokens. Longer documents need to be truncated before embedding, leading to information loss. If the information relevant to the user is located at the end of the document, it won’t be captured by the embedding at all.</li><li><strong>You May <em>Need</em> Text Segmentation:</strong> Some applications require embeddings for specific segments of the text but not for the entire document, like identifying the relevant passage in a text.</li></ul><h2 id="long-context-vs-truncation" style="position: relative;"><a href="#long-context-vs-truncation" title="Long Context vs. Truncation" id="anchor-long-context-vs-truncation"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Long Context vs. Truncation</h2><p>To see whether long context is worthwhile at all, let’s look at the performance of two retrieval scenarios:</p><ul><li>Encoding documents up to 8,192 tokens (about 10 pages of text).</li><li>Truncating documents at 192 tokens and encoding up to there.</li></ul><p>We’ll compare results using <code>jina-embeddings-v3</code> with the nDCG@10 retrieval metric. We tested the following datasets:</p>

<table>
<thead>
<tr>
<th>Dataset</th>
<th>Description</th>
<th>Query Example</th>
<th>Document Example</th>
<th>Mean Document Length (characters)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/"><strong>NFCorpus</strong></a></td>
<td>A full-text medical retrieval dataset with 3,244 queries and documents mostly from PubMed.</td>
<td>"Using Diet to Treat Asthma and Eczema"</td>
<td>"Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland Recent studies have suggested that [...]"</td>
<td>326,753</td>
</tr>
<tr>
<td><a href="https://github.com/Yale-LILY/QMSum"><strong>QMSum</strong></a></td>
<td>A query-based meeting summarization dataset requiring summarization of relevant meeting segments.</td>
<td>"The professor was the one to raise the issue and suggested that a knowledge engineering trick [...]"</td>
<td>"Project Manager: Is that alright now ? {vocalsound} Okay . Sorry ? Okay , everybody all set to start the meeting ? [...]"</td>
<td>37,445</td>
</tr>
<tr>
<td><a href="https://paperswithcode.com/dataset/narrativeqa"><strong>NarrativeQA</strong></a></td>
<td>QA dataset featuring long stories and corresponding questions about specific content.</td>
<td>"What kind of business Sophia owned in Paris?"</td>
<td>"ï»¿The Project Gutenberg EBook of The Old Wives' Tale, by Arnold Bennett\n\nThis eBook is for the use of anyone anywhere [...]"</td>
<td>53,336</td>
</tr>
<tr>
<td><a href="https://github.com/Alab-NII/2wikimultihop"><strong>2WikiMultihopQA</strong></a></td>
<td>A multi-hop QA dataset with up to 5 reasoning steps, designed with templates to avoid shortcuts.</td>
<td>"What is the award that the composer of song The Seeker (The Who Song) earned?"</td>
<td>"Passage 1:\nMargaret, Countess of Brienne\nMarguerite d'Enghien (born 1365 - d. after 1394), was the ruling suo jure [...]"</td>
<td>30,854</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2104.07091"><strong>SummScreenFD</strong></a></td>
<td>A screenplay summarization dataset with TV series transcripts and summaries requiring dispersed plot integration.</td>
<td>"Penny gets a new chair, which Sheldon enjoys until he finds out that she picked it up from [...]"</td>
<td>"[EXT. LAS VEGAS CITY (STOCK) - NIGHT]\n[EXT. ABERNATHY RESIDENCE - DRIVEWAY -- NIGHT]\n(The lamp post light over the [...]"</td>
<td>1,613</td>
</tr>
</tbody>
</table>

<p>As we can see, encoding more than 192 tokens can give notable performance improvements:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png" class="kg-image" alt="Bar chart titled 'Jina-Embeddings-V3' comparing performance of embedding tools with metrics plotted on the y-axis against a b" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 2: Comparison of Long-Context Embedding Performance and Short Text Embedding Performance</span></figcaption></figure><p>However, on some datasets, we see bigger improvements than on others:</p><ul><li>For <strong>NFCorpus</strong>, truncation barely makes a difference. This is because the titles and abstracts are right at the start of the documents, and these are highly relevant to typical user search terms. Whether truncated or not, the most pertinent data remains within the token limit.</li><li><strong>QMSum</strong> and <strong>NarrativeQA</strong> are considered "reading comprehension" tasks, where users typically search for specific facts within a text. These facts are often embedded in details scattered across the document, and may fall outside the truncated 192-token limit. For instance, in the NarrativeQA document <em>Percival Keene</em>, the question "Who is the bully that steals Percival's lunch?" is answered well beyond this limit. Similarly, in <strong>2WikiMultiHopQA</strong>, relevant information is dispersed throughout entire documents, requiring models to navigate and synthesize knowledge from multiple sections to answer queries effectively.</li><li><strong>SummScreenFD</strong> is a task aimed at identifying the screenplay corresponding to a given summary. Because the summary encompasses information distributed across the screenplay, encoding more of the text improves the accuracy of matching the summary to the correct screenplay.</li></ul><h2 id="segmenting-text-for-better-retrieval-performance" style="position: relative;"><a href="#segmenting-text-for-better-retrieval-performance" title="Segmenting Text for Better Retrieval Performance" id="anchor-segmenting-text-for-better-retrieval-performance"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Segmenting Text for Better Retrieval Performance</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Moving forwards, we discuss three similar concepts. To avoid confusion, we refer them as follows:<br>• <b><strong style="white-space: pre-wrap;">Segmentation</strong></b>: Detecting boundary cues in an input text, for example, sentences or a fixed number of tokens.<br>• <b><strong style="white-space: pre-wrap;">Naive chunking</strong></b>: Breaking the text into chunks based on segmentation cues, prior to encoding it.<br>• <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">Late chunking</strong></b></a>: Encoding the document first and then segmenting it (preserving context between chunks).</div></div><p>Instead of embedding an entire document into one vector, we can use various methods to first segment the document by assigning boundary cues:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/chunking-animation.gif" class="kg-image" alt="Black background image featuring the poem &quot;Books are like doors to new worlds...&quot; with different text processing styles label" width="2000" height="492" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/chunking-animation.gif 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/chunking-animation.gif 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/chunking-animation.gif 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/chunking-animation.gif 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 3: Applying “Fixed-Size”, “Sentence-Based”, and “Semantic” chunking method to a text passage</span></figcaption></figure><p>Some common methods include:</p><ul><li><strong>Segmenting by fixed size:</strong> The document is divided into segments of a fixed number of tokens, determined by the embedding model’s tokenizer. This ensures the tokenization of the segments corresponds to the tokenization of the entire document (segmenting by a specific number of characters could lead to a different tokenization).</li><li><strong>Segmenting by sentence:</strong> The document is segmented into sentences, and each chunk consists of <em>n</em> number of sentences.</li><li><strong>Segmenting by semantics:</strong> Each segment corresponds to multiple sentences and an embedding model determines the similarity of consecutive sentences. Sentences with high embedding similarities are assigned to the same chunk.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">You can easily perform segmentation with <a href="https://jina.ai/segmenter/">Jina Segmenter</a>, our free API for segmenting long text into chunks and tokenization based on the structure of the document.</div></div><p>For simplicity, we use fixed-size segmentation in this article.</p><h3 id="document-retrieval-using-naive-chunking" style="position: relative;"><a href="#document-retrieval-using-naive-chunking" title="Document Retrieval Using Naive Chunking" id="anchor-document-retrieval-using-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Document Retrieval Using Naive Chunking</h3><p>Once we’ve performed fixed-size segmentation, we can naively chunk the document according to those segments:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png" class="kg-image" alt="Screenshot showing comparative analysis between text excerpts in &quot;Document 1&quot; and annotations, focused on themes of books and" width="960" height="540" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 960w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 4: Naive chunking based on boundary cues detected during segmentation.</span></figcaption></figure><p>Using <code>jina-embeddings-v3</code>, we encode each chunk into an embedding that accurately captures its semantics, then store those embeddings in a vector database.</p><p>At runtime, the model encodes a user’s query to a query vector. We compare this against our vector database of chunk embeddings to find the chunk with the highest cosine similarity, and then return the corresponding document to the user:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--17-.png" class="kg-image" alt="Diagram showcasing document embedding process with blocks for 'Doc ID', 'Chunk ID', and 'Embedding'." width="2000" height="847" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--17-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--17-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--17-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/image--17-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 5: Document retrieval implemented with naive chunking: (1) The documents in the collection are split into chunks based on boundary cues, (2) the embedding model encodes all chunks and we store the resulting embeddings in a database, (3) when a query comes in, the embedding model encodes it and the database determines the most similar chunk. At the end we identify the relevant document from the document ID stored for the chunk in the database and return it to the user.</span></figcaption></figure><h3 id="problems-with-naive-chunking" style="position: relative;"><a href="#problems-with-naive-chunking" title="Problems with Naive Chunking" id="anchor-problems-with-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Problems with Naive Chunking</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png" class="kg-image" alt="Text excerpt from a Wikipedia article about Berlin highlighting its status as Germany's capital and its demographic details." width="1774" height="456" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--18-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--18-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--18-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png 1774w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 6: When chunking a text into sentences, references to earlier parts of the text cannot be resolved.</span></figcaption></figure><p>While naive chunking addresses some of the limitations of long-context embedding models, it also has its downsides:</p><ul><li><strong>Missing the Bigger Picture:</strong> When it comes to document retrieval, multiple embeddings of smaller chunks may fail to capture the document’s overall topic. Think of not being able to see the forest for the trees.</li><li><strong>Missing Context Problem:</strong> Chunks can’t be interpreted accurately as context information is missing, as illustrated in Figure 6.</li><li><strong>Efficiency:</strong> More chunks require more storage and increase retrieval time.</li></ul><h2 id="late-chunking-solves-the-context-problem" style="position: relative;"><a href="#late-chunking-solves-the-context-problem" title="Late Chunking Solves the Context Problem" id="anchor-late-chunking-solves-the-context-problem"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Late Chunking Solves the Context Problem</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">To solve the problem of missing context, we introduced a novel method called “late chunking”, described in our previous blog posts: <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">part I</strong></b></a>, <a href="https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/"><b><strong style="white-space: pre-wrap;">part II</strong></b></a>, <a href="https://jina.ai/news/finding-optimal-breakpoints-in-long-documents-using-small-language-models"><b><strong style="white-space: pre-wrap;">part III</strong></b></a>, <a href="https://arxiv.org/abs/2409.04701"><b><strong style="white-space: pre-wrap;">research paper</strong></b></a>.</div></div><p>Late chunking works in two main steps:</p><ol><li>First, it uses the model's long-context capabilities to encode the entire document into token embeddings. This preserves the full context of the document.</li><li>Then, it creates chunk embeddings by applying mean pooling to specific sequences of token embeddings, corresponding to the boundary cues identified during segmentation.</li></ol><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png" class="kg-image" alt="Diagram comparing 'Naive Chunking' and 'Late Chunking', depicting algorithm steps with labels, and emphasizing the 'Late' app" width="1200" height="865" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--19-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--19-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 7: Late vs naive chunking.</span></figcaption></figure><p>The key advantage of this approach is that the token embeddings are contextualized - meaning they naturally capture references and relationships to other parts of the document. Since the embedding process happens before chunking, each chunk retains awareness of the broader document context, solving the missing context problem that plagues naive chunking approaches.</p><p>For documents that exceed the model's maximum input size, we can use "long late chunking":</p><ol><li>First, we break the document into overlapping "macro-chunks." Each macro-chunk is sized to fit within the model's maximum context length (for example, 8,192 tokens).</li><li>The model processes these macro-chunks to create token embeddings.</li><li>Once we have the token embeddings, we proceed with standard late chunking - applying mean pooling to create the final chunk embeddings.</li></ol><p>This approach allows us to handle documents of any length while still preserving the benefits of late chunking. Think of it as a two-stage process: first making the document digestible for the model, then applying the regular late chunking procedure.</p><p>In short:</p><ul><li><strong>Naive chunking:</strong> Segment the document into small chunks, then encode each chunk separately.</li><li><strong>Late chunking:</strong> Encode the entire document at once to create token embeddings, then create chunk embeddings by pooling the token embeddings based on segment boundaries.</li><li><strong>Long late chunking:</strong> Split large documents into overlapping macro-chunks that fit the model's context window, encode these to get token embeddings, then apply late chunking as normal.</li></ul><p>For a more extensive description of the idea, take a look at our <a href="https://arxiv.org/abs/2409.04701">paper</a> or the blog posts mentioned above.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2409.04701"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models</div><div class="kg-bookmark-description">Many use cases require retrieving smaller portions of text, and dense vector-based retrieval systems often perform better with shorter text segments, as the semantics are less likely to be over-compressed in the embeddings. Consequently, practitioners often split text documents into smaller chunks and encode them separately. However, chunk embeddings created in this way can lose contextual information from surrounding chunks, resulting in sub-optimal representations. In this paper, we introduce a novel method called late chunking, which leverages long context embedding models to first embed all tokens of the long text, with chunking applied after the transformer model and just before mean pooling - hence the term late in its naming. The resulting chunk embeddings capture the full contextual information, leading to superior results across various retrieval tasks. The method is generic enough to be applied to a wide range of long-context embedding models and works without additional training. To further increase the effectiveness of late chunking, we propose a dedicated fine-tuning approach for embedding models.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-6.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-2.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="to-chunk-or-not-to-chunk" style="position: relative;"><a href="#to-chunk-or-not-to-chunk" title="To Chunk or Not to Chunk?" id="anchor-to-chunk-or-not-to-chunk"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>To Chunk or Not to Chunk?</h2><p>We’ve already seen that long-context embedding generally outperforms shorter text embeddings, and given an overview of both naive and late chunking strategies. The question now is: Is chunking better than long-context embedding?</p><p>To conduct a fair comparison, we truncate text values to the maximum sequence length of the model (8,192 tokens) before starting to segment them. We use fixed-size segmentation with 64 tokens per segment (for both naive segmentation and late chunking). Let's compare three scenarios:</p><ul><li><strong>No segmentation:</strong> We encode each text into a single embedding. This leads to the same scores as the previous experiment (see Figure 2), but we include them here to better compare them.</li><li><strong>Naive chunking:</strong> We segment the texts, then apply naive chunking based on the boundary cues.</li><li><strong>Late chunking:</strong> We segment the texts, then use late chunking to determine embeddings.</li></ul><p>For both late chunking and naive segmentation, we use chunk retrieval to determine the relevant document (as shown in Figure 5, earlier in this post).</p><p>The results show no clear winner:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png" class="kg-image" alt="Bar chart showcasing performance comparison of methods like No Chucking and Naive Chunking based on NDCG@10%, with a dynamic " width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 8: No chunking vs naive chunking vs late chunking</span></figcaption></figure><ul><li><strong>For fact retrieval, naive chunking performs better:</strong> For the QMSum, NarrativeQA, and 2WikiMultiHopQA datasets, the model has to identify relevant passages in the document. Here, naive chunking is clearly better than encoding everything into a single embedding, as likely only a few chunks include relevant information, and said chunks capture it much better than a single embedding of the whole document.</li><li><strong>Late chunking works best with coherent documents and relevant context:</strong> For documents covering a coherent topic where users search for overall themes rather than specific facts (like in NFCorpus), late chunking slightly outperforms no chunking, as it balances document-wide context with local detail. However, while late chunking generally performs better than naive chunking by preserving context, this advantage can become a liability when searching for isolated facts within documents containing mostly irrelevant information - as seen in the performance regressions for NarrativeQA and 2WikiMultiHopQA, where the added context becomes more distracting than helpful.</li></ul><h3 id="does-chunk-size-make-a-difference" style="position: relative;"><a href="#does-chunk-size-make-a-difference" title="Does Chunk Size Make a Difference?" id="anchor-does-chunk-size-make-a-difference"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Does Chunk Size Make a Difference?</h3><p>The effectiveness of chunking methods really depends on the dataset, highlighting how content structure plays a crucial role:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png" class="kg-image" alt="Three comparative graphs displaying performance metrics for datasets NFCorpus, QMSum, and NarrativeQA using Naive and Late Ch" width="1200" height="1800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--21-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--21-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 9: Comparison of chunk sizes with naive and late chunking.</span></figcaption></figure><p>As we can see, late chunking generally beats naive chunking at smaller chunk sizes, since smaller naive chunks are too small to contain much context, while smaller late chunks retain the context of the entire document, making them more semantically meaningful. The exception to this is the NarrativeQA dataset where there is simply so much irrelevant context that late chunking falls behind. At larger chunk sizes, naive chunking shows marked improvement (occasionally beating late chunking) due to the increased context, while late chunking’s performance gradually decreases.</p><h2 id="takeaways-when-to-use-what" style="position: relative;"><a href="#takeaways-when-to-use-what" title="Takeaways: When To Use What?" id="anchor-takeaways-when-to-use-what"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Takeaways: When To Use What?</h2><p>In this post, we’ve looked at different types of document retrieval tasks to better understand when to use segmentation and when late chunking helps. So, what we have learned?</p><h3 id="when-should-i-use-long-context-embedding" style="position: relative;"><a href="#when-should-i-use-long-context-embedding" title="When Should I use Long-Context Embedding?" id="anchor-when-should-i-use-long-context-embedding"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>When Should I use Long-Context Embedding?</h3><p>In general, it doesn’t harm retrieval accuracy to include as much text of your documents as you can to the input of your embedding model. However, long-context embedding models often focus on the beginning of documents, as they contain content like titles and introduction which are more important for judging relevance, but the models might miss content in the middle of the document.</p><h3 id="when-should-i-use-naive-chunking" style="position: relative;"><a href="#when-should-i-use-naive-chunking" title="When Should I use Naive Chunking?" id="anchor-when-should-i-use-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>When Should I use Naive Chunking?</h3><p>When documents cover multiple aspects, or user queries target specific information within a document, chunking generally improves retrieval performance.</p><p>Eventually, segmentation decisions depend on factors like the need to display partial text to users (e.g. as Google presents the relevant passages in the previews of the search results), which makes segmentation essential, or constraints on compute and memory, where segmentation may be less favorable due to increased retrieval overhead and resource usage.</p><h3 id="when-should-i-use-late-chunking" style="position: relative;"><a href="#when-should-i-use-late-chunking" title="When Should I use Late Chunking?" id="anchor-when-should-i-use-late-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>When Should I use Late Chunking?</h3><p>By encoding the full document before creating chunks, late chunking solves the problem of text segments losing their meaning due to missing context. This works particularly well with coherent documents, where each part relates to the whole. Our experiments show that late chunking is especially effective when dividing text into smaller chunks, as demonstrated in our <a href="https://arxiv.org/abs/2409.04701">paper</a>. However, there's one caveat: if parts of the document are unrelated to each other, including this broader context can actually make retrieval performance worse, as it adds noise to the embeddings.</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusion" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusion</h2><p>The choice between long-context embedding, naive chunking, and late chunking depends on the specific requirements of your retrieval task. Long-context embeddings are valuable for coherent documents with general queries, while chunking excels in cases where users seek specific facts or information within a document. Late chunking further enhances retrieval by retaining contextual coherence within smaller segments. Ultimately, understanding your data and retrieval goals will guide the optimal approach, balancing accuracy, efficiency, and contextual relevance.</p><p>If you're exploring these strategies, consider trying out <code>jina-embeddings-v3</code>—its advanced long-context capabilities, late chunking, and flexibility make it an excellent choice for diverse retrieval scenarios.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-15.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-5.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure></section></article><div data-v-33ef2eff="" class="row justify-between items-center q-py-md"><div data-v-33ef2eff=""><span data-v-33ef2eff="" class="text-weight-bold">Categories:</span><span data-v-33ef2eff="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech blog</div></div></div></span></div><div data-v-33ef2eff=""><div data-v-33ef2eff="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-33ef2eff="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fen-US%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-33ef2eff="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-33ef2eff="" class="text-h5 q-my-xl">Read more</div><a data-v-1f724e3b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/scaling-test-time-compute-for-embedding-models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1f724e3b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-1f724e3b="" class="q-focus-helper"></span><div data-v-1f724e3b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-1f724e3b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__label q-item__label--caption text-caption">December 12, 2024 • 11 minutes read</div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__section column q-item__section--main justify-center"><div data-v-1f724e3b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Scaling Test-Time Compute For Embedding Models</div></div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-1f724e3b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-1f724e3b="" class="col-4 overflow-hidden"><div data-v-1f724e3b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="David Hockney artwork of a hand holding a rod with three colored spheres on a blue-toned background."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="David Hockney artwork of a hand holding a rod with three colored spheres on a blue-toned background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/test-time-compute.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></a><a data-v-1f724e3b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/watermarking-text-with-embedding-models-to-protect-against-content-theft"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1f724e3b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-1f724e3b="" class="q-focus-helper"></span><div data-v-1f724e3b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-1f724e3b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__label q-item__label--caption text-caption">November 27, 2024 • 10 minutes read</div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__section column q-item__section--main justify-center"><div data-v-1f724e3b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Watermarking Text with Embedding Models to Protect Against Content Theft</div></div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-1f724e3b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-1f724e3b="" class="col-4 overflow-hidden"><div data-v-1f724e3b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/banner--1-.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-1f724e3b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/meta-prompt-for-better-jina-api-integration-and-codegen"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1f724e3b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-1f724e3b="" class="q-focus-helper"></span><div data-v-1f724e3b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-1f724e3b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__label q-item__label--caption text-caption">November 19, 2024 • 9 minutes read</div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__section column q-item__section--main justify-center"><div data-v-1f724e3b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Meta-Prompt for Better Jina API Integration and CodeGen</div></div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-1f724e3b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-1f724e3b="" class="col-4 overflow-hidden"><div data-v-1f724e3b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Digital transformation icons with arrows on a teal background indicate file conversion, with contrasting blue and grey accent"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Digital transformation icons with arrows on a teal background indicate file conversion, with contrasting blue and grey accent" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--58-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Offices</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Sunnyvale, CA</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, USA</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption text-dim">Level 5, Building 6, No.48 Haidian West St. Beijing, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption text-dim">402 Floor 4, Fu'an Technology Building, Shenzhen, China</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Search Foundation</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Embeddings</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Reranker</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Reader</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Classifier</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Segmenter</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Get Jina AI API key</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Rate Limit</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">API Status</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Company</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Newsroom</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Download logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Terms</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/COMMERCIAL-LICENSE-TERMS.pdf" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Commercial License</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#security"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Security</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; Conditions</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Privacy</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Manage Cookies</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-between q-gutter-x-sm col-12 col-md"><label class="q-field row no-wrap items-start q-field--outlined q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dense q-field--dark text-caption" for="f_6c40d45d-508a-4262-916c-b80049c9319c"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-symbols material-symbols-sharp q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_6c40d45d-508a-4262-916c-b80049c9319c" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_6c40d45d-508a-4262-916c-b80049c9319c_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">arrow_drop_down</i></div></div></div></label><div class="text-caption text-dim"> Jina AI © 2020-2024. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>