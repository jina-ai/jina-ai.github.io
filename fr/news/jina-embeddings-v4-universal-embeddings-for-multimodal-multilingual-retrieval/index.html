<!DOCTYPE html><html translate="no" dir="ltr" lang="fr"><head><title>Jina Embeddings v4 : Vecteurs universels pour la recherche multimodale et multilingue</title><meta charset="utf-8"><meta name="title" content="Jina Embeddings v4 : Vecteurs universels pour la recherche multimodale et multilingue"><meta name="description" content="Jina Embeddings v4 est un modèle d'向量模型 (Embeddings) universel de 3,8 milliards de paramètres pour la recherche multimodale et multilingue qui prend en charge les sorties d'向量模型 (Embeddings) à vecteur unique et à vecteurs multiples."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval"><meta property="og:title" content="Jina Embeddings v4 : Vecteurs universels pour la recherche multimodale et multilingue"><meta property="og:description" content="Jina Embeddings v4 est un modèle d'向量模型 (Embeddings) universel de 3,8 milliards de paramètres pour la recherche multimodale et multilingue qui prend en charge les sorties d'向量模型 (Embeddings) à vecteur unique et à vecteurs multiples."><meta property="og:image" content="https://jina.ai/blog-banner/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval"><meta property="twitter:title" content="Jina Embeddings v4 : Vecteurs universels pour la recherche multimodale et multilingue"><meta property="twitter:description" content="Jina Embeddings v4 est un modèle d'向量模型 (Embeddings) universel de 3,8 milliards de paramètres pour la recherche multimodale et multilingue qui prend en charge les sorties d'向量模型 (Embeddings) à vecteur unique et à vecteurs multiples."><meta property="twitter:image" content="https://jina.ai/blog-banner/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-BumM2D-P.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-rzO9Riiq.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-euA0SSb2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-Cg0dwsIc.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-HI1gZU-B.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-CvaMO2se.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-BH19cYjA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-CFXzYjD7.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/fr-DiR1v30g.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-Zo3aWnLX.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CRYKqATq.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-DmvyD6Yq.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/UserAvatarComponent-BsZGGR2_.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-BUF9mLqU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-FHURb6bB.js"><link rel="stylesheet" crossorigin="" href="/assets/UserAvatarComponent-HOhEbA2Z.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-OOxLHn_4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-CE0zfpha.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-7GLAMZNt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-eIKK1Cj3.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-erbvaxJ-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-Dj0Kj3Pn.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-ftSze8Eo.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-DV5b5DfL.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-DRcK0cSp.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-Cudx1rx3.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-DMpjmCd1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-Bxd6njqo.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-B5wwZO2S.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-ClA_0Sfw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-DveumXia.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-DihvZdVB.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-CC4zr72u.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-CukuawoY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-ipkcy9HK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-Bktc_RdF.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-CMWXfnSe.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-94OirUG2.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-0v_6KiP0.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Jina AI"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Jina AI"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="12 mins read"><meta property="article:published_time" content="2025-06-25T06:48:16.000+02:00"><meta property="article:modified_time" content="2025-06-25T06:48:16.000+02:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Jina Embeddings v4 : Vecteurs universels pour la recherche multimodale et multilingue",
  "description": "Jina Embeddings v4 est un modèle d'向量模型 (Embeddings) universel de 3,8 milliards de paramètres pour la recherche multimodale et multilingue qui prend en charge les sorties d'向量模型 (Embeddings) à vecteur unique et à vecteurs multiples.",
  "image": [
    "https://jina.ai/blog-banner/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval.webp"
  ],
  "datePublished": "2025-06-25T06:48:16.000+02:00",
  "dateModified": "2025-06-25T06:48:16.000+02:00",
  "author": [
    {
      "@type": "Organization",
      "name": "Jina AI",
      "url": "https://jina.ai"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-ce90450d="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-ce90450d="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-ce90450d="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-ce90450d="" class="q-space"></div><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-ce90450d="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-ce90450d="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-ce90450d="" class="q-list q-list--dark" role="list"><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Nouvelles</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Modèles</div></a><div data-v-ce90450d="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_10124688-6044-4956-858b-e03560d3aa64" aria-label="Développer &quot;Des produits&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Des produits</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_10124688-6044-4956-858b-e03560d3aa64" style="display: none;"><div data-v-ce90450d="" class="q-list q-list--dark" role="list" label="Des produits"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lecteur</div><div class="q-item__label q-item__label--caption text-caption">Lisez les URL et effectuez des recherches sur le Web pour de meilleurs LLM de base.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Intégrations</div><div class="q-item__label q-item__label--caption text-caption">Intégrations multimodales et multilingues de classe mondiale.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reclasseur</div><div class="q-item__label q-item__label--caption text-caption">Récupérateur neuronal de classe mondiale pour maximiser la pertinence de la recherche.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Recherche profonde</div><div class="q-item__label q-item__label--caption text-caption">Recherchez, lisez et raisonnez jusqu'à trouver la meilleure réponse.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_547922d7-d2dd-410e-b1e9-8ef8179d8b95" aria-label="Développer &quot;Plus&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Plus</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_547922d7-d2dd-410e-b1e9-8ef8179d8b95" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Classificateur</div><div class="q-item__label q-item__label--caption text-caption">Classification à zéro plan et à quelques plans pour l'image et le texte.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmenteur</div><div class="q-item__label q-item__label--caption text-caption">Coupez un long texte en morceaux et effectuez la tokenisation.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Documentation de l'API</div><div class="q-item__label q-item__label--caption text-caption">Génération automatique de code pour votre IDE ou LLM copilote</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-ce90450d="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_0d3a4ffa-fe86-4d64-ac80-daafd229c361" aria-label="Développer &quot;Entreprise&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Entreprise</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_0d3a4ffa-fe86-4d64-ac80-daafd229c361" style="display: none;"><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">À propos de nous</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Contacter le service commercial</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Programme de stage</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Rejoignez-nous</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Télécharger le logo</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">termes et conditions</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Se connecter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Se connecter</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-ce90450d="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_2f653e81-7cd4-4902-a93b-50732c7308f5"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_2f653e81-7cd4-4902-a93b-50732c7308f5" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_2f653e81-7cd4-4902-a93b-50732c7308f5_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-ce90450d="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Nouvelle architecture</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Getting Started</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Conclusion</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Mis en exergue</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">communiqué de presse</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">juin 25, 2025</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">Jina Embeddings v4 : Vecteurs universels pour la recherche multimodale et multilingue</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Jina Embeddings v4 est un modèle d'向量模型 (Embeddings) universel de 3,8 milliards de paramètres pour la recherche multimodale et multilingue qui prend en charge les sorties d'向量模型 (Embeddings) à vecteur unique et à vecteurs multiples.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/je-v4.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Jina AI"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Jina AI" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Jina AI • 12 minutes lues</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/models/jina-embeddings-v4"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v4 - Search Foundation Models</div><div class="kg-bookmark-description">Universal embedding model for multimodal and multilingual retrieval</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-35.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Search Foundation Models</span><span class="kg-bookmark-publisher">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-v4.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2506.18902"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval</div><div class="kg-bookmark-description">We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding model that unifies text and image representations through a novel architecture supporting both single-vector and multi-vector embeddings in the late interaction style. The model incorporates task-specific Low-Rank Adaptation (LoRA) adapters to optimize performance across diverse retrieval scenarios, including query-based information retrieval, cross-modal semantic similarity, and programming code search. Comprehensive evaluations demonstrate that jina-embeddings-v4 achieves state-of-the-art performance on both single- modal and cross-modal retrieval tasks, with particular strength in processing visually rich content such as tables, charts, diagrams, and mixed-media formats. To facilitate evaluation of this capability, we also introduce Jina-VDR, a novel benchmark specifically designed for visually rich image retrieval.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-38.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-34.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-embeddings-v4"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-embeddings-v4 · Hugging Face</div><div class="kg-bookmark-description">We’re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-39.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-v4-1.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Aujourd'hui, nous publions <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a>, notre nouveau modèle d'向量模型 (Embeddings) universel de 3,8 milliards de paramètres pour le texte et les images. Il comprend un ensemble d'adaptateurs LoRA spécifiques à chaque tâche qui optimisent les performances pour les tâches de récupération les plus courantes, notamment la récupération de requêtes-documents, la correspondance sémantique et la recherche de code. <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> atteint des performances de récupération de pointe sur les tâches multimodales et multilingues à travers les benchmarks MTEB, MMTEB, CoIR, LongEmbed, STS, <a href="https://github.com/jina-ai/jina-vdr">Jina-VDR</a>, CLIP et ViDoRe, avec une force particulière dans le traitement de contenu visuellement riche tel que les tableaux, les graphiques, les diagrammes et les mélanges de ceux-ci. Le modèle prend en charge à la fois les 向量模型 (Embeddings) à vecteur unique et à vecteurs multiples.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/model-perf-boxplot--18-.png" class="kg-image" alt="" width="2000" height="2781" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/06/model-perf-boxplot--18-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/06/model-perf-boxplot--18-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/06/model-perf-boxplot--18-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/06/model-perf-boxplot--18-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Performance de </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;"> à travers la récupération de documents visuels et les benchmarks multimodaux. Les distributions de boîtes à moustaches montrent les scores moyens et la variabilité des performances des modèles d'向量模型 (Embeddings) à travers six catégories de benchmarks : ViDoRe (récupération de documents visuels), Jina-VDR (récupération complète de documents visuels), Wikimedia Commons Retrieval (correspondance multilingue document-description), GitHub README Retrieval (récupération de documentation de code), Tweet Stock Retrieval (analyse de graphiques financiers) et CLIP Benchmark (récupération générale texte-image). Les variantes de Jina-embeddings-v4 (surlignées en cyan) démontrent des performances de pointe à travers les tâches de documents visuellement riches, avec la version à vecteurs multiples atteignant les scores les plus élevés dans les benchmarks de documents visuels spécialisés (90,2 sur ViDoRe, 80,2 sur Jina-VDR), tout en maintenant des performances compétitives sur les tâches générales de récupération multimodale (84,1 sur CLIP Benchmark). Les modèles sont classés par performance moyenne dans chaque catégorie de benchmark, avec des points de données individuels montrant les distributions de scores à travers plusieurs tâches d'évaluation.</span></figcaption></figure><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> est notre modèle d'向量模型 (Embeddings) le plus ambitieux à ce jour. En tant que modèle open source, <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> surpasse les principaux modèles d'向量模型 (Embeddings) propriétaires des principaux fournisseurs, offrant des performances supérieures de 12 % à <code>text-embedding-3-large</code> d'OpenAI sur la récupération multilingue (66,49 contre 59,27), une amélioration de 28 % sur les tâches de documents longs (67,11 contre 52,42), 15 % de mieux que <code>voyage-3</code> sur la récupération de code (71,59 contre 67,23) et égalant les performances de <code>gemini-embedding-001</code> de Google. Cela fait de v4 le modèle d'向量模型 (Embeddings) universel open source le plus performant disponible aujourd'hui, offrant aux chercheurs et aux développeurs des capacités d'向量模型 (Embeddings) multimodales de niveau entreprise avec une transparence totale sur le processus de formation, les décisions architecturales et les poids du modèle grâce à <a href="https://arxiv.org/abs/2506.18902">notre rapport technique complet.</a></p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/model-perf-boxplot--15-.png" class="kg-image" alt="" width="2000" height="2631" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/06/model-perf-boxplot--15-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/06/model-perf-boxplot--15-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/06/model-perf-boxplot--15-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/06/model-perf-boxplot--15-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Performance de </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;"> à travers cinq benchmarks de récupération. Le graphique montre les distributions de boîtes à moustaches avec les scores moyens pour chaque modèle à travers les benchmarks de récupération de texte, de récupération de code, de récupération multilingue, de récupération de contexte long et de similarité textuelle sémantique (STS). </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;"> (surligné en cyan) démontre des performances compétitives ou de pointe à travers toutes les catégories d'évaluation, avec des résultats particulièrement solides dans la récupération de texte et STS. Les modèles sont classés par performance moyenne dans chaque catégorie de benchmark, avec des points de données individuels montrant les distributions de scores à travers plusieurs tâches d'évaluation.</span></figcaption></figure><h2 id="new-architecture" style="position: relative;"><a href="#new-architecture" title="Nouvelle architecture" id="anchor-new-architecture"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Nouvelle architecture</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/Heading--51-.svg" class="kg-image" alt="" width="1200" height="630" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Architecture de </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;">. Le modèle est construit sur la base de </span><code spellcheck="false" style="white-space: pre-wrap;"><span>Qwen2.5-VL-3B-Instruct</span></code><span style="white-space: pre-wrap;"> (3,8 milliards de paramètres). Les entrées de texte et d'image sont traitées via un chemin partagé : les images sont d'abord converties en séquences de 词元 (Tokens) via un encodeur de vision, puis les deux modalités sont traitées conjointement par le décodeur de modèle de langage avec des couches d'attention contextuelle. Trois adaptateurs LoRA spécifiques à chaque tâche (60 millions de paramètres chacun) fournissent une optimisation spécialisée pour les tâches de récupération, de correspondance de texte et de code sans modifier les poids de la base gelée. L'architecture prend en charge deux modes de sortie : (1) 向量模型 (Embeddings) à vecteur unique (2048 dimensions, tronquables à 128) générés via un pooling moyen pour une recherche de similarité efficace, et (2) 向量模型 (Embeddings) à vecteurs multiples (128 dimensions par 词元 (Token)) via des couches de projection pour les stratégies de récupération d'interaction tardive.</span></figcaption></figure><p>La mise à niveau de <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> à<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> représente un changement de paradigme, passant des 向量模型 (Embeddings) uniquement textuels aux 向量模型 (Embeddings) multimodaux. Alors que la version v3 se concentrait sur l'optimisation des 向量模型 (Embeddings) textuels avec des adaptateurs LoRA spécifiques à chaque tâche, la version v4 répond au besoin croissant d'intégrer à la fois du contenu textuel et visuel dans des représentations unifiées.

</p><table>
<thead>
<tr>
<th><strong>Aspect</strong></th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">&lt;strong&gt;jina-embeddings-v3&lt;/strong&gt;</span></a></th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">&lt;strong&gt;jina-embeddings-v4&lt;/strong&gt;</span></a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Backbone Model</td>
<td>jina-XLM-RoBERTa</td>
<td>Qwen2.5-VL-3B-Instruct</td>
</tr>
<tr>
<td>Parameters (Base)</td>
<td>559M</td>
<td>3.8B</td>
</tr>
<tr>
<td>Parameters (with adapters)</td>
<td>572M</td>
<td>3.8B + 60M per adapter</td>
</tr>
<tr>
<td>Modalities</td>
<td>Text only</td>
<td>Text + Images (multimodal)</td>
</tr>
<tr>
<td>Max Input Length</td>
<td>8,192 tokens</td>
<td>32,768 tokens</td>
</tr>
<tr>
<td>Image Processing</td>
<td>None</td>
<td>Up to 20 megapixels, visually rich documents</td>
</tr>
  <tr>
<td>Multilingual Support</td>
<td>89 languages</td>
<td>29+ languages</td>
</tr>
<tr>
<td>Vector Types</td>
<td>Single-vector only</td>
<td>Single-vector + Multi-vector (late interaction)</td>
</tr>
<tr>
<td>Single-vector Dimensions</td>
<td>1024 (MRL truncatable to 32)</td>
<td>2048 (MRL truncatable to 128)</td>
</tr>
<tr>
<td>Multi-vector Dimensions</td>
<td>Not available</td>
<td>128 per token</td>
</tr>
<tr>
<td>Task LoRA Specializations</td>
<td>• Asymmetric retrieval<br>• Semantic similarity<br>• Classification<br>• Separation</td>
<td>• Asymmetric retrieval<br>• Semantic similarity<br>• Code retrieval</td>
</tr>
<tr>
<td>Training Stages</td>
<td>3-stage: Pre-training → Embedding fine-tuning → Adapter training</td>
<td>2-stage: Joint pair training → Task-specific adapter training</td>
</tr>
<tr>
<td>Loss Functions</td>
<td>InfoNCE, CoSent, Extended triplet loss</td>
<td>Joint InfoNCE + KL divergence for single/multi-vector</td>
</tr>
<tr>
<td>Positional Encoding</td>
<td>RoPE (rotary base frequency tuning)</td>
<td>M-RoPE (Multimodal Rotary Position Embedding)</td>
</tr>
<tr>
<td>Cross-modal Processing</td>
<td>N/A</td>
<td>Unified encoder (reduced modality gap)</td>
</tr>
<tr>
<td>MRL Support</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Attention Implementation</td>
<td>FlashAttention2</td>
<td>FlashAttention2</td>
</tr>
</tbody>
</table>

<h3 id="backbone" style="position: relative;"><a href="#backbone" title="Backbone" id="anchor-backbone"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Backbone</h3><p>Le changement architectural le plus important de la version v4 est le passage de <code>XLM-RoBERTa</code> à <code>Qwen2.5-VL-3B-Instruct</code> pour le backbone. Cette décision a été motivée par l'objectif principal de la version v4, qui est de créer un modèle de 向量模型 (Embedding) universel permettant un "véritable traitement multimodal" où les images sont converties en séquences de 词元 (Tokens) et traitées aux côtés du texte, éliminant ainsi le <a href="https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models">modality gap</a> présent dans les architectures à double encodeur.</p><p>La sélection du backbone s'aligne sur plusieurs objectifs de conception clés : l'excellence de Qwen2.5-VL dans la compréhension des documents soutient directement la force de la version v4 dans le traitement de contenu visuellement riche comme les tableaux, les graphiques et les captures d'écran. Les capacités de résolution dynamique permettent à la version v4 de gérer des images redimensionnées jusqu'à 20 mégapixels, comme spécifié dans l'architecture. L'encodage positionnel avancé fournit la base qui permet à la version v4 d'obtenir un alignement intermodal supérieur avec un score d'alignement de 0,71 contre 0,15 pour OpenAI CLIP.</p><h3 id="lora-adapters" style="position: relative;"><a href="#lora-adapters" title="LoRA Adapters" id="anchor-lora-adapters"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>LoRA Adapters</h3><p>La version v4 simplifie les cinq tâches de la version v3 en trois tâches ciblées, reflétant les leçons apprises sur l'efficacité et l'adoption par les utilisateurs :</p><ul><li><strong>Asymmetric retrieval</strong> (consolidation des adaptateurs query/passage de la version v3)</li><li><strong>Symmetric similarity</strong> (l'équivalent de text-matching de la version v3 pour les tâches STS)</li><li><strong>Code retrieval</strong> (appris de v2-code, manquant dans v3)</li></ul><p>Cette consolidation supprime les adaptateurs de classification et de séparation de la version v3, concentrant la version v4 sur les cas d'utilisation de 向量模型 (Embedding) les plus efficaces : la recherche et le STS.</p><h3 id="output-embeddings" style="position: relative;"><a href="#output-embeddings" title="Output Embeddings" id="anchor-output-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Output Embeddings</h3><p>La version v4 introduit un système à double sortie prenant en charge à la fois les 向量模型 (Embeddings) à vecteur unique et à vecteurs multiples, alors que la version v3 ne fournissait que des sorties à vecteur unique. Cela répond à différents scénarios de recherche :</p><ul><li><strong>Single-vector mode</strong>: 向量模型 (Embeddings) de dimension 2048 (troncables à 128 via MRL) pour une recherche de similarité efficace</li><li><strong>Multi-vector mode</strong>: 128 dimensions par 词元 (Token) pour <a href="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search">late-interaction retrieval</a></li></ul><p>Cette double approche offre une plus grande efficacité avec les représentations multi-vecteurs, en particulier dans la recherche de documents visuellement riches, tout en maintenant l'efficacité pour les tâches de similarité standard. L'avantage constant de 7 à 10 % en termes de performances des multi-vecteurs par rapport au mode single-vector dans les tâches visuelles suggère que l'interaction tardive offre une correspondance sémantique fondamentalement meilleure pour le contenu multimodal.</p><h3 id="parameter-size" style="position: relative;"><a href="#parameter-size" title="Parameter Size" id="anchor-parameter-size"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Parameter Size</h3><p>Bien que la version v4 soit 6,7 fois plus grande que la version v3 (3,8B contre 570M de paramètres), les améliorations de performances en texte seul sont en fait modestes, ce qui suggère que la mise à l'échelle des paramètres a été principalement motivée par les exigences multimodales plutôt que par l'amélioration du texte. Sur les principaux benchmarks de texte, la version v4 atteint 66,49 sur MMTEB contre 58,58 pour la version v3 (amélioration de 14 %) et 55,97 sur MTEB-EN contre 54,33 pour la version v3 (amélioration de 3 %). Pour la recherche de code, la version v4 obtient un score de 71,59 sur CoIR contre 55,07 pour la version v3 (amélioration de 30 %), tandis que les performances sur les documents longs montrent la version v4 à 67,11 contre 55,66 pour la version v3 sur LongEmbed (amélioration de 21 %). L'augmentation substantielle devient justifiée lorsque l'on considère les capacités multimodales de la version v4 : atteindre 84,11 nDCG@5 sur la recherche de documents visuels (Jina-VDR) et 90,17 sur les benchmarks ViDoRe - des capacités totalement absentes dans la version v3. L'augmentation des paramètres représente donc notre investissement dans la fonctionnalité multimodale tout en maintenant des performances de texte compétitives, avec l'architecture unifiée éliminant le besoin de modèles de texte et de vision séparés tout en atteignant un alignement intermodal de 0,71 contre 0,15 pour les approches traditionnelles à double encodeur.</p><h2 id="getting-started" style="position: relative;"><a href="#getting-started" title="Getting Started" id="anchor-getting-started"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Getting Started</h2><p>Pour une vérification rapide, essayez notre démo texte-image dans la boîte à outils Search Foundation. Nous avons préparé une collection d'images de documents provenant de notre site Web, et vous pouvez également ajouter vos propres URL d'images. Tapez simplement votre requête et appuyez sur Entrée pour voir les résultats classés. Vous pouvez les récupérer comme de la reconnaissance optique de caractères (OCR) ou de la recherche d'images basée sur le contenu - n'hésitez pas non plus à essayer des requêtes dans des langues autres que l'anglais.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://jina-ai-gmbh.ghost.io/content/media/2025/04/m0-demo-1_thumb.jpg" data-kg-custom-thumbnail="">
            <div class="kg-video-container" style="padding-bottom: 64.448%;">
                <video src="https://jina-ai-gmbh.ghost.io/content/media/2025/04/m0-demo-1.mp4" poster="https://img.spacergif.org/v1/1232x794/0a/spacer.png" width="1232" height="794" loop="" autoplay="" muted="" playsinline="" preload="metadata" style="background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/04/m0-demo-1_thumb.jpg') 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay kg-video-hide-animated">
                    <button class="kg-video-large-play-icon kg-video-hide-animated" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container kg-video-hide">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:22</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1×</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"></path>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">The demo is available at: </span><a href="https://jina.ai/api-dashboard/m0-image-rerank"><span style="white-space: pre-wrap;">https://jina.ai/api-dashboard/m0-image-rerank</span></a><span style="white-space: pre-wrap;"> Please note that using this demo will consume your primary API key's tokens. Also the demo might seem a bit slow since it needs to download all images on the server from those URLs, and no cache is implemented for images.</span></p></figcaption>
        </figure><h3 id="via-api" style="position: relative;"><a href="#via-api" title="Via API" id="anchor-via-api"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Via API</h3><p>Le code ci-dessous montre comment utiliser <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a>. Vous pouvez transmettre une chaîne de texte, une image codée en base64 ou une URL d'image. Les nouveaux utilisateurs peuvent obtenir une clé API Jina avec 10 millions de 词元 (Tokens) gratuits.</p><pre class="hljs-copy-wrapper"><code class="language-bash hljs">curl https://api.jina.ai/v1/embeddings \
  -H <span class="hljs-string">"Content-Type: application/json"</span> \
  -H <span class="hljs-string">"Authorization: Bearer JINA_API_KEY"</span> \
  -d @- &lt;&lt;<span class="hljs-string">EOFEOF
  {
    "model": "jina-embeddings-v4",
    "task": "text-matching",
    "input": [
        {
            "text": "A beautiful sunset over the beach"
        },
        {
            "text": "Un beau coucher de soleil sur la plage"
        },
        {
            "text": "海滩上美丽的日落"
        },
        {
            "text": "浜辺に沈む美しい夕日"
        },
        {
            "image": "https://i.ibb.co/nQNGqL0/beach1.jpg"
        },
        {
            "image": "https://i.ibb.co/r5w8hG8/beach2.jpg"
        },
        {
            "image": "iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAIAAABhUg/jAAAAMklEQVR4nO3MQREAMAgAoLkoFreTiSzhy4MARGe9bX99lEqlUqlUKpVKpVKpVCqVHksHaBwCA2cPf0cAAAAASUVORK5CYII="
        }
    ]
  }
EOFEOF</span>
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copier</button></div></pre><p>En raison de ressources GPU limitées, notre API d'向量模型 (Embeddings) prend actuellement en charge les documents d'une longueur maximale de 8&nbsp;000&nbsp;词元 (Tokens), bien que <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> puisse nativement traiter jusqu'à 32&nbsp;000&nbsp;词元 (Tokens). Pour les applications nécessitant des contextes plus longs que 8&nbsp;000&nbsp;词元 (Tokens) (telles que le <a href="https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii">Late Chunking</a>), nous vous recommandons de déployer nos modèles via des CSP ou d'auto-héberger le modèle.</p><h3 id="via-csp-marketplaces" style="position: relative;"><a href="#via-csp-marketplaces" title="Via les places de marché CSP" id="anchor-via-csp-marketplaces"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Via les places de marché CSP</h3><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> sera bientôt disponible directement sur AWS, Azure et GCP aux prix qui y sont indiqués.</p><h3 id="via-huggingface" style="position: relative;"><a href="#via-huggingface" title="Via HuggingFace" id="anchor-via-huggingface"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Via HuggingFace</h3><p>À des fins de recherche et d'expérimentation, vous pouvez utiliser le modèle localement à partir de notre page Hugging Face. Nous avons préparé un bloc-notes Google Colab qui montre comment cela fonctionne.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://colab.research.google.com/drive/1fb8jGCDPf-MXUnyXt-DNoe8_hmBDpDrl#scrollTo=M54aS0TvApyi"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Google Colab</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-38.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-9.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusion" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusion</h2><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> représente notre avancée la plus significative à ce jour&nbsp;: un modèle d'向量模型 (Embedding) universel de 3,8&nbsp;milliards de paramètres qui traite le texte et les images via un chemin unifié, prenant en charge la récupération dense et à interaction tardive tout en surpassant les modèles propriétaires de Google, OpenAI et Voyage&nbsp;AI, en particulier pour la récupération de documents riches en visuels. Mais cette capacité n'est pas apparue isolément&nbsp;; elle est l'aboutissement de quatre générations de résolution des limitations fondamentales.</p><p>Lorsque nous avons commencé avec <code>jina-embeddings-v1</code> au début de&nbsp;2022, tout le monde supposait que davantage de données signifiait de meilleures performances. Nous avons prouvé le contraire&nbsp;: le filtrage de 1,5&nbsp;milliard de paires à 385&nbsp;millions d'exemples de haute qualité a surpassé des ensembles de données beaucoup plus volumineux. La leçon&nbsp;: la conservation bat la collecte.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2307.11224"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models</div><div class="kg-bookmark-description">Jina Embeddings constitue un ensemble de modèles d'向量模型 (Embedding) de phrases à hautes performances, capables de traduire des entrées textuelles en représentations numériques, en capturant la sémantique du texte. Ces modèles excellent dans des applications telles que la récupération dense et la similarité textuelle sémantique. Cet article détaille le développement de Jina Embeddings, en commençant par la création d'ensembles de données par paires et par triplets de haute qualité. Il souligne le rôle crucial du nettoyage des données dans la préparation de l'ensemble de données, offre des informations approfondies sur le processus d'apprentissage du modèle et se termine par une évaluation complète des performances à l'aide du Massive Text Embedding Benchmark (MTEB). De plus, pour accroître la sensibilisation du modèle à la négation grammaticale, nous construisons un nouvel ensemble de données d'apprentissage et d'évaluation d'énoncés niés et non niés, que nous mettons à la disposition de la communauté.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-35.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-31.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Mais les utilisateurs continuaient de se heurter au mur des 512&nbsp;词元 (Tokens) de BERT. L'apprentissage sur des séquences plus longues semblait coûteux, jusqu'à ce que <code>jina-embeddings-v2</code> révèle une solution élégante&nbsp;: apprendre court, déployer long. Les biais d'attention linéaire d'ALiBi permettent aux modèles appris sur 512&nbsp;词元 (Tokens) de gérer de manière transparente 8&nbsp;192&nbsp;词元 (Tokens) lors de l'inférence. Nous avons obtenu plus de capacités pour moins de calcul.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2310.19923"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents</div><div class="kg-bookmark-description">Les modèles d'向量模型 (Embedding) de texte sont devenus des outils puissants pour transformer des phrases en vecteurs de caractéristiques de taille fixe qui encapsulent des informations sémantiques. Bien que ces modèles soient essentiels pour des tâches telles que la recherche d'informations, le regroupement sémantique et le 重排器 (Reranker) de texte, la plupart des modèles open source existants, en particulier ceux construits sur des architectures telles que BERT, ont du mal à représenter les longs documents et recourent souvent à la troncature. Une approche courante pour atténuer ce défi consiste à diviser les documents en paragraphes plus petits pour l'向量模型 (Embedding). Cependant, cette stratégie se traduit par un ensemble de vecteurs beaucoup plus important, ce qui entraîne une consommation de mémoire accrue et des recherches de vecteurs nécessitant beaucoup de calculs avec une latence élevée. Pour relever ces défis, nous présentons Jina Embeddings&nbsp;2, un modèle d'向量模型 (Embedding) de texte open source capable de prendre en charge jusqu'à 8&nbsp;192&nbsp;词元 (Tokens). Ce modèle est conçu pour transcender la limite conventionnelle de 512&nbsp;词元 (Tokens) et traiter avec compétence les longs documents. Jina Embeddings&nbsp;2 atteint non seulement des performances de pointe sur une gamme de tâches liées à l'向量模型 (Embedding) dans le benchmark MTEB, mais correspond également aux performances du modèle ada-002 propriétaire d'OpenAI. De plus, nos expériences indiquent qu'un contexte étendu peut améliorer les performances dans des tâches telles que NarrativeQA.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-36.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-32.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Le succès de <code>jina-embeddings-v2</code> a mis en évidence une autre contrainte&nbsp;: différentes tâches nécessitaient différentes optimisations. Plutôt que de construire des modèles distincts, <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> a utilisé de minuscules adaptateurs LoRA de 60M pour personnaliser un modèle de base de 570M pour n'importe quelle tâche. Un modèle est devenu cinq modèles spécialisés.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2409.10173"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v3: Multilingual Embeddings With Task LoRA</div><div class="kg-bookmark-description">Nous présentons jina-embeddings-v3, un nouveau modèle d'向量模型 (Embedding) de texte avec 570&nbsp;millions de paramètres, qui atteint des performances de pointe sur les données multilingues et les tâches de récupération de contexte long, prenant en charge des longueurs de contexte allant jusqu'à 8&nbsp;192&nbsp;词元 (Tokens). Le modèle comprend un ensemble d'adaptateurs Low-Rank Adaptation (LoRA) spécifiques à la tâche pour générer des 向量模型 (Embeddings) de haute qualité pour la récupération de documents de requête, le regroupement, la classification et la correspondance de texte. L'évaluation sur le benchmark MTEB montre que jina-embeddings-v3 surpasse les derniers 向量模型 (Embeddings) propriétaires d'OpenAI et de Cohere sur les tâches en anglais, tout en obtenant des performances supérieures à multilingual-e5-large-instruct sur toutes les tâches multilingues. Avec une dimension de sortie par défaut de 1024, les utilisateurs peuvent réduire de manière flexible les dimensions de l'向量模型 (Embedding) jusqu'à 32 sans compromettre les performances, grâce à Matryoshka Representation Learning.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-37.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Saba Sturua</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-33.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Même avec la spécialisation des tâches, nous sommes restés axés sur le texte, tandis que les utilisateurs avaient besoin d'une compréhension visuelle. Les modèles standard basés sur CLIP comme <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> et <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v2" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v2</span></a> utilisent des encodeurs distincts, créant un «&nbsp;écart de modalité&nbsp;» où un contenu similaire dans différents formats finit par être éloigné. Comme notre <a class="dynamic-model-name" href="/?sui&amp;model=jina-reranker-m0" target="_blank"><span class="dynamic-model-name-inner">jina-reranker-m0</span></a> récemment publié, <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> a complètement éliminé cet écart&nbsp;: un seul chemin unifié traite tout, supprimant l'écart plutôt que de le combler.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2506.18902"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval</div><div class="kg-bookmark-description">Nous présentons jina-embeddings-v4, un modèle d'向量模型 (Embedding) multimodal de 3,8&nbsp;milliards de paramètres qui unifie les représentations de texte et d'image grâce à une nouvelle architecture prenant en charge les 向量模型 (Embeddings) à vecteur unique et à vecteurs multiples dans le style d'interaction tardive. Le modèle intègre des adaptateurs Low-Rank Adaptation (LoRA) spécifiques à la tâche pour optimiser les performances dans divers scénarios de récupération, notamment la recherche d'informations basée sur des requêtes, la similarité sémantique intermodale et la recherche de code de programmation. Des évaluations complètes démontrent que jina-embeddings-v4 atteint des performances de pointe sur les tâches de récupération unimodales et intermodales, avec une force particulière dans le traitement du contenu riche en visuels tels que les tableaux, les graphiques, les diagrammes et les formats multimédias mixtes. Pour faciliter l'évaluation de cette capacité, nous présentons également Jina-VDR, un nouveau benchmark spécialement conçu pour la récupération d'images riches en visuels.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-39.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-35.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> et <a class="dynamic-model-name" href="/?sui&amp;model=jina-reranker-m0" target="_blank"><span class="dynamic-model-name-inner">jina-reranker-m0</span></a> partagent un changement fondamental&nbsp;: l'utilisation de 大模型 (LLM) comme backbones au lieu de modèles à encodeur uniquement. Ce n'est pas une coïncidence&nbsp;: cela reflète un avantage profond que la plupart manquent&nbsp;: les modèles à encodeur uniquement créent des «&nbsp;écarts de modalité&nbsp;» où les images se regroupent séparément du texte. Les modèles à décodeur uniquement ouvrent des possibilités qui n'étaient pas réalisables avec les architectures à encodeur uniquement, y compris la véritable représentation mixte de la modalité et l'explicabilité.</p><p>Notre principale idée : les vecteurs modèles (Embeddings) et la génération concernent tous deux la compréhension de la sémantique. Les grands modèles de langage (LLM) qui excellent dans la génération excellent naturellement dans la représentation. Nous pensons que l'avenir réside dans des architectures unifiées où les vecteurs modèles (embedding) et le réordonnancement (reranking) émergent du <strong>même modèle de base de recherche</strong>, et c'est exactement ce vers quoi Jina AI s'oriente.</p>
{{{output start}}}</section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Catégories:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Mis en exergue</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">communiqué de presse</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-ce90450d="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-ce90450d="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-ce90450d="" class="col-sm-12 col-md"><div data-v-ce90450d="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Des bureaux</div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Sunnyvale, Californie</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, États-Unis</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Berlin, Allemagne (siège social)</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Allemagne</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Pékin, Chine</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Niveau 5, bâtiment 6, n° 48, rue Haidian Ouest, Pékin, Chine</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Shenzhen, en Chine</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">402 étage 4, bâtiment technologique Fu'an, Shenzhen, Chine</div></div></div></div></div><div data-v-ce90450d="" class="col-sm-12 col-md row"><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fondation Recherche</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Lecteur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Intégrations</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Reclasseur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Recherche profonde</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Classificateur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Segmenteur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Documentation de l'API</div></a><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Obtenir la clé API Jina</div></div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Limite de taux</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-ce90450d="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Statut de l'API</div></a></div><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Entreprise</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">À propos de nous</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Contacter le service commercial</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Rédaction</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Programme de stage</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Rejoignez-nous</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Télécharger le logo</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Termes</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Sécurité</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">termes et conditions</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Confidentialité</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Gérer les cookies</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-ce90450d="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-ce90450d="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-ce90450d="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-ce90450d="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>