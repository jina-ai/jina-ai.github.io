<!DOCTYPE html><html translate="no" dir="ltr" lang="fr"><head><title>Au-delà de CLIP : Comment Jina-CLIP fait progresser la recherche multimodale</title><meta charset="utf-8"><meta name="title" content="Au-delà de CLIP : Comment Jina-CLIP fait progresser la recherche multimodale"><meta name="description" content="Découvrez comment Jina-CLIP améliore le modèle CLIP d'OpenAI avec une meilleure précision de recherche et des résultats plus diversifiés grâce à des embeddings texte-image unifiés."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/beyond-clip-how-jina-clip-advances-multimodal-search"><meta property="og:title" content="Au-delà de CLIP : Comment Jina-CLIP fait progresser la recherche multimodale"><meta property="og:description" content="Découvrez comment Jina-CLIP améliore le modèle CLIP d'OpenAI avec une meilleure précision de recherche et des résultats plus diversifiés grâce à des embeddings texte-image unifiés."><meta property="og:image" content="https://jina.ai/blog-banner/beyond-clip-how-jina-clip-advances-multimodal-search.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/beyond-clip-how-jina-clip-advances-multimodal-search"><meta property="twitter:title" content="Au-delà de CLIP : Comment Jina-CLIP fait progresser la recherche multimodale"><meta property="twitter:description" content="Découvrez comment Jina-CLIP améliore le modèle CLIP d'OpenAI avec une meilleure précision de recherche et des résultats plus diversifiés grâce à des embeddings texte-image unifiés."><meta property="twitter:image" content="https://jina.ai/blog-banner/beyond-clip-how-jina-clip-advances-multimodal-search.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-CqSgmygw.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-rzO9Riiq.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-e7ex4EYO.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-D5BvDXgu.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-Cd39USyK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-Ctnd3ip6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-DheNTbJQ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-X2S6Rmr8.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/fr-DiR1v30g.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-BVzHrk35.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-ChMOKHXj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-BjXk3WRm.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-BU9iIEJ-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/UserAvatarComponent-CXCDNeeB.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-Cc11z2P6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-wMBnTShO.js"><link rel="stylesheet" crossorigin="" href="/assets/UserAvatarComponent-HOhEbA2Z.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-CC-gf0BL.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-BGKkNyaf.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-wqkzToUm.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-DiIj5LlY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-AXDH3t-2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-jKzAnQoz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-Bgca4QVI.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-B36xfqcW.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-DcWwNoug.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-CCNgduYV.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-BlA6-VPN.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-Cna1ipbY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-BklFnD4b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-NG2JdsIP.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-CSXw3fVL.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-DO9vo9XY.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-BHzuOkdn.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-6FlFYF2Q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-C-YNYZbw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-DTm85u4a.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-CzIAG57h.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-C-bSVcPq.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-vSZoRHSY.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Bo Wang, Alex C-G"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Bo Wang, Alex C-G"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="11 mins read"><meta property="article:published_time" content="2024-10-29T11:51:40.000+01:00"><meta property="article:modified_time" content="2024-10-30T19:14:11.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Au-delà de CLIP : Comment Jina-CLIP fait progresser la recherche multimodale",
  "description": "Découvrez comment Jina-CLIP améliore le modèle CLIP d'OpenAI avec une meilleure précision de recherche et des résultats plus diversifiés grâce à des embeddings texte-image unifiés.",
  "image": [
    "https://jina.ai/blog-banner/beyond-clip-how-jina-clip-advances-multimodal-search.webp"
  ],
  "datePublished": "2024-10-29T11:51:40.000+01:00",
  "dateModified": "2024-10-30T19:14:11.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Bo Wang",
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-85e17eff="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-85e17eff="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-85e17eff="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-85e17eff="" class="q-space"></div><button data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-85e17eff="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-85e17eff="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-85e17eff="" class="q-list q-list--dark" role="list"><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Nouvelles</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Modèles</div></a><div data-v-85e17eff="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e8424c95-f1f7-4497-82ca-12560e2f1ac0" aria-label="Développer &quot;Des produits&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Des produits</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_e8424c95-f1f7-4497-82ca-12560e2f1ac0" style="display: none;"><div data-v-85e17eff="" class="q-list q-list--dark" role="list" label="Des produits"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Recherche profonde</div><div class="q-item__label q-item__label--caption text-caption">Recherchez, lisez et raisonnez jusqu'à trouver la meilleure réponse.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lecteur</div><div class="q-item__label q-item__label--caption text-caption">Lisez les URL et effectuez des recherches sur le Web pour de meilleurs LLM de base.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Intégrations</div><div class="q-item__label q-item__label--caption text-caption">Intégrations multimodales et multilingues de classe mondiale.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reclasseur</div><div class="q-item__label q-item__label--caption text-caption">Récupérateur neuronal de classe mondiale pour maximiser la pertinence de la recherche.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_b6f871dd-dbd9-4a00-b712-924bc94c2afc" aria-label="Développer &quot;Plus&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Plus</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_b6f871dd-dbd9-4a00-b712-924bc94c2afc" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Classificateur</div><div class="q-item__label q-item__label--caption text-caption">Classification à zéro plan et à quelques plans pour l'image et le texte.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmenteur</div><div class="q-item__label q-item__label--caption text-caption">Coupez un long texte en morceaux et effectuez la tokenisation.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Documentation de l'API</div><div class="q-item__label q-item__label--caption text-caption">Génération automatique de code pour votre IDE ou LLM copilote</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-85e17eff="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_7ed0685f-ca15-4ae3-a644-707f99ca8cf9" aria-label="Développer &quot;Entreprise&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Entreprise</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_7ed0685f-ca15-4ae3-a644-707f99ca8cf9" style="display: none;"><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">À propos de nous</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Contacter le service commercial</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Programme de stage</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Rejoignez-nous</div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Télécharger le logo</div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">termes et conditions</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Se connecter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Se connecter</div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-85e17eff="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_77383338-0d41-48eb-8fde-4c0c81b016c3"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_77383338-0d41-48eb-8fde-4c0c81b016c3" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_77383338-0d41-48eb-8fde-4c0c81b016c3_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-85e17eff="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Qu'est-ce que CLIP ?</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Comment jina-clip-v1 résout les limitations de CLIP</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Moyenner les embeddings de texte et d'image pour une performance supérieure à la moyenne</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Récupérer les résultats avec le texte ; les diversifier avec les images</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Conclusion</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog technique</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">octobre 29, 2024</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">Au-delà de CLIP : Comment Jina-CLIP fait progresser la recherche multimodale</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Découvrez comment Jina-CLIP améliore le modèle CLIP d'OpenAI avec une meilleure précision de recherche et des résultats plus diversifiés grâce à des embeddings texte-image unifiés.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img" aria-label="Abstract digital landscape with wave-like green and pink dunes against a dark background, conveying a tranquil atmosphere."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract digital landscape with wave-like green and pink dunes against a dark background, conveying a tranquil atmosphere." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/clip.jpg" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Bo Wang"><div style="padding-bottom: 93.2813%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Bo Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Bo Wang, Alex C-G • 11 minutes lues</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><p>La recherche multimodale, qui combine texte et images dans une expérience de recherche transparente, a gagné en popularité grâce à des modèles comme <a href="https://openai.com/index/clip/">CLIP d'OpenAI</a>. Ces modèles comblent efficacement le fossé entre les données visuelles et textuelles, permettant de relier les images aux textes pertinents et vice versa.</p><p>Bien que CLIP et les modèles similaires soient puissants, ils présentent des limitations notables, particulièrement lors du traitement de textes plus longs ou de relations textuelles complexes. C'est là qu'intervient <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image</div><div class="kg-bookmark-description">Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/--.jpg" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Conçu pour répondre à ces défis, <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> offre une meilleure compréhension du texte tout en maintenant de solides capacités d'association texte-image. Il fournit une solution plus rationalisée pour les applications utilisant les deux modalités, simplifiant le processus de recherche et éliminant la nécessité de jongler avec des modèles séparés pour le texte et les images.</p><p>Dans cet article, nous explorerons ce que <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> apporte aux applications de recherche multimodale, en présentant des expériences qui démontrent comment il améliore à la fois la précision et la variété des résultats grâce aux embeddings intégrés de texte et d'image.</p><h2 id="what-is-clip" style="position: relative;"><a href="#what-is-clip" title="Qu'est-ce que CLIP ?" id="anchor-what-is-clip"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Qu'est-ce que CLIP ?</h2><p>CLIP (Contrastive Language–Image Pretraining) est une architecture de modèle d'IA développée par OpenAI qui relie texte et images en apprenant des représentations conjointes. CLIP est essentiellement un modèle de texte et un modèle d'image soudés ensemble — il transforme les deux types d'entrées en un espace d'embedding partagé, où les textes et images similaires sont positionnés à proximité. CLIP a été entraîné sur un vaste ensemble de données de paires texte-image, lui permettant de comprendre la relation entre le contenu visuel et textuel. Cela lui permet de bien généraliser à travers différents domaines, le rendant très efficace dans les scénarios d'apprentissage zero-shot, comme la génération de légendes ou la recherche d'images.</p><p>Depuis la sortie de CLIP, d'autres modèles comme <a href="https://arxiv.org/abs/2303.15343">SigLiP</a>, <a href="https://arxiv.org/abs/2111.07991">LiT</a>, et <a href="https://arxiv.org/abs/2303.15389">EvaCLIP</a> ont développé ses fondations, améliorant des aspects tels que l'efficacité de l'entraînement, le passage à l'échelle et la compréhension multimodale. Ces modèles utilisent souvent des ensembles de données plus volumineux, des architectures améliorées et des techniques d'entraînement plus sophistiquées pour repousser les limites de l'alignement texte-image, faisant progresser davantage le domaine des modèles image-langage.</p><p>Bien que CLIP <em>puisse</em> fonctionner avec du texte seul, il présente des limitations importantes. Premièrement, il a été entraîné uniquement sur de courtes légendes, pas sur des textes longs, ne gérant qu'un maximum d'environ 77 mots. Deuxièmement, CLIP excelle dans la connexion du texte aux images mais peine à comparer du texte avec d'autre texte, comme reconnaître que les chaînes <code>a crimson fruit</code> et <code>a red apple</code> peuvent faire référence à la même chose. C'est là que les modèles de texte spécialisés, comme <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>, brillent.</p><p>Ces limitations compliquent les tâches de recherche impliquant à la fois du texte et des images, par exemple, une boutique en ligne "shop the look" où un utilisateur peut rechercher des produits de mode en utilisant soit une chaîne de texte, soit une image. Lors de l'indexation de vos produits, vous devez traiter chacun plusieurs fois - une fois pour l'image, une fois pour le texte, et une fois de plus avec un modèle spécifique au texte. De même, lorsqu'un utilisateur recherche un produit, votre système doit effectuer au moins deux recherches pour trouver à la fois les cibles textuelles et visuelles :</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-27.png" class="kg-image" alt="Flowchart outlining &quot;Offline Indexing&quot; and &quot;Online Querying&quot; processes with labeled blocks and arrows for XML data interactio" width="970" height="1255" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-27.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-27.png 970w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><h2 id="how-jina-clip-v1-solves-clip%E2%80%99s-shortcomings" style="position: relative;"><a href="#how-jina-clip-v1-solves-clip%E2%80%99s-shortcomings" title="Comment jina-clip-v1 résout les limitations de CLIP" id="anchor-how-jina-clip-v1-solves-clip-s-shortcomings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><strong>Comment </strong><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a><strong> résout les limitations de CLIP</strong></h2><p>Pour surmonter les limitations de CLIP, nous avons créé <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> pour comprendre des textes plus longs et faire correspondre plus efficacement les requêtes textuelles aux textes et aux images. Qu'est-ce qui rend <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> si spécial ? Tout d'abord, il utilise un modèle de compréhension du texte plus intelligent (JinaBERT), l'aidant à comprendre des textes plus longs et plus complexes (comme des descriptions de produits), pas seulement de courtes légendes (comme des noms de produits). Deuxièmement, nous avons entraîné <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> pour être performant sur deux aspects simultanément : faire correspondre le texte aux images et le texte à d'autres textes.</p><p>Avec OpenAI CLIP, ce n'est pas le cas : pour l'indexation et la recherche, vous devez invoquer deux modèles (CLIP pour les images et les textes courts comme les légendes, un autre embedding de texte pour les textes plus longs comme les descriptions). Non seulement cela ajoute une surcharge, mais cela ralentit la recherche, une opération qui <em>devrait</em> être très rapide. <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> fait tout cela dans un seul modèle, sans sacrifier la vitesse :</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-22.png" class="kg-image" alt="Flowchart of JaclinQ's offline indexing and online querying processes, involving imagery and text analysis." width="2000" height="2785" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-22.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-22.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-22.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/10/image-22.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Cette approche unifiée ouvre de nouvelles possibilités qui étaient difficiles avec les modèles précédents, remodelant potentiellement notre approche de la recherche. Dans cet article, nous avons mené deux expériences :</p><ul><li><strong>Améliorer les résultats de recherche en combinant la recherche de texte et d'images</strong> : Pouvons-nous combiner ce que <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> comprend du texte avec ce qu'il comprend des images ? Que se passe-t-il lorsque nous mélangeons ces deux types de compréhension ? L'ajout d'informations visuelles modifie-t-il nos résultats de recherche ? En bref, pouvons-nous obtenir de meilleurs résultats si nous recherchons avec du texte et des images simultanément ?</li><li><strong>Utiliser les images pour diversifier les résultats de recherche</strong> : La plupart des moteurs de recherche maximisent les correspondances textuelles. Mais pouvons-nous utiliser la compréhension des images de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> comme un "mélange visuel" ? Au lieu de montrer uniquement les résultats les plus pertinents, nous pourrions inclure des résultats visuellement diversifiés. Il ne s'agit pas de trouver plus de résultats liés, mais de montrer une plus grande variété de perspectives, même si elles sont moins étroitement liées. Ce faisant, nous pourrions découvrir des aspects d'un sujet auxquels nous n'avions pas pensé auparavant. Par exemple, dans le contexte de la recherche de mode, si un utilisateur recherche "robe de cocktail multicolore", veut-il que les premiers résultats se ressemblent tous (c'est-à-dire des correspondances <em>très</em> proches), ou une plus grande variété parmi laquelle choisir (via le mélange visuel) ?</li></ul><p>Ces deux approches sont précieuses dans une variété de cas d'utilisation où les utilisateurs peuvent rechercher avec du texte ou des images, comme dans le e-commerce, les médias, l'art et le design, l'imagerie médicale, et au-delà.</p><h2 id="averaging-text-and-image-embeddings-for-above-average-performance" style="position: relative;"><a href="#averaging-text-and-image-embeddings-for-above-average-performance" title="Moyenner les embeddings de texte et d'image pour une performance supérieure à la moyenne" id="anchor-averaging-text-and-image-embeddings-for-above-average-performance"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Moyenner les embeddings de texte et d'image pour une performance supérieure à la moyenne</h2><p>Lorsqu'un utilisateur soumet une requête (généralement sous forme de chaîne de texte), nous pouvons utiliser la tour de texte de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> pour encoder la requête en un embedding de texte. La force de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> réside dans sa capacité à comprendre à la fois le texte et les images en alignant les signaux texte-à-texte et texte-à-image dans le même espace sémantique.</p><p>Pouvons-nous améliorer les résultats de la recherche si nous combinons les embeddings pré-indexés de texte et d'image de chaque produit en les moyennant ?</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-28.png" class="kg-image" alt="Flowchart on a black background detailing text and image embedding processes with a black knit midi dress photo example." width="995" height="359" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-28.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-28.png 995w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Cela crée une représentation unique qui inclut à la fois les informations textuelles (par exemple, la description du produit) et visuelles (par exemple, l'image du produit). Nous pouvons ensuite utiliser l'embedding de la requête textuelle pour rechercher dans ces représentations mélangées. Comment cela affecte-t-il nos résultats de recherche ?</p><p>Pour le découvrir, nous avons utilisé le jeu de données <a href="https://github.com/xthan/fashion-200k">Fashion200k</a>, un ensemble de données à grande échelle spécifiquement créé pour les tâches liées à la recherche d'images de mode et à la compréhension cross-modale. Il se compose de plus de 200 000 images d'articles de mode, tels que des vêtements, des chaussures et des accessoires, accompagnées des descriptions de produits et métadonnées correspondantes.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/xthan/fashion-200k"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - xthan/fashion-200k: Fashion 200K dataset used in paper "Automatic Spatially-aware Fashion Concept Discovery."</div><div class="kg-bookmark-description">Fashion 200K dataset used in paper "Automatic Spatially-aware Fashion Concept Discovery." - xthan/fashion-200k</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="" style="cursor: help;"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">xthan</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://opengraph.githubassets.com/2116651d448aec6ea0508f5fdb123e6292fa00bfb1cf8fb6f3468cbe761da769/xthan/fashion-200k" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Nous avons ensuite catégorisé chaque article dans une catégorie générale (par exemple, <code>dress</code>) et une catégorie plus précise (comme <code>knit midi dress</code>).</p><h3 id="analyzing-three-retrieval-methods" style="position: relative;"><a href="#analyzing-three-retrieval-methods" title="Analyse de trois méthodes de recherche" id="anchor-analyzing-three-retrieval-methods"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><strong>Analyse de trois méthodes de recherche</strong></h3><p>Pour voir si la moyenne des embeddings de texte et d'image donnait de meilleurs résultats de recherche, nous avons expérimenté trois types de recherche, chacune utilisant une chaîne de texte (par exemple <code>red dress</code>) comme requête :</p><ul><li><strong>Requête vers Description utilisant les embeddings de texte :</strong> Recherche dans les descriptions de produits basée sur les embeddings de texte.</li><li><strong>Requête vers Image utilisant la recherche cross-modal :</strong> Recherche dans les images de produits basée sur les embeddings d'images.</li><li><strong>Requête vers Embedding Moyen :</strong> Recherche dans les embeddings moyens des descriptions et des images de produits.</li></ul><p>Nous avons d'abord indexé l'ensemble du jeu de données, puis généré aléatoirement 1 000 requêtes pour évaluer les performances. Nous avons encodé chaque requête en un embedding de texte et effectué la correspondance séparément, selon les méthodes décrites ci-dessus. Nous avons mesuré la précision en fonction de la correspondance entre les catégories des produits retournés et la requête d'entrée.</p><p>Lorsque nous avons utilisé la requête <code>multicolor henley t-shirt dress</code>, la recherche <strong>Requête vers Description</strong> a obtenu la meilleure précision top-5, mais les trois dernières robes classées étaient visuellement identiques. C'est moins qu'idéal, car une recherche efficace devrait équilibrer pertinence et diversité pour mieux capter l'attention de l'utilisateur.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-13.png" class="kg-image" alt="Array of five unique dresses, categorized as casual and day, arranged in a row on a white background with named tags for easy" width="2000" height="480" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-13.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-13.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-13.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-13.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>La recherche cross-modal <strong>Requête vers Image</strong> a utilisé la même requête et a adopté l'approche opposée, présentant une collection très diverse de robes. Bien qu'elle ait correspondu à deux résultats sur cinq avec la bonne catégorie générale, aucun ne correspondait à la catégorie précise.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-14.png" class="kg-image" alt="Variety of women's clothing items including short and long-sleeved tops and casual to maxi dresses with color swatches." width="2000" height="496" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-14.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-14.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-14.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-14.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>La <strong>recherche avec les embeddings moyens de texte et d'image</strong> a donné le meilleur résultat : les cinq résultats correspondaient à la catégorie générale, et deux sur cinq correspondaient à la catégorie précise. De plus, les articles visuellement dupliqués ont été éliminés, offrant une sélection plus variée. L'utilisation des embeddings de texte pour rechercher dans les embeddings moyens de texte et d'image semble maintenir la qualité de la recherche tout en incorporant des indices visuels, conduisant à des résultats plus diversifiés et équilibrés.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-15.png" class="kg-image" alt="Showcase of various women's dresses, including a multicolor henley t-shirt dress and a pink Missoni dress, labeled with categ" width="2000" height="513" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-15.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-15.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-15.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-15.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><h3 id="scaling-up-evaluating-with-more-queries" style="position: relative;"><a href="#scaling-up-evaluating-with-more-queries" title="Monter en échelle : Évaluation avec plus de requêtes" id="anchor-scaling-up-evaluating-with-more-queries"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><strong>Monter en échelle : Évaluation avec plus de requêtes</strong></h3><p>Pour voir si cela fonctionnerait à plus grande échelle, nous avons poursuivi l'expérience sur d'autres catégories générales et précises. Nous avons effectué plusieurs itérations, récupérant un nombre différent de résultats (« valeurs k ») à chaque fois.</p><p>Pour les catégories générales comme précises, la <strong>Requête vers Embedding Moyen</strong> a constamment obtenu la plus haute précision pour toutes les valeurs k (10, 20, 50, 100). Cela montre que la combinaison des embeddings de texte et d'image fournit les résultats les plus précis pour retrouver les articles pertinents, que la catégorie soit générale ou spécifique :</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-16.png" class="kg-image" alt="Comparative chart of 'Broad Precision@K' and 'Fine-grained Precision@K' showing different precision values for query-related " width="2000" height="836" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-16.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-16.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-16.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-16.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure>

<table>
<thead>
<tr>
<th><strong>k</strong></th>
<th><strong>Type de recherche</strong></th>
<th><strong>Précision catégorie générale (similarité cosinus)</strong></th>
<th><strong>Précision catégorie fine (similarité cosinus)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>Requête vers Description</td>
<td>0.9026</td>
<td>0.2314</td>
</tr>
<tr>
<td>10</td>
<td>Requête vers Image</td>
<td>0.7614</td>
<td>0.2037</td>
</tr>
<tr>
<td>10</td>
<td>Requête vers Embedding Moyen</td>
<td><strong>0.9230</strong></td>
<td><strong>0.2711</strong></td>
</tr>
<tr>
<td>20</td>
<td>Requête vers Description</td>
<td>0.9150</td>
<td>0.2316</td>
</tr>
<tr>
<td>20</td>
<td>Requête vers Image</td>
<td>0.7523</td>
<td>0.1964</td>
</tr>
<tr>
<td>20</td>
<td>Requête vers Embedding Moyen</td>
<td><strong>0.9229</strong></td>
<td><strong>0.2631</strong></td>
</tr>
<tr>
<td>50</td>
<td>Requête vers Description</td>
<td>0.9134</td>
<td>0.2254</td>
</tr>
<tr>
<td>50</td>
<td>Requête vers Image</td>
<td>0.7418</td>
<td>0.1750</td>
</tr>
<tr>
<td>50</td>
<td>Requête vers Embedding Moyen</td>
<td><strong>0.9226</strong></td>
<td><strong>0.2390</strong></td>
</tr>
<tr>
<td>100</td>
<td>Requête vers Description</td>
<td>0.9092</td>
<td>0.2139</td>
</tr>
<tr>
<td>100</td>
<td>Requête vers Image</td>
<td>0.7258</td>
<td>0.1675</td>
</tr>
<tr>
<td>100</td>
<td>Requête vers Embedding Moyen</td>
<td><strong>0.9150</strong></td>
<td><strong>0.2286</strong></td>
</tr>
</tbody>
</table>

<ul><li>La <strong>Requête vers Description utilisant les embeddings de texte</strong> a bien performé dans les deux catégories mais était légèrement en retrait par rapport à l'approche des embeddings moyens. Cela suggère que les descriptions textuelles seules fournissent des informations précieuses, particulièrement pour les catégories plus larges comme "robe", mais peuvent manquer de subtilité pour la classification précise (par exemple pour distinguer différents types de robes).</li><li>La <strong>Requête vers Image utilisant la recherche cross-modal</strong> a constamment eu la plus faible précision dans les deux catégories. Cela suggère que si les caractéristiques visuelles peuvent aider à identifier les catégories générales, elles sont moins efficaces pour capturer les distinctions précises des articles de mode. La difficulté de distinguer les catégories précises uniquement à partir des caractéristiques visuelles est particulièrement évidente, où les différences visuelles peuvent être subtiles et nécessiter un contexte supplémentaire fourni par le texte.</li><li>Globalement, la combinaison d'informations textuelles et visuelles (via les <strong>embeddings moyens</strong>) a atteint une haute précision dans les tâches de recherche de mode tant générales que précises. Les descriptions textuelles jouent un rôle important, particulièrement dans l'identification des catégories générales, tandis que les images seules sont moins efficaces dans les deux cas.</li></ul><p>Dans l'ensemble, la précision était beaucoup plus élevée pour les catégories générales par rapport aux catégories précises, principalement parce que les articles des catégories générales (par exemple <code>dress</code>) sont plus représentés dans le jeu de données que les catégories précises (par exemple <code>henley dress</code>), simplement parce que ces dernières sont des sous-ensembles des premières. Par nature, une catégorie générale est plus facile à généraliser qu'une catégorie précise. En dehors de l'exemple de la mode, il est simple d'identifier qu'un objet est, en général, un oiseau. C'est beaucoup plus difficile de l'identifier comme un <a href="https://www.youtube.com/watch?v=nPhVOZiPokA">Paradisier superbe de Vogelkop</a>.</p><p>Il est également à noter que l'information dans une requête textuelle correspond plus facilement à d'autres textes (comme les noms ou descriptions de produits) qu'aux caractéristiques visuelles. Par conséquent, si un texte est utilisé comme entrée, les textes sont une sortie plus probable que les images. Nous obtenons les meilleurs résultats en combinant à la fois les images et le texte (via la moyenne des embeddings) dans notre index.</p><h2 id="retrieve-results-with-text-diversify-them-with-images" style="position: relative;"><a href="#retrieve-results-with-text-diversify-them-with-images" title="Récupérer les résultats avec le texte ; les diversifier avec les images" id="anchor-retrieve-results-with-text-diversify-them-with-images"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Récupérer les résultats avec le texte ; les diversifier avec les images</h2><p>Dans la section précédente, nous avons abordé le problème des résultats de recherche visuellement dupliqués. Dans la recherche, <em>la précision seule n'est pas toujours suffisante</em>. Dans de nombreux cas, maintenir une liste classée concise mais hautement pertinente et diverse est plus efficace, particulièrement lorsque la requête de l'utilisateur est ambiguë (par exemple, si un utilisateur recherche<code>black jacket</code> — s'agit-il d'une veste de motard noire, d'un blouson aviateur, d'un blazer ou d'un autre type ?). </p><p>Maintenant, au lieu d'utiliser la capacité multimodale de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>, utilisons les embeddings textuels de sa tour de texte pour la recherche textuelle initiale, puis appliquons les embeddings d'images de la tour d'images comme "reclasseur visuel" pour diversifier les résultats de recherche. Ceci est illustré dans le diagramme ci-dessous :</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-29.png" class="kg-image" alt="Flowchart detailing multimodal document text processing, with branches for text and image embedding and various processing pa" width="975" height="476" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-29.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-29.png 975w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p></p><ol><li>D'abord, récupérer les k meilleurs résultats de recherche basés sur les embeddings textuels.</li><li>Pour chaque meilleur résultat de recherche, extraire les caractéristiques visuelles et les regrouper en utilisant les embeddings d'images.</li><li>Réorganiser les résultats de recherche en sélectionnant un élément de chaque cluster et présenter une liste diversifiée à l'utilisateur.</li></ol><p>Après avoir récupéré les cinquante meilleurs résultats, nous avons appliqué un clustering k-means léger (k=5) aux embeddings d'images, puis sélectionné des éléments de chaque cluster. La précision des catégories est restée cohérente avec la performance Query-to-Description, car nous avons utilisé la requête vers la catégorie de produit comme métrique de mesure. Cependant, les résultats classés ont commencé à couvrir plus d'aspects différents (comme le tissu, la coupe et le motif) avec la diversification basée sur l'image. Pour référence, voici l'exemple de la robe t-shirt henley multicolore mentionné précédemment :</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-18.png" class="kg-image" alt="Collection of t-shirt dresses categorized into casual and day, short and long sleeves, displayed in two rows." width="2000" height="1484" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-18.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-18.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-18.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-18.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Voyons maintenant comment la diversification affecte les résultats de recherche en utilisant la recherche par embedding textuel combinée avec l'embedding d'image comme reclasseur de diversification :</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-19.png" class="kg-image" alt="Five diverse dresses arranged in a row, categorized as various types including casual and day dresses, mini and short, and ma" width="2000" height="465" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-19.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-19.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-19.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-19.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Les résultats classés proviennent de la recherche textuelle mais commencent à couvrir des "aspects" plus diversifiés dans les cinq premiers exemples. Cela produit un effet similaire à la moyenne des embeddings sans réellement les moyenner.</p><p>Cependant, cela a un coût : nous devons appliquer une étape de clustering supplémentaire après avoir récupéré les k meilleurs résultats, ce qui ajoute quelques millisecondes supplémentaires, selon la taille du classement initial. De plus, la détermination de la valeur de k pour le clustering k-means implique une part de devinettes heuristiques. C'est le prix à payer pour une meilleure diversification des résultats !</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusion" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusion</h2><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> comble efficacement l'écart entre la recherche textuelle et la recherche d'images en unifiant les deux modalités dans un modèle unique et efficace. Nos expériences ont montré que sa capacité à traiter des textes plus longs et plus complexes aux côtés des images offre des performances de recherche supérieures par rapport aux modèles traditionnels comme CLIP.</p><p>Nos tests ont couvert diverses méthodes, notamment la correspondance du texte avec les descriptions, les images et les embeddings moyennés. Les résultats ont systématiquement montré que la combinaison des embeddings textuels et d'images produisait les meilleurs résultats, améliorant à la fois la précision et la diversité des résultats de recherche. Nous avons également découvert que l'utilisation des embeddings d'images comme "reclasseur visuel" améliorait la variété des résultats tout en maintenant la pertinence.</p><p>Ces avancées ont des implications significatives pour les applications du monde réel où les utilisateurs recherchent en utilisant à la fois des descriptions textuelles et des images. En comprenant simultanément les deux types de données, <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> rationalise le processus de recherche, fournissant des résultats plus pertinents et permettant des recommandations de produits plus diversifiées. Cette capacité de recherche unifiée s'étend au-delà du e-commerce pour bénéficier à la gestion des actifs médias, aux bibliothèques numériques et à la curation de contenu visuel, facilitant la découverte de contenu pertinent à travers différents formats.</p><p>Bien que <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> ne prenne actuellement en charge que l'anglais, nous travaillons actuellement sur <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v2" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v2</span></a>. Dans la lignée de <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> et <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v2" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v2</span></a>, cette nouvelle version sera un système de recherche multimodal multilingue à la pointe de la technologie prenant en charge 89 langues. Cette mise à niveau ouvrira de nouvelles possibilités pour les tâches de recherche et de récupération à travers différents marchés et industries, en faisant un modèle d'embedding plus puissant pour les applications mondiales dans le e-commerce, les médias et au-delà.</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Catégories:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog technique</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-85e17eff="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-85e17eff="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-85e17eff="" class="col-sm-12 col-md"><div data-v-85e17eff="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Des bureaux</div><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-85e17eff="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center"><div data-v-85e17eff="" class="q-item__label">Sunnyvale, Californie</div><div data-v-85e17eff="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, États-Unis</div></div></div><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-85e17eff="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center"><div data-v-85e17eff="" class="q-item__label">Berlin, Allemagne (siège social)</div><div data-v-85e17eff="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Allemagne</div></div></div><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-85e17eff="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center"><div data-v-85e17eff="" class="q-item__label">Pékin, Chine</div><div data-v-85e17eff="" class="q-item__label q-item__label--caption text-caption text-dim">Niveau 5, bâtiment 6, n° 48, rue Haidian Ouest, Pékin, Chine</div></div></div><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-85e17eff="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center"><div data-v-85e17eff="" class="q-item__label">Shenzhen, en Chine</div><div data-v-85e17eff="" class="q-item__label q-item__label--caption text-caption text-dim">402 étage 4, bâtiment technologique Fu'an, Shenzhen, Chine</div></div></div></div></div><div data-v-85e17eff="" class="col-sm-12 col-md row"><div data-v-85e17eff="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fondation Recherche</div><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Recherche profonde</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Lecteur</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Intégrations</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Reclasseur</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Classificateur</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Segmenteur</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Documentation de l'API</div></a><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Obtenir la clé API Jina</div></div><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Limite de taux</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-85e17eff="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Statut de l'API</div></a></div><div data-v-85e17eff="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Entreprise</div><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">À propos de nous</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Contacter le service commercial</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Rédaction</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Programme de stage</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Rejoignez-nous</div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Télécharger le logo</div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-85e17eff="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-85e17eff="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Termes</div><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Sécurité</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">termes et conditions</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Confidentialité</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--main justify-center">Gérer les cookies</div></a><a data-v-85e17eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-85e17eff="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-85e17eff="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-85e17eff="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-85e17eff="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-85e17eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-85e17eff="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>