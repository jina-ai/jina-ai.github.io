<!DOCTYPE html><html translate="no" dir="ltr" lang="fr"><head><title>A-t-on encore besoin du découpage avec les modèles qui gèrent les longs contextes ?</title><meta charset="utf-8"><meta name="title" content="A-t-on encore besoin du découpage avec les modèles qui gèrent les longs contextes ?"><meta name="description" content="Comparaison des performances des modèles d'embedding à contexte long selon différentes stratégies de découpage pour trouver l'approche optimale adaptée à vos besoins."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="og:title" content="A-t-on encore besoin du découpage avec les modèles qui gèrent les longs contextes ?"><meta property="og:description" content="Comparaison des performances des modèles d'embedding à contexte long selon différentes stratégies de découpage pour trouver l'approche optimale adaptée à vos besoins."><meta property="og:image" content="https://jina.ai/blog-banner/still-need-chunking-when-long-context-models-can-do-it-all.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="twitter:title" content="A-t-on encore besoin du découpage avec les modèles qui gèrent les longs contextes ?"><meta property="twitter:description" content="Comparaison des performances des modèles d'embedding à contexte long selon différentes stratégies de découpage pour trouver l'approche optimale adaptée à vos besoins."><meta property="twitter:image" content="https://jina.ai/blog-banner/still-need-chunking-when-long-context-models-can-do-it-all.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-0xuQLnK1.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-rzO9Riiq.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-C_sxytRJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-CAWQxWHK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-BSvEE8Cr.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-DgE64rzv.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-bZM3VFKp.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-DfQwAkEN.js"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/fr-DiR1v30g.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-Bni89cfF.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CKMR0WG9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-CR9NlEr5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-DeObFGfX.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/UserAvatarComponent-C1rgGh-z.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-B8zpboOh.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-BiFWQsz6.js"><link rel="stylesheet" crossorigin="" href="/assets/UserAvatarComponent-HOhEbA2Z.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-DF37KnKj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-B4KFYtjl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-D7xKfUOs.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-EZs4cS4X.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-D7GeLU85.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-BmTisq_j.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-DbT9WDTg.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-CwBo40RL.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-Q9SsU8j-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-xuall8K-.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-CqUndE9i.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-DueBurDr.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-BB71Q9C_.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-DtlSCNRQ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-qdXm0TVu.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-DihvZdVB.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-BQHNRY7e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-Qwy0HFkw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BANMUPSj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-BDpoMRr3.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-0MDL3P7P.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-BJriR31d.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-C1vDmaBY.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Alex C-G, Michael Günther"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Alex C-G, Michael Günther"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="13 mins read"><meta property="article:published_time" content="2024-12-05T00:55:21.000+01:00"><meta property="article:modified_time" content="2024-12-05T00:55:21.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "A-t-on encore besoin du découpage avec les modèles qui gèrent les longs contextes ?",
  "description": "Comparaison des performances des modèles d'embedding à contexte long selon différentes stratégies de découpage pour trouver l'approche optimale adaptée à vos besoins.",
  "image": [
    "https://jina.ai/blog-banner/still-need-chunking-when-long-context-models-can-do-it-all.webp"
  ],
  "datePublished": "2024-12-05T00:55:21.000+01:00",
  "dateModified": "2024-12-05T00:55:21.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    },
    {
      "@type": "Person",
      "name": "Michael Günther",
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-ce90450d="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-ce90450d="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-ce90450d="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-ce90450d="" class="q-space"></div><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-ce90450d="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-ce90450d="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-ce90450d="" class="q-list q-list--dark" role="list"><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Nouvelles</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Modèles</div></a><div data-v-ce90450d="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_93a2a6a9-bcb8-470b-912a-683af90d4250" aria-label="Développer &quot;Des produits&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Des produits</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_93a2a6a9-bcb8-470b-912a-683af90d4250" style="display: none;"><div data-v-ce90450d="" class="q-list q-list--dark" role="list" label="Des produits"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lecteur</div><div class="q-item__label q-item__label--caption text-caption">Lisez les URL et effectuez des recherches sur le Web pour de meilleurs LLM de base.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Intégrations</div><div class="q-item__label q-item__label--caption text-caption">Intégrations multimodales et multilingues de classe mondiale.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reclasseur</div><div class="q-item__label q-item__label--caption text-caption">Récupérateur neuronal de classe mondiale pour maximiser la pertinence de la recherche.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Recherche profonde</div><div class="q-item__label q-item__label--caption text-caption">Recherchez, lisez et raisonnez jusqu'à trouver la meilleure réponse.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_05c8cdb5-7b0b-4090-bef6-833d3b45398e" aria-label="Développer &quot;Plus&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Plus</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_05c8cdb5-7b0b-4090-bef6-833d3b45398e" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Classificateur</div><div class="q-item__label q-item__label--caption text-caption">Classification à zéro plan et à quelques plans pour l'image et le texte.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmenteur</div><div class="q-item__label q-item__label--caption text-caption">Coupez un long texte en morceaux et effectuez la tokenisation.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Documentation de l'API</div><div class="q-item__label q-item__label--caption text-caption">Génération automatique de code pour votre IDE ou LLM copilote</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-ce90450d="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_2c0f53c4-3a1f-4c6d-a503-88bef50e5174" aria-label="Développer &quot;Entreprise&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Entreprise</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_2c0f53c4-3a1f-4c6d-a503-88bef50e5174" style="display: none;"><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">À propos de nous</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Contacter le service commercial</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Programme de stage</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Rejoignez-nous</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Télécharger le logo</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">termes et conditions</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Se connecter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Se connecter</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-ce90450d="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_c063f836-e8b0-40d7-b185-97f1a605596f"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_c063f836-e8b0-40d7-b185-97f1a605596f" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_c063f836-e8b0-40d7-b185-97f1a605596f_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-ce90450d="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Le Contexte Long Est-il Vraiment Utile ?</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Problèmes avec les Embeddings de Contexte Long</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Contexte Long vs. Troncature</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Segmentation du texte pour de meilleures performances de recherche</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Le découpage tardif résout le problème de contexte</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Découper ou ne pas découper ?</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Conclusions : Quand Utiliser Quoi ?</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Conclusion</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog technique</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">décembre 04, 2024</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">A-t-on encore besoin du découpage avec les modèles qui gèrent les longs contextes ?</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Comparaison des performances des modèles d'embedding à contexte long selon différentes stratégies de découpage pour trouver l'approche optimale adaptée à vos besoins.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Michael Günther"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Michael Günther" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Alex C-G, Michael Günther • 13 minutes lues</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><p>En octobre 2023, nous avons introduit <code>jina-embeddings-v2</code>, la première famille de modèles d'embedding open-source capable de gérer des entrées allant jusqu'à 8 192 tokens. Dans la continuité, cette année nous avons lancé <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>, offrant le même support étendu d'entrées avec des améliorations supplémentaires.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-14.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-4.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Dans cet article, nous allons approfondir les embeddings de contexte long et répondre à quelques questions : Quand est-il pratique de consolider un tel volume de texte en un seul vecteur ? La segmentation améliore-t-elle la recherche, et si oui, comment ? Comment pouvons-nous préserver le contexte des différentes parties d'un document tout en segmentant le texte ?</p><p>Pour répondre à ces questions, nous allons comparer plusieurs méthodes de génération d'embeddings :</p><ul><li>Embedding de contexte long (encodage jusqu'à 8 192 tokens dans un document) vs contexte court (c'est-à-dire troncature à 192 tokens).</li><li>Sans découpage vs découpage naïf vs <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">late chunking</a>.</li><li>Différentes tailles de chunks avec découpage naïf et late chunking.</li></ul><h2 id="is-long-context-even-useful" style="position: relative;"><a href="#is-long-context-even-useful" title="Le Contexte Long Est-il Vraiment Utile ?" id="anchor-is-long-context-even-useful"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Le Contexte Long Est-il Vraiment Utile ?</h2><p>Avec la capacité d'encoder jusqu'à dix pages de texte dans un seul embedding, les modèles d'embedding de contexte long ouvrent des possibilités pour la représentation de texte à grande échelle. Mais est-ce vraiment utile ? Selon beaucoup de gens... non.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 6.35227 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--15-.png" width="559" height="88" alt="" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 5.21368 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png" width="610" height="117" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--16-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png 610w" style="cursor: help;"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 10.2143 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png" width="1430" height="140" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--14-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--14-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png 1430w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 11.0735 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png" width="1506" height="136" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png 1506w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div></div></div><figcaption><p><span style="white-space: pre-wrap;">Sources : </span><a href="https://www.youtube.com/watch?v=xKR08kDY2q4"><span style="white-space: pre-wrap;">Citation de Nils Reimer dans le podcast How AI Is Built</span></a><span style="white-space: pre-wrap;">, </span><a href="https://x.com/brainlag/status/1717221138483331158"><span style="white-space: pre-wrap;">tweet de brainlag</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38026784"><span style="white-space: pre-wrap;">commentaire de egorfine sur Hacker News</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38020753"><span style="white-space: pre-wrap;">commentaire de andy99 sur Hacker News</span></a></p></figcaption></figure><p>Nous allons aborder toutes ces préoccupations avec une investigation détaillée des capacités de contexte long, quand le contexte long est utile, et quand vous devriez (et ne devriez pas) l'utiliser. Mais d'abord, écoutons ces sceptiques et examinons certains des problèmes auxquels font face les modèles d'embedding de contexte long.</p><h2 id="problems-with-long-context-embeddings" style="position: relative;"><a href="#problems-with-long-context-embeddings" title="Problèmes avec les Embeddings de Contexte Long" id="anchor-problems-with-long-context-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Problèmes avec les Embeddings de Contexte Long</h2><p>Imaginons que nous construisons un système de recherche de documents pour des articles, comme ceux de notre <a href="https://jina.ai/news">blog Jina AI</a>. Parfois, un seul article peut couvrir plusieurs sujets, comme le <a href="https://jina.ai/news/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc">rapport sur notre visite à la conférence ICML 2024</a>, qui contient :</p><ul><li>Une introduction, capturant des informations générales sur ICML (nombre de participants, lieu, portée, etc).</li><li>La présentation de notre travail (<a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>).</li><li>Des résumés d'autres articles de recherche intéressants présentés à ICML.</li></ul><p>Si nous créons un seul embedding pour cet article, cet embedding représente un mélange de trois sujets disparates :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png" class="kg-image" alt="" width="2000" height="778" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 1 : Lors de l'embedding d'un document couvrant plusieurs sujets, le vecteur résultant représente un mélange de tous les paragraphes, perdant potentiellement les informations distinctes et spécifiques contenues dans chaque paragraphe individuel.</span></figcaption></figure><p>Cela conduit à plusieurs problèmes :</p><ul><li><strong>Dilution de la Représentation :</strong> Bien que tous les sujets d'un texte donné <em>puissent</em> être liés, un seul peut être pertinent pour la requête de recherche d'un utilisateur. Cependant, un seul embedding (dans ce cas, celui de l'ensemble du billet de blog) n'est qu'un point dans l'espace vectoriel. À mesure que plus de texte est ajouté à l'entrée du modèle, l'embedding se déplace pour capturer le sujet global de l'article, le rendant moins efficace pour représenter le contenu couvert dans des paragraphes spécifiques.</li><li><strong>Capacité Limitée :</strong> Les modèles d'embedding produisent des vecteurs de taille fixe, indépendamment de la longueur d'entrée. Plus on ajoute de contenu à l'entrée, plus il devient difficile pour le modèle de représenter toutes ces informations dans le vecteur. C'est comme réduire une image à 16×16 pixels — Si vous réduisez une image de quelque chose de simple, comme une pomme, vous pouvez encore tirer du sens de l'image réduite. Réduire un plan des rues de Berlin ? Pas vraiment.</li><li><strong>Perte d'Information :</strong> Dans certains cas, même les modèles d'embedding de contexte long atteignent leurs limites ; De nombreux modèles prennent en charge l'encodage de texte jusqu'à 8 192 tokens. Les documents plus longs doivent être tronqués avant l'embedding, conduisant à une perte d'information. Si l'information pertinente pour l'utilisateur se trouve à la fin du document, elle ne sera pas du tout capturée par l'embedding.</li><li><strong>Vous Pourriez <em>Avoir Besoin</em> de Segmentation de Texte :</strong> Certaines applications nécessitent des embeddings pour des segments spécifiques du texte mais pas pour l'ensemble du document, comme l'identification du passage pertinent dans un texte.</li></ul><h2 id="long-context-vs-truncation" style="position: relative;"><a href="#long-context-vs-truncation" title="Contexte Long vs. Troncature" id="anchor-long-context-vs-truncation"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Contexte Long vs. Troncature</h2><p>Pour voir si le contexte long est vraiment utile, examinons la performance de deux scénarios de recherche :</p><ul><li>Encodage de documents jusqu'à 8 192 tokens (environ 10 pages de texte).</li><li>Troncature des documents à 192 tokens et encodage jusqu'à ce point.</li></ul><p>Nous allons comparer les résultats en utilisant<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> avec la métrique de récupération nDCG@10. Nous avons testé les jeux de données suivants :</p>

<table>
<thead>
<tr>
<th>Dataset</th>
<th>Description</th>
<th>Exemple de requête</th>
<th>Exemple de document</th>
<th>Longueur moyenne des documents (caractères)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/"><strong>NFCorpus</strong></a></td>
<td>Un jeu de données de recherche médicale en texte intégral avec 3 244 requêtes et documents principalement issus de PubMed.</td>
<td>"Using Diet to Treat Asthma and Eczema"</td>
<td>"Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland Recent studies have suggested that [...]"</td>
<td>326 753</td>
</tr>
<tr>
<td><a href="https://github.com/Yale-LILY/QMSum"><strong>QMSum</strong></a></td>
<td>Un jeu de données de résumé de réunions basé sur des requêtes nécessitant le résumé des segments pertinents de réunions.</td>
<td>"The professor was the one to raise the issue and suggested that a knowledge engineering trick [...]"</td>
<td>"Project Manager: Is that alright now ? {vocalsound} Okay . Sorry ? Okay , everybody all set to start the meeting ? [...]"</td>
<td>37 445</td>
</tr>
<tr>
<td><a href="https://paperswithcode.com/dataset/narrativeqa"><strong>NarrativeQA</strong></a></td>
<td>Jeu de données QA contenant de longues histoires et des questions correspondantes sur des contenus spécifiques.</td>
<td>"What kind of business Sophia owned in Paris?"</td>
<td>"ï»¿The Project Gutenberg EBook of The Old Wives' Tale, by Arnold Bennett\n\nThis eBook is for the use of anyone anywhere [...]"</td>
<td>53 336</td>
</tr>
<tr>
<td><a href="https://github.com/Alab-NII/2wikimultihop"><strong>2WikiMultihopQA</strong></a></td>
<td>Un jeu de données QA multi-étapes avec jusqu'à 5 étapes de raisonnement, conçu avec des modèles pour éviter les raccourcis.</td>
<td>"What is the award that the composer of song The Seeker (The Who Song) earned?"</td>
<td>"Passage 1:\nMargaret, Countess of Brienne\nMarguerite d'Enghien (born 1365 - d. after 1394), was the ruling suo jure [...]"</td>
<td>30 854</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2104.07091"><strong>SummScreenFD</strong></a></td>
<td>Un jeu de données de résumés de scénarios avec des transcriptions et résumés de séries TV nécessitant l'intégration d'intrigues dispersées.</td>
<td>"Penny gets a new chair, which Sheldon enjoys until he finds out that she picked it up from [...]"</td>
<td>"[EXT. LAS VEGAS CITY (STOCK) - NIGHT]\n[EXT. ABERNATHY RESIDENCE - DRIVEWAY -- NIGHT]\n(The lamp post light over the [...]"</td>
<td>1 613</td>
</tr>
</tbody>
</table>

<p>Comme nous pouvons le voir, l'encodage de plus de 192 tokens peut apporter des améliorations notables de performance :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png" class="kg-image" alt="" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 2 : Comparaison des performances d'embedding de contexte long et d'embedding de texte court</span></figcaption></figure><p>Cependant, sur certains jeux de données, nous observons des améliorations plus importantes que sur d'autres :</p><ul><li>Pour <strong>NFCorpus</strong>, la troncature ne fait pratiquement aucune différence. Cela s'explique par le fait que les titres et les résumés se trouvent au début des documents, et ceux-ci sont très pertinents pour les termes de recherche typiques des utilisateurs. Que le texte soit tronqué ou non, les données les plus pertinentes restent dans la limite de tokens.</li><li><strong>QMSum</strong> et <strong>NarrativeQA</strong> sont considérés comme des tâches de "compréhension de lecture", où les utilisateurs recherchent généralement des faits spécifiques dans un texte. Ces faits sont souvent dispersés dans les détails du document et peuvent se trouver en dehors de la limite de 192 tokens. Par exemple, dans le document NarrativeQA <em>Percival Keene</em>, la réponse à la question "Qui est le tyran qui vole le déjeuner de Percival ?" se trouve bien au-delà de cette limite. De même, dans <strong>2WikiMultiHopQA</strong>, les informations pertinentes sont dispersées dans l'ensemble des documents, obligeant les modèles à naviguer et à synthétiser les connaissances de plusieurs sections pour répondre efficacement aux requêtes.</li><li><strong>SummScreenFD</strong> est une tâche visant à identifier le scénario correspondant à un résumé donné. Comme le résumé englobe des informations réparties dans tout le scénario, l'encodage d'une plus grande partie du texte améliore la précision de l'association du résumé au bon scénario.</li></ul><h2 id="segmenting-text-for-better-retrieval-performance" style="position: relative;"><a href="#segmenting-text-for-better-retrieval-performance" title="Segmentation du texte pour de meilleures performances de recherche" id="anchor-segmenting-text-for-better-retrieval-performance"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Segmentation du texte pour de meilleures performances de recherche</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Dans la suite, nous discutons de trois concepts similaires. Pour éviter toute confusion, nous les désignons comme suit :<br>• <b><strong style="white-space: pre-wrap;">Segmentation</strong></b> : Détection des marques de limite dans un texte d'entrée, par exemple, les phrases ou un nombre fixe de tokens.<br>• <b><strong style="white-space: pre-wrap;">Chunking naïf</strong></b> : Division du texte en chunks basée sur les marques de segmentation, avant de l'encoder.<br>• <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">Late chunking</strong></b></a> : Encodage du document d'abord puis segmentation (préservant le contexte entre les chunks).</div></div><p>Au lieu d'intégrer un document entier dans un seul vecteur, nous pouvons utiliser différentes méthodes pour d'abord segmenter le document en attribuant des marques de limite :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/chunking-animation.gif" class="kg-image" alt="" width="2000" height="492" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/chunking-animation.gif 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/chunking-animation.gif 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/chunking-animation.gif 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/chunking-animation.gif 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 3 : Application des méthodes de chunking "Taille fixe", "Basé sur les phrases" et "Sémantique" à un passage de texte</span></figcaption></figure><p>Quelques méthodes courantes incluent :</p><ul><li><strong>Segmentation par taille fixe :</strong> Le document est divisé en segments d'un nombre fixe de tokens, déterminé par le tokenizer du modèle d'embedding. Cela garantit que la tokenisation des segments correspond à la tokenisation du document entier (segmenter par un nombre spécifique de caractères pourrait conduire à une tokenisation différente).</li><li><strong>Segmentation par phrase :</strong> Le document est segmenté en phrases, et chaque chunk se compose de <em>n</em> phrases.</li><li><strong>Segmentation par sémantique :</strong> Chaque segment correspond à plusieurs phrases et un modèle d'embedding détermine la similarité des phrases consécutives. Les phrases ayant des similarités d'embedding élevées sont assignées au même chunk.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Vous pouvez facilement effectuer la segmentation avec <a href="https://jina.ai/segmenter/">Jina Segmenter</a>, notre API gratuite pour segmenter les longs textes en chunks et la tokenisation basée sur la structure du document.</div></div><p>Par souci de simplicité, nous utilisons la segmentation à taille fixe dans cet article.</p><h3 id="document-retrieval-using-naive-chunking" style="position: relative;"><a href="#document-retrieval-using-naive-chunking" title="Récupération de documents utilisant le chunking naïf" id="anchor-document-retrieval-using-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Récupération de documents utilisant le chunking naïf</h3><p>Une fois que nous avons effectué la segmentation à taille fixe, nous pouvons découper naïvement le document selon ces segments :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png" class="kg-image" alt="" width="960" height="540" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 960w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 4 : Chunking naïf basé sur les marques de limite détectées pendant la segmentation.</span></figcaption></figure><p>En utilisant <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>, nous encodons chaque chunk en un embedding qui capture précisément sa sémantique, puis stockons ces embeddings dans une base de données vectorielle.</p><p>À l'exécution, le modèle encode la requête d'un utilisateur en un vecteur de requête. Nous comparons celui-ci à notre base de données vectorielle d'embeddings de chunks pour trouver le chunk ayant la plus haute similarité cosinus, puis retournons le document correspondant à l'utilisateur :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--17-.png" class="kg-image" alt="" width="2000" height="847" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--17-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--17-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--17-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/image--17-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 5 : Recherche de documents implémentée avec un découpage naïf : (1) Les documents de la collection sont divisés en fragments selon des indices de délimitation, (2) le modèle d'embedding encode tous les fragments et nous stockons les embeddings résultants dans une base de données, (3) lorsqu'une requête arrive, le modèle d'embedding l'encode et la base de données détermine le fragment le plus similaire. À la fin, nous identifions le document pertinent à partir de l'ID du document stocké pour le fragment dans la base de données et le retournons à l'utilisateur.</span></figcaption></figure><h3 id="problems-with-naive-chunking" style="position: relative;"><a href="#problems-with-naive-chunking" title="Problèmes avec le découpage naïf" id="anchor-problems-with-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Problèmes avec le découpage naïf</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png" class="kg-image" alt="" width="1774" height="456" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--18-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--18-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--18-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png 1774w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 6 : Lors du découpage d'un texte en phrases, les références aux parties précédentes du texte ne peuvent pas être résolues.</span></figcaption></figure><p>Bien que le découpage naïf réponde à certaines limitations des modèles d'embedding à contexte long, il présente aussi des inconvénients :</p><ul><li><strong>Perte de la vue d'ensemble :</strong> En ce qui concerne la recherche de documents, plusieurs embeddings de petits fragments peuvent ne pas saisir le sujet global du document. C'est comme ne pas voir la forêt à cause des arbres.</li><li><strong>Problème de contexte manquant :</strong> Les fragments ne peuvent pas être interprétés avec précision car les informations contextuelles sont manquantes, comme illustré dans la Figure 6.</li><li><strong>Efficacité :</strong> Plus de fragments nécessitent plus de stockage et augmentent le temps de recherche.</li></ul><h2 id="late-chunking-solves-the-context-problem" style="position: relative;"><a href="#late-chunking-solves-the-context-problem" title="Le découpage tardif résout le problème de contexte" id="anchor-late-chunking-solves-the-context-problem"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Le découpage tardif résout le problème de contexte</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Pour résoudre le problème du contexte manquant, nous avons introduit une nouvelle méthode appelée « découpage tardif », décrite dans nos précédents articles de blog : <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">partie I</strong></b></a>, <a href="https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/"><b><strong style="white-space: pre-wrap;">partie II</strong></b></a>, <a href="https://jina.ai/news/finding-optimal-breakpoints-in-long-documents-using-small-language-models"><b><strong style="white-space: pre-wrap;">partie III</strong></b></a>, <a href="https://arxiv.org/abs/2409.04701"><b><strong style="white-space: pre-wrap;">article de recherche</strong></b></a>.</div></div><p>Le découpage tardif fonctionne en deux étapes principales :</p><ol><li>D'abord, il utilise les capacités de contexte long du modèle pour encoder l'ensemble du document en embeddings de tokens. Cela préserve le contexte complet du document.</li><li>Ensuite, il crée des embeddings de fragments en appliquant un pooling moyen à des séquences spécifiques d'embeddings de tokens, correspondant aux indices de délimitation identifiés lors de la segmentation.</li></ol><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png" class="kg-image" alt="" width="1200" height="865" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--19-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--19-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 7 : Découpage tardif vs découpage naïf.</span></figcaption></figure><p>L'avantage principal de cette approche est que les embeddings de tokens sont contextualisés - ce qui signifie qu'ils capturent naturellement les références et les relations avec d'autres parties du document. Puisque le processus d'embedding se produit avant le découpage, chaque fragment conserve une conscience du contexte plus large du document, résolvant ainsi le problème de contexte manquant qui affecte les approches de découpage naïf.</p><p>Pour les documents qui dépassent la taille d'entrée maximale du modèle, nous pouvons utiliser le « découpage tardif long » :</p><ol><li>D'abord, nous divisons le document en « macro-fragments » qui se chevauchent. Chaque macro-fragment est dimensionné pour s'adapter à la longueur maximale de contexte du modèle (par exemple, 8 192 tokens).</li><li>Le modèle traite ces macro-fragments pour créer des embeddings de tokens.</li><li>Une fois que nous avons les embeddings de tokens, nous procédons au découpage tardif standard - en appliquant le pooling moyen pour créer les embeddings de fragments finaux.</li></ol><p>Cette approche nous permet de gérer des documents de n'importe quelle longueur tout en préservant les avantages du découpage tardif. Considérez-la comme un processus en deux étapes : d'abord rendre le document digestible pour le modèle, puis appliquer la procédure de découpage tardif régulière.</p><p>En résumé :</p><ul><li><strong>Découpage naïf :</strong> Segmenter le document en petits fragments, puis encoder chaque fragment séparément.</li><li><strong>Découpage tardif :</strong> Encoder l'ensemble du document en une fois pour créer des embeddings de tokens, puis créer des embeddings de fragments en regroupant les embeddings de tokens selon les limites des segments.</li><li><strong>Découpage tardif long :</strong> Diviser les grands documents en macro-fragments qui se chevauchent et qui s'adaptent à la fenêtre de contexte du modèle, les encoder pour obtenir des embeddings de tokens, puis appliquer le découpage tardif normalement.</li></ul><p>Pour une description plus détaillée de l'idée, consultez notre <a href="https://arxiv.org/abs/2409.04701">article</a> ou les articles de blog mentionnés ci-dessus.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2409.04701"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models</div><div class="kg-bookmark-description">Many use cases require retrieving smaller portions of text, and dense vector-based retrieval systems often perform better with shorter text segments, as the semantics are less likely to be over-compressed in the embeddings. Consequently, practitioners often split text documents into smaller chunks and encode them separately. However, chunk embeddings created in this way can lose contextual information from surrounding chunks, resulting in sub-optimal representations. In this paper, we introduce a novel method called late chunking, which leverages long context embedding models to first embed all tokens of the long text, with chunking applied after the transformer model and just before mean pooling - hence the term late in its naming. The resulting chunk embeddings capture the full contextual information, leading to superior results across various retrieval tasks. The method is generic enough to be applied to a wide range of long-context embedding models and works without additional training. To further increase the effectiveness of late chunking, we propose a dedicated fine-tuning approach for embedding models.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-6.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-2.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="to-chunk-or-not-to-chunk" style="position: relative;"><a href="#to-chunk-or-not-to-chunk" title="Découper ou ne pas découper ?" id="anchor-to-chunk-or-not-to-chunk"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Découper ou ne pas découper ?</h2><p>Nous avons déjà vu que l'embedding à contexte long surpasse généralement les embeddings de textes plus courts, et donné un aperçu des stratégies de découpage naïf et tardif. La question est maintenant : Le découpage est-il meilleur que l'embedding à contexte long ?</p><p>Pour effectuer une comparaison équitable, nous tronquons les valeurs de texte à la longueur maximale de séquence du modèle (8 192 tokens) avant de commencer à les segmenter. Nous utilisons une segmentation de taille fixe avec 64 tokens par segment (pour la segmentation naïve et le découpage tardif). Comparons trois scénarios :</p><ul><li><strong>Pas de segmentation :</strong> Nous encodons chaque texte en un seul embedding. Cela conduit aux mêmes scores que l'expérience précédente (voir Figure 2), mais nous les incluons ici pour mieux les comparer.</li><li><strong>Découpage naïf :</strong> Nous segmentons les textes, puis appliquons un découpage naïf basé sur les indices de délimitation.</li><li><strong>Découpage tardif :</strong> Nous segmentons les textes, puis utilisons le découpage tardif pour déterminer les embeddings.</li></ul><p>Pour le découpage tardif et la segmentation naïve, nous utilisons la recherche de fragments pour déterminer le document pertinent (comme montré dans la Figure 5, plus haut dans cet article).</p><p>Les résultats ne montrent pas de gagnant clair :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png" class="kg-image" alt="" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 8 : Pas de découpage vs découpage naïf vs découpage tardif</span></figcaption></figure><ul><li><strong>Pour la recherche de faits, le découpage naïf est plus performant :</strong> Pour les jeux de données QMSum, NarrativeQA et 2WikiMultiHopQA, le modèle doit identifier les passages pertinents dans le document. Ici, le découpage naïf est clairement meilleur que l'encodage de tout en un seul embedding, car probablement seuls quelques fragments contiennent des informations pertinentes, et ces fragments les capturent beaucoup mieux qu'un seul embedding de l'ensemble du document.</li><li><strong>Le chunking tardif fonctionne mieux avec des documents cohérents et un contexte pertinent :</strong> Pour les documents couvrant un sujet cohérent où les utilisateurs recherchent des thèmes généraux plutôt que des faits spécifiques (comme dans NFCorpus), le chunking tardif surpasse légèrement l'absence de chunking, car il équilibre le contexte global du document avec les détails locaux. Cependant, bien que le chunking tardif soit généralement plus performant que le chunking naïf en préservant le contexte, cet avantage peut devenir un inconvénient lors de la recherche de faits isolés dans des documents contenant principalement des informations non pertinentes - comme le montrent les régressions de performance pour NarrativeQA et 2WikiMultiHopQA, où le contexte ajouté devient plus distrayant qu'utile.</li></ul><h3 id="does-chunk-size-make-a-difference" style="position: relative;"><a href="#does-chunk-size-make-a-difference" title="La Taille des Chunks Fait-elle une Différence ?" id="anchor-does-chunk-size-make-a-difference"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>La Taille des Chunks Fait-elle une Différence ?</h3><p>L'efficacité des méthodes de chunking dépend vraiment du dataset, soulignant combien la structure du contenu joue un rôle crucial :</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png" class="kg-image" alt="" width="1200" height="1800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--21-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--21-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Figure 9 : Comparaison des tailles de chunks avec chunking naïf et tardif.</span></figcaption></figure><p>Comme nous pouvons le voir, le chunking tardif surpasse généralement le chunking naïf avec des tailles de chunks plus petites, car les chunks naïfs plus petits sont trop réduits pour contenir beaucoup de contexte, tandis que les chunks tardifs plus petits conservent le contexte du document entier, les rendant plus significatifs sémantiquement. L'exception à cela est le dataset NarrativeQA où il y a simplement tellement de contexte non pertinent que le chunking tardif est moins performant. Avec des tailles de chunks plus grandes, le chunking naïf montre une amélioration marquée (dépassant occasionnellement le chunking tardif) grâce au contexte accru, tandis que la performance du chunking tardif diminue progressivement.</p><h2 id="takeaways-when-to-use-what" style="position: relative;"><a href="#takeaways-when-to-use-what" title="Conclusions : Quand Utiliser Quoi ?" id="anchor-takeaways-when-to-use-what"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusions : Quand Utiliser Quoi ?</h2><p>Dans cet article, nous avons examiné différents types de tâches de recherche de documents pour mieux comprendre quand utiliser la segmentation et quand le chunking tardif aide. Alors, qu'avons-nous appris ?</p><h3 id="when-should-i-use-long-context-embedding" style="position: relative;"><a href="#when-should-i-use-long-context-embedding" title="Quand Devrais-je Utiliser l'Embedding à Long Contexte ?" id="anchor-when-should-i-use-long-context-embedding"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Quand Devrais-je Utiliser l'Embedding à Long Contexte ?</h3><p>En général, inclure autant de texte de vos documents que possible dans l'entrée de votre modèle d'embedding ne nuit pas à la précision de la recherche. Cependant, les modèles d'embedding à long contexte se concentrent souvent sur le début des documents, car ils contiennent du contenu comme les titres et l'introduction qui sont plus importants pour juger de la pertinence, mais les modèles peuvent manquer du contenu au milieu du document.</p><h3 id="when-should-i-use-naive-chunking" style="position: relative;"><a href="#when-should-i-use-naive-chunking" title="Quand Devrais-je Utiliser le Chunking Naïf ?" id="anchor-when-should-i-use-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Quand Devrais-je Utiliser le Chunking Naïf ?</h3><p>Lorsque les documents couvrent plusieurs aspects, ou que les requêtes des utilisateurs ciblent des informations spécifiques dans un document, le chunking améliore généralement les performances de recherche.</p><p>Finalement, les décisions de segmentation dépendent de facteurs comme la nécessité d'afficher du texte partiel aux utilisateurs (par exemple, comme Google présente les passages pertinents dans les aperçus des résultats de recherche), ce qui rend la segmentation essentielle, ou des contraintes de calcul et de mémoire, où la segmentation peut être moins favorable en raison de la surcharge de recherche accrue et de l'utilisation des ressources.</p><h3 id="when-should-i-use-late-chunking" style="position: relative;"><a href="#when-should-i-use-late-chunking" title="Quand Devrais-je Utiliser le Chunking Tardif ?" id="anchor-when-should-i-use-late-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Quand Devrais-je Utiliser le Chunking Tardif ?</h3><p>En encodant le document complet avant de créer des chunks, le chunking tardif résout le problème des segments de texte perdant leur signification en raison d'un contexte manquant. Cela fonctionne particulièrement bien avec des documents cohérents, où chaque partie est liée à l'ensemble. Nos expériences montrent que le chunking tardif est particulièrement efficace lors de la division du texte en plus petits chunks, comme démontré dans notre <a href="https://arxiv.org/abs/2409.04701">article</a>. Cependant, il y a une mise en garde : si des parties du document n'ont pas de rapport entre elles, inclure ce contexte plus large peut en fait dégrader les performances de recherche, car cela ajoute du bruit aux embeddings.</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusion" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusion</h2><p>Le choix entre l'embedding à long contexte, le chunking naïf et le chunking tardif dépend des exigences spécifiques de votre tâche de recherche. Les embeddings à long contexte sont précieux pour les documents cohérents avec des requêtes générales, tandis que le chunking excelle dans les cas où les utilisateurs recherchent des faits ou des informations spécifiques dans un document. Le chunking tardif améliore davantage la recherche en conservant la cohérence contextuelle dans des segments plus petits. En fin de compte, la compréhension de vos données et de vos objectifs de recherche guidera l'approche optimale, équilibrant précision, efficacité et pertinence contextuelle.</p><p>Si vous explorez ces stratégies, envisagez d'essayer <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>—ses capacités avancées de long contexte, son chunking tardif et sa flexibilité en font un excellent choix pour divers scénarios de recherche.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-15.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-5.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Catégories:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog technique</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Ffr%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-ce90450d="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-ce90450d="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-ce90450d="" class="col-sm-12 col-md"><div data-v-ce90450d="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Des bureaux</div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Sunnyvale, Californie</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, États-Unis</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Berlin, Allemagne (siège social)</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Allemagne</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Pékin, Chine</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Niveau 5, bâtiment 6, n° 48, rue Haidian Ouest, Pékin, Chine</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Shenzhen, en Chine</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">402 étage 4, bâtiment technologique Fu'an, Shenzhen, Chine</div></div></div></div></div><div data-v-ce90450d="" class="col-sm-12 col-md row"><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fondation Recherche</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Lecteur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Intégrations</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Reclasseur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Recherche profonde</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Classificateur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Segmenteur</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Documentation de l'API</div></a><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Obtenir la clé API Jina</div></div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Limite de taux</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-ce90450d="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Statut de l'API</div></a></div><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Entreprise</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">À propos de nous</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Contacter le service commercial</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Rédaction</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Programme de stage</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Rejoignez-nous</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Télécharger le logo</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Termes</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Sécurité</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">termes et conditions</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Confidentialité</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Gérer les cookies</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-ce90450d="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-ce90450d="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-ce90450d="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-ce90450d="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>