const e="Nous fournissons les meilleurs intégrations, reclassements, lecteurs LLM et optimiseurs d'invites, ainsi qu'une IA de recherche pionnière pour les données multimodales.",s="Votre base de recherche, suralimentée.",t={approach:"Notre approche",approach_connect_dots:"Relier les points : les utilisateurs expérimentés aux entreprises",approach_connect_dots_description:"Alors, pourquoi l'accent mis sur les utilisateurs expérimentés est-il essentiel pour notre modèle centré sur l'entreprise ? Parce qu'il s'agit d'établir des relations précoces. En s'adressant aux utilisateurs expérimentés dès maintenant, nous construisons des ponts vers les entreprises qu'ils influenceront à l'avenir. Il s'agit d'un jeu stratégique - un investissement à long terme pour garantir que notre offre d'entreprise reste prioritaire lorsque ces utilisateurs expérimentés accèdent à des rôles décisionnels au sein des organisations.",approach_content1:"Dans le monde en évolution rapide de l'IA, les stratégies doivent être à la fois agiles et avant-gardistes. Bien que notre offre principale reste centrée sur les entreprises, le paysage de l'IA a évolué d'une manière qui nécessite de repenser notre approche de l'acquisition de clients. Voici pourquoi l'introduction des utilisateurs expérimentés comme point d'entrée de notre entonnoir n'est pas seulement innovante, mais cruciale pour notre croissance soutenue dans le secteur des entreprises.",approach_content2:"Chez Jina AI, notre stratégie est d'être proactif plutôt que réactif. L'inclusion des utilisateurs expérimentés comme point d'entrée de l'entonnoir garantit que nous capturons non seulement les tendances actuelles du marché, mais que nous sommes également stratégiquement prêts pour la croissance future de l'entreprise. Notre engagement envers les entreprises reste inébranlable ; cependant, notre approche pour les atteindre est innovante, robuste et, surtout, avant-gardiste.",approach_content4:`Tout le monde souhaite une meilleure recherche. Chez Jina AI, nous permettons une meilleure recherche en fournissant la <span class="text-primary text-bold">Search Foundation</span>, qui se compose d'Embeddings, de Rerankers, de Reader et de Prompt Ops. Ces composants fonctionnent de concert pour révolutionner la façon dont nous recherchons et comprenons les données.`,approach_miss_mark:"Pourquoi les MLOps traditionnels passent à côté de la cible",approach_miss_mark_description:"Alors que l'afflux d'utilisateurs expérimentés est important, les outils MLOps traditionnels sont mal équipés pour répondre à leurs besoins. Ces outils rappellent l'utilisation d'un tracteur pour naviguer dans les rues de la ville - ils sont lourds et souvent excessifs. Les développeurs de la nouvelle génération exigent des outils agiles et intuitifs qui complètent leur rythme de développement rapide.",approach_new_paradigm:"Technologie basée sur les invites : un nouveau paradigme",approach_new_paradigm_description:`2023 a annoncé un changement important : l'essor de la technologie basée sur les invites. En simplifiant le processus de développement de l'IA, il a démocratisé l'accès aux outils d'IA. Désormais, ceux qui n'ont pas une expérience approfondie de la programmation, appelés "utilisateurs expérimentés", peuvent s'engager dans le développement de l'IA sans les courbes d'apprentissage abruptes associées à des outils tels que Pytorch, Docker ou Kubernetes.

En établissant un parallèle, cela s'apparente à l'évolution de l'informatique personnelle. Au départ, seuls les experts en technologie utilisaient des ordinateurs. Mais avec l'avènement d'interfaces conviviales, un public plus large pourrait participer. Aujourd'hui, avec la technologie basée sur les invites, nous assistons à une démocratisation similaire de l'IA.`,awards:"Récompenses et reconnaissance",berlin:"Berlin, Allemagne (siège social)",berlin_address:"Prinzessinnenstraße 19-20, 10969 Berlin, Allemagne",berlin_address2:"Société d'expédition : Leipzigerstr. 96, 10117 Berlin, Allemagne",bj:"Pékin, Chine",bj_address:"Niveau 5, bâtiment 6, n° 48, rue Haidian Ouest, Pékin, Chine",brochure_info:"Votre guide de notre entreprise vous attend",description:"L'avenir commence ici.",download_brochure1:"Télécharger la brochure",download_docarray_logo:"Téléchargez le logo DocArray",download_docarray_logo_desc:"Accédez au logo DocArray, un projet open source initié par Jina AI et contribué à la Linux Foundation en décembre 2022. Disponible en modes clair et sombre, aux formats PNG et SVG.",download_jina_logo:"Téléchargez le logo Jina AI",download_jina_logo_desc:"Obtenez le logo Jina AI en modes clair et sombre, disponible aux formats PNG et SVG. Ce logo est une marque déposée auprès de l'Office de l'Union européenne pour la propriété intellectuelle (EUIPO).",download_logo:"Télécharger des logos",employees:"Les employés aujourd'hui",empower_developers:"Développeurs habilités",fastApiCaption:"Plus de 20 000 $ versés depuis 2021.",founded:"Fondé",founded_in:"Fondé en",investors:"Nos investisseurs",linuxFoundationCaption:"Verse une contribution annuelle de 10 000 $ à compter de 2022.",many:"Beaucoup",media:{video:"Entretien vidéo"},mission:"Notre mission",mission_content1:"Nos technologies clés, notamment le réglage rapide, le service rapide, le réglage de modèles et le service de modèles, incarnent notre engagement à démocratiser l'accès à l'IA. Grâce à notre initiative open source, nous nous efforçons de favoriser l'innovation, la collaboration et la transparence, garantissant des solutions évolutives, efficaces et robustes. Jina AI est plus qu'une simple entreprise ; il s'agit d'une communauté vouée à donner aux entreprises les moyens de relever les défis dynamiques de l'ère numérique et de prospérer dans leurs domaines.",mission_content2:"Au cœur de Jina AI se trouve notre mission : être le portail vers l’IA multimodale pour une clientèle diversifiée, des utilisateurs expérimentés et développeurs aux entreprises. Nous croyons profondément au pouvoir de l'open source et nous nous engageons à créer des outils avancés et accessibles pour la communauté de l'IA. Nos technologies clés, notamment le réglage rapide, le service rapide, le réglage intégré et le service intégré, incarnent notre engagement à démocratiser l'accès à l'IA. Grâce à notre initiative open source, nous nous efforçons de favoriser l'innovation, la collaboration et la transparence, garantissant des solutions évolutives, efficaces et robustes. Jina AI est plus qu'une simple entreprise ; il s'agit d'une communauté vouée à donner aux entreprises les moyens de relever les défis dynamiques de l'ère numérique et de prospérer dans leurs domaines.",mission_content3:"Chez Jina AI, notre mission est de diriger l'avancement de l'IA multimodale grâce à des technologies innovantes d'intégration et basées sur des invites, en nous concentrant spécifiquement sur des domaines tels que le traitement du langage naturel, l'analyse d'images et de vidéos et l'interaction de données multimodales. Cette spécialisation nous permet de fournir des solutions uniques qui transforment des données complexes et multi-sources en informations exploitables et en applications révolutionnaires.",mit_report_title:"Multimodal : la nouvelle frontière de l’IA",mit_techreview:"Revue technologique du MIT",numfocusCaption:"Donne régulièrement chaque mois à partir de 2022.",office:"Nos bureaux",otherProjectsCaption:"A fait don de plus de 3 000 $ via le parrainage Github.",our_answer:"Tout à fait Yann. Nous y sommes, construisant des ponts vers un avenir d'IA multimodal !",pythonSoftwareFoundationCaption:"A fourni un don unique de 10 000 $ et parrainé plusieurs événements PyCon, notamment ceux en Allemagne, en Italie, en Chine et aux États-Unis.",sefo:{layer0:"Applications utilisateur final",layer1:"RAG / orchestration",layer3:"GPU/mobile/edge/informatique locale"},segmentFaultCaption:"A fait un don unique de 6 000 $.",show_position:"Comment rechercher des positions de fondation dans l'écosystème ?",stats_1:"Fondée en février 2020, Jina AI s'est rapidement imposée comme un pionnier mondial de la technologie d'IA multimodale. Dans un délai impressionnant de 20 mois, nous avons réussi à lever 37,5 millions de dollars, marquant notre position forte dans l'industrie de l'IA. Notre technologie révolutionnaire, open source sur GitHub, a permis à plus de 40 000 développeurs dans le monde de créer et de déployer de manière transparente des applications multimodales sophistiquées.",stats_2:"En 2023, nous avons fait des progrès significatifs dans l'avancement des outils de génération d'IA basés sur la technologie multimodale. Cette innovation a profité à plus de 250 000 utilisateurs dans le monde, répondant à une pléthore d'exigences commerciales uniques. Qu'il s'agisse de faciliter la croissance des entreprises, d'améliorer l'efficacité opérationnelle ou d'optimiser les coûts, Jina AI se consacre à donner aux entreprises les moyens d'exceller à l'ère multimodale.",stats_4:`Fondée en 2020, Jina AI est une entreprise leader dans le domaine de l'IA de recherche. Notre plateforme <span class="text-primary text-bold">Search Foundation</span> combine des intégrations, des rerankers et des modèles de langage réduits pour aider les entreprises à créer des applications de recherche GenAI et multimodales fiables et de haute qualité.`,stats_v1:"Rechercher/accéder",subtitle:"Révolutionner la création de contenu grâce à des solutions générées par l'IA pour débloquer des possibilités infinies. Façonner l'avenir du contenu généré par l'IA et améliorer la créativité humaine.",sues_und_sauer:"Suẞ & Sauer",sues_und_sauer_tooltip:"Süß-Sauer, une saveur populaire (mais stéréotypée) de la cuisine germano-chinoise, signifie sucré-salé. C'est une métaphore des hauts et des bas de la vie d'une start-up.",sunnyvale_address:"710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, États-Unis",sz:"Shenzhen, en Chine",sz_address:"402 étage 4, bâtiment technologique Fu'an, Shenzhen, Chine",team:"À l'intérieur du portail de Jina AI",team_content1:"Aux quatre coins du monde, nous construisons l’avenir de l’IA. Nos perspectives distinctes enrichissent notre travail et suscitent des innovations. Au sein de ce portail, nous embrassons notre individualité et poursuivons avec passion nos rêves. Bienvenue sur le portail du futur de l'IA.",team_join:"Rejoignez-nous",team_size:"Ces photos incluent nos anciens collègues et stagiaires. Nous apprécions chacun d’entre eux.",technologies:"Les technologies",title:"À propos de Jina AI",title0:"L'avenir",title1:"Départs",title2:"Ici",title3:"Commence ici",understand_our_strength:"Comprendre notre force",understand_our_view2:"Comprendre la Fondation Search",users:"Utilisateurs enregistrés",value:"Nos récompenses",value_content1:"Nous ne nous contentons pas de ce qui est demandé. Nous ne faisons aucun compromis. Nous visons l'excellence.",vision:"Notre mission",vision_content1:"Inspiré par la perspicacité de Yann LeCun selon laquelle '",vision_content3:`L'avenir de l'IA est <span class="text-primary text-bold">multimodal</span>, et nous en faisons partie. Nous sommes conscients que les entreprises sont confrontées à des difficultés pour exploiter les données multimodales. En réponse, nous nous engageons auprès de la <span class="text-primary text-bold">Search Foundation</span> pour aider les entreprises et les développeurs à mieux rechercher et à utiliser les données multimodales pour la croissance de leur entreprise.`,yannlecun_quote:"Un système d'intelligence artificielle entraîné uniquement sur des mots et des phrases ne se rapprochera jamais de la compréhension humaine."},n={answer1:"Oui, la même clé API est valable pour tous les produits de base de recherche de Jina AI. Cela inclut les API d'intégration, de reclassement, de lecture et de réglage fin, avec des jetons partagés entre tous les services.",answer12:"Nous adhérons à une politique de confidentialité stricte et n'utilisons pas les données saisies par les utilisateurs pour entraîner nos modèles.",answer3:"Oui, l'utilisation des jetons peut être surveillée dans l'onglet « Acheter des jetons » en saisissant votre clé API, vous permettant ainsi d'afficher l'historique d'utilisation et les jetons restants.",answer4:"Si vous avez égaré une clé rechargée et souhaitez la récupérer, veuillez contacter le support AT jina.ai avec votre adresse e-mail enregistrée pour obtenir de l'aide.",answer5:"Non, nos clés API n'ont pas de date d'expiration. Cependant, si vous pensez que votre clé a été compromise et souhaitez la retirer ou transférer ses jetons vers une nouvelle clé, veuillez contacter notre équipe d'assistance pour obtenir de l'aide.",answer6:"En effet, notre architecture sans serveur décharge certains modèles pendant les périodes de faible utilisation. La requête initiale active ou « réchauffe » le modèle, ce qui peut prendre quelques secondes. Après cette première activation, les demandes suivantes sont traitées beaucoup plus rapidement.",question1:"Puis-je utiliser la même clé API pour l'intégration, le reclassement, le lecteur et le réglage fin des API ?",question12:"Les données saisies par l'utilisateur sont-elles utilisées pour entraîner vos modèles ?",question3:"Puis-je surveiller l’utilisation des jetons de ma clé API ?",question4:"Que dois-je faire si j'oublie ma clé API ?",question5:"Les clés API expirent-elles ?",question6:"Pourquoi la première demande pour certains modèles est-elle lente ?",title:"Questions courantes liées à l'API"},i={base_model:"Modèle de base pour un réglage fin",check_data:"Télécharger des données synthétiques",check_model:"Télécharger le modèle affiné",data_size:"Données synthétiques générées",description:"Obtenez des intégrations affinées pour le domaine de votre choix.",description_long:"Dites-nous simplement dans quel domaine vous souhaitez que vos intégrations excellent, et nous vous fournirons automatiquement un modèle d'intégration prêt à l'emploi et affiné pour ce domaine.",does_it_work_tho:"Mais est-ce que ça marche ?",does_it_work_tho_explain:"Le réglage automatique contient la promesse auto-magique de fournir des intégrations affinées pour n'importe quel domaine de votre choix. Mais cela fonctionne-t-il vraiment? C'est un doute assez raisonnable. Nous l'avons testé sur une variété de domaines et de modèles de base pour le savoir. Découvrez les résultats cueillis aux cerises et au citron ci-dessous.",domain_instruction:"Instruction de domaine",embedding_provider:"Sélectionnez un modèle d'intégration de base",eval_evaluation:"Validation",eval_map:"CARTE",eval_mrr:"MRR",eval_ndcg:"NDCG",eval_performance_before_after:"Performances sur la validation synthétique définie avant et après le réglage fin",eval_syntheticDataSize:"Total",eval_test:"Données réelles pour les tests",eval_training:"Entraînement",faq_v1:{answer1:"La fonctionnalité est actuellement en version bêta et coûte 1 million de jetons par modèle affiné. Vous pouvez utiliser votre clé API existante à partir de l'API Embedding/Reranker si elle contient suffisamment de jetons, ou vous pouvez créer une nouvelle clé API, qui comprend 1 million de jetons gratuits.",answer10:"Actuellement non. Notez que cette fonctionnalité est toujours en version bêta. Le stockage public des modèles affinés et des données synthétiques dans le hub de modèles Hugging Face nous aide, ainsi que la communauté, à évaluer la qualité de la formation. À l’avenir, nous prévoyons de proposer une option de stockage privé.",answer11:"Étant donné que tous les modèles affinés sont téléchargés sur Hugging Face, vous pouvez y accéder via SentenceTransformers en spécifiant simplement le nom du modèle.",answer12:"Veuillez vérifier votre dossier spam. Si vous ne le trouvez toujours pas, veuillez contacter notre équipe d'assistance en utilisant l'adresse e-mail que vous avez fournie.",answer2:"Vous n'avez pas besoin de fournir de données d'entraînement. Décrivez simplement votre domaine cible (le domaine pour lequel vous souhaitez que les intégrations affinées soient optimisées) en langage naturel, ou utilisez une URL comme référence, et notre système générera des données synthétiques pour entraîner le modèle.",answer3:"Environ 30 minutes.",answer4:"Les modèles affinés et les données synthétiques sont stockés publiquement dans le hub de modèles Hugging Face.",answer5:"Le système utilise l'API Reader pour récupérer le contenu de l'URL. Il analyse ensuite le contenu pour résumer le ton et le domaine, qu'il utilise comme lignes directrices pour générer des données synthétiques. Par conséquent, l’URL doit être accessible au public et représentative du domaine cible.",answer6:"Oui, vous pouvez affiner un modèle pour une langue autre que l'anglais. Le système détecte automatiquement la langue des instructions de votre domaine et génère des données synthétiques en conséquence. Nous vous recommandons également de choisir le modèle de base approprié pour la langue cible. Par exemple, si vous ciblez un domaine allemand, vous devez sélectionner « jina-embeddings-v2-base-de » comme modèle de base.",answer7:"Non, notre API de réglage fin ne prend en charge que les modèles Jina v2.",answer8:"À la fin du processus de réglage fin, le système évalue le modèle à l'aide d'un ensemble de tests retenu et rapporte les mesures de performances. Vous recevrez un e-mail détaillant les performances avant/après sur cet ensemble de tests. Vous êtes également encouragé à évaluer le modèle sur votre propre ensemble de tests pour garantir sa qualité.",answer9:"Le système génère des données synthétiques en intégrant l'instruction du domaine cible que vous fournissez au raisonnement des agents LLM. Il produit des triplets négatifs durs, essentiels à la formation de modèles d’intégration de haute qualité. Pour plus de détails, veuillez vous référer à notre prochain document de recherche sur Arxiv.",question1:"Combien coûte l’API de réglage fin ?",question10:"Puis-je garder mes modèles affinés et mes données synthétiques privés ?",question11:"Comment puis-je utiliser le modèle affiné ?",question12:"Je n'ai jamais reçu l'e-mail avec les résultats de l'évaluation. Que dois-je faire?",question2:"Que dois-je saisir ? Dois-je fournir des données de formation ?",question3:"Combien de temps faut-il pour peaufiner un modèle ?",question4:"Où sont stockés les modèles peaufinés ?",question5:"Si je fournis une URL de référence, comment le système l'utilise-t-il ?",question6:"Puis-je affiner un modèle pour une langue spécifique ?",question7:"Puis-je affiner les intégrations non-Jina, par exemple bge-M3 ?",question8:"Comment garantissez-vous la qualité des modèles peaufinés ?",question9:"Comment générer des données synthétiques ?",title:"Questions courantes liées au réglage automatique"},find_on_hf:"Liste des modèles affinés",temporarily_unavailable:"Temporairement indisponible. Nous améliorons notre système de réglage automatique pour mieux vous servir. Veuillez revenir plus tard.",test_on:"Testé sur {_dataSize} échantillons aléatoires de {_dataName}",test_performance_before_after:"Performances sur un ensemble de tests retenu avant et après le réglage fin",title:"API de réglage automatique",total_improve:"Moy. amélioration",usage:"Usage",what_is:"Qu’est-ce que le réglage automatique ?",what_is_answer_long:"Le réglage fin vous permet de prendre un modèle pré-entraîné et de l'adapter à une tâche ou un domaine spécifique en l'entraînant sur un nouvel ensemble de données. En pratique, trouver des données d’entraînement efficaces n’est pas simple pour de nombreux utilisateurs. Une formation efficace nécessite plus que la simple introduction de fichiers PDF bruts et HTML dans le modèle ; et il est difficile de bien faire les choses. Le réglage automatique résout ce problème en générant automatiquement des données de formation efficaces à l'aide d'un pipeline d'agents LLM avancé ; et affiner le modèle dans un flux de travail ML. Vous pouvez le considérer comme une combinaison de génération de données synthétiques et d'AutoML, il vous suffit donc de décrire votre domaine cible en langage naturel et de laisser notre système faire le reste."},r={description:"Du blog à la bannière, sans les invites !",example_description:`Alice commençait à être très fatiguée d'être assise à côté de sa sœur sur la berge et de n'avoir rien à faire : une ou deux fois, elle avait jeté un coup d'œil dans le livre que sa sœur lisait, mais il ne contenait ni images ni conversations, "et à quoi sert un livre", pensa Alice, "sans images ni conversations ?" Alors elle réfléchissait (du mieux qu'elle pouvait, car la chaleur de la journée la rendait somnolente et stupide), si le plaisir de faire une guirlande valait la peine de se lever et de cueillir les marguerites, quand soudain un lapin blanc aux yeux roses courut près d'elle.`,example_title:"Les aventures d'Alice au pays des merveilles - Chapitre 1"},o="Bêta",a={answer10:"Nous proposons un essai gratuit de bienvenue aux nouveaux utilisateurs, qui comprend un million de jetons à utiliser avec n'importe lequel de nos modèles, facilité par une clé API générée automatiquement. Une fois la limite de jetons gratuits atteinte, les utilisateurs peuvent facilement acheter des jetons supplémentaires pour leurs clés API via l'onglet « Acheter des jetons ».",answer13:"Non, les jetons ne sont pas déduits pour les demandes ayant échoué.",answer14:"Les paiements sont traités via Stripe, prenant en charge diverses méthodes de paiement, notamment les cartes de crédit, Google Pay et PayPal, pour votre commodité.",answer15:"Oui, une facture sera émise à l'adresse e-mail associée à votre compte Stripe lors de l'achat de tokens.",answer9:"Notre modèle de tarification est basé sur le nombre total de jetons traités, ce qui donne aux utilisateurs la possibilité d'attribuer ces jetons à un nombre illimité de phrases, offrant ainsi une solution rentable pour diverses exigences d'analyse de texte.",question10:"Existe-t-il un essai gratuit disponible pour les nouveaux utilisateurs ?",question13:"Les jetons sont-ils facturés pour les demandes ayant échoué ?",question14:"Quels moyens de paiement sont acceptés ?",question15:"La facturation est-elle disponible pour les achats de jetons ?",question9:"La facturation est-elle basée sur le nombre de phrases ou de demandes ?",title:"Questions courantes liées à la facturation"},l={all:"Tous",events:"Événement",featured:"Mis en exergue",insights:"Avis","knowledge-base":"Base de connaissances",latest:"Dernier",press:"communiqué de presse",releases:"Mise à jour logicielle","tech-blog":"Blog technique"},u={api_free_trial:"Clé API gratuite",api_paid:"Clé API payante",api_paid_or_free:"Utilisez-vous une clé API payante ou une clé d’essai gratuite ?",are_you:"Es-tu:",commercial_contact_sales:"Ceci est commercial. Contactez notre équipe commerciale.",contact_sales_for_licensing:"Contactez notre équipe commerciale pour les licences.",csp_user:"Utilisez-vous nos images de modèles officielles sur AWS et Azure ?",educational_teaching:"Un établissement d’enseignement qui l’utilise pour l’enseignement ?",for_profit_internal_use:"Une entreprise à but lucratif qui l'utilise en interne ?",free_use:"Vous pouvez utiliser les modèles librement.",government_public_services:"Une entité gouvernementale l’utilise pour des services publics ?",is_use_commercial:"Votre utilisation est-elle commerciale ?",may_be_commercial_contact:"Il peut s'agir d'une information commerciale. Veuillez nous contacter pour plus de précisions.",no:"Non",no1:"Non",no2:"Non",no3:"Non",no_restrictions:"Aucune restriction. Utilisez-le conformément à votre contrat actuel.",no_restrictions_apply:"Aucune restriction ne s'applique.",non_commercial_free_use:"Ceci n'est pas commercial. Vous pouvez utiliser les modèles librement.",non_profit_ngo_mission:"Une association à but non lucratif ou une ONG l'utilise pour votre mission ?",not_sure:"Pas sûr",personal_hobby_projects:"Vous l'utilisez pour des projets personnels ou de loisirs ?",product_service_sale:"Vous l’utilisez dans un produit ou un service que vous vendez ?",title:"Auto-vérification de la licence CC BY-NC",trial_key_restrictions:"La clé d'essai gratuite ne peut être utilisée qu'à des fins non commerciales. Veuillez acheter un forfait payant pour une utilisation commerciale.",typically_non_commercial_check:"Il s'agit généralement d'un service non commercial, mais vérifiez auprès de nous en cas de doute.",typically_non_commercial_free_use:"Il s'agit généralement d'un usage non commercial. Vous pouvez utiliser les modèles librement.",using_api_or_cloud:"Utilisez-vous notre API officielle ou nos images officielles sur Azure ou AWS ?",using_cc_by_nc_models:"Utilisez-vous ces modèles ?",yes:"Oui",yes1:"Oui",yes2:"Oui",yes3:"Oui"},d={access:"Accès public",access_explain:"Les classificateurs publics peuvent être utilisés par toute personne disposant du <code>classifier_id</code>, et leur utilisation consommera le quota de jetons de l'appelant plutôt que le vôtre. Les classificateurs privés ne sont accessibles que par vous.",access_private:"Privé",access_public:"Publique",api_delete:"Supprimer le classificateur",api_delete_explain:"Supprimer un classificateur par son ID.",api_list:"Classificateurs de listes",api_list_explain:"Listez tous les classificateurs que vous avez créés.",classifier_id:"ID du classificateur",classify_inputs:"Entrées à classer",classify_inputs_explain:"Pour le texte, il peut s'agir d'une phrase contenant jusqu'à 8192 jetons. Pour les images, il peut s'agir d'une URL ou d'une image codée en base64.",classify_labels:"Étiquettes des candidats",classify_labels_explain:"Les entrées seront classées selon ces étiquettes. Il peut y avoir jusqu'à 256 classes. Utilisez des étiquettes sémantiques pour de meilleures performances.",compare_table:{access_control:"Contrôle d'accès",classifier_id_required:"ID du classificateur requis",continuous_updates:"Mises à jour continues du modèle",default_solution:"Solution par défaut pour la classification générale",feature:"Fonctionnalité",few_shot:"Quelques coups",image_multi_lingual_support:"Support multimodal et multilingue",labels_required_classify:"Étiquettes requises dans /classify",labels_required_train:"Étiquettes requises dans /train",max_classes:"Classes maximales",max_classifiers:"Classificateurs maximum",max_inputs_request:"Nombre maximal d'entrées par requête",max_token_length:"Longueur maximale du jeton par entrée",na:"N / A",no:"Non",out_of_domain_solution:"Pour les données en dehors du domaine de v3/clip-v1 ou les données sensibles au temps",primary_use_case:"Cas d'utilisation principal",semantic_labels_required:"Étiquettes sémantiques requises",state_management:"Gestion de l'État",stateful:"Avec état",stateless:"Apatride",token_count:"{count} jetons",training_data_required:"Données de formation requises",yes:"Oui",zero_shot:"Coup zéro"},create_classifier:"Nouveau classificateur à quelques coups",create_classifier_explain:"Créez un nouveau classificateur à quelques coups et entraînez-le avec des exemples étiquetés.",description:"Classification à zéro plan et à quelques plans pour l'image et le texte.",description_long:"Essayez notre terrain de jeu API pour voir comment fonctionne notre classificateur.",description_long1:"Classificateur haute performance à zéro coup et à quelques coups pour données multimodales et multilingues.",explain:"Le classificateur est un service API qui catégorise le texte et les images à l'aide de modèles d'intégration (<code>jina-embeddings-v3</code> et <code>jina-clip-v1</code>), prenant en charge à la fois la classification à zéro coup sans données de formation et l'apprentissage à quelques coups avec un minimum d'exemples.",faq_v1:{answer1:"Le zero-shot nécessite des étiquettes sémantiques pendant la classification et aucune pendant l'apprentissage, tandis que le few-shot nécessite des étiquettes pendant l'apprentissage mais pas la classification. Cela signifie que le zero-shot est plus adapté aux besoins de classification flexibles et immédiats, tandis que le few-shot est plus adapté aux catégories fixes et spécifiques à un domaine qui peuvent évoluer au fil du temps.",answer10:"Oui, vous pouvez choisir entre <code>jina-embeddings-v3</code> pour la classification de texte (particulièrement utile pour le multilingue) et <code>jina-clip-v1</code> pour la classification multimodale. De nouveaux modèles comme <code>jina-clip-v2</code> seront automatiquement disponibles via l'API dès leur sortie.",answer2:"<code>num_iters</code> contrôle l'intensité de l'entraînement : les valeurs plus élevées renforcent les exemples importants tandis que les valeurs plus faibles minimisent l'impact des données moins fiables. Il peut être utilisé pour mettre en œuvre l'apprentissage en fonction du temps en donnant aux exemples récents un nombre d'itérations plus élevé, ce qui le rend utile pour faire évoluer les modèles de données.",answer3:"Les classificateurs publics peuvent être utilisés par toute personne disposant du <code>classifier_id</code>, en utilisant son propre quota de jetons. Les utilisateurs ne peuvent pas accéder aux données de formation ou à la configuration, et ne peuvent pas voir les demandes de classification des autres, ce qui permet un partage sécurisé des classificateurs.",answer4:"La méthode Few-shot nécessite 200 à 400 exemples d'entraînement pour surpasser la classification Zero-shot. Bien qu'elle atteigne finalement une plus grande précision, elle a besoin de cette période d'échauffement pour devenir efficace. Zero-shot fournit des performances cohérentes immédiatement sans données d'entraînement.",answer5:"Oui, l'API prend en charge les requêtes multilingues à l'aide de <code>jina-embeddings-v3</code> et la classification multimodale (texte/image) à l'aide de <code>jina-clip-v1</code>, avec prise en charge des images codées en URL ou en base64 dans la même requête.",answer6:"Zero-shot prend en charge 256 classes sans limite de classificateur, tandis que few-shot est limité à 16 classes et 16 classificateurs. Les deux prennent en charge 1 024 entrées par requête et 8 192 jetons par entrée.",answer7:"Le mode Few-shot permet une mise à jour continue via le point de terminaison <code>/train</code> pour s'adapter aux modèles de données changeants. Vous pouvez ajouter progressivement de nouveaux exemples ou classes lorsque la distribution des données change, sans reconstruire l'intégralité du classificateur.",answer8:"L'API utilise l'apprentissage en ligne en un seul passage : les exemples de formation mettent à jour les pondérations du classificateur mais ne sont pas stockés par la suite. Cela signifie que vous ne pouvez pas récupérer les données de formation historiques, mais cela garantit la confidentialité et l'efficacité des ressources.",answer9:"Commencez par un modèle à zéro coup pour obtenir des résultats immédiats et lorsque vous avez besoin d'une classification flexible avec des étiquettes sémantiques. Passez à un modèle à quelques coups lorsque vous avez 200 à 400 exemples, que vous avez besoin d'une plus grande précision ou que vous devez gérer des données spécifiques à un domaine/sensibles au temps.",question1:"Quelle est la différence entre les étiquettes en mode zero-shot et en mode few-shot ?",question10:"Puis-je utiliser différents modèles pour différentes langues/tâches ?",question2:"À quoi sert num_iters et comment dois-je l'utiliser ?",question3:"Comment fonctionne le partage de classificateurs publics ?",question4:"De combien de données ai-je besoin pour que le mode FPS fonctionne bien ?",question5:"Peut-il gérer plusieurs langues et à la fois du texte et des images ?",question6:"Quelles sont les limites strictes que je devrais connaître ?",question7:"Comment gérer les changements de données au fil du temps ?",question8:"Qu'advient-il de mes données d'entraînement après les avoir envoyées ?",question9:"Zero-shot ou few-shot : quand utiliser lequel ?",title:"Questions courantes liées au classificateur"},more:"plus",num_iters:"Itérations de formation",num_iters_explain:"Contrôle l'intensité de l'entraînement : des valeurs plus élevées améliorent la précision des exemples actuels mais augmentent le coût du jeton. La valeur par défaut de 10 fonctionne généralement bien.",read_notes:"Lire les notes de publication",select_classifier_or_model:"Sélectionnez un classificateur ou un modèle d'intégration",task_classify:"Classer",task_classify_explain:"Utilisez un classificateur à zéro coup ou à quelques coups pour classer du texte ou des images dans des classes définies.",task_manage:"Gérer",task_manage_explain:"Répertoriez ou supprimez vos classificateurs à quelques clichés.",task_select:"Sélectionnez une tâche",task_train:"Former",task_train_explain:"Créez ou mettez à jour un classificateur à quelques clichés avec des exemples étiquetés.",title:"API de classificateur",train_inputs:"Données de formation",train_inputs_explain:"Exemples de texte ou d'images avec des étiquettes pour la formation. Vous pouvez mettre à jour progressivement le classificateur avec de nouveaux exemples et étiquettes au fil du temps.",train_label:"Étiquette",what_is:"Qu'est-ce qu'un classificateur ?",when_to_use_what:"Quand utiliser le zero-shot ou le few-shot ?",when_to_use_what_explain:"Utilisez la classification zero-shot comme solution par défaut pour des résultats immédiats sur des tâches de classification générales avec jusqu'à 256 classes, tandis que l'apprentissage en quelques coups est mieux adapté lorsque vous traitez des données spécifiques à un domaine en dehors des connaissances des modèles d'intégration ou lorsque vous devez gérer des données sensibles au temps qui nécessitent des mises à jour continues du modèle."},c={description:"Intégrez des images et des phrases dans des vecteurs de longueur fixe avec CLIP"},p={description:"Plate-forme d'hébergement cloud pour les applications d'IA multimodales"},m={agreement:"En soumettant, vous confirmez que vous acceptez le traitement de vos données personnelles par Jina AI comme décrit dans le",anything_else:"Parlez-nous davantage de votre idée",cc_by_nc:"Demande d'utilisation commerciale des modèles CC BY-NC",cc_by_nc_description:"Nos derniers modèles sont généralement sous licence CC BY-NC. Pour une utilisation commerciale, accédez-y via notre API, Azure Marketplace ou AWS SageMaker. Cochez cette case pour une utilisation sur site en dehors de ces canaux.",company:"Organisation",company_size:"Taille de l'organisation",company_website:"Site Web de l'organisation",company_website_placeholder:"URL de la page d'accueil ou du profil LinkedIn de votre entreprise",country:"Pays",department:"Département",description:"Développez votre entreprise avec Jina AI.",drop_area_for_image:"Déposez vos images ici",faq:"FAQ",feedback_sent:"Soumis! Nous vous répondrons sous peu.",field_required:"Champ requis",get_api_key:"Comment obtenir ma clé API ?",image_upload:"Joindre des images",image_validate:"Vous pouvez joindre jusqu'à {_num} images. Uniquement JPG, JPEG, PNG, WEBP.",impact_snapshots:"Instantanés d'impact",invalid_date_format:"Format de date invalide. Veuillez utiliser le format JJ-MM-AAAA.",invalid_email:"Le courriel est invalide",invalid_number:"Numéro invalide. Veuillez saisir à nouveau",invalid_url:"L'URL n'est pas valide",name:"Nom",nc_check:"Ai-je besoin d’une licence commerciale ?",other_questions:"Autres questions",preferred_models:"Quels modèles vous intéressent ?",preferred_products:"Quels produits vous intéressent ?",pricing:"Tarifs ?",priority:"Assistance prioritaire pour les utilisateurs payants",private_statement:"Déclaration de confidentialité",rate_limit:"Quelle est la limite de débit ?",role:"Rôle de l'emploi",self_check:"Auto-vérification",sending_feedback:"Envoi...",shortcut:"Raccourci",submit:"Soumettre",submit_failed:"La soumission a échoué. Veuillez réessayer plus tard.",submit_success:"Merci pour votre soumission. Nous vous répondrons sous peu.",subtitle:"Jina AI, un leader de l'IA multimodale, excelle dans le réglage de modèle, le service de modèle, le réglage rapide et le service rapide. En tirant parti des technologies cloud natives telles que Kubernetes et des architectures sans serveur, nous proposons des solutions robustes, évolutives et prêtes pour la production. Grâce à notre expertise dans les grands modèles de langage, le texte, l'image, la vidéo, la compréhension audio, la recherche neuronale et l'art génératif, nous proposons des stratégies innovantes et pérennes pour faire progresser votre entreprise.",subtitle1:"Jina AI, leader de l'IA multimodale, excelle dans le réglage-intégration, le service-intégration, le réglage rapide et le service rapide. En tirant parti des technologies cloud natives telles que Kubernetes et des architectures sans serveur, nous proposons des solutions robustes, évolutives et prêtes pour la production. Grâce à notre expertise dans les grands modèles linguistiques, la compréhension du texte, des images, de la vidéo, de l'audio, la recherche neuronale et l'IA générative, nous proposons des stratégies innovantes et évolutives pour développer votre entreprise.",subtitle2:"Explorez Jina AI, la pointe de l'IA multimodale. Nous excellons dans les technologies d'intégration et d'invite, en utilisant des solutions cloud natives comme Kubernetes pour des systèmes robustes et évolutifs. Spécialisés dans les grands modèles de langage et le traitement multimédia, nous proposons des stratégies commerciales innovantes et tournées vers l’avenir grâce à notre expertise avancée en IA.",title:"Contacter le service commercial",trusted_by:"Approuvé par",turn_on_volume:"Augmentez le volume",work_email:"Email de travail"},g="Copie",v="Copié dans le presse-papier",_={description:"Un flux de travail humain dans la boucle pour créer des images HD à partir de texte"},f={description:"Créez des œuvres d'art Disco Diffusion convaincantes en une seule ligne de code"},h={description:"La structure de données pour les données multimodales"},b="Télécharger l'attestation SOC 2 Type 1",q={"11B tokens":"11 milliards","11B tokens_intuition1":"C’est similaire à la lecture de tous les articles en anglais sur Wikipédia.","11B tokens_targetUser":"Déploiement de production","1B tokens":"1 milliard","1B tokens_intuition1":`C'est à peu près la même chose que de lire les œuvres complètes de Shakespeare et toute la série "Harry Potter".`,"1B tokens_targetUser":"Développement de prototypes","1M tokens":"1 million","1M tokens_intuition1":`Équivalent à la lecture de l'intégralité du texte de "Le Hobbit" et "The Great Gatsby".`,"1M tokens_targetUser":"Expérience de jouet","1M_free":"1 million de jetons gratuits","1M_free_description":"Profitez de votre nouvelle clé API avec des jetons gratuits, aucune carte de crédit requise.","2_5B tokens":"2,5 milliards de jetons","2_5B tokens_intuition1":`Comparable à la transcription 1 000 fois de chaque mot prononcé dans la trilogie du film « Le Seigneur des Anneaux ».
`,"3p_integration":"Avec <b>{_numPartners}</b> services tiers","3p_integration_desc":"Intégrez notre base de recherche à vos services existants. Nos partenaires ont construit des connecteurs vers notre API, facilitant l'utilisation de nos modèles dans vos applications.","500M tokens":"500 millions de jetons","500M tokens_intuition1":"C’est comme regarder chaque épisode des « Simpsons » de la saison 1 à la saison 30.","59B tokens":"59 milliards de jetons","59B tokens_intuition1":"Égal à tous les tweets publiés dans le monde sur une période de deux jours.","5_5B tokens":"5,5 milliards de jetons","5_5B tokens_intuition1":"Équivalent à la lecture de l’intégralité du texte de l’Encyclopaedia Britannica.",Free1M:"1 million de jetons",add_pair:"Nouveau",add_time_explain:"La date à laquelle ce modèle a été ajouté à la Search Foundation.",api_integration_short:"Notre API d'intégration est nativement intégrée à diverses bases de données renommées, magasins de vecteurs, frameworks RAG et LLMOps.",api_integrations:"Intégrations d'API",api_key_update_message:"En remplaçant votre ancienne clé API, la nouvelle clé apparaîtra dans l'interface utilisateur à chaque fois que vous visiterez jina.ai. Les recharges futures s'appliqueront à cette nouvelle clé. Votre ancienne clé reste valide, donc si vous prévoyez de l'utiliser à nouveau, veuillez la conserver en toute sécurité.",api_key_update_title:"Remplacement de la clé API",auto_recharge:"Recharge automatique lorsque les jetons sont faibles",auto_recharge_confirm_message:"Êtes-vous sûr de vouloir désactiver la recharge automatique ? Cela empêchera les recharges automatiques lorsque le solde de votre token est faible.",auto_recharge_confirm_title:"Désactiver la recharge automatique",auto_recharge_description:"Recommandé pour un service ininterrompu en production. Lorsque le solde de votre token est inférieur au seuil que vous avez défini, nous rechargerons automatiquement votre carte de crédit du même montant que votre dernière recharge. Si vous avez acheté plusieurs packs lors de la dernière recharge, nous ne rechargerons qu'un seul pack.",auto_recharge_enable:"Vous avez activé la recharge automatique sur les jetons faibles",auto_recharge_enable_message:"Pour activer la recharge automatique, veuillez acheter un pack avec la recharge automatique définie sur vrai.",auto_recharge_enable_title:"Activer la recharge automatique",auto_request:"Aperçu automatique",auto_request_tooltip:`Prévisualisez automatiquement la réponse de l'API lors de la modification du modèle, en utilisant des centaines de jetons de votre clé API. Désactivez l'option d'envoi manuel d'une demande en cliquant sur "Obtenir une réponse".`,autostart:"L'intégration démarrera automatiquement après un bref délai",base64_description:"Les intégrations sont renvoyées sous forme de chaîne codée en base64. Plus efficace pour la transmission.",batch_job:"Travail par lots",batch_upload_hint:"Nous utiliserons la clé API et le modèle ci-dessous pour traiter les documents.","bge-base-en-v1_5_description":"Un modèle anglais robuste équilibrant performances et efficacité pour une utilisation polyvalente.","bge-base-en_description":"Un modèle anglais équilibré conçu pour des performances solides et fiables.","bge-base-zh-v1_5_description":"Un modèle chinois complet, équilibrant capacité et efficacité.","bge-base-zh_description":"Un modèle chinois polyvalent alliant efficacité et performances robustes.","bge-large-en-v1_5_description":"Un modèle anglais puissant offrant des intégrations de haut niveau avec une qualité exceptionnelle.","bge-large-en_description":"Un modèle anglais très performant conçu pour des intégrations de première qualité.","bge-large-zh-v1_5_description":"Un modèle chinois de grande capacité offrant des intégrations supérieures et détaillées.","bge-large-zh_description":"Un modèle chinois haute performance optimisé pour les intégrations de haut niveau.","bge-m3_description":"Un modèle multilingue polyvalent offrant des capacités étendues et des intégrations de haute qualité.","bge-small-en-v1_5_description":"Un modèle anglais simplifié offrant des intégrations efficaces et de haute qualité.","bge-small-en_description":"Un modèle anglais efficace pour des intégrations rationalisées et précises.","bge-small-zh-v1_5_description":"Un modèle chinois compact offrant des intégrations agiles et précises.","bge-small-zh_description":"Un modèle chinois agile pour des plongements efficaces et précis.",binary_description:"Les intégrations sont emballées sous la forme int8. Beaucoup plus efficace pour le stockage, la recherche et la transmission.",bulk:"Intégration par lots",bulk_embedding_failed:"Échec de la création d'une tâche d'intégration par lots",buy_more_quota:"Rechargez cette clé API avec plus de jetons",buy_poster:"Acheter une copie papier",cancel_button:"Annuler",click_upload_btn_above:"Cliquez sur le bouton de téléchargement ci-dessus pour commencer.",clip_v2_description:"jina-clip-v2 est un modèle de style CLIP de 0,9 B qui apporte trois avancées majeures : la prise en charge multilingue de 89 langues, une résolution d'image élevée à 512x512 et l'apprentissage de la représentation Matryoshka pour les plongements tronqués.",clip_v2_title:"clip-v2 : Incorporations multilingues et multimodales",code:"code",colbert_dimensions_explain:"La taille dimensionnelle de l'intégration par jeton.",compatible:"Mode compatible",compatible_explain:"Suit le même format de requête que nos modèles d'intégration de texte. Cela vous permet de basculer entre les modèles sans modifier la requête. Notez que la saisie d'image n'est pas prise en charge dans ce mode.",cosine_similarity:"Similitude cosinus",debugging:"Test",delete_pair:"Supprimer",description:"@:landing_page.embedding_desc1",dimensions:"Dimensions de sortie",dimensions_error:"La taille de la dimension doit être comprise entre 1 et 1024.",dimensions_explain:"Des dimensions plus petites permettent un stockage et une récupération efficaces, avec un impact minimal grâce à la représentation Matryoshka.",dimensions_warning:"Nous vous recommandons de conserver la taille de la dimension au-dessus de {_minDimension} pour des raisons de performances.",document:"Document",download:"Télécharger",edit_text1_text:"Modifier le texte de gauche",edit_text2_text:"Modifier le texte correct",embedding_done:"{_Count} phrases ont bien été intégrées.",embedding_none_description:"N'utilisez aucun modèle d'intégration",example_inputs:"Exemples d'entrées",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"Pour des informations détaillées sur nos processus de formation, nos sources de données et nos évaluations, veuillez vous référer à notre rapport technique disponible sur arXiv.",answer1:"Chaque utilisateur est autorisé à effectuer jusqu'à 100 requêtes par seconde, ce qui équivaut à 204 800 phrases de saisie par seconde.",answer17:"Nous développons actuellement des intégrations multimodales qui traiteront conjointement le texte, les images et l'audio. Des mises à jour seront annoncées bientôt !",answer18:"Pour toute question concernant le réglage fin de nos modèles avec des données spécifiques, veuillez nous contacter pour discuter de vos besoins. Nous sommes ouverts à l’exploration de la manière dont nos modèles peuvent être adaptés pour répondre à vos besoins.",answer19:"Oui, nos services sont disponibles sur la place de marché AWS et nous sommes en train de nous étendre aux places de marché Azure et GCP. Si vous avez des exigences particulières, veuillez nous contacter au service commercial AT jina.ai.",answer3:"Nos modèles prennent en charge l'anglais, l'allemand, l'espagnol, le chinois et divers langages de programmation. Pour plus de détails, veuillez vous référer à notre publication sur les modèles bilingues.",answer4:"Nos modèles permettent une longueur d'entrée allant jusqu'à 8 192 jetons, ce qui est nettement supérieur à la plupart des autres modèles. Un jeton peut aller d'un seul caractère, comme « a », à un mot entier, comme « pomme ». Le nombre total de caractères pouvant être saisis dépend de la longueur et de la complexité des mots utilisés. Cette capacité de saisie étendue permet à nos modèles jina-embeddings-v2 d'effectuer une analyse de texte plus complète et d'obtenir une plus grande précision dans la compréhension du contexte, en particulier pour les données textuelles volumineuses.",answer5:"Un seul appel API peut traiter jusqu'à 2 048 phrases ou textes, facilitant ainsi une analyse approfondie du texte en une seule requête.",answer6:"Vous pouvez utiliser soit <code>url</code>, soit <code>bytes</code> dans le champ <code>input</code> de la requête API. Pour <code>url</code>, indiquez l'URL de l'image que vous souhaitez traiter. Pour <code>octets</code>, encodez l'image au format base64 et incluez-la dans la requête. Le modèle renverra les intégrations de l'image dans la réponse.",answer7:"Selon le classement MTEB, notre modèle de base est en concurrence étroite avec le text-embedding-ada-002 d'OpenAI, affichant en moyenne des performances comparables. De plus, notre modèle de base excelle dans plusieurs tâches, notamment la classification, la classification par paires, le reclassement et la synthèse, surpassant ainsi le modèle d'OpenAI.",answer8:"La transition est simplifiée, car notre point de terminaison API, https://api.jina.ai/v1/embeddings, correspond aux schémas JSON d'entrée et de sortie du modèle text-embeddings-ada-002 d'OpenAI. Cette compatibilité garantit que les utilisateurs peuvent facilement remplacer le modèle OpenAI par le nôtre lorsqu’ils utilisent le point de terminaison d’OpenAI.",answer9:`Les jetons sont calculés en fonction de la longueur du texte et de la taille de l'image. Pour le texte de la requête, les jetons sont comptés de la manière standard. Pour l'image dans la demande, les étapes suivantes sont effectuées :
1. Taille des tuiles : chaque image est divisée en tuiles de taille 224x224 pixels.
	2. Couverture : le nombre de tuiles nécessaires pour couvrir complètement l'image d'entrée est calculé. Même si les dimensions de l'image ne sont pas parfaitement divisibles par 224, nous compterons les tuiles partielles comme des tuiles complètes.
	3. Total de tuiles : Le nombre total de tuiles couvrant l'image détermine le coût. Par exemple, si une image mesure 500 x 500 pixels, elle sera recouverte de 3 x 3 tuiles, ce qui donnera 9 tuiles.
	4. Calcul du coût : Chaque tuile contribue au coût final du traitement de l'image. Le coût par tuile est de 1000 jetons.

Exemple:
Pour une image de dimensions 500x500 pixels :

	• L'image est divisée en tuiles de 224 x 224 pixels.
	• Le nombre total de tuiles requises est de 3 (horizontal) x 3 (vertical) = 9 tuiles.
	• Le coût sera de 9*1000 = 9000 jetons`,question0:"Comment les modèles jina-embeddings-v2 ont-ils été formés ?",question1:"Combien de requêtes API puis-je effectuer par seconde ?",question17:"Fournissez-vous des modèles pour intégrer des images ou du son ?",question18:"Les modèles Jina Embedding peuvent-ils être ajustés avec des données privées ou d’entreprise ?",question19:"Vos points de terminaison peuvent-ils être hébergés en privé sur AWS, Azure ou GCP ?",question3:"Quelles langues vos modèles prennent-ils en charge ?",question4:"Quelle est la longueur maximale d’une seule phrase saisie ?",question5:"Quel est le nombre maximum de phrases que je peux inclure dans une seule demande ?",question6:"Comment envoyer des images au modèle jina-clip-v1 ?",question7:"Comment les modèles Jina Embeddings se comparent-ils au modèle text-embedding-ada-002 d'OpenAI ?",question8:"Dans quelle mesure la transition entre le text-embedding-ada-002 d'OpenAI et votre solution est-elle transparente ?",question9:"Comment les jetons sont-ils calculés lors de l'utilisation de jina-clip-v1 ?",title:"Questions courantes liées aux intégrations"},feature_8k1:"8192 longueur de jeton",feature_8k_description1:"Pionnier du premier modèle d'intégration open source avec une longueur de 8 192 jetons, permettant la représentation d'un chapitre entier dans un seul vecteur.",feature_cheap:"20x moins cher",feature_cheap_v1:"5x moins cher",feature_cheap_v1_description1:"Commencez par des essais gratuits et profitez d’une structure tarifaire simple. Accédez à de puissantes intégrations pour seulement 20 % du coût d'OpenAI.",feature_multilingual:"Proposant des modèles bilingues allemand-anglais, chinois-anglais, entre autres, idéaux pour les applications multilingues.",feature_on_premises:"La confidentialité avant tout",feature_on_premises_description1:"Déployez en toute transparence nos modèles d'intégration directement dans votre Virtual Private Cloud (VPC). Actuellement pris en charge sur AWS Sagemaker, avec des intégrations à venir pour Microsoft Azure et Google Cloud Platform. Pour des déploiements Kubernetes sur mesure, contactez notre équipe commerciale pour obtenir une assistance spécialisée.",feature_on_premises_description2:"Déployez les modèles Jina Embeddings dans AWS Sagemaker, et bientôt dans Microsoft Azure et Google Cloud Services, ou contactez notre équipe commerciale pour obtenir des déploiements Kubernetes personnalisés pour votre cloud privé virtuel et vos serveurs sur site.",feature_on_premises_description3:"Déployez les modèles Jina Embeddings dans AWS Sagemaker et Microsoft Azure, et bientôt dans Google Cloud Services, ou contactez notre équipe commerciale pour obtenir des déploiements Kubernetes personnalisés pour votre cloud privé virtuel et vos serveurs sur site.",feature_on_premises_description4:"Déployez les modèles Jina Embedding et Reranker sur site à l'aide d'AWS SageMaker, Microsoft Azure ou Google Cloud Services, en garantissant que vos données restent sous votre contrôle en toute sécurité.",feature_solid:"Le meilleur de sa catégorie",feature_solid_description1:"Développé à partir de nos recherches universitaires de pointe et rigoureusement testé par rapport aux modèles SOTA pour garantir des performances inégalées.",feature_top_perform1:"Intégration transparente",feature_top_perform_description1:"Entièrement compatible avec l'API d'OpenAI. S'intègre sans effort à plus de 10 bases de données vectorielles et systèmes RAG pour une expérience utilisateur fluide.",file_required:"Le fichier est requis",file_size_exceed:"Dépasser la taille maximale du fichier {_size}",file_type_not_supported:"Type de fichier non pris en charge",fill_example:"Remplissez un exemple",float_description:"Les intégrations sont renvoyées sous forme de liste de nombres à virgule flottante. Le plus courant et le plus facile à utiliser.",free:"Gratuit",generate_api_key_error:"La génération de la clé API a échoué.",generating_visualization:"Génération de visualisation...",get_new_key_button:"Obtenir une nouvelle clé",get_new_key_button_explain:"Opter pour une nouvelle clé entraînera la perte de l’historique d’utilisation associé à l’ancienne clé.",get_new_key_survey:"Remplissez l'enquête, aidez-nous à comprendre votre utilisation et obtenez une nouvelle clé API gratuitement !",includes:"Jetons valables pour :",index_and_search:"Index et recherche",index_and_search1:"Index et recherche",input:"Demande",input_api_key_error1:"Votre clé API n'est pas valide !",input_length:"Longueur d'entrée",input_type:"Intégrer en tant que document/requête",input_type_explain:"La même entrée peut servir soit de requête, soit d'incorporation de document, selon son rôle de recherche.",integrate:"Intégrer","jina-clip-v1_description":"Modèles d'intégration multimodaux pour les images et le texte anglais","jina-clip-v2_description":"Incorporations multilingues et multimodales pour textes et images","jina-colbert-v1-en_description":"ColBERT amélioré avec une longueur de jeton de 8 000 pour les tâches d'intégration et de reclassement","jina-colbert-v2_description":"Le meilleur ColBERT multilingue avec des performances de pointe en matière d'intégration et de reclassement","jina-embeddings-v2-base-code_description":"Optimisé pour la recherche de code et de docstring","jina-embeddings-v2-base-de_description":"Intégrations bilingues allemand-anglais avec performances SOTA","jina-embeddings-v2-base-en_description":"À égalité avec text-embedding-ada002 d'OpenAI","jina-embeddings-v2-base-es_description":"Intégrations bilingues espagnol-anglais avec performances SOTA","jina-embeddings-v2-base-zh_description":"Intégrations bilingues chinois-anglais avec performances SOTA","jina-embeddings-v2-small-en_description":"Optimisé pour une faible latence et une faible empreinte mémoire","jina-embeddings-v3_description":"Modèle d'intégration multilingue Frontier avec performances SOTA","jina-reranker-v1-base-en_description":"Notre premier modèle de reranker maximisant la pertinence de la recherche et du RAG","jina-reranker-v1-tiny-en_description":"Le modèle de reclassement le plus rapide, le mieux adapté pour classer un grand nombre de documents de manière fiable","jina-reranker-v1-turbo-en_description":"La meilleure combinaison de vitesse d'inférence rapide et de scores de pertinence précis","jina-reranker-v2-base-multilingual_description":"Le dernier et le meilleur modèle de reclassement avec prise en charge multilingue, des appels de fonctions et de la recherche de code.",key:"Clé API",key_enter_placeholder:"Veuillez saisir votre clé API",key_enter_placeholder_to_topup:"Saisissez la clé API que vous souhaitez recharger",key_to_top_up:"Vous avez une autre clé API à recharger ? Collez-la ci-dessus et cliquez sur « Enregistrer ».",key_warn:"Assurez-vous de stocker votre clé API dans un endroit sûr. Sinon vous devrez générer une nouvelle clé",key_warn_v2:"C'est votre clé unique. Conservez-la en toute sécurité !",language_explain:"Ce modèle prend en charge de manière optimale la langue {_langue}.",last_7_days:"Usage",late_chunking:"Morceau tardif",late_chunking_explain:"Appliquez la technique de découpage tardif pour exploiter les capacités de contexte long du modèle afin de générer des intégrations de morceaux contextuels.",learn_more:"Apprendre encore plus",learn_poster:"Découvrez comment nous l'avons fait",learning1:"En savoir plus sur les intégrations",learning1_description:"Par où commencer avec les intégrations ? Nous avons ce qu'il vous faut. Découvrez les intégrations de A à Z avec notre guide complet.",length:"Longueur du jeton",manage_billing:"Gérer la facture",manage_billing_tip:"Gérez vos informations de facturation, obtenez des factures et configurez la recharge automatique.",manage_quota1:"Clé API et facturation",max_file_size:"Taille maximale autorisée : {_maxSize}.",maximize_tooltip:"Maximisez ce panneau avec Shift+1",mistake_contact:"Si vous pensez qu'il s'agit d'une erreur, veuillez nous contacter.",mminput_placeholder:"Texte, URL de l'image, chaîne base64 de l'image",model_required:"Le modèle est requis",more_models:"{_numMore} autres modèles",more_than_two2:"Veuillez saisir plus de deux documents, c'est-à-dire plus de deux lignes.",multi_embedding:"Multi-vecteur",multi_embedding_explain:"Ce modèle renverra un sac d'intégrations contextualisées pour une entrée donnée. Chaque jeton de l'entrée est mappé à un vecteur dans la sortie.",multilingual:"Prise en charge multilingue",multimodal:"Multimodal",multimodal_explain:"Ce modèle peut encoder à la fois du texte et des images, ce qui le rend idéal pour les tâches de recherche multimodales.",new:"Nouveau modèle",no_data1:"Ajoutez une paire de phrases pour calculer la similarité",none:"Aucun",normalized:"Normalisation L2",normalized_explain:"Adapte l'intégration de sorte que sa norme euclidienne (L2) devienne 1, en préservant la direction. Utile lorsque l'aval implique un produit scalaire, une classification et une visualisation.",oncsp:"Sur CSP",onprem:"Sur site",open_tensorboard:"Ouvrir le visualiseur",opensource:"Système d'exploitation",opensource_explain:"Ce modèle est open source et disponible sur Hugging Face. Cliquez sur ce bouton pour voir le modèle sur Hugging Face.",original_documents:"Phrases à intégrer",original_documents_hint:"Entrez vos phrases ici. Chaque nouvelle ligne sera considérée comme une phrase/un document distinct.",output:"Réponse",output_dim:"Dimensions",output_dim_explain:"La dimension de sortie d'un vecteur d'incorporation de ce modèle est {_outputDim}.",output_dimension:"Dimensions de sortie",pairwise_test:"Par paire",per_k:"/ 1 000 jetons",per_m:"/ 1 million de jetons",please_fill_docs_first:"Veuillez d'abord saisir quelques phrases ci-dessous avant la recherche.",please_select_model:"Veuillez sélectionner un modèle d'intégration ou un modèle de reclassement",poster:"L'évolution des intégrations Poster",poster_description:"Découvrez l'affiche idéale pour votre espace, présentant des infographies captivantes ou des visuels à couper le souffle retraçant l'évolution des modèles d'intégration de texte depuis 1950.",pricing:"Tarification des API",pricing_desc:"La tarification de notre API est structurée autour de la quantité de jetons envoyés dans les requêtes. Pour l'API Reader, il s'agit du nombre de jetons dans les réponses. Ce modèle de tarification est applicable à tous les produits de la base de recherche de Jina AI : API d'intégration, de reclassement, de lecture et de réglage automatique. Avec la même clé API, vous avez accès à tous les services API.",protectData1:"Les données et documents de demande ne sont pas utilisés pour les modèles de formation.",protectData2:"Chiffrement des données en transit (TLS 1.2+) et au repos (AES-GCM 256).",protectData3:"Conforme SOC 2 et RGPD.",protect_data:"Protégez vos données",public_cloud_integration:"Avec <b>{_numPartners}</b> fournisseurs de services cloud",public_cloud_integration_desc:"Votre entreprise utilise-t-elle AWS ou Azure ? Déployez ensuite directement nos modèles de fondation de recherche sur ces plateformes dans votre entreprise, afin que vos données restent sécurisées et conformes.",query:"Requête",raise_issue:"Soulever un problème",rank_none_description:"N'utilisez aucun modèle de reranker",read_api_docs:"Spécifications de l'API",read_release_note:"Lire la note de publication",recharge_threshold:"Seuil de recharge",refresh:"Rafraîchir",refresh_key_tooltip1:"Obtenez une nouvelle clé API gratuitement",refresh_token_count1:"Actualiser pour obtenir les jetons disponibles de la clé API actuelle",regenerate:"Régénérer",remaining:"Jetons disponibles",remaining_left:"Il vous reste <b>{_leftTokens}</b> jetons dans la clé API ci-dessous.",request_number:"Heures de demande",request_path:"Point de terminaison de la demande",results_as_final_result:"#docs comme résultat final",results_fed_to_reranker:"#docs nourris pour reclasser",retry:"Recommencez",return_base64:"Base64 (sous forme de chaîne)",return_binary:"Binaire (emballé sous forme d'int8)",return_float:"Par défaut (comme float)",return_format:"Format des intégrations",return_format_explain:"Outre le flottant, vous pouvez lui demander de revenir sous forme binaire pour une récupération vectorielle plus rapide, ou sous forme d'encodage base64 pour une transmission plus rapide.",return_format_title:"Type de données de retour",return_ubinary:"Binaire (emballé sous forme de uint8)",right_api_key_to_charge:"Veuillez saisir la bonne clé API pour recharger",running:"Actif",score:"Score",search:"Recherche",search_hint:"Tapez pour rechercher dans les phrases répertoriées ci-dessous",select_classify_model:"Sélectionner un classificateur",select_embedding_model:"Sélectionnez les intégrations",select_rerank_model:"Sélectionnez un reclasseur",show_api_key:"Afficher la clé API",size:"Paramètres",size_explain:"Le nombre de paramètres dans le modèle est {_size}, notez qu'il ne s'agit pas de la taille du fichier modèle.",sleeping:"Inactif",start_batch:"Démarrer l'intégration par lots",start_embedding:"Indice",status_explain:"Notre architecture sans serveur peut décharger certains modèles pendant les périodes de faible utilisation. Pour les modèles actifs, les réponses sont immédiates. Les modèles inactifs nécessitent quelques secondes pour se charger lors de la demande initiale. Après l'activation, les demandes ultérieures sont traitées plus rapidement.",task_type:"Tâche en aval",task_type_classification:"Classification",task_type_classification_explain:"Classification des textes.",task_type_explain:"Sélectionnez la tâche en aval pour laquelle les intégrations seront utilisées. Le modèle renverra les intégrations optimisées pour cette tâche.",task_type_none_explain:"Aucun adaptateur ne sera utilisé. Une intégration générique sera renvoyée, utile pour le débogage ou le piratage.",task_type_retrieval_passage:"Passage de récupération",task_type_retrieval_passage_explain:"Intégration de documents dans une tâche de récupération de documents de requête.",task_type_retrieval_query:"Requête de récupération",task_type_retrieval_query_explain:"Intégration de requêtes dans une tâche de récupération de document de requête.",task_type_separation:"Séparation",task_type_separation_explain:"Regroupement de documents, visualisation de corpus.","task_type_text-matching":"Correspondance de texte","task_type_text-matching_explain":"Similarité sémantique de texte, recherche symétrique générale, recommandation, recherche de similitudes, déduplication.",tax_may_apply:"Selon votre emplacement, vous pouvez être facturé en USD, EUR ou dans d'autres devises. Des taxes peuvent s'appliquer.",text1:"Gauche",text2:"Droite",three_ways:"Trois façons d'acheter",three_ways_desc:"Abonnez-vous à notre API, achetez auprès de fournisseurs cloud ou obtenez une licence commerciale pour votre organisation.",title:"API d'intégration",token_example:`Un tweet compte environ 20 jetons, un article de presse environ 1 000 jetons et le roman de Charles Dickens "A Tale of Two Cities" compte plus d'un million de jetons.`,token_length_explain:"La longueur maximale de la séquence de jetons d'entrée est de {_tokenLength} pour ce modèle.",tokens:"Jetons",tools:"Outils",top_up_button:"Recharger l'ancienne clé",top_up_button_explain:"L'intégration de cette clé API offre une solution plus professionnelle, éliminant le besoin de changements de clé fréquents. Les données d'utilisation sont conservées et accessibles à tout moment.",top_up_warning_message1:"La clé API actuelle contient {_remainedTokens} jetons restants et sera remplacée par une nouvelle clé avec {_freeTokens} jetons. Vous pouvez continuer à utiliser ou recharger l'ancienne clé si vous l'avez stockée en toute sécurité. Comment veux-tu procéder?",top_up_warning_title:"Remplacer l'ancienne clé API",total_documents:"Progression de l'intégration : {_Processed}/{_Count} phrases.",tuning:"Affiner",turnstile_error:"Nous ne pouvons pas générer de clé API car nous n'avons pas pu vérifier si vous êtes humain.",turnstile_unsupported:"Nous ne pouvons pas générer de clé API car votre navigateur n'est pas pris en charge.",ubinary_description:"Les intégrations sont emballées sous forme de uint8. Beaucoup plus efficace pour le stockage, la recherche et la transmission.",upload:"Télécharger",upload_file:"Cliquez ici pour télécharger un fichier",usage:"Usage",usage_amount:"Jetons",usage_history:"Utilisation au cours des 7 derniers jours",usage_history_explain:"Les données ne sont pas en temps réel et peuvent être retardées de quelques minutes.",usage_reason:"Description",usage_reason_consume:"Utilisé",usage_reason_purchase:"Acheté",usage_reason_trial:"Procès",usage_rerank:"Usage",usage_time:"Date et heure",v3_description:"<code>jina-embeddings-v3</code> est un modèle d'intégration de texte multilingue de pointe avec 570 M de paramètres et 8 192 tokens de longueur, surpassant les dernières intégrations propriétaires d'OpenAI et de Cohere sur MTEB. Lisez notre article de blog et notre article de recherche ci-dessous.",v3_title:"v3 : Incorporations multilingues Frontier",vector_database_integration1:"Intégrations",vector_database_integration2:"Notre API d'intégration est nativement intégrée à diverses bases de données renommées, magasins de vecteurs, frameworks RAG et LLMOps. Pour commencer, copiez et collez simplement votre clé API dans l'une des intégrations répertoriées pour un démarrage rapide et transparent.",vector_database_integration3:"Notre API Embedding & Reranker est nativement intégrée à diverses bases de données renommées, magasins de vecteurs, frameworks RAG et LLMOps. Pour commencer, copiez et collez simplement votre clé API dans l'une des intégrations répertoriées pour un démarrage rapide et transparent.",vector_database_integration_description:"Intégrez de manière transparente et facile l'API Jina Embeddings à l'une des bases de données vectorielles, des cadres d'orchestration LLM et des applications RAG ci-dessous. Nos tutoriels vous montreront comment.",view_details:"Voir les détails",visualization_example:"Mapper toutes les phrases de cette section sur un espace vectoriel 3D",visualization_example_you_can:"Utilisez notre API ci-dessous, vous pouvez le faire aussi !",visualize:"Visualiser",visualize_done:"La visualisation est terminée, vous pouvez maintenant cliquer sur le bouton du haut pour ouvrir le visualiseur.",wait_for_processing:"Votre demande est en cours de traitement.",wait_stripe:"Ouverture du paiement Stripe, veuillez patienter",what_are_embedding:"Que sont les intégrations ?",what_are_embedding_answer:`Imaginez que vous appreniez à un ordinateur à saisir le sens nuancé des mots et des expressions. Les méthodes traditionnelles, qui reposaient sur des systèmes rigides fondés sur des règles, ont échoué car le langage est trop complexe et fluide. Entrez les intégrations de texte : une solution puissante qui traduit le texte dans un langage de nombres, plus précisément en vecteurs dans un espace de grande dimension.

Considérez les expressions « temps ensoleillé » et « ciel dégagé ». Pour nous, ils dressent un tableau similaire. À travers le prisme des intégrations, ces phrases sont transformées en vecteurs numériques proches les uns des autres dans cet espace multidimensionnel, capturant leur parenté sémantique. Cette proximité dans l’espace vectoriel ne concerne pas seulement la similitude des mots ou des expressions ; il s'agit de comprendre le contexte, les sentiments et même les nuances subtiles du sens.

Pourquoi cette avancée est-elle importante ? Tout d’abord, il comble le fossé entre la richesse du langage humain et l’efficacité informatique des algorithmes. Les algorithmes excellent dans l’analyse des chiffres, pas dans l’interprétation des textes. En convertissant le texte en vecteurs, les intégrations permettent à ces algorithmes de « comprendre » et de traiter le langage d'une manière qui était auparavant hors de portée.

Les applications pratiques sont vastes et variées. Qu'il s'agisse de recommander un contenu qui correspond à vos intérêts, d'alimenter une IA conversationnelle qui semble étonnamment humaine ou même de détecter des modèles subtils dans de grands volumes de texte, les intégrations sont la clé. Ils permettent aux machines d’effectuer des tâches telles que l’analyse des sentiments, la traduction linguistique et bien plus encore, avec une compréhension du langage de plus en plus nuancée et raffinée.`,what_is_a_token:"Un jeton en traitement de texte est une unité, souvent un mot. Par exemple, « Jina AI est géniale ! » devient cinq jetons, y compris la ponctuation.",why_do_you_need:"Choisir les bonnes intégrations",why_do_you_need_after:"Tirant parti des réseaux neuronaux profonds et des LLM, nos modèles d'intégration représentent les données multimodales dans un format rationalisé, améliorant la compréhension des machines, le stockage efficace et permettant des applications d'IA avancées. Ces intégrations jouent un rôle crucial dans la compréhension des données, l'amélioration de l'engagement des utilisateurs, la suppression des barrières linguistiques et l'optimisation des processus de développement.",why_do_you_need_before:"Nos modèles d'intégration sont conçus pour couvrir diverses applications de recherche et GenAI.",why_need_1_description:"Notre modèle d'intégration de base, optimisé par JinaBERT, est conçu pour un large spectre d'applications. Il excelle dans la compréhension de textes détaillés, ce qui le rend idéal pour la recherche sémantique, la classification de contenu et l'analyse linguistique complexe. Sa polyvalence est inégalée, prenant en charge la création d'outils avancés d'analyse des sentiments, de résumés de texte et de systèmes de recommandation personnalisés.",why_need_1_title:"Intégrations à usage général",why_need_2_description:"Nos modèles bilingues facilitent la communication entre les langues, en améliorant les plateformes multilingues, le support client mondial et la découverte de contenu multilingue. Conçus pour maîtriser les traductions allemand-anglais et chinois-anglais, ces modèles simplifient les interactions et favorisent la compréhension entre divers groupes linguistiques.",why_need_2_title:"Intégrations bilingues",why_need_3_description:"Conçu sur mesure pour les développeurs, notre modèle d'intégration de code optimise les tâches de codage telles que la synthèse, la génération de code et les révisions automatiques. Il augmente la productivité en offrant des informations plus approfondies sur les structures du code et en suggérant des améliorations, ce qui le rend essentiel pour développer des plugins IDE avancés, une documentation automatique et des outils de débogage de pointe.",why_need_3_title:"Intégrations de code",why_need_4_description:"Jina CLIP est notre dernier modèle d'intégration multimodal pour l'image et le texte. Une grande amélioration par rapport à OpenAI CLIP est que ce modèle unique peut être utilisé pour les tâches de récupération texte-texte, ainsi que pour les tâches de récupération texte-image, image-texte et image-image ! Donc un modèle, deux modalités, quatre directions de recherche !",why_need_4_title:"Intégrations multimodales",write_email_here:"Veuillez saisir l'adresse e-mail à laquelle vous souhaitez recevoir le lien de téléchargement une fois terminé.",you_can_leave:"Vous pouvez quitter cette page et nous vous enverrons le lien de téléchargement une fois terminé."},x={description:"Intégrations multimodales et multilingues de classe mondiale."},z={answer1:"Jina AI est spécialisée dans les technologies d'IA multimodales, y compris le réglage de modèle, le service de modèle, le réglage rapide et le service rapide. Nous exploitons des outils avancés tels que Kubernetes et des architectures sans serveur pour créer des solutions robustes, évolutives et prêtes pour la production.",answer10:"Nous proposons différentes options de licence en fonction de la nature du projet et des besoins du client. Les conditions détaillées peuvent être discutées avec notre équipe de vente.",answer11:"Nous fournissons des services dans le monde entier, avec notre siège social basé à Berlin, en Europe, et des bureaux supplémentaires à Pékin et Shenzhen.",answer12:"Oui, nous proposons une assistance sur site, en particulier pour les clients situés à proximité de nos bureaux à Berlin, Pékin et Shenzhen. Pour les autres sites, nous nous efforçons de fournir la meilleure assistance à distance possible et pouvons organiser une assistance sur site si nécessaire.",answer2:"Notre expertise couvre un large spectre, englobant les grands modèles de langage, le texte, l'image, la vidéo, la compréhension audio, la recherche neuronale et l'art génératif.",answer3:"Oui, nos solutions sont conçues pour être évolutives et prêtes pour la production. Nous construisons nos solutions à l'aide de technologies cloud natives qui permettent une mise à l'échelle efficace et des performances fiables dans les environnements de production.",answer4:"Nos services sont polyvalents et adaptables, ce qui les rend adaptés à un large éventail de secteurs, notamment le commerce électronique, la technologie juridique, le marketing numérique, les jeux, la santé, la finance et bien d'autres.",answer5:"Vous pouvez entrer en contact avec notre équipe commerciale via le formulaire de contact sur cette page. Nous serions ravis de discuter des exigences de votre projet et de la manière dont nos solutions peuvent aider votre entreprise.",answer6:"Nous fournissons un support continu pour assurer le bon fonctionnement de nos solutions. Cela inclut le dépannage, les mises à jour régulières et les améliorations basées sur vos commentaires et vos besoins.",answer7:"La durée du projet varie en fonction de la complexité et de la portée du projet. Après avoir compris vos besoins, nous pouvons vous fournir une estimation plus précise.",answer8:"La sécurité des données est notre priorité absolue. Nous adhérons à des politiques et réglementations strictes en matière de protection des données pour garantir la sécurité et la confidentialité de vos données.",answer9:"Le prix dépend de la complexité et des exigences du projet. Nous offrons à la fois des modèles de tarification basés sur le projet et des honoraires. Veuillez contacter notre équipe de vente pour plus d'informations.",question1:"Dans quoi Jina AI est-elle spécialisée ?",question10:"Quelles sont les conditions de licence de vos solutions ?",question11:"Quelle est votre zone de service ?",question12:"Proposez-vous une assistance sur site ?",question2:"Avec quels types d'IA Jina AI travaille-t-elle ?",question3:"Vos solutions sont-elles évolutives et prêtes pour la production ?",question4:"Quelles industries peuvent bénéficier des solutions de Jina AI ?",question5:"Comment démarrer un projet avec Jina AI ?",question6:"Quel accompagnement apportez-vous après la mise en place d'une solution ?",question7:"Quelle est la durée type d'un projet ?",question8:"Comment Jina AI protège-t-elle mes données ?",question9:"Quelle est la structure tarifaire de vos services ?"},A="FAQ",I={text:"Adieu.",toggle_btn:"Gardez ce panneau ouvert lors de votre prochaine visite",warning_message:"Ce panneau s'ouvrira automatiquement lorsque vous visiterez jina.ai. Vous devrez le fermer pour voir le contenu du site Web. Activer ce paramètre ?",warning_title:"Afficher au démarrage"},y={description:"Affiner les intégrations sur des données spécifiques à un domaine pour une meilleure qualité de recherche",intro:"Votre entreprise. Vos données. Votre modèle"},P={description:"Renforcez votre entreprise avec des solutions de réglage fin sur site"},L={api_key:"Entrez votre clé API.",back:"Dos",base_model_selected:"Modèle de base sélectionné",click_start:"Acceptez les conditions et commencez les réglages.",confirm_title:"Confirmer le travail de réglage fin",confirm_your_email:"Saisissez à nouveau votre adresse e-mail pour confirmer le travail de réglage fin. Les mises à jour et le lien de téléchargement seront envoyés à cet e-mail.",consent0:"J'accepte que des données synthétiques pour le réglage fin du modèle soient générées sur la base de mes instructions.",consent1:"Je reconnais que le modèle final et les données synthétiques seront accessibles au public sur Hugging Face.",consent2:"Je comprends que cette fonctionnalité est en version bêta et Jina AI n'offre aucune garantie. Les prix et l'UX peuvent changer.",continue:"Continuer",cost_1m_token:"Chaque tâche de réglage fin consomme 1 million de jetons. Assurez-vous de disposer de suffisamment de jetons ou rechargez votre solde. Vous pouvez également générer une nouvelle clé API. Chaque clé API est livrée avec 1 million de jetons gratuits.",doc_explain:"Décrivez à quoi devrait ressembler un document correspondant.",domain_explain:"Fournissez une description détaillée de la manière dont les intégrations affinées seront utilisées. Ceci est essentiel pour générer des données synthétiques de haute qualité qui amélioreront les performances de vos intégrations.",domain_explain2:"Il existe trois manières de spécifier vos besoins : une instruction générale, une URL ou une description du document de requête. Choisissez-en un.",domain_hint:"Décrivez le domaine pour lequel vous souhaitez affiner votre recherche.",email_not_match:"Les adresses e-mail ne correspondent pas. Veuillez vérifier.",failed_job:"La demande de réglage fin a échoué. Voir la raison ci-dessous.",find_on_huggingface:"Trouver des résultats sur Hugging Face",general_instruction:"Ou, instruction générale",general_instruction_caption:"Fournissez une description détaillée de la manière dont les intégrations affinées seront utilisées.",general_instruction_explain:"Décrivez votre domaine sous forme de texte libre. Vous pouvez l'imaginer comme une « invite » comme dans ChatGPT.",how_it_works:"Découvrez le processus de réglage fin.",job_acknowledged:"Votre travail de réglage fin a été mis en file d'attente. Vous recevrez un e-mail lorsque le travail commencera. Le processus complet prend souvent 20 minutes.",new_key:"Obtenir une nouvelle clé",not_enough_token:"Pas assez de jetons dans cette clé API. Veuillez recharger votre solde ou utiliser une autre clé API.",placeholder:"Réclamations d'assurance automobile",preview:"Aperçu",query_doc:"Description du document de requête",query_doc_caption:"Décrivez à quoi ressemble la requête et à quoi ressemble le document correspondant dans votre domaine.",query_explain:"Décrivez à quoi ressemble une requête.",reset:"Recommencer",select_base_model:"Choisissez un modèle d'intégration de base pour un réglage précis.",select_base_model_explain:"Sélectionnez un modèle de base comme point de départ pour le réglage fin. En règle générale, base-en est un bon choix, mais pour les tâches dans d'autres langues, envisagez d'utiliser un modèle bilingue.",start_tuning:"Commencer le réglage fin",url:"Ou l'URL de la page Web",url_caption:"Reportez-vous au contenu d'une URL pour un réglage précis.",url_explain:"URL publique d'une page Web contenant le contenu que vous souhaitez affiner.",use_url:"Utilisez plutôt l'URL. L'activer signifie que nous nous baserons sur le contenu de la page de cette URL pour générer des données synthétiques à des fins de réglage.",wait_for_processing:"Veuillez patienter pendant que nous accédons à votre requête...",which_domain:"Domaine de réglage fin",write_email_explain:"La mise au point prend du temps. Nous communiquerons par e-mail sur le début, la progression, l'achèvement et tout problème lié à votre travail de mise au point, ainsi que des détails sur le modèle affiné et l'ensemble de données de formation."},j={address_beijing:"Pékin, Chine",address_berlin:"Berlin, Allemagne (siège social)",address_shenzhen:"Shenzhen, en Chine",address_sunnyvale:"Sunnyvale, Californie",all_rights_reserved:"Tous les droits sont réservés.",company:"Entreprise",developers:"Développeurs",docs:"Documents",enterprise:"Entreprise",get_api_key:"Obtenir la clé API Jina AI",offices:"Des bureaux",power_users:"Utilisateurs avancés",privacy:"Confidentialité",privacy_policy:"politique de confidentialité",privacy_settings:"Gérer les cookies",security:"Sécurité",sefo:"Fondation Recherche",soc2:"Nous sommes conformes à la norme SOC 2 Type 1 de l'American Institute of Certified Public Accountants (AICPA).",status:"Statut de l'API",status_short:"Statut",tc:"termes et conditions",tc1:"Termes"},k="Obtenez votre clé API",C={stars:"Étoiles"},w={about_us:"À propos de nous",company:"Entreprise",contact_us:"Contacter le service commercial",developers_others:"Plus d'outils de développement",enterprise_others:"Plus d'outils d'entreprise",for_developers:"Pour les développeurs",for_developers_description:"Découvrez une pile d'IA multimodale open source complète conçue pour les développeurs.",for_enterprise:"Pour les entreprises",for_enterprise_description:"Découvrez des stratégies d'IA multimodales évolutives adaptées aux besoins de l'entreprise.",for_power_users:"Pour les utilisateurs expérimentés",for_power_users_description:"Utilisez nos outils multimodaux simplifiés pour améliorer votre productivité.",internship1:"Programme de stage",jobs:"Rejoignez-nous",join_discord:"Rejoignez notre communauté Discord",logos:"Télécharger le logo",maximize:"⇧1",maximize_btn:"Maximiser",news:"Nouvelles",open_day:"Journée portes ouvertes",open_in_full:"Afficher tous les produits d'entreprise dans une nouvelle fenêtre",power_users_others:"Plus d'outils pour les utilisateurs expérimentés",products:"Des produits"},R={description:"Partagez et découvrez les éléments de base des applications d'IA multimodales"},S={sentence_similarity:"Incorporation de phrases",updated_about:"Mise à jour sur"},N={project1:"Activation de la recherche de haute précision dans les données de maillage 3D à l'aide d'informations de nuage de points.",project10:"Exploitation de la vision par ordinateur pour améliorer l'accessibilité numérique des sites Web du gouvernement.",project11:"Perfectionnement du LLM pour une société de conseil afin d'optimiser l'analyse des données financières.",project12:"Stratégies marketing avancées en affinant les modèles texte-image pour le transfert de style.",project2:"Conception d'un moteur de recherche basé sur le contenu pour les courts métrages d'animation.",project3:"Amélioration des taux de conversion du commerce électronique en affinant les modèles d'intégration.",project4:"Exécution d'un réglage rapide pour accroître l'efficacité d'une société de conseil aux entreprises.",project5:"Compréhension de la scène de jeu et annotation automatique pionnière pour une entreprise de jeu de premier plan.",project6:"Mise en œuvre de l'extension des entrées en temps réel pour une entreprise de chatbot, améliorant l'expérience utilisateur.",project7:"Technologie juridique révolutionnée en permettant une recherche efficace dans de longs documents juridiques.",project8:"Prise en charge d'un service d'art génératif à haut débit pour les opérations à grande échelle.",project9:"Réaliser l'exploration de processus et la modélisation à l'aide de modèles de langage avancés."},M={description:"Modèles multimodaux de pointe disponibles pour l'inférence"},D={copy_full_prompt:"Copier l'invite complète",embedding:"Intégrations",how_to_use_meta_prompt:"Comment utiliser",meta_prompt:"Utiliser la méta-invite pour la génération de code",meta_prompt_description:"Le méta-invite guide les LLM (comme ChatGPT et Claude) à travers toutes nos API Search Foundation, rendant la génération de code plus facile et de meilleure qualité.",reranker:"Reclasseur",which_to_go:"Lequel intégrer avec {_vendor} ?"},E={answer1:"Premier cycle, maîtrise et doctorat. les étudiants du monde entier, intéressés par des domaines tels que la recherche, l'ingénierie, le marketing et les ventes, sont encouragés à postuler. Nous accueillons également des stages non techniques dans les domaines du marketing, des ventes, de l'assistance à la direction, etc. Nous recherchons des personnes passionnées prêtes à devenir les pionnières de l'IA multimodale avec nous.",answer10:"Oui, notre programme de stage offre une rémunération compétitive.",answer11:"En tant que stagiaire Jina AI, vous obtiendrez une expérience pratique de travail sur des projets stimulants, apprendrez des experts de l'industrie, ferez partie d'une communauté dynamique et aurez l'opportunité d'apporter de réelles contributions à notre travail de pionnier dans l'IA multimodale.",answer2:"Les stages doivent être effectués sur place dans l'un de nos bureaux, situés à Berlin, Pékin et Shenzhen.",answer3:"Oui, Jina AI offre une assistance raisonnable dans le processus de visa pour les candidats retenus.",answer4:"Oui, Jina AI fournit une couverture raisonnable du coût de la vie aux stagiaires pendant la période de stage.",answer5:"Oui, il est possible de travailler sur votre mémoire de maîtrise pendant votre stage à Jina AI, généralement applicable aux étudiants des universités allemandes. Cependant, vous devez avoir une communication préalable et l'accord du superviseur de votre université. Notez que nous n'aidons pas les étudiants à trouver des conseillers.",answer6:"Le processus de candidature comprend la soumission de votre formulaire de candidature, un CV, une lettre de motivation exprimant votre intérêt et votre motivation, ainsi que tout lien professionnel pertinent tel que GitHub ou LinkedIn. Nous évaluons les candidats en fonction de leur performance lors de l'entretien et de leur performance dans leur université.",answer7:"Oui, les stagiaires retenus peuvent recevoir une lettre de recommandation à la fin de leur stage, signée par notre PDG.",answer8:"La durée du stage varie en fonction de la fonction et du projet. Cependant, il varie généralement de trois à six mois.",answer9:"Oui, nous accueillons les candidatures de tous les horizons académiques. Nous apprécions votre passion et votre engagement à apprendre autant que votre expérience antérieure.",question1:"Qui peut postuler au programme de stage Jina AI ?",question10:"Est-ce un stage rémunéré ?",question11:"Quelles opportunités aurai-je en tant que stagiaire Jina AI ?",question2:"Où se déroulera le stage ?",question3:"Jina AI assiste-t-elle dans les processus de visa ?",question4:"Jina AI offre-t-elle des indemnités ou des avantages aux stagiaires ?",question5:"Puis-je travailler sur mon mémoire de Master pendant le stage à Jina AI ?",question6:"En quoi consiste le processus de candidature ?",question7:"Jina AI fournit-elle une lettre de recommandation post-stage ?",question8:"Quelle est la durée du stage ?",question9:"Puis-je postuler si je n'ai pas d'expérience préalable en IA ?"},U={about_internship_program:"À propos du programme de stages",about_internship_program_desc1:"Nous sommes ravis d'offrir cette opportunité unique à des personnes talentueuses de se joindre à notre équipe dynamique et de contribuer à des projets novateurs dans le domaine de l'intelligence artificielle. Ce stage est conçu pour vous fournir une expérience pratique précieuse, un mentorat et une exposition aux technologies de pointe qui façonnent l'avenir de l'IA.",about_internship_program_desc2:"Chez Jina AI, nous comprenons l'importance de nourrir et d'exploiter les jeunes talents. Nous reconnaissons que les stagiaires apportent de nouvelles perspectives, de l'enthousiasme et de la créativité à la table, revigorant notre équipe avec de nouvelles idées et approches. En offrant des stages, nous visons à favoriser la croissance des futurs leaders de l'industrie de l'IA tout en leur offrant une expérience du monde réel dans un environnement favorable et stimulant.",alumni:"ANCIENS",alumni_network:"Notre réseau dynamique d'anciens élèves",application:"Application",application_desc:"Embarquez pour un voyage transformateur avec Jina AI. Notre programme de stages complet invite tous les esprits passionnés qui aspirent à façonner l'avenir de l'intelligence artificielle. Rejoignez-nous pour acquérir une expérience du monde réel, travailler sur des projets stimulants et collaborer avec certains des esprits les plus brillants de l'industrie de l'IA.",apply:"Appliquer maintenant",autumn:"Automne",description:"Appel mondial à étudiants : Stage en recherche, ingénierie, marketing, vente et plus encore.",dev_rel_intern:"Stagiaire Relations Développeurs",enthusiastic:"ENTHOUSIASTE",explore_stories_from_our_interns:"Découvrez les histoires de nos stagiaires",explore_stories_from_our_interns1:"Laissez-vous inspirer par les parcours de nos stagiaires",innovative:"INNOVANT",intern_work1:"Modèles LLM affinés pour de meilleures incorporations",intern_work2:"Exploration du potentiel de Retrieval Augmented Generation",intern_work3:"Publication d'un article sur le thème des incorporations de phrases",intern_work4:"Injecter une vitalité juvénile continue dans l’équipe",intern_work5:"Techniques de quantification éprouvées pour compresser LLM",intern_work6:"Créer et promouvoir une campagne convaincante pour PromptPerfect",intern_work7:"JinaColBERT V2 rapidement développé et amélioré",recruiting_and_administrative_intern:"Stagiaire en recrutement et en administration",researcher_intern:"Chercheur stagiaire",self_motivated:"AUTO-MOTIVÉ",software_engineer_intern:"Stagiaire ingénieur logiciel",spring:"Printemps",submit_application:"Lancez votre aventure avec Jina AI",subtitle:"Notre programme de stages à temps plein offre une expérience de travail pratique grâce à des projets de stages bien conçus dans un large éventail de domaines.",subtitle1:"Appel mondial aux étudiants : stagiaires en recherche, ingénierie, marketing, ventes et plus encore pour lancer ensemble l'IA multimodale.",summer:"Été",title:"Programme de stage",who_do_we_look_for:"Qui cherchons-nous ?",who_do_we_look_for_desc:"Nous valorisons la diversité et encourageons les candidats de profils et d'horizons divers à rejoindre notre programme de stages. Les opportunités de stage sont proposées dans plusieurs départements, notamment l'ingénierie, la conception, la gestion des produits, les ventes et la gestion des comptes, le marketing et la gestion de la communauté.",winter:"Hiver"},T={description:"Déployez un projet local en tant que service cloud. Radicalement facile, pas de mauvaises surprises."},O={description:"Un fintuner expérimental pour les LLM open-source"},J={description:"Créez des applications d'IA multimodales sur le cloud"},V={description:"Plus de modalité, plus de mémoire, moins de coût",example_1:"Qui es-tu?",example_2:"Je suis un service de chat LLM créé par Jina AI"},G={add:"Ajouter une clé",add_key_explain:"Ajoutez une autre clé API à votre compte. Les clés ajoutées peuvent être gérées, rechargées ou supprimées à tout moment.",auto_recharge_title:"Activer la recharge automatique ?",available_resources:"Jetons disponibles",balance:"Jetons disponibles",balance_primary_key:"Solde de la clé primaire",cancel:"Annuler",copy:"Copier la clé",description:"Gérez les clés API pour tous les services Jina AI : Embeddings, Reader, Reranker, etc.",do_it_later:"Fais-le plus tard",email:"E-mail",existing_key:"Clé existante",filter_by:"Filtrer par clé",free_key:"Clé gratuite",generate_new_key:"Générer une nouvelle clé",generate_new_key_tooltip:"Générez une nouvelle clé API avec un solde vide. Vous pourrez recharger le solde plus tard.",invalid_key:"Clé invalide",is_primary:"Votre clé API principale. Vous pouvez la modifier après vous être connecté.",last_used:"Dernière utilisation",last_used_at:"Dernière activité",login:"Se connecter",login_explain:"Gérez plusieurs clés API et suivez leur utilisation, le tout dans un seul compte.",login_explain_long:"Connectez-vous pour stocker et gérer en toute sécurité vos clés API. Suivez l'historique d'utilisation, gérez plusieurs clés et ne perdez jamais l'accès à vos informations d'identification.",login_via:"connecté via {_provider}",logout:"Se déconnecter",logout_message:"Vos clés API restent stockées en toute sécurité dans votre compte. Connectez-vous à tout moment pour les gérer.",logout_success:"Déconnexion réussie",ok:"D'ACCORD",primary_key:"Définir comme clé primaire",primary_key_set:"Définissez avec succès {_apiKey} comme clé primaire.",primary_key_set_caption:"Cette clé sera utilisée dans toutes les démos, exemples et terrains de jeux sur jina.ai.",purchase:"Acheter des jetons",remove:"Retirer la clé",remove_message:"Etes-vous sûr de vouloir supprimer cette clé ? La clé restera valide et pourra être ajoutée à nouveau ultérieurement.",remove_primary_key:"Veuillez définir une autre clé comme clé primaire avant de supprimer la clé primaire actuelle.",remove_title:"Retirer la clé",revoke:"Révoquer la clé",revoke__message:"Etes-vous sûr de vouloir révoquer cette clé ? Une fois révoquée, cette clé deviendra définitivement invalide.",subscribed_key:"Clé Premium",title:"API de la fondation Jina Search",to_dashboard:"Gérer les clés",total_keys:"Clés totales",usage_history:"Historique d'utilisation",usage_summary:"7 derniers jours : {_usage} jetons"},B={GlobalQA:{description:"Appuyez sur la touche « / » sur n'importe quelle page pour ouvrir la boîte de questions. Tapez votre requête et appuyez sur « Entrée » pour recevoir des réponses directement liées au contenu de la page. Cette fonctionnalité est optimisée par PromptPerfect.",title:"RAG sur la page"},Recommender:{description:"Ouvrez la boîte de recommandation sur n'importe quelle page d'actualités avec « Maj+2 ». Sélectionnez le modèle de reclassement pour découvrir les 5 meilleurs articles liés à cette page d'actualités. Profitez de cette fonctionnalité en temps réel, optimisée par notre API Reranker.",title:"Article associé"},SceneXplainTooltip:{description:"Passez votre curseur sur n'importe quelle image sur les pages d'actualités ou dans notre catalogue de rédaction pour révéler la description de cette image. Les descriptions sont précalculées par SceneXplain et intégrées dans l'attribut ALT de l'image pour plus d'accessibilité.",title:"Sous-titrage des images"},explain:"Découvrez les fonctionnalités cachées sur notre site Web"},F={also_available_on:"Également disponible sur les places de marché",also_available_on1:"Disponible sur les places de marché de votre cloud d'entreprise",ask_how_your_question:"Merci de décrire votre problème",autotune:"Réglage automatique",badge:{"clip-v2":"sortie du clip-v2 !",v2:"Sortie v2 !",v3:"Version v3 !"},build_js:"Construire avec JavaScript",build_python:"Construire avec Python",ccbync:"Ce modèle est sous licence CC BY-NC 4.0. Utilisez-le via l'API ou notre image officielle AWS/Azure ; ou contactez le service commercial pour un déploiement sur site.",checkout_our_solution_for_you:"Découvrez notre solution sur mesure pour vous",classifier:"Classificateur",coming_soon:"À venir",contact_sales:"Contact",copied_to_clipboard:"Copié dans le presse-papier",copy:"Copie",developers:"Développeurs",developers_desc:"Libérez toute la puissance de l'IA multimodale avec des technologies cloud natives de pointe et une infrastructure open source.",download_pdf:"Télécharger le PDF",embedding:"Incorporations",embedding_desc1:"Incorporations multimodales multilingues à contexte long les plus performantes pour les applications de recherche, RAG et agents.",embedding_paper_desc:"Jina Embeddings constitue un ensemble de modèles d'incorporation de phrases hautes performances aptes à traduire diverses entrées textuelles en représentations numériques, capturant ainsi l'essence sémantique du texte. Bien que ces modèles ne soient pas exclusivement conçus pour la génération de texte, ils excellent dans des applications telles que la récupération dense et la similarité textuelle sémantique. Cet article détaille le développement de Jina Embeddings, en commençant par la création d'un ensemble de données par paires et triplets de haute qualité. Il souligne le rôle crucial du nettoyage des données dans la préparation des ensembles de données, donne un aperçu approfondi du processus de formation du modèle et se termine par une évaluation complète des performances à l'aide du Massive Textual Embedding Benchmark (MTEB).",embedding_paper_title:"Jina Embeddings : un nouvel ensemble de modèles d'intégration de phrases hautes performances",embeddings:"Intégrations",enterprise:"Entreprise",enterprise_desc:"Boostez votre activité avec des solutions d'IA multimodales évolutives, sécurisées et sur mesure.",enterprise_desc_v2:"Essayez nos modèles d'intégration de classe mondiale pour améliorer vos systèmes de recherche et RAG. Commencez par un essai gratuit !",enterprise_desc_v3:"Nos modèles de frontière constituent la base de recherche pour les systèmes de recherche d'entreprise et RAG de haute qualité.",error:"Il y a eu un problème avec l'opération de récupération : {message}",find_your_portal:"Trouvez votre portail",finding_faq:"Générer une réponse basée sur les connaissances de la FAQ ci-dessous",for:"Pour",for_developers:"Pour les développeurs",for_enterprise:"Pour les entreprises",for_power_users:"Pour les utilisateurs expérimentés",get_api_now:"API",get_started:"Commencer",go_to_product_homepage:"Accéder à la page d'accueil du produit",how_to:"Comment",include_experiment:"Inclut nos projets expérimentaux et archivés dans la solution.",join_community:"Communauté",key_manager:"Gérer la clé API",learn_more_embeddings:"En savoir plus sur les intégrations",learn_more_reader:"En savoir plus sur le lecteur",learn_more_reranker:"En savoir plus sur le reclassement",llm:"Modèles d'intégration LLM",llm_desc:"Nous fournissons une collection de modèles d'intégration de phrases hautes performances, comprenant entre 35 millions et 6 milliards de paramètres. Ils sont excellents pour améliorer la recherche neuronale, le reclassement, la similarité des phrases, les recommandations, etc. Préparez-vous à améliorer votre expérience d'IA !",mentioned_products:"Produits mentionnés :",mmstack:"Pile multimodale",mmstack_desc:"Au fil des années, nous avons développé une variété de logiciels open source pour aider les développeurs à créer une meilleure GenAI et à rechercher des applications plus rapidement.",models:"Modèles",more:"Plus",multimodal:"Multimodal",multimodal_ai:"IA multimodale",new:"Nouveau",newsroom:"Rédaction",num_publications:"{_total} publications au total.","on-prem-deploy":"Déploiement sur site","on-premises":"Sur site",opensource:"Open source",our_customer:"Nos clients",our_customer_explain:"Les entreprises de toutes tailles font confiance à la Search Foundation de Jina AI pour alimenter leurs outils et produits. Vous pouvez également le faire.",our_publications:"Nos publications",parameters:"Paramètres",podcast:"Podcast",power_users:"Utilisateurs avancés",power_users_desc:"Ingénierie automatique pour votre productivité quotidienne.",powered_by_promptperfect:'Propulsé par la fonctionnalité "Optimisation des invites" et "Invite en tant que service" de PromptPerfect',pricing:"Tarifs",proposing_solution:"Proposer une solution basée sur les produits Jina AI...",read_more:"En savoir plus",reader:"Lecteur",require_full_question:"Veuillez décrire votre problème avec plus de détails.",reranker:"Reclasseur",researcher_desc:"Découvrez comment nos modèles de recherche de frontière ont été formés à partir de zéro, consultez nos dernières publications. Rencontrez notre équipe chez EMNLP, SIGIR, ICLR, NeurIPS et ICML !",researchers:"Des chercheurs",sdk:"SDK",sdk_desc:"Vous souhaitez créer des applications AIGC de haut niveau à l'aide des API PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale ? Nous avons ce qu'il vous faut! Essayez notre SDK facile à utiliser et démarrez en quelques minutes.",sdk_docs:"Lire des documents",sdk_example:"Exemple",search_foundation:"Fondation de recherche",source_code:"Code source",starter_kit:"Kit de démarrage",supercharged1:"Suralimenté.",tokenizer:"Segmenteur",trusted_by:"CONFIÉ PAR",try_it_for_free:"Commencez instantanément — aucune carte de crédit ni inscription requise !",try_our_saas:"Essayez notre solution hébergée, un remplacement immédiat de l'API d'intégration d'OpenAI.",your_portal_to:"Votre portail vers",your_search_foundation1:"Votre fondation de recherche"},Q={description:"Applications Langchain en production avec Jina & FastAPI"},W={description:"Informations juridiques, conditions de service, politique de confidentialité et autres documents importants sur les produits et services de Jina AI.",title:"Informations légales"},H={api:"API de Jina AI",contact_sales_about_it:"Contactez le service commercial à ce sujet",deploy_it_on:"Déployez-le sur",description:"Au fil des années, nous avons continué à repousser les limites de la recherche. Vous trouverez ci-dessous les modèles que nous avons publiés. Passez la souris sur chacun d'eux ou cliquez dessus pour voir plus de détails.",find_on_hf:"Trouvez-le sur HuggingFace",search_for:"Recherchez-le sur notre site",search_models:"Filtrer par nom de modèle",title:"Nos modèles de recherche de fondations",use_it_via:"Utilisez-le via"},K={back_to_newsroom:"Retour à la salle de presse",categories:"Catégories",copy_link:"Copiez le lien vers cette section",in_this_article:"Dans cet article",learn_more:"Apprendre encore plus",news_not_found:"Article non trouvé",redirect_to_news:"Redirection vers la rédaction dans 5 secondes..."},X={academic:"Académique",academic_research:"Publications académiques",author:"Filtrer par auteur",description:"Lisez les dernières nouvelles et mises à jour de Jina AI.",description1:"Créer des innovations en matière d'IA, un mot à la fois.",engineering_group:"Groupe d'ingénierie",engineering_group_date:"31 mai 2021",minutes_read:"minutes lues",most_recent_articles:"Articles les plus récents",news_description:"Pour Jina 2.0, nous avons écouté la communauté. Vraiment, profondément écouté. « Quels sont vos points douloureux ? » nous avons demandé, anticipant avec impatience des commentaires précieux",news_title:"Search All the Things : nous organisons un concours MEME pour Jina 2.0",photos:"Photos",product:"Filtrer par produit",search:"Rechercher par titre",tech_blog:"Blog technique",title:"Rédaction",top_stories:"Meilleures histoires"},Y=`🎉 Notre premier livre, "Neural Search — From Prototype to Production with Jina" est officiellement sorti aujourd'hui !`,Z={description:"Une occasion exclusive d'avoir une vue d'initié sur Jina AI.",engage:"Nous encourageons fortement un dialogue interactif tout au long de la journée. L'échange de pensées et de perspectives est inestimable pour nous. Les collaborations potentielles issues de ces discussions pourraient contribuer de manière significative à un avenir plus intégré et innovant.",engage_title:"Engagez-vous avec nous",experience:"Nous avons organisé une visite immersive de trois heures pour nos invités, disponible en allemand, anglais, français, espagnol, chinois et russe. La visite couvre un examen approfondi de nos avancées en matière d'IA multimodale, notre point de vue sur le paysage de l'IA, suivi d'un examen détaillé de projets spécifiques. Nous terminerons par une discussion de groupe pour faciliter l'échange d'idées et de points de vue. Une option déjeuner est également disponible sur demande.",experience_title:"Le voyage d'un initié",group_size:"Estimation du nombre de visiteurs",impact:"Comprenez comment nos contributions à la communauté open-source et notre travail dans la technologie d'IA multimodale font de Jina AI un acteur influent de l'innovation en IA. Nous visons à jouer un rôle important dans les processus décisionnels, en veillant à ce que les progrès de la technologie de l'IA profitent à tous.",impact_title:"Incidence et influence",introduction:"Jina AI est ravie d'ouvrir ses portes à des entités et des organisations estimées intéressées par les progrès et l'avenir de l'intelligence artificielle. Nous offrons cette opportunité exclusive aux acteurs politiques, aux ONG, aux OBNL et aux secteurs de l'investissement d'avoir une vue d'initié de nos opérations et de nos visions ici à notre siège de Berlin.",motivation_min_length_v1:"Veuillez fournir une motivation plus détaillée.",motivation_placeholder_v2:"Partager vos motivations nous aidera à améliorer votre expérience.",motivation_to_attend_v2:"Pourquoi êtes-vous intéressé par notre journée portes ouvertes ?",one_hour:"1 heure",organization:"Organisation",organization_website:"Site Web de l'organisation",organization_website_placeholder:"URL de la page d'accueil ou du profil LinkedIn de votre organisation",preferred_date:"Date de préférence",preferred_language:"Langue préférée de la visite",preferred_products:"Quels produits vous intéressent ?",subtitle:"Un aperçu de l'avenir de l'IA multimodale",title:"Journée portes ouvertes",tutor_subtitle:"Une visite de trois heures méticuleusement organisée, vous rapprochant du cœur du travail révolutionnaire de Jina AI dans la technologie d'IA multimodale.",tutor_title:"Une plongée profonde exclusive dans",vision:"Rejoignez-nous pour un aperçu complet du paysage de l'IA tel que nous le voyons. Notre discussion se concentrera sur le potentiel des grands modèles de langage, de l'IA multimodale et de l'impact de la technologie open source pour façonner l'avenir de l'innovation mondiale.",vision_title:"Notre vision pour l'avenir"},$={answer1:"Nous proposons des visites en allemand, anglais, français, espagnol, chinois et russe.",answer2:"La visite dure généralement environ trois heures.",answer3:"Le déjeuner est facultatif et peut être organisé sur demande.",answer4:"Notre journée portes ouvertes est principalement conçue pour les groupes professionnels, tels que les politiciens, les ONG, les OBNL et les investisseurs. Cependant, nous faisons parfois des exceptions en fonction du profil de l'individu.",answer5:"Nous pouvons accueillir une variété de tailles de groupe. Veuillez indiquer la taille de votre groupe dans le formulaire d'inscription, et nous confirmerons les détails avec vous.",answer6:"Il y a une section dans le formulaire d'inscription où vous pouvez spécifier vos domaines d'intérêt ou toute demande spéciale. Nous ferons de notre mieux pour adapter la visite en fonction de vos besoins.",answer7:"Pour le moment, nous proposons uniquement des visites à notre siège social de Berlin situé à Kreuzberg. Nos bureaux de Pékin et de Shenzhen ne sont actuellement pas ouverts aux visites.",question1:"Quelles langues proposez-vous pour la visite ?",question2:"Quelle est la durée de la tournée ?",question3:"Le déjeuner est-il fourni ?",question4:"Les particuliers peuvent-ils s'inscrire à la journée portes ouvertes ?",question5:"De combien de personnes un groupe peut-il être composé pour la journée portes ouvertes ?",question6:"Comment puis-je spécifier les zones d'intérêt pour la visite ?",question7:"Des visites sont-elles disponibles dans vos bureaux de Pékin ou de Shenzhen ?"},ee={description:"Un cloud open source de grands modèles multimodaux servant de framework"},se={commercial_licence:{chip_label:"Exclusif pour les petites entreprises",company_size_note:"Exclusif aux entreprises de moins de 100 employés et de moins de 5 millions de dollars de chiffre d'affaires",cta_button:"Commencer",download_title:"Télécharger la licence commerciale",feature_api_desc:"Tester avant achat",feature_api_title:"Accès gratuit aux tests API",feature_consulting:"Séance de conseil trimestrielle de 2 heures avec nos experts modèles",feature_consulting_desc:"Trois (3) heures de services de consultation technique par période de licence.",feature_future_support:"Accès aux futurs modèles CC BY-NC sans autorisation",feature_future_support_desc:"Tout nouveau modèle publié par le Concédant sous CC-BY-NC-4.0 pendant la période de licence.",feature_models:"Utilisation commerciale illimitée de nos modèles CC BY-NC",feature_models_desc:"Utiliser les modèles à des fins commerciales, y compris pour une utilisation interne ou une intégration dans des applications destinées aux clients.",price_amount:"1 000 $",price_period:"/ quart",read_the_terms:"Examen des conditions de licence",read_the_terms_btn:"Termes",read_the_terms_desc:"Examinez les droits et les limitations de la licence commerciale avant l'achat",subtitle:"Tous les modèles dont vous avez besoin pour une meilleure recherche",test_before_purchase:"Essayez avant d'acheter",test_before_purchase_desc:"Obtenez 1 million de jetons API gratuits ou utilisez notre modèle Hugging Face pour valider les performances",title:"Licence commerciale",try_api:"Essayez d'abord l'API"},free_hour_consult:"Consultation gratuite d'une heure",free_hour_consult_description:"Une heure de consultation gratuite avec nos équipes produit et ingénierie pour discuter des meilleures pratiques pour votre cas d'utilisation",full_commercial:"Utilisation commerciale sans restriction",full_commercial_description:"Vous pouvez utiliser l'API à des fins commerciales sans aucune restriction.",higher_limit:"Limite de taux beaucoup plus élevée",higher_limit_description:"Obtenez jusqu'à 1000 RPM pour r.jina.ai et 100 RPM pour s.jina.ai ; plus de détails dans la section limite de débit.",key_manager:"Gestion des clés API",key_manager_description:"Gérez plusieurs clés API dans un seul compte, suivez l'historique d'utilisation et rechargez les jetons.",no_commercial:"Utilisation non commerciale uniquement (CC-BY-NC)",no_commercial_description:"Vous ne pouvez utiliser l'API qu'à des fins non commerciales. Pour une utilisation commerciale, veuillez recharger votre clé API.",on_prem:"Avec une licence commerciale pour un déploiement sur site",on_prem_explain:"Achetez une licence commerciale pour utiliser nos modèles sur site.",priority_support:"Assistance technique prioritaire",priority_support_description:"Réponse par e-mail garantie sur les problèmes et incidents techniques dans les 24 heures.",secured_by_stripe:"Paiement sécurisé via Stripe",via_api:"Avec l'API Jina Search Foundation",via_api_explain:"Le moyen le plus simple d'accéder à tous nos produits. Rechargez vos jetons au fur et à mesure."},te="Alimenté par",ne="Imprimer",ie={archived:"Archivé",cloud_native:"Nuage natif",core:"Cœur",data_structure:"Structure de données",embedding_serving:"Intégration du service",embedding_tuning:"Intégration du réglage",graduated:"Diplômé",incubating:"Incubation",kubernetes:"Kubernetes",large_size_model:"Modèle grande taille",linux_foundation:"Fondation Linux",llm1:"LLMOps",mid_size_model:"Modèle de taille moyenne",model_serving:"Modèle de service",model_tuning:"Réglage du modèle",observability:"Observabilité",orchestration:"Orchestration",prompt_serving:"Service rapide",prompt_tuning:"Réglage rapide",rag1:"CHIFFON",sandbox:"bac à sable",small_size_model:"Modèle de petite taille",vector_database:"Base de données vectorielle",vector_store:"Magasin de vecteurs"},re={description:"Premier outil pour une ingénierie rapide",image_model:"Modèles d'images",intro:"Premier outil pour une ingénierie rapide",intro1:"Le premier outil pour une ingénierie rapide",optimized:"Votre tâche est d'être mon partenaire de brainstorming et de fournir des idées créatives et des suggestions pour un sujet ou un problème donné. Votre réponse doit inclure des idées originales, uniques et pertinentes qui pourraient aider à résoudre le problème ou à approfondir le sujet de manière intéressante. Veuillez noter que votre réponse doit également tenir compte des exigences ou contraintes spécifiques de la tâche.",optimized_title:"Invite optimisée",original:"Votre rôle est d'être mon partenaire de brainstorming.",original_title:"Invite d'origine",text_model:"Modèles de texte"},oe={features:[{description:"Basculez facilement entre la génération de contenu et l'optimisation rapide, faites passer la qualité de votre contenu au niveau supérieur.",name:"Assistant",title:"Dose quotidienne de productivité."},{description:"Vous ne savez pas comment rédiger une instruction efficace ? Mettez simplement votre idée, en un clic, obtenez une meilleure instruction.",name:"Optimisation rapide",title:"De meilleurs intrants, de meilleurs résultats"},{description:"Comprenez l'ambiance de chaque modèle d'IA en comparant leur sortie de la même invite.",name:"Comparez les modèles",title:"Comparaison des modèles côte à côte."},{description:"Peut-être le moyen le plus simple de déployer vos invites en tant qu'API pour l'intégration.",name:"Déployer des invites",title:"Pas d'opérations, déployez simplement."},{description:"Personnalisez vos propres agents LLM et démarrez une simulation multi-agents. Découvrez comment ils collaborent ou s'affrontent dans un environnement virtuel pour atteindre l'objectif.",name:"Multi-agent",title:"Découvrez comment les agents collaborent"}],get_started:"Commencez avec PromptPerfect"},ae={api_key:"Clé API rechargée",success:"Merci pour votre achat!",success_caption:"Nous avons finalisé votre commande à {_purchasedTime}. Votre clé API est prête à être utilisée !"},le="Achetez maintenant",ue={batch_explain:"Cette API prend en charge les opérations par lots, autorisant jusqu'à 512 documents par requête, chaque document contenant jusqu'à 8192 jetons. L'exploitation intelligente des opérations par lots peut réduire considérablement le nombre de requêtes et améliorer les performances.",classifier:"Entraîner un classificateur à l'aide d'exemples étiquetés",classifier_few_shot:"Classer les entrées à l'aide d'un classificateur à quelques coups entraîné",classifier_few_shot_token_counting:"Jetons comptés comme : input_tokens",classifier_latency:"Le temps de réponse varie en fonction de la taille de l'entrée",classifier_token_counting:"Les jetons sont comptés comme suit : input_tokens × num_iters",classifier_zero_shot:"Classer les entrées à l'aide de la classification à coup zéro",classifier_zero_shot_token_counting:"Jetons comptés comme : input_tokens + label_tokens",depends:"dépend de la taille de l'entrée",description:"Description",embeddings:"Convertir du texte/des images en vecteurs de longueur fixe",endpoint:"Point de terminaison de l'API",explain:"Les limites de débit sont suivies de deux manières : <b>RPM</b> (requêtes par minute) et <b>TPM</b> (jetons par minute). Les limites sont appliquées par IP et peuvent être atteintes en fonction du seuil (RPM ou TPM) atteint en premier.",gjinaai:"Fonder une déclaration sur des connaissances Web",input_token_counting:"Comptez le nombre de jetons dans la demande d'entrée.",latency:"Latence moyenne",no_token_counting:"Le jeton n'est pas comptabilisé comme une utilisation.",output_token_counting:"Comptez le nombre de jetons dans la réponse de sortie.",premium_rate:"Avec un potentiel de limites de taux plus élevées",product:"Produit",requestType:"Demande autorisée",reranker:"Classer les documents par requête",rjinaai:"Convertir l'URL en texte compatible LLM",sjinaai:"Recherchez sur le Web et convertissez les résultats en texte adapté au LLM",tbd:"À déterminer",title:"Limite de taux",tokenCounting:"Comptage de l'utilisation des jetons",tokenizer:"Tokeniser et segmenter un texte long",total_token_counting:"Comptez le nombre total de jetons dans l’ensemble du processus.",understanding:"Comprendre la limite de débit",understanding_description:"Les limites de débit correspondent au nombre maximal de requêtes pouvant être adressées à une API en une minute par adresse IP (RPM). Découvrez ci-dessous les limites de débit pour chaque produit et niveau.",wAPIkey:"avec clé API",wPremium:"avec clé API Premium",woAPIkey:"sans clé API"},de={decision:"Décision",description:"Outils d'aide à la décision IA ultimes",intro:"Voir les deux faces de la médaille, prendre des décisions rationnelles"},ce={beta:"Expérimental",better_input:"Améliorez la qualité d’entrée dès le début",better_input_description:"Vous rencontrez des problèmes avec la sortie de votre agent ou du système RAG ? Cela peut être dû à une mauvaise qualité d'entrée.",check_price_table:"Consultez le tableau des prix",copy:"Copie",demo:{advanced_parameter_explain:"Paramètres spécifiques qui ne sont utilisés que pour {_product}.",advanced_parameters:"Spécifique",advanced_usage:"Utilisation avancée",ask_llm:"Demandez LLM sans et avec recherche de mise à la terre",ask_llm_directly:"Demandez directement à LLM",ask_llm_with_search_grounding:"Demandez LLM avec mise à la terre de recherche",ask_question:"Poser une question",ask_question_hint:"Saisissez une question et combinez-la avec le contenu récupéré pour que LLM génère une réponse",basic_usage:"Utilisation de base",basic_usage1:"Lire une URL",basic_usage2:"Rechercher une requête",basic_usage3:"Mise à la terre",common_parameter_explain:"Paramètres communs pouvant être utilisés pour {_product1}, {_product2} et {_product3}.",common_parameters:"Commun",copy:"Copie",fetch:"Récupérer du contenu",get_response:"Avoir une réponse",grounding_result_false:"Cette affirmation est fausse.",grounding_result_true:"Cette affirmation est vraie.",headers:{auth_token:"Ajouter une clé API pour une limite de débit plus élevée",auth_token_explain:"Entrez votre clé API Jina pour accéder à une limite de débit plus élevée. Pour obtenir les dernières informations sur les limites de taux, veuillez vous référer au tableau ci-dessous.",browser_locale:"Paramètres régionaux du navigateur",browser_locale_explain:"Contrôlez les paramètres régionaux du navigateur pour afficher la page. De nombreux sites Web proposent un contenu différent en fonction des paramètres régionaux.",custom_script:"Pré-exécuter du JavaScript personnalisé",custom_script_explain:"Exécute le code JavaScript de prétraitement, en acceptant soit une chaîne de code en ligne, soit un point de terminaison d'URL de script distant",deepdive:"Analyse de sources profondes",deepdive_explain:"Recherche plus de sources et lit les documents complets pour une vérification approfondie des faits. Légèrement plus lent mais plus précis et plus de références.",default:"Défaut",default_explain:"Le pipeline par défaut optimisé pour la plupart des sites Web et des entrées LLM.",file:"Fichier PDF/HTML local",file_explain:"Utilisez Reader sur vos fichiers PDF et HTML locaux en les téléchargeant. Ne prend en charge que les fichiers PDF et HTML.",html:"HTML",html_explain:"Renvoie documentElement.outerHTML.",image_caption:"Légende",image_caption_explain:"Sous-titre toutes les images à l'URL spécifiée, en ajoutant « Image [idx] : [caption] » comme balise alt pour celles qui n'en ont pas. Cela permet aux LLM en aval d'interagir avec les images dans des activités telles que le raisonnement et la synthèse.",images_summary:"Rassemblez toutes les images à la fin",images_summary_explain:'Une section "Images" sera créée à la fin. Cela donne aux LLM en aval un aperçu de tous les visuels de la page, ce qui peut améliorer le raisonnement.',json_response:"Réponse JSON",json_response_explain:"La réponse sera au format JSON, contenant l'URL, le titre, le contenu et l'horodatage (si disponible). En mode Recherche, il renvoie une liste de cinq entrées, chacune suivant la structure JSON décrite.",links_summary:"Rassemblez tous les liens à la fin",links_summary_explain:`Une section "Boutons & Liens" sera créée à la fin. Cela aide les LLM ou les agents Web en aval à naviguer sur la page ou à entreprendre d'autres actions.`,markdown:"Réduction",markdown_explain:"Renvoie le markdown directement à partir du HTML, en contournant le filtrage de lisibilité.",mode:"Mode lecture ou recherche",mode_explain:"Le mode Lecture permet d'accéder au contenu d'une URL, tandis que le mode Recherche vous permet de rechercher une requête sur le Web, en appliquant le mode Lecture à chaque URL de résultat de recherche.",no_cache:"Contourner le cache",no_cache_explain:"Notre serveur API met en cache le contenu des modes Lecture et Recherche pendant un certain temps. Pour contourner ce cache, définissez cet en-tête sur true.",no_gfm:"Désactivé",no_gfm_explain:"Fonctionnalités GFM (Github Flavored Markdown) désactivées.",no_gfm_table:"Pas de tableau GFM",no_gfm_table_explain:"Désactivez le tableau GFM mais conservez les éléments HTML du tableau en réponse.",opt_out_gfm:"Markdown à saveur Github",opt_out_gfm_explain:"Fonctionnalités d'activation/désactivation de GFM (Github Flavored Markdown).",pageshot:"Capture de page",pageshot_explain:"Renvoie l'URL de l'image de la capture d'écran de la page complète (avec le meilleur effort).",post_with_url:"Utiliser la méthode POST",post_with_url_explain:"Utilisez POST au lieu de la méthode GET avec une URL transmise dans le corps. Utile pour créer des SPA avec un routage basé sur le hachage.",proxy_server:"Utiliser un serveur proxy",proxy_server_explain:"Notre serveur API peut utiliser votre proxy pour accéder aux URL, ce qui est utile pour les pages accessibles uniquement via des proxys spécifiques.",references:"Références",references_explain:"Liste séparée par des virgules de références fournies par l'utilisateur (URL)",remove_all_images:"Supprimer toutes les images",remove_all_images_explain:"Supprimez toutes les images de la réponse.",remove_selector:"Sélecteur d'exclusion",remove_selector_explain:"Fournit une liste de sélecteurs CSS pour supprimer les éléments spécifiés de la page. Utile lorsque vous souhaitez exclure des parties spécifiques de la page comme les en-têtes, les pieds de page, etc.",result_count:"Limite de résultat",result_count_explain:"Le nombre de résultats de recherche à renvoyer.",return_format:"Format du contenu",return_format_explain:"Vous pouvez contrôler le niveau de détail de la réponse pour éviter un filtrage excessif. Le pipeline par défaut est optimisé pour la plupart des sites Web et des entrées LLM.",screenshot:"Capture d'écran",screenshot_explain:"Renvoie l'URL de l'image du premier écran.",set_cookie:"Cookie de transfert",set_cookie_explain:"Notre serveur API peut transmettre vos paramètres de cookies personnalisés lors de l'accès à l'URL, ce qui est utile pour les pages nécessitant une authentification supplémentaire. Notez que les demandes contenant des cookies ne seront pas mises en cache.",site_selector:"Recherche sur site",site_selector_explain:"Renvoie les résultats de la recherche uniquement à partir du site Web ou du domaine spécifié. Par défaut, il recherche sur l'ensemble du Web.",stream_mode:"Mode flux",stream_mode_explain:"Le mode flux est avantageux pour les grandes pages cibles, ce qui laisse plus de temps à la page pour s'afficher complètement. Si le mode standard génère un contenu incomplet, envisagez d’utiliser le mode Stream.",target_selector:"Sélecteur de cible",target_selector_explain:"Fournit une liste de sélecteurs CSS pour se concentrer sur des parties plus spécifiques de la page. Utile lorsque le contenu souhaité ne s'affiche pas dans les paramètres par défaut.",text:"Texte",text_explain:"Renvoie document.body.innerText.",wait_for_selector:"Attendre le sélecteur",wait_for_selector_explain:"Fournit une liste de sélecteurs CSS pour attendre que des éléments spécifiques apparaissent avant de revenir. Utile lorsque le contenu souhaité ne s'affiche pas dans les paramètres par défaut.",with_gfm:"Activé",with_gfm_explain:"Fonctionnalités GFM (Github Flavored Markdown) activées.",with_iframe:"Activer l'extraction d'iframe",with_iframe_explain:"Extrait et traite le contenu de tous les iframes intégrés dans l'arborescence DOM",with_shadow_dom:"Activer l'extraction Shadow DOM",with_shadow_dom_explain:"Parcourt et extrait le contenu de toutes les racines Shadow DOM dans le document",x_timeout:"Temps mort",x_timeout_explain:"Durée maximale d'attente pour le chargement de la page Web. Notez qu'il ne s'agit PAS du temps total de la requête de bout en bout."},how_to_stream:"Pour traiter le contenu dès qu'il devient disponible, définissez l'en-tête de la requête en mode flux. Cela minimise le temps jusqu'à ce que le premier octet soit reçu. Exemple en curl :",how_to_use1:"Ajoutez https://r.jina.ai/ à n'importe quelle URL de votre code ou outil où l'accès LLM est attendu. Cela renverra le contenu principal de la page dans un texte clair et convivial LLM.",how_to_use2:"Ajoutez https://s.jina.ai/ à votre requête. Cela appellera le moteur de recherche et renverra les 5 premiers résultats avec leurs URL et leur contenu, chacun dans un texte clair et convivial LLM.",how_to_use3:"Ajoutez https://g.jina.ai/ à votre déclaration. Cela appellera le moteur de jugement et renverra le pourcentage de véracité, une valeur booléenne indiquant si la déclaration est vraie ou fausse, un résumé de la raison et une liste de références.",key_required:"Clé API requise pour utiliser ce point de terminaison",learn_more:"Apprendre encore plus",open:"Ouvrir dans un nouvel onglet",params_classification:"Paramètres",raw_html:"HTML brut",reader_output:"Sortie du lecteur",reader_response:"Réponse du lecteur",reader_search_hint:"Si vous utilisez cette URL dans du code, n'oubliez pas de coder l'URL.",reader_url:"URL du lecteur",reader_url_hint:"Cliquez ci-dessous pour obtenir le contenu via notre API Reader",requires_post_method:"Cette fonction nécessite la méthode POST. En téléchargeant votre fichier local, la méthode POST sera automatiquement activée.",search_params:"Paramètres/en-têtes de recherche",search_query_rewrite:"Veuillez noter que contrairement à la démo présentée ci-dessus, en pratique, vous ne recherchez pas la question d'origine sur le Web pour vous ancrer. Ce que les gens font souvent, c'est réécrire la question d'origine ou utiliser des questions à sauts multiples. Ils lisent les résultats récupérés, puis génèrent des requêtes supplémentaires pour recueillir plus d'informations si nécessaire avant d'arriver à une réponse finale.",select_mode:"Sélectionner le mode",show_read_demo:"Découvrez comment Reader lit une URL",show_search_demo:"Découvrez comment Reader effectue des recherches sur le Web",slow_warning:"Cela peut prendre jusqu'à 30 secondes et coûte jusqu'à 300 000 jetons par demande.",standard_usage:"Utilisation standard",stream_mode:"Mode flux",stream_mode_explain:"Le mode flux est utile lorsque la page cible est volumineuse à afficher. Si vous trouvez que le mode standard vous donne un contenu incomplet, essayez le mode flux.",stream_mode_explain1:"Le mode streaming est utile lorsque vous constatez que le mode standard fournit un résultat incomplet. En effet, le mode streaming attendra un peu plus longtemps jusqu'à ce que la page soit entièrement rendue. Utilisez l'en-tête accept pour basculer le mode de streaming :",tagline:"Essayez la démo",try_demo:"Démo",use_headers:"Le comportement de l'API Reader peut être contrôlé avec les en-têtes de requête. Voici une liste complète des en-têtes pris en charge.",waiting_for_reader:"En attendant le résultat de l'API Reader d'abord...",warn_grounding_message:"Ce processus peut prendre jusqu'à 30 secondes et consommer jusqu'à 300 000 jetons par demande de mise à la terre. Certains navigateurs peuvent mettre fin à la demande en raison de la longue latence. Nous vous recommandons donc de copier le code et de l'exécuter à partir de votre terminal.",warn_grounding_title:"Latence élevée et utilisation de jetons",your_query:"Entrez votre requête",your_query_hint:"Tapez une question qui nécessite les dernières informations ou connaissances du monde.",your_statement:"Votre déclaration de vérification des faits",your_url:"Entrez votre URL",your_url_hint:"Cliquez ci-dessous pour récupérer directement le code source de la page"},description:"Lisez les URL et effectuez des recherches sur le Web pour de meilleurs LLM de base.",dont_panic_api_key_is_free:"Ne pas paniquer! Chaque nouvelle clé API contient un million de jetons gratuits !",faq_v1:{answer1:"L'API Reader est gratuite et ne nécessite pas de clé API. Ajoutez simplement « https://r.jina.ai/ » à votre URL.",answer10:"Non, l'API Reader ne peut traiter que le contenu provenant d'URL accessibles au public.",answer11:"Si vous demandez la même URL dans les 5 minutes, l'API Reader renverra le contenu mis en cache.",answer12:"Malheureusement non.",answer13:"Oui, vous pouvez soit utiliser le support PDF natif du Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4), soit utiliser la version HTML d'arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)",answer14:"Reader sous-titre toutes les images à l'URL spécifiée et ajoute « Image [idx] : [caption] » comme balise alt (si elles en manquent initialement). Cela permet aux LLM en aval d'interagir avec les images dans le raisonnement, la synthèse, etc.",answer15:"L'API Reader est conçue pour être hautement évolutive. Il est automatiquement mis à l'échelle en fonction du trafic en temps réel et le nombre maximal de requêtes simultanées est désormais d'environ 4 000. Nous le maintenons activement comme l'un des produits principaux de Jina AI. N'hésitez donc pas à l'utiliser en production.",answer16:"Veuillez trouver les dernières informations sur les limites de taux dans le tableau ci-dessous. Notez que nous travaillons activement à l'amélioration de la limite de débit et des performances de l'API Reader, le tableau sera mis à jour en conséquence.",answer2:"L'API Reader utilise un proxy pour récupérer n'importe quelle URL, rendant son contenu dans un navigateur pour extraire le contenu principal de haute qualité.",answer3:"Oui, l'API Reader est open source et disponible sur le référentiel Jina AI GitHub.",answer4:"L'API Reader traite généralement les URL et renvoie le contenu dans un délai de 2 secondes, bien que les pages complexes ou dynamiques puissent nécessiter plus de temps.",answer5:"Le scraping peut être compliqué et peu fiable, en particulier avec des pages complexes ou dynamiques. L'API Reader fournit une sortie rationalisée et fiable de texte propre et prêt pour LLM.",answer6:"L'API Reader renvoie le contenu dans la langue d'origine de l'URL. Il ne fournit pas de services de traduction.",answer7:"Si vous rencontrez des problèmes de blocage, veuillez contacter notre équipe d'assistance pour obtenir de l'aide et une résolution.",answer8:"Bien qu'elle soit principalement conçue pour les pages Web, l'API Reader peut extraire le contenu des PDF affichés au format HTML sur des sites Web comme arXiv, mais elle n'est pas optimisée pour l'extraction PDF générale.",answer9:"Actuellement, l'API Reader ne traite pas le contenu multimédia, mais les améliorations futures incluront le sous-titrage d'images et le résumé vidéo.",question1:"Quels sont les coûts associés à l’utilisation de l’API Reader ?",question10:"Est-il possible d'utiliser l'API Reader sur des fichiers HTML locaux ?",question11:"L'API Reader met-elle en cache le contenu ?",question12:"Puis-je utiliser l'API Reader pour accéder au contenu derrière une connexion ?",question13:"Puis-je utiliser l'API Reader pour accéder au PDF sur arXiv ?",question14:"Comment fonctionne la légende d’image dans Reader ?",question15:"Quelle est l’évolutivité du Reader ? Puis-je l’utiliser en production ?",question16:"Quelle est la limite de débit de l’API Reader ?",question2:"Comment fonctionne l'API Reader ?",question3:"L'API Reader est-elle open source ?",question4:"Quelle est la latence typique de l’API Reader ?",question5:"Pourquoi devrais-je utiliser l'API Reader au lieu de gratter la page moi-même ?",question6:"L'API Reader prend-elle en charge plusieurs langues ?",question7:"Que dois-je faire si un site Web bloque l’API Reader ?",question8:"L'API Reader peut-elle extraire le contenu des fichiers PDF ?",question9:"L'API Reader peut-elle traiter le contenu multimédia des pages Web ?",title:"Questions courantes liées aux lecteurs"},fast:"Rapide",fast_stream:"Streaming de données immédiat",fast_stream_description:"Besoin de données rapidement ? Notre API Reader peut diffuser des données pour minimiser la latence.",free:"Libre pour toujours",free_description:"L’API Reader est gratuite ! Il ne nécessite aucune carte de crédit ni secret API. Cela ne consommera pas votre quota de jetons.",is_free:"La meilleure partie? C'est gratuit!",is_free_description:"L'API Reader est disponible gratuitement et offre une limite de débit et une tarification flexibles. Construit sur une infrastructure évolutive, il offre une accessibilité, une concurrence et une fiabilité élevées. Nous nous efforçons d'être votre solution de mise à la terre préférée pour vos LLM.",open:"Ouvrir dans un nouvel onglet",original_pdf:"PDF original",rate_limit:"Limite de taux",read_grounding_release_note:"Lire la note de publication",reader_also_read_images:"Les images de la page Web sont automatiquement sous-titrées à l'aide d'un modèle de langage de vision dans le lecteur et formatées sous forme de balises alt d'image dans la sortie. Cela donne à votre LLM en aval juste assez d'indices pour intégrer ces images dans ses processus de raisonnement et de synthèse. Cela signifie que vous pouvez poser des questions sur les images, en sélectionner des spécifiques ou même transmettre leurs URL à un VLM plus puissant pour une analyse plus approfondie !",reader_description:"Convertissez une URL en entrée compatible LLM, en ajoutant simplement <code>r.jina.ai</code> devant.",reader_do_grounding:"Lecteur pour vérification des faits",reader_do_grounding_explain:"Le nouveau point de terminaison de mise à la terre offre une expérience de vérification des faits de bout en bout, en temps quasi réel. Il prend une déclaration donnée, la fonde à l'aide de résultats de recherche Web en temps réel et renvoie un score de factualité et les références exactes utilisées. Vous pouvez facilement fonder des déclarations pour réduire les hallucinations du LLM ou améliorer l'intégrité du contenu écrit par l'homme.",reader_do_pdf_explain:"Oui, Reader prend en charge nativement la lecture de PDF. Il est compatible avec la plupart des PDF, y compris ceux contenant de nombreuses images, et il est ultra-rapide ! En combinaison avec un LLM, vous pouvez facilement créer une IA ChatPDF ou d'analyse de documents en un rien de temps.",reader_do_search:"Lecteur pour la mise à la terre de la recherche",reader_do_search_explain:"Les LLM ont un seuil de connaissances, ce qui signifie qu'ils ne peuvent pas accéder aux dernières connaissances mondiales. Cela conduit à des problèmes tels que la désinformation, les réponses obsolètes, les hallucinations et d’autres problèmes factuels. La mise à la terre est absolument essentielle pour les applications GenAI. Reader vous permet de baser votre LLM avec les dernières informations du Web. Ajoutez simplement https://s.jina.ai/ à votre requête, et Reader effectuera une recherche sur le Web et renverra les cinq premiers résultats avec leurs URL et leur contenu, chacun dans un texte clair et convivial LLM. De cette façon, vous pouvez toujours garder votre LLM à jour, améliorer sa factualité et réduire les hallucinations.",reader_reads_images:"Reader lit aussi les images !",reader_reads_pdf:"Reader lit également les PDF !",reader_result:"Résultat du lecteur",table:{td_1_0:"Lire une URL renvoie son contenu, utile pour vérifier la mise à la terre",td_1_1:"20 tr/min",td_1_2:"200 tr/min",td_1_3:"Basé sur les jetons de sortie",td_1_4:"3 secondes",td_1_5:"3 secondes",td_2_0:"La recherche sur le Web renvoie les 5 premiers résultats, utiles pour ancrer la recherche",td_2_1:"5 tours",td_2_2:"40 tr/min",td_2_3:"Basé sur les jetons de sortie pour les 5 résultats de recherche",td_2_4:"10 secondes",td_2_5:"10 secondes",th0:"Point de terminaison",th1:"Description",th2:"Limite de débit sans clé API",th3:"Limite de débit avec clé API",th4:"Schéma de comptage de jetons",th5:"Latence moyenne",th6:"Latence moyenne"},title:"API de lecteur",usage:"Usage",usage_details_false:"Afficher uniquement les utilisations de base",usage_details_null:"Afficher les utilisations de base et avancées",usage_details_true:"Afficher uniquement les utilisations avancées",want_higher_rate_limit:"Vous souhaitez une limite de débit plus élevée jusqu'à 1 000 tr/min ? Nous pouvons vous soutenir !",what_is1:"Qu’est-ce que Reader ?",what_is_answer_long:"Introduire des informations Web dans les LLM est une étape importante de la mise à la terre, mais cela peut être un défi. La méthode la plus simple consiste à gratter la page Web et à alimenter le code HTML brut. Cependant, le scraping peut être complexe et souvent bloqué, et le HTML brut est encombré d'éléments superflus tels que des balises et des scripts. L'API Reader résout ces problèmes en extrayant le contenu principal d'une URL et en le convertissant en texte clair et convivial LLM, garantissant ainsi une saisie de haute qualité pour vos systèmes d'agent et RAG.",what_is_desc:"Un proxy qui accède à n'importe quelle URL et transforme le contenu principal en texte brut optimisé pour les LLM."},pe={confirm_message:"Il reste {_leftTokens} jetons à votre clé API. L'envoi du texte intégral des articles {_numArticles} à l'API Reranker, en utilisant le modèle {_selectedReranker} pour découvrir les articles associés à la page actuelle, réduira considérablement le nombre de jetons de votre clé API {_APIKey}. Voulez-vous poursuivre?",confirm_title:"Avertissement : utilisation élevée des jetons",out_of_quota:"Cette clé API est à court de jetons. Veuillez recharger votre compte ou utiliser une autre clé API.",recommend:"Obtenez le top 5",recommended_articles:"Top 5 des articles similaires"},me={benchmark:{description0:"LlamaIndex a évalué diverses combinaisons d'intégrations et de reclassements pour RAG, en menant une étude de réplication qui mesurait le rang réciproque moyen. Les résultats mettent en évidence l’amélioration significative de la qualité de recherche apportée par Jina Reranker, un avantage indépendant des intégrations spécifiques utilisées.",description1:"BIER (Benchmarking IR) évalue l'efficacité de récupération d'un modèle, y compris la pertinence et le NDCG. Un score BIER plus élevé est corrélé à des correspondances et à un classement des résultats de recherche plus précis.",description2:"Grâce au benchmark LoCo, nous avons mesuré la compréhension d'un modèle de la cohérence et du contexte locaux, ainsi que le classement spécifique à la requête. Un score LoCo plus élevé reflète une meilleure capacité à identifier et hiérarchiser les informations pertinentes.",description3:"Le MTEB (Multilingual Text Embedding Benchmark), dans son ensemble, teste les capacités d'un modèle en matière d'intégration de texte, y compris le clustering, la classification, la récupération et d'autres mesures. Cependant, pour notre comparaison, nous avons utilisé uniquement les tâches de reclassement du MTEB.",title:"Référence",title0:"LamaIndex",title1:"BÉIR",title2:"Locomotive",title3:"MTEB"},benchmark_description:"À titre de comparaison, nous avons inclus trois autres principaux reclasseurs de BGE (BAAI), BCE (Netease Youdao) et Cohere dans l'indice de référence. Comme le montrent les résultats ci-dessous, Jina Reranker détient le score moyen le plus élevé dans toutes les catégories pertinentes pour le reclassement, ce qui en fait un leader incontesté parmi ses pairs.",benchmark_title:"Référence de performances",choose_turbo:"Obtenez jusqu'à 5x d'accélération avec reranker-turbo",choose_turbo_description:"Nous proposons également deux nouveaux modèles de reranker open source : jina-reranker-v1-turbo-en et jina-reranker-v1-tiny-en, ce dernier n'a que 30 millions de paramètres et quatre couches. Ces deux nouveaux rerankers bénéficient d’une vitesse d’inférence 5 fois plus rapide que le modèle de base pour un très faible coût en termes de qualité. Ils sont parfaits pour les applications nécessitant un reclassement en temps réel. Lisez le benchmark ci-dessous.",customize_urself:"Changez-le et voyez comment la réponse change !",customize_urself_pl:"Changez-les et voyez comment la réponse change !",description:"Récupérateur neuronal de classe mondiale pour maximiser la pertinence de la recherche.",description_rich:"Optimisez la pertinence de la recherche et la précision du RAG avec notre API de reranker de pointe.",example_input_document:"Exemples de documents candidats à classer",example_input_query:"Exemple de requête",faq_v1:{answer1:"Le prix de l'API Reranker est aligné sur notre structure tarifaire de l'API d'intégration. Cela commence avec 1 million de jetons gratuits pour chaque nouvelle clé API. Au-delà des jetons gratuits, différents packages sont disponibles à l'achat. Pour plus de détails, veuillez visiter notre section tarification.",answer10:"Oui, Jina Reranker peut être déployé sur AWS. Si vous avez besoin d'un déploiement sur site dans une entreprise, vous pouvez facilement le faire via notre offre AWS Marketplace.",answer11:"Si vous êtes intéressé par un reranker affiné et adapté à des données de domaine spécifiques, veuillez contacter notre équipe commerciale. Notre équipe répondra à votre demande dans les plus brefs délais.",answer3:"La principale différence réside dans leur architecture. Pour les performances, nous recommandons jina-reranker-v1, qui a été largement testé et comparé à ses concurrents. Jina-reranker-v1 utilise une architecture à encodeurs croisés, tandis que Jina-colbert-v1 est basé sur l'architecture ColBERTv2 mais étend la longueur du contexte de la requête et du document à 8 192, obtenant ainsi des performances encore meilleures que le modèle ColBERTv2 d'origine.",answer4:"Oui, jina-colbert-v1 est open source et est accessible via Huggingface. Cependant, jina-reranker-v1 n'est pas open source.",answer5:"Actuellement, il ne prend en charge que l'anglais. Cependant, certains utilisateurs ont signalé que cela fonctionnait également bien avec le chinois. Cela peut être dû en partie au fait que jina-reranker-v1-base-en partage certains poids avec notre modèle d'intégration jina-embeddings-v2-base-zh.",answer6:"La longueur maximale du jeton de requête est de 512. Il n’y a aucune limite de jetons pour les documents.",answer7:"Vous pouvez reclasser jusqu'à 2 048 documents par requête.",answer8:"Il n’y a pas de notion de taille de lot contrairement à notre API Embedding. Vous ne pouvez envoyer qu’un seul tuple de document de requête par requête, mais le tuple peut inclure jusqu’à 2 048 documents candidats.",answer9:"La latence varie de 100 millisecondes à 7 secondes, en fonction en grande partie de la longueur des documents et de la requête. Par exemple, le reclassement de 100 documents de 256 jetons chacun avec une requête de 64 jetons prend environ 150 millisecondes. L'augmentation de la longueur du document à 4 096 jetons augmente le temps à 3,5 secondes. Si la longueur de la requête est augmentée à 512 jetons, le temps augmente encore à 7 secondes.",question1:"Combien coûte l’API Reranker ?",question10:"Puis-je déployer Jina Reranker sur AWS ?",question11:"Proposez-vous un reranker affiné sur les données spécifiques à un domaine ?",question3:"Quelle est la différence entre les deux rerankers ?",question4:"Jina Reranker est-il open source ?",question5:"Le reranker prend-il en charge plusieurs langues ?",question6:"Quelle est la longueur maximale des requêtes et des documents ?",question7:"Quel est le nombre maximum de documents que je peux reclasser par requête ?",question8:"Quelle est la taille du lot et combien de tuples de documents de requête puis-je envoyer en une seule requête ?",question9:"À quelle latence puis-je m'attendre lors du reclassement de 100 documents ?",title:"Questions courantes liées au reranker"},feature_on_premises_description2:"Déployez Jina Reranker sur AWS Sagemaker, et bientôt dans Microsoft Azure et Google Cloud Services, ou contactez notre équipe commerciale pour obtenir des déploiements Kubernetes personnalisés pour votre cloud privé virtuel et vos serveurs sur site.",feature_on_premises_description3:"Déployez Jina Reranker sur AWS Sagemaker et Microsoft Azure et bientôt dans Google Cloud Services, ou contactez notre équipe commerciale pour obtenir des déploiements Kubernetes personnalisés pour votre cloud privé virtuel et vos serveurs sur site.",feature_solid_description:"Développé à partir de nos recherches universitaires de pointe et rigoureusement testé par rapport aux rerankers SOTA pour garantir des performances inégalées.",how_it_works:"Voici comment cela fonctionne:",how_it_works_v1:{description1:"Un système de recherche utilise embeddings/BM25 pour trouver un large ensemble de documents potentiellement pertinents en fonction de la requête de l'utilisateur.",description2:"Le reranker prend ensuite ces résultats et les analyse à un niveau plus granulaire, en tenant compte des nuances de la manière dont les termes de requête interagissent avec le contenu du document.",description3:"Il réorganise les résultats de recherche, en plaçant ceux qu'il juge les plus pertinents en haut, sur la base de cette analyse plus approfondie.",title1:"Récupération initiale",title2:"Reclassement",title3:"Résultats améliorés"},improve_performance:"Amélioration garantie par rapport à la recherche vectorielle",improve_performance_description:"Nos évaluations ont démontré des améliorations pour les systèmes de recherche utilisant Jina Reranker avec +8 % de taux de réussite et +33 % de classement réciproque moyen.",learning1:"En savoir plus sur le Reranker",learning1_description:"Qu'est-ce qu'un reranker ? Pourquoi la recherche vectorielle ou la similarité cosinus ne suffisent-elles pas ? Découvrez les rerankers de A à Z avec notre guide complet.",read_more_about_benchmark:"En savoir plus sur le benchmark",read_more_about_turbo:"En savoir plus sur les modèles turbo et minuscules",read_more_about_v2:"Jina Reranker v2 est le meilleur reranker de sa catégorie sorti le 25 juin 2024 ; il est conçu pour Agentic RAG. Il offre une prise en charge des appels de fonctions, une récupération multilingue pour plus de 100 langues, des capacités de recherche de code et offre une accélération 6x par rapport à la v1. En savoir plus sur le modèle v2.",reranker_description:"Essayez notre API de reclassement de pointe pour maximiser la pertinence de votre recherche et la précision de RAG. Commencer gratuitement !",show_v2benchmark:"Afficher le benchmark pour le modèle v2 (dernier)",table:{number_token_document:"Nombre de jetons dans chaque document",number_token_query:"Nombre de jetons dans la requête",title:"Vous trouverez ci-dessous le coût en temps nécessaire au reclassement d'une requête et de 100 documents en millisecondes :"},title:"API de reclassement",top_n:"Nombre de documents retournés",top_n_explain:"Le nombre de documents les plus pertinents à renvoyer pour la requête.",try_embedding:"Essayez d'intégrer l'API gratuitement",try_reranker:"Essayez l'API de reclassement gratuitement",v2_features:{description1:"Reranker v2 permet la récupération de documents dans plus de 100 langues, quel que soit le langage de requête.",description2:"Reranker v2 classe les extraits de code et les signatures de fonctions en fonction de requêtes en langage naturel, idéal pour les applications Agentic RAG.",description3:"Reranker v2 classe les tables les plus pertinentes en fonction de requêtes en langage naturel, aidant ainsi à trier différents schémas de table et à identifier le plus pertinent avant de générer une requête SQL.",title1:"Récupération multilingue",title2:"Appel de fonction et recherche de code",title3:"Prise en charge des données tabulaires et structurées"},v2benchmark:{descBeir:"Scores NDCG 10 rapportés pour différents modèles de reclassement pour l'ensemble de données Beir",descCodeSearchNet:"Scores MRR 10 rapportés pour différents modèles de reclassement pour l'ensemble de données CodeSearchNet",descMKQA:"Rappel de 10 scores rapportés pour différents modèles de reclassement pour l'ensemble de données MKQA",descNSText2SQL:"Rappel de 3 scores rapportés pour différents modèles de reclassement pour l'ensemble de données NSText2SQL",descRTX4090:"Scores de débit (documents récupérés en 50 ms) rapportés pour différents modèles de reclassement sur un GPU RTX 4090.",descToolBench:"Rappel de 3 scores rapportés pour différents modèles de reclassement pour l'ensemble de données ToolBench",titleBeir:"BEIR (Benchmark hétérogène sur diverses tâches IR)",titleCodeSearchNet:"CodeSearchNet. Le benchmark est une combinaison de requêtes aux formats docstring et en langage naturel, avec des segments de code étiquetés pertinents pour les requêtes.",titleMKQA:"MKQA (Questions et réponses sur les connaissances multilingues)",titleNSText2SQL:"NSText2SQL",titleRTX4090:"Débit de Jina Reranker v2 sur RTX4090",titleToolBench:"Banc d'outils. Le benchmark collecte plus de 16 000 API publiques et les instructions correspondantes générées synthétiquement pour les utiliser dans des paramètres à API unique et multi-API."},vs_table:{col0:"Reclasseur",col0_1:"Précision et pertinence de recherche améliorées",col0_2:"Filtrage initial et rapide",col0_3:"Récupération de texte générale pour des requêtes étendues",col1:"Recherche de vecteurs",col1_1:"Détaillé : sous-document et segment de requête",col1_2:"Large : documents entiers",col1_3:"Intermédiaire : divers segments de texte",col2:"BM25",col2_1:"Haut",col2_2:"Moyen",col2_3:"Faible",col3_1:"Non requis",col3_2:"Haut",col3_3:"Faible, utilise un index prédéfini",col4_1:"Haut",col4_2:"Haut",col4_3:"Non requis",col5_1:"Supérieur pour les requêtes nuancées",col5_2:"Équilibré entre efficacité et précision",col5_3:"Cohérent et fiable pour un large éventail de requêtes",col6_1:"Très précis avec une compréhension contextuelle approfondie",col6_2:"Rapide et efficace, avec une précision modérée",col6_3:"Hautement évolutif, avec une efficacité établie",col7_1:"gourmand en ressources avec une mise en œuvre complexe",col7_2:"Peut ne pas capturer le contexte ou les nuances approfondies des requêtes",col7_3:"Peut sous-performer pour les recherches très spécifiques ou contextuelles",header0:"Meilleur pour",header1:"Granularité",header2:"Complexité du temps de requête",header3:"Complexité du temps d’indexation",header4:"Complexité du temps de formation",header5:"Qualité de la recherche",header6:"Forces",header7:"Faiblesses",subtitle:"Le tableau ci-dessous fournit une comparaison complète du Reranker, de la recherche Vector/Embeddings et du BM25, mettant en évidence leurs forces et leurs faiblesses dans diverses catégories.",title:"Comparaison de Reranker, Vector Search et BM25"},what_is:"Qu'est-ce qu'un reranker ?",what_is_answer_long:`L’objectif d’un système de recherche est de trouver les résultats les plus pertinents rapidement et efficacement. Traditionnellement, des méthodes telles que BM25 ou tf-idf ont été utilisées pour classer les résultats de recherche en fonction de la correspondance des mots clés. Des méthodes récentes, telles que la similarité cosinus basée sur l'intégration, ont été implémentées dans de nombreuses bases de données vectorielles. Ces méthodes sont simples mais peuvent parfois passer à côté des subtilités du langage et, plus important encore, de l'interaction entre les documents et l'intention d'une requête.

C'est là que le « reranker » brille. Un reranker est un modèle d'IA avancé qui prend l'ensemble initial de résultats d'une recherche (souvent fourni par une recherche basée sur des intégrations/jetons) et les réévalue pour s'assurer qu'ils correspondent plus étroitement à l'intention de l'utilisateur. Il va au-delà de la correspondance superficielle des termes pour considérer l’interaction plus profonde entre la requête de recherche et le contenu des documents.`,what_is_answer_long_ending:"Le reranker peut améliorer considérablement la qualité de la recherche car il opère au niveau des sous-documents et des sous-requêtes, ce qui signifie qu'il examine les mots et expressions individuels, leur signification et leurs relations les uns avec les autres dans la requête et les documents. Cela se traduit par un ensemble de résultats de recherche plus précis et contextuellement pertinents.",what_is_desc:"Un reranker est un modèle d'IA qui affine les résultats de recherche à partir d'une recherche vectorielle ou d'un modèle de récupération dense. En savoir plus."},ge={caption_image_desc:"Générez une description textuelle de l’image.",caption_image_title:"Légende de l'image",description:"Explorez la narration d'images au-delà des pixels",example1:"Cette vidéo semble être une séquence de nature mettant en vedette un charmant lapin blanc et un papillon dans un champ herbeux. Le lapin interagit avec le papillon de différentes manières, mettant en valeur leur relation unique. L'environnement naturel offre une toile de fond pittoresque, rehaussant la beauté de cette scène simple mais captivante.",generate_story_desc:"Créez une histoire inspirée de l’image, comportant souvent des dialogues ou des monologues de ses personnages.",generate_story_title:"Générer une histoire",intro1:"Solution d'IA leader pour les légendes d'images et les résumés vidéo",json_image_desc:"Générez un format JSON structuré à partir de l'image à l'aide d'un schéma prédéfini. Cela permet une extraction de données spécifiques de l’image.",json_image_title:"Extraire JSON de l'image",summarize_video_desc:"Générez un résumé concis de la vidéo, mettant en évidence les événements clés.",summarize_video_title:"Résumer la vidéo",visual_q_a_desc:"Répondez à une requête basée sur le contenu de l'image.",visual_q_a_title:"Questions et réponses visuelles"},ve={ask_on_current_page:"Interrogez la page actuelle sur...",find_solution:"Générer une solution pour...",hint:"Recherchez des produits, des actualités et vos questions",hotkey:"Appuyez sur la touche / pour effectuer une recherche sur cette page",hotkey1:"Presse",hotkey2:"pour basculer",hotkey_long1:"À tout moment, appuyez sur",hotkey_long3:"pour ouvrir la barre de recherche",more_results:"{_numMore} autres résultats",placeholder:"Posez n'importe quelle question sur cette page",proposing_solution:"Générer une réponse basée sur le contenu de la page...",required:"Veuillez décrire votre question avec plus de détails.",results:"résultats"},_e={description:"Naviguer, interagir, affiner : réinventez la découverte de produits"},fe={description:"Combler le fossé sémantique dans votre infrastructure de recherche existante"},he={"Hacker News":"Actualités des pirates",LinkedIn:"LinkedIn",facebook:"Facebook",reddit:"Reddit",rss:"flux RSS",share_btn:"Partager",twitter:"X (Twitter)"},be={click_to_learn_more:"Cliquez pour en savoir plus",contextualization:"Contextualisation",contextualization_desc:"Les rerankers ajustent les résultats de recherche initiaux en fonction d'une pertinence contextuelle profonde. requête. Cela affine le classement pour mieux correspondre à ce que les utilisateurs sont susceptibles de trouver utiles.",coreInfra:"Infra de base",coreInfra_desc:"Core Infra fournit une couche cloud native pour développer, déployer et orchestration des modèles de base de recherche à la fois dans le cloud public et sur site, permettant aux services d'évoluer sans effort.",embedding_serving:"Intégration du service",embedding_serving_description:"Fournir des intégrations via un microservice robuste et évolutif utilisant des technologies cloud natives.",embedding_tech:"Intégrations",embedding_tech_description:`Chez Jina AI, nous exploitons la puissance de la technologie intégrée pour révolutionner diverses applications d’IA. Cette technologie sert de méthode unifiée pour représenter et compresser efficacement divers types de données, garantissant ainsi l’absence de perte d’informations critiques. Notre objectif est de transformer des ensembles de données complexes en un format d’intégration universellement compréhensible, essentiel pour une analyse précise et perspicace de l’IA.

Les intégrations sont fondamentales, en particulier dans des applications telles que la reconnaissance précise d’images et de voix, où elles permettent de discerner des détails et des nuances fins. Dans le traitement du langage naturel, les intégrations améliorent la compréhension du contexte et des sentiments, conduisant à des outils d’IA conversationnelle et de traduction linguistique plus précis. Ils jouent également un rôle crucial dans le développement de systèmes de recommandation sophistiqués qui nécessitent une compréhension approfondie des préférences des utilisateurs pour différentes formes de contenu, telles que le texte, l'audio et la vidéo.`,embedding_tuning:"Intégration du réglage",embedding_tuning_description:"Optimiser les intégrations de haute qualité en intégrant l'expertise du domaine pour des performances améliorées spécifiques aux tâches.",embeddings:"Intégrations",embeddings_desc:"Les intégrations sont la pierre angulaire du système de recherche moderne, représentant les données multimodales en vecteurs de nombres. Ce processus permet une compréhension plus nuancée et contextuelle du contenu, bien au-delà de la simple correspondance de mots clés.",for_developers:"Pour les développeurs",for_enterprise:"Pour les entreprises",for_power_users:"Pour les utilisateurs expérimentés",grounding:"Mise à la terre",grounding_desc:"Le lecteur affine les entrées et les résultats via les LLM. Ils améliorent la qualité, la lisibilité et la factualité de la réponse finale.",model_serving:"Modèle de service",model_serving_description:"Le déploiement de modèles affinés dans un environnement de production, nécessitant généralement des ressources importantes telles que l'hébergement de GPU. MLOps, mettant l'accent sur le service des modèles de taille moyenne à grande de manière évolutive, efficace et fiable.",model_tuning:"Réglage du modèle",model_tuning_description:"Également connu sous le nom de réglage fin, consiste à ajuster les paramètres d'un modèle pré-formé sur un nouvel ensemble de données, souvent spécifique à une tâche, pour améliorer ses performances et l'adapter à une application spécifique.",personalization:"Personnalisation",personalization_desc:"Utilisation de données synthétiques guidées par les instructions de l'utilisateur pour former automatiquement un modèle d'intégration et de reclassement spécifique au domaine.",preprocessing:"Prétraitement",preprocessing_desc:"Le prétraitement implique le nettoyage, la normalisation et la transformation des données brutes dans un format digeste par le système de recherche.",promptOps:"InviteOps",promptOps_desc:"Prompt Ops améliore les entrées et sorties du système de recherche, y compris celles utilisées dans l'expansion des requêtes, l'entrée LLM et la réécriture des résultats. Cela garantit que la recherche comprend mieux et donne de meilleurs résultats.",prompt_serving:"Service rapide",prompt_serving_description:"Enveloppez et servez des invites via une API, sans héberger de modèles lourds. L'API appelle un service public de modèle de grande langue et gère l'orchestration des entrées et des sorties dans une chaîne d'opérations.",prompt_tech:"Ingénierie des invites et des agents",prompt_tech_description:`Chez Jina AI, nous reconnaissons l'ingénierie rapide comme essentielle pour interagir avec les grands modèles de langage (LLM). À mesure que ces modèles progressent, la complexité des invites augmente, englobant un raisonnement et une logique complexes. Cette avancée souligne la croissance étroitement liée des LLM et de la sophistication rapide.

Nous prévoyons un avenir dans lequel les LLM agiront comme des compilateurs, les invites devenant le nouveau langage de programmation. Ce changement suggère que les futures compétences technologiques pourraient se concentrer davantage sur une maîtrise rapide que sur le codage traditionnel. Notre engagement chez Jina AI est d'être leader dans ce domaine de transformation, en rendant l'IA avancée accessible et pratique pour une utilisation quotidienne en maîtrisant ce « langage » émergent.`,prompt_tuning:"Réglage rapide",prompt_tuning_description:"Le processus d'élaboration et de raffinement des invites d'entrée afin de guider sa sortie vers des réponses spécifiques et souhaitées.",representation:"Représentation",representation_desc:"Les intégrations transforment les données multimodales en un format uniforme et vectorisé. Cela permet au système de recherche de comprendre et de catégoriser le contenu au-delà de simples mots-clés.",rerankers:"Reclasseur",rerankers_desc:"Les rerankers prennent les résultats initiaux des intégrations et les affinent, garantissant que les résultats les plus pertinents sont présentés à l'utilisateur. Ceci est crucial pour fournir des résultats de recherche de haute qualité qui répondent à l’intention de l’utilisateur."},qe={care_most:"Qu’est-ce qui vous tient le plus à cœur ?",care_most_options:{accuracy:"Précision",cost:"Coût",other:"Autre",scalability:"Évolutivité",speed:"Vitesse"},care_most_required:"Lorsque vous choisissez un service, qu’est-ce qui vous importe le plus ?",company_size:"Quelle est la taille de votre entreprise ?",company_size_required:"Dites-nous que la taille de votre entreprise nous aide à fournir un meilleur service",company_url:"Quel est le site Internet de votre entreprise ?",company_url_required:"Dites-nous que le site Web de votre entreprise nous aide à fournir un meilleur service",contactName:"Votre nom",contactName_required:"Comment devrions-nous vous adresser ?",contactTitle:"Quel est votre titre de poste ?",contactTitle_required:"Votre titre de poste est requis",contact_us:"Contactez-nous",domain_required:"Dites-nous que votre domaine de travail nous aide à fournir un meilleur service",email:"E-mail",email_contact:"Votre email de contact",email_invalid:"Le courriel est invalide",email_required:"L'e-mail est requis",fine_tuned_embedding:"Intéressé par des intégrations affinées et adaptées à vos données et à votre cas d'utilisation ? Discutons!",fine_tuned_reranker:"Intéressé par des rerankers affinés et adaptés à vos données et à votre cas d'utilisation ? Discutons!",full_survey:"Répondez à l'enquête complète et obtenez une réponse plus rapide de notre équipe",get_new_key:"Obtenez votre clé API",get_update_blog_posts:"Recevez les dernières mises à jour pour les articles du blog",get_update_embeddings:"Obtenez les dernières mises à jour pour les intégrations",send:"Envoyer",sign_up:"S'inscrire",subscribe:"S'abonner",tell_domain:"Dites-nous votre domaine",usage_type:"Quel type d’utilisation vous décrit le mieux ?",usage_type_options:{other:"Autre",poc:"Preuve de concept",production:"Production",research:"Recherche"},usage_type_required:"Dites-nous que votre type d'utilisation nous aide à fournir un meilleur service",used_product:"Quel modèle utilisez-vous ?",used_product_required:"Sélectionnez le modèle que vous utilisez ou qui vous intéresse"},xe={description:"Techniques d'agent pour augmenter votre LLM et le pousser au-delà de ses limites"},ze="Table des matières",Ae={advance_usage:"Utilisez la requête POST pour plus de fonctionnalités",basic_usage:"Utiliser la requête GET pour compter les jetons",basic_usage_explain:"Vous pouvez simplement envoyer une requête GET pour compter le nombre de jetons dans votre texte.",change_content:"Modifiez le « contenu » et voyez le résultat en direct",chars:"personnages",chinese:"Chinois",chunk:"Gros morceau",chunk_all:"Tous les morceaux",chunking:"Rédiger de longs documents à la vitesse de l'éclair !",chunking_explain:"Vous pouvez également utiliser l'API Segmenter pour découper de longs documents en morceaux plus petits, ce qui facilite leur traitement dans les intégrations ou les reclassements. Nous exploitons des repères structurels courants et créons un ensemble de règles et d'heuristiques qui fonctionnent bien avec divers types de contenu, par exemple les langages Markdown, HTML, LaTeX et CJK.",chunking_short:"Morceautage",chunks_in_total:"{_numChunks} morceaux au total",count_tokens_hint:"<b>{_numTokens}</b> jetons, {_numChars} caractères.",description:"Coupez un long texte en morceaux et effectuez la tokenisation.",description_long:"Notre API Segmenter est essentielle pour aider les LLM à gérer les entrées dans les limites du contexte et à optimiser les performances du modèle. Elle permet aux développeurs de compter les jetons et d'extraire les segments de texte pertinents, garantissant ainsi un traitement efficace des données et une gestion des coûts.",description_long1:"API gratuite pour segmenter un texte long en morceaux et en tokenisation.",english:"Anglais",explain:"Un segmenteur est un composant essentiel qui convertit le texte en jetons ou en morceaux, qui sont les unités de données de base traitées par un modèle d'intégration/de reclassement ou LLM. Les jetons peuvent représenter des mots entiers, des parties de mots ou même des caractères individuels.",faq_v1:{answer1:"L'utilisation de l'API Segmenter est gratuite. En fournissant votre clé API, vous pouvez accéder à une limite de débit plus élevée et votre clé ne sera pas facturée.",answer10:"Outre les langues occidentales, le découpage fonctionne également bien avec le chinois, le japonais et le coréen.",answer2:"Sans clé API, vous pouvez accéder à l'API Segmenter à une vitesse limite de 20 RPM.",answer3:"Avec une clé API, vous pouvez accéder à l'API Segmenter à une vitesse limite de 200 RPM. Pour les utilisateurs payants premium, la limite de vitesse est de 1 000 RPM.",answer4:"Non, votre clé API n'est utilisée que pour accéder à une limite de débit plus élevée.",answer5:"Oui, l'API Segmenter est multilingue et prend en charge plus de 100 langues.",answer6:"Les requêtes GET sont uniquement utilisées pour compter le nombre de jetons dans un texte, ce qui vous permet de l'intégrer facilement comme compteur dans votre application. Les requêtes POST prennent en charge davantage de paramètres et de fonctionnalités, telles que le renvoi des N premiers/derniers jetons.",answer7:"Vous pouvez envoyer jusqu'à 64 000 caractères par demande.",answer8:"La fonction de découpage segmente les documents longs en morceaux plus petits en fonction d'indices structurels communs, garantissant une segmentation précise du texte en morceaux significatifs. Il s'agit essentiellement d'un (gros !) modèle d'expression régulière qui segmente le texte en fonction de certaines caractéristiques syntaxiques qui correspondent souvent à des limites sémantiques, telles que les fins de phrases, les sauts de paragraphe, la ponctuation et certaines conjonctions. Il ne s'agit pas d'un découpage sémantique. Cette (grosse) expression régulière est aussi puissante qu'elle peut l'être dans les limites des expressions régulières. Elle équilibre complexité et performances. Bien qu'une véritable compréhension sémantique ne soit pas possible avec les expressions régulières, elles se rapprochent bien du contexte grâce à des indices structurels communs.",answer9:"Si l'entrée contient des jetons spéciaux, notre API Segmenter les placera dans le champ « special_tokens ». Cela vous permet de les identifier facilement et de les gérer en conséquence pour vos tâches en aval, par exemple en les supprimant avant d'introduire le texte dans un LLM pour éviter les attaques par injection.",question1:"Combien coûte l'API Segmenter ?",question10:"Le chunking prend-il en charge d'autres langues que l'anglais ?",question2:"Si je ne fournis pas de clé API, quelle est la limite de débit ?",question3:"Si je fournis une clé API, quelle est la limite de débit ?",question4:"Allez-vous facturer les jetons à partir de ma clé API ?",question5:"L'API Segmenter prend-elle en charge plusieurs langues ?",question6:"Quelle est la différence entre les requêtes GET et POST ?",question7:"Quelle est la longueur maximale que je peux tokeniser par requête ?",question8:"Comment fonctionne la fonction de fragmentation ? S'agit-il d'une fragmentation sémantique ?",question9:"Comment gérez-vous les jetons spéciaux tels que « endoftext » dans l'API Segmenter ?",title:"Questions courantes liées au segmenteur"},free_api:"L'utilisation de l'API Segmenter est gratuite. En fournissant votre clé API, vous pouvez accéder à une limite de débit plus élevée et votre clé ne sera pas facturée.",input_text:"Saisir du texte",is_free:"L'API Segmenter est gratuite !",is_free_description:"En fournissant votre clé API, vous pouvez accéder à une limite de débit plus élevée et votre clé ne sera pas facturée.",japanese:"japonais",korean:"coréen",parameters:{auth_token:"Ajouter une clé API pour une limite de débit plus élevée",auth_token_explain:"Saisissez votre clé API Jina pour accéder à une limite de débit plus élevée. Pour obtenir les dernières informations sur la limite de débit, veuillez vous référer au tableau ci-dessous.",head:"Renvoyer les N premiers jetons",head_explain:"Renvoie les N premiers jetons du contenu donné. Limite exclusive. Ne peut pas être utilisé avec 'tail'.",learn_more:"Apprendre encore plus",max_chunk_length:"Longueur maximale de chaque morceau",max_chunk_length_explain:"Nombre maximal de caractères dans chaque bloc. En pratique, la longueur du bloc peut être inférieure à cette valeur s'il existe une limite naturelle dans le texte.",return_chunks:"Remettre les morceaux",return_chunks_explain:"Découper l'entrée en segments sémantiquement significatifs tout en gérant une grande variété de types de texte et de cas limites en fonction d'indices structurels communs.",return_tokens:"Remettre les jetons",return_tokens_explain:"Renvoyer les jetons et leurs identifiants correspondants dans la réponse. Basculer pour voir la visualisation du résultat.",tail:"Renvoie les N derniers jetons",tail_explain:"Renvoie les N derniers jetons du contenu donné. Limite exclusive. Ne peut pas être utilisé avec 'head'.",type:"Segmenteur",type_explain:"Choisissez le tokeniseur à utiliser.",used_by_models:"Utilisé dans {_usedBy}."},remove_boundary_cues:"Supprimer les sauts de ligne",remove_boundary_cues_explain:"Supprimez tous les sauts de ligne (les principaux repères de limite) de l'entrée, cela rend le problème plus difficile et voyez comment la réponse change !",show_space:"Afficher les espaces de début/de fin",table:{td_1_0:"Tokenisez les textes, comptez et obtenez les premier/dernier N jetons.",td_1_1:"20 tours/minute",td_1_2:"200 tr/min",td_1_3:"1000 tr/min",td_1_4:"Sans frais",td_1_5:"800 ms"},title:"API de segmentation",token_index:"Index du jeton : {_index}",usage:"Usage",visualization:"Visualisation",what_is:"Qu'est-ce qu'un segmenteur ?"},Ie={cta:"Traduire en code {_lang}",select_language:"Langue"},ye={description:"Une base de données vectorielles Python dont vous avez juste besoin - ni plus, ni moins"},Pe="zzz",Le={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:s,about_us_page:t,api_general_faq:n,autotune:i,best_banner:r,beta:o,billing_general_faq:a,blog_tags:l,cclicence:u,classifier:d,clip_as_service:c,cloud:p,contact_us_page:m,copy:g,copy_to_clipboard_success:v,dalle_flow:_,"dev-gpt":{description:"Votre équipe de développement virtuelle"},disco_art:f,doc_array:h,download:b,embedding:q,embeddings:x,faq:z,faq_button:A,farewell:I,finetuner:y,finetuner_plus:P,finetuning:L,footer:j,get_new_key:k,github:C,header:w,hub:R,huggingface:S,impact_snapshots:N,inference:M,integrations:D,internship_faq:E,internship_page:U,jcloud:T,jerboa:O,jina:J,jina_chat:V,key_manager:G,lab_dialog:B,landing_page:F,langchain_serve:Q,legal_page:W,model_graph:H,news_page:K,newsroom_page:X,notice:Y,open_day:Z,open_day_faq:$,open_gpt:ee,paywall:se,powered_by:te,print:ne,project_status:ie,prompt_perfect:re,promptperfect:oe,purchase:ae,purchase_now:le,rate_limit:ue,rationale:de,reader:ce,recommender:pe,reranker:me,scenex:ge,searchbar:ve,searchscape:_e,semantic:fe,share:he,spectrum:be,subscribe_system:qe,think_gpt:xe,toc:ze,tokenizer:Ae,translator:Ie,vectordb:ye,zzz:Pe};export{e as PRODUCT_DESCRIPTION,s as SEO_TAG_LINE,t as about_us_page,n as api_general_faq,i as autotune,r as best_banner,o as beta,a as billing_general_faq,l as blog_tags,u as cclicence,d as classifier,c as clip_as_service,p as cloud,m as contact_us_page,g as copy,v as copy_to_clipboard_success,_ as dalle_flow,Le as default,f as disco_art,h as doc_array,b as download,q as embedding,x as embeddings,z as faq,A as faq_button,I as farewell,y as finetuner,P as finetuner_plus,L as finetuning,j as footer,k as get_new_key,C as github,w as header,R as hub,S as huggingface,N as impact_snapshots,M as inference,D as integrations,E as internship_faq,U as internship_page,T as jcloud,O as jerboa,J as jina,V as jina_chat,G as key_manager,B as lab_dialog,F as landing_page,Q as langchain_serve,W as legal_page,H as model_graph,K as news_page,X as newsroom_page,Y as notice,Z as open_day,$ as open_day_faq,ee as open_gpt,se as paywall,te as powered_by,ne as print,ie as project_status,re as prompt_perfect,oe as promptperfect,ae as purchase,le as purchase_now,ue as rate_limit,de as rationale,ce as reader,pe as recommender,me as reranker,ge as scenex,ve as searchbar,_e as searchscape,fe as semantic,he as share,be as spectrum,qe as subscribe_system,xe as think_gpt,ze as toc,Ae as tokenizer,Ie as translator,ye as vectordb,Pe as zzz};
