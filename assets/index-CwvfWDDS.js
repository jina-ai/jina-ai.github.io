const t={PRODUCT_DESCRIPTION:e=>{const{normalize:n}=e;return n(["Wir bieten erstklassige Einbettungen, Reranker, LLM-Reader und Prompt-Optimierer sowie bahnbrechende Such-KI für multimodale Daten."])},SEO_TAG_LINE:e=>{const{normalize:n}=e;return n(["Ihre Suchgrundlage, aufgeladen."])},about_us_page:{approach:e=>{const{normalize:n}=e;return n(["Unser Vorgehen"])},approach_connect_dots:e=>{const{normalize:n}=e;return n(["Zusammenhänge: Von Power-Usern zu Unternehmen"])},approach_connect_dots_description:e=>{const{normalize:n}=e;return n(["Warum ist der Fokus auf Power-User für unser unternehmensorientiertes Modell so wichtig? Weil es darum geht, frühe Beziehungen aufzubauen. Indem wir uns jetzt an Power-User wenden, bauen wir Brücken zu den Unternehmen, die sie in Zukunft beeinflussen werden. Es handelt sich um eine strategische Maßnahme – eine langfristige Investition, um sicherzustellen, dass unser Unternehmensangebot im Vordergrund steht, wenn diese Power-User in Entscheidungsrollen innerhalb von Organisationen aufsteigen."])},approach_content1:e=>{const{normalize:n}=e;return n(["In der sich schnell entwickelnden Welt der KI müssen Strategien sowohl flexibel als auch zukunftsorientiert sein. Während sich unser Kernangebot weiterhin auf Unternehmen konzentriert, hat sich die KI-Landschaft in einer Weise verändert, die ein Überdenken unseres Ansatzes zur Kundenakquise erforderlich macht. Aus diesem Grund ist die Einführung von Power-Usern als Einstiegspunkt in unseren Funnel nicht nur innovativ, sondern auch entscheidend für unser nachhaltiges Wachstum im Unternehmenssektor."])},approach_content2:e=>{const{normalize:n}=e;return n(["Bei Jina AI besteht unsere Strategie darin, proaktiv statt reaktiv zu sein. Durch die Einbeziehung von Power-Usern als Einstiegspunkt in den Funnel stellen wir sicher, dass wir nicht nur aktuelle Markttrends erfassen, sondern auch strategisch für zukünftiges Unternehmenswachstum gerüstet sind. Unser Engagement für Unternehmen bleibt unerschütterlich; Unser Ansatz zur Erreichung dieser Ziele ist jedoch innovativ, robust und vor allem zukunftsorientiert."])},approach_content4:e=>{const{normalize:n}=e;return n(['Jeder möchte eine bessere Suche. Bei Jina AI ermöglichen wir eine bessere Suche, indem wir die <span class="text-primary text-bold">Search Foundation</span> bereitstellen, die aus Embeddings, Rerankers, Reader und Prompt Ops besteht. Diese Komponenten arbeiten zusammen, um die Art und Weise zu revolutionieren, wie wir Daten suchen und verstehen.'])},approach_miss_mark:e=>{const{normalize:n}=e;return n(["Warum traditionelle MLOps das Ziel verfehlen"])},approach_miss_mark_description:e=>{const{normalize:n}=e;return n(["Obwohl der Zustrom von Power-Usern beträchtlich ist, sind herkömmliche MLOps-Tools nicht in der Lage, deren Anforderungen zu erfüllen. Diese Werkzeuge erinnern an die Verwendung eines Traktors zum Navigieren durch die Straßen der Stadt – sie sind schwer und oft übertrieben. Die Entwickler der neuen Generation verlangen agile, intuitive Tools, die ihr schnelles Entwicklungstempo ergänzen."])},approach_new_paradigm:e=>{const{normalize:n}=e;return n(["Aufforderungsbasierte Technologie: Ein neues Paradigma"])},approach_new_paradigm_description:e=>{const{normalize:n}=e;return n([`Das Jahr 2023 läutete eine bedeutende Veränderung ein: den Aufstieg der prompt-basierten Technologie. Durch die Vereinfachung des KI-Entwicklungsprozesses wurde der Zugang zu KI-Tools demokratisiert. Jetzt können auch diejenigen ohne umfangreiche Programmiererfahrung – sogenannte „Power-User“ – an der KI-Entwicklung teilnehmen, ohne die steilen Lernkurven zu durchlaufen, die mit Tools wie Pytorch, Docker oder Kubernetes verbunden sind.

Wenn man eine Parallele zieht, ähnelt dies der Entwicklung des Personal Computing. Ursprünglich bedienten nur Technikexperten Computer. Aber mit dem Aufkommen benutzerfreundlicher Schnittstellen könnte ein breiteres Publikum teilnehmen. Heute erleben wir mit der auf Eingabeaufforderungen basierenden Technologie eine ähnliche Demokratisierung der KI.`])},awards:e=>{const{normalize:n}=e;return n(["Auszeichnungen und Anerkennung"])},berlin:e=>{const{normalize:n}=e;return n(["Berlin, Deutschland"])},berlin_address:e=>{const{normalize:n}=e;return n(["Prinzessinnenstraße 19-20, 10969 Berlin, Deutschland"])},berlin_address2:e=>{const{normalize:n}=e;return n(["Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlin, Deutschland"])},bj:e=>{const{normalize:n}=e;return n(["Peking, China"])},bj_address:e=>{const{normalize:n}=e;return n(["Ebene 5, Gebäude 6, Nr. 48 Haidian West St. Peking Haidian, China"])},brochure_info:e=>{const{normalize:n}=e;return n(["Ihr Leitfaden zu unserem Unternehmen erwartet Sie"])},description:e=>{const{normalize:n}=e;return n(["Die Zukunft beginnt hier."])},download_brochure1:e=>{const{normalize:n}=e;return n(["Broschüre herunterladen"])},download_docarray_logo:e=>{const{normalize:n}=e;return n(["Laden Sie das DocArray-Logo herunter"])},download_docarray_logo_desc:e=>{const{normalize:n}=e;return n(["Greifen Sie auf das DocArray-Logo zu, ein Open-Source-Projekt, das von Jina AI initiiert und im Dezember 2022 zur Linux Foundation beigetragen hat. Verfügbar im Hell- und Dunkelmodus, in den Formaten PNG und SVG."])},download_jina_logo:e=>{const{normalize:n}=e;return n(["Laden Sie das Jina AI-Logo herunter"])},download_jina_logo_desc:e=>{const{normalize:n}=e;return n(["Holen Sie sich das Jina AI-Logo sowohl im hellen als auch im dunklen Modus, verfügbar in den Formaten PNG und SVG. Dieses Logo ist eine eingetragene Marke beim Amt der Europäischen Union für geistiges Eigentum (EUIPO)."])},download_logo:e=>{const{normalize:n}=e;return n(["Logos herunterladen"])},employees:e=>{const{normalize:n}=e;return n(["Mitarbeiter heute"])},empower_developers:e=>{const{normalize:n}=e;return n(["unterstützte Entwickler"])},fastApiCaption:e=>{const{normalize:n}=e;return n(["Seit 2021 über 20.000 US-Dollar gespendet."])},founded:e=>{const{normalize:n}=e;return n(["Gegründet"])},founded_in:e=>{const{normalize:n}=e;return n(["Gegründet in"])},investors:e=>{const{normalize:n}=e;return n(["Unsere Investoren"])},linuxFoundationCaption:e=>{const{normalize:n}=e;return n(["Leistet ab 2022 einen jährlichen Beitrag von 10.000 US-Dollar."])},many:e=>{const{normalize:n}=e;return n(["Viele"])},media:{video:e=>{const{normalize:n}=e;return n(["Videointerview"])}},mission:e=>{const{normalize:n}=e;return n(["Unsere Aufgabe"])},mission_content1:e=>{const{normalize:n}=e;return n(["Unsere Schlüsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Model-Tuning und Model-Serving, verkörpern unser Engagement für die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative wollen wir Innovation, Zusammenarbeit und Transparenz fördern und skalierbare, effiziente und robuste Lösungen gewährleisten. Jina AI ist mehr als nur ein Unternehmen; es ist eine Community, die sich dafür einsetzt, Unternehmen dabei zu unterstützen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein."])},mission_content2:e=>{const{normalize:n}=e;return n(["Im Mittelpunkt von Jina AI steht unsere Mission, das Portal zur multimodalen KI für eine vielfältige Kundschaft zu sein, von Power-Usern und Entwicklern bis hin zu Unternehmen. Wir glauben fest an die Leistungsfähigkeit von Open Source und widmen uns der Entwicklung fortschrittlicher, zugänglicher Tools für die KI-Community. Unsere Schlüsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Embedding-Tuning und Embedding-Serving, verkörpern unser Engagement für die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative streben wir danach, Innovation, Zusammenarbeit und Transparenz zu fördern und skalierbare, effiziente und robuste Lösungen sicherzustellen. Jina AI ist mehr als nur ein Unternehmen; Es handelt sich um eine Community, deren Ziel es ist, Unternehmen dabei zu unterstützen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein."])},mission_content3:e=>{const{normalize:n}=e;return n(["Unsere Mission bei Jina AI besteht darin, die Weiterentwicklung der multimodalen KI durch innovative Einbettungs- und Eingabeaufforderungstechnologien voranzutreiben und uns dabei insbesondere auf Bereiche wie die Verarbeitung natürlicher Sprache, Bild- und Videoanalyse sowie modalübergreifende Dateninteraktion zu konzentrieren. Diese Spezialisierung ermöglicht es uns, einzigartige Lösungen bereitzustellen, die komplexe Daten aus mehreren Quellen in umsetzbare Erkenntnisse und bahnbrechende Anwendungen umwandeln."])},mit_report_title:e=>{const{normalize:n}=e;return n(["Multimodal: die neue Grenze der KI"])},mit_techreview:e=>{const{normalize:n}=e;return n(["MIT Technology Review"])},numfocusCaption:e=>{const{normalize:n}=e;return n(["Spendet ab 2022 regelmäßig jeden Monat."])},office:e=>{const{normalize:n}=e;return n(["Unsere Büros"])},otherProjectsCaption:e=>{const{normalize:n}=e;return n(["Über Github Sponsorship über 3.000 US-Dollar gespendet."])},our_answer:e=>{const{normalize:n}=e;return n(["Auf jeden Fall, Yann. Wir sind dabei und bauen Brücken in eine multimodale KI-Zukunft!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:n}=e;return n(["Hat eine einmalige Spende in Höhe von 10.000 US-Dollar geleistet und mehrere PyCon-Veranstaltungen gesponsert, darunter in Deutschland, Italien, China und den USA."])},sefo:{layer0:e=>{const{normalize:n}=e;return n(["Endbenutzeranwendungen"])},layer1:e=>{const{normalize:n}=e;return n(["RAG / Orchestrierung"])},layer3:e=>{const{normalize:n}=e;return n(["GPU / Mobil / Edge / lokales Computing"])}},segmentFaultCaption:e=>{const{normalize:n}=e;return n(["Hat eine einmalige Spende in Höhe von 6.000 US-Dollar geleistet."])},show_position:e=>{const{normalize:n}=e;return n(["Wie sucht man nach Stiftungspositionen im Ökosystem?"])},stats_1:e=>{const{normalize:n}=e;return n(["Jina AI wurde im Februar 2020 gegründet und hat sich schnell zu einem globalen Pionier der multimodalen KI-Technologie entwickelt. Innerhalb eines beeindruckenden Zeitrahmens von 20 Monaten haben wir erfolgreich 37,5 Millionen US-Dollar eingesammelt und damit unsere starke Position in der KI-Branche unterstrichen. Unsere bahnbrechende Technologie, Open-Source auf GitHub, hat über 40.000 Entwicklern auf der ganzen Welt die Möglichkeit gegeben, anspruchsvolle multimodale Anwendungen nahtlos zu erstellen und bereitzustellen."])},stats_2:e=>{const{normalize:n}=e;return n(["Im Jahr 2023 haben wir erhebliche Fortschritte bei der Weiterentwicklung von Tools zur KI-Generierung gemacht, die auf multimodaler Technologie basieren. Von dieser Innovation haben über 250.000 Benutzer weltweit profitiert und eine Vielzahl einzigartiger Geschäftsanforderungen erfüllt. Von der Erleichterung des Geschäftswachstums über die Verbesserung der betrieblichen Effizienz bis hin zur Kostenoptimierung setzt sich Jina AI dafür ein, Unternehmen zu befähigen, im multimodalen Zeitalter hervorragende Leistungen zu erbringen."])},stats_4:e=>{const{normalize:n}=e;return n(['Jina AI wurde 2020 in Berlin gegründet und ist ein führendes Unternehmen für Such-KI. Wir stellen die <span class="text-primary text-bold">Search Foundation</span> bereit, den Kern für GenAI und multimodale Anwendungen. Unsere Mission ist es, Unternehmen und Entwicklern dabei zu helfen, multimodale Daten mit einer besseren Suche zur Wertschöpfung freizusetzen. Als kommerzielles Open-Source-Unternehmen mögen wir offene Innovation.'])},stats_v1:e=>{const{normalize:n}=e;return n(["Suche/account"])},subtitle:e=>{const{normalize:n}=e;return n(["Revolutionierung der Inhaltserstellung durch KI-generierte Lösungen, um unendliche Möglichkeiten zu erschließen. Die Zukunft KI-generierter Inhalte gestalten und die menschliche Kreativität fördern."])},sues_und_sauer:e=>{const{normalize:n}=e;return n(["Süẞ & Sauer"])},sues_und_sauer_tooltip:e=>{const{normalize:n}=e;return n(["Süß-Sauer, ein beliebter (aber stereotyper) Geschmack in der deutsch-chinesischen Küche, bedeutet süß und sauer. Es ist eine Metapher für die Höhen und Tiefen des Startup-Lebens."])},sz:e=>{const{normalize:n}=e;return n(["Shenzhen, China"])},sz_address:e=>{const{normalize:n}=e;return n(["402, Etage 4, Fu'an Technology Building, Shenzhen Nanshan, China"])},team:e=>{const{normalize:n}=e;return n(["Im Portal von Jina AI"])},team_content1:e=>{const{normalize:n}=e;return n(["Von verschiedenen Orten der Welt aus gestalten wir die Zukunft der KI. Unsere unterschiedlichen Perspektiven bereichern unsere Arbeit und bringen Innovationen hervor. In diesem Portal leben wir unsere Individualität und verfolgen leidenschaftlich unsere Träume. Willkommen im Portal der KI-Zukunft."])},team_join:e=>{const{normalize:n}=e;return n(["Begleiten Sie uns"])},team_size:e=>{const{normalize:n}=e;return n(["Auf diesen Fotos sind unsere ehemaligen Kollegen und Praktikanten zu sehen – wir freuen uns über jeden einzelnen von ihnen."])},technologies:e=>{const{normalize:n}=e;return n(["Technologien"])},title:e=>{const{normalize:n}=e;return n(["Über Jina AI"])},title0:e=>{const{normalize:n}=e;return n(["Die Zukunft"])},title1:e=>{const{normalize:n}=e;return n(["Beginnt"])},title2:e=>{const{normalize:n}=e;return n(["Hier"])},title3:e=>{const{normalize:n}=e;return n(["Beginnt hier"])},understand_our_strength:e=>{const{normalize:n}=e;return n(["Verstehen Sie unsere Stärke"])},understand_our_view2:e=>{const{normalize:n}=e;return n(["Verstehen Sie die Grundlagen der Suche"])},users:e=>{const{normalize:n}=e;return n(["registrierte Benutzer"])},value:e=>{const{normalize:n}=e;return n(["Unser Wert"])},value_content1:e=>{const{normalize:n}=e;return n(["Offenheit fördert Innovation und Zusammenarbeit. Wir unterstützen diese Idee nicht nur – wir leben sie. Wir haben unsere Modelle und Projekte als Open Source veröffentlicht und teilen unser Fachwissen mit der Welt. Und wir gehen noch weiter: Von unserer frühen Unterstützung für FastAPI bis hin zur aktiven Unterstützung der Linux Foundation und der Python Software Foundation fühlen wir uns zutiefst verpflichtet, etwas zurückzugeben."])},vision:e=>{const{normalize:n}=e;return n(["Unsere Aufgabe"])},vision_content1:e=>{const{normalize:n}=e;return n(["Inspiriert von Yann LeCuns Einsicht, dass „"])},vision_content3:e=>{const{normalize:n}=e;return n(['Die Zukunft der KI ist <span class="text-primary text-bold">multimodal</span>, und wir sind ein Teil davon. Wir sind uns bewusst, dass Unternehmen bei der Nutzung multimodaler Daten vor Herausforderungen stehen. Als Reaktion darauf engagieren wir uns in der <span class="text-primary text-bold">Search Foundation</span>, um Unternehmen und Entwicklern dabei zu helfen, besser zu suchen und multimodale Daten für das Unternehmenswachstum zu nutzen.'])},yannlecun_quote:e=>{const{normalize:n}=e;return n(["Ein künstliches Intelligenzsystem, das allein auf Wörter und Sätze trainiert wird, wird niemals annähernd das menschliche Verständnis erreichen."])}},api_general_faq:{answer1:e=>{const{normalize:n}=e;return n(["Ja, derselbe API-Schlüssel ist für alle Suchgrundlagenprodukte von Jina AI gültig. Dies umfasst die APIs zum Einbetten, Neuranking, Lesen und Feinabstimmen, wobei die Token zwischen allen Diensten geteilt werden."])},answer12:e=>{const{normalize:n}=e;return n(["Wir halten uns an strenge Datenschutzrichtlinien und verwenden keine Benutzereingabedaten zum Training unserer Modelle."])},answer3:e=>{const{normalize:n}=e;return n(["Ja, die Token-Nutzung kann auf der Registerkarte „Token kaufen“ durch Eingabe Ihres API-Schlüssels überwacht werden, sodass Sie den Nutzungsverlauf und die verbleibenden Token anzeigen können."])},answer4:e=>{const{normalize:n}=e;return n(["Wenn Sie einen aufgeladenen Schlüssel verloren haben und ihn zurückholen möchten, wenden Sie sich bitte mit Ihrer registrierten E-Mail-Adresse an den Support von jina.ai, um Hilfe zu erhalten."])},answer5:e=>{const{normalize:n}=e;return n(["Nein, unsere API-Schlüssel haben kein Ablaufdatum. Wenn Sie jedoch den Verdacht haben, dass Ihr Schlüssel kompromittiert wurde und Sie ihn zurückziehen oder seine Token auf einen neuen Schlüssel übertragen möchten, wenden Sie sich bitte an unser Support-Team, um Hilfe zu erhalten."])},answer6:e=>{const{normalize:n}=e;return n(["Dies liegt daran, dass unsere serverlose Architektur bestimmte Modelle in Zeiten geringer Nutzung entlastet. Die erste Anfrage aktiviert oder „wärmt“ das Modell auf, was einige Sekunden dauern kann. Nach dieser ersten Aktivierung werden nachfolgende Anfragen viel schneller bearbeitet."])},question1:e=>{const{normalize:n}=e;return n(["Kann ich denselben API-Schlüssel zum Einbetten, Neuranking, für Reader und zur Feinabstimmung von APIs verwenden?"])},question12:e=>{const{normalize:n}=e;return n(["Werden Benutzereingabedaten zum Training Ihrer Modelle verwendet?"])},question3:e=>{const{normalize:n}=e;return n(["Kann ich die Token-Nutzung meines API-Schlüssels überwachen?"])},question4:e=>{const{normalize:n}=e;return n(["Was soll ich tun, wenn ich meinen API-Schlüssel vergesse?"])},question5:e=>{const{normalize:n}=e;return n(["Laufen API-Schlüssel ab?"])},question6:e=>{const{normalize:n}=e;return n(["Warum ist die erste Anfrage bei manchen Modellen langsam?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zu APIs"])}},autotune:{base_model:e=>{const{normalize:n}=e;return n(["Basismodell zum Feintuning"])},check_data:e=>{const{normalize:n}=e;return n(["Synthetische Daten herunterladen"])},check_model:e=>{const{normalize:n}=e;return n(["Feinabgestimmtes Modell herunterladen"])},data_size:e=>{const{normalize:n}=e;return n(["Synthetische Daten generiert"])},description:e=>{const{normalize:n}=e;return n(["Erhalten Sie fein abgestimmte Einbettungen für jede gewünschte Domäne."])},description_long:e=>{const{normalize:n}=e;return n(["Sagen Sie uns einfach, in welchem ​​Bereich Ihre Einbettungen herausragend sein sollen, und wir liefern automatisch ein gebrauchsfertiges, fein abgestimmtes Einbettungsmodell für diesen Bereich."])},does_it_work_tho:e=>{const{normalize:n}=e;return n(["Aber funktioniert es trotzdem?"])},does_it_work_tho_explain:e=>{const{normalize:n}=e;return n(["Die automatische Feinabstimmung verspricht wie durch Zauberhand feinabgestimmte Einbettungen für jede gewünschte Domäne. Aber funktioniert das wirklich? Das ist durchaus fraglich. Um das herauszufinden, haben wir es an einer Vielzahl von Domänen und Basismodellen getestet. Sehen Sie sich unten die Rosinenpickerei und die Zitronenpickerei an."])},domain_instruction:e=>{const{normalize:n}=e;return n(["Domänenanweisung"])},embedding_provider:e=>{const{normalize:n}=e;return n(["Wählen Sie ein Basis-Einbettungsmodell"])},eval_evaluation:e=>{const{normalize:n}=e;return n(["Validierung"])},eval_map:e=>{const{normalize:n}=e;return n(["KARTE"])},eval_mrr:e=>{const{normalize:n}=e;return n(["MRR"])},eval_ndcg:e=>{const{normalize:n}=e;return n(["NDCG"])},eval_performance_before_after:e=>{const{normalize:n}=e;return n(["Leistung im synthetischen Validierungssatz vor und nach der Feinabstimmung"])},eval_syntheticDataSize:e=>{const{normalize:n}=e;return n(["Gesamt"])},eval_test:e=>{const{normalize:n}=e;return n(["Echte Daten zum Testen"])},eval_training:e=>{const{normalize:n}=e;return n(["Ausbildung"])},faq_v1:{answer1:e=>{const{normalize:n}=e;return n(["Die Funktion befindet sich derzeit in der Betaphase und kostet 1 Mio. Token pro fein abgestimmtem Modell. Sie können Ihren vorhandenen API-Schlüssel aus der Embedding/Reranker-API verwenden, wenn dieser über genügend Token verfügt, oder Sie können einen neuen API-Schlüssel erstellen, der 1 Mio. kostenlose Token enthält."])},answer10:e=>{const{normalize:n}=e;return n(["Derzeit nicht. Beachten Sie, dass sich diese Funktion noch in der Betaphase befindet. Die öffentliche Speicherung der fein abgestimmten Modelle und synthetischen Daten im Hugging Face-Modell-Hub hilft uns und der Community, die Qualität des Trainings zu bewerten. In Zukunft planen wir, eine private Speicheroption anzubieten."])},answer11:e=>{const{normalize:n}=e;return n(["Da alle feinabgestimmten Modelle auf Hugging Face hochgeladen werden, können Sie über SentenceTransformers darauf zugreifen, indem Sie einfach den Modellnamen angeben."])},answer12:e=>{const{normalize:n}=e;return n(["Bitte überprüfen Sie Ihren Spam-Ordner. Wenn Sie ihn immer noch nicht finden können, wenden Sie sich bitte über die von Ihnen angegebene E-Mail-Adresse an unser Support-Team."])},answer2:e=>{const{normalize:n}=e;return n(["Sie müssen keine Trainingsdaten bereitstellen. Beschreiben Sie einfach Ihre Zieldomäne (die Domäne, für die die fein abgestimmten Einbettungen optimiert werden sollen) in natürlicher Sprache oder verwenden Sie eine URL als Referenz. Unser System generiert dann synthetische Daten zum Trainieren des Modells."])},answer3:e=>{const{normalize:n}=e;return n(["Etwa 30 Minuten."])},answer4:e=>{const{normalize:n}=e;return n(["Die feinabgestimmten Modelle und synthetischen Daten werden öffentlich im Hugging Face-Modell-Hub gespeichert."])},answer5:e=>{const{normalize:n}=e;return n(["Das System verwendet die Reader-API, um den Inhalt von der URL abzurufen. Anschließend analysiert es den Inhalt, um den Ton und die Domäne zusammenzufassen, die es als Richtlinien zum Generieren synthetischer Daten verwendet. Daher sollte die URL öffentlich zugänglich und repräsentativ für die Zieldomäne sein."])},answer6:e=>{const{normalize:n}=e;return n(["Ja, Sie können ein Modell für eine andere Sprache als Englisch optimieren. Das System erkennt automatisch die Sprache Ihrer Domänenanweisungen und generiert entsprechend synthetische Daten. Wir empfehlen außerdem, das entsprechende Basismodell für die Zielsprache auszuwählen. Wenn Sie beispielsweise eine deutsche Domäne als Ziel haben, sollten Sie als Basismodell „jina-embeddings-v2-base-de“ auswählen."])},answer7:e=>{const{normalize:n}=e;return n(["Nein, unsere Feinabstimmungs-API unterstützt nur Jina v2-Modelle."])},answer8:e=>{const{normalize:n}=e;return n(["Am Ende des Feinabstimmungsprozesses wertet das System das Modell anhand eines zurückgehaltenen Testsatzes aus und meldet Leistungsmesswerte. Sie erhalten eine E-Mail mit detaillierten Angaben zur Leistung vor/nach diesem Testsatz. Sie werden außerdem ermutigt, das Modell anhand Ihres eigenen Testsatzes auszuwerten, um seine Qualität sicherzustellen."])},answer9:e=>{const{normalize:n}=e;return n(["Das System generiert synthetische Daten, indem es die von Ihnen bereitgestellten Zieldomänenanweisungen mit den Argumenten der LLM-Agenten integriert. Es erzeugt harte negative Tripletts, die für das Training hochwertiger Einbettungsmodelle unerlässlich sind. Weitere Einzelheiten finden Sie in unserem kommenden Forschungspapier auf Arxiv."])},question1:e=>{const{normalize:n}=e;return n(["Wie viel kostet die Fine-Tuning-API?"])},question10:e=>{const{normalize:n}=e;return n(["Kann ich meine fein abgestimmten Modelle und synthetischen Daten vertraulich behandeln?"])},question11:e=>{const{normalize:n}=e;return n(["Wie kann ich das feinabgestimmte Modell verwenden?"])},question12:e=>{const{normalize:n}=e;return n(["Ich habe die E-Mail mit den Bewertungsergebnissen nie erhalten. Was soll ich tun?"])},question2:e=>{const{normalize:n}=e;return n(["Welche Eingaben muss ich machen? Muss ich Trainingsdaten angeben?"])},question3:e=>{const{normalize:n}=e;return n(["Wie lange dauert die Feinabstimmung eines Modells?"])},question4:e=>{const{normalize:n}=e;return n(["Wo werden die feinabgestimmten Modelle gespeichert?"])},question5:e=>{const{normalize:n}=e;return n(["Wenn ich eine Referenz-URL angebe, wie verwendet das System diese?"])},question6:e=>{const{normalize:n}=e;return n(["Kann ich ein Modell für eine bestimmte Sprache optimieren?"])},question7:e=>{const{normalize:n}=e;return n(["Kann ich Nicht-Jina-Einbettungen, z. B. bge-M3, feinabstimmen?"])},question8:e=>{const{normalize:n}=e;return n(["Wie stellen Sie die Qualität der optimierten Modelle sicher?"])},question9:e=>{const{normalize:n}=e;return n(["Wie generieren Sie synthetische Daten?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zur automatischen Feinabstimmung"])}},find_on_hf:e=>{const{normalize:n}=e;return n(["Liste der fein abgestimmten Modelle"])},temporarily_unavailable:e=>{const{normalize:n}=e;return n(["Vorübergehend nicht verfügbar. Wir aktualisieren unser automatisches Feinabstimmungssystem, um Ihnen einen besseren Service bieten zu können. Bitte schauen Sie später noch einmal vorbei."])},test_on:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Getestet an ",r(i("_dataSize"))," Zufallsstichproben aus ",r(i("_dataName"))])},test_performance_before_after:e=>{const{normalize:n}=e;return n(["Leistung im zurückgehaltenen Testsatz vor und nach der Feinabstimmung"])},title:e=>{const{normalize:n}=e;return n(["API für automatische Feinabstimmung"])},total_improve:e=>{const{normalize:n}=e;return n(["Durchschnittliche Verbesserung"])},usage:e=>{const{normalize:n}=e;return n(["Verwendung"])},what_is:e=>{const{normalize:n}=e;return n(["Was ist automatische Feinabstimmung?"])},what_is_answer_long:e=>{const{normalize:n}=e;return n(["Durch Feinabstimmung können Sie ein vorab trainiertes Modell nehmen und es an eine bestimmte Aufgabe oder Domäne anpassen, indem Sie es an einem neuen Datensatz trainieren. In der Praxis ist es für viele Benutzer nicht einfach, effektive Trainingsdaten zu finden. Für ein effektives Training ist mehr erforderlich, als einfach nur Roh-PDFs und HTMLs in das Modell einzugeben. Und es ist schwer, es richtig zu machen. Die automatische Feinabstimmung löst dieses Problem, indem sie mithilfe einer erweiterten LLM-Agent-Pipeline automatisch effektive Trainingsdaten generiert und das Modell innerhalb eines ML-Workflows feinabstimmt. Sie können es sich als eine Kombination aus synthetischer Datengenerierung und AutoML vorstellen. Sie müssen also nur Ihre Zieldomäne in natürlicher Sprache beschreiben und unser System den Rest erledigen lassen."])}},best_banner:{description:e=>{const{normalize:n}=e;return n(["Vom Blog-Artikel zum Banner, ohne eigene Prompts!"])},example_description:e=>{const{normalize:n}=e;return n(["Alice wurde es langsam sehr leid, neben ihrer Schwester am Ufer zu sitzen und nichts zu tun zu haben: Ein- oder zweimal hatte sie in das Buch geguckt, das ihre Schwester las, aber es enthielt weder Bilder noch Gespräche. „Und was nützt ein Buch“, dachte Alice, „ohne Bilder oder Gespräche?“ So überlegte sie in Gedanken (so gut sie konnte, denn der heiße Tag machte sie sehr schläfrig und dumm), ob das Vergnügen, eine Gänseblümchenkette zu machen, die Mühe wert wäre, aufzustehen und die Gänseblümchen zu pflücken, als plötzlich ein weißes Kaninchen mit rosa Augen dicht an ihr vorbeilief."])},example_title:e=>{const{normalize:n}=e;return n(["Alices Abenteuer im Wunderland – Kapitel 1"])}},beta:e=>{const{normalize:n}=e;return n(["Beta"])},billing_general_faq:{answer10:e=>{const{normalize:n}=e;return n(["Wir bieten neuen Benutzern eine einladende kostenlose Testversion an, die eine Million Token zur Verwendung mit jedem unserer Modelle umfasst und durch einen automatisch generierten API-Schlüssel erleichtert wird. Sobald das kostenlose Token-Limit erreicht ist, können Benutzer über die Registerkarte „Token kaufen“ ganz einfach zusätzliche Token für ihre API-Schlüssel erwerben."])},answer13:e=>{const{normalize:n}=e;return n(["Nein, für fehlgeschlagene Anfragen werden keine Token abgezogen."])},answer14:e=>{const{normalize:n}=e;return n(["Zahlungen werden über Stripe abgewickelt und unterstützen zu Ihrer Bequemlichkeit eine Vielzahl von Zahlungsmethoden, darunter Kreditkarten, Google Pay und PayPal."])},answer15:e=>{const{normalize:n}=e;return n(["Ja, beim Kauf von Tokens wird eine Rechnung an die E-Mail-Adresse ausgestellt, die mit Ihrem Stripe-Konto verknüpft ist."])},answer9:e=>{const{normalize:n}=e;return n(["Unser Preismodell basiert auf der Gesamtzahl der verarbeiteten Token und bietet Benutzern die Flexibilität, diese Token auf eine beliebige Anzahl von Sätzen zu verteilen. Dies bietet eine kostengünstige Lösung für unterschiedliche Textanalyseanforderungen."])},question10:e=>{const{normalize:n}=e;return n(["Gibt es eine kostenlose Testversion für neue Benutzer?"])},question13:e=>{const{normalize:n}=e;return n(["Werden für fehlgeschlagene Anfragen Token berechnet?"])},question14:e=>{const{normalize:n}=e;return n(["Welche Zahlungsmethoden werden akzeptiert?"])},question15:e=>{const{normalize:n}=e;return n(["Ist eine Rechnungsstellung für Token-Käufe verfügbar?"])},question9:e=>{const{normalize:n}=e;return n(["Erfolgt die Abrechnung nach der Anzahl der Sätze bzw. Anfragen?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zur Abrechnung"])}},blog_tags:{all:e=>{const{normalize:n}=e;return n(["Alle"])},events:e=>{const{normalize:n}=e;return n(["Ereignis"])},featured:e=>{const{normalize:n}=e;return n(["Hervorgehoben"])},insights:e=>{const{normalize:n}=e;return n(["Meinung"])},"knowledge-base":e=>{const{normalize:n}=e;return n(["Wissen"])},latest:e=>{const{normalize:n}=e;return n(["Neueste"])},press:e=>{const{normalize:n}=e;return n(["Pressemitteilung"])},releases:e=>{const{normalize:n}=e;return n(["Software-Aktualisierung"])},"tech-blog":e=>{const{normalize:n}=e;return n(["Tech-Blog"])}},cclicence:{api_free_trial:e=>{const{normalize:n}=e;return n(["Kostenloser API-Schlüssel"])},api_paid:e=>{const{normalize:n}=e;return n(["Kostenpflichtiger API-Schlüssel"])},api_paid_or_free:e=>{const{normalize:n}=e;return n(["Verwenden Sie einen kostenpflichtigen API-Schlüssel oder einen kostenlosen Testschlüssel?"])},are_you:e=>{const{normalize:n}=e;return n(["Bist du:"])},commercial_contact_sales:e=>{const{normalize:n}=e;return n(["Dies ist kommerziell. Kontaktieren Sie unser Verkaufsteam."])},contact_sales_for_licensing:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie für Lizenzierungen unser Vertriebsteam."])},csp_user:e=>{const{normalize:n}=e;return n(["Verwenden Sie unsere offiziellen Modellbilder auf AWS und Azure?"])},educational_teaching:e=>{const{normalize:n}=e;return n(["Eine Bildungseinrichtung, die es für die Lehre nutzt?"])},for_profit_internal_use:e=>{const{normalize:n}=e;return n(["Ein gewinnorientiertes Unternehmen, das es intern verwendet?"])},free_use:e=>{const{normalize:n}=e;return n(["Die Modelle können Sie frei verwenden."])},government_public_services:e=>{const{normalize:n}=e;return n(["Eine Regierungsbehörde, die es für öffentliche Dienste nutzt?"])},is_use_commercial:e=>{const{normalize:n}=e;return n(["Ist Ihre Nutzung kommerziell?"])},may_be_commercial_contact:e=>{const{normalize:n}=e;return n(["Dies kann kommerziell sein. Bitte kontaktieren Sie uns zur Klärung."])},no:e=>{const{normalize:n}=e;return n(["NEIN"])},no1:e=>{const{normalize:n}=e;return n(["NEIN"])},no2:e=>{const{normalize:n}=e;return n(["NEIN"])},no3:e=>{const{normalize:n}=e;return n(["NEIN"])},no_restrictions:e=>{const{normalize:n}=e;return n(["Keine Einschränkungen. Nutzung gemäß Ihrem aktuellen Vertrag."])},no_restrictions_apply:e=>{const{normalize:n}=e;return n(["Es gelten keine Einschränkungen."])},non_commercial_free_use:e=>{const{normalize:n}=e;return n(["Dies ist nicht kommerziell. Sie können die Modelle frei verwenden."])},non_profit_ngo_mission:e=>{const{normalize:n}=e;return n(["Eine gemeinnützige Organisation oder NGO nutzt es für Ihre Mission?"])},not_sure:e=>{const{normalize:n}=e;return n(["Nicht sicher"])},personal_hobby_projects:e=>{const{normalize:n}=e;return n(["Verwenden Sie es für persönliche oder Hobbyprojekte?"])},product_service_sale:e=>{const{normalize:n}=e;return n(["Verwenden Sie es in einem Produkt oder einer Dienstleistung, die Sie verkaufen?"])},title:e=>{const{normalize:n}=e;return n(["CC BY-NC Lizenz Selbstcheck"])},trial_key_restrictions:e=>{const{normalize:n}=e;return n(["Der kostenlose Testschlüssel kann nur für nichtkommerzielle Zwecke verwendet werden. Für die kommerzielle Nutzung erwerben Sie bitte ein kostenpflichtiges Paket."])},typically_non_commercial_check:e=>{const{normalize:n}=e;return n(["Dies ist normalerweise nicht kommerziell, aber fragen Sie uns, wenn Sie unsicher sind."])},typically_non_commercial_free_use:e=>{const{normalize:n}=e;return n(["Dies erfolgt in der Regel nicht kommerziell. Sie können die Modelle frei verwenden."])},using_api_or_cloud:e=>{const{normalize:n}=e;return n(["Verwenden Sie unsere offizielle API oder offiziellen Images auf Azure oder AWS?"])},using_cc_by_nc_models:e=>{const{normalize:n}=e;return n(["Verwenden Sie diese Modelle?"])},yes:e=>{const{normalize:n}=e;return n(["Ja"])},yes1:e=>{const{normalize:n}=e;return n(["Ja"])},yes2:e=>{const{normalize:n}=e;return n(["Ja"])},yes3:e=>{const{normalize:n}=e;return n(["Ja"])}},classifier:{access:e=>{const{normalize:n}=e;return n(["Öffentlicher Zugang"])},access_explain:e=>{const{normalize:n}=e;return n(["Öffentliche Klassifikatoren können von jedem mit der <code>classifier_id</code> verwendet werden und ihre Nutzung verbraucht das Token-Kontingent des Anrufers und nicht Ihres. Auf private Klassifikatoren können nur Sie zugreifen."])},access_private:e=>{const{normalize:n}=e;return n(["Privat"])},access_public:e=>{const{normalize:n}=e;return n(["Öffentlich"])},api_delete:e=>{const{normalize:n}=e;return n(["Klassifikator löschen"])},api_delete_explain:e=>{const{normalize:n}=e;return n(["Löschen Sie einen Klassifikator anhand seiner ID."])},api_list:e=>{const{normalize:n}=e;return n(["Klassifikatoren auflisten"])},api_list_explain:e=>{const{normalize:n}=e;return n(["Listen Sie alle Klassifikatoren auf, die Sie erstellt haben."])},classifier_id:e=>{const{normalize:n}=e;return n(["Klassifikator-ID"])},classify_inputs:e=>{const{normalize:n}=e;return n(["Zu klassifizierende Eingaben"])},classify_inputs_explain:e=>{const{normalize:n}=e;return n(["Bei Text kann es sich um einen Satz mit bis zu 8192 Token handeln. Bei Bildern kann es eine URL oder ein Base64-codiertes Bild sein."])},classify_labels:e=>{const{normalize:n}=e;return n(["Kandidatenbezeichnungen"])},classify_labels_explain:e=>{const{normalize:n}=e;return n(["Eingaben werden in diese Labels kategorisiert. Es können bis zu 256 Klassen sein. Verwenden Sie semantische Labels für eine bessere Leistung."])},compare_table:{access_control:e=>{const{normalize:n}=e;return n(["Zugriffskontrolle"])},classifier_id_required:e=>{const{normalize:n}=e;return n(["Klassifikator-ID erforderlich"])},continuous_updates:e=>{const{normalize:n}=e;return n(["Kontinuierliche Modellaktualisierungen"])},default_solution:e=>{const{normalize:n}=e;return n(["Standardlösung für die allgemeine Klassifizierung"])},feature:e=>{const{normalize:n}=e;return n(["Besonderheit"])},few_shot:e=>{const{normalize:n}=e;return n(["Wenige Schüsse"])},image_multi_lingual_support:e=>{const{normalize:n}=e;return n(["Multimodaler und mehrsprachiger Support"])},labels_required_classify:e=>{const{normalize:n}=e;return n(["In /classify erforderliche Beschriftungen"])},labels_required_train:e=>{const{normalize:n}=e;return n(["In /train erforderliche Beschriftungen"])},max_classes:e=>{const{normalize:n}=e;return n(["Maximale Klassen"])},max_classifiers:e=>{const{normalize:n}=e;return n(["Maximale Klassifikatoren"])},max_inputs_request:e=>{const{normalize:n}=e;return n(["Maximale Eingaben pro Anfrage"])},max_token_length:e=>{const{normalize:n}=e;return n(["Maximale Tokenlänge pro Eingabe"])},na:e=>{const{normalize:n}=e;return n(["N / A"])},no:e=>{const{normalize:n}=e;return n(["NEIN"])},out_of_domain_solution:e=>{const{normalize:n}=e;return n(["Für Daten außerhalb der Domäne von v3/clip-v1 oder zeitkritische Daten"])},primary_use_case:e=>{const{normalize:n}=e;return n(["Primärer Anwendungsfall"])},semantic_labels_required:e=>{const{normalize:n}=e;return n(["Semantische Bezeichnungen erforderlich"])},state_management:e=>{const{normalize:n}=e;return n(["Zustandsverwaltung"])},stateful:e=>{const{normalize:n}=e;return n(["Zustandsbehaftet"])},stateless:e=>{const{normalize:n}=e;return n(["Staatenlos"])},token_count:e=>{const{normalize:n,interpolate:r,named:i}=e;return n([r(i("count"))," Token"])},training_data_required:e=>{const{normalize:n}=e;return n(["Trainingsdaten erforderlich"])},yes:e=>{const{normalize:n}=e;return n(["Ja"])},zero_shot:e=>{const{normalize:n}=e;return n(["Nullschuss"])}},create_classifier:e=>{const{normalize:n}=e;return n(["Neuer Few-Shot-Klassifikator"])},create_classifier_explain:e=>{const{normalize:n}=e;return n(["Erstellen Sie einen neuen Few-Shot-Klassifikator und trainieren Sie ihn mit beschrifteten Beispielen."])},description:e=>{const{normalize:n}=e;return n(["Zero-Shot- und Few-Shot-Klassifizierung für Bild und Text."])},description_long:e=>{const{normalize:n}=e;return n(["Probieren Sie unseren API-Spielplatz aus, um zu sehen, wie unser Klassifikator funktioniert."])},description_long1:e=>{const{normalize:n}=e;return n(["Hochleistungsfähiger Zero-Shot- und Few-Shot-Klassifikator für multimodale und mehrsprachige Daten."])},explain:e=>{const{normalize:n}=e;return n(["Der Classifier ist ein API-Dienst, der Text und Bilder mithilfe von Einbettungsmodellen (<code>jina-embeddings-v3</code> und <code>jina-clip-v1</code>) kategorisiert und sowohl die Zero-Shot-Klassifizierung ohne Trainingsdaten als auch das Few-Shot-Learning mit minimalen Beispielen unterstützt."])},faq_v1:{answer1:e=>{const{normalize:n}=e;return n(["Zero-Shot erfordert semantische Bezeichnungen während der Klassifizierung und keine während des Trainings, während Few-Shot Bezeichnungen während des Trainings, aber keine Klassifizierung erfordert. Das bedeutet, dass Zero-Shot besser für flexible, unmittelbare Klassifizierungsanforderungen geeignet ist, während Few-Shot besser für feste, domänenspezifische Kategorien geeignet ist, die sich im Laufe der Zeit entwickeln können."])},answer10:e=>{const{normalize:n}=e;return n(["Ja, Sie können zwischen <code>jina-embeddings-v3</code> für die Textklassifizierung (besonders gut für mehrsprachige Texte) und <code>jina-clip-v1</code> für die multimodale Klassifizierung wählen. Neue Modelle wie <code>jina-clip-v2</code> werden nach der Veröffentlichung automatisch über die API verfügbar sein."])},answer2:e=>{const{normalize:n}=e;return n(["<code>num_iters</code> steuert die Trainingsintensität – höhere Werte verstärken wichtige Beispiele, während niedrigere Werte die Auswirkung weniger zuverlässiger Daten minimieren. Es kann verwendet werden, um zeitbewusstes Lernen zu implementieren, indem aktuellen Beispielen höhere Iterationszahlen zugewiesen werden, was es für sich entwickelnde Datenmuster wertvoll macht."])},answer3:e=>{const{normalize:n}=e;return n(["Öffentliche Klassifikatoren können von jedem mit der <code>classifier_id</code> verwendet werden, wobei das eigene Token-Kontingent verbraucht wird. Benutzer können nicht auf Trainingsdaten oder Konfigurationen zugreifen und die Klassifizierungsanforderungen anderer nicht sehen, wodurch eine sichere gemeinsame Nutzung von Klassifikatoren ermöglicht wird."])},answer4:e=>{const{normalize:n}=e;return n(["Few-Shot erfordert 200-400 Trainingsbeispiele, um die Zero-Shot-Klassifizierung zu übertreffen. Obwohl es letztendlich eine höhere Genauigkeit erreicht, benötigt es diese Aufwärmphase, um wirksam zu werden. Zero-Shot bietet sofort eine konsistente Leistung ohne Trainingsdaten."])},answer5:e=>{const{normalize:n}=e;return n(["Ja – die API unterstützt mehrsprachige Abfragen mit <code>jina-embeddings-v3</code> und multimodale (Text/Bild-)Klassifizierung mit <code>jina-clip-v1</code>, mit Unterstützung für URL- oder Base64-codierte Bilder in derselben Anfrage."])},answer6:e=>{const{normalize:n}=e;return n(["Zero-Shot unterstützt 256 Klassen ohne Klassifikatorbegrenzung, während Few-Shot auf 16 Klassen und 16 Klassifikatoren beschränkt ist. Beide unterstützen 1.024 Eingaben pro Anfrage und 8.192 Token pro Eingabe."])},answer7:e=>{const{normalize:n}=e;return n(["Der Few-Shot-Modus ermöglicht kontinuierliche Aktualisierungen über den Endpunkt <code>/train</code> zur Anpassung an sich ändernde Datenmuster. Sie können bei Änderungen der Datenverteilung schrittweise neue Beispiele oder Klassen hinzufügen, ohne den gesamten Klassifizierer neu erstellen zu müssen."])},answer8:e=>{const{normalize:n}=e;return n(["Die API verwendet One-Pass-Online-Lernen – Trainingsbeispiele aktualisieren Klassifikatorgewichte, werden aber anschließend nicht gespeichert. Dies bedeutet, dass Sie keine historischen Trainingsdaten abrufen können, gewährleistet jedoch Datenschutz und Ressourceneffizienz."])},answer9:e=>{const{normalize:n}=e;return n(["Beginnen Sie mit Zero-Shot für sofortige Ergebnisse und wenn Sie eine flexible Klassifizierung mit semantischen Labels benötigen. Wechseln Sie zu Few-Shot, wenn Sie 200-400 Beispiele haben, eine höhere Genauigkeit benötigen oder domänenspezifische/zeitkritische Daten verarbeiten müssen."])},question1:e=>{const{normalize:n}=e;return n(["Was ist der Unterschied zwischen den Beschriftungen bei Zero-Shot und Few-Shot?"])},question10:e=>{const{normalize:n}=e;return n(["Kann ich für unterschiedliche Sprachen/Aufgaben unterschiedliche Modelle verwenden?"])},question2:e=>{const{normalize:n}=e;return n(["Wofür ist num_iters und wie sollte ich es verwenden?"])},question3:e=>{const{normalize:n}=e;return n(["Wie funktioniert das öffentliche Teilen von Klassifikatoren?"])},question4:e=>{const{normalize:n}=e;return n(["Wie viele Daten benötige ich, damit Few-Shot gut funktioniert?"])},question5:e=>{const{normalize:n}=e;return n(["Kann es mehrere Sprachen und sowohl Text als auch Bilder verarbeiten?"])},question6:e=>{const{normalize:n}=e;return n(["Welche absoluten Grenzen sollte ich kennen?"])},question7:e=>{const{normalize:n}=e;return n(["Wie gehe ich mit Datenänderungen im Laufe der Zeit um?"])},question8:e=>{const{normalize:n}=e;return n(["Was passiert mit meinen Trainingsdaten, nachdem ich sie gesendet habe?"])},question9:e=>{const{normalize:n}=e;return n(["Zero-Shot vs. Few-Shot – wann verwendet man was?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zum Klassifikator"])}},more:e=>{const{normalize:n}=e;return n(["mehr"])},num_iters:e=>{const{normalize:n}=e;return n(["Trainingsiterationen"])},num_iters_explain:e=>{const{normalize:n}=e;return n(["Steuert die Trainingsintensität – höhere Werte verbessern die Genauigkeit bei aktuellen Beispielen, erhöhen aber die Token-Kosten. Der Standardwert 10 funktioniert normalerweise gut."])},read_notes:e=>{const{normalize:n}=e;return n(["Versionshinweise lesen"])},select_classifier_or_model:e=>{const{normalize:n}=e;return n(["Wählen Sie einen Klassifikator oder ein Einbettungsmodell aus"])},task_classify:e=>{const{normalize:n}=e;return n(["Klassifizieren"])},task_classify_explain:e=>{const{normalize:n}=e;return n(["Verwenden Sie einen Zero-Shot- oder Few-Shot-Klassifikator, um Text oder Bilder in definierte Klassen zu kategorisieren."])},task_manage:e=>{const{normalize:n}=e;return n(["Verwalten"])},task_manage_explain:e=>{const{normalize:n}=e;return n(["Listen Sie Ihre Few-Shot-Klassifikatoren auf oder löschen Sie sie."])},task_select:e=>{const{normalize:n}=e;return n(["Wählen Sie eine Aufgabe aus"])},task_train:e=>{const{normalize:n}=e;return n(["Zug"])},task_train_explain:e=>{const{normalize:n}=e;return n(["Erstellen oder aktualisieren Sie einen Few-Shot-Klassifikator mit beschrifteten Beispielen."])},title:e=>{const{normalize:n}=e;return n(["Klassifizierer-API"])},train_inputs:e=>{const{normalize:n}=e;return n(["Trainingsdaten"])},train_inputs_explain:e=>{const{normalize:n}=e;return n(["Text- oder Bildbeispiele mit Beschriftungen zum Training. Sie können den Klassifikator im Laufe der Zeit schrittweise mit neuen Beispielen und Beschriftungen aktualisieren."])},train_label:e=>{const{normalize:n}=e;return n(["Etikett"])},what_is:e=>{const{normalize:n}=e;return n(["Was ist ein Klassifikator?"])},when_to_use_what:e=>{const{normalize:n}=e;return n(["Wann sollte Zero-Shot oder Few-Shot verwendet werden?"])},when_to_use_what_explain:e=>{const{normalize:n}=e;return n(["Verwenden Sie die Zero-Shot-Klassifizierung als Standardlösung für sofortige Ergebnisse bei allgemeinen Klassifizierungsaufgaben mit bis zu 256 Klassen, während sich das Few-Shot-Learning besser eignet, wenn Sie mit domänenspezifischen Daten außerhalb des Wissens der eingebetteten Modelle arbeiten oder wenn Sie zeitkritische Daten verarbeiten müssen, die kontinuierliche Modellaktualisierungen erfordern."])}},clip_as_service:{description:e=>{const{normalize:n}=e;return n(["Erzeugen Sie Embedding-Vektoren in konstanter länge für Bilder und Sätze mit CLIP"])}},cloud:{description:e=>{const{normalize:n}=e;return n(["Cloud-Hosting-Plattform für multimodale KI-Anwendungen"])}},contact_us_page:{agreement:e=>{const{normalize:n}=e;return n(["Mit dem Absenden bestätigen Sie, dass Sie mit der Verarbeitung Ihrer personenbezogenen Daten durch Jina AI wie im Abschnitt beschrieben einverstanden sind"])},anything_else:e=>{const{normalize:n}=e;return n(["Erzählen Sie uns mehr über Ihre Idee"])},cc_by_nc:e=>{const{normalize:n}=e;return n(["Kommerzielle Nutzung von CC BY-NC-Modellen beantragen"])},cc_by_nc_description:e=>{const{normalize:n}=e;return n(["Unsere neuesten Modelle sind in der Regel CC BY-NC-lizenziert. Für die kommerzielle Nutzung greifen Sie über unsere API, Azure Marketplace oder AWS SageMaker darauf zu. Aktivieren Sie dieses Kontrollkästchen für die lokale Nutzung außerhalb dieser Kanäle."])},company:e=>{const{normalize:n}=e;return n(["Organisation"])},company_size:e=>{const{normalize:n}=e;return n(["Größe der Organisation"])},company_website:e=>{const{normalize:n}=e;return n(["Website der Organisation"])},company_website_placeholder:e=>{const{normalize:n}=e;return n(["URL für die Homepage oder das LinkedIn-Profil Ihres Unternehmens"])},country:e=>{const{normalize:n}=e;return n(["Land"])},department:e=>{const{normalize:n}=e;return n(["Abteilung"])},description:e=>{const{normalize:n}=e;return n(["Erweitern Sie Ihr Geschäft mit Jina AI."])},faq:e=>{const{normalize:n}=e;return n(["FAQ"])},field_required:e=>{const{normalize:n}=e;return n(["Feld ist erforderlich"])},get_api_key:e=>{const{normalize:n}=e;return n(["Wie erhalte ich meinen API-Schlüssel?"])},impact_snapshots:e=>{const{normalize:n}=e;return n(["Impact-Schnappschüsse"])},invalid_date_format:e=>{const{normalize:n}=e;return n(["Ungültiges Datumsformat. Bitte verwenden Sie das Format TT-MM-JJJJ."])},invalid_email:e=>{const{normalize:n}=e;return n(["E-Mail ist ungültig"])},invalid_number:e=>{const{normalize:n}=e;return n(["Ungültige Nummer. Bitte geben Sie erneut ein"])},invalid_url:e=>{const{normalize:n}=e;return n(["Die URL ist ungültig"])},name:e=>{const{normalize:n}=e;return n(["Name"])},nc_check:e=>{const{normalize:n}=e;return n(["Benötige ich eine gewerbliche Lizenz?"])},other_questions:e=>{const{normalize:n}=e;return n(["Andere Fragen"])},preferred_models:e=>{const{normalize:n}=e;return n(["Für welche Modelle interessieren Sie sich?"])},preferred_products:e=>{const{normalize:n}=e;return n(["Für welche Produkte interessieren Sie sich?"])},priority:e=>{const{normalize:n}=e;return n(["Vorrangiger Support für zahlende Benutzer"])},private_statement:e=>{const{normalize:n}=e;return n(["Datenschutzerklärung"])},rate_limit:e=>{const{normalize:n}=e;return n(["Wie hoch ist die Ratenbegrenzung?"])},role:e=>{const{normalize:n}=e;return n(["Position"])},self_check:e=>{const{normalize:n}=e;return n(["Selbstcheck"])},shortcut:e=>{const{normalize:n}=e;return n(["Abkürzung"])},submit:e=>{const{normalize:n}=e;return n(["Einreichen"])},submit_failed:e=>{const{normalize:n}=e;return n(["Die Übermittlung ist fehlgeschlagen. Bitte versuchen Sie es später noch einmal."])},submit_success:e=>{const{normalize:n}=e;return n(["Vielen Dank für Ihre Einreichung. Wir kommen bald auf Sie zurück."])},subtitle:e=>{const{normalize:n}=e;return n(["Jina AI, ein führendes Unternehmen im Bereich multimodale KI, zeichnet sich durch Modell-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite Lösungen. Mit unserer Expertise in großen Sprachmodellen, Text-, Bild-, Video- und Audioverständnis, neuronaler Suche und generativer Kunst bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen."])},subtitle1:e=>{const{normalize:n}=e;return n(["Jina AI, ein führender Anbieter multimodaler KI, zeichnet sich durch Embedding-Tuning, Embedding-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite Lösungen. Mit unserer Expertise in großen Sprachmodellen, Text-, Bild-, Video- und Audioverständnis, neuronaler Suche und generativer KI bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen."])},subtitle2:e=>{const{normalize:n}=e;return n(["Entdecken Sie Jina AI, die Spitze der multimodalen KI. Wir zeichnen uns durch die Einbettung und Bereitstellung von Technologien aus und nutzen Cloud-native Lösungen wie Kubernetes für robuste, skalierbare Systeme. Wir sind auf große Sprachmodelle und Medienverarbeitung spezialisiert und bieten mit unserer fortschrittlichen KI-Expertise innovative, zukunftsfähige Geschäftsstrategien."])},title:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie unseren Vertrieb"])},trusted_by:e=>{const{normalize:n}=e;return n(["Unsere Partner"])},turn_on_volume:e=>{const{normalize:n}=e;return n(["Erhöhen Sie die Lautstärke"])},work_email:e=>{const{normalize:n}=e;return n(["Arbeits Email"])}},copy:e=>{const{normalize:n}=e;return n(["Kopieren"])},copy_to_clipboard_success:e=>{const{normalize:n}=e;return n(["In die Zwischenablage kopiert"])},dalle_flow:{description:e=>{const{normalize:n}=e;return n(["Ein Human-in-the-Loop-Workflow zum Erstellen von HD-Bildern aus Text"])}},"dev-gpt":{description:e=>{const{normalize:n}=e;return n(["Ihr virtuelles Entwicklungsteam"])}},disco_art:{description:e=>{const{normalize:n}=e;return n(["Erstellen Sie überzeugende Disco Diffusion-Kunstwerke in einer Codezeile"])}},doc_array:{description:e=>{const{normalize:n}=e;return n(["Die Datenstruktur für multimodale Daten"])}},download:e=>{const{normalize:n}=e;return n(["SOC 2 Typ 1-Bescheinigung herunterladen"])},embedding:{"11B tokens":e=>{const{normalize:n}=e;return n(["11 Milliarden"])},"11B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Ähnlich wie das Lesen aller englischsprachigen Artikel auf Wikipedia."])},"11B tokens_targetUser":e=>{const{normalize:n}=e;return n(["Produktionsbereitstellung"])},"1B tokens":e=>{const{normalize:n}=e;return n(["1 Milliarde"])},"1B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Ungefähr so, als würde man die Gesamtwerke Shakespeares und die komplette „Harry Potter“-Reihe lesen."])},"1B tokens_targetUser":e=>{const{normalize:n}=e;return n(["Prototypenentwicklung"])},"1M tokens":e=>{const{normalize:n}=e;return n(["1 Million"])},"1M tokens_intuition1":e=>{const{normalize:n}=e;return n(["Entspricht dem Lesen des gesamten Textes von „Der Hobbit“ und „Der große Gatsby“."])},"1M tokens_targetUser":e=>{const{normalize:n}=e;return n(["Spielzeug-Experiment"])},"1M_free":e=>{const{normalize:n}=e;return n(["1 Million kostenlose Token"])},"1M_free_description":e=>{const{normalize:n}=e;return n(["Genießen Sie Ihren neuen API-Schlüssel mit kostenlosen Tokens, keine Kreditkarte erforderlich."])},"2_5B tokens":e=>{const{normalize:n}=e;return n(["2,5 Milliarden Token"])},"2_5B tokens_intuition1":e=>{const{normalize:n}=e;return n([`Vergleichbar mit der 1.000-fachen Transkription jedes gesprochenen Wortes aus der Filmtrilogie „Der Herr der Ringe“.
`])},"3p_integration":e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Mit <b>",r(i("_numPartners")),"</b> Drittanbieterdiensten"])},"3p_integration_desc":e=>{const{normalize:n}=e;return n(["Integrieren Sie unsere Suchgrundlage in Ihre vorhandenen Dienste. Unsere Partner haben Konnektoren zu unserer API erstellt, sodass Sie unsere Modelle ganz einfach in Ihren Anwendungen verwenden können."])},"500M tokens":e=>{const{normalize:n}=e;return n(["500 Millionen Token"])},"500M tokens_intuition1":e=>{const{normalize:n}=e;return n(["Ähnlich wie das Anschauen aller Folgen der „Simpsons“ von Staffel 1 bis Staffel 30."])},"59B tokens":e=>{const{normalize:n}=e;return n(["59B-Token"])},"59B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Entspricht allen Tweets, die weltweit innerhalb eines Zeitraums von zwei Tagen gepostet werden."])},"5_5B tokens":e=>{const{normalize:n}=e;return n(["5,5 Milliarden Token"])},"5_5B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Entspricht dem Lesen des gesamten Textes der Encyclopaedia Britannica."])},Free1M:e=>{const{normalize:n}=e;return n(["1 Mio. Token"])},add_pair:e=>{const{normalize:n}=e;return n(["Neu"])},add_time_explain:e=>{const{normalize:n}=e;return n(["Das Datum, an dem dieses Modell zur Search Foundation hinzugefügt wurde."])},api_integration_short:e=>{const{normalize:n}=e;return n(["Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert."])},api_integrations:e=>{const{normalize:n}=e;return n(["API-Integrationen"])},api_key_update_message:e=>{const{normalize:n}=e;return n(["Wenn Sie Ihren alten API-Schlüssel ersetzen, wird der neue Schlüssel in der Benutzeroberfläche angezeigt, wenn Sie jina.ai besuchen. Zukünftige Aufladungen werden auf diesen neuen Schlüssel angewendet. Ihr alter Schlüssel bleibt gültig. Wenn Sie ihn also erneut verwenden möchten, bewahren Sie ihn bitte sicher auf."])},api_key_update_title:e=>{const{normalize:n}=e;return n(["API-Schlüssel ersetzen"])},auto_recharge:e=>{const{normalize:n}=e;return n(["Automatisches Aufladen bei niedrigem Tokenstand"])},auto_recharge_confirm_message:e=>{const{normalize:n}=e;return n(["Möchten Sie die automatische Aufladung wirklich deaktivieren? Dadurch werden automatische Aufladungen verhindert, wenn Ihr Token-Guthaben niedrig ist."])},auto_recharge_confirm_title:e=>{const{normalize:n}=e;return n(["Automatisches Aufladen deaktivieren"])},auto_recharge_description:e=>{const{normalize:n}=e;return n(["Empfohlen für einen unterbrechungsfreien Betrieb in der Produktion. Wenn Ihr Token-Guthaben unter dem von Ihnen festgelegten Schwellenwert liegt, laden wir Ihre Kreditkarte automatisch mit dem gleichen Betrag wie bei Ihrer letzten Aufladung auf. Wenn Sie bei der letzten Aufladung mehrere Pakete gekauft haben, laden wir nur ein Paket auf."])},auto_recharge_enable:e=>{const{normalize:n}=e;return n(["Sie haben die automatische Aufladung bei niedrigen Token aktiviert"])},auto_recharge_enable_message:e=>{const{normalize:n}=e;return n(["Um die automatische Aufladung zu aktivieren, kaufen Sie bitte ein Paket, bei dem die automatische Aufladung auf „True“ eingestellt ist."])},auto_recharge_enable_title:e=>{const{normalize:n}=e;return n(["Automatisches Aufladen aktivieren"])},auto_request:e=>{const{normalize:n}=e;return n(["Automatische Vorschau"])},auto_request_tooltip:e=>{const{normalize:n}=e;return n(["Automatische Vorschau der API-Antwort beim Ändern des Modells unter Verwendung von Hunderten von Token aus Ihrem API-Schlüssel. Deaktivieren Sie das manuelle Senden einer Anfrage, indem Sie auf „Antwort abrufen“ klicken."])},autostart:e=>{const{normalize:n}=e;return n(["Die Einbettung beginnt nach einer kurzen Verzögerung automatisch"])},base64_description:e=>{const{normalize:n}=e;return n(["Die Einbettungen werden als Base64-codierte Zeichenfolge zurückgegeben. Effizienter für die Übertragung."])},batch_job:e=>{const{normalize:n}=e;return n(["Batch-Job"])},batch_upload_hint:e=>{const{normalize:n}=e;return n(["Wir werden den API-Schlüssel und das untenstehende Modell verwenden, um die Dokumente zu verarbeiten."])},"bge-base-en-v1_5_description":e=>{const{normalize:n}=e;return n(["Ein robustes englisches Modell mit der richtigen Balance zwischen Leistung und Effizienz für den vielseitigen Einsatz."])},"bge-base-en_description":e=>{const{normalize:n}=e;return n(["Ein ausgewogenes englisches Modell, das für solide und zuverlässige Leistung ausgelegt ist."])},"bge-base-zh-v1_5_description":e=>{const{normalize:n}=e;return n(["Ein abgerundetes chinesisches Modell, das Leistungsfähigkeit und Effizienz in Einklang bringt."])},"bge-base-zh_description":e=>{const{normalize:n}=e;return n(["Ein vielseitiges chinesisches Modell, das Effizienz und robuste Leistung kombiniert."])},"bge-large-en-v1_5_description":e=>{const{normalize:n}=e;return n(["Ein leistungsstarkes englisches Modell, das erstklassige Einbettungen mit außergewöhnlicher Qualität bietet."])},"bge-large-en_description":e=>{const{normalize:n}=e;return n(["Ein leistungsstarkes englisches Modell, das für Einbettungen in Premiumqualität entwickelt wurde."])},"bge-large-zh-v1_5_description":e=>{const{normalize:n}=e;return n(["Ein chinesisches Modell mit hoher Kapazität, das hervorragende und detaillierte Einbettungen liefert."])},"bge-large-zh_description":e=>{const{normalize:n}=e;return n(["Ein leistungsstarkes chinesisches Modell, optimiert für Einbettungen der Spitzenklasse."])},"bge-m3_description":e=>{const{normalize:n}=e;return n(["Ein vielseitiges mehrsprachiges Modell mit umfangreichen Funktionen und hochwertigen Einbettungen."])},"bge-small-en-v1_5_description":e=>{const{normalize:n}=e;return n(["Ein optimiertes englisches Modell, das effiziente und qualitativ hochwertige Einbettungen liefert."])},"bge-small-en_description":e=>{const{normalize:n}=e;return n(["Ein effizientes englisches Modell für optimierte und genaue Einbettungen."])},"bge-small-zh-v1_5_description":e=>{const{normalize:n}=e;return n(["Ein kompaktes chinesisches Modell, das flinke und präzise Einbettungen ermöglicht."])},"bge-small-zh_description":e=>{const{normalize:n}=e;return n(["Ein agiles chinesisches Modell für effiziente und präzise Einbettungen."])},binary_description:e=>{const{normalize:n}=e;return n(["Die Einbettungen werden als int8 gepackt. Viel effizienter für Speicherung, Suche und Übertragung."])},bulk:e=>{const{normalize:n}=e;return n(["Batch-Einbettung"])},bulk_embedding_failed:e=>{const{normalize:n}=e;return n(["Batch-Einbettungsauftrag konnte nicht erstellt werden"])},buy_more_quota:e=>{const{normalize:n}=e;return n(["Laden Sie diesen API-Schlüssel mit weiteren Token auf"])},buy_poster:e=>{const{normalize:n}=e;return n(["Kaufen Sie eine gedruckte Kopie"])},cancel_button:e=>{const{normalize:n}=e;return n(["Stornieren"])},click_upload_btn_above:e=>{const{normalize:n}=e;return n(["Klicken Sie oben auf die Schaltfläche „Hochladen“, um zu beginnen."])},code:e=>{const{normalize:n}=e;return n(["Code"])},colbert_dimensions_explain:e=>{const{normalize:n}=e;return n(["Die Dimensionsgröße der Einbettung pro Token."])},compatible:e=>{const{normalize:n}=e;return n(["Kompatibler Modus"])},compatible_explain:e=>{const{normalize:n}=e;return n(["Folgt demselben Anfrageformat wie unsere Texteinbettungsmodelle. So können Sie zwischen Modellen wechseln, ohne die Anfrage zu ändern. Beachten Sie, dass Bildeingaben in diesem Modus nicht unterstützt werden."])},cosine_similarity:e=>{const{normalize:n}=e;return n(["Kosinusähnlichkeit"])},debugging:e=>{const{normalize:n}=e;return n(["Prüfen"])},delete_pair:e=>{const{normalize:n}=e;return n(["Löschen"])},description:e=>{const{normalize:n,linked:r,type:i}=e;return n([r("landing_page.embedding_desc1",void 0,i)])},dimensions:e=>{const{normalize:n}=e;return n(["Ausgabedimensionen"])},dimensions_error:e=>{const{normalize:n}=e;return n(["Die Dimensionsgröße muss zwischen 1 und 1024 liegen."])},dimensions_explain:e=>{const{normalize:n}=e;return n(["Kleinere Abmessungen lassen sich dank MRL einfacher speichern und abrufen und haben nur minimale Auswirkungen auf die Leistung."])},dimensions_warning:e=>{const{normalize:n}=e;return n(["Für eine effektive Aufgabenausführung empfehlen wir, die Dimensionsgröße über 32 zu halten."])},document:e=>{const{normalize:n}=e;return n(["Dokumentieren"])},download:e=>{const{normalize:n}=e;return n(["Herunterladen"])},edit_text1_text:e=>{const{normalize:n}=e;return n(["Linken Text bearbeiten"])},edit_text2_text:e=>{const{normalize:n}=e;return n(["Bearbeiten Sie den richtigen Text"])},embedding_done:e=>{const{normalize:n,interpolate:r,named:i}=e;return n([r(i("_Count"))," Sätze erfolgreich eingebettet."])},embedding_none_description:e=>{const{normalize:n}=e;return n(["Verwenden Sie kein Einbettungsmodell"])},example_inputs:e=>{const{normalize:n}=e;return n(["Beispieleingaben"])},faq:e=>{const{normalize:n,linked:r,type:i}=e;return n([r("contact_us_page.faq",void 0,i)])},faqs_v2:{answer0:e=>{const{normalize:n}=e;return n(["Detaillierte Informationen zu unseren Schulungsprozessen, Datenquellen und Auswertungen finden Sie in unserem technischen Bericht, der auf arXiv verfügbar ist."])},answer1:e=>{const{normalize:n}=e;return n(["Jeder Benutzer darf bis zu 100 Anfragen pro Sekunde stellen, was 204.800 Eingabesätzen pro Sekunde entspricht."])},answer17:e=>{const{normalize:n}=e;return n(["Wir entwickeln derzeit multimodale Einbettungen, die Text, Bilder und Audio gemeinsam verarbeiten. Updates werden bald bekannt gegeben!"])},answer18:e=>{const{normalize:n}=e;return n(["Bei Fragen zur Feinabstimmung unserer Modelle mit spezifischen Daten kontaktieren Sie uns bitte, um Ihre Anforderungen zu besprechen. Wir sind offen dafür, herauszufinden, wie unsere Modelle an Ihre Bedürfnisse angepasst werden können."])},answer19:e=>{const{normalize:n}=e;return n(["Ja, unsere Dienste sind auf dem AWS-Marktplatz verfügbar und wir sind dabei, auf die Azure- und GCP-Marktplätze zu expandieren. Wenn Sie besondere Anforderungen haben, kontaktieren Sie uns bitte unter sales AT jina.ai."])},answer3:e=>{const{normalize:n}=e;return n(["Unsere Modelle unterstützen Englisch, Deutsch, Spanisch, Chinesisch und verschiedene Programmiersprachen. Weitere Einzelheiten finden Sie in unserer Publikation zu bilingualen Modellen."])},answer4:e=>{const{normalize:n}=e;return n(["Unsere Modelle ermöglichen eine Eingabelänge von bis zu 8192 Token, was deutlich höher ist als bei den meisten anderen Modellen. Ein Token kann von einem einzelnen Zeichen wie „a“ bis zu einem ganzen Wort wie „apple“ reichen. Die Gesamtzahl der eingebbaren Zeichen hängt von der Länge und Komplexität der verwendeten Wörter ab. Diese erweiterte Eingabefähigkeit ermöglicht unseren jina-embeddings-v2-Modellen eine umfassendere Textanalyse und eine höhere Genauigkeit beim Kontextverständnis, insbesondere bei umfangreichen Textdaten."])},answer5:e=>{const{normalize:n}=e;return n(["Ein einzelner API-Aufruf kann bis zu 2048 Sätze oder Texte verarbeiten und ermöglicht so eine umfassende Textanalyse in einer Anfrage."])},answer6:e=>{const{normalize:n}=e;return n(["Sie können entweder <code>url</code> oder <code>bytes</code> im Feld <code>input</code> der API-Anfrage verwenden. Geben Sie für <code>url</code> die URL des Bildes an, das Sie verarbeiten möchten. Für <code>bytes</code> kodieren Sie das Bild im Base64-Format und schließen Sie es in die Anfrage ein. Das Modell gibt die Einbettungen des Bildes in der Antwort zurück."])},answer7:e=>{const{normalize:n}=e;return n(["Laut MTEB-Bestenliste konkurriert unser Basismodell eng mit text-embedding-ada-002 von OpenAI und weist im Durchschnitt eine vergleichbare Leistung auf. Darüber hinaus zeichnet sich unser Basismodell bei mehreren Aufgaben aus, darunter Klassifizierung, Paarklassifizierung, Neubewertung und Zusammenfassung, und übertrifft damit das Modell von OpenAI."])},answer8:e=>{const{normalize:n}=e;return n(["Der Übergang wird rationalisiert, da unser API-Endpunkt https://api.jina.ai/v1/embeddings mit den Eingabe- und Ausgabe-JSON-Schemas des text-embeddings-ada-002-Modells von OpenAI übereinstimmt. Diese Kompatibilität stellt sicher, dass Benutzer das OpenAI-Modell problemlos durch unseres ersetzen können, wenn sie den Endpunkt von OpenAI verwenden."])},answer9:e=>{const{normalize:n}=e;return n([`Die Token werden basierend auf der Textlänge und der Bildgröße berechnet. Für Text in der Anfrage werden die Token auf die Standardweise gezählt. Für Bilder in der Anfrage werden die folgenden Schritte ausgeführt:
1. Kachelgröße: Jedes Bild wird in Kacheln der Größe 224 x 224 Pixel unterteilt.
2. Abdeckung: Die Anzahl der Kacheln, die erforderlich sind, um das Eingabebild vollständig abzudecken, wird berechnet. Auch wenn die Bildabmessungen nicht perfekt durch 224 teilbar sind, zählen wir Teilkacheln als vollständige Kacheln.
3. Gesamtzahl der Kacheln: Die Gesamtzahl der Kacheln, die das Bild abdecken, bestimmt die Kosten. Wenn ein Bild beispielsweise 500 x 500 Pixel groß ist, wird es von 3 x 3 Kacheln abgedeckt, was 9 Kacheln ergibt.
4. Kostenberechnung: Jede Kachel trägt zu den endgültigen Kosten der Bildverarbeitung bei. Die Kosten pro Kachel betragen 1000 Token.

Beispiel:
Für ein Bild mit den Abmessungen 500 x 500 Pixel:

• Das Bild wird in Kacheln mit 224 x 224 Pixeln unterteilt.
• Die Gesamtzahl der benötigten Kacheln beträgt 3 (horizontal) x 3 (vertikal) = 9 Kacheln.

• Die Kosten betragen 9*1000 = 9000 Token`])},question0:e=>{const{normalize:n}=e;return n(["Wie wurden die jina-embeddings-v2-Modelle trainiert?"])},question1:e=>{const{normalize:n}=e;return n(["Wie viele API-Anfragen kann ich pro Sekunde stellen?"])},question17:e=>{const{normalize:n}=e;return n(["Bieten Sie Modelle zum Einbetten von Bildern oder Audio an?"])},question18:e=>{const{normalize:n}=e;return n(["Können Jina Embedding-Modelle mit privaten oder Unternehmensdaten verfeinert werden?"])},question19:e=>{const{normalize:n}=e;return n(["Können Ihre Endpunkte privat auf AWS, Azure oder GCP gehostet werden?"])},question3:e=>{const{normalize:n}=e;return n(["Welche Sprachen unterstützen Ihre Modelle?"])},question4:e=>{const{normalize:n}=e;return n(["Was ist die maximale Länge für die Eingabe eines einzelnen Satzes?"])},question5:e=>{const{normalize:n}=e;return n(["Wie viele Sätze kann ich maximal in eine einzelne Anfrage einfügen?"])},question6:e=>{const{normalize:n}=e;return n(["Wie sende ich Bilder an das Modell jina-clip-v1?"])},question7:e=>{const{normalize:n}=e;return n(["Wie vergleichen sich Jina Embeddings-Modelle mit dem text-embedding-ada-002-Modell von OpenAI?"])},question8:e=>{const{normalize:n}=e;return n(["Wie nahtlos verläuft der Übergang von text-embedding-ada-002 von OpenAI zu Ihrer Lösung?"])},question9:e=>{const{normalize:n}=e;return n(["Wie werden Token bei Verwendung von jina-clip-v1 berechnet?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zu Einbettungen"])}},feature_8k1:e=>{const{normalize:n}=e;return n(["8192 Token-Länge"])},feature_8k_description1:e=>{const{normalize:n}=e;return n(["Pionierarbeit beim ersten Open-Source-Einbettungsmodell mit einer Länge von 8192 Token, das die Darstellung eines gesamten Kapitels in einem einzigen Vektor ermöglicht."])},feature_cheap:e=>{const{normalize:n}=e;return n(["20x günstiger"])},feature_cheap_v1:e=>{const{normalize:n}=e;return n(["5x günstiger"])},feature_cheap_v1_description1:e=>{const{normalize:n}=e;return n(["Beginnen Sie mit kostenlosen Testversionen und genießen Sie eine unkomplizierte Preisstruktur. Erhalten Sie Zugang zu leistungsstarken Einbettungen für nur 20 % der OpenAI-Kosten."])},feature_multilingual:e=>{const{normalize:n}=e;return n(["Bietet unter anderem zweisprachige Modelle für Deutsch-Englisch, Chinesisch-Englisch, ideal für mehrsprachige Anwendungen."])},feature_on_premises:e=>{const{normalize:n}=e;return n(["Datenschutz zuerst"])},feature_on_premises_description1:e=>{const{normalize:n}=e;return n(["Stellen Sie unsere Einbettungsmodelle nahtlos direkt in Ihrer Virtual Private Cloud (VPC) bereit. Wird derzeit auf AWS Sagemaker unterstützt, mit bevorstehenden Integrationen für Microsoft Azure und Google Cloud Platform. Für maßgeschneiderte Kubernetes-Bereitstellungen wenden Sie sich für spezielle Unterstützung an unser Vertriebsteam."])},feature_on_premises_description2:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um maßgeschneiderte Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und lokale Server zu erhalten."])},feature_on_premises_description3:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und Microsoft Azure und bald auch in Google Cloud Services bereit, oder wenden Sie sich an unser Vertriebsteam, um angepasste Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und Ihre lokalen Server zu erhalten."])},feature_on_premises_description4:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Embedding- und Reranker-Modelle vor Ort mit AWS SageMaker, Microsoft Azure oder Google Cloud Services bereit und stellen Sie sicher, dass Ihre Daten sicher unter Ihrer Kontrolle bleiben."])},feature_solid:e=>{const{normalize:n}=e;return n(["Klassenbester"])},feature_solid_description1:e=>{const{normalize:n}=e;return n(["Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests anhand der SOTA-Modelle, um eine beispiellose Leistung zu gewährleisten."])},feature_top_perform1:e=>{const{normalize:n}=e;return n(["Nahtlose Integration"])},feature_top_perform_description1:e=>{const{normalize:n}=e;return n(["Vollständig kompatibel mit der API von OpenAI. Lässt sich mühelos in über 10 Vektordatenbanken und RAG-Systeme integrieren und sorgt so für ein reibungsloses Benutzererlebnis."])},file_required:e=>{const{normalize:n}=e;return n(["Datei ist erforderlich"])},file_size_exceed:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Maximale Dateigröße ",r(i("_size"))," überschritten"])},file_type_not_supported:e=>{const{normalize:n}=e;return n(["Dateityp nicht unterstützt"])},fill_example:e=>{const{normalize:n}=e;return n(["Füllen Sie ein Beispiel aus"])},float_description:e=>{const{normalize:n}=e;return n(["Die Einbettungen werden als Liste von Gleitkommazahlen zurückgegeben. Am gebräuchlichsten und am einfachsten zu verwenden."])},free:e=>{const{normalize:n}=e;return n(["Frei"])},generate_api_key_error:e=>{const{normalize:n}=e;return n(["Die Generierung des API-Schlüssels ist fehlgeschlagen."])},generating_visualization:e=>{const{normalize:n}=e;return n(["Visualisierung wird erstellt..."])},get_new_key_button:e=>{const{normalize:n}=e;return n(["Holen Sie sich einen neuen Schlüssel"])},get_new_key_button_explain:e=>{const{normalize:n}=e;return n(["Wenn Sie sich für einen neuen Schlüssel entscheiden, geht der mit dem alten Schlüssel verbundene Nutzungsverlauf verloren."])},get_new_key_survey:e=>{const{normalize:n}=e;return n(["Nehmen Sie an der Umfrage teil, helfen Sie uns, Ihre Nutzung zu verstehen, und erhalten Sie kostenlos einen neuen API-Schlüssel!"])},includes:e=>{const{normalize:n}=e;return n(["Token gültig für:"])},index_and_search:e=>{const{normalize:n}=e;return n(["Index & Suche"])},index_and_search1:e=>{const{normalize:n}=e;return n(["Index & Suche"])},input:e=>{const{normalize:n}=e;return n(["Anfrage"])},input_api_key_error1:e=>{const{normalize:n}=e;return n(["Ihr API-Schlüssel ist ungültig!"])},input_length:e=>{const{normalize:n}=e;return n(["Eingabelänge"])},input_type:e=>{const{normalize:n}=e;return n(["Als Abfrage oder Dokument einbetten"])},input_type_explain:e=>{const{normalize:n}=e;return n(["Einige Einbettungsmodelle verfügen über spezielle Einbettungsstrategien für Abfragen und Dokumente. Dieselbe Zeichenfolge kann je nach ihrer Rolle in Ihrer Anwendung als Abfrage oder Dokument eingebettet werden."])},integrate:e=>{const{normalize:n}=e;return n(["Integrieren"])},"jina-clip-v1_description":e=>{const{normalize:n}=e;return n(["Unsere neuesten multimodalen Einbettungen für die Text- und Bildsuche."])},"jina-colbert-v1-en_description":e=>{const{normalize:n}=e;return n(["Verbessertes ColBERT mit 8K-Token-Länge zum Einbetten und Neuordnen von Aufgaben"])},"jina-colbert-v2_description":e=>{const{normalize:n}=e;return n(["Der beste mehrsprachige ColBERT mit Top-Leistung beim Einbetten und Neuranking"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:n}=e;return n(["Optimiert für die Suche nach Code und Dokumentzeichenfolgen"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen Deutsch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:n}=e;return n(["Auf Augenhöhe mit text-embedding-ada002 von OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen Spanisch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen Chinesisch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:n}=e;return n(["Optimiert für geringe Latenz und geringen Speicherbedarf"])},"jina-embeddings-v3_description":e=>{const{normalize:n}=e;return n(["Frontier-Mehrsprachigkeits-Einbettungsmodell mit SOTA-Leistung"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:n}=e;return n(["Unser erstes Reranker-Modell maximiert die Such- und RAG-Relevanz"])},"jina-reranker-v1-tiny-en_description":e=>{const{normalize:n}=e;return n(["Das schnellste Reranker-Modell, am besten geeignet für die zuverlässige Bewertung einer großen Anzahl von Dokumenten"])},"jina-reranker-v1-turbo-en_description":e=>{const{normalize:n}=e;return n(["Die beste Kombination aus schneller Inferenzgeschwindigkeit und präzisen Relevanzwerten"])},"jina-reranker-v2-base-multilingual_description":e=>{const{normalize:n}=e;return n(["Das neueste und beste Reranker-Modell mit mehrsprachiger Unterstützung für Funktionsaufrufe und Codesuche."])},key:e=>{const{normalize:n}=e;return n(["API-Schlüssel"])},key_enter_placeholder:e=>{const{normalize:n}=e;return n(["Bitte geben Sie Ihren API-Schlüssel ein"])},key_enter_placeholder_to_topup:e=>{const{normalize:n}=e;return n(["Geben Sie den API-Schlüssel ein, den Sie aufladen möchten"])},key_to_top_up:e=>{const{normalize:n}=e;return n(["Möchten Sie einen anderen API-Schlüssel aufladen? Fügen Sie ihn oben ein und klicken Sie auf „Speichern“."])},key_warn:e=>{const{normalize:n}=e;return n(["Stellen Sie sicher, dass Sie Ihren API-Schlüssel an einem sicheren Ort aufbewahren. Andernfalls müssen Sie einen neuen Schlüssel generieren"])},key_warn_v2:e=>{const{normalize:n}=e;return n(["Dies ist Ihr einzigartiger Schlüssel. Bewahren Sie ihn sicher auf!"])},language_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Dieses Modell unterstützt am besten die Sprache ",r(i("_Language")),"."])},last_7_days:e=>{const{normalize:n}=e;return n(["Nutzung in den letzten 7 Tagen"])},late_chunking:e=>{const{normalize:n}=e;return n(["Spätes Chunking"])},late_chunking_explain:e=>{const{normalize:n}=e;return n(["Wenden Sie die Late-Chunking-Technik an, um die Long-Context-Funktionen des Modells zum Generieren kontextbezogener Chunk-Einbettungen zu nutzen."])},learn_more:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr"])},learn_poster:e=>{const{normalize:n}=e;return n(["Erfahren Sie, wie wir es gemacht haben"])},learning1:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr über Einbettungen"])},learning1_description:e=>{const{normalize:n}=e;return n(["Wo soll man mit Einbettungen anfangen? Wir geben dir Deckung. Erfahren Sie mehr über Einbettungen von Grund auf mit unserem umfassenden Leitfaden."])},length:e=>{const{normalize:n}=e;return n(["Tokenlänge"])},manage_billing:e=>{const{normalize:n}=e;return n(["Rechnung verwalten"])},manage_billing_tip:e=>{const{normalize:n}=e;return n(["Verwalten Sie Ihre Rechnungsinformationen, erhalten Sie Rechnungen und richten Sie die automatische Aufladung ein."])},manage_quota1:e=>{const{normalize:n}=e;return n(["API-Schlüssel und Abrechnung"])},max_file_size:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Maximal zulässige Größe: ",r(i("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:n}=e;return n(["Maximieren Sie dieses Panel mit Umschalt+1"])},mistake_contact:e=>{const{normalize:n}=e;return n(["Wenn Sie glauben, dass es sich hierbei um einen Fehler handelt, nehmen Sie bitte Kontakt mit uns auf."])},model_required:e=>{const{normalize:n}=e;return n(["Modell ist erforderlich"])},more_than_two2:e=>{const{normalize:n}=e;return n(["Bitte geben Sie mehr als zwei Dokumente ein, also mehr als zwei Zeilen."])},multi_embedding:e=>{const{normalize:n}=e;return n(["Multi-Vektor"])},multi_embedding_explain:e=>{const{normalize:n}=e;return n(["Dieses Modell gibt eine Reihe kontextualisierter Einbettungen für eine bestimmte Eingabe zurück. Jedes Token in der Eingabe wird einem Vektor in der Ausgabe zugeordnet."])},multilingual:e=>{const{normalize:n}=e;return n(["Mehrsprachiger Support"])},multimodal:e=>{const{normalize:n}=e;return n(["Multimodal"])},multimodal_explain:e=>{const{normalize:n}=e;return n(["Dieses Modell kann sowohl Text- als auch Bildeingaben kodieren und ist daher ideal für multimodale Suchaufgaben."])},new:e=>{const{normalize:n}=e;return n(["Neues Modell"])},no_data1:e=>{const{normalize:n}=e;return n(["Fügen Sie ein Satzpaar hinzu, um die Ähnlichkeit zu berechnen"])},none:e=>{const{normalize:n}=e;return n(["Keiner"])},normalized:e=>{const{normalize:n}=e;return n(["L2-Normalisierung"])},normalized_explain:e=>{const{normalize:n}=e;return n(["Skaliert die Einbettung so, dass ihre euklidische (L2) Norm 1 wird, wobei die Richtung erhalten bleibt. Nützlich, wenn es im weiteren Verlauf um Skalarprodukt, Klassifizierung und Visualisierung geht."])},oncsp:e=>{const{normalize:n}=e;return n(["Auf CSP"])},onprem:e=>{const{normalize:n}=e;return n(["Vor Ort"])},open_tensorboard:e=>{const{normalize:n}=e;return n(["Öffnen Sie den Visualizer"])},opensource:e=>{const{normalize:n}=e;return n(["Betriebssystem"])},opensource_explain:e=>{const{normalize:n}=e;return n(["Dieses Modell ist Open Source und auf Hugging Face verfügbar. Klicken Sie auf diese Schaltfläche, um das Modell auf Hugging Face anzuzeigen."])},original_documents:e=>{const{normalize:n}=e;return n(["Einzubettende Sätze"])},original_documents_hint:e=>{const{normalize:n}=e;return n(["Geben Sie hier Ihre Sätze ein. Jede neue Zeile wird als separater Satz/Dokument betrachtet."])},output:e=>{const{normalize:n}=e;return n(["Antwort"])},output_dim:e=>{const{normalize:n}=e;return n(["Maße"])},output_dim_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Die Ausgabedimension eines Einbettungsvektors aus diesem Modell ist ",r(i("_outputDim")),"."])},output_dimension:e=>{const{normalize:n}=e;return n(["Ausgabedimensionen"])},pairwise_test:e=>{const{normalize:n}=e;return n(["Paarweise"])},per_k:e=>{const{normalize:n}=e;return n(["/ 1K-Token"])},per_m:e=>{const{normalize:n}=e;return n(["/ 1 Mio. Token"])},please_fill_docs_first:e=>{const{normalize:n}=e;return n(["Bitte geben Sie vor der Suche unten einige Sätze ein."])},please_select_model:e=>{const{normalize:n}=e;return n(["Bitte wählen Sie ein Einbettungsmodell oder ein Reranker-Modell aus"])},poster:e=>{const{normalize:n}=e;return n(["Die Evolution des Einbettungsplakats"])},poster_description:e=>{const{normalize:n}=e;return n(["Entdecken Sie das ideale Poster für Ihren Raum mit fesselnden Infografiken oder atemberaubenden Bildern, die die Entwicklung der Texteinbettungsmodelle seit 1950 nachzeichnen."])},pricing:e=>{const{normalize:n}=e;return n(["API-Preise"])},pricing_desc:e=>{const{normalize:n}=e;return n(["Unsere API-Preise richten sich nach der Anzahl der in den Anfragen gesendeten Token. Bei der Reader-API ist es die Anzahl der Token in den Antworten. Dieses Preismodell gilt für alle Produkte in der Suchgrundlage von Jina AI: Embedding-, Reranking-, Reader- und Auto Fine-Tuning-APIs. Mit demselben API-Schlüssel haben Sie Zugriff auf alle API-Dienste."])},protectData1:e=>{const{normalize:n}=e;return n(["Anforderungsdaten und Dokumente werden nicht für Trainingsmodelle verwendet."])},protectData2:e=>{const{normalize:n}=e;return n(["Datenverschlüsselung während der Übertragung (TLS 1.2+) und im Ruhezustand (AES-GCM 256)."])},protectData3:e=>{const{normalize:n}=e;return n(["SOC 2 und DSGVO-konform."])},protect_data:e=>{const{normalize:n}=e;return n(["Schützen Sie Ihre Daten"])},public_cloud_integration:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Mit <b>",r(i("_numPartners")),"</b> Cloud-Service-Anbietern"])},public_cloud_integration_desc:e=>{const{normalize:n}=e;return n(["Verwendet Ihr Unternehmen AWS oder Azure? Dann setzen Sie unsere Suchgrundlagenmodelle direkt auf diesen Plattformen in Ihrem Unternehmen ein, damit Ihre Daten sicher und konform bleiben."])},query:e=>{const{normalize:n}=e;return n(["Abfrage"])},raise_issue:e=>{const{normalize:n}=e;return n(["Problem melden"])},rank_none_description:e=>{const{normalize:n}=e;return n(["Verwenden Sie kein Reranker-Modell"])},read_api_docs:e=>{const{normalize:n}=e;return n(["API-Spezifikation"])},read_release_note:e=>{const{normalize:n}=e;return n(["Versionshinweis lesen"])},recharge_threshold:e=>{const{normalize:n}=e;return n(["Aufladeschwelle"])},refresh:e=>{const{normalize:n}=e;return n(["Aktualisierung"])},refresh_key_tooltip1:e=>{const{normalize:n}=e;return n(["Holen Sie sich kostenlos einen neuen API-Schlüssel"])},refresh_token_count1:e=>{const{normalize:n}=e;return n(["Aktualisieren Sie, um verfügbare Token des aktuellen API-Schlüssels zu erhalten"])},regenerate:e=>{const{normalize:n}=e;return n(["Regenerieren"])},remaining:e=>{const{normalize:n}=e;return n(["Verfügbare Token"])},remaining_left:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Sie haben noch <b>",r(i("_leftTokens")),"</b> Token im unten stehenden API-Schlüssel übrig."])},request_number:e=>{const{normalize:n}=e;return n(["Anfragezeiten"])},request_path:e=>{const{normalize:n}=e;return n(["Anforderungsendpunkt"])},results_as_final_result:e=>{const{normalize:n}=e;return n(["#docs als Endergebnis"])},results_fed_to_reranker:e=>{const{normalize:n}=e;return n(["#docs an Reranker weitergeleitet"])},retry:e=>{const{normalize:n}=e;return n(["Wiederholen"])},return_base64:e=>{const{normalize:n}=e;return n(["Base64 (als String)"])},return_binary:e=>{const{normalize:n}=e;return n(["Binär (als int8 gepackt)"])},return_float:e=>{const{normalize:n}=e;return n(["Standard (als Float)"])},return_format:e=>{const{normalize:n}=e;return n(["Einbettungsformat"])},return_format_explain:e=>{const{normalize:n}=e;return n(["Neben dem Float können Sie auch die Rückgabe als Binärwert für einen schnelleren Vektorabruf oder als Base64-Kodierung für eine schnellere Übertragung anfordern."])},return_format_title:e=>{const{normalize:n}=e;return n(["Zurückgebender Datentyp"])},return_ubinary:e=>{const{normalize:n}=e;return n(["Binär (als uint8 gepackt)"])},right_api_key_to_charge:e=>{const{normalize:n}=e;return n(["Bitte geben Sie zum Aufladen den richtigen API-Schlüssel ein"])},running:e=>{const{normalize:n}=e;return n(["Aktiv"])},score:e=>{const{normalize:n}=e;return n(["Punktzahl"])},search:e=>{const{normalize:n}=e;return n(["Suchen"])},search_hint:e=>{const{normalize:n}=e;return n(["Geben Sie Ihre Suche in die unten aufgeführten Sätze ein."])},select_classify_model:e=>{const{normalize:n}=e;return n(["Klassifikator auswählen"])},select_embedding_model:e=>{const{normalize:n}=e;return n(["Wählen Sie Einbettungen aus"])},select_rerank_model:e=>{const{normalize:n}=e;return n(["Reranker auswählen"])},show_api_key:e=>{const{normalize:n}=e;return n(["API-Schlüssel anzeigen"])},size:e=>{const{normalize:n}=e;return n(["Parameter"])},size_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Die Anzahl der Parameter im Modell beträgt ",r(i("_size")),". Beachten Sie, dass dies nicht die Größe der Modelldatei ist."])},sleeping:e=>{const{normalize:n}=e;return n(["Inaktiv"])},start_batch:e=>{const{normalize:n}=e;return n(["Starten Sie die Batch-Einbettung"])},start_embedding:e=>{const{normalize:n}=e;return n(["Index"])},status_explain:e=>{const{normalize:n}=e;return n(["Unsere serverlose Architektur kann in Zeiten geringer Nutzung bestimmte Modelle entlasten. Bei aktiven Modellen erfolgt die Reaktion sofort. Inaktive Modelle benötigen bei der ersten Anfrage einige Sekunden zum Laden. Nach der Aktivierung werden Folgeanfragen schneller bearbeitet."])},task_type:e=>{const{normalize:n}=e;return n(["Nachgelagerte Aufgabe"])},task_type_classification:e=>{const{normalize:n}=e;return n(["Einstufung"])},task_type_classification_explain:e=>{const{normalize:n}=e;return n(["Textklassifizierung."])},task_type_explain:e=>{const{normalize:n}=e;return n(["Wählen Sie die nachgelagerte Aufgabe aus, für die die Einbettungen verwendet werden. Das Modell gibt die optimierten Einbettungen für diese Aufgabe zurück."])},task_type_none_explain:e=>{const{normalize:n}=e;return n(["Es wird kein Adapter verwendet. Es wird eine generische Einbettung zurückgegeben, die zum Debuggen oder Hacken nützlich ist."])},task_type_retrieval_passage:e=>{const{normalize:n}=e;return n(["Abrufpassage"])},task_type_retrieval_passage_explain:e=>{const{normalize:n}=e;return n(["Einbetten von Dokumenten in eine Abfrage-/Dokumentenabrufaufgabe."])},task_type_retrieval_query:e=>{const{normalize:n}=e;return n(["Abfrage abfragen"])},task_type_retrieval_query_explain:e=>{const{normalize:n}=e;return n(["Einbetten von Abfragen in eine Abfragedokument-Abrufaufgabe."])},task_type_separation:e=>{const{normalize:n}=e;return n(["Trennung"])},task_type_separation_explain:e=>{const{normalize:n}=e;return n(["Dokumente clustern, Korpus visualisieren."])},"task_type_text-matching":e=>{const{normalize:n}=e;return n(["Textübereinstimmung"])},"task_type_text-matching_explain":e=>{const{normalize:n}=e;return n(["Semantische Textähnlichkeit, allgemeine symmetrische Abfrage, Empfehlung, Ähnliches finden, Deduplizierung."])},tax_may_apply:e=>{const{normalize:n}=e;return n(["Abhängig von Ihrem Standort werden Ihnen möglicherweise USD, EUR oder andere Währungen in Rechnung gestellt. Es können Steuern anfallen."])},text1:e=>{const{normalize:n}=e;return n(["Links"])},text2:e=>{const{normalize:n}=e;return n(["Rechts"])},title:e=>{const{normalize:n}=e;return n(["Einbettungs-API"])},token_example:e=>{const{normalize:n}=e;return n(["Ein Tweet kostet etwa 20 Token, ein Nachrichtenartikel etwa 1000 Token und Charles Dickens‘ Roman „Eine Geschichte zweier Städte“ hat über eine Million Token."])},token_length_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Die maximale Länge der Eingabe-Token-Sequenz beträgt für dieses Modell ",r(i("_tokenLength")),"."])},tokens:e=>{const{normalize:n}=e;return n(["Token"])},tools:e=>{const{normalize:n}=e;return n(["Werkzeuge"])},top_up_button:e=>{const{normalize:n}=e;return n(["Alten Schlüssel aufladen"])},top_up_button_explain:e=>{const{normalize:n}=e;return n(["Die Integration dieses API-Schlüssels bietet eine professionellere Lösung und macht häufige Schlüsseländerungen überflüssig. Nutzungsdaten werden gespeichert und sind jederzeit abrufbar."])},top_up_warning_message1:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Der aktuelle API-Schlüssel hat noch ",r(i("_remainedTokens"))," Token und wird durch einen neuen Schlüssel mit ",r(i("_freeTokens"))," Token ersetzt. Sie können den alten Schlüssel weiterhin verwenden oder aufladen, wenn Sie ihn sicher aufbewahrt haben. Wie wollen Sie fortfahren?"])},top_up_warning_title:e=>{const{normalize:n}=e;return n(["Ersetzen Sie den alten API-Schlüssel"])},total_documents:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Einbettungsfortschritt: ",r(i("_Verarbeitet")),"/",r(i("_Count"))," Sätze."])},tuning:e=>{const{normalize:n}=e;return n(["Feinabstimmung"])},turnstile_error:e=>{const{normalize:n}=e;return n(["Wir können keinen API-Schlüssel generieren, da wir nicht überprüfen konnten, ob Sie ein Mensch sind."])},turnstile_unsupported:e=>{const{normalize:n}=e;return n(["Wir können keinen API-Schlüssel generieren, da Ihr Browser nicht unterstützt wird."])},ubinary_description:e=>{const{normalize:n}=e;return n(["Die Einbettungen werden als uint8 gepackt. Viel effizienter für Speicherung, Suche und Übertragung."])},upload:e=>{const{normalize:n}=e;return n(["Hochladen"])},upload_file:e=>{const{normalize:n}=e;return n(["Klicken Sie hier, um eine Datei hochzuladen"])},usage:e=>{const{normalize:n}=e;return n(["Verwendung"])},usage_amount:e=>{const{normalize:n}=e;return n(["Token"])},usage_history:e=>{const{normalize:n}=e;return n(["Nutzung in den letzten 7 Tagen"])},usage_history_explain:e=>{const{normalize:n}=e;return n(["Die Daten liegen nicht in Echtzeit vor und können einige Minuten verzögert sein."])},usage_reason:e=>{const{normalize:n}=e;return n(["Beschreibung"])},usage_reason_consume:e=>{const{normalize:n}=e;return n(["Gebraucht"])},usage_reason_purchase:e=>{const{normalize:n}=e;return n(["Gekauft"])},usage_reason_trial:e=>{const{normalize:n}=e;return n(["Versuch"])},usage_rerank:e=>{const{normalize:n}=e;return n(["Verwendung"])},usage_time:e=>{const{normalize:n}=e;return n(["Terminzeit"])},v3_description:e=>{const{normalize:n}=e;return n(["<code>jina-embeddings-v3</code> ist ein bahnbrechendes mehrsprachiges Texteinbettungsmodell mit 570 Millionen Parametern und 8192 Tokenlänge, das die neuesten proprietären Einbettungen von OpenAI und Cohere auf MTEB übertrifft. Lesen Sie unten unseren Blogbeitrag und die Forschungsarbeit."])},v3_title:e=>{const{normalize:n}=e;return n(["v3: Frontier Mehrsprachige Einbettungen"])},vector_database_integration1:e=>{const{normalize:n}=e;return n(["Integrationen"])},vector_database_integration2:e=>{const{normalize:n}=e;return n(["Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Kopieren Sie zunächst einfach Ihren API-Schlüssel und fügen Sie ihn in eine der aufgeführten Integrationen ein, um einen schnellen und reibungslosen Start zu ermöglichen."])},vector_database_integration3:e=>{const{normalize:n}=e;return n(["Unsere Embedding & Reranker API ist nativ in verschiedene bekannte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Um zu beginnen, kopieren Sie einfach Ihren API-Schlüssel und fügen Sie ihn in eine der aufgelisteten Integrationen ein, um schnell und nahtlos zu starten."])},vector_database_integration_description:e=>{const{normalize:n}=e;return n(["Integrieren Sie die Jina Embeddings API nahtlos und einfach in alle unten aufgeführten Vektordatenbanken, LLM-Orchestrierungs-Frameworks und RAG-Anwendungen. Unsere Tutorials zeigen Ihnen wie."])},view_details:e=>{const{normalize:n}=e;return n(["Details anzeigen"])},visualization_example:e=>{const{normalize:n}=e;return n(["Zuordnung aller Sätze aus diesem Abschnitt zu einem 3D-Vektorraum"])},visualization_example_you_can:e=>{const{normalize:n}=e;return n(["Nutzen Sie unsere API unten, Sie können es auch tun!"])},visualize:e=>{const{normalize:n}=e;return n(["Visualisieren"])},visualize_done:e=>{const{normalize:n}=e;return n(["Die Visualisierung ist abgeschlossen. Sie können nun auf die obere Schaltfläche klicken, um den Visualizer zu öffnen."])},wait_for_processing:e=>{const{normalize:n}=e;return n(["Ihre Anfrage wird bearbeitet."])},wait_stripe:e=>{const{normalize:n}=e;return n(["Stripe-Zahlung wird geöffnet, bitte warten"])},what_are_embedding:e=>{const{normalize:n}=e;return n(["Was sind Einbettungen?"])},what_are_embedding_answer:e=>{const{normalize:n}=e;return n([`Stellen Sie sich vor, Sie bringen einem Computer bei, die nuancierten Bedeutungen von Wörtern und Phrasen zu erfassen. Traditionelle Methoden, die auf starren, regelbasierten Systemen basieren, scheitern, weil Sprache zu komplex und fließend ist. Hier kommen Text-Embeddings ins Spiel: eine leistungsstarke Lösung, die Text in eine Sprache der Zahlen übersetzt – genauer gesagt in Vektoren in einem hochdimensionalen Raum.

Betrachten Sie die Ausdrücke „sonniges Wetter“ und „klarer Himmel“. Für uns zeichnen sie ein ähnliches Bild. Durch die Linse der Embeddings werden diese Ausdrücke in numerische Vektoren umgewandelt, die in diesem mehrdimensionalen Raum nahe beieinander liegen und ihre semantische Verwandtschaft erfassen. Bei dieser Nähe im Vektorraum geht es nicht nur darum, dass Wörter oder Ausdrücke ähnlich sind; es geht darum, Kontext, Stimmung und sogar subtile Bedeutungsnuancen zu verstehen.

Warum ist dieser Durchbruch wichtig? Zunächst einmal überbrückt er die Lücke zwischen der Vielfalt der menschlichen Sprache und der Rechenleistung von Algorithmen. Algorithmen sind hervorragend darin, Zahlen zu verarbeiten, nicht darin, Texte zu interpretieren. Durch die Umwandlung von Text in Vektoren ermöglichen Einbettungen diesen Algorithmen, Sprache auf eine Weise zu „verstehen“ und zu verarbeiten, die zuvor unerreichbar war.

Die praktischen Anwendungen sind umfangreich und vielfältig. Ob es darum geht, Inhalte zu empfehlen, die Ihren Interessen entsprechen, eine Konversations-KI zu betreiben, die überraschend menschlich wirkt, oder sogar subtile Muster in großen Textmengen zu erkennen – Einbettungen sind der Schlüssel. Sie ermöglichen Maschinen, Aufgaben wie Stimmungsanalyse, Sprachübersetzung und vieles mehr auszuführen, mit einem immer nuancierteren und verfeinerten Sprachverständnis.`])},what_is_a_token:e=>{const{normalize:n}=e;return n(["Ein Token ist in der Textverarbeitung eine Einheit, oft ein Wort. Zum Beispiel: „Jina AI ist großartig!“ wird zu fünf Token, einschließlich der Interpunktion."])},why_do_you_need:e=>{const{normalize:n}=e;return n(["Auswahl der richtigen Einbettungen"])},why_do_you_need_after:e=>{const{normalize:n}=e;return n(["Mithilfe tiefer neuronaler Netze und LLMs stellen unsere Einbettungsmodelle multimodale Daten in einem optimierten Format dar, verbessern das Maschinenverständnis, die effiziente Speicherung und ermöglichen fortschrittliche KI-Anwendungen. Diese Einbettungen spielen eine entscheidende Rolle beim Verständnis der Daten, der Verbesserung des Benutzerengagements, der Überwindung von Sprachbarrieren und der Optimierung von Entwicklungsprozessen."])},why_do_you_need_before:e=>{const{normalize:n}=e;return n(["Unsere Einbettungsmodelle sind für die Abdeckung vielfältiger Such- und GenAI-Anwendungen konzipiert."])},why_need_1_description:e=>{const{normalize:n}=e;return n(["Unser von JinaBERT bereitgestelltes Kerneinbettungsmodell ist für ein breites Anwendungsspektrum konzipiert. Es zeichnet sich durch das Verständnis detaillierter Texte aus und eignet sich daher ideal für die semantische Suche, Inhaltsklassifizierung und komplexe Sprachanalyse. Seine Vielseitigkeit ist unübertroffen und unterstützt die Erstellung fortschrittlicher Stimmungsanalysetools, Textzusammenfassungen und personalisierter Empfehlungssysteme."])},why_need_1_title:e=>{const{normalize:n}=e;return n(["Allgemeine Einbettungen"])},why_need_2_description:e=>{const{normalize:n}=e;return n(["Unsere zweisprachigen Modelle erleichtern die Kommunikation über Sprachen hinweg und verbessern mehrsprachige Plattformen, globalen Kundensupport und die Entdeckung mehrsprachiger Inhalte. Diese Modelle wurden für die Beherrschung von Deutsch-Englisch- und Chinesisch-Englisch-Übersetzungen entwickelt. Sie vereinfachen die Interaktion und fördern das Verständnis zwischen verschiedenen Sprachgruppen."])},why_need_2_title:e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen"])},why_need_3_description:e=>{const{normalize:n}=e;return n(["Unser auf Entwickler zugeschnittenes Code-Einbettungsmodell optimiert Codierungsaufgaben wie Zusammenfassung, Codegenerierung und automatische Überprüfungen. Es steigert die Produktivität, indem es tiefere Einblicke in Codestrukturen bietet und Verbesserungen vorschlägt, was es für die Entwicklung fortschrittlicher IDE-Plugins, automatischer Dokumentation und modernster Debugging-Tools unerlässlich macht."])},why_need_3_title:e=>{const{normalize:n}=e;return n(["Code-Einbettungen"])},why_need_4_description:e=>{const{normalize:n}=e;return n(["Jina CLIP ist unser neuestes multimodales Einbettungsmodell für Bild und Text. Eine große Verbesserung gegenüber OpenAI CLIP besteht darin, dass dieses einzelne Modell sowohl für Text-Text-Abrufe als auch für Text-Bild-, Bild-Text- und Bild-Bild-Abrufaufgaben verwendet werden kann! Also ein Modell, zwei Modalitäten, vier Suchrichtungen!"])},why_need_4_title:e=>{const{normalize:n}=e;return n(["Multimodale Einbettungen"])},write_email_here:e=>{const{normalize:n}=e;return n(["Bitte geben Sie die E-Mail-Adresse ein, an die Sie nach Abschluss den Download-Link erhalten möchten."])},you_can_leave:e=>{const{normalize:n}=e;return n(["Sie können diese Seite verlassen und wir senden Ihnen nach Abschluss den Download-Link zu."])}},embeddings:{description:e=>{const{normalize:n}=e;return n(["Multimodale und mehrsprachige Einbettungen von Weltklasse."])}},faq:{answer1:e=>{const{normalize:n}=e;return n(["Jina AI ist auf multimodale KI-Technologien spezialisiert, darunter Model-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving. Wir nutzen fortschrittliche Tools wie Kubernetes und serverlose Architekturen, um robuste, skalierbare und produktionsbereite Lösungen zu erstellen."])},answer10:e=>{const{normalize:n}=e;return n(["Je nach Art des Projekts und den Bedürfnissen des Kunden bieten wir verschiedene Lizenzoptionen an. Detaillierte Konditionen können mit unserem Vertriebsteam besprochen werden."])},answer11:e=>{const{normalize:n}=e;return n(["Wir bieten Dienstleistungen weltweit an, mit unserem Hauptsitz in Berlin, Europa, und weiteren Büros in Peking und Shenzhen."])},answer12:e=>{const{normalize:n}=e;return n(["Ja, wir bieten Vor-Ort-Support an, insbesondere für Kunden in der Nähe unserer Büros in Berlin, Peking und Shenzhen. Für andere Standorte streben wir einen bestmöglichen Remote-Support an und können bei Bedarf auch einen Vor-Ort-Support arrangieren."])},answer2:e=>{const{normalize:n}=e;return n(["Unsere Expertise erstreckt sich über ein breites Spektrum und umfasst große Sprachmodelle, Text-, Bild-, Video- und Audioverständnis, neuronale Suche und generative Kunst."])},answer3:e=>{const{normalize:n}=e;return n(["Ja, unsere Lösungen sind skalierbar und produktionsbereit. Wir erstellen unsere Lösungen mithilfe cloudnativer Technologien, die eine effiziente Skalierung und zuverlässige Leistung in Produktionsumgebungen ermöglichen."])},answer4:e=>{const{normalize:n}=e;return n(["Unsere Dienstleistungen sind vielseitig und anpassungsfähig und eignen sich daher für eine Vielzahl von Branchen, darunter E-Commerce, Legal Tech, digitales Marketing, Gaming, Gesundheitswesen, Finanzen und viele mehr."])},answer5:e=>{const{normalize:n}=e;return n(["Über das Kontaktformular auf dieser Seite können Sie mit unserem Vertriebsteam in Kontakt treten. Wir besprechen gerne Ihre Projektanforderungen und wie unsere Lösungen Ihrem Unternehmen helfen können."])},answer6:e=>{const{normalize:n}=e;return n(["Wir bieten kontinuierliche Unterstützung, um den reibungslosen Betrieb unserer Lösungen sicherzustellen. Dazu gehören Fehlerbehebung, regelmäßige Updates und Verbesserungen basierend auf Ihrem Feedback und Ihren Bedürfnissen."])},answer7:e=>{const{normalize:n}=e;return n(["Die Projektdauer variiert je nach Komplexität und Umfang des Projekts. Nachdem wir Ihre Anforderungen verstanden haben, können wir einen genaueren Kostenvoranschlag erstellen."])},answer8:e=>{const{normalize:n}=e;return n(["Datensicherheit hat für uns oberste Priorität. Wir halten uns an strenge Datenschutzrichtlinien und -vorschriften, um sicherzustellen, dass Ihre Daten sicher und vertraulich sind."])},answer9:e=>{const{normalize:n}=e;return n(["Die Preisgestaltung richtet sich nach der Komplexität und den Anforderungen des Projekts. Wir bieten sowohl projektbasierte als auch Retainer-Preismodelle an. Für weitere Informationen wenden Sie sich bitte an unser Vertriebsteam."])},question1:e=>{const{normalize:n}=e;return n(["Worauf ist Jina AI spezialisiert?"])},question10:e=>{const{normalize:n}=e;return n(["Welche Lizenzbedingungen gelten für Ihre Lösungen?"])},question11:e=>{const{normalize:n}=e;return n(["Was ist Ihr Servicegebiet?"])},question12:e=>{const{normalize:n}=e;return n(["Bieten Sie Vor-Ort-Support an?"])},question2:e=>{const{normalize:n}=e;return n(["Mit welchen Arten von KI arbeitet Jina AI?"])},question3:e=>{const{normalize:n}=e;return n(["Sind Ihre Lösungen skalierbar und produktionsreif?"])},question4:e=>{const{normalize:n}=e;return n(["Welche Branchen können von den Lösungen von Jina AI profitieren?"])},question5:e=>{const{normalize:n}=e;return n(["Wie starten wir ein Projekt mit Jina AI?"])},question6:e=>{const{normalize:n}=e;return n(["Welche Unterstützung leisten Sie nach der Implementierung einer Lösung?"])},question7:e=>{const{normalize:n}=e;return n(["Was ist die typische Dauer für ein Projekt?"])},question8:e=>{const{normalize:n}=e;return n(["Wie schützt Jina AI meine Daten?"])},question9:e=>{const{normalize:n}=e;return n(["Wie ist die Preisstruktur für Ihre Dienstleistungen?"])}},faq_button:e=>{const{normalize:n}=e;return n(["FAQ"])},finetuner:{description:e=>{const{normalize:n}=e;return n(["Optimieren Sie die Einbettungen domänenspezifischer Daten für eine bessere Suchqualität"])},intro:e=>{const{normalize:n}=e;return n(["Ihr Unternehmen. Deine Daten. Ihr Modell"])}},finetuner_plus:{description:e=>{const{normalize:n}=e;return n(["Stärken Sie Ihr Unternehmen mit großen Sprachmodellen die genau auf Ihre Daten zugeschnitten sind"])}},finetuning:{api_key:e=>{const{normalize:n}=e;return n(["Geben Sie Ihren API-Schlüssel ein."])},back:e=>{const{normalize:n}=e;return n(["Zurück"])},base_model_selected:e=>{const{normalize:n}=e;return n(["Basismodell ausgewählt"])},click_start:e=>{const{normalize:n}=e;return n(["Stimmen Sie den Bedingungen zu und beginnen Sie mit der Feinabstimmung."])},confirm_title:e=>{const{normalize:n}=e;return n(["Feinabstimmung bestätigen"])},confirm_your_email:e=>{const{normalize:n}=e;return n(["Geben Sie Ihre E-Mail-Adresse erneut ein, um die Feinabstimmung zu bestätigen. Updates und der Download-Link werden an diese E-Mail-Adresse gesendet."])},consent0:e=>{const{normalize:n}=e;return n(["Ich bin damit einverstanden, dass nach meinen Vorgaben synthetische Daten zur Modellfeinabstimmung generiert werden."])},consent1:e=>{const{normalize:n}=e;return n(["Ich erkenne an, dass das endgültige Modell und die synthetischen Daten auf Hugging Face öffentlich zugänglich sein werden."])},consent2:e=>{const{normalize:n}=e;return n(["Ich verstehe, dass diese Funktion sich in der Betaphase befindet und Jina AI keine Garantien bietet. Preise und UX können sich ändern."])},continue:e=>{const{normalize:n}=e;return n(["Weitermachen"])},cost_1m_token:e=>{const{normalize:n}=e;return n(["Jeder Feinabstimmungsjob verbraucht 1 Million Token. Stellen Sie sicher, dass Sie über genügend Token verfügen, oder laden Sie Ihr Guthaben auf. Sie können auch einen neuen API-Schlüssel generieren. Jeder API-Schlüssel enthält 1 Million kostenlose Token."])},doc_explain:e=>{const{normalize:n}=e;return n(["Beschreiben Sie, wie ein übereinstimmendes Dokument aussehen sollte."])},domain_explain:e=>{const{normalize:n}=e;return n(["Geben Sie eine detaillierte Beschreibung an, wie die fein abgestimmten Einbettungen verwendet werden. Dies ist wichtig, um qualitativ hochwertige synthetische Daten zu generieren, die die Leistung Ihrer Einbettungen verbessern."])},domain_explain2:e=>{const{normalize:n}=e;return n(["Sie können Ihre Anforderung auf drei Arten angeben: eine allgemeine Anweisung, eine URL oder eine Abfragedokumentbeschreibung. Wählen Sie eine aus."])},domain_hint:e=>{const{normalize:n}=e;return n(["Beschreiben Sie die Domäne, für die Sie die Feinabstimmung vornehmen möchten."])},email_not_match:e=>{const{normalize:n}=e;return n(["Die E-Mail-Adressen stimmen nicht überein. Bitte überprüfen Sie."])},failed_job:e=>{const{normalize:n}=e;return n(["Die Feinabstimmungsanforderung ist fehlgeschlagen. Den Grund finden Sie weiter unten."])},find_on_huggingface:e=>{const{normalize:n}=e;return n(["Ergebnisse finden zu Hugging Face"])},general_instruction:e=>{const{normalize:n}=e;return n(["Oder allgemeine Anweisung"])},general_instruction_caption:e=>{const{normalize:n}=e;return n(["Geben Sie eine detaillierte Beschreibung der Verwendung der feinabgestimmten Einbettungen an."])},general_instruction_explain:e=>{const{normalize:n}=e;return n(["Beschreiben Sie Ihre Domain in freiem Text. Sie können es sich als eine „Eingabeaufforderung“ wie in ChatGPT vorstellen."])},how_it_works:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr über den Feinabstimmungsprozess."])},job_acknowledged:e=>{const{normalize:n}=e;return n(["Ihr Feinabstimmungsauftrag wurde in die Warteschlange gestellt. Sie erhalten eine E-Mail, wenn der Auftrag beginnt. Der gesamte Vorgang dauert oft 20 Minuten."])},new_key:e=>{const{normalize:n}=e;return n(["Neuen Schlüssel anfordern"])},not_enough_token:e=>{const{normalize:n}=e;return n(["Nicht genügend Token in diesem API-Schlüssel. Bitte laden Sie Ihr Guthaben auf oder verwenden Sie einen anderen API-Schlüssel."])},placeholder:e=>{const{normalize:n}=e;return n(["Ansprüche aus der Kfz-Versicherung"])},preview:e=>{const{normalize:n}=e;return n(["Vorschau"])},query_doc:e=>{const{normalize:n}=e;return n(["Abfrage-Dokumentbeschreibung"])},query_doc_caption:e=>{const{normalize:n}=e;return n(["Beschreiben Sie, wie die Abfrage aussieht und wie das übereinstimmende Dokument in Ihrer Domäne aussieht."])},query_explain:e=>{const{normalize:n}=e;return n(["Beschreiben Sie, wie eine Abfrage aussieht."])},reset:e=>{const{normalize:n}=e;return n(["Von vorn anfangen"])},select_base_model:e=>{const{normalize:n}=e;return n(["Wählen Sie zur Feinabstimmung ein Basis-Einbettungsmodell."])},select_base_model_explain:e=>{const{normalize:n}=e;return n(["Wählen Sie ein Basismodell als Ausgangspunkt für die Feinabstimmung aus. Normalerweise ist Base-en eine gute Wahl, aber für Aufgaben in anderen Sprachen sollten Sie die Verwendung eines zweisprachigen Modells in Betracht ziehen."])},start_tuning:e=>{const{normalize:n}=e;return n(["Beginnen Sie mit der Feinabstimmung"])},url:e=>{const{normalize:n}=e;return n(["Oder Webseiten-URL"])},url_caption:e=>{const{normalize:n}=e;return n(["Zur Feinabstimmung können Sie den Inhalt einer URL konsultieren."])},url_explain:e=>{const{normalize:n}=e;return n(["Öffentliche URL einer Webseite, die den Inhalt enthält, den Sie optimieren möchten."])},use_url:e=>{const{normalize:n}=e;return n(["Verwenden Sie stattdessen die URL. Wenn Sie diese Option aktivieren, werden wir auf Grundlage des Seiteninhalts dieser URL synthetische Daten zur Feinabstimmung generieren."])},wait_for_processing:e=>{const{normalize:n}=e;return n(["Bitte warten Sie, während wir Ihre Anfrage verarbeiten..."])},which_domain:e=>{const{normalize:n}=e;return n(["Feinabstimmung der Domäne"])},write_email_explain:e=>{const{normalize:n}=e;return n(["Die Feinabstimmung braucht Zeit. Wir informieren Sie per E-Mail über den Beginn, den Fortschritt, die Fertigstellung und etwaige Probleme Ihrer Feinabstimmungsarbeit sowie über Einzelheiten zum feinabgestimmten Modell und Trainingsdatensatz."])}},footer:{address_beijing:e=>{const{normalize:n}=e;return n(["Peking, China"])},address_berlin:e=>{const{normalize:n}=e;return n(["Berlin, Deutschland (Hauptsitz)"])},address_shenzhen:e=>{const{normalize:n}=e;return n(["Shenzhen, China"])},all_rights_reserved:e=>{const{normalize:n}=e;return n(["Alle Rechte vorbehalten."])},company:e=>{const{normalize:n}=e;return n(["Unternehmen"])},developers:e=>{const{normalize:n}=e;return n(["Entwickler"])},docs:e=>{const{normalize:n}=e;return n(["Dokumente"])},enterprise:e=>{const{normalize:n}=e;return n(["Unternehmen"])},get_api_key:e=>{const{normalize:n}=e;return n(["Holen Sie sich den Jina AI API-Schlüssel"])},offices:e=>{const{normalize:n}=e;return n(["Büros"])},power_users:e=>{const{normalize:n}=e;return n(["Power-User"])},privacy:e=>{const{normalize:n}=e;return n(["Privatsphäre"])},privacy_policy:e=>{const{normalize:n}=e;return n(["Datenschutz-Bestimmungen"])},privacy_settings:e=>{const{normalize:n}=e;return n(["Cookie-Einstellungen"])},security:e=>{const{normalize:n}=e;return n(["Sicherheit"])},sefo:e=>{const{normalize:n}=e;return n(["Stiftung durchsuchen"])},soc2:e=>{const{normalize:n}=e;return n(["Wir erfüllen die Anforderungen des American Institute of Certified Public Accountants (AICPA) nach SOC 2 Typ 1."])},status:e=>{const{normalize:n}=e;return n(["API-Status"])},status_short:e=>{const{normalize:n}=e;return n(["Status"])},tc:e=>{const{normalize:n}=e;return n(["Terms & amp; Bedingungen"])},tc1:e=>{const{normalize:n}=e;return n(["Bedingungen"])}},get_new_key:e=>{const{normalize:n}=e;return n(["Holen Sie sich Ihren API-Schlüssel"])},github:{stars:e=>{const{normalize:n}=e;return n(["Sterne"])}},header:{about_us:e=>{const{normalize:n}=e;return n(["Über uns"])},company:e=>{const{normalize:n}=e;return n(["Unternehmen"])},contact_us:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie unseren Vertrieb"])},developers_others:e=>{const{normalize:n}=e;return n(["Weitere Entwicklertools"])},enterprise_others:e=>{const{normalize:n}=e;return n(["Weitere Enterprise-Tools"])},for_developers:e=>{const{normalize:n}=e;return n(["Für Entwickler"])},for_developers_description:e=>{const{normalize:n}=e;return n(["Erleben Sie einen umfassenden multimodalen Open-Source-KI-Stack, der für Entwickler entwickelt wurde."])},for_enterprise:e=>{const{normalize:n}=e;return n(["Für Firmen"])},for_enterprise_description:e=>{const{normalize:n}=e;return n(["Entdecken Sie skalierbare multimodale KI-Strategien, die auf die Geschäftsanforderungen zugeschnitten sind."])},for_power_users:e=>{const{normalize:n}=e;return n(["Für Power-User"])},for_power_users_description:e=>{const{normalize:n}=e;return n(["Nutzen Sie unsere optimierten multimodalen Tools, um Ihre Produktivität zu steigern."])},internship1:e=>{const{normalize:n}=e;return n(["Praktikantenprogramm"])},jobs:e=>{const{normalize:n}=e;return n(["Begleiten Sie uns"])},join_discord:e=>{const{normalize:n}=e;return n(["Treten Sie unserer Discord-Community bei"])},logos:e=>{const{normalize:n}=e;return n(["Logo herunterladen"])},maximize:e=>{const{normalize:n}=e;return n(["⇧1"])},maximize_btn:e=>{const{normalize:n}=e;return n(["Maximieren"])},news:e=>{const{normalize:n}=e;return n(["Pressemitteilungen"])},open_day:e=>{const{normalize:n}=e;return n(["Tag der offenen Tür"])},open_in_full:e=>{const{normalize:n}=e;return n(["Alle Enterprise-Produkte in einem neuen Fenster anzeigen"])},power_users_others:e=>{const{normalize:n}=e;return n(["Mehr Power-User-Tools"])},products:e=>{const{normalize:n}=e;return n(["Produkte"])}},hub:{description:e=>{const{normalize:n}=e;return n(["Teilen und entdecken Sie Bausteine ​​für multimodale KI-Anwendungen"])}},huggingface:{sentence_similarity:e=>{const{normalize:n}=e;return n(["Text-Embedding"])},updated_about:e=>{const{normalize:n}=e;return n(["Aktualisiert über"])}},impact_snapshots:{project1:e=>{const{normalize:n}=e;return n(["Ermöglicht eine hochpräzise Suche in 3D-Netzdaten unter Verwendung von Punktwolkeninformationen."])},project10:e=>{const{normalize:n}=e;return n(["Nutzung von Computer Vision zur Verbesserung der digitalen Zugänglichkeit von Regierungswebsites."])},project11:e=>{const{normalize:n}=e;return n(["Fein abgestimmtes LLM für ein Beratungsunternehmen zur Optimierung der Finanzdatenanalyse."])},project12:e=>{const{normalize:n}=e;return n(["Fortschrittliche Marketingstrategien durch Feinabstimmung von Text-zu-Bild-Modellen für die Stilübertragung."])},project2:e=>{const{normalize:n}=e;return n(["Entwickelte eine inhaltsbasierte Suchmaschine für kurze Animationsfilme."])},project3:e=>{const{normalize:n}=e;return n(["Verbesserte E-Commerce-Conversion-Rates durch Feinabstimmung der Embedding-Modelle."])},project4:e=>{const{normalize:n}=e;return n(["Durchführung zeitnaher Optimierungen zur Effizienzsteigerung für ein Unternehmensberatungen."])},project5:e=>{const{normalize:n}=e;return n(["Pionierarbeit beim Verständnis von Spielszenen und automatischer Annotation für ein führendes Gaming-Unternehmen."])},project6:e=>{const{normalize:n}=e;return n(["Implementierung einer Echtzeit-Prompt-Erweiterung für ein Chatbot-Unternehmen, um das Benutzererlebnis zu verbessern."])},project7:e=>{const{normalize:n}=e;return n(["Revolutionierte die Rechtstechnologie, indem es eine effiziente Suche in umfangreichen Rechtsdokumenten ermöglichte."])},project8:e=>{const{normalize:n}=e;return n(["Unterstützung eines generativen Kunstdienstes mit hohem Durchsatz für groß angelegte Operationen."])},project9:e=>{const{normalize:n}=e;return n(["Durchführung von Process-Mining und Modellierung unter Verwendung fortschrittlicher Sprachmodelle."])}},inference:{description:e=>{const{normalize:n}=e;return n(["Hochmoderne multimodale KI-Modelle stehen für Sie über unsere API zur Verfügung"])}},integrations:{embedding:e=>{const{normalize:n}=e;return n(["Einbettungen"])},reranker:e=>{const{normalize:n}=e;return n(["Neubewerter"])},which_to_go:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Welches soll mit ",r(i("_vendor"))," integriert werden?"])}},internship_faq:{answer1:e=>{const{normalize:n}=e;return n(["Bachelor-, Master- und Ph.D.-Studiengänge Studierende aus der ganzen Welt mit Interesse an Bereichen wie Forschung, Ingenieurwesen, Marketing und Vertrieb werden aufgefordert, sich zu bewerben. Wir freuen uns auch über nicht-technische Praktika in den Bereichen Marketing, Vertrieb, Assistenz von Führungskräften und mehr. Wir suchen leidenschaftliche Menschen, die bereit sind, mit uns Pionierarbeit in der multimodalen KI zu leisten."])},answer10:e=>{const{normalize:n}=e;return n(["Ja, unser Praktikumsprogramm bietet eine wettbewerbsfähige Vergütung."])},answer11:e=>{const{normalize:n}=e;return n(["Als Jina AI-Praktikant sammeln Sie praktische Erfahrungen bei der Arbeit an anspruchsvollen Projekten, lernen von Branchenexperten, werden Teil einer lebendigen Community und haben die Möglichkeit, echte Beiträge zu unserer Pionierarbeit in der multimodalen KI zu leisten."])},answer2:e=>{const{normalize:n}=e;return n(["Praktika müssen vor Ort in einem unserer Büros in Berlin, Peking und Shenzhen absolviert werden."])},answer3:e=>{const{normalize:n}=e;return n(["Ja, Jina AI bietet erfolgreichen Antragstellern angemessene Unterstützung im Visumverfahren."])},answer4:e=>{const{normalize:n}=e;return n(["Ja, Jina AI bietet Praktikanten während des Praktikums eine angemessene Deckung der Lebenshaltungskosten an."])},answer5:e=>{const{normalize:n}=e;return n(["Ja, die Anfertigung Ihrer Masterarbeit während Ihres Praktikums bei Jina AI ist in der Regel für Studierende deutscher Hochschulen möglich. Sie benötigen jedoch eine vorherige Mitteilung und Zustimmung des Betreuers Ihrer Universität. Beachten Sie, dass wir Studierenden nicht bei der Suche nach Beratern helfen."])},answer6:e=>{const{normalize:n}=e;return n(["Der Bewerbungsprozess umfasst die Einreichung Ihres Bewerbungsformulars, eines Lebenslaufs, eines Anschreibens, in dem Sie Ihr Interesse und Ihre Motivation zum Ausdruck bringen, sowie aller relevanten beruflichen Links wie GitHub oder LinkedIn. Wir bewerten Kandidaten anhand ihrer Leistung während des Vorstellungsgesprächs und ihrer Leistung an ihrer Universität."])},answer7:e=>{const{normalize:n}=e;return n(["Ja, erfolgreiche Praktikanten können am Ende ihres Praktikums ein Empfehlungsschreiben erhalten, das von unserem CEO unterzeichnet wird."])},answer8:e=>{const{normalize:n}=e;return n(["Die Dauer des Praktikums variiert je nach Rolle und Projekt. In der Regel liegt sie jedoch zwischen drei und sechs Monaten."])},answer9:e=>{const{normalize:n}=e;return n(["Ja, wir freuen uns über Bewerbungen mit allen akademischen Hintergründen. Wir schätzen Ihre Leidenschaft und Ihr Engagement für das Lernen ebenso wie Ihre vorherige Erfahrung."])},question1:e=>{const{normalize:n}=e;return n(["Wer kann sich für das Jina AI-Praktikumsprogramm bewerben?"])},question10:e=>{const{normalize:n}=e;return n(["Ist das ein bezahltes Praktikum?"])},question11:e=>{const{normalize:n}=e;return n(["Welche Möglichkeiten habe ich als Jina AI-Praktikant?"])},question2:e=>{const{normalize:n}=e;return n(["Wo findet das Praktikum statt?"])},question3:e=>{const{normalize:n}=e;return n(["Unterstützt Jina AI bei Visa-Prozessen?"])},question4:e=>{const{normalize:n}=e;return n(["Bietet Jina AI Praktikanten Zulagen oder Vorteile?"])},question5:e=>{const{normalize:n}=e;return n(["Kann ich während des Praktikums bei Jina AI an meiner Masterarbeit arbeiten?"])},question6:e=>{const{normalize:n}=e;return n(["Wie läuft der Bewerbungsprozess ab?"])},question7:e=>{const{normalize:n}=e;return n(["Stellt Jina AI nach dem Praktikum ein Empfehlungsschreiben aus?"])},question8:e=>{const{normalize:n}=e;return n(["Wie lange dauert das Praktikum?"])},question9:e=>{const{normalize:n}=e;return n(["Kann ich mich bewerben, wenn ich noch keine Erfahrung im Bereich KI habe?"])}},internship_page:{about_internship_program:e=>{const{normalize:n}=e;return n(["Über das Praktikumsprogramm"])},about_internship_program_desc1:e=>{const{normalize:n}=e;return n(["Wir freuen uns, talentierten Menschen diese einzigartige Gelegenheit bieten zu können, Teil unseres dynamischen Teams zu werden und an bahnbrechenden Projekten im Bereich der künstlichen Intelligenz mitzuwirken. Dieses Praktikum soll Ihnen wertvolle praktische Erfahrungen, Mentoring und Einblick in modernste Technologien bieten, die die Zukunft der KI prägen."])},about_internship_program_desc2:e=>{const{normalize:n}=e;return n(["Bei Jina AI wissen wir, wie wichtig es ist, junge Talente zu fördern und zu gewinnen. Wir wissen, dass Praktikanten neue Perspektiven, Begeisterung und Kreativität einbringen und unser Team mit neuen Ideen und Ansätzen beleben. Durch die Bereitstellung von Praktika wollen wir das Wachstum zukünftiger Führungskräfte in der KI-Branche fördern und ihnen gleichzeitig praktische Erfahrungen in einem unterstützenden und herausfordernden Umfeld bieten."])},alumni:e=>{const{normalize:n}=e;return n(["ALUMNI"])},alumni_network:e=>{const{normalize:n}=e;return n(["Unser florierendes Alumni-Netzwerk"])},application:e=>{const{normalize:n}=e;return n(["Anwendung"])},application_desc:e=>{const{normalize:n}=e;return n(["Begeben Sie sich mit Jina AI auf eine transformative Reise. Unser umfassendes Praktikumsprogramm lädt alle leidenschaftlichen Köpfe ein, die die Zukunft der künstlichen Intelligenz mitgestalten möchten. Kommen Sie zu uns, um praktische Erfahrungen zu sammeln, an anspruchsvollen Projekten zu arbeiten und mit einigen der klügsten Köpfe der KI-Branche zusammenzuarbeiten."])},apply:e=>{const{normalize:n}=e;return n(["Jetzt bewerben"])},autumn:e=>{const{normalize:n}=e;return n(["Herbst"])},description:e=>{const{normalize:n}=e;return n(["Weltweite Ausschreibung für Studenten: Praktika in Forschung, Entwicklung, Marketing, Vertrieb und mehr."])},dev_rel_intern:e=>{const{normalize:n}=e;return n(["Praktikant im Bereich Developer Relations"])},enthusiastic:e=>{const{normalize:n}=e;return n(["ENTHUSIASTISCH"])},explore_stories_from_our_interns:e=>{const{normalize:n}=e;return n(["Entdecken Sie Geschichten unserer Praktikanten"])},explore_stories_from_our_interns1:e=>{const{normalize:n}=e;return n(["Lassen Sie sich von den Reisen unserer Praktikanten inspirieren"])},innovative:e=>{const{normalize:n}=e;return n(["INNOVATIV"])},intern_work1:e=>{const{normalize:n}=e;return n(["Fein abgestimmte LLM-Modelle für bessere Einbettungen"])},intern_work2:e=>{const{normalize:n}=e;return n(["Erkundete das Potenzial der Retrieval Augmented Generation"])},intern_work3:e=>{const{normalize:n}=e;return n(["Veröffentlichung eines Artikels zum Thema Satzeinbettungen"])},intern_work4:e=>{const{normalize:n}=e;return n(["Der Mannschaft kontinuierlich jugendliche Vitalität verleihen"])},intern_work5:e=>{const{normalize:n}=e;return n(["Benchmarked-Quantisierungstechniken zur Komprimierung von LLM"])},intern_work6:e=>{const{normalize:n}=e;return n(["Erstellen und Bewerben einer überzeugenden Kampagne für PromptPerfect"])},intern_work7:e=>{const{normalize:n}=e;return n(["Schnell entwickeltes und verbessertes JinaColBERT V2"])},recruiting_and_administrative_intern:e=>{const{normalize:n}=e;return n(["Praktikant im Bereich Personalbeschaffung und Verwaltung"])},researcher_intern:e=>{const{normalize:n}=e;return n(["Wissenschaftlicher Praktikant"])},self_motivated:e=>{const{normalize:n}=e;return n(["SELBST MOTIVIERT"])},software_engineer_intern:e=>{const{normalize:n}=e;return n(["Praktikant im Bereich Software-Ingenieur"])},spring:e=>{const{normalize:n}=e;return n(["Frühling"])},submit_application:e=>{const{normalize:n}=e;return n(["Starten Sie Ihr Abenteuer mit Jina AI"])},subtitle:e=>{const{normalize:n}=e;return n(["Unser Vollzeit-Praktikumsprogramm bietet praktische Arbeitserfahrung durch gut konzipierte Praktikumsprojekte in einem breiten Spektrum."])},subtitle1:e=>{const{normalize:n}=e;return n(["Weltweiter Aufruf für Studenten: Praktikanten in Forschung, Technik, Marketing, Vertrieb und mehr, um gemeinsam Pionierarbeit für multimodale KI zu leisten."])},summer:e=>{const{normalize:n}=e;return n(["Sommer"])},title:e=>{const{normalize:n}=e;return n(["Praktikantenprogramm"])},who_do_we_look_for:e=>{const{normalize:n}=e;return n(["Wen suchen wir?"])},who_do_we_look_for_desc:e=>{const{normalize:n}=e;return n(["Wir legen Wert auf Vielfalt und ermutigen Bewerber mit unterschiedlichen Profilen und Hintergründen, an unserem Praktikumsprogramm teilzunehmen. Die Praktikumsmöglichkeiten werden in mehreren Abteilungen angeboten, darunter Technik, Design, Produktmanagement, Vertrieb und Account Management, Marketing und Community Management."])},winter:e=>{const{normalize:n}=e;return n(["Winter"])}},jcloud:{description:e=>{const{normalize:n}=e;return n(["Stellen Sie ein lokales Projekt als Cloud-Dienst bereit. Radikal einfach, keine bösen Überraschungen."])}},jerboa:{description:e=>{const{normalize:n}=e;return n(["Ein experimenteller Finetuner für Open-Source-LLMs"])}},jina:{description:e=>{const{normalize:n}=e;return n(["Erstellen Sie multimodale KI-Anwendungen in der Cloud"])}},jina_chat:{description:e=>{const{normalize:n}=e;return n(["Mehr Modalitäten, längerer Speicher, weniger Kosten"])},example_1:e=>{const{normalize:n}=e;return n(["Wer bist du?"])},example_2:e=>{const{normalize:n}=e;return n(["Ich bin ein LLM-Chat-Dienst von Jina AI"])}},lab_dialog:{GlobalQA:{description:e=>{const{normalize:n}=e;return n(["Drücken Sie auf einer beliebigen Seite die Taste „/“, um das Fragenfeld zu öffnen. Geben Sie Ihre Anfrage ein und drücken Sie die Eingabetaste, um Antworten zu erhalten, die sich direkt auf den Seiteninhalt beziehen. Diese Funktion wird von PromptPerfect unterstützt."])},title:e=>{const{normalize:n}=e;return n(["On-Page-RAG"])}},Recommender:{description:e=>{const{normalize:n}=e;return n(["Öffnen Sie das Empfehlungsfeld auf einer beliebigen Nachrichtenseite mit „Umschalt+2“. Wählen Sie das Reranker-Modell aus, um die Top-5-Artikel zu dieser Nachrichtenseite zu entdecken. Genießen Sie diese Echtzeitfunktion, die von unserer Reranker-API unterstützt wird."])},title:e=>{const{normalize:n}=e;return n(["Verwandter Artikel"])}},SceneXplainTooltip:{description:e=>{const{normalize:n}=e;return n(["Bewegen Sie Ihren Mauszeiger über ein beliebiges Bild auf Nachrichtenseiten oder in unserem Newsroom-Katalog, um die Beschreibung dieses Bildes anzuzeigen. Beschreibungen werden von SceneXplain vorberechnet und zur Barrierefreiheit in das ALT-Attribut des Bildes eingebettet."])},title:e=>{const{normalize:n}=e;return n(["Bildunterschrift"])}},explain:e=>{const{normalize:n}=e;return n(["Entdecken Sie versteckte Funktionen auf unserer Website"])}},landing_page:{also_available_on:e=>{const{normalize:n}=e;return n(["Auch auf den Marktplätzen erhältlich"])},also_available_on1:e=>{const{normalize:n}=e;return n(["Verfügbar auf den Marktplätzen Ihrer Enterprise Cloud"])},ask_how_your_question:e=>{const{normalize:n}=e;return n(["Bitte beschreibe dein Problem"])},autotune:e=>{const{normalize:n}=e;return n(["Automatische Feinabstimmung"])},badge:{v2:e=>{const{normalize:n}=e;return n(["V2-Version!"])},v3:e=>{const{normalize:n}=e;return n(["V3-Version!"])}},build_js:e=>{const{normalize:n}=e;return n(["JavaScript SDK verwenden"])},build_python:e=>{const{normalize:n}=e;return n(["Python SDK verwenden"])},ccbync:e=>{const{normalize:n}=e;return n(["Dieses Modell ist unter CC BY-NC 4.0 lizenziert. Verwenden Sie es über die API oder unser offizielles AWS/Azure-Image oder wenden Sie sich für die Bereitstellung vor Ort an den Vertrieb."])},checkout_our_solution_for_you:e=>{const{normalize:n}=e;return n(["Entdecken Sie unsere auf Sie zugeschnittene Lösung"])},classifier:e=>{const{normalize:n}=e;return n(["Klassifikator"])},coming_soon:e=>{const{normalize:n}=e;return n(["Demnächst"])},contact_sales:e=>{const{normalize:n}=e;return n(["Kontakt"])},copied_to_clipboard:e=>{const{normalize:n}=e;return n(["In die Zwischenablage kopiert"])},copy:e=>{const{normalize:n}=e;return n(["Kopieren"])},developers:e=>{const{normalize:n}=e;return n(["Entwickler"])},developers_desc:e=>{const{normalize:n}=e;return n(["Nutzen Sie die volle Leistungsfähigkeit multimodaler KI mit modernsten Cloud-Technologien und Open-Source-Infrastruktur."])},download_pdf:e=>{const{normalize:n}=e;return n(["PDF Herunterladen"])},embedding:e=>{const{normalize:n}=e;return n(["Einbettungen"])},embedding_desc1:e=>{const{normalize:n}=e;return n(["Leistungsstarke multimodale, mehrsprachige Langkontext-Einbettungen für Such-, RAG- und Agentenanwendungen."])},embedding_paper_desc:e=>{const{normalize:n}=e;return n(["Jina Embeddings stellt eine Reihe leistungsstarker Text-Embedding-odelle dar, die in der Lage sind, verschiedene Texteingaben in numerische Darstellungen zu übersetzen und so die semantische Essenz des Textes zu erfassen. Obwohl diese Modelle nicht ausschließlich für die Textgenerierung konzipiert sind, zeichnen sie sich durch Anwendungen wie Dense Retrieval und semantische Textähnlichkeit aus. In diesem Artikel wird die Entwicklung von Jina Embeddings detailliert beschrieben, beginnend mit der Erstellung eines hochwertigen Paar- und Triplett-Datensatzes. Es unterstreicht die entscheidende Rolle der Datenbereinigung bei der Datensatzvorbereitung, gibt detaillierte Einblicke in den Modelltrainingsprozess und schließt mit einer umfassenden Leistungsbewertung mithilfe des Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:n}=e;return n(["Jina Embeddings: Ein neuartiger Satz leistungsstarker Text-Embedding-Modelle"])},embeddings:e=>{const{normalize:n}=e;return n(["Einbettungen"])},enterprise:e=>{const{normalize:n}=e;return n(["Unternehmen"])},enterprise_desc:e=>{const{normalize:n}=e;return n(["Steigern Sie Ihr Geschäft mit skalierbaren, sicheren und maßgeschneiderten multimodalen KI-Lösungen."])},enterprise_desc_v2:e=>{const{normalize:n}=e;return n(["Probieren Sie unsere erstklassigen Einbettungsmodelle aus, um Ihre Such- und RAG-Systeme zu verbessern. Beginnen Sie mit einer kostenlosen Testversion!"])},enterprise_desc_v3:e=>{const{normalize:n}=e;return n(["Unsere Frontier-Modelle bilden die Suchgrundlage für hochwertige Enterprise-Search- und RAG-Systeme."])},error:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Beim Abrufvorgang ist ein Problem aufgetreten: ",r(i("message"))])},find_your_portal:e=>{const{normalize:n}=e;return n(["Wählen Sie Ihr Portal"])},finding_faq:e=>{const{normalize:n}=e;return n(["Generieren einer Antwort basierend auf dem FAQ-Wissen unten"])},for:e=>{const{normalize:n}=e;return n(["Für"])},for_developers:e=>{const{normalize:n}=e;return n(["Für Entwickler"])},for_enterprise:e=>{const{normalize:n}=e;return n(["Für Unternehmen"])},for_power_users:e=>{const{normalize:n}=e;return n(["Für Power-User"])},get_api_now:e=>{const{normalize:n}=e;return n(["API"])},get_started:e=>{const{normalize:n}=e;return n(["Loslegen"])},go_to_product_homepage:e=>{const{normalize:n}=e;return n(["Zur Produkthomepage"])},how_to:e=>{const{normalize:n}=e;return n(["Wie man"])},include_experiment:e=>{const{normalize:n}=e;return n(["Bezieht unsere experimentellen und archivierten Projekte in die Lösung ein."])},join_community:e=>{const{normalize:n}=e;return n(["Gemeinschaft"])},learn_more_embeddings:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr über Einbettungen"])},learn_more_reader:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr über den Reader"])},learn_more_reranker:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr über Reranker"])},llm:e=>{const{normalize:n}=e;return n(["LLM-Embedding-Modelle"])},llm_desc:e=>{const{normalize:n}=e;return n(["Wir bieten eine Sammlung leistungsstarker Text-Embedding-Modelle mit 35 Millionen bis 6 Milliarden Parametern. Sie eignen sich hervorragend zur Verbesserung der neuronalen Suche, Neuordnung, Satzähnlichkeit, Empfehlungen usw. Machen Sie sich bereit, Ihr KI-Erlebnis zu verbessern!"])},mentioned_products:e=>{const{normalize:n}=e;return n(["Erwähnte Produkte:"])},mmstack:e=>{const{normalize:n}=e;return n(["Multimodaler Stapel"])},mmstack_desc:e=>{const{normalize:n}=e;return n(["Im Laufe der Jahre haben wir eine Vielzahl von Open-Source-Software entwickelt, die Entwicklern hilft, schneller bessere GenAI- und Suchanwendungen zu erstellen."])},models:e=>{const{normalize:n}=e;return n(["Modelle"])},more:e=>{const{normalize:n}=e;return n(["Mehr"])},multimodal:e=>{const{normalize:n}=e;return n(["Multimodal"])},multimodal_ai:e=>{const{normalize:n}=e;return n(["Multimodalen KI"])},new:e=>{const{normalize:n}=e;return n(["Neu"])},newsroom:e=>{const{normalize:n}=e;return n(["Pressemitteilungen"])},num_publications:e=>{const{normalize:n,interpolate:r,named:i}=e;return n([r(i("_total"))," Veröffentlichungen insgesamt."])},"on-prem-deploy":e=>{const{normalize:n}=e;return n(["Bereitstellung vor Ort"])},"on-premises":e=>{const{normalize:n}=e;return n(["Auf dem Gelände"])},opensource:e=>{const{normalize:n}=e;return n(["Open Source"])},our_customer:e=>{const{normalize:n}=e;return n(["Unsere Kunden"])},our_customer_explain:e=>{const{normalize:n}=e;return n(["Unternehmen jeder Größe vertrauen beim Aufbau ihrer Tools und Produkte auf die Search Foundation von Jina AI – das können Sie auch."])},our_publications:e=>{const{normalize:n}=e;return n(["Unsere Veröffentlichungen"])},parameters:e=>{const{normalize:n}=e;return n(["Parameter"])},podcast:e=>{const{normalize:n}=e;return n(["Podcast"])},power_users:e=>{const{normalize:n}=e;return n(["Power-User"])},power_users_desc:e=>{const{normalize:n}=e;return n(["Auto-Prompt-Engineering für Ihre tägliche Produktivität."])},powered_by_promptperfect:e=>{const{normalize:n}=e;return n(["Unterstützt durch die Funktionen „Prompt-Optimierung“ und „Prompt as a Service“ von PromptPerfect"])},pricing:e=>{const{normalize:n}=e;return n(["Preisgestaltung"])},proposing_solution:e=>{const{normalize:n}=e;return n(["Vorschlag einer Lösung basierend auf Jina AI-Produkten..."])},read_more:e=>{const{normalize:n}=e;return n(["Weiterlesen"])},reader:e=>{const{normalize:n}=e;return n(["Leser"])},require_full_question:e=>{const{normalize:n}=e;return n(["Bitte beschreiben Sie Ihr Problem detaillierter."])},reranker:e=>{const{normalize:n}=e;return n(["Reranker"])},researcher_desc:e=>{const{normalize:n}=e;return n(["Erfahren Sie, wie unsere bahnbrechenden Suchmodelle von Grund auf trainiert wurden, und sehen Sie sich unsere neuesten Veröffentlichungen an. Lernen Sie unser Team bei EMNLP, SIGIR, ICLR, NeurIPS und ICML kennen!"])},researchers:e=>{const{normalize:n}=e;return n(["Forscher"])},sdk:e=>{const{normalize:n}=e;return n(["SDK"])},sdk_desc:e=>{const{normalize:n}=e;return n(["Möchten Sie zukunftsweisende AIGC-Anwendungen erstellen? Mit den APIs PromptPerfect, SceneXplain, BestBanner, JinaChat und Rationale ist das einfach. Probieren Sie unser benutzerfreundliches SDK aus und legen Sie in wenigen Minuten los."])},sdk_docs:e=>{const{normalize:n}=e;return n(["Lesen Sie die Dokumente"])},sdk_example:e=>{const{normalize:n}=e;return n(["Beispiel"])},search_foundation:e=>{const{normalize:n}=e;return n(["Stiftung durchsuchen"])},source_code:e=>{const{normalize:n}=e;return n(["Quellcode"])},starter_kit:e=>{const{normalize:n}=e;return n(["Starter-Kit"])},supercharged1:e=>{const{normalize:n}=e;return n(["Aufgeladen."])},tokenizer:e=>{const{normalize:n}=e;return n(["Segmentierer"])},trusted_by:e=>{const{normalize:n}=e;return n(["UNSERE PARTNER"])},try_it_for_free:e=>{const{normalize:n}=e;return n(["Beginnen Sie sofort – keine Kreditkarte oder Registrierung erforderlich!"])},try_our_saas:e=>{const{normalize:n}=e;return n(["Probieren Sie unsere gehostete Lösung aus, einen direkten Ersatz für die Einbettungs-API von OpenAI."])},your_portal_to:e=>{const{normalize:n}=e;return n(["Ihr Portal zur"])},your_search_foundation1:e=>{const{normalize:n}=e;return n(["Ihre Suchgrundlage"])}},langchain_serve:{description:e=>{const{normalize:n}=e;return n(["Langchain-Apps in der Produktion mit Jina und FastAPI"])}},model_graph:{api:e=>{const{normalize:n}=e;return n(["Jina KI-API"])},contact_sales_about_it:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie hierzu den Vertrieb"])},deploy_it_on:e=>{const{normalize:n}=e;return n(["Bereitstellen auf"])},description:e=>{const{normalize:n}=e;return n(["Im Laufe der Jahre haben wir die Grenzen der Suche immer weiter erweitert. Nachfolgend finden Sie die Modelle, die wir veröffentlicht haben. Bewegen Sie den Mauszeiger darüber oder klicken Sie auf die einzelnen Modelle, um weitere Details anzuzeigen."])},find_on_hf:e=>{const{normalize:n}=e;return n(["Finden Sie es auf HuggingFace"])},search_for:e=>{const{normalize:n}=e;return n(["Suchen Sie auf unserer Website"])},search_models:e=>{const{normalize:n}=e;return n(["Nach Modellnamen filtern"])},title:e=>{const{normalize:n}=e;return n(["Unsere Search Foundation-Modelle"])},use_it_via:e=>{const{normalize:n}=e;return n(["Nutzen Sie es über"])}},news_page:{back_to_newsroom:e=>{const{normalize:n}=e;return n(["Zurück zum Newsroom"])},categories:e=>{const{normalize:n}=e;return n(["Kategorien"])},copy_link:e=>{const{normalize:n}=e;return n(["Kopieren Sie den Link zu diesem Abschnitt"])},in_this_article:e=>{const{normalize:n}=e;return n(["In diesem Artikel"])},learn_more:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr"])},news_not_found:e=>{const{normalize:n}=e;return n(["Artikel nicht gefunden"])},redirect_to_news:e=>{const{normalize:n}=e;return n(["Weiterleitung zum Newsroom in 5 Sekunden..."])}},newsroom_page:{academic:e=>{const{normalize:n}=e;return n(["Akademisch"])},academic_research:e=>{const{normalize:n}=e;return n(["Wissenschaftliche Publikationen"])},author:e=>{const{normalize:n}=e;return n(["Filtern nach Autor"])},description:e=>{const{normalize:n}=e;return n(["Lesen Sie die neuesten Nachrichten und Updates von Jina AI."])},description1:e=>{const{normalize:n}=e;return n(["KI-Innovationen entwickeln, Wort für Wort."])},engineering_group:e=>{const{normalize:n}=e;return n(["Engineering-Gruppe"])},engineering_group_date:e=>{const{normalize:n}=e;return n(["31. Mai 2021"])},minutes_read:e=>{const{normalize:n}=e;return n(["Minuten gelesen"])},most_recent_articles:e=>{const{normalize:n}=e;return n(["Neueste Artikel"])},news_description:e=>{const{normalize:n}=e;return n(["Bei Jina 2.0 haben wir auf die Community gehört. Wirklich tief zugehört. „Was sind Ihre Schmerzpunkte?“ „, fragten wir und waren gespannt auf wertvolles Feedback.“"])},news_title:e=>{const{normalize:n}=e;return n(["Durchsuchen Sie alle Dinge: Wir veranstalten einen MEME-Wettbewerb für Jina 2.0"])},photos:e=>{const{normalize:n}=e;return n(["Fotos"])},product:e=>{const{normalize:n}=e;return n(["Nach Produkt filtern"])},search:e=>{const{normalize:n}=e;return n(["Suche nach Titel"])},tech_blog:e=>{const{normalize:n}=e;return n(["Tech-Blog"])},title:e=>{const{normalize:n}=e;return n(["Pressemitteilungen"])},top_stories:e=>{const{normalize:n}=e;return n(["Top-Geschichten"])}},notice:e=>{const{normalize:n}=e;return n(["🎉 Unser erstes Buch „Neural Search – From Prototype to Production with Jina“ ist heute offiziell erhältlich!"])},open_day:{description:e=>{const{normalize:n}=e;return n(["Eine exklusive Gelegenheit, einen Insider-Einblick in Jina AI zu gewinnen."])},engage:e=>{const{normalize:n}=e;return n(["Wir fördern den interaktiven Dialog den ganzen Tag über. Der Austausch von Gedanken und Perspektiven ist für uns von unschätzbarem Wert. Mögliche Kooperationen, die sich aus diesen Diskussionen ergeben, könnten erheblich zu einer stärker integrierten und innovativeren Zukunft beitragen."])},engage_title:e=>{const{normalize:n}=e;return n(["Beteiligen Sie sich an uns"])},experience:e=>{const{normalize:n}=e;return n(["Wir haben für unsere Gäste eine immersive dreistündige Tour zusammengestellt, die auf Deutsch, Englisch, Französisch, Spanisch, Chinesisch und Russisch verfügbar ist. Die Tour bietet einen detaillierten Einblick in unsere Fortschritte in der multimodalen KI, unsere Sicht auf die KI-Landschaft, gefolgt von einer detaillierten Untersuchung spezifischer Projekte. Wir schließen mit einer Gruppendiskussion ab, um den Austausch von Ideen und Erkenntnissen zu erleichtern. Auf Anfrage ist auch ein Mittagessen erhältlich."])},experience_title:e=>{const{normalize:n}=e;return n(["Die Reise eines Insiders"])},group_size:e=>{const{normalize:n}=e;return n(["Geschätzte Besucherzahl"])},impact:e=>{const{normalize:n}=e;return n(["Erfahren Sie, wie unsere Beiträge zur Open-Source-Community und unsere Arbeit in der multimodalen KI-Technologie Jina AI als einflussreichen Akteur bei KI-Innovationen etablieren. Unser Ziel ist es, eine wichtige Rolle in Entscheidungsprozessen zu spielen und sicherzustellen, dass die Weiterentwicklung der KI-Technologie allen zugute kommt."])},impact_title:e=>{const{normalize:n}=e;return n(["Wirkung und Einfluss"])},introduction:e=>{const{normalize:n}=e;return n(["Jina AI freut sich, unsere Türen für angesehene Unternehmen und Organisationen zu öffnen, die sich für den Fortschritt und die Zukunft der künstlichen Intelligenz interessieren. Diese exklusive Gelegenheit bieten wir Vertretern aus Politik, NGOs, NPOs und der Investmentbranche an, hier in unserem Berliner Hauptsitz einen Insider-Blick auf unsere Aktivitäten und Visionen zu erhalten."])},motivation_min_length_v1:e=>{const{normalize:n}=e;return n(["Bitte geben Sie eine detailliertere Motivation an."])},motivation_placeholder_v2:e=>{const{normalize:n}=e;return n(["Wenn Sie uns Ihre Beweggründe mitteilen, können wir Ihr Erlebnis verbessern."])},motivation_to_attend_v2:e=>{const{normalize:n}=e;return n(["Warum interessieren Sie sich für unseren Tag der offenen Tür?"])},one_hour:e=>{const{normalize:n}=e;return n(["1 Stunde"])},organization:e=>{const{normalize:n}=e;return n(["Organisation"])},organization_website:e=>{const{normalize:n}=e;return n(["Website der Organisation"])},organization_website_placeholder:e=>{const{normalize:n}=e;return n(["URL für die Homepage oder das LinkedIn-Profil Ihrer Organisation"])},preferred_date:e=>{const{normalize:n}=e;return n(["Bevorzugtes Datum"])},preferred_language:e=>{const{normalize:n}=e;return n(["Bevorzugte Sprache der Tour"])},preferred_products:e=>{const{normalize:n}=e;return n(["Für welche Produkte interessieren Sie sich?"])},subtitle:e=>{const{normalize:n}=e;return n(["Ein Blick in die Zukunft der multimodalen KI"])},title:e=>{const{normalize:n}=e;return n(["Tag der offenen Tür"])},tutor_subtitle:e=>{const{normalize:n}=e;return n(["Eine sorgfältig kuratierte dreistündige Tour, die Ihnen den Kern der bahnbrechenden Arbeit von Jina AI in der multimodalen KI-Technologie näher bringt."])},tutor_title:e=>{const{normalize:n}=e;return n(["Ein exklusiver tiefer Einblick in"])},vision:e=>{const{normalize:n}=e;return n(["Verschaffen Sie sich mit uns einen umfassenden Überblick über die KI-Landschaft aus unserer Sicht. Unsere Diskussion konzentriert sich auf das Potenzial großer Sprachmodelle, multimodaler KI und den Einfluss von Open-Source-Technologie auf die Gestaltung der Zukunft globaler Innovation."])},vision_title:e=>{const{normalize:n}=e;return n(["Unsere Vision für die Zukunft"])}},open_day_faq:{answer1:e=>{const{normalize:n}=e;return n(["Wir bieten Führungen auf Deutsch, Englisch, Französisch, Spanisch, Chinesisch und Russisch an."])},answer2:e=>{const{normalize:n}=e;return n(["Die Tour dauert normalerweise etwa drei Stunden."])},answer3:e=>{const{normalize:n}=e;return n(["Das Mittagessen ist optional und kann auf Anfrage arrangiert werden."])},answer4:e=>{const{normalize:n}=e;return n(["Unser Tag der offenen Tür richtet sich in erster Linie an Berufsgruppen wie Politiker, NGOs, NPOs und Investoren. Allerdings machen wir gelegentlich Ausnahmen basierend auf dem Profil der Person."])},answer5:e=>{const{normalize:n}=e;return n(["Wir können unterschiedliche Gruppengrößen unterbringen. Bitte geben Sie im Anmeldeformular die Größe Ihrer Gruppe an und wir klären die Einzelheiten mit Ihnen ab."])},answer6:e=>{const{normalize:n}=e;return n(["Im Anmeldeformular gibt es einen Abschnitt, in dem Sie Ihre Interessengebiete oder spezielle Wünsche angeben können. Wir werden unser Bestes tun, um die Tour Ihren Bedürfnissen anzupassen."])},answer7:e=>{const{normalize:n}=e;return n(["Derzeit bieten wir Führungen nur in unserem Berliner Hauptsitz in Kreuzberg an. Unsere Büros in Peking und Shenzhen sind derzeit nicht für Führungen geöffnet."])},question1:e=>{const{normalize:n}=e;return n(["Welche Sprachen bieten Sie für die Tour an?"])},question2:e=>{const{normalize:n}=e;return n(["Wie lange dauert die Tour?"])},question3:e=>{const{normalize:n}=e;return n(["Wird Mittagessen angeboten?"])},question4:e=>{const{normalize:n}=e;return n(["Können sich Einzelpersonen für den Tag der offenen Tür anmelden?"])},question5:e=>{const{normalize:n}=e;return n(["Aus wie vielen Personen darf eine Gruppe am Tag der offenen Tür bestehen?"])},question6:e=>{const{normalize:n}=e;return n(["Wie kann ich Interessengebiete für die Tour angeben?"])},question7:e=>{const{normalize:n}=e;return n(["Sind Führungen in Ihren Büros in Peking oder Shenzhen verfügbar?"])}},open_gpt:{description:e=>{const{normalize:n}=e;return n(["Ein Open-Source-Cloud-natives Framework für die Bereitstellung großer multimodaler KI-Modelle"])}},paywall:{commercial_licence:{chip_label:e=>{const{normalize:n}=e;return n(["Exklusiv für kleine Unternehmen"])},company_size_note:e=>{const{normalize:n}=e;return n(["Exklusiv für Unternehmen mit weniger als 100 Mitarbeitern und einem Umsatz von 5 Mio. USD"])},cta_button:e=>{const{normalize:n}=e;return n(["Erste Schritte"])},download_title:e=>{const{normalize:n}=e;return n(["Kommerzielle Lizenz herunterladen"])},feature_api_desc:e=>{const{normalize:n}=e;return n(["Vor dem Kauf testen"])},feature_api_title:e=>{const{normalize:n}=e;return n(["Kostenloser API-Testzugriff"])},feature_consulting:e=>{const{normalize:n}=e;return n(["Vierteljährlich 2-stündiges Beratungsgespräch mit unseren Modellexperten"])},feature_consulting_desc:e=>{const{normalize:n}=e;return n(["Drei (3) Stunden technische Beratungsleistungen pro Lizenzperiode."])},feature_future_support:e=>{const{normalize:n}=e;return n(["Zugriff auf zukünftige CC BY-NC-Modelle ohne Erlaubnis"])},feature_future_support_desc:e=>{const{normalize:n}=e;return n(["Alle neuen Modelle, die vom Lizenzgeber während der Lizenzlaufzeit unter CC-BY-NC-4.0 veröffentlicht werden."])},feature_models:e=>{const{normalize:n}=e;return n(["Unbegrenzte kommerzielle Nutzung unserer CC BY-NC-Modelle"])},feature_models_desc:e=>{const{normalize:n}=e;return n(["Verwenden Sie die Modelle für kommerzielle Zwecke, einschließlich der internen Verwendung oder der Einbindung in kundenorientierte Anwendungen."])},price_amount:e=>{const{normalize:n}=e;return n(["1.000 US-Dollar"])},price_period:e=>{const{normalize:n}=e;return n(["/ Viertel"])},read_the_terms:e=>{const{normalize:n}=e;return n(["Lizenzbedingungen überprüfen"])},read_the_terms_btn:e=>{const{normalize:n}=e;return n(["Bedingungen"])},read_the_terms_desc:e=>{const{normalize:n}=e;return n(["Überprüfen Sie vor dem Kauf die kommerziellen Lizenzrechte und -beschränkungen"])},subtitle:e=>{const{normalize:n}=e;return n(["Alle Modelle, die Sie für eine bessere Suche benötigen"])},test_before_purchase:e=>{const{normalize:n}=e;return n(["Vor dem Kauf ausprobieren"])},test_before_purchase_desc:e=>{const{normalize:n}=e;return n(["Holen Sie sich 1 Million kostenlose API-Token oder nutzen Sie unser Hugging Face-Modell zur Leistungsüberprüfung"])},title:e=>{const{normalize:n}=e;return n(["Kommerzielle Lizenz"])},try_api:e=>{const{normalize:n}=e;return n(["Probieren Sie zuerst die API aus"])}},free_hour_consult:e=>{const{normalize:n}=e;return n(["Kostenlose 1-stündige Beratung"])},free_hour_consult_description:e=>{const{normalize:n}=e;return n(["Eine Stunde kostenlose Beratung mit unseren Produkt- und Entwicklungsteams, um die Best Practice für Ihren Anwendungsfall zu besprechen"])},full_commercial:e=>{const{normalize:n}=e;return n(["Uneingeschränkte kommerzielle Nutzung"])},full_commercial_description:e=>{const{normalize:n}=e;return n(["Sie können die API ohne Einschränkungen für kommerzielle Zwecke nutzen."])},higher_limit:e=>{const{normalize:n}=e;return n(["Deutlich höhere Ratenbegrenzung"])},higher_limit_description:e=>{const{normalize:n}=e;return n(["Erhalten Sie bis zu 1000 RPM für r.jina.ai und 100 RPM für s.jina.ai; weitere Einzelheiten im Abschnitt zur Ratenbegrenzung."])},no_commercial:e=>{const{normalize:n}=e;return n(["Nur für nichtkommerzielle Nutzung (CC-BY-NC)"])},no_commercial_description:e=>{const{normalize:n}=e;return n(["Sie können die API nur für nichtkommerzielle Zwecke verwenden. Für die kommerzielle Nutzung laden Sie bitte Ihren API-Schlüssel auf."])},on_prem:e=>{const{normalize:n}=e;return n(["Mit einer kommerziellen Lizenz für die Bereitstellung vor Ort"])},on_prem_explain:e=>{const{normalize:n}=e;return n(["Erwerben Sie eine kommerzielle Lizenz, um unsere Modelle vor Ort zu verwenden."])},priority_support:e=>{const{normalize:n}=e;return n(["Vorrangiger Kundensupport"])},priority_support_description:e=>{const{normalize:n}=e;return n(["Garantierte E-Mail-Antwort innerhalb von 24 Stunden, auch am Wochenende"])},secured_by_stripe:e=>{const{normalize:n}=e;return n(["Sichere Zahlung über Stripe"])},via_api:e=>{const{normalize:n}=e;return n(["Mit Jina Search Foundation API"])},via_api_explain:e=>{const{normalize:n}=e;return n(["Der einfachste Weg, auf alle unsere Produkte zuzugreifen. Laden Sie Tokens unterwegs auf."])}},powered_by:e=>{const{normalize:n}=e;return n(["Angetrieben von"])},print:e=>{const{normalize:n}=e;return n(["Drucken"])},project_status:{archived:e=>{const{normalize:n}=e;return n(["Archiviert"])},cloud_native:e=>{const{normalize:n}=e;return n(["Cloud-nativ"])},core:e=>{const{normalize:n}=e;return n(["Kern"])},data_structure:e=>{const{normalize:n}=e;return n(["Datenstruktur"])},embedding_serving:e=>{const{normalize:n}=e;return n(["Servieren einbetten"])},embedding_tuning:e=>{const{normalize:n}=e;return n(["Tuning einbetten"])},graduated:e=>{const{normalize:n}=e;return n(["Absolvent"])},incubating:e=>{const{normalize:n}=e;return n(["Inkubieren"])},kubernetes:e=>{const{normalize:n}=e;return n(["Kubernetes"])},large_size_model:e=>{const{normalize:n}=e;return n(["Großes Modell"])},linux_foundation:e=>{const{normalize:n}=e;return n(["Linux Foundation"])},llm1:e=>{const{normalize:n}=e;return n(["LLMOps"])},mid_size_model:e=>{const{normalize:n}=e;return n(["Mittelgroßes Modell"])},model_serving:e=>{const{normalize:n}=e;return n(["Modelldienst"])},model_tuning:e=>{const{normalize:n}=e;return n(["Modelltuning"])},observability:e=>{const{normalize:n}=e;return n(["Beobachtbarkeit"])},orchestration:e=>{const{normalize:n}=e;return n(["Orchestrierung"])},prompt_serving:e=>{const{normalize:n}=e;return n(["Prompt-Serving"])},prompt_tuning:e=>{const{normalize:n}=e;return n(["Prompt-Verbesserung"])},rag1:e=>{const{normalize:n}=e;return n(["LAPPEN"])},sandbox:e=>{const{normalize:n}=e;return n(["Sandkasten"])},small_size_model:e=>{const{normalize:n}=e;return n(["Kleines Modell"])},vector_database:e=>{const{normalize:n}=e;return n(["Vektordatenbank"])},vector_store:e=>{const{normalize:n}=e;return n(["Vector Store"])}},prompt_perfect:{description:e=>{const{normalize:n}=e;return n(["Erstklassiges Tool für schnelles Engineering"])},image_model:e=>{const{normalize:n}=e;return n(["Bildmodelle"])},intro:e=>{const{normalize:n}=e;return n(["Erstklassiges Tool für schnelles Engineering"])},intro1:e=>{const{normalize:n}=e;return n(["Das erstklassige Tool für schnelles Engineering"])},optimized:e=>{const{normalize:n}=e;return n(["Ihre Aufgabe ist es, mein Brainstorming-Partner zu sein und kreative Ideen und Vorschläge zu einem bestimmten Thema oder Problem zu liefern. Ihre Antwort sollte originelle, einzigartige und relevante Ideen enthalten, die zur Lösung des Problems beitragen oder das Thema auf interessante Weise weiter vertiefen können. Bitte beachten Sie, dass Ihre Antwort auch etwaige spezifische Anforderungen oder Einschränkungen der Aufgabe berücksichtigen sollte."])},optimized_title:e=>{const{normalize:n}=e;return n(["Optimierte Eingabeaufforderung"])},original:e=>{const{normalize:n}=e;return n(["Sei mein Brainstorming-Partner."])},original_title:e=>{const{normalize:n}=e;return n(["Ursprüngliche Aufforderung"])},text_model:e=>{const{normalize:n}=e;return n(["Textmodelle"])}},promptperfect:{features:[{description:e=>{const{normalize:n}=e;return n(["Wechseln Sie einfach zwischen Inhaltserstellung und sofortiger Optimierung und heben Sie die Qualität Ihrer Inhalte auf die nächste Stufe."])},name:e=>{const{normalize:n}=e;return n(["Assistent"])},title:e=>{const{normalize:n}=e;return n(["Tägliche Dosis Produktivität."])}},{description:e=>{const{normalize:n}=e;return n(["Sie wissen nicht, wie Sie eine effektive Anleitung schreiben? Geben Sie einfach Ihre Idee ein, ein Klick und Sie erhalten eine bessere Anleitung."])},name:e=>{const{normalize:n}=e;return n(["Schnelle Optimierung"])},title:e=>{const{normalize:n}=e;return n(["Bessere Eingänge, bessere Ausgänge"])}},{description:e=>{const{normalize:n}=e;return n(["Verstehen Sie die Stimmung jedes KI-Modells, indem Sie die Ausgaben derselben Eingabeaufforderung vergleichen."])},name:e=>{const{normalize:n}=e;return n(["Modelle vergleichen"])},title:e=>{const{normalize:n}=e;return n(["Nebeneinanderstellung der Modelle."])}},{description:e=>{const{normalize:n}=e;return n(["Dies ist möglicherweise die einfachste Möglichkeit, Ihre Eingabeaufforderungen als API zur Integration bereitzustellen."])},name:e=>{const{normalize:n}=e;return n(["Bereitstellen von Eingabeaufforderungen"])},title:e=>{const{normalize:n}=e;return n(["Keine Operationen, einfach bereitstellen."])}},{description:e=>{const{normalize:n}=e;return n(["Passen Sie Ihre eigenen LLM-Agenten an und starten Sie eine Multi-Agenten-Simulation. Sehen Sie, wie sie in einer virtuellen Umgebung zusammenarbeiten oder konkurrieren, um das Ziel zu erreichen."])},name:e=>{const{normalize:n}=e;return n(["Mehrere Agenten"])},title:e=>{const{normalize:n}=e;return n(["Erfahren Sie, wie Agenten zusammenarbeiten"])}}],get_started:e=>{const{normalize:n}=e;return n(["Erste Schritte mit PromptPerfect"])}},purchase:{success:e=>{const{normalize:n}=e;return n(["Danke für Ihren Einkauf!"])},success_caption:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Wir haben Ihre Bestellung am ",r(i("_purchasedTime"))," abgeschlossen. Ihr API-Schlüssel ist einsatzbereit!"])}},purchase_now:e=>{const{normalize:n}=e;return n(["Jetzt kaufen"])},rate_limit:{batch_explain:e=>{const{normalize:n}=e;return n(["Diese API unterstützt Batch-Operationen und ermöglicht bis zu 512 Dokumente pro Anfrage, wobei jedes Dokument bis zu 8192 Token enthalten kann. Durch die intelligente Nutzung von Batch-Operationen kann die Anzahl der Anfragen erheblich reduziert und die Leistung verbessert werden."])},classifier:e=>{const{normalize:n}=e;return n(["Trainieren eines Klassifikators anhand gekennzeichneter Beispiele"])},classifier_few_shot:e=>{const{normalize:n}=e;return n(["Klassifizieren Sie Eingaben mit einem trainierten Few-Shot-Klassifikator"])},classifier_few_shot_token_counting:e=>{const{normalize:n}=e;return n(["Token werden wie folgt gezählt: input_tokens"])},classifier_latency:e=>{const{normalize:n}=e;return n(["Die Reaktionszeit hängt von der Eingabegröße ab"])},classifier_token_counting:e=>{const{normalize:n}=e;return n(["Token werden wie folgt gezählt: input_tokens × num_iters"])},classifier_zero_shot:e=>{const{normalize:n}=e;return n(["Klassifizieren Sie Eingaben mithilfe der Zero-Shot-Klassifizierung"])},classifier_zero_shot_token_counting:e=>{const{normalize:n}=e;return n(["Token werden wie folgt gezählt: input_tokens + label_tokens"])},depends:e=>{const{normalize:n}=e;return n(["hängt von der Eingangsgröße ab"])},description:e=>{const{normalize:n}=e;return n(["Beschreibung"])},embeddings:e=>{const{normalize:n}=e;return n(["Konvertieren Sie Text/Bilder in Vektoren mit fester Länge"])},endpoint:e=>{const{normalize:n}=e;return n(["API-Endpunkt"])},explain:e=>{const{normalize:n}=e;return n(["Ratenbegrenzungen werden auf zwei Arten verfolgt: <b>RPM</b> (Anfragen pro Minute) und <b>TPM</b> (Tokens pro Minute). Begrenzungen werden pro IP durchgesetzt und können erreicht werden, je nachdem, welcher Schwellenwert (RPM oder TPM) zuerst erreicht wird."])},gjinaai:e=>{const{normalize:n}=e;return n(["Eine Aussage mit Webwissen untermauern"])},input_token_counting:e=>{const{normalize:n}=e;return n(["Zählen Sie die Anzahl der Token in der Eingabeanforderung."])},latency:e=>{const{normalize:n}=e;return n(["Durchschnittliche Latenz"])},no_token_counting:e=>{const{normalize:n}=e;return n(["Token werden nicht als Nutzung gezählt."])},output_token_counting:e=>{const{normalize:n}=e;return n(["Zählen Sie die Anzahl der Token in der Ausgabeantwort."])},premium_rate:e=>{const{normalize:n}=e;return n(["Mit Potenzial für höhere Ratenbegrenzungen"])},product:e=>{const{normalize:n}=e;return n(["Produkt"])},requestType:e=>{const{normalize:n}=e;return n(["Zulässige Anfrage"])},reranker:e=>{const{normalize:n}=e;return n(["Ordnen Sie Dokumente nach Abfrage"])},rjinaai:e=>{const{normalize:n}=e;return n(["URL in LLM-freundlichen Text konvertieren"])},sjinaai:e=>{const{normalize:n}=e;return n(["Durchsuchen Sie das Web und konvertieren Sie die Ergebnisse in LLM-freundlichen Text"])},tbd:e=>{const{normalize:n}=e;return n(["Wird noch festgelegt"])},title:e=>{const{normalize:n}=e;return n(["Ratenbegrenzung"])},tokenCounting:e=>{const{normalize:n}=e;return n(["Zählung der Token-Nutzung"])},tokenizer:e=>{const{normalize:n}=e;return n(["Tokenisieren und Segmentieren von Langtext"])},total_token_counting:e=>{const{normalize:n}=e;return n(["Zählen Sie die Gesamtzahl der Token im gesamten Vorgang."])},understanding:e=>{const{normalize:n}=e;return n(["Verstehen Sie die Ratenbegrenzung"])},understanding_description:e=>{const{normalize:n}=e;return n(["Ratenbegrenzungen sind die maximale Anzahl von Anfragen, die pro Minute pro IP-Adresse (RPM) an eine API gestellt werden können. Weitere Informationen zu den Ratenbegrenzungen für jedes Produkt und jede Stufe finden Sie weiter unten."])},wAPIkey:e=>{const{normalize:n}=e;return n(["mit API-Schlüssel"])},wPremium:e=>{const{normalize:n}=e;return n(["mit Premium-API-Schlüssel"])},woAPIkey:e=>{const{normalize:n}=e;return n(["ohne API-Schlüssel"])}},rationale:{decision:e=>{const{normalize:n}=e;return n(["Entscheidung"])},description:e=>{const{normalize:n}=e;return n(["Ultimative KI-Tools zur Entscheidungsfindung"])},intro:e=>{const{normalize:n}=e;return n(["Sehen Sie die zwei Seiten der Medaille und treffen Sie rationale Entscheidungen"])}},reader:{beta:e=>{const{normalize:n}=e;return n(["Experimental"])},better_input:e=>{const{normalize:n}=e;return n(["Verbessern Sie die Eingabequalität von Anfang an"])},better_input_description:e=>{const{normalize:n}=e;return n(["Haben Sie Probleme mit der Ausgabe Ihres Agenten oder RAG-Systems? Dies kann an der schlechten Eingabequalität liegen."])},check_price_table:e=>{const{normalize:n}=e;return n(["Überprüfen Sie die Preistabelle"])},copy:e=>{const{normalize:n}=e;return n(["Kopieren"])},demo:{advanced_usage:e=>{const{normalize:n}=e;return n(["Erweiterte Nutzung"])},ask_llm:e=>{const{normalize:n}=e;return n(["Fragen Sie LLM mit und ohne Suchgrundlage"])},ask_llm_directly:e=>{const{normalize:n}=e;return n(["Fragen Sie LLM direkt"])},ask_llm_with_search_grounding:e=>{const{normalize:n}=e;return n(["Ask LLM mit Suchgrundierung"])},ask_question:e=>{const{normalize:n}=e;return n(["Stellen Sie eine Frage"])},ask_question_hint:e=>{const{normalize:n}=e;return n(["Geben Sie eine Frage ein und kombinieren Sie sie mit dem abgerufenen Inhalt für LLM, um eine Antwort zu generieren"])},basic_usage:e=>{const{normalize:n}=e;return n(["Grundlegende Verwendung"])},basic_usage1:e=>{const{normalize:n}=e;return n(["Lesen einer URL"])},basic_usage2:e=>{const{normalize:n}=e;return n(["Suchen nach einer Abfrage"])},basic_usage3:e=>{const{normalize:n}=e;return n(["Erdung"])},copy:e=>{const{normalize:n}=e;return n(["Kopieren"])},fetch:e=>{const{normalize:n}=e;return n(["Inhalt abrufen"])},get_response:e=>{const{normalize:n}=e;return n(["Erhalten Antwort"])},headers:{auth_token:e=>{const{normalize:n}=e;return n(["API-Schlüssel für höhere Ratenbegrenzung hinzufügen"])},auth_token_explain:e=>{const{normalize:n}=e;return n(["Geben Sie Ihren Jina-API-Schlüssel ein, um auf eine höhere Ratenbegrenzung zuzugreifen. Aktuelle Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle."])},browser_locale:e=>{const{normalize:n}=e;return n(["Browser-Gebietsschema"])},browser_locale_explain:e=>{const{normalize:n}=e;return n(["Kontrollieren Sie die Browser-Gebietsschemata, um die Seite darzustellen. Viele Websites bieten je nach Gebietsschema unterschiedliche Inhalte an."])},default:e=>{const{normalize:n}=e;return n(["Standard"])},default_explain:e=>{const{normalize:n}=e;return n(["Die für die meisten Websites und LLM-Eingaben optimierte Standard-Pipeline."])},file:e=>{const{normalize:n}=e;return n(["Lokale PDF/HTML-Datei"])},file_explain:e=>{const{normalize:n}=e;return n(["Verwenden Sie Reader für Ihre lokalen PDF- und HTML-Dateien, indem Sie sie hochladen. Es werden nur PDF- und HTML-Dateien unterstützt."])},html:e=>{const{normalize:n}=e;return n(["HTML"])},html_explain:e=>{const{normalize:n}=e;return n(["Gibt documentElement.outerHTML zurück."])},image_caption:e=>{const{normalize:n}=e;return n(["Bildbeschreibung"])},image_caption_explain:e=>{const{normalize:n}=e;return n(["Beschriftet alle Bilder unter der angegebenen URL und fügt für Bilder ohne einen Alt-Tag „Bild [idx]: [Beschriftung]“ hinzu. Dies ermöglicht nachgelagerten LLMs die Interaktion mit den Bildern bei Aktivitäten wie Argumentation und Zusammenfassung."])},images_summary:e=>{const{normalize:n}=e;return n(["Sammeln Sie am Ende alle Bilder"])},images_summary_explain:e=>{const{normalize:n}=e;return n(["Am Ende wird ein Abschnitt „Bilder“ erstellt. Dies gibt den nachgelagerten LLMs einen Überblick über alle visuellen Elemente auf der Seite, was das Denken erleichtern kann."])},json_response:e=>{const{normalize:n}=e;return n(["JSON-Antwort"])},json_response_explain:e=>{const{normalize:n}=e;return n(["Die Antwort erfolgt im JSON-Format und enthält URL, Titel, Inhalt und Zeitstempel (sofern verfügbar). Im Suchmodus wird eine Liste mit fünf Einträgen zurückgegeben, die jeweils der beschriebenen JSON-Struktur folgen."])},links_summary:e=>{const{normalize:n}=e;return n(["Sammeln Sie alle Links am Ende"])},links_summary_explain:e=>{const{normalize:n}=e;return n(["Am Ende wird ein Abschnitt „Buttons & Links“ erstellt. Dies erleichtert den nachgelagerten LLMs oder Webagenten die Navigation auf der Seite oder das Ausführen weiterer Aktionen."])},markdown:e=>{const{normalize:n}=e;return n(["Markdown"])},markdown_explain:e=>{const{normalize:n}=e;return n(["Gibt das Markdown direkt aus dem HTML zurück und umgeht dabei die Lesbarkeitsfilterung."])},mode:e=>{const{normalize:n}=e;return n(["Lese- oder Suchmodus"])},mode_explain:e=>{const{normalize:n}=e;return n(["Der Lesemodus dient zum Zugriff auf den Inhalt einer URL, während Sie im Suchmodus eine Abfrage im Web eingeben können, indem Sie den Lesemodus auf jede URL mit Suchergebnis anwenden."])},no_cache:e=>{const{normalize:n}=e;return n(["Umgehen des Cache"])},no_cache_explain:e=>{const{normalize:n}=e;return n(["Unser API-Server speichert sowohl Inhalte im Lese- als auch im Suchmodus für eine bestimmte Zeit im Cache. Um diesen Cache zu umgehen, setzen Sie diesen Header auf „true“."])},pageshot:e=>{const{normalize:n}=e;return n(["Seitenfoto"])},pageshot_explain:e=>{const{normalize:n}=e;return n(["Gibt die Bild-URL des Screenshots der gesamten Seite zurück (mit bestmöglicher Leistung)."])},post_with_url:e=>{const{normalize:n}=e;return n(["POST-Methode verwenden"])},post_with_url_explain:e=>{const{normalize:n}=e;return n(["Verwenden Sie POST statt GET mit einer im Text übergebenen URL. Nützlich zum Erstellen von SPAs mit hashbasiertem Routing."])},proxy_server:e=>{const{normalize:n}=e;return n(["Verwenden Sie einen Proxyserver"])},proxy_server_explain:e=>{const{normalize:n}=e;return n(["Unser API-Server kann Ihren Proxy nutzen, um auf URLs zuzugreifen, was für Seiten hilfreich ist, auf die nur über bestimmte Proxys zugegriffen werden kann."])},references:e=>{const{normalize:n}=e;return n(["Verweise"])},references_explain:e=>{const{normalize:n}=e;return n(["Durch Kommas getrennte Liste der vom Benutzer bereitgestellten Referenzen (URLs)"])},remove_selector:e=>{const{normalize:n}=e;return n(["Ausgeschlossener Selektor"])},remove_selector_explain:e=>{const{normalize:n}=e;return n(["Bietet eine Liste mit CSS-Selektoren zum Entfernen der angegebenen Elemente der Seite. Nützlich, wenn Sie bestimmte Teile der Seite wie Kopfzeilen, Fußzeilen usw. ausschließen möchten."])},return_format:e=>{const{normalize:n}=e;return n(["Inhaltsformat"])},return_format_explain:e=>{const{normalize:n}=e;return n(["Sie können den Detaillierungsgrad der Antwort steuern, um eine Überfilterung zu verhindern. Die Standardpipeline ist für die meisten Websites und LLM-Eingaben optimiert."])},screenshot:e=>{const{normalize:n}=e;return n(["Bildschirmfoto"])},screenshot_explain:e=>{const{normalize:n}=e;return n(["Gibt die Bild-URL des ersten Bildschirms zurück."])},set_cookie:e=>{const{normalize:n}=e;return n(["Weiterleiten Cookie"])},set_cookie_explain:e=>{const{normalize:n}=e;return n(["Unser API-Server kann Ihre benutzerdefinierten Cookie-Einstellungen beim Zugriff auf die URL weiterleiten, was für Seiten nützlich ist, die eine zusätzliche Authentifizierung erfordern. Beachten Sie, dass Anfragen mit Cookies nicht zwischengespeichert werden."])},site_selector:e=>{const{normalize:n}=e;return n(["In-Site-Suche"])},site_selector_explain:e=>{const{normalize:n}=e;return n(["Gibt nur Suchergebnisse von der angegebenen Website oder Domäne zurück. Standardmäßig wird das gesamte Web durchsucht."])},stream_mode:e=>{const{normalize:n}=e;return n(["Stream-Modus"])},stream_mode_explain:e=>{const{normalize:n}=e;return n(["Der Stream-Modus ist für große Zielseiten von Vorteil, da er mehr Zeit für die vollständige Darstellung der Seite bietet. Wenn der Standardmodus unvollständige Inhalte ergibt, sollten Sie den Stream-Modus verwenden."])},target_selector:e=>{const{normalize:n}=e;return n(["Zielauswahl"])},target_selector_explain:e=>{const{normalize:n}=e;return n(["Stellen Sie eine Liste mit CSS-Selektoren bereit, um sich auf spezifischere Teile der Seite zu konzentrieren. Nützlich, wenn der gewünschte Inhalt in den Standardeinstellungen nicht angezeigt wird."])},text:e=>{const{normalize:n}=e;return n(["Text"])},text_explain:e=>{const{normalize:n}=e;return n(["Gibt document.body.innerText zurück."])},wait_for_selector:e=>{const{normalize:n}=e;return n(["Auf Selektor warten"])},wait_for_selector_explain:e=>{const{normalize:n}=e;return n(["Geben Sie eine Liste mit CSS-Selektoren an, um auf das Erscheinen bestimmter Elemente zu warten, bevor Sie zurückkehren. Nützlich, wenn der gewünschte Inhalt in den Standardeinstellungen nicht angezeigt wird."])},with_iframe:e=>{const{normalize:n}=e;return n(["Iframe"])},with_iframe_explain:e=>{const{normalize:n}=e;return n(["Das zurückgegebene Ergebnis umfasst auch den Inhalt der Iframes auf der Seite."])},with_shadow_dom:e=>{const{normalize:n}=e;return n(["Schatten-DOM"])},with_shadow_dom_explain:e=>{const{normalize:n}=e;return n(["Das zurückgegebene Ergebnis enthält auch den Inhalt des Schatten-DOM auf der Seite."])},x_timeout:e=>{const{normalize:n}=e;return n(["Time-out"])},x_timeout_explain:e=>{const{normalize:n}=e;return n(["Maximale Wartezeit bis zum Laden der Webseite. Beachten Sie, dass dies NICHT die Gesamtzeit für die gesamte End-to-End-Anforderung ist."])}},how_to_stream:e=>{const{normalize:n}=e;return n(["Um Inhalte zu verarbeiten, sobald sie verfügbar sind, setzen Sie den Anforderungsheader auf den Stream-Modus. Dadurch wird die Zeit bis zum Empfang des ersten Bytes minimiert. Beispiel in curl:"])},how_to_use1:e=>{const{normalize:n}=e;return n(["Fügen Sie https://r.jina.ai/ zu jeder URL in Ihrem Code oder Tool hinzu, bei der LLM-Zugriff erwartet wird. Dadurch wird der Hauptinhalt der Seite in sauberem, LLM-freundlichem Text zurückgegeben."])},how_to_use2:e=>{const{normalize:n}=e;return n(["Fügen Sie Ihrer Abfrage https://s.jina.ai/ hinzu. Dadurch wird die Suchmaschine aufgerufen und die Top-5-Ergebnisse mit ihren URLs und Inhalten zurückgegeben, jeweils in sauberem, LLM-freundlichem Text."])},how_to_use3:e=>{const{normalize:n}=e;return n(["Fügen Sie Ihrer Aussage https://g.jina.ai/ hinzu. Dadurch wird die Beurteilungs-Engine aufgerufen und der Prozentsatz der Wahrhaftigkeit, ein Boolescher Wert, der angibt, ob die Aussage wahr oder falsch ist, eine Zusammenfassung der Gründe und eine Referenzliste zurückgegeben."])},key_required:e=>{const{normalize:n}=e;return n(["Zur Verwendung dieses Endpunkts ist ein API-Schlüssel erforderlich"])},learn_more:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr"])},open:e=>{const{normalize:n}=e;return n(["In einer neuen Registerkarte öffnen"])},raw_html:e=>{const{normalize:n}=e;return n(["Rohes HTML"])},reader_output:e=>{const{normalize:n}=e;return n(["Reader-Ausgabe"])},reader_response:e=>{const{normalize:n}=e;return n(["Leserreaktion"])},reader_search_hint:e=>{const{normalize:n}=e;return n(["Wenn Sie diese URL im Code verwenden, vergessen Sie nicht, die URL zu kodieren."])},reader_url:e=>{const{normalize:n}=e;return n(["Leser-URL"])},reader_url_hint:e=>{const{normalize:n}=e;return n(["Klicken Sie unten, um den Inhalt über unsere Reader-API abzurufen"])},requires_post_method:e=>{const{normalize:n}=e;return n(["Diese Funktion erfordert die POST-Methode. Beim Hochladen Ihrer lokalen Datei wird die POST-Methode automatisch aktiviert."])},search_params:e=>{const{normalize:n}=e;return n(["Suchparameter/Header"])},search_query_rewrite:e=>{const{normalize:n}=e;return n(["Bitte beachten Sie, dass Sie im Gegensatz zur oben gezeigten Demo in der Praxis nicht die ursprüngliche Frage im Internet nach einer Grundlage durchsuchen. Häufig wird die ursprüngliche Frage umgeschrieben oder es werden Multi-Hop-Fragen verwendet. Die abgerufenen Ergebnisse werden gelesen und anschließend werden zusätzliche Abfragen erstellt, um bei Bedarf weitere Informationen zu sammeln, bevor eine endgültige Antwort gefunden wird."])},select_mode:e=>{const{normalize:n}=e;return n(["Auswahlmodus"])},show_read_demo:e=>{const{normalize:n}=e;return n(["Sehen Sie, wie Reader eine URL liest"])},show_search_demo:e=>{const{normalize:n}=e;return n(["Sehen Sie, wie Reader im Web sucht"])},slow_warning:e=>{const{normalize:n}=e;return n(["Dies kann bis zu 30 Sekunden dauern und kostet bis zu 300.000 Token pro Anfrage."])},standard_usage:e=>{const{normalize:n}=e;return n(["Standardverwendung"])},stream_mode:e=>{const{normalize:n}=e;return n(["Stream-Modus"])},stream_mode_explain:e=>{const{normalize:n}=e;return n(["Der Stream-Modus ist nützlich, wenn die Zielseite zu groß zum Rendern ist. Wenn Sie feststellen, dass der Standardmodus unvollständige Inhalte liefert, versuchen Sie es mit dem Stream-Modus."])},stream_mode_explain1:e=>{const{normalize:n}=e;return n(["Der Streaming-Modus ist nützlich, wenn Sie feststellen, dass der Standardmodus ein unvollständiges Ergebnis liefert. Dies liegt daran, dass der Streaming-Modus etwas länger wartet, bis die Seite vollständig gerendert ist. Verwenden Sie den Accept-Header, um den Streaming-Modus umzuschalten:"])},tagline:e=>{const{normalize:n}=e;return n(["Testen Sie die Demo"])},try_demo:e=>{const{normalize:n}=e;return n(["Demo"])},use_headers:e=>{const{normalize:n}=e;return n(["Das Verhalten der Reader-API kann mit Anforderungsheadern gesteuert werden. Hier ist eine vollständige Liste der unterstützten Header."])},waiting_for_reader:e=>{const{normalize:n}=e;return n(["Warte zuerst auf das Ergebnis der Reader-API ..."])},warn_grounding_message:e=>{const{normalize:n}=e;return n(["Dieser Vorgang kann bis zu 30 Sekunden dauern und bis zu 300.000 Token pro Erdungsanforderung verbrauchen. Einige Browser können die Anforderung aufgrund der langen Latenz abbrechen. Wir empfehlen daher, den Code zu kopieren und von Ihrem Terminal aus auszuführen."])},warn_grounding_title:e=>{const{normalize:n}=e;return n(["Hohe Latenz und Token-Nutzung"])},your_query:e=>{const{normalize:n}=e;return n(["Geben Sie Ihre Suchanfrage ein"])},your_query_hint:e=>{const{normalize:n}=e;return n(["Geben Sie eine Frage ein, die aktuelle Informationen oder Weltwissen erfordert."])},your_url:e=>{const{normalize:n}=e;return n(["Geben Sie Ihre URL ein"])},your_url_hint:e=>{const{normalize:n}=e;return n(["Klicken Sie unten, um den Quellcode der Seite direkt abzurufen"])}},description:e=>{const{normalize:n}=e;return n(["Lesen Sie URLs und suchen Sie im Internet nach fundierteren LLMs."])},dont_panic_api_key_is_free:e=>{const{normalize:n}=e;return n(["Keine Panik! Jeder neue API-Schlüssel enthält eine Million kostenlose Token!"])},faq_v1:{answer1:e=>{const{normalize:n}=e;return n(["Die Reader-API ist kostenlos und erfordert keinen API-Schlüssel. Fügen Sie Ihrer URL einfach „https://r.jina.ai/“ voran."])},answer10:e=>{const{normalize:n}=e;return n(["Nein, die Reader-API kann nur Inhalte von öffentlich zugänglichen URLs verarbeiten."])},answer11:e=>{const{normalize:n}=e;return n(["Wenn Sie innerhalb von 5 Minuten dieselbe URL anfordern, gibt die Reader-API den zwischengespeicherten Inhalt zurück."])},answer12:e=>{const{normalize:n}=e;return n(["Leider nicht."])},answer13:e=>{const{normalize:n}=e;return n(["Ja, Sie können entweder die native PDF-Unterstützung des Readers (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) oder die HTML-Version von arXiv (https://r.jina.ai/https://arxiv.org/html/2310.19923v4) verwenden."])},answer14:e=>{const{normalize:n}=e;return n(["Der Reader betitelt alle Bilder unter der angegebenen URL und fügt `Image [idx]: [caption]` als Alt-Tag hinzu (falls ursprünglich keiner vorhanden ist). Dies ermöglicht nachgelagerten LLMs, beim Denken, Zusammenfassen usw. mit den Bildern zu interagieren."])},answer15:e=>{const{normalize:n}=e;return n(["Die Reader-API ist auf hohe Skalierbarkeit ausgelegt. Sie wird automatisch auf Basis des Echtzeitverkehrs skaliert und die maximale Anzahl gleichzeitiger Anfragen liegt derzeit bei etwa 4000. Wir pflegen sie aktiv als eines der Kernprodukte von Jina AI. Sie können sie also gerne in der Produktion verwenden."])},answer16:e=>{const{normalize:n}=e;return n(["Die neuesten Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle. Beachten Sie, dass wir aktiv an der Verbesserung der Ratenbegrenzung und der Leistung der Reader-API arbeiten. Die Tabelle wird entsprechend aktualisiert."])},answer2:e=>{const{normalize:n}=e;return n(["Die Reader-API verwendet einen Proxy, um jede beliebige URL abzurufen und ihren Inhalt in einem Browser darzustellen, um hochwertigen Hauptinhalt zu extrahieren."])},answer3:e=>{const{normalize:n}=e;return n(["Ja, die Reader-API ist Open Source und im Jina AI GitHub-Repository verfügbar."])},answer4:e=>{const{normalize:n}=e;return n(["Die Reader-API verarbeitet URLs im Allgemeinen innerhalb von 2 Sekunden und gibt Inhalte zurück. Komplexe oder dynamische Seiten können jedoch mehr Zeit benötigen."])},answer5:e=>{const{normalize:n}=e;return n(["Scraping kann kompliziert und unzuverlässig sein, insbesondere bei komplexen oder dynamischen Seiten. Die Reader-API bietet eine optimierte, zuverlässige Ausgabe von sauberem, LLM-fähigem Text."])},answer6:e=>{const{normalize:n}=e;return n(["Die Reader-API gibt Inhalte in der Originalsprache der URL zurück. Sie bietet keine Übersetzungsdienste an."])},answer7:e=>{const{normalize:n}=e;return n(["Wenn bei Ihnen Blockierungsprobleme auftreten, wenden Sie sich für Unterstützung und Lösung bitte an unser Supportteam."])},answer8:e=>{const{normalize:n}=e;return n(["Obwohl die Reader-API in erster Linie für Webseiten entwickelt wurde, kann sie auch Inhalte aus PDF-Dateien extrahieren, die auf Websites wie arXiv im HTML-Format angezeigt werden. Sie ist jedoch nicht für die allgemeine PDF-Extraktion optimiert."])},answer9:e=>{const{normalize:n}=e;return n(["Derzeit verarbeitet die Reader-API keine Medieninhalte, zukünftige Erweiterungen werden jedoch Bildunterschriften und Videozusammenfassungen umfassen."])},question1:e=>{const{normalize:n}=e;return n(["Welche Kosten sind mit der Nutzung der Reader-API verbunden?"])},question10:e=>{const{normalize:n}=e;return n(["Ist es möglich, die Reader-API auf lokale HTML-Dateien anzuwenden?"])},question11:e=>{const{normalize:n}=e;return n(["Speichert die Reader-API den Inhalt im Cache?"])},question12:e=>{const{normalize:n}=e;return n(["Kann ich die Reader-API verwenden, um auf Inhalte hinter einer Anmeldung zuzugreifen?"])},question13:e=>{const{normalize:n}=e;return n(["Kann ich die Reader-API verwenden, um auf arXiv auf PDF zuzugreifen?"])},question14:e=>{const{normalize:n}=e;return n(["Wie funktionieren Bildunterschriften im Reader?"])},question15:e=>{const{normalize:n}=e;return n(["Wie skalierbar ist der Reader? Kann ich ihn in der Produktion einsetzen?"])},question16:e=>{const{normalize:n}=e;return n(["Wie hoch ist die Ratenbegrenzung der Reader-API?"])},question2:e=>{const{normalize:n}=e;return n(["Wie funktioniert die Reader-API?"])},question3:e=>{const{normalize:n}=e;return n(["Ist die Reader-API Open Source?"])},question4:e=>{const{normalize:n}=e;return n(["Wie hoch ist die typische Latenz für die Reader-API?"])},question5:e=>{const{normalize:n}=e;return n(["Warum sollte ich die Reader-API verwenden, anstatt die Seite selbst zu scrapen?"])},question6:e=>{const{normalize:n}=e;return n(["Unterstützt die Reader-API mehrere Sprachen?"])},question7:e=>{const{normalize:n}=e;return n(["Was soll ich tun, wenn eine Website die Reader-API blockiert?"])},question8:e=>{const{normalize:n}=e;return n(["Kann die Reader-API Inhalte aus PDF-Dateien extrahieren?"])},question9:e=>{const{normalize:n}=e;return n(["Kann die Reader-API Medieninhalte von Webseiten verarbeiten?"])},title:e=>{const{normalize:n}=e;return n(["Häufig gestellte Fragen zum Leser"])}},fast:e=>{const{normalize:n}=e;return n(["Schnell"])},fast_stream:e=>{const{normalize:n}=e;return n(["Sofortiges Daten-Streaming"])},fast_stream_description:e=>{const{normalize:n}=e;return n(["Sie benötigen Daten schnell? Unsere Reader-API kann Daten streamen, um die Latenz zu minimieren."])},free:e=>{const{normalize:n}=e;return n(["Für immer frei"])},free_description:e=>{const{normalize:n}=e;return n(["Die Reader-API ist kostenlos! Sie erfordert weder eine Kreditkarte noch ein API-Geheimnis. Ihr Token-Kontingent wird dadurch nicht verbraucht."])},is_free:e=>{const{normalize:n}=e;return n(["Und das Beste daran? Es ist kostenlos!"])},is_free_description:e=>{const{normalize:n}=e;return n(["Die Reader API ist kostenlos erhältlich und bietet flexible Ratenbegrenzungen und Preise. Sie basiert auf einer skalierbaren Infrastruktur und bietet hohe Zugänglichkeit, Parallelität und Zuverlässigkeit. Wir möchten Ihre bevorzugte Grundlösung für Ihre LLMs sein."])},open:e=>{const{normalize:n}=e;return n(["In neuem Tab öffnen"])},original_pdf:e=>{const{normalize:n}=e;return n(["Original PDF"])},rate_limit:e=>{const{normalize:n}=e;return n(["Bewertungslimit"])},read_grounding_release_note:e=>{const{normalize:n}=e;return n(["Versionshinweis lesen"])},reader_also_read_images:e=>{const{normalize:n}=e;return n(["Bilder auf der Webseite werden mithilfe eines Vision Language Model im Reader automatisch mit Bildunterschriften versehen und in der Ausgabe als Bild-Alt-Tags formatiert. Dadurch erhält Ihr nachgelagertes LLM gerade genug Hinweise, um diese Bilder in seine Denk- und Zusammenfassungsprozesse einzubeziehen. Das bedeutet, dass Sie Fragen zu den Bildern stellen, bestimmte Bilder auswählen oder sogar ihre URLs zur tieferen Analyse an ein leistungsfähigeres VLM weiterleiten können!"])},reader_description:e=>{const{normalize:n}=e;return n(["Konvertieren Sie eine URL in eine LLM-freundliche Eingabe, indem Sie einfach <code>r.jina.ai</code> davor hinzufügen."])},reader_do_grounding:e=>{const{normalize:n}=e;return n(["Reader zum Faktencheck"])},reader_do_grounding_explain:e=>{const{normalize:n}=e;return n(["Der neue Grounding-Endpunkt bietet eine durchgängige, nahezu in Echtzeit erfolgende Faktenprüfung. Er nimmt eine gegebene Aussage, begründet sie anhand von Echtzeit-Websuchergebnissen und gibt einen Faktizitätswert und die genauen verwendeten Referenzen zurück. Sie können Aussagen problemlos begründen, um LLM-Halluzinationen zu reduzieren oder die Integrität von von Menschen verfassten Inhalten zu verbessern."])},reader_do_pdf_explain:e=>{const{normalize:n}=e;return n(["Ja, Reader unterstützt das Lesen von PDFs nativ. Es ist mit den meisten PDFs kompatibel, auch mit denen mit vielen Bildern, und es ist blitzschnell! In Kombination mit einem LLM können Sie im Handumdrehen ganz einfach eine ChatPDF- oder Dokumentenanalyse-KI erstellen."])},reader_do_search:e=>{const{normalize:n}=e;return n(["Reader zur Sucheingrenzung"])},reader_do_search_explain:e=>{const{normalize:n}=e;return n(["LLMs haben einen Wissens-Cut-off, das heißt, sie haben keinen Zugriff auf das neueste Weltwissen. Dies führt zu Problemen wie Fehlinformationen, veralteten Antworten, Halluzinationen und anderen Sachlichkeitsproblemen. Für GenAI-Anwendungen ist eine Grundlage absolut unerlässlich. Reader ermöglicht es Ihnen, Ihren LLM mit den neuesten Informationen aus dem Internet zu verankern. Stellen Sie Ihrer Abfrage einfach https://s.jina.ai/ voran, und Reader durchsucht das Internet und gibt die fünf besten Ergebnisse mit ihren URLs und Inhalten zurück, jeweils in sauberem, LLM-freundlichem Text. Auf diese Weise können Sie Ihren LLM immer auf dem neuesten Stand halten, seine Sachlichkeit verbessern und Halluzinationen reduzieren."])},reader_reads_images:e=>{const{normalize:n}=e;return n(["Reader liest auch Bilder!"])},reader_reads_pdf:e=>{const{normalize:n}=e;return n(["Reader liest auch PDFs!"])},reader_result:e=>{const{normalize:n}=e;return n(["Leserergebnis"])},table:{td_1_0:e=>{const{normalize:n}=e;return n(["Lesen einer URL und Zurückgeben des Inhalts, nützlich zur Überprüfung der Erdung"])},td_1_1:e=>{const{normalize:n}=e;return n(["20 U/min"])},td_1_2:e=>{const{normalize:n}=e;return n(["200 U/min"])},td_1_3:e=>{const{normalize:n}=e;return n(["Basierend auf den Ausgabetoken"])},td_1_4:e=>{const{normalize:n}=e;return n(["3 Sekunden"])},td_1_5:e=>{const{normalize:n}=e;return n(["3 Sekunden"])},td_2_0:e=>{const{normalize:n}=e;return n(["Bei einer Suche im Web werden die fünf besten Ergebnisse zurückgegeben, was zur Eingrenzung der Suche nützlich ist."])},td_2_1:e=>{const{normalize:n}=e;return n(["5 U/min"])},td_2_2:e=>{const{normalize:n}=e;return n(["40 U/min"])},td_2_3:e=>{const{normalize:n}=e;return n(["Basierend auf den Ausgabetoken für alle 5 Suchergebnisse"])},td_2_4:e=>{const{normalize:n}=e;return n(["10 Sekunden"])},td_2_5:e=>{const{normalize:n}=e;return n(["10 Sekunden"])},th0:e=>{const{normalize:n}=e;return n(["Endpunkt"])},th1:e=>{const{normalize:n}=e;return n(["Beschreibung"])},th2:e=>{const{normalize:n}=e;return n(["Ratenbegrenzung ohne API-Schlüssel"])},th3:e=>{const{normalize:n}=e;return n(["Ratenbegrenzung mit API-Schlüssel"])},th4:e=>{const{normalize:n}=e;return n(["Token-Zählschema"])},th5:e=>{const{normalize:n}=e;return n(["Durchschnittliche Latenz"])},th6:e=>{const{normalize:n}=e;return n(["Durchschnittliche Latenz"])}},title:e=>{const{normalize:n}=e;return n(["Leser-API"])},usage:e=>{const{normalize:n}=e;return n(["Verwendung"])},usage_details_false:e=>{const{normalize:n}=e;return n(["Nur grundlegende Verwendungen anzeigen"])},usage_details_null:e=>{const{normalize:n}=e;return n(["Grundlegende und erweiterte Verwendungsmöglichkeiten anzeigen"])},usage_details_true:e=>{const{normalize:n}=e;return n(["Nur erweiterte Verwendungen anzeigen"])},want_higher_rate_limit:e=>{const{normalize:n}=e;return n(["Sie möchten eine höhere Ratenbegrenzung bis 1000 RPM? Wir unterstützen Sie!"])},what_is1:e=>{const{normalize:n}=e;return n(["Was ist Reader?"])},what_is_answer_long:e=>{const{normalize:n}=e;return n(["Das Einspeisen von Webinformationen in LLMs ist ein wichtiger Schritt zur Einarbeitung, kann aber auch eine Herausforderung sein. Die einfachste Methode besteht darin, die Webseite zu scrapen und das Roh-HTML einzuspeisen. Das Scraping kann jedoch komplex und oft blockiert sein, und Roh-HTML ist mit irrelevanten Elementen wie Markups und Skripten überladen. Die Reader-API behebt diese Probleme, indem sie den Kerninhalt aus einer URL extrahiert und in sauberen, LLM-freundlichen Text umwandelt, wodurch eine qualitativ hochwertige Eingabe für Ihre Agent- und RAG-Systeme sichergestellt wird."])},what_is_desc:e=>{const{normalize:n}=e;return n(["Ein Proxy, der auf jede URL zugreift und den Hauptinhalt in für LLMs optimierten Klartext umwandelt."])}},recommender:{confirm_message:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Für Ihren API-Schlüssel sind noch ",r(i("_leftTokens"))," Token übrig. Wenn Sie den vollständigen Text von ",r(i("_numArticles")),"-Artikeln an die Reranker-API senden und dabei das Modell ",r(i("_selectedReranker"))," verwenden, um verwandte Artikel für die aktuelle Seite zu ermitteln, wird die Tokenanzahl Ihres API-Schlüssels ",r(i("_APIKey"))," erheblich reduziert. Möchten Sie fortfahren?"])},confirm_title:e=>{const{normalize:n}=e;return n(["Warnung: Hohe Token-Nutzung"])},out_of_quota:e=>{const{normalize:n}=e;return n(["Für diesen API-Schlüssel sind keine Token mehr vorhanden. Bitte laden Sie Ihr Konto auf oder verwenden Sie einen anderen API-Schlüssel."])},recommend:e=>{const{normalize:n}=e;return n(["Holen Sie sich die Top 5"])},recommended_articles:e=>{const{normalize:n}=e;return n(["Top-5 ähnliche Artikel"])}},reranker:{benchmark:{description0:e=>{const{normalize:n}=e;return n(["LlamaIndex bewertete verschiedene Kombinationen von Einbettungen und Rerankern für RAG und führte eine Replikationsstudie durch, in der der mittlere reziproke Rang gemessen wurde. Die Ergebnisse unterstreichen die deutliche Verbesserung der Suchqualität durch den Jina Reranker, ein Vorteil, der unabhängig von den verwendeten spezifischen Einbettungen ist."])},description1:e=>{const{normalize:n}=e;return n(["BIER (Benchmarking IR) bewertet die Abrufeffektivität eines Modells, einschließlich Relevanz und NDCG. Ein höherer BIER-Score korreliert mit genaueren Übereinstimmungen und Suchergebnissen."])},description2:e=>{const{normalize:n}=e;return n(["Mithilfe des LoCo-Benchmarks haben wir das Verständnis eines Modells für lokale Kohärenz und Kontext sowie das abfragespezifische Ranking gemessen. Eine höhere LoCo-Bewertung spiegelt eine bessere Fähigkeit wider, relevante Informationen zu identifizieren und zu priorisieren."])},description3:e=>{const{normalize:n}=e;return n(["Der MTEB (Multilingual Text Embedding Benchmark) testet im Großen und Ganzen die Fähigkeiten eines Modells bei Texteinbettungen, einschließlich Clustering, Klassifizierung, Abruf und anderen Metriken. Für unseren Vergleich haben wir jedoch nur die Reranking-Aufgaben des MTEB herangezogen."])},title:e=>{const{normalize:n}=e;return n(["Benchmark"])},title0:e=>{const{normalize:n}=e;return n(["LamaIndex"])},title1:e=>{const{normalize:n}=e;return n(["BEIR"])},title2:e=>{const{normalize:n}=e;return n(["Lok"])},title3:e=>{const{normalize:n}=e;return n(["MTBB"])}},benchmark_description:e=>{const{normalize:n}=e;return n(["Zum Vergleich haben wir drei weitere führende Reranker von BGE (BAAI), BCE (Netease Youdao) und Cohere in die Benchmark einbezogen. Wie aus den folgenden Ergebnissen hervorgeht, erzielt Jina Reranker in allen relevanten Kategorien für das Reranking die höchste Durchschnittspunktzahl und ist damit klarer Spitzenreiter unter seinen Mitbewerbern."])},benchmark_title:e=>{const{normalize:n}=e;return n(["Leistungsbenchmark"])},choose_turbo:e=>{const{normalize:n}=e;return n(["Bis zu 5-fache Geschwindigkeitssteigerung mit Reranker-Turbo"])},choose_turbo_description:e=>{const{normalize:n}=e;return n(["Wir bieten außerdem zwei neue Open-Source-Reranker-Modelle an: jina-reranker-v1-turbo-en und jina-reranker-v1-tiny-en. Letzteres hat nur 30 Millionen Parameter und vier Schichten. Diese beiden neuen Reranker bieten eine 5-mal schnellere Inferenzgeschwindigkeit als das Basismodell bei nur sehr geringen Qualitätseinbußen. Sie eignen sich perfekt für Anwendungen, die ein Reranking in Echtzeit erfordern. Lesen Sie den Benchmark unten."])},customize_urself:e=>{const{normalize:n}=e;return n(["Ändern Sie es und sehen Sie, wie sich die Reaktion ändert!"])},customize_urself_pl:e=>{const{normalize:n}=e;return n(["Ändern Sie sie und sehen Sie, wie sich die Reaktion ändert!"])},description:e=>{const{normalize:n}=e;return n(["Neural Retriever der Weltklasse zur Maximierung der Suchrelevanz."])},description_rich:e=>{const{normalize:n}=e;return n(["Maximieren Sie die Suchrelevanz und RAG-Genauigkeit mit unserer hochmodernen Reranker-API."])},example_input_document:e=>{const{normalize:n}=e;return n(["Beispieldokumente von Kandidaten zum Ranking"])},example_input_query:e=>{const{normalize:n}=e;return n(["Beispielabfrage"])},faq_v1:{answer1:e=>{const{normalize:n}=e;return n(["Die Preise für die Reranker-API richten sich nach unserer Preisstruktur für die Embedding-API. Es beginnt mit 1 Million kostenlosen Token für jeden neuen API-Schlüssel. Über die kostenlosen Token hinaus stehen verschiedene Pakete zum Kauf zur Verfügung. Weitere Informationen finden Sie in unserem Abschnitt „Preise“."])},answer10:e=>{const{normalize:n}=e;return n(["Ja, Jina Reranker kann auf AWS bereitgestellt werden. Wenn Sie eine lokale Bereitstellung in einer Unternehmensumgebung benötigen, können Sie dies ganz einfach über unser AWS Marketplace-Angebot tun."])},answer11:e=>{const{normalize:n}=e;return n(["Wenn Sie an einem fein abgestimmten Reranker interessiert sind, der auf bestimmte Domaindaten zugeschnitten ist, wenden Sie sich bitte an unser Vertriebsteam. Unser Team wird Ihre Anfrage zeitnah beantworten."])},answer3:e=>{const{normalize:n}=e;return n(["Der Hauptunterschied liegt in ihrer Architektur. Für die Leistung empfehlen wir jina-reranker-v1, das ausgiebig getestet und mit Wettbewerbern verglichen wurde. Jina-reranker-v1 nutzt eine Cross-Encoder-Architektur, während Jina-colbert-v1 auf der ColBERTv2-Architektur basiert, aber die Kontextlänge sowohl der Abfrage als auch des Dokuments auf 8192 erweitert, wodurch eine noch bessere Leistung als das ursprüngliche ColBERTv2-Modell erzielt wird."])},answer4:e=>{const{normalize:n}=e;return n(["Ja, jina-colbert-v1 ist Open Source und kann über Huggingface aufgerufen werden. Allerdings ist jina-reranker-v1 kein Open Source."])},answer5:e=>{const{normalize:n}=e;return n(["Derzeit wird nur Englisch unterstützt. Einige Benutzer haben jedoch berichtet, dass es auch mit Chinesisch gut funktioniert. Dies kann teilweise daran liegen, dass jina-reranker-v1-base-en einige Gewichtungen mit unserem Einbettungsmodell jina-embeddings-v2-base-zh teilt."])},answer6:e=>{const{normalize:n}=e;return n(["Die maximale Länge des Abfragetokens beträgt 512. Für Dokumente gibt es keine Tokenbeschränkung."])},answer7:e=>{const{normalize:n}=e;return n(["Sie können bis zu 2048 Dokumente pro Abfrage neu einordnen."])},answer8:e=>{const{normalize:n}=e;return n(["Im Gegensatz zu unserer Einbettungs-API gibt es kein Konzept der Stapelgröße. Sie können pro Anfrage nur ein Abfrage-Dokument-Tupel senden, das Tupel kann jedoch bis zu 2048 Kandidatendokumente enthalten."])},answer9:e=>{const{normalize:n}=e;return n(["Die Latenz variiert zwischen 100 Millisekunden und 7 Sekunden und hängt weitgehend von der Länge der Dokumente und der Abfrage ab. Beispielsweise dauert das Neuranking von 100 Dokumenten mit jeweils 256 Token bei einer 64-Token-Abfrage etwa 150 Millisekunden. Durch Erhöhen der Dokumentlänge auf 4096 Token erhöht sich die Zeit auf 3,5 Sekunden. Wenn die Abfragelänge auf 512 Token erhöht wird, erhöht sich die Zeit weiter auf 7 Sekunden."])},question1:e=>{const{normalize:n}=e;return n(["Wie viel kostet die Reranker-API?"])},question10:e=>{const{normalize:n}=e;return n(["Kann ich Jina Reranker auf AWS bereitstellen?"])},question11:e=>{const{normalize:n}=e;return n(["Bieten Sie einen genau abgestimmten Reranker für domänenspezifische Daten an?"])},question3:e=>{const{normalize:n}=e;return n(["Was ist der Unterschied zwischen den beiden Rerankern?"])},question4:e=>{const{normalize:n}=e;return n(["Ist Jina Reranker Open Source?"])},question5:e=>{const{normalize:n}=e;return n(["Unterstützt der Reranker mehrere Sprachen?"])},question6:e=>{const{normalize:n}=e;return n(["Wie lang dürfen Anfragen und Dokumente maximal sein?"])},question7:e=>{const{normalize:n}=e;return n(["Wie viele Dokumente kann ich pro Abfrage maximal neu einordnen?"])},question8:e=>{const{normalize:n}=e;return n(["Wie groß ist die Stapelgröße und wie viele Abfrage-Dokument-Tupel kann ich in einer Anfrage senden?"])},question9:e=>{const{normalize:n}=e;return n(["Mit welcher Latenz kann ich rechnen, wenn ich 100 Dokumente neu einordne?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zum Reranker"])}},feature_on_premises_description2:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Reranker auf AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um maßgeschneiderte Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und lokale Server zu erhalten."])},feature_on_premises_description3:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Reranker auf AWS Sagemaker und Microsoft Azure und bald auch in Google Cloud Services bereit, oder wenden Sie sich an unser Vertriebsteam, um angepasste Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und Ihre lokalen Server zu erhalten."])},feature_solid_description:e=>{const{normalize:n}=e;return n(["Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests mit den SOTA-Rerankern, um eine beispiellose Leistung zu gewährleisten."])},how_it_works:e=>{const{normalize:n}=e;return n(["So funktioniert das:"])},how_it_works_v1:{description1:e=>{const{normalize:n}=e;return n(["Ein Suchsystem verwendet Einbettungen/BM25, um basierend auf der Anfrage des Benutzers eine breite Palette potenziell relevanter Dokumente zu finden."])},description2:e=>{const{normalize:n}=e;return n(["Anschließend analysiert der Reranker diese Ergebnisse auf einer detaillierteren Ebene und berücksichtigt dabei die Nuancen der Interaktion der Abfragebegriffe mit dem Dokumentinhalt."])},description3:e=>{const{normalize:n}=e;return n(["Es ordnet die Suchergebnisse neu und platziert diejenigen, die es auf der Grundlage dieser tiefergehenden Analyse für am relevantesten hält, ganz oben."])},title1:e=>{const{normalize:n}=e;return n(["Erster Abruf"])},title2:e=>{const{normalize:n}=e;return n(["Neueinstufung"])},title3:e=>{const{normalize:n}=e;return n(["Verbesserte Ergebnisse"])}},improve_performance:e=>{const{normalize:n}=e;return n(["Garantierte Verbesserung gegenüber der Vektorsuche"])},improve_performance_description:e=>{const{normalize:n}=e;return n(["Unsere Auswertungen zeigten Verbesserungen für Suchsysteme, die den Jina Reranker verwenden, mit +8 % bei der Trefferquote und +33 % beim mittleren reziproken Rang."])},learning1:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr über Reranker"])},learning1_description:e=>{const{normalize:n}=e;return n(["Was ist ein Reranker? Warum reicht die Vektorsuche oder die Kosinusähnlichkeit nicht aus? Erfahren Sie mit unserem umfassenden Leitfaden mehr über Reranker von Grund auf."])},read_more_about_benchmark:e=>{const{normalize:n}=e;return n(["Lesen Sie mehr über den Benchmark"])},read_more_about_turbo:e=>{const{normalize:n}=e;return n(["Lesen Sie mehr über die Turbo- und Tiny-Modelle"])},read_more_about_v2:e=>{const{normalize:n}=e;return n(["Jina Reranker v2 ist der beste Reranker seiner Klasse, der am 25. Juni 2024 veröffentlicht wurde. Er wurde für Agentic RAG entwickelt. Er bietet Funktionsaufrufunterstützung, mehrsprachigen Abruf für über 100 Sprachen, Codesuchfunktionen und ist 6-mal schneller als v1. Lesen Sie mehr über das v2-Modell."])},reranker_description:e=>{const{normalize:n}=e;return n(["Probieren Sie unsere hochmoderne Reranker-API aus, um Ihre Suchrelevanz und RAG-Genauigkeit zu maximieren. Kostenlos starten!"])},show_v2benchmark:e=>{const{normalize:n}=e;return n(["Benchmark für Modell v2 (neueste) anzeigen"])},table:{number_token_document:e=>{const{normalize:n}=e;return n(["Anzahl der Token in jedem Dokument"])},number_token_query:e=>{const{normalize:n}=e;return n(["Anzahl der Token in der Abfrage"])},title:e=>{const{normalize:n}=e;return n(["Unten ist der Zeitaufwand für das Reranking einer Abfrage und 100 Dokumenten in Millisekunden aufgeführt:"])}},title:e=>{const{normalize:n}=e;return n(["Reranker-API"])},top_n:e=>{const{normalize:n}=e;return n(["Anzahl der zurückgegebenen Dokumente"])},top_n_explain:e=>{const{normalize:n}=e;return n(["Die Anzahl der relevantesten Dokumente, die für die Abfrage zurückgegeben werden sollen."])},try_embedding:e=>{const{normalize:n}=e;return n(["Probieren Sie die Einbettungs-API kostenlos aus"])},try_reranker:e=>{const{normalize:n}=e;return n(["Testen Sie die Reranker-API kostenlos"])},v2_features:{description1:e=>{const{normalize:n}=e;return n(["Reranker v2 ermöglicht die Dokumentensuche in über 100 Sprachen, unabhängig von der Abfragesprache."])},description2:e=>{const{normalize:n}=e;return n(["Reranker v2 bewertet Codeausschnitte und Funktionssignaturen auf der Grundlage von Abfragen in natürlicher Sprache und ist somit ideal für Agentic RAG-Anwendungen."])},description3:e=>{const{normalize:n}=e;return n(["Reranker v2 erstellt eine Rangfolge der relevantesten Tabellen auf der Grundlage von Abfragen in natürlicher Sprache und hilft so dabei, verschiedene Tabellenschemata zu sortieren und das relevanteste zu identifizieren, bevor eine SQL-Abfrage generiert wird."])},title1:e=>{const{normalize:n}=e;return n(["Mehrsprachiger Abruf"])},title2:e=>{const{normalize:n}=e;return n(["Funktionsaufruf und Codesuche"])},title3:e=>{const{normalize:n}=e;return n(["Unterstützung tabellarischer und strukturierter Daten"])}},v2benchmark:{descBeir:e=>{const{normalize:n}=e;return n(["NDCG 10-Wertungen für verschiedene Neurankingmodelle für den Beir-Datensatz gemeldet"])},descCodeSearchNet:e=>{const{normalize:n}=e;return n(["MRR 10-Werte für verschiedene Reranking-Modelle für den CodeSearchNet-Datensatz gemeldet"])},descMKQA:e=>{const{normalize:n}=e;return n(["Erinnern Sie sich an 10 Ergebnisse, die für verschiedene Reranking-Modelle für den MKQA-Datensatz gemeldet wurden"])},descNSText2SQL:e=>{const{normalize:n}=e;return n(["Erinnern Sie sich an 3 Ergebnisse, die für verschiedene Neurankingmodelle für den NSText2SQL-Datensatz gemeldet wurden"])},descRTX4090:e=>{const{normalize:n}=e;return n(["Durchsatzwerte (Abruf von Dokumenten in 50 ms), die für verschiedene Neurankingmodelle auf einer RTX 4090-GPU gemeldet wurden."])},descToolBench:e=>{const{normalize:n}=e;return n(["Erinnern Sie sich an 3 Bewertungen, die für verschiedene Neurankingmodelle für den ToolBench-Datensatz gemeldet wurden"])},titleBeir:e=>{const{normalize:n}=e;return n(["BEIR (Heterogener Benchmark für verschiedene IR-Aufgaben)"])},titleCodeSearchNet:e=>{const{normalize:n}=e;return n(["CodeSearchNet. Der Benchmark ist eine Kombination aus Abfragen in Docstring- und natürlichen Sprachformaten mit gekennzeichneten Codesegmenten, die für die Abfragen relevant sind."])},titleMKQA:e=>{const{normalize:n}=e;return n(["MKQA (Fragen und Antworten zum mehrsprachigen Wissen)"])},titleNSText2SQL:e=>{const{normalize:n}=e;return n(["NSText2SQL"])},titleRTX4090:e=>{const{normalize:n}=e;return n(["Durchsatz von Jina Reranker v2 auf RTX4090"])},titleToolBench:e=>{const{normalize:n}=e;return n(["ToolBench. Der Benchmark sammelt über 16.000 öffentliche APIs und entsprechende synthetisch generierte Anweisungen für deren Verwendung in Einzel- und Multi-API-Einstellungen."])}},vs_table:{col0:e=>{const{normalize:n}=e;return n(["Reranker"])},col0_1:e=>{const{normalize:n}=e;return n(["Verbesserte Suchpräzision und Relevanz"])},col0_2:e=>{const{normalize:n}=e;return n(["Erste, schnelle Filterung"])},col0_3:e=>{const{normalize:n}=e;return n(["Allgemeine Textsuche für weitreichende Abfragen"])},col1:e=>{const{normalize:n}=e;return n(["Vektorsuche"])},col1_1:e=>{const{normalize:n}=e;return n(["Detailliert: Unterdokument und Abfragesegment"])},col1_2:e=>{const{normalize:n}=e;return n(["Breit: Ganze Dokumente"])},col1_3:e=>{const{normalize:n}=e;return n(["Mittelstufe: Verschiedene Textsegmente"])},col2:e=>{const{normalize:n}=e;return n(["BM25"])},col2_1:e=>{const{normalize:n}=e;return n(["Hoch"])},col2_2:e=>{const{normalize:n}=e;return n(["Mittel"])},col2_3:e=>{const{normalize:n}=e;return n(["Niedrig"])},col3_1:e=>{const{normalize:n}=e;return n(["Nicht benötigt"])},col3_2:e=>{const{normalize:n}=e;return n(["Hoch"])},col3_3:e=>{const{normalize:n}=e;return n(["Niedrig, nutzt vorgefertigten Index"])},col4_1:e=>{const{normalize:n}=e;return n(["Hoch"])},col4_2:e=>{const{normalize:n}=e;return n(["Hoch"])},col4_3:e=>{const{normalize:n}=e;return n(["Nicht benötigt"])},col5_1:e=>{const{normalize:n}=e;return n(["Hervorragend für differenzierte Abfragen"])},col5_2:e=>{const{normalize:n}=e;return n(["Ausgewogen zwischen Effizienz und Genauigkeit"])},col5_3:e=>{const{normalize:n}=e;return n(["Konsistent und zuverlässig für eine breite Palette von Abfragen"])},col6_1:e=>{const{normalize:n}=e;return n(["Sehr präzise mit tiefem Kontextverständnis"])},col6_2:e=>{const{normalize:n}=e;return n(["Schnell und effizient, mit mäßiger Genauigkeit"])},col6_3:e=>{const{normalize:n}=e;return n(["Hoch skalierbar, mit nachgewiesener Wirksamkeit"])},col7_1:e=>{const{normalize:n}=e;return n(["Ressourcenintensiv bei komplexer Umsetzung"])},col7_2:e=>{const{normalize:n}=e;return n(["Erfasst möglicherweise keinen tiefen Abfragekontext oder keine Nuancen"])},col7_3:e=>{const{normalize:n}=e;return n(["Bei sehr spezifischen oder kontextbezogenen Suchen ist die Leistung möglicherweise unterdurchschnittlich"])},header0:e=>{const{normalize:n}=e;return n(["Beste für"])},header1:e=>{const{normalize:n}=e;return n(["Die Granularität"])},header2:e=>{const{normalize:n}=e;return n(["Komplexität der Abfragezeit"])},header3:e=>{const{normalize:n}=e;return n(["Zeitkomplexität indizieren"])},header4:e=>{const{normalize:n}=e;return n(["Komplexität der Trainingszeit"])},header5:e=>{const{normalize:n}=e;return n(["Suchqualität"])},header6:e=>{const{normalize:n}=e;return n(["Stärken"])},header7:e=>{const{normalize:n}=e;return n(["Schwächen"])},subtitle:e=>{const{normalize:n}=e;return n(["Die folgende Tabelle bietet einen umfassenden Vergleich von Reranker, Vector/Embeddings Search und BM25 und hebt deren Stärken und Schwächen in verschiedenen Kategorien hervor."])},title:e=>{const{normalize:n}=e;return n(["Vergleich von Reranker, Vector Search und BM25"])}},what_is:e=>{const{normalize:n}=e;return n(["Was ist ein Reranker?"])},what_is_answer_long:e=>{const{normalize:n}=e;return n([`Ziel eines Suchsystems ist es, schnell und effizient die relevantesten Ergebnisse zu finden. Traditionell wurden Methoden wie BM25 oder tf-idf verwendet, um Suchergebnisse basierend auf der Keyword-Übereinstimmung zu ordnen. Neuere Methoden, wie beispielsweise die einbettungsbasierte Kosinusähnlichkeit, wurden in vielen Vektordatenbanken implementiert. Diese Methoden sind unkompliziert, können jedoch manchmal die Feinheiten der Sprache und vor allem die Interaktion zwischen Dokumenten und der Absicht einer Abfrage außer Acht lassen.

Hier glänzt der „Reranker“. Ein Reranker ist ein fortschrittliches KI-Modell, das die anfänglichen Ergebnisse einer Suche – oft bereitgestellt durch eine einbettungs-/tokenbasierte Suche – und sie neu bewertet, um sicherzustellen, dass sie besser mit der Absicht des Benutzers übereinstimmen. Es geht über den oberflächlichen Abgleich von Begriffen hinaus und berücksichtigt die tiefere Interaktion zwischen der Suchanfrage und dem Inhalt der Dokumente.`])},what_is_answer_long_ending:e=>{const{normalize:n}=e;return n(["Der Reranker kann die Suchqualität erheblich verbessern, da er auf Unterdokument- und Unterabfrageebene arbeitet, d. h. die einzelnen Wörter und Phrasen, ihre Bedeutung und ihre Beziehung zueinander innerhalb der Abfrage und der Dokumente untersucht. Dies führt zu präziseren und kontextbezogeneren Suchergebnissen."])},what_is_desc:e=>{const{normalize:n}=e;return n(["Ein Reranker ist ein KI-Modell, das die Suchergebnisse aus einer Vektorsuche oder einem Dense-Retrieval-Modell verfeinert. Mehr lesen."])}},scenex:{caption_image_desc:e=>{const{normalize:n}=e;return n(["Generieren Sie eine Textbeschreibung des Bildes."])},caption_image_title:e=>{const{normalize:n}=e;return n(["Bildunterschrift"])},description:e=>{const{normalize:n}=e;return n(["Entdecken Sie auf Bildern basierende Geschichtenerzählungen jenseits von Pixeln"])},example1:e=>{const{normalize:n}=e;return n(["Bei diesem Video handelt es sich offenbar um eine Naturaufnahme mit einem bezaubernden weißen Hasen und einem Schmetterling auf einer Wiese. Der Hase interagiert auf unterschiedliche Weise mit dem Schmetterling und zeigt so ihre einzigartige Beziehung. Die natürliche Umgebung bietet eine malerische Kulisse und unterstreicht die Schönheit dieser einfachen, aber faszinierenden Szene."])},generate_story_desc:e=>{const{normalize:n}=e;return n(["Erstellen Sie eine vom Bild inspirierte Geschichte, die häufig Dialoge oder Monologe der Charaktere enthält."])},generate_story_title:e=>{const{normalize:n}=e;return n(["Geschichte generieren"])},intro1:e=>{const{normalize:n}=e;return n(["Führende KI-Lösung für Bildunterschriften und Videozusammenfassungen"])},json_image_desc:e=>{const{normalize:n}=e;return n(["Generieren Sie mithilfe eines vordefinierten Schemas ein strukturiertes JSON-Format aus dem Bild. Dies ermöglicht eine gezielte Datenextraktion aus dem Bild."])},json_image_title:e=>{const{normalize:n}=e;return n(["Extrahieren Sie JSON aus dem Bild"])},summarize_video_desc:e=>{const{normalize:n}=e;return n(["Erstellen Sie eine prägnante Zusammenfassung des Videos und heben Sie wichtige Ereignisse hervor."])},summarize_video_title:e=>{const{normalize:n}=e;return n(["Video zusammenfassen"])},visual_q_a_desc:e=>{const{normalize:n}=e;return n(["Beantworten Sie eine Frage basierend auf dem Bildinhalt."])},visual_q_a_title:e=>{const{normalize:n}=e;return n(["Visuelle Fragen und Antworten"])}},searchbar:{ask_on_current_page:e=>{const{normalize:n}=e;return n(["Fragen Sie auf der aktuellen Seite nach..."])},find_solution:e=>{const{normalize:n}=e;return n(["Generieren Sie eine Lösung für..."])},hint:e=>{const{normalize:n}=e;return n(["Durchsuchen Sie Produkte, Neuigkeiten und Ihre Fragen"])},hotkey:e=>{const{normalize:n}=e;return n(["Drücken Sie die Taste /, um auf dieser Seite zu suchen"])},hotkey1:e=>{const{normalize:n}=e;return n(["Drücken Sie"])},hotkey2:e=>{const{normalize:n}=e;return n(["Umschalten"])},hotkey_long1:e=>{const{normalize:n}=e;return n(["Drücken Sie jederzeit"])},hotkey_long3:e=>{const{normalize:n}=e;return n(["um die Suchleiste zu öffnen"])},more_results:e=>{const{normalize:n,interpolate:r,named:i}=e;return n([r(i("_numMore"))," weitere Ergebnisse"])},placeholder:e=>{const{normalize:n}=e;return n(["Stellen Sie auf dieser Seite Fragen"])},proposing_solution:e=>{const{normalize:n}=e;return n(["Generierung einer Antwort basierend auf dem Seiteninhalt ..."])},required:e=>{const{normalize:n}=e;return n(["Bitte beschreiben Sie Ihre Frage genauer."])},results:e=>{const{normalize:n}=e;return n(["Ergebnisse"])}},searchscape:{description:e=>{const{normalize:n}=e;return n(["Navigieren, interagieren, verfeinern: Produktentdeckung neu denken"])}},semantic:{description:e=>{const{normalize:n}=e;return n(["Überbrückung der semantischen Lücke in Ihrer vorhandenen Suchinfrastruktur"])}},share:{"Hacker News":e=>{const{normalize:n}=e;return n(["Hacker-News"])},LinkedIn:e=>{const{normalize:n}=e;return n(["LinkedIn"])},facebook:e=>{const{normalize:n}=e;return n(["Facebook"])},reddit:e=>{const{normalize:n}=e;return n(["Reddit"])},rss:e=>{const{normalize:n}=e;return n(["RSS-Feed"])},share_btn:e=>{const{normalize:n}=e;return n(["Aktie"])},twitter:e=>{const{normalize:n}=e;return n(["X (Twitter)"])}},spectrum:{click_to_learn_more:e=>{const{normalize:n}=e;return n(["Klicke, um mehr zu lernen"])},contextualization:e=>{const{normalize:n}=e;return n(["Kontextualisierung"])},contextualization_desc:e=>{const{normalize:n}=e;return n(["Reranker passen anfängliche Suchergebnisse basierend auf tiefer kontextueller Relevanz in Bezug auf die Abfrage an. Dadurch wird das Ranking verfeinert, um besser zu dem zu passen, was Benutzer wahrscheinlich nützlich finden."])},coreInfra:e=>{const{normalize:n}=e;return n(["Kerninfrastruktur"])},coreInfra_desc:e=>{const{normalize:n}=e;return n(["Core Infra bietet eine Cloud-native Ebene für die Entwicklung, Bereitstellung und Orchestrierung von Suchgrundlagenmodellen sowohl in der öffentlichen Cloud als auch vor Ort, sodass Dienste problemlos nach oben und unten skaliert werden können."])},embedding_serving:e=>{const{normalize:n}=e;return n(["Servieren einbetten"])},embedding_serving_description:e=>{const{normalize:n}=e;return n(["Bereitstellung von Einbettungen über einen robusten, skalierbaren Mikroservice unter Verwendung cloudnativer Technologien."])},embedding_tech:e=>{const{normalize:n}=e;return n(["Einbettungen"])},embedding_tech_description:e=>{const{normalize:n}=e;return n([`Bei Jina AI nutzen wir die Leistungsfähigkeit der Einbettungstechnologie, um verschiedene KI-Anwendungen zu revolutionieren. Diese Technologie dient als einheitliche Methode zur effizienten Darstellung und Komprimierung verschiedener Datentypen und stellt sicher, dass keine wichtigen Informationen verloren gehen. Unser Fokus liegt auf der Transformation komplexer Datensätze in ein allgemein verständliches Einbettungsformat, das für eine präzise und aufschlussreiche KI-Analyse unerlässlich ist.

Einbettungen sind von grundlegender Bedeutung, insbesondere bei Anwendungen wie der präzisen Bild- und Spracherkennung, wo sie dabei helfen, feinkörnige Details und Nuancen zu erkennen. Bei der Verarbeitung natürlicher Sprache verbessern Einbettungen das Verständnis von Kontext und Stimmung und führen zu genaueren Konversations-KI- und Sprachübersetzungstools. Sie sind auch von entscheidender Bedeutung bei der Entwicklung anspruchsvoller Empfehlungssysteme, die ein tiefes Verständnis der Benutzerpräferenzen in verschiedenen Inhaltsformen wie Text, Audio und Video erfordern.`])},embedding_tuning:e=>{const{normalize:n}=e;return n(["Tuning einbetten"])},embedding_tuning_description:e=>{const{normalize:n}=e;return n(["Optimierung hochwertiger Einbettungen durch Integration von Fachwissen für eine verbesserte aufgabenspezifische Leistung."])},embeddings:e=>{const{normalize:n}=e;return n(["Einbettungen"])},embeddings_desc:e=>{const{normalize:n}=e;return n(["Einbettungen sind die Eckpfeiler moderner Suchsysteme und stellen multimodale Daten in Zahlenvektoren dar. Dieser Prozess ermöglicht ein differenzierteres und kontextbezogeneres Verständnis von Inhalten, das weit über die einfache Keyword-Übereinstimmung hinausgeht."])},for_developers:e=>{const{normalize:n}=e;return n(["Für Entwickler"])},for_enterprise:e=>{const{normalize:n}=e;return n(["Für Unternehmen"])},for_power_users:e=>{const{normalize:n}=e;return n(["Für Power-User"])},grounding:e=>{const{normalize:n}=e;return n(["Erdung"])},grounding_desc:e=>{const{normalize:n}=e;return n(["Der Leser verfeinert Eingaben und Ergebnisse durch LLMs. Sie verbessern die Qualität, Lesbarkeit und Sachlichkeit der endgültigen Antwort."])},model_serving:e=>{const{normalize:n}=e;return n(["Modelldienst"])},model_serving_description:e=>{const{normalize:n}=e;return n(["Die Bereitstellung fein abgestimmter Modelle in einer Produktionsumgebung, die in der Regel erhebliche Ressourcen wie GPU-Hosting erfordert. MLOps, wobei der Schwerpunkt auf der skalierbaren, effizienten und zuverlässigen Bereitstellung mittelgroßer bis großer Modelle liegt."])},model_tuning:e=>{const{normalize:n}=e;return n(["Modelltuning"])},model_tuning_description:e=>{const{normalize:n}=e;return n(["Bei der Feinabstimmung, auch Feinabstimmung genannt, werden die Parameter eines vorab trainierten Modells an einem neuen, oft aufgabenspezifischen Datensatz angepasst, um dessen Leistung zu verbessern und es an eine bestimmte Anwendung anzupassen."])},personalization:e=>{const{normalize:n}=e;return n(["Personalisierung"])},personalization_desc:e=>{const{normalize:n}=e;return n(["Verwenden Sie synthetische Daten und trainieren Sie anhand von Benutzeranweisungen automatisch ein domänenspezifisches Einbettungs- und Reranking-Modell."])},preprocessing:e=>{const{normalize:n}=e;return n(["Vorverarbeitung"])},preprocessing_desc:e=>{const{normalize:n}=e;return n(["Bei der Vorverarbeitung werden die Rohdaten bereinigt, normalisiert und in ein für das Suchsystem verwertbares Format umgewandelt."])},promptOps:e=>{const{normalize:n}=e;return n(["PromptOps"])},promptOps_desc:e=>{const{normalize:n}=e;return n(["Prompt Ops verbessern die Eingabe und Ausgabe des Suchsystems, einschließlich der bei der Abfrageerweiterung, der LLM-Eingabe und der Ergebnisumschreibung verwendeten. Dies stellt sicher, dass die Suche besser versteht und bessere Ergebnisse liefert."])},prompt_serving:e=>{const{normalize:n}=e;return n(["Prompte Bedienung"])},prompt_serving_description:e=>{const{normalize:n}=e;return n(["Verpacken und Bereitstellen von Prompts über eine API, ohne umfangreiche Modelle zu hosten. Die API ruft einen öffentlichen Modelldienst für große Sprachen auf und übernimmt die Orchestrierung von Ein- und Ausgaben in einer Operationskette."])},prompt_tech:e=>{const{normalize:n}=e;return n(["Prompt- und Agent-Engineering"])},prompt_tech_description:e=>{const{normalize:n}=e;return n([`Bei Jina AI erkennen wir, dass Prompt Engineering für die Interaktion mit großen Sprachmodellen (LLMs) von entscheidender Bedeutung ist. Mit der Weiterentwicklung dieser Modelle nimmt die Komplexität der Eingabeaufforderungen zu und umfasst komplexe Überlegungen und Logik. Dieser Fortschritt unterstreicht das miteinander verflochtene Wachstum von LLMs und die schnelle Weiterentwicklung.

Wir sehen eine Zukunft voraus, in der LLMs als Compiler fungieren und Eingabeaufforderungen zur neuen Programmiersprache werden. Diese Verschiebung deutet darauf hin, dass sich zukünftige technologische Kompetenzen mehr auf die schnelle Beherrschung als auf die traditionelle Codierung konzentrieren könnten. Unser Ziel bei Jina AI ist es, in diesem transformativen Bereich eine Führungsrolle zu übernehmen und durch die Beherrschung dieser aufstrebenden „Sprache“ fortschrittliche KI für den täglichen Gebrauch zugänglich und praktisch zu machen.`])},prompt_tuning:e=>{const{normalize:n}=e;return n(["Prompte Abstimmung"])},prompt_tuning_description:e=>{const{normalize:n}=e;return n(["Der Prozess der Erstellung und Verfeinerung der Prompts, um die Ausgabe auf bestimmte, gewünschte Antworten auszurichten."])},representation:e=>{const{normalize:n}=e;return n(["Darstellung"])},representation_desc:e=>{const{normalize:n}=e;return n(["Embeddings transformieren multimodale Daten in ein einheitliches, vektorisiertes Format. Dadurch ist das Suchsystem in der Lage, Inhalte über einfache Schlagwörter hinaus zu verstehen und zu kategorisieren."])},rerankers:e=>{const{normalize:n}=e;return n(["Neubewerter"])},rerankers_desc:e=>{const{normalize:n}=e;return n(["Reranker übernehmen die anfänglichen Ergebnisse aus den Einbettungen und verfeinern sie, um sicherzustellen, dass dem Benutzer die relevantesten Ergebnisse präsentiert werden. Dies ist entscheidend, um qualitativ hochwertige Suchergebnisse zu liefern, die der Absicht des Benutzers entsprechen."])}},subscribe_system:{care_most:e=>{const{normalize:n}=e;return n(["Was liegt Ihnen am meisten am Herzen?"])},care_most_options:{accuracy:e=>{const{normalize:n}=e;return n(["Genauigkeit"])},cost:e=>{const{normalize:n}=e;return n(["Kosten"])},other:e=>{const{normalize:n}=e;return n(["Andere"])},scalability:e=>{const{normalize:n}=e;return n(["Skalierbarkeit"])},speed:e=>{const{normalize:n}=e;return n(["Geschwindigkeit"])}},care_most_required:e=>{const{normalize:n}=e;return n(["Was ist Ihnen bei der Auswahl einer Dienstleistung am wichtigsten?"])},company_size:e=>{const{normalize:n}=e;return n(["Wie groß ist Ihr Unternehmen?"])},company_size_required:e=>{const{normalize:n}=e;return n(["Teilen Sie uns mit, dass die Größe Ihres Unternehmens uns hilft, einen besseren Service zu bieten"])},company_url:e=>{const{normalize:n}=e;return n(["Wie lautet die Website Ihres Unternehmens?"])},company_url_required:e=>{const{normalize:n}=e;return n(["Sagen Sie uns, dass die Website Ihres Unternehmens uns hilft, einen besseren Service zu bieten"])},contactName:e=>{const{normalize:n}=e;return n(["Ihr Name"])},contactName_required:e=>{const{normalize:n}=e;return n(["Wie sollen wir Sie ansprechen?"])},contactTitle:e=>{const{normalize:n}=e;return n(["Wie lautet deine Jobbezeichnung?"])},contactTitle_required:e=>{const{normalize:n}=e;return n(["Ihre Berufsbezeichnung ist erforderlich"])},contact_us:e=>{const{normalize:n}=e;return n(["Kontaktiere uns"])},domain_required:e=>{const{normalize:n}=e;return n(["Teilen Sie uns mit, dass Ihre Arbeitsdomäne uns hilft, einen besseren Service zu bieten"])},email:e=>{const{normalize:n}=e;return n(["Email"])},email_contact:e=>{const{normalize:n}=e;return n(["Ihre Kontakt-E-Mail"])},email_invalid:e=>{const{normalize:n}=e;return n(["E-Mail ist ungültig"])},email_required:e=>{const{normalize:n}=e;return n(["E-Mail ist erforderlich"])},fine_tuned_embedding:e=>{const{normalize:n}=e;return n(["Sind Sie an fein abgestimmten Einbettungen interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!"])},fine_tuned_reranker:e=>{const{normalize:n}=e;return n(["Sind Sie an fein abgestimmten Rerankern interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!"])},full_survey:e=>{const{normalize:n}=e;return n(["Nehmen Sie an der vollständigen Umfrage teil und erhalten Sie schnellere Antworten von unserem Team"])},get_new_key:e=>{const{normalize:n}=e;return n(["Holen Sie sich Ihren API-Schlüssel"])},get_update_blog_posts:e=>{const{normalize:n}=e;return n(["Erhalten Sie die neuesten Updates für die Blogbeiträge"])},get_update_embeddings:e=>{const{normalize:n}=e;return n(["Erhalten Sie die neuesten Updates für die Einbettungen"])},send:e=>{const{normalize:n}=e;return n(["Schicken"])},sign_up:e=>{const{normalize:n}=e;return n(["Melden Sie sich an"])},subscribe:e=>{const{normalize:n}=e;return n(["Abonnieren"])},tell_domain:e=>{const{normalize:n}=e;return n(["Teilen Sie uns Ihre Domain mit"])},usage_type:e=>{const{normalize:n}=e;return n(["Welche Art der Nutzung beschreibt Sie am besten?"])},usage_type_options:{other:e=>{const{normalize:n}=e;return n(["Andere"])},poc:e=>{const{normalize:n}=e;return n(["Konzeptioneller Beweiß"])},production:e=>{const{normalize:n}=e;return n(["Produktion"])},research:e=>{const{normalize:n}=e;return n(["Forschung"])}},usage_type_required:e=>{const{normalize:n}=e;return n(["Teilen Sie uns mit, dass Ihre Nutzungsart uns hilft, einen besseren Service zu bieten"])},used_product:e=>{const{normalize:n}=e;return n(["Welches Modell verwenden Sie?"])},used_product_required:e=>{const{normalize:n}=e;return n(["Wählen Sie das Modell aus, das Sie verwenden oder an dem Sie interessiert sind"])}},think_gpt:{description:e=>{const{normalize:n}=e;return n(["Agententechniken zur Erweiterung Ihres LLM und zur Überschreitung seiner Grenzen"])}},toc:e=>{const{normalize:n}=e;return n(["Inhaltsverzeichnis"])},tokenizer:{advance_usage:e=>{const{normalize:n}=e;return n(["Verwenden Sie die POST-Anfrage für weitere Funktionen"])},basic_usage:e=>{const{normalize:n}=e;return n(["Verwenden Sie eine GET-Anfrage, um Token zu zählen"])},basic_usage_explain:e=>{const{normalize:n}=e;return n(["Sie können einfach eine GET-Anfrage senden, um die Anzahl der Token in Ihrem Text zu zählen."])},change_content:e=>{const{normalize:n}=e;return n(["Ändern Sie den „Inhalt“ und sehen Sie sich das Live-Ergebnis an"])},chars:e=>{const{normalize:n}=e;return n(["Charaktere"])},chinese:e=>{const{normalize:n}=e;return n(["chinesisch"])},chunk:e=>{const{normalize:n}=e;return n(["Brocken"])},chunk_all:e=>{const{normalize:n}=e;return n(["Alle Brocken"])},chunking:e=>{const{normalize:n}=e;return n(["Blitzschnelles Zerlegen langer Dokumente in Blöcke!"])},chunking_explain:e=>{const{normalize:n}=e;return n(["Sie können die Segmenter-API auch verwenden, um lange Dokumente in kleinere Abschnitte zu zerlegen, sodass sie leichter in Einbettungen oder Rerankern verarbeitet werden können. Wir nutzen gängige Strukturmerkmale und erstellen eine Reihe von Regeln und Heuristiken, die bei unterschiedlichen Inhaltstypen gut funktionieren, z. B. in den Sprachen Markdown, HTML, LaTeX und CJK."])},chunking_short:e=>{const{normalize:n}=e;return n(["Chunking"])},chunks_in_total:e=>{const{normalize:n,interpolate:r,named:i}=e;return n([r(i("_numChunks"))," Chunks insgesamt"])},count_tokens_hint:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["<b>",r(i("_numTokens")),"</b> Token, ",r(i("_numChars"))," Zeichen."])},description:e=>{const{normalize:n}=e;return n(["Schneiden Sie langen Text in Abschnitte und führen Sie eine Tokenisierung durch."])},description_long:e=>{const{normalize:n}=e;return n(["Unsere Segmenter-API ist entscheidend, um LLMs dabei zu helfen, Eingaben innerhalb von Kontextgrenzen zu verwalten und die Modellleistung zu optimieren. Sie ermöglicht Entwicklern, Token zu zählen und relevante Textsegmente zu extrahieren, was eine effiziente Datenverarbeitung und Kostenverwaltung gewährleistet."])},description_long1:e=>{const{normalize:n}=e;return n(["Kostenlose API zum Segmentieren langer Texte in Blöcke und zur Tokenisierung."])},english:e=>{const{normalize:n}=e;return n(["Englisch"])},explain:e=>{const{normalize:n}=e;return n(["Ein Segmentierer ist eine wichtige Komponente, die Text in Token oder Blöcke umwandelt. Dabei handelt es sich um die grundlegenden Dateneinheiten, die ein Embedding-/Reranker-Modell oder LLM verarbeitet. Token können ganze Wörter, Wortteile oder sogar einzelne Zeichen darstellen."])},faq_v1:{answer1:e=>{const{normalize:n}=e;return n(["Die Segmenter-API ist kostenlos nutzbar. Durch die Angabe Ihres API-Schlüssels können Sie auf ein höheres Ratenlimit zugreifen und Ihr Schlüssel wird Ihnen nicht in Rechnung gestellt."])},answer10:e=>{const{normalize:n}=e;return n(["Neben westlichen Sprachen funktioniert Chunking auch gut mit Chinesisch, Japanisch und Koreanisch."])},answer2:e=>{const{normalize:n}=e;return n(["Ohne API-Schlüssel können Sie auf die Segmenter-API mit einer Ratenbegrenzung von 20 RPM zugreifen."])},answer3:e=>{const{normalize:n}=e;return n(["Mit einem API-Schlüssel können Sie auf die Segmenter-API mit einer Ratenbegrenzung von 200 RPM zugreifen. Für Premium-Benutzer beträgt die Ratenbegrenzung 1000 RPM."])},answer4:e=>{const{normalize:n}=e;return n(["Nein, Ihr API-Schlüssel wird nur verwendet, um auf ein höheres Ratenlimit zuzugreifen."])},answer5:e=>{const{normalize:n}=e;return n(["Ja, die Segmenter-API ist mehrsprachig und unterstützt über 100 Sprachen."])},answer6:e=>{const{normalize:n}=e;return n(["GET-Anfragen werden ausschließlich zum Zählen der Anzahl von Token in einem Text verwendet und ermöglichen Ihnen die einfache Integration als Zähler in Ihre Anwendung. POST-Anfragen unterstützen mehr Parameter und Funktionen, wie z. B. die Rückgabe der ersten/letzten N Token."])},answer7:e=>{const{normalize:n}=e;return n(["Sie können bis zu 64.000 Zeichen pro Anfrage senden."])},answer8:e=>{const{normalize:n}=e;return n(["Die Chunking-Funktion segmentiert lange Dokumente anhand gemeinsamer Strukturmerkmale in kleinere Chunks und stellt so eine genaue Segmentierung des Textes in sinnvolle Chunks sicher. Im Wesentlichen handelt es sich um ein (großes!) Regex-Muster, das Text anhand bestimmter syntaktischer Merkmale segmentiert, die häufig mit semantischen Grenzen übereinstimmen, wie etwa Satzenden, Absatzumbrüchen, Zeichensetzung und bestimmten Konjunktionen. Es handelt sich nicht um semantisches Chunking. Dieser (große) Regex ist so leistungsfähig, wie er im Rahmen der Beschränkungen regulärer Ausdrücke sein kann. Er schafft ein Gleichgewicht zwischen Komplexität und Leistung. Während mit Regex kein echtes semantisches Verständnis möglich ist, wird der Kontext anhand gemeinsamer Strukturmerkmale gut angenähert."])},answer9:e=>{const{normalize:n}=e;return n(["Wenn die Eingabe spezielle Token enthält, fügt unsere Segmenter-API diese in das Feld „special_tokens“ ein. So können Sie sie leicht identifizieren und für Ihre nachgelagerten Aufgaben entsprechend behandeln, z. B. indem Sie sie entfernen, bevor Sie den Text in ein LLM einspeisen, um Injektionsangriffe zu verhindern."])},question1:e=>{const{normalize:n}=e;return n(["Wie viel kostet die Segmenter-API?"])},question10:e=>{const{normalize:n}=e;return n(["Unterstützt Chunking andere Sprachen als Englisch?"])},question2:e=>{const{normalize:n}=e;return n(["Wenn ich keinen API-Schlüssel angebe, wie hoch ist dann die Ratenbegrenzung?"])},question3:e=>{const{normalize:n}=e;return n(["Wie hoch ist die Ratenbegrenzung, wenn ich einen API-Schlüssel angebe?"])},question4:e=>{const{normalize:n}=e;return n(["Werden die Token von meinem API-Schlüssel abgezogen?"])},question5:e=>{const{normalize:n}=e;return n(["Unterstützt die Segmenter-API mehrere Sprachen?"])},question6:e=>{const{normalize:n}=e;return n(["Was ist der Unterschied zwischen GET- und POST-Anfragen?"])},question7:e=>{const{normalize:n}=e;return n(["Was ist die maximale Länge, die ich pro Anfrage tokenisieren kann?"])},question8:e=>{const{normalize:n}=e;return n(["Wie funktioniert die Chunking-Funktion? Handelt es sich dabei um semantisches Chunking?"])},question9:e=>{const{normalize:n}=e;return n(["Wie handhaben Sie spezielle Token wie „Endoftext“ in der Segmenter-API?"])},title:e=>{const{normalize:n}=e;return n(["Häufige Fragen zum Segmenter"])}},free_api:e=>{const{normalize:n}=e;return n(["Die Nutzung der Segmenter-API ist kostenlos. Durch die Angabe Ihres API-Schlüssels können Sie auf ein höheres Ratenlimit zugreifen, und für Ihren Schlüssel werden keine Kosten erhoben."])},input_text:e=>{const{normalize:n}=e;return n(["Eingabetext"])},is_free:e=>{const{normalize:n}=e;return n(["Segmenter-API ist kostenlos!"])},is_free_description:e=>{const{normalize:n}=e;return n(["Durch die Angabe Ihres API-Schlüssels können Sie auf eine höhere Ratenbegrenzung zugreifen und für Ihren Schlüssel fallen keine Kosten an."])},japanese:e=>{const{normalize:n}=e;return n(["japanisch"])},korean:e=>{const{normalize:n}=e;return n(["Koreanisch"])},parameters:{auth_token:e=>{const{normalize:n}=e;return n(["API-Schlüssel für höhere Ratenbegrenzung hinzufügen"])},auth_token_explain:e=>{const{normalize:n}=e;return n(["Geben Sie Ihren Jina-API-Schlüssel ein, um auf eine höhere Ratenbegrenzung zuzugreifen. Aktuelle Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle."])},head:e=>{const{normalize:n}=e;return n(["Die ersten N Token zurückgeben"])},head_explain:e=>{const{normalize:n}=e;return n(["Gibt die ersten N Token des angegebenen Inhalts zurück. Grenzenexklusiv. Kann nicht mit „tail“ verwendet werden."])},learn_more:e=>{const{normalize:n}=e;return n(["Mehr erfahren"])},max_chunk_length:e=>{const{normalize:n}=e;return n(["Maximale Länge jedes Blocks"])},max_chunk_length_explain:e=>{const{normalize:n}=e;return n(["Maximale Anzahl von Zeichen in jedem Block. In der Praxis kann die Blocklänge kleiner als dieser Wert sein, wenn es im Text eine natürliche Grenze gibt."])},return_chunks:e=>{const{normalize:n}=e;return n(["Die Brocken zurückgeben"])},return_chunks_explain:e=>{const{normalize:n}=e;return n(["Aufteilung der Eingabe in semantisch sinnvolle Segmente bei gleichzeitiger Verarbeitung einer großen Vielfalt an Textarten und Randfällen auf der Grundlage gemeinsamer Strukturhinweise."])},return_tokens:e=>{const{normalize:n}=e;return n(["Die Token zurückgeben"])},return_tokens_explain:e=>{const{normalize:n}=e;return n(["Gibt die Token und ihre entsprechenden IDs in der Antwort zurück. Schalten Sie um, um die Ergebnisvisualisierung anzuzeigen."])},tail:e=>{const{normalize:n}=e;return n(["Die letzten N Token zurückgeben"])},tail_explain:e=>{const{normalize:n}=e;return n(["Gibt die letzten N Token des angegebenen Inhalts zurück. Grenzenexklusiv. Kann nicht mit „head“ verwendet werden."])},type:e=>{const{normalize:n}=e;return n(["Segmentierer"])},type_explain:e=>{const{normalize:n}=e;return n(["Wählen Sie den zu verwendenden Tokenizer aus."])},used_by_models:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Wird in ",r(i("_usedBy"))," verwendet."])}},remove_boundary_cues:e=>{const{normalize:n}=e;return n(["Zeilenumbrüche entfernen"])},remove_boundary_cues_explain:e=>{const{normalize:n}=e;return n(["Entfernen Sie alle Zeilenumbrüche (die wichtigsten Begrenzungshinweise) aus der Eingabe. Dadurch wird das Problem anspruchsvoller und Sie können sehen, wie sich die Antwort ändert."])},show_space:e=>{const{normalize:n}=e;return n(["Führende/nachfolgende Leerzeichen anzeigen"])},table:{td_1_0:e=>{const{normalize:n}=e;return n(["Texte tokenisieren, zählen und die ersten/letzten N Token abrufen."])},td_1_1:e=>{const{normalize:n}=e;return n(["20 U/min"])},td_1_2:e=>{const{normalize:n}=e;return n(["200 U/min"])},td_1_3:e=>{const{normalize:n}=e;return n(["1000 U/min"])},td_1_4:e=>{const{normalize:n}=e;return n(["Keine Gebühr"])},td_1_5:e=>{const{normalize:n}=e;return n(["800 ms"])}},title:e=>{const{normalize:n}=e;return n(["Segmenter-API"])},token_index:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Token-Index: ",r(i("_index"))])},usage:e=>{const{normalize:n}=e;return n(["Verwendung"])},visualization:e=>{const{normalize:n}=e;return n(["Visualisierung"])},what_is:e=>{const{normalize:n}=e;return n(["Was ist ein Segmenter?"])}},translator:{cta:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["In ",r(i("_lang")),"-Code übersetzen"])},select_language:e=>{const{normalize:n}=e;return n(["Sprache"])}},vectordb:{description:e=>{const{normalize:n}=e;return n(["Eine Python-Vektordatenbank, die Sie brauchen – nicht mehr und nicht weniger"])}},zzz:e=>{const{normalize:n}=e;return n(["zzz"])}};export{t as default};
