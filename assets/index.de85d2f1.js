var t={searchbar:{placeholder:e=>{const{normalize:n}=e;return n(["Type your question about this page"])},proposing_solution:e=>{const{normalize:n}=e;return n(["Crafting answer from the page content..."])},hotkey:e=>{const{normalize:n}=e;return n(["Use / key for quick questions"])},hotkey1:e=>{const{normalize:n}=e;return n(["Use"])},hotkey2:e=>{const{normalize:n}=e;return n(["to toggle"])},hotkey_long1:e=>{const{normalize:n}=e;return n(["At any time, press"])},hotkey_long2:e=>{const{normalize:n}=e;return n(["to ask question about the current page"])},required:e=>{const{normalize:n}=e;return n(["Please describe your question with more details."])}},SEO_TAG_LINE:e=>{const{normalize:n}=e;return n(["Expert in Search: Embeddings, Re-ranking, Prompting"])},PRODUCT_DESCRIPTION:e=>{const{normalize:n}=e;return n(["Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications."])},notice:e=>{const{normalize:n}=e;return n(['\u{1F389} Our first book, "Neural Search \u2014 From Prototype to Production with Jina" is officially out today!'])},purchase_now:e=>{const{normalize:n}=e;return n(["Purchase now"])},copy:e=>{const{normalize:n}=e;return n(["Copy"])},copy_to_clipboard_success:e=>{const{normalize:n}=e;return n(["Copied to clipboard"])},powered_by:e=>{const{normalize:n}=e;return n(["Powered by"])},open_day:{title:e=>{const{normalize:n}=e;return n(["Open Day"])},description:e=>{const{normalize:n}=e;return n(["An exclusive opportunity to gain an insider's view of Jina AI."])},organization:e=>{const{normalize:n}=e;return n(["Organization"])},group_size:e=>{const{normalize:n}=e;return n(["Number of visitors"])},organization_website:e=>{const{normalize:n}=e;return n(["Organization website"])},organization_website_placeholder:e=>{const{normalize:n}=e;return n(["URL for your organization's homepage or LinkedIn profile"])},preferred_products:e=>{const{normalize:n}=e;return n(["Which products are you interested in?"])},preferred_date:e=>{const{normalize:n}=e;return n(["Preferred date"])},preferred_language:e=>{const{normalize:n}=e;return n(["Preferred language"])},subtitle:e=>{const{normalize:n}=e;return n(["A Glimpse into the Future of Multimodal AI"])},introduction:e=>{const{normalize:n}=e;return n(["Jina AI is delighted to open our doors to esteemed entities and organizations interested in the progress and future of Artificial Intelligence. We extend this exclusive opportunity for those in politics, NGOs, NPOs, and investment sectors to gain an insider's view of our operations and visions here at our Berlin headquarters."])},vision_title:e=>{const{normalize:n}=e;return n(["Our Vision for the Future"])},vision:e=>{const{normalize:n}=e;return n(["Join us for a comprehensive overview of the AI landscape as we see it. Our discussion will focus on the potential of Large Language Models, multimodal AI, and the impact of open-source technology in shaping the future of global innovation."])},experience:e=>{const{normalize:n}=e;return n(["We've arranged an immersive three-hour tour for our guests, available in German, English, French, Spanish, Chinese, and Russian. The tour covers an in-depth look into our advancements in multimodal AI, our perspective on the AI landscape, followed by a detailed examination of specific projects. We'll conclude with a group discussion to facilitate the exchange of ideas and insights. A lunch option is also available upon request."])},experience_title:e=>{const{normalize:n}=e;return n(["An Insider's Journey"])},impact_title:e=>{const{normalize:n}=e;return n(["Impact and Influence"])},impact:e=>{const{normalize:n}=e;return n(["Understand how our contributions to the open-source community and our work in multimodal AI technology are establishing Jina AI as an influential player in AI innovation. We aim to play a significant role in decision-making processes, ensuring that the advancement of AI technology benefits all."])},engage_title:e=>{const{normalize:n}=e;return n(["Engage with Us"])},engage:e=>{const{normalize:n}=e;return n(["We highly encourage an interactive dialogue throughout the day. The exchange of thoughts and perspectives is invaluable to us. Potential collaborations stemming from these discussions could significantly contribute to a more integrated and innovative future."])},tutor_title:e=>{const{normalize:n}=e;return n(["An Exclusive Deep Dive into"])},tutor_subtitle:e=>{const{normalize:n}=e;return n(["A meticulously curated three-hour tour, bringing you closer to the heart of Jina AI's groundbreaking work in multimodal AI technology."])},one_hour:e=>{const{normalize:n}=e;return n(["1 hour"])},motivation_to_attend_v2:e=>{const{normalize:n}=e;return n(["Why are you interested in our Open Day?"])},motivation_placeholder_v2:e=>{const{normalize:n}=e;return n(["Sharing your motivations will help us improve your experience."])},motivation_min_length_v1:e=>{const{normalize:n}=e;return n(["Please provide a more detailed motivation."])}},internship_faq:{question1:e=>{const{normalize:n}=e;return n(["Who can apply for the Jina AI internship program?"])},answer1:e=>{const{normalize:n}=e;return n(["Undergraduate, Masters, and Ph.D. students from all over the world, with interest in fields such as research, engineering, marketing, and sales, are encouraged to apply. We also welcome non-technical internships in marketing, sales, executive assistance, and more. We are seeking passionate individuals ready to pioneer multimodal AI with us."])},question2:e=>{const{normalize:n}=e;return n(["Where will the internship take place?"])},answer2:e=>{const{normalize:n}=e;return n(["Internships must be carried out onsite at one of our offices, which are located in Berlin, Beijing, and Shenzhen."])},question3:e=>{const{normalize:n}=e;return n(["Does Jina AI assist with visa processes?"])},answer3:e=>{const{normalize:n}=e;return n(["Yes, Jina AI offers reasonable assistance in the visa process for successful applicants."])},question4:e=>{const{normalize:n}=e;return n(["Does Jina AI provide any allowances or benefits for interns?"])},answer4:e=>{const{normalize:n}=e;return n(["Yes, Jina AI provides a reasonable amount of living cost coverage for interns during the internship period."])},question5:e=>{const{normalize:n}=e;return n(["Can I work on my Master's thesis during the internship at Jina AI?"])},answer5:e=>{const{normalize:n}=e;return n(["Yes, it is possible to work on your Master's thesis during your internship at Jina AI, typically applicable to students at German universities. However, you must have prior communication and agreement from your university's supervisor. Note that we do not help students find advisors."])},question6:e=>{const{normalize:n}=e;return n(["What does the application process involve?"])},answer6:e=>{const{normalize:n}=e;return n(["The application process includes submitting your application form, a resume, a cover letter expressing your interest and motivation, and any relevant professional links such as GitHub or LinkedIn. We evaluate candidates based on their performance during the interview and their performance in their university."])},question7:e=>{const{normalize:n}=e;return n(["Does Jina AI provide any letter of recommendation post-internship?"])},answer7:e=>{const{normalize:n}=e;return n(["Yes, successful interns may receive a letter of recommendation at the end of their internship, signed by our CEO."])},question8:e=>{const{normalize:n}=e;return n(["What is the duration of the internship?"])},answer8:e=>{const{normalize:n}=e;return n(["The duration of the internship varies based on the role and project. However, it typically ranges from three to six months."])},question9:e=>{const{normalize:n}=e;return n(["Can I apply if I don't have prior experience in AI?"])},answer9:e=>{const{normalize:n}=e;return n(["Yes, we welcome applications from all academic backgrounds. We value your passion and commitment to learn as much as prior experience."])},question10:e=>{const{normalize:n}=e;return n(["Is this a paid internship?"])},answer10:e=>{const{normalize:n}=e;return n(["Yes, our internship program offers competitive remuneration."])},question11:e=>{const{normalize:n}=e;return n(["What opportunities will I have as a Jina AI intern?"])},answer11:e=>{const{normalize:n}=e;return n(["As a Jina AI intern, you'll get hands-on experience working on challenging projects, learn from industry experts, be part of a vibrant community, and have the opportunity to make real contributions to our pioneering work in multimodal AI."])}},open_day_faq:{question1:e=>{const{normalize:n}=e;return n(["What languages do you offer for the tour?"])},answer1:e=>{const{normalize:n}=e;return n(["We offer tours in German, English, French, Spanish, Chinese, and Russian."])},question2:e=>{const{normalize:n}=e;return n(["What is the duration of the tour?"])},answer2:e=>{const{normalize:n}=e;return n(["The tour typically lasts for approximately three hours."])},question3:e=>{const{normalize:n}=e;return n(["Is lunch provided?"])},answer3:e=>{const{normalize:n}=e;return n(["Lunch is optional and can be arranged upon request."])},question4:e=>{const{normalize:n}=e;return n(["Can individuals register for the Open Day?"])},answer4:e=>{const{normalize:n}=e;return n(["Our Open Day is designed primarily for professional groups, such as politicians, NGOs, NPOs, and investors. However, we occasionally make exceptions based on the individual's profile."])},question5:e=>{const{normalize:n}=e;return n(["How many people can a group consist of for the Open Day?"])},answer5:e=>{const{normalize:n}=e;return n(["We can accommodate a variety of group sizes. Please indicate the size of your group in the registration form, and we will confirm the details with you."])},question6:e=>{const{normalize:n}=e;return n(["How can I specify areas of interest for the tour?"])},answer6:e=>{const{normalize:n}=e;return n(["There's a section in the registration form where you can specify your areas of interest or any special requests. We will do our best to tailor the tour according to your needs."])},question7:e=>{const{normalize:n}=e;return n(["Are tours available at your Beijing or Shenzhen offices?"])},answer7:e=>{const{normalize:n}=e;return n(["At this time, we only offer tours at our Berlin headquarter located in Kreuzberg. Our Beijing and Shenzhen offices are not currently open for tours."])}},header:{products:e=>{const{normalize:n}=e;return n(["Products"])},news:e=>{const{normalize:n}=e;return n(["News"])},open_day:e=>{const{normalize:n}=e;return n(["Open day"])},for_power_users:e=>{const{normalize:n}=e;return n(["For Power Users"])},for_power_users_description:e=>{const{normalize:n}=e;return n(["Utilize our streamlined multimodal tools to enhance your productivity."])},power_users_others:e=>{const{normalize:n}=e;return n(["More power user tools"])},for_developers:e=>{const{normalize:n}=e;return n(["For Developers"])},for_developers_description:e=>{const{normalize:n}=e;return n(["Experience a comprehensive open-source multimodal AI stack designed for developers."])},developers_others:e=>{const{normalize:n}=e;return n(["More developer tools"])},for_enterprise:e=>{const{normalize:n}=e;return n(["For Enterprises"])},for_enterprise_description:e=>{const{normalize:n}=e;return n(["Discover scalable multimodal AI strategies tailored to meet business needs."])},enterprise_others:e=>{const{normalize:n}=e;return n(["More enterprise solutions"])},internship1:e=>{const{normalize:n}=e;return n(["Intern program"])},company:e=>{const{normalize:n}=e;return n(["Company"])},about_us:e=>{const{normalize:n}=e;return n(["About us"])},contact_us:e=>{const{normalize:n}=e;return n(["Contact sales"])},jobs:e=>{const{normalize:n}=e;return n(["Join us"])},join_discord:e=>{const{normalize:n}=e;return n(["Join our Discord community"])}},footer:{power_users:e=>{const{normalize:n}=e;return n(["Power Users"])},developers:e=>{const{normalize:n}=e;return n(["Developers"])},enterprise:e=>{const{normalize:n}=e;return n(["Enterprise"])},address_beijing:e=>{const{normalize:n}=e;return n(["Beijing, China"])},address_shenzhen:e=>{const{normalize:n}=e;return n(["Shenzhen, China"])},address_berlin:e=>{const{normalize:n}=e;return n(["Berlin, Germany (HQ)"])},offices:e=>{const{normalize:n}=e;return n(["Offices"])},docs:e=>{const{normalize:n}=e;return n(["Docs"])},company:e=>{const{normalize:n}=e;return n(["Company"])},all_rights_reserved:e=>{const{normalize:n}=e;return n(["All rights reserved."])},tc:e=>{const{normalize:n}=e;return n(["Terms and Conditions"])},privacy_policy:e=>{const{normalize:n}=e;return n(["Privacy Policy"])},privacy_settings:e=>{const{normalize:n}=e;return n(["Privacy Settings"])}},prompt_perfect:{description:e=>{const{normalize:n}=e;return n(["Premier tool for prompt engineering"])},intro:e=>{const{normalize:n}=e;return n(["Premier tool for prompt engineering"])},intro1:e=>{const{normalize:n}=e;return n(["The premier tool for prompt engineering"])},original_title:e=>{const{normalize:n}=e;return n(["Original prompt"])},optimized_title:e=>{const{normalize:n}=e;return n(["Optimized prompt"])},original:e=>{const{normalize:n}=e;return n(["Your role is to be my brainstorming partner."])},optimized:e=>{const{normalize:n}=e;return n(["Your task is to be my brainstorming partner and provide creative ideas and suggestions for a given topic or problem. Your response should include original, unique, and relevant ideas that could help solve the problem or further explore the topic in an interesting way. Please note that your response should also take into account any specific requirements or constraints of the task."])},text_model:e=>{const{normalize:n}=e;return n(["Text models"])},image_model:e=>{const{normalize:n}=e;return n(["Image models"])}},jina_chat:{description:e=>{const{normalize:n}=e;return n(["More modality, longer memory, less cost"])},example_1:e=>{const{normalize:n}=e;return n(["Who are you?"])},example_2:e=>{const{normalize:n}=e;return n(["I'm a LLM chat service made by Jina AI"])}},scenex:{intro1:e=>{const{normalize:n}=e;return n(["Leading AI solution for image captions and video summaries"])},description:e=>{const{normalize:n}=e;return n(["Explore image storytelling beyond pixels"])},example1:e=>{const{normalize:n}=e;return n(["This video appears to be a nature footage featuring a charming white bunny and a butterfly in a grassy field. The bunny is seen interacting with the butterfly in different ways, showcasing their unique relationship. The natural surroundings provide a picturesque backdrop, enhancing the beauty of this simple yet captivating scene."])},caption_image_title:e=>{const{normalize:n}=e;return n(["Caption Image"])},caption_image_desc:e=>{const{normalize:n}=e;return n(["Generate a textual description of the image."])},json_image_title:e=>{const{normalize:n}=e;return n(["Extract JSON from Image"])},json_image_desc:e=>{const{normalize:n}=e;return n(["Generate a structured JSON format from the image using a predefined schema. This allows for specific data extraction from the image."])},visual_q_a_title:e=>{const{normalize:n}=e;return n(["Visual Q&A"])},visual_q_a_desc:e=>{const{normalize:n}=e;return n(["Answer a query based on the image's content."])},summarize_video_title:e=>{const{normalize:n}=e;return n(["Summarize Video"])},summarize_video_desc:e=>{const{normalize:n}=e;return n(["Generate a concise summary of the video, highlighting key events."])},generate_story_title:e=>{const{normalize:n}=e;return n(["Generate Story"])},generate_story_desc:e=>{const{normalize:n}=e;return n(["Craft a story inspired by the image, often featuring dialogues or monologues of its characters."])}},rationale:{description:e=>{const{normalize:n}=e;return n(["Ultimate AI decision-making tools"])},intro:e=>{const{normalize:n}=e;return n(["See two sides of the coin, make rational decisions"])},decision:e=>{const{normalize:n}=e;return n(["Decision"])}},best_banner:{description:e=>{const{normalize:n}=e;return n(["Blog to banner, without the prompts!"])},example_title:e=>{const{normalize:n}=e;return n(["Alice's Adventures in Wonderland - Chapter 1"])},example_description:e=>{const{normalize:n}=e;return n(["Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, \u201Cand what is the use of a book,\u201D thought Alice \u201Cwithout pictures or conversations?\u201D So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her."])}},doc_array:{description:e=>{const{normalize:n}=e;return n(["The data structure for multimodal data"])}},jina:{description:e=>{const{normalize:n}=e;return n(["Build multimodal AI applications on the cloud"])}},finetuner:{description:e=>{const{normalize:n}=e;return n(["Fine-tune embeddings on domain specific data for better search quality"])},intro:e=>{const{normalize:n}=e;return n(["On-prem embedding-tuning for your company on your data"])}},hub:{description:e=>{const{normalize:n}=e;return n(["Share and discover building blocks for multimodal AI applications"])}},clip_as_service:{description:e=>{const{normalize:n}=e;return n(["Embed images and sentences into fixed-length vectors with CLIP"])}},dalle_flow:{description:e=>{const{normalize:n}=e;return n(["A human-in-the-Loop workflow for creating HD images from text"])}},disco_art:{description:e=>{const{normalize:n}=e;return n(["Create compelling Disco Diffusion artworks in one line of code"])}},think_gpt:{description:e=>{const{normalize:n}=e;return n(["Agent techniques to augment your LLM and push it beyond its limits"])}},jcloud:{description:e=>{const{normalize:n}=e;return n(["Deploy a local project as a cloud service. Radically easy, no nasty surprises."])}},"dev-gpt":{description:e=>{const{normalize:n}=e;return n(["Your virtual development team"])}},langchain_serve:{description:e=>{const{normalize:n}=e;return n(["Langchain apps on production with Jina & FastAPI"])}},vectordb:{description:e=>{const{normalize:n}=e;return n(["A Python vector database you just need - no more, no less"])}},open_gpt:{description:e=>{const{normalize:n}=e;return n(["An open-source cloud-native of large multimodal models serving framework"])}},jerboa:{description:e=>{const{normalize:n}=e;return n(["An experimental finetuner for open-source LLMs"])}},finetuner_plus:{description:e=>{const{normalize:n}=e;return n(["Empower your enterprise with on-premise finetuning solutions"])}},inference:{description:e=>{const{normalize:n}=e;return n(["State-of-the-art multimodal models available for inference"])}},cloud:{description:e=>{const{normalize:n}=e;return n(["Cloud hosting platform for multimodal AI applications"])}},semantic:{description:e=>{const{normalize:n}=e;return n(["Bridging the semantic gap in your existing search infrastructure"])}},searchscape:{description:e=>{const{normalize:n}=e;return n(["Navigate, interact, refine: reimagine product discovery"])}},reranker:{title:e=>{const{normalize:n}=e;return n(["Reranker API"])},read_more_about_benchmark:e=>{const{normalize:n}=e;return n(["Read more about the benchmark"])},benchmark_title:e=>{const{normalize:n}=e;return n(["Performance Benchmark"])},try_embedding:e=>{const{normalize:n}=e;return n(["Try embedding API for free"])},try_reranker:e=>{const{normalize:n}=e;return n(["Try reranker API for free"])},benchmark_description:e=>{const{normalize:n}=e;return n(["For comparison, we included three other leading rerankers by BGE (BAAI), BCE (Netease Youdao), and Cohere in the benchmark. As shown by the results below, Jina Reranker holds the highest average score in all relevant categories for reranking, making it a clear leader among its peers."])},benchmark:{title0:e=>{const{normalize:n}=e;return n(["LlamaIndex"])},title1:e=>{const{normalize:n}=e;return n(["BEIR"])},title2:e=>{const{normalize:n}=e;return n(["LoCo"])},title3:e=>{const{normalize:n}=e;return n(["MTEB"])},description0:e=>{const{normalize:n}=e;return n(["LlamaIndex assessed various combinations of embeddings and rerankers for RAG, conducting a replication study that measured the Mean Reciprocal Rank. The findings highlight the Jina Reranker's significant enhancement of search quality, a benefit that is independent of the specific embeddings used."])},description1:e=>{const{normalize:n}=e;return n(["BIER (Benchmarking IR) assesses a model's retrieval effectiveness, including relevance and NDCG. A higher BIER score correlates to more accurate matches and search result rankings."])},description2:e=>{const{normalize:n}=e;return n(["Through the LoCo benchmark, we measured a model's understanding of local coherence and context, together with query-specific ranking. A LoCo higher score reflects a better ability to identify and prioritize relevant information."])},description3:e=>{const{normalize:n}=e;return n(["The MTEB (Multilingual Text Embedding Benchmark), on the whole, tests a model\u2019s abilities in text embeddings, including clustering, classification, retrieval, and other metrics. However, for our comparison, we only used the MTEB\u2019s Reranking tasks."])}},vs_table:{title:e=>{const{normalize:n}=e;return n(["Comparison of Reranker, Vector Search, and BM25"])},subtitle:e=>{const{normalize:n}=e;return n(["The table below provides a comprehensive comparison of the Reranker, Vector/Embeddings Search, and BM25, highlighting their strengths and weaknesses across various categories."])},col0:e=>{const{normalize:n}=e;return n(["Reranker"])},col1:e=>{const{normalize:n}=e;return n(["Vector Search"])},col2:e=>{const{normalize:n}=e;return n(["BM25"])},header0:e=>{const{normalize:n}=e;return n(["Best For"])},header1:e=>{const{normalize:n}=e;return n(["Granularity"])},header2:e=>{const{normalize:n}=e;return n(["Query Time Complexity"])},header3:e=>{const{normalize:n}=e;return n(["Indexing Time Complexity"])},header4:e=>{const{normalize:n}=e;return n(["Training Time Complexity"])},header5:e=>{const{normalize:n}=e;return n(["Search Quality"])},header6:e=>{const{normalize:n}=e;return n(["Strengths"])},header7:e=>{const{normalize:n}=e;return n(["Weaknesses"])},col0_2:e=>{const{normalize:n}=e;return n(["Initial, rapid filtering"])},col0_1:e=>{const{normalize:n}=e;return n(["Enhanced search precision and relevance"])},col0_3:e=>{const{normalize:n}=e;return n(["General text retrieval across wide-ranging queries"])},col1_1:e=>{const{normalize:n}=e;return n(["Detailed: Sub-document and query segment"])},col1_2:e=>{const{normalize:n}=e;return n(["Broad: Entire documents"])},col1_3:e=>{const{normalize:n}=e;return n(["Intermediate: Various text segments"])},col2_1:e=>{const{normalize:n}=e;return n(["High"])},col2_2:e=>{const{normalize:n}=e;return n(["Medium"])},col2_3:e=>{const{normalize:n}=e;return n(["Low"])},col3_1:e=>{const{normalize:n}=e;return n(["Not required"])},col3_2:e=>{const{normalize:n}=e;return n(["High"])},col3_3:e=>{const{normalize:n}=e;return n(["Low, utilizes pre-built index"])},col4_1:e=>{const{normalize:n}=e;return n(["High"])},col4_2:e=>{const{normalize:n}=e;return n(["High"])},col4_3:e=>{const{normalize:n}=e;return n(["Not required"])},col5_1:e=>{const{normalize:n}=e;return n(["Superior for nuanced queries"])},col5_2:e=>{const{normalize:n}=e;return n(["Balanced between efficiency and accuracy"])},col5_3:e=>{const{normalize:n}=e;return n(["Consistent and reliable for a broad set of queries"])},col6_1:e=>{const{normalize:n}=e;return n(["Highly accurate with deep contextual understanding"])},col6_2:e=>{const{normalize:n}=e;return n(["Quick and efficient, with moderate accuracy"])},col6_3:e=>{const{normalize:n}=e;return n(["Highly scalable, with established efficacy"])},col7_1:e=>{const{normalize:n}=e;return n(["Resource-intensive with complex implementation"])},col7_2:e=>{const{normalize:n}=e;return n(["May not capture deep query context or nuances"])},col7_3:e=>{const{normalize:n}=e;return n(["May underperform for highly specific or contextual searches"])}},feature_solid_description:e=>{const{normalize:n}=e;return n(["Developed from our cutting-edge academic research and rigorously tested against the SOTA rerankers to ensure unparalleled performance."])},improve_performance:e=>{const{normalize:n}=e;return n(["+33% relevance over vector search"])},improve_performance_description:e=>{const{normalize:n}=e;return n(["Our evaluations show that search systems employing the Jina Reranker enjoy +8% in hit rate and +33% in mean reciprocal rank."])},description_rich:e=>{const{normalize:n}=e;return n(["Maximize the search relevancy and RAG accuracy with our cutting-edge reranker API. Start with 1M free tokens."])},reranker_description:e=>{const{normalize:n}=e;return n(["Try our cutting-edge reranker API to maximize your search relevancy and RAG accuracy. Starting for free!"])},description:e=>{const{normalize:n}=e;return n(["Maximize the search relevancy and RAG accuracy at ease"])},learning1:e=>{const{normalize:n}=e;return n(["Learning about Reranker"])},what_is:e=>{const{normalize:n}=e;return n(["What is a Reranker?"])},how_it_works:e=>{const{normalize:n}=e;return n(["Here's how it works:"])},how_it_works_v1:{title1:e=>{const{normalize:n}=e;return n(["Initial Retrieval"])},description1:e=>{const{normalize:n}=e;return n(["A search system uses embeddings/BM25 to find a broad set of potentially relevant documents based on the user's query."])},title2:e=>{const{normalize:n}=e;return n(["Reranking"])},description2:e=>{const{normalize:n}=e;return n(["The reranker then takes these results and analyzes them at a more granular level, considering the nuances of how the query terms interact with the document content."])},title3:e=>{const{normalize:n}=e;return n(["Improved Results"])},description3:e=>{const{normalize:n}=e;return n(["It reorders the search results, placing the ones it deems most relevant at the top, based on this deeper analysis."])}},what_is_answer_long:e=>{const{normalize:n}=e;return n([`The goal of a search system is to find the most relevant results quickly and efficiently. Traditionally, methods like BM25 or tf-idf have been used to rank search results based on keyword matching. Recent methods, such as embedding-based cosine similarity, have been implemented in many vector databases. These methods are straightforward but can sometimes miss the subtleties of language, and most importantly, the interaction between documents and a query's intent.

This is where the "reranker" shines. A reranker is an advanced AI model that takes the initial set of results from a search\u2014often provided by an embeddings/token-based search\u2014and reevaluates them to ensure they align more closely with the user's intent. It looks beyond the surface-level matching of terms to consider the deeper interaction between the search query and the content of the documents.`])},what_is_answer_long_ending:e=>{const{normalize:n}=e;return n(["The reranker can significantly improve the search quality because it operates at a sub-document and sub-query level, meaning it looks at the individual words and phrases, their meanings, and how they relate to each other within the query and the documents. This results in a more precise and contextually relevant set of search results."])},what_is_desc:e=>{const{normalize:n}=e;return n(["A reranker is an AI model that refines the search results from a vector search or a dense retrieval model. Read more."])},learning1_description:e=>{const{normalize:n}=e;return n(["What is a reranker? Why is vector search or cosine similarity not enough? Learn about rerankers from the ground up with our comprehensive guide."])},feature_on_premises_description2:e=>{const{normalize:n}=e;return n(["Deploy Jina Reranker on AWS Sagemaker, and soon in Microsoft Azure and Google Cloud Services, or contact our sales team to get customized Kubernetes deployments for your Virtual Private Cloud and on-premises servers."])}},landing_page:{learn_more_embeddings:e=>{const{normalize:n}=e;return n(["Learn more about embeddings"])},learn_more_reranker:e=>{const{normalize:n}=e;return n(["Learn more about reranker"])},try_it_for_free:e=>{const{normalize:n}=e;return n(["Try it for free, no credit card required"])},reranker:e=>{const{normalize:n}=e;return n(["Reranker"])},finding_faq:e=>{const{normalize:n}=e;return n(["Generating answer based on the FAQ knowledge below"])},embeddings:e=>{const{normalize:n}=e;return n(["Embeddings"])},new:e=>{const{normalize:n}=e;return n(["New"])},"on-premises":e=>{const{normalize:n}=e;return n(["On-premises"])},"on-prem-deploy":e=>{const{normalize:n}=e;return n(["On-premises deployment"])},also_available_on1:e=>{const{normalize:n}=e;return n(["Available on the marketplaces of your enterprise cloud"])},coming_soon:e=>{const{normalize:n}=e;return n(["Coming soon"])},try_our_saas:e=>{const{normalize:n}=e;return n(["Try our hosted solution, a drop-in replacement for OpenAI's embedding API."])},also_available_on:e=>{const{normalize:n}=e;return n(["Available on the marketplaces"])},our_publications:e=>{const{normalize:n}=e;return n(["Our Publications"])},embedding_desc1:e=>{const{normalize:n}=e;return n(["Start with 1M free tokens. Top-performing, 8192 context length bilingual embeddings for your search and RAG systems."])},enterprise_desc_v2:e=>{const{normalize:n}=e;return n(["Try our world-class embedding models to improve your search and RAG systems. Start with a free trial!"])},enterprise_desc_v3:e=>{const{normalize:n}=e;return n(["We develop cutting-edge search foundational models for high-quality enterprise search and RAG solutions. Start with a free trial!"])},researcher_desc:e=>{const{normalize:n}=e;return n(["To understand how our large language models were trained from scratch for embedding tasks, check out our latest research and publications. Meet our team at the EMNLP, ACL, SIGIR, NeurIPS, and ICML conferences."])},include_experiment:e=>{const{normalize:n}=e;return n(["Includes our experimental and archived projects in the solution."])},your_portal_to:e=>{const{normalize:n}=e;return n(["Your Portal to"])},copy:e=>{const{normalize:n}=e;return n(["Copy"])},require_full_question:e=>{const{normalize:n}=e;return n(["Please describe your problem with more details."])},proposing_solution:e=>{const{normalize:n}=e;return n(["Proposing a solution based on Jina AI products..."])},mentioned_products:e=>{const{normalize:n}=e;return n(["Mentioned products:"])},copied_to_clipboard:e=>{const{normalize:n}=e;return n(["Copied to clipboard"])},checkout_our_solution_for_you:e=>{const{normalize:n}=e;return n(["Find out our solution tailored for you"])},ask_how_your_question:e=>{const{normalize:n}=e;return n(["Please describe your problem"])},how_to:e=>{const{normalize:n}=e;return n(["How to"])},powered_by_promptperfect:e=>{const{normalize:n}=e;return n([`Powered by PromptPerfect's "Prompt optimization" and "Prompt as a service" feature`])},error:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["There was a problem with the fetch operation: ",r(o("message"))])},find_your_portal:e=>{const{normalize:n}=e;return n(["Find Your Portal"])},opensource:e=>{const{normalize:n}=e;return n(["Open Source"])},mmstack:e=>{const{normalize:n}=e;return n(["Multimodal Stack"])},mmstack_desc:e=>{const{normalize:n}=e;return n(["The developer-friendly, cloud-native, and production-ready stack for building multimodal AI applications."])},llm:e=>{const{normalize:n}=e;return n(["LLM embedding models"])},llm_desc:e=>{const{normalize:n}=e;return n(["We provide a collection of high-performance sentence embedding models, boasting between 35 million to 6 billion parameters. They're excellent for enhancing neural search, reranking, sentence similarity, recommendations, etc. Get ready to elevate your AI experience!"])},parameters:e=>{const{normalize:n}=e;return n(["Parameters"])},download_pdf:e=>{const{normalize:n}=e;return n(["Download PDF"])},multimodal_ai:e=>{const{normalize:n}=e;return n(["Multimodal AI"])},multimodal:e=>{const{normalize:n}=e;return n(["Multimodal"])},contact_sales:e=>{const{normalize:n}=e;return n(["Contact sales"])},join_community:e=>{const{normalize:n}=e;return n(["Join community"])},trusted_by:e=>{const{normalize:n}=e;return n(["TRUSTED BY"])},newsroom:e=>{const{normalize:n}=e;return n(["Newsroom"])},read_more:e=>{const{normalize:n}=e;return n(["Read more"])},for:e=>{const{normalize:n}=e;return n(["For"])},power_users:e=>{const{normalize:n}=e;return n(["Power Users"])},researchers:e=>{const{normalize:n}=e;return n(["Researchers"])},power_users_desc:e=>{const{normalize:n}=e;return n(["Experience powerful, user-friendly multimodal AI apps. No coding, no fuss, just results."])},developers:e=>{const{normalize:n}=e;return n(["Developers"])},developers_desc:e=>{const{normalize:n}=e;return n(["Unleash the full power of multimodal AI with cutting-edge cloud-native technologies and open-source infrastructure."])},sdk:e=>{const{normalize:n}=e;return n(["SDK"])},starter_kit:e=>{const{normalize:n}=e;return n(["Starter Kit"])},sdk_desc:e=>{const{normalize:n}=e;return n(["Want to build high-level AIGC applications using PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale APIs? We've got you covered! Try our easy-to-use SDK and get started in minutes."])},sdk_docs:e=>{const{normalize:n}=e;return n(["Read docs"])},sdk_example:e=>{const{normalize:n}=e;return n(["Example"])},build_python:e=>{const{normalize:n}=e;return n(["Build with Python"])},build_js:e=>{const{normalize:n}=e;return n(["Build with JavaScript"])},enterprise:e=>{const{normalize:n}=e;return n(["Enterprise"])},enterprise_desc:e=>{const{normalize:n}=e;return n(["Boost your business with scalable, secure, and bespoke multimodal AI solutions."])},embedding_paper_title:e=>{const{normalize:n}=e;return n(["Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models"])},embedding_paper_desc:e=>{const{normalize:n}=e;return n(["Jina Embeddings constitutes a set of high-performance sentence embedding models adept at translating various textual inputs into numerical representations, thereby capturing the semantic essence of the text. While these models are not exclusively designed for text generation, they excel in applications such as dense retrieval and semantic textual similarity. This paper details the development of Jina Embeddings, starting with the creation of a high-quality pairwise and triplet dataset. It underlines the crucial role of data cleaning in dataset preparation, gives in-depth insights into the model training process, and concludes with a comprehensive performance evaluation using the Massive Textual Embedding Benchmark (MTEB)."])}},about_us_page:{download_logo:e=>{const{normalize:n}=e;return n(["Download logos"])},download_jina_logo:e=>{const{normalize:n}=e;return n(["Download the Jina AI Logo"])},download_jina_logo_desc:e=>{const{normalize:n}=e;return n(["Get the Jina AI logo in both light and dark modes, available in PNG and SVG formats. This logo is a registered trademark with the European Union Intellectual Property Office (EUIPO)."])},download_docarray_logo:e=>{const{normalize:n}=e;return n(["Download the DocArray Logo"])},download_docarray_logo_desc:e=>{const{normalize:n}=e;return n(["Access the DocArray logo, an open-source project initiated by Jina AI and contributed to the Linux Foundation in December 2022. Available in light and dark modes, in PNG and SVG formats."])},brochure_info:e=>{const{normalize:n}=e;return n(["Your Guide to Our Company Awaits"])},download_brochure1:e=>{const{normalize:n}=e;return n(["Download brochure"])},employees:e=>{const{normalize:n}=e;return n(["Employees"])},approach:e=>{const{normalize:n}=e;return n(["Our Approach"])},approach_content1:e=>{const{normalize:n}=e;return n(["In the rapidly evolving world of AI, strategies need to be both nimble and forward-thinking. While our core offering remains centered on enterprises, the AI landscape has shifted in ways that necessitate a rethinking of our approach to customer acquisition. Here's why introducing power users as the entry point of our funnel isn't just innovative, but crucial for our sustained growth in the enterprise sector."])},approach_content2:e=>{const{normalize:n}=e;return n(["At Jina AI, our strategy is to be proactive rather than reactive. The inclusion of power users as the funnel's entry point ensures we're not only capturing current market trends but are also strategically poised for future enterprise growth. Our commitment to enterprises remains unwavering; however, our approach to reaching them is innovative, robust, and, above all, forward-thinking."])},approach_new_paradigm:e=>{const{normalize:n}=e;return n(["Prompt-based Technology: A New Paradigm"])},approach_miss_mark:e=>{const{normalize:n}=e;return n(["Why Traditional MLOps Miss the Mark"])},approach_connect_dots:e=>{const{normalize:n}=e;return n(["Connecting the Dots: Power Users to Enterprises"])},approach_new_paradigm_description:e=>{const{normalize:n}=e;return n([`2023 heralded a significant change: the rise of prompt-based technology. By simplifying the AI development process, it has democratized access to AI tools. Now, those without extensive programming experience\u2014termed as 'power users'\u2014can engage in AI development without the steep learning curves associated with tools like Pytorch, Docker, or Kubernetes.

Drawing a parallel, this is akin to the evolution of personal computing. Initially, only tech experts operated computers. But with the advent of user-friendly interfaces, a broader audience could participate. Today, with prompt-based technology, we're witnessing a similar democratization in AI.`])},approach_miss_mark_description:e=>{const{normalize:n}=e;return n(["While the influx of power users is significant, traditional MLOps tools are ill-equipped to cater to their needs. These tools are reminiscent of using a tractor to navigate city streets\u2014they're heavy and often excessive. The new-gen developers demand agile, intuitive tools that complement their rapid development pace."])},approach_connect_dots_description:e=>{const{normalize:n}=e;return n(["So, why is a power user focus essential for our enterprise-centric model? Because it\u2019s about establishing early relationships. By catering to power users now, we're building bridges to the enterprises they'll influence in the future. It\u2019s a strategic play\u2014a long-term investment to ensure our enterprise offering remains top-of-mind when these power users ascend to decision-making roles within organizations."])},title:e=>{const{normalize:n}=e;return n(["About Jina AI"])},title0:e=>{const{normalize:n}=e;return n(["The Future"])},title1:e=>{const{normalize:n}=e;return n(["Starts"])},title2:e=>{const{normalize:n}=e;return n(["Here"])},description:e=>{const{normalize:n}=e;return n(["The future starts here."])},subtitle:e=>{const{normalize:n}=e;return n(["Revolutionizing content creation through AI-generated solutions to unlock infinite possibilities. Shaping the future of AI-generated content and enhancing human creativity."])},stats:e=>{const{normalize:n}=e;return n(["Pioneering the Future of Multimodal AI"])},founded:e=>{const{normalize:n}=e;return n(["Founded"])},founded_in:e=>{const{normalize:n}=e;return n(["Founded in"])},empower_developers:e=>{const{normalize:n}=e;return n(["Developers Empowered"])},technologies:e=>{const{normalize:n}=e;return n(["Technologies"])},users:e=>{const{normalize:n}=e;return n(["Users Registered"])},value:e=>{const{normalize:n}=e;return n(["Our Value"])},value_content:e=>{const{normalize:n}=e;return n([`At Jina AI, we believe in the power of open-source technology to accelerate innovation, foster collaboration, and empower communities. We're not just advocates - we are active contributors, investing significantly in the open-source community.

From being the driving force behind FastAPI, to our ongoing support for the Linux and Python Foundations, we are passionate about giving back. But we don\u2019t stop there; we\u2019ve also open-sourced our core infrastructure, sharing our multimodal AI expertise with the world.

At Jina AI, we strive to lead by example, using our resources to nurture the community that nurtures us. It\u2019s our way of saying thank you and ensuring a vibrant future for the technologies we all depend on. After all, we're all in this together.`])},stats_1:e=>{const{normalize:n}=e;return n(["Founded in February 2020, Jina AI has swiftly emerged as a global pioneer in multimodal AI technology. Within an impressive timeframe of 20 months, we have successfully raised $37.5M, marking our strong position in the AI industry. Our ground-breaking technology, open-sourced on GitHub, has empowered over 40,000 developers around the globe to seamlessly build and deploy sophisticated multimodal applications."])},stats_2:e=>{const{normalize:n}=e;return n(["In 2023, we've made significant strides in advancing AI generation tools grounded on multimodal technology. This innovation has benefited over 250,000 users worldwide, catering to a plethora of unique business requirements. From facilitating business growth and enhancing operational efficiency to optimizing costs, Jina AI is dedicated to empowering businesses to excel in the multimodal era."])},stats_3:e=>{const{normalize:n}=e;return n([`Founded in 2020 and based in Berlin, Germany, Jina AI has swiftly risen as a leader in multimodal AI, focusing on prompt and embedding techniques. As a company rooted in the EU, our vision and services extend worldwide, providing businesses and developers with innovative platforms to harness the power of AI for value creation and cost savings. 

Our commitment to open-source and open research has shaped our identity as a commercial open-source software company. This dedication to innovation is underscored by our financial growth, marked by a $38M raise in our Series A round in November 2021. At Jina AI, we're bridging the gap between advanced AI and practical applications on a global scale.`])},investors:e=>{const{normalize:n}=e;return n(["Our Investors"])},vision:e=>{const{normalize:n}=e;return n(["Our Vision"])},vision_content1:e=>{const{normalize:n}=e;return n(["Inspired by Yann LeCun's insight that '"])},vision_content2:e=>{const{normalize:n}=e;return n(["Jina AI envisions paving the way towards the future of AI as a multimodal reality. We recognize that the existing machine learning and software ecosystems face challenges in handling multimodal AI. As a response, we're committed to developing pioneering tools and platforms that assist businesses and developers in navigating these complexities. Our vision is to play a crucial role in helping the world harness the vast potential of multimodal AI and truly revolutionize the way we interpret and interact with information."])},yannlecun_quote:e=>{const{normalize:n}=e;return n(["An artificial intelligence system trained on words and sentences alone will never approximate human understanding."])},our_answer:e=>{const{normalize:n}=e;return n(["Absolutely, Yann. We're on it, building bridges to a multimodal AI future!"])},mission:e=>{const{normalize:n}=e;return n(["Our Mission"])},mission_content1:e=>{const{normalize:n}=e;return n(["At the heart of Jina AI lies our mission to be the portal to multimodal AI for a diverse clientele, from power users and developers to enterprises. We deeply believe in the power of open-source and are dedicated to building advanced, accessible tools for the AI community. Our key technologies, including prompt-tuning, prompt-serving, model-tuning, and model-serving, embody our commitment to democratizing access to AI. Through our open-source initiative, we strive to foster innovation, collaboration, and transparency, ensuring scalable, efficient, and robust solutions. Jina AI is more than just a company; it's a community devoted to empowering businesses to meet the dynamic challenges of the digital age and thrive in their domains."])},mission_content2:e=>{const{normalize:n}=e;return n(["At the heart of Jina AI lies our mission to be the portal to multimodal AI for a diverse clientele, from power users and developers to enterprises. We deeply believe in the power of open-source and are dedicated to building advanced, accessible tools for the AI community. Our key technologies, including prompt-tuning, prompt-serving, embedding-tuning, and embedding-serving, embody our commitment to democratizing access to AI. Through our open-source initiative, we strive to foster innovation, collaboration, and transparency, ensuring scalable, efficient, and robust solutions. Jina AI is more than just a company; it's a community devoted to empowering businesses to meet the dynamic challenges of the digital age and thrive in their domains."])},mission_content3:e=>{const{normalize:n}=e;return n(["At Jina AI, our mission is to lead the advancement of multimodal AI through innovative embedding and prompt-based technologies, focusing specifically on areas like natural language processing, image and video analysis, and cross-modal data interaction. This specialization allows us to provide unique solutions that turn complex, multi-source data into actionable insights and groundbreaking applications."])},team:e=>{const{normalize:n}=e;return n(["Inside the Portal of Jina AI"])},team_content:e=>{const{normalize:n}=e;return n(["From diverse corners of the globe, we're co-creating the future of multimodal AI. Our distinct lifestyles and perspectives enrich our work, sparking creativity and progress. Within this portal, we embrace our individuality, cherish our freedom, and passionately pursue our dreams. Welcome to the portal of the AI future."])},team_join:e=>{const{normalize:n}=e;return n(["Join us"])},office:e=>{const{normalize:n}=e;return n(["Our Offices"])},berlin:e=>{const{normalize:n}=e;return n(["Berlin, Germany"])},berlin_address:e=>{const{normalize:n}=e;return n(["Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany"])},berlin_address2:e=>{const{normalize:n}=e;return n(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berlin, Germany"])},bj:e=>{const{normalize:n}=e;return n(["Beijing, China"])},bj_address:e=>{const{normalize:n}=e;return n(["Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China"])},sz:e=>{const{normalize:n}=e;return n(["Shenzhen, China"])},sz_address:e=>{const{normalize:n}=e;return n(["402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China"])},awards:e=>{const{normalize:n}=e;return n(["Awards & Recognition"])},fastApiCaption:e=>{const{normalize:n}=e;return n(["Contributed over $20,000 since 2021."])},linuxFoundationCaption:e=>{const{normalize:n}=e;return n(["Makes an annual contribution of $10,000 starting from 2022."])},pythonSoftwareFoundationCaption:e=>{const{normalize:n}=e;return n(["Provided a one-time donation of $10,000 and sponsored multiple PyCon events including those in Germany, Italy, China, and the US."])},numfocusCaption:e=>{const{normalize:n}=e;return n(["Regularly donates each month starting from 2022."])},segmentFaultCaption:e=>{const{normalize:n}=e;return n(["Contributed a one-time donation of $6,000."])},otherProjectsCaption:e=>{const{normalize:n}=e;return n(["Donated over $3,000 via Github Sponsorship."])},understand_our_strength:e=>{const{normalize:n}=e;return n(["Understand Our Strength"])},understand_our_view:e=>{const{normalize:n}=e;return n(["Understand Our View"])}},internship_page:{title:e=>{const{normalize:n}=e;return n(["Intern Program"])},description:e=>{const{normalize:n}=e;return n(["Worldwide call for students: Intern in research, engineering, marketing, sales and more to pioneer multimodal AI together."])},subtitle:e=>{const{normalize:n}=e;return n(["Our full-time internship programme provides hands-on work experience through well-designed internship projects in a wide range of scope."])},subtitle1:e=>{const{normalize:n}=e;return n(["Worldwide call for students: Intern in research, engineering, marketing, sales and more to pioneer multimodal AI together."])},alumni:e=>{const{normalize:n}=e;return n(["ALUMNI"])},about_internship_program:e=>{const{normalize:n}=e;return n(["About Internship Program"])},about_internship_program_desc1:e=>{const{normalize:n}=e;return n(["We are excited to offer this unique opportunity for talented individuals to join our dynamic team and contribute to groundbreaking projects in the field of Artificial Intelligence. This internship is designed to provide you with valuable hands-on experience, mentorship, and exposure to cutting-edge technologies that are shaping the future of AI."])},about_internship_program_desc2:e=>{const{normalize:n}=e;return n(["At Jina AI, we understand the significance of nurturing and harnessing young talent. We recognize that interns bring fresh perspectives, enthusiasm, and creativity to the table, invigorating our team with new ideas and approaches. By providing internships, we aim to foster the growth of future leaders in the AI industry while offering them real-world experience in a supportive and challenging environment."])},who_do_we_look_for:e=>{const{normalize:n}=e;return n(["Who do we look for?"])},who_do_we_look_for_desc:e=>{const{normalize:n}=e;return n(["We value diversity and encourage applicants from diverse profiles and backgrounds to join our Internship Program. The internship opportunities are offered in multiple departments, including Engineering, Design, Product Management, Sales and Account Management, Marketing and Community Management."])},enthusiastic:e=>{const{normalize:n}=e;return n(["ENTHUSIASTIC"])},self_motivated:e=>{const{normalize:n}=e;return n(["SELF-MOTIVATED"])},innovative:e=>{const{normalize:n}=e;return n(["INNOVATIVE"])},explore_stories_from_our_interns:e=>{const{normalize:n}=e;return n(["Explore stories from our interns"])},explore_stories_from_our_interns1:e=>{const{normalize:n}=e;return n(["Get inspired by our interns' journeys"])},software_engineer_intern:e=>{const{normalize:n}=e;return n(["Software Engineer Intern"])},recruiting_and_administrative_intern:e=>{const{normalize:n}=e;return n(["Recruiting and Administrative Intern"])},dev_rel_intern:e=>{const{normalize:n}=e;return n(["Developer Relations Intern"])},alumni_network:e=>{const{normalize:n}=e;return n(["Our thriving alumni network"])},intern_work1:e=>{const{normalize:n}=e;return n(["Fine-tuned LLM models for better embeddings"])},intern_work2:e=>{const{normalize:n}=e;return n(["Explored the potential of Retrieval Augmented Generation"])},intern_work3:e=>{const{normalize:n}=e;return n(["Published a paper on the topic of sentence embeddings"])},intern_work4:e=>{const{normalize:n}=e;return n(["Injecting continuous youthful vitality into the team"])},intern_work5:e=>{const{normalize:n}=e;return n(["Benchmarked quantization techniques to compress LLM"])},intern_work6:e=>{const{normalize:n}=e;return n(["Creating and promoting compelling campaign for PromptPerfect"])},application:e=>{const{normalize:n}=e;return n(["Application"])},submit_application:e=>{const{normalize:n}=e;return n(["Kickstart your adventure with Jina AI"])},application_desc:e=>{const{normalize:n}=e;return n(["Embark on a transformative journey with Jina AI. Our comprehensive internship program invites all passionate minds who aspire to shape the future of artificial intelligence. Join us to get real-world experience, work on challenging projects, and collaborate with some of the brightest minds in the AI industry."])},summer:e=>{const{normalize:n}=e;return n(["Summer"])},autumn:e=>{const{normalize:n}=e;return n(["Autumn"])},winter:e=>{const{normalize:n}=e;return n(["Winter"])},spring:e=>{const{normalize:n}=e;return n(["Spring"])},apply:e=>{const{normalize:n}=e;return n(["Apply now"])}},embeddings:{description:e=>{const{normalize:n}=e;return n(["Our world-class embeddings for your search and RAG systems"])}},spectrum:{prompt_tech:e=>{const{normalize:n}=e;return n(["Prompt & agent engineering"])},embedding_tech:e=>{const{normalize:n}=e;return n(["Embeddings"])},for_power_users:e=>{const{normalize:n}=e;return n(["For Power Users"])},for_developers:e=>{const{normalize:n}=e;return n(["For Developers"])},for_enterprise:e=>{const{normalize:n}=e;return n(["For Enterprises"])},prompt_serving:e=>{const{normalize:n}=e;return n(["Prompt Serving"])},prompt_tuning:e=>{const{normalize:n}=e;return n(["Prompt Tuning"])},model_serving:e=>{const{normalize:n}=e;return n(["Model Serving"])},model_tuning:e=>{const{normalize:n}=e;return n(["Model Tuning"])},embedding_serving:e=>{const{normalize:n}=e;return n(["Embedding Serving"])},embedding_tuning:e=>{const{normalize:n}=e;return n(["Embedding Tuning"])},prompt_tech_description:e=>{const{normalize:n}=e;return n([`At Jina AI, we recognize prompt engineering as vital for interacting with large language models (LLMs). As these models advance, the complexity of prompts escalates, encompassing intricate reasoning and logic. This advancement underscores the intertwined growth of LLMs and prompt sophistication.

We foresee a future where LLMs act as compilers, with prompts becoming the new programming language. This shift suggests that future technological proficiency may focus more on prompt mastery than traditional coding. Our commitment at Jina AI is to lead in this transformative area, making advanced AI accessible and practical for everyday use by mastering this emerging 'language'.`])},embedding_tech_description:e=>{const{normalize:n}=e;return n([`At Jina AI, we harness the power of embedding technology to revolutionize diverse AI applications. This technology serves as a unified method to efficiently represent and compress various data types, ensuring no loss of critical information. Our focus is on transforming complex datasets into a universally understandable embedding format, which is essential for precise and insightful AI analysis.

Embeddings are fundamental, especially in applications like precise image and voice recognition, where they help discern fine-grained details and nuances. In natural language processing, embeddings enhance understanding of context and sentiment, leading to more accurate conversational AI and language translation tools. They are also crucial in developing sophisticated recommendation systems that require a deep understanding of user preferences across different content forms, such as text, audio, and video.`])},prompt_serving_description:e=>{const{normalize:n}=e;return n(["Wrapping and serving prompts through an API, without hosting heavy models. The API calls a public large language model service and handles the orchestration of inputs and outputs in a chain of operations."])},prompt_tuning_description:e=>{const{normalize:n}=e;return n(["The process of crafting and refining the input prompts in order to guide its output towards specific, desired responses."])},embedding_serving_description:e=>{const{normalize:n}=e;return n(["Delivering embeddings through a robust, scalable microservice using cloud-native technologies."])},embedding_tuning_description:e=>{const{normalize:n}=e;return n(["Optimizing high-quality embeddings by integrating domain expertise for enhanced task-specific performance."])},model_serving_description:e=>{const{normalize:n}=e;return n(["The deployment of fine-tuned models in a production environment, usually requiring substantial resources such as GPU hosting. MLOps, emphasizing the serving of mid-size to large models in a scalable, efficient, and reliable manner."])},model_tuning_description:e=>{const{normalize:n}=e;return n(["Also known as fine-tuning, involves adjusting the parameters of a pre-trained model on a new, often task-specific dataset to improve its performance and adapt it to a specific application."])}},huggingface:{sentence_similarity:e=>{const{normalize:n}=e;return n(["Sentence embedding"])},updated_about:e=>{const{normalize:n}=e;return n(["Updated about"])}},impact_snapshots:{project1:e=>{const{normalize:n}=e;return n(["Enable high-accuracy search within 3D mesh data using point cloud information."])},project2:e=>{const{normalize:n}=e;return n(["Design a content-based search engine for short animation films."])},project3:e=>{const{normalize:n}=e;return n(["Enhance e-commerce conversion rates by fine-tuning embedding models."])},project4:e=>{const{normalize:n}=e;return n(["Execute prompt tuning to boost efficiency for a business consulting company."])},project5:e=>{const{normalize:n}=e;return n(["Pioneer game scene understanding and automatic annotation for a leading gaming enterprise."])},project6:e=>{const{normalize:n}=e;return n(["Implement real-time input expansion for a chatbot company, enhancing user experience."])},project7:e=>{const{normalize:n}=e;return n(["Revolutionize legal tech by enabling efficient search within lengthy legal documents."])},project8:e=>{const{normalize:n}=e;return n(["Support a high-throughput generative art service for large-scale operations."])},project9:e=>{const{normalize:n}=e;return n(["Carry out process mining and modeling using advanced language models."])},project10:e=>{const{normalize:n}=e;return n(["Leverage computer vision to improve digital accessibility of government websites."])},project11:e=>{const{normalize:n}=e;return n(["Fine-tune LLM for a consulting firm to optimize finance data analysis."])},project12:e=>{const{normalize:n}=e;return n(["Advance marketing strategies by fine-tuning text-to-image models for style transferring."])}},project_status:{graduated:e=>{const{normalize:n}=e;return n(["Graduated"])},incubating:e=>{const{normalize:n}=e;return n(["Incubating"])},sandbox:e=>{const{normalize:n}=e;return n(["Sandbox"])},archived:e=>{const{normalize:n}=e;return n(["Archived"])},kubernetes:e=>{const{normalize:n}=e;return n(["Kubernetes"])},cloud_native:e=>{const{normalize:n}=e;return n(["Cloud Native"])},prompt_tuning:e=>{const{normalize:n}=e;return n(["Prompt Tuning"])},model_serving:e=>{const{normalize:n}=e;return n(["Model Serving"])},model_tuning:e=>{const{normalize:n}=e;return n(["Model Tuning"])},embedding_serving:e=>{const{normalize:n}=e;return n(["Embedding Serving"])},embedding_tuning:e=>{const{normalize:n}=e;return n(["Embedding Tuning"])},prompt_serving:e=>{const{normalize:n}=e;return n(["Prompt Serving"])},core:e=>{const{normalize:n}=e;return n(["Core"])},small_size_model:e=>{const{normalize:n}=e;return n(["Small Size Model"])},large_size_model:e=>{const{normalize:n}=e;return n(["Large Size Model"])},mid_size_model:e=>{const{normalize:n}=e;return n(["Mid Size Model"])},orchestration:e=>{const{normalize:n}=e;return n(["Orchestration"])},linux_foundation:e=>{const{normalize:n}=e;return n(["Linux Foundation"])},vector_database:e=>{const{normalize:n}=e;return n(["Vector Database"])},data_structure:e=>{const{normalize:n}=e;return n(["Data Structure"])},vector_store:e=>{const{normalize:n}=e;return n(["Vector Store"])},llm1:e=>{const{normalize:n}=e;return n(["LLMOps"])},rag1:e=>{const{normalize:n}=e;return n(["RAG"])}},contact_us_page:{title:e=>{const{normalize:n}=e;return n(["Contact sales"])},description:e=>{const{normalize:n}=e;return n(["Grow your business with Jina AI."])},impact_snapshots:e=>{const{normalize:n}=e;return n(["Impact Snapshots"])},subtitle:e=>{const{normalize:n}=e;return n(["Explore Jina AI, the forefront of multimodal AI. We excel in embedding and prompt technologies, utilizing cloud-native solutions like Kubernetes for robust, scalable systems. Specializing in large language models and media processing, we offer innovative, future-ready business strategies with our advanced AI expertise."])},subtitle1:e=>{const{normalize:n}=e;return n(["Jina AI, a leader in multimodal AI, excels in embedding-tuning, embedding-serving, prompt-tuning, and prompt-serving. Leveraging cloud-native technologies like Kubernetes and serverless architectures, we deliver robust, scalable, and production-ready solutions. With expertise in large language models, text, image, video, audio understanding, neural search, and generative AI, we provide innovative, future-proof strategies to elevate your business."])},subtitle2:e=>{const{normalize:n}=e;return n(["Explore Jina AI, the forefront of multimodal AI. We excel in embedding and prompt technologies, utilizing cloud-native solutions like Kubernetes for robust, scalable systems. Specializing in large language models and media processing, we offer innovative, future-ready business strategies with our advanced AI expertise."])},trusted_by:e=>{const{normalize:n}=e;return n(["Trusted by"])},name:e=>{const{normalize:n}=e;return n(["Name"])},work_email:e=>{const{normalize:n}=e;return n(["Work email"])},country:e=>{const{normalize:n}=e;return n(["Country"])},company:e=>{const{normalize:n}=e;return n(["Company"])},company_size:e=>{const{normalize:n}=e;return n(["Company size"])},company_website:e=>{const{normalize:n}=e;return n(["Company website"])},company_website_placeholder:e=>{const{normalize:n}=e;return n(["URL for your company's homepage or LinkedIn profile"])},invalid_url:e=>{const{normalize:n}=e;return n(["URL is invalid"])},invalid_email:e=>{const{normalize:n}=e;return n(["Email is invalid"])},preferred_products:e=>{const{normalize:n}=e;return n(["Which products are you interested in?"])},department:e=>{const{normalize:n}=e;return n(["Department"])},role:e=>{const{normalize:n}=e;return n(["Job role"])},field_required:e=>{const{normalize:n}=e;return n(["Field is required"])},invalid_date_format:e=>{const{normalize:n}=e;return n(["Invalid date format. Please use DD-MM-YYYY format."])},invalid_number:e=>{const{normalize:n}=e;return n(["Invalid number. Please input again"])},anything_else:e=>{const{normalize:n}=e;return n(["Tell us more about your project"])},agreement:e=>{const{normalize:n}=e;return n(["By submitting, you confirm that you agree to the processing of your personal data by Jina AI as described in the"])},private_statement:e=>{const{normalize:n}=e;return n(["Privacy Statement"])},submit:e=>{const{normalize:n}=e;return n(["Submit"])},submit_success:e=>{const{normalize:n}=e;return n(["Thank you for your submission. We will get back to you shortly."])},submit_failed:e=>{const{normalize:n}=e;return n(["Submission failed. Please try again later."])},faq:e=>{const{normalize:n}=e;return n(["FAQ"])}},blog_tags:{featured:e=>{const{normalize:n}=e;return n(["Featured"])},"tech-blog":e=>{const{normalize:n}=e;return n(["Tech blog"])},all:e=>{const{normalize:n}=e;return n(["All"])},press:e=>{const{normalize:n}=e;return n(["Press release"])},events:e=>{const{normalize:n}=e;return n(["Events"])},insights:e=>{const{normalize:n}=e;return n(["Insights"])},"knowledge-base":e=>{const{normalize:n}=e;return n(["Knowledge base"])},releases:e=>{const{normalize:n}=e;return n(["Software updates"])}},newsroom_page:{title:e=>{const{normalize:n}=e;return n(["Newsroom"])},top_stories:e=>{const{normalize:n}=e;return n(["Top stories"])},description:e=>{const{normalize:n}=e;return n(["Read the latest news and updates from Jina AI."])},tech_blog:e=>{const{normalize:n}=e;return n(["Tech blog"])},news_title:e=>{const{normalize:n}=e;return n(["Search All the Things: We're Running a MEME Contest for Jina 2.0"])},news_description:e=>{const{normalize:n}=e;return n(["For Jina 2.0, we listened to the community. Truly, deeply listened. \u201CWhat are your pain points?\u201D we asked, eagerly anticipating valuable feedback"])},engineering_group:e=>{const{normalize:n}=e;return n(["Engineering Group"])},engineering_group_date:e=>{const{normalize:n}=e;return n(["31 May, 2021"])},author:e=>{const{normalize:n}=e;return n(["By author"])},product:e=>{const{normalize:n}=e;return n(["By product"])},photos:e=>{const{normalize:n}=e;return n(["Photos"])},most_recent_articles:e=>{const{normalize:n}=e;return n(["Most recent articles"])},minutes_read:e=>{const{normalize:n}=e;return n(["minutes read"])},search:e=>{const{normalize:n}=e;return n(["Search by title"])}},news_page:{copy_link:e=>{const{normalize:n}=e;return n(["Copy the link to this section"])},news_not_found:e=>{const{normalize:n}=e;return n(["Article not found"])},redirect_to_news:e=>{const{normalize:n}=e;return n(["Redirecting to newsroom in 5 seconds..."])},back_to_newsroom:e=>{const{normalize:n}=e;return n(["Back to Newsroom"])},categories:e=>{const{normalize:n}=e;return n(["Categories"])},learn_more:e=>{const{normalize:n}=e;return n(["Learn more"])},in_this_article:e=>{const{normalize:n}=e;return n(["In this article"])}},github:{stars:e=>{const{normalize:n}=e;return n(["Stars"])}},share:{share_btn:e=>{const{normalize:n}=e;return n(["Share"])},"Hacker News":e=>{const{normalize:n}=e;return n(["Hacker News"])},LinkedIn:e=>{const{normalize:n}=e;return n(["LinkedIn"])},reddit:e=>{const{normalize:n}=e;return n(["Reddit"])},twitter:e=>{const{normalize:n}=e;return n(["X (Twitter)"])},facebook:e=>{const{normalize:n}=e;return n(["Facebook"])},rss:e=>{const{normalize:n}=e;return n(["RSS feed"])}},faq:{question1:e=>{const{normalize:n}=e;return n(["What does Jina AI specialize in?"])},answer1:e=>{const{normalize:n}=e;return n(["Jina AI specializes in multimodal AI technologies, including embedding-tuning, embedding-serving, prompt-tuning, and prompt-serving. We leverage advanced tools like Kubernetes and serverless architectures to create robust, scalable, and production-ready solutions."])},question2:e=>{const{normalize:n}=e;return n(["What types of AI does Jina AI work with?"])},answer2:e=>{const{normalize:n}=e;return n(["Our expertise spans a broad spectrum, encompassing large language models, text, image, video, audio understanding, neural search, and generative art."])},question3:e=>{const{normalize:n}=e;return n(["Are your solutions scalable and production-ready?"])},answer3:e=>{const{normalize:n}=e;return n(["Yes, our solutions are designed to be scalable and ready for production. We build our solutions using cloud-native technologies that allow for efficient scaling and reliable performance in production environments."])},question4:e=>{const{normalize:n}=e;return n(["What industries can benefit from Jina AI's solutions?"])},answer4:e=>{const{normalize:n}=e;return n(["Our services are versatile and adaptable, making them suitable for a wide range of industries, including e-commerce, legal tech, digital marketing, gaming, healthcare, finance, and many more."])},question5:e=>{const{normalize:n}=e;return n(["How do we start a project with Jina AI?"])},answer5:e=>{const{normalize:n}=e;return n(["You can get in touch with our sales team through the contact form on this page. We would love to discuss your project requirements and how our solutions can help your business."])},question6:e=>{const{normalize:n}=e;return n(["What support do you provide after implementing a solution?"])},answer6:e=>{const{normalize:n}=e;return n(["We provide continuous support to ensure the smooth operation of our solutions. This includes troubleshooting, regular updates, and improvements based on your feedback and needs."])},question7:e=>{const{normalize:n}=e;return n(["What is the typical duration for a project?"])},answer7:e=>{const{normalize:n}=e;return n(["Project duration varies depending on the complexity and scope of the project. After understanding your requirements, we can provide a more accurate estimate."])},question8:e=>{const{normalize:n}=e;return n(["How does Jina AI protect my data?"])},answer8:e=>{const{normalize:n}=e;return n(["Data security is our top priority. We adhere to strict data protection policies and regulations to ensure your data is secure and confidential."])},question9:e=>{const{normalize:n}=e;return n(["What is the pricing structure for your services?"])},answer9:e=>{const{normalize:n}=e;return n(["Pricing depends on the project's complexity and requirements. We offer both project-based and retainer pricing models. Please contact our sales team for more information."])},question10:e=>{const{normalize:n}=e;return n(["What are the licensing terms for your solutions?"])},answer10:e=>{const{normalize:n}=e;return n(["We provide different licensing options based on the nature of the project and the client's needs. Detailed terms can be discussed with our sales team."])},question11:e=>{const{normalize:n}=e;return n(["What is your service area?"])},answer11:e=>{const{normalize:n}=e;return n(["We provide services globally, with our headquarters based in Berlin, Europe, and additional offices in Beijing and Shenzhen."])},question12:e=>{const{normalize:n}=e;return n(["Do you offer onsite support?"])},answer12:e=>{const{normalize:n}=e;return n(["Yes, we offer onsite support, especially for clients located near our offices in Berlin, Beijing, and Shenzhen. For other locations, we strive to provide the best possible remote support and can arrange for onsite support if necessary."])}},beta:e=>{const{normalize:n}=e;return n(["Beta"])},print:e=>{const{normalize:n}=e;return n(["Print"])},subscribe_system:{email:e=>{const{normalize:n}=e;return n(["Email"])},email_contact:e=>{const{normalize:n}=e;return n(["Your contact Email"])},subscribe:e=>{const{normalize:n}=e;return n(["Subscribe"])},send:e=>{const{normalize:n}=e;return n(["Send"])},contact_us:e=>{const{normalize:n}=e;return n(["Contact us"])},sign_up:e=>{const{normalize:n}=e;return n(["Sign up"])},tell_domain:e=>{const{normalize:n}=e;return n(["Tell us your domain"])},get_update_embeddings:e=>{const{normalize:n}=e;return n(["Get the latest updates for the embeddings"])},get_update_blog_posts:e=>{const{normalize:n}=e;return n(["Get the latest updates for the blog posts"])},email_required:e=>{const{normalize:n}=e;return n(["Email is required"])},email_invalid:e=>{const{normalize:n}=e;return n(["Email is invalid"])},fine_tuned_embedding:e=>{const{normalize:n}=e;return n(["Interested in fine-tuned embeddings tailored to your data and use case? Let's discuss!"])}},embedding:{pricing:e=>{const{normalize:n}=e;return n(["API Pricing"])},right_api_key_to_charge:e=>{const{normalize:n}=e;return n(["Please input the right API key to top up"])},pricing_desc:e=>{const{normalize:n}=e;return n(["Our API pricing is structured around the quantity of tokens sent in the requests. This pricing model is applicable to both embedding and reranking APIs. With the same API key, you have access to both services."])},select_embedding_model:e=>{const{normalize:n}=e;return n(["Select embeddings"])},select_rerank_model:e=>{const{normalize:n}=e;return n(["Select reranker"])},fill_example:e=>{const{normalize:n}=e;return n(["Fill in the example"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:n}=e;return n(["The leading reranker maximizing search and RAG relevance"])},"jina-colbert-v1-en_description":e=>{const{normalize:n}=e;return n(["A reranker utilizing ColBERT's late interaction architecture"])},read_api_docs:e=>{const{normalize:n}=e;return n(["Read the docs"])},input:e=>{const{normalize:n}=e;return n(["Request"])},output:e=>{const{normalize:n}=e;return n(["Response"])},usage_rerank:e=>{const{normalize:n}=e;return n(["Usage"])},input_length:e=>{const{normalize:n}=e;return n(["Input length"])},output_dimension:e=>{const{normalize:n}=e;return n(["Output dimensions"])},token_length_explain:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["The maximum length of the input token sequence is ",r(o("_tokenLength"))," for this model."])},output_dim_explain:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["The output dimension of an embedding vector from this model is ",r(o("_outputDim")),"."])},size_explain:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["The number of parameters in the model is ",r(o("_size")),", note that this is not the size of the model file."])},language_explain:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["This model best supports ",r(o("_language"))," language."])},opensource:e=>{const{normalize:n}=e;return n(["OSS"])},opensource_explain:e=>{const{normalize:n}=e;return n(["This model is open source and available on Hugging Face. Click this button to view the model on Hugging Face."])},wait_for_processing:e=>{const{normalize:n}=e;return n(["Your request is being processed."])},you_can_leave:e=>{const{normalize:n}=e;return n(["You can leave this page and we will send you the download link upon completion."])},click_upload_btn_above:e=>{const{normalize:n}=e;return n(["Click the upload button above to start."])},start_batch:e=>{const{normalize:n}=e;return n(["Start batch embedding"])},visualization_example_you_can:e=>{const{normalize:n}=e;return n(["Use our API below, you can do it too!"])},start_embedding:e=>{const{normalize:n}=e;return n(["Index"])},maximize_tooltip:e=>{const{normalize:n}=e;return n(["Maximize this panel"])},show_api_key:e=>{const{normalize:n}=e;return n(["Show API Key"])},batch_job:e=>{const{normalize:n}=e;return n(["Batch Job"])},bulk_embedding_failed:e=>{const{normalize:n}=e;return n(["Fail to create batch embedding job"])},search:e=>{const{normalize:n}=e;return n(["Search"])},visualize:e=>{const{normalize:n}=e;return n(["Visualize"])},bulk:e=>{const{normalize:n}=e;return n(["Batch embed"])},what_are_embedding:e=>{const{normalize:n}=e;return n(["What are Embeddings?"])},what_are_embedding_answer:e=>{const{normalize:n}=e;return n([`At the heart of modern natural language processing (NLP) lies a transformative technique known as text embeddings. Imagine the challenge of teaching a computer to grasp the nuanced meanings of words and phrases. Traditional methods, which relied on rigid, rule-based systems, fell short because language is too complex and fluid. Enter text embeddings: a powerful solution that translates text into a language of numbers\u2014specifically, into vectors in a high-dimensional space.

Consider the phrases "sunny weather" and "clear skies." To us, they paint a similar picture. Through the lens of embeddings, these phrases are transformed into numerical vectors that reside close to each other in this multi-dimensional space, capturing their semantic kinship. This closeness in the vector space is not just about words or phrases being similar; it's about understanding context, sentiment, and even subtle nuances in meaning.

Why is this breakthrough important? For starters, it bridges the gap between the richness of human language and the computational efficiency of algorithms. Algorithms excel at crunching numbers, not interpreting texts. By converting text into vectors, embeddings make it possible for these algorithms to 'understand' and process language in a way that was previously out of reach.

The practical applications are vast and varied. Whether it's recommending content that resonates with your interests, powering conversational AI that feels surprisingly human, or even detecting subtle patterns in large volumes of text, embeddings are the key. They enable machines to perform tasks like sentiment analysis, language translation, and much more, with an understanding of language that is increasingly nuanced and refined.`])},open_tensorboard:e=>{const{normalize:n}=e;return n(["Open visualizer"])},visualization_example:e=>{const{normalize:n}=e;return n(["Embedding all sentences from this section to a 3D vector space"])},visualize_done:e=>{const{normalize:n}=e;return n(["Visualization is done, you can now click the top button to open the visualizer."])},more_than_two2:e=>{const{normalize:n}=e;return n(["Please enter more than two documents, i.e. more than two lines."])},generating_visualization:e=>{const{normalize:n}=e;return n(["Generating visualization..."])},query:e=>{const{normalize:n}=e;return n(["Query"])},document:e=>{const{normalize:n}=e;return n(["Document"])},pairwise_test:e=>{const{normalize:n}=e;return n(["Pairwise"])},search_hint:e=>{const{normalize:n}=e;return n(["Type to search within the documents listed below"])},original_documents:e=>{const{normalize:n}=e;return n(["Documents to embed"])},total_documents:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["Embedding progress: ",r(o("_Processed")),"/",r(o("_Count"))," documents."])},embedding_done:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["Successfully embedded ",r(o("_Count"))," documents."])},please_fill_docs_first:e=>{const{normalize:n}=e;return n(["Please first enter some documents below before search."])},original_documents_hint:e=>{const{normalize:n}=e;return n(["Enter your documents here. Each new line will be considered a separate document."])},upload_file:e=>{const{normalize:n}=e;return n(["Click here to upload a file"])},max_file_size:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["Maximum size allowed: ",r(o("_maxSize")),"."])},write_email_here:e=>{const{normalize:n}=e;return n(["Please enter the email where you want to receive the download link upon completion."])},upload:e=>{const{normalize:n}=e;return n(["Upload"])},download:e=>{const{normalize:n}=e;return n(["Download"])},batch_upload_hint:e=>{const{normalize:n}=e;return n(["We will use the API key and the model below to process the documents."])},autostart:e=>{const{normalize:n}=e;return n(["Embedding will automatically start after a brief delay"])},learn_more:e=>{const{normalize:n}=e;return n(["Learn more"])},why_do_you_need:e=>{const{normalize:n}=e;return n(["Choosing the Right Embeddings"])},why_do_you_need_before:e=>{const{normalize:n}=e;return n(["Our embedding models are specifically designed to cater to diverse applications, combining language, code and multimodal representation to open up new possibilities in AI-driven solutions."])},why_do_you_need_after:e=>{const{normalize:n}=e;return n(["Leveraging deep neural networks and LLMs, our embedding models represent multimodal data into a streamlined format, improving machine comprehension, efficient storage and enabling advanced AI applications. These embeddings play a crucial role in understanding the data, enhancing user engagement, overcoming language barriers, and optimizing development processes."])},why_need_1_title:e=>{const{normalize:n}=e;return n(["General-Purpose Embeddings"])},why_need_1_description:e=>{const{normalize:n}=e;return n(["Our core embedding model, powered by JinaBERT, is built for a broad spectrum of applications. It excels in understanding detailed text, making it ideal for semantic search, content classification, and intricate language analysis. Its versatility is unmatched, supporting the creation of advanced sentiment analysis tools, text summarization, and personalized recommendation systems."])},why_need_2_title:e=>{const{normalize:n}=e;return n(["Bilingual Embeddings"])},why_need_2_description:e=>{const{normalize:n}=e;return n(["Our bilingual models facilitate communication across languages, enhancing multilingual platforms, global customer support, and cross-lingual content discovery. Designed to master German-English and Chinese-English translations, these models simplify interactions and foster understanding among diverse linguistic groups."])},why_need_3_title:e=>{const{normalize:n}=e;return n(["Code Embeddings"])},why_need_3_description:e=>{const{normalize:n}=e;return n(["Tailored for developers, our code embedding model optimizes coding tasks like summarization, code generation, and automatic reviews. It boosts productivity by offering deeper insights into code structures and suggesting improvements, making it essential for developing advanced IDE plugins, automatic documentation, and cutting-edge debugging tools."])},top_up_warning_message:e=>{const{normalize:n,interpolate:r,named:o}=e;return n(["The current API key has ",r(o("_remainedTokens"))," tokens remaining and will be replaced by a new key with ",r(o("_freeTokens"))," tokens. You may continue to use or top up the old key if you have stored it securely. Do you wish to proceed?"])},top_up_warning_title:e=>{const{normalize:n}=e;return n(["Replace Old API Key"])},top_up_button:e=>{const{normalize:n}=e;return n(["Top Up Old Key"])},get_new_key_button:e=>{const{normalize:n}=e;return n(["Get New Key"])},cancel_button:e=>{const{normalize:n}=e;return n(["Cancel"])},"1M_free":e=>{const{normalize:n}=e;return n(["1M free tokens"])},"1M_free_description":e=>{const{normalize:n}=e;return n(["Receive 1 million free tokens with each new API key, no credit card needed. Suitable for both personal and commercial projects."])},protectData1:e=>{const{normalize:n}=e;return n(["Request data and documents are not used for training models."])},protectData2:e=>{const{normalize:n}=e;return n(["Data encryption in transit (TLS 1.2+) and at rest (AES-GCM 256)."])},protectData3:e=>{const{normalize:n}=e;return n(["SOC 2 and GDPR compliant."])},multilingual:e=>{const{normalize:n}=e;return n(["Multilingual support"])},protect_data:e=>{const{normalize:n}=e;return n(["Protect Your Data"])},feature_multilingual:e=>{const{normalize:n}=e;return n(["Offering bilingual models for German-English, Chinese-English, Spanish-English among others, ideal for cross-lingual applications."])},add_pair:e=>{const{normalize:n}=e;return n(["New"])},poster:e=>{const{normalize:n}=e;return n(["The Evolution of Embeddings Poster"])},poster_description:e=>{const{normalize:n}=e;return n(["Discover the ideal poster for your space, featuring captivating infographics or breathtaking visuals tracing the evolution of text embedding models since 1950."])},buy_poster:e=>{const{normalize:n}=e;return n(["Buy a hard copy"])},learn_poster:e=>{const{normalize:n}=e;return n(["Learn how we made it"])},delete_pair:e=>{const{normalize:n}=e;return n(["Delete"])},length:e=>{const{normalize:n}=e;return n(["Token length"])},debugging:e=>{const{normalize:n}=e;return n(["Test"])},text1:e=>{const{normalize:n}=e;return n(["Left"])},text2:e=>{const{normalize:n}=e;return n(["Right"])},new:e=>{const{normalize:n}=e;return n(["New model"])},edit_text1_text:e=>{const{normalize:n}=e;return n(["Edit left text"])},edit_text2_text:e=>{const{normalize:n}=e;return n(["Edit right text"])},no_data1:e=>{const{normalize:n}=e;return n(["Add a pair of sentences to calculate the similarity"])},cosine_similarity:e=>{const{normalize:n}=e;return n(["Cosine similarity"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:n}=e;return n(["Spanish-English bilingual embeddings with SOTA performance"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:n}=e;return n(["Optimized for code and docstring search"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:n}=e;return n(["Optimized for low latency and memory footprint"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:n}=e;return n(["On par with OpenAI's text-embedding-ada002"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:n}=e;return n(["Chinese-English bilingual embeddings with SOTA performance"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:n}=e;return n(["German-English bilingual embeddings with SOTA performance"])},learning1:e=>{const{normalize:n}=e;return n(["Learning about Embeddings"])},learning1_description:e=>{const{normalize:n}=e;return n(["Where to start with embeddings? We've got you covered. Learn about embeddings from the ground up with our comprehensive guide."])},feature_solid:e=>{const{normalize:n}=e;return n(["Best-in-class"])},feature_solid_description1:e=>{const{normalize:n}=e;return n(["Developed from our cutting-edge academic research and rigorously tested against the SOTA models to ensure unparalleled performance."])},feature_8k1:e=>{const{normalize:n}=e;return n(["8192 token-length"])},feature_8k_description1:e=>{const{normalize:n}=e;return n(["Pioneering the first open-source embedding model with an 8192-token length, enabling the representation of an entire chapter in a single vector."])},feature_top_perform1:e=>{const{normalize:n}=e;return n(["Seamless integration"])},feature_top_perform_description1:e=>{const{normalize:n}=e;return n(["Fully compatible with OpenAI's API. Effortlessly integrates with over 10 vector databases and RAG systems for a smooth user experience."])},feature_cheap:e=>{const{normalize:n}=e;return n(["50x cheaper"])},feature_cheap_v1:e=>{const{normalize:n}=e;return n(["5x more affordable"])},feature_cheap_v1_description1:e=>{const{normalize:n}=e;return n(["Start with free trials and enjoy a straightforward pricing structure. Get access to powerful embeddings for just 20% of OpenAI's cost."])},feature_on_premises:e=>{const{normalize:n}=e;return n(["Privacy first"])},feature_on_premises_description1:e=>{const{normalize:n}=e;return n(["Seamlessly deploy our embedding models directly within your Virtual Private Cloud (VPC). Currently supported on AWS Sagemaker, with forthcoming integrations for Microsoft Azure and Google Cloud Platform. For tailored Kubernetes deployments, reach out to our sales team for specialized assistance."])},feature_on_premises_description2:e=>{const{normalize:n}=e;return n(["Deploy Jina Embeddings models in AWS Sagemaker, and soon in Microsoft Azure and Google Cloud Services, or contact our sales team to get customized Kubernetes deployments for your Virtual Private Cloud and on-premises servers."])},vector_database_integration1:e=>{const{normalize:n}=e;return n(["Integrations"])},integrate:e=>{const{normalize:n}=e;return n(["Integrate"])},vector_database_integration_description:e=>{const{normalize:n}=e;return n(["Seamlessly and easily integrate the Jina Embeddings API with any of these databases, frameworks and applications below. Our tutorials will show you how."])},vector_database_integration2:e=>{const{normalize:n}=e;return n(["Our Embedding API is natively integrated with various renowned databases, vector stores, RAG, and LLMOps frameworks. To begin, just copy and paste your API key into any of the listed integrations for a quick and seamless start."])},api_integration_short:e=>{const{normalize:n}=e;return n(["Our Embedding API is natively integrated with various renowned databases, vector stores, RAG, and LLMOps frameworks."])},title:e=>{const{normalize:n}=e;return n(["Embedding API"])},description:e=>{const{normalize:n,linked:r,type:o}=e;return n([r("landing_page.embedding_desc1",void 0,o)])},key_enter_placeholder_to_topup:e=>{const{normalize:n}=e;return n(["Enter the API key you wish to recharge"])},key_to_top_up:e=>{const{normalize:n}=e;return n(["API key for recharge"])},key_enter_placeholder:e=>{const{normalize:n}=e;return n(["Please enter your API key"])},key_warn_v2:e=>{const{normalize:n}=e;return n(["Each new key has some free tokens for you to try out. You can top up your key at any time. Make sure to store your API key at a safe place!"])},key_warn:e=>{const{normalize:n}=e;return n(["Make sure to store your API key at a safe place. Otherwise you will need to generate a new key"])},refresh_key_tooltip:e=>{const{normalize:n}=e;return n(["Refresh and get a new API key"])},regenerate:e=>{const{normalize:n}=e;return n(["Regenerate"])},retry:e=>{const{normalize:n}=e;return n(["Retry"])},refresh:e=>{const{normalize:n}=e;return n(["Refresh"])},generate_api_key_error:e=>{const{normalize:n}=e;return n(["Fail to generate an API key"])},key:e=>{const{normalize:n}=e;return n(["API key"])},code:e=>{const{normalize:n}=e;return n(["code"])},manage_quota1:e=>{const{normalize:n}=e;return n(["Buy tokens"])},size:e=>{const{normalize:n}=e;return n(["Parameters"])},output_dim:e=>{const{normalize:n}=e;return n(["Dimensions"])},remaining:e=>{const{normalize:n}=e;return n(["Available tokens"])},usage:e=>{const{normalize:n}=e;return n(["Usage"])},api_integrations:e=>{const{normalize:n}=e;return n(["API Integrations"])},usage_history:e=>{const{normalize:n}=e;return n(["Usage history"])},view_details:e=>{const{normalize:n}=e;return n(["View Details"])},input_api_key_error1:e=>{const{normalize:n}=e;return n(["Your API key doesn't exist"])},usage_time:e=>{const{normalize:n}=e;return n(["Time"])},usage_amount:e=>{const{normalize:n}=e;return n(["Amount"])},usage_reason:e=>{const{normalize:n}=e;return n(["Reason"])},usage_reason_trial:e=>{const{normalize:n}=e;return n(["Trial"])},usage_reason_consume:e=>{const{normalize:n}=e;return n(["Consume"])},usage_reason_purchase:e=>{const{normalize:n}=e;return n(["Purchase"])},wait_stripe:e=>{const{normalize:n}=e;return n(["Opening Stripe payment, please wait"])},refresh_token_count1:e=>{const{normalize:n}=e;return n(["Refresh to get available tokens of current API key"])},what_is_a_token:e=>{const{normalize:n}=e;return n(['A token in text processing is a unit, often a word. For example, "Jina AI is great!" becomes five tokens, including the punctuation.'])},token_example:e=>{const{normalize:n}=e;return n([`A tweet is about 20 tokens, a news article is about 1000 tokens, and Charles Dickens' novel "A Tale of Two Cities" has over a million tokens.`])},buy_more_quota:e=>{const{normalize:n}=e;return n(["Top up this API key by selecting the tokens you need"])},tokens:e=>{const{normalize:n}=e;return n(["Tokens"])},"500M tokens":e=>{const{normalize:n}=e;return n(["500M tokens"])},"500M tokens_intuition1":e=>{const{normalize:n}=e;return n(["10 years of the NY Times every day, or reading In Search of Lost Time 300 times."])},"1B tokens":e=>{const{normalize:n}=e;return n(["1B tokens"])},"1B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Roughly 10,000 average novels, or rereading all the Harry Potter novels 1000 times."])},"2_5B tokens":e=>{const{normalize:n}=e;return n(["2.5B tokens"])},"2_5B tokens_intuition1":e=>{const{normalize:n}=e;return n(["All the words spoken in one day by 150,000 people, or 100 times the size of the US Code of Federal Regulations."])},"5_5B tokens":e=>{const{normalize:n}=e;return n(["5.5B tokens"])},"5_5B tokens_intuition1":e=>{const{normalize:n}=e;return n(["All the words ever published in the NY Times."])},"11B tokens":e=>{const{normalize:n}=e;return n(["11B tokens"])},"11B tokens_intuition1":e=>{const{normalize:n}=e;return n(["A bit more than the entire English Wikipedia."])},"59B tokens":e=>{const{normalize:n}=e;return n(["59B tokens"])},"59B tokens_intuition1":e=>{const{normalize:n}=e;return n(["All the tweets in the world for two days."])},per_k:e=>{const{normalize:n}=e;return n(["/ 1K tokens"])},per_m:e=>{const{normalize:n}=e;return n(["/ 1M tokens"])},faq:e=>{const{normalize:n,linked:r,type:o}=e;return n([r("contact_us_page.faq",void 0,o)])},faqs:{question1:e=>{const{normalize:n}=e;return n(["What distinguishes the Small model from the Base model?"])},answer1:e=>{const{normalize:n}=e;return n(["Both the Small and Base models are crafted utilizing the robust JinaBert architecture, differing primarily in their scale. The Small model comprises 33 million parameters, whereas the Base model comprises 137 million parameters. While the Base model delivers superior embedding performance, it incurs a minor trade-off in throughput (Queries per second), making the Small model a more agile option for certain use cases."])},question2:e=>{const{normalize:n}=e;return n(["What is the anticipated Queries Per Second (QPS) for both the Small and Base models?"])},answer2:e=>{const{normalize:n}=e;return n(["The QPS is contingent upon the length of the user-input sentences and the chosen model. For the Base model, the QPS can range from 4 to 100, while for the Small model, the range is between 10 to 300."])},question3:e=>{const{normalize:n}=e;return n(["Which languages are supported by your models?"])},answer3:e=>{const{normalize:n}=e;return n(["At present, our models exclusively support English. However, we are actively expanding our linguistic capabilities by training additional language-specific models. These forthcoming models are being designed to offer the same qualitative and quantitative advantages as the jina-embeddings-v2."])},question4:e=>{const{normalize:n}=e;return n(["What is the maximum number of characters I can input in a single sentence?"])},answer4:e=>{const{normalize:n}=e;return n(["Our models are highly capable, allowing for an input length of 8192 tokens, which is significantly longer than what most other models offer. A token can be as short as one character or as long as one word (e.g., 'a' or 'apple'). The number of characters you can input into a sentence depends on the length and complexity of the words used. This extended input length of jina-embedddings-v2 models enables more comprehensive text analysis and higher accuracy in understanding the context, especially in scenarios dealing with extensive textual data."])},question5:e=>{const{normalize:n}=e;return n(["What is the maximum number of sentences I can include in a single request?"])},answer5:e=>{const{normalize:n}=e;return n(["A single API call can accommodate up to 2048 sentences or texts, allowing for extensive text analysis in one go."])},question6:e=>{const{normalize:n}=e;return n(["On what basis is the Base model characterized as state-of-the-art?"])},answer6:e=>{const{normalize:n}=e;return n(["Our assertion stems from rigorous assessments conducted under the open-source evaluation framework, Massive Text Embedding Benchmark (MTEB). Our Base model has achieved an average rank of 17th on this leaderboard, with particularly impressive performance in core tasks like classification, summarization, and text-similarity. Notably, it stands out as the sole open-source model that supports an extensive 8192 token input context length, a sign of state-of-the-art performance."])},question7:e=>{const{normalize:n}=e;return n(["How do Jina Embeddings models compare to OpenAI's text-embedding-ada002 model?"])},answer7:e=>{const{normalize:n}=e;return n(["According to the MTEB Leaderboard, our Base model holds its ground against OpenAI\u2019s text-embedding-ada-002, showcasing comparable performance on average (ranking 17th versus 15th). Moreover, our Base model surpasses OpenAI\u2019s offering in several tasks including classification, pair-classification, re-ranking, and summarization."])},question8:e=>{const{normalize:n}=e;return n(["I am currently utilizing OpenAI's text-embedding-ada-002. How seamless is the transition to your solution?"])},answer8:e=>{const{normalize:n}=e;return n(["Transitioning is made effortless as our API endpoint, https://api.jina.ai/v1/embeddings, aligns perfectly with the input and output JSON schemas of OpenAI\u2019s endpoint for the text-embeddings-ada-002 model. This compatibility allows users to integrate our model as a direct drop-in replacement for text-embeddings-ada-002 when utilizing OpenAI\u2019s endpoint."])},question9:e=>{const{normalize:n}=e;return n(["Is the billing based on the number of sentences or requests?"])},answer9:e=>{const{normalize:n}=e;return n(["Our billing model is based on the total number of tokens processed. Users have the flexibility to distribute these tokens across as many sentences as they desire, providing a cost-effective and adaptable solution for varying text analysis needs."])},question10:e=>{const{normalize:n}=e;return n(["Is there a free trial available for new users?"])},answer10:e=>{const{normalize:n}=e;return n(["Yes, we welcome new users by offering a complimentary trial for embedding up to 10,000 tokens using any of our models. An auto-generated API key facilitates this trial. Upon exhaustion of the free token limit, users can effortlessly purchase top-ups for their existing API keys via the designated 'Top-Up' tab."])},question11:e=>{const{normalize:n}=e;return n(["Do API keys have an expiration date?"])},answer11:e=>{const{normalize:n}=e;return n(["No, our API keys do not have an expiration date."])},question12:e=>{const{normalize:n}=e;return n(["Is user input data utilized for training your models?"])},answer12:e=>{const{normalize:n}=e;return n(["No, we uphold a strict privacy policy and do not utilize user input data for training our models."])},question13:e=>{const{normalize:n}=e;return n(["Are tokens charged for failed requests?"])},answer13:e=>{const{normalize:n}=e;return n(["No, tokens are not charged in the event of failed requests."])},question14:e=>{const{normalize:n}=e;return n(["What payment methods are accepted?"])},answer14:e=>{const{normalize:n}=e;return n(["We have partnered with Stripe to facilitate a smooth payment process. Through this platform, we accept various payment methods including credit cards, Google Pay, and PayPal for your convenience."])},question15:e=>{const{normalize:n}=e;return n(["Is invoicing available for token purchases?"])},answer15:e=>{const{normalize:n}=e;return n(["Yes, upon purchasing tokens, an invoice will be sent to the email address associated with your Stripe account."])},question16:e=>{const{normalize:n}=e;return n(["What should I do if I forget my API key?"])},answer16:e=>{const{normalize:n}=e;return n(["For free quota usage, you can easily generate a new API key on https://jina.ai/embeddings. If your key has been topped-up, please reach out to support AT jina.ai using your registered email for assistance."])},question17:e=>{const{normalize:n}=e;return n(["Do you provide models for embedding images or audio?"])},answer17:e=>{const{normalize:n}=e;return n(["We are actively working on multimodal models that will cater to text, images, and audio embedding. Stay tuned for these updates!"])},question18:e=>{const{normalize:n}=e;return n(["Is there an option to fine-tune Jina Embedding models using private or company data?"])},answer18:e=>{const{normalize:n}=e;return n(["While we currently do not offer fine-tuning services, we are gearing up to introduce this feature soon. Keep an eye out for this feature!"])},question19:e=>{const{normalize:n}=e;return n(["Can your endpoints be hosted privately on AWS, Azure, or GCP marketplaces?"])},answer19:e=>{const{normalize:n}=e;return n(["AWS SageMaker is available now. Soon, jina-embeddings-v2 model packages will be accessible through all major cloud service providers' platforms."])},question20:e=>{const{normalize:n}=e;return n(["How were the jina-embeddings-v2 models trained?"])},answer20:e=>{const{normalize:n}=e;return n(["For an in-depth understanding of our training methodology, data, and evaluations, we invite you to explore our technical report available on arXiv."])},question21:e=>{const{normalize:n}=e;return n(["How many API requests can I make every second?"])},answer21:e=>{const{normalize:n}=e;return n(["Each user can make up to 100 requests per second, allowing to input 204,800 input sentences per second."])}}}};export{t as default};
