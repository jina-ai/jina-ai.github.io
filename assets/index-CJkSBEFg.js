const e="我们提供一流的向量模型、重排器、LLM 读取器和提示词优化器，为多模态数据赋能最先进的搜索 AI。",n="您的搜索，从此起飞。",t={approach:"我们的策略",approach_connect_dots:"绘图连线：从高级用户至企业用户",approach_connect_dots_description:"为何我们如此重视高级用户在整体策略中的地位？这是一个提前布局的考量。今日之投资，为了明日他们在企业中的影响力。这是我们的远见卓识，确保当这些高级用户掌握企业的话语权时，我们仍为他们心之所向。",approach_content1:"在人工智能的风云变幻中，策略必须灵活应变，洞察未来。尽管 Jina AI 以企业为核心，但AI的舞台已演变，吸引客户的策略亦当与时俱进。因此，以高级用户为突破口，不仅是我们的策略创新，更体现了我们对企业发展的坚韧不拔。",approach_content2:"在 Jina AI，我们不甘于守成，而是勇于开创。以高级用户为先导，确保我们把握当下，预见未来。对于企业，我们的决心坚如磐石；但在通向成功的路上，我们走的是一条既稳健又前瞻的新路。",approach_content4:'每个人都希望获得更好的搜索体验。在 Jina AI，我们通过提供 <span class="text-primary text-bold">搜索底座</span>（由向量模型、重排器、读取器 和 提示词工程组成）来实现更好的搜索体验。这些组件协同工作，彻底改变了我们搜索和理解数据的方式。',approach_miss_mark:"传统MLOps的短板",approach_miss_mark_description:"尽管高级用户日益壮大，但传统的MLOps工具往往步履蹒跚，难以满足他们的需求。它们宛如过时的老马，难以应对新时代的快节奏竞赛。新一代的开发者饥渴地寻求更为轻巧、直观的武器。",approach_new_paradigm:"提示词工程：AI开发之新潮",approach_new_paradigm_description:"2023年，AI世界迎来新篇章，提示词工程如日方升，实现了AI工具的大众化进程。即使是那些缺乏编程根基的高级用户，也能游刃有余地涉猎AI，无需再对如Pytorch、Docker或Kubernetes等深感畏难。此情此景，与个人计算的崛起历程颇为相似。当年，仅有的技术精英才可与计算机沟通，但随着更为亲和的界面的问世，大众也得以加入其行列。今日，随着提示词工程的普及，我们正在目睹AI领域的新一轮普及浪潮。",awards:"奖项与殊荣",berlin:"德国柏林",berlin_address:"Prinzessinnenstraße 19-20，10969 柏林，德国",berlin_address2:"工商注册地址: Leipzigerstr. 96, 10117 柏林, 德国",bj:"中国北京",bj_address:"中国北京市海淀区西大街48号6号楼5层",brochure_info:"我们公司的指南等待您的光临",description:"未来从这里开始。",download_brochure1:"下载手册",download_docarray_logo:"下载 DocArray的Logo",download_docarray_logo_desc:"获取 DocArray 徽标，这是一个由 Jina AI 发起的开源项目，并于 2022 年 12 月捐赠给了 Linux 基金会。提供浅色和深色模式、PNG 和 SVG 格式。",download_jina_logo:"下载Jina AI的Logo",download_jina_logo_desc:"获取浅色和深色模式下的 Jina AI 徽标，提供 PNG 和 SVG 格式。该标志是欧盟知识产权局（EUIPO）的注册商标。",download_logo:"下载Logo",employees:"当今员工",empower_developers:"开发者生态",fastApiCaption:"自 2021 年以来捐款超过 20,000 美元。",founded:"成立年份",founded_in:"成立于",investors:"我们的投资方",linuxFoundationCaption:"从 2022 年开始，每年捐款 10,000 美元。",many:"许多",media:{video:"视频采访"},mission:"我们的使命",mission_content1:"我们的关键技术包括快速调优、快速服务、模型调优和模型服务，体现了我们致力于使人工智能普及的承诺。通过我们的开源计划，我们努力促进创新、协作和透明度，确保提供可扩展、高效和强大的解决方案。Jina AI 不仅仅是一家公司；它是一个致力于帮助企业应对数字时代的动态挑战并在其领域蓬勃发展的社区。",mission_content2:"Jina AI 的核心理念在于我们的使命：成为从高级用户、开发者至各大企业的多模态 AI 通道。我们深信开源的魔力，并致力于为 AI 社区构建前沿且易于接入的工具。我们的关键技术，诸如提示词微调、模型向量调优部署等，展现了我们对 AI 普及的坚定信仰。借助我们的开源方案，我们旨在推动创新、合作与透明度，确保我们的方案既可扩展、高效又强大。Jina AI 不只是一个公司，它更是一个助企业应对数字化时代挑战并在其领域中持续领先的共同体。",mission_content3:"在 Jina AI，我们的使命是通过创新的向量模型和基于提示的技术，引领多模态AI的发展。我们特别关注自然语言处理、图像与视频分析以及跨模态数据交互等领域。我们的专业化致力于提供独特的解决方案，能够将复杂的多源数据转化为具有实际操作价值的洞察和创新应用。",mit_report_title:"多模态：人工智能的新前沿",mit_techreview:"麻省理工科技评论",numfocusCaption:"从 2022 年开始每月定期捐款。",office:"我们的办公室",otherProjectsCaption:"通过 Github 赞助捐赠了超过 3,000 美元。",our_answer:"不能同意更多，Yann。我们正在努力搭建通向多模态AI未来的桥梁！",pythonSoftwareFoundationCaption:"一次性捐赠 10,000 美元，并赞助了多项 PyCon 活动，包括德国、意大利、中国和美国的活动。",sefo:{layer0:"面向用户的应用",layer1:"RAG/编排系统",layer3:"GPU/移动/边缘/本地计算"},segmentFaultCaption:"一次性捐款 6,000 美元。",show_position:"搜索底座在生态系统中的定位？",stats_1:"Jina AI 于 2020 年 2 月成立，短短 20 个月，已成为多模态AI技术的翘楚。这段时间里，我们成功筹集了 3750 万美元，确立了在 AI 行业的领军地位。在 GitHub 上，我们的革命性开源技术赋能超过 40,000 名开发者，使他们得以毫无障碍地构建与部署多模态应用。",stats_2:"到了 2023 年，我们在基于多模态技术的 AI 工具方面取得了跨越式的突破。这一创新已让超过 250,000 名用户受益，满足了各式各样的业务需求。无论是推动业务增长、提升运营效率还是优化成本，Jina AI 都致力于助力企业在多模态时代锐意进取。",stats_4:'Jina AI 成立于 2020 年，是一家领先的搜索 AI 公司。我们的 <span class="text-primary text-bold">搜索底座</span> 平台包含了向量模型、重排器和小语言模型，可帮助企业构建可靠且高质量的生成式AI和多模态的搜索应用。',stats_v1:"当搜索与加速主义碰撞",subtitle:"通过人工智能生成的解决方案彻底改变内容创建，释放无限可能性。塑造人工智能生成内容的未来并增强人类创造力。",sues_und_sauer:"酸甜苦辣",sues_und_sauer_tooltip:"Süß-Sauer 是德式中餐中一种流行的口味（地道的中餐里这种口味并不常见，属于德国人对中餐的刻板印象），意思是酸甜口。它隐喻着创业生涯的起起落落。",sunnyvale_address:"710 Lakeway Dr, Ste 200, 桑尼维尔, CA 94085, 美国",sz:"中国深圳",sz_address:"中国深圳市福安科技大厦4楼402",team:"我们的团队",team_content1:"我们从全球各个角落构建 AI 的未来。我们独特的视角丰富了我们的工作，激发了创新。在这个门户网站中，我们拥抱个性，热情追求梦想。欢迎来到 AI 未来的门户网站。",team_join:"加入我们",team_size:"这些照片包括我们以前的同事和实习生——我们感谢他们每一个人。",technologies:"核心技术",title:"关于极纳科技",title0:"未来",title1:"起源",title2:"于此",title3:"始于斯",understand_our_strength:"了解我们的强项",understand_our_view2:"了解搜索底座",users:"注册用户",value:"我们的奖项",value_content1:"我们不会安于现状。我们不会妥协。我们追求卓越。",vision:"我们的任务",vision_content1:"启发于 Yann LeCun 对于AI的观点，“",vision_content3:'AI 的未来是<span class="text-primary text-bold">多模态</span>，而我们是其中的一部分。我们意识到企业在利用多模态数据方面面临挑战。为此，我们致力于<span class="text-primary text-bold">搜索底座</span>，以帮助企业和开发者更好地进行搜索，并利用多模态数据促进业务增长。',yannlecun_quote:"仅靠单词和句子训练的人工智能系统永远无法接近人类的理解力。"},i={answer1:"是的，同一个 API 密钥适用于 Jina AI 的所有搜索底座产品。这包括向量、重新排名、读取器和微调 API，所有服务之间共享词元。",answer12:"我们遵守严格的隐私政策，不使用用户输入数据来训练我们的模型。",answer3:"是的，可以通过输入 API 密钥在“购买词元”选项卡中监控词元使用情况，从而查看使用历史记录和剩余词元。",answer4:"如果您丢失了充值秘钥并希望取回它，请使用您的注册电子邮件联系支持人员寻求帮助。",answer5:"不，我们的 API 密钥没有过期日期。但是，如果您怀疑您的密钥已被泄露并希望废弃它或将其词元转移到新密钥，请联系我们的支持团队寻求帮助。",answer6:"这是因为我们的无服务器架构在低使用率期间卸载了某些模型。初始请求会激活或“预热”模型，这可能需要几秒钟的时间。初始激活后，后续请求的处理速度会更快。",question1:"我可以使用相同的 API 密钥进行向量、重新排名、读取器和微调 API 吗？",question12:"用户输入数据是否用于训练您的模型？",question3:"我可以查看 API 密钥的词元使用情况吗？",question4:"如果我忘记了 API 密钥，该怎么办？",question5:"API 密钥会过期吗？",question6:"为什么某些模型的第一次请求很慢？",title:"API相关常见问题"},a={base_model:"微调底座模型",check_data:"下载合成数据",check_model:"下载微调模型",data_size:"生成合成数据",description:"获取您想要的任何域的微调向量模型。",description_long:"只需告诉我们您希望向量模型在哪个领域中表现出色，我们就会自动为该领域提供一个可立即使用的、经过微调的向量模型模型。",does_it_work_tho:"但它真的有效吗？",does_it_work_tho_explain:"自动微调具有神奇的自动效果，可以为您想要的任何域提供微调的向量。但它真的有效吗？这是一个相当合理的疑问。我们在各种领域和底座模型上对其进行了测试以找出答案。查看下面的精选和精选结果。",domain_instruction:"领域指令",embedding_provider:"选择基础向量模型",eval_evaluation:"验证",eval_map:"地图",eval_mrr:"月平均收入",eval_ndcg:"神经胶质细胞癌",eval_performance_before_after:"微调前后合成验证集上的表现",eval_syntheticDataSize:"全部的",eval_test:"真实数据测试",eval_training:"训练",faq_v1:{answer1:"此功能目前处于测试阶段，每个微调模型需要花费 100 万个词元。如果 Embedding/Reranker API 中有足够的词元，您可以使用现有的 API 密钥，也可以创建一个新的 API 密钥，其中包含 100 万个免费词元。",answer10:"目前没有。请注意，此功能仍处于测试阶段。将微调后的模型和合成数据公开存储在 Hugging Face 模型中心有助于我们和社区评估训练的质量。未来，我们计划提供私人存储选项。",answer11:"由于所有微调模型都已上传至 Hugging Face，因此您只需指定模型名称即可通过 SentenceTransformers 访问它们。",answer12:"请检查您的垃圾邮件文件夹。如果仍然找不到，请使用您提供的电子邮件地址联系我们的支持团队。",answer2:"您无需提供任何训练数据。只需用自然语言描述您的目标域（您希望优化微调向量模型的域），或使用 URL 作为参考，我们的系统就会生成合成数据来训练模型。",answer3:"大约 30 分钟。",answer4:"经过微调的模型和合成数据公开存储在 Hugging Face 模型中心。",answer5:"系统使用 Reader API 从 URL 中获取内容。然后分析内容以总结语气和领域，并以此作为生成合成数据的指导方针。因此，URL 应该是公开可访问的，并且代表目标域。",answer6:"是的，您可以针对非英语语言微调模型。系统会自动检测域指令的语言并相应地生成合成数据。我们还建议为目标语言选择合适的底座模型。例如，如果针对德语域，则应选择“jina-embeddings-v2-base-de”作为底座模型。",answer7:"不，我们的微调 API 仅支持 Jina v2 模型。",answer8:"在微调过程结束时，系统会使用保留的测试集评估模型并报告性能指标。您将收到一封电子邮件，详细说明此测试集的前后性能。我们还鼓励您在自己的测试集上评估模型以确保其质量。",answer9:"该系统通过将您提供的目标域指令与 LLM 智能体的推理相结合来生成合成数据。它会产生具有挑战的三元组，这对于训练高质量的向量模型模型至关重要。有关更多详细信息，请参阅我们即将在 Arxiv 上发表的研究论文。",question1:"微调 API 的费用是多少？",question10:"我可以对我的微调模型和合成数据保持私密吗？",question11:"如何使用微调模型？",question12:"我从未收到包含评估结果的电子邮件。我该怎么办？",question2:"我需要输入什么？我需要提供训练数据吗？",question3:"微调一个模型需要多长时间？",question4:"微调后的模型存储在哪里？",question5:"如果我提供一个参考 URL，系统将如何使用它？",question6:"我可以针对特定语言微调模型吗？",question7:"我可以微调非 Jina 向量模型吗，例如 bge-M3？",question8:"如何保证微调模型的质量？",question9:"如何生成合成数据？",title:"自微调相关常见问题"},find_on_hf:"列出微调模型",temporarily_unavailable:"暂时不可用。我们正在升级自动微调系统，以便为您提供更好的服务。请稍后再查看。",test_on:"已对来自 {_dataName} 的 {_dataSize} 个随机样本进行测试",test_performance_before_after:"微调前后在保留测试集上的表现",title:"自微调 API",total_improve:"平均改善",usage:"用法",what_is:"什么是自微调？",what_is_answer_long:"微调允许您采用预先训练的模型，并通过在新的数据集上进行训练来使其适应特定任务或领域。实际上，对于许多用户来说，找到有效的训练数据并不是一件容易的事。有效的训练不仅仅需要将原始 PDF、HTML 放入模型中；而且很难做到正确。自微调通过使用高级 LLM 智能体管道自动生成有效的训练数据来解决此问题；并在 ML 工作流中微调模型。您可以将其视为合成数据生成和 AutoML 的组合，因此您需要做的就是用自然语言描述您的目标域，然后让我们的系统完成剩下的工作。"},_={description:"从文章直接生成插图，无需提示词",example_description:"爱丽丝开始厌倦了坐在岸边姐姐身边，无所事事：有一两次她偷看了姐姐正在读的书，但里面没有图片或对话，“书有什么用，”爱丽丝想，“没有图片或对话？”于是，她正在心里思考（尽她所能，因为炎热的天气让她感到非常困倦和愚蠢），制作菊花链的乐趣是否值得费力起身去采摘雏菊，突然一只粉红色眼睛的白兔跑到她身边。",example_title:"爱丽丝梦游仙境 - 第 1 章"},r="试用版",o={answer10:"我们为新用户提供免费试用，其中包括 100 万个词元，可通过自动生成的 API 密钥与我们的任何模型一起使用。一旦达到免费词元限制，用户可以通过“购买词元”选项卡轻松为其 API 密钥购买额外的词元。",answer13:"不，失败的请求不会扣除词元。",answer14:"付款通过 Stripe 处理，支持多种付款方式，包括信用卡、Google Pay 和 PayPal，为您提供方便。",answer15:"是的，购买词元后，发票将发送到与您的 Stripe 帐户关联的电子邮件地址。",answer9:"我们的定价模型基于处理的词元总数，允许用户灵活地在任意数量的句子中分配这些词元，为不同的文本分析需求提供经济高效的解决方案。",question10:"新用户可以免费试用吗？",question13:"失败的请求是否会扣除词元？",question14:"接受哪些付款方式？",question15:"词元购买后可以开具发票吗？",question9:"API是根据句子的数量或请求的数量计费吗？",title:"与计费相关的常见问题"},s={all:"全部",events:"活动",featured:"甄选",insights:"观点","knowledge-base":"知识库",latest:"最新的",press:"新闻稿",releases:"软件更新","tech-blog":"技术文章"},c={api_free_trial:"免费 API 密钥",api_paid:"付费 API 密钥",api_paid_or_free:"您使用的是付费 API 密钥还是免费试用密钥？",are_you:"你是：",commercial_contact_sales:"此为商业性质。请联系我们的销售团队。",contact_sales_for_licensing:"联系我们的销售团队获取许可。",csp_user:"您是否在 AWS 和 Azure 上使用我们的官方模型？",educational_teaching:"教育机构用它来教学吗？",for_profit_internal_use:"盈利性公司在内部使用它吗？",free_use:"您可以自由使用这些模型。",government_public_services:"政府实体使用它来提供公共服务？",is_use_commercial:"您的用途是商业用途吗？",may_be_commercial_contact:"这可能是商业用途。请联系我们进行澄清。",no:"不",no1:"不",no2:"不",no3:"不",no_restrictions:"无限制。请按照当前协议使用。",no_restrictions_apply:"沒有限制。",non_commercial_free_use:"本模型非商业性质，您可以自由使用。",non_profit_ngo_mission:"非营利组织或非政府组织是否利用它来完成你的使命？",not_sure:"没有把握",personal_hobby_projects:"将其用于个人项目或者业余爱好项目？",product_service_sale:"在您销售的产品或服务中使用它吗？",title:"CC BY-NC 许可证自检",trial_key_restrictions:"免费试用密钥仅可用于非商业用途。如需商业用途，请购买付费套餐。",typically_non_commercial_check:"这通常是非商业性的，但如果不确定，请与我们联系。",typically_non_commercial_free_use:"这通常是非商业性的。您可以自由使用这些模型。",using_api_or_cloud:"您是否使用我们的官方 API 或在 Azure 或 AWS 上我们的官方镜像？",using_cc_by_nc_models:"你正在使用这些模型吗？",yes:"是的",yes1:"是的",yes2:"是的",yes3:"是的"},d={access:"公共访问",access_explain:"任何拥有 <code>classifier_id</code> 的人都可以使用公共分类器，并且它们的使用将消耗调用者的词元配额，而不是您的。私有分类器只能由您访问。",access_private:"私人的",access_public:"民众",api_delete:"删除分类器",api_delete_explain:"根据分类器ID删除分类器。",api_list:"列表分类器",api_list_explain:"列出您已创建的所有分类器。",classifier_id:"分类器 ID",classify_inputs:"要分类的输入",classify_inputs_explain:"对于文本，它可以是最多 8192 个词元的句子。对于图像，它可以是 URL 或 base64 编码的图像。",classify_labels:"候选标注",classify_labels_explain:"输入将被归类到这些类别中。最多可以有 256 个类别。使用带语义类别可获得更好的性能。",compare_table:{access_control:"访问控制",classifier_id_required:"必需分类器 ID",continuous_updates:"持续模型更新",default_solution:"一般分类问题的默认解决方案",feature:"特点",few_shot:"少量样本",image_multi_lingual_support:"多模态和多语言支持",labels_required_classify:"/classify 中需要的标注",labels_required_train:"/train 中需要的标注",max_classes:"最大类数",max_classifiers:"最大分类器",max_inputs_request:"每个请求的最大输入",max_token_length:"每个输入的最大词元长度",na:"不适用",no:"不",out_of_domain_solution:"对于 v3/clip-v1 域之外的数据或时间敏感的数据",primary_use_case:"主要用例",semantic_labels_required:"需要语义标注",state_management:"状态管理",stateful:"有状态",stateless:"无状态",token_count:"{count} 个标记",training_data_required:"需要训练数据",yes:"是的",zero_shot:"零样本"},create_classifier:"新的少样本分类器",create_classifier_explain:"创建一个新的小样本分类器并使用标记示例对其进行训练。",description:"图像和文本的零样本和少样本分类。",description_long:"试用我们的 API 沙盒实验场来了解我们的分类器如何工作。",description_long1:"针对多模态和多语言数据的高性能零样本和少样本分类器。",explain:"分类器是一种 API 服务，它使用向量模型 (<code>jina-embeddings-v3</code> 和 <code>jina-clip-v1</code>) 对文本和图像进行分类，支持无需训练数据的零样本分类和使用最少示例的少样本学习。",faq_v1:{answer1:"零样本分类需要语义标签，训练时不需要，而少样本分类则需要训练时需要标签，但分类时不需要。这意味着零样本分类更适合灵活、即时的分类需求，而少样本分类更适合固定的、特定领域的类别，这些类别可以随时间而演变。",answer10:"是的，您可以选择 <code>jina-embeddings-v3</code> 进行文本分类（特别适合多语言）和 <code>jina-clip-v1</code> 进行多模态分类。新模型（如 <code>jina-clip-v2</code>）将在发布时通过 API 自动提供。",answer2:"<code>num_iters</code> 控制训练强度 - 较高的值会强化重要示例，而较低的值会最大限度地减少不太可靠数据的影响。它可用于通过为近期示例提供更高的迭代次数来实现时间感知学习，这使其对于不断发展的数据模式很有价值。",answer3:"任何拥有 <code>classifier_id</code> 的人都可以使用公共分类器，并消耗自己的词元配额。用户无法访问训练数据或配置，也无法查看其他人的分类请求，从而实现安全的分类器共享。",answer4:"少量样本需要 200-400 个训练样本才能超越零样本分类。虽然它最终会实现更高的准确率，但需要这段预热期才能发挥作用。零样本无需训练数据即可立即提供一致的性能。",answer5:"是的 - API 支持使用 <code>jina-embeddings-v3</code> 进行多语言查询和使用 <code>jina-clip-v1</code> 进行多模态（文本/图像）分类，并支持在同一请求中对 URL 或 base64 编码的图像进行支持。",answer6:"Zero-shot 支持 256 个类别，没有分类器限制，而 few-shot 则限制为 16 个类别和 16 个分类器。两者均支持每个请求 1,024 个输入和每个输入 8,192 个标记。",answer7:"少量样本模式允许通过 <code>/train</code> 端点进行持续更新，以适应不断变化的数据模式。当数据分布发生变化时，您可以逐步添加新的示例或类别，而无需重建整个分类器。",answer8:"该 API 使用一次性在线学习 - 训练示例会更新分类器权重，但之后不会存储。这意味着您无法检索历史训练数据，但它可以确保隐私和资源效率。",answer9:"当您需要使用语义标签进行灵活分类时，请从零样本开始，以获得即时结果。当您有 200-400 个示例、需要更高的准确度或需要处理特定领域/时间敏感的数据时，请切换到少样本。",question1:"零样本和小样本的标签有何不同？",question10:"我可以针对不同的语言/任务使用不同的模型吗？",question2:"num_iters 有什么用处以及如何使用它？",question3:"公共分类器共享如何工作？",question4:"我需要多少数据才能使小样本研究发挥良好作用？",question5:"它能处理多种语言和文本/图像吗？",question6:"我应该了解哪些硬性限制？",question7:"我该如何处理随时间而发生的数据变化？",question8:"我发送训练数据后会发生什么情况？",question9:"零样本与小样本——何时使用哪个？",title:"分类器相关常见问题"},more:"更多",num_iters:"训练迭代",num_iters_explain:"控制训练强度 - 较高的值可提高当前示例的准确性，但会增加词元成本。默认值 10 通常效果很好。",read_notes:"阅读发行说明",select_classifier_or_model:"选择分类器或向量模型",task_classify:"分类",task_classify_explain:"使用零样本或少样本分类器将文本或图像分类到定义的类别中。",task_manage:"管理",task_manage_explain:"列出或删除你的小样本分类器。",task_select:"选择任务",task_train:"训练",task_train_explain:"使用标记示例创建或更新少量分类器。",title:"分类器 API",train_inputs:"训练数据",train_inputs_explain:"用于训练的带有标签的文本或图像示例。您可以随着时间的推移使用新示例和标签逐步更新分类器。",train_label:"标签",what_is:"什么是分类器？",when_to_use_what:"何时使用零样本或小样本？",when_to_use_what_explain:"使用零样本分类作为默认解决方案，可以在最多 256 个类别的一般分类任务中获得即时结果，而少样本学习更适合处理向量模型知识之外的特定领域数据，或者需要处理需要持续模型更新的时间敏感数据。"},l={description:"使用 CLIP 将图像和文本向量到固定长度的向量中"},p={description:"多模态AI应用的云托管平台"},u={agreement:"提交即表示您确认同意 Jina AI 按照以下规定处理您的个人数据",anything_else:"告诉我们更多关于你的想法",cc_by_nc:"请求 CC BY-NC 模型的商业使用",cc_by_nc_description:"我们的最新模型通常采用 CC BY-NC 许可。如需商业使用，请通过我们的 API、Azure Marketplace 或 AWS SageMaker 访问它们。如需在这些渠道之外进行本地使用，请勾选此框。",company:"组织",company_size:"组织规模",company_website:"组织网站",company_website_placeholder:"您公司主页或 LinkedIn 个人资料的 URL",country:"国家",department:"部门",description:"与 Jina AI 一起拓展您的业务。",drop_area_for_image:"将图片拖放到此处",faq:"常问问题",feedback_sent:"已提交！我们将尽快回复您。",field_required:"字段为必填项",get_api_key:"如何获取我的 API 密钥？",image_upload:"附加图片",image_validate:"您最多可以附加 {_num} 张图片。仅限 JPG、JPEG、PNG、WEBP。",impact_snapshots:"实际案例",invalid_date_format:"日期格式无效。请使用 DD-MM-YYYY 格式。",invalid_email:"电子邮件无效",invalid_number:"无效数字。请再次输入",invalid_url:"网址无效",name:"姓名",nc_check:"我需要商业许可证吗？",other_questions:"其他问题",preferred_models:"您对哪些模型感兴趣？",preferred_products:"您对哪些产品感兴趣？",pricing:"定价？",priority:"优先支持付费用户",private_statement:"隐私声明",rate_limit:"速率限制是多少？",role:"职业角色",self_check:"自检",sending_feedback:"正在发送...",shortcut:"捷径",submit:"提交",submit_failed:"提交失败。请稍后再试。",submit_success:"感谢您提交。我们会尽快给您回复。",subtitle:"Jina AI 是多模态 AI 领域的领导者，擅长模型调优、模型服务、提示词调优部署。利用 Kubernetes 和无服务器架构等云原生技术，我们提供强大、可扩展且可立即投入生产的解决方案。凭借大语言模型、文本、图像、视频、音频理解、神经搜索和生成艺术方面的专业知识，我们提供创新、面向未来的策略来提升您的业务。",subtitle1:"Jina AI 是多模态 AI 领域的领导者，擅长大模型向量调优和部署、提示词调优和部署。利用 Kubernetes 和无服务器架构等云原生技术，我们提供强大、可扩展且可立即投入生产的解决方案。凭借大语言模型、文本、图像、视频、音频理解、神经搜索和生成式AI方面的专业知识，我们提供创新、面向未来的策略来提升您的业务。",subtitle2:"了解多模态AI最前沿的Jina AI。我们擅长向量化和提示词技术，利用 Kubernetes 等云原生解决方案来构建强大、可扩展的系统。我们专注于大型语言模型和媒体处理，利用先进的人工智能专业知识提供创新、面向未来的业务战略。",title:"联系销售",trusted_by:"我们值得信赖",turn_on_volume:"调高音量",work_email:"工作邮箱"},m="复制",g="已复制到剪贴板",A={description:"用于从文本创建高清图像的人机交互工作流程"},h={description:"用一行代码创建引人注目的 Disco Diffusion 艺术作品"},I={description:"多模态数据的数据结构"},b="下载 SOC 2 类型 1 证明",f={"11B tokens":"壹佰壹拾亿","11B tokens_intuition1":"类似于阅读维基百科上的所有英文文章。","11B tokens_targetUser":"生产部署","1B tokens":"拾亿","1B tokens_intuition1":"大概和读完莎士比亚全集和整个《哈利波特》系列是一样的。","1B tokens_targetUser":"原型开发","1M tokens":"壹佰万","1M tokens_intuition1":"相当于读完了《霍比特人》和《了不起的盖茨比》的全部文本。","1M tokens_targetUser":"玩具实验","1M_free":"免费百万词元随心用","1M_free_description":"使用免费词元享受您的新 API 密钥，无需信用卡。","2_5B tokens":"2.5B 词元","2_5B tokens_intuition1":"相当于把电影《指环王》三部曲里说的每一个字都抄录1000遍。","3p_integration":"拥有 <b>{_numPartners}</b> 家第三方服务","3p_integration_desc":"将我们的搜索底座与您现有的服务相集成。我们的合作伙伴已经打通了与我们 API 的连接，让您可以轻松地在应用程序中使用我们的模型。","500M tokens":"500M 词元","500M tokens_intuition1":"类似于观看《辛普森一家》从第 1 季到第 30 季的每一集。","59B tokens":"59B 词元","59B tokens_intuition1":"相当于两天内全球发布的所有推文。","5_5B tokens":"5.5B 词元","5_5B tokens_intuition1":"相当于阅读大英百科全书的全部内容。",Free1M:"100 万个词元",add_pair:"新建",add_time_explain:"此模型被添加到搜索底座的时间。",api_integration_short:"在流行数据库、向量数据库、RAG 和 LLMOps 框架轻松使用我们的向量模型API。",api_integrations:"API集成",api_key_update_message:"通过替换旧 API 密钥，新密钥将在您每次访问 jina.ai 时显示在 UI 中。未来的充值将适用于此新密钥。您的旧密钥仍然有效，因此如果您打算再次使用它，请安全保存。",api_key_update_title:"更换 API 密钥",auto_recharge:"当词元低时自动充值",auto_recharge_confirm_message:"您确定要禁用自动充值吗？这将阻止您词元余额不足时自动充值。",auto_recharge_confirm_title:"禁用自动充值",auto_recharge_description:"当您需要在生产环境中使用时开启此选项。这样当您的词元余额低于您设置的阈值时，我们将自动向您的信用卡充值与您上次充值相同的金额。如果您在上次充值中购买了多个词元包，我们将只向该API充值一个包。",auto_recharge_enable:"您已启用自动充值",auto_recharge_enable_message:"要启用自动充值，请在购买套餐时打开自动充值开关。",auto_recharge_enable_title:"启用自动充值",auto_request:"自动预览",auto_request_tooltip:"使用 API 密钥中的数百个词元，在更改模型时自动预览 API 响应。关闭后，单击“获取响应”即可手动发送请求。",autostart:"向量化将自动开始",base64_description:"向量以 base64 编码的字符串形式返回。传输效率更高。",batch_job:"批处理",batch_upload_hint:"我们将使用如下的 API 密钥和模型来批处理。","bge-base-en-v1_5_description":"一种强大的英语模型，平衡了性能和效率，适合多种用途。","bge-base-en_description":"平衡的英语模型，旨在实现可靠的性能。","bge-base-zh-v1_5_description":"全面平衡能力与效率的中国模式。","bge-base-zh_description":"集效率与强劲性能于一身的多功能中国车型。","bge-large-en-v1_5_description":"强大的英语模型，提供具有卓越品质的顶级向量。","bge-large-en_description":"专为优质向量而打造的顶级英语模型。","bge-large-zh-v1_5_description":"提供卓越且详细向量的高容量中文模型。","bge-large-zh_description":"针对顶级向量优化的高性能中文模型。","bge-m3_description":"一种多功能多语言模型，提供广泛的功能和高质量的向量。","bge-small-en-v1_5_description":"精简的英语模型，提供高效、高质量的向量。","bge-small-en_description":"一种高效的英语模型，用于简化和准确的向量。","bge-small-zh-v1_5_description":"紧凑的中国模型，提供灵活、精确的向量。","bge-small-zh_description":"一种敏捷的中国模型，用于高效、精确的向量。",binary_description:"向量被打包为 int8。存储、搜索和传输效率更高。",bulk:"批处理",bulk_embedding_failed:"创建批处理失败",buy_more_quota:"使用更多词元充值此 API 密钥",buy_poster:"购买海报",cancel_button:"取消",click_upload_btn_above:"单击上面的上传按钮即可开始。",clip_v2_description:"jina-clip-v2 是一个 0.9B CLIP 风格模型，它带来了三大进步：对 89 种语言的多语言支持、512x512 的高图像分辨率和用于截断向量的 Matryoshka 表示学习。",clip_v2_title:"clip-v2：多语言多模态向量",code:"代码",colbert_dimensions_explain:"每个标记向量的维度大小。",compatible:"兼容模式",compatible_explain:"遵循与我们的文本向量模型相同的请求格式。这允许您在不更改请求的情况下在模型之间切换。请注意，此模式下不支持图像输入。",cosine_similarity:"余弦相似度",debugging:"测试",delete_pair:"删除",description:"@:landing_page.embedding_desc1",dimensions:"输出维度",dimensions_error:"尺寸大小必须介于 1 到 1024 之间。",dimensions_explain:"较小的尺寸可以实现高效的存储和检索，并且由于采用了 Matryoshka 表示法，影响最小。",dimensions_warning:"为了提高性能，我们建议将尺寸大小保持在 {_minDimension} 以上。",document:"文档",download:"下载",edit_text1_text:"编辑左侧文字",edit_text2_text:"编辑右侧文字",embedding_done:"成功向量化{_Count}个句子。",embedding_none_description:"不要使用任何向量模型",example_inputs:"示例输入",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"有关我们的训练过程、数据源和评估的详细信息，请参阅 arXiv 上提供的技术报告。",answer1:"每个用户每秒最多可以发出 100 个请求，相当于每秒 204,800 个输入句子。",answer17:"我们目前正在开发多模态向量模型，将联合处理文本、图像和音频。更新内容将很快公布！",answer18:"有关使用特定数据微调我们的模型的疑问，请联系我们讨论您的要求。我们愿意探索如何调整我们的模型来满足您的需求。",answer19:"是的，我们的服务可在 AWS 市场上使用，并且我们正在扩展到 Azure 和 GCP 市场。如果您有特殊要求，请联系我们的销售人员 AT jina.ai。",answer3:"我们的模型支持英语、德语、西班牙语、中文和各种编程语言。欲了解更多详情，请参阅我们关于双语模型的论文。",answer4:"我们的模型允许输入长度高达 8192 个词元，这明显高于大多数其他模型。词元的范围可以从单个字符（如“a”）到整个单词（如“apple”）。可以输入的字符总数取决于所用单词的长度和复杂性。这种扩展的输入功能使我们的 jina-embeddings-v2 模型能够执行更全面的文本分析，并在上下文理解方面实现更高的准确性，特别是对于大量文本数据。",answer5:"一次 API 调用最多可以处理 2048 个句子或文本，从而有助于在一次请求中进行广泛的文本分析。",answer6:"您可以在 API 请求的 <code>input</code> 字段中使用 <code>url</code> 或 <code>bytes</code>。对于 <code>url</code>，请提供要处理的图像的 URL。对于 <code>bytes</code>，请以 base64 格式对图像进行编码并将其包含在请求中。模型将在响应中返回图像的向量。",answer7:"根据 MTEB 排行榜，我们的模型与 OpenAI 的 text-embedding-ada-002 密切竞争，表现出平均性能相当。此外，我们的模型在多项任务上表现出色，包括分类、配对分类、重排器和总结，优于 OpenAI 的模型。",answer8:"由于我们的 API 接口 https://api.jina.ai/v1/embeddings 与 OpenAI 的 text-embeddings-ada-002 模型的输入和输出 JSON 模式相匹配，因此转换得到了简化。这种兼容性确保用户在使用 OpenAI 的接口时可以轻松地将 OpenAI 模型替换为我们的模型。",answer9:`词元是根据文本长度和图像大小计算的。对于请求中的文本，词元以标准方式计算。对于请求中的图像，执行以下步骤：
1. 图块大小：每幅图像被分成大小为 224x224 像素的图块。
2. 覆盖率：计算完全覆盖输入图像所需的图块数量。即使图像尺寸不能被 224 完全整除，我们也会将部分图块算作完整图块。
3. 总图块数：覆盖图像的图块总数决定了成本。例如，如果图像为 500x500 像素，它将被 3x3 图块覆盖，从而产生 9 个图块。
4. 成本计算：每个图块都会影响处理图像的最终成本。每个图块的成本为 1000 个词元。

示例：
对于尺寸为 500x500 像素的图像：

• 图像被分成 224x224 像素的图块。
• 所需瓷砖总数为 3（水平）x 3（垂直）= 9 块瓷砖。
• 成本为 9*1000 = 9000 个词元`,question0:"jina-embeddings-v2 模型是如何训练的？",question1:"我每秒可以发出多少个 API 请求？",question17:"你们提供向量模型图像或音频的模型吗？",question18:"Jina 向量模型模型可以使用私人或公司数据进行微调吗？",question19:"您的接口可以私有托管在 AWS、Azure 或 GCP 上吗？",question3:"你们的模型支持哪些语言？",question4:"单个句子输入的最大长度是多少？",question5:"单个请求中最多可以包含多少个句子？",question6:"如何将图像发送到 jina-clip-v1 模型？",question7:"Jina Embeddings 模型与 OpenAI 的 text-embedding-ada-002 模型相比如何？",question8:"从 OpenAI 的 text-embedding-ada-002 到您的解决方案的迁移有多顺畅？",question9:"使用 jina-clip-v1 时如何计算词元？",title:"向量模型相关的常见问题"},feature_8k1:"8192长度",feature_8k_description1:"世界首发的 8192 个词元长度的开源向量模型，能够把一整版人民日报压缩成一个向量。",feature_cheap:"降本 50 倍",feature_cheap_v1:"5 倍降本",feature_cheap_v1_description1:"从免费试用开始，简单的定价结构，快捷支付。只需 OpenAI 20% 的成本即可获得强大的向量模型。",feature_multilingual:"提供德英、中英等双语模型，出海企业适合跨语言应用必备。",feature_on_premises:"隐私第一",feature_on_premises_description1:"直接在您的虚拟私有云 (VPC) 中无缝部署我们的向量模型。轻松在 AWS Sagemaker上部署，即将与微软Azure 和谷歌 Cloud Platform 集成。如需定制 Kubernetes 部署，请联系我们的销售团队寻求专业帮助。",feature_on_premises_description2:"您可以轻松在 AWS Sagemaker上部署我们的向量模型，我们很快将在微软Azure和谷歌Cloud Services中提供支持。如需定制 Kubernetes 部署，请联系我们的销售团队寻求专业帮助。",feature_on_premises_description3:"在 AWS Sagemaker 和 Microsoft Azure 中部署 Jina Embeddings 模型，并很快在 Google Cloud Services 中部署，或者联系我们的销售团队，为您的虚拟私有云和本地服务器获取定制的 Kubernetes 部署。",feature_on_premises_description4:"使用 AWS SageMaker、Microsoft Azure 或 Google Cloud Services 在本地部署 Jina Embedding 和 Reranker 模型，确保您的数据安全地处于您的控制之下。",feature_solid:"出类拔萃",feature_solid_description1:"基于我们实打实的AI科研工作，并与同类模型进行了严格对比测试，以确保模型的最佳性能。",feature_top_perform1:"无缝集成",feature_top_perform_description1:"与OpenAI的API完全兼容。轻松与 10 多个向量数据库和 RAG 系统集成，提供流畅的开发者体验。",file_required:"请上传文件",file_size_exceed:"文件大小超过上限 {_size}",file_type_not_supported:"文件类型不支持",fill_example:"填写示例",float_description:"向量以浮点数列表的形式返回。最常见且易于使用。",free:"自由的",generate_api_key_error:"API 密钥生成失败。",generating_visualization:"生成可视化...",get_new_key_button:"获取新密钥",get_new_key_button_explain:"选择新密钥将导致与旧密钥相关的使用历史记录丢失。",get_new_key_survey:"填写调查问卷，帮助我们了解您的使用情况，并免费获得新的 API 密钥！",includes:"购得词元可在以下产品中使用：",index_and_search:"先索引再查询",index_and_search1:"索引和搜索",input:"请求",input_api_key_error1:"您的 API 密钥无效！",input_length:"输入长度",input_type:"向量化文档/查询",input_type_explain:"根据搜索角色，相同的输入可以作为查询或文档向量。",integrate:"集成","jina-clip-v1_description":"图像和英文文本的多模态向量模型","jina-clip-v2_description":"文本和图像的多语言多模态向量模型","jina-colbert-v1-en_description":"改进版的ColBERT模型支持8K长度的上下文，可用于向量化和重排任务","jina-colbert-v2_description":"最新的多语言ColBERT，在向量化和重排方面具有顶级性能","jina-embeddings-v2-base-code_description":"针对代码和技术文档搜索的向量模型","jina-embeddings-v2-base-de_description":"支持德英双语的 8K 最佳向量模型","jina-embeddings-v2-base-en_description":"与 OpenAI 的 text-embedding-ada002旗鼓相当","jina-embeddings-v2-base-es_description":"支持西英双语的 8K 最佳向量模型","jina-embeddings-v2-base-zh_description":"支持中英双语的 8K 最佳向量模型","jina-embeddings-v2-small-en_description":"针对低延迟和小内存进行了优化","jina-embeddings-v3_description":"最新、最好的向量化模型，在文本和代码上均具有最佳性能","jina-reranker-v1-base-en_description":"我们的第一个重排器最大化搜索和 RAG 相关性","jina-reranker-v1-tiny-en_description":"最快的重排器，适合对大量文档进行可靠的排序","jina-reranker-v1-turbo-en_description":"速度与准确率的最佳权衡选择","jina-reranker-v2-base-multilingual_description":"最先进的多语言文档和查询重排器，具有最佳的准确性和速度性能",key:"API密钥",key_enter_placeholder:"请输入您的 API 密钥",key_enter_placeholder_to_topup:"输入您要充值的 API 密钥",key_to_top_up:"有其他 API 密钥需要充值？粘贴上述内容并点击“保存”。",key_warn:"请确保将您的 API 密钥存储在安全的地方。否则您将需要生成一个新密钥",key_warn_v2:"这是您的专属密钥。请安全保存！",language_explain:"该模型对{_language}语言有最好的支持。",last_7_days:"用法",late_chunking:"后期分块",late_chunking_explain:"应用后期分块技术来利用模型的长上下文功能来生成上下文块向量化。",learn_more:"了解更多",learn_poster:"了解海报",learning1:"学习向量模型",learning1_description:"什么是向量，为什么要向量化？我们已经为您提供了一些入门文章。通过我们的综合指南从头开始了解向量模型。",length:"长度",manage_billing:"管理发票",manage_billing_tip:"管理您的账单信息、获取发票并设置自动充值。",manage_quota1:"密钥和计费",max_file_size:"最大允许的尺寸：{_maxSize}。",maximize_tooltip:"使用 Shift+1 最大化此面板",mistake_contact:"如果您认为这是一个错误，请联系我们。",mminput_placeholder:"文本、图片URL、图片base64字符串",model_required:"请选择模型",more_models:"其他 {_numMore} 个模型",more_than_two2:"请输入两个以上的文档，即两行以上。",multi_embedding:"多载体",multi_embedding_explain:"该模型会给一个输入返回一组向量。输入句子中的每个词元都被映射到单独的一个向量。",multilingual:"多语言支持",multimodal:"多式联运",multimodal_explain:"该模型可以对文本和图像输入进行编码，使其成为多模态搜索任务的理想选择。",new:"新模型",no_data1:"添加一对句子来计算相似度",none:"没有任何",normalized:"L2 规范化",normalized_explain:"归一化向量，使其欧几里得 (L2) 范数变为 1，保持方向。当下游涉及点积、分类、可视化时很有用。",oncsp:"关于 CSP",onprem:"私有化部署",open_tensorboard:"打开可视化工具",opensource:"开源",opensource_explain:"该模型是开源的，可从 Hugging Face 下载使用。单击此按钮可查看 Hugging Face 上的模型。",original_documents:"向量化的句子",original_documents_hint:"在此处输入句子。每个新行将被视为一个单独的句子/文档。",output:"响应",output_dim:"输出维度",output_dim_explain:"该模型输出的向量维度为 {_outputDim}。",output_dimension:"输出维度",pairwise_test:"成对测试",per_k:"每千个词元",per_m:"每百万词元",please_fill_docs_first:"在搜索之前，请先在下面输入一些句子。",please_select_model:"请选择向量模型或重排器模型",poster:"向量模型70年",poster_description:"在您的办公空间或起居室内悬挂一张我们精心制作的海报，在1950年以来文本向量模型的进化和演变中寻找下一个灵感。",pricing:"API价格表",pricing_desc:"我们的 API 定价是根据请求中发送的词元数量确定的。对于读取器 API，它是响应中的词元数量。此定价模型适用于 Jina AI 搜索底座中的所有产品：向量、重新排名、读取器、自动微调 API。使用相同的 API 密钥，您可以访问所有 API 服务。",protectData1:"您向我们发送的数据和文档都不会用于模型训练。",protectData2:"数据在传输过程中加密 (TLS 1.2+) ，同时静态数据也会被加密 (AES-GCM 256)。",protectData3:"SOC 2 和 GDPR 合规。",protect_data:"保护您的数据",public_cloud_integration:"与 <b>{_numPartners}</b> 个云服务提供商合作",public_cloud_integration_desc:"您的公司是否在使用 AWS 或 Azure？那么请直接在贵公司的这些平台上私有化部署我们的搜索底座模型，这样您的数据就能保持安全且合规。",query:"查询句",raise_issue:"问题反馈",rank_none_description:"不要使用任何重排模型",read_api_docs:"API 规范",read_release_note:"阅读发行说明",recharge_threshold:"充值门槛",refresh:"刷新",refresh_key_tooltip1:"免费获取新的 API 密钥",refresh_token_count1:"刷新以获取当前 API 密钥的可用词元",regenerate:"生成新的密钥",remaining:"剩余词元额度",remaining_left:"您在下面的 API 密钥中还剩余 <b>{_leftTokens}</b> 个词元。",request_number:"请求次数",request_path:"请求端点",results_as_final_result:"最终结果的文档数",results_fed_to_reranker:"提交给重排器的文档数",retry:"重试",return_base64:"Base64（字符串）",return_binary:"二进制（打包为 int8）",return_float:"默认（浮点型）",return_format:"向量格式",return_format_explain:"除了浮点数之外，您还可以要求它以二进制形式返回，以便更快地进行矢量检索，或者以 base64 编码形式返回，以便更快地进行传输。",return_format_title:"返回数据类型",return_ubinary:"二进制（打包为 uint8）",right_api_key_to_charge:"请输入正确的API密钥进行充值",running:"运行中",score:"分数",search:"搜索",search_hint:"在下列句子中输入要搜索的内容",select_classify_model:"选择分类器",select_embedding_model:"选择向量模型",select_rerank_model:"选择重排器",show_api_key:"显示 API 密钥",size:"参数",size_explain:"模型中的参数数量为{_size}，请注意，这不代表模型的文件大小。",sleeping:"休眠中",start_batch:"开始批处理",start_embedding:"开始索引",status_explain:"我们的无服务器架构可能根据使用率即时从内存中卸载一些当下无人使用的模型。对于活跃模型，响应是立即的。而休眠中的模型在收到第一次请求时才会加载，这一过程可能会持续几十秒。模型被唤醒后，后续请求的处理速度会更快。",task_type:"下游任务",task_type_classification:"分类",task_type_classification_explain:"文本分类。",task_type_explain:"选择将使用向量模型的下游任务。模型将返回针对该任务优化的向量。",task_type_none_explain:"不使用适配器。将返回通用向量，可用于调试或黑客攻击。",task_type_retrieval_passage:"检索通道",task_type_retrieval_passage_explain:"将文档向量化查询文档检索任务中。",task_type_retrieval_query:"检索查询",task_type_retrieval_query_explain:"在查询文档检索任务中向量化查询。",task_type_separation:"分离",task_type_separation_explain:"聚类文档，可视化语料库。","task_type_text-matching":"文本匹配","task_type_text-matching_explain":"语义文本相似度、广义对称检索、推荐、查找相似项、去重。",tax_may_apply:"根据您所在的位置，您可能需要支付美元、欧元或其他货币的费用。可能需缴纳税费。",text1:"左",text2:"右",three_ways:"三种购买方式",three_ways_desc:"订阅我们的 API、通过云提供商购买或为您的组织获取商业许可证。",title:"向量模型API",token_example:"一条微博大约有 20 个词元，一篇人民日报新闻大约有 1000 个词元，而查尔斯·狄更斯的小说《双城记》有超过一百万个词元。",token_length_explain:"此模型所支持的输入词元的最大长度为 {_tokenLength}。",tokens:"词元",tools:"工具",top_up_button:"给旧密钥充值",top_up_button_explain:"集成此 API 密钥可提供更专业的解决方案，无需频繁更改密钥。使用数据将被保留并可随时访问。",top_up_warning_message1:"当前 API 密钥还剩 {_remainedTokens} 词元，将被具有 {_freeTokens} 词元的新密钥替换。如果您已妥善保管旧密钥，则可以继续使用或充值旧密钥。您想如何进行？",top_up_warning_title:"是否替换旧密钥？",total_documents:"向量化进度：{_Processed}/{_Count} 个句子。",tuning:"微调",turnstile_error:"我们无法生成 API 密钥，因为我们无法验证您是否是人类。",turnstile_unsupported:"由于您的浏览器不受支持，我们无法生成 API 密钥。",ubinary_description:"向量被打包为 uint8。存储、搜索和传输效率更高。",upload:"上传",upload_file:"单击此处上传文件",usage:"用法",usage_amount:"词元",usage_history:"过去 7 天的使用情况",usage_history_explain:"数据并不是实时的，可能会延迟几分钟。",usage_reason:"描述",usage_reason_consume:"用过的",usage_reason_purchase:"已购买",usage_reason_trial:"使用",usage_rerank:"用法",usage_time:"时间日期",v3_description:"<code>jina-embeddings-v3</code> 是一种前沿多语言文本向量模型，具有 570M 个参数和 8192 个词元长度，在 MTEB 上的表现优于 OpenAI 和 Cohere 的最新专有向量模型。请阅读下面的博客文章和研究论文。",v3_title:"v3：顶级多语言向量模型",vector_database_integration1:"集成",vector_database_integration2:"在流行数据库、向量数据库、RAG 和 LLMOps 框架轻松使用我们的向量模型API。首先，只需将您的 API 密钥复制到以下任意集成中即可快速使用我们的模型。",vector_database_integration3:"我们的 Embedding & Reranker API 与各种知名数据库、向量存储、RAG 和 LLMOps 框架原生集成。首先，只需将您的 API 密钥复制并粘贴到任何列出的集成中即可快速无缝地启动。",vector_database_integration_description:"将 Jina Embeddings API 与以下任何向量数据库、LLM 编排框架和 RAG 应用程序无缝、轻松地集成。我们的教程将向您展示如何操作。",view_details:"查看详情",visualization_example:"将本节中的所有句子映射到 3D 向量空间",visualization_example_you_can:"使用我们下面的API，你也可以做到！",visualize:"可视化",visualize_done:"可视化已完成，您现在可以单击顶部按钮打开可视化工具。",wait_for_processing:"您的请求正在处理中。",wait_stripe:"正在开通Stripe支付，请稍候",what_are_embedding:"什么是向量化？",what_are_embedding_answer:`想象一下教计算机掌握单词和短语的细微含义。传统方法依赖于严格的基于规则的系统，由于语言过于复杂和流动，因此无法达到预期效果。输入文本向量：一种强大的解决方案，可将文本转换为数字语言 - 具体来说，转换为高维空间中的向量。

考虑短语“晴朗的天气”和“晴朗的天空”。对我们来说，它们描绘了相似的画面。通过向量的视角，这些短语被转换成数字向量，它们在这个多维空间中彼此靠近，捕捉它们的语义亲缘关系。向量空间中的这种接近性不仅仅是单词或短语相似；它还涉及理解上下文、情感，甚至含义中的细微差别。

为什么这一突破很重要？首先，它弥合了人类语言的丰富性和算法的计算效率之间的差距。算法擅长处理数字，而不是解释文本。通过将文本转换为向量，向量使这些算法能够以以前无法实现的方式“理解”和处理语言。

实际应用范围广泛且多种多样。无论是推荐符合您兴趣的内容，还是为感觉非常人性化的对话式人工智能提供支持，甚至是在大量文本中检测微妙的模式，向量都是关键。它们使机器能够执行情绪分析、语言翻译等任务，并且对语言的理解越来越细致入微和精细化。`,what_is_a_token:"文本处理中的词元是一个单元，通常是一个单词。例如，“Jina AI 太棒了！”变成五个词元，包括标点符号。",why_do_you_need:"选择最适合的向量模型",why_do_you_need_after:"通过深度学习和先进的语言处理技术，我们的向量模型能够将复杂的多模态数据转换为简化的格式，这不仅提升了机器的理解力，也为实现更复杂的AI应用提供了可能，包括但不限于提高数据解析能力、增加用户互动、消除语言障碍和改进开发流程。",why_do_you_need_before:"我们的向量模型旨在涵盖各种搜索和 GenAI 应用。",why_need_1_description:"我们依托JinaBERT打造的向量基座模型，面向各种场景设计。它在解析长篇文本方面表现出色，适合用于语义搜索、内容分類及深度语言分析等任务。这种多功能性使其成为开发情绪分析工具、文本摘要和个性化推荐系统的理想选择。",why_need_1_title:"通用向量",why_need_2_description:"我们的双语模型旨在打破语言壁垒，提升多语言平台的沟通效率、全球客户支持和跨语言内容的发现能力。专注于德语-英语和中文-英语的双向翻译，让不同语言的用户能够更容易地理解和交流。",why_need_2_title:"双语向量",why_need_3_description:"专为开发者设计的代码向量模型，能够简化代码摘要编写、代码生成和自动代码审查等任务。通过深入分析代码结构并提供改进建议，显著提升了开发效率，是开发高级IDE插件、自动生成文档和创新调试工具的关键。",why_need_3_title:"代码向量",why_need_4_description:"Jina CLIP 是我们最新的图像和文本多模态向量模型。与 OpenAI CLIP 相比，一个很大的改进是，这个单一模型可以用于文本-文本检索，以及文本-图像、图像-文本和图像-图像检索任务！因此，一个模型，两种模态，四个搜索方向！",why_need_4_title:"多模态向量",write_email_here:"请输入您希望在完成后接收下载链接的电子邮件。",you_can_leave:"您可以离开此页面，完成后我们将向您发送下载链接。"},w={description:"世界一流的多模态多语言向量模型。"},P={answer1:"Jina AI 专注于多模态AI技术，包括大模型向量的调优和部署、提示词的调优和部署。我们利用 Kubernetes 和无服务器架构等先进工具来创建强大、可扩展且可立即投入生产的解决方案。",answer10:"我们根据项目的性质和客户的需求提供不同的许可选项。详细条款可以与我们的销售团队讨论。",answer11:"我们在全球范围内提供服务，总部位于欧洲柏林，并在北京和深圳设有办公室。",answer12:"是的，我们提供现场支持，特别是对于位于柏林、北京和深圳办公室附近的客户。对于其他地点，我们努力提供最好的远程支持，并在必要时安排现场支持。",answer2:"我们的专业知识涵盖广泛，包括大型语言模型、文本、图像、视频、音频理解、神经搜索和生成式AI。",answer3:"是的，我们的解决方案设计为可扩展并可用于生产。我们使用云原生技术构建解决方案，从而在生产环境中实现高效扩展和可靠的性能。",answer4:"我们的服务用途广泛且适应性强，适用于多种行业，包括电子商务、法律技术、数字营销、游戏、医疗保健、金融等。",answer5:"您可以通过此页面上的联系表与我们的销售团队取得联系。我们很乐意讨论您的项目需求以及我们的解决方案如何帮助您的业务。",answer6:"我们提供持续的支持，以确保我们的解决方案顺利运行。这包括根据您的反馈和需求进行故障排除、定期更新和改进。",answer7:"项目持续时间根据项目的复杂性和范围而有所不同。了解您的要求后，我们可以提供更准确的估算。",answer8:"数据安全是我们的首要任务。我们遵守严格的数据保护政策和法规，以确保您的数据安全和保密。",answer9:"定价取决于项目的复杂性和要求。我们提供基于项目的定价模型和保留定价模型。请联系我们的销售团队了解更多信息。",question1:"Jina AI 擅长什么？",question10:"你们的解决方案的许可条款是什么？",question11:"您的服务区域是什么？",question12:"你们提供现场支持吗？",question2:"Jina AI 适用于哪些类型的人工智能？",question3:"您的解决方案可扩展且可投入生产吗？",question4:"哪些行业可以从 Jina AI 的解决方案中受益？",question5:"我们如何使用 Jina AI 启动一个项目？",question6:"实施解决方案后您提供哪些支持？",question7:"项目的典型持续时间是多长？",question8:"Jina AI 如何保护我的数据？",question9:"你们的服务的定价结构是怎样的？"},k="常见问题",y={text:"江湖再见。",toggle_btn:"下次访问时保持此面板打开",warning_message:"当您访问 jina.ai 时，此面板将自动打开。您需要关闭它才能查看网站内容。启用此设置吗？",warning_title:"启动时显示"},v={description:"调优特定领域数据的大模型向量以获得更好的搜索质量",intro:"你的公司、你的数据、你的模型"},L={description:"为您的企业提供本地调优解决方案"},x={api_key:"输入您的 API 密钥。",back:"后退",base_model_selected:"选择底座模型",click_start:"同意条款并开始微调。",confirm_title:"确认微调工作",confirm_your_email:"重新输入您的电子邮件地址以确认微调工作。更新和下载链接将发送到此电子邮件。",consent0:"我同意根据我的指示生成用于模型微调的合成数据。",consent1:"我承认最终模型和合成数据将在 Hugging Face 上公开。",consent2:"我了解此功能处于测试阶段，Jina AI 不提供任何保证。定价和用户体验可能会发生变化。",continue:"继续",cost_1m_token:"每个微调作业消耗 1M 词元。请确保您有足够的词元或充值。您也可以生成新的 API 密钥。每个 API 密钥附带 1M 免费词元。",doc_explain:"描述匹配的文档应该是什么样的。",domain_explain:"详细描述如何使用微调向量模型。这对于生成高质量的合成数据（可提高向量模型的性能）至关重要。",domain_explain2:"有三种方式可以指定您的需求：一般说明、URL 或查询文档描述。请选择一种。",domain_hint:"描述您希望微调的域。",email_not_match:"电子邮件地址不匹配。请验证。",failed_job:"微调请求失败。请参阅下面的原因。",find_on_huggingface:"在 Hugging Face 上查找结果",general_instruction:"或者，一般说明",general_instruction_caption:"提供有关如何使用微调向量的详细描述。",general_instruction_explain:"以自由格式的文本描述您的域名。您可以将其想象为 ChatGPT 中的“提示”。",how_it_works:"了解微调过程。",job_acknowledged:"您的微调作业已排队。作业开始时，您将收到一封电子邮件。整个过程通常需要 20 分钟才能完成。",new_key:"获取新密钥",not_enough_token:"此 API 密钥中词元不足。请充值或使用其他 API 密钥。",placeholder:"汽车保险索赔",preview:"预览",query_doc:"查询文档描述",query_doc_caption:"描述查询是什么样的以及匹配的文档在您的域中是什么样的。",query_explain:"描述查询的样子。",reset:"重来",select_base_model:"选择一个基础向量模型进行微调。",select_base_model_explain:"选择一个底座模型作为微调的起点。通常，base-en 是一个不错的选择，但对于其他语言的任务，请考虑使用双语模型。",start_tuning:"开始微调",url:"或者，网页网址",url_caption:"参考URL中的内容进行微调。",url_explain:"包含您要微调的内容的网页的公共 URL。",use_url:"使用 URL 代替。启用该选项意味着我们将根据该 URL 的页面内容生成合成数据以进行微调。",wait_for_processing:"请稍候，我们正在处理您的请求...",which_domain:"微调域",write_email_explain:"微调需要时间。我们将通过电子邮件告知您微调工作的开始、进度、完成情况和任何问题，以及微调模型和训练数据集的详细信息。"},q={address_beijing:"中国北京",address_berlin:"德国柏林",address_shenzhen:"中国深圳",address_sunnyvale:"加利福尼亚州桑尼维尔",all_rights_reserved:"版权所有",company:"公司",developers:"为开发者",docs:"文档",enterprise:"为企业",get_api_key:"获取 Jina AI API 密钥",offices:"办公室",power_users:"为高级用户",privacy:"隐私",privacy_policy:"隐私政策",privacy_settings:"管理 Cookie",security:"安全",sefo:"搜索底座",soc2:"我们符合美国注册会计师协会 (AICPA) 的 SOC 2 Type 1 标准。",status:"API 状态",status_short:"服务状态",tc:"条款及条件",tc1:"条款"},M="获取 API 密钥",R={stars:"Stars"},J={about_us:"关于我们",company:"公司",contact_us:"联系销售",developers_others:"更多开发者工具",enterprise_others:"更多企业工具",for_developers:"为开发者赋能",for_developers_description:"专为开发人员打造的的多模态开源技术栈。",for_enterprise:"为企业赋能",for_enterprise_description:"探索为企业定制的多模态解决方案。",for_power_users:"为高级用户赋能",for_power_users_description:"利用我们多模态工具来提高您的日常生产力。",internship1:"实习生计划",jobs:"加入我们",join_discord:"加入我们的 Discord 社区",logos:"下载Logo",maximize:"⇧1",maximize_btn:"最大化",news:"新闻",open_day:"开放日",open_in_full:"在新窗口中显示所有企业产品",power_users_others:"更多高级用户工具",products:"产品"},S={description:"分享和发现多模态AI应用程序的构建模块"},j={sentence_similarity:"句向量模型",updated_about:"更新了关于"},C={project1:"使用点云信息在 3D 网格数据中实现高精度搜索。",project10:"利用计算机视觉提高政府网站的数字可访问性。",project11:"为一家咨询公司优化财务数据分析的调优大规模语言模型。",project12:"通过调优文本到图像模型以进行风格转换来实现高级营销策略。",project2:"设计了一个基于内容的动画短片搜索引擎。",project3:"通过调优向量模型来提高电子商务转化率。",project4:"为一家商业咨询公司进行及时调整以提高效率。",project5:"为一家领先的游戏企业开创了游戏场景理解和自动标注的先河。",project6:"为一家聊天机器人公司实现了实时输入扩展，增强了用户体验。",project7:"通过在冗长的法律文档中实现高效搜索。",project8:"支持大规模运营的高吞吐量生成艺术服务。",project9:"使用高级语言模型进行流程挖掘和建模。"},z={description:"最先进的多模态推理模型"},T={copy_full_prompt:"复制完整提示词",embedding:"向量模型",how_to_use_meta_prompt:"如何使用",meta_prompt:"使用元提示词进行代码生成",meta_prompt_description:"元提示词可以让大模型（如 ChatGPT 和 Claude）知晓我们所有的API使用方法，从而使代码生成更容易、质量更高。",reranker:"重排器",which_to_go:"哪一个与{_vendor}集成？"},G={answer1:"本科、硕士、博士我们鼓励来自世界各地对研究、工程、营销和销售等领域感兴趣的学生申请。我们还欢迎营销、销售、行政助理等领域的非技术实习机会。我们正在寻找热情的个人，准备与我们一起开拓多模态AI。",answer10:"是的，我们的实习计划提供有竞争力的薪酬。",answer11:"作为 Jina AI 实习生，您将获得从事具有挑战性的项目的实践经验，向行业专家学习，成为充满活力的社区的一部分，并有机会为我们在多模态 AI 领域的开创性工作做出真正的贡献。",answer2:"实习必须在我们位于柏林、北京和深圳的办事处之一现场进行。",answer3:"是的，Jina AI 在签证流程中为成功申请者提供合理的帮助。",answer4:"是的，Jina AI 为实习生在实习期间提供合理的生活费保障。",answer5:"是的，您可以在 Jina AI 实习期间完成硕士论文，这通常适用于德国大学的学生。但是，您必须事先征得您所在大学主管的沟通并同意。请注意，我们不帮助学生寻找顾问。",answer6:"申请过程包括提交您的申请表、简历、表达您的兴趣和动机的求职信以及任何相关的专业链接，例如 GitHub 或 LinkedIn。我们根据候选人在面试中的表现以及他们在大学的表现来评估他们。",answer7:"是的，成功的实习生可能会在实习结束时收到一封由我们首席执行官签署的推荐信。",answer8:"实习的持续时间根据角色和项目而有所不同。然而，它通常为三到六个月。",answer9:"是的，我们欢迎所有学术背景的申请。我们重视您对学习的热情和承诺，就像您以前的经验一样。",question1:"哪些人可以申请 Jina AI 实习项目？",question10:"这是带薪实习吗？",question11:"作为 Jina AI 实习生，我将获得哪些机会？",question2:"实习将在哪里进行？",question3:"Jina AI 是否协助办理签证流程？",question4:"Jina AI 是否为实习生提供任何津贴或福利？",question5:"在 Jina AI 实习期间可以写硕士论文吗？",question6:"申请流程涉及哪些内容？",question7:"Jina AI 实习后有推荐信吗？",question8:"实习期限是多长？",question9:"如果我没有人工智能方面的经验，我可以申请吗？"},B={about_internship_program:"关于实习计划",about_internship_program_desc1:"我们很高兴为有才华的人提供这个独特的机会加入我们充满活力的团队，并为人工智能领域的突破性项目做出贡献。该实习旨在为您提供宝贵的实践经验、指导和接触正在塑造人工智能未来的尖端技术。",about_internship_program_desc2:"在 Jina AI，我们深知培养和利用年轻人才的重要性。我们认识到实习生带来了新的视角、热情和创造力，用新的想法和方法激励我们的团队。通过提供实习机会，我们的目标是促进人工智能行业未来领导者的成长，同时在支持性和挑战性的环境中为他们提供实际经验。",alumni:"校友",alumni_network:"我们蓬勃发展的校友网络",application:"应用",application_desc:"与 Jina AI 一起踏上变革之旅。我们全面的实习计划邀请所有渴望塑造人工智能未来的充满激情的伙伴。加入我们，获得现实世界的经验，从事具有挑战性的项目，并与人工智能行业中一些最聪明的人做同事。",apply:"现在申请",autumn:"秋季",description:"全球招募学生：研究、工程、营销、销售等专业的实习。",dev_rel_intern:"开发者关系实习生",enthusiastic:"热情的",explore_stories_from_our_interns:"探索我们实习生的故事",explore_stories_from_our_interns1:"从我们的实习生的旅程中获得灵感",innovative:"创新的",intern_work1:"微调 LLM 模型以实现更好的句向量模型",intern_work2:"探索检索增强生成(RAG)算法的潜力",intern_work3:"发表了一篇关于句子向量的论文",intern_work4:"为团队注入源源不断的年轻活力",intern_work5:"压缩 LLM 的基准量化技术",intern_work6:"为 PromptPerfect 创建和推广引人注目的活动",intern_work7:"快速开发和改进 JinaColBERT V2",recruiting_and_administrative_intern:"招聘及行政实习生",researcher_intern:"实习研究员",self_motivated:"自我激励",software_engineer_intern:"软件工程师实习生",spring:"春季",submit_application:"与 Jina AI 一起开始你的冒险",subtitle:"我们的全日制实习计划通过精心设计的广泛范围的实习项目提供实践工作经验。",subtitle1:"全球范围内招募学生：研究、工程、营销、销售等领域的实习生，共同开创多模态AI。",summer:"夏季",title:"实习生计划",who_do_we_look_for:"我们要找谁？",who_do_we_look_for_desc:"我们重视多样性，并鼓励来自不同背景和背景的申请人加入我们的实习计划。多个部门提供实习机会，包括工程、设计、产品管理、销售和客户管理、营销和社区管理。",winter:"冬季"},U={description:"将一个本地项目部署为云服务。极其简单，没有令人不快的意外。"},O={description:"开源的 LLM 的实验性调优器"},E={description:"在云端构建多模态AI应用"},D={description:"更多模态、更长记忆、更低成本",example_1:"你是谁？",example_2:"我是 Jina AI 制作的 LLM 聊天服务"},N={add:"添加密钥",add_key_explain:"向您的帐户添加另一个 API 密钥。可以随时管理、充值或删除添加的密钥。",auto_recharge_title:"启用自动充值吗？",available_resources:"可用词元",balance:"可用词元",balance_primary_key:"主密钥余额",cancel:"取消",copy:"复制密钥",description:"管理所有 Jina AI 服务的 API 密钥 — Embeddings、Reader、Reranker 等。",do_it_later:"稍后再做",existing_key:"现有密钥",filter_by:"按密钥过滤",free_key:"免费密钥",invalid_key:"密钥无效",is_primary:"您的主密钥。登录后您可以更改它。",last_used:"最后使用",last_used_at:"上次活动",login:"登录",login_explain:"管理多个 API 密钥并跟踪使用情况——全部在一个帐户中完成。",login_explain_long:"登录以安全地存储和管理您的 API 密钥。跟踪使用历史记录、管理多个密钥，并且永远不会失去对您的凭据的访问权限。",logout:"登出",logout_message:"您的 API 密钥安全地存储在您的帐户中。您可以随时登录来管理它们。",logout_success:"已成功登出",ok:"好的",primary_key:"设置为主密钥",primary_key_set:"成功将 {_apiKey} 设置为您的主密钥。",primary_key_set_caption:"此密钥将用于 jina.ai 上的所有演示、示例和沙盒实验场。",purchase:"购买词元",remove:"移除密钥",remove_message:"您确定要删除此密钥吗？该密钥仍然有效，以后可以再次添加。",remove_primary_key:"删除当前主密钥之前，请将另一个键设置为主密钥。",remove_title:"移除密钥",revoke:"撤销密钥",revoke__message:"您确定要撤销此密钥吗？一旦撤销，此密钥将永久无效。",subscribed_key:"付费密钥",title:"Jina 搜索底座 API",to_dashboard:"管理密钥",total_keys:"密钥数",usage_history:"使用历史记录",usage_summary:"过去 7 天：{_usage} 个词元"},F={GlobalQA:{description:"在任意页面上按“/”键即可打开提问。输入您的查询并按“Enter”得到页面内容相关的答案。此功能由 PromptPerfect 提供支持。",title:"页上RAG"},Recommender:{description:"使用“Shift+2”打开任何新闻页面上的推荐框。选择重排模型以发现与该新闻页面相关的前 5 篇文章。此功能由我们的 Reranker API 提供实时支持。",title:"相关文章"},SceneXplainTooltip:{description:"将鼠标悬停在新闻页面或我们的新闻室目录中的任何图片上，以显示该图片的描述。描述由 SceneXplain 预先计算并向量化在图像的 ALT 属性中。",title:"图像标注"},explain:"探索我们网站上的隐藏功能"},H={also_available_on:"也可在应用市场上使用",also_available_on1:"通过应用市场一键部署到您的企业云上",ask_how_your_question:"请描述您的问题",autotune:"自微调",badge:{"clip-v2":"clip-v2 发布！",v2:"第二版已发布！",v3:"v3 发布！"},build_js:"使用 JavaScript 开发",build_python:"使用 Python 开发",ccbync:"此模型为 CC BY-NC 4.0 许可。通过 API 或我们的官方 AWS/Azure 映像使用它；或联系销售人员进行本地部署。",checkout_our_solution_for_you:"了解我们为您量身定制的解决方案",classifier:"分类器",coming_soon:"敬请期待",contact_sales:"联系我们",copied_to_clipboard:"已复制到剪贴板",copy:"复制",developers:"开发者",developers_desc:"通过尖端的云原生技术和开源基础设施，释放多模态AI的全部力量。",download_pdf:"下载 PDF",embedding:"向量",embedding_desc1:"适用于搜索、RAG、智能体应用程序的性能最佳的多模态多语言长上下文向量模型。",embedding_paper_desc:"Jina Embeddings 构成了一组高性能文本向量模型，擅长将各种文本输入转换为数字表示，从而捕获文本的语义本质。虽然这些模型并非专门为文本生成而设计，但它们在密集检索和语义文本相似性等应用中表现出色。本文详细介绍了 Jina Embeddings 的开发，从创建高质量的成对和三元组数据集开始。它强调了数据清理在数据集准备中的关键作用，深入了解了模型训练过程，并使用大规模文本向量基准 (MTEB) 进行了全面的性能评估。",embedding_paper_title:"Jina Embeddings：一套新颖的高性能文本向量模型",embeddings:"向量模型",enterprise:"企业",enterprise_desc:"通过可扩展、安全和定制的多模态AI解决方案促进您的业务。",enterprise_desc_v2:"用我们世界一流的向量模型来改进您的搜索和 RAG 系统。从免费试用开始！",enterprise_desc_v3:"我们的前沿模型构成了高质量企业搜索和 RAG 系统的搜索底座。",error:"出现了问题：{message}",find_your_portal:"探索您的专属传送门",finding_faq:"根据以下常见问题解答知识生成答案",for:"为",for_developers:"为开发者",for_enterprise:"为企业",for_power_users:"为高级用户",get_api_now:"API",get_started:"开始使用",go_to_product_homepage:"转至产品主页",how_to:"如何",include_experiment:"在解决方案中提及我们还在实验中和已归档的项目。",join_community:"社区",key_manager:"管理 API 密钥",learn_more_embeddings:"了解向量模型",learn_more_reader:"详细了解读取器",learn_more_reranker:"了解重排器",llm:"LLM 大模型向量模型",llm_desc:"我们提供了一系列高性能文本向量模型，拥有 3500 万到 60 亿个参数。它们非常适合增强神经搜索、重排器、句子相似性、推荐等。准备好提升您的 AI 体验！",mentioned_products:"提及产品：",mmstack:"多模态技术栈",mmstack_desc:"多年来，我们开发了各种开源软件，帮助开发人员构建更好的 GenAI 和更快地搜索应用程序。",models:"模型",more:"更多的",multimodal:"多模态",multimodal_ai:"多模态AI",new:"新的",newsroom:"新闻",num_publications:"共计 {_total} 篇出版物。","on-prem-deploy":"私有化部署","on-premises":"本地",opensource:"开源",our_customer:"我们的客户",our_customer_explain:"大大小小的企业都信任 Jina AI 的搜索底座技术来构建他们的工具和产品——您也可以信任我们。",our_publications:"我们的论文",parameters:"参数",podcast:"播客",power_users:"高级用户",power_users_desc:"自动提示词工程，提高您的日常工作效率。",powered_by_promptperfect:"由 PromptPerfect 的“提示词优化”和“提示即服务”功能提供支持",pricing:"价格表",proposing_solution:"基于 Jina AI 产品线的构思解决方案...",read_more:"更多新闻",reader:"读取器",require_full_question:"请更详细地描述您的问题。",reranker:"重排器",researcher_desc:"了解我们的前沿搜索模型是如何从头开始训练的，查看我们的最新出版物。在 EMNLP、SIGIR、ICLR、NeurIPS 和 ICML 与我们的团队见面！",researchers:"研究人员",sdk:"软件开发工具包",sdk_desc:"想要使用 PromptPerfect、SceneXplain、BestBanner、JinaChat、Rationale API 构建高级 AIGC 应用程序？我们为您服务！尝试我们易于使用的 SDK，几分钟内即可开始使用。",sdk_docs:"阅读文档",sdk_example:"例子",search_foundation:"搜索底座",source_code:"源代码",starter_kit:"新人包",supercharged1:"从此不同！",tokenizer:"切分器",trusted_by:"我们值得信赖",try_it_for_free:"立即开始——无需信用卡或注册！",try_our_saas:"尝试我们托管的的云原生推理方案，它是OpenAI API的1:1替代品。",your_portal_to:"邀您通往",your_search_foundation1:"您的搜索底座"},K={description:"使用 Jina 和 FastAPI 制作生产级别的 Langchain 应用程序"},W={description:"关于Jina AI产品和服务的法律信息、服务条款、隐私政策和其他重要文件。",title:"法律信息"},Y={api:"Jina AI的API",contact_sales_about_it:"联系销售人员了解详情",deploy_it_on:"部署于",description:"多年来，我们不断突破搜索的界限。以下是我们发布的模型 — 将鼠标悬停或单击每个模型可查看更多详细信息。",find_on_hf:"在 HuggingFace 上找到它",search_for:"在我们的网站上搜索",search_models:"按模型名称过滤",title:"我们的搜索底座模型",use_it_via:"通过使用"},X={back_to_newsroom:"返回新闻首页",categories:"类别",copy_link:"复制此部分的链接",in_this_article:"文章导览",learn_more:"了解更多",news_not_found:"糟糕！未找到文章",redirect_to_news:"将在5 秒后重定向至新闻首页..."},Q={academic:"学术",academic_research:"学术论文",author:"按作者过滤",description:"阅读 Jina AI 的最新新闻和更新。",description1:"一字一句地撰写AI技术创新。",engineering_group:"工程组",engineering_group_date:"2021 年 5 月 31 日",minutes_read:"分钟的阅读量",most_recent_articles:"最新文章",news_description:"对于 Jina 2.0，我们听取了社区的意见。确实，深深地听过。 “你的痛点是什么？”我们询问并热切期待宝贵的反馈",news_title:"搜索所有内容：我们正在为 Jina 2.0 举办 MEME 竞赛",photos:"相片",product:"按产品过滤",search:"按标题搜索",tech_blog:"技术文章",title:"新闻",top_stories:"甄选文章"},V="🎉 我们的第一本书《神经搜索——与 Jina 一起从原型到生产》今天正式出版！",Z={description:"参访 Jina AI 内部的独家机会。",engage:"我们强烈鼓励全天进行互动对话。思想和观点的交流对我们来说非常宝贵。这些讨论产生的潜在合作可以为更加一体化和创新的未来做出重大贡献。",engage_title:"头脑风暴",experience:"我们为客人安排了三小时的沉浸式游览，提供德语、英语、法语、西班牙语、中文和俄语版本。这次巡演将深入探讨我们在多模态AI方面的进展、我们对人工智能领域的看法，然后对具体项目进行详细审查。最后我们将进行小组讨论，以促进思想和见解的交流。还可应要求提供午餐选择。",experience_title:"业内人士之旅",group_size:"预计参观人数",impact:"了解我们对开源社区的贡献以及我们在多模态AI技术方面的工作如何使 Jina AI 成为人工智能创新领域有影响力的参与者。我们的目标是在决策过程中发挥重要作用，确保人工智能技术的进步惠及所有人。",impact_title:"行业影响力",introduction:"Jina AI 很高兴向对那些对人工智能未来感兴趣的机构敞开大门。我们为政界、非政府机构、非营利机构和投资领域的人士提供开放日。在此，诚邀您做客柏林总部，了解我们的运营、愿景的行业洞察。",motivation_min_length_v1:"请提供更详细的动机。",motivation_placeholder_v2:"分享您的动机将帮助我们改善您的体验。",motivation_to_attend_v2:"您为什么对我们的开放日感兴趣？",one_hour:"1小时",organization:"机构",organization_website:"机构网站",organization_website_placeholder:"您机构的主页或 LinkedIn 个人资料的 URL",preferred_date:"首选日期",preferred_language:"首选语言",preferred_products:"您对哪些产品感兴趣？",subtitle:"多模态AI的未来一瞥",title:"开放日",tutor_subtitle:"精心策划的三小时导览，让您更接近 Jina AI 在多模态AI技术方面的开创性工作的核心。",tutor_title:"独家深入探讨",vision:"加入我们，全面了解我们所看到的人工智能前景。我们的讨论将重点关注大型语言模型、多模态AI的潜力以及开源技术在塑造全球创新未来方面的影响。",vision_title:"未来愿景"},$={answer1:"我们提供德语、英语、法语、西班牙语、中文和俄语的讲解服务。",answer2:"讲解通常持续大约三个小时。",answer3:"午餐是可选的，可根据要求安排。",answer4:"我们的开放日主要是为专业团体设计的，例如政治家、非政府机构、非营利机构和投资者。然而，我们偶尔会根据个人的个人资料做出例外情况。",answer5:"我们可以容纳各种规模的团体。请在报名表中注明您的团体人数，我们将与您确认详细信息。",answer6:"注册表中有一个部分，您可以在其中指定您感兴趣的领域或任何特殊要求。我们将尽力根据您的需求定制行程。",answer7:"目前，我们仅在位于克罗伊茨贝格的柏林总部提供开放日。我们的北京和深圳办事处目前不开放参观。",question1:"你们提供哪些语言的讲解服务？",question2:"讲解时长是多少？",question3:"提供午餐吗？",question4:"个人可以报名参加开放日吗？",question5:"开放日的团体可以有多少人？",question6:"我如何指定讲解的兴趣区域？",question7:"你们的北京或深圳办事处提供开放日吗？"},ee={description:"开源、云原生的大型多模态模型服务框架"},ne={commercial_licence:{chip_label:"专为小型公司",company_size_note:"专为员工人数少于 100 人且收入少于 500 万美元的公司提供",cta_button:"立即开始",download_title:"下载商业许可证",feature_api_desc:"购买前请先测试",feature_api_title:"免费 API 测试访问",feature_consulting:"每季度与我们的模型专家进行 2 小时的咨询会议",feature_consulting_desc:"每个许可期限内提供三 (3) 小时的技术咨询服务。",feature_future_support:"无需许可即可访问未来的 CC BY-NC 模型",feature_future_support_desc:"许可期限内许可方根据 CC-BY-NC-4.0 发布的任何新模型。",feature_models:"无限制地使用我们的 CC BY-NC 模型进行商业使用",feature_models_desc:"将模型用于商业目的，包括内部使用或纳入面向客户的应用程序。",price_amount:"1,000 美元",price_period:"/ 每季度",read_the_terms:"查看许可条款",read_the_terms_btn:"条款",read_the_terms_desc:"购买前查看商业许可权利和限制",subtitle:"这些模型助您实现更好的搜索",test_before_purchase:"购买前请先试用",test_before_purchase_desc:"获取 100 万个免费 API 词元或使用我们的 Hugging Face 模型来验证性能",title:"商业许可证",try_api:"首先尝试 API"},free_hour_consult:"免费1小时咨询",free_hour_consult_description:"与我们的产品和工程团队进行一小时免费咨询，讨论适合您场景下的最佳实践",full_commercial:"不受限制的商业用途",full_commercial_description:"您可以将 API 用于商业目的，不受任何限制。",higher_limit:"更高速率！",higher_limit_description:"r.jina.ai 最高可达 1000 RPM，s.jina.ai 最高可达 100 RPM；更多详细信息请参阅速率限制部分。",key_manager:"API 密钥管理",key_manager_description:"在一个帐户中管理多个 API 密钥、跟踪使用历史记录和充值令牌。",no_commercial:"仅限非商业用途（CC-BY-NC）",no_commercial_description:"您只能将API用于非商业用途，若要用于商业用途，请充值您的API密钥。",on_prem:"拥有本地部署的商业许可证",on_prem_explain:"购买商业许可证以在现场使用我们的模型。",priority_support:"优先技术支持",priority_support_description:"保证在 24 小时内通过电子邮件回复技术问题和事件。",secured_by_stripe:"通过 Stripe 安全付款",via_api:"使用 Jina Search Foundation API",via_api_explain:"访问我们所有产品的最简单方法。随时充值词元。"},te="基于",ie="打印",ae={archived:"已存档",cloud_native:"云原生",core:"基层核心",data_structure:"数据结构",embedding_serving:"大模型向量部署",embedding_tuning:"大模型向量调优",graduated:"已毕业",incubating:"孵化中",kubernetes:"Kubernetes",large_size_model:"大型模型",linux_foundation:"Linux 基金会",llm1:"LLM框架",mid_size_model:"中型模型",model_serving:"模型部署",model_tuning:"模型调优",observability:"可观察性",orchestration:"云编排",prompt_serving:"提示词部署",prompt_tuning:"提示词调优",rag1:"RAG应用",sandbox:"沙盒",small_size_model:"小型模型",vector_database:"向量数据库",vector_store:"向量数据库"},_e={description:"首屈一指的提示词工具箱",image_model:"图像模型",intro:"首屈一指的提示词工具箱",intro1:"提示词工程的首要工具",optimized:"你的任务是成为我的头脑风暴伙伴，为特定的主题或问题提供创造性的想法和建议。您的回答应该包括原创的、独特的和相关的想法，这些想法可以帮助解决问题或以有趣的方式进一步探索该主题。请注意，您的回答还应考虑任务的任何具体要求或限制。",optimized_title:"优化后的提示词",original:"你的角色是成为我的头脑风暴伙伴。",original_title:"原提示词",text_model:"文本模型"},re={features:[{description:"轻松在内容成产和提示词优化之间切换，将您的内容质量提升到新的水平。",name:"智能助手",title:"每日一罐生产力。"},{description:"不知道如何编写有效的提示词？只需输入您的想法，点一下鼠标，即可获得更好的提示词。",name:"提示词优化",title:"更好的输入，更好的输出"},{description:"通过比较同一提示词的输出来了解每个 AI 模型的性格。",name:"模型大比拼",title:"并排模型比较。"},{description:"这也许是将提示词部署为 API 最简单的方法。",name:"部署提示词",title:"告别繁琐Ops，直接部署。"},{description:"定制您自己的 LLM 智能体，并启动多智能体模拟。查看它们如何在虚拟环境中协作或竞争以达到目标。",name:"多智能体",title:"探索智能体如何协作"}],get_started:"开始使用 PromptPerfect"},oe={api_key:"充值API密钥",success:"感谢您的购买！",success_caption:"我们已于 {_purchasedTime} 完成您的订单。您的 API 密钥已可供使用！"},se="立即购买",ce={batch_explain:"此 API 支持批量操作，每次请求最多允许 512 个文档，每个文档最多包含 8192 个词元。巧妙利用批量操作可以大幅减少请求次数并提高性能。",classifier:"使用标记示例训练分类器",classifier_few_shot:"使用经过训练的少样本分类器对输入进行分类",classifier_few_shot_token_counting:"词元计数为：input_tokens",classifier_latency:"响应时间随输入大小而变化",classifier_token_counting:"词元计数为：input_tokens × num_iters",classifier_zero_shot:"使用零样本分类对输入进行分类",classifier_zero_shot_token_counting:"词元计数为：input_tokens + label_tokens",depends:"取决于输入大小",description:"描述",embeddings:"将文本/图像转为定长向量",endpoint:"API端口",explain:"速率限制以两种方式跟踪：<b>RPM</b>（每分钟请求数）和<b>TPM</b>（每分钟词元数）。限制是针对每个 IP 强制执行的，并且可以根据首先达到的阈值（RPM 或 TPM）来达到。",gjinaai:"用网络知识支撑声明",input_token_counting:"以输入请求中的词元数量为准。",latency:"平均延迟",no_token_counting:"词元不计算使用量。",output_token_counting:"以输出响应中的词元数量为准。",premium_rate:"有可能提高速率限制",product:"产品",requestType:"请求类型",reranker:"按查询对文档进行精排",rjinaai:"将 URL 转换为 LLM 友好文本",sjinaai:"搜索网络并将结果转换为 LLM 友好文本",tbd:"有待确定",title:"速率限制",tokenCounting:"词元使用计数",tokenizer:"对长文本进行分词分句",total_token_counting:"统计整个过程中词元的总数。",understanding:"了解速率限制",understanding_description:"速率限制是指每个 IP 地址在一分钟内可以向 API 发出的最大请求数 (RPM)。请在下面详细了解每个产品和层级的速率限制。",wAPIkey:"使用 API 密钥",wPremium:"带有高级 API 密钥",woAPIkey:"无 API 密钥"},de={decision:"决定",description:"LLM辅助智能决策工具",intro:"看到硬币的两面，做出理性的决定"},le={beta:"实验",better_input:"从一开始就提高输入质量",better_input_description:"您的Agent或 RAG 系统输出出现问题？这可能是由于输入质量差造成的。",check_price_table:"查看价格表",copy:"复制",demo:{advanced_parameter_explain:"仅用于{_product}的特定参数。",advanced_parameters:"具体的",advanced_usage:"高级用法",ask_llm:"询问 LLM 是否需要搜索依据",ask_llm_directly:"直接询问LLM",ask_llm_with_search_grounding:"通过搜索询问LLM",ask_question:"提出问题",ask_question_hint:"输入问题并将其与获取的 LLM 内容相结合以生成答案",basic_usage:"基本用法",basic_usage1:"读取 URL",basic_usage2:"搜索查询",basic_usage3:"查论",common_parameter_explain:"可用于{_product1}、{_product2}和{_product3}的通用参数。",common_parameters:"通用参数",copy:"复制",fetch:"获取内容",get_response:"获取响应",grounding_result_false:"此言差矣。",grounding_result_true:"此言正确。",headers:{auth_token:"添加 API 密钥以实现更高的速率限制",auth_token_explain:"输入您的 Jina API 密钥以访问更高的速率限制。有关最新速率限制信息，请参阅下表。",browser_locale:"浏览器区域设置",browser_locale_explain:"控制浏览器区域设置以呈现页面。许多网站根据区域设置提供不同的内容。",custom_script:"预执行自定义 JavaScript",custom_script_explain:"执行预处理 JavaScript 代码，接受内联代码字符串或远程脚本 URL 端点",deepdive:"深度源代码分析",deepdive_explain:"搜索更多来源并阅读完整文档以进行彻底的事实核查。速度稍慢但更准确且参考资料更多。",default:"默认",default_explain:"针对大多数网站和 LLM 输入优化的默认管道。",file:"本地 PDF/HTML 文件",file_explain:"通过上传本地 PDF 和 HTML 文件，使用阅读器阅读它们。仅支持 pdf 和 html 文件。",html:"HTML",html_explain:"返回 documentElement.outerHTML。",image_caption:"图片说明",image_caption_explain:"为指定 URL 上的所有图像添加标题，为没有标题的图像添加“Image [idx]: [caption]”作为 alt 标签。这允许下游 LLM 在推理和总结等活动中与图像进行交互。",images_summary:"将所有图像集中到最后",images_summary_explain:"最后会创建一个“图像”部分。这可以让下游的 LLM 概览页面上的所有视觉效果，从而提高推理能力。",json_response:"JSON 响应",json_response_explain:"响应将采用 JSON 格式，包含 URL、标题、内容和时间戳（如果可用）。在搜索模式下，它会返回一个包含五个条目的列表，每个条目都遵循描述的 JSON 结构。",links_summary:"将所有链接集中到最后",links_summary_explain:"最后会创建一个“按钮和链接”部分。这可以帮助下游 LLM 或 Web 代理浏览页面或采取进一步的行动。",markdown:"Markdown",markdown_explain:"直接从 HTML 返回 markdown，绕过可读性过滤。",mode:"阅读或搜索模式",mode_explain:"阅读模式用于访问 URL 的内容，而搜索模式允许您在网络上搜索查询，并将阅读模式应用于每个搜索结果 URL。",no_cache:"绕过缓存",no_cache_explain:"我们的 API 服务器会将读取和搜索模式的内容缓存一段时间。要绕过此缓存，请将此标头设置为 true。",no_gfm:"已禁用",no_gfm_explain:"GFM（Github Flavored Markdown）功能已禁用。",no_gfm_table:"无 GFM 表",no_gfm_table_explain:"选择退出 GFM 表但保留表 HTML 元素作为响应。",opt_out_gfm:"Github 风格的 Markdown",opt_out_gfm_explain:"选择加入/退出 GFM（Github Flavored Markdown）功能。",pageshot:"页面快照",pageshot_explain:"返回整页截图的图片网址（尽力而为）。",post_with_url:"使用 POST 方法",post_with_url_explain:"使用 POST 方法代替 GET 方法，并在正文中传递 URL。对于使用基于哈希的路由构建 SPA 非常有用。",proxy_server:"使用代理服务器",proxy_server_explain:"我们的 API 服务器可以利用您的代理来访问 URL，这对于只能通过特定代理访问的页面很有帮助。",references:"参考",references_explain:"以逗号分隔的用户提供的参考 (url) 列表",remove_all_images:"删除所有图片",remove_all_images_explain:"从响应中删除所有图像。",remove_selector:"排除选择器",remove_selector_explain:"提供 CSS 选择器列表以删除页面的指定元素。当您想要排除页面的特定部分（如页眉、页脚等）时很有用。",return_format:"内容格式",return_format_explain:"您可以控制响应中的细节级别，以防止过度过滤。默认管道针对大多数网站和 LLM 输入进行了优化。",screenshot:"截屏",screenshot_explain:"返回第一个屏幕的图像URL。",set_cookie:"转发 Cookie",set_cookie_explain:"我们的 API 服务器可以在访问 URL 时转发您的自定义 Cookie 设置，这对于需要额外身份验证的页面非常有用。请注意，带有 Cookie 的请求不会被缓存。",site_selector:"站内搜索",site_selector_explain:"仅返回指定网站或域的搜索结果。默认情况下，它会搜索整个网络。",stream_mode:"流模式",stream_mode_explain:"流模式有利于较大的目标页面，从而留出更多时间让页面完全呈现。如果标准模式导致内容不完整，请考虑使用流模式。",target_selector:"目标选择器",target_selector_explain:"提供 CSS 选择器列表，以关注页面的更具体部分。当您想要的内容在默认设置下不显示时很有用。",text:"文本",text_explain:"返回 document.body.innerText。",wait_for_selector:"等待选择器",wait_for_selector_explain:"提供一个 CSS 选择器列表，等待特定元素出现后再返回。当默认设置下无法显示所需内容时，此功能非常有用。",with_gfm:"已启用",with_gfm_explain:"已启用 GFM（Github Flavored Markdown）功能。",with_iframe:"启用 iframe 提取",with_iframe_explain:"提取并处理 DOM 树中所有嵌入的 iframe 的内容",with_shadow_dom:"启用 Shadow DOM 提取",with_shadow_dom_explain:"遍历文档中所有 Shadow DOM 根并提取内容",x_timeout:"超时时间",x_timeout_explain:"等待网页加载的最长时间。请注意，这不是整个端到端请求的总时间。"},how_to_stream:"要在内容可用时对其进行处理，请将请求标头设置为流模式。这可以最大限度地缩短收到第一个字节所需的时间。curl 中的示例：",how_to_use1:"将 https://r.jina.ai/ 添加到代码或工具中需要 LLM 访问的任何 URL。这将以干净、LLM 友好的文本返回页面的主要内容。",how_to_use2:"将 https://s.jina.ai/ 添加到您的查询中。这将调用搜索引擎并返回前 5 个结果及其 URL 和内容，每个结果都以简洁、LLM 友好的文本显示。",how_to_use3:"将 https://g.jina.ai/ 添加到您的语句中。这将调用判断引擎并返回真实性百分比、表示语句是真还是假的布尔值、原因摘要和参考列表。",key_required:"使用此端点需要 API 密钥",learn_more:"了解更多",open:"在新标签页中打开",params_classification:"参数",raw_html:"原始 HTML",reader_output:"读取器的输出",reader_response:"读取器反应",reader_search_hint:"如果您在代码中使用此 URL，请不要忘记对该 URL 进行编码。",reader_url:"读取器网址",reader_url_hint:"点击下面通过我们的读取器 API 获取内容",requires_post_method:"此功能需要 POST 方法。上传本地文件后，将自动启用 POST 方法。",search_params:"搜索参数",search_query_rewrite:"请注意，与上面的演示不同，在实践中，您不会在网上搜索原始问题来获取基础。人们经常做的是重写原始问题或使用多跳问题。他们阅读检索到的结果，然后生成其他查询以根据需要收集更多信息，然后得出最终答案。",select_mode:"选择模式",show_read_demo:"了解 Reader 如何读取 URL",show_search_demo:"了解读取器如何搜索网络",slow_warning:"这可能需要长达 30 秒并且每个请求最多需要 300K 个词元。",standard_usage:"标准用法",stream_mode:"流模式",stream_mode_explain:"当目标页面很大而无法渲染时，流模式非常有用。如果您发现标准模式提供的内容不完整，请尝试流模式。",stream_mode_explain1:"当您发现标准模式提供的结果不完整时，流式模式很有用。这是因为流式模式将等待更长时间，直到页面完全呈现。使用 accept-header 切换流式模式：",tagline:"试用演示",try_demo:"演示",use_headers:"可以使用请求标头来控制 Reader API 的行为。以下是受支持标头的完整列表。",waiting_for_reader:"首先等待 Reader API 结果...",warn_grounding_message:"此过程可能需要长达 30 秒的时间，并且每个查论请求最多会消耗 300K 个词元。某些浏览器可能会因为较长的延迟而终止请求，因此我们建议复制代码并从终端运行它。",warn_grounding_title:"高延迟和词元使用率",your_query:"输入您的查询",your_query_hint:"输入需要最新信息或世界知识的问题。",your_statement:"您的事实核查声明",your_url:"输入您的 URL",your_url_hint:"点击下面直接获取页面源代码"},description:"阅读 URL或通过搜索为LLM提供更好的依据。",dont_panic_api_key_is_free:"不要惊慌！每个新的 API 密钥都包含一百万个免费词元！",faq_v1:{answer1:"读取器 API 是免费的，不需要 API 密钥。只需在您的 URL 前面添加“https://r.jina.ai/”即可。",answer10:"不可以，读取器 API 只能处理来自可公开访问的 URL 的内容。",answer11:"如果您在 5 分钟内请求相同的 URL，读取器 API 将返回缓存的内容。",answer12:"不幸的是没有。",answer13:"是的，您可以使用读取器中的原生 PDF 支持（https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4）或使用 arXiv 中的 HTML 版本（https://r.jina.ai/https://arxiv.org/html/2310.19923v4）",answer14:"Reader 为指定 URL 上的所有图像添加标题，并添加 `Image [idx]: [caption]` 作为 alt 标签（如果最初没有）。这使得下游 LLM 能够与图像进行推理、总结等交互。",answer15:"Reader API 的设计具有高度可扩展性。它根据实时流量自动扩展，最大并发请求数现在约为 4000。我们正在积极维护它，将其作为 Jina AI 的核心产品之一。因此，请放心在生产中使用它。",answer16:"请在下表中查找最新的速率限制信息。请注意，我们正在积极致力于改进 Reader API 的速率限制和性能，因此该表将进行相应更新。",answer2:"读取器 API 使用代理来获取任何 URL，并在浏览器中呈现其内容以提取高质量的主要内容。",answer3:"是的，读取器 API 是开源的，可以在 Jina AI GitHub 存储库中找到。",answer4:"读取器 API 通常会在 2 秒内处理 URL 并返回内容，但复杂或动态的页面可能需要更多时间。",answer5:"抓取可能很复杂且不可靠，尤其是复杂或动态页面。读取器 API 提供简洁、可靠的干净 LLM 级文本输出。",answer6:"读取器 API 返回 URL 原始语言的内容。它不提供翻译服务。",answer7:"如果您遇到阻止问题，请联系我们的支持团队寻求帮助和解决方案。",answer8:"虽然 读取器 API 主要用于网页，但它可以从 arXiv 等网站上以 HTML 格式查看的 PDF 中提取内容，但它并未针对一般 PDF 提取进行优化。",answer9:"目前，读取器 API 不处理媒体内容，但未来的增强功能将包括图像字幕和视频摘要。",question1:"使用 读取器 API 的相关费用是多少？",question10:"是否可以在本地 HTML 文件上使用 读取器 API？",question11:"读取器 API 是否缓存内容？",question12:"我可以使用 读取器API 来访问登录后的内容吗？",question13:"我可以使用读取器 API 访问 arXiv 上的 PDF 吗？",question14:"图片标注在读取器中如何发挥作用？",question15:"读取器的可扩展性如何？我可以在生产中使用它吗？",question16:"Reader API 的速率限制是多少？",question2:"读取器 API 如何发挥作用？",question3:"读取器 API 是开源的吗？",question4:"读取器 API 的典型延迟是多少？",question5:"为什么我应该使用 读取器 API 而不是自己抓取页面？",question6:"读取器 API 是否支持多种语言？",question7:"如果某个网站屏蔽了 读取器 API，我该怎么办？",question8:"读取器 API 可以从 PDF 文件中提取内容吗？",question9:"读取器 API 可以处理来自网页的媒体内容吗？",title:"与读取器相关的常见问题"},fast:"快速地",fast_stream:"即时数据流",fast_stream_description:"需要快速获取数据？我们的 读取器 API 可以传输数据以最大程度地减少延迟。",free:"永远免费",free_description:"读取器 API 是免费的！它不需要信用卡或 API 密码。它不会消耗您的词元配额。",is_free:"而且它是竟然是免费的！",is_free_description:"Reader API 可免费使用，并提供灵活的速率限制和定价。它建立在可扩展的基础架构上，具有高可访问性、并发性和可靠性。我们努力成为您 LLM 的首选基础解决方案。",open:"在新标签页中打开",original_pdf:"原始 PDF",rate_limit:"速率限制",read_grounding_release_note:"阅读发布说明",reader_also_read_images:"网页上的图像会使用读取器中的视觉语言模型自动添加标题，并在输出中格式化为图像 alt 标签。这为您的下游 LLM 提供了足够的提示，以将这些图像纳入其推理和总结过程。这意味着您可以询问有关图像的问题，选择特定的图像，甚至将其 URL 转发到更强大的 VLM 进行更深入的分析！",reader_description:"将 URL 转换为 LLM 友好输入，只需在前面添加 <code>r.jina.ai</code> 即可。",reader_do_grounding:"事实核查阅读器",reader_do_grounding_explain:"新的基准端点提供端到端、近乎实时的事实核查体验。它获取给定的陈述，使用实时网络搜索结果对其进行基准化验，并返回事实性分数和使用的确切参考资料。您可以轻松对陈述进行基准化验，以减少 LLM 幻觉或提高人工编写内容的完整性。",reader_do_pdf_explain:"是的，Reader 本身支持 PDF 阅读。它兼容大多数 PDF，包括包含大量图片的 PDF，而且速度极快！结合 LLM，您可以轻松快速地构建 ChatPDF 或文档分析 AI。",reader_do_search:"搜索溯源读取器",reader_do_search_explain:"LLM 有知识限制，这意味着他们无法获取最新的世界知识。这会导致错误信息、过时的回应、幻觉和其他事实问题等问题。基础对于 GenAI 应用程序绝对必不可少。Reader 允许您使用来自网络的最新信息为您的 LLM 打下基础。只需在您的查询前面添加 https://s.jina.ai/，Reader 就会搜索网络并返回前五个结果及其 URL 和内容，每个结果都以干净、LLM 友好的文本显示。这样，您就可以始终让您的 LLM 保持最新状态，提高其事实性并减少幻觉。",reader_reads_images:"读取器也顺便识图！",reader_reads_pdf:"读取器还可以阅读 PDF！",reader_result:"读取器结果",table:{td_1_0:"读取 URL 返回其内容，用于单渠道依据",td_1_1:"20 请求每分钟",td_1_2:"200 请求每分钟",td_1_3:"根据输出词元",td_1_4:"3 秒",td_1_5:"3 秒",td_2_0:"在网络上搜索返回前 5 个结果，有助于获得世界知识和搜索依据",td_2_1:"5 请求每分钟",td_2_2:"40 请求每分钟",td_2_3:"根据所有 5 个搜索结果的输出词元数",td_2_4:"10 秒",td_2_5:"10 秒",th0:"端点",th1:"描述",th2:"无 API 密钥的速率限制",th3:"使用 API 密钥进行速率限制",th4:"词元计数方案",th5:"平均延迟",th6:"平均延迟"},title:"读取器 API",usage:"用法",usage_details_false:"仅显示基本用法",usage_details_null:"显示基本用法和高级用法",usage_details_true:"仅显示高级用法",want_higher_rate_limit:"想要更高的速率限制（高达 1000 RPM）？我们可以为您提供支持！",what_is1:"什么是读取器？",what_is_answer_long:"将网络信息输入 LLM 是打好基础的重要一步，但这可能很有挑战性。最简单的方法是抓取网页并输入原始 HTML。但是，抓取可能很复杂且经常受阻，而且原始 HTML 中充斥着标记和脚本等无关元素。读取器 API 通过从 URL 中提取核心内容并将其转换为干净的、LLM 友好的文本来解决这些问题，从而确保为您的Agent和 RAG 系统提供高质量的输入。",what_is_desc:"访问任何 URL 并提取其主要内容转换为针对 LLM 优化的文本。"},pe={confirm_message:"您的 API 密钥还剩 {_leftTokens} 个词元。将 {_numArticles} 篇文章的全文发送到重排器API，利用 {_selectedReranker} 模型去寻扎与当前页面的相关文章，这将显着消耗 API 密钥 {_APIKey} 的词元计数。您想继续吗？",confirm_title:"警告：大量消耗词元",out_of_quota:"此 API 密钥已用完词元。请为您的帐户充值或使用不同的 API 密钥。",recommend:"获取前 5 名",recommended_articles:"前 5 条类似文章"},ue={benchmark:{description0:"LlamaIndex 评估了 RAG 的向量模型和重排器器的各种组合，我们对起进行复现。研究结果显示 Jina 重排器 显着提高了搜索质量，这一优势与上游所使用的特定向量模型无关。",description1:"BIER（Benchmarking IR）评估模型的检索有效性，包括相关性和NDCG。较高的 BIER 分数与更准确的匹配和搜索结果排名相关。",description2:"通过 LoCo 基准测试，我们测量了模型对本地连贯性和上下文的理解，以及特定于查询的排名。 LoCo 分数越高，反映出识别相关信息并确定优先级的能力越好。",description3:"MTEB（多语言文本向量模型基准）总体上测试了模型在文本向量模型方面的能力，包括聚类、分类、检索和其他指标。然而，为了进行比较，我们仅使用 MTEB 的重排器任务。",title:"基准",title0:"LlamaIndex",title1:"BIER",title2:"LoCo",title3:"MTEB"},benchmark_description:"为了进行比较，我们在基准测试中纳入了 BGE (北京智源研究院)、BCE (网易有道) 和 Cohere 的其他三个领先的重排器。如下图所示，Jina 重排器 在所有相关重排类别中平均得分最高，在同行中处于明显领先地位。",benchmark_title:"性能基准测试",choose_turbo:"5倍提速的Turbo版本",choose_turbo_description:"我们还提供两个新的开源重排模型：jina-reranker-v1-turbo-en 和 jina-reranker-v1-tiny-en，后者只有 30M 个参数和 4 层。这两个新的重排器的推理速度比底座模型快 5 倍，而质量却只下降一点点。它们非常适合需要实时重排的应用程序。请阅读下面的评测。",customize_urself:"试试改变它看看响应如何变化！",customize_urself_pl:"试试改变它们看看响应如何变化！",description:"世界一流的神经检索器，可最大限度地提高搜索相关性。",description_rich:"利用我们先进的重排 API 最大限度地提高搜索相关性和 RAG 准确性。",example_input_document:"待排序候选文档示例",example_input_query:"查询示例",faq_v1:{answer1:"重排器 API 的定价与我们的向量模型 API 定价结构一致。每个新 API 密钥都会获得 100 万个免费词元。除了免费词元之外，还可以购买不同的套餐。欲了解更多详情，请访问我们的定价部分。",answer10:"是的，Jina 重排器 可以部署在 AWS 上。如果您需要在企业环境中进行本地部署，您可以通过我们的 AWS Marketplace 产品轻松实现。",answer11:"如果您对针对特定域数据量身定制的微调重排器感兴趣，请联系我们的销售团队。我们的团队将及时回复您的询问。",answer3:"主要区别在于它们的架构。就性能而言，我们推荐 jina-reranker-v1，它已经过针对竞争对手的广泛测试和基准测试。 Jina-reranker-v1 采用交叉编码器架构，而 Jina-colbert-v1 基于 ColBERTv2 架构，但将查询和文档的上下文长度扩展至 8192，实现了比原始 ColBERTv2 模型更好的性能。",answer4:"是的，jina-colbert-v1 是开源的，可以通过 Huggingface 访问。但是，jina-reranker-v1 不是开源的。",answer5:"目前，它仅支持英语。然而，一些用户报告说它也适用于中文。这可能部分是因为 jina-reranker-v1-base-en 与我们的 jina-embeddings-v2-base-zh 向量模型模型共享一些权重。",answer6:"最大查询词元长度为 512。文档没有词元限制。",answer7:"每个查询最多可以对 2048 个文档进行重排。",answer8:"与我们的向量模型 API 不同，没有批量大小的概念。每个请求只能发送一个查询文档元组，但该元组最多可以包含 2048 个候选文档。",answer9:"延迟从 100 毫秒到 7 秒不等，主要取决于文档和查询的长度。例如，使用 64 个词元的查询对 100 个包含 256 个词元的文档进行重排大约需要 150 毫秒。将文档长度增加到 4096 个词元将使时间增加到 3.5 秒。如果查询长度增加到 512 个词元，则时间进一步增加到 7 秒。",question1:"重排器 API 的费用是多少？",question10:"我可以在 AWS 上部署 Jina Reranker 吗？",question11:"你们是否提供针对特定领域数据的微调重排器？",question3:"这两个重排器有什么区别？",question4:"Jina Reranker 是开源的吗？",question5:"重排器支持多种语言吗？",question6:"查询和文档的最大长度是多少？",question7:"每个查询可以重排的最大文档数是多少？",question8:"批量大小是多少以及在一个请求中可以发送多少个查询文档元组？",question9:"对 100 个文档重排时，预计延迟会是多少？",title:"与 重排器 相关的常见问题"},feature_on_premises_description2:"在 AWS Sagemaker 上部署我们的重排模型，很快就会在 Microsoft Azure 和 Google Cloud Services 上部署，或者联系我们的销售团队，为您的虚拟私有云和本地服务器获取定制的 Kubernetes 部署。",feature_on_premises_description3:"在 AWS Sagemaker 和 Microsoft Azure 上部署 Jina Reranker，很快就会在 Google Cloud Services 上部署 Jina Reranker，或者联系我们的销售团队，为您的虚拟私有云和本地服务器获取定制的 Kubernetes 部署。",feature_solid_description:"由我们的尖端学术研究开发而成，并针对 SOTA 重排器器进行了严格测试，以确保无与伦比的性能。",how_it_works:"在搜索系统中，重排器的工作原理如下：",how_it_works_v1:{description1:"根据用户的查询，使用向量模型或BM25或TF-IDF等维度，在数据库中粗略匹配相关文档。",description2:"重排模型会获取这些初排结果，并在更精细的颗粒度上对文档和查询其进行相关性分析，同时考虑查询术语与文档内容交互等细微差别。",description3:"重排模型会将其认为最相关的结果放在顶部，从而改善搜索质量。",title1:"初始检索",title2:"重排",title3:"改善后的结果"},improve_performance:"搜索质量高人一等",improve_performance_description:"我们的评估表明，使用我们重排器的搜索系统得到了有效的改进，命中率提高了 8%，平均倒排(MRR)提高了 33%。",learning1:"了解重排器",learning1_description:"什么是重排模型？为什么向量搜索或两两余弦相似度还不够？通过我们的综合指南从头开始了解重排器。",read_more_about_benchmark:"阅读有关基准测试的更多信息",read_more_about_turbo:"了解有关涡轮增压和微型模型的更多信息",read_more_about_v2:"Jina Reranker v2 是同类最佳的重排器，于 2024 年 6 月 25 日发布；它是为 Agentic RAG 构建的。它具有函数调用支持、超过 100 种语言的多语言检索、代码搜索功能，并且比 v1 的速度提高了 6 倍。了解有关 v2 模型的更多信息。",reranker_description:"尝试我们先进的重排器 API，最大限度地提高您的搜索相关性和 RAG 准确性。免费试用！",show_v2benchmark:"显示 v2 模型的基准（最新）",table:{number_token_document:"每个文档中的词元数量",number_token_query:"查询中的词元数量",title:"以下是对一个查询和 100 个文档进行重排的时间成本（以毫秒为单位）："},title:"重排器 API",top_n:"返回最优的重排文档数量",top_n_explain:"与查询最相关的文档的数量。",try_embedding:"免费使用向量模型 API",try_reranker:"免费试用重排器 API",v2_features:{description1:"Reranker v2 支持超过 100 种语言的文档检索，无论查询语言是什么。",description2:"Reranker v2 根据自然语言查询对代码片段和函数签名进行排名，非常适合 Agentic RAG 应用程序。",description3:"Reranker v2 根据自然语言查询对最相关的表进行排名，帮助对不同的表模式进行排序并在生成 SQL 查询之前确定最相关的表模式。",title1:"多语言检索",title2:"函数调用和代码搜索",title3:"表格和结构化数据支持"},v2benchmark:{descBeir:"针对 Beir 数据集的不同重排器报告的 NDCG 10 分数",descCodeSearchNet:"CodeSearchNet 数据集中不同重排模型的 MRR 10 得分报告",descMKQA:"回忆一下 MKQA 数据集中不同重排器报告的 10 个分数",descNSText2SQL:"回顾 NSText2SQL 数据集中不同重排器报告的 3 个分数",descRTX4090:"RTX 4090 GPU 上不同重新排名模型的吞吐量（50 毫秒内检索到的文档）分数报告。",descToolBench:"召回 ToolBench 数据集中不同重排器报告的 3 个分数",titleBeir:"BEIR（不同 IR 任务的异构基准测试）",titleCodeSearchNet:"CodeSearchNet。基准测试是文档字符串和自然语言格式的查询的组合，并带有与查询相关的标记代码段。",titleMKQA:"MKQA（多语言知识问答）",titleNSText2SQL:"NSText2SQL",titleRTX4090:"Jina Reranker v2 在 RTX4090 上的吞吐量",titleToolBench:"ToolBench。该基准测试收集了超过 16,000 个公共 API 以及相应的合成生成指令，以便在单 API 和多 API 设置中使用它们。"},vs_table:{col0:"重排器",col0_1:"增强的搜索精度和相关性",col0_2:"初始、快速过滤",col0_3:"跨广泛查询的一般文本检索",col1:"向量搜索",col1_1:"详细：子文档和查询段",col1_2:"广泛：整个文档",col1_3:"中级：各种文本片段",col2:"BM25",col2_1:"高的",col2_2:"中等的",col2_3:"低的",col3_1:"不需要",col3_2:"高的",col3_3:"低，利用预建索引",col4_1:"高的",col4_2:"高的",col4_3:"不需要",col5_1:"更适合细致入微的查询",col5_2:"效率与准确性之间的平衡",col5_3:"对于广泛的查询来说一致且可靠",col6_1:"高度准确，具有深入的上下文理解",col6_2:"快速高效，准确度适中",col6_3:"高度可扩展，具有既定的功效",col7_1:"资源密集且实施复杂",col7_2:"可能无法捕获深层查询上下文或细微差别",col7_3:"对于高度具体或上下文搜索可能表现不佳",header0:"最适合场景",header1:"粒度",header2:"查询时间复杂度",header3:"索引时间复杂度",header4:"训练时间复杂度",header5:"搜索质量",header6:"优势",header7:"弱点",subtitle:"下表提供了 重排器、向量搜索和 BM25 的全面比较，突出显示了它们在各个类别中的优缺点。",title:"重排器、向量搜索和 BM25 的比较"},what_is:"什么是重排器？",what_is_answer_long:`搜索的本质就是快速有效地找到最用户想要的结果。上世纪的BM25 或 tf-idf 等关键字匹配算法已成熟用在各类搜索结果进行排名。近几年来，基于向量模型的余弦相似度大放异彩，已在许多向量数据库成为标配。但这些方法的本质都相对简单，经常会忽略掉自然语言的微妙之处，最重要的是，忽略掉文档和查询意图之间的关联信息。

“重排模型”由此而生！重排模型实际是一种高级AI模型，它从搜索中获取初始候选集（通常由基于向量/基于词元的搜索结果提供）并重新评估它们与用户搜索意图之间的相关性。重排器超越了文字的表层匹配，探索查询和文档内容之间更深层次的交互。`,what_is_answer_long_ending:"重排器可以显着提高搜索质量，因为它在子文档和子查询级别运行，这意味着它会查看各个单词和短语、它们的含义以及它们在查询和文档中如何相互关联。这会产生一组更精确且与上下文相关的搜索结果。",what_is_desc:"重排器是一种AI模型，可优化BM25搜索或向量召回的搜索结果。通过我们的文章了解更多。"},me={caption_image_desc:"生成图像的文字描述。",caption_image_title:"标题图像",description:"探索每一个像素背后的故事",example1:"该视频似乎是一段自然镜头，其中有一只迷人的白色兔子和一只蝴蝶在草地上。兔子以不同的方式与蝴蝶互动，展示了它们独特的关系。周围的自然环境提供了风景如画的背景，增强了这个简单而迷人的场景的美丽。",generate_story_desc:"根据图像创作一个故事，通常以人物的对话或独白为特色。",generate_story_title:"生成故事",intro1:"独领风骚的图像视频理解AI",json_image_desc:"使用预定义的架构从图像生成结构化 JSON 格式。这允许从图像中提取特定的数据。",json_image_title:"从图像中提取 JSON",summarize_video_desc:"生成视频的简洁摘要，突出显示关键事件。",summarize_video_title:"总结视频",visual_q_a_desc:"根据图像内容回答查询。",visual_q_a_title:"视觉问答"},ge={ask_on_current_page:"向当前页提问...",find_solution:"生成相应的解决方案...",hint:"搜索产品、新闻和您的问题",hotkey:"按 / 键可在本页提问",hotkey1:"按",hotkey2:"切换",hotkey_long1:"在任何页面，按下",hotkey_long3:"打开搜索栏",more_results:"另外 {_numMore} 个结果",placeholder:"对本页内容提问",proposing_solution:"根据当前页面内容生成答案...",required:"请更详细地描述您的问题。",results:"结果"},Ae={description:"导航、交互、优化：重新定义产品搜索"},he={description:"弥合现有搜索底座设施中的语义差距"},Ie={"Hacker News":"HN新闻",LinkedIn:"领英",facebook:"脸书",reddit:"红迪网",rss:"RSS订阅",share_btn:"分享",twitter:"X（前推特）"},be={click_to_learn_more:"点击了解更多",contextualization:"上下文理解",contextualization_desc:"重排器根据查询的深度上下文相关性调整初始搜索结果。这可以优化排名，以更好地匹配用户可能认为有用的内容。",coreInfra:"核心基础设施",coreInfra_desc:"Core infra 提供了一个云原生层，用于在公共云和本地开发、部署和编排搜索底座模型，使服务能够毫不费力地扩大和缩小。",embedding_serving:"大模型向量部署",embedding_serving_description:"使用云原生技术通过强大、可扩展的微服务部署大模型向量推理。",embedding_tech:"向量模型",embedding_tech_description:`在Jina AI，我们正通过向量模型技术彻底转变人工智能应用的面貌。这种技术能够作为一种统一的手段，有效地表达和压缩多种类型的数据，同时确保关键信息不会丢失。我们的核心目标是将复杂的数据集转化为普遍易懂的向量模型格式，为精准和深入的人工智能分析提供支持。

向量模型在AI领域扮演着基础但至关重要的角色。在精确图像识别和语音识别等领域，它们帮助我们识别更为微妙的细节和差异。在自然语言处理中，它们能增强对上下文和情感的理解，使对话式AI和语言翻译工具更加准确。此外，在构建复杂的推荐系统时，这些系统需要对不同内容形式（如文本、音频和视频）的用户偏好有深入的了解，而向量模型在这方面发挥着关键作用。`,embedding_tuning:"大模型向量精调",embedding_tuning_description:"通过代入专业知识和行业数据来训练高质量的大模型向量，以增强特定任务上的性能。",embeddings:"向量模型",embeddings_desc:"向量模型是现代搜索系统的基石，将多模态数据表示为数字向量。此过程使内容的理解更加细致入微，远超简单的关键字匹配。",for_developers:"对于开发者",for_enterprise:"对于企业",for_power_users:"对于高级用户",grounding:"溯源",grounding_desc:"读取器通过 LLM 完善输入和结果。它们提高了最终答案的质量、可读性和真实性。",model_serving:"模型部署",model_serving_description:"在生产环境中部署调优模型，通常需要大量资源，例如 GPU 托管。 MLOps 强调以可扩展、高效和可靠的方式服务中型到大型模型。",model_tuning:"模型调优",model_tuning_description:"于特定任务的数据集上调整预训练模型的参数，以提高其性能并使其适应特定应用程序。",personalization:"个性化",personalization_desc:"使用用户指令引导的合成数据自动训练特定领域的向量化和重排器。",preprocessing:"预处理",preprocessing_desc:"预处理包括清理、规范化和将原始数据转换为搜索系统可理解的格式。",promptOps:"提示词工作流",promptOps_desc:"Prompt Ops 改进了搜索系统的输入和输出，包括用于查询扩展、LLM 输入和结果重写的输入和输出。这确保搜索更容易理解，结果也更好。",prompt_serving:"提示词部署",prompt_serving_description:"通过 API 包装和提供提示，无需托管重型模型。该 API 调用公共大型语言模型服务并处理操作链中输入和输出的编排。",prompt_tech:"提示词和智能体工程",prompt_tech_description:`在Jina AI，我们深知提示词工程在与大型语言模型（LLM）交流中的重要性。随着这些模型的不断进化，我们的提示词也变得越来越复杂，涵盖了深入的推理和逻辑思维。这种进步彰显了LLM和提示词工程之间相互加强的关系。

展望未来，我们相信LLM将成为编译器的角色，而提示词则将演变成新型的编程语言。这意味着，未来的技术技能可能更侧重于掌握提示词的艺术，而不仅仅是传统的编程技巧。在Jina AI，我们的目标是引领这场技术变革，通过精通这种新兴的“语言”，让先进的人工智能变得更加易于理解和应用。`,prompt_tuning:"提示词调优",prompt_tuning_description:"精心设计和完善输入提示的过程，以引导其输出达到特定的、期望的响应。",representation:"表征学习",representation_desc:"向量化将多模态数据转换为统一的向量格式。这使搜索系统能够理解和分类简单关键字以外的内容。",rerankers:"重排器",rerankers_desc:"重排器会从向量模型中获取初始结果并对其进行优化，确保向用户呈现最相关的结果。这对于提供符合用户意图的高质量搜索结果至关重要。"},fe={care_most:"你最关心什么？",care_most_options:{accuracy:"准确性",cost:"成本",other:"其他",scalability:"吞吐量",speed:"速度"},care_most_required:"选择API服务时，您最关心什么？",company_size:"贵公司规模有多大？",company_size_required:"告诉我们您公司的规模有助于我们提供更好的服务",company_url:"贵公司的网站是什么？",company_url_required:"告诉我们您公司的网站有助于我们提供更好的服务",contactName:"你的名字",contactName_required:"我们该如何称呼你呢？",contactTitle:"您在公司内如何任职？",contactTitle_required:"您的职位名称为必填项",contact_us:"联系我们",domain_required:"告诉我们您的工作领域有助于我们提供更好的服务",email:"电子邮件",email_contact:"您的联系邮箱",email_invalid:"电子邮件无效",email_required:"电子邮件为必填项",fine_tuned_embedding:"想要您私域数据专属向量模型？我们随时恭候！",fine_tuned_reranker:"想要您私域数据上的专属重排器？来！我们讨论一下！",full_survey:"参加完整的调查并获得我们团队的更快回复",get_new_key:"获取 API 密钥",get_update_blog_posts:"提醒我博客文章的最新更新",get_update_embeddings:"提醒我向量模型的最新消息",send:"发送",sign_up:"订阅",subscribe:"订阅",tell_domain:"您的领域或微调方向",usage_type:"哪种用法最能描述您？",usage_type_options:{other:"其他",poc:"原型设计或概念验证",production:"生产环境",research:"研究阶段"},usage_type_required:"告诉我们您的使用类型有助于我们提供更好的服务",used_product:"您使用的是哪个模型？",used_product_required:"选择您正在使用或您感兴趣的模型"},we={description:"增强你的 LLM 并将其推向极限"},Pe="目录",ke={advance_usage:"使用 POST 请求获取更多功能",basic_usage:"使用 GET 请求直接返回词元数量",basic_usage_explain:"您可以简单地发送一个 GET 请求来计算文本中的词元数量。",change_content:"更改“content”参数并查看实时结果",chars:"字符",chinese:"中文",chunk:"切块",chunk_all:"所有区块",chunking:"对长文档进行切块，快如闪电鞭！",chunking_explain:"您还可以使用切分器将长文档分割成较小的块，从而更轻松地在向量模型或重排器中处理它们。我们利用常见的结构线索并构建了一套规则和启发式方法，这些规则和启发式方法在不同类型的内容（例如 Markdown、HTML、LaTeX 和 CJK 语言）中表现良好。",chunking_short:"切块",chunks_in_total:"总共 {_numChunks} 个切块",count_tokens_hint:"<b>{_numTokens}</b> 个词元，{_numChars} 个字符。",description:"将长文本切分成块并进行标记。",description_long:"我们的切分器对于帮助 LLM 在上下文限制内管理输入以及优化模型性能至关重要。它允许开发人员计算词元并提取相关文本段，从而确保高效的数据处理和成本管理。",description_long1:"用于将长文本分割成块并进行切词的免费 API。",english:"英语",explain:"分段器是将文本转换为词元或块的关键组件，它们是向量模型/重排器或 LLM 处理的基本数据单位。词元可以表示整个单词、单词的一部分，甚至是单个字符。",faq_v1:{answer1:"切分器可免费使用。通过提供您的 API 密钥，您可以访问更高的速率限制，并且不会向您的密钥收费。",answer10:"除了西方语言外，分块技术还适用于中文、日语和韩语。",answer2:"如果没有 API 密钥，您可以以 20 RPM 的速率限制访问切分器。",answer3:"使用 API 密钥，您可以以 200 RPM 的速率限制访问切分器。对于高级付费用户，速率限制为 1000 RPM。",answer4:"不可以，您的 API 密钥仅用于访问更高的速率限制。",answer5:"是的，切分器是多语言的，支持超过 100 种语言。",answer6:"GET 请求仅用于计算文本中的词元数，可让您轻松将其作为计数器集成到应用程序中。POST 请求支持更多参数和功能，例如返回第一个/最后一个 N 个词元。",answer7:"每个请求最多可以发送 64k 个字符。",answer8:"切块功能可根据常见的结构线索将长文档分割成较小的块，从而确保将文本准确地分割成有意义的块。本质上，它是一个（大！）正则表达式模式，可根据某些通常与语义边界一致的句法特征（例如句子结尾、段落分隔符、标点符号和某些连词）对文本进行分割。它不是语义切块。这个（大）正则表达式在正则表达式的限制范围内尽可能强大。它平衡了复杂性和性能。虽然正则表达式无法实现真正的语义理解，但它可以通过常见的结构线索很好地近似上下文。",answer9:"如果输入包含特殊词元，我们的切分器会将它们放入“special_tokens”字段中。这样您就可以轻松识别它们并根据下游任务进行相应的处理，例如在将文本输入 LLM 之前将其删除以防止注入攻击。",question1:"切分器的价格是多少？",question10:"分块是否支持英语以外的其他语言？",question2:"如果我不提供 API 密钥，速率限制是多少？",question3:"如果我提供 API 密钥，速率限制是多少？",question4:"您会从我的 API 密钥中收取词元吗？",question5:"切分器是否支持多种语言？",question6:"GET 和 POST 请求有什么区别？",question7:"每个请求可以切词的最大长度是多少？",question8:"切块功能如何工作？是语义切块吗？",question9:"如何在切分器中处理诸如“endoftext”之类的特殊词元？",title:"与分段器相关的常见问题"},free_api:"切分器可免费使用。通过提供您的 API 密钥，您可以访问更高的速率限制，并且不会向您的密钥收费。",input_text:"输入文本",is_free:"切分器是免费的！",is_free_description:"通过提供您的 API 密钥，您可以访问更高的速率限制，并且不会对您的密钥收费。",japanese:"日语",korean:"韩语",parameters:{auth_token:"添加 API 密钥以实现更高的速率限制",auth_token_explain:"输入您的Jina API密钥以访问更高的速率限制。有关最新速率限制信息，请参阅下表。",head:"返回前 N 个词元",head_explain:"返回给定内容的前 N 个词元。不包括恰好切在的边界点。不能与“tail”一起使用。",learn_more:"了解更多",max_chunk_length:"每个块的最大长度",max_chunk_length_explain:"每个块中的最大字符数。实际上，如果文本中有自然边界，块长度可以小于此值。",return_chunks:"返回切块",return_chunks_explain:"将输入切为具有语义意义的片段，根据常见的结构线索，使用启发式规则适应各种文本类型和边缘情况。",return_tokens:"是否返回分词结果",return_tokens_explain:"在响应中返回词元及其对应的 id。切换以查看结果可视化。",tail:"返回最后 N 个词元",tail_explain:"返回给定内容的最后 N 个词元。不包括恰好切在的边界点。不能与“head”一起使用。",type:"切分器",type_explain:"选择要使用的切分器。",used_by_models:"用于 {_usedBy}。"},remove_boundary_cues:"删除换行符",remove_boundary_cues_explain:"从输入中删除所有换行符（主要边界提示），这会使问题更具挑战性，并查看响应如何变化！",show_space:"显示前导/尾随空格",table:{td_1_0:"对文本进行分词、计数并获取第一个/最后一个 N 个词元。",td_1_1:"20 转/分",td_1_2:"200 转/分",td_1_3:"1000 转/分",td_1_4:"免费",td_1_5:"800毫秒"},title:"切分器 API",token_index:"词元代码：{_index}",usage:"用法",visualization:"可视化",what_is:"什么是切分器？"},ye={cta:"翻译成{_lang}代码",select_language:"语言"},ve={description:"您只需要一个 Python 向量数据库 - 不多也不少"},Le="zzz",xe={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:t,api_general_faq:i,autotune:a,best_banner:_,beta:r,billing_general_faq:o,blog_tags:s,cclicence:c,classifier:d,clip_as_service:l,cloud:p,contact_us_page:u,copy:m,copy_to_clipboard_success:g,dalle_flow:A,"dev-gpt":{description:"您的虚拟开发团队"},disco_art:h,doc_array:I,download:b,embedding:f,embeddings:w,faq:P,faq_button:k,farewell:y,finetuner:v,finetuner_plus:L,finetuning:x,footer:q,get_new_key:M,github:R,header:J,hub:S,huggingface:j,impact_snapshots:C,inference:z,integrations:T,internship_faq:G,internship_page:B,jcloud:U,jerboa:O,jina:E,jina_chat:D,key_manager:N,lab_dialog:F,landing_page:H,langchain_serve:K,legal_page:W,model_graph:Y,news_page:X,newsroom_page:Q,notice:V,open_day:Z,open_day_faq:$,open_gpt:ee,paywall:ne,powered_by:te,print:ie,project_status:ae,prompt_perfect:_e,promptperfect:re,purchase:oe,purchase_now:se,rate_limit:ce,rationale:de,reader:le,recommender:pe,reranker:ue,scenex:me,searchbar:ge,searchscape:Ae,semantic:he,share:Ie,spectrum:be,subscribe_system:fe,think_gpt:we,toc:Pe,tokenizer:ke,translator:ye,vectordb:ve,zzz:Le};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,t as about_us_page,i as api_general_faq,a as autotune,_ as best_banner,r as beta,o as billing_general_faq,s as blog_tags,c as cclicence,d as classifier,l as clip_as_service,p as cloud,u as contact_us_page,m as copy,g as copy_to_clipboard_success,A as dalle_flow,xe as default,h as disco_art,I as doc_array,b as download,f as embedding,w as embeddings,P as faq,k as faq_button,y as farewell,v as finetuner,L as finetuner_plus,x as finetuning,q as footer,M as get_new_key,R as github,J as header,S as hub,j as huggingface,C as impact_snapshots,z as inference,T as integrations,G as internship_faq,B as internship_page,U as jcloud,O as jerboa,E as jina,D as jina_chat,N as key_manager,F as lab_dialog,H as landing_page,K as langchain_serve,W as legal_page,Y as model_graph,X as news_page,Q as newsroom_page,V as notice,Z as open_day,$ as open_day_faq,ee as open_gpt,ne as paywall,te as powered_by,ie as print,ae as project_status,_e as prompt_perfect,re as promptperfect,oe as purchase,se as purchase_now,ce as rate_limit,de as rationale,le as reader,pe as recommender,ue as reranker,me as scenex,ge as searchbar,Ae as searchscape,he as semantic,Ie as share,be as spectrum,fe as subscribe_system,we as think_gpt,Pe as toc,ke as tokenizer,ye as translator,ve as vectordb,Le as zzz};
