const t={PRODUCT_DESCRIPTION:n=>{const{normalize:r}=n;return r(["Мы предоставляем лучшие в своем классе встраивания, средства изменения ранжирования, LLM-считыватели и быстрые оптимизаторы, а также новаторский поисковый искусственный интеллект для мультимодальных данных."])},SEO_TAG_LINE:n=>{const{normalize:r}=n;return r(["Ваш Фонд Поиска, Сверхзаряженный."])},about_us_page:{approach:n=>{const{normalize:r}=n;return r(["Наш подход"])},approach_connect_dots:n=>{const{normalize:r}=n;return r(["Соединение точек: опытные пользователи для предприятий"])},approach_connect_dots_description:n=>{const{normalize:r}=n;return r(["Итак, почему для нашей модели, ориентированной на предприятие, так важна ориентация на опытных пользователей? Потому что речь идет об установлении ранних отношений. Угождая опытным пользователям сейчас, мы наводим мосты с предприятиями, на которые они будут влиять в будущем. Это стратегическая игра — долгосрочные инвестиции, чтобы наши корпоративные предложения оставались в центре внимания, когда эти опытные пользователи поднимаются на руководящие должности в организациях."])},approach_content1:n=>{const{normalize:r}=n;return r(["В быстро развивающемся мире ИИ стратегии должны быть одновременно гибкими и дальновидными. В то время как наше основное предложение по-прежнему сосредоточено на предприятиях, ландшафт ИИ изменился таким образом, что это требует переосмысления нашего подхода к привлечению клиентов. Вот почему введение опытных пользователей в качестве точки входа в нашу воронку не только инновационно, но и имеет решающее значение для нашего устойчивого роста в корпоративном секторе."])},approach_content2:n=>{const{normalize:r}=n;return r(["В Jina AI наша стратегия заключается в том, чтобы действовать на опережение, а не реагировать. Включение опытных пользователей в качестве точки входа в воронку гарантирует, что мы не только улавливаем текущие рыночные тенденции, но и стратегически готовы к будущему росту предприятия. Наша приверженность предприятиям остается непоколебимой; однако наш подход к их достижению является инновационным, надежным и, прежде всего, дальновидным."])},approach_content4:n=>{const{normalize:r}=n;return r(['Каждый хочет лучшего поиска. В Jina AI мы обеспечиваем лучший поиск, предоставляя <span class="text-primary text-bold">Search Foundation</span>, который состоит из Embeddings, Rerankers, Reader и Prompt Ops. Эти компоненты работают сообща, чтобы произвести революцию в том, как мы ищем и понимаем данные.'])},approach_miss_mark:n=>{const{normalize:r}=n;return r(["Почему традиционные MLOps промахиваются"])},approach_miss_mark_description:n=>{const{normalize:r}=n;return r(["Хотя приток опытных пользователей значителен, традиционные инструменты MLOps плохо приспособлены для удовлетворения их потребностей. Эти инструменты напоминают использование трактора для передвижения по городским улицам — они тяжелые и часто чрезмерные. Разработчикам нового поколения требуются гибкие, интуитивно понятные инструменты, дополняющие их быстрый темп разработки."])},approach_new_paradigm:n=>{const{normalize:r}=n;return r(["Технология на основе подсказок: новая парадигма"])},approach_new_paradigm_description:n=>{const{normalize:r}=n;return r([`2023 год ознаменовался значительным изменением: появлением технологий, основанных на подсказках. Упростив процесс разработки ИИ, он демократизировал доступ к инструментам ИИ. Теперь те, у кого нет обширного опыта программирования, называемые «опытными пользователями», могут заниматься разработкой ИИ без крутых кривых обучения, связанных с такими инструментами, как Pytorch, Docker или Kubernetes.

Проводя параллель, это похоже на эволюцию персональных компьютеров. Первоначально компьютерами управляли только технические специалисты. Но с появлением удобных интерфейсов в нем могла участвовать более широкая аудитория. Сегодня, с технологией, основанной на подсказках, мы наблюдаем аналогичную демократизацию в ИИ.`])},awards:n=>{const{normalize:r}=n;return r(["Награды и признание"])},berlin:n=>{const{normalize:r}=n;return r(["Берлин, Германия"])},berlin_address:n=>{const{normalize:r}=n;return r(["Prinzessinnenstraße 19-20, 10969 Берлин, Германия"])},berlin_address2:n=>{const{normalize:r}=n;return r(["Geschäftsanschrift: Leipzigerstr. 96, 10117 Берлин, Германия"])},bj:n=>{const{normalize:r}=n;return r(["Пекин, Китай"])},bj_address:n=>{const{normalize:r}=n;return r(["Уровень 5, корпус 6, № 48, Западная улица Хайдянь, Пекин, Хайдянь, Китай"])},brochure_info:n=>{const{normalize:r}=n;return r(["Ваш путеводитель по нашей компании ждет"])},description:n=>{const{normalize:r}=n;return r(["Будущее начинается здесь."])},download_brochure1:n=>{const{normalize:r}=n;return r(["Скачать брошюру"])},download_docarray_logo:n=>{const{normalize:r}=n;return r(["Загрузите логотип DocArray"])},download_docarray_logo_desc:n=>{const{normalize:r}=n;return r(["Получите доступ к логотипу DocArray — проекту с открытым исходным кодом, инициированному Jina AI и предоставленному Linux Foundation в декабре 2022 года. Доступно в светлом и темном режимах, в форматах PNG и SVG."])},download_jina_logo:n=>{const{normalize:r}=n;return r(["Загрузите логотип Jina AI"])},download_jina_logo_desc:n=>{const{normalize:r}=n;return r(["Получите логотип Jina AI как в светлом, так и в темном режимах, доступный в форматах PNG и SVG. Этот логотип является зарегистрированной торговой маркой в ​​Ведомстве интеллектуальной собственности Европейского Союза (EUIPO)."])},download_logo:n=>{const{normalize:r}=n;return r(["Скачать логотипы"])},employees:n=>{const{normalize:r}=n;return r(["Сотрудники сегодня"])},empower_developers:n=>{const{normalize:r}=n;return r(["Расширение возможностей разработчиков"])},fastApiCaption:n=>{const{normalize:r}=n;return r(["С 2021 года пожертвовал более 20 000 долларов."])},founded:n=>{const{normalize:r}=n;return r(["Основан"])},founded_in:n=>{const{normalize:r}=n;return r(["Основан в"])},investors:n=>{const{normalize:r}=n;return r(["Наши инвесторы"])},linuxFoundationCaption:n=>{const{normalize:r}=n;return r(["Вносит ежегодный взнос в размере 10 000 долларов США, начиная с 2022 года."])},many:n=>{const{normalize:r}=n;return r(["Много"])},media:{video:n=>{const{normalize:r}=n;return r(["Видео интервью"])}},mission:n=>{const{normalize:r}=n;return r(["Наша миссия"])},mission_content1:n=>{const{normalize:r}=n;return r(["Мы. Наши ключевые технологии, включая быструю настройку, оперативное обслуживание, настройку моделей и обслуживание моделей, воплощают нашу приверженность демократизации доступа к ИИ. Посредством нашей инициативы с открытым исходным кодом мы стремимся способствовать инновациям, сотрудничеству и прозрачности, обеспечивая масштабируемые, эффективные и надежные решения. Jina AI — это больше, чем просто компания; это сообщество, призванное дать компаниям возможность решать динамичные задачи цифровой эпохи и процветать в своих областях."])},mission_content2:n=>{const{normalize:r}=n;return r(["В основе Jina AI лежит наша миссия — стать порталом к ​​мультимодальному ИИ для самых разных клиентов: от опытных пользователей и разработчиков до предприятий. Мы глубоко верим в силу открытого исходного кода и стремимся создавать передовые и доступные инструменты для сообщества искусственного интеллекта. Наши ключевые технологии, в том числе быстрая настройка, оперативное обслуживание, встраивание-настройка и встраивание-обслуживание, воплощают нашу приверженность демократизации доступа к ИИ. Посредством нашей инициативы с открытым исходным кодом мы стремимся способствовать инновациям, сотрудничеству и прозрачности, обеспечивая масштабируемые, эффективные и надежные решения. Jina AI — это больше, чем просто компания; это сообщество, призванное дать компаниям возможность решать динамичные задачи цифровой эпохи и процветать в своих областях."])},mission_content3:n=>{const{normalize:r}=n;return r(["Наша миссия в Jina AI — возглавлять развитие мультимодального искусственного интеллекта с помощью инновационных технологий внедрения и подсказок, уделяя особое внимание таким областям, как обработка естественного языка, анализ изображений и видео, а также кросс-модальное взаимодействие данных. Эта специализация позволяет нам предоставлять уникальные решения, которые превращают сложные данные из нескольких источников в действенные идеи и новаторские приложения."])},mit_report_title:n=>{const{normalize:r}=n;return r(["Мультимодальность: новый рубеж ИИ"])},mit_techreview:n=>{const{normalize:r}=n;return r(["Обзор технологий Массачусетского технологического института"])},numfocusCaption:n=>{const{normalize:r}=n;return r(["Регулярно жертвует каждый месяц, начиная с 2022 года."])},office:n=>{const{normalize:r}=n;return r(["Наши офисы"])},otherProjectsCaption:n=>{const{normalize:r}=n;return r(["Пожертвовал более 3000 долларов через спонсорство Github."])},our_answer:n=>{const{normalize:r}=n;return r(["Абсолютно, Ян. Мы работаем над этим, строим мосты в будущее мультимодального ИИ!"])},pythonSoftwareFoundationCaption:n=>{const{normalize:r}=n;return r(["Предоставил единовременное пожертвование в размере 10 000 долларов и спонсировал несколько мероприятий PyCon, в том числе в Германии, Италии, Китае и США."])},sefo:{layer0:n=>{const{normalize:r}=n;return r(["Приложения для конечных пользователей"])},layer1:n=>{const{normalize:r}=n;return r(["РАГ / оркестровка"])},layer3:n=>{const{normalize:r}=n;return r(["Графический процессор / мобильные / периферийные / локальные вычисления"])}},segmentFaultCaption:n=>{const{normalize:r}=n;return r(["Сделал единовременное пожертвование в размере 6000 долларов."])},show_position:n=>{const{normalize:r}=n;return r(["Как искать фундаментальные позиции в экосистеме?"])},stats_1:n=>{const{normalize:r}=n;return r(["Компания Jina AI, основанная в феврале 2020 года, быстро стала мировым пионером в области мультимодальных технологий искусственного интеллекта. В течение впечатляющих 20 месяцев мы успешно привлекли 37,5 млн долларов, что подтверждает нашу сильную позицию в индустрии искусственного интеллекта. Наша новаторская технология с открытым исходным кодом на GitHub позволила более чем 40 000 разработчиков по всему миру беспрепятственно создавать и развертывать сложные мультимодальные приложения."])},stats_2:n=>{const{normalize:r}=n;return r(["В 2023 году мы добились значительных успехов в совершенствовании инструментов создания ИИ, основанных на мультимодальных технологиях. Эта инновация принесла пользу более чем 250 000 пользователей по всему миру, удовлетворяя множество уникальных бизнес-требований. От содействия росту бизнеса и повышения операционной эффективности до оптимизации затрат — Jina AI стремится помочь компаниям преуспеть в эпоху мультимодальных перевозок."])},stats_4:n=>{const{normalize:r}=n;return r(['Jina AI, основанная в 2020 году в Берлине, является ведущей компанией в сфере поискового искусственного интеллекта. Мы предоставляем <span class="text-primary text-bold">Search Foundation</span>, ядро ​​для GenAI и мультимодальных приложений. Наша миссия — помочь предприятиям и разработчикам использовать мультимодальные данные для создания ценности с помощью лучшего поиска. Как коммерческая компания с открытым исходным кодом, мы любим открытые инновации.'])},stats_v1:n=>{const{normalize:r}=n;return r(["Поиск/акк"])},subtitle:n=>{const{normalize:r}=n;return r(["Революционное создание контента с помощью решений, созданных на основе искусственного интеллекта, чтобы открыть безграничные возможности. Формирование будущего контента, созданного искусственным интеллектом, и расширение человеческого творчества."])},sues_und_sauer:n=>{const{normalize:r}=n;return r(["Süẞ & Sauer"])},sues_und_sauer_tooltip:n=>{const{normalize:r}=n;return r(["Süß-Sauer, популярный (хотя и стереотипный) вкус в немецко-китайской кухне, означает сладкий и кислый. Это метафора взлетов и падений стартап-жизни."])},sz:n=>{const{normalize:r}=n;return r(["Шэньчжэнь, Китай"])},sz_address:n=>{const{normalize:r}=n;return r(["402, этаж 4, технологическое здание Фуань, Шэньчжэнь Наньшань, Китай"])},team:n=>{const{normalize:r}=n;return r(["Внутри портала Джины ИИ"])},team_content1:n=>{const{normalize:r}=n;return r(["Из разных уголков земного шара мы строим будущее искусственного интеллекта. Наши различные точки зрения обогащают нашу работу, порождая инновации. На этом портале мы раскрываем свою индивидуальность и страстно преследуем свои мечты. Добро пожаловать на портал будущего искусственного интеллекта."])},team_join:n=>{const{normalize:r}=n;return r(["Присоединяйтесь к нам"])},team_size:n=>{const{normalize:r}=n;return r(["На этих фотографиях — наши бывшие коллеги и стажеры — мы ценим каждого из них."])},technologies:n=>{const{normalize:r}=n;return r(["Технологии"])},title:n=>{const{normalize:r}=n;return r(["О Джине А.И."])},title0:n=>{const{normalize:r}=n;return r(["Будущее"])},title1:n=>{const{normalize:r}=n;return r(["Старт"])},title2:n=>{const{normalize:r}=n;return r(["Здесь"])},title3:n=>{const{normalize:r}=n;return r(["Начинается здесь"])},understand_our_strength:n=>{const{normalize:r}=n;return r(["Поймите нашу силу"])},understand_our_view2:n=>{const{normalize:r}=n;return r(["Понимание Фонда Поиска"])},users:n=>{const{normalize:r}=n;return r(["Пользователи зарегистрированы"])},value:n=>{const{normalize:r}=n;return r(["Наши награды"])},value_content1:n=>{const{normalize:r}=n;return r(["Мы не останавливаемся. Мы не идем на компромисс. Мы стремимся к совершенству."])},vision:n=>{const{normalize:r}=n;return r(["Наша миссия"])},vision_content1:n=>{const{normalize:r}=n;return r(["Вдохновленный выводом Яна Лекуна о том, что «"])},vision_content3:n=>{const{normalize:r}=n;return r(['Будущее искусственного интеллекта — <span class="text-primary text-bold">мультимодальное</span>, и мы являемся его частью. Мы понимаем, что предприятия сталкиваются с проблемами при использовании мультимодальных данных. В ответ мы стремимся к тому, чтобы <span class="text-primary text-bold">Search Foundation</span> помогал предприятиям и разработчикам лучше осуществлять поиск и использовать мультимодальные данные для развития бизнеса.'])},yannlecun_quote:n=>{const{normalize:r}=n;return r(["Система искусственного интеллекта, обученная только словам и предложениям, никогда не приблизится к человеческому пониманию."])}},api_general_faq:{answer1:n=>{const{normalize:r}=n;return r(["Да, один и тот же ключ API действителен для всех продуктов базы поиска от Jina AI. Это включает в себя API-интерфейсы внедрения, изменения рейтинга, чтения и тонкой настройки с токенами, совместно используемыми всеми службами."])},answer12:n=>{const{normalize:r}=n;return r(["Мы придерживаемся строгой политики конфиденциальности и не используем вводимые пользователем данные для обучения наших моделей."])},answer3:n=>{const{normalize:r}=n;return r(["Да, использование токенов можно отслеживать на вкладке «Купить токены», введя свой ключ API, что позволяет просматривать историю использования и оставшиеся токены."])},answer4:n=>{const{normalize:r}=n;return r(["Если вы потеряли пополненный ключ и хотите его восстановить, обратитесь за помощью в службу поддержки AT jina.ai, указав свой зарегистрированный адрес электронной почты."])},answer5:n=>{const{normalize:r}=n;return r(["Нет, наши ключи API не имеют срока действия. Однако, если вы подозреваете, что ваш ключ был скомпрометирован, и хотите удалить его или перенести его токены на новый ключ, обратитесь за помощью в нашу службу поддержки."])},answer6:n=>{const{normalize:r}=n;return r(["Это связано с тем, что наша бессерверная архитектура разгружает определенные модели в периоды низкой нагрузки. Первоначальный запрос активирует или «прогревает» модель, что может занять несколько секунд. После этой первоначальной активации последующие запросы обрабатываются гораздо быстрее."])},question1:n=>{const{normalize:r}=n;return r(["Могу ли я использовать один и тот же ключ API для встраивания, изменения рейтинга, чтения и тонкой настройки API?"])},question12:n=>{const{normalize:r}=n;return r(["Используются ли входные данные пользователя для обучения ваших моделей?"])},question3:n=>{const{normalize:r}=n;return r(["Могу ли я отслеживать использование токена моего ключа API?"])},question4:n=>{const{normalize:r}=n;return r(["Что мне делать, если я забуду свой ключ API?"])},question5:n=>{const{normalize:r}=n;return r(["Срок действия ключей API истекает?"])},question6:n=>{const{normalize:r}=n;return r(["Почему первый запрос у некоторых моделей медленный?"])},title:n=>{const{normalize:r}=n;return r(["Общие вопросы, связанные с API"])}},autotune:{base_model:n=>{const{normalize:r}=n;return r(["Базовая модель для доводки"])},check_data:n=>{const{normalize:r}=n;return r(["Скачать синтетические данные"])},check_model:n=>{const{normalize:r}=n;return r(["Скачать доработанную модель"])},data_size:n=>{const{normalize:r}=n;return r(["Созданы синтетические данные"])},description:n=>{const{normalize:r}=n;return r(["Получите точно настроенные встраивания для любого желаемого домена."])},description_long:n=>{const{normalize:r}=n;return r(["Просто сообщите нам, в каком домене вы хотите, чтобы ваши внедрения преуспели, и мы автоматически предоставим готовую к использованию, точно настроенную модель внедрения для этого домена."])},does_it_work_tho:n=>{const{normalize:r}=n;return r(["Но работает ли это?"])},does_it_work_tho_explain:n=>{const{normalize:r}=n;return r(["Автоматическая точная настройка дает волшебное обещание предоставить точно настроенные встраивания для любого домена, который вы захотите. Но действительно ли это работает? Это вполне обоснованное сомнение. Чтобы выяснить это, мы протестировали его на различных доменах и базовых моделях. Посмотрите результаты, собранные вишнями и лимонами ниже."])},domain_instruction:n=>{const{normalize:r}=n;return r(["Инструкция домена"])},embedding_provider:n=>{const{normalize:r}=n;return r(["Выберите базовую модель внедрения"])},eval_evaluation:n=>{const{normalize:r}=n;return r(["Проверка"])},eval_map:n=>{const{normalize:r}=n;return r(["КАРТА"])},eval_mrr:n=>{const{normalize:r}=n;return r(["МРР"])},eval_ndcg:n=>{const{normalize:r}=n;return r(["НДЦГ"])},eval_performance_before_after:n=>{const{normalize:r}=n;return r(["Производительность при синтетической проверке, установленной до и после тонкой настройки"])},eval_syntheticDataSize:n=>{const{normalize:r}=n;return r(["Общий"])},eval_test:n=>{const{normalize:r}=n;return r(["Реальные данные для тестирования"])},eval_training:n=>{const{normalize:r}=n;return r(["Обучение"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["Эта функция в настоящее время находится на стадии бета-тестирования и стоит 1 миллион токенов за каждую настроенную модель. Вы можете использовать существующий ключ API из API внедрения/переранжирования, если в нем достаточно токенов, или вы можете создать новый ключ API, который включает 1 миллион бесплатных токенов."])},answer10:n=>{const{normalize:r}=n;return r(["В данный момент нет. Обратите внимание, что эта функция все еще находится в стадии бета-тестирования. Публичное хранение точно настроенных моделей и синтетических данных в центре моделей Hugging Face помогает нам и сообществу оценить качество обучения. В будущем мы планируем предложить вариант частного хранения."])},answer11:n=>{const{normalize:r}=n;return r(["Поскольку все доработанные модели загружаются в Hugging Face, вы можете получить к ним доступ через SentenceTransformers, просто указав имя модели."])},answer12:n=>{const{normalize:r}=n;return r(["Пожалуйста, проверьте папку со спамом. Если вы все еще не можете его найти, свяжитесь с нашей службой поддержки, используя указанный вами адрес электронной почты."])},answer2:n=>{const{normalize:r}=n;return r(["Вам не нужно предоставлять какие-либо данные для обучения. Просто опишите свой целевой домен (домен, для которого вы хотите оптимизировать точно настроенные внедрения) на естественном языке или используйте URL-адрес в качестве ссылки, и наша система сгенерирует синтетические данные для обучения модели."])},answer3:n=>{const{normalize:r}=n;return r(["Около 30 минут."])},answer4:n=>{const{normalize:r}=n;return r(["Точно настроенные модели и синтетические данные хранятся публично в хабе моделей Hugging Face."])},answer5:n=>{const{normalize:r}=n;return r(["Система использует API Reader для получения контента по URL-адресу. Затем он анализирует контент, чтобы обобщить тон и предметную область, которые он использует в качестве ориентиров для создания синтетических данных. Следовательно, URL-адрес должен быть общедоступным и представлять целевой домен."])},answer6:n=>{const{normalize:r}=n;return r(["Да, вы можете настроить модель для языка, отличного от английского. Система автоматически определяет язык инструкций вашего домена и соответствующим образом генерирует синтетические данные. Мы также рекомендуем выбрать подходящую базовую модель для целевого языка. Например, если вы ориентируетесь на немецкий домен, вам следует выбрать jina-embeddings-v2-base-de в качестве базовой модели."])},answer7:n=>{const{normalize:r}=n;return r(["Нет, наш API тонкой настройки поддерживает только модели Jina v2."])},answer8:n=>{const{normalize:r}=n;return r(["В конце процесса точной настройки система оценивает модель с использованием отложенного набора тестов и сообщает показатели производительности. Вы получите электронное письмо с подробным описанием производительности до и после этого набора тестов. Вам также рекомендуется оценить модель на собственном тестовом наборе, чтобы убедиться в ее качестве."])},answer9:n=>{const{normalize:r}=n;return r(["Система генерирует синтетические данные путем интеграции предоставленных вами инструкций целевой области с рассуждениями агентов LLM. Он создает жесткие отрицательные триплеты, которые необходимы для обучения высококачественных моделей внедрения. Для получения более подробной информации, пожалуйста, обратитесь к нашему предстоящему исследованию Arxiv."])},question1:n=>{const{normalize:r}=n;return r(["Сколько стоит API тонкой настройки?"])},question10:n=>{const{normalize:r}=n;return r(["Могу ли я сохранить конфиденциальность своих точно настроенных моделей и синтетических данных?"])},question11:n=>{const{normalize:r}=n;return r(["Как я могу использовать доработанную модель?"])},question12:n=>{const{normalize:r}=n;return r(["Я так и не получил письмо с результатами оценки. Что я должен делать?"])},question2:n=>{const{normalize:r}=n;return r(["Что мне нужно ввести? Нужно ли мне предоставлять данные обучения?"])},question3:n=>{const{normalize:r}=n;return r(["Сколько времени занимает доводка модели?"])},question4:n=>{const{normalize:r}=n;return r(["Где хранятся доработанные модели?"])},question5:n=>{const{normalize:r}=n;return r(["Если я предоставлю ссылочный URL-адрес, как система его будет использовать?"])},question6:n=>{const{normalize:r}=n;return r(["Могу ли я точно настроить модель для конкретного языка?"])},question7:n=>{const{normalize:r}=n;return r(["Могу ли я точно настроить встраивания, отличные от Jina, например, bge-M3?"])},question8:n=>{const{normalize:r}=n;return r(["Как вы обеспечиваете качество доработанных моделей?"])},question9:n=>{const{normalize:r}=n;return r(["Как генерировать синтетические данные?"])},title:n=>{const{normalize:r}=n;return r(["Распространенные вопросы, связанные с автоматической точной настройкой"])}},find_on_hf:n=>{const{normalize:r}=n;return r(["Список доработанных моделей"])},temporarily_unavailable:n=>{const{normalize:r}=n;return r(["Временно недоступен. Мы модернизируем нашу систему автоматической настройки, чтобы лучше обслуживать вас. Пожалуйста, зайдите позже."])},test_on:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Протестировано на случайных выборках ",e(o("_dataSize"))," из ",e(o("_dataName")),"."])},test_performance_before_after:n=>{const{normalize:r}=n;return r(["Производительность на продолжительном тестовом наборе до и после тонкой настройки"])},title:n=>{const{normalize:r}=n;return r(["API автоматической точной настройки"])},total_improve:n=>{const{normalize:r}=n;return r(["Среднее улучшение"])},usage:n=>{const{normalize:r}=n;return r(["Применение"])},what_is:n=>{const{normalize:r}=n;return r(["Что такое автоматическая точная настройка?"])},what_is_answer_long:n=>{const{normalize:r}=n;return r(["Точная настройка позволяет вам взять предварительно обученную модель и адаптировать ее к конкретной задаче или предметной области, обучая ее на новом наборе данных. На практике поиск эффективных обучающих данных не является простой задачей для многих пользователей. Для эффективного обучения требуется нечто большее, чем просто добавление в модель необработанных PDF-файлов и HTML-файлов; и это трудно сделать правильно. Автоматическая точная настройка решает эту проблему, автоматически генерируя эффективные обучающие данные с помощью расширенного конвейера агентов LLM; и точная настройка модели в рамках рабочего процесса машинного обучения. Вы можете рассматривать это как комбинацию генерации синтетических данных и AutoML, поэтому все, что вам нужно сделать, это описать целевой домен на естественном языке, а наша система сделает все остальное."])}},best_banner:{description:n=>{const{normalize:r}=n;return r(["Блог на баннере, без подсказок!"])},example_description:n=>{const{normalize:r}=n;return r(["Алиса начинала очень уставать сидеть рядом с сестрой на берегу и от нечего делать: раз или два она заглядывала в книгу, которую читала сестра, но в ней не было ни картинок, ни разговоров, «а что толку в книге, — думала Алиса, — без картинок и разговоров?» И вот она размышляла про себя (как могла, потому что жаркий день вызывал у нее сонливость и глупость), стоит ли удовольствие плести маргаритку труда встать и сорвать маргаритки, как вдруг рядом с ней пробежал Белый Кролик с розовыми глазами."])},example_title:n=>{const{normalize:r}=n;return r(["Приключения Алисы в стране чудес - Глава 1"])}},beta:n=>{const{normalize:r}=n;return r(["Бета"])},billing_general_faq:{answer10:n=>{const{normalize:r}=n;return r(["Мы предлагаем новым пользователям приветственную бесплатную пробную версию, которая включает один миллион токенов для использования с любой из наших моделей, чему способствует автоматически сгенерированный ключ API. Как только лимит бесплатных токенов будет достигнут, пользователи смогут легко приобрести дополнительные токены для своих ключей API через вкладку «Купить токены»."])},answer13:n=>{const{normalize:r}=n;return r(["Нет, токены не снимаются за неудачные запросы."])},answer14:n=>{const{normalize:r}=n;return r(["Платежи обрабатываются через Stripe, поддерживающий для вашего удобства различные способы оплаты, включая кредитные карты, Google Pay и PayPal."])},answer15:n=>{const{normalize:r}=n;return r(["Да, после покупки токенов на адрес электронной почты, связанный с вашей учетной записью Stripe, будет выставлен счет."])},answer9:n=>{const{normalize:r}=n;return r(["Наша модель ценообразования основана на общем количестве обработанных токенов, что позволяет пользователям гибко распределять эти токены по любому количеству предложений, предлагая экономически эффективное решение для разнообразных требований к анализу текста."])},question10:n=>{const{normalize:r}=n;return r(["Доступна ли бесплатная пробная версия для новых пользователей?"])},question13:n=>{const{normalize:r}=n;return r(["Взимаются ли токены за неудачные запросы?"])},question14:n=>{const{normalize:r}=n;return r(["Какие способы оплаты принимаются?"])},question15:n=>{const{normalize:r}=n;return r(["Доступно ли выставление счетов за покупку токенов?"])},question9:n=>{const{normalize:r}=n;return r(["Выставление счетов зависит от количества предложений или запросов?"])},title:n=>{const{normalize:r}=n;return r(["Общие вопросы, связанные с выставлением счетов"])}},blog_tags:{all:n=>{const{normalize:r}=n;return r(["Все"])},events:n=>{const{normalize:r}=n;return r(["Событие"])},featured:n=>{const{normalize:r}=n;return r(["Избранное"])},insights:n=>{const{normalize:r}=n;return r(["Мнение"])},"knowledge-base":n=>{const{normalize:r}=n;return r(["База знаний"])},latest:n=>{const{normalize:r}=n;return r(["Последний"])},press:n=>{const{normalize:r}=n;return r(["пресс-релиз"])},releases:n=>{const{normalize:r}=n;return r(["Обновление программного обеспечения"])},"tech-blog":n=>{const{normalize:r}=n;return r(["Технический блог"])}},cclicence:{api_free_trial:n=>{const{normalize:r}=n;return r(["Бесплатный API-ключ"])},api_paid:n=>{const{normalize:r}=n;return r(["Платный API-ключ"])},api_paid_or_free:n=>{const{normalize:r}=n;return r(["Используете ли вы платный ключ API или бесплатный пробный ключ?"])},are_you:n=>{const{normalize:r}=n;return r(["Ты:"])},commercial_contact_sales:n=>{const{normalize:r}=n;return r(["Это коммерческое предложение. Свяжитесь с нашим отделом продаж."])},contact_sales_for_licensing:n=>{const{normalize:r}=n;return r(["Для получения лицензии свяжитесь с нашим отделом продаж."])},csp_user:n=>{const{normalize:r}=n;return r(["Используете ли вы наши официальные образы моделей в AWS и Azure?"])},educational_teaching:n=>{const{normalize:r}=n;return r(["Образовательное учреждение, использующее его для обучения?"])},for_profit_internal_use:n=>{const{normalize:r}=n;return r(["Коммерческая компания, использующая его для внутренних целей?"])},free_use:n=>{const{normalize:r}=n;return r(["Вы можете свободно использовать модели."])},government_public_services:n=>{const{normalize:r}=n;return r(["Государственное учреждение использует его для оказания государственных услуг?"])},is_use_commercial:n=>{const{normalize:r}=n;return r(["Является ли Ваше использование коммерческим?"])},may_be_commercial_contact:n=>{const{normalize:r}=n;return r(["Это может быть коммерческим. Пожалуйста, свяжитесь с нами для уточнения."])},no:n=>{const{normalize:r}=n;return r(["Нет"])},no1:n=>{const{normalize:r}=n;return r(["Нет"])},no2:n=>{const{normalize:r}=n;return r(["Нет"])},no3:n=>{const{normalize:r}=n;return r(["Нет"])},no_restrictions:n=>{const{normalize:r}=n;return r(["Никаких ограничений. Используйте согласно текущему соглашению."])},no_restrictions_apply:n=>{const{normalize:r}=n;return r(["Ограничения не применяются."])},non_commercial_free_use:n=>{const{normalize:r}=n;return r(["Это некоммерческое использование. Вы можете использовать модели свободно."])},non_profit_ngo_mission:n=>{const{normalize:r}=n;return r(["Некоммерческая или неправительственная организация использует его для своей миссии?"])},not_sure:n=>{const{normalize:r}=n;return r(["Не уверен"])},personal_hobby_projects:n=>{const{normalize:r}=n;return r(["Используете ли вы его для личных или любительских проектов?"])},product_service_sale:n=>{const{normalize:r}=n;return r(["Используете ли вы его в продаваемом вами продукте или услуге?"])},title:n=>{const{normalize:r}=n;return r(["Самостоятельная проверка лицензии CC BY-NC"])},trial_key_restrictions:n=>{const{normalize:r}=n;return r(["Бесплатный пробный ключ можно использовать только в некоммерческих целях. Для коммерческого использования приобретите платный пакет."])},typically_non_commercial_check:n=>{const{normalize:r}=n;return r(["Обычно это некоммерческое использование, но если вы не уверены, свяжитесь с нами."])},typically_non_commercial_free_use:n=>{const{normalize:r}=n;return r(["Это обычно некоммерческое использование. Вы можете свободно использовать модели."])},using_api_or_cloud:n=>{const{normalize:r}=n;return r(["Используете ли вы наш официальный API или официальные образы на Azure или AWS?"])},using_cc_by_nc_models:n=>{const{normalize:r}=n;return r(["Используете ли вы эти модели?"])},yes:n=>{const{normalize:r}=n;return r(["Да"])},yes1:n=>{const{normalize:r}=n;return r(["Да"])},yes2:n=>{const{normalize:r}=n;return r(["Да"])},yes3:n=>{const{normalize:r}=n;return r(["Да"])}},classifier:{access:n=>{const{normalize:r}=n;return r(["Публичный доступ"])},access_explain:n=>{const{normalize:r}=n;return r(["Публичные классификаторы могут использоваться любым человеком с <code>classifier_id</code>, и их использование будет потреблять квоту токенов вызывающего, а не вашу. Частные классификаторы доступны только вам."])},access_private:n=>{const{normalize:r}=n;return r(["Частный"])},access_public:n=>{const{normalize:r}=n;return r(["Публичный"])},api_delete:n=>{const{normalize:r}=n;return r(["Удалить классификатор"])},api_delete_explain:n=>{const{normalize:r}=n;return r(["Удалить классификатор по его идентификатору."])},api_list:n=>{const{normalize:r}=n;return r(["Список классификаторов"])},api_list_explain:n=>{const{normalize:r}=n;return r(["Перечислите все созданные вами классификаторы."])},classifier_id:n=>{const{normalize:r}=n;return r(["Идентификатор классификатора"])},classify_inputs:n=>{const{normalize:r}=n;return r(["Входные данные для классификации"])},classify_inputs_explain:n=>{const{normalize:r}=n;return r(["Для текста это может быть предложение длиной до 8192 токенов. Для изображений это может быть URL или изображение в кодировке base64."])},classify_labels:n=>{const{normalize:r}=n;return r(["Кандидатские ярлыки"])},classify_labels_explain:n=>{const{normalize:r}=n;return r(["Входные данные будут категоризированы по этим меткам. Может быть до 256 классов. Используйте семантические метки для лучшей производительности."])},compare_table:{access_control:n=>{const{normalize:r}=n;return r(["Контроль доступа"])},classifier_id_required:n=>{const{normalize:r}=n;return r(["Требуется идентификатор классификатора"])},continuous_updates:n=>{const{normalize:r}=n;return r(["Непрерывные обновления модели"])},default_solution:n=>{const{normalize:r}=n;return r(["Решение по умолчанию для общей классификации"])},feature:n=>{const{normalize:r}=n;return r(["Особенность"])},few_shot:n=>{const{normalize:r}=n;return r(["Несколько выстрелов"])},image_multi_lingual_support:n=>{const{normalize:r}=n;return r(["Мультимодальная и многоязычная поддержка"])},labels_required_classify:n=>{const{normalize:r}=n;return r(["Метки, необходимые в /classify"])},labels_required_train:n=>{const{normalize:r}=n;return r(["Метки, необходимые в /train"])},max_classes:n=>{const{normalize:r}=n;return r(["Максимальное количество классов"])},max_classifiers:n=>{const{normalize:r}=n;return r(["Максимальные классификаторы"])},max_inputs_request:n=>{const{normalize:r}=n;return r(["Максимальное количество входов на запрос"])},max_token_length:n=>{const{normalize:r}=n;return r(["Максимальная длина токена на вход"])},na:n=>{const{normalize:r}=n;return r(["Н/Д"])},no:n=>{const{normalize:r}=n;return r(["Нет"])},out_of_domain_solution:n=>{const{normalize:r}=n;return r(["Для данных за пределами домена v3/clip-v1 или чувствительных ко времени данных"])},primary_use_case:n=>{const{normalize:r}=n;return r(["Основной вариант использования"])},semantic_labels_required:n=>{const{normalize:r}=n;return r(["Требуются семантические метки"])},state_management:n=>{const{normalize:r}=n;return r(["Государственное управление"])},stateful:n=>{const{normalize:r}=n;return r(["С сохранением состояния"])},stateless:n=>{const{normalize:r}=n;return r(["Без гражданства"])},token_count:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("count"))," жетонов"])},training_data_required:n=>{const{normalize:r}=n;return r(["Требуются данные для обучения"])},yes:n=>{const{normalize:r}=n;return r(["Да"])},zero_shot:n=>{const{normalize:r}=n;return r(["Нулевой выстрел"])}},create_classifier:n=>{const{normalize:r}=n;return r(["Новый малокадровый классификатор"])},create_classifier_explain:n=>{const{normalize:r}=n;return r(["Создайте новый классификатор с несколькими результатами и обучите его с помощью маркированных примеров."])},description:n=>{const{normalize:r}=n;return r(["Классификация изображений и текста по нулевому и небольшому количеству кадров."])},description_long:n=>{const{normalize:r}=n;return r(["Попробуйте нашу площадку API, чтобы увидеть, как работает наш классификатор."])},description_long1:n=>{const{normalize:r}=n;return r(["Высокопроизводительный классификатор с нулевым и малым числом выборок для мультимодальных и многоязычных данных."])},explain:n=>{const{normalize:r}=n;return r(["Классификатор — это API-сервис, который классифицирует текст и изображения с использованием моделей встраивания (<code>jina-embeddings-v3</code> и <code>jina-clip-v1</code>), поддерживая как классификацию с нуля без обучающих данных, так и обучение с несколькими попытками и минимальным количеством примеров."])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["Zero-shot требует семантических меток во время классификации и ничего во время обучения, в то время как few-shot требует меток во время обучения, но не классификации. Это означает, что zero-shot лучше подходит для гибких, немедленных потребностей в классификации, в то время как few-shot лучше подходит для фиксированных, специфичных для домена категорий, которые могут меняться со временем."])},answer10:n=>{const{normalize:r}=n;return r(["Да, вы можете выбрать между <code>jina-embeddings-v3</code> для классификации текста (особенно хорошо для многоязычных) и <code>jina-clip-v1</code> для мультимодальной классификации. Новые модели, такие как <code>jina-clip-v2</code>, будут автоматически доступны через API после выпуска."])},answer2:n=>{const{normalize:r}=n;return r(["<code>num_iters</code> контролирует интенсивность обучения — более высокие значения усиливают важные примеры, а более низкие значения минимизируют влияние менее надежных данных. Его можно использовать для внедрения обучения с учетом времени, предоставляя недавним примерам более высокие числа итераций, что делает его ценным для развивающихся шаблонов данных."])},answer3:n=>{const{normalize:r}=n;return r(["Публичные классификаторы могут использоваться любым человеком с <code>classifier_id</code>, потребляя собственную квоту токенов. Пользователи не могут получить доступ к данным обучения или конфигурации и не могут видеть запросы классификации других, что позволяет безопасно делиться классификаторами."])},answer4:n=>{const{normalize:r}=n;return r(["Few-shot требует 200-400 обучающих примеров, чтобы превзойти классификацию zero-shot. Хотя в конечном итоге он достигает более высокой точности, ему необходим этот период разминки, чтобы стать эффективным. Zero-shot обеспечивает постоянную производительность немедленно без обучающих данных."])},answer5:n=>{const{normalize:r}=n;return r(["Да — API поддерживает многоязычные запросы с использованием <code>jina-embeddings-v3</code> и мультимодальную (текст/изображение) классификацию с использованием <code>jina-clip-v1</code>, с поддержкой URL или изображений в кодировке base64 в одном запросе."])},answer6:n=>{const{normalize:r}=n;return r(["Zero-shot поддерживает 256 классов без ограничения по классификаторам, в то время как few-shot ограничен 16 классами и 16 классификаторами. Оба поддерживают 1024 входа на запрос и 8192 токена на вход."])},answer7:n=>{const{normalize:r}=n;return r(["Режим Few-shot позволяет непрерывно обновлять конечную точку <code>/train</code> для адаптации к изменяющимся шаблонам данных. Вы можете постепенно добавлять новые примеры или классы при изменении распределения данных, не перестраивая весь классификатор."])},answer8:n=>{const{normalize:r}=n;return r(["API использует однопроходное онлайн-обучение — обучающие примеры обновляют веса классификатора, но не сохраняются после этого. Это означает, что вы не можете извлечь исторические обучающие данные, но это обеспечивает конфиденциальность и эффективность ресурсов."])},answer9:n=>{const{normalize:r}=n;return r(["Начните с нулевого выстрела для немедленных результатов и когда вам нужна гибкая классификация с семантическими метками. Переключитесь на несколько выстрелов, когда у вас 200-400 примеров, нужна более высокая точность или вам нужно обрабатывать доменно-зависимые/временные данные."])},question1:n=>{const{normalize:r}=n;return r(["Чем отличаются метки в нулевом и малом количестве снимков?"])},question10:n=>{const{normalize:r}=n;return r(["Могу ли я использовать разные модели для разных языков/задач?"])},question2:n=>{const{normalize:r}=n;return r(["Для чего нужен num_iters и как его использовать?"])},question3:n=>{const{normalize:r}=n;return r(["Как работает публичный обмен классификаторами?"])},question4:n=>{const{normalize:r}=n;return r(["Сколько данных мне нужно для эффективной работы метода few-shot?"])},question5:n=>{const{normalize:r}=n;return r(["Может ли он обрабатывать несколько языков и текст/изображения?"])},question6:n=>{const{normalize:r}=n;return r(["О каких жестких ограничениях мне следует знать?"])},question7:n=>{const{normalize:r}=n;return r(["Как обрабатывать изменения данных с течением времени?"])},question8:n=>{const{normalize:r}=n;return r(["Что происходит с моими тренировочными данными после их отправки?"])},question9:n=>{const{normalize:r}=n;return r(["Нулевой или малый выстрел — когда какой использовать?"])},title:n=>{const{normalize:r}=n;return r(["Общие вопросы, связанные с классификатором"])}},more:n=>{const{normalize:r}=n;return r(["более"])},num_iters:n=>{const{normalize:r}=n;return r(["Итерации обучения"])},num_iters_explain:n=>{const{normalize:r}=n;return r(["Контролирует интенсивность обучения — более высокие значения повышают точность на текущих примерах, но увеличивают стоимость токена. Значение по умолчанию 10 обычно работает хорошо."])},read_notes:n=>{const{normalize:r}=n;return r(["Прочитать примечания к выпуску"])},select_classifier_or_model:n=>{const{normalize:r}=n;return r(["Выберите классификатор или модель внедрения"])},task_classify:n=>{const{normalize:r}=n;return r(["Классифицировать"])},task_classify_explain:n=>{const{normalize:r}=n;return r(["Используйте классификатор с нулевым или малым числом повторов для классификации текста или изображений по определенным классам."])},task_manage:n=>{const{normalize:r}=n;return r(["Управлять"])},task_manage_explain:n=>{const{normalize:r}=n;return r(["Перечислите или удалите несколько классификаторов."])},task_select:n=>{const{normalize:r}=n;return r(["Выберите задачу"])},task_train:n=>{const{normalize:r}=n;return r(["Тренироваться"])},task_train_explain:n=>{const{normalize:r}=n;return r(["Создайте или обновите классификатор из нескольких снимков с помеченными примерами."])},title:n=>{const{normalize:r}=n;return r(["API классификатора"])},train_inputs:n=>{const{normalize:r}=n;return r(["Данные обучения"])},train_inputs_explain:n=>{const{normalize:r}=n;return r(["Примеры текста или изображений с метками для обучения. Вы можете постепенно обновлять классификатор новыми примерами и метками с течением времени."])},train_label:n=>{const{normalize:r}=n;return r(["Этикетка"])},what_is:n=>{const{normalize:r}=n;return r(["Что такое классификатор?"])},when_to_use_what:n=>{const{normalize:r}=n;return r(["Когда использовать «ноль выстрелов» или «несколько выстрелов»?"])},when_to_use_what_explain:n=>{const{normalize:r}=n;return r(["Используйте классификацию с нулевым числом повторов в качестве решения по умолчанию для получения немедленных результатов в общих задачах классификации с использованием до 256 классов, в то время как обучение с малым числом повторов лучше подходит при работе с данными, относящимися к предметной области, за пределами знаний моделей внедрения или когда вам необходимо обрабатывать чувствительные ко времени данные, требующие постоянного обновления модели."])}},clip_as_service:{description:n=>{const{normalize:r}=n;return r(["Встраивайте изображения и предложения в векторы фиксированной длины с помощью CLIP"])}},cloud:{description:n=>{const{normalize:r}=n;return r(["Платформа облачного хостинга для мультимодальных приложений ИИ"])}},contact_us_page:{agreement:n=>{const{normalize:r}=n;return r(["Отправляя заявку, вы подтверждаете свое согласие на обработку ваших персональных данных компанией Jina AI, как описано в"])},anything_else:n=>{const{normalize:r}=n;return r(["Расскажите нам больше о своей идее"])},cc_by_nc:n=>{const{normalize:r}=n;return r(["Запросить коммерческое использование моделей CC BY-NC"])},cc_by_nc_description:n=>{const{normalize:r}=n;return r(["Наши последние модели обычно имеют лицензию CC BY-NC. Для коммерческого использования получите к ним доступ через наш API, Azure Marketplace или AWS SageMaker. Установите этот флажок для локального использования за пределами этих каналов."])},company:n=>{const{normalize:r}=n;return r(["Организация"])},company_size:n=>{const{normalize:r}=n;return r(["Размер организации"])},company_website:n=>{const{normalize:r}=n;return r(["Сайт организации"])},company_website_placeholder:n=>{const{normalize:r}=n;return r(["URL-адрес домашней страницы вашей компании или профиля LinkedIn."])},country:n=>{const{normalize:r}=n;return r(["Страна"])},department:n=>{const{normalize:r}=n;return r(["Отделение"])},description:n=>{const{normalize:r}=n;return r(["Развивайте свой бизнес с Jina AI."])},faq:n=>{const{normalize:r}=n;return r(["Часто задаваемые вопросы"])},feedback_sent:n=>{const{normalize:r}=n;return r(["Отправлено! Мы свяжемся с вами в ближайшее время."])},field_required:n=>{const{normalize:r}=n;return r(["Поле, обязательное для заполнения"])},get_api_key:n=>{const{normalize:r}=n;return r(["Как получить мой ключ API?"])},impact_snapshots:n=>{const{normalize:r}=n;return r(["Моментальные снимки воздействия"])},invalid_date_format:n=>{const{normalize:r}=n;return r(["Неверный формат даты. Пожалуйста, используйте формат ДД-ММ-ГГГГ."])},invalid_email:n=>{const{normalize:r}=n;return r(["Электронная почта недействительна"])},invalid_number:n=>{const{normalize:r}=n;return r(["Неправильный номер. Пожалуйста, введите еще раз"])},invalid_url:n=>{const{normalize:r}=n;return r(["URL-адрес недействителен"])},name:n=>{const{normalize:r}=n;return r(["Имя"])},nc_check:n=>{const{normalize:r}=n;return r(["Нужна ли мне коммерческая лицензия?"])},other_questions:n=>{const{normalize:r}=n;return r(["Другие вопросы"])},preferred_models:n=>{const{normalize:r}=n;return r(["Какие модели вас интересуют?"])},preferred_products:n=>{const{normalize:r}=n;return r(["Какие продукты вас интересуют?"])},priority:n=>{const{normalize:r}=n;return r(["Приоритетная поддержка для платных пользователей"])},private_statement:n=>{const{normalize:r}=n;return r(["Заявление о конфиденциальности"])},rate_limit:n=>{const{normalize:r}=n;return r(["Каков предел ставки?"])},role:n=>{const{normalize:r}=n;return r(["Роль работы"])},self_check:n=>{const{normalize:r}=n;return r(["Самопроверка"])},sending_feedback:n=>{const{normalize:r}=n;return r(["Отправка..."])},shortcut:n=>{const{normalize:r}=n;return r(["Ярлык"])},submit:n=>{const{normalize:r}=n;return r(["Представлять на рассмотрение"])},submit_failed:n=>{const{normalize:r}=n;return r(["Отправка не удалась. Пожалуйста, повторите попытку позже."])},submit_success:n=>{const{normalize:r}=n;return r(["Спасибо за ваш вклад. Мы скоро к тебе вернемся."])},subtitle:n=>{const{normalize:r}=n;return r(["Jina AI, лидер в области мультимодального ИИ, преуспевает в настройке моделей, обслуживании моделей, настройке подсказок и подсказках. Используя облачные технологии, такие как Kubernetes и бессерверные архитектуры, мы предоставляем надежные, масштабируемые и готовые к работе решения. Имея опыт работы с крупными языковыми моделями, текстом, изображениями, видео, аудио, нейронным поиском и генеративным искусством, мы предлагаем инновационные, ориентированные на будущее стратегии для развития вашего бизнеса."])},subtitle1:n=>{const{normalize:r}=n;return r(["Jina AI, лидер в области мультимодального искусственного интеллекта, превосходно справляется с настройкой внедрения, обслуживанием внедрения, быстрой настройкой и быстрым обслуживанием. Используя облачные технологии, такие как Kubernetes, и бессерверные архитектуры, мы предоставляем надежные, масштабируемые и готовые к использованию решения. Обладая опытом в области больших языковых моделей, понимания текста, изображений, видео, аудио, нейронного поиска и генеративного искусственного интеллекта, мы предлагаем инновационные, перспективные стратегии для развития вашего бизнеса."])},subtitle2:n=>{const{normalize:r}=n;return r(["Исследуйте Jina AI, передовую разработку мультимодального искусственного интеллекта. Мы преуспеваем во внедрении и оперативном использовании технологий, используя облачные решения, такие как Kubernetes, для создания надежных и масштабируемых систем. Специализируясь на больших языковых моделях и обработке мультимедиа, мы предлагаем инновационные, перспективные бизнес-стратегии, основанные на нашем передовом опыте в области искусственного интеллекта."])},title:n=>{const{normalize:r}=n;return r(["Связаться с отделом продаж"])},trusted_by:n=>{const{normalize:r}=n;return r(["Нам доверяют"])},turn_on_volume:n=>{const{normalize:r}=n;return r(["Увеличьте громкость"])},work_email:n=>{const{normalize:r}=n;return r(["Рабочий адрес электронной почты"])}},copy:n=>{const{normalize:r}=n;return r(["Копировать"])},copy_to_clipboard_success:n=>{const{normalize:r}=n;return r(["Скопировано в буфер обмена"])},dalle_flow:{description:n=>{const{normalize:r}=n;return r(["Рабочий процесс «человек в цикле» для создания HD-изображений из текста."])}},"dev-gpt":{description:n=>{const{normalize:r}=n;return r(["Ваша виртуальная команда разработчиков"])}},disco_art:{description:n=>{const{normalize:r}=n;return r(["Создавайте привлекательные произведения искусства Disco Diffusion в одной строке кода"])}},doc_array:{description:n=>{const{normalize:r}=n;return r(["Структура данных для мультимодальных данных"])}},download:n=>{const{normalize:r}=n;return r(["Загрузить аттестацию SOC 2 Type 1"])},embedding:{"11B tokens":n=>{const{normalize:r}=n;return r(["11 миллиардов"])},"11B tokens_intuition1":n=>{const{normalize:r}=n;return r(["Это похоже на чтение всех англоязычных статей в Википедии."])},"11B tokens_targetUser":n=>{const{normalize:r}=n;return r(["Развертывание производства"])},"1B tokens":n=>{const{normalize:r}=n;return r(["1000000000"])},"1B tokens_intuition1":n=>{const{normalize:r}=n;return r(["Примерно то же самое, что читать полное собрание сочинений Шекспира и всю серию «Гарри Поттер»."])},"1B tokens_targetUser":n=>{const{normalize:r}=n;return r(["Разработка прототипа"])},"1M tokens":n=>{const{normalize:r}=n;return r(["1 миллион"])},"1M tokens_intuition1":n=>{const{normalize:r}=n;return r(["Эквивалентно прочтению всего текста «Хоббита» и «Великого Гэтсби»."])},"1M tokens_targetUser":n=>{const{normalize:r}=n;return r(["Игрушечный эксперимент"])},"1M_free":n=>{const{normalize:r}=n;return r(["1 миллион бесплатных токенов"])},"1M_free_description":n=>{const{normalize:r}=n;return r(["Наслаждайтесь новым ключом API с бесплатными токенами, кредитная карта не требуется."])},"2_5B tokens":n=>{const{normalize:r}=n;return r(["2,5 млрд токенов"])},"2_5B tokens_intuition1":n=>{const{normalize:r}=n;return r([`Это сравнимо с 1000-кратной расшифровкой каждого слова, сказанного в трилогии «Властелин колец».
`])},"3p_integration":n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["С помощью <b>",e(o("_numPartners")),"</b> сторонних сервисов"])},"3p_integration_desc":n=>{const{normalize:r}=n;return r(["Интегрируйте нашу базу поиска с существующими службами. Наши партнеры создали коннекторы для нашего API, что упрощает использование наших моделей в ваших приложениях."])},"500M tokens":n=>{const{normalize:r}=n;return r(["500 миллионов токенов"])},"500M tokens_intuition1":n=>{const{normalize:r}=n;return r(["Аналогично просмотру каждой серии «Симпсонов» с 1 по 30 сезон."])},"59B tokens":n=>{const{normalize:r}=n;return r(["59B токенов"])},"59B tokens_intuition1":n=>{const{normalize:r}=n;return r(["Равно всем твитам, опубликованным по всему миру за двухдневный период."])},"5_5B tokens":n=>{const{normalize:r}=n;return r(["5,5 млрд токенов"])},"5_5B tokens_intuition1":n=>{const{normalize:r}=n;return r(["Эквивалентно чтению всего текста Британской энциклопедии."])},Free1M:n=>{const{normalize:r}=n;return r(["1 млн токенов"])},add_pair:n=>{const{normalize:r}=n;return r(["Новый"])},add_time_explain:n=>{const{normalize:r}=n;return r(["Дата добавления данной модели в Search Foundation."])},api_integration_short:n=>{const{normalize:r}=n;return r(["Наш API для встраивания изначально интегрирован с различными известными базами данных, векторными хранилищами, платформами RAG и LLMOps."])},api_integrations:n=>{const{normalize:r}=n;return r(["API-интеграция"])},api_key_update_message:n=>{const{normalize:r}=n;return r(["Заменив старый ключ API, новый ключ будет отображаться в пользовательском интерфейсе всякий раз, когда вы посещаете jina.ai. Будущие пополнения будут применяться к этому новому ключу. Ваш старый ключ остается действительным, поэтому, если вы планируете использовать его снова, пожалуйста, сохраните его в надежном месте."])},api_key_update_title:n=>{const{normalize:r}=n;return r(["Замена ключа API"])},auto_recharge:n=>{const{normalize:r}=n;return r(["Автоматическое пополнение счета при низком уровне токенов"])},auto_recharge_confirm_message:n=>{const{normalize:r}=n;return r(["Вы уверены, что хотите отключить автоматическое пополнение? Это предотвратит автоматическое пополнение, когда баланс ваших токенов низкий."])},auto_recharge_confirm_title:n=>{const{normalize:r}=n;return r(["Отключить автоматическое пополнение"])},auto_recharge_description:n=>{const{normalize:r}=n;return r(["Рекомендуется для бесперебойной службы на производстве. Когда баланс вашего токена станет ниже установленного вами порога, мы автоматически пополним вашу кредитную карту на ту же сумму, что и ваше последнее пополнение. Если при последнем пополнении вы приобрели несколько пакетов, мы пополним только один пакет."])},auto_recharge_enable:n=>{const{normalize:r}=n;return r(["Вы включили автоматическое пополнение при низком уровне токенов"])},auto_recharge_enable_message:n=>{const{normalize:r}=n;return r(["Чтобы включить функцию автоматического пополнения, приобретите пакет, в котором для функции автоматического пополнения установлено значение true."])},auto_recharge_enable_title:n=>{const{normalize:r}=n;return r(["Включить автоматическое пополнение"])},auto_request:n=>{const{normalize:r}=n;return r(["Автоматический предварительный просмотр"])},auto_request_tooltip:n=>{const{normalize:r}=n;return r(["Автоматически просматривайте ответ API при изменении модели, используя сотни токенов из вашего ключа API. Отключите отправку запроса вручную, нажав «Получить ответ»."])},autostart:n=>{const{normalize:r}=n;return r(["Встраивание начнется автоматически после небольшой задержки."])},base64_description:n=>{const{normalize:r}=n;return r(["Вложения возвращаются в виде строки в кодировке Base64. Более эффективен для передачи."])},batch_job:n=>{const{normalize:r}=n;return r(["Пакетное задание"])},batch_upload_hint:n=>{const{normalize:r}=n;return r(["Мы будем использовать ключ API и модель ниже для обработки документов."])},"bge-base-en-v1_5_description":n=>{const{normalize:r}=n;return r(["Надежная английская модель, сочетающая в себе производительность и эффективность для универсального использования."])},"bge-base-en_description":n=>{const{normalize:r}=n;return r(["Сбалансированная английская модель, созданная для прочной и надежной работы."])},"bge-base-zh-v1_5_description":n=>{const{normalize:r}=n;return r(["Всесторонняя китайская модель, сочетающая в себе возможности и эффективность."])},"bge-base-zh_description":n=>{const{normalize:r}=n;return r(["Универсальная китайская модель, сочетающая в себе эффективность и надежность."])},"bge-large-en-v1_5_description":n=>{const{normalize:r}=n;return r(["Мощная английская модель, предлагающая первоклассные встраиваемые системы исключительного качества."])},"bge-large-en_description":n=>{const{normalize:r}=n;return r(["Высокопроизводительная английская модель, созданная для встраивания премиум-класса."])},"bge-large-zh-v1_5_description":n=>{const{normalize:r}=n;return r(["Высокопроизводительная китайская модель с превосходными и детальными встраиваниями."])},"bge-large-zh_description":n=>{const{normalize:r}=n;return r(["Высокопроизводительная китайская модель, оптимизированная для встраивания высшего уровня."])},"bge-m3_description":n=>{const{normalize:r}=n;return r(["Универсальная многоязычная модель, предлагающая широкие возможности и высококачественные встраивания."])},"bge-small-en-v1_5_description":n=>{const{normalize:r}=n;return r(["Оптимизированная английская модель, обеспечивающая эффективное и высококачественное встраивание."])},"bge-small-en_description":n=>{const{normalize:r}=n;return r(["Эффективная английская модель для упрощенного и точного встраивания."])},"bge-small-zh-v1_5_description":n=>{const{normalize:r}=n;return r(["Компактная китайская модель, обеспечивающая маневренность и точность встраивания."])},"bge-small-zh_description":n=>{const{normalize:r}=n;return r(["Гибкая китайская модель для эффективного и точного встраивания."])},binary_description:n=>{const{normalize:r}=n;return r(["Вложения упакованы как int8. Гораздо эффективнее для хранения, поиска и передачи."])},bulk:n=>{const{normalize:r}=n;return r(["Пакетное встраивание"])},bulk_embedding_failed:n=>{const{normalize:r}=n;return r(["Не удалось создать задание пакетного внедрения."])},buy_more_quota:n=>{const{normalize:r}=n;return r(["Пополните этот ключ API дополнительными токенами"])},buy_poster:n=>{const{normalize:r}=n;return r(["Купить бумажную копию"])},cancel_button:n=>{const{normalize:r}=n;return r(["Отмена"])},click_upload_btn_above:n=>{const{normalize:r}=n;return r(["Нажмите кнопку загрузки выше, чтобы начать."])},code:n=>{const{normalize:r}=n;return r(["код"])},colbert_dimensions_explain:n=>{const{normalize:r}=n;return r(["Размер измерения вложения на токен."])},compatible:n=>{const{normalize:r}=n;return r(["Совместимый режим"])},compatible_explain:n=>{const{normalize:r}=n;return r(["Соответствует тому же формату запроса, что и наши модели встраивания текста. Это позволяет переключаться между моделями без изменения запроса. Обратите внимание, что в этом режиме не поддерживается ввод изображений."])},cosine_similarity:n=>{const{normalize:r}=n;return r(["Косинусное подобие"])},debugging:n=>{const{normalize:r}=n;return r(["Тест"])},delete_pair:n=>{const{normalize:r}=n;return r(["Удалить"])},description:n=>{const{normalize:r,linked:e,type:o}=n;return r([e("landing_page.embedding_desc1",void 0,o)])},dimensions:n=>{const{normalize:r}=n;return r(["Размеры вывода"])},dimensions_error:n=>{const{normalize:r}=n;return r(["Размер измерения должен быть в диапазоне от 1 до 1024."])},dimensions_explain:n=>{const{normalize:r}=n;return r(["Меньшие размеры проще хранить и извлекать, при этом влияние на производительность минимально благодаря MRL."])},dimensions_warning:n=>{const{normalize:r}=n;return r(["Для эффективного выполнения задач мы рекомендуем поддерживать размерность более 32."])},document:n=>{const{normalize:r}=n;return r(["Документ"])},download:n=>{const{normalize:r}=n;return r(["Скачать"])},edit_text1_text:n=>{const{normalize:r}=n;return r(["Редактировать левый текст"])},edit_text2_text:n=>{const{normalize:r}=n;return r(["Редактировать правильный текст"])},embedding_done:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Предложений успешно внедрено: ",e(o("_Count")),"."])},embedding_none_description:n=>{const{normalize:r}=n;return r(["Не используйте никакую модель внедрения"])},example_inputs:n=>{const{normalize:r}=n;return r(["Пример входных данных"])},faq:n=>{const{normalize:r,linked:e,type:o}=n;return r([e("contact_us_page.faq",void 0,o)])},faqs_v2:{answer0:n=>{const{normalize:r}=n;return r(["Подробную информацию о наших процессах обучения, источниках данных и оценках можно найти в нашем техническом отчете, доступном на arXiv."])},answer1:n=>{const{normalize:r}=n;return r(["Каждому пользователю разрешено делать до 100 запросов в секунду, что соответствует 204 800 входным предложениям в секунду."])},answer17:n=>{const{normalize:r}=n;return r(["В настоящее время мы разрабатываем мультимодальные внедрения, которые будут совместно обрабатывать текст, изображения и аудио. Обновления будут объявлены в ближайшее время!"])},answer18:n=>{const{normalize:r}=n;return r(["По вопросам точной настройки наших моделей с использованием конкретных данных свяжитесь с нами, чтобы обсудить ваши требования. Мы открыты для изучения того, как наши модели могут быть адаптированы к вашим потребностям."])},answer19:n=>{const{normalize:r}=n;return r(["Да, наши услуги доступны на торговой площадке AWS, и мы находимся в процессе расширения на торговые площадки Azure и GCP. Если у вас есть особые требования, пожалуйста, свяжитесь с нами по продажам на jina.ai."])},answer3:n=>{const{normalize:r}=n;return r(["Наши модели поддерживают английский, немецкий, испанский, китайский и различные языки программирования. Более подробную информацию можно найти в нашей публикации о двуязычных моделях."])},answer4:n=>{const{normalize:r}=n;return r(["Наши модели допускают длину ввода до 8192 токенов, что значительно больше, чем у большинства других моделей. Токен может варьироваться от одного символа, например «а», до целого слова, например «яблоко». Общее количество символов, которые можно ввести, зависит от длины и сложности используемых слов. Эти расширенные возможности ввода позволяют нашим моделям jina-embeddings-v2 выполнять более полный анализ текста и достигать более высокой точности понимания контекста, особенно для обширных текстовых данных."])},answer5:n=>{const{normalize:r}=n;return r(["Один вызов API может обрабатывать до 2048 предложений или текстов, что позволяет выполнить обширный анализ текста за один запрос."])},answer6:n=>{const{normalize:r}=n;return r(["Вы можете использовать либо <code>url</code>, либо <code>bytes</code> в поле <code>input</code> запроса API. В поле <code>url</code> укажите URL-адрес изображения, которое вы хотите обработать. Для <code>bytes</code> закодируйте изображение в формате base64 и включите его в запрос. Модель вернет вложения изображения в ответ."])},answer7:n=>{const{normalize:r}=n;return r(["Согласно таблице лидеров MTEB, наша базовая модель тесно конкурирует с text-embedding-ada-002 от OpenAI, демонстрируя в среднем сопоставимую производительность. Кроме того, наша базовая модель превосходно справляется с несколькими задачами, включая классификацию, парную классификацию, переранжирование и обобщение, превосходя модель OpenAI."])},answer8:n=>{const{normalize:r}=n;return r(["Переход упрощен, поскольку наша конечная точка API https://api.jina.ai/v1/embeddings соответствует входным и выходным схемам JSON модели OpenAI text-embeddings-ada-002. Эта совместимость гарантирует, что пользователи смогут легко заменить модель OpenAI на нашу при использовании конечной точки OpenAI."])},answer9:n=>{const{normalize:r}=n;return r([`Токены рассчитываются на основе длины текста и размера изображения. Для текста в запросе токены считаются стандартным способом. Для изображения в запросе выполняются следующие шаги:
1. Размер плитки: каждое изображение разделено на плитки размером 224x224 пикселей.
	2. Покрытие: рассчитывается количество плиток, необходимое для полного покрытия входного изображения. Даже если размеры изображения не делятся на 224, мы будем считать частичные плитки полными.
	3. Общее количество плиток: общее количество плиток, покрывающих изображение, определяет стоимость. Например, если изображение имеет размер 500x500 пикселей, оно будет покрыто плитками 3x3, в результате чего получится 9 плиток.
	4. Расчет стоимости: каждая плитка влияет на окончательную стоимость обработки изображения. Стоимость одной плитки — 1000 жетонов.

Пример:
Для изображения размером 500x500 пикселей:

	• Изображение разделено на фрагменты размером 224x224 пикселя.
	• Общее количество требуемых плиток составляет 3 (по горизонтали) x 3 (по вертикали) = 9 плиток.
	• Стоимость составит 9*1000 = 9000 токенов.`])},question0:n=>{const{normalize:r}=n;return r(["Как обучались модели jina-embeddings-v2?"])},question1:n=>{const{normalize:r}=n;return r(["Сколько запросов API я могу сделать в секунду?"])},question17:n=>{const{normalize:r}=n;return r(["Предоставляете ли вы модели для встраивания изображений или аудио?"])},question18:n=>{const{normalize:r}=n;return r(["Можно ли точно настроить модели Jina Embedding с использованием частных данных или данных компании?"])},question19:n=>{const{normalize:r}=n;return r(["Могут ли ваши конечные точки размещаться в частном порядке на AWS, Azure или GCP?"])},question3:n=>{const{normalize:r}=n;return r(["Какие языки поддерживают ваши модели?"])},question4:n=>{const{normalize:r}=n;return r(["Какова максимальная длина ввода одного предложения?"])},question5:n=>{const{normalize:r}=n;return r(["Какое максимальное количество предложений я могу включить в один запрос?"])},question6:n=>{const{normalize:r}=n;return r(["Как отправить изображения в модель jina-clip-v1?"])},question7:n=>{const{normalize:r}=n;return r(["Чем модели Jina Embeddings отличаются от модели OpenAI text-embedding-ada-002?"])},question8:n=>{const{normalize:r}=n;return r(["Насколько плавным является переход от text-embedding-ada-002 от OpenAI к вашему решению?"])},question9:n=>{const{normalize:r}=n;return r(["Как рассчитываются токены при использовании jina-clip-v1?"])},title:n=>{const{normalize:r}=n;return r(["Общие вопросы, связанные с встраиваниями"])}},feature_8k1:n=>{const{normalize:r}=n;return r(["длина токена 8192"])},feature_8k_description1:n=>{const{normalize:r}=n;return r(["Впервые появилась первая модель внедрения с открытым исходным кодом длиной 8192 токена, позволяющая представить всю главу в одном векторе."])},feature_cheap:n=>{const{normalize:r}=n;return r(["в 20 раз дешевле"])},feature_cheap_v1:n=>{const{normalize:r}=n;return r(["в 5 раз дешевле"])},feature_cheap_v1_description1:n=>{const{normalize:r}=n;return r(["Начните с бесплатных пробных версий и наслаждайтесь простой структурой ценообразования. Получите доступ к мощным встроенным компонентам всего за 20 % от стоимости OpenAI."])},feature_multilingual:n=>{const{normalize:r}=n;return r(["Предлагает двуязычные модели для немецкого-английского, китайского-английского и других языков, идеально подходящие для межъязыковых приложений."])},feature_on_premises:n=>{const{normalize:r}=n;return r(["Конфиденциальность прежде всего"])},feature_on_premises_description1:n=>{const{normalize:r}=n;return r(["Легко развертывайте наши модели внедрения непосредственно в своем виртуальном частном облаке (VPC). В настоящее время поддерживается на AWS Sagemaker, в ближайшее время будет реализована интеграция с Microsoft Azure и Google Cloud Platform. Для индивидуального развертывания Kubernetes обратитесь в наш отдел продаж за специализированной помощью."])},feature_on_premises_description2:n=>{const{normalize:r}=n;return r(["Развертывайте модели Jina Embeddings в AWS Sagemaker, а вскоре и в Microsoft Azure и Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов."])},feature_on_premises_description3:n=>{const{normalize:r}=n;return r(["Развертывайте модели Jina Embeddings в AWS Sagemaker и Microsoft Azure, а вскоре и в Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов."])},feature_on_premises_description4:n=>{const{normalize:r}=n;return r(["Развертывайте модели Jina Embedding и Reranker локально с помощью AWS SageMaker, Microsoft Azure или облачных сервисов Google, гарантируя, что ваши данные останутся под вашим контролем."])},feature_solid:n=>{const{normalize:r}=n;return r(["Лучшие в своем классе"])},feature_solid_description1:n=>{const{normalize:r}=n;return r(["Разработано на основе передовых научных исследований и тщательно протестировано на соответствие моделям SOTA, чтобы обеспечить непревзойденную производительность."])},feature_top_perform1:n=>{const{normalize:r}=n;return r(["Бесшовная интеграция"])},feature_top_perform_description1:n=>{const{normalize:r}=n;return r(["Полностью совместим с API OpenAI. Легко интегрируется с более чем 10 векторными базами данных и системами RAG, обеспечивая удобство работы с пользователем."])},file_required:n=>{const{normalize:r}=n;return r(["Требуется файл"])},file_size_exceed:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Превышен максимальный размер файла ",e(o("_size"))])},file_type_not_supported:n=>{const{normalize:r}=n;return r(["Тип файла не поддерживается"])},fill_example:n=>{const{normalize:r}=n;return r(["Заполните пример"])},float_description:n=>{const{normalize:r}=n;return r(["Вложения возвращаются в виде списка чисел с плавающей запятой. Самый распространенный и простой в использовании."])},free:n=>{const{normalize:r}=n;return r(["Бесплатно"])},generate_api_key_error:n=>{const{normalize:r}=n;return r(["Не удалось создать ключ API."])},generating_visualization:n=>{const{normalize:r}=n;return r(["Создание визуализации..."])},get_new_key_button:n=>{const{normalize:r}=n;return r(["Получить новый ключ"])},get_new_key_button_explain:n=>{const{normalize:r}=n;return r(["Выбор нового ключа приведет к потере истории использования, связанной со старым ключом."])},get_new_key_survey:n=>{const{normalize:r}=n;return r(["Заполните опрос, помогите нам понять ваше использование и получите новый ключ API бесплатно!"])},includes:n=>{const{normalize:r}=n;return r(["Токены действительны для:"])},index_and_search:n=>{const{normalize:r}=n;return r(["Индекс и поиск"])},index_and_search1:n=>{const{normalize:r}=n;return r(["Индекс и поиск"])},input:n=>{const{normalize:r}=n;return r(["Запрос"])},input_api_key_error1:n=>{const{normalize:r}=n;return r(["Ваш ключ API недействителен!"])},input_length:n=>{const{normalize:r}=n;return r(["Входная длина"])},input_type:n=>{const{normalize:r}=n;return r(["Встроить как запрос или документ"])},input_type_explain:n=>{const{normalize:r}=n;return r(["Некоторые модели внедрения имеют специальные стратегии внедрения для запросов и документов. Одна и та же строка может быть внедрена как запрос или документ в зависимости от ее роли в вашем приложении."])},integrate:n=>{const{normalize:r}=n;return r(["Интегрировать"])},"jina-clip-v1_description":n=>{const{normalize:r}=n;return r(["Наши новейшие мультимодальные внедрения для поиска текста и изображений."])},"jina-colbert-v1-en_description":n=>{const{normalize:r}=n;return r(["Улучшенный ColBERT с длиной токена 8 КБ для внедрения и изменения ранжирования задач."])},"jina-colbert-v2_description":n=>{const{normalize:r}=n;return r(["Лучший многоязычный ColBERT с высочайшей производительностью при встраивании и переоценке"])},"jina-embeddings-v2-base-code_description":n=>{const{normalize:r}=n;return r(["Оптимизирован для поиска кода и строки документации."])},"jina-embeddings-v2-base-de_description":n=>{const{normalize:r}=n;return r(["Немецко-английские двуязычные встраивания с производительностью SOTA"])},"jina-embeddings-v2-base-en_description":n=>{const{normalize:r}=n;return r(["На одном уровне с text-embedding-ada002 от OpenAI."])},"jina-embeddings-v2-base-es_description":n=>{const{normalize:r}=n;return r(["Двуязычные встраивания на испанском и английском языках с производительностью SOTA"])},"jina-embeddings-v2-base-zh_description":n=>{const{normalize:r}=n;return r(["Китайско-английское двуязычное встраивание с производительностью SOTA"])},"jina-embeddings-v2-small-en_description":n=>{const{normalize:r}=n;return r(["Оптимизирован для низкой задержки и использования памяти."])},"jina-embeddings-v3_description":n=>{const{normalize:r}=n;return r(["Модель многоязыкового встраивания Frontier с производительностью SOTA"])},"jina-reranker-v1-base-en_description":n=>{const{normalize:r}=n;return r(["Наша первая модель реранкера, максимизирующая поиск и релевантность RAG."])},"jina-reranker-v1-tiny-en_description":n=>{const{normalize:r}=n;return r(["Самая быстрая модель реранжирования, лучше всего подходящая для надежного ранжирования большого количества документов."])},"jina-reranker-v1-turbo-en_description":n=>{const{normalize:r}=n;return r(["Лучшее сочетание быстрой скорости вывода и точных оценок релевантности."])},"jina-reranker-v2-base-multilingual_description":n=>{const{normalize:r}=n;return r(["Новейшая и лучшая модель реранкера с многоязычной поддержкой вызова функций и поиска кода."])},key:n=>{const{normalize:r}=n;return r(["API-ключ"])},key_enter_placeholder:n=>{const{normalize:r}=n;return r(["Пожалуйста, введите свой ключ API"])},key_enter_placeholder_to_topup:n=>{const{normalize:r}=n;return r(["Введите ключ API, который вы хотите пополнить."])},key_to_top_up:n=>{const{normalize:r}=n;return r(["Хотите пополнить счет другим ключом API? Вставьте его выше и нажмите «Сохранить»."])},key_warn:n=>{const{normalize:r}=n;return r(["Обязательно сохраните ключ API в безопасном месте. В противном случае вам нужно будет сгенерировать новый ключ."])},key_warn_v2:n=>{const{normalize:r}=n;return r(["Это ваш уникальный ключ. Храните его в надежном месте!"])},language_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Эта модель лучше всего поддерживает язык ",e(o("_language")),"."])},last_7_days:n=>{const{normalize:r}=n;return r(["Использование за последние 7 дней"])},late_chunking:n=>{const{normalize:r}=n;return r(["Позднее дробление"])},late_chunking_explain:n=>{const{normalize:r}=n;return r(["Примените метод позднего фрагментирования, чтобы использовать возможности длинного контекста модели для генерации контекстных внедрений фрагментов."])},learn_more:n=>{const{normalize:r}=n;return r(["Узнать больше"])},learn_poster:n=>{const{normalize:r}=n;return r(["Узнайте, как мы это сделали"])},learning1:n=>{const{normalize:r}=n;return r(["Изучение вложений"])},learning1_description:n=>{const{normalize:r}=n;return r(["С чего начать встраивание? Мы вас прикроем. Узнайте о встраиваниях с нуля с помощью нашего подробного руководства."])},length:n=>{const{normalize:r}=n;return r(["Длина токена"])},manage_billing:n=>{const{normalize:r}=n;return r(["Управление счетом"])},manage_billing_tip:n=>{const{normalize:r}=n;return r(["Управляйте своей платежной информацией, получайте счета и настраивайте автоматическое пополнение счета."])},manage_quota1:n=>{const{normalize:r}=n;return r(["Ключ API и биллинг"])},max_file_size:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Максимально допустимый размер: ",e(o("_maxSize")),"."])},maximize_tooltip:n=>{const{normalize:r}=n;return r(["Разверните эту панель с помощью Shift+1"])},mistake_contact:n=>{const{normalize:r}=n;return r(["Если вы считаете, что это ошибка, свяжитесь с нами."])},model_required:n=>{const{normalize:r}=n;return r(["Требуется модель"])},more_than_two2:n=>{const{normalize:r}=n;return r(["Пожалуйста, введите более двух документов, т.е. более двух строк."])},multi_embedding:n=>{const{normalize:r}=n;return r(["Многовекторный"])},multi_embedding_explain:n=>{const{normalize:r}=n;return r(["Эта модель вернет пакет контекстуализированных вложений для данного ввода. Каждый токен на входе сопоставляется с вектором на выходе."])},multilingual:n=>{const{normalize:r}=n;return r(["Многоязычная поддержка"])},multimodal:n=>{const{normalize:r}=n;return r(["Мультимодальный"])},multimodal_explain:n=>{const{normalize:r}=n;return r(["Эта модель может кодировать как текстовые, так и графические входные данные, что делает ее идеальной для задач мультимодального поиска."])},new:n=>{const{normalize:r}=n;return r(["Новая модель"])},no_data1:n=>{const{normalize:r}=n;return r(["Добавьте пару предложений, чтобы вычислить сходство."])},none:n=>{const{normalize:r}=n;return r(["Никто"])},normalized:n=>{const{normalize:r}=n;return r(["Нормализация L2"])},normalized_explain:n=>{const{normalize:r}=n;return r(["Масштабирует вложение так, что его евклидова (L2) норма становится 1, сохраняя направление. Полезно, когда нисходящий поток включает скалярное произведение, классификацию, визуализацию."])},oncsp:n=>{const{normalize:r}=n;return r(["На CSP"])},onprem:n=>{const{normalize:r}=n;return r(["Локально"])},open_tensorboard:n=>{const{normalize:r}=n;return r(["Открыть визуализатор"])},opensource:n=>{const{normalize:r}=n;return r(["Операционные системы"])},opensource_explain:n=>{const{normalize:r}=n;return r(["Эта модель имеет открытый исходный код и доступна на Hugging Face. Нажмите эту кнопку, чтобы просмотреть модель на Hugging Face."])},original_documents:n=>{const{normalize:r}=n;return r(["Предложения для вставки"])},original_documents_hint:n=>{const{normalize:r}=n;return r(["Введите сюда свои предложения. Каждая новая строка будет считаться отдельным предложением/документом."])},output:n=>{const{normalize:r}=n;return r(["Ответ"])},output_dim:n=>{const{normalize:r}=n;return r(["Размеры"])},output_dim_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Выходная размерность вектора внедрения из этой модели — ",e(o("_outputDim")),"."])},output_dimension:n=>{const{normalize:r}=n;return r(["Выходные размеры"])},pairwise_test:n=>{const{normalize:r}=n;return r(["Попарно"])},per_k:n=>{const{normalize:r}=n;return r(["/ 1 тыс. токенов"])},per_m:n=>{const{normalize:r}=n;return r(["/ 1 млн токенов"])},please_fill_docs_first:n=>{const{normalize:r}=n;return r(["Пожалуйста, сначала введите несколько предложений ниже, прежде чем искать."])},please_select_model:n=>{const{normalize:r}=n;return r(["Пожалуйста, выберите модель внедрения или модель реранкера"])},poster:n=>{const{normalize:r}=n;return r(["Плакат «Эволюция вложений»"])},poster_description:n=>{const{normalize:r}=n;return r(["Откройте для себя идеальный плакат для вашего помещения с увлекательной инфографикой или захватывающими визуальными эффектами, прослеживающими эволюцию моделей встраивания текста с 1950 года."])},pricing:n=>{const{normalize:r}=n;return r(["Цены на API"])},pricing_desc:n=>{const{normalize:r}=n;return r(["Цены на наши API основаны на количестве токенов, отправленных в запросах. Для Reader API это количество токенов в ответах. Эта модель ценообразования применима ко всем продуктам в поисковой базе Jina AI: API-интерфейсы внедрения, изменения рейтинга, чтения, автоматической тонкой настройки. С одним и тем же ключом API у вас есть доступ ко всем службам API."])},protectData1:n=>{const{normalize:r}=n;return r(["Данные запроса и документы не используются для обучения моделей."])},protectData2:n=>{const{normalize:r}=n;return r(["Шифрование данных при передаче (TLS 1.2+) и при хранении (AES-GCM 256)."])},protectData3:n=>{const{normalize:r}=n;return r(["Соответствует SOC 2 и GDPR."])},protect_data:n=>{const{normalize:r}=n;return r(["Защитите свои данные"])},public_cloud_integration:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["С <b>",e(o("_numPartners")),"</b> поставщиками облачных услуг"])},public_cloud_integration_desc:n=>{const{normalize:r}=n;return r(["Ваша компания использует AWS или Azure? Затем напрямую разверните наши модели базы поиска на этих платформах в вашей компании, чтобы ваши данные оставались в безопасности и соответствовали требованиям."])},query:n=>{const{normalize:r}=n;return r(["Запрос"])},raise_issue:n=>{const{normalize:r}=n;return r(["Поднять вопрос"])},rank_none_description:n=>{const{normalize:r}=n;return r(["Не используйте модели реранкера"])},read_api_docs:n=>{const{normalize:r}=n;return r(["Спецификация API"])},read_release_note:n=>{const{normalize:r}=n;return r(["Прочитать примечание к выпуску"])},recharge_threshold:n=>{const{normalize:r}=n;return r(["Порог пополнения"])},refresh:n=>{const{normalize:r}=n;return r(["Обновить"])},refresh_key_tooltip1:n=>{const{normalize:r}=n;return r(["Получите новый ключ API бесплатно"])},refresh_token_count1:n=>{const{normalize:r}=n;return r(["Обновите, чтобы получить доступные токены текущего ключа API."])},regenerate:n=>{const{normalize:r}=n;return r(["Регенерировать"])},remaining:n=>{const{normalize:r}=n;return r(["Доступные токены"])},remaining_left:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["У вас осталось <b>",e(o("_leftTokens")),"</b> токенов в ключе API, указанном ниже."])},request_number:n=>{const{normalize:r}=n;return r(["Запрос времени"])},request_path:n=>{const{normalize:r}=n;return r(["Запрос конечной точки"])},results_as_final_result:n=>{const{normalize:r}=n;return r(["#docs как конечный результат"])},results_fed_to_reranker:n=>{const{normalize:r}=n;return r(["#docs переданы в программу реранкинга"])},retry:n=>{const{normalize:r}=n;return r(["Повторить попытку"])},return_base64:n=>{const{normalize:r}=n;return r(["Base64 (как строка)"])},return_binary:n=>{const{normalize:r}=n;return r(["Двоичный (упакованный как int8)"])},return_float:n=>{const{normalize:r}=n;return r(["По умолчанию (как плавающее значение)"])},return_format:n=>{const{normalize:r}=n;return r(["Формат встраивания"])},return_format_explain:n=>{const{normalize:r}=n;return r(["Помимо числа с плавающей запятой, вы можете попросить его вернуть двоичный формат для более быстрого поиска векторов или кодировку Base64 для более быстрой передачи."])},return_format_title:n=>{const{normalize:r}=n;return r(["Возвращаемый тип данных"])},return_ubinary:n=>{const{normalize:r}=n;return r(["Двоичный (упакованный как uint8)"])},right_api_key_to_charge:n=>{const{normalize:r}=n;return r(["Пожалуйста, введите правильный ключ API для пополнения счета."])},running:n=>{const{normalize:r}=n;return r(["Активный"])},score:n=>{const{normalize:r}=n;return r(["Счет"])},search:n=>{const{normalize:r}=n;return r(["Поиск"])},search_hint:n=>{const{normalize:r}=n;return r(["Введите текст для поиска в предложениях, перечисленных ниже"])},select_classify_model:n=>{const{normalize:r}=n;return r(["Выберите классификатор"])},select_embedding_model:n=>{const{normalize:r}=n;return r(["Выберите вложения"])},select_rerank_model:n=>{const{normalize:r}=n;return r(["Выберите средство изменения рейтинга"])},show_api_key:n=>{const{normalize:r}=n;return r(["Показать ключ API"])},size:n=>{const{normalize:r}=n;return r(["Параметры"])},size_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Количество параметров в модели — ",e(o("_size")),". Обратите внимание, что это не размер файла модели."])},sleeping:n=>{const{normalize:r}=n;return r(["Неактивный"])},start_batch:n=>{const{normalize:r}=n;return r(["Начать пакетное внедрение"])},start_embedding:n=>{const{normalize:r}=n;return r(["Индекс"])},status_explain:n=>{const{normalize:r}=n;return r(["Наша бессерверная архитектура может разгружать определенные модели в периоды низкой нагрузки. Для активных моделей реакция немедленная. Неактивным моделям требуется несколько секунд для загрузки после первоначального запроса. После активации последующие запросы обрабатываются быстрее."])},task_type:n=>{const{normalize:r}=n;return r(["Задача ниже по течению"])},task_type_classification:n=>{const{normalize:r}=n;return r(["Классификация"])},task_type_classification_explain:n=>{const{normalize:r}=n;return r(["Классификация текста."])},task_type_explain:n=>{const{normalize:r}=n;return r(["Выберите задачу ниже по потоку, для которой будут использоваться вложения. Модель вернет оптимизированные вложения для этой задачи."])},task_type_none_explain:n=>{const{normalize:r}=n;return r(["Адаптер не будет использоваться. Будет возвращено общее вложение, полезное для отладки или взлома."])},task_type_retrieval_passage:n=>{const{normalize:r}=n;return r(["Проход для извлечения"])},task_type_retrieval_passage_explain:n=>{const{normalize:r}=n;return r(["Внедрение документов в задачу поиска документов по запросу."])},task_type_retrieval_query:n=>{const{normalize:r}=n;return r(["Запрос на поиск"])},task_type_retrieval_query_explain:n=>{const{normalize:r}=n;return r(["Встраивание запросов в задачу поиска документов по запросу."])},task_type_separation:n=>{const{normalize:r}=n;return r(["Разделение"])},task_type_separation_explain:n=>{const{normalize:r}=n;return r(["Кластеризация документов, визуализация корпуса."])},"task_type_text-matching":n=>{const{normalize:r}=n;return r(["Сопоставление текста"])},"task_type_text-matching_explain":n=>{const{normalize:r}=n;return r(["Семантическое сходство текста, общий симетрический поиск, рекомендация, поиск похожего, дедупликация."])},tax_may_apply:n=>{const{normalize:r}=n;return r(["В зависимости от вашего местоположения с вас может взиматься плата в долларах США, евро или других валютах. Могут взиматься налоги."])},text1:n=>{const{normalize:r}=n;return r(["Левый"])},text2:n=>{const{normalize:r}=n;return r(["Верно"])},title:n=>{const{normalize:r}=n;return r(["Встраивание API"])},token_example:n=>{const{normalize:r}=n;return r(["Твит стоит около 20 токенов, новостная статья — около 1000 токенов, а роман Чарльза Диккенса «Повесть о двух городах» — более миллиона токенов."])},token_length_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Максимальная длина входной последовательности токенов – ",e(o("_tokenLength"))," для этой модели."])},tokens:n=>{const{normalize:r}=n;return r(["Токены"])},tools:n=>{const{normalize:r}=n;return r(["Инструменты"])},top_up_button:n=>{const{normalize:r}=n;return r(["Пополнить старый ключ"])},top_up_button_explain:n=>{const{normalize:r}=n;return r(["Интеграция этого ключа API предлагает более профессиональное решение, устраняющее необходимость частой смены ключа. Данные об использовании сохраняются и доступны в любое время."])},top_up_warning_message1:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["В текущем ключе API осталось токенов ",e(o("_remainedTokens")),", и он будет заменен новым ключом с токенами ",e(o("_freeTokens")),". Вы можете продолжать использовать или пополнять старый ключ, если сохранили его в надежном месте. Как вы хотите продолжить?"])},top_up_warning_title:n=>{const{normalize:r}=n;return r(["Заменить старый ключ API"])},total_documents:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Ход внедрения: ",e(o("_Processed")),"/",e(o("_Count"))," предложений."])},tuning:n=>{const{normalize:r}=n;return r(["Тонкая настройка"])},turnstile_error:n=>{const{normalize:r}=n;return r(["Мы не можем сгенерировать ключ API, поскольку не можем проверить, являетесь ли вы человеком."])},turnstile_unsupported:n=>{const{normalize:r}=n;return r(["Мы не можем сгенерировать ключ API, поскольку ваш браузер не поддерживается."])},ubinary_description:n=>{const{normalize:r}=n;return r(["Вложения упакованы как uint8. Гораздо эффективнее для хранения, поиска и передачи."])},upload:n=>{const{normalize:r}=n;return r(["Загрузить"])},upload_file:n=>{const{normalize:r}=n;return r(["Нажмите здесь, чтобы загрузить файл"])},usage:n=>{const{normalize:r}=n;return r(["Применение"])},usage_amount:n=>{const{normalize:r}=n;return r(["Токены"])},usage_history:n=>{const{normalize:r}=n;return r(["Использование за последние 7 дней"])},usage_history_explain:n=>{const{normalize:r}=n;return r(["Данные не поступают в режиме реального времени и могут задерживаться на несколько минут."])},usage_reason:n=>{const{normalize:r}=n;return r(["Описание"])},usage_reason_consume:n=>{const{normalize:r}=n;return r(["Использовал"])},usage_reason_purchase:n=>{const{normalize:r}=n;return r(["Куплено"])},usage_reason_trial:n=>{const{normalize:r}=n;return r(["Пробный"])},usage_rerank:n=>{const{normalize:r}=n;return r(["Применение"])},usage_time:n=>{const{normalize:r}=n;return r(["Дата время"])},v3_description:n=>{const{normalize:r}=n;return r(["<code>jina-embeddings-v3</code> — это передовая многоязычная модель встраивания текста с 570 млн параметров и длиной токена 8192, превосходящая последние фирменные встраивания от OpenAI и Cohere на MTEB. Прочитайте наш блог и исследовательскую работу ниже."])},v3_title:n=>{const{normalize:r}=n;return r(["v3: Frontier Многоязычные Вложения"])},vector_database_integration1:n=>{const{normalize:r}=n;return r(["Интеграции"])},vector_database_integration2:n=>{const{normalize:r}=n;return r(["Наш API для встраивания изначально интегрирован с различными известными базами данных, векторными хранилищами, платформами RAG и LLMOps. Для начала просто скопируйте и вставьте свой ключ API в любую из перечисленных интеграций для быстрого и беспроблемного запуска."])},vector_database_integration3:n=>{const{normalize:r}=n;return r(["Наш API для встраивания и переранжирования изначально интегрирован с различными известными базами данных, векторными хранилищами, платформами RAG и LLMOps. Для начала просто скопируйте и вставьте свой ключ API в любую из перечисленных интеграций для быстрого и беспроблемного запуска."])},vector_database_integration_description:n=>{const{normalize:r}=n;return r(["Беспрепятственно и легко интегрируйте Jina Embeddings API с любой векторной базой данных, структурами оркестрации LLM и приложениями RAG, указанными ниже. Наши уроки покажут вам, как это сделать."])},view_details:n=>{const{normalize:r}=n;return r(["Посмотреть детали"])},visualization_example:n=>{const{normalize:r}=n;return r(["Отображение всех предложений из этого раздела в трехмерном векторном пространстве."])},visualization_example_you_can:n=>{const{normalize:r}=n;return r(["Используйте наш API ниже, вы тоже можете это сделать!"])},visualize:n=>{const{normalize:r}=n;return r(["Визуализируйте"])},visualize_done:n=>{const{normalize:r}=n;return r(["Визуализация завершена, теперь вы можете нажать верхнюю кнопку, чтобы открыть визуализатор."])},wait_for_processing:n=>{const{normalize:r}=n;return r(["Ваш запрос обрабатывается."])},wait_stripe:n=>{const{normalize:r}=n;return r(["Открытие платежа Stripe, пожалуйста, подождите"])},what_are_embedding:n=>{const{normalize:r}=n;return r(["Что такое вложения?"])},what_are_embedding_answer:n=>{const{normalize:r}=n;return r([`Представьте себе, что вы учите компьютер понимать нюансы значений слов и фраз. Традиционные методы, опиравшиеся на жесткие, основанные на правилах системы, потерпели неудачу, поскольку язык слишком сложен и изменчив. Введите встраивание текста: мощное решение, которое переводит текст на язык чисел, в частности, в векторы в многомерном пространстве.

Рассмотрим фразы «солнечная погода» и «ясное небо». Нам они рисуют аналогичную картину. Через призму вложений эти фразы преобразуются в числовые векторы, находящиеся близко друг к другу в этом многомерном пространстве, фиксируя их семантическое родство. Эта близость в векторном пространстве связана не только со схожестью слов или фраз; речь идет о понимании контекста, настроений и даже тонких смысловых нюансов.

Почему этот прорыв важен? Во-первых, он устраняет разрыв между богатством человеческого языка и вычислительной эффективностью алгоритмов. Алгоритмы превосходно обрабатывают цифры, а не интерпретируют тексты. Преобразуя текст в векторы, встраивания позволяют этим алгоритмам «понимать» и обрабатывать язык способами, которые ранее были недоступны.

Практическое применение обширно и разнообразно. Будь то рекомендация контента, который соответствует вашим интересам, активация диалогового искусственного интеллекта, который кажется удивительно человечным, или даже обнаружение тонких закономерностей в больших объемах текста, встраивание является ключевым моментом. Они позволяют машинам выполнять такие задачи, как анализ настроений, языковой перевод и многое другое, при этом понимание языка становится все более тонким и тонким.`])},what_is_a_token:n=>{const{normalize:r}=n;return r(["Токен в обработке текста — это единица, часто слово. Например: «Джина ИИ великолепен!» становится пятью знаками, включая знаки препинания."])},why_do_you_need:n=>{const{normalize:r}=n;return r(["Выбор правильных вложений"])},why_do_you_need_after:n=>{const{normalize:r}=n;return r(["Используя глубокие нейронные сети и LLM, наши модели внедрения представляют мультимодальные данные в оптимизированном формате, улучшая машинное понимание, эффективное хранение и позволяя использовать передовые приложения искусственного интеллекта. Эти внедрения играют решающую роль в понимании данных, повышении вовлеченности пользователей, преодолении языковых барьеров и оптимизации процессов разработки."])},why_do_you_need_before:n=>{const{normalize:r}=n;return r(["Наши модели внедрения предназначены для охвата разнообразных приложений поиска и GenAI."])},why_need_1_description:n=>{const{normalize:r}=n;return r(["Наша базовая модель внедрения, основанная на JinaBERT, создана для широкого спектра приложений. Он превосходно понимает подробный текст, что делает его идеальным для семантического поиска, классификации контента и сложного языкового анализа. Его универсальность не имеет себе равных: он поддерживает создание передовых инструментов анализа настроений, обобщения текста и систем персонализированных рекомендаций."])},why_need_1_title:n=>{const{normalize:r}=n;return r(["Вложения общего назначения"])},why_need_2_description:n=>{const{normalize:r}=n;return r(["Наши двуязычные модели облегчают общение на разных языках, расширяя возможности многоязычных платформ, глобальную поддержку клиентов и обнаружение межъязыкового контента. Эти модели, предназначенные для освоения немецко-английского и китайско-английского переводов, упрощают взаимодействие и способствуют взаимопониманию между различными языковыми группами."])},why_need_2_title:n=>{const{normalize:r}=n;return r(["Двуязычные встраивания"])},why_need_3_description:n=>{const{normalize:r}=n;return r(["Наша модель внедрения кода, специально разработанная для разработчиков, оптимизирует такие задачи кодирования, как суммирование, генерация кода и автоматические проверки. Он повышает производительность, предлагая более глубокое понимание структур кода и предлагая улучшения, что делает его незаменимым для разработки расширенных плагинов IDE, автоматической документации и передовых инструментов отладки."])},why_need_3_title:n=>{const{normalize:r}=n;return r(["Встраивание кода"])},why_need_4_description:n=>{const{normalize:r}=n;return r(["Jina CLIP — наша новейшая мультимодальная модель внедрения изображений и текста. Большим улучшением по сравнению с OpenAI CLIP является то, что эту единую модель можно использовать для извлечения текста-текста, а также задач извлечения текста-изображения, изображения-текста и изображения-изображения! Итак, одна модель, две модальности, четыре направления поиска!"])},why_need_4_title:n=>{const{normalize:r}=n;return r(["Мультимодальные вложения"])},write_email_here:n=>{const{normalize:r}=n;return r(["Пожалуйста, введите адрес электронной почты, на который вы хотите получить ссылку для скачивания после завершения."])},you_can_leave:n=>{const{normalize:r}=n;return r(["Вы можете покинуть эту страницу, и после завершения мы вышлем вам ссылку для скачивания."])}},embeddings:{description:n=>{const{normalize:r}=n;return r(["Мультимодальные многоязычные вложения мирового класса."])}},faq:{answer1:n=>{const{normalize:r}=n;return r(["Jina AI специализируется на мультимодальных технологиях искусственного интеллекта, включая настройку моделей, обслуживание моделей, настройку подсказок и обслуживание подсказок. Мы используем передовые инструменты, такие как Kubernetes и бессерверные архитектуры, для создания надежных, масштабируемых и готовых к работе решений."])},answer10:n=>{const{normalize:r}=n;return r(["Мы предоставляем различные варианты лицензирования в зависимости от характера проекта и потребностей клиента. Подробные условия можно обсудить с нашим отделом продаж."])},answer11:n=>{const{normalize:r}=n;return r(["Мы предоставляем услуги по всему миру, наша штаб-квартира находится в Берлине, Европа, а дополнительные офисы — в Пекине и Шэньчжэне."])},answer12:n=>{const{normalize:r}=n;return r(["Да, мы предлагаем поддержку на месте, особенно для клиентов, находящихся рядом с нашими офисами в Берлине, Пекине и Шэньчжэне. В других местах мы стремимся обеспечить наилучшую удаленную поддержку и при необходимости можем организовать поддержку на месте."])},answer2:n=>{const{normalize:r}=n;return r(["Наш опыт охватывает широкий спектр, включая большие языковые модели, текст, изображения, видео, понимание звука, нейронный поиск и генеративное искусство."])},answer3:n=>{const{normalize:r}=n;return r(["Да, наши решения масштабируются и готовы к работе. Мы создаем наши решения с использованием облачных технологий, которые обеспечивают эффективное масштабирование и надежную работу в производственных средах."])},answer4:n=>{const{normalize:r}=n;return r(["Наши услуги универсальны и адаптируемы, что делает их подходящими для широкого круга отраслей, включая электронную коммерцию, юридические технологии, цифровой маркетинг, игры, здравоохранение, финансы и многие другие."])},answer5:n=>{const{normalize:r}=n;return r(["Вы можете связаться с нашим отделом продаж через контактную форму на этой странице. Мы хотели бы обсудить требования вашего проекта и то, как наши решения могут помочь вашему бизнесу."])},answer6:n=>{const{normalize:r}=n;return r(["Мы предоставляем постоянную поддержку для обеспечения бесперебойной работы наших решений. Это включает в себя устранение неполадок, регулярные обновления и улучшения на основе ваших отзывов и потребностей."])},answer7:n=>{const{normalize:r}=n;return r(["Продолжительность проекта варьируется в зависимости от сложности и объема проекта. После понимания ваших требований, мы можем предоставить более точную оценку."])},answer8:n=>{const{normalize:r}=n;return r(["Безопасность данных является нашим главным приоритетом. Мы придерживаемся строгих политик и правил защиты данных, чтобы обеспечить безопасность и конфиденциальность ваших данных."])},answer9:n=>{const{normalize:r}=n;return r(["Цена зависит от сложности проекта и требований. Мы предлагаем модели ценообразования как на основе проекта, так и на основе авансовых платежей. Пожалуйста, свяжитесь с нашим отделом продаж для получения дополнительной информации."])},question1:n=>{const{normalize:r}=n;return r(["На чем специализируется Jina AI?"])},question10:n=>{const{normalize:r}=n;return r(["Каковы условия лицензирования ваших решений?"])},question11:n=>{const{normalize:r}=n;return r(["Какова ваша зона обслуживания?"])},question12:n=>{const{normalize:r}=n;return r(["Вы предлагаете поддержку на месте?"])},question2:n=>{const{normalize:r}=n;return r(["С какими типами ИИ работает Jina AI?"])},question3:n=>{const{normalize:r}=n;return r(["Ваши решения масштабируемы и готовы к работе?"])},question4:n=>{const{normalize:r}=n;return r(["Какие отрасли могут извлечь выгоду из решений Jina AI?"])},question5:n=>{const{normalize:r}=n;return r(["Как нам начать проект с Jina AI?"])},question6:n=>{const{normalize:r}=n;return r(["Какую поддержку вы оказываете после внедрения решения?"])},question7:n=>{const{normalize:r}=n;return r(["Какова типичная продолжительность проекта?"])},question8:n=>{const{normalize:r}=n;return r(["Как Jina AI защищает мои данные?"])},question9:n=>{const{normalize:r}=n;return r(["Какова структура ценообразования на ваши услуги?"])}},faq_button:n=>{const{normalize:r}=n;return r(["Часто задаваемые вопросы"])},farewell:{text:n=>{const{normalize:r}=n;return r(["Прощание."])}},finetuner:{description:n=>{const{normalize:r}=n;return r(["Точная настройка встраивания данных для конкретного домена для повышения качества поиска"])},intro:n=>{const{normalize:r}=n;return r(["Ваша компания. Ваши данные. Ваша модель"])}},finetuner_plus:{description:n=>{const{normalize:r}=n;return r(["Расширьте возможности своего предприятия с помощью локальных решений для точной настройки"])}},finetuning:{api_key:n=>{const{normalize:r}=n;return r(["Введите свой ключ API."])},back:n=>{const{normalize:r}=n;return r(["Назад"])},base_model_selected:n=>{const{normalize:r}=n;return r(["Выбрана базовая модель"])},click_start:n=>{const{normalize:r}=n;return r(["Согласитесь с условиями и приступайте к тонкой настройке."])},confirm_title:n=>{const{normalize:r}=n;return r(["Подтвердить работу по тонкой настройке"])},confirm_your_email:n=>{const{normalize:r}=n;return r(["Повторно введите свой адрес электронной почты, чтобы подтвердить работу по тонкой настройке. Обновления и ссылка для скачивания будут отправлены на этот адрес электронной почты."])},consent0:n=>{const{normalize:r}=n;return r(["Я согласен, что по моим инструкциям будут сформированы синтетические данные для тонкой настройки модели."])},consent1:n=>{const{normalize:r}=n;return r(["Я подтверждаю, что окончательная модель и синтетические данные будут общедоступны на Hugging Face."])},consent2:n=>{const{normalize:r}=n;return r(["Я понимаю, что эта функция находится в стадии бета-тестирования, и Jina AI не предоставляет никаких гарантий. Цены и UX могут измениться."])},continue:n=>{const{normalize:r}=n;return r(["Продолжать"])},cost_1m_token:n=>{const{normalize:r}=n;return r(["Каждая работа по тонкой настройке потребляет 1 миллион токенов. Убедитесь, что у вас достаточно жетонов, или пополните свой баланс. Вы также можете создать новый ключ API. Каждый ключ API поставляется с 1 млн бесплатных токенов."])},doc_explain:n=>{const{normalize:r}=n;return r(["Опишите, как должен выглядеть согласованный документ."])},domain_explain:n=>{const{normalize:r}=n;return r(["Предоставьте подробное описание того, как будут использоваться точно настроенные встраивания. Это важно для создания высококачественных синтетических данных, которые улучшат производительность ваших внедрений."])},domain_explain2:n=>{const{normalize:r}=n;return r(["Существует три способа указать ваше требование: общая инструкция, URL-адрес или описание запроса-документа. Выбери один."])},domain_hint:n=>{const{normalize:r}=n;return r(["Опишите домен, для которого вы хотите выполнить точную настройку."])},email_not_match:n=>{const{normalize:r}=n;return r(["Адреса электронной почты не совпадают. Пожалуйста, подтвердите."])},failed_job:n=>{const{normalize:r}=n;return r(["Запрос на тонкую настройку не выполнен. См. причину ниже."])},find_on_huggingface:n=>{const{normalize:r}=n;return r(["Найдите результаты на Hugging Face"])},general_instruction:n=>{const{normalize:r}=n;return r(["Или общая инструкция"])},general_instruction_caption:n=>{const{normalize:r}=n;return r(["Предоставьте подробное описание того, как будут использоваться точно настроенные встраивания."])},general_instruction_explain:n=>{const{normalize:r}=n;return r(["Опишите свой домен в свободной форме. Вы можете представить это как «подсказку», как в ChatGPT."])},how_it_works:n=>{const{normalize:r}=n;return r(["Узнайте о процессе тонкой настройки."])},job_acknowledged:n=>{const{normalize:r}=n;return r(["Ваша работа по тонкой настройке поставлена ​​в очередь. Вы получите электронное письмо, когда задание начнется. Весь процесс часто занимает 20 минут."])},new_key:n=>{const{normalize:r}=n;return r(["Получить новый ключ"])},not_enough_token:n=>{const{normalize:r}=n;return r(["Недостаточно токенов в этом ключе API. Пожалуйста, пополните свой баланс или используйте другой ключ API."])},placeholder:n=>{const{normalize:r}=n;return r(["Претензии по страхованию автомобиля"])},preview:n=>{const{normalize:r}=n;return r(["Предварительный просмотр"])},query_doc:n=>{const{normalize:r}=n;return r(["Описание документа-запроса"])},query_doc_caption:n=>{const{normalize:r}=n;return r(["Опишите, как выглядит запрос и как выглядит соответствующий документ в вашем домене."])},query_explain:n=>{const{normalize:r}=n;return r(["Опишите, как выглядит запрос."])},reset:n=>{const{normalize:r}=n;return r(["Начать сначала"])},select_base_model:n=>{const{normalize:r}=n;return r(["Выберите базовую модель внедрения для тонкой настройки."])},select_base_model_explain:n=>{const{normalize:r}=n;return r(["Выберите базовую модель в качестве отправной точки для тонкой настройки. Обычно хорошим выбором является base-en, но для задач на других языках рассмотрите возможность использования двуязычной модели."])},start_tuning:n=>{const{normalize:r}=n;return r(["Начать тонкую настройку"])},url:n=>{const{normalize:r}=n;return r(["Или URL веб-страницы"])},url_caption:n=>{const{normalize:r}=n;return r(["Обратитесь к содержимому URL-адреса для точной настройки."])},url_explain:n=>{const{normalize:r}=n;return r(["Публичный URL-адрес веб-страницы, содержащей контент, который вы хотите настроить."])},use_url:n=>{const{normalize:r}=n;return r(["Вместо этого используйте URL-адрес. Включение этого параметра означает, что мы будем использовать содержимое страницы этого URL-адреса для создания синтетических данных для точной настройки."])},wait_for_processing:n=>{const{normalize:r}=n;return r(["Пожалуйста подождите, пока мы обрабатываем ваш запрос..."])},which_domain:n=>{const{normalize:r}=n;return r(["Тонкая настройка домена"])},write_email_explain:n=>{const{normalize:r}=n;return r(["Точная настройка требует времени. Мы будем сообщать по электронной почте о начале, ходе, завершении и любых проблемах вашей работы по точной настройке, а также о подробностях точно настроенной модели и наборе обучающих данных."])}},footer:{address_beijing:n=>{const{normalize:r}=n;return r(["Пекин, Китай"])},address_berlin:n=>{const{normalize:r}=n;return r(["Берлин, Германия (штаб-квартира)"])},address_shenzhen:n=>{const{normalize:r}=n;return r(["Шэньчжэнь, Китай"])},all_rights_reserved:n=>{const{normalize:r}=n;return r(["Все права защищены."])},company:n=>{const{normalize:r}=n;return r(["Компания"])},developers:n=>{const{normalize:r}=n;return r(["Разработчики"])},docs:n=>{const{normalize:r}=n;return r(["Документы"])},enterprise:n=>{const{normalize:r}=n;return r(["Предприятие"])},get_api_key:n=>{const{normalize:r}=n;return r(["Получить ключ API Jina AI"])},offices:n=>{const{normalize:r}=n;return r(["Офисы"])},power_users:n=>{const{normalize:r}=n;return r(["Опытные пользователи"])},privacy:n=>{const{normalize:r}=n;return r(["Конфиденциальность"])},privacy_policy:n=>{const{normalize:r}=n;return r(["политика конфиденциальности"])},privacy_settings:n=>{const{normalize:r}=n;return r(["Управление файлами cookie"])},security:n=>{const{normalize:r}=n;return r(["Безопасность"])},sefo:n=>{const{normalize:r}=n;return r(["Поиск Фонда"])},soc2:n=>{const{normalize:r}=n;return r(["Мы соответствуем стандарту SOC 2 Type 1 Американского института сертифицированных бухгалтеров (AICPA)."])},status:n=>{const{normalize:r}=n;return r(["Статус API"])},status_short:n=>{const{normalize:r}=n;return r(["Статус"])},tc:n=>{const{normalize:r}=n;return r(["Условия использования"])},tc1:n=>{const{normalize:r}=n;return r(["Условия"])}},get_new_key:n=>{const{normalize:r}=n;return r(["Получите свой API-ключ"])},github:{stars:n=>{const{normalize:r}=n;return r(["Звезды"])}},header:{about_us:n=>{const{normalize:r}=n;return r(["О нас"])},company:n=>{const{normalize:r}=n;return r(["Компания"])},contact_us:n=>{const{normalize:r}=n;return r(["Связаться с отделом продаж"])},developers_others:n=>{const{normalize:r}=n;return r(["Дополнительные инструменты разработчика"])},enterprise_others:n=>{const{normalize:r}=n;return r(["Больше корпоративных инструментов"])},for_developers:n=>{const{normalize:r}=n;return r(["Для разработчиков"])},for_developers_description:n=>{const{normalize:r}=n;return r(["Испытайте комплексный стек мультимодального ИИ с открытым исходным кодом, разработанный для разработчиков."])},for_enterprise:n=>{const{normalize:r}=n;return r(["Для предприятий"])},for_enterprise_description:n=>{const{normalize:r}=n;return r(["Откройте для себя масштабируемые мультимодальные стратегии искусственного интеллекта, адаптированные к потребностям бизнеса."])},for_power_users:n=>{const{normalize:r}=n;return r(["Для опытных пользователей"])},for_power_users_description:n=>{const{normalize:r}=n;return r(["Используйте наши оптимизированные мультимодальные инструменты для повышения производительности."])},internship1:n=>{const{normalize:r}=n;return r(["Стажерская программа"])},jobs:n=>{const{normalize:r}=n;return r(["Присоединяйтесь к нам"])},join_discord:n=>{const{normalize:r}=n;return r(["Присоединяйтесь к нашему сообществу Discord"])},logos:n=>{const{normalize:r}=n;return r(["Скачать логотип"])},maximize:n=>{const{normalize:r}=n;return r(["⇧1"])},maximize_btn:n=>{const{normalize:r}=n;return r(["Увеличить"])},news:n=>{const{normalize:r}=n;return r(["Новости"])},open_day:n=>{const{normalize:r}=n;return r(["День открытых дверей"])},open_in_full:n=>{const{normalize:r}=n;return r(["Показать все корпоративные продукты в новом окне"])},power_users_others:n=>{const{normalize:r}=n;return r(["Больше инструментов для опытных пользователей"])},products:n=>{const{normalize:r}=n;return r(["Продукты"])}},hub:{description:n=>{const{normalize:r}=n;return r(["Делитесь и открывайте строительные блоки для мультимодальных приложений ИИ"])}},huggingface:{sentence_similarity:n=>{const{normalize:r}=n;return r(["Встраивание предложения"])},updated_about:n=>{const{normalize:r}=n;return r(["Обновлено о"])}},impact_snapshots:{project1:n=>{const{normalize:r}=n;return r(["Включен высокоточный поиск в данных 3D-сетки с использованием информации об облаке точек."])},project10:n=>{const{normalize:r}=n;return r(["Использование компьютерного зрения для улучшения цифровой доступности государственных веб-сайтов."])},project11:n=>{const{normalize:r}=n;return r(["Тонкая настройка LLM для консалтинговой фирмы для оптимизации анализа финансовых данных."])},project12:n=>{const{normalize:r}=n;return r(["Расширенные маркетинговые стратегии за счет точной настройки моделей преобразования текста в изображение для передачи стиля."])},project2:n=>{const{normalize:r}=n;return r(["Разработан поисковик по контенту для короткометражных анимационных фильмов."])},project3:n=>{const{normalize:r}=n;return r(["Улучшенные показатели конверсии электронной коммерции за счет точной настройки моделей встраивания."])},project4:n=>{const{normalize:r}=n;return r(["Выполнена оперативная настройка для повышения эффективности бизнес-консалтинговой компании."])},project5:n=>{const{normalize:r}=n;return r(["Первопроходец в понимании игровых сцен и автоматических аннотаций для ведущего игрового предприятия."])},project6:n=>{const{normalize:r}=n;return r(["Реализовано расширение ввода в реальном времени для чат-ботов, улучшающее взаимодействие с пользователем."])},project7:n=>{const{normalize:r}=n;return r(["Революция в области юридических технологий, обеспечивающая эффективный поиск в длинных юридических документах."])},project8:n=>{const{normalize:r}=n;return r(["Поддержка высокопроизводительного генеративного художественного сервиса для крупномасштабных операций."])},project9:n=>{const{normalize:r}=n;return r(["Осуществлял интеллектуальный анализ и моделирование процессов с использованием передовых языковых моделей."])}},inference:{description:n=>{const{normalize:r}=n;return r(["Современные мультимодальные модели, доступные для логического вывода"])}},integrations:{embedding:n=>{const{normalize:r}=n;return r(["Вложения"])},reranker:n=>{const{normalize:r}=n;return r(["Реранкер"])},which_to_go:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Какой из них интегрировать с ",e(o("_vendor")),"?"])}},internship_faq:{answer1:n=>{const{normalize:r}=n;return r(["Бакалавриат, магистратура и доктор философии. студентам со всего мира, интересующимся такими областями, как исследования, инженерия, маркетинг и продажи, рекомендуется подавать заявки. Мы также приветствуем нетехнические стажировки в области маркетинга, продаж, помощи руководителям и т. д. Мы ищем увлеченных людей, готовых стать пионерами мультимодального ИИ вместе с нами."])},answer10:n=>{const{normalize:r}=n;return r(["Да, наша программа стажировок предлагает конкурентоспособное вознаграждение."])},answer11:n=>{const{normalize:r}=n;return r(["Став стажером Jina AI, вы получите практический опыт работы над сложными проектами, поучитесь у отраслевых экспертов, станете частью динамичного сообщества и получите возможность внести реальный вклад в нашу новаторскую работу в области мультимодального ИИ."])},answer2:n=>{const{normalize:r}=n;return r(["Стажировку необходимо проводить на месте в одном из наших офисов, расположенных в Берлине, Пекине и Шэньчжэне."])},answer3:n=>{const{normalize:r}=n;return r(["Да, Jina AI предлагает разумную помощь в процессе получения визы для успешных заявителей."])},answer4:n=>{const{normalize:r}=n;return r(["Да, Jina AI обеспечивает разумное покрытие расходов на проживание для стажеров в течение периода стажировки."])},answer5:n=>{const{normalize:r}=n;return r(["Да, во время стажировки в Jina AI можно работать над магистерской диссертацией, что обычно применимо к студентам немецких университетов. Тем не менее, вы должны получить предварительное уведомление и согласие от научного руководителя вашего университета. Обратите внимание, что мы не помогаем студентам найти консультантов."])},answer6:n=>{const{normalize:r}=n;return r(["Процесс подачи заявки включает отправку формы заявки, резюме, сопроводительного письма, выражающего ваш интерес и мотивацию, а также любых соответствующих профессиональных ссылок, таких как GitHub или LinkedIn. Мы оцениваем кандидатов на основе их результатов во время собеседования и их результатов в их университете."])},answer7:n=>{const{normalize:r}=n;return r(["Да, успешные стажеры могут получить рекомендательное письмо по окончании стажировки, подписанное нашим генеральным директором."])},answer8:n=>{const{normalize:r}=n;return r(["Продолжительность стажировки зависит от роли и проекта. Однако обычно он составляет от трех до шести месяцев."])},answer9:n=>{const{normalize:r}=n;return r(["Да, мы приветствуем заявки от всех ученых. Мы ценим вашу страсть и стремление учиться так же, как предыдущий опыт."])},question1:n=>{const{normalize:r}=n;return r(["Кто может подать заявку на участие в программе стажировки Jina AI?"])},question10:n=>{const{normalize:r}=n;return r(["Это оплачиваемая стажировка?"])},question11:n=>{const{normalize:r}=n;return r(["Какие возможности я получу в качестве стажера Jina AI?"])},question2:n=>{const{normalize:r}=n;return r(["Где будет проходить стажировка?"])},question3:n=>{const{normalize:r}=n;return r(["Помогает ли Jina AI с оформлением визы?"])},question4:n=>{const{normalize:r}=n;return r(["Предоставляет ли Jina AI какие-либо надбавки или льготы для стажеров?"])},question5:n=>{const{normalize:r}=n;return r(["Могу ли я работать над магистерской диссертацией во время стажировки в Jina AI?"])},question6:n=>{const{normalize:r}=n;return r(["Что включает в себя процесс подачи заявки?"])},question7:n=>{const{normalize:r}=n;return r(["Предоставляет ли Jina AI какое-либо рекомендательное письмо после стажировки?"])},question8:n=>{const{normalize:r}=n;return r(["Какова продолжительность стажировки?"])},question9:n=>{const{normalize:r}=n;return r(["Могу ли я подать заявку, если у меня нет опыта работы с ИИ?"])}},internship_page:{about_internship_program:n=>{const{normalize:r}=n;return r(["О программе стажировки"])},about_internship_program_desc1:n=>{const{normalize:r}=n;return r(["Мы рады предложить эту уникальную возможность талантливым людям присоединиться к нашей динамичной команде и внести свой вклад в новаторские проекты в области искусственного интеллекта. Эта стажировка предназначена для того, чтобы предоставить вам ценный практический опыт, наставничество и знакомство с передовыми технологиями, формирующими будущее ИИ."])},about_internship_program_desc2:n=>{const{normalize:r}=n;return r(["В Jina AI мы понимаем важность воспитания и использования молодых талантов. Мы понимаем, что стажеры привносят свежие взгляды, энтузиазм и креативность, вдохновляя нашу команду новыми идеями и подходами. Предоставляя стажировки, мы стремимся способствовать росту будущих лидеров индустрии искусственного интеллекта, предлагая им реальный опыт в благоприятной и сложной среде."])},alumni:n=>{const{normalize:r}=n;return r(["ВЫПУСКНИКИ"])},alumni_network:n=>{const{normalize:r}=n;return r(["Наша процветающая сеть выпускников"])},application:n=>{const{normalize:r}=n;return r(["Приложение"])},application_desc:n=>{const{normalize:r}=n;return r(["Отправляйтесь в преобразующее путешествие вместе с Jina AI. Наша комплексная программа стажировок приглашает всех страстных умов, которые стремятся формировать будущее искусственного интеллекта. Присоединяйтесь к нам, чтобы получить реальный опыт, работать над сложными проектами и сотрудничать с некоторыми из самых ярких умов в индустрии искусственного интеллекта."])},apply:n=>{const{normalize:r}=n;return r(["Применить сейчас"])},autumn:n=>{const{normalize:r}=n;return r(["Осень"])},description:n=>{const{normalize:r}=n;return r(["Призыв студентов по всему миру: стажировка в области исследований, инженерии, маркетинга, продаж и т. д."])},dev_rel_intern:n=>{const{normalize:r}=n;return r(["Стажер по связям с разработчиками"])},enthusiastic:n=>{const{normalize:r}=n;return r(["ЭНТУЗИАСТИЧНЫЙ"])},explore_stories_from_our_interns:n=>{const{normalize:r}=n;return r(["Ознакомьтесь с историями наших стажеров"])},explore_stories_from_our_interns1:n=>{const{normalize:r}=n;return r(["Вдохновитесь путешествиями наших стажеров"])},innovative:n=>{const{normalize:r}=n;return r(["ИННОВАЦИОННЫЙ"])},intern_work1:n=>{const{normalize:r}=n;return r(["Точно настроенные модели LLM для лучшего встраивания"])},intern_work2:n=>{const{normalize:r}=n;return r(["Изучил потенциал поисковой дополненной генерации"])},intern_work3:n=>{const{normalize:r}=n;return r(["Опубликована статья на тему встраивания предложений."])},intern_work4:n=>{const{normalize:r}=n;return r(["Привнесение постоянной юношеской жизненной энергии в команду"])},intern_work5:n=>{const{normalize:r}=n;return r(["Тестируемые методы квантования для сжатия LLM"])},intern_work6:n=>{const{normalize:r}=n;return r(["Создание и продвижение привлекательной кампании для PromptPerfect"])},intern_work7:n=>{const{normalize:r}=n;return r(["Быстро разработанный и улучшенный JinaColBERT V2"])},recruiting_and_administrative_intern:n=>{const{normalize:r}=n;return r(["Рекрутинговый и административный стажер"])},researcher_intern:n=>{const{normalize:r}=n;return r(["Стажер-исследователь"])},self_motivated:n=>{const{normalize:r}=n;return r(["САМОМОТИВИРОВАННЫЙ"])},software_engineer_intern:n=>{const{normalize:r}=n;return r(["Инженер-программист Стажер"])},spring:n=>{const{normalize:r}=n;return r(["Весна"])},submit_application:n=>{const{normalize:r}=n;return r(["Начните свое приключение с Jina AI"])},subtitle:n=>{const{normalize:r}=n;return r(["Наша программа стажировок на полный рабочий день позволяет получить практический опыт работы благодаря хорошо продуманным проектам стажировок в самых разных областях."])},subtitle1:n=>{const{normalize:r}=n;return r(["Всемирный конкурс для студентов: стажируйтесь в области исследований, инженерии, маркетинга, продаж и т. д., чтобы вместе разработать мультимодальный ИИ."])},summer:n=>{const{normalize:r}=n;return r(["Лето"])},title:n=>{const{normalize:r}=n;return r(["Стажерская программа"])},who_do_we_look_for:n=>{const{normalize:r}=n;return r(["Кого мы ищем?"])},who_do_we_look_for_desc:n=>{const{normalize:r}=n;return r(["Мы ценим разнообразие и призываем соискателей из разных профилей и опыта присоединиться к нашей программе стажировок. Возможности стажировки предлагаются в нескольких отделах, включая проектирование, дизайн, управление продуктами, управление продажами и учетными записями, маркетинг и управление сообществом."])},winter:n=>{const{normalize:r}=n;return r(["Зима"])}},jcloud:{description:n=>{const{normalize:r}=n;return r(["Разверните локальный проект как облачный сервис. Радикально просто, без неприятных сюрпризов."])}},jerboa:{description:n=>{const{normalize:r}=n;return r(["Экспериментальный точный тюнер для LLM с открытым исходным кодом"])}},jina:{description:n=>{const{normalize:r}=n;return r(["Создавайте мультимодальные приложения ИИ в облаке"])}},jina_chat:{description:n=>{const{normalize:r}=n;return r(["Больше модальности, больше памяти, меньше затрат"])},example_1:n=>{const{normalize:r}=n;return r(["Кто ты?"])},example_2:n=>{const{normalize:r}=n;return r(["Я чат-сервис LLM, созданный Jina AI."])}},lab_dialog:{GlobalQA:{description:n=>{const{normalize:r}=n;return r(["Нажмите клавишу «/» на любой странице, чтобы открыть окно вопроса. Введите свой запрос и нажмите «Ввод», чтобы получить ответы, непосредственно связанные с содержимым страницы. Эта функция поддерживается PromptPerfect."])},title:n=>{const{normalize:r}=n;return r(["RAG на странице"])}},Recommender:{description:n=>{const{normalize:r}=n;return r(["Откройте окно рекомендаций на любой странице новостей, нажав «Shift+2». Выберите модель реранкера, чтобы просмотреть топ-5 статей, связанных с этой новостной страницей. Наслаждайтесь этой функцией в реальном времени, основанной на нашем API Reranker."])},title:n=>{const{normalize:r}=n;return r(["Связанная статья"])}},SceneXplainTooltip:{description:n=>{const{normalize:r}=n;return r(["Наведите курсор на любое изображение на страницах новостей или в каталоге нашей редакции, чтобы просмотреть описание этого изображения. Описания предварительно вычисляются SceneXplain и встраиваются в атрибут ALT изображения для обеспечения доступности."])},title:n=>{const{normalize:r}=n;return r(["Подпись к изображению"])}},explain:n=>{const{normalize:r}=n;return r(["Откройте для себя скрытые функции на нашем сайте"])}},landing_page:{also_available_on:n=>{const{normalize:r}=n;return r(["Также доступно на торговых площадках"])},also_available_on1:n=>{const{normalize:r}=n;return r(["Доступно на торговых площадках вашего корпоративного облака."])},ask_how_your_question:n=>{const{normalize:r}=n;return r(["Пожалуйста, опишите вашу проблему"])},autotune:n=>{const{normalize:r}=n;return r(["Автоматическая точная настройка"])},badge:{v2:n=>{const{normalize:r}=n;return r(["релиз v2!"])},v3:n=>{const{normalize:r}=n;return r(["Релиз v3!"])}},build_js:n=>{const{normalize:r}=n;return r(["Создавайте с помощью JavaScript"])},build_python:n=>{const{normalize:r}=n;return r(["Создавайте с помощью Python"])},ccbync:n=>{const{normalize:r}=n;return r(["Эта модель лицензирована по лицензии CC BY-NC 4.0. Используйте ее через API или наш официальный образ AWS/Azure; или свяжитесь с отделом продаж для локального развертывания."])},checkout_our_solution_for_you:n=>{const{normalize:r}=n;return r(["Узнайте о нашем решении, разработанном специально для вас"])},classifier:n=>{const{normalize:r}=n;return r(["Классификатор"])},coming_soon:n=>{const{normalize:r}=n;return r(["Вскоре"])},contact_sales:n=>{const{normalize:r}=n;return r(["Контакт"])},copied_to_clipboard:n=>{const{normalize:r}=n;return r(["Скопировано в буфер обмена"])},copy:n=>{const{normalize:r}=n;return r(["Копировать"])},developers:n=>{const{normalize:r}=n;return r(["Разработчики"])},developers_desc:n=>{const{normalize:r}=n;return r(["Раскройте всю мощь мультимодального ИИ с помощью передовых облачных технологий и инфраструктуры с открытым исходным кодом."])},download_pdf:n=>{const{normalize:r}=n;return r(["Скачать PDF"])},embedding:n=>{const{normalize:r}=n;return r(["Вложения"])},embedding_desc1:n=>{const{normalize:r}=n;return r(["Высокопроизводительные мультимодальные многоязычные встраивания с длинным контекстом для приложений поиска, RAG и агентов."])},embedding_paper_desc:n=>{const{normalize:r}=n;return r(["Jina Embeddings представляет собой набор высокопроизводительных моделей встраивания предложений, способных преобразовывать различные текстовые входные данные в числовые представления, тем самым улавливая семантическую сущность текста. Хотя эти модели предназначены не только для генерации текста, они превосходны в таких приложениях, как плотный поиск и семантическое сходство текста. В этом документе подробно описывается разработка Jina Embeddings, начиная с создания высококачественного парного и тройного набора данных. В нем подчеркивается решающая роль очистки данных при подготовке наборов данных, подробно рассматривается процесс обучения модели и завершается всесторонней оценкой производительности с использованием теста массового встраивания текста (MTEB)."])},embedding_paper_title:n=>{const{normalize:r}=n;return r(["Jina Embeddings: новый набор высокопроизводительных моделей встраивания предложений"])},embeddings:n=>{const{normalize:r}=n;return r(["Вложения"])},enterprise:n=>{const{normalize:r}=n;return r(["Предприятие"])},enterprise_desc:n=>{const{normalize:r}=n;return r(["Расширьте свой бизнес с помощью масштабируемых, безопасных и индивидуальных мультимодальных решений на базе ИИ."])},enterprise_desc_v2:n=>{const{normalize:r}=n;return r(["Попробуйте наши модели внедрения мирового класса, чтобы улучшить свои системы поиска и RAG. Начните с бесплатной пробной версии!"])},enterprise_desc_v3:n=>{const{normalize:r}=n;return r(["Наши передовые модели формируют поисковую основу для высококачественных систем корпоративного поиска и RAG."])},error:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Возникла проблема с операцией выборки: ",e(o("message"))])},find_your_portal:n=>{const{normalize:r}=n;return r(["Найдите свой портал"])},finding_faq:n=>{const{normalize:r}=n;return r(["Генерация ответа на основе знаний часто задаваемых вопросов ниже"])},for:n=>{const{normalize:r}=n;return r(["Для"])},for_developers:n=>{const{normalize:r}=n;return r(["Для разработчиков"])},for_enterprise:n=>{const{normalize:r}=n;return r(["Для предприятия"])},for_power_users:n=>{const{normalize:r}=n;return r(["Для опытных пользователей"])},get_api_now:n=>{const{normalize:r}=n;return r(["API"])},get_started:n=>{const{normalize:r}=n;return r(["Начать"])},go_to_product_homepage:n=>{const{normalize:r}=n;return r(["Перейти на домашнюю страницу продукта"])},how_to:n=>{const{normalize:r}=n;return r(["Как"])},include_experiment:n=>{const{normalize:r}=n;return r(["Включает в решение наши экспериментальные и архивные проекты."])},join_community:n=>{const{normalize:r}=n;return r(["Сообщество"])},learn_more_embeddings:n=>{const{normalize:r}=n;return r(["Узнайте больше о встраиваниях"])},learn_more_reader:n=>{const{normalize:r}=n;return r(["Узнать больше о читателе"])},learn_more_reranker:n=>{const{normalize:r}=n;return r(["Узнать больше о реранкере"])},llm:n=>{const{normalize:r}=n;return r(["Модели встраивания LLM"])},llm_desc:n=>{const{normalize:r}=n;return r(["Мы предоставляем коллекцию высокопроизводительных моделей встраивания предложений, содержащих от 35 миллионов до 6 миллиардов параметров. Они отлично подходят для улучшения нейронного поиска, повторного ранжирования, схожести предложений, рекомендаций и т. д. Приготовьтесь улучшить свой опыт работы с ИИ!"])},mentioned_products:n=>{const{normalize:r}=n;return r(["Упомянутые продукты:"])},mmstack:n=>{const{normalize:r}=n;return r(["Мультимодальный стек"])},mmstack_desc:n=>{const{normalize:r}=n;return r(["За прошедшие годы мы разработали разнообразное программное обеспечение с открытым исходным кодом, которое помогает разработчикам быстрее создавать лучшие приложения GenAI и поисковые приложения."])},models:n=>{const{normalize:r}=n;return r(["Модели"])},more:n=>{const{normalize:r}=n;return r(["Более"])},multimodal:n=>{const{normalize:r}=n;return r(["Мультимодальный"])},multimodal_ai:n=>{const{normalize:r}=n;return r(["Мультимодальный ИИ"])},new:n=>{const{normalize:r}=n;return r(["Новый"])},newsroom:n=>{const{normalize:r}=n;return r(["отдел новостей"])},num_publications:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Всего публикаций ",e(o("_total")),"."])},"on-prem-deploy":n=>{const{normalize:r}=n;return r(["Локальное развертывание"])},"on-premises":n=>{const{normalize:r}=n;return r(["Локально"])},opensource:n=>{const{normalize:r}=n;return r(["Открытый источник"])},our_customer:n=>{const{normalize:r}=n;return r(["Наши клиенты"])},our_customer_explain:n=>{const{normalize:r}=n;return r(["Компании всех размеров доверяют Jina AI Search Foundation в обеспечении работы своих инструментов и продуктов — можете и вы."])},our_publications:n=>{const{normalize:r}=n;return r(["Наши публикации"])},parameters:n=>{const{normalize:r}=n;return r(["Параметры"])},podcast:n=>{const{normalize:r}=n;return r(["Подкаст"])},power_users:n=>{const{normalize:r}=n;return r(["Опытные пользователи"])},power_users_desc:n=>{const{normalize:r}=n;return r(["Автоматическое оперативное проектирование для вашей повседневной производительности."])},powered_by_promptperfect:n=>{const{normalize:r}=n;return r(["Работает на основе функций PromptPerfect «Быстрая оптимизация» и «Подсказка как услуга»."])},pricing:n=>{const{normalize:r}=n;return r(["Цены"])},proposing_solution:n=>{const{normalize:r}=n;return r(["Предлагаем решение на основе продуктов Jina AI..."])},read_more:n=>{const{normalize:r}=n;return r(["Читать далее"])},reader:n=>{const{normalize:r}=n;return r(["Читатель"])},require_full_question:n=>{const{normalize:r}=n;return r(["Пожалуйста, опишите вашу проблему более подробно."])},reranker:n=>{const{normalize:r}=n;return r(["Реранкер"])},researcher_desc:n=>{const{normalize:r}=n;return r(["Поймите, как наши модели поиска на границе были обучены с нуля, ознакомьтесь с нашими последними публикациями. Познакомьтесь с нашей командой в EMNLP, SIGIR, ICLR, NeurIPS и ICML!"])},researchers:n=>{const{normalize:r}=n;return r(["Исследователи"])},sdk:n=>{const{normalize:r}=n;return r(["SDK"])},sdk_desc:n=>{const{normalize:r}=n;return r(["Хотите создавать высокоуровневые приложения AIGC, используя API PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale? Мы вас прикрыли! Попробуйте наш простой в использовании SDK и начните работу за считанные минуты."])},sdk_docs:n=>{const{normalize:r}=n;return r(["Читать документы"])},sdk_example:n=>{const{normalize:r}=n;return r(["Пример"])},search_foundation:n=>{const{normalize:r}=n;return r(["Поисковый фонд"])},source_code:n=>{const{normalize:r}=n;return r(["Исходный код"])},starter_kit:n=>{const{normalize:r}=n;return r(["Стартовый комплект"])},supercharged1:n=>{const{normalize:r}=n;return r(["Сверхзаряженный."])},tokenizer:n=>{const{normalize:r}=n;return r(["Сегментатор"])},trusted_by:n=>{const{normalize:r}=n;return r(["ДОВЕРЯЕТ"])},try_it_for_free:n=>{const{normalize:r}=n;return r(["Начните прямо сейчас — кредитная карта или регистрация не требуются!"])},try_our_saas:n=>{const{normalize:r}=n;return r(["Попробуйте наше размещенное решение — замену API встраивания OpenAI."])},your_portal_to:n=>{const{normalize:r}=n;return r(["Ваш портал в"])},your_search_foundation1:n=>{const{normalize:r}=n;return r(["Ваш фонд поиска"])}},langchain_serve:{description:n=>{const{normalize:r}=n;return r(["Приложения Langchain в производстве с Jina и FastAPI"])}},model_graph:{api:n=>{const{normalize:r}=n;return r(["Jina AI API"])},contact_sales_about_it:n=>{const{normalize:r}=n;return r(["Свяжитесь с отделом продаж по этому поводу"])},deploy_it_on:n=>{const{normalize:r}=n;return r(["Разверните его на"])},description:n=>{const{normalize:r}=n;return r(["На протяжении многих лет мы продолжали расширять границы поиска. Ниже представлены модели, которые мы выпустили — наведите курсор или щелкните каждую из них, чтобы увидеть больше подробностей."])},find_on_hf:n=>{const{normalize:r}=n;return r(["Найдите это на HuggingFace"])},search_for:n=>{const{normalize:r}=n;return r(["Поиск на нашем сайте"])},search_models:n=>{const{normalize:r}=n;return r(["Фильтр по названию модели"])},title:n=>{const{normalize:r}=n;return r(["Наши модели фундамента поиска"])},use_it_via:n=>{const{normalize:r}=n;return r(["Используйте его через"])}},news_page:{back_to_newsroom:n=>{const{normalize:r}=n;return r(["Назад в отдел новостей"])},categories:n=>{const{normalize:r}=n;return r(["Категории"])},copy_link:n=>{const{normalize:r}=n;return r(["Скопируйте ссылку на этот раздел"])},in_this_article:n=>{const{normalize:r}=n;return r(["В этой статье"])},learn_more:n=>{const{normalize:r}=n;return r(["Узнать больше"])},news_not_found:n=>{const{normalize:r}=n;return r(["Статья не найдена"])},redirect_to_news:n=>{const{normalize:r}=n;return r(["Перенаправление в редакцию через 5 секунд..."])}},newsroom_page:{academic:n=>{const{normalize:r}=n;return r(["Академический"])},academic_research:n=>{const{normalize:r}=n;return r(["Академические публикации"])},author:n=>{const{normalize:r}=n;return r(["Фильтровать по автору"])},description:n=>{const{normalize:r}=n;return r(["Читайте последние новости и обновления от Jina AI."])},description1:n=>{const{normalize:r}=n;return r(["Создание инноваций в области ИИ, одно слово за раз."])},engineering_group:n=>{const{normalize:r}=n;return r(["Инженерная группа"])},engineering_group_date:n=>{const{normalize:r}=n;return r(["31 мая 2021 г."])},minutes_read:n=>{const{normalize:r}=n;return r(["минуты чтения"])},most_recent_articles:n=>{const{normalize:r}=n;return r(["Последние статьи"])},news_description:n=>{const{normalize:r}=n;return r(["Для Jina 2.0 мы прислушались к сообществу. Верно, глубоко выслушал. «Каковы ваши болевые точки?» — спросили мы, с нетерпением ожидая ценных отзывов."])},news_title:n=>{const{normalize:r}=n;return r(["Искать все: мы проводим конкурс MEME для Jina 2.0"])},photos:n=>{const{normalize:r}=n;return r(["Фото"])},product:n=>{const{normalize:r}=n;return r(["Фильтровать по продукту"])},search:n=>{const{normalize:r}=n;return r(["Поиск по названию"])},tech_blog:n=>{const{normalize:r}=n;return r(["Технический блог"])},title:n=>{const{normalize:r}=n;return r(["отдел новостей"])},top_stories:n=>{const{normalize:r}=n;return r(["Главные новости"])}},notice:n=>{const{normalize:r}=n;return r(["🎉 Сегодня официально вышла наша первая книга «Нейронный поиск — от прототипа к производству с Джиной»!"])},open_day:{description:n=>{const{normalize:r}=n;return r(["Эксклюзивная возможность получить представление о Jina AI изнутри."])},engage:n=>{const{normalize:r}=n;return r(["Мы настоятельно рекомендуем интерактивный диалог в течение дня. Обмен мыслями и взглядами бесценен для нас. Потенциальное сотрудничество, вытекающее из этих дискуссий, могло бы внести значительный вклад в более интегрированное и инновационное будущее."])},engage_title:n=>{const{normalize:r}=n;return r(["Взаимодействуйте с нами"])},experience:n=>{const{normalize:r}=n;return r(["Мы организовали для наших гостей трехчасовую иммерсивную экскурсию, доступную на немецком, английском, французском, испанском, китайском и русском языках. Экскурсия охватывает углубленный взгляд на наши достижения в области мультимодального ИИ, нашу точку зрения на ландшафт ИИ, после чего следует подробное изучение конкретных проектов. Мы завершим обсуждение групповым обсуждением, чтобы облегчить обмен идеями и идеями. Обед также предоставляется по запросу."])},experience_title:n=>{const{normalize:r}=n;return r(["Путешествие инсайдера"])},group_size:n=>{const{normalize:r}=n;return r(["Предполагаемое количество посетителей"])},impact:n=>{const{normalize:r}=n;return r(["Узнайте, как наш вклад в сообщество с открытым исходным кодом и наша работа в области мультимодальных технологий искусственного интеллекта делают Jina AI влиятельным игроком в области инноваций в области искусственного интеллекта. Мы стремимся играть важную роль в процессах принятия решений, гарантируя, что развитие технологий искусственного интеллекта принесет пользу всем."])},impact_title:n=>{const{normalize:r}=n;return r(["Воздействие и влияние"])},introduction:n=>{const{normalize:r}=n;return r(["Jina AI рада открыть наши двери для уважаемых лиц и организаций, заинтересованных в прогрессе и будущем искусственного интеллекта. Мы предоставляем эту эксклюзивную возможность тем, кто занимается политикой, НКО, НКО и инвестиционным сектором, чтобы получить инсайдерскую информацию о нашей деятельности и видении здесь, в нашей штаб-квартире в Берлине."])},motivation_min_length_v1:n=>{const{normalize:r}=n;return r(["Пожалуйста, предоставьте более подробную мотивацию."])},motivation_placeholder_v2:n=>{const{normalize:r}=n;return r(["Если вы поделитесь своими мотивами, это поможет нам улучшить ваш опыт."])},motivation_to_attend_v2:n=>{const{normalize:r}=n;return r(["Почему вам интересен наш День открытых дверей?"])},one_hour:n=>{const{normalize:r}=n;return r(["1 час"])},organization:n=>{const{normalize:r}=n;return r(["Организация"])},organization_website:n=>{const{normalize:r}=n;return r(["Сайт организации"])},organization_website_placeholder:n=>{const{normalize:r}=n;return r(["URL-адрес домашней страницы вашей организации или профиля LinkedIn."])},preferred_date:n=>{const{normalize:r}=n;return r(["Желаемая дата"])},preferred_language:n=>{const{normalize:r}=n;return r(["Предпочтительный язык тура"])},preferred_products:n=>{const{normalize:r}=n;return r(["Какие продукты вас интересуют?"])},subtitle:n=>{const{normalize:r}=n;return r(["Взгляд в будущее мультимодального ИИ"])},title:n=>{const{normalize:r}=n;return r(["День открытых дверей"])},tutor_subtitle:n=>{const{normalize:r}=n;return r(["Тщательно подобранный трехчасовой тур, который приблизит вас к сердцу новаторской работы Jina AI в области мультимодальной технологии искусственного интеллекта."])},tutor_title:n=>{const{normalize:r}=n;return r(["Эксклюзивное глубокое погружение в"])},vision:n=>{const{normalize:r}=n;return r(["Присоединяйтесь к нам, чтобы получить исчерпывающий обзор ландшафта ИИ, каким мы его видим. Наше обсуждение будет сосредоточено на потенциале больших языковых моделей, мультимодального ИИ и влиянии технологий с открытым исходным кодом на формирование будущего глобальных инноваций."])},vision_title:n=>{const{normalize:r}=n;return r(["Наше видение будущего"])}},open_day_faq:{answer1:n=>{const{normalize:r}=n;return r(["Мы предлагаем туры на немецком, английском, французском, испанском, китайском и русском языках."])},answer2:n=>{const{normalize:r}=n;return r(["Экскурсия обычно длится около трех часов."])},answer3:n=>{const{normalize:r}=n;return r(["Обед не является обязательным и может быть организован по запросу."])},answer4:n=>{const{normalize:r}=n;return r(["Наш День открытых дверей предназначен в первую очередь для профессиональных групп, таких как политики, НПО, НКО и инвесторы. Тем не менее, мы иногда делаем исключения на основе профиля человека."])},answer5:n=>{const{normalize:r}=n;return r(["Мы можем разместить группы разного размера. Пожалуйста, укажите размер вашей группы в регистрационной форме, и мы согласуем с вами детали."])},answer6:n=>{const{normalize:r}=n;return r(["В регистрационной форме есть раздел, где вы можете указать свои интересы или любые особые пожелания. Мы сделаем все возможное, чтобы адаптировать тур в соответствии с вашими потребностями."])},answer7:n=>{const{normalize:r}=n;return r(["В настоящее время мы предлагаем туры только в нашу берлинскую штаб-квартиру, расположенную в Кройцберге. Наши офисы в Пекине и Шэньчжэне в настоящее время закрыты для экскурсий."])},question1:n=>{const{normalize:r}=n;return r(["Какие языки вы предлагаете для тура?"])},question2:n=>{const{normalize:r}=n;return r(["Какова продолжительность тура?"])},question3:n=>{const{normalize:r}=n;return r(["Предоставляется ли обед?"])},question4:n=>{const{normalize:r}=n;return r(["Могут ли физические лица зарегистрироваться на День открытых дверей?"])},question5:n=>{const{normalize:r}=n;return r(["Сколько человек может состоять в группе на День открытых дверей?"])},question6:n=>{const{normalize:r}=n;return r(["Как я могу указать области интереса для тура?"])},question7:n=>{const{normalize:r}=n;return r(["Доступны ли туры в ваших офисах в Пекине или Шэньчжэне?"])}},open_gpt:{description:n=>{const{normalize:r}=n;return r(["Облачная платформа с открытым исходным кодом для больших мультимодальных моделей, обслуживающая платформу"])}},paywall:{commercial_licence:{chip_label:n=>{const{normalize:r}=n;return r(["Эксклюзивно для малых компаний"])},company_size_note:n=>{const{normalize:r}=n;return r(["Эксклюзивно для компаний с числом сотрудников менее 100 человек и доходом менее 5 млн долларов США"])},cta_button:n=>{const{normalize:r}=n;return r(["Начать"])},download_title:n=>{const{normalize:r}=n;return r(["Загрузить коммерческую лицензию"])},feature_api_desc:n=>{const{normalize:r}=n;return r(["Тест перед покупкой"])},feature_api_title:n=>{const{normalize:r}=n;return r(["Бесплатный доступ к тестированию API"])},feature_consulting:n=>{const{normalize:r}=n;return r(["Ежеквартальная двухчасовая консультационная сессия с нашими экспертами по моделям"])},feature_consulting_desc:n=>{const{normalize:r}=n;return r(["Три (3) часа технических консультационных услуг за период действия лицензии."])},feature_future_support:n=>{const{normalize:r}=n;return r(["Доступ к будущим моделям CC BY-NC без разрешения"])},feature_future_support_desc:n=>{const{normalize:r}=n;return r(["Любые новые модели, выпущенные Лицензиаром в соответствии с CC-BY-NC-4.0 в течение Срока действия лицензии."])},feature_models:n=>{const{normalize:r}=n;return r(["Неограниченное коммерческое использование наших моделей CC BY-NC"])},feature_models_desc:n=>{const{normalize:r}=n;return r(["Использовать Модели в коммерческих целях, включая внутреннее использование или включение в клиентские приложения."])},price_amount:n=>{const{normalize:r}=n;return r(["1000 долларов США"])},price_period:n=>{const{normalize:r}=n;return r(["/ четверть"])},read_the_terms:n=>{const{normalize:r}=n;return r(["Ознакомьтесь с условиями лицензии"])},read_the_terms_btn:n=>{const{normalize:r}=n;return r(["Условия"])},read_the_terms_desc:n=>{const{normalize:r}=n;return r(["Перед покупкой ознакомьтесь с правами и ограничениями коммерческой лицензии."])},subtitle:n=>{const{normalize:r}=n;return r(["Каждая модель, которая вам нужна для лучшего поиска"])},test_before_purchase:n=>{const{normalize:r}=n;return r(["Попробуйте перед покупкой"])},test_before_purchase_desc:n=>{const{normalize:r}=n;return r(["Получите 1 млн бесплатных токенов API или используйте нашу модель Hugging Face для проверки производительности"])},title:n=>{const{normalize:r}=n;return r(["Коммерческая лицензия"])},try_api:n=>{const{normalize:r}=n;return r(["Попробуйте сначала API"])}},free_hour_consult:n=>{const{normalize:r}=n;return r(["Бесплатная часовая консультация"])},free_hour_consult_description:n=>{const{normalize:r}=n;return r(["Один час бесплатной консультации с нашими командами по продуктам и инженерам для обсуждения наилучшей практики для вашего варианта использования"])},full_commercial:n=>{const{normalize:r}=n;return r(["Неограниченное коммерческое использование"])},full_commercial_description:n=>{const{normalize:r}=n;return r(["Вы можете использовать API в коммерческих целях без каких-либо ограничений."])},higher_limit:n=>{const{normalize:r}=n;return r(["Гораздо более высокий предел скорости"])},higher_limit_description:n=>{const{normalize:r}=n;return r(["Получите до 1000 об/мин для r.jina.ai и 100 об/мин для s.jina.ai; более подробная информация в разделе «Ограничение скорости»."])},no_commercial:n=>{const{normalize:r}=n;return r(["Только для некоммерческого использования (CC-BY-NC)"])},no_commercial_description:n=>{const{normalize:r}=n;return r(["Вы можете использовать API только в некоммерческих целях. Для коммерческого использования, пожалуйста, пополните свой ключ API."])},on_prem:n=>{const{normalize:r}=n;return r(["С коммерческой лицензией для локального развертывания"])},on_prem_explain:n=>{const{normalize:r}=n;return r(["Приобретите коммерческую лицензию для использования наших моделей локально."])},priority_support:n=>{const{normalize:r}=n;return r(["Приоритетная поддержка клиентов"])},priority_support_description:n=>{const{normalize:r}=n;return r(["Гарантированный ответ по электронной почте в течение 24 часов, включая выходные"])},secured_by_stripe:n=>{const{normalize:r}=n;return r(["Безопасная оплата через Stripe"])},via_api:n=>{const{normalize:r}=n;return r(["С API Jina Search Foundation"])},via_api_explain:n=>{const{normalize:r}=n;return r(["Самый простой способ получить доступ ко всем нашим продуктам. Пополняйте токены по мере использования."])}},powered_by:n=>{const{normalize:r}=n;return r(["Питаться от"])},print:n=>{const{normalize:r}=n;return r(["Распечатать"])},project_status:{archived:n=>{const{normalize:r}=n;return r(["В архиве"])},cloud_native:n=>{const{normalize:r}=n;return r(["Облако Собственный"])},core:n=>{const{normalize:r}=n;return r(["Основной"])},data_structure:n=>{const{normalize:r}=n;return r(["Структура данных"])},embedding_serving:n=>{const{normalize:r}=n;return r(["Встраивание обслуживания"])},embedding_tuning:n=>{const{normalize:r}=n;return r(["Встраивание настройки"])},graduated:n=>{const{normalize:r}=n;return r(["Окончил"])},incubating:n=>{const{normalize:r}=n;return r(["Инкубация"])},kubernetes:n=>{const{normalize:r}=n;return r(["Кубернетес"])},large_size_model:n=>{const{normalize:r}=n;return r(["Модель большого размера"])},linux_foundation:n=>{const{normalize:r}=n;return r(["Фонд Linux"])},llm1:n=>{const{normalize:r}=n;return r(["LLMOps"])},mid_size_model:n=>{const{normalize:r}=n;return r(["Модель среднего размера"])},model_serving:n=>{const{normalize:r}=n;return r(["Обслуживание моделей"])},model_tuning:n=>{const{normalize:r}=n;return r(["Настройка модели"])},observability:n=>{const{normalize:r}=n;return r(["Наблюдаемость"])},orchestration:n=>{const{normalize:r}=n;return r(["Оркестровка"])},prompt_serving:n=>{const{normalize:r}=n;return r(["Быстрое обслуживание"])},prompt_tuning:n=>{const{normalize:r}=n;return r(["Оперативная настройка"])},rag1:n=>{const{normalize:r}=n;return r(["ТРЯПКА"])},sandbox:n=>{const{normalize:r}=n;return r(["Песочница"])},small_size_model:n=>{const{normalize:r}=n;return r(["Модель маленького размера"])},vector_database:n=>{const{normalize:r}=n;return r(["База данных векторов"])},vector_store:n=>{const{normalize:r}=n;return r(["Векторный магазин"])}},prompt_perfect:{description:n=>{const{normalize:r}=n;return r(["Первоклассный инструмент для быстрого инжиниринга"])},image_model:n=>{const{normalize:r}=n;return r(["Модели изображений"])},intro:n=>{const{normalize:r}=n;return r(["Первоклассный инструмент для быстрого инжиниринга"])},intro1:n=>{const{normalize:r}=n;return r(["Главный инструмент для быстрого проектирования"])},optimized:n=>{const{normalize:r}=n;return r(["Ваша задача — быть моим партнером по мозговому штурму и предлагать творческие идеи и предложения по заданной теме или проблеме. Ваш ответ должен включать оригинальные, уникальные и актуальные идеи, которые могут помочь решить проблему или продолжить интересное изучение темы. Обратите внимание, что ваш ответ должен также учитывать любые конкретные требования или ограничения задачи."])},optimized_title:n=>{const{normalize:r}=n;return r(["Оптимизированная подсказка"])},original:n=>{const{normalize:r}=n;return r(["Твоя роль — быть моим партнером по мозговому штурму."])},original_title:n=>{const{normalize:r}=n;return r(["Оригинальная подсказка"])},text_model:n=>{const{normalize:r}=n;return r(["Текстовые модели"])}},promptperfect:{features:[{description:n=>{const{normalize:r}=n;return r(["Легко переключайтесь между созданием контента и быстрой оптимизацией, поднимите качество вашего контента на новый уровень."])},name:n=>{const{normalize:r}=n;return r(["Ассистент"])},title:n=>{const{normalize:r}=n;return r(["Ежедневная доза продуктивности."])}},{description:n=>{const{normalize:r}=n;return r(["Не знаете, как написать эффективную инструкцию? Просто внесите свою идею в один клик и получите более подробную инструкцию."])},name:n=>{const{normalize:r}=n;return r(["Оперативная оптимизация"])},title:n=>{const{normalize:r}=n;return r(["Лучшие входы, лучшие результаты"])}},{description:n=>{const{normalize:r}=n;return r(["Поймите атмосферу каждой модели ИИ, сравнив их результаты при выполнении одной и той же подсказки."])},name:n=>{const{normalize:r}=n;return r(["Сравнить модели"])},title:n=>{const{normalize:r}=n;return r(["Параллельное сравнение моделей."])}},{description:n=>{const{normalize:r}=n;return r(["Возможно, это самый простой способ развернуть ваши подсказки в качестве API для интеграции."])},name:n=>{const{normalize:r}=n;return r(["Развертывание подсказок"])},title:n=>{const{normalize:r}=n;return r(["Никаких операций, просто развертывание."])}},{description:n=>{const{normalize:r}=n;return r(["Настройте своих собственных агентов LLM и запустите мультиагентное моделирование. Посмотрите, как они сотрудничают или конкурируют в виртуальной среде для достижения цели."])},name:n=>{const{normalize:r}=n;return r(["Мультиагент"])},title:n=>{const{normalize:r}=n;return r(["Узнайте, как агенты сотрудничают"])}}],get_started:n=>{const{normalize:r}=n;return r(["Начните работу с PromptPerfect"])}},purchase:{success:n=>{const{normalize:r}=n;return r(["Спасибо за покупку!"])},success_caption:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Мы завершили ваш заказ в ",e(o("_purchasedTime")),". Ваш ключ API готов к использованию!"])}},purchase_now:n=>{const{normalize:r}=n;return r(["Купить сейчас"])},rate_limit:{batch_explain:n=>{const{normalize:r}=n;return r(["Этот API поддерживает пакетные операции, позволяя обрабатывать до 512 документов на запрос, при этом каждый документ может содержать до 8192 токенов. Разумное использование пакетных операций может значительно сократить количество запросов и повысить производительность."])},classifier:n=>{const{normalize:r}=n;return r(["Обучить классификатор с использованием маркированных примеров"])},classifier_few_shot:n=>{const{normalize:r}=n;return r(["Классифицируйте входные данные с помощью обученного классификатора с несколькими попытками"])},classifier_few_shot_token_counting:n=>{const{normalize:r}=n;return r(["Токены учитываются как: input_tokens"])},classifier_latency:n=>{const{normalize:r}=n;return r(["Время отклика зависит от размера входных данных"])},classifier_token_counting:n=>{const{normalize:r}=n;return r(["Токены подсчитываются как: input_tokens × num_iters"])},classifier_zero_shot:n=>{const{normalize:r}=n;return r(["Классифицируйте входные данные, используя классификацию с нулевым результатом"])},classifier_zero_shot_token_counting:n=>{const{normalize:r}=n;return r(["Токены считаются как: input_tokens + label_tokens"])},depends:n=>{const{normalize:r}=n;return r(["зависит от размера входных данных"])},description:n=>{const{normalize:r}=n;return r(["Описание"])},embeddings:n=>{const{normalize:r}=n;return r(["Преобразование текста/изображений в векторы фиксированной длины"])},endpoint:n=>{const{normalize:r}=n;return r(["Конечная точка API"])},explain:n=>{const{normalize:r}=n;return r(["Ограничения скорости отслеживаются двумя способами: <b>RPM</b> (запросы в минуту) и <b>TPM</b> (токены в минуту). Ограничения применяются к каждому IP-адресу и могут быть достигнуты в зависимости от того, какой порог — RPM или TPM — будет достигнут первым."])},gjinaai:n=>{const{normalize:r}=n;return r(["Подтверждение заявления знаниями в области Интернета"])},input_token_counting:n=>{const{normalize:r}=n;return r(["Подсчитайте количество токенов во входном запросе."])},latency:n=>{const{normalize:r}=n;return r(["Средняя задержка"])},no_token_counting:n=>{const{normalize:r}=n;return r(["Токен не считается использованием."])},output_token_counting:n=>{const{normalize:r}=n;return r(["Подсчитайте количество токенов в выходном ответе."])},premium_rate:n=>{const{normalize:r}=n;return r(["С потенциалом для более высоких лимитов ставок"])},product:n=>{const{normalize:r}=n;return r(["Продукт"])},requestType:n=>{const{normalize:r}=n;return r(["Разрешенный запрос"])},reranker:n=>{const{normalize:r}=n;return r(["Ранжировать документы по запросу"])},rjinaai:n=>{const{normalize:r}=n;return r(["Преобразовать URL в текст, понятный LLM"])},sjinaai:n=>{const{normalize:r}=n;return r(["Поиск в Интернете и преобразование результатов в текст, понятный LLM"])},tbd:n=>{const{normalize:r}=n;return r(["Будет определено"])},title:n=>{const{normalize:r}=n;return r(["Ограничение скорости"])},tokenCounting:n=>{const{normalize:r}=n;return r(["Подсчет использования токенов"])},tokenizer:n=>{const{normalize:r}=n;return r(["Токенизация и сегментация длинного текста"])},total_token_counting:n=>{const{normalize:r}=n;return r(["Подсчитайте общее количество токенов за весь процесс."])},understanding:n=>{const{normalize:r}=n;return r(["Понять ограничение скорости"])},understanding_description:n=>{const{normalize:r}=n;return r(["Ограничения скорости — это максимальное количество запросов, которые можно сделать к API в течение минуты на IP-адрес (RPM). Узнайте больше об ограничениях скорости для каждого продукта и уровня ниже."])},wAPIkey:n=>{const{normalize:r}=n;return r(["с API-ключом"])},wPremium:n=>{const{normalize:r}=n;return r(["с премиум-ключом API"])},woAPIkey:n=>{const{normalize:r}=n;return r(["без API-ключа"])}},rationale:{decision:n=>{const{normalize:r}=n;return r(["Решение"])},description:n=>{const{normalize:r}=n;return r(["Совершенные инструменты для принятия решений с помощью ИИ"])},intro:n=>{const{normalize:r}=n;return r(["Видите две стороны медали, принимайте рациональные решения"])}},reader:{beta:n=>{const{normalize:r}=n;return r(["Экспериментальный"])},better_input:n=>{const{normalize:r}=n;return r(["Повышайте качество ввода с самого начала"])},better_input_description:n=>{const{normalize:r}=n;return r(["Возникли проблемы с выходными данными вашего агента или системы RAG? Возможно, это связано с плохим качеством ввода."])},check_price_table:n=>{const{normalize:r}=n;return r(["Проверьте таблицу цен"])},copy:n=>{const{normalize:r}=n;return r(["Копировать"])},demo:{advanced_usage:n=>{const{normalize:r}=n;return r(["Расширенное использование"])},ask_llm:n=>{const{normalize:r}=n;return r(["Спросите LLM без и с заземлением поиска"])},ask_llm_directly:n=>{const{normalize:r}=n;return r(["Спросите LLM напрямую"])},ask_llm_with_search_grounding:n=>{const{normalize:r}=n;return r(["Спросите LLM с обоснованием поиска"])},ask_question:n=>{const{normalize:r}=n;return r(["Задать вопрос"])},ask_question_hint:n=>{const{normalize:r}=n;return r(["Введите вопрос и объедините его с полученным контентом, чтобы LLM сгенерировал ответ."])},basic_usage:n=>{const{normalize:r}=n;return r(["Основное использование"])},basic_usage1:n=>{const{normalize:r}=n;return r(["Чтение URL-адреса"])},basic_usage2:n=>{const{normalize:r}=n;return r(["Поиск запроса"])},basic_usage3:n=>{const{normalize:r}=n;return r(["Заземление"])},copy:n=>{const{normalize:r}=n;return r(["Копировать"])},fetch:n=>{const{normalize:r}=n;return r(["Получить контент"])},get_response:n=>{const{normalize:r}=n;return r(["Получить ответ"])},headers:{auth_token:n=>{const{normalize:r}=n;return r(["Добавьте ключ API для более высокого лимита скорости"])},auth_token_explain:n=>{const{normalize:r}=n;return r(["Введите свой ключ API Jina, чтобы получить доступ к более высокому лимиту скорости. Актуальную информацию об ограничениях скорости можно найти в таблице ниже."])},browser_locale:n=>{const{normalize:r}=n;return r(["Язык браузера"])},browser_locale_explain:n=>{const{normalize:r}=n;return r(["Управляйте локалью браузера для отображения страницы. Множество веб-сайтов предоставляют разный контент в зависимости от локали."])},default:n=>{const{normalize:r}=n;return r(["По умолчанию"])},default_explain:n=>{const{normalize:r}=n;return r(["Стандартный конвейер, оптимизированный для большинства веб-сайтов и ввода LLM."])},file:n=>{const{normalize:r}=n;return r(["Локальный файл PDF/HTML"])},file_explain:n=>{const{normalize:r}=n;return r(["Используйте Reader на локальных файлах PDF и HTML, загрузив их. Поддерживает только файлы PDF и HTML."])},html:n=>{const{normalize:r}=n;return r(["HTML"])},html_explain:n=>{const{normalize:r}=n;return r(["Возвращает documentElement.outerHTML."])},image_caption:n=>{const{normalize:r}=n;return r(["Подпись к изображению"])},image_caption_explain:n=>{const{normalize:r}=n;return r(["Подписывает все изображения по указанному URL-адресу, добавляя «Image [idx]: [caption]» в качестве альтернативного тега для тех, у кого его нет. Это позволяет последующим LLM взаимодействовать с изображениями в таких действиях, как рассуждение и подведение итогов."])},images_summary:n=>{const{normalize:r}=n;return r(["Соберите все изображения в конце"])},images_summary_explain:n=>{const{normalize:r}=n;return r(["В конце будет создан раздел «Изображения». Это дает последующим специалистам LLM обзор всех визуальных элементов на странице, что может улучшить логику."])},json_response:n=>{const{normalize:r}=n;return r(["JSON-ответ"])},json_response_explain:n=>{const{normalize:r}=n;return r(["Ответ будет в формате JSON, содержащий URL-адрес, заголовок, контент и временную метку (если имеется). В режиме поиска он возвращает список из пяти записей, каждая из которых соответствует описанной структуре JSON."])},links_summary:n=>{const{normalize:r}=n;return r(["Соберите все ссылки в конце"])},links_summary_explain:n=>{const{normalize:r}=n;return r(["В конце будет создан раздел «Кнопки и ссылки». Это помогает нижестоящим LLM или веб-агентам перемещаться по странице или предпринимать дальнейшие действия."])},markdown:n=>{const{normalize:r}=n;return r(["Уценка"])},markdown_explain:n=>{const{normalize:r}=n;return r(["Возвращает разметку непосредственно из HTML, минуя фильтрацию читабельности."])},mode:n=>{const{normalize:r}=n;return r(["Режим чтения или поиска"])},mode_explain:n=>{const{normalize:r}=n;return r(["Режим чтения предназначен для доступа к содержимому URL-адреса, а режим поиска позволяет выполнять поиск по запросу в Интернете, применяя режим чтения к каждому URL-адресу результата поиска."])},no_cache:n=>{const{normalize:r}=n;return r(["Обход кэша"])},no_cache_explain:n=>{const{normalize:r}=n;return r(["Наш сервер API кэширует содержимое режима чтения и поиска в течение определенного периода времени. Чтобы обойти этот кеш, установите для этого заголовка значение true."])},pageshot:n=>{const{normalize:r}=n;return r(["Снимок страницы"])},pageshot_explain:n=>{const{normalize:r}=n;return r(["Возвращает URL-адрес изображения полного снимка экрана страницы (с максимальной эффективностью)."])},post_with_url:n=>{const{normalize:r}=n;return r(["Использовать метод POST"])},post_with_url_explain:n=>{const{normalize:r}=n;return r(["Используйте POST вместо метода GET с URL-адресом, переданным в теле. Полезно для создания SPA с маршрутизацией на основе хеша."])},proxy_server:n=>{const{normalize:r}=n;return r(["Используйте прокси-сервер"])},proxy_server_explain:n=>{const{normalize:r}=n;return r(["Наш сервер API может использовать ваш прокси-сервер для доступа к URL-адресам, что полезно для страниц, доступных только через определенные прокси."])},references:n=>{const{normalize:r}=n;return r(["Ссылки"])},references_explain:n=>{const{normalize:r}=n;return r(["Список ссылок (URL), предоставленных пользователем, разделенных запятыми."])},remove_selector:n=>{const{normalize:r}=n;return r(["Исключенный селектор"])},remove_selector_explain:n=>{const{normalize:r}=n;return r(["Предоставьте список селекторов CSS для удаления указанных элементов страницы. Полезно, когда вы хотите исключить определенные части страницы, такие как заголовки, нижние колонтитулы и т. д."])},return_format:n=>{const{normalize:r}=n;return r(["Формат контента"])},return_format_explain:n=>{const{normalize:r}=n;return r(["Вы можете контролировать уровень детализации ответа, чтобы предотвратить чрезмерную фильтрацию. Конвейер по умолчанию оптимизирован для большинства веб-сайтов и входных данных LLM."])},screenshot:n=>{const{normalize:r}=n;return r(["Скриншот"])},screenshot_explain:n=>{const{normalize:r}=n;return r(["Возвращает URL-адрес изображения первого экрана."])},set_cookie:n=>{const{normalize:r}=n;return r(["Переслать файл cookie"])},set_cookie_explain:n=>{const{normalize:r}=n;return r(["Наш сервер API может пересылать ваши пользовательские настройки файлов cookie при доступе к URL-адресу, что полезно для страниц, требующих дополнительной аутентификации. Обратите внимание, что запросы с файлами cookie не кэшируются."])},site_selector:n=>{const{normalize:r}=n;return r(["Поиск по сайту"])},site_selector_explain:n=>{const{normalize:r}=n;return r(["Возвращает результаты поиска только с указанного веб-сайта или домена. По умолчанию он выполняет поиск по всей сети."])},stream_mode:n=>{const{normalize:r}=n;return r(["Режим потока"])},stream_mode_explain:n=>{const{normalize:r}=n;return r(["Режим потока полезен для больших целевых страниц, поскольку дает больше времени для полной визуализации страницы. Если в стандартном режиме контент получается неполным, рассмотрите возможность использования режима Stream."])},target_selector:n=>{const{normalize:r}=n;return r(["Целевой селектор"])},target_selector_explain:n=>{const{normalize:r}=n;return r(["Предоставьте список селекторов CSS, чтобы сосредоточиться на более конкретных частях страницы. Полезно, когда желаемый вами контент не отображается при настройках по умолчанию."])},text:n=>{const{normalize:r}=n;return r(["Текст"])},text_explain:n=>{const{normalize:r}=n;return r(["Возвращает document.body.innerText."])},wait_for_selector:n=>{const{normalize:r}=n;return r(["Подождите селектора"])},wait_for_selector_explain:n=>{const{normalize:r}=n;return r(["Предоставьте список селекторов CSS для ожидания появления определенных элементов перед возвратом. Полезно, когда желаемый вами контент не отображается при настройках по умолчанию."])},with_iframe:n=>{const{normalize:r}=n;return r(["IFrame"])},with_iframe_explain:n=>{const{normalize:r}=n;return r(["Возвращаемый результат также будет включать содержимое фреймов на странице."])},with_shadow_dom:n=>{const{normalize:r}=n;return r(["Тень ДОМ"])},with_shadow_dom_explain:n=>{const{normalize:r}=n;return r(["Возвращаемый результат также будет включать содержимое теневого DOM на странице."])},x_timeout:n=>{const{normalize:r}=n;return r(["Тайм-аут"])},x_timeout_explain:n=>{const{normalize:r}=n;return r(["Максимальное время ожидания загрузки веб-страницы. Обратите внимание, что это НЕ общее время для всего сквозного запроса."])}},how_to_stream:n=>{const{normalize:r}=n;return r(["Чтобы обрабатывать контент по мере его поступления, установите для заголовка запроса потоковый режим. Это минимизирует время до получения первого байта. Пример в локоне:"])},how_to_use1:n=>{const{normalize:r}=n;return r(["Добавьте https://r.jina.ai/ к любому URL-адресу в вашем коде или инструменте, где ожидается доступ к LLM. Это вернет основное содержимое страницы в чистом, удобном для LLM тексте."])},how_to_use2:n=>{const{normalize:r}=n;return r(["Добавьте https://s.jina.ai/ в свой запрос. Это вызовет поисковую систему и вернет 5 лучших результатов с их URL-адресами и содержимым, каждый в чистом, удобном для LLM тексте."])},how_to_use3:n=>{const{normalize:r}=n;return r(["Добавьте https://g.jina.ai/ к вашему утверждению. Это вызовет механизм суждений и вернет процент правдивости, логическое значение, указывающее, является ли утверждение истинным или ложным, краткое изложение причин и список ссылок."])},key_required:n=>{const{normalize:r}=n;return r(["Для использования этой конечной точки требуется ключ API"])},learn_more:n=>{const{normalize:r}=n;return r(["Узнать больше"])},open:n=>{const{normalize:r}=n;return r(["Открыть в новой вкладке"])},raw_html:n=>{const{normalize:r}=n;return r(["Необработанный HTML"])},reader_output:n=>{const{normalize:r}=n;return r(["Вывод считывателя"])},reader_response:n=>{const{normalize:r}=n;return r(["Ответ читателя"])},reader_search_hint:n=>{const{normalize:r}=n;return r(["Если вы используете этот URL-адрес в коде, не забудьте его закодировать."])},reader_url:n=>{const{normalize:r}=n;return r(["URL-адрес читателя"])},reader_url_hint:n=>{const{normalize:r}=n;return r(["Нажмите ниже, чтобы получить контент через наш Reader API."])},requires_post_method:n=>{const{normalize:r}=n;return r(["Эта функция требует метод POST. При загрузке локального файла метод POST будет включен автоматически."])},search_params:n=>{const{normalize:r}=n;return r(["Параметры поиска/Заголовки"])},search_query_rewrite:n=>{const{normalize:r}=n;return r(["Обратите внимание: в отличие от демонстрации, показанной выше, на практике вам не нужно искать в Интернете исходный вопрос для обоснования. Люди часто переписывают исходный вопрос или используют вопросы с несколькими переходами. Они считывают полученные результаты, а затем генерируют дополнительные запросы для сбора дополнительной информации по мере необходимости, прежде чем прийти к окончательному ответу."])},select_mode:n=>{const{normalize:r}=n;return r(["Выбрать режим"])},show_read_demo:n=>{const{normalize:r}=n;return r(["Посмотрите, как Reader читает URL-адрес"])},show_search_demo:n=>{const{normalize:r}=n;return r(["Посмотрите, как Reader выполняет поиск в Интернете"])},slow_warning:n=>{const{normalize:r}=n;return r(["Это может занять до 30 секунд и стоить до 300 тыс. токенов за запрос."])},standard_usage:n=>{const{normalize:r}=n;return r(["Стандартное использование"])},stream_mode:n=>{const{normalize:r}=n;return r(["Режим потока"])},stream_mode_explain:n=>{const{normalize:r}=n;return r(["Режим потока полезен, когда целевая страница имеет большой размер для визуализации. Если вы обнаружите, что стандартный режим дает неполный контент, попробуйте потоковый режим."])},stream_mode_explain1:n=>{const{normalize:r}=n;return r(["Режим потоковой передачи полезен, когда вы обнаружите, что стандартный режим дает неполный результат. Это связано с тем, что режим потоковой передачи будет ждать немного дольше, пока страница не будет полностью отображена. Используйте заголовок Accept для переключения режима потоковой передачи:"])},tagline:n=>{const{normalize:r}=n;return r(["Попробуйте демо"])},try_demo:n=>{const{normalize:r}=n;return r(["Демо"])},use_headers:n=>{const{normalize:r}=n;return r(["Поведением Reader API можно управлять с помощью заголовков запросов. Вот полный список поддерживаемых заголовков."])},waiting_for_reader:n=>{const{normalize:r}=n;return r(["Сначала ожидание результата API Reader..."])},warn_grounding_message:n=>{const{normalize:r}=n;return r(["Этот процесс может занять до 30 секунд и потреблять до 300 тыс. токенов на запрос заземления. Некоторые браузеры могут завершить запрос из-за большой задержки, поэтому мы рекомендуем скопировать код и запустить его с вашего терминала."])},warn_grounding_title:n=>{const{normalize:r}=n;return r(["Высокая задержка и использование токенов"])},your_query:n=>{const{normalize:r}=n;return r(["Введите ваш запрос"])},your_query_hint:n=>{const{normalize:r}=n;return r(["Введите вопрос, который требует новейшей информации или мировых знаний."])},your_url:n=>{const{normalize:r}=n;return r(["Введите свой URL"])},your_url_hint:n=>{const{normalize:r}=n;return r(["Нажмите ниже, чтобы получить исходный код страницы напрямую."])}},description:n=>{const{normalize:r}=n;return r(["Читайте URL-адреса и ищите информацию в Интернете для получения более подходящей подготовки для получения степени магистра права."])},dont_panic_api_key_is_free:n=>{const{normalize:r}=n;return r(["Не паникуйте! Каждый новый ключ API содержит один миллион бесплатных токенов!"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["API Reader предоставляется бесплатно и не требует ключа API. Просто добавьте https://r.jina.ai/ к своему URL-адресу."])},answer10:n=>{const{normalize:r}=n;return r(["Нет, Reader API может обрабатывать контент только с общедоступных URL-адресов."])},answer11:n=>{const{normalize:r}=n;return r(["Если вы запросите тот же URL-адрес в течение 5 минут, Reader API вернет кэшированный контент."])},answer12:n=>{const{normalize:r}=n;return r(["К сожалению нет."])},answer13:n=>{const{normalize:r}=n;return r(["Да, вы можете использовать встроенную поддержку PDF в Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) или HTML-версию из arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)"])},answer14:n=>{const{normalize:r}=n;return r(["Reader подписывает все изображения по указанному URL-адресу и добавляет `Image [idx]: [caption]` в качестве альтернативного тега (если он изначально отсутствует). Это позволяет последующим LLM-специалистам взаимодействовать с изображениями при рассуждениях, обобщениях и т. д."])},answer15:n=>{const{normalize:r}=n;return r(["Reader API разработан с учетом высокой масштабируемости. Он автоматически масштабируется на основе трафика в реальном времени, а максимальное количество параллельных запросов сейчас составляет около 4000. Мы активно поддерживаем его как один из основных продуктов Jina AI. Так что смело используйте его в производстве."])},answer16:n=>{const{normalize:r}=n;return r(["Актуальную информацию об ограничениях скорости можно найти в таблице ниже. Обратите внимание, что мы активно работаем над улучшением ограничения скорости и производительности Reader API, таблица будет соответствующим образом обновлена."])},answer2:n=>{const{normalize:r}=n;return r(["API Reader использует прокси-сервер для получения любого URL-адреса, отображая его содержимое в браузере для извлечения высококачественного основного контента."])},answer3:n=>{const{normalize:r}=n;return r(["Да, Reader API имеет открытый исходный код и доступен в репозитории Jina AI GitHub."])},answer4:n=>{const{normalize:r}=n;return r(["Reader API обычно обрабатывает URL-адреса и возвращает контент в течение 2 секунд, хотя для сложных или динамических страниц может потребоваться больше времени."])},answer5:n=>{const{normalize:r}=n;return r(["Парсинг может быть сложным и ненадежным, особенно для сложных или динамических страниц. Reader API обеспечивает оптимизированный и надежный вывод чистого текста, готового к LLM."])},answer6:n=>{const{normalize:r}=n;return r(["API Reader возвращает контент на исходном языке URL-адреса. Он не предоставляет услуги перевода."])},answer7:n=>{const{normalize:r}=n;return r(["Если у вас возникли проблемы с блокировкой, обратитесь в нашу службу поддержки для помощи и решения."])},answer8:n=>{const{normalize:r}=n;return r(["Хотя Reader API в первую очередь предназначен для веб-страниц, он может извлекать контент из PDF-файлов, просматриваемых в формате HTML на таких веб-сайтах, как arXiv, но он не оптимизирован для общего извлечения PDF-файлов."])},answer9:n=>{const{normalize:r}=n;return r(["В настоящее время Reader API не обрабатывает мультимедийный контент, но будущие улучшения будут включать субтитры к изображениям и обобщение видео."])},question1:n=>{const{normalize:r}=n;return r(["Каковы затраты, связанные с использованием Reader API?"])},question10:n=>{const{normalize:r}=n;return r(["Можно ли использовать Reader API для локальных файлов HTML?"])},question11:n=>{const{normalize:r}=n;return r(["Кэширует ли Reader API контент?"])},question12:n=>{const{normalize:r}=n;return r(["Могу ли я использовать API Reader для доступа к контенту после входа в систему?"])},question13:n=>{const{normalize:r}=n;return r(["Могу ли я использовать Reader API для доступа к PDF-файлам на arXiv?"])},question14:n=>{const{normalize:r}=n;return r(["Как работает подпись к изображению в Reader?"])},question15:n=>{const{normalize:r}=n;return r(["Какова масштабируемость Reader? Могу ли я использовать его в производстве?"])},question16:n=>{const{normalize:r}=n;return r(["Каков предел скорости API Reader?"])},question2:n=>{const{normalize:r}=n;return r(["Как работает API Reader?"])},question3:n=>{const{normalize:r}=n;return r(["Является ли Reader API открытым исходным кодом?"])},question4:n=>{const{normalize:r}=n;return r(["Какова типичная задержка для Reader API?"])},question5:n=>{const{normalize:r}=n;return r(["Почему мне следует использовать Reader API вместо того, чтобы самостоятельно очищать страницу?"])},question6:n=>{const{normalize:r}=n;return r(["Поддерживает ли Reader API несколько языков?"])},question7:n=>{const{normalize:r}=n;return r(["Что делать, если веб-сайт блокирует Reader API?"])},question8:n=>{const{normalize:r}=n;return r(["Может ли Reader API извлекать контент из PDF-файлов?"])},question9:n=>{const{normalize:r}=n;return r(["Может ли Reader API обрабатывать медиаконтент с веб-страниц?"])},title:n=>{const{normalize:r}=n;return r(["Общие вопросы, связанные с читателями"])}},fast:n=>{const{normalize:r}=n;return r(["Быстрый"])},fast_stream:n=>{const{normalize:r}=n;return r(["Немедленная потоковая передача данных"])},fast_stream_description:n=>{const{normalize:r}=n;return r(["Нужны данные быстро? Наш Reader API может передавать данные в потоковом режиме, чтобы минимизировать задержку."])},free:n=>{const{normalize:r}=n;return r(["Бесплатно навсегда"])},free_description:n=>{const{normalize:r}=n;return r(["Reader API бесплатен! Для этого не требуется кредитная карта или секрет API. Он не будет использовать вашу квоту токена."])},is_free:n=>{const{normalize:r}=n;return r(["Лучшая часть? Это бесплатно!"])},is_free_description:n=>{const{normalize:r}=n;return r(["Reader API доступен бесплатно и предлагает гибкие ограничения по скорости и ценам. Построенный на основе масштабируемой инфраструктуры, он обеспечивает высокую доступность, параллелизм и надежность. Мы стремимся быть вашим предпочтительным решением по заземлению для ваших студентов LLM."])},open:n=>{const{normalize:r}=n;return r(["Открыть в новой вкладке"])},original_pdf:n=>{const{normalize:r}=n;return r(["Исходный PDF-файл"])},rate_limit:n=>{const{normalize:r}=n;return r(["Ограничение скорости"])},read_grounding_release_note:n=>{const{normalize:r}=n;return r(["Прочитать примечание к выпуску"])},reader_also_read_images:n=>{const{normalize:r}=n;return r(["Изображения на веб-странице автоматически снабжаются подписями с использованием языковой модели видения в программе чтения и форматируются в виде тегов alt изображения на выходе. Это дает вашему последующему LLM достаточно подсказок, чтобы включить эти изображения в процессы рассуждения и обобщения. Это означает, что вы можете задавать вопросы об изображениях, выбирать конкретные изображения или даже пересылать их URL-адреса более мощному VLM для более глубокого анализа!"])},reader_description:n=>{const{normalize:r}=n;return r(["Преобразуйте URL-адрес в формат ввода, удобный для LLM, просто добавив <code>r.jina.ai</code> в начало."])},reader_do_grounding:n=>{const{normalize:r}=n;return r(["Читатель для проверки фактов"])},reader_do_grounding_explain:n=>{const{normalize:r}=n;return r(["Новая конечная точка заземления предлагает сквозной, практически в реальном времени опыт проверки фактов. Она берет заданное утверждение, обосновывает его с помощью результатов веб-поиска в реальном времени и возвращает оценку фактичности и точные использованные ссылки. Вы можете легко обосновать утверждения, чтобы уменьшить галлюцинации LLM или улучшить целостность контента, написанного человеком."])},reader_do_pdf_explain:n=>{const{normalize:r}=n;return r(["Да, Reader изначально поддерживает чтение PDF-файлов. Он совместим с большинством PDF-файлов, в том числе с большим количеством изображений, и работает молниеносно! В сочетании с LLM вы можете легко создать ChatPDF или ИИ для анализа документов в кратчайшие сроки."])},reader_do_search:n=>{const{normalize:r}=n;return r(["Читалка для заземления поиска"])},reader_do_search_explain:n=>{const{normalize:r}=n;return r(["У LLM есть ограничение на знания, что означает, что они не могут получить доступ к новейшим мировым знаниям. Это приводит к таким проблемам, как дезинформация, устаревшие ответы, галлюцинации и другие проблемы с фактами. Заземление абсолютно необходимо для приложений GenAI. Reader позволяет вам снабжать свой LLM самой последней информацией из Интернета. Просто добавьте https://s.jina.ai/ к своему запросу, и Reader выполнит поиск в Интернете и вернет пять лучших результатов с их URL-адресами и содержимым, каждый в чистом, удобном для LLM тексте. Таким образом, вы всегда сможете поддерживать свой LLM в актуальном состоянии, повышать его достоверность и уменьшать количество галлюцинаций."])},reader_reads_images:n=>{const{normalize:r}=n;return r(["Ридер тоже читает изображения!"])},reader_reads_pdf:n=>{const{normalize:r}=n;return r(["Ридер также читает PDF-файлы!"])},reader_result:n=>{const{normalize:r}=n;return r(["Результат чтения"])},table:{td_1_0:n=>{const{normalize:r}=n;return r(["Прочитайте URL-адрес и верните его содержимое, что полезно для проверки заземления."])},td_1_1:n=>{const{normalize:r}=n;return r(["20 об/мин"])},td_1_2:n=>{const{normalize:r}=n;return r(["200 об/мин"])},td_1_3:n=>{const{normalize:r}=n;return r(["На основе выходных токенов"])},td_1_4:n=>{const{normalize:r}=n;return r(["3 секунды"])},td_1_5:n=>{const{normalize:r}=n;return r(["3 секунды"])},td_2_0:n=>{const{normalize:r}=n;return r(["Поиск в Интернете возвращает топ-5 результатов, что полезно для обоснования поиска."])},td_2_1:n=>{const{normalize:r}=n;return r(["5 об/мин"])},td_2_2:n=>{const{normalize:r}=n;return r(["40 об/мин"])},td_2_3:n=>{const{normalize:r}=n;return r(["На основе токенов вывода для всех 5 результатов поиска."])},td_2_4:n=>{const{normalize:r}=n;return r(["10 секунд"])},td_2_5:n=>{const{normalize:r}=n;return r(["10 секунд"])},th0:n=>{const{normalize:r}=n;return r(["Конечная точка"])},th1:n=>{const{normalize:r}=n;return r(["Описание"])},th2:n=>{const{normalize:r}=n;return r(["Ограничение скорости без ключа API"])},th3:n=>{const{normalize:r}=n;return r(["Ограничение скорости с ключом API"])},th4:n=>{const{normalize:r}=n;return r(["Схема подсчета токенов"])},th5:n=>{const{normalize:r}=n;return r(["Средняя задержка"])},th6:n=>{const{normalize:r}=n;return r(["Средняя задержка"])}},title:n=>{const{normalize:r}=n;return r(["API-интерфейс читателя"])},usage:n=>{const{normalize:r}=n;return r(["Применение"])},usage_details_false:n=>{const{normalize:r}=n;return r(["Показать только основные варианты использования"])},usage_details_null:n=>{const{normalize:r}=n;return r(["Показать базовое и расширенное использование"])},usage_details_true:n=>{const{normalize:r}=n;return r(["Показывать только расширенное использование"])},want_higher_rate_limit:n=>{const{normalize:r}=n;return r(["Хотите более высокий предел скорости до 1000 об/мин? Мы можем поддержать вас!"])},what_is1:n=>{const{normalize:r}=n;return r(["Что такое Ридер?"])},what_is_answer_long:n=>{const{normalize:r}=n;return r(["Предоставление веб-информации в программы LLM является важным шагом в обучении, однако это может быть непросто. Самый простой метод — очистить веб-страницу и передать ей необработанный HTML-код. Однако парсинг может быть сложным и часто блокируется, а необработанный HTML загроможден посторонними элементами, такими как разметка и скрипты. Reader API решает эти проблемы, извлекая основной контент из URL-адреса и преобразуя его в чистый, удобный для LLM текст, обеспечивая высококачественный ввод для вашего агента и систем RAG."])},what_is_desc:n=>{const{normalize:r}=n;return r(["Прокси-сервер, который обращается к любому URL-адресу и преобразует основной контент в обычный текст, оптимизированный для LLM."])}},recommender:{confirm_message:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["В вашем ключе API осталось токенов ",e(o("_leftTokens")),". Отправка полного текста статей ",e(o("_numArticles"))," в API Reranker с использованием модели ",e(o("_selectedReranker"))," для обнаружения связанных статей для текущей страницы значительно уменьшит количество токенов вашего ключа API ",e(o("_APIKey")),". Вы хотите продолжить?"])},confirm_title:n=>{const{normalize:r}=n;return r(["Предупреждение: высокий уровень использования токенов"])},out_of_quota:n=>{const{normalize:r}=n;return r(["В этом ключе API закончились токены. Пополните свой аккаунт или используйте другой ключ API."])},recommend:n=>{const{normalize:r}=n;return r(["Получить топ-5"])},recommended_articles:n=>{const{normalize:r}=n;return r(["Топ-5 похожих статей"])}},reranker:{benchmark:{description0:n=>{const{normalize:r}=n;return r(["LlamaIndex оценил различные комбинации встраивания и реранкинга для RAG, проведя исследование репликации, в котором измерялся средний обратный ранг. Результаты подчеркивают значительное улучшение качества поиска с помощью Jina Reranker, преимущество, которое не зависит от конкретных используемых вложений."])},description1:n=>{const{normalize:r}=n;return r(["BIER (Benchmarking IR) оценивает эффективность поиска модели, включая релевантность и NDCG. Более высокий показатель BIER коррелирует с более точными совпадениями и рейтингом результатов поиска."])},description2:n=>{const{normalize:r}=n;return r(["С помощью теста LoCo мы измерили понимание модели локальной связности и контекста, а также ранжирование по конкретному запросу. Более высокий балл LoCo отражает лучшую способность выявлять и расставлять приоритеты в соответствующей информации."])},description3:n=>{const{normalize:r}=n;return r(["Тест MTEB (Multilingual Text Embedding Benchmark) в целом проверяет возможности модели по встраиванию текста, включая кластеризацию, классификацию, поиск и другие показатели. Однако для нашего сравнения мы использовали только задачи переранжирования MTEB."])},title:n=>{const{normalize:r}=n;return r(["Контрольный показатель"])},title0:n=>{const{normalize:r}=n;return r(["ЛамаИндекс"])},title1:n=>{const{normalize:r}=n;return r(["БЕЙР"])},title2:n=>{const{normalize:r}=n;return r(["ЛоКо"])},title3:n=>{const{normalize:r}=n;return r(["МТЕБ"])}},benchmark_description:n=>{const{normalize:r}=n;return r(["Для сравнения мы включили в тест три других ведущих ререйнера от BGE (BAAI), BCE (Netease Youdao) и Cohere. Как показывают результаты ниже, Jina Reranker имеет самый высокий средний балл во всех соответствующих категориях для ререйтинга, что делает его явным лидером среди аналогов."])},benchmark_title:n=>{const{normalize:r}=n;return r(["Тест производительности"])},choose_turbo:n=>{const{normalize:r}=n;return r(["Получите ускорение до 5 раз с помощью Reranker-Turbo"])},choose_turbo_description:n=>{const{normalize:r}=n;return r(["Мы также предлагаем две новые модели реранкера с открытым исходным кодом: jina-reranker-v1-turbo-en и jina-reranker-v1-tiny-en, последняя имеет всего 30 миллионов параметров и четыре слоя. Эти два новых устройства реранкинга имеют в 5 раз более высокую скорость вывода, чем базовая модель, при очень небольших затратах на качество. Они идеально подходят для приложений, требующих изменения ранжирования в реальном времени. Прочтите тест ниже."])},customize_urself:n=>{const{normalize:r}=n;return r(["Измените его и посмотрите, как изменится реакция!"])},customize_urself_pl:n=>{const{normalize:r}=n;return r(["Измените их и посмотрите, как изменится реакция!"])},description:n=>{const{normalize:r}=n;return r(["Нейронный ретривер мирового класса для максимального повышения релевантности поиска."])},description_rich:n=>{const{normalize:r}=n;return r(["Увеличьте релевантность поиска и точность RAG с помощью нашего передового API-интерфейса реранжировщика."])},example_input_document:n=>{const{normalize:r}=n;return r(["Примеры документов кандидата для ранжирования"])},example_input_query:n=>{const{normalize:r}=n;return r(["Пример запроса"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["Цены на Reranker API соответствуют нашей структуре ценообразования API для встраивания. Он начинается с 1 миллиона бесплатных токенов за каждый новый ключ API. Помимо бесплатных жетонов, для покупки доступны различные пакеты. Для более подробной информации посетите наш раздел цен."])},answer10:n=>{const{normalize:r}=n;return r(["Да, Jina Reranker можно развернуть на AWS. Если вам требуется локальное развертывание в корпоративной среде, вы можете легко сделать это с помощью нашего предложения AWS Marketplace."])},answer11:n=>{const{normalize:r}=n;return r(["Если вы заинтересованы в точно настроенном механизме изменения рейтинга, адаптированном к конкретным данным домена, свяжитесь с нашим отделом продаж. Наша команда оперативно ответит на ваш запрос."])},answer3:n=>{const{normalize:r}=n;return r(["Основное отличие заключается в их архитектуре. По производительности мы рекомендуем jina-reranker-v1, который был тщательно протестирован и сравнен с конкурентами. Jina-reranker-v1 использует архитектуру перекрестного кодирования, а Jina-colbert-v1 основан на архитектуре ColBERTv2, но увеличивает длину контекста как запроса, так и документа до 8192, обеспечивая даже лучшую производительность, чем исходная модель ColBERTv2."])},answer4:n=>{const{normalize:r}=n;return r(["Да, jina-colbert-v1 имеет открытый исходный код, и доступ к нему можно получить через Huggingface. Однако jina-reranker-v1 не имеет открытого исходного кода."])},answer5:n=>{const{normalize:r}=n;return r(["В настоящее время он поддерживает только английский язык. Однако некоторые пользователи сообщили, что он также хорошо работает с китайским языком. Частично это может быть связано с тем, что jina-reranker-v1-base-en имеет некоторые общие веса с нашей моделью встраивания jina-embeddings-v2-base-zh."])},answer6:n=>{const{normalize:r}=n;return r(["Максимальная длина токена запроса — 512. Для документов ограничения на токен не существует."])},answer7:n=>{const{normalize:r}=n;return r(["Вы можете переоценить до 2048 документов по одному запросу."])},answer8:n=>{const{normalize:r}=n;return r(["В отличие от нашего API внедрения, понятия размера пакета не существует. Вы можете отправить только один кортеж запроса-документа за запрос, но кортеж может включать до 2048 документов-кандидатов."])},answer9:n=>{const{normalize:r}=n;return r(["Задержка варьируется от 100 миллисекунд до 7 секунд и во многом зависит от длины документов и запроса. Например, переоценка 100 документов по 256 токенов каждый с помощью запроса из 64 токенов занимает около 150 миллисекунд. Увеличение длины документа до 4096 токенов увеличивает время до 3,5 секунд. Если длина запроса увеличивается до 512 токенов, время увеличивается до 7 секунд."])},question1:n=>{const{normalize:r}=n;return r(["Сколько стоит API Reranker?"])},question10:n=>{const{normalize:r}=n;return r(["Могу ли я развернуть Jina Reranker на AWS?"])},question11:n=>{const{normalize:r}=n;return r(["Предлагаете ли вы точно настроенный механизм изменения рейтинга на основе данных, специфичных для конкретного домена?"])},question3:n=>{const{normalize:r}=n;return r(["В чем разница между двумя реранкерами?"])},question4:n=>{const{normalize:r}=n;return r(["Является ли Jina Reranker открытым исходным кодом?"])},question5:n=>{const{normalize:r}=n;return r(["Поддерживает ли реранкер несколько языков?"])},question6:n=>{const{normalize:r}=n;return r(["Какова максимальная длина запросов и документов?"])},question7:n=>{const{normalize:r}=n;return r(["Какое максимальное количество документов я могу переоценить по одному запросу?"])},question8:n=>{const{normalize:r}=n;return r(["Каков размер пакета и сколько кортежей документов-запросов я могу отправить в одном запросе?"])},question9:n=>{const{normalize:r}=n;return r(["Какую задержку можно ожидать при изменении ранжирования 100 документов?"])},title:n=>{const{normalize:r}=n;return r(["Общие вопросы, связанные с реранкером"])}},feature_on_premises_description2:n=>{const{normalize:r}=n;return r(["Разверните Jina Reranker на AWS Sagemaker, а вскоре и в Microsoft Azure и Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов."])},feature_on_premises_description3:n=>{const{normalize:r}=n;return r(["Разверните Jina Reranker на AWS Sagemaker и Microsoft Azure, а вскоре и в Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов."])},feature_solid_description:n=>{const{normalize:r}=n;return r(["Разработано на основе наших передовых академических исследований и тщательно протестировано с помощью реранкеров SOTA, чтобы обеспечить беспрецедентную производительность."])},how_it_works:n=>{const{normalize:r}=n;return r(["Вот как это работает:"])},how_it_works_v1:{description1:n=>{const{normalize:r}=n;return r(["Поисковая система использует embeddings/BM25 для поиска широкого набора потенциально релевантных документов на основе запроса пользователя."])},description2:n=>{const{normalize:r}=n;return r(["Затем программа реранкинга берет эти результаты и анализирует их на более детальном уровне, учитывая нюансы взаимодействия условий запроса с содержимым документа."])},description3:n=>{const{normalize:r}=n;return r(["На основе более глубокого анализа он меняет порядок результатов поиска, помещая вверху те, которые он считает наиболее релевантными."])},title1:n=>{const{normalize:r}=n;return r(["Первоначальное получение"])},title2:n=>{const{normalize:r}=n;return r(["Изменение рейтинга"])},title3:n=>{const{normalize:r}=n;return r(["Улучшенные результаты"])}},improve_performance:n=>{const{normalize:r}=n;return r(["Гарантированное улучшение по сравнению с векторным поиском"])},improve_performance_description:n=>{const{normalize:r}=n;return r(["Наши оценки продемонстрировали улучшение поисковых систем, использующих Jina Reranker, с +8% по показателю результативности и +33% по среднему взаимному рейтингу."])},learning1:n=>{const{normalize:r}=n;return r(["Изучение реранкера"])},learning1_description:n=>{const{normalize:r}=n;return r(["Что такое реранкер? Почему недостаточно векторного поиска или косинусного сходства? Узнайте о реранкерах с нуля с помощью нашего подробного руководства."])},read_more_about_benchmark:n=>{const{normalize:r}=n;return r(["Подробнее о тесте"])},read_more_about_turbo:n=>{const{normalize:r}=n;return r(["Подробнее о турбо- и миниатюрных моделях"])},read_more_about_v2:n=>{const{normalize:r}=n;return r(["Jina Reranker v2 — лучший в своем классе инструмент для изменения рейтинга, выпущенный 25 июня 2024 года; он создан для Agentic RAG. Он поддерживает вызов функций, многоязычный поиск для более чем 100 языков, возможности поиска кода и обеспечивает шестикратное ускорение по сравнению с версией v1. Подробнее о модели v2."])},reranker_description:n=>{const{normalize:r}=n;return r(["Попробуйте наш передовой API-интерфейс для изменения рейтинга, чтобы максимизировать релевантность поиска и точность RAG. Стартуем бесплатно!"])},show_v2benchmark:n=>{const{normalize:r}=n;return r(["Показать тест для модели v2 (последней)"])},table:{number_token_document:n=>{const{normalize:r}=n;return r(["Количество токенов в каждом документе"])},number_token_query:n=>{const{normalize:r}=n;return r(["Количество токенов в запросе"])},title:n=>{const{normalize:r}=n;return r(["Ниже приведены временные затраты на переоценку одного запроса и 100 документов в миллисекундах:"])}},title:n=>{const{normalize:r}=n;return r(["API реранкера"])},top_n:n=>{const{normalize:r}=n;return r(["Количество возвращенных документов"])},top_n_explain:n=>{const{normalize:r}=n;return r(["Количество наиболее релевантных документов, возвращаемых по запросу."])},try_embedding:n=>{const{normalize:r}=n;return r(["Попробуйте встроить API бесплатно"])},try_reranker:n=>{const{normalize:r}=n;return r(["Попробуйте API реранкера бесплатно"])},v2_features:{description1:n=>{const{normalize:r}=n;return r(["Reranker v2 позволяет извлекать документы на более чем 100 языках, независимо от языка запроса."])},description2:n=>{const{normalize:r}=n;return r(["Reranker v2 ранжирует фрагменты кода и сигнатуры функций на основе запросов на естественном языке, что идеально подходит для приложений Agentic RAG."])},description3:n=>{const{normalize:r}=n;return r(["Reranker v2 ранжирует наиболее релевантные таблицы на основе запросов на естественном языке, помогая сортировать различные схемы таблиц и определять наиболее релевантную перед созданием SQL-запроса."])},title1:n=>{const{normalize:r}=n;return r(["Многоязычный поиск"])},title2:n=>{const{normalize:r}=n;return r(["Вызов функций и поиск кода"])},title3:n=>{const{normalize:r}=n;return r(["Поддержка табличных и структурированных данных"])}},v2benchmark:{descBeir:n=>{const{normalize:r}=n;return r(["Представлены оценки NDCG 10 для различных моделей реранжирования набора данных Beir."])},descCodeSearchNet:n=>{const{normalize:r}=n;return r(["Оценки MRR 10 представлены для различных моделей реранжирования набора данных CodeSearchNet."])},descMKQA:n=>{const{normalize:r}=n;return r(["Напомним, 10 оценок были получены для различных моделей реранжирования для набора данных MKQA."])},descNSText2SQL:n=>{const{normalize:r}=n;return r(["Напомним, что для различных моделей реранжирования для набора данных NSText2SQL сообщалось о трех оценках."])},descRTX4090:n=>{const{normalize:r}=n;return r(["Показатели пропускной способности (документы извлекаются за 50 мс) представлены для различных моделей реранжирования на графическом процессоре RTX 4090."])},descToolBench:n=>{const{normalize:r}=n;return r(["Напомним, что для различных моделей реранжирования для набора данных ToolBench было получено 3 балла."])},titleBeir:n=>{const{normalize:r}=n;return r(["BEIR (гетерогенный тест для различных задач IR)"])},titleCodeSearchNet:n=>{const{normalize:r}=n;return r(["CodeSearchNet. Тест представляет собой комбинацию запросов в форматах строк документации и естественном языке с помеченными сегментами кода, соответствующими запросам."])},titleMKQA:n=>{const{normalize:r}=n;return r(["MKQA (Многоязычные вопросы и ответы)"])},titleNSText2SQL:n=>{const{normalize:r}=n;return r(["НСтекст2SQL"])},titleRTX4090:n=>{const{normalize:r}=n;return r(["Пропускная способность Jina Reranker v2 на RTX4090"])},titleToolBench:n=>{const{normalize:r}=n;return r(["ИнструментБенч. Тест собирает более 16 тысяч общедоступных API и соответствующих синтетически сгенерированных инструкций для их использования в настройках с одним и несколькими API."])}},vs_table:{col0:n=>{const{normalize:r}=n;return r(["Реранкер"])},col0_1:n=>{const{normalize:r}=n;return r(["Повышенная точность и релевантность поиска"])},col0_2:n=>{const{normalize:r}=n;return r(["Начальная, быстрая фильтрация"])},col0_3:n=>{const{normalize:r}=n;return r(["Общий поиск текста по широкому кругу запросов"])},col1:n=>{const{normalize:r}=n;return r(["Векторный поиск"])},col1_1:n=>{const{normalize:r}=n;return r(["Подробно: вложенный документ и сегмент запроса."])},col1_2:n=>{const{normalize:r}=n;return r(["Широкий: все документы."])},col1_3:n=>{const{normalize:r}=n;return r(["Средний уровень: различные фрагменты текста."])},col2:n=>{const{normalize:r}=n;return r(["БМ25"])},col2_1:n=>{const{normalize:r}=n;return r(["Высокий"])},col2_2:n=>{const{normalize:r}=n;return r(["Середина"])},col2_3:n=>{const{normalize:r}=n;return r(["Низкий"])},col3_1:n=>{const{normalize:r}=n;return r(["Не требуется"])},col3_2:n=>{const{normalize:r}=n;return r(["Высокий"])},col3_3:n=>{const{normalize:r}=n;return r(["Низкий, использует готовый индекс"])},col4_1:n=>{const{normalize:r}=n;return r(["Высокий"])},col4_2:n=>{const{normalize:r}=n;return r(["Высокий"])},col4_3:n=>{const{normalize:r}=n;return r(["Не требуется"])},col5_1:n=>{const{normalize:r}=n;return r(["Превосходно для тонких запросов"])},col5_2:n=>{const{normalize:r}=n;return r(["Баланс между эффективностью и точностью"])},col5_3:n=>{const{normalize:r}=n;return r(["Согласованность и надежность для широкого круга запросов"])},col6_1:n=>{const{normalize:r}=n;return r(["Высокая точность и глубокое понимание контекста"])},col6_2:n=>{const{normalize:r}=n;return r(["Быстро и эффективно, с умеренной точностью."])},col6_3:n=>{const{normalize:r}=n;return r(["Высокая масштабируемость и доказанная эффективность"])},col7_1:n=>{const{normalize:r}=n;return r(["Ресурсоемкость со сложной реализацией"])},col7_2:n=>{const{normalize:r}=n;return r(["Может не улавливать глубокий контекст или нюансы запроса."])},col7_3:n=>{const{normalize:r}=n;return r(["Может быть неэффективным для узкоспециализированного или контекстного поиска."])},header0:n=>{const{normalize:r}=n;return r(["Лучшее для"])},header1:n=>{const{normalize:r}=n;return r(["Детализация"])},header2:n=>{const{normalize:r}=n;return r(["Сложность времени запроса"])},header3:n=>{const{normalize:r}=n;return r(["Индексация временной сложности"])},header4:n=>{const{normalize:r}=n;return r(["Сложность времени обучения"])},header5:n=>{const{normalize:r}=n;return r(["Качество поиска"])},header6:n=>{const{normalize:r}=n;return r(["Сильные стороны"])},header7:n=>{const{normalize:r}=n;return r(["Недостатки"])},subtitle:n=>{const{normalize:r}=n;return r(["В таблице ниже представлено всестороннее сравнение Reranker, Vector/Embeddings Search и BM25, подчеркивая их сильные и слабые стороны в различных категориях."])},title:n=>{const{normalize:r}=n;return r(["Сравнение реранкера, векторного поиска и BM25"])}},what_is:n=>{const{normalize:r}=n;return r(["Что такое реранкер?"])},what_is_answer_long:n=>{const{normalize:r}=n;return r([`Цель поисковой системы — быстро и эффективно находить наиболее релевантные результаты. Традиционно для ранжирования результатов поиска на основе соответствия ключевых слов использовались такие методы, как BM25 или tf-idf. Последние методы, такие как косинусное сходство на основе встраивания, были реализованы во многих векторных базах данных. Эти методы просты, но иногда могут упускать из виду тонкости языка и, что наиболее важно, взаимодействие между документами и целью запроса.

Вот тут-то и сияет «реранкер». Реранкер — это усовершенствованная модель искусственного интеллекта, которая берет первоначальный набор результатов поиска (часто предоставляемого поиском на основе внедрений/токенов) и повторно оценивает их, чтобы убедиться, что они более точно соответствуют намерениям пользователя. Он выходит за рамки сопоставления терминов на поверхностном уровне и рассматривает более глубокое взаимодействие между поисковым запросом и содержанием документов.`])},what_is_answer_long_ending:n=>{const{normalize:r}=n;return r(["Средство повторного ранжирования может значительно улучшить качество поиска, поскольку оно работает на уровне поддокумента и подзапроса, то есть анализирует отдельные слова и фразы, их значения и то, как они соотносятся друг с другом в запросе и документах. Это приводит к более точному и контекстуально релевантному набору результатов поиска."])},what_is_desc:n=>{const{normalize:r}=n;return r(["Реранкер — это модель искусственного интеллекта, которая уточняет результаты поиска на основе векторного поиска или модели плотного поиска. Читать далее."])}},scenex:{caption_image_desc:n=>{const{normalize:r}=n;return r(["Создайте текстовое описание изображения."])},caption_image_title:n=>{const{normalize:r}=n;return r(["Подпись к изображению"])},description:n=>{const{normalize:r}=n;return r(["Исследуйте рассказывание историй изображениями за пределами пикселей"])},example1:n=>{const{normalize:r}=n;return r(["Это видео представляет собой кадры природы, на которых изображены очаровательный белый кролик и бабочка в травянистом поле. Зайчик по-разному взаимодействует с бабочкой, демонстрируя их уникальные отношения. Природная среда создает живописный фон, подчеркивая красоту этой простой, но захватывающей сцены."])},generate_story_desc:n=>{const{normalize:r}=n;return r(["Создайте историю, вдохновленную изображением, часто включающую диалоги или монологи персонажей."])},generate_story_title:n=>{const{normalize:r}=n;return r(["Создать историю"])},intro1:n=>{const{normalize:r}=n;return r(["Ведущее решение искусственного интеллекта для подписей к изображениям и обзоров видео"])},json_image_desc:n=>{const{normalize:r}=n;return r(["Создайте структурированный формат JSON из изображения, используя предопределенную схему. Это позволяет извлекать конкретные данные из изображения."])},json_image_title:n=>{const{normalize:r}=n;return r(["Извлечь JSON из изображения"])},summarize_video_desc:n=>{const{normalize:r}=n;return r(["Создайте краткое изложение видео, выделив ключевые события."])},summarize_video_title:n=>{const{normalize:r}=n;return r(["Подведение итогов видео"])},visual_q_a_desc:n=>{const{normalize:r}=n;return r(["Ответьте на запрос, основанный на содержимом изображения."])},visual_q_a_title:n=>{const{normalize:r}=n;return r(["Визуальные вопросы и ответы"])}},searchbar:{ask_on_current_page:n=>{const{normalize:r}=n;return r(["Спросите текущую страницу о..."])},find_solution:n=>{const{normalize:r}=n;return r(["Создайте решение для..."])},hint:n=>{const{normalize:r}=n;return r(["Поиск по продуктам, новостям и вашим вопросам"])},hotkey:n=>{const{normalize:r}=n;return r(["Нажмите клавишу / для поиска на этой странице."])},hotkey1:n=>{const{normalize:r}=n;return r(["Нажимать"])},hotkey2:n=>{const{normalize:r}=n;return r(["переключать"])},hotkey_long1:n=>{const{normalize:r}=n;return r(["В любой момент нажмите"])},hotkey_long3:n=>{const{normalize:r}=n;return r(["открыть панель поиска"])},more_results:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_numMore"))," ещё результатов"])},placeholder:n=>{const{normalize:r}=n;return r(["Задайте любой вопрос на этой странице"])},proposing_solution:n=>{const{normalize:r}=n;return r(["Генерация ответа на основе содержимого страницы..."])},required:n=>{const{normalize:r}=n;return r(["Пожалуйста, опишите свой вопрос более подробно."])},results:n=>{const{normalize:r}=n;return r(["Результаты"])}},searchscape:{description:n=>{const{normalize:r}=n;return r(["Навигация, взаимодействие, уточнение: переосмыслите поиск продукта"])}},semantic:{description:n=>{const{normalize:r}=n;return r(["Преодоление семантического разрыва в существующей поисковой инфраструктуре"])}},share:{"Hacker News":n=>{const{normalize:r}=n;return r(["Хакерские новости"])},LinkedIn:n=>{const{normalize:r}=n;return r(["LinkedIn"])},facebook:n=>{const{normalize:r}=n;return r(["Фейсбук"])},reddit:n=>{const{normalize:r}=n;return r(["Реддит"])},rss:n=>{const{normalize:r}=n;return r(["Новостная лента"])},share_btn:n=>{const{normalize:r}=n;return r(["Делиться"])},twitter:n=>{const{normalize:r}=n;return r(["Х (Твиттер)"])}},spectrum:{click_to_learn_more:n=>{const{normalize:r}=n;return r(["Нажмите, чтобы узнать больше"])},contextualization:n=>{const{normalize:r}=n;return r(["Контекстуализация"])},contextualization_desc:n=>{const{normalize:r}=n;return r(["Реранкеры корректируют первоначальные результаты поиска на основе глубокой контекстуальной релевантности. запрос. Это улучшает рейтинг, чтобы лучше соответствовать тому, что пользователи могут найти полезным."])},coreInfra:n=>{const{normalize:r}=n;return r(["Базовая инфраструктура"])},coreInfra_desc:n=>{const{normalize:r}=n;return r(["Core infra обеспечивает облачный уровень для разработки, развертывания и оркестрации моделей платформы поиска как в общедоступном облаке, так и локально, что позволяет легко масштабировать сервисы вверх и вниз."])},embedding_serving:n=>{const{normalize:r}=n;return r(["Встраивание обслуживания"])},embedding_serving_description:n=>{const{normalize:r}=n;return r(["Встраивание с помощью надежного масштабируемого микросервиса с использованием облачных технологий."])},embedding_tech:n=>{const{normalize:r}=n;return r(["Вложения"])},embedding_tech_description:n=>{const{normalize:r}=n;return r([`В Jina AI мы используем возможности внедрения технологий, чтобы произвести революцию в различных приложениях искусственного интеллекта. Эта технология служит унифицированным методом эффективного представления и сжатия различных типов данных, гарантируя отсутствие потери важной информации. Наше внимание сосредоточено на преобразовании сложных наборов данных в универсально понятный формат внедрения, который необходим для точного и глубокого анализа ИИ.

Встраивание имеет основополагающее значение, особенно в таких приложениях, как точное распознавание изображений и голоса, где оно помогает различать мелкие детали и нюансы. При обработке естественного языка встраивания улучшают понимание контекста и настроений, что приводит к созданию более точных инструментов разговорного искусственного интеллекта и языкового перевода. Они также имеют решающее значение для разработки сложных систем рекомендаций, которые требуют глубокого понимания предпочтений пользователей в различных формах контента, таких как текст, аудио и видео.`])},embedding_tuning:n=>{const{normalize:r}=n;return r(["Встраивание настройки"])},embedding_tuning_description:n=>{const{normalize:r}=n;return r(["Оптимизация высококачественных внедрений за счет интеграции опыта предметной области для повышения производительности конкретных задач."])},embeddings:n=>{const{normalize:r}=n;return r(["Вложения"])},embeddings_desc:n=>{const{normalize:r}=n;return r(["Вложения — это краеугольный камень современной поисковой системы, представляющий мультимодальные данные в векторы чисел. Этот процесс обеспечивает более детальное и контекстуальное понимание контента, выходящее далеко за рамки простого сопоставления ключевых слов."])},for_developers:n=>{const{normalize:r}=n;return r(["Для разработчиков"])},for_enterprise:n=>{const{normalize:r}=n;return r(["Для предприятий"])},for_power_users:n=>{const{normalize:r}=n;return r(["Для опытных пользователей"])},grounding:n=>{const{normalize:r}=n;return r(["Заземление"])},grounding_desc:n=>{const{normalize:r}=n;return r(["Читатель уточняет исходные данные и результаты с помощью LLM. Они улучшают качество, читабельность и актуальность окончательного ответа."])},model_serving:n=>{const{normalize:r}=n;return r(["Обслуживание моделей"])},model_serving_description:n=>{const{normalize:r}=n;return r(["Развертывание точно настроенных моделей в производственной среде, обычно требующее значительных ресурсов, таких как хостинг на графическом процессоре. MLOps, уделяя особое внимание обслуживанию моделей среднего и крупного размера масштабируемым, эффективным и надежным способом."])},model_tuning:n=>{const{normalize:r}=n;return r(["Настройка модели"])},model_tuning_description:n=>{const{normalize:r}=n;return r(["Также известная как тонкая настройка, включает в себя настройку параметров предварительно обученной модели на новом, часто специфичном для задачи наборе данных, чтобы улучшить ее производительность и адаптировать ее к конкретному приложению."])},personalization:n=>{const{normalize:r}=n;return r(["Персонализация"])},personalization_desc:n=>{const{normalize:r}=n;return r(["Использование синтетических данных в соответствии с инструкциями пользователя для автоматического обучения модели внедрения и переранжирования для конкретной предметной области."])},preprocessing:n=>{const{normalize:r}=n;return r(["Предварительная обработка"])},preprocessing_desc:n=>{const{normalize:r}=n;return r(["Предварительная обработка включает в себя очистку, нормализацию и преобразование необработанных данных в формат, удобный для восприятия поисковой системой."])},promptOps:n=>{const{normalize:r}=n;return r(["PromptOps"])},promptOps_desc:n=>{const{normalize:r}=n;return r(["Prompt Ops улучшает ввод и вывод поисковой системы, в том числе те, которые используются при расширении запросов, LLM-вводе и переписывании результатов. Это гарантирует, что поиск будет лучше понимать и давать лучшие результаты."])},prompt_serving:n=>{const{normalize:r}=n;return r(["Быстрое обслуживание"])},prompt_serving_description:n=>{const{normalize:r}=n;return r(["Обтекание и обслуживание подсказок через API без размещения тяжелых моделей. API вызывает общедоступную службу модели большого языка и управляет согласованием входных и выходных данных в цепочке операций."])},prompt_tech:n=>{const{normalize:r}=n;return r(["Оперативная и агентская разработка"])},prompt_tech_description:n=>{const{normalize:r}=n;return r([`В Jina AI мы считаем, что оперативное проектирование жизненно важно для взаимодействия с большими языковыми моделями (LLM). По мере развития этих моделей сложность подсказок возрастает, включая сложные рассуждения и логику. Этот прогресс подчеркивает переплетение роста LLM и быстрого развития.

Мы предвидим будущее, в котором LLM будут действовать как компиляторы, а подсказки станут новым языком программирования. Этот сдвиг предполагает, что будущие технологические навыки могут быть больше ориентированы на быстрое освоение, чем на традиционное программирование. Наша цель в Jina AI — стать лидером в этой преобразующей области, делая передовой искусственный интеллект доступным и практичным для повседневного использования путем освоения этого нового «языка».`])},prompt_tuning:n=>{const{normalize:r}=n;return r(["Оперативная настройка"])},prompt_tuning_description:n=>{const{normalize:r}=n;return r(["Процесс создания и уточнения входных подсказок для направления его вывода в сторону конкретных желаемых ответов."])},representation:n=>{const{normalize:r}=n;return r(["Представление"])},representation_desc:n=>{const{normalize:r}=n;return r(["Встраивания преобразуют мультимодальные данные в единый векторизованный формат. Это позволяет поисковой системе понимать и классифицировать контент, помимо простых ключевых слов."])},rerankers:n=>{const{normalize:r}=n;return r(["Реранкер"])},rerankers_desc:n=>{const{normalize:r}=n;return r(["Реранкеры берут первоначальные результаты из вложений и уточняют их, гарантируя, что наиболее релевантные результаты будут представлены пользователю. Это крайне важно для предоставления высококачественных результатов поиска, соответствующих намерениям пользователя."])}},subscribe_system:{care_most:n=>{const{normalize:r}=n;return r(["Что вас больше всего волнует?"])},care_most_options:{accuracy:n=>{const{normalize:r}=n;return r(["Точность"])},cost:n=>{const{normalize:r}=n;return r(["Расходы"])},other:n=>{const{normalize:r}=n;return r(["Другой"])},scalability:n=>{const{normalize:r}=n;return r(["Масштабируемость"])},speed:n=>{const{normalize:r}=n;return r(["Скорость"])}},care_most_required:n=>{const{normalize:r}=n;return r(["Что вас больше всего волнует при выборе услуги?"])},company_size:n=>{const{normalize:r}=n;return r(["Каков размер вашей компании?"])},company_size_required:n=>{const{normalize:r}=n;return r(["Сообщите нам, что размер вашей компании помогает нам предоставлять лучший сервис."])},company_url:n=>{const{normalize:r}=n;return r(["Какой у вашей компании сайт?"])},company_url_required:n=>{const{normalize:r}=n;return r(["Сообщите нам, что веб-сайт вашей компании помогает нам предоставлять лучший сервис."])},contactName:n=>{const{normalize:r}=n;return r(["Ваше имя"])},contactName_required:n=>{const{normalize:r}=n;return r(["Как нам следует обратиться к вам?"])},contactTitle:n=>{const{normalize:r}=n;return r(["Какова ваша должность?"])},contactTitle_required:n=>{const{normalize:r}=n;return r(["Требуется ваша должность"])},contact_us:n=>{const{normalize:r}=n;return r(["Связаться с нами"])},domain_required:n=>{const{normalize:r}=n;return r(["Сообщите нам, что ваша область работы помогает нам предоставлять лучший сервис."])},email:n=>{const{normalize:r}=n;return r(["Электронная почта"])},email_contact:n=>{const{normalize:r}=n;return r(["Ваш контактный адрес электронной почты"])},email_invalid:n=>{const{normalize:r}=n;return r(["Электронная почта недействительна"])},email_required:n=>{const{normalize:r}=n;return r(["Требуется электронная почта"])},fine_tuned_embedding:n=>{const{normalize:r}=n;return r(["Заинтересованы в тонко настроенных внедрениях, адаптированных к вашим данным и варианту использования? Давайте обсудим!"])},fine_tuned_reranker:n=>{const{normalize:r}=n;return r(["Заинтересованы в точно настроенных программах реранкинга, адаптированных к вашим данным и варианту использования? Давайте обсудим!"])},full_survey:n=>{const{normalize:r}=n;return r(["Пройдите полный опрос и получите более быстрый ответ от нашей команды"])},get_new_key:n=>{const{normalize:r}=n;return r(["Получите свой API-ключ"])},get_update_blog_posts:n=>{const{normalize:r}=n;return r(["Получайте последние обновления для сообщений в блоге"])},get_update_embeddings:n=>{const{normalize:r}=n;return r(["Получайте последние обновления для встраивания"])},send:n=>{const{normalize:r}=n;return r(["Отправлять"])},sign_up:n=>{const{normalize:r}=n;return r(["Зарегистрироваться"])},subscribe:n=>{const{normalize:r}=n;return r(["Подписаться"])},tell_domain:n=>{const{normalize:r}=n;return r(["Сообщите нам свой домен"])},usage_type:n=>{const{normalize:r}=n;return r(["Какой тип использования лучше всего описывает вас?"])},usage_type_options:{other:n=>{const{normalize:r}=n;return r(["Другой"])},poc:n=>{const{normalize:r}=n;return r(["Доказательство концепции"])},production:n=>{const{normalize:r}=n;return r(["Производство"])},research:n=>{const{normalize:r}=n;return r(["Исследовать"])}},usage_type_required:n=>{const{normalize:r}=n;return r(["Сообщите нам, что ваш тип использования помогает нам предоставлять лучший сервис."])},used_product:n=>{const{normalize:r}=n;return r(["Какую модель вы используете?"])},used_product_required:n=>{const{normalize:r}=n;return r(["Выберите модель, которую вы используете или которая вас интересует"])}},think_gpt:{description:n=>{const{normalize:r}=n;return r(["Методы агента для расширения вашего LLM и выхода за его пределы"])}},toc:n=>{const{normalize:r}=n;return r(["Содержание"])},tokenizer:{advance_usage:n=>{const{normalize:r}=n;return r(["Используйте POST-запрос для получения дополнительных функций"])},basic_usage:n=>{const{normalize:r}=n;return r(["Используйте GET-запрос для подсчета токенов"])},basic_usage_explain:n=>{const{normalize:r}=n;return r(["Вы можете просто отправить GET-запрос, чтобы подсчитать количество токенов в вашем тексте."])},change_content:n=>{const{normalize:r}=n;return r(["Измените «контент» и посмотрите результат в реальном времени"])},chars:n=>{const{normalize:r}=n;return r(["персонажи"])},chinese:n=>{const{normalize:r}=n;return r(["китайский"])},chunk:n=>{const{normalize:r}=n;return r(["Кусок"])},chunk_all:n=>{const{normalize:r}=n;return r(["Все куски"])},chunking:n=>{const{normalize:r}=n;return r(["Молниеносная обработка длинных документов!"])},chunking_explain:n=>{const{normalize:r}=n;return r(["Вы также можете использовать API Segmenter для разрезания длинных документов на более мелкие фрагменты, что упрощает их обработку в встраиваниях или рераннерах. Мы используем общие структурные подсказки и создаем набор правил и эвристик, которые хорошо работают с различными типами контента, например, языками Markdown, HTML, LaTeX и CJK."])},chunking_short:n=>{const{normalize:r}=n;return r(["Разделение на части"])},chunks_in_total:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_numChunks"))," кусков всего"])},count_tokens_hint:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["<b>",e(o("_numTokens")),"</b> токенов, ",e(o("_numChars"))," символов."])},description:n=>{const{normalize:r}=n;return r(["Разрежьте длинный текст на куски и выполните токенизацию."])},description_long:n=>{const{normalize:r}=n;return r(["Наш API Segmenter имеет решающее значение для помощи LLM в управлении вводом в рамках контекстных ограничений и оптимизации производительности модели. Он позволяет разработчикам подсчитывать токены и извлекать соответствующие текстовые сегменты, обеспечивая эффективную обработку данных и управление затратами."])},description_long1:n=>{const{normalize:r}=n;return r(["Бесплатный API для сегментации длинного текста на фрагменты и токенизации."])},english:n=>{const{normalize:r}=n;return r(["Английский"])},explain:n=>{const{normalize:r}=n;return r(["Сегментатор — это важный компонент, который преобразует текст в токены или фрагменты, которые являются основными единицами данных, обрабатываемыми моделью внедрения/переранжирования или LLM. Токены могут представлять целые слова, части слов или даже отдельные символы."])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["API Segmenter можно использовать бесплатно. Предоставляя свой ключ API, вы можете получить доступ к более высокому пределу скорости, и ваш ключ не будет оплачиваться."])},answer10:n=>{const{normalize:r}=n;return r(["Помимо западных языков, разбиение на фрагменты также хорошо работает с китайским, японским и корейским языками."])},answer2:n=>{const{normalize:r}=n;return r(["Без ключа API вы можете получить доступ к API Segmenter со скоростью 20 об/мин."])},answer3:n=>{const{normalize:r}=n;return r(["С помощью API-ключа вы можете получить доступ к API Segmenter с ограничением скорости 200 RPM. Для платных пользователей премиум-подписки ограничение скорости составляет 1000 RPM."])},answer4:n=>{const{normalize:r}=n;return r(["Нет, ваш ключ API используется только для доступа к более высокому лимиту скорости."])},answer5:n=>{const{normalize:r}=n;return r(["Да, API Segmenter многоязычен и поддерживает более 100 языков."])},answer6:n=>{const{normalize:r}=n;return r(["Запросы GET используются исключительно для подсчета количества токенов в тексте, что позволяет вам легко интегрировать его в качестве счетчика в ваше приложение. Запросы POST поддерживают больше параметров и функций, таких как возврат первых/последних N токенов."])},answer7:n=>{const{normalize:r}=n;return r(["Вы можете отправить до 64 тыс. символов за один запрос."])},answer8:n=>{const{normalize:r}=n;return r(["Функция фрагментации сегментирует длинные документы на более мелкие фрагменты на основе общих структурных сигналов, обеспечивая точную сегментацию текста на значимые фрагменты. По сути, это (большой!) шаблон регулярного выражения, который сегментирует текст на основе определенных синтаксических признаков, которые часто совпадают с семантическими границами, такими как окончания предложений, разрывы абзацев, пунктуация и определенные союзы. Это не семантическое фрагментирование. Это (большое) регулярное выражение настолько мощно, насколько это возможно в рамках ограничений регулярных выражений. Оно уравновешивает сложность и производительность. Хотя истинное семантическое понимание невозможно с помощью регулярных выражений, оно хорошо аппроксимирует контекст с помощью общих структурных сигналов."])},answer9:n=>{const{normalize:r}=n;return r(["Если входные данные содержат специальные токены, наш API Segmenter поместит их в поле «special_tokens». Это позволяет вам легко идентифицировать их и обрабатывать соответствующим образом для ваших последующих задач, например, удаляя их перед подачей текста в LLM для предотвращения атак с инъекциями."])},question1:n=>{const{normalize:r}=n;return r(["Сколько стоит API Segmenter?"])},question10:n=>{const{normalize:r}=n;return r(["Поддерживает ли функция фрагментации другие языки, кроме английского?"])},question2:n=>{const{normalize:r}=n;return r(["Если я не предоставлю ключ API, каков предел скорости?"])},question3:n=>{const{normalize:r}=n;return r(["Если я предоставлю ключ API, каков предел скорости?"])},question4:n=>{const{normalize:r}=n;return r(["Будете ли вы взимать плату за токены с моего ключа API?"])},question5:n=>{const{normalize:r}=n;return r(["Поддерживает ли API Segmenter несколько языков?"])},question6:n=>{const{normalize:r}=n;return r(["В чем разница между запросами GET и POST?"])},question7:n=>{const{normalize:r}=n;return r(["Какую максимальную длину я могу токенизировать за один запрос?"])},question8:n=>{const{normalize:r}=n;return r(["Как работает функция фрагментации? Это семантическая фрагментация?"])},question9:n=>{const{normalize:r}=n;return r(["Как вы обрабатываете специальные токены, такие как «endoftext» в API Segmenter?"])},title:n=>{const{normalize:r}=n;return r(["Распространенные вопросы, связанные с сегментатором"])}},free_api:n=>{const{normalize:r}=n;return r(["Segmenter API можно использовать бесплатно. Предоставляя свой ключ API, вы можете получить доступ к более высокому пределу скорости, и ваш ключ не будет оплачиваться."])},input_text:n=>{const{normalize:r}=n;return r(["Введите текст"])},is_free:n=>{const{normalize:r}=n;return r(["API сегментатора бесплатен!"])},is_free_description:n=>{const{normalize:r}=n;return r(["Указав свой ключ API, вы сможете получить доступ к более высокому лимиту скорости, и плата за ваш ключ взиматься не будет."])},japanese:n=>{const{normalize:r}=n;return r(["японский"])},korean:n=>{const{normalize:r}=n;return r(["корейский"])},parameters:{auth_token:n=>{const{normalize:r}=n;return r(["Добавьте ключ API для более высокого лимита скорости"])},auth_token_explain:n=>{const{normalize:r}=n;return r(["Введите свой ключ API Jina, чтобы получить доступ к более высокому пределу скорости. Для получения последней информации о пределе скорости см. таблицу ниже."])},head:n=>{const{normalize:r}=n;return r(["Верните первые N токенов"])},head_explain:n=>{const{normalize:r}=n;return r(["Возвращает первые N токенов указанного содержимого. Исключает границу. Не может использоваться с 'tail'."])},learn_more:n=>{const{normalize:r}=n;return r(["Узнать больше"])},max_chunk_length:n=>{const{normalize:r}=n;return r(["Максимальная длина каждого фрагмента"])},max_chunk_length_explain:n=>{const{normalize:r}=n;return r(["Максимальное количество символов в каждом фрагменте. На практике длина фрагмента может быть меньше этого значения, если в тексте есть естественная граница."])},return_chunks:n=>{const{normalize:r}=n;return r(["Верните куски"])},return_chunks_explain:n=>{const{normalize:r}=n;return r(["Разделение входных данных на семантически значимые сегменты с обработкой широкого спектра типов текста и пограничных случаев на основе общих структурных признаков."])},return_tokens:n=>{const{normalize:r}=n;return r(["Верните жетоны."])},return_tokens_explain:n=>{const{normalize:r}=n;return r(["Верните токены и соответствующие им идентификаторы в ответе. Переключите, чтобы увидеть визуализацию результата."])},tail:n=>{const{normalize:r}=n;return r(["Верните последние N токенов"])},tail_explain:n=>{const{normalize:r}=n;return r(["Возвращает последние N токенов указанного контента. Исключает границу. Не может использоваться с 'head'."])},type:n=>{const{normalize:r}=n;return r(["Сегментатор"])},type_explain:n=>{const{normalize:r}=n;return r(["Выберите токенизатор для использования."])},used_by_models:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Используется в ",e(o("_usedBy")),"."])}},remove_boundary_cues:n=>{const{normalize:r}=n;return r(["Удалить переносы строк"])},remove_boundary_cues_explain:n=>{const{normalize:r}=n;return r(["Удалите все разрывы строк (основные граничные сигналы) из входных данных, это усложнит задачу, и посмотрите, как изменится ответ!"])},show_space:n=>{const{normalize:r}=n;return r(["Показать начальные/конечные пробелы"])},table:{td_1_0:n=>{const{normalize:r}=n;return r(["Токенизируйте тексты, подсчитывайте и получайте первые/последние N токенов."])},td_1_1:n=>{const{normalize:r}=n;return r(["20 об/мин"])},td_1_2:n=>{const{normalize:r}=n;return r(["200 об/мин"])},td_1_3:n=>{const{normalize:r}=n;return r(["1000 об/мин"])},td_1_4:n=>{const{normalize:r}=n;return r(["Бесплатно"])},td_1_5:n=>{const{normalize:r}=n;return r(["800мс"])}},title:n=>{const{normalize:r}=n;return r(["API сегментатора"])},token_index:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Индекс токена: ",e(o("_index"))])},usage:n=>{const{normalize:r}=n;return r(["Использование"])},visualization:n=>{const{normalize:r}=n;return r(["Визуализация"])},what_is:n=>{const{normalize:r}=n;return r(["Что такое сегментатор?"])}},translator:{cta:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["Перевести на ",e(o("_lang"))," код"])},select_language:n=>{const{normalize:r}=n;return r(["Язык"])}},vectordb:{description:n=>{const{normalize:r}=n;return r(["База данных векторов Python, которая вам просто необходима — ни больше, ни меньше"])}},zzz:n=>{const{normalize:r}=n;return r(["zzz"])}};export{t as default};
