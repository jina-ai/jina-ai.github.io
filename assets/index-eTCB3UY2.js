const o={PRODUCT_DESCRIPTION:e=>{const{normalize:a}=e;return a(["Proporcionamos las mejores incorporaciones, reclasificadores, lectores de LLM y optimizadores rápidos de su clase, siendo pioneros en la búsqueda de IA para datos multimodales."])},SEO_TAG_LINE:e=>{const{normalize:a}=e;return a(["Su base de búsqueda, sobrealimentada."])},about_us_page:{approach:e=>{const{normalize:a}=e;return a(["Nuestro enfoque"])},approach_connect_dots:e=>{const{normalize:a}=e;return a(["Conectando los puntos: usuarios avanzados para empresas"])},approach_connect_dots_description:e=>{const{normalize:a}=e;return a(["Entonces, ¿por qué es esencial un enfoque en el usuario avanzado para nuestro modelo centrado en la empresa? Porque se trata de establecer relaciones tempranas. Al atender a los usuarios avanzados ahora, estamos construyendo puentes hacia las empresas en las que influirán en el futuro. Es una jugada estratégica: una inversión a largo plazo para garantizar que nuestra oferta empresarial siga siendo una prioridad cuando estos usuarios avanzados asciendan a roles de toma de decisiones dentro de las organizaciones."])},approach_content1:e=>{const{normalize:a}=e;return a(["En el mundo de la IA en rápida evolución, las estrategias deben ser ágiles y con visión de futuro. Si bien nuestra oferta principal sigue centrada en las empresas, el panorama de la IA ha cambiado de manera que es necesario repensar nuestro enfoque para la adquisición de clientes. He aquí por qué presentar a los usuarios avanzados como el punto de entrada de nuestro embudo no solo es innovador, sino crucial para nuestro crecimiento sostenido en el sector empresarial."])},approach_content2:e=>{const{normalize:a}=e;return a(["En Jina AI, nuestra estrategia es ser proactivos en lugar de reactivos. La inclusión de usuarios avanzados como punto de entrada del embudo garantiza que no solo capturamos las tendencias actuales del mercado, sino que también estamos estratégicamente preparados para el crecimiento empresarial futuro. Nuestro compromiso con las empresas sigue siendo inquebrantable; sin embargo, nuestro enfoque para llegar a ellos es innovador, sólido y, sobre todo, con visión de futuro."])},approach_content4:e=>{const{normalize:a}=e;return a(['Todos quieren una mejor búsqueda. En Jina AI, facilitamos una mejor búsqueda al proporcionar la <span class="text-primary text-bold">Base de búsqueda</span>, que consta de incrustaciones, reclasificadores, lectores y operaciones de aviso. Estos componentes funcionan en conjunto para revolucionar la forma en que buscamos y entendemos los datos. Esto conduce a una mejor experiencia de búsqueda, confianza del usuario, un aumento directo de las ventas y la activación de un nuevo crecimiento comercial.'])},approach_miss_mark:e=>{const{normalize:a}=e;return a(["Por qué los MLOps tradicionales no dan en el blanco"])},approach_miss_mark_description:e=>{const{normalize:a}=e;return a(["Si bien la afluencia de usuarios avanzados es significativa, las herramientas tradicionales de MLOps están mal equipadas para satisfacer sus necesidades. Estas herramientas recuerdan el uso de un tractor para moverse por las calles de la ciudad: son pesadas y, a menudo, excesivas. Los desarrolladores de nueva generación exigen herramientas ágiles e intuitivas que complementen su rápido ritmo de desarrollo."])},approach_new_paradigm:e=>{const{normalize:a}=e;return a(["Tecnología basada en avisos: un nuevo paradigma"])},approach_new_paradigm_description:e=>{const{normalize:a}=e;return a([`2023 anunció un cambio significativo: el surgimiento de la tecnología basada en avisos. Al simplificar el proceso de desarrollo de IA, ha democratizado el acceso a las herramientas de IA. Ahora, aquellos que no tienen una amplia experiencia en programación, denominados "usuarios avanzados", pueden participar en el desarrollo de IA sin las pronunciadas curvas de aprendizaje asociadas con herramientas como Pytorch, Docker o Kubernetes.

Trazando un paralelo, esto es similar a la evolución de la computación personal. Inicialmente, solo los expertos en tecnología operaban computadoras. Pero con la llegada de las interfaces fáciles de usar, podría participar una audiencia más amplia. Hoy, con la tecnología basada en avisos, estamos presenciando una democratización similar en la IA.`])},awards:e=>{const{normalize:a}=e;return a(["Premios y reconocimientos"])},berlin:e=>{const{normalize:a}=e;return a(["Berlín, Alemania"])},berlin_address:e=>{const{normalize:a}=e;return a(["Prinzessinnenstraße 19-20, 10969 Berlín, Alemania"])},berlin_address2:e=>{const{normalize:a}=e;return a(["Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlín, Alemania"])},bj:e=>{const{normalize:a}=e;return a(["Beijing, China"])},bj_address:e=>{const{normalize:a}=e;return a(["Nivel 5, Edificio 6, No.48 Haidian West St. Beijing Haidian, China"])},brochure_info:e=>{const{normalize:a}=e;return a(["Su guía de nuestra empresa le espera"])},description:e=>{const{normalize:a}=e;return a(["El futuro comienza aquí."])},download_brochure1:e=>{const{normalize:a}=e;return a(["Descargar folleto"])},download_docarray_logo:e=>{const{normalize:a}=e;return a(["Descargue el logotipo de DocArray"])},download_docarray_logo_desc:e=>{const{normalize:a}=e;return a(["Acceda al logotipo de DocArray, un proyecto de código abierto iniciado por Jina AI y contribuido a la Fundación Linux en diciembre de 2022. Disponible en modos claro y oscuro, en formatos PNG y SVG."])},download_jina_logo:e=>{const{normalize:a}=e;return a(["Descargue el logotipo de Jina AI"])},download_jina_logo_desc:e=>{const{normalize:a}=e;return a(["Obtenga el logotipo de Jina AI en modo claro y oscuro, disponible en formatos PNG y SVG. Este logotipo es una marca registrada en la Oficina de Propiedad Intelectual de la Unión Europea (EUIPO)."])},download_logo:e=>{const{normalize:a}=e;return a(["Descargar logotipos"])},employees:e=>{const{normalize:a}=e;return a(["Los empleados hoy"])},empower_developers:e=>{const{normalize:a}=e;return a(["Desarrolladores empoderados"])},fastApiCaption:e=>{const{normalize:a}=e;return a(["Contribuyó con más de $ 20,000 desde 2021."])},founded:e=>{const{normalize:a}=e;return a(["Fundado"])},founded_in:e=>{const{normalize:a}=e;return a(["Fundado en"])},investors:e=>{const{normalize:a}=e;return a(["Nuestros inversores"])},linuxFoundationCaption:e=>{const{normalize:a}=e;return a(["Realiza un aporte anual de $10,000 a partir de 2022."])},many:e=>{const{normalize:a}=e;return a(["Muchos"])},mission:e=>{const{normalize:a}=e;return a(["Nuestra misión"])},mission_content1:e=>{const{normalize:a}=e;return a(["Nosotros Nuestras tecnologías clave, que incluyen el ajuste rápido, el servicio rápido, el ajuste de modelos y el servicio de modelos, encarnan nuestro compromiso de democratizar el acceso a la IA. A través de nuestra iniciativa de código abierto, nos esforzamos por fomentar la innovación, la colaboración y la transparencia, garantizando soluciones escalables, eficientes y sólidas. Jina AI es más que una simple empresa; es una comunidad dedicada a capacitar a las empresas para que enfrenten los desafíos dinámicos de la era digital y prosperen en sus dominios."])},mission_content2:e=>{const{normalize:a}=e;return a(["En el corazón de Jina AI se encuentra nuestra misión de ser el portal hacia la IA multimodal para una clientela diversa, desde usuarios avanzados y desarrolladores hasta empresas. Creemos profundamente en el poder del código abierto y estamos dedicados a crear herramientas avanzadas y accesibles para la comunidad de IA. Nuestras tecnologías clave, que incluyen el ajuste rápido, el servicio rápido, el ajuste integrado y el servicio integrado, encarnan nuestro compromiso de democratizar el acceso a la IA. A través de nuestra iniciativa de código abierto, nos esforzamos por fomentar la innovación, la colaboración y la transparencia, garantizando soluciones escalables, eficientes y sólidas. Jina AI es más que una simple empresa; es una comunidad dedicada a capacitar a las empresas para que enfrenten los desafíos dinámicos de la era digital y prosperen en sus dominios."])},mission_content3:e=>{const{normalize:a}=e;return a(["En Jina AI, nuestra misión es liderar el avance de la IA multimodal a través de tecnologías innovadoras de integración y basadas en avisos, centrándonos específicamente en áreas como el procesamiento del lenguaje natural, el análisis de imágenes y videos y la interacción de datos intermodales. Esta especialización nos permite ofrecer soluciones únicas que convierten datos complejos de múltiples fuentes en conocimientos prácticos y aplicaciones innovadoras."])},mit_report_title:e=>{const{normalize:a}=e;return a(["Multimodal: la nueva frontera de la IA"])},mit_techreview:e=>{const{normalize:a}=e;return a(["Revisión de tecnología del MIT"])},numfocusCaption:e=>{const{normalize:a}=e;return a(["Dona regularmente cada mes a partir de 2022."])},office:e=>{const{normalize:a}=e;return a(["Nuestras oficinas"])},otherProjectsCaption:e=>{const{normalize:a}=e;return a(["Donó más de $ 3,000 a través del patrocinio de Github."])},our_answer:e=>{const{normalize:a}=e;return a(["Absolutamente Yann. ¡Estamos en ello, construyendo puentes hacia un futuro de IA multimodal!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:a}=e;return a(["Proporcionó una donación única de $ 10,000 y patrocinó múltiples eventos de PyCon, incluidos los de Alemania, Italia, China y los EE. UU."])},sefo:{layer0:e=>{const{normalize:a}=e;return a(["Aplicaciones de usuario final"])},layer1:e=>{const{normalize:a}=e;return a(["RAG / orquestación"])},layer3:e=>{const{normalize:a}=e;return a(["GPU/móvil/borde/computación local"])}},segmentFaultCaption:e=>{const{normalize:a}=e;return a(["Contribuyó con una donación única de $ 6,000."])},stats_1:e=>{const{normalize:a}=e;return a(["Fundada en febrero de 2020, Jina AI se ha convertido rápidamente en pionera mundial en tecnología de IA multimodal. En un período impresionante de 20 meses, recaudamos con éxito $37,5 millones, lo que marca nuestra sólida posición en la industria de la IA. Nuestra tecnología innovadora, de código abierto en GitHub, ha permitido a más de 40 000 desarrolladores de todo el mundo crear e implementar aplicaciones multimodales sofisticadas sin problemas."])},stats_2:e=>{const{normalize:a}=e;return a(["En 2023, hemos logrado avances significativos en el avance de las herramientas de generación de IA basadas en tecnología multimodal. Esta innovación ha beneficiado a más de 250 000 usuarios en todo el mundo, atendiendo a una plétora de requisitos comerciales únicos. Desde facilitar el crecimiento empresarial y mejorar la eficiencia operativa hasta optimizar los costos, Jina AI se dedica a empoderar a las empresas para que sobresalgan en la era multimodal."])},stats_4:e=>{const{normalize:a}=e;return a(['Fundada en 2020 en Berlín, Jina AI es una empresa líder en inteligencia artificial de búsqueda. Proporcionamos la <span class="text-primary text-bold">Search Foundation</span>, el núcleo de GenAI y aplicaciones multimodales. Nuestra misión es ayudar a las empresas y desarrolladores a desbloquear datos multimodales para la creación de valor con una mejor búsqueda. Como empresa comercial de código abierto, nos gusta la innovación abierta.'])},stats_v1:e=>{const{normalize:a}=e;return a(["Buscar/cuenta"])},subtitle:e=>{const{normalize:a}=e;return a(["Revolucionando la creación de contenido a través de soluciones generadas por IA para desbloquear infinitas posibilidades. Dando forma al futuro del contenido generado por IA y mejorando la creatividad humana."])},sues_und_sauer:e=>{const{normalize:a}=e;return a(["Sué y Sauer"])},sues_und_sauer_tooltip:e=>{const{normalize:a}=e;return a(["Süß-Sauer, un sabor popular (aunque estereotipado) en la cocina chino-alemana, significa agridulce. Es una metáfora de los altibajos de la vida de una startup."])},sz:e=>{const{normalize:a}=e;return a(["Shenzhen, China"])},sz_address:e=>{const{normalize:a}=e;return a(["402, Piso 4, Edificio de Tecnología Fu'an, Shenzhen Nanshan, China"])},team:e=>{const{normalize:a}=e;return a(["Dentro del Portal de Jina AI"])},team_content1:e=>{const{normalize:a}=e;return a(["Desde diversos rincones del mundo, estamos construyendo el futuro de la IA. Nuestras distintas perspectivas enriquecen nuestro trabajo y generan innovaciones. Dentro de este portal, abrazamos nuestra individualidad y perseguimos apasionadamente nuestros sueños. Bienvenido al portal del futuro de la IA."])},team_join:e=>{const{normalize:a}=e;return a(["Únete a nosotros"])},team_size:e=>{const{normalize:a}=e;return a(["Estas fotografías incluyen a nuestros antiguos compañeros y pasantes; agradecemos a cada uno de ellos."])},technologies:e=>{const{normalize:a}=e;return a(["Tecnologías"])},title:e=>{const{normalize:a}=e;return a(["Acerca de Jina AI"])},title0:e=>{const{normalize:a}=e;return a(["El futuro"])},title1:e=>{const{normalize:a}=e;return a(["Empieza"])},title2:e=>{const{normalize:a}=e;return a(["Aquí"])},title3:e=>{const{normalize:a}=e;return a(["Comienza aquí"])},understand_our_strength:e=>{const{normalize:a}=e;return a(["Comprender nuestra fuerza"])},understand_our_view2:e=>{const{normalize:a}=e;return a(["Comprender la Fundación de Búsqueda"])},users:e=>{const{normalize:a}=e;return a(["Usuarios Registrados"])},value:e=>{const{normalize:a}=e;return a(["Nuestro valor"])},value_content1:e=>{const{normalize:a}=e;return a(["La apertura impulsa la innovación y fomenta la colaboración. No solo apoyamos esta idea, sino que la vivimos. Hemos abierto el código fuente de nuestros modelos y proyectos y compartimos nuestra experiencia con el mundo. Y vamos más allá: desde ser uno de los primeros donantes de FastAPI hasta respaldar activamente a la Linux Foundation y a la Python Software Foundation, estamos profundamente comprometidos con la retribución."])},vision:e=>{const{normalize:a}=e;return a(["Nuestra misión"])},vision_content1:e=>{const{normalize:a}=e;return a(["Inspirado por la idea de Yann LeCun de que '"])},vision_content3:e=>{const{normalize:a}=e;return a(['El futuro de la IA es <span class="text-primary text-bold">multimodal</span> y nosotros somos parte de él. Sabemos que las empresas enfrentan desafíos al aprovechar los datos multimodales. En respuesta, estamos comprometidos con la <span class="text-primary text-bold">Search Foundation</span> para ayudar a las empresas y desarrolladores a buscar mejor y utilizar datos multimodales para el crecimiento empresarial.'])},yannlecun_quote:e=>{const{normalize:a}=e;return a(["Un sistema de inteligencia artificial entrenado solo con palabras y oraciones nunca se aproximará a la comprensión humana."])}},api_general_faq:{answer1:e=>{const{normalize:a}=e;return a(["Sí, la misma clave API es válida para todos los productos básicos de búsqueda de Jina AI. Esto incluye las API de integración, reclasificación, lectura y ajuste, con tokens compartidos entre todos los servicios."])},answer12:e=>{const{normalize:a}=e;return a(["Nos adherimos a una estricta política de privacidad y no utilizamos datos ingresados ​​por el usuario para entrenar nuestros modelos."])},answer3:e=>{const{normalize:a}=e;return a(['Sí, el uso de tokens se puede monitorear en la pestaña "Comprar tokens" ingresando su clave API, lo que le permite ver el historial de uso y los tokens restantes.'])},answer4:e=>{const{normalize:a}=e;return a(["Si extravió una clave de recarga y desea recuperarla, comuníquese con el soporte técnico de jina.ai con su correo electrónico registrado para obtener ayuda."])},answer5:e=>{const{normalize:a}=e;return a(["No, nuestras claves API no tienen fecha de vencimiento. Sin embargo, si sospecha que su clave se ha visto comprometida y desea retirarla o transferir sus tokens a una nueva clave, comuníquese con nuestro equipo de soporte para obtener ayuda."])},answer6:e=>{const{normalize:a}=e;return a(['Esto se debe a que nuestra arquitectura sin servidor descarga ciertos modelos durante períodos de bajo uso. La solicitud inicial activa o "calienta" el modelo, lo que puede tardar unos segundos. Después de esta activación inicial, las solicitudes posteriores se procesan mucho más rápidamente.'])},question1:e=>{const{normalize:a}=e;return a(["¿Puedo usar la misma clave API para incrustar, reclasificar, leer y ajustar las API?"])},question12:e=>{const{normalize:a}=e;return a(["¿Se utilizan los datos de entrada del usuario para entrenar sus modelos?"])},question3:e=>{const{normalize:a}=e;return a(["¿Puedo monitorear el uso del token de mi clave API?"])},question4:e=>{const{normalize:a}=e;return a(["¿Qué debo hacer si olvido mi clave API?"])},question5:e=>{const{normalize:a}=e;return a(["¿Caducan las claves API?"])},question6:e=>{const{normalize:a}=e;return a(["¿Por qué la primera solicitud de algunos modelos es lenta?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con API"])}},autotune:{base_model:e=>{const{normalize:a}=e;return a(["Modelo base para ajuste fino"])},check_data:e=>{const{normalize:a}=e;return a(["Descargar datos sintéticos"])},check_model:e=>{const{normalize:a}=e;return a(["Descargar modelo ajustado"])},data_size:e=>{const{normalize:a}=e;return a(["Datos sintéticos generados"])},description:e=>{const{normalize:a}=e;return a(["Obtenga incorporaciones optimizadas para cualquier dominio que desee."])},description_long:e=>{const{normalize:a}=e;return a(["Simplemente díganos en qué dominio desea que sus incrustaciones destaquen y le entregaremos automáticamente un modelo de incrustación optimizado y listo para usar para ese dominio."])},does_it_work_tho:e=>{const{normalize:a}=e;return a(["¿Pero funciona?"])},does_it_work_tho_explain:e=>{const{normalize:a}=e;return a(["El ajuste automático tiene la promesa automática de ofrecer incrustaciones ajustadas para cualquier dominio que desee. pero de verdad funciona? Esta es una duda bastante razonable. Lo hemos probado en una variedad de dominios y modelos base para averiguarlo. Echa un vistazo a los resultados seleccionados con cereza y limón a continuación."])},domain_instruction:e=>{const{normalize:a}=e;return a(["Instrucción de dominio"])},embedding_provider:e=>{const{normalize:a}=e;return a(["Seleccione un modelo de incrustación base"])},eval_evaluation:e=>{const{normalize:a}=e;return a(["Validación"])},eval_map:e=>{const{normalize:a}=e;return a(["MAPA"])},eval_mrr:e=>{const{normalize:a}=e;return a(["MRR"])},eval_ndcg:e=>{const{normalize:a}=e;return a(["NDCG"])},eval_performance_before_after:e=>{const{normalize:a}=e;return a(["Rendimiento en el conjunto de validación sintética antes y después del ajuste"])},eval_syntheticDataSize:e=>{const{normalize:a}=e;return a(["Total"])},eval_test:e=>{const{normalize:a}=e;return a(["Datos reales para realizar pruebas."])},eval_training:e=>{const{normalize:a}=e;return a(["Capacitación"])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["La función se encuentra actualmente en versión beta y cuesta 1 millón de tokens por modelo ajustado. Puede usar su clave API existente de la API Embedding/Reranker si tiene suficientes tokens, o puede crear una nueva clave API, que incluye 1 millón de tokens gratuitos."])},answer10:e=>{const{normalize:a}=e;return a(["Actualmente no. Tenga en cuenta que esta función aún está en versión beta. Almacenar los modelos ajustados y los datos sintéticos públicamente en el centro de modelos de Hugging Face nos ayuda a nosotros y a la comunidad a evaluar la calidad de la capacitación. En el futuro, planeamos ofrecer una opción de almacenamiento privado."])},answer11:e=>{const{normalize:a}=e;return a(["Dado que todos los modelos ajustados se cargan en Hugging Face, puedes acceder a ellos a través de SentenceTransformers simplemente especificando el nombre del modelo."])},answer12:e=>{const{normalize:a}=e;return a(["Por favor revisa tu carpeta de spam. Si aún no puede encontrarlo, comuníquese con nuestro equipo de soporte utilizando la dirección de correo electrónico que proporcionó."])},answer2:e=>{const{normalize:a}=e;return a(["No es necesario proporcionar ningún dato de entrenamiento. Simplemente describa su dominio de destino (el dominio para el cual desea que se optimicen las incrustaciones ajustadas) en lenguaje natural, o use una URL como referencia, y nuestro sistema generará datos sintéticos para entrenar el modelo."])},answer3:e=>{const{normalize:a}=e;return a(["Unos 30 minutos."])},answer4:e=>{const{normalize:a}=e;return a(["Los modelos ajustados y los datos sintéticos se almacenan públicamente en el centro de modelos de Hugging Face."])},answer5:e=>{const{normalize:a}=e;return a(["El sistema utiliza la API Reader para recuperar el contenido de la URL. Luego analiza el contenido para resumir el tono y el dominio, que utiliza como pautas para generar datos sintéticos. Por lo tanto, la URL debe ser de acceso público y representativa del dominio de destino."])},answer6:e=>{const{normalize:a}=e;return a(["Sí, puede ajustar un modelo para un idioma distinto del inglés. El sistema detecta automáticamente el idioma de las instrucciones de su dominio y genera datos sintéticos en consecuencia. También recomendamos elegir el modelo base adecuado para el idioma de destino. Por ejemplo, si se dirige a un dominio alemán, debe seleccionar 'jina-embeddings-v2-base-de' como modelo base."])},answer7:e=>{const{normalize:a}=e;return a(["No, nuestra API de ajuste solo admite modelos Jina v2."])},answer8:e=>{const{normalize:a}=e;return a(["Al final del proceso de ajuste, el sistema evalúa el modelo utilizando un conjunto de pruebas disponible e informa las métricas de rendimiento. Recibirá un correo electrónico detallando el rendimiento antes y después de este equipo de prueba. También le recomendamos que evalúe el modelo en su propio equipo de prueba para garantizar su calidad."])},answer9:e=>{const{normalize:a}=e;return a(["El sistema genera datos sintéticos integrando la instrucción del dominio objetivo que usted proporciona con el razonamiento de los agentes de LLM. Produce tripletes negativos duros, que son esenciales para entrenar modelos de incrustación de alta calidad. Para obtener más detalles, consulte nuestro próximo artículo de investigación sobre Arxiv."])},question1:e=>{const{normalize:a}=e;return a(["¿Cuánto cuesta la API de ajuste fino?"])},question10:e=>{const{normalize:a}=e;return a(["¿Puedo mantener la privacidad de mis modelos ajustados y mis datos sintéticos?"])},question11:e=>{const{normalize:a}=e;return a(["¿Cómo puedo utilizar el modelo ajustado?"])},question12:e=>{const{normalize:a}=e;return a(["Nunca recibí el correo electrónico con los resultados de la evaluación. ¿Qué tengo que hacer?"])},question2:e=>{const{normalize:a}=e;return a(["¿Qué necesito ingresar? ¿Necesito proporcionar datos de entrenamiento?"])},question3:e=>{const{normalize:a}=e;return a(["¿Cuánto tiempo lleva perfeccionar un modelo?"])},question4:e=>{const{normalize:a}=e;return a(["¿Dónde se almacenan los modelos ajustados?"])},question5:e=>{const{normalize:a}=e;return a(["Si proporciono una URL de referencia, ¿cómo la usa el sistema?"])},question6:e=>{const{normalize:a}=e;return a(["¿Puedo ajustar un modelo para un idioma específico?"])},question7:e=>{const{normalize:a}=e;return a(["¿Puedo ajustar incrustaciones que no sean de Jina, por ejemplo, bge-M3?"])},question8:e=>{const{normalize:a}=e;return a(["¿Cómo se garantiza la calidad de los modelos ajustados?"])},question9:e=>{const{normalize:a}=e;return a(["¿Cómo se generan datos sintéticos?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con el ajuste automático"])}},find_on_hf:e=>{const{normalize:a}=e;return a(["Lista de modelos ajustados"])},temporarily_unavailable:e=>{const{normalize:a}=e;return a(["Temporalmente no disponible. Estamos actualizando nuestro sistema de ajuste automático para brindarle un mejor servicio. Por favor, vuelva más tarde."])},test_on:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Probado en ",n(r("_dataSize"))," muestras aleatorias de ",n(r("_dataName"))])},test_performance_before_after:e=>{const{normalize:a}=e;return a(["Rendimiento en el conjunto de pruebas retenido antes y después del ajuste fino"])},title:e=>{const{normalize:a}=e;return a(["API de ajuste automático"])},total_improve:e=>{const{normalize:a}=e;return a(["Promedio mejora"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},what_is:e=>{const{normalize:a}=e;return a(["¿Qué es el ajuste fino automático?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a(["El ajuste fino le permite tomar un modelo previamente entrenado y adaptarlo a una tarea o dominio específico entrenándolo en un nuevo conjunto de datos. En la práctica, encontrar datos de entrenamiento efectivos no es sencillo para muchos usuarios. La formación eficaz requiere algo más que simplemente incluir archivos PDF y HTML sin formato en el modelo; y es difícil hacerlo bien. El ajuste automático resuelve este problema al generar automáticamente datos de capacitación efectivos utilizando una canalización avanzada de agentes LLM; y ajustar el modelo dentro de un flujo de trabajo de ML. Puede pensarlo como una combinación de generación de datos sintéticos y AutoML, por lo que todo lo que necesita hacer es describir su dominio de destino en lenguaje natural y dejar que nuestro sistema haga el resto."])}},best_banner:{description:e=>{const{normalize:a}=e;return a(["¡Blog a banner, sin las indicaciones!"])},example_description:e=>{const{normalize:a}=e;return a(['Alicia empezaba a cansarse mucho de estar sentada junto a su hermana en la orilla y de no tener nada que hacer: una o dos veces había echado un vistazo al libro que su hermana estaba leyendo, pero no tenía dibujos ni conversaciones, "y de qué sirve un libro", pensó Alicia, "sin dibujos ni conversaciones". Así que estaba considerando en su propia mente (lo mejor que podía, porque el día caluroso la hacía sentir muy soñolienta y estúpida), si el placer de hacer una cadena de margaritas valdría la pena de levantarse y recoger las margaritas, cuando de repente un Conejo Blanco con ojos rosados ​​corrió cerca de ella.'])},example_title:e=>{const{normalize:a}=e;return a(["Las aventuras de Alicia en el país de las maravillas - Capítulo 1"])}},beta:e=>{const{normalize:a}=e;return a(["Beta"])},billing_general_faq:{answer10:e=>{const{normalize:a}=e;return a(['Ofrecemos una prueba gratuita de bienvenida a nuevos usuarios, que incluye un millón de tokens para usar con cualquiera de nuestros modelos, facilitada por una clave API generada automáticamente. Una vez que se alcanza el límite de tokens gratuitos, los usuarios pueden comprar fácilmente tokens adicionales para sus claves API a través de la pestaña "Comprar tokens".'])},answer13:e=>{const{normalize:a}=e;return a(["No, los tokens no se deducen por solicitudes fallidas."])},answer14:e=>{const{normalize:a}=e;return a(["Los pagos se procesan a través de Stripe y admiten una variedad de métodos de pago que incluyen tarjetas de crédito, Google Pay y PayPal para su comodidad."])},answer15:e=>{const{normalize:a}=e;return a(["Sí, se emitirá una factura a la dirección de correo electrónico asociada a su cuenta de Stripe tras la compra de tokens."])},answer9:e=>{const{normalize:a}=e;return a(["Nuestro modelo de precios se basa en la cantidad total de tokens procesados, lo que permite a los usuarios la flexibilidad de asignar estos tokens en cualquier cantidad de oraciones, ofreciendo una solución rentable para diversos requisitos de análisis de texto."])},question10:e=>{const{normalize:a}=e;return a(["¿Hay una prueba gratuita disponible para nuevos usuarios?"])},question13:e=>{const{normalize:a}=e;return a(["¿Se cobran tokens por solicitudes fallidas?"])},question14:e=>{const{normalize:a}=e;return a(["¿Qué métodos de pago se aceptan?"])},question15:e=>{const{normalize:a}=e;return a(["¿Está disponible la facturación para compras de tokens?"])},question9:e=>{const{normalize:a}=e;return a(["¿La facturación se basa en el número de sentencias o solicitudes?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con la facturación"])}},blog_tags:{all:e=>{const{normalize:a}=e;return a(["Todo"])},events:e=>{const{normalize:a}=e;return a(["Evento"])},featured:e=>{const{normalize:a}=e;return a(["Presentado"])},insights:e=>{const{normalize:a}=e;return a(["Opinión"])},"knowledge-base":e=>{const{normalize:a}=e;return a(["Base de conocimientos"])},latest:e=>{const{normalize:a}=e;return a(["El último"])},press:e=>{const{normalize:a}=e;return a(["presione soltar"])},releases:e=>{const{normalize:a}=e;return a(["Actualización de software"])},"tech-blog":e=>{const{normalize:a}=e;return a(["Blog de tecnología"])}},cclicence:{api_free_trial:e=>{const{normalize:a}=e;return a(["Clave API gratuita"])},api_paid:e=>{const{normalize:a}=e;return a(["Clave API paga"])},api_paid_or_free:e=>{const{normalize:a}=e;return a(["¿Estás utilizando una clave API paga o una clave de prueba gratuita?"])},are_you:e=>{const{normalize:a}=e;return a(["Eres:"])},commercial_contact_sales:e=>{const{normalize:a}=e;return a(["Esto es comercial. Contacte con nuestro equipo comercial."])},contact_sales_for_licensing:e=>{const{normalize:a}=e;return a(["Contacte con nuestro equipo de ventas para obtener licencias."])},csp_user:e=>{const{normalize:a}=e;return a(["¿Está utilizando nuestras imágenes de modelos oficiales en AWS y Azure?"])},educational_teaching:e=>{const{normalize:a}=e;return a(["¿Una institución educativa lo utiliza para enseñar?"])},for_profit_internal_use:e=>{const{normalize:a}=e;return a(["¿Una empresa con fines de lucro que lo utiliza internamente?"])},free_use:e=>{const{normalize:a}=e;return a(["Puedes utilizar los modelos libremente."])},government_public_services:e=>{const{normalize:a}=e;return a(["¿Una entidad gubernamental que lo utiliza para servicios públicos?"])},is_use_commercial:e=>{const{normalize:a}=e;return a(["¿Su uso es comercial?"])},may_be_commercial_contact:e=>{const{normalize:a}=e;return a(["Esto puede ser comercial. Póngase en contacto con nosotros para obtener más información."])},no:e=>{const{normalize:a}=e;return a(["No"])},no1:e=>{const{normalize:a}=e;return a(["No"])},no2:e=>{const{normalize:a}=e;return a(["No"])},no3:e=>{const{normalize:a}=e;return a(["No"])},no_restrictions:e=>{const{normalize:a}=e;return a(["Sin restricciones. Utilícelo según su contrato actual."])},no_restrictions_apply:e=>{const{normalize:a}=e;return a(["No se aplican restricciones."])},non_commercial_free_use:e=>{const{normalize:a}=e;return a(["Esto no es para uso comercial. Puedes usar los modelos libremente."])},non_profit_ngo_mission:e=>{const{normalize:a}=e;return a(["¿Una organización sin fines de lucro u ONG lo utiliza para su misión?"])},not_sure:e=>{const{normalize:a}=e;return a(["No estoy seguro"])},personal_hobby_projects:e=>{const{normalize:a}=e;return a(["¿Lo estás usando para proyectos personales o de hobby?"])},product_service_sale:e=>{const{normalize:a}=e;return a(["¿Lo estás utilizando en un producto o servicio que vendes?"])},title:e=>{const{normalize:a}=e;return a(["Autocomprobación de licencia CC BY-NC"])},trial_key_restrictions:e=>{const{normalize:a}=e;return a(["La clave de prueba gratuita solo se puede utilizar para fines no comerciales. Adquiera un paquete pago para uso comercial."])},typically_non_commercial_check:e=>{const{normalize:a}=e;return a(["Por lo general, esto no es comercial, pero consulte con nosotros si no está seguro."])},typically_non_commercial_free_use:e=>{const{normalize:a}=e;return a(["Por lo general, no se trata de un proyecto comercial. Puedes utilizar los modelos libremente."])},using_api_or_cloud:e=>{const{normalize:a}=e;return a(["¿Está utilizando nuestra API oficial o imágenes oficiales en Azure o AWS?"])},using_cc_by_nc_models:e=>{const{normalize:a}=e;return a(["¿Estas utilizando estos modelos?"])},yes:e=>{const{normalize:a}=e;return a(["Sí"])},yes1:e=>{const{normalize:a}=e;return a(["Sí"])},yes2:e=>{const{normalize:a}=e;return a(["Sí"])},yes3:e=>{const{normalize:a}=e;return a(["Sí"])}},clip_as_service:{description:e=>{const{normalize:a}=e;return a(["Incruste imágenes y oraciones en vectores de longitud fija con CLIP"])}},cloud:{description:e=>{const{normalize:a}=e;return a(["Plataforma de alojamiento en la nube para aplicaciones de IA multimodal"])}},contact_us_page:{agreement:e=>{const{normalize:a}=e;return a(["Al enviar, confirma que está de acuerdo con el procesamiento de sus datos personales por parte de Jina AI como se describe en el"])},anything_else:e=>{const{normalize:a}=e;return a(["Cuéntanos más sobre tu idea"])},cc_by_nc:e=>{const{normalize:a}=e;return a(["Solicitar uso comercial de modelos CC BY-NC"])},cc_by_nc_description:e=>{const{normalize:a}=e;return a(["Nuestros últimos modelos suelen tener licencia CC BY-NC. Para uso comercial, acceda a ellos a través de nuestra API, Azure Marketplace o AWS SageMaker. Marque esta casilla para uso local fuera de estos canales."])},company:e=>{const{normalize:a}=e;return a(["Organización"])},company_size:e=>{const{normalize:a}=e;return a(["Tamaño de la organización"])},company_website:e=>{const{normalize:a}=e;return a(["Sitio web de la organización"])},company_website_placeholder:e=>{const{normalize:a}=e;return a(["URL de la página de inicio de su empresa o del perfil de LinkedIn"])},country:e=>{const{normalize:a}=e;return a(["País"])},department:e=>{const{normalize:a}=e;return a(["Departamento"])},description:e=>{const{normalize:a}=e;return a(["Haga crecer su negocio con Jina AI."])},faq:e=>{const{normalize:a}=e;return a(["Preguntas más frecuentes"])},field_required:e=>{const{normalize:a}=e;return a(["Se requiere campo"])},get_api_key:e=>{const{normalize:a}=e;return a(["¿Cómo obtener mi clave API?"])},impact_snapshots:e=>{const{normalize:a}=e;return a(["Instantáneas de impacto"])},invalid_date_format:e=>{const{normalize:a}=e;return a(["Formato de fecha no válido. Utilice el formato DD-MM-AAAA."])},invalid_email:e=>{const{normalize:a}=e;return a(["el correo electrónico es invalido"])},invalid_number:e=>{const{normalize:a}=e;return a(["Número invalido. Por favor ingrese de nuevo"])},invalid_url:e=>{const{normalize:a}=e;return a(["La URL no es válida."])},name:e=>{const{normalize:a}=e;return a(["Nombre"])},nc_check:e=>{const{normalize:a}=e;return a(["¿Necesito una licencia comercial?"])},other_questions:e=>{const{normalize:a}=e;return a(["Otras preguntas"])},preferred_models:e=>{const{normalize:a}=e;return a(["¿En qué modelos estás interesado?"])},preferred_products:e=>{const{normalize:a}=e;return a(["¿En qué productos estás interesado?"])},priority:e=>{const{normalize:a}=e;return a(["Soporte prioritario para usuarios pagos"])},private_statement:e=>{const{normalize:a}=e;return a(["Declaracion de privacidad"])},rate_limit:e=>{const{normalize:a}=e;return a(["¿Cuál es el límite de velocidad?"])},role:e=>{const{normalize:a}=e;return a(["Puesto de trabajo"])},self_check:e=>{const{normalize:a}=e;return a(["Autocomprobación"])},shortcut:e=>{const{normalize:a}=e;return a(["Atajo"])},submit:e=>{const{normalize:a}=e;return a(["Entregar"])},submit_failed:e=>{const{normalize:a}=e;return a(["Envío fallido. Por favor, inténtelo de nuevo más tarde."])},submit_success:e=>{const{normalize:a}=e;return a(["Gracias por tu envío. Nos pondremos en contacto con usted en breve."])},subtitle:e=>{const{normalize:a}=e;return a(["Jina AI, líder en IA multimodal, se destaca en el ajuste de modelos, el servicio de modelos, el ajuste de avisos y el servicio de avisos. Al aprovechar las tecnologías nativas de la nube como Kubernetes y las arquitecturas sin servidor, ofrecemos soluciones sólidas, escalables y listas para producción. Con experiencia en modelos de lenguaje grande, texto, imagen, video, comprensión de audio, búsqueda neuronal y arte generativo, brindamos estrategias innovadoras y preparadas para el futuro para elevar su negocio."])},subtitle1:e=>{const{normalize:a}=e;return a(["Jina AI, líder en IA multimodal, se destaca en el ajuste de integración, el servicio de integración, el ajuste rápido y el servicio rápido. Aprovechando tecnologías nativas de la nube como Kubernetes y arquitecturas sin servidor, ofrecemos soluciones sólidas, escalables y listas para producción. Con experiencia en modelos de lenguaje grandes, texto, imágenes, video, comprensión de audio, búsqueda neuronal e inteligencia artificial generativa, brindamos estrategias innovadoras y preparadas para el futuro para elevar su negocio."])},subtitle2:e=>{const{normalize:a}=e;return a(["Explore Jina AI, la vanguardia de la IA multimodal. Nos destacamos en la integración y rapidez de tecnologías, utilizando soluciones nativas de la nube como Kubernetes para sistemas robustos y escalables. Especializados en grandes modelos de lenguaje y procesamiento de medios, ofrecemos estrategias comerciales innovadoras y preparadas para el futuro con nuestra experiencia avanzada en IA."])},title:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},trusted_by:e=>{const{normalize:a}=e;return a(["Confiado por"])},turn_on_volume:e=>{const{normalize:a}=e;return a(["Sube el volumen"])},work_email:e=>{const{normalize:a}=e;return a(["Correo electrónico del trabajo"])}},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},copy_to_clipboard_success:e=>{const{normalize:a}=e;return a(["Copiado al portapapeles"])},dalle_flow:{description:e=>{const{normalize:a}=e;return a(["Un flujo de trabajo human-in-the-Loop para crear imágenes HD a partir de texto"])}},"dev-gpt":{description:e=>{const{normalize:a}=e;return a(["Tu equipo de desarrollo virtual"])}},disco_art:{description:e=>{const{normalize:a}=e;return a(["Cree atractivas obras de arte de Disco Diffusion en una línea de código"])}},doc_array:{description:e=>{const{normalize:a}=e;return a(["La estructura de datos para datos multimodales"])}},download:e=>{const{normalize:a}=e;return a(["Descargar Certificación SOC 2 Tipo 1"])},embedding:{"11B tokens":e=>{const{normalize:a}=e;return a(["11 mil millones"])},"11B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Similar a leer todos los artículos en inglés en Wikipedia."])},"11B tokens_targetUser":e=>{const{normalize:a}=e;return a(["Despliegue de producción"])},"1B tokens":e=>{const{normalize:a}=e;return a(["1 mil millones"])},"1B tokens_intuition1":e=>{const{normalize:a}=e;return a(['Casi lo mismo que leer las obras completas de Shakespeare y toda la serie "Harry Potter".'])},"1B tokens_targetUser":e=>{const{normalize:a}=e;return a(["Desarrollo de prototipos"])},"1M tokens":e=>{const{normalize:a}=e;return a(["1 millón"])},"1M tokens_intuition1":e=>{const{normalize:a}=e;return a(['Equivale a leer el texto completo de "El Hobbit" y "El gran Gatsby".'])},"1M tokens_targetUser":e=>{const{normalize:a}=e;return a(["experimento de juguete"])},"1M_free":e=>{const{normalize:a}=e;return a(["1 millón de fichas gratis"])},"1M_free_description":e=>{const{normalize:a}=e;return a(["Disfrute de su nueva clave API con tokens gratuitos, sin necesidad de tarjeta de crédito."])},"2_5B tokens":e=>{const{normalize:a}=e;return a(["2.500 millones de fichas"])},"2_5B tokens_intuition1":e=>{const{normalize:a}=e;return a([`Comparable a transcribir cada palabra pronunciada en la trilogía de la película "El Señor de los Anillos" 1.000 veces.
`])},"3p_integration":e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Con <b>",n(r("_numPartners")),"</b> servicios de terceros"])},"3p_integration_desc":e=>{const{normalize:a}=e;return a(["Integre nuestra base de búsqueda con sus servicios existentes. Nuestros socios han creado conectores para nuestra API, lo que facilita el uso de nuestros modelos en sus aplicaciones."])},"500M tokens":e=>{const{normalize:a}=e;return a(["500 millones de fichas"])},"500M tokens_intuition1":e=>{const{normalize:a}=e;return a(['Similar a ver todos los episodios de "Los Simpson" desde la temporada 1 hasta la temporada 30.'])},"59B tokens":e=>{const{normalize:a}=e;return a(["59 mil millones de fichas"])},"59B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Igual a todos los tweets publicados en todo el mundo durante un período de dos días."])},"5_5B tokens":e=>{const{normalize:a}=e;return a(["5.500 millones de fichas"])},"5_5B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Equivale a leer el texto completo de la Encyclopaedia Britannica."])},Free1M:e=>{const{normalize:a}=e;return a(["1 millón de fichas"])},add_pair:e=>{const{normalize:a}=e;return a(["Nuevo"])},add_time_explain:e=>{const{normalize:a}=e;return a(["La fecha en que se agregó este modelo a la Fundación de búsqueda."])},api_integration_short:e=>{const{normalize:a}=e;return a(["Nuestra API de incrustación está integrada de forma nativa con varias bases de datos, almacenes de vectores, marcos RAG y LLMOps de renombre."])},api_integrations:e=>{const{normalize:a}=e;return a(["Integraciones API"])},api_key_update_message:e=>{const{normalize:a}=e;return a(["Al reemplazar su antigua clave API, la nueva clave aparecerá en la interfaz de usuario cada vez que visite jina.ai. Las futuras recargas se aplicarán a esta nueva clave. Su antigua clave sigue siendo válida, por lo que, si planea volver a usarla, guárdela de forma segura."])},api_key_update_title:e=>{const{normalize:a}=e;return a(["Reemplazo de clave API"])},auto_recharge:e=>{const{normalize:a}=e;return a(["Recarga automática cuando las fichas están bajas"])},auto_recharge_confirm_message:e=>{const{normalize:a}=e;return a(["¿Está seguro de que desea desactivar la recarga automática? Esto evitará las recargas automáticas cuando el saldo de su token sea bajo."])},auto_recharge_confirm_title:e=>{const{normalize:a}=e;return a(["Desactivar recarga automática"])},auto_recharge_description:e=>{const{normalize:a}=e;return a(["Recomendado para servicio ininterrumpido en producción. Cuando el saldo de su token esté por debajo del umbral que estableció, recargaremos automáticamente su tarjeta de crédito por el mismo monto que su última recarga. Si compraste varios paquetes en la última recarga, recargaremos solo un paquete."])},auto_recharge_enable:e=>{const{normalize:a}=e;return a(["Habilitaste la recarga automática en tokens bajos"])},auto_recharge_enable_message:e=>{const{normalize:a}=e;return a(["Para habilitar la recarga automática, compre un paquete con la recarga automática configurada como verdadera."])},auto_recharge_enable_title:e=>{const{normalize:a}=e;return a(["Habilitar recarga automática"])},auto_request:e=>{const{normalize:a}=e;return a(["Vista previa automática"])},auto_request_tooltip:e=>{const{normalize:a}=e;return a(['Obtenga una vista previa automática de la respuesta de la API al cambiar el modelo, utilizando cientos de tokens de su clave API. Desactive el envío manual de una solicitud haciendo clic en "Obtener respuesta".'])},autostart:e=>{const{normalize:a}=e;return a(["La inserción comenzará automáticamente después de un breve retraso."])},base64_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones se devuelven como una cadena codificada en base64. Más eficiente para la transmisión."])},batch_job:e=>{const{normalize:a}=e;return a(["Trabajo por lotes"])},batch_upload_hint:e=>{const{normalize:a}=e;return a(["Usaremos la clave API y el modelo siguiente para procesar los documentos."])},"bge-base-en-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo inglés robusto que equilibra rendimiento y eficiencia para un uso versátil."])},"bge-base-en_description":e=>{const{normalize:a}=e;return a(["Un modelo inglés equilibrado diseñado para un rendimiento sólido y fiable."])},"bge-base-zh-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo chino completo que equilibra capacidad y eficiencia."])},"bge-base-zh_description":e=>{const{normalize:a}=e;return a(["Un modelo chino versátil que combina eficiencia y rendimiento robusto."])},"bge-large-en-v1_5_description":e=>{const{normalize:a}=e;return a(["Un potente modelo inglés que ofrece incrustaciones de primer nivel con una calidad excepcional."])},"bge-large-en_description":e=>{const{normalize:a}=e;return a(["Un modelo inglés de alto rendimiento diseñado para incrustaciones de primera calidad."])},"bge-large-zh-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo chino de alta capacidad que ofrece incrustaciones superiores y detalladas."])},"bge-large-zh_description":e=>{const{normalize:a}=e;return a(["Un modelo chino de alto rendimiento optimizado para incrustaciones de primer nivel."])},"bge-m3_description":e=>{const{normalize:a}=e;return a(["Un modelo multilingüe versátil que ofrece amplias capacidades e incorporaciones de alta calidad."])},"bge-small-en-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo inglés simplificado que ofrece incrustaciones eficientes y de alta calidad."])},"bge-small-en_description":e=>{const{normalize:a}=e;return a(["Un modelo inglés eficiente para incrustaciones optimizadas y precisas."])},"bge-small-zh-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo chino compacto que proporciona incrustaciones ágiles y precisas."])},"bge-small-zh_description":e=>{const{normalize:a}=e;return a(["Un modelo chino ágil para incrustaciones eficientes y precisas."])},binary_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones están empaquetadas como int8. Mucho más eficiente para almacenamiento, búsqueda y transmisión."])},bulk:e=>{const{normalize:a}=e;return a(["Incrustación por lotes"])},bulk_embedding_failed:e=>{const{normalize:a}=e;return a(["No se pudo crear el trabajo de incrustación por lotes"])},buy_more_quota:e=>{const{normalize:a}=e;return a(["Recarga esta clave API con más tokens"])},buy_poster:e=>{const{normalize:a}=e;return a(["Compre una copia impresa"])},cancel_button:e=>{const{normalize:a}=e;return a(["Cancelar"])},click_upload_btn_above:e=>{const{normalize:a}=e;return a(["Haga clic en el botón de carga de arriba para comenzar."])},code:e=>{const{normalize:a}=e;return a(["código"])},colbert_dimensions_explain:e=>{const{normalize:a}=e;return a(["El tamaño de la dimensión de la incrustación por token."])},compatible:e=>{const{normalize:a}=e;return a(["Modo compatible"])},compatible_explain:e=>{const{normalize:a}=e;return a(["Sigue el mismo formato de solicitud que nuestros modelos de incrustación de texto. Esto le permite cambiar entre modelos sin cambiar la solicitud. Tenga en cuenta que la entrada de imágenes no es compatible con este modo."])},cosine_similarity:e=>{const{normalize:a}=e;return a(["Similitud del coseno"])},debugging:e=>{const{normalize:a}=e;return a(["Prueba"])},delete_pair:e=>{const{normalize:a}=e;return a(["Borrar"])},description:e=>{const{normalize:a,linked:n,type:r}=e;return a([n("landing_page.embedding_desc1",void 0,r)])},dimensions:e=>{const{normalize:a}=e;return a(["Dimensiones de salida"])},dimensions_error:e=>{const{normalize:a}=e;return a(["El tamaño de la dimensión debe estar entre 1 y 1024."])},dimensions_explain:e=>{const{normalize:a}=e;return a(["Las dimensiones más pequeñas son más fáciles de almacenar y recuperar, con un impacto mínimo en el rendimiento gracias a MRL."])},dimensions_warning:e=>{const{normalize:a}=e;return a(["Recomendamos mantener el tamaño de la dimensión por encima de 32 para un desempeño efectivo de la tarea."])},document:e=>{const{normalize:a}=e;return a(["Documento"])},download:e=>{const{normalize:a}=e;return a(["Descargar"])},edit_text1_text:e=>{const{normalize:a}=e;return a(["Editar texto de la izquierda"])},edit_text2_text:e=>{const{normalize:a}=e;return a(["Editar texto correcto"])},embedding_done:e=>{const{normalize:a,interpolate:n,named:r}=e;return a([n(r("_Count"))," oraciones insertadas correctamente."])},embedding_none_description:e=>{const{normalize:a}=e;return a(["No utilice ningún modelo de incrustación."])},example_inputs:e=>{const{normalize:a}=e;return a(["Entradas de ejemplo"])},faq:e=>{const{normalize:a,linked:n,type:r}=e;return a([n("contact_us_page.faq",void 0,r)])},faqs_v2:{answer0:e=>{const{normalize:a}=e;return a(["Para obtener información detallada sobre nuestros procesos de capacitación, fuentes de datos y evaluaciones, consulte nuestro informe técnico disponible en arXiv."])},answer1:e=>{const{normalize:a}=e;return a(["Cada usuario puede realizar hasta 100 solicitudes por segundo, lo que equivale a 204.800 frases de entrada por segundo."])},answer17:e=>{const{normalize:a}=e;return a(["Actualmente estamos desarrollando incrustaciones multimodales que procesarán conjuntamente texto, imágenes y audio. ¡Las actualizaciones se anunciarán pronto!"])},answer18:e=>{const{normalize:a}=e;return a(["Si tiene consultas sobre cómo ajustar nuestros modelos con datos específicos, contáctenos para analizar sus requisitos. Estamos abiertos a explorar cómo nuestros modelos se pueden adaptar para satisfacer sus necesidades."])},answer19:e=>{const{normalize:a}=e;return a(["Sí, nuestros servicios están disponibles en el mercado de AWS y estamos en el proceso de expandirnos a los mercados de Azure y GCP. Si tiene requisitos particulares, contáctenos en ventas AT jina.ai."])},answer3:e=>{const{normalize:a}=e;return a(["Nuestros modelos admiten inglés, alemán, español, chino y varios lenguajes de programación. Para obtener más detalles, consulte nuestra publicación sobre modelos bilingües."])},answer4:e=>{const{normalize:a}=e;return a(['Nuestros modelos permiten una longitud de entrada de hasta 8192 tokens, que es significativamente mayor que la mayoría de los otros modelos. Un token puede variar desde un solo carácter, como "a", hasta una palabra completa, como "manzana". La cantidad total de caracteres que se pueden ingresar depende de la longitud y complejidad de las palabras utilizadas. Esta capacidad de entrada extendida permite que nuestros modelos jina-embeddings-v2 realicen análisis de texto más completos y logren una mayor precisión en la comprensión del contexto, especialmente para datos textuales extensos.'])},answer5:e=>{const{normalize:a}=e;return a(["Una sola llamada API puede procesar hasta 2048 oraciones o textos, lo que facilita un análisis de texto extenso en una sola solicitud."])},answer6:e=>{const{normalize:a}=e;return a(["Puede utilizar <code>url</code> o <code>bytes</code> en el campo <code>input</code> de la solicitud de API. Para <code>url</code>, proporcione la URL de la imagen que desea procesar. Para <code>bytes</code>, codifique la imagen en formato base64 e inclúyala en la solicitud. El modelo devolverá las incrustaciones de la imagen en la respuesta."])},answer7:e=>{const{normalize:a}=e;return a(["Según la tabla de clasificación MTEB, nuestro modelo Base compite estrechamente con el text-embedding-ada-002 de OpenAI, mostrando un rendimiento comparable en promedio. Además, nuestro modelo Base sobresale en varias tareas, incluida la clasificación, clasificación por pares, reclasificación y resumen, superando al modelo de OpenAI."])},answer8:e=>{const{normalize:a}=e;return a(["La transición se simplifica, ya que nuestro punto final API, https://api.jina.ai/v1/embeddings, coincide con los esquemas JSON de entrada y salida del modelo text-embeddings-ada-002 de OpenAI. Esta compatibilidad garantiza que los usuarios puedan reemplazar fácilmente el modelo OpenAI por el nuestro cuando utilizan el punto final de OpenAI."])},answer9:e=>{const{normalize:a}=e;return a([`Los tokens se calculan en función de la longitud del texto y el tamaño de la imagen. Para el texto de la solicitud, los tokens se cuentan de la forma estándar. Para la imagen en la solicitud, se llevan a cabo los siguientes pasos:
1. Tamaño del mosaico: cada imagen se divide en mosaicos de tamaño 224x224 píxeles.
	2. Cobertura: se calcula la cantidad de mosaicos necesarios para cubrir completamente la imagen de entrada. Incluso si las dimensiones de la imagen no son perfectamente divisibles por 224, contaremos mosaicos parciales como mosaicos completos.
	3. Total de mosaicos: el número total de mosaicos que cubren la imagen determina el costo. Por ejemplo, si una imagen tiene 500x500 píxeles, estaría cubierta por mosaicos de 3x3, lo que daría como resultado 9 mosaicos.
	4. Cálculo de costos: Cada mosaico contribuye al costo final de procesamiento de la imagen. El coste por ficha es de 1000 fichas.

Ejemplo:
Para una imagen con dimensiones de 500x500 píxeles:

	• La imagen se divide en mosaicos de 224x224 píxeles.
	• El número total de mosaicos requeridos es 3 (horizontal) x 3 (vertical) = 9 mosaicos.
	• El costo será 9*1000 = 9000 tokens`])},question0:e=>{const{normalize:a}=e;return a(["¿Cómo se entrenaron los modelos jina-embeddings-v2?"])},question1:e=>{const{normalize:a}=e;return a(["¿Cuántas solicitudes de API puedo realizar por segundo?"])},question17:e=>{const{normalize:a}=e;return a(["¿Proporcionan modelos para incrustar imágenes o audio?"])},question18:e=>{const{normalize:a}=e;return a(["¿Se pueden ajustar los modelos de Jina Embedding con datos privados o de la empresa?"])},question19:e=>{const{normalize:a}=e;return a(["¿Se pueden alojar sus puntos finales de forma privada en AWS, Azure o GCP?"])},question3:e=>{const{normalize:a}=e;return a(["¿Qué idiomas admiten sus modelos?"])},question4:e=>{const{normalize:a}=e;return a(["¿Cuál es la longitud máxima para la entrada de una sola oración?"])},question5:e=>{const{normalize:a}=e;return a(["¿Cuál es el número máximo de frases que puedo incluir en una sola solicitud?"])},question6:e=>{const{normalize:a}=e;return a(["¿Cómo envío imágenes al modelo jina-clip-v1?"])},question7:e=>{const{normalize:a}=e;return a(["¿Cómo se comparan los modelos de Jina Embeddings con el modelo text-embedding-ada-002 de OpenAI?"])},question8:e=>{const{normalize:a}=e;return a(["¿Qué tan fluida es la transición desde text-embedding-ada-002 de OpenAI a su solución?"])},question9:e=>{const{normalize:a}=e;return a(["¿Cómo se calculan los tokens cuando se usa jina-clip-v1?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con incrustaciones"])}},feature_8k1:e=>{const{normalize:a}=e;return a(["8192 longitud del token"])},feature_8k_description1:e=>{const{normalize:a}=e;return a(["Ser pionero en el primer modelo de integración de código abierto con una longitud de 8192 tokens, que permite la representación de un capítulo completo en un solo vector."])},feature_cheap:e=>{const{normalize:a}=e;return a(["20 veces más barato"])},feature_cheap_v1:e=>{const{normalize:a}=e;return a(["5 veces más barato"])},feature_cheap_v1_description1:e=>{const{normalize:a}=e;return a(["Comience con pruebas gratuitas y disfrute de una estructura de precios sencilla. Obtenga acceso a potentes incorporaciones por solo el 20 % del coste de OpenAI."])},feature_multilingual:e=>{const{normalize:a}=e;return a(["Ofreciendo modelos bilingües para alemán-inglés, chino-inglés, entre otros, ideales para aplicaciones multilingües."])},feature_on_premises:e=>{const{normalize:a}=e;return a(["Privacidad primero"])},feature_on_premises_description1:e=>{const{normalize:a}=e;return a(["Implemente sin problemas nuestros modelos integrados directamente dentro de su nube privada virtual (VPC). Actualmente es compatible con AWS Sagemaker, con próximas integraciones para Microsoft Azure y Google Cloud Platform. Para implementaciones personalizadas de Kubernetes, comuníquese con nuestro equipo de ventas para obtener asistencia especializada."])},feature_on_premises_description2:e=>{const{normalize:a}=e;return a(["Implemente modelos de Jina Embeddings en AWS Sagemaker y pronto en Microsoft Azure y Google Cloud Services, o comuníquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description3:e=>{const{normalize:a}=e;return a(["Implemente modelos de Jina Embeddings en AWS Sagemaker y Microsoft Azure, y pronto en Google Cloud Services, o comuníquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description4:e=>{const{normalize:a}=e;return a(["Implemente modelos Jina Embedding y Reranker en las instalaciones utilizando AWS SageMaker, Microsoft Azure o Google Cloud Services, garantizando que sus datos permanezcan seguros bajo su control."])},feature_solid:e=>{const{normalize:a}=e;return a(["Mejor en clase"])},feature_solid_description1:e=>{const{normalize:a}=e;return a(["Desarrollado a partir de nuestra investigación académica de vanguardia y probado rigurosamente con los modelos SOTA para garantizar un rendimiento incomparable."])},feature_top_perform1:e=>{const{normalize:a}=e;return a(["Integración perfecta"])},feature_top_perform_description1:e=>{const{normalize:a}=e;return a(["Totalmente compatible con la API de OpenAI. Se integra sin esfuerzo con más de 10 bases de datos vectoriales y sistemas RAG para una experiencia de usuario fluida."])},file_required:e=>{const{normalize:a}=e;return a(["Se requiere archivo"])},file_size_exceed:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Superar el tamaño máximo de archivo ",n(r("_size"))])},file_type_not_supported:e=>{const{normalize:a}=e;return a(["Tipo de archivo no compatible"])},fill_example:e=>{const{normalize:a}=e;return a(["Complete un ejemplo"])},float_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones se devuelven como una lista de números de punto flotante. El más común y fácil de usar."])},free:e=>{const{normalize:a}=e;return a(["Gratis"])},generate_api_key_error:e=>{const{normalize:a}=e;return a(["Error al generar la clave API."])},generating_visualization:e=>{const{normalize:a}=e;return a(["Generando visualización..."])},get_new_key_button:e=>{const{normalize:a}=e;return a(["Obtener nueva clave"])},get_new_key_button_explain:e=>{const{normalize:a}=e;return a(["Optar por una nueva clave resultará en la pérdida del historial de uso asociado con la clave anterior."])},get_new_key_survey:e=>{const{normalize:a}=e;return a(["Complete la encuesta, ayúdenos a comprender su uso y obtenga una nueva clave API gratis."])},includes:e=>{const{normalize:a}=e;return a(["Fichas válidas para:"])},index_and_search:e=>{const{normalize:a}=e;return a(["Índice y búsqueda"])},index_and_search1:e=>{const{normalize:a}=e;return a(["Índice y búsqueda"])},input:e=>{const{normalize:a}=e;return a(["Pedido"])},input_api_key_error1:e=>{const{normalize:a}=e;return a(["¡Su clave API no es válida!"])},input_length:e=>{const{normalize:a}=e;return a(["Longitud de entrada"])},input_type:e=>{const{normalize:a}=e;return a(["Insertar como consulta o documento"])},input_type_explain:e=>{const{normalize:a}=e;return a(["Algunos modelos de integración tienen estrategias de integración dedicadas para consultas y documentos. La misma cadena se puede incrustar como una consulta o un documento según su función en su aplicación."])},integrate:e=>{const{normalize:a}=e;return a(["Integrar"])},"jina-clip-v1_description":e=>{const{normalize:a}=e;return a(["Nuestras últimas incorporaciones multimodales para recuperación de texto e imágenes."])},"jina-colbert-v1-en_description":e=>{const{normalize:a}=e;return a(["ColBERT mejorado con una longitud de token de 8K para tareas de incrustación y reclasificación"])},"jina-colbert-v2_description":e=>{const{normalize:a}=e;return a(["El mejor ColBERT multilingüe con el máximo rendimiento en integración y reclasificación"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:a}=e;return a(["Optimizado para búsqueda de código y cadenas de documentos"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:a}=e;return a(["Integraciones bilingües alemán-inglés con rendimiento SOTA"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:a}=e;return a(["A la par con text-embedding-ada002 de OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:a}=e;return a(["Incorporaciones bilingües español-inglés con rendimiento SOTA"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:a}=e;return a(["Integraciones bilingües chino-inglés con rendimiento SOTA"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:a}=e;return a(["Optimizado para baja latencia y uso de memoria"])},"jina-embeddings-v3_description":e=>{const{normalize:a}=e;return a(["Modelo de integración multilingüe de Frontier con rendimiento SOTA"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:a}=e;return a(["Nuestro primer modelo de reranker que maximiza la búsqueda y la relevancia de RAG"])},"jina-reranker-v1-tiny-en_description":e=>{const{normalize:a}=e;return a(["El modelo de reordenación más rápido, más adecuado para clasificar una gran cantidad de documentos de manera confiable"])},"jina-reranker-v1-turbo-en_description":e=>{const{normalize:a}=e;return a(["La mejor combinación de velocidad de inferencia rápida y puntuaciones de relevancia precisas"])},"jina-reranker-v2-base-multilingual_description":e=>{const{normalize:a}=e;return a(["El último y mejor modelo de reranker con soporte multilingüe, llamadas de funciones y búsqueda de códigos."])},key:e=>{const{normalize:a}=e;return a(["Clave API"])},key_enter_placeholder:e=>{const{normalize:a}=e;return a(["Por favor ingrese su clave API"])},key_enter_placeholder_to_topup:e=>{const{normalize:a}=e;return a(["Ingresa la clave API que deseas recargar"])},key_to_top_up:e=>{const{normalize:a}=e;return a(['¿Tiene una clave API diferente para recargar? Péguela arriba y haga clic en "Guardar".'])},key_warn:e=>{const{normalize:a}=e;return a(["Asegúrese de guardar su clave API en un lugar seguro. De lo contrario, deberá generar una nueva clave."])},key_warn_v2:e=>{const{normalize:a}=e;return a(["Esta es tu clave única. ¡Guárdala de forma segura!"])},language_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Este modelo es el que mejor admite el idioma ",n(r("_language")),"."])},last_7_days:e=>{const{normalize:a}=e;return a(["Uso en los últimos 7 días"])},late_chunking:e=>{const{normalize:a}=e;return a(["Troceo tardío"])},late_chunking_explain:e=>{const{normalize:a}=e;return a(["Aplique la técnica de fragmentación tardía para aprovechar las capacidades de contexto largo del modelo para generar incrustaciones de fragmentos contextuales."])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende más"])},learn_poster:e=>{const{normalize:a}=e;return a(["Aprende cómo lo hicimos"])},learning1:e=>{const{normalize:a}=e;return a(["Aprendiendo sobre incrustaciones"])},learning1_description:e=>{const{normalize:a}=e;return a(["¿Por dónde empezar con las incrustaciones? Te tenemos cubierto. Aprenda sobre las incrustaciones desde cero con nuestra guía completa."])},length:e=>{const{normalize:a}=e;return a(["Longitud del token"])},manage_billing:e=>{const{normalize:a}=e;return a(["Gestionar factura"])},manage_billing_tip:e=>{const{normalize:a}=e;return a(["Administre su información de facturación, obtenga facturas y configure la recarga automática."])},manage_quota1:e=>{const{normalize:a}=e;return a(["Clave API y facturación"])},max_file_size:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Tamaño máximo permitido: ",n(r("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:a}=e;return a(["Maximizar este panel con Shift+1"])},mistake_contact:e=>{const{normalize:a}=e;return a(["Si cree que esto es un error, por favor contáctenos."])},model_required:e=>{const{normalize:a}=e;return a(["Se requiere modelo"])},more_than_two2:e=>{const{normalize:a}=e;return a(["Introduzca más de dos documentos, es decir, más de dos líneas."])},multi_embedding:e=>{const{normalize:a}=e;return a(["Multivector"])},multi_embedding_explain:e=>{const{normalize:a}=e;return a(["Este modelo devolverá una bolsa de incrustaciones contextualizadas para una entrada determinada. Cada token en la entrada se asigna a un vector en la salida."])},multilingual:e=>{const{normalize:a}=e;return a(["Soporte multilingüe"])},multimodal:e=>{const{normalize:a}=e;return a(["Multimodal"])},multimodal_explain:e=>{const{normalize:a}=e;return a(["Este modelo puede codificar entradas de texto e imágenes, lo que lo hace ideal para tareas de búsqueda multimodal."])},new:e=>{const{normalize:a}=e;return a(["Nuevo modelo"])},no_data1:e=>{const{normalize:a}=e;return a(["Agrega un par de oraciones para calcular la similitud."])},none:e=>{const{normalize:a}=e;return a(["Ninguno"])},normalized:e=>{const{normalize:a}=e;return a(["Normalización L2"])},normalized_explain:e=>{const{normalize:a}=e;return a(["Escala la incrustación de modo que su norma euclidiana (L2) se convierta en 1, lo que preserva la dirección. Resulta útil cuando el proceso posterior implica un producto escalar, una clasificación y una visualización."])},onprem:e=>{const{normalize:a}=e;return a(["Local"])},open_tensorboard:e=>{const{normalize:a}=e;return a(["Visualizador abierto"])},opensource:e=>{const{normalize:a}=e;return a(["SO"])},opensource_explain:e=>{const{normalize:a}=e;return a(["Este modelo es de código abierto y está disponible en Hugging Face. Haga clic en este botón para ver el modelo en Hugging Face."])},original_documents:e=>{const{normalize:a}=e;return a(["Oraciones para insertar"])},original_documents_hint:e=>{const{normalize:a}=e;return a(["Introduzca aquí sus frases. Cada nueva línea se considerará una oración/documento independiente."])},output:e=>{const{normalize:a}=e;return a(["Respuesta"])},output_dim:e=>{const{normalize:a}=e;return a(["Dimensiones"])},output_dim_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["La dimensión de salida de un vector de incrustación de este modelo es ",n(r("_outputDim")),"."])},output_dimension:e=>{const{normalize:a}=e;return a(["Dimensiones de salida"])},pairwise_test:e=>{const{normalize:a}=e;return a(["Por parejas"])},per_k:e=>{const{normalize:a}=e;return a(["/ 1K fichas"])},per_m:e=>{const{normalize:a}=e;return a(["/ 1 millón de fichas"])},please_fill_docs_first:e=>{const{normalize:a}=e;return a(["Primero ingrese algunas oraciones a continuación antes de realizar la búsqueda."])},please_select_model:e=>{const{normalize:a}=e;return a(["Seleccione un modelo de incrustación o un modelo de Reranker"])},poster:e=>{const{normalize:a}=e;return a(["La evolución de las incrustaciones Póster"])},poster_description:e=>{const{normalize:a}=e;return a(["Descubra el póster ideal para su espacio, con infografías cautivadoras o imágenes impresionantes que rastrean la evolución de los modelos de incrustación de texto desde 1950."])},pricing:e=>{const{normalize:a}=e;return a(["Precios de API"])},pricing_desc:e=>{const{normalize:a}=e;return a(["El precio de nuestra API se estructura en función de la cantidad de tokens enviados en las solicitudes. Para Reader API, es la cantidad de tokens en las respuestas. Este modelo de precios es aplicable a todos los productos de la base de búsqueda de Jina AI: API de incrustación, reclasificación, lector y ajuste automático. Con la misma clave API, tienes acceso a todos los servicios API."])},protectData1:e=>{const{normalize:a}=e;return a(["Los datos y documentos de la solicitud no se utilizan para los modelos de capacitación."])},protectData2:e=>{const{normalize:a}=e;return a(["Cifrado de datos en tránsito (TLS 1.2+) y en reposo (AES-GCM 256)."])},protectData3:e=>{const{normalize:a}=e;return a(["Cumple con SOC 2 y GDPR."])},protect_data:e=>{const{normalize:a}=e;return a(["Proteja sus datos"])},public_cloud_integration:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Con <b>",n(r("_numPartners")),"</b> proveedores de servicios en la nube"])},public_cloud_integration_desc:e=>{const{normalize:a}=e;return a(["¿Su empresa utiliza AWS o Azure? Luego, implemente directamente nuestros modelos básicos de búsqueda en estas plataformas de su empresa, para que sus datos se mantengan seguros y cumplan con las normas."])},query:e=>{const{normalize:a}=e;return a(["Consulta"])},raise_issue:e=>{const{normalize:a}=e;return a(["Plantear un problema"])},rank_none_description:e=>{const{normalize:a}=e;return a(["No utilices ningún modelo de reranker."])},read_api_docs:e=>{const{normalize:a}=e;return a(["Especificación API"])},read_release_note:e=>{const{normalize:a}=e;return a(["Leer la nota de lanzamiento"])},recharge_threshold:e=>{const{normalize:a}=e;return a(["Umbral de recarga"])},refresh:e=>{const{normalize:a}=e;return a(["Actualizar"])},refresh_key_tooltip1:e=>{const{normalize:a}=e;return a(["Obtenga una nueva clave API gratis"])},refresh_token_count1:e=>{const{normalize:a}=e;return a(["Actualice para obtener tokens disponibles de la clave API actual"])},regenerate:e=>{const{normalize:a}=e;return a(["Regenerado"])},remaining:e=>{const{normalize:a}=e;return a(["Fichas disponibles"])},remaining_left:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Te quedan <b>",n(r("_leftTokens")),"</b> tokens en la clave API a continuación."])},request_number:e=>{const{normalize:a}=e;return a(["Horarios de solicitud"])},request_path:e=>{const{normalize:a}=e;return a(["Punto final de solicitud"])},results_as_final_result:e=>{const{normalize:a}=e;return a(["#docs como resultado final"])},results_fed_to_reranker:e=>{const{normalize:a}=e;return a(["#docs enviados al reranker"])},retry:e=>{const{normalize:a}=e;return a(["Rever"])},return_base64:e=>{const{normalize:a}=e;return a(["Base64 (como cadena)"])},return_binary:e=>{const{normalize:a}=e;return a(["Binario (empaquetado como int8)"])},return_float:e=>{const{normalize:a}=e;return a(["Predeterminado (como flotante)"])},return_format:e=>{const{normalize:a}=e;return a(["Formato de incrustaciones"])},return_format_explain:e=>{const{normalize:a}=e;return a(["Además del flotante, puede pedirle que regrese como binario para una recuperación de vectores más rápida o como codificación base64 para una transmisión más rápida."])},return_format_title:e=>{const{normalize:a}=e;return a(["Tipo de datos de retorno"])},return_ubinary:e=>{const{normalize:a}=e;return a(["Binario (empaquetado como uint8)"])},right_api_key_to_charge:e=>{const{normalize:a}=e;return a(["Ingrese la clave API correcta para recargar"])},running:e=>{const{normalize:a}=e;return a(["Activo"])},score:e=>{const{normalize:a}=e;return a(["Puntaje"])},search:e=>{const{normalize:a}=e;return a(["Buscar"])},search_hint:e=>{const{normalize:a}=e;return a(["Escriba para buscar dentro de las oraciones que se enumeran a continuación"])},select_embedding_model:e=>{const{normalize:a}=e;return a(["Seleccionar incrustaciones"])},select_rerank_model:e=>{const{normalize:a}=e;return a(["Seleccionar reclasificador"])},show_api_key:e=>{const{normalize:a}=e;return a(["Mostrar clave API"])},size:e=>{const{normalize:a}=e;return a(["Parámetros"])},size_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["La cantidad de parámetros en el modelo es ",n(r("_size")),"; tenga en cuenta que este no es el tamaño del archivo del modelo."])},sleeping:e=>{const{normalize:a}=e;return a(["Inactivo"])},start_batch:e=>{const{normalize:a}=e;return a(["Iniciar la incrustación por lotes"])},start_embedding:e=>{const{normalize:a}=e;return a(["Índice"])},status_explain:e=>{const{normalize:a}=e;return a(["Nuestra arquitectura sin servidor puede descargar ciertos modelos durante períodos de bajo uso. Para los modelos activos, las respuestas son inmediatas. Los modelos inactivos requieren unos segundos para cargarse tras la solicitud inicial. Después de la activación, las solicitudes posteriores se procesan más rápidamente."])},task_type:e=>{const{normalize:a}=e;return a(["Tarea posterior"])},task_type_classification:e=>{const{normalize:a}=e;return a(["Clasificación"])},task_type_classification_explain:e=>{const{normalize:a}=e;return a(["Clasificación de texto."])},task_type_explain:e=>{const{normalize:a}=e;return a(["Seleccione la tarea posterior para la que se utilizarán las incrustaciones. El modelo devolverá las incrustaciones optimizadas para esa tarea."])},task_type_none_explain:e=>{const{normalize:a}=e;return a(["No se utilizará ningún adaptador. Se devolverá una incrustación genérica, útil para depuración o piratería."])},task_type_retrieval_passage:e=>{const{normalize:a}=e;return a(["Pasaje de recuperación"])},task_type_retrieval_passage_explain:e=>{const{normalize:a}=e;return a(["Incrustar documentos en una tarea de recuperación de documentos de consulta."])},task_type_retrieval_query:e=>{const{normalize:a}=e;return a(["Consulta de recuperación"])},task_type_retrieval_query_explain:e=>{const{normalize:a}=e;return a(["Incorporación de consultas en una tarea de recuperación de documentos de consulta."])},task_type_separation:e=>{const{normalize:a}=e;return a(["Separación"])},task_type_separation_explain:e=>{const{normalize:a}=e;return a(["Agrupamiento de documentos, visualización de corpus."])},"task_type_text-matching":e=>{const{normalize:a}=e;return a(["Coincidencia de texto"])},"task_type_text-matching_explain":e=>{const{normalize:a}=e;return a(["Similitud de texto semántico, recuperación simétrica general, recomendación, búsqueda de similares, deduplicación."])},tax_may_apply:e=>{const{normalize:a}=e;return a(["Dependiendo de su ubicación, es posible que se le cobre en USD, EUR u otras monedas. Se pueden aplicar impuestos."])},text1:e=>{const{normalize:a}=e;return a(["Izquierda"])},text2:e=>{const{normalize:a}=e;return a(["Bien"])},title:e=>{const{normalize:a}=e;return a(["API de incrustación"])},token_example:e=>{const{normalize:a}=e;return a(['Un tweet equivale a aproximadamente 20 tokens, un artículo de noticias equivale a aproximadamente 1000 tokens y la novela de Charles Dickens "A Tale of Two Cities" tiene más de un millón de tokens.'])},token_length_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["La longitud máxima de la secuencia del token de entrada es ",n(r("_tokenLength"))," para este modelo."])},tokens:e=>{const{normalize:a}=e;return a(["Fichas"])},tools:e=>{const{normalize:a}=e;return a(["Herramientas"])},top_up_button:e=>{const{normalize:a}=e;return a(["Recargar clave antigua"])},top_up_button_explain:e=>{const{normalize:a}=e;return a(["La integración de esta clave API ofrece una solución más profesional, eliminando la necesidad de cambios frecuentes de clave. Los datos de uso se conservan y son accesibles en cualquier momento."])},top_up_warning_message1:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["A la clave API actual le quedan ",n(r("_remainedTokens"))," tokens y será reemplazada por una nueva clave con tokens ",n(r("_freeTokens")),". Puede continuar usando o recargar la clave anterior si la ha almacenado de forma segura. ¿Como quieres proceder?"])},top_up_warning_title:e=>{const{normalize:a}=e;return a(["Reemplazar la antigua clave API"])},total_documents:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Progreso de la incrustación: ",n(r("_Processed")),"/",n(r("_Count"))," oraciones."])},tuning:e=>{const{normalize:a}=e;return a(["Afinar"])},turnstile_error:e=>{const{normalize:a}=e;return a(["No podemos generar una clave API porque no pudimos verificar si eres humano."])},turnstile_unsupported:e=>{const{normalize:a}=e;return a(["No podemos generar una clave API porque su navegador no es compatible."])},ubinary_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones se empaquetan como uint8. Mucho más eficiente para almacenamiento, búsqueda y transmisión."])},upload:e=>{const{normalize:a}=e;return a(["Subir"])},upload_file:e=>{const{normalize:a}=e;return a(["Haga clic aquí para cargar un archivo"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},usage_amount:e=>{const{normalize:a}=e;return a(["Fichas"])},usage_history:e=>{const{normalize:a}=e;return a(["Uso en los últimos 7 días"])},usage_history_explain:e=>{const{normalize:a}=e;return a(["Los datos no están en tiempo real y pueden sufrir un retraso de unos minutos."])},usage_reason:e=>{const{normalize:a}=e;return a(["Descripción"])},usage_reason_consume:e=>{const{normalize:a}=e;return a(["Usado"])},usage_reason_purchase:e=>{const{normalize:a}=e;return a(["Comprado"])},usage_reason_trial:e=>{const{normalize:a}=e;return a(["Ensayo"])},usage_rerank:e=>{const{normalize:a}=e;return a(["Uso"])},usage_time:e=>{const{normalize:a}=e;return a(["Fecha y hora"])},v3_description:e=>{const{normalize:a}=e;return a(["<code>jina-embeddings-v3</code> es un modelo de incrustación de texto multilingüe de vanguardia con 570 millones de parámetros y una longitud de token de 8192, que supera a las últimas incrustaciones patentadas de OpenAI y Cohere en MTEB. Lea nuestra publicación de blog y nuestro artículo de investigación a continuación."])},v3_title:e=>{const{normalize:a}=e;return a(["v3: Integraciones multilingües de Frontier"])},vector_database_integration1:e=>{const{normalize:a}=e;return a(["Integraciones"])},vector_database_integration2:e=>{const{normalize:a}=e;return a(["Nuestra API de incrustación está integrada de forma nativa con varias bases de datos, almacenes de vectores, marcos RAG y LLMOps de renombre. Para comenzar, simplemente copie y pegue su clave API en cualquiera de las integraciones enumeradas para un comienzo rápido y sin problemas."])},vector_database_integration3:e=>{const{normalize:a}=e;return a(["Nuestra API Embedding & Reranker está integrada de forma nativa con varias bases de datos, almacenes de vectores, RAG y marcos LLMOps de renombre. Para comenzar, simplemente copie y pegue su clave API en cualquiera de las integraciones enumeradas para un comienzo rápido y sin problemas."])},vector_database_integration_description:e=>{const{normalize:a}=e;return a(["Integre fácil y perfectamente la API de Jina Embeddings con cualquiera de las bases de datos vectoriales, marcos de orquestación LLM y aplicaciones RAG que aparecen a continuación. Nuestros tutoriales le mostrarán cómo."])},view_details:e=>{const{normalize:a}=e;return a(["Ver detalles"])},visualization_example:e=>{const{normalize:a}=e;return a(["Mapear todas las oraciones de esta sección a un espacio vectorial 3D"])},visualization_example_you_can:e=>{const{normalize:a}=e;return a(["Utilice nuestra API a continuación, ¡usted también puede hacerlo!"])},visualize:e=>{const{normalize:a}=e;return a(["Visualizar"])},visualize_done:e=>{const{normalize:a}=e;return a(["La visualización ha terminado, ahora puede hacer clic en el botón superior para abrir el visualizador."])},wait_for_processing:e=>{const{normalize:a}=e;return a(["Se está procesando su petición."])},wait_stripe:e=>{const{normalize:a}=e;return a(["Abriendo pago de Stripe, por favor espere"])},what_are_embedding:e=>{const{normalize:a}=e;return a(["¿Qué son las incrustaciones?"])},what_are_embedding_answer:e=>{const{normalize:a}=e;return a([`Imagínese enseñarle a una computadora a captar los significados matizados de palabras y frases. Los métodos tradicionales, que se basaban en sistemas rígidos basados ​​en reglas, se quedaron cortos porque el lenguaje es demasiado complejo y fluido. Ingrese a las incrustaciones de texto: una poderosa solución que traduce texto a un lenguaje de números, específicamente, a vectores en un espacio de alta dimensión.

Considere las frases "clima soleado" y "cielo despejado". Para nosotros, nos pintan un cuadro similar. A través de la lente de las incrustaciones, estas frases se transforman en vectores numéricos que residen cerca unos de otros en este espacio multidimensional, capturando su parentesco semántico. Esta cercanía en el espacio vectorial no se trata solo de que las palabras o frases sean similares; se trata de comprender el contexto, el sentimiento e incluso los matices sutiles del significado.

¿Por qué es importante este avance? Para empezar, cierra la brecha entre la riqueza del lenguaje humano y la eficiencia computacional de los algoritmos. Los algoritmos destacan por procesar números, no por interpretar textos. Al convertir texto en vectores, las incrustaciones hacen posible que estos algoritmos "comprendan" y procesen el lenguaje de una manera que antes estaba fuera de su alcance.

Las aplicaciones prácticas son amplias y variadas. Ya sea recomendar contenido que resuene con sus intereses, impulsar una IA conversacional que parezca sorprendentemente humana o incluso detectar patrones sutiles en grandes volúmenes de texto, las incrustaciones son la clave. Permiten que las máquinas realicen tareas como análisis de sentimientos, traducción de idiomas y mucho más, con una comprensión del lenguaje cada vez más matizada y refinada.`])},what_is_a_token:e=>{const{normalize:a}=e;return a(['Un token en el procesamiento de textos es una unidad, a menudo una palabra. Por ejemplo, "¡Jina AI es genial!" se convierte en cinco fichas, incluida la puntuación.'])},why_do_you_need:e=>{const{normalize:a}=e;return a(["Elegir las incrustaciones adecuadas"])},why_do_you_need_after:e=>{const{normalize:a}=e;return a(["Aprovechando las redes neuronales profundas y los LLM, nuestros modelos integrados representan datos multimodales en un formato optimizado, lo que mejora la comprensión de las máquinas, el almacenamiento eficiente y permite aplicaciones avanzadas de IA. Estas incorporaciones desempeñan un papel crucial en la comprensión de los datos, la mejora de la participación del usuario, la superación de las barreras del idioma y la optimización de los procesos de desarrollo."])},why_do_you_need_before:e=>{const{normalize:a}=e;return a(["Nuestros modelos de integración están diseñados para cubrir diversas aplicaciones de búsqueda y GenAI."])},why_need_1_description:e=>{const{normalize:a}=e;return a(["Nuestro modelo de integración central, impulsado por JinaBERT, está diseñado para un amplio espectro de aplicaciones. Destaca en la comprensión de textos detallados, lo que lo hace ideal para búsqueda semántica, clasificación de contenido y análisis de lenguaje complejo. Su versatilidad es incomparable y admite la creación de herramientas avanzadas de análisis de sentimientos, resúmenes de texto y sistemas de recomendación personalizados."])},why_need_1_title:e=>{const{normalize:a}=e;return a(["Incrustaciones de uso general"])},why_need_2_description:e=>{const{normalize:a}=e;return a(["Nuestros modelos bilingües facilitan la comunicación entre idiomas, mejorando las plataformas multilingües, la atención al cliente global y el descubrimiento de contenido en varios idiomas. Diseñados para dominar las traducciones alemán-inglés y chino-inglés, estos modelos simplifican las interacciones y fomentan la comprensión entre diversos grupos lingüísticos."])},why_need_2_title:e=>{const{normalize:a}=e;return a(["Incorporaciones bilingües"])},why_need_3_description:e=>{const{normalize:a}=e;return a(["Diseñado para desarrolladores, nuestro modelo de incorporación de código optimiza las tareas de codificación como el resumen, la generación de código y las revisiones automáticas. Aumenta la productividad al ofrecer información más profunda sobre las estructuras del código y sugerir mejoras, lo que lo hace esencial para desarrollar complementos IDE avanzados, documentación automática y herramientas de depuración de vanguardia."])},why_need_3_title:e=>{const{normalize:a}=e;return a(["Incorporaciones de código"])},why_need_4_description:e=>{const{normalize:a}=e;return a(["Jina CLIP es nuestro último modelo de incrustación multimodal para imágenes y texto. Una gran mejora con respecto a OpenAI CLIP es que este modelo único se puede utilizar para la recuperación de texto-texto, así como para tareas de recuperación de texto-imagen, imagen-texto e imagen-imagen. ¡Así que un modelo, dos modalidades, cuatro direcciones de búsqueda!"])},why_need_4_title:e=>{const{normalize:a}=e;return a(["Incrustaciones multimodales"])},write_email_here:e=>{const{normalize:a}=e;return a(["Ingrese el correo electrónico donde desea recibir el enlace de descarga al finalizar."])},you_can_leave:e=>{const{normalize:a}=e;return a(["Puede abandonar esta página y le enviaremos el enlace de descarga una vez finalizada."])}},embeddings:{description:e=>{const{normalize:a}=e;return a(["Integraciones multilingües y multimodales de clase mundial para búsqueda/RAG/agentes."])}},faq:{answer1:e=>{const{normalize:a}=e;return a(["Jina AI se especializa en tecnologías de IA multimodales, incluido el ajuste de modelos, el servicio de modelos, el ajuste de avisos y el servicio de avisos. Aprovechamos herramientas avanzadas como Kubernetes y arquitecturas sin servidor para crear soluciones robustas, escalables y listas para producción."])},answer10:e=>{const{normalize:a}=e;return a(["Brindamos diferentes opciones de licencia según la naturaleza del proyecto y las necesidades del cliente. Los términos detallados se pueden discutir con nuestro equipo de ventas."])},answer11:e=>{const{normalize:a}=e;return a(["Brindamos servicios a nivel mundial, con nuestra sede central en Berlín, Europa, y oficinas adicionales en Beijing y Shenzhen."])},answer12:e=>{const{normalize:a}=e;return a(["Sí, ofrecemos soporte en el sitio, especialmente para clientes ubicados cerca de nuestras oficinas en Berlín, Beijing y Shenzhen. Para otras ubicaciones, nos esforzamos por brindar el mejor soporte remoto posible y podemos organizar el soporte en el sitio si es necesario."])},answer2:e=>{const{normalize:a}=e;return a(["Nuestra experiencia abarca un amplio espectro, que abarca grandes modelos de lenguaje, texto, imagen, video, comprensión de audio, búsqueda neuronal y arte generativo."])},answer3:e=>{const{normalize:a}=e;return a(["Sí, nuestras soluciones están diseñadas para ser escalables y listas para la producción. Creamos nuestras soluciones utilizando tecnologías nativas de la nube que permiten un escalado eficiente y un rendimiento confiable en entornos de producción."])},answer4:e=>{const{normalize:a}=e;return a(["Nuestros servicios son versátiles y adaptables, lo que los hace adecuados para una amplia gama de industrias, que incluyen comercio electrónico, tecnología legal, marketing digital, juegos, atención médica, finanzas y muchas más."])},answer5:e=>{const{normalize:a}=e;return a(["Puede ponerse en contacto con nuestro equipo comercial a través del formulario de contacto de esta página. Nos encantaría discutir los requisitos de su proyecto y cómo nuestras soluciones pueden ayudar a su negocio."])},answer6:e=>{const{normalize:a}=e;return a(["Brindamos soporte continuo para garantizar el buen funcionamiento de nuestras soluciones. Esto incluye resolución de problemas, actualizaciones periódicas y mejoras basadas en sus comentarios y necesidades."])},answer7:e=>{const{normalize:a}=e;return a(["La duración del proyecto varía según la complejidad y el alcance del proyecto. Después de comprender sus requisitos, podemos proporcionarle una estimación más precisa."])},answer8:e=>{const{normalize:a}=e;return a(["La seguridad de los datos es nuestra máxima prioridad. Nos adherimos a estrictas políticas y regulaciones de protección de datos para garantizar que sus datos estén seguros y confidenciales."])},answer9:e=>{const{normalize:a}=e;return a(["El precio depende de la complejidad y los requisitos del proyecto. Ofrecemos modelos de precios basados ​​en proyectos y de retención. Póngase en contacto con nuestro equipo de ventas para obtener más información."])},question1:e=>{const{normalize:a}=e;return a(["¿En qué se especializa Jina AI?"])},question10:e=>{const{normalize:a}=e;return a(["¿Cuáles son los términos de licencia para sus soluciones?"])},question11:e=>{const{normalize:a}=e;return a(["¿Cuál es su área de servicio?"])},question12:e=>{const{normalize:a}=e;return a(["¿Ofrecen soporte en el sitio?"])},question2:e=>{const{normalize:a}=e;return a(["¿Con qué tipos de IA trabaja Jina AI?"])},question3:e=>{const{normalize:a}=e;return a(["¿Sus soluciones son escalables y están listas para la producción?"])},question4:e=>{const{normalize:a}=e;return a(["¿Qué industrias pueden beneficiarse de las soluciones de Jina AI?"])},question5:e=>{const{normalize:a}=e;return a(["¿Cómo comenzamos un proyecto con Jina AI?"])},question6:e=>{const{normalize:a}=e;return a(["¿Qué apoyo brindan después de implementar una solución?"])},question7:e=>{const{normalize:a}=e;return a(["¿Cuál es la duración típica de un proyecto?"])},question8:e=>{const{normalize:a}=e;return a(["¿Cómo protege Jina AI mis datos?"])},question9:e=>{const{normalize:a}=e;return a(["¿Cuál es la estructura de precios de sus servicios?"])}},faq_button:e=>{const{normalize:a}=e;return a(["Preguntas más frecuentes"])},finetuner:{description:e=>{const{normalize:a}=e;return a(["Ajuste las incrustaciones en datos específicos del dominio para una mejor calidad de búsqueda"])},intro:e=>{const{normalize:a}=e;return a(["Tu compañía. Tu información. tu modelo"])}},finetuner_plus:{description:e=>{const{normalize:a}=e;return a(["Potencie su empresa con soluciones de ajuste fino en las instalaciones"])}},finetuning:{api_key:e=>{const{normalize:a}=e;return a(["Ingrese su clave API."])},back:e=>{const{normalize:a}=e;return a(["Atrás"])},base_model_selected:e=>{const{normalize:a}=e;return a(["Modelo base seleccionado"])},click_start:e=>{const{normalize:a}=e;return a(["Acepte los términos y comience a realizar ajustes."])},confirm_title:e=>{const{normalize:a}=e;return a(["Confirmar el trabajo de ajuste"])},confirm_your_email:e=>{const{normalize:a}=e;return a(["Vuelva a ingresar su dirección de correo electrónico para confirmar el trabajo de ajuste. Las actualizaciones y el enlace de descarga se enviarán a este correo electrónico."])},consent0:e=>{const{normalize:a}=e;return a(["Acepto que se generen datos sintéticos para el ajuste del modelo según mis instrucciones."])},consent1:e=>{const{normalize:a}=e;return a(["Reconozco que el modelo final y los datos sintéticos estarán accesibles públicamente en Hugging Face."])},consent2:e=>{const{normalize:a}=e;return a(["Entiendo que esta función está en versión beta y Jina AI no ofrece garantías. El precio y la UX pueden cambiar."])},continue:e=>{const{normalize:a}=e;return a(["Continuar"])},cost_1m_token:e=>{const{normalize:a}=e;return a(["Cada trabajo de ajuste consume 1 millón de tokens. Asegúrese de tener suficientes tokens o recargue su saldo. También puede generar una nueva clave API. Cada clave API viene con 1 millón de tokens gratuitos."])},doc_explain:e=>{const{normalize:a}=e;return a(["Describe cómo debería verse un documento coincidente."])},domain_explain:e=>{const{normalize:a}=e;return a(["Proporcione una descripción detallada de cómo se utilizarán las incrustaciones ajustadas. Esto es esencial para generar datos sintéticos de alta calidad que mejorarán el rendimiento de sus incrustaciones."])},domain_explain2:e=>{const{normalize:a}=e;return a(["Hay tres formas de especificar sus requisitos: una instrucción general, una URL o una descripción del documento de consulta. Elige uno."])},domain_hint:e=>{const{normalize:a}=e;return a(["Describe el dominio que deseas ajustar."])},email_not_match:e=>{const{normalize:a}=e;return a(["Las direcciones de correo no coinciden. Por favor verificar."])},failed_job:e=>{const{normalize:a}=e;return a(["La solicitud de ajuste falló. Vea el motivo a continuación."])},find_on_huggingface:e=>{const{normalize:a}=e;return a(["Encuentra resultados en Abrazar la cara"])},general_instruction:e=>{const{normalize:a}=e;return a(["O instrucción general"])},general_instruction_caption:e=>{const{normalize:a}=e;return a(["Proporcione una descripción detallada de cómo se utilizarán las incrustaciones ajustadas."])},general_instruction_explain:e=>{const{normalize:a}=e;return a(['Describe tu dominio en texto de formato libre. Puedes imaginarlo como un "mensaje" como en ChatGPT.'])},how_it_works:e=>{const{normalize:a}=e;return a(["Obtenga más información sobre el proceso de ajuste."])},job_acknowledged:e=>{const{normalize:a}=e;return a(["Su trabajo de ajuste ha sido puesto en cola. Recibirás un correo electrónico cuando comience el trabajo. El proceso completo suele tardar 20 minutos en completarse."])},new_key:e=>{const{normalize:a}=e;return a(["Obtener nueva clave"])},not_enough_token:e=>{const{normalize:a}=e;return a(["No hay suficientes tokens en esta clave API. Recargue su saldo o utilice una clave API diferente."])},placeholder:e=>{const{normalize:a}=e;return a(["Reclamaciones de seguros de automóviles"])},preview:e=>{const{normalize:a}=e;return a(["Avance"])},query_doc:e=>{const{normalize:a}=e;return a(["Descripción del documento de consulta"])},query_doc_caption:e=>{const{normalize:a}=e;return a(["Describe cómo se ve la consulta y cómo se ve el documento coincidente en tu dominio."])},query_explain:e=>{const{normalize:a}=e;return a(["Describe cómo se ve una consulta."])},reset:e=>{const{normalize:a}=e;return a(["Comenzar de nuevo"])},select_base_model:e=>{const{normalize:a}=e;return a(["Elija un modelo de incrustación base para realizar ajustes."])},select_base_model_explain:e=>{const{normalize:a}=e;return a(["Seleccione un modelo base como punto de partida para el ajuste fino. Normalmente, base-en es una buena opción, pero para tareas en otros idiomas, considere utilizar un modelo bilingüe."])},start_tuning:e=>{const{normalize:a}=e;return a(["Comience a realizar ajustes"])},url:e=>{const{normalize:a}=e;return a(["O URL de la página web"])},url_caption:e=>{const{normalize:a}=e;return a(["Consulte el contenido de una URL para realizar ajustes."])},url_explain:e=>{const{normalize:a}=e;return a(["URL pública de una página web que contiene el contenido que desea ajustar."])},use_url:e=>{const{normalize:a}=e;return a(["Utilice URL en su lugar. Activarlo significa que nos basaremos en el contenido de la página de esa URL para generar datos sintéticos para realizar ajustes."])},wait_for_processing:e=>{const{normalize:a}=e;return a(["Espere mientras procesamos su solicitud..."])},which_domain:e=>{const{normalize:a}=e;return a(["Dominio de ajuste"])},write_email_explain:e=>{const{normalize:a}=e;return a(["El ajuste fino lleva tiempo. Nos comunicaremos por correo electrónico sobre el inicio, el progreso, la finalización y cualquier problema relacionado con su trabajo de ajuste, junto con detalles sobre el modelo ajustado y el conjunto de datos de entrenamiento."])}},footer:{address_beijing:e=>{const{normalize:a}=e;return a(["Beijing, China"])},address_berlin:e=>{const{normalize:a}=e;return a(["Berlín, Alemania (sede central)"])},address_shenzhen:e=>{const{normalize:a}=e;return a(["Shenzhen, China"])},all_rights_reserved:e=>{const{normalize:a}=e;return a(["Reservados todos los derechos."])},company:e=>{const{normalize:a}=e;return a(["Compañía"])},developers:e=>{const{normalize:a}=e;return a(["Desarrolladores"])},docs:e=>{const{normalize:a}=e;return a(["Documentos"])},enterprise:e=>{const{normalize:a}=e;return a(["Empresa"])},get_api_key:e=>{const{normalize:a}=e;return a(["Obtenga la clave API de Jina AI"])},offices:e=>{const{normalize:a}=e;return a(["Oficinas"])},power_users:e=>{const{normalize:a}=e;return a(["Usuarios avanzados"])},privacy:e=>{const{normalize:a}=e;return a(["Privacidad"])},privacy_policy:e=>{const{normalize:a}=e;return a(["política de privacidad"])},privacy_settings:e=>{const{normalize:a}=e;return a(["Administrar cookies"])},security:e=>{const{normalize:a}=e;return a(["Seguridad"])},sefo:e=>{const{normalize:a}=e;return a(["Fundación de búsqueda"])},soc2:e=>{const{normalize:a}=e;return a(["Cumplimos con el estándar SOC 2 Tipo 1 del Instituto Americano de Contadores Públicos Certificados (AICPA)."])},status:e=>{const{normalize:a}=e;return a(["Estado de la API"])},status_short:e=>{const{normalize:a}=e;return a(["Estado"])},tc:e=>{const{normalize:a}=e;return a(["Términos y condiciones"])},tc1:e=>{const{normalize:a}=e;return a(["Términos"])}},get_new_key:e=>{const{normalize:a}=e;return a(["Obtenga su clave API"])},github:{stars:e=>{const{normalize:a}=e;return a(["Estrellas"])}},header:{about_us:e=>{const{normalize:a}=e;return a(["Sobre nosotros"])},company:e=>{const{normalize:a}=e;return a(["Compañía"])},contact_us:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},developers_others:e=>{const{normalize:a}=e;return a(["Más herramientas para desarrolladores"])},enterprise_others:e=>{const{normalize:a}=e;return a(["Más herramientas empresariales"])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_developers_description:e=>{const{normalize:a}=e;return a(["Experimente una pila integral de IA multimodal de código abierto diseñada para desarrolladores."])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para Empresas"])},for_enterprise_description:e=>{const{normalize:a}=e;return a(["Descubra estrategias escalables de IA multimodal diseñadas para satisfacer las necesidades comerciales."])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},for_power_users_description:e=>{const{normalize:a}=e;return a(["Utilice nuestras herramientas multimodales optimizadas para mejorar su productividad."])},internship1:e=>{const{normalize:a}=e;return a(["Programa de prácticas"])},jobs:e=>{const{normalize:a}=e;return a(["Únete a nosotros"])},join_discord:e=>{const{normalize:a}=e;return a(["Únete a nuestra comunidad de Discord"])},logos:e=>{const{normalize:a}=e;return a(["Descargar logotipo"])},maximize:e=>{const{normalize:a}=e;return a(["⇧1"])},maximize_btn:e=>{const{normalize:a}=e;return a(["Maximizar"])},news:e=>{const{normalize:a}=e;return a(["Noticias"])},open_day:e=>{const{normalize:a}=e;return a(["Día abierto"])},open_in_full:e=>{const{normalize:a}=e;return a(["Mostrar todos los productos empresariales en una nueva ventana"])},power_users_others:e=>{const{normalize:a}=e;return a(["Más herramientas para usuarios avanzados"])},products:e=>{const{normalize:a}=e;return a(["Productos"])}},hub:{description:e=>{const{normalize:a}=e;return a(["Comparta y descubra componentes básicos para aplicaciones de IA multimodal"])}},huggingface:{sentence_similarity:e=>{const{normalize:a}=e;return a(["incrustación de oraciones"])},updated_about:e=>{const{normalize:a}=e;return a(["actualizado sobre"])}},impact_snapshots:{project1:e=>{const{normalize:a}=e;return a(["Búsqueda de alta precisión habilitada dentro de datos de malla 3D utilizando información de nube de puntos."])},project10:e=>{const{normalize:a}=e;return a(["Aprovechó la visión artificial para mejorar la accesibilidad digital de los sitios web gubernamentales."])},project11:e=>{const{normalize:a}=e;return a(["LLM ajustado para una firma de consultoría para optimizar el análisis de datos financieros."])},project12:e=>{const{normalize:a}=e;return a(["Estrategias de marketing avanzadas mediante el ajuste fino de los modelos de texto a imagen para la transferencia de estilo."])},project2:e=>{const{normalize:a}=e;return a(["Diseñé un motor de búsqueda basado en contenido para cortometrajes de animación."])},project3:e=>{const{normalize:a}=e;return a(["Tasas de conversión de comercio electrónico mejoradas mediante el ajuste fino de los modelos integrados."])},project4:e=>{const{normalize:a}=e;return a(["Realicé ajustes rápidos para aumentar la eficiencia de una empresa de consultoría empresarial."])},project5:e=>{const{normalize:a}=e;return a(["Pionero en la comprensión de la escena del juego y la anotación automática para una empresa de juegos líder."])},project6:e=>{const{normalize:a}=e;return a(["Implementé la expansión de entrada en tiempo real para una empresa de chatbot, mejorando la experiencia del usuario."])},project7:e=>{const{normalize:a}=e;return a(["Revolucionó la tecnología legal al permitir una búsqueda eficiente en documentos legales extensos."])},project8:e=>{const{normalize:a}=e;return a(["Apoyó un servicio de arte generativo de alto rendimiento para operaciones a gran escala."])},project9:e=>{const{normalize:a}=e;return a(["Realización de minería y modelado de procesos utilizando modelos de lenguaje avanzado."])}},inference:{description:e=>{const{normalize:a}=e;return a(["Modelos multimodales de última generación disponibles para inferencia"])}},integrations:{embedding:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},reranker:e=>{const{normalize:a}=e;return a(["reclasificador"])},which_to_go:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["¿Cuál integrar con ",n(r("_vendor")),"?"])}},internship_faq:{answer1:e=>{const{normalize:a}=e;return a(["Licenciatura, maestría y doctorado. Se alienta a los estudiantes de todo el mundo, con interés en campos como la investigación, la ingeniería, el marketing y las ventas, a postularse. También damos la bienvenida a pasantías no técnicas en marketing, ventas, asistencia ejecutiva y más. Estamos buscando personas apasionadas listas para ser pioneros en la IA multimodal con nosotros."])},answer10:e=>{const{normalize:a}=e;return a(["Sí, nuestro programa de prácticas ofrece una remuneración competitiva."])},answer11:e=>{const{normalize:a}=e;return a(["Como pasante de Jina AI, obtendrá experiencia práctica trabajando en proyectos desafiantes, aprenderá de expertos de la industria, será parte de una comunidad vibrante y tendrá la oportunidad de hacer contribuciones reales a nuestro trabajo pionero en AI multimodal."])},answer2:e=>{const{normalize:a}=e;return a(["Las pasantías deben llevarse a cabo en el sitio en una de nuestras oficinas, que se encuentran en Berlín, Beijing y Shenzhen."])},answer3:e=>{const{normalize:a}=e;return a(["Sí, Jina AI ofrece asistencia razonable en el proceso de visa para los solicitantes seleccionados."])},answer4:e=>{const{normalize:a}=e;return a(["Sí, Jina AI brinda una cantidad razonable de cobertura de costo de vida para los pasantes durante el período de pasantía."])},answer5:e=>{const{normalize:a}=e;return a(["Sí, es posible trabajar en su tesis de maestría durante su pasantía en Jina AI, generalmente aplicable a estudiantes en universidades alemanas. Sin embargo, debe tener una comunicación previa y acuerdo del supervisor de su universidad. Tenga en cuenta que no ayudamos a los estudiantes a encontrar asesores."])},answer6:e=>{const{normalize:a}=e;return a(["El proceso de solicitud incluye enviar su formulario de solicitud, un currículum, una carta de presentación que exprese su interés y motivación, y cualquier enlace profesional relevante como GitHub o LinkedIn. Evaluamos a los candidatos en función de su desempeño durante la entrevista y su desempeño en su universidad."])},answer7:e=>{const{normalize:a}=e;return a(["Sí, los pasantes exitosos pueden recibir una carta de recomendación al final de su pasantía, firmada por nuestro CEO."])},answer8:e=>{const{normalize:a}=e;return a(["La duración de la pasantía varía según el rol y el proyecto. Sin embargo, por lo general oscila entre tres y seis meses."])},answer9:e=>{const{normalize:a}=e;return a(["Sí, aceptamos solicitudes de todos los antecedentes académicos. Valoramos su pasión y compromiso por aprender tanto como su experiencia previa."])},question1:e=>{const{normalize:a}=e;return a(["¿Quién puede solicitar el programa de pasantías de Jina AI?"])},question10:e=>{const{normalize:a}=e;return a(["¿Es esta una pasantía remunerada?"])},question11:e=>{const{normalize:a}=e;return a(["¿Qué oportunidades tendré como pasante de Jina AI?"])},question2:e=>{const{normalize:a}=e;return a(["¿Dónde se realizará la pasantía?"])},question3:e=>{const{normalize:a}=e;return a(["¿Jina AI ayuda con los procesos de visa?"])},question4:e=>{const{normalize:a}=e;return a(["¿Jina AI proporciona asignaciones o beneficios para los pasantes?"])},question5:e=>{const{normalize:a}=e;return a(["¿Puedo trabajar en mi tesis de maestría durante la pasantía en Jina AI?"])},question6:e=>{const{normalize:a}=e;return a(["¿En qué consiste el proceso de solicitud?"])},question7:e=>{const{normalize:a}=e;return a(["¿Jina AI proporciona alguna carta de recomendación posterior a la pasantía?"])},question8:e=>{const{normalize:a}=e;return a(["¿Cuál es la duración de la pasantía?"])},question9:e=>{const{normalize:a}=e;return a(["¿Puedo presentar una solicitud si no tengo experiencia previa en IA?"])}},internship_page:{about_internship_program:e=>{const{normalize:a}=e;return a(["Acerca del programa de pasantías"])},about_internship_program_desc1:e=>{const{normalize:a}=e;return a(["Estamos emocionados de ofrecer esta oportunidad única para que personas talentosas se unan a nuestro equipo dinámico y contribuyan a proyectos innovadores en el campo de la Inteligencia Artificial. Esta pasantía está diseñada para brindarle una valiosa experiencia práctica, tutoría y exposición a tecnologías de vanguardia que están dando forma al futuro de la IA."])},about_internship_program_desc2:e=>{const{normalize:a}=e;return a(["En Jina AI, entendemos la importancia de nutrir y aprovechar el talento joven. Reconocemos que los pasantes aportan nuevas perspectivas, entusiasmo y creatividad a la mesa, fortaleciendo a nuestro equipo con nuevas ideas y enfoques. Al proporcionar pasantías, nuestro objetivo es fomentar el crecimiento de los futuros líderes en la industria de la IA al tiempo que les ofrecemos una experiencia del mundo real en un entorno estimulante y de apoyo."])},alumni:e=>{const{normalize:a}=e;return a(["ALUMNOS"])},alumni_network:e=>{const{normalize:a}=e;return a(["Nuestra próspera red de antiguos alumnos"])},application:e=>{const{normalize:a}=e;return a(["Solicitud"])},application_desc:e=>{const{normalize:a}=e;return a(["Embárquese en un viaje transformador con Jina AI. Nuestro completo programa de pasantías invita a todas las mentes apasionadas que aspiran a dar forma al futuro de la inteligencia artificial. Únase a nosotros para obtener experiencia en el mundo real, trabajar en proyectos desafiantes y colaborar con algunas de las mentes más brillantes de la industria de la IA."])},apply:e=>{const{normalize:a}=e;return a(["Aplica ya"])},autumn:e=>{const{normalize:a}=e;return a(["Otoño"])},description:e=>{const{normalize:a}=e;return a(["Convocatoria mundial para estudiantes: Prácticas en investigación, ingeniería, marketing, ventas y más."])},dev_rel_intern:e=>{const{normalize:a}=e;return a(["Pasante de Relaciones con Desarrolladores"])},enthusiastic:e=>{const{normalize:a}=e;return a(["ENTUSIASTA"])},explore_stories_from_our_interns:e=>{const{normalize:a}=e;return a(["Explore las historias de nuestros pasantes"])},explore_stories_from_our_interns1:e=>{const{normalize:a}=e;return a(["Inspírate con los viajes de nuestros pasantes"])},innovative:e=>{const{normalize:a}=e;return a(["INNOVADOR"])},intern_work1:e=>{const{normalize:a}=e;return a(["Modelos LLM ajustados para mejores incrustaciones"])},intern_work2:e=>{const{normalize:a}=e;return a(["Exploró el potencial de recuperación de generación aumentada"])},intern_work3:e=>{const{normalize:a}=e;return a(["Publicó un artículo sobre el tema de las incrustaciones de oraciones."])},intern_work4:e=>{const{normalize:a}=e;return a(["Inyectar vitalidad juvenil continua al equipo."])},intern_work5:e=>{const{normalize:a}=e;return a(["Técnicas de cuantificación comparadas para comprimir LLM"])},intern_work6:e=>{const{normalize:a}=e;return a(["Creación y promoción de campañas atractivas para PromptPerfect"])},intern_work7:e=>{const{normalize:a}=e;return a(["JinaColBERT V2 desarrollado y mejorado rápidamente"])},recruiting_and_administrative_intern:e=>{const{normalize:a}=e;return a(["Practicante de Reclutamiento y Administración"])},researcher_intern:e=>{const{normalize:a}=e;return a(["Investigador en prácticas"])},self_motivated:e=>{const{normalize:a}=e;return a(["AUTO MOTIVADO"])},software_engineer_intern:e=>{const{normalize:a}=e;return a(["Pasante de ingeniería de software"])},spring:e=>{const{normalize:a}=e;return a(["Primavera"])},submit_application:e=>{const{normalize:a}=e;return a(["Comienza tu aventura con Jina AI"])},subtitle:e=>{const{normalize:a}=e;return a(["Nuestro programa de pasantías de tiempo completo brinda experiencia laboral práctica a través de proyectos de pasantías bien diseñados en una amplia gama de alcances."])},subtitle1:e=>{const{normalize:a}=e;return a(["Convocatoria mundial para estudiantes: Pasantes en investigación, ingeniería, marketing, ventas y más para ser pioneros juntos en la IA multimodal."])},summer:e=>{const{normalize:a}=e;return a(["Verano"])},title:e=>{const{normalize:a}=e;return a(["Programa de pasantías"])},who_do_we_look_for:e=>{const{normalize:a}=e;return a(["¿A quién buscamos?"])},who_do_we_look_for_desc:e=>{const{normalize:a}=e;return a(["Valoramos la diversidad y alentamos a los solicitantes de diversos perfiles y antecedentes a unirse a nuestro Programa de pasantías. Las oportunidades de pasantías se ofrecen en varios departamentos, incluidos ingeniería, diseño, gestión de productos, gestión de ventas y cuentas, marketing y gestión comunitaria."])},winter:e=>{const{normalize:a}=e;return a(["Invierno"])}},jcloud:{description:e=>{const{normalize:a}=e;return a(["Implemente un proyecto local como un servicio en la nube. Radicalmente fácil, sin sorpresas desagradables."])}},jerboa:{description:e=>{const{normalize:a}=e;return a(["Un perfeccionador experimental para LLM de código abierto"])}},jina:{description:e=>{const{normalize:a}=e;return a(["Cree aplicaciones de IA multimodales en la nube"])}},jina_chat:{description:e=>{const{normalize:a}=e;return a(["Más modalidad, más memoria, menos costo"])},example_1:e=>{const{normalize:a}=e;return a(["¿Quién eres?"])},example_2:e=>{const{normalize:a}=e;return a(["Soy un servicio de chat LLM creado por Jina AI"])}},lab_dialog:{GlobalQA:{description:e=>{const{normalize:a}=e;return a(["Presione la tecla '/' en cualquier página para abrir el cuadro de preguntas. Escriba su consulta y presione 'Entrar' para recibir respuestas directamente relacionadas con el contenido de la página. Esta característica está impulsada por PromptPerfect."])},title:e=>{const{normalize:a}=e;return a(["RAG en la página"])}},Recommender:{description:e=>{const{normalize:a}=e;return a(["Abra el cuadro de recomendación en cualquier página de noticias con 'Shift+2'. Seleccione el modelo de reranker para descubrir los 5 artículos principales relacionados con esa página de noticias. Disfrute de esta función en tiempo real, impulsada por nuestra API Reranker."])},title:e=>{const{normalize:a}=e;return a(["Artículo relacionado"])}},SceneXplainTooltip:{description:e=>{const{normalize:a}=e;return a(["Pase el cursor sobre cualquier imagen en las páginas de noticias o en nuestro catálogo de redacción para revelar la descripción de esa imagen. Las descripciones las calcula previamente SceneXplain y las incrustan en el atributo ALT de la imagen para mayor accesibilidad."])},title:e=>{const{normalize:a}=e;return a(["Subtítulos de imágenes"])}},explain:e=>{const{normalize:a}=e;return a(["Descubra funciones ocultas en nuestro sitio web"])}},landing_page:{also_available_on:e=>{const{normalize:a}=e;return a(["También disponible en los mercados."])},also_available_on1:e=>{const{normalize:a}=e;return a(["Disponible en los mercados de su nube empresarial"])},ask_how_your_question:e=>{const{normalize:a}=e;return a(["Por favor describe tu problema"])},autotune:e=>{const{normalize:a}=e;return a(["Ajuste fino automático"])},badge:{v2:e=>{const{normalize:a}=e;return a(["Lanzamiento v2!"])},v3:e=>{const{normalize:a}=e;return a(["¡Lanzamiento v3!"])}},build_js:e=>{const{normalize:a}=e;return a(["Construir con JavaScript"])},build_python:e=>{const{normalize:a}=e;return a(["Construir con Python"])},ccbync:e=>{const{normalize:a}=e;return a(["Este modelo tiene licencia CC BY-NC 4.0. Úselo a través de la API o nuestra imagen oficial de AWS/Azure, o comuníquese con el departamento de ventas para una implementación local."])},checkout_our_solution_for_you:e=>{const{normalize:a}=e;return a(["Descubra nuestra solución a su medida"])},coming_soon:e=>{const{normalize:a}=e;return a(["Muy pronto"])},contact_sales:e=>{const{normalize:a}=e;return a(["Contacto"])},copied_to_clipboard:e=>{const{normalize:a}=e;return a(["Copiado al portapapeles"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},developers:e=>{const{normalize:a}=e;return a(["Desarrolladores"])},developers_desc:e=>{const{normalize:a}=e;return a(["Libere todo el poder de la IA multimodal con tecnologías nativas de la nube de vanguardia e infraestructura de código abierto."])},download_pdf:e=>{const{normalize:a}=e;return a(["Descargar PDF"])},embedding_desc1:e=>{const{normalize:a}=e;return a(["Incrustaciones de contexto largo multilingües y multimodales de alto rendimiento para aplicaciones de búsqueda, RAG y agentes."])},embedding_paper_desc:e=>{const{normalize:a}=e;return a(["Jina Embeddings constituye un conjunto de modelos de incrustación de oraciones de alto rendimiento, expertos en traducir varias entradas textuales en representaciones numéricas, capturando así la esencia semántica del texto. Si bien estos modelos no están diseñados exclusivamente para la generación de texto, se destacan en aplicaciones como la recuperación densa y la similitud textual semántica. Este documento detalla el desarrollo de Jina Embeddings, comenzando con la creación de un conjunto de datos de pares y triples de alta calidad. Subraya el papel crucial de la limpieza de datos en la preparación del conjunto de datos, brinda información detallada sobre el proceso de capacitación del modelo y concluye con una evaluación integral del rendimiento utilizando Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:a}=e;return a(["Jina Embeddings: un novedoso conjunto de modelos de incrustación de oraciones de alto rendimiento"])},embeddings:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},enterprise:e=>{const{normalize:a}=e;return a(["Empresa"])},enterprise_desc:e=>{const{normalize:a}=e;return a(["Impulse su negocio con soluciones de IA multimodal escalables, seguras y personalizadas."])},enterprise_desc_v2:e=>{const{normalize:a}=e;return a(["Pruebe nuestros modelos de integración de clase mundial para mejorar sus sistemas de búsqueda y RAG. ¡Empiece con una prueba gratuita!"])},enterprise_desc_v3:e=>{const{normalize:a}=e;return a(["Nuestros modelos de frontera forman la base de búsqueda para sistemas RAG y de búsqueda empresarial de alta calidad."])},error:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Hubo un problema con la operación de búsqueda: ",n(r("mensaje"))])},find_your_portal:e=>{const{normalize:a}=e;return a(["Encuentre su Portal"])},finding_faq:e=>{const{normalize:a}=e;return a(["Generando respuestas basadas en el conocimiento de las preguntas frecuentes a continuación"])},for:e=>{const{normalize:a}=e;return a(["Para"])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para empresas"])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},get_api_now:e=>{const{normalize:a}=e;return a(["API"])},get_started:e=>{const{normalize:a}=e;return a(["Empezar"])},go_to_product_homepage:e=>{const{normalize:a}=e;return a(["Ir a la página de inicio del producto"])},how_to:e=>{const{normalize:a}=e;return a(["Cómo"])},include_experiment:e=>{const{normalize:a}=e;return a(["Incluye nuestros proyectos experimentales y archivados en la solución."])},join_community:e=>{const{normalize:a}=e;return a(["Comunidad"])},learn_more_embeddings:e=>{const{normalize:a}=e;return a(["Más información sobre incrustaciones"])},learn_more_reader:e=>{const{normalize:a}=e;return a(["Más información sobre el lector"])},learn_more_reranker:e=>{const{normalize:a}=e;return a(["Más información sobre el cambio de rango"])},llm:e=>{const{normalize:a}=e;return a(["Modelos de inclusión LLM"])},llm_desc:e=>{const{normalize:a}=e;return a(["Proporcionamos una colección de modelos de incrustación de oraciones de alto rendimiento, con entre 35 millones y 6 mil millones de parámetros. Son excelentes para mejorar la búsqueda neuronal, la reclasificación, la similitud de oraciones, las recomendaciones, etc. ¡Prepárate para mejorar tu experiencia de IA!"])},mentioned_products:e=>{const{normalize:a}=e;return a(["Productos mencionados:"])},mmstack:e=>{const{normalize:a}=e;return a(["Stack multimodal"])},mmstack_desc:e=>{const{normalize:a}=e;return a(["A lo largo de los años, hemos desarrollado una variedad de software de código abierto para ayudar a los desarrolladores a crear mejores aplicaciones GenAI y de búsqueda más rápido."])},models:e=>{const{normalize:a}=e;return a(["Modelos"])},more:e=>{const{normalize:a}=e;return a(["Más"])},multimodal:e=>{const{normalize:a}=e;return a(["Multimodal"])},multimodal_ai:e=>{const{normalize:a}=e;return a(["IA multimodal"])},new:e=>{const{normalize:a}=e;return a(["Nuevo"])},newsroom:e=>{const{normalize:a}=e;return a(["Sala de prensa"])},num_publications:e=>{const{normalize:a,interpolate:n,named:r}=e;return a([n(r("_total"))," publicaciones en total."])},"on-prem-deploy":e=>{const{normalize:a}=e;return a(["Implementación local"])},"on-premises":e=>{const{normalize:a}=e;return a(["En las instalaciones"])},opensource:e=>{const{normalize:a}=e;return a(["Código abierto"])},our_customer:e=>{const{normalize:a}=e;return a(["Nuestros clientes"])},our_customer_explain:e=>{const{normalize:a}=e;return a(["Empresas de todos los tamaños confían en la Fundación de búsqueda de Jina AI para potenciar sus herramientas y productos; usted también puede hacerlo."])},our_publications:e=>{const{normalize:a}=e;return a(["Nuestras Publicaciones"])},parameters:e=>{const{normalize:a}=e;return a(["Parámetros"])},podcast:e=>{const{normalize:a}=e;return a(["Podcast"])},power_users:e=>{const{normalize:a}=e;return a(["Usuarios avanzados"])},power_users_desc:e=>{const{normalize:a}=e;return a(["Ingeniería automática rápida para su productividad diaria."])},powered_by_promptperfect:e=>{const{normalize:a}=e;return a(['Desarrollado por la función "Optimización de solicitud" y "Solicitud como servicio" de PromptPerfect'])},pricing:e=>{const{normalize:a}=e;return a(["Precios"])},proposing_solution:e=>{const{normalize:a}=e;return a(["Proponiendo una solución basada en los productos Jina AI..."])},read_more:e=>{const{normalize:a}=e;return a(["Leer más"])},reader:e=>{const{normalize:a}=e;return a(["Lector"])},require_full_question:e=>{const{normalize:a}=e;return a(["Describe tu problema con más detalles."])},reranker:e=>{const{normalize:a}=e;return a(["reclasificador"])},researcher_desc:e=>{const{normalize:a}=e;return a(["Comprenda cómo se entrenaron nuestros modelos de búsqueda de frontera desde cero; consulte nuestras últimas publicaciones. ¡Conozca a nuestro equipo en EMNLP, SIGIR, ICLR, NeurIPS e ICML!"])},researchers:e=>{const{normalize:a}=e;return a(["Investigadores"])},sdk:e=>{const{normalize:a}=e;return a(["SDK"])},sdk_desc:e=>{const{normalize:a}=e;return a(["¿Quiere crear aplicaciones AIGC de alto nivel con las API de PromptPerfect, SceneXplain, BestBanner, JinaChat y Rationale? ¡Le tenemos cubierto! Pruebe nuestro SDK fácil de usar y comience en minutos."])},sdk_docs:e=>{const{normalize:a}=e;return a(["Leer documentos"])},sdk_example:e=>{const{normalize:a}=e;return a(["Ejemplo"])},search_foundation:e=>{const{normalize:a}=e;return a(["Fundación de búsqueda"])},source_code:e=>{const{normalize:a}=e;return a(["Código fuente"])},starter_kit:e=>{const{normalize:a}=e;return a(["Kit de inicio"])},supercharged1:e=>{const{normalize:a}=e;return a(["Sobrealimentado."])},tokenizer:e=>{const{normalize:a}=e;return a(["Segmentador"])},trusted_by:e=>{const{normalize:a}=e;return a(["DE CONFIANZA PARA"])},try_it_for_free:e=>{const{normalize:a}=e;return a(["¡Empiece de inmediato, sin necesidad de tarjeta de crédito ni registro!"])},try_our_saas:e=>{const{normalize:a}=e;return a(["Pruebe nuestra solución alojada, un reemplazo directo de la API integrada de OpenAI."])},your_portal_to:e=>{const{normalize:a}=e;return a(["Tu Portal a"])},your_search_foundation1:e=>{const{normalize:a}=e;return a(["Tu base de búsqueda"])}},langchain_serve:{description:e=>{const{normalize:a}=e;return a(["Aplicaciones Langchain en producción con Jina y FastAPI"])}},model_graph:{api:e=>{const{normalize:a}=e;return a(["API de inteligencia artificial de Jina"])},contact_sales_about_it:e=>{const{normalize:a}=e;return a(["Contacte con ventas al respecto"])},deploy_it_on:e=>{const{normalize:a}=e;return a(["Implementarlo en"])},description:e=>{const{normalize:a}=e;return a(["A lo largo de los años, hemos seguido ampliando los límites de la búsqueda. A continuación, se muestran los modelos que hemos lanzado: pase el cursor sobre cada uno o haga clic en él para ver más detalles."])},find_on_hf:e=>{const{normalize:a}=e;return a(["Encuéntrelo en HuggingFace"])},search_for:e=>{const{normalize:a}=e;return a(["Buscalo en nuestro sitio"])},search_models:e=>{const{normalize:a}=e;return a(["Filtrar por nombre de modelo"])},title:e=>{const{normalize:a}=e;return a(["Nuestros modelos de base de búsqueda"])},use_it_via:e=>{const{normalize:a}=e;return a(["Úselo a través de"])}},news_page:{back_to_newsroom:e=>{const{normalize:a}=e;return a(["Volver a la sala de prensa"])},categories:e=>{const{normalize:a}=e;return a(["Categorías"])},copy_link:e=>{const{normalize:a}=e;return a(["Copia el enlace a esta sección."])},in_this_article:e=>{const{normalize:a}=e;return a(["En este articulo"])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende más"])},news_not_found:e=>{const{normalize:a}=e;return a(["Artículo no encontrado"])},redirect_to_news:e=>{const{normalize:a}=e;return a(["Redirigiendo a la sala de redacción en 5 segundos..."])}},newsroom_page:{academic:e=>{const{normalize:a}=e;return a(["Académico"])},academic_research:e=>{const{normalize:a}=e;return a(["Publicaciones Académicas"])},author:e=>{const{normalize:a}=e;return a(["Filtrar por autor"])},description:e=>{const{normalize:a}=e;return a(["Lea las últimas noticias y actualizaciones de Jina AI."])},description1:e=>{const{normalize:a}=e;return a(["Creando innovaciones en IA, palabra a palabra."])},engineering_group:e=>{const{normalize:a}=e;return a(["Grupo de Ingeniería"])},engineering_group_date:e=>{const{normalize:a}=e;return a(["31 mayo, 2021"])},minutes_read:e=>{const{normalize:a}=e;return a(["minutos de lectura"])},most_recent_articles:e=>{const{normalize:a}=e;return a(["Artículos más recientes"])},news_description:e=>{const{normalize:a}=e;return a(['Para Jina 2.0, escuchamos a la comunidad. Verdaderamente, profundamente escuchado. "¿Cuáles son tus puntos débiles?" preguntamos, esperando ansiosamente comentarios valiosos'])},news_title:e=>{const{normalize:a}=e;return a(["Buscar todas las cosas: estamos organizando un concurso MEME para Jina 2.0"])},photos:e=>{const{normalize:a}=e;return a(["Fotos"])},product:e=>{const{normalize:a}=e;return a(["Filtrar por producto"])},search:e=>{const{normalize:a}=e;return a(["Buscar por título"])},tech_blog:e=>{const{normalize:a}=e;return a(["Blog de tecnología"])},title:e=>{const{normalize:a}=e;return a(["Sala de prensa"])},top_stories:e=>{const{normalize:a}=e;return a(["Historias destacadas"])}},notice:e=>{const{normalize:a}=e;return a(['🎉 ¡Nuestro primer libro, "Búsqueda neuronal: del prototipo a la producción con Jina" sale oficialmente hoy!'])},open_day:{description:e=>{const{normalize:a}=e;return a(["Una oportunidad exclusiva para obtener una visión privilegiada de Jina AI."])},engage:e=>{const{normalize:a}=e;return a(["Recomendamos encarecidamente un diálogo interactivo durante todo el día. El intercambio de pensamientos y perspectivas es invaluable para nosotros. Las colaboraciones potenciales derivadas de estas discusiones podrían contribuir significativamente a un futuro más integrado e innovador."])},engage_title:e=>{const{normalize:a}=e;return a(["Participa con nosotros"])},experience:e=>{const{normalize:a}=e;return a(["Hemos organizado un recorrido inmersivo de tres horas para nuestros huéspedes, disponible en alemán, inglés, francés, español, chino y ruso. El recorrido cubre una mirada en profundidad a nuestros avances en IA multimodal, nuestra perspectiva sobre el panorama de la IA, seguido de un examen detallado de proyectos específicos. Concluiremos con una discusión grupal para facilitar el intercambio de ideas y puntos de vista. Una opción de almuerzo también está disponible bajo petición."])},experience_title:e=>{const{normalize:a}=e;return a(["El viaje de un iniciado"])},group_size:e=>{const{normalize:a}=e;return a(["Número estimado de visitantes"])},impact:e=>{const{normalize:a}=e;return a(["Comprenda cómo nuestras contribuciones a la comunidad de código abierto y nuestro trabajo en tecnología de IA multimodal están estableciendo a Jina AI como un jugador influyente en la innovación de IA. Nuestro objetivo es desempeñar un papel importante en los procesos de toma de decisiones, asegurando que el avance de la tecnología de IA beneficie a todos."])},impact_title:e=>{const{normalize:a}=e;return a(["Impacto e influencia"])},introduction:e=>{const{normalize:a}=e;return a(["Jina AI se complace en abrir nuestras puertas a entidades y organizaciones estimadas interesadas en el progreso y el futuro de la Inteligencia Artificial. Extendemos esta oportunidad exclusiva para aquellos en la política, las ONG, las OSFL y los sectores de inversión para obtener una visión interna de nuestras operaciones y visiones aquí en nuestra sede de Berlín."])},motivation_min_length_v1:e=>{const{normalize:a}=e;return a(["Proporcione una motivación más detallada."])},motivation_placeholder_v2:e=>{const{normalize:a}=e;return a(["Compartir tus motivaciones nos ayudará a mejorar tu experiencia."])},motivation_to_attend_v2:e=>{const{normalize:a}=e;return a(["¿Por qué te interesa nuestra jornada de puertas abiertas?"])},one_hour:e=>{const{normalize:a}=e;return a(["1 hora"])},organization:e=>{const{normalize:a}=e;return a(["Organización"])},organization_website:e=>{const{normalize:a}=e;return a(["Sitio web de la organización"])},organization_website_placeholder:e=>{const{normalize:a}=e;return a(["URL de la página de inicio de su organización o del perfil de LinkedIn"])},preferred_date:e=>{const{normalize:a}=e;return a(["Fecha preferida"])},preferred_language:e=>{const{normalize:a}=e;return a(["Idioma preferido del tour"])},preferred_products:e=>{const{normalize:a}=e;return a(["¿En qué productos estás interesado?"])},subtitle:e=>{const{normalize:a}=e;return a(["Un vistazo al futuro de la IA multimodal"])},title:e=>{const{normalize:a}=e;return a(["Dia abierto"])},tutor_subtitle:e=>{const{normalize:a}=e;return a(["Un recorrido de tres horas cuidadosamente seleccionado que lo acerca al corazón del trabajo innovador de Jina AI en tecnología de IA multimodal."])},tutor_title:e=>{const{normalize:a}=e;return a(["Una inmersión profunda exclusiva en"])},vision:e=>{const{normalize:a}=e;return a(["Únase a nosotros para obtener una descripción general completa del panorama de la IA tal como lo vemos. Nuestra discusión se centrará en el potencial de los modelos de lenguaje grande, la IA multimodal y el impacto de la tecnología de código abierto en la configuración del futuro de la innovación global."])},vision_title:e=>{const{normalize:a}=e;return a(["Nuestra visión para el futuro"])}},open_day_faq:{answer1:e=>{const{normalize:a}=e;return a(["Ofrecemos tours en alemán, inglés, francés, español, chino y ruso."])},answer2:e=>{const{normalize:a}=e;return a(["El recorrido suele durar aproximadamente tres horas."])},answer3:e=>{const{normalize:a}=e;return a(["El almuerzo es opcional y se puede organizar bajo petición."])},answer4:e=>{const{normalize:a}=e;return a(["Nuestra Jornada de Puertas Abiertas está diseñada principalmente para grupos profesionales, como políticos, ONG, OSFL e inversores. Sin embargo, ocasionalmente hacemos excepciones según el perfil de la persona."])},answer5:e=>{const{normalize:a}=e;return a(["Podemos acomodar una variedad de tamaños de grupo. Indique el tamaño de su grupo en el formulario de registro y le confirmaremos los detalles."])},answer6:e=>{const{normalize:a}=e;return a(["Hay una sección en el formulario de registro donde puede especificar sus áreas de interés o cualquier solicitud especial. Haremos todo lo posible para adaptar el recorrido de acuerdo a sus necesidades."])},answer7:e=>{const{normalize:a}=e;return a(["En este momento, solo ofrecemos tours en nuestra sede de Berlín ubicada en Kreuzberg. Nuestras oficinas de Beijing y Shenzhen no están abiertas actualmente para visitas."])},question1:e=>{const{normalize:a}=e;return a(["¿Qué idiomas ofrecen para el tour?"])},question2:e=>{const{normalize:a}=e;return a(["¿Cuál es la duración del recorrido?"])},question3:e=>{const{normalize:a}=e;return a(["¿Se proporciona almuerzo?"])},question4:e=>{const{normalize:a}=e;return a(["¿Pueden registrarse personas para la Jornada de Puertas Abiertas?"])},question5:e=>{const{normalize:a}=e;return a(["¿De cuántas personas puede estar formado un grupo para la Jornada de Puertas Abiertas?"])},question6:e=>{const{normalize:a}=e;return a(["¿Cómo puedo especificar áreas de interés para el tour?"])},question7:e=>{const{normalize:a}=e;return a(["¿Hay recorridos disponibles en sus oficinas de Beijing o Shenzhen?"])}},open_gpt:{description:e=>{const{normalize:a}=e;return a(["Un marco de servicio nativo de la nube de código abierto de grandes modelos multimodales"])}},paywall:{free_hour_consult:e=>{const{normalize:a}=e;return a(["Consulta gratuita de 1 hora"])},free_hour_consult_description:e=>{const{normalize:a}=e;return a(["Una hora de consulta gratuita con nuestros equipos de productos e ingeniería para analizar las mejores prácticas para su caso de uso."])},full_commercial:e=>{const{normalize:a}=e;return a(["Uso comercial sin restricciones"])},full_commercial_description:e=>{const{normalize:a}=e;return a(["Puede utilizar la API para fines comerciales sin ninguna restricción."])},higher_limit:e=>{const{normalize:a}=e;return a(["Límite de tasa mucho más alto"])},higher_limit_description:e=>{const{normalize:a}=e;return a(["Obtén hasta 1000 RPM para r.jina.ai y 100 RPM para s.jina.ai; más detalles en la sección de límite de velocidad."])},no_commercial:e=>{const{normalize:a}=e;return a(["Sólo para uso no comercial (CC-BY-NC)"])},no_commercial_description:e=>{const{normalize:a}=e;return a(["Puede utilizar la API únicamente con fines no comerciales. Para uso comercial, recargue su clave API."])},priority_support:e=>{const{normalize:a}=e;return a(["Atención al cliente prioritaria"])},priority_support_description:e=>{const{normalize:a}=e;return a(["Respuesta por correo electrónico garantizada dentro de las 24 horas, incluidos los fines de semana."])}},powered_by:e=>{const{normalize:a}=e;return a(["Energizado por"])},print:e=>{const{normalize:a}=e;return a(["Imprimir"])},project_status:{archived:e=>{const{normalize:a}=e;return a(["Archivado"])},cloud_native:e=>{const{normalize:a}=e;return a(["Nativo de la nube"])},core:e=>{const{normalize:a}=e;return a(["Centro"])},data_structure:e=>{const{normalize:a}=e;return a(["Estructura de datos"])},embedding_serving:e=>{const{normalize:a}=e;return a(["Incrustar servicio"])},embedding_tuning:e=>{const{normalize:a}=e;return a(["Ajuste de incrustación"])},graduated:e=>{const{normalize:a}=e;return a(["Graduado"])},incubating:e=>{const{normalize:a}=e;return a(["incubando"])},kubernetes:e=>{const{normalize:a}=e;return a(["Kubernetes"])},large_size_model:e=>{const{normalize:a}=e;return a(["Modelo de gran tamaño"])},linux_foundation:e=>{const{normalize:a}=e;return a(["Fundación Linux"])},llm1:e=>{const{normalize:a}=e;return a(["LLMOps"])},mid_size_model:e=>{const{normalize:a}=e;return a(["Modelo de tamaño mediano"])},model_serving:e=>{const{normalize:a}=e;return a(["Servicio modelo"])},model_tuning:e=>{const{normalize:a}=e;return a(["Ajuste del modelo"])},observability:e=>{const{normalize:a}=e;return a(["Observabilidad"])},orchestration:e=>{const{normalize:a}=e;return a(["Orquestación"])},prompt_serving:e=>{const{normalize:a}=e;return a(["Servicio rápido"])},prompt_tuning:e=>{const{normalize:a}=e;return a(["Sintonización rápida"])},rag1:e=>{const{normalize:a}=e;return a(["TRAPO"])},sandbox:e=>{const{normalize:a}=e;return a(["Salvadera"])},small_size_model:e=>{const{normalize:a}=e;return a(["Modelo de tamaño pequeño"])},vector_database:e=>{const{normalize:a}=e;return a(["Base de datos de vectores"])},vector_store:e=>{const{normalize:a}=e;return a(["Tienda de vectores"])}},prompt_perfect:{description:e=>{const{normalize:a}=e;return a(["Herramienta principal para ingeniería rápida"])},image_model:e=>{const{normalize:a}=e;return a(["Modelos de imagen"])},intro:e=>{const{normalize:a}=e;return a(["Herramienta principal para ingeniería rápida"])},intro1:e=>{const{normalize:a}=e;return a(["La principal herramienta para una ingeniería rápida"])},optimized:e=>{const{normalize:a}=e;return a(["Su tarea es ser mi compañero de lluvia de ideas y proporcionar ideas y sugerencias creativas para un tema o problema determinado. Su respuesta debe incluir ideas originales, únicas y relevantes que puedan ayudar a resolver el problema o explorar más a fondo el tema de una manera interesante. Tenga en cuenta que su respuesta también debe tener en cuenta los requisitos o limitaciones específicos de la tarea."])},optimized_title:e=>{const{normalize:a}=e;return a(["Mensaje optimizado"])},original:e=>{const{normalize:a}=e;return a(["Tu papel es ser mi compañero de intercambio de ideas."])},original_title:e=>{const{normalize:a}=e;return a(["Aviso original"])},text_model:e=>{const{normalize:a}=e;return a(["Modelos de texto"])}},promptperfect:{features:[{description:e=>{const{normalize:a}=e;return a(["Cambie fácilmente entre generación de contenido y optimización rápida, lleve la calidad de su contenido al siguiente nivel."])},name:e=>{const{normalize:a}=e;return a(["Asistente"])},title:e=>{const{normalize:a}=e;return a(["Dosis diaria de productividad."])}},{description:e=>{const{normalize:a}=e;return a(["¿No sabes cómo escribir una instrucción eficaz? Simplemente introduzca su idea, con un clic, obtenga una mejor instrucción."])},name:e=>{const{normalize:a}=e;return a(["Optimización inmediata"])},title:e=>{const{normalize:a}=e;return a(["Mejores insumos, mejores resultados"])}},{description:e=>{const{normalize:a}=e;return a(["Comprenda la vibra de cada modelo de IA comparando su resultado del mismo mensaje."])},name:e=>{const{normalize:a}=e;return a(["Comparar modelos"])},title:e=>{const{normalize:a}=e;return a(["Comparación de modelos lado a lado."])}},{description:e=>{const{normalize:a}=e;return a(["Quizás la forma más sencilla de implementar sus indicaciones como API para la integración."])},name:e=>{const{normalize:a}=e;return a(["Implementar indicaciones"])},title:e=>{const{normalize:a}=e;return a(["Sin operaciones, solo despliegue."])}},{description:e=>{const{normalize:a}=e;return a(["Personalice sus propios agentes LLM e inicie una simulación de múltiples agentes. Vea cómo colaboran o compiten en un entorno virtual para alcanzar la meta."])},name:e=>{const{normalize:a}=e;return a(["Multiagente"])},title:e=>{const{normalize:a}=e;return a(["Explora cómo colaboran los agentes"])}}],get_started:e=>{const{normalize:a}=e;return a(["Comience con PromptPerfect"])}},purchase:{success:e=>{const{normalize:a}=e;return a(["Gracias por su compra!"])},success_caption:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Hemos completado su pedido a las ",n(r("_purchasedTime")),". ¡Su clave API está lista para usar!"])}},purchase_now:e=>{const{normalize:a}=e;return a(["Comprar ahora"])},rate_limit:{batch_explain:e=>{const{normalize:a}=e;return a(["Esta API admite operaciones por lotes, lo que permite hasta 512 documentos por solicitud, cada uno de los cuales contiene hasta 8192 tokens. El uso inteligente de las operaciones por lotes puede reducir significativamente la cantidad de solicitudes y mejorar el rendimiento."])},depends:e=>{const{normalize:a}=e;return a(["depende del tamaño de entrada"])},description:e=>{const{normalize:a}=e;return a(["Descripción"])},embeddings:e=>{const{normalize:a}=e;return a(["Convertir texto/imágenes en vectores de longitud fija"])},endpoint:e=>{const{normalize:a}=e;return a(["Punto final de API"])},explain:e=>{const{normalize:a}=e;return a(["Los límites de velocidad se controlan de dos maneras: <b>RPM</b> (solicitudes por minuto) y <b>TPM</b> (tokens por minuto). Los límites se aplican por IP y se pueden alcanzar en función del umbral que se alcance primero (RPM o TPM)."])},gjinaai:e=>{const{normalize:a}=e;return a(["Fundamentar una declaración con conocimiento web"])},input_token_counting:e=>{const{normalize:a}=e;return a(["Cuente la cantidad de tokens en la solicitud de entrada."])},latency:e=>{const{normalize:a}=e;return a(["Latencia media"])},no_token_counting:e=>{const{normalize:a}=e;return a(["El token no se cuenta como uso."])},output_token_counting:e=>{const{normalize:a}=e;return a(["Cuente la cantidad de tokens en la respuesta de salida."])},premium_rate:e=>{const{normalize:a}=e;return a(["Con potencial para límites de tarifas más altos"])},product:e=>{const{normalize:a}=e;return a(["Producto"])},requestType:e=>{const{normalize:a}=e;return a(["Solicitud Permitida"])},reranker:e=>{const{normalize:a}=e;return a(["Clasificar documentos por consulta"])},rjinaai:e=>{const{normalize:a}=e;return a(["Convertir URL a texto compatible con LLM"])},sjinaai:e=>{const{normalize:a}=e;return a(["Busque en la web y convierta los resultados en texto compatible con LLM"])},tbd:e=>{const{normalize:a}=e;return a(["Por determinar"])},title:e=>{const{normalize:a}=e;return a(["Límite de velocidad"])},tokenCounting:e=>{const{normalize:a}=e;return a(["Recuento de uso de tokens"])},tokenizer:e=>{const{normalize:a}=e;return a(["Tokenizar y segmentar textos largos"])},total_token_counting:e=>{const{normalize:a}=e;return a(["Cuente el número total de tokens en todo el proceso."])},understanding:e=>{const{normalize:a}=e;return a(["Entender el límite de velocidad"])},understanding_description:e=>{const{normalize:a}=e;return a(["Los límites de velocidad son la cantidad máxima de solicitudes que se pueden realizar a una API en un minuto por dirección IP (RPM). Obtenga más información sobre los límites de velocidad para cada producto y nivel a continuación."])},wAPIkey:e=>{const{normalize:a}=e;return a(["con clave API"])},wPremium:e=>{const{normalize:a}=e;return a(["con clave API Premium"])},woAPIkey:e=>{const{normalize:a}=e;return a(["Sin clave API"])}},rationale:{decision:e=>{const{normalize:a}=e;return a(["Decisión"])},description:e=>{const{normalize:a}=e;return a(["Las mejores herramientas de toma de decisiones de IA"])},intro:e=>{const{normalize:a}=e;return a(["Ver las dos caras de la moneda, tomar decisiones racionales"])}},reader:{beta:e=>{const{normalize:a}=e;return a(["Experimental"])},better_input:e=>{const{normalize:a}=e;return a(["Mejore la calidad de la entrada desde el principio"])},better_input_description:e=>{const{normalize:a}=e;return a(["¿Tiene problemas con la salida de su agente o del sistema RAG? Puede deberse a una mala calidad de entrada."])},check_price_table:e=>{const{normalize:a}=e;return a(["Consulte la tabla de precios"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},demo:{advanced_usage:e=>{const{normalize:a}=e;return a(["Uso avanzado"])},ask_llm:e=>{const{normalize:a}=e;return a(["Pregunte a LLM sin y con base de búsqueda"])},ask_llm_directly:e=>{const{normalize:a}=e;return a(["Pregúntele a LLM directamente"])},ask_llm_with_search_grounding:e=>{const{normalize:a}=e;return a(["Pregúntele a LLM con base de búsqueda"])},ask_question:e=>{const{normalize:a}=e;return a(["Haz una pregunta"])},ask_question_hint:e=>{const{normalize:a}=e;return a(["Ingrese una pregunta y combínela con el contenido obtenido para que LLM genere una respuesta."])},basic_usage:e=>{const{normalize:a}=e;return a(["Uso básico"])},basic_usage1:e=>{const{normalize:a}=e;return a(["Leer una URL"])},basic_usage2:e=>{const{normalize:a}=e;return a(["Buscar una consulta"])},basic_usage3:e=>{const{normalize:a}=e;return a(["Toma de tierra"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},fetch:e=>{const{normalize:a}=e;return a(["Obtener contenido"])},get_response:e=>{const{normalize:a}=e;return a(["Obtener una respuesta"])},headers:{auth_token:e=>{const{normalize:a}=e;return a(["Agregue clave API para un límite de tasa más alto"])},auth_token_explain:e=>{const{normalize:a}=e;return a(["Ingrese su clave API de Jina para acceder a un límite de tasa más alto. Para obtener la información más reciente sobre el límite de tarifas, consulte la siguiente tabla."])},browser_locale:e=>{const{normalize:a}=e;return a(["Configuración regional del navegador"])},browser_locale_explain:e=>{const{normalize:a}=e;return a(["Controla la configuración regional del navegador para mostrar la página. Muchos sitios web ofrecen contenido diferente según la configuración regional."])},default:e=>{const{normalize:a}=e;return a(["Por defecto"])},default_explain:e=>{const{normalize:a}=e;return a(["La canalización predeterminada optimizada para la mayoría de los sitios web y la entrada LLM."])},file:e=>{const{normalize:a}=e;return a(["Archivo PDF/HTML local"])},file_explain:e=>{const{normalize:a}=e;return a(["Utilice Reader en sus archivos PDF y HTML locales cargándolos. Solo se admiten archivos PDF y HTML."])},html:e=>{const{normalize:a}=e;return a(["HTML"])},html_explain:e=>{const{normalize:a}=e;return a(["Devuelve documentElement.outerHTML."])},image_caption:e=>{const{normalize:a}=e;return a(["Captura de imagen"])},image_caption_explain:e=>{const{normalize:a}=e;return a(["Subtitula todas las imágenes en la URL especificada, agregando 'Imagen [idx]: [caption]' como etiqueta alternativa para aquellas que no tienen una. Esto permite que los LLM posteriores interactúen con las imágenes en actividades como razonar y resumir."])},images_summary:e=>{const{normalize:a}=e;return a(["Reúna todas las imágenes al final"])},images_summary_explain:e=>{const{normalize:a}=e;return a(['Se creará una sección de "Imágenes" al final. Esto brinda a los LLM posteriores una descripción general de todos los elementos visuales de la página, lo que puede mejorar el razonamiento.'])},json_response:e=>{const{normalize:a}=e;return a(["Respuesta JSON"])},json_response_explain:e=>{const{normalize:a}=e;return a(["La respuesta estará en formato JSON y contendrá la URL, el título, el contenido y la marca de tiempo (si está disponible). En el modo de búsqueda, devuelve una lista de cinco entradas, cada una de las cuales sigue la estructura JSON descrita."])},links_summary:e=>{const{normalize:a}=e;return a(["Reúna todos los enlaces al final"])},links_summary_explain:e=>{const{normalize:a}=e;return a(['Al final se creará una sección de "Botones y enlaces". Esto ayuda a los LLM posteriores o agentes web a navegar por la página o realizar más acciones.'])},markdown:e=>{const{normalize:a}=e;return a(["Reducción"])},markdown_explain:e=>{const{normalize:a}=e;return a(["Devuelve el markdown directamente desde el HTML, omitiendo el filtrado de legibilidad."])},mode:e=>{const{normalize:a}=e;return a(["Modo de lectura o búsqueda"])},mode_explain:e=>{const{normalize:a}=e;return a(["El modo de lectura sirve para acceder al contenido de una URL, mientras que el modo de búsqueda le permite buscar una consulta en la web, aplicando el modo de lectura a cada URL de resultado de búsqueda."])},no_cache:e=>{const{normalize:a}=e;return a(["Omitir el caché"])},no_cache_explain:e=>{const{normalize:a}=e;return a(["Nuestro servidor API almacena en caché los contenidos del modo Lectura y Búsqueda durante un cierto período de tiempo. Para omitir este caché, establezca este encabezado en verdadero."])},pageshot:e=>{const{normalize:a}=e;return a(["Captura de página"])},pageshot_explain:e=>{const{normalize:a}=e;return a(["Devuelve la URL de la imagen de la captura de pantalla de la página completa (con el máximo esfuerzo)."])},post_with_url:e=>{const{normalize:a}=e;return a(["Usar el método POST"])},post_with_url_explain:e=>{const{normalize:a}=e;return a(["Utilice POST en lugar del método GET con una URL pasada en el cuerpo. Útil para crear SPA con enrutamiento basado en hash."])},proxy_server:e=>{const{normalize:a}=e;return a(["Utilice un servidor proxy"])},proxy_server_explain:e=>{const{normalize:a}=e;return a(["Nuestro servidor API puede utilizar su proxy para acceder a las URL, lo cual resulta útil para páginas a las que solo se puede acceder a través de servidores proxy específicos."])},references:e=>{const{normalize:a}=e;return a(["Referencias"])},references_explain:e=>{const{normalize:a}=e;return a(["Lista separada por comas de referencias proporcionadas por el usuario (URL)"])},return_format:e=>{const{normalize:a}=e;return a(["Formato del contenido"])},return_format_explain:e=>{const{normalize:a}=e;return a(["Puede controlar el nivel de detalle de la respuesta para evitar el filtrado excesivo. La canalización predeterminada está optimizada para la mayoría de los sitios web y las entradas de LLM."])},screenshot:e=>{const{normalize:a}=e;return a(["Captura de pantalla"])},screenshot_explain:e=>{const{normalize:a}=e;return a(["Devuelve la URL de la imagen de la primera pantalla."])},set_cookie:e=>{const{normalize:a}=e;return a(["Cookie de reenvío"])},set_cookie_explain:e=>{const{normalize:a}=e;return a(["Nuestro servidor API puede reenviar su configuración de cookies personalizada al acceder a la URL, lo cual es útil para páginas que requieren autenticación adicional. Tenga en cuenta que las solicitudes con cookies no se almacenarán en caché."])},site_selector:e=>{const{normalize:a}=e;return a(["Búsqueda en el sitio"])},site_selector_explain:e=>{const{normalize:a}=e;return a(["Devuelve los resultados de búsqueda solo del sitio web o dominio especificado. Por defecto busca en toda la web."])},stream_mode:e=>{const{normalize:a}=e;return a(["Modo de transmisión"])},stream_mode_explain:e=>{const{normalize:a}=e;return a(["El modo de transmisión es beneficioso para páginas de destino grandes, ya que permite más tiempo para que la página se represente por completo. Si el modo estándar genera contenido incompleto, considere usar el modo Stream."])},target_selector:e=>{const{normalize:a}=e;return a(["Selector de objetivos"])},target_selector_explain:e=>{const{normalize:a}=e;return a(["Proporcione un selector de CSS para centrarse en una parte más específica de la página. Útil cuando el contenido deseado no se muestra en la configuración predeterminada."])},text:e=>{const{normalize:a}=e;return a(["Texto"])},text_explain:e=>{const{normalize:a}=e;return a(["Devuelve documento.body.innerText."])},wait_for_selector:e=>{const{normalize:a}=e;return a(["Esperar al selector"])},wait_for_selector_explain:e=>{const{normalize:a}=e;return a(["Espere a que aparezca un elemento específico antes de regresar. Útil cuando el contenido deseado no se muestra en la configuración predeterminada."])},x_timeout:e=>{const{normalize:a}=e;return a(["Se acabó el tiempo"])},x_timeout_explain:e=>{const{normalize:a}=e;return a(["Tiempo máximo de espera para que se cargue la página web. Tenga en cuenta que NO es el tiempo total de toda la solicitud de principio a fin."])}},how_to_stream:e=>{const{normalize:a}=e;return a(["Para procesar el contenido a medida que esté disponible, configure el encabezado de la solicitud en modo de transmisión. Esto minimiza el tiempo hasta que se recibe el primer byte. Ejemplo en curl:"])},how_to_use1:e=>{const{normalize:a}=e;return a(["Agregue https://r.jina.ai/ a cualquier URL en su código o herramienta donde se espera acceso LLM. Esto devolverá el contenido principal de la página en un texto limpio y compatible con LLM."])},how_to_use2:e=>{const{normalize:a}=e;return a(["Agregue https://s.jina.ai/ a su consulta. Esto llamará al motor de búsqueda y arrojará los 5 primeros resultados con sus URL y contenidos, cada uno en texto limpio y compatible con LLM."])},how_to_use3:e=>{const{normalize:a}=e;return a(["Agregue https://g.jina.ai/ a su declaración. Esto llamará al motor de juicio y devolverá un porcentaje de veracidad, un valor booleano que indica si la declaración es verdadera o falsa, un resumen de la razón y una lista de referencias."])},key_required:e=>{const{normalize:a}=e;return a(["Se requiere una clave API para utilizar este punto final"])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende más"])},open:e=>{const{normalize:a}=e;return a(["Abrir en una nueva pestaña"])},raw_html:e=>{const{normalize:a}=e;return a(["HTML sin formato"])},reader_output:e=>{const{normalize:a}=e;return a(["Salida del lector"])},reader_response:e=>{const{normalize:a}=e;return a(["La respuesta del lector"])},reader_search_hint:e=>{const{normalize:a}=e;return a(["Si utiliza esta URL en el código, no olvide codificar la URL."])},reader_url:e=>{const{normalize:a}=e;return a(["URL del lector"])},reader_url_hint:e=>{const{normalize:a}=e;return a(["Haga clic a continuación para obtener el contenido a través de nuestra Reader API"])},requires_post_method:e=>{const{normalize:a}=e;return a(["Esta función requiere el método POST. Al cargar el archivo local, el método POST se activará automáticamente."])},search_params:e=>{const{normalize:a}=e;return a(["Parámetros de búsqueda/encabezados"])},search_query_rewrite:e=>{const{normalize:a}=e;return a(["Tenga en cuenta que, a diferencia de la demostración que se muestra arriba, en la práctica no busca la pregunta original en la web para fundamentarse. Lo que la gente suele hacer es reescribir la pregunta original o utilizar preguntas de múltiples saltos. Leen los resultados recuperados y luego generan consultas adicionales para recopilar más información según sea necesario antes de llegar a una respuesta final."])},select_mode:e=>{const{normalize:a}=e;return a(["Seleccionar modo"])},show_read_demo:e=>{const{normalize:a}=e;return a(["Vea cómo Reader lee una URL"])},show_search_demo:e=>{const{normalize:a}=e;return a(["Vea cómo Reader busca en la web"])},slow_warning:e=>{const{normalize:a}=e;return a(["Esto puede tardar hasta 30 segundos y cuesta hasta 300.000 tokens por solicitud."])},standard_usage:e=>{const{normalize:a}=e;return a(["Uso estándar"])},stream_mode:e=>{const{normalize:a}=e;return a(["Modo de transmisión"])},stream_mode_explain:e=>{const{normalize:a}=e;return a(["El modo de transmisión es útil cuando la página de destino es grande para representar. Si encuentra que el modo estándar le proporciona contenido incompleto, pruebe el modo de transmisión."])},stream_mode_explain1:e=>{const{normalize:a}=e;return a(["El modo Streaming es útil cuando descubre que el modo estándar proporciona un resultado incompleto. Esto se debe a que el modo de transmisión esperará un poco más hasta que la página se represente por completo. Utilice el encabezado de aceptación para alternar el modo de transmisión:"])},tagline:e=>{const{normalize:a}=e;return a(["Pruebe la demostración"])},try_demo:e=>{const{normalize:a}=e;return a(["Manifestación"])},use_headers:e=>{const{normalize:a}=e;return a(["El comportamiento de la API Reader se puede controlar con encabezados de solicitud. Aquí hay una lista completa de encabezados compatibles."])},waiting_for_reader:e=>{const{normalize:a}=e;return a(["Esperando primero el resultado de Reader API..."])},warn_grounding_message:e=>{const{normalize:a}=e;return a(["Este proceso puede tardar hasta 30 segundos y consumir hasta 300 000 tokens por solicitud de conexión a tierra. Algunos navegadores pueden finalizar la solicitud debido a la larga latencia, por lo que recomendamos copiar el código y ejecutarlo desde su terminal."])},warn_grounding_title:e=>{const{normalize:a}=e;return a(["Alta latencia y uso de tokens"])},your_query:e=>{const{normalize:a}=e;return a(["Ingresa tu consulta"])},your_query_hint:e=>{const{normalize:a}=e;return a(["Escriba una pregunta que requiera la información más reciente o conocimiento mundial."])},your_url:e=>{const{normalize:a}=e;return a(["Introduce tu URL"])},your_url_hint:e=>{const{normalize:a}=e;return a(["Haga clic a continuación para obtener el código fuente de la página directamente"])}},description:e=>{const{normalize:a}=e;return a(["Lea las URL o busque en la web y obtenga una mejor base para los LLM."])},dont_panic_api_key_is_free:e=>{const{normalize:a}=e;return a(["¡No entrar en pánico! ¡Cada nueva clave API contiene un millón de tokens gratis!"])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["La API Reader es gratuita y no requiere una clave API. Simplemente anteponga 'https://r.jina.ai/' a su URL."])},answer10:e=>{const{normalize:a}=e;return a(["No, la API Reader solo puede procesar contenido de URL de acceso público."])},answer11:e=>{const{normalize:a}=e;return a(["Si solicita la misma URL en un plazo de 5 minutos, la API de Reader devolverá el contenido almacenado en caché."])},answer12:e=>{const{normalize:a}=e;return a(["Lamentablemente no."])},answer13:e=>{const{normalize:a}=e;return a(["Sí, puede utilizar la compatibilidad con PDF nativo del Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) o utilizar la versión HTML de arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)"])},answer14:e=>{const{normalize:a}=e;return a(["Reader subtitula todas las imágenes en la URL especificada y agrega `Imagen [idx]: [caption]` como etiqueta alt (si inicialmente carecen de una). Esto permite a los LLM posteriores interactuar con las imágenes para razonar, resumir, etc."])},answer15:e=>{const{normalize:a}=e;return a(["La API Reader está diseñada para ser altamente escalable. Se escala automáticamente en función del tráfico en tiempo real y las solicitudes de concurrencia máxima ahora son de alrededor de 4000. Lo mantenemos activamente como uno de los productos principales de Jina AI. Así que siéntete libre de usarlo en producción."])},answer16:e=>{const{normalize:a}=e;return a(["Encuentre la información más reciente sobre el límite de tarifas en la siguiente tabla. Tenga en cuenta que estamos trabajando activamente para mejorar el límite de velocidad y el rendimiento de Reader API; la tabla se actualizará en consecuencia."])},answer2:e=>{const{normalize:a}=e;return a(["La API Reader utiliza un proxy para recuperar cualquier URL y representar su contenido en un navegador para extraer contenido principal de alta calidad."])},answer3:e=>{const{normalize:a}=e;return a(["Sí, la API Reader es de código abierto y está disponible en el repositorio GitHub de Jina AI."])},answer4:e=>{const{normalize:a}=e;return a(["La API Reader generalmente procesa las URL y devuelve el contenido en 2 segundos, aunque las páginas complejas o dinámicas pueden requerir más tiempo."])},answer5:e=>{const{normalize:a}=e;return a(["El scraping puede ser complicado y poco confiable, particularmente con páginas complejas o dinámicas. Reader API proporciona una salida optimizada y confiable de texto limpio y listo para LLM."])},answer6:e=>{const{normalize:a}=e;return a(["La API Reader devuelve contenido en el idioma original de la URL. No proporciona servicios de traducción."])},answer7:e=>{const{normalize:a}=e;return a(["Si tiene problemas de bloqueo, comuníquese con nuestro equipo de soporte para obtener ayuda y resolución."])},answer8:e=>{const{normalize:a}=e;return a(["Si bien está diseñada principalmente para páginas web, la API Reader puede extraer contenido de archivos PDF vistos en formato HTML en sitios web como arXiv, pero no está optimizada para la extracción general de PDF."])},answer9:e=>{const{normalize:a}=e;return a(["Actualmente, Reader API no procesa contenido multimedia, pero futuras mejoras incluirán subtítulos de imágenes y resúmenes de videos."])},question1:e=>{const{normalize:a}=e;return a(["¿Cuáles son los costos asociados con el uso de Reader API?"])},question10:e=>{const{normalize:a}=e;return a(["¿Es posible utilizar la API de Reader en archivos HTML locales?"])},question11:e=>{const{normalize:a}=e;return a(["¿Reader API almacena en caché el contenido?"])},question12:e=>{const{normalize:a}=e;return a(["¿Puedo usar Reader API para acceder al contenido tras un inicio de sesión?"])},question13:e=>{const{normalize:a}=e;return a(["¿Puedo utilizar la API de Reader para acceder a PDF en arXiv?"])},question14:e=>{const{normalize:a}=e;return a(["¿Cómo funciona el título de imagen en Reader?"])},question15:e=>{const{normalize:a}=e;return a(["¿Cuál es la escalabilidad del Reader? ¿Puedo usarlo en producción?"])},question16:e=>{const{normalize:a}=e;return a(["¿Cuál es el límite de velocidad de la API Reader?"])},question2:e=>{const{normalize:a}=e;return a(["¿Cómo funciona la API Reader?"])},question3:e=>{const{normalize:a}=e;return a(["¿La API Reader es de código abierto?"])},question4:e=>{const{normalize:a}=e;return a(["¿Cuál es la latencia típica de la API Reader?"])},question5:e=>{const{normalize:a}=e;return a(["¿Por qué debería utilizar Reader API en lugar de raspar la página yo mismo?"])},question6:e=>{const{normalize:a}=e;return a(["¿La API Reader admite varios idiomas?"])},question7:e=>{const{normalize:a}=e;return a(["¿Qué debo hacer si un sitio web bloquea la API de Reader?"])},question8:e=>{const{normalize:a}=e;return a(["¿Puede la API Reader extraer contenido de archivos PDF?"])},question9:e=>{const{normalize:a}=e;return a(["¿Puede la API Reader procesar contenido multimedia de páginas web?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con los lectores"])}},fast:e=>{const{normalize:a}=e;return a(["Rápido"])},fast_stream:e=>{const{normalize:a}=e;return a(["Transmisión de datos inmediata"])},fast_stream_description:e=>{const{normalize:a}=e;return a(["¿Necesita datos rápidamente? Nuestra API Reader puede transmitir datos para minimizar la latencia."])},free:e=>{const{normalize:a}=e;return a(["Siempre libre"])},free_description:e=>{const{normalize:a}=e;return a(["¡La API del lector es gratuita! No requiere tarjeta de crédito ni secreto de API. No consumirá su cuota de tokens."])},is_free:e=>{const{normalize:a}=e;return a(["¿La mejor parte? ¡Es gratis!"])},is_free_description:e=>{const{normalize:a}=e;return a(["Reader API está disponible de forma gratuita y ofrece límites de tarifas y precios flexibles. Construido sobre una infraestructura escalable, ofrece alta accesibilidad, simultaneidad y confiabilidad. Nos esforzamos por ser su solución de conexión a tierra preferida para sus LLM."])},open:e=>{const{normalize:a}=e;return a(["Abrir en una pestaña nueva"])},original_pdf:e=>{const{normalize:a}=e;return a(["PDF original"])},rate_limit:e=>{const{normalize:a}=e;return a(["Límite de tarifa"])},read_grounding_release_note:e=>{const{normalize:a}=e;return a(["Leer la nota de lanzamiento"])},reader_also_read_images:e=>{const{normalize:a}=e;return a(["Las imágenes de la página web se subtitulan automáticamente utilizando un modelo de lenguaje de visión en el lector y se formatean como etiquetas alternativas de imagen en la salida. Esto le brinda a su LLM posterior suficientes sugerencias para incorporar esas imágenes en sus procesos de razonamiento y resumen. Esto significa que puede hacer preguntas sobre las imágenes, seleccionar imágenes específicas o incluso reenviar sus URL a un VLM más potente para un análisis más profundo."])},reader_description:e=>{const{normalize:a}=e;return a(["Obtenga información compatible con LLM desde una URL o una búsqueda web, simplemente agregando <code>r.jina.ai</code> al frente."])},reader_do_grounding:e=>{const{normalize:a}=e;return a(["Lector para verificación de datos"])},reader_do_grounding_explain:e=>{const{normalize:a}=e;return a(["El nuevo punto de conexión ofrece una experiencia de verificación de hechos de principio a fin casi en tiempo real. Toma una afirmación determinada, la fundamenta utilizando resultados de búsqueda web en tiempo real y devuelve una puntuación de veracidad y las referencias exactas utilizadas. Puede fundamentar fácilmente las afirmaciones para reducir las alucinaciones de LLM o mejorar la integridad del contenido escrito por humanos."])},reader_do_pdf_explain:e=>{const{normalize:a}=e;return a(["Sí, Reader admite de forma nativa la lectura de PDF. Es compatible con la mayoría de los archivos PDF, incluidos aquellos con muchas imágenes, ¡y es ultrarrápido! Combinado con un LLM, puede crear fácilmente un ChatPDF o una IA de análisis de documentos en poco tiempo."])},reader_do_search:e=>{const{normalize:a}=e;return a(["Lector para bases de búsqueda."])},reader_do_search_explain:e=>{const{normalize:a}=e;return a(["Los LLM tienen un límite de conocimientos, lo que significa que no pueden acceder a los conocimientos mundiales más recientes. Esto conduce a problemas como desinformación, respuestas obsoletas, alucinaciones y otras cuestiones objetivas. La conexión a tierra es absolutamente esencial para las aplicaciones GenAI. Reader le permite basar su LLM con la información más reciente de la web. Simplemente anteponga https://s.jina.ai/ a su consulta y Reader buscará en la web y devolverá los cinco resultados principales con sus URL y contenidos, cada uno en texto limpio y compatible con LLM. De esta manera, siempre podrá mantener actualizado su LLM, mejorar su factibilidad y reducir las alucinaciones."])},reader_reads_images:e=>{const{normalize:a}=e;return a(["¡El lector también lee imágenes!"])},reader_reads_pdf:e=>{const{normalize:a}=e;return a(["¡El lector también lee archivos PDF!"])},reader_result:e=>{const{normalize:a}=e;return a(["Resultado del lector"])},table:{td_1_0:e=>{const{normalize:a}=e;return a(["Leer una URL y devolver su contenido, útil para comprobar la conexión a tierra"])},td_1_1:e=>{const{normalize:a}=e;return a(["20 rpm"])},td_1_2:e=>{const{normalize:a}=e;return a(["200 rpm"])},td_1_3:e=>{const{normalize:a}=e;return a(["Basado en los tokens de salida"])},td_1_4:e=>{const{normalize:a}=e;return a(["3 segundos"])},td_1_5:e=>{const{normalize:a}=e;return a(["3 segundos"])},td_2_0:e=>{const{normalize:a}=e;return a(["La búsqueda en la web arroja los 5 primeros resultados, lo que resulta útil para la base de búsqueda"])},td_2_1:e=>{const{normalize:a}=e;return a(["5 RPM"])},td_2_2:e=>{const{normalize:a}=e;return a(["40 rpm"])},td_2_3:e=>{const{normalize:a}=e;return a(["Basado en los tokens de salida para los 5 resultados de búsqueda"])},td_2_4:e=>{const{normalize:a}=e;return a(["10 segundos"])},td_2_5:e=>{const{normalize:a}=e;return a(["10 segundos"])},th0:e=>{const{normalize:a}=e;return a(["Punto final"])},th1:e=>{const{normalize:a}=e;return a(["Descripción"])},th2:e=>{const{normalize:a}=e;return a(["Límite de velocidad sin clave API"])},th3:e=>{const{normalize:a}=e;return a(["Límite de tasa con clave API"])},th4:e=>{const{normalize:a}=e;return a(["Esquema de conteo de tokens"])},th5:e=>{const{normalize:a}=e;return a(["Latencia media"])},th6:e=>{const{normalize:a}=e;return a(["Latencia media"])}},title:e=>{const{normalize:a}=e;return a(["API de lector"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},usage_details_false:e=>{const{normalize:a}=e;return a(["Mostrar solo usos básicos"])},usage_details_null:e=>{const{normalize:a}=e;return a(["Mostrar usos básicos y avanzados"])},usage_details_true:e=>{const{normalize:a}=e;return a(["Mostrar solo usos avanzados"])},want_higher_rate_limit:e=>{const{normalize:a}=e;return a(["¿Quiere un límite de velocidad más alto, hasta 1000 RPM? ¡Podemos apoyarte!"])},what_is1:e=>{const{normalize:a}=e;return a(["¿Qué es el lector?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a(["Introducir información web en los LLM es un paso importante para la puesta a tierra, pero puede ser un desafío. El método más simple es raspar la página web y alimentar el HTML sin formato. Sin embargo, el scraping puede ser complejo y a menudo bloqueado, y el HTML sin formato está lleno de elementos extraños como marcas y scripts. Reader API aborda estos problemas extrayendo el contenido principal de una URL y convirtiéndolo en texto limpio y compatible con LLM, lo que garantiza una entrada de alta calidad para su agente y sus sistemas RAG."])},what_is_desc:e=>{const{normalize:a}=e;return a(["Un proxy que accede a cualquier URL y transforma el contenido principal en texto sin formato optimizado para LLM."])}},recommender:{confirm_message:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["A su clave API le quedan ",n(r("_leftTokens"))," tokens. Enviar el texto completo de los artículos ",n(r("_numArticles"))," a la API de Reranker, utilizando el modelo ",n(r("_selectedReranker"))," para descubrir artículos relacionados para la página actual, reducirá significativamente el recuento de tokens de su clave API ",n(r("_APIKey")),". Quieres proceder?"])},confirm_title:e=>{const{normalize:a}=e;return a(["Advertencia: uso elevado de tokens"])},out_of_quota:e=>{const{normalize:a}=e;return a(["Esta clave API se ha quedado sin tokens. Recargue su cuenta o utilice una clave API diferente."])},recommend:e=>{const{normalize:a}=e;return a(["Consigue el top 5"])},recommended_articles:e=>{const{normalize:a}=e;return a(["Los 5 mejores artículos similares"])}},reranker:{benchmark:{description0:e=>{const{normalize:a}=e;return a(["LlamaIndex evaluó varias combinaciones de incrustaciones y reordenadores para RAG y realizó un estudio de replicación que midió el rango recíproco medio. Los hallazgos destacan la mejora significativa de la calidad de búsqueda de Jina Reranker, un beneficio que es independiente de las incrustaciones específicas utilizadas."])},description1:e=>{const{normalize:a}=e;return a(["BIER (Benchmarking IR) evalúa la efectividad de la recuperación de un modelo, incluida la relevancia y NDCG. Una puntuación BIER más alta se correlaciona con coincidencias y clasificaciones de resultados de búsqueda más precisas."])},description2:e=>{const{normalize:a}=e;return a(["A través del punto de referencia LoCo, medimos la comprensión de un modelo sobre la coherencia y el contexto local, junto con la clasificación específica de la consulta. Una puntuación más alta de LoCo refleja una mejor capacidad para identificar y priorizar información relevante."])},description3:e=>{const{normalize:a}=e;return a(["El MTEB (Parámetro de referencia de incrustación de texto multilingüe), en general, prueba las capacidades de un modelo en la incrustación de texto, incluida la agrupación, clasificación, recuperación y otras métricas. Sin embargo, para nuestra comparación, solo utilizamos las tareas de Reranking del MTEB."])},title:e=>{const{normalize:a}=e;return a(["Punto de referencia"])},title0:e=>{const{normalize:a}=e;return a(["LlamaIndex"])},title1:e=>{const{normalize:a}=e;return a(["BEIR"])},title2:e=>{const{normalize:a}=e;return a(["Locomotora"])},title3:e=>{const{normalize:a}=e;return a(["MTEB"])}},benchmark_description:e=>{const{normalize:a}=e;return a(["A modo de comparación, incluimos otros tres rerankers líderes de BGE (BAAI), BCE (Netease Youdao) y Cohere en el índice de referencia. Como lo muestran los resultados a continuación, Jina Reranker tiene el puntaje promedio más alto en todas las categorías relevantes para el reranking, lo que lo convierte en un claro líder entre sus pares."])},benchmark_title:e=>{const{normalize:a}=e;return a(["Punto de referencia de rendimiento"])},choose_turbo:e=>{const{normalize:a}=e;return a(["Obtenga una aceleración de hasta 5 veces con reranker-turbo"])},choose_turbo_description:e=>{const{normalize:a}=e;return a(["También ofrecemos dos nuevos modelos de reranker de código abierto: jina-reranker-v1-turbo-en y jina-reranker-v1-tiny-en; este último tiene solo 30 millones de parámetros y cuatro capas. Estos dos nuevos reordenadores disfrutan de una velocidad de inferencia 5 veces más rápida que el modelo base con un costo de calidad muy pequeño. Son perfectos para aplicaciones que requieren reclasificación en tiempo real. Lea el punto de referencia a continuación."])},customize_urself:e=>{const{normalize:a}=e;return a(["¡Cámbialo y verás cómo cambia la respuesta!"])},customize_urself_pl:e=>{const{normalize:a}=e;return a(["¡Cámbialos y observa cómo cambia la respuesta!"])},description:e=>{const{normalize:a}=e;return a(["Recuperador neuronal de clase mundial para maximizar la relevancia de la búsqueda."])},description_rich:e=>{const{normalize:a}=e;return a(["Maximice la relevancia de la búsqueda y la precisión de RAG con nuestra API de reclasificación de vanguardia. Comience con 1 millón de tokens gratis."])},example_input_document:e=>{const{normalize:a}=e;return a(["Ejemplos de documentos candidatos para clasificar"])},example_input_query:e=>{const{normalize:a}=e;return a(["Consulta de ejemplo"])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["El precio de la API Reranker está alineado con nuestra estructura de precios de API integrada. Comienza con 1 millón de tokens gratis por cada nueva clave API. Más allá de los tokens gratuitos, hay diferentes paquetes disponibles para su compra. Para obtener más detalles, visite nuestra sección de precios."])},answer10:e=>{const{normalize:a}=e;return a(["Sí, Jina Reranker se puede implementar en AWS. Si necesita una implementación local en un entorno empresarial, puede hacerlo fácilmente a través de nuestra oferta de AWS Marketplace."])},answer11:e=>{const{normalize:a}=e;return a(["Si está interesado en un reranker ajustado y adaptado a datos de dominio específicos, comuníquese con nuestro equipo de ventas. Nuestro equipo responderá a su consulta con prontitud."])},answer3:e=>{const{normalize:a}=e;return a(["La principal diferencia radica en su arquitectura. En cuanto al rendimiento, recomendamos jina-reranker-v1, que ha sido ampliamente probado y comparado con la competencia. Jina-reranker-v1 utiliza una arquitectura de codificador cruzado, mientras que Jina-colbert-v1 se basa en la arquitectura ColBERTv2 pero extiende la longitud del contexto tanto de la consulta como del documento a 8192, logrando un rendimiento aún mejor que el modelo ColBERTv2 original."])},answer4:e=>{const{normalize:a}=e;return a(["Sí, jina-colbert-v1 es de código abierto y se puede acceder a él a través de Huggingface. Sin embargo, jina-reranker-v1 no es de código abierto."])},answer5:e=>{const{normalize:a}=e;return a(["Actualmente, solo admite inglés. Sin embargo, algunos usuarios han informado que también funciona bien con el chino. Esto puede deberse en parte a que jina-reranker-v1-base-en comparte algunos pesos con nuestro modelo de incrustación jina-embeddings-v2-base-zh."])},answer6:e=>{const{normalize:a}=e;return a(["La longitud máxima del token de consulta es 512. No hay límite de token para los documentos."])},answer7:e=>{const{normalize:a}=e;return a(["Puede reclasificar hasta 2048 documentos por consulta."])},answer8:e=>{const{normalize:a}=e;return a(["No existe un concepto de tamaño de lote a diferencia de nuestra API de incrustación. Puede enviar solo una tupla de documento de consulta por solicitud, pero la tupla puede incluir hasta 2048 documentos candidatos."])},answer9:e=>{const{normalize:a}=e;return a(["La latencia varía de 100 milisegundos a 7 segundos, dependiendo en gran medida de la longitud de los documentos y de la consulta. Por ejemplo, reclasificar 100 documentos de 256 tokens cada uno con una consulta de 64 tokens lleva unos 150 milisegundos. Aumentar la longitud del documento a 4096 tokens aumenta el tiempo a 3,5 segundos. Si la longitud de la consulta aumenta a 512 tokens, el tiempo aumenta aún más a 7 segundos."])},question1:e=>{const{normalize:a}=e;return a(["¿Cuánto cuesta la API de Reranker?"])},question10:e=>{const{normalize:a}=e;return a(["¿Puedo implementar Jina Reranker en AWS?"])},question11:e=>{const{normalize:a}=e;return a(["¿Ofrecen un reranker ajustado en datos específicos del dominio?"])},question3:e=>{const{normalize:a}=e;return a(["¿Cuál es la diferencia entre los dos rerankers?"])},question4:e=>{const{normalize:a}=e;return a(["¿Jina Reranker es de código abierto?"])},question5:e=>{const{normalize:a}=e;return a(["¿El reranker admite varios idiomas?"])},question6:e=>{const{normalize:a}=e;return a(["¿Cuál es la extensión máxima para consultas y documentos?"])},question7:e=>{const{normalize:a}=e;return a(["¿Cuál es la cantidad máxima de documentos que puedo reclasificar por consulta?"])},question8:e=>{const{normalize:a}=e;return a(["¿Cuál es el tamaño del lote y cuántas tuplas de documentos de consulta puedo enviar en una solicitud?"])},question9:e=>{const{normalize:a}=e;return a(["¿Qué latencia puedo esperar al reclasificar 100 documentos?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con el reranker"])}},feature_on_premises_description2:e=>{const{normalize:a}=e;return a(["Implemente Jina Reranker en AWS Sagemaker y pronto en Microsoft Azure y Google Cloud Services, o comuníquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description3:e=>{const{normalize:a}=e;return a(["Implemente Jina Reranker en AWS Sagemaker y Microsoft Azure y pronto en Google Cloud Services, o comuníquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_solid_description:e=>{const{normalize:a}=e;return a(["Desarrollado a partir de nuestra investigación académica de vanguardia y probado rigurosamente con los reclasificadores SOTA para garantizar un rendimiento incomparable."])},how_it_works:e=>{const{normalize:a}=e;return a(["Así es como funciona:"])},how_it_works_v1:{description1:e=>{const{normalize:a}=e;return a(["Un sistema de búsqueda utiliza embeddings/BM25 para encontrar un amplio conjunto de documentos potencialmente relevantes en función de la consulta del usuario."])},description2:e=>{const{normalize:a}=e;return a(["Luego, el reclasificador toma estos resultados y los analiza a un nivel más granular, considerando los matices de cómo los términos de consulta interactúan con el contenido del documento."])},description3:e=>{const{normalize:a}=e;return a(["Reordena los resultados de la búsqueda, colocando en la parte superior los que considera más relevantes, en base a este análisis más profundo."])},title1:e=>{const{normalize:a}=e;return a(["Recuperación inicial"])},title2:e=>{const{normalize:a}=e;return a(["Reclasificación"])},title3:e=>{const{normalize:a}=e;return a(["Resultados mejorados"])}},improve_performance:e=>{const{normalize:a}=e;return a(["Mejora garantizada sobre la búsqueda de vectores"])},improve_performance_description:e=>{const{normalize:a}=e;return a(["Nuestras evaluaciones demostraron mejoras en los sistemas de búsqueda que emplean Jina Reranker con un +8 % en la tasa de aciertos y un +33 % en la clasificación recíproca media."])},learning1:e=>{const{normalize:a}=e;return a(["Aprendiendo sobre Reranker"])},learning1_description:e=>{const{normalize:a}=e;return a(["¿Qué es un reranker? ¿Por qué no es suficiente la búsqueda de vectores o la similitud de cosenos? Aprenda sobre los rerankers desde cero con nuestra guía completa."])},read_more_about_benchmark:e=>{const{normalize:a}=e;return a(["Leer más sobre el punto de referencia"])},read_more_about_turbo:e=>{const{normalize:a}=e;return a(["Lea más sobre los modelos turbo y tiny"])},read_more_about_v2:e=>{const{normalize:a}=e;return a(["Jina Reranker v2 es el mejor reranker de su clase lanzado el 25 de junio de 2024; está diseñado para Agentic RAG. Cuenta con soporte de llamada de funciones, recuperación multilingüe para más de 100 idiomas, capacidades de búsqueda de códigos y ofrece una velocidad 6 veces mayor que la v1. Lea más sobre el modelo v2."])},reranker_description:e=>{const{normalize:a}=e;return a(["Pruebe nuestra API de reranker de vanguardia para maximizar la relevancia de su búsqueda y la precisión de RAG. ¡Empezando gratis!"])},show_v2benchmark:e=>{const{normalize:a}=e;return a(["Mostrar punto de referencia para el modelo v2 (más reciente)"])},table:{number_token_document:e=>{const{normalize:a}=e;return a(["Número de tokens en cada documento"])},number_token_query:e=>{const{normalize:a}=e;return a(["Número de tokens en la consulta"])},title:e=>{const{normalize:a}=e;return a(["A continuación se muestra el costo de tiempo de reclasificar una consulta y 100 documentos en milisegundos:"])}},title:e=>{const{normalize:a}=e;return a(["API de reclasificación"])},top_n:e=>{const{normalize:a}=e;return a(["Número de documentos devueltos"])},top_n_explain:e=>{const{normalize:a}=e;return a(["El número de documentos más relevantes que se devolverán para la consulta."])},try_embedding:e=>{const{normalize:a}=e;return a(["Pruebe incorporar API de forma gratuita"])},try_reranker:e=>{const{normalize:a}=e;return a(["Pruebe la API de reranker gratis"])},v2_features:{description1:e=>{const{normalize:a}=e;return a(["Reranker v2 permite la recuperación de documentos en más de 100 idiomas, independientemente del idioma de consulta."])},description2:e=>{const{normalize:a}=e;return a(["Reranker v2 clasifica fragmentos de código y firmas de funciones en función de consultas en lenguaje natural, ideal para aplicaciones Agentic RAG."])},description3:e=>{const{normalize:a}=e;return a(["Reranker v2 clasifica las tablas más relevantes basándose en consultas en lenguaje natural, lo que ayuda a ordenar diferentes esquemas de tablas e identificar el más relevante antes de generar una consulta SQL."])},title1:e=>{const{normalize:a}=e;return a(["Recuperación multilingüe"])},title2:e=>{const{normalize:a}=e;return a(["Llamada de funciones y búsqueda de códigos"])},title3:e=>{const{normalize:a}=e;return a(["Soporte de datos tabulares y estructurados"])}},v2benchmark:{descBeir:e=>{const{normalize:a}=e;return a(["Puntuaciones NDCG 10 reportadas para diferentes modelos de reclasificación para el conjunto de datos de Beir"])},descCodeSearchNet:e=>{const{normalize:a}=e;return a(["Puntuaciones de MRR 10 informadas para diferentes modelos de reclasificación para el conjunto de datos CodeSearchNet"])},descMKQA:e=>{const{normalize:a}=e;return a(["Recuerde 10 puntuaciones reportadas para diferentes modelos de reclasificación para el conjunto de datos MKQA"])},descNSText2SQL:e=>{const{normalize:a}=e;return a(["Recuerde 3 puntuaciones reportadas para diferentes modelos de reclasificación para el conjunto de datos NSText2SQL"])},descRTX4090:e=>{const{normalize:a}=e;return a(["Puntuaciones de rendimiento (documentos recuperados en 50 ms) informadas para diferentes modelos de reclasificación en una GPU RTX 4090."])},descToolBench:e=>{const{normalize:a}=e;return a(["Recuerde 3 puntuaciones reportadas para diferentes modelos de reclasificación para el conjunto de datos de ToolBench"])},titleBeir:e=>{const{normalize:a}=e;return a(["BEIR (Parámetro de referencia heterogéneo en diversas tareas de RI)"])},titleCodeSearchNet:e=>{const{normalize:a}=e;return a(["CódigoSearchNet. El punto de referencia es una combinación de consultas en formatos de cadena de documentación y lenguaje natural, con segmentos de código etiquetados relevantes para las consultas."])},titleMKQA:e=>{const{normalize:a}=e;return a(["MKQA (Preguntas y respuestas sobre conocimientos multilingües)"])},titleNSText2SQL:e=>{const{normalize:a}=e;return a(["NSText2SQL"])},titleRTX4090:e=>{const{normalize:a}=e;return a(["Rendimiento de Jina Reranker v2 en RTX4090"])},titleToolBench:e=>{const{normalize:a}=e;return a(["Banco de herramientas. El punto de referencia recopila más de 16 mil API públicas y las correspondientes instrucciones generadas sintéticamente para usarlas en configuraciones de API única y múltiple."])}},vs_table:{col0:e=>{const{normalize:a}=e;return a(["reclasificador"])},col0_1:e=>{const{normalize:a}=e;return a(["Precisión y relevancia de búsqueda mejoradas"])},col0_2:e=>{const{normalize:a}=e;return a(["Filtrado inicial y rápido"])},col0_3:e=>{const{normalize:a}=e;return a(["Recuperación de texto general en consultas de amplio alcance"])},col1:e=>{const{normalize:a}=e;return a(["Búsqueda de vectores"])},col1_1:e=>{const{normalize:a}=e;return a(["Detallado: subdocumento y segmento de consulta"])},col1_2:e=>{const{normalize:a}=e;return a(["Amplio: documentos completos"])},col1_3:e=>{const{normalize:a}=e;return a(["Intermedio: varios segmentos de texto"])},col2:e=>{const{normalize:a}=e;return a(["BM25"])},col2_1:e=>{const{normalize:a}=e;return a(["Alto"])},col2_2:e=>{const{normalize:a}=e;return a(["Medio"])},col2_3:e=>{const{normalize:a}=e;return a(["Bajo"])},col3_1:e=>{const{normalize:a}=e;return a(["No requerido"])},col3_2:e=>{const{normalize:a}=e;return a(["Alto"])},col3_3:e=>{const{normalize:a}=e;return a(["Bajo, utiliza índice prediseñado"])},col4_1:e=>{const{normalize:a}=e;return a(["Alto"])},col4_2:e=>{const{normalize:a}=e;return a(["Alto"])},col4_3:e=>{const{normalize:a}=e;return a(["No requerido"])},col5_1:e=>{const{normalize:a}=e;return a(["Superior para consultas matizadas"])},col5_2:e=>{const{normalize:a}=e;return a(["Equilibrado entre eficiencia y precisión"])},col5_3:e=>{const{normalize:a}=e;return a(["Consistente y confiable para un amplio conjunto de consultas"])},col6_1:e=>{const{normalize:a}=e;return a(["Altamente preciso con una profunda comprensión contextual."])},col6_2:e=>{const{normalize:a}=e;return a(["Rápido y eficiente, con precisión moderada."])},col6_3:e=>{const{normalize:a}=e;return a(["Altamente escalable, con eficacia establecida"])},col7_1:e=>{const{normalize:a}=e;return a(["Uso intensivo de recursos con implementación compleja"])},col7_2:e=>{const{normalize:a}=e;return a(["Es posible que no capture el contexto o los matices de la consulta profunda"])},col7_3:e=>{const{normalize:a}=e;return a(["Puede tener un rendimiento inferior en búsquedas muy específicas o contextuales"])},header0:e=>{const{normalize:a}=e;return a(["Mejor para"])},header1:e=>{const{normalize:a}=e;return a(["Granularidad"])},header2:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de consulta"])},header3:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de indexación"])},header4:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de entrenamiento"])},header5:e=>{const{normalize:a}=e;return a(["Calidad de búsqueda"])},header6:e=>{const{normalize:a}=e;return a(["Fortalezas"])},header7:e=>{const{normalize:a}=e;return a(["Debilidades"])},subtitle:e=>{const{normalize:a}=e;return a(["La siguiente tabla proporciona una comparación completa de Reranker, Vector/Inbeddings Search y BM25, destacando sus fortalezas y debilidades en varias categorías."])},title:e=>{const{normalize:a}=e;return a(["Comparación de Reranker, Vector Search y BM25"])}},what_is:e=>{const{normalize:a}=e;return a(["¿Qué es un reranker?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a([`El objetivo de un sistema de búsqueda es encontrar los resultados más relevantes de forma rápida y eficaz. Tradicionalmente, se han utilizado métodos como BM25 o tf-idf para clasificar los resultados de búsqueda según la concordancia de palabras clave. En muchas bases de datos vectoriales se han implementado métodos recientes, como la similitud de coseno basada en incrustación. Estos métodos son sencillos, pero a veces pueden pasar por alto las sutilezas del lenguaje y, lo más importante, la interacción entre los documentos y la intención de una consulta.

Aquí es donde brilla el "reranker". Un reranker es un modelo de IA avanzado que toma el conjunto inicial de resultados de una búsqueda (a menudo proporcionado por una búsqueda incrustada/basada en tokens) y los reevalúa para garantizar que se alineen más estrechamente con la intención del usuario. Mira más allá de la coincidencia superficial de términos para considerar la interacción más profunda entre la consulta de búsqueda y el contenido de los documentos.`])},what_is_answer_long_ending:e=>{const{normalize:a}=e;return a(["El reclasificador puede mejorar significativamente la calidad de la búsqueda porque opera a nivel de subdocumento y subconsulta, lo que significa que analiza las palabras y frases individuales, sus significados y cómo se relacionan entre sí dentro de la consulta y los documentos. Esto da como resultado un conjunto de resultados de búsqueda más preciso y contextualmente relevante."])},what_is_desc:e=>{const{normalize:a}=e;return a(["Un reranker es un modelo de IA que refina los resultados de la búsqueda a partir de una búsqueda vectorial o un modelo de recuperación denso. Leer más."])}},scenex:{caption_image_desc:e=>{const{normalize:a}=e;return a(["Generar una descripción textual de la imagen."])},caption_image_title:e=>{const{normalize:a}=e;return a(["Imagen de título"])},description:e=>{const{normalize:a}=e;return a(["Explore la narración de imágenes más allá de los píxeles"])},example1:e=>{const{normalize:a}=e;return a(["Este vídeo parece ser un metraje de la naturaleza que muestra un encantador conejito blanco y una mariposa en un campo de hierba. Se ve al conejito interactuando con la mariposa de diferentes maneras, mostrando su relación única. El entorno natural proporciona un telón de fondo pintoresco que realza la belleza de esta escena sencilla pero cautivadora."])},generate_story_desc:e=>{const{normalize:a}=e;return a(["Elabora una historia inspirada en la imagen, que a menudo incluye diálogos o monólogos de sus personajes."])},generate_story_title:e=>{const{normalize:a}=e;return a(["Generar historia"])},intro1:e=>{const{normalize:a}=e;return a(["Solución líder de IA para subtítulos de imágenes y resúmenes de vídeos"])},json_image_desc:e=>{const{normalize:a}=e;return a(["Genere un formato JSON estructurado a partir de la imagen utilizando un esquema predefinido. Esto permite la extracción de datos específicos de la imagen."])},json_image_title:e=>{const{normalize:a}=e;return a(["Extraer JSON de la imagen"])},summarize_video_desc:e=>{const{normalize:a}=e;return a(["Genere un resumen conciso del vídeo, destacando los eventos clave."])},summarize_video_title:e=>{const{normalize:a}=e;return a(["Resumir vídeo"])},visual_q_a_desc:e=>{const{normalize:a}=e;return a(["Responda una consulta basada en el contenido de la imagen."])},visual_q_a_title:e=>{const{normalize:a}=e;return a(["Preguntas y respuestas visuales"])}},searchbar:{ask_on_current_page:e=>{const{normalize:a}=e;return a(["Pregunte a la página actual sobre..."])},find_solution:e=>{const{normalize:a}=e;return a(["Generar una solución para..."])},hint:e=>{const{normalize:a}=e;return a(["Busque productos, noticias y sus preguntas."])},hotkey:e=>{const{normalize:a}=e;return a(["Presione la tecla / para buscar en esta página"])},hotkey1:e=>{const{normalize:a}=e;return a(["Prensa"])},hotkey2:e=>{const{normalize:a}=e;return a(["para alternar"])},hotkey_long1:e=>{const{normalize:a}=e;return a(["En cualquier momento, presione"])},hotkey_long3:e=>{const{normalize:a}=e;return a(["para abrir la barra de búsqueda"])},more_results:e=>{const{normalize:a,interpolate:n,named:r}=e;return a([n(r("_numMore"))," más resultados"])},placeholder:e=>{const{normalize:a}=e;return a(["Haga cualquier pregunta en esta página"])},proposing_solution:e=>{const{normalize:a}=e;return a(["Generando respuesta basada en el contenido de la página..."])},required:e=>{const{normalize:a}=e;return a(["Describe tu pregunta con más detalles."])},results:e=>{const{normalize:a}=e;return a(["resultados"])}},searchscape:{description:e=>{const{normalize:a}=e;return a(["Navegue, interactúe, perfeccione: vuelva a imaginar el descubrimiento de productos"])}},semantic:{description:e=>{const{normalize:a}=e;return a(["Cerrar la brecha semántica en su infraestructura de búsqueda existente"])}},share:{"Hacker News":e=>{const{normalize:a}=e;return a(["Noticias de piratas informáticos"])},LinkedIn:e=>{const{normalize:a}=e;return a(["LinkedIn"])},facebook:e=>{const{normalize:a}=e;return a(["Facebook"])},reddit:e=>{const{normalize:a}=e;return a(["Reddit"])},rss:e=>{const{normalize:a}=e;return a(["RSS Feed"])},share_btn:e=>{const{normalize:a}=e;return a(["Compartir"])},twitter:e=>{const{normalize:a}=e;return a(["X (Twitter)"])}},spectrum:{click_to_learn_more:e=>{const{normalize:a}=e;return a(["Haz click para aprender mas"])},contextualization:e=>{const{normalize:a}=e;return a(["Contextualización"])},contextualization_desc:e=>{const{normalize:a}=e;return a(["Los rerankers ajustan los resultados de búsqueda iniciales en función de una profunda relevancia contextual. consulta. Esto refina la clasificación para que coincida mejor con lo que los usuarios probablemente encuentren útil."])},coreInfra:e=>{const{normalize:a}=e;return a(["Infraestructura central"])},coreInfra_desc:e=>{const{normalize:a}=e;return a(["Core Infra proporciona una capa nativa de la nube para desarrollar, implementar y orquestar modelos básicos de búsqueda tanto en la nube pública como en las instalaciones, lo que permite que los servicios aumenten y disminuyan sin esfuerzo."])},embedding_serving:e=>{const{normalize:a}=e;return a(["Incrustar servicio"])},embedding_serving_description:e=>{const{normalize:a}=e;return a(["Entrega de incorporaciones a través de un microservicio robusto y escalable que utiliza tecnologías nativas de la nube."])},embedding_tech:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},embedding_tech_description:e=>{const{normalize:a}=e;return a([`En Jina AI, aprovechamos el poder de la tecnología integrada para revolucionar diversas aplicaciones de IA. Esta tecnología sirve como un método unificado para representar y comprimir de manera eficiente varios tipos de datos, garantizando que no se pierda información crítica. Nuestro objetivo es transformar conjuntos de datos complejos en un formato de incrustación universalmente comprensible, lo cual es esencial para un análisis de IA preciso y revelador.

Las incrustaciones son fundamentales, especialmente en aplicaciones como el reconocimiento preciso de imágenes y voz, donde ayudan a discernir detalles y matices finos. En el procesamiento del lenguaje natural, las incorporaciones mejoran la comprensión del contexto y el sentimiento, lo que lleva a herramientas de traducción de idiomas e inteligencia artificial conversacional más precisas. También son cruciales para desarrollar sistemas de recomendación sofisticados que requieren una comprensión profunda de las preferencias del usuario en diferentes formas de contenido, como texto, audio y video.`])},embedding_tuning:e=>{const{normalize:a}=e;return a(["Ajuste de incrustación"])},embedding_tuning_description:e=>{const{normalize:a}=e;return a(["Optimización de incorporaciones de alta calidad mediante la integración de experiencia en el dominio para mejorar el rendimiento de tareas específicas."])},embeddings:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},embeddings_desc:e=>{const{normalize:a}=e;return a(["Las incrustaciones son la piedra angular del sistema de búsqueda moderno y representan datos multimodales en vectores de números. Este proceso permite una comprensión más matizada y contextual del contenido, mucho más allá de la simple coincidencia de palabras clave."])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para Empresas"])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},grounding:e=>{const{normalize:a}=e;return a(["Toma de tierra"])},grounding_desc:e=>{const{normalize:a}=e;return a(["Lector refinando entradas y resultados a través de LLM. Mejoran la calidad, legibilidad y factibilidad de la respuesta final."])},model_serving:e=>{const{normalize:a}=e;return a(["Servicio modelo"])},model_serving_description:e=>{const{normalize:a}=e;return a(["La implementación de modelos ajustados en un entorno de producción, que generalmente requiere recursos sustanciales, como el alojamiento de GPU. MLOps, enfatizando el servicio de modelos medianos a grandes de una manera escalable, eficiente y confiable."])},model_tuning:e=>{const{normalize:a}=e;return a(["Ajuste del modelo"])},model_tuning_description:e=>{const{normalize:a}=e;return a(["También conocido como ajuste fino, implica ajustar los parámetros de un modelo previamente entrenado en un nuevo conjunto de datos, a menudo específico de una tarea, para mejorar su rendimiento y adaptarlo a una aplicación específica."])},personalization:e=>{const{normalize:a}=e;return a(["Personalización"])},personalization_desc:e=>{const{normalize:a}=e;return a(["Uso de datos sintéticos guiados por las instrucciones del usuario para entrenar automáticamente un modelo de incrustación y reclasificación específico del dominio."])},preprocessing:e=>{const{normalize:a}=e;return a(["Preprocesamiento"])},preprocessing_desc:e=>{const{normalize:a}=e;return a(["El preprocesamiento implica limpiar, normalizar y transformar datos sin procesar en un formato que el sistema de búsqueda pueda digerir."])},promptOps:e=>{const{normalize:a}=e;return a(["Operaciones inmediatas"])},promptOps_desc:e=>{const{normalize:a}=e;return a(["Prompt Ops mejora la entrada y salida del sistema de búsqueda, incluidas las utilizadas en la expansión de consultas, la entrada de LLM y la reescritura de resultados. Esto garantiza que la búsqueda se comprenda mejor y obtenga mejores resultados."])},prompt_serving:e=>{const{normalize:a}=e;return a(["Servicio rápido"])},prompt_serving_description:e=>{const{normalize:a}=e;return a(["Envolviendo y entregando avisos a través de una API, sin alojar modelos pesados. La API llama a un servicio de modelo de lenguaje grande público y maneja la orquestación de entradas y salidas en una cadena de operaciones."])},prompt_tech:e=>{const{normalize:a}=e;return a(["Ingeniería rápida y de agentes"])},prompt_tech_description:e=>{const{normalize:a}=e;return a([`En Jina AI, reconocemos que la ingeniería rápida es vital para interactuar con grandes modelos de lenguaje (LLM). A medida que estos modelos avanzan, la complejidad de las indicaciones aumenta, abarcando razonamiento y lógica intrincados. Este avance subraya el crecimiento entrelazado de los LLM y la sofisticación inmediata.

Prevemos un futuro en el que los LLM actuarán como compiladores y los mensajes se convertirán en el nuevo lenguaje de programación. Este cambio sugiere que el dominio tecnológico futuro puede centrarse más en el dominio rápido que en la codificación tradicional. Nuestro compromiso en Jina AI es liderar esta área transformadora, haciendo que la IA avanzada sea accesible y práctica para el uso diario al dominar este "lenguaje" emergente.`])},prompt_tuning:e=>{const{normalize:a}=e;return a(["Sintonización rápida"])},prompt_tuning_description:e=>{const{normalize:a}=e;return a(["El proceso de elaborar y refinar las indicaciones de entrada para guiar su salida hacia respuestas específicas y deseadas."])},representation:e=>{const{normalize:a}=e;return a(["Representación"])},representation_desc:e=>{const{normalize:a}=e;return a(["Las incrustaciones transforman datos multimodales en un formato vectorizado uniforme. Esto permite que el sistema de búsqueda comprenda y categorice el contenido más allá de simples palabras clave."])},rerankers:e=>{const{normalize:a}=e;return a(["reclasificador"])},rerankers_desc:e=>{const{normalize:a}=e;return a(["Los rerankers toman los resultados iniciales de las incrustaciones y los refinan, asegurando que se presenten los resultados más relevantes al usuario. Esto es crucial para ofrecer resultados de búsqueda de alta calidad que cumplan con la intención del usuario."])}},subscribe_system:{care_most:e=>{const{normalize:a}=e;return a(["¿Qué es lo que más te importa?"])},care_most_options:{accuracy:e=>{const{normalize:a}=e;return a(["Exactitud"])},cost:e=>{const{normalize:a}=e;return a(["Costo"])},other:e=>{const{normalize:a}=e;return a(["Otro"])},scalability:e=>{const{normalize:a}=e;return a(["Escalabilidad"])},speed:e=>{const{normalize:a}=e;return a(["Velocidad"])}},care_most_required:e=>{const{normalize:a}=e;return a(["A la hora de elegir un servicio, ¿qué es lo que más te importa?"])},company_size:e=>{const{normalize:a}=e;return a(["¿Cuál es el tamaño de su empresa?"])},company_size_required:e=>{const{normalize:a}=e;return a(["Cuéntanos el tamaño de tu empresa nos ayuda a dar un mejor servicio"])},company_url:e=>{const{normalize:a}=e;return a(["¿Cuál es el sitio web de su empresa?"])},company_url_required:e=>{const{normalize:a}=e;return a(["Cuéntanos que la web de tu empresa nos ayuda a dar un mejor servicio"])},contactName:e=>{const{normalize:a}=e;return a(["Su nombre"])},contactName_required:e=>{const{normalize:a}=e;return a(["¿Cómo deberíamos dirigirnos a usted?"])},contactTitle:e=>{const{normalize:a}=e;return a(["¿Cuál es su profesión?"])},contactTitle_required:e=>{const{normalize:a}=e;return a(["Su título de trabajo es requerido"])},contact_us:e=>{const{normalize:a}=e;return a(["Contáctenos"])},domain_required:e=>{const{normalize:a}=e;return a(["Cuéntanos tu dominio de trabajo nos ayuda a dar un mejor servicio"])},email:e=>{const{normalize:a}=e;return a(["Correo electrónico"])},email_contact:e=>{const{normalize:a}=e;return a(["Tu correo electrónico de contacto"])},email_invalid:e=>{const{normalize:a}=e;return a(["el correo electrónico es invalido"])},email_required:e=>{const{normalize:a}=e;return a(["correo electronico es requerido"])},fine_tuned_embedding:e=>{const{normalize:a}=e;return a(["¿Está interesado en incorporaciones optimizadas y adaptadas a sus datos y caso de uso? ¡Vamos a discutir!"])},fine_tuned_reranker:e=>{const{normalize:a}=e;return a(["¿Está interesado en reclasificadores ajustados y adaptados a sus datos y caso de uso? ¡Vamos a discutir!"])},full_survey:e=>{const{normalize:a}=e;return a(["Responda la encuesta completa y obtenga una respuesta más rápida de nuestro equipo"])},get_new_key:e=>{const{normalize:a}=e;return a(["Obtenga su clave API"])},get_update_blog_posts:e=>{const{normalize:a}=e;return a(["Obtenga las últimas actualizaciones de las publicaciones del blog."])},get_update_embeddings:e=>{const{normalize:a}=e;return a(["Obtenga las últimas actualizaciones para las incorporaciones"])},send:e=>{const{normalize:a}=e;return a(["Enviar"])},sign_up:e=>{const{normalize:a}=e;return a(["Inscribirse"])},subscribe:e=>{const{normalize:a}=e;return a(["Suscribir"])},tell_domain:e=>{const{normalize:a}=e;return a(["Cuéntanos tu dominio"])},usage_type:e=>{const{normalize:a}=e;return a(["¿Qué tipo de uso te describe mejor?"])},usage_type_options:{other:e=>{const{normalize:a}=e;return a(["Otro"])},poc:e=>{const{normalize:a}=e;return a(["Prueba de concepto"])},production:e=>{const{normalize:a}=e;return a(["Producción"])},research:e=>{const{normalize:a}=e;return a(["Investigación"])}},usage_type_required:e=>{const{normalize:a}=e;return a(["Díganos que su tipo de uso nos ayuda a brindar un mejor servicio."])},used_product:e=>{const{normalize:a}=e;return a(["¿Qué modelo estás usando?"])},used_product_required:e=>{const{normalize:a}=e;return a(["Selecciona el modelo que estás utilizando o te interesa"])}},think_gpt:{description:e=>{const{normalize:a}=e;return a(["Técnicas de agentes para aumentar su LLM y llevarlo más allá de sus límites"])}},tokenizer:{advance_usage:e=>{const{normalize:a}=e;return a(["Utilice la solicitud POST para obtener más funciones"])},basic_usage:e=>{const{normalize:a}=e;return a(["Utilice la solicitud GET para contar tokens"])},basic_usage_explain:e=>{const{normalize:a}=e;return a(["Simplemente puede enviar una solicitud GET para contar la cantidad de tokens en su texto."])},change_content:e=>{const{normalize:a}=e;return a(["Cambie el 'contenido' y vea el resultado en vivo"])},chars:e=>{const{normalize:a}=e;return a(["personajes"])},chinese:e=>{const{normalize:a}=e;return a(["Chino"])},chunk:e=>{const{normalize:a}=e;return a(["Pedazo"])},chunk_all:e=>{const{normalize:a}=e;return a(["Todos los trozos"])},chunking:e=>{const{normalize:a}=e;return a(["¡Agrupe documentos largos a la velocidad del rayo!"])},chunking_explain:e=>{const{normalize:a}=e;return a(["También puede utilizar Segmenter API para dividir documentos largos en fragmentos más pequeños, lo que facilita su procesamiento en incrustaciones o reclasificadores. Aprovechamos las señales estructurales comunes y creamos un conjunto de reglas y heurísticas que funcionan bien en diversos tipos de contenido, por ejemplo, lenguajes Markdown, HTML, LaTeX y CJK."])},chunking_short:e=>{const{normalize:a}=e;return a(["Fragmentación"])},chunks_in_total:e=>{const{normalize:a,interpolate:n,named:r}=e;return a([n(r("_numChunks"))," fragmentos en total"])},count_tokens_hint:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["<b>",n(r("_numTokens")),"</b> tokens, ",n(r("_numChars"))," caracteres."])},description:e=>{const{normalize:a}=e;return a(["Segmenta el texto largo en fragmentos y realiza la tokenización."])},description_long:e=>{const{normalize:a}=e;return a(["Nuestra API Segmenter es fundamental para ayudar a los LLM a gestionar la entrada dentro de los límites del contexto y optimizar el rendimiento del modelo. Permite a los desarrolladores contar tokens y extraer segmentos de texto relevantes, lo que garantiza un procesamiento de datos eficiente y una gestión de costos."])},description_long1:e=>{const{normalize:a}=e;return a(["API gratuita para segmentar texto largo en fragmentos y tokenizarlo."])},english:e=>{const{normalize:a}=e;return a(["Inglés"])},explain:e=>{const{normalize:a}=e;return a(["Un segmentador es un componente crucial que convierte el texto en tokens o fragmentos, que son las unidades básicas de datos que procesa un modelo de incrustación/reclasificación o LLM. Los tokens pueden representar palabras completas, partes de palabras o incluso caracteres individuales."])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["La API de Segmenter es de uso gratuito. Si proporciona su clave API, podrá acceder a un límite de velocidad más alto y no se le cobrará por su clave."])},answer10:e=>{const{normalize:a}=e;return a(["Además de los idiomas occidentales, la fragmentación también funciona bien con el chino, el japonés y el coreano."])},answer2:e=>{const{normalize:a}=e;return a(["Sin una clave API, puede acceder a la API de Segmenter con un límite de velocidad de 20 RPM."])},answer3:e=>{const{normalize:a}=e;return a(["Con una clave API, puede acceder a la API de Segmenter con un límite de velocidad de 200 RPM. Para los usuarios pagos premium, el límite de velocidad es de 1000 RPM."])},answer4:e=>{const{normalize:a}=e;return a(["No, su clave API solo se utiliza para acceder a un límite de velocidad más alto."])},answer5:e=>{const{normalize:a}=e;return a(["Sí, la API de Segmenter es multilingüe y admite más de 100 idiomas."])},answer6:e=>{const{normalize:a}=e;return a(["Las solicitudes GET se utilizan únicamente para contar la cantidad de tokens en un texto, lo que le permite integrarlo fácilmente como un contador en su aplicación. Las solicitudes POST admiten más parámetros y funciones, como devolver los primeros/últimos N tokens."])},answer7:e=>{const{normalize:a}=e;return a(["Puede enviar hasta 64k caracteres por solicitud."])},answer8:e=>{const{normalize:a}=e;return a(["La función de fragmentación segmenta documentos largos en fragmentos más pequeños según señales estructurales comunes, lo que garantiza una segmentación precisa del texto en fragmentos significativos. Básicamente, se trata de un patrón de expresiones regulares (¡grande!) que segmenta el texto según ciertas características sintácticas que suelen coincidir con los límites semánticos, como los finales de las oraciones, los saltos de párrafo, la puntuación y ciertas conjunciones. No se trata de fragmentación semántica. Esta expresión regular (grande) es tan potente como puede serlo dentro de las limitaciones de las expresiones regulares. Equilibra la complejidad y el rendimiento. Si bien la verdadera comprensión semántica no es posible con las expresiones regulares, se aproxima bien al contexto mediante señales estructurales comunes."])},answer9:e=>{const{normalize:a}=e;return a(["Si la entrada contiene tokens especiales, nuestra API Segmenter los colocará en el campo 'special_tokens'. Esto le permite identificarlos fácilmente y manejarlos como corresponde para sus tareas posteriores, por ejemplo, eliminarlos antes de introducir el texto en un LLM para evitar ataques de inyección."])},question1:e=>{const{normalize:a}=e;return a(["¿Cuánto cuesta la API Segmenter?"])},question10:e=>{const{normalize:a}=e;return a(["¿La función de chunking admite otros idiomas además del inglés?"])},question2:e=>{const{normalize:a}=e;return a(["Si no proporciono una clave API, ¿cuál es el límite de velocidad?"])},question3:e=>{const{normalize:a}=e;return a(["Si proporciono una clave API, ¿cuál es el límite de velocidad?"])},question4:e=>{const{normalize:a}=e;return a(["¿Cobrarás los tokens de mi clave API?"])},question5:e=>{const{normalize:a}=e;return a(["¿La API de Segmenter admite varios idiomas?"])},question6:e=>{const{normalize:a}=e;return a(["¿Cuál es la diferencia entre las solicitudes GET y POST?"])},question7:e=>{const{normalize:a}=e;return a(["¿Cuál es la longitud máxima que puedo tokenizar por solicitud?"])},question8:e=>{const{normalize:a}=e;return a(["¿Cómo funciona la función de fragmentación? ¿Se trata de fragmentación semántica?"])},question9:e=>{const{normalize:a}=e;return a(["¿Cómo se manejan tokens especiales como 'endoftext' en la API de Segmenter?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas frecuentes relacionadas con el segmentador"])}},free_api:e=>{const{normalize:a}=e;return a(["La API de Segmenter es de uso gratuito. Si proporciona su clave API, podrá acceder a un límite de velocidad más alto y no se le cobrará por la clave."])},input_text:e=>{const{normalize:a}=e;return a(["Texto de entrada"])},is_free:e=>{const{normalize:a}=e;return a(["¡La API de Segmenter es gratuita!"])},is_free_description:e=>{const{normalize:a}=e;return a(["Al proporcionar su clave API, podrá acceder a un límite de tarifa más alto y no se le cobrará su clave."])},japanese:e=>{const{normalize:a}=e;return a(["japonés"])},korean:e=>{const{normalize:a}=e;return a(["coreano"])},parameters:{auth_token:e=>{const{normalize:a}=e;return a(["Agregar clave API para límite de velocidad más alto"])},auth_token_explain:e=>{const{normalize:a}=e;return a(["Ingresa tu clave API de Jina para acceder a un límite de velocidad más alto. Para obtener la información más actualizada sobre el límite de velocidad, consulta la siguiente tabla."])},head:e=>{const{normalize:a}=e;return a(["Devuelve los primeros N tokens"])},head_explain:e=>{const{normalize:a}=e;return a(["Devuelve los primeros N tokens del contenido indicado. Excluye límites. No se puede utilizar con 'tail'."])},learn_more:e=>{const{normalize:a}=e;return a(["Más información"])},max_chunk_length:e=>{const{normalize:a}=e;return a(["Longitud máxima de cada fragmento"])},max_chunk_length_explain:e=>{const{normalize:a}=e;return a(["Número máximo de caracteres en cada fragmento. En la práctica, la longitud del fragmento puede ser menor que este valor, si existe un límite natural en el texto."])},return_chunks:e=>{const{normalize:a}=e;return a(["Devolver los trozos"])},return_chunks_explain:e=>{const{normalize:a}=e;return a(["Dividir la entrada en segmentos semánticamente significativos mientras se maneja una amplia variedad de tipos de texto y casos extremos basados en señales estructurales comunes."])},return_tokens:e=>{const{normalize:a}=e;return a(["Devolver las fichas"])},return_tokens_explain:e=>{const{normalize:a}=e;return a(["Devuelve los tokens y sus identificadores correspondientes en la respuesta. Activa o desactiva esta opción para ver la visualización del resultado."])},tail:e=>{const{normalize:a}=e;return a(["Devuelve los últimos N tokens"])},tail_explain:e=>{const{normalize:a}=e;return a(["Devuelve los últimos N tokens del contenido indicado. Excluye límites. No se puede utilizar con 'head'."])},type:e=>{const{normalize:a}=e;return a(["Segmentador"])},type_explain:e=>{const{normalize:a}=e;return a(["Seleccione el tokenizador a utilizar."])},used_by_models:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Utilizado en ",n(r("_usedBy")),"."])}},remove_boundary_cues:e=>{const{normalize:a}=e;return a(["Eliminar saltos de línea"])},remove_boundary_cues_explain:e=>{const{normalize:a}=e;return a(["Elimine todos los saltos de línea (las principales señales de límite) de la entrada, esto hace que el problema sea más desafiante y observe cómo cambia la respuesta."])},show_space:e=>{const{normalize:a}=e;return a(["Mostrar espacios iniciales y finales"])},table:{td_1_0:e=>{const{normalize:a}=e;return a(["Tokeniza textos, cuenta y obtén los primeros/últimos N tokens."])},td_1_1:e=>{const{normalize:a}=e;return a(["20 RPM"])},td_1_2:e=>{const{normalize:a}=e;return a(["200 RPM"])},td_1_3:e=>{const{normalize:a}=e;return a(["1000 RPM"])},td_1_4:e=>{const{normalize:a}=e;return a(["Sin cargo"])},td_1_5:e=>{const{normalize:a}=e;return a(["800 ms"])}},title:e=>{const{normalize:a}=e;return a(["API de segmentación"])},token_index:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Índice de token: ",n(r("_index"))])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},visualization:e=>{const{normalize:a}=e;return a(["Visualización"])},what_is:e=>{const{normalize:a}=e;return a(["¿Qué es un segmentador?"])}},translator:{cta:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Traducir al código ",n(r("_lang"))])},select_language:e=>{const{normalize:a}=e;return a(["Idioma"])}},vectordb:{description:e=>{const{normalize:a}=e;return a(["Una base de datos vectorial de Python que solo necesita, ni más ni menos"])}},zzz:e=>{const{normalize:a}=e;return a(["zzz"])}};export{o as default};
