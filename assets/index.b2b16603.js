var t={PRODUCT_DESCRIPTION:e=>{const{normalize:n}=e;return n(["Jina AI bietet eine erstklassige Einbettungs-API und einen Prompt-Optimierer und erleichtert so die Entwicklung multimodaler KI-Anwendungen."])},SEO_TAG_LINE:e=>{const{normalize:n}=e;return n(["F\xFChrend in den Bereichen Einbettungen, Re-Ranking, Suche und multimodale KI"])},about_us_page:{approach:e=>{const{normalize:n}=e;return n(["Unser Vorgehen"])},approach_connect_dots:e=>{const{normalize:n}=e;return n(["Zusammenh\xE4nge: Von Power-Usern zu Unternehmen"])},approach_connect_dots_description:e=>{const{normalize:n}=e;return n(["Warum ist der Fokus auf Power-User f\xFCr unser unternehmensorientiertes Modell so wichtig? Weil es darum geht, fr\xFChe Beziehungen aufzubauen. Indem wir uns jetzt an Power-User wenden, bauen wir Br\xFCcken zu den Unternehmen, die sie in Zukunft beeinflussen werden. Es handelt sich um eine strategische Ma\xDFnahme \u2013 eine langfristige Investition, um sicherzustellen, dass unser Unternehmensangebot im Vordergrund steht, wenn diese Power-User in Entscheidungsrollen innerhalb von Organisationen aufsteigen."])},approach_content1:e=>{const{normalize:n}=e;return n(["In der sich schnell entwickelnden Welt der KI m\xFCssen Strategien sowohl flexibel als auch zukunftsorientiert sein. W\xE4hrend sich unser Kernangebot weiterhin auf Unternehmen konzentriert, hat sich die KI-Landschaft in einer Weise ver\xE4ndert, die ein \xDCberdenken unseres Ansatzes zur Kundenakquise erforderlich macht. Aus diesem Grund ist die Einf\xFChrung von Power-Usern als Einstiegspunkt in unseren Funnel nicht nur innovativ, sondern auch entscheidend f\xFCr unser nachhaltiges Wachstum im Unternehmenssektor."])},approach_content2:e=>{const{normalize:n}=e;return n(["Bei Jina AI besteht unsere Strategie darin, proaktiv statt reaktiv zu sein. Durch die Einbeziehung von Power-Usern als Einstiegspunkt in den Funnel stellen wir sicher, dass wir nicht nur aktuelle Markttrends erfassen, sondern auch strategisch f\xFCr zuk\xFCnftiges Unternehmenswachstum ger\xFCstet sind. Unser Engagement f\xFCr Unternehmen bleibt unersch\xFCtterlich; Unser Ansatz zur Erreichung dieser Ziele ist jedoch innovativ, robust und vor allem zukunftsorientiert."])},approach_miss_mark:e=>{const{normalize:n}=e;return n(["Warum traditionelle MLOps das Ziel verfehlen"])},approach_miss_mark_description:e=>{const{normalize:n}=e;return n(["Obwohl der Zustrom von Power-Usern betr\xE4chtlich ist, sind herk\xF6mmliche MLOps-Tools nicht in der Lage, deren Anforderungen zu erf\xFCllen. Diese Werkzeuge erinnern an die Verwendung eines Traktors zum Navigieren durch die Stra\xDFen der Stadt \u2013 sie sind schwer und oft \xFCbertrieben. Die Entwickler der neuen Generation verlangen agile, intuitive Tools, die ihr schnelles Entwicklungstempo erg\xE4nzen."])},approach_new_paradigm:e=>{const{normalize:n}=e;return n(["Aufforderungsbasierte Technologie: Ein neues Paradigma"])},approach_new_paradigm_description:e=>{const{normalize:n}=e;return n([`Das Jahr 2023 l\xE4utete eine bedeutende Ver\xE4nderung ein: den Aufstieg der prompt-basierten Technologie. Durch die Vereinfachung des KI-Entwicklungsprozesses wurde der Zugang zu KI-Tools demokratisiert. Jetzt k\xF6nnen auch diejenigen ohne umfangreiche Programmiererfahrung \u2013 sogenannte \u201EPower-User\u201C \u2013 an der KI-Entwicklung teilnehmen, ohne die steilen Lernkurven zu durchlaufen, die mit Tools wie Pytorch, Docker oder Kubernetes verbunden sind.

Wenn man eine Parallele zieht, \xE4hnelt dies der Entwicklung des Personal Computing. Urspr\xFCnglich bedienten nur Technikexperten Computer. Aber mit dem Aufkommen benutzerfreundlicher Schnittstellen k\xF6nnte ein breiteres Publikum teilnehmen. Heute erleben wir mit der auf Eingabeaufforderungen basierenden Technologie eine \xE4hnliche Demokratisierung der KI.`])},awards:e=>{const{normalize:n}=e;return n(["Auszeichnungen und Anerkennung"])},berlin:e=>{const{normalize:n}=e;return n(["Berlin, Deutschland"])},berlin_address:e=>{const{normalize:n}=e;return n(["Ohlauer Str. 43 (1. OG), Zone A, 10999 Berlin"])},berlin_address2:e=>{const{normalize:n}=e;return n(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berlin, Deutschland"])},bj:e=>{const{normalize:n}=e;return n(["Peking, China"])},bj_address:e=>{const{normalize:n}=e;return n(["Ebene 5, Geb\xE4ude 6, Nr. 48 Haidian West St. Peking Haidian, China"])},brochure_info:e=>{const{normalize:n}=e;return n(["Ihr Leitfaden zu unserem Unternehmen erwartet Sie"])},description:e=>{const{normalize:n}=e;return n(["Die Zukunft beginnt hier."])},download_brochure1:e=>{const{normalize:n}=e;return n(["Brosch\xFCre herunterladen"])},download_docarray_logo:e=>{const{normalize:n}=e;return n(["Laden Sie das DocArray-Logo herunter"])},download_docarray_logo_desc:e=>{const{normalize:n}=e;return n(["Greifen Sie auf das DocArray-Logo zu, ein Open-Source-Projekt, das von Jina AI initiiert und im Dezember 2022 zur Linux Foundation beigetragen hat. Verf\xFCgbar im Hell- und Dunkelmodus, in den Formaten PNG und SVG."])},download_jina_logo:e=>{const{normalize:n}=e;return n(["Laden Sie das Jina AI-Logo herunter"])},download_jina_logo_desc:e=>{const{normalize:n}=e;return n(["Holen Sie sich das Jina AI-Logo sowohl im hellen als auch im dunklen Modus, verf\xFCgbar in den Formaten PNG und SVG. Dieses Logo ist eine eingetragene Marke beim Amt der Europ\xE4ischen Union f\xFCr geistiges Eigentum (EUIPO)."])},download_logo:e=>{const{normalize:n}=e;return n(["Logos herunterladen"])},employees:e=>{const{normalize:n}=e;return n(["Mitarbeiter"])},empower_developers:e=>{const{normalize:n}=e;return n(["unterst\xFCtzte Entwickler"])},fastApiCaption:e=>{const{normalize:n}=e;return n(["Seit 2021 \xFCber 20.000 US-Dollar gespendet."])},founded:e=>{const{normalize:n}=e;return n(["Gegr\xFCndet"])},founded_in:e=>{const{normalize:n}=e;return n(["Gegr\xFCndet in"])},investors:e=>{const{normalize:n}=e;return n(["Unsere Investoren"])},linuxFoundationCaption:e=>{const{normalize:n}=e;return n(["Leistet ab 2022 einen j\xE4hrlichen Beitrag von 10.000 US-Dollar."])},mission:e=>{const{normalize:n}=e;return n(["Unsere Aufgabe"])},mission_content1:e=>{const{normalize:n}=e;return n(["Im Mittelpunkt von Jina AI steht unsere Mission, das Portal zur multimodalen KI f\xFCr eine vielf\xE4ltige Kundschaft zu sein, von Power-Usern und Entwicklern bis hin zu Unternehmen. Wir glauben fest an die Leistungsf\xE4higkeit von Open Source und widmen uns der Entwicklung fortschrittlicher, zug\xE4nglicher Tools f\xFCr die KI-Community. Unsere Schl\xFCsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Model-Tuning und Model-Serving, verk\xF6rpern unser Engagement f\xFCr die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative streben wir danach, Innovation, Zusammenarbeit und Transparenz zu f\xF6rdern und skalierbare, effiziente und robuste L\xF6sungen sicherzustellen. Jina AI ist mehr als nur ein Unternehmen; Es handelt sich um eine Community, deren Ziel es ist, Unternehmen dabei zu unterst\xFCtzen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein."])},mission_content2:e=>{const{normalize:n}=e;return n(["Im Mittelpunkt von Jina AI steht unsere Mission, das Portal zur multimodalen KI f\xFCr eine vielf\xE4ltige Kundschaft zu sein, von Power-Usern und Entwicklern bis hin zu Unternehmen. Wir glauben fest an die Leistungsf\xE4higkeit von Open Source und widmen uns der Entwicklung fortschrittlicher, zug\xE4nglicher Tools f\xFCr die KI-Community. Unsere Schl\xFCsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Embedding-Tuning und Embedding-Serving, verk\xF6rpern unser Engagement f\xFCr die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative streben wir danach, Innovation, Zusammenarbeit und Transparenz zu f\xF6rdern und skalierbare, effiziente und robuste L\xF6sungen sicherzustellen. Jina AI ist mehr als nur ein Unternehmen; Es handelt sich um eine Community, deren Ziel es ist, Unternehmen dabei zu unterst\xFCtzen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein."])},mission_content3:e=>{const{normalize:n}=e;return n(["Unsere Mission bei Jina AI besteht darin, die Weiterentwicklung der multimodalen KI durch innovative Einbettungs- und Eingabeaufforderungstechnologien voranzutreiben und uns dabei insbesondere auf Bereiche wie die Verarbeitung nat\xFCrlicher Sprache, Bild- und Videoanalyse sowie modal\xFCbergreifende Dateninteraktion zu konzentrieren. Diese Spezialisierung erm\xF6glicht es uns, einzigartige L\xF6sungen bereitzustellen, die komplexe Daten aus mehreren Quellen in umsetzbare Erkenntnisse und bahnbrechende Anwendungen umwandeln."])},numfocusCaption:e=>{const{normalize:n}=e;return n(["Spendet ab 2022 regelm\xE4\xDFig jeden Monat."])},office:e=>{const{normalize:n}=e;return n(["Unsere B\xFCros"])},otherProjectsCaption:e=>{const{normalize:n}=e;return n(["\xDCber Github Sponsorship \xFCber 3.000 US-Dollar gespendet."])},our_answer:e=>{const{normalize:n}=e;return n(["Auf jeden Fall, Yann. Wir sind dabei und bauen Br\xFCcken in eine multimodale KI-Zukunft!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:n}=e;return n(["Hat eine einmalige Spende in H\xF6he von 10.000 US-Dollar geleistet und mehrere PyCon-Veranstaltungen gesponsert, darunter in Deutschland, Italien, China und den USA."])},segmentFaultCaption:e=>{const{normalize:n}=e;return n(["Hat eine einmalige Spende in H\xF6he von 6.000 US-Dollar geleistet."])},stats:e=>{const{normalize:n}=e;return n(["Pionierarbeit f\xFCr die Zukunft der multimodalen KI"])},stats_1:e=>{const{normalize:n}=e;return n(["Jina AI wurde im Februar 2020 gegr\xFCndet und hat sich schnell zu einem globalen Pionier der multimodalen KI-Technologie entwickelt. Innerhalb eines beeindruckenden Zeitrahmens von 20 Monaten haben wir erfolgreich 37,5 Millionen US-Dollar eingesammelt und damit unsere starke Position in der KI-Branche unterstrichen. Unsere bahnbrechende Technologie, Open-Source auf GitHub, hat \xFCber 40.000 Entwicklern auf der ganzen Welt die M\xF6glichkeit gegeben, anspruchsvolle multimodale Anwendungen nahtlos zu erstellen und bereitzustellen."])},stats_2:e=>{const{normalize:n}=e;return n(["Im Jahr 2023 haben wir erhebliche Fortschritte bei der Weiterentwicklung von Tools zur KI-Generierung gemacht, die auf multimodaler Technologie basieren. Von dieser Innovation haben \xFCber 250.000 Benutzer weltweit profitiert und eine Vielzahl einzigartiger Gesch\xE4ftsanforderungen erf\xFCllt. Von der Erleichterung des Gesch\xE4ftswachstums \xFCber die Verbesserung der betrieblichen Effizienz bis hin zur Kostenoptimierung setzt sich Jina AI daf\xFCr ein, Unternehmen zu bef\xE4higen, im multimodalen Zeitalter hervorragende Leistungen zu erbringen."])},stats_3:e=>{const{normalize:n}=e;return n([`Jina AI wurde 2020 gegr\xFCndet und hat seinen Sitz in Berlin, Deutschland. Jina AI hat sich schnell zu einem f\xFChrenden Unternehmen im Bereich multimodaler KI entwickelt und konzentriert sich auf Prompt- und Einbettungstechniken. Als in der EU verwurzeltes Unternehmen erstrecken sich unsere Vision und Dienstleistungen weltweit und bieten Unternehmen und Entwicklern innovative Plattformen, um die Leistungsf\xE4higkeit der KI f\xFCr Wertsch\xF6pfung und Kosteneinsparungen zu nutzen.

Unser Engagement f\xFCr Open Source und offene Forschung hat unsere Identit\xE4t als kommerzielles Open-Source-Softwareunternehmen gepr\xE4gt. Dieses Engagement f\xFCr Innovation wird durch unser finanzielles Wachstum unterstrichen, das durch eine Kapitalerh\xF6hung in H\xF6he von 38 Millionen US-Dollar in unserer Serie-A-Runde im November 2021 gekennzeichnet ist. Bei Jina AI schlie\xDFen wir die L\xFCcke zwischen fortschrittlicher KI und praktischen Anwendungen auf globaler Ebene.`])},subtitle:e=>{const{normalize:n}=e;return n(["Revolutionierung der Inhaltserstellung durch KI-generierte L\xF6sungen, um unendliche M\xF6glichkeiten zu erschlie\xDFen. Die Zukunft KI-generierter Inhalte gestalten und die menschliche Kreativit\xE4t f\xF6rdern."])},sz:e=>{const{normalize:n}=e;return n(["Shenzhen, China"])},sz_address:e=>{const{normalize:n}=e;return n(["402, Etage 4, Fu'an Technology Building, Shenzhen Nanshan, China"])},team:e=>{const{normalize:n}=e;return n(["Im Portal von Jina AI"])},team_content:e=>{const{normalize:n}=e;return n(["Aus verschiedenen Teilen der Welt gestalten wir gemeinsam die Zukunft der multimodalen KI. Unsere unterschiedlichen Lebensstile und Perspektiven bereichern unsere Arbeit und f\xF6rdern Kreativit\xE4t und Fortschritt. Innerhalb dieses Portals umarmen wir unsere Individualit\xE4t, sch\xE4tzen unsere Freiheit und verfolgen leidenschaftlich unsere Tr\xE4ume. Willkommen auf dem Portal der KI-Zukunft."])},team_join:e=>{const{normalize:n}=e;return n(["Begleiten Sie uns"])},technologies:e=>{const{normalize:n}=e;return n(["Technologien"])},title:e=>{const{normalize:n}=e;return n(["\xDCber Jina AI"])},title0:e=>{const{normalize:n}=e;return n(["Die Zukunft"])},title1:e=>{const{normalize:n}=e;return n(["Beginnt"])},title2:e=>{const{normalize:n}=e;return n(["Hier"])},title3:e=>{const{normalize:n}=e;return n(["Beginnt hier"])},understand_our_strength:e=>{const{normalize:n}=e;return n(["Verstehen Sie unsere St\xE4rke"])},understand_our_view:e=>{const{normalize:n}=e;return n(["Verstehen Sie unsere Sicht"])},users:e=>{const{normalize:n}=e;return n(["registrierte Benutzer"])},value:e=>{const{normalize:n}=e;return n(["Unser Wert"])},value_content:e=>{const{normalize:n}=e;return n([`Bei Jina AI glauben wir an die Kraft der Open-Source-Technologie, um Innovationen zu beschleunigen, die Zusammenarbeit zu f\xF6rdern und Gemeinschaften zu st\xE4rken. Wir sind nicht nur Bef\xFCrworter \u2013 wir sind aktive Mitwirkende und investieren erheblich in die Open-Source-Community.

Von unserer Rolle als treibende Kraft hinter FastAPI bis hin zu unserer kontinuierlichen Unterst\xFCtzung der Linux- und Python-Grundlagen geben wir mit Leidenschaft etwas zur\xFCck. Aber wir h\xF6ren hier nicht auf; Wir haben auch unsere Kerninfrastruktur als Open-Source-L\xF6sung bereitgestellt und teilen so unsere multimodale KI-Expertise mit der Welt.

Bei Jina AI streben wir danach, mit gutem Beispiel voranzugehen und unsere Ressourcen zu nutzen, um die Gemeinschaft zu f\xF6rdern, die uns f\xF6rdert. Es ist unsere Art, Danke zu sagen und den Technologien, auf die wir alle angewiesen sind, eine lebendige Zukunft zu sichern. Schlie\xDFlich stecken wir alle im selben Boot.`])},vision:e=>{const{normalize:n}=e;return n(["Unsere Vision"])},vision_content1:e=>{const{normalize:n}=e;return n(["Inspiriert von Yann LeCuns Einsicht, dass \u201E"])},vision_content2:e=>{const{normalize:n}=e;return n(["Jina AI m\xF6chte den Weg f\xFCr die Zukunft der KI als multimodale Realit\xE4t ebnen. Wir sind uns bewusst, dass die bestehenden \xD6kosysteme f\xFCr maschinelles Lernen und Software beim Umgang mit multimodaler KI vor Herausforderungen stehen. Als Reaktion darauf engagieren wir uns f\xFCr die Entwicklung bahnbrechender Tools und Plattformen, die Unternehmen und Entwickler bei der Bew\xE4ltigung dieser Komplexit\xE4t unterst\xFCtzen. Unsere Vision ist es, eine entscheidende Rolle dabei zu spielen, der Welt dabei zu helfen, das enorme Potenzial der multimodalen KI zu nutzen und die Art und Weise, wie wir Informationen interpretieren und mit ihnen interagieren, wirklich zu revolutionieren."])},yannlecun_quote:e=>{const{normalize:n}=e;return n(["Ein k\xFCnstliches Intelligenzsystem, das allein auf W\xF6rter und S\xE4tze trainiert wird, wird niemals ann\xE4hernd das menschliche Verst\xE4ndnis erreichen."])}},best_banner:{description:e=>{const{normalize:n}=e;return n(["Vom Blog-Artikel zum Banner, ohne eigene Prompts!"])},example_description:e=>{const{normalize:n}=e;return n(["Alice wurde es langsam sehr leid, neben ihrer Schwester am Ufer zu sitzen und nichts zu tun zu haben: Ein- oder zweimal hatte sie in das Buch geguckt, das ihre Schwester las, aber es enthielt weder Bilder noch Gespr\xE4che. \u201EUnd was n\xFCtzt ein Buch\u201C, dachte Alice, \u201Eohne Bilder oder Gespr\xE4che?\u201C So \xFCberlegte sie in Gedanken (so gut sie konnte, denn der hei\xDFe Tag machte sie sehr schl\xE4frig und dumm), ob das Vergn\xFCgen, eine G\xE4nsebl\xFCmchenkette zu machen, die M\xFChe wert w\xE4re, aufzustehen und die G\xE4nsebl\xFCmchen zu pfl\xFCcken, als pl\xF6tzlich ein wei\xDFes Kaninchen mit rosa Augen dicht an ihr vorbeilief."])},example_title:e=>{const{normalize:n}=e;return n(["Alices Abenteuer im Wunderland \u2013 Kapitel 1"])}},beta:e=>{const{normalize:n}=e;return n(["Beta"])},blog_tags:{all:e=>{const{normalize:n}=e;return n(["Alle"])},events:e=>{const{normalize:n}=e;return n(["Veranstaltungen"])},featured:e=>{const{normalize:n}=e;return n(["Hervorgehoben"])},insights:e=>{const{normalize:n}=e;return n(["Erkenntnisse"])},"knowledge-base":e=>{const{normalize:n}=e;return n(["Wissen"])},press:e=>{const{normalize:n}=e;return n(["Pressemitteilung"])},releases:e=>{const{normalize:n}=e;return n(["Software-Updates"])},"tech-blog":e=>{const{normalize:n}=e;return n(["Tech-Blog"])}},clip_as_service:{description:e=>{const{normalize:n}=e;return n(["Erzeugen Sie Embedding-Vektoren in konstanter l\xE4nge f\xFCr Bilder und S\xE4tze mit CLIP"])}},cloud:{description:e=>{const{normalize:n}=e;return n(["Cloud-Hosting-Plattform f\xFCr multimodale KI-Anwendungen"])}},contact_us_page:{agreement:e=>{const{normalize:n}=e;return n(["Mit dem Absenden best\xE4tigen Sie, dass Sie mit der Verarbeitung Ihrer personenbezogenen Daten durch Jina AI wie im Abschnitt beschrieben einverstanden sind"])},anything_else:e=>{const{normalize:n}=e;return n(["Erz\xE4hlen Sie uns mehr \xFCber Ihr Projekt"])},company:e=>{const{normalize:n}=e;return n(["Unternehmen"])},company_size:e=>{const{normalize:n}=e;return n(["Firmengr\xF6\xDFe"])},company_website:e=>{const{normalize:n}=e;return n(["Unternehmenswebseite"])},company_website_placeholder:e=>{const{normalize:n}=e;return n(["URL f\xFCr die Homepage oder das LinkedIn-Profil Ihres Unternehmens"])},country:e=>{const{normalize:n}=e;return n(["Land"])},department:e=>{const{normalize:n}=e;return n(["Abteilung"])},description:e=>{const{normalize:n}=e;return n(["Erweitern Sie Ihr Gesch\xE4ft mit Jina AI."])},faq:e=>{const{normalize:n}=e;return n(["FAQ"])},field_required:e=>{const{normalize:n}=e;return n(["Feld ist erforderlich"])},impact_snapshots:e=>{const{normalize:n}=e;return n(["Impact-Schnappsch\xFCsse"])},invalid_date_format:e=>{const{normalize:n}=e;return n(["Ung\xFCltiges Datumsformat. Bitte verwenden Sie das Format TT-MM-JJJJ."])},invalid_email:e=>{const{normalize:n}=e;return n(["E-Mail ist ung\xFCltig"])},invalid_number:e=>{const{normalize:n}=e;return n(["Ung\xFCltige Nummer. Bitte geben Sie erneut ein"])},invalid_url:e=>{const{normalize:n}=e;return n(["Die URL ist ung\xFCltig"])},name:e=>{const{normalize:n}=e;return n(["Name"])},preferred_products:e=>{const{normalize:n}=e;return n(["F\xFCr welche Produkte interessieren Sie sich?"])},private_statement:e=>{const{normalize:n}=e;return n(["Datenschutzerkl\xE4rung"])},role:e=>{const{normalize:n}=e;return n(["Position"])},submit:e=>{const{normalize:n}=e;return n(["Einreichen"])},submit_failed:e=>{const{normalize:n}=e;return n(["Die \xDCbermittlung ist fehlgeschlagen. Bitte versuchen Sie es sp\xE4ter noch einmal."])},submit_success:e=>{const{normalize:n}=e;return n(["Vielen Dank f\xFCr Ihre Einreichung. Wir kommen bald auf Sie zur\xFCck."])},subtitle:e=>{const{normalize:n}=e;return n(["Jina AI, ein f\xFChrendes Unternehmen im Bereich multimodale KI, zeichnet sich durch Modell-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite L\xF6sungen. Mit unserer Expertise in gro\xDFen Sprachmodellen, Text-, Bild-, Video- und Audioverst\xE4ndnis, neuronaler Suche und generativer Kunst bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen."])},subtitle1:e=>{const{normalize:n}=e;return n(["Jina AI, ein f\xFChrender Anbieter multimodaler KI, zeichnet sich durch Embedding-Tuning, Embedding-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite L\xF6sungen. Mit unserer Expertise in gro\xDFen Sprachmodellen, Text-, Bild-, Video- und Audioverst\xE4ndnis, neuronaler Suche und generativer KI bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen."])},subtitle2:e=>{const{normalize:n}=e;return n(["Entdecken Sie Jina AI, die Spitze der multimodalen KI. Wir zeichnen uns durch die Einbettung und Bereitstellung von Technologien aus und nutzen Cloud-native L\xF6sungen wie Kubernetes f\xFCr robuste, skalierbare Systeme. Wir sind auf gro\xDFe Sprachmodelle und Medienverarbeitung spezialisiert und bieten mit unserer fortschrittlichen KI-Expertise innovative, zukunftsf\xE4hige Gesch\xE4ftsstrategien."])},title:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie unseren Vertrieb"])},trusted_by:e=>{const{normalize:n}=e;return n(["Unsere Partner"])},work_email:e=>{const{normalize:n}=e;return n(["Arbeits Email"])}},copy:e=>{const{normalize:n}=e;return n(["Kopieren"])},copy_to_clipboard_success:e=>{const{normalize:n}=e;return n(["In die Zwischenablage kopiert"])},dalle_flow:{description:e=>{const{normalize:n}=e;return n(["Ein Human-in-the-Loop-Workflow zum Erstellen von HD-Bildern aus Text"])}},"dev-gpt":{description:e=>{const{normalize:n}=e;return n(["Ihr virtuelles Entwicklungsteam"])}},disco_art:{description:e=>{const{normalize:n}=e;return n(["Erstellen Sie \xFCberzeugende Disco Diffusion-Kunstwerke in einer Codezeile"])}},doc_array:{description:e=>{const{normalize:n}=e;return n(["Die Datenstruktur f\xFCr multimodale Daten"])}},embedding:{"11B tokens":e=>{const{normalize:n}=e;return n(["11B-Token"])},"11B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Etwas mehr als die gesamte englische Wikipedia."])},"1B tokens":e=>{const{normalize:n}=e;return n(["1B-Token"])},"1B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Ungef\xE4hr 10.000 durchschnittliche Romane oder 1000-maliges erneutes Lesen aller Harry-Potter-Romane."])},"1M_free":e=>{const{normalize:n}=e;return n(["1 Million kostenlose Token"])},"1M_free_description":e=>{const{normalize:n}=e;return n(["Erhalten Sie 1 Million kostenlose Token mit jedem neuen API-Schl\xFCssel, keine Kreditkarte erforderlich. Geeignet sowohl f\xFCr private als auch kommerzielle Projekte."])},"2_5B tokens":e=>{const{normalize:n}=e;return n(["2,5 Milliarden Token"])},"2_5B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Alle W\xF6rter, die an einem Tag von 150.000 Menschen gesprochen werden, oder 100-mal so gro\xDF wie der US-amerikanische Code of Federal Regulations."])},"500M tokens":e=>{const{normalize:n}=e;return n(["500 Millionen Token"])},"500M tokens_intuition1":e=>{const{normalize:n}=e;return n(["Jeden Tag 10 Jahre lang die NY Times lesen oder 300 Mal \u201EAuf der Suche nach der verlorenen Zeit\u201C lesen."])},"59B tokens":e=>{const{normalize:n}=e;return n(["59B-Token"])},"59B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Alle Tweets der Welt f\xFCr zwei Tage."])},"5_5B tokens":e=>{const{normalize:n}=e;return n(["5,5 Milliarden Token"])},"5_5B tokens_intuition1":e=>{const{normalize:n}=e;return n(["Alle W\xF6rter, die jemals in der NY Times ver\xF6ffentlicht wurden."])},add_pair:e=>{const{normalize:n}=e;return n(["Neu"])},api_integration_short:e=>{const{normalize:n}=e;return n(["Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert."])},api_integrations:e=>{const{normalize:n}=e;return n(["API-Integrationen"])},autostart:e=>{const{normalize:n}=e;return n(["Die Einbettung beginnt nach einer kurzen Verz\xF6gerung automatisch"])},batch_job:e=>{const{normalize:n}=e;return n(["Batch-Job"])},batch_upload_hint:e=>{const{normalize:n}=e;return n(["Wir werden den API-Schl\xFCssel und das untenstehende Modell verwenden, um die Dokumente zu verarbeiten."])},bulk:e=>{const{normalize:n}=e;return n(["Batch-Einbettung"])},bulk_embedding_failed:e=>{const{normalize:n}=e;return n(["Batch-Einbettungsauftrag konnte nicht erstellt werden"])},buy_more_quota:e=>{const{normalize:n}=e;return n(["F\xFCllen Sie diesen API-Schl\xFCssel auf, indem Sie die ben\xF6tigten Token ausw\xE4hlen"])},buy_poster:e=>{const{normalize:n}=e;return n(["Kaufen Sie eine gedruckte Kopie"])},cancel_button:e=>{const{normalize:n}=e;return n(["Stornieren"])},click_upload_btn_above:e=>{const{normalize:n}=e;return n(["Klicken Sie oben auf die Schaltfl\xE4che \u201EHochladen\u201C, um zu beginnen."])},code:e=>{const{normalize:n}=e;return n(["Code"])},cosine_similarity:e=>{const{normalize:n}=e;return n(["Kosinus\xE4hnlichkeit"])},debugging:e=>{const{normalize:n}=e;return n(["Pr\xFCfen"])},delete_pair:e=>{const{normalize:n}=e;return n(["L\xF6schen"])},description:e=>{const{normalize:n,linked:r,type:i}=e;return n([r("landing_page.embedding_desc1",void 0,i)])},document:e=>{const{normalize:n}=e;return n(["Dokumentieren"])},download:e=>{const{normalize:n}=e;return n(["Herunterladen"])},edit_text1_text:e=>{const{normalize:n}=e;return n(["Linken Text bearbeiten"])},edit_text2_text:e=>{const{normalize:n}=e;return n(["Bearbeiten Sie den richtigen Text"])},embedding_done:e=>{const{normalize:n,interpolate:r,named:i}=e;return n([r(i("_Count"))," Dokumente erfolgreich eingebettet."])},faq:e=>{const{normalize:n,linked:r,type:i}=e;return n([r("contact_us_page.faq",void 0,i)])},faqs:{answer1:e=>{const{normalize:n}=e;return n(["Sowohl das Small- als auch das Base-Modell basieren auf der robusten JinaBert-Architektur und unterscheiden sich haupts\xE4chlich in ihrer Gr\xF6\xDFe. Das Small-Modell umfasst 33 Millionen Parameter, w\xE4hrend das Base-Modell 137 Millionen Parameter umfasst. W\xE4hrend das Basismodell eine \xFCberlegene Einbettungsleistung bietet, geht es mit einem geringf\xFCgigen Kompromiss beim Durchsatz (Abfragen pro Sekunde) einher, was das kleine Modell f\xFCr bestimmte Anwendungsf\xE4lle zu einer agileren Option macht."])},answer10:e=>{const{normalize:n}=e;return n(["Ja, wir hei\xDFen neue Benutzer willkommen, indem wir eine kostenlose Testversion f\xFCr die Einbettung von bis zu 10.000 Token mit einem unserer Modelle anbieten. Ein automatisch generierter API-Schl\xFCssel erleichtert diesen Test. Sobald das kostenlose Token-Limit ersch\xF6pft ist, k\xF6nnen Benutzer m\xFChelos Aufladungen f\xFCr ihre vorhandenen API-Schl\xFCssel \xFCber die daf\xFCr vorgesehene Registerkarte \u201EAufladung\u201C erwerben."])},answer11:e=>{const{normalize:n}=e;return n(["Nein, unsere API-Schl\xFCssel haben kein Ablaufdatum."])},answer12:e=>{const{normalize:n}=e;return n(["Nein, wir halten uns an strenge Datenschutzrichtlinien und verwenden keine Benutzereingabedaten zum Training unserer Modelle."])},answer13:e=>{const{normalize:n}=e;return n(["Nein, bei fehlgeschlagenen Anfragen werden keine Tokens berechnet."])},answer14:e=>{const{normalize:n}=e;return n(["Wir haben eine Partnerschaft mit Stripe geschlossen, um einen reibungslosen Zahlungsvorgang zu erm\xF6glichen. \xDCber diese Plattform akzeptieren wir zu Ihrer Bequemlichkeit verschiedene Zahlungsmethoden, darunter Kreditkarten, Google Pay und PayPal."])},answer15:e=>{const{normalize:n}=e;return n(["Ja, beim Kauf von Token wird eine Rechnung an die E-Mail-Adresse gesendet, die mit Ihrem Stripe-Konto verkn\xFCpft ist."])},answer16:e=>{const{normalize:n}=e;return n(["F\xFCr die kostenlose Kontingentnutzung k\xF6nnen Sie ganz einfach einen neuen API-Schl\xFCssel unter https://jina.ai/embeddings generieren. Wenn Ihr Schl\xFCssel aufgeladen wurde, wenden Sie sich bitte \xFCber Ihre registrierte E-Mail-Adresse an den Support von AT jina.ai, um Hilfe zu erhalten."])},answer17:e=>{const{normalize:n}=e;return n(["Wir arbeiten aktiv an multimodalen Modellen, die die Einbettung von Text, Bildern und Audio erm\xF6glichen. Seien Sie gespannt auf diese Updates!"])},answer18:e=>{const{normalize:n}=e;return n(["Obwohl wir derzeit keine Feinabstimmungsdienste anbieten, bereiten wir uns darauf vor, diese Funktion bald einzuf\xFChren. Halten Sie Ausschau nach dieser Funktion!"])},answer19:e=>{const{normalize:n}=e;return n(["AWS SageMaker ist jetzt verf\xFCgbar. Bald werden die Modellpakete von jina-embeddings-v2 \xFCber die Plattformen aller gro\xDFen Cloud-Dienstanbieter zug\xE4nglich sein."])},answer2:e=>{const{normalize:n}=e;return n(["Der QPS h\xE4ngt von der L\xE4nge der vom Benutzer eingegebenen S\xE4tze und dem gew\xE4hlten Modell ab. F\xFCr das Basismodell kann der QPS-Wert zwischen 4 und 100 liegen, w\xE4hrend der Bereich f\xFCr das kleine Modell zwischen 10 und 300 liegt."])},answer20:e=>{const{normalize:n}=e;return n(["F\xFCr ein tieferes Verst\xE4ndnis unserer Trainingsmethodik, Daten und Auswertungen laden wir Sie ein, unseren technischen Bericht zu erkunden, der auf arXiv verf\xFCgbar ist."])},answer21:e=>{const{normalize:n}=e;return n(["Jeder Benutzer kann bis zu 100 Anfragen pro Sekunde stellen, was die Eingabe von 204.800 Eingabes\xE4tzen pro Sekunde erm\xF6glicht."])},answer3:e=>{const{normalize:n}=e;return n(["Derzeit unterst\xFCtzen unsere Modelle ausschlie\xDFlich Englisch. Wir erweitern jedoch aktiv unsere sprachlichen F\xE4higkeiten, indem wir zus\xE4tzliche sprachspezifische Modelle trainieren. Diese kommenden Modelle sollen die gleichen qualitativen und quantitativen Vorteile bieten wie jina-embeddings-v2."])},answer4:e=>{const{normalize:n}=e;return n(["Unsere Modelle sind \xE4u\xDFerst leistungsf\xE4hig und erm\xF6glichen eine Eingabel\xE4nge von 8192 Token, was deutlich l\xE4nger ist als das, was die meisten anderen Modelle bieten. Ein Token kann nur ein Zeichen oder ein Wort lang sein (z. B. \u201Ea\u201C oder \u201Eapple\u201C). Die Anzahl der Zeichen, die Sie in einen Satz eingeben k\xF6nnen, h\xE4ngt von der L\xE4nge und Komplexit\xE4t der verwendeten W\xF6rter ab. Diese erweiterte Eingabel\xE4nge von jina-embeddings-v2-Modellen erm\xF6glicht eine umfassendere Textanalyse und eine h\xF6here Genauigkeit beim Verst\xE4ndnis des Kontexts, insbesondere in Szenarien mit umfangreichen Textdaten."])},answer5:e=>{const{normalize:n}=e;return n(["Ein einziger API-Aufruf kann bis zu 2048 S\xE4tze oder Texte verarbeiten und erm\xF6glicht so eine umfassende Textanalyse auf einmal."])},answer6:e=>{const{normalize:n}=e;return n(["Unsere Aussage basiert auf strengen Bewertungen, die im Rahmen des Open-Source-Bewertungsrahmens Massive Text Embedding Benchmark (MTEB) durchgef\xFChrt wurden. Unser Basismodell hat in dieser Bestenliste einen durchschnittlichen Platz 17 erreicht, mit besonders beeindruckender Leistung bei Kernaufgaben wie Klassifizierung, Zusammenfassung und Text\xE4hnlichkeit. Es zeichnet sich insbesondere dadurch aus, dass es das einzige Open-Source-Modell ist, das eine umfangreiche Eingabekontextl\xE4nge von 8192 Token unterst\xFCtzt, ein Zeichen f\xFCr hochmoderne Leistung."])},answer7:e=>{const{normalize:n}=e;return n(["Laut MTEB-Bestenliste behauptet sich unser Basismodell gegen\xFCber text-embedding-ada-002 von OpenAI und zeigt im Durchschnitt eine vergleichbare Leistung (Rang 17 gegen\xFCber 15). Dar\xFCber hinaus \xFCbertrifft unser Basismodell das Angebot von OpenAI in mehreren Aufgaben, einschlie\xDFlich Klassifizierung, Paarklassifizierung, Neubewertung und Zusammenfassung."])},answer8:e=>{const{normalize:n}=e;return n(["Der \xDCbergang erfolgt m\xFChelos, da unser API-Endpunkt https://api.jina.ai/v1/embeddings perfekt mit den Eingabe- und Ausgabe-JSON-Schemas des OpenAI-Endpunkts f\xFCr das text-embeddings-ada-002-Modell \xFCbereinstimmt. Diese Kompatibilit\xE4t erm\xF6glicht es Benutzern, unser Modell als direkten Ersatz f\xFCr text-embeddings-ada-002 zu integrieren, wenn sie den Endpunkt von OpenAI nutzen."])},answer9:e=>{const{normalize:n}=e;return n(["Unser Abrechnungsmodell basiert auf der Gesamtzahl der verarbeiteten Token. Benutzer haben die Flexibilit\xE4t, diese Token auf beliebig viele S\xE4tze zu verteilen und bieten so eine kosteng\xFCnstige und anpassungsf\xE4hige L\xF6sung f\xFCr unterschiedliche Textanalyseanforderungen."])},question1:e=>{const{normalize:n}=e;return n(["Was unterscheidet das Small-Modell vom Base-Modell?"])},question10:e=>{const{normalize:n}=e;return n(["Gibt es eine kostenlose Testversion f\xFCr neue Benutzer?"])},question11:e=>{const{normalize:n}=e;return n(["Haben API-Schl\xFCssel ein Ablaufdatum?"])},question12:e=>{const{normalize:n}=e;return n(["Werden Benutzereingabedaten zum Trainieren Ihrer Modelle verwendet?"])},question13:e=>{const{normalize:n}=e;return n(["Werden f\xFCr fehlgeschlagene Anfragen Token berechnet?"])},question14:e=>{const{normalize:n}=e;return n(["Welche Zahlungsmethoden werden akzeptiert?"])},question15:e=>{const{normalize:n}=e;return n(["Ist eine Rechnungsstellung f\xFCr Token-K\xE4ufe verf\xFCgbar?"])},question16:e=>{const{normalize:n}=e;return n(["Was soll ich tun, wenn ich meinen API-Schl\xFCssel vergesse?"])},question17:e=>{const{normalize:n}=e;return n(["Bieten Sie Modelle zum Einbetten von Bildern oder Audio an?"])},question18:e=>{const{normalize:n}=e;return n(["Gibt es eine Option zur Feinabstimmung von Jina Embedding-Modellen anhand privater oder Unternehmensdaten?"])},question19:e=>{const{normalize:n}=e;return n(["K\xF6nnen Ihre Endpunkte privat auf AWS-, Azure- oder GCP-Marktpl\xE4tzen gehostet werden?"])},question2:e=>{const{normalize:n}=e;return n(["Wie hoch sind die erwarteten Abfragen pro Sekunde (Queries Per Second, QPS) f\xFCr das Small- und das Base-Modell?"])},question20:e=>{const{normalize:n}=e;return n(["Wie wurden die jina-embeddings-v2-Modelle trainiert?"])},question21:e=>{const{normalize:n}=e;return n(["Wie viele API-Anfragen kann ich pro Sekunde stellen?"])},question3:e=>{const{normalize:n}=e;return n(["Welche Sprachen werden von Ihren Modellen unterst\xFCtzt?"])},question4:e=>{const{normalize:n}=e;return n(["Wie viele Zeichen kann ich maximal in einen Satz eingeben?"])},question5:e=>{const{normalize:n}=e;return n(["Wie viele S\xE4tze kann ich maximal in eine einzelne Anfrage einf\xFCgen?"])},question6:e=>{const{normalize:n}=e;return n(["Auf welcher Grundlage wird das Basismodell als State-of-the-Art bezeichnet?"])},question7:e=>{const{normalize:n}=e;return n(["Wie vergleichen sich Jina Embeddings-Modelle mit dem text-embedding-ada002-Modell von OpenAI?"])},question8:e=>{const{normalize:n}=e;return n(["Ich verwende derzeit text-embedding-ada-002 von OpenAI. Wie nahtlos verl\xE4uft der \xDCbergang zu Ihrer L\xF6sung?"])},question9:e=>{const{normalize:n}=e;return n(["Erfolgt die Abrechnung nach Anzahl der S\xE4tze bzw. Anfragen?"])}},feature_8k1:e=>{const{normalize:n}=e;return n(["8192 Token-L\xE4nge"])},feature_8k_description1:e=>{const{normalize:n}=e;return n(["Pionierarbeit beim ersten Open-Source-Einbettungsmodell mit einer L\xE4nge von 8192 Token, das die Darstellung eines gesamten Kapitels in einem einzigen Vektor erm\xF6glicht."])},feature_cheap:e=>{const{normalize:n}=e;return n(["20x g\xFCnstiger"])},feature_cheap_v1:e=>{const{normalize:n}=e;return n(["5x g\xFCnstiger"])},feature_cheap_v1_description1:e=>{const{normalize:n}=e;return n(["Beginnen Sie mit kostenlosen Testversionen und genie\xDFen Sie eine unkomplizierte Preisstruktur. Erhalten Sie Zugang zu leistungsstarken Einbettungen f\xFCr nur 20 % der OpenAI-Kosten."])},feature_multilingual:e=>{const{normalize:n}=e;return n(["Bietet unter anderem zweisprachige Modelle f\xFCr Deutsch-Englisch, Chinesisch-Englisch, ideal f\xFCr mehrsprachige Anwendungen."])},feature_on_premises:e=>{const{normalize:n}=e;return n(["Datenschutz zuerst"])},feature_on_premises_description1:e=>{const{normalize:n}=e;return n(["Stellen Sie unsere Einbettungsmodelle nahtlos direkt in Ihrer Virtual Private Cloud (VPC) bereit. Wird derzeit auf AWS Sagemaker unterst\xFCtzt, mit bevorstehenden Integrationen f\xFCr Microsoft Azure und Google Cloud Platform. F\xFCr ma\xDFgeschneiderte Kubernetes-Bereitstellungen wenden Sie sich f\xFCr spezielle Unterst\xFCtzung an unser Vertriebsteam."])},feature_on_premises_description2:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um ma\xDFgeschneiderte Kubernetes-Bereitstellungen f\xFCr Ihre Virtual Private Cloud und lokale Server zu erhalten."])},feature_solid:e=>{const{normalize:n}=e;return n(["Klassenbester"])},feature_solid_description1:e=>{const{normalize:n}=e;return n(["Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests anhand der SOTA-Modelle, um eine beispiellose Leistung zu gew\xE4hrleisten."])},feature_top_perform1:e=>{const{normalize:n}=e;return n(["Nahtlose Integration"])},feature_top_perform_description1:e=>{const{normalize:n}=e;return n(["Vollst\xE4ndig kompatibel mit der API von OpenAI. L\xE4sst sich m\xFChelos in \xFCber 10 Vektordatenbanken und RAG-Systeme integrieren und sorgt so f\xFCr ein reibungsloses Benutzererlebnis."])},file_required:e=>{const{normalize:n}=e;return n(["Datei ist erforderlich"])},file_size_exceed:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Maximale Dateigr\xF6\xDFe ",r(i("_size"))," \xFCberschritten"])},file_type_not_supported:e=>{const{normalize:n}=e;return n(["Dateityp nicht unterst\xFCtzt"])},fill_example:e=>{const{normalize:n}=e;return n(["F\xFCllen Sie das Beispiel aus"])},generate_api_key_error:e=>{const{normalize:n}=e;return n(["Die Generierung des API-Schl\xFCssels ist fehlgeschlagen."])},generating_visualization:e=>{const{normalize:n}=e;return n(["Visualisierung wird erstellt..."])},get_new_key_button:e=>{const{normalize:n}=e;return n(["Holen Sie sich einen neuen Schl\xFCssel"])},get_new_key_button_explain:e=>{const{normalize:n}=e;return n(["Wenn Sie sich f\xFCr einen neuen Schl\xFCssel entscheiden, geht der mit dem alten Schl\xFCssel verbundene Nutzungsverlauf verloren."])},get_new_key_survey:e=>{const{normalize:n}=e;return n(["Nehmen Sie an der Umfrage teil, helfen Sie uns, Ihre Nutzung zu verstehen, und erhalten Sie kostenlos einen neuen API-Schl\xFCssel!"])},input:e=>{const{normalize:n}=e;return n(["Anfrage"])},input_api_key_error1:e=>{const{normalize:n}=e;return n(["Ihr API-Schl\xFCssel existiert nicht"])},input_length:e=>{const{normalize:n}=e;return n(["Eingabel\xE4nge"])},integrate:e=>{const{normalize:n}=e;return n(["Integrieren"])},"jina-colbert-v1-en_description":e=>{const{normalize:n}=e;return n(["Ein Reranker, der die Late-Interaction-Architektur von ColBERT nutzt"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:n}=e;return n(["Optimiert f\xFCr die Suche nach Code und Dokumentzeichenfolgen"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen Deutsch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:n}=e;return n(["Auf Augenh\xF6he mit text-embedding-ada002 von OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen Spanisch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen Chinesisch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:n}=e;return n(["Optimiert f\xFCr geringe Latenz und geringen Speicherbedarf"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:n}=e;return n(["Der f\xFChrende Reranker maximiert die Such- und RAG-Relevanz"])},key:e=>{const{normalize:n}=e;return n(["API-Schl\xFCssel"])},key_enter_placeholder:e=>{const{normalize:n}=e;return n(["Bitte geben Sie Ihren API-Schl\xFCssel ein"])},key_enter_placeholder_to_topup:e=>{const{normalize:n}=e;return n(["Geben Sie den API-Schl\xFCssel ein, den Sie aufladen m\xF6chten"])},key_to_top_up:e=>{const{normalize:n}=e;return n(["API-Schl\xFCssel zum Aufladen"])},key_warn:e=>{const{normalize:n}=e;return n(["Stellen Sie sicher, dass Sie Ihren API-Schl\xFCssel an einem sicheren Ort aufbewahren. Andernfalls m\xFCssen Sie einen neuen Schl\xFCssel generieren"])},key_warn_v2:e=>{const{normalize:n}=e;return n(["F\xFCr jeden neuen Schl\xFCssel gibt es einige kostenlose Token, die Sie ausprobieren k\xF6nnen. Sie k\xF6nnen Ihren Schl\xFCssel jederzeit aufladen. Stellen Sie sicher, dass Sie Ihren API-Schl\xFCssel an einem sicheren Ort aufbewahren!"])},language_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Dieses Modell unterst\xFCtzt am besten die Sprache ",r(i("_Language")),"."])},learn_more:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr"])},learn_poster:e=>{const{normalize:n}=e;return n(["Erfahren Sie, wie wir es gemacht haben"])},learning1:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr \xFCber Einbettungen"])},learning1_description:e=>{const{normalize:n}=e;return n(["Wo soll man mit Einbettungen anfangen? Wir geben dir Deckung. Erfahren Sie mehr \xFCber Einbettungen von Grund auf mit unserem umfassenden Leitfaden."])},length:e=>{const{normalize:n}=e;return n(["Tokenl\xE4nge"])},manage_quota1:e=>{const{normalize:n}=e;return n(["Kaufen Sie Token"])},max_file_size:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Maximal zul\xE4ssige Gr\xF6\xDFe: ",r(i("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:n}=e;return n(["Maximieren Sie dieses Panel"])},model_required:e=>{const{normalize:n}=e;return n(["Modell ist erforderlich"])},more_than_two2:e=>{const{normalize:n}=e;return n(["Bitte geben Sie mehr als zwei Dokumente ein, also mehr als zwei Zeilen."])},multilingual:e=>{const{normalize:n}=e;return n(["Mehrsprachiger Support"])},new:e=>{const{normalize:n}=e;return n(["Neues Modell"])},no_data1:e=>{const{normalize:n}=e;return n(["F\xFCgen Sie ein Satzpaar hinzu, um die \xC4hnlichkeit zu berechnen"])},open_tensorboard:e=>{const{normalize:n}=e;return n(["\xD6ffnen Sie den Visualizer"])},opensource:e=>{const{normalize:n}=e;return n(["Betriebssystem"])},opensource_explain:e=>{const{normalize:n}=e;return n(["Dieses Modell ist Open Source und auf Hugging Face verf\xFCgbar. Klicken Sie auf diese Schaltfl\xE4che, um das Modell auf Hugging Face anzuzeigen."])},original_documents:e=>{const{normalize:n}=e;return n(["Dokumente zum Einbetten"])},original_documents_hint:e=>{const{normalize:n}=e;return n(["Geben Sie hier Ihre Unterlagen ein. Jede neue Zeile wird als separates Dokument betrachtet."])},output:e=>{const{normalize:n}=e;return n(["Antwort"])},output_dim:e=>{const{normalize:n}=e;return n(["Ma\xDFe"])},output_dim_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Die Ausgabedimension eines Einbettungsvektors aus diesem Modell ist ",r(i("_outputDim")),"."])},output_dimension:e=>{const{normalize:n}=e;return n(["Ausgabedimensionen"])},pairwise_test:e=>{const{normalize:n}=e;return n(["Paarweise"])},per_k:e=>{const{normalize:n}=e;return n(["/ 1K-Token"])},per_m:e=>{const{normalize:n}=e;return n(["/ 1 Mio. Token"])},please_fill_docs_first:e=>{const{normalize:n}=e;return n(["Bitte geben Sie unten zun\xE4chst einige Dokumente ein, bevor Sie mit der Suche beginnen."])},poster:e=>{const{normalize:n}=e;return n(["Die Evolution des Einbettungsplakats"])},poster_description:e=>{const{normalize:n}=e;return n(["Entdecken Sie das ideale Poster f\xFCr Ihren Raum mit fesselnden Infografiken oder atemberaubenden Bildern, die die Entwicklung der Texteinbettungsmodelle seit 1950 nachzeichnen."])},pricing:e=>{const{normalize:n}=e;return n(["API-Preise"])},pricing_desc:e=>{const{normalize:n}=e;return n(["Unsere API-Preise richten sich nach der Menge der in den Anfragen gesendeten Token. Dieses Preismodell gilt sowohl f\xFCr das Einbetten als auch f\xFCr das Reranking von APIs. Mit demselben API-Schl\xFCssel haben Sie Zugriff auf beide Dienste."])},protectData1:e=>{const{normalize:n}=e;return n(["Anforderungsdaten und Dokumente werden nicht f\xFCr Trainingsmodelle verwendet."])},protectData2:e=>{const{normalize:n}=e;return n(["Datenverschl\xFCsselung w\xE4hrend der \xDCbertragung (TLS 1.2+) und im Ruhezustand (AES-GCM 256)."])},protectData3:e=>{const{normalize:n}=e;return n(["SOC 2 und DSGVO-konform."])},protect_data:e=>{const{normalize:n}=e;return n(["Sch\xFCtzen Sie Ihre Daten"])},query:e=>{const{normalize:n}=e;return n(["Abfrage"])},read_api_docs:e=>{const{normalize:n}=e;return n(["Lesen Sie die Dokumente"])},refresh:e=>{const{normalize:n}=e;return n(["Aktualisierung"])},refresh_key_tooltip:e=>{const{normalize:n}=e;return n(["Aktualisieren Sie und erhalten Sie einen neuen API-Schl\xFCssel"])},refresh_token_count1:e=>{const{normalize:n}=e;return n(["Aktualisieren Sie, um verf\xFCgbare Token des aktuellen API-Schl\xFCssels zu erhalten"])},regenerate:e=>{const{normalize:n}=e;return n(["Regenerieren"])},remaining:e=>{const{normalize:n}=e;return n(["Verf\xFCgbare Token"])},retry:e=>{const{normalize:n}=e;return n(["Wiederholen"])},right_api_key_to_charge:e=>{const{normalize:n}=e;return n(["Bitte geben Sie zum Aufladen den richtigen API-Schl\xFCssel ein"])},search:e=>{const{normalize:n}=e;return n(["Suchen"])},search_hint:e=>{const{normalize:n}=e;return n(["Geben Sie ein, um in den unten aufgef\xFChrten Dokumenten zu suchen"])},select_embedding_model:e=>{const{normalize:n}=e;return n(["W\xE4hlen Sie Einbettungen aus"])},select_rerank_model:e=>{const{normalize:n}=e;return n(["Reranker ausw\xE4hlen"])},show_api_key:e=>{const{normalize:n}=e;return n(["API-Schl\xFCssel anzeigen"])},size:e=>{const{normalize:n}=e;return n(["Parameter"])},size_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Die Anzahl der Parameter im Modell betr\xE4gt ",r(i("_size")),". Beachten Sie, dass dies nicht die Gr\xF6\xDFe der Modelldatei ist."])},start_batch:e=>{const{normalize:n}=e;return n(["Starten Sie die Batch-Einbettung"])},start_embedding:e=>{const{normalize:n}=e;return n(["Index"])},text1:e=>{const{normalize:n}=e;return n(["Links"])},text2:e=>{const{normalize:n}=e;return n(["Rechts"])},title:e=>{const{normalize:n}=e;return n(["Einbettungs-API"])},token_example:e=>{const{normalize:n}=e;return n(["Ein Tweet kostet etwa 20 Token, ein Nachrichtenartikel etwa 1000 Token und Charles Dickens\u2018 Roman \u201EEine Geschichte zweier St\xE4dte\u201C hat \xFCber eine Million Token."])},token_length_explain:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Die maximale L\xE4nge der Eingabe-Token-Sequenz betr\xE4gt f\xFCr dieses Modell ",r(i("_tokenLength")),"."])},tokens:e=>{const{normalize:n}=e;return n(["Token"])},top_up_button:e=>{const{normalize:n}=e;return n(["Alten Schl\xFCssel aufladen"])},top_up_button_explain:e=>{const{normalize:n}=e;return n(["Die Integration dieses API-Schl\xFCssels bietet eine professionellere L\xF6sung und macht h\xE4ufige Schl\xFCssel\xE4nderungen \xFCberfl\xFCssig. Nutzungsdaten werden gespeichert und sind jederzeit abrufbar."])},top_up_warning_message1:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Der aktuelle API-Schl\xFCssel hat noch ",r(i("_remainedTokens"))," Token und wird durch einen neuen Schl\xFCssel mit ",r(i("_freeTokens"))," Token ersetzt. Sie k\xF6nnen den alten Schl\xFCssel weiterhin verwenden oder aufladen, wenn Sie ihn sicher aufbewahrt haben. Wie wollen Sie fortfahren?"])},top_up_warning_title:e=>{const{normalize:n}=e;return n(["Ersetzen Sie den alten API-Schl\xFCssel"])},total_documents:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Einbettungsfortschritt: ",r(i("_Processed")),"/",r(i("_Count"))," Dokumente."])},upload:e=>{const{normalize:n}=e;return n(["Hochladen"])},upload_file:e=>{const{normalize:n}=e;return n(["Klicken Sie hier, um eine Datei hochzuladen"])},usage:e=>{const{normalize:n}=e;return n(["Verwendung"])},usage_amount:e=>{const{normalize:n}=e;return n(["Menge"])},usage_history:e=>{const{normalize:n}=e;return n(["Nutzungsverlauf"])},usage_reason:e=>{const{normalize:n}=e;return n(["Grund"])},usage_reason_consume:e=>{const{normalize:n}=e;return n(["Verbrauchen"])},usage_reason_purchase:e=>{const{normalize:n}=e;return n(["Kaufen"])},usage_reason_trial:e=>{const{normalize:n}=e;return n(["Versuch"])},usage_rerank:e=>{const{normalize:n}=e;return n(["Verwendung"])},usage_time:e=>{const{normalize:n}=e;return n(["Zeit"])},vector_database_integration1:e=>{const{normalize:n}=e;return n(["Integrationen"])},vector_database_integration2:e=>{const{normalize:n}=e;return n(["Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Kopieren Sie zun\xE4chst einfach Ihren API-Schl\xFCssel und f\xFCgen Sie ihn in eine der aufgef\xFChrten Integrationen ein, um einen schnellen und reibungslosen Start zu erm\xF6glichen."])},vector_database_integration_description:e=>{const{normalize:n}=e;return n(["Integrieren Sie die Jina Embeddings API nahtlos und einfach in alle unten aufgef\xFChrten Vektordatenbanken, LLM-Orchestrierungs-Frameworks und RAG-Anwendungen. Unsere Tutorials zeigen Ihnen wie."])},view_details:e=>{const{normalize:n}=e;return n(["Details anzeigen"])},visualization_example:e=>{const{normalize:n}=e;return n(["Zuordnung aller S\xE4tze aus diesem Abschnitt zu einem 3D-Vektorraum"])},visualization_example_you_can:e=>{const{normalize:n}=e;return n(["Nutzen Sie unsere API unten, Sie k\xF6nnen es auch tun!"])},visualize:e=>{const{normalize:n}=e;return n(["Visualisieren"])},visualize_done:e=>{const{normalize:n}=e;return n(["Die Visualisierung ist abgeschlossen. Sie k\xF6nnen nun auf die obere Schaltfl\xE4che klicken, um den Visualizer zu \xF6ffnen."])},wait_for_processing:e=>{const{normalize:n}=e;return n(["Ihre Anfrage wird bearbeitet."])},wait_stripe:e=>{const{normalize:n}=e;return n(["Stripe-Zahlung wird ge\xF6ffnet, bitte warten"])},what_are_embedding:e=>{const{normalize:n}=e;return n(["Was sind Einbettungen?"])},what_are_embedding_answer:e=>{const{normalize:n}=e;return n([`Das Herzst\xFCck der modernen Verarbeitung nat\xFCrlicher Sprache (NLP) ist eine transformative Technik, die als Texteinbettung bekannt ist. Stellen Sie sich die Herausforderung vor, einem Computer beizubringen, die differenzierte Bedeutung von W\xF6rtern und Phrasen zu erfassen. Traditionelle Methoden, die auf starren, regelbasierten Systemen beruhten, reichten nicht aus, weil die Sprache zu komplex und flie\xDFend ist. Geben Sie Texteinbettungen ein: eine leistungsstarke L\xF6sung, die Text in eine Zahlensprache \xFCbersetzt \u2013 insbesondere in Vektoren in einem hochdimensionalen Raum.

Denken Sie an die Ausdr\xFCcke \u201Esonniges Wetter\u201C und \u201Eklarer Himmel\u201C. F\xFCr uns zeichnen sie ein \xE4hnliches Bild. Durch die Linse der Einbettungen werden diese Phrasen in numerische Vektoren umgewandelt, die in diesem mehrdimensionalen Raum nahe beieinander liegen und so ihre semantische Verwandtschaft erfassen. Bei dieser N\xE4he im Vektorraum geht es nicht nur darum, dass W\xF6rter oder Phrasen \xE4hnlich sind; Es geht darum, den Kontext, die Stimmung und sogar subtile Bedeutungsnuancen zu verstehen.

Warum ist dieser Durchbruch wichtig? Zun\xE4chst einmal schlie\xDFt es die L\xFCcke zwischen dem Reichtum der menschlichen Sprache und der Recheneffizienz von Algorithmen. Algorithmen zeichnen sich dadurch aus, dass sie mit Zahlen rechnen, nicht mit der Interpretation von Texten. Durch die Umwandlung von Text in Vektoren erm\xF6glichen Einbettungen diesen Algorithmen, Sprache auf eine Weise zu \u201Everstehen\u201C und zu verarbeiten, die zuvor unerreichbar war.

Die praktischen Anwendungen sind umfangreich und vielf\xE4ltig. Ob es darum geht, Inhalte zu empfehlen, die Ihren Interessen entsprechen, eine Konversations-KI zu unterst\xFCtzen, die sich \xFCberraschend menschlich anf\xFChlt, oder sogar subtile Muster in gro\xDFen Textmengen zu erkennen \u2013 Einbettungen sind der Schl\xFCssel. Sie erm\xF6glichen es Maschinen, Aufgaben wie Sentimentanalyse, Sprach\xFCbersetzung und vieles mehr durchzuf\xFChren, wobei das Verst\xE4ndnis der Sprache immer differenzierter und verfeinert wird.`])},what_is_a_token:e=>{const{normalize:n}=e;return n(["Ein Token ist in der Textverarbeitung eine Einheit, oft ein Wort. Zum Beispiel: \u201EJina AI ist gro\xDFartig!\u201C wird zu f\xFCnf Token, einschlie\xDFlich der Interpunktion."])},why_do_you_need:e=>{const{normalize:n}=e;return n(["Auswahl der richtigen Einbettungen"])},why_do_you_need_after:e=>{const{normalize:n}=e;return n(["Mithilfe tiefer neuronaler Netze und LLMs stellen unsere Einbettungsmodelle multimodale Daten in einem optimierten Format dar, verbessern das Maschinenverst\xE4ndnis, die effiziente Speicherung und erm\xF6glichen fortschrittliche KI-Anwendungen. Diese Einbettungen spielen eine entscheidende Rolle beim Verst\xE4ndnis der Daten, der Verbesserung des Benutzerengagements, der \xDCberwindung von Sprachbarrieren und der Optimierung von Entwicklungsprozessen."])},why_do_you_need_before:e=>{const{normalize:n}=e;return n(["Unsere Einbettungsmodelle sind speziell f\xFCr verschiedene Anwendungen konzipiert und kombinieren Sprache, Code und multimodale Darstellung, um neue M\xF6glichkeiten f\xFCr KI-gesteuerte L\xF6sungen zu er\xF6ffnen."])},why_need_1_description:e=>{const{normalize:n}=e;return n(["Unser von JinaBERT bereitgestelltes Kerneinbettungsmodell ist f\xFCr ein breites Anwendungsspektrum konzipiert. Es zeichnet sich durch das Verst\xE4ndnis detaillierter Texte aus und eignet sich daher ideal f\xFCr die semantische Suche, Inhaltsklassifizierung und komplexe Sprachanalyse. Seine Vielseitigkeit ist un\xFCbertroffen und unterst\xFCtzt die Erstellung fortschrittlicher Stimmungsanalysetools, Textzusammenfassungen und personalisierter Empfehlungssysteme."])},why_need_1_title:e=>{const{normalize:n}=e;return n(["Allgemeine Einbettungen"])},why_need_2_description:e=>{const{normalize:n}=e;return n(["Unsere zweisprachigen Modelle erleichtern die Kommunikation \xFCber Sprachen hinweg und verbessern mehrsprachige Plattformen, globalen Kundensupport und die Entdeckung mehrsprachiger Inhalte. Diese Modelle wurden f\xFCr die Beherrschung von Deutsch-Englisch- und Chinesisch-Englisch-\xDCbersetzungen entwickelt. Sie vereinfachen die Interaktion und f\xF6rdern das Verst\xE4ndnis zwischen verschiedenen Sprachgruppen."])},why_need_2_title:e=>{const{normalize:n}=e;return n(["Zweisprachige Einbettungen"])},why_need_3_description:e=>{const{normalize:n}=e;return n(["Unser auf Entwickler zugeschnittenes Code-Einbettungsmodell optimiert Codierungsaufgaben wie Zusammenfassung, Codegenerierung und automatische \xDCberpr\xFCfungen. Es steigert die Produktivit\xE4t, indem es tiefere Einblicke in Codestrukturen bietet und Verbesserungen vorschl\xE4gt, was es f\xFCr die Entwicklung fortschrittlicher IDE-Plugins, automatischer Dokumentation und modernster Debugging-Tools unerl\xE4sslich macht."])},why_need_3_title:e=>{const{normalize:n}=e;return n(["Code-Einbettungen"])},write_email_here:e=>{const{normalize:n}=e;return n(["Bitte geben Sie die E-Mail-Adresse ein, an die Sie nach Abschluss den Download-Link erhalten m\xF6chten."])},you_can_leave:e=>{const{normalize:n}=e;return n(["Sie k\xF6nnen diese Seite verlassen und wir senden Ihnen nach Abschluss den Download-Link zu."])}},embeddings:{description:e=>{const{normalize:n}=e;return n(["Unsere erstklassigen Einbettungen f\xFCr Ihre Such- und RAG-Systeme"])}},faq:{answer1:e=>{const{normalize:n}=e;return n(["Jina AI ist auf multimodale KI-Technologien spezialisiert, darunter Model-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving. Wir nutzen fortschrittliche Tools wie Kubernetes und serverlose Architekturen, um robuste, skalierbare und produktionsbereite L\xF6sungen zu erstellen."])},answer10:e=>{const{normalize:n}=e;return n(["Je nach Art des Projekts und den Bed\xFCrfnissen des Kunden bieten wir verschiedene Lizenzoptionen an. Detaillierte Konditionen k\xF6nnen mit unserem Vertriebsteam besprochen werden."])},answer11:e=>{const{normalize:n}=e;return n(["Wir bieten Dienstleistungen weltweit an, mit unserem Hauptsitz in Berlin, Europa, und weiteren B\xFCros in Peking und Shenzhen."])},answer12:e=>{const{normalize:n}=e;return n(["Ja, wir bieten Vor-Ort-Support an, insbesondere f\xFCr Kunden in der N\xE4he unserer B\xFCros in Berlin, Peking und Shenzhen. F\xFCr andere Standorte streben wir einen bestm\xF6glichen Remote-Support an und k\xF6nnen bei Bedarf auch einen Vor-Ort-Support arrangieren."])},answer2:e=>{const{normalize:n}=e;return n(["Unsere Expertise erstreckt sich \xFCber ein breites Spektrum und umfasst gro\xDFe Sprachmodelle, Text-, Bild-, Video- und Audioverst\xE4ndnis, neuronale Suche und generative Kunst."])},answer3:e=>{const{normalize:n}=e;return n(["Ja, unsere L\xF6sungen sind skalierbar und produktionsbereit. Wir erstellen unsere L\xF6sungen mithilfe cloudnativer Technologien, die eine effiziente Skalierung und zuverl\xE4ssige Leistung in Produktionsumgebungen erm\xF6glichen."])},answer4:e=>{const{normalize:n}=e;return n(["Unsere Dienstleistungen sind vielseitig und anpassungsf\xE4hig und eignen sich daher f\xFCr eine Vielzahl von Branchen, darunter E-Commerce, Legal Tech, digitales Marketing, Gaming, Gesundheitswesen, Finanzen und viele mehr."])},answer5:e=>{const{normalize:n}=e;return n(["\xDCber das Kontaktformular auf dieser Seite k\xF6nnen Sie mit unserem Vertriebsteam in Kontakt treten. Wir besprechen gerne Ihre Projektanforderungen und wie unsere L\xF6sungen Ihrem Unternehmen helfen k\xF6nnen."])},answer6:e=>{const{normalize:n}=e;return n(["Wir bieten kontinuierliche Unterst\xFCtzung, um den reibungslosen Betrieb unserer L\xF6sungen sicherzustellen. Dazu geh\xF6ren Fehlerbehebung, regelm\xE4\xDFige Updates und Verbesserungen basierend auf Ihrem Feedback und Ihren Bed\xFCrfnissen."])},answer7:e=>{const{normalize:n}=e;return n(["Die Projektdauer variiert je nach Komplexit\xE4t und Umfang des Projekts. Nachdem wir Ihre Anforderungen verstanden haben, k\xF6nnen wir einen genaueren Kostenvoranschlag erstellen."])},answer8:e=>{const{normalize:n}=e;return n(["Datensicherheit hat f\xFCr uns oberste Priorit\xE4t. Wir halten uns an strenge Datenschutzrichtlinien und -vorschriften, um sicherzustellen, dass Ihre Daten sicher und vertraulich sind."])},answer9:e=>{const{normalize:n}=e;return n(["Die Preisgestaltung richtet sich nach der Komplexit\xE4t und den Anforderungen des Projekts. Wir bieten sowohl projektbasierte als auch Retainer-Preismodelle an. F\xFCr weitere Informationen wenden Sie sich bitte an unser Vertriebsteam."])},question1:e=>{const{normalize:n}=e;return n(["Worauf ist Jina AI spezialisiert?"])},question10:e=>{const{normalize:n}=e;return n(["Welche Lizenzbedingungen gelten f\xFCr Ihre L\xF6sungen?"])},question11:e=>{const{normalize:n}=e;return n(["Was ist Ihr Servicegebiet?"])},question12:e=>{const{normalize:n}=e;return n(["Bieten Sie Vor-Ort-Support an?"])},question2:e=>{const{normalize:n}=e;return n(["Mit welchen Arten von KI arbeitet Jina AI?"])},question3:e=>{const{normalize:n}=e;return n(["Sind Ihre L\xF6sungen skalierbar und produktionsreif?"])},question4:e=>{const{normalize:n}=e;return n(["Welche Branchen k\xF6nnen von den L\xF6sungen von Jina AI profitieren?"])},question5:e=>{const{normalize:n}=e;return n(["Wie starten wir ein Projekt mit Jina AI?"])},question6:e=>{const{normalize:n}=e;return n(["Welche Unterst\xFCtzung leisten Sie nach der Implementierung einer L\xF6sung?"])},question7:e=>{const{normalize:n}=e;return n(["Was ist die typische Dauer f\xFCr ein Projekt?"])},question8:e=>{const{normalize:n}=e;return n(["Wie sch\xFCtzt Jina AI meine Daten?"])},question9:e=>{const{normalize:n}=e;return n(["Wie ist die Preisstruktur f\xFCr Ihre Dienstleistungen?"])}},finetuner:{description:e=>{const{normalize:n}=e;return n(["Optimieren Sie die Einbettungen dom\xE4nenspezifischer Daten f\xFCr eine bessere Suchqualit\xE4t"])},intro:e=>{const{normalize:n}=e;return n(["Ihr Unternehmen. Deine Daten. Ihr Modell"])}},finetuner_plus:{description:e=>{const{normalize:n}=e;return n(["St\xE4rken Sie Ihr Unternehmen mit gro\xDFen Sprachmodellen die genau auf Ihre Daten zugeschnitten sind"])}},footer:{address_beijing:e=>{const{normalize:n}=e;return n(["Peking, China"])},address_berlin:e=>{const{normalize:n}=e;return n(["Berlin, Deutschland (Hauptsitz)"])},address_shenzhen:e=>{const{normalize:n}=e;return n(["Shenzhen, China"])},all_rights_reserved:e=>{const{normalize:n}=e;return n(["Alle Rechte vorbehalten."])},company:e=>{const{normalize:n}=e;return n(["Unternehmen"])},developers:e=>{const{normalize:n}=e;return n(["Entwickler"])},docs:e=>{const{normalize:n}=e;return n(["Dokumente"])},enterprise:e=>{const{normalize:n}=e;return n(["Unternehmen"])},offices:e=>{const{normalize:n}=e;return n(["B\xFCros"])},power_users:e=>{const{normalize:n}=e;return n(["Power-User"])},privacy_policy:e=>{const{normalize:n}=e;return n(["Datenschutz-Bestimmungen"])},privacy_settings:e=>{const{normalize:n}=e;return n(["Datenschutzeinstellungen"])},tc:e=>{const{normalize:n}=e;return n(["Terms & amp; Bedingungen"])}},github:{stars:e=>{const{normalize:n}=e;return n(["Sterne"])}},header:{about_us:e=>{const{normalize:n}=e;return n(["\xDCber uns"])},company:e=>{const{normalize:n}=e;return n(["Unternehmen"])},contact_us:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie unseren Vertrieb"])},developers_others:e=>{const{normalize:n}=e;return n(["Weitere Entwicklertools"])},enterprise_others:e=>{const{normalize:n}=e;return n(["Weitere Unternehmensl\xF6sungen"])},for_developers:e=>{const{normalize:n}=e;return n(["F\xFCr Entwickler"])},for_developers_description:e=>{const{normalize:n}=e;return n(["Erleben Sie einen umfassenden multimodalen Open-Source-KI-Stack, der f\xFCr Entwickler entwickelt wurde."])},for_enterprise:e=>{const{normalize:n}=e;return n(["F\xFCr Firmen"])},for_enterprise_description:e=>{const{normalize:n}=e;return n(["Entdecken Sie skalierbare multimodale KI-Strategien, die auf die Gesch\xE4ftsanforderungen zugeschnitten sind."])},for_power_users:e=>{const{normalize:n}=e;return n(["F\xFCr Power-User"])},for_power_users_description:e=>{const{normalize:n}=e;return n(["Nutzen Sie unsere optimierten multimodalen Tools, um Ihre Produktivit\xE4t zu steigern."])},internship1:e=>{const{normalize:n}=e;return n(["Praktikantenprogramm"])},jobs:e=>{const{normalize:n}=e;return n(["Begleiten Sie uns"])},join_discord:e=>{const{normalize:n}=e;return n(["Treten Sie unserer Discord-Community bei"])},news:e=>{const{normalize:n}=e;return n(["Pressemitteilungen"])},open_day:e=>{const{normalize:n}=e;return n(["Tag der offenen T\xFCr"])},power_users_others:e=>{const{normalize:n}=e;return n(["Mehr Power-User-Tools"])},products:e=>{const{normalize:n}=e;return n(["Produkte"])}},hub:{description:e=>{const{normalize:n}=e;return n(["Teilen und entdecken Sie Bausteine \u200B\u200Bf\xFCr multimodale KI-Anwendungen"])}},huggingface:{sentence_similarity:e=>{const{normalize:n}=e;return n(["Text-Embedding"])},updated_about:e=>{const{normalize:n}=e;return n(["Aktualisiert \xFCber"])}},impact_snapshots:{project1:e=>{const{normalize:n}=e;return n(["Erm\xF6glicht eine hochpr\xE4zise Suche in 3D-Netzdaten unter Verwendung von Punktwolkeninformationen."])},project10:e=>{const{normalize:n}=e;return n(["Nutzung von Computer Vision zur Verbesserung der digitalen Zug\xE4nglichkeit von Regierungswebsites."])},project11:e=>{const{normalize:n}=e;return n(["Fein abgestimmtes LLM f\xFCr ein Beratungsunternehmen zur Optimierung der Finanzdatenanalyse."])},project12:e=>{const{normalize:n}=e;return n(["Fortschrittliche Marketingstrategien durch Feinabstimmung von Text-zu-Bild-Modellen f\xFCr die Stil\xFCbertragung."])},project2:e=>{const{normalize:n}=e;return n(["Entwickelte eine inhaltsbasierte Suchmaschine f\xFCr kurze Animationsfilme."])},project3:e=>{const{normalize:n}=e;return n(["Verbesserte E-Commerce-Conversion-Rates durch Feinabstimmung der Embedding-Modelle."])},project4:e=>{const{normalize:n}=e;return n(["Durchf\xFChrung zeitnaher Optimierungen zur Effizienzsteigerung f\xFCr ein Unternehmensberatungen."])},project5:e=>{const{normalize:n}=e;return n(["Pionierarbeit beim Verst\xE4ndnis von Spielszenen und automatischer Annotation f\xFCr ein f\xFChrendes Gaming-Unternehmen."])},project6:e=>{const{normalize:n}=e;return n(["Implementierung einer Echtzeit-Prompt-Erweiterung f\xFCr ein Chatbot-Unternehmen, um das Benutzererlebnis zu verbessern."])},project7:e=>{const{normalize:n}=e;return n(["Revolutionierte die Rechtstechnologie, indem es eine effiziente Suche in umfangreichen Rechtsdokumenten erm\xF6glichte."])},project8:e=>{const{normalize:n}=e;return n(["Unterst\xFCtzung eines generativen Kunstdienstes mit hohem Durchsatz f\xFCr gro\xDF angelegte Operationen."])},project9:e=>{const{normalize:n}=e;return n(["Durchf\xFChrung von Process-Mining und Modellierung unter Verwendung fortschrittlicher Sprachmodelle."])}},inference:{description:e=>{const{normalize:n}=e;return n(["Hochmoderne multimodale KI-Modelle stehen f\xFCr Sie \xFCber unsere API zur Verf\xFCgung"])}},internship_faq:{answer1:e=>{const{normalize:n}=e;return n(["Bachelor-, Master- und Ph.D.-Studieng\xE4nge Studierende aus der ganzen Welt mit Interesse an Bereichen wie Forschung, Ingenieurwesen, Marketing und Vertrieb werden aufgefordert, sich zu bewerben. Wir freuen uns auch \xFCber nicht-technische Praktika in den Bereichen Marketing, Vertrieb, Assistenz von F\xFChrungskr\xE4ften und mehr. Wir suchen leidenschaftliche Menschen, die bereit sind, mit uns Pionierarbeit in der multimodalen KI zu leisten."])},answer10:e=>{const{normalize:n}=e;return n(["Ja, unser Praktikumsprogramm bietet eine wettbewerbsf\xE4hige Verg\xFCtung."])},answer11:e=>{const{normalize:n}=e;return n(["Als Jina AI-Praktikant sammeln Sie praktische Erfahrungen bei der Arbeit an anspruchsvollen Projekten, lernen von Branchenexperten, werden Teil einer lebendigen Community und haben die M\xF6glichkeit, echte Beitr\xE4ge zu unserer Pionierarbeit in der multimodalen KI zu leisten."])},answer2:e=>{const{normalize:n}=e;return n(["Praktika m\xFCssen vor Ort in einem unserer B\xFCros in Berlin, Peking und Shenzhen absolviert werden."])},answer3:e=>{const{normalize:n}=e;return n(["Ja, Jina AI bietet erfolgreichen Antragstellern angemessene Unterst\xFCtzung im Visumverfahren."])},answer4:e=>{const{normalize:n}=e;return n(["Ja, Jina AI bietet Praktikanten w\xE4hrend des Praktikums eine angemessene Deckung der Lebenshaltungskosten an."])},answer5:e=>{const{normalize:n}=e;return n(["Ja, die Anfertigung Ihrer Masterarbeit w\xE4hrend Ihres Praktikums bei Jina AI ist in der Regel f\xFCr Studierende deutscher Hochschulen m\xF6glich. Sie ben\xF6tigen jedoch eine vorherige Mitteilung und Zustimmung des Betreuers Ihrer Universit\xE4t. Beachten Sie, dass wir Studierenden nicht bei der Suche nach Beratern helfen."])},answer6:e=>{const{normalize:n}=e;return n(["Der Bewerbungsprozess umfasst die Einreichung Ihres Bewerbungsformulars, eines Lebenslaufs, eines Anschreibens, in dem Sie Ihr Interesse und Ihre Motivation zum Ausdruck bringen, sowie aller relevanten beruflichen Links wie GitHub oder LinkedIn. Wir bewerten Kandidaten anhand ihrer Leistung w\xE4hrend des Vorstellungsgespr\xE4chs und ihrer Leistung an ihrer Universit\xE4t."])},answer7:e=>{const{normalize:n}=e;return n(["Ja, erfolgreiche Praktikanten k\xF6nnen am Ende ihres Praktikums ein Empfehlungsschreiben erhalten, das von unserem CEO unterzeichnet wird."])},answer8:e=>{const{normalize:n}=e;return n(["Die Dauer des Praktikums variiert je nach Rolle und Projekt. In der Regel liegt sie jedoch zwischen drei und sechs Monaten."])},answer9:e=>{const{normalize:n}=e;return n(["Ja, wir freuen uns \xFCber Bewerbungen mit allen akademischen Hintergr\xFCnden. Wir sch\xE4tzen Ihre Leidenschaft und Ihr Engagement f\xFCr das Lernen ebenso wie Ihre vorherige Erfahrung."])},question1:e=>{const{normalize:n}=e;return n(["Wer kann sich f\xFCr das Jina AI-Praktikumsprogramm bewerben?"])},question10:e=>{const{normalize:n}=e;return n(["Ist das ein bezahltes Praktikum?"])},question11:e=>{const{normalize:n}=e;return n(["Welche M\xF6glichkeiten habe ich als Jina AI-Praktikant?"])},question2:e=>{const{normalize:n}=e;return n(["Wo findet das Praktikum statt?"])},question3:e=>{const{normalize:n}=e;return n(["Unterst\xFCtzt Jina AI bei Visa-Prozessen?"])},question4:e=>{const{normalize:n}=e;return n(["Bietet Jina AI Praktikanten Zulagen oder Vorteile?"])},question5:e=>{const{normalize:n}=e;return n(["Kann ich w\xE4hrend des Praktikums bei Jina AI an meiner Masterarbeit arbeiten?"])},question6:e=>{const{normalize:n}=e;return n(["Wie l\xE4uft der Bewerbungsprozess ab?"])},question7:e=>{const{normalize:n}=e;return n(["Stellt Jina AI nach dem Praktikum ein Empfehlungsschreiben aus?"])},question8:e=>{const{normalize:n}=e;return n(["Wie lange dauert das Praktikum?"])},question9:e=>{const{normalize:n}=e;return n(["Kann ich mich bewerben, wenn ich noch keine Erfahrung im Bereich KI habe?"])}},internship_page:{about_internship_program:e=>{const{normalize:n}=e;return n(["\xDCber das Praktikumsprogramm"])},about_internship_program_desc1:e=>{const{normalize:n}=e;return n(["Wir freuen uns, talentierten Menschen diese einzigartige Gelegenheit bieten zu k\xF6nnen, Teil unseres dynamischen Teams zu werden und an bahnbrechenden Projekten im Bereich der k\xFCnstlichen Intelligenz mitzuwirken. Dieses Praktikum soll Ihnen wertvolle praktische Erfahrungen, Mentoring und Einblick in modernste Technologien bieten, die die Zukunft der KI pr\xE4gen."])},about_internship_program_desc2:e=>{const{normalize:n}=e;return n(["Bei Jina AI wissen wir, wie wichtig es ist, junge Talente zu f\xF6rdern und zu gewinnen. Wir wissen, dass Praktikanten neue Perspektiven, Begeisterung und Kreativit\xE4t einbringen und unser Team mit neuen Ideen und Ans\xE4tzen beleben. Durch die Bereitstellung von Praktika wollen wir das Wachstum zuk\xFCnftiger F\xFChrungskr\xE4fte in der KI-Branche f\xF6rdern und ihnen gleichzeitig praktische Erfahrungen in einem unterst\xFCtzenden und herausfordernden Umfeld bieten."])},alumni:e=>{const{normalize:n}=e;return n(["ALUMNI"])},alumni_network:e=>{const{normalize:n}=e;return n(["Unser florierendes Alumni-Netzwerk"])},application:e=>{const{normalize:n}=e;return n(["Anwendung"])},application_desc:e=>{const{normalize:n}=e;return n(["Begeben Sie sich mit Jina AI auf eine transformative Reise. Unser umfassendes Praktikumsprogramm l\xE4dt alle leidenschaftlichen K\xF6pfe ein, die die Zukunft der k\xFCnstlichen Intelligenz mitgestalten m\xF6chten. Kommen Sie zu uns, um praktische Erfahrungen zu sammeln, an anspruchsvollen Projekten zu arbeiten und mit einigen der kl\xFCgsten K\xF6pfe der KI-Branche zusammenzuarbeiten."])},apply:e=>{const{normalize:n}=e;return n(["Jetzt bewerben"])},autumn:e=>{const{normalize:n}=e;return n(["Herbst"])},description:e=>{const{normalize:n}=e;return n(["Weltweiter Aufruf f\xFCr Studenten: Praktikanten in Forschung, Technik, Marketing, Vertrieb und mehr, um gemeinsam Pionierarbeit f\xFCr multimodale KI zu leisten."])},dev_rel_intern:e=>{const{normalize:n}=e;return n(["Praktikant im Bereich Developer Relations"])},enthusiastic:e=>{const{normalize:n}=e;return n(["ENTHUSIASTISCH"])},explore_stories_from_our_interns:e=>{const{normalize:n}=e;return n(["Entdecken Sie Geschichten unserer Praktikanten"])},explore_stories_from_our_interns1:e=>{const{normalize:n}=e;return n(["Lassen Sie sich von den Reisen unserer Praktikanten inspirieren"])},innovative:e=>{const{normalize:n}=e;return n(["INNOVATIV"])},intern_work1:e=>{const{normalize:n}=e;return n(["Fein abgestimmte LLM-Modelle f\xFCr bessere Einbettungen"])},intern_work2:e=>{const{normalize:n}=e;return n(["Erkundete das Potenzial der Retrieval Augmented Generation"])},intern_work3:e=>{const{normalize:n}=e;return n(["Ver\xF6ffentlichung eines Artikels zum Thema Satzeinbettungen"])},intern_work4:e=>{const{normalize:n}=e;return n(["Der Mannschaft kontinuierlich jugendliche Vitalit\xE4t verleihen"])},intern_work5:e=>{const{normalize:n}=e;return n(["Benchmarked-Quantisierungstechniken zur Komprimierung von LLM"])},intern_work6:e=>{const{normalize:n}=e;return n(["Erstellen und Bewerben einer \xFCberzeugenden Kampagne f\xFCr PromptPerfect"])},recruiting_and_administrative_intern:e=>{const{normalize:n}=e;return n(["Praktikant im Bereich Personalbeschaffung und Verwaltung"])},self_motivated:e=>{const{normalize:n}=e;return n(["SELBST MOTIVIERT"])},software_engineer_intern:e=>{const{normalize:n}=e;return n(["Praktikant im Bereich Software-Ingenieur"])},spring:e=>{const{normalize:n}=e;return n(["Fr\xFChling"])},submit_application:e=>{const{normalize:n}=e;return n(["Starten Sie Ihr Abenteuer mit Jina AI"])},subtitle:e=>{const{normalize:n}=e;return n(["Unser Vollzeit-Praktikumsprogramm bietet praktische Arbeitserfahrung durch gut konzipierte Praktikumsprojekte in einem breiten Spektrum."])},subtitle1:e=>{const{normalize:n}=e;return n(["Weltweiter Aufruf f\xFCr Studenten: Praktikanten in Forschung, Technik, Marketing, Vertrieb und mehr, um gemeinsam Pionierarbeit f\xFCr multimodale KI zu leisten."])},summer:e=>{const{normalize:n}=e;return n(["Sommer"])},title:e=>{const{normalize:n}=e;return n(["Praktikantenprogramm"])},who_do_we_look_for:e=>{const{normalize:n}=e;return n(["Wen suchen wir?"])},who_do_we_look_for_desc:e=>{const{normalize:n}=e;return n(["Wir legen Wert auf Vielfalt und ermutigen Bewerber mit unterschiedlichen Profilen und Hintergr\xFCnden, an unserem Praktikumsprogramm teilzunehmen. Die Praktikumsm\xF6glichkeiten werden in mehreren Abteilungen angeboten, darunter Technik, Design, Produktmanagement, Vertrieb und Account Management, Marketing und Community Management."])},winter:e=>{const{normalize:n}=e;return n(["Winter"])}},jcloud:{description:e=>{const{normalize:n}=e;return n(["Stellen Sie ein lokales Projekt als Cloud-Dienst bereit. Radikal einfach, keine b\xF6sen \xDCberraschungen."])}},jerboa:{description:e=>{const{normalize:n}=e;return n(["Ein experimenteller Finetuner f\xFCr Open-Source-LLMs"])}},jina:{description:e=>{const{normalize:n}=e;return n(["Erstellen Sie multimodale KI-Anwendungen in der Cloud"])}},jina_chat:{description:e=>{const{normalize:n}=e;return n(["Mehr Modalit\xE4ten, l\xE4ngerer Speicher, weniger Kosten"])},example_1:e=>{const{normalize:n}=e;return n(["Wer bist du?"])},example_2:e=>{const{normalize:n}=e;return n(["Ich bin ein LLM-Chat-Dienst von Jina AI"])}},landing_page:{also_available_on:e=>{const{normalize:n}=e;return n(["Auch auf den Marktpl\xE4tzen erh\xE4ltlich"])},also_available_on1:e=>{const{normalize:n}=e;return n(["Verf\xFCgbar auf den Marktpl\xE4tzen Ihrer Enterprise Cloud"])},ask_how_your_question:e=>{const{normalize:n}=e;return n(["Bitte beschreibe dein Problem"])},build_js:e=>{const{normalize:n}=e;return n(["JavaScript SDK verwenden"])},build_python:e=>{const{normalize:n}=e;return n(["Python SDK verwenden"])},checkout_our_solution_for_you:e=>{const{normalize:n}=e;return n(["Entdecken Sie unsere auf Sie zugeschnittene L\xF6sung"])},coming_soon:e=>{const{normalize:n}=e;return n(["Demn\xE4chst"])},contact_sales:e=>{const{normalize:n}=e;return n(["Kontaktieren Sie unseren Vertrieb"])},copied_to_clipboard:e=>{const{normalize:n}=e;return n(["In die Zwischenablage kopiert"])},copy:e=>{const{normalize:n}=e;return n(["Kopieren"])},developers:e=>{const{normalize:n}=e;return n(["Entwickler"])},developers_desc:e=>{const{normalize:n}=e;return n(["Nutzen Sie die volle Leistungsf\xE4higkeit multimodaler KI mit modernsten Cloud-Technologien und Open-Source-Infrastruktur."])},download_pdf:e=>{const{normalize:n}=e;return n(["PDF Herunterladen"])},embedding_desc1:e=>{const{normalize:n}=e;return n(["Das weltweit erste Open-Source-Einbettungsmodell mit einer L\xE4nge von 8192 Token, das mit text-embedding-ada002 von OpenAI im Massive Text Embedding Benchmark (MTEB) \xFCbereinstimmt."])},embedding_paper_desc:e=>{const{normalize:n}=e;return n(["Jina Embeddings stellt eine Reihe leistungsstarker Text-Embedding-odelle dar, die in der Lage sind, verschiedene Texteingaben in numerische Darstellungen zu \xFCbersetzen und so die semantische Essenz des Textes zu erfassen. Obwohl diese Modelle nicht ausschlie\xDFlich f\xFCr die Textgenerierung konzipiert sind, zeichnen sie sich durch Anwendungen wie Dense Retrieval und semantische Text\xE4hnlichkeit aus. In diesem Artikel wird die Entwicklung von Jina Embeddings detailliert beschrieben, beginnend mit der Erstellung eines hochwertigen Paar- und Triplett-Datensatzes. Es unterstreicht die entscheidende Rolle der Datenbereinigung bei der Datensatzvorbereitung, gibt detaillierte Einblicke in den Modelltrainingsprozess und schlie\xDFt mit einer umfassenden Leistungsbewertung mithilfe des Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:n}=e;return n(["Jina Embeddings: Ein neuartiger Satz leistungsstarker Text-Embedding-Modelle"])},embeddings:e=>{const{normalize:n}=e;return n(["Einbettungen"])},enterprise:e=>{const{normalize:n}=e;return n(["Unternehmen"])},enterprise_desc:e=>{const{normalize:n}=e;return n(["Steigern Sie Ihr Gesch\xE4ft mit skalierbaren, sicheren und ma\xDFgeschneiderten multimodalen KI-L\xF6sungen."])},enterprise_desc_v2:e=>{const{normalize:n}=e;return n(["Probieren Sie unsere erstklassigen Einbettungsmodelle aus, um Ihre Such- und RAG-Systeme zu verbessern. Beginnen Sie mit einer kostenlosen Testversion!"])},enterprise_desc_v3:e=>{const{normalize:n}=e;return n(["Wir entwickeln hochmoderne Suchgrundmodelle f\xFCr hochwertige Unternehmenssuch- und RAG-L\xF6sungen. Beginnen Sie mit einer kostenlosen Testversion!"])},error:e=>{const{normalize:n,interpolate:r,named:i}=e;return n(["Beim Abrufvorgang ist ein Problem aufgetreten: ",r(i("message"))])},find_your_portal:e=>{const{normalize:n}=e;return n(["W\xE4hlen Sie Ihr Portal"])},finding_faq:e=>{const{normalize:n}=e;return n(["Generieren einer Antwort basierend auf dem FAQ-Wissen unten"])},for:e=>{const{normalize:n}=e;return n(["F\xFCr"])},get_api_now:e=>{const{normalize:n}=e;return n(["API"])},how_to:e=>{const{normalize:n}=e;return n(["Wie man"])},include_experiment:e=>{const{normalize:n}=e;return n(["Bezieht unsere experimentellen und archivierten Projekte in die L\xF6sung ein."])},join_community:e=>{const{normalize:n}=e;return n(["Treten Sie der Community bei"])},learn_more_embeddings:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr \xFCber Einbettungen"])},learn_more_reranker:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr \xFCber Reranker"])},llm:e=>{const{normalize:n}=e;return n(["LLM-Embedding-Modelle"])},llm_desc:e=>{const{normalize:n}=e;return n(["Wir bieten eine Sammlung leistungsstarker Text-Embedding-Modelle mit 35 Millionen bis 6 Milliarden Parametern. Sie eignen sich hervorragend zur Verbesserung der neuronalen Suche, Neuordnung, Satz\xE4hnlichkeit, Empfehlungen usw. Machen Sie sich bereit, Ihr KI-Erlebnis zu verbessern!"])},mentioned_products:e=>{const{normalize:n}=e;return n(["Erw\xE4hnte Produkte:"])},mmstack:e=>{const{normalize:n}=e;return n(["Multimodaler Stapel"])},mmstack_desc:e=>{const{normalize:n}=e;return n(["Der entwicklerfreundliche, cloudnative und produktionsbereite Stack f\xFCr die Erstellung multimodaler KI-Anwendungen."])},multimodal:e=>{const{normalize:n}=e;return n(["Multimodal"])},multimodal_ai:e=>{const{normalize:n}=e;return n(["Multimodalen KI"])},new:e=>{const{normalize:n}=e;return n(["Neu"])},newsroom:e=>{const{normalize:n}=e;return n(["Pressemitteilungen"])},"on-prem-deploy":e=>{const{normalize:n}=e;return n(["Bereitstellung vor Ort"])},"on-premises":e=>{const{normalize:n}=e;return n(["Auf dem Gel\xE4nde"])},opensource:e=>{const{normalize:n}=e;return n(["Open Source"])},our_publications:e=>{const{normalize:n}=e;return n(["Unsere Ver\xF6ffentlichungen"])},parameters:e=>{const{normalize:n}=e;return n(["Parameter"])},power_users:e=>{const{normalize:n}=e;return n(["Power-User"])},power_users_desc:e=>{const{normalize:n}=e;return n(["Erleben Sie leistungsstarke, benutzerfreundliche multimodale KI-Apps. Kein Programmieren, kein Aufwand, nur Ergebnisse."])},powered_by_promptperfect:e=>{const{normalize:n}=e;return n(["Unterst\xFCtzt durch die Funktionen \u201EPrompt-Optimierung\u201C und \u201EPrompt as a Service\u201C von PromptPerfect"])},pricing:e=>{const{normalize:n}=e;return n(["Preisgestaltung"])},proposing_solution:e=>{const{normalize:n}=e;return n(["Vorschlag einer L\xF6sung basierend auf Jina AI-Produkten..."])},read_more:e=>{const{normalize:n}=e;return n(["Weiterlesen"])},require_full_question:e=>{const{normalize:n}=e;return n(["Bitte beschreiben Sie Ihr Problem detaillierter."])},reranker:e=>{const{normalize:n}=e;return n(["Reranker"])},researcher_desc:e=>{const{normalize:n}=e;return n(["Um zu verstehen, wie unsere gro\xDFen Sprachmodelle von Grund auf f\xFCr Einbettungsaufgaben trainiert wurden, schauen Sie sich unsere neuesten Forschungsergebnisse und Ver\xF6ffentlichungen an. Treffen Sie unser Team auf den EMNLP-, ACL-, SIGIR-, NeurIPS- und ICML-Konferenzen."])},researchers:e=>{const{normalize:n}=e;return n(["Forscher"])},sdk:e=>{const{normalize:n}=e;return n(["SDK"])},sdk_desc:e=>{const{normalize:n}=e;return n(["M\xF6chten Sie zukunftsweisende AIGC-Anwendungen erstellen? Mit den APIs PromptPerfect, SceneXplain, BestBanner, JinaChat und Rationale ist das einfach. Probieren Sie unser benutzerfreundliches SDK aus und legen Sie in wenigen Minuten los."])},sdk_docs:e=>{const{normalize:n}=e;return n(["Lesen Sie die Dokumente"])},sdk_example:e=>{const{normalize:n}=e;return n(["Beispiel"])},starter_kit:e=>{const{normalize:n}=e;return n(["Starter-Kit"])},supercharged:e=>{const{normalize:n}=e;return n(["Aufgeladen."])},trusted_by:e=>{const{normalize:n}=e;return n(["UNSERE PARTNER"])},try_it_for_free:e=>{const{normalize:n}=e;return n(["Probieren Sie es kostenlos aus, keine Kreditkarte erforderlich"])},try_our_saas:e=>{const{normalize:n}=e;return n(["Probieren Sie unsere gehostete L\xF6sung aus, einen direkten Ersatz f\xFCr die Einbettungs-API von OpenAI."])},your_portal_to:e=>{const{normalize:n}=e;return n(["Ihr Portal zur"])},your_search_foundation:e=>{const{normalize:n}=e;return n(["Ihre Suchgrundlage"])}},langchain_serve:{description:e=>{const{normalize:n}=e;return n(["Langchain-Apps in der Produktion mit Jina und FastAPI"])}},news_page:{back_to_newsroom:e=>{const{normalize:n}=e;return n(["Zur\xFCck zum Newsroom"])},categories:e=>{const{normalize:n}=e;return n(["Kategorien"])},copy_link:e=>{const{normalize:n}=e;return n(["Kopieren Sie den Link zu diesem Abschnitt"])},in_this_article:e=>{const{normalize:n}=e;return n(["In diesem Artikel"])},learn_more:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr"])},news_not_found:e=>{const{normalize:n}=e;return n(["Artikel nicht gefunden"])},redirect_to_news:e=>{const{normalize:n}=e;return n(["Weiterleitung zum Newsroom in 5 Sekunden..."])}},newsroom_page:{author:e=>{const{normalize:n}=e;return n(["Vom Autor"])},description:e=>{const{normalize:n}=e;return n(["Lesen Sie die neuesten Nachrichten und Updates von Jina AI."])},engineering_group:e=>{const{normalize:n}=e;return n(["Engineering-Gruppe"])},engineering_group_date:e=>{const{normalize:n}=e;return n(["31. Mai 2021"])},minutes_read:e=>{const{normalize:n}=e;return n(["Minuten gelesen"])},most_recent_articles:e=>{const{normalize:n}=e;return n(["Neueste Artikel"])},news_description:e=>{const{normalize:n}=e;return n(["Bei Jina 2.0 haben wir auf die Community geh\xF6rt. Wirklich tief zugeh\xF6rt. \u201EWas sind Ihre Schmerzpunkte?\u201C \u201E, fragten wir und waren gespannt auf wertvolles Feedback.\u201C"])},news_title:e=>{const{normalize:n}=e;return n(["Durchsuchen Sie alle Dinge: Wir veranstalten einen MEME-Wettbewerb f\xFCr Jina 2.0"])},photos:e=>{const{normalize:n}=e;return n(["Fotos"])},product:e=>{const{normalize:n}=e;return n(["Nach Produkt"])},search:e=>{const{normalize:n}=e;return n(["Suche nach Titel"])},tech_blog:e=>{const{normalize:n}=e;return n(["Tech-Blog"])},title:e=>{const{normalize:n}=e;return n(["Pressemitteilungen"])},top_stories:e=>{const{normalize:n}=e;return n(["Top-Geschichten"])}},notice:e=>{const{normalize:n}=e;return n(["\u{1F389} Unser erstes Buch \u201ENeural Search \u2013 From Prototype to Production with Jina\u201C ist heute offiziell erh\xE4ltlich!"])},open_day:{description:e=>{const{normalize:n}=e;return n(["Eine exklusive Gelegenheit, einen Insider-Einblick in Jina AI zu gewinnen."])},engage:e=>{const{normalize:n}=e;return n(["Wir f\xF6rdern den interaktiven Dialog den ganzen Tag \xFCber. Der Austausch von Gedanken und Perspektiven ist f\xFCr uns von unsch\xE4tzbarem Wert. M\xF6gliche Kooperationen, die sich aus diesen Diskussionen ergeben, k\xF6nnten erheblich zu einer st\xE4rker integrierten und innovativeren Zukunft beitragen."])},engage_title:e=>{const{normalize:n}=e;return n(["Beteiligen Sie sich an uns"])},experience:e=>{const{normalize:n}=e;return n(["Wir haben f\xFCr unsere G\xE4ste eine immersive dreist\xFCndige Tour zusammengestellt, die auf Deutsch, Englisch, Franz\xF6sisch, Spanisch, Chinesisch und Russisch verf\xFCgbar ist. Die Tour bietet einen detaillierten Einblick in unsere Fortschritte in der multimodalen KI, unsere Sicht auf die KI-Landschaft, gefolgt von einer detaillierten Untersuchung spezifischer Projekte. Wir schlie\xDFen mit einer Gruppendiskussion ab, um den Austausch von Ideen und Erkenntnissen zu erleichtern. Auf Anfrage ist auch ein Mittagessen erh\xE4ltlich."])},experience_title:e=>{const{normalize:n}=e;return n(["Die Reise eines Insiders"])},group_size:e=>{const{normalize:n}=e;return n(["Gesch\xE4tzte Besucherzahl"])},impact:e=>{const{normalize:n}=e;return n(["Erfahren Sie, wie unsere Beitr\xE4ge zur Open-Source-Community und unsere Arbeit in der multimodalen KI-Technologie Jina AI als einflussreichen Akteur bei KI-Innovationen etablieren. Unser Ziel ist es, eine wichtige Rolle in Entscheidungsprozessen zu spielen und sicherzustellen, dass die Weiterentwicklung der KI-Technologie allen zugute kommt."])},impact_title:e=>{const{normalize:n}=e;return n(["Wirkung und Einfluss"])},introduction:e=>{const{normalize:n}=e;return n(["Jina AI freut sich, unsere T\xFCren f\xFCr angesehene Unternehmen und Organisationen zu \xF6ffnen, die sich f\xFCr den Fortschritt und die Zukunft der k\xFCnstlichen Intelligenz interessieren. Diese exklusive Gelegenheit bieten wir Vertretern aus Politik, NGOs, NPOs und der Investmentbranche an, hier in unserem Berliner Hauptsitz einen Insider-Blick auf unsere Aktivit\xE4ten und Visionen zu erhalten."])},motivation_min_length_v1:e=>{const{normalize:n}=e;return n(["Bitte geben Sie eine detailliertere Motivation an."])},motivation_placeholder_v2:e=>{const{normalize:n}=e;return n(["Wenn Sie uns Ihre Beweggr\xFCnde mitteilen, k\xF6nnen wir Ihr Erlebnis verbessern."])},motivation_to_attend_v2:e=>{const{normalize:n}=e;return n(["Warum interessieren Sie sich f\xFCr unseren Tag der offenen T\xFCr?"])},one_hour:e=>{const{normalize:n}=e;return n(["1 Stunde"])},organization:e=>{const{normalize:n}=e;return n(["Organisation"])},organization_website:e=>{const{normalize:n}=e;return n(["Website der Organisation"])},organization_website_placeholder:e=>{const{normalize:n}=e;return n(["URL f\xFCr die Homepage oder das LinkedIn-Profil Ihrer Organisation"])},preferred_date:e=>{const{normalize:n}=e;return n(["Bevorzugtes Datum"])},preferred_language:e=>{const{normalize:n}=e;return n(["Bevorzugte Sprache der Tour"])},preferred_products:e=>{const{normalize:n}=e;return n(["F\xFCr welche Produkte interessieren Sie sich?"])},subtitle:e=>{const{normalize:n}=e;return n(["Ein Blick in die Zukunft der multimodalen KI"])},title:e=>{const{normalize:n}=e;return n(["Tag der offenen T\xFCr"])},tutor_subtitle:e=>{const{normalize:n}=e;return n(["Eine sorgf\xE4ltig kuratierte dreist\xFCndige Tour, die Ihnen den Kern der bahnbrechenden Arbeit von Jina AI in der multimodalen KI-Technologie n\xE4her bringt."])},tutor_title:e=>{const{normalize:n}=e;return n(["Ein exklusiver tiefer Einblick in"])},vision:e=>{const{normalize:n}=e;return n(["Verschaffen Sie sich mit uns einen umfassenden \xDCberblick \xFCber die KI-Landschaft aus unserer Sicht. Unsere Diskussion konzentriert sich auf das Potenzial gro\xDFer Sprachmodelle, multimodaler KI und den Einfluss von Open-Source-Technologie auf die Gestaltung der Zukunft globaler Innovation."])},vision_title:e=>{const{normalize:n}=e;return n(["Unsere Vision f\xFCr die Zukunft"])}},open_day_faq:{answer1:e=>{const{normalize:n}=e;return n(["Wir bieten F\xFChrungen auf Deutsch, Englisch, Franz\xF6sisch, Spanisch, Chinesisch und Russisch an."])},answer2:e=>{const{normalize:n}=e;return n(["Die Tour dauert normalerweise etwa drei Stunden."])},answer3:e=>{const{normalize:n}=e;return n(["Das Mittagessen ist optional und kann auf Anfrage arrangiert werden."])},answer4:e=>{const{normalize:n}=e;return n(["Unser Tag der offenen T\xFCr richtet sich in erster Linie an Berufsgruppen wie Politiker, NGOs, NPOs und Investoren. Allerdings machen wir gelegentlich Ausnahmen basierend auf dem Profil der Person."])},answer5:e=>{const{normalize:n}=e;return n(["Wir k\xF6nnen unterschiedliche Gruppengr\xF6\xDFen unterbringen. Bitte geben Sie im Anmeldeformular die Gr\xF6\xDFe Ihrer Gruppe an und wir kl\xE4ren die Einzelheiten mit Ihnen ab."])},answer6:e=>{const{normalize:n}=e;return n(["Im Anmeldeformular gibt es einen Abschnitt, in dem Sie Ihre Interessengebiete oder spezielle W\xFCnsche angeben k\xF6nnen. Wir werden unser Bestes tun, um die Tour Ihren Bed\xFCrfnissen anzupassen."])},answer7:e=>{const{normalize:n}=e;return n(["Derzeit bieten wir F\xFChrungen nur in unserem Berliner Hauptsitz in Kreuzberg an. Unsere B\xFCros in Peking und Shenzhen sind derzeit nicht f\xFCr F\xFChrungen ge\xF6ffnet."])},question1:e=>{const{normalize:n}=e;return n(["Welche Sprachen bieten Sie f\xFCr die Tour an?"])},question2:e=>{const{normalize:n}=e;return n(["Wie lange dauert die Tour?"])},question3:e=>{const{normalize:n}=e;return n(["Wird Mittagessen angeboten?"])},question4:e=>{const{normalize:n}=e;return n(["K\xF6nnen sich Einzelpersonen f\xFCr den Tag der offenen T\xFCr anmelden?"])},question5:e=>{const{normalize:n}=e;return n(["Aus wie vielen Personen darf eine Gruppe am Tag der offenen T\xFCr bestehen?"])},question6:e=>{const{normalize:n}=e;return n(["Wie kann ich Interessengebiete f\xFCr die Tour angeben?"])},question7:e=>{const{normalize:n}=e;return n(["Sind F\xFChrungen in Ihren B\xFCros in Peking oder Shenzhen verf\xFCgbar?"])}},open_gpt:{description:e=>{const{normalize:n}=e;return n(["Ein Open-Source-Cloud-natives Framework f\xFCr die Bereitstellung gro\xDFer multimodaler KI-Modelle"])}},powered_by:e=>{const{normalize:n}=e;return n(["Angetrieben von"])},print:e=>{const{normalize:n}=e;return n(["Drucken"])},project_status:{archived:e=>{const{normalize:n}=e;return n(["Archiviert"])},cloud_native:e=>{const{normalize:n}=e;return n(["Cloud-nativ"])},core:e=>{const{normalize:n}=e;return n(["Kern"])},data_structure:e=>{const{normalize:n}=e;return n(["Datenstruktur"])},embedding_serving:e=>{const{normalize:n}=e;return n(["Servieren einbetten"])},embedding_tuning:e=>{const{normalize:n}=e;return n(["Tuning einbetten"])},graduated:e=>{const{normalize:n}=e;return n(["Absolvent"])},incubating:e=>{const{normalize:n}=e;return n(["Inkubieren"])},kubernetes:e=>{const{normalize:n}=e;return n(["Kubernetes"])},large_size_model:e=>{const{normalize:n}=e;return n(["Gro\xDFes Modell"])},linux_foundation:e=>{const{normalize:n}=e;return n(["Linux Foundation"])},llm1:e=>{const{normalize:n}=e;return n(["LLMOps"])},mid_size_model:e=>{const{normalize:n}=e;return n(["Mittelgro\xDFes Modell"])},model_serving:e=>{const{normalize:n}=e;return n(["Modelldienst"])},model_tuning:e=>{const{normalize:n}=e;return n(["Modelltuning"])},orchestration:e=>{const{normalize:n}=e;return n(["Orchestrierung"])},prompt_serving:e=>{const{normalize:n}=e;return n(["Prompt-Serving"])},prompt_tuning:e=>{const{normalize:n}=e;return n(["Prompt-Verbesserung"])},rag1:e=>{const{normalize:n}=e;return n(["LAPPEN"])},sandbox:e=>{const{normalize:n}=e;return n(["Sandkasten"])},small_size_model:e=>{const{normalize:n}=e;return n(["Kleines Modell"])},vector_database:e=>{const{normalize:n}=e;return n(["Vektordatenbank"])},vector_store:e=>{const{normalize:n}=e;return n(["Vector Store"])}},prompt_perfect:{description:e=>{const{normalize:n}=e;return n(["Erstklassiges Tool f\xFCr schnelles Engineering"])},image_model:e=>{const{normalize:n}=e;return n(["Bildmodelle"])},intro:e=>{const{normalize:n}=e;return n(["Erstklassiges Tool f\xFCr schnelles Engineering"])},intro1:e=>{const{normalize:n}=e;return n(["Das erstklassige Tool f\xFCr schnelles Engineering"])},optimized:e=>{const{normalize:n}=e;return n(["Ihre Aufgabe ist es, mein Brainstorming-Partner zu sein und kreative Ideen und Vorschl\xE4ge zu einem bestimmten Thema oder Problem zu liefern. Ihre Antwort sollte originelle, einzigartige und relevante Ideen enthalten, die zur L\xF6sung des Problems beitragen oder das Thema auf interessante Weise weiter vertiefen k\xF6nnen. Bitte beachten Sie, dass Ihre Antwort auch etwaige spezifische Anforderungen oder Einschr\xE4nkungen der Aufgabe ber\xFCcksichtigen sollte."])},optimized_title:e=>{const{normalize:n}=e;return n(["Optimierte Eingabeaufforderung"])},original:e=>{const{normalize:n}=e;return n(["Sei mein Brainstorming-Partner."])},original_title:e=>{const{normalize:n}=e;return n(["Urspr\xFCngliche Aufforderung"])},text_model:e=>{const{normalize:n}=e;return n(["Textmodelle"])}},purchase_now:e=>{const{normalize:n}=e;return n(["Jetzt kaufen"])},rationale:{decision:e=>{const{normalize:n}=e;return n(["Entscheidung"])},description:e=>{const{normalize:n}=e;return n(["Ultimative KI-Tools zur Entscheidungsfindung"])},intro:e=>{const{normalize:n}=e;return n(["Sehen Sie die zwei Seiten der Medaille und treffen Sie rationale Entscheidungen"])}},reranker:{benchmark:{description0:e=>{const{normalize:n}=e;return n(["LlamaIndex bewertete verschiedene Kombinationen von Einbettungen und Rerankern f\xFCr RAG und f\xFChrte eine Replikationsstudie durch, in der der mittlere reziproke Rang gemessen wurde. Die Ergebnisse unterstreichen die deutliche Verbesserung der Suchqualit\xE4t durch den Jina Reranker, ein Vorteil, der unabh\xE4ngig von den verwendeten spezifischen Einbettungen ist."])},description1:e=>{const{normalize:n}=e;return n(["BIER (Benchmarking IR) bewertet die Abrufeffektivit\xE4t eines Modells, einschlie\xDFlich Relevanz und NDCG. Ein h\xF6herer BIER-Score korreliert mit genaueren \xDCbereinstimmungen und Suchergebnissen."])},description2:e=>{const{normalize:n}=e;return n(["Mithilfe des LoCo-Benchmarks haben wir das Verst\xE4ndnis eines Modells f\xFCr lokale Koh\xE4renz und Kontext sowie das abfragespezifische Ranking gemessen. Eine h\xF6here LoCo-Bewertung spiegelt eine bessere F\xE4higkeit wider, relevante Informationen zu identifizieren und zu priorisieren."])},description3:e=>{const{normalize:n}=e;return n(["Der MTEB (Multilingual Text Embedding Benchmark) testet im Gro\xDFen und Ganzen die F\xE4higkeiten eines Modells bei Texteinbettungen, einschlie\xDFlich Clustering, Klassifizierung, Abruf und anderen Metriken. F\xFCr unseren Vergleich haben wir jedoch nur die Reranking-Aufgaben des MTEB herangezogen."])},title0:e=>{const{normalize:n}=e;return n(["LamaIndex"])},title1:e=>{const{normalize:n}=e;return n(["BEIR"])},title2:e=>{const{normalize:n}=e;return n(["Lok"])},title3:e=>{const{normalize:n}=e;return n(["MTBB"])}},benchmark_description:e=>{const{normalize:n}=e;return n(["Zum Vergleich haben wir drei weitere f\xFChrende Reranker von BGE (BAAI), BCE (Netease Youdao) und Cohere in die Benchmark einbezogen. Wie aus den folgenden Ergebnissen hervorgeht, erzielt Jina Reranker in allen relevanten Kategorien f\xFCr das Reranking die h\xF6chste Durchschnittspunktzahl und ist damit klarer Spitzenreiter unter seinen Mitbewerbern."])},benchmark_title:e=>{const{normalize:n}=e;return n(["Leistungsbenchmark"])},description:e=>{const{normalize:n}=e;return n(["Maximieren Sie ganz einfach die Suchrelevanz und die RAG-Genauigkeit"])},description_rich:e=>{const{normalize:n}=e;return n(["Maximieren Sie die Suchrelevanz und RAG-Genauigkeit mit unserer hochmodernen Reranker-API. Beginnen Sie mit 1 Million kostenlosen Token."])},feature_on_premises_description2:e=>{const{normalize:n}=e;return n(["Stellen Sie Jina Reranker auf AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um ma\xDFgeschneiderte Kubernetes-Bereitstellungen f\xFCr Ihre Virtual Private Cloud und lokale Server zu erhalten."])},feature_solid_description:e=>{const{normalize:n}=e;return n(["Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests mit den SOTA-Rerankern, um eine beispiellose Leistung zu gew\xE4hrleisten."])},how_it_works:e=>{const{normalize:n}=e;return n(["So funktioniert das:"])},how_it_works_v1:{description1:e=>{const{normalize:n}=e;return n(["Ein Suchsystem verwendet Einbettungen/BM25, um basierend auf der Anfrage des Benutzers eine breite Palette potenziell relevanter Dokumente zu finden."])},description2:e=>{const{normalize:n}=e;return n(["Anschlie\xDFend analysiert der Reranker diese Ergebnisse auf einer detaillierteren Ebene und ber\xFCcksichtigt dabei die Nuancen der Interaktion der Abfragebegriffe mit dem Dokumentinhalt."])},description3:e=>{const{normalize:n}=e;return n(["Es ordnet die Suchergebnisse neu und platziert diejenigen, die es auf der Grundlage dieser tiefergehenden Analyse f\xFCr am relevantesten h\xE4lt, ganz oben."])},title1:e=>{const{normalize:n}=e;return n(["Erster Abruf"])},title2:e=>{const{normalize:n}=e;return n(["Neueinstufung"])},title3:e=>{const{normalize:n}=e;return n(["Verbesserte Ergebnisse"])}},improve_performance:e=>{const{normalize:n}=e;return n(["Garantierte Verbesserung gegen\xFCber der Vektorsuche"])},improve_performance_description:e=>{const{normalize:n}=e;return n(["Unsere Auswertungen zeigten Verbesserungen f\xFCr Suchsysteme, die den Jina Reranker verwenden, mit +8 % bei der Trefferquote und +33 % beim mittleren reziproken Rang."])},learning1:e=>{const{normalize:n}=e;return n(["Erfahren Sie mehr \xFCber Reranker"])},learning1_description:e=>{const{normalize:n}=e;return n(["Was ist ein Reranker? Warum reicht die Vektorsuche oder die Kosinus\xE4hnlichkeit nicht aus? Erfahren Sie mit unserem umfassenden Leitfaden mehr \xFCber Reranker von Grund auf."])},read_more_about_benchmark:e=>{const{normalize:n}=e;return n(["Lesen Sie mehr \xFCber den Benchmark"])},reranker_description:e=>{const{normalize:n}=e;return n(["Probieren Sie unsere hochmoderne Reranker-API aus, um Ihre Suchrelevanz und RAG-Genauigkeit zu maximieren. Kostenlos starten!"])},title:e=>{const{normalize:n}=e;return n(["Reranker-API"])},try_embedding:e=>{const{normalize:n}=e;return n(["Probieren Sie die Einbettungs-API kostenlos aus"])},try_reranker:e=>{const{normalize:n}=e;return n(["Testen Sie die Reranker-API kostenlos"])},vs_table:{col0:e=>{const{normalize:n}=e;return n(["Reranker"])},col0_1:e=>{const{normalize:n}=e;return n(["Verbesserte Suchpr\xE4zision und Relevanz"])},col0_2:e=>{const{normalize:n}=e;return n(["Erste, schnelle Filterung"])},col0_3:e=>{const{normalize:n}=e;return n(["Allgemeine Textsuche f\xFCr weitreichende Abfragen"])},col1:e=>{const{normalize:n}=e;return n(["Vektorsuche"])},col1_1:e=>{const{normalize:n}=e;return n(["Detailliert: Unterdokument und Abfragesegment"])},col1_2:e=>{const{normalize:n}=e;return n(["Breit: Ganze Dokumente"])},col1_3:e=>{const{normalize:n}=e;return n(["Mittelstufe: Verschiedene Textsegmente"])},col2:e=>{const{normalize:n}=e;return n(["BM25"])},col2_1:e=>{const{normalize:n}=e;return n(["Hoch"])},col2_2:e=>{const{normalize:n}=e;return n(["Mittel"])},col2_3:e=>{const{normalize:n}=e;return n(["Niedrig"])},col3_1:e=>{const{normalize:n}=e;return n(["Nicht ben\xF6tigt"])},col3_2:e=>{const{normalize:n}=e;return n(["Hoch"])},col3_3:e=>{const{normalize:n}=e;return n(["Niedrig, nutzt vorgefertigten Index"])},col4_1:e=>{const{normalize:n}=e;return n(["Hoch"])},col4_2:e=>{const{normalize:n}=e;return n(["Hoch"])},col4_3:e=>{const{normalize:n}=e;return n(["Nicht ben\xF6tigt"])},col5_1:e=>{const{normalize:n}=e;return n(["Hervorragend f\xFCr differenzierte Abfragen"])},col5_2:e=>{const{normalize:n}=e;return n(["Ausgewogen zwischen Effizienz und Genauigkeit"])},col5_3:e=>{const{normalize:n}=e;return n(["Konsistent und zuverl\xE4ssig f\xFCr eine breite Palette von Abfragen"])},col6_1:e=>{const{normalize:n}=e;return n(["Sehr pr\xE4zise mit tiefem Kontextverst\xE4ndnis"])},col6_2:e=>{const{normalize:n}=e;return n(["Schnell und effizient, mit m\xE4\xDFiger Genauigkeit"])},col6_3:e=>{const{normalize:n}=e;return n(["Hoch skalierbar, mit nachgewiesener Wirksamkeit"])},col7_1:e=>{const{normalize:n}=e;return n(["Ressourcenintensiv bei komplexer Umsetzung"])},col7_2:e=>{const{normalize:n}=e;return n(["Erfasst m\xF6glicherweise keinen tiefen Abfragekontext oder keine Nuancen"])},col7_3:e=>{const{normalize:n}=e;return n(["Bei sehr spezifischen oder kontextbezogenen Suchen ist die Leistung m\xF6glicherweise unterdurchschnittlich"])},header0:e=>{const{normalize:n}=e;return n(["Beste f\xFCr"])},header1:e=>{const{normalize:n}=e;return n(["Die Granularit\xE4t"])},header2:e=>{const{normalize:n}=e;return n(["Komplexit\xE4t der Abfragezeit"])},header3:e=>{const{normalize:n}=e;return n(["Zeitkomplexit\xE4t indizieren"])},header4:e=>{const{normalize:n}=e;return n(["Komplexit\xE4t der Trainingszeit"])},header5:e=>{const{normalize:n}=e;return n(["Suchqualit\xE4t"])},header6:e=>{const{normalize:n}=e;return n(["St\xE4rken"])},header7:e=>{const{normalize:n}=e;return n(["Schw\xE4chen"])},subtitle:e=>{const{normalize:n}=e;return n(["Die folgende Tabelle bietet einen umfassenden Vergleich von Reranker, Vector/Embeddings Search und BM25 und hebt deren St\xE4rken und Schw\xE4chen in verschiedenen Kategorien hervor."])},title:e=>{const{normalize:n}=e;return n(["Vergleich von Reranker, Vector Search und BM25"])}},what_is:e=>{const{normalize:n}=e;return n(["Was ist ein Reranker?"])},what_is_answer_long:e=>{const{normalize:n}=e;return n([`Ziel eines Suchsystems ist es, schnell und effizient die relevantesten Ergebnisse zu finden. Traditionell wurden Methoden wie BM25 oder tf-idf verwendet, um Suchergebnisse basierend auf der Keyword-\xDCbereinstimmung zu ordnen. Neuere Methoden, wie beispielsweise die einbettungsbasierte Kosinus\xE4hnlichkeit, wurden in vielen Vektordatenbanken implementiert. Diese Methoden sind unkompliziert, k\xF6nnen jedoch manchmal die Feinheiten der Sprache und vor allem die Interaktion zwischen Dokumenten und der Absicht einer Abfrage au\xDFer Acht lassen.

Hier gl\xE4nzt der \u201EReranker\u201C. Ein Reranker ist ein fortschrittliches KI-Modell, das die anf\xE4nglichen Ergebnisse einer Suche \u2013 oft bereitgestellt durch eine einbettungs-/tokenbasierte Suche \u2013 und sie neu bewertet, um sicherzustellen, dass sie besser mit der Absicht des Benutzers \xFCbereinstimmen. Es geht \xFCber den oberfl\xE4chlichen Abgleich von Begriffen hinaus und ber\xFCcksichtigt die tiefere Interaktion zwischen der Suchanfrage und dem Inhalt der Dokumente.`])},what_is_answer_long_ending:e=>{const{normalize:n}=e;return n(["Der Reranker kann die Suchqualit\xE4t erheblich verbessern, da er auf Unterdokument- und Unterabfrageebene arbeitet, d. h. die einzelnen W\xF6rter und Phrasen, ihre Bedeutung und ihre Beziehung zueinander innerhalb der Abfrage und der Dokumente untersucht. Dies f\xFChrt zu pr\xE4ziseren und kontextbezogeneren Suchergebnissen."])},what_is_desc:e=>{const{normalize:n}=e;return n(["Ein Reranker ist ein KI-Modell, das die Suchergebnisse aus einer Vektorsuche oder einem Dense-Retrieval-Modell verfeinert. Mehr lesen."])}},scenex:{caption_image_desc:e=>{const{normalize:n}=e;return n(["Generieren Sie eine Textbeschreibung des Bildes."])},caption_image_title:e=>{const{normalize:n}=e;return n(["Bildunterschrift"])},description:e=>{const{normalize:n}=e;return n(["Entdecken Sie auf Bildern basierende Geschichtenerz\xE4hlungen jenseits von Pixeln"])},example1:e=>{const{normalize:n}=e;return n(["Bei diesem Video handelt es sich offenbar um eine Naturaufnahme mit einem bezaubernden wei\xDFen Hasen und einem Schmetterling auf einer Wiese. Der Hase interagiert auf unterschiedliche Weise mit dem Schmetterling und zeigt so ihre einzigartige Beziehung. Die nat\xFCrliche Umgebung bietet eine malerische Kulisse und unterstreicht die Sch\xF6nheit dieser einfachen, aber faszinierenden Szene."])},generate_story_desc:e=>{const{normalize:n}=e;return n(["Erstellen Sie eine vom Bild inspirierte Geschichte, die h\xE4ufig Dialoge oder Monologe der Charaktere enth\xE4lt."])},generate_story_title:e=>{const{normalize:n}=e;return n(["Geschichte generieren"])},intro1:e=>{const{normalize:n}=e;return n(["F\xFChrende KI-L\xF6sung f\xFCr Bildunterschriften und Videozusammenfassungen"])},json_image_desc:e=>{const{normalize:n}=e;return n(["Generieren Sie mithilfe eines vordefinierten Schemas ein strukturiertes JSON-Format aus dem Bild. Dies erm\xF6glicht eine gezielte Datenextraktion aus dem Bild."])},json_image_title:e=>{const{normalize:n}=e;return n(["Extrahieren Sie JSON aus dem Bild"])},summarize_video_desc:e=>{const{normalize:n}=e;return n(["Erstellen Sie eine pr\xE4gnante Zusammenfassung des Videos und heben Sie wichtige Ereignisse hervor."])},summarize_video_title:e=>{const{normalize:n}=e;return n(["Video zusammenfassen"])},visual_q_a_desc:e=>{const{normalize:n}=e;return n(["Beantworten Sie eine Frage basierend auf dem Bildinhalt."])},visual_q_a_title:e=>{const{normalize:n}=e;return n(["Visuelle Fragen und Antworten"])}},searchbar:{hotkey:e=>{const{normalize:n}=e;return n(["Dr\xFCcken Sie die Taste /, um auf dieser Seite zu suchen"])},hotkey1:e=>{const{normalize:n}=e;return n(["Dr\xFCcken Sie"])},hotkey2:e=>{const{normalize:n}=e;return n(["Umschalten"])},hotkey_long1:e=>{const{normalize:n}=e;return n(["Dr\xFCcken Sie jederzeit"])},hotkey_long2:e=>{const{normalize:n}=e;return n(["um auf der aktuellen Seite zu suchen"])},placeholder:e=>{const{normalize:n}=e;return n(["Stellen Sie auf dieser Seite Fragen"])},proposing_solution:e=>{const{normalize:n}=e;return n(["Generierung einer Antwort basierend auf dem Seiteninhalt ..."])},required:e=>{const{normalize:n}=e;return n(["Bitte beschreiben Sie Ihre Frage genauer."])}},searchscape:{description:e=>{const{normalize:n}=e;return n(["Navigieren, interagieren, verfeinern: Produktentdeckung neu denken"])}},semantic:{description:e=>{const{normalize:n}=e;return n(["\xDCberbr\xFCckung der semantischen L\xFCcke in Ihrer vorhandenen Suchinfrastruktur"])}},share:{"Hacker News":e=>{const{normalize:n}=e;return n(["Hacker-News"])},LinkedIn:e=>{const{normalize:n}=e;return n(["LinkedIn"])},facebook:e=>{const{normalize:n}=e;return n(["Facebook"])},reddit:e=>{const{normalize:n}=e;return n(["Reddit"])},rss:e=>{const{normalize:n}=e;return n(["RSS-Feed"])},share_btn:e=>{const{normalize:n}=e;return n(["Aktie"])},twitter:e=>{const{normalize:n}=e;return n(["X (Twitter)"])}},spectrum:{embedding_serving:e=>{const{normalize:n}=e;return n(["Servieren einbetten"])},embedding_serving_description:e=>{const{normalize:n}=e;return n(["Bereitstellung von Einbettungen \xFCber einen robusten, skalierbaren Mikroservice unter Verwendung cloudnativer Technologien."])},embedding_tech:e=>{const{normalize:n}=e;return n(["Einbettungen"])},embedding_tech_description:e=>{const{normalize:n}=e;return n([`Bei Jina AI nutzen wir die Leistungsf\xE4higkeit der Einbettungstechnologie, um verschiedene KI-Anwendungen zu revolutionieren. Diese Technologie dient als einheitliche Methode zur effizienten Darstellung und Komprimierung verschiedener Datentypen und stellt sicher, dass keine wichtigen Informationen verloren gehen. Unser Fokus liegt auf der Transformation komplexer Datens\xE4tze in ein allgemein verst\xE4ndliches Einbettungsformat, das f\xFCr eine pr\xE4zise und aufschlussreiche KI-Analyse unerl\xE4sslich ist.

Einbettungen sind von grundlegender Bedeutung, insbesondere bei Anwendungen wie der pr\xE4zisen Bild- und Spracherkennung, wo sie dabei helfen, feink\xF6rnige Details und Nuancen zu erkennen. Bei der Verarbeitung nat\xFCrlicher Sprache verbessern Einbettungen das Verst\xE4ndnis von Kontext und Stimmung und f\xFChren zu genaueren Konversations-KI- und Sprach\xFCbersetzungstools. Sie sind auch von entscheidender Bedeutung bei der Entwicklung anspruchsvoller Empfehlungssysteme, die ein tiefes Verst\xE4ndnis der Benutzerpr\xE4ferenzen in verschiedenen Inhaltsformen wie Text, Audio und Video erfordern.`])},embedding_tuning:e=>{const{normalize:n}=e;return n(["Tuning einbetten"])},embedding_tuning_description:e=>{const{normalize:n}=e;return n(["Optimierung hochwertiger Einbettungen durch Integration von Fachwissen f\xFCr eine verbesserte aufgabenspezifische Leistung."])},for_developers:e=>{const{normalize:n}=e;return n(["F\xFCr Entwickler"])},for_enterprise:e=>{const{normalize:n}=e;return n(["F\xFCr Unternehmen"])},for_power_users:e=>{const{normalize:n}=e;return n(["F\xFCr Power-User"])},model_serving:e=>{const{normalize:n}=e;return n(["Modelldienst"])},model_serving_description:e=>{const{normalize:n}=e;return n(["Die Bereitstellung fein abgestimmter Modelle in einer Produktionsumgebung, die in der Regel erhebliche Ressourcen wie GPU-Hosting erfordert. MLOps, wobei der Schwerpunkt auf der skalierbaren, effizienten und zuverl\xE4ssigen Bereitstellung mittelgro\xDFer bis gro\xDFer Modelle liegt."])},model_tuning:e=>{const{normalize:n}=e;return n(["Modelltuning"])},model_tuning_description:e=>{const{normalize:n}=e;return n(["Bei der Feinabstimmung, auch Feinabstimmung genannt, werden die Parameter eines vorab trainierten Modells an einem neuen, oft aufgabenspezifischen Datensatz angepasst, um dessen Leistung zu verbessern und es an eine bestimmte Anwendung anzupassen."])},prompt_serving:e=>{const{normalize:n}=e;return n(["Prompte Bedienung"])},prompt_serving_description:e=>{const{normalize:n}=e;return n(["Verpacken und Bereitstellen von Prompts \xFCber eine API, ohne umfangreiche Modelle zu hosten. Die API ruft einen \xF6ffentlichen Modelldienst f\xFCr gro\xDFe Sprachen auf und \xFCbernimmt die Orchestrierung von Ein- und Ausgaben in einer Operationskette."])},prompt_tech:e=>{const{normalize:n}=e;return n(["Prompt- und Agent-Engineering"])},prompt_tech_description:e=>{const{normalize:n}=e;return n([`Bei Jina AI erkennen wir, dass Prompt Engineering f\xFCr die Interaktion mit gro\xDFen Sprachmodellen (LLMs) von entscheidender Bedeutung ist. Mit der Weiterentwicklung dieser Modelle nimmt die Komplexit\xE4t der Eingabeaufforderungen zu und umfasst komplexe \xDCberlegungen und Logik. Dieser Fortschritt unterstreicht das miteinander verflochtene Wachstum von LLMs und die schnelle Weiterentwicklung.

Wir sehen eine Zukunft voraus, in der LLMs als Compiler fungieren und Eingabeaufforderungen zur neuen Programmiersprache werden. Diese Verschiebung deutet darauf hin, dass sich zuk\xFCnftige technologische Kompetenzen mehr auf die schnelle Beherrschung als auf die traditionelle Codierung konzentrieren k\xF6nnten. Unser Ziel bei Jina AI ist es, in diesem transformativen Bereich eine F\xFChrungsrolle zu \xFCbernehmen und durch die Beherrschung dieser aufstrebenden \u201ESprache\u201C fortschrittliche KI f\xFCr den t\xE4glichen Gebrauch zug\xE4nglich und praktisch zu machen.`])},prompt_tuning:e=>{const{normalize:n}=e;return n(["Prompte Abstimmung"])},prompt_tuning_description:e=>{const{normalize:n}=e;return n(["Der Prozess der Erstellung und Verfeinerung der Prompts, um die Ausgabe auf bestimmte, gew\xFCnschte Antworten auszurichten."])}},subscribe_system:{care_most:e=>{const{normalize:n}=e;return n(["Was liegt Ihnen am meisten am Herzen?"])},care_most_options:{accuracy:e=>{const{normalize:n}=e;return n(["Genauigkeit"])},cost:e=>{const{normalize:n}=e;return n(["Kosten"])},other:e=>{const{normalize:n}=e;return n(["Andere"])},scalability:e=>{const{normalize:n}=e;return n(["Skalierbarkeit"])},speed:e=>{const{normalize:n}=e;return n(["Geschwindigkeit"])}},care_most_required:e=>{const{normalize:n}=e;return n(["Was ist Ihnen bei der Auswahl einer Dienstleistung am wichtigsten?"])},company_size:e=>{const{normalize:n}=e;return n(["Wie gro\xDF ist Ihr Unternehmen?"])},company_size_required:e=>{const{normalize:n}=e;return n(["Teilen Sie uns mit, dass die Gr\xF6\xDFe Ihres Unternehmens uns hilft, einen besseren Service zu bieten"])},company_url:e=>{const{normalize:n}=e;return n(["Wie lautet die Website Ihres Unternehmens?"])},company_url_required:e=>{const{normalize:n}=e;return n(["Sagen Sie uns, dass die Website Ihres Unternehmens uns hilft, einen besseren Service zu bieten"])},contactName:e=>{const{normalize:n}=e;return n(["Ihr Name"])},contactName_required:e=>{const{normalize:n}=e;return n(["Wie sollen wir Sie ansprechen?"])},contactTitle:e=>{const{normalize:n}=e;return n(["Wie lautet deine Jobbezeichnung?"])},contactTitle_required:e=>{const{normalize:n}=e;return n(["Ihre Berufsbezeichnung ist erforderlich"])},contact_us:e=>{const{normalize:n}=e;return n(["Kontaktiere uns"])},domain_required:e=>{const{normalize:n}=e;return n(["Teilen Sie uns mit, dass Ihre Arbeitsdom\xE4ne uns hilft, einen besseren Service zu bieten"])},email:e=>{const{normalize:n}=e;return n(["Email"])},email_contact:e=>{const{normalize:n}=e;return n(["Ihre Kontakt-E-Mail"])},email_invalid:e=>{const{normalize:n}=e;return n(["E-Mail ist ung\xFCltig"])},email_required:e=>{const{normalize:n}=e;return n(["E-Mail ist erforderlich"])},fine_tuned_embedding:e=>{const{normalize:n}=e;return n(["Sind Sie an fein abgestimmten Einbettungen interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!"])},fine_tuned_reranker:e=>{const{normalize:n}=e;return n(["Sind Sie an fein abgestimmten Rerankern interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!"])},full_survey:e=>{const{normalize:n}=e;return n(["Nehmen Sie an der vollst\xE4ndigen Umfrage teil und erhalten Sie schnellere Antworten von unserem Team"])},get_new_key:e=>{const{normalize:n}=e;return n(["Holen Sie sich einen neuen API-Schl\xFCssel"])},get_update_blog_posts:e=>{const{normalize:n}=e;return n(["Erhalten Sie die neuesten Updates f\xFCr die Blogbeitr\xE4ge"])},get_update_embeddings:e=>{const{normalize:n}=e;return n(["Erhalten Sie die neuesten Updates f\xFCr die Einbettungen"])},send:e=>{const{normalize:n}=e;return n(["Schicken"])},sign_up:e=>{const{normalize:n}=e;return n(["Melden Sie sich an"])},subscribe:e=>{const{normalize:n}=e;return n(["Abonnieren"])},tell_domain:e=>{const{normalize:n}=e;return n(["Teilen Sie uns Ihre Domain mit"])},usage_type:e=>{const{normalize:n}=e;return n(["Welche Art der Nutzung beschreibt Sie am besten?"])},usage_type_options:{other:e=>{const{normalize:n}=e;return n(["Andere"])},poc:e=>{const{normalize:n}=e;return n(["Konzeptioneller Bewei\xDF"])},production:e=>{const{normalize:n}=e;return n(["Produktion"])},research:e=>{const{normalize:n}=e;return n(["Forschung"])}},usage_type_required:e=>{const{normalize:n}=e;return n(["Teilen Sie uns mit, dass Ihre Nutzungsart uns hilft, einen besseren Service zu bieten"])}},think_gpt:{description:e=>{const{normalize:n}=e;return n(["Agententechniken zur Erweiterung Ihres LLM und zur \xDCberschreitung seiner Grenzen"])}},vectordb:{description:e=>{const{normalize:n}=e;return n(["Eine Python-Vektordatenbank, die Sie brauchen \u2013 nicht mehr und nicht weniger"])}},zzz:e=>{const{normalize:n}=e;return n(["zzz"])}};export{t as default};
