var o={PRODUCT_DESCRIPTION:e=>{const{normalize:a}=e;return a(["Jina AI proporciona la mejor API de integraci\xF3n y un optimizador r\xE1pido de su clase, lo que facilita el desarrollo de aplicaciones de IA multimodal."])},SEO_TAG_LINE:e=>{const{normalize:a}=e;return a(["Liderando en incrustaciones, reclasificaci\xF3n, b\xFAsqueda e IA multimodal"])},about_us_page:{approach:e=>{const{normalize:a}=e;return a(["Nuestro enfoque"])},approach_connect_dots:e=>{const{normalize:a}=e;return a(["Conectando los puntos: usuarios avanzados para empresas"])},approach_connect_dots_description:e=>{const{normalize:a}=e;return a(["Entonces, \xBFpor qu\xE9 es esencial un enfoque en el usuario avanzado para nuestro modelo centrado en la empresa? Porque se trata de establecer relaciones tempranas. Al atender a los usuarios avanzados ahora, estamos construyendo puentes hacia las empresas en las que influir\xE1n en el futuro. Es una jugada estrat\xE9gica: una inversi\xF3n a largo plazo para garantizar que nuestra oferta empresarial siga siendo una prioridad cuando estos usuarios avanzados asciendan a roles de toma de decisiones dentro de las organizaciones."])},approach_content1:e=>{const{normalize:a}=e;return a(["En el mundo de la IA en r\xE1pida evoluci\xF3n, las estrategias deben ser \xE1giles y con visi\xF3n de futuro. Si bien nuestra oferta principal sigue centrada en las empresas, el panorama de la IA ha cambiado de manera que es necesario repensar nuestro enfoque para la adquisici\xF3n de clientes. He aqu\xED por qu\xE9 presentar a los usuarios avanzados como el punto de entrada de nuestro embudo no solo es innovador, sino crucial para nuestro crecimiento sostenido en el sector empresarial."])},approach_content2:e=>{const{normalize:a}=e;return a(["En Jina AI, nuestra estrategia es ser proactivos en lugar de reactivos. La inclusi\xF3n de usuarios avanzados como punto de entrada del embudo garantiza que no solo capturamos las tendencias actuales del mercado, sino que tambi\xE9n estamos estrat\xE9gicamente preparados para el crecimiento empresarial futuro. Nuestro compromiso con las empresas sigue siendo inquebrantable; sin embargo, nuestro enfoque para llegar a ellos es innovador, s\xF3lido y, sobre todo, con visi\xF3n de futuro."])},approach_miss_mark:e=>{const{normalize:a}=e;return a(["Por qu\xE9 los MLOps tradicionales no dan en el blanco"])},approach_miss_mark_description:e=>{const{normalize:a}=e;return a(["Si bien la afluencia de usuarios avanzados es significativa, las herramientas tradicionales de MLOps est\xE1n mal equipadas para satisfacer sus necesidades. Estas herramientas recuerdan el uso de un tractor para moverse por las calles de la ciudad: son pesadas y, a menudo, excesivas. Los desarrolladores de nueva generaci\xF3n exigen herramientas \xE1giles e intuitivas que complementen su r\xE1pido ritmo de desarrollo."])},approach_new_paradigm:e=>{const{normalize:a}=e;return a(["Tecnolog\xEDa basada en avisos: un nuevo paradigma"])},approach_new_paradigm_description:e=>{const{normalize:a}=e;return a([`2023 anunci\xF3 un cambio significativo: el surgimiento de la tecnolog\xEDa basada en avisos. Al simplificar el proceso de desarrollo de IA, ha democratizado el acceso a las herramientas de IA. Ahora, aquellos que no tienen una amplia experiencia en programaci\xF3n, denominados "usuarios avanzados", pueden participar en el desarrollo de IA sin las pronunciadas curvas de aprendizaje asociadas con herramientas como Pytorch, Docker o Kubernetes.

Trazando un paralelo, esto es similar a la evoluci\xF3n de la computaci\xF3n personal. Inicialmente, solo los expertos en tecnolog\xEDa operaban computadoras. Pero con la llegada de las interfaces f\xE1ciles de usar, podr\xEDa participar una audiencia m\xE1s amplia. Hoy, con la tecnolog\xEDa basada en avisos, estamos presenciando una democratizaci\xF3n similar en la IA.`])},awards:e=>{const{normalize:a}=e;return a(["Premios y reconocimientos"])},berlin:e=>{const{normalize:a}=e;return a(["Berl\xEDn, Alemania"])},berlin_address:e=>{const{normalize:a}=e;return a(["calle Ohlauer 43 (primer piso), zona A, 10999 Berl\xEDn"])},berlin_address2:e=>{const{normalize:a}=e;return a(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berl\xEDn, Alemania"])},bj:e=>{const{normalize:a}=e;return a(["Beijing, China"])},bj_address:e=>{const{normalize:a}=e;return a(["Nivel 5, Edificio 6, No.48 Haidian West St. Beijing Haidian, China"])},brochure_info:e=>{const{normalize:a}=e;return a(["Su gu\xEDa de nuestra empresa le espera"])},description:e=>{const{normalize:a}=e;return a(["El futuro comienza aqu\xED."])},download_brochure1:e=>{const{normalize:a}=e;return a(["Descargar folleto"])},download_docarray_logo:e=>{const{normalize:a}=e;return a(["Descargue el logotipo de DocArray"])},download_docarray_logo_desc:e=>{const{normalize:a}=e;return a(["Acceda al logotipo de DocArray, un proyecto de c\xF3digo abierto iniciado por Jina AI y contribuido a la Fundaci\xF3n Linux en diciembre de 2022. Disponible en modos claro y oscuro, en formatos PNG y SVG."])},download_jina_logo:e=>{const{normalize:a}=e;return a(["Descargue el logotipo de Jina AI"])},download_jina_logo_desc:e=>{const{normalize:a}=e;return a(["Obtenga el logotipo de Jina AI en modo claro y oscuro, disponible en formatos PNG y SVG. Este logotipo es una marca registrada en la Oficina de Propiedad Intelectual de la Uni\xF3n Europea (EUIPO)."])},download_logo:e=>{const{normalize:a}=e;return a(["Descargar logotipos"])},employees:e=>{const{normalize:a}=e;return a(["Empleados"])},empower_developers:e=>{const{normalize:a}=e;return a(["Desarrolladores empoderados"])},fastApiCaption:e=>{const{normalize:a}=e;return a(["Contribuy\xF3 con m\xE1s de $ 20,000 desde 2021."])},founded:e=>{const{normalize:a}=e;return a(["Fundado"])},founded_in:e=>{const{normalize:a}=e;return a(["Fundado en"])},investors:e=>{const{normalize:a}=e;return a(["Nuestros inversores"])},linuxFoundationCaption:e=>{const{normalize:a}=e;return a(["Realiza un aporte anual de $10,000 a partir de 2022."])},mission:e=>{const{normalize:a}=e;return a(["Nuestra misi\xF3n"])},mission_content1:e=>{const{normalize:a}=e;return a(["En el coraz\xF3n de Jina AI se encuentra nuestra misi\xF3n de ser el portal de la IA multimodal para una clientela diversa, desde usuarios avanzados y desarrolladores hasta empresas. Creemos profundamente en el poder del c\xF3digo abierto y nos dedicamos a crear herramientas avanzadas y accesibles para la comunidad de IA. Nuestras tecnolog\xEDas clave, que incluyen el ajuste r\xE1pido, el servicio r\xE1pido, el ajuste de modelos y el servicio de modelos, encarnan nuestro compromiso de democratizar el acceso a la IA. A trav\xE9s de nuestra iniciativa de c\xF3digo abierto, nos esforzamos por fomentar la innovaci\xF3n, la colaboraci\xF3n y la transparencia, garantizando soluciones escalables, eficientes y s\xF3lidas. Jina AI es m\xE1s que una empresa; es una comunidad dedicada a empoderar a las empresas para enfrentar los desaf\xEDos din\xE1micos de la era digital y prosperar en sus dominios."])},mission_content2:e=>{const{normalize:a}=e;return a(["En el coraz\xF3n de Jina AI se encuentra nuestra misi\xF3n de ser el portal hacia la IA multimodal para una clientela diversa, desde usuarios avanzados y desarrolladores hasta empresas. Creemos profundamente en el poder del c\xF3digo abierto y estamos dedicados a crear herramientas avanzadas y accesibles para la comunidad de IA. Nuestras tecnolog\xEDas clave, que incluyen el ajuste r\xE1pido, el servicio r\xE1pido, el ajuste integrado y el servicio integrado, encarnan nuestro compromiso de democratizar el acceso a la IA. A trav\xE9s de nuestra iniciativa de c\xF3digo abierto, nos esforzamos por fomentar la innovaci\xF3n, la colaboraci\xF3n y la transparencia, garantizando soluciones escalables, eficientes y s\xF3lidas. Jina AI es m\xE1s que una simple empresa; es una comunidad dedicada a capacitar a las empresas para que enfrenten los desaf\xEDos din\xE1micos de la era digital y prosperen en sus dominios."])},mission_content3:e=>{const{normalize:a}=e;return a(["En Jina AI, nuestra misi\xF3n es liderar el avance de la IA multimodal a trav\xE9s de tecnolog\xEDas innovadoras de integraci\xF3n y basadas en avisos, centr\xE1ndonos espec\xEDficamente en \xE1reas como el procesamiento del lenguaje natural, el an\xE1lisis de im\xE1genes y videos y la interacci\xF3n de datos intermodales. Esta especializaci\xF3n nos permite ofrecer soluciones \xFAnicas que convierten datos complejos de m\xFAltiples fuentes en conocimientos pr\xE1cticos y aplicaciones innovadoras."])},numfocusCaption:e=>{const{normalize:a}=e;return a(["Dona regularmente cada mes a partir de 2022."])},office:e=>{const{normalize:a}=e;return a(["Nuestras oficinas"])},otherProjectsCaption:e=>{const{normalize:a}=e;return a(["Don\xF3 m\xE1s de $ 3,000 a trav\xE9s del patrocinio de Github."])},our_answer:e=>{const{normalize:a}=e;return a(["Absolutamente Yann. \xA1Estamos en ello, construyendo puentes hacia un futuro de IA multimodal!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:a}=e;return a(["Proporcion\xF3 una donaci\xF3n \xFAnica de $ 10,000 y patrocin\xF3 m\xFAltiples eventos de PyCon, incluidos los de Alemania, Italia, China y los EE. UU."])},segmentFaultCaption:e=>{const{normalize:a}=e;return a(["Contribuy\xF3 con una donaci\xF3n \xFAnica de $ 6,000."])},stats:e=>{const{normalize:a}=e;return a(["Pioneros en el futuro de la IA multimodal"])},stats_1:e=>{const{normalize:a}=e;return a(["Fundada en febrero de 2020, Jina AI se ha convertido r\xE1pidamente en pionera mundial en tecnolog\xEDa de IA multimodal. En un per\xEDodo impresionante de 20 meses, recaudamos con \xE9xito $37,5 millones, lo que marca nuestra s\xF3lida posici\xF3n en la industria de la IA. Nuestra tecnolog\xEDa innovadora, de c\xF3digo abierto en GitHub, ha permitido a m\xE1s de 40\xA0000 desarrolladores de todo el mundo crear e implementar aplicaciones multimodales sofisticadas sin problemas."])},stats_2:e=>{const{normalize:a}=e;return a(["En 2023, hemos logrado avances significativos en el avance de las herramientas de generaci\xF3n de IA basadas en tecnolog\xEDa multimodal. Esta innovaci\xF3n ha beneficiado a m\xE1s de 250 000 usuarios en todo el mundo, atendiendo a una pl\xE9tora de requisitos comerciales \xFAnicos. Desde facilitar el crecimiento empresarial y mejorar la eficiencia operativa hasta optimizar los costos, Jina AI se dedica a empoderar a las empresas para que sobresalgan en la era multimodal."])},stats_3:e=>{const{normalize:a}=e;return a([`Fundada en 2020 y con sede en Berl\xEDn, Alemania, Jina AI se ha convertido r\xE1pidamente en l\xEDder en IA multimodal, centr\xE1ndose en t\xE9cnicas r\xE1pidas e integradas. Como empresa con sede en la UE, nuestra visi\xF3n y servicios se extienden por todo el mundo, proporcionando a empresas y desarrolladores plataformas innovadoras para aprovechar el poder de la IA para la creaci\xF3n de valor y el ahorro de costos.

Nuestro compromiso con el c\xF3digo abierto y la investigaci\xF3n abierta ha dado forma a nuestra identidad como empresa comercial de software de c\xF3digo abierto. Esta dedicaci\xF3n a la innovaci\xF3n se ve subrayada por nuestro crecimiento financiero, marcado por un aumento de 38 millones de d\xF3lares en nuestra ronda Serie A en noviembre de 2021. En Jina AI, estamos cerrando la brecha entre la IA avanzada y las aplicaciones pr\xE1cticas a escala global.`])},subtitle:e=>{const{normalize:a}=e;return a(["Revolucionando la creaci\xF3n de contenido a trav\xE9s de soluciones generadas por IA para desbloquear infinitas posibilidades. Dando forma al futuro del contenido generado por IA y mejorando la creatividad humana."])},sz:e=>{const{normalize:a}=e;return a(["Shenzhen, China"])},sz_address:e=>{const{normalize:a}=e;return a(["402, Piso 4, Edificio de Tecnolog\xEDa Fu'an, Shenzhen Nanshan, China"])},team:e=>{const{normalize:a}=e;return a(["Dentro del Portal de Jina AI"])},team_content:e=>{const{normalize:a}=e;return a(["Desde diversos rincones del mundo, estamos co-creando el futuro de la IA multimodal. Nuestros distintos estilos de vida y perspectivas enriquecen nuestro trabajo, estimulando la creatividad y el progreso. Dentro de este portal, abrazamos nuestra individualidad, apreciamos nuestra libertad y perseguimos apasionadamente nuestros sue\xF1os. Bienvenido al portal del futuro de la IA."])},team_join:e=>{const{normalize:a}=e;return a(["\xDAnete a nosotros"])},technologies:e=>{const{normalize:a}=e;return a(["Tecnolog\xEDas"])},title:e=>{const{normalize:a}=e;return a(["Acerca de Jina AI"])},title0:e=>{const{normalize:a}=e;return a(["El futuro"])},title1:e=>{const{normalize:a}=e;return a(["Empieza"])},title2:e=>{const{normalize:a}=e;return a(["Aqu\xED"])},title3:e=>{const{normalize:a}=e;return a(["Comienza aqu\xED"])},understand_our_strength:e=>{const{normalize:a}=e;return a(["Comprender nuestra fuerza"])},understand_our_view:e=>{const{normalize:a}=e;return a(["Entender nuestra visi\xF3n"])},users:e=>{const{normalize:a}=e;return a(["Usuarios Registrados"])},value:e=>{const{normalize:a}=e;return a(["Nuestro valor"])},value_content:e=>{const{normalize:a}=e;return a([`En Jina AI, creemos en el poder de la tecnolog\xEDa de c\xF3digo abierto para acelerar la innovaci\xF3n, fomentar la colaboraci\xF3n y empoderar a las comunidades. No somos solo defensores: somos colaboradores activos que invertimos significativamente en la comunidad de c\xF3digo abierto.

Desde ser la fuerza impulsora detr\xE1s de FastAPI hasta nuestro soporte continuo para Linux y Python Foundations, nos apasiona retribuir. Pero no nos detenemos ah\xED; tambi\xE9n hemos abierto nuestra infraestructura central, compartiendo nuestra experiencia en IA multimodal con el mundo.

En Jina AI, nos esforzamos por liderar con el ejemplo, utilizando nuestros recursos para nutrir a la comunidad que nos nutre. Es nuestra forma de decir gracias y garantizar un futuro vibrante para las tecnolog\xEDas de las que todos dependemos. Despu\xE9s de todo, estamos todos juntos en esto.`])},vision:e=>{const{normalize:a}=e;return a(["Nuestra visi\xF3n"])},vision_content1:e=>{const{normalize:a}=e;return a(["Inspirado por la idea de Yann LeCun de que '"])},vision_content2:e=>{const{normalize:a}=e;return a(["Jina AI prev\xE9 allanar el camino hacia el futuro de la IA como una realidad multimodal. Reconocemos que los ecosistemas de software y aprendizaje autom\xE1tico existentes enfrentan desaf\xEDos en el manejo de la IA multimodal. Como respuesta, nos comprometemos a desarrollar herramientas y plataformas pioneras que ayuden a las empresas y los desarrolladores a navegar por estas complejidades. Nuestra visi\xF3n es desempe\xF1ar un papel crucial para ayudar al mundo a aprovechar el vasto potencial de la IA multimodal y revolucionar verdaderamente la forma en que interpretamos e interactuamos con la informaci\xF3n."])},yannlecun_quote:e=>{const{normalize:a}=e;return a(["Un sistema de inteligencia artificial entrenado solo con palabras y oraciones nunca se aproximar\xE1 a la comprensi\xF3n humana."])}},api_general_faq:{answer1:e=>{const{normalize:a}=e;return a(["S\xED, se puede utilizar la misma clave API para las API de incrustaci\xF3n y reclasificaci\xF3n, con tokens compartidos entre los dos servicios."])},answer12:e=>{const{normalize:a}=e;return a(["Nos adherimos a una estricta pol\xEDtica de privacidad y no utilizamos datos ingresados \u200B\u200Bpor el usuario para entrenar nuestros modelos."])},answer3:e=>{const{normalize:a}=e;return a(['S\xED, el uso de tokens se puede monitorear en la pesta\xF1a "Comprar tokens" ingresando su clave API, lo que le permite ver el historial de uso y los tokens restantes.'])},answer4:e=>{const{normalize:a}=e;return a(["Si extravi\xF3 una clave de recarga y desea recuperarla, comun\xEDquese con el soporte t\xE9cnico de jina.ai con su correo electr\xF3nico registrado para obtener ayuda."])},answer5:e=>{const{normalize:a}=e;return a(["No, nuestras claves API no tienen fecha de vencimiento. Sin embargo, si sospecha que su clave se ha visto comprometida y desea retirarla o transferir sus tokens a una nueva clave, comun\xEDquese con nuestro equipo de soporte para obtener ayuda."])},answer6:e=>{const{normalize:a}=e;return a(['Esto se debe a que nuestra arquitectura sin servidor descarga ciertos modelos durante per\xEDodos de bajo uso. La solicitud inicial activa o "calienta" el modelo, lo que puede tardar unos segundos. Despu\xE9s de esta activaci\xF3n inicial, las solicitudes posteriores se procesan mucho m\xE1s r\xE1pidamente.'])},question1:e=>{const{normalize:a}=e;return a(["\xBFPuedo usar la misma clave API para las API de inserci\xF3n y reclasificaci\xF3n?"])},question12:e=>{const{normalize:a}=e;return a(["\xBFSe utilizan los datos de entrada del usuario para entrenar sus modelos?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFPuedo monitorear el uso del token de mi clave API?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 debo hacer si olvido mi clave API?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFCaducan las claves API?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFPor qu\xE9 la primera solicitud de algunos modelos es lenta?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con API"])}},best_banner:{description:e=>{const{normalize:a}=e;return a(["\xA1Blog a banner, sin las indicaciones!"])},example_description:e=>{const{normalize:a}=e;return a(['Alicia empezaba a cansarse mucho de estar sentada junto a su hermana en la orilla y de no tener nada que hacer: una o dos veces hab\xEDa echado un vistazo al libro que su hermana estaba leyendo, pero no ten\xEDa dibujos ni conversaciones, "y de qu\xE9 sirve un libro", pens\xF3 Alicia, "sin dibujos ni conversaciones". As\xED que estaba considerando en su propia mente (lo mejor que pod\xEDa, porque el d\xEDa caluroso la hac\xEDa sentir muy so\xF1olienta y est\xFApida), si el placer de hacer una cadena de margaritas valdr\xEDa la pena de levantarse y recoger las margaritas, cuando de repente un Conejo Blanco con ojos rosados \u200B\u200Bcorri\xF3 cerca de ella.'])},example_title:e=>{const{normalize:a}=e;return a(["Las aventuras de Alicia en el pa\xEDs de las maravillas - Cap\xEDtulo 1"])}},beta:e=>{const{normalize:a}=e;return a(["Beta"])},billing_general_faq:{answer10:e=>{const{normalize:a}=e;return a(['Ofrecemos una prueba gratuita de bienvenida a nuevos usuarios, que incluye un mill\xF3n de tokens para usar con cualquiera de nuestros modelos, facilitada por una clave API generada autom\xE1ticamente. Una vez que se alcanza el l\xEDmite de tokens gratuitos, los usuarios pueden comprar f\xE1cilmente tokens adicionales para sus claves API a trav\xE9s de la pesta\xF1a "Comprar tokens".'])},answer13:e=>{const{normalize:a}=e;return a(["No, los tokens no se deducen por solicitudes fallidas."])},answer14:e=>{const{normalize:a}=e;return a(["Los pagos se procesan a trav\xE9s de Stripe y admiten una variedad de m\xE9todos de pago que incluyen tarjetas de cr\xE9dito, Google Pay y PayPal para su comodidad."])},answer15:e=>{const{normalize:a}=e;return a(["S\xED, se emitir\xE1 una factura a la direcci\xF3n de correo electr\xF3nico asociada a su cuenta de Stripe tras la compra de tokens."])},answer9:e=>{const{normalize:a}=e;return a(["Nuestro modelo de precios se basa en la cantidad total de tokens procesados, lo que permite a los usuarios la flexibilidad de asignar estos tokens en cualquier cantidad de oraciones, ofreciendo una soluci\xF3n rentable para diversos requisitos de an\xE1lisis de texto."])},question10:e=>{const{normalize:a}=e;return a(["\xBFHay una prueba gratuita disponible para nuevos usuarios?"])},question13:e=>{const{normalize:a}=e;return a(["\xBFSe cobran tokens por solicitudes fallidas?"])},question14:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 m\xE9todos de pago se aceptan?"])},question15:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 disponible la facturaci\xF3n para compras de tokens?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFLa facturaci\xF3n se basa en el n\xFAmero de sentencias o solicitudes?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con la facturaci\xF3n"])}},blog_tags:{all:e=>{const{normalize:a}=e;return a(["Todo"])},events:e=>{const{normalize:a}=e;return a(["Eventos"])},featured:e=>{const{normalize:a}=e;return a(["Presentado"])},insights:e=>{const{normalize:a}=e;return a(["Perspectivas"])},"knowledge-base":e=>{const{normalize:a}=e;return a(["Base de conocimientos"])},press:e=>{const{normalize:a}=e;return a(["presione soltar"])},releases:e=>{const{normalize:a}=e;return a(["Actualizaciones de software"])},"tech-blog":e=>{const{normalize:a}=e;return a(["Blog de tecnolog\xEDa"])}},clip_as_service:{description:e=>{const{normalize:a}=e;return a(["Incruste im\xE1genes y oraciones en vectores de longitud fija con CLIP"])}},cloud:{description:e=>{const{normalize:a}=e;return a(["Plataforma de alojamiento en la nube para aplicaciones de IA multimodal"])}},contact_us_page:{agreement:e=>{const{normalize:a}=e;return a(["Al enviar, confirma que est\xE1 de acuerdo con el procesamiento de sus datos personales por parte de Jina AI como se describe en el"])},anything_else:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos m\xE1s sobre tu proyecto"])},company:e=>{const{normalize:a}=e;return a(["Compa\xF1\xEDa"])},company_size:e=>{const{normalize:a}=e;return a(["Tama\xF1o de la empresa"])},company_website:e=>{const{normalize:a}=e;return a(["P\xE1gina Web de la compa\xF1\xEDa"])},company_website_placeholder:e=>{const{normalize:a}=e;return a(["URL de la p\xE1gina de inicio de su empresa o del perfil de LinkedIn"])},country:e=>{const{normalize:a}=e;return a(["Pa\xEDs"])},department:e=>{const{normalize:a}=e;return a(["Departamento"])},description:e=>{const{normalize:a}=e;return a(["Haga crecer su negocio con Jina AI."])},faq:e=>{const{normalize:a}=e;return a(["Preguntas m\xE1s frecuentes"])},field_required:e=>{const{normalize:a}=e;return a(["Se requiere campo"])},impact_snapshots:e=>{const{normalize:a}=e;return a(["Instant\xE1neas de impacto"])},invalid_date_format:e=>{const{normalize:a}=e;return a(["Formato de fecha no v\xE1lido. Utilice el formato DD-MM-AAAA."])},invalid_email:e=>{const{normalize:a}=e;return a(["el correo electr\xF3nico es invalido"])},invalid_number:e=>{const{normalize:a}=e;return a(["N\xFAmero invalido. Por favor ingrese de nuevo"])},invalid_url:e=>{const{normalize:a}=e;return a(["La URL no es v\xE1lida."])},name:e=>{const{normalize:a}=e;return a(["Nombre"])},preferred_products:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 productos est\xE1s interesado?"])},private_statement:e=>{const{normalize:a}=e;return a(["Declaracion de privacidad"])},role:e=>{const{normalize:a}=e;return a(["Puesto de trabajo"])},submit:e=>{const{normalize:a}=e;return a(["Entregar"])},submit_failed:e=>{const{normalize:a}=e;return a(["Env\xEDo fallido. Por favor, int\xE9ntelo de nuevo m\xE1s tarde."])},submit_success:e=>{const{normalize:a}=e;return a(["Gracias por tu env\xEDo. Nos pondremos en contacto con usted en breve."])},subtitle:e=>{const{normalize:a}=e;return a(["Jina AI, l\xEDder en IA multimodal, se destaca en el ajuste de modelos, el servicio de modelos, el ajuste de avisos y el servicio de avisos. Al aprovechar las tecnolog\xEDas nativas de la nube como Kubernetes y las arquitecturas sin servidor, ofrecemos soluciones s\xF3lidas, escalables y listas para producci\xF3n. Con experiencia en modelos de lenguaje grande, texto, imagen, video, comprensi\xF3n de audio, b\xFAsqueda neuronal y arte generativo, brindamos estrategias innovadoras y preparadas para el futuro para elevar su negocio."])},subtitle1:e=>{const{normalize:a}=e;return a(["Jina AI, l\xEDder en IA multimodal, se destaca en el ajuste de integraci\xF3n, el servicio de integraci\xF3n, el ajuste r\xE1pido y el servicio r\xE1pido. Aprovechando tecnolog\xEDas nativas de la nube como Kubernetes y arquitecturas sin servidor, ofrecemos soluciones s\xF3lidas, escalables y listas para producci\xF3n. Con experiencia en modelos de lenguaje grandes, texto, im\xE1genes, video, comprensi\xF3n de audio, b\xFAsqueda neuronal e inteligencia artificial generativa, brindamos estrategias innovadoras y preparadas para el futuro para elevar su negocio."])},subtitle2:e=>{const{normalize:a}=e;return a(["Explore Jina AI, la vanguardia de la IA multimodal. Nos destacamos en la integraci\xF3n y rapidez de tecnolog\xEDas, utilizando soluciones nativas de la nube como Kubernetes para sistemas robustos y escalables. Especializados en grandes modelos de lenguaje y procesamiento de medios, ofrecemos estrategias comerciales innovadoras y preparadas para el futuro con nuestra experiencia avanzada en IA."])},title:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},trusted_by:e=>{const{normalize:a}=e;return a(["Confiado por"])},work_email:e=>{const{normalize:a}=e;return a(["Correo electr\xF3nico del trabajo"])}},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},copy_to_clipboard_success:e=>{const{normalize:a}=e;return a(["Copiado al portapapeles"])},dalle_flow:{description:e=>{const{normalize:a}=e;return a(["Un flujo de trabajo human-in-the-Loop para crear im\xE1genes HD a partir de texto"])}},"dev-gpt":{description:e=>{const{normalize:a}=e;return a(["Tu equipo de desarrollo virtual"])}},disco_art:{description:e=>{const{normalize:a}=e;return a(["Cree atractivas obras de arte de Disco Diffusion en una l\xEDnea de c\xF3digo"])}},doc_array:{description:e=>{const{normalize:a}=e;return a(["La estructura de datos para datos multimodales"])}},embedding:{"11B tokens":e=>{const{normalize:a}=e;return a(["11 mil millones de fichas"])},"11B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Un poco m\xE1s que toda la Wikipedia en ingl\xE9s."])},"1B tokens":e=>{const{normalize:a}=e;return a(["1 bill\xF3n de fichas"])},"1B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Aproximadamente 10.000 novelas promedio, o releer todas las novelas de Harry Potter 1.000 veces."])},"1M_free":e=>{const{normalize:a}=e;return a(["1 mill\xF3n de fichas gratis"])},"1M_free_description":e=>{const{normalize:a}=e;return a(["Reciba 1 mill\xF3n de tokens gratis con cada nueva clave API, sin necesidad de tarjeta de cr\xE9dito. Adecuado tanto para proyectos personales como comerciales."])},"2_5B tokens":e=>{const{normalize:a}=e;return a(["2.500 millones de fichas"])},"2_5B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Todas las palabras pronunciadas en un d\xEDa por 150.000 personas, o 100 veces el tama\xF1o del C\xF3digo de Regulaciones Federales de EE. UU."])},"500M tokens":e=>{const{normalize:a}=e;return a(["500 millones de fichas"])},"500M tokens_intuition1":e=>{const{normalize:a}=e;return a(["10 a\xF1os del NY Times todos los d\xEDas, o leer En busca del tiempo perdido 300 veces."])},"59B tokens":e=>{const{normalize:a}=e;return a(["59 mil millones de fichas"])},"59B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Todos los tweets del mundo durante dos d\xEDas."])},"5_5B tokens":e=>{const{normalize:a}=e;return a(["5.500 millones de fichas"])},"5_5B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Todas las palabras jam\xE1s publicadas en el NY Times."])},add_pair:e=>{const{normalize:a}=e;return a(["Nuevo"])},api_integration_short:e=>{const{normalize:a}=e;return a(["Nuestra API de incrustaci\xF3n est\xE1 integrada de forma nativa con varias bases de datos, almacenes de vectores, marcos RAG y LLMOps de renombre."])},api_integrations:e=>{const{normalize:a}=e;return a(["Integraciones API"])},autostart:e=>{const{normalize:a}=e;return a(["La inserci\xF3n comenzar\xE1 autom\xE1ticamente despu\xE9s de un breve retraso."])},batch_job:e=>{const{normalize:a}=e;return a(["Trabajo por lotes"])},batch_upload_hint:e=>{const{normalize:a}=e;return a(["Usaremos la clave API y el modelo siguiente para procesar los documentos."])},bulk:e=>{const{normalize:a}=e;return a(["Incrustaci\xF3n por lotes"])},bulk_embedding_failed:e=>{const{normalize:a}=e;return a(["No se pudo crear el trabajo de incrustaci\xF3n por lotes"])},buy_more_quota:e=>{const{normalize:a}=e;return a(["Recarga esta clave API seleccionando los tokens que necesitas"])},buy_poster:e=>{const{normalize:a}=e;return a(["Compre una copia impresa"])},cancel_button:e=>{const{normalize:a}=e;return a(["Cancelar"])},click_upload_btn_above:e=>{const{normalize:a}=e;return a(["Haga clic en el bot\xF3n de carga de arriba para comenzar."])},code:e=>{const{normalize:a}=e;return a(["c\xF3digo"])},cosine_similarity:e=>{const{normalize:a}=e;return a(["Similitud del coseno"])},debugging:e=>{const{normalize:a}=e;return a(["Prueba"])},delete_pair:e=>{const{normalize:a}=e;return a(["Borrar"])},description:e=>{const{normalize:a,linked:n,type:r}=e;return a([n("landing_page.embedding_desc1",void 0,r)])},document:e=>{const{normalize:a}=e;return a(["Documento"])},download:e=>{const{normalize:a}=e;return a(["Descargar"])},edit_text1_text:e=>{const{normalize:a}=e;return a(["Editar texto de la izquierda"])},edit_text2_text:e=>{const{normalize:a}=e;return a(["Editar texto correcto"])},embedding_done:e=>{const{normalize:a,interpolate:n,named:r}=e;return a([n(r("_Count"))," documentos insertados correctamente."])},embedding_none_description:e=>{const{normalize:a}=e;return a(["No utilice ning\xFAn modelo de incrustaci\xF3n."])},faq:e=>{const{normalize:a,linked:n,type:r}=e;return a([n("contact_us_page.faq",void 0,r)])},faqs_v2:{answer0:e=>{const{normalize:a}=e;return a(["Para obtener informaci\xF3n detallada sobre nuestros procesos de capacitaci\xF3n, fuentes de datos y evaluaciones, consulte nuestro informe t\xE9cnico disponible en arXiv."])},answer1:e=>{const{normalize:a}=e;return a(["Cada usuario puede realizar hasta 100 solicitudes por segundo, lo que equivale a 204.800 frases de entrada por segundo."])},answer17:e=>{const{normalize:a}=e;return a(["Actualmente estamos desarrollando incrustaciones multimodales que procesar\xE1n conjuntamente texto, im\xE1genes y audio. \xA1Las actualizaciones se anunciar\xE1n pronto!"])},answer18:e=>{const{normalize:a}=e;return a(["Si tiene consultas sobre c\xF3mo ajustar nuestros modelos con datos espec\xEDficos, cont\xE1ctenos para analizar sus requisitos. Estamos abiertos a explorar c\xF3mo nuestros modelos se pueden adaptar para satisfacer sus necesidades."])},answer19:e=>{const{normalize:a}=e;return a(["S\xED, nuestros servicios est\xE1n disponibles en el mercado de AWS y estamos en el proceso de expandirnos a los mercados de Azure y GCP. Si tiene requisitos particulares, cont\xE1ctenos en ventas AT jina.ai."])},answer2:e=>{const{normalize:a}=e;return a(["S\xED, todos nuestros modelos son de c\xF3digo abierto y accesibles en Hugging Face."])},answer3:e=>{const{normalize:a}=e;return a(["Nuestros modelos admiten ingl\xE9s, alem\xE1n, espa\xF1ol, chino y varios lenguajes de programaci\xF3n. Para obtener m\xE1s detalles, consulte nuestra publicaci\xF3n sobre modelos biling\xFCes."])},answer4:e=>{const{normalize:a}=e;return a(['Nuestros modelos permiten una longitud de entrada de hasta 8192 tokens, que es significativamente mayor que la mayor\xEDa de los otros modelos. Un token puede variar desde un solo car\xE1cter, como "a", hasta una palabra completa, como "manzana". La cantidad total de caracteres que se pueden ingresar depende de la longitud y complejidad de las palabras utilizadas. Esta capacidad de entrada extendida permite que nuestros modelos jina-embeddings-v2 realicen an\xE1lisis de texto m\xE1s completos y logren una mayor precisi\xF3n en la comprensi\xF3n del contexto, especialmente para datos textuales extensos.'])},answer5:e=>{const{normalize:a}=e;return a(["Una sola llamada API puede procesar hasta 2048 oraciones o textos, lo que facilita un an\xE1lisis de texto extenso en una sola solicitud."])},answer7:e=>{const{normalize:a}=e;return a(["Seg\xFAn la tabla de clasificaci\xF3n MTEB, nuestro modelo Base compite estrechamente con el text-embedding-ada-002 de OpenAI, mostrando un rendimiento comparable en promedio. Adem\xE1s, nuestro modelo Base sobresale en varias tareas, incluida la clasificaci\xF3n, clasificaci\xF3n por pares, reclasificaci\xF3n y resumen, superando al modelo de OpenAI."])},answer8:e=>{const{normalize:a}=e;return a(["La transici\xF3n se simplifica, ya que nuestro punto final API, https://api.jina.ai/v1/embeddings, coincide con los esquemas JSON de entrada y salida del modelo text-embeddings-ada-002 de OpenAI. Esta compatibilidad garantiza que los usuarios puedan reemplazar f\xE1cilmente el modelo OpenAI por el nuestro cuando utilizan el punto final de OpenAI."])},question0:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se entrenaron los modelos jina-embeddings-v2?"])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1ntas solicitudes de API puedo realizar por segundo?"])},question17:e=>{const{normalize:a}=e;return a(["\xBFProporcionan modelos para incrustar im\xE1genes o audio?"])},question18:e=>{const{normalize:a}=e;return a(["\xBFSe pueden ajustar los modelos de Jina Embedding con datos privados o de la empresa?"])},question19:e=>{const{normalize:a}=e;return a(["\xBFSe pueden alojar sus puntos finales de forma privada en AWS, Azure o GCP?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFLos modelos detr\xE1s de la API son de c\xF3digo abierto?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 idiomas admiten sus modelos?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la longitud m\xE1xima para la entrada de una sola oraci\xF3n?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el n\xFAmero m\xE1ximo de frases que puedo incluir en una sola solicitud?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se comparan los modelos de Jina Embeddings con el modelo text-embedding-ada-002 de OpenAI?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 tan fluida es la transici\xF3n desde text-embedding-ada-002 de OpenAI a su soluci\xF3n?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con incrustaciones"])}},feature_8k1:e=>{const{normalize:a}=e;return a(["8192 longitud del token"])},feature_8k_description1:e=>{const{normalize:a}=e;return a(["Ser pionero en el primer modelo de integraci\xF3n de c\xF3digo abierto con una longitud de 8192 tokens, que permite la representaci\xF3n de un cap\xEDtulo completo en un solo vector."])},feature_cheap:e=>{const{normalize:a}=e;return a(["20 veces m\xE1s barato"])},feature_cheap_v1:e=>{const{normalize:a}=e;return a(["5 veces m\xE1s barato"])},feature_cheap_v1_description1:e=>{const{normalize:a}=e;return a(["Comience con pruebas gratuitas y disfrute de una estructura de precios sencilla. Obtenga acceso a potentes incorporaciones por solo el 20 % del coste de OpenAI."])},feature_multilingual:e=>{const{normalize:a}=e;return a(["Ofreciendo modelos biling\xFCes para alem\xE1n-ingl\xE9s, chino-ingl\xE9s, entre otros, ideales para aplicaciones multiling\xFCes."])},feature_on_premises:e=>{const{normalize:a}=e;return a(["Privacidad primero"])},feature_on_premises_description1:e=>{const{normalize:a}=e;return a(["Implemente sin problemas nuestros modelos integrados directamente dentro de su nube privada virtual (VPC). Actualmente es compatible con AWS Sagemaker, con pr\xF3ximas integraciones para Microsoft Azure y Google Cloud Platform. Para implementaciones personalizadas de Kubernetes, comun\xEDquese con nuestro equipo de ventas para obtener asistencia especializada."])},feature_on_premises_description2:e=>{const{normalize:a}=e;return a(["Implemente modelos de Jina Embeddings en AWS Sagemaker y pronto en Microsoft Azure y Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description3:e=>{const{normalize:a}=e;return a(["Implemente modelos de Jina Embeddings en AWS Sagemaker y Microsoft Azure, y pronto en Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_solid:e=>{const{normalize:a}=e;return a(["Mejor en clase"])},feature_solid_description1:e=>{const{normalize:a}=e;return a(["Desarrollado a partir de nuestra investigaci\xF3n acad\xE9mica de vanguardia y probado rigurosamente con los modelos SOTA para garantizar un rendimiento incomparable."])},feature_top_perform1:e=>{const{normalize:a}=e;return a(["Integraci\xF3n perfecta"])},feature_top_perform_description1:e=>{const{normalize:a}=e;return a(["Totalmente compatible con la API de OpenAI. Se integra sin esfuerzo con m\xE1s de 10 bases de datos vectoriales y sistemas RAG para una experiencia de usuario fluida."])},file_required:e=>{const{normalize:a}=e;return a(["Se requiere archivo"])},file_size_exceed:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Superar el tama\xF1o m\xE1ximo de archivo ",n(r("_size"))])},file_type_not_supported:e=>{const{normalize:a}=e;return a(["Tipo de archivo no compatible"])},fill_example:e=>{const{normalize:a}=e;return a(["Completa el ejemplo"])},generate_api_key_error:e=>{const{normalize:a}=e;return a(["Error al generar la clave API."])},generating_visualization:e=>{const{normalize:a}=e;return a(["Generando visualizaci\xF3n..."])},get_new_key_button:e=>{const{normalize:a}=e;return a(["Obtener nueva clave"])},get_new_key_button_explain:e=>{const{normalize:a}=e;return a(["Optar por una nueva clave resultar\xE1 en la p\xE9rdida del historial de uso asociado con la clave anterior."])},get_new_key_survey:e=>{const{normalize:a}=e;return a(["Complete la encuesta, ay\xFAdenos a comprender su uso y obtenga una nueva clave API gratis."])},index_and_search:e=>{const{normalize:a}=e;return a(["\xCDndice y b\xFAsqueda"])},index_and_search1:e=>{const{normalize:a}=e;return a(["\xCDndice y b\xFAsqueda"])},input:e=>{const{normalize:a}=e;return a(["Pedido"])},input_api_key_error1:e=>{const{normalize:a}=e;return a(["Tu clave API no existe"])},input_length:e=>{const{normalize:a}=e;return a(["Longitud de entrada"])},integrate:e=>{const{normalize:a}=e;return a(["Integrar"])},"jina-colbert-v1-en_description":e=>{const{normalize:a}=e;return a(["ColBERT mejorado con una longitud de token de 8K para tareas de incrustaci\xF3n y reclasificaci\xF3n"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:a}=e;return a(["Optimizado para b\xFAsqueda de c\xF3digo y cadenas de documentos"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:a}=e;return a(["Integraciones biling\xFCes alem\xE1n-ingl\xE9s con rendimiento SOTA"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:a}=e;return a(["A la par con text-embedding-ada002 de OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:a}=e;return a(["Incorporaciones biling\xFCes espa\xF1ol-ingl\xE9s con rendimiento SOTA"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:a}=e;return a(["Integraciones biling\xFCes chino-ingl\xE9s con rendimiento SOTA"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:a}=e;return a(["Optimizado para baja latencia y uso de memoria"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:a}=e;return a(["El reranker l\xEDder que maximiza la b\xFAsqueda y la relevancia de RAG"])},key:e=>{const{normalize:a}=e;return a(["Clave API"])},key_enter_placeholder:e=>{const{normalize:a}=e;return a(["Por favor ingrese su clave API"])},key_enter_placeholder_to_topup:e=>{const{normalize:a}=e;return a(["Ingresa la clave API que deseas recargar"])},key_to_top_up:e=>{const{normalize:a}=e;return a(["Clave API para recarga"])},key_warn:e=>{const{normalize:a}=e;return a(["Aseg\xFArese de guardar su clave API en un lugar seguro. De lo contrario, deber\xE1 generar una nueva clave."])},key_warn_v2:e=>{const{normalize:a}=e;return a(["Cada nueva clave tiene algunos tokens gratuitos que puedes probar. Puedes recargar tu clave en cualquier momento. \xA1Aseg\xFArese de guardar su clave API en un lugar seguro!"])},language_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Este modelo es el que mejor admite el idioma ",n(r("_language")),"."])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende m\xE1s"])},learn_poster:e=>{const{normalize:a}=e;return a(["Aprende c\xF3mo lo hicimos"])},learning1:e=>{const{normalize:a}=e;return a(["Aprendiendo sobre incrustaciones"])},learning1_description:e=>{const{normalize:a}=e;return a(["\xBFPor d\xF3nde empezar con las incrustaciones? Te tenemos cubierto. Aprenda sobre las incrustaciones desde cero con nuestra gu\xEDa completa."])},length:e=>{const{normalize:a}=e;return a(["Longitud del token"])},manage_quota1:e=>{const{normalize:a}=e;return a(["Comprar fichas"])},max_file_size:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Tama\xF1o m\xE1ximo permitido: ",n(r("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:a}=e;return a(["Maximizar este panel"])},model_required:e=>{const{normalize:a}=e;return a(["Se requiere modelo"])},more_than_two2:e=>{const{normalize:a}=e;return a(["Introduzca m\xE1s de dos documentos, es decir, m\xE1s de dos l\xEDneas."])},multi_embedding:e=>{const{normalize:a}=e;return a(["Incrustaci\xF3n m\xFAltiple"])},multi_embedding_explain:e=>{const{normalize:a}=e;return a(["Este modelo devolver\xE1 una bolsa de incrustaciones contextualizadas para una entrada determinada. Cada token en la entrada se asigna a un vector en la salida."])},multilingual:e=>{const{normalize:a}=e;return a(["Soporte multiling\xFCe"])},new:e=>{const{normalize:a}=e;return a(["Nuevo modelo"])},no_data1:e=>{const{normalize:a}=e;return a(["Agrega un par de oraciones para calcular la similitud."])},none:e=>{const{normalize:a}=e;return a(["Ninguno"])},open_tensorboard:e=>{const{normalize:a}=e;return a(["Visualizador abierto"])},opensource:e=>{const{normalize:a}=e;return a(["SO"])},opensource_explain:e=>{const{normalize:a}=e;return a(["Este modelo es de c\xF3digo abierto y est\xE1 disponible en Hugging Face. Haga clic en este bot\xF3n para ver el modelo en Hugging Face."])},original_documents:e=>{const{normalize:a}=e;return a(["Documentos para incrustar"])},original_documents_hint:e=>{const{normalize:a}=e;return a(["Ingrese sus documentos aqu\xED. Cada nueva l\xEDnea se considerar\xE1 un documento independiente."])},output:e=>{const{normalize:a}=e;return a(["Respuesta"])},output_dim:e=>{const{normalize:a}=e;return a(["Dimensiones"])},output_dim_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["La dimensi\xF3n de salida de un vector de incrustaci\xF3n de este modelo es ",n(r("_outputDim")),"."])},output_dimension:e=>{const{normalize:a}=e;return a(["Dimensiones de salida"])},pairwise_test:e=>{const{normalize:a}=e;return a(["Por parejas"])},per_k:e=>{const{normalize:a}=e;return a(["/ 1K fichas"])},per_m:e=>{const{normalize:a}=e;return a(["/ 1 mill\xF3n de fichas"])},please_fill_docs_first:e=>{const{normalize:a}=e;return a(["Primero ingrese algunos documentos a continuaci\xF3n antes de realizar la b\xFAsqueda."])},please_select_model:e=>{const{normalize:a}=e;return a(["Seleccione un modelo de incrustaci\xF3n o un modelo de Reranker"])},poster:e=>{const{normalize:a}=e;return a(["La evoluci\xF3n de las incrustaciones P\xF3ster"])},poster_description:e=>{const{normalize:a}=e;return a(["Descubra el p\xF3ster ideal para su espacio, con infograf\xEDas cautivadoras o im\xE1genes impresionantes que rastrean la evoluci\xF3n de los modelos de incrustaci\xF3n de texto desde 1950."])},pricing:e=>{const{normalize:a}=e;return a(["Precios de API"])},pricing_desc:e=>{const{normalize:a}=e;return a(["El precio de nuestra API se estructura en funci\xF3n de la cantidad de tokens enviados en las solicitudes. Este modelo de precios se aplica tanto a la incorporaci\xF3n como a la reclasificaci\xF3n de API. Con la misma clave API, tienes acceso a ambos servicios."])},protectData1:e=>{const{normalize:a}=e;return a(["Los datos y documentos de la solicitud no se utilizan para los modelos de capacitaci\xF3n."])},protectData2:e=>{const{normalize:a}=e;return a(["Cifrado de datos en tr\xE1nsito (TLS 1.2+) y en reposo (AES-GCM 256)."])},protectData3:e=>{const{normalize:a}=e;return a(["Cumple con SOC 2 y GDPR."])},protect_data:e=>{const{normalize:a}=e;return a(["Proteja sus datos"])},query:e=>{const{normalize:a}=e;return a(["Consulta"])},rank_none_description:e=>{const{normalize:a}=e;return a(["No utilices ning\xFAn modelo de reranker."])},read_api_docs:e=>{const{normalize:a}=e;return a(["Leer documentos"])},refresh:e=>{const{normalize:a}=e;return a(["Actualizar"])},refresh_key_tooltip:e=>{const{normalize:a}=e;return a(["Actualiza y obt\xE9n una nueva clave API"])},refresh_token_count1:e=>{const{normalize:a}=e;return a(["Actualice para obtener tokens disponibles de la clave API actual"])},regenerate:e=>{const{normalize:a}=e;return a(["Regenerado"])},remaining:e=>{const{normalize:a}=e;return a(["Fichas disponibles"])},results_as_final_result:e=>{const{normalize:a}=e;return a(["#docs como resultado final"])},results_fed_to_reranker:e=>{const{normalize:a}=e;return a(["#docs enviados al reranker"])},retry:e=>{const{normalize:a}=e;return a(["Rever"])},right_api_key_to_charge:e=>{const{normalize:a}=e;return a(["Ingrese la clave API correcta para recargar"])},running:e=>{const{normalize:a}=e;return a(["Activo"])},score:e=>{const{normalize:a}=e;return a(["Puntaje"])},search:e=>{const{normalize:a}=e;return a(["Buscar"])},search_hint:e=>{const{normalize:a}=e;return a(["Escriba para buscar dentro de los documentos que se enumeran a continuaci\xF3n"])},select_embedding_model:e=>{const{normalize:a}=e;return a(["Seleccionar incrustaciones"])},select_rerank_model:e=>{const{normalize:a}=e;return a(["Seleccionar reclasificador"])},show_api_key:e=>{const{normalize:a}=e;return a(["Mostrar clave API"])},size:e=>{const{normalize:a}=e;return a(["Par\xE1metros"])},size_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["La cantidad de par\xE1metros en el modelo es ",n(r("_size")),"; tenga en cuenta que este no es el tama\xF1o del archivo del modelo."])},sleeping:e=>{const{normalize:a}=e;return a(["Inactivo"])},start_batch:e=>{const{normalize:a}=e;return a(["Iniciar la incrustaci\xF3n por lotes"])},start_embedding:e=>{const{normalize:a}=e;return a(["\xCDndice"])},status_explain:e=>{const{normalize:a}=e;return a(["Nuestra arquitectura sin servidor puede descargar ciertos modelos durante per\xEDodos de bajo uso. Para los modelos activos, las respuestas son inmediatas. Los modelos inactivos requieren unos segundos para cargarse tras la solicitud inicial. Despu\xE9s de la activaci\xF3n, las solicitudes posteriores se procesan m\xE1s r\xE1pidamente."])},text1:e=>{const{normalize:a}=e;return a(["Izquierda"])},text2:e=>{const{normalize:a}=e;return a(["Bien"])},title:e=>{const{normalize:a}=e;return a(["API de incrustaci\xF3n"])},token_example:e=>{const{normalize:a}=e;return a(['Un tweet equivale a aproximadamente 20 tokens, un art\xEDculo de noticias equivale a aproximadamente 1000 tokens y la novela de Charles Dickens "A Tale of Two Cities" tiene m\xE1s de un mill\xF3n de tokens.'])},token_length_explain:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["La longitud m\xE1xima de la secuencia del token de entrada es ",n(r("_tokenLength"))," para este modelo."])},tokens:e=>{const{normalize:a}=e;return a(["Fichas"])},top_up_button:e=>{const{normalize:a}=e;return a(["Recargar clave antigua"])},top_up_button_explain:e=>{const{normalize:a}=e;return a(["La integraci\xF3n de esta clave API ofrece una soluci\xF3n m\xE1s profesional, eliminando la necesidad de cambios frecuentes de clave. Los datos de uso se conservan y son accesibles en cualquier momento."])},top_up_warning_message1:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["A la clave API actual le quedan ",n(r("_remainedTokens"))," tokens y ser\xE1 reemplazada por una nueva clave con tokens ",n(r("_freeTokens")),". Puede continuar usando o recargar la clave anterior si la ha almacenado de forma segura. \xBFComo quieres proceder?"])},top_up_warning_title:e=>{const{normalize:a}=e;return a(["Reemplazar la antigua clave API"])},total_documents:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Progreso de la incorporaci\xF3n: ",n(r("_Processed")),"/",n(r("_Count"))," documentos."])},upload:e=>{const{normalize:a}=e;return a(["Subir"])},upload_file:e=>{const{normalize:a}=e;return a(["Haga clic aqu\xED para cargar un archivo"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},usage_amount:e=>{const{normalize:a}=e;return a(["Cantidad"])},usage_history:e=>{const{normalize:a}=e;return a(["Historial de uso"])},usage_reason:e=>{const{normalize:a}=e;return a(["Raz\xF3n"])},usage_reason_consume:e=>{const{normalize:a}=e;return a(["Consumir"])},usage_reason_purchase:e=>{const{normalize:a}=e;return a(["Compra"])},usage_reason_trial:e=>{const{normalize:a}=e;return a(["Ensayo"])},usage_rerank:e=>{const{normalize:a}=e;return a(["Uso"])},usage_time:e=>{const{normalize:a}=e;return a(["Tiempo"])},vector_database_integration1:e=>{const{normalize:a}=e;return a(["Integraciones"])},vector_database_integration2:e=>{const{normalize:a}=e;return a(["Nuestra API de incrustaci\xF3n est\xE1 integrada de forma nativa con varias bases de datos, almacenes de vectores, marcos RAG y LLMOps de renombre. Para comenzar, simplemente copie y pegue su clave API en cualquiera de las integraciones enumeradas para un comienzo r\xE1pido y sin problemas."])},vector_database_integration_description:e=>{const{normalize:a}=e;return a(["Integre f\xE1cil y perfectamente la API de Jina Embeddings con cualquiera de las bases de datos vectoriales, marcos de orquestaci\xF3n LLM y aplicaciones RAG que aparecen a continuaci\xF3n. Nuestros tutoriales le mostrar\xE1n c\xF3mo."])},view_details:e=>{const{normalize:a}=e;return a(["Ver detalles"])},visualization_example:e=>{const{normalize:a}=e;return a(["Mapear todas las oraciones de esta secci\xF3n a un espacio vectorial 3D"])},visualization_example_you_can:e=>{const{normalize:a}=e;return a(["Utilice nuestra API a continuaci\xF3n, \xA1usted tambi\xE9n puede hacerlo!"])},visualize:e=>{const{normalize:a}=e;return a(["Visualizar"])},visualize_done:e=>{const{normalize:a}=e;return a(["La visualizaci\xF3n ha terminado, ahora puede hacer clic en el bot\xF3n superior para abrir el visualizador."])},wait_for_processing:e=>{const{normalize:a}=e;return a(["Se est\xE1 procesando su petici\xF3n."])},wait_stripe:e=>{const{normalize:a}=e;return a(["Abriendo pago de Stripe, por favor espere"])},what_are_embedding:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 son las incrustaciones?"])},what_are_embedding_answer:e=>{const{normalize:a}=e;return a([`En el coraz\xF3n del procesamiento del lenguaje natural (PLN) moderno se encuentra una t\xE9cnica transformadora conocida como incrustaci\xF3n de texto. Imagine el desaf\xEDo de ense\xF1arle a una computadora a captar los significados matizados de palabras y frases. Los m\xE9todos tradicionales, que se basaban en sistemas r\xEDgidos basados \u200B\u200Ben reglas, se quedaron cortos porque el lenguaje es demasiado complejo y fluido. Ingrese a las incrustaciones de texto: una poderosa soluci\xF3n que traduce texto a un lenguaje de n\xFAmeros, espec\xEDficamente, a vectores en un espacio de alta dimensi\xF3n.

Considere las frases "clima soleado" y "cielo despejado". Para nosotros, nos pintan un cuadro similar. A trav\xE9s de la lente de las incrustaciones, estas frases se transforman en vectores num\xE9ricos que residen cerca unos de otros en este espacio multidimensional, capturando su parentesco sem\xE1ntico. Esta cercan\xEDa en el espacio vectorial no se trata solo de que las palabras o frases sean similares; se trata de comprender el contexto, el sentimiento e incluso los matices sutiles del significado.

\xBFPor qu\xE9 es importante este avance? Para empezar, cierra la brecha entre la riqueza del lenguaje humano y la eficiencia computacional de los algoritmos. Los algoritmos destacan por procesar n\xFAmeros, no por interpretar textos. Al convertir texto en vectores, las incrustaciones hacen posible que estos algoritmos "comprendan" y procesen el lenguaje de una manera que antes estaba fuera de su alcance.

Las aplicaciones pr\xE1cticas son amplias y variadas. Ya sea recomendar contenido que resuene con sus intereses, impulsar una IA conversacional que parezca sorprendentemente humana o incluso detectar patrones sutiles en grandes vol\xFAmenes de texto, las incrustaciones son la clave. Permiten que las m\xE1quinas realicen tareas como an\xE1lisis de sentimientos, traducci\xF3n de idiomas y mucho m\xE1s, con una comprensi\xF3n del lenguaje cada vez m\xE1s matizada y refinada.`])},what_is_a_token:e=>{const{normalize:a}=e;return a(['Un token en el procesamiento de textos es una unidad, a menudo una palabra. Por ejemplo, "\xA1Jina AI es genial!" se convierte en cinco fichas, incluida la puntuaci\xF3n.'])},why_do_you_need:e=>{const{normalize:a}=e;return a(["Elegir las incrustaciones adecuadas"])},why_do_you_need_after:e=>{const{normalize:a}=e;return a(["Aprovechando las redes neuronales profundas y los LLM, nuestros modelos integrados representan datos multimodales en un formato optimizado, lo que mejora la comprensi\xF3n de las m\xE1quinas, el almacenamiento eficiente y permite aplicaciones avanzadas de IA. Estas incorporaciones desempe\xF1an un papel crucial en la comprensi\xF3n de los datos, la mejora de la participaci\xF3n del usuario, la superaci\xF3n de las barreras del idioma y la optimizaci\xF3n de los procesos de desarrollo."])},why_do_you_need_before:e=>{const{normalize:a}=e;return a(["Nuestros modelos de integraci\xF3n est\xE1n dise\xF1ados espec\xEDficamente para atender diversas aplicaciones, combinando lenguaje, c\xF3digo y representaci\xF3n multimodal para abrir nuevas posibilidades en soluciones impulsadas por IA."])},why_need_1_description:e=>{const{normalize:a}=e;return a(["Nuestro modelo de integraci\xF3n central, impulsado por JinaBERT, est\xE1 dise\xF1ado para un amplio espectro de aplicaciones. Destaca en la comprensi\xF3n de textos detallados, lo que lo hace ideal para b\xFAsqueda sem\xE1ntica, clasificaci\xF3n de contenido y an\xE1lisis de lenguaje complejo. Su versatilidad es incomparable y admite la creaci\xF3n de herramientas avanzadas de an\xE1lisis de sentimientos, res\xFAmenes de texto y sistemas de recomendaci\xF3n personalizados."])},why_need_1_title:e=>{const{normalize:a}=e;return a(["Incrustaciones de uso general"])},why_need_2_description:e=>{const{normalize:a}=e;return a(["Nuestros modelos biling\xFCes facilitan la comunicaci\xF3n entre idiomas, mejorando las plataformas multiling\xFCes, la atenci\xF3n al cliente global y el descubrimiento de contenido en varios idiomas. Dise\xF1ados para dominar las traducciones alem\xE1n-ingl\xE9s y chino-ingl\xE9s, estos modelos simplifican las interacciones y fomentan la comprensi\xF3n entre diversos grupos ling\xFC\xEDsticos."])},why_need_2_title:e=>{const{normalize:a}=e;return a(["Incorporaciones biling\xFCes"])},why_need_3_description:e=>{const{normalize:a}=e;return a(["Dise\xF1ado para desarrolladores, nuestro modelo de incorporaci\xF3n de c\xF3digo optimiza las tareas de codificaci\xF3n como el resumen, la generaci\xF3n de c\xF3digo y las revisiones autom\xE1ticas. Aumenta la productividad al ofrecer informaci\xF3n m\xE1s profunda sobre las estructuras del c\xF3digo y sugerir mejoras, lo que lo hace esencial para desarrollar complementos IDE avanzados, documentaci\xF3n autom\xE1tica y herramientas de depuraci\xF3n de vanguardia."])},why_need_3_title:e=>{const{normalize:a}=e;return a(["Incorporaciones de c\xF3digo"])},write_email_here:e=>{const{normalize:a}=e;return a(["Ingrese el correo electr\xF3nico donde desea recibir el enlace de descarga al finalizar."])},you_can_leave:e=>{const{normalize:a}=e;return a(["Puede abandonar esta p\xE1gina y le enviaremos el enlace de descarga una vez finalizada."])}},embeddings:{description:e=>{const{normalize:a}=e;return a(["Nuestras integraciones de clase mundial para sus sistemas de b\xFAsqueda y RAG"])}},faq:{answer1:e=>{const{normalize:a}=e;return a(["Jina AI se especializa en tecnolog\xEDas de IA multimodales, incluido el ajuste de modelos, el servicio de modelos, el ajuste de avisos y el servicio de avisos. Aprovechamos herramientas avanzadas como Kubernetes y arquitecturas sin servidor para crear soluciones robustas, escalables y listas para producci\xF3n."])},answer10:e=>{const{normalize:a}=e;return a(["Brindamos diferentes opciones de licencia seg\xFAn la naturaleza del proyecto y las necesidades del cliente. Los t\xE9rminos detallados se pueden discutir con nuestro equipo de ventas."])},answer11:e=>{const{normalize:a}=e;return a(["Brindamos servicios a nivel mundial, con nuestra sede central en Berl\xEDn, Europa, y oficinas adicionales en Beijing y Shenzhen."])},answer12:e=>{const{normalize:a}=e;return a(["S\xED, ofrecemos soporte en el sitio, especialmente para clientes ubicados cerca de nuestras oficinas en Berl\xEDn, Beijing y Shenzhen. Para otras ubicaciones, nos esforzamos por brindar el mejor soporte remoto posible y podemos organizar el soporte en el sitio si es necesario."])},answer2:e=>{const{normalize:a}=e;return a(["Nuestra experiencia abarca un amplio espectro, que abarca grandes modelos de lenguaje, texto, imagen, video, comprensi\xF3n de audio, b\xFAsqueda neuronal y arte generativo."])},answer3:e=>{const{normalize:a}=e;return a(["S\xED, nuestras soluciones est\xE1n dise\xF1adas para ser escalables y listas para la producci\xF3n. Creamos nuestras soluciones utilizando tecnolog\xEDas nativas de la nube que permiten un escalado eficiente y un rendimiento confiable en entornos de producci\xF3n."])},answer4:e=>{const{normalize:a}=e;return a(["Nuestros servicios son vers\xE1tiles y adaptables, lo que los hace adecuados para una amplia gama de industrias, que incluyen comercio electr\xF3nico, tecnolog\xEDa legal, marketing digital, juegos, atenci\xF3n m\xE9dica, finanzas y muchas m\xE1s."])},answer5:e=>{const{normalize:a}=e;return a(["Puede ponerse en contacto con nuestro equipo comercial a trav\xE9s del formulario de contacto de esta p\xE1gina. Nos encantar\xEDa discutir los requisitos de su proyecto y c\xF3mo nuestras soluciones pueden ayudar a su negocio."])},answer6:e=>{const{normalize:a}=e;return a(["Brindamos soporte continuo para garantizar el buen funcionamiento de nuestras soluciones. Esto incluye resoluci\xF3n de problemas, actualizaciones peri\xF3dicas y mejoras basadas en sus comentarios y necesidades."])},answer7:e=>{const{normalize:a}=e;return a(["La duraci\xF3n del proyecto var\xEDa seg\xFAn la complejidad y el alcance del proyecto. Despu\xE9s de comprender sus requisitos, podemos proporcionarle una estimaci\xF3n m\xE1s precisa."])},answer8:e=>{const{normalize:a}=e;return a(["La seguridad de los datos es nuestra m\xE1xima prioridad. Nos adherimos a estrictas pol\xEDticas y regulaciones de protecci\xF3n de datos para garantizar que sus datos est\xE9n seguros y confidenciales."])},answer9:e=>{const{normalize:a}=e;return a(["El precio depende de la complejidad y los requisitos del proyecto. Ofrecemos modelos de precios basados \u200B\u200Ben proyectos y de retenci\xF3n. P\xF3ngase en contacto con nuestro equipo de ventas para obtener m\xE1s informaci\xF3n."])},question1:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 se especializa Jina AI?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1les son los t\xE9rminos de licencia para sus soluciones?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es su \xE1rea de servicio?"])},question12:e=>{const{normalize:a}=e;return a(["\xBFOfrecen soporte en el sitio?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFCon qu\xE9 tipos de IA trabaja Jina AI?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFSus soluciones son escalables y est\xE1n listas para la producci\xF3n?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 industrias pueden beneficiarse de las soluciones de Jina AI?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo comenzamos un proyecto con Jina AI?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 apoyo brindan despu\xE9s de implementar una soluci\xF3n?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la duraci\xF3n t\xEDpica de un proyecto?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo protege Jina AI mis datos?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la estructura de precios de sus servicios?"])}},finetuner:{description:e=>{const{normalize:a}=e;return a(["Ajuste las incrustaciones en datos espec\xEDficos del dominio para una mejor calidad de b\xFAsqueda"])},intro:e=>{const{normalize:a}=e;return a(["Tu compa\xF1\xEDa. Tu informaci\xF3n. tu modelo"])}},finetuner_plus:{description:e=>{const{normalize:a}=e;return a(["Potencie su empresa con soluciones de ajuste fino en las instalaciones"])}},footer:{address_beijing:e=>{const{normalize:a}=e;return a(["Beijing, China"])},address_berlin:e=>{const{normalize:a}=e;return a(["Berl\xEDn, Alemania (sede central)"])},address_shenzhen:e=>{const{normalize:a}=e;return a(["Shenzhen, China"])},all_rights_reserved:e=>{const{normalize:a}=e;return a(["Reservados todos los derechos."])},company:e=>{const{normalize:a}=e;return a(["Compa\xF1\xEDa"])},developers:e=>{const{normalize:a}=e;return a(["Desarrolladores"])},docs:e=>{const{normalize:a}=e;return a(["Documentos"])},enterprise:e=>{const{normalize:a}=e;return a(["Empresa"])},offices:e=>{const{normalize:a}=e;return a(["Oficinas"])},power_users:e=>{const{normalize:a}=e;return a(["Usuarios avanzados"])},privacy:e=>{const{normalize:a}=e;return a(["Privacidad"])},privacy_policy:e=>{const{normalize:a}=e;return a(["pol\xEDtica de privacidad"])},privacy_settings:e=>{const{normalize:a}=e;return a(["La configuraci\xF3n de privacidad"])},status:e=>{const{normalize:a}=e;return a(["Estado"])},tc:e=>{const{normalize:a}=e;return a(["T\xE9rminos y condiciones"])},tc1:e=>{const{normalize:a}=e;return a(["T\xE9rminos"])}},github:{stars:e=>{const{normalize:a}=e;return a(["Estrellas"])}},header:{about_us:e=>{const{normalize:a}=e;return a(["Sobre nosotros"])},company:e=>{const{normalize:a}=e;return a(["Compa\xF1\xEDa"])},contact_us:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},developers_others:e=>{const{normalize:a}=e;return a(["M\xE1s herramientas para desarrolladores"])},enterprise_others:e=>{const{normalize:a}=e;return a(["M\xE1s soluciones empresariales"])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_developers_description:e=>{const{normalize:a}=e;return a(["Experimente una pila integral de IA multimodal de c\xF3digo abierto dise\xF1ada para desarrolladores."])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para Empresas"])},for_enterprise_description:e=>{const{normalize:a}=e;return a(["Descubra estrategias escalables de IA multimodal dise\xF1adas para satisfacer las necesidades comerciales."])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},for_power_users_description:e=>{const{normalize:a}=e;return a(["Utilice nuestras herramientas multimodales optimizadas para mejorar su productividad."])},internship1:e=>{const{normalize:a}=e;return a(["Programa de pr\xE1cticas"])},jobs:e=>{const{normalize:a}=e;return a(["\xDAnete a nosotros"])},join_discord:e=>{const{normalize:a}=e;return a(["\xDAnete a nuestra comunidad de Discord"])},news:e=>{const{normalize:a}=e;return a(["Noticias"])},open_day:e=>{const{normalize:a}=e;return a(["D\xEDa abierto"])},power_users_others:e=>{const{normalize:a}=e;return a(["M\xE1s herramientas para usuarios avanzados"])},products:e=>{const{normalize:a}=e;return a(["Productos"])}},hub:{description:e=>{const{normalize:a}=e;return a(["Comparta y descubra componentes b\xE1sicos para aplicaciones de IA multimodal"])}},huggingface:{sentence_similarity:e=>{const{normalize:a}=e;return a(["incrustaci\xF3n de oraciones"])},updated_about:e=>{const{normalize:a}=e;return a(["actualizado sobre"])}},impact_snapshots:{project1:e=>{const{normalize:a}=e;return a(["B\xFAsqueda de alta precisi\xF3n habilitada dentro de datos de malla 3D utilizando informaci\xF3n de nube de puntos."])},project10:e=>{const{normalize:a}=e;return a(["Aprovech\xF3 la visi\xF3n artificial para mejorar la accesibilidad digital de los sitios web gubernamentales."])},project11:e=>{const{normalize:a}=e;return a(["LLM ajustado para una firma de consultor\xEDa para optimizar el an\xE1lisis de datos financieros."])},project12:e=>{const{normalize:a}=e;return a(["Estrategias de marketing avanzadas mediante el ajuste fino de los modelos de texto a imagen para la transferencia de estilo."])},project2:e=>{const{normalize:a}=e;return a(["Dise\xF1\xE9 un motor de b\xFAsqueda basado en contenido para cortometrajes de animaci\xF3n."])},project3:e=>{const{normalize:a}=e;return a(["Tasas de conversi\xF3n de comercio electr\xF3nico mejoradas mediante el ajuste fino de los modelos integrados."])},project4:e=>{const{normalize:a}=e;return a(["Realic\xE9 ajustes r\xE1pidos para aumentar la eficiencia de una empresa de consultor\xEDa empresarial."])},project5:e=>{const{normalize:a}=e;return a(["Pionero en la comprensi\xF3n de la escena del juego y la anotaci\xF3n autom\xE1tica para una empresa de juegos l\xEDder."])},project6:e=>{const{normalize:a}=e;return a(["Implement\xE9 la expansi\xF3n de entrada en tiempo real para una empresa de chatbot, mejorando la experiencia del usuario."])},project7:e=>{const{normalize:a}=e;return a(["Revolucion\xF3 la tecnolog\xEDa legal al permitir una b\xFAsqueda eficiente en documentos legales extensos."])},project8:e=>{const{normalize:a}=e;return a(["Apoy\xF3 un servicio de arte generativo de alto rendimiento para operaciones a gran escala."])},project9:e=>{const{normalize:a}=e;return a(["Realizaci\xF3n de miner\xEDa y modelado de procesos utilizando modelos de lenguaje avanzado."])}},inference:{description:e=>{const{normalize:a}=e;return a(["Modelos multimodales de \xFAltima generaci\xF3n disponibles para inferencia"])}},internship_faq:{answer1:e=>{const{normalize:a}=e;return a(["Licenciatura, maestr\xEDa y doctorado. Se alienta a los estudiantes de todo el mundo, con inter\xE9s en campos como la investigaci\xF3n, la ingenier\xEDa, el marketing y las ventas, a postularse. Tambi\xE9n damos la bienvenida a pasant\xEDas no t\xE9cnicas en marketing, ventas, asistencia ejecutiva y m\xE1s. Estamos buscando personas apasionadas listas para ser pioneros en la IA multimodal con nosotros."])},answer10:e=>{const{normalize:a}=e;return a(["S\xED, nuestro programa de pr\xE1cticas ofrece una remuneraci\xF3n competitiva."])},answer11:e=>{const{normalize:a}=e;return a(["Como pasante de Jina AI, obtendr\xE1 experiencia pr\xE1ctica trabajando en proyectos desafiantes, aprender\xE1 de expertos de la industria, ser\xE1 parte de una comunidad vibrante y tendr\xE1 la oportunidad de hacer contribuciones reales a nuestro trabajo pionero en AI multimodal."])},answer2:e=>{const{normalize:a}=e;return a(["Las pasant\xEDas deben llevarse a cabo en el sitio en una de nuestras oficinas, que se encuentran en Berl\xEDn, Beijing y Shenzhen."])},answer3:e=>{const{normalize:a}=e;return a(["S\xED, Jina AI ofrece asistencia razonable en el proceso de visa para los solicitantes seleccionados."])},answer4:e=>{const{normalize:a}=e;return a(["S\xED, Jina AI brinda una cantidad razonable de cobertura de costo de vida para los pasantes durante el per\xEDodo de pasant\xEDa."])},answer5:e=>{const{normalize:a}=e;return a(["S\xED, es posible trabajar en su tesis de maestr\xEDa durante su pasant\xEDa en Jina AI, generalmente aplicable a estudiantes en universidades alemanas. Sin embargo, debe tener una comunicaci\xF3n previa y acuerdo del supervisor de su universidad. Tenga en cuenta que no ayudamos a los estudiantes a encontrar asesores."])},answer6:e=>{const{normalize:a}=e;return a(["El proceso de solicitud incluye enviar su formulario de solicitud, un curr\xEDculum, una carta de presentaci\xF3n que exprese su inter\xE9s y motivaci\xF3n, y cualquier enlace profesional relevante como GitHub o LinkedIn. Evaluamos a los candidatos en funci\xF3n de su desempe\xF1o durante la entrevista y su desempe\xF1o en su universidad."])},answer7:e=>{const{normalize:a}=e;return a(["S\xED, los pasantes exitosos pueden recibir una carta de recomendaci\xF3n al final de su pasant\xEDa, firmada por nuestro CEO."])},answer8:e=>{const{normalize:a}=e;return a(["La duraci\xF3n de la pasant\xEDa var\xEDa seg\xFAn el rol y el proyecto. Sin embargo, por lo general oscila entre tres y seis meses."])},answer9:e=>{const{normalize:a}=e;return a(["S\xED, aceptamos solicitudes de todos los antecedentes acad\xE9micos. Valoramos su pasi\xF3n y compromiso por aprender tanto como su experiencia previa."])},question1:e=>{const{normalize:a}=e;return a(["\xBFQui\xE9n puede solicitar el programa de pasant\xEDas de Jina AI?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFEs esta una pasant\xEDa remunerada?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 oportunidades tendr\xE9 como pasante de Jina AI?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFD\xF3nde se realizar\xE1 la pasant\xEDa?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFJina AI ayuda con los procesos de visa?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFJina AI proporciona asignaciones o beneficios para los pasantes?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFPuedo trabajar en mi tesis de maestr\xEDa durante la pasant\xEDa en Jina AI?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 consiste el proceso de solicitud?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFJina AI proporciona alguna carta de recomendaci\xF3n posterior a la pasant\xEDa?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la duraci\xF3n de la pasant\xEDa?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFPuedo presentar una solicitud si no tengo experiencia previa en IA?"])}},internship_page:{about_internship_program:e=>{const{normalize:a}=e;return a(["Acerca del programa de pasant\xEDas"])},about_internship_program_desc1:e=>{const{normalize:a}=e;return a(["Estamos emocionados de ofrecer esta oportunidad \xFAnica para que personas talentosas se unan a nuestro equipo din\xE1mico y contribuyan a proyectos innovadores en el campo de la Inteligencia Artificial. Esta pasant\xEDa est\xE1 dise\xF1ada para brindarle una valiosa experiencia pr\xE1ctica, tutor\xEDa y exposici\xF3n a tecnolog\xEDas de vanguardia que est\xE1n dando forma al futuro de la IA."])},about_internship_program_desc2:e=>{const{normalize:a}=e;return a(["En Jina AI, entendemos la importancia de nutrir y aprovechar el talento joven. Reconocemos que los pasantes aportan nuevas perspectivas, entusiasmo y creatividad a la mesa, fortaleciendo a nuestro equipo con nuevas ideas y enfoques. Al proporcionar pasant\xEDas, nuestro objetivo es fomentar el crecimiento de los futuros l\xEDderes en la industria de la IA al tiempo que les ofrecemos una experiencia del mundo real en un entorno estimulante y de apoyo."])},alumni:e=>{const{normalize:a}=e;return a(["ALUMNOS"])},alumni_network:e=>{const{normalize:a}=e;return a(["Nuestra pr\xF3spera red de antiguos alumnos"])},application:e=>{const{normalize:a}=e;return a(["Solicitud"])},application_desc:e=>{const{normalize:a}=e;return a(["Emb\xE1rquese en un viaje transformador con Jina AI. Nuestro completo programa de pasant\xEDas invita a todas las mentes apasionadas que aspiran a dar forma al futuro de la inteligencia artificial. \xDAnase a nosotros para obtener experiencia en el mundo real, trabajar en proyectos desafiantes y colaborar con algunas de las mentes m\xE1s brillantes de la industria de la IA."])},apply:e=>{const{normalize:a}=e;return a(["Aplica ya"])},autumn:e=>{const{normalize:a}=e;return a(["Oto\xF1o"])},description:e=>{const{normalize:a}=e;return a(["Convocatoria mundial para estudiantes: Pasantes en investigaci\xF3n, ingenier\xEDa, marketing, ventas y m\xE1s para ser pioneros juntos en la IA multimodal."])},dev_rel_intern:e=>{const{normalize:a}=e;return a(["Pasante de Relaciones con Desarrolladores"])},enthusiastic:e=>{const{normalize:a}=e;return a(["ENTUSIASTA"])},explore_stories_from_our_interns:e=>{const{normalize:a}=e;return a(["Explore las historias de nuestros pasantes"])},explore_stories_from_our_interns1:e=>{const{normalize:a}=e;return a(["Insp\xEDrate con los viajes de nuestros pasantes"])},innovative:e=>{const{normalize:a}=e;return a(["INNOVADOR"])},intern_work1:e=>{const{normalize:a}=e;return a(["Modelos LLM ajustados para mejores incrustaciones"])},intern_work2:e=>{const{normalize:a}=e;return a(["Explor\xF3 el potencial de recuperaci\xF3n de generaci\xF3n aumentada"])},intern_work3:e=>{const{normalize:a}=e;return a(["Public\xF3 un art\xEDculo sobre el tema de las incrustaciones de oraciones."])},intern_work4:e=>{const{normalize:a}=e;return a(["Inyectar vitalidad juvenil continua al equipo."])},intern_work5:e=>{const{normalize:a}=e;return a(["T\xE9cnicas de cuantificaci\xF3n comparadas para comprimir LLM"])},intern_work6:e=>{const{normalize:a}=e;return a(["Creaci\xF3n y promoci\xF3n de campa\xF1as atractivas para PromptPerfect"])},recruiting_and_administrative_intern:e=>{const{normalize:a}=e;return a(["Practicante de Reclutamiento y Administraci\xF3n"])},self_motivated:e=>{const{normalize:a}=e;return a(["AUTO MOTIVADO"])},software_engineer_intern:e=>{const{normalize:a}=e;return a(["Pasante de ingenier\xEDa de software"])},spring:e=>{const{normalize:a}=e;return a(["Primavera"])},submit_application:e=>{const{normalize:a}=e;return a(["Comienza tu aventura con Jina AI"])},subtitle:e=>{const{normalize:a}=e;return a(["Nuestro programa de pasant\xEDas de tiempo completo brinda experiencia laboral pr\xE1ctica a trav\xE9s de proyectos de pasant\xEDas bien dise\xF1ados en una amplia gama de alcances."])},subtitle1:e=>{const{normalize:a}=e;return a(["Convocatoria mundial para estudiantes: Pasantes en investigaci\xF3n, ingenier\xEDa, marketing, ventas y m\xE1s para ser pioneros juntos en la IA multimodal."])},summer:e=>{const{normalize:a}=e;return a(["Verano"])},title:e=>{const{normalize:a}=e;return a(["Programa de pasant\xEDas"])},who_do_we_look_for:e=>{const{normalize:a}=e;return a(["\xBFA qui\xE9n buscamos?"])},who_do_we_look_for_desc:e=>{const{normalize:a}=e;return a(["Valoramos la diversidad y alentamos a los solicitantes de diversos perfiles y antecedentes a unirse a nuestro Programa de pasant\xEDas. Las oportunidades de pasant\xEDas se ofrecen en varios departamentos, incluidos ingenier\xEDa, dise\xF1o, gesti\xF3n de productos, gesti\xF3n de ventas y cuentas, marketing y gesti\xF3n comunitaria."])},winter:e=>{const{normalize:a}=e;return a(["Invierno"])}},jcloud:{description:e=>{const{normalize:a}=e;return a(["Implemente un proyecto local como un servicio en la nube. Radicalmente f\xE1cil, sin sorpresas desagradables."])}},jerboa:{description:e=>{const{normalize:a}=e;return a(["Un perfeccionador experimental para LLM de c\xF3digo abierto"])}},jina:{description:e=>{const{normalize:a}=e;return a(["Cree aplicaciones de IA multimodales en la nube"])}},jina_chat:{description:e=>{const{normalize:a}=e;return a(["M\xE1s modalidad, m\xE1s memoria, menos costo"])},example_1:e=>{const{normalize:a}=e;return a(["\xBFQui\xE9n eres?"])},example_2:e=>{const{normalize:a}=e;return a(["Soy un servicio de chat LLM creado por Jina AI"])}},lab_dialog:{GlobalQA:{description:e=>{const{normalize:a}=e;return a(["Presione la tecla '/' en cualquier p\xE1gina para abrir el cuadro de preguntas. Escriba su consulta y presione 'Entrar' para recibir respuestas directamente relacionadas con el contenido de la p\xE1gina. Esta caracter\xEDstica est\xE1 impulsada por PromptPerfect."])},title:e=>{const{normalize:a}=e;return a(["RAG en la p\xE1gina"])}},Recommender:{description:e=>{const{normalize:a}=e;return a(["Abra el cuadro de recomendaci\xF3n en cualquier p\xE1gina de noticias con 'Shift+2'. Seleccione el modelo de reranker para descubrir los 5 art\xEDculos principales relacionados con esa p\xE1gina de noticias. Disfrute de esta funci\xF3n en tiempo real, impulsada por nuestra API Reranker."])},title:e=>{const{normalize:a}=e;return a(["Art\xEDculo relacionado"])}},SceneXplainTooltip:{description:e=>{const{normalize:a}=e;return a(["Pase el cursor sobre cualquier imagen en las p\xE1ginas de noticias o en nuestro cat\xE1logo de redacci\xF3n para revelar la descripci\xF3n de esa imagen. Las descripciones las calcula previamente SceneXplain y las incrustan en el atributo ALT de la imagen para mayor accesibilidad."])},title:e=>{const{normalize:a}=e;return a(["Subt\xEDtulos de im\xE1genes"])}},explain:e=>{const{normalize:a}=e;return a(["Descubra funciones ocultas en nuestro sitio web"])}},landing_page:{also_available_on:e=>{const{normalize:a}=e;return a(["Tambi\xE9n disponible en los mercados."])},also_available_on1:e=>{const{normalize:a}=e;return a(["Disponible en los mercados de su nube empresarial"])},ask_how_your_question:e=>{const{normalize:a}=e;return a(["Por favor describe tu problema"])},build_js:e=>{const{normalize:a}=e;return a(["Construir con JavaScript"])},build_python:e=>{const{normalize:a}=e;return a(["Construir con Python"])},checkout_our_solution_for_you:e=>{const{normalize:a}=e;return a(["Descubra nuestra soluci\xF3n a su medida"])},coming_soon:e=>{const{normalize:a}=e;return a(["Muy pronto"])},contact_sales:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},copied_to_clipboard:e=>{const{normalize:a}=e;return a(["Copiado al portapapeles"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},developers:e=>{const{normalize:a}=e;return a(["Desarrolladores"])},developers_desc:e=>{const{normalize:a}=e;return a(["Libere todo el poder de la IA multimodal con tecnolog\xEDas nativas de la nube de vanguardia e infraestructura de c\xF3digo abierto."])},download_pdf:e=>{const{normalize:a}=e;return a(["Descargar PDF"])},embedding_desc1:e=>{const{normalize:a}=e;return a(["El primer modelo de incrustaci\xF3n de c\xF3digo abierto del mundo con una longitud de 8192 tokens, que coincide con text-embedding-ada002 de OpenAI en Massive Text Embedding Benchmark (MTEB)."])},embedding_paper_desc:e=>{const{normalize:a}=e;return a(["Jina Embeddings constituye un conjunto de modelos de incrustaci\xF3n de oraciones de alto rendimiento, expertos en traducir varias entradas textuales en representaciones num\xE9ricas, capturando as\xED la esencia sem\xE1ntica del texto. Si bien estos modelos no est\xE1n dise\xF1ados exclusivamente para la generaci\xF3n de texto, se destacan en aplicaciones como la recuperaci\xF3n densa y la similitud textual sem\xE1ntica. Este documento detalla el desarrollo de Jina Embeddings, comenzando con la creaci\xF3n de un conjunto de datos de pares y triples de alta calidad. Subraya el papel crucial de la limpieza de datos en la preparaci\xF3n del conjunto de datos, brinda informaci\xF3n detallada sobre el proceso de capacitaci\xF3n del modelo y concluye con una evaluaci\xF3n integral del rendimiento utilizando Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:a}=e;return a(["Jina Embeddings: un novedoso conjunto de modelos de incrustaci\xF3n de oraciones de alto rendimiento"])},embeddings:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},enterprise:e=>{const{normalize:a}=e;return a(["Empresa"])},enterprise_desc:e=>{const{normalize:a}=e;return a(["Impulse su negocio con soluciones de IA multimodal escalables, seguras y personalizadas."])},enterprise_desc_v2:e=>{const{normalize:a}=e;return a(["Pruebe nuestros modelos de integraci\xF3n de clase mundial para mejorar sus sistemas de b\xFAsqueda y RAG. \xA1Empiece con una prueba gratuita!"])},enterprise_desc_v3:e=>{const{normalize:a}=e;return a(["Desarrollamos modelos b\xE1sicos de b\xFAsqueda de vanguardia para soluciones RAG y de b\xFAsqueda empresarial de alta calidad. \xA1Empiece con una prueba gratuita!"])},error:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["Hubo un problema con la operaci\xF3n de b\xFAsqueda: ",n(r("mensaje"))])},find_your_portal:e=>{const{normalize:a}=e;return a(["Encuentre su Portal"])},finding_faq:e=>{const{normalize:a}=e;return a(["Generando respuestas basadas en el conocimiento de las preguntas frecuentes a continuaci\xF3n"])},for:e=>{const{normalize:a}=e;return a(["Para"])},get_api_now:e=>{const{normalize:a}=e;return a(["API"])},how_to:e=>{const{normalize:a}=e;return a(["C\xF3mo"])},include_experiment:e=>{const{normalize:a}=e;return a(["Incluye nuestros proyectos experimentales y archivados en la soluci\xF3n."])},join_community:e=>{const{normalize:a}=e;return a(["\xDAnete a la comunidad"])},learn_more_embeddings:e=>{const{normalize:a}=e;return a(["M\xE1s informaci\xF3n sobre incrustaciones"])},learn_more_reranker:e=>{const{normalize:a}=e;return a(["M\xE1s informaci\xF3n sobre el cambio de rango"])},llm:e=>{const{normalize:a}=e;return a(["Modelos de inclusi\xF3n LLM"])},llm_desc:e=>{const{normalize:a}=e;return a(["Proporcionamos una colecci\xF3n de modelos de incrustaci\xF3n de oraciones de alto rendimiento, con entre 35 millones y 6 mil millones de par\xE1metros. Son excelentes para mejorar la b\xFAsqueda neuronal, la reclasificaci\xF3n, la similitud de oraciones, las recomendaciones, etc. \xA1Prep\xE1rate para mejorar tu experiencia de IA!"])},mentioned_products:e=>{const{normalize:a}=e;return a(["Productos mencionados:"])},mmstack:e=>{const{normalize:a}=e;return a(["Stack multimodal"])},mmstack_desc:e=>{const{normalize:a}=e;return a(["El Stack para desarrolladores, f\xE1cil de usar, nativo de la nube y listo para producci\xF3n para crear aplicaciones de IA multimodales."])},multimodal:e=>{const{normalize:a}=e;return a(["Multimodal"])},multimodal_ai:e=>{const{normalize:a}=e;return a(["IA multimodal"])},new:e=>{const{normalize:a}=e;return a(["Nuevo"])},newsroom:e=>{const{normalize:a}=e;return a(["Sala de prensa"])},"on-prem-deploy":e=>{const{normalize:a}=e;return a(["Implementaci\xF3n local"])},"on-premises":e=>{const{normalize:a}=e;return a(["En las instalaciones"])},opensource:e=>{const{normalize:a}=e;return a(["C\xF3digo abierto"])},our_publications:e=>{const{normalize:a}=e;return a(["Nuestras Publicaciones"])},parameters:e=>{const{normalize:a}=e;return a(["Par\xE1metros"])},podcast:e=>{const{normalize:a}=e;return a(["Podcast"])},power_users:e=>{const{normalize:a}=e;return a(["Usuarios avanzados"])},power_users_desc:e=>{const{normalize:a}=e;return a(["Experimente aplicaciones de IA multimodal potentes y f\xE1ciles de usar. Sin codificaci\xF3n, sin complicaciones, solo resultados."])},powered_by_promptperfect:e=>{const{normalize:a}=e;return a(['Desarrollado por la funci\xF3n "Optimizaci\xF3n de solicitud" y "Solicitud como servicio" de PromptPerfect'])},pricing:e=>{const{normalize:a}=e;return a(["Precios"])},proposing_solution:e=>{const{normalize:a}=e;return a(["Proponiendo una soluci\xF3n basada en los productos Jina AI..."])},read_more:e=>{const{normalize:a}=e;return a(["Leer m\xE1s"])},require_full_question:e=>{const{normalize:a}=e;return a(["Describe tu problema con m\xE1s detalles."])},reranker:e=>{const{normalize:a}=e;return a(["reclasificador"])},researcher_desc:e=>{const{normalize:a}=e;return a(["Para comprender c\xF3mo se entrenaron nuestros grandes modelos de lenguaje desde cero para tareas de integraci\xF3n, consulte nuestras investigaciones y publicaciones m\xE1s recientes. Conozca a nuestro equipo en las conferencias EMNLP, ACL, SIGIR, NeurIPS e ICML."])},researchers:e=>{const{normalize:a}=e;return a(["Investigadores"])},sdk:e=>{const{normalize:a}=e;return a(["SDK"])},sdk_desc:e=>{const{normalize:a}=e;return a(["\xBFQuiere crear aplicaciones AIGC de alto nivel con las API de PromptPerfect, SceneXplain, BestBanner, JinaChat y Rationale? \xA1Le tenemos cubierto! Pruebe nuestro SDK f\xE1cil de usar y comience en minutos."])},sdk_docs:e=>{const{normalize:a}=e;return a(["Leer documentos"])},sdk_example:e=>{const{normalize:a}=e;return a(["Ejemplo"])},starter_kit:e=>{const{normalize:a}=e;return a(["Kit de inicio"])},supercharged:e=>{const{normalize:a}=e;return a(["Sobrealimentado."])},trusted_by:e=>{const{normalize:a}=e;return a(["DE CONFIANZA PARA"])},try_it_for_free:e=>{const{normalize:a}=e;return a(["Pru\xE9balo gratis, no se requiere tarjeta de cr\xE9dito"])},try_our_saas:e=>{const{normalize:a}=e;return a(["Pruebe nuestra soluci\xF3n alojada, un reemplazo directo de la API integrada de OpenAI."])},your_portal_to:e=>{const{normalize:a}=e;return a(["Tu Portal a"])},your_search_foundation:e=>{const{normalize:a}=e;return a(["Tu base de b\xFAsqueda"])}},langchain_serve:{description:e=>{const{normalize:a}=e;return a(["Aplicaciones Langchain en producci\xF3n con Jina y FastAPI"])}},news_page:{back_to_newsroom:e=>{const{normalize:a}=e;return a(["Volver a la sala de prensa"])},categories:e=>{const{normalize:a}=e;return a(["Categor\xEDas"])},copy_link:e=>{const{normalize:a}=e;return a(["Copia el enlace a esta secci\xF3n."])},in_this_article:e=>{const{normalize:a}=e;return a(["En este articulo"])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende m\xE1s"])},news_not_found:e=>{const{normalize:a}=e;return a(["Art\xEDculo no encontrado"])},redirect_to_news:e=>{const{normalize:a}=e;return a(["Redirigiendo a la sala de redacci\xF3n en 5 segundos..."])}},newsroom_page:{author:e=>{const{normalize:a}=e;return a(["por autor"])},description:e=>{const{normalize:a}=e;return a(["Lea las \xFAltimas noticias y actualizaciones de Jina AI."])},engineering_group:e=>{const{normalize:a}=e;return a(["Grupo de Ingenier\xEDa"])},engineering_group_date:e=>{const{normalize:a}=e;return a(["31 mayo, 2021"])},minutes_read:e=>{const{normalize:a}=e;return a(["minutos de lectura"])},most_recent_articles:e=>{const{normalize:a}=e;return a(["Art\xEDculos m\xE1s recientes"])},news_description:e=>{const{normalize:a}=e;return a(['Para Jina 2.0, escuchamos a la comunidad. Verdaderamente, profundamente escuchado. "\xBFCu\xE1les son tus puntos d\xE9biles?" preguntamos, esperando ansiosamente comentarios valiosos'])},news_title:e=>{const{normalize:a}=e;return a(["Buscar todas las cosas: estamos organizando un concurso MEME para Jina 2.0"])},photos:e=>{const{normalize:a}=e;return a(["Fotos"])},product:e=>{const{normalize:a}=e;return a(["por producto"])},search:e=>{const{normalize:a}=e;return a(["Buscar por t\xEDtulo"])},tech_blog:e=>{const{normalize:a}=e;return a(["Blog de tecnolog\xEDa"])},title:e=>{const{normalize:a}=e;return a(["Sala de prensa"])},top_stories:e=>{const{normalize:a}=e;return a(["Historias destacadas"])}},notice:e=>{const{normalize:a}=e;return a(['\u{1F389} \xA1Nuestro primer libro, "B\xFAsqueda neuronal: del prototipo a la producci\xF3n con Jina" sale oficialmente hoy!'])},open_day:{description:e=>{const{normalize:a}=e;return a(["Una oportunidad exclusiva para obtener una visi\xF3n privilegiada de Jina AI."])},engage:e=>{const{normalize:a}=e;return a(["Recomendamos encarecidamente un di\xE1logo interactivo durante todo el d\xEDa. El intercambio de pensamientos y perspectivas es invaluable para nosotros. Las colaboraciones potenciales derivadas de estas discusiones podr\xEDan contribuir significativamente a un futuro m\xE1s integrado e innovador."])},engage_title:e=>{const{normalize:a}=e;return a(["Participa con nosotros"])},experience:e=>{const{normalize:a}=e;return a(["Hemos organizado un recorrido inmersivo de tres horas para nuestros hu\xE9spedes, disponible en alem\xE1n, ingl\xE9s, franc\xE9s, espa\xF1ol, chino y ruso. El recorrido cubre una mirada en profundidad a nuestros avances en IA multimodal, nuestra perspectiva sobre el panorama de la IA, seguido de un examen detallado de proyectos espec\xEDficos. Concluiremos con una discusi\xF3n grupal para facilitar el intercambio de ideas y puntos de vista. Una opci\xF3n de almuerzo tambi\xE9n est\xE1 disponible bajo petici\xF3n."])},experience_title:e=>{const{normalize:a}=e;return a(["El viaje de un iniciado"])},group_size:e=>{const{normalize:a}=e;return a(["N\xFAmero estimado de visitantes"])},impact:e=>{const{normalize:a}=e;return a(["Comprenda c\xF3mo nuestras contribuciones a la comunidad de c\xF3digo abierto y nuestro trabajo en tecnolog\xEDa de IA multimodal est\xE1n estableciendo a Jina AI como un jugador influyente en la innovaci\xF3n de IA. Nuestro objetivo es desempe\xF1ar un papel importante en los procesos de toma de decisiones, asegurando que el avance de la tecnolog\xEDa de IA beneficie a todos."])},impact_title:e=>{const{normalize:a}=e;return a(["Impacto e influencia"])},introduction:e=>{const{normalize:a}=e;return a(["Jina AI se complace en abrir nuestras puertas a entidades y organizaciones estimadas interesadas en el progreso y el futuro de la Inteligencia Artificial. Extendemos esta oportunidad exclusiva para aquellos en la pol\xEDtica, las ONG, las OSFL y los sectores de inversi\xF3n para obtener una visi\xF3n interna de nuestras operaciones y visiones aqu\xED en nuestra sede de Berl\xEDn."])},motivation_min_length_v1:e=>{const{normalize:a}=e;return a(["Proporcione una motivaci\xF3n m\xE1s detallada."])},motivation_placeholder_v2:e=>{const{normalize:a}=e;return a(["Compartir tus motivaciones nos ayudar\xE1 a mejorar tu experiencia."])},motivation_to_attend_v2:e=>{const{normalize:a}=e;return a(["\xBFPor qu\xE9 te interesa nuestra jornada de puertas abiertas?"])},one_hour:e=>{const{normalize:a}=e;return a(["1 hora"])},organization:e=>{const{normalize:a}=e;return a(["Organizaci\xF3n"])},organization_website:e=>{const{normalize:a}=e;return a(["Sitio web de la organizaci\xF3n"])},organization_website_placeholder:e=>{const{normalize:a}=e;return a(["URL de la p\xE1gina de inicio de su organizaci\xF3n o del perfil de LinkedIn"])},preferred_date:e=>{const{normalize:a}=e;return a(["Fecha preferida"])},preferred_language:e=>{const{normalize:a}=e;return a(["Idioma preferido del tour"])},preferred_products:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 productos est\xE1s interesado?"])},subtitle:e=>{const{normalize:a}=e;return a(["Un vistazo al futuro de la IA multimodal"])},title:e=>{const{normalize:a}=e;return a(["Dia abierto"])},tutor_subtitle:e=>{const{normalize:a}=e;return a(["Un recorrido de tres horas cuidadosamente seleccionado que lo acerca al coraz\xF3n del trabajo innovador de Jina AI en tecnolog\xEDa de IA multimodal."])},tutor_title:e=>{const{normalize:a}=e;return a(["Una inmersi\xF3n profunda exclusiva en"])},vision:e=>{const{normalize:a}=e;return a(["\xDAnase a nosotros para obtener una descripci\xF3n general completa del panorama de la IA tal como lo vemos. Nuestra discusi\xF3n se centrar\xE1 en el potencial de los modelos de lenguaje grande, la IA multimodal y el impacto de la tecnolog\xEDa de c\xF3digo abierto en la configuraci\xF3n del futuro de la innovaci\xF3n global."])},vision_title:e=>{const{normalize:a}=e;return a(["Nuestra visi\xF3n para el futuro"])}},open_day_faq:{answer1:e=>{const{normalize:a}=e;return a(["Ofrecemos tours en alem\xE1n, ingl\xE9s, franc\xE9s, espa\xF1ol, chino y ruso."])},answer2:e=>{const{normalize:a}=e;return a(["El recorrido suele durar aproximadamente tres horas."])},answer3:e=>{const{normalize:a}=e;return a(["El almuerzo es opcional y se puede organizar bajo petici\xF3n."])},answer4:e=>{const{normalize:a}=e;return a(["Nuestra Jornada de Puertas Abiertas est\xE1 dise\xF1ada principalmente para grupos profesionales, como pol\xEDticos, ONG, OSFL e inversores. Sin embargo, ocasionalmente hacemos excepciones seg\xFAn el perfil de la persona."])},answer5:e=>{const{normalize:a}=e;return a(["Podemos acomodar una variedad de tama\xF1os de grupo. Indique el tama\xF1o de su grupo en el formulario de registro y le confirmaremos los detalles."])},answer6:e=>{const{normalize:a}=e;return a(["Hay una secci\xF3n en el formulario de registro donde puede especificar sus \xE1reas de inter\xE9s o cualquier solicitud especial. Haremos todo lo posible para adaptar el recorrido de acuerdo a sus necesidades."])},answer7:e=>{const{normalize:a}=e;return a(["En este momento, solo ofrecemos tours en nuestra sede de Berl\xEDn ubicada en Kreuzberg. Nuestras oficinas de Beijing y Shenzhen no est\xE1n abiertas actualmente para visitas."])},question1:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 idiomas ofrecen para el tour?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la duraci\xF3n del recorrido?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFSe proporciona almuerzo?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFPueden registrarse personas para la Jornada de Puertas Abiertas?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFDe cu\xE1ntas personas puede estar formado un grupo para la Jornada de Puertas Abiertas?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo puedo especificar \xE1reas de inter\xE9s para el tour?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFHay recorridos disponibles en sus oficinas de Beijing o Shenzhen?"])}},open_gpt:{description:e=>{const{normalize:a}=e;return a(["Un marco de servicio nativo de la nube de c\xF3digo abierto de grandes modelos multimodales"])}},powered_by:e=>{const{normalize:a}=e;return a(["Energizado por"])},print:e=>{const{normalize:a}=e;return a(["Imprimir"])},project_status:{archived:e=>{const{normalize:a}=e;return a(["Archivado"])},cloud_native:e=>{const{normalize:a}=e;return a(["Nativo de la nube"])},core:e=>{const{normalize:a}=e;return a(["Centro"])},data_structure:e=>{const{normalize:a}=e;return a(["Estructura de datos"])},embedding_serving:e=>{const{normalize:a}=e;return a(["Incrustar servicio"])},embedding_tuning:e=>{const{normalize:a}=e;return a(["Ajuste de incrustaci\xF3n"])},graduated:e=>{const{normalize:a}=e;return a(["Graduado"])},incubating:e=>{const{normalize:a}=e;return a(["incubando"])},kubernetes:e=>{const{normalize:a}=e;return a(["Kubernetes"])},large_size_model:e=>{const{normalize:a}=e;return a(["Modelo de gran tama\xF1o"])},linux_foundation:e=>{const{normalize:a}=e;return a(["Fundaci\xF3n Linux"])},llm1:e=>{const{normalize:a}=e;return a(["LLMOps"])},mid_size_model:e=>{const{normalize:a}=e;return a(["Modelo de tama\xF1o mediano"])},model_serving:e=>{const{normalize:a}=e;return a(["Servicio modelo"])},model_tuning:e=>{const{normalize:a}=e;return a(["Ajuste del modelo"])},orchestration:e=>{const{normalize:a}=e;return a(["Orquestaci\xF3n"])},prompt_serving:e=>{const{normalize:a}=e;return a(["Servicio r\xE1pido"])},prompt_tuning:e=>{const{normalize:a}=e;return a(["Sintonizaci\xF3n r\xE1pida"])},rag1:e=>{const{normalize:a}=e;return a(["TRAPO"])},sandbox:e=>{const{normalize:a}=e;return a(["Salvadera"])},small_size_model:e=>{const{normalize:a}=e;return a(["Modelo de tama\xF1o peque\xF1o"])},vector_database:e=>{const{normalize:a}=e;return a(["Base de datos de vectores"])},vector_store:e=>{const{normalize:a}=e;return a(["Tienda de vectores"])}},prompt_perfect:{description:e=>{const{normalize:a}=e;return a(["Herramienta principal para ingenier\xEDa r\xE1pida"])},image_model:e=>{const{normalize:a}=e;return a(["Modelos de imagen"])},intro:e=>{const{normalize:a}=e;return a(["Herramienta principal para ingenier\xEDa r\xE1pida"])},intro1:e=>{const{normalize:a}=e;return a(["La principal herramienta para una ingenier\xEDa r\xE1pida"])},optimized:e=>{const{normalize:a}=e;return a(["Su tarea es ser mi compa\xF1ero de lluvia de ideas y proporcionar ideas y sugerencias creativas para un tema o problema determinado. Su respuesta debe incluir ideas originales, \xFAnicas y relevantes que puedan ayudar a resolver el problema o explorar m\xE1s a fondo el tema de una manera interesante. Tenga en cuenta que su respuesta tambi\xE9n debe tener en cuenta los requisitos o limitaciones espec\xEDficos de la tarea."])},optimized_title:e=>{const{normalize:a}=e;return a(["Mensaje optimizado"])},original:e=>{const{normalize:a}=e;return a(["Tu papel es ser mi compa\xF1ero de intercambio de ideas."])},original_title:e=>{const{normalize:a}=e;return a(["Aviso original"])},text_model:e=>{const{normalize:a}=e;return a(["Modelos de texto"])}},purchase_now:e=>{const{normalize:a}=e;return a(["Comprar ahora"])},rationale:{decision:e=>{const{normalize:a}=e;return a(["Decisi\xF3n"])},description:e=>{const{normalize:a}=e;return a(["Las mejores herramientas de toma de decisiones de IA"])},intro:e=>{const{normalize:a}=e;return a(["Ver las dos caras de la moneda, tomar decisiones racionales"])}},recommender:{confirm_message:e=>{const{normalize:a,interpolate:n,named:r}=e;return a(["A su clave API le quedan ",n(r("_leftTokens"))," tokens. Enviar el texto completo de los art\xEDculos ",n(r("_numArticles"))," a la API de Reranker, utilizando el modelo ",n(r("_selectedReranker"))," para descubrir art\xEDculos relacionados para la p\xE1gina actual, reducir\xE1 significativamente el recuento de tokens de su clave API ",n(r("_APIKey")),". Quieres proceder?"])},confirm_title:e=>{const{normalize:a}=e;return a(["Advertencia: uso elevado de tokens"])},out_of_quota:e=>{const{normalize:a}=e;return a(["Esta clave API se ha quedado sin tokens. Recargue su cuenta o utilice una clave API diferente."])},recommend:e=>{const{normalize:a}=e;return a(["Obtenga los 5 mejores relacionados"])},recommended_articles:e=>{const{normalize:a}=e;return a(["Los 5 art\xEDculos m\xE1s relacionados"])}},reranker:{benchmark:{description0:e=>{const{normalize:a}=e;return a(["LlamaIndex evalu\xF3 varias combinaciones de incrustaciones y reordenadores para RAG y realiz\xF3 un estudio de replicaci\xF3n que midi\xF3 el rango rec\xEDproco medio. Los hallazgos destacan la mejora significativa de la calidad de b\xFAsqueda de Jina Reranker, un beneficio que es independiente de las incrustaciones espec\xEDficas utilizadas."])},description1:e=>{const{normalize:a}=e;return a(["BIER (Benchmarking IR) eval\xFAa la efectividad de la recuperaci\xF3n de un modelo, incluida la relevancia y NDCG. Una puntuaci\xF3n BIER m\xE1s alta se correlaciona con coincidencias y clasificaciones de resultados de b\xFAsqueda m\xE1s precisas."])},description2:e=>{const{normalize:a}=e;return a(["A trav\xE9s del punto de referencia LoCo, medimos la comprensi\xF3n de un modelo sobre la coherencia y el contexto local, junto con la clasificaci\xF3n espec\xEDfica de la consulta. Una puntuaci\xF3n m\xE1s alta de LoCo refleja una mejor capacidad para identificar y priorizar informaci\xF3n relevante."])},description3:e=>{const{normalize:a}=e;return a(["El MTEB (Par\xE1metro de referencia de incrustaci\xF3n de texto multiling\xFCe), en general, prueba las capacidades de un modelo en la incrustaci\xF3n de texto, incluida la agrupaci\xF3n, clasificaci\xF3n, recuperaci\xF3n y otras m\xE9tricas. Sin embargo, para nuestra comparaci\xF3n, solo utilizamos las tareas de Reranking del MTEB."])},title0:e=>{const{normalize:a}=e;return a(["LlamaIndex"])},title1:e=>{const{normalize:a}=e;return a(["BEIR"])},title2:e=>{const{normalize:a}=e;return a(["Locomotora"])},title3:e=>{const{normalize:a}=e;return a(["MTEB"])}},benchmark_description:e=>{const{normalize:a}=e;return a(["A modo de comparaci\xF3n, incluimos otros tres rerankers l\xEDderes de BGE (BAAI), BCE (Netease Youdao) y Cohere en el \xEDndice de referencia. Como lo muestran los resultados a continuaci\xF3n, Jina Reranker tiene el puntaje promedio m\xE1s alto en todas las categor\xEDas relevantes para el reranking, lo que lo convierte en un claro l\xEDder entre sus pares."])},benchmark_title:e=>{const{normalize:a}=e;return a(["Punto de referencia de rendimiento"])},description:e=>{const{normalize:a}=e;return a(["Maximice la relevancia de la b\xFAsqueda y la precisi\xF3n de RAG c\xF3modamente"])},description_rich:e=>{const{normalize:a}=e;return a(["Maximice la relevancia de la b\xFAsqueda y la precisi\xF3n de RAG con nuestra API de reclasificaci\xF3n de vanguardia. Comience con 1 mill\xF3n de tokens gratis."])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["El precio de la API Reranker est\xE1 alineado con nuestra estructura de precios de API integrada. Comienza con 1 mill\xF3n de tokens gratis por cada nueva clave API. M\xE1s all\xE1 de los tokens gratuitos, hay diferentes paquetes disponibles para su compra. Para obtener m\xE1s detalles, visite nuestra secci\xF3n de precios."])},answer10:e=>{const{normalize:a}=e;return a(["S\xED, Jina Reranker se puede implementar en AWS. Si necesita una implementaci\xF3n local en un entorno empresarial, puede hacerlo f\xE1cilmente a trav\xE9s de nuestra oferta de AWS Marketplace."])},answer11:e=>{const{normalize:a}=e;return a(["Si est\xE1 interesado en un reranker ajustado y adaptado a datos de dominio espec\xEDficos, comun\xEDquese con nuestro equipo de ventas. Nuestro equipo responder\xE1 a su consulta con prontitud."])},answer3:e=>{const{normalize:a}=e;return a(["La principal diferencia radica en su arquitectura. En cuanto al rendimiento, recomendamos jina-reranker-v1, que ha sido ampliamente probado y comparado con la competencia. Jina-reranker-v1 utiliza una arquitectura de codificador cruzado, mientras que Jina-colbert-v1 se basa en la arquitectura ColBERTv2 pero extiende la longitud del contexto tanto de la consulta como del documento a 8192, logrando un rendimiento a\xFAn mejor que el modelo ColBERTv2 original."])},answer4:e=>{const{normalize:a}=e;return a(["S\xED, jina-colbert-v1 es de c\xF3digo abierto y se puede acceder a \xE9l a trav\xE9s de Huggingface. Sin embargo, jina-reranker-v1 no es de c\xF3digo abierto."])},answer5:e=>{const{normalize:a}=e;return a(["Actualmente, solo admite ingl\xE9s. Sin embargo, algunos usuarios han informado que tambi\xE9n funciona bien con el chino. Esto puede deberse en parte a que jina-reranker-v1-base-en comparte algunos pesos con nuestro modelo de incrustaci\xF3n jina-embeddings-v2-base-zh."])},answer6:e=>{const{normalize:a}=e;return a(["La longitud m\xE1xima del token de consulta es 512. No hay l\xEDmite de token para los documentos."])},answer7:e=>{const{normalize:a}=e;return a(["Puede reclasificar hasta 2048 documentos por consulta."])},answer8:e=>{const{normalize:a}=e;return a(["No existe un concepto de tama\xF1o de lote a diferencia de nuestra API de incrustaci\xF3n. Puede enviar solo una tupla de documento de consulta por solicitud, pero la tupla puede incluir hasta 2048 documentos candidatos."])},answer9:e=>{const{normalize:a}=e;return a(["La latencia var\xEDa de 100 milisegundos a 7 segundos, dependiendo en gran medida de la longitud de los documentos y de la consulta. Por ejemplo, reclasificar 100 documentos de 256 tokens cada uno con una consulta de 64 tokens lleva unos 150 milisegundos. Aumentar la longitud del documento a 4096 tokens aumenta el tiempo a 3,5 segundos. Si la longitud de la consulta aumenta a 512 tokens, el tiempo aumenta a\xFAn m\xE1s a 7 segundos."])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1nto cuesta la API de Reranker?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFPuedo implementar Jina Reranker en AWS?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFOfrecen un reranker ajustado en datos espec\xEDficos del dominio?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la diferencia entre los dos rerankers?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFJina Reranker es de c\xF3digo abierto?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFEl reranker admite varios idiomas?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la extensi\xF3n m\xE1xima para consultas y documentos?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la cantidad m\xE1xima de documentos que puedo reclasificar por consulta?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el tama\xF1o del lote y cu\xE1ntas tuplas de documentos de consulta puedo enviar en una solicitud?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 latencia puedo esperar al reclasificar 100 documentos?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con el reranker"])}},feature_on_premises_description2:e=>{const{normalize:a}=e;return a(["Implemente Jina Reranker en AWS Sagemaker y pronto en Microsoft Azure y Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description3:e=>{const{normalize:a}=e;return a(["Implemente Jina Reranker en AWS Sagemaker y Microsoft Azure y pronto en Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_solid_description:e=>{const{normalize:a}=e;return a(["Desarrollado a partir de nuestra investigaci\xF3n acad\xE9mica de vanguardia y probado rigurosamente con los reclasificadores SOTA para garantizar un rendimiento incomparable."])},how_it_works:e=>{const{normalize:a}=e;return a(["As\xED es como funciona:"])},how_it_works_v1:{description1:e=>{const{normalize:a}=e;return a(["Un sistema de b\xFAsqueda utiliza embeddings/BM25 para encontrar un amplio conjunto de documentos potencialmente relevantes en funci\xF3n de la consulta del usuario."])},description2:e=>{const{normalize:a}=e;return a(["Luego, el reclasificador toma estos resultados y los analiza a un nivel m\xE1s granular, considerando los matices de c\xF3mo los t\xE9rminos de consulta interact\xFAan con el contenido del documento."])},description3:e=>{const{normalize:a}=e;return a(["Reordena los resultados de la b\xFAsqueda, colocando en la parte superior los que considera m\xE1s relevantes, en base a este an\xE1lisis m\xE1s profundo."])},title1:e=>{const{normalize:a}=e;return a(["Recuperaci\xF3n inicial"])},title2:e=>{const{normalize:a}=e;return a(["Reclasificaci\xF3n"])},title3:e=>{const{normalize:a}=e;return a(["Resultados mejorados"])}},improve_performance:e=>{const{normalize:a}=e;return a(["Mejora garantizada sobre la b\xFAsqueda de vectores"])},improve_performance_description:e=>{const{normalize:a}=e;return a(["Nuestras evaluaciones demostraron mejoras en los sistemas de b\xFAsqueda que emplean Jina Reranker con un +8 % en la tasa de aciertos y un +33 % en la clasificaci\xF3n rec\xEDproca media."])},learning1:e=>{const{normalize:a}=e;return a(["Aprendiendo sobre Reranker"])},learning1_description:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es un reranker? \xBFPor qu\xE9 no es suficiente la b\xFAsqueda de vectores o la similitud de cosenos? Aprenda sobre los rerankers desde cero con nuestra gu\xEDa completa."])},read_more_about_benchmark:e=>{const{normalize:a}=e;return a(["Leer m\xE1s sobre el punto de referencia"])},reranker_description:e=>{const{normalize:a}=e;return a(["Pruebe nuestra API de reranker de vanguardia para maximizar la relevancia de su b\xFAsqueda y la precisi\xF3n de RAG. \xA1Empezando gratis!"])},table:{number_token_document:e=>{const{normalize:a}=e;return a(["N\xFAmero de tokens en cada documento"])},number_token_query:e=>{const{normalize:a}=e;return a(["N\xFAmero de tokens en la consulta"])},title:e=>{const{normalize:a}=e;return a(["A continuaci\xF3n se muestra el costo de tiempo de reclasificar una consulta y 100 documentos en milisegundos:"])}},title:e=>{const{normalize:a}=e;return a(["API de reclasificaci\xF3n"])},try_embedding:e=>{const{normalize:a}=e;return a(["Pruebe incorporar API de forma gratuita"])},try_reranker:e=>{const{normalize:a}=e;return a(["Pruebe la API de reranker gratis"])},vs_table:{col0:e=>{const{normalize:a}=e;return a(["reclasificador"])},col0_1:e=>{const{normalize:a}=e;return a(["Precisi\xF3n y relevancia de b\xFAsqueda mejoradas"])},col0_2:e=>{const{normalize:a}=e;return a(["Filtrado inicial y r\xE1pido"])},col0_3:e=>{const{normalize:a}=e;return a(["Recuperaci\xF3n de texto general en consultas de amplio alcance"])},col1:e=>{const{normalize:a}=e;return a(["B\xFAsqueda de vectores"])},col1_1:e=>{const{normalize:a}=e;return a(["Detallado: subdocumento y segmento de consulta"])},col1_2:e=>{const{normalize:a}=e;return a(["Amplio: documentos completos"])},col1_3:e=>{const{normalize:a}=e;return a(["Intermedio: varios segmentos de texto"])},col2:e=>{const{normalize:a}=e;return a(["BM25"])},col2_1:e=>{const{normalize:a}=e;return a(["Alto"])},col2_2:e=>{const{normalize:a}=e;return a(["Medio"])},col2_3:e=>{const{normalize:a}=e;return a(["Bajo"])},col3_1:e=>{const{normalize:a}=e;return a(["No requerido"])},col3_2:e=>{const{normalize:a}=e;return a(["Alto"])},col3_3:e=>{const{normalize:a}=e;return a(["Bajo, utiliza \xEDndice predise\xF1ado"])},col4_1:e=>{const{normalize:a}=e;return a(["Alto"])},col4_2:e=>{const{normalize:a}=e;return a(["Alto"])},col4_3:e=>{const{normalize:a}=e;return a(["No requerido"])},col5_1:e=>{const{normalize:a}=e;return a(["Superior para consultas matizadas"])},col5_2:e=>{const{normalize:a}=e;return a(["Equilibrado entre eficiencia y precisi\xF3n"])},col5_3:e=>{const{normalize:a}=e;return a(["Consistente y confiable para un amplio conjunto de consultas"])},col6_1:e=>{const{normalize:a}=e;return a(["Altamente preciso con una profunda comprensi\xF3n contextual."])},col6_2:e=>{const{normalize:a}=e;return a(["R\xE1pido y eficiente, con precisi\xF3n moderada."])},col6_3:e=>{const{normalize:a}=e;return a(["Altamente escalable, con eficacia establecida"])},col7_1:e=>{const{normalize:a}=e;return a(["Uso intensivo de recursos con implementaci\xF3n compleja"])},col7_2:e=>{const{normalize:a}=e;return a(["Es posible que no capture el contexto o los matices de la consulta profunda"])},col7_3:e=>{const{normalize:a}=e;return a(["Puede tener un rendimiento inferior en b\xFAsquedas muy espec\xEDficas o contextuales"])},header0:e=>{const{normalize:a}=e;return a(["Mejor para"])},header1:e=>{const{normalize:a}=e;return a(["Granularidad"])},header2:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de consulta"])},header3:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de indexaci\xF3n"])},header4:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de entrenamiento"])},header5:e=>{const{normalize:a}=e;return a(["Calidad de b\xFAsqueda"])},header6:e=>{const{normalize:a}=e;return a(["Fortalezas"])},header7:e=>{const{normalize:a}=e;return a(["Debilidades"])},subtitle:e=>{const{normalize:a}=e;return a(["La siguiente tabla proporciona una comparaci\xF3n completa de Reranker, Vector/Inbeddings Search y BM25, destacando sus fortalezas y debilidades en varias categor\xEDas."])},title:e=>{const{normalize:a}=e;return a(["Comparaci\xF3n de Reranker, Vector Search y BM25"])}},what_is:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es un reranker?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a([`El objetivo de un sistema de b\xFAsqueda es encontrar los resultados m\xE1s relevantes de forma r\xE1pida y eficaz. Tradicionalmente, se han utilizado m\xE9todos como BM25 o tf-idf para clasificar los resultados de b\xFAsqueda seg\xFAn la concordancia de palabras clave. En muchas bases de datos vectoriales se han implementado m\xE9todos recientes, como la similitud de coseno basada en incrustaci\xF3n. Estos m\xE9todos son sencillos, pero a veces pueden pasar por alto las sutilezas del lenguaje y, lo m\xE1s importante, la interacci\xF3n entre los documentos y la intenci\xF3n de una consulta.

Aqu\xED es donde brilla el "reranker". Un reranker es un modelo de IA avanzado que toma el conjunto inicial de resultados de una b\xFAsqueda (a menudo proporcionado por una b\xFAsqueda incrustada/basada en tokens) y los reeval\xFAa para garantizar que se alineen m\xE1s estrechamente con la intenci\xF3n del usuario. Mira m\xE1s all\xE1 de la coincidencia superficial de t\xE9rminos para considerar la interacci\xF3n m\xE1s profunda entre la consulta de b\xFAsqueda y el contenido de los documentos.`])},what_is_answer_long_ending:e=>{const{normalize:a}=e;return a(["El reclasificador puede mejorar significativamente la calidad de la b\xFAsqueda porque opera a nivel de subdocumento y subconsulta, lo que significa que analiza las palabras y frases individuales, sus significados y c\xF3mo se relacionan entre s\xED dentro de la consulta y los documentos. Esto da como resultado un conjunto de resultados de b\xFAsqueda m\xE1s preciso y contextualmente relevante."])},what_is_desc:e=>{const{normalize:a}=e;return a(["Un reranker es un modelo de IA que refina los resultados de la b\xFAsqueda a partir de una b\xFAsqueda vectorial o un modelo de recuperaci\xF3n denso. Leer m\xE1s."])}},scenex:{caption_image_desc:e=>{const{normalize:a}=e;return a(["Generar una descripci\xF3n textual de la imagen."])},caption_image_title:e=>{const{normalize:a}=e;return a(["Imagen de t\xEDtulo"])},description:e=>{const{normalize:a}=e;return a(["Explore la narraci\xF3n de im\xE1genes m\xE1s all\xE1 de los p\xEDxeles"])},example1:e=>{const{normalize:a}=e;return a(["Este v\xEDdeo parece ser un metraje de la naturaleza que muestra un encantador conejito blanco y una mariposa en un campo de hierba. Se ve al conejito interactuando con la mariposa de diferentes maneras, mostrando su relaci\xF3n \xFAnica. El entorno natural proporciona un tel\xF3n de fondo pintoresco que realza la belleza de esta escena sencilla pero cautivadora."])},generate_story_desc:e=>{const{normalize:a}=e;return a(["Elabora una historia inspirada en la imagen, que a menudo incluye di\xE1logos o mon\xF3logos de sus personajes."])},generate_story_title:e=>{const{normalize:a}=e;return a(["Generar historia"])},intro1:e=>{const{normalize:a}=e;return a(["Soluci\xF3n l\xEDder de IA para subt\xEDtulos de im\xE1genes y res\xFAmenes de v\xEDdeos"])},json_image_desc:e=>{const{normalize:a}=e;return a(["Genere un formato JSON estructurado a partir de la imagen utilizando un esquema predefinido. Esto permite la extracci\xF3n de datos espec\xEDficos de la imagen."])},json_image_title:e=>{const{normalize:a}=e;return a(["Extraer JSON de la imagen"])},summarize_video_desc:e=>{const{normalize:a}=e;return a(["Genere un resumen conciso del v\xEDdeo, destacando los eventos clave."])},summarize_video_title:e=>{const{normalize:a}=e;return a(["Resumir v\xEDdeo"])},visual_q_a_desc:e=>{const{normalize:a}=e;return a(["Responda una consulta basada en el contenido de la imagen."])},visual_q_a_title:e=>{const{normalize:a}=e;return a(["Preguntas y respuestas visuales"])}},searchbar:{ask_on_current_page:e=>{const{normalize:a}=e;return a(["Pregunte a la p\xE1gina actual sobre..."])},find_solution:e=>{const{normalize:a}=e;return a(["Generar una soluci\xF3n para..."])},hotkey:e=>{const{normalize:a}=e;return a(["Presione la tecla / para buscar en esta p\xE1gina"])},hotkey1:e=>{const{normalize:a}=e;return a(["Prensa"])},hotkey2:e=>{const{normalize:a}=e;return a(["para alternar"])},hotkey_long1:e=>{const{normalize:a}=e;return a(["En cualquier momento, presione"])},hotkey_long3:e=>{const{normalize:a}=e;return a(["para abrir la barra de b\xFAsqueda"])},more_results:e=>{const{normalize:a,interpolate:n,named:r}=e;return a([n(r("_numMore"))," m\xE1s resultados"])},placeholder:e=>{const{normalize:a}=e;return a(["Haga cualquier pregunta en esta p\xE1gina"])},proposing_solution:e=>{const{normalize:a}=e;return a(["Generando respuesta basada en el contenido de la p\xE1gina..."])},required:e=>{const{normalize:a}=e;return a(["Describe tu pregunta con m\xE1s detalles."])},results:e=>{const{normalize:a}=e;return a(["resultados"])}},searchscape:{description:e=>{const{normalize:a}=e;return a(["Navegue, interact\xFAe, perfeccione: vuelva a imaginar el descubrimiento de productos"])}},semantic:{description:e=>{const{normalize:a}=e;return a(["Cerrar la brecha sem\xE1ntica en su infraestructura de b\xFAsqueda existente"])}},share:{"Hacker News":e=>{const{normalize:a}=e;return a(["Noticias de piratas inform\xE1ticos"])},LinkedIn:e=>{const{normalize:a}=e;return a(["LinkedIn"])},facebook:e=>{const{normalize:a}=e;return a(["Facebook"])},reddit:e=>{const{normalize:a}=e;return a(["Reddit"])},rss:e=>{const{normalize:a}=e;return a(["RSS Feed"])},share_btn:e=>{const{normalize:a}=e;return a(["Compartir"])},twitter:e=>{const{normalize:a}=e;return a(["X (Twitter)"])}},spectrum:{embedding_serving:e=>{const{normalize:a}=e;return a(["Incrustar servicio"])},embedding_serving_description:e=>{const{normalize:a}=e;return a(["Entrega de incorporaciones a trav\xE9s de un microservicio robusto y escalable que utiliza tecnolog\xEDas nativas de la nube."])},embedding_tech:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},embedding_tech_description:e=>{const{normalize:a}=e;return a([`En Jina AI, aprovechamos el poder de la tecnolog\xEDa integrada para revolucionar diversas aplicaciones de IA. Esta tecnolog\xEDa sirve como un m\xE9todo unificado para representar y comprimir de manera eficiente varios tipos de datos, garantizando que no se pierda informaci\xF3n cr\xEDtica. Nuestro objetivo es transformar conjuntos de datos complejos en un formato de incrustaci\xF3n universalmente comprensible, lo cual es esencial para un an\xE1lisis de IA preciso y revelador.

Las incrustaciones son fundamentales, especialmente en aplicaciones como el reconocimiento preciso de im\xE1genes y voz, donde ayudan a discernir detalles y matices finos. En el procesamiento del lenguaje natural, las incorporaciones mejoran la comprensi\xF3n del contexto y el sentimiento, lo que lleva a herramientas de traducci\xF3n de idiomas e inteligencia artificial conversacional m\xE1s precisas. Tambi\xE9n son cruciales para desarrollar sistemas de recomendaci\xF3n sofisticados que requieren una comprensi\xF3n profunda de las preferencias del usuario en diferentes formas de contenido, como texto, audio y video.`])},embedding_tuning:e=>{const{normalize:a}=e;return a(["Ajuste de incrustaci\xF3n"])},embedding_tuning_description:e=>{const{normalize:a}=e;return a(["Optimizaci\xF3n de incorporaciones de alta calidad mediante la integraci\xF3n de experiencia en el dominio para mejorar el rendimiento de tareas espec\xEDficas."])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para Empresas"])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},model_serving:e=>{const{normalize:a}=e;return a(["Servicio modelo"])},model_serving_description:e=>{const{normalize:a}=e;return a(["La implementaci\xF3n de modelos ajustados en un entorno de producci\xF3n, que generalmente requiere recursos sustanciales, como el alojamiento de GPU. MLOps, enfatizando el servicio de modelos medianos a grandes de una manera escalable, eficiente y confiable."])},model_tuning:e=>{const{normalize:a}=e;return a(["Ajuste del modelo"])},model_tuning_description:e=>{const{normalize:a}=e;return a(["Tambi\xE9n conocido como ajuste fino, implica ajustar los par\xE1metros de un modelo previamente entrenado en un nuevo conjunto de datos, a menudo espec\xEDfico de una tarea, para mejorar su rendimiento y adaptarlo a una aplicaci\xF3n espec\xEDfica."])},prompt_serving:e=>{const{normalize:a}=e;return a(["Servicio r\xE1pido"])},prompt_serving_description:e=>{const{normalize:a}=e;return a(["Envolviendo y entregando avisos a trav\xE9s de una API, sin alojar modelos pesados. La API llama a un servicio de modelo de lenguaje grande p\xFAblico y maneja la orquestaci\xF3n de entradas y salidas en una cadena de operaciones."])},prompt_tech:e=>{const{normalize:a}=e;return a(["Ingenier\xEDa r\xE1pida y de agentes"])},prompt_tech_description:e=>{const{normalize:a}=e;return a([`En Jina AI, reconocemos que la ingenier\xEDa r\xE1pida es vital para interactuar con grandes modelos de lenguaje (LLM). A medida que estos modelos avanzan, la complejidad de las indicaciones aumenta, abarcando razonamiento y l\xF3gica intrincados. Este avance subraya el crecimiento entrelazado de los LLM y la sofisticaci\xF3n inmediata.

Prevemos un futuro en el que los LLM actuar\xE1n como compiladores y los mensajes se convertir\xE1n en el nuevo lenguaje de programaci\xF3n. Este cambio sugiere que el dominio tecnol\xF3gico futuro puede centrarse m\xE1s en el dominio r\xE1pido que en la codificaci\xF3n tradicional. Nuestro compromiso en Jina AI es liderar esta \xE1rea transformadora, haciendo que la IA avanzada sea accesible y pr\xE1ctica para el uso diario al dominar este "lenguaje" emergente.`])},prompt_tuning:e=>{const{normalize:a}=e;return a(["Sintonizaci\xF3n r\xE1pida"])},prompt_tuning_description:e=>{const{normalize:a}=e;return a(["El proceso de elaborar y refinar las indicaciones de entrada para guiar su salida hacia respuestas espec\xEDficas y deseadas."])}},subscribe_system:{care_most:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es lo que m\xE1s te importa?"])},care_most_options:{accuracy:e=>{const{normalize:a}=e;return a(["Exactitud"])},cost:e=>{const{normalize:a}=e;return a(["Costo"])},other:e=>{const{normalize:a}=e;return a(["Otro"])},scalability:e=>{const{normalize:a}=e;return a(["Escalabilidad"])},speed:e=>{const{normalize:a}=e;return a(["Velocidad"])}},care_most_required:e=>{const{normalize:a}=e;return a(["A la hora de elegir un servicio, \xBFqu\xE9 es lo que m\xE1s te importa?"])},company_size:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el tama\xF1o de su empresa?"])},company_size_required:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos el tama\xF1o de tu empresa nos ayuda a dar un mejor servicio"])},company_url:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el sitio web de su empresa?"])},company_url_required:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos que la web de tu empresa nos ayuda a dar un mejor servicio"])},contactName:e=>{const{normalize:a}=e;return a(["Su nombre"])},contactName_required:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo deber\xEDamos dirigirnos a usted?"])},contactTitle:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es su profesi\xF3n?"])},contactTitle_required:e=>{const{normalize:a}=e;return a(["Su t\xEDtulo de trabajo es requerido"])},contact_us:e=>{const{normalize:a}=e;return a(["Cont\xE1ctenos"])},domain_required:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos tu dominio de trabajo nos ayuda a dar un mejor servicio"])},email:e=>{const{normalize:a}=e;return a(["Correo electr\xF3nico"])},email_contact:e=>{const{normalize:a}=e;return a(["Tu correo electr\xF3nico de contacto"])},email_invalid:e=>{const{normalize:a}=e;return a(["el correo electr\xF3nico es invalido"])},email_required:e=>{const{normalize:a}=e;return a(["correo electronico es requerido"])},fine_tuned_embedding:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 interesado en incorporaciones optimizadas y adaptadas a sus datos y caso de uso? \xA1Vamos a discutir!"])},fine_tuned_reranker:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 interesado en reclasificadores ajustados y adaptados a sus datos y caso de uso? \xA1Vamos a discutir!"])},full_survey:e=>{const{normalize:a}=e;return a(["Responda la encuesta completa y obtenga una respuesta m\xE1s r\xE1pida de nuestro equipo"])},get_new_key:e=>{const{normalize:a}=e;return a(["Obtenga una nueva clave API"])},get_update_blog_posts:e=>{const{normalize:a}=e;return a(["Obtenga las \xFAltimas actualizaciones de las publicaciones del blog."])},get_update_embeddings:e=>{const{normalize:a}=e;return a(["Obtenga las \xFAltimas actualizaciones para las incorporaciones"])},send:e=>{const{normalize:a}=e;return a(["Enviar"])},sign_up:e=>{const{normalize:a}=e;return a(["Inscribirse"])},subscribe:e=>{const{normalize:a}=e;return a(["Suscribir"])},tell_domain:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos tu dominio"])},usage_type:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 tipo de uso te describe mejor?"])},usage_type_options:{other:e=>{const{normalize:a}=e;return a(["Otro"])},poc:e=>{const{normalize:a}=e;return a(["Prueba de concepto"])},production:e=>{const{normalize:a}=e;return a(["Producci\xF3n"])},research:e=>{const{normalize:a}=e;return a(["Investigaci\xF3n"])}},usage_type_required:e=>{const{normalize:a}=e;return a(["D\xEDganos que su tipo de uso nos ayuda a brindar un mejor servicio."])},used_product:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 modelo est\xE1s usando?"])},used_product_required:e=>{const{normalize:a}=e;return a(["Selecciona el modelo que est\xE1s utilizando o te interesa"])}},think_gpt:{description:e=>{const{normalize:a}=e;return a(["T\xE9cnicas de agentes para aumentar su LLM y llevarlo m\xE1s all\xE1 de sus l\xEDmites"])}},vectordb:{description:e=>{const{normalize:a}=e;return a(["Una base de datos vectorial de Python que solo necesita, ni m\xE1s ni menos"])}},zzz:e=>{const{normalize:a}=e;return a(["zzz"])}};export{o as default};
