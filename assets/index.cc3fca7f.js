var r={embedding:{read_api_docs:e=>{const{normalize:i}=e;return i(["Leggi i documenti"])},input:e=>{const{normalize:i}=e;return i(["Richiesta"])},output:e=>{const{normalize:i}=e;return i(["Risposta"])},usage_rerank:e=>{const{normalize:i}=e;return i(["Utilizzo"])},input_length:e=>{const{normalize:i}=e;return i(["Lunghezza immessa"])},output_dimension:e=>{const{normalize:i}=e;return i(["Dimensioni di uscita"])},token_length_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["La lunghezza massima della sequenza del token di input \xE8 ",n(o("_tokenLength"))," per questo modello."])},output_dim_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["La dimensione di output di un vettore di incorporamento da questo modello \xE8 ",n(o("_outputDim")),"."])},size_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Il numero di parametri nel modello \xE8 ",n(o("_size")),", tieni presente che questa non \xE8 la dimensione del file del modello."])},language_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Questo modello supporta al meglio la lingua ",n(o("_lingual")),"."])},opensource:e=>{const{normalize:i}=e;return i(["sistema operativo"])},opensource_explain:e=>{const{normalize:i}=e;return i(["Questo modello \xE8 open source e disponibile su Hugging Face. Fare clic su questo pulsante per visualizzare il modello su Hugging Face."])},input_api_key_error1:e=>{const{normalize:i}=e;return i(["La tua chiave API non esiste"])},wait_for_processing:e=>{const{normalize:i}=e;return i(["La tua richiesta sta per essere eseguita."])},you_can_leave:e=>{const{normalize:i}=e;return i(["Puoi lasciare questa pagina e al termine ti invieremo il collegamento per il download."])},click_upload_btn_above:e=>{const{normalize:i}=e;return i(["Fai clic sul pulsante di caricamento in alto per iniziare."])},start_batch:e=>{const{normalize:i}=e;return i(["Avvia l'incorporamento batch"])},batch_job:e=>{const{normalize:i}=e;return i(["Lavoro in batch"])},bulk_embedding_failed:e=>{const{normalize:i}=e;return i(["Impossibile creare il processo di incorporamento batch"])},upload_file:e=>{const{normalize:i}=e;return i(["Fare clic qui per caricare un file"])},max_file_size:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Dimensione massima consentita: ",n(o("_maxSize")),"."])},write_email_here:e=>{const{normalize:i}=e;return i(["Inserisci l'e-mail in cui desideri ricevere il collegamento per il download al termine."])},upload:e=>{const{normalize:i}=e;return i(["Caricamento"])},download:e=>{const{normalize:i}=e;return i(["Scaricamento"])},batch_upload_hint:e=>{const{normalize:i}=e;return i(["Utilizzeremo la chiave API e il modello seguente per elaborare i documenti."])},bulk:e=>{const{normalize:i}=e;return i(["Incorporamento batch"])},manage_quota1:e=>{const{normalize:i}=e;return i(["Acquista gettoni"])},visualization_example_you_can:e=>{const{normalize:i}=e;return i(["Utilizza la nostra API qui sotto, puoi farlo anche tu!"])},what_are_embedding:e=>{const{normalize:i}=e;return i(["Cosa sono gli incorporamenti?"])},what_are_embedding_answer:e=>{const{normalize:i}=e;return i([`Al centro della moderna elaborazione del linguaggio naturale (PNL) si trova una tecnica trasformativa nota come incorporamenti di testo. Immagina la sfida di insegnare a un computer a cogliere le sfumature dei significati di parole e frasi. I metodi tradizionali, che si basavano su sistemi rigidi e basati su regole, non erano all\u2019altezza perch\xE9 il linguaggio \xE8 troppo complesso e fluido. Inserisci gli incorporamenti di testo: una soluzione potente che traduce il testo in un linguaggio di numeri, in particolare in vettori in uno spazio ad alta dimensione.

Considera le frasi "tempo soleggiato" e "cielo sereno". Per noi dipingono un quadro simile. Attraverso la lente degli incorporamenti, queste frasi vengono trasformate in vettori numerici che risiedono vicini gli uni agli altri in questo spazio multidimensionale, catturandone la parentela semantica. Questa vicinanza nello spazio vettoriale non riguarda solo la somiglianza di parole o frasi; si tratta di comprendere il contesto, il sentimento e persino le sottili sfumature di significato.

Perch\xE9 \xE8 importante questa svolta? Per cominciare, colma il divario tra la ricchezza del linguaggio umano e l\u2019efficienza computazionale degli algoritmi. Gli algoritmi eccellono nell\u2019elaborazione dei numeri, non nell\u2019interpretazione dei testi. Convertendo il testo in vettori, gli incorporamenti consentono a questi algoritmi di "comprendere" ed elaborare il linguaggio in un modo che prima era fuori portata.

Le applicazioni pratiche sono vaste e variegate. Che si tratti di consigliare contenuti che siano in sintonia con i tuoi interessi, di potenziare un'intelligenza artificiale conversazionale che sembri sorprendentemente umana o addirittura di rilevare modelli sottili in grandi volumi di testo, gli incorporamenti sono la chiave. Consentono alle macchine di eseguire attivit\xE0 come l'analisi dei sentimenti, la traduzione linguistica e molto altro, con una comprensione del linguaggio sempre pi\xF9 sfumata e raffinata.`])},visualization_example:e=>{const{normalize:i}=e;return i(["Mappare tutte le frasi di questa sezione in uno spazio vettoriale 3D"])},more_than_two2:e=>{const{normalize:i}=e;return i(["Inserisci pi\xF9 di due documenti, ovvero pi\xF9 di due righe."])},start_embedding:e=>{const{normalize:i}=e;return i(["Indice"])},maximize_tooltip:e=>{const{normalize:i}=e;return i(["Ingrandisci questo pannello"])},visualize_done:e=>{const{normalize:i}=e;return i(["La visualizzazione \xE8 terminata, ora puoi fare clic sul pulsante in alto per aprire il visualizzatore."])},visualize:e=>{const{normalize:i}=e;return i(["Visualizzare"])},open_tensorboard:e=>{const{normalize:i}=e;return i(["Apri visualizzatore"])},generating_visualization:e=>{const{normalize:i}=e;return i(["Generazione della visualizzazione..."])},show_api_key:e=>{const{normalize:i}=e;return i(["Mostra chiave API"])},search:e=>{const{normalize:i}=e;return i(["Ricerca"])},query:e=>{const{normalize:i}=e;return i(["Domanda"])},document:e=>{const{normalize:i}=e;return i(["Documento"])},pairwise_test:e=>{const{normalize:i}=e;return i(["A coppie"])},search_hint:e=>{const{normalize:i}=e;return i(["Digita per effettuare la ricerca tra i documenti elencati di seguito"])},original_documents:e=>{const{normalize:i}=e;return i(["Documenti per l'incorporamento"])},total_documents:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Avanzamento incorporamento: ",n(o("_Processed")),"/",n(o("_Count"))," documenti."])},embedding_done:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_Count"))," documenti incorporati correttamente."])},please_fill_docs_first:e=>{const{normalize:i}=e;return i(["Inserisci alcuni documenti qui sotto prima della ricerca."])},original_documents_hint:e=>{const{normalize:i}=e;return i(["Inserisci qui i tuoi documenti. Ogni nuova riga sar\xE0 considerata un documento separato."])},autostart:e=>{const{normalize:i}=e;return i(["L'incorporamento verr\xE0 avviato automaticamente dopo un breve ritardo"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue spagnolo-inglese con prestazioni SOTA"])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di pi\xF9"])},why_do_you_need:e=>{const{normalize:i}=e;return i(["Scegliere gli incorporamenti giusti"])},why_do_you_need_before:e=>{const{normalize:i}=e;return i(["I nostri modelli di incorporamento sono progettati specificamente per soddisfare diverse applicazioni, combinando linguaggio, codice e rappresentazione multimodale per aprire nuove possibilit\xE0 nelle soluzioni basate sull'intelligenza artificiale."])},why_do_you_need_after:e=>{const{normalize:i}=e;return i(["Sfruttando reti neurali profonde e LLM, i nostri modelli di incorporamento rappresentano dati multimodali in un formato semplificato, migliorando la comprensione automatica, l'archiviazione efficiente e consentendo applicazioni IA avanzate. Questi incorporamenti svolgono un ruolo cruciale nella comprensione dei dati, nel miglioramento del coinvolgimento degli utenti, nel superamento delle barriere linguistiche e nell'ottimizzazione dei processi di sviluppo."])},why_need_1_title:e=>{const{normalize:i}=e;return i(["Incorporamenti per uso generale"])},why_need_1_description:e=>{const{normalize:i}=e;return i(["Il nostro modello di incorporamento del core, basato su JinaBERT, \xE8 costruito per un ampio spettro di applicazioni. Eccelle nella comprensione di testi dettagliati, rendendolo ideale per la ricerca semantica, la classificazione dei contenuti e l'analisi linguistica complessa. La sua versatilit\xE0 non ha eguali e supporta la creazione di strumenti avanzati di analisi del sentiment, riepilogo del testo e sistemi di consigli personalizzati."])},why_need_2_title:e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue"])},why_need_2_description:e=>{const{normalize:i}=e;return i(["I nostri modelli bilingui facilitano la comunicazione tra le lingue, migliorando le piattaforme multilingue, l'assistenza clienti globale e la scoperta di contenuti multilinguistici. Progettati per padroneggiare le traduzioni tedesco-inglese e cinese-inglese, questi modelli semplificano le interazioni e favoriscono la comprensione tra diversi gruppi linguistici."])},why_need_3_title:e=>{const{normalize:i}=e;return i(["Incorporamenti di codice"])},why_need_3_description:e=>{const{normalize:i}=e;return i(["Progettato su misura per gli sviluppatori, il nostro modello di incorporamento del codice ottimizza le attivit\xE0 di codifica come il riepilogo, la generazione di codice e le revisioni automatiche. Aumenta la produttivit\xE0 offrendo approfondimenti sulle strutture del codice e suggerendo miglioramenti, rendendolo essenziale per lo sviluppo di plug-in IDE avanzati, documentazione automatica e strumenti di debug all'avanguardia."])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:i}=e;return i(["Ottimizzato per la ricerca di codici e stringhe di documenti"])},top_up_warning_message:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Alla chiave API corrente sono rimasti token ",n(o("_remainedTokens"))," e verr\xE0 sostituita da una nuova chiave con token ",n(o("_freeTokens")),". Puoi continuare a utilizzare o ricaricare la vecchia chiave se l'hai conservata in modo sicuro. Desideri procedere?"])},top_up_warning_title:e=>{const{normalize:i}=e;return i(["Sostituisci la vecchia chiave API"])},top_up_button:e=>{const{normalize:i}=e;return i(["Ricarica la vecchia chiave"])},get_new_key_button:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave"])},cancel_button:e=>{const{normalize:i}=e;return i(["Annulla"])},"1M_free":e=>{const{normalize:i}=e;return i(["1 milione di token gratuiti"])},"1M_free_description":e=>{const{normalize:i}=e;return i(["Ricevi 1 milione di token gratuiti con ogni nuova chiave API, senza bisogno di carta di credito. Adatto sia per progetti personali che commerciali."])},per_m:e=>{const{normalize:i}=e;return i(["/1 milione di gettoni"])},"500M tokens_intuition1":e=>{const{normalize:i}=e;return i(["10 anni del NY Times ogni giorno, o leggendo Alla ricerca del tempo perduto 300 volte."])},"1B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Circa 10.000 romanzi in media, ovvero rileggere tutti i romanzi di Harry Potter 1000 volte."])},"2_5B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Tutte le parole pronunciate in un giorno da 150.000 persone, ovvero 100 volte pi\xF9 grandi del Codice dei regolamenti federali degli Stati Uniti."])},"5_5B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Tutte le parole mai pubblicate sul NY Times."])},"11B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Un po' pi\xF9 dell'intera Wikipedia inglese."])},"59B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Tutti i tweet del mondo per due giorni."])},"1B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 1 miliardo"])},"2_5B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 2,5 miliardi"])},"5_5B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 5,5 miliardi"])},"11B tokens":e=>{const{normalize:i}=e;return i(["11 miliardi di gettoni"])},"59B tokens":e=>{const{normalize:i}=e;return i(["59 miliardi di gettoni"])},protectData1:e=>{const{normalize:i}=e;return i(["I dati e i documenti della richiesta non vengono utilizzati per i modelli di training."])},protectData2:e=>{const{normalize:i}=e;return i(["Crittografia dei dati in transito (TLS 1.2+) e a riposo (AES-GCM 256)."])},protectData3:e=>{const{normalize:i}=e;return i(["Conforme a SOC 2 e GDPR."])},protect_data:e=>{const{normalize:i}=e;return i(["Proteggi i tuoi dati"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue tedesco-inglese con prestazioni SOTA"])},multilingual:e=>{const{normalize:i}=e;return i(["Supporto multilingue"])},feature_multilingual:e=>{const{normalize:i}=e;return i(["Offre modelli bilingui tedesco-inglese, cinese-inglese, tra gli altri, ideali per applicazioni multilingue."])},feature_solid:e=>{const{normalize:i}=e;return i(["Migliore della classe"])},feature_solid_description1:e=>{const{normalize:i}=e;return i(["Sviluppato dalla nostra ricerca accademica all'avanguardia e rigorosamente testato rispetto ai modelli SOTA per garantire prestazioni senza pari."])},feature_8k1:e=>{const{normalize:i}=e;return i(["8192 lunghezza del token"])},feature_8k_description1:e=>{const{normalize:i}=e;return i(["Pioniere del primo modello di incorporamento open source con una lunghezza di 8192 token, che consente la rappresentazione di un intero capitolo in un unico vettore."])},feature_top_perform1:e=>{const{normalize:i}=e;return i(["Integrazione senza problemi"])},feature_top_perform_description1:e=>{const{normalize:i}=e;return i(["Pienamente compatibile con l'API di OpenAI. Si integra facilmente con oltre 10 database vettoriali e sistemi RAG per un'esperienza utente fluida."])},feature_cheap_v1_description1:e=>{const{normalize:i}=e;return i(["Inizia con prove gratuite e goditi una struttura dei prezzi semplice. Ottieni l'accesso a potenti incorporamenti a solo il 20% del costo di OpenAI."])},poster:e=>{const{normalize:i}=e;return i(["Poster L'evoluzione degli incorporamenti"])},poster_description:e=>{const{normalize:i}=e;return i(["Scopri il poster ideale per il tuo spazio, con infografiche accattivanti o immagini mozzafiato che tracciano l'evoluzione dei modelli di incorporamento del testo dal 1950."])},buy_poster:e=>{const{normalize:i}=e;return i(["Acquista una copia cartacea"])},learn_poster:e=>{const{normalize:i}=e;return i(["Scopri come l'abbiamo realizzato"])},new:e=>{const{normalize:i}=e;return i(["Nuovo modello"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue cinese-inglese con prestazioni SOTA"])},no_data1:e=>{const{normalize:i}=e;return i(["Aggiungi un paio di frasi per calcolare la somiglianza"])},add_pair:e=>{const{normalize:i}=e;return i(["Nuovo"])},delete_pair:e=>{const{normalize:i}=e;return i(["Eliminare"])},debugging:e=>{const{normalize:i}=e;return i(["Test"])},text1:e=>{const{normalize:i}=e;return i(["Sinistra"])},text2:e=>{const{normalize:i}=e;return i(["Giusto"])},edit_text1_text:e=>{const{normalize:i}=e;return i(["Modifica il testo a sinistra"])},edit_text2_text:e=>{const{normalize:i}=e;return i(["Modifica il testo corretto"])},cosine_similarity:e=>{const{normalize:i}=e;return i(["Somiglianza del coseno"])},integrate:e=>{const{normalize:i}=e;return i(["Integrare"])},vector_database_integration2:e=>{const{normalize:i}=e;return i(["La nostra API di incorporamento \xE8 integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps. Per iniziare, copia e incolla la tua chiave API in una qualsiasi delle integrazioni elencate per un avvio rapido e senza intoppi."])},api_integration_short:e=>{const{normalize:i}=e;return i(["La nostra API di incorporamento \xE8 integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps."])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},api_integrations:e=>{const{normalize:i}=e;return i(["Integrazioni API"])},tokens:e=>{const{normalize:i}=e;return i(["Gettoni"])},vector_database_integration1:e=>{const{normalize:i}=e;return i(["Integrazioni"])},vector_database_integration_description:e=>{const{normalize:i}=e;return i(["Integra in modo semplice e senza soluzione di continuit\xE0 l'API Jina Embeddings con qualsiasi database vettoriale, framework di orchestrazione LLM e applicazioni RAG riportati di seguito. I nostri tutorial ti mostreranno come."])},refresh_token_count1:e=>{const{normalize:i}=e;return i(["Aggiorna per ottenere i token disponibili della chiave API corrente"])},feature_on_premises_description2:e=>{const{normalize:i}=e;return i(["Distribuisci i modelli Jina Embeddings in AWS Sagemaker e presto anche in Microsoft Azure e nei servizi cloud di Google, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},faqs:{question21:e=>{const{normalize:i}=e;return i(["Quante richieste API posso effettuare ogni secondo?"])},answer21:e=>{const{normalize:i}=e;return i(["Ogni utente pu\xF2 effettuare fino a 100 richieste al secondo, consentendo di inserire 204.800 frasi di input al secondo."])},answer19:e=>{const{normalize:i}=e;return i(["AWS SageMaker \xE8 ora disponibile. Presto, i pacchetti del modello jina-embeddings-v2 saranno accessibili attraverso tutte le principali piattaforme dei principali fornitori di servizi cloud."])},question1:e=>{const{normalize:i}=e;return i(["Cosa distingue il modello Small dal modello Base?"])},answer1:e=>{const{normalize:i}=e;return i(["Sia il modello Small che quello Base sono realizzati utilizzando la robusta architettura JinaBert, differenziandosi principalmente per la loro scala. Il modello Small comprende 33 milioni di parametri, mentre il modello Base comprende 137 milioni di parametri. Sebbene il modello Base offra prestazioni di incorporamento superiori, comporta un piccolo compromesso in termini di velocit\xE0 effettiva (query al secondo), rendendo il modello Small un'opzione pi\xF9 agile per determinati casi d'uso."])},question2:e=>{const{normalize:i}=e;return i(["Qual \xE8 il numero di query al secondo (QPS) previste per i modelli Small e Base?"])},answer2:e=>{const{normalize:i}=e;return i(["Il QPS dipende dalla lunghezza delle frasi immesse dall'utente e dal modello scelto. Per il modello Base, il QPS pu\xF2 variare da 4 a 100, mentre per il modello Small l'intervallo \xE8 compreso tra 10 e 300."])},question3:e=>{const{normalize:i}=e;return i(["Quali lingue sono supportate dai vostri modelli?"])},answer3:e=>{const{normalize:i}=e;return i(["Al momento i nostri modelli supportano esclusivamente l'inglese. Tuttavia, stiamo espandendo attivamente le nostre capacit\xE0 linguistiche formando ulteriori modelli specifici della lingua. Questi prossimi modelli sono stati progettati per offrire gli stessi vantaggi qualitativi e quantitativi del jina-embeddings-v2."])},question4:e=>{const{normalize:i}=e;return i(["Qual \xE8 il numero massimo di caratteri che posso inserire in una singola frase?"])},answer4:e=>{const{normalize:i}=e;return i([`I nostri modelli sono altamente capaci e consentono una lunghezza di input di 8192 token, che \xE8 significativamente pi\xF9 lunga di quella offerta dalla maggior parte degli altri modelli. Un token pu\xF2 essere corto quanto un carattere o lungo quanto una parola (ad esempio, "a" o "mela"). Il numero di caratteri che puoi inserire in una frase dipende dalla lunghezza e dalla complessit\xE0 delle parole utilizzate. Questa lunghezza di input estesa dei modelli jina-embedddings-v2 consente un'analisi del testo pi\xF9 completa e una maggiore precisione nella comprensione del contesto, specialmente negli scenari che trattano dati testuali estesi.`])},question5:e=>{const{normalize:i}=e;return i(["Qual \xE8 il numero massimo di frasi che posso includere in una singola richiesta?"])},answer5:e=>{const{normalize:i}=e;return i(["Una singola chiamata API pu\xF2 contenere fino a 2048 frasi o testi, consentendo un'analisi approfondita del testo in una volta sola."])},question6:e=>{const{normalize:i}=e;return i(["Su quali basi il modello Base si definisce all'avanguardia?"])},answer6:e=>{const{normalize:i}=e;return i(["La nostra affermazione deriva da valutazioni rigorose condotte nell'ambito del quadro di valutazione open source, Massive Text Embedding Benchmark (MTEB). Il nostro modello Base ha raggiunto una posizione media al 17\xB0 posto in questa classifica, con prestazioni particolarmente impressionanti in attivit\xE0 fondamentali come classificazione, riepilogo e somiglianza del testo. In particolare, si distingue come l'unico modello open source che supporta un'ampia lunghezza del contesto di input del token 8192, un segno di prestazioni all'avanguardia."])},question7:e=>{const{normalize:i}=e;return i(["Come si confrontano i modelli Jina Embeddings con il modello text-embedding-ada002 di OpenAI?"])},answer7:e=>{const{normalize:i}=e;return i(["Secondo la classifica MTEB, il nostro modello Base mantiene la sua posizione rispetto al text-embedding-ada-002 di OpenAI, mostrando prestazioni comparabili in media (classificandosi 17\xB0 contro 15\xB0). Inoltre, il nostro modello Base supera l\u2019offerta di OpenAI in diversi compiti tra cui classificazione, classificazione delle coppie, riclassificazione e riepilogo."])},question8:e=>{const{normalize:i}=e;return i(["Attualmente sto utilizzando text-embedding-ada-002 di OpenAI. Quanto \xE8 fluida la transizione alla tua soluzione?"])},answer8:e=>{const{normalize:i}=e;return i(["La transizione avviene senza sforzo poich\xE9 il nostro endpoint API, https://api.jina.ai/v1/embeddings, si allinea perfettamente con gli schemi JSON di input e output dell'endpoint di OpenAI per il modello text-embeddings-ada-002. Questa compatibilit\xE0 consente agli utenti di integrare il nostro modello come sostituto diretto di text-embeddings-ada-002 quando utilizzano l'endpoint di OpenAI."])},question9:e=>{const{normalize:i}=e;return i(["La fatturazione \xE8 basata sul numero di frasi o richieste?"])},answer9:e=>{const{normalize:i}=e;return i(["Il nostro modello di fatturazione si basa sul numero totale di token elaborati. Gli utenti hanno la flessibilit\xE0 di distribuire questi token su tutte le frasi che desiderano, fornendo una soluzione conveniente e adattabile per le diverse esigenze di analisi del testo."])},question10:e=>{const{normalize:i}=e;return i(["\xC8 disponibile una prova gratuita per i nuovi utenti?"])},answer10:e=>{const{normalize:i}=e;return i([`S\xEC, diamo il benvenuto ai nuovi utenti offrendo una prova gratuita per incorporare fino a 10.000 token utilizzando uno qualsiasi dei nostri modelli. Una chiave API generata automaticamente facilita questa prova. Una volta esaurito il limite di token gratuiti, gli utenti possono acquistare facilmente ricariche per le chiavi API esistenti tramite l'apposita scheda "Ricarica".`])},question11:e=>{const{normalize:i}=e;return i(["Le chiavi API hanno una data di scadenza?"])},answer11:e=>{const{normalize:i}=e;return i(["No, le nostre chiavi API non hanno una data di scadenza."])},question12:e=>{const{normalize:i}=e;return i(["I dati di input dell'utente vengono utilizzati per addestrare i tuoi modelli?"])},answer12:e=>{const{normalize:i}=e;return i(["No, rispettiamo una rigorosa politica sulla privacy e non utilizziamo i dati di input degli utenti per addestrare i nostri modelli."])},question13:e=>{const{normalize:i}=e;return i(["Vengono addebitati i token per le richieste non riuscite?"])},answer13:e=>{const{normalize:i}=e;return i(["No, i token non vengono addebitati in caso di richieste non riuscite."])},question14:e=>{const{normalize:i}=e;return i(["Quali metodi di pagamento sono accettati?"])},answer14:e=>{const{normalize:i}=e;return i(["Collaboriamo con Stripe per facilitare un processo di pagamento fluido. Attraverso questa piattaforma, accettiamo vari metodi di pagamento tra cui carte di credito, Google Pay e PayPal per la tua comodit\xE0."])},question15:e=>{const{normalize:i}=e;return i(["\xC8 disponibile la fatturazione per gli acquisti di token?"])},answer15:e=>{const{normalize:i}=e;return i(["S\xEC, al momento dell'acquisto dei token, verr\xE0 inviata una fattura all'indirizzo email associato al tuo account Stripe."])},question16:e=>{const{normalize:i}=e;return i(["Cosa devo fare se dimentico la mia chiave API?"])},answer16:e=>{const{normalize:i}=e;return i(["Per l'utilizzo della quota gratuita, puoi generare facilmente una nuova chiave API su https://jina.ai/embeddings. Se la tua chiave \xE8 stata ricaricata, contatta il supporto AT jina.ai utilizzando la tua email registrata per ricevere assistenza."])},question17:e=>{const{normalize:i}=e;return i(["Fornite modelli per incorporare immagini o audio?"])},answer17:e=>{const{normalize:i}=e;return i(["Stiamo lavorando attivamente su modelli multimodali che soddisferanno l'incorporamento di testo, immagini e audio. Restate sintonizzati per questi aggiornamenti!"])},question18:e=>{const{normalize:i}=e;return i(["Esiste un'opzione per ottimizzare i modelli Jina Embedding utilizzando dati privati \u200B\u200Bo aziendali?"])},answer18:e=>{const{normalize:i}=e;return i(["Anche se al momento non offriamo servizi di ottimizzazione, ci stiamo preparando a introdurre presto questa funzionalit\xE0. Tieni d'occhio questa funzionalit\xE0!"])},question19:e=>{const{normalize:i}=e;return i(["I tuoi endpoint possono essere ospitati privatamente sui marketplace AWS, Azure o GCP?"])},question20:e=>{const{normalize:i}=e;return i(["Come sono stati addestrati i modelli jina-embeddings-v2?"])},answer20:e=>{const{normalize:i}=e;return i(["Per una comprensione approfondita della nostra metodologia di formazione, dei dati e delle valutazioni, ti invitiamo a esplorare il nostro rapporto tecnico disponibile su arXiv."])}},learning1:e=>{const{normalize:i}=e;return i(["Conoscere gli incorporamenti"])},learning1_description:e=>{const{normalize:i}=e;return i(["Da dove cominciare con gli incorporamenti? Ti abbiamo coperto. Scopri di pi\xF9 sugli incorporamenti con la nostra guida completa."])},length:e=>{const{normalize:i}=e;return i(["Lunghezza del token"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:i}=e;return i(["Ottimizzato per bassa latenza e ingombro di memoria"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:i}=e;return i(["Alla pari con text-embedding-ada002 di OpenAI"])},feature_on_premises_description1:e=>{const{normalize:i}=e;return i(["Distribuisci senza problemi i nostri modelli di incorporamento direttamente nel tuo Virtual Private Cloud (VPC). Attualmente supportato su AWS Sagemaker, con prossime integrazioni per Microsoft Azure e Google Cloud Platform. Per implementazioni Kubernetes personalizzate, contatta il nostro team di vendita per assistenza specializzata."])},feature_on_premises:e=>{const{normalize:i}=e;return i(["La privacy prima di tutto"])},feature_cheap_v1:e=>{const{normalize:i}=e;return i(["5 volte pi\xF9 economico"])},feature_cheap:e=>{const{normalize:i}=e;return i(["20 volte pi\xF9 economico"])},title:e=>{const{normalize:i}=e;return i(["Incorporamento dell'API"])},description:e=>{const{normalize:i,linked:n,type:o}=e;return i([n("landing_page.embedding_desc1",void 0,o)])},faq:e=>{const{normalize:i,linked:n,type:o}=e;return i([n("contattaci_pagina.faq",void 0,o)])},key_enter_placeholder_to_topup:e=>{const{normalize:i}=e;return i(["Inserisci la chiave API che desideri ricaricare"])},key_to_top_up:e=>{const{normalize:i}=e;return i(["Chiave API per la ricarica"])},key_warn_v2:e=>{const{normalize:i}=e;return i(["Ogni nuova chiave ha alcuni token gratuiti da provare. Puoi ricaricare la tua chiave in qualsiasi momento. Assicurati di conservare la chiave API in un luogo sicuro!"])},key_enter_placeholder:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API"])},key_warn:e=>{const{normalize:i}=e;return i(["Assicurati di conservare la chiave API in un luogo sicuro. Altrimenti dovrai generare una nuova chiave"])},refresh_key_tooltip:e=>{const{normalize:i}=e;return i(["Aggiorna e ottieni una nuova chiave API"])},regenerate:e=>{const{normalize:i}=e;return i(["Rigenerare"])},retry:e=>{const{normalize:i}=e;return i(["Riprova"])},refresh:e=>{const{normalize:i}=e;return i(["ricaricare"])},generate_api_key_error:e=>{const{normalize:i}=e;return i(["La generazione della chiave API non \xE8 riuscita."])},key:e=>{const{normalize:i}=e;return i(["Chiave API"])},code:e=>{const{normalize:i}=e;return i(["codice"])},size:e=>{const{normalize:i}=e;return i(["Parametri"])},output_dim:e=>{const{normalize:i}=e;return i(["Dimensioni"])},remaining:e=>{const{normalize:i}=e;return i(["Gettoni disponibili"])},usage_history:e=>{const{normalize:i}=e;return i(["Cronologia dell'utilizzo"])},view_details:e=>{const{normalize:i}=e;return i(["Visualizza dettagli"])},usage_time:e=>{const{normalize:i}=e;return i(["Tempo"])},usage_amount:e=>{const{normalize:i}=e;return i(["Quantit\xE0"])},usage_reason:e=>{const{normalize:i}=e;return i(["Motivo"])},usage_reason_trial:e=>{const{normalize:i}=e;return i(["Prova"])},usage_reason_consume:e=>{const{normalize:i}=e;return i(["Consumare"])},usage_reason_purchase:e=>{const{normalize:i}=e;return i(["Acquistare"])},wait_stripe:e=>{const{normalize:i}=e;return i(["Apertura pagamento Stripe, attendere prego"])},what_is_a_token:e=>{const{normalize:i}=e;return i([`Un token nell'elaborazione del testo \xE8 un'unit\xE0, spesso una parola. Ad esempio, "Jina AI \xE8 fantastica!" diventa cinque gettoni, compresa la punteggiatura.`])},token_example:e=>{const{normalize:i}=e;return i(['Un tweet \xE8 di circa 20 token, un articolo di notizie \xE8 di circa 1000 token e il romanzo di Charles Dickens "A Tale of Two Cities" ha oltre un milione di token.'])},buy_more_quota:e=>{const{normalize:i}=e;return i(["Ricarica questa chiave API selezionando i token di cui hai bisogno"])},"500M tokens":e=>{const{normalize:i}=e;return i(["500 milioni di gettoni"])},per_k:e=>{const{normalize:i}=e;return i(["/ Gettoni da 1K"])}},reranker:{read_more_about_benchmark:e=>{const{normalize:i}=e;return i(["Ulteriori informazioni sul benchmark"])},try_embedding:e=>{const{normalize:i}=e;return i(["Prova a incorporare l'API gratuitamente"])},try_reranker:e=>{const{normalize:i}=e;return i(["Prova gratuitamente l'API reranker"])},benchmark:{title0:e=>{const{normalize:i}=e;return i(["LlamaIndex"])},description0:e=>{const{normalize:i}=e;return i(["LlamaIndex ha valutato varie combinazioni di incorporamenti e reranker per RAG, conducendo uno studio di replica che ha misurato il rango reciproco medio. I risultati evidenziano il significativo miglioramento della qualit\xE0 della ricerca apportato da Jina Reranker, un vantaggio indipendente dagli specifici incorporamenti utilizzati."])},title1:e=>{const{normalize:i}=e;return i(["BEIR"])},title2:e=>{const{normalize:i}=e;return i(["LoCo"])},title3:e=>{const{normalize:i}=e;return i(["MTEB"])},description1:e=>{const{normalize:i}=e;return i(["BIER (Benchmarking IR) valuta l'efficacia del recupero di un modello, inclusi la pertinenza e l'NDCG. Un punteggio BIER pi\xF9 elevato \xE8 correlato a corrispondenze e classifiche dei risultati di ricerca pi\xF9 accurate."])},description2:e=>{const{normalize:i}=e;return i(["Attraverso il benchmark LoCo, abbiamo misurato la comprensione di un modello della coerenza e del contesto locale, insieme alla classificazione specifica della query. Un punteggio LoCo pi\xF9 alto riflette una migliore capacit\xE0 di identificare e dare priorit\xE0 alle informazioni rilevanti."])},description3:e=>{const{normalize:i}=e;return i(["L'MTEB (Multilingual Text Embedding Benchmark), nel complesso, mette alla prova le capacit\xE0 di un modello negli incorporamenti di testo, inclusi clustering, classificazione, recupero e altri parametri. Tuttavia, per il nostro confronto, abbiamo utilizzato solo le attivit\xE0 di riclassificazione di MTEB."])}},vs_table:{subtitle:e=>{const{normalize:i}=e;return i(["La tabella seguente fornisce un confronto completo tra Reranker, ricerca di vettori/incorporamenti e BM25, evidenziandone i punti di forza e di debolezza nelle varie categorie."])},title:e=>{const{normalize:i}=e;return i(["Confronto tra Reranker, Ricerca vettoriale e BM25"])},col0:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},col1:e=>{const{normalize:i}=e;return i(["Ricerca vettoriale"])},col2:e=>{const{normalize:i}=e;return i(["BM25"])},header0:e=>{const{normalize:i}=e;return i(["Ideale per"])},header1:e=>{const{normalize:i}=e;return i(["Granularit\xE0"])},header2:e=>{const{normalize:i}=e;return i(["Complessit\xE0 temporale delle query"])},header3:e=>{const{normalize:i}=e;return i(["Complessit\xE0 temporale dell'indicizzazione"])},header4:e=>{const{normalize:i}=e;return i(["Complessit\xE0 del tempo di allenamento"])},header5:e=>{const{normalize:i}=e;return i(["Ricerca di qualit\xE0"])},header6:e=>{const{normalize:i}=e;return i(["Punti di forza"])},header7:e=>{const{normalize:i}=e;return i(["Punti deboli"])},col0_2:e=>{const{normalize:i}=e;return i(["Filtraggio iniziale rapido"])},col0_1:e=>{const{normalize:i}=e;return i(["Maggiore precisione e pertinenza della ricerca"])},col0_3:e=>{const{normalize:i}=e;return i(["Recupero generale del testo attraverso query ad ampio raggio"])},col1_1:e=>{const{normalize:i}=e;return i(["Dettagliato: documento secondario e segmento di query"])},col1_2:e=>{const{normalize:i}=e;return i(["Ampio: interi documenti"])},col1_3:e=>{const{normalize:i}=e;return i(["Intermedio: vari segmenti di testo"])},col2_1:e=>{const{normalize:i}=e;return i(["Alto"])},col2_2:e=>{const{normalize:i}=e;return i(["medio"])},col2_3:e=>{const{normalize:i}=e;return i(["Basso"])},col3_1:e=>{const{normalize:i}=e;return i(["Non richiesto"])},col3_2:e=>{const{normalize:i}=e;return i(["Alto"])},col3_3:e=>{const{normalize:i}=e;return i(["Basso, utilizza un indice predefinito"])},col4_1:e=>{const{normalize:i}=e;return i(["Alto"])},col4_2:e=>{const{normalize:i}=e;return i(["Alto"])},col4_3:e=>{const{normalize:i}=e;return i(["Non richiesto"])},col5_1:e=>{const{normalize:i}=e;return i(["Superiore per query sfumate"])},col5_2:e=>{const{normalize:i}=e;return i(["In equilibrio tra efficienza e precisione"])},col5_3:e=>{const{normalize:i}=e;return i(["Coerente e affidabile per un'ampia gamma di query"])},col6_1:e=>{const{normalize:i}=e;return i(["Altamente accurato con una profonda comprensione del contesto"])},col6_2:e=>{const{normalize:i}=e;return i(["Veloce ed efficiente, con una precisione moderata"])},col6_3:e=>{const{normalize:i}=e;return i(["Altamente scalabile, con efficacia consolidata"])},col7_1:e=>{const{normalize:i}=e;return i(["Ad alta intensit\xE0 di risorse con implementazione complessa"])},col7_2:e=>{const{normalize:i}=e;return i(["Potrebbe non acquisire il contesto o le sfumature approfondite della query"])},col7_3:e=>{const{normalize:i}=e;return i(["Potrebbe avere prestazioni inferiori per ricerche altamente specifiche o contestuali"])}},benchmark_title:e=>{const{normalize:i}=e;return i(["Benchmark delle prestazioni"])},benchmark_description:e=>{const{normalize:i}=e;return i(["Per fare un confronto, abbiamo incluso nel benchmark altri tre principali reranker di BGE (BAAI), BCE (Netease Youdao) e Cohere. Come mostrato dai risultati di seguito, Jina Reranker detiene il punteggio medio pi\xF9 alto in tutte le categorie rilevanti per il riranking, rendendolo un chiaro leader tra i suoi pari."])},how_it_works:e=>{const{normalize:i}=e;return i(["Ecco come funziona:"])},how_it_works_v1:{title1:e=>{const{normalize:i}=e;return i(["Recupero iniziale"])},description1:e=>{const{normalize:i}=e;return i(["Un sistema di ricerca utilizza embeddings/BM25 per trovare un'ampia serie di documenti potenzialmente rilevanti in base alla query dell'utente."])},title2:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},description2:e=>{const{normalize:i}=e;return i(["Il reranker prende quindi questi risultati e li analizza a un livello pi\xF9 granulare, considerando le sfumature di come i termini della query interagiscono con il contenuto del documento."])},title3:e=>{const{normalize:i}=e;return i(["Risultati migliorati"])},description3:e=>{const{normalize:i}=e;return i(["Riordina i risultati della ricerca, posizionando quelli che ritiene pi\xF9 rilevanti in alto, sulla base di questa analisi pi\xF9 approfondita."])}},what_is_answer_long:e=>{const{normalize:i}=e;return i([`L'obiettivo di un sistema di ricerca \xE8 trovare i risultati pi\xF9 pertinenti in modo rapido ed efficiente. Tradizionalmente, metodi come BM25 o tf-idf sono stati utilizzati per classificare i risultati di ricerca in base alla corrispondenza delle parole chiave. Metodi recenti, come la somiglianza del coseno basata sull'incorporamento, sono stati implementati in molti database vettoriali. Questi metodi sono semplici ma a volte possono non cogliere le sottigliezze del linguaggio e, soprattutto, l'interazione tra i documenti e l'intento di una query.

\xC8 qui che brilla il "reranker". Un reranker \xE8 un modello di intelligenza artificiale avanzato che prende il set iniziale di risultati da una ricerca, spesso forniti da una ricerca basata su incorporamenti/token, e li rivaluta per garantire che siano pi\xF9 allineati con l'intento dell'utente. Si guarda oltre la corrispondenza superficiale dei termini per considerare l'interazione pi\xF9 profonda tra la query di ricerca e il contenuto dei documenti.`])},what_is_answer_long_ending:e=>{const{normalize:i}=e;return i(["Il reranker pu\xF2 migliorare significativamente la qualit\xE0 della ricerca perch\xE9 opera a livello di sottodocumento e sottoquery, il che significa che esamina le singole parole e frasi, i loro significati e il modo in cui si relazionano tra loro all'interno della query e dei documenti. Ci\xF2 si traduce in un insieme di risultati di ricerca pi\xF9 precisi e contestualmente pertinenti."])},what_is:e=>{const{normalize:i}=e;return i(["Cos'\xE8 un reranker?"])},what_is_desc:e=>{const{normalize:i}=e;return i(["Un reranker \xE8 un modello di intelligenza artificiale che affina i risultati della ricerca da una ricerca vettoriale o da un modello di recupero denso. Per saperne di pi\xF9."])},feature_solid_description:e=>{const{normalize:i}=e;return i(["Sviluppato dalla nostra ricerca accademica all'avanguardia e rigorosamente testato rispetto ai reranker SOTA per garantire prestazioni senza precedenti."])},improve_performance:e=>{const{normalize:i}=e;return i(["Miglioramento garantito rispetto alla ricerca vettoriale"])},improve_performance_description:e=>{const{normalize:i}=e;return i(["Le nostre valutazioni hanno dimostrato miglioramenti per i sistemi di ricerca che utilizzano Jina Reranker con +8% nel tasso di successo e +33% nel ranking reciproco medio."])},title:e=>{const{normalize:i}=e;return i(["API di riclassificazione"])},description_rich:e=>{const{normalize:i}=e;return i(["Massimizza la pertinenza della ricerca e l'accuratezza del RAG con la nostra API di riclassificazione all'avanguardia. Inizia con 1 milione di token gratuiti."])},reranker_description:e=>{const{normalize:i}=e;return i(["Prova la nostra API di riclassificazione all'avanguardia per massimizzare la pertinenza della ricerca e la precisione del RAG. A partire gratis!"])},description:e=>{const{normalize:i}=e;return i(["Massimizza facilmente la pertinenza della ricerca e la precisione RAG"])},learning1:e=>{const{normalize:i}=e;return i(["Imparare a conoscere Reranker"])},learning1_description:e=>{const{normalize:i}=e;return i(["Cos'\xE8 un reranker? Perch\xE9 la ricerca vettoriale o la somiglianza del coseno non sono sufficienti? Scopri i reranker da zero con la nostra guida completa."])},feature_on_premises_description2:e=>{const{normalize:i}=e;return i(["Distribuisci Jina Reranker su AWS Sagemaker e presto anche su Microsoft Azure e sui servizi cloud di Google oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])}},landing_page:{learn_more_embeddings:e=>{const{normalize:i}=e;return i(["Ulteriori informazioni sugli incorporamenti"])},learn_more_reranker:e=>{const{normalize:i}=e;return i(["Scopri di pi\xF9 sul riclassificazione"])},try_it_for_free:e=>{const{normalize:i}=e;return i(["Provalo gratuitamente, non \xE8 richiesta la carta di credito"])},enterprise_desc_v3:e=>{const{normalize:i}=e;return i(["Sviluppiamo modelli fondamentali di ricerca all'avanguardia per soluzioni RAG e ricerca aziendale di alta qualit\xE0. Inizia con una prova gratuita!"])},reranker:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},embedding_desc1:e=>{const{normalize:i}=e;return i(["Il primo modello di incorporamento open source al mondo con una lunghezza di 8192 token, corrispondente al text-embedding-ada002 di OpenAI nel Massive Text Embedding Benchmark (MTEB)."])},"on-prem-deploy":e=>{const{normalize:i}=e;return i(["Distribuzione locale"])},also_available_on1:e=>{const{normalize:i}=e;return i(["Disponibile sui marketplace del tuo cloud aziendale"])},new:e=>{const{normalize:i}=e;return i(["Nuovo"])},"on-premises":e=>{const{normalize:i}=e;return i(["In sede"])},finding_faq:e=>{const{normalize:i}=e;return i(["Generazione di una risposta in base alla conoscenza delle domande frequenti riportate di seguito"])},embeddings:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},coming_soon:e=>{const{normalize:i}=e;return i(["Prossimamente"])},try_our_saas:e=>{const{normalize:i}=e;return i(["Prova la nostra soluzione ospitata, un sostituto immediato dell'API di incorporamento di OpenAI."])},also_available_on:e=>{const{normalize:i}=e;return i(["Disponibile anche sui marketplace"])},our_publications:e=>{const{normalize:i}=e;return i(["Le nostre pubblicazioni"])},enterprise_desc_v2:e=>{const{normalize:i}=e;return i(["Prova i nostri modelli di incorporamento di livello mondiale per migliorare i tuoi sistemi di ricerca e RAG. Inizia con una prova gratuita!"])},researcher_desc:e=>{const{normalize:i}=e;return i(["Per capire come i nostri modelli linguistici di grandi dimensioni sono stati addestrati da zero per le attivit\xE0 di incorporamento, consulta le nostre ultime ricerche e pubblicazioni. Incontra il nostro team alle conferenze EMNLP, ACL, SIGIR, NeurIPS e ICML."])},your_portal_to:e=>{const{normalize:i}=e;return i(["Il tuo portale per"])},find_your_portal:e=>{const{normalize:i}=e;return i(["Trova il tuo portale"])},opensource:e=>{const{normalize:i}=e;return i(["Fonte aperta"])},mmstack:e=>{const{normalize:i}=e;return i(["Pila multimodale"])},mmstack_desc:e=>{const{normalize:i}=e;return i(["Lo stack adatto agli sviluppatori, nativo per il cloud e pronto per la produzione per la creazione di applicazioni IA multimodali."])},llm:e=>{const{normalize:i}=e;return i(["Modelli di incorporamento LLM"])},llm_desc:e=>{const{normalize:i}=e;return i(["Forniamo una raccolta di modelli di incorporamento di frasi ad alte prestazioni, che vantano tra 35 milioni e 6 miliardi di parametri. Sono eccellenti per migliorare la ricerca neurale, la riclassificazione, la somiglianza delle frasi, i consigli, ecc. Preparati a migliorare la tua esperienza AI!"])},parameters:e=>{const{normalize:i}=e;return i(["Parametri"])},download_pdf:e=>{const{normalize:i}=e;return i(["Scarica il pdf"])},multimodal_ai:e=>{const{normalize:i}=e;return i(["IA multimodale"])},contact_sales:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},join_community:e=>{const{normalize:i}=e;return i(["Unisciti alla comunit\xE0"])},trusted_by:e=>{const{normalize:i}=e;return i(["AFFIDATO DA"])},newsroom:e=>{const{normalize:i}=e;return i(["Sala stampa"])},read_more:e=>{const{normalize:i}=e;return i(["Per saperne di pi\xF9"])},for:e=>{const{normalize:i}=e;return i(["Per"])},researchers:e=>{const{normalize:i}=e;return i(["Ricercatori"])},developers:e=>{const{normalize:i}=e;return i(["Sviluppatori"])},developers_desc:e=>{const{normalize:i}=e;return i(["Libera tutta la potenza dell'intelligenza artificiale multimodale con tecnologie cloud-native all'avanguardia e un'infrastruttura open source."])},sdk:e=>{const{normalize:i}=e;return i(["SDK"])},sdk_desc:e=>{const{normalize:i}=e;return i(["Vuoi creare applicazioni AIGC di alto livello utilizzando le API PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale? Ti abbiamo coperto! Prova il nostro SDK facile da usare e inizia in pochi minuti."])},sdk_docs:e=>{const{normalize:i}=e;return i(["Leggi i documenti"])},build_python:e=>{const{normalize:i}=e;return i(["Costruisci con Python"])},build_js:e=>{const{normalize:i}=e;return i(["Costruisci con JavaScript"])},enterprise:e=>{const{normalize:i}=e;return i(["Impresa"])},enterprise_desc:e=>{const{normalize:i}=e;return i(["Potenzia il tuo business con soluzioni AI multimodali scalabili, sicure e su misura."])},embedding_paper_title:e=>{const{normalize:i}=e;return i(["Jina Embedding: un nuovo set di modelli di incorporamento di frasi ad alte prestazioni"])},embedding_paper_desc:e=>{const{normalize:i}=e;return i(["Jina Embeddings costituisce un insieme di modelli di incorporamento di frasi ad alte prestazioni abili nel tradurre vari input testuali in rappresentazioni numeriche, catturando cos\xEC l'essenza semantica del testo. Sebbene questi modelli non siano progettati esclusivamente per la generazione di testo, eccellono in applicazioni come il recupero denso e la somiglianza testuale semantica. Questo documento descrive in dettaglio lo sviluppo di Jina Embeddings, a partire dalla creazione di un set di dati pairwise e triplet di alta qualit\xE0. Sottolinea il ruolo cruciale della pulizia dei dati nella preparazione del set di dati, fornisce approfondimenti sul processo di addestramento del modello e si conclude con una valutazione completa delle prestazioni utilizzando il Massive Textual Embedding Benchmark (MTEB)."])},multimodal:e=>{const{normalize:i}=e;return i(["Multimodale"])},starter_kit:e=>{const{normalize:i}=e;return i(["Kit di partenza"])},copy:e=>{const{normalize:i}=e;return i(["copia"])},proposing_solution:e=>{const{normalize:i}=e;return i(["Proporre una soluzione basata sui prodotti Jina AI..."])},mentioned_products:e=>{const{normalize:i}=e;return i(["Prodotti menzionati:"])},copied_to_clipboard:e=>{const{normalize:i}=e;return i(["Copiato negli appunti"])},checkout_our_solution_for_you:e=>{const{normalize:i}=e;return i(["Scopri la nostra soluzione su misura per te"])},ask_how_your_question:e=>{const{normalize:i}=e;return i(["Descrivi il tuo problema"])},how_to:e=>{const{normalize:i}=e;return i(["Come"])},powered_by_promptperfect:e=>{const{normalize:i}=e;return i(['Alimentato dalla funzione "Prompt optimization" e "Prompt as a service" di PromptPerfect'])},error:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Si \xE8 verificato un problema con l'operazione di recupero: ",n(o("messaggio"))])},require_full_question:e=>{const{normalize:i}=e;return i(["Descrivi il tuo problema con maggiori dettagli."])},sdk_example:e=>{const{normalize:i}=e;return i(["Esempio"])},include_experiment:e=>{const{normalize:i}=e;return i(["Include i nostri progetti sperimentali e archiviati nella soluzione."])},power_users:e=>{const{normalize:i}=e;return i(["Utenti esperti"])},power_users_desc:e=>{const{normalize:i}=e;return i(["Sperimenta app AI multimodali potenti e intuitive. Nessuna codifica, nessuna confusione, solo risultati."])}},searchbar:{required:e=>{const{normalize:i}=e;return i(["Descrivi la tua domanda con maggiori dettagli."])},placeholder:e=>{const{normalize:i}=e;return i(["Fai qualsiasi domanda in questa pagina"])},proposing_solution:e=>{const{normalize:i}=e;return i(["Generazione della risposta in base al contenuto della pagina..."])},hotkey:e=>{const{normalize:i}=e;return i(["Premere il tasto / per effettuare la ricerca in questa pagina"])},hotkey1:e=>{const{normalize:i}=e;return i(["Premere"])},hotkey2:e=>{const{normalize:i}=e;return i(["per attivare"])},hotkey_long1:e=>{const{normalize:i}=e;return i(["In qualsiasi momento, premere"])},hotkey_long2:e=>{const{normalize:i}=e;return i(["per eseguire la ricerca nella pagina corrente"])}},about_us_page:{download_logo:e=>{const{normalize:i}=e;return i(["Scarica loghi"])},download_jina_logo:e=>{const{normalize:i}=e;return i(["Scarica il logo Jina AI"])},download_jina_logo_desc:e=>{const{normalize:i}=e;return i(["Ottieni il logo Jina AI sia in modalit\xE0 chiara che scura, disponibile nei formati PNG e SVG. Questo logo \xE8 un marchio registrato presso l'Ufficio dell'Unione europea per la propriet\xE0 intellettuale (EUIPO)."])},download_docarray_logo:e=>{const{normalize:i}=e;return i(["Scarica il logo DocArray"])},download_docarray_logo_desc:e=>{const{normalize:i}=e;return i(["Accedi al logo DocArray, un progetto open source avviato da Jina AI e contribuito alla Linux Foundation nel dicembre 2022. Disponibile in modalit\xE0 chiara e scura, nei formati PNG e SVG."])},download_brochure1:e=>{const{normalize:i}=e;return i(["Scarica l'opuscolo"])},title:e=>{const{normalize:i}=e;return i(["A proposito di Jina AI"])},brochure_info:e=>{const{normalize:i}=e;return i(["La tua guida alla nostra azienda ti aspetta"])},employees:e=>{const{normalize:i}=e;return i(["Dipendenti"])},founded_in:e=>{const{normalize:i}=e;return i(["Fondato nel"])},stats_3:e=>{const{normalize:i}=e;return i([`Fondata nel 2020 e con sede a Berlino, in Germania, Jina AI \xE8 rapidamente diventata leader nell'intelligenza artificiale multimodale, concentrandosi su tecniche rapide e di incorporamento. Essendo un'azienda radicata nell'UE, la nostra visione e i nostri servizi si estendono a livello mondiale, fornendo ad aziende e sviluppatori piattaforme innovative per sfruttare la potenza dell'intelligenza artificiale per la creazione di valore e il risparmio sui costi.

Il nostro impegno per l'open source e la ricerca aperta ha plasmato la nostra identit\xE0 di azienda di software commerciale open source. Questa dedizione all'innovazione \xE8 sottolineata dalla nostra crescita finanziaria, contrassegnata da un aumento di 38 milioni di dollari nel nostro round di serie A nel novembre 2021. In Jina AI, stiamo colmando il divario tra l'intelligenza artificiale avanzata e le applicazioni pratiche su scala globale.`])},mission_content3:e=>{const{normalize:i}=e;return i(["In Jina AI, la nostra missione \xE8 guidare il progresso dell'intelligenza artificiale multimodale attraverso tecnologie innovative di incorporamento e basate su prompt, concentrandoci specificamente su aree come l'elaborazione del linguaggio naturale, l'analisi di immagini e video e l'interazione intermodale dei dati. Questa specializzazione ci consente di fornire soluzioni uniche che trasformano dati complessi provenienti da pi\xF9 fonti in informazioni fruibili e applicazioni rivoluzionarie."])},understand_our_view:e=>{const{normalize:i}=e;return i(["Comprendi il nostro punto di vista"])},title1:e=>{const{normalize:i}=e;return i(["Inizia"])},title2:e=>{const{normalize:i}=e;return i(["Qui"])},subtitle:e=>{const{normalize:i}=e;return i(["Rivoluzionando la creazione di contenuti attraverso soluzioni generate dall'intelligenza artificiale per sbloccare infinite possibilit\xE0. Plasmare il futuro dei contenuti generati dall'intelligenza artificiale e migliorare la creativit\xE0 umana."])},stats:e=>{const{normalize:i}=e;return i(["Pioniere del futuro dell'IA multimodale"])},founded:e=>{const{normalize:i}=e;return i(["Fondato"])},empower_developers:e=>{const{normalize:i}=e;return i(["Sviluppatori potenziati"])},technologies:e=>{const{normalize:i}=e;return i(["Tecnologie"])},users:e=>{const{normalize:i}=e;return i(["Utenti registrati"])},value:e=>{const{normalize:i}=e;return i(["Il nostro valore"])},value_content:e=>{const{normalize:i}=e;return i([`In Jina AI, crediamo nel potere della tecnologia open source per accelerare l'innovazione, favorire la collaborazione e potenziare le comunit\xE0. Non siamo solo sostenitori: contribuiamo attivamente, investendo in modo significativo nella comunit\xE0 open source.

Dall'essere la forza trainante dietro FastAPI, al nostro continuo supporto per Linux e Python Foundations, siamo appassionati di restituire. Ma non ci fermiamo qui; abbiamo anche reso open source la nostra infrastruttura principale, condividendo la nostra esperienza di IA multimodale con il mondo.

In Jina AI, ci sforziamo di dare l'esempio, utilizzando le nostre risorse per nutrire la comunit\xE0 che ci nutre. \xC8 il nostro modo di dire grazie e garantire un futuro vibrante per le tecnologie da cui tutti dipendiamo. Dopotutto, siamo tutti coinvolti in questo insieme.`])},stats_1:e=>{const{normalize:i}=e;return i(["Fondata nel febbraio 2020, Jina AI \xE8 rapidamente emersa come pioniere globale nella tecnologia AI multimodale. Nell'impressionante lasso di tempo di 20 mesi, abbiamo raccolto con successo 37,5 milioni di dollari, segnando la nostra posizione di forza nel settore dell'IA. La nostra rivoluzionaria tecnologia, open-source su GitHub, ha consentito a oltre 40.000 sviluppatori in tutto il mondo di creare e distribuire senza problemi sofisticate applicazioni multimodali."])},stats_2:e=>{const{normalize:i}=e;return i(["Nel 2023, abbiamo fatto passi da gigante nel far progredire gli strumenti di generazione dell'IA basati sulla tecnologia multimodale. Questa innovazione ha beneficiato di oltre 250.000 utenti in tutto il mondo, soddisfacendo una pletora di requisiti aziendali unici. Dalla facilitazione della crescita aziendale e dal miglioramento dell'efficienza operativa all'ottimizzazione dei costi, Jina AI \xE8 dedicata a consentire alle aziende di eccellere nell'era multimodale."])},investors:e=>{const{normalize:i}=e;return i(["I nostri investitori"])},vision:e=>{const{normalize:i}=e;return i(["La nostra visione"])},vision_content1:e=>{const{normalize:i}=e;return i(["Ispirato dall'intuizione di Yann LeCun che '"])},vision_content2:e=>{const{normalize:i}=e;return i(["Jina AI prevede di aprire la strada al futuro dell'IA come realt\xE0 multimodale. Riconosciamo che gli ecosistemi di machine learning e software esistenti devono affrontare sfide nella gestione dell'IA multimodale. In risposta, ci impegniamo a sviluppare strumenti e piattaforme all'avanguardia che aiutino le aziende e gli sviluppatori a superare queste complessit\xE0. La nostra visione \xE8 quella di svolgere un ruolo cruciale nell'aiutare il mondo a sfruttare il vasto potenziale dell'IA multimodale e rivoluzionare veramente il modo in cui interpretiamo e interagiamo con le informazioni."])},yannlecun_quote:e=>{const{normalize:i}=e;return i(["Un sistema di intelligenza artificiale addestrato solo su parole e frasi non si avviciner\xE0 mai alla comprensione umana."])},our_answer:e=>{const{normalize:i}=e;return i(["Assolutamente, Yann. Ci stiamo lavorando, costruendo ponti verso un futuro di intelligenza artificiale multimodale!"])},mission:e=>{const{normalize:i}=e;return i(["La nostra missione"])},team:e=>{const{normalize:i}=e;return i(["All'interno del Portale di Jina AI"])},team_content:e=>{const{normalize:i}=e;return i(["Da diversi angoli del globo, stiamo co-creando il futuro dell'IA multimodale. I nostri diversi stili di vita e prospettive arricchiscono il nostro lavoro, stimolando la creativit\xE0 e il progresso. All'interno di questo portale, abbracciamo la nostra individualit\xE0, amiamo la nostra libert\xE0 e perseguiamo con passione i nostri sogni. Benvenuti nel portale del futuro dell'IA."])},team_join:e=>{const{normalize:i}=e;return i(["Unisciti a noi"])},office:e=>{const{normalize:i}=e;return i(["I nostri uffici"])},berlin:e=>{const{normalize:i}=e;return i(["Berlino, Germania"])},berlin_address:e=>{const{normalize:i}=e;return i(["Ohlauer Str. 43 (1\xB0 piano), zona A, 10999 Berlino"])},bj:e=>{const{normalize:i}=e;return i(["Pechino, Cina"])},bj_address:e=>{const{normalize:i}=e;return i(["Livello 5, Edificio 6, No.48 Haidian West St. Beijing Haidian, Cina"])},sz:e=>{const{normalize:i}=e;return i(["Shenzen, Cina"])},sz_address:e=>{const{normalize:i}=e;return i(["402, Piano 4, Fu'an Technology Building, Shenzhen Nanshan, Cina"])},awards:e=>{const{normalize:i}=e;return i(["Premi e riconoscimenti"])},fastApiCaption:e=>{const{normalize:i}=e;return i(["Ha contribuito con oltre $ 20.000 dal 2021."])},linuxFoundationCaption:e=>{const{normalize:i}=e;return i(["Versa un contributo annuo di $ 10.000 a partire dal 2022."])},pythonSoftwareFoundationCaption:e=>{const{normalize:i}=e;return i(["Ha fornito una donazione una tantum di $ 10.000 e ha sponsorizzato numerosi eventi PyCon, inclusi quelli in Germania, Italia, Cina e Stati Uniti."])},numfocusCaption:e=>{const{normalize:i}=e;return i(["Dona regolarmente ogni mese a partire dal 2022."])},segmentFaultCaption:e=>{const{normalize:i}=e;return i(["Ha contribuito con una donazione una tantum di $ 6.000."])},otherProjectsCaption:e=>{const{normalize:i}=e;return i(["Donati oltre $ 3.000 tramite Github Sponsorship."])},understand_our_strength:e=>{const{normalize:i}=e;return i(["Comprendi la nostra forza"])},berlin_address2:e=>{const{normalize:i}=e;return i(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berlino, Germania"])},title0:e=>{const{normalize:i}=e;return i(["Il futuro"])},description:e=>{const{normalize:i}=e;return i(["Il futuro inizia qui."])},mission_content1:e=>{const{normalize:i}=e;return i(["Al centro di Jina AI c'\xE8 la nostra missione di essere il portale per l'IA multimodale per una clientela diversificata, dagli utenti esperti e sviluppatori alle imprese. Crediamo profondamente nel potere dell'open source e ci dedichiamo alla creazione di strumenti avanzati e accessibili per la comunit\xE0 dell'IA. Le nostre tecnologie chiave, tra cui il prompt tuning, il prompt-serving, il model-tuning e il model-serving, incarnano il nostro impegno per la democratizzazione dell'accesso all'IA. Attraverso la nostra iniziativa open source, ci sforziamo di promuovere l'innovazione, la collaborazione e la trasparenza, garantendo soluzioni scalabili, efficienti e solide. Jina AI \xE8 pi\xF9 di una semplice azienda; \xE8 una comunit\xE0 dedicata a consentire alle aziende di affrontare le sfide dinamiche dell'era digitale e prosperare nei loro domini."])},approach:e=>{const{normalize:i}=e;return i(["Il nostro approccio"])},approach_content1:e=>{const{normalize:i}=e;return i(["Nel mondo in rapida evoluzione dell'IA, le strategie devono essere agili e lungimiranti. Sebbene la nostra offerta principale rimanga incentrata sulle aziende, il panorama dell'IA \xE8 cambiato in modi che richiedono un ripensamento del nostro approccio all'acquisizione dei clienti. Ecco perch\xE9 introdurre gli utenti esperti come punto di ingresso della nostra canalizzazione non \xE8 solo innovativo, ma cruciale per la nostra crescita sostenuta nel settore aziendale."])},approach_content2:e=>{const{normalize:i}=e;return i(["In Jina AI, la nostra strategia \xE8 quella di essere proattivi piuttosto che reattivi. L'inclusione degli utenti esperti come punto di ingresso della canalizzazione garantisce che non solo catturiamo le attuali tendenze del mercato, ma siamo anche strategicamente pronti per la futura crescita aziendale. Il nostro impegno nei confronti delle imprese rimane incrollabile; tuttavia, il nostro approccio per raggiungerli \xE8 innovativo, robusto e, soprattutto, lungimirante."])},approach_new_paradigm:e=>{const{normalize:i}=e;return i(["Tecnologia basata su prompt: un nuovo paradigma"])},approach_miss_mark:e=>{const{normalize:i}=e;return i(["Perch\xE9 i MLOps tradizionali mancano il bersaglio"])},approach_connect_dots:e=>{const{normalize:i}=e;return i(["Collegare i punti: Power Users alle imprese"])},approach_new_paradigm_description:e=>{const{normalize:i}=e;return i([`Il 2023 ha annunciato un cambiamento significativo: l'ascesa della tecnologia basata sul prompt. Semplificando il processo di sviluppo dell'IA, ha democratizzato l'accesso agli strumenti di intelligenza artificiale. Ora, coloro che non hanno una vasta esperienza di programmazione, definiti "utenti esperti", possono dedicarsi allo sviluppo dell'IA senza le ripide curve di apprendimento associate a strumenti come Pytorch, Docker o Kubernetes.

Facendo un parallelo, questo \xE8 simile all'evoluzione del personal computer. Inizialmente, solo gli esperti di tecnologia gestivano i computer. Ma con l'avvento delle interfacce user-friendly, potrebbe partecipare un pubblico pi\xF9 ampio. Oggi, con la tecnologia basata sul prompt, stiamo assistendo a una democratizzazione simile nell'IA.`])},approach_miss_mark_description:e=>{const{normalize:i}=e;return i(["Sebbene l'afflusso di utenti esperti sia significativo, gli strumenti MLOps tradizionali non sono attrezzati per soddisfare le loro esigenze. Questi strumenti ricordano l'uso di un trattore per spostarsi nelle strade della citt\xE0: sono pesanti e spesso eccessivi. Gli sviluppatori di nuova generazione richiedono strumenti agili e intuitivi che completino il loro rapido ritmo di sviluppo."])},approach_connect_dots_description:e=>{const{normalize:i}=e;return i(["Quindi, perch\xE9 l'attenzione per gli utenti esperti \xE8 essenziale per il nostro modello incentrato sull'azienda? Perch\xE9 si tratta di stabilire relazioni precoci. Rivolgendoci ora agli utenti esperti, stiamo costruendo ponti verso le imprese che influenzeranno in futuro. \xC8 un gioco strategico: un investimento a lungo termine per garantire che la nostra offerta aziendale rimanga al primo posto quando questi utenti esperti salgono a ruoli decisionali all'interno delle organizzazioni."])},mission_content2:e=>{const{normalize:i}=e;return i(["Al centro di Jina AI c'\xE8 la nostra missione di essere il portale dell'intelligenza artificiale multimodale per una clientela diversificata, dagli utenti esperti e dagli sviluppatori alle imprese. Crediamo profondamente nella potenza dell'open source e ci dedichiamo alla creazione di strumenti avanzati e accessibili per la comunit\xE0 AI. Le nostre tecnologie chiave, tra cui prompt-tuning, prompt-serving, embedding-tuning e embedding-serving, incarnano il nostro impegno per la democratizzazione dell'accesso all'intelligenza artificiale. Attraverso la nostra iniziativa open source, ci impegniamo a promuovere l'innovazione, la collaborazione e la trasparenza, garantendo soluzioni scalabili, efficienti e robuste. Jina AI \xE8 pi\xF9 di una semplice azienda; \xE8 una comunit\xE0 dedicata a consentire alle aziende di affrontare le sfide dinamiche dell'era digitale e prosperare nei loro settori."])}},subscribe_system:{contact_us:e=>{const{normalize:i}=e;return i(["Contattaci"])},email_contact:e=>{const{normalize:i}=e;return i(["La tua e-mail di contatto"])},send:e=>{const{normalize:i}=e;return i(["Inviare"])},tell_domain:e=>{const{normalize:i}=e;return i(["Raccontaci il tuo dominio"])},fine_tuned_embedding:e=>{const{normalize:i}=e;return i(["Sei interessato a incorporamenti ottimizzati su misura per i tuoi dati e il tuo caso d'uso? Discutiamone!"])},subscribe:e=>{const{normalize:i}=e;return i(["sottoscrivi"])},email:e=>{const{normalize:i}=e;return i(["E-mail"])},sign_up:e=>{const{normalize:i}=e;return i(["Iscrizione"])},get_update_embeddings:e=>{const{normalize:i}=e;return i(["Ottieni gli ultimi aggiornamenti per gli incorporamenti"])},get_update_blog_posts:e=>{const{normalize:i}=e;return i(["Ricevi gli ultimi aggiornamenti per i post del blog"])},email_required:e=>{const{normalize:i}=e;return i(["L'e-mail \xE8 obbligatoria"])},email_invalid:e=>{const{normalize:i}=e;return i(["L'email non \xE8 valida"])}},powered_by:e=>{const{normalize:i}=e;return i(["Offerto da"])},SEO_TAG_LINE:e=>{const{normalize:i}=e;return i(["Migliori incorporamenti e istruzioni perfette"])},PRODUCT_DESCRIPTION:e=>{const{normalize:i}=e;return i(["Jina AI fornisce API di incorporamento e ottimizzatore di prompt di prima qualit\xE0, facilitando lo sviluppo di applicazioni AI multimodali."])},news_page:{news_not_found:e=>{const{normalize:i}=e;return i(["Articolo non trovato"])},redirect_to_news:e=>{const{normalize:i}=e;return i(["Reindirizzamento alla redazione tra 5 secondi..."])},back_to_newsroom:e=>{const{normalize:i}=e;return i(["Torniamo alla redazione"])},categories:e=>{const{normalize:i}=e;return i(["Categorie"])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di pi\xF9"])},in_this_article:e=>{const{normalize:i}=e;return i(["In questo articolo"])}},project_status:{llm1:e=>{const{normalize:i}=e;return i(["LLMOps"])},rag1:e=>{const{normalize:i}=e;return i(["STRACCIO"])},vector_store:e=>{const{normalize:i}=e;return i(["Negozio di vettore"])},graduated:e=>{const{normalize:i}=e;return i(["Laureato"])},incubating:e=>{const{normalize:i}=e;return i(["Incubazione"])},sandbox:e=>{const{normalize:i}=e;return i(["Sabbiera"])},archived:e=>{const{normalize:i}=e;return i(["Archiviato"])},kubernetes:e=>{const{normalize:i}=e;return i(["Kubernetes"])},cloud_native:e=>{const{normalize:i}=e;return i(["Nativo del cloud"])},prompt_tuning:e=>{const{normalize:i}=e;return i(["Sintonizzazione rapida"])},model_serving:e=>{const{normalize:i}=e;return i(["Modello che serve"])},model_tuning:e=>{const{normalize:i}=e;return i(["Messa a punto del modello"])},prompt_serving:e=>{const{normalize:i}=e;return i(["Servizio rapido"])},core:e=>{const{normalize:i}=e;return i(["Nucleo"])},small_size_model:e=>{const{normalize:i}=e;return i(["Modello di piccole dimensioni"])},large_size_model:e=>{const{normalize:i}=e;return i(["Modello di grandi dimensioni"])},mid_size_model:e=>{const{normalize:i}=e;return i(["Modello di taglia media"])},orchestration:e=>{const{normalize:i}=e;return i(["Orchestrazione"])},linux_foundation:e=>{const{normalize:i}=e;return i(["Fondazione Linux"])},vector_database:e=>{const{normalize:i}=e;return i(["Banca dati vettoriale"])},data_structure:e=>{const{normalize:i}=e;return i(["Struttura dati"])},embedding_serving:e=>{const{normalize:i}=e;return i(["Incorporamento della pubblicazione"])},embedding_tuning:e=>{const{normalize:i}=e;return i(["Incorporamento dell'ottimizzazione"])}},open_day:{motivation_to_attend_v2:e=>{const{normalize:i}=e;return i(["Perch\xE9 sei interessato al nostro Open Day?"])},motivation_placeholder_v2:e=>{const{normalize:i}=e;return i(["Condividere le tue motivazioni ci aiuter\xE0 a migliorare la tua esperienza."])},organization_website:e=>{const{normalize:i}=e;return i(["Sito web dell'organizzazione"])},organization_website_placeholder:e=>{const{normalize:i}=e;return i(["URL della home page o del profilo LinkedIn della tua organizzazione"])},preferred_products:e=>{const{normalize:i}=e;return i(["A quali prodotti sei interessato?"])},title:e=>{const{normalize:i}=e;return i(["Giornata delle porte aperte"])},organization:e=>{const{normalize:i}=e;return i(["Organizzazione"])},group_size:e=>{const{normalize:i}=e;return i(["Numero stimato di visitatori"])},preferred_date:e=>{const{normalize:i}=e;return i(["Data preferita"])},preferred_language:e=>{const{normalize:i}=e;return i(["Lingua preferita del tour"])},subtitle:e=>{const{normalize:i}=e;return i(["Uno sguardo al futuro dell'IA multimodale"])},introduction:e=>{const{normalize:i}=e;return i(["Jina AI \xE8 lieta di aprire le nostre porte a entit\xE0 e organizzazioni stimate interessate al progresso e al futuro dell'Intelligenza Artificiale. Estendiamo questa opportunit\xE0 esclusiva per coloro che operano in politica, ONG, NPO e settori di investimento per ottenere una visione dall'interno delle nostre operazioni e visioni qui presso la nostra sede di Berlino."])},vision_title:e=>{const{normalize:i}=e;return i(["La nostra visione per il futuro"])},vision:e=>{const{normalize:i}=e;return i(["Unisciti a noi per una panoramica completa del panorama dell'IA come lo vediamo noi. La nostra discussione si concentrer\xE0 sul potenziale dei modelli linguistici di grandi dimensioni, dell'IA multimodale e dell'impatto della tecnologia open source nel plasmare il futuro dell'innovazione globale."])},experience:e=>{const{normalize:i}=e;return i(["Abbiamo organizzato un coinvolgente tour di tre ore per i nostri ospiti, disponibile in tedesco, inglese, francese, spagnolo, cinese e russo. Il tour copre uno sguardo approfondito ai nostri progressi nell'IA multimodale, la nostra prospettiva sul panorama dell'IA, seguito da un esame dettagliato di progetti specifici. Concluderemo con una discussione di gruppo per facilitare lo scambio di idee e approfondimenti. Su richiesta \xE8 disponibile anche un'opzione per il pranzo."])},experience_title:e=>{const{normalize:i}=e;return i(["Il viaggio di un insider"])},impact_title:e=>{const{normalize:i}=e;return i(["Impatto e influenza"])},impact:e=>{const{normalize:i}=e;return i(["Scopri come i nostri contributi alla comunit\xE0 open source e il nostro lavoro nella tecnologia IA multimodale stanno facendo di Jina AI un attore influente nell'innovazione IA. Miriamo a svolgere un ruolo significativo nei processi decisionali, assicurandoci che il progresso della tecnologia AI sia vantaggioso per tutti."])},engage_title:e=>{const{normalize:i}=e;return i(["Interagisci con noi"])},engage:e=>{const{normalize:i}=e;return i(["Incoraggiamo vivamente un dialogo interattivo durante tutta la giornata. Lo scambio di pensieri e prospettive \xE8 inestimabile per noi. Le potenziali collaborazioni derivanti da queste discussioni potrebbero contribuire in modo significativo a un futuro pi\xF9 integrato e innovativo."])},tutor_title:e=>{const{normalize:i}=e;return i(["Un'esclusiva immersione profonda in"])},tutor_subtitle:e=>{const{normalize:i}=e;return i(["Un tour di tre ore meticolosamente curato, che ti avvicina al cuore del lavoro rivoluzionario di Jina AI nella tecnologia AI multimodale."])},one_hour:e=>{const{normalize:i}=e;return i(["1 ora"])},description:e=>{const{normalize:i}=e;return i(["Un'opportunit\xE0 esclusiva per ottenere una visione dall'interno di Jina AI."])},motivation_min_length_v1:e=>{const{normalize:i}=e;return i(["Si prega di fornire una motivazione pi\xF9 dettagliata."])}},contact_us_page:{subtitle2:e=>{const{normalize:i}=e;return i(["Esplora Jina AI, l'avanguardia dell'IA multimodale. Eccelliamo nell'incorporamento e nell'immediatezza delle tecnologie, utilizzando soluzioni native del cloud come Kubernetes per sistemi robusti e scalabili. Specializzati in modelli linguistici di grandi dimensioni e nell'elaborazione dei media, offriamo strategie aziendali innovative e pronte per il futuro con la nostra competenza avanzata in materia di intelligenza artificiale."])},company_website:e=>{const{normalize:i}=e;return i(["Sito web aziendale"])},company_website_placeholder:e=>{const{normalize:i}=e;return i(["URL della home page o del profilo LinkedIn della tua azienda"])},invalid_url:e=>{const{normalize:i}=e;return i(["L'URL non \xE8 valido"])},invalid_email:e=>{const{normalize:i}=e;return i(["L'email non \xE8 valida"])},preferred_products:e=>{const{normalize:i}=e;return i(["A quali prodotti sei interessato?"])},title:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},impact_snapshots:e=>{const{normalize:i}=e;return i(["Istantanee di impatto"])},subtitle:e=>{const{normalize:i}=e;return i(["Jina AI, leader nell'IA multimodale, eccelle nell'ottimizzazione dei modelli, nel servizio dei modelli, nella messa a punto rapida e nel servizio rapido. Sfruttando le tecnologie native del cloud come Kubernetes e le architetture serverless, forniamo soluzioni robuste, scalabili e pronte per la produzione. Con esperienza in modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione audio, ricerca neurale e arte generativa, forniamo strategie innovative e a prova di futuro per elevare la tua attivit\xE0."])},trusted_by:e=>{const{normalize:i}=e;return i(["Scelto da"])},work_email:e=>{const{normalize:i}=e;return i(["E-mail di lavoro"])},country:e=>{const{normalize:i}=e;return i(["Paese"])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},company_size:e=>{const{normalize:i}=e;return i(["Dimensione aziendale"])},department:e=>{const{normalize:i}=e;return i(["Dipartimento"])},role:e=>{const{normalize:i}=e;return i(["Ruolo"])},field_required:e=>{const{normalize:i}=e;return i(["Il campo \xE8 obbligatiorio"])},anything_else:e=>{const{normalize:i}=e;return i(["Raccontaci di pi\xF9 sul tuo progetto"])},agreement:e=>{const{normalize:i}=e;return i(["Inviando, confermi di accettare il trattamento dei tuoi dati personali da parte di Jina AI come descritto nell'"])},private_statement:e=>{const{normalize:i}=e;return i(["Informativa sulla Privacy"])},submit:e=>{const{normalize:i}=e;return i(["Invia"])},submit_success:e=>{const{normalize:i}=e;return i(["Grazie per la vostra presentazione. Vi risponderemo al pi\xF9 presto."])},submit_failed:e=>{const{normalize:i}=e;return i(["Invio non riuscito. Per favore riprova pi\xF9 tardi."])},faq:e=>{const{normalize:i}=e;return i(["FAQ"])},description:e=>{const{normalize:i}=e;return i(["Fai crescere la tua attivit\xE0 con Jina AI."])},name:e=>{const{normalize:i}=e;return i(["Nome"])},invalid_date_format:e=>{const{normalize:i}=e;return i(["Formato data non valido. Utilizza il formato GG-MM-AAAA."])},invalid_number:e=>{const{normalize:i}=e;return i(["Numero non valido. Si prega di inserire di nuovo"])},subtitle1:e=>{const{normalize:i}=e;return i(["Jina AI, leader nell'intelligenza artificiale multimodale, eccelle nell'ottimizzazione dell'incorporamento, dell'incorporamento, dell'ottimizzazione e del servizio tempestivo. Sfruttando tecnologie native del cloud come Kubernetes e architetture serverless, forniamo soluzioni robuste, scalabili e pronte per la produzione. Con esperienza in modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione dell'audio, ricerca neurale e intelligenza artificiale generativa, forniamo strategie innovative e a prova di futuro per far crescere il tuo business."])}},share:{share_btn:e=>{const{normalize:i}=e;return i(["Condividere"])},"Hacker News":e=>{const{normalize:i}=e;return i(["Notizie sugli hacker"])},LinkedIn:e=>{const{normalize:i}=e;return i(["LinkedIn"])},reddit:e=>{const{normalize:i}=e;return i(["Reddit"])},twitter:e=>{const{normalize:i}=e;return i(["X (Twitter)"])},facebook:e=>{const{normalize:i}=e;return i(["Facebook"])},rss:e=>{const{normalize:i}=e;return i(["RSS Feed"])}},blog_tags:{releases:e=>{const{normalize:i}=e;return i(["Aggiornamenti software"])},press:e=>{const{normalize:i}=e;return i(["comunicato stampa"])},featured:e=>{const{normalize:i}=e;return i(["In primo piano"])},"tech-blog":e=>{const{normalize:i}=e;return i(["Blog tecnico"])},all:e=>{const{normalize:i}=e;return i(["Tutto"])},events:e=>{const{normalize:i}=e;return i(["Eventi"])},insights:e=>{const{normalize:i}=e;return i(["Approfondimenti"])},"knowledge-base":e=>{const{normalize:i}=e;return i(["Base di conoscenza"])}},spectrum:{prompt_tech:e=>{const{normalize:i}=e;return i(["Ingegneria dei prompt e degli agenti"])},embedding_tech:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},prompt_tech_description:e=>{const{normalize:i}=e;return i([`In Jina AI, riconosciamo che il prompt engineering \xE8 vitale per interagire con modelli linguistici di grandi dimensioni (LLM). Man mano che questi modelli avanzano, la complessit\xE0 dei suggerimenti aumenta, comprendendo ragionamenti e logiche intricati. Questo progresso sottolinea la crescita intrecciata degli LLM e la rapida sofisticazione.

Prevediamo un futuro in cui gli LLM fungeranno da compilatori, con i prompt che diventeranno il nuovo linguaggio di programmazione. Questo cambiamento suggerisce che la futura competenza tecnologica potrebbe concentrarsi maggiormente sulla padronanza tempestiva rispetto alla codifica tradizionale. Il nostro impegno in Jina AI \xE8 quello di guidare in quest'area di trasformazione, rendendo l'intelligenza artificiale avanzata accessibile e pratica per l'uso quotidiano attraverso la padronanza di questo "linguaggio" emergente.`])},embedding_tech_description:e=>{const{normalize:i}=e;return i([`In Jina AI, sfruttiamo la potenza dell'integrazione della tecnologia per rivoluzionare diverse applicazioni di intelligenza artificiale. Questa tecnologia funge da metodo unificato per rappresentare e comprimere in modo efficiente vari tipi di dati, garantendo l'assenza di perdita di informazioni critiche. Il nostro obiettivo \xE8 trasformare set di dati complessi in un formato di incorporamento universalmente comprensibile, essenziale per un'analisi AI precisa e approfondita.

Gli incorporamenti sono fondamentali, soprattutto in applicazioni come il riconoscimento preciso di immagini e voce, dove aiutano a distinguere dettagli e sfumature a grana fine. Nell'elaborazione del linguaggio naturale, gli incorporamenti migliorano la comprensione del contesto e del sentimento, portando a strumenti di intelligenza artificiale conversazionale e di traduzione linguistica pi\xF9 accurati. Sono inoltre cruciali nello sviluppo di sofisticati sistemi di raccomandazione che richiedono una profonda comprensione delle preferenze degli utenti attraverso diverse forme di contenuto, come testo, audio e video.`])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le Imprese"])},prompt_serving:e=>{const{normalize:i}=e;return i(["Servizio rapido"])},prompt_tuning:e=>{const{normalize:i}=e;return i(["Sintonizzazione rapida"])},model_serving:e=>{const{normalize:i}=e;return i(["Modello che serve"])},model_tuning:e=>{const{normalize:i}=e;return i(["Messa a punto del modello"])},prompt_serving_description:e=>{const{normalize:i}=e;return i(["Wrapping e fornitura di prompt tramite un'API, senza ospitare modelli pesanti. L'API chiama un servizio di modello di linguaggio di grandi dimensioni pubblico e gestisce l'orchestrazione di input e output in una catena di operazioni."])},prompt_tuning_description:e=>{const{normalize:i}=e;return i(["Il processo di creazione e raffinamento dell'input richiede al fine di guidare il suo output verso risposte specifiche e desiderate."])},model_serving_description:e=>{const{normalize:i}=e;return i(["La distribuzione di modelli ottimizzati in un ambiente di produzione, che in genere richiede risorse sostanziali come l'hosting GPU. MLOps, enfatizzando la fornitura di modelli di medie e grandi dimensioni in modo scalabile, efficiente e affidabile."])},model_tuning_description:e=>{const{normalize:i}=e;return i(["Conosciuto anche come fine tuning, comporta la regolazione dei parametri di un modello preaddestrato su un nuovo set di dati, spesso specifico per attivit\xE0, per migliorarne le prestazioni e adattarlo a un'applicazione specifica."])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},embedding_serving:e=>{const{normalize:i}=e;return i(["Incorporamento della pubblicazione"])},embedding_tuning:e=>{const{normalize:i}=e;return i(["Incorporamento dell'ottimizzazione"])},embedding_serving_description:e=>{const{normalize:i}=e;return i(["Fornire incorporamenti tramite un microservizio robusto e scalabile utilizzando tecnologie native del cloud."])},embedding_tuning_description:e=>{const{normalize:i}=e;return i(["Ottimizzazione degli incorporamenti di alta qualit\xE0 integrando le competenze del settore per migliorare le prestazioni specifiche delle attivit\xE0."])}},prompt_perfect:{text_model:e=>{const{normalize:i}=e;return i(["Modelli testuali"])},image_model:e=>{const{normalize:i}=e;return i(["Modelli di immagine"])},intro1:e=>{const{normalize:i}=e;return i(["Lo strumento principale per un'ingegneria tempestiva"])},original_title:e=>{const{normalize:i}=e;return i(["Richiesta originale"])},optimized_title:e=>{const{normalize:i}=e;return i(["Prompt ottimizzato"])},original:e=>{const{normalize:i}=e;return i(["Il tuo ruolo \xE8 quello di essere il mio compagno di brainstorming."])},optimized:e=>{const{normalize:i}=e;return i(["Il tuo compito \xE8 essere il mio compagno di brainstorming e fornire idee e suggerimenti creativi per un determinato argomento o problema. La tua risposta dovrebbe includere idee originali, uniche e pertinenti che potrebbero aiutare a risolvere il problema o esplorare ulteriormente l'argomento in modo interessante. Tieni presente che la tua risposta dovrebbe anche tenere conto di eventuali requisiti o vincoli specifici dell'attivit\xE0."])},description:e=>{const{normalize:i}=e;return i(["Strumento principale per l'ingegneria rapida"])},intro:e=>{const{normalize:i}=e;return i(["Strumento principale per l'ingegneria rapida"])}},scenex:{caption_image_title:e=>{const{normalize:i}=e;return i(["Immagine della didascalia"])},caption_image_desc:e=>{const{normalize:i}=e;return i(["Genera una descrizione testuale dell'immagine."])},json_image_title:e=>{const{normalize:i}=e;return i(["Estrai JSON dall'immagine"])},json_image_desc:e=>{const{normalize:i}=e;return i(["Genera un formato JSON strutturato dall'immagine utilizzando uno schema predefinito. Ci\xF2 consente l'estrazione di dati specifici dall'immagine."])},visual_q_a_title:e=>{const{normalize:i}=e;return i(["Domande e risposte visive"])},visual_q_a_desc:e=>{const{normalize:i}=e;return i(["Rispondi a una domanda in base al contenuto dell'immagine."])},summarize_video_title:e=>{const{normalize:i}=e;return i(["Riepiloga il video"])},summarize_video_desc:e=>{const{normalize:i}=e;return i(["Genera un riepilogo conciso del video, evidenziando gli eventi chiave."])},generate_story_title:e=>{const{normalize:i}=e;return i(["Genera storia"])},generate_story_desc:e=>{const{normalize:i}=e;return i(["Crea una storia ispirata all'immagine, spesso con dialoghi o monologhi dei suoi personaggi."])},example1:e=>{const{normalize:i}=e;return i(["Questo video sembra essere un filmato naturalistico con un affascinante coniglietto bianco e una farfalla in un campo erboso. Il coniglietto viene visto interagire con la farfalla in diversi modi, mostrando la loro relazione unica. L'ambiente naturale offre uno sfondo pittoresco, esaltando la bellezza di questa scena semplice ma accattivante."])},intro1:e=>{const{normalize:i}=e;return i(["Soluzione AI leader per didascalie di immagini e riepiloghi video"])},description:e=>{const{normalize:i}=e;return i(["Esplora la narrazione di immagini oltre i pixel"])}},copy:e=>{const{normalize:i}=e;return i(["copia"])},embeddings:{description:e=>{const{normalize:i}=e;return i(["I nostri incorporamenti di livello mondiale per i tuoi sistemi di ricerca e RAG"])}},header:{power_users_others:e=>{const{normalize:i}=e;return i(["Pi\xF9 strumenti per utenti esperti"])},developers_others:e=>{const{normalize:i}=e;return i(["Altri strumenti per sviluppatori"])},enterprise_others:e=>{const{normalize:i}=e;return i(["Pi\xF9 soluzioni aziendali"])},news:e=>{const{normalize:i}=e;return i(["Notizia"])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le Imprese"])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},about_us:e=>{const{normalize:i}=e;return i(["Chi siamo"])},contact_us:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},jobs:e=>{const{normalize:i}=e;return i(["Unisciti a noi"])},join_discord:e=>{const{normalize:i}=e;return i(["Unisciti alla nostra comunit\xE0 Discord"])},open_day:e=>{const{normalize:i}=e;return i(["Giornata aperta"])},internship1:e=>{const{normalize:i}=e;return i(["Programma di stagista"])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},for_power_users_description:e=>{const{normalize:i}=e;return i(["Utilizza i nostri strumenti multimodali ottimizzati per migliorare la tua produttivit\xE0."])},for_developers_description:e=>{const{normalize:i}=e;return i(["Sperimenta uno stack IA multimodale open source completo progettato per gli sviluppatori."])},for_enterprise_description:e=>{const{normalize:i}=e;return i(["Scopri strategie AI multimodali scalabili su misura per soddisfare le esigenze aziendali."])}},notice:e=>{const{normalize:i}=e;return i(['\u{1F389} Il nostro primo libro, "Neural Search \u2014 From Prototype to Production with Jina" \xE8 ufficialmente uscito oggi!'])},purchase_now:e=>{const{normalize:i}=e;return i(["Acquista adesso"])},copy_to_clipboard_success:e=>{const{normalize:i}=e;return i(["Copiato negli appunti"])},footer:{developers:e=>{const{normalize:i}=e;return i(["Sviluppatori"])},enterprise:e=>{const{normalize:i}=e;return i(["Impresa"])},address_beijing:e=>{const{normalize:i}=e;return i(["Pechino, Cina"])},address_shenzhen:e=>{const{normalize:i}=e;return i(["Shenzen, Cina"])},address_berlin:e=>{const{normalize:i}=e;return i(["Berlino, Germania (sede centrale)"])},offices:e=>{const{normalize:i}=e;return i(["Uffici"])},docs:e=>{const{normalize:i}=e;return i(["Documenti"])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},all_rights_reserved:e=>{const{normalize:i}=e;return i(["Tutti i diritti riservati."])},privacy_policy:e=>{const{normalize:i}=e;return i(["politica sulla riservatezza"])},privacy_settings:e=>{const{normalize:i}=e;return i(["Impostazioni della privacy"])},tc:e=>{const{normalize:i}=e;return i(["Termini e Condizioni"])},power_users:e=>{const{normalize:i}=e;return i(["Utenti esperti"])}},jina_chat:{description:e=>{const{normalize:i}=e;return i(["Pi\xF9 modalit\xE0, memoria pi\xF9 lunga, meno costi"])},example_1:e=>{const{normalize:i}=e;return i(["Chi sei?"])},example_2:e=>{const{normalize:i}=e;return i(["Sono un servizio di chat LLM creato da Jina AI"])}},rationale:{description:e=>{const{normalize:i}=e;return i(["Strumenti decisionali IA all'avanguardia"])},intro:e=>{const{normalize:i}=e;return i(["Guarda i due lati della medaglia, prendi decisioni razionali"])},decision:e=>{const{normalize:i}=e;return i(["Decisione"])}},best_banner:{description:e=>{const{normalize:i}=e;return i(["Dal blog al banner, senza i prompt!"])},example_title:e=>{const{normalize:i}=e;return i(["Le avventure di Alice nel paese delle meraviglie - Capitolo 1"])},example_description:e=>{const{normalize:i}=e;return i([`Alice cominciava a stancarsi molto di stare seduta accanto a sua sorella sulla riva e di non avere niente da fare: una o due volte aveva sbirciato nel libro che sua sorella stava leggendo, ma non conteneva immagini o conversazioni, "e a che serve un libro", pens\xF2 Alice "senza immagini o conversazioni?" Quindi stava valutando tra s\xE9 (come meglio poteva, perch\xE9 la giornata calda la faceva sentire molto assonnata e stupida), se il piacere di fare una catena di margherite sarebbe valsa la pena di alzarsi e raccogliere le margherite, quando all'improvviso un Bianconiglio con gli occhi rosa le corse vicino.`])}},doc_array:{description:e=>{const{normalize:i}=e;return i(["La struttura dei dati per i dati multimodali"])}},jina:{description:e=>{const{normalize:i}=e;return i(["Crea applicazioni IA multimodali nel cloud"])}},finetuner:{description:e=>{const{normalize:i}=e;return i(["Ottimizza gli incorporamenti sui dati specifici del dominio per una migliore qualit\xE0 della ricerca"])},intro:e=>{const{normalize:i}=e;return i(["La tua azienda. I tuoi dati. Il tuo modello"])}},hub:{description:e=>{const{normalize:i}=e;return i(["Condividi e scopri elementi costitutivi per applicazioni IA multimodali"])}},clip_as_service:{description:e=>{const{normalize:i}=e;return i(["Incorpora immagini e frasi in vettori di lunghezza fissa con CLIP"])}},dalle_flow:{description:e=>{const{normalize:i}=e;return i(["Un flusso di lavoro human-in-the-Loop per la creazione di immagini HD dal testo"])}},disco_art:{description:e=>{const{normalize:i}=e;return i(["Crea avvincenti opere d'arte Disco Diffusion in una riga di codice"])}},think_gpt:{description:e=>{const{normalize:i}=e;return i(["Tecniche di agente per aumentare il tuo LLM e spingerlo oltre i suoi limiti"])}},jcloud:{description:e=>{const{normalize:i}=e;return i(["Distribuisci un progetto locale come servizio cloud. Radicalmente facile, senza brutte sorprese."])}},"dev-gpt":{description:e=>{const{normalize:i}=e;return i(["Il tuo team di sviluppo virtuale"])}},langchain_serve:{description:e=>{const{normalize:i}=e;return i(["App Langchain in produzione con Jina e FastAPI"])}},vectordb:{description:e=>{const{normalize:i}=e;return i(["Un database vettoriale Python di cui hai solo bisogno, n\xE9 pi\xF9 n\xE9 meno"])}},open_gpt:{description:e=>{const{normalize:i}=e;return i(["Un cloud-native open source di grandi modelli multimodali al servizio del framework"])}},jerboa:{description:e=>{const{normalize:i}=e;return i(["Un finetuner sperimentale per LLM open source"])}},finetuner_plus:{description:e=>{const{normalize:i}=e;return i(["Potenzia la tua azienda con soluzioni di fine tuning on-premise"])}},inference:{description:e=>{const{normalize:i}=e;return i(["Modelli multimodali all'avanguardia disponibili per l'inferenza"])}},cloud:{description:e=>{const{normalize:i}=e;return i(["Piattaforma di cloud hosting per applicazioni AI multimodali"])}},semantic:{description:e=>{const{normalize:i}=e;return i(["Colmare il divario semantico nella tua infrastruttura di ricerca esistente"])}},searchscape:{description:e=>{const{normalize:i}=e;return i(["Naviga, interagisci, perfeziona: reinventa la scoperta del prodotto"])}},huggingface:{sentence_similarity:e=>{const{normalize:i}=e;return i(["Incorporamento di frasi"])},updated_about:e=>{const{normalize:i}=e;return i(["Aggiornato circa"])}},impact_snapshots:{project1:e=>{const{normalize:i}=e;return i(["Ricerca ad alta precisione abilitata all'interno dei dati mesh 3D utilizzando le informazioni sulla nuvola di punti."])},project2:e=>{const{normalize:i}=e;return i(["Progettato un motore di ricerca basato sui contenuti per cortometraggi di animazione."])},project3:e=>{const{normalize:i}=e;return i(["Miglioramento dei tassi di conversione dell'e-commerce perfezionando i modelli di incorporamento."])},project4:e=>{const{normalize:i}=e;return i(["Messa a punto rapida eseguita per aumentare l'efficienza per una societ\xE0 di consulenza aziendale."])},project5:e=>{const{normalize:i}=e;return i(["Precursore della comprensione delle scene di gioco e dell'annotazione automatica per un'azienda leader nel settore dei giochi."])},project6:e=>{const{normalize:i}=e;return i(["Implementata l'espansione dell'input in tempo reale per un'azienda di chatbot, migliorando l'esperienza dell'utente."])},project7:e=>{const{normalize:i}=e;return i(["Tecnologia legale rivoluzionata consentendo una ricerca efficiente all'interno di lunghi documenti legali."])},project8:e=>{const{normalize:i}=e;return i(["Supporto di un servizio di arte generativa ad alto rendimento per operazioni su larga scala."])},project9:e=>{const{normalize:i}=e;return i(["Eseguito il process mining e la modellazione utilizzando modelli linguistici avanzati."])},project10:e=>{const{normalize:i}=e;return i(["Sfruttata la computer vision per migliorare l'accessibilit\xE0 digitale dei siti web governativi."])},project11:e=>{const{normalize:i}=e;return i(["LLM perfezionato per una societ\xE0 di consulenza per ottimizzare l'analisi dei dati finanziari."])},project12:e=>{const{normalize:i}=e;return i(["Strategie di marketing avanzate perfezionando i modelli di testo in immagine per il trasferimento dello stile."])}},newsroom_page:{title:e=>{const{normalize:i}=e;return i(["Sala stampa"])},top_stories:e=>{const{normalize:i}=e;return i(["Le migliori storie"])},tech_blog:e=>{const{normalize:i}=e;return i(["Blog tecnico"])},news_title:e=>{const{normalize:i}=e;return i(["Cerca tutte le cose: stiamo organizzando un concorso MEME per Jina 2.0"])},news_description:e=>{const{normalize:i}=e;return i(['Per Jina 2.0, abbiamo ascoltato la community. Veramente, profondamente ascoltato. "Quali sono i tuoi punti dolenti?" abbiamo chiesto, aspettando con impazienza un prezioso feedback'])},engineering_group:e=>{const{normalize:i}=e;return i(["Gruppo Ingegneria"])},engineering_group_date:e=>{const{normalize:i}=e;return i(["31 maggio 2021"])},author:e=>{const{normalize:i}=e;return i(["Per autore"])},product:e=>{const{normalize:i}=e;return i(["Per prodotto"])},photos:e=>{const{normalize:i}=e;return i(["Fotografie"])},most_recent_articles:e=>{const{normalize:i}=e;return i(["Articoli pi\xF9 recenti"])},minutes_read:e=>{const{normalize:i}=e;return i(["minuti letti"])},search:e=>{const{normalize:i}=e;return i(["Cerca per titolo"])},description:e=>{const{normalize:i}=e;return i(["Leggi le ultime notizie e gli aggiornamenti da Jina AI."])}},github:{stars:e=>{const{normalize:i}=e;return i(["Stelle"])}},faq:{question1:e=>{const{normalize:i}=e;return i(["In cosa \xE8 specializzata Jina AI?"])},answer1:e=>{const{normalize:i}=e;return i(["Jina AI \xE8 specializzata in tecnologie AI multimodali, tra cui ottimizzazione dei modelli, servizio dei modelli, messa a punto rapida e servizio rapido. Sfruttiamo strumenti avanzati come Kubernetes e architetture serverless per creare soluzioni robuste, scalabili e pronte per la produzione."])},question2:e=>{const{normalize:i}=e;return i(["Con quali tipi di IA funziona Jina AI?"])},answer2:e=>{const{normalize:i}=e;return i(["La nostra esperienza copre un ampio spettro, comprendendo modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione audio, ricerca neurale e arte generativa."])},question3:e=>{const{normalize:i}=e;return i(["Le tue soluzioni sono scalabili e pronte per la produzione?"])},answer3:e=>{const{normalize:i}=e;return i(["S\xEC, le nostre soluzioni sono progettate per essere scalabili e pronte per la produzione. Costruiamo le nostre soluzioni utilizzando tecnologie cloud-native che consentono una scalabilit\xE0 efficiente e prestazioni affidabili negli ambienti di produzione."])},question4:e=>{const{normalize:i}=e;return i(["Quali settori possono trarre vantaggio dalle soluzioni di Jina AI?"])},answer4:e=>{const{normalize:i}=e;return i(["I nostri servizi sono versatili e adattabili, il che li rende adatti a un'ampia gamma di settori, tra cui e-commerce, tecnologia legale, marketing digitale, giochi, assistenza sanitaria, finanza e molti altri."])},question5:e=>{const{normalize:i}=e;return i(["Come si avvia un progetto con Jina AI?"])},answer5:e=>{const{normalize:i}=e;return i(["Puoi metterti in contatto con il nostro team di vendita tramite il modulo di contatto in questa pagina. Ci piacerebbe discutere i requisiti del tuo progetto e come le nostre soluzioni possono aiutare la tua azienda."])},question6:e=>{const{normalize:i}=e;return i(["Quale supporto fornite dopo aver implementato una soluzione?"])},answer6:e=>{const{normalize:i}=e;return i(["Forniamo supporto continuo per garantire il buon funzionamento delle nostre soluzioni. Ci\xF2 include la risoluzione dei problemi, aggiornamenti regolari e miglioramenti in base al tuo feedback e alle tue esigenze."])},question7:e=>{const{normalize:i}=e;return i(["Qual \xE8 la durata tipica di un progetto?"])},answer7:e=>{const{normalize:i}=e;return i(["La durata del progetto varia a seconda della complessit\xE0 e della portata del progetto. Dopo aver compreso le vostre esigenze, possiamo fornire una stima pi\xF9 accurata."])},question8:e=>{const{normalize:i}=e;return i(["In che modo Jina AI protegge i miei dati?"])},answer8:e=>{const{normalize:i}=e;return i(["La sicurezza dei dati \xE8 la nostra massima priorit\xE0. Aderiamo a rigide politiche e normative sulla protezione dei dati per garantire che i tuoi dati siano sicuri e riservati."])},question9:e=>{const{normalize:i}=e;return i(["Qual \xE8 la struttura dei prezzi per i vostri servizi?"])},answer9:e=>{const{normalize:i}=e;return i(["Il prezzo dipende dalla complessit\xE0 e dai requisiti del progetto. Offriamo sia modelli di prezzi basati su progetto che di trattenuta. Si prega di contattare il nostro team di vendita per ulteriori informazioni."])},question10:e=>{const{normalize:i}=e;return i(["Quali sono i termini di licenza per le vostre soluzioni?"])},answer10:e=>{const{normalize:i}=e;return i(["Forniamo diverse opzioni di licenza in base alla natura del progetto e alle esigenze del cliente. I termini dettagliati possono essere discussi con il nostro team di vendita."])},question11:e=>{const{normalize:i}=e;return i(["Qual \xE8 la tua area di servizio?"])},answer11:e=>{const{normalize:i}=e;return i(["Forniamo servizi a livello globale, con la nostra sede centrale a Berlino, in Europa, e uffici aggiuntivi a Pechino e Shenzhen."])},question12:e=>{const{normalize:i}=e;return i(["Offrite supporto in loco?"])},answer12:e=>{const{normalize:i}=e;return i(["S\xEC, offriamo assistenza in loco, in particolare per i clienti che si trovano vicino ai nostri uffici di Berlino, Pechino e Shenzhen. Per altre localit\xE0, ci sforziamo di fornire il miglior supporto remoto possibile e, se necessario, possiamo organizzare il supporto in loco."])}},beta:e=>{const{normalize:i}=e;return i(["Beta"])},open_day_faq:{question1:e=>{const{normalize:i}=e;return i(["Quali lingue offrite per il tour?"])},answer1:e=>{const{normalize:i}=e;return i(["Offriamo tour in tedesco, inglese, francese, spagnolo, cinese e russo."])},question2:e=>{const{normalize:i}=e;return i(["Qual \xE8 la durata del tour?"])},answer2:e=>{const{normalize:i}=e;return i(["Il tour dura in genere circa tre ore."])},question3:e=>{const{normalize:i}=e;return i(["Il pranzo \xE8 previsto?"])},answer3:e=>{const{normalize:i}=e;return i(["Il pranzo \xE8 facoltativo e pu\xF2 essere organizzato su richiesta."])},question4:e=>{const{normalize:i}=e;return i(["Le persone possono iscriversi all'Open Day?"])},answer4:e=>{const{normalize:i}=e;return i(["Il nostro Open Day \xE8 progettato principalmente per gruppi professionali, come politici, ONG, NPO e investitori. Tuttavia, occasionalmente facciamo delle eccezioni in base al profilo dell'individuo."])},question5:e=>{const{normalize:i}=e;return i(["Da quante persone pu\xF2 essere composto un gruppo per l'Open Day?"])},answer5:e=>{const{normalize:i}=e;return i(["Siamo in grado di ospitare una variet\xE0 di dimensioni di gruppo. Indica la dimensione del tuo gruppo nel modulo di registrazione e confermeremo i dettagli con te."])},question6:e=>{const{normalize:i}=e;return i(["Come posso specificare le aree di interesse per il tour?"])},answer6:e=>{const{normalize:i}=e;return i(["C'\xE8 una sezione nel modulo di registrazione dove puoi specificare le tue aree di interesse o eventuali richieste particolari. Faremo del nostro meglio per personalizzare il tour in base alle vostre esigenze."])},question7:e=>{const{normalize:i}=e;return i(["I tour sono disponibili presso i vostri uffici di Pechino o Shenzhen?"])},answer7:e=>{const{normalize:i}=e;return i(["Al momento, offriamo tour solo presso la nostra sede di Berlino situata a Kreuzberg. I nostri uffici di Pechino e Shenzhen non sono attualmente aperti per i tour."])}},print:e=>{const{normalize:i}=e;return i(["Stampa"])},internship_faq:{question1:e=>{const{normalize:i}=e;return i(["Chi pu\xF2 fare domanda per il programma di tirocinio Jina AI?"])},answer1:e=>{const{normalize:i}=e;return i(["Laurea, master e dottorato di ricerca. studenti provenienti da tutto il mondo, con interesse in campi come la ricerca, l'ingegneria, il marketing e le vendite, sono incoraggiati ad applicare. Accogliamo con favore anche stage non tecnici in marketing, vendite, assistenza esecutiva e altro ancora. Cerchiamo persone appassionate pronte a fare da pionieri nell'IA multimodale con noi."])},question2:e=>{const{normalize:i}=e;return i(["Dove si svolger\xE0 il tirocinio?"])},answer2:e=>{const{normalize:i}=e;return i(["Gli stage devono essere svolti in loco presso uno dei nostri uffici, che si trovano a Berlino, Pechino e Shenzhen."])},question3:e=>{const{normalize:i}=e;return i(["Jina AI assiste con le procedure di visto?"])},answer3:e=>{const{normalize:i}=e;return i(["S\xEC, Jina AI offre un'assistenza ragionevole nel processo di visto per i richiedenti selezionati."])},question4:e=>{const{normalize:i}=e;return i(["Jina AI fornisce indennit\xE0 o benefici per gli stagisti?"])},answer4:e=>{const{normalize:i}=e;return i(["S\xEC, Jina AI fornisce una ragionevole copertura del costo della vita per gli stagisti durante il periodo di tirocinio."])},question5:e=>{const{normalize:i}=e;return i(["Posso lavorare alla mia tesi di Master durante lo stage presso Jina AI?"])},answer5:e=>{const{normalize:i}=e;return i(["S\xEC, \xE8 possibile lavorare alla tua tesi di Master durante il tirocinio presso Jina AI, tipicamente applicabile agli studenti delle universit\xE0 tedesche. Tuttavia, \xE8 necessario disporre di una comunicazione preventiva e del consenso del supervisore della propria universit\xE0. Tieni presente che non aiutiamo gli studenti a trovare consulenti."])},question6:e=>{const{normalize:i}=e;return i(["Cosa prevede il processo di candidatura?"])},answer6:e=>{const{normalize:i}=e;return i(["Il processo di candidatura include l'invio del modulo di candidatura, un curriculum, una lettera di presentazione che esprima il tuo interesse e la tua motivazione e qualsiasi link professionale pertinente come GitHub o LinkedIn. Valutiamo i candidati in base alle loro prestazioni durante il colloquio e alle loro prestazioni nella loro universit\xE0."])},question7:e=>{const{normalize:i}=e;return i(["Jina AI fornisce una lettera di raccomandazione dopo lo stage?"])},answer7:e=>{const{normalize:i}=e;return i(["S\xEC, gli stagisti di successo possono ricevere una lettera di raccomandazione alla fine del loro tirocinio, firmata dal nostro CEO."])},question8:e=>{const{normalize:i}=e;return i(["Qual \xE8 la durata del tirocinio?"])},answer8:e=>{const{normalize:i}=e;return i(["La durata dello stage varia in base al ruolo e al progetto. Tuttavia, in genere varia da tre a sei mesi."])},question9:e=>{const{normalize:i}=e;return i(["Posso candidarmi se non ho precedenti esperienze in IA?"])},answer9:e=>{const{normalize:i}=e;return i(["S\xEC, accogliamo candidature di ogni estrazione accademica. Apprezziamo la tua passione e il tuo impegno per imparare tanto quanto l'esperienza precedente."])},question10:e=>{const{normalize:i}=e;return i(["\xC8 uno stage retribuito?"])},answer10:e=>{const{normalize:i}=e;return i(["S\xEC, il nostro programma di tirocinio offre una remunerazione competitiva."])},question11:e=>{const{normalize:i}=e;return i(["Quali opportunit\xE0 avr\xF2 come stagista Jina AI?"])},answer11:e=>{const{normalize:i}=e;return i(["In qualit\xE0 di stagista Jina AI, acquisirai esperienza pratica lavorando su progetti stimolanti, imparerai da esperti del settore, entrerai a far parte di una vivace comunit\xE0 e avrai l'opportunit\xE0 di dare un contributo reale al nostro lavoro pionieristico nell'IA multimodale."])}},internship_page:{title:e=>{const{normalize:i}=e;return i(["Programma di stagista"])},description:e=>{const{normalize:i}=e;return i(["Bando mondiale per studenti: stagista in ricerca, ingegneria, marketing, vendite e altro ancora per aprire la strada all'IA multimodale insieme."])},subtitle:e=>{const{normalize:i}=e;return i(["Il nostro programma di tirocinio a tempo pieno offre un'esperienza lavorativa pratica attraverso progetti di tirocinio ben progettati in una vasta gamma di ambiti."])},subtitle1:e=>{const{normalize:i}=e;return i(["Bando mondiale per studenti: stagista in ricerca, ingegneria, marketing, vendite e altro ancora per aprire la strada all'IA multimodale insieme."])},alumni:e=>{const{normalize:i}=e;return i(["ALUNNI"])},about_internship_program:e=>{const{normalize:i}=e;return i(["Informazioni sul programma di tirocinio"])},about_internship_program_desc1:e=>{const{normalize:i}=e;return i(["Siamo entusiasti di offrire questa opportunit\xE0 unica a persone di talento per entrare a far parte del nostro team dinamico e contribuire a progetti innovativi nel campo dell'Intelligenza Artificiale. Questo stage \xE8 progettato per fornirti preziosa esperienza pratica, tutoraggio ed esposizione a tecnologie all'avanguardia che stanno plasmando il futuro dell'IA."])},about_internship_program_desc2:e=>{const{normalize:i}=e;return i(["In Jina AI, comprendiamo l'importanza di coltivare e sfruttare i giovani talenti. Riconosciamo che i tirocinanti portano sul tavolo nuove prospettive, entusiasmo e creativit\xE0, rinvigorendo il nostro team con nuove idee e approcci. Fornendo stage, miriamo a favorire la crescita dei futuri leader nel settore dell'intelligenza artificiale, offrendo loro un'esperienza del mondo reale in un ambiente stimolante e stimolante."])},who_do_we_look_for:e=>{const{normalize:i}=e;return i(["Chi cerchiamo?"])},who_do_we_look_for_desc:e=>{const{normalize:i}=e;return i(["Apprezziamo la diversit\xE0 e incoraggiamo i candidati con profili e background diversi a partecipare al nostro programma di tirocinio. Le opportunit\xE0 di tirocinio sono offerte in pi\xF9 dipartimenti, tra cui ingegneria, design, gestione del prodotto, gestione delle vendite e dell'account, marketing e gestione della comunit\xE0."])},enthusiastic:e=>{const{normalize:i}=e;return i(["ENTUSIASTA"])},self_motivated:e=>{const{normalize:i}=e;return i(["AUTOMOTIVATO"])},innovative:e=>{const{normalize:i}=e;return i(["INNOVATIVO"])},explore_stories_from_our_interns:e=>{const{normalize:i}=e;return i(["Esplora le storie dei nostri stagisti"])},explore_stories_from_our_interns1:e=>{const{normalize:i}=e;return i(["Lasciati ispirare dai viaggi dei nostri stagisti"])},software_engineer_intern:e=>{const{normalize:i}=e;return i(["Tirocinante Ingegnere informatico"])},alumni_network:e=>{const{normalize:i}=e;return i(["La nostra fiorente rete di ex studenti"])},intern_work1:e=>{const{normalize:i}=e;return i(["Modelli LLM ottimizzati per incorporamenti migliori"])},intern_work2:e=>{const{normalize:i}=e;return i(["Esplorato il potenziale di Retrieval Augmented Generation"])},intern_work3:e=>{const{normalize:i}=e;return i(["Ha pubblicato un articolo sul tema dell'incorporamento di frasi"])},application:e=>{const{normalize:i}=e;return i(["Applicazione"])},submit_application:e=>{const{normalize:i}=e;return i(["Dai il via alla tua avventura con Jina AI"])},application_desc:e=>{const{normalize:i}=e;return i(["Intraprendi un viaggio di trasformazione con Jina AI. Il nostro programma di tirocinio completo invita tutte le menti appassionate che aspirano a plasmare il futuro dell'intelligenza artificiale. Unisciti a noi per fare esperienza nel mondo reale, lavorare su progetti stimolanti e collaborare con alcune delle menti pi\xF9 brillanti del settore dell'IA."])},summer:e=>{const{normalize:i}=e;return i(["Estate"])},autumn:e=>{const{normalize:i}=e;return i(["Autunno"])},winter:e=>{const{normalize:i}=e;return i(["Inverno"])},spring:e=>{const{normalize:i}=e;return i(["Primavera"])},apply:e=>{const{normalize:i}=e;return i(["Applica ora"])},recruiting_and_administrative_intern:e=>{const{normalize:i}=e;return i(["Stagista reclutamento e amministrazione"])},dev_rel_intern:e=>{const{normalize:i}=e;return i(["Stagista nelle relazioni con gli sviluppatori"])},intern_work4:e=>{const{normalize:i}=e;return i(["Infondere continua vitalit\xE0 giovanile nella squadra"])},intern_work5:e=>{const{normalize:i}=e;return i(["Tecniche di quantizzazione benchmark per comprimere LLM"])},intern_work6:e=>{const{normalize:i}=e;return i(["Creazione e promozione di una campagna avvincente per PromptPerfect"])}}};export{r as default};
