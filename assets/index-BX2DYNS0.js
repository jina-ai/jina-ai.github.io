const e="Erstklassige Einbettungen, Reranker, Webcrawler-Scraper, Deepsearch, kleine LMs. Die Such-KI für mehrsprachige und multimodale Daten.",n="Ihre Suchbasis – mit Turbolader.",i={approach:"Unser Vorgehen",approach_connect_dots:"Zusammenhänge: Von Power-Usern zu Unternehmen",approach_connect_dots_description:"Warum ist der Fokus auf Power-User für unser unternehmensorientiertes Modell so wichtig? Weil es darum geht, frühe Beziehungen aufzubauen. Indem wir uns jetzt an Power-User wenden, bauen wir Brücken zu den Unternehmen, die sie in Zukunft beeinflussen werden. Es handelt sich um eine strategische Maßnahme – eine langfristige Investition, um sicherzustellen, dass unser Unternehmensangebot im Vordergrund steht, wenn diese Power-User in Entscheidungsrollen innerhalb von Organisationen aufsteigen.",approach_content1:"In der sich schnell entwickelnden Welt der KI müssen Strategien sowohl flexibel als auch zukunftsorientiert sein. Während sich unser Kernangebot weiterhin auf Unternehmen konzentriert, hat sich die KI-Landschaft in einer Weise verändert, die ein Überdenken unseres Ansatzes zur Kundenakquise erforderlich macht. Aus diesem Grund ist die Einführung von Power-Usern als Einstiegspunkt in unseren Funnel nicht nur innovativ, sondern auch entscheidend für unser nachhaltiges Wachstum im Unternehmenssektor.",approach_content2:"Bei Jina AI besteht unsere Strategie darin, proaktiv statt reaktiv zu sein. Durch die Einbeziehung von Power-Usern als Einstiegspunkt in den Funnel stellen wir sicher, dass wir nicht nur aktuelle Markttrends erfassen, sondern auch strategisch für zukünftiges Unternehmenswachstum gerüstet sind. Unser Engagement für Unternehmen bleibt unerschütterlich; Unser Ansatz zur Erreichung dieser Ziele ist jedoch innovativ, robust und vor allem zukunftsorientiert.",approach_content4:'Jeder möchte eine bessere Suche. Bei Jina AI ermöglichen wir eine bessere Suche, indem wir die <span class="text-primary text-bold">Search Foundation</span> bereitstellen, die aus Embeddings, Rerankers, Reader und Prompt Ops besteht. Diese Komponenten arbeiten zusammen, um die Art und Weise zu revolutionieren, wie wir Daten suchen und verstehen.',approach_miss_mark:"Warum traditionelle MLOps das Ziel verfehlen",approach_miss_mark_description:"Obwohl der Zustrom von Power-Usern beträchtlich ist, sind herkömmliche MLOps-Tools nicht in der Lage, deren Anforderungen zu erfüllen. Diese Werkzeuge erinnern an die Verwendung eines Traktors zum Navigieren durch die Straßen der Stadt – sie sind schwer und oft übertrieben. Die Entwickler der neuen Generation verlangen agile, intuitive Tools, die ihr schnelles Entwicklungstempo ergänzen.",approach_new_paradigm:"Aufforderungsbasierte Technologie: Ein neues Paradigma",approach_new_paradigm_description:`Das Jahr 2023 läutete eine bedeutende Veränderung ein: den Aufstieg der prompt-basierten Technologie. Durch die Vereinfachung des KI-Entwicklungsprozesses wurde der Zugang zu KI-Tools demokratisiert. Jetzt können auch diejenigen ohne umfangreiche Programmiererfahrung – sogenannte „Power-User“ – an der KI-Entwicklung teilnehmen, ohne die steilen Lernkurven zu durchlaufen, die mit Tools wie Pytorch, Docker oder Kubernetes verbunden sind.

Wenn man eine Parallele zieht, ähnelt dies der Entwicklung des Personal Computing. Ursprünglich bedienten nur Technikexperten Computer. Aber mit dem Aufkommen benutzerfreundlicher Schnittstellen könnte ein breiteres Publikum teilnehmen. Heute erleben wir mit der auf Eingabeaufforderungen basierenden Technologie eine ähnliche Demokratisierung der KI.`,awards:"Auszeichnungen und Anerkennung",berlin:"Berlin, Deutschland (Hauptsitz)",berlin_address:"Prinzessinnenstraße 19-20, 10969 Berlin, Deutschland",berlin_address2:"Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlin, Deutschland",bj:"Peking, China",bj_address:"Ebene 5, Gebäude 6, Nr. 48 Haidian West St. Peking, China",brochure_info:"Ihr Leitfaden zu unserem Unternehmen erwartet Sie",description:"Die Zukunft beginnt hier.",download_brochure1:"Broschüre herunterladen",download_docarray_logo:"Laden Sie das DocArray-Logo herunter",download_docarray_logo_desc:"Greifen Sie auf das DocArray-Logo zu, ein Open-Source-Projekt, das von Jina AI initiiert und im Dezember 2022 zur Linux Foundation beigetragen hat. Verfügbar im Hell- und Dunkelmodus, in den Formaten PNG und SVG.",download_jina_logo:"Laden Sie das Jina AI-Logo herunter",download_jina_logo_desc:"Holen Sie sich das Jina AI-Logo sowohl im hellen als auch im dunklen Modus, verfügbar in den Formaten PNG und SVG. Dieses Logo ist eine eingetragene Marke beim Amt der Europäischen Union für geistiges Eigentum (EUIPO).",download_logo:"Logos herunterladen",employees:"Mitarbeiter heute",empower_developers:"unterstützte Entwickler",fastApiCaption:"Seit 2021 über 20.000 US-Dollar gespendet.",founded:"Gegründet",founded_in:"Gegründet in",investors:"Unsere Investoren",linuxFoundationCaption:"Leistet ab 2022 einen jährlichen Beitrag von 10.000 US-Dollar.",many:"Viele",media:{video:"Videointerview"},mission:"Unsere Aufgabe",mission_content1:"Unsere Schlüsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Model-Tuning und Model-Serving, verkörpern unser Engagement für die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative wollen wir Innovation, Zusammenarbeit und Transparenz fördern und skalierbare, effiziente und robuste Lösungen gewährleisten. Jina AI ist mehr als nur ein Unternehmen; es ist eine Community, die sich dafür einsetzt, Unternehmen dabei zu unterstützen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein.",mission_content2:"Im Mittelpunkt von Jina AI steht unsere Mission, das Portal zur multimodalen KI für eine vielfältige Kundschaft zu sein, von Power-Usern und Entwicklern bis hin zu Unternehmen. Wir glauben fest an die Leistungsfähigkeit von Open Source und widmen uns der Entwicklung fortschrittlicher, zugänglicher Tools für die KI-Community. Unsere Schlüsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Embedding-Tuning und Embedding-Serving, verkörpern unser Engagement für die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative streben wir danach, Innovation, Zusammenarbeit und Transparenz zu fördern und skalierbare, effiziente und robuste Lösungen sicherzustellen. Jina AI ist mehr als nur ein Unternehmen; Es handelt sich um eine Community, deren Ziel es ist, Unternehmen dabei zu unterstützen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein.",mission_content3:"Unsere Mission bei Jina AI besteht darin, die Weiterentwicklung der multimodalen KI durch innovative Einbettungs- und Eingabeaufforderungstechnologien voranzutreiben und uns dabei insbesondere auf Bereiche wie die Verarbeitung natürlicher Sprache, Bild- und Videoanalyse sowie modalübergreifende Dateninteraktion zu konzentrieren. Diese Spezialisierung ermöglicht es uns, einzigartige Lösungen bereitzustellen, die komplexe Daten aus mehreren Quellen in umsetzbare Erkenntnisse und bahnbrechende Anwendungen umwandeln.",mit_report_title:"Multimodal: die neue Grenze der KI",mit_techreview:"MIT Technology Review",numfocusCaption:"Spendet ab 2022 regelmäßig jeden Monat.",office:"Unsere Büros",otherProjectsCaption:"Über Github Sponsorship über 3.000 US-Dollar gespendet.",our_answer:"Auf jeden Fall, Yann. Wir sind dabei und bauen Brücken in eine multimodale KI-Zukunft!",pythonSoftwareFoundationCaption:"Hat eine einmalige Spende in Höhe von 10.000 US-Dollar geleistet und mehrere PyCon-Veranstaltungen gesponsert, darunter in Deutschland, Italien, China und den USA.",sectors:{ecommerceRetail:"Marktplätze der nächsten Generation",ecommerceRetail_description:"Führende E-Commerce- und Einzelhandelsunternehmen arbeiten mit Jina AI zusammen, um präzise Produktempfehlungen und umfassende Sucherlebnisse zu bieten. Unsere mehrsprachigen Einbettungen und KI-gesteuerten Reranker helfen dabei, die Auffindbarkeit zu optimieren, die Konversion zu steigern und die Zeit bis zur Erkenntnisgewinnung für globale Produktkataloge zu verkürzen.",ecommerceRetail_short:"E-Commerce und Einzelhandel",financeConsulting:"Visionäre Berater und Analysten",financeConsulting_description:"Finanzunternehmen und Beratungsfirmen nutzen die umfangreiche Datenbereinigung und das domänenspezifische Modelltraining von Jina AI, um Erkenntnisse in Echtzeit zu gewinnen. Unsere Unternehmenslizenzen und sicheren On-Premise-Bereitstellungen ermöglichen es ihnen, die Vertraulichkeit zu wahren und gleichzeitig von erweiterten Abfrage- und Analysefunktionen zu profitieren.",financeConsulting_short:"Fin & Consult",media:"Fesselnde Inhaltsersteller",media_description:"Medienunternehmen nutzen Jina AI, um umfangreiche Multimedia-Ressourcen in durchsuchbares Wissen umzuwandeln, interne Recherchen zu optimieren und das Benutzererlebnis zu verbessern. Unsere spezialisierten Reader- und Reranking-Dienste gewährleisten eine präzise, kontextabhängige Suche in Artikeln, Videos und Archiven.",media_short:"Medien",misc:"Zukunftsorientierte Pioniere",misc_description:"Organisationen aus den Bereichen Bildung, Landwirtschaft, Immobilien und darüber hinaus nutzen die flexiblen Lösungen von Jina AI, um Daten in großem Umfang zu bereinigen, zu extrahieren und zu transformieren. Durch die Nutzung unseres hochmodernen neuronalen Retrieval-Stacks erschließen sie sich neue Möglichkeiten und bleiben in ihren jeweiligen Bereichen an der Spitze.",misc_short:"Sonstiges",technology:"Bahnbrechende Technologie-Innovatoren",technology_description:"Führende Unternehmen in den Bereichen Software, Cloud, KI und Daten verlassen sich auf die neuronalen Suchlösungen von Jina AI, um ihre LLM-basierten Such-, RAG- und KI-Agentensysteme zu betreiben. Unsere erweiterten Reader, Einbettungen, Reranker und kleinen LMs helfen ihnen, schneller als je zuvor vom POC zur Unternehmensreife zu gelangen.",technology_short:"Technik"},sefo:{layer0:"Endbenutzeranwendungen",layer1:"RAG / Orchestrierung",layer3:"GPU / Mobil / Edge / lokales Computing"},segmentFaultCaption:"Hat eine einmalige Spende in Höhe von 6.000 US-Dollar geleistet.",show_position:"Wie sucht man nach Stiftungspositionen im Ökosystem?",stats_1:"Jina AI wurde im Februar 2020 gegründet und hat sich schnell zu einem globalen Pionier der multimodalen KI-Technologie entwickelt. Innerhalb eines beeindruckenden Zeitrahmens von 20 Monaten haben wir erfolgreich 37,5 Millionen US-Dollar eingesammelt und damit unsere starke Position in der KI-Branche unterstrichen. Unsere bahnbrechende Technologie, Open-Source auf GitHub, hat über 40.000 Entwicklern auf der ganzen Welt die Möglichkeit gegeben, anspruchsvolle multimodale Anwendungen nahtlos zu erstellen und bereitzustellen.",stats_2:"Im Jahr 2023 haben wir erhebliche Fortschritte bei der Weiterentwicklung von Tools zur KI-Generierung gemacht, die auf multimodaler Technologie basieren. Von dieser Innovation haben über 250.000 Benutzer weltweit profitiert und eine Vielzahl einzigartiger Geschäftsanforderungen erfüllt. Von der Erleichterung des Geschäftswachstums über die Verbesserung der betrieblichen Effizienz bis hin zur Kostenoptimierung setzt sich Jina AI dafür ein, Unternehmen zu befähigen, im multimodalen Zeitalter hervorragende Leistungen zu erbringen.",stats_4:'Jina AI wurde 2020 gegründet und ist ein führendes Unternehmen im Bereich der Such-KI. Unsere <span class="text-primary text-bold">Search Foundation</span>-Plattform kombiniert Embeddings, Reranker und Small Language Models, um Unternehmen beim Aufbau zuverlässiger und qualitativ hochwertiger GenAI- und multimodaler Suchanwendungen zu unterstützen.',stats_v1:"Suche/account",subtitle:"Revolutionierung der Inhaltserstellung durch KI-generierte Lösungen, um unendliche Möglichkeiten zu erschließen. Die Zukunft KI-generierter Inhalte gestalten und die menschliche Kreativität fördern.",sues_und_sauer:"Süẞ & Sauer",sues_und_sauer_tooltip:"Süß-Sauer, ein beliebter (aber stereotyper) Geschmack in der deutsch-chinesischen Küche, bedeutet süß und sauer. Es ist eine Metapher für die Höhen und Tiefen des Startup-Lebens.",sunnyvale_address:"710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, USA",sz:"Shenzhen, China",sz_address:"402 Etage 4, Fu'an Technology Building, Shenzhen, China",team:"Im Portal von Jina AI",team_content1:"Von verschiedenen Orten der Welt aus gestalten wir die Zukunft der KI. Unsere unterschiedlichen Perspektiven bereichern unsere Arbeit und bringen Innovationen hervor. In diesem Portal leben wir unsere Individualität und verfolgen leidenschaftlich unsere Träume. Willkommen im Portal der KI-Zukunft.",team_join:"Begleiten Sie uns",team_size:"Auf diesen Fotos sind unsere ehemaligen Kollegen und Praktikanten zu sehen – wir freuen uns über jeden einzelnen von ihnen.",technologies:"Technologien",title:"Über Jina AI",title0:"Die Zukunft",title1:"Beginnt",title2:"Hier",title3:"Beginnt hier",understand_our_strength:"Verstehen Sie unsere Stärke",understand_our_view2:"Verstehen Sie die Grundlagen der Suche",users:"registrierte Benutzer",value:"Unsere Auszeichnungen",value_content1:"Wir geben uns nicht zufrieden. Wir gehen keine Kompromisse ein. Wir streben nach Spitzenleistung.",vision:"Unsere Aufgabe",vision_content1:"Inspiriert von Yann LeCuns Einsicht, dass „",vision_content3:'Die Zukunft der KI ist <span class="text-primary text-bold">multimodal</span>, und wir sind ein Teil davon. Wir sind uns bewusst, dass Unternehmen bei der Nutzung multimodaler Daten vor Herausforderungen stehen. Als Reaktion darauf engagieren wir uns in der <span class="text-primary text-bold">Search Foundation</span>, um Unternehmen und Entwicklern dabei zu helfen, besser zu suchen und multimodale Daten für das Unternehmenswachstum zu nutzen.',yannlecun_quote:"Ein künstliches Intelligenzsystem, das allein auf Wörter und Sätze trainiert wird, wird niemals annähernd das menschliche Verständnis erreichen."},r={answer1:"Ja, derselbe API-Schlüssel ist für alle Suchgrundlagenprodukte von Jina AI gültig. Dazu gehören die APIs zum Lesen, Einbetten, Neurangieren, Klassifizieren und Feinabstimmen, wobei die Token zwischen allen Diensten geteilt werden.",answer10:"Dies liegt daran, dass unsere serverlose Architektur bestimmte Modelle in Zeiten geringer Nutzung auslagert. Die erste Anfrage aktiviert oder „wärmt“ das Modell auf, was einige Sekunden dauern kann. Nach dieser ersten Aktivierung werden nachfolgende Anfragen viel schneller verarbeitet.",answer12:"Wir halten uns an eine strikte Datenschutzrichtlinie und verwenden keine Benutzereingabedaten zum Trainieren unserer Modelle. Wir sind außerdem SOC 2 Typ I und Typ II-konform und gewährleisten so hohe Sicherheits- und Datenschutzstandards.",answer3:"Ja, die Token-Nutzung kann auf der Registerkarte „API-Schlüssel und Abrechnung“ überwacht werden, indem Sie Ihren API-Schlüssel eingeben. So können Sie den aktuellen Nutzungsverlauf und die verbleibenden Token anzeigen. Wenn Sie sich beim API-Dashboard angemeldet haben, können diese Details auch auf der Registerkarte „API-Schlüssel verwalten“ angezeigt werden.",answer4:"Wenn Sie einen aufgeladenen Schlüssel verlegt haben und ihn abrufen möchten, wenden Sie sich bitte mit Ihrer registrierten E-Mail-Adresse an support@jina.ai. Es wird empfohlen, sich anzumelden, damit Ihr API-Schlüssel sicher gespeichert und leicht zugänglich bleibt.",answer5:"Nein, unsere API-Schlüssel haben kein Ablaufdatum. Wenn Sie jedoch vermuten, dass Ihr Schlüssel kompromittiert wurde und Sie ihn löschen möchten, wenden Sie sich bitte an unser Supportteam. Sie können Ihren Schlüssel auch im <a class='text-primary' href='https://jina.ai/api-dashboard'>API-Schlüsselverwaltungs-Dashboard</a> widerrufen.",answer6:"Ja, Sie können Token von einem Premium-Schlüssel auf einen anderen übertragen. Nachdem Sie sich auf dem <a class='text-primary' href='https://jina.ai/api-dashboard'>API-Schlüsselverwaltungs-Dashboard</a> bei Ihrem Konto angemeldet haben, verwenden Sie die Einstellungen des Schlüssels, den Sie übertragen möchten, um alle verbleibenden bezahlten Token zu übertragen.",answer7:"Ja, Sie können Ihren API-Schlüssel widerrufen, wenn Sie glauben, dass er kompromittiert wurde. Durch das Widerrufen eines Schlüssels wird dieser sofort für alle Benutzer deaktiviert, die ihn gespeichert haben, und alle verbleibenden Guthaben und zugehörigen Eigenschaften werden dauerhaft unbrauchbar. Wenn es sich bei dem Schlüssel um einen Premium-Schlüssel handelt, haben Sie die Möglichkeit, das verbleibende bezahlte Guthaben vor dem Widerruf auf einen anderen Schlüssel zu übertragen. Beachten Sie, dass diese Aktion nicht rückgängig gemacht werden kann. Um einen Schlüssel zu widerrufen, gehen Sie zu den Schlüsseleinstellungen im <a class='text-primary' href='https://jina.ai/api-dashboard'>Dashboard zur API-Schlüsselverwaltung</a>.",question1:"Kann ich denselben API-Schlüssel für Reader-, Einbettungs-, Neurang-, Klassifizierungs- und Feinabstimmungs-APIs verwenden?",question10:"Warum ist die erste Anfrage für einige Modelle langsam?",question12:"Werden Benutzereingabedaten zum Training Ihrer Modelle verwendet?",question3:"Kann ich die Token-Nutzung meines API-Schlüssels überwachen?",question4:"Was soll ich tun, wenn ich meinen API-Schlüssel vergesse?",question5:"Laufen API-Schlüssel ab?",question6:"Kann ich Token zwischen API-Schlüsseln übertragen?",question7:"Kann ich meinen API-Schlüssel widerrufen?",title:"Häufige Fragen zu APIs"},t={base_model:"Basismodell zum Feintuning",check_data:"Synthetische Daten herunterladen",check_model:"Feinabgestimmtes Modell herunterladen",data_size:"Synthetische Daten generiert",description:"Erhalten Sie fein abgestimmte Einbettungen für jede gewünschte Domäne.",description_long:"Sagen Sie uns einfach, in welchem ​​Bereich Ihre Einbettungen herausragend sein sollen, und wir liefern automatisch ein gebrauchsfertiges, fein abgestimmtes Einbettungsmodell für diesen Bereich.",does_it_work_tho:"Aber funktioniert es trotzdem?",does_it_work_tho_explain:"Die automatische Feinabstimmung verspricht wie durch Zauberhand feinabgestimmte Einbettungen für jede gewünschte Domäne. Aber funktioniert das wirklich? Das ist durchaus fraglich. Um das herauszufinden, haben wir es an einer Vielzahl von Domänen und Basismodellen getestet. Sehen Sie sich unten die Rosinenpickerei und die Zitronenpickerei an.",domain_instruction:"Domänenanweisung",embedding_provider:"Wählen Sie ein Basis-Einbettungsmodell",eval_evaluation:"Validierung",eval_map:"KARTE",eval_mrr:"MRR",eval_ndcg:"NDCG",eval_performance_before_after:"Leistung im synthetischen Validierungssatz vor und nach der Feinabstimmung",eval_syntheticDataSize:"Gesamt",eval_test:"Echte Daten zum Testen",eval_training:"Ausbildung",faq_v1:{answer1:"Die Funktion befindet sich derzeit in der Betaphase und kostet 1 Mio. Token pro fein abgestimmtem Modell. Sie können Ihren vorhandenen API-Schlüssel aus der Embedding/Reranker-API verwenden, wenn dieser über genügend Token verfügt, oder Sie können einen neuen API-Schlüssel erstellen, der 1 Mio. kostenlose Token enthält.",answer10:"Derzeit nicht. Beachten Sie, dass sich diese Funktion noch in der Betaphase befindet. Die öffentliche Speicherung der fein abgestimmten Modelle und synthetischen Daten im Hugging Face-Modell-Hub hilft uns und der Community, die Qualität des Trainings zu bewerten. In Zukunft planen wir, eine private Speicheroption anzubieten.",answer11:"Da alle feinabgestimmten Modelle auf Hugging Face hochgeladen werden, können Sie über SentenceTransformers darauf zugreifen, indem Sie einfach den Modellnamen angeben.",answer12:"Bitte überprüfen Sie Ihren Spam-Ordner. Wenn Sie ihn immer noch nicht finden können, wenden Sie sich bitte über die von Ihnen angegebene E-Mail-Adresse an unser Support-Team.",answer2:"Sie müssen keine Trainingsdaten bereitstellen. Beschreiben Sie einfach Ihre Zieldomäne (die Domäne, für die die fein abgestimmten Einbettungen optimiert werden sollen) in natürlicher Sprache oder verwenden Sie eine URL als Referenz. Unser System generiert dann synthetische Daten zum Trainieren des Modells.",answer3:"Etwa 30 Minuten.",answer4:"Die feinabgestimmten Modelle und synthetischen Daten werden öffentlich im Hugging Face-Modell-Hub gespeichert.",answer5:"Das System verwendet die Reader-API, um den Inhalt von der URL abzurufen. Anschließend analysiert es den Inhalt, um den Ton und die Domäne zusammenzufassen, die es als Richtlinien zum Generieren synthetischer Daten verwendet. Daher sollte die URL öffentlich zugänglich und repräsentativ für die Zieldomäne sein.",answer6:"Ja, Sie können ein Modell für eine andere Sprache als Englisch optimieren. Das System erkennt automatisch die Sprache Ihrer Domänenanweisungen und generiert entsprechend synthetische Daten. Wir empfehlen außerdem, das entsprechende Basismodell für die Zielsprache auszuwählen. Wenn Sie beispielsweise eine deutsche Domäne als Ziel haben, sollten Sie als Basismodell „jina-embeddings-v2-base-de“ auswählen.",answer7:"Nein, unsere Feinabstimmungs-API unterstützt nur Jina v2-Modelle.",answer8:"Am Ende des Feinabstimmungsprozesses wertet das System das Modell anhand eines zurückgehaltenen Testsatzes aus und meldet Leistungsmesswerte. Sie erhalten eine E-Mail mit detaillierten Angaben zur Leistung vor/nach diesem Testsatz. Sie werden außerdem ermutigt, das Modell anhand Ihres eigenen Testsatzes auszuwerten, um seine Qualität sicherzustellen.",answer9:"Das System generiert synthetische Daten, indem es die von Ihnen bereitgestellten Zieldomänenanweisungen mit den Argumenten der LLM-Agenten integriert. Es erzeugt harte negative Tripletts, die für das Training hochwertiger Einbettungsmodelle unerlässlich sind. Weitere Einzelheiten finden Sie in unserem kommenden Forschungspapier auf Arxiv.",question1:"Wie viel kostet die Fine-Tuning-API?",question10:"Kann ich meine fein abgestimmten Modelle und synthetischen Daten vertraulich behandeln?",question11:"Wie kann ich das feinabgestimmte Modell verwenden?",question12:"Ich habe die E-Mail mit den Bewertungsergebnissen nie erhalten. Was soll ich tun?",question2:"Welche Eingaben muss ich machen? Muss ich Trainingsdaten angeben?",question3:"Wie lange dauert die Feinabstimmung eines Modells?",question4:"Wo werden die feinabgestimmten Modelle gespeichert?",question5:"Wenn ich eine Referenz-URL angebe, wie verwendet das System diese?",question6:"Kann ich ein Modell für eine bestimmte Sprache optimieren?",question7:"Kann ich Nicht-Jina-Einbettungen, z. B. bge-M3, feinabstimmen?",question8:"Wie stellen Sie die Qualität der optimierten Modelle sicher?",question9:"Wie generieren Sie synthetische Daten?",title:"Häufige Fragen zur automatischen Feinabstimmung"},find_on_hf:"Liste der fein abgestimmten Modelle",temporarily_unavailable:"Vorübergehend nicht verfügbar. Wir aktualisieren unser automatisches Feinabstimmungssystem, um Ihnen einen besseren Service bieten zu können. Bitte schauen Sie später noch einmal vorbei.",test_on:"Getestet an {_dataSize} Zufallsstichproben aus {_dataName}",test_performance_before_after:"Leistung im zurückgehaltenen Testsatz vor und nach der Feinabstimmung",title:"API für automatische Feinabstimmung",total_improve:"Durchschnittliche Verbesserung",usage:"Verwendung",what_is:"Was ist automatische Feinabstimmung?",what_is_answer_long:"Durch Feinabstimmung können Sie ein vorab trainiertes Modell nehmen und es an eine bestimmte Aufgabe oder Domäne anpassen, indem Sie es an einem neuen Datensatz trainieren. In der Praxis ist es für viele Benutzer nicht einfach, effektive Trainingsdaten zu finden. Für ein effektives Training ist mehr erforderlich, als einfach nur Roh-PDFs und HTMLs in das Modell einzugeben. Und es ist schwer, es richtig zu machen. Die automatische Feinabstimmung löst dieses Problem, indem sie mithilfe einer erweiterten LLM-Agent-Pipeline automatisch effektive Trainingsdaten generiert und das Modell innerhalb eines ML-Workflows feinabstimmt. Sie können es sich als eine Kombination aus synthetischer Datengenerierung und AutoML vorstellen. Sie müssen also nur Ihre Zieldomäne in natürlicher Sprache beschreiben und unser System den Rest erledigen lassen."},s={auth_required:"Zur Nutzung der Avatar-Generierung ist eine Authentifizierung erforderlich",classificationError:"Fehler beim Klassifizieren des Bildes. Bitte versuchen Sie es erneut.",clickToDownload:"Klicken Sie hier, um SVG herunterzuladen",customize:"Funktionen anpassen",description:"Erstellen Sie einzigartige Avatare mit anpassbaren Funktionen",downloadError:"Fehler beim Herunterladen des Avatars",downloadSuccess:"Avatar erfolgreich heruntergeladen",download_success:"Avatar erfolgreich heruntergeladen",error_loading:"Avatar-Assets konnten nicht geladen werden. Bitte versuchen Sie es erneut.",error_processing:"Fehler bei der Bildverarbeitung",file_hint:"Unterstützte Formate: JPG, PNG, GIF, WebP",generate:"Avatar generieren",how_does_it_work:"Wie funktioniert es?",noImageSelected:"Bitte wählen Sie zuerst ein Bild aus",select_file:"Wählen Sie eine Portraitbilddatei aus",title:"Avatar-Generator",upload_description:"Wählen Sie ein Bild zur Konvertierung in Base64 (256 x 256) aus.",upload_title:"Bild hochladen",usage:"Avatar-Generierung"},a={description:"Vom Blog-Artikel zum Banner, ohne eigene Prompts!",example_description:"Alice wurde es langsam sehr leid, neben ihrer Schwester am Ufer zu sitzen und nichts zu tun zu haben: Ein- oder zweimal hatte sie in das Buch geguckt, das ihre Schwester las, aber es enthielt weder Bilder noch Gespräche. „Und was nützt ein Buch“, dachte Alice, „ohne Bilder oder Gespräche?“ So überlegte sie in Gedanken (so gut sie konnte, denn der heiße Tag machte sie sehr schläfrig und dumm), ob das Vergnügen, eine Gänseblümchenkette zu machen, die Mühe wert wäre, aufzustehen und die Gänseblümchen zu pflücken, als plötzlich ein weißes Kaninchen mit rosa Augen dicht an ihr vorbeilief.",example_title:"Alices Abenteuer im Wunderland – Kapitel 1"},u="Beta",d={answer10:"Wir bieten neuen Benutzern eine einladende kostenlose Testversion an, die eine Million Token zur Verwendung mit jedem unserer Modelle umfasst und durch einen automatisch generierten API-Schlüssel erleichtert wird. Sobald das kostenlose Token-Limit erreicht ist, können Benutzer über die Registerkarte „Token kaufen“ ganz einfach zusätzliche Token für ihre API-Schlüssel erwerben.",answer13:"Nein, für fehlgeschlagene Anfragen werden keine Token abgezogen.",answer14:"Zahlungen werden über Stripe abgewickelt und unterstützen zu Ihrer Bequemlichkeit eine Vielzahl von Zahlungsmethoden, darunter Kreditkarten, Google Pay und PayPal.",answer15:"Ja, beim Kauf von Tokens wird eine Rechnung an die E-Mail-Adresse ausgestellt, die mit Ihrem Stripe-Konto verknüpft ist.",answer9:"Unser Preismodell basiert auf der Gesamtzahl der verarbeiteten Token und bietet Benutzern die Flexibilität, diese Token auf eine beliebige Anzahl von Sätzen zu verteilen. Dies bietet eine kostengünstige Lösung für unterschiedliche Textanalyseanforderungen.",question10:"Gibt es eine kostenlose Testversion für neue Benutzer?",question13:"Werden für fehlgeschlagene Anfragen Token berechnet?",question14:"Welche Zahlungsmethoden werden akzeptiert?",question15:"Ist eine Rechnungsstellung für Token-Käufe verfügbar?",question9:"Erfolgt die Abrechnung nach der Anzahl der Sätze bzw. Anfragen?",title:"Häufige Fragen zur Abrechnung"},l={all:"Alle",events:"Ereignis",featured:"Hervorgehoben",insights:"Meinung","knowledge-base":"Wissen",latest:"Neueste",press:"Pressemitteilung",releases:"Software-Aktualisierung","tech-blog":"Tech-Blog"},o={caption:"Entdecken Sie „Re·Search“, unser wunderschön gestaltetes Jahrbuch, in dem unsere besten Forschungsartikel und Suchgrundlagenmodelle im Jahr 2024 präsentiert werden.",order_now:"Jetzt bestellen"},h={api_free_trial:"Kostenloser API-Schlüssel",api_paid:"Kostenpflichtiger API-Schlüssel",api_paid_or_free:"Verwenden Sie einen kostenpflichtigen API-Schlüssel oder einen kostenlosen Testschlüssel?",are_you:"Bist du:",commercial_contact_sales:"Dies ist kommerziell. Kontaktieren Sie unser Verkaufsteam.",contact_sales_for_licensing:"Kontaktieren Sie für Lizenzierungen unser Vertriebsteam.",csp_user:"Verwenden Sie unsere offiziellen Modellbilder auf AWS und Azure?",educational_teaching:"Eine Bildungseinrichtung, die es für die Lehre nutzt?",for_profit_internal_use:"Ein gewinnorientiertes Unternehmen, das es intern verwendet?",free_use:"Die Modelle können Sie frei verwenden.",government_public_services:"Eine Regierungsbehörde, die es für öffentliche Dienste nutzt?",is_use_commercial:"Ist Ihre Nutzung kommerziell?",may_be_commercial_contact:"Dies kann kommerziell sein. Bitte kontaktieren Sie uns zur Klärung.",no:"NEIN",no1:"NEIN",no2:"NEIN",no3:"NEIN",no_restrictions:"Keine Einschränkungen. Nutzung gemäß Ihrem aktuellen Vertrag.",no_restrictions_apply:"Es gelten keine Einschränkungen.",non_commercial_free_use:"Dies ist nicht kommerziell. Sie können die Modelle frei verwenden.",non_profit_ngo_mission:"Eine gemeinnützige Organisation oder NGO nutzt es für Ihre Mission?",not_sure:"Nicht sicher",personal_hobby_projects:"Verwenden Sie es für persönliche oder Hobbyprojekte?",product_service_sale:"Verwenden Sie es in einem Produkt oder einer Dienstleistung, die Sie verkaufen?",title:"CC BY-NC Lizenz Selbstcheck",trial_key_restrictions:"Der kostenlose Testschlüssel kann nur für nichtkommerzielle Zwecke verwendet werden. Für die kommerzielle Nutzung erwerben Sie bitte ein kostenpflichtiges Paket.",typically_non_commercial_check:"Dies ist normalerweise nicht kommerziell, aber fragen Sie uns, wenn Sie unsicher sind.",typically_non_commercial_free_use:"Dies erfolgt in der Regel nicht kommerziell. Sie können die Modelle frei verwenden.",using_api_or_cloud:"Verwenden Sie unsere offizielle API oder offiziellen Images auf Azure oder AWS?",using_cc_by_nc_models:"Verwenden Sie diese Modelle?",yes:"Ja",yes1:"Ja",yes2:"Ja",yes3:"Ja"},g={access:"Öffentlicher Zugang",access_explain:"Öffentliche Klassifikatoren können von jedem mit der <code>classifier_id</code> verwendet werden und ihre Nutzung verbraucht das Token-Kontingent des Anrufers und nicht Ihres. Auf private Klassifikatoren können nur Sie zugreifen.",access_private:"Privat",access_public:"Öffentlich",api_delete:"Klassifikator löschen",api_delete_explain:"Löschen Sie einen Klassifikator anhand seiner ID.",api_list:"Klassifikatoren auflisten",api_list_explain:"Listen Sie alle Klassifikatoren auf, die Sie erstellt haben.",classifier_id:"Klassifikator-ID",classify_inputs:"Zu klassifizierende Eingaben",classify_inputs_explain:"Bei Text kann es sich um einen Satz mit bis zu 8192 Token handeln. Bei Bildern kann es eine URL oder ein Base64-codiertes Bild sein.",classify_labels:"Kandidatenbezeichnungen",classify_labels_explain:"Eingaben werden in diese Labels kategorisiert. Es können bis zu 256 Klassen sein. Verwenden Sie semantische Labels für eine bessere Leistung.",compare_table:{access_control:"Zugriffskontrolle",classifier_id_required:"Klassifikator-ID erforderlich",continuous_updates:"Kontinuierliche Modellaktualisierungen",default_solution:"Standardlösung für die allgemeine Klassifizierung",feature:"Besonderheit",few_shot:"Wenige Schüsse",image_multi_lingual_support:"Multimodaler und mehrsprachiger Support",labels_required_classify:"In /classify erforderliche Beschriftungen",labels_required_train:"In /train erforderliche Beschriftungen",max_classes:"Maximale Klassen",max_classifiers:"Maximale Klassifikatoren",max_inputs_request:"Maximale Eingaben pro Anfrage",max_token_length:"Maximale Tokenlänge pro Eingabe",na:"N / A",no:"NEIN",out_of_domain_solution:"Für Daten außerhalb der Domäne von v3/clip-v1 oder zeitkritische Daten",primary_use_case:"Primärer Anwendungsfall",semantic_labels_required:"Semantische Bezeichnungen erforderlich",state_management:"Zustandsverwaltung",stateful:"Zustandsbehaftet",stateless:"Staatenlos",token_count:"{count} Token",training_data_required:"Trainingsdaten erforderlich",yes:"Ja",zero_shot:"Nullschuss"},create_classifier:"Neuer Few-Shot-Klassifikator",create_classifier_explain:"Erstellen Sie einen neuen Few-Shot-Klassifikator und trainieren Sie ihn mit beschrifteten Beispielen.",description:"Zero-Shot- und Few-Shot-Klassifizierung für Bild und Text.",description_long:"Probieren Sie unseren API-Spielplatz aus, um zu sehen, wie unser Klassifikator funktioniert.",description_long1:"Hochleistungsfähiger Zero-Shot- und Few-Shot-Klassifikator für multimodale und mehrsprachige Daten.",explain:"Der Classifier ist ein API-Dienst, der Text und Bilder mithilfe von Einbettungsmodellen (<code>jina-embeddings-v3</code> und <code>jina-clip-v1</code>) kategorisiert und sowohl die Zero-Shot-Klassifizierung ohne Trainingsdaten als auch das Few-Shot-Learning mit minimalen Beispielen unterstützt.",faq_v1:{answer1:"Zero-Shot erfordert semantische Bezeichnungen während der Klassifizierung und keine während des Trainings, während Few-Shot Bezeichnungen während des Trainings, aber keine Klassifizierung erfordert. Das bedeutet, dass Zero-Shot besser für flexible, unmittelbare Klassifizierungsanforderungen geeignet ist, während Few-Shot besser für feste, domänenspezifische Kategorien geeignet ist, die sich im Laufe der Zeit entwickeln können.",answer10:"Ja, Sie können zwischen <code>jina-embeddings-v3</code> für die Textklassifizierung (besonders gut für mehrsprachige Texte) und <code>jina-clip-v1</code> für die multimodale Klassifizierung wählen. Neue Modelle wie <code>jina-clip-v2</code> werden nach der Veröffentlichung automatisch über die API verfügbar sein.",answer2:"<code>num_iters</code> steuert die Trainingsintensität – höhere Werte verstärken wichtige Beispiele, während niedrigere Werte die Auswirkung weniger zuverlässiger Daten minimieren. Es kann verwendet werden, um zeitbewusstes Lernen zu implementieren, indem aktuellen Beispielen höhere Iterationszahlen zugewiesen werden, was es für sich entwickelnde Datenmuster wertvoll macht.",answer3:"Öffentliche Klassifikatoren können von jedem mit der <code>classifier_id</code> verwendet werden, wobei das eigene Token-Kontingent verbraucht wird. Benutzer können nicht auf Trainingsdaten oder Konfigurationen zugreifen und die Klassifizierungsanforderungen anderer nicht sehen, wodurch eine sichere gemeinsame Nutzung von Klassifikatoren ermöglicht wird.",answer4:"Few-Shot erfordert 200-400 Trainingsbeispiele, um die Zero-Shot-Klassifizierung zu übertreffen. Obwohl es letztendlich eine höhere Genauigkeit erreicht, benötigt es diese Aufwärmphase, um wirksam zu werden. Zero-Shot bietet sofort eine konsistente Leistung ohne Trainingsdaten.",answer5:"Ja – die API unterstützt mehrsprachige Abfragen mit <code>jina-embeddings-v3</code> und multimodale (Text/Bild-)Klassifizierung mit <code>jina-clip-v1</code>, mit Unterstützung für URL- oder Base64-codierte Bilder in derselben Anfrage.",answer6:"Zero-Shot unterstützt 256 Klassen ohne Klassifikatorbegrenzung, während Few-Shot auf 16 Klassen und 16 Klassifikatoren beschränkt ist. Beide unterstützen 1.024 Eingaben pro Anfrage und 8.192 Token pro Eingabe.",answer7:"Der Few-Shot-Modus ermöglicht kontinuierliche Aktualisierungen über den Endpunkt <code>/train</code> zur Anpassung an sich ändernde Datenmuster. Sie können bei Änderungen der Datenverteilung schrittweise neue Beispiele oder Klassen hinzufügen, ohne den gesamten Klassifizierer neu erstellen zu müssen.",answer8:"Die API verwendet One-Pass-Online-Lernen – Trainingsbeispiele aktualisieren Klassifikatorgewichte, werden aber anschließend nicht gespeichert. Dies bedeutet, dass Sie keine historischen Trainingsdaten abrufen können, gewährleistet jedoch Datenschutz und Ressourceneffizienz.",answer9:"Beginnen Sie mit Zero-Shot für sofortige Ergebnisse und wenn Sie eine flexible Klassifizierung mit semantischen Labels benötigen. Wechseln Sie zu Few-Shot, wenn Sie 200-400 Beispiele haben, eine höhere Genauigkeit benötigen oder domänenspezifische/zeitkritische Daten verarbeiten müssen.",question1:"Was ist der Unterschied zwischen den Beschriftungen bei Zero-Shot und Few-Shot?",question10:"Kann ich für unterschiedliche Sprachen/Aufgaben unterschiedliche Modelle verwenden?",question2:"Wofür ist num_iters und wie sollte ich es verwenden?",question3:"Wie funktioniert das öffentliche Teilen von Klassifikatoren?",question4:"Wie viele Daten benötige ich, damit Few-Shot gut funktioniert?",question5:"Kann es mehrere Sprachen und sowohl Text als auch Bilder verarbeiten?",question6:"Welche absoluten Grenzen sollte ich kennen?",question7:"Wie gehe ich mit Datenänderungen im Laufe der Zeit um?",question8:"Was passiert mit meinen Trainingsdaten, nachdem ich sie gesendet habe?",question9:"Zero-Shot vs. Few-Shot – wann verwendet man was?",title:"Häufige Fragen zum Klassifikator"},more:"mehr",num_iters:"Trainingsiterationen",num_iters_explain:"Steuert die Trainingsintensität – höhere Werte verbessern die Genauigkeit bei aktuellen Beispielen, erhöhen aber die Token-Kosten. Der Standardwert 10 funktioniert normalerweise gut.",read_notes:"Versionshinweise lesen",select_classifier_or_model:"Wählen Sie einen Klassifikator oder ein Einbettungsmodell aus",task_classify:"Klassifizieren",task_classify_explain:"Verwenden Sie einen Zero-Shot- oder Few-Shot-Klassifikator, um Text oder Bilder in definierte Klassen zu kategorisieren.",task_manage:"Verwalten",task_manage_explain:"Listen Sie Ihre Few-Shot-Klassifikatoren auf oder löschen Sie sie.",task_select:"Wählen Sie eine Aufgabe aus",task_train:"Zug",task_train_explain:"Erstellen oder aktualisieren Sie einen Few-Shot-Klassifikator mit beschrifteten Beispielen.",title:"Klassifizierer-API",train_inputs:"Trainingsdaten",train_inputs_explain:"Text- oder Bildbeispiele mit Beschriftungen zum Training. Sie können den Klassifikator im Laufe der Zeit schrittweise mit neuen Beispielen und Beschriftungen aktualisieren.",train_label:"Etikett",what_is:"Was ist ein Klassifikator?",when_to_use_what:"Wann sollte Zero-Shot oder Few-Shot verwendet werden?",when_to_use_what_explain:"Verwenden Sie die Zero-Shot-Klassifizierung als Standardlösung für sofortige Ergebnisse bei allgemeinen Klassifizierungsaufgaben mit bis zu 256 Klassen, während sich das Few-Shot-Learning besser eignet, wenn Sie mit domänenspezifischen Daten außerhalb des Wissens der eingebetteten Modelle arbeiten oder wenn Sie zeitkritische Daten verarbeiten müssen, die kontinuierliche Modellaktualisierungen erfordern."},c={description:"Erzeugen Sie Embedding-Vektoren in konstanter länge für Bilder und Sätze mit CLIP"},m={description:"Cloud-Hosting-Plattform für multimodale KI-Anwendungen"},b={agreement:"Mit dem Absenden bestätigen Sie, dass Sie mit der Verarbeitung Ihrer personenbezogenen Daten durch Jina AI wie im Abschnitt beschrieben einverstanden sind",anything_else:"Erzählen Sie uns mehr über Ihre Idee",cc_by_nc:"Kommerzielle Nutzung von CC BY-NC-Modellen beantragen",cc_by_nc_description:"Unsere neuesten Modelle sind in der Regel CC BY-NC-lizenziert. Für die kommerzielle Nutzung greifen Sie über unsere API, Azure Marketplace oder AWS SageMaker darauf zu. Aktivieren Sie dieses Kontrollkästchen für die lokale Nutzung außerhalb dieser Kanäle.",company:"Organisation",company_size:"Größe der Organisation",company_website:"Website der Organisation",company_website_placeholder:"URL für die Homepage oder das LinkedIn-Profil Ihres Unternehmens",country:"Land",department:"Abteilung",description:"Erweitern Sie Ihr Geschäft mit Jina AI.",drop_area_for_image:"Legen Sie Ihre Bilder hier ab",faq:"FAQ",feedback_sent:"Gesendet! Wir werden uns in Kürze bei Ihnen melden.",field_required:"Feld ist erforderlich",get_api_key:"Wie erhalte ich meinen API-Schlüssel?",image_upload:"Bilder anhängen",image_validate:"Sie können bis zu {_num} Bilder anhängen. Nur JPG, JPEG, PNG, WEBP.",impact_snapshots:"Impact-Schnappschüsse",invalid_date_format:"Ungültiges Datumsformat. Bitte verwenden Sie das Format TT-MM-JJJJ.",invalid_email:"E-Mail ist ungültig",invalid_number:"Ungültige Nummer. Bitte geben Sie erneut ein",invalid_url:"Die URL ist ungültig",name:"Name",nc_check:"Benötige ich eine gewerbliche Lizenz?",other_questions:"Andere Fragen",preferred_models:"Für welche Modelle interessieren Sie sich?",preferred_products:"Für welche Produkte interessieren Sie sich?",pricing:"Preise?",priority:"Vorrangiger Support für zahlende Benutzer",private_statement:"Datenschutzerklärung",rate_limit:"Wie hoch ist die Ratenbegrenzung?",role:"Position",self_check:"Selbstcheck",sending_feedback:"Senden...",shortcut:"Abkürzung",submit:"Einreichen",submit_failed:"Die Übermittlung ist fehlgeschlagen. Bitte versuchen Sie es später noch einmal.",submit_success:"Vielen Dank für Ihre Einreichung. Wir kommen bald auf Sie zurück.",subtitle:"Jina AI, ein führendes Unternehmen im Bereich multimodale KI, zeichnet sich durch Modell-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite Lösungen. Mit unserer Expertise in großen Sprachmodellen, Text-, Bild-, Video- und Audioverständnis, neuronaler Suche und generativer Kunst bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen.",subtitle1:"Jina AI, ein führender Anbieter multimodaler KI, zeichnet sich durch Embedding-Tuning, Embedding-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite Lösungen. Mit unserer Expertise in großen Sprachmodellen, Text-, Bild-, Video- und Audioverständnis, neuronaler Suche und generativer KI bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen.",subtitle2:"Entdecken Sie Jina AI, die Spitze der multimodalen KI. Wir zeichnen uns durch die Einbettung und Bereitstellung von Technologien aus und nutzen Cloud-native Lösungen wie Kubernetes für robuste, skalierbare Systeme. Wir sind auf große Sprachmodelle und Medienverarbeitung spezialisiert und bieten mit unserer fortschrittlichen KI-Expertise innovative, zukunftsfähige Geschäftsstrategien.",title:"Kontaktieren Sie unseren Vertrieb",trusted_by:"Unsere Partner",turn_on_volume:"Erhöhen Sie die Lautstärke",work_email:"Arbeits Email"},f="Kopieren",k="In die Zwischenablage kopiert",p={description:"Ein Human-in-the-Loop-Workflow zum Erstellen von HD-Bildern aus Text"},z={api_endpoint:"API-Endpunkt",api_key:"API-Schlüssel",api_tagline:"Vollständig kompatibel mit dem Chat-API-Schema von OpenAI. Tauschen Sie einfach <code>api.openai.com</code> gegen <code>deepsearch.jina.ai</code> aus, um loszulegen.",api_title:"DeepSearch-API",assistant_message:"Assistent",chat_ui:{clear_context_message:"Möchten Sie den Kontext wirklich löschen? Dadurch wird die Konversation zurückgesetzt.",clear_context_title:"Neuer Chat?",description:"Stimmungscheck mit einer einfachen Chat-Benutzeroberfläche. DeepSearch eignet sich am besten für komplexe Fragen, die iteratives Denken, Weltwissen oder aktuelle Informationen erfordern.",example_q1:"Was ist der neueste Blogbeitrag von OpenAI?",example_q2:"Was ist die Idee hinter dem Node-Deepresearch-Projekt?",example_q3:"was genau ist eine Verbesserung von jina-colbert-v2 gegenüber jina-colbert-v1?",input_cant_be_empty:"Die Eingabe darf nicht leer sein.",input_placeholder:"Geben Sie hier Ihre Frage ein",keyman:"Schlüsselmanager",move_to_new:"Wir haben gerade eine neue DeepSearch-Benutzeroberfläche eingeführt, die blitzschnell, minimalistisch und KOSTENLOS ist. Sehen Sie sie sich unter https://search.jina.ai an oder klicken Sie auf die Schaltfläche unten, um sie auszuprobieren!",new_chat:"Den aktuellen Chat löschen und eine neue Unterhaltung beginnen",new_url:"Neue Benutzeroberfläche besuchen",payment_required:"Ihr API-Schlüssel enthält nicht mehr genügend Token. Wenn Sie mehrere API-Schlüssel haben, können Sie im Schlüsselmanager zu dem Schlüssel mit genügend Token wechseln. Andernfalls können Sie Ihren API-Schlüssel aufladen, um fortzufahren.",purchase:"API-Schlüssel aufladen",rate_limit_exceeded:"Sie haben das Ratenlimit überschritten. Bitte versuchen Sie es später erneut oder verwenden Sie Ihren API-Schlüssel, um ein höheres Ratenlimit zu erhalten.",stay:"Bleiben Sie bei der klassischen Demo-Benutzeroberfläche",thinking:"Denken...",thinking_done:"Gedankenkette",title:"DeepSearch-Chat",use_user_key:"Verwenden Sie Ihren API-Schlüssel, um ein höheres Ratenlimit zu erhalten."},client_3p:"Chat-Clients",client_3p_explain:"Für ein optimales Erlebnis empfehlen wir die Verwendung professioneller Chat-Clients. DeepSearch ist vollständig mit dem Chat-API-Schema von OpenAI kompatibel und lässt sich daher problemlos mit jedem OpenAI-kompatiblen Client verwenden.",comparison:{group1:{bestFor:"Schnelle Antworten auf Allgemeinwissensfragen",feature1:"Antworten werden ausschließlich aus vorab trainiertem Wissen mit einem festen Stichtag generiert",limitations:"Kein Zugriff auf Echtzeit- oder Nachtrainingsinformationen möglich",timeCost:"ca. 1s",title:"Standard-LLM",tokenCost:"ca. 1000 Token"},group2:{bestFor:"Fragen, die aktuelle oder domänenspezifische Informationen erfordern",feature1:"Antworten, die durch die Zusammenfassung der Ergebnisse einer Single-Pass-Suche generiert werden",feature2:"Kann auch nach Trainingsende auf aktuelle Informationen zugreifen",limitations:"Hat Probleme mit komplexen Fragen, die Multi-Hop-Argumentation erfordern",timeCost:"ca. 3s",title:"RAG und Grounded LLMs",tokenCost:"etwa 10.000 Token"},group3:{bestFor:"Komplexe Fragen, die gründliche Recherche und Argumentation erfordern",feature1:"Autonomer Agent, der iterativ sucht, liest und argumentiert",feature2:"Entscheidet dynamisch über die nächsten Schritte auf Grundlage aktueller Erkenntnisse",feature3:"Bewertet die Qualität der Antworten selbst, bevor Ergebnisse zurückgegeben werden",feature4:"Kann durch mehrere Such- und Argumentationszyklen tief in Themen eintauchen",limitations:"Dauert länger als einfache LLM- oder RAG-Ansätze",timeCost:"etwa 50er Jahre",title:"DeepSearch",tokenCost:"etwa 500.000 Token"}},demo:"Chatten Sie mit DeepSearch",demo_description:"Stimmungscheck mit einer einfachen Chat-Benutzeroberfläche. DeepSearch eignet sich am besten für komplexe Fragen, die iteratives Denken, Weltwissen oder aktuelle Informationen erfordern.",description:"Suchen, lesen und überlegen, bis die beste Antwort gefunden ist.",explain:"DeepSearch kombiniert Websuche, Lesen und Argumentation für eine umfassende Untersuchung. Stellen Sie es sich als einen Agenten vor, dem Sie eine Rechercheaufgabe erteilen – er sucht umfassend und durchläuft mehrere Iterationen, bevor er eine Antwort liefert.",faq:{answer1:"DeepSearch ist eine LLM-API, die iterative Such-, Lese- und Argumentationsvorgänge durchführt, bis sie eine genaue Antwort auf eine Abfrage findet oder ihr Token-Budgetlimit erreicht.",answer10:"Ratenbegrenzungen variieren je nach API-Schlüsselebene und reichen von 10 RPM bis 30 RPM. Dies ist bei Anwendungen mit hohem Abfragevolumen zu berücksichtigen.",answer11:"DeepSearch verpackt Denkschritte in XML-Tags <think>...</think> und liefert anschließend die endgültige Antwort, wobei es dem OpenAI-Streaming-Format folgt, jedoch mit diesen speziellen Markierungen für die Gedankenkette.",answer12:"Ja. Jina Reader wird zum Suchen und Lesen im Internet verwendet und bietet dem System die Möglichkeit, effizient auf Webinhalte zuzugreifen und diese zu verarbeiten.",answer14:"Ja, die Token-Nutzung von DeepSearch bei komplexen Abfragen ist wohl hoch – im Durchschnitt 70.000 Token im Vergleich zu 500 für einfache LLM-Antworten. Dies zeigt die Tiefe der Recherche, hat aber auch Auswirkungen auf die Kosten.",answer18:"Das System wird in erster Linie durch das Token-Budget und nicht durch die Schrittzahl gesteuert. Sobald das Token-Budget überschritten ist, wechselt es in den Beast-Modus zur Generierung der endgültigen Antwort. Weitere Einzelheiten finden Sie unter <code>reasoning_effort</code>.",answer19:"Referenzen werden als so wichtig erachtet, dass das System, wenn eine Antwort als endgültig gilt, aber keine Referenzen enthält, mit der Suche fortfährt, anstatt die Antwort zu akzeptieren.",answer2:"Im Gegensatz zu OpenAI und Gemini konzentriert sich DeepSearch speziell darauf, durch Iteration genaue Antworten zu liefern, anstatt lange Artikel zu erstellen. Es ist für schnelle, präzise Antworten aus der Deep Web-Suche optimiert, anstatt umfassende Berichte zu erstellen.",answer20:"Ja, aber mit umfangreichen Forschungsschritten. Das Beispiel „Wer wird 2028 Präsident sein?“ zeigt, dass es mit spekulativen Fragen durch mehrere Forschungsiterationen umgehen kann, obwohl die Genauigkeit solcher Vorhersagen nicht garantiert ist.",answer3:"Sie benötigen einen Jina API-Schlüssel. Wir bieten 1 Million kostenlose Token für neue API-Schlüssel.",answer5:"Es generiert eine endgültige Antwort auf Grundlage des gesamten gesammelten Wissens, anstatt einfach aufzugeben oder eine unvollständige Antwort zurückzugeben.",answer6:"Nein. Obwohl zur Verbesserung der Genauigkeit ein iterativer Suchvorgang verwendet wird, zeigt die Auswertung, dass bei Prüfungsfragen eine Bestehensquote von 75 % erreicht wird. Das ist zwar deutlich besser als der Basiswert von 0 % (Gemini-2.0-Flash), aber nicht perfekt.",answer7:"Es gibt erhebliche Unterschiede: Abfragen können zwischen 1 und 42 Schritte umfassen, wobei der Durchschnitt basierend auf Auswertungsdaten 4 Schritte beträgt. Das sind 20 Sekunden. Einfache Abfragen können schnell gelöst werden, während komplexe Forschungsfragen viele Iterationen und bis zu 120 Sekunden umfassen können.",answer9:"Ja, die offizielle DeepSearch-API unter deepsearch.jina.ai/v1/chat/completions ist vollständig mit dem OpenAI-API-Schema kompatibel und verwendet „jina-deepsearch-v1“ als Modellnamen. Daher ist es ganz einfach, von OpenAI zu DeepSearch zu wechseln und es mit lokalen Clients oder jedem OpenAI-kompatiblen Client zu verwenden. Für ein nahtloses Erlebnis empfehlen wir dringend Chatwise.",question1:"Was ist DeepSearch?",question10:"Was sind die Ratenbegrenzungen für die API?",question11:"Was ist der Inhalt des <think>-Tags?",question12:"Verwendet DeepSearch Jina Reader für die Websuche und das Lesen?",question14:"Warum verwendet DeepSearch so viele Token für meine Abfragen?",question18:"Gibt es eine Möglichkeit, die Anzahl der Schritte zu kontrollieren oder zu begrenzen?",question19:"Wie zuverlässig sind die Referenzen in den Antworten?",question2:"Wie unterscheidet sich DeepSearch von den umfassenden Recherchefunktionen von OpenAI und Gemini?",question20:"Kann DeepSearch Fragen zu zukünftigen Ereignissen verarbeiten?",question3:"Welchen API-Schlüssel benötige ich, um DeepSearch zu verwenden?",question5:"Was passiert, wenn DeepSearch sein Token-Budget erreicht? Gibt es eine unvollständige Antwort zurück?",question6:"Garantiert DeepSearch genaue Antworten?",question7:"Wie lange dauert eine typische DeepSearch-Abfrage?",question9:"Kann DeepSearch mit jedem OpenAI-kompatiblen Client wie Chatwise, CherryStudio oder ChatBox funktionieren?",title:"Häufige Fragen zu DeepSearch"},high_explain:"Maximales Denken und Suchen bei komplexen Abfragen (2 Mio. Token/Anforderung)","jina-deepsearch-v1_explain":"Prägnante Antwort mit iterativer Suche",last_chunk:"Dies ist der letzte Teil des Streams, der die endgültige Antwort, die besuchten URLs und die Token-Nutzung enthält. Klicken Sie auf die Schaltfläche oben, um eine Antwort in Echtzeit zu erhalten.",learn_more:"Mehr erfahren",low_explain:"Grundlegendes Denken und Suchen für einfache Abfragen (max. 500.000 Token/Anforderung)",medium_explain:"Mäßiges Denkvermögen und Suchtiefe (1 Mio. Token/Anforderung)",message:"Nachricht",message_type:"Bild/Dokument anhängen",message_type_explain:"Es werden verschiedene Nachrichtentypen (Modalitäten) unterstützt, wie Text (.txt, .pdf), Bilder (.png, .webp, .jpeg). Dateien bis zu 10 MB werden unterstützt und müssen im Voraus in Daten-URI codiert werden.",messages:"Nachrichten",messages_explain:"Eine Liste der Nachrichten zwischen dem Benutzer und dem Assistenten, die die bisherige Konversation darstellen.",model:"Modell",model_explain:"ID des zu verwendenden Modells.",model_name:"Modellname",open:"Offen",parameters:{auth_token:"@:tokenizer.parameters.auth_token",auth_token_explain:"Die Nutzung der DeepSearch-API ist kostenlos. Durch die Angabe Ihres API-Schlüssels können Sie auf ein höheres Ratenlimit zugreifen und Ihr Schlüssel wird nicht in Rechnung gestellt.",budget_tokens:"Budget-Token",budget_tokens_explain:"Dies bestimmt die maximale Anzahl an Token, die für den DeepSearch-Prozess verwendet werden dürfen. Größere Budgets können die Antwortqualität verbessern, indem sie eine umfassendere Suche nach komplexen Abfragen ermöglichen, obwohl DeepSearch möglicherweise nicht das gesamte zugewiesene Budget verwendet. Dies überschreibt den Parameter <code>reasoning_effort</code>.",json_schema:"Strukturierte Ausgabe",json_schema_explain:"Dadurch werden strukturierte Ausgaben aktiviert, die sicherstellen, dass die endgültige Antwort des Modells mit Ihrem bereitgestellten JSON-Schema übereinstimmt.",max_attempts:"Max. Versuche",max_attempts_explain:"Die maximale Anzahl von Wiederholungsversuchen zum Lösen eines Problems (und aller Teilprobleme) im DeepSearch-Prozess. Ein höherer Wert ermöglicht es DeepSearch, das Problem mithilfe verschiedener Denkansätze und Lösungsstrategien erneut zu lösen. Dieser Parameter überschreibt den Parameter <code>reasoning_effort</code>.",model:"@:deepsearch.modell",model_explain:"@:deepsearch.model_explain",reasoning_effort:"@:deepsearch.reasoning_effort",reasoning_effort_explain:"@:deepsearch.reasoning_effort_explain",stream:"@:deepsearch.stream",stream_explain:"@:deepsearch.stream_explain"},reasoning_effort:"Argumentationsaufwand",reasoning_effort_explain:"Beschränkt den Schlussfolgerungsaufwand für Schlussfolgerungsmodelle. Derzeit unterstützte Werte sind niedrig, mittel und hoch. Eine Reduzierung des Schlussfolgerungsaufwands kann zu schnelleren Antworten und weniger Schlussfolgerungstoken in einer Antwort führen.",stream:"Streaming",stream_explain:"Übermittelt Ereignisse, sobald sie über vom Server gesendete Ereignisse auftreten, einschließlich Argumentationsschritte und endgültiger Antworten. Wir <b>empfohlen dringend</b>, diese Option aktiviert zu lassen, da die Ausführung von DeepSearch-Anfragen viel Zeit in Anspruch nehmen kann. Das Deaktivieren des Streamings kann zu „524 Timeout“-Fehlern führen.",tagline:"@:deepsearch.beschreibung",title:"DeepSearch",type_file:"Datei anhängen",type_image:"Anhängen eines Bilds",type_text:"Nur-Text-Nachricht",user_message:"Benutzer",what_is:"Was ist DeepSearch?"},w={description:"Erstellen Sie überzeugende Disco Diffusion-Kunstwerke in einer Codezeile"},_={description:"Die Datenstruktur für multimodale Daten"},S="SOC 2 Typ 1-Bescheinigung herunterladen",v={"11B tokens":"11 Milliarden","11B tokens_intuition1":"Ähnlich wie das Lesen aller englischsprachigen Artikel auf Wikipedia.","11B tokens_targetUser":"Produktionsbereitstellung","1B tokens":"1 Milliarde","1B tokens_intuition1":"Ungefähr so, als würde man die Gesamtwerke Shakespeares und die komplette „Harry Potter“-Reihe lesen.","1B tokens_targetUser":"Prototypenentwicklung","1M tokens":"1 Million","1M tokens_intuition1":"Entspricht dem Lesen des gesamten Textes von „Der Hobbit“ und „Der große Gatsby“.","1M tokens_targetUser":"Spielzeug-Experiment","1M_free":"1 Million kostenlose Token","1M_free_description":"Genießen Sie Ihren neuen API-Schlüssel mit kostenlosen Tokens, keine Kreditkarte erforderlich.","2_5B tokens":"2,5 Milliarden Token","2_5B tokens_intuition1":`Vergleichbar mit der 1.000-fachen Transkription jedes gesprochenen Wortes aus der Filmtrilogie „Der Herr der Ringe“.
`,"3p_integration":"Mit <b>{_numPartners}</b> Drittanbieterdiensten","3p_integration_desc":"Integrieren Sie unsere Suchgrundlage in Ihre vorhandenen Dienste. Unsere Partner haben Konnektoren zu unserer API erstellt, sodass Sie unsere Modelle ganz einfach in Ihren Anwendungen verwenden können.","500M tokens":"500 Millionen Token","500M tokens_intuition1":"Ähnlich wie das Anschauen aller Folgen der „Simpsons“ von Staffel 1 bis Staffel 30.","59B tokens":"59B-Token","59B tokens_intuition1":"Entspricht allen Tweets, die weltweit innerhalb eines Zeitraums von zwei Tagen gepostet werden.","5_5B tokens":"5,5 Milliarden Token","5_5B tokens_intuition1":"Entspricht dem Lesen des gesamten Textes der Encyclopaedia Britannica.",Free1M:"1 Mio. Token","ReaderLM-v2_description":"Ein kleines Sprachmodell zur Konvertierung von reinem HTML in Markdown oder JSON",add_pair:"Neu",add_time_explain:"Das Datum, an dem dieses Modell zur Search Foundation hinzugefügt wurde.",api_integration_short:"Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert.",api_integrations:"API-Integrationen",api_key_update_message:"Wenn Sie Ihren alten API-Schlüssel ersetzen, wird der neue Schlüssel in der Benutzeroberfläche angezeigt, wenn Sie jina.ai besuchen. Zukünftige Aufladungen werden auf diesen neuen Schlüssel angewendet. Ihr alter Schlüssel bleibt gültig. Wenn Sie ihn also erneut verwenden möchten, bewahren Sie ihn bitte sicher auf.",api_key_update_title:"API-Schlüssel ersetzen",auto_recharge:"Automatisches Aufladen bei niedrigem Token-Guthaben",auto_recharge_confirm_message:"Möchten Sie die automatische Aufladung wirklich deaktivieren? Dadurch werden automatische Aufladungen bei niedrigem Token-Guthaben gestoppt und Ihr Dienst oder Ihre Anwendung kann unterbrochen werden.",auto_recharge_confirm_title:"Automatisches Aufladen deaktivieren",auto_recharge_description:"Empfohlen für einen unterbrechungsfreien Betrieb in der Produktion. Wenn Ihr Token-Guthaben unter den festgelegten Schwellenwert fällt, belasten wir Ihre gespeicherte Zahlungsmethode automatisch für das zuletzt gekaufte Paket, bis der Schwellenwert erreicht ist.",auto_recharge_enable:"Sie haben die automatische Aufladung bei niedrigen Token aktiviert",auto_recharge_enable_message:"Um die automatische Aufladung zu aktivieren, kaufen Sie bitte ein Paket, bei dem die automatische Aufladung auf „True“ eingestellt ist.",auto_recharge_enable_message2:"Bitte wählen Sie ein Paket aus, das gekauft werden soll, wenn die automatische Aufladung ausgelöst wird.",auto_recharge_enable_title:"Automatisches Aufladen aktivieren",auto_request:"Automatische Vorschau",auto_request_tooltip:"Automatische Vorschau der API-Antwort beim Ändern des Modells unter Verwendung von Hunderten von Token aus Ihrem API-Schlüssel. Deaktivieren Sie das manuelle Senden einer Anfrage, indem Sie auf „Antwort abrufen“ klicken.",autostart:"Die Einbettung beginnt nach einer kurzen Verzögerung automatisch",base64_description:"Die Einbettungen werden als Base64-codierte Zeichenfolge zurückgegeben. Effizienter für die Übertragung.",batch_job:"Batch-Job",batch_upload_hint:"Wir werden den API-Schlüssel und das untenstehende Modell verwenden, um die Dokumente zu verarbeiten.","bge-base-en-v1_5_description":"Ein robustes englisches Modell mit der richtigen Balance zwischen Leistung und Effizienz für den vielseitigen Einsatz.","bge-base-en_description":"Ein ausgewogenes englisches Modell, das für solide und zuverlässige Leistung ausgelegt ist.","bge-base-zh-v1_5_description":"Ein abgerundetes chinesisches Modell, das Leistungsfähigkeit und Effizienz in Einklang bringt.","bge-base-zh_description":"Ein vielseitiges chinesisches Modell, das Effizienz und robuste Leistung kombiniert.","bge-large-en-v1_5_description":"Ein leistungsstarkes englisches Modell, das erstklassige Einbettungen mit außergewöhnlicher Qualität bietet.","bge-large-en_description":"Ein leistungsstarkes englisches Modell, das für Einbettungen in Premiumqualität entwickelt wurde.","bge-large-zh-v1_5_description":"Ein chinesisches Modell mit hoher Kapazität, das hervorragende und detaillierte Einbettungen liefert.","bge-large-zh_description":"Ein leistungsstarkes chinesisches Modell, optimiert für Einbettungen der Spitzenklasse.","bge-m3_description":"Ein vielseitiges mehrsprachiges Modell mit umfangreichen Funktionen und hochwertigen Einbettungen.","bge-small-en-v1_5_description":"Ein optimiertes englisches Modell, das effiziente und qualitativ hochwertige Einbettungen liefert.","bge-small-en_description":"Ein effizientes englisches Modell für optimierte und genaue Einbettungen.","bge-small-zh-v1_5_description":"Ein kompaktes chinesisches Modell, das flinke und präzise Einbettungen ermöglicht.","bge-small-zh_description":"Ein agiles chinesisches Modell für effiziente und präzise Einbettungen.",binary_description:"Die Einbettungen werden als int8 gepackt. Viel effizienter für Speicherung, Suche und Übertragung.",bulk:"Batch-Einbettung",bulk_embedding_failed:"Batch-Einbettungsauftrag konnte nicht erstellt werden",buy_more_quota:"Laden Sie diesen API-Schlüssel mit weiteren Token auf",buy_poster:"Kaufen Sie eine gedruckte Kopie",cancel_button:"Stornieren",click_upload_btn_above:"Klicken Sie oben auf die Schaltfläche „Hochladen“, um zu beginnen.",clip_v2_description:"jina-clip-v2 ist ein 0,9B CLIP-Stil-Modell, das drei große Fortschritte bringt: mehrsprachige Unterstützung für 89 Sprachen, hohe Bildauflösung von 512 x 512 und Matryoshka-Darstellungslernen für verkürzte Einbettungen.",clip_v2_title:"clip-v2: Mehrsprachige multimodale Einbettungen",code:"Code",colbert_dimensions_explain:"Die Dimensionsgröße der Einbettung pro Token.",compatible:"Kompatibler Modus",compatible_explain:"Folgt demselben Anfrageformat wie unsere Texteinbettungsmodelle. So können Sie zwischen Modellen wechseln, ohne die Anfrage zu ändern. Beachten Sie, dass Bildeingaben in diesem Modus nicht unterstützt werden.",contact_sales:"Kontakt Vertrieb",contact_sales_description:"Kontaktieren Sie unser Vertriebsteam",cosine_similarity:"Kosinusähnlichkeit",debugging:"Prüfen",delete_pair:"Löschen",description:"@:landing_page.embedding_desc1",dimensions:"Ausgabedimensionen",dimensions_error:"Die Dimensionsgröße muss zwischen 1 und 1024 liegen.",dimensions_explain:"Kleinere Abmessungen ermöglichen eine effiziente Speicherung und Abfrage mit minimaler Beeinträchtigung dank der Matrjoschka-Darstellung.",dimensions_warning:"Aus Leistungsgründen empfehlen wir, die Dimensionsgröße über {_minDimension} zu halten.",document:"Dokumentieren",download:"Herunterladen",edit_text1_text:"Linken Text bearbeiten",edit_text2_text:"Bearbeiten Sie den richtigen Text",embedding_done:"{_Count} Sätze erfolgreich eingebettet.",embedding_none_description:"Verwenden Sie kein Einbettungsmodell",example_inputs:"Beispieleingaben",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"Detaillierte Informationen zu unseren Schulungsprozessen, Datenquellen und Auswertungen finden Sie in unserem technischen Bericht, der auf arXiv verfügbar ist.",answer1:"Jina CLIP <code>jina-clip-v2</code> ist ein erweitertes multimodales Einbettungsmodell, das Text-Text-, Text-Bild-, Bild-Bild- und Bild-Text-Abrufaufgaben unterstützt. Im Gegensatz zum ursprünglichen OpenAI CLIP, das mit der Text-Text-Suche Probleme hat, ist Jina CLIP ein hervorragender Textabrufer. <code>jina-clip-v2</code> bietet eine 3 % bessere Leistung als <code>jina-clip-v1</code> sowohl bei Text-Bild- als auch bei Text-Text-Abrufaufgaben, unterstützt 89 Sprachen für den mehrsprachigen Bildabruf, verarbeitet Bilder mit höherer Auflösung (512 x 512) und reduziert den Speicherbedarf mit Matryoshka-Darstellungen. Weitere Informationen finden Sie in unserem technischen Bericht.",answer17:"Ja, <code>jina-clip-v2</code> und <code>jina-clip-v1</code> können sowohl Bilder als auch Texte einbetten. Einbettungsmodelle für weitere Modalitäten werden in Kürze angekündigt!",answer18:"Bei Fragen zur Feinabstimmung unserer Modelle mit spezifischen Daten kontaktieren Sie uns bitte, um Ihre Anforderungen zu besprechen. Wir sind offen dafür, herauszufinden, wie unsere Modelle an Ihre Bedürfnisse angepasst werden können.",answer19:"Ja, unsere Dienste sind auf den Marktplätzen AWS, Azure und GCP verfügbar. Wenn Sie spezielle Anforderungen haben, kontaktieren Sie uns bitte unter sales AT jina.ai.",answer3:"Seit seiner Veröffentlichung am 18. September 2024 ist <code>jina-embeddings-v3</code> das beste mehrsprachige Modell und belegt den 2. Platz auf der MTEB-Bestenliste für englische Modelle mit weniger als 1 Milliarde Parametern. v3 unterstützt insgesamt 89 Sprachen, darunter die 30 mit der besten Leistung: Arabisch, Bengalisch, Chinesisch, Dänisch, Niederländisch, Englisch, Finnisch, Französisch, Georgisch, Deutsch, Griechisch, Hindi, Indonesisch, Italienisch, Japanisch, Koreanisch, Lettisch, Norwegisch, Polnisch, Portugiesisch, Rumänisch, Russisch, Slowakisch, Spanisch, Schwedisch, Thailändisch, Türkisch, Ukrainisch, Urdu und Vietnamesisch. Weitere Einzelheiten finden Sie im technischen Bericht zu <code>jina-embeddings-v3</code>.",answer4:"Unsere Modelle ermöglichen eine Eingabelänge von bis zu 8192 Token, was deutlich höher ist als bei den meisten anderen Modellen. Ein Token kann von einem einzelnen Buchstaben wie „a“ bis zu einem ganzen Wort wie „apple“ reichen. Die Gesamtzahl der eingebbaren Zeichen hängt von der Länge und Komplexität der verwendeten Wörter ab. Diese erweiterte Eingabefunktion ermöglicht unseren Modellen <code>jina-embeddings-v3</code> und <code>jina-clip</code> eine umfassendere Textanalyse und eine höhere Genauigkeit beim Kontextverständnis, insbesondere bei umfangreichen Textdaten.",answer5:"Ein einzelner API-Aufruf kann bis zu 2048 Sätze oder Texte verarbeiten und ermöglicht so eine umfassende Textanalyse in einer Anfrage.",answer6:"Sie können entweder <code>url</code> oder <code>bytes</code> im Feld <code>input</code> der API-Anfrage verwenden. Geben Sie für <code>url</code> die URL des Bildes an, das Sie verarbeiten möchten. Für <code>bytes</code> kodieren Sie das Bild im Base64-Format und schließen Sie es in die Anfrage ein. Das Modell gibt die Einbettungen des Bildes in der Antwort zurück.",answer7:"Bei Bewertungen der MTEB-Benchmarks Englisch, Mehrsprachig und LongEmbed übertrifft <code>jina-embeddings-v3</code> die neuesten proprietären Embeddings von OpenAI und Cohere bei englischen Aufgaben und übertrifft <code>multilingual-e5-large-instruct</code> bei allen mehrsprachigen Aufgaben. Mit einer Standardausgabedimension von 1024 können Benutzer die Embedding-Dimensionen dank der Integration von Matryoshka Representation Learning (MRL) ohne Leistungseinbußen auf 32 reduzieren.",answer8:"Der Übergang ist optimiert, da <a class='text-primary' href='https://api.jina.ai/v1/embeddings'>unser API-Endpunkt</a> mit den Eingabe- und Ausgabe-JSON-Schemata des <code>text-embedding-3-large</code>-Modells von OpenAI übereinstimmt. Diese Kompatibilität stellt sicher, dass Benutzer das OpenAI-Modell problemlos durch unseres ersetzen können, wenn sie den OpenAI-Endpunkt verwenden.",answer9:`Token werden basierend auf der Textlänge und der Bildgröße berechnet. Für Text in der Anfrage werden Token auf die Standardweise gezählt. Für Bilder werden die folgenden Schritte ausgeführt:

1. Kachelgröße: Jedes Bild wird in Kacheln unterteilt. Für <code>jina-clip-v2</code> sind die Kacheln 512 x 512 Pixel groß, während sie für <code>jina-clip-v1</code> 224 x 224 Pixel groß sind.

2. Abdeckung: Die Anzahl der Kacheln, die zum Abdecken des Eingabebildes erforderlich sind, wird berechnet. Auch wenn die Bildabmessungen nicht perfekt durch die Kachelgröße teilbar sind, werden Teilkacheln als vollständige Kacheln gezählt.

3. Gesamtzahl der Kacheln: Die Gesamtzahl der Kacheln, die das Bild abdecken, bestimmt die Kosten. Beispielsweise würde ein 600 x 600 Pixel großes Bild in v2 von 2 x 2 Kacheln (4 Kacheln) und in v1 von 3 x 3 Kacheln (9 Kacheln) abgedeckt.
4. Kostenberechnung: Für <code>jina-clip-v2</code> kostet jede Kachel 4000 Token, während für <code>jina-clip-v1</code> jede Kachel 1000 Token kostet.

Beispiel:
Für ein Bild mit den Abmessungen 600 x 600 Pixel:

• Mit <code>jina-clip-v2</code>

• Das Bild wird in 512 x 512 Pixel große Kacheln unterteilt.

• Die Gesamtzahl der erforderlichen Kacheln beträgt 2 (horizontal) x 2 (vertikal) = 4 Kacheln.

• Die Kosten für <code>jina-clip-v2</code> betragen 4*4000 = 16000 Token.

• Mit <code>jina-clip-v1</code>

• Das Bild wird in 224 x 224 Pixel große Kacheln unterteilt.
• Die Gesamtzahl der erforderlichen Kacheln beträgt 3 (horizontal) x 3 (vertikal) = 9 Kacheln.
• Die Kosten für jina-clip-v1 betragen 9*1000 = 9000 Token.`,question0:"Wie wurden die Jina-Embeddings-V3-Modelle trainiert?",question1:"Was sind die Jina-Clip-Modelle und kann ich sie für die Text- und Bildsuche verwenden?",question17:"Bieten Sie Modelle zum Einbetten von Bildern oder Audio an?",question18:"Können Jina Embedding-Modelle mit privaten oder Unternehmensdaten verfeinert werden?",question19:"Können Ihre Endpunkte privat auf AWS, Azure oder GCP gehostet werden?",question3:"Welche Sprachen unterstützen Ihre Modelle?",question4:"Was ist die maximale Länge für die Eingabe eines einzelnen Satzes?",question5:"Wie viele Sätze kann ich maximal in eine einzelne Anfrage einfügen?",question6:"Wie sende ich Bilder an die Jina-Clip-Modelle?",question7:"Wie schneiden Jina-Embeddings-Modelle im Vergleich zu den neuesten Embeddings von OpenAI und Cohere ab?",question8:"Wie nahtlos ist der Übergang von OpenAIs Text-Embedding-3-Large zu Ihrer Lösung?",question9:"Wie werden Token bei der Verwendung von Jina-Clip-Modellen berechnet?",title:"Häufige Fragen zu Einbettungen"},feature_8k1:"8192 Token-Länge",feature_8k_description1:"Pionierarbeit beim ersten Open-Source-Einbettungsmodell mit einer Länge von 8192 Token, das die Darstellung eines gesamten Kapitels in einem einzigen Vektor ermöglicht.",feature_cheap:"20x günstiger",feature_cheap_v1:"5x günstiger",feature_cheap_v1_description1:"Beginnen Sie mit kostenlosen Testversionen und genießen Sie eine unkomplizierte Preisstruktur. Erhalten Sie Zugang zu leistungsstarken Einbettungen für nur 20 % der OpenAI-Kosten.",feature_multilingual:"Bietet unter anderem zweisprachige Modelle für Deutsch-Englisch, Chinesisch-Englisch, ideal für mehrsprachige Anwendungen.",feature_on_premises:"Datenschutz zuerst",feature_on_premises_description1:"Stellen Sie unsere Einbettungsmodelle nahtlos direkt in Ihrer Virtual Private Cloud (VPC) bereit. Wird derzeit auf AWS Sagemaker unterstützt, mit bevorstehenden Integrationen für Microsoft Azure und Google Cloud Platform. Für maßgeschneiderte Kubernetes-Bereitstellungen wenden Sie sich für spezielle Unterstützung an unser Vertriebsteam.",feature_on_premises_description2:"Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um maßgeschneiderte Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und lokale Server zu erhalten.",feature_on_premises_description3:"Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und Microsoft Azure und bald auch in Google Cloud Services bereit, oder wenden Sie sich an unser Vertriebsteam, um angepasste Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und Ihre lokalen Server zu erhalten.",feature_on_premises_description4:"Stellen Sie Jina Embedding- und Reranker-Modelle vor Ort mit AWS SageMaker, Microsoft Azure oder Google Cloud Services bereit und stellen Sie sicher, dass Ihre Daten sicher unter Ihrer Kontrolle bleiben.",feature_solid:"Klassenbester",feature_solid_description1:"Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests anhand der SOTA-Modelle, um eine beispiellose Leistung zu gewährleisten.",feature_top_perform1:"Nahtlose Integration",feature_top_perform_description1:"Vollständig kompatibel mit der API von OpenAI. Lässt sich mühelos in über 10 Vektordatenbanken und RAG-Systeme integrieren und sorgt so für ein reibungsloses Benutzererlebnis.",file_required:"Datei ist erforderlich",file_size_exceed:"Maximale Dateigröße {_size} überschritten",file_type_not_supported:"Dateityp nicht unterstützt",fill_example:"Füllen Sie ein Beispiel aus",float_description:"Die Einbettungen werden als Liste von Gleitkommazahlen zurückgegeben. Am gebräuchlichsten und am einfachsten zu verwenden.",free:"Frei",generate_api_key_error:"Die Generierung des API-Schlüssels ist fehlgeschlagen.",generating_visualization:"Visualisierung wird erstellt...",get_new_key_button:"Holen Sie sich einen neuen Schlüssel",get_new_key_button_explain:"Wenn Sie sich für einen neuen Schlüssel entscheiden, geht der mit dem alten Schlüssel verbundene Nutzungsverlauf verloren.",get_new_key_survey:"Nehmen Sie an der Umfrage teil, helfen Sie uns, Ihre Nutzung zu verstehen, und erhalten Sie kostenlos einen neuen API-Schlüssel!",includes:"Token gültig für:",index_and_search:"Index & Suche",index_and_search1:"Index & Suche",input:"Anfrage",input_api_key_error1:"Ihr API-Schlüssel ist ungültig!",input_length:"Eingabelänge",input_type:"Als Dokument/Abfrage einbetten",input_type_explain:"Derselbe Input kann je nach Suchfunktion entweder als Abfrage oder als eingebettetes Dokument dienen.",integrate:"Integrieren","jina-clip-v1_description":"Multimodale Einbettungsmodelle für Bilder und englischen Text","jina-clip-v2_description":"Mehrsprachige multimodale Einbettungen für Texte und Bilder","jina-colbert-v1-en_description":"Verbessertes ColBERT mit 8K-Token-Länge zum Einbetten und Neuordnen von Aufgaben","jina-colbert-v2_description":"Der beste mehrsprachige ColBERT mit Top-Leistung beim Einbetten und Neuranking","jina-embedding-b-en-v1_description":"Die erste Version des Jina-Embedding-Modells, das OG.","jina-embeddings-v2-base-code_description":"Optimiert für die Suche nach Code und Dokumentzeichenfolgen","jina-embeddings-v2-base-de_description":"Zweisprachige Einbettungen Deutsch-Englisch mit SOTA-Leistung","jina-embeddings-v2-base-en_description":"Auf Augenhöhe mit text-embedding-ada002 von OpenAI","jina-embeddings-v2-base-es_description":"Zweisprachige Einbettungen Spanisch-Englisch mit SOTA-Leistung","jina-embeddings-v2-base-zh_description":"Zweisprachige Einbettungen Chinesisch-Englisch mit SOTA-Leistung","jina-embeddings-v2-small-en_description":"Optimiert für geringe Latenz und geringen Speicherbedarf","jina-embeddings-v3_description":"Frontier-Mehrsprachigkeits-Einbettungsmodell mit SOTA-Leistung","jina-reranker-v1-base-en_description":"Unser erstes Reranker-Modell maximiert die Such- und RAG-Relevanz","jina-reranker-v1-tiny-en_description":"Das schnellste Reranker-Modell, am besten geeignet für die zuverlässige Bewertung einer großen Anzahl von Dokumenten","jina-reranker-v1-turbo-en_description":"Die beste Kombination aus schneller Inferenzgeschwindigkeit und präzisen Relevanzwerten","jina-reranker-v2-base-multilingual_description":"Das neueste und beste Reranker-Modell mit mehrsprachiger Unterstützung für Funktionsaufrufe und Codesuche.",key:"API-Schlüssel",key_enter_placeholder:"Bitte geben Sie Ihren API-Schlüssel ein",key_enter_placeholder_to_topup:"Geben Sie den API-Schlüssel ein, den Sie aufladen möchten",key_to_top_up:"Möchten Sie einen anderen API-Schlüssel aufladen? Fügen Sie ihn oben ein und klicken Sie auf „Speichern“.",key_warn:"Stellen Sie sicher, dass Sie Ihren API-Schlüssel an einem sicheren Ort aufbewahren. Andernfalls müssen Sie einen neuen Schlüssel generieren",key_warn_v2:"Dies ist Ihr einzigartiger Schlüssel. Bewahren Sie ihn sicher auf!",language_explain:"Dieses Modell unterstützt am besten die Sprache {_Language}.",last_7_days:"Verwendung",late_chunking:"Spätes Chunking",late_chunking_explain:"Wenden Sie die Late-Chunking-Technik an, um die Long-Context-Funktionen des Modells zum Generieren kontextbezogener Chunk-Einbettungen zu nutzen.",learn_more:"Erfahren Sie mehr",learn_poster:"Erfahren Sie, wie wir es gemacht haben",learning1:"Erfahren Sie mehr über Einbettungen",learning1_description:"Wo soll man mit Einbettungen anfangen? Wir geben dir Deckung. Erfahren Sie mehr über Einbettungen von Grund auf mit unserem umfassenden Leitfaden.",length:"Tokenlänge",manage_billing:"Rechnung verwalten",manage_billing_tip:"Verwalten Sie Ihre Rechnungsinformationen, erhalten Sie Rechnungen und richten Sie die automatische Aufladung ein.",manage_quota1:"API-Schlüssel und Abrechnung",max_file_size:"Maximal zulässige Größe: {_maxSize}.",maximize_tooltip:"Maximieren Sie dieses Panel mit Umschalt+1",mistake_contact:"Wenn Sie glauben, dass es sich hierbei um einen Fehler handelt, nehmen Sie bitte Kontakt mit uns auf.",mminput_placeholder:"Text, Bild-URL, Bild-Base64-Zeichenfolge",model_required:"Modell ist erforderlich",more_models:"{_numMore} weitere Modelle",more_than_two2:"Bitte geben Sie mehr als zwei Dokumente ein, also mehr als zwei Zeilen.",multi_embedding:"Multi-Vektor",multi_embedding_explain:"Dieses Modell gibt eine Reihe kontextualisierter Einbettungen für eine bestimmte Eingabe zurück. Jedes Token in der Eingabe wird einem Vektor in der Ausgabe zugeordnet.",multilingual:"Mehrsprachiger Support",multimodal:"Multimodal",multimodal_explain:"Dieses Modell kann sowohl Text- als auch Bildeingaben kodieren und ist daher ideal für multimodale Suchaufgaben.",new:"Neues Modell",no_data1:"Fügen Sie ein Satzpaar hinzu, um die Ähnlichkeit zu berechnen",none:"Keiner",normalized:"L2-Normalisierung",normalized_explain:"Skaliert die Einbettung so, dass ihre euklidische (L2) Norm 1 wird, wobei die Richtung erhalten bleibt. Nützlich, wenn es im weiteren Verlauf um Skalarprodukt, Klassifizierung und Visualisierung geht.",oncsp:"Auf CSP",onprem:"Vor Ort",open_tensorboard:"Öffnen Sie den Visualizer",opensource:"Betriebssystem",opensource_explain:"Dieses Modell ist Open Source und auf Hugging Face verfügbar. Klicken Sie auf diese Schaltfläche, um das Modell auf Hugging Face anzuzeigen.",original_documents:"Einzubettende Sätze",original_documents_hint:"Geben Sie hier Ihre Sätze ein. Jede neue Zeile wird als separater Satz/Dokument betrachtet.",output:"Antwort",output_dim:"Maße",output_dim_explain:"Die Ausgabedimension eines Einbettungsvektors aus diesem Modell ist {_outputDim}.",output_dimension:"Ausgabedimensionen",pairwise_test:"Paarweise",per_k:"/ 1K-Token",per_m:"/ 1 Mio. Token",please_fill_docs_first:"Bitte geben Sie vor der Suche unten einige Sätze ein.",please_select_model:"Bitte wählen Sie ein Einbettungsmodell oder ein Reranker-Modell aus",poster:"Die Evolution des Einbettungsplakats",poster_description:"Entdecken Sie das ideale Poster für Ihren Raum mit fesselnden Infografiken oder atemberaubenden Bildern, die die Entwicklung der Texteinbettungsmodelle seit 1950 nachzeichnen.",pricing:"API-Preise",pricing_desc:"Die API-Preise basieren auf der Token-Nutzung. Ein API-Schlüssel gibt Ihnen Zugriff auf alle Produkte der Suchgrundlage.",protectData1:"Anforderungsdaten und Dokumente werden nicht für Trainingsmodelle verwendet.",protectData2:"Datenverschlüsselung während der Übertragung (TLS 1.2+) und im Ruhezustand (AES-GCM 256).",protectData3:"SOC 2 und DSGVO-konform.",protect_data:"Schützen Sie Ihre Daten",public_cloud_integration:"Mit <b>{_numPartners}</b> Cloud-Service-Anbietern",public_cloud_integration_desc:"Verwendet Ihr Unternehmen AWS oder Azure? Dann setzen Sie unsere Suchgrundlagenmodelle direkt auf diesen Plattformen in Ihrem Unternehmen ein, damit Ihre Daten sicher und konform bleiben.",query:"Abfrage",raise_issue:"Problem melden",rank_none_description:"Verwenden Sie kein Reranker-Modell",read_api_docs:"API-Spezifikation",read_release_note:"Versionshinweis lesen","reader-lm-05b_description":"Ein kleines Sprachmodell zur Konvertierung von reinem HTML in Markdown","reader-lm-15b_description":"Ein kleines Sprachmodell zur Konvertierung von reinem HTML in Markdown",recharge_threshold:"Aufladeschwelle",refresh:"Aktualisierung",refresh_key_tooltip1:"Holen Sie sich kostenlos einen neuen API-Schlüssel",refresh_token_count1:"Aktualisieren Sie, um verfügbare Token des aktuellen API-Schlüssels zu erhalten",regenerate:"Regenerieren",remaining:"Verfügbare Token",remaining_left:"Sie haben noch <b>{_leftTokens}</b> Token im unten stehenden API-Schlüssel übrig.",request_number:"Anfragezeiten",request_path:"Anforderungsendpunkt",results_as_final_result:"#docs als Endergebnis",results_fed_to_reranker:"#docs an Reranker weitergeleitet",retry:"Wiederholen",return_base64:"Base64 (als String)",return_binary:"Binär (als int8 gepackt)",return_float:"Standard (als Float)",return_format:"Einbettungsformat",return_format_explain:"Neben dem Float können Sie auch die Rückgabe als Binärwert für einen schnelleren Vektorabruf oder als Base64-Kodierung für eine schnellere Übertragung anfordern.",return_format_title:"Zurückgebender Datentyp",return_ubinary:"Binär (als uint8 gepackt)",right_api_key_to_charge:"Bitte geben Sie zum Aufladen den richtigen API-Schlüssel ein",running:"Aktiv",score:"Punktzahl",search:"Suchen",search_hint:"Geben Sie Ihre Suche in die unten aufgeführten Sätze ein.",select_classify_model:"Klassifikator auswählen",select_embedding_model:"Wählen Sie Einbettungen aus",select_rerank_model:"Reranker auswählen",show_api_key:"API-Schlüssel anzeigen",size:"Parameter",size_explain:"Die Anzahl der Parameter im Modell beträgt {_size}. Beachten Sie, dass dies nicht die Größe der Modelldatei ist.",sleeping:"Inaktiv",start_batch:"Starten Sie die Batch-Einbettung",start_embedding:"Index",status_explain:"Unsere serverlose Architektur kann in Zeiten geringer Nutzung bestimmte Modelle entlasten. Bei aktiven Modellen erfolgt die Reaktion sofort. Inaktive Modelle benötigen bei der ersten Anfrage einige Sekunden zum Laden. Nach der Aktivierung werden Folgeanfragen schneller bearbeitet.",task_type:"Nachgelagerte Aufgabe",task_type_classification:"Einstufung",task_type_classification_explain:"Textklassifizierung.",task_type_explain:"Wählen Sie die nachgelagerte Aufgabe aus, für die die Einbettungen verwendet werden. Das Modell gibt die optimierten Einbettungen für diese Aufgabe zurück.",task_type_none_explain:"Es wird kein Adapter verwendet. Es wird eine generische Einbettung zurückgegeben, die zum Debuggen oder Hacken nützlich ist.",task_type_retrieval_passage:"Abrufpassage",task_type_retrieval_passage_explain:"Einbetten von Dokumenten in eine Abfrage-/Dokumentenabrufaufgabe.",task_type_retrieval_query:"Abfrage abfragen",task_type_retrieval_query_explain:"Einbetten von Abfragen in eine Abfragedokument-Abrufaufgabe.",task_type_separation:"Trennung",task_type_separation_explain:"Dokumente clustern, Korpus visualisieren.","task_type_text-matching":"Textübereinstimmung","task_type_text-matching_explain":"Semantische Textähnlichkeit, allgemeine symmetrische Abfrage, Empfehlung, Ähnliches finden, Deduplizierung.",tax_may_apply:"Abhängig von Ihrem Standort werden Ihnen möglicherweise USD, EUR oder andere Währungen in Rechnung gestellt. Es können Steuern anfallen.",text1:"Links",text2:"Rechts",three_ways:"Drei Möglichkeiten zum Kauf",three_ways_desc:"Abonnieren Sie unsere API, kaufen Sie über Cloud-Anbieter oder erwerben Sie eine kommerzielle Lizenz für Ihr Unternehmen.",title:"Einbettungs-API",token_example:"Ein Tweet kostet etwa 20 Token, ein Nachrichtenartikel etwa 1000 Token und Charles Dickens‘ Roman „Eine Geschichte zweier Städte“ hat über eine Million Token.",token_length_explain:"Die maximale Länge der Eingabe-Token-Sequenz beträgt für dieses Modell {_tokenLength}.",tokens:"Token",tools:"Werkzeuge",top_up_button:"Alten Schlüssel aufladen",top_up_button_explain:"Die Integration dieses API-Schlüssels bietet eine professionellere Lösung und macht häufige Schlüsseländerungen überflüssig. Nutzungsdaten werden gespeichert und sind jederzeit abrufbar.",top_up_warning_message1:"Der aktuelle API-Schlüssel hat noch {_remainedTokens} Token und wird durch einen neuen Schlüssel mit {_freeTokens} Token ersetzt. Sie können den alten Schlüssel weiterhin verwenden oder aufladen, wenn Sie ihn sicher aufbewahrt haben. Wie wollen Sie fortfahren?",top_up_warning_title:"Ersetzen Sie den alten API-Schlüssel",total_documents:"Einbettungsfortschritt: {_Verarbeitet}/{_Count} Sätze.",tuning:"Feinabstimmung",turnstile_error:"Wir können keinen API-Schlüssel generieren, da wir nicht überprüfen konnten, ob Sie ein Mensch sind.",turnstile_unsupported:"Wir können keinen API-Schlüssel generieren, da Ihr Browser nicht unterstützt wird.",ubinary_description:"Die Einbettungen werden als uint8 gepackt. Viel effizienter für Speicherung, Suche und Übertragung.",upload:"Hochladen",upload_file:"Klicken Sie hier, um eine Datei hochzuladen",usage:"Verwendung",usage_amount:"Token",usage_history:"Nutzung in den letzten 7 Tagen",usage_history_explain:"Die Daten liegen nicht in Echtzeit vor und können einige Minuten verzögert sein.",usage_reason:"Beschreibung",usage_reason_consume:"Gebraucht",usage_reason_purchase:"Gekauft",usage_reason_transfer_in:"Überweisung in",usage_reason_transfer_out:"Auszahlen",usage_reason_trial:"Versuch",usage_rerank:"Verwendung",usage_time:"Terminzeit",v3_description:"<code>jina-embeddings-v3</code> ist ein bahnbrechendes mehrsprachiges Texteinbettungsmodell mit 570 Millionen Parametern und 8192 Tokenlänge, das die neuesten proprietären Einbettungen von OpenAI und Cohere auf MTEB übertrifft. Lesen Sie unten unseren Blogbeitrag und die Forschungsarbeit.",v3_title:"v3: Frontier Mehrsprachige Einbettungen",vector_database_integration1:"Integrationen",vector_database_integration2:"Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Kopieren Sie zunächst einfach Ihren API-Schlüssel und fügen Sie ihn in eine der aufgeführten Integrationen ein, um einen schnellen und reibungslosen Start zu ermöglichen.",vector_database_integration3:"Unsere Embedding & Reranker API ist nativ in verschiedene bekannte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Um zu beginnen, kopieren Sie einfach Ihren API-Schlüssel und fügen Sie ihn in eine der aufgelisteten Integrationen ein, um schnell und nahtlos zu starten.",vector_database_integration_description:"Integrieren Sie die Jina Embeddings API nahtlos und einfach in alle unten aufgeführten Vektordatenbanken, LLM-Orchestrierungs-Frameworks und RAG-Anwendungen. Unsere Tutorials zeigen Ihnen wie.",view_details:"Details anzeigen",visualization_example:"Zuordnung aller Sätze aus diesem Abschnitt zu einem 3D-Vektorraum",visualization_example_you_can:"Nutzen Sie unsere API unten, Sie können es auch tun!",visualize:"Visualisieren",visualize_done:"Die Visualisierung ist abgeschlossen. Sie können nun auf die obere Schaltfläche klicken, um den Visualizer zu öffnen.",wait_for_processing:"Ihre Anfrage wird bearbeitet.",wait_stripe:"Stripe-Zahlung wird geöffnet, bitte warten",what_are_embedding:"Was sind Einbettungen?",what_are_embedding_answer:`Stellen Sie sich vor, Sie bringen einem Computer bei, die nuancierten Bedeutungen von Wörtern und Phrasen zu erfassen. Traditionelle Methoden, die auf starren, regelbasierten Systemen basieren, scheitern, weil Sprache zu komplex und fließend ist. Hier kommen Text-Embeddings ins Spiel: eine leistungsstarke Lösung, die Text in eine Sprache der Zahlen übersetzt – genauer gesagt in Vektoren in einem hochdimensionalen Raum.

Betrachten Sie die Ausdrücke „sonniges Wetter“ und „klarer Himmel“. Für uns zeichnen sie ein ähnliches Bild. Durch die Linse der Embeddings werden diese Ausdrücke in numerische Vektoren umgewandelt, die in diesem mehrdimensionalen Raum nahe beieinander liegen und ihre semantische Verwandtschaft erfassen. Bei dieser Nähe im Vektorraum geht es nicht nur darum, dass Wörter oder Ausdrücke ähnlich sind; es geht darum, Kontext, Stimmung und sogar subtile Bedeutungsnuancen zu verstehen.

Warum ist dieser Durchbruch wichtig? Zunächst einmal überbrückt er die Lücke zwischen der Vielfalt der menschlichen Sprache und der Rechenleistung von Algorithmen. Algorithmen sind hervorragend darin, Zahlen zu verarbeiten, nicht darin, Texte zu interpretieren. Durch die Umwandlung von Text in Vektoren ermöglichen Einbettungen diesen Algorithmen, Sprache auf eine Weise zu „verstehen“ und zu verarbeiten, die zuvor unerreichbar war.

Die praktischen Anwendungen sind umfangreich und vielfältig. Ob es darum geht, Inhalte zu empfehlen, die Ihren Interessen entsprechen, eine Konversations-KI zu betreiben, die überraschend menschlich wirkt, oder sogar subtile Muster in großen Textmengen zu erkennen – Einbettungen sind der Schlüssel. Sie ermöglichen Maschinen, Aufgaben wie Stimmungsanalyse, Sprachübersetzung und vieles mehr auszuführen, mit einem immer nuancierteren und verfeinerten Sprachverständnis.`,what_is_a_token:"Ein Token ist in der Textverarbeitung eine Einheit, oft ein Wort. Zum Beispiel: „Jina AI ist großartig!“ wird zu fünf Token, einschließlich der Interpunktion.",why_do_you_need:"Auswahl der richtigen Einbettungen",why_do_you_need_after:"Mithilfe tiefer neuronaler Netze und LLMs stellen unsere Einbettungsmodelle multimodale Daten in einem optimierten Format dar, verbessern das Maschinenverständnis, die effiziente Speicherung und ermöglichen fortschrittliche KI-Anwendungen. Diese Einbettungen spielen eine entscheidende Rolle beim Verständnis der Daten, der Verbesserung des Benutzerengagements, der Überwindung von Sprachbarrieren und der Optimierung von Entwicklungsprozessen.",why_do_you_need_before:"Unsere Einbettungsmodelle sind für die Abdeckung vielfältiger Such- und GenAI-Anwendungen konzipiert.",why_need_1_description:"Unser von JinaBERT bereitgestelltes Kerneinbettungsmodell ist für ein breites Anwendungsspektrum konzipiert. Es zeichnet sich durch das Verständnis detaillierter Texte aus und eignet sich daher ideal für die semantische Suche, Inhaltsklassifizierung und komplexe Sprachanalyse. Seine Vielseitigkeit ist unübertroffen und unterstützt die Erstellung fortschrittlicher Stimmungsanalysetools, Textzusammenfassungen und personalisierter Empfehlungssysteme.",why_need_1_title:"Allgemeine Einbettungen",why_need_2_description:"Unsere zweisprachigen Modelle erleichtern die Kommunikation über Sprachen hinweg und verbessern mehrsprachige Plattformen, globalen Kundensupport und die Entdeckung mehrsprachiger Inhalte. Diese Modelle wurden für die Beherrschung von Deutsch-Englisch- und Chinesisch-Englisch-Übersetzungen entwickelt. Sie vereinfachen die Interaktion und fördern das Verständnis zwischen verschiedenen Sprachgruppen.",why_need_2_title:"Zweisprachige Einbettungen",why_need_3_description:"Unser auf Entwickler zugeschnittenes Code-Einbettungsmodell optimiert Codierungsaufgaben wie Zusammenfassung, Codegenerierung und automatische Überprüfungen. Es steigert die Produktivität, indem es tiefere Einblicke in Codestrukturen bietet und Verbesserungen vorschlägt, was es für die Entwicklung fortschrittlicher IDE-Plugins, automatischer Dokumentation und modernster Debugging-Tools unerlässlich macht.",why_need_3_title:"Code-Einbettungen",why_need_4_description:"Jina CLIP ist unser neuestes multimodales Einbettungsmodell für Bild und Text. Eine große Verbesserung gegenüber OpenAI CLIP besteht darin, dass dieses einzelne Modell sowohl für Text-Text-Abrufe als auch für Text-Bild-, Bild-Text- und Bild-Bild-Abrufaufgaben verwendet werden kann! Also ein Modell, zwei Modalitäten, vier Suchrichtungen!",why_need_4_title:"Multimodale Einbettungen",write_email_here:"Bitte geben Sie die E-Mail-Adresse ein, an die Sie nach Abschluss den Download-Link erhalten möchten.",you_can_leave:"Sie können diese Seite verlassen und wir senden Ihnen nach Abschluss den Download-Link zu."},A={description:"Multimodale und mehrsprachige Einbettungen von Weltklasse."},I={contractType:{department:"Abteilungslizenz",poc:"Proof of Concept (3-6 Monate)",standard:"Standard Enterprise-Lizenz",title:"Vertragsart"},department:{businessSponsor:"Sponsor der Geschäftseinheit",executionModel:"Ausführungsmodell",growth:{high:"Klares unternehmensweites Potenzial",highDesc:"Strategische Initiative mit geplanter unternehmensweiter Einführung",limited:"Beschränkt auf Abteilung",limitedDesc:"Konzentrieren Sie sich mit Standard-Support auf die Bedürfnisse einzelner Abteilungen",steady:"Potenzial für andere Abteilungen",steadyDesc:"Geplanter Ausbau auf 2-3 Abteilungen innerhalb von 12 Monaten"},growthTitle:"Wachstumskurve",sponsorDescription:"Engagierter leitender Sponsor, der die Implementierung vorantreibt, strategische Richtung vorgibt und sicherstellt, dass Ressourcen zugewiesen werden"},descriptions:{contractType:{department:"Bereitstellung in einer einzelnen Abteilung mit der Flexibilität, später zu erweitern",poc:"Testbereitstellung zum Testen von Modellen in Ihrer spezifischen Umgebung und Ihren Anwendungsfällen",standard:"Vollständige Unternehmensbereitstellung mit uneingeschränkter Modellnutzung"},department:{growth:"Pläne zur Ausweitung der Modellnutzung auf andere Abteilungen",sponsorship:"Gibt an, ob eine umsatzgenerierende Abteilung die Bereitstellung unterstützt"},features:{csm:"Persönlicher Kundenerfolgsmanager für strategische Beratung und Unterstützung",priority:"Garantiert schnelle Reaktion bei kritischen Problemen",training:"Hilfe beim Vortraining oder der Feinabstimmung von Modellen für Ihre spezifischen Daten"},models:{clip:"Verarbeiten Sie sowohl Bilder als auch Text für multimodale Anwendungen",colbert:"Spezialisiertes Modell für hochpräzisen Dokumentenabruf",embeddings:"Texteinbettungsmodell für semantische Suche und Textähnlichkeit",reader:"Konvertiert HTML-Inhalte in ein sauberes Markdown-Format",reranker:"Optimiert die Suchergebnisse für eine bessere Relevanz"},payment:{annual:"Einmalige Jahreszahlung für vereinfachte Abrechnung",quarterly:"Regelmäßige Zahlungen alle drei Monate"},poc:{duration:"Zeitplan zum Testen und Validieren der Modellleistung in Ihrer Umgebung",metrics:"Verfolgen Sie wichtige Leistungsindikatoren und Modellwirksamkeit"},support:{enterprise:"Umfassende Supportabdeckung mit höchster Priorität",premium:"Zusätzliche Beratungsstunden und schnellere Reaktionszeiten",standard:"Grundlegender technischer Support und Anleitung zur Implementierung"},usage:{business:"Wie viele unterschiedliche Unternehmen werden Anwendungen nutzen, die auf unseren Modellen basieren?",consumer:"Wie viele Endbenutzer werden monatlich mit unseren Modellen interagieren"}},features:{csm:"Engagierter Customer Success Manager",priority:"SLA mit vorrangiger Antwort (4 Stunden)",title:"Zusätzliche Merkmale",training:"Unterstützung bei benutzerdefiniertem Modelltraining"},interests:"Ich bin an dieser konfigurierten kommerziellen Lizenz interessiert (${_Price})",labels:{basePrice:"Grundpreis",custom:"Kontaktieren Sie den Vertrieb für individuelle Preise",discountApplied:"Rabatt angewendet",included:"Im Grundpreis enthalten",learnMore:"Mehr erfahren",priceQuarterly:"Preis pro Quartal",selectAll:"Alle Modelle auswählen",selectSupport:"Supportstufe auswählen",totalPrice:"Gesamtpreis",upTo:"Bis zu {count}"},messaging:{additionalFeatures:"Zusätzliche Funktionen enthalten:",baseModelIncluded:"Basis-Embeddings-Modell (jina-embeddings-v3) enthalten",deptIncludes:"Die Abteilungslizenz beinhaltet:",deptReviews:"Vierteljährliche Geschäftsüberprüfungssitzungen",deptRoadmap:"Roadmap-Planung für die Unternehmenserweiterung",deptSponsor:"Abstimmungssitzungen mit leitenden Sponsoren",deptWorkshops:"Abteilungsübergreifende Kollaborationsworkshops",enterpriseAlert:"Ihr Nutzungsniveau deutet auf eine unternehmensweite Möglichkeit hin. Lassen Sie uns einen Anruf vereinbaren, um eine individuelle Unternehmensvereinbarung zu besprechen.",noModelsSelected:"Keine zusätzlichen Modelle ausgewählt. Basis-Einbettungsmodell wird verwendet.",pocCheckins:"Zweiwöchentliche Check-ins mit dem technischen Team",pocIncludes:"Das POC-Paket umfasst:",pocMetrics:"Dashboard zur Nachverfolgung von Erfolgsmetriken",pocMigration:"Migrationsunterstützung zur Volllizenz",pocTemplate:"Vorlage für die Dokumentation von POC-Ergebnissen",selectedModels:"Ausgewählte Modelle:",standardFeatures:"Funktionen der Standardlizenz:",supportTierIncluded:"{tier} Supportstufe inklusive {hours}",usageTierBusiness:"Nutzungsstufe für Unternehmen: Bis zu {count} Geschäftskonten",usageTierConsumer:"Nutzungsstufe für Verbraucher: Bis zu {count} aktive Benutzer pro Monat"},models:{clip:"jina-clip-v2",colbert:"jina-colbert-v2",description:"Wählen Sie die Modelle aus, die in Ihr kommerzielles Paket aufgenommen werden sollen",embeddings:"jina-einbettungen-v3",lm:"Leser-lm",reranker:"jina-reranker-v2",title:"Ausgewählte Modelle"},payment:{annual:"Jährliche Abrechnung (10 % Rabatt)",features:"Enthaltene Funktionen",quarterly:"Vierteljährliche Abrechnung",title:"Zahlungsbedingungen"},poc:{description:"POC umfasst die Verfolgung von Erfolgsmetriken und einen Upgrade-Pfad zur Volllizenz",duration:"POC-Dauer (Monate)"},pricing:{annual:"Jahr",cta:"Sprechen Sie mit unserem Vertrieb",disclaimer:"Dieser Preisrechner liefert eine Schätzung. Ihr endgültiger Preis kann je nach spezifischen Anforderungen, Volumenverpflichtungen und benutzerdefinierten Konfigurationen variieren. Kontaktieren Sie unser Vertriebsteam für ein detailliertes Angebot.",frequency:"${price} / {frequency}",oneTime:"${price} einmalig",pocTotal:"{months}-Monats-POC-Preis: ${price}",quarterly:"Quartal",title:"Geschätzter Preis"},short_title:"Konfigurationslizenz",subtitle:"Konfigurieren Sie Ihre Unternehmenslizenz für Jina AI-Modelle",support:{enterprise:"Prämie",hoursQuarter:"{hours} Stunden/Quartal",premium:"Standard",standard:"Lite",title:"Support-Stufe"},title:"Enterprise Lizenz Konfigurator",tooltips:{annualDiscount:"Sparen Sie 10 % bei jährlicher Zahlung",businessSponsor:"Wenn Sie als Sponsor eine Geschäftseinheit haben, können Sie unter Umständen zusätzliche Rabatte erhalten",pocDuration:"Wählen Sie die Dauer Ihres Proof of Concept-Zeitraums",supportTier:"Wählen Sie die Supportstufe, die Ihren Anforderungen am besten entspricht",usageLimit:"Kontaktieren Sie uns für individuelle Preise, wenn Sie diese Grenzen überschreiten"},usage:{business:"B2B (Geschäftskonten)",businessCount:"Anzahl der Geschäftskonten",businessDescription:"Anzahl unterschiedlicher Geschäftskonten unter Verwendung unserer Modelle",consumer:"B2C (Endbenutzer)",consumerCount:"Monatlich aktive Benutzer",consumerDescription:"Anzahl der monatlich aktiven Endbenutzer über alle Anwendungen hinweg",title:"Nutzungskonfiguration"}},M={answer1:"Jina AI ist auf multimodale KI-Technologien spezialisiert, darunter Model-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving. Wir nutzen fortschrittliche Tools wie Kubernetes und serverlose Architekturen, um robuste, skalierbare und produktionsbereite Lösungen zu erstellen.",answer10:"Je nach Art des Projekts und den Bedürfnissen des Kunden bieten wir verschiedene Lizenzoptionen an. Detaillierte Konditionen können mit unserem Vertriebsteam besprochen werden.",answer11:"Wir bieten Dienstleistungen weltweit an, mit unserem Hauptsitz in Berlin, Europa, und weiteren Büros in Peking und Shenzhen.",answer12:"Ja, wir bieten Vor-Ort-Support an, insbesondere für Kunden in der Nähe unserer Büros in Berlin, Peking und Shenzhen. Für andere Standorte streben wir einen bestmöglichen Remote-Support an und können bei Bedarf auch einen Vor-Ort-Support arrangieren.",answer2:"Unsere Expertise erstreckt sich über ein breites Spektrum und umfasst große Sprachmodelle, Text-, Bild-, Video- und Audioverständnis, neuronale Suche und generative Kunst.",answer3:"Ja, unsere Lösungen sind skalierbar und produktionsbereit. Wir erstellen unsere Lösungen mithilfe cloudnativer Technologien, die eine effiziente Skalierung und zuverlässige Leistung in Produktionsumgebungen ermöglichen.",answer4:"Unsere Dienstleistungen sind vielseitig und anpassungsfähig und eignen sich daher für eine Vielzahl von Branchen, darunter E-Commerce, Legal Tech, digitales Marketing, Gaming, Gesundheitswesen, Finanzen und viele mehr.",answer5:"Über das Kontaktformular auf dieser Seite können Sie mit unserem Vertriebsteam in Kontakt treten. Wir besprechen gerne Ihre Projektanforderungen und wie unsere Lösungen Ihrem Unternehmen helfen können.",answer6:"Wir bieten kontinuierliche Unterstützung, um den reibungslosen Betrieb unserer Lösungen sicherzustellen. Dazu gehören Fehlerbehebung, regelmäßige Updates und Verbesserungen basierend auf Ihrem Feedback und Ihren Bedürfnissen.",answer7:"Die Projektdauer variiert je nach Komplexität und Umfang des Projekts. Nachdem wir Ihre Anforderungen verstanden haben, können wir einen genaueren Kostenvoranschlag erstellen.",answer8:"Datensicherheit hat für uns oberste Priorität. Wir halten uns an strenge Datenschutzrichtlinien und -vorschriften, um sicherzustellen, dass Ihre Daten sicher und vertraulich sind.",answer9:"Die Preisgestaltung richtet sich nach der Komplexität und den Anforderungen des Projekts. Wir bieten sowohl projektbasierte als auch Retainer-Preismodelle an. Für weitere Informationen wenden Sie sich bitte an unser Vertriebsteam.",question1:"Worauf ist Jina AI spezialisiert?",question10:"Welche Lizenzbedingungen gelten für Ihre Lösungen?",question11:"Was ist Ihr Servicegebiet?",question12:"Bieten Sie Vor-Ort-Support an?",question2:"Mit welchen Arten von KI arbeitet Jina AI?",question3:"Sind Ihre Lösungen skalierbar und produktionsreif?",question4:"Welche Branchen können von den Lösungen von Jina AI profitieren?",question5:"Wie starten wir ein Projekt mit Jina AI?",question6:"Welche Unterstützung leisten Sie nach der Implementierung einer Lösung?",question7:"Was ist die typische Dauer für ein Projekt?",question8:"Wie schützt Jina AI meine Daten?",question9:"Wie ist die Preisstruktur für Ihre Dienstleistungen?"},D="FAQ",E={text:"Lebewohl.",toggle_btn:"Lassen Sie dieses Fenster bei Ihrem nächsten Besuch geöffnet",warning_message:"Dieses Fenster wird automatisch geöffnet, wenn Sie jina.ai besuchen. Sie müssen es schließen, um den Inhalt der Website anzuzeigen. Diese Einstellung aktivieren?",warning_title:"Beim Start anzeigen"},T={description:"Optimieren Sie die Einbettungen domänenspezifischer Daten für eine bessere Suchqualität",intro:"Ihr Unternehmen. Deine Daten. Ihr Modell"},B={description:"Stärken Sie Ihr Unternehmen mit großen Sprachmodellen die genau auf Ihre Daten zugeschnitten sind"},P={api_key:"Geben Sie Ihren API-Schlüssel ein.",back:"Zurück",base_model_selected:"Basismodell ausgewählt",click_start:"Stimmen Sie den Bedingungen zu und beginnen Sie mit der Feinabstimmung.",confirm_title:"Feinabstimmung bestätigen",confirm_your_email:"Geben Sie Ihre E-Mail-Adresse erneut ein, um die Feinabstimmung zu bestätigen. Updates und der Download-Link werden an diese E-Mail-Adresse gesendet.",consent0:"Ich bin damit einverstanden, dass nach meinen Vorgaben synthetische Daten zur Modellfeinabstimmung generiert werden.",consent1:"Ich erkenne an, dass das endgültige Modell und die synthetischen Daten auf Hugging Face öffentlich zugänglich sein werden.",consent2:"Ich verstehe, dass diese Funktion sich in der Betaphase befindet und Jina AI keine Garantien bietet. Preise und UX können sich ändern.",continue:"Weitermachen",cost_1m_token:"Jeder Feinabstimmungsjob verbraucht 1 Million Token. Stellen Sie sicher, dass Sie über genügend Token verfügen, oder laden Sie Ihr Guthaben auf. Sie können auch einen neuen API-Schlüssel generieren. Jeder API-Schlüssel enthält 1 Million kostenlose Token.",doc_explain:"Beschreiben Sie, wie ein übereinstimmendes Dokument aussehen sollte.",domain_explain:"Geben Sie eine detaillierte Beschreibung an, wie die fein abgestimmten Einbettungen verwendet werden. Dies ist wichtig, um qualitativ hochwertige synthetische Daten zu generieren, die die Leistung Ihrer Einbettungen verbessern.",domain_explain2:"Sie können Ihre Anforderung auf drei Arten angeben: eine allgemeine Anweisung, eine URL oder eine Abfragedokumentbeschreibung. Wählen Sie eine aus.",domain_hint:"Beschreiben Sie die Domäne, für die Sie die Feinabstimmung vornehmen möchten.",email_not_match:"Die E-Mail-Adressen stimmen nicht überein. Bitte überprüfen Sie.",failed_job:"Die Feinabstimmungsanforderung ist fehlgeschlagen. Den Grund finden Sie weiter unten.",find_on_huggingface:"Ergebnisse finden zu Hugging Face",general_instruction:"Oder allgemeine Anweisung",general_instruction_caption:"Geben Sie eine detaillierte Beschreibung der Verwendung der feinabgestimmten Einbettungen an.",general_instruction_explain:"Beschreiben Sie Ihre Domain in freiem Text. Sie können es sich als eine „Eingabeaufforderung“ wie in ChatGPT vorstellen.",how_it_works:"Erfahren Sie mehr über den Feinabstimmungsprozess.",job_acknowledged:"Ihr Feinabstimmungsauftrag wurde in die Warteschlange gestellt. Sie erhalten eine E-Mail, wenn der Auftrag beginnt. Der gesamte Vorgang dauert oft 20 Minuten.",new_key:"Neuen Schlüssel anfordern",not_enough_token:"Nicht genügend Token in diesem API-Schlüssel. Bitte laden Sie Ihr Guthaben auf oder verwenden Sie einen anderen API-Schlüssel.",placeholder:"Ansprüche aus der Kfz-Versicherung",preview:"Vorschau",query_doc:"Abfrage-Dokumentbeschreibung",query_doc_caption:"Beschreiben Sie, wie die Abfrage aussieht und wie das übereinstimmende Dokument in Ihrer Domäne aussieht.",query_explain:"Beschreiben Sie, wie eine Abfrage aussieht.",reset:"Von vorn anfangen",select_base_model:"Wählen Sie zur Feinabstimmung ein Basis-Einbettungsmodell.",select_base_model_explain:"Wählen Sie ein Basismodell als Ausgangspunkt für die Feinabstimmung aus. Normalerweise ist Base-en eine gute Wahl, aber für Aufgaben in anderen Sprachen sollten Sie die Verwendung eines zweisprachigen Modells in Betracht ziehen.",start_tuning:"Beginnen Sie mit der Feinabstimmung",url:"Oder Webseiten-URL",url_caption:"Zur Feinabstimmung können Sie den Inhalt einer URL konsultieren.",url_explain:"Öffentliche URL einer Webseite, die den Inhalt enthält, den Sie optimieren möchten.",use_url:"Verwenden Sie stattdessen die URL. Wenn Sie diese Option aktivieren, werden wir auf Grundlage des Seiteninhalts dieser URL synthetische Daten zur Feinabstimmung generieren.",wait_for_processing:"Bitte warten Sie, während wir Ihre Anfrage verarbeiten...",which_domain:"Feinabstimmung der Domäne",write_email_explain:"Die Feinabstimmung braucht Zeit. Wir informieren Sie per E-Mail über den Beginn, den Fortschritt, die Fertigstellung und etwaige Probleme Ihrer Feinabstimmungsarbeit sowie über Einzelheiten zum feinabgestimmten Modell und Trainingsdatensatz."},L={address_beijing:"Peking, China",address_berlin:"Berlin, Deutschland (Hauptsitz)",address_shenzhen:"Shenzhen, China",address_sunnyvale:"Sunnyvale, Kalifornien",all_rights_reserved:"Alle Rechte vorbehalten.",api_documentation:"API-Dokumentation",company:"Unternehmen",developers:"Entwickler",docs:"Dokumente",enterprise:"Unternehmen",get_api_key:"Jina API-Schlüssel abrufen",offices:"Büros",power_users:"Power-User",privacy:"Privatsphäre",privacy_policy:"Datenschutz-Bestimmungen",privacy_settings:"Cookie-Einstellungen",security:"Sicherheit",sefo:"Stiftung durchsuchen",soc2:"Wir erfüllen die Anforderungen von SOC 2 Typ 1 und 2 des American Institute of Certified Public Accountants (AICPA).",status:"API-Status",status_short:"Status",tc:"Terms & amp; Bedingungen",tc1:"Bedingungen"},x="Holen Sie sich Ihren API-Schlüssel",R={stars:"Sterne"},y={description:"Grundaussagen mit Webwissen",title:"Faktencheck",usage:"Erdung"},K={about_us:"Über uns",api_docs:"API-Dokumente",api_docs_explain:"Automatische Codegenerierung für Ihre Copilot-IDE oder LLM",company:"Unternehmen",contact_us:"Kontaktieren Sie unseren Vertrieb",developers_others:"Weitere Entwicklertools",enterprise_others:"Mehr",for_developers:"Für Entwickler",for_developers_description:"Erleben Sie einen umfassenden multimodalen Open-Source-KI-Stack, der für Entwickler entwickelt wurde.",for_enterprise:"Für Firmen",for_enterprise_description:"Entdecken Sie skalierbare multimodale KI-Strategien, die auf die Geschäftsanforderungen zugeschnitten sind.",for_power_users:"Für Power-User",for_power_users_description:"Nutzen Sie unsere optimierten multimodalen Tools, um Ihre Produktivität zu steigern.",internship1:"Praktikantenprogramm",jobs:"Begleiten Sie uns",join_discord:"Treten Sie unserer Discord-Community bei",logos:"Logo herunterladen",maximize:"⇧1",maximize_btn:"Maximieren",news:"Pressemitteilungen",open_day:"Tag der offenen Tür",open_in_full:"Alle Enterprise-Produkte in einem neuen Fenster anzeigen",power_users_others:"Mehr Power-User-Tools",products:"Produkte"},V={description:"Teilen und entdecken Sie Bausteine ​​für multimodale KI-Anwendungen"},W={sentence_similarity:"Text-Embedding",updated_about:"Aktualisiert über"},F={project1:"Ermöglicht eine hochpräzise Suche in 3D-Netzdaten unter Verwendung von Punktwolkeninformationen.",project10:"Nutzung von Computer Vision zur Verbesserung der digitalen Zugänglichkeit von Regierungswebsites.",project11:"Fein abgestimmtes LLM für ein Beratungsunternehmen zur Optimierung der Finanzdatenanalyse.",project12:"Fortschrittliche Marketingstrategien durch Feinabstimmung von Text-zu-Bild-Modellen für die Stilübertragung.",project2:"Entwickelte eine inhaltsbasierte Suchmaschine für kurze Animationsfilme.",project3:"Verbesserte E-Commerce-Conversion-Rates durch Feinabstimmung der Embedding-Modelle.",project4:"Durchführung zeitnaher Optimierungen zur Effizienzsteigerung für ein Unternehmensberatungen.",project5:"Pionierarbeit beim Verständnis von Spielszenen und automatischer Annotation für ein führendes Gaming-Unternehmen.",project6:"Implementierung einer Echtzeit-Prompt-Erweiterung für ein Chatbot-Unternehmen, um das Benutzererlebnis zu verbessern.",project7:"Revolutionierte die Rechtstechnologie, indem es eine effiziente Suche in umfangreichen Rechtsdokumenten ermöglichte.",project8:"Unterstützung eines generativen Kunstdienstes mit hohem Durchsatz für groß angelegte Operationen.",project9:"Durchführung von Process-Mining und Modellierung unter Verwendung fortschrittlicher Sprachmodelle."},G={description:"Hochmoderne multimodale KI-Modelle stehen für Sie über unsere API zur Verfügung"},C="Die Anforderung ist fehlgeschlagen, da in Ihrem API-Schlüssel nicht mehr genügend Token vorhanden sind. Bitte laden Sie ihn auf, um fortzufahren.",U={copy_full_prompt:"Eingabeaufforderung vollständig kopieren",embedding:"Einbettungen",how_to_use_meta_prompt:"Anwendung",meta_prompt:"Verwenden Sie Meta-Prompt zur Codegenerierung",meta_prompt_description:"Die Meta-Eingabeaufforderung führt LLMs (wie ChatGPT und Claude) durch alle unsere Search Foundation-APIs und vereinfacht so die Codegenerierung und sorgt für eine höhere Qualität.",reranker:"Neubewerter",which_to_go:"Welches soll mit {_vendor} integriert werden?"},j={answer1:"Bachelor-, Master- und Ph.D.-Studiengänge Studierende aus der ganzen Welt mit Interesse an Bereichen wie Forschung, Ingenieurwesen, Marketing und Vertrieb werden aufgefordert, sich zu bewerben. Wir freuen uns auch über nicht-technische Praktika in den Bereichen Marketing, Vertrieb, Assistenz von Führungskräften und mehr. Wir suchen leidenschaftliche Menschen, die bereit sind, mit uns Pionierarbeit in der multimodalen KI zu leisten.",answer10:"Ja, unser Praktikumsprogramm bietet eine wettbewerbsfähige Vergütung.",answer11:"Als Jina AI-Praktikant sammeln Sie praktische Erfahrungen bei der Arbeit an anspruchsvollen Projekten, lernen von Branchenexperten, werden Teil einer lebendigen Community und haben die Möglichkeit, echte Beiträge zu unserer Pionierarbeit in der multimodalen KI zu leisten.",answer2:"Praktika müssen vor Ort in einem unserer Büros in Berlin, Peking und Shenzhen absolviert werden.",answer3:"Ja, Jina AI bietet erfolgreichen Antragstellern angemessene Unterstützung im Visumverfahren.",answer4:"Ja, Jina AI bietet Praktikanten während des Praktikums eine angemessene Deckung der Lebenshaltungskosten an.",answer5:"Ja, die Anfertigung Ihrer Masterarbeit während Ihres Praktikums bei Jina AI ist in der Regel für Studierende deutscher Hochschulen möglich. Sie benötigen jedoch eine vorherige Mitteilung und Zustimmung des Betreuers Ihrer Universität. Beachten Sie, dass wir Studierenden nicht bei der Suche nach Beratern helfen.",answer6:"Der Bewerbungsprozess umfasst die Einreichung Ihres Bewerbungsformulars, eines Lebenslaufs, eines Anschreibens, in dem Sie Ihr Interesse und Ihre Motivation zum Ausdruck bringen, sowie aller relevanten beruflichen Links wie GitHub oder LinkedIn. Wir bewerten Kandidaten anhand ihrer Leistung während des Vorstellungsgesprächs und ihrer Leistung an ihrer Universität.",answer7:"Ja, erfolgreiche Praktikanten können am Ende ihres Praktikums ein Empfehlungsschreiben erhalten, das von unserem CEO unterzeichnet wird.",answer8:"Die Dauer des Praktikums variiert je nach Rolle und Projekt. In der Regel liegt sie jedoch zwischen drei und sechs Monaten.",answer9:"Ja, wir freuen uns über Bewerbungen mit allen akademischen Hintergründen. Wir schätzen Ihre Leidenschaft und Ihr Engagement für das Lernen ebenso wie Ihre vorherige Erfahrung.",question1:"Wer kann sich für das Jina AI-Praktikumsprogramm bewerben?",question10:"Ist das ein bezahltes Praktikum?",question11:"Welche Möglichkeiten habe ich als Jina AI-Praktikant?",question2:"Wo findet das Praktikum statt?",question3:"Unterstützt Jina AI bei Visa-Prozessen?",question4:"Bietet Jina AI Praktikanten Zulagen oder Vorteile?",question5:"Kann ich während des Praktikums bei Jina AI an meiner Masterarbeit arbeiten?",question6:"Wie läuft der Bewerbungsprozess ab?",question7:"Stellt Jina AI nach dem Praktikum ein Empfehlungsschreiben aus?",question8:"Wie lange dauert das Praktikum?",question9:"Kann ich mich bewerben, wenn ich noch keine Erfahrung im Bereich KI habe?"},q={about_internship_program:"Über das Praktikumsprogramm",about_internship_program_desc1:"Wir freuen uns, talentierten Menschen diese einzigartige Gelegenheit bieten zu können, Teil unseres dynamischen Teams zu werden und an bahnbrechenden Projekten im Bereich der künstlichen Intelligenz mitzuwirken. Dieses Praktikum soll Ihnen wertvolle praktische Erfahrungen, Mentoring und Einblick in modernste Technologien bieten, die die Zukunft der KI prägen.",about_internship_program_desc2:"Bei Jina AI wissen wir, wie wichtig es ist, junge Talente zu fördern und zu gewinnen. Wir wissen, dass Praktikanten neue Perspektiven, Begeisterung und Kreativität einbringen und unser Team mit neuen Ideen und Ansätzen beleben. Durch die Bereitstellung von Praktika wollen wir das Wachstum zukünftiger Führungskräfte in der KI-Branche fördern und ihnen gleichzeitig praktische Erfahrungen in einem unterstützenden und herausfordernden Umfeld bieten.",alumni:"ALUMNI",alumni_network:"Unser florierendes Alumni-Netzwerk",application:"Anwendung",application_desc:"Begeben Sie sich mit Jina AI auf eine transformative Reise. Unser umfassendes Praktikumsprogramm lädt alle leidenschaftlichen Köpfe ein, die die Zukunft der künstlichen Intelligenz mitgestalten möchten. Kommen Sie zu uns, um praktische Erfahrungen zu sammeln, an anspruchsvollen Projekten zu arbeiten und mit einigen der klügsten Köpfe der KI-Branche zusammenzuarbeiten.",apply:"Jetzt bewerben",autumn:"Herbst",description:"Weltweite Ausschreibung für Studenten: Praktika in Forschung, Entwicklung, Marketing, Vertrieb und mehr.",dev_rel_intern:"Praktikant im Bereich Developer Relations",enthusiastic:"ENTHUSIASTISCH",explore_stories_from_our_interns:"Entdecken Sie Geschichten unserer Praktikanten",explore_stories_from_our_interns1:"Lassen Sie sich von den Reisen unserer Praktikanten inspirieren",innovative:"INNOVATIV",intern_work1:"Fein abgestimmte LLM-Modelle für bessere Einbettungen",intern_work2:"Erkundete das Potenzial der Retrieval Augmented Generation",intern_work3:"Veröffentlichung eines Artikels zum Thema Satzeinbettungen",intern_work4:"Der Mannschaft kontinuierlich jugendliche Vitalität verleihen",intern_work5:"Benchmarked-Quantisierungstechniken zur Komprimierung von LLM",intern_work6:"Erstellen und Bewerben einer überzeugenden Kampagne für PromptPerfect",intern_work7:"Schnell entwickeltes und verbessertes JinaColBERT V2",recruiting_and_administrative_intern:"Praktikant im Bereich Personalbeschaffung und Verwaltung",researcher_intern:"Wissenschaftlicher Praktikant",self_motivated:"SELBST MOTIVIERT",software_engineer_intern:"Praktikant im Bereich Software-Ingenieur",spring:"Frühling",submit_application:"Starten Sie Ihr Abenteuer mit Jina AI",subtitle:"Unser Vollzeit-Praktikumsprogramm bietet praktische Arbeitserfahrung durch gut konzipierte Praktikumsprojekte in einem breiten Spektrum.",subtitle1:"Weltweiter Aufruf für Studenten: Praktikanten in Forschung, Technik, Marketing, Vertrieb und mehr, um gemeinsam Pionierarbeit für multimodale KI zu leisten.",summer:"Sommer",title:"Praktikantenprogramm",who_do_we_look_for:"Wen suchen wir?",who_do_we_look_for_desc:"Wir legen Wert auf Vielfalt und ermutigen Bewerber mit unterschiedlichen Profilen und Hintergründen, an unserem Praktikumsprogramm teilzunehmen. Die Praktikumsmöglichkeiten werden in mehreren Abteilungen angeboten, darunter Technik, Design, Produktmanagement, Vertrieb und Account Management, Marketing und Community Management.",winter:"Winter"},N={description:"Stellen Sie ein lokales Projekt als Cloud-Dienst bereit. Radikal einfach, keine bösen Überraschungen."},J={description:"Ein experimenteller Finetuner für Open-Source-LLMs"},O={description:"Erstellen Sie multimodale KI-Anwendungen in der Cloud"},H={description:"Mehr Modalitäten, längerer Speicher, weniger Kosten",example_1:"Wer bist du?",example_2:"Ich bin ein LLM-Chat-Dienst von Jina AI"},Z={add:"Schlüssel hinzufügen",add_key_explain:"Fügen Sie Ihrem Konto einen weiteren API-Schlüssel hinzu. Hinzugefügte Schlüssel können jederzeit verwaltet, aufgeladen oder entfernt werden.",add_shared_key:"Zu meinen Schlüsseln hinzufügen",add_success:"Ein Schlüssel {_key} wurde erfolgreich hinzugefügt.",advance_settings:"Erweiterte Einstellungen öffnen",advanced_feature:"Erweiterte Funktion nur für Premium-Schlüssel.",auto_recharge_enable_success:"Automatisches Aufladen für den Schlüssel {_key} erfolgreich aktiviert.",auto_recharge_title:"Automatisches Aufladen aktivieren?",auto_reminder:"Erinnerung bei niedrigem Guthaben",auto_reminder_cancel_message:"Möchten Sie die automatische Erinnerung für diesen Schlüssel wirklich abbrechen?",auto_reminder_cancel_title:"Automatische Erinnerung abbrechen",auto_reminder_description:"Erhalten Sie automatische E-Mail-Benachrichtigungen, wenn Ihr Token-Guthaben unter die von Ihnen festgelegten Schwellenwerte fällt. Sie können bis zu drei Schwellenwerte konfigurieren.",auto_reminder_email:"E-Mail-Adresse für Erinnerungen",auto_reminder_info:"Die Benachrichtigung wird an {_email} gesendet, wenn der Token-Saldo unter {_threshold} Token fällt.",auto_reminder_threshold:"Erinnern Sie sich, wenn",auto_reminder_threshold_error:"Der Schwellenwert muss zwischen 1 und 1T liegen.",auto_reminder_toggle:"Automatische Erinnerung umschalten. Bitte beachten Sie, dass diese Funktion nur mit einem Premiumschlüssel aktiviert werden kann.",available_resources:"Verfügbare Token",balance:"Verfügbare Token",balance_primary_key:"Primärschlüsselsaldo",cancel:"Stornieren",confirm:"Bestätigen",copy:"Schlüssel kopieren",copy_share_link:"Link kopieren",description:"Verwalten Sie API-Schlüssel für alle Jina AI-Dienste – Embeddings, Reader, Reranker und mehr.",do_it_later:"Mach es später",email:"E-Mail",existing_key:"Vorhandener Schlüssel",filter_by:"Filtern nach Schlüssel",free_key:"Kostenloser Schlüssel",generate_new_key:"Neuen Schlüssel generieren",generate_new_key_tooltip:"Generieren Sie einen neuen API-Schlüssel mit leerem Guthaben. Sie können das Guthaben später aufladen.",generate_success:"Ein neuer Schlüssel {_key} wurde erfolgreich generiert.",get_free_key:"API-Schlüssel erstellen",ignore:"Ignorieren",invalid_email:"Ungültige E-Mail",invalid_key:"Ungültiger Schlüssel",is_primary:"Ihr primärer API-Schlüssel. Sie können ihn nach dem Einloggen ändern.",last_used:"Zuletzt verwendet",last_used_at:"Letzte Aktivität",login:"Einloggen",login_explain:"Verwalten Sie mehrere API-Schlüssel und verfolgen Sie die Nutzung – alles in einem Konto.",login_explain_long:"Melden Sie sich an, um Ihre API-Schlüssel sicher zu speichern und zu verwalten. Verfolgen Sie den Nutzungsverlauf, verwalten Sie mehrere Schlüssel und verlieren Sie nie den Zugriff auf Ihre Anmeldeinformationen.",login_required:"Bitte melden Sie sich an, bevor Sie den gemeinsamen Schlüssel hinzufügen.",login_via:"angemeldet über {_provider}",logout:"Aus Konto abmelden",logout_message:"Ihre API-Schlüssel bleiben sicher in Ihrem Konto gespeichert. Melden Sie sich jederzeit an, um sie zu verwalten.",logout_success:"Erfolgreich abgemeldet",no_key_title:"Benötigen Sie einen API-Schlüssel?",no_key_with_login:"Sie haben noch keinen API-Schlüssel erstellt. Generieren Sie jetzt einen und erhalten Sie kostenlose Token zum Starten.",no_key_without_login:"Sie haben bereits ein Konto? Melden Sie sich an, um auf Ihre API-Schlüssel zuzugreifen, oder klicken Sie auf „{_button}“, um ein neues Konto zu erstellen.",no_transferable_keys:"Es sind keine weiteren Schlüssel zum Übertragen verfügbar. Bitte fügen Sie zuerst einen neuen Schlüssel hinzu.",ok:"OK",primary_key:"Als Primärschlüssel festlegen",primary_key_set:"{_apiKey} wurde erfolgreich als Primärschlüssel festgelegt.",primary_key_set_caption:"Dieser Schlüssel wird in allen Demos, Beispielen und Spielplätzen auf jina.ai verwendet.",purchase:"Token kaufen",recharge_threshold_confirm_message:"Möchten Sie den Schwellenwert für die automatische Aufladung wirklich auf {_threshold} Token ändern?",recharge_threshold_confirm_title:"Schwellenwert für automatisches Aufladen ändern",remove:"Schlüssel entfernen",remove_explain:"Das Entfernen des Schlüssels aus Ihrer Liste hat keine Auswirkungen auf den Dienst, abhängige Vorgänge oder andere Benutzer, die ihn gespeichert haben. Der Schlüssel bleibt funktionsfähig und kann jederzeit wieder hinzugefügt werden.",remove_message:"Möchten Sie diesen Schlüssel wirklich entfernen? Der Schlüssel bleibt funktionsfähig und kann jederzeit wieder hinzugefügt werden.",remove_primary_key:"Bitte legen Sie einen anderen Schlüssel als Primärschlüssel fest, bevor Sie den aktuellen Primärschlüssel entfernen.",remove_success:"Der Schlüssel {_key} wurde erfolgreich entfernt.",remove_title:"Schlüssel entfernen",revoke:"Schlüssel widerrufen",revoke_error:"Der von Ihnen eingegebene Schlüssel stimmt nicht mit dem Schlüssel überein, den Sie widerrufen möchten.",revoke_explain:"Durch das Widerrufen eines Schlüssels wird dieser sofort für alle Benutzer deaktiviert, die ihn gespeichert haben, und alle verbleibenden Guthaben und zugehörigen Eigenschaften werden dauerhaft unbrauchbar. Diese Aktion kann nicht rückgängig gemacht werden.",revoke_label:"Bitte bestätigen Sie den Widerruf dieses Schlüssels, indem Sie ihn unten eingeben",revoke_message:"Möchten Sie diesen Schlüssel wirklich widerrufen? Nach dem Widerruf wird dieser Schlüssel für alle Benutzer, die ihn gespeichert haben, dauerhaft ungültig. Alle verbleibenden Guthaben und zugehörigen Eigenschaften werden dauerhaft unbrauchbar. Diese Aktion kann nicht rückgängig gemacht werden.",revoke_success:"Der Schlüssel {_key} wurde erfolgreich widerrufen.",revoke_title:"Schlüssel widerrufen",save:"Speichern",settings:"Einstellungen",share:"Schlüssel teilen",share_key_confirm_message:`Der Empfänger kann das Guthaben dieses Schlüssels einsehen, verwalten und aufladen. Sie behalten dieselben Rechte.

Bitte beachten Sie, dass der Link in 24 Stunden abläuft.`,share_key_confirm_title:"API-Schlüssel teilen",share_key_expired_at:"Der freigegebene Link läuft um {_time} ab!",share_key_expired_message:"Der Freigabelink des Schlüssels ist abgelaufen. Bitten Sie den Schlüsselinhaber, ihn erneut freizugeben.",share_key_expired_title:"Der freigegebene Link ist abgelaufen",share_key_message:"{_user} hat einen API-Schlüssel mit Ihnen geteilt. Fügen Sie ihn hinzu, um den Schlüssel und seinen Saldo zu verwalten.",share_link_copied:"Link zum Teilen kopiert",shared_from:"Schlüssel geteilt von {_user}",shared_key:"Gemeinsam genutzter Schlüssel",subscribed_key:"Premium-Schlüssel",title:"Jina Search Foundation-API",to_dashboard:"Schlüssel verwalten",top_up:"Nachfüllen",total_keys:"Gesamtanzahl Schlüssel",transfer_before_revoke:"Übertragen Sie die restlichen bezahlten Token, bevor Sie den Schlüssel widerrufen.",transfer_explain:"Übertragen Sie Ihre verbleibenden bezahlten Token nahtlos auf ein anderes Konto, um mehr Flexibilität und verbesserte Sicherheit bei der Verwaltung Ihrer Ressourcen zu erhalten.",transfer_label:"Übertragen nach",transfer_message:"Möchten Sie Ihre verbleibenden bezahlten Token {_tokens} wirklich von {_source} nach {_target} übertragen?",transfer_success:"Token erfolgreich von {_source} nach {_target} übertragen.",transfer_title:"Token übertragen",usage_history:"Nutzungsverlauf",usage_summary:"Letzte 7 Tage: {_usage} Token"},Q={GlobalQA:{description:"Drücken Sie auf einer beliebigen Seite die Taste „/“, um das Fragenfeld zu öffnen. Geben Sie Ihre Anfrage ein und drücken Sie die Eingabetaste, um Antworten zu erhalten, die sich direkt auf den Seiteninhalt beziehen. Diese Funktion wird von PromptPerfect unterstützt.",title:"On-Page-RAG"},Recommender:{description:"Öffnen Sie das Empfehlungsfeld auf einer beliebigen Nachrichtenseite mit „Umschalt+2“. Wählen Sie das Reranker-Modell aus, um die Top-5-Artikel zu dieser Nachrichtenseite zu entdecken. Genießen Sie diese Echtzeitfunktion, die von unserer Reranker-API unterstützt wird.",title:"Verwandter Artikel"},SceneXplainTooltip:{description:"Bewegen Sie Ihren Mauszeiger über ein beliebiges Bild auf Nachrichtenseiten oder in unserem Newsroom-Katalog, um die Beschreibung dieses Bildes anzuzeigen. Beschreibungen werden von SceneXplain vorberechnet und zur Barrierefreiheit in das ALT-Attribut des Bildes eingebettet.",title:"Bildunterschrift"},explain:"Entdecken Sie versteckte Funktionen auf unserer Website"},X={also_available_on:"Auch auf den Marktplätzen erhältlich",also_available_on1:"Verfügbar auf den Marktplätzen Ihrer Enterprise Cloud",ask_how_your_question:"Bitte beschreibe dein Problem",autotune:"Automatische Feinabstimmung",avatar:"Avatar-Generator",badge:{"clip-v2":"Clip-V2-Veröffentlichung!","readerlm-v2":"ReaderLM-v2-Veröffentlichung!",v2:"V2-Version!",v3:"V3-Version!"},browser_info_title:"Browserinformationen",build_js:"JavaScript SDK verwenden",build_python:"Python SDK verwenden",ccbync:"Dieses Modell ist unter CC BY-NC 4.0 lizenziert. Verwenden Sie es über die API oder unser offizielles AWS/Azure-Image oder wenden Sie sich für die Bereitstellung vor Ort an den Vertrieb.",checkout_our_solution_for_you:"Entdecken Sie unsere auf Sie zugeschnittene Lösung",classifier:"Klassifikator",coming_soon:"Demnächst",contact_sales:"Kontakt",copied_to_clipboard:"In die Zwischenablage kopiert",copy:"Kopieren",developers:"Entwickler",developers_desc:"Nutzen Sie die volle Leistungsfähigkeit multimodaler KI mit modernsten Cloud-Technologien und Open-Source-Infrastruktur.",download_pdf:"PDF Herunterladen",embedding:"Einbettungen",embedding_desc1:"Leistungsstarke multimodale, mehrsprachige Langkontext-Einbettungen für Such-, RAG- und Agentenanwendungen.",embedding_paper_desc:"Jina Embeddings stellt eine Reihe leistungsstarker Text-Embedding-odelle dar, die in der Lage sind, verschiedene Texteingaben in numerische Darstellungen zu übersetzen und so die semantische Essenz des Textes zu erfassen. Obwohl diese Modelle nicht ausschließlich für die Textgenerierung konzipiert sind, zeichnen sie sich durch Anwendungen wie Dense Retrieval und semantische Textähnlichkeit aus. In diesem Artikel wird die Entwicklung von Jina Embeddings detailliert beschrieben, beginnend mit der Erstellung eines hochwertigen Paar- und Triplett-Datensatzes. Es unterstreicht die entscheidende Rolle der Datenbereinigung bei der Datensatzvorbereitung, gibt detaillierte Einblicke in den Modelltrainingsprozess und schließt mit einer umfassenden Leistungsbewertung mithilfe des Massive Textual Embedding Benchmark (MTEB).",embedding_paper_title:"Jina Embeddings: Ein neuartiger Satz leistungsstarker Text-Embedding-Modelle",embeddings:"Einbettungen",enterprise:"Unternehmen",enterprise_desc:"Steigern Sie Ihr Geschäft mit skalierbaren, sicheren und maßgeschneiderten multimodalen KI-Lösungen.",enterprise_desc_v2:"Probieren Sie unsere erstklassigen Einbettungsmodelle aus, um Ihre Such- und RAG-Systeme zu verbessern. Beginnen Sie mit einer kostenlosen Testversion!",enterprise_desc_v3:"Unsere Frontier-Modelle bilden die Suchgrundlage für hochwertige Enterprise-Search- und RAG-Systeme.",error:"Beim Abrufvorgang ist ein Problem aufgetreten: {message}",find_your_portal:"Wählen Sie Ihr Portal",finding_faq:"Generieren einer Antwort basierend auf dem FAQ-Wissen unten",for:"Für",for_better_search:"Für eine bessere Suche",for_developers:"Für Entwickler",for_enterprise:"Für Unternehmen",for_power_users:"Für Power-User",get_api_now:"API",get_started:"Loslegen",go_to_product_homepage:"Zur Produkthomepage",grounding:"Erdung",how_to:"Wie man",include_experiment:"Bezieht unsere experimentellen und archivierten Projekte in die Lösung ein.",join_community:"Gemeinschaft",key_manager:"API-Schlüssel verwalten",learn_more_embeddings:"Erfahren Sie mehr über Einbettungen",learn_more_reader:"Erfahren Sie mehr über den Reader",learn_more_reranker:"Erfahren Sie mehr über Reranker",llm:"LLM-Embedding-Modelle",llm_desc:"Wir bieten eine Sammlung leistungsstarker Text-Embedding-Modelle mit 35 Millionen bis 6 Milliarden Parametern. Sie eignen sich hervorragend zur Verbesserung der neuronalen Suche, Neuordnung, Satzähnlichkeit, Empfehlungen usw. Machen Sie sich bereit, Ihr KI-Erlebnis zu verbessern!",mentioned_products:"Erwähnte Produkte:",mmstack:"Multimodaler Stapel",mmstack_desc:"Im Laufe der Jahre haben wir eine Vielzahl von Open-Source-Software entwickelt, die Entwicklern hilft, schneller bessere GenAI- und Suchanwendungen zu erstellen.",models:"Modelle",more:"Mehr",multimodal:"Multimodal",multimodal_ai:"Multimodalen KI",new:"Neu",newsroom:"Pressemitteilungen",num_publications:"{_total} Veröffentlichungen insgesamt.","on-prem-deploy":"Bereitstellung vor Ort","on-premises":"Auf dem Gelände",opensource:"Open Source",our_customer:"Unsere Kunden",our_customer_explain:"Unternehmen jeder Größe vertrauen beim Aufbau ihrer Tools und Produkte auf die Search Foundation von Jina AI – das können Sie auch.",our_publications:"Unsere Veröffentlichungen",parameters:"Parameter",podcast:"Podcast",power_users:"Power-User",power_users_desc:"Auto-Prompt-Engineering für Ihre tägliche Produktivität.",powered_by_promptperfect:"Unterstützt durch die Funktionen „Prompt-Optimierung“ und „Prompt as a Service“ von PromptPerfect",pricing:"Preisgestaltung",proposing_solution:"Vorschlag einer Lösung basierend auf Jina AI-Produkten...",read_more:"Weiterlesen",reader:"Leser",require_full_question:"Bitte beschreiben Sie Ihr Problem detaillierter.",reranker:"Reranker",researcher_desc:"Erfahren Sie, wie unsere bahnbrechenden Suchmodelle von Grund auf trainiert wurden, und sehen Sie sich unsere neuesten Veröffentlichungen an. Lernen Sie unser Team bei EMNLP, SIGIR, ICLR, NeurIPS und ICML kennen!",researchers:"Forscher",sdk:"SDK",sdk_desc:"Möchten Sie zukunftsweisende AIGC-Anwendungen erstellen? Mit den APIs PromptPerfect, SceneXplain, BestBanner, JinaChat und Rationale ist das einfach. Probieren Sie unser benutzerfreundliches SDK aus und legen Sie in wenigen Minuten los.",sdk_docs:"Lesen Sie die Dokumente",sdk_example:"Beispiel",search_foundation:"Stiftung durchsuchen",source_code:"Quellcode",starter_kit:"Starter-Kit",supercharged1:"mit Turbolader.",tokenizer:"Segmentierer",trusted_by:"UNSERE PARTNER",try_it_for_free:"Beginnen Sie sofort – keine Kreditkarte oder Registrierung erforderlich!",try_our_saas:"Probieren Sie unsere gehostete Lösung aus, einen direkten Ersatz für die Einbettungs-API von OpenAI.",version_notify:"Sie sehen eine ältere Version dieser Website. Die neuesten Funktionen finden Sie unter {_link}",view_browser_info:"Browserinformationen anzeigen",your_portal_to:"Ihr Portal zur",your_search_foundation1:"Ihre Suchbasis"},Y={description:"Langchain-Apps in der Produktion mit Jina und FastAPI"},$={description:"Rechtliche Informationen, Servicebedingungen, Datenschutzrichtlinie und andere wichtige Dokumente zu den Produkten und Dienstleistungen von Jina AI.",download_type1:"SOC 2 Typ 1-Bescheinigung herunterladen",download_type2:"SOC 2 Typ 2-Bescheinigung herunterladen",request_audit:"Prüfbericht anfordern",title:"Rechtliche Hinweise"},ee={api:"LLM-als-SERP-API",description:"Große Sprachmodelle als Suchergebnisseiten",faq_v1:{answer1:"SERP steht für Search Engine Results Page (Suchmaschinenergebnisseite). Das ist die Seite, die Suchmaschinen als Antwort auf eine Suchanfrage eines Benutzers anzeigen. Sie enthält eine Ergebnisliste, häufig mit zusätzlichen Informationen wie URLs, Snippets und Domänennamen.",answer2:"Ja, LLM-as-SERP verwendet große Sprachmodelle, um Suchergebnisse zu generieren.",answer3:"Halluzinationen.",answer4:"Sie könnten in den Trainingsdaten des Modells enthalten sein.",answer5:"Ja, Sie können die LLM-as-SERP-API zum Generieren von Suchergebnissen verwenden. Klicken Sie auf die Schaltfläche unten.",answer6:"Wir haben es entwickelt, während wir mit der Sucherdung von DeepSearch experimentierten. Lesen Sie unseren Blogbeitrag, indem Sie auf die Schaltfläche klicken.",answer7:"Ja, der Code ist Open Source und auf GitHub verfügbar.",question1:"Was ist SERP?",question2:"Also werden alle Suchergebnisse von LLM generiert?",question3:"Warum sind einige URLs in den Suchergebnissen defekt und führen zu 404-Seiten?",question4:"Warum sind dann einige URLs echt und führen zur tatsächlichen Seite?",question5:"Kann ich es per API aufrufen?",question6:"Aber wenn alle Suchergebnisse gefälscht sind, was ist dann der Sinn dieser Demo oder API?",question7:"Ist es Open Source?",title:"Häufige Fragen zu LLM als SERP"},okay_but_why:"Warum kann es nützlich sein?",parameters:{auth_token:"@:tokenizer.parameters.auth_token",auth_token_explain:"Die Nutzung von LLM als SERP-API ist kostenlos. Durch die Angabe Ihres API-Schlüssels können Sie auf ein höheres Ratenlimit zugreifen und Ihr Schlüssel wird Ihnen nicht in Rechnung gestellt.",country:"Bevorzugtes Land",country_explain:"Das für die Suche zu verwendende Land. Es handelt sich um einen zweistelligen Ländercode.",language:"Bevorzugte Sprache",language_explain:"Die für die Suche zu verwendende Sprache. Es handelt sich um einen zweistelligen Sprachencode.",location:"Bevorzugter Standort",location_explain:"Von wo aus die Suchanfrage stammen soll. Es wird empfohlen, den Standort auf Stadtebene anzugeben, um die Suche eines echten Benutzers zu simulieren.",number:"Anzahl der Ergebnisse",number_explain:"Die maximale Anzahl der zurückzugebenden Ergebnisse. Die Verwendung von „num“ kann zu Verzögerungen führen und/oder die Einbeziehung spezialisierter Ergebnistypen verhindern. Es wird nicht garantiert, dass die Ergebnisse die in „num“ angegebene Anzahl von Ergebnissen enthalten.",page:"Pagination",page_explain:"Der Ergebnis-Offset. Er überspringt die angegebene Anzahl von Ergebnissen. Er wird für die Seitennummerierung verwendet.",query:"Abfrage",query_explain:"Die Abfrage, nach der Sie suchen möchten. Sie können alles verwenden, was Sie auch bei einer normalen Suche verwenden würden, z. B. inurl:, site:, intitle:."},query_label:"Ihre Anfrage",title:"LLM als SERP"},ne={api:"Jina KI-API",browse_catalog:"Katalog durchsuchen",contact_sales_about_it:"Kontaktieren Sie hierzu den Vertrieb",deploy_it_on:"Bereitstellen auf",description:"Wir haben die Entwicklung von Suchmodellen seit dem ersten Tag vorangetrieben. Sehen Sie sich unten die Entwicklung unseres Modells an. Bewegen Sie den Mauszeiger oder klicken Sie, um die einzelnen Meilensteine zu entdecken.",find_on_hf:"Finden Sie es auf HuggingFace",search_for:"Suchen Sie auf unserer Website",search_models:"Nach Modellnamen filtern",title:"Unsere Search Foundation-Modelle",use_it_via:"Nutzen Sie es über"},ie={back_to_models:"Zurück zu den Modellen",comparison:{btn:"Vergleichen",select_models:"Wählen Sie Modelle zum Vergleichen aus"},error:"Modell konnte nicht geladen werden",input_type:{"3d":"3D",audio:"Audio",code:"Code",document:"Dokumentieren",graph:"Graph",image:"Bild","multi-vector":"Multi-Vektor",other:"Andere",ranking:"Ranglisten",tabular:"Tabellarisch",text:"Text","text (code)":"Text (Code)","text (document)":"Text (Dokument)","text (html)":"Text (HTML)","text (json)":"Text (JSON)","text (markdown)":"Text (Markdown)","text (query)":"Text (Abfrage)",timeseries:"Zeitreihen",vector:"Vektor",video:"Video"},loading:"Modelldetails werden geladen …",metadata:{api_link:"Jina-API",arxiv:"ArXiv-Artikel",aws_link:"AWS SageMaker",azure_link:"Microsoft Azure",deprecated_by:"Veraltet von",gcp_link:"Google Cloud",huggingface_link:"Umarmendes Gesicht",input_type:"Eingang",license:"Lizenz",license_link:"Kommerzielle Lizenz",output_type:"Ausgabe","reader-api_link":"Jina-API",related_models:"Ähnliche Modelle",release_blog:"Beitrag veröffentlichen",release_date:"Veröffentlichungsdatum"},search:{no_results:'Es wurden keine Modelle gefunden, die mit "{query}" übereinstimmen.',placeholder:"Suche nach Namen, Tags oder Typ..."},sections:{availability:"Verfügbarkeit",blogs:"Blogs, die dieses Modell erwähnen",external_links:"Externe Links und Ressourcen",guidance:{"ReaderLM-v2":"Das Modell ist über ein Google Colab-Notebook zugänglich, das die Konvertierung von HTML in Markdown, die JSON-Extraktion und das Befolgen von Anweisungen demonstriert. Für HTML-zu-Markdown-Aufgaben können Benutzer reines HTML ohne Präfixanweisungen eingeben, während die JSON-Extraktion eine bestimmte Schemaformatierung erfordert. Die Hilfsfunktion create_prompt erleichtert die einfache Erstellung von Eingabeaufforderungen für beide Aufgaben. Obwohl das Modell auf der kostenlosen T4-GPU-Stufe von Colab funktioniert (erfordert vllm und triton), weist es ohne Unterstützung von bfloat16 oder Flash Attention 2 Einschränkungen auf. Für den Produktionseinsatz wird RTX 3090/4090 empfohlen. Das Modell wird auf AWS SageMaker, Azure und dem GCP-Marktplatz verfügbar sein und unter CC BY-NC 4.0 für die nichtkommerzielle Nutzung lizenziert sein.","jina-clip-v1":"Um Jina CLIP v1 effektiv einzusetzen, sollten Teams sowohl dessen Fähigkeiten als auch Ressourcenanforderungen berücksichtigen. Das Modell verarbeitet Bilder in 224 x 224 Pixel großen Kacheln, wobei jede Kachel 1.000 Tokens Verarbeitungskapazität verbraucht. Für eine optimale Leistung implementieren Sie eine effiziente Bildvorverarbeitung, die diesen Abmessungen entspricht. Obwohl das Modell sowohl bei der Verarbeitung kurzer als auch langer Texte hervorragend ist, unterstützt es derzeit nur Eingaben in englischer Sprache. Teams sollten die Token-Nutzung sorgfältig abwägen: Text erfordert ungefähr 1,1 Tokens pro Wort, während Bilder in Kacheln verarbeitet werden (z. B. erfordert ein 750 x 500 Pixel großes Bild 12 Kacheln und verbraucht 12.000 Tokens). Das Modell ist sowohl über die Jina Embeddings API als auch als Open-Source-Version auf Hugging Face unter der Apache 2.0-Lizenz verfügbar und bietet Flexibilität bei den Bereitstellungsoptionen. Erwägen Sie für Produktionsumgebungen die Verwendung der Bereitstellungsoptionen AWS Marketplace oder Azure, die optimierte Infrastruktur-Setups bieten.","jina-clip-v2":"Für eine optimale Bereitstellung sollten Benutzer mehrere Schlüsselfaktoren berücksichtigen. Das Modell erfordert CUDA-fähige Hardware für eine effiziente Verarbeitung, wobei der Speicherbedarf basierend auf Batchgröße und Bildauflösung skaliert wird. Um API-Kosten und -Leistung zu optimieren, skalieren Sie Bilder vor der Verarbeitung auf 512 x 512 Pixel – größere Bilder werden automatisch gekachelt, was den Token-Verbrauch und die Verarbeitungszeit erhöht. Das Modell eignet sich hervorragend zum Abgleichen von Bildern mit beschreibendem Text in verschiedenen Sprachen, kann jedoch mit abstrakten Konzepten oder hochspezialisierten domänenspezifischen Inhalten Probleme haben. Es ist besonders effektiv für die E-Commerce-Produktsuche, Inhaltsempfehlungssysteme und visuelle Suchanwendungen, ist jedoch möglicherweise nicht für Aufgaben geeignet, die eine feinkörnige visuelle Detailanalyse oder hochspezialisiertes Fachwissen erfordern. Berücksichtigen Sie bei Verwendung der Matryoshka-Darstellungsfunktion den Kompromiss zwischen Dimensionsreduzierung und Leistung – während 64-dimensionale Einbettungen eine starke Leistung beibehalten, können kritische Anwendungen von höheren Dimensionen profitieren.","jina-colbert-v1-en":"Um Jina-ColBERT-v1-en effektiv einzusetzen, sollten Teams mehrere praktische Aspekte berücksichtigen. Das Modell erfordert eine CUDA-fähige GPU für optimale Leistung, obwohl CPU-Inferenz für die Entwicklung möglich ist. Bei der Dokumentverarbeitung entspricht das 8.192-Token-Limit ungefähr 6.000 Wörtern, sodass es für die meisten Dokumenttypen geeignet ist, einschließlich akademischer Arbeiten, technischer Dokumentation und Langforminhalte. Teams sollten eine effiziente Dokumentvorverarbeitung implementieren, um Token-Limits zu handhaben, und eine Stapelverarbeitung für die Indizierung im großen Maßstab in Betracht ziehen. Obwohl das Modell bei englischsprachigen Inhalten hervorragend funktioniert, ist es nicht für mehrsprachige Anwendungen oder sprachübergreifende Abfragen konzipiert. Implementieren Sie für Produktionsbereitstellungen geeignete Dokument-Chunking-Strategien und erwägen Sie die Verwendung von Vektorähnlichkeitsindizes (wie FAISS) für eine effiziente Abfrage. Das Modell ist besonders effektiv, wenn es in RAG-Pipelines mit Frameworks wie RAGatouille integriert wird, was die Implementierung komplexer Abfragemuster vereinfacht.","jina-colbert-v2":"Um Jina-ColBERT-v2 effektiv einzusetzen, sollten Teams mehrere praktische Aspekte berücksichtigen. Das Modell erfordert CUDA-fähige Hardware für optimale Leistung und unterstützt Dokumentlängen von bis zu 8.192 Token (erweiterbar auf 12.288), wobei Abfragen auf 32 Token begrenzt sind. Für den Produktionseinsatz ist das Modell über die Jina Search Foundation API, den AWS-Marktplatz und Azure verfügbar, wobei eine nicht kommerzielle Version über Hugging Face zugänglich ist. Bei der Implementierung sollten Teams angeben, ob sie Abfragen oder Dokumente einbetten, da das Modell asymmetrische Kodierung verwendet. Das Modell ist nicht für die Echtzeitverarbeitung extrem großer Dokumentsammlungen ohne ordnungsgemäße Indizierung ausgelegt, und obwohl es sich beim mehrsprachigen Abrufen auszeichnet, kann es bei spezialisierten domänenspezifischen Aufgaben eine etwas geringere Leistung aufweisen als Modelle, die für diese spezifischen Domänen optimiert sind.","jina-embedding-b-en-v1":"Für eine optimale Bereitstellung erfordert das Modell eine CUDA-fähige GPU, obwohl seine moderate Größe eine effiziente Inferenz auf Standardhardware ermöglicht. Das Modell akzeptiert Eingabesequenzen mit einer Länge von bis zu 512 Token und eignet sich besonders gut für Produktionsumgebungen, in denen eine konsistente, zuverlässige Einbettungsgenerierung von entscheidender Bedeutung ist. Es funktioniert am besten bei englischsprachigem Inhalt und ist ideal für Anwendungen wie semantische Suche, Dokumentähnlichkeitsvergleich und Inhaltsempfehlungssysteme. Teams sollten die Verwendung der neueren Versionen v2 oder v3 für neue Projekte in Betracht ziehen, da diese eine verbesserte Leistung und eine breitere Sprachunterstützung bieten. Das Modell wird nicht für Aufgaben empfohlen, die mehrsprachiges Verständnis oder spezielles Domänenwissen über allgemeine englische Texte hinaus erfordern.","jina-embeddings-v2-base-code":"Um Jina Embeddings v2 Base Code effektiv einzusetzen, sollten Teams mehrere praktische Aspekte berücksichtigen. Das Modell lässt sich nahtlos in beliebte Vektordatenbanken wie MongoDB, Qdrant und Weaviate integrieren, sodass sich skalierbare Codesuchsysteme leicht erstellen lassen. Für optimale Leistung implementieren Sie eine geeignete Codevorverarbeitung, um das 8.192-Token-Limit zu handhaben, das normalerweise die meisten Funktions- und Klassendefinitionen abdeckt. Obwohl das Modell 30 Programmiersprachen unterstützt, zeigt es die beste Leistung in den sechs Kernsprachen: Python, JavaScript, Java, PHP, Go und Ruby. Teams sollten die Verwendung von Batchverarbeitung für die Indizierung von Code im großen Maßstab in Betracht ziehen, um die Leistung zu optimieren. Die RAG-Kompatibilität des Modells macht es besonders effektiv für die automatische Dokumentationserstellung und das Codeverständnis, obwohl Teams geeignete Chunking-Strategien für sehr große Codebasen implementieren sollten. Erwägen Sie für Produktionsbereitstellungen die Verwendung des AWS SageMaker-Endpunkts für verwaltete Inferenz und implementieren Sie geeignete Caching-Strategien, um die Abfrageleistung zu optimieren.","jina-embeddings-v2-base-de":"Um Jina Embeddings v2 Base German effektiv einzusetzen, sollten Organisationen mehrere praktische Aspekte berücksichtigen. Das Modell lässt sich nahtlos in beliebte Vektordatenbanken wie MongoDB, Qdrant und Weaviate integrieren, sodass sich skalierbare zweisprachige Suchsysteme problemlos erstellen lassen. Für eine optimale Leistung implementieren Sie eine geeignete Textvorverarbeitung, um das Limit von 8.192 Token effektiv zu handhaben – dies reicht normalerweise für etwa 15 bis 20 Textseiten. Obwohl das Modell sowohl bei deutschen als auch bei englischen Inhalten hervorragend funktioniert, ist es besonders effektiv bei sprachübergreifenden Abrufaufgaben, bei denen Abfrage- und Dokumentsprachen unterschiedlich sein können. Organisationen sollten die Implementierung von Caching-Strategien für häufig aufgerufene Inhalte in Betracht ziehen und die Stapelverarbeitung für die Indexierung von Dokumenten im großen Maßstab verwenden. Die AWS SageMaker-Integration des Modells bietet einen zuverlässigen Weg zur Produktionsbereitstellung, obwohl Teams die Token-Nutzung überwachen und eine entsprechende Ratenbegrenzung für Anwendungen mit hohem Datenverkehr implementieren sollten. Wenn Sie das Modell für RAG-Anwendungen verwenden, sollten Sie die Implementierung einer Spracherkennung in Betracht ziehen, um die Eingabeaufforderungserstellung basierend auf der Eingabesprache zu optimieren.","jina-embeddings-v2-base-en":"Um Jina Embeddings v2 Base English effektiv einzusetzen, sollten Teams mehrere praktische Aspekte berücksichtigen. Das Modell erfordert CUDA-fähige Hardware für optimale Leistung, obwohl es aufgrund seiner effizienten Architektur auf GPUs für Verbraucher laufen kann. Es ist über mehrere Kanäle verfügbar: direkter Download von Hugging Face, Bereitstellung im AWS Marketplace oder die Jina AI API mit 1 Mio. kostenlosen Token. Für Produktionsbereitstellungen bietet AWS SageMaker in der Region us-east-1 die skalierbarste Lösung. Das Modell eignet sich hervorragend für allgemeine Textanalysen, ist aber ohne Feinabstimmung möglicherweise nicht die beste Wahl für hochspezialisierte wissenschaftliche Terminologie oder fachspezifischen Jargon. Wenn Sie lange Dokumente verarbeiten, sollten Sie sie in sinnvolle semantische Blöcke aufteilen, anstatt sie willkürlich aufzuteilen, um die Kontextintegrität zu wahren. Für optimale Ergebnisse implementieren Sie eine ordnungsgemäße Textvorverarbeitung und stellen Sie saubere, gut formatierte Eingabedaten sicher.","jina-embeddings-v2-base-es":"Um dieses Modell effektiv zu nutzen, sollten Organisationen für optimale Leistung Zugriff auf eine CUDA-fähige GPU-Infrastruktur sicherstellen. Das Modell lässt sich nahtlos in die wichtigsten Vektordatenbanken und RAG-Frameworks wie MongoDB, Qdrant, Weaviate und Haystack integrieren und ist somit problemlos in Produktionsumgebungen einsetzbar. Es eignet sich hervorragend für Anwendungen wie die zweisprachige Dokumentensuche, Inhaltsempfehlungssysteme und die sprachenübergreifende Dokumentenanalyse. Obwohl das Modell eine beeindruckende Vielseitigkeit aufweist, ist es insbesondere für zweisprachige Szenarien in Spanisch und Englisch optimiert und möglicherweise nicht die beste Wahl für einsprachige Anwendungen oder Szenarien mit anderen Sprachpaaren. Für optimale Ergebnisse sollten Eingabetexte entweder in Spanisch oder Englisch richtig formatiert sein, obwohl das Modell gemischtsprachige Inhalte effektiv verarbeitet. Das Modell unterstützt die Feinabstimmung für domänenspezifische Anwendungen, dies sollte jedoch unter sorgfältiger Berücksichtigung der Qualität und Verteilung der Trainingsdaten angegangen werden.","jina-embeddings-v2-base-zh":"Das Modell erfordert 322 MB Speicherplatz und kann über mehrere Kanäle bereitgestellt werden, darunter AWS SageMaker (Region US-Ost 1) und die Jina AI API. GPU-Beschleunigung ist zwar nicht zwingend erforderlich, kann die Verarbeitungsgeschwindigkeit für Produktionsworkloads jedoch erheblich verbessern. Das Modell eignet sich hervorragend für verschiedene Anwendungen, darunter Dokumentanalyse, mehrsprachige Suche und sprachübergreifende Informationsbeschaffung. Benutzer sollten jedoch beachten, dass es speziell für zweisprachige Szenarien mit Chinesisch und Englisch optimiert ist. Für optimale Ergebnisse sollte der Eingabetext ordnungsgemäß segmentiert werden. Obwohl das Modell bis zu 8.192 Token verarbeiten kann, wird empfohlen, extrem lange Dokumente für eine bessere Leistung in semantisch sinnvolle Abschnitte aufzuteilen. Das Modell ist möglicherweise nicht für Aufgaben geeignet, die eine Echtzeitverarbeitung sehr kurzer Texte erfordern, für die spezialisierte Modelle mit geringerer Latenz möglicherweise besser geeignet sind.","jina-embeddings-v3":"Um Jina Embeddings v3 effektiv einzusetzen, sollten Teams ihren spezifischen Anwendungsfall berücksichtigen, um den geeigneten Task-Adapter auszuwählen: retrieval.query und retrieval.passage für Suchanwendungen, Trennung für Clustering-Aufgaben, Klassifizierung für Kategorisierung und Text-Matching für semantische Ähnlichkeit. Das Modell erfordert CUDA-fähige Hardware für optimale Leistung, obwohl es aufgrund seiner effizienten Architektur deutlich weniger GPU-Speicher benötigt als größere Alternativen. Für die Produktionsbereitstellung bietet die AWS SageMaker-Integration einen optimierten Weg zur Skalierbarkeit. Das Modell eignet sich hervorragend für mehrsprachige Anwendungen, erfordert jedoch möglicherweise eine zusätzliche Evaluierung für ressourcenarme Sprachen. Obwohl es lange Dokumente mit bis zu 8.192 Token unterstützt, wird optimale Leistung mit der Late-Chunking-Funktion für sehr lange Texte erreicht. Teams sollten das Modell nicht für Aufgaben verwenden, die Echtzeitgenerierung oder komplexe Schlussfolgerungen erfordern – es ist für Einbettung und Abruf konzipiert, nicht für Textgenerierung oder direkte Beantwortung von Fragen.","jina-reranker-v1-base-en":"Das Modell erfordert CUDA-fähige Hardware für optimale Leistung und ist sowohl über API-Endpunkte als auch über AWS SageMaker-Bereitstellungsoptionen zugänglich. Obwohl es extrem lange Sequenzen verarbeiten kann, sollten Benutzer den Kompromiss zwischen Kontextlänge und Verarbeitungszeit berücksichtigen – die Latenz des Modells erhöht sich bei längeren Dokumenten erheblich, von 156 ms für 256 Token auf 7068 ms für 4096 Token bei einer 512-Token-Abfrage. Für Produktionsbereitstellungen wird empfohlen, eine zweistufige Pipeline zu implementieren, bei der die Vektorsuche erste Kandidaten für die Neubewertung liefert. Das Modell ist speziell für englische Inhalte optimiert und funktioniert bei mehrsprachigen oder codelastigen Dokumenten möglicherweise nicht optimal. Bei der Integration mit RAG-Systemen sollten Benutzer die Anzahl der zur Neubewertung gesendeten Dokumente basierend auf ihren Latenzanforderungen sorgfältig anpassen, wobei 100–200 Dokumente normalerweise ein gutes Gleichgewicht zwischen Qualität und Leistung bieten.","jina-reranker-v1-tiny-en":"Um dieses Modell effektiv einzusetzen, sollten Organisationen Szenarien priorisieren, in denen Verarbeitungsgeschwindigkeit und Ressourceneffizienz entscheidende Aspekte sind. Das Modell eignet sich besonders gut für Edge-Computing-Bereitstellungen, mobile Anwendungen und Suchsysteme mit hohem Durchsatz, bei denen strenge Latenzanforderungen gelten. Obwohl es bei den meisten Reranking-Aufgaben außergewöhnlich gut funktioniert, ist es wichtig zu beachten, dass für Anwendungen, die ein absolut höchstes Maß an Ranking-Präzision erfordern, das Basismodell möglicherweise immer noch vorzuziehen ist. Das Modell erfordert eine CUDA-fähige GPU-Infrastruktur für optimale Leistung, obwohl seine effiziente Architektur bedeutet, dass es effektiv auf weniger leistungsstarker Hardware ausgeführt werden kann als seine größeren Gegenstücke. Für die Bereitstellung lässt sich das Modell nahtlos in die wichtigsten Vektordatenbanken und RAG-Frameworks integrieren und ist sowohl über die Reranker-API als auch über AWS SageMaker verfügbar. Bei der Feinabstimmung für bestimmte Domänen sollten Benutzer die Qualität der Trainingsdaten sorgfältig mit der kompakten Architektur des Modells abwägen, um seine Leistungsmerkmale beizubehalten.","jina-reranker-v1-turbo-en":"Das Modell erfordert CUDA-fähige Hardware für optimale Leistung und kann über AWS SageMaker bereitgestellt oder über API-Endpunkte aufgerufen werden. Für Produktionsbereitstellungen sollten Unternehmen eine zweistufige Pipeline implementieren, bei der die Vektorsuche erste Kandidaten für die Neubewertung bereitstellt. Obwohl das Modell 8.192 Token unterstützt, sollten Benutzer die Latenzauswirkungen längerer Sequenzen berücksichtigen – die Verarbeitungszeit steigt mit der Dokumentlänge. Der Sweet Spot für die meisten Anwendungen liegt bei der Neubewertung von 100–200 Kandidaten pro Abfrage, was Qualität und Geschwindigkeit ausbalanciert. Das Modell ist speziell für englische Inhalte optimiert und funktioniert bei mehrsprachigen Dokumenten möglicherweise nicht optimal. Die Speicheranforderungen sind deutlich niedriger als beim Basismodell und erfordern normalerweise nur 150 MB GPU-Speicher im Vergleich zu 550 MB. Dadurch eignet es sich für die Bereitstellung auf kleineren Instanzen und ermöglicht erhebliche Kosteneinsparungen in Cloud-Umgebungen.","jina-reranker-v2-base-multilingual":"Für eine optimale Bereitstellung erfordert das Modell eine CUDA-fähige GPU und kann über mehrere Kanäle aufgerufen werden, darunter die Reranker-API, wichtige RAG-Frameworks wie Haystack und LangChain, oder privat über Cloud-Marktplätze bereitgestellt werden. Das Modell eignet sich hervorragend für Szenarien, die ein genaues Verständnis über Sprachbarrieren und Datentypen hinweg erfordern, und ist daher ideal für globale Unternehmen, die mit mehrsprachigen Inhalten, API-Dokumentationen oder Code-Repositories arbeiten. Sein umfangreiches Kontextfenster mit 524.288 Token ermöglicht die Verarbeitung großer Dokumente oder ganzer Codebasen in einem einzigen Durchgang. Teams sollten die Verwendung dieses Modells in Betracht ziehen, wenn sie die Suchgenauigkeit über Sprachen hinweg verbessern müssen, Funktionsaufruffunktionen für agentenbasierte RAG-Systeme benötigen oder die Codesuchfunktionalität über mehrsprachige Codebasen hinweg verbessern möchten. Das Modell ist besonders effektiv in Verbindung mit Vektorsuchsystemen, wo es die endgültige Rangfolge der abgerufenen Dokumente erheblich verbessern kann.","reader-lm-05b":"Um Reader LM 0.5B effektiv einzusetzen, sollten Organisationen sicherstellen, dass ihre Infrastruktur die CUDA-Anforderungen des Modells erfüllen kann, obwohl seine effiziente Architektur es auf GPUs für Verbraucher laufen lässt. Das Modell funktioniert am besten mit rohem HTML-Input und erfordert keine speziellen Präfixe oder Anweisungen. Für optimale Leistung implementieren Sie den bereitgestellten Wiederholungserkennungsmechanismus, um potenzielle Token-Schleifen bei der Ausgabegenerierung zu verhindern. Obwohl das Modell mehrere Sprachen und verschiedene HTML-Strukturen unterstützt, ist es speziell für die Inhaltsextraktion und Markdown-Konvertierung konzipiert – es sollte nicht für Aufgaben wie Textgenerierung, Zusammenfassung oder direkte Beantwortung von Fragen verwendet werden. Das Modell ist über AWS SageMaker für die Produktionsbereitstellung verfügbar, und zum Testen und Experimentieren steht ein Google Colab-Notebook zur Verfügung. Teams sollten sich bewusst sein, dass das Modell zwar extrem lange Dokumente mit bis zu 256.000 Token verarbeiten kann, die Verarbeitung derart großer Eingaben jedoch möglicherweise zusätzliche Speicherverwaltungsstrategien erfordert.","reader-lm-15b":"Um Reader LM 1.5B effektiv einzusetzen, sollten sich Organisationen auf Szenarien konzentrieren, die eine komplexe HTML-Dokumentenverarbeitung beinhalten, bei der Genauigkeit und Effizienz von größter Bedeutung sind. Das Modell erfordert eine CUDA-fähige GPU-Infrastruktur für optimale Leistung, obwohl es aufgrund seiner effizienten Architektur im Vergleich zu größeren Alternativen auch auf bescheidenerer Hardware effektiv ausgeführt werden kann. Für Produktionsbereitstellungen ist das Modell sowohl über AWS SageMaker als auch über Azure Marketplace verfügbar und bietet flexible Integrationsoptionen. Obwohl das Modell bei der Konvertierung von HTML in Markdown hervorragend ist, ist es wichtig zu beachten, dass es speziell für diese Aufgabe optimiert ist und möglicherweise nicht für die allgemeine Textgenerierung oder andere NLP-Aufgaben geeignet ist. Bei der Verarbeitung extrem langer Dokumente (annähernd 512.000 Token) sollten sich Benutzer darüber im Klaren sein, dass die Leistung nachlassen kann, da dies die Trainingsparameter des Modells überschreitet. Für optimale Ergebnisse implementieren Sie die bereitgestellten Wiederholungserkennungsmechanismen und erwägen Sie die Verwendung der kontrastiven Suche während der Inferenz, um die Ausgabequalität aufrechtzuerhalten.",title:"Anleitung"},image_size:"Eingabebildgröße",language:"Sprachunterstützung",methods:{"ReaderLM-v2":"Das Training von ReaderLM-v2 basierte auf Qwen2.5-1.5B-Instruction und umfasste einen html-markdown-1m-Datensatz mit einer Million HTML-Dokumenten mit durchschnittlich 56.000 Token. Der Trainingsprozess umfasste: 1) Vortraining mit langem Kontext unter Verwendung von Ring-Zag-Aufmerksamkeit und RoPE, um den Kontext von 32.000 auf 256.000 Token zu erweitern, 2) überwachtes Feintuning mit verfeinerten Datensätzen, 3) direkte Präferenzoptimierung für die Ausgabeausrichtung und 4) Feintuning der Selbstspielverstärkung. Die Datenaufbereitung folgte einer dreistufigen Pipeline (Entwurf-Verfeinerung-Kritik), die von Qwen2.5-32B-Instruction unterstützt wurde, wobei spezialisierte Modelle für bestimmte Aufgaben trainiert wurden, bevor sie über lineare Parameterinterpolation zusammengeführt wurden.","jina-clip-v1":"Die Architektur des Modells stellt eine bedeutende Innovation im multimodalen KI-Design dar und kombiniert einen angepassten Jina BERT v2-Textencoder mit dem hochmodernen EVA-02-Bildencoder der Beijing Academy for Artificial Intelligence. Der Textencoder unterstützt Sequenzen mit bis zu 12.288 Token – über 100-mal länger als das 77-Token-Limit des ursprünglichen CLIP – während der Bildencoder 16 Patch-Token effizient verarbeitet. Der Trainingsprozess folgt einem neuartigen dreistufigen Ansatz: Erstens das Ausrichten von Bild-Untertitel-Paaren unter Beibehaltung des Textverständnisses durch verschachteltes Textpaartraining; zweitens das Integrieren von KI-generierten längeren Textbeschreibungen von Bildern; und schließlich die Verwendung harter negativer Texttripel zur Verbesserung der semantischen Unterscheidungsfähigkeiten. Diese einzigartige Trainingsmethode ermöglicht es dem Modell, sowohl bei kurzen Untertiteln als auch bei detaillierten Textbeschreibungen eine hohe Leistung aufrechtzuerhalten und gleichzeitig ein starkes visuelles Verständnis zu bewahren.","jina-clip-v2":"Im Kern verwendet Jina CLIP v2 eine ausgeklügelte Dual-Encoder-Architektur, die einen Jina XLM-RoBERTa-Text-Encoder (561 Millionen Parameter) mit einem EVA02-L14-Vision-Encoder (304 Millionen Parameter) kombiniert. Der Text-Encoder verarbeitet Inhalte in 89 Sprachen mit einem riesigen Kontextfenster von 696.320 Token, während der Vision-Encoder hochauflösende Bilder mit bis zu 512 x 512 Pixeln verarbeitet. Das Modell führt innovatives Matryoshka-Repräsentationslernen ein, das eine dynamische Anpassung der Einbettungsdimension von 1024 auf 64 Dimensionen unter Beibehaltung der Leistung ermöglicht. Diese Architektur verarbeitet sowohl Text als auch Bilder über ihre jeweiligen Encoder und projiziert sie in einen gemeinsamen semantischen Raum, in dem ähnliche Konzepte unabhängig von ihrer ursprünglichen Modalität oder Sprache ausgerichtet sind.","jina-colbert-v1-en":"Das Modell verwendet eine innovative Late-Interaction-Architektur, die die Funktionsweise des Dokumentabrufs grundlegend verändert. Anstatt ganze Dokumente auf einmal zu vergleichen, verarbeitet es Abfragen und Dokumente bis zur letzten Matching-Phase unabhängig voneinander und verwendet dabei eine angepasste Version des ColBERT-Ansatzes. Die Architektur kombiniert zwei Schlüsselkomponenten: einen Dokument-Encoder, der Text mit bis zu 8.192 Token verarbeitet (über 16-mal länger als Standard-Transformatoren) und einen Abfrage-Encoder, der präzise Darstellungen auf Token-Ebene erstellt. Jedes Token in Abfrage und Dokument erhält seinen eigenen 128-dimensionalen Einbettungsvektor, wodurch feinkörnige semantische Informationen erhalten bleiben, die in Einzelvektormodellen verloren gehen würden. Der Late-Interaction-Mechanismus ermöglicht dann ein effizientes Token-für-Token-Matching zwischen Abfragen und Dokumenten, wobei Max-Pooling- und Summationsoperationen verwendet werden, um endgültige Relevanzwerte zu berechnen, ohne dass aufwändige All-to-All-Vergleiche erforderlich sind.","jina-colbert-v2":"Das Modell baut auf der ColBERT-Architektur auf und führt einen ausgeklügelten Mechanismus für späte Interaktion ein, der die Art und Weise, wie Abfragen und Dokumente abgeglichen werden, grundlegend verändert. Im Kern verwendet es ein modifiziertes XLM-RoBERTa-Backbone mit 560 Millionen Parametern, das durch rotierende Positionseinbettungen erweitert und mit Flash Attention optimiert wird. Der Trainingsprozess umfasst zwei wichtige Phasen: anfängliches Vortraining mit unterschiedlichen, schwach überwachten Daten aus verschiedenen Sprachen, gefolgt von Feinabstimmung mit gekennzeichneten Triplettdaten und überwachter Destillation. Was diesen Ansatz einzigartig macht, ist die Implementierung des Matryoshka-Darstellungslernens, das es dem Modell ermöglicht, Einbettungen in mehreren Dimensionen (128, 96 oder 64) aus einem einzigen Trainingsprozess zu erstellen, was eine dynamische Speicheroptimierung ohne erneutes Training ermöglicht.","jina-embedding-b-en-v1":"Das Modell verwendet eine T5-Encoder-basierte Architektur, die mit Mean Pooling erweitert wurde, um Darstellungen mit fester Länge zu generieren. Das Modell wurde anhand des sorgfältig kuratierten Linnaeus-Clean-Datensatzes trainiert, der 385 Millionen hochwertige Satzpaare enthält, die aus anfänglich 1,6 Milliarden Paaren herausgefiltert wurden, und durchlief einen zweiphasigen Trainingsprozess. Die erste Phase nutzte kontrastives Lernen mit InfoNCE-Verlust bei Textpaaren, während die zweite Phase ein Triplet-Training beinhaltete, um die Fähigkeit des Modells zu verfeinern, zwischen ähnlichen und unähnlichen Inhalten zu unterscheiden. Dieser innovative Trainingsansatz, kombiniert mit strenger Datenfilterung einschließlich Spracherkennung und Konsistenzprüfung, ermöglicht es dem Modell, nuancierte semantische Beziehungen effektiv zu erfassen.","jina-embeddings-v2-base-code":"Das Modell erreicht seine beeindruckende Leistung durch eine spezielle Architektur, die speziell für das Codeverständnis entwickelt wurde. Im Kern verwendet es ein transformatorbasiertes neuronales Netzwerk mit 161 Millionen Parametern, das anhand verschiedener Programmiersprachen-Datensätze trainiert wurde, wobei der Schwerpunkt auf sechs Hauptsprachen liegt: Python, JavaScript, Java, PHP, Go und Ruby. Was diese Architektur einzigartig macht, ist ihr erweitertes Kontextfenster mit 8.192 Token, das es ermöglicht, ganze Funktionen oder mehrere Dateien gleichzeitig zu verarbeiten und gleichzeitig das semantische Verständnis aufrechtzuerhalten. Das Modell generiert dichte 768-dimensionale Einbettungen, die sowohl die syntaktische Struktur als auch die semantische Bedeutung des Codes erfassen und es ihm ermöglichen, Beziehungen zwischen verschiedenen Codesegmenten zu verstehen, selbst wenn sie unterschiedliche Programmiermuster oder Syntax verwenden, um dasselbe Ziel zu erreichen.","jina-embeddings-v2-base-de":"Das Modell erreicht seine beeindruckenden zweisprachigen Fähigkeiten durch eine innovative Architektur, die sowohl deutsche als auch englische Texte in einem einheitlichen 768-dimensionalen Einbettungsraum verarbeitet. Im Kern verwendet es ein transformatorbasiertes neuronales Netzwerk mit 161 Millionen Parametern, das sorgfältig darauf trainiert wurde, semantische Beziehungen zwischen beiden Sprachen zu verstehen. Was diese Architektur besonders effektiv macht, ist ihr Ansatz zur Minimierung von Verzerrungen, der speziell darauf ausgelegt ist, die häufige Falle der Bevorzugung englischer Grammatikstrukturen zu vermeiden - ein Problem, das in jüngsten Untersuchungen mit mehrsprachigen Modellen festgestellt wurde. Das erweiterte Kontextfenster des Modells mit 8.192 Token ermöglicht es ihm, ganze Dokumente oder mehrere Textseiten in einem einzigen Durchgang zu verarbeiten und dabei die semantische Kohärenz über lange Inhalte in beiden Sprachen hinweg aufrechtzuerhalten.","jina-embeddings-v2-base-en":"Die Architektur des Modells kombiniert ein BERT Small-Backbone mit einem innovativen symmetrischen bidirektionalen ALiBi-Mechanismus (Attention with Linear Biases), wodurch die Notwendigkeit herkömmlicher Positionseinbettungen entfällt. Diese architektonische Wahl ermöglicht es dem Modell, weit über seine Trainingslänge von 512 Token hinaus zu extrapolieren und Sequenzen von bis zu 8.192 Token ohne Leistungseinbußen zu verarbeiten. Der Trainingsprozess umfasste zwei Schlüsselphasen: anfängliches Vortraining auf dem C4-Datensatz, gefolgt von einer Verfeinerung auf der kuratierten Sammlung von über 40 spezialisierten Datensätzen von Jina AI. Diese vielfältigen Trainingsdaten, darunter anspruchsvolle Negativbeispiele und abwechslungsreiche Satzpaare, gewährleisten eine robuste Leistung in verschiedenen Bereichen und Anwendungsfällen. Das Modell erzeugt 768-dimensionale dichte Vektoren, die nuancierte semantische Beziehungen erfassen, was mit relativ bescheidenen 137 Millionen Parametern erreicht wird.","jina-embeddings-v2-base-es":"Das Herzstück dieses Modells ist eine innovative Architektur, die auf symmetrischem bidirektionalem ALiBi (Attention with Linear Biases) basiert, einem ausgeklügelten Ansatz, der die Verarbeitung von Sequenzen mit bis zu 8.192 Token ohne traditionelle Positionseinbettungen ermöglicht. Das Modell verwendet eine modifizierte BERT-Architektur mit 161 Millionen Parametern, die Gated Linear Units (GLU) und spezielle Layer-Normalisierungstechniken enthält. Das Training erfolgt in einem dreistufigen Prozess: anfängliches Vortraining anhand eines riesigen Textkorpus, gefolgt von Feinabstimmung mit sorgfältig kuratierten Textpaaren und schließlich hartes Negativtraining zur Verbesserung der Unterscheidung zwischen ähnlichen, aber semantisch unterschiedlichen Inhalten. Dieser Ansatz, kombiniert mit 768-dimensionalen Einbettungen, ermöglicht es dem Modell, nuancierte semantische Beziehungen zu erfassen und gleichzeitig die Rechenleistung aufrechtzuerhalten.","jina-embeddings-v2-base-zh":"Die Architektur des Modells kombiniert ein BERT-basiertes Backbone mit symmetrischem bidirektionalem ALiBi (Attention with Linear Biases) und ermöglicht so die effiziente Verarbeitung langer Sequenzen ohne die traditionelle 512-Token-Beschränkung. Der Trainingsprozess folgt einem sorgfältig orchestrierten dreiphasigen Ansatz: anfängliches Vortraining mit hochwertigen zweisprachigen Daten, gefolgt von primären und sekundären Feinabstimmungsphasen. Diese methodische Trainingsstrategie, gepaart mit den 161 Millionen Parametern und der 768-dimensionalen Ausgabe des Modells, erreicht eine bemerkenswerte Effizienz bei gleichzeitiger Beibehaltung einer ausgewogenen Leistung in beiden Sprachen. Der symmetrische bidirektionale ALiBi-Mechanismus stellt eine bedeutende Innovation dar, die es dem Modell ermöglicht, Dokumente mit einer Länge von bis zu 8.192 Token zu verarbeiten – eine Fähigkeit, die bisher proprietären Lösungen vorbehalten war.","jina-embeddings-v3":"Die Architektur des Modells stellt eine bedeutende Innovation in der Einbettungstechnologie dar. Sie basiert auf jina-XLM-RoBERTa mit 24 Schichten und wurde mit aufgabenspezifischen Low-Rank Adaptation (LoRA)-Adaptern erweitert. LoRA-Adapter sind spezialisierte neuronale Netzwerkkomponenten, die das Modell für verschiedene Aufgaben wie Abruf, Klassifizierung oder Clustering optimieren, ohne die Parameteranzahl wesentlich zu erhöhen – sie erhöhen die Gesamtparameter um weniger als 3 %. Das Modell enthält Matryoshka Representation Learning (MRL), wodurch Einbettungen flexibel von 1024 auf bis zu 32 Dimensionen reduziert werden können, während die Leistung erhalten bleibt. Das Training umfasste einen dreistufigen Prozess: anfängliches Vortraining mit mehrsprachigem Text aus 89 Sprachen, Feinabstimmung gepaarter Texte für die Einbettungsqualität und spezialisiertes Adaptertraining zur Aufgabenoptimierung. Das Modell unterstützt Kontextlängen von bis zu 8.192 Token durch Rotary Position Embeddings (RoPE) mit einer innovativen Basisfrequenzanpassungstechnik, die die Leistung sowohl bei kurzen als auch bei langen Texten verbessert.","jina-reranker-v1-base-en":"Das Modell verwendet eine BERT-basierte Cross-Attention-Architektur, die sich grundlegend von traditionellen, auf Einbettung basierenden Ansätzen unterscheidet. Anstatt vorab berechnete Dokument-Einbettungen zu vergleichen, führt es dynamische Interaktionen auf Token-Ebene zwischen Abfragen und Dokumenten durch, wodurch es kontextuelle Nuancen erfassen kann, die einfache Ähnlichkeitsmetriken übersehen. Die 137 Millionen Parameter der Architektur sind sorgfältig strukturiert, um ein tiefes semantisches Verständnis zu ermöglichen und gleichzeitig die Rechenleistung aufrechtzuerhalten. Eine herausragende Innovation ist die Fähigkeit, Sequenzen mit bis zu 262.144 Token zu verarbeiten – weit über die typischen Modellbeschränkungen hinaus –, was durch ausgefeilte Optimierungstechniken erreicht wird, die trotz des vergrößerten Kontextfensters schnelle Inferenzgeschwindigkeiten aufrechterhalten.","jina-reranker-v1-tiny-en":"Das Modell verwendet eine optimierte vierschichtige Architektur auf Basis von JinaBERT mit symmetrischem bidirektionalem ALiBi (Attention with Linear Biases), was eine effiziente Verarbeitung langer Sequenzen ermöglicht. Seine Entwicklung nutzt einen fortschrittlichen Ansatz zur Wissensdestillation, bei dem ein größeres, leistungsstarkes Lehrermodell (jina-reranker-v1-base-en) den Trainingsprozess leitet, sodass das kleinere Modell optimales Rankingverhalten erlernen kann, ohne umfangreiche reale Trainingsdaten zu benötigen. Diese innovative Trainingsmethode, kombiniert mit Architekturoptimierungen wie reduzierten verborgenen Schichten und effizienten Aufmerksamkeitsmechanismen, ermöglicht es dem Modell, qualitativ hochwertige Rankings beizubehalten und gleichzeitig den Rechenleistungsbedarf deutlich zu reduzieren. Das Ergebnis ist ein Modell, das eine bemerkenswerte Effizienz erreicht, ohne seine Fähigkeit zum Verstehen komplexer Dokumentbeziehungen zu beeinträchtigen.","jina-reranker-v1-turbo-en":"Das Modell erreicht seine Effizienz durch eine innovative sechsschichtige Architektur, die die anspruchsvollen Reranking-Fähigkeiten seines größeren Gegenstücks auf nur 37,8 Millionen Parameter komprimiert – eine drastische Reduzierung gegenüber den 137 Millionen des Basismodells. Dieses optimierte Design verwendet Wissensdestillation, wobei das größere Basismodell als Lehrer fungiert und die Turbovariante trainiert, um sein Verhalten anzupassen und dabei weniger Ressourcen zu verwenden. Die Architektur behält den zentralen BERT-basierten Cross-Attention-Mechanismus für Interaktionen auf Token-Ebene zwischen Abfragen und Dokumenten bei, optimiert ihn jedoch auf Geschwindigkeit durch eine reduzierte Schichtanzahl und eine effiziente Parameterzuweisung. Das Modell unterstützt Sequenzen mit bis zu 8.192 Token und ermöglicht so eine umfassende Dokumentenanalyse bei gleichzeitiger Beibehaltung schneller Inferenzgeschwindigkeiten durch anspruchsvolle Optimierungstechniken.","jina-reranker-v2-base-multilingual":"Das Modell verwendet eine Cross-Encoder-Architektur, die mit Flash Attention 2 erweitert wurde und einen direkten Vergleich zwischen Abfragen und Dokumenten ermöglicht, um eine genauere Relevanzbewertung zu erzielen. Das Modell wird in einem vierstufigen Prozess trainiert. Zunächst werden die Fähigkeiten der englischen Sprache aufgebaut, dann werden nach und nach sprachübergreifende und mehrsprachige Daten integriert, bevor die endgültige Verfeinerung mit Hard-Negative-Beispielen erfolgt. Dieser innovative Trainingsansatz in Kombination mit der Flash Attention 2-Implementierung ermöglicht es dem Modell, Sequenzen mit bis zu 524.288 Token zu verarbeiten und dabei eine außergewöhnliche Geschwindigkeit beizubehalten. Dank der Effizienz der Architektur kann es komplexe Neubewertungsaufgaben in mehreren Sprachen mit einem 6-mal höheren Durchsatz als sein Vorgänger bewältigen und gleichzeitig eine genaue Relevanzbewertung durch direkte Abfrage-Dokument-Interaktion gewährleisten.","reader-lm-05b":"Das Modell verwendet eine innovative „flache, aber breite“ Architektur, die speziell für selektive Kopiervorgänge und nicht für die kreative Textgenerierung optimiert ist. Das Modell basiert auf einer reinen Decoder-Grundlage mit 24 Schichten und 896 verborgenen Dimensionen und verwendet spezialisierte Aufmerksamkeitsmechanismen mit 14 Abfrageköpfen und 2 Schlüssel-Wert-Köpfen, um Eingabesequenzen effizient zu verarbeiten. Der Trainingsprozess umfasste zwei unterschiedliche Phasen: zuerst mit kürzerem, einfacherem HTML (32.000 Token), um grundlegende Konvertierungsmuster zu erlernen, dann mit komplexem, realitätsnahem HTML (128.000 Token), um anspruchsvolle Fälle zu bewältigen. Das Modell integriert während des Trainings eine kontrastive Suche und implementiert einen Wiederholungserkennungsmechanismus, um Degenerationsprobleme wie Token-Schleifen zu verhindern. Ein einzigartiger Aspekt seiner Architektur ist der Zickzack-Ring-Aufmerksamkeitsmechanismus, der es dem Modell ermöglicht, extrem lange Sequenzen mit bis zu 256.000 Token zu verarbeiten und dabei eine stabile Leistung aufrechtzuerhalten.","reader-lm-15b":"Das Modell verwendet eine innovative „flache, aber breite“ Architektur, die traditionelle Skalierungsansätze im Sprachmodelldesign in Frage stellt. Sein Kern sind 28 Transformer-Schichten, die mit 12 Abfrageköpfen und 2 Schlüssel-Wert-Köpfen konfiguriert sind, wodurch ein einzigartiges Gleichgewicht entsteht, das selektive Kopiervorgänge optimiert und gleichzeitig ein tiefes semantisches Verständnis aufrechterhält. Die Architektur verfügt über eine versteckte Größe von 1536 und eine Zwischengröße von 8960, die sorgfältig darauf abgestimmt ist, Sequenzen mit bis zu 256.000 Token zu verarbeiten. Der Trainingsprozess umfasste zwei unterschiedliche Phasen: Zuerst konzentrierte man sich auf kurzes und einfaches HTML mit 32.000 Tokensequenzen, dann ging es weiter zu langem und schwierigem HTML mit 128.000 Token, wobei Zickzack-Ring-Attention für eine effiziente Verarbeitung implementiert wurde. Dieser Ansatz, kombiniert mit kontrastiver Suche und speziellen Wiederholungserkennungsmechanismen, ermöglicht es dem Modell, häufige Probleme wie Degeneration und langweilige Schleifen zu vermeiden, die normalerweise kleinere Sprachmodelle plagen, die komplexe Dokumentverarbeitungsaufgaben bewältigen.",title:"Methoden"},model_comparison:"Modellvergleich",model_details:"Modelldetails",model_io_graph:"E/A-Diagramm {_number}",model_name:"Name",output_dimension:"Ausgabedimension",overview:{"ReaderLM-v2":"ReaderLM-v2 ist ein 1,5-B-Parameter-Sprachmodell, das reines HTML in Markdown oder JSON konvertiert und bis zu 512.000 Tokens kombinierte Eingabe-/Ausgabelänge mit Unterstützung für 29 Sprachen verarbeitet. Anders als sein Vorgänger, der HTML-zu-Markdown als „selektives Kopieren“ behandelte, geht v2 es als Übersetzungsprozess an und ermöglicht so eine bessere Verarbeitung komplexer Elemente wie Codezäune, verschachtelte Listen, Tabellen und LaTeX-Gleichungen. Das Modell behält eine konsistente Leistung über verschiedene Kontextlängen hinweg bei und führt direkte HTML-zu-JSON-Generierungsfunktionen mit vordefinierten Schemata ein.","jina-clip-v1":"Jina CLIP v1 revolutioniert die multimodale KI, indem es das erste Modell ist, das sowohl bei Text-zu-Text- als auch bei Text-zu-Bild-Abrufaufgaben gleichermaßen hervorragende Ergebnisse liefert. Im Gegensatz zu herkömmlichen CLIP-Modellen, die mit reinen Textszenarien zu kämpfen haben, erreicht dieses Modell eine hochmoderne Leistung über alle Abrufkombinationen hinweg und behält dabei eine bemerkenswert kompakte Parametergröße von 223 M bei. Das Modell befasst sich mit einer kritischen Herausforderung der Branche, indem es die Notwendigkeit separater Modelle für die Text- und Bildverarbeitung eliminiert und so die Systemkomplexität und den Rechenaufwand reduziert. Für Teams, die Suchsysteme, Empfehlungsmaschinen oder Tools zur Inhaltsanalyse erstellen, bietet Jina CLIP v1 eine einzige, effiziente Lösung, die sowohl Text- als auch visuelle Inhalte mit außergewöhnlicher Genauigkeit verarbeitet.","jina-clip-v2":"Jina CLIP v2 revolutioniert die multimodale KI, indem es die Lücke zwischen visuellem und textlichem Verständnis in 89 Sprachen schließt. Dieses Modell löst kritische Herausforderungen im globalen E-Commerce, im Content Management und in der interkulturellen Kommunikation, indem es eine genaue Bild-Text-Übereinstimmung unabhängig von Sprachbarrieren ermöglicht. Für Unternehmen, die international expandieren oder mehrsprachige Inhalte verwalten, macht es separate Modelle pro Sprache oder komplexe Übersetzungspipelines überflüssig. Das Modell glänzt insbesondere in Szenarien, die eine präzise visuelle Suche über Sprachgrenzen hinweg erfordern, wie z. B. die Produktfindung auf globalen Marktplätzen oder das mehrsprachige digitale Asset-Management.","jina-colbert-v1-en":"Jina-ColBERT-v1-en revolutioniert die Textsuche, indem es eine kritische Herausforderung bei der Informationsbeschaffung löst: das Erreichen einer hohen Genauigkeit ohne Einbußen bei der Rechenleistung. Im Gegensatz zu herkömmlichen Modellen, die ganze Dokumente in einzelne Vektoren komprimieren, behält dieses Modell ein präzises Verständnis auf Token-Ebene bei und benötigt dabei nur 137 Millionen Parameter. Für Teams, die Suchanwendungen, Empfehlungssysteme oder Content-Discovery-Plattformen erstellen, eliminiert Jina-ColBERT-v1-en den traditionellen Kompromiss zwischen Suchqualität und Systemleistung. Das Modell glänzt insbesondere in Szenarien, in denen ein differenziertes Textverständnis entscheidend ist, wie z. B. bei der Suche nach technischer Dokumentation, beim Abrufen akademischer Arbeiten oder bei jeder Anwendung, bei der das Erfassen subtiler semantischer Beziehungen den Unterschied zwischen dem Finden der richtigen Informationen und dem Übersehen kritischer Inhalte ausmachen kann.","jina-colbert-v2":"Jina-ColBERT-v2 ist ein bahnbrechendes mehrsprachiges Informationsabrufmodell, das die kritische Herausforderung einer effizienten, qualitativ hochwertigen Suche in mehreren Sprachen löst. Als erstes mehrsprachiges ColBERT-ähnliches Modell, das kompakte Einbettungen generiert, geht es auf den wachsenden Bedarf an skalierbaren, kostengünstigen mehrsprachigen Suchlösungen in globalen Anwendungen ein. Organisationen, die mit mehrsprachigen Inhalten arbeiten, von E-Commerce-Plattformen bis hin zu Content-Management-Systemen, können dieses Modell nutzen, um genaue Suchergebnisse in 89 Sprachen bereitzustellen und gleichzeitig durch seine innovativen Dimensionsreduzierungsfunktionen die Speicher- und Rechenkosten erheblich zu senken.","jina-embedding-b-en-v1":"Jina Embedding B v1 ist ein spezialisiertes Text-Embedding-Modell, das englische Texte in hochdimensionale numerische Darstellungen transformiert und dabei die semantische Bedeutung beibehält. Das Modell erfüllt den kritischen Bedarf an effizienten und genauen Text-Embeddings in Produktionsumgebungen und ist besonders wertvoll für Organisationen, die ein Gleichgewicht zwischen Rechenleistung und Einbettungsqualität benötigen. Mit seinen 110 Millionen Parametern, die 768-dimensionale Embeddings generieren, dient es als praktische Lösung für Teams, die semantische Such-, Dokumentclustering- oder Inhaltsempfehlungssysteme implementieren, ohne umfangreiche Rechenressourcen zu benötigen.","jina-embeddings-v2-base-code":"Jina Embeddings v2 Base Code bewältigt eine entscheidende Herausforderung der modernen Softwareentwicklung: die effiziente Navigation und das Verständnis großer Codebasen. Für Entwicklungsteams, die mit der Code-Erkennung und -Dokumentation zu kämpfen haben, verändert dieses Modell die Art und Weise, wie Entwickler mit Code interagieren, indem es die Suche in natürlicher Sprache in 30 Programmiersprachen ermöglicht. Im Gegensatz zu herkömmlichen Code-Suchtools, die auf exakter Musterübereinstimmung basieren, versteht dieses Modell die semantische Bedeutung hinter dem Code und ermöglicht es Entwicklern, relevante Codeausschnitte anhand einfacher englischer Beschreibungen zu finden. Diese Funktion ist besonders wertvoll für Teams, die große Legacy-Codebasen pflegen, Entwickler, die in neue Projekte einsteigen, oder Organisationen, die die Wiederverwendung von Code und die Dokumentationspraktiken verbessern möchten.","jina-embeddings-v2-base-de":"Jina Embeddings v2 Base German befasst sich mit einer kritischen Herausforderung im internationalen Geschäft: der Überbrückung der Sprachbarriere zwischen dem deutschen und dem englischen Markt. Für deutsche Unternehmen, die in englischsprachige Gebiete expandieren, wo ein Drittel der Unternehmen über 20 % ihres weltweiten Umsatzes erwirtschaftet, ist ein genaues zweisprachiges Verständnis unerlässlich. Dieses Modell verändert die Art und Weise, wie Unternehmen mit sprachenübergreifenden Inhalten umgehen, indem es nahtloses Textverständnis und -abrufen sowohl auf Deutsch als auch auf Englisch ermöglicht. Damit ist es von unschätzbarem Wert für Unternehmen, die internationale Dokumentationssysteme, Kundensupportplattformen oder Content-Management-Lösungen implementieren. Im Gegensatz zu herkömmlichen übersetzungsbasierten Ansätzen ordnet dieses Modell äquivalente Bedeutungen in beiden Sprachen direkt demselben Einbettungsraum zu und ermöglicht so genauere und effizientere zweisprachige Abläufe.","jina-embeddings-v2-base-en":"Jina Embeddings v2 Base English ist ein bahnbrechendes Open-Source-Text-Embedding-Modell, das die kritische Herausforderung der Verarbeitung langer Dokumente bei gleichzeitig hoher Genauigkeit löst. Organisationen, die mit der Analyse umfangreicher juristischer Dokumente, Forschungsarbeiten oder Finanzberichte zu kämpfen haben, werden dieses Modell besonders wertvoll finden. Es zeichnet sich dadurch aus, dass es Dokumente mit einer Länge von bis zu 8.192 Token verarbeiten kann – 16-mal länger als herkömmliche Modelle – und dabei die gleiche Leistung wie die proprietären Lösungen von OpenAI bietet. Mit einer kompakten Größe von 0,27 GB und effizienter Ressourcennutzung bietet es eine zugängliche Lösung für Teams, die erweiterte Dokumentanalysen ohne übermäßigen Rechenaufwand implementieren möchten.","jina-embeddings-v2-base-es":"Jina Embeddings v2 Base Spanish ist ein bahnbrechendes zweisprachiges Texteinbettungsmodell, das sich der kritischen Herausforderung der sprachübergreifenden Informationsbeschaffung und -analyse von spanischen und englischen Inhalten stellt. Im Gegensatz zu herkömmlichen mehrsprachigen Modellen, die häufig eine Voreingenommenheit gegenüber bestimmten Sprachen zeigen, liefert dieses Modell eine wirklich ausgewogene Leistung sowohl auf Spanisch als auch auf Englisch und ist daher unverzichtbar für Organisationen, die in spanischsprachigen Märkten tätig sind oder zweisprachige Inhalte verarbeiten. Das bemerkenswerteste Merkmal des Modells ist seine Fähigkeit, geometrisch ausgerichtete Einbettungen zu generieren – wenn Texte auf Spanisch und Englisch dieselbe Bedeutung ausdrücken, gruppieren sich ihre Vektordarstellungen auf natürliche Weise im Einbettungsraum und ermöglichen so eine nahtlose sprachübergreifende Suche und Analyse.","jina-embeddings-v2-base-zh":"Jina Embeddings v2 Base Chinese beschreitet neue Wege als erstes Open-Source-Modell, das sowohl chinesische als auch englische Texte mit einer beispiellosen Kontextlänge von 8.192 Token nahtlos verarbeitet. Dieses zweisprachige Kraftpaket geht auf eine entscheidende Herausforderung im globalen Geschäft ein: die Notwendigkeit einer genauen Verarbeitung von Langformatdokumenten mit chinesischem und englischem Inhalt. Im Gegensatz zu herkömmlichen Modellen, die mit dem sprachenübergreifenden Verständnis zu kämpfen haben oder separate Modelle für jede Sprache erfordern, bildet dieses Modell äquivalente Bedeutungen in beiden Sprachen im selben Einbettungsraum ab, was es für global expandierende oder mehrsprachige Inhalte verwaltende Unternehmen von unschätzbarem Wert macht.","jina-embeddings-v3":"Jina Embeddings v3 ist ein bahnbrechendes mehrsprachiges Text-Embedding-Modell, das die Art und Weise verändert, wie Organisationen Textverständnis und -abruf über verschiedene Sprachen hinweg handhaben. Im Kern löst es die kritische Herausforderung, eine hohe Leistung über mehrere Sprachen und Aufgaben hinweg aufrechtzuerhalten und gleichzeitig die Rechenleistungsanforderungen überschaubar zu halten. Das Modell glänzt insbesondere in Produktionsumgebungen, in denen es auf Effizienz ankommt – es erreicht modernste Leistung mit nur 570 Millionen Parametern und ist damit für Teams zugänglich, die sich den Rechenaufwand größerer Modelle nicht leisten können. Organisationen, die skalierbare, mehrsprachige Suchsysteme erstellen oder Inhalte über Sprachbarrieren hinweg analysieren müssen, werden dieses Modell besonders wertvoll finden.","jina-reranker-v1-base-en":"Jina Reranker v1 Base English revolutioniert die Verfeinerung von Suchergebnissen, indem es eine kritische Einschränkung herkömmlicher Vektorsuchsysteme behebt: die Unfähigkeit, nuancierte Beziehungen zwischen Abfragen und Dokumenten zu erfassen. Während die Vektorsuche mit Kosinusähnlichkeit schnelle erste Ergebnisse liefert, übersieht sie häufig subtile Relevanzsignale, die menschliche Benutzer intuitiv verstehen. Dieser Reranker schließt diese Lücke, indem er eine anspruchsvolle Analyse auf Token-Ebene sowohl von Abfragen als auch von Dokumenten durchführt und so eine bemerkenswerte Verbesserung der Suchgenauigkeit um 20 % erzielt. Für Organisationen, die mit der Suchgenauigkeit zu kämpfen haben oder RAG-Systeme implementieren, bietet dieses Modell eine leistungsstarke Lösung, die die Ergebnisqualität erheblich verbessert, ohne dass eine vollständige Überholung der vorhandenen Suchinfrastruktur erforderlich ist.","jina-reranker-v1-tiny-en":"Jina Reranker v1 Tiny English stellt einen Durchbruch bei der effizienten Suchverfeinerung dar und wurde speziell für Organisationen entwickelt, die eine leistungsstarke Neubewertung in ressourcenbeschränkten Umgebungen benötigen. Dieses Modell befasst sich mit der kritischen Herausforderung, die Suchqualität beizubehalten und gleichzeitig den Rechenaufwand und die Bereitstellungskosten erheblich zu senken. Mit nur 33 Millionen Parametern – einem Bruchteil der typischen Reranker-Größen – bietet es durch innovative Techniken zur Wissensdestillation eine bemerkenswert wettbewerbsfähige Leistung. Das überraschendste Merkmal des Modells ist seine Fähigkeit, Dokumente fast fünfmal schneller als Basismodelle zu verarbeiten und dabei über 92 % ihrer Genauigkeit beizubehalten. Dadurch wird die Suchverfeinerung auf Unternehmensniveau für Anwendungen zugänglich, bei denen Rechenressourcen knapp sind.","jina-reranker-v1-turbo-en":"Jina Reranker v1 Turbo English befasst sich mit einer kritischen Herausforderung in Produktionssuchsystemen: dem Kompromiss zwischen Ergebnisqualität und Rechenleistung. Während herkömmliche Reranker eine verbesserte Suchgenauigkeit bieten, sind sie aufgrund ihrer Rechenleistungsanforderungen für Echtzeitanwendungen oft unpraktisch. Dieses Modell durchbricht diese Barriere, indem es 95 % der Genauigkeit des Basismodells liefert, Dokumente dabei dreimal schneller verarbeitet und 75 % weniger Speicher verbraucht. Für Organisationen, die mit Suchlatenz oder Rechenkosten zu kämpfen haben, bietet dieses Modell eine überzeugende Lösung, die eine qualitativ hochwertige Suchverfeinerung beibehält und gleichzeitig die Infrastrukturanforderungen und Betriebskosten erheblich reduziert.","jina-reranker-v2-base-multilingual":"Jina Reranker v2 Base Multilingual ist ein Cross-Encoder-Modell, das die Suchgenauigkeit über Sprachbarrieren und Datentypen hinweg verbessern soll. Dieser Reranker befasst sich mit der kritischen Herausforderung der präzisen Informationsbeschaffung in mehrsprachigen Umgebungen und ist besonders wertvoll für globale Unternehmen, die Suchergebnisse über verschiedene Sprachen und Inhaltstypen hinweg verfeinern müssen. Mit Unterstützung für über 100 Sprachen und einzigartigen Funktionen für Funktionsaufrufe und Codesuche dient es als einheitliche Lösung für Teams, die eine genaue Suchverfeinerung für internationale Inhalte, API-Dokumentation und mehrsprachige Codebasen benötigen. Das kompakte 278-M-Parameterdesign des Modells macht es besonders attraktiv für Organisationen, die eine Balance zwischen hoher Leistung und Ressourceneffizienz suchen.","reader-lm-05b":"Reader LM 0.5B ist ein spezialisiertes Sprachmodell, das die komplexe Herausforderung der Konvertierung von HTML-Dokumenten in sauberen, strukturierten Markdown-Text löst. Dieses Modell erfüllt ein wichtiges Bedürfnis moderner Datenverarbeitungs-Pipelines: die effiziente Umwandlung unübersichtlicher Webinhalte in ein Format, das sich ideal für LLMs und Dokumentationssysteme eignet. Im Gegensatz zu allgemeinen Sprachmodellen, die enorme Rechenressourcen erfordern, erreicht Reader LM 0.5B eine professionelle HTML-Verarbeitung mit nur 494 Millionen Parametern und ist damit für Teams mit begrenzten Rechenressourcen zugänglich. Organisationen, die sich mit der Verarbeitung von Webinhalten, der Automatisierung von Dokumentationen oder der Entwicklung von LLM-basierten Anwendungen befassen, werden dieses Modell besonders wertvoll finden, um ihre Workflows zur Inhaltsvorbereitung zu optimieren.","reader-lm-15b":"Reader LM 1.5B stellt einen Durchbruch in der effizienten Dokumentenverarbeitung dar und bewältigt die kritische Herausforderung, komplexe Webinhalte in saubere, strukturierte Formate umzuwandeln. Dieses spezialisierte Sprachmodell befasst sich mit einem grundlegenden Problem moderner KI-Pipelines: der Notwendigkeit, HTML-Inhalte für nachgelagerte Aufgaben effizient zu verarbeiten und zu bereinigen, ohne sich auf instabile regelbasierte Systeme oder ressourcenintensive große Sprachmodelle verlassen zu müssen. Was dieses Modell wirklich bemerkenswert macht, ist seine Fähigkeit, 50-mal so große Modelle zu übertreffen und dabei einen überraschend kompakten Parameter-Footprint von 1,54 B beizubehalten. Organisationen, die sich mit der Verarbeitung von Webinhalten im großen Maßstab, der Automatisierung von Dokumentationen oder Content-Management-Systemen befassen, werden dieses Modell besonders wertvoll finden, da es extrem lange Dokumente verarbeiten und gleichzeitig eine überragende Genauigkeit bei der Konvertierung von HTML in Markdown bieten kann.",title:"Überblick"},parameter_size:"Parameter",performance:{"ReaderLM-v2":"In umfassenden Benchmarks übertrifft ReaderLM-v2 größere Modelle wie Qwen2.5-32B-Instruct und Gemini2-flash-expr bei HTML-zu-Markdown-Aufgaben. Bei der Extraktion von Hauptinhalten erreicht es einen ROUGE-L von 0,84, einen Jaro-Winkler von 0,82 und eine deutlich niedrigere Levenshtein-Distanz (0,22) im Vergleich zu Mitbewerbern. Bei HTML-zu-JSON-Aufgaben hält es mit F1-Ergebnissen von 0,81 und einer Erfolgsquote von 98 % eine konkurrenzfähige Leistung aufrecht. Das Modell verarbeitet 67 Token/s Eingabe und 36 Token/s Ausgabe auf einer T4-GPU, wobei die Degenerationsprobleme durch kontrastives Verlusttraining deutlich reduziert werden.","jina-clip-v1":"Jina CLIP v1 weist in allen Benchmarks bemerkenswerte Verbesserungen gegenüber OpenAIs ursprünglichem CLIP auf. Bei der Nur-Text-Abfrage erreicht es eine Leistungssteigerung von 165 % mit einem Ergebnis von 0,429 im Vergleich zu CLIPs 0,162. Bei bildbezogenen Aufgaben zeigt es durchgängige Verbesserungen: 2 % besser bei der Text-zu-Bild-Abfrage (0,899), 6 % bei der Bild-zu-Text-Abfrage (0,803) und 12 % bei der Bild-zu-Bild-Abfrage (0,916). Das Modell glänzt insbesondere bei Aufgaben zur visuellen Klassifizierung ohne vorheriges Training in bestimmten Domänen und kategorisiert erfolgreich Bilder. Bei der Bewertung anhand von Standardbenchmarks wie MTEB für die Textabfrage, CIFAR-100 für Bildaufgaben und Flickr8k/30k und MSCOCO Captions für modalübergreifende Leistung übertrifft es durchgängig spezialisierte Einzelmodalitätsmodelle und behält gleichzeitig die wettbewerbsfähige Leistung bei modalübergreifenden Aufgaben bei.","jina-clip-v2":"Das Modell erreicht mit 98,0 % Genauigkeit bei Flickr30k-Bild-zu-Text-Abrufaufgaben eine hochmoderne Leistung und übertrifft damit sowohl seinen Vorgänger als auch NLLB-CLIP-SigLIP. In mehrsprachigen Szenarien zeigt es eine bis zu 4 %ige Verbesserung gegenüber NLLB-CLIP-SigLIP bei sprachübergreifenden Bildabrufaufgaben, obwohl es weniger Parameter als sein größter Konkurrent hat. Das Modell behält seine starke Leistung auch bei komprimierten Einbettungen bei – bei einer Reduzierung der Abmessungen um 75 % bleiben bei Text-, Bild- und modalübergreifenden Aufgaben immer noch über 99 % der Leistung erhalten. Bei den umfassenden mehrsprachigen MTEB-Benchmarks erreicht es 69,86 % beim Abruf und 67,77 % bei Aufgaben zur semantischen Ähnlichkeit und ist damit konkurrenzfähig mit spezialisierten Text-Einbettungsmodellen.","jina-colbert-v1-en":"Jina-ColBERT-v1-en weist in verschiedenen Benchmarks bemerkenswerte Verbesserungen gegenüber Basismodellen auf. In der BEIR-Datensatzsammlung erreicht es in mehreren Kategorien eine überlegene Leistung: 49,4 % bei Arguana (gegenüber 46,5 % bei ColBERTv2), 79,5 % bei FEVER (gegenüber 78,8 %) und 75,0 % bei TREC-COVID (gegenüber 72,6 %). Am beeindruckendsten ist die dramatische Verbesserung beim LoCo-Benchmark für das Verständnis langfristiger Kontexte mit 83,7 % gegenüber 74,3 % bei ColBERTv2. Das Modell zeichnet sich insbesondere in Szenarien aus, die ein detailliertes semantisches Verständnis erfordern, und übertrifft traditionelle Einbettungsmodelle, während die Rechenleistung durch seinen innovativen Ansatz der späten Interaktion erhalten bleibt. Diese Verbesserungen werden erreicht, während die Parameteranzahl des Modells bei bescheidenen 137 Millionen gehalten wird, was es sowohl leistungsstark als auch praktisch für Produktionseinsätze macht.","jina-colbert-v2":"In Tests unter realen Bedingungen zeigt Jina-ColBERT-v2 außergewöhnliche Fähigkeiten in mehreren Benchmarks. Es erreicht eine Verbesserung von 6,5 % gegenüber dem ursprünglichen ColBERT-v2 bei englischen Aufgaben mit einem Durchschnittswert von 0,521 in 14 BEIR-Benchmarks. Noch beeindruckender ist, dass es traditionelle, auf BM25 basierende Abrufmethoden in allen getesteten Sprachen in MIRACL-Benchmarks übertrifft und insbesondere in sprachübergreifenden Szenarien seine Stärken zeigt. Das Modell behält diese hohe Leistung auch bei Verwendung reduzierter Einbettungsdimensionen bei – die Reduzierung von 128 auf 64 Dimensionen führt nur zu einem Leistungsrückgang von 1,5 % bei halbiertem Speicherbedarf. Dies führt zu erheblichen Kosteneinsparungen in der Produktion: Beispielsweise kostet die Speicherung von 100 Millionen Dokumenten mit 64-dimensionalen Vektoren 659,62 USD pro Monat auf AWS, verglichen mit 1.319,24 USD für 128 Dimensionen.","jina-embedding-b-en-v1":"Bei realen Tests zeigt Jina Embedding B v1 beeindruckende Fähigkeiten, insbesondere bei Aufgaben zur semantischen Textähnlichkeit. Das Modell erreicht mit einem Score von 0,751 eine Spitzenleistung bei STS12 und übertrifft damit etablierte Modelle wie all-mpnet-base-v2 und all-minilm-l6-v2. Es zeigt eine starke Leistung bei verschiedenen Benchmarks und behält gleichzeitig effiziente Inferenzzeiten bei. Benutzer sollten jedoch beachten, dass das Modell speziell für englischsprachige Inhalte optimiert ist und bei mehrsprachigen oder codespezifischen Aufgaben möglicherweise nicht optimal funktioniert. Das Modell wurde inzwischen durch jina-embeddings-v2-base-en und jina-embeddings-v3 ersetzt, die eine verbesserte Leistung für ein breiteres Spektrum von Anwendungsfällen bieten.","jina-embeddings-v2-base-code":"In Tests unter realen Bedingungen zeigt Jina Embeddings v2 Base Code außergewöhnliche Fähigkeiten und ist in neun von fünfzehn entscheidenden CodeNetSearch-Benchmarks führend. Im Vergleich zu Modellen von Branchenriesen wie Microsoft und Salesforce erreicht es eine überlegene Leistung bei gleichzeitig effizienterem Platzbedarf. Das Modell zeichnet sich insbesondere durch sprachübergreifendes Codeverständnis aus und gleicht erfolgreich funktional gleichwertige Codeausschnitte in verschiedenen Programmiersprachen ab. Sein Kontextfenster mit 8.192 Token erweist sich als besonders wertvoll für große Funktionen und komplexe Codedateien und übertrifft herkömmliche Modelle, die normalerweise nur einige hundert Token verarbeiten, deutlich. Die Effizienz des Modells zeigt sich in seiner kompakten Größe von 307 MB (unquantisiert), die schnelle Inferenz ermöglicht und gleichzeitig eine hohe Genauigkeit bei Codeähnlichkeit und Suchaufgaben beibehält.","jina-embeddings-v2-base-de":"In Tests unter realen Bedingungen zeigt Jina Embeddings v2 Base German außergewöhnliche Effizienz und Genauigkeit, insbesondere bei sprachübergreifenden Abfrageaufgaben. Das Modell übertrifft Microsofts E5-Basismodell, obwohl es weniger als ein Drittel so groß ist, und erreicht die Leistung von E5 Large, obwohl es siebenmal kleiner ist. In wichtigen Benchmarks, darunter WikiCLIR für die Abfrage von Englisch nach Deutsch, STS17 und STS22 für bidirektionales Sprachverständnis und BUCC für präzise zweisprachige Textausrichtung, zeigt das Modell durchweg überlegene Fähigkeiten. Seine kompakte Größe von 322 MB ermöglicht die Bereitstellung auf Standardhardware bei gleichzeitiger Beibehaltung modernster Leistung, was es besonders effizient für Produktionsumgebungen macht, in denen Rechenressourcen eine Rolle spielen.","jina-embeddings-v2-base-en":"In Tests unter realen Bedingungen zeigt Jina Embeddings v2 Base English außergewöhnliche Fähigkeiten in mehreren Benchmarks. Es übertrifft OpenAIs text-embedding-ada-002 in mehreren wichtigen Metriken: Klassifizierung (73,45 % vs. 70,93 %), Neubewertung (85,38 % vs. 84,89 %), Abruf (56,98 % vs. 56,32 %) und Zusammenfassung (31,6 % vs. 30,8 %). Diese Zahlen bedeuten praktische Vorteile bei Aufgaben wie der Dokumentklassifizierung, bei der das Modell eine überlegene Fähigkeit zur Kategorisierung komplexer Texte zeigt, und bei Suchanwendungen, bei denen es Benutzeranfragen besser versteht und relevante Dokumente findet. Benutzer sollten jedoch beachten, dass die Leistung bei der Verarbeitung hochspezialisierter domänenspezifischer Inhalte, die nicht in den Trainingsdaten enthalten sind, variieren kann.","jina-embeddings-v2-base-es":"In umfassenden Benchmark-Bewertungen zeigt das Modell außergewöhnliche Fähigkeiten, insbesondere bei sprachübergreifenden Abrufaufgaben, bei denen es deutlich größere mehrsprachige Modelle wie E5 und BGE-M3 übertrifft, obwohl es nur 15-30 % deren Größe hat. Das Modell erzielt eine überlegene Leistung bei Abruf- und Clustering-Aufgaben und zeigt besondere Stärken beim Abgleichen semantisch äquivalenter Inhalte über Sprachen hinweg. Beim Test mit dem MTEB-Benchmark zeigt es eine robuste Leistung bei verschiedenen Aufgaben, darunter Klassifizierung, Clustering und semantische Ähnlichkeit. Das erweiterte Kontextfenster von 8.192 Tokens erweist sich als besonders wertvoll für die Verarbeitung langer Dokumente und zeigt eine konsistente Leistung selbst bei Dokumenten, die sich über mehrere Seiten erstrecken – eine Fähigkeit, die den meisten Konkurrenzmodellen fehlt.","jina-embeddings-v2-base-zh":"In Benchmarks auf der chinesischen MTEB-Bestenliste (C-MTEB) zeigt das Modell eine außergewöhnliche Leistung unter Modellen unter 0,5 GB und schneidet insbesondere bei Aufgaben in chinesischer Sprache hervorragend ab. Es übertrifft OpenAIs text-embedding-ada-002 in chinesischspezifischen Anwendungen deutlich und bleibt bei englischsprachigen Aufgaben konkurrenzfähig. Eine bemerkenswerte Verbesserung in dieser Version ist die verfeinerte Verteilung der Ähnlichkeitswerte, die die in der Vorschauversion vorhandenen Probleme mit der Punkteinflation behebt. Das Modell bietet jetzt eindeutigere und logischere Ähnlichkeitswerte und gewährleistet so eine genauere Darstellung semantischer Beziehungen zwischen Texten. Diese Verbesserung wird insbesondere in Vergleichstests deutlich, in denen das Modell eine bessere Unterscheidung zwischen verwandten und nicht verwandten Inhalten in beiden Sprachen zeigt.","jina-embeddings-v3":"Das Modell weist in Tests unter realen Bedingungen ein außergewöhnliches Verhältnis von Effizienz zu Leistung auf und übertrifft sowohl Open-Source-Alternativen als auch proprietäre Lösungen von OpenAI und Cohere bei englischen Aufgaben, während es in mehrsprachigen Szenarien brilliert. Am überraschendsten ist, dass es bessere Ergebnisse erzielt als e5-mistral-7b-instruct, das 12-mal mehr Parameter hat, was seine bemerkenswerte Effizienz unterstreicht. In MTEB-Benchmark-Bewertungen erreicht es über alle Aufgaben hinweg einen Durchschnittswert von 65,52, mit besonders starken Leistungen bei Klassifizierungsgenauigkeit (82,58) und Satzähnlichkeit (85,80). Das Modell behält eine konsistente Leistung über alle Sprachen hinweg bei und erreicht bei mehrsprachigen Aufgaben einen Wert von 64,44. Bei Verwendung von MRL zur Dimensionsreduzierung behält es auch bei niedrigeren Dimensionen eine starke Leistung bei – beispielsweise behält es bei 64 Dimensionen 92 % seiner Abrufleistung im Vergleich zu den vollen 1024 Dimensionen bei.","jina-reranker-v1-base-en":"In umfassenden Benchmarks zeigt das Modell außergewöhnliche Verbesserungen in allen wichtigen Kennzahlen und erreicht eine 8 % höhere Trefferquote und eine 33 % höhere mittlere reziproke Rangfolge im Vergleich zur Basisvektorsuche. Im BEIR-Benchmark erreicht es einen Durchschnittswert von 0,5588 und übertrifft damit andere Reranker von BGE (0,5032), BCE (0,4969) und Cohere (0,5141). Besonders beeindruckend ist seine Leistung im LoCo-Benchmark, wo es im Durchschnitt 0,873 Punkte erreicht und damit die Konkurrenz beim Verständnis lokaler Kohärenz und kontextabhängiger Rangfolge deutlich übertrifft. Das Modell zeigt besondere Stärken bei der Bewertung technischer Inhalte und erreicht Werte von 0,996 bei qasper_abstract-Aufgaben und 0,962 bei der Analyse von Regierungsberichten, zeigt jedoch eine relativ geringere Leistung (0,466) bei Aufgaben zur Besprechungszusammenfassung.","jina-reranker-v1-tiny-en":"In umfassenden Benchmark-Bewertungen zeigt das Modell außergewöhnliche Fähigkeiten, die den herkömmlichen Kompromiss zwischen Größe und Leistung in Frage stellen. Im BEIR-Benchmark erreicht es einen NDCG-10-Score von 48,54 und behält 92,5 % der Leistung des Basismodells bei, obwohl es nur ein Viertel so groß ist. Noch beeindruckender ist, dass es in den LlamaIndex RAG-Benchmarks eine Trefferquote von 83,16 % beibehält und damit fast mit größeren Modellen mithalten kann, während es Dokumente deutlich schneller verarbeitet. Das Modell zeichnet sich insbesondere durch seinen Durchsatz aus und verarbeitet Dokumente fast fünfmal schneller als das Basismodell und verbraucht dabei 13 % weniger Speicher als selbst die Turbo-Variante. Diese Werte lassen sich in einer realen Leistung niederschlagen, die mit viel größeren Modellen wie mxbai-rerank-base-v1 (184 Mio. Parameter) und bge-reranker-base (278 Mio. Parameter) mithalten oder diese sogar übertrifft.","jina-reranker-v1-turbo-en":"In umfassenden Benchmarks zeigt die Turbo-Variante eine bemerkenswerte Effizienz ohne nennenswerte Kompromisse bei der Genauigkeit. Im BEIR-Benchmark erreicht sie einen NDCC-10-Score von 49,60, wobei 95 % der Leistung des Basismodells (52,45) erhalten bleiben und viele größere Konkurrenten wie bge-reranker-base (47,89, 278 Mio. Parameter) übertroffen werden. In RAG-Anwendungen behält sie eine beeindruckende Trefferquote von 83,51 % und 0,6498 MRR bei und zeigt damit besondere Stärken bei praktischen Abrufaufgaben. Die Geschwindigkeitsverbesserungen des Modells sind noch bemerkenswerter – es verarbeitet Dokumente dreimal schneller als das Basismodell, wobei der Durchsatz bei reduzierter Parameteranzahl nahezu linear skaliert. Benutzer sollten jedoch eine etwas geringere Leistung bei extrem nuancierten Ranking-Aufgaben beachten, bei denen die volle Parameteranzahl größerer Modelle marginale Vorteile bietet.","jina-reranker-v2-base-multilingual":"Bei realen Tests zeigt das Modell außergewöhnliche Fähigkeiten in verschiedenen Benchmarks. Es erreicht eine hochmoderne Leistung auf der AirBench-Bestenliste für RAG-Systeme und zeigt starke Ergebnisse bei mehrsprachigen Aufgaben, einschließlich des MKQA-Datensatzes, der 26 Sprachen umfasst. Das Modell zeichnet sich insbesondere bei strukturierten Datenaufgaben aus und erreicht hohe Rückrufwerte sowohl beim Funktionsaufruf (ToolBench-Benchmark) als auch beim SQL-Schema-Matching (NSText2SQL-Benchmark). Am beeindruckendsten ist, dass es diese Ergebnisse liefert, während es Dokumente 15-mal schneller verarbeitet als vergleichbare Modelle wie bge-reranker-v2-m3, was es für Echtzeitanwendungen praktisch macht. Benutzer sollten jedoch beachten, dass für eine optimale Leistung eine CUDA-fähige GPU für die Inferenz erforderlich ist.","reader-lm-05b":"In Tests unter realen Bedingungen zeigt Reader LM 0.5B beeindruckende Effizienz-Leistungs-Verhältnisse in mehreren Metriken. Das Modell erreicht einen ROUGE-L-Score von 0,56, was auf eine starke Inhaltserhaltung hinweist, und behält eine niedrige Token-Fehlerrate von 0,34 bei, was auf minimale Halluzinationen hinweist. In qualitativen Bewertungen von 22 verschiedenen HTML-Quellen, darunter Nachrichtenartikel, Blogbeiträge und E-Commerce-Seiten in mehreren Sprachen, zeigt es besondere Stärken in Bezug auf Strukturerhaltung und Verwendung der Markdown-Syntax. Das Modell eignet sich hervorragend für die Verarbeitung komplexer moderner Webseiten, bei denen Inline-CSS und Skripte auf Hunderttausende von Token erweitert werden können – ein Szenario, in dem herkömmliche regelbasierte Ansätze oft versagen. Es ist jedoch wichtig zu beachten, dass das Modell zwar bei einfachen HTML-zu-Markdown-Konvertierungsaufgaben außergewöhnlich gut abschneidet, für hochdynamische oder JavaScript-lastige Seiten jedoch möglicherweise zusätzliche Verarbeitung erfordert.","reader-lm-15b":"In umfassenden Benchmark-Bewertungen zeigt Reader LM 1.5B außergewöhnliche Fähigkeiten, die Industriestandards herausfordern. Das Modell erreicht einen ROUGE-L-Score von 0,72 und eine Token-Fehlerrate von 0,19 und übertrifft damit größere Modelle wie GPT-4 (0,43 ROUGE-L, 0,50 TER) und Gemini-1.5-Pro (0,42 ROUGE-L, 0,48 TER) bei HTML-zu-Markdown-Konvertierungsaufgaben deutlich. Seine Leistung glänzt insbesondere bei qualitativen Bewertungen in vier Schlüsseldimensionen: Header-Extraktion, Hauptinhaltsextraktion, Erhaltung der Rich-Structure-Struktur und Verwendung der Markdown-Syntax. Das Modell behält bei verschiedenen Dokumenttypen, von Nachrichtenartikeln und Blogbeiträgen bis hin zu Landingpages und Forenbeiträgen, in mehreren Sprachen, darunter Englisch, Deutsch, Japanisch und Chinesisch, durchgängig eine hohe Genauigkeit bei. Diese Leistung wird bei der Verarbeitung von Dokumenten mit einer Länge von bis zu 256.000 Token erreicht, wodurch die Notwendigkeit teurer Chunking-Operationen entfällt, die normalerweise bei größeren Modellen erforderlich sind.",title:"Leistung"},performance_metrics:"Leistungsmetriken",publications:"Publikationen",tags:"Schlagwörter",token_length:"Länge des Eingabetokens",usage_requirements:"Nutzung & Voraussetzungen",using_model:"Erhältlich über"},select_model:"Wählen Sie ein Modell aus der Liste aus, um Details anzuzeigen",sort:{direction:{asc:"Aufsteigend",desc:"Absteigend",name:"Richtung"},label:"Sortieren",name:"Name",parameter_size:"Größe",release_date:"Datum"},title:"{_modelName} – Foundation-Modelle durchsuchen",warnings:{deprecated:"Dieses Modell wird durch neuere Modelle ersetzt."}},re={back_to_newsroom:"Zurück zum Newsroom",categories:"Kategorien",copy_link:"Kopieren Sie den Link zu diesem Abschnitt",in_this_article:"In diesem Artikel",learn_more:"Erfahren Sie mehr",news_not_found:"Artikel nicht gefunden",redirect_to_news:"Weiterleitung zum Newsroom in 5 Sekunden..."},te={academic:"Akademisch",academic_research:"Wissenschaftliche Publikationen",author:"Filtern nach Autor",description:"Lesen Sie die neuesten Nachrichten und Updates von Jina AI.",description1:"KI-Innovationen entwickeln, Wort für Wort.",engineering_group:"Engineering-Gruppe",engineering_group_date:"31. Mai 2021",minutes_read:"Minuten gelesen",most_recent_articles:"Neueste Artikel",news_description:"Bei Jina 2.0 haben wir auf die Community gehört. Wirklich tief zugehört. „Was sind Ihre Schmerzpunkte?“ „, fragten wir und waren gespannt auf wertvolles Feedback.“",news_title:"Durchsuchen Sie alle Dinge: Wir veranstalten einen MEME-Wettbewerb für Jina 2.0",photos:"Fotos",product:"Nach Produkt filtern",search:"Suche nach Titel",tech_blog:"Tech-Blog",title:"Pressemitteilungen",top_stories:"Top-Geschichten"},se="🎉 Unser erstes Buch „Neural Search – From Prototype to Production with Jina“ ist heute offiziell erhältlich!",ae={description:"Eine exklusive Gelegenheit, einen Insider-Einblick in Jina AI zu gewinnen.",engage:"Wir fördern den interaktiven Dialog den ganzen Tag über. Der Austausch von Gedanken und Perspektiven ist für uns von unschätzbarem Wert. Mögliche Kooperationen, die sich aus diesen Diskussionen ergeben, könnten erheblich zu einer stärker integrierten und innovativeren Zukunft beitragen.",engage_title:"Beteiligen Sie sich an uns",experience:"Wir haben für unsere Gäste eine immersive dreistündige Tour zusammengestellt, die auf Deutsch, Englisch, Französisch, Spanisch, Chinesisch und Russisch verfügbar ist. Die Tour bietet einen detaillierten Einblick in unsere Fortschritte in der multimodalen KI, unsere Sicht auf die KI-Landschaft, gefolgt von einer detaillierten Untersuchung spezifischer Projekte. Wir schließen mit einer Gruppendiskussion ab, um den Austausch von Ideen und Erkenntnissen zu erleichtern. Auf Anfrage ist auch ein Mittagessen erhältlich.",experience_title:"Die Reise eines Insiders",group_size:"Geschätzte Besucherzahl",impact:"Erfahren Sie, wie unsere Beiträge zur Open-Source-Community und unsere Arbeit in der multimodalen KI-Technologie Jina AI als einflussreichen Akteur bei KI-Innovationen etablieren. Unser Ziel ist es, eine wichtige Rolle in Entscheidungsprozessen zu spielen und sicherzustellen, dass die Weiterentwicklung der KI-Technologie allen zugute kommt.",impact_title:"Wirkung und Einfluss",introduction:"Jina AI freut sich, unsere Türen für angesehene Unternehmen und Organisationen zu öffnen, die sich für den Fortschritt und die Zukunft der künstlichen Intelligenz interessieren. Diese exklusive Gelegenheit bieten wir Vertretern aus Politik, NGOs, NPOs und der Investmentbranche an, hier in unserem Berliner Hauptsitz einen Insider-Blick auf unsere Aktivitäten und Visionen zu erhalten.",motivation_min_length_v1:"Bitte geben Sie eine detailliertere Motivation an.",motivation_placeholder_v2:"Wenn Sie uns Ihre Beweggründe mitteilen, können wir Ihr Erlebnis verbessern.",motivation_to_attend_v2:"Warum interessieren Sie sich für unseren Tag der offenen Tür?",one_hour:"1 Stunde",organization:"Organisation",organization_website:"Website der Organisation",organization_website_placeholder:"URL für die Homepage oder das LinkedIn-Profil Ihrer Organisation",preferred_date:"Bevorzugtes Datum",preferred_language:"Bevorzugte Sprache der Tour",preferred_products:"Für welche Produkte interessieren Sie sich?",subtitle:"Ein Blick in die Zukunft der multimodalen KI",title:"Tag der offenen Tür",tutor_subtitle:"Eine sorgfältig kuratierte dreistündige Tour, die Ihnen den Kern der bahnbrechenden Arbeit von Jina AI in der multimodalen KI-Technologie näher bringt.",tutor_title:"Ein exklusiver tiefer Einblick in",vision:"Verschaffen Sie sich mit uns einen umfassenden Überblick über die KI-Landschaft aus unserer Sicht. Unsere Diskussion konzentriert sich auf das Potenzial großer Sprachmodelle, multimodaler KI und den Einfluss von Open-Source-Technologie auf die Gestaltung der Zukunft globaler Innovation.",vision_title:"Unsere Vision für die Zukunft"},ue={answer1:"Wir bieten Führungen auf Deutsch, Englisch, Französisch, Spanisch, Chinesisch und Russisch an.",answer2:"Die Tour dauert normalerweise etwa drei Stunden.",answer3:"Das Mittagessen ist optional und kann auf Anfrage arrangiert werden.",answer4:"Unser Tag der offenen Tür richtet sich in erster Linie an Berufsgruppen wie Politiker, NGOs, NPOs und Investoren. Allerdings machen wir gelegentlich Ausnahmen basierend auf dem Profil der Person.",answer5:"Wir können unterschiedliche Gruppengrößen unterbringen. Bitte geben Sie im Anmeldeformular die Größe Ihrer Gruppe an und wir klären die Einzelheiten mit Ihnen ab.",answer6:"Im Anmeldeformular gibt es einen Abschnitt, in dem Sie Ihre Interessengebiete oder spezielle Wünsche angeben können. Wir werden unser Bestes tun, um die Tour Ihren Bedürfnissen anzupassen.",answer7:"Derzeit bieten wir Führungen nur in unserem Berliner Hauptsitz in Kreuzberg an. Unsere Büros in Peking und Shenzhen sind derzeit nicht für Führungen geöffnet.",question1:"Welche Sprachen bieten Sie für die Tour an?",question2:"Wie lange dauert die Tour?",question3:"Wird Mittagessen angeboten?",question4:"Können sich Einzelpersonen für den Tag der offenen Tür anmelden?",question5:"Aus wie vielen Personen darf eine Gruppe am Tag der offenen Tür bestehen?",question6:"Wie kann ich Interessengebiete für die Tour angeben?",question7:"Sind Führungen in Ihren Büros in Peking oder Shenzhen verfügbar?"},de={description:"Ein Open-Source-Cloud-natives Framework für die Bereitstellung großer multimodaler KI-Modelle"},le={commercial_licence:{chip_label:"Exklusiv für kleine Unternehmen",company_size_note:"Exklusiv für Unternehmen mit weniger als 50 Mitarbeitern oder einem Umsatz von 500.000 US-Dollar",cta_button:"Erste Schritte",download_title:"Kommerzielle Lizenz herunterladen",feature_api_desc:"Vor dem Kauf testen",feature_api_title:"Kostenloser API-Testzugriff",feature_consulting:"Zwei Stunden Beratung mit unseren Modell-Experten",feature_consulting_desc:"Zwei (2) Stunden technische Beratungsleistungen pro Lizenzperiode.",feature_future_support:"Zugriff auf zukünftige CC BY-NC-Modelle ohne Erlaubnis",feature_future_support_desc:"Alle neuen Modelle, die vom Lizenzgeber während der Lizenzlaufzeit unter CC-BY-NC-4.0 veröffentlicht werden.",feature_models:"Unbegrenzte kommerzielle Nutzung unserer CC BY-NC-Modelle",feature_models_desc:"Verwenden Sie die Modelle für kommerzielle Zwecke, einschließlich der internen Verwendung oder der Einbindung in kundenorientierte Anwendungen.",price_amount:"1.000 US-Dollar",price_period:"/ Viertel",read_the_terms:"Lizenzbedingungen überprüfen",read_the_terms_btn:"Bedingungen",read_the_terms_desc:"Überprüfen Sie vor dem Kauf die kommerziellen Lizenzrechte und -beschränkungen",subtitle:"Alle Modelle, die Sie für eine bessere Suche benötigen",test_before_purchase:"Vor dem Kauf ausprobieren",test_before_purchase_desc:"Holen Sie sich 1 Million kostenlose API-Token oder nutzen Sie unser Hugging Face-Modell zur Leistungsüberprüfung",title:"Teamlizenz",try_api:"Probieren Sie zuerst die API aus"},full_commercial:"Uneingeschränkte kommerzielle Nutzung",full_commercial_description:"Sie können die API ohne Einschränkungen für kommerzielle Zwecke nutzen.",higher_limit:"Deutlich höhere Ratenbegrenzung",higher_limit_description:"Erhalten Sie bis zu 1000 RPM für r.jina.ai und 100 RPM für s.jina.ai; weitere Einzelheiten im Abschnitt zur Ratenbegrenzung.",key_manager:"Grundlegende Schlüsselverwaltung",key_manager_description:"Verwalten Sie mehrere API-Schlüssel in einem Konto, verfolgen Sie den Nutzungsverlauf und laden Sie Token auf.",no_commercial:"Nur für nichtkommerzielle Nutzung (CC-BY-NC)",no_commercial_description:"Sie können die API nur für nichtkommerzielle Zwecke verwenden. Für die kommerzielle Nutzung laden Sie bitte Ihren API-Schlüssel auf.",on_prem:"Mit einer kommerziellen Lizenz für den Einsatz vor Ort",on_prem_explain:"Erwerben Sie eine kommerzielle Lizenz, um unsere Modelle vor Ort zu verwenden.",premium_key:"Premium-Schlüssel mit deutlich höheren Ratenlimits",premium_key_description:"Erhalten Sie deutlich höhere Ratenlimits und Zugriff auf Premiumfunktionen. Weitere Einzelheiten finden Sie in der Ratenlimittabelle.",premium_key_manager:"Erweiterte Schlüsselverwaltung",premium_key_manager_description:"Grundlegende und erweiterte Funktionen wie automatische Erinnerung, Widerruf, Token-Übertragung.",priority_support:"Vorrangiger technischer Support",priority_support_description:"Garantierte E-Mail-Antwort bei technischen Problemen und Vorfällen innerhalb von 24 Stunden.",secured_by_stripe:"Sichere Zahlung über Stripe",standard_key:"Standardschlüssel",standard_key_description:"Zugriff auf alle API-Produkte der Jina Search Foundation mit einer Standard-Ratenbegrenzung.",via_api:"Mit Jina Search Foundation API",via_api_explain:"Der einfachste Weg, auf alle unsere Produkte zuzugreifen. Laden Sie Tokens unterwegs auf."},oe="Angetrieben von",he="Drucken",ge={archived:"Archiviert",cloud_native:"Cloud-nativ",core:"Kern",data_structure:"Datenstruktur",embedding_serving:"Servieren einbetten",embedding_tuning:"Tuning einbetten",graduated:"Absolvent",incubating:"Inkubieren",kubernetes:"Kubernetes",large_size_model:"Großes Modell",linux_foundation:"Linux Foundation",llm1:"LLMOps",mid_size_model:"Mittelgroßes Modell",model_serving:"Modelldienst",model_tuning:"Modelltuning",observability:"Beobachtbarkeit",orchestration:"Orchestrierung",prompt_serving:"Prompt-Serving",prompt_tuning:"Prompt-Verbesserung",rag1:"LAPPEN",sandbox:"Sandkasten",small_size_model:"Kleines Modell",vector_database:"Vektordatenbank",vector_store:"Vector Store"},ce={description:"Erstklassiges Tool für schnelles Engineering",image_model:"Bildmodelle",intro:"Erstklassiges Tool für schnelles Engineering",intro1:"Das erstklassige Tool für schnelles Engineering",optimized:"Ihre Aufgabe ist es, mein Brainstorming-Partner zu sein und kreative Ideen und Vorschläge zu einem bestimmten Thema oder Problem zu liefern. Ihre Antwort sollte originelle, einzigartige und relevante Ideen enthalten, die zur Lösung des Problems beitragen oder das Thema auf interessante Weise weiter vertiefen können. Bitte beachten Sie, dass Ihre Antwort auch etwaige spezifische Anforderungen oder Einschränkungen der Aufgabe berücksichtigen sollte.",optimized_title:"Optimierte Eingabeaufforderung",original:"Sei mein Brainstorming-Partner.",original_title:"Ursprüngliche Aufforderung",text_model:"Textmodelle"},me={features:[{description:"Wechseln Sie einfach zwischen Inhaltserstellung und sofortiger Optimierung und heben Sie die Qualität Ihrer Inhalte auf die nächste Stufe.",name:"Assistent",title:"Tägliche Dosis Produktivität."},{description:"Sie wissen nicht, wie Sie eine effektive Anleitung schreiben? Geben Sie einfach Ihre Idee ein, ein Klick und Sie erhalten eine bessere Anleitung.",name:"Schnelle Optimierung",title:"Bessere Eingänge, bessere Ausgänge"},{description:"Verstehen Sie die Stimmung jedes KI-Modells, indem Sie die Ausgaben derselben Eingabeaufforderung vergleichen.",name:"Modelle vergleichen",title:"Nebeneinanderstellung der Modelle."},{description:"Dies ist möglicherweise die einfachste Möglichkeit, Ihre Eingabeaufforderungen als API zur Integration bereitzustellen.",name:"Bereitstellen von Eingabeaufforderungen",title:"Keine Operationen, einfach bereitstellen."},{description:"Passen Sie Ihre eigenen LLM-Agenten an und starten Sie eine Multi-Agenten-Simulation. Sehen Sie, wie sie in einer virtuellen Umgebung zusammenarbeiten oder konkurrieren, um das Ziel zu erreichen.",name:"Mehrere Agenten",title:"Erfahren Sie, wie Agenten zusammenarbeiten"}],get_started:"Erste Schritte mit PromptPerfect"},be={api_key:"Aufgeladener API-Schlüssel",free_key:"Kostenloser API-Schlüssel",generation:"Ihr API-Schlüssel ist bereit!",generation_caption:"Ihr API-Schlüssel wurde am {_purchasedTime} generiert und ist einsatzbereit!",success:"Danke für Ihren Einkauf!",success_caption:"Ihre Bestellung wurde um {_purchasedTime} abgeschlossen. Ihr API-Schlüssel wurde aufgeladen und ist einsatzbereit!"},fe="Jetzt kaufen",ke={batch_explain:"Diese API unterstützt Batch-Operationen und ermöglicht bis zu 512 Dokumente pro Anfrage, wobei jedes Dokument bis zu 8192 Token enthalten kann. Durch die intelligente Nutzung von Batch-Operationen kann die Anzahl der Anfragen erheblich reduziert und die Leistung verbessert werden.",classifier:"Trainieren eines Klassifikators anhand gekennzeichneter Beispiele",classifier_few_shot:"Klassifizieren Sie Eingaben mit einem trainierten Few-Shot-Klassifikator",classifier_few_shot_token_counting:"Token werden wie folgt gezählt: input_tokens",classifier_latency:"Die Reaktionszeit hängt von der Eingabegröße ab",classifier_token_counting:"Token werden wie folgt gezählt: input_tokens × num_iters",classifier_zero_shot:"Klassifizieren Sie Eingaben mithilfe der Zero-Shot-Klassifizierung",classifier_zero_shot_token_counting:"Token werden wie folgt gezählt: input_tokens + label_tokens",deepsearch:"Überlegen, suchen und iterieren, um die beste Antwort zu finden",depends:"hängt von der Eingangsgröße ab",description:"Beschreibung",embeddings:"Konvertieren Sie Text/Bilder in Vektoren mit fester Länge",endpoint:"API-Endpunkt",explain:"Ratenbegrenzungen werden auf zwei Arten verfolgt: <b>RPM</b> (Anfragen pro Minute) und <b>TPM</b> (Tokens pro Minute). Begrenzungen werden pro IP/API-Schlüssel erzwungen und können erreicht werden, je nachdem, welcher Schwellenwert (RPM oder TPM) zuerst erreicht wird. Beachten Sie, dass, wenn in der Anfrage ein API-Schlüssel angegeben ist, Ratenbegrenzungen pro Schlüssel verfolgt werden, nicht pro IP-Adresse.",flat_rate_per_request:"Jede Anfrage kostet eine feste Anzahl an Token, beginnend bei {_number} Token",gjinaai:"Eine Aussage mit Webwissen untermauern",icon:"Symbol",input_token_counting:"Zählen Sie die Anzahl der Token in der Eingabeanforderung.",latency:"Durchschnittliche Latenz",llm_serp:"Verwenden Sie LLM, um eine Seite mit Suchmaschinenergebnissen zu generieren",no_token_counting:"Token werden nicht als Nutzung gezählt.",output_token_counting:"Zählen Sie die Anzahl der Token in der Ausgabeantwort.",premium_rate:"Mit Potenzial für höhere Ratenbegrenzungen",product:"Produkt",requestType:"Zulässige Anfrage",reranker:"Ordnen Sie Dokumente nach Abfrage",rjinaai:"URL in LLM-freundlichen Text konvertieren",search:"Suchen",sjinaai:"Durchsuchen Sie das Web und konvertieren Sie die Ergebnisse in LLM-freundlichen Text",tbd:"Wird noch festgelegt",title:"Ratenbegrenzung",tokenCounting:"Zählung der Token-Nutzung",tokenizer:"Tokenisieren und Segmentieren von Langtext",total_token_counting:"Zählen Sie die Gesamtzahl der Token im gesamten Vorgang.",understanding:"Verstehen Sie die Ratenbegrenzung",understanding_description:"Ratenbegrenzungen sind die maximale Anzahl von Anfragen, die pro Minute pro IP-Adresse/API-Schlüssel (RPM) an eine API gestellt werden können. Nachfolgend erfahren Sie mehr über die Ratenbegrenzungen für jedes Produkt und jede Stufe.",wAPIkey:"mit API-Schlüssel",wPremium:"mit Premium-API-Schlüssel",woAPIkey:"ohne API-Schlüssel"},pe={decision:"Entscheidung",description:"Ultimative KI-Tools zur Entscheidungsfindung",intro:"Sehen Sie die zwei Seiten der Medaille und treffen Sie rationale Entscheidungen"},ze={beta:"Experimental",better_input:"Verbessern Sie die Eingabequalität von Anfang an",better_input_description:"Haben Sie Probleme mit der Ausgabe Ihres Agenten oder RAG-Systems? Dies kann an der schlechten Eingabequalität liegen.",check_price_table:"Überprüfen Sie die Preistabelle",copy:"Kopieren",demo:{advanced_parameter_explain:"Spezifische Parameter, die nur für diesen Endpunkt verwendet werden.",advanced_parameters:"Spezifisch",advanced_usage:"Erweiterte Nutzung",ask_llm:"Fragen Sie LLM mit und ohne Suchgrundlage",ask_llm_directly:"Fragen Sie LLM direkt",ask_llm_with_search_grounding:"Ask LLM mit Suchgrundierung",ask_question:"Stellen Sie eine Frage",ask_question_hint:"Geben Sie eine Frage ein und kombinieren Sie sie mit dem abgerufenen Inhalt für LLM, um eine Antwort zu generieren",basic_usage:"Grundlegende Verwendung",basic_usage1:"Verwenden Sie <code>r.jina.ai</code>, um eine URL zu lesen und ihren Inhalt abzurufen",basic_usage2:"Verwenden Sie <code>s.jina.ai</code>, um im Web zu suchen und SERP zu erhalten",basic_usage3:"Erdung",common_parameter_explain:"Allgemeine Parameter, die für {_product1}, {_product2} und {_product3} verwendet werden können.",common_parameters:"Gemeinsam",copy:"Kopieren",fetch:"Inhalt abrufen",get_response:"Erhalten Antwort",grounding_result_false:"Diese Aussage ist falsch.",grounding_result_true:"Diese Aussage ist wahr.",headers:{auth_token:"API-Schlüssel für höhere Ratenbegrenzung hinzufügen",auth_token_explain:"Geben Sie Ihren Jina-API-Schlüssel ein, um auf eine höhere Ratenbegrenzung zuzugreifen. Aktuelle Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle.",auto:"Auto",auto_explain:"Wählt automatisch die optimale Engine für die URL aus.",base:"Weiterleitungsseite folgen",base_explain:"Wählen Sie aus, ob nach dem Befolgen aller Weiterleitungen zur endgültigen Ziel-URL aufgelöst werden soll. Aktivieren Sie diese Option, um der vollständigen Weiterleitungskette zu folgen.",browser:"Beste Qualität",browser_explain:"Hochwertige Engine zur Lösung von Rendering-Problemen und Bereitstellung der besten Inhaltsausgabe.",browser_locale:"Browser-Gebietsschema anpassen",browser_locale_explain:"Kontrollieren Sie die Browser-Gebietsschemata, um die Seite darzustellen. Viele Websites bieten je nach Gebietsschema unterschiedliche Inhalte an.",cf_browser:"Experimenteller Browser",cf_browser_explain:"Schnelle Engine, die JavaScript-lastige Websites effektiv verarbeiten kann.",country:"@:llm_serp.parameters.country",country_explain:"@:llm_serp.parameters.country_explain",custom_script:"Vorab-Ausführen von JavaScript",custom_script_explain:"Führt die Vorverarbeitung von JS-Code aus (Inline-String oder Remote-URL).",deepdive:"Tiefgehende Quellenanalyse",deepdive_explain:"Durchsucht mehr Quellen und liest vollständige Dokumente zur gründlichen Überprüfung der Fakten. Etwas langsamer, aber genauer und mit mehr Referenzen.",default:"Standard",default_explain:"Die für die meisten Websites und LLM-Eingaben optimierte Standard-Pipeline.",direct:"Geschwindigkeit zuerst",direct_explain:"Schnellste Engine, auf Geschwindigkeit optimiert, kann jedoch nicht mit JavaScript generierten dynamischen Inhalten umgehen.",dnt:"Nicht zwischenspeichern/verfolgen!",dnt_explain:"Wenn aktiviert, werden Anforderungsergebnisse nicht auf unseren Servern zwischengespeichert.",engine:"Engine lesen",engine_default:"Standard",engine_default_explain:"Kompatibelster Motor mit gutem Gleichgewicht zwischen Qualität und Geschwindigkeit.",engine_explain:"Wählen Sie die Engine aus, die zum Parsen des Inhalts für die angegebene URL verwendet werden soll. Beeinflussen Sie die Qualität, Geschwindigkeit und Kompatibilität des Ergebnisses.",file:"Lokale PDF/HTML-Datei",file_explain:"Verwenden Sie Reader für Ihre lokalen PDF- und HTML-Dateien, indem Sie sie hochladen. Es werden nur PDF- und HTML-Dateien unterstützt.",html:"HTML",html_explain:"Gibt documentElement.outerHTML zurück.",image_caption:"Bildbeschreibung",image_caption_explain:"Beschriftet alle Bilder unter der angegebenen URL und fügt für Bilder ohne einen Alt-Tag „Bild [idx]: [Beschriftung]“ hinzu. Dies ermöglicht nachgelagerten LLMs die Interaktion mit den Bildern bei Aktivitäten wie Argumentation und Zusammenfassung.",images_summary:"Sammeln Sie am Ende alle Bilder",images_summary_all:"Zusammenfassung (Alle Bilder)",images_summary_all_explain:"Eine Zusammenfassung der gesammelten Bilder ist enthalten, ohne Duplikate herauszufiltern.",images_summary_explain:"Am Ende wird ein Abschnitt „Bilder“ erstellt. Dies gibt den nachgelagerten LLMs einen Überblick über alle visuellen Elemente auf der Seite, was das Denken erleichtern kann.",images_summary_true:"Zusammenfassung (gefiltert)",images_summary_true_explain:"Eine Zusammenfassung der gesammelten Bilder ist enthalten, doppelte Bilder werden jedoch herausgefiltert.",instruction_explain:"Informationen per Anweisung extrahieren",invalid_json:"Ungültiges JSON-Schema",json_response:"JSON-Antwort",json_response_explain:"Die Antwort erfolgt im JSON-Format und enthält URL, Titel, Inhalt und Zeitstempel (sofern verfügbar). Im Suchmodus wird eine Liste mit fünf Einträgen zurückgegeben, die jeweils der beschriebenen JSON-Struktur folgen.",json_schema_explain:"HTML-zu-JSON-Extraktion mit JSON-Schema",language:"@:llm_serp.parameters.language",language_explain:"@:llm_serp.parameters.language_explain",links_summary:"Sammeln Sie alle Links am Ende",links_summary_all:"Zusammenfassung (Alle Links)",links_summary_all_explain:"Eine Zusammenfassung der gesammelten Links ist enthalten, ohne Duplikate zu filtern.",links_summary_explain:"Am Ende wird ein Abschnitt „Buttons & Links“ erstellt. Dies erleichtert den nachgelagerten LLMs oder Webagenten die Navigation auf der Seite oder das Ausführen weiterer Aktionen.",links_summary_no:"Keine Zusammenfassung (Standard)",links_summary_no_explain:"Am Ende wird kein Zusammenfassungsabschnitt erstellt.",links_summary_true:"Zusammenfassung (gefiltert)",links_summary_true_explain:"Eine Zusammenfassung der gesammelten Links ist enthalten, doppelte Links werden jedoch herausgefiltert.",location:"@:llm_serp.parameters.location",location_explain:"@:llm_serp.parameters.location_explain",markdown:"Markdown",markdown_explain:"Gibt das Markdown direkt aus dem HTML zurück und umgeht dabei die Lesbarkeitsfilterung.",md:{bullet_list_marker:"Aufzählungszeichenstil",bullet_list_marker_explain:"Legt das Markierungszeichen für die Aufzählungsliste fest (wird an Turndown weitergegeben).",em_delimiter:"Hervorhebungsstil",em_delimiter_explain:"Definiert das Markdown-Hervorhebungstrennzeichen (an Turndown übergeben).",heading_style:"Überschriftenstil",heading_style_explain:"Legt das Markdown-Überschriftenformat fest (an Turndown übergeben).",hr:"Horizontaler Regelstil",hr_explain:"Definiert das horizontale Markdown-Regelformat (an Turndown übergeben).",link_reference_style:"Referenzlink-Stil",link_reference_style_explain:"Legt das Markdown-Referenzlinkformat fest (an Turndown übergeben).",link_style:"Link-Stil",link_style_explain:"Bestimmt das Markdown-Linkformat (an Turndown übergeben).",strong_delimiter:"Stil mit starker Betonung",strong_delimiter_explain:"Legt ein starkes Hervorhebungstrennzeichen für Markdown fest (wird an Turndown weitergegeben)."},mode:"Lese- oder Suchmodus",mode_explain:"Der Lesemodus dient zum Zugriff auf den Inhalt einer URL, während Sie im Suchmodus eine Abfrage im Web eingeben können, indem Sie den Lesemodus auf jede URL mit Suchergebnis anwenden.",no_cache:"Cache umgehen",no_cache_explain:"Unser API-Server speichert sowohl Inhalte im Lese- als auch im Suchmodus für eine bestimmte Zeit im Cache. Um diesen Cache zu umgehen, setzen Sie diesen Header auf „true“.",no_gfm:"Deaktiviert",no_gfm_explain:"GFM-Funktionen (Github Flavored Markdown) deaktiviert.",no_gfm_table:"Keine GFM-Tabelle",no_gfm_table_explain:"Deaktivieren Sie die GFM-Tabelle, behalten Sie jedoch die HTML-Tabellenelemente als Antwort bei.",number:"@:llm_serp.parameters.number",number_explain:"@:llm_serp.parameters.number_explain",opt_out_gfm:"Markdown mit Github-Flavour",opt_out_gfm_explain:"Opt-in/Out-Funktionen von GFM (Github Flavored Markdown).",page:"@:llm_serp.parameters.page",page_explain:"@:llm_serp.parameters.page_explain",pageshot:"Seitenfoto",pageshot_explain:"Gibt die Bild-URL des Screenshots der gesamten Seite zurück (mit bestmöglicher Leistung).",post_with_url:"POST-Methode verwenden",post_with_url_explain:"Verwenden Sie POST statt GET mit einer im Text übergebenen URL. Nützlich zum Erstellen von SPAs mit hashbasiertem Routing.",proxy:"Verwenden Sie einen länderspezifischen Proxyserver",proxy_explain:"Legen Sie den Ländercode für den standortbasierten Proxyserver fest. Verwenden Sie „auto“ für eine optimale Auswahl oder „none“, um die Auswahl zu deaktivieren.",proxy_server:"Verwenden Sie einen Proxyserver",proxy_server_explain:"Unser API-Server kann Ihren Proxy nutzen, um auf URLs zuzugreifen, was für Seiten hilfreich ist, auf die nur über bestimmte Proxys zugegriffen werden kann.",reader_url:"@:reader.demo.reader_url",references:"Verweise",references_explain:"Durch Kommas getrennte Liste der vom Benutzer bereitgestellten Referenzen (URLs)",remove_all_images:"Alle Bilder entfernen",remove_all_images_explain:"Entfernen Sie alle Bilder aus der Antwort.",remove_selector:"CSS-Selektor: Ausschließen",remove_selector_explain:"CSS-Selektoren für zu entfernende Elemente (Kopfzeilen, Fußzeilen usw.).",respond_with:"Verwenden Sie ReaderLM-v2",respond_with_explain:"Verwendet ReaderLM-v2 für die Konvertierung von HTML in Markdown, um qualitativ hochwertige Ergebnisse für Websites mit komplexen Strukturen und Inhalten zu liefern. Kostet 3x Token!",result_count:"Nummer",result_count_explain:"Legt die maximale Anzahl zurückgegebener Ergebnisse fest. Die Verwendung von „num“ kann zu Verzögerungen führen und spezielle Ergebnistypen ausschließen. Lassen Sie diese Option weg, es sei denn, Sie benötigen ausdrücklich mehr Ergebnisse pro Seite.",return_format:"Inhaltsformat",return_format_explain:"Sie können den Detaillierungsgrad der Antwort steuern, um eine Überfilterung zu verhindern. Die Standardpipeline ist für die meisten Websites und LLM-Eingaben optimiert.",robot_txt:"User-Agent anpassen",robot_txt_explain:"Definieren Sie den Bot-User-Agent, um vor dem Abrufen von Inhalten eine Prüfung mit robots.txt durchzuführen.",screenshot:"Bildschirmfoto",screenshot_explain:"Gibt die Bild-URL des ersten Bildschirms zurück.",search_engine:"Suchmaschine",search_engine_explain:"Wählen Sie die Suchmaschine aus, die Sie für die Suche verwenden möchten. Beeinflussen Sie Qualität, Geschwindigkeit und Kompatibilität des Ergebnisses.",search_result_mode:"Lesen Sie den gesamten Inhalt der SERP",search_result_mode_explain:"Besuchen Sie jede URL im Suchergebnis und geben Sie den vollständigen Inhalt mit Reader zurück. Aktivieren Sie diese Option, um weitere Reader-spezifische Optionen zu aktivieren.",set_cookie:"Weiterleiten Cookie",set_cookie_explain:"Unser API-Server kann Ihre benutzerdefinierten Cookie-Einstellungen beim Zugriff auf die URL weiterleiten, was für Seiten nützlich ist, die eine zusätzliche Authentifizierung erfordern. Beachten Sie, dass Anfragen mit Cookies nicht zwischengespeichert werden.",site_selector:"In-Site-Suche",site_selector_explain:"Gibt nur Suchergebnisse von der angegebenen Website oder Domäne zurück. Standardmäßig wird das gesamte Web durchsucht.",stream_mode:"Stream-Modus",stream_mode_explain:"Der Stream-Modus ist für große Zielseiten von Vorteil, da er mehr Zeit für die vollständige Darstellung der Seite bietet. Wenn der Standardmodus unvollständige Inhalte ergibt, sollten Sie den Stream-Modus verwenden.",target_selector:"CSS-Selektor: Nur",target_selector_explain:"Liste von CSS-Selektoren zum Ansprechen bestimmter Seitenelemente.",text:"Text",text_explain:"Gibt document.body.innerText zurück.",token_budget:"Token-Budget",token_budget_explain:"Begrenzt die maximale Anzahl von Token, die für diese Anfrage verwendet werden. Bei Überschreitung dieses Grenzwertes schlägt die Anfrage fehl.",viewport:"Ansichtsfenster-Konfiguration",viewport_explain:"Legt die Abmessungen des Browser-Ansichtsfensters für responsives Rendering fest.",vlm:"VLM",vlm_explain:"Ideal für kurze Seiten mit Rich Media und komplexen Layouts.",wait_for_selector:"CSS-Selektor: Wait-For",wait_for_selector_explain:"CSS-Selektoren, auf die gewartet werden soll, bevor Ergebnisse zurückgegeben werden.",with_favicon:"Favicons abrufen",with_favicon_explain:"Dadurch wird das Favicon jeder URL in der SERP abgerufen und als Bild-URI in die Antwort aufgenommen, was für die UI-Wiedergabe nützlich ist.",with_gfm:"Ermöglicht",with_gfm_explain:"GFM-Funktionen (Github Flavored Markdown) aktiviert.",with_iframe:"iframe-Extraktion",with_iframe_explain:"Verarbeitet Inhalte aus allen eingebetteten Iframes im DOM-Baum.",with_shadow_dom:"Shadow-DOM-Extraktion",with_shadow_dom_explain:"Extrahiert Inhalte aus allen Shadow-DOM-Stämmen im Dokument.",x_timeout:"Time-out",x_timeout_explain:"Maximale Wartezeit beim Laden der Seite (nicht die gesamte Anforderungsverarbeitungszeit).",your_query:"@:reader.demo.your_query"},how_to_stream:"Um Inhalte zu verarbeiten, sobald sie verfügbar sind, setzen Sie den Anforderungsheader auf den Stream-Modus. Dadurch wird die Zeit bis zum Empfang des ersten Bytes minimiert. Beispiel in curl:",how_to_use1:"Fügen Sie https://r.jina.ai/ zu jeder URL in Ihrem Code oder Tool hinzu, bei der LLM-Zugriff erwartet wird. Dadurch wird der Hauptinhalt der Seite in sauberem, LLM-freundlichem Text zurückgegeben.",how_to_use2:"Fügen Sie Ihrer Abfrage https://s.jina.ai/ hinzu. Dadurch wird die Suchmaschine aufgerufen und die Top-5-Ergebnisse mit ihren URLs und Inhalten zurückgegeben, jeweils in sauberem, LLM-freundlichem Text.",how_to_use3:"Fügen Sie Ihrer Aussage https://g.jina.ai/ hinzu. Dadurch wird die Beurteilungs-Engine aufgerufen und der Prozentsatz der Wahrhaftigkeit, ein Boolescher Wert, der angibt, ob die Aussage wahr oder falsch ist, eine Zusammenfassung der Gründe und eine Referenzliste zurückgegeben.",key_required:"Zur Verwendung dieses Endpunkts ist ein API-Schlüssel erforderlich",learn_more:"Erfahren Sie mehr",open:"In einer neuen Registerkarte öffnen",params_classification:"Parameter",raw_html:"Rohes HTML",reader_output:"Reader-Ausgabe",reader_response:"Leserreaktion",reader_search_hint:"Wenn Sie diese URL im Code verwenden, vergessen Sie nicht, die URL zu kodieren.",reader_url:"Leser-URL",reader_url_hint:"Klicken Sie unten, um den Inhalt über unsere Reader-API abzurufen",requires_post_method:"Diese Funktion erfordert die POST-Methode. Beim Hochladen Ihrer lokalen Datei wird die POST-Methode automatisch aktiviert.",search_params:"Suchparameter/Header",search_query_rewrite:"Bitte beachten Sie, dass Sie im Gegensatz zur oben gezeigten Demo in der Praxis nicht die ursprüngliche Frage im Internet nach einer Grundlage durchsuchen. Häufig wird die ursprüngliche Frage umgeschrieben oder es werden Multi-Hop-Fragen verwendet. Die abgerufenen Ergebnisse werden gelesen und anschließend werden zusätzliche Abfragen erstellt, um bei Bedarf weitere Informationen zu sammeln, bevor eine endgültige Antwort gefunden wird.",select_mode:"Auswahlmodus",show_read_demo:"Sehen Sie, wie Reader eine URL liest",show_search_demo:"Sehen Sie, wie Reader im Web sucht",slow_warning:"Dies kann bis zu 30 Sekunden dauern und kostet bis zu 300.000 Token pro Anfrage.",standard_usage:"Standardverwendung",stream_mode:"Stream-Modus",stream_mode_explain:"Der Stream-Modus ist nützlich, wenn die Zielseite zu groß zum Rendern ist. Wenn Sie feststellen, dass der Standardmodus unvollständige Inhalte liefert, versuchen Sie es mit dem Stream-Modus.",stream_mode_explain1:"Der Streaming-Modus ist nützlich, wenn Sie feststellen, dass der Standardmodus ein unvollständiges Ergebnis liefert. Dies liegt daran, dass der Streaming-Modus etwas länger wartet, bis die Seite vollständig gerendert ist. Verwenden Sie den Accept-Header, um den Streaming-Modus umzuschalten:",tagline:"Testen Sie die Demo",try_demo:"Demo",use_headers:"Das Verhalten der Reader-API kann mit Anforderungsheadern gesteuert werden. Hier ist eine vollständige Liste der unterstützten Header.",waiting_for_reader:"Warte zuerst auf das Ergebnis der Reader-API ...",warn_grounding_message:"Dieser Vorgang kann bis zu 30 Sekunden dauern und bis zu 300.000 Token pro Erdungsanforderung verbrauchen. Einige Browser können die Anforderung aufgrund der langen Latenz abbrechen. Wir empfehlen daher, den Code zu kopieren und von Ihrem Terminal aus auszuführen.",warn_grounding_title:"Hohe Latenz und Token-Nutzung",your_query:"Geben Sie Ihre Suchanfrage ein",your_query_hint:"Geben Sie eine Frage ein, die aktuelle Informationen oder Weltwissen erfordert.",your_statement:"Ihre Faktencheck-Aussage",your_url:"Geben Sie Ihre URL ein",your_url_hint:"Klicken Sie unten, um den Quellcode der Seite direkt abzurufen"},description:"Lesen Sie URLs und suchen Sie im Internet nach fundierteren LLMs.",dont_panic_api_key_is_free:"Keine Panik! Jeder neue API-Schlüssel enthält eine Million kostenlose Token!",faq_v1:{answer1:"Die Reader-API ist kostenlos und erfordert keinen API-Schlüssel. Fügen Sie Ihrer URL einfach „https://r.jina.ai/“ voran.",answer10:"Nein, die Reader-API kann nur Inhalte von öffentlich zugänglichen URLs verarbeiten.",answer11:"Wenn Sie innerhalb von 5 Minuten dieselbe URL anfordern, gibt die Reader-API den zwischengespeicherten Inhalt zurück.",answer12:"Leider nicht.",answer13:"Ja, Sie können entweder die native PDF-Unterstützung des Readers (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) oder die HTML-Version von arXiv (https://r.jina.ai/https://arxiv.org/html/2310.19923v4) verwenden.",answer14:"Der Reader betitelt alle Bilder unter der angegebenen URL und fügt `Image [idx]: [caption]` als Alt-Tag hinzu (falls ursprünglich keiner vorhanden ist). Dies ermöglicht nachgelagerten LLMs, beim Denken, Zusammenfassen usw. mit den Bildern zu interagieren.",answer15:"Die Reader-API ist auf hohe Skalierbarkeit ausgelegt. Sie wird automatisch auf Basis des Echtzeitverkehrs skaliert und die maximale Anzahl gleichzeitiger Anfragen liegt derzeit bei etwa 4000. Wir pflegen sie aktiv als eines der Kernprodukte von Jina AI. Sie können sie also gerne in der Produktion verwenden.",answer16:"Die neuesten Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle. Beachten Sie, dass wir aktiv an der Verbesserung der Ratenbegrenzung und der Leistung der Reader-API arbeiten. Die Tabelle wird entsprechend aktualisiert.",answer17:"Reader-LM ist ein neuartiges Small Language Model (SLM), das für die Datenextraktion und -bereinigung aus dem offenen Web entwickelt wurde. Es konvertiert rohes, verrauschtes HTML in sauberes Markdown und ist dabei von Jina Reader inspiriert. Mit einem Fokus auf Kosteneffizienz und kleiner Modellgröße ist Reader-LM sowohl praktisch als auch leistungsstark. Es ist derzeit auf den Marktplätzen AWS, Azure und GCP verfügbar. Wenn Sie spezielle Anforderungen haben, kontaktieren Sie uns bitte unter sales AT jina.ai.",answer2:"Die Reader-API verwendet einen Proxy, um jede beliebige URL abzurufen und ihren Inhalt in einem Browser darzustellen, um hochwertigen Hauptinhalt zu extrahieren.",answer3:"Ja, die Reader-API ist Open Source und im Jina AI GitHub-Repository verfügbar.",answer4:"Die Reader-API verarbeitet URLs im Allgemeinen innerhalb von 2 Sekunden und gibt Inhalte zurück. Komplexe oder dynamische Seiten können jedoch mehr Zeit benötigen.",answer5:"Scraping kann kompliziert und unzuverlässig sein, insbesondere bei komplexen oder dynamischen Seiten. Die Reader-API bietet eine optimierte, zuverlässige Ausgabe von sauberem, LLM-fähigem Text.",answer6:"Die Reader-API gibt Inhalte in der Originalsprache der URL zurück. Sie bietet keine Übersetzungsdienste an.",answer7:"Wenn bei Ihnen Blockierungsprobleme auftreten, wenden Sie sich für Unterstützung und Lösung bitte an unser Supportteam.",answer8:"Obwohl die Reader-API in erster Linie für Webseiten entwickelt wurde, kann sie auch Inhalte aus PDF-Dateien extrahieren, die auf Websites wie arXiv im HTML-Format angezeigt werden. Sie ist jedoch nicht für die allgemeine PDF-Extraktion optimiert.",answer9:"Derzeit verarbeitet die Reader-API keine Medieninhalte, zukünftige Erweiterungen werden jedoch Bildunterschriften und Videozusammenfassungen umfassen.",question1:"Welche Kosten sind mit der Nutzung der Reader-API verbunden?",question10:"Ist es möglich, die Reader-API auf lokale HTML-Dateien anzuwenden?",question11:"Speichert die Reader-API den Inhalt im Cache?",question12:"Kann ich die Reader-API verwenden, um auf Inhalte hinter einer Anmeldung zuzugreifen?",question13:"Kann ich die Reader-API verwenden, um auf arXiv auf PDF zuzugreifen?",question14:"Wie funktionieren Bildunterschriften im Reader?",question15:"Wie skalierbar ist der Reader? Kann ich ihn in der Produktion einsetzen?",question16:"Wie hoch ist die Ratenbegrenzung der Reader-API?",question17:"Was ist Reader-LM? Wie kann ich es verwenden?",question2:"Wie funktioniert die Reader-API?",question3:"Ist die Reader-API Open Source?",question4:"Wie hoch ist die typische Latenz für die Reader-API?",question5:"Warum sollte ich die Reader-API verwenden, anstatt die Seite selbst zu scrapen?",question6:"Unterstützt die Reader-API mehrere Sprachen?",question7:"Was soll ich tun, wenn eine Website die Reader-API blockiert?",question8:"Kann die Reader-API Inhalte aus PDF-Dateien extrahieren?",question9:"Kann die Reader-API Medieninhalte von Webseiten verarbeiten?",title:"Häufig gestellte Fragen zum Leser"},fast:"Schnell",fast_stream:"Sofortiges Daten-Streaming",fast_stream_description:"Sie benötigen Daten schnell? Unsere Reader-API kann Daten streamen, um die Latenz zu minimieren.",free:"Für immer frei",free_description:"Die Reader-API ist kostenlos! Sie erfordert weder eine Kreditkarte noch ein API-Geheimnis. Ihr Token-Kontingent wird dadurch nicht verbraucht.",is_free:"Und das Beste daran? Es ist kostenlos!",is_free_description:"Die Reader API ist kostenlos erhältlich und bietet flexible Ratenbegrenzungen und Preise. Sie basiert auf einer skalierbaren Infrastruktur und bietet hohe Zugänglichkeit, Parallelität und Zuverlässigkeit. Wir möchten Ihre bevorzugte Grundlösung für Ihre LLMs sein.",lm_v2_description:"ReaderLM-v2 ist ein 1,5-B-Parameter-Sprachmodell, das auf die Konvertierung von HTML in Markdown und die Extraktion von HTML in JSON spezialisiert ist. Es unterstützt Dokumente mit bis zu 512.000 Token in 29 Sprachen und bietet im Vergleich zu seinem Vorgänger eine um 20 % höhere Genauigkeit.",lm_v2_title:"ReaderLM v2: Kleines Sprachmodell für HTML zu Markdown und JSON",open:"In neuem Tab öffnen",original_pdf:"Original PDF",rate_limit:"Bewertungslimit",read_grounding_release_note:"Versionshinweis lesen",reader_also_read_images:"Bilder auf der Webseite werden mithilfe eines Vision Language Model im Reader automatisch mit Bildunterschriften versehen und in der Ausgabe als Bild-Alt-Tags formatiert. Dadurch erhält Ihr nachgelagertes LLM gerade genug Hinweise, um diese Bilder in seine Denk- und Zusammenfassungsprozesse einzubeziehen. Das bedeutet, dass Sie Fragen zu den Bildern stellen, bestimmte Bilder auswählen oder sogar ihre URLs zur tieferen Analyse an ein leistungsfähigeres VLM weiterleiten können!",reader_description:"Konvertieren Sie eine URL in eine LLM-freundliche Eingabe, indem Sie einfach <code>r.jina.ai</code> davor hinzufügen.",reader_do_grounding:"Reader zum Faktencheck",reader_do_grounding_explain:"Der neue Grounding-Endpunkt bietet eine durchgängige, nahezu in Echtzeit erfolgende Faktenprüfung. Er nimmt eine gegebene Aussage, begründet sie anhand von Echtzeit-Websuchergebnissen und gibt einen Faktizitätswert und die genauen verwendeten Referenzen zurück. Sie können Aussagen problemlos begründen, um LLM-Halluzinationen zu reduzieren oder die Integrität von von Menschen verfassten Inhalten zu verbessern.",reader_do_pdf_explain:"Ja, Reader unterstützt das Lesen von PDFs nativ. Es ist mit den meisten PDFs kompatibel, auch mit denen mit vielen Bildern, und es ist blitzschnell! In Kombination mit einem LLM können Sie im Handumdrehen ganz einfach eine ChatPDF- oder Dokumentenanalyse-KI erstellen.",reader_do_search:"Reader für Websuche und SERP",reader_do_search_explain:"Reader kann als SERP-API verwendet werden. Damit können Sie Ihr LLM mit dem Inhalt hinter der Seite der Suchmaschine füttern. Stellen Sie Ihrer Abfrage einfach <code>https://s.jina.ai/?q=</code> voran, und Reader durchsucht das Web und gibt die fünf besten Ergebnisse mit ihren URLs und Inhalten zurück, jeweils in sauberem, LLM-freundlichem Text. Auf diese Weise können Sie Ihr LLM immer auf dem neuesten Stand halten, seine Sachlichkeit verbessern und Halluzinationen reduzieren.",reader_reads_images:"Reader liest auch Bilder!",reader_reads_pdf:"Reader liest auch PDFs!",reader_result:"Leserergebnis",table:{td_1_0:"Lesen einer URL und Zurückgeben des Inhalts, nützlich zur Überprüfung der Erdung",td_1_1:"20 U/min",td_1_2:"200 U/min",td_1_3:"Basierend auf den Ausgabetoken",td_1_4:"3 Sekunden",td_1_5:"3 Sekunden",td_2_0:"Bei einer Suche im Web werden die fünf besten Ergebnisse zurückgegeben, was zur Eingrenzung der Suche nützlich ist.",td_2_1:"5 U/min",td_2_2:"40 U/min",td_2_3:"Basierend auf den Ausgabetoken für alle 5 Suchergebnisse",td_2_4:"10 Sekunden",td_2_5:"10 Sekunden",th0:"Endpunkt",th1:"Beschreibung",th2:"Ratenbegrenzung ohne API-Schlüssel",th3:"Ratenbegrenzung mit API-Schlüssel",th4:"Token-Zählschema",th5:"Durchschnittliche Latenz",th6:"Durchschnittliche Latenz"},title:"Leser-API",usage:"Verwendung",usage_details_false:"Nur grundlegende Verwendungen anzeigen",usage_details_null:"Grundlegende und erweiterte Verwendungsmöglichkeiten anzeigen",usage_details_true:"Nur erweiterte Verwendungen anzeigen",want_higher_rate_limit:"Sie möchten eine höhere Ratenbegrenzung bis 1000 RPM? Wir unterstützen Sie!",what_is1:"Was ist Reader?",what_is_answer_long:"Das Einspeisen von Webinformationen in LLMs ist ein wichtiger Schritt zur Einarbeitung, kann aber auch eine Herausforderung sein. Die einfachste Methode besteht darin, die Webseite zu scrapen und das Roh-HTML einzuspeisen. Das Scraping kann jedoch komplex und oft blockiert sein, und Roh-HTML ist mit irrelevanten Elementen wie Markups und Skripten überladen. Die Reader-API behebt diese Probleme, indem sie den Kerninhalt aus einer URL extrahiert und in sauberen, LLM-freundlichen Text umwandelt, wodurch eine qualitativ hochwertige Eingabe für Ihre Agent- und RAG-Systeme sichergestellt wird.",what_is_desc:"Ein Proxy, der auf jede URL zugreift und den Hauptinhalt in für LLMs optimierten Klartext umwandelt."},we={confirm_message:"Für Ihren API-Schlüssel sind noch {_leftTokens} Token übrig. Wenn Sie den vollständigen Text von {_numArticles}-Artikeln an die Reranker-API senden und dabei das Modell {_selectedReranker} verwenden, um verwandte Artikel für die aktuelle Seite zu ermitteln, wird die Tokenanzahl Ihres API-Schlüssels {_APIKey} erheblich reduziert. Möchten Sie fortfahren?",confirm_title:"Warnung: Hohe Token-Nutzung",out_of_quota:"Für diesen API-Schlüssel sind keine Token mehr vorhanden. Bitte laden Sie Ihr Konto auf oder verwenden Sie einen anderen API-Schlüssel.",recommend:"Holen Sie sich die Top 5",recommended_articles:"Top-5 ähnliche Artikel"},_e={benchmark:{description0:"LlamaIndex bewertete verschiedene Kombinationen von Einbettungen und Rerankern für RAG und führte eine Replikationsstudie durch, in der der mittlere reziproke Rang gemessen wurde. Die Ergebnisse unterstreichen die deutliche Verbesserung der Suchqualität durch den Jina Reranker, ein Vorteil, der unabhängig von den verwendeten spezifischen Einbettungen ist.",description1:"BIER (Benchmarking IR) bewertet die Abrufeffektivität eines Modells, einschließlich Relevanz und NDCG. Ein höherer BIER-Score korreliert mit genaueren Übereinstimmungen und Suchergebnissen.",description2:"Mithilfe des LoCo-Benchmarks haben wir das Verständnis eines Modells für lokale Kohärenz und Kontext sowie das abfragespezifische Ranking gemessen. Eine höhere LoCo-Bewertung spiegelt eine bessere Fähigkeit wider, relevante Informationen zu identifizieren und zu priorisieren.",description3:"Der MTEB (Multilingual Text Embedding Benchmark) testet im Großen und Ganzen die Fähigkeiten eines Modells bei Texteinbettungen, einschließlich Clustering, Klassifizierung, Abruf und anderen Metriken. Für unseren Vergleich haben wir jedoch nur die Reranking-Aufgaben des MTEB herangezogen.",title:"Benchmark",title0:"LamaIndex",title1:"BEIR",title2:"Lok",title3:"MTBB"},benchmark_description:"Zum Vergleich haben wir drei weitere führende Reranker von BGE (BAAI), BCE (Netease Youdao) und Cohere in die Benchmark einbezogen. Wie aus den folgenden Ergebnissen hervorgeht, erzielt Jina Reranker in allen relevanten Kategorien für das Reranking die höchste Durchschnittspunktzahl und ist damit klarer Spitzenreiter unter seinen Mitbewerbern.",benchmark_title:"Leistungsbenchmark",choose_turbo:"Bis zu 5-fache Geschwindigkeitssteigerung mit Reranker-Turbo",choose_turbo_description:"Wir bieten außerdem zwei neue Open-Source-Reranker-Modelle an: jina-reranker-v1-turbo-en und jina-reranker-v1-tiny-en. Letzteres hat nur 30 Millionen Parameter und vier Schichten. Diese beiden neuen Reranker bieten eine 5-mal schnellere Inferenzgeschwindigkeit als das Basismodell bei nur sehr geringen Qualitätseinbußen. Sie eignen sich perfekt für Anwendungen, die ein Reranking in Echtzeit erfordern. Lesen Sie den Benchmark unten.",customize_urself:"Ändern Sie es und sehen Sie, wie sich die Reaktion ändert!",customize_urself_pl:"Ändern Sie sie und sehen Sie, wie sich die Reaktion ändert!",description:"Neural Retriever der Weltklasse zur Maximierung der Suchrelevanz.",description_rich:"Maximieren Sie die Suchrelevanz und RAG-Genauigkeit mit unserer hochmodernen Reranker-API.",example_input_document:"Beispieldokumente von Kandidaten zum Ranking",example_input_query:"Beispielabfrage",faq_v1:{answer1:"Die Preise für die Reranker-API richten sich nach unserer Preisstruktur für die Embedding-API. Es beginnt mit 1 Million kostenlosen Token für jeden neuen API-Schlüssel. Über die kostenlosen Token hinaus stehen verschiedene Pakete zum Kauf zur Verfügung. Weitere Informationen finden Sie in unserem Abschnitt „Preise“.",answer10:"Ja, unsere Dienste sind auf den Marktplätzen AWS, Azure und GCP verfügbar. Wenn Sie spezielle Anforderungen haben, kontaktieren Sie uns bitte unter sales AT jina.ai.",answer11:"Wenn Sie an einem fein abgestimmten Reranker interessiert sind, der auf bestimmte Domaindaten zugeschnitten ist, wenden Sie sich bitte an unser Vertriebsteam. Unser Team wird Ihre Anfrage zeitnah beantworten.",answer3:"<code>jina-reranker-v2-base-multilingual</code> zeichnet sich durch mehrsprachige Unterstützung aus, übertrifft <code>bge-reranker-v2-m3</code> und bietet einen 15-mal schnelleren Durchsatz als <code>jina-reranker-v1-base-en</code>. Es unterstützt auch agentenbasierte Aufgaben und Codeabruf. <code>jina-colbert-v2</code> ist eine Verbesserung gegenüber <code>ColBERTv2</code>, bietet eine um 6,5 % bessere Abrufleistung und bietet mehrsprachige Unterstützung für 89 Sprachen. Es verfügt über benutzergesteuerte Einbettungsgrößen für optimale Effizienz und Präzision.",answer4:"Ja, sowohl <code>jina-reranker-v2-base-multilingual</code> als auch <code>jina-colbert-v2</code> sind Open Source und unter der Lizenz CC-BY-NC 4.0 verfügbar. Sie können die Modelle für nichtkommerzielle Zwecke frei verwenden, weitergeben und anpassen.",answer5:"Ja, sowohl <code>jina-reranker-v2-base-multilingual</code> als auch <code>jina-colbert-v2</code> unterstützen über 100 Sprachen, darunter Englisch, Chinesisch und andere wichtige Weltsprachen. Sie sind für mehrsprachige Aufgaben optimiert und übertreffen frühere Modelle.",answer6:"Die maximale Länge des Abfragetokens beträgt 512. Für Dokumente gibt es keine Tokenbeschränkung.",answer7:"Sie können bis zu 2048 Dokumente pro Abfrage neu einordnen.",answer8:"Im Gegensatz zu unserer Einbettungs-API gibt es kein Konzept der Stapelgröße. Sie können pro Anfrage nur ein Abfrage-Dokument-Tupel senden, das Tupel kann jedoch bis zu 2048 Kandidatendokumente enthalten.",answer9:"Die Latenz variiert zwischen 100 Millisekunden und 7 Sekunden und hängt weitgehend von der Länge der Dokumente und der Abfrage ab. Beispielsweise dauert das Neuranking von 100 Dokumenten mit jeweils 256 Token bei einer 64-Token-Abfrage etwa 150 Millisekunden. Durch Erhöhen der Dokumentlänge auf 4096 Token erhöht sich die Zeit auf 3,5 Sekunden. Wenn die Abfragelänge auf 512 Token erhöht wird, erhöht sich die Zeit weiter auf 7 Sekunden.",question1:"Wie viel kostet die Reranker-API?",question10:"Können Ihre Endpunkte privat auf AWS, Azure oder GCP gehostet werden?",question11:"Bieten Sie einen genau abgestimmten Reranker für domänenspezifische Daten an?",question3:"Was ist der Unterschied zwischen den beiden Rerankern?",question4:"Sind Jina Reranker Open Source?",question5:"Unterstützen die Reranker mehrere Sprachen?",question6:"Wie lang dürfen Anfragen und Dokumente maximal sein?",question7:"Wie viele Dokumente kann ich pro Abfrage maximal neu einordnen?",question8:"Wie groß ist die Stapelgröße und wie viele Abfrage-Dokument-Tupel kann ich in einer Anfrage senden?",question9:"Mit welcher Latenz kann ich rechnen, wenn ich 100 Dokumente neu einordne?",title:"Häufige Fragen zum Reranker"},feature_on_premises_description2:"Stellen Sie Jina Reranker auf AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um maßgeschneiderte Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und lokale Server zu erhalten.",feature_on_premises_description3:"Stellen Sie Jina Reranker auf AWS Sagemaker und Microsoft Azure und bald auch in Google Cloud Services bereit, oder wenden Sie sich an unser Vertriebsteam, um angepasste Kubernetes-Bereitstellungen für Ihre Virtual Private Cloud und Ihre lokalen Server zu erhalten.",feature_solid_description:"Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests mit den SOTA-Rerankern, um eine beispiellose Leistung zu gewährleisten.",how_it_works:"So funktioniert das:",how_it_works_v1:{description1:"Ein Suchsystem verwendet Einbettungen/BM25, um basierend auf der Anfrage des Benutzers eine breite Palette potenziell relevanter Dokumente zu finden.",description2:"Anschließend analysiert der Reranker diese Ergebnisse auf einer detaillierteren Ebene und berücksichtigt dabei die Nuancen der Interaktion der Abfragebegriffe mit dem Dokumentinhalt.",description3:"Es ordnet die Suchergebnisse neu und platziert diejenigen, die es auf der Grundlage dieser tiefergehenden Analyse für am relevantesten hält, ganz oben.",title1:"Erster Abruf",title2:"Neueinstufung",title3:"Verbesserte Ergebnisse"},improve_performance:"Garantierte Verbesserung gegenüber der Vektorsuche",improve_performance_description:"Unsere Auswertungen zeigten Verbesserungen für Suchsysteme, die den Jina Reranker verwenden, mit +8 % bei der Trefferquote und +33 % beim mittleren reziproken Rang.",learning1:"Erfahren Sie mehr über Reranker",learning1_description:"Was ist ein Reranker? Warum reicht die Vektorsuche oder die Kosinusähnlichkeit nicht aus? Erfahren Sie mit unserem umfassenden Leitfaden mehr über Reranker von Grund auf.",read_more_about_benchmark:"Lesen Sie mehr über den Benchmark",read_more_about_turbo:"Lesen Sie mehr über die Turbo- und Tiny-Modelle",read_more_about_v2:"Jina Reranker v2 ist der beste Reranker seiner Klasse, der am 25. Juni 2024 veröffentlicht wurde. Er wurde für Agentic RAG entwickelt. Er bietet Funktionsaufrufunterstützung, mehrsprachigen Abruf für über 100 Sprachen, Codesuchfunktionen und ist 6-mal schneller als v1. Lesen Sie mehr über das v2-Modell.",reranker_description:"Probieren Sie unsere hochmoderne Reranker-API aus, um Ihre Suchrelevanz und RAG-Genauigkeit zu maximieren. Kostenlos starten!",show_v2benchmark:"Benchmark für Modell v2 (neueste) anzeigen",table:{number_token_document:"Anzahl der Token in jedem Dokument",number_token_query:"Anzahl der Token in der Abfrage",title:"Unten ist der Zeitaufwand für das Reranking einer Abfrage und 100 Dokumenten in Millisekunden aufgeführt:"},title:"Reranker-API",top_n:"Anzahl der zurückgegebenen Dokumente",top_n_explain:"Die Anzahl der relevantesten Dokumente, die für die Abfrage zurückgegeben werden sollen.",try_embedding:"Probieren Sie die Einbettungs-API kostenlos aus",try_reranker:"Testen Sie die Reranker-API kostenlos",v2_features:{description1:"Reranker v2 ermöglicht die Dokumentensuche in über 100 Sprachen, unabhängig von der Abfragesprache.",description2:"Reranker v2 bewertet Codeausschnitte und Funktionssignaturen auf der Grundlage von Abfragen in natürlicher Sprache und ist somit ideal für Agentic RAG-Anwendungen.",description3:"Reranker v2 erstellt eine Rangfolge der relevantesten Tabellen auf der Grundlage von Abfragen in natürlicher Sprache und hilft so dabei, verschiedene Tabellenschemata zu sortieren und das relevanteste zu identifizieren, bevor eine SQL-Abfrage generiert wird.",title1:"Mehrsprachiger Abruf",title2:"Funktionsaufruf und Codesuche",title3:"Unterstützung tabellarischer und strukturierter Daten"},v2benchmark:{descBeir:"NDCG 10-Wertungen für verschiedene Neurankingmodelle für den Beir-Datensatz gemeldet",descCodeSearchNet:"MRR 10-Werte für verschiedene Reranking-Modelle für den CodeSearchNet-Datensatz gemeldet",descMKQA:"Erinnern Sie sich an 10 Ergebnisse, die für verschiedene Reranking-Modelle für den MKQA-Datensatz gemeldet wurden",descNSText2SQL:"Erinnern Sie sich an 3 Ergebnisse, die für verschiedene Neurankingmodelle für den NSText2SQL-Datensatz gemeldet wurden",descRTX4090:"Durchsatzwerte (Abruf von Dokumenten in 50 ms), die für verschiedene Neurankingmodelle auf einer RTX 4090-GPU gemeldet wurden.",descToolBench:"Erinnern Sie sich an 3 Bewertungen, die für verschiedene Neurankingmodelle für den ToolBench-Datensatz gemeldet wurden",titleBeir:"BEIR (Heterogener Benchmark für verschiedene IR-Aufgaben)",titleCodeSearchNet:"CodeSearchNet. Der Benchmark ist eine Kombination aus Abfragen in Docstring- und natürlichen Sprachformaten mit gekennzeichneten Codesegmenten, die für die Abfragen relevant sind.",titleMKQA:"MKQA (Fragen und Antworten zum mehrsprachigen Wissen)",titleNSText2SQL:"NSText2SQL",titleRTX4090:"Durchsatz von Jina Reranker v2 auf RTX4090",titleToolBench:"ToolBench. Der Benchmark sammelt über 16.000 öffentliche APIs und entsprechende synthetisch generierte Anweisungen für deren Verwendung in Einzel- und Multi-API-Einstellungen."},vs_table:{col0:"Reranker",col0_1:"Verbesserte Suchpräzision und Relevanz",col0_2:"Erste, schnelle Filterung",col0_3:"Allgemeine Textsuche für weitreichende Abfragen",col1:"Vektorsuche",col1_1:"Detailliert: Unterdokument und Abfragesegment",col1_2:"Breit: Ganze Dokumente",col1_3:"Mittelstufe: Verschiedene Textsegmente",col2:"BM25",col2_1:"Hoch",col2_2:"Mittel",col2_3:"Niedrig",col3_1:"Nicht benötigt",col3_2:"Hoch",col3_3:"Niedrig, nutzt vorgefertigten Index",col4_1:"Hoch",col4_2:"Hoch",col4_3:"Nicht benötigt",col5_1:"Hervorragend für differenzierte Abfragen",col5_2:"Ausgewogen zwischen Effizienz und Genauigkeit",col5_3:"Konsistent und zuverlässig für eine breite Palette von Abfragen",col6_1:"Sehr präzise mit tiefem Kontextverständnis",col6_2:"Schnell und effizient, mit mäßiger Genauigkeit",col6_3:"Hoch skalierbar, mit nachgewiesener Wirksamkeit",col7_1:"Ressourcenintensiv bei komplexer Umsetzung",col7_2:"Erfasst möglicherweise keinen tiefen Abfragekontext oder keine Nuancen",col7_3:"Bei sehr spezifischen oder kontextbezogenen Suchen ist die Leistung möglicherweise unterdurchschnittlich",header0:"Beste für",header1:"Die Granularität",header2:"Komplexität der Abfragezeit",header3:"Zeitkomplexität indizieren",header4:"Komplexität der Trainingszeit",header5:"Suchqualität",header6:"Stärken",header7:"Schwächen",subtitle:"Die folgende Tabelle bietet einen umfassenden Vergleich von Reranker, Vector/Embeddings Search und BM25 und hebt deren Stärken und Schwächen in verschiedenen Kategorien hervor.",title:"Vergleich von Reranker, Vector Search und BM25"},what_is:"Was ist ein Reranker?",what_is_answer_long:`Ziel eines Suchsystems ist es, schnell und effizient die relevantesten Ergebnisse zu finden. Traditionell wurden Methoden wie BM25 oder tf-idf verwendet, um Suchergebnisse basierend auf der Keyword-Übereinstimmung zu ordnen. Neuere Methoden, wie beispielsweise die einbettungsbasierte Kosinusähnlichkeit, wurden in vielen Vektordatenbanken implementiert. Diese Methoden sind unkompliziert, können jedoch manchmal die Feinheiten der Sprache und vor allem die Interaktion zwischen Dokumenten und der Absicht einer Abfrage außer Acht lassen.

Hier glänzt der „Reranker“. Ein Reranker ist ein fortschrittliches KI-Modell, das die anfänglichen Ergebnisse einer Suche – oft bereitgestellt durch eine einbettungs-/tokenbasierte Suche – und sie neu bewertet, um sicherzustellen, dass sie besser mit der Absicht des Benutzers übereinstimmen. Es geht über den oberflächlichen Abgleich von Begriffen hinaus und berücksichtigt die tiefere Interaktion zwischen der Suchanfrage und dem Inhalt der Dokumente.`,what_is_answer_long_ending:"Der Reranker kann die Suchqualität erheblich verbessern, da er auf Unterdokument- und Unterabfrageebene arbeitet, d. h. die einzelnen Wörter und Phrasen, ihre Bedeutung und ihre Beziehung zueinander innerhalb der Abfrage und der Dokumente untersucht. Dies führt zu präziseren und kontextbezogeneren Suchergebnissen.",what_is_desc:"Ein Reranker ist ein KI-Modell, das die Suchergebnisse aus einer Vektorsuche oder einem Dense-Retrieval-Modell verfeinert. Mehr lesen."},Se={caption_image_desc:"Generieren Sie eine Textbeschreibung des Bildes.",caption_image_title:"Bildunterschrift",description:"Entdecken Sie auf Bildern basierende Geschichtenerzählungen jenseits von Pixeln",example1:"Bei diesem Video handelt es sich offenbar um eine Naturaufnahme mit einem bezaubernden weißen Hasen und einem Schmetterling auf einer Wiese. Der Hase interagiert auf unterschiedliche Weise mit dem Schmetterling und zeigt so ihre einzigartige Beziehung. Die natürliche Umgebung bietet eine malerische Kulisse und unterstreicht die Schönheit dieser einfachen, aber faszinierenden Szene.",generate_story_desc:"Erstellen Sie eine vom Bild inspirierte Geschichte, die häufig Dialoge oder Monologe der Charaktere enthält.",generate_story_title:"Geschichte generieren",intro1:"Führende KI-Lösung für Bildunterschriften und Videozusammenfassungen",json_image_desc:"Generieren Sie mithilfe eines vordefinierten Schemas ein strukturiertes JSON-Format aus dem Bild. Dies ermöglicht eine gezielte Datenextraktion aus dem Bild.",json_image_title:"Extrahieren Sie JSON aus dem Bild",summarize_video_desc:"Erstellen Sie eine prägnante Zusammenfassung des Videos und heben Sie wichtige Ereignisse hervor.",summarize_video_title:"Video zusammenfassen",visual_q_a_desc:"Beantworten Sie eine Frage basierend auf dem Bildinhalt.",visual_q_a_title:"Visuelle Fragen und Antworten"},ve={ask_deepsearch:"Fragen Sie DeepSearch nach ...",ask_on_current_page:"Fragen Sie auf der aktuellen Seite nach...",find_solution:"Generieren Sie eine Lösung für...",hint:"Durchsuchen Sie Produkte, Neuigkeiten und Ihre Fragen",hotkey:"Drücken Sie die Taste /, um auf dieser Seite zu suchen",hotkey1:"Drücken Sie",hotkey2:"Umschalten",hotkey_long1:"Drücken Sie jederzeit",hotkey_long3:"um die Suchleiste zu öffnen",more_results:"{_numMore} weitere Ergebnisse",placeholder:"Stellen Sie auf dieser Seite Fragen",proposing_solution:"Generierung einer Antwort basierend auf dem Seiteninhalt ...",required:"Bitte beschreiben Sie Ihre Frage genauer.",results:"Ergebnisse"},Ae={description:"Navigieren, interagieren, verfeinern: Produktentdeckung neu denken"},Ie={description:"Überbrückung der semantischen Lücke in Ihrer vorhandenen Suchinfrastruktur"},Me={"Hacker News":"Hacker-News",LinkedIn:"LinkedIn",facebook:"Facebook",reddit:"Reddit",rss:"RSS-Feed",share_btn:"Aktie",twitter:"X (Twitter)"},De={click_to_learn_more:"Klicke, um mehr zu lernen",contextualization:"Kontextualisierung",contextualization_desc:"Reranker passen anfängliche Suchergebnisse basierend auf tiefer kontextueller Relevanz in Bezug auf die Abfrage an. Dadurch wird das Ranking verfeinert, um besser zu dem zu passen, was Benutzer wahrscheinlich nützlich finden.",coreInfra:"Kerninfrastruktur",coreInfra_desc:"Core Infra bietet eine Cloud-native Ebene für die Entwicklung, Bereitstellung und Orchestrierung von Suchgrundlagenmodellen sowohl in der öffentlichen Cloud als auch vor Ort, sodass Dienste problemlos nach oben und unten skaliert werden können.",embedding_serving:"Servieren einbetten",embedding_serving_description:"Bereitstellung von Einbettungen über einen robusten, skalierbaren Mikroservice unter Verwendung cloudnativer Technologien.",embedding_tech:"Einbettungen",embedding_tech_description:`Bei Jina AI nutzen wir die Leistungsfähigkeit der Einbettungstechnologie, um verschiedene KI-Anwendungen zu revolutionieren. Diese Technologie dient als einheitliche Methode zur effizienten Darstellung und Komprimierung verschiedener Datentypen und stellt sicher, dass keine wichtigen Informationen verloren gehen. Unser Fokus liegt auf der Transformation komplexer Datensätze in ein allgemein verständliches Einbettungsformat, das für eine präzise und aufschlussreiche KI-Analyse unerlässlich ist.

Einbettungen sind von grundlegender Bedeutung, insbesondere bei Anwendungen wie der präzisen Bild- und Spracherkennung, wo sie dabei helfen, feinkörnige Details und Nuancen zu erkennen. Bei der Verarbeitung natürlicher Sprache verbessern Einbettungen das Verständnis von Kontext und Stimmung und führen zu genaueren Konversations-KI- und Sprachübersetzungstools. Sie sind auch von entscheidender Bedeutung bei der Entwicklung anspruchsvoller Empfehlungssysteme, die ein tiefes Verständnis der Benutzerpräferenzen in verschiedenen Inhaltsformen wie Text, Audio und Video erfordern.`,embedding_tuning:"Tuning einbetten",embedding_tuning_description:"Optimierung hochwertiger Einbettungen durch Integration von Fachwissen für eine verbesserte aufgabenspezifische Leistung.",embeddings:"Einbettungen",embeddings_desc:"Einbettungen sind die Eckpfeiler moderner Suchsysteme und stellen multimodale Daten in Zahlenvektoren dar. Dieser Prozess ermöglicht ein differenzierteres und kontextbezogeneres Verständnis von Inhalten, das weit über die einfache Keyword-Übereinstimmung hinausgeht.",for_developers:"Für Entwickler",for_enterprise:"Für Unternehmen",for_power_users:"Für Power-User",grounding:"Erdung",grounding_desc:"Der Leser verfeinert Eingaben und Ergebnisse durch LLMs. Sie verbessern die Qualität, Lesbarkeit und Sachlichkeit der endgültigen Antwort.",model_serving:"Modelldienst",model_serving_description:"Die Bereitstellung fein abgestimmter Modelle in einer Produktionsumgebung, die in der Regel erhebliche Ressourcen wie GPU-Hosting erfordert. MLOps, wobei der Schwerpunkt auf der skalierbaren, effizienten und zuverlässigen Bereitstellung mittelgroßer bis großer Modelle liegt.",model_tuning:"Modelltuning",model_tuning_description:"Bei der Feinabstimmung, auch Feinabstimmung genannt, werden die Parameter eines vorab trainierten Modells an einem neuen, oft aufgabenspezifischen Datensatz angepasst, um dessen Leistung zu verbessern und es an eine bestimmte Anwendung anzupassen.",personalization:"Personalisierung",personalization_desc:"Verwenden Sie synthetische Daten und trainieren Sie anhand von Benutzeranweisungen automatisch ein domänenspezifisches Einbettungs- und Reranking-Modell.",preprocessing:"Vorverarbeitung",preprocessing_desc:"Bei der Vorverarbeitung werden die Rohdaten bereinigt, normalisiert und in ein für das Suchsystem verwertbares Format umgewandelt.",promptOps:"PromptOps",promptOps_desc:"Prompt Ops verbessern die Eingabe und Ausgabe des Suchsystems, einschließlich der bei der Abfrageerweiterung, der LLM-Eingabe und der Ergebnisumschreibung verwendeten. Dies stellt sicher, dass die Suche besser versteht und bessere Ergebnisse liefert.",prompt_serving:"Prompte Bedienung",prompt_serving_description:"Verpacken und Bereitstellen von Prompts über eine API, ohne umfangreiche Modelle zu hosten. Die API ruft einen öffentlichen Modelldienst für große Sprachen auf und übernimmt die Orchestrierung von Ein- und Ausgaben in einer Operationskette.",prompt_tech:"Prompt- und Agent-Engineering",prompt_tech_description:`Bei Jina AI erkennen wir, dass Prompt Engineering für die Interaktion mit großen Sprachmodellen (LLMs) von entscheidender Bedeutung ist. Mit der Weiterentwicklung dieser Modelle nimmt die Komplexität der Eingabeaufforderungen zu und umfasst komplexe Überlegungen und Logik. Dieser Fortschritt unterstreicht das miteinander verflochtene Wachstum von LLMs und die schnelle Weiterentwicklung.

Wir sehen eine Zukunft voraus, in der LLMs als Compiler fungieren und Eingabeaufforderungen zur neuen Programmiersprache werden. Diese Verschiebung deutet darauf hin, dass sich zukünftige technologische Kompetenzen mehr auf die schnelle Beherrschung als auf die traditionelle Codierung konzentrieren könnten. Unser Ziel bei Jina AI ist es, in diesem transformativen Bereich eine Führungsrolle zu übernehmen und durch die Beherrschung dieser aufstrebenden „Sprache“ fortschrittliche KI für den täglichen Gebrauch zugänglich und praktisch zu machen.`,prompt_tuning:"Prompte Abstimmung",prompt_tuning_description:"Der Prozess der Erstellung und Verfeinerung der Prompts, um die Ausgabe auf bestimmte, gewünschte Antworten auszurichten.",representation:"Darstellung",representation_desc:"Embeddings transformieren multimodale Daten in ein einheitliches, vektorisiertes Format. Dadurch ist das Suchsystem in der Lage, Inhalte über einfache Schlagwörter hinaus zu verstehen und zu kategorisieren.",rerankers:"Neubewerter",rerankers_desc:"Reranker übernehmen die anfänglichen Ergebnisse aus den Einbettungen und verfeinern sie, um sicherzustellen, dass dem Benutzer die relevantesten Ergebnisse präsentiert werden. Dies ist entscheidend, um qualitativ hochwertige Suchergebnisse zu liefern, die der Absicht des Benutzers entsprechen."},Ee={care_most:"Was liegt Ihnen am meisten am Herzen?",care_most_options:{accuracy:"Genauigkeit",cost:"Kosten",other:"Andere",scalability:"Skalierbarkeit",speed:"Geschwindigkeit"},care_most_required:"Was ist Ihnen bei der Auswahl einer Dienstleistung am wichtigsten?",company_size:"Wie groß ist Ihr Unternehmen?",company_size_required:"Teilen Sie uns mit, dass die Größe Ihres Unternehmens uns hilft, einen besseren Service zu bieten",company_url:"Wie lautet die Website Ihres Unternehmens?",company_url_required:"Sagen Sie uns, dass die Website Ihres Unternehmens uns hilft, einen besseren Service zu bieten",contactName:"Ihr Name",contactName_required:"Wie sollen wir Sie ansprechen?",contactTitle:"Wie lautet deine Jobbezeichnung?",contactTitle_required:"Ihre Berufsbezeichnung ist erforderlich",contact_us:"Kontaktiere uns",domain_required:"Teilen Sie uns mit, dass Ihre Arbeitsdomäne uns hilft, einen besseren Service zu bieten",email:"Email",email_contact:"Ihre Kontakt-E-Mail",email_invalid:"E-Mail ist ungültig",email_required:"E-Mail ist erforderlich",fine_tuned_embedding:"Sind Sie an fein abgestimmten Einbettungen interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!",fine_tuned_reranker:"Sind Sie an fein abgestimmten Rerankern interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!",full_survey:"Nehmen Sie an der vollständigen Umfrage teil und erhalten Sie schnellere Antworten von unserem Team",get_new_key:"Holen Sie sich Ihren API-Schlüssel",get_update_blog_posts:"Erhalten Sie die neuesten Updates für die Blogbeiträge",get_update_embeddings:"Erhalten Sie die neuesten Updates für die Einbettungen",send:"Schicken",sign_up:"Melden Sie sich an",subscribe:"Abonnieren",tell_domain:"Teilen Sie uns Ihre Domain mit",usage_type:"Welche Art der Nutzung beschreibt Sie am besten?",usage_type_options:{other:"Andere",poc:"Konzeptioneller Beweiß",production:"Produktion",research:"Forschung"},usage_type_required:"Teilen Sie uns mit, dass Ihre Nutzungsart uns hilft, einen besseren Service zu bieten",used_product:"Welches Modell verwenden Sie?",used_product_required:"Wählen Sie das Modell aus, das Sie verwenden oder an dem Sie interessiert sind"},Te={description:"Agententechniken zur Erweiterung Ihres LLM und zur Überschreitung seiner Grenzen"},Be="Inhaltsverzeichnis",Pe={advance_usage:"Verwenden Sie die POST-Anfrage für weitere Funktionen",basic_usage:"Verwenden Sie eine GET-Anfrage, um Token zu zählen",basic_usage_explain:"Sie können einfach eine GET-Anfrage senden, um die Anzahl der Token in Ihrem Text zu zählen.",change_content:"Ändern Sie den „Inhalt“ und sehen Sie sich das Live-Ergebnis an",chars:"Charaktere",chinese:"chinesisch",chunk:"Brocken",chunk_all:"Alle Brocken",chunking:"Blitzschnelles Zerlegen langer Dokumente in Blöcke!",chunking_explain:"Sie können die Segmenter-API auch verwenden, um lange Dokumente in kleinere Abschnitte zu zerlegen, sodass sie leichter in Einbettungen oder Rerankern verarbeitet werden können. Wir nutzen gängige Strukturmerkmale und erstellen eine Reihe von Regeln und Heuristiken, die bei unterschiedlichen Inhaltstypen gut funktionieren, z. B. in den Sprachen Markdown, HTML, LaTeX und CJK.",chunking_short:"Chunking",chunks_in_total:"{_numChunks} Chunks insgesamt",count_tokens_hint:"<b>{_numTokens}</b> Token, {_numChars} Zeichen.",description:"Schneiden Sie langen Text in Abschnitte und führen Sie eine Tokenisierung durch.",description_long:"Unsere Segmenter-API ist entscheidend, um LLMs dabei zu helfen, Eingaben innerhalb von Kontextgrenzen zu verwalten und die Modellleistung zu optimieren. Sie ermöglicht Entwicklern, Token zu zählen und relevante Textsegmente zu extrahieren, was eine effiziente Datenverarbeitung und Kostenverwaltung gewährleistet.",description_long1:"Kostenlose API zum Segmentieren langer Texte in Blöcke und zur Tokenisierung.",english:"Englisch",explain:"Ein Segmentierer ist eine wichtige Komponente, die Text in Token oder Blöcke umwandelt. Dabei handelt es sich um die grundlegenden Dateneinheiten, die ein Embedding-/Reranker-Modell oder LLM verarbeitet. Token können ganze Wörter, Wortteile oder sogar einzelne Zeichen darstellen.",faq_v1:{answer1:"Die Segmenter-API ist kostenlos nutzbar. Durch die Angabe Ihres API-Schlüssels können Sie auf ein höheres Ratenlimit zugreifen und Ihr Schlüssel wird Ihnen nicht in Rechnung gestellt.",answer10:"Neben westlichen Sprachen funktioniert Chunking auch gut mit Chinesisch, Japanisch und Koreanisch.",answer2:"Ohne API-Schlüssel können Sie auf die Segmenter-API mit einer Ratenbegrenzung von 20 RPM zugreifen.",answer3:"Mit einem API-Schlüssel können Sie auf die Segmenter-API mit einer Ratenbegrenzung von 200 RPM zugreifen. Für Premium-Benutzer beträgt die Ratenbegrenzung 1000 RPM.",answer4:"Nein, Ihr API-Schlüssel wird nur verwendet, um auf ein höheres Ratenlimit zuzugreifen.",answer5:"Ja, die Segmenter-API ist mehrsprachig und unterstützt über 100 Sprachen.",answer6:"GET-Anfragen werden ausschließlich zum Zählen der Anzahl von Token in einem Text verwendet und ermöglichen Ihnen die einfache Integration als Zähler in Ihre Anwendung. POST-Anfragen unterstützen mehr Parameter und Funktionen, wie z. B. die Rückgabe der ersten/letzten N Token.",answer7:"Sie können bis zu 64.000 Zeichen pro Anfrage senden.",answer8:"Die Chunking-Funktion segmentiert lange Dokumente anhand gemeinsamer Strukturmerkmale in kleinere Chunks und stellt so eine genaue Segmentierung des Textes in sinnvolle Chunks sicher. Im Wesentlichen handelt es sich um ein (großes!) Regex-Muster, das Text anhand bestimmter syntaktischer Merkmale segmentiert, die häufig mit semantischen Grenzen übereinstimmen, wie etwa Satzenden, Absatzumbrüchen, Zeichensetzung und bestimmten Konjunktionen. Es handelt sich nicht um semantisches Chunking. Dieser (große) Regex ist so leistungsfähig, wie er im Rahmen der Beschränkungen regulärer Ausdrücke sein kann. Er schafft ein Gleichgewicht zwischen Komplexität und Leistung. Während mit Regex kein echtes semantisches Verständnis möglich ist, wird der Kontext anhand gemeinsamer Strukturmerkmale gut angenähert.",answer9:"Wenn die Eingabe spezielle Token enthält, fügt unsere Segmenter-API diese in das Feld „special_tokens“ ein. So können Sie sie leicht identifizieren und für Ihre nachgelagerten Aufgaben entsprechend behandeln, z. B. indem Sie sie entfernen, bevor Sie den Text in ein LLM einspeisen, um Injektionsangriffe zu verhindern.",question1:"Wie viel kostet die Segmenter-API?",question10:"Unterstützt Chunking andere Sprachen als Englisch?",question2:"Wenn ich keinen API-Schlüssel angebe, wie hoch ist dann die Ratenbegrenzung?",question3:"Wie hoch ist die Ratenbegrenzung, wenn ich einen API-Schlüssel angebe?",question4:"Werden die Token von meinem API-Schlüssel abgezogen?",question5:"Unterstützt die Segmenter-API mehrere Sprachen?",question6:"Was ist der Unterschied zwischen GET- und POST-Anfragen?",question7:"Was ist die maximale Länge, die ich pro Anfrage tokenisieren kann?",question8:"Wie funktioniert die Chunking-Funktion? Handelt es sich dabei um semantisches Chunking?",question9:"Wie handhaben Sie spezielle Token wie „Endoftext“ in der Segmenter-API?",title:"Häufige Fragen zum Segmenter"},free_api:"Die Nutzung der Segmenter-API ist kostenlos. Durch die Angabe Ihres API-Schlüssels können Sie auf ein höheres Ratenlimit zugreifen, und für Ihren Schlüssel werden keine Kosten erhoben.",input_text:"Eingabetext",is_free:"Segmenter-API ist kostenlos!",is_free_description:"Durch die Angabe Ihres API-Schlüssels können Sie auf eine höhere Ratenbegrenzung zugreifen und für Ihren Schlüssel fallen keine Kosten an.",japanese:"japanisch",korean:"Koreanisch",parameters:{auth_token:"API-Schlüssel für höhere Ratenbegrenzung hinzufügen",auth_token_explain:"Geben Sie Ihren Jina-API-Schlüssel ein, um auf eine höhere Ratenbegrenzung zuzugreifen. Aktuelle Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle.",head:"Die ersten N Token zurückgeben",head_explain:"Gibt die ersten N Token des angegebenen Inhalts zurück. Grenzenexklusiv. Kann nicht mit „tail“ verwendet werden.",learn_more:"Mehr erfahren",max_chunk_length:"Maximale Länge jedes Blocks",max_chunk_length_explain:"Maximale Anzahl von Zeichen in jedem Block. In der Praxis kann die Blocklänge kleiner als dieser Wert sein, wenn es im Text eine natürliche Grenze gibt.",return_chunks:"Die Brocken zurückgeben",return_chunks_explain:"Aufteilung der Eingabe in semantisch sinnvolle Segmente bei gleichzeitiger Verarbeitung einer großen Vielfalt an Textarten und Randfällen auf der Grundlage gemeinsamer Strukturhinweise.",return_tokens:"Die Token zurückgeben",return_tokens_explain:"Gibt die Token und ihre entsprechenden IDs in der Antwort zurück. Schalten Sie um, um die Ergebnisvisualisierung anzuzeigen.",tail:"Die letzten N Token zurückgeben",tail_explain:"Gibt die letzten N Token des angegebenen Inhalts zurück. Grenzenexklusiv. Kann nicht mit „head“ verwendet werden.",type:"Segmentierer",type_explain:"Wählen Sie den zu verwendenden Tokenizer aus.",used_by_models:"Wird in {_usedBy} verwendet."},remove_boundary_cues:"Zeilenumbrüche entfernen",remove_boundary_cues_explain:"Entfernen Sie alle Zeilenumbrüche (die wichtigsten Begrenzungshinweise) aus der Eingabe. Dadurch wird das Problem anspruchsvoller und Sie können sehen, wie sich die Antwort ändert.",show_space:"Führende/nachfolgende Leerzeichen anzeigen",table:{td_1_0:"Texte tokenisieren, zählen und die ersten/letzten N Token abrufen.",td_1_1:"20 U/min",td_1_2:"200 U/min",td_1_3:"1000 U/min",td_1_4:"Keine Gebühr",td_1_5:"800 ms"},title:"Segmenter-API",token_index:"Token-Index: {_index}",usage:"Verwendung",visualization:"Visualisierung",what_is:"Was ist ein Segmenter?"},Le={cta:"In {_lang}-Code übersetzen",select_language:"Sprache"},xe={description:"Eine Python-Vektordatenbank, die Sie brauchen – nicht mehr und nicht weniger"},Re="zzz",ye={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:i,api_general_faq:r,autotune:t,avatar:s,best_banner:a,beta:u,billing_general_faq:d,blog_tags:l,book2024:o,cclicence:h,classifier:g,clip_as_service:c,cloud:m,contact_us_page:b,copy:f,copy_to_clipboard_success:k,dalle_flow:p,deepsearch:z,"dev-gpt":{description:"Ihr virtuelles Entwicklungsteam"},disco_art:w,doc_array:_,download:S,embedding:v,embeddings:A,estimator:I,faq:M,faq_button:D,farewell:E,finetuner:T,finetuner_plus:B,finetuning:P,footer:L,get_new_key:x,github:R,grounding:y,header:K,hub:V,huggingface:W,impact_snapshots:F,inference:G,insufficient_error_message:C,integrations:U,internship_faq:j,internship_page:q,jcloud:N,jerboa:J,jina:O,jina_chat:H,key_manager:Z,lab_dialog:Q,landing_page:X,langchain_serve:Y,legal_page:$,llm_serp:ee,model_graph:ne,models:ie,news_page:re,newsroom_page:te,notice:se,open_day:ae,open_day_faq:ue,open_gpt:de,paywall:le,powered_by:oe,print:he,project_status:ge,prompt_perfect:ce,promptperfect:me,purchase:be,purchase_now:fe,rate_limit:ke,rationale:pe,reader:ze,recommender:we,reranker:_e,scenex:Se,searchbar:ve,searchscape:Ae,semantic:Ie,share:Me,spectrum:De,subscribe_system:Ee,think_gpt:Te,toc:Be,tokenizer:Pe,translator:Le,vectordb:xe,zzz:Re};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,i as about_us_page,r as api_general_faq,t as autotune,s as avatar,a as best_banner,u as beta,d as billing_general_faq,l as blog_tags,o as book2024,h as cclicence,g as classifier,c as clip_as_service,m as cloud,b as contact_us_page,f as copy,k as copy_to_clipboard_success,p as dalle_flow,z as deepsearch,ye as default,w as disco_art,_ as doc_array,S as download,v as embedding,A as embeddings,I as estimator,M as faq,D as faq_button,E as farewell,T as finetuner,B as finetuner_plus,P as finetuning,L as footer,x as get_new_key,R as github,y as grounding,K as header,V as hub,W as huggingface,F as impact_snapshots,G as inference,C as insufficient_error_message,U as integrations,j as internship_faq,q as internship_page,N as jcloud,J as jerboa,O as jina,H as jina_chat,Z as key_manager,Q as lab_dialog,X as landing_page,Y as langchain_serve,$ as legal_page,ee as llm_serp,ne as model_graph,ie as models,re as news_page,te as newsroom_page,se as notice,ae as open_day,ue as open_day_faq,de as open_gpt,le as paywall,oe as powered_by,he as print,ge as project_status,ce as prompt_perfect,me as promptperfect,be as purchase,fe as purchase_now,ke as rate_limit,pe as rationale,ze as reader,we as recommender,_e as reranker,Se as scenex,ve as searchbar,Ae as searchscape,Ie as semantic,Me as share,De as spectrum,Ee as subscribe_system,Te as think_gpt,Be as toc,Pe as tokenizer,Le as translator,xe as vectordb,Re as zzz};
