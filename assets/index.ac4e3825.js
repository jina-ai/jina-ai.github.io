var r={PRODUCT_DESCRIPTION:e=>{const{normalize:i}=e;return i(["Forniamo incorporamenti, riclassificatori, lettori LLM e ottimizzatori tempestivi di altissimo livello, un'intelligenza artificiale di ricerca pionieristica per dati multimodali."])},SEO_TAG_LINE:e=>{const{normalize:i}=e;return i(["La tua base di ricerca, potenziata."])},about_us_page:{approach:e=>{const{normalize:i}=e;return i(["Il nostro approccio"])},approach_connect_dots:e=>{const{normalize:i}=e;return i(["Collegare i punti: Power Users alle imprese"])},approach_connect_dots_description:e=>{const{normalize:i}=e;return i(["Quindi, perch\xE9 l'attenzione per gli utenti esperti \xE8 essenziale per il nostro modello incentrato sull'azienda? Perch\xE9 si tratta di stabilire relazioni precoci. Rivolgendoci ora agli utenti esperti, stiamo costruendo ponti verso le imprese che influenzeranno in futuro. \xC8 un gioco strategico: un investimento a lungo termine per garantire che la nostra offerta aziendale rimanga al primo posto quando questi utenti esperti salgono a ruoli decisionali all'interno delle organizzazioni."])},approach_content1:e=>{const{normalize:i}=e;return i(["Nel mondo in rapida evoluzione dell'IA, le strategie devono essere agili e lungimiranti. Sebbene la nostra offerta principale rimanga incentrata sulle aziende, il panorama dell'IA \xE8 cambiato in modi che richiedono un ripensamento del nostro approccio all'acquisizione dei clienti. Ecco perch\xE9 introdurre gli utenti esperti come punto di ingresso della nostra canalizzazione non \xE8 solo innovativo, ma cruciale per la nostra crescita sostenuta nel settore aziendale."])},approach_content2:e=>{const{normalize:i}=e;return i(["In Jina AI, la nostra strategia \xE8 quella di essere proattivi piuttosto che reattivi. L'inclusione degli utenti esperti come punto di ingresso della canalizzazione garantisce che non solo catturiamo le attuali tendenze del mercato, ma siamo anche strategicamente pronti per la futura crescita aziendale. Il nostro impegno nei confronti delle imprese rimane incrollabile; tuttavia, il nostro approccio per raggiungerli \xE8 innovativo, robusto e, soprattutto, lungimirante."])},approach_content4:e=>{const{normalize:i}=e;return i(['Tutti vogliono una ricerca migliore. In Jina AI, consentiamo una migliore ricerca fornendo la <span class="text-primary text-bold">Base di ricerca</span>, che comprende incorporamenti, riclassificatori, operazioni di richiesta e Infra. Questi componenti lavorano di concerto per rivoluzionare il modo in cui cerchiamo e comprendiamo i dati. Ci\xF2 porta a una migliore esperienza di ricerca, alla fiducia degli utenti, a un aumento diretto delle vendite e allo sblocco di una nuova crescita aziendale.'])},approach_miss_mark:e=>{const{normalize:i}=e;return i(["Perch\xE9 i MLOps tradizionali mancano il bersaglio"])},approach_miss_mark_description:e=>{const{normalize:i}=e;return i(["Sebbene l'afflusso di utenti esperti sia significativo, gli strumenti MLOps tradizionali non sono attrezzati per soddisfare le loro esigenze. Questi strumenti ricordano l'uso di un trattore per spostarsi nelle strade della citt\xE0: sono pesanti e spesso eccessivi. Gli sviluppatori di nuova generazione richiedono strumenti agili e intuitivi che completino il loro rapido ritmo di sviluppo."])},approach_new_paradigm:e=>{const{normalize:i}=e;return i(["Tecnologia basata su prompt: un nuovo paradigma"])},approach_new_paradigm_description:e=>{const{normalize:i}=e;return i([`Il 2023 ha annunciato un cambiamento significativo: l'ascesa della tecnologia basata sul prompt. Semplificando il processo di sviluppo dell'IA, ha democratizzato l'accesso agli strumenti di intelligenza artificiale. Ora, coloro che non hanno una vasta esperienza di programmazione, definiti "utenti esperti", possono dedicarsi allo sviluppo dell'IA senza le ripide curve di apprendimento associate a strumenti come Pytorch, Docker o Kubernetes.

Facendo un parallelo, questo \xE8 simile all'evoluzione del personal computer. Inizialmente, solo gli esperti di tecnologia gestivano i computer. Ma con l'avvento delle interfacce user-friendly, potrebbe partecipare un pubblico pi\xF9 ampio. Oggi, con la tecnologia basata sul prompt, stiamo assistendo a una democratizzazione simile nell'IA.`])},awards:e=>{const{normalize:i}=e;return i(["Premi e riconoscimenti"])},berlin:e=>{const{normalize:i}=e;return i(["Berlino, Germania"])},berlin_address:e=>{const{normalize:i}=e;return i(["Prinzessinnenstra\xDFe 19-20, 10969 Berlino, Germania"])},berlin_address2:e=>{const{normalize:i}=e;return i(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berlino, Germania"])},bj:e=>{const{normalize:i}=e;return i(["Pechino, Cina"])},bj_address:e=>{const{normalize:i}=e;return i(["Livello 5, Edificio 6, No.48 Haidian West St. Beijing Haidian, Cina"])},brochure_info:e=>{const{normalize:i}=e;return i(["La tua guida alla nostra azienda ti aspetta"])},description:e=>{const{normalize:i}=e;return i(["Il futuro inizia qui."])},download_brochure1:e=>{const{normalize:i}=e;return i(["Scarica l'opuscolo"])},download_docarray_logo:e=>{const{normalize:i}=e;return i(["Scarica il logo DocArray"])},download_docarray_logo_desc:e=>{const{normalize:i}=e;return i(["Accedi al logo DocArray, un progetto open source avviato da Jina AI e contribuito alla Linux Foundation nel dicembre 2022. Disponibile in modalit\xE0 chiara e scura, nei formati PNG e SVG."])},download_jina_logo:e=>{const{normalize:i}=e;return i(["Scarica il logo Jina AI"])},download_jina_logo_desc:e=>{const{normalize:i}=e;return i(["Ottieni il logo Jina AI sia in modalit\xE0 chiara che scura, disponibile nei formati PNG e SVG. Questo logo \xE8 un marchio registrato presso l'Ufficio dell'Unione europea per la propriet\xE0 intellettuale (EUIPO)."])},download_logo:e=>{const{normalize:i}=e;return i(["Scarica loghi"])},employees:e=>{const{normalize:i}=e;return i(["Dipendenti"])},empower_developers:e=>{const{normalize:i}=e;return i(["Sviluppatori potenziati"])},fastApiCaption:e=>{const{normalize:i}=e;return i(["Ha contribuito con oltre $ 20.000 dal 2021."])},founded:e=>{const{normalize:i}=e;return i(["Fondato"])},founded_in:e=>{const{normalize:i}=e;return i(["Fondato nel"])},investors:e=>{const{normalize:i}=e;return i(["I nostri investitori"])},linuxFoundationCaption:e=>{const{normalize:i}=e;return i(["Versa un contributo annuo di $ 10.000 a partire dal 2022."])},mission:e=>{const{normalize:i}=e;return i(["La nostra missione"])},mission_content1:e=>{const{normalize:i}=e;return i(["Le nostre tecnologie chiave, tra cui prompt-tuning, prompt-serving, model-tuning e model-serving, incarnano il nostro impegno a democratizzare l'accesso all'intelligenza artificiale. Attraverso la nostra iniziativa open source, ci impegniamo a promuovere l'innovazione, la collaborazione e la trasparenza, garantendo soluzioni scalabili, efficienti e robuste. Jina AI \xE8 pi\xF9 di una semplice azienda; \xE8 una comunit\xE0 dedicata a consentire alle aziende di affrontare le sfide dinamiche dell'era digitale e prosperare nei loro settori."])},mission_content2:e=>{const{normalize:i}=e;return i(["Al centro di Jina AI c'\xE8 la nostra missione di essere il portale dell'intelligenza artificiale multimodale per una clientela diversificata, dagli utenti esperti e dagli sviluppatori alle imprese. Crediamo profondamente nella potenza dell'open source e ci dedichiamo alla creazione di strumenti avanzati e accessibili per la comunit\xE0 AI. Le nostre tecnologie chiave, tra cui prompt-tuning, prompt-serving, embedding-tuning e embedding-serving, incarnano il nostro impegno per la democratizzazione dell'accesso all'intelligenza artificiale. Attraverso la nostra iniziativa open source, ci impegniamo a promuovere l'innovazione, la collaborazione e la trasparenza, garantendo soluzioni scalabili, efficienti e robuste. Jina AI \xE8 pi\xF9 di una semplice azienda; \xE8 una comunit\xE0 dedicata a consentire alle aziende di affrontare le sfide dinamiche dell'era digitale e prosperare nei loro settori."])},mission_content3:e=>{const{normalize:i}=e;return i(["In Jina AI, la nostra missione \xE8 guidare il progresso dell'intelligenza artificiale multimodale attraverso tecnologie innovative di incorporamento e basate su prompt, concentrandoci specificamente su aree come l'elaborazione del linguaggio naturale, l'analisi di immagini e video e l'interazione intermodale dei dati. Questa specializzazione ci consente di fornire soluzioni uniche che trasformano dati complessi provenienti da pi\xF9 fonti in informazioni fruibili e applicazioni rivoluzionarie."])},mit_report_title:e=>{const{normalize:i}=e;return i(["Multimodale: la nuova frontiera dell\u2019IA"])},mit_techreview:e=>{const{normalize:i}=e;return i(["Revisione della tecnologia del MIT"])},numfocusCaption:e=>{const{normalize:i}=e;return i(["Dona regolarmente ogni mese a partire dal 2022."])},office:e=>{const{normalize:i}=e;return i(["I nostri uffici"])},otherProjectsCaption:e=>{const{normalize:i}=e;return i(["Donati oltre $ 3.000 tramite Github Sponsorship."])},our_answer:e=>{const{normalize:i}=e;return i(["Assolutamente, Yann. Ci stiamo lavorando, costruendo ponti verso un futuro di intelligenza artificiale multimodale!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:i}=e;return i(["Ha fornito una donazione una tantum di $ 10.000 e ha sponsorizzato numerosi eventi PyCon, inclusi quelli in Germania, Italia, Cina e Stati Uniti."])},sefo:{layer0:e=>{const{normalize:i}=e;return i(["Applicazioni per l'utente finale"])},layer1:e=>{const{normalize:i}=e;return i(["RAG/orchestrazione"])},layer3:e=>{const{normalize:i}=e;return i(["GPU/mobile/edge/elaborazione locale"])}},segmentFaultCaption:e=>{const{normalize:i}=e;return i(["Ha contribuito con una donazione una tantum di $ 6.000."])},stats_1:e=>{const{normalize:i}=e;return i(["Fondata nel febbraio 2020, Jina AI \xE8 rapidamente emersa come pioniere globale nella tecnologia AI multimodale. Nell'impressionante lasso di tempo di 20 mesi, abbiamo raccolto con successo 37,5 milioni di dollari, segnando la nostra posizione di forza nel settore dell'IA. La nostra rivoluzionaria tecnologia, open-source su GitHub, ha consentito a oltre 40.000 sviluppatori in tutto il mondo di creare e distribuire senza problemi sofisticate applicazioni multimodali."])},stats_2:e=>{const{normalize:i}=e;return i(["Nel 2023, abbiamo fatto passi da gigante nel far progredire gli strumenti di generazione dell'IA basati sulla tecnologia multimodale. Questa innovazione ha beneficiato di oltre 250.000 utenti in tutto il mondo, soddisfacendo una pletora di requisiti aziendali unici. Dalla facilitazione della crescita aziendale e dal miglioramento dell'efficienza operativa all'ottimizzazione dei costi, Jina AI \xE8 dedicata a consentire alle aziende di eccellere nell'era multimodale."])},stats_4:e=>{const{normalize:i}=e;return i([`Fondata nel 2020 a Berlino, Jina AI \xE8 un'azienda leader nel settore dell'intelligenza artificiale per la ricerca. Forniamo <span class="text-primary text-bold">Search Foundation</span>, il nucleo per GenAI e applicazioni multimodali. La nostra missione \xE8 aiutare le aziende e gli sviluppatori a sbloccare i dati multimodali per la creazione di valore con una ricerca migliore. In quanto azienda commerciale open source, ci piace l'innovazione aperta.`])},stats_v1:e=>{const{normalize:i}=e;return i(["Cerca/acc"])},subtitle:e=>{const{normalize:i}=e;return i(["Rivoluzionando la creazione di contenuti attraverso soluzioni generate dall'intelligenza artificiale per sbloccare infinite possibilit\xE0. Plasmare il futuro dei contenuti generati dall'intelligenza artificiale e migliorare la creativit\xE0 umana."])},sz:e=>{const{normalize:i}=e;return i(["Shenzen, Cina"])},sz_address:e=>{const{normalize:i}=e;return i(["402, Piano 4, Fu'an Technology Building, Shenzhen Nanshan, Cina"])},team:e=>{const{normalize:i}=e;return i(["All'interno del Portale di Jina AI"])},team_content1:e=>{const{normalize:i}=e;return i(["Da diversi angoli del globo, stiamo costruendo il futuro dell'intelligenza artificiale. Le nostre prospettive distinte arricchiscono il nostro lavoro, innescando innovazioni. All'interno di questo portale, abbracciamo la nostra individualit\xE0 e perseguiamo con passione i nostri sogni. Benvenuti nel portale del futuro dell'IA."])},team_join:e=>{const{normalize:i}=e;return i(["Unisciti a noi"])},technologies:e=>{const{normalize:i}=e;return i(["Tecnologie"])},title:e=>{const{normalize:i}=e;return i(["A proposito di Jina AI"])},title0:e=>{const{normalize:i}=e;return i(["Il futuro"])},title1:e=>{const{normalize:i}=e;return i(["Inizia"])},title2:e=>{const{normalize:i}=e;return i(["Qui"])},title3:e=>{const{normalize:i}=e;return i(["Inizia qui"])},understand_our_strength:e=>{const{normalize:i}=e;return i(["Comprendi la nostra forza"])},understand_our_view2:e=>{const{normalize:i}=e;return i(["Comprendere il fondamento della ricerca"])},users:e=>{const{normalize:i}=e;return i(["Utenti registrati"])},value:e=>{const{normalize:i}=e;return i(["Il nostro valore"])},value_content1:e=>{const{normalize:i}=e;return i([`Crediamo che l\u2019apertura possa accelerare l\u2019innovazione e favorire la collaborazione. Non siamo solo sostenitori: siamo contributori attivi, che investono in modo significativo nella comunit\xE0 open source.

Dall'essere uno dei primi donatori di FastAPI, al supportare attivamente la Linux Foundation e la Python Software Foundation, siamo appassionati nel restituire qualcosa. Ma non ci fermiamo qui; abbiamo anche reso open source i nostri modelli e progetti, condividendo la nostra esperienza con il mondo.`])},vision:e=>{const{normalize:i}=e;return i(["La nostra missione"])},vision_content1:e=>{const{normalize:i}=e;return i(["Ispirato dall'intuizione di Yann LeCun che '"])},vision_content3:e=>{const{normalize:i}=e;return i([`Il futuro dell'intelligenza artificiale \xE8 <span class="text-primary text-bold">multimodale</span> e noi ne facciamo parte. Ci rendiamo conto che le aziende devono affrontare sfide nello sfruttamento dei dati multimodali. In risposta, ci impegniamo a favore della <span class="text-primary text-bold">Search Foundation</span> per aiutare le aziende e gli sviluppatori a effettuare ricerche migliori e a utilizzare dati multimodali per la crescita aziendale.`])},yannlecun_quote:e=>{const{normalize:i}=e;return i(["Un sistema di intelligenza artificiale addestrato solo su parole e frasi non si avviciner\xE0 mai alla comprensione umana."])}},api_general_faq:{answer1:e=>{const{normalize:i}=e;return i(["S\xEC, la stessa chiave API \xE8 valida per tutti i prodotti di base di ricerca di Jina AI. Ci\xF2 include l'incorporamento, il riclassificazione, il lettore e l'ottimizzazione delle API, con token condivisi tra tutti i servizi."])},answer12:e=>{const{normalize:i}=e;return i(["Aderiamo a una rigorosa politica sulla privacy e non utilizziamo i dati di input degli utenti per addestrare i nostri modelli."])},answer3:e=>{const{normalize:i}=e;return i([`S\xEC, l'utilizzo dei token pu\xF2 essere monitorato nella scheda "Acquista token" inserendo la chiave API, consentendoti di visualizzare la cronologia di utilizzo e i token rimanenti.`])},answer4:e=>{const{normalize:i}=e;return i(["Se hai smarrito una chiave ricaricata e desideri recuperarla, contatta il supporto AT jina.ai con la tua e-mail registrata per ricevere assistenza."])},answer5:e=>{const{normalize:i}=e;return i(["No, le nostre chiavi API non hanno una data di scadenza. Tuttavia, se sospetti che la tua chiave sia stata compromessa e desideri ritirarla o trasferire i suoi token su una nuova chiave, contatta il nostro team di supporto per assistenza."])},answer6:e=>{const{normalize:i}=e;return i(['Questo perch\xE9 la nostra architettura serverless scarica determinati modelli durante i periodi di scarso utilizzo. La richiesta iniziale attiva o "riscalda" il modello, operazione che potrebbe richiedere alcuni secondi. Dopo questa attivazione iniziale, le richieste successive vengono elaborate molto pi\xF9 rapidamente.'])},question1:e=>{const{normalize:i}=e;return i(["Posso utilizzare la stessa chiave API per incorporare, riclassificare, leggere e ottimizzare le API?"])},question12:e=>{const{normalize:i}=e;return i(["I dati di input dell'utente vengono utilizzati per addestrare i tuoi modelli?"])},question3:e=>{const{normalize:i}=e;return i(["Posso monitorare l'utilizzo del token della mia chiave API?"])},question4:e=>{const{normalize:i}=e;return i(["Cosa devo fare se dimentico la mia chiave API?"])},question5:e=>{const{normalize:i}=e;return i(["Le chiavi API scadono?"])},question6:e=>{const{normalize:i}=e;return i(["Perch\xE9 la prima richiesta per alcuni modelli \xE8 lenta?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative all'API"])}},autotune:{base_model:e=>{const{normalize:i}=e;return i(["Modello base per la messa a punto"])},check_data:e=>{const{normalize:i}=e;return i(["Scarica i dati sintetici"])},check_model:e=>{const{normalize:i}=e;return i(["Scarica il modello ottimizzato"])},data_size:e=>{const{normalize:i}=e;return i(["Dati sintetici generati"])},description:e=>{const{normalize:i}=e;return i(["Ottieni incorporamenti ottimizzati per qualsiasi dominio desideri."])},description_long:e=>{const{normalize:i}=e;return i(["Dicci semplicemente in quale dominio desideri che i tuoi incorporamenti eccellano e noi forniremo automaticamente un modello di incorporamento pronto all'uso e ottimizzato per quel dominio."])},does_it_work_tho:e=>{const{normalize:i}=e;return i(["Ma funziona comunque?"])},does_it_work_tho_explain:e=>{const{normalize:i}=e;return i(["La regolazione fine automatica mantiene la promessa auto-magica di fornire incorporamenti ottimizzati per qualsiasi dominio tu voglia. Ma funziona veramente? Questo \xE8 un dubbio abbastanza ragionevole. Lo abbiamo testato su una variet\xE0 di domini e modelli base per scoprirlo. Dai un'occhiata ai risultati selezionati con la ciliegia e con il limone qui sotto."])},domain_instruction:e=>{const{normalize:i}=e;return i(["Istruzioni sul dominio"])},embedding_provider:e=>{const{normalize:i}=e;return i(["Seleziona un modello di incorporamento di base"])},eval_evaluation:e=>{const{normalize:i}=e;return i(["Validazione"])},eval_map:e=>{const{normalize:i}=e;return i(["CARTA GEOGRAFICA"])},eval_mrr:e=>{const{normalize:i}=e;return i(["MRR"])},eval_ndcg:e=>{const{normalize:i}=e;return i(["NDCG"])},eval_performance_before_after:e=>{const{normalize:i}=e;return i(["Prestazioni sul set di validazione sintetica prima e dopo la messa a punto"])},eval_syntheticDataSize:e=>{const{normalize:i}=e;return i(["Totale"])},eval_test:e=>{const{normalize:i}=e;return i(["Dati reali per i test"])},eval_training:e=>{const{normalize:i}=e;return i(["Formazione"])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i(["La funzionalit\xE0 \xE8 attualmente in versione beta e costa 1 milione di token per modello ottimizzato. Puoi utilizzare la chiave API esistente dall'API Embedding/Reranker se dispone di token sufficienti oppure puoi creare una nuova chiave API, che include 1 milione di token gratuiti."])},answer10:e=>{const{normalize:i}=e;return i(["Attualmente no. Tieni presente che questa funzionalit\xE0 \xE8 ancora in versione beta. L'archiviazione pubblica dei modelli ottimizzati e dei dati sintetici nell'hub del modello Hugging Face aiuta noi e la comunit\xE0 a valutare la qualit\xE0 della formazione. In futuro, prevediamo di offrire un'opzione di archiviazione privata."])},answer11:e=>{const{normalize:i}=e;return i(["Poich\xE9 tutti i modelli ottimizzati vengono caricati su Hugging Face, puoi accedervi tramite SentenceTransformers semplicemente specificando il nome del modello."])},answer12:e=>{const{normalize:i}=e;return i(["Per favore controlla la tua cartella spam. Se ancora non riesci a trovarlo, contatta il nostro team di supporto utilizzando l'indirizzo email che hai fornito."])},answer2:e=>{const{normalize:i}=e;return i(["Non \xE8 necessario fornire alcun dato di addestramento. Descrivi semplicemente il tuo dominio di destinazione (il dominio per il quale desideri ottimizzare gli incorporamenti) in linguaggio naturale o utilizza un URL come riferimento e il nostro sistema generer\xE0 dati sintetici per addestrare il modello."])},answer3:e=>{const{normalize:i}=e;return i(["Circa 30 minuti."])},answer4:e=>{const{normalize:i}=e;return i(["I modelli ottimizzati e i dati sintetici vengono archiviati pubblicamente nell'hub del modello Hugging Face."])},answer5:e=>{const{normalize:i}=e;return i(["Il sistema utilizza l'API Reader per recuperare il contenuto dall'URL. Quindi analizza il contenuto per riassumere il tono e il dominio, che utilizza come linee guida per la generazione di dati sintetici. Pertanto, l'URL dovrebbe essere accessibile al pubblico e rappresentativo del dominio di destinazione."])},answer6:e=>{const{normalize:i}=e;return i([`S\xEC, puoi mettere a punto un modello per una lingua diversa dall'inglese. Il sistema rileva automaticamente la lingua delle istruzioni del tuo dominio e genera di conseguenza dati sintetici. Raccomandiamo inoltre di scegliere il modello base appropriato per la lingua di destinazione. Ad esempio, se scegli come target un dominio tedesco, dovresti selezionare "jina-embeddings-v2-base-de" come modello base.`])},answer7:e=>{const{normalize:i}=e;return i(["No, la nostra API di ottimizzazione supporta solo i modelli Jina v2."])},answer8:e=>{const{normalize:i}=e;return i(["Al termine del processo di messa a punto, il sistema valuta il modello utilizzando un set di test e segnala le metriche delle prestazioni. Riceverai un'e-mail con i dettagli delle prestazioni prima/dopo su questo set di test. Ti invitiamo inoltre a valutare il modello sul tuo set di test per garantirne la qualit\xE0."])},answer9:e=>{const{normalize:i}=e;return i(["Il sistema genera dati sintetici integrando le istruzioni del dominio di destinazione fornite con il ragionamento degli agenti LLM. Produce triplette negative rigide, essenziali per l'addestramento di modelli di incorporamento di alta qualit\xE0. Per maggiori dettagli, fare riferimento al nostro prossimo documento di ricerca su Arxiv."])},question1:e=>{const{normalize:i}=e;return i(["Quanto costa l'API di fine-tuning?"])},question10:e=>{const{normalize:i}=e;return i(["Posso mantenere privati \u200B\u200Bi miei modelli ottimizzati e i dati sintetici?"])},question11:e=>{const{normalize:i}=e;return i(["Come posso utilizzare il modello ottimizzato?"])},question12:e=>{const{normalize:i}=e;return i(["Non ho mai ricevuto l'e-mail con i risultati della valutazione. Cosa dovrei fare?"])},question2:e=>{const{normalize:i}=e;return i(["Cosa devo inserire? Devo fornire i dati di allenamento?"])},question3:e=>{const{normalize:i}=e;return i(["Quanto tempo ci vuole per mettere a punto un modello?"])},question4:e=>{const{normalize:i}=e;return i(["Dove vengono archiviati i modelli ottimizzati?"])},question5:e=>{const{normalize:i}=e;return i(["Se fornisco un URL di riferimento, come lo utilizza il sistema?"])},question6:e=>{const{normalize:i}=e;return i(["Posso mettere a punto un modello per una lingua specifica?"])},question7:e=>{const{normalize:i}=e;return i(["Posso ottimizzare gli incorporamenti non Jina, ad esempio bge-M3?"])},question8:e=>{const{normalize:i}=e;return i(["Come garantite la qualit\xE0 dei modelli perfezionati?"])},question9:e=>{const{normalize:i}=e;return i(["Come si generano dati sintetici?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative alla regolazione fine automatica"])}},find_on_hf:e=>{const{normalize:i}=e;return i(["Elenca i modelli ottimizzati"])},temporarily_unavailable:e=>{const{normalize:i}=e;return i(["Temporaneamente non disponibile. Stiamo aggiornando il nostro sistema di regolazione automatica per offrirti un servizio migliore. Per favore controllare pi\xF9 tardi."])},test_on:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Testato su campioni casuali ",n(o("_dataSize"))," da ",n(o("_dataName"))])},test_performance_before_after:e=>{const{normalize:i}=e;return i(["Prestazioni sul test impostato prima e dopo la messa a punto"])},title:e=>{const{normalize:i}=e;return i(["API di regolazione fine automatica"])},total_improve:e=>{const{normalize:i}=e;return i(["Media miglioramento"])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},what_is:e=>{const{normalize:i}=e;return i(["Che cos'\xE8 la sintonizzazione fine automatica?"])},what_is_answer_long:e=>{const{normalize:i}=e;return i(["L'ottimizzazione consente di prendere un modello pre-addestrato e adattarlo a un'attivit\xE0 o dominio specifico addestrandolo su un nuovo set di dati. In pratica, trovare dati di addestramento efficaci non \xE8 semplice per molti utenti. Una formazione efficace richiede molto pi\xF9 che il semplice inserimento di PDF grezzi e HTML nel modello; ed \xE8 difficile farlo bene. La regolazione fine automatica risolve questo problema generando automaticamente dati di addestramento efficaci utilizzando una pipeline di agenti LLM avanzata; e mettere a punto il modello all'interno di un flusso di lavoro ML. Puoi pensarlo come una combinazione di generazione di dati sintetici e AutoML, quindi tutto ci\xF2 che devi fare \xE8 descrivere il tuo dominio di destinazione in linguaggio naturale e lasciare che il nostro sistema faccia il resto."])}},best_banner:{description:e=>{const{normalize:i}=e;return i(["Dal blog al banner, senza i prompt!"])},example_description:e=>{const{normalize:i}=e;return i([`Alice cominciava a stancarsi molto di stare seduta accanto a sua sorella sulla riva e di non avere niente da fare: una o due volte aveva sbirciato nel libro che sua sorella stava leggendo, ma non conteneva immagini o conversazioni, "e a che serve un libro", pens\xF2 Alice "senza immagini o conversazioni?" Quindi stava valutando tra s\xE9 (come meglio poteva, perch\xE9 la giornata calda la faceva sentire molto assonnata e stupida), se il piacere di fare una catena di margherite sarebbe valsa la pena di alzarsi e raccogliere le margherite, quando all'improvviso un Bianconiglio con gli occhi rosa le corse vicino.`])},example_title:e=>{const{normalize:i}=e;return i(["Le avventure di Alice nel paese delle meraviglie - Capitolo 1"])}},beta:e=>{const{normalize:i}=e;return i(["Beta"])},billing_general_faq:{answer10:e=>{const{normalize:i}=e;return i([`Offriamo un'accogliente prova gratuita ai nuovi utenti, che include un milione di token da utilizzare con qualsiasi dei nostri modelli, facilitata da una chiave API generata automaticamente. Una volta raggiunto il limite di token gratuiti, gli utenti possono facilmente acquistare token aggiuntivi per le proprie chiavi API tramite la scheda "Acquista token".`])},answer13:e=>{const{normalize:i}=e;return i(["No, i token non vengono detratti per le richieste non riuscite."])},answer14:e=>{const{normalize:i}=e;return i(["I pagamenti vengono elaborati tramite Stripe, che supporta una variet\xE0 di metodi di pagamento tra cui carte di credito, Google Pay e PayPal per la tua comodit\xE0."])},answer15:e=>{const{normalize:i}=e;return i(["S\xEC, al momento dell'acquisto dei token verr\xE0 emessa una fattura all'indirizzo e-mail associato al tuo account Stripe."])},answer9:e=>{const{normalize:i}=e;return i(["Il nostro modello di prezzo si basa sul numero totale di token elaborati, consentendo agli utenti la flessibilit\xE0 di allocare questi token su qualsiasi numero di frasi, offrendo una soluzione economicamente vantaggiosa per diversi requisiti di analisi del testo."])},question10:e=>{const{normalize:i}=e;return i(["\xC8 disponibile una prova gratuita per i nuovi utenti?"])},question13:e=>{const{normalize:i}=e;return i(["Vengono addebitati i token per le richieste non riuscite?"])},question14:e=>{const{normalize:i}=e;return i(["Quali metodi di pagamento sono accettati?"])},question15:e=>{const{normalize:i}=e;return i(["\xC8 disponibile la fatturazione per gli acquisti di token?"])},question9:e=>{const{normalize:i}=e;return i(["La fatturazione \xE8 basata sul numero di frasi o richieste?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative alla fatturazione"])}},blog_tags:{all:e=>{const{normalize:i}=e;return i(["Tutto"])},events:e=>{const{normalize:i}=e;return i(["Eventi"])},featured:e=>{const{normalize:i}=e;return i(["In primo piano"])},insights:e=>{const{normalize:i}=e;return i(["Approfondimenti"])},"knowledge-base":e=>{const{normalize:i}=e;return i(["Base di conoscenza"])},press:e=>{const{normalize:i}=e;return i(["comunicato stampa"])},releases:e=>{const{normalize:i}=e;return i(["Aggiornamenti software"])},"tech-blog":e=>{const{normalize:i}=e;return i(["Blog tecnico"])}},clip_as_service:{description:e=>{const{normalize:i}=e;return i(["Incorpora immagini e frasi in vettori di lunghezza fissa con CLIP"])}},cloud:{description:e=>{const{normalize:i}=e;return i(["Piattaforma di cloud hosting per applicazioni AI multimodali"])}},contact_us_page:{agreement:e=>{const{normalize:i}=e;return i(["Inviando, confermi di accettare il trattamento dei tuoi dati personali da parte di Jina AI come descritto nell'"])},anything_else:e=>{const{normalize:i}=e;return i(["Raccontaci di pi\xF9 sul tuo progetto"])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},company_size:e=>{const{normalize:i}=e;return i(["Dimensione aziendale"])},company_website:e=>{const{normalize:i}=e;return i(["Sito web aziendale"])},company_website_placeholder:e=>{const{normalize:i}=e;return i(["URL della home page o del profilo LinkedIn della tua azienda"])},country:e=>{const{normalize:i}=e;return i(["Paese"])},department:e=>{const{normalize:i}=e;return i(["Dipartimento"])},description:e=>{const{normalize:i}=e;return i(["Fai crescere la tua attivit\xE0 con Jina AI."])},faq:e=>{const{normalize:i}=e;return i(["FAQ"])},field_required:e=>{const{normalize:i}=e;return i(["Il campo \xE8 obbligatiorio"])},impact_snapshots:e=>{const{normalize:i}=e;return i(["Istantanee di impatto"])},invalid_date_format:e=>{const{normalize:i}=e;return i(["Formato data non valido. Utilizza il formato GG-MM-AAAA."])},invalid_email:e=>{const{normalize:i}=e;return i(["L'email non \xE8 valida"])},invalid_number:e=>{const{normalize:i}=e;return i(["Numero non valido. Si prega di inserire di nuovo"])},invalid_url:e=>{const{normalize:i}=e;return i(["L'URL non \xE8 valido"])},name:e=>{const{normalize:i}=e;return i(["Nome"])},preferred_products:e=>{const{normalize:i}=e;return i(["A quali prodotti sei interessato?"])},private_statement:e=>{const{normalize:i}=e;return i(["Informativa sulla Privacy"])},role:e=>{const{normalize:i}=e;return i(["Ruolo"])},submit:e=>{const{normalize:i}=e;return i(["Invia"])},submit_failed:e=>{const{normalize:i}=e;return i(["Invio non riuscito. Per favore riprova pi\xF9 tardi."])},submit_success:e=>{const{normalize:i}=e;return i(["Grazie per la vostra presentazione. Vi risponderemo al pi\xF9 presto."])},subtitle:e=>{const{normalize:i}=e;return i(["Jina AI, leader nell'IA multimodale, eccelle nell'ottimizzazione dei modelli, nel servizio dei modelli, nella messa a punto rapida e nel servizio rapido. Sfruttando le tecnologie native del cloud come Kubernetes e le architetture serverless, forniamo soluzioni robuste, scalabili e pronte per la produzione. Con esperienza in modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione audio, ricerca neurale e arte generativa, forniamo strategie innovative e a prova di futuro per elevare la tua attivit\xE0."])},subtitle1:e=>{const{normalize:i}=e;return i(["Jina AI, leader nell'intelligenza artificiale multimodale, eccelle nell'ottimizzazione dell'incorporamento, dell'incorporamento, dell'ottimizzazione e del servizio tempestivo. Sfruttando tecnologie native del cloud come Kubernetes e architetture serverless, forniamo soluzioni robuste, scalabili e pronte per la produzione. Con esperienza in modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione dell'audio, ricerca neurale e intelligenza artificiale generativa, forniamo strategie innovative e a prova di futuro per far crescere il tuo business."])},subtitle2:e=>{const{normalize:i}=e;return i(["Esplora Jina AI, l'avanguardia dell'IA multimodale. Eccelliamo nell'incorporamento e nell'immediatezza delle tecnologie, utilizzando soluzioni native del cloud come Kubernetes per sistemi robusti e scalabili. Specializzati in modelli linguistici di grandi dimensioni e nell'elaborazione dei media, offriamo strategie aziendali innovative e pronte per il futuro con la nostra competenza avanzata in materia di intelligenza artificiale."])},title:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},trusted_by:e=>{const{normalize:i}=e;return i(["Scelto da"])},work_email:e=>{const{normalize:i}=e;return i(["E-mail di lavoro"])}},copy:e=>{const{normalize:i}=e;return i(["copia"])},copy_to_clipboard_success:e=>{const{normalize:i}=e;return i(["Copiato negli appunti"])},dalle_flow:{description:e=>{const{normalize:i}=e;return i(["Un flusso di lavoro human-in-the-Loop per la creazione di immagini HD dal testo"])}},"dev-gpt":{description:e=>{const{normalize:i}=e;return i(["Il tuo team di sviluppo virtuale"])}},disco_art:{description:e=>{const{normalize:i}=e;return i(["Crea avvincenti opere d'arte Disco Diffusion in una riga di codice"])}},doc_array:{description:e=>{const{normalize:i}=e;return i(["La struttura dei dati per i dati multimodali"])}},embedding:{"11B tokens":e=>{const{normalize:i}=e;return i(["11 miliardi"])},"11B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Simile alla lettura di tutti gli articoli in lingua inglese su Wikipedia."])},"11B tokens_targetUser":e=>{const{normalize:i}=e;return i(["Distribuzione della produzione"])},"1B tokens":e=>{const{normalize:i}=e;return i(["1 miliardo"])},"1B tokens_intuition1":e=>{const{normalize:i}=e;return i([`Pi\xF9 o meno come leggere l'opera completa di Shakespeare e l'intera serie "Harry Potter".`])},"1B tokens_targetUser":e=>{const{normalize:i}=e;return i(["Sviluppo del prototipo"])},"1M tokens":e=>{const{normalize:i}=e;return i(["1 milione"])},"1M tokens_intuition1":e=>{const{normalize:i}=e;return i([`Equivale a leggere l'intero testo de "Lo Hobbit" e "Il Grande Gatsby".`])},"1M tokens_targetUser":e=>{const{normalize:i}=e;return i(["Esperimento di giocattoli"])},"1M_free":e=>{const{normalize:i}=e;return i(["1 milione di token gratuiti"])},"1M_free_description":e=>{const{normalize:i}=e;return i(["Goditi i token gratuiti nella tua nuova chiave API, senza bisogno di carta di credito."])},"2_5B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 2,5 miliardi"])},"2_5B tokens_intuition1":e=>{const{normalize:i}=e;return i([`Paragonabile a trascrivere 1.000 volte ogni parola pronunciata nella trilogia del film "Il Signore degli Anelli".
`])},"3p_integration":e=>{const{normalize:i}=e;return i(["Con servizio di terze parti"])},"3p_integration_desc":e=>{const{normalize:i}=e;return i(["Integra la nostra base di ricerca con i tuoi servizi esistenti. I nostri partner hanno creato connettori per la nostra API, semplificando l'utilizzo dei nostri modelli nelle tue applicazioni."])},"500M tokens":e=>{const{normalize:i}=e;return i(["500 milioni di gettoni"])},"500M tokens_intuition1":e=>{const{normalize:i}=e;return i(['\xC8 simile a guardare ogni episodio di "I Simpson" dalla stagione 1 alla stagione 30.'])},"59B tokens":e=>{const{normalize:i}=e;return i(["59 miliardi di gettoni"])},"59B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Uguale a tutti i tweet pubblicati in tutto il mondo in un periodo di due giorni."])},"5_5B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 5,5 miliardi"])},"5_5B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Equivale a leggere l'intero testo dell'Enciclopedia Britannica."])},Free1M:e=>{const{normalize:i}=e;return i(["Gettoni da 1 milione"])},add_pair:e=>{const{normalize:i}=e;return i(["Nuovo"])},api_integration_short:e=>{const{normalize:i}=e;return i(["La nostra API di incorporamento \xE8 integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps."])},api_integrations:e=>{const{normalize:i}=e;return i(["Integrazioni API"])},auto_recharge:e=>{const{normalize:i}=e;return i(["Ricarica automatica quando i gettoni sono bassi"])},auto_recharge_description:e=>{const{normalize:i}=e;return i(["Consigliato per un servizio ininterrotto in produzione. Quando il saldo del tuo token \xE8 inferiore alla soglia impostata, ricaricheremo automaticamente la tua carta di credito per lo stesso importo dell'ultima ricarica. Se hai acquistato pi\xF9 pacchetti nell'ultima ricarica, ricaricheremo solo un pacchetto."])},autostart:e=>{const{normalize:i}=e;return i(["L'incorporamento verr\xE0 avviato automaticamente dopo un breve ritardo"])},base64_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti vengono restituiti come stringa con codifica base64. Pi\xF9 efficiente per la trasmissione."])},batch_job:e=>{const{normalize:i}=e;return i(["Lavoro in batch"])},batch_upload_hint:e=>{const{normalize:i}=e;return i(["Utilizzeremo la chiave API e il modello seguente per elaborare i documenti."])},"bge-base-en-v1_5_description":e=>{const{normalize:i}=e;return i(["Un robusto modello inglese che bilancia prestazioni ed efficienza per un utilizzo versatile."])},"bge-base-en_description":e=>{const{normalize:i}=e;return i(["Un modello inglese equilibrato progettato per prestazioni solide e affidabili."])},"bge-base-zh-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello cinese a tutto tondo che bilancia capacit\xE0 ed efficienza."])},"bge-base-zh_description":e=>{const{normalize:i}=e;return i(["Un modello cinese versatile che unisce efficienza e prestazioni robuste."])},"bge-large-en-v1_5_description":e=>{const{normalize:i}=e;return i(["Un potente modello inglese che offre incastri di alto livello con una qualit\xE0 eccezionale."])},"bge-large-en_description":e=>{const{normalize:i}=e;return i(["Un modello inglese dalle prestazioni elevate, realizzato per incorporamenti di alta qualit\xE0."])},"bge-large-zh-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello cinese ad alta capacit\xE0 che offre incorporamenti superiori e dettagliati."])},"bge-large-zh_description":e=>{const{normalize:i}=e;return i(["Un modello cinese ad alte prestazioni ottimizzato per incorporamenti di alto livello."])},"bge-m3_description":e=>{const{normalize:i}=e;return i(["Un modello multilingue versatile che offre funzionalit\xE0 estese e incorporamenti di alta qualit\xE0."])},"bge-small-en-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello inglese semplificato che offre incorporamenti efficienti e di alta qualit\xE0."])},"bge-small-en_description":e=>{const{normalize:i}=e;return i(["Un modello inglese efficiente per incorporamenti snelli e accurati."])},"bge-small-zh-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello cinese compatto che fornisce incorporamenti agili e precisi."])},"bge-small-zh_description":e=>{const{normalize:i}=e;return i(["Un modello cinese agile per incorporamenti efficienti e precisi."])},binary_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti sono impacchettati come int8. Molto pi\xF9 efficiente per l'archiviazione, la ricerca e la trasmissione."])},bulk:e=>{const{normalize:i}=e;return i(["Incorporamento batch"])},bulk_embedding_failed:e=>{const{normalize:i}=e;return i(["Impossibile creare il processo di incorporamento batch"])},buy_more_quota:e=>{const{normalize:i}=e;return i(["Ricarica questa chiave API con pi\xF9 token"])},buy_poster:e=>{const{normalize:i}=e;return i(["Acquista una copia cartacea"])},cancel_button:e=>{const{normalize:i}=e;return i(["Annulla"])},click_upload_btn_above:e=>{const{normalize:i}=e;return i(["Fai clic sul pulsante di caricamento in alto per iniziare."])},code:e=>{const{normalize:i}=e;return i(["codice"])},cosine_similarity:e=>{const{normalize:i}=e;return i(["Somiglianza del coseno"])},debugging:e=>{const{normalize:i}=e;return i(["Test"])},delete_pair:e=>{const{normalize:i}=e;return i(["Eliminare"])},description:e=>{const{normalize:i,linked:n,type:o}=e;return i([n("landing_page.embedding_desc1",void 0,o)])},document:e=>{const{normalize:i}=e;return i(["Documento"])},download:e=>{const{normalize:i}=e;return i(["Scaricamento"])},edit_text1_text:e=>{const{normalize:i}=e;return i(["Modifica il testo a sinistra"])},edit_text2_text:e=>{const{normalize:i}=e;return i(["Modifica il testo corretto"])},embedding_done:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_Count"))," documenti incorporati correttamente."])},embedding_none_description:e=>{const{normalize:i}=e;return i(["Non utilizzare alcun modello di incorporamento"])},example_inputs:e=>{const{normalize:i}=e;return i(["Ingressi di esempio"])},faq:e=>{const{normalize:i,linked:n,type:o}=e;return i([n("contattaci_pagina.faq",void 0,o)])},faqs_v2:{answer0:e=>{const{normalize:i}=e;return i(["Per informazioni dettagliate sui nostri processi di formazione, fonti di dati e valutazioni, fare riferimento al nostro rapporto tecnico disponibile su arXiv."])},answer1:e=>{const{normalize:i}=e;return i(["Ogni utente pu\xF2 effettuare fino a 100 richieste al secondo, pari a 204.800 frasi di input al secondo."])},answer17:e=>{const{normalize:i}=e;return i(["Attualmente stiamo sviluppando incorporamenti multimodali che elaboreranno congiuntamente testo, immagini e audio. Gli aggiornamenti saranno annunciati presto!"])},answer18:e=>{const{normalize:i}=e;return i(["Per domande sulla messa a punto dei nostri modelli con dati specifici, contattaci per discutere le tue esigenze. Siamo aperti a esplorare come i nostri modelli possono essere adattati per soddisfare le vostre esigenze."])},answer19:e=>{const{normalize:i}=e;return i(["S\xEC, i nostri servizi sono disponibili sul marketplace AWS e siamo in fase di espansione sui marketplace Azure e GCP. Se hai esigenze particolari, contattaci all'ufficio vendite AT jina.ai."])},answer3:e=>{const{normalize:i}=e;return i(["I nostri modelli supportano inglese, tedesco, spagnolo, cinese e vari linguaggi di programmazione. Per maggiori dettagli si rimanda alla nostra pubblicazione sui modelli bilingui."])},answer4:e=>{const{normalize:i}=e;return i([`I nostri modelli consentono una lunghezza di input fino a 8192 token, che \xE8 significativamente pi\xF9 alta rispetto alla maggior parte degli altri modelli. Un token pu\xF2 variare da un singolo carattere, come "a", a un'intera parola, come "mela". Il numero totale di caratteri che possono essere immessi dipende dalla lunghezza e dalla complessit\xE0 delle parole utilizzate. Questa funzionalit\xE0 di input estesa consente ai nostri modelli jina-embeddings-v2 di eseguire analisi del testo pi\xF9 complete e ottenere una maggiore precisione nella comprensione del contesto, in particolare per dati testuali estesi.`])},answer5:e=>{const{normalize:i}=e;return i(["Una singola chiamata API pu\xF2 elaborare fino a 2048 frasi o testi, facilitando un'analisi approfondita del testo in un'unica richiesta."])},answer6:e=>{const{normalize:i}=e;return i(["Puoi utilizzare <code>url</code> o <code>bytes</code> nel campo <code>input</code> della richiesta API. Per <code>url</code>, fornisci l'URL dell'immagine che desideri elaborare. Per <code>bytes</code>, codifica l'immagine in formato base64 e includila nella richiesta. Il modello restituir\xE0 gli incorporamenti dell'immagine nella risposta."])},answer7:e=>{const{normalize:i}=e;return i(["Secondo la classifica MTEB, il nostro modello Base compete strettamente con il text-embedding-ada-002 di OpenAI, mostrando in media prestazioni comparabili. Inoltre, il nostro modello Base eccelle in diversi compiti, tra cui classificazione, classificazione di coppie, riclassificazione e riepilogo, superando il modello di OpenAI."])},answer8:e=>{const{normalize:i}=e;return i(["La transizione \xE8 semplificata, poich\xE9 il nostro endpoint API, https://api.jina.ai/v1/embeddings, corrisponde agli schemi JSON di input e output del modello text-embeddings-ada-002 di OpenAI. Questa compatibilit\xE0 garantisce che gli utenti possano facilmente sostituire il modello OpenAI con il nostro quando utilizzano l'endpoint OpenAI."])},answer9:e=>{const{normalize:i}=e;return i([`I token vengono calcolati in base alla lunghezza del testo e alla dimensione dell'immagine. Per il testo nella richiesta, i token vengono conteggiati in modo standard. Per l'immagine nella richiesta, vengono eseguiti i seguenti passaggi:
1. Dimensione tessera: ogni immagine \xE8 divisa in tessere di dimensione 224x224 pixel.
	2. Copertura: viene calcolato il numero di tessere necessarie per coprire completamente l'immagine in ingresso. Anche se le dimensioni dell'immagine non sono perfettamente divisibili per 224, conteremo le tessere parziali come tessere intere.
	3. Tessere totali: il numero totale di tessere che coprono l'immagine determina il costo. Ad esempio, se un'immagine \xE8 500x500 pixel, sarebbe coperta da riquadri 3x3, risultando in 9 riquadri.
	4. Calcolo del costo: Ogni tessera contribuisce al costo finale dell'elaborazione dell'immagine. Il costo per tessera \xE8 di 1000 gettoni.

Esempio:
Per un'immagine con dimensioni 500x500 pixel:

	\u2022 L'immagine \xE8 divisa in riquadri da 224x224 pixel.
	\u2022 Il numero totale di tessere richieste \xE8 3 (orizzontale) x 3 (verticale) = 9 tessere.
	\u2022 Il costo sar\xE0 9*1000 = 9000 token`])},question0:e=>{const{normalize:i}=e;return i(["Come sono stati addestrati i modelli jina-embeddings-v2?"])},question1:e=>{const{normalize:i}=e;return i(["Quante richieste API posso effettuare al secondo?"])},question17:e=>{const{normalize:i}=e;return i(["Fornite modelli per incorporare immagini o audio?"])},question18:e=>{const{normalize:i}=e;return i(["I modelli Jina Embedding possono essere ottimizzati con dati privati \u200B\u200Bo aziendali?"])},question19:e=>{const{normalize:i}=e;return i(["I tuoi endpoint possono essere ospitati privatamente su AWS, Azure o GCP?"])},question3:e=>{const{normalize:i}=e;return i(["Quali lingue supportano i vostri modelli?"])},question4:e=>{const{normalize:i}=e;return i(["Qual \xE8 la lunghezza massima per una singola frase inserita?"])},question5:e=>{const{normalize:i}=e;return i(["Qual \xE8 il numero massimo di frasi che posso includere in una singola richiesta?"])},question6:e=>{const{normalize:i}=e;return i(["Come posso inviare immagini al modello jina-clip-v1?"])},question7:e=>{const{normalize:i}=e;return i(["Come si confrontano i modelli Jina Embeddings con il modello text-embedding-ada-002 di OpenAI?"])},question8:e=>{const{normalize:i}=e;return i(["Quanto \xE8 fluida la transizione da text-embedding-ada-002 di OpenAI alla tua soluzione?"])},question9:e=>{const{normalize:i}=e;return i(["Come vengono calcolati i token quando si utilizza jina-clip-v1?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative agli incorporamenti"])}},feature_8k1:e=>{const{normalize:i}=e;return i(["8192 lunghezza del token"])},feature_8k_description1:e=>{const{normalize:i}=e;return i(["Pioniere del primo modello di incorporamento open source con una lunghezza di 8192 token, che consente la rappresentazione di un intero capitolo in un unico vettore."])},feature_cheap:e=>{const{normalize:i}=e;return i(["20 volte pi\xF9 economico"])},feature_cheap_v1:e=>{const{normalize:i}=e;return i(["5 volte pi\xF9 economico"])},feature_cheap_v1_description1:e=>{const{normalize:i}=e;return i(["Inizia con prove gratuite e goditi una struttura dei prezzi semplice. Ottieni l'accesso a potenti incorporamenti a solo il 20% del costo di OpenAI."])},feature_multilingual:e=>{const{normalize:i}=e;return i(["Offre modelli bilingui tedesco-inglese, cinese-inglese, tra gli altri, ideali per applicazioni multilingue."])},feature_on_premises:e=>{const{normalize:i}=e;return i(["La privacy prima di tutto"])},feature_on_premises_description1:e=>{const{normalize:i}=e;return i(["Distribuisci senza problemi i nostri modelli di incorporamento direttamente nel tuo Virtual Private Cloud (VPC). Attualmente supportato su AWS Sagemaker, con prossime integrazioni per Microsoft Azure e Google Cloud Platform. Per implementazioni Kubernetes personalizzate, contatta il nostro team di vendita per assistenza specializzata."])},feature_on_premises_description2:e=>{const{normalize:i}=e;return i(["Distribuisci i modelli Jina Embeddings in AWS Sagemaker e presto anche in Microsoft Azure e nei servizi cloud di Google, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_on_premises_description3:e=>{const{normalize:i}=e;return i(["Distribuisci i modelli Jina Embeddings in AWS Sagemaker e Microsoft Azure, e presto anche nei servizi Google Cloud, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_on_premises_description4:e=>{const{normalize:i}=e;return i(["Distribuisci modelli Jina Embedding e Reranker in locale utilizzando AWS SageMaker, Microsoft Azure o Google Cloud Services, garantendo che i tuoi dati rimangano saldamente sotto il tuo controllo."])},feature_solid:e=>{const{normalize:i}=e;return i(["Migliore della classe"])},feature_solid_description1:e=>{const{normalize:i}=e;return i(["Sviluppato dalla nostra ricerca accademica all'avanguardia e rigorosamente testato rispetto ai modelli SOTA per garantire prestazioni senza pari."])},feature_top_perform1:e=>{const{normalize:i}=e;return i(["Integrazione senza problemi"])},feature_top_perform_description1:e=>{const{normalize:i}=e;return i(["Pienamente compatibile con l'API di OpenAI. Si integra facilmente con oltre 10 database vettoriali e sistemi RAG per un'esperienza utente fluida."])},file_required:e=>{const{normalize:i}=e;return i(["Il file \xE8 obbligatorio"])},file_size_exceed:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Supera la dimensione massima del file ",n(o("_size"))])},file_type_not_supported:e=>{const{normalize:i}=e;return i(["Tipo di file non supportato"])},fill_example:e=>{const{normalize:i}=e;return i(["Compila l'esempio"])},float_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti vengono restituiti come un elenco di numeri a virgola mobile. Il pi\xF9 comune e facile da usare."])},free:e=>{const{normalize:i}=e;return i(["Gratuito"])},generate_api_key_error:e=>{const{normalize:i}=e;return i(["La generazione della chiave API non \xE8 riuscita."])},generating_visualization:e=>{const{normalize:i}=e;return i(["Generazione della visualizzazione..."])},get_new_key_button:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave"])},get_new_key_button_explain:e=>{const{normalize:i}=e;return i(["La scelta di una nuova chiave comporter\xE0 la perdita della cronologia di utilizzo associata alla vecchia chiave."])},get_new_key_survey:e=>{const{normalize:i}=e;return i(["Compila il sondaggio, aiutaci a comprendere il tuo utilizzo e ottieni una nuova chiave API gratuitamente!"])},includes:e=>{const{normalize:i}=e;return i(["Gettoni validi per:"])},index_and_search:e=>{const{normalize:i}=e;return i(["Indicizza e cerca"])},index_and_search1:e=>{const{normalize:i}=e;return i(["Indicizza e cerca"])},input:e=>{const{normalize:i}=e;return i(["Richiesta"])},input_api_key_error1:e=>{const{normalize:i}=e;return i(["La tua chiave API non \xE8 valida!"])},input_length:e=>{const{normalize:i}=e;return i(["Lunghezza immessa"])},input_type:e=>{const{normalize:i}=e;return i(["Incorpora come query o documento"])},input_type_explain:e=>{const{normalize:i}=e;return i(["Alcuni modelli di incorporamento dispongono di strategie di incorporamento dedicate per query e documenti. La stessa stringa pu\xF2 essere incorporata come query o documento a seconda del suo ruolo nell'applicazione."])},integrate:e=>{const{normalize:i}=e;return i(["Integrare"])},"jina-clip-v1_description":e=>{const{normalize:i}=e;return i(["I nostri ultimi incorporamenti multimodali per il recupero di testo e immagini."])},"jina-colbert-v1-en_description":e=>{const{normalize:i}=e;return i(["ColBERT migliorato con token di lunghezza 8K per attivit\xE0 di incorporamento e riclassificazione"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:i}=e;return i(["Ottimizzato per la ricerca di codici e stringhe di documenti"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue tedesco-inglese con prestazioni SOTA"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:i}=e;return i(["Alla pari con text-embedding-ada002 di OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue spagnolo-inglese con prestazioni SOTA"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue cinese-inglese con prestazioni SOTA"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:i}=e;return i(["Ottimizzato per bassa latenza e ingombro di memoria"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:i}=e;return i(["Il nostro primo modello di riclassificazione che massimizza la ricerca e la pertinenza RAG"])},"jina-reranker-v1-tiny-en_description":e=>{const{normalize:i}=e;return i(["Il modello di riclassificazione pi\xF9 veloce, pi\xF9 adatto per classificare in modo affidabile un gran numero di documenti"])},"jina-reranker-v1-turbo-en_description":e=>{const{normalize:i}=e;return i(["La migliore combinazione di elevata velocit\xE0 di inferenza e punteggi di pertinenza accurati"])},"jina-reranker-v2-base-multilingual_description":e=>{const{normalize:i}=e;return i(["L'ultimo e migliore modello di riclassificazione con supporto multilingue, chiamata di funzioni e ricerca di codice."])},key:e=>{const{normalize:i}=e;return i(["Chiave API"])},key_enter_placeholder:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API"])},key_enter_placeholder_to_topup:e=>{const{normalize:i}=e;return i(["Inserisci la chiave API che desideri ricaricare"])},key_to_top_up:e=>{const{normalize:i}=e;return i(["Hai gi\xE0 una chiave? Mettilo qui per ricaricarlo"])},key_warn:e=>{const{normalize:i}=e;return i(["Assicurati di conservare la chiave API in un luogo sicuro. Altrimenti dovrai generare una nuova chiave"])},key_warn_v2:e=>{const{normalize:i}=e;return i(["Assicurati di conservare la chiave API in un luogo sicuro!"])},language_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Questo modello supporta al meglio la lingua ",n(o("_lingual")),"."])},last_7_days:e=>{const{normalize:i}=e;return i(["Utilizzo negli ultimi 7 giorni"])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di pi\xF9"])},learn_poster:e=>{const{normalize:i}=e;return i(["Scopri come l'abbiamo realizzato"])},learning1:e=>{const{normalize:i}=e;return i(["Conoscere gli incorporamenti"])},learning1_description:e=>{const{normalize:i}=e;return i(["Da dove cominciare con gli incorporamenti? Ti abbiamo coperto. Scopri di pi\xF9 sugli incorporamenti con la nostra guida completa."])},length:e=>{const{normalize:i}=e;return i(["Lunghezza del token"])},manage_billing:e=>{const{normalize:i}=e;return i(["Gestisci la fattura"])},manage_billing_tip:e=>{const{normalize:i}=e;return i(["Gestisci i tuoi dati di fatturazione, ricevi fatture e imposta la ricarica automatica."])},manage_quota1:e=>{const{normalize:i}=e;return i(["Chiave API e fatturazione"])},max_file_size:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Dimensione massima consentita: ",n(o("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:i}=e;return i(["Ingrandisci questo pannello"])},model_required:e=>{const{normalize:i}=e;return i(["Il modello \xE8 obbligatorio"])},more_than_two2:e=>{const{normalize:i}=e;return i(["Inserisci pi\xF9 di due documenti, ovvero pi\xF9 di due righe."])},multi_embedding:e=>{const{normalize:i}=e;return i(["Multivettore"])},multi_embedding_explain:e=>{const{normalize:i}=e;return i(["Questo modello restituir\xE0 un pacchetto di incorporamenti contestualizzati per un dato input. Ogni token nell'input viene mappato su un vettore nell'output."])},multilingual:e=>{const{normalize:i}=e;return i(["Supporto multilingue"])},multimodal:e=>{const{normalize:i}=e;return i(["Multimodale"])},multimodal_explain:e=>{const{normalize:i}=e;return i(["Questo modello pu\xF2 codificare input sia di testo che di immagini, rendendolo ideale per attivit\xE0 di ricerca multimodale."])},new:e=>{const{normalize:i}=e;return i(["Nuovo modello"])},no_data1:e=>{const{normalize:i}=e;return i(["Aggiungi un paio di frasi per calcolare la somiglianza"])},none:e=>{const{normalize:i}=e;return i(["Nessuno"])},onprem:e=>{const{normalize:i}=e;return i(["In sede"])},open_tensorboard:e=>{const{normalize:i}=e;return i(["Apri visualizzatore"])},opensource:e=>{const{normalize:i}=e;return i(["sistema operativo"])},opensource_explain:e=>{const{normalize:i}=e;return i(["Questo modello \xE8 open source e disponibile su Hugging Face. Fare clic su questo pulsante per visualizzare il modello su Hugging Face."])},original_documents:e=>{const{normalize:i}=e;return i(["Documenti per l'incorporamento"])},original_documents_hint:e=>{const{normalize:i}=e;return i(["Inserisci qui i tuoi documenti. Ogni nuova riga sar\xE0 considerata un documento separato."])},output:e=>{const{normalize:i}=e;return i(["Risposta"])},output_dim:e=>{const{normalize:i}=e;return i(["Dimensioni"])},output_dim_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["La dimensione di output di un vettore di incorporamento da questo modello \xE8 ",n(o("_outputDim")),"."])},output_dimension:e=>{const{normalize:i}=e;return i(["Dimensioni di uscita"])},pairwise_test:e=>{const{normalize:i}=e;return i(["A coppie"])},per_k:e=>{const{normalize:i}=e;return i(["/ Gettoni da 1K"])},per_m:e=>{const{normalize:i}=e;return i(["/1 milione di gettoni"])},please_fill_docs_first:e=>{const{normalize:i}=e;return i(["Inserisci alcuni documenti qui sotto prima della ricerca."])},please_select_model:e=>{const{normalize:i}=e;return i(["Seleziona un modello di incorporamento o un modello di riclassificazione"])},poster:e=>{const{normalize:i}=e;return i(["Poster L'evoluzione degli incorporamenti"])},poster_description:e=>{const{normalize:i}=e;return i(["Scopri il poster ideale per il tuo spazio, con infografiche accattivanti o immagini mozzafiato che tracciano l'evoluzione dei modelli di incorporamento del testo dal 1950."])},pricing:e=>{const{normalize:i}=e;return i(["Prezzi dell'API"])},pricing_desc:e=>{const{normalize:i}=e;return i(["I nostri prezzi API sono strutturati in base alla quantit\xE0 di token inviati nelle richieste. Per l'API Reader, \xE8 la quantit\xE0 di token nelle risposte. Questo modello di prezzo \xE8 applicabile a tutti i prodotti nella base di ricerca di Jina AI: API di incorporamento, riclassificazione, lettore e ottimizzazione automatica. Con la stessa chiave API hai accesso a tutti i servizi API."])},protectData1:e=>{const{normalize:i}=e;return i(["I dati e i documenti della richiesta non vengono utilizzati per i modelli di training."])},protectData2:e=>{const{normalize:i}=e;return i(["Crittografia dei dati in transito (TLS 1.2+) e a riposo (AES-GCM 256)."])},protectData3:e=>{const{normalize:i}=e;return i(["Conforme a SOC 2 e GDPR."])},protect_data:e=>{const{normalize:i}=e;return i(["Proteggi i tuoi dati"])},public_cloud_integration:e=>{const{normalize:i}=e;return i(["Con il fornitore di servizi cloud"])},public_cloud_integration_desc:e=>{const{normalize:i}=e;return i(["La tua azienda utilizza AWS o Azure? Quindi distribuisci direttamente i nostri modelli di base di ricerca su queste piattaforme nella tua azienda, in modo che i tuoi dati rimangano sicuri e conformi."])},query:e=>{const{normalize:i}=e;return i(["Domanda"])},rank_none_description:e=>{const{normalize:i}=e;return i(["Non utilizzare alcun modello di riclassificazione"])},read_api_docs:e=>{const{normalize:i}=e;return i(["Leggi i documenti"])},recharge_threshold:e=>{const{normalize:i}=e;return i(["Soglia di ricarica"])},refresh:e=>{const{normalize:i}=e;return i(["ricaricare"])},refresh_key_tooltip1:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave API gratuitamente"])},refresh_token_count1:e=>{const{normalize:i}=e;return i(["Aggiorna per ottenere i token disponibili della chiave API corrente"])},regenerate:e=>{const{normalize:i}=e;return i(["Rigenerare"])},remaining:e=>{const{normalize:i}=e;return i(["Gettoni disponibili"])},remaining_left:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Hai <b>",n(o("_leftTokens")),"</b> token rimasti nella chiave API di seguito."])},results_as_final_result:e=>{const{normalize:i}=e;return i(["#docs come risultato finale"])},results_fed_to_reranker:e=>{const{normalize:i}=e;return i(["#documenti alimentati a Reranker"])},retry:e=>{const{normalize:i}=e;return i(["Riprova"])},return_base64:e=>{const{normalize:i}=e;return i(["Base64 (come stringa)"])},return_binary:e=>{const{normalize:i}=e;return i(["Binario (compresso come int8)"])},return_float:e=>{const{normalize:i}=e;return i(["Predefinito (come float)"])},return_format:e=>{const{normalize:i}=e;return i(["Formato degli incorporamenti"])},return_format_explain:e=>{const{normalize:i}=e;return i(["Oltre al float, puoi chiedergli di restituire come binario per un recupero vettoriale pi\xF9 veloce o come codifica base64 per una trasmissione pi\xF9 veloce."])},return_format_title:e=>{const{normalize:i}=e;return i(["Tipo di dati restituito"])},return_ubinary:e=>{const{normalize:i}=e;return i(["Binario (compresso come uint8)"])},right_api_key_to_charge:e=>{const{normalize:i}=e;return i(["Inserisci la chiave API corretta per ricaricare"])},running:e=>{const{normalize:i}=e;return i(["Attivo"])},score:e=>{const{normalize:i}=e;return i(["Punto"])},search:e=>{const{normalize:i}=e;return i(["Ricerca"])},search_hint:e=>{const{normalize:i}=e;return i(["Digita per effettuare la ricerca tra i documenti elencati di seguito"])},select_embedding_model:e=>{const{normalize:i}=e;return i(["Seleziona incorporamenti"])},select_rerank_model:e=>{const{normalize:i}=e;return i(["Seleziona riclassificazione"])},show_api_key:e=>{const{normalize:i}=e;return i(["Mostra chiave API"])},size:e=>{const{normalize:i}=e;return i(["Parametri"])},size_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Il numero di parametri nel modello \xE8 ",n(o("_size")),", tieni presente che questa non \xE8 la dimensione del file del modello."])},sleeping:e=>{const{normalize:i}=e;return i(["Inattivo"])},start_batch:e=>{const{normalize:i}=e;return i(["Avvia l'incorporamento batch"])},start_embedding:e=>{const{normalize:i}=e;return i(["Indice"])},status_explain:e=>{const{normalize:i}=e;return i(["La nostra architettura serverless potrebbe scaricare alcuni modelli durante i periodi di scarso utilizzo. Per i modelli attivi, le risposte sono immediate. I modelli inattivi richiedono alcuni secondi per essere caricati alla richiesta iniziale. Dopo l'attivazione, le richieste successive vengono elaborate pi\xF9 rapidamente."])},tax_may_apply:e=>{const{normalize:i}=e;return i(["A seconda della tua posizione, l'addebito potrebbe essere effettuato in USD, EUR o altre valute. Potrebbero essere applicate tasse."])},text1:e=>{const{normalize:i}=e;return i(["Sinistra"])},text2:e=>{const{normalize:i}=e;return i(["Giusto"])},title:e=>{const{normalize:i}=e;return i(["Incorporamento dell'API"])},token_example:e=>{const{normalize:i}=e;return i(['Un tweet \xE8 di circa 20 token, un articolo di notizie \xE8 di circa 1000 token e il romanzo di Charles Dickens "A Tale of Two Cities" ha oltre un milione di token.'])},token_length_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["La lunghezza massima della sequenza del token di input \xE8 ",n(o("_tokenLength"))," per questo modello."])},tokens:e=>{const{normalize:i}=e;return i(["Gettoni"])},top_up_button:e=>{const{normalize:i}=e;return i(["Ricarica la vecchia chiave"])},top_up_button_explain:e=>{const{normalize:i}=e;return i(["L'integrazione di questa chiave API offre una soluzione pi\xF9 professionale, eliminando la necessit\xE0 di frequenti modifiche della chiave. I dati di utilizzo vengono conservati e accessibili in qualsiasi momento."])},top_up_warning_message1:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Alla chiave API corrente sono rimasti token ",n(o("_remainedTokens"))," e verr\xE0 sostituita da una nuova chiave con token ",n(o("_freeTokens")),". Puoi continuare a utilizzare o ricaricare la vecchia chiave se l'hai conservata in modo sicuro. Come vuoi procedere?"])},top_up_warning_title:e=>{const{normalize:i}=e;return i(["Sostituisci la vecchia chiave API"])},total_documents:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Avanzamento incorporamento: ",n(o("_Processed")),"/",n(o("_Count"))," documenti."])},tuning:e=>{const{normalize:i}=e;return i(["Sintonizzare"])},ubinary_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti sono impacchettati come uint8. Molto pi\xF9 efficiente per l'archiviazione, la ricerca e la trasmissione."])},upload:e=>{const{normalize:i}=e;return i(["Caricamento"])},upload_file:e=>{const{normalize:i}=e;return i(["Fare clic qui per caricare un file"])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},usage_amount:e=>{const{normalize:i}=e;return i(["Gettoni"])},usage_history:e=>{const{normalize:i}=e;return i(["Utilizzo negli ultimi 7 giorni"])},usage_history_explain:e=>{const{normalize:i}=e;return i(["I dati non sono in tempo reale e possono subire ritardi di alcuni minuti."])},usage_reason:e=>{const{normalize:i}=e;return i(["Descrizione"])},usage_reason_consume:e=>{const{normalize:i}=e;return i(["Usato"])},usage_reason_purchase:e=>{const{normalize:i}=e;return i(["Acquistato"])},usage_reason_trial:e=>{const{normalize:i}=e;return i(["Prova"])},usage_rerank:e=>{const{normalize:i}=e;return i(["Utilizzo"])},usage_time:e=>{const{normalize:i}=e;return i(["Appuntamento"])},vector_database_integration1:e=>{const{normalize:i}=e;return i(["Integrazioni"])},vector_database_integration2:e=>{const{normalize:i}=e;return i(["La nostra API di incorporamento \xE8 integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps. Per iniziare, copia e incolla la tua chiave API in una qualsiasi delle integrazioni elencate per un avvio rapido e senza intoppi."])},vector_database_integration3:e=>{const{normalize:i}=e;return i(["La nostra API Embedding & Reranker \xE8 integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps. Per iniziare, copia e incolla la tua chiave API in una qualsiasi delle integrazioni elencate per un avvio rapido e senza intoppi."])},vector_database_integration_description:e=>{const{normalize:i}=e;return i(["Integra in modo semplice e senza soluzione di continuit\xE0 l'API Jina Embeddings con qualsiasi database vettoriale, framework di orchestrazione LLM e applicazioni RAG riportati di seguito. I nostri tutorial ti mostreranno come."])},view_details:e=>{const{normalize:i}=e;return i(["Visualizza dettagli"])},visualization_example:e=>{const{normalize:i}=e;return i(["Mappare tutte le frasi di questa sezione in uno spazio vettoriale 3D"])},visualization_example_you_can:e=>{const{normalize:i}=e;return i(["Utilizza la nostra API qui sotto, puoi farlo anche tu!"])},visualize:e=>{const{normalize:i}=e;return i(["Visualizzare"])},visualize_done:e=>{const{normalize:i}=e;return i(["La visualizzazione \xE8 terminata, ora puoi fare clic sul pulsante in alto per aprire il visualizzatore."])},wait_for_processing:e=>{const{normalize:i}=e;return i(["La tua richiesta sta per essere eseguita."])},wait_stripe:e=>{const{normalize:i}=e;return i(["Apertura pagamento Stripe, attendere prego"])},what_are_embedding:e=>{const{normalize:i}=e;return i(["Cosa sono gli incorporamenti?"])},what_are_embedding_answer:e=>{const{normalize:i}=e;return i([`Immagina di insegnare a un computer a cogliere le sfumature dei significati di parole e frasi. I metodi tradizionali, che si basavano su sistemi rigidi e basati su regole, non erano all\u2019altezza perch\xE9 il linguaggio \xE8 troppo complesso e fluido. Inserisci gli incorporamenti di testo: una soluzione potente che traduce il testo in un linguaggio di numeri, in particolare in vettori in uno spazio ad alta dimensione.

Considera le frasi "tempo soleggiato" e "cielo sereno". Per noi dipingono un quadro simile. Attraverso la lente degli incorporamenti, queste frasi vengono trasformate in vettori numerici che risiedono vicini gli uni agli altri in questo spazio multidimensionale, catturandone la parentela semantica. Questa vicinanza nello spazio vettoriale non riguarda solo la somiglianza di parole o frasi; si tratta di comprendere il contesto, il sentimento e persino le sottili sfumature di significato.

Perch\xE9 \xE8 importante questa svolta? Per cominciare, colma il divario tra la ricchezza del linguaggio umano e l\u2019efficienza computazionale degli algoritmi. Gli algoritmi eccellono nell\u2019elaborazione dei numeri, non nell\u2019interpretazione dei testi. Convertendo il testo in vettori, gli incorporamenti consentono a questi algoritmi di "comprendere" ed elaborare il linguaggio in un modo che prima era fuori portata.

Le applicazioni pratiche sono vaste e variegate. Che si tratti di consigliare contenuti che siano in sintonia con i tuoi interessi, di potenziare un'intelligenza artificiale conversazionale che sembri sorprendentemente umana o addirittura di rilevare modelli sottili in grandi volumi di testo, gli incorporamenti sono la chiave. Consentono alle macchine di eseguire attivit\xE0 come l'analisi del sentiment, la traduzione linguistica e molto altro, con una comprensione del linguaggio sempre pi\xF9 sfumata e raffinata.`])},what_is_a_token:e=>{const{normalize:i}=e;return i([`Un token nell'elaborazione del testo \xE8 un'unit\xE0, spesso una parola. Ad esempio, "Jina AI \xE8 fantastica!" diventa cinque gettoni, compresa la punteggiatura.`])},why_do_you_need:e=>{const{normalize:i}=e;return i(["Scegliere gli incorporamenti giusti"])},why_do_you_need_after:e=>{const{normalize:i}=e;return i(["Sfruttando reti neurali profonde e LLM, i nostri modelli di incorporamento rappresentano dati multimodali in un formato semplificato, migliorando la comprensione automatica, l'archiviazione efficiente e consentendo applicazioni IA avanzate. Questi incorporamenti svolgono un ruolo cruciale nella comprensione dei dati, nel miglioramento del coinvolgimento degli utenti, nel superamento delle barriere linguistiche e nell'ottimizzazione dei processi di sviluppo."])},why_do_you_need_before:e=>{const{normalize:i}=e;return i(["I nostri modelli di incorporamento sono progettati per coprire diverse applicazioni di ricerca e GenAI."])},why_need_1_description:e=>{const{normalize:i}=e;return i(["Il nostro modello di incorporamento del core, basato su JinaBERT, \xE8 costruito per un ampio spettro di applicazioni. Eccelle nella comprensione di testi dettagliati, rendendolo ideale per la ricerca semantica, la classificazione dei contenuti e l'analisi linguistica complessa. La sua versatilit\xE0 non ha eguali e supporta la creazione di strumenti avanzati di analisi del sentiment, riepilogo del testo e sistemi di consigli personalizzati."])},why_need_1_title:e=>{const{normalize:i}=e;return i(["Incorporamenti per uso generale"])},why_need_2_description:e=>{const{normalize:i}=e;return i(["I nostri modelli bilingui facilitano la comunicazione tra le lingue, migliorando le piattaforme multilingue, l'assistenza clienti globale e la scoperta di contenuti multilinguistici. Progettati per padroneggiare le traduzioni tedesco-inglese e cinese-inglese, questi modelli semplificano le interazioni e favoriscono la comprensione tra diversi gruppi linguistici."])},why_need_2_title:e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue"])},why_need_3_description:e=>{const{normalize:i}=e;return i(["Progettato su misura per gli sviluppatori, il nostro modello di incorporamento del codice ottimizza le attivit\xE0 di codifica come il riepilogo, la generazione di codice e le revisioni automatiche. Aumenta la produttivit\xE0 offrendo approfondimenti sulle strutture del codice e suggerendo miglioramenti, rendendolo essenziale per lo sviluppo di plug-in IDE avanzati, documentazione automatica e strumenti di debug all'avanguardia."])},why_need_3_title:e=>{const{normalize:i}=e;return i(["Incorporamenti di codice"])},why_need_4_description:e=>{const{normalize:i}=e;return i(["Jina CLIP \xE8 il nostro ultimo modello di incorporamento multimodale per immagini e testo. Un grande miglioramento rispetto a OpenAI CLIP \xE8 che questo singolo modello pu\xF2 essere utilizzato per il recupero di testo-testo, nonch\xE9 per attivit\xE0 di recupero di testo-immagine, immagine-testo e immagine-immagine! Quindi un modello, due modalit\xE0, quattro direzioni di ricerca!"])},why_need_4_title:e=>{const{normalize:i}=e;return i(["Incorporamenti multimodali"])},write_email_here:e=>{const{normalize:i}=e;return i(["Inserisci l'e-mail in cui desideri ricevere il collegamento per il download al termine."])},you_can_leave:e=>{const{normalize:i}=e;return i(["Puoi lasciare questa pagina e al termine ti invieremo il collegamento per il download."])}},embeddings:{description:e=>{const{normalize:i}=e;return i(["I nostri incorporamenti di livello mondiale per sistemi di ricerca, RAG e agenti."])}},faq:{answer1:e=>{const{normalize:i}=e;return i(["Jina AI \xE8 specializzata in tecnologie AI multimodali, tra cui ottimizzazione dei modelli, servizio dei modelli, messa a punto rapida e servizio rapido. Sfruttiamo strumenti avanzati come Kubernetes e architetture serverless per creare soluzioni robuste, scalabili e pronte per la produzione."])},answer10:e=>{const{normalize:i}=e;return i(["Forniamo diverse opzioni di licenza in base alla natura del progetto e alle esigenze del cliente. I termini dettagliati possono essere discussi con il nostro team di vendita."])},answer11:e=>{const{normalize:i}=e;return i(["Forniamo servizi a livello globale, con la nostra sede centrale a Berlino, in Europa, e uffici aggiuntivi a Pechino e Shenzhen."])},answer12:e=>{const{normalize:i}=e;return i(["S\xEC, offriamo assistenza in loco, in particolare per i clienti che si trovano vicino ai nostri uffici di Berlino, Pechino e Shenzhen. Per altre localit\xE0, ci sforziamo di fornire il miglior supporto remoto possibile e, se necessario, possiamo organizzare il supporto in loco."])},answer2:e=>{const{normalize:i}=e;return i(["La nostra esperienza copre un ampio spettro, comprendendo modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione audio, ricerca neurale e arte generativa."])},answer3:e=>{const{normalize:i}=e;return i(["S\xEC, le nostre soluzioni sono progettate per essere scalabili e pronte per la produzione. Costruiamo le nostre soluzioni utilizzando tecnologie cloud-native che consentono una scalabilit\xE0 efficiente e prestazioni affidabili negli ambienti di produzione."])},answer4:e=>{const{normalize:i}=e;return i(["I nostri servizi sono versatili e adattabili, il che li rende adatti a un'ampia gamma di settori, tra cui e-commerce, tecnologia legale, marketing digitale, giochi, assistenza sanitaria, finanza e molti altri."])},answer5:e=>{const{normalize:i}=e;return i(["Puoi metterti in contatto con il nostro team di vendita tramite il modulo di contatto in questa pagina. Ci piacerebbe discutere i requisiti del tuo progetto e come le nostre soluzioni possono aiutare la tua azienda."])},answer6:e=>{const{normalize:i}=e;return i(["Forniamo supporto continuo per garantire il buon funzionamento delle nostre soluzioni. Ci\xF2 include la risoluzione dei problemi, aggiornamenti regolari e miglioramenti in base al tuo feedback e alle tue esigenze."])},answer7:e=>{const{normalize:i}=e;return i(["La durata del progetto varia a seconda della complessit\xE0 e della portata del progetto. Dopo aver compreso le vostre esigenze, possiamo fornire una stima pi\xF9 accurata."])},answer8:e=>{const{normalize:i}=e;return i(["La sicurezza dei dati \xE8 la nostra massima priorit\xE0. Aderiamo a rigide politiche e normative sulla protezione dei dati per garantire che i tuoi dati siano sicuri e riservati."])},answer9:e=>{const{normalize:i}=e;return i(["Il prezzo dipende dalla complessit\xE0 e dai requisiti del progetto. Offriamo sia modelli di prezzi basati su progetto che di trattenuta. Si prega di contattare il nostro team di vendita per ulteriori informazioni."])},question1:e=>{const{normalize:i}=e;return i(["In cosa \xE8 specializzata Jina AI?"])},question10:e=>{const{normalize:i}=e;return i(["Quali sono i termini di licenza per le vostre soluzioni?"])},question11:e=>{const{normalize:i}=e;return i(["Qual \xE8 la tua area di servizio?"])},question12:e=>{const{normalize:i}=e;return i(["Offrite supporto in loco?"])},question2:e=>{const{normalize:i}=e;return i(["Con quali tipi di IA funziona Jina AI?"])},question3:e=>{const{normalize:i}=e;return i(["Le tue soluzioni sono scalabili e pronte per la produzione?"])},question4:e=>{const{normalize:i}=e;return i(["Quali settori possono trarre vantaggio dalle soluzioni di Jina AI?"])},question5:e=>{const{normalize:i}=e;return i(["Come si avvia un progetto con Jina AI?"])},question6:e=>{const{normalize:i}=e;return i(["Quale supporto fornite dopo aver implementato una soluzione?"])},question7:e=>{const{normalize:i}=e;return i(["Qual \xE8 la durata tipica di un progetto?"])},question8:e=>{const{normalize:i}=e;return i(["In che modo Jina AI protegge i miei dati?"])},question9:e=>{const{normalize:i}=e;return i(["Qual \xE8 la struttura dei prezzi per i vostri servizi?"])}},faq_button:e=>{const{normalize:i}=e;return i(["FAQ"])},finetuner:{description:e=>{const{normalize:i}=e;return i(["Ottimizza gli incorporamenti sui dati specifici del dominio per una migliore qualit\xE0 della ricerca"])},intro:e=>{const{normalize:i}=e;return i(["La tua azienda. I tuoi dati. Il tuo modello"])}},finetuner_plus:{description:e=>{const{normalize:i}=e;return i(["Potenzia la tua azienda con soluzioni di fine tuning on-premise"])}},finetuning:{api_key:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API."])},back:e=>{const{normalize:i}=e;return i(["Indietro"])},base_model_selected:e=>{const{normalize:i}=e;return i(["Modello base selezionato"])},click_start:e=>{const{normalize:i}=e;return i(["Accetta i termini e inizia la messa a punto."])},confirm_title:e=>{const{normalize:i}=e;return i(["Conferma il lavoro di regolazione fine"])},confirm_your_email:e=>{const{normalize:i}=e;return i(["Inserisci nuovamente il tuo indirizzo email per confermare il lavoro di perfezionamento. Gli aggiornamenti e il collegamento per il download verranno inviati a questa email."])},consent0:e=>{const{normalize:i}=e;return i(["Accetto che i dati sintetici per la messa a punto del modello vengano generati in base alle mie istruzioni."])},consent1:e=>{const{normalize:i}=e;return i(["Riconosco che il modello finale e i dati sintetici saranno accessibili pubblicamente su Hugging Face."])},consent2:e=>{const{normalize:i}=e;return i(["Comprendo che questa funzionalit\xE0 \xE8 in versione beta e Jina AI non offre garanzie. Il prezzo e l'UX potrebbero cambiare."])},continue:e=>{const{normalize:i}=e;return i(["Continua"])},cost_1m_token:e=>{const{normalize:i}=e;return i(["Ogni lavoro di perfezionamento consuma 1 milione di token. Assicurati di avere gettoni sufficienti o ricarica il tuo saldo. Puoi anche generare una nuova chiave API. Ogni chiave API viene fornita con 1 milione di token gratuiti."])},doc_explain:e=>{const{normalize:i}=e;return i(["Descrivi come dovrebbe apparire un documento abbinato."])},domain_explain:e=>{const{normalize:i}=e;return i(["Fornire una descrizione dettagliata di come verranno utilizzati gli incorporamenti ottimizzati. Ci\xF2 \xE8 essenziale per generare dati sintetici di alta qualit\xE0 che miglioreranno le prestazioni dei tuoi incorporamenti."])},domain_explain2:e=>{const{normalize:i}=e;return i(["Esistono tre modi per specificare le tue esigenze: un'istruzione generale, un URL o una descrizione del documento di query. Scegline uno."])},domain_hint:e=>{const{normalize:i}=e;return i(["Descrivi il dominio per il quale desideri ottimizzare."])},email_not_match:e=>{const{normalize:i}=e;return i(["Gli indirizzi email non combaciano. Si prega di verificare."])},failed_job:e=>{const{normalize:i}=e;return i(["La richiesta di perfezionamento non \xE8 riuscita. Vedi il motivo qui sotto."])},find_on_huggingface:e=>{const{normalize:i}=e;return i(["Trova risultati su Abbracciare il viso"])},general_instruction:e=>{const{normalize:i}=e;return i(["Oppure istruzioni generali"])},general_instruction_caption:e=>{const{normalize:i}=e;return i(["Fornire una descrizione dettagliata di come verranno utilizzati gli incorporamenti ottimizzati."])},general_instruction_explain:e=>{const{normalize:i}=e;return i(['Descrivi il tuo dominio in testo in formato libero. Puoi immaginarlo come un "prompt" come in ChatGPT.'])},how_it_works:e=>{const{normalize:i}=e;return i(["Scopri il processo di perfezionamento."])},job_acknowledged:e=>{const{normalize:i}=e;return i(["Il tuo lavoro di perfezionamento \xE8 stato messo in coda. Riceverai un'e-mail all'inizio del lavoro. Il completamento dell'intero processo richiede spesso 20 minuti."])},new_key:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave"])},not_enough_token:e=>{const{normalize:i}=e;return i(["Token insufficienti in questa chiave API. Ricarica il tuo saldo o utilizza una chiave API diversa."])},placeholder:e=>{const{normalize:i}=e;return i(["Sinistri di assicurazione auto"])},preview:e=>{const{normalize:i}=e;return i(["Anteprima"])},query_doc:e=>{const{normalize:i}=e;return i(["Descrizione del documento di query"])},query_doc_caption:e=>{const{normalize:i}=e;return i(["Descrivi come appare la query e come appare il documento corrispondente nel tuo dominio."])},query_explain:e=>{const{normalize:i}=e;return i(["Descrivi come appare una query."])},reset:e=>{const{normalize:i}=e;return i(["Ricominciare"])},select_base_model:e=>{const{normalize:i}=e;return i(["Scegli un modello di incorporamento di base per la messa a punto."])},select_base_model_explain:e=>{const{normalize:i}=e;return i(["Selezionare un modello base come punto di partenza per la messa a punto. In genere, base-en \xE8 una buona scelta, ma per attivit\xE0 in altre lingue, considera l'utilizzo di un modello bilingue."])},start_tuning:e=>{const{normalize:i}=e;return i(["Inizia la messa a punto"])},url:e=>{const{normalize:i}=e;return i(["Oppure l'URL della pagina web"])},url_caption:e=>{const{normalize:i}=e;return i(["Fare riferimento al contenuto di un URL per la messa a punto."])},url_explain:e=>{const{normalize:i}=e;return i(["URL pubblico di una pagina Web che contiene il contenuto che desideri ottimizzare."])},use_url:e=>{const{normalize:i}=e;return i(["Utilizza invece l'URL. Attivarlo significa che ci baseremo sul contenuto della pagina di quell'URL per generare dati sintetici per la messa a punto."])},wait_for_processing:e=>{const{normalize:i}=e;return i(["Si prega di attendere l'elaborazione della tua richiesta..."])},which_domain:e=>{const{normalize:i}=e;return i(["Dominio di messa a punto"])},write_email_explain:e=>{const{normalize:i}=e;return i(["La messa a punto richiede tempo. Comunicheremo via e-mail l'inizio, l'avanzamento, il completamento e tutti i problemi del lavoro di ottimizzazione, insieme ai dettagli sul modello ottimizzato e sul set di dati di addestramento."])}},footer:{address_beijing:e=>{const{normalize:i}=e;return i(["Pechino, Cina"])},address_berlin:e=>{const{normalize:i}=e;return i(["Berlino, Germania (sede centrale)"])},address_shenzhen:e=>{const{normalize:i}=e;return i(["Shenzen, Cina"])},all_rights_reserved:e=>{const{normalize:i}=e;return i(["Tutti i diritti riservati."])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},developers:e=>{const{normalize:i}=e;return i(["Sviluppatori"])},docs:e=>{const{normalize:i}=e;return i(["Documenti"])},enterprise:e=>{const{normalize:i}=e;return i(["Impresa"])},offices:e=>{const{normalize:i}=e;return i(["Uffici"])},power_users:e=>{const{normalize:i}=e;return i(["Utenti esperti"])},privacy:e=>{const{normalize:i}=e;return i(["Privacy"])},privacy_policy:e=>{const{normalize:i}=e;return i(["politica sulla riservatezza"])},privacy_settings:e=>{const{normalize:i}=e;return i(["Gestisci i cookie"])},status:e=>{const{normalize:i}=e;return i(["Stato dell'API"])},tc:e=>{const{normalize:i}=e;return i(["Termini & Condizioni"])},tc1:e=>{const{normalize:i}=e;return i(["Termini"])}},get_new_key:e=>{const{normalize:i}=e;return i(["Ottieni la tua chiave API"])},github:{stars:e=>{const{normalize:i}=e;return i(["Stelle"])}},header:{about_us:e=>{const{normalize:i}=e;return i(["Chi siamo"])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},contact_us:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},developers_others:e=>{const{normalize:i}=e;return i(["Altri strumenti per sviluppatori"])},enterprise_others:e=>{const{normalize:i}=e;return i(["Pi\xF9 soluzioni aziendali"])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_developers_description:e=>{const{normalize:i}=e;return i(["Sperimenta uno stack IA multimodale open source completo progettato per gli sviluppatori."])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le Imprese"])},for_enterprise_description:e=>{const{normalize:i}=e;return i(["Scopri strategie AI multimodali scalabili su misura per soddisfare le esigenze aziendali."])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},for_power_users_description:e=>{const{normalize:i}=e;return i(["Utilizza i nostri strumenti multimodali ottimizzati per migliorare la tua produttivit\xE0."])},internship1:e=>{const{normalize:i}=e;return i(["Programma di stagista"])},jobs:e=>{const{normalize:i}=e;return i(["Unisciti a noi"])},join_discord:e=>{const{normalize:i}=e;return i(["Unisciti alla nostra comunit\xE0 Discord"])},logos:e=>{const{normalize:i}=e;return i(["Scarica il logo"])},news:e=>{const{normalize:i}=e;return i(["Notizia"])},open_day:e=>{const{normalize:i}=e;return i(["Giornata aperta"])},open_in_full:e=>{const{normalize:i}=e;return i(["Mostra tutti i prodotti aziendali in una nuova finestra"])},power_users_others:e=>{const{normalize:i}=e;return i(["Pi\xF9 strumenti per utenti esperti"])},products:e=>{const{normalize:i}=e;return i(["Prodotti"])}},hub:{description:e=>{const{normalize:i}=e;return i(["Condividi e scopri elementi costitutivi per applicazioni IA multimodali"])}},huggingface:{sentence_similarity:e=>{const{normalize:i}=e;return i(["Incorporamento di frasi"])},updated_about:e=>{const{normalize:i}=e;return i(["Aggiornato circa"])}},impact_snapshots:{project1:e=>{const{normalize:i}=e;return i(["Ricerca ad alta precisione abilitata all'interno dei dati mesh 3D utilizzando le informazioni sulla nuvola di punti."])},project10:e=>{const{normalize:i}=e;return i(["Sfruttata la computer vision per migliorare l'accessibilit\xE0 digitale dei siti web governativi."])},project11:e=>{const{normalize:i}=e;return i(["LLM perfezionato per una societ\xE0 di consulenza per ottimizzare l'analisi dei dati finanziari."])},project12:e=>{const{normalize:i}=e;return i(["Strategie di marketing avanzate perfezionando i modelli di testo in immagine per il trasferimento dello stile."])},project2:e=>{const{normalize:i}=e;return i(["Progettato un motore di ricerca basato sui contenuti per cortometraggi di animazione."])},project3:e=>{const{normalize:i}=e;return i(["Miglioramento dei tassi di conversione dell'e-commerce perfezionando i modelli di incorporamento."])},project4:e=>{const{normalize:i}=e;return i(["Messa a punto rapida eseguita per aumentare l'efficienza per una societ\xE0 di consulenza aziendale."])},project5:e=>{const{normalize:i}=e;return i(["Precursore della comprensione delle scene di gioco e dell'annotazione automatica per un'azienda leader nel settore dei giochi."])},project6:e=>{const{normalize:i}=e;return i(["Implementata l'espansione dell'input in tempo reale per un'azienda di chatbot, migliorando l'esperienza dell'utente."])},project7:e=>{const{normalize:i}=e;return i(["Tecnologia legale rivoluzionata consentendo una ricerca efficiente all'interno di lunghi documenti legali."])},project8:e=>{const{normalize:i}=e;return i(["Supporto di un servizio di arte generativa ad alto rendimento per operazioni su larga scala."])},project9:e=>{const{normalize:i}=e;return i(["Eseguito il process mining e la modellazione utilizzando modelli linguistici avanzati."])}},inference:{description:e=>{const{normalize:i}=e;return i(["Modelli multimodali all'avanguardia disponibili per l'inferenza"])}},integrations:{embedding:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},reranker:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},which_to_go:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Quale integrare con ",n(o("_vendor")),"?"])}},internship_faq:{answer1:e=>{const{normalize:i}=e;return i(["Laurea, master e dottorato di ricerca. studenti provenienti da tutto il mondo, con interesse in campi come la ricerca, l'ingegneria, il marketing e le vendite, sono incoraggiati ad applicare. Accogliamo con favore anche stage non tecnici in marketing, vendite, assistenza esecutiva e altro ancora. Cerchiamo persone appassionate pronte a fare da pionieri nell'IA multimodale con noi."])},answer10:e=>{const{normalize:i}=e;return i(["S\xEC, il nostro programma di tirocinio offre una remunerazione competitiva."])},answer11:e=>{const{normalize:i}=e;return i(["In qualit\xE0 di stagista Jina AI, acquisirai esperienza pratica lavorando su progetti stimolanti, imparerai da esperti del settore, entrerai a far parte di una vivace comunit\xE0 e avrai l'opportunit\xE0 di dare un contributo reale al nostro lavoro pionieristico nell'IA multimodale."])},answer2:e=>{const{normalize:i}=e;return i(["Gli stage devono essere svolti in loco presso uno dei nostri uffici, che si trovano a Berlino, Pechino e Shenzhen."])},answer3:e=>{const{normalize:i}=e;return i(["S\xEC, Jina AI offre un'assistenza ragionevole nel processo di visto per i richiedenti selezionati."])},answer4:e=>{const{normalize:i}=e;return i(["S\xEC, Jina AI fornisce una ragionevole copertura del costo della vita per gli stagisti durante il periodo di tirocinio."])},answer5:e=>{const{normalize:i}=e;return i(["S\xEC, \xE8 possibile lavorare alla tua tesi di Master durante il tirocinio presso Jina AI, tipicamente applicabile agli studenti delle universit\xE0 tedesche. Tuttavia, \xE8 necessario disporre di una comunicazione preventiva e del consenso del supervisore della propria universit\xE0. Tieni presente che non aiutiamo gli studenti a trovare consulenti."])},answer6:e=>{const{normalize:i}=e;return i(["Il processo di candidatura include l'invio del modulo di candidatura, un curriculum, una lettera di presentazione che esprima il tuo interesse e la tua motivazione e qualsiasi link professionale pertinente come GitHub o LinkedIn. Valutiamo i candidati in base alle loro prestazioni durante il colloquio e alle loro prestazioni nella loro universit\xE0."])},answer7:e=>{const{normalize:i}=e;return i(["S\xEC, gli stagisti di successo possono ricevere una lettera di raccomandazione alla fine del loro tirocinio, firmata dal nostro CEO."])},answer8:e=>{const{normalize:i}=e;return i(["La durata dello stage varia in base al ruolo e al progetto. Tuttavia, in genere varia da tre a sei mesi."])},answer9:e=>{const{normalize:i}=e;return i(["S\xEC, accogliamo candidature di ogni estrazione accademica. Apprezziamo la tua passione e il tuo impegno per imparare tanto quanto l'esperienza precedente."])},question1:e=>{const{normalize:i}=e;return i(["Chi pu\xF2 fare domanda per il programma di tirocinio Jina AI?"])},question10:e=>{const{normalize:i}=e;return i(["\xC8 uno stage retribuito?"])},question11:e=>{const{normalize:i}=e;return i(["Quali opportunit\xE0 avr\xF2 come stagista Jina AI?"])},question2:e=>{const{normalize:i}=e;return i(["Dove si svolger\xE0 il tirocinio?"])},question3:e=>{const{normalize:i}=e;return i(["Jina AI assiste con le procedure di visto?"])},question4:e=>{const{normalize:i}=e;return i(["Jina AI fornisce indennit\xE0 o benefici per gli stagisti?"])},question5:e=>{const{normalize:i}=e;return i(["Posso lavorare alla mia tesi di Master durante lo stage presso Jina AI?"])},question6:e=>{const{normalize:i}=e;return i(["Cosa prevede il processo di candidatura?"])},question7:e=>{const{normalize:i}=e;return i(["Jina AI fornisce una lettera di raccomandazione dopo lo stage?"])},question8:e=>{const{normalize:i}=e;return i(["Qual \xE8 la durata del tirocinio?"])},question9:e=>{const{normalize:i}=e;return i(["Posso candidarmi se non ho precedenti esperienze in IA?"])}},internship_page:{about_internship_program:e=>{const{normalize:i}=e;return i(["Informazioni sul programma di tirocinio"])},about_internship_program_desc1:e=>{const{normalize:i}=e;return i(["Siamo entusiasti di offrire questa opportunit\xE0 unica a persone di talento per entrare a far parte del nostro team dinamico e contribuire a progetti innovativi nel campo dell'Intelligenza Artificiale. Questo stage \xE8 progettato per fornirti preziosa esperienza pratica, tutoraggio ed esposizione a tecnologie all'avanguardia che stanno plasmando il futuro dell'IA."])},about_internship_program_desc2:e=>{const{normalize:i}=e;return i(["In Jina AI, comprendiamo l'importanza di coltivare e sfruttare i giovani talenti. Riconosciamo che i tirocinanti portano sul tavolo nuove prospettive, entusiasmo e creativit\xE0, rinvigorendo il nostro team con nuove idee e approcci. Fornendo stage, miriamo a favorire la crescita dei futuri leader nel settore dell'intelligenza artificiale, offrendo loro un'esperienza del mondo reale in un ambiente stimolante e stimolante."])},alumni:e=>{const{normalize:i}=e;return i(["ALUNNI"])},alumni_network:e=>{const{normalize:i}=e;return i(["La nostra fiorente rete di ex studenti"])},application:e=>{const{normalize:i}=e;return i(["Applicazione"])},application_desc:e=>{const{normalize:i}=e;return i(["Intraprendi un viaggio di trasformazione con Jina AI. Il nostro programma di tirocinio completo invita tutte le menti appassionate che aspirano a plasmare il futuro dell'intelligenza artificiale. Unisciti a noi per fare esperienza nel mondo reale, lavorare su progetti stimolanti e collaborare con alcune delle menti pi\xF9 brillanti del settore dell'IA."])},apply:e=>{const{normalize:i}=e;return i(["Applica ora"])},autumn:e=>{const{normalize:i}=e;return i(["Autunno"])},description:e=>{const{normalize:i}=e;return i(["Bando mondiale per studenti: stage in ricerca, ingegneria, marketing, vendite e altro ancora."])},dev_rel_intern:e=>{const{normalize:i}=e;return i(["Stagista nelle relazioni con gli sviluppatori"])},enthusiastic:e=>{const{normalize:i}=e;return i(["ENTUSIASTA"])},explore_stories_from_our_interns:e=>{const{normalize:i}=e;return i(["Esplora le storie dei nostri stagisti"])},explore_stories_from_our_interns1:e=>{const{normalize:i}=e;return i(["Lasciati ispirare dai viaggi dei nostri stagisti"])},innovative:e=>{const{normalize:i}=e;return i(["INNOVATIVO"])},intern_work1:e=>{const{normalize:i}=e;return i(["Modelli LLM ottimizzati per incorporamenti migliori"])},intern_work2:e=>{const{normalize:i}=e;return i(["Esplorato il potenziale di Retrieval Augmented Generation"])},intern_work3:e=>{const{normalize:i}=e;return i(["Ha pubblicato un articolo sul tema dell'incorporamento di frasi"])},intern_work4:e=>{const{normalize:i}=e;return i(["Infondere continua vitalit\xE0 giovanile nella squadra"])},intern_work5:e=>{const{normalize:i}=e;return i(["Tecniche di quantizzazione benchmark per comprimere LLM"])},intern_work6:e=>{const{normalize:i}=e;return i(["Creazione e promozione di una campagna avvincente per PromptPerfect"])},recruiting_and_administrative_intern:e=>{const{normalize:i}=e;return i(["Stagista reclutamento e amministrazione"])},self_motivated:e=>{const{normalize:i}=e;return i(["AUTOMOTIVATO"])},software_engineer_intern:e=>{const{normalize:i}=e;return i(["Tirocinante Ingegnere informatico"])},spring:e=>{const{normalize:i}=e;return i(["Primavera"])},submit_application:e=>{const{normalize:i}=e;return i(["Dai il via alla tua avventura con Jina AI"])},subtitle:e=>{const{normalize:i}=e;return i(["Il nostro programma di tirocinio a tempo pieno offre un'esperienza lavorativa pratica attraverso progetti di tirocinio ben progettati in una vasta gamma di ambiti."])},subtitle1:e=>{const{normalize:i}=e;return i(["Bando mondiale per studenti: stagista in ricerca, ingegneria, marketing, vendite e altro ancora per aprire la strada all'IA multimodale insieme."])},summer:e=>{const{normalize:i}=e;return i(["Estate"])},title:e=>{const{normalize:i}=e;return i(["Programma di stagista"])},who_do_we_look_for:e=>{const{normalize:i}=e;return i(["Chi cerchiamo?"])},who_do_we_look_for_desc:e=>{const{normalize:i}=e;return i(["Apprezziamo la diversit\xE0 e incoraggiamo i candidati con profili e background diversi a partecipare al nostro programma di tirocinio. Le opportunit\xE0 di tirocinio sono offerte in pi\xF9 dipartimenti, tra cui ingegneria, design, gestione del prodotto, gestione delle vendite e dell'account, marketing e gestione della comunit\xE0."])},winter:e=>{const{normalize:i}=e;return i(["Inverno"])}},jcloud:{description:e=>{const{normalize:i}=e;return i(["Distribuisci un progetto locale come servizio cloud. Radicalmente facile, senza brutte sorprese."])}},jerboa:{description:e=>{const{normalize:i}=e;return i(["Un finetuner sperimentale per LLM open source"])}},jina:{description:e=>{const{normalize:i}=e;return i(["Crea applicazioni IA multimodali nel cloud"])}},jina_chat:{description:e=>{const{normalize:i}=e;return i(["Pi\xF9 modalit\xE0, memoria pi\xF9 lunga, meno costi"])},example_1:e=>{const{normalize:i}=e;return i(["Chi sei?"])},example_2:e=>{const{normalize:i}=e;return i(["Sono un servizio di chat LLM creato da Jina AI"])}},lab_dialog:{GlobalQA:{description:e=>{const{normalize:i}=e;return i(['Premi il tasto "/" su qualsiasi pagina per aprire la casella delle domande. Digita la tua query e premi "Invio" per ricevere risposte direttamente correlate al contenuto della pagina. Questa funzionalit\xE0 \xE8 fornita da PromptPerfect.'])},title:e=>{const{normalize:i}=e;return i(["RAG a pagina"])}},Recommender:{description:e=>{const{normalize:i}=e;return i(['Apri la casella dei consigli su qualsiasi pagina di notizie con "Shift+2". Seleziona il modello di riclassificazione per scoprire i primi 5 articoli relativi a quella pagina di notizie. Goditi questa funzionalit\xE0 in tempo reale, basata sulla nostra API Reranker.'])},title:e=>{const{normalize:i}=e;return i(["Articolo correlato"])}},SceneXplainTooltip:{description:e=>{const{normalize:i}=e;return i(["Passa il cursore su qualsiasi immagine nelle pagine delle notizie o nel nostro catalogo della redazione per rivelare la descrizione di quell'immagine. Le descrizioni sono precalcolate da SceneXplain e incorporate nell'attributo ALT dell'immagine per l'accessibilit\xE0."])},title:e=>{const{normalize:i}=e;return i(["Didascalie delle immagini"])}},explain:e=>{const{normalize:i}=e;return i(["Scopri le funzionalit\xE0 nascoste sul nostro sito web"])}},landing_page:{also_available_on:e=>{const{normalize:i}=e;return i(["Disponibile anche sui marketplace"])},also_available_on1:e=>{const{normalize:i}=e;return i(["Disponibile sui marketplace del tuo cloud aziendale"])},ask_how_your_question:e=>{const{normalize:i}=e;return i(["Descrivi il tuo problema"])},autotune:e=>{const{normalize:i}=e;return i(["Sintonia automatica"])},badge:{v2:e=>{const{normalize:i}=e;return i(["Versione v2!"])}},build_js:e=>{const{normalize:i}=e;return i(["Costruisci con JavaScript"])},build_python:e=>{const{normalize:i}=e;return i(["Costruisci con Python"])},checkout_our_solution_for_you:e=>{const{normalize:i}=e;return i(["Scopri la nostra soluzione su misura per te"])},coming_soon:e=>{const{normalize:i}=e;return i(["Prossimamente"])},contact_sales:e=>{const{normalize:i}=e;return i(["Contatto"])},copied_to_clipboard:e=>{const{normalize:i}=e;return i(["Copiato negli appunti"])},copy:e=>{const{normalize:i}=e;return i(["copia"])},developers:e=>{const{normalize:i}=e;return i(["Sviluppatori"])},developers_desc:e=>{const{normalize:i}=e;return i(["Libera tutta la potenza dell'intelligenza artificiale multimodale con tecnologie cloud-native all'avanguardia e un'infrastruttura open source."])},download_pdf:e=>{const{normalize:i}=e;return i(["Scarica il pdf"])},embedding_desc1:e=>{const{normalize:i}=e;return i(["Il primo modello di incorporamento open source al mondo con una lunghezza di 8192 token, corrispondente al text-embedding-ada002 di OpenAI nel Massive Text Embedding Benchmark (MTEB)."])},embedding_paper_desc:e=>{const{normalize:i}=e;return i(["Jina Embeddings costituisce un insieme di modelli di incorporamento di frasi ad alte prestazioni abili nel tradurre vari input testuali in rappresentazioni numeriche, catturando cos\xEC l'essenza semantica del testo. Sebbene questi modelli non siano progettati esclusivamente per la generazione di testo, eccellono in applicazioni come il recupero denso e la somiglianza testuale semantica. Questo documento descrive in dettaglio lo sviluppo di Jina Embeddings, a partire dalla creazione di un set di dati pairwise e triplet di alta qualit\xE0. Sottolinea il ruolo cruciale della pulizia dei dati nella preparazione del set di dati, fornisce approfondimenti sul processo di addestramento del modello e si conclude con una valutazione completa delle prestazioni utilizzando il Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:i}=e;return i(["Jina Embedding: un nuovo set di modelli di incorporamento di frasi ad alte prestazioni"])},embeddings:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},enterprise:e=>{const{normalize:i}=e;return i(["Impresa"])},enterprise_desc:e=>{const{normalize:i}=e;return i(["Potenzia il tuo business con soluzioni AI multimodali scalabili, sicure e su misura."])},enterprise_desc_v2:e=>{const{normalize:i}=e;return i(["Prova i nostri modelli di incorporamento di livello mondiale per migliorare i tuoi sistemi di ricerca e RAG. Inizia con una prova gratuita!"])},enterprise_desc_v3:e=>{const{normalize:i}=e;return i(["Sviluppiamo basi di ricerca all'avanguardia per soluzioni RAG e ricerca aziendale di alta qualit\xE0. Inizia con una prova gratuita!"])},error:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Si \xE8 verificato un problema con l'operazione di recupero: ",n(o("messaggio"))])},find_your_portal:e=>{const{normalize:i}=e;return i(["Trova il tuo portale"])},finding_faq:e=>{const{normalize:i}=e;return i(["Generazione di una risposta in base alla conoscenza delle domande frequenti riportate di seguito"])},for:e=>{const{normalize:i}=e;return i(["Per"])},get_api_now:e=>{const{normalize:i}=e;return i(["API"])},get_started:e=>{const{normalize:i}=e;return i(["Iniziare"])},how_to:e=>{const{normalize:i}=e;return i(["Come"])},include_experiment:e=>{const{normalize:i}=e;return i(["Include i nostri progetti sperimentali e archiviati nella soluzione."])},join_community:e=>{const{normalize:i}=e;return i(["Comunit\xE0"])},learn_more_embeddings:e=>{const{normalize:i}=e;return i(["Ulteriori informazioni sugli incorporamenti"])},learn_more_reader:e=>{const{normalize:i}=e;return i(["Scopri di pi\xF9 sul lettore"])},learn_more_reranker:e=>{const{normalize:i}=e;return i(["Scopri di pi\xF9 sul riclassificazione"])},llm:e=>{const{normalize:i}=e;return i(["Modelli di incorporamento LLM"])},llm_desc:e=>{const{normalize:i}=e;return i(["Forniamo una raccolta di modelli di incorporamento di frasi ad alte prestazioni, che vantano tra 35 milioni e 6 miliardi di parametri. Sono eccellenti per migliorare la ricerca neurale, la riclassificazione, la somiglianza delle frasi, i consigli, ecc. Preparati a migliorare la tua esperienza AI!"])},mentioned_products:e=>{const{normalize:i}=e;return i(["Prodotti menzionati:"])},mmstack:e=>{const{normalize:i}=e;return i(["Pila multimodale"])},mmstack_desc:e=>{const{normalize:i}=e;return i(["Nel corso degli anni, abbiamo sviluppato una variet\xE0 di software open source per aiutare gli sviluppatori a creare una migliore GenAI e a cercare le applicazioni pi\xF9 velocemente."])},multimodal:e=>{const{normalize:i}=e;return i(["Multimodale"])},multimodal_ai:e=>{const{normalize:i}=e;return i(["IA multimodale"])},new:e=>{const{normalize:i}=e;return i(["Nuovo"])},newsroom:e=>{const{normalize:i}=e;return i(["Sala stampa"])},"on-prem-deploy":e=>{const{normalize:i}=e;return i(["Distribuzione locale"])},"on-premises":e=>{const{normalize:i}=e;return i(["In sede"])},opensource:e=>{const{normalize:i}=e;return i(["Fonte aperta"])},our_publications:e=>{const{normalize:i}=e;return i(["Le nostre pubblicazioni"])},parameters:e=>{const{normalize:i}=e;return i(["Parametri"])},podcast:e=>{const{normalize:i}=e;return i(["Podcast"])},power_users:e=>{const{normalize:i}=e;return i(["Utenti esperti"])},power_users_desc:e=>{const{normalize:i}=e;return i(["Ingegneria automatica per la tua produttivit\xE0 quotidiana."])},powered_by_promptperfect:e=>{const{normalize:i}=e;return i(['Alimentato dalla funzione "Prompt optimization" e "Prompt as a service" di PromptPerfect'])},pricing:e=>{const{normalize:i}=e;return i(["Prezzi"])},proposing_solution:e=>{const{normalize:i}=e;return i(["Proporre una soluzione basata sui prodotti Jina AI..."])},read_more:e=>{const{normalize:i}=e;return i(["Per saperne di pi\xF9"])},reader:e=>{const{normalize:i}=e;return i(["Lettore"])},require_full_question:e=>{const{normalize:i}=e;return i(["Descrivi il tuo problema con maggiori dettagli."])},reranker:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},researcher_desc:e=>{const{normalize:i}=e;return i(["Per capire come i nostri modelli linguistici di grandi dimensioni sono stati addestrati da zero per le attivit\xE0 di incorporamento, consulta le nostre ultime ricerche e pubblicazioni. Incontra il nostro team alle conferenze EMNLP, ACL, SIGIR, NeurIPS e ICML."])},researchers:e=>{const{normalize:i}=e;return i(["Ricercatori"])},sdk:e=>{const{normalize:i}=e;return i(["SDK"])},sdk_desc:e=>{const{normalize:i}=e;return i(["Vuoi creare applicazioni AIGC di alto livello utilizzando le API PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale? Ti abbiamo coperto! Prova il nostro SDK facile da usare e inizia in pochi minuti."])},sdk_docs:e=>{const{normalize:i}=e;return i(["Leggi i documenti"])},sdk_example:e=>{const{normalize:i}=e;return i(["Esempio"])},search_foundation:e=>{const{normalize:i}=e;return i(["Cerca Fondazione"])},source_code:e=>{const{normalize:i}=e;return i(["Codice sorgente"])},starter_kit:e=>{const{normalize:i}=e;return i(["Kit di partenza"])},supercharged1:e=>{const{normalize:i}=e;return i(["Sovralimentato."])},trusted_by:e=>{const{normalize:i}=e;return i(["AFFIDATO DA"])},try_it_for_free:e=>{const{normalize:i}=e;return i(["Provalo gratuitamente, non \xE8 richiesta la carta di credito"])},try_our_saas:e=>{const{normalize:i}=e;return i(["Prova la nostra soluzione ospitata, un sostituto immediato dell'API di incorporamento di OpenAI."])},your_portal_to:e=>{const{normalize:i}=e;return i(["Il tuo portale per"])},your_search_foundation1:e=>{const{normalize:i}=e;return i(["La tua base di ricerca"])}},langchain_serve:{description:e=>{const{normalize:i}=e;return i(["App Langchain in produzione con Jina e FastAPI"])}},news_page:{back_to_newsroom:e=>{const{normalize:i}=e;return i(["Torniamo alla redazione"])},categories:e=>{const{normalize:i}=e;return i(["Categorie"])},copy_link:e=>{const{normalize:i}=e;return i(["Copia il collegamento a questa sezione"])},in_this_article:e=>{const{normalize:i}=e;return i(["In questo articolo"])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di pi\xF9"])},news_not_found:e=>{const{normalize:i}=e;return i(["Articolo non trovato"])},redirect_to_news:e=>{const{normalize:i}=e;return i(["Reindirizzamento alla redazione tra 5 secondi..."])}},newsroom_page:{academic:e=>{const{normalize:i}=e;return i(["Accademico"])},academic_research:e=>{const{normalize:i}=e;return i(["Pubblicazioni accademiche"])},author:e=>{const{normalize:i}=e;return i(["Per autore"])},description:e=>{const{normalize:i}=e;return i(["Leggi le ultime notizie e gli aggiornamenti da Jina AI."])},description1:e=>{const{normalize:i}=e;return i(["Realizzare innovazioni legate all'intelligenza artificiale, una parola alla volta."])},engineering_group:e=>{const{normalize:i}=e;return i(["Gruppo Ingegneria"])},engineering_group_date:e=>{const{normalize:i}=e;return i(["31 maggio 2021"])},minutes_read:e=>{const{normalize:i}=e;return i(["minuti letti"])},most_recent_articles:e=>{const{normalize:i}=e;return i(["Articoli pi\xF9 recenti"])},news_description:e=>{const{normalize:i}=e;return i(['Per Jina 2.0, abbiamo ascoltato la community. Veramente, profondamente ascoltato. "Quali sono i tuoi punti dolenti?" abbiamo chiesto, aspettando con impazienza un prezioso feedback'])},news_title:e=>{const{normalize:i}=e;return i(["Cerca tutte le cose: stiamo organizzando un concorso MEME per Jina 2.0"])},photos:e=>{const{normalize:i}=e;return i(["Fotografie"])},product:e=>{const{normalize:i}=e;return i(["Per prodotto"])},search:e=>{const{normalize:i}=e;return i(["Cerca per titolo"])},tech_blog:e=>{const{normalize:i}=e;return i(["Blog tecnico"])},title:e=>{const{normalize:i}=e;return i(["Sala stampa"])},top_stories:e=>{const{normalize:i}=e;return i(["Le migliori storie"])}},notice:e=>{const{normalize:i}=e;return i(['\u{1F389} Il nostro primo libro, "Neural Search \u2014 From Prototype to Production with Jina" \xE8 ufficialmente uscito oggi!'])},open_day:{description:e=>{const{normalize:i}=e;return i(["Un'opportunit\xE0 esclusiva per ottenere una visione dall'interno di Jina AI."])},engage:e=>{const{normalize:i}=e;return i(["Incoraggiamo vivamente un dialogo interattivo durante tutta la giornata. Lo scambio di pensieri e prospettive \xE8 inestimabile per noi. Le potenziali collaborazioni derivanti da queste discussioni potrebbero contribuire in modo significativo a un futuro pi\xF9 integrato e innovativo."])},engage_title:e=>{const{normalize:i}=e;return i(["Interagisci con noi"])},experience:e=>{const{normalize:i}=e;return i(["Abbiamo organizzato un coinvolgente tour di tre ore per i nostri ospiti, disponibile in tedesco, inglese, francese, spagnolo, cinese e russo. Il tour copre uno sguardo approfondito ai nostri progressi nell'IA multimodale, la nostra prospettiva sul panorama dell'IA, seguito da un esame dettagliato di progetti specifici. Concluderemo con una discussione di gruppo per facilitare lo scambio di idee e approfondimenti. Su richiesta \xE8 disponibile anche un'opzione per il pranzo."])},experience_title:e=>{const{normalize:i}=e;return i(["Il viaggio di un insider"])},group_size:e=>{const{normalize:i}=e;return i(["Numero stimato di visitatori"])},impact:e=>{const{normalize:i}=e;return i(["Scopri come i nostri contributi alla comunit\xE0 open source e il nostro lavoro nella tecnologia IA multimodale stanno facendo di Jina AI un attore influente nell'innovazione IA. Miriamo a svolgere un ruolo significativo nei processi decisionali, assicurandoci che il progresso della tecnologia AI sia vantaggioso per tutti."])},impact_title:e=>{const{normalize:i}=e;return i(["Impatto e influenza"])},introduction:e=>{const{normalize:i}=e;return i(["Jina AI \xE8 lieta di aprire le nostre porte a entit\xE0 e organizzazioni stimate interessate al progresso e al futuro dell'Intelligenza Artificiale. Estendiamo questa opportunit\xE0 esclusiva per coloro che operano in politica, ONG, NPO e settori di investimento per ottenere una visione dall'interno delle nostre operazioni e visioni qui presso la nostra sede di Berlino."])},motivation_min_length_v1:e=>{const{normalize:i}=e;return i(["Si prega di fornire una motivazione pi\xF9 dettagliata."])},motivation_placeholder_v2:e=>{const{normalize:i}=e;return i(["Condividere le tue motivazioni ci aiuter\xE0 a migliorare la tua esperienza."])},motivation_to_attend_v2:e=>{const{normalize:i}=e;return i(["Perch\xE9 sei interessato al nostro Open Day?"])},one_hour:e=>{const{normalize:i}=e;return i(["1 ora"])},organization:e=>{const{normalize:i}=e;return i(["Organizzazione"])},organization_website:e=>{const{normalize:i}=e;return i(["Sito web dell'organizzazione"])},organization_website_placeholder:e=>{const{normalize:i}=e;return i(["URL della home page o del profilo LinkedIn della tua organizzazione"])},preferred_date:e=>{const{normalize:i}=e;return i(["Data preferita"])},preferred_language:e=>{const{normalize:i}=e;return i(["Lingua preferita del tour"])},preferred_products:e=>{const{normalize:i}=e;return i(["A quali prodotti sei interessato?"])},subtitle:e=>{const{normalize:i}=e;return i(["Uno sguardo al futuro dell'IA multimodale"])},title:e=>{const{normalize:i}=e;return i(["Giornata delle porte aperte"])},tutor_subtitle:e=>{const{normalize:i}=e;return i(["Un tour di tre ore meticolosamente curato, che ti avvicina al cuore del lavoro rivoluzionario di Jina AI nella tecnologia AI multimodale."])},tutor_title:e=>{const{normalize:i}=e;return i(["Un'esclusiva immersione profonda in"])},vision:e=>{const{normalize:i}=e;return i(["Unisciti a noi per una panoramica completa del panorama dell'IA come lo vediamo noi. La nostra discussione si concentrer\xE0 sul potenziale dei modelli linguistici di grandi dimensioni, dell'IA multimodale e dell'impatto della tecnologia open source nel plasmare il futuro dell'innovazione globale."])},vision_title:e=>{const{normalize:i}=e;return i(["La nostra visione per il futuro"])}},open_day_faq:{answer1:e=>{const{normalize:i}=e;return i(["Offriamo tour in tedesco, inglese, francese, spagnolo, cinese e russo."])},answer2:e=>{const{normalize:i}=e;return i(["Il tour dura in genere circa tre ore."])},answer3:e=>{const{normalize:i}=e;return i(["Il pranzo \xE8 facoltativo e pu\xF2 essere organizzato su richiesta."])},answer4:e=>{const{normalize:i}=e;return i(["Il nostro Open Day \xE8 progettato principalmente per gruppi professionali, come politici, ONG, NPO e investitori. Tuttavia, occasionalmente facciamo delle eccezioni in base al profilo dell'individuo."])},answer5:e=>{const{normalize:i}=e;return i(["Siamo in grado di ospitare una variet\xE0 di dimensioni di gruppo. Indica la dimensione del tuo gruppo nel modulo di registrazione e confermeremo i dettagli con te."])},answer6:e=>{const{normalize:i}=e;return i(["C'\xE8 una sezione nel modulo di registrazione dove puoi specificare le tue aree di interesse o eventuali richieste particolari. Faremo del nostro meglio per personalizzare il tour in base alle vostre esigenze."])},answer7:e=>{const{normalize:i}=e;return i(["Al momento, offriamo tour solo presso la nostra sede di Berlino situata a Kreuzberg. I nostri uffici di Pechino e Shenzhen non sono attualmente aperti per i tour."])},question1:e=>{const{normalize:i}=e;return i(["Quali lingue offrite per il tour?"])},question2:e=>{const{normalize:i}=e;return i(["Qual \xE8 la durata del tour?"])},question3:e=>{const{normalize:i}=e;return i(["Il pranzo \xE8 previsto?"])},question4:e=>{const{normalize:i}=e;return i(["Le persone possono iscriversi all'Open Day?"])},question5:e=>{const{normalize:i}=e;return i(["Da quante persone pu\xF2 essere composto un gruppo per l'Open Day?"])},question6:e=>{const{normalize:i}=e;return i(["Come posso specificare le aree di interesse per il tour?"])},question7:e=>{const{normalize:i}=e;return i(["I tour sono disponibili presso i vostri uffici di Pechino o Shenzhen?"])}},open_gpt:{description:e=>{const{normalize:i}=e;return i(["Un cloud-native open source di grandi modelli multimodali al servizio del framework"])}},powered_by:e=>{const{normalize:i}=e;return i(["Offerto da"])},print:e=>{const{normalize:i}=e;return i(["Stampa"])},project_status:{archived:e=>{const{normalize:i}=e;return i(["Archiviato"])},cloud_native:e=>{const{normalize:i}=e;return i(["Nativo del cloud"])},core:e=>{const{normalize:i}=e;return i(["Nucleo"])},data_structure:e=>{const{normalize:i}=e;return i(["Struttura dati"])},embedding_serving:e=>{const{normalize:i}=e;return i(["Incorporamento della pubblicazione"])},embedding_tuning:e=>{const{normalize:i}=e;return i(["Incorporamento dell'ottimizzazione"])},graduated:e=>{const{normalize:i}=e;return i(["Laureato"])},incubating:e=>{const{normalize:i}=e;return i(["Incubazione"])},kubernetes:e=>{const{normalize:i}=e;return i(["Kubernetes"])},large_size_model:e=>{const{normalize:i}=e;return i(["Modello di grandi dimensioni"])},linux_foundation:e=>{const{normalize:i}=e;return i(["Fondazione Linux"])},llm1:e=>{const{normalize:i}=e;return i(["LLMOps"])},mid_size_model:e=>{const{normalize:i}=e;return i(["Modello di taglia media"])},model_serving:e=>{const{normalize:i}=e;return i(["Modello che serve"])},model_tuning:e=>{const{normalize:i}=e;return i(["Messa a punto del modello"])},observability:e=>{const{normalize:i}=e;return i(["Osservabilit\xE0"])},orchestration:e=>{const{normalize:i}=e;return i(["Orchestrazione"])},prompt_serving:e=>{const{normalize:i}=e;return i(["Servizio rapido"])},prompt_tuning:e=>{const{normalize:i}=e;return i(["Sintonizzazione rapida"])},rag1:e=>{const{normalize:i}=e;return i(["STRACCIO"])},sandbox:e=>{const{normalize:i}=e;return i(["Sabbiera"])},small_size_model:e=>{const{normalize:i}=e;return i(["Modello di piccole dimensioni"])},vector_database:e=>{const{normalize:i}=e;return i(["Banca dati vettoriale"])},vector_store:e=>{const{normalize:i}=e;return i(["Negozio di vettore"])}},prompt_perfect:{description:e=>{const{normalize:i}=e;return i(["Strumento principale per l'ingegneria rapida"])},image_model:e=>{const{normalize:i}=e;return i(["Modelli di immagine"])},intro:e=>{const{normalize:i}=e;return i(["Strumento principale per l'ingegneria rapida"])},intro1:e=>{const{normalize:i}=e;return i(["Lo strumento principale per un'ingegneria tempestiva"])},optimized:e=>{const{normalize:i}=e;return i(["Il tuo compito \xE8 essere il mio compagno di brainstorming e fornire idee e suggerimenti creativi per un determinato argomento o problema. La tua risposta dovrebbe includere idee originali, uniche e pertinenti che potrebbero aiutare a risolvere il problema o esplorare ulteriormente l'argomento in modo interessante. Tieni presente che la tua risposta dovrebbe anche tenere conto di eventuali requisiti o vincoli specifici dell'attivit\xE0."])},optimized_title:e=>{const{normalize:i}=e;return i(["Prompt ottimizzato"])},original:e=>{const{normalize:i}=e;return i(["Il tuo ruolo \xE8 quello di essere il mio compagno di brainstorming."])},original_title:e=>{const{normalize:i}=e;return i(["Richiesta originale"])},text_model:e=>{const{normalize:i}=e;return i(["Modelli testuali"])}},promptperfect:{features:[{description:e=>{const{normalize:i}=e;return i(["Passa facilmente dalla generazione di contenuti all'ottimizzazione rapida e porta la qualit\xE0 dei tuoi contenuti a un livello superiore."])},name:e=>{const{normalize:i}=e;return i(["Assistente"])},title:e=>{const{normalize:i}=e;return i(["Dose giornaliera di produttivit\xE0."])}},{description:e=>{const{normalize:i}=e;return i(["Non sai come scrivere un'istruzione efficace? Inserisci semplicemente la tua idea, con un clic ottieni istruzioni migliori."])},name:e=>{const{normalize:i}=e;return i(["Ottimizzazione immediata"])},title:e=>{const{normalize:i}=e;return i(["Migliori input, migliori risultati"])}},{description:e=>{const{normalize:i}=e;return i(["Comprendi l'atmosfera di ogni modello di intelligenza artificiale confrontando l'output dello stesso prompt."])},name:e=>{const{normalize:i}=e;return i(["Confronta i modelli"])},title:e=>{const{normalize:i}=e;return i(["Confronto dei modelli affiancati."])}},{description:e=>{const{normalize:i}=e;return i(["Forse il modo pi\xF9 semplice per distribuire le tue richieste come API per l'integrazione."])},name:e=>{const{normalize:i}=e;return i(["Distribuire i prompt"])},title:e=>{const{normalize:i}=e;return i(["Nessuna operazione, basta schierarsi."])}},{description:e=>{const{normalize:i}=e;return i(["Personalizza i tuoi agenti LLM e avvia una simulazione multi-agente. Guarda come collaborano o competono in un ambiente virtuale per raggiungere l'obiettivo."])},name:e=>{const{normalize:i}=e;return i(["Multiagente"])},title:e=>{const{normalize:i}=e;return i(["Scopri come collaborano gli agenti"])}}],get_started:e=>{const{normalize:i}=e;return i(["Inizia con PromptPerfect"])}},purchase:{success:e=>{const{normalize:i}=e;return i(["Grazie per il vostro acquisto!"])},success_caption:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Abbiamo completato il tuo ordine alle ",n(o("_purchasedTime")),". La tua chiave API \xE8 pronta per l'uso!"])}},purchase_now:e=>{const{normalize:i}=e;return i(["Acquista adesso"])},rationale:{decision:e=>{const{normalize:i}=e;return i(["Decisione"])},description:e=>{const{normalize:i}=e;return i(["Strumenti decisionali IA all'avanguardia"])},intro:e=>{const{normalize:i}=e;return i(["Guarda i due lati della medaglia, prendi decisioni razionali"])}},reader:{better_input:e=>{const{normalize:i}=e;return i(["Migliora la qualit\xE0 dell'input fin dall'inizio"])},better_input_description:e=>{const{normalize:i}=e;return i(["Riscontri problemi con l'output del tuo agente o del sistema RAG? Potrebbe essere dovuto alla scarsa qualit\xE0 dell'input."])},copy:e=>{const{normalize:i}=e;return i(["copia"])},demo:{advanced_usage:e=>{const{normalize:i}=e;return i(["Utilizzo avanzato"])},ask_llm:e=>{const{normalize:i}=e;return i(["Chiedi a LLM senza e con ricerca messa a terra"])},ask_llm_directly:e=>{const{normalize:i}=e;return i(["Chiedi direttamente a LLM"])},ask_llm_with_search_grounding:e=>{const{normalize:i}=e;return i(["Chiedi a LLM con la messa a terra della ricerca"])},ask_question:e=>{const{normalize:i}=e;return i(["Poni una domanda"])},ask_question_hint:e=>{const{normalize:i}=e;return i(["Inserisci una domanda e combinala con il contenuto recuperato affinch\xE9 LLM generi una risposta"])},basic_usage:e=>{const{normalize:i}=e;return i(["Utilizzo di base"])},basic_usage1:e=>{const{normalize:i}=e;return i(["Leggi un URL"])},basic_usage2:e=>{const{normalize:i}=e;return i(["Cerca una query"])},fetch:e=>{const{normalize:i}=e;return i(["Recupera contenuto"])},get_response:e=>{const{normalize:i}=e;return i(["Ottieni risposta"])},headers:{auth_token:e=>{const{normalize:i}=e;return i(["Aggiungi chiave API per un limite di velocit\xE0 pi\xF9 elevato"])},auth_token_explain:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API Jina per accedere a un limite di velocit\xE0 pi\xF9 elevato. Per le informazioni pi\xF9 recenti sui limiti di tariffa, fare riferimento alla tabella seguente."])},default:e=>{const{normalize:i}=e;return i(["Predefinito"])},default_explain:e=>{const{normalize:i}=e;return i(["La pipeline predefinita \xE8 ottimizzata per la maggior parte dei siti Web e per l'input LLM."])},html:e=>{const{normalize:i}=e;return i(["HTML"])},html_explain:e=>{const{normalize:i}=e;return i(["Restituisce documentElement.outerHTML."])},image_caption:e=>{const{normalize:i}=e;return i(["Didascalia immagine"])},image_caption_explain:e=>{const{normalize:i}=e;return i([`Sottotitola tutte le immagini all'URL specificato, aggiungendo "Immagine [idx]: [didascalia]" come tag alt per quelle senza. Ci\xF2 consente ai LLM a valle di interagire con le immagini in attivit\xE0 come il ragionamento e il riepilogo.`])},images_summary:e=>{const{normalize:i}=e;return i(["Raccogli tutte le immagini alla fine"])},images_summary_explain:e=>{const{normalize:i}=e;return i(['Alla fine verr\xE0 creata una sezione "Immagini". Ci\xF2 fornisce ai LLM a valle una panoramica di tutti gli elementi visivi sulla pagina, il che pu\xF2 migliorare il ragionamento.'])},json_response:e=>{const{normalize:i}=e;return i(["Risposta JSON"])},json_response_explain:e=>{const{normalize:i}=e;return i(["La risposta sar\xE0 in formato JSON, contenente l'URL, il titolo, il contenuto e il timestamp (se disponibile). Nella modalit\xE0 di ricerca, restituisce un elenco di cinque voci, ciascuna seguendo la struttura JSON descritta."])},links_summary:e=>{const{normalize:i}=e;return i(["Raccogli tutti i collegamenti alla fine"])},links_summary_explain:e=>{const{normalize:i}=e;return i(['Alla fine verr\xE0 creata una sezione "Pulsanti e collegamenti". Ci\xF2 aiuta i LLM downstream o gli agenti web a navigare nella pagina o a intraprendere ulteriori azioni.'])},markdown:e=>{const{normalize:i}=e;return i(["Ribasso"])},markdown_explain:e=>{const{normalize:i}=e;return i(["Restituisce il markdown direttamente dall'HTML, ignorando il componente di leggibilit\xE0."])},mode:e=>{const{normalize:i}=e;return i(["Modalit\xE0 di lettura o ricerca"])},mode_explain:e=>{const{normalize:i}=e;return i(["La modalit\xE0 di lettura consente di accedere al contenuto di un URL, mentre la modalit\xE0 di ricerca consente di cercare una query sul Web, applicando la modalit\xE0 di lettura a ciascun URL dei risultati di ricerca."])},no_cache:e=>{const{normalize:i}=e;return i(["Bypassa la cache"])},no_cache_explain:e=>{const{normalize:i}=e;return i(["Il nostro server API memorizza nella cache sia i contenuti in modalit\xE0 Lettura che quelli in modalit\xE0 Ricerca per un certo periodo di tempo. Per ignorare questa cache, imposta questa intestazione su true."])},proxy_server:e=>{const{normalize:i}=e;return i(["Utilizza un server proxy"])},proxy_server_explain:e=>{const{normalize:i}=e;return i(["Il nostro server API pu\xF2 utilizzare il tuo proxy per accedere agli URL, il che \xE8 utile per le pagine accessibili solo tramite proxy specifici."])},return_format:e=>{const{normalize:i}=e;return i(["Livello di dettagli"])},return_format_explain:e=>{const{normalize:i}=e;return i(["Puoi controllare il livello di dettaglio nella risposta per evitare un filtro eccessivo. La pipeline predefinita \xE8 ottimizzata per la maggior parte dei siti Web e per l'input LLM."])},screenshot:e=>{const{normalize:i}=e;return i(["Immagine dello schermo"])},screenshot_explain:e=>{const{normalize:i}=e;return i(["Restituisce l'URL dello screenshot della pagina web."])},set_cookie:e=>{const{normalize:i}=e;return i(["Cookie in avanti"])},set_cookie_explain:e=>{const{normalize:i}=e;return i(["Il nostro server API pu\xF2 inoltrare le tue impostazioni personalizzate dei cookie quando accedi all'URL, il che \xE8 utile per le pagine che richiedono un'autenticazione aggiuntiva. Tieni presente che le richieste con cookie non verranno memorizzate nella cache."])},stream_mode:e=>{const{normalize:i}=e;return i(["Modalit\xE0 flusso"])},stream_mode_explain:e=>{const{normalize:i}=e;return i(["La modalit\xE0 streaming \xE8 vantaggiosa per le pagine di destinazione di grandi dimensioni, poich\xE9 consente pi\xF9 tempo per il rendering completo della pagina. Se la modalit\xE0 standard genera contenuti incompleti, prendi in considerazione l'utilizzo della modalit\xE0 Stream."])},target_selector:e=>{const{normalize:i}=e;return i(["Selettore di destinazione"])},target_selector_explain:e=>{const{normalize:i}=e;return i(["Fornisci un selettore CSS per concentrarti su una parte pi\xF9 specifica della pagina. Utile quando il contenuto desiderato non viene visualizzato nelle impostazioni predefinite."])},text:e=>{const{normalize:i}=e;return i(["Testo"])},text_explain:e=>{const{normalize:i}=e;return i(["Restituisce document.body.innerText."])},wait_for_selector:e=>{const{normalize:i}=e;return i(["Attendi il selettore"])},wait_for_selector_explain:e=>{const{normalize:i}=e;return i(["Attendi che venga visualizzato un elemento specifico prima di tornare. Utile quando il contenuto desiderato non viene visualizzato nelle impostazioni predefinite."])},x_timeout:e=>{const{normalize:i}=e;return i(["Timeout personalizzato"])},x_timeout_explain:e=>{const{normalize:i}=e;return i(["Pu\xF2 essere utile quando la pagina \xE8 troppo lenta per il rendering. Per l'endpoint di ricerca, \xE8 il tempo massimo di attesa per la lettura di tutti i risultati della ricerca."])}},how_to_stream:e=>{const{normalize:i}=e;return i(["Per elaborare il contenuto non appena diventa disponibile, imposta l'intestazione della richiesta sulla modalit\xE0 streaming. Ci\xF2 riduce al minimo il tempo necessario alla ricezione del primo byte. Esempio nell'arricciatura:"])},how_to_use1:e=>{const{normalize:i}=e;return i(["Aggiungi <code>https://r.jina.ai/</code> a qualsiasi URL nel tuo codice o strumento in cui \xE8 previsto l'accesso LLM. Ci\xF2 restituir\xE0 il contenuto principale della pagina in un testo pulito e compatibile con LLM."])},how_to_use2:e=>{const{normalize:i}=e;return i(["Aggiungi <code>https://s.jina.ai/</code> alla tua query. Questo chiamer\xE0 il motore di ricerca e restituir\xE0 i primi 5 risultati con i relativi URL e contenuti, ciascuno in testo pulito e compatibile con LLM."])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di pi\xF9"])},open:e=>{const{normalize:i}=e;return i(["Apri in una nuova scheda"])},raw_html:e=>{const{normalize:i}=e;return i(["HTML grezzo"])},reader_output:e=>{const{normalize:i}=e;return i(["Uscita del lettore"])},reader_response:e=>{const{normalize:i}=e;return i(["La risposta del lettore"])},reader_search_hint:e=>{const{normalize:i}=e;return i(["Se utilizzi questo URL nel codice, non dimenticare di codificare l'URL."])},reader_url:e=>{const{normalize:i}=e;return i(["URL del lettore"])},reader_url_hint:e=>{const{normalize:i}=e;return i(["Fai clic di seguito per ottenere il contenuto tramite la nostra API Reader"])},search_query_rewrite:e=>{const{normalize:i}=e;return i(["Tieni presente che, a differenza della demo mostrata sopra, in pratica non cerchi la domanda originale sul web per il grounding. Ci\xF2 che le persone fanno spesso \xE8 riscrivere la domanda originale o utilizzare domande multi-hop. Leggono i risultati recuperati e quindi generano ulteriori query per raccogliere pi\xF9 informazioni necessarie prima di arrivare a una risposta finale."])},show_read_demo:e=>{const{normalize:i}=e;return i(["Scopri come Reader legge un URL"])},show_search_demo:e=>{const{normalize:i}=e;return i(["Scopri come Reader effettua ricerche sul Web"])},standard_usage:e=>{const{normalize:i}=e;return i(["Utilizzo standard"])},stream_mode:e=>{const{normalize:i}=e;return i(["Modalit\xE0 flusso"])},stream_mode_explain:e=>{const{normalize:i}=e;return i(["La modalit\xE0 stream \xE8 utile quando la pagina di destinazione \xE8 grande da visualizzare. Se ritieni che la modalit\xE0 standard ti fornisca contenuti incompleti, prova la modalit\xE0 streaming."])},stream_mode_explain1:e=>{const{normalize:i}=e;return i(["La modalit\xE0 streaming \xE8 utile quando si riscontra che la modalit\xE0 standard fornisce un risultato incompleto. Questo perch\xE9 la modalit\xE0 streaming attender\xE0 un po' pi\xF9 a lungo finch\xE9 la pagina non sar\xE0 completamente renderizzata. Utilizza l'intestazione di accettazione per attivare/disattivare la modalit\xE0 di streaming:"])},tagline:e=>{const{normalize:i}=e;return i(["Prova la demo"])},try_demo:e=>{const{normalize:i}=e;return i(["Dimostrazione"])},use_headers:e=>{const{normalize:i}=e;return i(["Il comportamento dell'API Reader pu\xF2 essere controllato con le intestazioni della richiesta. Ecco un elenco completo delle intestazioni supportate."])},waiting_for_reader:e=>{const{normalize:i}=e;return i(["In attesa prima del risultato dell'API Reader..."])},your_query:e=>{const{normalize:i}=e;return i(["Inserisci la tua domanda"])},your_query_hint:e=>{const{normalize:i}=e;return i(["Digita una domanda che richiede le informazioni pi\xF9 recenti o la conoscenza del mondo."])},your_url:e=>{const{normalize:i}=e;return i(["Inserisci il tuo URL"])},your_url_hint:e=>{const{normalize:i}=e;return i(["Fai clic di seguito per recuperare direttamente il codice sorgente della pagina"])}},description:e=>{const{normalize:i}=e;return i(["Leggi gli URL o cerca sul Web, ottieni basi migliori per i LLM."])},dont_panic_api_key_is_free:e=>{const{normalize:i}=e;return i(["Niente panico! Ogni nuova chiave API contiene un milione di token gratuiti!"])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i([`L'API Reader \xE8 gratuita e non richiede una chiave API. Basta anteporre "https://r.jina.ai/" al tuo URL.`])},answer10:e=>{const{normalize:i}=e;return i(["No, l'API Reader pu\xF2 elaborare solo contenuti provenienti da URL accessibili pubblicamente."])},answer11:e=>{const{normalize:i}=e;return i(["Se richiedi lo stesso URL entro 5 minuti, l'API Reader restituir\xE0 il contenuto memorizzato nella cache."])},answer12:e=>{const{normalize:i}=e;return i(["Sfortunatamente no."])},answer13:e=>{const{normalize:i}=e;return i(["S\xEC, puoi utilizzare il supporto PDF nativo dal Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) o utilizzare la versione HTML da arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)"])},answer14:e=>{const{normalize:i}=e;return i([`Reader sottotitola tutte le immagini all'URL specificato e aggiunge "Immagine [idx]: [didascalia]" come tag alt (se inizialmente ne manca uno). Ci\xF2 consente ai LLM a valle di interagire con le immagini nel ragionamento, nel riepilogo, ecc.`])},answer15:e=>{const{normalize:i}=e;return i(["L'API Reader \xE8 progettata per essere altamente scalabile. Viene ridimensionato automaticamente in base al traffico in tempo reale e il numero massimo di richieste simultanee \xE8 ora di circa 4000. Lo manteniamo attivamente come uno dei prodotti principali di Jina AI. Quindi sentitevi liberi di usarlo in produzione."])},answer16:e=>{const{normalize:i}=e;return i(["Puoi trovare le informazioni pi\xF9 recenti sui limiti di tariffa nella tabella seguente. Tieni presente che stiamo lavorando attivamente per migliorare il limite di velocit\xE0 e le prestazioni dell'API Reader, la tabella verr\xE0 aggiornata di conseguenza."])},answer2:e=>{const{normalize:i}=e;return i(["L'API Reader utilizza un proxy per recuperare qualsiasi URL, visualizzandone il contenuto in un browser per estrarre contenuti principali di alta qualit\xE0."])},answer3:e=>{const{normalize:i}=e;return i(["S\xEC, l'API Reader \xE8 open source e disponibile nel repository Jina AI GitHub."])},answer4:e=>{const{normalize:i}=e;return i(["L'API Reader generalmente elabora gli URL e restituisce il contenuto entro 2 secondi, sebbene le pagine complesse o dinamiche potrebbero richiedere pi\xF9 tempo."])},answer5:e=>{const{normalize:i}=e;return i(["Lo scraping pu\xF2 essere complicato e inaffidabile, in particolare con pagine complesse o dinamiche. L'API Reader fornisce un output ottimizzato e affidabile di testo pulito e pronto per LLM."])},answer6:e=>{const{normalize:i}=e;return i(["L'API Reader restituisce il contenuto nella lingua originale dell'URL. Non fornisce servizi di traduzione."])},answer7:e=>{const{normalize:i}=e;return i(["Se riscontri problemi di blocco, contatta il nostro team di supporto per assistenza e risoluzione."])},answer8:e=>{const{normalize:i}=e;return i(["Sebbene progettata principalmente per le pagine Web, l'API Reader pu\xF2 estrarre contenuto dai PDF visualizzati in formato HTML su siti Web come arXiv, ma non \xE8 ottimizzata per l'estrazione PDF generale."])},answer9:e=>{const{normalize:i}=e;return i(["Attualmente, l'API Reader non elabora i contenuti multimediali, ma i miglioramenti futuri includeranno i sottotitoli delle immagini e il riepilogo dei video."])},question1:e=>{const{normalize:i}=e;return i(["Quali sono i costi associati all'utilizzo dell'API Reader?"])},question10:e=>{const{normalize:i}=e;return i(["\xC8 possibile utilizzare l'API Reader su file HTML locali?"])},question11:e=>{const{normalize:i}=e;return i(["L'API Reader memorizza nella cache il contenuto?"])},question12:e=>{const{normalize:i}=e;return i(["Posso utilizzare l'API Reader per accedere ai contenuti dietro un login?"])},question13:e=>{const{normalize:i}=e;return i(["Posso utilizzare l'API Reader per accedere ai PDF su arXiv?"])},question14:e=>{const{normalize:i}=e;return i(["Come funziona la didascalia delle immagini in Reader?"])},question15:e=>{const{normalize:i}=e;return i(["Qual \xE8 la scalabilit\xE0 del Reader? Posso usarlo in produzione?"])},question16:e=>{const{normalize:i}=e;return i(["Qual \xE8 il limite di velocit\xE0 dell'API Reader?"])},question2:e=>{const{normalize:i}=e;return i(["Come funziona l'API Reader?"])},question3:e=>{const{normalize:i}=e;return i(["L'API Reader \xE8 open source?"])},question4:e=>{const{normalize:i}=e;return i(["Qual \xE8 la latenza tipica per l'API Reader?"])},question5:e=>{const{normalize:i}=e;return i(["Perch\xE9 dovrei utilizzare l'API Reader invece di raschiare la pagina da solo?"])},question6:e=>{const{normalize:i}=e;return i(["L'API Reader supporta pi\xF9 lingue?"])},question7:e=>{const{normalize:i}=e;return i(["Cosa devo fare se un sito web blocca l'API Reader?"])},question8:e=>{const{normalize:i}=e;return i(["L'API Reader pu\xF2 estrarre il contenuto dai file PDF?"])},question9:e=>{const{normalize:i}=e;return i(["L'API Reader pu\xF2 elaborare i contenuti multimediali dalle pagine Web?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative ai lettori"])}},fast:e=>{const{normalize:i}=e;return i(["Veloce"])},fast_stream:e=>{const{normalize:i}=e;return i(["Streaming immediato dei dati"])},fast_stream_description:e=>{const{normalize:i}=e;return i(["Hai bisogno di dati velocemente? La nostra API Reader pu\xF2 eseguire lo streaming dei dati per ridurre al minimo la latenza."])},free:e=>{const{normalize:i}=e;return i(["Libero per sempre"])},free_description:e=>{const{normalize:i}=e;return i(["L'API Reader \xE8 gratuita! Non richiede carta di credito o segreto API. Non consumer\xE0 la tua quota di token."])},is_free:e=>{const{normalize:i}=e;return i(["La parte migliore? \xC8 gratis!"])},is_free_description:e=>{const{normalize:i}=e;return i(["L'API Reader \xE8 disponibile gratuitamente e offre limiti di tariffa e prezzi flessibili. Costruito su un'infrastruttura scalabile, offre elevata accessibilit\xE0, concorrenza e affidabilit\xE0. Ci sforziamo di essere la soluzione di messa a terra preferita per i tuoi LLM."])},open:e=>{const{normalize:i}=e;return i(["Apri in una nuova scheda"])},original_pdf:e=>{const{normalize:i}=e;return i(["PDF originale"])},rate_limit:e=>{const{normalize:i}=e;return i(["Limite di tariffa"])},reader_also_read_images:e=>{const{normalize:i}=e;return i(["Le immagini sulla pagina Web vengono automaticamente sottotitolate utilizzando un modello di linguaggio visivo nel lettore e formattate come tag alt dell'immagine nell'output. Ci\xF2 fornisce al tuo LLM a valle suggerimenti sufficienti per incorporare tali immagini nei suoi processi di ragionamento e riepilogo. Ci\xF2 significa che puoi porre domande sulle immagini, selezionarne di specifiche o persino inoltrare i loro URL a un VLM pi\xF9 potente per un'analisi pi\xF9 approfondita!"])},reader_description:e=>{const{normalize:i}=e;return i(["Ottieni input compatibili con LLM da un URL o da una ricerca sul Web, semplicemente aggiungendo <code>r.jina.ai</code> davanti."])},reader_do_pdf_explain:e=>{const{normalize:i}=e;return i(["S\xEC, Reader supporta nativamente la lettura di PDF. \xC8 compatibile con la maggior parte dei PDF, compresi quelli con molte immagini, ed \xE8 velocissimo! In combinazione con un LLM, puoi facilmente creare un ChatPDF o un'intelligenza artificiale per l'analisi dei documenti in pochissimo tempo."])},reader_do_search:e=>{const{normalize:i}=e;return i(["Lettore per la ricerca di messa a terra"])},reader_do_search_explain:e=>{const{normalize:i}=e;return i(["Gli LLM hanno un limite di conoscenza, il che significa che non possono accedere alle ultime conoscenze del mondo. Ci\xF2 porta a problemi come disinformazione, risposte obsolete, allucinazioni e altri problemi di fattualit\xE0. La messa a terra \xE8 assolutamente essenziale per le applicazioni GenAI. Reader ti consente di radicare il tuo LLM con le informazioni pi\xF9 recenti dal web. Basta anteporre <code>https://s.jina.ai/</code> alla tua query e Reader effettuer\xE0 una ricerca sul Web e restituir\xE0 i primi cinque risultati con i relativi URL e contenuti, ciascuno in testo pulito e compatibile con LLM. In questo modo, puoi sempre mantenere aggiornato il tuo LLM, migliorarne la fattualit\xE0 e ridurre le allucinazioni."])},reader_reads_images:e=>{const{normalize:i}=e;return i(["Il lettore legge anche le immagini!"])},reader_reads_pdf:e=>{const{normalize:i}=e;return i(["Reader legge anche i PDF!"])},reader_result:e=>{const{normalize:i}=e;return i(["Risultato del lettore"])},table:{td_1_0:e=>{const{normalize:i}=e;return i(["Leggere un URL e restituirne il contenuto, utile per verificare la messa a terra"])},td_1_1:e=>{const{normalize:i}=e;return i(["20 giri al minuto"])},td_1_2:e=>{const{normalize:i}=e;return i(["200 giri al minuto"])},td_1_3:e=>{const{normalize:i}=e;return i(["In base ai token di output"])},td_1_4:e=>{const{normalize:i}=e;return i(["3 secondi"])},td_2_0:e=>{const{normalize:i}=e;return i(["La ricerca sul Web restituisce i primi 5 risultati, utili per radicare la ricerca"])},td_2_1:e=>{const{normalize:i}=e;return i(["5 giri al minuto"])},td_2_2:e=>{const{normalize:i}=e;return i(["40 giri al minuto"])},td_2_3:e=>{const{normalize:i}=e;return i(["In base ai token di output per tutti e 5 i risultati della ricerca"])},td_2_4:e=>{const{normalize:i}=e;return i(["10 secondi"])},th0:e=>{const{normalize:i}=e;return i(["Punto finale"])},th1:e=>{const{normalize:i}=e;return i(["Descrizione"])},th2:e=>{const{normalize:i}=e;return i(["Limite di velocit\xE0 senza chiave API"])},th3:e=>{const{normalize:i}=e;return i(["Limite di velocit\xE0 con chiave API"])},th4:e=>{const{normalize:i}=e;return i(["Schema di conteggio dei token"])},th5:e=>{const{normalize:i}=e;return i(["Latenza media"])}},title:e=>{const{normalize:i}=e;return i(["API del lettore"])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},usage_details_false:e=>{const{normalize:i}=e;return i(["Mostra solo gli utilizzi di base"])},usage_details_null:e=>{const{normalize:i}=e;return i(["Mostra gli usi di base e avanzati"])},usage_details_true:e=>{const{normalize:i}=e;return i(["Mostra solo gli usi avanzati"])},want_higher_rate_limit:e=>{const{normalize:i}=e;return i(["Desideri un limite di velocit\xE0 pi\xF9 elevato fino a 1000 RPM? Possiamo supportarti!"])},what_is1:e=>{const{normalize:i}=e;return i(["Cos'\xE8 Reader?"])},what_is_answer_long:e=>{const{normalize:i}=e;return i(["L'inserimento delle informazioni web nei LLM \xE8 un passo importante per radicarsi, ma pu\xF2 essere impegnativo. Il metodo pi\xF9 semplice \xE8 raschiare la pagina web e alimentare l'HTML grezzo. Tuttavia, lo scraping pu\xF2 essere complesso e spesso bloccato e l'HTML grezzo \xE8 ingombro di elementi estranei come markup e script. L'API Reader risolve questi problemi estraendo il contenuto principale da un URL e convertendolo in testo pulito e compatibile con LLM, garantendo input di alta qualit\xE0 per il tuo agente e i sistemi RAG."])},what_is_desc:e=>{const{normalize:i}=e;return i(["Un proxy che accede a qualsiasi URL e trasforma il contenuto principale in testo semplice ottimizzato per LLM."])}},recommender:{confirm_message:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Nella tua chiave API restano ",n(o("_leftTokens"))," token. L'invio del testo completo degli articoli ",n(o("_numArticles"))," all'API Reranker, utilizzando il modello ",n(o("_selectedReranker"))," per scoprire articoli correlati per la pagina corrente, ridurr\xE0 in modo significativo il conteggio dei token della tua chiave API ",n(o("_APIKey")),". Vuoi procedere?"])},confirm_title:e=>{const{normalize:i}=e;return i(["Avvertenza: utilizzo elevato di token"])},out_of_quota:e=>{const{normalize:i}=e;return i(["Questa chiave API ha esaurito i token. Ricarica il tuo account o utilizza una chiave API diversa."])},recommend:e=>{const{normalize:i}=e;return i(["Ottieni i primi 5 correlati"])},recommended_articles:e=>{const{normalize:i}=e;return i(["I 5 articoli pi\xF9 correlati"])}},reranker:{benchmark:{description0:e=>{const{normalize:i}=e;return i(["LlamaIndex ha valutato varie combinazioni di incorporamenti e reranker per RAG, conducendo uno studio di replica che ha misurato il rango reciproco medio. I risultati evidenziano il significativo miglioramento della qualit\xE0 della ricerca apportato da Jina Reranker, un vantaggio indipendente dagli specifici incorporamenti utilizzati."])},description1:e=>{const{normalize:i}=e;return i(["BIER (Benchmarking IR) valuta l'efficacia del recupero di un modello, inclusi la pertinenza e l'NDCG. Un punteggio BIER pi\xF9 elevato \xE8 correlato a corrispondenze e classifiche dei risultati di ricerca pi\xF9 accurate."])},description2:e=>{const{normalize:i}=e;return i(["Attraverso il benchmark LoCo, abbiamo misurato la comprensione di un modello della coerenza e del contesto locale, insieme alla classificazione specifica della query. Un punteggio LoCo pi\xF9 alto riflette una migliore capacit\xE0 di identificare e dare priorit\xE0 alle informazioni rilevanti."])},description3:e=>{const{normalize:i}=e;return i(["L'MTEB (Multilingual Text Embedding Benchmark), nel complesso, mette alla prova le capacit\xE0 di un modello negli incorporamenti di testo, inclusi clustering, classificazione, recupero e altri parametri. Tuttavia, per il nostro confronto, abbiamo utilizzato solo le attivit\xE0 di riclassificazione di MTEB."])},title:e=>{const{normalize:i}=e;return i(["Segno di riferimento"])},title0:e=>{const{normalize:i}=e;return i(["LlamaIndex"])},title1:e=>{const{normalize:i}=e;return i(["BEIR"])},title2:e=>{const{normalize:i}=e;return i(["LoCo"])},title3:e=>{const{normalize:i}=e;return i(["MTEB"])}},benchmark_description:e=>{const{normalize:i}=e;return i(["Per fare un confronto, abbiamo incluso nel benchmark altri tre principali reranker di BGE (BAAI), BCE (Netease Youdao) e Cohere. Come mostrato dai risultati di seguito, Jina Reranker detiene il punteggio medio pi\xF9 alto in tutte le categorie rilevanti per il riranking, rendendolo un chiaro leader tra i suoi pari."])},benchmark_title:e=>{const{normalize:i}=e;return i(["Benchmark delle prestazioni"])},choose_turbo:e=>{const{normalize:i}=e;return i(["Ottieni una velocit\xE0 fino a 5 volte superiore con reranker-turbo"])},choose_turbo_description:e=>{const{normalize:i}=e;return i(["Offriamo anche due nuovi modelli di reranker open source: jina-reranker-v1-turbo-en e jina-reranker-v1-tiny-en, quest'ultimo ha solo 30 milioni di parametri e quattro livelli. Questi due nuovi reranker godono di una velocit\xE0 di inferenza 5 volte pi\xF9 veloce rispetto al modello base con un costo molto basso in termini di qualit\xE0. Sono perfetti per le applicazioni che richiedono il riclassificazione in tempo reale. Leggi il benchmark qui sotto."])},customize_urself:e=>{const{normalize:i}=e;return i(["Cambialo e guarda come cambia la risposta!"])},customize_urself_pl:e=>{const{normalize:i}=e;return i(["Cambiali e guarda come cambia la risposta!"])},description:e=>{const{normalize:i}=e;return i(["Massimizza facilmente la pertinenza della ricerca e la precisione RAG."])},description_rich:e=>{const{normalize:i}=e;return i(["Massimizza la pertinenza della ricerca e l'accuratezza del RAG con la nostra API di riclassificazione all'avanguardia. Inizia con 1 milione di token gratuiti."])},example_input_document:e=>{const{normalize:i}=e;return i(["Esempi di documenti candidati da classificare"])},example_input_query:e=>{const{normalize:i}=e;return i(["Interrogazione di esempio"])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i(["I prezzi per l'API Reranker sono in linea con la nostra struttura dei prezzi dell'API Embedding. Si inizia con 1 milione di token gratuiti per ogni nuova chiave API. Oltre ai token gratuiti, sono disponibili per l'acquisto diversi pacchetti. Per maggiori dettagli, visita la nostra sezione prezzi."])},answer10:e=>{const{normalize:i}=e;return i(["S\xEC, Jina Reranker pu\xF2 essere distribuito su AWS. Se hai bisogno di una distribuzione locale in un ambiente aziendale, puoi farlo facilmente tramite la nostra offerta AWS Marketplace."])},answer11:e=>{const{normalize:i}=e;return i(["Se sei interessato a un reranking ottimizzato su misura per dati di dominio specifici, contatta il nostro team di vendita. Il nostro team risponder\xE0 tempestivamente alla tua richiesta."])},answer3:e=>{const{normalize:i}=e;return i(["La differenza principale sta nella loro architettura. Per quanto riguarda le prestazioni, consigliamo jina-reranker-v1, che \xE8 stato ampiamente testato e confrontato con la concorrenza. Jina-reranker-v1 utilizza un'architettura cross-encoder, mentre Jina-colbert-v1 si basa sull'architettura ColBERTv2 ma estende la lunghezza del contesto sia della query che del documento a 8192, ottenendo prestazioni ancora migliori rispetto al modello ColBERTv2 originale."])},answer4:e=>{const{normalize:i}=e;return i(["S\xEC, jina-colbert-v1 \xE8 open source ed \xE8 possibile accedervi tramite Huggingface. Tuttavia, jina-reranker-v1 non \xE8 open source."])},answer5:e=>{const{normalize:i}=e;return i(["Attualmente supporta solo l'inglese. Tuttavia, alcuni utenti hanno segnalato che funziona bene anche con il cinese. Ci\xF2 potrebbe essere in parte dovuto al fatto che jina-reranker-v1-base-en condivide alcuni pesi con il nostro modello di incorporamento jina-embeddings-v2-base-zh."])},answer6:e=>{const{normalize:i}=e;return i(["La lunghezza massima del token di query \xE8 512. Non esiste alcun limite di token per i documenti."])},answer7:e=>{const{normalize:i}=e;return i(["Puoi riclassificare fino a 2048 documenti per query."])},answer8:e=>{const{normalize:i}=e;return i(["Non esiste il concetto di dimensione batch a differenza della nostra API di incorporamento. \xC8 possibile inviare solo una tupla di documento di query per richiesta, ma la tupla pu\xF2 includere fino a 2048 documenti candidati."])},answer9:e=>{const{normalize:i}=e;return i(["La latenza varia da 100 millisecondi a 7 secondi, a seconda in gran parte della lunghezza dei documenti e della query. Ad esempio, la riclassificazione di 100 documenti di 256 token ciascuno con una query da 64 token richiede circa 150 millisecondi. Aumentando la lunghezza del documento a 4096 token, il tempo aumenta a 3,5 secondi. Se la lunghezza della query viene aumentata a 512 token, il tempo aumenta ulteriormente a 7 secondi."])},question1:e=>{const{normalize:i}=e;return i(["Quanto costa l'API Reranker?"])},question10:e=>{const{normalize:i}=e;return i(["Posso distribuire Jina Reranker su AWS?"])},question11:e=>{const{normalize:i}=e;return i(["Offrite un reranking ottimizzato sui dati specifici del dominio?"])},question3:e=>{const{normalize:i}=e;return i(["Qual \xE8 la differenza tra i due reranker?"])},question4:e=>{const{normalize:i}=e;return i(["Jina Reranker \xE8 open source?"])},question5:e=>{const{normalize:i}=e;return i(["Il reranker supporta pi\xF9 lingue?"])},question6:e=>{const{normalize:i}=e;return i(["Qual \xE8 la lunghezza massima per query e documenti?"])},question7:e=>{const{normalize:i}=e;return i(["Qual \xE8 il numero massimo di documenti che posso riclassificare per query?"])},question8:e=>{const{normalize:i}=e;return i(["Qual \xE8 la dimensione del batch e quante tuple di documenti di query posso inviare in una richiesta?"])},question9:e=>{const{normalize:i}=e;return i(["Quale latenza posso aspettarmi quando riclassifico 100 documenti?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative al riclassificazione"])}},feature_on_premises_description2:e=>{const{normalize:i}=e;return i(["Distribuisci Jina Reranker su AWS Sagemaker e presto anche su Microsoft Azure e sui servizi cloud di Google oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_on_premises_description3:e=>{const{normalize:i}=e;return i(["Distribuisci Jina Reranker su AWS Sagemaker e Microsoft Azure e presto nei servizi cloud di Google, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_solid_description:e=>{const{normalize:i}=e;return i(["Sviluppato dalla nostra ricerca accademica all'avanguardia e rigorosamente testato rispetto ai reranker SOTA per garantire prestazioni senza precedenti."])},how_it_works:e=>{const{normalize:i}=e;return i(["Ecco come funziona:"])},how_it_works_v1:{description1:e=>{const{normalize:i}=e;return i(["Un sistema di ricerca utilizza embeddings/BM25 per trovare un'ampia serie di documenti potenzialmente rilevanti in base alla query dell'utente."])},description2:e=>{const{normalize:i}=e;return i(["Il reranker prende quindi questi risultati e li analizza a un livello pi\xF9 granulare, considerando le sfumature di come i termini della query interagiscono con il contenuto del documento."])},description3:e=>{const{normalize:i}=e;return i(["Riordina i risultati della ricerca, posizionando quelli che ritiene pi\xF9 rilevanti in alto, sulla base di questa analisi pi\xF9 approfondita."])},title1:e=>{const{normalize:i}=e;return i(["Recupero iniziale"])},title2:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},title3:e=>{const{normalize:i}=e;return i(["Risultati migliorati"])}},improve_performance:e=>{const{normalize:i}=e;return i(["Miglioramento garantito rispetto alla ricerca vettoriale"])},improve_performance_description:e=>{const{normalize:i}=e;return i(["Le nostre valutazioni hanno dimostrato miglioramenti per i sistemi di ricerca che utilizzano Jina Reranker con +8% nel tasso di successo e +33% nel ranking reciproco medio."])},learning1:e=>{const{normalize:i}=e;return i(["Imparare a conoscere Reranker"])},learning1_description:e=>{const{normalize:i}=e;return i(["Cos'\xE8 un reranker? Perch\xE9 la ricerca vettoriale o la somiglianza del coseno non sono sufficienti? Scopri i reranker da zero con la nostra guida completa."])},read_more_about_benchmark:e=>{const{normalize:i}=e;return i(["Ulteriori informazioni sul benchmark"])},read_more_about_turbo:e=>{const{normalize:i}=e;return i(["Maggiori informazioni sui modelli turbo e tiny"])},read_more_about_v2:e=>{const{normalize:i}=e;return i(["Jina Reranker v2 \xE8 il miglior reranker della categoria rilasciato il 25 giugno 2024; \xE8 costruito per Agentic RAG. \xC8 dotato di supporto per chiamate di funzioni, recupero multilingue per oltre 100 lingue, funzionalit\xE0 di ricerca di codice e offre una velocit\xE0 6 volte superiore rispetto alla versione v1. Ulteriori informazioni sul modello v2."])},reranker_description:e=>{const{normalize:i}=e;return i(["Prova la nostra API di riclassificazione all'avanguardia per massimizzare la pertinenza della ricerca e la precisione del RAG. A partire gratis!"])},show_v2benchmark:e=>{const{normalize:i}=e;return i(["Mostra benchmark per il modello v2 (pi\xF9 recente)"])},table:{number_token_document:e=>{const{normalize:i}=e;return i(["Numero di token in ciascun documento"])},number_token_query:e=>{const{normalize:i}=e;return i(["Numero di token nella query"])},title:e=>{const{normalize:i}=e;return i(["Di seguito \xE8 riportato il tempo impiegato per riclassificare una query e 100 documenti in millisecondi:"])}},title:e=>{const{normalize:i}=e;return i(["API di riclassificazione"])},top_n:e=>{const{normalize:i}=e;return i(["Numero di documenti restituiti"])},top_n_explain:e=>{const{normalize:i}=e;return i(["Il numero di documenti pi\xF9 rilevanti da restituire per la query."])},try_embedding:e=>{const{normalize:i}=e;return i(["Prova a incorporare l'API gratuitamente"])},try_reranker:e=>{const{normalize:i}=e;return i(["Prova gratuitamente l'API reranker"])},v2_features:{description1:e=>{const{normalize:i}=e;return i(["Reranker v2 consente il recupero di documenti in oltre 100 lingue, indipendentemente dalla lingua della query."])},description2:e=>{const{normalize:i}=e;return i(["Reranker v2 classifica i frammenti di codice e le firme delle funzioni in base a query in linguaggio naturale, ideali per le applicazioni Agentic RAG."])},description3:e=>{const{normalize:i}=e;return i(["Reranker v2 classifica le tabelle pi\xF9 rilevanti in base a query in linguaggio naturale, aiutando a ordinare diversi schemi di tabelle e a identificare quello pi\xF9 rilevante prima di generare una query SQL."])},title1:e=>{const{normalize:i}=e;return i(["Recupero multilingue"])},title2:e=>{const{normalize:i}=e;return i(["Chiamata di funzioni e ricerca di codici"])},title3:e=>{const{normalize:i}=e;return i(["Supporto dati tabulari e strutturati"])}},v2benchmark:{descBeir:e=>{const{normalize:i}=e;return i(["Punteggi NDCG 10 riportati per diversi modelli di riclassificazione per il set di dati Beir"])},descCodeSearchNet:e=>{const{normalize:i}=e;return i(["Punteggi MRR 10 riportati per diversi modelli di riclassificazione per il set di dati CodeSearchNet"])},descMKQA:e=>{const{normalize:i}=e;return i(["Richiama 10 punteggi riportati per diversi modelli di riclassificazione per il set di dati MKQA"])},descNSText2SQL:e=>{const{normalize:i}=e;return i(["Richiama 3 punteggi riportati per diversi modelli di riclassificazione per il set di dati NSText2SQL"])},descRTX4090:e=>{const{normalize:i}=e;return i(["Punteggi di throughput (documenti recuperati in 50 ms) riportati per diversi modelli di riclassificazione su una GPU RTX 4090."])},descToolBench:e=>{const{normalize:i}=e;return i(["Richiama 3 punteggi riportati per diversi modelli di riclassificazione per il set di dati ToolBench"])},titleBeir:e=>{const{normalize:i}=e;return i(["BEIR (Benchmark eterogeneo su diversi compiti IR)"])},titleCodeSearchNet:e=>{const{normalize:i}=e;return i(["CodeSearchNet. Il benchmark \xE8 una combinazione di query in formato docstring e linguaggio naturale, con segmenti di codice etichettati pertinenti alle query."])},titleMKQA:e=>{const{normalize:i}=e;return i(["MKQA (Domande e risposte sulla conoscenza multilingue)"])},titleNSText2SQL:e=>{const{normalize:i}=e;return i(["NSText2SQL"])},titleRTX4090:e=>{const{normalize:i}=e;return i(["Velocit\xE0 effettiva di Jina Reranker v2 su RTX4090"])},titleToolBench:e=>{const{normalize:i}=e;return i(["Banco degli attrezzi. Il benchmark raccoglie oltre 16mila API pubbliche e le corrispondenti istruzioni generate sinteticamente per utilizzarle in impostazioni API singole e multi-API."])}},vs_table:{col0:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},col0_1:e=>{const{normalize:i}=e;return i(["Maggiore precisione e pertinenza della ricerca"])},col0_2:e=>{const{normalize:i}=e;return i(["Filtraggio iniziale rapido"])},col0_3:e=>{const{normalize:i}=e;return i(["Recupero generale del testo attraverso query ad ampio raggio"])},col1:e=>{const{normalize:i}=e;return i(["Ricerca vettoriale"])},col1_1:e=>{const{normalize:i}=e;return i(["Dettagliato: documento secondario e segmento di query"])},col1_2:e=>{const{normalize:i}=e;return i(["Ampio: interi documenti"])},col1_3:e=>{const{normalize:i}=e;return i(["Intermedio: vari segmenti di testo"])},col2:e=>{const{normalize:i}=e;return i(["BM25"])},col2_1:e=>{const{normalize:i}=e;return i(["Alto"])},col2_2:e=>{const{normalize:i}=e;return i(["medio"])},col2_3:e=>{const{normalize:i}=e;return i(["Basso"])},col3_1:e=>{const{normalize:i}=e;return i(["Non richiesto"])},col3_2:e=>{const{normalize:i}=e;return i(["Alto"])},col3_3:e=>{const{normalize:i}=e;return i(["Basso, utilizza un indice predefinito"])},col4_1:e=>{const{normalize:i}=e;return i(["Alto"])},col4_2:e=>{const{normalize:i}=e;return i(["Alto"])},col4_3:e=>{const{normalize:i}=e;return i(["Non richiesto"])},col5_1:e=>{const{normalize:i}=e;return i(["Superiore per query sfumate"])},col5_2:e=>{const{normalize:i}=e;return i(["In equilibrio tra efficienza e precisione"])},col5_3:e=>{const{normalize:i}=e;return i(["Coerente e affidabile per un'ampia gamma di query"])},col6_1:e=>{const{normalize:i}=e;return i(["Altamente accurato con una profonda comprensione del contesto"])},col6_2:e=>{const{normalize:i}=e;return i(["Veloce ed efficiente, con una precisione moderata"])},col6_3:e=>{const{normalize:i}=e;return i(["Altamente scalabile, con efficacia consolidata"])},col7_1:e=>{const{normalize:i}=e;return i(["Ad alta intensit\xE0 di risorse con implementazione complessa"])},col7_2:e=>{const{normalize:i}=e;return i(["Potrebbe non acquisire il contesto o le sfumature approfondite della query"])},col7_3:e=>{const{normalize:i}=e;return i(["Potrebbe avere prestazioni inferiori per ricerche altamente specifiche o contestuali"])},header0:e=>{const{normalize:i}=e;return i(["Ideale per"])},header1:e=>{const{normalize:i}=e;return i(["Granularit\xE0"])},header2:e=>{const{normalize:i}=e;return i(["Complessit\xE0 temporale delle query"])},header3:e=>{const{normalize:i}=e;return i(["Complessit\xE0 temporale dell'indicizzazione"])},header4:e=>{const{normalize:i}=e;return i(["Complessit\xE0 del tempo di allenamento"])},header5:e=>{const{normalize:i}=e;return i(["Ricerca di qualit\xE0"])},header6:e=>{const{normalize:i}=e;return i(["Punti di forza"])},header7:e=>{const{normalize:i}=e;return i(["Punti deboli"])},subtitle:e=>{const{normalize:i}=e;return i(["La tabella seguente fornisce un confronto completo tra Reranker, ricerca di vettori/incorporamenti e BM25, evidenziandone i punti di forza e di debolezza nelle varie categorie."])},title:e=>{const{normalize:i}=e;return i(["Confronto tra Reranker, Ricerca vettoriale e BM25"])}},what_is:e=>{const{normalize:i}=e;return i(["Cos'\xE8 un reranker?"])},what_is_answer_long:e=>{const{normalize:i}=e;return i([`L'obiettivo di un sistema di ricerca \xE8 trovare i risultati pi\xF9 pertinenti in modo rapido ed efficiente. Tradizionalmente, metodi come BM25 o tf-idf sono stati utilizzati per classificare i risultati di ricerca in base alla corrispondenza delle parole chiave. Metodi recenti, come la somiglianza del coseno basata sull'incorporamento, sono stati implementati in molti database vettoriali. Questi metodi sono semplici ma a volte possono non cogliere le sottigliezze del linguaggio e, soprattutto, l'interazione tra i documenti e l'intento di una query.

\xC8 qui che brilla il "reranker". Un reranker \xE8 un modello di intelligenza artificiale avanzato che prende il set iniziale di risultati da una ricerca, spesso forniti da una ricerca basata su incorporamenti/token, e li rivaluta per garantire che siano pi\xF9 allineati con l'intento dell'utente. Si guarda oltre la corrispondenza superficiale dei termini per considerare l'interazione pi\xF9 profonda tra la query di ricerca e il contenuto dei documenti.`])},what_is_answer_long_ending:e=>{const{normalize:i}=e;return i(["Il reranker pu\xF2 migliorare significativamente la qualit\xE0 della ricerca perch\xE9 opera a livello di sottodocumento e sottoquery, il che significa che esamina le singole parole e frasi, i loro significati e il modo in cui si relazionano tra loro all'interno della query e dei documenti. Ci\xF2 si traduce in un insieme di risultati di ricerca pi\xF9 precisi e contestualmente pertinenti."])},what_is_desc:e=>{const{normalize:i}=e;return i(["Un reranker \xE8 un modello di intelligenza artificiale che affina i risultati della ricerca da una ricerca vettoriale o da un modello di recupero denso. Per saperne di pi\xF9."])}},scenex:{caption_image_desc:e=>{const{normalize:i}=e;return i(["Genera una descrizione testuale dell'immagine."])},caption_image_title:e=>{const{normalize:i}=e;return i(["Immagine della didascalia"])},description:e=>{const{normalize:i}=e;return i(["Esplora la narrazione di immagini oltre i pixel"])},example1:e=>{const{normalize:i}=e;return i(["Questo video sembra essere un filmato naturalistico con un affascinante coniglietto bianco e una farfalla in un campo erboso. Il coniglietto viene visto interagire con la farfalla in diversi modi, mostrando la loro relazione unica. L'ambiente naturale offre uno sfondo pittoresco, esaltando la bellezza di questa scena semplice ma accattivante."])},generate_story_desc:e=>{const{normalize:i}=e;return i(["Crea una storia ispirata all'immagine, spesso con dialoghi o monologhi dei suoi personaggi."])},generate_story_title:e=>{const{normalize:i}=e;return i(["Genera storia"])},intro1:e=>{const{normalize:i}=e;return i(["Soluzione AI leader per didascalie di immagini e riepiloghi video"])},json_image_desc:e=>{const{normalize:i}=e;return i(["Genera un formato JSON strutturato dall'immagine utilizzando uno schema predefinito. Ci\xF2 consente l'estrazione di dati specifici dall'immagine."])},json_image_title:e=>{const{normalize:i}=e;return i(["Estrai JSON dall'immagine"])},summarize_video_desc:e=>{const{normalize:i}=e;return i(["Genera un riepilogo conciso del video, evidenziando gli eventi chiave."])},summarize_video_title:e=>{const{normalize:i}=e;return i(["Riepiloga il video"])},visual_q_a_desc:e=>{const{normalize:i}=e;return i(["Rispondi a una domanda in base al contenuto dell'immagine."])},visual_q_a_title:e=>{const{normalize:i}=e;return i(["Domande e risposte visive"])}},searchbar:{ask_on_current_page:e=>{const{normalize:i}=e;return i(["Chiedi alla pagina corrente informazioni su..."])},find_solution:e=>{const{normalize:i}=e;return i(["Genera una soluzione per..."])},hint:e=>{const{normalize:i}=e;return i(["Scrivi la tua domanda qui..."])},hotkey:e=>{const{normalize:i}=e;return i(["Premere il tasto / per effettuare la ricerca in questa pagina"])},hotkey1:e=>{const{normalize:i}=e;return i(["Premere"])},hotkey2:e=>{const{normalize:i}=e;return i(["per attivare"])},hotkey_long1:e=>{const{normalize:i}=e;return i(["In qualsiasi momento, premere"])},hotkey_long3:e=>{const{normalize:i}=e;return i(["per aprire la barra di ricerca"])},more_results:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_numMore"))," altri risultati"])},placeholder:e=>{const{normalize:i}=e;return i(["Fai qualsiasi domanda in questa pagina"])},proposing_solution:e=>{const{normalize:i}=e;return i(["Generazione della risposta in base al contenuto della pagina..."])},required:e=>{const{normalize:i}=e;return i(["Descrivi la tua domanda con maggiori dettagli."])},results:e=>{const{normalize:i}=e;return i(["risultati"])}},searchscape:{description:e=>{const{normalize:i}=e;return i(["Naviga, interagisci, perfeziona: reinventa la scoperta del prodotto"])}},semantic:{description:e=>{const{normalize:i}=e;return i(["Colmare il divario semantico nella tua infrastruttura di ricerca esistente"])}},share:{"Hacker News":e=>{const{normalize:i}=e;return i(["Notizie sugli hacker"])},LinkedIn:e=>{const{normalize:i}=e;return i(["LinkedIn"])},facebook:e=>{const{normalize:i}=e;return i(["Facebook"])},reddit:e=>{const{normalize:i}=e;return i(["Reddit"])},rss:e=>{const{normalize:i}=e;return i(["RSS Feed"])},share_btn:e=>{const{normalize:i}=e;return i(["Condividere"])},twitter:e=>{const{normalize:i}=e;return i(["X (Twitter)"])}},spectrum:{click_to_learn_more:e=>{const{normalize:i}=e;return i(["Clicca per saperne di pi\xF9"])},contextualization:e=>{const{normalize:i}=e;return i(["Contestualizzazione"])},contextualization_desc:e=>{const{normalize:i}=e;return i(["I reranker regolano i risultati della ricerca iniziale in base alla profonda pertinenza contestuale. domanda. Ci\xF2 perfeziona la classifica per corrispondere meglio a ci\xF2 che gli utenti potrebbero trovare utile."])},coreInfra:e=>{const{normalize:i}=e;return i(["Core Infra"])},coreInfra_desc:e=>{const{normalize:i}=e;return i(["Core Infra fornisce un livello cloud-native per lo sviluppo, l'implementazione e l'orchestrazione di modelli di base della ricerca sia nel cloud pubblico che on-premise, consentendo ai servizi di scalare verso l'alto e verso il basso senza sforzo."])},embedding_serving:e=>{const{normalize:i}=e;return i(["Incorporamento della pubblicazione"])},embedding_serving_description:e=>{const{normalize:i}=e;return i(["Fornire incorporamenti tramite un microservizio robusto e scalabile utilizzando tecnologie native del cloud."])},embedding_tech:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},embedding_tech_description:e=>{const{normalize:i}=e;return i([`In Jina AI, sfruttiamo la potenza dell'integrazione della tecnologia per rivoluzionare diverse applicazioni di intelligenza artificiale. Questa tecnologia funge da metodo unificato per rappresentare e comprimere in modo efficiente vari tipi di dati, garantendo l'assenza di perdita di informazioni critiche. Il nostro obiettivo \xE8 trasformare set di dati complessi in un formato di incorporamento universalmente comprensibile, essenziale per un'analisi AI precisa e approfondita.

Gli incorporamenti sono fondamentali, soprattutto in applicazioni come il riconoscimento preciso di immagini e voce, dove aiutano a distinguere dettagli e sfumature a grana fine. Nell'elaborazione del linguaggio naturale, gli incorporamenti migliorano la comprensione del contesto e del sentimento, portando a strumenti di intelligenza artificiale conversazionale e di traduzione linguistica pi\xF9 accurati. Sono inoltre cruciali nello sviluppo di sofisticati sistemi di raccomandazione che richiedono una profonda comprensione delle preferenze degli utenti attraverso diverse forme di contenuto, come testo, audio e video.`])},embedding_tuning:e=>{const{normalize:i}=e;return i(["Incorporamento dell'ottimizzazione"])},embedding_tuning_description:e=>{const{normalize:i}=e;return i(["Ottimizzazione degli incorporamenti di alta qualit\xE0 integrando le competenze del settore per migliorare le prestazioni specifiche delle attivit\xE0."])},embeddings:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},embeddings_desc:e=>{const{normalize:i}=e;return i(["Gli incorporamenti sono i pilastri del moderno sistema di ricerca, rappresentando dati multimodali in vettori di numeri. Questo processo consente una comprensione pi\xF9 sfumata e contestuale dei contenuti, ben oltre la semplice corrispondenza delle parole chiave."])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le Imprese"])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},grounding:e=>{const{normalize:i}=e;return i(["Messa a terra"])},grounding_desc:e=>{const{normalize:i}=e;return i(["Lettore che perfeziona input e risultati attraverso LLM. Migliorano la qualit\xE0, la leggibilit\xE0 e la fattualit\xE0 della risposta finale."])},model_serving:e=>{const{normalize:i}=e;return i(["Modello che serve"])},model_serving_description:e=>{const{normalize:i}=e;return i(["La distribuzione di modelli ottimizzati in un ambiente di produzione, che in genere richiede risorse sostanziali come l'hosting GPU. MLOps, enfatizzando la fornitura di modelli di medie e grandi dimensioni in modo scalabile, efficiente e affidabile."])},model_tuning:e=>{const{normalize:i}=e;return i(["Messa a punto del modello"])},model_tuning_description:e=>{const{normalize:i}=e;return i(["Conosciuto anche come fine tuning, comporta la regolazione dei parametri di un modello preaddestrato su un nuovo set di dati, spesso specifico per attivit\xE0, per migliorarne le prestazioni e adattarlo a un'applicazione specifica."])},personalization:e=>{const{normalize:i}=e;return i(["Personalizzazione"])},personalization_desc:e=>{const{normalize:i}=e;return i(["Utilizzo di dati sintetici guidati dalle istruzioni dell'utente per addestrare automaticamente un modello di incorporamento e riclassificazione specifico del dominio."])},promptOps:e=>{const{normalize:i}=e;return i(["PromptOps"])},promptOps_desc:e=>{const{normalize:i}=e;return i(["Prompt Ops migliora l'input e l'output del sistema di ricerca, compresi quelli utilizzati nell'espansione delle query, nell'input LLM e nella riscrittura dei risultati. Ci\xF2 garantisce che la ricerca sia compresa meglio e dia risultati migliori."])},prompt_serving:e=>{const{normalize:i}=e;return i(["Servizio rapido"])},prompt_serving_description:e=>{const{normalize:i}=e;return i(["Wrapping e fornitura di prompt tramite un'API, senza ospitare modelli pesanti. L'API chiama un servizio di modello di linguaggio di grandi dimensioni pubblico e gestisce l'orchestrazione di input e output in una catena di operazioni."])},prompt_tech:e=>{const{normalize:i}=e;return i(["Ingegneria dei prompt e degli agenti"])},prompt_tech_description:e=>{const{normalize:i}=e;return i([`In Jina AI, riconosciamo che il prompt engineering \xE8 vitale per interagire con modelli linguistici di grandi dimensioni (LLM). Man mano che questi modelli avanzano, la complessit\xE0 dei suggerimenti aumenta, comprendendo ragionamenti e logiche intricati. Questo progresso sottolinea la crescita intrecciata degli LLM e la rapida sofisticazione.

Prevediamo un futuro in cui gli LLM fungeranno da compilatori, con i prompt che diventeranno il nuovo linguaggio di programmazione. Questo cambiamento suggerisce che la futura competenza tecnologica potrebbe concentrarsi maggiormente sulla padronanza tempestiva rispetto alla codifica tradizionale. Il nostro impegno in Jina AI \xE8 quello di guidare in quest'area di trasformazione, rendendo l'intelligenza artificiale avanzata accessibile e pratica per l'uso quotidiano attraverso la padronanza di questo "linguaggio" emergente.`])},prompt_tuning:e=>{const{normalize:i}=e;return i(["Sintonizzazione rapida"])},prompt_tuning_description:e=>{const{normalize:i}=e;return i(["Il processo di creazione e raffinamento dell'input richiede al fine di guidare il suo output verso risposte specifiche e desiderate."])},representation:e=>{const{normalize:i}=e;return i(["Rappresentazione"])},representation_desc:e=>{const{normalize:i}=e;return i(["Gli incorporamenti trasformano i dati multimodali in un formato uniforme e vettoriale. Ci\xF2 consente al sistema di ricerca di comprendere e classificare i contenuti oltre le semplici parole chiave."])},rerankers:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},rerankers_desc:e=>{const{normalize:i}=e;return i(["I reranker prendono i risultati iniziali dagli incorporamenti e li perfezionano, garantendo che all'utente vengano presentati i risultati pi\xF9 rilevanti. Questo \xE8 fondamentale per fornire risultati di ricerca di alta qualit\xE0 che soddisfino le intenzioni dell'utente."])}},subscribe_system:{care_most:e=>{const{normalize:i}=e;return i(["Cosa ti interessa di pi\xF9?"])},care_most_options:{accuracy:e=>{const{normalize:i}=e;return i(["Precisione"])},cost:e=>{const{normalize:i}=e;return i(["Costo"])},other:e=>{const{normalize:i}=e;return i(["Altro"])},scalability:e=>{const{normalize:i}=e;return i(["Scalabilit\xE0"])},speed:e=>{const{normalize:i}=e;return i(["Velocit\xE0"])}},care_most_required:e=>{const{normalize:i}=e;return i(["Quando scegli un servizio, cosa ti interessa di pi\xF9?"])},company_size:e=>{const{normalize:i}=e;return i(["Qual \xE8 la dimensione della tua azienda?"])},company_size_required:e=>{const{normalize:i}=e;return i(["Raccontaci che le dimensioni della tua azienda ci aiutano a fornire un servizio migliore"])},company_url:e=>{const{normalize:i}=e;return i(["Qual \xE8 il sito web della tua azienda?"])},company_url_required:e=>{const{normalize:i}=e;return i(["Raccontaci che il sito web della tua azienda ci aiuta a fornire un servizio migliore"])},contactName:e=>{const{normalize:i}=e;return i(["Il tuo nome"])},contactName_required:e=>{const{normalize:i}=e;return i(["Come dovremmo rivolgerci a te?"])},contactTitle:e=>{const{normalize:i}=e;return i(["Qual \xE8 la tua mansione?"])},contactTitle_required:e=>{const{normalize:i}=e;return i(["Il tuo titolo professionale \xE8 obbligatorio"])},contact_us:e=>{const{normalize:i}=e;return i(["Contattaci"])},domain_required:e=>{const{normalize:i}=e;return i(["Raccontaci che il tuo dominio di lavoro ci aiuta a fornire un servizio migliore"])},email:e=>{const{normalize:i}=e;return i(["E-mail"])},email_contact:e=>{const{normalize:i}=e;return i(["La tua e-mail di contatto"])},email_invalid:e=>{const{normalize:i}=e;return i(["L'email non \xE8 valida"])},email_required:e=>{const{normalize:i}=e;return i(["L'e-mail \xE8 obbligatoria"])},fine_tuned_embedding:e=>{const{normalize:i}=e;return i(["Sei interessato a incorporamenti ottimizzati su misura per i tuoi dati e il tuo caso d'uso? Discutiamone!"])},fine_tuned_reranker:e=>{const{normalize:i}=e;return i(["Ti interessano riranker ottimizzati su misura per i tuoi dati e il tuo caso d'uso? Discutiamone!"])},full_survey:e=>{const{normalize:i}=e;return i(["Partecipa al sondaggio completo e ottieni una risposta pi\xF9 rapida dal nostro team"])},get_new_key:e=>{const{normalize:i}=e;return i(["Ottieni la tua chiave API"])},get_update_blog_posts:e=>{const{normalize:i}=e;return i(["Ricevi gli ultimi aggiornamenti per i post del blog"])},get_update_embeddings:e=>{const{normalize:i}=e;return i(["Ottieni gli ultimi aggiornamenti per gli incorporamenti"])},send:e=>{const{normalize:i}=e;return i(["Inviare"])},sign_up:e=>{const{normalize:i}=e;return i(["Iscrizione"])},subscribe:e=>{const{normalize:i}=e;return i(["sottoscrivi"])},tell_domain:e=>{const{normalize:i}=e;return i(["Raccontaci il tuo dominio"])},usage_type:e=>{const{normalize:i}=e;return i(["Quale tipo di utilizzo ti descrive meglio?"])},usage_type_options:{other:e=>{const{normalize:i}=e;return i(["Altro"])},poc:e=>{const{normalize:i}=e;return i(["Verifica teorica"])},production:e=>{const{normalize:i}=e;return i(["Produzione"])},research:e=>{const{normalize:i}=e;return i(["Ricerca"])}},usage_type_required:e=>{const{normalize:i}=e;return i(["Comunicaci che il tuo tipo di utilizzo ci aiuta a fornire un servizio migliore"])},used_product:e=>{const{normalize:i}=e;return i(["Quale modello stai utilizzando?"])},used_product_required:e=>{const{normalize:i}=e;return i(["Seleziona il modello che stai utilizzando o a cui sei interessato"])}},think_gpt:{description:e=>{const{normalize:i}=e;return i(["Tecniche di agente per aumentare il tuo LLM e spingerlo oltre i suoi limiti"])}},vectordb:{description:e=>{const{normalize:i}=e;return i(["Un database vettoriale Python di cui hai solo bisogno, n\xE9 pi\xF9 n\xE9 meno"])}},zzz:e=>{const{normalize:i}=e;return i(["zzz"])}};export{r as default};
