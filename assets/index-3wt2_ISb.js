const e="クラス最高のベクターモデル、リアレンジャー、ウェブクローラー、ディープサーチ、小規模な言語モデル。多言語・マルチモーダルデータのための検索AI。",n="あなたの検索基盤、ぐんぐん加速！",a={approach:"私たちの戦略",approach_connect_dots:"ワイヤーの引き出し: パワー ユーザーからエンタープライズ ユーザーまで",approach_connect_dots_description:"全体的な戦略においてパワー ユーザーをこれほど重視するのはなぜですか?これは事前の計画に関する考慮事項です。明日の企業への影響力のために、今日投資してください。これは、これらのパワー ユーザーが企業の発言権を引き継いだ場合でも、当社が引き続き彼らをサポートできるようにするための当社のビジョンです。",approach_content1:"人工知能の絶えず変化する状況では、戦略は柔軟であり、将来を洞察する必要があります。 Jina AI はエンタープライズに焦点を当てていますが、AI 分野は進化しており、顧客を引き付ける戦略も時代に合わせる必要があります。したがって、上級ユーザーをブレークスルーポイントとして捉えることは、当社の戦略的革新であるだけでなく、企業発展における当社の粘り強さを反映しています。",approach_content2:"Jina AI では、これまでの栄誉に甘んじることなく、あえてイノベーションを起こします。上級ユーザーをリードすることで、現在を把握し、将来を予測することができます。企業としての私たちの決意は揺るぎませんが、成功への道においては、着実かつ前向きな新しい道を歩んでいます。",approach_content4:'誰もがより良い検索エクスペリエンスを望んでいます。 Jina AI では、ベクトル モデル、並べ替え機能、リーダー、プロンプト ワード エンジニアリング エクスペリエンスで構成される<span class="text-primary text-bold">検索ベース</span>を提供することで、より優れた検索を可能にします。これらのコンポーネントは連携して、データの検索と理解の方法に革命をもたらします。',approach_miss_mark:"従来の MLOps の欠点",approach_miss_mark_description:"パワー ユーザーの数が増加しているにもかかわらず、従来の MLOps ツールでは機能が低下し、ユーザーのニーズを満たせないことがよくあります。彼らは新時代のペースの速い競争に対処できない時代遅れの馬のようなものです。新世代の開発者は、より軽く、より直感的な武器を求めています。",approach_new_paradigm:"プロンプトワードプロジェクト：AI開発の新たなトレンド",approach_new_paradigm_description:"2023年、AIの世界は新たな章を迎え、プロンプトワードプロジェクトが急速に推進され、AIツールの普及プロセスが実現します。プログラミングの基礎を持たない上級ユーザーでも、Pytorch、Docker、Kubernetes に怯えることなく、簡単に AI に参加できます。この状況はパーソナル コンピューティングの台頭と非常によく似ています。当時、コンピュータと通信できるのは技術エリートだけでしたが、よりユーザーフレンドリーなインターフェイスの出現により、一般の人もその仲間に加わることができるようになりました。今日、プロンプト ワード エンジニアリングの人気により、AI の分野でも人気の新たな波が起きています。",awards:"受賞歴と優秀賞",berlin:"ドイツ、ベルリン（本社）",berlin_address:"Prinzessinnenstraße 19-20、10969 ベルリン、ドイツ",berlin_address2:"登録住所: Leipzigerstr. 96、10117 ベルリン、ドイツ",bj:"中国、北京",bj_address:"中国北京市海淀区西街48号ビル6号5階",brochure_info:"当社の会社案内があなたをお待ちしています",description:"未来はここから始まります。",download_brochure1:"パンフレットをダウンロード",download_docarray_logo:"DocArray のロゴをダウンロード",download_docarray_logo_desc:"Jina AI によって開始され、2022 年 12 月に Linux Foundation に寄付されたオープンソース プロジェクトである DocArray ロゴを入手してください。ライトモードとダークモード、PNG および SVG 形式で利用できます。",download_jina_logo:"Jina AIのロゴをダウンロード",download_jina_logo_desc:"Jina AI ロゴをライト モードとダーク モードで入手できます。PNG 形式と SVG 形式で利用できます。このマークは欧州連合知的財産局 (EUIPO) の登録商標です。",download_logo:"ロゴをダウンロード",employees:"今日の従業員",empower_developers:"開発者エコシステム",fastApiCaption:"2021 年以降、20,000 ドル以上を寄付しました。",founded:"年設立",founded_in:"に設立されました",investors:"私たちの投資家",linuxFoundationCaption:"2022 年からは、年間 10,000 ドルを寄付してください。",many:"多くの",media:{video:"ビデオインタビュー"},mission:"我々の使命",mission_content1:"当社の主要テクノロジーには、高速チューニング、高速サービング、モデル チューニング、モデル サービングが含まれており、人工知能の民主化への取り組みを反映しています。当社は、オープンソース プログラムを通じて、イノベーション、コラボレーション、透明性を促進し、スケーラブルで効率的かつ堅牢なソリューションを確保するよう努めています。 Jina AI は単なる企業ではなく、企業がデジタル時代のダイナミックな課題に対処し、その分野で成功することを支援することに特化したコミュニティです。",mission_content2:"Jina AI の中核となる哲学は、パワー ユーザーや開発者から大企業までのマルチモーダル AI チャネルになるという私たちの使命にあります。私たちはオープンソースの力を信じており、AI コミュニティのための最先端のアクセス可能なツールの構築に取り組んでいます。プロンプトワード微調整、モデルベクトル調整および展開などの当社の主要テクノロジーは、AI の普及に対する当社の確固たる信念を示しています。オープンソースのアプローチにより、私たちはイノベーション、コラボレーション、透明性を推進し、アプローチがスケーラブルで効率的かつ強力であることを保証することを目指しています。 Jina AI は単なる企業ではなく、企業がデジタル時代の課題に対処し、各分野でリーダーであり続けることを支援するコミュニティです。",mission_content3:"Jina AI の使命は、革新的なベクトル モデルとヒントベースの技術を通じて、マルチモーダル AI の開発をリードすることです。私たちは、自然言語処理、画像およびビデオ分析、クロスモーダルデータインタラクションなどの分野に特に注意を払っています。当社の専門分野は、複雑なマルチソース データを、実際に実行可能な価値を持つ洞察と革新的なアプリケーションに変換する独自のソリューションの提供に重点を置いています。",mit_report_title:"マルチモダリティ: 人工知能の新たなフロンティア",mit_techreview:"MITテクノロジーレビュー",numfocusCaption:"2022 年から毎月定期的に寄付を行ってください。",office:"私たちのオフィス",otherProjectsCaption:"Github のスポンサーシップを通じて 3,000 ドル以上を寄付しました。",our_answer:"これ以上同意することはできません、ヤン。私たちはマルチモーダル AI の未来への架け橋を築くために懸命に取り組んでいます。",pythonSoftwareFoundationCaption:"1 回限りの 10,000 ドルの寄付を行い、ドイツ、イタリア、中国、米国などの複数の PyCon イベントを後援しました。",sectors:{ecommerceRetail:"次世代の電子商取引",ecommerceRetail_description:"電子商取引および小売のリーダーは、Jina AI と提携して、正確な製品の推奨と詳細な検索エクスペリエンスを提供します。当社の多言語ベクトルと AI 主導の並べ替え機能は、グローバル製品カタログの検索を最適化し、コンバージョン率を高め、洞察を得るまでの時間を短縮します。",ecommerceRetail_short:"Eコマース小売",financeConsulting:"コンサルタントとアナリスト",financeConsulting_description:"金融会社やコンサルティング会社は、大規模なデータクレンジングとドメイン固有のモデルトレーニングに Jina AI を使用し、リアルタイムの洞察を獲得しています。当社のエンタープライズ ライセンスと安全なオンプレミス展開により、高度な検索および分析機能のメリットを活用しながら機密性を確保できます。",financeConsulting_short:"コンサルティングファイナンス",media:"コンテンツクリエイター",media_description:"メディア組織は、Jina AI を使用して、膨大な量のマルチメディア資産を検索可能な知識に変換し、社内調査を効率化し、ユーザー エクスペリエンスを充実させます。当社の専門リーダーおよび再ランク付けサービスにより、記事、ビデオ、アーカイブ全体にわたって正確でコンテキストを意識した発見が保証されます。",media_short:"メディア、文化、クリエイティブ",misc:"おしゃれな人になろう",misc_description:"教育、農業、不動産などの組織は、Jina AI の柔軟なソリューションを活用して、大規模なデータのクリーニング、抽出、変換を行っています。当社の最先端のニューラル検索スタックを活用することで、彼らは新たな可能性を解き放ち、各分野の最前線に留まります。",misc_short:"その他",technology:"先駆的で革新的な技術者",technology_description:"ソフトウェア、クラウド、AI、データのリーダー企業は、大規模モデルベースの検索、RAG、AI エージェント システムを強化するために、Jina AI のニューラル検索ソリューションを活用しています。当社の高度なリーダー、ベクター、再シーケンサー、および小規模言語モデルにより、パイロットから実稼働までをこれまで以上に迅速に進めることができます。",technology_short:"ソフトウェア技術"},sefo:{layer0:"ユーザー向けアプリケーション",layer1:"RAG/アレンジメントシステム",layer3:"GPU/モバイル/エッジ/ローカル コンピューティング"},segmentFaultCaption:"1 回限り 6,000 ドルを寄付してください。",show_position:"エコシステムにおける Search Foundation の位置は何ですか?",stats_1:"Jina AI は 2020 年 2 月に設立され、わずか 20 か月でマルチモーダル AI テクノロジーのリーダーになりました。この間、当社は 3,750 万ドルの調達に成功し、AI 業界のリーダーとしての地位を確立しました。 GitHub では、当社の革新的なオープンソース テクノロジーにより、40,000 人を超える開発者が何の障壁もなくマルチモーダル アプリを構築およびデプロイできるようになりました。",stats_2:"2023 年までに、私たちはマルチモーダル テクノロジーに基づいた AI ツールを飛躍的に進歩させました。このイノベーションは 250,000 人以上のユーザーに恩恵をもたらし、幅広いビジネス ニーズを満たしています。ビジネスの成長の促進、業務効率の向上、コストの最適化など、Jina AI は企業がマルチモーダル時代を前進できるよう支援することに尽力しています。",stats_4:'2020 年に設立された Jina AI は、検索 AI の大手企業です。弊社の<span class="text-primary text-bold">検索ベース</span> プラットフォームには、ベクター モデル、再配列ツール、小規模言語モデルが含まれており、企業が信頼性の高い高品質な生成 AI とマルチモデルの状態を構築できるように支援します。 -アート検索アプリケーション。',stats_v1:"検索が加速主義と衝突する場合",subtitle:"AI 生成ソリューションでコンテンツ作成に革命を起こし、無限の可能性を解き放ちます。 AI が生成するコンテンツの未来を形成し、人間の創造性を強化します。",sues_und_sauer:"スーとザウアー",sues_und_sauer_tooltip:"ズーザウアーはドイツ風中華料理で人気のフレーバーです (このフレーバーは本格的な中華料理では一般的ではなく、ドイツの中華料理のステレオタイプに属します)。これは甘くて酸っぱいことを意味します。これは起業家としてのキャリアの浮き沈みの比喩です。",sunnyvale_address:"710 Lakeway Dr、Ste 200、サニーベール、CA 94085、アメリカ合衆国",sz:"深セン、中国",sz_address:"ルーム 402、4 階、福安テクノロジービル、深セン、中国",team:"私たちのチーム",team_content1:"私たちは地球の隅々から AI の未来を構築します。私たちのユニークな視点は私たちの仕事を豊かにし、イノベーションを刺激します。このポータルでは、私たちは個性を受け入れ、情熱的に夢を追い求めます。 AI の未来へのポータルへようこそ。",team_join:"参加しませんか",team_size:"これらの写真には私たちの元同僚やインターンも含まれています。私たちは彼ら一人一人に感謝しています。",technologies:"コアテクノロジー",title:"ジナテクノロジーについて",title0:"未来",title1:"起源",title2:"ここ",title3:"ここから始まる",understand_our_strength:"当社の強みを知る",understand_our_view2:"検索ベースについて学ぶ",users:"登録ユーザー",value:"私たちの賞",value_content1:"私たちはこれまでの栄光に満足するつもりはありません。私たちは妥協しません。私たちは卓越性を追求します。",vision:"我々の使命",vision_content1:"AI に関するヤン・ルカンの視点からインスピレーションを得て、「",vision_content3:'AI の未来は<span class="text-primary text-bold">マルチモーダル</span>であり、私たちはその一部です。私たちは、企業がマルチモーダル データを活用する際に直面する課題を認識しています。そのために、私たちは企業や開発者がより適切に検索し、マルチモーダル データを活用してビジネスの成長を促進できるよう、<span class="text-primary text-bold">検索基盤</span> に取り組んでいます。',yannlecun_quote:"単語や文章だけで訓練された AI システムは、決して人間の理解に近づくことはできません。"},i={answer1:"はい、同じ API キーが Jina AI のすべての検索ベース製品で機能します。これには、Reader、Embedding、Reranger、Classifier、Fine-Tune Model API が含まれており、すべてのサービス間でトークンが共有されます。",answer10:"これは、使用率が低い場合、サーバーレス アーキテクチャが特定のモデルをオフロードするためです。最初のリクエストではモデルがアクティブ化または「ウォームアップ」されますが、これには数秒かかる場合があります。最初のアクティベーションの後、後続のリクエストははるかに高速に処理されます。",answer12:"当社は厳格なプライバシー ポリシーを遵守しており、モデルのトレーニングにユーザー入力データを使用しません。また、SOC 2 Type I および Type II にも準拠しており、高水準のセキュリティとプライバシーを保証します。",answer3:"はい、[キーと請求] タブに API キーを入力すると、最近のトークン使用量と残りのトークン残高を表示できます。 API キー コントロール パネルにサインインしている場合は、[API キーの管理] タブでこれらの詳細を表示することもできます。",answer4:"リチャージ キーを紛失し、再取得したい場合は、登録した電子メールを使用してサポート AT jina.ai までご連絡ください。安全に保管し、API キーに簡単にアクセスできるように、ログインすることをお勧めします。",answer5:"いいえ、API キーには有効期限がありません。ただし、キーが侵害された疑いがあり、キーを非アクティブ化したい場合は、弊社のサポート チームにご連絡ください。 <a class='text-primary' href='https://jina.ai/api-dashboard'>API キー コントロール パネル</a>でキーを自己破壊することもできます。",answer6:"はい、残りの有料トークン残高をあるプレミアム キーから別のプレミアム キーに移すことができます。 <a class='text-primary' href='https://jina.ai/api-dashboard'>API キー コントロール パネル</a>でアカウントにログインした後、キー転送の設定インターフェースに移動します。残りのすべての支払い済みトークン残高。",answer7:"はい、API キーが侵害されたと思われる場合は、破棄できます。キーを破棄すると、そのキーを保存しているすべてのユーザーに対してキーが即座に無効になり、残りのトークン残高と関連資産はすべて永久に利用できなくなります。プレミアム キーをお持ちの場合は、それを書き込む前に、残りの支払い済みトークンの残高を別のキーに転送することを選択できます。この操作は元に戻すことができないことに注意してください。キーを破棄するには、<a class='text-primary' href='https://jina.ai/api-dashboard'>API キー ダッシュボード</a>のキー設定に移動します。",question1:"Reader、Embedding、Reranker、Classifier、Fine-Tuned Model API に同じ API キーを使用できますか?",question10:"一部のモデルの初回リクエストに時間がかかるのはなぜですか?",question12:"ユーザー入力データはモデルのトレーニングに使用されますか?",question3:"API キーのトークンの使用状況を表示できますか?",question4:"API キーを忘れた場合はどうすればよいですか?",question5:"API キーには有効期限がありますか?",question6:"API キー間でトークン残高を転送できますか?",question7:"API キーを破棄してもいいですか?",title:"API関連のFAQ"},t={base_model:"ベースモデルの微調整",check_data:"合成データをダウンロードする",check_model:"微調整されたモデルをダウンロードする",data_size:"合成データの生成",description:"任意のドメインに対して微調整されたベクトル モデルを入手します。",description_long:"ベクトル モデルをどのドメインで優れたものにしたいかを教えてください。そのドメイン向けに、すぐに使用できる微調整されたベクトル モデル モデルが自動的に提供されます。",does_it_work_tho:"しかし、本当に効果があるのでしょうか？",does_it_work_tho_explain:"Auto-Spin には、希望するドメインに微調整されたベクトルを提供する魔法のような自動効果があります。しかし、本当に効果があるのでしょうか？これはかなり合理的な質問です。様々なフィールドとベースモデルでテストを行い、それを明らかにしました。以下の注目の結果と注目の結果をチェックしてください。",domain_instruction:"ドメインディレクティブ",embedding_provider:"基底ベクトルモデルの選択",eval_evaluation:"確認する",eval_map:"地図",eval_mrr:"平均月収",eval_ndcg:"グリア細胞癌",eval_performance_before_after:"微調整前後の合成検証セットのパフォーマンス",eval_syntheticDataSize:"全て",eval_test:"実際のデータのテスト",eval_training:"電車",faq_v1:{answer1:"この機能は現在ベータ版であり、微調整されたモデルごとに 100 万トークンかかります。 Embedding/Reranker API に十分なトークンがある場合は、既存の API キーを使用することも、1,000 万個の無料トークンを含む新しい API キーを作成することもできます。",answer10:"今は何もありません。この機能はまだベータ版であることに注意してください。微調整されたモデルと合成データを Hugging Face Model Center に公開して保存することは、私たちとコミュニティがトレーニングの品質を評価するのに役立ちます。将来的には、プライベート ストレージ オプションも提供する予定です。",answer11:"すべての微調整されたモデルはすでに Hugging Face にアップロードされているため、SentenceTransformers を通じてモデル名を指定するだけでモデルにアクセスできます。",answer12:"スパムフォルダを確認してください。それでも見つからない場合は、指定した電子メール アドレスを使用してサポート チームにお問い合わせください。",answer2:"トレーニング データを提供する必要はありません。ターゲット ドメイン (微調整されたベクトル モデルを最適化するドメイン) を自然言語で記述するか、URL を参照として使用するだけで、システムがモデルをトレーニングするための合成データを生成します。",answer3:"約30分。",answer4:"微調整されたモデルと合成データは、Hugging Face Model Center に公的に保存されます。",answer5:"システムは Reader API を使用して URL からコンテンツを取得します。次に、コンテンツを分析してトーンとドメインを要約し、合成データを生成するためのガイドラインとして使用しました。したがって、URL はパブリックにアクセス可能であり、ターゲット ドメインを表す必要があります。",answer6:"はい、英語以外の言語向けにモデルを微調整できます。システムはドメイン命令の言語を自動的に検出し、それに応じて合成データを生成します。また、ターゲット言語に適切な基本モデルを選択することをお勧めします。たとえば、ドイツ語ドメインをターゲットとする場合は、「jina-embeddings-v2-base-de」をベース モデルとして選択する必要があります。",answer7:"いいえ、微調整 API は Jina v2 モデルのみをサポートしています。",answer8:"微調整プロセスの最後に、保持されたテスト セットを使用してモデルが評価され、パフォーマンス メトリックが報告されます。このテスト セットの前後のパフォーマンスの詳細を記載した電子メールが届きます。また、品質を保証するために、独自のテスト セットでモデルを評価することをお勧めします。",answer9:"システムは、ユーザーが提供するターゲット ドメインの指示と大規模なモデル エージェントからの推論を組み合わせて、合成データを生成します。高品質のベクトルベースのモデルをトレーニングするために不可欠な、難しいトリプレットを生成します。詳細については、Arxiv で公開予定の研究論文をご覧ください。",question1:"API の微調整にはどれくらいの費用がかかりますか?",question10:"微調整されたモデルと合成データを非公開にしておくことができますか?",question11:"微調整モデルの使用方法は?",question12:"査定結果のメールが届きません。私は何をしますか？",question2:"何を入力する必要がありますか?トレーニング データを提供する必要がありますか?",question3:"モデルの微調整にはどのくらい時間がかかりますか?",question4:"微調整されたモデルはどこに保存されますか?",question5:"参照 URL を指定した場合、システムはそれをどのように使用しますか?",question6:"特定の言語に合わせてモデルを微調整できますか?",question7:"bge-M3 など、Jina 以外のベクトル モデルを微調整できますか?",question8:"微調整されたモデルの品質を保証するにはどうすればよいですか?",question9:"合成データを生成するにはどうすればよいですか?",title:"セルフチューニングに関するよくある質問"},find_on_hf:"微調整されたモデルをリストする",temporarily_unavailable:"一時的に利用できなくなりました。より良いサービスを提供するために、自動微調整システムをアップグレードしています。後でもう一度確認してください。",test_on:"{_dataName} からの {_dataSize} 個のランダム サンプルでテストされました",test_performance_before_after:"微調整前後の、保持されたテストセットのパフォーマンス",title:"セルフチューニングAPI",total_improve:"平均的な改善",usage:"使用法",what_is:"セルフチューニングとは何ですか?",what_is_answer_long:"微調整により、事前トレーニング済みのモデルを新しいデータセットでトレーニングして、特定のタスクまたはドメインに適応させることができます。実際、多くのユーザーにとって、効果的なトレーニング データを見つけることは簡単な作業ではありません。効果的なトレーニングには、生の PDF/HTML をモデルに入力する以上のことが求められますが、これを正しく行うことは困難です。自己微調整は、高レベルの大規模モデル エージェント パイプラインを使用して効果的なトレーニング データを自動的に生成し、ML ワークフローでモデルを微調整することで、この問題を解決します。これは合成データ生成と AutoML の組み合わせと考えることができます。つまり、ターゲット ドメインを自然言語で記述するだけで、あとはシステムに任せることができます。"},r={auth_required:"アバター生成を使用するには認証が必要です",classificationError:"画像の分類中にエラーが発生しました。もう一度試してください。",clickToDownload:"クリックしてSVGをダウンロード",customize:"カスタム機能",description:"カスタマイズ可能な機能を備えたユニークなアバターを生成",downloadError:"アバターのダウンロード中にエラーが発生しました",downloadSuccess:"アバターのダウンロードに成功しました",download_success:"アバターのダウンロードに成功しました",error_loading:"アバター リソースをロードできません。もう一度お試しください。",error_processing:"画像の処理中にエラーが発生しました",file_hint:"サポートされている形式: JPG、PNG、GIF、WebP",generate:"アバターの生成",how_does_it_work:"どのように機能するのでしょうか?",noImageSelected:"最初に写真を選択してください",select_file:"ポートレート画像ファイルを選択",title:"アバタージェネレーター",upload_description:"base64に変換する画像（256x256）を選択します",upload_title:"写真をアップロードする",usage:"アバターの生成"},s="体験版",o={answer10:"新規ユーザーには無料トライアルを提供しており、これには自動生成された API キーを介して引き換えられる、当社のどのモデルでも使用できる 1,000 万トークンが含まれています。無料トークンを使い切ったら、ユーザーは「トークンを購入」タブから API キーで使用するための追加トークンを簡単に購入できます。",answer13:"いいえ、失敗したリクエストに対してトークンは差し引かれません。",answer14:"支払いは Stripe を通じて処理され、クレジット カード、Google Pay、PayPal などの複数の支払い方法がサポートされているため、便利です。",answer15:"はい、トークンを購入すると、Stripe アカウントに関連付けられた電子メール アドレスに請求書が送信されます。",answer9:"当社の価格モデルは処理されるトークンの総数に基づいており、ユーザーはこれらのトークンを任意の数の文に柔軟に割り当てることができ、さまざまなテキスト分析ニーズに費用対効果の高いソリューションを提供します。",question10:"新規ユーザーは無料トライアルを利用できますか?",question13:"失敗したリクエストに対してトークンは差し引かれますか?",question14:"どのような支払い方法が利用できますか?",question15:"Ci Yuanを購入した後に請求書を発行できますか?",question9:"API の料金は文の数またはリクエストの数に基づいて課金されますか?",title:"請求に関するよくある質問"},_={all:"全て",events:"活動",featured:"選択",insights:"ビュー","knowledge-base":"知識ベース",latest:"最新",press:"プレスリリース",releases:"ソフトウェアの更新","tech-blog":"技術記事"},d={caption:"2024 年に向けて最も影響力のある調査および検索ベース モデルを厳選した年鑑 Re·Search をご覧ください。",order_now:"今すぐ注文"},l={api_free_trial:"無料のAPIキー",api_paid:"有料APIキー",api_paid_or_free:"有料の API キーを使用していますか? それとも無料の試用版キーを使用していますか?",are_you:"あなたは誰ですか：",commercial_contact_sales:"これは商業的な性質のものです。当社の営業チームにお問い合わせください。",contact_sales_for_licensing:"ライセンスについては、弊社の営業チームにお問い合わせください。",csp_user:"AWS と Azure で公式モデルを使用していますか?",educational_teaching:"教育機関は教育に使用していますか?",for_profit_internal_use:"営利企業は社内でそれを使用していますか?",free_use:"これらのモデルは自由に使用できます。",government_public_services:"政府機関が公共サービスを提供するために使用していますか?",is_use_commercial:"あなたの使用は商用ですか?",may_be_commercial_contact:"これは商用利用が可能です。ご不明な点がございましたら、お問い合わせください。",no:"いいえ",no1:"いいえ",no2:"いいえ",no3:"いいえ",no_restrictions:"制限はありません。現在の規約に従ってご利用ください。",no_restrictions_apply:"制限はありません。",non_commercial_free_use:"このモデルは非商用ですのでご自由にお使いいただけます。",non_profit_ngo_mission:"非営利団体や NGO はあなたの使命を果たすためにそれを使用していますか?",not_sure:"わからない",personal_hobby_projects:"個人的なプロジェクトや趣味のプロジェクトに使用しますか?",product_service_sale:"販売する製品やサービスに使用しますか?",title:"CC BY-NC ライセンスのセルフチェック",trial_key_restrictions:"無料トライアル キーは、非営利目的でのみ使用できます。商用利用の場合は、有料パッケージをご購入ください。",typically_non_commercial_check:"通常、これは非営利ですが、不明な場合はご連絡ください。",typically_non_commercial_free_use:"これは通常、非営利的なものです。これらのモデルは自由に使用できます。",using_api_or_cloud:"Azure または AWS で公式 API または公式ミラーを使用していますか?",using_cc_by_nc_models:"これらのモデルを使用していますか?",yes:"はい",yes1:"はい",yes2:"はい",yes3:"はい"},c={access:"パブリックアクセス",access_explain:"パブリック分類子は、<code>classifier_id</code> を持つ誰でも使用でき、それらを使用すると、自分のトークン割り当てではなく、呼び出し元のトークン割り当てが消費されます。プライベート分類子には自分だけがアクセスできます。",access_private:"プライベート",access_public:"人々",api_delete:"分類子の削除",api_delete_explain:"分類子 ID に基づいて分類子を削除します。",api_list:"リスト分類子",api_list_explain:"作成したすべての分類子をリストします。",classifier_id:"分類子ID",classify_inputs:"分類される入力",classify_inputs_explain:"テキストの場合、最大 8192 トークンの文になります。画像の場合、URL または base64 でエンコードされた画像になります。",classify_labels:"候補の注釈",classify_labels_explain:"入力はこれらのカテゴリに分類されます。カテゴリは最大 256 個まで存在します。パフォーマンスを向上させるには、セマンティック カテゴリを使用します。",compare_table:{access_control:"アクセス制御",classifier_id_required:"必要な分類子 ID",continuous_updates:"継続的なモデルの更新",default_solution:"一般的な分類問題に対するデフォルトのソリューション",feature:"特徴",few_shot:"小さなサンプル",image_multi_lingual_support:"マルチモードおよび多言語のサポート",labels_required_classify:"/classify で必要な注釈",labels_required_train:"/train には注釈が必要です",max_classes:"クラスの最大数",max_classifiers:"最大分類子",max_inputs_request:"リクエストごとの最大入力",max_token_length:"入力あたりの最大トークン長",na:"適用できない",no:"いいえ",out_of_domain_solution:"v3/clip-v1 ドメイン外のデータまたは時間に敏感なデータの場合",primary_use_case:"主な使用例",semantic_labels_required:"セマンティックな注釈が必要です",state_management:"ステータス管理",stateful:"ステートフル",stateless:"ステートレス",token_count:"{count} 個のトークン",training_data_required:"トレーニングデータが必要です",yes:"はい",zero_shot:"ゼロサンプル"},create_classifier:"新しい少数ショット分類器",create_classifier_explain:"新しい少数ショット分類器を作成し、トレーニング サンプルを使用してトレーニングします。",description:"画像とテキストのゼロショットおよび少数ショットの分類。",description_long:"API サンドボックスを試して、分類子がどのように機能するかを確認してください。",description_long1:"マルチモーダルおよび多言語データ向けの高性能ゼロショット分類器および少数ショット分類器。",explain:"分類器は、ベクター モデル (<code>jina-embeddings-v3</code> および <code>jina-clip-v1</code>) を使用してテキストと画像を分類する API サービスであり、トレーニング データなしのゼロ ショット分類と最小限の例による少数ショット学習をサポートします。",faq_v1:{answer1:"ゼロショット分類にはセマンティック ラベルが必要ですが、トレーニング中には必要ありません。一方、少数ショット分類には、トレーニング中にラベルが必要ですが、分類中には必要ありません。これは、柔軟で即時の分類ニーズにはゼロショット分類の方が適しているのに対し、時間の経過とともに進化する可能性がある固定のドメイン固有のカテゴリには少数ショット分類の方が適していることを意味します。",answer10:"はい、テキスト分類 (特に多言語に適しています) には <code>jina-embeddings-v3</code> を選択し、マルチモーダル分類には <code>jina-clip-v1</code> を選択できます。新しいモデル (<code>jina-clip-v2</code> など) は、リリース時に API を通じて自動的に利用可能になります。",answer2:"<code>num_iters</code> はトレーニング強度を制御します。値が大きいほど重要な例が強調され、値が小さいほど信頼性の低いデータの影響が最小限に抑えられます。これを使用すると、最近の例をより多くの反復回数で供給することで、時間認識学習を実現でき、進化するデータ パターンにとって価値があります。",answer3:"<code>classifier_id</code> を持つユーザーは誰でもパブリック分類子を使用し、独自のトークン クォータを消費できます。ユーザーはトレーニング データや設定にアクセスしたり、他の人の分類リクエストを表示したりできないため、安全な分類子の共有が可能になります。",answer4:"サンプル数が少ない場合、ゼロショット分類を超えるには 200 ～ 400 のトレーニング サンプルが必要です。最終的にはより高い精度が達成されますが、効果的にするにはこのウォームアップ期間が必要です。 Zero-shot は、トレーニング データを必要とせずに、すぐに安定したパフォーマンスを提供します。",answer5:"はい。API は、<code>jina-embeddings-v3</code> を使用した多言語クエリと、<code>jina-clip-v1</code> を使用したマルチモーダル (テキスト/画像) 分類をサポートし、同じリクエストで URL または base64 でエンコードされた画像もサポートします。",answer6:"ゼロショットは分類子の制限なしで 256 のカテゴリをサポートしますが、フューショットは 16 のカテゴリと 16 の分類子に制限されます。どちらも、リクエストごとに 1,024 個の入力と、入力ごとに 8,192 個のトークンをサポートします。",answer7:"少数のサンプル パターンにより、変化するデータ パターンに適応するために <code>/train</code> エンドポイントを介した継続的な更新が可能になります。データの分布が変化した場合、分類器全体を再構築することなく、新しい例やカテゴリを段階的に追加できます。",answer8:"API はワンショットのオンライン学習を使用します。トレーニング サンプルは分類子の重みを更新しますが、その後は保存されません。つまり、過去のトレーニング データを取得することはできませんが、プライバシーとリソース効率は確保されます。",answer9:"セマンティック ラベルを使用した柔軟な分類が必要な場合は、即座に結果を得るためにサンプルをゼロから開始します。 200 ～ 400 個のサンプルがある場合、より高い精度が必要な場合、またはドメイン固有のデータや時間に敏感なデータを処理する必要がある場合は、少数のサンプルに切り替えます。",question1:"ゼロサンプルと小さなサンプルのラベルの違いは何ですか?",question10:"異なる言語/タスクに異なるモデルを使用できますか?",question2:"num_iters は何に使用されますか?またその使用方法は何ですか?",question3:"パブリック分類子の共有はどのように機能しますか?",question4:"小規模なサンプル研究をうまく機能させるにはどのくらいのデータが必要ですか?",question5:"複数の言語やテキスト・画像を扱うことはできますか？",question6:"注意すべきハード制限は何ですか?",question7:"時間の経過に伴うデータの変化にどのように対処すればよいですか?",question8:"トレーニング データを送信した後はどうなりますか?",question9:"ゼロサンプルと少量サンプル - いつどちらを使用するか?",title:"分類子に関するよくある質問"},more:"もっと",num_iters:"トレーニングの反復",num_iters_explain:"トレーニング強度を制御します。値が大きいほど、現在の例の精度が向上しますが、トークン コストが増加します。通常は、デフォルト値の 10 が適切に機能します。",read_notes:"リリースノートを読む",select_classifier_or_model:"分類子または埋め込みモデルを選択します",task_classify:"分類",task_classify_explain:"ゼロショット分類器または少数ショット分類器を使用して、テキストまたは画像を定義済みのカテゴリに分類します。",task_manage:"管理",task_manage_explain:"少数ショット分類器をリストまたは削除します。",task_select:"タスクの選択",task_train:"電車",task_train_explain:"トレーニング サンプルを使用して、少数の分類器を作成または更新します。",title:"分類子 API",train_inputs:"トレーニングデータ",train_inputs_explain:"トレーニング用のラベル付きテキストまたは画像の例。時間の経過とともに、新しい例とラベルを使用して分類子を段階的に更新できます。",train_label:"ラベル",what_is:"分類子とは何ですか?",when_to_use_what:"ゼロまたは少量のサンプルをいつ使用するか?",when_to_use_what_explain:"デフォルトのソリューションとしてゼロショット分類を使用すると、最大 256 のカテゴリを含む一般的な分類タスクで即時に結果が得られますが、埋め込まれたモデルの知識の範囲外にあるドメイン固有のデータや、時間がかかる場所の処理には、少数ショット学習の方が適しています。モデルの更新が必要です 機密データ。"},p={description:"CLIPを使用して画像とテキストを固定長ベクトルに変換します"},u={description:"マルチモーダル AI アプリケーション用のクラウド ホスティング プラットフォーム"},m={agreement:"送信すると、Jina AI が次の規定に従って個人データを処理することに同意したことになります。",anything_else:"あなたのアイデアについて詳しく教えてください",cc_by_nc:"商用利用の CC BY-NC モデルをリクエストする",cc_by_nc_description:"当社の最新モデルは、多くの場合、CC BY-NC に基づいてライセンスを取得しています。商用利用の場合は、API、Azure Marketplace、または AWS SageMaker を通じてアクセスしてください。これらのチャネル以外でローカルで使用する場合は、このボックスをチェックしてください。",company:"整理する",company_size:"組織の規模",company_website:"団体のウェブサイト",company_website_placeholder:"会社のホームページまたは LinkedIn プロフィールの URL",country:"国家",department:"部門",description:"Jina AI でビジネスを成長させましょう。",drop_area_for_image:"ここに画像をドラッグ＆ドロップします",faq:"よくある質問",feedback_sent:"提出されました！できるだけ早くご連絡させていただきます。",field_required:"フィールドは必須項目です",get_api_key:"API キーを取得するにはどうすればよいですか?",image_upload:"写真を添付する",image_validate:"最大 {_num} 枚の画像を添付できます。 JPG、JPEG、PNG、WEBP のみ。",impact_snapshots:"実際のケース",invalid_date_format:"日付形式が無効です。 DD-MM-YYYY 形式を使用してください。",invalid_email:"無効な電子メール",invalid_number:"無効な番号。もう一度入力してください",invalid_url:"無効なURL",name:"名前",nc_check:"商用ライセンスは必要ですか?",other_questions:"その他の質問",preferred_models:"どのモデルに興味がありますか?",preferred_products:"どのような製品に興味がありますか?",premium_key:"プレミアム API キー",pricing:"価格設定？",priority:"有料ユーザーへのサポートを優先する",private_statement:"プライバシーに関する声明",rate_limit:"レート制限とは何ですか?",role:"専門的な役割",self_check:"セルフテスト",sending_feedback:"送信中...",shortcut:"ショートカット",standard_key:"標準APIキー",submit:"提出する",submit_failed:"送信に失敗しました。後でもう一度試してください。",submit_success:"ご提出いただきありがとうございます。できるだけ早くご連絡させていただきます。",subtitle:"Jina AI はマルチモーダル AI 分野のリーダーであり、モデル チューニング、モデル サービング、プロンプト ワード チューニングの展開に優れています。 Kubernetes やサーバーレス アーキテクチャなどのクラウド ネイティブ テクノロジーを活用して、強力でスケーラブルな本番環境対応のソリューションを提供します。大規模言語モデル、テキスト、画像、ビデオ、音声理解、ニューラル検索、生成アートの専門知識を活かし、革新的で将来を見据えた戦略を提供してお客様のビジネスを成長させます。",subtitle1:"Jina AI は、マルチモーダル AI 分野のリーダーであり、大規模モデル ベクトルのチューニングと展開、プロンプト ワードのチューニングと展開を専門としています。 Kubernetes やサーバーレス アーキテクチャなどのクラウド ネイティブ テクノロジーを活用して、強力でスケーラブルな本番環境対応のソリューションを提供します。大規模言語モデル、テキスト、画像、ビデオ、音声理解、ニューラル検索、生成 AI に関する専門知識を活かし、革新的で将来を見据えた戦略を提供してお客様のビジネスを成長させます。",subtitle2:"最先端のマルチモーダル AI である Jina AI について学びましょう。当社はベクトル化とプロンプトワードテクノロジーを専門とし、Kubernetes などのクラウドネイティブソリューションを活用して強力でスケーラブルなシステムを構築します。当社は大規模な言語モデルとメディア処理を専門とし、高度な人工知能の専門知識を活用して、革新的で将来性のあるビジネス戦略を実現します。",title:"営業担当者に問い合わせる",trusted_by:"私たちは信頼できる",turn_on_volume:"音量を上げる",work_email:"仕事のメール"},g="コピー",b="クリップボードにコピーされました",A={description:"テキストから高解像度画像を作成するための人間とコンピュータのインタラクティブなワークフロー"},h={api_endpoint:"APIポート",api_key:"APIキー",api_tagline:"OpenAI のチャット API スキーマと完全に互換性があり、開始するには <code>api.openai.com</code> を <code>deepsearch.jina.ai</code> に置き換えるだけです。",api_title:"ディープサーチAPI",assistant_message:"アシスタント",chat_ui:{api_key_required:"APIキーが必要です!",clear_context_message:"コンテキストをクリアしてもよろしいですか?これによりダイアログがリセットされます。",clear_context_title:"新しいチャットですか？",description:"シンプルなチャット インターフェースでディープ検索が適切に機能するかどうかを確認します。ディープ サーチは、反復的な推論、世界に関する知識、または最新の情報を必要とする複雑な問題に最適です。",example_q1:"OpenAI の最新のブログ投稿の内容は何ですか?",example_q2:"node-DeepResearch プロジェクトの背後にある動機は何ですか?",example_q3:"jina-colbert-v2 は jina-colbert-v1 と比べてどのような点が改善されていますか?",input_cant_be_empty:"入力内容は空欄にできません",input_placeholder:"ここに質問を入力してください",keyman:"キーマネージャー",move_to_new:"高速、シンプル、無料の新しい Deep Search UI をリリースしました。 https://search.jina.ai で確認するか、下のボタンをクリックして試してみてください。",new_chat:"現在のチャットをクリアして新しいチャットを開始します",new_url:"新しいUIにアクセスする",payment_required:"API キーに残っているトークンが不足しています。複数の API キーがある場合は、キー マネージャーで十分なトークンを持つキーに切り替えることができます。それ以外の場合は、API キーを再チャージして続行できます。",purchase:"APIキーを再チャージ",rate_limit_exceeded:"レート制限を超えました。後でもう一度お試しいただくか、API キーを使用してレート制限を引き上げてください。",stay:"クラシックなデモUIを維持する",thinking:"考え...",thinking_done:"思考の連鎖",title:"ディープサーチチャット",use_user_key:"レート制限を高めるには、API キーを使用します。"},client_3p:"チャットクライアント",client_3p_explain:"最高のエクスペリエンスを得るには、プロフェッショナルなチャット クライアントを使用することをお勧めします。 DeepSearch は OpenAI のチャット API アーキテクチャと完全に互換性があるため、OpenAI 互換のクライアントであれば簡単に使用できます。",comparison:{group1:{bestFor:"一般知識の質問への簡単な回答",feature1:"回答は、期限が決まっている事前トレーニング済みの知識から完全に生成されます。",limitations:"リアルタイムまたは訓練された情報にアクセスできない",timeCost:"約1秒",title:"大型モデル",tokenCost:"約1000語"},group2:{bestFor:"最新情報や分野固有の情報を必要とする質問",feature1:"個々の検索結果を集約して生成された回答",feature2:"研修期限を超えて最新情報を入手できる能力",limitations:"マルチホップ推論を必要とする複雑な問題を解決する",timeCost:"約3秒",title:"RAGパラダイムと検索機能を備えた大規模モデル",tokenCost:"約10,000語"},group3:{bestFor:"徹底的な調査と推論を必要とする複雑な問題",feature1:"繰り返し検索、読み取り、推論できる自律エージェント",feature2:"現在の調査結果に基づいて次のアクションを動的に決定する",feature3:"結果を返す前に回答の質を自己評価する",feature4:"複数の検索と推論のサイクルを通じてトピックをより深く掘り下げることができる",limitations:"単純な大規模モデルやRAG法よりも時間がかかる",timeCost:"約50秒",title:"ディープサーチ",tokenCost:"約50万語"}},demo:"Deep Searchとチャット",demo_description:"シンプルなチャット インターフェースでディープ検索が適切に機能するかどうかを確認します。ディープ サーチは、反復的な推論、世界に関する知識、または最新の情報を必要とする複雑な問題に最適です。",description:"最善の答えが見つかるまで、検索し、読み、推論してください。",explain:"ディープサーチは、Web 検索、読み取り、推論を組み合わせて包括的な調査を行います。これは、あなたの研究課題を受け取るエージェントと考えることができます。広範囲に検索し、多くの反復を経て、答えを導き出します。",faq:{answer1:"Deep Search は、クエリに対する正確な回答が見つかるか、トークン予算の制限に達するまで、反復的な検索、読み取り、推論を実行する大規模なモデル API です。",answer10:"レート制限は API キー層によって異なり、10 RPM から 30 RPM の範囲になります。これはクエリを多用するアプリケーションにとって重要です。",answer11:"ディープ サーチは、思考ステップを XML タグ <think>...</think> で囲み、OpenAI フロー形式に従いながら、思考の連鎖を表すためにこれらの特別なタグを使用して最終的な答えを提供します。",answer12:"はい。 Jina Reader は Web ページの検索と読み取りに使用され、システムに Web ページのコンテンツに効率的にアクセスして処理する機能を提供します。",answer14:"はい、複雑なクエリにおける Deep Search のトークン使用量は、おそらく高く、基本的な大規模モデル応答の 500 トークンと比較して、平均 70,000 トークンです。これは研究の深さを示していますが、コストにも影響します。",answer18:"このシステムは、ステップ数ではなく、主に単語予算によって制御されます。単語単位の予算を超えると、システムはビースト モードに入り、最終的な回答を生成します。詳細については、<code>reasoning_effort</code> を参照してください。",answer19:"参照は非常に重要であり、回答が明確であるにもかかわらず参照がない場合、システムは回答を受け入れずに検索を続行します。",answer2:"OpenAI や Gemini とは異なり、DeepSearch は長い記事を生成するのではなく、反復を通じて正確な回答を提供することに重点を置いています。これは、包括的なレポートを作成するためではなく、ディープ ウェブ検索に対する高速で正確な回答を得るために最適化されています。",answer20:"はい、しかし多くの調査が必要です。 「2028 年に大統領になるのは誰か」という例は、そのような予測の正確さは保証できないものの、複数の研究の反復を通じて推測的な質問に対処することが可能であることを示しています。",answer3:"Jina API キーが必要です。新しい API キーには 1,000 万個の無料トークンを提供します。",answer5:"単に諦めたり不完全な答えを返すのではなく、蓄積されたすべての知識に基づいて最終的な答えを生成します。",answer6:"いいえ。精度を向上させるために反復検索プロセスを使用していますが、評価ではテスト問題の合格率が 75% に達しており、0% のベースライン (gemini-2.0-flash) より大幅に向上していますが、完璧ではありません。",answer7:"評価データによると、クエリには 1 ～ 42 ステップかかることがあり、平均は 4 ステップです。それは20秒です。単純なクエリはすぐに解決できますが、複雑な調査の質問には複数の反復が必要になり、最大 120 秒かかる場合があります。",answer9:"はい、deepsearch.jina.ai/v1/chat/completions にある公式の Deep Search API は、モデル名として「jina-deepsearch-v1」を使用して、OpenAI API アーキテクチャと完全に互換性があります。したがって、OpenAI から Deep Search に切り替えて、ローカル クライアントまたは任意の OpenAI 互換クライアントで使用するのは非常に簡単です。シームレスな体験のために Chatwise を強くお勧めします。",question1:"ディープサーチとは何ですか?",question10:"API のレート制限は何ですか?",question11:"<think> タグ内には何がありますか?",question12:"Deep Search は Web 検索と閲覧に Jina Reader を使用していますか?",question14:"ディープサーチではクエリになぜこれほど多くのタグが使用されるのでしょうか?",question18:"ステップ数を制御または制限する方法はありますか?",question19:"回答内の参照はどの程度信頼できるのでしょうか?",question2:"Deep Search は、OpenAI や Gemini のディープ リサーチ機能とどう違うのでしょうか?",question20:"ディープサーチは将来のイベントに関する質問を処理できますか?",question3:"DeepResearch を使用するにはどのような API キーが必要ですか?",question5:"ディープサーチがトークン予算に達すると何が起こりますか?不完全な回答が返されますか?",question6:"ディープサーチは回答の正確性を保証できますか?",question7:"典型的なディープ検索クエリにはどれくらいの時間がかかりますか?",question9:"Deep Search は、Chatwise、CherryStudio、ChatBox などの OpenAI 互換クライアントで動作しますか?",title:"ディープサーチに関するよくある質問"},last_chunk:"これはフローの最後の部分であり、最終的な回答、アクセスした URL、トークンの使用が含まれます。リアルタイムの回答を得るには、上のボタンをクリックしてください。",learn_more:"もっと詳しく知る",message:"情報",message_type:"画像/文書を添付する",message_type_explain:"テキスト (.txt、.pdf)、画像 (.png、.webp、.jpeg) など、さまざまなメッセージ タイプ (モダリティ) をサポートします。サポートされるファイルのサイズは最大 10 MB で、データ URI として事前にエンコードされている必要があります。",messages:"情報",messages_explain:"これまでのユーザーとアシスタント間の会話のメッセージのリスト。",model:"モデル",model_explain:"使用するモデルの ID。",model_name:"モデル名",open:"開ける",parameters:{arxiv_optimized_search:"Arxiv最適化検索",arxiv_optimized_search_explain:"検索エンジンはarXivの研究論文向けに最適化されました。これにより、すべての検索がarXivのみに限定されます。",auth_token:"@:トークナイザー.パラメータ.認証トークン",auth_token_explain:"DeepSearch API は無料でご利用いただけます。 API キーを提供することで、より高いレート制限にアクセスできるようになり、キーに対して料金が請求されなくなります。",bad_hostnames:"不適切なドメイン名",bad_hostnames_explain:"コンテンツ取得から除外するドメインの厳密なリスト。既知のジャンク、低品質、または無関係な Web サイトを除外するためによく使用されます。",boost_hostnames:"プレミアムドメイン",boost_hostnames_explain:"コンテンツ取得の優先度が高いドメインのリスト。価値あるコンテンツを提供する特定のドメインの高品質なソースに役立ちます。",budget_tokens:"ワード予算",budget_tokens_explain:"これにより、ディープ検索プロセスで許可されるトークンの最大数が決まります。予算を大きくすると、複雑なクエリに対してより徹底的な検索が可能になり、応答品質が向上しますが、深い検索では割り当てられた予算全体が使用されない可能性があります。これは <code>reasoning_effort</code> パラメータをオーバーライドします。",high_explain:"複雑なクエリを可能な限り推論して検索します（リクエストごとに最大 200 万語）","jina-deepsearch-v1_explain":"反復的な検索を通じて簡潔な回答を提供する",json_schema:"構造化された出力",json_schema_explain:"これにより、構造化された出力が有効になり、モデルからの最終的な回答が、指定した JSON スキーマと一致するようになります。",language_code:"回答と思考言語",language_code_explain:"回答の言語を指定し、指定された言語コードで考えることが必須です。デフォルトでは、回答の言語は入力メッセージの主言語に基づいて自動的に決定されます。回答の質は言語によって多少影響を受ける可能性があります。",low_explain:"基本的な推論と簡単なクエリの検索（リクエストあたり最大 500,000 語）",max_attempts:"最大試行回数",max_attempts_explain:"DeepSearch 中に問題 (およびそのすべてのサブ問題) を解決するための再試行の最大回数。値を大きくすると、Deep Search は異なる推論方法と解決戦略を使用して問題の解決を再試行できるようになります。このパラメータは <code>reasoning_effort</code> パラメータをオーバーライドします。",max_returned_urls:"最大リターン URL",max_returned_urls_explain:"最終的な回答/チャンクに含める URL の最大数。 URL は関連性やその他の重要な要素によってランク付けされます。",medium_explain:"中程度の推論と検索の深さ（リクエストごとに最大 100 万語）",model:"@:ディープサーチモデル",model_explain:"@:deepsearch.モデルの説明",no_direct_answer:"直接的な答えはない",no_direct_answer_explain:"クエリが些細なものに見えても、モデルはさらに思考/検索のステップを踏む必要があります。これは、「1+1=?」のような些細な質問ではなく、クエリに常に DeepSearch が必要であることが確実な状況で DeepSearch を使用する場合に便利です。",only_hostnames:"ドメイン名のみ許可する",only_hostnames_explain:"許可されたドメインのリスト内でのみ検索および読み取りを行います。その他のフィールドはすべて無視されます。特定のドメインにアクセスできない場合、または回答がまったく含まれていない場合、ディープ検索の品質は大幅に低下します。",reasoning_effort:"@:deepsearch.reasoning_effort",reasoning_effort_explain:"@:deepsearch.reasoning_effort_explain",search_language_code:"検索クエリ言語",search_language_code_explain:"検索クエリの言語を強制します。これは、リソースが特定の言語である可能性が高い場合に便利です。デフォルトでは、自動的に決定されます。",stream:"@:ディープサーチストリーム",stream_explain:"@:ディープサーチ.stream_explain",with_images:"画像を含める",with_images_explain:"このオプションを有効にすると、最終的な回答に最も関連性の高い画像が含まれます。これらの画像は、検索中に訪問したウェブサイトから取得されます。"},reasoning_effort:"推論力の強さ",reasoning_effort_explain:"推論モデルの推論ワークロードを制限します。現在サポートされている値は、Low、Medium、High です。推論のワークロードを減らすと、応答が速くなり、推論に使用される応答内のトークンが少なくなります。",stream:"ストリーミング復帰",stream_explain:"サーバーから送信されたイベントは、推論手順や最終的な回答など、イベントが発生したタイミングに関する情報を伝えます。ディープ検索リクエストは完了までに長い時間がかかる可能性があるため、このオプションを有効にしておくことを<b>強く推奨</b>します。ストリーミングを無効にすると、「524 タイムアウト」エラーが発生する可能性があります。",tagline:"@:ディープサーチの説明",title:"ディープサーチ",type_file:"ファイルを添付する",type_image:"写真を添付する",type_text:"プレーンテキストメッセージ",user_message:"ユーザー",what_is:"ディープサーチとは何ですか?"},I={description:"1 行のコードで目を引くディスコ ディフュージョン アートワークを作成"},v={description:"マルチモーダルデータのデータ構造"},k="SOC 2 タイプ 1 認定をダウンロード",P={"11B tokens":"百十億","11B tokens_intuition1":"Wikipedia ですべての英語の記事を読むのと同様です。","11B tokens_targetUser":"本番展開","1B tokens":"十億","1B tokens_intuition1":"おそらくシェイクスピア全集や「ハリー・ポッター」シリーズを全部読むのと同じだろう。","1B tokens_targetUser":"試作開発","1M tokens":"壹仟万","1M tokens_intuition1":"『ホビット』『華麗なるギャツビー』の全文を読むのに相当します。","1M tokens_targetUser":"おもちゃの実験","1M_free":"壹仟万語を無料でご利用いただけます","1M_free_description":"無料トークンを使用して新しい API キーをお楽しみください。クレジット カードは必要ありません。","2_5B tokens":"25億ワード要素","2_5B tokens_intuition1":"これは、「ロード・オブ・ザ・リング」三部作で話されたすべての単語を 1,000 回書き写すことに相当します。","3p_integration":"<b>{_numPartners}</b> 個のサードパーティ サービスがある","3p_integration_desc":"当社の検索インフラストラクチャを既存のサービスと統合します。当社のパートナーは当社の API へのコネクタを構築しているため、アプリケーションで当社のモデルを簡単に使用できます。","500M tokens":"5億トークン","500M tokens_intuition1":"シンプソンズのシーズン 1 からシーズン 30 までの全エピソードを視聴するのと同じです。","59B tokens":"59B ワード要素","59B tokens_intuition1":"これは、2 日間に世界中で投稿されたツイートすべてに相当します。","5_5B tokens":"55億ワード要素","5_5B tokens_intuition1":"これはブリタニカ百科事典の全内容を読むのと同じです。",Free1M:"壹仟万語","ReaderLM-v2_description":"生の HTML をマークダウンまたは JSON に変換するための小規模な言語モデル",add_pair:"新しい",add_time_explain:"このモデルが検索ベースに追加された時刻。",api_integration_short:"当社のベクター モデル API は、一般的なデータベース、ベクター データベース、RAG および LLMOps フレームワークで簡単に使用できます。",api_integrations:"API統合",api_key_update_message:"古い API キーを置き換えると、jina.ai にアクセスするたびに新しいキーが UI に表示されます。今後の追加はこの新しいキーに適用されます。古いキーはまだ有効なので、再度使用する予定がある場合は安全に保管してください。",api_key_update_title:"APIキーを変更する",auto_recharge:"残高が少なくなると自動的にチャージする",auto_recharge_confirm_message:"自動再チャージを無効にしてもよろしいですか?トークンの残高が少なくなると、自動リチャージが停止し、サービスやアプリケーションが中断される可能性があります。",auto_recharge_confirm_title:"自動チャージを無効にする",auto_recharge_description:"実稼働環境での中断のないサービスに推奨されます。ワード残高が設定されたしきい値を下回ると、しきい値に達するまで、保存されている支払い方法を使用して、最後に購入したパッケージが自動的にリチャージされます。",auto_recharge_enable:"自動チャージを有効にしました",auto_recharge_enable_message:"自動リチャージを有効にするには、プラン購入時に自動リチャージのスイッチをオンにしてください。",auto_recharge_enable_message2:"オートチャージ時に購入する必要があるパッケージを選択してください。",auto_recharge_enable_title:"自動補充を有効にする",auto_request:"自動プレビュー",auto_request_tooltip:"API キー内の数百のトークンを使用してモデルを変更するときに、API 応答を自動的にプレビューします。閉じたら、「応答を取得」をクリックしてリクエストを手動で送信します。",autostart:"ベクトル化が自動的に開始されます",base64_description:"ベクトルは、base64 でエンコードされた文字列として返されます。伝達効率が高くなります。",batch_job:"バッチ処理",batch_upload_hint:"バッチ処理には以下のAPIキーとモデルを使用します。","bge-base-en-v1_5_description":"性能と効率を両立し、さまざまな用途に適した強力な英国モデル。","bge-base-en_description":"確かな演奏性を追求したバランスの良い英国式モデル。","bge-base-zh-v1_5_description":"性能と効率を総合的にバランスさせた中国モデル。","bge-base-zh_description":"効率性とパワフルなパフォーマンスを兼ね備えた汎用性の高い中華モデル。","bge-large-en-v1_5_description":"優れた品質のトップベクトルを提供する強力な英語モデル。","bge-large-en_description":"高品質のベクター用に構築された一流の英語モデル。","bge-large-zh-v1_5_description":"優れた詳細なベクトルを備えた大容量の中国語モデルを提供します。","bge-large-zh_description":"上位ベクトル向けに最適化された高性能中国モデル。","bge-m3_description":"広範な機能と高品質のベクトルを提供する多言語モデル。","bge-small-en-v1_5_description":"効率的で高品質のベクトルを提供する合理化された英語モデル。","bge-small-en_description":"簡略化された正確なベクトルのための効率的な英語モデル。","bge-small-zh-v1_5_description":"柔軟で正確なベクタリングを実現するコンパクトな中国モデル。","bge-small-zh_description":"効率的かつ正確なベクトル化のためのアジャイルな中国語モデル。",binary_description:"ベクトルは int8 としてパックされます。保管、検索、転送がより効率的になります。",bulk:"バッチ処理",bulk_embedding_failed:"バッチの作成に失敗しました",buy_more_quota:"この API キーにさらにトークンを追加します",buy_poster:"ポスターを購入する",cancel_button:"キャンセル",click_upload_btn_above:"上のアップロードボタンをクリックして開始してください。",clip_v2_description:"jina-clip-v2 は、89 言語の多言語サポート、512 x 512 の高解像度画像、切り捨てられたベクトルの Matryoshka 表現学習という 3 つの大きな進歩をもたらす 0.9B CLIP スタイルのモデルです。",clip_v2_title:"Clip-v2: 多言語、マルチモーダル埋め込み",code:"コード",colbert_dimensions_explain:"各トークン ベクトルの次元サイズ。",compatible:"互換モード",compatible_explain:"テキスト ベクター モデルと同じリクエスト形式に従います。これにより、リクエストを変更せずにモデルを切り替えることができます。このモードでは画像入力はサポートされていないことに注意してください。",contact_sales:"営業担当へのお問い合わせ",contact_sales_description:"営業チームにお問い合わせください",cosine_similarity:"コサイン類似度",daily_view:"デイリービュー",debugging:"テスト",delete_pair:"消去",description:"@:landing_page.embedding_desc1",dimensions:"出力寸法",dimensions_error:"次元は 1 ～ 1024 の範囲にする必要があります。",dimensions_explain:"サイズが小さいため、マトリョーシカ表現による影響を最小限に抑えながら、効率的な保管と取得が可能になります。",dimensions_warning:"パフォーマンスを向上させるには、ディメンション サイズを {_minDimension} 以上に保つことをお勧めします。",document:"書類",document_type:{image:"画像リスト",pdf:"PDF",text:"テキストリスト",text_and_image:"テキストと画像のリスト"},download:"ダウンロード",edit_text1_text:"左側のテキストを編集する",edit_text2_text:"右側のテキストを編集します",embedding_done:"{_Count} 文のベクトル化に成功しました。",embedding_none_description:"ベクトルモデルを使用しないでください",example_explain:"画像と PDF の制限: リクエストごとに最大 16 枚の画像 (最小 28 x 28 ピクセル、各最大 8 MB) または 1 つの PDF ドキュメント (最大 8 MB、最大 16 ページ)。",example_inputs:"入力例",export_csv:"CSVにエクスポート",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"トレーニング プロセス、データ ソース、評価の詳細については、arXiv で入手可能な技術レポートを参照してください。",answer1:"Jina CLIP <code>jina-clip-v2</code> は、テキスト-テキスト、テキスト-画像、画像-画像、画像-テキストの検索タスクをサポートする高度なマルチモーダル ベクトル モデルです。テキスト間の検索のパフォーマンスが低かったオリジナルの OpenAI CLIP とは異なり、Jina CLIP はテキスト検索に優れています。 <code>jina-clip-v2</code> は、テキスト-画像およびテキスト-テキスト検索タスクにおいて <code>jina-clip-v1</code> よりもパフォーマンスが 3% 向上し、多言語画像検索用に 89 の言語をサポートし、より高解像度の画像 (512x512) を処理し、マトリョーシカ表現によってストレージ要件を削減します。詳細については、弊社の技術レポートをご覧ください。",answer17:"はい、<code>jina-clip-v2</code> と <code>jina-clip-v1</code> は画像とテキストをサポートできます。より多くのモダリティのベクトル モデルが近日中に発表される予定です。",answer18:"特定のデータを使用したモデルの微調整についてご質問がある場合は、要件についてお問い合わせください。私たちのモデルをお客様のニーズに合わせてどのように適応できるかを検討したいと考えています。",answer19:"はい、当社のサービスは AWS、Azure、GCP マーケットプレイスで利用できます。特定の要件がある場合は、セールス AT jina.ai までお問い合わせください。",answer3:"2024 年 9 月 18 日のリリースの時点で、<code>jina-embeddings-v3</code> は最高の多言語モデルであり、パラメータ数が 10 億未満のモデルの MTEB 英語リーダーボードで 2 位にランクされています。 v3 は、パフォーマンス上位 30 言語を含む合計 89 言語をサポートしています: アラビア語、ベンガル語、中国語、デンマーク語、オランダ語、英語、フィンランド語、フランス語、グルジア語、ドイツ語、ギリシャ語、ヒンディー語、インドネシア語、イタリア語、日本語、韓国語、ラトビア語、ノルウェー語、ポーランド語、ポルトガル語、ルーマニア語、ロシア語、スロバキア語、スペイン語、スウェーデン語、タイ語、トルコ語、ウクライナ語、ウルドゥー語、ベトナム語。詳細については、<code>jina-embeddings-v3</code> テクニカル レポートを参照してください。",answer4:"私たちのモデルでは、最大 8192 トークンまでの入力長が許可されており、これは他のほとんどのモデルよりもはるかに長くなります。トークンの範囲は、単一の文字 (「a」など) から単語全体 (「apple」など) までです。入力できる合計文字数は、使用される単語の長さと複雑さによって異なります。この拡張された入力機能により、<code>jina-embeddings-v3</code> モデルと <code>jina-clip</code> モデルは、特に大量の場合に、より包括的なテキスト分析を実行し、より高いレベルのコンテキスト理解を達成できるようになります。テキストデータのこと。",answer5:"API 呼び出しは最大 2048 文またはテキストを処理できるため、1 回のリクエストで広範なテキスト分析が容易になります。",answer6:"API リクエストの <code>input</code> フィールドでは、<code>url</code> または <code>bytes</code> のいずれかを使用できます。 <code>url</code> には、処理する画像の URL を指定します。 <code>bytes</code> の場合、画像を base64 形式でエンコードし、リクエストに含めます。モデルは結果として画像のベクトルを返します。",answer7:"MTEB 英語、多言語、および LongEmbed ベンチマークの評価では、<code>jina-embeddings-v3</code> は英語タスクで OpenAI と Cohere の最新独自ベクトル モデルを上回り、すべての多言語で OpenAI と Cohere の最新独自ベクトル モデルを上回りました。 <code>multilingual-e5-large-instruct</code> を超えたタスク。 Matryoshka Representation Learning (MRL) の統合により、デフォルトの出力次元は 1024 ですが、ユーザーはパフォーマンスに影響を与えることなくベクトル次元を 32 に切り捨てることができます。",answer8:"<a class='text-primary' href='https://api.jina.ai/v1/embeddings'>API エンドポイント</a>は OpenAI の <code>text-embeddings と互換性があるため、移行プロセスはスムーズでした。 -3-large</code> モデルの入力 JSON スキーマと出力 JSON スキーマが一致します。この互換性により、ユーザーは OpenAI エンドポイントを使用するときに、OpenAI モデルを当社のモデルに簡単に置き換えることができます。",answer9:`トークンは、テキストの長さと画像のサイズに基づいて計算されます。トークンは、リクエスト内のテキストに対して標準的な方法で計算されます。画像の場合は、次の手順に従います。

1. タイルサイズ: 各画像はタイルに分割されます。 <code>jina-clip-v2</code> の場合、タイルは 512x512 ピクセルですが、<code>jina-clip-v1</code> の場合、タイルは 224x224 ピクセルです。
2. カバレッジ: 入力画像をカバーするのに必要なタイルの数を計算します。画像のサイズがタイルのサイズで正確に割り切れない場合でも、部分的なタイルは完全なタイルとして扱われます。
3. タイルの総数: 画像を覆うタイルの総数によってコストが決まります。たとえば、600 x 600 ピクセルの画像は、v2 では 2 x 2 タイル (4 タイル) で覆われ、v1 では 3 x 3 タイル (9 タイル) で覆われます。
4. コスト計算: <code>jina-clip-v2</code> の場合、タイルあたりのコストは 4000 トークンですが、<code>jina-clip-v1</code> の場合、タイルあたりのコストは 1000 トークンです。

例：
サイズが 600 x 600 ピクセルの画像の場合:

• <code>jina-clip-v2</code> を使用する
• 画像は 512 x 512 ピクセルのタイルに分割されます。
• 必要なタイルの合計数は、2 (水平) x 2 (垂直) = 4 タイルです。
• <code>jina-clip-v2</code> のコストは 4*4000 = 16000 トークンです。

• <code>jina-clip-v1</code> を使用する
• 画像は 224 x 224 ピクセルのタイルに分割されます。
• 必要なタイルの合計数は、3 (水平) x 3 (垂直) = 9 タイルです。
• jina-clip-v1 のコストは 9*1000 = 9000 トークンです。`,question0:"jina-embeddings-v3 モデルはどのようにトレーニングされますか?",question1:"jina-clipモデルとは何ですか?テキスト検索や画像検索にも使えますか？",question17:"ベクターモデル画像やオーディオモデルを提供していますか?",question18:"Jina Embedding モデルは個人データまたは企業データを使用して微調整できますか?",question19:"サービスを AWS、Azure、または GCP にプライベートにデプロイできますか?",question3:"あなたのモデルはどの言語をサポートしていますか?",question4:"単一の文入力の最大長はどれくらいですか?",question5:"1 つのリクエストには何文を含めることができますか?",question6:"jina-clip モデルに画像を送信するにはどうすればいいですか?",question7:"Jina Embeddings モデルは、OpenAI や Cohere の最新のベクトル モデルとどのように比較されますか?",question8:"OpenAI の text-embedding-3-large から Jina Embeddings モデルに移行するにはどうすればよいですか?",question9:"jina-clipモデルを使用する場合のトークンの計算方法は?",title:"ベクトル モデルに関するよくある質問"},feature_8k1:"8192長さ",feature_8k_description1:"8192 ワード長の世界初のオープンソース ベクトル モデルは、人民日報のページ全体をベクトルに圧縮できます。",feature_cheap:"コストを50倍削減",feature_cheap_v1:"5倍のコスト削減",feature_cheap_v1_description1:"まずは無料トライアル、シンプルな料金体系、迅速な支払いから始めてください。 OpenAI のコストのわずか 20% で強力なベクトル モデルを入手できます。",feature_multilingual:"海外企業の多言語アプリケーションに不可欠な、ドイツ語-英語、中国語-英語、その他のバイリンガル モデルを提供します。",feature_on_premises:"プライバシー第一",feature_on_premises_description1:"ベクター モデルを Virtual Private Cloud (VPC) に直接シームレスにデプロイします。 AWS Sagemaker に簡単にデプロイでき、まもなく Microsoft Azure および Google Cloud Platform と統合される予定です。 Kubernetes の展開をカスタマイズするには、当社の営業チームに専門的なサポートをお問い合わせください。",feature_on_premises_description2:"当社のベクトル モデルは AWS Sagemaker に簡単にデプロイでき、まもなく Microsoft Azure および Google Cloud Services でのサポートを提供する予定です。 Kubernetes の展開をカスタマイズするには、当社の営業チームに専門的なサポートをお問い合わせください。",feature_on_premises_description3:"Jina Embeddings モデルを AWS Sagemaker と Microsoft Azure にデプロイし、まもなく Google Cloud サービスにもデプロイするか、当社の営業チームに問い合わせて、仮想プライベート クラウドとオンプレミス サーバー用のカスタム Kubernetes デプロイメントを入手してください。",feature_on_premises_description4:"AWS SageMaker、Microsoft Azure、または Google Cloud Services を使用して Jina Embedding モデルと Reranker モデルをローカルにデプロイし、データを安全に管理します。",feature_solid:"並外れた",feature_solid_description1:"当社の確かな AI 科学研究活動に基づいて、モデルの最高のパフォーマンスを保証するために、同様のモデルとの厳格な比較テストを実施しました。",feature_top_perform1:"シームレス統合",feature_top_perform_description1:"OpenAIのAPIと完全に互換性があります。 10 を超えるベクター データベースや RAG システムと簡単に統合できるため、開発者エクスペリエンスがスムーズになります。",file_required:"ファイルをアップロードしてください",file_size_exceed:"ファイルサイズが {_size} 制限を超えています",file_type_not_supported:"サポートされていないファイル形式",fill_example:"記入例",float_description:"ベクトルは浮動小数点数のリストとして返されます。最も一般的で使いやすい。",free:"無料",generate_api_key_error:"API キーの生成に失敗しました。",generating_visualization:"ビジュアライゼーションを生成...",get_new_key_button:"新しいキーを取得する",get_new_key_button_explain:"新しいキーを選択すると、古いキーに関連付けられていた使用履歴が失われます。",get_new_key_survey:"アンケートに記入して使用状況を把握し、新しい API キーを無料で入手してください。",hourly_view:"1時間ごとに表示",includes:"購入したワード要素は以下の製品で使用できます。",index_and_search:"インデックス作成と検索",index_and_search1:"インデックス作成と検索",input:"聞く",input_api_key_error1:"API キーが無効です。",input_length:"長さを入力してください",input_type:"ドキュメント/クエリとして埋め込む",input_type_explain:"検索ロールに応じて、同じ入力をクエリまたはドキュメントとして埋め込むことができます。",integrate:"統合された",je_v4_description:"jina-embeddings-v4 は、これまでで最も大きな飛躍です。統一されたパスを介してテキストと画像を埋め込み、高密度検索と遅延インタラクティブ検索の両方をサポートする 38 億のモデルで、特に視覚的に豊富なドキュメント検索において、Google、OpenAI、Voyage AI の独自モデルよりも優れています。",je_v4_title:"v4: マルチモーダル多言語検索のためのユニバーサル埋め込み","jina-clip-v1_description":"画像と英語テキストのマルチモーダルベクトルモデル","jina-clip-v2_description":"テキストと画像のための多言語およびマルチモーダルベクターモデル","jina-colbert-v1-en_description":"改良された ColBERT モデルは 8K 長さのコンテキストをサポートし、ベクトル化および再配置タスクに使用できます。","jina-colbert-v2_description":"ベクトル化と並べ替えで最高のパフォーマンスを発揮する最新の多言語 ColBERT","jina-embedding-b-en-v1_description":"伝説の OG、Jina ベクター モデルの最初のバージョン。","jina-embeddings-v2-base-code_description":"コードおよび技術文書検索用のベクトル モデル","jina-embeddings-v2-base-de_description":"ドイツ語と英語のバイリンガルをサポートする 8K 最高のベクトル モデル","jina-embeddings-v2-base-en_description":"OpenAI の text-embedding-ada002 に相当","jina-embeddings-v2-base-es_description":"スペイン語と英語のバイリンガルをサポートする 8K 最高のベクトル モデル","jina-embeddings-v2-base-zh_description":"中国語と英語のバイリンガリズムをサポートする 8K 最高のベクトル モデル","jina-embeddings-v2-small-en_description":"低レイテンシーと少量のメモリ向けに最適化","jina-embeddings-v3_description":"テキストとコードの両方で最適なパフォーマンスを備えた最新かつ最高のベクトル化モデル","jina-embeddings-v4_description":"マルチモーダル・多言語検索のための汎用ベクトルモデル","jina-reranker-m0_description":"視覚的な文書をランク付けするための多言語マルチモーダルリランカー","jina-reranker-v1-base-en_description":"最初のリランカーは検索と RAG 関連性を最大化します","jina-reranker-v1-tiny-en_description":"大量のドキュメントを確実に並べ替えるための最速の並べ替え機能","jina-reranker-v1-turbo-en_description":"速度と精度の間の最適なトレードオフ","jina-reranker-v2-base-multilingual_description":"クラス最高の精度と速度パフォーマンスを備えた最先端の多言語ドキュメントおよびクエリ リフォーマー",key:"APIキー",key_enter_placeholder:"API キーを入力してください",key_enter_placeholder_to_topup:"トップアップしたいAPIキーを入力してください",key_to_top_up:"他に追加する API キーがありますか?上記の内容を貼り付けて「保存」をクリックします。",key_warn:"API キーは安全な場所に保管してください。それ以外の場合は、新しいキーを生成する必要があります",key_warn_v2:"これはあなた固有のキーです。大切に保管してください！",language_explain:"このモデルは、{_language} 言語を最もよくサポートしています。",last_7_days:"使用法",late_chunking:"遅延分離技術",late_chunking_explain:"モデルの長いコンテキスト機能を活用してコンテキスト ブロックのベクトル化を生成するために、後期ステップ手法が適用されます。",learn_more:"もっと詳しく知る",learn_poster:"ポスターを知る",learning1:"ベクトルモデルの学習",learning1_description:"ベクトルとは何ですか?なぜベクトル化する必要があるのですか?始めるための記事がいくつかあります。包括的なガイドでベクトル モデルについて基礎から学びましょう。",length:"長さ",manage_billing:"請求書の管理",manage_billing_tip:"請求情報を管理し、請求書を取得し、自動チャージを設定します。",manage_quota1:"鍵と請求",max_file_size:"最大許容サイズ: {_maxSize}。",maximize_tooltip:"このパネルを最大化するには Shift+1 を使用します",mistake_contact:"これがバグだと思われる場合は、お問い合わせください。",mminput_placeholder:"テキスト、画像 URL、画像の Base64 文字列",model_required:"モデルを選択してください",more_models:"他 {_numMore} 個のモデル",more_than_two2:"文書は 2 つ以上、つまり 2 行以上入力してください。",multi_embedding:"マルチベクトル",multi_embedding_explain:"モデルは入力に対してベクトルのセットを返します。入力文内の各トークンは個別のベクトルにマッピングされます。",multilingual:"多言語サポート",multimodal:"マルチモダリティ",multimodal_explain:"このモデルはテキスト入力と画像入力の両方をエンコードできるため、マルチモーダル検索タスクに最適です。",new:"ニューモデル",new_price_apply:"新しい価格モデルは 2025 年 5 月 6 日に開始されました。この日付より前に自動リチャージを有効にしていた場合、以前の価格 (つまり購入時の価格) が引き続き請求されます。新しい価格は、自動再チャージ設定を変更した場合、または新しい API キーを購入した場合にのみ適用されます。",no_data1:"ペアの文を追加して類似度を計算します",none:"なにもない",normalized:"L2正規化",normalized_explain:"方向を維持しながら、ユークリッド (L2) ノルムが 1 になるように埋め込みをスケーリングします。下流でドット積、分類、視覚化が行われる場合に役立ちます。",oncsp:"CSPについて",onprem:"プライベート展開",open_tensorboard:"視覚化ツールを開く",opensource:"オープンソース",opensource_explain:"モデルはオープンソースであり、Hugging Face からダウンロードできます。このボタンをクリックすると、Hugging Face のモデルが表示されます。",original_documents:"ベクトル化された文章",original_documents_hint:"ここに文章を入力してください。新しい行はそれぞれ別の文/文書として扱われます。",output:"応答",output_dim:"出力寸法",output_dim_explain:"このモデルのベクトル出力の次元は {_outputDim} です。",output_dimension:"出力寸法",pairwise_test:"ペアテスト",per_k:"千語あたり",per_m:"100万語あたりの単語",please_fill_docs_first:"検索する前に、以下に文章を入力してください。",please_select_model:"埋め込みモデルまたはリランカー モデルを選択してください",poster:"ベクターモデル70年",poster_description:"当社の丁寧に作られたポスターをオフィススペースやリビングルームに飾って、1950 年以来のテキスト ベクター モデルの進化と進化から次のインスピレーションを見つけてください。",pricing:"API価格表",pricing_desc:"API の価格はトークンの使用量に基づいて決まります。すべての Search Essentials 製品にアクセスするための 1 つの API キー。",protectData1:"あなたが私たちに送ったデータや文書はモデルのトレーニングには使用されません。",protectData2:"データは転送中 (TLS 1.2+) および保存中 (AES-GCM 256) で暗号化されます。",protectData3:"SOC 2 および GDPR への準拠。",protect_data:"データを保護する",public_cloud_integration:"<b>{_numPartners}</b> のクラウド サービス プロバイダーと連携します",public_cloud_integration_desc:"あなたの会社は AWS または Azure を使用していますか?次に、当社の検索インフラストラクチャ モデルを社内のこれらのプラットフォームに直接展開して、データの安全性と準拠性を維持します。",query:"クエリ文",raise_issue:"問題のフィードバック",rank_none_description:"再配置モデルは使用しないでください",read_api_docs:"API仕様",read_release_note:"リリースノートを読む","reader-lm-05b_description":"生の HTML を Markdown に変換するための小さな言語モデル","reader-lm-15b_description":"生の HTML を Markdown に変換するための小さな言語モデル",recharge_threshold:"この値より低い場合は充電してください",refresh:"リフレッシュする",refresh_key_tooltip1:"新しい API キーを無料で取得する",refresh_token_count1:"更新して現在の API キーで使用可能なトークンを取得します",regenerate:"新しいキーを生成する",remaining:"トークン残量",remaining_left:"以下の API キーには <b>{_leftTokens}</b> 個のトークンが残っています。",request_number:"リクエスト数",request_path:"エンドポイント",requests:"聞く",rerank_multimodal_explain:"このモデルはテキストと画像の両方の入力を並べ替えることができるため、マルチモーダル検索タスクに最適です。",results_as_final_result:"最終結果として #docs",results_fed_to_reranker:"リランカーへの #docs フィード",retry:"リトライ",return_base64:"Base64 (文字列)",return_binary:"バイナリ (int8 としてパック)",return_float:"デフォルト (浮動小数点)",return_format:"ベクトル形式",return_format_explain:"浮動小数点に加えて、ベクトルの取得を高速化するためにバイナリに設定したり、転送を高速化するために base64 エンコードに設定することもできます。",return_format_title:"出力データ型",return_multi_vector:"出力マルチベクトル",return_multi_vector_explain:"有効にすると、モデルは各文書に対してNxDマルチベクトルを返します。ここで、Nは文書内のトークンの数です。これは、対話型スタイル検索後の処理に役立ちます。",return_ubinary:"バイナリ (uint8 としてパック)",right_api_key_to_charge:"リチャージするには正しい API キーを入力してください",rpm_avg:"平均回転数",rpm_last7DaysTotal:"過去7日間の合計",rpm_max:"最大回転数",rpm_min:"最小回転数",rpm_p50:"平均回転数",rpm_p90:"90パーセンタイルRPM",rpm_p95:"95 パーセンタイル RPM",rpm_p99:"99パーセンタイルRPM",running:"ランニング",score:"分数",search:"検索",search_hint:"次の文に検索したい内容を入力してください",select_classify_model:"分類子の選択",select_embedding_model:"埋め込みを選択",select_rerank_model:"再注文者の選択",show_api_key:"APIキーを表示",size:"パラメータ",size_explain:"モデル内のパラメータの数は {_size} です。これはモデルのファイル サイズを表すものではないことに注意してください。",sleeping:"睡眠",start_batch:"バッチ処理を開始する",start_embedding:"インデックス作成の開始",status_explain:"当社のサーバーレス アーキテクチャでは、使用状況に応じて、現在使用されていない一部のモデルをメモリから即座にオフロードする場合があります。アクティブなモデルの場合、応答は即時に行われます。休止中のモデルは最初のリクエストを受信するまでロードされず、このプロセスは数十秒かかる場合があります。モデルが起動されると、後続のリクエストはより速く処理されます。",task_type:"下流タスク",task_type_classification:"分類",task_type_classification_explain:"テキストの分類。",task_type_code_passage_explain:"コード検索タスクのためにコード ドキュメントをベクトル化します。",task_type_code_query_explain:"コード取得タスクにおけるクエリのベクトル化。",task_type_explain:"当社のベクトルモデルは汎用性が高く、一般的なタスクで優れたパフォーマンスを発揮します。タスクが設定されると、そのタスクに合わせて高度に最適化されたベクトルが提供されます。",task_type_none_explain:"LoRAアダプタは使用されません。デバッグやハッキングに使用できる汎用ベクトルが返されます。",task_type_retrieval_passage:"検索チャンネル",task_type_retrieval_passage_explain:"クエリドキュメント取得タスクのためにドキュメントをベクトル化します。",task_type_retrieval_query:"検索クエリ",task_type_retrieval_query_explain:"クエリドキュメント取得タスクにおけるクエリのベクトル化。",task_type_separation:"分離",task_type_separation_explain:"クラスタリングドキュメント、視覚化コーパス。","task_type_text-matching":"テキストマッチング","task_type_text-matching_explain":"セマンティックテキストの類似性、一般化された対称検索、推奨、類似アイテムの検索、および重複排除。",tax_may_apply:"お住まいの地域によっては、米ドル、ユーロ、またはその他の通貨で請求される場合があります。税金が適用される場合があります。",text1:"左",text2:"右",three_ways:"3つの購入方法",three_ways_desc:"API をサブスクライブするか、クラウド プロバイダーを通じて購入するか、組織の商用ライセンスを取得します。",title:"ベクトルモデルAPI",token_example:"Weibo の投稿には約 20 トークンがあり、人民日報のニュース記事には約 1,000 トークンがあり、チャールズ ディケンズの小説「二都物語」には 100 万以上のトークンがあります。",token_length_explain:"このモデルでサポートされる入力トークンの最大長は {_tokenLength} です。",tokens:"単語要素",tools:"道具",top_up_button:"古いキーを補充する",top_up_button_explain:"この API キーを統合すると、キーを頻繁に変更する必要がなく、より専門的なソリューションが提供されます。使用状況データは保持され、いつでもアクセスできます。",top_up_warning_message1:"現在の API キーには {_remainedTokens} トークンが残っており、{_freeTokens} トークンを持つ新しいキーに置き換えられます。古いキーを安全な場所に保管している場合は、古いキーを引き続き使用するか、追加することができます。どのように進めたいですか?",top_up_warning_title:"古い鍵を交換しますか?",total_documents:"ベクトル化の進行状況: {_Processed}/{_Count} 文。",total_quantity:"作成以降のトークンの総数",total_request:"作成以降のリクエストの総数",truncate:"最大長に切り捨て",truncate_explain:"有効にすると、モデルはエラーをスローするのではなく、モデルで許可されている最大コンテキスト長を超える末尾を自動的に削除します。",tuning:"微調整",turnstile_error:"あなたが人間であることを確認できないため、API キーを生成できません。",turnstile_unsupported:"お使いのブラウザはサポートされていないため、API キーを生成できません。",ubinary_description:"ベクトルは uint8 としてパックされます。保管、検索、転送がより効率的になります。",unknown:"未知",upload:"アップロード",upload_file:"ファイルをアップロードするにはここをクリックしてください",usage:"投与量",usage_amount:"単語要素",usage_history:"過去7日間の使用状況",usage_history_explain:"データはリアルタイムではないため、数分遅れる場合があります。",usage_reason:"説明する",usage_reason_consume:"呼ばれた",usage_reason_purchase:"買った",usage_reason_transfer_in:"転入",usage_reason_transfer_out:"転出",usage_reason_trial:"新しいAPIキーごとに無料トークンが付属",usage_rerank:"使用法",usage_time:"時間日付",v3_description:"<code>jina-embeddings-v3</code> は、5 億 7000 万のパラメータと 8192 トークン長を備えた最先端の多言語テキスト埋め込みモデルであり、MTEB 上の OpenAI および Cohere の最新の独自の埋め込みモデルよりも優れています。以下のブログ投稿と研究論文をお読みください。",v3_title:"v3: 最上位の多言語ベクトル モデル",vector_database_integration1:"統合された",vector_database_integration2:"当社のベクター モデル API は、一般的なデータベース、ベクター データベース、RAG および LLMOps フレームワークで簡単に使用できます。開始するには、API キーを以下の統合のいずれかにコピーするだけで、モデルをすぐに使用できます。",vector_database_integration3:"当社の Embedding & Reranker API は、さまざまなよく知られたデータベース、ベクター ストア、RAG および LLMOps フレームワークとネイティブに統合します。まず、API キーをコピーして、リストされている統合のいずれかに貼り付けるだけで、迅速かつシームレスに開始できます。",vector_database_integration_description:"Jina Embeddings API を、以下のベクター データベース、大規模モデル オーケストレーション フレームワーク、RAG アプリケーションのいずれかとシームレスかつ簡単に統合します。チュートリアルでその方法を説明します。",view_details:"詳細を確認する",visualization_example:"このセクションのすべての文を 3D ベクトル空間にマッピングします",visualization_example_you_can:"以下の API を使用すれば、あなたもそれを行うことができます。",visualize:"視覚化",visualize_done:"ビジュアライゼーションが完了したので、上部のボタンをクリックしてビジュアライザを開くことができます。",wait_for_processing:"リクエストは処理中です。",wait_stripe:"Stripe 支払いを開始します。お待ちください。",what_are_embedding:"ベクトル化とは何ですか?",what_are_embedding_answer:`コンピューターに単語やフレーズの微妙な意味を教えることを想像してみてください。従来のアプローチは、厳密なルールベースのシステムに依存していますが、言語が複雑かつ流動的であるため、望ましい結果を達成できません。入力テキストの埋め込み: テキストを数値言語、特に高次元空間のベクトルに変換するための強力なソリューションです。

「晴天」と「快晴」というフレーズを考えてみましょう。私たちにとって、彼らは同じような絵を描いています。埋め込みパースペクティブを通じて、これらのフレーズは、この多次元空間で互いに近い数値ベクトルに変換され、意味上の類似性が捕捉されます。ベクトル空間におけるこの近接性は、単に単語やフレーズの類似性を意味するものではなく、文脈、感情、さらには意味のニュアンスを理解することにも関係します。

この画期的な進歩がなぜ重要なのでしょうか?まず、人間の言語の豊かさとアルゴリズムの計算効率の間のギャップを埋めます。アルゴリズムはテキストの解釈ではなく、数値の処理に適しています。テキストをベクトルに変換することにより、埋め込みにより、これらのアルゴリズムは以前は不可能だった方法で言語を「理解」し、処理できるようになります。

実際の応用例は多岐にわたります。自分の興味に合ったコンテンツを推奨する場合でも、人間味あふれる会話型 AI を強化する場合でも、さらには大量のテキスト内の微妙なパターンを検出する場合でも、埋め込みが鍵となります。これらにより、機械は感情分析、言語翻訳、そしてますます微妙で洗練された言語理解などのタスクを実行できるようになります。`,what_is_a_token:"テキスト処理におけるトークンは単位であり、通常は単語です。たとえば、「Jina AI はすごいです!」は句読点を含めて 5 つのトークンになります。",why_do_you_need:"最適なベクトル モデルを選択する",why_do_you_need_after:"深層学習と高度な言語処理テクノロジーを通じて、当社のベクトル モデルは、複雑なマルチモーダル データを簡素化された形式に変換できます。これにより、機械の理解が向上するだけでなく、以下を含むより複雑な AI アプリケーションを実装する可能性も提供されます。データ解析機能の向上、ユーザー対話の増加、言語の壁の排除、開発プロセスの改善などです。",why_do_you_need_before:"当社のベクトルは、さまざまな検索および GenAI アプリケーションをカバーするように設計されています。",why_need_1_description:"私たちは、JinaBERT によって作成されたベクトル ベース モデルを利用して、さまざまなシナリオに合わせて設計します。長いテキストの解析に優れており、意味検索、内容分類、深い言語分析などのタスクに適しています。この多用途性により、センチメント分析ツール、テキスト要約、およびパーソナライズされた推奨システムの開発に最適です。",why_need_1_title:"普遍的なベクトル",why_need_2_description:"当社のバイリンガル モデルは、言語の壁を取り除き、コミュニケーション効率、グローバルな顧客サポート、多言語プラットフォーム全体での言語を超えたコンテンツの発見を向上させるように設計されています。ドイツ語-英語、中国語-英語の双方向翻訳に重点を置いており、異なる言語のユーザーがより簡単に理解してコミュニケーションをとることができます。",why_need_2_title:"バイリンガルベクトル",why_need_3_description:"コードの要約、コード生成、自動コード レビューなどのタスクを簡素化するために開発者向けに特別に設計されたコード ベクトル モデル。コード構造を徹底的に分析し、改善提案を提供することにより、開発効率が大幅に向上します。これは、高度な IDE プラグイン、自動生成ドキュメント、革新的なデバッグ ツールを開発するための鍵となります。",why_need_3_title:"コードベクトル",why_need_4_description:"Jina CLIP は、画像とテキスト用の最新のマルチモーダル埋め込みモデルです。 OpenAI CLIP に対する大きな改善点は、この単一のモデルをテキスト間検索だけでなく、テキスト画像、画像テキスト、画像間検索タスクにも使用できることです。したがって、1 つのモデル、2 つのモダリティ、4 つの検索方向があります。",why_need_4_title:"マルチモーダル埋め込み",write_email_here:"完了時にダウンロードリンクを受け取りたい電子メールを入力してください。",you_can_leave:"このページから離れても構いません。完了したら、ダウンロード リンクを送信します。"},y={description:"世界クラスのマルチモーダル、多言語埋め込み。"},f={contractType:{department:"サブセクターライセンス",poc:"概念実証 (3 ～ 6 か月)",standard:"標準エンタープライズライセンス",title:"契約種類"},department:{businessSponsor:"事業部内の推薦者",executionModel:"実行モデル",growth:{high:"企業全体の可能性を特定する",highDesc:"全社展開を目指した戦略的取り組みを計画",limited:"制限された部門",limitedDesc:"標準サポートにより個々の部門のニーズに焦点を当てる",steady:"他の分野での可能性",steadyDesc:"12か月以内に2～3部門に拡大予定"},growthTitle:"成長の軌跡",sponsorDescription:"実装を提唱し、戦略的方向性を提供し、リソースが確実に割り当てられるようにする専任のエグゼクティブ スポンサー"},descriptions:{contractType:{department:"単一部門で導入され、後で柔軟に拡張可能",poc:"特定の環境およびユースケースでモデルをテストするための実験的デプロイメント",standard:"完全なエンタープライズ展開、無制限のモデル使用"},department:{growth:"他部門への活用拡大も予定",sponsorship:"収益を生み出す部門が導入をサポートしているかどうかを示します"},features:{csm:"パーソナル カスタマー サクセス マネージャーが戦略的なガイダンスとサポートを提供します",priority:"重要な問題への迅速な対応を保証する",training:"特定のデータに合わせてモデルを事前トレーニングまたは微調整するのに役立ちます"},models:{clip:"マルチモーダルアプリケーション向けの画像とテキストの処理",colbert:"高精度な文書検索を実現する特別モデル",embeddings:"セマンティック検索とテキスト類似性のためのテキスト ベクトル モデル",reader:"HTML コンテンツをクリーンなマークダウン形式に変換する",reranker:"検索結果を微調整して関連性を高める"},payment:{annual:"年1回の簡素化された会計支払い",quarterly:"3ヶ月ごとの定期支払い"},poc:{duration:"環境内でモデルのパフォーマンスをテストおよび検証するためのタイムライン",metrics:"重要なパフォーマンス指標とモデルの有効性を追跡する"},support:{enterprise:"最優先の包括的なサポート範囲",premium:"追加の相談時間とより迅速な応答時間",standard:"基本的な技術サポートと実装ガイダンス"},usage:{business:"私たちのモデルを活用したアプリケーションを使用するさまざまな企業がどれくらいあるでしょうか",consumer:"毎月何人のエンド ユーザーがモデルを操作するか"}},features:{csm:"専任のアカウントマネージャー",priority:"優先対応SLA（4時間以内）",title:"その他の機能",training:"カスタムモデルトレーニングのサポート"},interests:"この構成の商用ライセンス (${_Price}) に興味があります",labels:{basePrice:"基本価格",custom:"カスタム価格については営業にお問い合わせください",discountApplied:"すでに割引を受けています",included:"基本料金に含まれるもの",learnMore:"もっと詳しく知る",priceQuarterly:"四半期あたりの価格",selectAll:"すべてのモデルを選択してください",selectSupport:"サポート層を選択してください",totalPrice:"合計金額",upTo:"最大 {count}"},messaging:{additionalFeatures:"追加機能は次のとおりです。",baseModelIncluded:"基本的なベクトル モデル (jina-embeddings-v3) が含まれています",deptIncludes:"部門ライセンスには次のものが含まれます。",deptReviews:"四半期ごとの事業検討会議",deptRoadmap:"事業拡大ロードマップの策定",deptSponsor:"エグゼクティブスポンサー調整会議",deptWorkshops:"部門横断連携セミナー",enterpriseAlert:"あなたの使用レベルは、これが企業全体の機会であることを示しています。カスタムのエンタープライズ契約について話し合うための電話をスケジュールしましょう。",noModelsSelected:"他のモデルは選択されていません。基底ベクトル モデルを使用します。",pocCheckins:"技術チームとの 2 週間ごとのチェックイン",pocIncludes:"POC パッケージには以下が含まれます。",pocMetrics:"成功指標追跡ダッシュボード",pocMigration:"フルライセンスへの移行をサポート",pocTemplate:"POC結果文書テンプレート",selectedModels:"選択したモデル:",standardFeatures:"標準ライセンスの機能:",supportTierIncluded:"{tier} サポート階層には {時間} が含まれます",usageTierBusiness:"ビジネス利用レベル: 最大 {count} 個のビジネス アカウント",usageTierConsumer:"一般ユーザー向けの使用量レベル: 1 か月あたり最大 {count} 人のアクティブ ユーザー"},models:{clip:"ジナクリップ-v2",colbert:"ジナコルベールv2",description:"ビジネス パッケージに含めるモデルを選択してください",embeddings:"ジナベクターv3",lm:"リーダー映画",reranker:"ジナリランカーv2",title:"モデルを選択してください"},payment:{annual:"年間決済（10％割引）",features:"含まれる機能",quarterly:"四半期ごとに請求される",title:"支払い条件"},poc:{description:"POC には、成功指標の追跡と完全なライセンス アップグレード パスが含まれています",duration:"POC期間（月）"},pricing:{annual:"年",cta:"弊社営業スタッフまでお問い合わせください",disclaimer:"この料金計算ツールは見積もりを提供します。最終的な価格は、特定の要件、数量の約束、カスタム構成によって異なる場合があります。詳細な見積もりについては、当社の営業チームにお問い合わせください。",frequency:"${price} / {frequency}",oneTime:"1 回あたり ${price}",pocTotal:"{months} の月間 POC 価格: ${price}",quarterly:"四半期",title:"推定価格"},short_title:"ライセンスの構成",subtitle:"Jina AI モデルのエンタープライズ ライセンスを構成する",support:{enterprise:"高度な",hoursQuarter:"{時間} 時間/四半期",premium:"標準",standard:"軽量",title:"サポート層"},title:"エンタープライズ ライセンス コンフィギュレーター",tooltips:{annualDiscount:"年払いで 10% 割引",businessSponsor:"事業部門のスポンサーに追加の割引を受けてもらう",pocDuration:"概念実証期間の期間を選択します",supportTier:"ニーズに最適なサポート レベルを選択してください",usageLimit:"これらの制限を超えた場合は、カスタム価格についてお問い合わせください。"},usage:{business:"B2B (ビジネスアカウント)",businessCount:"ビジネスアカウントの数",businessDescription:"私たちのモデルを使用したさまざまなビジネスアカウントの数",consumer:"B2C (エンドユーザー)",consumerCount:"月間アクティブユーザー数",consumerDescription:"すべてのアプリケーションにわたる月間アクティブ エンド ユーザーの数",title:"使用構成"}},w={answer1:"Jina AI は、大規模なモデル ベクトルの調整と展開、プロンプト ワードの調整と展開など、マルチモーダル AI テクノロジーに焦点を当てています。当社は、Kubernetes やサーバーレス アーキテクチャなどの高度なツールを活用して、強力でスケーラブルで実稼働対応のソリューションを作成します。",answer10:"プロジェクトの性質とクライアントのニーズに応じて、さまざまなライセンス オプションを提供します。詳細な条件については、当社の営業チームにご相談ください。",answer11:"当社はヨーロッパのベルリンに本社を置き、北京と深センにオフィスを構え、世界中でサービスを提供しています。",answer12:"はい、特にベルリン、北京、深センのオフィス近くにお住まいのお客様にオンサイト サポートを提供しています。他の拠点については、可能な限り最高のリモート サポートを提供するよう努め、必要に応じてオンサイト サポートを手配します。",answer2:"当社の専門知識は、大規模言語モデル、テキスト、画像、ビデオ、音声理解、ニューラル検索、生成 AI など、幅広い分野にわたります。",answer3:"はい、当社のソリューションはスケーラブルで実稼働対応できるように設計されています。当社はクラウドネイティブ テクノロジーを使用してソリューションを構築し、実稼働環境で効率的なスケーリングと信頼性の高いパフォーマンスを実現します。",answer4:"当社のサービスは多用途で、電子商取引、リーガルテック、デジタルマーケティング、ゲーム、ヘルスケア、金融など、さまざまな業界に適応できます。",answer5:"このページのお問い合わせフォームから当社の営業チームにご連絡いただけます。お客様のプロジェクトのニーズや、当社のソリューションがお客様のビジネスにどのように役立つかについて喜んでご相談させていただきます。",answer6:"当社は、ソリューションがスムーズに実行されるように継続的なサポートを提供します。これには、トラブルシューティング、定期的な更新、フィードバックやニーズに基づく改善が含まれます。",answer7:"プロジェクトの期間は、プロジェクトの複雑さと範囲によって異なります。お客様のご要望を理解できましたら、より正確なお見積りをご提供させていただきます。",answer8:"データのセキュリティは当社の最優先事項です。当社は、お客様のデータの安全性と機密性を確保するために、厳格なデータ保護ポリシーと規制を遵守しています。",answer9:"価格はプロジェクトの複雑さと要件によって異なります。当社では、プロジェクトベースの価格モデルと維持価格モデルを提供しています。詳細については、当社の営業チームにお問い合わせください。",question1:"ジナAIは何が得意ですか?",question10:"ソリューションのライセンス条件は何ですか?",question11:"サービスエリアはどこですか?",question12:"オンサイトサポートはありますか?",question2:"Jina AI はどのような種類の人工知能に適していますか?",question3:"あなたのソリューションはスケーラブルで、実稼働の準備ができていますか?",question4:"Jina AI のソリューションから恩恵を受けるのはどの業界ですか?",question5:"Jina AI を使用してプロジェクトを開始するにはどうすればよいですか?",question6:"ソリューション導入後はどのようなサポートを提供しますか?",question7:"プロジェクトの通常の期間はどれくらいですか?",question8:"Jina AI は私のデータをどのように保護しますか?",question9:"サービスの料金体系は何ですか?"},x="よくある質問",R={text:"別れを告げる。",toggle_btn:"次回訪問するときは、このパネルを開いたままにしてください",warning_message:"jina.ai にアクセスすると、このパネルが自動的に開きます。 Web サイトのコンテンツを表示するには、Web サイトを閉じる必要があります。この設定を有効にしますか?",warning_title:"起動時に表示される"},L={description:"検索品質を向上させるためにドメイン固有のデータに合わせて大規模なモデル ベクトルを調整する",intro:"あなたの会社、データ、モデル"},M={description:"ビジネス向けのローカルチューニングソリューション"},q={api_key:"API キーを入力します。",back:"戻る",base_model_selected:"ベースモデルを選択してください",click_start:"規約に同意して微調整を開始します。",confirm_title:"微調整作業の確認",confirm_your_email:"電子メール アドレスを再入力して、調整が機能していることを確認します。アップデートとダウンロード リンクはこのメールに送信されます。",consent0:"私の指示に従って、モデル微調整用の合成データを生成することに同意します。",consent1:"最終モデルと合成データはHugging Faceで公開されることを了承します。",consent2:"この機能はベータ版であり、Jina AI はいかなる保証もしないことを理解しています。価格とユーザーエクスペリエンスは変更される場合があります。",continue:"続く",cost_1m_token:"各微調整ジョブは 100 万トークンを消費します。十分なトークンがあることを確認するか、チャージしてください。新しい API キーを生成することもできます。各 API キーには 1,000 万個の無料トークンが付属します。",doc_explain:"一致するドキュメントがどのように見えるべきかを説明します。",domain_explain:"微調整されたベクトル モデルの使用方法の詳細な説明。これは、ベクトル モデルのパフォーマンスを向上させる高品質の合成データを生成するために重要です。",domain_explain2:"要件を指定するには、一般的な説明、URL、またはクエリ ドキュメントの説明の 3 つの方法があります。一つ選んでください。",domain_hint:"微調整したいドメインを説明します。",email_not_match:"メールアドレスが一致しません。確認してください。",failed_job:"微調整リクエストが失敗しました。その理由を以下でご覧ください。",find_on_huggingface:"ハグフェイスに関する検索結果",general_instruction:"または、一般的な指示",general_instruction_caption:"トリム ベクトルの使用方法について詳しく説明します。",general_instruction_explain:"ドメイン名を自由形式のテキストで説明します。 ChatGPT の「プロンプト」のようなものと考えることができます。",how_it_works:"微調整プロセスを理解します。",job_acknowledged:"微調整ジョブはキューに入れられています。課題が開始されるとメールが届きます。通常、プロセス全体が完了するまでに 20 分かかります。",new_key:"新しいキーを取得する",not_enough_token:"この API キーには十分なトークンがありません。追加するか、別の API キーを使用してください。",placeholder:"自動車保険の請求",preview:"プレビュー",query_doc:"クエリ文書の説明",query_doc_caption:"クエリがどのようなものであるか、およびドメイン内で一致するドキュメントがどのようなものであるかを説明します。",query_explain:"クエリがどのようなものかを説明します。",reset:"また",select_base_model:"微調整する基底ベクトル モデルを選択します。",select_base_model_explain:"微調整の開始点としてベース モデルを選択します。一般に、base-en が適切な選択ですが、他の言語でのタスクの場合は、バイリンガル モデルの使用を検討してください。",start_tuning:"微調整を開始する",url:"または、Web ページの URL",url_caption:"微調整については、URL の内容を参照してください。",url_explain:"微調整するコンテンツを含むページのパブリック URL。",use_url:"代わりに URL を使用してください。このオプションを有効にすると、微調整のためにこの URL のページ コンテンツに基づいて合成データが生成されます。",wait_for_processing:"リクエストを処理するまでお待ちください...",which_domain:"ドメインの微調整",write_email_explain:"微調整には時間がかかります。微調整作業の開始、進行状況、完了、問題点、および微調整されたモデルとトレーニング データセットの詳細を電子メールでお知らせします。"},C={address_beijing:"中国、北京",address_berlin:"ドイツ、ベルリン（本社）",address_shenzhen:"深セン、中国",address_sunnyvale:"カリフォルニア州サニーベール",all_rights_reserved:"無断転載を禁じます",api_documentation:"APIドキュメント",company:"会社",developers:"開発者向け",docs:"書類",enterprise:"ビジネスのための",get_api_key:"Jina APIキーを取得する",offices:"オフィス",power_users:"上級ユーザー向け",privacy:"プライバシー",privacy_policy:"プライバシーポリシー",privacy_settings:"Cookieを管理する",security:"安全性",sefo:"検索ベース",soc2:"当社は、米国公認会計士協会 (AICPA) SOC 2 タイプ 1 およびタイプ 2 基準に準拠しています。",status:"APIステータス",status_short:"サービス状況",tc:"利用規約",tc1:"条項"},S="APIキーを取得する",j={stars:"出演者"},T={description:"ネットワークの知識を地上でのプレゼンテーションに適用する",title:"ファクトチェック",usage:"アースに使用します"},J={about_us:"私たちについて",api_docs:"APIドキュメント",api_docs_explain:"AIプログラミングアシスタントIDEまたは大規模モデル用のコードを自動生成",company:"会社",contact_us:"営業担当者に問い合わせる",developers_others:"その他の開発者ツール",enterprise_others:"もっと",for_developers:"開発者に力を与える",for_developers_description:"開発者向けに特別に構築されたマルチモーダルなオープンソース テクノロジー スタック。",for_enterprise:"ビジネスに力を与える",for_enterprise_description:"企業向けにカスタマイズされたマルチモーダル ソリューションを検討してください。",for_power_users:"パワーユーザーに権限を与える",for_power_users_description:"マルチモーダル ツールを使用して、日々の生産性を向上させます。",internship1:"インターンプログラム",jobs:"参加しませんか",join_discord:"Discord コミュニティに参加してください",logos:"ロゴをダウンロード",maximize:"⇧1",maximize_btn:"最大化する",news:"ニュース",open_day:"オープンデー",open_in_full:"すべてのエンタープライズ製品を新しいウィンドウで表示する",power_users_others:"より高度なユーザー ツール",products:"製品"},E={description:"マルチモーダル AI アプリケーションの構成要素を共有および発見する"},B={sentence_similarity:"文ベクトルモデル",updated_about:"について更新されました"},G={project1:"点群情報を利用し、3Dメッシュデータの高精度検索を実現します。",project10:"コンピューター ビジョンを使用して政府 Web サイトのデジタル アクセシビリティを向上させます。",project11:"コンサルティング会社の財務データ分析を最適化するために大規模な言語モデルを調整します。",project12:"スタイル転送用のテキストから画像へのモデルを調整することで、高度なマーケティング戦略を実装します。",project2:"短編アニメーション映画向けのコンテンツベースの検索エンジンを設計しました。",project3:"ベクトル モデルを調整することで、電子商取引のコンバージョン率を向上させます。",project4:"ビジネス コンサルティング会社の効率を向上させるためにタイムリーな調整を行います。",project5:"大手ゲーム会社向けの先駆的なゲームシーンの理解と自動アノテーション。",project6:"ユーザー エクスペリエンスを向上させるために、チャットボット会社向けにリアルタイム入力拡張機能を実装しました。",project7:"長い法的文書内での効率的な検索を可能にする。",project8:"大規模な運用をサポートする高スループットのジェネレーティブ アート サービス。",project9:"高級言語モデルを使用したプロセスマイニングとモデリング。"},U={description:"最先端のマルチモーダル推論モデル"},D="API キーに残っているトークンが不足しているため、リクエストは失敗しました。再チャージして続行してください。",O={copy_full_prompt:"プロンプトの単語全体をコピーします",embedding:"ベクトルモデル",how_to_use_meta_prompt:"使用方法",meta_prompt:"コード生成にメタヒント ワードを使用する",meta_prompt_description:"メタ ヒントにより、API の使用状況がすべて大規模モデル (ChatGPT や Claude など) に認識されるようになり、コード生成が容易になり、高品質になります。",reranker:"並べ替え者",which_to_go:"{_vendor} と統合できるのはどれですか?"},z={answer1:"学部、修士、博士 研究、エンジニアリング、マーケティング、販売などの分野に興味のある世界中の学生の応募を奨励します。また、マーケティング、販売、事務アシスタントなどの分野での非技術的なインターンシップの機会も歓迎します。私たちは、マルチモーダル AI を一緒に開拓する意欲のある情熱的な人材を探しています。",answer10:"はい、当社のインターンシップ プログラムは競争力のある給与を提供します。",answer11:"Jina AI インターンとして、挑戦的なプロジェクトに取り組む実践的な経験を積み、業界の専門家から学び、活気に満ちたコミュニティの一員となり、マルチモーダル AI における画期的な取り組みに真の貢献をする機会を得ることができます。",answer2:"インターンシップは、ベルリン、北京、深センにある当社のオフィスのいずれかで現地で行う必要があります。",answer3:"はい、Jina AI はビザの手続きにおいて合格した申請者に適切な支援を提供します。",answer4:"はい、Jina AI はインターンシップ中に妥当な生活費をインターン生に提供します。",answer5:"はい、Jina AI でのインターンシップ中に修士論文を完成させることができます。このインターンシップはドイツの大学の学生が一般的に利用できます。ただし、大学の指導教員に事前に連絡し、同意を得る必要があります。私たちは学生がアドバイザーを見つけるお手伝いはしませんのでご了承ください。",answer6:"応募プロセスには、応募フォーム、履歴書、興味や動機を表明するカバーレター、および GitHub や LinkedIn などの関連する専門リンクの提出が含まれます。私たちは候補者を面接での成績と大学での成績に基づいて評価します。",answer7:"はい、成功したインターンは、インターンシップ終了時に CEO が署名した推薦状を受け取ることができます。",answer8:"インターンシップの期間は、役割やプロジェクトによって異なります。ただし、通常は 3 ～ 6 か月かかります。",answer9:"はい、あらゆる学歴からのご応募を歓迎いたします。私たちは、これまでの経験と同様に、学習に対するあなたの情熱と取り組みを尊重します。",question1:"Jina AI インターンシップ プログラムには誰が応募できますか?",question10:"これは有給のインターンシップですか？",question11:"Jina AI インターンとしてどのような機会がありますか?",question2:"インターンシップはどこで行われますか?",question3:"Jina AI はビザ手続きをサポートしますか?",question4:"Jina AI はインターンに特典や福利厚生を提供していますか?",question5:"Jina AIでのインターンシップ中に修士論文を書くことはできますか?",question6:"申請プロセスには何が関係しますか?",question7:"Jina AI インターンシップ後に推薦状はありますか?",question8:"インターンシップの期間はどれくらいですか？",question9:"人工知能の経験がなくても応募できますか?"},N={about_internship_program:"インターンシッププログラムについて",about_internship_program_desc1:"私たちは、才能ある人材に当社のダイナミックなチームに参加し、人工知能分野の画期的なプロジェクトに貢献するこのユニークな機会を提供できることを嬉しく思います。このインターンシップは、貴重な実践的な経験、指導、人工知能の未来を形作る最先端のテクノロジーに触れることを目的に設計されています。",about_internship_program_desc2:"Jina AI では、若い才能を育成し、活用することの重要性を理解しています。私たちは、インターンが新しい視点、熱意、創造性をもたらし、新しいアイデアやアプローチで私たちのチームにインスピレーションを与えることを認識しています。インターンシップの機会を提供することで、私たちは AI 業界の将来のリーダーの成長を促進し、支援的でやりがいのある環境で実際の経験を提供することを目指しています。",alumni:"卒業生",alumni_network:"活発な同窓生ネットワーク",application:"応用",application_desc:"Jina AI とともに変革の旅に乗り出しましょう。当社の包括的なインターンシップ プログラムには、人工知能の未来を形作ることを熱望するすべての情熱的な従業員が招待されます。私たちに参加して、現実世界での経験を積み、挑戦的なプロジェクトに取り組み、AI 業界で最も優秀な人材と一緒に働きましょう。",apply:"今すぐお申し込みください",autumn:"秋",description:"世界中で学生を募集しています: 研究、エンジニアリング、マーケティング、セールスなどのインターンシップ。",dev_rel_intern:"開発者関係インターン",enthusiastic:"情熱的",explore_stories_from_our_interns:"インターン生のストーリーをご覧ください",explore_stories_from_our_interns1:"インターンたちの旅からインスピレーションを得てください",innovative:"革新的な",intern_work1:"大規模モデルを微調整して、より良い文章埋め込みを実現する",intern_work2:"検索拡張生成 (RAG) アルゴリズムの可能性を探る",intern_work3:"文ベクトルに関する論文を発表しました",intern_work4:"若いエネルギーをチームに着実に注入する",intern_work5:"大規模モデルを圧縮するためのベンチマーク量子化技術",intern_work6:"PromptPerfect の魅力的なキャンペーンを作成して宣伝する",intern_work7:"JinaColBERT V2 を迅速に開発および改善する",recruiting_and_administrative_intern:"採用および管理インターン",researcher_intern:"インターン研究員",self_motivated:"セルフモチベーション",software_engineer_intern:"ソフトウェアエンジニアインターン",spring:"春",submit_application:"Jina AI で冒険を始めましょう",subtitle:"当社のフルタイム インターンシップ プログラムでは、慎重に設計された幅広いインターンシップ プロジェクトを通じて実践的な就業体験を提供します。",subtitle1:"研究、エンジニアリング、マーケティング、営業などの分野のインターンを世界中から募集し、マルチモーダル AI を共同で作成します。",summer:"夏",title:"インターンプログラム",who_do_we_look_for:"私たちが探しているのは誰ですか?",who_do_we_look_for_desc:"私たちは多様性を重視しており、あらゆる背景や経歴の応募者がインターンシップ プログラムに参加することを奨励しています。インターンシップの機会は、エンジニアリング、設計、製品管理、販売およびアカウント管理、マーケティング、コミュニティ管理など、複数の部門にわたって利用できます。",winter:"冬"},W={description:"ローカル プロジェクトをクラウド サービスとしてデプロイします。非常にシンプルで、不快な驚きはありません。"},H={description:"大規模モデル向けのオープンソース実験チューナー"},F={description:"クラウドでマルチモーダル AI アプリケーションを構築する"},K={description:"より多くのモード、より長いメモリ、より低いコスト",example_1:"あなたは誰ですか？",example_2:"私はJina AIが作った大規模なモデルチャットサービスです"},Q={add:"キーを追加",add_key_explain:"アカウントに別の API キーを追加します。追加されたキーはいつでも管理、再充電、または削除できます。",add_key_labels_explain:"複数のキーを効率的に管理できるように、キーにラベルを追加します。",add_key_labels_input_explain:"複数のタグが許可されます。 「Enter」キーを使用して新しいタグを追加します。",add_shared_key:"私のキーに追加",add_success:"キー {_key} が正常に追加されました。",advance_settings:"詳細設定を開く",advanced_feature:"高度な機能はプレミアム キーでのみ利用できます。",auto_recharge_enable_success:"キー {_key} の自動再チャージが正常に有効になりました。",auto_recharge_title:"自動補充を有効にしますか?",auto_reminder:"残高不足通知",auto_reminder_cancel_message:"このキーの自動リマインダーをキャンセルしてもよろしいですか?",auto_reminder_cancel_title:"自動リマインダーをキャンセルする",auto_reminder_description:"トークン残高が設定されたしきい値を下回ると、自動電子メール アラートが届きます。最大 3 つのしきい値を設定できます。",auto_reminder_email:"リマインダーメールアドレス",auto_reminder_info:"トークン残高が {_threshold} を下回ると、メールによるリマインダーが {_email} に送信されます。",auto_reminder_threshold:"アラートしきい値",auto_reminder_threshold_error:"しきい値は 1 ～ 1T の間である必要があります。",auto_reminder_toggle:"自動リマインダーのオンとオフを切り替えます。この機能は詳細キーのみが有効になることに注意してください。",available_resources:"利用可能なトークン",balance:"利用可能なトークン",balance_primary_key:"マスターキーバランス",cancel:"キャンセル",confirm:"確認する",copy:"キーをコピーする",copy_share_link:"リンクをコピー",customized_tags:"キーにラベルを付ける",day_requests:"リクエスト数/日",day_tokens:"単語数/日",description:"すべての Jina AI サービス (埋め込み、リーダー、リランカーなど) の API キーを管理します。",do_it_later:"後でやってください",email:"電子メール",existing_key:"既存のキー",filter:"属性でフィルタリング",filter_by:"キーによるフィルター",free_key:"フリーキー",generate_new_key:"新しいキーを生成する",generate_new_key_tooltip:"残高が空の新しい API キーを生成します。後で補充することもできます。",generate_success:"新しいキー {_key} が正常に生成されました。",get_free_key:"APIキーの作成",hour_requests:"リクエスト数/時間",hour_tokens:"単語数/時間",ignore:"無視する",invalid_email:"電子メールが無効です",invalid_key:"無効なキー",is_primary:"あなたのマスターキー。ログイン後に変更できます。",key_labels:"ラベル",labels_updated:"ラベルが正常に更新されました。",last_used:"最後に使用した",last_used_at:"最後のアクティビティ",left_requests:"残りリクエスト数: {_num} 件",left_tokens:"残りトークン数: {_num}",login:"ログイン",login_explain:"複数の API キーの管理と使用状況の追跡をすべて 1 つのアカウントで行います。",login_explain_long:"サインインして API キーを安全に保存および管理します。使用履歴を追跡し、複数のキーを管理し、資格情報へのアクセスを失うことはありません。",login_required:"まずログインしてから共有キーを追加してください。",login_via:"{_provider}経由でログイン",logout:"サインアウト",logout_message:"API キーはアカウントに安全に保存されます。いつでもログインして管理できます。",logout_success:"正常にログアウトされました",no_key_title:"API キーは必要ですか?",no_key_with_login:"API キーをまだ作成していません。今すぐ生成し、無料のトークンを取得して始めましょう。",no_key_without_login:"すでにアカウントをお持ちですか?サインインして API キーにアクセスするか、{_button} をクリックして新しい API キーを作成します。",no_recent_usage:"過去24時間以内に使用されていません",no_transferable_keys:"他に転送できるキーはありません。まず新しいキーを追加してください。",normal_key:"共通キー",ok:"わかりました",primary_key:"主キーとして設定",primary_key_set:"{_apiKey} をマスターキーとして正常に設定しました。",primary_key_set_caption:"このキーは、jina.ai のすべてのデモ、サンプル、サンドボックス ラボに使用されます。",purchase:"単語要素を購入する",readonly:"このキーへのアクセスを読み取り専用に制限してください。",readonly_explain:"このキーへのアクセスを読み取り専用に制限します。この動作により、このキーを補充したり、共有したり、主キーとして選択したりする機能が無効になります。",readonly_key:"読み取り専用キー",readonly_label:"読み取り専用アクセス",recharge_threshold_confirm_message:"自動リチャージのしきい値を {_threshold} トークンに変更してもよろしいですか?",recharge_threshold_confirm_title:"自動リチャージのしきい値を変更する",remove:"キーを削除します",remove_explain:"リストからキーを削除しても、そのキーに依存するソフトウェアやサービス、またはキーを保存している他のユーザーには影響しません。キーはまだ有効であり、いつでも再追加できます。",remove_message:"キーを削除してもよろしいですか?このキーはまだ有効であり、いつでも再追加できます。",remove_primary_key:"現在のマスター キーを削除する前に、別のキーをマスター キーとして設定します。",remove_success:"キー {_key} が正常に削除されました。",remove_title:"キーを削除します",requests:"聞く",requests_depleted:"残高がマイナスです。チャージが必要です!",revert_changes:"変更を元に戻す",revoke:"キーを破壊する",revoke_error:"入力したキーは、破棄しようとしているキーと一致しません。",revoke_explain:"キーを破棄すると、そのキーを保存したすべてのユーザーに対してそのキーが即時かつ永久に無効になり、そのキーに残っているすべてのトークン残高と関連資産は永久に利用できなくなります。この操作は元に戻すことができません。",revoke_label:"破棄を確認するには、このキーを下に入力してください",revoke_message:"このキーを破棄してもよろしいですか?このキーは一度破棄されると、それを保存したすべてのユーザーに対して永久に無効になります。このキーの残りのすべてのトークン残高と関連資産は永久に利用できなくなります。この操作は元に戻すことができません。",revoke_success:"キー {_key} は正常に破棄されました。",revoke_title:"キーを破壊する",save:"保存",save_as:"名前を付けて保存",settings:"設定",share:"共有キー",share_key_confirm_message:`受信者は、このキーの残高を表示、管理、補充することができます。同じ権限を保持します。
このリンクは 24 時間後に期限切れになることに注意してください。`,share_key_confirm_title:"APIキーを共有する",share_key_expired_at:"共有リンクは {_time} に期限切れになります。",share_key_expired_message:"キーの共有リンクの有効期限が切れています。キーの所有者に再度共有するよう依頼してください。",share_key_expired_title:"共有リンクの有効期限が切れました",share_key_message:"{_user} が API キーをあなたと共有しました。鍵とその残高を管理するために追加します。",share_link_copied:"共有リンクがコピーされました",share_token_keys:"これらのトークンは、{_num} 個の他のキーによって共有されます",shared_from:"{_user} が共有したキー",shared_key:"共有キー",subscribed_key:"アドバンストキー",tickets:{actions:"アクション",button:"注文",client_name:"顧客名",currency_cny_format:"¥{value}",currency_eur_format:"€{value}",currency_usd_format:"${value}",explain:"注文書と請求書の表示と管理",export_csv:"CSVエクスポート",invoice_status:"請求書のステータス",invoice_status_failed:"失敗した",invoice_status_issued:"リリース",invoice_status_pending:"リクエストされていません",invoice_status_processing:"処理",notes:"メモ",open_time:"作成時間",order_id:"注文番号",payment_status:"支払い状況",payment_status_failed:"失敗した",payment_status_paid:"有料",payment_status_pending:"まだ支払われていない",payment_time:"支払い時期",pricing_strategy:"価格設定基準",product_name:"製品を購入する",purchase_time:"購入時間",quantity:"購入数量",request_invoice:"請求書をリクエストする",title:"購入注文履歴",total_amount:"一時金",unit_price:"単価",view_details:"詳細を確認する"},title:"ジナ検索ベースAPI",to_dashboard:"キーを管理する",token_expired:"おっと！リクエストに問題が発生しました。もう一度お試しください。ログアウトして再度ログインしてください。",token_expiry_detail:"現在の使用率 {_rate} では、トークンは {_date} に使い果たされます。",token_expiry_estimate:"期待される。使い果たされました: {_date} ({_days}d {_hours}h)",token_expiry_no_rate:"トークン消費量を推定するための最近の使用データがありません",tokens:"トークン",tokens_depleted:"残高がマイナスです。チャージが必要です!",tokens_per_hour:"トークン/時間",top_up:"補充する",total_keys:"キーの数",transfer_before_revoke:"キーを破棄する前に、支払い済みのトークンの残りの残高を転送してください。",transfer_explain:"管理リソースの柔軟性とセキュリティを強化するために、残りの有料トークン残高全体を別のキーに転送します。",transfer_label:"に転送する",transfer_message:"{_tokens} の残りの有料トークン残高全体を {_source} から {_target} に転送してもよろしいですか?",transfer_success:"プレミアム トークンの残高を {_source} から {_target} に正常に転送しました。",transfer_title:"トークンを転送する",update_key_failed:"キー情報を更新できませんでした。しばらくしてからもう一度お試しください。",update_label:"タグの更新",usage:"使用法",usage_history:"利用履歴",usage_summary:"過去 7 日間: {_usage} トークン",view_tickets:"発注書と請求書を表示する"},V={GlobalQA:{description:"任意のページで「/」キーを押して質問を開きます。クエリを入力して「Enter」を押すと、ページのコンテンツに関連する回答が表示されます。この機能は PromptPerfect によって強化されています。",title:"ページラグ"},Recommender:{description:"ニュース ページでおすすめボックスを開くには、「Shift+2」を使用します。このニュース ページに関連する上位 5 つの記事を見つけるには、再ランク付けモデルを選択します。この機能は、Reranker API によってリアルタイムで利用されます。",title:"関連記事"},SceneXplainTooltip:{description:"ニュース ページまたはニュースルームのディレクトリにある画像の上にマウスを置くと、その画像の説明が表示されます。説明は SceneXplain によって事前に計算され、画像の ALT 属性でベクトル化されます。",title:"画像注釈"},explain:"私たちのウェブサイトの隠れた機能を探索してください"},X={also_available_on:"App Marketでも入手可能",also_available_on1:"アプリケーション マーケットを通じてワンクリックでエンタープライズ クラウドに導入できます。",ask_how_your_question:"問題について説明してください",autotune:"セルフチューニング",avatar:"アバタージェネレーター",badge:{"clip-v2":"クリップv2がリリースされました！",m0:"m0 リリースしました！","readerlm-v2":"ReaderLM-v2がリリースされました！",v2:"第二弾が発売されました！",v3:"v3がリリースされました！",v4:"v4 リリース！"},browser_info_title:"ブラウザ情報",build_js:"JavaScriptを使用して開発",build_python:"Pythonを使用して開発",ccbync:"このモデルは CC BY-NC 4.0 に基づいてライセンスされています。 API または公式 AWS/Azure イメージを介して使用するか、オンプレミス展開については営業にお問い合わせください。",checkout_our_solution_for_you:"お客様に合わせた当社のソリューションについてご覧ください",classifier:"分類子",coming_soon:"乞うご期待",contact_sales:"お問い合わせ",copied_to_clipboard:"クリップボードにコピーされました",copy:"コピー",developers:"開発者",developers_desc:"最先端のクラウドネイティブ テクノロジーとオープンソース インフラストラクチャを使用して、マルチモーダル AI の能力を最大限に引き出します。",download_pdf:"PDFをダウンロード",embedding:"埋め込む",embedding_desc1:"検索、RAG、エージェント アプリケーション向けの最先端のマルチモーダルな多言語ロング コンテキスト ベクトル モデル。",embedding_paper_desc:"Jina Embeddings は、さまざまなテキスト入力を数値表現に変換することに優れた高性能テキスト ベクトル モデルのセットを構成し、それによってテキストの意味論的な本質を捉えます。これらのモデルはテキスト生成用に特別に設計されたものではありませんが、高密度検索や意味論的なテキストの類似性などのアプリケーションで良好に機能します。この記事では、高品質のペアごとおよびトリプレット データセットの作成から始まる、Jina Embeddings の開発について詳しく説明します。データセットの準備におけるデータ クリーニングの重要な役割を強調し、モデル トレーニング プロセスについての洞察を提供し、大規模テキスト ベクトル ベンチマーク (MTEB) を使用して包括的なパフォーマンス評価を実施します。",embedding_paper_title:"Jina Embeddings: 高性能テキスト ベクトル モデルの新しいセット",embeddings:"ベクトルモデル",enterprise:"企業",enterprise_desc:"スケーラブルで安全、カスタマイズ可能なマルチモーダル AI ソリューションでビジネスを強化します。",enterprise_desc_v2:"世界クラスのベクトル モデルを使用して、検索システムと RAG システムを改善します。まずは無料トライアルから始めましょう！",enterprise_desc_v3:"当社の最先端のモデルは、高品質のエンタープライズ検索および RAG システムの検索基盤を形成します。",error:"問題が発生しました: {message}",find_your_portal:"独自のポータルを探索する",finding_faq:"次の FAQ の知識に基づいて回答を生成します。",for:"のために",for_better_search:"より良い検索のために",for_developers:"開発者向け",for_enterprise:"ビジネスのための",for_power_users:"上級ユーザー向け",get_api_now:"API",get_started:"使い始める",go_to_product_homepage:"製品ホームページへ",grounding:"地面",how_to:"どうやって",include_experiment:"ソリューション内の実験プロジェクトとアーカイブされたプロジェクトについて言及します。",join_community:"コミュニティ",key_manager:"APIキーを管理する",learn_more_embeddings:"ベクトルモデルについて学ぶ",learn_more_reader:"読者について詳しく見る",learn_more_reranker:"再注文者について学ぶ",llm:"大規模モデル ベクトルモデル",llm_desc:"当社は、3,500 万から 60 億のパラメータを備えた高性能テキスト ベクトル モデル ファミリを提供します。これらは、ニューラル検索、並べ替え、文の類似性、推奨事項などを強化するのに最適です。 AI エクスペリエンスを向上させる準備をしましょう。",mentioned_products:"言及された製品:",mmstack:"マルチモーダル技術スタック",mmstack_desc:"私たちは長年にわたり、開発者がより優れた GenAI と検索アプリケーションをより迅速に構築できるようにするオープン ソース ソフトウェアを開発してきました。",models:"モデル",more:"もっと",multimodal:"マルチモーダル",multimodal_ai:"マルチモーダル AI",new:"新しい",newsroom:"ニュース",num_publications:"合計 {_total} 件の出版物。","on-prem-deploy":"プライベート展開","on-premises":"地元",opensource:"オープンソース",our_customer:"私たちの顧客",our_customer_explain:"あらゆる規模の企業が、自社のツールや製品を強化するために Jina AI の検索基盤を信頼しています。あなたにもそうすることができます。",our_publications:"私たちの論文",parameters:"パラメータ",podcast:"ポッドキャスト",power_users:"VIP",power_users_desc:"自動ワードプロンプトプロジェクトにより、日々の作業効率が向上します。",powered_by_promptperfect:"PromptPerfect のプロンプトワード最適化および Prompts-as-a-Service 機能を活用",pricing:"価格表",proposing_solution:"Jina AI 製品ラインに基づいて考案されたソリューション...",read_more:"もっとニュース",reader:"読者",refresh_page:"リフレッシュ",require_full_question:"問題をさらに詳しく説明してください。",reranker:"並べ替え者",researcher_desc:"最先端の検索モデルがゼロからトレーニングされる方法を学び、最新の出版物をチェックしてください。 EMNLP、SIGIR、ICLR、NeurIPS、ICML のチームをご紹介します。",researchers:"研究者",sdk:"ソフトウェア開発キット",sdk_desc:"PromptPerfect、SceneXplain、BestBanner、JinaChat、Rationale API を使用して高度な AIGC アプリケーションを構築したいですか?私たちはあなたのお手伝いをいたします！使いやすい SDK を試して、数分で使い始めてください。",sdk_docs:"文書を読む",sdk_example:"例",search_foundation:"検索ベース",source_code:"ソースコード",starter_kit:"新規パッケージ",supercharged1:"ぐんぐん加速！",tokenizer:"スライサー",trusted_by:"私たちは信頼できる",try_it_for_free:"今すぐ始めましょう - クレジット カードや登録は必要ありません。",try_our_saas:"OpenAI API を 1:1 で置き換える、マネージドのクラウドネイティブ推論ソリューションをお試しください。",version_notify:"中国本土のウェブサイトを閲覧中です。一部のインタラクティブなデモンストレーション機能は、正しく表示されないか機能しない場合があります。完全な機能が必要で、ネットワーク環境が許す場合は、国際サイト {_link} をご覧ください。",view_browser_info:"ブラウザ情報を表示",your_portal_to:"ご招待します",your_search_foundation1:"あなたの検索基盤"},Y={description:"Jina と FastAPI を使用して実稼働グレードの Langchain アプリケーションを作成する"},$={description:"Jina AI の製品とサービスに関する法的情報、利用規約、プライバシー ポリシー、その他の重要な文書。",download_type1:"SOC 2 タイプ I 証明書のダウンロード",download_type2:"SOC 2 タイプ II 証明書のダウンロード",request_audit:"監査レポートを要求する",title:"法的情報"},Z={api:"LLM を SERP API として使用する",description:"検索結果ページとしての大規模言語モデル",faq_v1:{answer1:"SERP は Search Engine Results Page の略で、ユーザーのクエリに応じて検索エンジンが表示するページです。結果のリストと、通常は URL、概要、ドメイン名などのその他の情報が含まれます。",answer2:"はい、LLM-as-SERP は大規模な言語モデルを使用して検索結果を生成します。",answer3:"幻覚が起こる。",answer4:"それらはモデルのトレーニング データ内に存在する可能性があります。",answer5:"はい、LLM-as-SERP API を使用して検索結果を生成できます。下のボタンをクリックしてください。",answer6:"ディープサーチの検索基盤を実験しながら開発しました。ボタンをクリックしてブログ投稿をお読みください。",answer7:"はい、コードはオープンソースであり、GitHub で入手できます。",question1:"SERP とは何ですか?",question2:"では、すべての検索結果は LLM によって生成されるのでしょうか?",question3:"検索結果の一部の URL が壊れていて 404 ページが表示されるのはなぜですか?",question4:"では、なぜ一部の URL は本物であり、実際のページにつながるのでしょうか?",question5:"API 経由で呼び出すことはできますか?",question6:"しかし、検索結果がすべて偽物であれば、このデモや API の意味は何でしょうか?",question7:"オープンソースですか?",title:"LLM を SERP として使用する場合の FAQ"},okay_but_why:"遊ぶのは楽しいですが、何の意味があるのでしょうか?",parameters:{auth_token:"@:トークナイザー.パラメータ.認証トークン",auth_token_explain:"LLM は SERP API として無料で使用できます。 API キーを提供することで、より高いレート制限にアクセスできるようになり、キーに対して料金が請求されなくなります。",country:"希望する国",country_explain:"検索する国。これは 2 文字の国コードです。",language:"優先言語",language_explain:"検索する言語。これは 2 文字の言語コードです。",location:"希望する場所",location_explain:"検索クエリの発生元となる場所。実際のユーザーの検索をシミュレートするには、都市レベルで場所を指定することをお勧めします。",number:"結果件数",number_explain:"返される結果の最大数。 num を使用すると、遅延が発生したり、特殊な結果タイプが含まれなくなる可能性があります。結果には、num で指定された数の結果が含まれることは保証されません。",page:"ページネーション",page_explain:"結果のオフセット。指定された数の結果をスキップします。ページングに使用されます。",query:"聞く",query_explain:"検索したいクエリ。通常の検索で使用するものなら何でも使用できます。たとえば、inurl:、site:、intitle: などです。"},query_label:"お問い合わせ",title:"LLM を SERP として"},ee={api:"ジナAI API",browse_catalog:"カタログを閲覧する",contact_sales_about_it:"詳細については営業担当者にお問い合わせください",deploy_it_on:"デプロイ先",description:"私たちは設立当初から検索モデルを推進してきました。以下のモデルの進化をご覧ください。カーソルを置くかクリックして各マイルストーンを確認してください。",find_on_hf:"HuggingFace で見つけてください",search_for:"私たちのサイトを検索",search_models:"モデル名でフィルタリングする",title:"検索ベースモデル",use_it_via:"を使用することで"},ne={back_to_models:"リターンモデル",comparison:{btn:"比較する",select_models:"比較するモデルを選択してください"},error:"モデルのロードに失敗しました",input_type:{"3d":"3D",audio:"ボーカル",code:"コード",document:"書類",graph:"グラフィックス",image:"写真","image (document)":"画像（文書）","image (query)":"画像（クエリ）","multi-vector":"マルチベクトル",other:"他の",pdf:"PDF",ranking:"ランキング",tabular:"シート",text:"文章","text (code)":"テキスト（コード）","text (document)":"テキスト（文書）","text (html)":"テキスト(HTML)","text (json)":"テキスト(JSON)","text (markdown)":"テキスト (マークダウン)","text (query)":"テキスト（クエリ）",timeseries:"時系列",vector:"ベクター",video:"ビデオ"},loading:"モデルの詳細を読み込み中...",metadata:{api_link:"API",arxiv:"ArXiv 論文",aws_link:"アマゾンクラウド",azure_link:"マイクロソフトクラウド",deprecated_by:"廃止されました",gcp_link:"グーグルクラウド",huggingface_link:"顔を抱きしめる",input_type:"入力",license:"ライセンス",license_link:"商用ライセンス",output_type:"出力","reader-api_link":"ジナAPI",related_models:"関連機種",release_blog:"リリースノート",release_date:"発売日"},search:{no_results:"「{query}」に一致するモデルが見つかりませんでした",placeholder:"名前、タグ、タイプで検索..."},sections:{availability:"可用性",blogs:"このモデルについて言及しているブログ",external_links:"外部リンクとリソース",guidance:{"ReaderLM-v2":"このモデルには、HTML から Markdown への変換、JSON 抽出、および命令のフォローを示す Google Colab ノートブック経由でアクセスできます。 HTML からマークダウンへのタスクの場合、ユーザーはプレフィックス ディレクティブなしで生の HTML を入力できますが、JSON 抽出には特定のスキーマ形式が必要です。 create_prompt ヘルパー関数を使用すると、両方のタスクのプロンプトを簡単に作成できます。モデルは Colab の無料 T4 GPU 層 (vllm および triton が必要) で実行できますが、bfloat16 またはフラッシュ アテンション 2 がサポートされていないため制限があります。本番環境での使用には RTX 3090/4090 が推奨されます。このモデルは、AWS SageMaker、Azure、および GCP マーケットプレイスで入手可能になり、CC BY-NC 4.0 ライセンスに基づいて非営利使用がライセンスされます。","jina-clip-v1":"Jina CLIP v1 を効果的に導入するには、チームはその機能とリソース要件の両方を考慮する必要があります。このモデルは 224 x 224 ピクセルのタイルで画像を処理し、各タイルは 1,000 トークンの処理能力を消費します。最高のパフォーマンスを得るには、これらの寸法に合わせて効果的な画像前処理を実装します。このモデルは短いテキストと長いテキストの両方の処理で優れたパフォーマンスを発揮しますが、現在は英語の入力のみをサポートしています。チームはトークンの使用を慎重に検討する必要があります。テキストは 1 単語あたり約 1.1 トークンを必要としますが、画像はタイルで処理されます (たとえば、750 x 500 ピクセルの画像には 12 個のタイルが必要で、12,000 トークンを消費します)。このモデルは、Jina Embeddings API 経由で、また Apache 2.0 ライセンスの下で Hugging Face のオープンソースとして利用可能であり、柔軟な展開オプションを提供します。実稼働環境では、最適化されたインフラストラクチャ設定を提供する AWS Marketplace または Azure デプロイメント オプションの使用を検討してください。","jina-clip-v2":"最適な展開のために、ユーザーはいくつかの重要な要素を考慮する必要があります。このモデルでは、効率的な処理のために CUDA 対応のハードウェアが必要であり、メモリ要件はバッチ サイズと画像解像度に応じて変化します。 API のコストとパフォーマンスを最適化するには、処理前に画像を 512 x 512 ピクセルにサイズ変更します。大きい画像は自動的にタイル化されるため、トークンの使用量と処理時間が増加します。このモデルは、言語間で画像と説明文を一致させることに優れていますが、抽象的な概念や高度に専門化されたドメイン固有のコンテンツの処理が難しい場合があります。これは、電子商取引の製品検索、コンテンツ推奨システム、およびビジュアル検索アプリケーションには特に効果的ですが、きめ細かい視覚的詳細の分析や高度に専門化されたドメインの専門知識を必要とするタスクには適さない可能性があります。 Matryoshka を使用して特徴を表現する場合は、次元削減とパフォーマンスのトレードオフを考慮してください。64 次元のベクトルは強力なパフォーマンスを維持しますが、重要なアプリケーションではより高い次元のメリットが得られる可能性があります。","jina-colbert-v1-en":"Jina-ColBERT-v1-en を効果的に展開するには、チームはいくつかの実用的な側面を考慮する必要があります。このモデルでは、最適なパフォーマンスを得るために CUDA 対応 GPU が必要ですが、開発中に CPU 推論が利用可能です。文書処理の場合、8,192 トークンの制限は約 6,000 ワードに相当し、学術論文、技術文書、長文コンテンツなど、ほとんどの種類の文書に適しています。チームは、トークン制限に対処するために効果的なドキュメント前処理を実装し、大規模なインデックス作成のためのバッチ処理を検討する必要があります。このモデルは英語コンテンツの処理には優れていますが、多言語アプリケーションや言語をまたいだ検索向けには設計されていません。運用環境の場合は、適切なドキュメントのチャンク化戦略を実装し、効率的な検索のために FAISS などのベクトル類似性インデックスの使用を検討してください。このモデルは、RAGatouille などのフレームワークを使用して RAG パイプラインに統合すると特に効果的であり、複雑な取得パターンの実装が簡素化されます。","jina-colbert-v2":"Jina-ColBERT-v2 を効果的に導入するには、チームはいくつかの実用的な側面を考慮する必要があります。このモデルは、最適なパフォーマンスを得るために CUDA 対応ハードウェアを必要とし、クエリを 32 トークンに制限しながら、最大 8,192 トークン (12,288 まで拡張可能) のドキュメント長をサポートします。実稼働環境の場合、モデルは Jina Search Foundation API、AWS Marketplace、Azure を通じて入手でき、非商用バージョンは Hugging Face を通じて入手できます。モデルでは非対称エンコーディングが使用されているため、実装する際、チームはベクトル クエリであるかドキュメントであるかを指定する必要があります。このモデルは、適切なインデックスを作成せずに、非常に大規模なドキュメントのコレクションをリアルタイムで処理するように設計されていないため、多言語検索では良好なパフォーマンスを発揮しますが、特殊なドメインでは、これらの特定のドメイン タスクのパフォーマンスが微調整されたモデルと比較してパフォーマンスが低下する可能性があります。わずかに低くなります。","jina-embedding-b-en-v1":"最適な展開のためには、モデルには CUDA 対応 GPU が必要ですが、その適度なサイズにより標準ハードウェアで効率的な推論が可能になります。このモデルは最大 512 トークンの長さの入力シーケンスを受け入れるため、一貫性のある信頼性の高いベクトル生成が重要な運用環境に最適です。英語コンテンツで最高のパフォーマンスを発揮し、意味検索、文書類似性比較、コンテンツ推奨システムなどのアプリケーションに最適です。チームは、より優れたパフォーマンスとより広範な言語サポートを提供するため、新しいプロジェクトには新しい v2 または v3 バージョンの使用を検討する必要があります。このモデルは、多言語の理解や一般的な英語のテキストを超えた専門分野の知識を必要とするタスクにはお勧めできません。","jina-embeddings-v2-base-code":"Jina Embeddings v2 コード ベースを効果的に展開するには、チームはいくつかの実用的な側面を考慮する必要があります。このモデルは、MongoDB、Qdrant、Weaviate などの一般的なベクトル データベースとシームレスに統合されており、スケーラブルなコード検索システムを簡単に構築できます。最高のパフォーマンスを得るには、8,192 トークンの制限を処理する適切なコード前処理を実装します。通常、これはほとんどの関数およびクラス定義に対応します。このモデルは 30 のプログラミング言語をサポートしていますが、Python、JavaScript、Java、PHP、Go、Ruby の 6 つのコア言語で最も強力なパフォーマンスを示します。チームは、パフォーマンスを最適化するために、大規模なコードのインデックス作成にバッチ処理の使用を検討する必要があります。モデルの RAG 互換性により、自動ドキュメント生成やコード理解タスクに特に効果的ですが、チームは非常に大規模なコード ベースに対して適切なチャンク戦略を実装する必要があります。本番環境のデプロイでは、マネージド推論に AWS SageMaker エンドポイントの使用を検討し、適切なキャッシュ戦略を実装してクエリのパフォーマンスを最適化します。","jina-embeddings-v2-base-de":"Jina Embeddings v2 Base German を効果的に展開するには、組織はいくつかの実用的な側面を考慮する必要があります。このモデルは、MongoDB、Qdrant、Weaviate などの一般的なベクトル データベースとシームレスに統合されており、スケーラブルなバイリンガル検索システムを簡単に構築できます。最高のパフォーマンスを得るには、適切なテキスト前処理を実装して、8,192 トークンの制限を効率的に処理します。これは通常、約 15 ～ 20 ページのテキストに対応します。このモデルはドイツ語と英語の両方のコンテンツで良好にパフォーマンスしますが、クエリ言語とドキュメント言語が異なる可能性がある言語間検索タスクに使用すると特に効果的です。組織は、頻繁にアクセスされるコンテンツに対してキャッシュ ポリシーを実装し、大規模なドキュメントのインデックス作成にバッチ処理を使用することを検討する必要があります。このモデルの AWS SageMaker 統合は、本番環境へのデプロイメントへの信頼できるパスを提供しますが、チームはトークンの使用状況を監視し、高トラフィックのアプリケーションに適切なレート制限を実装する必要があります。 RAG アプリケーションにこのモデルを使用する場合は、入力言語に基づいてプロンプトの構築を最適化する言語検出の実装を検討してください。","jina-embeddings-v2-base-en":"Jina Embeddings v2 Base English を効果的に展開するには、チームはいくつかの実用的な側面を考慮する必要があります。このモデルでは、最適なパフォーマンスを得るために CUDA 対応のハードウェアが必要ですが、効率的なアーキテクチャにより、コンシューマー グレードの GPU でも実行できます。これは、Hugging Face からの直接ダウンロード、AWS Marketplace からのデプロイメント、または 1,000 万の無料トークンを使用した Jina AI API など、複数のチャネルを通じて入手できます。本番環境への導入では、us-east-1 リージョンの AWS SageMaker が最もスケーラブルなソリューションを提供します。このモデルは一般的なテキスト分析には優れていますが、微調整を行わないと、高度に専門化された科学用語やドメイン固有の用語には最適な選択肢ではない可能性があります。長いドキュメントを処理するときは、コンテキストをそのまま維持するためにドキュメントを恣意的に分割するのではなく、意味のある意味のチャンクに分割することを検討してください。最良の結果を得るには、適切なテキスト前処理を実装し、入力データがクリーンで適切にフォーマットされていることを確認してください。","jina-embeddings-v2-base-es":"このモデルを効果的に活用するには、組織は最適なパフォーマンスを得るために CUDA 対応の GPU インフラストラクチャにアクセスできるようにする必要があります。このモデルは、MongoDB、Qdrant、Weaviate、Haystack などの主要なベクトル データベースや RAG フレームワークとシームレスに統合されているため、運用環境への導入が簡単になります。バイリンガル文書検索、コンテンツ推奨システム、言語横断文書分析などのアプリケーションに優れています。このモデルはパフォーマンスは良好ですが、スペイン語と英語のバイリンガル シナリオに特化して最適化されているため、単言語アプリケーションや他の言語ペアが関与するシナリオには最適な選択ではない可能性があります。最良の結果を得るには、入力テキストはスペイン語または英語で適切にフォーマットされている必要がありますが、モデルは混合言語コンテンツを効果的に処理できます。このモデルはドメイン固有のアプリケーションの微調整をサポートしていますが、トレーニング データの品質と配布については慎重に考慮する必要があります。","jina-embeddings-v2-base-zh":"このモデルには 322 MB のストレージが必要で、AWS SageMaker (us-east-1 リージョン) や Jina AI API などの複数のチャネルを通じてデプロイできます。 GPU アクセラレーションは必須ではありませんが、実稼働ワークロードを大幅に高速化できます。このモデルは、文書分析、多言語検索、言語をまたいだ情報検索などのさまざまなアプリケーションで適切に機能しますが、ユーザーは特に中国語と英語のバイリンガル シナリオ向けに最適化されていることに注意する必要があります。最良の結果を得るには、入力テキストを適切にセグメント化する必要があります。モデルは最大 8,192 個のトークンを処理できますが、パフォーマンスを向上させるために、非常に長いドキュメントを意味的に意味のあるチャンクに分割することをお勧めします。このモデルは、非常に短いテキストのリアルタイム処理を必要とするタスクには適していない可能性があり、低遅延の専用モデルの方が適している可能性があります。","jina-embeddings-v3":"Jina Embeddings v3 を効果的に導入するには、チームは特定のユースケースを考慮して適切なタスクアダプタを選択する必要があります。検索アプリケーションでは retrieval.query と retrieval.passage を、クラスタリングタスクでは Separation を、分類では classification を、セマンティック類似性では textmatching を使用します。このモデルでは、最高のパフォーマンスを得るために CUDA 対応ハードウェアが必要ですが、効率的なアーキテクチャのため、大規模な代替手段に比べて GPU メモリの必要量が大幅に少なくて済みます。本番環境での導入では、AWS SageMaker との統合により、スケーラビリティへのシンプルなパスが提供されます。このモデルは多言語アプリケーションで良好なパフォーマンスを発揮しますが、リソースの少ない言語では追加の評価が必要になる場合があります。最大 8,192 トークンの長いドキュメントをサポートしていますが、非常に長いテキストには遅延セグメンテーション機能を使用すると最高のパフォーマンスが得られます。このモデルはベクトル化と検索用に設計されており、テキスト生成や直接的な質問への回答には使用しないでください。","jina-embeddings-v4":"Jina Embeddings V4 を効果的に使用するには、アプリケーションのニーズに合わせて適切な LoRA アダプタを選択してください。クエリとドキュメントの構造が異なる非対称クエリドキュメント検索シナリオでは、「Retrieve」アダプタを使用し、クエリと段落の内容を区別するために適切なプレフィックスを使用してください。「Text Matching」アダプタは、クエリへの回答ではなく類似コンテンツの検索を目的とするセマンティック類似性タスクと対称検索に適しており、ドキュメントクラスタリング、重複検出、コンテンツ推奨システムに最適です。プログラミング関連のアプリケーションでは、「Code」アダプタが自然言語からコードへの検索、コード間の類似性検索、技術的な質疑応答シナリオに最適化されています。パフォーマンスと効率性の要件に基づいて出力モードを選択してください。シングルベクトルは効率的な類似性検索を提供し、ストレージ容量が限られた環境に適しており、切り捨て次元により、許容可能な品質のトレードオフで次元を 2048 から 128-512 に削減できます。一方、マルチベクトルは複雑な検索タスク、特にリッチなビジュアルコンテンツを含む文書を扱う際に高い精度を提供します。後者では、インタラクションスコアリングによって詳細な関係性を捉えることができます。このモデルの統合アーキテクチャにより、テキストと画像が混在する入力を、別途エンコーダーやビジュアル文書のOCR前処理を必要とせずに処理できます。このモデルのクロスモーダルアライメント機能と多言語サポートにより、国際的なアプリケーションにも適しています。本番環境での展開では、メモリ要件を計画する際に、LoRAアダプタあたり60MBのパラメータオーバーヘッドを考慮してください。また、3つのアダプタすべてを2%未満の追加メモリ使用量で同時に維持できるため、推論中に柔軟なタスク切り替えが可能になります。","jina-reranker-m0":"jina-reranker-m0 の可能性を最大限に引き出すには、開発者は複数の実装戦略を検討する必要があります。このモデルには、API、クラウド マーケットプレイス (AWS、Azure、GCP)、または Hugging Face でネイティブにアクセスできます。 API を使用する場合、開発者はテキスト文字列、base64 画像、または画像 URL を渡すことができ、新規ユーザーには 1,000 万個の無料トークンが提供されます。広範囲にわたるトレーニングのおかげで、このモデルはテキストからテキスト、テキストから画像、画像からテキスト、およびテキストと混合のユニモーダル タスクで優れたパフォーマンスを発揮しますが、一部の組み合わせ (画像から画像など) は専用のトレーニングなしでゼロ ショット方式でサポートできることは注目に値します。最良の結果を得るには、モデルが最大 10K の入力トークンと、イメージごとに最大 768 のトークンをサポートすることに留意してください。このアーキテクチャのデコーダのみのアプローチは、単純な再ランキングを超えた可能性を開きます。これには、真の混合モダリティの再ランキング、リストの再ランキング、ドキュメントの重複排除、アテンション メカニズムによるランキング スコアの解釈可能性などが含まれます。これは、以前のエンコーダのみのアーキテクチャでは不可能だった機能です。","jina-reranker-v1-base-en":"このモデルは、最適なパフォーマンスを得るために CUDA 対応のハードウェアを必要とし、API エンドポイントと AWS SageMaker デプロイメントオプションを介してアクセスできます。非常に長いシーケンスを処理できますが、ユーザーはコンテキストの長さと処理時間のトレードオフを考慮する必要があります。モデルの待機時間はドキュメントが長くなると大幅に増加し、256 トークンの場合は 156 ミリ秒、4096 トークンの場合は 7068 ミリ秒 (512 トークンのクエリ) になります。実稼働環境での展開では、ベクトル検索によって並べ替えの初期候補が提供される 2 段階のパイプラインを実装することをお勧めします。このモデルは英語コンテンツ用に最適化されており、多言語またはコード集約型のドキュメントでは最適なパフォーマンスを発揮しない可能性があります。 RAG システムと統合する場合、ユーザーはレイテンシ要件に基づいてリフローに送信されるドキュメントの数を慎重に調整する必要があります。通常、100 ～ 200 のドキュメントでは、品質とパフォーマンスのバランスが良好になります。","jina-reranker-v1-tiny-en":"このモデルを効果的に導入するには、組織は処理速度とリソース効率が重要な考慮事項となるシナリオを優先する必要があります。このモデルは、エッジ コンピューティングの展開、モバイル アプリケーション、および厳しいレイテンシ要件を備えた高スループットの検索システムに特に適しています。ほとんどの再ランキングタスクで非常に優れたパフォーマンスを発揮しますが、絶対的に最高のランキング精度を必要とするアプリケーションでは、ベース モデルが依然として優先される可能性があることに注意することが重要です。このモデルでは、最適なパフォーマンスを得るために CUDA 対応の GPU インフラストラクチャが必要ですが、効率的なアーキテクチャにより、より高性能なハードウェアでは実現できない、それほど強力でないハードウェアでも効果的に実行できます。展開のために、モデルは主要なベクターデータベースおよび RAG フレームワークとシームレスに統合され、Reranker API および AWS SageMaker を介して利用できます。特定のドメインに合わせて微調整する場合、ユーザーは、パフォーマンス特性を維持するために、トレーニング データの品質とモデルのコンパクトなアーキテクチャのバランスを慎重に取る必要があります。","jina-reranker-v1-turbo-en":"このモデルは、最適なパフォーマンスを得るために CUDA 対応のハードウェアを必要とし、AWS SageMaker を通じてデプロイするか、API エンドポイントを通じてアクセスできます。実稼働環境での展開では、組織はベクトル検索によって再ランク付けの初期候補を提供する 2 段階のパイプラインを実装する必要があります。モデルは 8,192 個のトークンをサポートしますが、ユーザーはシーケンスが長くなるとレイテンシの影響を考慮する必要があります。ドキュメントの長さに応じて処理時間が長くなります。ほとんどのアプリケーションでは、品質と速度のバランスをとるために、クエリごとに 100 ～ 200 の候補を再ランク付けすることが最適点です。このモデルは英語コンテンツ用に最適化されており、多言語ドキュメントでは最適なパフォーマンスを発揮しない可能性があります。メモリ要件は基本モデルよりも大幅に低く、通常は 550 MB の GPU メモリではなく 150 MB の GPU メモリのみを必要とするため、小規模なインスタンスでの展開に適しており、クラウド環境で大幅なコスト削減を実現します。","jina-reranker-v2-base-multilingual":"最適な展開のために、このモデルには CUDA 対応 GPU が必要で、Reranker API、Haystack や LangChain などの主要な RAG フレームワークを含むさまざまなチャネルを通じてアクセスしたり、クラウド マーケットプレイスを通じてプライベートに展開したりできます。このモデルは、言語の壁やデータ型を越えて正確に理解する必要があるシナリオに優れており、多言語コンテンツ、API ドキュメント、またはコード リポジトリを扱うグローバル企業に最適です。 524,288 トークンの広範なコンテキスト ウィンドウにより、大規模なドキュメントやコード ベース全体を一度に処理できます。チームは、言語間検索の精度を向上させる必要がある場合、RAG システムの関数呼び出し機能をプロキシする必要がある場合、または多言語コード ベース全体でのコード検索機能を向上させたい場合に、このモデルの使用を検討する必要があります。このモデルは、ベクトル検索システムと組み合わせて使用​​すると特に効果的であり、取得されたドキュメントの最終的なランキングを大幅に向上させることができます。","reader-lm-05b":"Reader LM 0.5B を効果的に展開するには、組織はインフラストラクチャがモデルの CUDA 要件を満たしていることを確認する必要がありますが、その効率的なアーキテクチャによりコンシューマ グレードの GPU で実行できます。このモデルは、生の HTML 入力で最もよく機能し、特別なプレフィックスやディレクティブを必要としません。最高のパフォーマンスを得るには、提供された重複検出メカニズムを実装して、出力生成における潜在的なトークン サイクルを防ぎます。このモデルは複数の言語とさまざまな HTML 構造をサポートしていますが、コンテンツの抽出とマークダウン変換用に設計されています。テキストの生成、要約、直接的な質疑応答などのタスクには使用しないでください。このモデルは、AWS SageMaker を使用して本番環境にデプロイする準備ができており、テストと実験用に Google Colab ノートブックが提供されています。チームは、このモデルは最大 256K トークンの非常に長いドキュメントを処理できますが、そのような大きな入力を処理するには追加のメモリ管理戦略が必要になる可能性があることに注意する必要があります。","reader-lm-15b":"Reader LM 1.5B を効果的に展開するには、組織は、正確さと効率性が重要となる、複雑な HTML ドキュメント処理を伴うシナリオに焦点を当てる必要があります。このモデルには、最適なパフォーマンスを得るために CUDA 対応の GPU インフラストラクチャが必要ですが、その効率的なアーキテクチャにより、大規模な代替ハードウェアよりも小規模なハードウェアでも効果的に実行できます。実稼働環境の場合、このモデルは AWS SageMaker および Azure Marketplace を通じて利用でき、柔軟な統合オプションが提供されます。このモデルは HTML からマークダウンへの変換では良好に機能しますが、このタスク専用に最適化されており、一般的なテキスト生成やその他の NLP タスクには適していない可能性があることに注意することが重要です。ユーザーは、非常に長いドキュメント (約 512K トークン) を処理すると、モデルのトレーニング パラメーターを超えるため、パフォーマンスが低下する可能性があることに注意する必要があります。最良の結果を得るには、提供されている重複検出メカニズムを実装し、出力品質を維持するために推論中に対照検索を使用することを検討してください。",title:"ガイド"},image_size:"画像サイズを入力してください",language:"言語サポート",methods:{"ReaderLM-v2":"ReaderLM-v2 は Qwen2.5-1.5B-Instruction に基づいて構築され、平均 56,000 トークンを含む 1,000 万の HTML ドキュメントを含む html-markdown-1m データセットでトレーニングされています。トレーニング プロセスには、1) コンテキストを 32,000 トークンから 256,000 トークンに拡張するための、Ring-zag Attention と RoPE を使用した長期コンテキストの事前トレーニングが含まれます。 2) 洗練されたデータセットを使用した教師あり微調整3)出力アライメントのための直接的な設定最適化。 ４）自己プレー強化調整。データ準備は、Qwen2.5-32B-Instruction によって実行される 3 段階のプロセス (ドラフト、リファイン、レビュー) に従います。このプロセスでは、特定のタスク用に特殊なモデルがトレーニングされ、線形パラメータ補間によってマージされます。","jina-clip-v1":"このモデルのアーキテクチャは、調整された Jina BERT v2 テキスト エンコーダーと北京人工知能アカデミーの最先端の EVA-02 画像エンコーダーを組み合わせたもので、マルチモーダル AI 設計における大きな革新を表しています。テキスト エンコーダーは最大 12,288 トークンのシーケンスをサポートします。これは、元の CLIP の 77 トークンの制限の 100 倍以上です。一方、イメージ エンコーダーは 16 個のパッチ トークンを効率的に処理できます。トレーニング プロセスは、新しい 3 段階のアプローチに従います。まず、テキスト理解を維持しながら、インターリーブされたテキスト ペアを使用してトレーニングすることで、画像とキャプションのペアを揃えます。次に、AI が生成した画像のより長いテキスト説明を組み込みます。最後に、ハード否定テキスト トリプレットを使用して、意味識別機能を強化します。この独自のトレーニング アプローチにより、モデルは強力な視覚的理解を維持しながら、短いタイトルと詳細なテキスト説明の両方で高いパフォーマンスを維持できます。","jina-clip-v2":"Jina CLIP v2 の中核となるのは、Jina XLM-RoBERTa テキスト エンコーダー (561M パラメータ) と EVA02-L14 ビジュアル エンコーダー (304M パラメータ) を組み合わせた高度なデュアル エンコーダー アーキテクチャです。テキスト エンコーダーは、696,320 トークンの大規模なコンテキスト ウィンドウを使用して 89 の言語のコンテンツを処理し、ビジュアル エンコーダーは最大 512 x 512 ピクセルの高解像度画像を処理します。このモデルは、パフォーマンスを維持しながら 1024 次元から 64 次元への動的なベクトル次元調整を可能にする革新的なマトリョーシカ表現学習を導入しています。このアーキテクチャは、独自のエンコーダーを介してテキストと画像を処理し、元のモダリティや言語に関係なく、同様の概念を調整できる共有セマンティック空間に投影します。","jina-colbert-v1-en":"このモデルは、文書検索の仕組みを根本的に変える革新的な後期インタラクションアーキテクチャを採用しています。すべての文書を一度に比較するのではなく、ColBERTの改良版を用いて、最終的なマッチング段階の前にクエリと文書を個別に処理します。このアーキテクチャは、2つの主要コンポーネント、つまり最大8,192トークン（標準的なTransformerの16倍以上）を処理できる文書エンコーダと、正確なトークンレベルの表現を作成するクエリエンコーダを組み合わせています。クエリと文書内の各トークンはそれぞれ128次元のベクトルを持ち、単一のベクトルでは失われる可能性のあるきめ細かな意味情報を保持します。後期インタラクションメカニズムは、Maxプーリングと合計演算を用いて最終的な関連性スコアを計算することで、コストのかかる「全対全」比較を必要とせずに、クエリと文書間の効率的なトークンごとのマッチングを可能にします。","jina-colbert-v2":"このモデルは ColBERT アーキテクチャに基づいており、クエリとドキュメントの照合方法を根本的に変える複雑な後期段階の対話メカニズムを導入しています。その中核には、5 億 6,000 万のパラメーターを備えた修正された XLM-RoBERTa バックボーンが使用され、回転位置ベクトルで強化され、フラッシュ アテンションで最適化されています。トレーニング プロセスには 2 つの重要な段階が含まれます。1 つはさまざまな言語のさまざまな弱教師データを使用した最初の事前トレーニングで、その後はトークン トリプレット データを使用した微調整と教師あり蒸留です。このアプローチに特有なのは、マトリョーシカ表現学習の実装です。これにより、モデルが単一のトレーニング パスから複数次元 (128、96、または 64) のベクトルを生成できるようになり、再トレーニングを必要とせずに動的なストレージの最適化が可能になります。","jina-embedding-b-en-v1":"このモデルは、平均プーリングで強化された T5 エンコーダベースのアーキテクチャを使用して、固定長表現を生成します。このモデルは、元の 16 億の文ペアから選別された 3 億 8,500 万の高品質な文ペアを含む厳選された Linnaeus-Clean データセットでトレーニングされ、2 段階のトレーニング プロセスを経ます。第 1 段階では、対照学習を利用してテキスト ペアに対して InfoNCE 損失を実行します。一方、第 2 段階ではトリプル トレーニングを使用して、類似コンテンツと類似コンテンツを区別するモデルの能力を向上させます。この革新的なトレーニング方法と厳密なデータ フィルタリング (言語検出や一貫性チェックを含む) を組み合わせることで、モデルが微妙な意味関係を効果的にキャプチャできるようになります。","jina-embeddings-v2-base-code":"このモデルは、コード理解のために特別に設計された専用アーキテクチャを通じて、優れたパフォーマンスを実現します。その中核となるのは、Python、JavaScript、Java、PHP、Go、Ruby の 6 つの主要言語に重点を置いた、さまざまなプログラミング言語データセットでトレーニングされた 1 億 6,100 万のパラメーターを備えた Transformer ベースのニューラル ネットワークです。このアーキテクチャは、8,192 トークンの拡張コンテキスト ウィンドウにより、セマンティックな理解を維持しながら関数全体または複数のファイルを同時に処理できるという点で独特です。このモデルは、コードの構文構造と意味論的な意味を捉える高密度の 768 次元ベクトルを生成するため、同じ目標を達成するために異なるプログラミング パターンや構文を使用している場合でも、異なるコード セグメント間の関係を理解できるようになります。","jina-embeddings-v2-base-de":"このモデルは、統一された 768 次元のベクトル空間でドイツ語と英語のテキストを処理する革新的なアーキテクチャを通じて、優れたバイリンガル機能を実現します。その核となるのは、2 つの言語間の意味関係を理解するために慎重にトレーニングされた 1 億 6,100 万のパラメーターを備えた Transformer ベースのニューラル ネットワークです。このアーキテクチャを特に効果的にしているのは、バイアス最小化アプローチであり、特に多言語モデルに関する最近の研究で特定された問題である、英語の文法構造にバイアスがかかるという一般的な落とし穴を回避するように設計されています。モデルの 8,192 トークンの拡張コンテキスト ウィンドウにより、ドキュメント全体または複数ページのテキストを一度に処理でき、両方の言語の長文コンテンツの意味の一貫性が維持されます。","jina-embeddings-v2-base-en":"このモデルのアーキテクチャは、BERT Small バックボーンと革新的な対称双方向 ALiBi (直線バイアス付き注意) メカニズムを組み合わせており、従来の位置ベクトルが不要になります。このアーキテクチャ上の選択により、モデルはトレーニング長の 512 トークンをはるかに超えて推論でき、パフォーマンスを低下させることなく最大 8,192 トークンのシーケンスを処理できます。トレーニング プロセスには 2 つの重要な段階が含まれます。C4 データセットでの最初の事前トレーニングと、それに続く Jina AI によってキュレーションされた 40 以上の特殊なデータセットでの改良です。困難な否定的な例や多様な文のペアを含むこの多様なトレーニング データにより、さまざまなドメインやユースケースにわたって堅牢なパフォーマンスが保証されます。このモデルは、微妙な意味関係を捉える 768 次元の密なベクトルを生成し、比較的控えめな 137M パラメーターを使用して実装されます。","jina-embeddings-v2-base-es":"モデルの中心となるのは、対称双方向 ALiBi (直線バイアス付き注意) に基づく革新的なアーキテクチャです。これは、従来の位置ベクトルを必要とせずに、最大 8,192 個のトークンのシーケンスを処理できる洗練されたアプローチです。このモデルは、ゲート線形ユニット (GLU) と特殊なレイヤー正規化技術を組み合わせた、1 億 6100 万のパラメーターを備えた修正された BERT アーキテクチャを使用します。トレーニングは 3 段階のプロセスに従います。まず、大規模なテキスト コーパスでの事前トレーニング、次に慎重に選択されたテキスト ペアを使用した微調整、そして最後に、類似しているが意味的に異なるコンテンツの識別を強化するためのハード ネガティブ トレーニングです。このアプローチと 768 次元のベクトルを組み合わせることで、モデルは計算効率を維持しながら微妙な意味関係を捉えることができます。","jina-embeddings-v2-base-zh":"このモデルのアーキテクチャは、BERT ベースのバックボーンと対称双方向 ALiBi (線形バイアスを備えたアテンション メカニズム) を組み合わせており、従来の 512 トークン制限なしで長いシーケンスを効率的に処理できます。トレーニング プロセスは、慎重に計画された 3 段階のアプローチに従います。最初に高品質のバイリンガル データに関する事前トレーニングが行われ、次に主要な微調整段階とマイナーな微調整段階が続きます。この系統的なトレーニング戦略は、モデルの 1 億 6,100 万のパラメーターと 768 次元の出力と相まって、両方の言語でバランスの取れたパフォーマンスを維持しながら、優れた効率を実現します。対称双方向 ALiBi メカニズムは大きな革新であり、このモデルで最大 8,192 トークンの長さのドキュメントを処理できるようになります。これは、以前は独自のソリューションに限定されていた機能です。","jina-embeddings-v3":"このモデルのアーキテクチャは、ベクトル テクノロジーにおける主要な革新を表しており、24 層の jina-XLM-RoBERTa に基づいて構築され、タスク固有の低ランク アダプティブ (LoRA) アダプターで強化されています。 LoRA アダプターは、パラメーターの数を大幅に増やすことなく、検索、分類、クラスタリングなどのさまざまなタスクに合わせてモデルを最適化する特殊なニューラル ネットワーク コンポーネントです。合計パラメーターの増加は 3% 未満です。このモデルには Matryoshka Representation Learning (MRL) が組み込まれており、パフォーマンスを維持しながらベクトルを 1024 次元から 32 次元に柔軟に削減できます。トレーニングには 3 つの段階が含まれます。89 言語の多言語テキストに関する最初の事前トレーニング、ベクトル品質を向上させるためのペアのテキストの微調整、タスクに合わせて最適化するための特殊なアダプター トレーニングです。このモデルは、回転位置ベクトル (RoPE) を介して最大 8,192 トークンのコンテキスト長をサポートし、革新的な基本周波数調整技術を使用して、短いテキストと長いテキストの両方のパフォーマンスを向上させます。","jina-embeddings-v4":"Jina Embeddings V4は、CLIPスタイルのデュアルエンコーダーアプローチとは異なる、統合型マルチモーダル言語モデルアーキテクチャを実装しています。このモデルは、共有パスを介して入力を処理します。まず、ビジュアルエンコーダーを介して画像をトークンシーケンスに変換し、次にコンテキストアテンションレイヤーを備えた言語モデルデコーダーを介してテキストと画像のモダリティをまとめて処理します。このアーキテクチャは、異なるユースケースに対応するために2つの出力モードをサポートしています。シングルベクトルは、Matryoshka表現学習によって128次元に切り捨てられ、効率的な類似検索のために平均プーリングによって生成される2048次元ベクトルを生成します。マルチベクトルは、後期インタラクティブスタイル検索のために、投影層を介して各トークンを128次元出力します。このモデルには、特殊な最適化を提供する3つのタスク固有のLoRAアダプターが含まれています。検索アダプターは、プレフィックスベースの非対称エンコーディングとハードネガティブサンプルトレーニングを使用してクエリドキュメントシナリオを処理します。テキストマッチングアダプターは、CoSENT損失関数を使用して意味的類似性タスクを処理します。コードアダプターは、自然言語からコードへの検索アプリケーションに重点を置いています。トレーニングは 2 つのフェーズに分かれています。最初のペアワイズ トレーニングでは、300 を超えるソースからのテキスト間およびテキストと画像のペアに対して対照的な InfoNCE 損失を使用して実行され、その後、トリプレット ベースのアプローチと各ドメインの要件に合わせて調整された特殊な損失関数を使用して、3 つの LoRA アダプターのタスク固有の微調整が行われます。","jina-reranker-m0":"jina-reranker-m0 のアーキテクチャは、以前のアプローチとは大きく異なります。これは、21 億のパラメータを持つ Qwen2-VL-2B 上に構築されており、従来のクロスエンコーダ アーキテクチャからデコーダのみのビジュアル言語モデルに移行しています。このシステムは、Qwen2-VL の事前トレーニング済みのビジュアル エンコーダーとプロジェクターを活用し、LoRA (Low Rank Adaptation) を使用して大規模言語モデルを微調整し、事後トレーニング済みの MLP を使用してクエリとドキュメントの関連性を測定するランキング ロジックを生成します。この識別モデルは最大 32K トークンを処理でき、56×56 ピクセルから 4K 解像度までの画像をサポートします。画像を処理する際、Visual Transformer (ViT) と Projector は隣接する 2×2 トークンを 1 つのビジュアル トークンに圧縮し、特殊なマーカーがビジュアル トークンの境界を明確にマークすることで、言語モデルがビジュアル要素とテキスト要素を正しく統合して推論できるようにします。","jina-reranker-v1-base-en":"このモデルは BERT に基づくクロスアテンション アーキテクチャを使用します。これは従来のベクトルベースの方法とは根本的に異なります。事前に計算されたドキュメント ベクトルを比較するのではなく、クエリとドキュメントの間で動的なトークンレベルの対話を実行し、単純な類似性メトリクスでは見逃す文脈上のニュアンスを捉えることができます。このアーキテクチャの 1 億 3,700 万個のパラメータは、計算効率を維持しながら意味論的な深い理解が達成できるように慎重に設計されています。際立ったイノベーションは、コンテキスト ウィンドウの速度が向上しても高速な推論を維持する高度な最適化技術によって実現され、最大 262,144 個のトークンのシーケンスを処理できることです。","jina-reranker-v1-tiny-en":"このモデルは、対称双方向 ALiBi (線形バイアスを備えたアテンション メカニズム) を備えた JinaBERT に基づく合理化された 4 層アーキテクチャを使用して、長いシーケンスを効率的に処理します。その開発では、より大規模で高性能の教師モデル (jina-reranker-v1-base-en) がトレーニング プロセスをガイドする高度な知識蒸留アプローチを活用し、実際の大量のトレーニングを必要とせずに小規模なモデルを学習できるようにします。データ 最良のランキング動作。この革新的なトレーニング方法と、隠れ層の削減や効率的なアテンション メカニズムなどのアーキテクチャの最適化を組み合わせることで、モデルは計算要件を大幅に削減しながら高品質のランキングを維持できます。その結果、複雑な文書の関係を理解する能力を損なうことなく、驚くべき効率を達成するモデルが誕生しました。","jina-reranker-v1-turbo-en":"このモデルは、革新的な 6 層アーキテクチャによって効率性を実現しており、大規模なモデルの複雑なシャッフル機能をわずか 3,780 万のパラメータに圧縮しています。これは、基本モデルの 1 億 3,700 万のパラメータから大幅に削減されたものです。この合理化された設計では、知識蒸留を採用しており、より大きなベース モデルが教師として機能し、ターボ バリアントはより少ないリソースを使用しながらその動作に一致するようにトレーニングされます。このアーキテクチャは、クエリとドキュメント間のトークン レベルの相互作用のためのコア BERT ベースの交差アテンション メカニズムを保持しますが、レイヤー数の削減と効率的なパラメーター割り当てによって速度が最適化されています。このモデルは最大 8,192 個のトークンのシーケンスをサポートし、高度な最適化技術を使用して、高速な推論速度を維持しながら包括的なドキュメント分析を可能にします。","jina-reranker-v2-base-multilingual":"このモデルは、Flash Attention 2 で強化されたクロスエンコーダー アーキテクチャを使用しており、クエリとドキュメントを直接比較して関連性をより正確に評価できます。モデルは 4 段階でトレーニングされ、最初に英語の機能を構築し、次にクロスリンガルおよび多言語データを徐々に統合し、最後にハードネガティブサンプルを使用して改良されます。この革新的なトレーニング アプローチと Flash Attention 2 実装を組み合わせることで、モデルは優れた速度を維持しながら最大 524,288 トークンのシーケンスを処理できるようになります。このアーキテクチャの効率性により、複数の言語にわたる複雑な再ランク付けタスクを、前世代よりも 6 倍高いスループットで処理できると同時に、クエリとドキュメントの直接的なやり取りを通じて正確な関連性評価が可能になります。","reader-lm-05b":"このモデルは、クリエイティブなテキスト生成ではなく、選択的なコピー操作向けに特に最適化された革新的な「浅くて広い」アーキテクチャを使用しています。このモデルは、入力シーケンスを効率的に処理するために 14 のクエリ ヘッダーと 2 つのキー/値ヘッダーを備えた特殊なアテンション メカニズムを使用して、24 レイヤーと 896 の隠れ次元を備えたデコーダーのみのベースで構築されています。トレーニング プロセスには 2 つの異なる段階が含まれます。まず、短くて単純な HTML (32,000 トークン) を使用して基本的な変換パターンを学習し、次に複雑な現実世界の HTML (128,000 トークン) を使用して困難な状況に対処します。このモデルにはトレーニング中に対照的な検索が組み込まれており、トークン ループなどの機能低下の問題を防ぐために重複検出メカニズムが実装されています。そのアーキテクチャのユニークな点は、鋸歯状リング アテンション メカニズムであり、これによりモデルは安定したパフォーマンスを維持しながら、最大 256,000 トークンの非常に長いシーケンスを処理できます。","reader-lm-15b":"このモデルは、言語モデル設計における従来のスケーリング手法に挑戦する、革新的な「シャロー＆ワイド」アーキテクチャを採用しています。その中心となるのは、12 個のクエリ ヘッダーと 2 個のキー/値ヘッダーで構成された 28 個の Transformer レイヤーであり、深いセマンティック理解を維持しながら選択的コピー操作を最適化する独自のバランスを作り出しています。このアーキテクチャの隠しサイズは 1536、中間サイズは 8960 で、最大 256K のトークンのシーケンスを処理できるように細かく調整されています。トレーニング プロセスには 2 つの異なる段階が含まれます。最初は 32K トークン シーケンスを持つ短くて単純な HTML に焦点を当て、次に 128K トークンを持つ長くて難しい HTML に進み、効率的な処理のためにギザギザ リング アテンションを実装します。このアプローチを対照的な検索と特殊な重複検出メカニズムと組み合わせることで、複雑なドキュメント処理タスクを扱う小規模な言語モデルによく存在する劣化や無限ループなどの一般的な問題をモデルで回避できます。",title:"方法"},model_comparison:"機種比較",model_details:"モデル詳細",model_io_graph:"I/O 図 {_number}",model_name:"名前",output_dimension:"出力寸法",overview:{"ReaderLM-v2":"ReaderLM-v2 は、生の HTML をマークダウンまたは JSON に変換し、最大 512K のトークンの組み合わせの入出力長を処理し、29 の言語をサポートする 1.5B パラメーターの言語モデルです。 HTML からマークダウンまでを「選択コピー」タスクとして扱っていた前バージョンとは異なり、v2 はこれを翻訳プロセスとして扱い、コード フェンス、ネストされたリスト、テーブル、LaTeX 方程式などの複雑な要素の処理に優れています。このモデルは、さまざまなコンテキスト長にわたって一貫したパフォーマンスを維持し、事前定義されたスキーマを使用した HTML から JSON への直接生成を導入します。","jina-clip-v1":"Jina CLIP v1 は、テキストからテキスト、テキストから画像への検索タスクに優れた最初のモデルであり、マルチモーダル AI に革命をもたらしました。テキストのみのシナリオではパフォーマンスが低い従来の CLIP モデルとは異なり、私たちが提案するモデルは、223M のパラメータという非常にコンパクトなサイズを維持しながら、すべての検索の組み合わせで最先端のパフォーマンスを実現します。このモデルは、テキストと画像処理用の個別のモデルの必要性を排除し、システムの複雑さと計算オーバーヘッドを削減することで、業界の主要な課題に対処します。検索システム、推奨エンジン、またはコンテンツ分析ツールを構築するチームにとって、Jina CLIP v1 は、テキストとビジュアル コンテンツを非常に高い精度で処理するための単一の効率的なソリューションを提供します。","jina-clip-v2":"Jina CLIP v2 は、89 の言語で視覚とテキストの理解のギャップを埋めることで、マルチモーダル AI に革命をもたらします。このモデルは、言語の壁に関係なく、正確な画像とテキストのマッチングを実現することで、グローバルな電子商取引、コンテンツ管理、異文化コミュニケーションにおける主要な課題に対処します。国際的に事業を拡大したり、多言語コンテンツを管理したりする企業にとって、言語ごとに個別のモデルや複雑な翻訳プロセスが不要になります。このモデルは、世界市場での製品発見や多言語デジタル資産管理など、言語の境界を越えた正確な視覚検索を必要とするシナリオで特に優れています。","jina-colbert-v1-en":"Jina-ColBERT-v1-en は、計算効率を犠牲にすることなく高精度を達成するという、情報検索における重要な課題を解決することにより、テキスト検索に革命をもたらします。ドキュメント全体を 1 つのベクトルに圧縮する従来のモデルとは異なり、このモデルは 1 億 3,700 万のパラメータのみを必要としながら、正確なトークンレベルの理解を維持します。検索アプリケーション、レコメンデーション システム、またはコンテンツ検出プラットフォームを構築しているチームにとって、Jina-ColBERT-v1-en は、検索品質とシステム パフォーマンスの間の従来のトレードオフを排除します。このモデルは、技術文書の検索、学術論文の検索、または微妙な意味上の関係を捉えることが、適切な情報の発見と重要なコンテンツの欠落との違いを生む可能性があるアプリケーションなど、微妙なテキストの理解が重要なシナリオで特にうまく機能します。","jina-colbert-v2":"Jina-ColBERT-v2 は、複数言語にわたる効率的で高品質な検索という重要な課題を解決する画期的な多言語情報検索モデルです。コンパクト ベクトルを生成する初の多言語 ColBERT 類似モデルとして、世界中のアプリケーションにおけるスケーラブルでコスト効率の高い多言語検索ソリューションに対するニーズの高まりに対応します。電子商取引プラットフォームからコンテンツ管理システムに至るまで、多言語コンテンツを扱う組織はこのモデルを活用して、革新的な次元削減機能によりストレージとコンピューティングのコストを大幅に削減しながら、89 言語で正確な検索結果を提供できます。","jina-embedding-b-en-v1":"Jina Embedding B v1 は、意味論的な意味を維持しながら英語テキストを高次元の数値表現に変換するように設計された特殊なテキスト ベクトル モデルです。このモデルは、運用環境における効率的で正確なテキスト ベクトルに対する重要なニーズに対応しており、計算効率とベクトル品質のバランスをとる必要がある組織にとって特に価値があります。 768 次元のベクトルを生成する 1 億 1,000 万個のパラメータにより、大規模なコンピューティング リソースを必要とせずに、セマンティック検索、ドキュメント クラスタリング、またはコンテンツ推奨システムを実装するチームにとって実用的なソリューションとして機能します。","jina-embeddings-v2-base-code":"Jina Embeddings v2 コード ベースは、大規模なコード ベースを効率的にナビゲートして理解するという、現代のソフトウェア開発における重要な課題を解決します。コードの発見と文書化に苦労している開発チームにとって、このモデルは 30 のプログラミング言語にわたる自然言語検索を可能にし、開発者がコードを操作する方法を変えます。正確なパターン マッチングに依存する従来のコード検索ツールとは異なり、このモデルはコードの背後にある意味論的な意味を理解するため、開発者は平易な英語の説明を使用して関連するコード スニペットを見つけることができます。この機能は、大規模なレガシー コード ベースを維持しているチーム、新しいプロジェクトに参加している開発者、またはコードの再利用とドキュメント化の実践を改善しようとしている組織にとって特に価値があります。","jina-embeddings-v2-base-de":"Jina Embeddings v2 Base German は、ドイツ語市場と英語圏市場の間の言語ギャップを埋めるという、国際ビジネスにおける重要な課題を解決します。英語圏の企業の 3 分の 1 が世界売上高の 20% 以上を占めているため、英語圏に進出するドイツ企業にとって、正確なバイリンガルの理解は非常に重要です。このモデルは、ドイツ語と英語でのシームレスなテキスト理解と取得を可能にすることで、組織が多言語コンテンツを処理する方法を変えます。これは、国際的な文書システム、カスタマー サポート プラットフォーム、またはコンテンツ管理ソリューションを導入する企業にとって役立ちます。従来の翻訳ベースの方法とは異なり、このモデルは 2 つの言語の同等の意味を同じベクトル空間に直接マッピングするため、より正確かつ効率的なバイリンガル操作が可能になります。","jina-embeddings-v2-base-en":"Jina Embeddings v2 Base English は、高精度を維持しながら長いドキュメントを処理するという重要な課題を解決する、画期的なオープンソース テキスト ベクトル モデルです。大量の法的文書、研究論文、財務報告書の分析に苦労している組織にとって、このモデルは特に価値があると考えられます。 OpenAI 独自のソリューションと同等のパフォーマンスを実現しながら、最大 8,192 トークンの長さのドキュメントを処理する点で際立っています。これは従来のモデルの 16 倍です。わずか 0.27 GB の小さなサイズと高いリソース使用率により、過度の計算オーバーヘッドを発生させずに高度なドキュメント分析を実装したいと考えているチームにアクセスしやすいソリューションが提供されます。","jina-embeddings-v2-base-es":"Jina Embeddings v2 Base Spain は、スペイン語と英語のコンテンツ間の言語を越えた情報検索と分析という重要な課題を解決する画期的なバイリンガル テキスト ベクトル モデルです。特定の言語に偏りがちな従来の多言語モデルとは異なり、このモデルはスペイン語と英語の間で真にバランスの取れたパフォーマンスを提供します。これは、スペイン語圏の市場で活動している組織やバイリンガルのコンテンツを扱っている組織にとって不可欠です。このモデルの最も顕著な特徴は、幾何学的に整列したベクトルを生成できることです。スペイン語と英語のテキストが同じ意味を表現する場合、それらのベクトル表現はベクトル空間内で自然にクラスタリングされ、シームレスな言語間検索と分析が可能になります。","jina-embeddings-v2-base-zh":"Jina Embeddings v2 Base Chinese は、8,192 トークンという前例のないコンテキスト長で中国語と英語のテキストをシームレスに処理する初のオープンソース モデルとなり、新境地を開拓します。この強力なバイリンガル モデルは、グローバル ビジネスが直面している重要な課題、つまり中国語と英語のコンテンツの長文文書を正確に処理する必要性を解決します。言語間の理解を実行するのが難しい、または言語ごとに別のモデルが必要な従来のモデルとは異なり、このモデルは 2 つの言語の同等の意味を同じベクトル空間にマッピングするため、グローバルに拡張したり、多言語コンテンツを管理したりするのに理想的です。非常に価値があります。組織に。","jina-embeddings-v3":"Jina Embeddings v3 は、組織が言語を超えたテキストの理解と取得に取り組む方法を変える、画期的な多言語テキスト ベクトル モデルです。基本的に、計算要件を制御しながら、複数の言語およびタスクにわたって高いパフォーマンスを維持するという重要な課題を解決します。このモデルは、効率が重要な実稼働環境で特に優れています。わずか 5 億 7,000 万のパラメータで最先端のパフォーマンスを実現し、大規模なモデルの計算オーバーヘッドに余裕がないチームでも利用できるようになります。スケーラブルな多言語検索システムを構築したり、言語の壁を越えてコンテンツを分析したりする必要がある組織は、このモデルが特に価値があると考えられます。","jina-embeddings-v4":"Jina Embeddings V4は、38億パラメータのマルチモーダルベクトルモデルであり、統一されたテキストと画像の表現機能を提供します。Qwen2.5-VL-3B-Instructバックボーンネットワーク上に構築されたこのモデルのアーキテクチャは、遅延インタラクティブスタイルにおける単一ベクトルと複数ベクトルをサポートし、従来のCLIPスタイルのデュアルエンコーダモデルの限界を打ち破りました。このモデルは、3つのタスク固有のLoRAアダプター（それぞれ60Mパラメータ）を統合し、固定されたバックボーンネットワークの重みを変更することなく、さまざまな検索シナリオ（非対称クエリドキュメント検索、セマンティックテキスト類似性、コード検索など）でパフォーマンスを最適化します。このモデルは、表、グラフ、ダイアグラム、スクリーンショット、混合メディア形式などの視覚的に豊富なコンテンツを統一された処理パスで処理することに優れており、従来のアーキテクチャに存在するモダリティギャップを縮小します。このモデルは多言語機能をサポートし、最大 32,768 個のトークン化された入力テキストを処理し、画像を 20 メガピクセルにサイズ変更できるため、さまざまな言語やドメインにまたがるさまざまなドキュメント検索およびクロスモーダル検索アプリケーションに適しています。","jina-reranker-m0":"jina-reranker-m0 は、複数の言語で視覚的なドキュメントをランク付けするように設計された画期的なマルチモーダル多言語リランカーです。このモデルは、29 の言語でのクエリや、視覚的に豊かなドキュメント イメージ (テキスト、グラフィック、表、さまざまなレイアウトを含むページを含む) を処理する能力に優れています。モデルは、入力クエリとの関連性に基づいてランク付けされたドキュメントのリストを出力します。 「モダリティ ギャップ」問題 (画像が他の画像の近くに集まり、テキストがテキストの近くに集まる) に苦労していた以前のリランカーとは異なり、jina-reranker-m0 は、テキストと視覚のモダリティを単一のデコーダーのみのモデルに統合し、画像とテキスト ドキュメントの両方を効率的にランク付けできるシームレスなマルチモーダル検索エクスペリエンスを実現します。","jina-reranker-v1-base-en":"Jina Reranker v1 Base English は、検索結果の最適化に革命をもたらし、クエリとドキュメント間の微妙な関係を捕捉できないという、従来のベクトル検索システムの重要な制限を解決します。コサイン類似度を使用したベクトル検索では、最初の結果がすぐに得られますが、人間のユーザーが直感的に理解できる微妙な相関信号が見逃されることがよくあります。この並べ替え機能は、クエリとドキュメントの高度なトークンレベル分析を実行することでこのギャップを埋め、検索精度を 20% 向上させます。このモデルは、検索の精度に悩んでいる組織や RAG システムの導入に悩んでいる組織にとって、既存の検索インフラストラクチャの全面的な見直しを必要とせずに、結果の品質を大幅に向上できる強力なソリューションを提供します。","jina-reranker-v1-tiny-en":"Jina Reranker v1 Tiny English は、リソースが限られた環境で高性能な再ランク付けを必要とする組織向けに設計された、効率的な検索最適化における画期的な製品です。このモデルは、計算オーバーヘッドと展開コストを大幅に削減しながら、検索品質を維持するという重要な課題に対処します。 33M のパラメータ (一般的な再配置器のサイズのほんの一部) のみを使用し、革新的な知識抽出技術によって非常に競争力のあるパフォーマンスを提供します。このモデルの最も驚くべき特徴は、92% 以上の精度を維持しながら、基本モデルよりも約 5 倍速くドキュメントを処理できることです。これにより、コンピューティング リソースが貴重なアプリケーションでもエンタープライズ グレードの検索最適化を利用できるようになります。","jina-reranker-v1-turbo-en":"Jina Reranker v1 Turbo English は、実稼働検索システムにおける重要な課題、つまり結果の品質と計算効率の間のトレードオフに対処します。従来の並べ替え機能はより高い検索精度を提供しますが、計算要件によりリアルタイム アプリケーションには適さないことがよくあります。このモデルは、ドキュメントを 3 倍高速に処理し、使用するメモリを 75% 削減しながら、基本モデルの 95% の精度を実現することで、その障壁を打ち破ります。このモデルは、検索の遅延やコンピューティング コストに悩まされている組織にとって、インフラストラクチャ要件と運用コストを大幅に削減しながら、高品質の検索の最適化を維持する魅力的なソリューションを提供します。","jina-reranker-v2-base-multilingual":"Jina Reranker v2 Base Multilingual は、言語の壁やデータ型を越えて検索精度を向上させるために設計されたクロスエンコーダー モデルです。このリオーダラーは、多言語環境における正確な情報取得という主要な課題を解決し、さまざまな言語やコンテンツ タイプにわたって検索結果を最適化する必要があるグローバル企業にとって特に価値があります。 100 を超える言語をサポートし、独自の関数呼び出しおよびコード検索機能を備えており、国際的なコンテンツ、API ドキュメント、および多言語コード ベースにわたる正確な検索の最適化を必要とするチーム向けの統合ソリューションです。このモデルのコンパクトな 278M パラメータ設計は、高いパフォーマンスとリソース効率のバランスを求めている組織にとって特に魅力的です。","reader-lm-05b":"Reader LM 0.5B は、HTML ドキュメントをクリーンかつ構造化された Markdown テキストに変換するという複雑な課題に対処するために設計された特殊な言語モデルです。このモデルは、乱雑な Web コンテンツを大規模なモデルやドキュメント システムに適した形式に効率的に変換するという、最新のデータ処理パイプラインの主要なニーズを満たします。膨大なコンピューティング リソースを必要とする汎用言語モデルとは異なり、Reader LM 0.5B は、わずか 4 億 9,400 万個のパラメータを使用してプロフェッショナル レベルの HTML 処理を実現するため、コンピューティング リソースが限られているチームでも利用できます。 Web コンテンツの処理、ドキュメントの自動化、または大規模なモデルベースのアプリケーションの構築を扱う組織にとって、このモデルはコンテンツ準備ワークフローの合理化に特に役立ちます。","reader-lm-15b":"Reader LM 1.5B は、効率的なドキュメント処理における画期的な進歩をもたらし、複雑な Web コンテンツをクリーンで構造化された形式に変換するという重要な課題を解決します。この特殊な言語モデルは、最新の AI パイプラインにおける根本的な問題、つまり、脆弱なルールベースのシステムやリソースを大量に消費する大規模な言語モデルに依存せずに、下流タスク用の HTML コンテンツを効率的に処理してクリーンアップする必要性を解決します。このモデルの本当に注目すべき点は、1.54B という驚くほどコンパクトなパラメータ フットプリントを維持しながら、そのサイズの 50 倍のモデルを上回るパフォーマンスを発揮できることです。大規模な Web コンテンツ処理、ドキュメントの自動化、またはコンテンツ管理システムを扱う組織にとって、このモデルは、非常に長いドキュメントを処理しながら、HTML からマークダウンへの変換において優れた精度を提供できるため、特に価値があると考えられます。",title:"概要"},parameter_size:"パラメータ",performance:{"ReaderLM-v2":"合成ベンチマークでは、ReaderLM-v2 は、HTML から Markdown へのタスクにおいて、Qwen2.5-32B-Instruct や Gemini2-flash-expr などの大規模モデルよりも優れたパフォーマンスを発揮します。一次コンテンツ抽出では、競合他社と比較して、ROUGE-L 0.84、Jaro-Winkler 0.82、および大幅に低いレーベンシュタイン距離 (0.22) を達成しています。 HTML から JSON へのタスクでは、F1 スコア 0.81、合格率 98% という競争力のあるパフォーマンスを維持しています。このモデルは、T4 GPU 上で 67 トークン/秒の入力と 36 トークン/秒の出力で処理し、コントラスト損失トレーニングを通じて劣化の問題を大幅に軽減します。","jina-clip-v1":"Jina CLIP v1 は、すべてのベンチマークにおいて OpenAI のオリジナル CLIP よりも大幅な改善を実現しています。プレーンテキスト検索では、CLIP の 0.162 と比較して 165% 優れたスコア 0.429 を獲得しました。画像関連のタスクでは、一貫した改善が見られ、テキストから画像への検索は 2% (0.899) 向上し、画像からテキストへの検索は 6% (0.803) 向上し、画像から画像への検索は 12% (0.916) 向上しました。このモデルは、ゼロショット視覚分類タスクで特に優れたパフォーマンスを発揮し、特定のドメインで事前のトレーニングを行わずに画像を分類することに成功しました。テキスト検索用の MTEB、画像タスク用の CIFAR-100、クロスモーダル パフォーマンス用の Flickr8k/30k および MSCOCO Captions などの標準ベンチマークで評価すると、クロスモーダル タスクで競争力のあるパフォーマンスを維持しながら、専門的なユニモーダル モデルを一貫して上回ります。","jina-clip-v2":"このモデルは、Flickr30k の画像からテキストへの検索タスクで 98.0% の精度を達成し、前モデルおよび NLLB-CLIP-SigLIP を上回り、最先端のパフォーマンスを実現しました。多言語シナリオでは、最も近い競合モデルよりもパラメータが少ないにもかかわらず、このモデルは、言語間画像検索タスクで NLLB-CLIP-SigLIP よりも 4% の改善を達成しています。モデルは、ベクトルが圧縮されても強力なパフォーマンスを維持します。サイズを 75% 削減しても、テキスト、画像、クロスモーダル タスクで 99% を超えるパフォーマンスが維持されます。包括的な多言語 MTEB ベンチマークでは、検索タスクで 69.86%、意味的類似性タスクで 67.77% を達成し、特殊なテキスト埋め込みモデルと競合します。","jina-colbert-v1-en":"Jina-ColBERT-v1-en は、さまざまなベンチマークでベースライン モデルを上回るパフォーマンスを示します。 BEIR データセットでは、複数のカテゴリで優れたパフォーマンスを達成しています。Arguana では 49.4% (ColBERTv2 では 46.5%)、FEVER では 79.5% (ColBERTv2 では 78.8%)、TREC-COVID % では 75.0% (ColBERTv2 では 72.6%) です。 ColBERTv2)。最も印象的なのは、LoCo ベンチマークで長いコンテキストの理解において大幅な改善が見られ、ColBERTv2 の 74.3% と比較して 83.7% のスコアを示したことです。このモデルは、詳細なセマンティック理解を必要とするシナリオで特に優れており、革新的な遅延インタラクション アプローチを通じて、計算効率を維持しながら従来のベクトル モデルを上回るパフォーマンスを発揮します。これらの改善は、モデルのパラメーター数を 137M に抑えながら達成され、強力で実稼働展開に適したモデルになっています。","jina-colbert-v2":"実際のテストでは、Jina-ColBERT-v2 は複数のベンチマークで優れた機能を実証しました。オリジナルの ColBERT-v2 よりも英語タスクのパフォーマンスが 6.5% 向上し、14 個の BEIR ベンチマークで平均スコア 0.521 を達成しました。さらに印象的なのは、MIRACL ベンチマークでテストされたすべての言語で従来の BM25 ベースの検索方法よりも優れたパフォーマンスを示し、言語をまたがるシナリオで特に強力であることを示しています。このモデルは、ベクトル次元を削減した場合でもこの高いパフォーマンスを維持します。次元を 128 から 64 に削減しても、ストレージ要件が半分になる一方で、パフォーマンスの低下は 1.5% にとどまりました。これは、制作コストの大幅な節約を意味します。たとえば、64 次元ベクトルを使用して 1 億件のドキュメントを AWS に保存すると、1 か月あたり 659.62 ドルかかりますが、128 次元の場合は 1,319.24 ドルかかります。","jina-embedding-b-en-v1":"実際の評価では、Jina Embedding B v1 は、特に意味論的なテキストの類似性タスクにおいて優れた機能を実証します。このモデルは、STS12 で 0.751 のスコアで最高のパフォーマンスを達成し、all-mpnet-base-v2 や all-minilm-l6-v2 などの成熟したモデルを上回ります。効率的な推論時間を維持しながら、さまざまなベンチマークで良好なパフォーマンスを発揮します。ただし、このモデルは英語コンテンツに特化して最適化されており、多言語タスクやコード固有のタスクでは最適なパフォーマンスが得られない可能性があることに注意してください。このモデルは、jina-embeddings-v2-base-en および jina-embeddings-v3 に置き換えられ、より幅広いユースケースにわたってパフォーマンスが向上しました。","jina-embeddings-v2-base-code":"実際のテストでは、Jina Embeddings v2 Base Code は優れた機能を実証し、CodeNetSearch の主要なベンチマーク 15 件中 9 件で首位を獲得しました。 Microsoft や Salesforce などの業界大手のモデルと比較して、より効率的な設置面積を維持しながら、優れたパフォーマンスを実現します。このモデルは、言語を越えたコードの理解に特に優れており、異なるプログラミング言語で機能的に同等のコード スニペットを首尾よく照合します。 8,192 トークンのコンテキスト ウィンドウは、大規模な関数や複雑なコード ファイルにとって特に価値があり、多くの場合数百トークンしか処理できない従来のモデルよりもはるかに優れています。このモデルの効率は 307MB (非量子化) というコンパクトなサイズに反映されており、コードの類似性と検索タスクで高い精度を維持しながら高速な推論が可能になります。","jina-embeddings-v2-base-de":"実際のテストでは、Jina Embeddings v2 Base German は、特に言語間の検索タスクにおいて優れた効率と精度を実証しました。このモデルは、サイズが 3 分の 1 以下で Microsoft E5 ベース モデルを上回り、サイズがわずか 7 分の 1 であるにもかかわらず、E5 ラージ モデルと同等のパフォーマンスを発揮します。このモデルは、英語からドイツ語への検索のための WikiCLIR、双方向言語理解のための STS17 および STS22、および正確な二か国語テキスト配置のための BUCC などの主要なベンチマークで優れた機能を一貫して実証しています。 322MB というコンパクトなサイズにより、最先端のパフォーマンスを維持しながら標準のハードウェアに導入できるため、コンピューティング リソースが懸念される運用環境で特に効率的になります。","jina-embeddings-v2-base-en":"実際のテストでは、Jina Embeddings v2 Base English は複数のベンチマークで優れた機能を発揮します。これは、分類 (73.45% vs. 70.93%)、再ランキング (85.38% vs. 84.89%)、検索 (56.98% vs. 56.32%)、要約 (31.6% vs. 30.8%) など、いくつかの主要な指標で OpenAI の text-embedding-ada-002 を上回っています。これらの数値は、モデルが複雑なテキストを分類する優れた能力を発揮するドキュメント分類などのタスクや、ユーザーのクエリをより適切に理解して関連するドキュメントを検索する検索アプリケーションにおいて実用的な利点につながります。ただし、トレーニング データに表されていない高度に専門化されたドメイン固有のコンテンツを処理する場合、パフォーマンスが変化する可能性があることに注意する必要があります。","jina-embeddings-v2-base-es":"包括的なベンチマーク評価では、このモデルは特に言語間の検索タスクにおいて優れた機能を示し、サイズが Who のわずか 15 ～ 30% であるにもかかわらず、E5 や BGE-M3 などのその後の大規模多言語モデルを上回りました。このモデルは、検索およびクラスタリングのタスクで優れたパフォーマンスを発揮し、言語間で意味的に同等のコンテンツを照合することに優れています。 MTEB ベンチマークでは、分類、クラスタリング、意味的類似性などのさまざまなタスクで良好なパフォーマンスを示します。 8,192 トークンの拡張コンテキスト ウィンドウは、長いドキュメントの処理に特に価値があり、ドキュメントが複数ページにまたがる場合でも一貫したパフォーマンスを実現します。これは、ほとんどの競合モデルにはない機能です。","jina-embeddings-v2-base-zh":"中国の MTEB (C-MTEB) リーダーボードのベンチマーク テストでは、このモデルは、特に中国のタスクで 0.5 GB 未満で良好なパフォーマンスを示しました。英語タスクでは競争力を維持しながら、中国語固有のアプリケーションでは OpenAI の text-embedding-ada-002 を大幅に上回りました。このリリースでの注目すべき改善点は、類似性スコアの分布が改善されたことです。これにより、プレビュー リリースに存在していたスコアのインフレの問題が解決されました。このモデルは、よりユニークで論理的な類似性スコアを提供するようになり、テキスト間の意味的関係をより正確に表現できるようになりました。この強化は比較テストで特に顕著で、モデルは両方の言語で関連するコンテンツと無関係なコンテンツをより適切に区別できることがわかりました。","jina-embeddings-v3":"このモデルは、実世界のテストで優れた効率対パフォーマンス比を実証し、英語タスクではオープンソースの代替案や OpenAI や Cohere の独自ソリューションを上回っていると同時に、多言語シナリオでも良好なパフォーマンスを示しています。最も驚くべきことに、12 倍のパラメータを使用する e5-mistral-7b-instruct よりも優れた結果が得られ、その優れた効率性が強調されます。 MTEB ベンチマーク評価では、すべてのタスクで平均スコア 65.52 を達成し、特に分類精度 (82.58) と文の類似性 (85.80) で優れたパフォーマンスを示しました。このモデルは言語間で一貫したパフォーマンスを維持し、多言語タスクで 64.44 のスコアを獲得しました。次元削減に MRL を使用すると、より低い次元でも強力なパフォーマンスが維持されます。たとえば、64 次元では、完全な 1024 次元と比較して 92% の検索パフォーマンスが維持されます。","jina-embeddings-v4":"Jina Embeddings V4は、複数のベンチマークカテゴリーで非常に競争力のあるパフォーマンスを達成しました。画像文書検索では、JinaVDRベンチマークで平均スコア72.19を達成しました。これはColPali-v1.2の64.50を上回ります。また、ViDoReベンチマークでは平均スコア84.11を達成しました。これはColPaliの83.90を上回ります。さらに、マルチベクターモードではViDoReのスコア90.17を達成しました。クロスモーダル検索では、CLIPベンチマークで84.11を達成しました。これはjina-clip-v2の81.12、nllb-clip-large-siglipの83.19を上回ります。テキスト検索タスクでは、MTEB-enで55.97、MMTEBで66.49を達成し、長文文書処理にも優れており、LongEmbedでは67.11を達成しました（前モデルの55.66を上回っています）。セマンティックテキスト類似性評価でも優れた性能を示し、英語STSタスクで85.89、多言語STSベンチマークで72.70のスコアを獲得しました。コード検索機能はCoIRベンチマークで71.59に達しましたが、voyage-code-3（77.33）などの専用モデルはこの分野でより高いスコアを獲得しています。クロスモーダルアライメント性能はOpenAI CLIPの0.15に対して0.71と向上し、マルチモーダルモデルにおけるモダリティギャップ問題に対処しています。視覚的に豊富なタスクでは、マルチベクター モードがシングルベクター モードよりも一貫して優れたパフォーマンスを発揮しますが、シングルベクター モードは標準的な検索シナリオで効率的なパフォーマンスを提供します。","jina-reranker-m0":"Jina-reranker-m0 は複数のベンチマークで素晴らしい結果を達成しました。テキスト間の再ランキングでは、BEIR ベンチマークで 58.95 NDCG-10 のスコアを達成し、jina-embeddings-v3 (55.81) や bge-reranker-v2-m3 (56.51) などの競合製品を上回りました。多言語コンテンツについては、18 言語をカバーする MIRACL ベンチマークで 66.75 NDCG-10 を達成しました。長い文書の MLDR ベンチマークでは、13 の言語で 59.83 NDCG-10 を達成しました。 CoIR ベンチマークでのコード検索では、63.55 NDCG-10 を達成し、競合製品をはるかに上回ります。しかし、このモデルは視覚的な文書検索において真価を発揮します。ViDoRe ベンチマークでは、印象的な 91.02 NDCG-5 スコアを達成し、視覚言語の組み合わせ推論をテストする Winoground では平均スコア 43.92 を達成し、他のモデルと比較してテキストと画像の関係を理解する能力が優れていることを示しています。","jina-reranker-v1-base-en":"合成ベンチマークでは、このモデルは主要な指標で良好なパフォーマンスを示し、ベースラインのベクトル検索と比較して、ヒット率で 8% の向上、平均相互ランキングで 33% の向上を達成しました。 BEIR ベンチマークでは、平均スコア 0.5588 を達成し、BGE (0.5032)、BCE (0.4969)、Cohere (0.5141) などの他の並べ替えツールを上回っています。 LoCo ベンチマークでのパフォーマンスは特に優れており、平均スコアは 0.873 で、ローカルの一貫性とコンテキストを意識したランキングの理解という点で競合他社を大きく上回っています。このモデルは、技術的な内容の評価では良好なパフォーマンスを示し、qasper_abstract タスクでは 0.996、政府報告書の分析では 0.962 のスコアを獲得しましたが、会議の抽象タスクでは比較的低いパフォーマンス (0.466) でした。","jina-reranker-v1-tiny-en":"包括的なベンチマーク評価では、このモデルは優れた機能を実証し、従来のサイズとパフォーマンスのトレードオフに挑戦します。 BEIR ベンチマークでは、このモデルは NDCG-10 スコア 48.54 を達成し、サイズはわずか 4 分の 1 でありながら、ベース モデルのパフォーマンスの 92.5% を維持しました。さらに驚くべきことに、LlamaIndex RAG ベンチマークでは、ドキュメントの処理速度が大幅に向上しながら、ヒット率 83.16% を維持し、より大きなモデルとほぼ一致しました。このモデルは特にスループットの点で優れており、ベース モデルよりほぼ 5 倍高速にドキュメントを処理しながら、ターボ バージョンよりも 13% 少ないメモリ使用量を実現します。これらのメトリクスは、mxbai-rerank-base-v1 (1 億 8,400 万パラメーター) や bge-reranker-base (2 億 7,800 万パラメーター) などのより大規模なモデルと同等またはそれを超える実際のパフォーマンスに変換されます。","jina-reranker-v1-turbo-en":"合成ベンチマークでは、ターボ バージョンは精度が大幅に低下することなく、優れた効率を示しました。 BEIR ベンチマークでは、NDCC-10 スコア 49.60 を達成し、基本モデル (52.45) のパフォーマンスの 95% を維持しながら、bge-reranker-base (47.89、2 億 7800 万パラメーター) などの多くのより大きな競合他社を上回りました。 RAG アプリケーションでは、83.51% という驚異的なヒット率と 0.6498 MRR を維持し、実際の検索タスクで特に利点を示しています。このモデルの速度向上はさらに顕著で、基本モデルよりも 3 倍速くドキュメントを処理し、パラメーターの数が減少するにつれてスループットがほぼ直線的に増加します。ただし、ユーザーは、大規模なモデルのパラメーターの全数がわずかな利点しか提供しない、非常にきめの細かいランキング タスクではパフォーマンスがわずかに低下することに注意する必要があります。","jina-reranker-v2-base-multilingual":"実際の評価では、モデルはさまざまなベンチマークで良好なパフォーマンスを示しました。 RAG システムの AirBench リーダーボードで最先端のパフォーマンスを実現し、26 言語をカバーする MKQA データセットを含む多言語タスクで優れています。このモデルは構造化データ タスクで特に優れており、関数呼び出し (ToolBench ベンチマーク) と SQL パターン マッチング (NSText2SQL ベンチマーク) の両方で高い再現率を達成しています。最も印象的なのは、bge-reranker-v2-m3 などの同等のモデルよりも最大 15 倍高速にドキュメントを処理しながらこれらの結果を提供し、リアルタイム アプリケーションに適していることです。ただし、最適なパフォーマンスを得るには推論用の CUDA 対応 GPU が必要であることに注意してください。","reader-lm-05b":"実際のテストでは、Reader LM 0.5B は複数の指標にわたって優れた効率対パフォーマンス比を実証しました。このモデルは、ROUGE-L スコア 0.56 を達成し、コンテンツが良好に保存されていることを示し、トークン エラー率 0.34 を維持し、最小限のアーティファクトを示しました。多言語のニュース記事、ブログ投稿、電子商取引ページを含む 22 の異なる HTML ソースの定性的評価において、構造の保持とマークダウン構文の使用に関して良好なパフォーマンスを示しました。このモデルは、インライン CSS とスクリプトが数十万のトークンに拡張できる、複雑な最新の Web ページの処理に優れています。従来のルールベースのアプローチでは失敗することがよくあります。ただし、このモデルは単純な HTML からマークダウンへの変換タスクでは非常にうまく機能しますが、非常に動的なページや JavaScript を多用するページでは追加の処理が必要になる場合があることに注意することが重要です。","reader-lm-15b":"包括的なベンチマーク評価において、Reader LM 1.5B は業界標準に挑戦する能力を実証しました。このモデルの ROUGE-L スコアは 0.72、トークン エラー率は 0.19 で、GPT-4 (0.43 ROUGE-L、0.50 TER) や Gemini-1.5-Pro (0.42 ROUGE-L、0.50 TER) よりも大幅に優れています。 TER) HTML から Markdown への変換タスクでは 0.48 TER) およびその他の大規模なモデル。そのパフォーマンスは、タイトル抽出、メインコンテンツ抽出、豊富な構造の保存、マークダウン構文の使用という 4 つの主要な側面の定性的評価において際立っています。このモデルは、ニュース記事やブログ投稿からランディング ページやフォーラム投稿に至るまで、さまざまな種類のドキュメントにわたって一貫して高い精度を維持し、英語、ドイツ語、日本語、中国語などの複数の言語をサポートしています。このパフォーマンスは、長さが 256K までのトークンを含むドキュメントを処理する場合に、大規模なモデルで通常必要とされる高価なチャンク操作を行わずに達成されます。",title:"パフォーマンス"},performance_metrics:"パフォーマンス指標",publications:"出版物",tags:"ラベル",token_length:"単語の長さを入力してください",usage_requirements:"用途と要件",using_model:"以下の方法で入手できます"},select_model:"リストからモデルを選択して詳細を表示します",sort:{direction:{asc:"昇順",desc:"降順",name:"方向"},label:"タイプ",name:"名前",parameter_size:"サイズ",release_date:"日付"},title:"{_modelName} - 基本モデルの検索",warnings:{deprecated:"このモデルは、新しいモデルでは非推奨になりました。"}},ae={back_to_newsroom:"ニュースホームページに戻る",categories:"カテゴリー",copy_link:"このセクションへのリンクをコピーします",in_this_article:"記事ナビゲーション",learn_more:"もっと詳しく知る",news_not_found:"おっとっと！記事が見つかりませんでした",redirect_to_news:"5 秒後にニュースのホームページにリダイレクトされます..."},ie={academic:"アカデミック",academic_research:"学術論文",author:"著者でフィルタリングする",description:"Jina AI の最新ニュースとアップデートをお読みください。",description1:"AI テクノロジーのイノベーションについて一言一句書きます。",engineering_group:"エンジニアリングチーム",engineering_group_date:"2021年5月31日",minutes_read:"読む時間",most_recent_articles:"最新記事",news_description:"Jina 2.0 では、コミュニティの声に耳を傾けました。確かに、深く聞いてしまいました。 「あなたの課題は何ですか?」と尋ね、貴重なフィードバックをお待ちしています。",news_title:"すべてのコンテンツを検索: Jina 2.0 の MEME コンテストを開催しています。",photos:"写真",product:"製品でフィルタリングする",search:"タイトルから探す",tech_blog:"技術記事",title:"ニュース",top_stories:"記事を選択する"},te="🎉 私たちの最初の本『Neural Search – From Prototype to Production with Jina』が本日正式にリリースされました!",re={description:"Jina AI 内部への独占アクセス。",engage:"私たちは、一日を通して双方向の会話を強く推奨します。アイデアや視点の交換は私たちにとって非常に貴重です。これらの議論から生まれる潜在的な協力は、より統合された革新的な未来に大きく貢献する可能性があります。",engage_title:"ブレーンストーミング",experience:"ゲスト向けに、ドイツ語、英語、フランス語、スペイン語、中国語、ロシア語でご利用いただける 3 時間の没入型ツアーを企画しました。このツアーでは、マルチモーダル AI における当社の進歩と人工知能分野に関する当社の見解を詳しく説明し、その後、特定のプロジェクトの詳細なレビューを提供します。最後にグループディスカッションを行い、アイデアや洞察の交換を促進します。リクエストに応じてランチのオプションも利用できます。",experience_title:"インサイダーズツアー",group_size:"推定来場者数",impact:"オープンソース コミュニティへの貢献とマルチモーダル AI テクノロジーへの取り組みにより、Jina AI が人工知能イノベーションにおいてどのように影響力のあるプレーヤーになったかをご覧ください。私たちの目標は、意思決定において重要な役割を果たし、AI テクノロジーの進歩がすべての人に利益をもたらすようにすることです。",impact_title:"業界への影響",introduction:"Jina AI は、人工知能の将来に関心のある機関に門戸を開くことを嬉しく思います。私たちは、政治、NGO、非営利、投資部門の人々に公開日を提供しています。弊社の運営、ビジョン、業界の洞察について知るために、ぜひベルリン本社を訪問してください。",motivation_min_length_v1:"詳しい動機を教えてください。",motivation_placeholder_v2:"あなたのモチベーションを共有していただくと、あなたのエクスペリエンスを向上させることができます。",motivation_to_attend_v2:"なぜ私たちのオープンデーに興味を持ったのですか？",one_hour:"1時間",organization:"機構",organization_website:"機関のウェブサイト",organization_website_placeholder:"組織のホームページまたは LinkedIn プロフィールの URL",preferred_date:"希望日",preferred_language:"優先言語",preferred_products:"どのような製品に興味がありますか?",subtitle:"マルチモーダル AI の未来を垣間見る",title:"オープンデー",tutor_subtitle:"この慎重に厳選された 3 時間のツアーでは、Jina AI のマルチモーダル AI テクノロジーにおける先駆的な取り組みの核心に迫ることができます。",tutor_title:"独占的な徹底したディスカッション",vision:"私たちが考える人工知能の未来について包括的に見てみましょう。私たちの議論は、大規模な言語モデル、マルチモーダル AI の可能性、そして世界的なイノベーションの未来を形作る上でのオープンソース テクノロジーの影響に焦点を当てます。",vision_title:"将来のビジョン"},se={answer1:"ドイツ語、英語、フランス語、スペイン語、中国語、ロシア語でのガイド付きツアーを提供しています。",answer2:"講義は通常約 3 時間かかります。",answer3:"ランチはオプションで、リクエストに応じて手配可能です。",answer4:"私たちの公開日は主に、政治家、NGO、非営利団体、投資家などの専門家グループを対象に設計されています。ただし、個人のプロフィールに基づいて例外を設ける場合があります。",answer5:"あらゆる規模のグループに対応できます。登録フォームにグループの人数をご記入ください。詳細を確認させていただきます。",answer6:"登録フォームには、興味のある分野や特別な要件を指定できるセクションがあります。お客様のニーズに合わせて旅程を調整できるよう最善を尽くします。",answer7:"現在、ベルリンのクロイツベルク本社でのみオープンデーを提供しています。北京および深センのオフィスは現在ツアーを停止しています。",question1:"ツアーサービスは何語で提供されますか?",question2:"講義時間はどれくらいですか？",question3:"昼食は提供されますか?",question4:"個人でもオープンデーに登録できますか?",question5:"オープンデーには何人までグループに参加できますか?",question6:"チュートリアルの対象分野を指定するにはどうすればよいですか?",question7:"北京または深センのオフィスには営業日がありますか?"},oe={description:"オープンソース、クラウドネイティブの大規模マルチモーダル モデル サービス フレームワーク"},_e={commercial_licence:{chip_label:"中小企業向けに設計",company_size_note:"従業員が 50 人未満、または収益が 500,000 ドル未満の企業のみ",cta_button:"今すぐ始めましょう",download_title:"商用ライセンスをダウンロード",feature_api_desc:"購入前にテストしてください",feature_api_title:"無料の API テスト アクセス",feature_consulting:"当社のモデル専門家による 2 時間のコンサルティング",feature_consulting_desc:"ライセンス期間ごとに 2 時間の技術コンサルティング サービス。",feature_future_support:"将来の CC BY-NC モデルに許可なくアクセスする",feature_future_support_desc:"ライセンス期間中に CC-BY-NC-4.0 に基づいてライセンサーによってリリースされた新しいモデル。",feature_models:"CC BY-NC モデルによる無制限の商用利用",feature_models_desc:"内部使用や顧客向けアプリケーションへの組み込みなど、ビジネス目的でモデルを使用します。",price_amount:"1,000ドル",price_period:"/ 四半期ごと",read_the_terms:"ライセンス条項を表示する",read_the_terms_btn:"条項",read_the_terms_desc:"購入前に商用ライセンスの権利と制限を確認してください",subtitle:"より良い検索に必要なすべてのモデル",test_before_purchase:"購入する前にお試しください",test_before_purchase_desc:"1,000万の無料APIトークンを取得するか、Hugging Faceモデルを使用してパフォーマンスを検証してください",title:"チームライセンス",try_api:"まずはAPIを試してみる"},consulting_us:"1時間の技術相談",consulting_us_description:"弊社のエンジニアにご相談ください。弊社の API をお客様のシステムに実装するためのベスト プラクティスについて専門家のアドバイスが得られます。",full_commercial:"無制限の商用利用",full_commercial_description:"API は商用目的で制限なく使用できます。",higher_limit:"より高い調整可能なレート制限",higher_limit_description:"レート制限のセクションに詳細が記載されています。",key_manager:"基本的な鍵管理",key_manager_description:"1 つのアカウントで複数の API キーを管理し、使用履歴を追跡し、トークンを補充します。",no_commercial:"非商用目的のみ使用可能 (CC-BY-NC)。",no_commercial_description:"この API は非営利目的でのみ使用できます。商用利用の場合は、API キープランをご購入ください。",on_prem:"ローカルで使用するための商用ライセンスを持っている",on_prem_explain:"現場で当社のモデルを使用するには、商用ライセンスを購入してください。",premium_key:"アドバンストキーにはより高いレート制限があります",premium_key_description:"より高いレート制限を取得し、高度な機能を使用するには、レート制限の表で詳細を確認してください。",premium_key_manager:"高度な鍵管理",premium_key_manager_description:"自動リマインダー、元に戻す、トークン転送などの基本機能と高度な機能。",premium_support:"24時間プレミアムカスタマーサポート",premium_support_description:"ご質問には24時間以内に回答することを保証します。",priority_support:"テクニカルサポート",priority_support_description:"技術的な問題やインシデントが発生した場合、72 時間以内に電子メールで応答することを保証します。",secured_by_stripe:"Stripe で安全に支払い",standard_key:"標準キー",standard_key_description:"標準のレート制限ですべての Jina 検索ベース API にアクセスします。",via_api:"Jinaを使用した検索ベースAPI",via_api_explain:"すべての製品にアクセスする最も簡単な方法。いつでもトークンをリチャージできます。"},de="に基づく",le="印刷する",ce={archived:"アーカイブ済み",cloud_native:"クラウドネイティブ",core:"草の根コア",data_structure:"データ構造",embedding_serving:"大規模なモデル ベクトルの展開",embedding_tuning:"大規模モデルのベクトル調整",graduated:"卒業",incubating:"孵化中",kubernetes:"Kubernetes",large_size_model:"大型モデル",linux_foundation:"Linux財団",llm1:"LLM フレームワーク",mid_size_model:"ミディアムモデル",model_serving:"モデルの展開",model_tuning:"モデルのチューニング",observability:"可観測性",orchestration:"クラウドオーケストレーション",prompt_serving:"プロンプトワード展開",prompt_tuning:"即時単語チューニング",rag1:"RAGアプリケーション",sandbox:"サンドボックス",small_size_model:"小型モデル",vector_database:"ベクトルデータベース",vector_store:"ベクトルデータベース"},pe={description:"プレミアプロンプトワードツールボックス",image_model:"画像モデル",intro:"プレミアプロンプトワードツールボックス",intro1:"プロンプトワードエンジニアリングのための最高のツール",optimized:"あなたの役割は、私のブレーンストーミングのパートナーとなり、特定のトピックや問題に対して創造的なアイデアや提案を提供することです。回答には、問題を解決したり、興味深い方法でトピックをさらに探求したりするのに役立つ、独創的でユニークな関連性の高いアイデアが含まれている必要があります。回答では、タスクの特定の要件や制限も考慮する必要があることに注意してください。",optimized_title:"最適化されたプロンプトワード",original:"あなたの役割は、私のブレインストーミングパートナーになることです。",original_title:"元のプロンプトワード",text_model:"テキストモデル"},ue={features:[{description:"コンテンツの生成とプロンプトワードの最適化を簡単に切り替えて、コンテンツの品質を次のレベルに引き上げます。",name:"スマートアシスタント",title:"毎日の生産性向上。"},{description:"効果的なプロンプトワードの書き方がわかりませんか?考えを入力するだけで、マウスをクリックするだけでより適切な言葉が得られます。",name:"プロンプトワードの最適化",title:"より良いインプット、より良いアウトプット"},{description:"同じプロンプト単語に対する出力を比較することで、各 AI モデルの個性を理解します。",name:"模型コンテスト",title:"モデルを並べて比較。"},{description:"これはおそらく、プロンプト ワードを API として展開する最も簡単な方法です。",name:"導入プロンプトの単語",title:"面倒な Ops に別れを告げて、直接デプロイします。"},{description:"独自の大規模エージェントをカスタマイズし、マルチエージェント シミュレーションを起動します。目標を達成するために仮想環境でどのように協力したり競争したりするかをご覧ください。",name:"マルチエージェント",title:"エージェントがどのように連携するかを確認する"}],get_started:"PromptPerfect を使ってみる"},me={api_key:"リチャージAPIキー",free_key:"無料のAPIキー",generation:"API キーの準備ができました。",generation_caption:"API キーが生成され、{_purchasedTime} に使用できるようになりました。",success:"ご購入いただきありがとうございます！",success_caption:"ご注文は{_purchasedTime}に完了しました。 API キーが再チャージされ、使用できるようになりました。トークン残高が更新されていない場合は、ページを更新してください。"},ge="即購入",be={batch_explain:"この API はバッチ操作をサポートしており、リクエストごとに最大 512 個のドキュメントを許可し、ドキュメントごとに最大 8192 個のトークンを使用できます。バッチ操作を賢く使用すると、リクエストの数が大幅に削減され、パフォーマンスが向上します。",classifier:"トレーニング サンプルを使用して分類器をトレーニングする",classifier_few_shot:"トレーニングされた少数ショット分類器を使用して入力を分類する",classifier_few_shot_token_counting:"トークン数: 入力トークン",classifier_latency:"応答時間は入力サイズによって異なります",classifier_token_counting:"単語数は、入力単語×反復回数で表されます。",classifier_zero_shot:"ゼロショット分類を使用して入力を分類する",classifier_zero_shot_token_counting:"単語数は、入力単語とタグ単語の合計です。",deepsearch:"推論し、検索し、繰り返して最善の答えを見つける",depends:"入力サイズに依存",description:"説明する",embeddings:"テキスト/画像を固定長ベクトルに変換する",endpoint:"APIポート",explain:"レート制限は、<b>RPM</b> (1 分あたりのリクエスト数) と <b>TPM</b> (1 分あたりの単語数) の 3 つの方法で追跡されます。制限は IP/API キーごとに適用され、RPM または TPM のしきい値に最初に達したときにトリガーされます。リクエスト ヘッダーに API キーを指定すると、IP アドレスではなくキーによってレート制限が追跡されます。",flat_rate_per_request:"各リクエストには、{_number} トークンから始まる固定数のトークンが必要です。",further_boost:"足りない？より高いレート制限を取得するには、お問い合わせください。",gjinaai:"ネットワークの知識を利用して発言を裏付ける",icon:"アイコン",input_token_counting:"入力リクエスト内のトークンの数に基づきます。",key_explain:"「シルバー」トークンパックを購入すると、このティアの有料APIキーが手に入ります。",latency:"平均遅延",llm_serp:"LLM を使用した検索エンジン結果ページの生成",no_key_explain:"API キーなしで API を使用する場合、「ユーザー」という概念がないため、IP アドレスごとにレート制限が行われます。共有環境で使用している場合は、レート制限に早く達する可能性があります。",no_token_counting:"トークンの使用量はカウントされません。",output_token_counting:"出力応答内のトークンの数に基づきます。",premium_key_explain:"このティアの有料APIキーを取得するには、「ゴールド」トークンパックを購入してください",premium_rate:"レート制限を増やすことが可能",product:"製品",requestType:"リクエストの種類",reranker:"クエリによるドキュメントの絞り込み",rjinaai:"URLをモデルに適した大きなテキストに変換する",search:"検索",sjinaai:"ウェブを検索し、結果をモデルに適した大きなテキストに変換します",tbd:"未定",title:"レート制限",tokenCounting:"単語の使用数",tokenizer:"長いテキストを単語や文に分割する",total_token_counting:"プロセス全体のトークンの総数をカウントします。",understanding:"レート制限について学ぶ",understanding_description:"レート制限とは、1 分間に IP アドレス/API キー (RPM) ごとに API に対して実行できるリクエストの最大数です。各製品およびティアのレート制限の詳細については、以下をご覧ください。",wAPIkey:"APIキーを使用する",wPremium:"プレミアムAPIキー付属",woAPIkey:"APIキーがありません"},Ae={decision:"決める",description:"LLM 支援のインテリジェントな意思決定ツール",intro:"コインの両面を見て合理的な意思決定を行う"},he={beta:"実験",better_input:"最初から入力品質を向上させる",better_input_description:"Agent または RAG システムの出力に問題がありますか?これは入力品質が低いことが原因である可能性があります。",check_price_table:"価格表を見る",copy:"コピー",demo:{advanced_parameter_explain:"このエンドポイント専用の特定のパラメータ。",advanced_parameters:"特定の",advanced_usage:"高度な使用法",ask_llm:"大きなモデルを探す必要があるかどうかを尋ねる",ask_llm_directly:"LLMに直接質問してください",ask_llm_with_search_grounding:"検索経由で LLM に問い合わせる",ask_question:"質問する",ask_question_hint:"質問を入力し、取得した大規模モデルコンテンツと組み合わせて回答を生成します",basic_usage:"基本的な使い方",basic_usage1:"<code>r.jina.ai</code> を使用して URL を読み取り、その内容を取得します。",basic_usage2:"<code>s.jina.ai</code> でウェブを検索し、SERP を取得します",basic_usage3:"確認して話し合う",common_parameter_explain:"{_product1}、{_product2}、および {_product3} で使用できる共通パラメータ。",common_parameters:"共通パラメータ",content_length:"コンテンツの長さ（バイト）",copy:"コピー",fetch:"コンテンツを取得する",get_response:"応答を取得する",grounding_result_false:"これは間違いです。",grounding_result_true:"この発言は正しいです。",headers:{atx:"代替タイトル構文",atx_explain:"タイトルを作成するには、テキストの下の行に任意の数の「==」または「--」文字を使用します。",auth_token:"レート制限を高めるには API キーを追加します",auth_token_explain:"より高いレート制限にアクセスするには、Jina API キーを入力してください。最新のレート制限情報については、以下の表を参照してください。",auto:"車",auto_explain:"URL に最適なエンジンを自動的に選択します。",base:"リダイレクトページに従う",base_explain:"すべてのリダイレクトをたどった後、最終的な宛先 URL に解決するかどうかを選択します。完全なリダイレクト チェーンを追跡できるようにします。",browser:"品質第一",browser_explain:"高品質のエンジンは、レンダリングの問題を解決し、最高のコンテンツ出力を提供するように設計されています。",browser_locale:"ブラウザのロケールをカスタマイズする",browser_locale_explain:"ページをレンダリングするためのブラウザーのロケール設定を制御します。多くの Web サイトは、ロケール設定に基づいて異なるコンテンツを提供します。",cf_browser:"実験的なブラウザ",cf_browser_explain:"私たちは、JavaScript を多用するサイトを処理できる高速エンジンを実験しています。実稼働環境での使用は推奨されません。動作が変更になる場合があります。",country:"@:llm_serp.parameters.country",country_explain:"@:llm_serp.parameters.country_explain",custom_script:"JavaScript の事前実行",custom_script_explain:"前処理された JS コード (インライン文字列またはリモート URL) を実行します。",deepdive:"ソースコードの詳細な分析",deepdive_explain:"徹底的な事実確認のために、さらに多くの情報源を検索し、文書全体をお読みください。少し遅いですが、より正確で、参照も多くなります。",default:"デフォルト",default_explain:"ほとんどのサイトと大規模なモデル入力向けに最適化されたデフォルトのパイプライン。",direct:"スピード第一",direct_explain:"最も高速なエンジンで、速度が最適化されていますが、JavaScript によって生成された動的コンテンツを処理することはできません。",discarded_explain:"リンクはアンカー テキストに置き換えられます。",dnt:"キャッシュ/トラックしないでください。",dnt_explain:"有効にすると、リクエストの結果はサーバー上にキャッシュされません。",engine:"読み取りエンジン",engine_default:"デフォルト",engine_default_explain:"最も互換性の高いエンジンは、品質と速度のバランスが良好です。",engine_default_html:"デフォルトで生のHTMLレスポンスを使用する",engine_default_html_explain:"デフォルトのエンジンには HTML 応答があり、マークダウン変換は必要ありません。",engine_default_markdown:"デフォルトでは読みやすさフィルターなし",engine_default_markdown_explain:"Markdown 応答のデフォルト エンジンには、読みやすさのフィルタリング (ヘッダー、フッターなどの削除) はありません。",engine_default_timeout:"デフォルトだがタイムアウトが設定されている",engine_default_timeout_explain:"デフォルトのエンジンですが、最大タイムアウトは 5 秒です。",engine_explain:"Web コンテンツを取得するために使用するブラウザ エンジンを選択します。これは、コンテンツの品質、速度、完全性、アクセシビリティに影響します。",eu_compliance:"EU規制に準拠",eu_compliance_explain:"すべてのインフラストラクチャとデータ処理操作は完全に EU の管轄下にあります。",file:"ローカル PDF/HTML ファイル",file_explain:"ローカルの PDF および HTML ファイルをアップロードして、リーダーを使用して読み取ります。 pdf および html ファイルのみがサポートされます。",html:"HTML",html_explain:"documentElement.outerHTML を返します。",image_caption:"説明する",image_caption_explain:"指定された URL にあるすべての画像にキャプションを追加し、キャプションのない画像には alt タグとして「Image [idx]: [caption]」を追加します。これにより、大規模な下流モデルは推論や要約などのアクティビティ中に画像を操作できるようになります。",images_summary:"最後にすべての写真を集める",images_summary_all:"全て",images_summary_all_explain:"すべての画像は記事の最後にリストされています。",images_summary_explain:"最後に、「写真」セクションが作成されます。これにより、下流の大規模モデルはページ上のすべてのビジュアルを概観できるようになり、推論機能が向上します。",images_summary_no:"なし",images_summary_no_explain:"画像はインラインのままです。",images_summary_true:"重複排除",images_summary_true_explain:"重複排除された画像は記事の最後にリストされています。",inlined_explain:"リンクはテキスト内に直接埋め込まれます。",instruction_explain:"指示に従って情報を抽出する",invalid_json:"JSON 形式エラー",json_response:"JSON応答",json_response_explain:"応答は JSON 形式で、URL、ヘッダー、コンテンツ、およびタイムスタンプ (利用可能な場合) が含まれます。検索モードでは、記述された JSON 構造にそれぞれ従う 5 つのエントリのリストが返されます。",json_schema_explain:"JSON スキーマを使用した HTML から JSON への抽出",language:"@:llm_serp.parameters.language",language_explain:"@:llm_serp.parameters.language_explain",links_summary:"すべてのリンクを最後までグループ化する",links_summary_all:"全て",links_summary_all_explain:"すべてのリンクは記事の最後に記載されています。",links_summary_explain:"最後に、「ボタンとリンク」セクションが作成されます。これにより、下流の大規模モデルや Web エージェントがページを参照したり、さらにアクションを実行したりできるようになります。",links_summary_no:"なし",links_summary_no_explain:"リンクはインラインのままです。",links_summary_true:"重複排除",links_summary_true_explain:"重複排除されたリンクは記事の最後にリストされます。",location:"@:llm_serp.parameters.location",location_explain:"@:llm_serp.parameters.location_explain",markdown:"マークダウン",markdown_explain:"可読性フィルタリングをバイパスして、HTML から直接マークダウンを返します。",md:{bullet_list_marker:"箇条書きスタイル",bullet_list_marker_explain:"箇条書きリストのマーク文字を設定します (Turndown に渡されます)。",em_delimiter:"スタイルを重視",em_delimiter_explain:"マークダウン強調区切り文字を定義します (Turndown に渡されます)。",heading_style:"見出しスタイル",heading_style_explain:"マークダウンのタイトル形式を設定します (Turndown に渡されます)。",hr:"水平線スタイル",hr_explain:"マークダウンの水平罫線形式を定義します (Turndown に渡されます)。",link_reference_style:"参照リンクスタイル",link_reference_style_explain:"マークダウン参照リンク形式を設定します (Turndown に渡されます)。",link_style:"リンクスタイル",link_style_explain:"マークダウン リンク形式を決定します (Turndown に渡されます)。",strong_delimiter:"スタイルを重視",strong_delimiter_explain:"マークダウンの強い強調区切り文字を設定します (Turndown に渡されます)。"},md_link_discarded:"プレーンテキスト",md_link_inline:"列をなして",md_link_referenced:"参考文献",mode:"読み取りまたは検索モード",mode_explain:"読み取りモードは URL のコンテンツにアクセスするために使用され、検索モードを使用すると、Web 上でクエリを検索し、各検索結果の URL に読み取りモードを適用できます。",no_cache:"キャッシュのバイパス",no_cache_explain:"当社の API サーバーは、読み取りモードと検索モードのコンテンツを一定期間キャッシュします。このキャッシュをバイパスするには、このヘッダーを true に設定します。",no_gfm:"無効",no_gfm_explain:"GFM (Github Flavored Markdown) 機能は無効になっています。",no_gfm_table:"GFM テーブルがありません",no_gfm_table_explain:"GFM テーブルからオプトアウトしますが、テーブルの HTML 要素は応答として保持します。",number:"@:llm_serp.parameters.number",number_explain:"@:llm_serp.parameters.number_explain",opt_out_gfm:"Github スタイルのマークダウン",opt_out_gfm_explain:"GFM (Github Flavored Markdown) 機能のオプトイン/アウト。",page:"@:llm_serp.parameters.page",page_explain:"@:llm_serp.parameters.page_explain",pageshot:"ページのスナップショット",pageshot_explain:"ページ全体のスクリーンショットの画像 URL を返します (ベストエフォート)。",post_with_url:"POSTメソッドを使用する",post_with_url_explain:"GET メソッドの代わりに POST メソッドを使用し、本文に URL を渡します。ハッシュベースのルーティングを備えた SPA を構築する場合に役立ちます。",proxy:"国別のプロキシサーバーを使用する",proxy_explain:"ロケーションベースのプロキシ サーバーの国コードを設定します。最適な選択には「自動」を使用し、無効にするには「なし」を使用します。",proxy_server:"プロキシサーバーを使用する",proxy_server_explain:"API サーバーはプロキシを利用して URL にアクセスできます。これは、特定のプロキシ経由でのみアクセスできるページに役立ちます。",reader_url:"@:reader.demo.reader_url",referenced_explain:"リンクは記事の最後にリストされており、本文では番号で参照されます。",references:"参照",references_explain:"ユーザー指定の参照 (URL) のカンマ区切りリスト",remove_all_images:"すべての写真を削除",remove_all_images_explain:"応答からすべての画像を削除します。",remove_selector:"CSSセレクター: 除外",remove_selector_explain:"削除する要素の CSS セレクター (ヘッダー、フッターなど)。",respond_with:"ReaderLM-v2の使用",respond_with_explain:"ReaderLM-v2 を使用して HTML を Markdown に変換し、複雑な構造とコンテンツを持つ Web サイトに高品質の結果を提供します。他のエンジンよりも3倍多くのトークンを消費します!",result_count:"番号",result_count_explain:"返される結果の最大数を設定します。 num を使用すると遅延が発生し、特殊な結果タイプが除外される可能性があります。 1 ページあたりにさらに多くの結果を表示することが明示的に必要な場合を除き、これを無視してください。",return_format:"コンテンツ形式",return_format_explain:"過剰なフィルタリングを防ぐために、応答の詳細レベルを制御できます。デフォルトのパイプラインは、ほとんどのサイトと大規模なモデル入力に対して最適化されています。",robot_txt:"ロボットポリシーを厳守する",robot_txt_explain:"コンテンツを取得する前に robots.txt と照合されるロボットの User-Agent を定義します。",screenshot:"スクリーンショット",screenshot_explain:"最初の画面の画像 URL を返します。",search_engine:"検索エンジン",search_engine_explain:"検索に使用するエンジンを選択します。結果の品質、速度、互換性に影響します。",search_result_mode:"SERPの全コンテンツを読む",search_result_mode_explain:"検索結果の各 URL にアクセスし、リーダーを使用して完全なコンテンツを返します。切り替えて、リーダー固有のオプションを有効にします。",serp_type:"SERP コンテンツタイプ",serp_type_explain:"検索するコンテンツの種類。これは現在、非常に実験的な機能であり、請求方法の種類によって異なります。",set_cookie:"転送クッキー",set_cookie_explain:"弊社の API サーバーは、URL にアクセスするときにカスタム Cookie 設定を転送できます。これは、追加の認証が必要なページに役立ちます。 Cookie を含むリクエストはキャッシュされないことに注意してください。",setext:"番号記号タイトル",setext_explain:"タイトルを作成するには、単語またはフレーズの前に番号記号 (#) を使用します。",site_selector:"サイト検索",site_selector_explain:"指定された Web サイトまたはドメインの検索結果のみを返します。デフォルトでは、Web 全体を検索します。",stream_mode:"ストリーミングモード",stream_mode_explain:"ストリーミング モードでは、ターゲット ページを大きくすることが容易になり、ページが完全にレンダリングされるまでにより多くの時間を費やすことができます。標準モードでコンテンツが不完全になる場合は、ストリーミング モードの使用を検討してください。",target_selector:"CSSセレクター: のみ",target_selector_explain:"特定のページ要素をターゲットにするために使用される CSS セレクターのリスト。",text:"文章",text_explain:"document.body.innerText を返します。",token_budget:"トークンの予算",token_budget_explain:"このリクエストで使用されるトークンの最大数を制限します。この制限を超えると、リクエストは失敗します。",viewport:"ビューポートの構成",viewport_explain:"レスポンシブ レンダリング用のブラウザ ビューポート サイズを設定します。",vlm:"可変長モデル",vlm_explain:"リッチメディアや複雑なレイアウトを含む短いページに最適です。",wait_for_selector:"CSS セレクター: Wait-For",wait_for_selector_explain:"結果を返す前に待機する CSS セレクター。",with_favicon:"アイコンを取得",with_favicon_explain:"これにより、SERP 内の各 URL のアイコンが取得され、画像 URI として応答に含められるため、UI レンダリングに役立ちます。",with_gfm:"有効",with_gfm_explain:"GFM（Github Flavored Markdown）機能が有効になりました。",with_iframe:"iframe 抽出",with_iframe_explain:"DOM ツリー内のすべての iframe 埋め込みコンテンツを処理します。",with_shadow_dom:"シャドウDOM抽出",with_shadow_dom_explain:"ドキュメント内のすべての Shadow DOM ルートからコンテンツを抽出します。",x_timeout:"タイムアウト",x_timeout_explain:"最大ページ読み込み待機時間（合計リクエスト処理時間ではありません）。",your_query:"@:reader.demo.your_query"},how_to_stream:"コンテンツが利用可能になったときに処理するには、リクエスト ヘッダーをストリーミング モードに設定します。これにより、最初のバイトの受信にかかる時間が最小限に抑えられます。カールの例:",how_to_use1:"大規模モデルへのアクセスを必要とするコードまたはツール内の任意の URL に https://r.jina.ai/ を追加します。これにより、ページのメインコンテンツが、モックアップに適したクリーンなテキストで表示されます。",how_to_use2:"クエリに https://s.jina.ai/ を追加します。これにより、検索エンジンが呼び出され、その URL とコンテンツが返され、各結果が簡潔で大規模モデルに適したテキストで表示されます。",how_to_use3:"https://g.jina.ai/ をステートメントに追加します。これにより、意思決定エンジンが呼び出され、真実のパーセンテージ、ステートメントが真か偽かを示すブール値、理由の概要、および参照リストが返されます。",key_required:"このエンドポイントを使用するには API キーが必要です",learn_more:"もっと詳しく知る",open:"新しいタブで開く",params_classification:"パラメータ",performance_compare:"パフォーマンス比較",raw_html:"生のHTML",reader_output:"リーダー出力",reader_response:"読者の反応",reader_search_hint:"コードでこの URL を使用する場合は、URL をエンコードすることを忘れないでください。",reader_url:"リーダーの URL",reader_url_hint:"リーダー API 経由でコンテンツを取得するには、以下をクリックしてください",requires_post_method:"この機能には POST メソッドが必要です。ローカル ファイルをアップロードすると、POST メソッドが自動的に有効になります。",response_time:"応答時間（ミリ秒）",search_params:"検索パラメータ",search_query_rewrite:"上記のデモンストレーションとは異なり、実際には、根拠を得るために元の質問を Web で検索する必要はないことに注意してください。よく行われるのは、元の問題を書き直したり、マルチホップの問題を使用したりすることです。検索結果を読み取り、最終的な回答に到達する前に、必要に応じて追加のクエリを生成してさらに情報を収集します。",select_mode:"モード選択",show_read_demo:"Reader が URL を読み取る方法を学ぶ",show_search_demo:"読者がネットワークをどのように検索するかを理解する",slow_warning:"これには最大 30 秒かかる場合があり、リクエストごとに最大 300K のトークンが必要になります。",standard_usage:"標準的な使用方法",stream_mode:"ストリーミングモード",stream_mode_explain:"ストリーミング モードは、ターゲット ページが大きすぎてレンダリングできない場合に便利です。標準モードで提供される機能が不完全であると思われる場合は、ストリーミング モードを試してください。",stream_mode_explain1:"ストリーミング モードは、標準モードでは不完全な結果が得られることがわかった場合に便利です。これは、ストリーミング モードでは、ページが完全にレンダリングされるまで待機する時間が長くなるためです。 accept-header を使用してストリーミング モードを切り替えます。",tagline:"デモを試してみる",try_demo:"デモ",use_headers:"リクエスト ヘッダーを使用して、Reader API の動作を制御できます。以下は、サポートされているヘッダーの完全なリストです。",waiting_for_reader:"まず Reader API の結果を待ちます...",warn_grounding_message:"このプロセスには最大 30 秒かかり、クエリ リクエストごとに最大 300K のトークンが消費されます。一部のブラウザーでは長時間の遅延によりリクエストが終了する場合があるため、コードをコピーしてターミナルから実行することをお勧めします。",warn_grounding_title:"高いレイテンシとトークン使用量",your_query:"クエリを入力してください",your_query_hint:"最新の情報や世界の知識が必要な質問を入力してください。",your_statement:"あなたの事実確認声明",your_url:"URLを入力してください",your_url_hint:"ページのソースコードに直接アクセスするには、以下をクリックしてください"},description:"URL を読み取ったり検索したりすると、大規模なモデルのサポートが向上します。",dont_panic_api_key_is_free:"慌てないで！新しい API キーごとに 1,000 万個の無料トークンが含まれます。",engine_speed_test:"読み取り速度テスト",faq_v1:{answer1:"Reader API は無料であり、API キーは必要ありません。 URL の前に「https://r.jina.ai/」を追加するだけです。",answer10:"いいえ、Reader API は、公的にアクセス可能な URL からのコンテンツのみを処理できます。",answer11:"5 分以内に同じ URL をリクエストすると、Reader API はキャッシュされたコンテンツを返します。",answer12:"残念だけど違う。",answer13:"はい、リーダーでネイティブ PDF サポート (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) を使用するか、arXiv で HTML バージョン (https:// r. jina.ai/https://arxiv.org/html/2310.19923v4)",answer14:"リーダーは指定された URL にあるすべての画像にキャプションを追加し、最初に何もなかった場合は `Image [idx]: [caption]` を alt タグとして追加します。これにより、大規模な下流モデルが推論や要約などのために画像と対話できるようになります。",answer15:"Reader API は、高度に拡張できるように設計されています。リアルタイムのトラフィックに基づいて自動的に拡張され、同時リクエストの最大数は約 4,000 になりました。当社は、Jina AI のコア製品の 1 つとして積極的に維持しています。したがって、本番環境で自由に使用してください。",answer16:"最新のレート制限情報は以下の表で確認してください。私たちは Reader API のレート制限とパフォーマンスの改善に積極的に取り組んでおり、それに応じてこの表も更新されることに注意してください。",answer17:"Reader-LM は、オープン Web からデータを抽出してクリーニングするために設計された新しい小型言語モデル (SLM) です。 Jina Reader からインスピレーションを得て、生のノイズの多い HTML をクリーンなマークダウンに変換します。費用対効果と小型モデルサイズに重点を置いた Reader-LM は、実用的かつ強力です。現在、AWS、Azure、GCP マーケットプレイスで入手できます。特定の要件がある場合は、セールス AT jina.ai までお問い合わせください。",answer2:"Reader API は、プロキシを使用して URL を取得し、そのコンテンツをブラウザーでレンダリングして、高品質のプライマリ コンテンツを抽出します。",answer3:"はい、リーダー API はオープンソースであり、Jina AI GitHub リポジトリにあります。",answer4:"Reader API は通常、URL を処理して 2 秒以内にコンテンツを返しますが、複雑なページや動的なページの場合はさらに時間がかかる場合があります。",answer5:"特に複雑なページや動的なページの場合、スクレイピングは複雑で信頼性が低くなる可能性があります。リーダー API は、簡潔で信頼性が高く、簡潔な、クリーンで大規模なモデル レベルのテキスト出力を提供します。",answer6:"Reader API は、URL のコンテンツを元の言語で返します。翻訳サービスは提供しておりません。",answer7:"ブロックの問題が発生した場合は、サポート チームに問い合わせて解決策を求めてください。",answer8:"Reader API は主に Web ページを対象としており、arXiv などのサイトで HTML で表示される PDF からコンテンツを抽出できますが、一般的な PDF 抽出には最適化されていません。",answer9:"現在、リーダー API はメディア コンテンツを処理しませんが、将来的には画像のキャプションやビデオの概要などの機能強化が行われる予定です。",question1:"Reader API の使用に関連するコストはいくらですか?",question10:"ローカル HTML ファイルで Reader API を使用することはできますか?",question11:"Reader API はコンテンツをキャッシュしますか?",question12:"ログイン後に Reader API を使用してコンテンツにアクセスできますか?",question13:"Reader API を使用して arXiv 上の PDF にアクセスできますか?",question14:"画像の注釈はリーダーでどのように機能しますか?",question15:"リーダーの拡張性はどの程度ですか?これを本番環境で使用できますか?",question16:"Reader API のレート制限は何ですか?",question17:"Reader-LMとは何ですか?使い方は？",question2:"Reader API はどのように機能しますか?",question3:"リーダー API はオープンソースですか?",question4:"Reader API の一般的なレイテンシはどれくらいですか?",question5:"自分でページをスクレイピングする代わりに Reader API を使用する必要があるのはなぜですか?",question6:"Reader API は複数の言語をサポートしていますか?",question7:"Web サイトが Reader API をブロックした場合はどうすればよいですか?",question8:"Reader API は PDF ファイルからコンテンツを抽出できますか?",question9:"Reader API は Web ページのメディア コンテンツを処理できますか?",title:"リーダーに関するよくある質問"},fast:"素早く",fast_stream:"リアルタイムのデータフロー",fast_stream_description:"データをすぐに取得する必要がありますか?当社のリーダー API は、遅延を最小限に抑えるためにデータを転送できます。",free:"いつでも無料",free_description:"Reader API は無料です。クレジット カードや API パスワードは必要ありません。トークン クォータは消費されません。",is_free:"そしてそれは実際には無料です！",is_free_description:"Reader API は無料で使用でき、柔軟なレート制限と価格設定を提供します。高いアクセシビリティ、同時実行性、信頼性を備えたスケーラブルなインフラストラクチャ上に構築されています。当社は、大型モデルの基礎ソリューションとしてお客様に選ばれるよう努めています。",lm_v2_description:"ReaderLM-v2 は、HTML から Markdown への変換および HTML から JSON への抽出のために特別に設計された 1.5B パラメーター言語モデルです。 29 言語で最大 512,000 トークンのドキュメントをサポートし、以前のものよりも 20% 精度が向上しています。",lm_v2_title:"ReaderLM v2: HTML から Markdown および JSON までの小規模な言語モデル",open:"新しいタブで開く",original_pdf:"オリジナルPDF",rate_limit:"レート制限",read_grounding_release_note:"リリースノートを読む",reader_also_read_images:"Web 上の画像は、リーダーの視覚言語モデルを使用して自動的にキャプションが付けられ、出力では画像の alt タグとしてフォーマットされます。これにより、下流の大規模モデルがこれらの画像を推論および要約プロセスに組み込むための十分なヒントが提供されます。つまり、画像について質問したり、特定の画像を選択したり、さらに強力な VLM に URL を転送してより詳細な分析を行ったりすることもできます。",reader_description:"URL を大規模モデルに適した入力に変換するには、先頭に <code>r.jina.ai</code> を追加するだけです。",reader_do_grounding:"ファクトチェックリーダー",reader_do_grounding_explain:"新しいベースライン エンドポイントは、エンドツーエンドでほぼリアルタイムのファクトチェック エクスペリエンスを提供します。指定されたステートメントを取得し、ライブ Web 検索結果を使用してベンチマークし、事実性スコアと使用された正確な参照を返します。ステートメントを簡単にベンチマークして、大きなモデルの錯覚を減らしたり、人間が作成したコンテンツの完全性を向上させたりすることができます。",reader_do_pdf_explain:"はい、Reader は PDF の読み取りをネイティブにサポートしています。画像の多い PDF も含め、ほとんどの PDF と互換性があり、非常に高速です。ビッグモデルと組み合わせることで、ChatPDF やドキュメント分析 AI を簡単かつ迅速に構築できます。",reader_do_search:"ウェブ検索とSERPのリーダー",reader_do_search_explain:"Reader は SERP API として使用できます。これにより、SERP の背後にあるコンテンツを LLM に提供できるようになります。クエリの先頭に <code>https://s.jina.ai/?q=</code> を追加するだけで、Reader は Web を検索し、URL とコンテンツを含む上位 5 件の結果を、それぞれ LLM に適したわかりやすいテキストで返します。こうすることで、LLM を常に最新の状態に保ち、信頼性を高め、誤解を減らすことができます。",reader_reads_images:"絵も読める！",reader_reads_pdf:"Reader は PDF も読むことができます。",reader_result:"リーダーの結果",table:{td_1_0:"URL を読み取り、単一チャネルごとにそのコンテンツを返します。",td_1_1:"1 分あたり 20 リクエスト",td_1_2:"1 分あたり 200 リクエスト",td_1_3:"出力トークンによると",td_1_4:"3秒",td_1_5:"3秒",td_2_0:"Web を検索すると上位 5 件の結果が返され、世界中の知識を獲得し、証拠を検索するのに役立ちます",td_2_1:"1 分あたり 5 リクエスト",td_2_2:"1 分あたり 40 リクエスト",td_2_3:"5 つの検索結果すべてに基づいてトークン数を出力します。",td_2_4:"10秒",td_2_5:"10秒",th0:"終点",th1:"説明する",th2:"APIキーを使用しないレート制限",th3:"APIキーを使用したレート制限",th4:"トークンカウントスキーム",th5:"平均遅延",th6:"平均遅延"},title:"リーダーAPI",usage:"使用法",usage_details_false:"基本的な使い方のみを表示",usage_details_null:"基本的な使い方と高度な使い方を表示する",usage_details_true:"高度な使用法のみを表示",want_higher_rate_limit:"より高いレート制限 (最大 1000 RPM) が必要ですか?私たちはあなたをサポートできます！",what_is1:"リーダーとは何ですか?",what_is_answer_long:"ネットワーク情報をより大きなモデルに取り込むことは、優れた基盤を構築するための重要なステップですが、困難な場合もあります。最も簡単な方法は、Web ページをスクレイピングして生の HTML を入力することです。ただし、クロールは複雑でブロックされることが多く、生の HTML にはタグやスクリプトなどの不要な要素が混在します。 Reader API は、URL からコア コンテンツを抽出し、それをクリーンで大きなモデル対応テキストに変換することでこれらの問題を解決し、エージェントおよび RAG システムへの高品質の入力を保証します。",what_is_desc:"任意の URL にアクセスし、そのメイン コンテンツを大規模なモデルに最適化されたテキストに抽出します。",which_engine_is_you:"あなたにぴったりのエンジンはどれですか?",which_engine_is_you_explain:"さまざまなエンジンがさまざまなタスクに最適化されており、品質、速度、互換性、コストが異なります。 URL をテストし、ニーズに最も適したものを選択します。"},Ie={confirm_message:"API キーには {_leftTokens} トークンが残っています。 {_numArticles} 個の記事の全文を Reranker API に送信し、{_selectedReranker} モデルを使用して現在のページに関連する記事を検索します。これにより、API キー {_APIKey} のトークン カウントが大幅に消費されます。続けたいですか？",confirm_title:"警告: 大量のトークンを消費します",out_of_quota:"この API キーのトークンが不足しています。アカウントに資金を投入するか、別の API キーを使用してください。",recommend:"トップ5を獲得する",recommended_articles:"類似記事トップ 5"},ve={benchmark:{description0:"LlamaIndex は、RAG のベクトル モデルとリオーダラーのさまざまな組み合わせを評価し、それを再現します。結果は、Jina Reranker が検索品質を大幅に向上させ、これは上流で使用される特定のベクトル モデルに依存しない利点であることを示しています。",description1:"BIER (ベンチマーク IR) は、関連性や NDCG を含むモデルの検索有効性を評価します。 BIER スコアが高いほど、一致および検索結果のランキングがより正確になります。",description2:"LoCo ベンチマークを使用して、ローカルの一貫性とコンテキスト、およびクエリ固有のランキングに対するモデルの理解を測定します。 LoCo スコアが高いほど、関連情報を特定して優先順位を付ける能力が優れていることを示します。",description3:"一般的に、MTEB（多言語テキスト埋め込みベンチマーク）は、クラスタリング、分類、検索、その他の指標を含むテキスト埋め込みモデルにおけるモデルの能力をテストします。ただし、比較のために、MTEBの再ランキングタスクのみを使用しました。",title:"基準",title0:"ラマインデックス",title1:"ビア",title2:"ロコ",title3:"MTEB"},benchmark_description:"比較のために、BGE (Beijing Intelligent Source Research Institute)、BCE (NetEase Youdao)、および Cohere の他の 3 つの主要な再順序付け会社をベンチマークに含めました。以下のグラフからわかるように、Jina Reranker は関連するすべてのリランキング カテゴリで最高の平均スコアを獲得しており、同業他社の中で明らかにリードしています。",benchmark_title:"パフォーマンスのベンチマーク",choose_turbo:"ターボバージョンは5倍高速",choose_turbo_description:"また、新しいオープンソースの再ランク付けモデルとして、jina-reranker-v1-turbo-en と jina-reranker-v1-tiny-en も提供しています。後者は、3000 万のパラメーターと 4 つのレイヤーのみを備えています。 2 つの新しい再配置ツールは、品質がわずかに低下するだけで、基本モデルよりも 5 倍高速に推論できます。リアルタイムのリフローを必要とするアプリケーションに最適です。以下のレビューをお読みください。",customize_urself:"変更してみて、応答がどのように変化するかを確認してください。",customize_urself_m0:"テキストを変更したり、画像をアップロードしたりして、応答がどのように変化するかを確認してください。",customize_urself_pl:"変更してみて、応答がどのように変化するかを確認してください。",demo:{add_images:"画像を追加する",image_collection:"並べ替えにテスト画像を追加する",image_error:"画像を読み込めません",image_urls:"画像 URL (1 行につき 1 つの画像 URL)",model_selector_label:"ランキングモデルの選択",relevance_score:"jina-reranker-m0によって与えられた相関関係: {_score}",your_query:"ご質問はここに"},description:"検索の関連性を最大化する世界クラスのニューラルレトリーバー。",description_rich:"高度な並べ替え API を使用して、検索の関連性と RAG の精度を最大化します。",example_input_document:"仕分け候補文書の例",example_input_query:"サンプルクエリ",example_input_query_m0:"（テキストまたは画像）",faq_v1:{answer1:"Reranker API の価格は、Embedding API の価格体系と一致しています。新しい API キーごとに 1,000 万個の無料トークンが付属します。無料トークンに加えて、さまざまなパッケージを購入することもできます。詳細については、料金セクションをご覧ください。",answer10:"はい、当社のサービスは AWS、Azure、GCP マーケットプレイスで利用できます。特定の要件がある場合は、セールス AT jina.ai までお問い合わせください。",answer11:"特定のドメインデータに合わせて調整されたリフォーマーに興味がある場合は、当社の営業チームまでお問い合わせください。弊社チームがお客様のお問い合わせに迅速に対応させていただきます。",answer12:"<code>jina-reranker-m0</code> モデルで受け入れられる最小画像サイズは 28x28 ピクセルです。",answer3:"<code>jina-reranker-v2-base-multilingual</code> は、<code>bge-reranker-v2-m3</code> よりも優れたパフォーマンスと、<code>jina よりも優れたスループットを備え、多言語サポートで優れたパフォーマンスを発揮します。 - reranker-v1-base-en</code> は 15 倍高速です。また、エージェントのタスクとコードの取得もサポートします。 <code>jina-colbert-v2</code> は <code>ColBERTv2</code> を改良し、検索パフォーマンスを 6.5% 向上させ、89 言語の多言語サポートを追加しました。最適な効率と精度を実現するために、ユーザー制御のベクトル サイズを備えています。",answer4:"はい、<code>jina-reranker-v2-base-multilingual</code> と <code>jina-colbert-v2</code> は両方とも CC-BY-NC 4.0 ライセンスの下でオープン ソースです。これらのモデルは、非営利目的で自由に使用、共有、改変することができます。",answer5:"はい、<code>jina-reranker-v2-base-multilingual</code> と <code>jina-colbert-v2</code> は両方とも、英語、中国語、その他の主要な世界言語を含む 100 以上の言語をサポートしています。これらは多言語タスク用に最適化されており、以前のモデルよりも優れたパフォーマンスを発揮します。",answer6:"クエリ トークンの最大長は 512 です。ドキュメントにはトークンの制限はありません。",answer7:"各クエリでは、最大 2048 個のドキュメントを並べ替えることができます。",answer8:"ベクター モデル API とは異なり、バッチ サイズの概念はありません。リクエストごとに送信できるクエリ ドキュメント タプルは 1 つだけですが、タプルには最大 2048 個の候補ドキュメントを含めることができます。",answer9:"待ち時間は、ドキュメントとクエリの長​​さに応じて、100 ミリ秒から 7 秒の範囲です。たとえば、64 語のクエリを使用して 256 個のトークンを持つ 100 個のドキュメントを並べ替えるには、約 150 ミリ秒かかります。ドキュメントの長さを 4096 トークンに増やすと、時間は 3.5 秒に増加します。クエリの長​​さが 512 トークンに増加すると、時間はさらに 7 秒に増加します。",question1:"Reranker API の料金はいくらですか?",question10:"サービスを AWS、Azure、または GCP にプライベートにデプロイできますか?",question11:"ドメイン固有のデータに対して微調整された再配列ツールを提供していますか?",question12:"ドキュメントの最小画像サイズはどれくらいですか?",question3:"これら 2 つの再配置ツールの違いは何ですか?",question4:"Jina Rerankers はオープンソースですか?",question5:"リシーケンサは複数の言語をサポートしていますか?",question6:"クエリとドキュメントの最大長はどれくらいですか?",question7:"クエリごとに並べ替えできるドキュメントの最大数はいくつですか?",question8:"バッチ サイズはどれくらいですか? 1 つのリクエストで送信できるクエリ ドキュメント タプルの数はどれくらいですか?",question9:"100 個のドキュメントをリフローする場合に予想される待ち時間はどれくらいですか?",title:"リランカーに関するよくある質問"},feature_on_premises_description2:"当社の再スケジュール モデルを AWS Sagemaker にデプロイし、まもなく Microsoft Azure および Google Cloud Services にデプロイするか、当社の営業チームに連絡して、仮想プライベート クラウドおよびオンプレミス サーバー用のカスタム Kubernetes デプロイメントを入手してください。",feature_on_premises_description3:"Jina Reranker を AWS Sagemaker と Microsoft Azure にデプロイし、まもなく Google Cloud サービスにもデプロイするか、当社の営業チームに連絡して、仮想プライベート クラウドとオンプレミス サーバー用のカスタム Kubernetes デプロイメントを入手してください。",feature_solid_description:"当社の最先端の学術研究によって開発され、比類のないパフォーマンスを保証するために SOTA 再配列に対して厳密にテストされています。",how_it_works:"検索システムでは、並べ替え機能は次のように動作します。",how_it_works_v1:{description1:"ユーザーのクエリに基づいて、BM25 や TF-IDF などのベクトル モデルまたはディメンションを使用して、データベース内の関連ドキュメントを大まかに照合します。",description2:"再配置モデルは、これらの予備的なランキング結果を取得し、クエリ用語がドキュメント コンテンツとどのように相互作用するかなどのニュアンスを考慮して、より細かい粒度でドキュメントとクエリの相関分析を実行します。",description3:"再ランキング モデルは、最も関連性が高いと思われる結果を上位に配置することで検索品質を向上させます。",title1:"初期検索",title2:"並べ替える",title3:"結果の改善"},image_search:"Text2Image 並べ替えサンドボックス",improve_performance:"検索品質が他よりも優れている",improve_performance_description:"私たちの評価では、リランカーを使用した検索システムが大幅に改善され、ヒット率が 8%、平均逆ランキング (MRR) が 33% 向上したことがわかりました。",learning1:"再注文者について学ぶ",learning1_description:"再配置モデルとは何ですか?ベクトル検索やペアごとのコサイン類似性が十分ではないのはなぜですか?包括的なガイドでリシーケンサーについて基礎から学びましょう。",m0_description:"当社の新しいマルチモーダル多言語再配置ツールを使用すると、複数の言語でビジュアル ドキュメントを取得でき、多言語の長いドキュメントやコード検索タスクで SOTA パフォーマンスを実現できます。",m0_title:"jina-reranker-m0: 多言語およびマルチモーダルドキュメント再ランク付けツール",read_more_about_benchmark:"ベンチマークの詳細を読む",read_more_about_turbo:"ターボモデルとマイクロモデルについて詳しく見る",read_more_about_v2:"Jina Reranker v2 は、2024 年 6 月 25 日にリリースされたクラス最高のリランカーであり、Agentic RAG 用に構築されています。関数呼び出しのサポート、100 を超える言語での多言語検索、コード検索機能が特徴で、v1 よりも 6 倍高速です。 v2 モデルの詳細については、こちらをご覧ください。",reranker_description:"高度な 並べ替え者 API を試して、検索の関連性と RAG の精度を最大化してください。無料でお試しください!",return_documents:"文書のテキストを返します",return_documents_explain:"制御結果情報。有効にすると、ドキュメント テキスト、関連性スコア、インデックスが含まれます。無効にすると、関連性スコアとインデックスのみが表示されます。",show_v2benchmark:"v2 モデル (最新) のベースラインを表示します。",table:{number_token_document:"各ドキュメント内のトークンの数",number_token_query:"クエリ内のトークンの数",title:"クエリと 100 個のドキュメントを並べ替えるのにかかる時間コスト (ミリ秒) は次のとおりです。"},title:"リオーダラー API",top_n:"並べ替えられたドキュメントの最適な数を返します。",top_n_explain:"クエリに最も関連するドキュメントの数。",try_embedding:"ベクターモデルAPIの無償利用",try_reranker:"並べ替え者 API の無料トライアル",v2_features:{description1:"Reranker v2 は、クエリ言語に関係なく、100 以上の言語でのドキュメント検索をサポートしています。",description2:"Reranker v2 は、自然言語クエリに基づいてコード スニペットと関数シグネチャをランク付けするため、Agentic RAG アプリケーションに最適です。",description3:"Reranker v2 は、自然言語クエリに基づいて最も関連性の高いテーブルをランク付けし、さまざまなテーブル スキーマをランク付けし、SQL クエリを生成する前に最も関連性の高いテーブル スキーマを決定するのに役立ちます。",title1:"多言語検索",title2:"関数呼び出しとコード検索",title3:"表形式および構造化データのサポート"},v2benchmark:{descBeir:"Beir データセットのさまざまな再配列者によって報告された NDCG 10 スコア",descCodeSearchNet:"CodeSearchNet データセット内の再配置されたさまざまなモデルの MRR 10 スコア レポート",descMKQA:"MKQA データセット内のさまざまな並べ替えによって報告された 10 個のスコアを思い出してください。",descNSText2SQL:"NSText2SQL データセット内のさまざまな並べ替え者によって報告された 3 つのスコアを確認する",descRTX4090:"RTX 4090 GPU 上のさまざまな再ランキング モデルについて報告されたスループット (50 ミリ秒で取得されたドキュメント) スコア。",descToolBench:"ToolBench データセット内のさまざまな並べ替えによって報告された 3 つのスコアを思い出してください。",titleBeir:"BEIR (さまざまな IR タスクの異種ベンチマーク)",titleCodeSearchNet:"コードサーチネット。ベンチマークは、自然言語形式のドキュメント文字列とクエリを組み合わせたもので、クエリに関連するタグ付きスニペットが含まれます。",titleMKQA:"MKQA (多言語知識の質問と回答)",titleNSText2SQL:"NSText2SQL",titleRTX4090:"RTX4090 での Jina Reranker v2 スループット",titleToolBench:"ツールベンチ。このベンチマークは、16,000 を超えるパブリック API と、それらをシングル API およびマルチ API 設定で使用するための対応する合成ビルド命令を収集します。"},vs_table:{col0:"並べ替え者",col0_1:"検索の精度と関連性の向上",col0_2:"初期の迅速なフィルタリング",col0_3:"幅広いクエリにわたる一般的なテキスト検索",col1:"ベクトル検索",col1_1:"詳細: サブドキュメントとクエリセグメント",col1_2:"広範囲: 文書全体",col1_3:"中級: さまざまなテキストの断片",col2:"BM25",col2_1:"高い",col2_2:"適度",col2_3:"低い",col3_1:"不要",col3_2:"高い",col3_3:"低い、事前に構築されたインデックスを利用する",col4_1:"高い",col4_2:"高い",col4_3:"不要",col5_1:"より詳細な問い合わせに最適",col5_2:"効率と精度のバランス",col5_3:"幅広いクエリに対する一貫性と信頼性",col6_1:"深い文脈理解による高精度",col6_2:"中程度の精度で高速かつ効率的",col6_3:"確立された機能で拡張性が高い",col7_1:"リソースが大量に消費され、実装が複雑",col7_2:"深いクエリのコンテキストやニュアンスを捉えられない可能性がある",col7_3:"非常に具体的な検索や文脈に応じた検索ではパフォーマンスが低下する可能性があります",header0:"シーンに最適",header1:"粒度",header2:"クエリ時間の複雑さ",header3:"インデックス作成時間の複雑さ",header4:"トレーニング時間の複雑さ",header5:"検索品質",header6:"アドバンテージ",header7:"弱さ",subtitle:"以下の表は、リオーダラー、ベクトル検索、BM25 の包括的な比較を示し、各カテゴリの長所と短所を示しています。",title:"再配列器、ベクトル検索、BM25の比較"},what_is:"リアレンジャーとは何ですか？",what_is_answer_long:`検索の本質は、ほとんどのユーザーが望む結果を迅速かつ効率的に見つけることです。前世紀の BM25 や tf-idf などのキーワード マッチング アルゴリズムは、さまざまな検索結果のランク付けに成熟して使用されてきました。近年、ベクトル モデルに基づくコサイン類似度が非常に普及しており、多くのベクトル データベースで標準となっています。ただし、これらの方法は本質的に比較的単純であり、多くの場合、自然言語の微妙な点、そして最も重要なことに、ドキュメントとクエリの意図の間の相関情報が無視されます。

そこで誕生したのが「並べ替えモデル」です！再ランキング モデルは、実際には、検索から候補の初期セット (通常はベクトルベース/用語ベースの検索結果によって提供される) を取得し、ユーザーの検索意図との関連性を再評価する高度な AI モデルです。リフラワーは、テキストの表面レベルの一致を超えて、クエリとドキュメント コンテンツ間のより深い相互作用を調査します。`,what_is_answer_long_ending:"並べ替え者 はサブドキュメントおよびサブクエリ レベルで動作するため、検索品質を大幅に向上させることができます。つまり、個々の単語やフレーズ、その意味、およびクエリとドキュメント内での相互の関連性が調べられます。これにより、より正確で状況に応じた一連の検索結果が得られます。",what_is_desc:"Reranker は、BM25 検索またはベクトルリコールの検索結果を最適化する AI モデルです。詳細については、記事をご覧ください。"},ke={caption_image_desc:"画像のテキスト説明を生成します。",caption_image_title:"ヘッダー画像",description:"あらゆるピクセルの背後にあるストーリーを発見する",example1:"このビデオは、牧草地で魅力的な白ウサギと蝶をフィーチャーした自然のショットのようです。ウサギはさまざまな方法で蝶と対話し、その独特の関係を示しています。周囲の自然は、このシンプルでありながら魅力的なシーンの美しさを高める絵のような背景を提供します。",generate_story_desc:"絵に基づいて、通常は登場人物の会話や独白を盛り込んだストーリーを作成します。",generate_story_title:"ストーリーを生成する",intro1:"画像と動画を理解するAIの先駆者",json_image_desc:"事前定義されたスキーマを使用して、画像から構造化された JSON 形式を生成します。これにより、画像から特定のデータを抽出できるようになります。",json_image_title:"画像からJSONを抽出する",summarize_video_desc:"主要なイベントを強調して、ビデオの簡潔な概要を生成します。",summarize_video_title:"まとめ動画",visual_q_a_desc:"画像コンテンツに基づいてクエリに回答します。",visual_q_a_title:"ビジュアルQ&A"},Pe={ask_deepsearch:"Deep Search に質問する...",ask_on_current_page:"このページについて質問する...",find_solution:"対応するソリューションを生成...",hint:"製品、ニュース、質問を検索します",hotkey:"このページで質問するには / キーを押してください",hotkey1:"によると",hotkey2:"スイッチ",hotkey_long1:"任意のページで、 を押します。",hotkey_long3:"検索バーを開く",more_results:"さらに {_numMore} 件の結果",placeholder:"このページの内容について質問する",proposing_solution:"現在のページのコンテンツに基づいて回答を生成します...",required:"問題をさらに詳しく説明してください。",results:"結果"},ye={description:"ナビゲーション、インタラクション、最適化: 製品検索の再定義"},fe={beta:"実験"},we={description:"既存の検索インフラストラクチャにおけるセマンティック ギャップを埋める"},xe={"Hacker News":"HNニュース",LinkedIn:"リンクトイン",facebook:"フェイスブック",reddit:"レディット",rss:"RSS購読",share_btn:"共有",twitter:"X（旧ツイッター）"},Re={click_to_learn_more:"クリックして詳細を確認する",contextualization:"文脈の理解",contextualization_desc:"リランカーは、クエリの深い文脈上の関連性に基づいて、最初の検索結果を調整します。これにより、ユーザーが役立つと思われるコンテンツにさらに適合するようにランキングを最適化できます。",coreInfra:"コアインフラストラクチャ",coreInfra_desc:"コア インフラストラクチャは、パブリック クラウドおよびオンプレミスで検索インフラストラクチャ モデルを開発、展開、調整するためのクラウド ネイティブ レイヤーを提供し、サービスを簡単にスケールアップおよびスケールダウンできるようにします。",embedding_serving:"大規模なモデル ベクトルの展開",embedding_serving_description:"クラウドネイティブ テクノロジーを使用して、強力でスケーラブルなマイクロサービスを使用して大規模なモデルのベクトル推論を展開します。",embedding_tech:"ベクトルモデル",embedding_tech_description:`Jina AI では、ベクター モデリング テクノロジーを通じて AI アプリケーションのあり方に革命を起こしています。このテクノロジーは、重要な情報が失われないようにしながら、複数の種類のデータを効果的に表現および圧縮するための統一された手段として機能します。私たちの主な目標は、複雑なデータセットを普遍的に理解可能なベクトル モデル形式に変換し、正確で詳細な AI 分析をサポートすることです。

ベクトルモデルは、AI の分野において基本的かつ重要な役割を果たします。正確な画像認識や音声認識などの分野では、より微妙な詳細や違いを検出するのに役立ちます。自然言語処理では、文脈や感情の理解が強化され、会話型 AI や言語翻訳ツールの精度が向上します。さらに、ベクトル モデルは、テキスト、オーディオ、ビデオなどのさまざまなコンテンツ モダリティにわたるユーザーの好みを深く理解する必要がある複雑なレコメンデーション システムの構築において重要な役割を果たします。`,embedding_tuning:"大規模モデルのベクトル微調整",embedding_tuning_description:"専門知識と業界データを組み込んで高品質の大規模モデル ベクトルをトレーニングし、特定のタスクのパフォーマンスを向上させます。",embeddings:"ベクトルモデル",embeddings_desc:"ベクトル モデルは現代の検索システムの基礎であり、マルチモーダル データを数値ベクトルとして表現します。このプロセスにより、単純なキーワードの一致をはるかに超えた、コンテンツのより微妙な理解が可能になります。",for_developers:"開発者向け",for_enterprise:"ビジネスのための",for_power_users:"上級ユーザー向け",grounding:"トレーサビリティ",grounding_desc:"読者は、大規模なモデルを通じて入力と結果を改良します。最終的な回答の品質、読みやすさ、信頼性が向上します。",model_serving:"モデルの展開",model_serving_description:"調整されたモデルを運用環境にデプロイするには、多くの場合、GPU ホスティングなどの大量のリソースが必要になります。 MLOps は、スケーラブルで効率的かつ信頼性の高い方法で中規模から大規模のモデルを提供することに重点を置いています。",model_tuning:"モデルのチューニング",model_tuning_description:"タスク固有のデータセットで事前トレーニングされたモデルのパラメーターを調整して、パフォーマンスを向上させ、特定のアプリケーションに適応させます。",personalization:"パーソナライズする",personalization_desc:"ユーザーの指示に従って合成データを使用して、ドメイン固有のベクトル化機能と再配置機能を自動的にトレーニングします。",preprocessing:"前処理",preprocessing_desc:"前処理には、生データのクリーニング、正規化、検索システムが理解できる形式への変換が含まれます。",promptOps:"迅速な操作",promptOps_desc:"Prompt Ops は、クエリの拡張、大規模なモデルの入力、結果の書き換えなど、検索システムの入力と出力を改善します。これにより、検索がよりわかりやすくなり、結果も向上します。",prompt_serving:"プロンプトワード展開",prompt_serving_description:"API を介してヒントをラップして提供することで、重いモデルをホストする必要がなくなります。この API は、共通の大規模言語モデル サービスを呼び出し、一連の操作における入出力のオーケストレーションを処理します。",prompt_tech:"即効性のある言葉とエージェント エンジニアリング",prompt_tech_description:`Jina AI では、大規模言語モデル (LLM) と通信する際のプロンプト ワード エンジニアリングの重要性を理解しています。これらのモデルが進化し続けるにつれて、私たちが発する言葉はますます複雑になり、深い推論や論理的思考が含まれるようになりました。この進歩は、LLM とプロンプトワードエンジニアリングの相互強化関係を浮き彫りにしています。

将来的には、LLM がコンパイラーの役割を引き受け、プロンプト ワードが新しいタイプのプログラミング言語に進化すると考えられます。これは、将来の技術スキルが従来のプログラミング スキルだけではなく、プロンプト ワードの技術を習得することに重点が置かれる可能性があることを意味します。 Jina AI の目標は、この技術革命をリードし、この新たな「言語」に習熟することで高度な人工知能を理解し、応用しやすくすることです。`,prompt_tuning:"即時単語チューニング",prompt_tuning_description:"入力プロンプトを慎重に設計および調整して、その出力を特定の望ましい応答に向けるプロセスです。",representation:"表現学習",representation_desc:"ベクトル化は、マルチモーダル データを統一されたベクトル形式に変換します。これにより、検索システムは単純なキーワードを超えてコンテンツを理解して分類できるようになります。",rerankers:"並べ替え者",rerankers_desc:"再配置機能は、ベクトル モデルから初期結果を取得し、それらを最適化して、最も関連性の高い結果がユーザーに表示されるようにします。これは、ユーザーの意図に一致する高品質の検索結果を提供するために重要です。"},Le={care_most:"一番大切にしていることは何ですか?",care_most_options:{accuracy:"正確さ",cost:"料金",other:"他の",scalability:"スループット",speed:"スピード"},care_most_required:"APIサービスを選ぶ際に一番気になることは何ですか?",company_size:"あなたの会社の規模はどれくらいですか?",company_size_required:"貴社の規模を教えていただくと、より良いサービスを提供することができます",company_url:"あなたの会社のウェブサイトは何ですか?",company_url_required:"貴社のウェブサイトについてお知らせいただくと、より良いサービスを提供することができます",contactName:"あなたの名前",contactName_required:"何と呼ぼうか？",contactTitle:"社内でどのように溶け込んでいますか?",contactTitle_required:"役職は必須です",contact_us:"お問い合わせ",domain_required:"あなたの仕事分野を教えていただくと、より良いサービスを提供することができます",email:"Eメール",email_contact:"あなたの連絡先メールアドレス",email_invalid:"無効な電子メール",email_required:"メールアドレスは必須です",fine_tuned_embedding:"プライベート ドメイン データ用の排他的なベクトル モデルが必要ですか?いつでもお待ちしております！",fine_tuned_reranker:"あなたの個人データを専門に再注文する人が必要ですか?来る！話し合ってみましょう！",full_survey:"アンケートにすべて回答すると、チームからより迅速な回答が得られます",get_new_key:"APIキーを取得する",get_update_blog_posts:"ブログ投稿の最新の更新を通知する",get_update_embeddings:"ベクトル モデルに関する最新ニュースを思い出してください",send:"送信",sign_up:"サブスクリプション",subscribe:"サブスクリプション",tell_domain:"自分の分野や方向性の微調整",usage_type:"どの用法があなたに最もよく当てはまりますか?",usage_type_options:{other:"他の",poc:"プロトタイピングまたは概念実証",production:"本番環境",research:"研究段階"},usage_type_required:"より良いサービスを提供するために、お客様の使用パターンをお知らせください。",used_product:"どのモデルを使用していますか?",used_product_required:"使用しているモデルまたは興味のあるモデルを選択してください"},Me={description:"大規模モデルを強化して限界まで押し上げましょう"},qe="目次",Ce={advance_usage:"その他の機能については POST リクエストを使用してください",basic_usage:"GET リクエストを使用してトークンの数を直接返します",basic_usage_explain:"GET リクエストを送信するだけで、テキスト内のトークンの数をカウントできます。",change_content:"「コンテンツ」パラメータを変更してライブ結果を確認する",chars:"キャラクター",chinese:"中国語",chunk:"細かく切る",chunk_all:"すべてのブロック",chunking:"長い文書を稲妻の鞭のように速く切り分けます。",chunking_explain:"また、スプリッターを使用して長いドキュメントを小さなチャンクに分割し、ベクター モデルや並べ替えで処理しやすくすることもできます。私たちは共通の構造的ヒントを取り入れ、Markdown、HTML、LaTeX、CJK 言語など、さまざまな種類のコンテンツにわたって適切に機能する一連のルールとヒューリスティックを構築しました。",chunking_short:"細かく切る",chunks_in_total:"合計チャンク数 {_numChunks}",count_tokens_hint:"<b>{_numTokens}</b> トークン、{_numChars} 文字。",description:"長いテキストをチャンクまたはトークンに分割します。",description_long:"当社のスライサーは、大規模なモデルがコンテキスト制約内で入力を管理し、モデルのパフォーマンスを最適化するために不可欠です。これにより、開発者はトークンをカウントし、関連するテキスト セグメントを抽出できるため、効率的なデータ処理とコスト管理が可能になります。",description_long1:"長いテキストをチャンクに分割し、単語を分割するための無料 API。",english:"英語",explain:"セグメンターは、テキストをトークンまたはチャンクに変換する重要なコンポーネントです。トークンまたはチャンクは、ベクター モデル/リアレンジャーまたは大規模モデルによって処理される基本データ単位です。トークンは、単語全体、単語の一部、または単一の文字を表すことができます。",faq_v1:{answer1:"スライサーは無料でご利用いただけます。 API キーを提供すると、より高いレート制限にアクセスでき、キーは請求されません。",answer10:"チャンキング技術は、西洋言語に加えて、中国語、日本語、韓国語でも機能します。",answer2:"API キーを使用しない場合は、20 RPM のレート制限でスライサーにアクセスできます。",answer3:"API キーを使用すると、200 RPM のレート制限でスライサーにアクセスできます。プレミアム有料ユーザーの場合、レート制限は 1000 RPM です。",answer4:"いいえ、API キーはより高いレート制限にアクセスするためにのみ使用されます。",answer5:"はい、スライサーは多言語対応で、100 以上の言語をサポートしています。",answer6:"GET リクエストはテキスト内のトークンの数をカウントするためにのみ使用されるため、これをカウンターとしてアプリケーションに簡単に統合できます。 POST リクエストは、最初と最後の N 個のトークンを返すなど、より多くのパラメーターと機能をサポートします。",answer7:"リクエストごとに最大 64,000 文字を送信できます。",answer8:"タイル機能は、共通の構造上の手がかりに基づいて長い文書を小さなチャンクに分割し、テキストが意味のあるチャンクに正確に分割されるようにします。基本的に、これは、意味上の境界 (文末、段落区切り文字、句読点、および特定の接続詞など) と一般に一致する特定の構文上の特徴に基づいてテキストを分割する (大きな!) 正規表現パターンです。それは意味論的な分割ではありません。この (大きな) 正規表現は、正規表現の制限内で可能な限り強力です。複雑さとパフォーマンスのバランスをとります。正規表現は真の意味の理解を達成することはできませんが、共通の構造上の手がかりを通じてコン​​テキストの適切な近似を提供できます。",answer9:"入力に特別なトークンが含まれている場合、トークナイザーはそれらを「special_tokens」フィールドに格納します。こうすることで、それらを簡単に識別し、下流のタスクに応じて処理することができます。たとえば、インジェクション攻撃を防ぐために、テキストを大規模なモデルに取り込む前にそれらを削除するなどです。",question1:"スライサーの値段はいくらですか？",question10:"チャンキングは英語以外の言語もサポートしていますか?",question2:"API キーを提供しない場合のレート制限は何ですか?",question3:"API キーを指定した場合、レート制限はどのくらいになりますか?",question4:"私の API キーからトークンを請求してくれますか?",question5:"スライサーは複数の言語をサポートしていますか?",question6:"GET リクエストと POST リクエストの違いは何ですか?",question7:"リクエストごとに分割できる単語の最大長はどれくらいですか?",question8:"ダイシング機能はどのように機能しますか?それはセマンティックダイシングですか？",question9:"スプリッターで「endoftext」のような特別なトークンを処理するにはどうすればよいですか?",title:"セグメンターに関するよくある質問"},free_api:"スライサーは無料でご利用いただけます。 API キーを提供すると、より高いレート制限にアクセスでき、キーは請求されません。",input_text:"テキストを入力してください",is_free:"スライサーは無料です！",is_free_description:"API キーを提供すると、より高いレート制限にアクセスでき、キーは請求されません。",japanese:"日本語",korean:"韓国人",parameters:{auth_token:"レート制限を高めるには API キーを追加します",auth_token_explain:"より高いレート制限にアクセスするには、Jina API キーを入力してください。最新のレート制限情報については、以下の表を参照してください。",head:"最初の N 個のトークンを返す",head_explain:"指定されたコンテンツの最初の N 個のトークンを返します。ボーダー専用。 「しっぽ」とは併用できません。",learn_more:"もっと詳しく知る",max_chunk_length:"各ブロックの最大長",max_chunk_length_explain:"各ブロック内の最大文字数。実際、テキスト内に自然な境界がある場合、ブロックの長さはこの値よりも小さくなる可能性があります。",return_chunks:"サイコロに戻る",return_chunks_explain:"共通の構造上の手がかりに基づいて、さまざまなテキスト タイプや特殊なケースに適応するヒューリスティック ルールを使用して、入力を意味的に意味のある部分にスライスします。",return_tokens:"単語分割結果を返すかどうか",return_tokens_explain:"トークンとそれに対応する ID を応答で返します。切り替えて結果の視覚化を表示します。",tail:"最後の N 個のトークンを返します",tail_explain:"指定されたコンテンツの最後の N 個のトークンを返します。ボーダー専用。 「ヘッド」では使用できません。",type:"セグメンタ",type_explain:"使用するトークナイザーを選択します。",used_by_models:"{_usedBy} の場合。"},remove_boundary_cues:"改行を削除する",remove_boundary_cues_explain:"入力からすべての改行を削除します (主要な境界のヒント)。これにより、質問がより難しくなり、応答がどのように変化するかを確認してください。",show_space:"先頭/末尾のスペースを表示する",table:{td_1_0:"テキストをセグメント化し、最初と最後の N 個のトークンを数えて取得します。",td_1_1:"20rpm",td_1_2:"200rpm",td_1_3:"1000rpm",td_1_4:"無料",td_1_5:"800ミリ秒"},title:"セグメンタ API",token_index:"トークンコード: {_index}",usage:"使用法",visualization:"視覚化",what_is:"セグメンタとは何ですか?",your_input:"複数行テキスト"},Se={cta:"{_lang} コードに翻訳されました",select_language:"言語"},je={description:"必要なのは Python ベクトル データベースだけです - それ以上でもそれ以下でもありません"},Te="zzz",Je={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:a,api_general_faq:i,autotune:t,avatar:r,beta:s,billing_general_faq:o,blog_tags:_,book2024:d,cclicence:l,classifier:c,clip_as_service:p,cloud:u,contact_us_page:m,copy:g,copy_to_clipboard_success:b,dalle_flow:A,deepsearch:h,"dev-gpt":{description:"仮想開発チーム"},disco_art:I,doc_array:v,download:k,embedding:P,embeddings:y,estimator:f,faq:w,faq_button:x,farewell:R,finetuner:L,finetuner_plus:M,finetuning:q,footer:C,get_new_key:S,github:j,grounding:T,header:J,hub:E,huggingface:B,impact_snapshots:G,inference:U,insufficient_error_message:D,integrations:O,internship_faq:z,internship_page:N,jcloud:W,jerboa:H,jina:F,jina_chat:K,key_manager:Q,lab_dialog:V,landing_page:X,langchain_serve:Y,legal_page:$,llm_serp:Z,model_graph:ee,models:ne,news_page:ae,newsroom_page:ie,notice:te,open_day:re,open_day_faq:se,open_gpt:oe,paywall:_e,powered_by:de,print:le,project_status:ce,prompt_perfect:pe,promptperfect:ue,purchase:me,purchase_now:ge,rate_limit:be,rationale:Ae,reader:he,recommender:Ie,reranker:ve,scenex:ke,searchbar:Pe,searchscape:ye,sefo_api:fe,semantic:we,share:xe,spectrum:Re,subscribe_system:Le,think_gpt:Me,toc:qe,tokenizer:Ce,translator:Se,vectordb:je,zzz:Te};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,a as about_us_page,i as api_general_faq,t as autotune,r as avatar,s as beta,o as billing_general_faq,_ as blog_tags,d as book2024,l as cclicence,c as classifier,p as clip_as_service,u as cloud,m as contact_us_page,g as copy,b as copy_to_clipboard_success,A as dalle_flow,h as deepsearch,Je as default,I as disco_art,v as doc_array,k as download,P as embedding,y as embeddings,f as estimator,w as faq,x as faq_button,R as farewell,L as finetuner,M as finetuner_plus,q as finetuning,C as footer,S as get_new_key,j as github,T as grounding,J as header,E as hub,B as huggingface,G as impact_snapshots,U as inference,D as insufficient_error_message,O as integrations,z as internship_faq,N as internship_page,W as jcloud,H as jerboa,F as jina,K as jina_chat,Q as key_manager,V as lab_dialog,X as landing_page,Y as langchain_serve,$ as legal_page,Z as llm_serp,ee as model_graph,ne as models,ae as news_page,ie as newsroom_page,te as notice,re as open_day,se as open_day_faq,oe as open_gpt,_e as paywall,de as powered_by,le as print,ce as project_status,pe as prompt_perfect,ue as promptperfect,me as purchase,ge as purchase_now,be as rate_limit,Ae as rationale,he as reader,Ie as recommender,ve as reranker,ke as scenex,Pe as searchbar,ye as searchscape,fe as sefo_api,we as semantic,xe as share,Re as spectrum,Le as subscribe_system,Me as think_gpt,qe as toc,Ce as tokenizer,Se as translator,je as vectordb,Te as zzz};
