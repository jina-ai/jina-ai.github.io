const e="一流的嵌入、重排器、網絡爬蟲、深度搜索、小型 LM。用於多語言和多模態數據的搜索 AI。",n="您的搜索，如虎添翼！",a={approach:"我們的策略",approach_connect_dots:"繪圖連線：從高級用户至企業用户",approach_connect_dots_description:"為何我們如此重視高級用户在整體策略中的地位？這是一個提前佈局的考量。今日之投資，為了明日他們在企業中的影響力。這是我們的遠見卓識，確保當這些高級用户掌握企業的話語權時，我們仍為他們心之所向。",approach_content1:"在人工智能的風雲變幻中，策略必須靈活應變，洞察未來。儘管 Jina AI 以企業為核心，但AI的舞台已演變，吸引客户的策略亦當與時俱進。因此，以高級用户為突破口，不僅是我們的策略創新，更體現了我們對企業發展的堅韌不拔。",approach_content2:"在 Jina AI，我們不甘於守成，而是勇於開創。以高級用户為先導，確保我們把握當下，預見未來。對於企業，我們的決心堅如磐石；但在通向成功的路上，我們走的是一條既穩健又前瞻的新路。",approach_content4:'每個人都希望獲得更好的搜索體驗。在 Jina AI，我們通過提供 <span class="text-primary text-bold">搜索底座</span>（由向量模型、重排器、讀取器 和 提示詞工程組成）來實現更好的搜索體驗。這些組件協同工作，徹底改變了我們搜索和理解數據的方式。',approach_miss_mark:"傳統MLOps的短板",approach_miss_mark_description:"儘管高級用户日益壯大，但傳統的MLOps工具往往步履蹣跚，難以滿足他們的需求。它們宛如過時的老馬，難以應對新時代的快節奏競賽。新一代的開發者飢渴地尋求更為輕巧、直觀的武器。",approach_new_paradigm:"提示詞工程：AI開發之新潮",approach_new_paradigm_description:"2023年，AI世界迎來新篇章，提示詞工程如日方升，實現了AI工具的大眾化進程。即使是那些缺乏編程根基的高級用户，也能遊刃有餘地涉獵AI，無需再對如Pytorch、Docker或Kubernetes等深感畏難。此情此景，與個人計算的崛起歷程頗為相似。當年，僅有的技術精英才可與計算機溝通，但隨着更為親和的界面的問世，大眾也得以加入其行列。今日，隨着提示詞工程的普及，我們正在目睹AI領域的新一輪普及浪潮。",awards:"獎項與殊榮",berlin:"德國柏林（總部）",berlin_address:"Prinzessinnenstraße 19-20，10969 柏林，德國",berlin_address2:"工商註冊地址: Leipzigerstr. 96, 10117 柏林, 德國",bj:"中國北京",bj_address:"中國北京市海淀區西大街48號6號樓5層",brochure_info:"我們公司的指南等待您的光臨",description:"未來從這裏開始。",download_brochure1:"下載手冊",download_docarray_logo:"下載 DocArray的Logo",download_docarray_logo_desc:"獲取 DocArray 徽標，這是一個由 Jina AI 發起的開源項目，並於 2022 年 12 月捐贈給了 Linux 基金會。提供淺色和深色模式、PNG 和 SVG 格式。",download_jina_logo:"下載Jina AI的Logo",download_jina_logo_desc:"獲取淺色和深色模式下的 Jina AI 徽標，提供 PNG 和 SVG 格式。該標誌是歐盟知識產權局（EUIPO）的註冊商標。",download_logo:"下載Logo",employees:"當今員工",empower_developers:"開發者生態",fastApiCaption:"自 2021 年以來捐款超過 20,000 美元。",founded:"成立年份",founded_in:"成立於",investors:"我們的投資方",linuxFoundationCaption:"從 2022 年開始，每年捐款 10,000 美元。",many:"許多",media:{video:"視頻採訪"},mission:"我們的使命",mission_content1:"我們的關鍵技術包括快速調優、快速服務、模型調優和模型服務，體現了我們致力於使人工智能普及的承諾。通過我們的開源計劃，我們努力促進創新、協作和透明度，確保提供可擴展、高效和強大的解決方案。Jina AI 不僅僅是一家公司；它是一個致力於幫助企業應對數字時代的動態挑戰並在其領域蓬勃發展的社區。",mission_content2:"Jina AI 的核心理念在於我們的使命：成為從高級用户、開發者至各大企業的多模態 AI 通道。我們深信開源的魔力，並致力於為 AI 社區構建前沿且易於接入的工具。我們的關鍵技術，諸如提示詞微調、模型向量調優部署等，展現了我們對 AI 普及的堅定信仰。藉助我們的開源方案，我們旨在推動創新、合作與透明度，確保我們的方案既可擴展、高效又強大。Jina AI 不只是一個公司，它更是一個助企業應對數字化時代挑戰並在其領域中持續領先的共同體。",mission_content3:"在 Jina AI，我們的使命是通過創新的向量模型和基於提示的技術，引領多模態AI的發展。我們特別關注自然語言處理、圖片與視頻分析以及跨模態數據交互等領域。我們的專業化致力於提供獨特的解決方案，能夠將複雜的多源數據轉化為具有實際操作價值的洞察和創新應用。",mit_report_title:"多模態：人工智能的新前沿",mit_techreview:"麻省理工科技評論",numfocusCaption:"從 2022 年開始每月定期捐款。",office:"我們的辦公室",otherProjectsCaption:"通過 Github 贊助捐贈了超過 3,000 美元。",our_answer:"不能同意更多，Yann。我們正在努力搭建通向多模態AI未來的橋樑！",pythonSoftwareFoundationCaption:"一次性捐贈 10,000 美元，並贊助了多項 PyCon 活動，包括德國、意大利、中國和美國的活動。",sectors:{ecommerceRetail:"下一代電商",ecommerceRetail_description:"電子商務和零售業領導者與 Jina AI 合作，提供精準的產品推薦和深入的搜索體驗。我們的多語言向量和 AI 驅動的重排器有助於優化發現、提高轉化率並縮短全球產品目錄的洞察時間。",ecommerceRetail_short:"電商零售",financeConsulting:"諮詢顧問和分析師",financeConsulting_description:"金融公司和諮詢公司利用 Jina AI 的大規模數據清理和特定領域模型訓練，獲得實時洞察。我們的企業許可和安全的本地部署，使他們能夠確保機密性，同時受益於先進的檢索和分析功能。",financeConsulting_short:"諮詢金融",media:"內容創作者",media_description:"媒體組織使用 Jina AI 將大量多媒體資產轉化為可搜索的知識，簡化內部研究並豐富用户體驗。我們專業的讀取器和重新排名服務可確保在文章、視頻和檔案中進行準確、情境感知的發現。",media_short:"媒體文創",misc:"弄潮兒",misc_description:"教育、農業、房地產等行業的組織利用 Jina AI 靈活的解決方案來大規模清理、提取和轉換數據。通過利用我們尖端的神經檢索堆棧，他們解鎖了新的可能性並在各自的領域保持領先地位。",misc_short:"其他的",technology:"開拓創新的技術者",technology_description:"軟件、雲、AI 和數據領域的領導者依靠 Jina AI 的神經搜索解決方案來支持其基於大模型的搜索、RAG 和 AI 代理系統。我們的高級讀取器、向量、重排器和小語言模型可幫助他們以前所未有的速度從試驗品轉向生產級。",technology_short:"軟件科技"},sefo:{layer0:"面向用户的應用",layer1:"RAG/編排系統",layer3:"GPU/移動/邊緣/本地計算"},segmentFaultCaption:"一次性捐款 6,000 美元。",show_position:"搜索底座在生態系統中的定位？",stats_1:"Jina AI 於 2020 年 2 月成立，短短 20 個月，已成為多模態AI技術的翹楚。這段時間裏，我們成功籌集了 3750 萬美元，確立了在 AI 行業的領軍地位。在 GitHub 上，我們的革命性開源技術賦能超過 40,000 名開發者，使他們得以毫無障礙地構建與部署多模態應用。",stats_2:"到了 2023 年，我們在基於多模態技術的 AI 工具方面取得了跨越式的突破。這一創新已讓超過 250,000 名用户受益，滿足了各式各樣的業務需求。無論是推動業務增長、提升運營效率還是優化成本，Jina AI 都致力於助力企業在多模態時代鋭意進取。",stats_4:'Jina AI 成立於 2020 年，是一家領先的搜索 AI 公司。我們的 <span class="text-primary text-bold">搜索底座</span> 平台包含了向量模型、重排器和小語言模型，可幫助企業構建可靠且高質量的生成式AI和多模態的搜索應用。',stats_v1:"當搜索與加速主義碰撞",subtitle:"通過人工智能生成的解決方案徹底改變內容創建，釋放無限可能性。塑造人工智能生成內容的未來並增強人類創造力。",sues_und_sauer:"酸甜苦辣",sues_und_sauer_tooltip:"Süß-Sauer 是德式中餐中一種流行的口味（地道的中餐裏這種口味並不常見，屬於德國人對中餐的刻板印象），意思是酸甜口。它隱喻着創業生涯的起起落落。",sunnyvale_address:"710 Lakeway Dr, Ste 200, 桑尼維爾, CA 94085, 美國",sz:"中國深圳",sz_address:"中國深圳市賦安科技大廈4樓402",team:"我們的團隊",team_content1:"我們從全球各個角落構建 AI 的未來。我們獨特的視角豐富了我們的工作，激發了創新。在這個門户網站中，我們擁抱個性，熱情追求夢想。歡迎來到 AI 未來的門户網站。",team_join:"加入我們",team_size:"這些照片包括我們以前的同事和實習生——我們感謝他們每一個人。",technologies:"核心技術",title:"關於極納科技",title0:"未來",title1:"起源",title2:"於此",title3:"始於斯",understand_our_strength:"瞭解我們的強項",understand_our_view2:"瞭解搜索底座",users:"註冊用户",value:"我們的獎項",value_content1:"我們不會安於現狀。我們不會妥協。我們追求卓越。",vision:"我們的任務",vision_content1:"啓發於 Yann LeCun 對於AI的觀點，“",vision_content3:'AI 的未來是<span class="text-primary text-bold">多模態</span>，而我們是其中的一部分。我們意識到企業在利用多模態數據方面面臨挑戰。為此，我們致力於<span class="text-primary text-bold">搜索底座</span>，以幫助企業和開發者更好地進行搜索，並利用多模態數據促進業務增長。',yannlecun_quote:"僅靠單詞和句子訓練的人工智能系統永遠無法接近人類的理解力。"},i={answer1:"是的，同一個 API 密鑰適用於 Jina AI 的所有搜索基礎產品。這包括讀取器、向量模型、重排器、分類器和微調模型 API，所有服務之間共享詞元。",answer10:"這是因為我們的無服務器架構在使用率較低時會卸載某些模型。初始請求會激活或“預熱”模型，這可能需要幾秒鐘。初始激活後，後續請求的處理速度會快得多。",answer12:"我們遵守嚴格的隱私政策，不會使用用户輸入數據來訓練我們的模型。我們還符合 SOC 2 類型 I 和類型 II 標準，確保高標準的安全性和隱私性。",answer3:"是的，您可以在“密鑰和計費”選項卡中輸入您的 API 密鑰來查看詞元最近的使用記錄和剩餘詞元餘額。如果您已登錄 API 密鑰控制面板，也可以在“管理 API 密鑰”選項卡中查看這些詳細信息。",answer4:"如果您遺失了充值密鑰並希望找回，請使用您的註冊電子郵件聯繫 support AT jina.ai 尋求幫助。建議登錄以便於安全保存和便捷訪問您的 API 密鑰。",answer5:"不，我們的 API 密鑰沒有到期日期。但是，如果您懷疑您的密鑰已被泄露並希望停用它，請聯繫我們的支持團隊尋求幫助。您還可以在<a class='text-primary' href='https://jina.ai/api-dashboard'>API 密鑰控制面板</a>中自助銷燬您的密鑰。",answer6:"是的，您可以將剩餘的付費詞元餘額從一個高級密鑰轉移到另一個密鑰。在<a class='text-primary' href='https://jina.ai/api-dashboard'>API 密鑰控制面板</a>上登錄您的帳户後，在該密鑰的設置界面來轉移所有剩餘的付費詞元餘額。",answer7:"是的，如果您認為您的 API 密鑰已被泄露，您可以銷燬該密鑰。銷燬密鑰將立即為所有存儲該密鑰的用户禁用該密鑰，並且所有剩餘詞元餘額和關聯資產將永久不可用。如果您擁有高級密鑰，您可以選擇在銷燬之前將剩餘的已付款詞元餘額轉移到另一個密鑰。請注意，此操作無法撤消。要銷燬密鑰，請前往<a class='text-primary' href='https://jina.ai/api-dashboard'>API 密鑰控制面板</a>中的密鑰設置。",question1:"我可以對讀取器、向量模型、重排器、分類器和微調模型 API 使用相同的 API 密鑰嗎？",question10:"為什麼有些機型第一次請求比較慢？",question12:"用户輸入數據是否用於訓練您的模型？",question3:"我可以查看 API 密鑰的詞元使用情況嗎？",question4:"如果我忘記了 API 密鑰，該怎麼辦？",question5:"API 密鑰會過期嗎？",question6:"我可以在 API 密鑰之間轉移詞元餘額嗎？",question7:"我可以銷燬我的 API 密鑰嗎？",title:"API相關常見問題"},t={base_model:"微調底座模型",check_data:"下載合成數據",check_model:"下載微調模型",data_size:"生成合成數據",description:"獲取您想要的任何域的微調向量模型。",description_long:"只需告訴我們您希望向量模型在哪個領域中表現出色，我們就會自動為該領域提供一個可立即使用的、經過微調的向量模型模型。",does_it_work_tho:"但它真的有效嗎？",does_it_work_tho_explain:"自動微調具有神奇的自動效果，可以為您想要的任何域提供微調的向量。但它真的有效嗎？這是一個相當合理的疑問。我們在各種領域和底座模型上對其進行了測試以找出答案。查看下面的精選和精選結果。",domain_instruction:"領域指令",embedding_provider:"選擇基礎向量模型",eval_evaluation:"驗證",eval_map:"地圖",eval_mrr:"月平均收入",eval_ndcg:"神經膠質細胞癌",eval_performance_before_after:"微調前後合成驗證集上的表現",eval_syntheticDataSize:"全部的",eval_test:"真實數據測試",eval_training:"訓練",faq_v1:{answer1:"此功能目前處於測試階段，每個微調模型需要花費 100 萬個詞元。如果 Embedding/Reranker API 中有足夠的詞元，您可以使用現有的 API 密鑰，也可以創建一個新的 API 密鑰，其中包含 1000 萬個免費詞元。",answer10:"目前沒有。請注意，此功能仍處於測試階段。將微調後的模型和合成數據公開存儲在 Hugging Face 模型中心有助於我們和社區評估訓練的質量。未來，我們計劃提供私人存儲選項。",answer11:"由於所有微調模型都已上傳至 Hugging Face，因此您只需指定模型名稱即可通過 SentenceTransformers 訪問它們。",answer12:"請檢查您的垃圾郵件文件夾。如果仍然找不到，請使用您提供的電子郵件地址聯繫我們的支持團隊。",answer2:"您無需提供任何訓練數據。只需用自然語言描述您的目標域（您希望優化微調向量模型的域），或使用 URL 作為參考，我們的系統就會生成合成數據來訓練模型。",answer3:"大約 30 分鐘。",answer4:"經過微調的模型和合成數據公開存儲在 Hugging Face 模型中心。",answer5:"系統使用 Reader API 從 URL 中獲取內容。然後分析內容以總結語氣和領域，並以此作為生成合成數據的指導方針。因此，URL 應該是公開可訪問的，並且代表目標域。",answer6:"是的，您可以針對非英語語言微調模型。系統會自動檢測域指令的語言並相應地生成合成數據。我們還建議為目標語言選擇合適的底座模型。例如，如果針對德語域，則應選擇“jina-embeddings-v2-base-de”作為底座模型。",answer7:"不，我們的微調 API 僅支持 Jina v2 模型。",answer8:"在微調過程結束時，系統會使用保留的測試集評估模型並報告性能指標。您將收到一封電子郵件，詳細説明此測試集的前後性能。我們還鼓勵您在自己的測試集上評估模型以確保其質量。",answer9:"該系統通過將您提供的目標域指令與大模型智能體的推理相結合來生成合成數據。它會產生具有挑戰的三元組，這對於訓練高質量的向量模型模型至關重要。有關更多詳細信息，請參閲我們即將在 Arxiv 上發表的研究論文。",question1:"微調 API 的費用是多少？",question10:"我可以對我的微調模型和合成數據保持私密嗎？",question11:"如何使用微調模型？",question12:"我從未收到包含評估結果的電子郵件。我該怎麼辦？",question2:"我需要輸入什麼？我需要提供訓練數據嗎？",question3:"微調一個模型需要多長時間？",question4:"微調後的模型存儲在哪裏？",question5:"如果我提供一個參考 URL，系統將如何使用它？",question6:"我可以針對特定語言微調模型嗎？",question7:"我可以微調非 Jina 向量模型嗎，例如 bge-M3？",question8:"如何保證微調模型的質量？",question9:"如何生成合成數據？",title:"自微調相關常見問題"},find_on_hf:"列出微調模型",temporarily_unavailable:"暫時不可用。我們正在升級自動微調系統，以便為您提供更好的服務。請稍後再查看。",test_on:"已對來自 {_dataName} 的 {_dataSize} 個隨機樣本進行測試",test_performance_before_after:"微調前後在保留測試集上的表現",title:"自微調 API",total_improve:"平均改善",usage:"用法",what_is:"什麼是自微調？",what_is_answer_long:"微調允許您採用預先訓練的模型，並通過在新的數據集上進行訓練來使其適應特定任務或領域。實際上，對於許多用户來説，找到有效的訓練數據並不是一件容易的事。有效的訓練不僅僅需要將原始 PDF、HTML 放入模型中；而且很難做到正確。自微調通過使用高級大模型智能體管道自動生成有效的訓練數據來解決此問題；並在 ML 工作流中微調模型。您可以將其視為合成數據生成和 AutoML 的組合，因此您需要做的就是用自然語言描述您的目標域，然後讓我們的系統完成剩下的工作。"},r={auth_required:"使用頭像生成需要身份驗證",classificationError:"對圖片進行分類時出錯。請重試。",clickToDownload:"點擊下載 SVG",customize:"自定義功能",description:"生成具有可定製功能的獨特頭像",downloadError:"下載頭像時出錯",downloadSuccess:"頭像下載成功",download_success:"頭像下載成功",error_loading:"無法加載頭像資源，請重試。",error_processing:"處理圖片時出錯",file_hint:"支持的格式：JPG、PNG、GIF、WebP",generate:"生成頭像",how_does_it_work:"它是如何工作的？",noImageSelected:"請先選擇圖片",select_file:"選擇肖像圖片文件",title:"頭像生成器",upload_description:"選擇要轉換為 base64 的圖片（256x256）",upload_title:"上傳圖片",usage:"頭像生成"},o="試用版",s={answer10:"我們為新用户提供免費試用，其中包含一千萬個可用於我們任何模型的詞元，並通過自動生成的 API 密鑰進行兑換。免費詞元用完後，用户可以通過“購買詞元”標籤頁輕鬆購買額外的詞元，用於 API 密鑰。",answer13:"不，失敗的請求不會扣除詞元。",answer14:"付款通過 Stripe 處理，支持多種付款方式，包括信用卡、Google Pay 和 PayPal，為您提供方便。",answer15:"是的，購買詞元后，發票將發送到與您的 Stripe 帳户關聯的電子郵件地址。",answer9:"我們的定價模型基於處理的詞元總數，允許用户靈活地在任意數量的句子中分配這些詞元，為不同的文本分析需求提供經濟高效的解決方案。",question10:"新用户可以免費試用嗎？",question13:"失敗的請求是否會扣除詞元？",question14:"接受哪些付款方式？",question15:"詞元購買後可以開具發票嗎？",question9:"API是根據句子的數量或請求的數量計費嗎？",title:"與計費相關的常見問題"},_={all:"全部",events:"活動",featured:"甄選",insights:"觀點","knowledge-base":"知識庫",latest:"最新的",press:"新聞稿",releases:"軟件更新","tech-blog":"技術文章"},d={caption:"探索《Re·Search》，由我們精心設計的年鑑，收錄了我們2024年最具影響力的研究和搜索底座模型。",order_now:"立即訂購"},l={api_free_trial:"免費 API 密鑰",api_paid:"付費 API 密鑰",api_paid_or_free:"您使用的是付費 API 密鑰還是免費試用密鑰？",are_you:"你是：",commercial_contact_sales:"此為商業性質。請聯繫我們的銷售團隊。",contact_sales_for_licensing:"聯繫我們的銷售團隊獲取許可。",csp_user:"您是否在 AWS 和 Azure 上使用我們的官方模型？",educational_teaching:"教育機構用它來教學嗎？",for_profit_internal_use:"盈利性公司在內部使用它嗎？",free_use:"您可以自由使用這些模型。",government_public_services:"政府實體使用它來提供公共服務？",is_use_commercial:"您的用途是商業用途嗎？",may_be_commercial_contact:"這可能是商業用途。請聯繫我們進行澄清。",no:"不",no1:"不",no2:"不",no3:"不",no_restrictions:"無限制。請按照當前協議使用。",no_restrictions_apply:"沒有限制。",non_commercial_free_use:"本模型非商業性質，您可以自由使用。",non_profit_ngo_mission:"非營利組織或非政府組織是否利用它來完成你的使命？",not_sure:"沒有把握",personal_hobby_projects:"將其用於個人項目或者業餘愛好項目？",product_service_sale:"在您銷售的產品或服務中使用它嗎？",title:"CC BY-NC 許可證自檢",trial_key_restrictions:"免費試用密鑰僅可用於非商業用途。如需商業用途，請購買付費套餐。",typically_non_commercial_check:"這通常是非商業性的，但如果不確定，請與我們聯繫。",typically_non_commercial_free_use:"這通常是非商業性的。您可以自由使用這些模型。",using_api_or_cloud:"您是否使用我們的官方 API 或在 Azure 或 AWS 上我們的官方鏡像？",using_cc_by_nc_models:"你正在使用這些模型嗎？",yes:"是的",yes1:"是的",yes2:"是的",yes3:"是的"},c={access:"公共訪問",access_explain:"任何擁有 <code>classifier_id</code> 的人都可以使用公共分類器，並且它們的使用將消耗調用者的詞元配額，而不是您的。私有分類器只能由您訪問。",access_private:"私人的",access_public:"民眾",api_delete:"刪除分類器",api_delete_explain:"根據分類器ID刪除分類器。",api_list:"列表分類器",api_list_explain:"列出您已創建的所有分類器。",classifier_id:"分類器 ID",classify_inputs:"要分類的輸入",classify_inputs_explain:"對於文本，它可以是最多 8192 個詞元的句子。對於圖片，它可以是 URL 或 base64 編碼的圖片。",classify_labels:"候選標註",classify_labels_explain:"輸入將被歸類到這些類別中。最多可以有 256 個類別。使用帶語義類別可獲得更好的性能。",compare_table:{access_control:"訪問控制",classifier_id_required:"必需分類器 ID",continuous_updates:"持續模型更新",default_solution:"一般分類問題的默認解決方案",feature:"特點",few_shot:"少量樣本",image_multi_lingual_support:"多模態和多語言支持",labels_required_classify:"/classify 中需要的標註",labels_required_train:"/train 中需要的標註",max_classes:"最大類數",max_classifiers:"最大分類器",max_inputs_request:"每個請求的最大輸入",max_token_length:"每個輸入的最大詞元長度",na:"不適用",no:"不",out_of_domain_solution:"對於 v3/clip-v1 域之外的數據或時間敏感的數據",primary_use_case:"主要用例",semantic_labels_required:"需要語義標註",state_management:"狀態管理",stateful:"有狀態",stateless:"無狀態",token_count:"{count} 個詞元",training_data_required:"需要訓練數據",yes:"是的",zero_shot:"零樣本"},create_classifier:"新的少樣本分類器",create_classifier_explain:"創建一個新的小樣本分類器並使用訓練樣本對其進行訓練。",description:"圖片和文本的零樣本和少樣本分類。",description_long:"試用我們的 API 沙盒實驗場來了解我們的分類器如何工作。",description_long1:"針對多模態和多語言數據的高性能零樣本和少樣本分類器。",explain:"分類器是一種 API 服務，它使用向量模型 (<code>jina-embeddings-v3</code> 和 <code>jina-clip-v1</code>) 對文本和圖片進行分類，支持無需訓練數據的零樣本分類和使用最少示例的少樣本學習。",faq_v1:{answer1:"零樣本分類需要語義標籤，訓練時不需要，而少樣本分類則需要訓練時需要標籤，但分類時不需要。這意味着零樣本分類更適合靈活、即時的分類需求，而少樣本分類更適合固定的、特定領域的類別，這些類別可以隨時間而演變。",answer10:"是的，您可以選擇 <code>jina-embeddings-v3</code> 進行文本分類（特別適合多語言）和 <code>jina-clip-v1</code> 進行多模態分類。新模型（如 <code>jina-clip-v2</code>）將在發佈時通過 API 自動提供。",answer2:"<code>num_iters</code> 控制訓練強度 - 較高的值會強化重要示例，而較低的值會最大限度地減少不太可靠數據的影響。它可用於通過為近期示例提供更高的迭代次數來實現時間感知學習，這使其對於不斷髮展的數據模式很有價值。",answer3:"任何擁有 <code>classifier_id</code> 的人都可以使用公共分類器，並消耗自己的詞元配額。用户無法訪問訓練數據或配置，也無法查看其他人的分類請求，從而實現安全的分類器共享。",answer4:"少量樣本需要 200-400 個訓練樣本才能超越零樣本分類。雖然它最終會實現更高的準確率，但需要這段預熱期才能發揮作用。零樣本無需訓練數據即可立即提供一致的性能。",answer5:"是的 - API 支持使用 <code>jina-embeddings-v3</code> 進行多語言查詢和使用 <code>jina-clip-v1</code> 進行多模態（文本/圖片）分類，並支持在同一請求中對 URL 或 base64 編碼的圖片進行支持。",answer6:"Zero-shot 支持 256 個類別，沒有分類器限制，而 few-shot 則限制為 16 個類別和 16 個分類器。兩者均支持每個請求 1,024 個輸入和每個輸入 8,192 個詞元。",answer7:"少量樣本模式允許通過 <code>/train</code> 端點進行持續更新，以適應不斷變化的數據模式。當數據分佈發生變化時，您可以逐步添加新的示例或類別，而無需重建整個分類器。",answer8:"該 API 使用一次性在線學習 - 訓練示例會更新分類器權重，但之後不會存儲。這意味着您無法檢索歷史訓練數據，但它可以確保隱私和資源效率。",answer9:"當您需要使用語義標籤進行靈活分類時，請從零樣本開始，以獲得即時結果。當您有 200-400 個示例、需要更高的準確度或需要處理特定領域/時間敏感的數據時，請切換到少樣本。",question1:"零樣本和小樣本的標籤有何不同？",question10:"我可以針對不同的語言/任務使用不同的模型嗎？",question2:"num_iters 有什麼用處以及如何使用它？",question3:"公共分類器共享如何工作？",question4:"我需要多少數據才能使小樣本研究發揮良好作用？",question5:"它能處理多種語言和文本/圖片嗎？",question6:"我應該瞭解哪些硬性限制？",question7:"我該如何處理隨時間而發生的數據變化？",question8:"我發送訓練數據後會發生什麼情況？",question9:"零樣本與小樣本——何時使用哪個？",title:"分類器相關常見問題"},more:"更多",num_iters:"訓練迭代",num_iters_explain:"控制訓練強度 - 較高的值可提高當前示例的準確性，但會增加詞元成本。默認值 10 通常效果很好。",read_notes:"讀取發行説明",select_classifier_or_model:"選擇分類器或向量模型",task_classify:"分類",task_classify_explain:"使用零樣本或少樣本分類器將文本或圖片分類到定義的類別中。",task_manage:"管理",task_manage_explain:"列出或刪除你的小樣本分類器。",task_select:"選擇任務",task_train:"訓練",task_train_explain:"使用訓練樣本創建或更新少量分類器。",title:"分類器 API",train_inputs:"訓練數據",train_inputs_explain:"用於訓練的帶有標籤的文本或圖片示例。您可以隨着時間的推移使用新示例和標籤逐步更新分類器。",train_label:"標籤",what_is:"什麼是分類器？",when_to_use_what:"何時使用零樣本或小樣本？",when_to_use_what_explain:"使用零樣本分類作為默認解決方案，可以在最多 256 個類別的一般分類任務中獲得即時結果，而少樣本學習更適合處理向量模型知識之外的特定領域數據，或者需要處理需要持續模型更新的時間敏感數據。"},p={description:"使用 CLIP 將圖片和文本向量到固定長度的向量中"},u={description:"多模態AI應用的雲託管平台"},m={agreement:"提交即表示您確認同意 Jina AI 按照以下規定處理您的個人數據",anything_else:"告訴我們更多關於你的想法",cc_by_nc:"請求 CC BY-NC 模型的商業使用",cc_by_nc_description:"我們的最新模型通常採用 CC BY-NC 許可。如需商業使用，請通過我們的 API、Azure Marketplace 或 AWS SageMaker 訪問它們。如需在這些渠道之外進行本地使用，請勾選此框。",company:"組織",company_size:"組織規模",company_website:"組織網站",company_website_placeholder:"您公司主頁或 LinkedIn 個人資料的 URL",country:"國家",department:"部門",description:"與 Jina AI 一起拓展您的業務。",drop_area_for_image:"將圖片拖放到此處",faq:"常見問題",feedback_sent:"已提交！我們將盡快回復您。",field_required:"字段為必填項",get_api_key:"如何獲取我的 API 密鑰？",image_upload:"附加圖片",image_validate:"您最多可以附加 {_num} 張圖片。僅限 JPG、JPEG、PNG、WEBP。",impact_snapshots:"實際案例",invalid_date_format:"日期格式無效。請使用 DD-MM-YYYY 格式。",invalid_email:"電子郵件無效",invalid_number:"無效數字。請再次輸入",invalid_url:"網址無效",name:"姓名",nc_check:"我需要商業許可證嗎？",other_questions:"其他問題",preferred_models:"您對哪些模型感興趣？",preferred_products:"您對哪些產品感興趣？",premium_key:"高級 API 密鑰",pricing:"定價？",priority:"優先支持付費用户",private_statement:"隱私聲明",rate_limit:"速率限制是多少？",role:"職業角色",self_check:"自檢",sending_feedback:"正在發送...",shortcut:"捷徑",standard_key:"標準 API 密鑰",submit:"提交",submit_failed:"提交失敗。請稍後再試。",submit_success:"感謝您提交。我們會盡快給您回覆。",subtitle:"Jina AI 是多模態 AI 領域的領導者，擅長模型調優、模型服務、提示詞調優部署。利用 Kubernetes 和無服務器架構等雲原生技術，我們提供強大、可擴展且可立即投入生產的解決方案。憑藉大語言模型、文本、圖片、視頻、音頻理解、神經搜索和生成藝術方面的專業知識，我們提供創新、面向未來的策略來提升您的業務。",subtitle1:"Jina AI 是多模態 AI 領域的領導者，擅長大模型向量調優和部署、提示詞調優和部署。利用 Kubernetes 和無服務器架構等雲原生技術，我們提供強大、可擴展且可立即投入生產的解決方案。憑藉大語言模型、文本、圖片、視頻、音頻理解、神經搜索和生成式AI方面的專業知識，我們提供創新、面向未來的策略來提升您的業務。",subtitle2:"瞭解多模態AI最前沿的Jina AI。我們擅長向量化和提示詞技術，利用 Kubernetes 等雲原生解決方案來構建強大、可擴展的系統。我們專注於大型語言模型和媒體處理，利用先進的人工智能專業知識提供創新、面向未來的業務戰略。",title:"聯繫銷售",trusted_by:"我們值得信賴",turn_on_volume:"調高音量",work_email:"工作郵箱"},g="複製",A="已複製到剪貼板",b={description:"用於從文本創建高清圖片的人機交互工作流程"},h={api_endpoint:"API 端口",api_key:"API 密鑰",api_tagline:"與 OpenAI 的聊天 API 模式完全兼容，只需將 <code>api.openai.com</code> 與 <code>deepsearch.jina.ai</code> 交換即可開始。",api_title:"深度搜索 API",assistant_message:"助手",chat_ui:{api_key_required:"需要 API 密鑰！",clear_context_message:"您確定要清除上下文嗎？這將重置對話。",clear_context_title:"新聊天？",description:"在簡單的聊天界面中看看深度搜索地不地道。深度搜索最適合需要迭代推理、世界知識或最新信息的複雜問題。",example_q1:"OpenAI 的最新博客寫的什麼？",example_q2:"node-DeepResearch 項目背後的都動機是什麼？",example_q3:"jina-colbert-v2 相對於 jina-colbert-v1 究竟有哪些改進？",input_cant_be_empty:"輸入不能為空",input_placeholder:"在這裏輸入您的問題",keyman:"密鑰管理器",move_to_new:"我們剛剛推出了一款全新的深度搜索UI，它速度快、簡潔且免費。請訪問 https://search.jina.ai 查看或單擊下面的按鈕嘗試一下！",new_chat:"清除當前聊天並開始新對話",new_url:"訪問新 UI",payment_required:"您的 API 密鑰中剩餘的詞元額度不足。如果您有多個 API 密鑰，您可以切換到密鑰管理器中詞元額度充足的密鑰。否則，您可以充值 API 密鑰以繼續。",purchase:"充值API密鑰",rate_limit_exceeded:"您已超出速率限制。請稍後重試，或使用您的 API 密鑰獲取更高的速率限制。",stay:"保留經典演示 UI",thinking:"正在思考...",thinking_done:"思維鏈",title:"深度搜索聊天",use_user_key:"使用您的 API 密鑰來獲取更高的速率限制。"},client_3p:"聊天客户端",client_3p_explain:"為了獲得最佳體驗，我們建議使用專業的聊天客户端。深度搜索 與 OpenAI 的聊天 API 架構完全兼容，因此可以輕鬆與任何兼容 OpenAI 的客户端一起使用。",comparison:{group1:{bestFor:"常識問題的快速答案",feature1:"答案完全由預先訓練的知識生成，具有固定的截止日期",limitations:"無法獲取實時或訓練後的信息",timeCost:"約1秒",title:"大模型",tokenCost:"約 1000 個詞元"},group2:{bestFor:"需要當前或特定領域信息的問題",feature1:"通過彙總單次搜索結果生成的答案",feature2:"能夠獲取訓練截止時間以外的當前信息",limitations:"解決需要多跳推理的複雜問題",timeCost:"約 3 秒",title:"RAG範式和帶搜索的大模型",tokenCost:"約 10,000 個詞元"},group3:{bestFor:"需要深入研究和推理的複雜問題",feature1:"自主智能體，可反覆搜索、讀取和推理",feature2:"根據當前發現動態決定下一步行動",feature3:"在返回結果之前自我評估答案質量",feature4:"可以通過多次搜索和推理循環深入研究主題",limitations:"比簡單的大模型或 RAG 方法花費的時間更長",timeCost:"約50秒",title:"深度搜索",tokenCost:"約 500,000 個詞元"}},demo:"與深度搜索聊天",demo_description:"在簡單的聊天界面裏看看深度搜索地不地道。深度搜索最適合需要迭代推理、世界知識或最新信息的複雜問題。",description:"搜索、讀取並推理直到找到最佳答案。",explain:"深度搜索結合了網絡搜索、讀取和推理，可進行全面調查。您可以將其視為一個代理，接受您的研究任務 - 它會進行廣泛搜索並經過多次迭代，然後給出答案。",faq:{answer1:"深度搜索是一個大模型API，它執行迭代搜索、讀取和推理，直到找到查詢的準確答案或達到其詞元預算限制。",answer10:"速率限制因 API 密鑰層而異，範圍從 10 RPM 到 30 RPM。對於查詢量大的應用程序來説，這一點很重要。",answer11:"深度搜索將思考步驟包裝在 XML 標籤 <think>...</think> 中，然後提供最終答案，遵循 OpenAI 流格式，但使用這些特殊標記來表示思路鏈。",answer12:"是的。Jina Reader 用於網頁搜索和讀取，為系統提供高效訪問和處理網頁內容的能力。",answer14:"是的，深度搜索在複雜查詢中的詞元使用量可以説很高 - 平均為 70,000 個詞元，而基本大模型響應為 500 個詞元。這顯示了研究的深度，但也影響了成本。",answer18:"該系統主要由詞元預算而非步數控制。一旦超出詞元預算，系統就會進入 Beast 模式以生成最終答案。查看 <code>reasoning_effort</code> 瞭解更多詳情。",answer19:"參考文獻非常重要，如果一個答案被認為是明確的，但缺乏參考文獻，系統會繼續搜索而不是接受該答案。",answer2:"與 OpenAI 和 Gemini 不同，深度搜索專注於通過迭代提供準確的答案，而不是生成長篇文章。它針對深度網絡搜索的快速、精確答案進行了優化，而不是創建全面的報告。",answer20:"是的，但需要進行大量的研究。“誰將在 2028 年成為總統”的例子表明，它可以通過多次研究迭代來處理推測性問題，儘管這種預測的準確性無法得到保證。",answer3:"您需要 Jina API 密鑰。我們為新 API 密鑰提供 1000 萬個免費詞元。",answer5:"它根據所有積累的知識生成最終答案，而不是僅僅放棄或返回不完整的答案。",answer6:"不是。雖然它使用迭代搜索過程來提高準確性，但評估顯示它在測試題目上的通過率達到了 75％，明顯優於 0％ 的基線（gemini-2.0-flash），但並不完美。",answer7:"它差別很大 - 根據評估數據，查詢可能需要 1 到 42 步，平均需要 4 步。也就是 20 秒。簡單的查詢可能很快得到解決，而複雜的研究問題可能涉及多次迭代，最多需要 120 秒。",answer9:"是的，deepsearch.jina.ai/v1/chat/completions 上的官方深度搜索API 與 OpenAI API 架構完全兼容，使用“jina-deepsearch-v1”作為模型名稱。因此，從 OpenAI 切換到深度搜索並與本地客户端或任何兼容 OpenAI 的客户端一起使用非常容易。我們強烈推薦 Chatwise 以獲得無縫體驗。",question1:"什麼是深度搜索？",question10:"API 的速率限制是多少？",question11:"<think>標籤裏面的內容是什麼？",question12:"深度搜索是否使用 Jina Reader 進行網頁搜索和讀取？",question14:"為什麼深度搜索對我的查詢使用這麼多標記？",question18:"有沒有辦法控制或限制步數？",question19:"答案中的參考文獻有多可靠？",question2:"深度搜索與 OpenAI 和 Gemini 的深度研究能力有何不同？",question20:"深度搜索能處理有關未來事件的問題嗎？",question3:"我需要什麼 API 密鑰來使用 DeepResearch？",question5:"當深度搜索達到其詞元預算時會發生什麼？它會返回不完整的答案嗎？",question6:"深度搜索能保證答案的準確性嗎？",question7:"一次典型的深度搜索查詢需要多長時間？",question9:"深度搜索可以與任何與 OpenAI 兼容的客户端（如 Chatwise、CherryStudio 或 ChatBox）配合使用嗎？",title:"深度搜索相關常見問題"},last_chunk:"這是流的最後一部分，其中包含最終答案、訪問過的 URL 和詞元使用情況。單擊上面的按鈕可獲取實時響應。",learn_more:"瞭解更多",message:"消息",message_type:"附加圖片/文檔",message_type_explain:"支持不同的消息類型（模態），如文本（.txt、.pdf）、圖片（.png、.webp、.jpeg）。支持的文件最大為 10MB，並且必須預先編碼為數據 URI。",messages:"消息",messages_explain:"用户和助手之間迄今為止的對話的消息列表。",model:"模型",model_explain:"要使用的模型的 ID。",model_name:"模型名稱",open:"打開",parameters:{auth_token:"@:tokenizer.parameters.auth_token",auth_token_explain:"深度搜索API 可免費使用。通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會向您的密鑰收費。",bad_hostnames:"不良域名",bad_hostnames_explain:"嚴格排除在內容檢索之外的域列表。通常用於過濾已知的垃圾、低質量或不相關的網站。",boost_hostnames:"優質域名",boost_hostnames_explain:"內容檢索優先級較高的域列表。對於提供有價值內容的特定域的高質量來源很有用。",budget_tokens:"詞元預算",budget_tokens_explain:"這決定了深度搜索流程允許使用的最大詞元數。更大的預算可以通過對複雜查詢啓用更詳盡的搜索來提高響應質量，儘管深度搜索可能不會使用分配的全部預算。這會覆蓋 <code>reasoning_effort</code> 參數。",high_explain:"最大程度地推理和搜索複雜查詢 (單次請求最多兩百萬詞元)","jina-deepsearch-v1_explain":"通過迭代搜索給出簡潔的答案",json_schema:"結構化輸出",json_schema_explain:"這將啓用結構化輸出，確保模型的最終答案與您提供的 JSON 模式相匹配。",language_code:"回答/思考語言",language_code_explain:"強制指定答案的語言，並使用給定的語言代碼進行思考。默認情況下，答案的語言會自動根據輸入消息的主要語言確定。答案的質量可能會受到語言的細微影響。",low_explain:"基本推理和搜索簡單查詢（單次請求最多五十萬詞元）",max_attempts:"最大嘗試次數",max_attempts_explain:"深度搜索過程中解決問題（及其所有子問題）的最大重試次數。較大的值允許深度搜索使用不同的推理方法和解決策略重試解決問題。此參數會覆蓋 <code>reasoning_effort</code> 參數。",max_returned_urls:"最大返回 URL",max_returned_urls_explain:"最終答案/塊中包含的最大 URL 數量。URL 按相關性和其他重要因素排序。",medium_explain:"中等推理和搜索深度 (單次請求最多一百萬詞元)",model:"@:deepsearch.model",model_explain:"@:deepsearch.model_explain",no_direct_answer:"不要直接回答",no_direct_answer_explain:"開啓後，即使用户的問題非常簡單，也會強制模型採取進一步的思考/搜索步驟。僅在您已經非常確定輸入的問題始終需要進行深度搜索的情況下使用，即您的輸入不可能包含“1+1=？吃了麼您?”之類的簡單、無意義、腦筋急轉彎似的問題時，開啓此功能很有用。",only_hostnames:"僅允許域名",only_hostnames_explain:"僅在允許的域名列表中搜索和閲讀。所有其他域都將被忽略。若給定域名無法訪問或根本不包含答案則讓深度搜索質量會顯著下降。",reasoning_effort:"@:deepsearch.reasoning_effort",reasoning_effort_explain:"@:deepsearch.reasoning_effort_explain",stream:"@:deepsearch.stream",stream_explain:"@:deepsearch.stream_explain"},reasoning_effort:"推理強度",reasoning_effort_explain:"限制推理模型的推理工作量。當前支持的值有低、中和高。減少推理工作量可以加快響應速度，並減少響應中用於推理的標記。",stream:"流式返回",stream_explain:"通過服務器發送的事件傳遞事件發生時的信息，包括推理步驟和最終答案。我們<b>強烈建議</b>保持此選項處於啓用狀態，因為深度搜索請求可能需要很長時間才能完成。禁用流式傳輸可能會導致“524 超時”錯誤。",tagline:"@:deepsearch.description",title:"深度搜索",type_file:"附加文件",type_image:"附加圖片",type_text:"純文本消息",user_message:"用户",what_is:"什麼是深度搜索？"},I={description:"用一行代碼創建引人注目的 Disco Diffusion 藝術作品"},k={description:"多模態數據的數據結構"},v="下載 SOC 2 類型 1 證明",y={"11B tokens":"壹佰壹拾億","11B tokens_intuition1":"類似於讀取維基百科上的所有英文文章。","11B tokens_targetUser":"生產部署","1B tokens":"拾億","1B tokens_intuition1":"大概和讀完莎士比亞全集和整個《哈利波特》系列是一樣的。","1B tokens_targetUser":"原型開發","1M tokens":"壹仟萬","1M tokens_intuition1":"相當於讀完了《霍比特人》和《了不起的蓋茨比》的全部文本。","1M tokens_targetUser":"簡單嘗試","1M_free":"免費千萬詞元隨心用","1M_free_description":"在您的API密鑰上直接使用贈送的免費詞元，無需註冊或信用卡。","2_5B tokens":"2.5B 詞元","2_5B tokens_intuition1":"相當於把電影《指環王》三部曲裏説的每一個字都抄錄1000遍。","3p_integration":"擁有 <b>{_numPartners}</b> 家第三方服務","3p_integration_desc":"將我們的搜索底座與您現有的服務相集成。我們的合作伙伴已經打通了與我們 API 的連接，讓您可以輕鬆地在應用程序中使用我們的模型。","500M tokens":"500M 詞元","500M tokens_intuition1":"類似於觀看《辛普森一家》從第 1 季到第 30 季的每一集。","59B tokens":"59B 詞元","59B tokens_intuition1":"相當於兩天內全球發佈的所有推文。","5_5B tokens":"5.5B 詞元","5_5B tokens_intuition1":"相當於讀取大英百科全書的全部內容。",Free1M:"1000萬個詞元","ReaderLM-v2_description":"用於將原始 HTML 轉換為 markdown 或 JSON 的小型語言模型",add_pair:"新建",add_time_explain:"此模型被添加到搜索底座的時間。",api_integration_short:"在流行數據庫、向量數據庫、RAG 和 LLMOps 框架輕鬆使用我們的向量模型API。",api_integrations:"API集成",api_key_update_message:"通過替換舊 API 密鑰，新密鑰將在您每次訪問 jina.ai 時顯示在 UI 中。未來的充值將適用於此新密鑰。您的舊密鑰仍然有效，因此如果您打算再次使用它，請安全保存。",api_key_update_title:"更換 API 密鑰",auto_recharge:"詞元餘額不足時自動充值",auto_recharge_confirm_message:"您確定要禁用自動充值嗎？當您的詞元餘額不足時，這將停止自動充值，並可能中斷您的服務或應用程序。",auto_recharge_confirm_title:"禁用自動充值",auto_recharge_description:"建議用於生產環境不間斷的服務。當您的詞元餘額低於設定的閾值時，我們將使用您保存的支付方式自動為您充值上次購買的套餐，直到達到閾值。",auto_recharge_enable:"您已啓用自動充值",auto_recharge_enable_message:"要啓用自動充值，請在購買套餐時打開自動充值開關。",auto_recharge_enable_message2:"請選擇自動充值時需要購買的套餐。",auto_recharge_enable_title:"啓用自動充值",auto_request:"自動預覽",auto_request_tooltip:"使用 API 密鑰中的數百個詞元，在更改模型時自動預覽 API 響應。關閉後，單擊“獲取響應”即可手動發送請求。",autostart:"向量化將自動開始",base64_description:"向量以 base64 編碼的字符串形式返回。傳輸效率更高。",batch_job:"批處理",batch_upload_hint:"我們將使用如下的 API 密鑰和模型來批處理。","bge-base-en-v1_5_description":"一種強大的英語模型，平衡了性能和效率，適合多種用途。","bge-base-en_description":"平衡的英語模型，旨在實現可靠的性能。","bge-base-zh-v1_5_description":"全面平衡能力與效率的中國模式。","bge-base-zh_description":"集效率與強勁性能於一身的多功能中國車型。","bge-large-en-v1_5_description":"強大的英語模型，提供具有卓越品質的頂級向量。","bge-large-en_description":"專為優質向量而打造的頂級英語模型。","bge-large-zh-v1_5_description":"提供卓越且詳細向量的高容量中文模型。","bge-large-zh_description":"針對頂級向量優化的高性能中文模型。","bge-m3_description":"一種多功能多語言模型，提供廣泛的功能和高質量的向量。","bge-small-en-v1_5_description":"精簡的英語模型，提供高效、高質量的向量。","bge-small-en_description":"一種高效的英語模型，用於簡化和準確的向量。","bge-small-zh-v1_5_description":"緊湊的中國模型，提供靈活、精確的向量。","bge-small-zh_description":"一種敏捷的中國模型，用於高效、精確的向量。",binary_description:"向量被打包為 int8。存儲、搜索和傳輸效率更高。",bulk:"批處理",bulk_embedding_failed:"創建批處理失敗",buy_more_quota:"使用更多詞元充值此 API 密鑰",buy_poster:"購買海報",cancel_button:"取消",click_upload_btn_above:"單擊上面的上傳按鈕即可開始。",clip_v2_description:"jina-clip-v2 是一個 0.9B CLIP 風格模型，它帶來了三大進步：對 89 種語言的多語言支持、512x512 的高圖片分辨率和用於截斷向量的 Matryoshka 表示學習。",clip_v2_title:"clip-v2：多語言多模態向量",code:"代碼",colbert_dimensions_explain:"每個詞元向量的維度大小。",compatible:"兼容模式",compatible_explain:"遵循與我們的文本向量模型相同的請求格式。這允許您在不更改請求的情況下在模型之間切換。請注意，此模式下不支持圖片輸入。",contact_sales:"聯繫銷售人員",contact_sales_description:"與我們的銷售團隊聯繫",cosine_similarity:"餘弦相似度",daily_view:"每日視圖",debugging:"測試",delete_pair:"刪除",description:"@:landing_page.embedding_desc1",dimensions:"輸出維度",dimensions_error:"尺寸大小必須介於 1 到 1024 之間。",dimensions_explain:"較小的尺寸可以實現高效的存儲和檢索，並且由於採用了 Matryoshka 表示法，影響最小。",dimensions_warning:"為了提高性能，我們建議將尺寸大小保持在 {_minDimension} 以上。",document:"文檔",download:"下載",edit_text1_text:"編輯左側文字",edit_text2_text:"編輯右側文字",embedding_done:"成功向量化{_Count}個句子。",embedding_none_description:"不要使用任何向量模型",example_inputs:"示例輸入",export_csv:"導出為 CSV",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"有關我們的訓練過程、數據源和評估的詳細信息，請參閲 arXiv 上提供的技術報告。",answer1:"Jina CLIP <code>jina-clip-v2</code> 是一種先進的多模態向量模型，支持文本-文本、文本-圖片、圖片-圖片和圖片-文本檢索任務。與在文本-文本搜索方面表現不佳的原始 OpenAI CLIP 不同，Jina CLIP 在文本檢索方面表現出色。<code>jina-clip-v2</code> 在文本-圖片和文本-文本檢索任務中比 <code>jina-clip-v1</code> 的性能提高了 3%，支持 89 種語言進行多語言圖片檢索，處理更高分辨率的圖片（512x512），並通過 Matryoshka 表示降低存儲要求。您可以在我們的技術報告中讀取更多相關信息。",answer17:"是的，<code>jina-clip-v2</code> 和 <code>jina-clip-v1</code> 可以支持圖片和文本。更多模態上的向量模型將很快公佈！",answer18:"有關使用特定數據微調我們的模型的疑問，請聯繫我們討論您的要求。我們願意探索如何調整我們的模型來滿足您的需求。",answer19:"是的，我們的服務在 AWS、Azure 和 GCP 市場上可用。如果您有特定要求，請通過 sales AT jina.ai 聯繫我們。",answer3:"截至 2024 年 9 月 18 日發佈，<code>jina-embeddings-v3</code> 是最好的多語言模型，在參數少於 10 億的模型的 MTEB 英語排行榜上排名第二。v3 共支持 89 種語言，包括性能最佳的前 30 種語言：阿拉伯語、孟加拉語、中文、丹麥語、荷蘭語、英語、芬蘭語、法語、格魯吉亞語、德語、希臘語、印地語、印尼語、意大利語、日語、韓語、拉脱維亞語、挪威語、波蘭語、葡萄牙語、羅馬尼亞語、俄語、斯洛伐克語、西班牙語、瑞典語、泰語、土耳其語、烏克蘭語、烏爾都語和越南語。有關更多詳細信息，請參閲 <code>jina-embeddings-v3</code> 技術報告。",answer4:"我們的模型允許輸入長度高達 8192 個詞元，這比大多數其他模型高得多。詞元的範圍可以從單個字符（如“a”）到整個單詞（如“apple”）。可以輸入的字符總數取決於所用單詞的長度和複雜性。這種擴展的輸入功能使我們的 <code>jina-embeddings-v3</code> 和 <code>jina-clip</code> 模型能夠執行更全面的文本分析，並在上下文理解方面實現更高的準確性，尤其是對於大量文本數據。",answer5:"一次 API 調用最多可以處理 2048 個句子或文本，從而有助於在一次請求中進行廣泛的文本分析。",answer6:"您可以在 API 請求的 <code>input</code> 字段中使用 <code>url</code> 或 <code>bytes</code>。對於 <code>url</code>，請提供要處理的圖片的 URL。對於 <code>bytes</code>，請以 base64 格式對圖片進行編碼並將其包含在請求中。模型將在結果中返回圖片的向量。",answer7:"在 MTEB 英語、多語言和 LongEmbed 基準的評估中，<code>jina-embeddings-v3</code> 在英語任務上的表現優於 OpenAI 和 Cohere 的最新專有向量模型，並在所有多語言任務中超越 <code>multilingual-e5-large-instruct</code>。由於集成了 Matryoshka 表示學習 (MRL)，默認輸出維度為 1024，用户可以將向量維度截斷為 32，而不會影響性能。",answer8:"遷移過程十分順暢，因為<a class='text-primary' href='https://api.jina.ai/v1/embeddings'>我們的 API 端點</a>與 OpenAI 的 <code>text-embedding-3-large</code> 模型的輸入和輸出 JSON 架構相匹配。這種兼容性確保用户在使用 OpenAI 端點時可以輕鬆地將 OpenAI 模型替換為我們的模型。",answer9:`詞元是根據文本長度和圖片大小計算的。對於請求中的文本，詞元以標準方式計算。對於圖片，執行以下步驟：

1. 圖塊大小：每個圖片被分成圖塊。對於 <code>jina-clip-v2</code>，圖塊為 512x512 像素，而對於 <code>jina-clip-v1</code>，圖塊為 224x224 像素。
2. 覆蓋率：計算覆蓋輸入圖片所需的圖塊數量。即使圖片尺寸不能被圖塊大小完全整除，部分圖塊也會被視為完整圖塊。
3. 總圖塊數：覆蓋圖片的圖塊總數決定了成本。例如，600x600 像素的圖片在 v2 中將被 2x2 圖塊（4 個圖塊）覆蓋，在 v1 中將被 3x3 圖塊（9 個圖塊）覆蓋。
4. 成本計算：對於 <code>jina-clip-v2</code>，每個圖塊的成本為 4000 個詞元，而對於 <code>jina-clip-v1</code>，每個圖塊的成本為 1000 個詞元。

示例：
對於尺寸為 600x600 像素的圖片：

• 使用 <code>jina-clip-v2</code>
• 圖片被分成 512x512 像素圖塊。
• 所需的圖塊總數為 2（水平）x 2（垂直）= 4 個圖塊。
• <code>jina-clip-v2</code> 的成本為 4*4000 = 16000 個詞元。

• 使用 <code>jina-clip-v1</code>
• 圖片被分成 224x224 像素圖塊。
• 所需的圖塊總數為 3（水平）x 3（垂直）= 9 塊圖塊。
• jina-clip-v1 的成本為 9*1000 = 9000 個詞元。`,question0:"jina-embeddings-v3 模型是如何訓練的？",question1:"jina-clip 模型是什麼？我可以使用它們進行文本和圖片搜索嗎？",question17:"你們提供向量模型圖片或音頻的模型嗎？",question18:"Jina 向量模型模型可以使用私人或公司數據進行微調嗎？",question19:"您的服務可以在 AWS、Azure 或 GCP 上私有化部署嗎？",question3:"你們的模型支持哪些語言？",question4:"單個句子輸入的最大長度是多少？",question5:"單個請求中最多可以包含多少個句子？",question6:"如何將圖片發送給 jina-clip 模型？",question7:"Jina Embeddings 模型與 OpenAI 和 Cohere 的最新向量模型相比如何？",question8:"如何從 OpenAI 的 text-embedding-3-large 遷移到 Jina Embeddings 模型？",question9:"使用 jina-clip 模型時如何計算 token？",title:"向量模型相關的常見問題"},feature_8k1:"8192長度",feature_8k_description1:"世界首發的 8192 個詞元長度的開源向量模型，能夠把一整版人民日報壓縮成一個向量。",feature_cheap:"降本 50 倍",feature_cheap_v1:"5 倍降本",feature_cheap_v1_description1:"從免費試用開始，簡單的定價結構，快捷支付。只需 OpenAI 20% 的成本即可獲得強大的向量模型。",feature_multilingual:"提供德英、中英等雙語模型，出海企業適合跨語言應用必備。",feature_on_premises:"隱私第一",feature_on_premises_description1:"直接在您的虛擬私有云 (VPC) 中無縫部署我們的向量模型。輕鬆在 AWS Sagemaker上部署，即將與微軟Azure 和谷歌 Cloud Platform 集成。如需定製 Kubernetes 部署，請聯繫我們的銷售團隊尋求專業幫助。",feature_on_premises_description2:"您可以輕鬆在 AWS Sagemaker上部署我們的向量模型，我們很快將在微軟Azure和谷歌Cloud Services中提供支持。如需定製 Kubernetes 部署，請聯繫我們的銷售團隊尋求專業幫助。",feature_on_premises_description3:"在 AWS Sagemaker 和 Microsoft Azure 中部署 Jina Embeddings 模型，並很快在 Google Cloud Services 中部署，或者聯繫我們的銷售團隊，為您的虛擬私有云和本地服務器獲取定製的 Kubernetes 部署。",feature_on_premises_description4:"使用 AWS SageMaker、Microsoft Azure 或 Google Cloud Services 在本地部署 Jina Embedding 和 Reranker 模型，確保您的數據安全地處於您的控制之下。",feature_solid:"出類拔萃",feature_solid_description1:"基於我們實打實的AI科研工作，並與同類模型進行了嚴格對比測試，以確保模型的最佳性能。",feature_top_perform1:"無縫集成",feature_top_perform_description1:"與OpenAI的API完全兼容。輕鬆與 10 多個向量數據庫和 RAG 系統集成，提供流暢的開發者體驗。",file_required:"請上傳文件",file_size_exceed:"文件大小超過上限 {_size}",file_type_not_supported:"文件類型不支持",fill_example:"填寫示例",float_description:"向量以浮點數列表的形式返回。最常見且易於使用。",free:"免費",generate_api_key_error:"API 密鑰生成失敗。",generating_visualization:"生成可視化...",get_new_key_button:"獲取新密鑰",get_new_key_button_explain:"選擇新密鑰將導致與舊密鑰相關的使用歷史記錄丟失。",get_new_key_survey:"填寫調查問卷，幫助我們瞭解您的使用情況，並免費獲得新的 API 密鑰！",hourly_view:"每小時查看",includes:"購得詞元可在以下產品中使用：",index_and_search:"先索引再查詢",index_and_search1:"索引和搜索",input:"請求",input_api_key_error1:"您的 API 密鑰無效！",input_length:"輸入長度",input_type:"向量化文檔/查詢",input_type_explain:"根據搜索角色，相同的輸入可以作為查詢或文檔向量。",integrate:"集成","jina-clip-v1_description":"圖片和英文文本的多模態向量模型","jina-clip-v2_description":"文本和圖片的多語言多模態向量模型","jina-colbert-v1-en_description":"改進版的ColBERT模型支持8K長度的上下文，可用於向量化和重排任務","jina-colbert-v2_description":"最新的多語言ColBERT，在向量化和重排方面具有頂級性能","jina-embedding-b-en-v1_description":"Jina 向量模型的第一個版本，傳説中的OG。","jina-embeddings-v2-base-code_description":"針對代碼和技術文檔搜索的向量模型","jina-embeddings-v2-base-de_description":"支持德英雙語的 8K 最佳向量模型","jina-embeddings-v2-base-en_description":"與 OpenAI 的 text-embedding-ada002旗鼓相當","jina-embeddings-v2-base-es_description":"支持西英雙語的 8K 最佳向量模型","jina-embeddings-v2-base-zh_description":"支持中英雙語的 8K 最佳向量模型","jina-embeddings-v2-small-en_description":"針對低延遲和小內存進行了優化","jina-embeddings-v3_description":"最新、最好的向量化模型，在文本和代碼上均具有最佳性能","jina-reranker-m0_description":"用於對視覺文檔進行排名的多語言多模態重排器","jina-reranker-v1-base-en_description":"我們的第一個重排器最大化搜索和 RAG 相關性","jina-reranker-v1-tiny-en_description":"最快的重排器，適合對大量文檔進行可靠的排序","jina-reranker-v1-turbo-en_description":"速度與準確率的最佳權衡選擇","jina-reranker-v2-base-multilingual_description":"最先進的多語言文檔和查詢重排器，具有最佳的準確性和速度性能",key:"API密鑰",key_enter_placeholder:"請輸入您的 API 密鑰",key_enter_placeholder_to_topup:"輸入您要充值的 API 密鑰",key_to_top_up:"有其他 API 密鑰需要充值？粘貼上述內容並點擊“保存”。",key_warn:"請確保將您的 API 密鑰存儲在安全的地方。否則您將需要生成一個新密鑰",key_warn_v2:"這是您的專屬密鑰。請安全保存！",language_explain:"該模型對{_language}語言有最好的支持。",last_7_days:"用法",late_chunking:"後期分塊",late_chunking_explain:"應用後期分塊技術來利用模型的長上下文功能來生成上下文塊向量化。",learn_more:"瞭解更多",learn_poster:"瞭解海報",learning1:"學習向量模型",learning1_description:"什麼是向量，為什麼要向量化？我們已經為您提供了一些入門文章。通過我們的綜合指南從頭開始瞭解向量模型。",length:"長度",manage_billing:"管理發票",manage_billing_tip:"管理您的賬單信息、獲取發票並設置自動充值。",manage_quota1:"密鑰和計費",max_file_size:"最大允許的尺寸：{_maxSize}。",maximize_tooltip:"使用 Shift+1 最大化此面板",mistake_contact:"如果您認為這是一個錯誤，請聯繫我們。",mminput_placeholder:"文本、圖片URL、圖片base64字符串",model_required:"請選擇模型",more_models:"其他 {_numMore} 個模型",more_than_two2:"請輸入兩個以上的文檔，即兩行以上。",multi_embedding:"多向量",multi_embedding_explain:"該模型會給一個輸入返回一組向量。輸入句子中的每個詞元都被映射到單獨的一個向量。",multilingual:"多語言支持",multimodal:"多模態",multimodal_explain:"該模型可以對文本和圖片輸入進行編碼，使其成為多模態搜索任務的理想選擇。",new:"新模型",no_data1:"添加一對句子來計算相似度",none:"沒有任何",normalized:"L2 規範化",normalized_explain:"歸一化向量，使其歐幾里得 (L2) 範數變為 1，保持方向。當下遊涉及點積、分類、可視化時很有用。",oncsp:"關於 CSP",onprem:"私有化部署",open_tensorboard:"打開可視化工具",opensource:"開源",opensource_explain:"該模型是開源的，可從 Hugging Face 下載使用。單擊此按鈕可查看 Hugging Face 上的模型。",original_documents:"向量化的句子",original_documents_hint:"在此處輸入句子。每個新行將被視為一個單獨的句子/文檔。",output:"響應",output_dim:"輸出維度",output_dim_explain:"該模型輸出的向量維度為 {_outputDim}。",output_dimension:"輸出維度",pairwise_test:"成對測試",per_k:"每千個詞元",per_m:"每百萬詞元",please_fill_docs_first:"在搜索之前，請先在下面輸入一些句子。",please_select_model:"請選擇向量模型或重排器模型",poster:"向量模型70年",poster_description:"在您的辦公空間或起居室內懸掛一張我們精心製作的海報，在1950年以來文本向量模型的進化和演變中尋找下一個靈感。",pricing:"API價格表",pricing_desc:"API 定價基於詞元使用情況。一個 API 密鑰即可訪問所有搜索基礎產品。",protectData1:"您向我們發送的數據和文檔都不會用於模型訓練。",protectData2:"數據在傳輸過程中加密 (TLS 1.2+) ，同時靜態數據也會被加密 (AES-GCM 256)。",protectData3:"SOC 2 和 GDPR 合規。",protect_data:"保護您的數據",public_cloud_integration:"與 <b>{_numPartners}</b> 個雲服務提供商合作",public_cloud_integration_desc:"您的公司是否在使用 AWS 或 Azure？那麼請直接在貴公司的這些平台上私有化部署我們的搜索底座模型，這樣您的數據就能保持安全且合規。",query:"查詢句",raise_issue:"問題反饋",rank_none_description:"不要使用任何重排模型",read_api_docs:"API 規範",read_release_note:"讀取發行説明","reader-lm-05b_description":"用於將原始 HTML 轉換為 Markdown 的小型語言模型","reader-lm-15b_description":"用於將原始 HTML 轉換為 Markdown 的小型語言模型",recharge_threshold:"充值門檻",refresh:"刷新",refresh_key_tooltip1:"免費獲取新的 API 密鑰",refresh_token_count1:"刷新以獲取當前 API 密鑰的可用詞元",regenerate:"生成新的密鑰",remaining:"剩餘詞元額度",remaining_left:"您在下面的 API 密鑰中還剩餘 <b>{_leftTokens}</b> 個詞元。",request_number:"請求次數",request_path:"請求端點",rerank_multimodal_explain:"該模型可以對文本和圖像輸入進行重排，使其成為多模態搜索任務的理想選擇。",results_as_final_result:"最終結果的文檔數",results_fed_to_reranker:"提交給重排器的文檔數",retry:"重試",return_base64:"Base64（字符串）",return_binary:"二進制（打包為 int8）",return_float:"默認（浮點型）",return_format:"向量格式",return_format_explain:"除了浮點數之外，您還可以要求它以二進制形式返回，以便更快地進行矢量檢索，或者以 base64 編碼形式返回，以便更快地進行傳輸。",return_format_title:"返回數據類型",return_ubinary:"二進制（打包為 uint8）",right_api_key_to_charge:"請輸入正確的API密鑰進行充值",rpm_avg:"平均RPM",rpm_last7DaysTotal:"過去 7 天總計",rpm_max:"最高RPM",rpm_min:"最低RPM",rpm_p50:"RPM中位值",rpm_p90:"90分位RPM",rpm_p95:"95分位RPM",rpm_p99:"99分位RPM",running:"運行中",score:"分數",search:"搜索",search_hint:"在下列句子中輸入要搜索的內容",select_classify_model:"選擇分類器",select_embedding_model:"選擇向量模型",select_rerank_model:"選擇重排器",show_api_key:"顯示 API 密鑰",size:"參數",size_explain:"模型中的參數數量為{_size}，請注意，這不代表模型的文件大小。",sleeping:"休眠中",start_batch:"開始批處理",start_embedding:"開始索引",status_explain:"我們的無服務器架構可能根據使用率即時從內存中卸載一些當下無人使用的模型。對於活躍模型，響應是立即的。而休眠中的模型在收到第一次請求時才會加載，這一過程可能會持續幾十秒。模型被喚醒後，後續請求的處理速度會更快。",task_type:"下游任務",task_type_classification:"分類",task_type_classification_explain:"文本分類。",task_type_explain:"選擇將使用向量模型的下游任務。模型將返回針對該任務優化的向量。",task_type_none_explain:"不使用適配器。將返回通用向量，可用於調試或黑客攻擊。",task_type_retrieval_passage:"檢索通道",task_type_retrieval_passage_explain:"將文檔向量化查詢文檔檢索任務中。",task_type_retrieval_query:"檢索查詢",task_type_retrieval_query_explain:"在查詢文檔檢索任務中向量化查詢。",task_type_separation:"分離",task_type_separation_explain:"聚類文檔，可視化語料庫。","task_type_text-matching":"文本匹配","task_type_text-matching_explain":"語義文本相似度、廣義對稱檢索、推薦、查找相似項、去重。",tax_may_apply:"根據您所在的位置，您可能需要支付美元、歐元或其他貨幣的費用。可能需繳納税費。",text1:"左",text2:"右",three_ways:"三種購買方式",three_ways_desc:"訂閲我們的 API、通過雲提供商購買或為您的組織獲取商業許可證。",title:"向量模型API",token_example:"一條微博大約有 20 個詞元，一篇人民日報新聞大約有 1000 個詞元，而查爾斯·狄更斯的小説《雙城記》有超過一百萬個詞元。",token_length_explain:"此模型所支持的輸入詞元的最大長度為 {_tokenLength}。",tokens:"詞元",tools:"工具",top_up_button:"給舊密鑰充值",top_up_button_explain:"集成此 API 密鑰可提供更專業的解決方案，無需頻繁更改密鑰。使用數據將被保留並可隨時訪問。",top_up_warning_message1:"當前 API 密鑰還剩 {_remainedTokens} 詞元，將被具有 {_freeTokens} 詞元的新密鑰替換。如果您已妥善保管舊密鑰，則可以繼續使用或充值舊密鑰。您想如何進行？",top_up_warning_title:"是否替換舊密鑰？",total_documents:"向量化進度：{_Processed}/{_Count} 個句子。",total_quantity:"自創建起詞元總數",total_request:"自創建起請求總數",truncate:"在最大上下文長度處截斷",truncate_explain:"啓用後，模型將自動刪除超出模型允許的最大上下文長度的尾部，而不是拋出錯誤。",tuning:"微調",turnstile_error:"我們無法生成 API 密鑰，因為我們無法驗證您是否是人類。",turnstile_unsupported:"由於您的瀏覽器不受支持，我們無法生成 API 密鑰。",ubinary_description:"向量被打包為 uint8。存儲、搜索和傳輸效率更高。",unknown:"未知",upload:"上傳",upload_file:"單擊此處上傳文件",usage:"用量",usage_amount:"詞元",usage_history:"過去7天的使用情況",usage_history_explain:"數據並不是實時的，可能會延遲幾分鐘。",usage_reason:"描述",usage_reason_consume:"調用了",usage_reason_purchase:"已購買",usage_reason_transfer_in:"轉入",usage_reason_transfer_out:"轉出",usage_reason_trial:"每個新 API 密鑰中都有免費詞元",usage_rerank:"用法",usage_time:"時間日期",v3_description:"<code>jina-embeddings-v3</code> 是一種前沿多語言文本向量模型，具有 570M 個參數和 8192 個詞元長度，在 MTEB 上的表現優於 OpenAI 和 Cohere 的最新專有向量模型。請讀取下面的博客文章和研究論文。",v3_title:"v3：頂級多語言向量模型",vector_database_integration1:"集成",vector_database_integration2:"在流行數據庫、向量數據庫、RAG 和 LLMOps 框架輕鬆使用我們的向量模型API。首先，只需將您的 API 密鑰複製到以下任意集成中即可快速使用我們的模型。",vector_database_integration3:"我們的 Embedding & Reranker API 與各種知名數據庫、向量存儲、RAG 和 LLMOps 框架原生集成。首先，只需將您的 API 密鑰複製並粘貼到任何列出的集成中即可快速無縫地啓動。",vector_database_integration_description:"將 Jina Embeddings API 與以下任何向量數據庫、大模型編排框架和 RAG 應用程序無縫、輕鬆地集成。我們的教程將向您展示如何操作。",view_details:"查看詳情",visualization_example:"將本節中的所有句子映射到 3D 向量空間",visualization_example_you_can:"使用我們下面的API，你也可以做到！",visualize:"可視化",visualize_done:"可視化已完成，您現在可以單擊頂部按鈕打開可視化工具。",wait_for_processing:"您的請求正在處理中。",wait_stripe:"正在開通Stripe支付，請稍候",what_are_embedding:"什麼是向量化？",what_are_embedding_answer:`想象一下教計算機掌握單詞和短語的細微含義。傳統方法依賴於嚴格的基於規則的系統，由於語言過於複雜和流動，因此無法達到預期效果。輸入文本向量：一種強大的解決方案，可將文本轉換為數字語言 - 具體來説，轉換為高維空間中的向量。

考慮短語“晴朗的天氣”和“晴朗的天空”。對我們來説，它們描繪了相似的畫面。通過向量的視角，這些短語被轉換成數字向量，它們在這個多維空間中彼此靠近，捕捉它們的語義親緣關係。向量空間中的這種接近性不僅僅是單詞或短語相似；它還涉及理解上下文、情感，甚至含義中的細微差別。

為什麼這一突破很重要？首先，它彌合了人類語言的豐富性和算法的計算效率之間的差距。算法擅長處理數字，而不是解釋文本。通過將文本轉換為向量，向量使這些算法能夠以以前無法實現的方式“理解”和處理語言。

實際應用範圍廣泛且多種多樣。無論是推薦符合您興趣的內容，還是為感覺非常人性化的對話式人工智能提供支持，甚至是在大量文本中檢測微妙的模式，向量都是關鍵。它們使機器能夠執行情緒分析、語言翻譯等任務，並且對語言的理解越來越細緻入微和精細化。`,what_is_a_token:"文本處理中的詞元是一個單元，通常是一個單詞。例如，“Jina AI 太棒了！”變成五個詞元，包括標點符號。",why_do_you_need:"選擇最適合的向量模型",why_do_you_need_after:"通過深度學習和先進的語言處理技術，我們的向量模型能夠將複雜的多模態數據轉換為簡化的格式，這不僅提升了機器的理解力，也為實現更復雜的AI應用提供了可能，包括但不限於提高數據解析能力、增加用户互動、消除語言障礙和改進開發流程。",why_do_you_need_before:"我們的向量模型旨在涵蓋各種搜索和 GenAI 應用。",why_need_1_description:"我們依託JinaBERT打造的向量基座模型，面向各種場景設計。它在解析長篇文本方面表現出色，適合用於語義搜索、內容分類及深度語言分析等任務。這種多功能性使其成為開發情緒分析工具、文本摘要和個性化推薦系統的理想選擇。",why_need_1_title:"通用向量",why_need_2_description:"我們的雙語模型旨在打破語言壁壘，提升多語言平台的溝通效率、全球客户支持和跨語言內容的發現能力。專注於德語-英語和中文-英語的雙向翻譯，讓不同語言的用户能夠更容易地理解和交流。",why_need_2_title:"雙語向量",why_need_3_description:"專為開發者設計的代碼向量模型，能夠簡化代碼摘要編寫、代碼生成和自動代碼審查等任務。通過深入分析代碼結構並提供改進建議，顯著提升了開發效率，是開發高級IDE插件、自動生成文檔和創新調試工具的關鍵。",why_need_3_title:"代碼向量",why_need_4_description:"Jina CLIP 是我們最新的圖片和文本多模態向量模型。與 OpenAI CLIP 相比，一個很大的改進是，這個單一模型可以用於文本-文本檢索，以及文本-圖片、圖片-文本和圖片-圖片檢索任務！因此，一個模型，兩種模態，四個搜索方向！",why_need_4_title:"多模態向量",write_email_here:"請輸入您希望在完成後接收下載鏈接的電子郵件。",you_can_leave:"您可以離開此頁面，完成後我們將向您發送下載鏈接。"},P={description:"世界一流的多模態多語言向量模型。"},w={contractType:{department:"子部門許可證",poc:"概念驗證（3-6個月）",standard:"標準企業許可證",title:"合同類型"},department:{businessSponsor:"業務單位內薦人",executionModel:"執行模型",growth:{high:"明確整個企業的潛力",highDesc:"計劃在全公司範圍內採用的戰略舉措",limited:"限部門",limitedDesc:"通過標準支持關注單個部門的需求",steady:"其他部門的潛力",steadyDesc:"計劃在 12 個月內擴展到 2-3 個部門"},growthTitle:"增長軌跡",sponsorDescription:"專門的執行發起人，倡導實施，提供戰略方向，並確保資源得到分配"},descriptions:{contractType:{department:"單一部門部署，後期可靈活擴展",poc:"試驗部署以在特定環境和用例中測試模型",standard:"全面企業部署，模型使用不受限制"},department:{growth:"計劃擴大模型在其他部門的使用",sponsorship:"表明創收部門是否支持部署"},features:{csm:"個人客户成功經理提供戰略指導和支持",priority:"保證對關鍵問題做出快速響應",training:"幫助您針對特定數據進行預訓練或微調模型"},models:{clip:"為多模態應用處理圖片和文本",colbert:"高精度文檔檢索專用模型",embeddings:"用於語義搜索和文本相似度的文本向量模型",reader:"將 HTML 內容轉換為乾淨的 markdown 格式",reranker:"微調搜索結果以提高相關性"},payment:{annual:"每年一次的簡化會計付款",quarterly:"每三個月定期付款"},poc:{duration:"在您的環境中測試和驗證模型性能的時間表",metrics:"跟蹤關鍵績效指標和模型有效性"},support:{enterprise:"最高優先級的全面支持覆蓋",premium:"額外的諮詢時間和更快的響應時間",standard:"基礎技術支持與實施指導"},usage:{business:"有多少不同的企業將使用由我們的模型支持的應用程序",consumer:"每月有多少終端用户將與我們的模型進行交互"}},features:{csm:"專門的客户經理",priority:"優先響應 SLA（4 小時內）",title:"其他功能",training:"自定義模型訓練支持"},interests:"我對此配置的商業許可 (${_Price}) 感興趣",labels:{basePrice:"基價",custom:"聯繫銷售人員瞭解定製價格",discountApplied:"已享受折扣",included:"包含在基礎價格中",learnMore:"瞭解更多",priceQuarterly:"每季度價格",selectAll:"選擇所有型號",selectSupport:"選擇支持層",totalPrice:"總價",upTo:"最多 {count} 個"},messaging:{additionalFeatures:"附加功能包括：",baseModelIncluded:"包含基本向量模型 (jina-embeddings-v3)",deptIncludes:"部門執照包括：",deptReviews:"季度業務審查會議",deptRoadmap:"企業擴張路線圖規劃",deptSponsor:"執行發起人協調會議",deptWorkshops:"跨部門協作研討會",enterpriseAlert:"您的使用水平表明這是一個企業範圍內的機會。讓我們安排一次通話來討論定製企業協議。",noModelsSelected:"未選擇其他模型。使用基礎向量模型。",pocCheckins:"每兩週與技術團隊進行一次檢查",pocIncludes:"POC 包包括：",pocMetrics:"成功指標跟蹤儀表板",pocMigration:"支持遷移至完整許可證",pocTemplate:"POC 結果文檔模板",selectedModels:"選定的模型：",standardFeatures:"標準許可證功能：",supportTierIncluded:"{tier} 支持層包含 {hours}",usageTierBusiness:"商業使用層級：最多 {count} 個商業帳户",usageTierConsumer:"消費者使用層級：每月最多 {count} 個活躍用户"},models:{clip:"jina-clip-v2",colbert:"jina-colbert-v2",description:"選擇要包含在您的商業套餐中的模型",embeddings:"jina-embeddings-v3",lm:"reader-lm",reranker:"jina-reranker-v2",title:"選擇型號"},payment:{annual:"年度結算（10% 折扣）",features:"包含的功能",quarterly:"按季度計費",title:"付款條款"},poc:{description:"POC 包括成功指標跟蹤和完整許可升級路徑",duration:"POC 持續時間（月）"},pricing:{annual:"年",cta:"與我們的銷售人員聯繫",disclaimer:"此定價計算器提供估算。您的最終價格可能因具體要求、數量承諾和自定義配置而異。請聯繫我們的銷售團隊獲取詳細報價。",frequency:"${price} / {frequency}",oneTime:"${price} 一次性",pocTotal:"{months} 月 POC 價格：${price}",quarterly:"季度",title:"預計價格"},short_title:"配置許可證",subtitle:"為 Jina AI 模型配置企業許可證",support:{enterprise:"高級的",hoursQuarter:"{hours} 小時/季度",premium:"標準的",standard:"輕量的",title:"支持層"},title:"企業許可證配置器",tooltips:{annualDiscount:"按年付款可節省 10%",businessSponsor:"擁有業務單位贊助商可享受額外折扣",pocDuration:"選擇概念驗證期的持續時間",supportTier:"選擇最適合您需求的支持級別",usageLimit:"如果超出這些限制，請聯繫我們獲取定製價格"},usage:{business:"B2B（企業賬户）",businessCount:"企業賬户數量",businessDescription:"使用我們的模型的不同商業賬户數量",consumer:"B2C（終端用户）",consumerCount:"每月活躍用户",consumerDescription:"所有應用程序的每月活躍終端用户數量",title:"使用配置"}},f={answer1:"Jina AI 專注於多模態AI技術，包括大模型向量的調優和部署、提示詞的調優和部署。我們利用 Kubernetes 和無服務器架構等先進工具來創建強大、可擴展且可立即投入生產的解決方案。",answer10:"我們根據項目的性質和客户的需求提供不同的許可選項。詳細條款可以與我們的銷售團隊討論。",answer11:"我們在全球範圍內提供服務，總部位於歐洲柏林，並在北京和深圳設有辦公室。",answer12:"是的，我們提供現場支持，特別是對於位於柏林、北京和深圳辦公室附近的客户。對於其他地點，我們努力提供最好的遠程支持，並在必要時安排現場支持。",answer2:"我們的專業知識涵蓋廣泛，包括大型語言模型、文本、圖片、視頻、音頻理解、神經搜索和生成式AI。",answer3:"是的，我們的解決方案設計為可擴展並可用於生產。我們使用雲原生技術構建解決方案，從而在生產環境中實現高效擴展和可靠的性能。",answer4:"我們的服務用途廣泛且適應性強，適用於多種行業，包括電子商務、法律技術、數字營銷、遊戲、醫療保健、金融等。",answer5:"您可以通過此頁面上的聯繫表與我們的銷售團隊取得聯繫。我們很樂意討論您的項目需求以及我們的解決方案如何幫助您的業務。",answer6:"我們提供持續的支持，以確保我們的解決方案順利運行。這包括根據您的反饋和需求進行故障排除、定期更新和改進。",answer7:"項目持續時間根據項目的複雜性和範圍而有所不同。瞭解您的要求後，我們可以提供更準確的估算。",answer8:"數據安全是我們的首要任務。我們遵守嚴格的數據保護政策和法規，以確保您的數據安全和保密。",answer9:"定價取決於項目的複雜性和要求。我們提供基於項目的定價模型和保留定價模型。請聯繫我們的銷售團隊瞭解更多信息。",question1:"Jina AI 擅長什麼？",question10:"你們的解決方案的許可條款是什麼？",question11:"您的服務區域是什麼？",question12:"你們提供現場支持嗎？",question2:"Jina AI 適用於哪些類型的人工智能？",question3:"您的解決方案可擴展且可投入生產嗎？",question4:"哪些行業可以從 Jina AI 的解決方案中受益？",question5:"我們如何使用 Jina AI 啓動一個項目？",question6:"實施解決方案後您提供哪些支持？",question7:"項目的典型持續時間是多長？",question8:"Jina AI 如何保護我的數據？",question9:"你們的服務的定價結構是怎樣的？"},x="常見問題",R={text:"江湖再見。",toggle_btn:"下次訪問時保持此面板打開",warning_message:"當您訪問 jina.ai 時，此面板將自動打開。您需要關閉它才能查看網站內容。啓用此設置嗎？",warning_title:"啓動時顯示"},L={description:"調優特定領域數據的大模型向量以獲得更好的搜索質量",intro:"你的公司、你的數據、你的模型"},M={description:"為您的企業提供本地調優解決方案"},q={api_key:"輸入您的 API 密鑰。",back:"後退",base_model_selected:"選擇底座模型",click_start:"同意條款並開始微調。",confirm_title:"確認微調工作",confirm_your_email:"重新輸入您的電子郵件地址以確認微調工作。更新和下載鏈接將發送到此電子郵件。",consent0:"我同意根據我的指示生成用於模型微調的合成數據。",consent1:"我承認最終模型和合成數據將在 Hugging Face 上公開。",consent2:"我瞭解此功能處於測試階段，Jina AI 不提供任何保證。定價和用户體驗可能會發生變化。",continue:"繼續",cost_1m_token:"每個微調作業消耗 1M 詞元。請確保您有足夠的詞元或充值。您也可以生成新的 API 密鑰。每個 API 密鑰附帶 10M 免費詞元。",doc_explain:"描述匹配的文檔應該是什麼樣的。",domain_explain:"詳細描述如何使用微調向量模型。這對於生成高質量的合成數據（可提高向量模型的性能）至關重要。",domain_explain2:"有三種方式可以指定您的需求：一般説明、URL 或查詢文檔描述。請選擇一種。",domain_hint:"描述您希望微調的域。",email_not_match:"電子郵件地址不匹配。請驗證。",failed_job:"微調請求失敗。請參閲下面的原因。",find_on_huggingface:"在 Hugging Face 上查找結果",general_instruction:"或者，一般説明",general_instruction_caption:"提供有關如何使用微調向量的詳細描述。",general_instruction_explain:"以自由格式的文本描述您的域名。您可以將其想象為 ChatGPT 中的“提示”。",how_it_works:"瞭解微調過程。",job_acknowledged:"您的微調作業已排隊。作業開始時，您將收到一封電子郵件。整個過程通常需要 20 分鐘才能完成。",new_key:"獲取新密鑰",not_enough_token:"此 API 密鑰中詞元不足。請充值或使用其他 API 密鑰。",placeholder:"汽車保險索賠",preview:"預覽",query_doc:"查詢文檔描述",query_doc_caption:"描述查詢是什麼樣的以及匹配的文檔在您的域中是什麼樣的。",query_explain:"描述查詢的樣子。",reset:"重來",select_base_model:"選擇一個基礎向量模型進行微調。",select_base_model_explain:"選擇一個底座模型作為微調的起點。通常，base-en 是一個不錯的選擇，但對於其他語言的任務，請考慮使用雙語模型。",start_tuning:"開始微調",url:"或者，網頁網址",url_caption:"參考URL中的內容進行微調。",url_explain:"包含您要微調的內容的網頁的公共 URL。",use_url:"使用 URL 代替。啓用該選項意味着我們將根據該 URL 的頁面內容生成合成數據以進行微調。",wait_for_processing:"請稍候，我們正在處理您的請求...",which_domain:"微調域",write_email_explain:"微調需要時間。我們將通過電子郵件告知您微調工作的開始、進度、完成情況和任何問題，以及微調模型和訓練數據集的詳細信息。"},C={address_beijing:"中國北京",address_berlin:"德國柏林（總部）",address_shenzhen:"中國深圳",address_sunnyvale:"加利福尼亞州桑尼維爾",all_rights_reserved:"版權所有",api_documentation:"API 文檔",company:"公司",developers:"為開發者",docs:"文檔",enterprise:"為企業",get_api_key:"獲取 Jina API 密鑰",offices:"辦公室",power_users:"為高級用户",privacy:"隱私",privacy_policy:"隱私政策",privacy_settings:"管理 Cookie",security:"安全",sefo:"搜索底座",soc2:"我們符合美國註冊會計師協會 (AICPA) 的 SOC 2 Type 1 和 Type 2 標準。",status:"API 狀態",status_short:"服務狀態",tc:"條款及條件",tc1:"條款"},j="獲取 API 密鑰",S={stars:"Stars"},T={description:"運用網絡知識進行地面陳述",title:"事實核查",usage:"接地使用"},J={about_us:"關於我們",api_docs:"API 文檔",api_docs_explain:"為您的AI 編程助手 IDE 或大模型自動生成代碼",company:"公司",contact_us:"聯繫銷售",developers_others:"更多開發者工具",enterprise_others:"更多的",for_developers:"為開發者賦能",for_developers_description:"專為開發人員打造的的多模態開源技術棧。",for_enterprise:"為企業賦能",for_enterprise_description:"探索為企業定製的多模態解決方案。",for_power_users:"為高級用户賦能",for_power_users_description:"利用我們多模態工具來提高您的日常生產力。",internship1:"實習生計劃",jobs:"加入我們",join_discord:"加入我們的 Discord 社區",logos:"下載Logo",maximize:"⇧1",maximize_btn:"最大化",news:"新聞",open_day:"開放日",open_in_full:"在新窗口中顯示所有企業產品",power_users_others:"更多高級用户工具",products:"產品"},B={description:"分享和發現多模態AI應用程序的構建模塊"},E={sentence_similarity:"句向量模型",updated_about:"更新了關於"},G={project1:"使用點雲信息在 3D 網格數據中實現高精度搜索。",project10:"利用計算機視覺提高政府網站的數字可訪問性。",project11:"為一家諮詢公司優化財務數據分析的調優大規模語言模型。",project12:"通過調優文本到圖片模型以進行風格轉換來實現高級營銷策略。",project2:"設計了一個基於內容的動畫短片搜索引擎。",project3:"通過調優向量模型來提高電子商務轉化率。",project4:"為一家商業諮詢公司進行及時調整以提高效率。",project5:"為一家領先的遊戲企業開創了遊戲場景理解和自動標註的先河。",project6:"為一家聊天機器人公司實現了實時輸入擴展，增強了用户體驗。",project7:"通過在冗長的法律文檔中實現高效搜索。",project8:"支持大規模運營的高吞吐量生成藝術服務。",project9:"使用高級語言模型進行流程挖掘和建模。"},U={description:"最先進的多模態推理模型"},z="由於您的 API 密鑰中剩餘詞元不足，因此請求失敗，請充值後繼續。",O={copy_full_prompt:"複製完整提示詞",embedding:"向量模型",how_to_use_meta_prompt:"如何使用",meta_prompt:"使用元提示詞進行代碼生成",meta_prompt_description:"元提示詞可以讓大模型（如 ChatGPT 和 Claude）知曉我們所有的API使用方法，從而使代碼生成更容易、質量更高。",reranker:"重排器",which_to_go:"哪一個與{_vendor}集成？"},D={answer1:"本科、碩士、博士我們鼓勵來自世界各地對研究、工程、營銷和銷售等領域感興趣的學生申請。我們還歡迎營銷、銷售、行政助理等領域的非技術實習機會。我們正在尋找熱情的個人，準備與我們一起開拓多模態AI。",answer10:"是的，我們的實習計劃提供有競爭力的薪酬。",answer11:"作為 Jina AI 實習生，您將獲得從事具有挑戰性的項目的實踐經驗，向行業專家學習，成為充滿活力的社區的一部分，並有機會為我們在多模態 AI 領域的開創性工作做出真正的貢獻。",answer2:"實習必須在我們位於柏林、北京和深圳的辦事處之一現場進行。",answer3:"是的，Jina AI 在簽證流程中為成功申請者提供合理的幫助。",answer4:"是的，Jina AI 為實習生在實習期間提供合理的生活費保障。",answer5:"是的，您可以在 Jina AI 實習期間完成碩士論文，這通常適用於德國大學的學生。但是，您必須事先徵得您所在大學主管的溝通並同意。請注意，我們不幫助學生尋找顧問。",answer6:"申請過程包括提交您的申請表、簡歷、表達您的興趣和動機的求職信以及任何相關的專業鏈接，例如 GitHub 或 LinkedIn。我們根據候選人在面試中的表現以及他們在大學的表現來評估他們。",answer7:"是的，成功的實習生可能會在實習結束時收到一封由我們首席執行官簽署的推薦信。",answer8:"實習的持續時間根據角色和項目而有所不同。然而，它通常為三到六個月。",answer9:"是的，我們歡迎所有學術背景的申請。我們重視您對學習的熱情和承諾，就像您以前的經驗一樣。",question1:"哪些人可以申請 Jina AI 實習項目？",question10:"這是帶薪實習嗎？",question11:"作為 Jina AI 實習生，我將獲得哪些機會？",question2:"實習將在哪裏進行？",question3:"Jina AI 是否協助辦理簽證流程？",question4:"Jina AI 是否為實習生提供任何津貼或福利？",question5:"在 Jina AI 實習期間可以寫碩士論文嗎？",question6:"申請流程涉及哪些內容？",question7:"Jina AI 實習後有推薦信嗎？",question8:"實習期限是多長？",question9:"如果我沒有人工智能方面的經驗，我可以申請嗎？"},H={about_internship_program:"關於實習計劃",about_internship_program_desc1:"我們很高興為有才華的人提供這個獨特的機會加入我們充滿活力的團隊，併為人工智能領域的突破性項目做出貢獻。該實習旨在為您提供寶貴的實踐經驗、指導和接觸正在塑造人工智能未來的尖端技術。",about_internship_program_desc2:"在 Jina AI，我們深知培養和利用年輕人才的重要性。我們認識到實習生帶來了新的視角、熱情和創造力，用新的想法和方法激勵我們的團隊。通過提供實習機會，我們的目標是促進人工智能行業未來領導者的成長，同時在支持性和挑戰性的環境中為他們提供實際經驗。",alumni:"校友",alumni_network:"我們蓬勃發展的校友網絡",application:"應用",application_desc:"與 Jina AI 一起踏上變革之旅。我們全面的實習計劃邀請所有渴望塑造人工智能未來的充滿激情的夥伴。加入我們，獲得現實世界的經驗，從事具有挑戰性的項目，並與人工智能行業中一些最聰明的人做同事。",apply:"現在申請",autumn:"秋季",description:"全球招募學生：研究、工程、營銷、銷售等專業的實習。",dev_rel_intern:"開發者關係實習生",enthusiastic:"熱情的",explore_stories_from_our_interns:"探索我們實習生的故事",explore_stories_from_our_interns1:"從我們的實習生的旅程中獲得靈感",innovative:"創新的",intern_work1:"微調大模型模型以實現更好的句向量模型",intern_work2:"探索檢索增強生成(RAG)算法的潛力",intern_work3:"發表了一篇關於句子向量的論文",intern_work4:"為團隊注入源源不斷的年輕活力",intern_work5:"壓縮大模型的基準量化技術",intern_work6:"為 PromptPerfect 創建和推廣引人注目的活動",intern_work7:"快速開發和改進 JinaColBERT V2",recruiting_and_administrative_intern:"招聘及行政實習生",researcher_intern:"實習研究員",self_motivated:"自我激勵",software_engineer_intern:"軟件工程師實習生",spring:"春季",submit_application:"與 Jina AI 一起開始你的冒險",subtitle:"我們的全日制實習計劃通過精心設計的廣泛範圍的實習項目提供實踐工作經驗。",subtitle1:"全球範圍內招募學生：研究、工程、營銷、銷售等領域的實習生，共同開創多模態AI。",summer:"夏季",title:"實習生計劃",who_do_we_look_for:"我們要找誰？",who_do_we_look_for_desc:"我們重視多樣性，並鼓勵來自不同背景和背景的申請人加入我們的實習計劃。多個部門提供實習機會，包括工程、設計、產品管理、銷售和客户管理、營銷和社區管理。",winter:"冬季"},N={description:"將一個本地項目部署為雲服務。極其簡單，沒有令人不快的意外。"},F={description:"開源的大模型的實驗性調優器"},W={description:"在雲端構建多模態AI應用"},K={description:"更多模態、更長記憶、更低成本",example_1:"你是誰？",example_2:"我是 Jina AI 製作的大模型聊天服務"},Q={add:"添加密鑰",add_key_explain:"向您的帳户添加另一個 API 密鑰。可以隨時管理、充值或刪除添加的密鑰。",add_key_labels_explain:"給您的鑰匙添加一些標籤，以幫助您有效地管理多個鑰匙。",add_key_labels_input_explain:"允許多個標籤。使用“Enter”鍵添加新標籤。",add_shared_key:"添加到我的鑰匙",add_success:"已成功添加密鑰 {_key}。",advance_settings:"打開高級設置",advanced_feature:"高級功能僅適用於高級密鑰。",auto_recharge_enable_success:"已成功為密鑰 {_key} 開啓自動充值。",auto_recharge_title:"啓用自動充值嗎？",auto_reminder:"低餘額提醒",auto_reminder_cancel_message:"您確實要取消此密鑰的自動提醒嗎？",auto_reminder_cancel_title:"取消自動提醒",auto_reminder_description:"當您的詞元餘額低於設定的閾值時，您會收到自動電子郵件提醒。您最多可以配置三個閾值。",auto_reminder_email:"提醒電子郵件地址",auto_reminder_info:"當詞元餘額低於 {_threshold} 時，郵件提醒將發送到 {_email}。",auto_reminder_threshold:"提醒閾值",auto_reminder_threshold_error:"閾值必須介於 1 到 1T 之間。",auto_reminder_toggle:"開關自動提醒，請注意只有高級密鑰才能啓用此功能。",available_resources:"可用詞元",balance:"可用詞元",balance_primary_key:"主密鑰餘額",cancel:"取消",confirm:"確認",copy:"複製密鑰",copy_share_link:"複製鏈接",customized_tags:"給你的鑰匙貼上標籤",day_requests:"請求/天",day_tokens:"詞元/天",description:"管理所有 Jina AI 服務的 API 密鑰 — Embeddings、Reader、Reranker 等。",do_it_later:"稍後再做",email:"電子郵件",existing_key:"現有密鑰",filter_by:"按密鑰過濾",free_key:"免費密鑰",generate_new_key:"生成新密鑰",generate_new_key_tooltip:"生成一個新的 API 密鑰，其中的餘額為空。您可以稍後充值。",generate_success:"成功生成新密鑰 {_key}。",get_free_key:"創建 API 密鑰",hour_requests:"請求/小時",hour_tokens:"詞元/小時",ignore:"忽略",invalid_email:"郵箱無效",invalid_key:"無效密鑰",is_primary:"您的主密鑰。登錄後您可以更改它。",key_labels:"標籤",labels_updated:"已成功更新標籤。",last_used:"最後使用",last_used_at:"上次活動",login:"登錄",login_explain:"管理多個 API 密鑰並跟蹤使用情況——全部在一個帳户中完成。",login_explain_long:"登錄以安全地存儲和管理您的 API 密鑰。跟蹤使用歷史記錄、管理多個密鑰，並且永遠不會失去對您的憑據的訪問權限。",login_required:"請先登錄，然後添加共享密鑰。",login_via:"通過 {_provider} 登錄",logout:"登出",logout_message:"您的 API 密鑰安全地存儲在您的帳户中。您可以隨時登錄來管理它們。",logout_success:"已成功登出",no_key_title:"需要 API 密鑰嗎？",no_key_with_login:"您尚未創建 API 密鑰。立即生成一個並獲取免費詞元以開始使用。",no_key_without_login:"已有帳户？登錄以訪問您的 API 密鑰，或單擊“{_button}”創建一個新密鑰。",no_recent_usage:"最近24小時無使用",no_transferable_keys:"沒有其他可供轉移的密鑰，請先添加新密鑰。",normal_key:"普通密鑰",ok:"好的",primary_key:"設置為主密鑰",primary_key_set:"成功將 {_apiKey} 設置為您的主密鑰。",primary_key_set_caption:"此密鑰將用於 jina.ai 上的所有演示、示例和沙盒實驗場。",purchase:"購買詞元",readonly:"限制自己對此密鑰的只讀訪問權限。",readonly_explain:"限制自己對此密鑰的只讀訪問權限。此行為將禁用充值、共享以及將此密鑰選為主密鑰的功能。",readonly_key:"只讀密鑰",readonly_label:"只讀訪問",recharge_threshold_confirm_message:"您確定要將自動充值閾值更改為{_threshold}個詞元嗎？",recharge_threshold_confirm_title:"更改自動充值閾值",remove:"移除密鑰",remove_explain:"從列表中移除密鑰不會影響依賴該密鑰的軟件和服務,或存儲該密鑰的其他用户。該密鑰仍然有效，並且可以隨時重新添加。",remove_message:"您確定要移除密鑰嗎？此密鑰仍然有效，可以隨時重新添加。",remove_primary_key:"移除當前主密鑰之前，請將另一個密鑰設置為主密鑰。",remove_success:"已成功移除密鑰 {_key}。",remove_title:"移除密鑰",revert_changes:"恢復更改",revoke:"銷燬密鑰",revoke_error:"您輸入的密鑰與您嘗試銷燬的密鑰不匹配。",revoke_explain:"銷燬密鑰將立即對所有儲存它的用户永久失效，並且該密鑰所有剩餘詞元餘額和關聯資產將永久不可用。此操作無法撤消。",revoke_label:"請在下面輸入此密鑰以確認銷燬",revoke_message:"您確定要銷燬此密鑰嗎？一旦銷燬，此密鑰將對所有存儲它的用户永久失效。該密鑰所有剩餘詞元餘額和關聯資產將永久不可用。此操作無法撤消。",revoke_success:"已成功銷燬密鑰 {_key}。",revoke_title:"銷燬密鑰",save:"保存",save_as:"保存為",settings:"設置",share:"分享密鑰",share_key_confirm_message:`接收者將能夠查看、管理和充值此密鑰的餘額。您將保留相同的權限。
請注意，該鏈接將在 24 小時後過期。`,share_key_confirm_title:"分享 API 密鑰",share_key_expired_at:"分享鏈接將於{_time}過期！",share_key_expired_message:"密鑰的分享鏈接已過期，請讓密鑰擁有者重新分享。",share_key_expired_title:"分享鏈接已過期",share_key_message:"{_user} 已與您共享 API 密鑰。添加它以管理密鑰及其餘額。",share_link_copied:"分享鏈接已複製",share_token_keys:"這些詞元由 {_num} 個其他密鑰共享",shared_from:"密鑰由 {_user} 共享",shared_key:"共享密鑰",subscribed_key:"高級密鑰",tickets:{actions:"行動",button:"採購單",client_name:"客户名稱",currency_cny_format:"¥{value}",currency_eur_format:"€{value}",currency_usd_format:"${value}",explain:"查看和管理您的採購單和發票",export_csv:"導出 CSV",invoice_status:"發票狀態",invoice_status_failed:"失敗",invoice_status_issued:"已開票",invoice_status_pending:"未申請",invoice_status_processing:"處理中",notes:"筆記",open_time:"創建時間",order_id:"訂單編號",payment_status:"付款狀態",payment_status_failed:"失敗的",payment_status_paid:"已支付",payment_status_pending:"尚未支付",payment_time:"付款時間",pricing_strategy:"定價依據",product_name:"購買產品",purchase_time:"購買時間",quantity:"購買數量",request_invoice:"索取發票",title:"採購單歷史記錄",total_amount:"總金額",unit_price:"單價",view_details:"查看詳情"},title:"Jina 搜索底座 API",to_dashboard:"管理密鑰",token_expiry_detail:"按照當前使用率 {_rate}，詞元將於 {_date} 耗盡",token_expiry_estimate:"預計在{_date}（{_days}天{_hours}小時後）耗盡",token_expiry_no_rate:"沒有近期使用數據來估計詞元消耗情況",tokens_depleted:"已達到詞元上限",tokens_per_hour:"詞元/小時",top_up:"充值",total_keys:"密鑰數",transfer_before_revoke:"在銷燬密鑰之前轉移剩餘的已付費詞元餘額。",transfer_explain:"將您全部剩餘的付費詞元餘額轉移到另一個密鑰，以獲得更大的靈活性並增強管理資源的安全性。",transfer_label:"轉移到",transfer_message:"您確定要將全部剩餘的付費詞元餘額 {_tokens} 從 {_source} 轉移到 {_target} 嗎？",transfer_success:"已成功將付費詞元餘額從 {_source} 轉移到 {_target}。",transfer_title:"轉移詞元",update_key_failed:"更新密鑰信息失敗，請稍後重試。",update_label:"更新標籤",usage:"用量",usage_history:"使用歷史記錄",usage_summary:"過去 7 天：{_usage} 個詞元",view_tickets:"查看採購訂單和發票"},X={GlobalQA:{description:"在任意頁面上按“/”鍵即可打開提問。輸入您的查詢並按“Enter”得到頁面內容相關的答案。此功能由 PromptPerfect 提供支持。",title:"頁上RAG"},Recommender:{description:"使用“Shift+2”打開任何新聞頁面上的推薦框。選擇重排模型以發現與該新聞頁面相關的前 5 篇文章。此功能由我們的 Reranker API 提供實時支持。",title:"相關文章"},SceneXplainTooltip:{description:"將鼠標懸停在新聞頁面或我們的新聞室目錄中的任何圖片上，以顯示該圖片的描述。描述由 SceneXplain 預先計算並向量化在圖片的 ALT 屬性中。",title:"圖片標註"},explain:"探索我們網站上的隱藏功能"},V={also_available_on:"也可在應用市場上使用",also_available_on1:"通過應用市場一鍵部署到您的企業雲上",ask_how_your_question:"請描述您的問題",autotune:"自微調",avatar:"頭像生成器",badge:{"clip-v2":"clip-v2 發佈！",m0:"m0 發佈！","readerlm-v2":"ReaderLM-v2 發佈！",v2:"第二版已發佈！",v3:"v3 發佈！"},browser_info_title:"瀏覽器信息",build_js:"使用 JavaScript 開發",build_python:"使用 Python 開發",ccbync:"此模型為 CC BY-NC 4.0 許可。通過 API 或我們的官方 AWS/Azure 映像使用它；或聯繫銷售人員進行本地部署。",checkout_our_solution_for_you:"瞭解我們為您量身定製的解決方案",classifier:"分類器",coming_soon:"敬請期待",contact_sales:"聯繫我們",copied_to_clipboard:"已複製到剪貼板",copy:"複製",developers:"開發者",developers_desc:"通過尖端的雲原生技術和開源基礎設施，釋放多模態AI的全部力量。",download_pdf:"下載 PDF",embedding:"向量",embedding_desc1:"適用於搜索、RAG、智能體應用程序的性能最佳的多模態多語言長上下文向量模型。",embedding_paper_desc:"Jina Embeddings 構成了一組高性能文本向量模型，擅長將各種文本輸入轉換為數字表示，從而捕獲文本的語義本質。雖然這些模型並非專門為文本生成而設計，但它們在密集檢索和語義文本相似性等應用中表現出色。本文詳細介紹了 Jina Embeddings 的開發，從創建高質量的成對和三元組數據集開始。它強調了數據清理在數據集準備中的關鍵作用，深入瞭解了模型訓練過程，並使用大規模文本向量基準 (MTEB) 進行了全面的性能評估。",embedding_paper_title:"Jina Embeddings：一套新穎的高性能文本向量模型",embeddings:"向量模型",enterprise:"企業",enterprise_desc:"通過可擴展、安全和定製的多模態AI解決方案促進您的業務。",enterprise_desc_v2:"用我們世界一流的向量模型來改進您的搜索和 RAG 系統。從免費試用開始！",enterprise_desc_v3:"我們的前沿模型構成了高質量企業搜索和 RAG 系統的搜索底座。",error:"出現了問題：{message}",find_your_portal:"探索您的專屬傳送門",finding_faq:"根據以下常見問題解答知識生成答案",for:"為",for_better_search:"為了更好的搜索",for_developers:"為開發者",for_enterprise:"為企業",for_power_users:"為高級用户",get_api_now:"API",get_started:"開始使用",go_to_product_homepage:"轉至產品主頁",grounding:"接地",how_to:"如何",include_experiment:"在解決方案中提及我們還在實驗中和已歸檔的項目。",join_community:"社區",key_manager:"管理 API 密鑰",learn_more_embeddings:"瞭解向量模型",learn_more_reader:"詳細瞭解讀取器",learn_more_reranker:"瞭解重排器",llm:"大模型向量模型",llm_desc:"我們提供了一系列高性能文本向量模型，擁有 3500 萬到 60 億個參數。它們非常適合增強神經搜索、重排器、句子相似性、推薦等。準備好提升您的 AI 體驗！",mentioned_products:"提及產品：",mmstack:"多模態技術棧",mmstack_desc:"多年來，我們開發了各種開源軟件，幫助開發人員構建更好的 GenAI 和更快地搜索應用程序。",models:"模型",more:"更多的",multimodal:"多模態",multimodal_ai:"多模態AI",new:"新的",newsroom:"新聞",num_publications:"共計 {_total} 篇出版物。","on-prem-deploy":"私有化部署","on-premises":"本地",opensource:"開源",our_customer:"我們的客户",our_customer_explain:"各種規模的企業都信賴 Jina AI 的搜索基礎來支持他們的工具和產品——您也可以。",our_publications:"我們的論文",parameters:"參數",podcast:"播客",power_users:"高級用户",power_users_desc:"自動提示詞工程，提高您的日常工作效率。",powered_by_promptperfect:"由 PromptPerfect 的“提示詞優化”和“提示即服務”功能提供支持",pricing:"價格表",proposing_solution:"基於 Jina AI 產品線的構思解決方案...",read_more:"更多新聞",reader:"讀取器",refresh_page:"刷新",require_full_question:"請更詳細地描述您的問題。",reranker:"重排器",researcher_desc:"瞭解我們的前沿搜索模型是如何從頭開始訓練的，查看我們的最新出版物。在 EMNLP、SIGIR、ICLR、NeurIPS 和 ICML 與我們的團隊見面！",researchers:"研究人員",sdk:"軟件開發工具包",sdk_desc:"想要使用 PromptPerfect、SceneXplain、BestBanner、JinaChat、Rationale API 構建高級 AIGC 應用程序？我們為您服務！嘗試我們易於使用的 SDK，幾分鐘內即可開始使用。",sdk_docs:"讀取文檔",sdk_example:"例子",search_foundation:"搜索底座",source_code:"源代碼",starter_kit:"新人包",supercharged1:"如虎添翼！",tokenizer:"切分器",trusted_by:"我們值得信賴",try_it_for_free:"立即開始——無需信用卡或註冊！",try_our_saas:"嘗試我們託管的的雲原生推理方案，它是OpenAI API的1:1替代品。",version_notify:"您正在瀏覽的是我們的中國大陸網站。一些互動演示功能可能無法正常顯示或運行。如需完整功能且網絡環境允許，歡迎訪問我們的國際站 {_link}",view_browser_info:"查看瀏覽器信息",your_portal_to:"邀您通往",your_search_foundation1:"您的搜索底座"},Y={description:"使用 Jina 和 FastAPI 製作生產級別的 Langchain 應用程序"},$={description:"關於Jina AI產品和服務的法律信息、服務條款、隱私政策和其他重要文件。",download_type1:"下載 SOC 2 I型證明",download_type2:"下載 SOC 2 II型證明",request_audit:"索取審計報告",title:"法律信息"},Z={api:"LLM-as-SERP API",description:"大型語言模型作為搜索結果頁面",faq_v1:{answer1:"SERP 代表搜索引擎結果頁面，是搜索引擎響應用户查詢而顯示的頁面。它包含結果列表，通常還包含其他信息，例如 URL、摘要、域名。",answer2:"是的，LLM-as-SERP 使用大型語言模型來生成搜索結果。",answer3:"出現幻覺。",answer4:"它們可能在模型的訓練數據中。",answer5:"是的，您可以使用 LLM-as-SERP API 來生成搜索結果。點擊下面的按鈕。",answer6:"我們在試驗深度搜索的搜索基礎時開發了它。點擊按鈕讀取我們的博客文章。",answer7:"是的，代碼是開源的，可以在 GitHub 上獲取。",question1:"什麼是 SERP？",question2:"那麼所有搜索結果都是由 LLM 生成的嗎？",question3:"為什麼搜索結果中有些 URL 損壞並導致 404 頁面？",question4:"那麼為什麼有些 URL 是真實的並且會引導至實際的頁面？",question5:"我可以通過 API 調用它嗎？",question6:"但是如果所有搜索結果都是假的，那麼這個演示或 API 有什麼意義呢？",question7:"它是開源的嗎？",title:"LLM-as-SERP 常見問題"},okay_but_why:"玩兒歸玩兒，它有什麼用？",parameters:{auth_token:"@:tokenizer.parameters.auth_token",auth_token_explain:"LLM 作為 SERP API 可免費使用。通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會向您的密鑰收費。",country:"首選國家",country_explain:"用於搜索的國家/地區。這是兩個字母的國家/地區代碼。",language:"首選語言",language_explain:"搜索所用的語言。這是一個雙字母的語言代碼。",location:"首選地點",location_explain:"您希望搜索查詢源自何處。建議指定城市級別的位置，以便模擬真實用户的搜索。",number:"結果數量",number_explain:"返回的最大結果數。使用 num 可能會導致延遲，和/或阻止包含專門的結果類型。結果不保證具有 num 中指定的結果數。",page:"分頁",page_explain:"結果偏移量。它會跳過給定數量的結果。它用於分頁。",query:"詢問",query_explain:"您要搜索的查詢。您可以使用常規搜索中使用的任何內容。例如 inurl:、site:、intitle:。"},query_label:"您的查詢",title:"LLM 作為 SERP"},ee={api:"Jina AI的API",browse_catalog:"瀏覽目錄",contact_sales_about_it:"聯繫銷售人員瞭解詳情",deploy_it_on:"部署於",description:"從第一天起，我們就一直在推動搜索模型的發展。請查看下面的模型演變過程 — 將鼠標懸停或單擊即可發現每個里程碑。",find_on_hf:"在 HuggingFace 上找到它",search_for:"在我們的網站上搜索",search_models:"按模型名稱過濾",title:"我們的搜索底座模型",use_it_via:"通過使用"},ne={back_to_models:"返回模型",comparison:{btn:"比較",select_models:"選擇要比較的模型"},error:"加載模型失敗",input_type:{"3d":"3D",audio:"聲音的",code:"代碼",document:"文檔",graph:"圖形",image:"圖片","image (document)":"圖像（文檔）","image (query)":"圖像（查詢）","multi-vector":"多向量",other:"其他",ranking:"排名",tabular:"表格",text:"文本","text (code)":"文本（代碼）","text (document)":"文本（文檔）","text (html)":"文本（HTML）","text (json)":"文本（JSON）","text (markdown)":"文本（Markdown）","text (query)":"文本（查詢）",timeseries:"時間序列",vector:"向量",video:"視頻"},loading:"正在加載模型詳細信息...",metadata:{api_link:"Jina API",arxiv:"ArXiv 論文",aws_link:"亞馬遜雲",azure_link:"微軟雲",deprecated_by:"已棄用",gcp_link:"谷歌雲",huggingface_link:"抱抱臉",input_type:"輸入",license:"許可證",license_link:"商業許可證",output_type:"輸出","reader-api_link":"Jina API",related_models:"相關模型",release_blog:"發行説明",release_date:"發佈日期"},search:{no_results:"未找到與“{query}”匹配的模型",placeholder:"按名稱、標籤或類型搜索..."},sections:{availability:"可用性",blogs:"提及此模型的博客",external_links:"外部鏈接和資源",guidance:{"ReaderLM-v2":"該模型可通過 Google Colab 筆記本訪問，該筆記本演示了 HTML 到 Markdown 的轉換、JSON 提取和指令遵循。對於 HTML 到 Markdown 任務，用户可以輸入沒有前綴指令的原始 HTML，而 JSON 提取則需要特定的架構格式。create_prompt 輔助函數有助於輕鬆為這兩個任務創建提示。雖然該模型可以在 Colab 的免費 T4 GPU 層上運行（需要 vllm 和 triton），但如果不支持 bfloat16 或 flash Attention 2，則存在侷限性。建議將 RTX 3090/4090 用於生產用途。該模型將在 AWS SageMaker、Azure 和 GCP 市場上提供，根據 CC BY-NC 4.0 許可用於非商業用途。","jina-clip-v1":"為了有效部署 Jina CLIP v1，團隊應同時考慮其功能和資源需求。該模型以 224x224 像素圖塊的形式處理圖片，每個圖塊消耗 1,000 個詞元的處理能力。為了獲得最佳性能，請實施有效的圖片預處理以匹配這些尺寸。雖然該模型在短文本和長文本處理方面都表現出色，但目前僅支持英語輸入。團隊應仔細考慮詞元的使用：文本每個單詞大約需要 1.1 個詞元，而圖片以圖塊的形式處理（例如，750x500 像素的圖片需要 12 個圖塊，消耗 12,000 個詞元）。該模型可通過 Jina Embeddings API 和 Apache 2.0 許可下的 Hugging Face 上的開源版本獲得，提供靈活的部署選項。對於生產環境，請考慮使用 AWS Marketplace 或 Azure 部署選項，它們提供優化的基礎設施設置。","jina-clip-v2":"為了實現最佳部署，用户應考慮幾個關鍵因素。該模型需要支持 CUDA 的硬件才能高效處理，內存需求會根據批次大小和圖片分辨率進行調整。為了優化 API 成本和性能，請在處理之前將圖片大小調整為 512x512 像素 - 較大的圖片會自動平鋪，從而增加詞元使用量和處理時間。該模型擅長跨語言匹配帶有描述性文本的圖片，但可能難以處理抽象概念或高度專業化的特定領域內容。它對於電子商務產品搜索、內容推薦系統和視覺搜索應用程序特別有效，但可能不適合需要細粒度視覺細節分析或高度專業化領域專業知識的任務。使用 Matryoshka 表示功能時，請考慮降維和性能之間的權衡 - 雖然 64 維向量保持了強大的性能，但關鍵應用程序可能會受益於更高的維度。","jina-colbert-v1-en":"為了有效部署 Jina-ColBERT-v1-en，團隊應考慮幾個實際方面。該模型需要具有 CUDA 功能的 GPU 才能獲得最佳性能，儘管開發過程中可以使用 CPU 推理。對於文檔處理，8,192 個詞元限制相當於大約 6,000 個單詞，使其適用於大多數文檔類型，包括學術論文、技術文檔和長篇內容。團隊應實施有效的文檔預處理來處理詞元限制，並考慮對大規模索引進行批處理。雖然該模型擅長處理英語內容，但它並非為多語言應用程序或跨語言檢索而設計的。對於生產部署，請實施適當的文檔分塊策略，並考慮使用向量相似性索引（如 FAISS）進行有效檢索。當使用 RAGatouille 等框架將該模型集成到 RAG 管道中時，該模型特別有效，這簡化了複雜檢索模式的實現。","jina-colbert-v2":"為了有效部署 Jina-ColBERT-v2，團隊應考慮幾個實際方面。該模型需要支持 CUDA 的硬件才能獲得最佳性能，並支持最多 8,192 個詞元（可擴展至 12,288 個）的文檔長度，同時將查詢限制為 32 個詞元。對於生產部署，該模型可通過 Jina Search Foundation API、AWS 市場和 Azure 獲得，非商業版本可通過 Hugging Face 訪問。在實施時，團隊應指定他們是向量查詢還是文檔，因為該模型使用非對稱編碼。該模型並非專為在沒有適當索引的情況下實時處理極大的文檔集合而設計，雖然它在多語言檢索方面表現出色，但與針對這些特定領域進行微調的模型相比，它在專門的特定領域任務上的性能可能會略低。","jina-embedding-b-en-v1":"為了實現最佳部署，該模型需要具有 CUDA 功能的 GPU，儘管其適中的大小允許在標準硬件上進行高效推理。該模型接受長度最多為 512 個詞元的輸入序列，特別適合一致、可靠的向量生成至關重要的生產環境。它在英語內容上表現最佳，是語義搜索、文檔相似性比較和內容推薦系統等應用的理想選擇。團隊應考慮在新項目中使用較新的 v2 或 v3 版本，因為它們提供了更好的性能和更廣泛的語言支持。不建議將該模型用於需要多語言理解或一般英語文本之外的專門領域知識的任務。","jina-embeddings-v2-base-code":"為了有效部署 Jina Embeddings v2 基礎代碼，團隊應考慮幾個實際方面。該模型與 MongoDB、Qdrant 和 Weaviate 等流行的矢量數據庫無縫集成，從而可以輕鬆構建可擴展的代碼搜索系統。為了獲得最佳性能，請實施適當的代碼預處理以處理 8,192 個詞元限制，這通常可以容納大多數函數和類定義。雖然該模型支持 30 種編程語言，但它在六種核心語言中表現出最強的性能：Python、JavaScript、Java、PHP、Go 和 Ruby。團隊應考慮使用批處理進行大規模代碼索引以優化性能。該模型的 RAG 兼容性使其對於自動文檔生成和代碼理解任務特別有效，但團隊應該為非常大的代碼庫實施適當的分塊策略。對於生產部署，請考慮使用 AWS SageMaker 端點進行託管推理，並實施適當的緩存策略以優化查詢性能。","jina-embeddings-v2-base-de":"為了有效部署 Jina Embeddings v2 Base German，組織應考慮幾個實際方面。該模型與 MongoDB、Qdrant 和 Weaviate 等流行的矢量數據庫無縫集成，使構建可擴展的雙語搜索系統變得簡單。為了獲得最佳性能，請實施適當的文本預處理以有效處理 8,192 個詞元限制 - 這通常可容納大約 15-20 頁文本。雖然該模型在德語和英語內容方面都表現出色，但在用於查詢和文檔語言可能不同的跨語言檢索任務時尤其有效。組織應考慮為經常訪問的內容實施緩存策略，並使用批處理進行大規模文檔索引。該模型的 AWS SageMaker 集成提供了一條可靠的生產部署路徑，但團隊應該監控詞元使用情況併為高流量應用程序實施適當的速率限制。當將該模型用於 RAG 應用程序時，請考慮實施語言檢測以根據輸入語言優化提示構造。","jina-embeddings-v2-base-en":"為了有效部署 Jina Embeddings v2 Base English，團隊應考慮幾個實際方面。該模型需要支持 CUDA 的硬件才能獲得最佳性能，但其高效的架構意味着它可以在消費級 GPU 上運行。它可通過多種渠道獲得：直接從 Hugging Face 下載、AWS Marketplace 部署或帶有 1000 萬個免費詞元的 Jina AI API。對於生產部署，us-east-1 區域中的 AWS SageMaker 提供了最具可擴展性的解決方案。該模型擅長通用文本分析，但對於未經微調的高度專業化的科學術語或領域特定術語，可能不是最佳選擇。處理長文檔時，請考慮將它們分解為有意義的語義塊，而不是任意拆分以保持上下文完整性。為獲得最佳結果，請實施適當的文本預處理並確保輸入數據乾淨、格式良好。","jina-embeddings-v2-base-es":"為了有效利用該模型，組織應確保能夠訪問支持 CUDA 的 GPU 基礎架構以獲得最佳性能。該模型與主要的矢量數據庫和 RAG 框架（包括 MongoDB、Qdrant、Weaviate 和 Haystack）無縫集成，使其可輕鬆部署到生產環境中。它在雙語文檔搜索、內容推薦系統和跨語言文檔分析等應用中表現出色。雖然該模型表現出色，但它特別針對西班牙語-英語雙語場景進行了優化，可能不是單語應用或涉及其他語言對的場景的最佳選擇。為了獲得最佳效果，輸入文本應以西班牙語或英語正確格式化，但該模型可以有效處理混合語言內容。該模型支持針對特定領域的應用程序進行微調，但應仔細考慮訓練數據的質量和分佈。","jina-embeddings-v2-base-zh":"該模型需要 322MB 的存儲空間，可通過多種渠道部署，包括 AWS SageMaker（us-east-1 區域）和 Jina AI API。雖然 GPU 加速不是強制性的，但它可以顯著提高生產工作負載的處理速度。該模型在文檔分析、多語言搜索和跨語言信息檢索等各種應用中表現出色，但用户應注意，它專門針對中英雙語場景進行了優化。為了獲得最佳效果，輸入文本應正確分段，雖然該模型最多可以處理 8,192 個詞元，但建議將極長的文檔分解為具有語義意義的塊以獲得更好的性能。該模型可能不適合需要實時處理非常短的文本的任務，在這些任務中，低延遲的專用模型可能更合適。","jina-embeddings-v3":"為了有效部署 Jina Embeddings v3，團隊應考慮其特定用例以選擇適當的任務適配器：搜索應用程序使用 retrieval.query 和 retrieval.passage，聚類任務使用分離，分類使用分類，語義相似性使用文本匹配。該模型需要具有 CUDA 功能的硬件才能獲得最佳性能，但其高效的架構意味着它所需的 GPU 內存比更大的替代方案少得多。對於生產部署，AWS SageMaker 集成提供了一條簡化的可擴展性路徑。該模型在多語言應用程序中表現出色，但對於資源匱乏的語言可能需要額外的評估。雖然它支持多達 8,192 個詞元的長文檔，但對於非常長的文本，使用後期分塊功能可實現最佳性能。團隊應避免將該模型用於需要實時生成或複雜推理的任務 - 它是為向量和檢索而設計的，而不是文本生成或直接問答。","jina-reranker-m0":"為了最大限度地發揮 jina-reranker-m0 的潛力，開發者應考慮多種實施策略。該模型可通過 API、雲服務市場（AWS、Azure、GCP）或 Hugging Face 本地訪問。使用 API 時，開發者可以傳遞文本字符串、base64 圖像或圖像 URL，新用户可獲得一千萬個免費詞元。得益於大量的訓練，該模型在文本轉文本、文本轉圖像、圖像轉文本以及文本轉混合單峯任務中表現優異，但值得注意的是，某些組合（例如圖像轉圖像）無需專門訓練即可以零樣本方式支持。為了獲得最佳效果，請記住該模型最多支持 10K 個輸入詞元，每幅圖像最多 768 個詞元。該架構的僅解碼器方法開闢了簡單重新排序之外的可能性，包括真正的混合模態重新排序、列表重新排序、文檔重複數據刪除和通過注意力機制的排名分數可解釋性 - 這些功能是以前的僅編碼器架構無法實現的。","jina-reranker-v1-base-en":"該模型需要支持 CUDA 的硬件才能實現最佳性能，並且可通過 API 端點和 AWS SageMaker 部署選項訪問。雖然它可以處理極長的序列，但用户應該考慮上下文長度和處理時間之間的權衡——模型的延遲會隨着文檔的延長而顯着增加，從 256 個詞元的 156 毫秒到 4096 個詞元的 7068 毫秒（512 個詞元查詢）。對於生產部署，建議實施兩階段管道，其中向量搜索提供重排的初始候選。該模型專門針對英語內容進行了優化，在多語言或代碼密集型文檔上可能無法達到最佳效果。與 RAG 系統集成時，用户應根據其延遲要求仔細調整發送以進行重排的文檔數量，100-200 個文檔通常可以在質量和性能之間提供良好的平衡。","jina-reranker-v1-tiny-en":"為了有效部署此模型，組織應優先考慮處理速度和資源效率是關鍵考慮因素的場景。該模型特別適合邊緣計算部署、移動應用程序和對延遲要求嚴格的高吞吐量搜索系統。雖然它在大多數重排任務中表現非常出色，但需要注意的是，對於需要絕對最高排名精度的應用程序，基本模型可能仍然是首選。該模型需要具有 CUDA 功能的 GPU 基礎設施才能獲得最佳性能，但其高效的架構意味着它可以在功能較弱的硬件上有效運行，而其大型同類產品則不然。對於部署，該模型與主要的矢量數據庫和 RAG 框架無縫集成，並且可通過 Reranker API 和 AWS SageMaker 獲得。在針對特定域進行微調時，用户應仔細平衡訓練數據質量和模型的緊湊架構，以保持其性能特徵。","jina-reranker-v1-turbo-en":"該模型需要支持 CUDA 的硬件才能實現最佳性能，並且可以通過 AWS SageMaker 部署或通過 API 端點訪問。對於生產部署，組織應實施兩階段管道，其中向量搜索提供重排的初始候選。雖然該模型支持 8,192 個詞元，但用户應考慮較長序列的延遲影響——處理時間會隨着文檔長度的增加而增加。大多數應用程序的最佳點是每個查詢重排 100-200 個候選，以平衡質量和速度。該模型專門針對英語內容進行了優化，在多語言文檔上可能無法達到最佳效果。內存要求明顯低於基本模型，通常只需要 150MB 的 GPU 內存，而 550MB 則需要，使其適合部署在較小的實例上，並在雲環境中節省大量成本。","jina-reranker-v2-base-multilingual":"為了實現最佳部署，該模型需要具有 CUDA 功能的 GPU，並且可以通過多種渠道訪問，包括 Reranker API、主要的 RAG 框架（如 Haystack 和 LangChain），或通過雲市場私下部署。該模型在需要跨語言障礙和數據類型進行精確理解的場景中表現出色，使其成為處理多語言內容、API 文檔或代碼存儲庫的全球企業的理想選擇。其廣泛的 524,288 個詞元上下文窗口支持一次性處理大型文檔或整個代碼庫。當團隊需要提高跨語言搜索準確性、需要代理 RAG 系統的函數調用功能或想要改進跨多語言代碼庫的代碼搜索功能時，應考慮使用此模型。該模型與矢量搜索系統結合使用時特別有效，可以顯著提高檢索到的文檔的最終排名。","reader-lm-05b":"為了有效部署 Reader LM 0.5B，組織應確保其基礎設施能夠滿足模型的 CUDA 要求，儘管其高效的架構意味着它可以在消費級 GPU 上運行。該模型最適合原始 HTML 輸入，不需要特殊的前綴或指令。為獲得最佳性能，請實施提供的重複檢測機制以防止在輸出生成中出現潛在的詞元循環。雖然該模型支持多種語言和各種 HTML 結構，但它專為內容提取和 markdown 轉換而設計 - 不應用於文本生成、摘要或直接問答等任務。該模型可通過 AWS SageMaker 進行生產部署，並提供 Google Colab 筆記本供測試和實驗。團隊應該注意，雖然該模型可以處理多達 256K 個詞元的超長文檔，但處理如此大的輸入可能需要額外的內存管理策略。","reader-lm-15b":"為了有效部署 Reader LM 1.5B，組織應專注於涉及複雜 HTML 文檔處理的場景，其中準確性和效率至關重要。該模型需要具有 CUDA 功能的 GPU 基礎設施才能獲得最佳性能，但其高效的架構意味着與更大的替代方案相比，它可以在更適中的硬件上有效運行。對於生產部署，該模型可通過 AWS SageMaker 和 Azure Marketplace 獲得，提供靈活的集成選項。雖然該模型在 HTML 到 markdown 的轉換方面表現出色，但需要注意的是，它專門針對此任務進行了優化，可能不適合通用文本生成或其他 NLP 任務。在處理極長的文檔（接近 512K 個詞元）時，用户應注意性能可能會下降，因為這超出了模型的訓練參數。為獲得最佳結果，請實施提供的重複檢測機制，並考慮在推理過程中使用對比搜索以保持輸出質量。",title:"最佳實踐"},image_size:"輸入圖片大小",language:"語言支持",methods:{"ReaderLM-v2":"ReaderLM-v2 基於 Qwen2.5-1.5B-Instruction 構建，其訓練基於一個包含一千萬個 HTML 文檔的 html-markdown-1m 數據集，每個文檔平均包含 56,000 個 token。訓練過程包括：1) 使用 Ring-zag Attention 和 RoPE 進行長上下文預訓練，將上下文從 32,000 個 token 擴展到 256,000 個 token；2) 使用精煉數據集進行監督微調；3) 直接偏好優化以實現輸出對齊；以及 4) 自我對弈強化調整。數據準備遵循由 Qwen2.5-32B-Instruction 驅動的三步流程（起草-精煉-評審），其中針對特定任務訓練了專門的模型，然後通過線性參數插值進行合併。","jina-clip-v1":"該模型的架構代表了多模態 AI 設計的重大創新，將經過調整的 Jina BERT v2 文本編碼器與北京人工智能研究院的尖端 EVA-02 圖片編碼器相結合。文本編碼器支持最多 12,288 個詞元的序列 - 比原始 CLIP 的 77 個詞元限制長 100 多倍 - 而圖片編碼器可以高效處理 16 個補丁詞元。訓練過程遵循一種新穎的三步方法：首先，通過交錯文本對訓練對齊圖片-標題對，同時保持文本理解；其次，結合 AI 生成的較長的圖片文本描述；最後，使用硬負文本三元組來增強語義區分能力。這種獨特的訓練方法使模型能夠在短標題和詳細文本描述中保持高性能，同時保留強大的視覺理解力。","jina-clip-v2":"Jina CLIP v2 的核心是採用複雜的雙編碼器架構，將 Jina XLM-RoBERTa 文本編碼器（561M 參數）與 EVA02-L14 視覺編碼器（304M 參數）相結合。文本編碼器使用 696,320 個詞元的海量上下文窗口處理 89 種語言的內容，而視覺編碼器則處理高達 512x512 像素的高分辨率圖片。該模型引入了創新的 Matryoshka 表示學習，可在保持性能的同時實現動態向量維度從 1024 維到 64 維的調整。該架構通過各自的編碼器處理文本和圖片，將它們投射到共享語義空間中，無論其原始模態或語言如何，相似的概念都可以對齊。","jina-colbert-v1-en":"該模型採用創新的後期交互架構，從根本上改變了文檔檢索的工作方式。它並非一次性比較所有文檔，而是使用改良版的 ColBERT 方法，在最終匹配階段之前獨立處理查詢和文檔。該架構結合了兩個關鍵組件：一個文檔編碼器，可處理多達 8,192 個 token（比標準 Transformer 長 16 倍以上），以及一個查詢編碼器，可創建精確的 token 級表徵。查詢和文檔中的每個 token 都擁有各自的 128 維嵌入向量，從而保留了單向量中可能丟失的細粒度語義信息。後期交互機制支持查詢和文檔之間高效的逐 token 匹配，使用最大池化和求和運算來計算最終的相關性得分，而無需進行昂貴的“全部對全部”比較。","jina-colbert-v2":"該模型以 ColBERT 架構為基礎，引入了一種複雜的後期交互機制，從根本上改變了查詢和文檔的匹配方式。其核心是使用經過修改的 XLM-RoBERTa 主幹，具有 5.6 億個參數，通過旋轉位置向量增強，並通過閃存注意進行優化。訓練過程涉及兩個關鍵階段：使用來自各種語言的各種弱監督數據進行初始預訓練，然後使用詞元三元組數據進行微調和監督蒸餾。這種方法的獨特之處在於實現了 Matryoshka 表示學習，這使模型能夠從單個訓練過程中生成多個維度（128、96 或 64）的向量，從而允許動態存儲優化而無需重新訓練。","jina-embedding-b-en-v1":"該模型採用基於 T5 編碼器的架構，並通過均值池化增強來生成固定長度的表示。該模型在精心策劃的 Linnaeus-Clean 數據集上進行訓練，該數據集包含從最初的 16 億對句子中篩選出的 3.85 億對高質量句子對，該模型經歷了兩個階段的訓練過程。第一階段利用對比學習對文本對進行 InfoNCE 損失，而第二階段則採用三重訓練來提高模型區分相似和不同內容的能力。這種創新的訓練方法與嚴格的數據過濾（包括語言檢測和一致性檢查）相結合，使模型能夠有效捕捉細微的語義關係。","jina-embeddings-v2-base-code":"該模型通過專門為代碼理解而設計的專用架構實現了令人印象深刻的性能。其核心是使用基於 Transformer 的神經網絡，該網絡具有 1.61 億個參數，在各種編程語言數據集上進行訓練，重點是六種主要語言：Python、JavaScript、Java、PHP、Go 和 Ruby。該架構的獨特之處在於其擴展的上下文窗口為 8,192 個詞元，使其能夠同時處理整個函數或多個文件，同時保持語義理解。該模型生成密集的 768 維向量，可捕獲代碼的句法結構和語義含義，使其能夠理解不同代碼段之間的關係，即使它們使用不同的編程模式或語法來實現相同的目標。","jina-embeddings-v2-base-de":"該模型通過創新架構實現了令人印象深刻的雙語能力，該架構在統一的 768 維向量空間中處理德語和英語文本。其核心是採用基於 Transformer 的神經網絡，該網絡具有 1.61 億個參數，經過精心訓練，可以理解兩種語言之間的語義關係。這種架構特別有效的原因是其偏差最小化方法，專門設計用於避免偏向英語語法結構的常見陷阱 - 這是最近多語言模型研究中發現的一個問題。該模型的擴展上下文窗口為 8,192 個詞元，使其能夠一次性處理整個文檔或多頁文本，從而保持兩種語言長篇內容的語義一致性。","jina-embeddings-v2-base-en":"該模型的架構將 BERT Small 主幹與創新的對稱雙向 ALiBi（具有線性偏差的注意力機制）機制相結合，消除了對傳統位置向量的需求。這種架構選擇使模型能夠推斷出遠遠超出其 512 個詞元的訓練長度，處理多達 8,192 個詞元的序列而不會降低性能。訓練過程涉及兩個關鍵階段：在 C4 數據集上進行初始預訓練，然後在 Jina AI 精選的 40 多個專業數據集上進行細化。這些多樣化的訓練數據（包括具有挑戰性的負面示例和不同的句子對）確保了在不同領域和用例中的穩健性能。該模型生成 768 維密集向量，可捕捉細微的語義關係，使用相對適中的 137M 個參數實現。","jina-embeddings-v2-base-es":"該模型的核心是基於對稱雙向 ALiBi（具有線性偏差的注意力機制）的創新架構，這是一種複雜的方法，無需傳統的位置向量即可處理多達 8,192 個詞元的序列。該模型採用具有 161M 個參數的改進的 BERT 架構，結合了門控線性單元 (GLU) 和專門的層規範化技術。訓練遵循三個階段的過程：首先在海量文本語料庫上進行預訓練，然後使用精心挑選的文本對進行微調，最後進行硬負訓練以增強對相似但語義不同的內容的區分。這種方法與 768 維向量相結合，使模型能夠捕捉細微的語義關係，同時保持計算效率。","jina-embeddings-v2-base-zh":"該模型的架構將基於 BERT 的主幹與對稱雙向 ALiBi（具有線性偏差的注意力機制）相結合，從而能夠高效處理長序列，而不受傳統 512 個 token 的限制。訓練過程遵循精心策劃的三階段方法：首先在高質量雙語數據上進行預訓練，然後進行主要和次要微調階段。這種有條不紊的訓練策略，加上模型的 161M 參數和 768 維輸出，實現了卓越的效率，同時保持了兩種語言的平衡性能。對稱雙向 ALiBi 機制代表了一項重大創新，使模型能夠處理長度高達 8,192 個 token 的文檔——這一功能以前僅限於專有解決方案。","jina-embeddings-v3":"該模型的架構代表了向量技術的重大創新，它建立在具有 24 層的 jina-XLM-RoBERTa 基礎上，並通過特定於任務的低秩自適應 (LoRA) 適配器進行了增強。LoRA 適配器是專門的神經網絡組件，可針對不同的任務（如檢索、分類或聚類）優化模型，而不會顯着增加參數數量 - 它們使總參數增加不到 3%。該模型結合了 Matryoshka 表示學習 (MRL)，允許將向量從 1024 維靈活地減少到 32 維，同時保持性能。訓練涉及三個階段：對來自 89 種語言的多語言文本進行初始預訓練，對成對文本進行微調以提高向量質量，以及專門的適配器訓練以優化任務。該模型通過旋轉位置向量 (RoPE) 支持高達 8,192 個詞元的上下文長度，並採用創新的基頻調整技術來提高短文本和長文本的性能。","jina-reranker-m0":"jina-reranker-m0 的架構與之前的方法有很大不同。它基於具有 21 億個參數的 Qwen2-VL-2B 構建，從經典的交叉編碼器架構轉變為僅解碼器的視覺語言模型。該系統利用 Qwen2-VL 的預訓練視覺編碼器和投影儀，使用 LoRA（低秩自適應）微調其大型語言模型，並使用後訓練的 MLP 來生成衡量查詢文檔相關性的排名邏輯。這個判別模型可以處理多達 32K 個標記，並支持從 56×56 像素到 4K 分辨率的圖像。在處理圖像時，視覺轉換器 (ViT) 和投影儀將相鄰的 2×2 標記壓縮為單個視覺標記，而特殊標記則清楚地標記視覺標記邊界，使語言模型能夠正確地集成和推理視覺和文本元素。","jina-reranker-v1-base-en":"該模型採用基於 BERT 的交叉注意架構，與傳統的基於向量的方法有着根本區別。它不是比較預先計算的文檔向量，而是在查詢和文檔之間執行動態詞元級交互，從而能夠捕捉簡單的相似性指標所遺漏的上下文細微差別。該架構的 1.37 億個參數經過精心設計，可在保持計算效率的同時實現深度語義理解。一個突出的創新是它能夠處理多達 262,144 個詞元的序列（遠遠超出了典型的模型限制），這是通過複雜的優化技術實現的，儘管上下文窗口增加了，但仍能保持快速的推理速度。","jina-reranker-v1-tiny-en":"該模型採用基於 JinaBERT 的精簡四層架構，具有對稱雙向 ALiBi（具有線性偏差的注意力機制），可高效處理長序列。其開發利用了一種先進的知識蒸餾方法，其中更大的高性能教師模型 (jina-reranker-v1-base-en) 指導訓練過程，使較小的模型無需大量現實世界的訓練數據即可學習最佳排名行為。這種創新的訓練方法與減少隱藏層和高效注意力機制等架構優化相結合，使模型能夠保持高質量的排名，同時顯著降低計算要求。結果是模型實現了卓越的效率，同時又不損害其理解複雜文檔關係的能力。","jina-reranker-v1-turbo-en":"該模型通過創新的六層架構實現了其效率，該架構將其較大模型的複雜重排功能壓縮為僅 3780 萬個參數 - 與基礎模型的 1.37 億個參數相比大幅減少。這種精簡的設計採用知識蒸餾，其中較大的基礎模型充當老師，訓練 turbo 變體以匹配其行為，同時使用更少的資源。該架構保留了核心的基於 BERT 的交叉注意機制，用於查詢和文檔之間的詞元級交互，但通過減少層數和有效的參數分配來優化其速度。該模型支持多達 8,192 個詞元的序列，通過複雜的優化技術實現全面的文檔分析，同時保持快速的推理速度。","jina-reranker-v2-base-multilingual":"該模型採用了通過 Flash Attention 2 增強的交叉編碼器架構，可以直接比較查詢和文檔，從而更準確地評估相關性。該模型經過四階段的訓練，首先建立英語語言能力，然後逐步整合跨語言和多語言數據，最後使用硬負樣本進行細化。這種創新的訓練方法與 Flash Attention 2 實現相結合，使該模型能夠處理多達 524,288 個詞元的序列，同時保持出色的速度。該架構的效率使其能夠處理跨多種語言的複雜重排任務，吞吐量比其前代產品高出 6 倍，同時通過直接查詢文檔交互確保準確的相關性評估。","reader-lm-05b":"該模型採用創新的“淺而寬”架構，專門針對選擇性複製操作而非創造性文本生成進行優化。該模型建立在僅解碼器的基礎上，具有 24 層和 896 個隱藏維度，使用具有 14 個查詢頭和 2 個鍵值頭的專門注意機制來高效處理輸入序列。訓練過程涉及兩個不同的階段：首先使用更短、更簡單的 HTML（32K 個詞元）來學習基本的轉換模式，然後使用複雜的真實 HTML（128K 個詞元）來處理具有挑戰性的情況。該模型在訓練期間結合了對比搜索，並實施了重複檢測機制，以防止出現詞元循環等退化問題。其架構的一個獨特方面是鋸齒環注意機制，這使模型能夠處理高達 256K 個詞元的極長序列，同時保持穩定的性能。","reader-lm-15b":"該模型採用了一種創新的“淺而寬”架構，挑戰了語言模型設計中的傳統擴展方法。其核心是 28 個Transformer層，配置了 12 個查詢頭和 2 個鍵值頭，從而創建了一種獨特的平衡，可優化選擇性複製操作，同時保持深度語義理解。該架構的隱藏大小為 1536，中間大小為 8960，經過精心調整，可處理最多 256K 個詞元的序列。訓練過程涉及兩個不同的階段：首先專注於具有 32K 個詞元序列的短而簡單的 HTML，然後推進到具有 128K 個詞元的長而難的 HTML，實現鋸齒狀環注意以實現高效處理。這種方法與對比搜索和專門的重複檢測機制相結合，使模型能夠避免處理複雜文檔處理任務的小型語言模型中通常存在的退化和死循環等常見問題。",title:"方法"},model_comparison:"模型比較",model_details:"模型詳細信息",model_io_graph:"I/O 圖 {_number}",model_name:"名稱",output_dimension:"輸出維度",overview:{"ReaderLM-v2":"ReaderLM-v2 是一個 1.5B 參數語言模型，可將原始 HTML 轉換為 markdown 或 JSON，處理最多 512K 個詞元組合輸入/輸出長度，支持 29 種語言。與將 HTML 到 markdown 視為“選擇性複製”任務的前身不同，v2 將其視為翻譯過程，從而能夠出色地處理代碼圍欄、嵌套列表、表格和 LaTeX 方程式等複雜元素。該模型在不同的上下文長度下保持一致的性能，並引入了具有預定義架構的直接 HTML 到 JSON 生成功能。","jina-clip-v1":"Jina CLIP v1 是第一個在文本轉文本和文本轉圖片檢索任務中表現優異的模型，它徹底改變了多模態 AI。與在純文本場景中表現不佳的傳統 CLIP 模型不同，該模型在所有檢索組合中都實現了最先進的性能，同時保持了非常緊湊的 223M 參數大小。該模型解決了一個關鍵的行業挑戰，它消除了對用於文本和圖片處理的單獨模型的需求，從而降低了系統複雜性和計算開銷。對於構建搜索系統、推薦引擎或內容分析工具的團隊，Jina CLIP v1 提供了一個單一、高效的解決方案，可以以極高的準確性處理文本和視覺內容。","jina-clip-v2":"Jina CLIP v2 徹底改變了多模態 AI，它彌合了 89 種語言中視覺和文本理解之間的差距。該模型通過實現準確的圖片文本匹配，解決了全球電子商務、內容管理和跨文化交流中的關鍵挑戰，不受語言障礙的影響。對於在國際上擴張或管理多語言內容的企業來説，它消除了對每種語言單獨使用模型或複雜翻譯流程的需求。該模型在需要跨語言邊界進行精確視覺搜索的場景中尤其出色，例如全球市場產品發現或多語言數字資產管理。","jina-colbert-v1-en":"Jina-ColBERT-v1-en 通過解決信息檢索中的一個關鍵挑戰，徹底改變了文本搜索：在不犧牲計算效率的情況下實現高精度。與將整個文檔壓縮為單個向量的傳統模型不同，此模型在僅需要 1.37 億個參數的情況下保持了精確的詞元級理解。對於構建搜索應用程序、推薦系統或內容發現平台的團隊來説，Jina-ColBERT-v1-en 消除了搜索質量和系統性能之間的傳統權衡。該模型在細緻入微的文本理解至關重要的場景中尤其出色，例如技術文檔搜索、學術論文檢索或任何捕捉微妙的語義關係可能會在找到正確信息和遺漏關鍵內容之間產生差異的應用程序。","jina-colbert-v2":"Jina-ColBERT-v2 是一種突破性的多語言信息檢索模型，解決了跨多種語言進行高效、高質量搜索的關鍵挑戰。作為第一個生成緊湊向量的多語言 ColBERT 類模型，它滿足了全球應用中對可擴展、經濟高效的多語言搜索解決方案日益增長的需求。從電子商務平台到內容管理系統，處理多語言內容的組織可以利用此模型提供 89 種語言的準確搜索結果，同時通過其創新的降維功能顯着降低存儲和計算成本。","jina-embedding-b-en-v1":"Jina Embedding B v1 是一種專門的文本向量模型，旨在將英文文本轉換為高維數字表示，同時保持語義含義。該模型滿足了生產環境中對高效、準確的文本向量的關鍵需求，對於需要在計算效率和向量質量之間取得平衡的組織尤其有價值。憑藉其 1.1 億個參數生成 768 維向量，它可作為團隊實施語義搜索、文檔聚類或內容推薦系統的實用解決方案，而無需大量計算資源。","jina-embeddings-v2-base-code":"Jina Embeddings v2 基礎代碼解決了現代軟件開發中的一個關鍵挑戰：高效導航和理解大型代碼庫。對於在代碼發現和文檔方面遇到困難的開發團隊，此模型通過跨 30 種編程語言啓用自然語言搜索，改變了開發人員與代碼交互的方式。與依賴精確模式匹配的傳統代碼搜索工具不同，此模型理解代碼背後的語義含義，允許開發人員使用簡單的英語描述找到相關的代碼片段。此功能對於維護大型遺留代碼庫的團隊、加入新項目的開發人員或希望改進代碼重用和文檔實踐的組織尤其有價值。","jina-embeddings-v2-base-de":"Jina Embeddings v2 Base German 解決了國際業務中的一個關鍵挑戰：彌合德語和英語市場之間的語言差距。對於向英語地區擴張的德國公司來説，準確的雙語理解至關重要，因為英語地區三分之一的企業的全球銷售額佔比超過 20%。該模型通過實現德語和英語的無縫文本理解和檢索，改變了組織處理跨語言內容的方式，這對於實施國際文檔系統、客户支持平台或內容管理解決方案的公司來説非常有用。與傳統的基於翻譯的方法不同，該模型將兩種語言的等效含義直接映射到相同的向量空間，從而實現更準確、更高效的雙語操作。","jina-embeddings-v2-base-en":"Jina Embeddings v2 Base English 是一種突破性的開源文本向量模型，它解決了處理長文檔同時保持高準確率的關鍵挑戰。那些難以分析大量法律文件、研究論文或財務報告的組織會發現這個模型特別有價值。它以處理長度高達 8,192 個詞元的文檔而脱穎而出——比傳統模型長 16 倍——同時性能與 OpenAI 的專有解決方案相匹配。它體積小巧，僅為 0.27GB，資源利用率高，為尋求實施高級文檔分析而無需過多計算開銷的團隊提供了一個可訪問的解決方案。","jina-embeddings-v2-base-es":"Jina Embeddings v2 Base Spanish 是一種突破性的雙語文本向量模型，可解決西班牙語和英語內容之間的跨語言信息檢索和分析這一關鍵挑戰。與通常偏向特定語言的傳統多語言模型不同，該模型在西班牙語和英語之間實現了真正平衡的性能，對於在西班牙語市場運營或處理雙語內容的組織來説，它是必不可少的。該模型最引人注目的特點是它能夠生成幾何對齊的向量 - 當西班牙語和英語文本表達相同的含義時，它們的向量表示會自然地聚集在向量空間中，從而實現無縫的跨語言搜索和分析。","jina-embeddings-v2-base-zh":"Jina Embeddings v2 Base Chinese 開創了先河，成為第一個無縫處理中文和英文文本的開源模型，其上下文長度達到前所未有的 8,192 個 token。這個強大的雙語模型解決了全球商業面臨的一個關鍵挑戰：需要準確、長篇文檔處理中文和英文內容。與傳統模型難以進行跨語言理解或需要為每種語言建立單獨的模型不同，該模型將兩種語言的等效含義映射到同一個向量空間，這對於在全球範圍內擴張或管理多語言內容的組織來説非常有價值。","jina-embeddings-v3":"Jina Embeddings v3 是一種突破性的多語言文本向量模型，它改變了組織處理跨語言文本理解和檢索的方式。從本質上講，它解決了在多種語言和任務中保持高性能，同時保持計算要求可控的關鍵挑戰。該模型在效率至關重要的生產環境中尤其出色 - 它僅用 5.7 億個參數就實現了最先進的性能，這使得無法承擔較大模型計算開銷的團隊也可以使用它。需要構建可擴展的多語言搜索系統或跨語言障礙分析內容的組織會發現這個模型特別有價值。","jina-reranker-m0":"jina-reranker-m0 是一種突破性的多模態多語言重排器，旨在對多種語言的視覺文檔進行排序。該模型的卓越之處在於它能夠處理 29 種語言的查詢以及視覺豐富的文檔圖像（包括帶有文本、圖形、表格和各種佈局的頁面）。該模型輸出按與輸入查詢的相關性排序的文檔列表。與之前苦苦應對“模態差距”問題（其中圖像聚集在其他圖像附近，而文本聚集在文本附近）的重排器不同，jina-reranker-m0 將文本和視覺模態統一在一個僅解碼器的模型中，從而創建一種無縫的多模態搜索體驗，可以有效地對圖像和文本文檔進行排序。","jina-reranker-v1-base-en":"Jina Reranker v1 Base English 徹底改變了搜索結果優化，解決了傳統向量搜索系統的一個關鍵限制：無法捕捉查詢和文檔之間的細微關係。雖然採用餘弦相似度的向量搜索可以快速提供初始結果，但它通常會錯過人類用户直觀理解的細微相關性信號。此重排器通過對查詢和文檔執行復雜的詞元級分析來彌補這一差距，將搜索準確率提高了 20%。對於在搜索精度方面遇到困難或實施 RAG 系統的組織，此模型提供了一種強大的解決方案，可顯著提高結果質量，而無需徹底改造現有的搜索基礎設施。","jina-reranker-v1-tiny-en":"Jina Reranker v1 Tiny English 代表了高效搜索優化的突破，專為需要在資源受限環境中進行高性能重排的組織而設計。該模型解決了保持搜索質量的關鍵挑戰，同時顯著降低了計算開銷和部署成本。它僅使用 33M 個參數（典型重排器大小的一小部分），通過創新的知識提煉技術提供了極具競爭力的性能。該模型最令人驚訝的功能是它能夠以比基礎模型快近五倍的速度處理文檔，同時保持 92% 以上的準確率，使企業級搜索優化可供計算資源非常寶貴的應用程序使用。","jina-reranker-v1-turbo-en":"Jina Reranker v1 Turbo English 解決了生產搜索系統中的一個關鍵挑戰：結果質量和計算效率之間的權衡。雖然傳統的重排器提供了更高的搜索準確度，但它們的計算需求往往使它們不適用於實時應用。該模型突破了這一障礙，它提供了基本模型 95% 的準確度，同時處理文檔的速度提高了三倍，使用的內存減少了 75%。對於在搜索延遲或計算成本方面苦苦掙扎的組織，該模型提供了一個引人注目的解決方案，既能保持高質量的搜索優化，又能顯著降低基礎設施要求和運營成本。","jina-reranker-v2-base-multilingual":"Jina Reranker v2 Base Multilingual 是一種跨編碼器模型，旨在提高跨語言障礙和數據類型的搜索準確性。此重排器解決了多語言環境中精確信息檢索的關鍵挑戰，對於需要跨不同語言和內容類型優化搜索結果的全球企業尤其有價值。它支持 100 多種語言，並具有獨特的函數調用和代碼搜索功能，是需要跨國際內容、API 文檔和多語言代碼庫進行精確搜索優化的團隊的統一解決方案。該模型緊湊的 278M 參數設計使其對於尋求平衡高性能和資源效率的組織特別有吸引力。","reader-lm-05b":"Reader LM 0.5B 是一種專門的語言模型，旨在解決將 HTML 文檔轉換為乾淨、結構化的 Markdown 文本的複雜挑戰。該模型滿足了現代數據處理流程中的一項關鍵需求：高效地將雜亂的 Web 內容轉換為適合大模型和文檔系統的格式。與需要大量計算資源的通用語言模型不同，Reader LM 0.5B 僅使用 4.94 億個參數即可實現專業級 HTML 處理，這使得計算資源有限的團隊也可以使用它。處理 Web 內容處理、文檔自動化或構建大模型支持的應用程序的組織會發現此模型對於簡化其內容準備工作流程特別有用。","reader-lm-15b":"Reader LM 1.5B 代表了高效文檔處理方面的突破，解決了將複雜的 Web 內容轉換為乾淨的結構化格式這一關鍵挑戰。這種專門的語言模型解決了現代 AI 流程中的一個基本問題：需要高效處理和清理 HTML 內容以用於下游任務，而無需依賴脆弱的基於規則的系統或資源密集型的大型語言模型。這個模型真正引人注目的地方在於，它能夠超越其大小 50 倍的模型，同時保持令人驚訝的緊湊的 1.54B 參數佔用空間。處理大規模 Web 內容處理、文檔自動化或內容管理系統的組織會發現這個模型特別有價值，因為它能夠處理極長的文檔，同時在 HTML 到 Markdown 的轉換中提供卓越的準確性。",title:"概述"},parameter_size:"參數",performance:{"ReaderLM-v2":"在綜合基準測試中，ReaderLM-v2 在 HTML 到 Markdown 任務上的表現優於 Qwen2.5-32B-Instruct 和 Gemini2-flash-expr 等大型模型。對於主要內容提取，它實現了 0.84 的 ROUGE-L、0.82 的 Jaro-Winkler，並且與競爭對手相比，Levenshtein 距離 (0.22) 明顯更低。在 HTML 到 JSON 任務中，它保持了具有競爭力的性能，F1 得分為 0.81，通過率為 98%。該模型在 T4 GPU 上以 67 個 token/s 的輸入和 36 個 token/s 的輸出進行處理，通過對比損失訓練顯著減少了退化問題。","jina-clip-v1":"Jina CLIP v1 在所有基準測試中都比 OpenAI 的原始 CLIP 有了顯著的改進。在純文本檢索中，它的性能提高了 165%，得分為 0.429，而 CLIP 的得分為 0.162。對於與圖片相關的任務，它顯示出持續的改進：文本到圖片檢索提高了 2%（0.899），圖片到文本檢索提高了 6%（0.803），圖片到圖片檢索提高了 12%（0.916）。該模型在零樣本視覺分類任務中尤其出色，無需在特定領域進行事先訓練即可成功對圖片進行分類。在標準基準（如文本檢索的 MTEB、圖片任務的 CIFAR-100 以及跨模態性能的 Flickr8k/30k 和 MSCOCO Captions）上進行評估時，它始終優於專門的單模態模型，同時在跨模態任務中保持了有競爭力的性能。","jina-clip-v2":"該模型在 Flickr30k 圖片到文本檢索任務中實現了 98.0% 的準確率，超越了其前身和 NLLB-CLIP-SigLIP，達到了最佳性能。在多語言場景中，儘管參數比其最大的競爭對手少，但在跨語言圖片檢索任務中，該模型比 NLLB-CLIP-SigLIP 提高了 4%。即使向量被壓縮，該模型仍能保持強勁的性能 - 將尺寸減少 75% 仍可在文本、圖片和跨模態任務中保持 99% 以上的性能。在綜合多語言 MTEB 基準測試中，它在檢索任務中實現了 69.86%，在語義相似性任務中實現了 67.77%，與專門的文本向量模型相比具有競爭力。","jina-colbert-v1-en":"Jina-ColBERT-v1-en 在各種基準測試中都比基線模型表現出色。在 BEIR 數據集上，它在多個類別中取得了優異的表現：Arguana 上為 49.4%（而 ColBERTv2 為 46.5%），FEVER 上為 79.5%（而 ColBERTv2 為 78.8%），TREC-COVID 上為 75.0%（而 ColBERTv2 為 72.6%）。最令人印象深刻的是，它在長上下文理解的 LoCo 基準測試中表現出了顯著的改進，得分為 83.7%，而 ColBERTv2 為 74.3%。該模型在需要詳細語義理解的場景中尤其出色，通過其創新的後期交互方法，它的表現優於傳統的向量模型，同時保持了計算效率。這些改進是在將模型的參數數量保持在 137M 的適中水平的同時實現的，使其功能強大且適用於生產部署。","jina-colbert-v2":"在實際測試中，Jina-ColBERT-v2 在多個基準測試中展現出卓越的能力。它在英語任務上的表現比原始的 ColBERT-v2 提高了 6.5%，在 14 個 BEIR 基準測試中的平均得分為 0.521。更令人印象深刻的是，它在 MIRACL 基準測試中在所有測試語言中的表現都優於傳統的基於 BM25 的檢索方法，在跨語言場景中表現出特別的優勢。即使在使用減少的向量維度時，該模型也能保持這種高性能 - 從 128 維降至 64 維僅導致性能下降 1.5%，同時存儲需求減半。這意味着生產成本顯著節省：例如，在 AWS 上存儲 1 億份具有 64 維向量的文檔每月成本為 659.62 美元，而 128 維則為 1,319.24 美元。","jina-embedding-b-en-v1":"在實際評估中，Jina Embedding B v1 展現出令人印象深刻的功能，尤其是在語義文本相似性任務中。該模型在 STS12 上以 0.751 的得分實現了最佳性能，超越了 all-mpnet-base-v2 和 all-minilm-l6-v2 等成熟模型。它在各種基準測試中都表現出色，同時保持了高效的推理時間。但是，用户應注意，該模型專門針對英語內容進行了優化，在多語言或特定於代碼的任務上可能無法達到最佳性能。該模型已被 jina-embeddings-v2-base-en 和 jina-embeddings-v3 取代，它們在更廣泛的用例中提供了增強的性能。","jina-embeddings-v2-base-code":"在實際測試中，Jina Embeddings v2 Base Code 展現出卓越的能力，在 15 個關鍵 CodeNetSearch 基準測試中的 9 箇中處於領先地位。與微軟和 Salesforce 等行業巨頭的模型相比，它在保持更高效的佔用空間的同時實現了卓越的性能。該模型在跨語言代碼理解方面尤其出色，成功地匹配了不同編程語言中功能等效的代碼片段。它的 8,192 個 token 上下文窗口對於大型函數和複雜代碼文件特別有價值，遠遠優於通常只能處理幾百個 token 的傳統模型。該模型的效率體現在其 307MB（未量化）的緊湊尺寸上，可實現快速推理，同時在代碼相似性和搜索任務中保持高精度。","jina-embeddings-v2-base-de":"在實際測試中，Jina Embeddings v2 Base German 表現出卓越的效率和準確性，尤其是在跨語言檢索任務中。該模型在大小不到微軟 E5 基礎模型三分之一的情況下表現優於後者，儘管體積只有後者的七分之一，但性能卻與 E5 大型模型相當。在包括用於英語到德語檢索的 WikiCLIR、用於雙向語言理解的 STS17 和 STS22 以及用於精確雙語文本對齊的 BUCC 在內的關鍵基準測試中，該模型始終表現出卓越的能力。其緊湊的尺寸為 322MB，可在標準硬件上部署，同時保持最先進的性能，使其在考慮計算資源的生產環境中特別高效。","jina-embeddings-v2-base-en":"在實際測試中，Jina Embeddings v2 Base English 在多個基準測試中展現出卓越的能力。它在幾個關鍵指標上都優於 OpenAI 的 text-embedding-ada-002：分類（73.45% vs 70.93%）、重排（85.38% vs 84.89%）、檢索（56.98% vs 56.32%）和摘要（31.6% vs 30.8%）。這些數字在文檔分類等任務中轉化為實際優勢，其中模型顯示出對複雜文本進行分類的卓越能力，並在搜索應用中，它更好地理解用户查詢並找到相關文檔。但是，用户應注意，在處理訓練數據中未表示的高度專業化領域特定內容時，性能可能會有所不同。","jina-embeddings-v2-base-es":"在綜合基準評估中，該模型表現出卓越的能力，特別是在跨語言檢索任務中，儘管其規模只有 E5 和 BGE-M3 等大型多語言模型的 15-30%，但其表現卻優於後者。該模型在檢索和聚類任務中表現出色，在跨語言匹配語義等效內容方面表現出色。在 MTEB 基準測試中，它在分類、聚類和語義相似性等各種任務中表現出色。8,192 個詞元的擴展上下文窗口對於長文檔處理尤其有價值，即使文檔跨越多頁，也能表現出一致的性能——這是大多數競爭模型所缺乏的能力。","jina-embeddings-v2-base-zh":"在中文 MTEB (C-MTEB) 排行榜的基準測試中，該模型在 0.5GB 以下的模型中表現出色，尤其是在中文任務中表現出色。它在中文特定應用中的表現明顯優於 OpenAI 的 text-embedding-ada-002，同時在英語任務中保持了競爭力。此版本中的一個顯着改進是改進了相似度分數分佈，解決了預覽版本中存在的分數膨脹問題。該模型現在提供更獨特、更合乎邏輯的相似度分數，確保更準確地表示文本之間的語義關係。這種增強在比較測試中尤為明顯，其中模型在兩種語言中對相關和不相關內容表現出更好的區分能力。","jina-embeddings-v3":"該模型在實際測試中展現出卓越的效率性能比，在英語任務上的表現優於開源替代方案以及來自 OpenAI 和 Cohere 的專有解決方案，同時在多語言場景中也表現出色。最令人驚訝的是，它取得了比參數多 12 倍的 e5-mistral-7b-instruct 更好的結果，凸顯了其卓越的效率。在 MTEB 基準評估中，它在所有任務中獲得了 65.52 的平均分數，在分類準確率（82.58）和句子相似度（85.80）方面表現尤為出色。該模型在不同語言中保持一致的性能，在多語言任務上的得分為 64.44。當使用 MRL 進行降維時，即使在較低維度下也能保持強勁性能 - 例如，與完整的 1024 維相比，64 維可以保持 92% 的檢索性能。","jina-reranker-m0":"Jina-reranker-m0 在多個基準測試中取得了令人印象深刻的成績。在文本到文本重排中，它在 BEIR 基準測試中獲得了 58.95 NDCG-10 的分數，優於 jina-embeddings-v3（55.81）和 bge-reranker-v2-m3（56.51）等競爭對手。對於多語言內容，它在涵蓋 18 種語言的 MIRACL 基準測試中獲得了 66.75 NDCG-10。在針對長文檔的 MLDR 基準測試中，它在 13 種語言中獲得了 59.83 NDCG-10。對於 CoIR 基準測試中的代碼檢索，它獲得了 63.55 NDCG-10，遠遠優於競爭對手。但該模型在視覺文檔檢索方面真正大放異彩——在 ViDoRe 基準測試中，它獲得了令人印象深刻的 91.02 NDCG-5 分數，而在測試視覺語言組合推理的 Winoground 上，它獲得了 43.92 的平均分數，證明了它與其他模型相比，在理解文本和圖像之間關係方面具有更出色的能力。","jina-reranker-v1-base-en":"在綜合基準測試中，該模型在關鍵指標方面表現出色，與基線向量搜索相比，命中率提高了 8%，平均倒數排名提高了 33%。在 BEIR 基準測試中，它的平均得分為 0.5588，優於 BGE（0.5032）、BCE（0.4969）和 Cohere（0.5141）等其他重排器。其在 LoCo 基準測試中的表現尤其令人印象深刻，平均得分為 0.873，在理解局部連貫性和上下文感知排名方面遠遠領先於競爭對手。該模型在技術內容評估方面表現出色，在 qasper_abstract 任務中得分為 0.996，在政府報告分析中得分為 0.962，但在會議摘要任務中表現相對較低（0.466）。","jina-reranker-v1-tiny-en":"在綜合基準評估中，該模型展現出卓越的能力，挑戰了傳統的大小與性能之間的權衡。在 BEIR 基準測試中，該模型的 NDCG-10 得分為 48.54，保留了基礎模型 92.5% 的性能，而尺寸僅為其四分之一。更令人印象深刻的是，在 LlamaIndex RAG 基準測試中，它保持了 83.16% 的命中率，幾乎與更大的模型相匹配，同時處理文檔的速度明顯更快。該模型在吞吐量方面尤其出色，處理文檔的速度幾乎是基礎模型的五倍，而使用的內存甚至比 turbo 版本還要少 13%。這些指標轉化為實際性能，可與 mxbai-rerank-base-v1（184M 個參數）和 bge-reranker-base（278M 個參數）等更大的模型相媲美或超過它們。","jina-reranker-v1-turbo-en":"在綜合基準測試中，turbo 變體表現出卓越的效率，且準確度沒有顯著降低。在 BEIR 基準測試中，它獲得了 49.60 的 NDCC-10 得分，保留了基礎模型 95% 的性能（52.45），同時超越了許多更大的競爭對手，如 bge-reranker-base（47.89，278M 參數）。在 RAG 應用中，它保持了令人印象深刻的 83.51% 命中率和 0.6498 MRR，在實際檢索任務中表現出特別的優勢。該模型的速度提升更加驚人——它處理文檔的速度比基礎模型快三倍，吞吐量幾乎隨參數數量的減少而線性增長。但是，用户應該注意到，在極其細微的排名任務中，性能略有下降，其中較大模型的完整參數數量提供了邊際優勢。","jina-reranker-v2-base-multilingual":"在實際評估中，該模型在各種基準測試中都表現出色。它在 RAG 系統的 AirBench 排行榜上取得了最先進的性能，並在多語言任務中表現出色，包括涵蓋 26 種語言的 MKQA 數據集。該模型在結構化數據任務中尤其出色，在函數調用（ToolBench 基準測試）和 SQL 模式匹配（NSText2SQL 基準測試）中都取得了高召回率。最令人印象深刻的是，它在提供這些結果的同時，處理文檔的速度比 bge-reranker-v2-m3 等同類模型快 15 倍，使其適用於實時應用。但是，用户應注意，最佳性能需要具有 CUDA 功能的 GPU 進行推理。","reader-lm-05b":"在實際測試中，Reader LM 0.5B 在多個指標上表現出令人印象深刻的效率與性能比。該模型的 ROUGE-L 得分達到 0.56，表明內容保存效果良好，並且保持了 0.34 的低詞元錯誤率，顯示出最小的幻覺。在對 22 種不同的 HTML 源（包括多種語言的新聞文章、博客文章和電子商務頁面）進行定性評估時，它在結構保存和 markdown 語法使用方面表現出色。該模型擅長處理複雜的現代網頁，其中內聯 CSS 和腳本可以擴展到數十萬個詞元 - 傳統的基於規則的方法經常會失敗。但是，需要注意的是，雖然該模型在簡單的 HTML 到 markdown 轉換任務上表現非常出色，但對於高度動態或 JavaScript 密集的頁面，它可能需要額外的處理。","reader-lm-15b":"在全面的基準評估中，Reader LM 1.5B 展現出挑戰行業標準的卓越能力。該模型的 ROUGE-L 得分為 0.72，Token 錯誤率為 0.19，在 HTML 到 Markdown 轉換任務中明顯優於 GPT-4（0.43 ROUGE-L、0.50 TER）和 Gemini-1.5-Pro（0.42 ROUGE-L、0.48 TER）等大型模型。其性能在四個關鍵維度的定性評估中尤為突出：標題提取、主要內容提取、豐富結構保存和 Markdown 語法使用。該模型在多種文檔類型（從新聞文章和博客文章到登錄頁面和論壇帖子）中始終保持高精度，支持多種語言，包括英語、德語、日語和中文。這種性能是在處理長度高達 256K 的 token 的文檔時實現的，無需使用大型模型通常需要的昂貴分塊操作。",title:"性能"},performance_metrics:"績效指標",publications:"出版物",tags:"標籤",token_length:"輸入詞元長度",usage_requirements:"使用和要求",using_model:"可通過以下方式獲取"},select_model:"從列表中選擇一個模型以查看詳細信息",sort:{direction:{asc:"升序",desc:"降序",name:"方向"},label:"種類",name:"名稱",parameter_size:"尺寸",release_date:"日期"},title:"{_modelName} - 搜索底座模型",warnings:{deprecated:"此模型已被較新的模型棄用。"}},ae={back_to_newsroom:"返回新聞首頁",categories:"類別",copy_link:"複製此部分的鏈接",in_this_article:"文章導覽",learn_more:"瞭解更多",news_not_found:"糟糕！未找到文章",redirect_to_news:"將在5 秒後重定向至新聞首頁..."},ie={academic:"學術",academic_research:"學術論文",author:"按作者過濾",description:"讀取 Jina AI 的最新新聞和更新。",description1:"一字一句地撰寫AI技術創新。",engineering_group:"工程組",engineering_group_date:"2021 年 5 月 31 日",minutes_read:"分鐘的讀取量",most_recent_articles:"最新文章",news_description:"對於 Jina 2.0，我們聽取了社區的意見。確實，深深地聽過。 “你的痛點是什麼？”我們詢問並熱切期待寶貴的反饋",news_title:"搜索所有內容：我們正在為 Jina 2.0 舉辦 MEME 競賽",photos:"相片",product:"按產品過濾",search:"按標題搜索",tech_blog:"技術文章",title:"新聞",top_stories:"甄選文章"},te="🎉 我們的第一本書《神經搜索——與 Jina 一起從原型到生產》今天正式出版！",re={description:"參訪 Jina AI 內部的獨家機會。",engage:"我們強烈鼓勵全天進行互動對話。思想和觀點的交流對我們來説非常寶貴。這些討論產生的潛在合作可以為更加一體化和創新的未來做出重大貢獻。",engage_title:"頭腦風暴",experience:"我們為客人安排了三小時的沉浸式遊覽，提供德語、英語、法語、西班牙語、中文和俄語版本。這次巡演將深入探討我們在多模態AI方面的進展、我們對人工智能領域的看法，然後對具體項目進行詳細審查。最後我們將進行小組討論，以促進思想和見解的交流。還可應要求提供午餐選擇。",experience_title:"業內人士之旅",group_size:"預計參觀人數",impact:"瞭解我們對開源社區的貢獻以及我們在多模態AI技術方面的工作如何使 Jina AI 成為人工智能創新領域有影響力的參與者。我們的目標是在決策過程中發揮重要作用，確保人工智能技術的進步惠及所有人。",impact_title:"行業影響力",introduction:"Jina AI 很高興向對那些對人工智能未來感興趣的機構敞開大門。我們為政界、非政府機構、非營利機構和投資領域的人士提供開放日。在此，誠邀您做客柏林總部，瞭解我們的運營、願景的行業洞察。",motivation_min_length_v1:"請提供更詳細的動機。",motivation_placeholder_v2:"分享您的動機將幫助我們改善您的體驗。",motivation_to_attend_v2:"您為什麼對我們的開放日感興趣？",one_hour:"1小時",organization:"機構",organization_website:"機構網站",organization_website_placeholder:"您機構的主頁或 LinkedIn 個人資料的 URL",preferred_date:"首選日期",preferred_language:"首選語言",preferred_products:"您對哪些產品感興趣？",subtitle:"多模態AI的未來一瞥",title:"開放日",tutor_subtitle:"精心策劃的三小時導覽，讓您更接近 Jina AI 在多模態AI技術方面的開創性工作的核心。",tutor_title:"獨家深入探討",vision:"加入我們，全面瞭解我們所看到的人工智能前景。我們的討論將重點關注大型語言模型、多模態AI的潛力以及開源技術在塑造全球創新未來方面的影響。",vision_title:"未來願景"},oe={answer1:"我們提供德語、英語、法語、西班牙語、中文和俄語的講解服務。",answer2:"講解通常持續大約三個小時。",answer3:"午餐是可選的，可根據要求安排。",answer4:"我們的開放日主要是為專業團體設計的，例如政治家、非政府機構、非營利機構和投資者。然而，我們偶爾會根據個人的個人資料做出例外情況。",answer5:"我們可以容納各種規模的團體。請在報名表中註明您的團體人數，我們將與您確認詳細信息。",answer6:"註冊表中有一個部分，您可以在其中指定您感興趣的領域或任何特殊要求。我們將盡力根據您的需求定製行程。",answer7:"目前，我們僅在位於克羅伊茨貝格的柏林總部提供開放日。我們的北京和深圳辦事處目前不開放參觀。",question1:"你們提供哪些語言的講解服務？",question2:"講解時長是多少？",question3:"提供午餐嗎？",question4:"個人可以報名參加開放日嗎？",question5:"開放日的團體可以有多少人？",question6:"我如何指定講解的興趣區域？",question7:"你們的北京或深圳辦事處提供開放日嗎？"},se={description:"開源、雲原生的大型多模態模型服務框架"},_e={commercial_licence:{chip_label:"專為小型公司",company_size_note:"僅限員工人數少於 50 人或收入少於 50 萬美元的公司",cta_button:"立即開始",download_title:"下載商業許可證",feature_api_desc:"購買前請先測試",feature_api_title:"免費 API 測試訪問",feature_consulting:"與我們的模型專家進行兩小時的諮詢",feature_consulting_desc:"每個許可期限內提供兩 (2) 小時的技術諮詢服務。",feature_future_support:"無需許可即可訪問未來的 CC BY-NC 模型",feature_future_support_desc:"許可期限內許可方根據 CC-BY-NC-4.0 發佈的任何新模型。",feature_models:"無限制地使用我們的 CC BY-NC 模型進行商業使用",feature_models_desc:"將模型用於商業目的，包括內部使用或納入面向客户的應用程序。",price_amount:"1,000 美元",price_period:"/ 每季度",read_the_terms:"查看許可條款",read_the_terms_btn:"條款",read_the_terms_desc:"購買前查看商業許可權利和限制",subtitle:"這些模型助您實現更好的搜索",test_before_purchase:"購買前請先試用",test_before_purchase_desc:"獲取 1000 萬個免費 API 詞元或使用我們的 Hugging Face 模型來驗證性能",title:"團隊許可",try_api:"首先嚐試 API"},consulting_us:"一小時的技術諮詢",consulting_us_description:"與我們的工程師深入交流獲得有關將我們的 API 實施到您的系統中的最佳實踐的專家指導。",full_commercial:"不受限制的商業用途",full_commercial_description:"您可以將 API 用於商業目的，不受任何限制。",higher_limit:"更高且可調節的速率限制",higher_limit_description:"速率限制部分有更多詳細信息。",key_manager:"基本密鑰管理",key_manager_description:"在一個帳户中管理多個 API 密鑰、跟蹤使用歷史記錄和充值詞元。",no_commercial:"僅限非商業用途（CC-BY-NC）。",no_commercial_description:"您只能將此 API 用於非商業用途。如需商業用途，請購買 API 密鑰套餐。",on_prem:"擁有本地使用的商業許可證",on_prem_explain:"購買商業許可證以在現場使用我們的模型。",premium_key:"高級密鑰具有更高的速率限制",premium_key_description:"獲得更高的速率限制並使用高級功能，請查看速率限制表瞭解詳情。",premium_key_manager:"高級密鑰管理",premium_key_manager_description:"基本功能和高級功能，例如自動提醒、撤銷、詞元傳輸。",premium_support:"金牌客户支持",premium_support_description:"保證在 24 小時內對任何問題做出回應。",priority_support:"優先技術支持",priority_support_description:"保證在 72 小時內通過電子郵件回覆技術問題或事故。",secured_by_stripe:"通過 Stripe 安全付款",standard_key:"標準密鑰",standard_key_description:"以標準速率限制訪問所有Jina 搜索底座API。",via_api:"使用Jina 搜索底座API",via_api_explain:"訪問我們所有產品的最簡單方法。隨時充值詞元。"},de="基於",le="打印",ce={archived:"已存檔",cloud_native:"雲原生",core:"基層核心",data_structure:"數據結構",embedding_serving:"大模型向量部署",embedding_tuning:"大模型向量調優",graduated:"已畢業",incubating:"孵化中",kubernetes:"Kubernetes",large_size_model:"大型模型",linux_foundation:"Linux 基金會",llm1:"LLM框架",mid_size_model:"中型模型",model_serving:"模型部署",model_tuning:"模型調優",observability:"可觀察性",orchestration:"雲編排",prompt_serving:"提示詞部署",prompt_tuning:"提示詞調優",rag1:"RAG應用",sandbox:"沙盒",small_size_model:"小型模型",vector_database:"向量數據庫",vector_store:"向量數據庫"},pe={description:"首屈一指的提示詞工具箱",image_model:"圖片模型",intro:"首屈一指的提示詞工具箱",intro1:"提示詞工程的首要工具",optimized:"你的任務是成為我的頭腦風暴夥伴，為特定的主題或問題提供創造性的想法和建議。您的回答應該包括原創的、獨特的和相關的想法，這些想法可以幫助解決問題或以有趣的方式進一步探索該主題。請注意，您的回答還應考慮任務的任何具體要求或限制。",optimized_title:"優化後的提示詞",original:"你的角色是成為我的頭腦風暴夥伴。",original_title:"原提示詞",text_model:"文本模型"},ue={features:[{description:"輕鬆在內容成產和提示詞優化之間切換，將您的內容質量提升到新的水平。",name:"智能助手",title:"每日一罐生產力。"},{description:"不知道如何編寫有效的提示詞？只需輸入您的想法，點一下鼠標，即可獲得更好的提示詞。",name:"提示詞優化",title:"更好的輸入，更好的輸出"},{description:"通過比較同一提示詞的輸出來瞭解每個 AI 模型的性格。",name:"模型大比拼",title:"並排模型比較。"},{description:"這也許是將提示詞部署為 API 最簡單的方法。",name:"部署提示詞",title:"告別繁瑣Ops，直接部署。"},{description:"定製您自己的大模型智能體，並啓動多智能體模擬。查看它們如何在虛擬環境中協作或競爭以達到目標。",name:"多智能體",title:"探索智能體如何協作"}],get_started:"開始使用 PromptPerfect"},me={api_key:"充值API密鑰",free_key:"免費 API 密鑰",generation:"您的 API 密鑰已準備好！",generation_caption:"您的 API 密鑰已於 {_purchasedTime} 生成並可供使用！",success:"感謝您的購買！",success_caption:"您的訂單已於{_purchasedTime}完成。您的 API 密鑰已充值並可供使用！如果您發現詞元餘額未更新，請刷新頁面。"},ge="立即購買",Ae={batch_explain:"此 API 支持批量操作，每次請求最多允許 512 個文檔，每個文檔最多包含 8192 個詞元。巧妙利用批量操作可以大幅減少請求次數並提高性能。",classifier:"使用訓練樣本訓練分類器",classifier_few_shot:"使用經過訓練的少樣本分類器對輸入進行分類",classifier_few_shot_token_counting:"詞元計數為：輸入詞元",classifier_latency:"響應時間隨輸入大小而變化",classifier_token_counting:"詞元計數為：輸入詞元 × 迭代次數",classifier_zero_shot:"使用零樣本分類對輸入進行分類",classifier_zero_shot_token_counting:"詞元計數為：輸入詞元 加 標籤詞元",deepsearch:"推理、搜索和迭代以找到最佳答案",depends:"取決於輸入大小",description:"描述",embeddings:"將文本/圖片轉為定長向量",endpoint:"API端口",explain:"速率限制通過三種方式跟蹤：<b>RPM</b>（每分鐘請求數）和<b>TPM</b>（每分鐘詞元數）。限制按 IP/API 密鑰強制執行，當首先達到 RPM 或 TPM 閾值時，將觸發限制。當您在請求標頭中提供 API 密鑰時，我們會按密鑰而不是 IP 地址跟蹤速率限制。",flat_rate_per_request:"每個請求都需要固定數量的詞元，從 {_number} 個詞元開始",further_boost:"還不夠？請聯繫我們以提升到更高的速率限制！",gjinaai:"用網絡知識支撐聲明",icon:"圖標",input_token_counting:"以輸入請求中的詞元數量為準。",key_explain:"購買“白銀”詞元包可獲得此級別的付費 API 密鑰",latency:"平均延遲",llm_serp:"使用LLM生成搜索引擎結果頁面",no_key_explain:"使用沒有 API 密鑰的 API 時，沒有“用户”概念，因此速率限制是針對每個 IP 地址執行的。如果您恰好在共享環境中使用它，您可能會更快達到速率限制。",no_token_counting:"詞元不計算使用量。",output_token_counting:"以輸出響應中的詞元數量為準。",premium_key_explain:"購買“黃金”詞元包即可獲得此級別的付費 API 密鑰",premium_rate:"有可能提高速率限制",product:"產品",requestType:"請求類型",reranker:"按查詢對文檔進行精排",rjinaai:"將 URL 轉換為大模型友好文本",search:"搜索",sjinaai:"搜索網絡並將結果轉換為大模型友好文本",tbd:"有待確定",title:"速率限制",tokenCounting:"詞元使用計數",tokenizer:"對長文本進行分詞分句",total_token_counting:"統計整個過程中詞元的總數。",understanding:"瞭解速率限制",understanding_description:"速率限制是指每個 IP 地址/API 密鑰 (RPM) 在一分鐘內可以向 API 發出的最大請求數。請在下面詳細瞭解每個產品和層級的速率限制。",wAPIkey:"使用 API 密鑰",wPremium:"帶有高級 API 密鑰",woAPIkey:"無 API 密鑰"},be={decision:"決定",description:"LLM輔助智能決策工具",intro:"看到硬幣的兩面，做出理性的決定"},he={beta:"實驗",better_input:"從一開始就提高輸入質量",better_input_description:"您的Agent或 RAG 系統輸出出現問題？這可能是由於輸入質量差造成的。",check_price_table:"查看價格表",copy:"複製",demo:{advanced_parameter_explain:"僅用於此端點的特定參數。",advanced_parameters:"具體的",advanced_usage:"高級用法",ask_llm:"詢問大模型是否需要搜索依據",ask_llm_directly:"直接詢問LLM",ask_llm_with_search_grounding:"通過搜索詢問LLM",ask_question:"提出問題",ask_question_hint:"輸入問題並將其與獲取的大模型內容相結合以生成答案",basic_usage:"基本用法",basic_usage1:"使用 <code>r.jina.ai</code> 讀取 URL 並獲取其內容",basic_usage2:"使用 <code>s.jina.ai</code> 搜索網絡並獲取 SERP",basic_usage3:"查論",common_parameter_explain:"可用於{_product1}、{_product2}和{_product3}的通用參數。",common_parameters:"通用參數",content_length:"內容長度（字節）",copy:"複製",fetch:"獲取內容",get_response:"獲取響應",grounding_result_false:"此言差矣。",grounding_result_true:"此言正確。",headers:{atx:"替代標題語法",atx_explain:"使用文本下方行中的任意數量的“==”或“--”字符來創建標題。",auth_token:"添加 API 密鑰以實現更高的速率限制",auth_token_explain:"輸入您的 Jina API 密鑰以訪問更高的速率限制。有關最新速率限制信息，請參閲下表。",auto:"自動",auto_explain:"自動為 URL 選擇最佳引擎。",base:"關注重定向頁面",base_explain:"選擇是否在遵循所有重定向後解析到最終目標網址。啓用以遵循完整的重定向鏈。",browser:"質量優先",browser_explain:"高質量引擎旨在解決渲染問題並提供最佳內容輸出。",browser_locale:"自定義瀏覽器區域設置",browser_locale_explain:"控制瀏覽器區域設置以呈現頁面。許多網站根據區域設置提供不同的內容。",cf_browser:"實驗性瀏覽器",cf_browser_explain:"我們正在試驗一款能夠處理 JavaScript 密集型網站的快速引擎。不建議用於生產用途。我們可能會更改其行為。",country:"@:llm_serp.parameters.country",country_explain:"@:llm_serp.parameters.country_explain",custom_script:"預運行 JavaScript",custom_script_explain:"執行預處理 JS 代碼（內聯字符串或遠程 URL）。",deepdive:"深度源代碼分析",deepdive_explain:"搜索更多來源並讀取完整文檔以進行徹底的事實核查。速度稍慢但更準確且參考資料更多。",default:"默認",default_explain:"針對大多數網站和大模型輸入優化的默認管道。",direct:"速度優先",direct_explain:"最快的引擎，速度經過優化但無法處理 JavaScript 生成的動態內容。",discarded_explain:"鏈接被其錨文本替換。",dnt:"請勿緩存/跟蹤！",dnt_explain:"啓用後，請求結果將不會緩存在我們的服務器上。",engine:"讀取引擎",engine_default:"默認",engine_default_explain:"最兼容的引擎在質量和速度之間提供良好的平衡。",engine_default_html:"默認使用原始 HTML 響應",engine_default_html_explain:"默認引擎具有 HTML 響應，無需 markdown 轉換。",engine_default_markdown:"默認不帶可讀性過濾",engine_default_markdown_explain:"具有 Markdown 響應的默認引擎沒有可讀性過濾（刪除頁眉、頁腳等）。",engine_default_timeout:"默認但設置了超時",engine_default_timeout_explain:"默認引擎但設置了5秒的最大超時。",engine_explain:"選擇用於獲取網頁內容的瀏覽器引擎。這會影響內容的質量、速度、完整性和可訪問性。",eu_compliance:"符合歐盟規定",eu_compliance_explain:"所有基礎設施和數據處理操作完全在歐盟管轄範圍內。",file:"本地 PDF/HTML 文件",file_explain:"通過上傳本地 PDF 和 HTML 文件，使用讀取器讀取它們。僅支持 pdf 和 html 文件。",html:"HTML",html_explain:"返回 documentElement.outerHTML。",image_caption:"圖片説明",image_caption_explain:"為指定 URL 上的所有圖片添加標題，為沒有標題的圖片添加“Image [idx]: [caption]”作為 alt 標籤。這允許下游大模型在推理和總結等活動中與圖片進行交互。",images_summary:"將所有圖片集中到最後",images_summary_all:"全部",images_summary_all_explain:"文末列出所有圖片。",images_summary_explain:"最後會創建一個“圖片”部分。這可以讓下游的大模型概覽頁面上的所有視覺效果，從而提高推理能力。",images_summary_no:"無",images_summary_no_explain:"圖片保持內聯。",images_summary_true:"去重",images_summary_true_explain:"文末列出去重圖片。",inlined_explain:"鏈接直接嵌入文本中。",instruction_explain:"根據指令提取信息",invalid_json:"JSON 格式錯誤",json_response:"JSON 響應",json_response_explain:"響應將採用 JSON 格式，包含 URL、標題、內容和時間戳（如果可用）。在搜索模式下，它會返回一個包含五個條目的列表，每個條目都遵循描述的 JSON 結構。",json_schema_explain:"使用 JSON Schema 進行 HTML 轉 JSON 提取",language:"@:llm_serp.parameters.language",language_explain:"@:llm_serp.parameters.language_explain",links_summary:"將所有鏈接集中到最後",links_summary_all:"全部",links_summary_all_explain:"文末列出所有鏈接。",links_summary_explain:"最後會創建一個“按鈕和鏈接”部分。這可以幫助下游大模型或 Web 代理瀏覽頁面或採取進一步的行動。",links_summary_no:"無",links_summary_no_explain:"鏈接保持內聯。",links_summary_true:"去重",links_summary_true_explain:"文末列出去重鏈接。",location:"@:llm_serp.parameters.location",location_explain:"@:llm_serp.parameters.location_explain",markdown:"Markdown",markdown_explain:"直接從 HTML 返回 markdown，繞過可讀性過濾。",md:{bullet_list_marker:"項目符號樣式",bullet_list_marker_explain:"設置項目符號列表標記字符（傳遞給 Turndown）。",em_delimiter:"強調風格",em_delimiter_explain:"定義 markdown 強調分隔符（傳遞給 Turndown）。",heading_style:"標題樣式",heading_style_explain:"設置 markdown 標題格式（傳遞給 Turndown）。",hr:"水平線樣式",hr_explain:"定義 markdown 水平規則格式（傳遞給 Turndown）。",link_reference_style:"參考鏈接樣式",link_reference_style_explain:"設置 markdown 參考鏈接格式（傳遞給 Turndown）。",link_style:"鏈接樣式",link_style_explain:"確定 markdown 鏈接格式（傳遞給 Turndown）。",strong_delimiter:"強調風格",strong_delimiter_explain:"設置 markdown 強強調分隔符（傳遞給 Turndown）。"},md_link_discarded:"純文本",md_link_inline:"內聯",md_link_referenced:"引用",mode:"讀取或搜索模式",mode_explain:"讀取模式用於訪問 URL 的內容，而搜索模式允許您在網絡上搜索查詢，並將讀取模式應用於每個搜索結果 URL。",no_cache:"繞過緩存",no_cache_explain:"我們的 API 服務器會將讀取和搜索模式的內容緩存一段時間。要繞過此緩存，請將此標頭設置為 true。",no_gfm:"已禁用",no_gfm_explain:"GFM（Github Flavored Markdown）功能已禁用。",no_gfm_table:"無 GFM 表",no_gfm_table_explain:"選擇退出 GFM 表但保留表 HTML 元素作為響應。",number:"@:llm_serp.parameters.number",number_explain:"@:llm_serp.parameters.number_explain",opt_out_gfm:"Github 風格的 Markdown",opt_out_gfm_explain:"選擇加入/退出 GFM（Github Flavored Markdown）功能。",page:"@:llm_serp.parameters.page",page_explain:"@:llm_serp.parameters.page_explain",pageshot:"頁面快照",pageshot_explain:"返回整頁截圖的圖片網址（盡力而為）。",post_with_url:"使用 POST 方法",post_with_url_explain:"使用 POST 方法代替 GET 方法，並在正文中傳遞 URL。對於使用基於哈希的路由構建 SPA 非常有用。",proxy:"使用特定國家/地區的代理服務器",proxy_explain:"設置基於位置的代理服務器的國家代碼。使用“自動”進行最佳選擇或使用“無”禁用。",proxy_server:"使用代理服務器",proxy_server_explain:"我們的 API 服務器可以利用您的代理來訪問 URL，這對於只能通過特定代理訪問的頁面很有幫助。",reader_url:"@:reader.demo.reader_url",referenced_explain:"鏈接列於文末，在文中以數字引用。",references:"參考",references_explain:"以逗號分隔的用户提供的參考 (url) 列表",remove_all_images:"刪除所有圖片",remove_all_images_explain:"從響應中刪除所有圖片。",remove_selector:"CSS 選擇器：排除",remove_selector_explain:"要刪除的元素的 CSS 選擇器（頁眉、頁腳等）。",respond_with:"使用 ReaderLM-v2",respond_with_explain:"使用 ReaderLM-v2 將 HTML 轉換為 Markdown，為結構和內容複雜的網站提供高質量的結果。比其它引擎消耗 3 倍詞元！",result_count:"數字",result_count_explain:"設置返回的最大結果數。使用 num 可能會導致延遲並排除特殊結果類型。除非您明確需要每頁顯示更多結果，否則請忽略。",return_format:"內容格式",return_format_explain:"您可以控制響應中的細節級別，以防止過度過濾。默認管道針對大多數網站和大模型輸入進行了優化。",robot_txt:"嚴格遵守機器人政策",robot_txt_explain:"定義機器人用户代理 (User-Agent)，在獲取內容之前對照 robots.txt 進行檢查。",screenshot:"截屏",screenshot_explain:"返回第一個屏幕的圖片URL。",search_engine:"搜索引擎",search_engine_explain:"選擇搜索使用的引擎。影響結果的質量、速度和兼容性。",search_result_mode:"讀取 SERP 的完整內容",search_result_mode_explain:"訪問搜索結果中的每個 URL 並使用讀取器返回完整內容。切換以啓用更多特定於讀取器的選項。",serp_type:"SERP 內容類型",serp_type_explain:"搜索的內容類型。目前屬於高度實驗性功能，不同類型計費方式不同。",set_cookie:"轉發 Cookie",set_cookie_explain:"我們的 API 服務器可以在訪問 URL 時轉發您的自定義 Cookie 設置，這對於需要額外身份驗證的頁面非常有用。請注意，帶有 Cookie 的請求不會被緩存。",setext:"數字符號標題",setext_explain:"在單詞或短語前使用數字符號 (#) 來創建標題。",site_selector:"站內搜索",site_selector_explain:"僅返回指定網站或域的搜索結果。默認情況下，它會搜索整個網絡。",stream_mode:"流模式",stream_mode_explain:"流模式有利於較大的目標頁面，從而留出更多時間讓頁面完全呈現。如果標準模式導致內容不完整，請考慮使用流模式。",target_selector:"CSS 選擇器：僅限",target_selector_explain:"用於定位特定頁面元素的 CSS 選擇器列表。",text:"文本",text_explain:"返回 document.body.innerText。",token_budget:"限制詞元預算",token_budget_explain:"限制此請求使用的最大詞元數。超出此限制將導致請求失敗。",viewport:"視口配置",viewport_explain:"設置瀏覽器視口尺寸以實現響應式渲染。",vlm:"可變長度模型",vlm_explain:"非常適合具有豐富媒體和複雜佈局的短頁面。",wait_for_selector:"CSS 選擇器：Wait-For",wait_for_selector_explain:"返回結果之前要等待的 CSS 選擇器。",with_favicon:"獲取圖標",with_favicon_explain:"這將獲取 SERP 中每個 URL 的圖標，並將它們作為圖片 URI 包含在響應中，這對於 UI 渲染很有用。",with_gfm:"已啓用",with_gfm_explain:"已啓用 GFM（Github Flavored Markdown）功能。",with_iframe:"iframe 提取",with_iframe_explain:"處理 DOM 樹中所有嵌入 iframe 的內容。",with_shadow_dom:"影子 DOM 提取",with_shadow_dom_explain:"從文檔中的所有 Shadow DOM 根中提取內容。",x_timeout:"超時時間",x_timeout_explain:"最大頁面加載等待時間（不是總請求處理時間）。",your_query:"@:reader.demo.your_query"},how_to_stream:"要在內容可用時對其進行處理，請將請求標頭設置為流模式。這可以最大限度地縮短收到第一個字節所需的時間。curl 中的示例：",how_to_use1:"將 https://r.jina.ai/ 添加到代碼或工具中需要大模型訪問的任何 URL。這將以乾淨、大模型友好的文本返回頁面的主要內容。",how_to_use2:"將 https://s.jina.ai/ 添加到您的查詢中。這將調用搜索引擎並返回其 URL 和內容，每個結果都以簡潔、大模型友好的文本顯示。",how_to_use3:"將 https://g.jina.ai/ 添加到您的語句中。這將調用判斷引擎並返回真實性百分比、表示語句是真還是假的布爾值、原因摘要和參考列表。",key_required:"使用此端點需要 API 密鑰",learn_more:"瞭解更多",open:"在新標籤頁中打開",params_classification:"參數",performance_compare:"性能比較",raw_html:"原始 HTML",reader_output:"讀取器的輸出",reader_response:"讀取器反應",reader_search_hint:"如果您在代碼中使用此 URL，請不要忘記對該 URL 進行編碼。",reader_url:"讀取器網址",reader_url_hint:"點擊下面通過我們的讀取器 API 獲取內容",requires_post_method:"此功能需要 POST 方法。上傳本地文件後，將自動啓用 POST 方法。",response_time:"響應時間（毫秒）",search_params:"搜索參數",search_query_rewrite:"請注意，與上面的演示不同，在實踐中，您不會在網上搜索原始問題來獲取基礎。人們經常做的是重寫原始問題或使用多跳問題。他們讀取檢索到的結果，然後生成其他查詢以根據需要收集更多信息，然後得出最終答案。",select_mode:"選擇模式",show_read_demo:"瞭解 Reader 如何讀取 URL",show_search_demo:"瞭解讀取器如何搜索網絡",slow_warning:"這可能需要長達 30 秒並且每個請求最多需要 300K 個詞元。",standard_usage:"標準用法",stream_mode:"流模式",stream_mode_explain:"當目標頁面很大而無法渲染時，流模式非常有用。如果您發現標準模式提供的內容不完整，請嘗試流模式。",stream_mode_explain1:"當您發現標準模式提供的結果不完整時，流式模式很有用。這是因為流式模式將等待更長時間，直到頁面完全呈現。使用 accept-header 切換流式模式：",tagline:"試用演示",try_demo:"演示",use_headers:"可以使用請求標頭來控制 Reader API 的行為。以下是受支持標頭的完整列表。",waiting_for_reader:"首先等待 Reader API 結果...",warn_grounding_message:"此過程可能需要長達 30 秒的時間，並且每個查論請求最多會消耗 300K 個詞元。某些瀏覽器可能會因為較長的延遲而終止請求，因此我們建議複製代碼並從終端運行它。",warn_grounding_title:"高延遲和詞元使用率",your_query:"輸入您的查詢",your_query_hint:"輸入需要最新信息或世界知識的問題。",your_statement:"您的事實核查聲明",your_url:"輸入您的 URL",your_url_hint:"點擊下面直接獲取頁面源代碼"},description:"讀取URL或搜索為大模型提供更好的依據。",dont_panic_api_key_is_free:"別慌！每個新的 API 密鑰都包含一千萬個免費詞元！",engine_speed_test:"讀取速度測試",faq_v1:{answer1:"讀取器 API 是免費的，不需要 API 密鑰。只需在您的 URL 前面添加“https://r.jina.ai/”即可。",answer10:"不可以，讀取器 API 只能處理來自可公開訪問的 URL 的內容。",answer11:"如果您在 5 分鐘內請求相同的 URL，讀取器 API 將返回緩存的內容。",answer12:"不幸的是沒有。",answer13:"是的，您可以使用讀取器中的原生 PDF 支持（https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4）或使用 arXiv 中的 HTML 版本（https://r.jina.ai/https://arxiv.org/html/2310.19923v4）",answer14:"Reader 為指定 URL 上的所有圖片添加標題，並添加 `Image [idx]: [caption]` 作為 alt 標籤（如果最初沒有）。這使得下游大模型能夠與圖片進行推理、總結等交互。",answer15:"Reader API 的設計具有高度可擴展性。它根據實時流量自動擴展，最大併發請求數現在約為 4000。我們正在積極維護它，將其作為 Jina AI 的核心產品之一。因此，請放心在生產中使用它。",answer16:"請在下表中查找最新的速率限制信息。請注意，我們正在積極致力於改進 Reader API 的速率限制和性能，因此該表將進行相應更新。",answer17:"Reader-LM 是一種新型小型語言模型 (SLM)，專為從開放網絡中提取和清理數據而設計。它將原始、嘈雜的 HTML 轉換為乾淨的 markdown，靈感來自 Jina Reader。Reader-LM 注重成本效益和小模型尺寸，既實用又強大。它目前在 AWS、Azure 和 GCP 市場上可用。如果您有特定要求，請通過 sales AT jina.ai 聯繫我們。",answer2:"讀取器 API 使用代理來獲取任何 URL，並在瀏覽器中呈現其內容以提取高質量的主要內容。",answer3:"是的，讀取器 API 是開源的，可以在 Jina AI GitHub 存儲庫中找到。",answer4:"讀取器 API 通常會在 2 秒內處理 URL 並返回內容，但複雜或動態的頁面可能需要更多時間。",answer5:"抓取可能很複雜且不可靠，尤其是複雜或動態頁面。讀取器 API 提供簡潔、可靠的乾淨大模型級文本輸出。",answer6:"讀取器 API 返回 URL 原始語言的內容。它不提供翻譯服務。",answer7:"如果您遇到阻止問題，請聯繫我們的支持團隊尋求幫助和解決方案。",answer8:"雖然 讀取器 API 主要用於網頁，但它可以從 arXiv 等網站上以 HTML 格式查看的 PDF 中提取內容，但它並未針對一般 PDF 提取進行優化。",answer9:"目前，讀取器 API 不處理媒體內容，但未來的增強功能將包括圖片字幕和視頻摘要。",question1:"使用 讀取器 API 的相關費用是多少？",question10:"是否可以在本地 HTML 文件上使用 讀取器 API？",question11:"讀取器 API 是否緩存內容？",question12:"我可以使用 讀取器API 來訪問登錄後的內容嗎？",question13:"我可以使用讀取器 API 訪問 arXiv 上的 PDF 嗎？",question14:"圖片標註在讀取器中如何發揮作用？",question15:"讀取器的可擴展性如何？我可以在生產中使用它嗎？",question16:"Reader API 的速率限制是多少？",question17:"什麼是 Reader-LM？如何使用它？",question2:"讀取器 API 如何發揮作用？",question3:"讀取器 API 是開源的嗎？",question4:"讀取器 API 的典型延遲是多少？",question5:"為什麼我應該使用 讀取器 API 而不是自己抓取頁面？",question6:"讀取器 API 是否支持多種語言？",question7:"如果某個網站屏蔽了 讀取器 API，我該怎麼辦？",question8:"讀取器 API 可以從 PDF 文件中提取內容嗎？",question9:"讀取器 API 可以處理來自網頁的媒體內容嗎？",title:"與讀取器相關的常見問題"},fast:"快速地",fast_stream:"即時數據流",fast_stream_description:"需要快速獲取數據？我們的 讀取器 API 可以傳輸數據以最大程度地減少延遲。",free:"永遠免費",free_description:"讀取器 API 是免費的！它不需要信用卡或 API 密碼。它不會消耗您的詞元配額。",is_free:"而且它是竟然是免費的！",is_free_description:"Reader API 可免費使用，並提供靈活的速率限制和定價。它建立在可擴展的基礎架構上，具有高可訪問性、併發性和可靠性。我們努力成為您大模型的首選基礎解決方案。",lm_v2_description:"ReaderLM-v2 是一個 1.5B 參數語言模型，專門用於 HTML 到 Markdown 的轉換和 HTML 到 JSON 的提取。它支持 29 種語言中多達 512K 個詞元的文檔，準確率比其前身高 20%。",lm_v2_title:"ReaderLM v2：從 HTML 到 Markdown 和 JSON 的小型語言模型",open:"在新標籤頁中打開",original_pdf:"原始 PDF",rate_limit:"速率限制",read_grounding_release_note:"讀取發佈説明",reader_also_read_images:"網頁上的圖片會使用讀取器中的視覺語言模型自動添加標題，並在輸出中格式化為圖片 alt 標籤。這為您的下游大模型提供了足夠的提示，以將這些圖片納入其推理和總結過程。這意味着您可以詢問有關圖片的問題，選擇特定的圖片，甚至將其 URL 轉發到更強大的 VLM 進行更深入的分析！",reader_description:"將 URL 轉換為大模型友好輸入，只需在前面添加 <code>r.jina.ai</code> 即可。",reader_do_grounding:"事實核查讀取器",reader_do_grounding_explain:"新的基準端點提供端到端、近乎實時的事實核查體驗。它獲取給定的陳述，使用實時網絡搜索結果對其進行基準化驗，並返回事實性分數和使用的確切參考資料。您可以輕鬆對陳述進行基準化驗，以減少大模型幻覺或提高人工編寫內容的完整性。",reader_do_pdf_explain:"是的，Reader 本身支持 PDF 讀取。它兼容大多數 PDF，包括包含大量圖片的 PDF，而且速度極快！結合大模型，您可以輕鬆快速地構建 ChatPDF 或文檔分析 AI。",reader_do_search:"用於網頁搜索和 SERP 的讀取器",reader_do_search_explain:"Reader 可用作 SERP API。它允許您將搜索結果引擎頁面背後的內容提供給您的 LLM。只需在您的查詢前面添加 <code>https://s.jina.ai/?q=</code>，Reader 就會搜索網絡並返回前五個結果及其 URL 和內容，每個結果都以乾淨、LLM 友好的文本顯示。這樣，您就可以始終讓您的 LLM 保持最新狀態，提高其真實性，並減少幻覺。",reader_reads_images:"讀取器也順便識圖！",reader_reads_pdf:"讀取器還可以讀取 PDF！",reader_result:"讀取器結果",table:{td_1_0:"讀取 URL 返回其內容，用於單渠道依據",td_1_1:"20 請求每分鐘",td_1_2:"200 請求每分鐘",td_1_3:"根據輸出詞元",td_1_4:"3 秒",td_1_5:"3 秒",td_2_0:"在網絡上搜索返回前 5 個結果，有助於獲得世界知識和搜索依據",td_2_1:"5 請求每分鐘",td_2_2:"40 請求每分鐘",td_2_3:"根據所有 5 個搜索結果的輸出詞元數",td_2_4:"10 秒",td_2_5:"10 秒",th0:"端點",th1:"描述",th2:"無 API 密鑰的速率限制",th3:"使用 API 密鑰進行速率限制",th4:"詞元計數方案",th5:"平均延遲",th6:"平均延遲"},title:"讀取器 API",usage:"用法",usage_details_false:"僅顯示基本用法",usage_details_null:"顯示基本用法和高級用法",usage_details_true:"僅顯示高級用法",want_higher_rate_limit:"想要更高的速率限制（高達 1000 RPM）？我們可以為您提供支持！",what_is1:"什麼是讀取器？",what_is_answer_long:"將網絡信息輸入大模型是打好基礎的重要一步，但這可能很有挑戰性。最簡單的方法是抓取網頁並輸入原始 HTML。但是，抓取可能很複雜且經常受阻，而且原始 HTML 中充斥着標記和腳本等無關元素。讀取器 API 通過從 URL 中提取核心內容並將其轉換為乾淨的、大模型友好的文本來解決這些問題，從而確保為您的Agent和 RAG 系統提供高質量的輸入。",what_is_desc:"訪問任何 URL 並提取其主要內容轉換為針對大模型優化的文本。",which_engine_is_you:"哪種引擎適合您？",which_engine_is_you_explain:"不同的引擎針對不同的任務進行了優化，質量、速度、兼容性和成本各不相同。測試 URL 並選擇最符合您需求的 URL。"},Ie={confirm_message:"您的 API 密鑰還剩 {_leftTokens} 個詞元。將 {_numArticles} 篇文章的全文發送到重排器API，利用 {_selectedReranker} 模型去尋扎與當前頁面的相關文章，這將顯着消耗 API 密鑰 {_APIKey} 的詞元計數。您想繼續嗎？",confirm_title:"警告：大量消耗詞元",out_of_quota:"此 API 密鑰已用完詞元。請為您的帳户充值或使用不同的 API 密鑰。",recommend:"獲取前 5 名",recommended_articles:"前 5 條類似文章"},ke={benchmark:{description0:"LlamaIndex 評估了 RAG 的向量模型和重排器器的各種組合，我們對起進行復現。研究結果顯示 Jina 重排器 顯着提高了搜索質量，這一優勢與上游所使用的特定向量模型無關。",description1:"BIER（Benchmarking IR）評估模型的檢索有效性，包括相關性和NDCG。較高的 BIER 分數與更準確的匹配和搜索結果排名相關。",description2:"通過 LoCo 基準測試，我們測量了模型對本地連貫性和上下文的理解，以及特定於查詢的排名。 LoCo 分數越高，反映出識別相關信息並確定優先級的能力越好。",description3:"總體而言，MTEB（多語言文本嵌入基準）測試的是模型在文本嵌入方面的能力，包括聚類、分類、檢索和其他指標。不過，為了進行比較，我們僅使用了 MTEB 的重排序任務。",title:"基準",title0:"LlamaIndex",title1:"BIER",title2:"LoCo",title3:"MTEB"},benchmark_description:"為了進行比較，我們在基準測試中納入了 BGE (北京智源研究院)、BCE (網易有道) 和 Cohere 的其他三個領先的重排器。如下圖所示，Jina 重排器 在所有相關重排類別中平均得分最高，在同行中處於明顯領先地位。",benchmark_title:"性能基準測試",choose_turbo:"5倍提速的Turbo版本",choose_turbo_description:"我們還提供兩個新的開源重排模型：jina-reranker-v1-turbo-en 和 jina-reranker-v1-tiny-en，後者只有 30M 個參數和 4 層。這兩個新的重排器的推理速度比底座模型快 5 倍，而質量卻只下降一點點。它們非常適合需要實時重排的應用程序。請讀取下面的評測。",customize_urself:"試試改變它看看響應如何變化！",customize_urself_m0:"試試更改文本或上傳圖像看看響應如何變化！",customize_urself_pl:"試試改變它們看看響應如何變化！",demo:{add_images:"添加圖像",image_collection:"添加測試圖像以重新排序",image_error:"無法加載圖片",image_urls:"圖片 URL（每行一個圖片 URL）",model_selector_label:"選擇排名模型",relevance_score:"jina-reranker-m0給到的相關性：{_score}",your_query:"您的疑問在這裏"},description:"世界一流的重排器，最大限度地提高搜索相關性。",description_rich:"利用我們先進的重排 API 最大限度地提高搜索相關性和 RAG 準確性。",example_input_document:"待排序候選文檔示例",example_input_query:"查詢示例",example_input_query_m0:"（文本或圖像）",faq_v1:{answer1:"重排器 API 的定價與我們的向量模型 API 定價結構一致。每個新 API 密鑰都會獲得 1000 萬個免費詞元。除了免費詞元之外，還可以購買不同的套餐。欲瞭解更多詳情，請訪問我們的定價部分。",answer10:"是的，我們的服務在 AWS、Azure 和 GCP 市場上可用。如果您有特定要求，請通過 sales AT jina.ai 聯繫我們。",answer11:"如果您對針對特定域數據量身定製的微調重排器感興趣，請聯繫我們的銷售團隊。我們的團隊將及時回覆您的詢問。",answer12:"<code>jina-reranker-m0</code> 模型可接受的最小圖像尺寸為 28x28 像素。",answer3:"<code>jina-reranker-v2-base-multilingual</code> 在多語言支持方面表現出色，性能優於 <code>bge-reranker-v2-m3</code>，吞吐量比 <code>jina-reranker-v1-base-en</code> 快 15 倍。它還支持代理任務和代碼檢索。<code>jina-colbert-v2</code> 在 <code>ColBERTv2</code> 的基礎上進行了改進，檢索性能提高了 6.5%，並增加了對 89 種語言的多語言支持。它具有用户控制的向量大小，以實現最佳效率和精度。",answer4:"是的，<code>jina-reranker-v2-base-multilingual</code> 和 <code>jina-colbert-v2</code> 都是基於 CC-BY-NC 4.0 協議開源。您可以自由地使用、共享和改編這些模型用於非商業用途。",answer5:"是的，<code>jina-reranker-v2-base-multilingual</code> 和 <code>jina-colbert-v2</code> 均支持 100 多種語言，包括英語、中文和其他全球主要語言。它們針對多語言任務進行了優化，並且表現優於以前的模型。",answer6:"最大查詢詞元長度為 512。文檔沒有詞元限制。",answer7:"每個查詢最多可以對 2048 個文檔進行重排。",answer8:"與我們的向量模型 API 不同，沒有批量大小的概念。每個請求只能發送一個查詢文檔元組，但該元組最多可以包含 2048 個候選文檔。",answer9:"延遲從 100 毫秒到 7 秒不等，主要取決於文檔和查詢的長度。例如，使用 64 個詞元的查詢對 100 個包含 256 個詞元的文檔進行重排大約需要 150 毫秒。將文檔長度增加到 4096 個詞元將使時間增加到 3.5 秒。如果查詢長度增加到 512 個詞元，則時間進一步增加到 7 秒。",question1:"重排器 API 的費用是多少？",question10:"您的服務可以在 AWS、Azure 或 GCP 上私有化部署嗎？",question11:"你們是否提供針對特定領域數據的微調重排器？",question12:"文檔的最小圖像尺寸是多少？",question3:"這兩個重排器有什麼區別？",question4:"Jina Rerankers 是開源的嗎？",question5:"重排器是否支持多種語言？",question6:"查詢和文檔的最大長度是多少？",question7:"每個查詢可以重排的最大文檔數是多少？",question8:"批量大小是多少以及在一個請求中可以發送多少個查詢文檔元組？",question9:"對 100 個文檔重排時，預計延遲會是多少？",title:"與 重排器 相關的常見問題"},feature_on_premises_description2:"在 AWS Sagemaker 上部署我們的重排模型，很快就會在 Microsoft Azure 和 Google Cloud Services 上部署，或者聯繫我們的銷售團隊，為您的虛擬私有云和本地服務器獲取定製的 Kubernetes 部署。",feature_on_premises_description3:"在 AWS Sagemaker 和 Microsoft Azure 上部署 Jina Reranker，很快就會在 Google Cloud Services 上部署 Jina Reranker，或者聯繫我們的銷售團隊，為您的虛擬私有云和本地服務器獲取定製的 Kubernetes 部署。",feature_solid_description:"由我們的尖端學術研究開發而成，並針對 SOTA 重排器器進行了嚴格測試，以確保無與倫比的性能。",how_it_works:"在搜索系統中，重排器的工作原理如下：",how_it_works_v1:{description1:"根據用户的查詢，使用向量模型或BM25或TF-IDF等維度，在數據庫中粗略匹配相關文檔。",description2:"重排模型會獲取這些初排結果，並在更精細的顆粒度上對文檔和查詢其進行相關性分析，同時考慮查詢術語與文檔內容交互等細微差別。",description3:"重排模型會將其認為最相關的結果放在頂部，從而改善搜索質量。",title1:"初始檢索",title2:"重排",title3:"改善後的結果"},image_search:"M0文圖重排沙盒",improve_performance:"搜索質量高人一等",improve_performance_description:"我們的評估表明，使用我們重排器的搜索系統得到了有效的改進，命中率提高了 8%，平均倒排(MRR)提高了 33%。",learning1:"瞭解重排器",learning1_description:"什麼是重排模型？為什麼向量搜索或兩兩餘弦相似度還不夠？通過我們的綜合指南從頭開始瞭解重排器。",m0_description:"我們新的多模態多語言重排器可用於檢索多種語言的視覺文檔，在多語言長文檔和代碼搜索任務上具有 SOTA 性能。",m0_title:"jina-reranker-m0：多語言多模態文檔重排器",read_more_about_benchmark:"讀取有關基準測試的更多信息",read_more_about_turbo:"瞭解有關渦輪增壓和微型模型的更多信息",read_more_about_v2:"Jina Reranker v2 是同類最佳的重排器，於 2024 年 6 月 25 日發佈；它是為 Agentic RAG 構建的。它具有函數調用支持、超過 100 種語言的多語言檢索、代碼搜索功能，並且比 v1 的速度提高了 6 倍。瞭解有關 v2 模型的更多信息。",reranker_description:"嘗試我們先進的重排器 API，最大限度地提高您的搜索相關性和 RAG 準確性。免費試用！",return_documents:"返回文檔文本",return_documents_explain:"控制結果信息。啓用時，包括文檔文本、相關性分數和索引。禁用時，僅顯示相關性分數和索引。",show_v2benchmark:"顯示 v2 模型的基準（最新）",table:{number_token_document:"每個文檔中的詞元數量",number_token_query:"查詢中的詞元數量",title:"以下是對一個查詢和 100 個文檔進行重排的時間成本（以毫秒為單位）："},title:"重排器 API",top_n:"返回最優的重排文檔數量",top_n_explain:"與查詢最相關的文檔的數量。",try_embedding:"免費使用向量模型 API",try_reranker:"免費試用重排器 API",v2_features:{description1:"Reranker v2 支持超過 100 種語言的文檔檢索，無論查詢語言是什麼。",description2:"Reranker v2 根據自然語言查詢對代碼片段和函數簽名進行排名，非常適合 Agentic RAG 應用程序。",description3:"Reranker v2 根據自然語言查詢對最相關的表進行排名，幫助對不同的表模式進行排序並在生成 SQL 查詢之前確定最相關的表模式。",title1:"多語言檢索",title2:"函數調用和代碼搜索",title3:"表格和結構化數據支持"},v2benchmark:{descBeir:"針對 Beir 數據集的不同重排器報告的 NDCG 10 分數",descCodeSearchNet:"CodeSearchNet 數據集中不同重排模型的 MRR 10 得分報告",descMKQA:"回憶一下 MKQA 數據集中不同重排器報告的 10 個分數",descNSText2SQL:"回顧 NSText2SQL 數據集中不同重排器報告的 3 個分數",descRTX4090:"RTX 4090 GPU 上不同重排模型的吞吐量（50 毫秒內檢索到的文檔）分數報告。",descToolBench:"召回 ToolBench 數據集中不同重排器報告的 3 個分數",titleBeir:"BEIR（不同 IR 任務的異構基準測試）",titleCodeSearchNet:"CodeSearchNet。基準測試是文檔字符串和自然語言格式的查詢的組合，並帶有與查詢相關的標記代碼段。",titleMKQA:"MKQA（多語言知識問答）",titleNSText2SQL:"NSText2SQL",titleRTX4090:"Jina Reranker v2 在 RTX4090 上的吞吐量",titleToolBench:"ToolBench。該基準測試收集了超過 16,000 個公共 API 以及相應的合成生成指令，以便在單 API 和多 API 設置中使用它們。"},vs_table:{col0:"重排器",col0_1:"增強的搜索精度和相關性",col0_2:"初始、快速過濾",col0_3:"跨廣泛查詢的一般文本檢索",col1:"向量搜索",col1_1:"詳細：子文檔和查詢段",col1_2:"廣泛：整個文檔",col1_3:"中級：各種文本片段",col2:"BM25",col2_1:"高的",col2_2:"中等的",col2_3:"低的",col3_1:"不需要",col3_2:"高的",col3_3:"低，利用預建索引",col4_1:"高的",col4_2:"高的",col4_3:"不需要",col5_1:"更適合細緻入微的查詢",col5_2:"效率與準確性之間的平衡",col5_3:"對於廣泛的查詢來説一致且可靠",col6_1:"高度準確，具有深入的上下文理解",col6_2:"快速高效，準確度適中",col6_3:"高度可擴展，具有既定的功效",col7_1:"資源密集且實施複雜",col7_2:"可能無法捕獲深層查詢上下文或細微差別",col7_3:"對於高度具體或上下文搜索可能表現不佳",header0:"最適合場景",header1:"粒度",header2:"查詢時間複雜度",header3:"索引時間複雜度",header4:"訓練時間複雜度",header5:"搜索質量",header6:"優勢",header7:"弱點",subtitle:"下表提供了 重排器、向量搜索和 BM25 的全面比較，突出顯示了它們在各個類別中的優缺點。",title:"重排器、向量搜索和 BM25 的比較"},what_is:"什麼是重排器？",what_is_answer_long:`搜索的本質就是快速有效地找到最用户想要的結果。上世紀的BM25 或 tf-idf 等關鍵字匹配算法已成熟用在各類搜索結果進行排名。近幾年來，基於向量模型的餘弦相似度大放異彩，已在許多向量數據庫成為標配。但這些方法的本質都相對簡單，經常會忽略掉自然語言的微妙之處，最重要的是，忽略掉文檔和查詢意圖之間的關聯信息。

“重排模型”由此而生！重排模型實際是一種高級AI模型，它從搜索中獲取初始候選集（通常由基於向量/基於詞元的搜索結果提供）並重新評估它們與用户搜索意圖之間的相關性。重排器超越了文字的表層匹配，探索查詢和文檔內容之間更深層次的交互。`,what_is_answer_long_ending:"重排器可以顯着提高搜索質量，因為它在子文檔和子查詢級別運行，這意味着它會查看各個單詞和短語、它們的含義以及它們在查詢和文檔中如何相互關聯。這會產生一組更精確且與上下文相關的搜索結果。",what_is_desc:"重排器是一種AI模型，可優化BM25搜索或向量召回的搜索結果。通過我們的文章瞭解更多。"},ve={caption_image_desc:"生成圖片的文字描述。",caption_image_title:"標題圖片",description:"探索每一個像素背後的故事",example1:"該視頻似乎是一段自然鏡頭，其中有一隻迷人的白色兔子和一隻蝴蝶在草地上。兔子以不同的方式與蝴蝶互動，展示了它們獨特的關係。周圍的自然環境提供了風景如畫的背景，增強了這個簡單而迷人的場景的美麗。",generate_story_desc:"根據圖片創作一個故事，通常以人物的對話或獨白為特色。",generate_story_title:"生成故事",intro1:"獨領風騷的圖片視頻理解AI",json_image_desc:"使用預定義的架構從圖片生成結構化 JSON 格式。這允許從圖片中提取特定的數據。",json_image_title:"從圖片中提取 JSON",summarize_video_desc:"生成視頻的簡潔摘要，突出顯示關鍵事件。",summarize_video_title:"總結視頻",visual_q_a_desc:"根據圖片內容回答查詢。",visual_q_a_title:"視覺問答"},ye={ask_deepsearch:"向深度搜索提問...",ask_on_current_page:"向當前頁提問...",find_solution:"生成相應的解決方案...",hint:"搜索產品、新聞和您的問題",hotkey:"按 / 鍵可在本頁提問",hotkey1:"按",hotkey2:"切換",hotkey_long1:"在任何頁面，按下",hotkey_long3:"打開搜索欄",more_results:"另外 {_numMore} 個結果",placeholder:"對本頁內容提問",proposing_solution:"根據當前頁面內容生成答案...",required:"請更詳細地描述您的問題。",results:"結果"},Pe={description:"導航、交互、優化：重新定義產品搜索"},we={beta:"實驗"},fe={description:"彌合現有搜索底座設施中的語義差距"},xe={"Hacker News":"HN新聞",LinkedIn:"領英",facebook:"臉書",reddit:"紅迪網",rss:"RSS訂閲",share_btn:"分享",twitter:"X（前推特）"},Re={click_to_learn_more:"點擊瞭解更多",contextualization:"上下文理解",contextualization_desc:"重排器根據查詢的深度上下文相關性調整初始搜索結果。這可以優化排名，以更好地匹配用户可能認為有用的內容。",coreInfra:"核心基礎設施",coreInfra_desc:"Core infra 提供了一個雲原生層，用於在公共雲和本地開發、部署和編排搜索底座模型，使服務能夠毫不費力地擴大和縮小。",embedding_serving:"大模型向量部署",embedding_serving_description:"使用雲原生技術通過強大、可擴展的微服務部署大模型向量推理。",embedding_tech:"向量模型",embedding_tech_description:`在Jina AI，我們正通過向量模型技術徹底轉變人工智能應用的面貌。這種技術能夠作為一種統一的手段，有效地表達和壓縮多種類型的數據，同時確保關鍵信息不會丟失。我們的核心目標是將複雜的數據集轉化為普遍易懂的向量模型格式，為精準和深入的人工智能分析提供支持。

向量模型在AI領域扮演着基礎但至關重要的角色。在精確圖片識別和語音識別等領域，它們幫助我們識別更為微妙的細節和差異。在自然語言處理中，它們能增強對上下文和情感的理解，使對話式AI和語言翻譯工具更加準確。此外，在構建複雜的推薦系統時，這些系統需要對不同內容形式（如文本、音頻和視頻）的用户偏好有深入的瞭解，而向量模型在這方面發揮着關鍵作用。`,embedding_tuning:"大模型向量精調",embedding_tuning_description:"通過代入專業知識和行業數據來訓練高質量的大模型向量，以增強特定任務上的性能。",embeddings:"向量模型",embeddings_desc:"向量模型是現代搜索系統的基石，將多模態數據表示為數字向量。此過程使內容的理解更加細緻入微，遠超簡單的關鍵字匹配。",for_developers:"對於開發者",for_enterprise:"對於企業",for_power_users:"對於高級用户",grounding:"溯源",grounding_desc:"讀取器通過大模型完善輸入和結果。它們提高了最終答案的質量、可讀性和真實性。",model_serving:"模型部署",model_serving_description:"在生產環境中部署調優模型，通常需要大量資源，例如 GPU 託管。 MLOps 強調以可擴展、高效和可靠的方式服務中型到大型模型。",model_tuning:"模型調優",model_tuning_description:"於特定任務的數據集上調整預訓練模型的參數，以提高其性能並使其適應特定應用程序。",personalization:"個性化",personalization_desc:"使用用户指令引導的合成數據自動訓練特定領域的向量化和重排器。",preprocessing:"預處理",preprocessing_desc:"預處理包括清理、規範化和將原始數據轉換為搜索系統可理解的格式。",promptOps:"提示詞工作流",promptOps_desc:"Prompt Ops 改進了搜索系統的輸入和輸出，包括用於查詢擴展、大模型輸入和結果重寫的輸入和輸出。這確保搜索更容易理解，結果也更好。",prompt_serving:"提示詞部署",prompt_serving_description:"通過 API 包裝和提供提示，無需託管重型模型。該 API 調用公共大型語言模型服務並處理操作鏈中輸入和輸出的編排。",prompt_tech:"提示詞和智能體工程",prompt_tech_description:`在Jina AI，我們深知提示詞工程在與大型語言模型（LLM）交流中的重要性。隨着這些模型的不斷進化，我們的提示詞也變得越來越複雜，涵蓋了深入的推理和邏輯思維。這種進步彰顯了LLM和提示詞工程之間相互加強的關係。

展望未來，我們相信LLM將成為編譯器的角色，而提示詞則將演變成新型的編程語言。這意味着，未來的技術技能可能更側重於掌握提示詞的藝術，而不僅僅是傳統的編程技巧。在Jina AI，我們的目標是引領這場技術變革，通過精通這種新興的“語言”，讓先進的人工智能變得更加易於理解和應用。`,prompt_tuning:"提示詞調優",prompt_tuning_description:"精心設計和完善輸入提示的過程，以引導其輸出達到特定的、期望的響應。",representation:"表徵學習",representation_desc:"向量化將多模態數據轉換為統一的向量格式。這使搜索系統能夠理解和分類簡單關鍵字以外的內容。",rerankers:"重排器",rerankers_desc:"重排器會從向量模型中獲取初始結果並對其進行優化，確保向用户呈現最相關的結果。這對於提供符合用户意圖的高質量搜索結果至關重要。"},Le={care_most:"你最關心什麼？",care_most_options:{accuracy:"準確性",cost:"成本",other:"其他",scalability:"吞吐量",speed:"速度"},care_most_required:"選擇API服務時，您最關心什麼？",company_size:"貴公司規模有多大？",company_size_required:"告訴我們您公司的規模有助於我們提供更好的服務",company_url:"貴公司的網站是什麼？",company_url_required:"告訴我們您公司的網站有助於我們提供更好的服務",contactName:"你的名字",contactName_required:"我們該如何稱呼你呢？",contactTitle:"您在公司內如何任職？",contactTitle_required:"您的職位名稱為必填項",contact_us:"聯繫我們",domain_required:"告訴我們您的工作領域有助於我們提供更好的服務",email:"電子郵件",email_contact:"您的聯繫郵箱",email_invalid:"電子郵件無效",email_required:"電子郵件為必填項",fine_tuned_embedding:"想要您私域數據專屬向量模型？我們隨時恭候！",fine_tuned_reranker:"想要您私域數據上的專屬重排器？來！我們討論一下！",full_survey:"參加完整的調查並獲得我們團隊的更快回復",get_new_key:"獲取 API 密鑰",get_update_blog_posts:"提醒我博客文章的最新更新",get_update_embeddings:"提醒我向量模型的最新消息",send:"發送",sign_up:"訂閲",subscribe:"訂閲",tell_domain:"您的領域或微調方向",usage_type:"哪種用法最能描述您？",usage_type_options:{other:"其他",poc:"原型設計或概念驗證",production:"生產環境",research:"研究階段"},usage_type_required:"告訴我們您的使用類型有助於我們提供更好的服務",used_product:"您使用的是哪個模型？",used_product_required:"選擇您正在使用或您感興趣的模型"},Me={description:"增強你的大模型並將其推向極限"},qe="目錄",Ce={advance_usage:"使用 POST 請求獲取更多功能",basic_usage:"使用 GET 請求直接返回詞元數量",basic_usage_explain:"您可以簡單地發送一個 GET 請求來計算文本中的詞元數量。",change_content:"更改“content”參數並查看實時結果",chars:"字符",chinese:"中文",chunk:"切塊",chunk_all:"所有區塊",chunking:"對長文檔進行切塊，快如閃電鞭！",chunking_explain:"您還可以使用切分器將長文檔分割成較小的塊，從而更輕鬆地在向量模型或重排器中處理它們。我們利用常見的結構線索並構建了一套規則和啓發式方法，這些規則和啓發式方法在不同類型的內容（例如 Markdown、HTML、LaTeX 和 CJK 語言）中表現良好。",chunking_short:"切塊",chunks_in_total:"總共 {_numChunks} 個切塊",count_tokens_hint:"<b>{_numTokens}</b> 個詞元，{_numChars} 個字符。",description:"將長文本切分成塊或詞元。",description_long:"我們的切分器對於幫助大模型在上下文限制內管理輸入以及優化模型性能至關重要。它允許開發人員計算詞元並提取相關文本段，從而確保高效的數據處理和成本管理。",description_long1:"用於將長文本分割成塊並進行切詞的免費 API。",english:"英語",explain:"分段器是將文本轉換為詞元或塊的關鍵組件，它們是向量模型/重排器或大模型處理的基本數據單位。詞元可以表示整個單詞、單詞的一部分，甚至是單個字符。",faq_v1:{answer1:"切分器可免費使用。通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會向您的密鑰收費。",answer10:"除了西方語言外，分塊技術還適用於中文、日語和韓語。",answer2:"如果沒有 API 密鑰，您可以以 20 RPM 的速率限制訪問切分器。",answer3:"使用 API 密鑰，您可以以 200 RPM 的速率限制訪問切分器。對於高級付費用户，速率限制為 1000 RPM。",answer4:"不可以，您的 API 密鑰僅用於訪問更高的速率限制。",answer5:"是的，切分器是多語言的，支持超過 100 種語言。",answer6:"GET 請求僅用於計算文本中的詞元數，可讓您輕鬆將其作為計數器集成到應用程序中。POST 請求支持更多參數和功能，例如返回第一個/最後一個 N 個詞元。",answer7:"每個請求最多可以發送 64k 個字符。",answer8:"切塊功能可根據常見的結構線索將長文檔分割成較小的塊，從而確保將文本準確地分割成有意義的塊。本質上，它是一個（大！）正則表達式模式，可根據某些通常與語義邊界一致的句法特徵（例如句子結尾、段落分隔符、標點符號和某些連詞）對文本進行分割。它不是語義切塊。這個（大）正則表達式在正則表達式的限制範圍內儘可能強大。它平衡了複雜性和性能。雖然正則表達式無法實現真正的語義理解，但它可以通過常見的結構線索很好地近似上下文。",answer9:"如果輸入包含特殊詞元，我們的切分器會將它們放入“special_tokens”字段中。這樣您就可以輕鬆識別它們並根據下游任務進行相應的處理，例如在將文本輸入大模型之前將其刪除以防止注入攻擊。",question1:"切分器的價格是多少？",question10:"分塊是否支持英語以外的其他語言？",question2:"如果我不提供 API 密鑰，速率限制是多少？",question3:"如果我提供 API 密鑰，速率限制是多少？",question4:"您會從我的 API 密鑰中收取詞元嗎？",question5:"切分器是否支持多種語言？",question6:"GET 和 POST 請求有什麼區別？",question7:"每個請求可以切詞的最大長度是多少？",question8:"切塊功能如何工作？是語義切塊嗎？",question9:"如何在切分器中處理諸如“endoftext”之類的特殊詞元？",title:"與分段器相關的常見問題"},free_api:"切分器可免費使用。通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會向您的密鑰收費。",input_text:"輸入文本",is_free:"切分器是免費的！",is_free_description:"通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會對您的密鑰收費。",japanese:"日語",korean:"韓語",parameters:{auth_token:"添加 API 密鑰以實現更高的速率限制",auth_token_explain:"輸入您的Jina API密鑰以訪問更高的速率限制。有關最新速率限制信息，請參閲下表。",head:"返回前 N 個詞元",head_explain:"返回給定內容的前 N 個詞元。不包括恰好切在的邊界點。不能與“tail”一起使用。",learn_more:"瞭解更多",max_chunk_length:"每個塊的最大長度",max_chunk_length_explain:"每個塊中的最大字符數。實際上，如果文本中有自然邊界，塊長度可以小於此值。",return_chunks:"返回切塊",return_chunks_explain:"將輸入切為具有語義意義的片段，根據常見的結構線索，使用啓發式規則適應各種文本類型和邊緣情況。",return_tokens:"是否返回分詞結果",return_tokens_explain:"在響應中返回詞元及其對應的 id。切換以查看結果可視化。",tail:"返回最後 N 個詞元",tail_explain:"返回給定內容的最後 N 個詞元。不包括恰好切在的邊界點。不能與“head”一起使用。",type:"切分器",type_explain:"選擇要使用的切分器。",used_by_models:"用於 {_usedBy}。"},remove_boundary_cues:"刪除換行符",remove_boundary_cues_explain:"從輸入中刪除所有換行符（主要邊界提示），這會使問題更具挑戰性，並查看響應如何變化！",show_space:"顯示前導/尾隨空格",table:{td_1_0:"對文本進行分詞、計數並獲取第一個/最後一個 N 個詞元。",td_1_1:"20 轉/分",td_1_2:"200 轉/分",td_1_3:"1000 轉/分",td_1_4:"免費",td_1_5:"800毫秒"},title:"切分器 API",token_index:"詞元代碼：{_index}",usage:"用法",visualization:"可視化",what_is:"什麼是切分器？"},je={cta:"翻譯成{_lang}代碼",select_language:"語言"},Se={description:"您只需要一個 Python 向量數據庫 - 不多也不少"},Te="zzz",Je={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:a,api_general_faq:i,autotune:t,avatar:r,beta:o,billing_general_faq:s,blog_tags:_,book2024:d,cclicence:l,classifier:c,clip_as_service:p,cloud:u,contact_us_page:m,copy:g,copy_to_clipboard_success:A,dalle_flow:b,deepsearch:h,"dev-gpt":{description:"您的虛擬開發團隊"},disco_art:I,doc_array:k,download:v,embedding:y,embeddings:P,estimator:w,faq:f,faq_button:x,farewell:R,finetuner:L,finetuner_plus:M,finetuning:q,footer:C,get_new_key:j,github:S,grounding:T,header:J,hub:B,huggingface:E,impact_snapshots:G,inference:U,insufficient_error_message:z,integrations:O,internship_faq:D,internship_page:H,jcloud:N,jerboa:F,jina:W,jina_chat:K,key_manager:Q,lab_dialog:X,landing_page:V,langchain_serve:Y,legal_page:$,llm_serp:Z,model_graph:ee,models:ne,news_page:ae,newsroom_page:ie,notice:te,open_day:re,open_day_faq:oe,open_gpt:se,paywall:_e,powered_by:de,print:le,project_status:ce,prompt_perfect:pe,promptperfect:ue,purchase:me,purchase_now:ge,rate_limit:Ae,rationale:be,reader:he,recommender:Ie,reranker:ke,scenex:ve,searchbar:ye,searchscape:Pe,sefo_api:we,semantic:fe,share:xe,spectrum:Re,subscribe_system:Le,think_gpt:Me,toc:qe,tokenizer:Ce,translator:je,vectordb:Se,zzz:Te};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,a as about_us_page,i as api_general_faq,t as autotune,r as avatar,o as beta,s as billing_general_faq,_ as blog_tags,d as book2024,l as cclicence,c as classifier,p as clip_as_service,u as cloud,m as contact_us_page,g as copy,A as copy_to_clipboard_success,b as dalle_flow,h as deepsearch,Je as default,I as disco_art,k as doc_array,v as download,y as embedding,P as embeddings,w as estimator,f as faq,x as faq_button,R as farewell,L as finetuner,M as finetuner_plus,q as finetuning,C as footer,j as get_new_key,S as github,T as grounding,J as header,B as hub,E as huggingface,G as impact_snapshots,U as inference,z as insufficient_error_message,O as integrations,D as internship_faq,H as internship_page,N as jcloud,F as jerboa,W as jina,K as jina_chat,Q as key_manager,X as lab_dialog,V as landing_page,Y as langchain_serve,$ as legal_page,Z as llm_serp,ee as model_graph,ne as models,ae as news_page,ie as newsroom_page,te as notice,re as open_day,oe as open_day_faq,se as open_gpt,_e as paywall,de as powered_by,le as print,ce as project_status,pe as prompt_perfect,ue as promptperfect,me as purchase,ge as purchase_now,Ae as rate_limit,be as rationale,he as reader,Ie as recommender,ke as reranker,ve as scenex,ye as searchbar,Pe as searchscape,we as sefo_api,fe as semantic,xe as share,Re as spectrum,Le as subscribe_system,Me as think_gpt,qe as toc,Ce as tokenizer,je as translator,Se as vectordb,Te as zzz};
