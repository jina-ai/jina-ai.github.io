const t={PRODUCT_DESCRIPTION:n=>{const{normalize:r}=n;return r(["当社は、最先端のベクトル モデル、再配列器、LLM リーダー、プロンプト ワード オプティマイザーを提供して、マルチモーダル データに対する最先端の検索 AI を強化します。"])},SEO_TAG_LINE:n=>{const{normalize:r}=n;return r(["あなたの検索は二度と同じものになることはありません。"])},about_us_page:{approach:n=>{const{normalize:r}=n;return r(["私たちの戦略"])},approach_connect_dots:n=>{const{normalize:r}=n;return r(["ワイヤーの引き出し: パワー ユーザーからエンタープライズ ユーザーまで"])},approach_connect_dots_description:n=>{const{normalize:r}=n;return r(["全体的な戦略においてパワー ユーザーをこれほど重視するのはなぜですか?これは事前の計画に関する考慮事項です。明日の企業への影響力のために、今日投資してください。これは、これらのパワー ユーザーが企業の発言権を引き継いだ場合でも、当社が引き続き彼らをサポートできるようにするための当社のビジョンです。"])},approach_content1:n=>{const{normalize:r}=n;return r(["人工知能の絶えず変化する状況では、戦略は柔軟であり、将来を洞察する必要があります。 Jina AI はエンタープライズに焦点を当てていますが、AI 分野は進化しており、顧客を引き付ける戦略も時代に合わせる必要があります。したがって、上級ユーザーをブレークスルーポイントとして捉えることは、当社の戦略的革新であるだけでなく、企業発展における当社の粘り強さを反映しています。"])},approach_content2:n=>{const{normalize:r}=n;return r(["Jina AI では、これまでの栄誉に甘んじることなく、あえてイノベーションを起こします。上級ユーザーをリードすることで、現在を把握し、将来を予測することができます。企業としての私たちの決意は揺るぎませんが、成功への道においては、着実かつ前向きな新しい道を歩んでいます。"])},approach_content4:n=>{const{normalize:r}=n;return r(['誰もがより良い検索エクスペリエンスを望んでいます。 Jina AI では、ベクトル モデル、並べ替え機能、リーダー、プロンプト ワード エンジニアリング エクスペリエンスで構成される<span class="text-primary text-bold">検索ベース</span>を提供することで、より優れた検索を可能にします。これらのコンポーネントは連携して、データの検索と理解の方法に革命をもたらします。'])},approach_miss_mark:n=>{const{normalize:r}=n;return r(["従来の MLOps の欠点"])},approach_miss_mark_description:n=>{const{normalize:r}=n;return r(["パワー ユーザーの数が増加しているにもかかわらず、従来の MLOps ツールでは機能が低下し、ユーザーのニーズを満たせないことがよくあります。彼らは新時代のペースの速い競争に対処できない時代遅れの馬のようなものです。新世代の開発者は、より軽く、より直感的な武器を求めています。"])},approach_new_paradigm:n=>{const{normalize:r}=n;return r(["プロンプトワードプロジェクト：AI開発の新たなトレンド"])},approach_new_paradigm_description:n=>{const{normalize:r}=n;return r(["2023年、AIの世界は新たな章を迎え、プロンプトワードプロジェクトが急速に推進され、AIツールの普及プロセスが実現します。プログラミングの基礎を持たない上級ユーザーでも、Pytorch、Docker、Kubernetes に怯えることなく、簡単に AI に参加できます。この状況はパーソナル コンピューティングの台頭と非常によく似ています。当時、コンピュータと通信できるのは技術エリートだけでしたが、よりユーザーフレンドリーなインターフェイスの出現により、一般の人もその仲間に加わることができるようになりました。今日、プロンプト ワード エンジニアリングの人気により、AI の分野でも人気の新たな波が起きています。"])},awards:n=>{const{normalize:r}=n;return r(["受賞歴と優秀賞"])},berlin:n=>{const{normalize:r}=n;return r(["ベルリン、ドイツ"])},berlin_address:n=>{const{normalize:r}=n;return r(["Prinzessinnenstraße 19-20、10969 ベルリン、ドイツ"])},berlin_address2:n=>{const{normalize:r}=n;return r(["登録住所: Leipzigerstr. 96、10117 ベルリン、ドイツ"])},bj:n=>{const{normalize:r}=n;return r(["中国、北京"])},bj_address:n=>{const{normalize:r}=n;return r(["中国北京市海淀区海淀西街48号ビル6号5階"])},brochure_info:n=>{const{normalize:r}=n;return r(["当社の会社案内があなたをお待ちしています"])},description:n=>{const{normalize:r}=n;return r(["未来はここから始まります。"])},download_brochure1:n=>{const{normalize:r}=n;return r(["パンフレットをダウンロード"])},download_docarray_logo:n=>{const{normalize:r}=n;return r(["DocArray のロゴをダウンロード"])},download_docarray_logo_desc:n=>{const{normalize:r}=n;return r(["Jina AI によって開始され、2022 年 12 月に Linux Foundation に寄付されたオープンソース プロジェクトである DocArray ロゴを入手してください。ライトモードとダークモード、PNG および SVG 形式で利用できます。"])},download_jina_logo:n=>{const{normalize:r}=n;return r(["Jina AIのロゴをダウンロード"])},download_jina_logo_desc:n=>{const{normalize:r}=n;return r(["Jina AI ロゴをライト モードとダーク モードで入手できます。PNG 形式と SVG 形式で利用できます。このマークは欧州連合知的財産局 (EUIPO) の登録商標です。"])},download_logo:n=>{const{normalize:r}=n;return r(["ロゴをダウンロード"])},employees:n=>{const{normalize:r}=n;return r(["今日の従業員"])},empower_developers:n=>{const{normalize:r}=n;return r(["開発者エコシステム"])},fastApiCaption:n=>{const{normalize:r}=n;return r(["2021 年以降、20,000 ドル以上を寄付しました。"])},founded:n=>{const{normalize:r}=n;return r(["年設立"])},founded_in:n=>{const{normalize:r}=n;return r(["に設立されました"])},investors:n=>{const{normalize:r}=n;return r(["私たちの投資家"])},linuxFoundationCaption:n=>{const{normalize:r}=n;return r(["2022 年からは、年間 10,000 ドルを寄付してください。"])},many:n=>{const{normalize:r}=n;return r(["多くの"])},media:{video:n=>{const{normalize:r}=n;return r(["ビデオインタビュー"])}},mission:n=>{const{normalize:r}=n;return r(["我々の使命"])},mission_content1:n=>{const{normalize:r}=n;return r(["当社の主要テクノロジーには、高速チューニング、高速サービング、モデル チューニング、モデル サービングが含まれており、人工知能の民主化への取り組みを反映しています。当社は、オープンソース プログラムを通じて、イノベーション、コラボレーション、透明性を促進し、スケーラブルで効率的かつ堅牢なソリューションを確保するよう努めています。 Jina AI は単なる企業ではなく、企業がデジタル時代のダイナミックな課題に対処し、その分野で成功することを支援することに特化したコミュニティです。"])},mission_content2:n=>{const{normalize:r}=n;return r(["Jina AI の中核となる哲学は、パワー ユーザーや開発者から大企業までのマルチモーダル AI チャネルになるという私たちの使命にあります。私たちはオープンソースの力を信じており、AI コミュニティのための最先端のアクセス可能なツールの構築に取り組んでいます。プロンプトワード微調整、モデルベクトル調整および展開などの当社の主要テクノロジーは、AI の普及に対する当社の確固たる信念を示しています。オープンソースのアプローチにより、私たちはイノベーション、コラボレーション、透明性を推進し、アプローチがスケーラブルで効率的かつ強力であることを保証することを目指しています。 Jina AI は単なる企業ではなく、企業がデジタル時代の課題に対処し、各分野でリーダーであり続けることを支援するコミュニティです。"])},mission_content3:n=>{const{normalize:r}=n;return r(["Jina AI の使命は、革新的なベクトル モデルとヒントベースのテクノロジーを通じてマルチモーダル AI の開発を主導することです。当社は、自然言語処理、画像およびビデオ分析、クロスモーダル データ インタラクションなどの分野に特に重点を置いています。当社の専門分野は、複雑なマルチソースデータを実際に実用的な価値を持つ洞察と革新的なアプリケーションに変換する独自のソリューションを提供することに重点を置いています。"])},mit_report_title:n=>{const{normalize:r}=n;return r(["マルチモダリティ: 人工知能の新たなフロンティア"])},mit_techreview:n=>{const{normalize:r}=n;return r(["MITテクノロジーレビュー"])},numfocusCaption:n=>{const{normalize:r}=n;return r(["2022 年から毎月定期的に寄付を行ってください。"])},office:n=>{const{normalize:r}=n;return r(["私たちのオフィス"])},otherProjectsCaption:n=>{const{normalize:r}=n;return r(["Github のスポンサーシップを通じて 3,000 ドル以上を寄付しました。"])},our_answer:n=>{const{normalize:r}=n;return r(["これ以上同意することはできません、ヤン。私たちはマルチモーダル AI の未来への架け橋を築くために懸命に取り組んでいます。"])},pythonSoftwareFoundationCaption:n=>{const{normalize:r}=n;return r(["1 回限りの 10,000 ドルの寄付を行い、ドイツ、イタリア、中国、米国などの複数の PyCon イベントを後援しました。"])},sefo:{layer0:n=>{const{normalize:r}=n;return r(["ユーザー向けアプリケーション"])},layer1:n=>{const{normalize:r}=n;return r(["RAG/アレンジメントシステム"])},layer3:n=>{const{normalize:r}=n;return r(["GPU/モバイル/エッジ/ローカル コンピューティング"])}},segmentFaultCaption:n=>{const{normalize:r}=n;return r(["1 回限り 6,000 ドルを寄付してください。"])},show_position:n=>{const{normalize:r}=n;return r(["エコシステムにおける Search Foundation の位置は何ですか?"])},stats_1:n=>{const{normalize:r}=n;return r(["Jina AI は 2020 年 2 月に設立され、わずか 20 か月でマルチモーダル AI テクノロジーのリーダーになりました。この間、当社は 3,750 万ドルの調達に成功し、AI 業界のリーダーとしての地位を確立しました。 GitHub では、当社の革新的なオープンソース テクノロジーにより、40,000 人を超える開発者が何の障壁もなくマルチモーダル アプリを構築およびデプロイできるようになりました。"])},stats_2:n=>{const{normalize:r}=n;return r(["2023 年までに、私たちはマルチモーダル テクノロジーに基づいた AI ツールを飛躍的に進歩させました。このイノベーションは 250,000 人以上のユーザーに恩恵をもたらし、幅広いビジネス ニーズを満たしています。ビジネスの成長の促進、業務効率の向上、コストの最適化など、Jina AI は企業がマルチモーダル時代を前進できるよう支援することに尽力しています。"])},stats_4:n=>{const{normalize:r}=n;return r(['Jina AI は 2020 年に設立され、ベルリンに本社を置く検索 AI の大手企業です。弊社は、GenAI およびマルチモーダル アプリケーションの中核となる<span class="text-primary text-bold">検索ベース</span>を提供します。私たちの使命は、企業や開発者がマルチモーダル データを活用し、より優れた検索を通じて価値を生み出すのを支援することです。商用オープンソース企業として、私たちはオープンイノベーションを愛しています。'])},stats_v1:n=>{const{normalize:r}=n;return r(["検索が加速主義と衝突する場合"])},subtitle:n=>{const{normalize:r}=n;return r(["AI 生成ソリューションでコンテンツ作成に革命を起こし、無限の可能性を解き放ちます。 AI が生成するコンテンツの未来を形成し、人間の創造性を強化します。"])},sues_und_sauer:n=>{const{normalize:r}=n;return r(["スーとザウアー"])},sues_und_sauer_tooltip:n=>{const{normalize:r}=n;return r(["ズーザウアーはドイツ風中華料理で人気のフレーバーです (このフレーバーは本格的な中華料理では一般的ではなく、ドイツの中華料理のステレオタイプに属します)。これは甘くて酸っぱいことを意味します。これは起業家としてのキャリアの浮き沈みの比喩です。"])},sz:n=>{const{normalize:r}=n;return r(["深セン、中国"])},sz_address:n=>{const{normalize:r}=n;return r(["深セン市南山区福安テクノロジービル4階402号室"])},team:n=>{const{normalize:r}=n;return r(["私たちのチーム"])},team_content1:n=>{const{normalize:r}=n;return r(["私たちは地球の隅々から AI の未来を構築します。私たちのユニークな視点は私たちの仕事を豊かにし、イノベーションを刺激します。このポータルでは、私たちは個性を受け入れ、情熱的に夢を追い求めます。 AI の未来へのポータルへようこそ。"])},team_join:n=>{const{normalize:r}=n;return r(["参加しませんか"])},team_size:n=>{const{normalize:r}=n;return r(["これらの写真には私たちの元同僚やインターンも含まれています。私たちは彼ら一人一人に感謝しています。"])},technologies:n=>{const{normalize:r}=n;return r(["コアテクノロジー"])},title:n=>{const{normalize:r}=n;return r(["ジナテクノロジーについて"])},title0:n=>{const{normalize:r}=n;return r(["未来"])},title1:n=>{const{normalize:r}=n;return r(["起源"])},title2:n=>{const{normalize:r}=n;return r(["ここ"])},title3:n=>{const{normalize:r}=n;return r(["から始まりました"])},understand_our_strength:n=>{const{normalize:r}=n;return r(["当社の強みを知る"])},understand_our_view2:n=>{const{normalize:r}=n;return r(["検索ベースについて学ぶ"])},users:n=>{const{normalize:r}=n;return r(["登録ユーザー"])},value:n=>{const{normalize:r}=n;return r(["私たちの賞"])},value_content1:n=>{const{normalize:r}=n;return r(["私たちはこれまでの栄光に満足するつもりはありません。私たちは妥協しません。私たちは卓越性を追求します。"])},vision:n=>{const{normalize:r}=n;return r(["我々の使命"])},vision_content1:n=>{const{normalize:r}=n;return r(["AI に関するヤン・ルカンの視点からインスピレーションを得て、「"])},vision_content3:n=>{const{normalize:r}=n;return r(['AI の未来は<span class="text-primary text-bold">マルチモーダル</span>であり、私たちはその一部です。私たちは、企業がマルチモーダル データを活用する際に直面する課題を認識しています。そのために、私たちは企業や開発者がより適切に検索し、マルチモーダル データを活用してビジネスの成長を促進できるよう、<span class="text-primary text-bold">検索基盤</span> に取り組んでいます。'])},yannlecun_quote:n=>{const{normalize:r}=n;return r(["単語や文章だけで訓練された AI システムは、決して人間の理解に近づくことはできません。"])}},api_general_faq:{answer1:n=>{const{normalize:r}=n;return r(["はい、同じ API キーが Jina AI のすべての検索ベース製品で機能します。これには、ベクター、再ランキング、リーダー、微調整 API が含まれ、すべてのサービス間でトークンが共有されます。"])},answer12:n=>{const{normalize:r}=n;return r(["当社は厳格なプライバシー ポリシーを遵守しており、モデルのトレーニングにユーザー入力データを使用しません。"])},answer3:n=>{const{normalize:r}=n;return r(["はい、[トークンの購入] タブで API キーを入力してトークンの使用状況を監視することで、使用履歴と残りのトークンを表示できます。"])},answer4:n=>{const{normalize:r}=n;return r(["リチャージ キーを紛失し、再取得したい場合は、登録した電子メールを使用してサポートにお問い合わせください。"])},answer5:n=>{const{normalize:r}=n;return r(["いいえ、API キーには有効期限がありません。ただし、キーが侵害された疑いがあり、キーを廃棄するか、トークンを新しいキーに転送したい場合は、サポート チームにお問い合わせください。"])},answer6:n=>{const{normalize:r}=n;return r(["これは、サーバーレス アーキテクチャが使用率が低い期間に特定のモデルの負荷を軽減するためです。最初のリクエストではモデルがアクティブ化または「ウォームアップ」されますが、これには数秒かかる場合があります。最初のアクティベーションの後、後続のリクエストはより速く処理されます。"])},question1:n=>{const{normalize:r}=n;return r(["ベクター、再ランク、リーダー、微調整 API に同じ API キーを使用できますか?"])},question12:n=>{const{normalize:r}=n;return r(["ユーザー入力データはモデルのトレーニングに使用されますか?"])},question3:n=>{const{normalize:r}=n;return r(["API キーのトークンの使用状況を表示できますか?"])},question4:n=>{const{normalize:r}=n;return r(["API キーを忘れた場合はどうすればよいですか?"])},question5:n=>{const{normalize:r}=n;return r(["API キーには有効期限がありますか?"])},question6:n=>{const{normalize:r}=n;return r(["一部のモデルでは最初のリクエストが遅いのはなぜですか?"])},title:n=>{const{normalize:r}=n;return r(["API関連のFAQ"])}},autotune:{base_model:n=>{const{normalize:r}=n;return r(["ベースモデルの微調整"])},check_data:n=>{const{normalize:r}=n;return r(["合成データをダウンロードする"])},check_model:n=>{const{normalize:r}=n;return r(["微調整されたモデルをダウンロードする"])},data_size:n=>{const{normalize:r}=n;return r(["合成データの生成"])},description:n=>{const{normalize:r}=n;return r(["任意のドメインに対して微調整されたベクトル モデルを入手します。"])},description_long:n=>{const{normalize:r}=n;return r(["ベクトル モデルをどのドメインで優れたものにしたいかを教えてください。そのドメイン向けに、すぐに使用できる微調整されたベクトル モデル モデルが自動的に提供されます。"])},does_it_work_tho:n=>{const{normalize:r}=n;return r(["しかし、本当に効果があるのでしょうか？"])},does_it_work_tho_explain:n=>{const{normalize:r}=n;return r(["Auto-Spin には、希望するドメインに微調整されたベクトルを提供する魔法のような自動効果があります。しかし、本当に効果があるのでしょうか？これはかなり合理的な質問です。様々なフィールドとベースモデルでテストを行い、それを明らかにしました。以下の注目の結果と注目の結果をチェックしてください。"])},domain_instruction:n=>{const{normalize:r}=n;return r(["ドメインディレクティブ"])},embedding_provider:n=>{const{normalize:r}=n;return r(["基底ベクトルモデルの選択"])},eval_evaluation:n=>{const{normalize:r}=n;return r(["確認する"])},eval_map:n=>{const{normalize:r}=n;return r(["地図"])},eval_mrr:n=>{const{normalize:r}=n;return r(["平均月収"])},eval_ndcg:n=>{const{normalize:r}=n;return r(["グリア細胞癌"])},eval_performance_before_after:n=>{const{normalize:r}=n;return r(["微調整前後の合成検証セットのパフォーマンス"])},eval_syntheticDataSize:n=>{const{normalize:r}=n;return r(["全て"])},eval_test:n=>{const{normalize:r}=n;return r(["実際のデータのテスト"])},eval_training:n=>{const{normalize:r}=n;return r(["電車"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["この機能は現在ベータ版であり、微調整モデルごとに 100 万トークンの費用がかかります。 Embedding/Reranker API に十分なトークンがある場合は、既存の API キーを使用するか、100 万の無料トークンを使用して新しい API キーを作成できます。"])},answer10:n=>{const{normalize:r}=n;return r(["今は何もありません。この機能はまだベータ版であることに注意してください。微調整されたモデルと合成データを Hugging Face Model Center に公開して保存することは、私たちとコミュニティがトレーニングの品質を評価するのに役立ちます。将来的には、プライベート ストレージ オプションも提供する予定です。"])},answer11:n=>{const{normalize:r}=n;return r(["すべての微調整されたモデルはすでに Hugging Face にアップロードされているため、SentenceTransformers を通じてモデル名を指定するだけでモデルにアクセスできます。"])},answer12:n=>{const{normalize:r}=n;return r(["スパムフォルダを確認してください。それでも見つからない場合は、指定した電子メール アドレスを使用してサポート チームにお問い合わせください。"])},answer2:n=>{const{normalize:r}=n;return r(["トレーニング データを提供する必要はありません。ターゲット ドメイン (微調整されたベクトル モデルを最適化するドメイン) を自然言語で記述するか、URL を参照として使用するだけで、システムがモデルをトレーニングするための合成データを生成します。"])},answer3:n=>{const{normalize:r}=n;return r(["約30分。"])},answer4:n=>{const{normalize:r}=n;return r(["微調整されたモデルと合成データは、Hugging Face Model Center に公的に保存されます。"])},answer5:n=>{const{normalize:r}=n;return r(["システムは Reader API を使用して URL からコンテンツを取得します。次に、コンテンツを分析してトーンとドメインを要約し、合成データを生成するためのガイドラインとして使用しました。したがって、URL はパブリックにアクセス可能であり、ターゲット ドメインを表す必要があります。"])},answer6:n=>{const{normalize:r}=n;return r(["はい、英語以外の言語向けにモデルを微調整できます。システムはドメイン命令の言語を自動的に検出し、それに応じて合成データを生成します。また、ターゲット言語に適切な基本モデルを選択することをお勧めします。たとえば、ドイツ語ドメインをターゲットとする場合は、「jina-embeddings-v2-base-de」をベース モデルとして選択する必要があります。"])},answer7:n=>{const{normalize:r}=n;return r(["いいえ、微調整 API は Jina v2 モデルのみをサポートしています。"])},answer8:n=>{const{normalize:r}=n;return r(["微調整プロセスの最後に、保持されたテスト セットを使用してモデルが評価され、パフォーマンス メトリックが報告されます。このテスト セットの前後のパフォーマンスの詳細を記載した電子メールが届きます。また、品質を保証するために、独自のテスト セットでモデルを評価することをお勧めします。"])},answer9:n=>{const{normalize:r}=n;return r(["システムは、指定したターゲット ドメインの指示と LLM エージェントの推論を組み合わせて合成データを生成します。これは、高品質のベクトル モデル モデルをトレーニングするために重要な、困難なトリプルを生成します。詳細については、Arxiv に関する今後の研究論文を参照してください。"])},question1:n=>{const{normalize:r}=n;return r(["API の微調整にはどれくらいの費用がかかりますか?"])},question10:n=>{const{normalize:r}=n;return r(["微調整されたモデルと合成データを非公開にしておくことができますか?"])},question11:n=>{const{normalize:r}=n;return r(["微調整モデルの使用方法は?"])},question12:n=>{const{normalize:r}=n;return r(["査定結果のメールが届きません。私は何をしますか？"])},question2:n=>{const{normalize:r}=n;return r(["何を入力する必要がありますか?トレーニング データを提供する必要がありますか?"])},question3:n=>{const{normalize:r}=n;return r(["モデルの微調整にはどのくらい時間がかかりますか?"])},question4:n=>{const{normalize:r}=n;return r(["微調整されたモデルはどこに保存されますか?"])},question5:n=>{const{normalize:r}=n;return r(["参照 URL を指定した場合、システムはそれをどのように使用しますか?"])},question6:n=>{const{normalize:r}=n;return r(["特定の言語に合わせてモデルを微調整できますか?"])},question7:n=>{const{normalize:r}=n;return r(["bge-M3 など、Jina 以外のベクトル モデルを微調整できますか?"])},question8:n=>{const{normalize:r}=n;return r(["微調整されたモデルの品質を保証するにはどうすればよいですか?"])},question9:n=>{const{normalize:r}=n;return r(["合成データを生成するにはどうすればよいですか?"])},title:n=>{const{normalize:r}=n;return r(["セルフチューニングに関するよくある質問"])}},find_on_hf:n=>{const{normalize:r}=n;return r(["微調整されたモデルをリストする"])},temporarily_unavailable:n=>{const{normalize:r}=n;return r(["一時的に利用できなくなりました。より良いサービスを提供するために、自動微調整システムをアップグレードしています。後でもう一度確認してください。"])},test_on:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_dataName"))," からの ",e(o("_dataSize"))," 個のランダム サンプルでテストされました"])},test_performance_before_after:n=>{const{normalize:r}=n;return r(["微調整前後の、保持されたテストセットのパフォーマンス"])},title:n=>{const{normalize:r}=n;return r(["セルフチューニングAPI"])},total_improve:n=>{const{normalize:r}=n;return r(["平均的な改善"])},usage:n=>{const{normalize:r}=n;return r(["使用法"])},what_is:n=>{const{normalize:r}=n;return r(["セルフチューニングとは何ですか?"])},what_is_answer_long:n=>{const{normalize:r}=n;return r(["微調整を行うと、事前トレーニングされたモデルを取得し、新しいデータセットでトレーニングすることにより、それを特定のタスクまたはドメインに適応させることができます。実際、多くのユーザーにとって、効果的なトレーニング データを見つけるのは簡単な作業ではありません。効果的なトレーニングには、単に生の PDF や HTML をモデルに組み込むだけでは不十分ですが、それを正しく行うのは困難です。セルフチューニングは、高度な LLM エージェント パイプラインを使用して有効なトレーニング データを自動的に生成し、ML ワークフロー内でモデルを微調整することで、この問題を解決します。これは合成データ生成と AutoML を組み合わせたものと考えることができるため、ターゲット ドメインを自然言語で記述するだけで、残りはシステムに任せることができます。"])}},best_banner:{description:n=>{const{normalize:r}=n;return r(["記事から直接イラストを生成し、プロンプトの言葉は必要ありません"])},example_description:n=>{const{normalize:r}=n;return r(["アリスは、何もすることがなく、海岸で妹の隣に座っていることに飽き始めていました。妹が読んでいる本を一度か二度覗いてみましたが、そこには絵もセリフもありませんでした。「本に何の役に立つの？」アリスは、「絵もセリフも何もないの？」と思いました。それで彼女は、デイジーチェーンを作る喜びに価値があるのか​​どうか、心の中で考えていました（暑い気候でとても眠くて愚かな気分になっていたので、できる限りのことを考えていました）立ち上がってヒナギクを摘むのに苦労していると、突然ピンクの目をした白いウサギが逃げ出しました。彼女のところに来てください。"])},example_title:n=>{const{normalize:r}=n;return r(["不思議の国のアリス - 第 1 章"])}},beta:n=>{const{normalize:r}=n;return r(["体験版"])},billing_general_faq:{answer10:n=>{const{normalize:r}=n;return r(["新規ユーザーには、自動生成された API キーを介して任意のモデルで使用できる 100 万トークンを含む無料トライアルを提供します。無料トークンの制限に達すると、ユーザーは「トークンの購入」タブから API キーの追加トークンを簡単に購入できます。"])},answer13:n=>{const{normalize:r}=n;return r(["いいえ、失敗したリクエストに対してトークンは差し引かれません。"])},answer14:n=>{const{normalize:r}=n;return r(["支払いは Stripe を通じて処理され、クレジット カード、Google Pay、PayPal などの複数の支払い方法がサポートされているため、便利です。"])},answer15:n=>{const{normalize:r}=n;return r(["はい、トークンを購入すると、Stripe アカウントに関連付けられた電子メール アドレスに請求書が送信されます。"])},answer9:n=>{const{normalize:r}=n;return r(["当社の価格モデルは処理されるトークンの総数に基づいており、ユーザーはこれらのトークンを任意の数の文に柔軟に割り当てることができ、さまざまなテキスト分析ニーズに費用対効果の高いソリューションを提供します。"])},question10:n=>{const{normalize:r}=n;return r(["新規ユーザーは無料トライアルを利用できますか?"])},question13:n=>{const{normalize:r}=n;return r(["失敗したリクエストに対してトークンは差し引かれますか?"])},question14:n=>{const{normalize:r}=n;return r(["どのような支払い方法が利用できますか?"])},question15:n=>{const{normalize:r}=n;return r(["Ci Yuanを購入した後に請求書を発行できますか?"])},question9:n=>{const{normalize:r}=n;return r(["API の料金は文の数またはリクエストの数に基づいて課金されますか?"])},title:n=>{const{normalize:r}=n;return r(["請求に関するよくある質問"])}},blog_tags:{all:n=>{const{normalize:r}=n;return r(["全て"])},events:n=>{const{normalize:r}=n;return r(["活動"])},featured:n=>{const{normalize:r}=n;return r(["選択"])},insights:n=>{const{normalize:r}=n;return r(["ビュー"])},"knowledge-base":n=>{const{normalize:r}=n;return r(["知識ベース"])},latest:n=>{const{normalize:r}=n;return r(["最新"])},press:n=>{const{normalize:r}=n;return r(["プレスリリース"])},releases:n=>{const{normalize:r}=n;return r(["ソフトウェアの更新"])},"tech-blog":n=>{const{normalize:r}=n;return r(["技術記事"])}},cclicence:{api_free_trial:n=>{const{normalize:r}=n;return r(["無料のAPIキー"])},api_paid:n=>{const{normalize:r}=n;return r(["有料APIキー"])},api_paid_or_free:n=>{const{normalize:r}=n;return r(["有料の API キーを使用していますか? それとも無料の試用版キーを使用していますか?"])},are_you:n=>{const{normalize:r}=n;return r(["あなたは誰ですか："])},commercial_contact_sales:n=>{const{normalize:r}=n;return r(["これは商業的な性質のものです。当社の営業チームにお問い合わせください。"])},contact_sales_for_licensing:n=>{const{normalize:r}=n;return r(["ライセンスについては、弊社の営業チームにお問い合わせください。"])},csp_user:n=>{const{normalize:r}=n;return r(["AWS と Azure で公式モデルを使用していますか?"])},educational_teaching:n=>{const{normalize:r}=n;return r(["教育機関は教育に使用していますか?"])},for_profit_internal_use:n=>{const{normalize:r}=n;return r(["営利企業は社内でそれを使用していますか?"])},free_use:n=>{const{normalize:r}=n;return r(["これらのモデルは自由に使用できます。"])},government_public_services:n=>{const{normalize:r}=n;return r(["政府機関が公共サービスを提供するために使用していますか?"])},is_use_commercial:n=>{const{normalize:r}=n;return r(["あなたの使用は商用ですか?"])},may_be_commercial_contact:n=>{const{normalize:r}=n;return r(["これは商用利用が可能です。ご不明な点がございましたら、お問い合わせください。"])},no:n=>{const{normalize:r}=n;return r(["いいえ"])},no1:n=>{const{normalize:r}=n;return r(["いいえ"])},no2:n=>{const{normalize:r}=n;return r(["いいえ"])},no3:n=>{const{normalize:r}=n;return r(["いいえ"])},no_restrictions:n=>{const{normalize:r}=n;return r(["制限はありません。現在の規約に従ってご利用ください。"])},no_restrictions_apply:n=>{const{normalize:r}=n;return r(["制限はありません。"])},non_commercial_free_use:n=>{const{normalize:r}=n;return r(["このモデルは非商用ですのでご自由にお使いいただけます。"])},non_profit_ngo_mission:n=>{const{normalize:r}=n;return r(["非営利団体や NGO はあなたの使命を果たすためにそれを使用していますか?"])},not_sure:n=>{const{normalize:r}=n;return r(["わからない"])},personal_hobby_projects:n=>{const{normalize:r}=n;return r(["個人的なプロジェクトや趣味のプロジェクトに使用しますか?"])},product_service_sale:n=>{const{normalize:r}=n;return r(["販売する製品やサービスに使用しますか?"])},title:n=>{const{normalize:r}=n;return r(["CC BY-NC ライセンスのセルフチェック"])},trial_key_restrictions:n=>{const{normalize:r}=n;return r(["無料トライアル キーは、非営利目的でのみ使用できます。商用利用の場合は、有料パッケージをご購入ください。"])},typically_non_commercial_check:n=>{const{normalize:r}=n;return r(["通常、これは非営利ですが、不明な場合はご連絡ください。"])},typically_non_commercial_free_use:n=>{const{normalize:r}=n;return r(["これは通常、非営利的なものです。これらのモデルは自由に使用できます。"])},using_api_or_cloud:n=>{const{normalize:r}=n;return r(["Azure または AWS で公式 API または公式ミラーを使用していますか?"])},using_cc_by_nc_models:n=>{const{normalize:r}=n;return r(["これらのモデルを使用していますか?"])},yes:n=>{const{normalize:r}=n;return r(["はい"])},yes1:n=>{const{normalize:r}=n;return r(["はい"])},yes2:n=>{const{normalize:r}=n;return r(["はい"])},yes3:n=>{const{normalize:r}=n;return r(["はい"])}},classifier:{access:n=>{const{normalize:r}=n;return r(["パブリックアクセス"])},access_explain:n=>{const{normalize:r}=n;return r(["パブリック分類子は、<code>classifier_id</code> を持つ誰でも使用でき、それらを使用すると、自分のトークン割り当てではなく、呼び出し元のトークン割り当てが消費されます。プライベート分類子には自分だけがアクセスできます。"])},access_private:n=>{const{normalize:r}=n;return r(["プライベート"])},access_public:n=>{const{normalize:r}=n;return r(["人々"])},api_delete:n=>{const{normalize:r}=n;return r(["分類子の削除"])},api_delete_explain:n=>{const{normalize:r}=n;return r(["分類子 ID に基づいて分類子を削除します。"])},api_list:n=>{const{normalize:r}=n;return r(["リスト分類子"])},api_list_explain:n=>{const{normalize:r}=n;return r(["作成したすべての分類子をリストします。"])},classifier_id:n=>{const{normalize:r}=n;return r(["分類子ID"])},classify_inputs:n=>{const{normalize:r}=n;return r(["分類される入力"])},classify_inputs_explain:n=>{const{normalize:r}=n;return r(["テキストの場合、最大 8192 トークンの文を含めることができます。画像の場合、これは URL または Base64 でエンコードされた画像になります。"])},classify_labels:n=>{const{normalize:r}=n;return r(["候補の注釈"])},classify_labels_explain:n=>{const{normalize:r}=n;return r(["入力はこれらのカテゴリに分類されます。カテゴリは最大 256 個まで存在します。パフォーマンスを向上させるには、セマンティック カテゴリを使用します。"])},compare_table:{access_control:n=>{const{normalize:r}=n;return r(["アクセス制御"])},classifier_id_required:n=>{const{normalize:r}=n;return r(["必要な分類子 ID"])},continuous_updates:n=>{const{normalize:r}=n;return r(["継続的なモデルの更新"])},default_solution:n=>{const{normalize:r}=n;return r(["一般的な分類問題に対するデフォルトのソリューション"])},feature:n=>{const{normalize:r}=n;return r(["特徴"])},few_shot:n=>{const{normalize:r}=n;return r(["小さなサンプル"])},image_multi_lingual_support:n=>{const{normalize:r}=n;return r(["マルチモードおよび多言語のサポート"])},labels_required_classify:n=>{const{normalize:r}=n;return r(["/classify で必要な注釈"])},labels_required_train:n=>{const{normalize:r}=n;return r(["/train には注釈が必要です"])},max_classes:n=>{const{normalize:r}=n;return r(["クラスの最大数"])},max_classifiers:n=>{const{normalize:r}=n;return r(["最大分類子"])},max_inputs_request:n=>{const{normalize:r}=n;return r(["リクエストごとの最大入力"])},max_token_length:n=>{const{normalize:r}=n;return r(["入力あたりの最大トークン長"])},na:n=>{const{normalize:r}=n;return r(["適用できない"])},no:n=>{const{normalize:r}=n;return r(["いいえ"])},out_of_domain_solution:n=>{const{normalize:r}=n;return r(["v3/clip-v1 ドメイン外のデータまたは時間に敏感なデータの場合"])},primary_use_case:n=>{const{normalize:r}=n;return r(["主な使用例"])},semantic_labels_required:n=>{const{normalize:r}=n;return r(["セマンティックな注釈が必要です"])},state_management:n=>{const{normalize:r}=n;return r(["ステータス管理"])},stateful:n=>{const{normalize:r}=n;return r(["ステートフル"])},stateless:n=>{const{normalize:r}=n;return r(["ステートレス"])},token_count:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("count"))," 個のタグ"])},training_data_required:n=>{const{normalize:r}=n;return r(["トレーニングデータが必要です"])},yes:n=>{const{normalize:r}=n;return r(["はい"])},zero_shot:n=>{const{normalize:r}=n;return r(["ゼロサンプル"])}},create_classifier:n=>{const{normalize:r}=n;return r(["新しい少数ショット分類器"])},create_classifier_explain:n=>{const{normalize:r}=n;return r(["新しい少数ショット分類器を作成し、ラベル付きの例を使用してトレーニングします。"])},description:n=>{const{normalize:r}=n;return r(["画像とテキストのゼロショットと少数ショットの分類。"])},description_long:n=>{const{normalize:r}=n;return r(["API プレイグラウンドを試して、分類子がどのように機能するかを確認してください。"])},description_long1:n=>{const{normalize:r}=n;return r(["マルチモーダルおよび多言語データ向けの高性能ゼロショット分類器および少数ショット分類器。"])},explain:n=>{const{normalize:r}=n;return r(["Classifier は、埋め込みモデル (<code>jina-embeddings-v3</code> および <code>jina-clip-v1</code>) を使用して、トレーニング データを必要とせずにテキストと画像を分類する API サービスです。最小限の例を使用した分類と少数ショット学習。"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["ゼロショット分類にはセマンティック ラベルが必要ですが、トレーニング中には必要ありません。一方、少数ショット分類には、トレーニング中にラベルが必要ですが、分類中には必要ありません。これは、柔軟で即時の分類ニーズにはゼロショット分類の方が適しているのに対し、時間の経過とともに進化する可能性がある固定のドメイン固有のカテゴリには少数ショット分類の方が適していることを意味します。"])},answer10:n=>{const{normalize:r}=n;return r(["はい、テキスト分類 (特に多言語に適しています) には <code>jina-embeddings-v3</code> を選択し、マルチモーダル分類には <code>jina-clip-v1</code> を選択できます。新しいモデル (<code>jina-clip-v2</code> など) は、リリース時に API を通じて自動的に利用可能になります。"])},answer2:n=>{const{normalize:r}=n;return r(["<code>num_iters</code> はトレーニング強度を制御します。値が大きいほど重要な例が強調され、値が小さいほど信頼性の低いデータの影響が最小限に抑えられます。これを使用すると、最近の例をより多くの反復回数で供給することで、時間認識学習を実現でき、進化するデータ パターンにとって価値があります。"])},answer3:n=>{const{normalize:r}=n;return r(["<code>classifier_id</code> を持つユーザーは誰でもパブリック分類子を使用し、独自のトークン クォータを消費できます。ユーザーはトレーニング データや設定にアクセスしたり、他の人の分類リクエストを表示したりできないため、安全な分類子の共有が可能になります。"])},answer4:n=>{const{normalize:r}=n;return r(["サンプル数が少ない場合、ゼロショット分類を超えるには 200 ～ 400 のトレーニング サンプルが必要です。最終的にはより高い精度が達成されますが、効果的にするにはこのウォームアップ期間が必要です。 Zero-shot は、トレーニング データを必要とせずに、すぐに安定したパフォーマンスを提供します。"])},answer5:n=>{const{normalize:r}=n;return r(["はい - API は、<code>jina-embeddings-v3</code> を使用した多言語クエリと、同じで <code>jina-clip-v1</code> を使用したマルチモーダル (テキスト/画像) 分類をサポートしています。リクエスト内の URL または Base64 エンコードされた画像。"])},answer6:n=>{const{normalize:r}=n;return r(["ゼロショットは分類子の制限なしで 256 のカテゴリをサポートしますが、フューショットは 16 のカテゴリと 16 の分類子に制限されます。どちらも、リクエストごとに 1,024 個の入力と、入力ごとに 8,192 個のトークンをサポートします。"])},answer7:n=>{const{normalize:r}=n;return r(["少数のサンプル パターンにより、変化するデータ パターンに適応するために <code>/train</code> エンドポイントを介した継続的な更新が可能になります。データの分布が変化した場合、分類器全体を再構築することなく、新しい例やカテゴリを段階的に追加できます。"])},answer8:n=>{const{normalize:r}=n;return r(["API はワンショットのオンライン学習を使用します。トレーニング サンプルは分類子の重みを更新しますが、その後は保存されません。つまり、過去のトレーニング データを取得することはできませんが、プライバシーとリソース効率は確保されます。"])},answer9:n=>{const{normalize:r}=n;return r(["セマンティック ラベルを使用した柔軟な分類が必要な場合は、即座に結果を得るためにサンプルをゼロから開始します。 200 ～ 400 個のサンプルがある場合、より高い精度が必要な場合、またはドメイン固有のデータや時間に敏感なデータを処理する必要がある場合は、少数のサンプルに切り替えます。"])},question1:n=>{const{normalize:r}=n;return r(["ゼロサンプルと小さなサンプルのラベルの違いは何ですか?"])},question10:n=>{const{normalize:r}=n;return r(["異なる言語/タスクに異なるモデルを使用できますか?"])},question2:n=>{const{normalize:r}=n;return r(["num_iters は何に使用されますか?またその使用方法は何ですか?"])},question3:n=>{const{normalize:r}=n;return r(["パブリック分類子の共有はどのように機能しますか?"])},question4:n=>{const{normalize:r}=n;return r(["小規模なサンプル研究をうまく機能させるにはどのくらいのデータが必要ですか?"])},question5:n=>{const{normalize:r}=n;return r(["多言語やテキスト・画像に対応できますか？"])},question6:n=>{const{normalize:r}=n;return r(["注意すべきハード制限は何ですか?"])},question7:n=>{const{normalize:r}=n;return r(["時間の経過に伴うデータの変化にどのように対処すればよいですか?"])},question8:n=>{const{normalize:r}=n;return r(["トレーニング データを送信した後はどうなりますか?"])},question9:n=>{const{normalize:r}=n;return r(["ゼロサンプルと少量サンプル - いつどちらを使用するか?"])},title:n=>{const{normalize:r}=n;return r(["分類子に関するよくある質問"])}},more:n=>{const{normalize:r}=n;return r(["もっと"])},num_iters:n=>{const{normalize:r}=n;return r(["トレーニングの反復"])},num_iters_explain:n=>{const{normalize:r}=n;return r(["トレーニング強度を制御します。値が大きいほど、現在の例の精度が向上しますが、トークン コストが増加します。通常は、デフォルト値の 10 が適切に機能します。"])},read_notes:n=>{const{normalize:r}=n;return r(["リリースノートを読む"])},select_classifier_or_model:n=>{const{normalize:r}=n;return r(["分類子または埋め込みモデルを選択します"])},task_classify:n=>{const{normalize:r}=n;return r(["分類"])},task_classify_explain:n=>{const{normalize:r}=n;return r(["ゼロショットまたはフューショット分類子を使用して、テキストまたは画像を定義されたカテゴリに分類します。"])},task_manage:n=>{const{normalize:r}=n;return r(["管理"])},task_manage_explain:n=>{const{normalize:r}=n;return r(["少数ショット分類器をリストまたは削除します。"])},task_select:n=>{const{normalize:r}=n;return r(["タスクの選択"])},task_train:n=>{const{normalize:r}=n;return r(["電車"])},task_train_explain:n=>{const{normalize:r}=n;return r(["ラベル付きの例を使用して、少数の分類器を作成または更新します。"])},title:n=>{const{normalize:r}=n;return r(["分類子 API"])},train_inputs:n=>{const{normalize:r}=n;return r(["トレーニングデータ"])},train_inputs_explain:n=>{const{normalize:r}=n;return r(["トレーニング用のラベル付きテキストまたは画像の例。新しい例やラベルを使用して、時間の経過とともに分類器を段階的に更新できます。"])},train_label:n=>{const{normalize:r}=n;return r(["ラベル"])},what_is:n=>{const{normalize:r}=n;return r(["分類子とは何ですか?"])},when_to_use_what:n=>{const{normalize:r}=n;return r(["ゼロまたは少量のサンプルをいつ使用するか?"])},when_to_use_what_explain:n=>{const{normalize:r}=n;return r(["デフォルトのソリューションとしてゼロショット分類を使用すると、最大 256 のカテゴリを含む一般的な分類タスクで即時に結果が得られますが、埋め込まれたモデルの知識の範囲外にあるドメイン固有のデータや、時間がかかる場所の処理には、少数ショット学習の方が適しています。モデルの更新が必要です 機密データ。"])}},clip_as_service:{description:n=>{const{normalize:r}=n;return r(["CLIP を使用してベクトル画像とテキストを固定長ベクトルに変換"])}},cloud:{description:n=>{const{normalize:r}=n;return r(["マルチモーダル AI アプリケーション用のクラウド ホスティング プラットフォーム"])}},contact_us_page:{agreement:n=>{const{normalize:r}=n;return r(["送信すると、Jina AI が次の規定に従って個人データを処理することに同意したことになります。"])},anything_else:n=>{const{normalize:r}=n;return r(["あなたのアイデアについて詳しく教えてください"])},cc_by_nc:n=>{const{normalize:r}=n;return r(["商用利用の CC BY-NC モデルをリクエストする"])},cc_by_nc_description:n=>{const{normalize:r}=n;return r(["当社の最新モデルは、多くの場合、CC BY-NC に基づいてライセンスを取得しています。商用利用の場合は、API、Azure Marketplace、または AWS SageMaker を通じてアクセスしてください。これらのチャネル以外でローカルで使用する場合は、このボックスをチェックしてください。"])},company:n=>{const{normalize:r}=n;return r(["整理する"])},company_size:n=>{const{normalize:r}=n;return r(["組織の規模"])},company_website:n=>{const{normalize:r}=n;return r(["団体のウェブサイト"])},company_website_placeholder:n=>{const{normalize:r}=n;return r(["会社のホームページまたは LinkedIn プロフィールの URL"])},country:n=>{const{normalize:r}=n;return r(["国家"])},department:n=>{const{normalize:r}=n;return r(["部門"])},description:n=>{const{normalize:r}=n;return r(["Jina AI でビジネスを成長させましょう。"])},faq:n=>{const{normalize:r}=n;return r(["よくある質問"])},feedback_sent:n=>{const{normalize:r}=n;return r(["提出されました！できるだけ早くご連絡させていただきます。"])},field_required:n=>{const{normalize:r}=n;return r(["フィールドは必須項目です"])},get_api_key:n=>{const{normalize:r}=n;return r(["API キーを取得するにはどうすればよいですか?"])},impact_snapshots:n=>{const{normalize:r}=n;return r(["実際のケース"])},invalid_date_format:n=>{const{normalize:r}=n;return r(["日付形式が無効です。 DD-MM-YYYY 形式を使用してください。"])},invalid_email:n=>{const{normalize:r}=n;return r(["無効な電子メール"])},invalid_number:n=>{const{normalize:r}=n;return r(["無効な番号。もう一度入力してください"])},invalid_url:n=>{const{normalize:r}=n;return r(["無効なURL"])},name:n=>{const{normalize:r}=n;return r(["名前"])},nc_check:n=>{const{normalize:r}=n;return r(["商用ライセンスは必要ですか?"])},other_questions:n=>{const{normalize:r}=n;return r(["その他の質問"])},preferred_models:n=>{const{normalize:r}=n;return r(["どのモデルに興味がありますか?"])},preferred_products:n=>{const{normalize:r}=n;return r(["どのような製品に興味がありますか?"])},priority:n=>{const{normalize:r}=n;return r(["有料ユーザーへのサポートを優先する"])},private_statement:n=>{const{normalize:r}=n;return r(["プライバシーに関する声明"])},rate_limit:n=>{const{normalize:r}=n;return r(["レート制限とは何ですか?"])},role:n=>{const{normalize:r}=n;return r(["専門的な役割"])},self_check:n=>{const{normalize:r}=n;return r(["セルフテスト"])},sending_feedback:n=>{const{normalize:r}=n;return r(["送信中..."])},shortcut:n=>{const{normalize:r}=n;return r(["ショートカット"])},submit:n=>{const{normalize:r}=n;return r(["提出する"])},submit_failed:n=>{const{normalize:r}=n;return r(["送信に失敗しました。後でもう一度試してください。"])},submit_success:n=>{const{normalize:r}=n;return r(["ご提出いただきありがとうございます。できるだけ早くご連絡させていただきます。"])},subtitle:n=>{const{normalize:r}=n;return r(["Jina AI は、モデル チューニング、モデル サービス、プロンプト ワード チューニングとデプロイメントを専門とするマルチモーダル AI 分野のリーダーです。 Kubernetes やサーバーレス アーキテクチャなどのクラウド ネイティブ テクノロジーを活用して、強力でスケーラブルで実稼働対応のソリューションを提供します。大規模な言語モデル、テキスト、画像、ビデオ、音声理解、ニューラル検索、ジェネレーティブ アートに関する専門知識を活かし、お客様のビジネスを強化するための革新的で将来性のある戦略を提供します。"])},subtitle1:n=>{const{normalize:r}=n;return r(["Jina AI はマルチモーダル AI 分野のリーダーであり、大規模モデルのベクトルのチューニングと展開、およびプロンプト ワードのチューニングと展開を専門としています。 Kubernetes やサーバーレス アーキテクチャなどのクラウド ネイティブ テクノロジーを活用して、強力でスケーラブルで実稼働対応のソリューションを提供します。大規模な言語モデル、テキスト、画像、ビデオ、音声理解、ニューラル検索、生成 AI に関する専門知識を活かし、お客様のビジネスを強化するための革新的で将来性のある戦略を提供します。"])},subtitle2:n=>{const{normalize:r}=n;return r(["最先端のマルチモーダル AI である Jina AI について学びましょう。当社はベクトル化とプロンプトワードテクノロジーを専門とし、Kubernetes などのクラウドネイティブソリューションを活用して強力でスケーラブルなシステムを構築します。当社は大規模な言語モデルとメディア処理を専門とし、高度な人工知能の専門知識を活用して、革新的で将来性のあるビジネス戦略を実現します。"])},title:n=>{const{normalize:r}=n;return r(["営業担当者に問い合わせる"])},trusted_by:n=>{const{normalize:r}=n;return r(["私たちは信頼できる"])},turn_on_volume:n=>{const{normalize:r}=n;return r(["音量を上げる"])},work_email:n=>{const{normalize:r}=n;return r(["仕事のメール"])}},copy:n=>{const{normalize:r}=n;return r(["コピー"])},copy_to_clipboard_success:n=>{const{normalize:r}=n;return r(["クリップボードにコピーされました"])},dalle_flow:{description:n=>{const{normalize:r}=n;return r(["テキストから高解像度画像を作成するための人間とコンピューターの対話ワークフロー"])}},"dev-gpt":{description:n=>{const{normalize:r}=n;return r(["仮想開発チーム"])}},disco_art:{description:n=>{const{normalize:r}=n;return r(["1 行のコードで目を引くディスコ ディフュージョン アートワークを作成"])}},doc_array:{description:n=>{const{normalize:r}=n;return r(["マルチモーダルデータのデータ構造"])}},download:n=>{const{normalize:r}=n;return r(["SOC 2 タイプ 1 認定をダウンロード"])},embedding:{"11B tokens":n=>{const{normalize:r}=n;return r(["1億1000万"])},"11B tokens_intuition1":n=>{const{normalize:r}=n;return r(["Wikipedia の英語の記事をすべて読むのと似ています。"])},"11B tokens_targetUser":n=>{const{normalize:r}=n;return r(["本番展開"])},"1B tokens":n=>{const{normalize:r}=n;return r(["1億"])},"1B tokens_intuition1":n=>{const{normalize:r}=n;return r(["おそらくシェイクスピア全集や「ハリー・ポッター」シリーズを全部読むのと同じだろう。"])},"1B tokens_targetUser":n=>{const{normalize:r}=n;return r(["試作開発"])},"1M tokens":n=>{const{normalize:r}=n;return r(["100万"])},"1M tokens_intuition1":n=>{const{normalize:r}=n;return r(["『ホビット』『華麗なるギャツビー』の全文を読むのに相当します。"])},"1M tokens_targetUser":n=>{const{normalize:r}=n;return r(["おもちゃの実験"])},"1M_free":n=>{const{normalize:r}=n;return r(["何百万もの単語を無料で自由に使用できます"])},"1M_free_description":n=>{const{normalize:r}=n;return r(["無料トークンを使用して新しい API キーをお楽しみください。クレジット カードは必要ありません。"])},"2_5B tokens":n=>{const{normalize:r}=n;return r(["25億ワード要素"])},"2_5B tokens_intuition1":n=>{const{normalize:r}=n;return r(["これは、「ロード・オブ・ザ・リング」三部作で話されたすべての単語を 1,000 回書き写すことに相当します。"])},"3p_integration":n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["<b>",e(o("_numPartners")),"</b> 個のサードパーティ サービスがある"])},"3p_integration_desc":n=>{const{normalize:r}=n;return r(["当社の検索インフラストラクチャを既存のサービスと統合します。当社のパートナーは当社の API へのコネクタを構築しているため、アプリケーションで当社のモデルを簡単に使用できます。"])},"500M tokens":n=>{const{normalize:r}=n;return r(["5億トークン"])},"500M tokens_intuition1":n=>{const{normalize:r}=n;return r(["シンプソンズのシーズン 1 からシーズン 30 までの全エピソードを視聴するのと同じです。"])},"59B tokens":n=>{const{normalize:r}=n;return r(["59B ワード要素"])},"59B tokens_intuition1":n=>{const{normalize:r}=n;return r(["これは、2 日間に世界中で投稿されたツイートすべてに相当します。"])},"5_5B tokens":n=>{const{normalize:r}=n;return r(["55億ワード要素"])},"5_5B tokens_intuition1":n=>{const{normalize:r}=n;return r(["ブリタニカ百科事典をすべて読むのと同等です。"])},Free1M:n=>{const{normalize:r}=n;return r(["100万トークン"])},add_pair:n=>{const{normalize:r}=n;return r(["新しい"])},add_time_explain:n=>{const{normalize:r}=n;return r(["このモデルが検索ベースに追加された時刻。"])},api_integration_short:n=>{const{normalize:r}=n;return r(["当社のベクター モデル API は、一般的なデータベース、ベクター データベース、RAG および LLMOps フレームワークで簡単に使用できます。"])},api_integrations:n=>{const{normalize:r}=n;return r(["API統合"])},api_key_update_message:n=>{const{normalize:r}=n;return r(["古い API キーを置き換えると、jina.ai にアクセスするたびに新しいキーが UI に表示されます。今後の追加はこの新しいキーに適用されます。古いキーはまだ有効なので、再度使用する予定がある場合は安全に保管してください。"])},api_key_update_title:n=>{const{normalize:r}=n;return r(["APIキーを変更する"])},auto_recharge:n=>{const{normalize:r}=n;return r(["ワード要素が少なくなると自動的にリチャージ"])},auto_recharge_confirm_message:n=>{const{normalize:r}=n;return r(["自動再チャージを無効にしてもよろしいですか?これにより、トークン残高が少ない場合の自動補充が防止されます。"])},auto_recharge_confirm_title:n=>{const{normalize:r}=n;return r(["自動チャージを無効にする"])},auto_recharge_description:n=>{const{normalize:r}=n;return r(["運用環境で使用する必要がある場合は、このオプションを有効にしてください。このようにして、トークン残高が設定したしきい値を下回ると、最後のリチャージと同じ金額がクレジット カードに自動的にリチャージされます。前回のリチャージで複数のトークン パッケージを購入した場合、この API には 1 つのパッケージのみがリチャージされます。"])},auto_recharge_enable:n=>{const{normalize:r}=n;return r(["自動チャージを有効にしました"])},auto_recharge_enable_message:n=>{const{normalize:r}=n;return r(["自動リチャージを有効にするには、プラン購入時に自動リチャージのスイッチをオンにしてください。"])},auto_recharge_enable_title:n=>{const{normalize:r}=n;return r(["自動補充を有効にする"])},auto_request:n=>{const{normalize:r}=n;return r(["自動プレビュー"])},auto_request_tooltip:n=>{const{normalize:r}=n;return r(["API キー内の数百のトークンを使用してモデルを変更するときに、API 応答を自動的にプレビューします。閉じたら、「応答を取得」をクリックしてリクエストを手動で送信します。"])},autostart:n=>{const{normalize:r}=n;return r(["ベクトル化が自動的に開始されます"])},base64_description:n=>{const{normalize:r}=n;return r(["ベクトルは、base64 でエンコードされた文字列として返されます。伝達効率が高くなります。"])},batch_job:n=>{const{normalize:r}=n;return r(["バッチ処理"])},batch_upload_hint:n=>{const{normalize:r}=n;return r(["バッチ処理には以下のAPIキーとモデルを使用します。"])},"bge-base-en-v1_5_description":n=>{const{normalize:r}=n;return r(["性能と効率を両立し、さまざまな用途に適した強力な英国モデル。"])},"bge-base-en_description":n=>{const{normalize:r}=n;return r(["確かな演奏性を追求したバランスの良い英国式モデル。"])},"bge-base-zh-v1_5_description":n=>{const{normalize:r}=n;return r(["性能と効率を総合的にバランスさせた中国モデル。"])},"bge-base-zh_description":n=>{const{normalize:r}=n;return r(["効率性とパワフルなパフォーマンスを兼ね備えた汎用性の高い中華モデル。"])},"bge-large-en-v1_5_description":n=>{const{normalize:r}=n;return r(["優れた品質のトップベクトルを提供する強力な英語モデル。"])},"bge-large-en_description":n=>{const{normalize:r}=n;return r(["高品質のベクター用に構築された一流の英語モデル。"])},"bge-large-zh-v1_5_description":n=>{const{normalize:r}=n;return r(["優れた詳細なベクトルを備えた大容量の中国語モデルを提供します。"])},"bge-large-zh_description":n=>{const{normalize:r}=n;return r(["上位ベクトル向けに最適化された高性能中国モデル。"])},"bge-m3_description":n=>{const{normalize:r}=n;return r(["広範な機能と高品質のベクトルを提供する多言語モデル。"])},"bge-small-en-v1_5_description":n=>{const{normalize:r}=n;return r(["効率的で高品質のベクトルを提供する合理化された英語モデル。"])},"bge-small-en_description":n=>{const{normalize:r}=n;return r(["簡略化された正確なベクトルのための効率的な英語モデル。"])},"bge-small-zh-v1_5_description":n=>{const{normalize:r}=n;return r(["柔軟で正確なベクタリングを実現するコンパクトな中国モデル。"])},"bge-small-zh_description":n=>{const{normalize:r}=n;return r(["効率的かつ正確なベクトル化のためのアジャイルな中国語モデル。"])},binary_description:n=>{const{normalize:r}=n;return r(["ベクトルは int8 としてパックされます。保管、検索、転送がより効率的になります。"])},bulk:n=>{const{normalize:r}=n;return r(["バッチ処理"])},bulk_embedding_failed:n=>{const{normalize:r}=n;return r(["バッチの作成に失敗しました"])},buy_more_quota:n=>{const{normalize:r}=n;return r(["この API キーにさらにトークンを追加します"])},buy_poster:n=>{const{normalize:r}=n;return r(["ポスターを購入する"])},cancel_button:n=>{const{normalize:r}=n;return r(["キャンセル"])},click_upload_btn_above:n=>{const{normalize:r}=n;return r(["上のアップロードボタンをクリックして開始してください。"])},code:n=>{const{normalize:r}=n;return r(["コード"])},colbert_dimensions_explain:n=>{const{normalize:r}=n;return r(["各マーカー埋め込みの寸法サイズ。"])},compatible:n=>{const{normalize:r}=n;return r(["互換モード"])},compatible_explain:n=>{const{normalize:r}=n;return r(["テキスト ベクトル モデルと同じリクエスト形式に従います。これにより、リクエストを変更せずにモデルを切り替えることができます。このモードでは画像入力はサポートされていないことに注意してください。"])},cosine_similarity:n=>{const{normalize:r}=n;return r(["コサイン類似度"])},debugging:n=>{const{normalize:r}=n;return r(["テスト"])},delete_pair:n=>{const{normalize:r}=n;return r(["消去"])},description:n=>{const{normalize:r,linked:e,type:o}=n;return r([e("landing_page.embedding_desc1",void 0,o)])},dimensions:n=>{const{normalize:r}=n;return r(["出力寸法"])},dimensions_error:n=>{const{normalize:r}=n;return r(["次元は 1 ～ 1024 の範囲にする必要があります。"])},dimensions_explain:n=>{const{normalize:r}=n;return r(["サイズが小さいほど保存と取得が容易で、MRL によるパフォーマンスへの影響は最小限に抑えられます。"])},dimensions_warning:n=>{const{normalize:r}=n;return r(["タスクを効率的に実行するには、サイズを 32 以上に保つことをお勧めします。"])},document:n=>{const{normalize:r}=n;return r(["書類"])},download:n=>{const{normalize:r}=n;return r(["ダウンロード"])},edit_text1_text:n=>{const{normalize:r}=n;return r(["左側のテキストを編集する"])},edit_text2_text:n=>{const{normalize:r}=n;return r(["右側のテキストを編集します"])},embedding_done:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_Count"))," 文のベクトル化に成功しました。"])},embedding_none_description:n=>{const{normalize:r}=n;return r(["ベクトルモデルを使用しないでください"])},example_inputs:n=>{const{normalize:r}=n;return r(["入力例"])},faq:n=>{const{normalize:r,linked:e,type:o}=n;return r([e("contact_us_page.faq",void 0,o)])},faqs_v2:{answer0:n=>{const{normalize:r}=n;return r(["トレーニング プロセス、データ ソース、評価の詳細については、arXiv で入手可能な技術レポートを参照してください。"])},answer1:n=>{const{normalize:r}=n;return r(["各ユーザーは 1 秒あたり最大 100 リクエストを行うことができ、これは 1 秒あたり 204,800 の入力文に相当します。"])},answer17:n=>{const{normalize:r}=n;return r(["私たちは現在、テキスト、画像、音声を共同処理するマルチモーダル ベクトル モデルを開発中です。アップデートは近日中に発表されます！"])},answer18:n=>{const{normalize:r}=n;return r(["特定のデータを使用したモデルの微調整についてご質問がある場合は、要件についてお問い合わせください。私たちのモデルをお客様のニーズに合わせてどのように適応できるかを検討したいと考えています。"])},answer19:n=>{const{normalize:r}=n;return r(["はい、当社のサービスは AWS Marketplace で利用でき、Azure および GCP Marketplace にも拡大中です。特別なご要望がある場合は、営業担当 jina.ai までお問い合わせください。"])},answer3:n=>{const{normalize:r}=n;return r(["当社のモデルは、英語、ドイツ語、スペイン語、中国語、およびさまざまなプログラミング言語をサポートしています。詳細については、バイリンガル モデルに関する論文を参照してください。"])},answer4:n=>{const{normalize:r}=n;return r(["私たちのモデルでは、最大 8192 トークンの長さの入力が可能ですが、これは他のほとんどのモデルよりも大幅に長くなります。トークンの範囲は、単一の文字 (「a」など) から単語全体 (「apple」など) までです。入力できる合計文字数は、使用される単語の長さと複雑さによって異なります。この拡張された入力機能により、jina-embeddings-v2 モデルは、より包括的なテキスト分析を実行し、特に大量のテキスト データのコンテキスト理解においてより高い精度を達成できるようになります。"])},answer5:n=>{const{normalize:r}=n;return r(["API 呼び出しは最大 2048 文またはテキストを処理できるため、1 回のリクエストで広範なテキスト分析が容易になります。"])},answer6:n=>{const{normalize:r}=n;return r(["API リクエストの <code>input</code> フィールドでは <code>url</code> または <code>bytes</code> を使用できます。 <code>url</code> には、処理する画像の URL を指定します。 <code>bytes</code> の場合、画像を Base64 形式でエンコードし、リクエストに含めます。モデルは応答に画像の埋め込みを返します。"])},answer7:n=>{const{normalize:r}=n;return r(["MTEB ランキングによると、私たちのモデルは OpenAI の text-embedding-ada-002 とほぼ競合しており、同等の平均パフォーマンスを示しています。さらに、私たちのモデルは、分類、ペアごとの分類、並べ替え、要約などの複数のタスクにおいて OpenAI のモデルよりも優れています。"])},answer8:n=>{const{normalize:r}=n;return r(["API インターフェイス https://api.jina.ai/v1/embeddings が OpenAI の text-embeddings-ada-002 モデルの入力および出力 JSON スキーマと一致するため、変換が簡素化されます。この互換性により、ユーザーは OpenAI のインターフェイスを使用する際に、OpenAI モデルを当社のモデルに簡単に置き換えることができます。"])},answer9:n=>{const{normalize:r}=n;return r([`トークンはテキストの長さと画像のサイズに基づいて計算されます。リクエスト内のテキストの場合、トークンは標準的な方法でカウントされます。リクエスト内の画像に対して、次の手順を実行します。
1. タイル サイズ: 各画像はサイズ 224x224 ピクセルのタイルに分割されます。
2. カバレッジ: 入力画像を完全にカバーするために必要なタイルの数を計算します。画像サイズが正確に 224 で割り切れない場合でも、部分的なタイルは完全なタイルとしてカウントされます。
3. タイルの総数: 画像を覆うタイルの総数によってコストが決まります。たとえば、画像が 500x500 ピクセルの場合、3x3 のタイルで覆われ、9 つのタイルになります。
4. コスト計算: 各タイルは、画像処理の最終コストに影響します。各タイルのコストは 1000 トークンです。

例：
サイズが 500x500 ピクセルの画像の場合:

• 画像は 224x224 ピクセルのタイルに分割されます。
• 必要なタイルの総数は、3 (水平) x 3 (垂直) = 9 タイルです。
• コストは 9*1000 = 9000 トークンです`])},question0:n=>{const{normalize:r}=n;return r(["jina-embeddings-v2 モデルはどのようにトレーニングされますか?"])},question1:n=>{const{normalize:r}=n;return r(["1 秒あたり何件の API リクエストを行うことができますか?"])},question17:n=>{const{normalize:r}=n;return r(["ベクター モデル画像またはオーディオ モデルは提供されますか?"])},question18:n=>{const{normalize:r}=n;return r(["Jina Vector Model モデルは個人データまたは企業データを使用して微調整できますか?"])},question19:n=>{const{normalize:r}=n;return r(["インターフェイスを AWS、Azure、または GCP でプライベートにホストできますか?"])},question3:n=>{const{normalize:r}=n;return r(["あなたのモデルはどの言語をサポートしていますか?"])},question4:n=>{const{normalize:r}=n;return r(["単一の文入力の最大長はどれくらいですか?"])},question5:n=>{const{normalize:r}=n;return r(["1 つのリクエストには何文を含めることができますか?"])},question6:n=>{const{normalize:r}=n;return r(["jina-clip-v1 モデルに画像を送信するにはどうすればよいですか?"])},question7:n=>{const{normalize:r}=n;return r(["Jina Embeddings モデルは OpenAI の text-embedding-ada-002 モデルとどのように比較されますか?"])},question8:n=>{const{normalize:r}=n;return r(["OpenAI の text-embedding-ada-002 からソリューションへの移行はどのくらいスムーズでしたか?"])},question9:n=>{const{normalize:r}=n;return r(["jina-clip-v1 を使用するときにトークンをカウントするにはどうすればよいですか?"])},title:n=>{const{normalize:r}=n;return r(["ベクトル モデルに関するよくある質問"])}},feature_8k1:n=>{const{normalize:r}=n;return r(["8192長さ"])},feature_8k_description1:n=>{const{normalize:r}=n;return r(["8192 ワード長の世界初のオープンソース ベクトル モデルは、人民日報のページ全体をベクトルに圧縮できます。"])},feature_cheap:n=>{const{normalize:r}=n;return r(["コストを50倍削減"])},feature_cheap_v1:n=>{const{normalize:r}=n;return r(["5倍のコスト削減"])},feature_cheap_v1_description1:n=>{const{normalize:r}=n;return r(["まずは無料トライアル、シンプルな料金体系、迅速な支払いから始めてください。 OpenAI のコストのわずか 20% で強力なベクトル モデルを入手できます。"])},feature_multilingual:n=>{const{normalize:r}=n;return r(["海外企業の多言語アプリケーションに不可欠な、ドイツ語-英語、中国語-英語、その他のバイリンガル モデルを提供します。"])},feature_on_premises:n=>{const{normalize:r}=n;return r(["プライバシー第一"])},feature_on_premises_description1:n=>{const{normalize:r}=n;return r(["ベクター モデルを Virtual Private Cloud (VPC) に直接シームレスにデプロイします。 AWS Sagemaker に簡単にデプロイでき、まもなく Microsoft Azure および Google Cloud Platform と統合される予定です。 Kubernetes の展開をカスタマイズするには、当社の営業チームに専門的なサポートをお問い合わせください。"])},feature_on_premises_description2:n=>{const{normalize:r}=n;return r(["当社のベクトル モデルは AWS Sagemaker に簡単にデプロイでき、まもなく Microsoft Azure および Google Cloud Services でのサポートを提供する予定です。 Kubernetes の展開をカスタマイズするには、当社の営業チームに専門的なサポートをお問い合わせください。"])},feature_on_premises_description3:n=>{const{normalize:r}=n;return r(["Jina Embeddings モデルを AWS Sagemaker と Microsoft Azure にデプロイし、まもなく Google Cloud サービスにもデプロイするか、当社の営業チームに問い合わせて、仮想プライベート クラウドとオンプレミス サーバー用のカスタム Kubernetes デプロイメントを入手してください。"])},feature_on_premises_description4:n=>{const{normalize:r}=n;return r(["AWS SageMaker、Microsoft Azure、または Google Cloud Services を使用して Jina Embedding モデルと Reranker モデルをローカルにデプロイし、データを安全に管理します。"])},feature_solid:n=>{const{normalize:r}=n;return r(["並外れた"])},feature_solid_description1:n=>{const{normalize:r}=n;return r(["当社の確かな AI 科学研究活動に基づいて、モデルの最高のパフォーマンスを保証するために、同様のモデルとの厳格な比較テストを実施しました。"])},feature_top_perform1:n=>{const{normalize:r}=n;return r(["シームレス統合"])},feature_top_perform_description1:n=>{const{normalize:r}=n;return r(["OpenAIのAPIと完全に互換性があります。 10 を超えるベクター データベースや RAG システムと簡単に統合できるため、開発者エクスペリエンスがスムーズになります。"])},file_required:n=>{const{normalize:r}=n;return r(["ファイルをアップロードしてください"])},file_size_exceed:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["ファイルサイズが ",e(o("_size"))," 制限を超えています"])},file_type_not_supported:n=>{const{normalize:r}=n;return r(["サポートされていないファイル形式"])},fill_example:n=>{const{normalize:r}=n;return r(["記入例"])},float_description:n=>{const{normalize:r}=n;return r(["ベクトルは浮動小数点数のリストとして返されます。最も一般的で使いやすい。"])},free:n=>{const{normalize:r}=n;return r(["無料"])},generate_api_key_error:n=>{const{normalize:r}=n;return r(["API キーの生成に失敗しました。"])},generating_visualization:n=>{const{normalize:r}=n;return r(["ビジュアライゼーションを生成..."])},get_new_key_button:n=>{const{normalize:r}=n;return r(["新しいキーを取得する"])},get_new_key_button_explain:n=>{const{normalize:r}=n;return r(["新しいキーを選択すると、古いキーに関連付けられていた使用履歴が失われます。"])},get_new_key_survey:n=>{const{normalize:r}=n;return r(["アンケートに記入して使用状況を把握し、新しい API キーを無料で入手してください。"])},includes:n=>{const{normalize:r}=n;return r(["購入したワード要素は以下の製品で使用できます。"])},index_and_search:n=>{const{normalize:r}=n;return r(["インデックス作成と検索"])},index_and_search1:n=>{const{normalize:r}=n;return r(["インデックス作成と検索"])},input:n=>{const{normalize:r}=n;return r(["聞く"])},input_api_key_error1:n=>{const{normalize:r}=n;return r(["API キーが無効です。"])},input_length:n=>{const{normalize:r}=n;return r(["長さを入力してください"])},input_type:n=>{const{normalize:r}=n;return r(["クエリまたはドキュメントのベクトル化"])},input_type_explain:n=>{const{normalize:r}=n;return r(["一部のベクトル モデルには、クエリとドキュメントに特化したベクトル化戦略があります。ビジネス シナリオでの役割に応じて、同じ文字列をクエリまたはドキュメントにベクトル化できます。"])},integrate:n=>{const{normalize:r}=n;return r(["統合された"])},"jina-clip-v1_description":n=>{const{normalize:r}=n;return r(["テキストおよび画像検索用の最新のマルチモーダル ベクトル モデル。"])},"jina-colbert-v1-en_description":n=>{const{normalize:r}=n;return r(["改良された ColBERT モデルは 8K 長さのコンテキストをサポートし、ベクトル化および再配置タスクに使用できます。"])},"jina-colbert-v2_description":n=>{const{normalize:r}=n;return r(["ベクトル化と並べ替えで最高のパフォーマンスを発揮する最新の多言語 ColBERT"])},"jina-embeddings-v2-base-code_description":n=>{const{normalize:r}=n;return r(["コードおよび技術文書検索用のベクトル モデル"])},"jina-embeddings-v2-base-de_description":n=>{const{normalize:r}=n;return r(["ドイツ語と英語のバイリンガルをサポートする 8K 最高のベクトル モデル"])},"jina-embeddings-v2-base-en_description":n=>{const{normalize:r}=n;return r(["OpenAI の text-embedding-ada002 に相当"])},"jina-embeddings-v2-base-es_description":n=>{const{normalize:r}=n;return r(["スペイン語と英語のバイリンガルをサポートする 8K 最高のベクトル モデル"])},"jina-embeddings-v2-base-zh_description":n=>{const{normalize:r}=n;return r(["中国語と英語のバイリンガリズムをサポートする 8K 最高のベクトル モデル"])},"jina-embeddings-v2-small-en_description":n=>{const{normalize:r}=n;return r(["低レイテンシーと少量のメモリ向けに最適化"])},"jina-embeddings-v3_description":n=>{const{normalize:r}=n;return r(["テキストとコードの両方で最適なパフォーマンスを備えた最新かつ最高のベクトル化モデル"])},"jina-reranker-v1-base-en_description":n=>{const{normalize:r}=n;return r(["最初のリランカーは検索と RAG 関連性を最大化します"])},"jina-reranker-v1-tiny-en_description":n=>{const{normalize:r}=n;return r(["大量のドキュメントを確実に並べ替えるための最速の並べ替え機能"])},"jina-reranker-v1-turbo-en_description":n=>{const{normalize:r}=n;return r(["速度と精度の間の最適なトレードオフ"])},"jina-reranker-v2-base-multilingual_description":n=>{const{normalize:r}=n;return r(["クラス最高の精度と速度パフォーマンスを備えた最先端の多言語ドキュメントおよびクエリ リフォーマー"])},key:n=>{const{normalize:r}=n;return r(["APIキー"])},key_enter_placeholder:n=>{const{normalize:r}=n;return r(["API キーを入力してください"])},key_enter_placeholder_to_topup:n=>{const{normalize:r}=n;return r(["トップアップしたいAPIキーを入力してください"])},key_to_top_up:n=>{const{normalize:r}=n;return r(["他に追加する API キーがありますか?上記の内容を貼り付けて「保存」をクリックします。"])},key_warn:n=>{const{normalize:r}=n;return r(["API キーは安全な場所に保管してください。それ以外の場合は、新しいキーを生成する必要があります"])},key_warn_v2:n=>{const{normalize:r}=n;return r(["これはあなた固有のキーです。大切に保管してください！"])},language_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["このモデルは、",e(o("_language"))," 言語を最もよくサポートしています。"])},last_7_days:n=>{const{normalize:r}=n;return r(["過去 7 日間の使用量"])},late_chunking:n=>{const{normalize:r}=n;return r(["ポストチャンク化"])},late_chunking_explain:n=>{const{normalize:r}=n;return r(["ポストブロッキング手法は、モデルのロングコンテキスト機能を利用してコンテキスト ブロックのベクトル化を生成するために適用されます。"])},learn_more:n=>{const{normalize:r}=n;return r(["もっと詳しく知る"])},learn_poster:n=>{const{normalize:r}=n;return r(["ポスターを知る"])},learning1:n=>{const{normalize:r}=n;return r(["ベクトルモデルの学習"])},learning1_description:n=>{const{normalize:r}=n;return r(["ベクトルとは何ですか?なぜベクトル化する必要があるのですか?始めるための記事がいくつかあります。包括的なガイドでベクトル モデルについて基礎から学びましょう。"])},length:n=>{const{normalize:r}=n;return r(["長さ"])},manage_billing:n=>{const{normalize:r}=n;return r(["請求書の管理"])},manage_billing_tip:n=>{const{normalize:r}=n;return r(["請求情報を管理し、請求書を取得し、自動チャージを設定します。"])},manage_quota1:n=>{const{normalize:r}=n;return r(["鍵と請求"])},max_file_size:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["最大許容サイズ: ",e(o("_maxSize")),"。"])},maximize_tooltip:n=>{const{normalize:r}=n;return r(["このパネルを最大化するには Shift+1 を使用します"])},mistake_contact:n=>{const{normalize:r}=n;return r(["これがバグだと思われる場合は、お問い合わせください。"])},model_required:n=>{const{normalize:r}=n;return r(["モデルを選択してください"])},more_than_two2:n=>{const{normalize:r}=n;return r(["文書は 2 つ以上、つまり 2 行以上入力してください。"])},multi_embedding:n=>{const{normalize:r}=n;return r(["マルチキャリア"])},multi_embedding_explain:n=>{const{normalize:r}=n;return r(["モデルは入力に対してベクトルのセットを返します。入力文内の各トークンは個別のベクトルにマッピングされます。"])},multilingual:n=>{const{normalize:r}=n;return r(["多言語サポート"])},multimodal:n=>{const{normalize:r}=n;return r(["複合一貫輸送"])},multimodal_explain:n=>{const{normalize:r}=n;return r(["このモデルはテキストと画像の入力をエンコードできるため、マルチモーダル検索タスクに最適です。"])},new:n=>{const{normalize:r}=n;return r(["ニューモデル"])},no_data1:n=>{const{normalize:r}=n;return r(["ペアの文を追加して類似度を計算します"])},none:n=>{const{normalize:r}=n;return r(["なにもない"])},normalized:n=>{const{normalize:r}=n;return r(["L2正規化"])},normalized_explain:n=>{const{normalize:r}=n;return r(["方向を維持しながら、ユークリッド (L2) ノルムが 1 になるように埋め込みをスケーリングします。下流でドット積、分類、視覚化が行われる場合に役立ちます。"])},oncsp:n=>{const{normalize:r}=n;return r(["CSPについて"])},onprem:n=>{const{normalize:r}=n;return r(["プライベート展開"])},open_tensorboard:n=>{const{normalize:r}=n;return r(["視覚化ツールを開く"])},opensource:n=>{const{normalize:r}=n;return r(["オープンソース"])},opensource_explain:n=>{const{normalize:r}=n;return r(["モデルはオープンソースであり、Hugging Face からダウンロードできます。このボタンをクリックすると、Hugging Face のモデルが表示されます。"])},original_documents:n=>{const{normalize:r}=n;return r(["ベクトル化された文章"])},original_documents_hint:n=>{const{normalize:r}=n;return r(["ここに文章を入力してください。新しい行はそれぞれ別の文/文書として扱われます。"])},output:n=>{const{normalize:r}=n;return r(["応答"])},output_dim:n=>{const{normalize:r}=n;return r(["出力寸法"])},output_dim_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["このモデルのベクトル出力の次元は ",e(o("_outputDim"))," です。"])},output_dimension:n=>{const{normalize:r}=n;return r(["出力寸法"])},pairwise_test:n=>{const{normalize:r}=n;return r(["ペアテスト"])},per_k:n=>{const{normalize:r}=n;return r(["千語あたり"])},per_m:n=>{const{normalize:r}=n;return r(["100万語あたりの単語"])},please_fill_docs_first:n=>{const{normalize:r}=n;return r(["検索する前に、以下に文章を入力してください。"])},please_select_model:n=>{const{normalize:r}=n;return r(["埋め込みモデルまたはリランカー モデルを選択してください"])},poster:n=>{const{normalize:r}=n;return r(["ベクターモデル70年"])},poster_description:n=>{const{normalize:r}=n;return r(["当社の丁寧に作られたポスターをオフィススペースやリビングルームに飾って、1950 年以来のテキスト ベクター モデルの進化と進化から次のインスピレーションを見つけてください。"])},pricing:n=>{const{normalize:r}=n;return r(["API価格表"])},pricing_desc:n=>{const{normalize:r}=n;return r(["API の価格は、リクエストで送信されるトークンの数に基づいています。 Reader API の場合、これは応答内のトークンの数です。この価格モデルは、Jina AI 検索ベースのすべての製品 (Vector、Rerank、Reader、Auto-Nudge API) に適用されます。同じ API キーを使用して、すべての API サービスにアクセスできます。"])},protectData1:n=>{const{normalize:r}=n;return r(["あなたが私たちに送ったデータや文書はモデルのトレーニングには使用されません。"])},protectData2:n=>{const{normalize:r}=n;return r(["データは転送中 (TLS 1.2+) および保存中 (AES-GCM 256) で暗号化されます。"])},protectData3:n=>{const{normalize:r}=n;return r(["SOC 2 および GDPR への準拠。"])},protect_data:n=>{const{normalize:r}=n;return r(["データを保護する"])},public_cloud_integration:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["<b>",e(o("_numPartners")),"</b> のクラウド サービス プロバイダーと連携します"])},public_cloud_integration_desc:n=>{const{normalize:r}=n;return r(["あなたの会社は AWS または Azure を使用していますか?次に、当社の検索インフラストラクチャ モデルを社内のこれらのプラットフォームに直接展開して、データの安全性と準拠性を維持します。"])},query:n=>{const{normalize:r}=n;return r(["クエリ文"])},raise_issue:n=>{const{normalize:r}=n;return r(["問題のフィードバック"])},rank_none_description:n=>{const{normalize:r}=n;return r(["再配置モデルは使用しないでください"])},read_api_docs:n=>{const{normalize:r}=n;return r(["API仕様"])},read_release_note:n=>{const{normalize:r}=n;return r(["リリースノートを読む"])},recharge_threshold:n=>{const{normalize:r}=n;return r(["リチャージ閾値"])},refresh:n=>{const{normalize:r}=n;return r(["リフレッシュする"])},refresh_key_tooltip1:n=>{const{normalize:r}=n;return r(["新しい API キーを無料で取得する"])},refresh_token_count1:n=>{const{normalize:r}=n;return r(["更新して現在の API キーで使用可能なトークンを取得します"])},regenerate:n=>{const{normalize:r}=n;return r(["新しいキーを生成する"])},remaining:n=>{const{normalize:r}=n;return r(["トークン残量"])},remaining_left:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["以下の API キーには <b>",e(o("_leftTokens")),"</b> 個のトークンが残っています。"])},request_number:n=>{const{normalize:r}=n;return r(["リクエスト数"])},request_path:n=>{const{normalize:r}=n;return r(["リクエストエンドポイント"])},results_as_final_result:n=>{const{normalize:r}=n;return r(["最終結果として #docs"])},results_fed_to_reranker:n=>{const{normalize:r}=n;return r(["リランカーへの #docs フィード"])},retry:n=>{const{normalize:r}=n;return r(["リトライ"])},return_base64:n=>{const{normalize:r}=n;return r(["Base64 (文字列)"])},return_binary:n=>{const{normalize:r}=n;return r(["バイナリ (int8 としてパック)"])},return_float:n=>{const{normalize:r}=n;return r(["デフォルト (浮動小数点)"])},return_format:n=>{const{normalize:r}=n;return r(["ベクトル形式"])},return_format_explain:n=>{const{normalize:r}=n;return r(["浮動小数点に加えて、ベクトルの取得を高速化するためにバイナリで返すように要求することも、転送を高速化するために Base64 エンコードで返すように要求することもできます。"])},return_format_title:n=>{const{normalize:r}=n;return r(["戻り値のデータ型"])},return_ubinary:n=>{const{normalize:r}=n;return r(["バイナリ (uint8 としてパック)"])},right_api_key_to_charge:n=>{const{normalize:r}=n;return r(["リチャージするには正しい API キーを入力してください"])},running:n=>{const{normalize:r}=n;return r(["ランニング"])},score:n=>{const{normalize:r}=n;return r(["分数"])},search:n=>{const{normalize:r}=n;return r(["検索"])},search_hint:n=>{const{normalize:r}=n;return r(["次の文に検索したい内容を入力してください"])},select_classify_model:n=>{const{normalize:r}=n;return r(["分類子の選択"])},select_embedding_model:n=>{const{normalize:r}=n;return r(["埋め込みを選択"])},select_rerank_model:n=>{const{normalize:r}=n;return r(["再注文者の選択"])},show_api_key:n=>{const{normalize:r}=n;return r(["APIキーを表示"])},size:n=>{const{normalize:r}=n;return r(["パラメータ"])},size_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["モデル内のパラメータの数は ",e(o("_size"))," です。これはモデルのファイル サイズを表すものではないことに注意してください。"])},sleeping:n=>{const{normalize:r}=n;return r(["睡眠"])},start_batch:n=>{const{normalize:r}=n;return r(["バッチ処理を開始する"])},start_embedding:n=>{const{normalize:r}=n;return r(["インデックス作成の開始"])},status_explain:n=>{const{normalize:r}=n;return r(["当社のサーバーレス アーキテクチャでは、使用状況に応じて、現在使用されていない一部のモデルをメモリから即座にオフロードする場合があります。アクティブなモデルの場合、応答は即時に行われます。休止中のモデルは最初のリクエストを受信するまでロードされず、このプロセスは数十秒かかる場合があります。モデルが起動されると、後続のリクエストはより速く処理されます。"])},task_type:n=>{const{normalize:r}=n;return r(["下流タスク"])},task_type_classification:n=>{const{normalize:r}=n;return r(["分類"])},task_type_classification_explain:n=>{const{normalize:r}=n;return r(["テキストの分類。"])},task_type_explain:n=>{const{normalize:r}=n;return r(["ベクトル モデルを使用するダウンストリーム タスクを選択します。モデルはタスクに最適化されたベクトルを返します。"])},task_type_none_explain:n=>{const{normalize:r}=n;return r(["アダプターは使用しません。デバッグやハッキングに使用できる汎用の埋め込みを返します。"])},task_type_retrieval_passage:n=>{const{normalize:r}=n;return r(["検索チャンネル"])},task_type_retrieval_passage_explain:n=>{const{normalize:r}=n;return r(["クエリドキュメント取得タスクのためにドキュメントをベクトル化します。"])},task_type_retrieval_query:n=>{const{normalize:r}=n;return r(["検索クエリ"])},task_type_retrieval_query_explain:n=>{const{normalize:r}=n;return r(["クエリドキュメント取得タスクにおけるクエリのベクトル化。"])},task_type_separation:n=>{const{normalize:r}=n;return r(["分離"])},task_type_separation_explain:n=>{const{normalize:r}=n;return r(["クラスタリングドキュメント、視覚化コーパス。"])},"task_type_text-matching":n=>{const{normalize:r}=n;return r(["テキストマッチング"])},"task_type_text-matching_explain":n=>{const{normalize:r}=n;return r(["セマンティックテキストの類似性、一般化された対称検索、推奨、類似アイテムの検索、および重複排除。"])},tax_may_apply:n=>{const{normalize:r}=n;return r(["お住まいの地域によっては、米ドル、ユーロ、またはその他の通貨で請求される場合があります。税金が適用される場合があります。"])},text1:n=>{const{normalize:r}=n;return r(["左"])},text2:n=>{const{normalize:r}=n;return r(["右"])},title:n=>{const{normalize:r}=n;return r(["ベクトルモデルAPI"])},token_example:n=>{const{normalize:r}=n;return r(["Weibo の投稿には約 20 トークンがあり、人民日報のニュース記事には約 1,000 トークンがあり、チャールズ ディケンズの小説「二都物語」には 100 万以上のトークンがあります。"])},token_length_explain:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["このモデルでサポートされる入力トークンの最大長は ",e(o("_tokenLength"))," です。"])},tokens:n=>{const{normalize:r}=n;return r(["単語要素"])},tools:n=>{const{normalize:r}=n;return r(["道具"])},top_up_button:n=>{const{normalize:r}=n;return r(["古いキーを補充する"])},top_up_button_explain:n=>{const{normalize:r}=n;return r(["この API キーを統合すると、キーを頻繁に変更する必要がなく、より専門的なソリューションが提供されます。使用状況データは保持され、いつでもアクセスできます。"])},top_up_warning_message1:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["現在の API キーには ",e(o("_remainedTokens"))," トークンが残っており、",e(o("_freeTokens"))," トークンを持つ新しいキーに置き換えられます。古いキーを安全な場所に保管している場合は、古いキーを引き続き使用するか、追加することができます。どのように進めたいですか?"])},top_up_warning_title:n=>{const{normalize:r}=n;return r(["古い鍵を交換しますか?"])},total_documents:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["ベクトル化の進行状況: ",e(o("_Processed")),"/",e(o("_Count"))," 文。"])},tuning:n=>{const{normalize:r}=n;return r(["微調整"])},turnstile_error:n=>{const{normalize:r}=n;return r(["あなたが人間であることを確認できないため、API キーを生成できません。"])},turnstile_unsupported:n=>{const{normalize:r}=n;return r(["お使いのブラウザはサポートされていないため、API キーを生成できません。"])},ubinary_description:n=>{const{normalize:r}=n;return r(["ベクトルは uint8 としてパックされます。保管、検索、転送がより効率的になります。"])},upload:n=>{const{normalize:r}=n;return r(["アップロード"])},upload_file:n=>{const{normalize:r}=n;return r(["ファイルをアップロードするにはここをクリックしてください"])},usage:n=>{const{normalize:r}=n;return r(["使用法"])},usage_amount:n=>{const{normalize:r}=n;return r(["単語要素"])},usage_history:n=>{const{normalize:r}=n;return r(["過去 7 日間の使用量"])},usage_history_explain:n=>{const{normalize:r}=n;return r(["データはリアルタイムではないため、数分遅れる場合があります。"])},usage_reason:n=>{const{normalize:r}=n;return r(["説明する"])},usage_reason_consume:n=>{const{normalize:r}=n;return r(["使用済み"])},usage_reason_purchase:n=>{const{normalize:r}=n;return r(["買った"])},usage_reason_trial:n=>{const{normalize:r}=n;return r(["使用"])},usage_rerank:n=>{const{normalize:r}=n;return r(["使用法"])},usage_time:n=>{const{normalize:r}=n;return r(["時間日付"])},v3_description:n=>{const{normalize:r}=n;return r(["<code>jina-embeddings-v3</code> は、5 億 7,000 万個のパラメータと 8,192 個のトークン長を備えた最先端の多言語テキスト ベクトル モデルで、MTEB 上の OpenAI および Cohere の最新の独自ベクトル モデルを上回ります。以下のブログ投稿と研究論文をお読みください。"])},v3_title:n=>{const{normalize:r}=n;return r(["v3: 最上位の多言語ベクトル モデル"])},vector_database_integration1:n=>{const{normalize:r}=n;return r(["統合された"])},vector_database_integration2:n=>{const{normalize:r}=n;return r(["当社のベクター モデル API は、一般的なデータベース、ベクター データベース、RAG および LLMOps フレームワークで簡単に使用できます。開始するには、API キーを以下の統合のいずれかにコピーするだけで、モデルをすぐに使用できます。"])},vector_database_integration3:n=>{const{normalize:r}=n;return r(["当社の Embedding & Reranker API は、さまざまなよく知られたデータベース、ベクター ストア、RAG および LLMOps フレームワークとネイティブに統合します。まず、API キーをコピーして、リストされている統合のいずれかに貼り付けるだけで、迅速かつシームレスに開始できます。"])},vector_database_integration_description:n=>{const{normalize:r}=n;return r(["Jina Embeddings API を次のベクター データベース、LLM オーケストレーション フレームワーク、RAG アプリケーションのいずれかとシームレスかつ簡単に統合します。私たちのチュートリアルでその方法を説明します。"])},view_details:n=>{const{normalize:r}=n;return r(["詳細を確認する"])},visualization_example:n=>{const{normalize:r}=n;return r(["このセクションのすべての文を 3D ベクトル空間にマッピングします"])},visualization_example_you_can:n=>{const{normalize:r}=n;return r(["以下の API を使用すれば、あなたもそれを行うことができます。"])},visualize:n=>{const{normalize:r}=n;return r(["視覚化"])},visualize_done:n=>{const{normalize:r}=n;return r(["ビジュアライゼーションが完了したので、上部のボタンをクリックしてビジュアライザを開くことができます。"])},wait_for_processing:n=>{const{normalize:r}=n;return r(["リクエストは処理中です。"])},wait_stripe:n=>{const{normalize:r}=n;return r(["Stripe 支払いを開始します。お待ちください。"])},what_are_embedding:n=>{const{normalize:r}=n;return r(["ベクトル化とは何ですか?"])},what_are_embedding_answer:n=>{const{normalize:r}=n;return r([`コンピューターに単語やフレーズの微妙な意味を教えることを想像してみてください。従来のアプローチは、厳密なルールベースのシステムに依存していますが、言語が複雑かつ流動的であるため、望ましい結果を達成できません。入力テキストの埋め込み: テキストを数値言語、特に高次元空間のベクトルに変換するための強力なソリューションです。

「晴天」と「快晴」というフレーズを考えてみましょう。私たちにとって、彼らは同じような絵を描いています。埋め込みパースペクティブを通じて、これらのフレーズは、この多次元空間で互いに近い数値ベクトルに変換され、意味上の類似性が捕捉されます。ベクトル空間におけるこの近接性は、単に単語やフレーズの類似性を意味するものではなく、文脈、感情、さらには意味のニュアンスを理解することにも関係します。

この画期的な進歩がなぜ重要なのでしょうか?まず、人間の言語の豊かさとアルゴリズムの計算効率の間のギャップを埋めます。アルゴリズムはテキストの解釈ではなく、数値の処理に適しています。テキストをベクトルに変換することにより、埋め込みにより、これらのアルゴリズムは以前は不可能だった方法で言語を「理解」し、処理できるようになります。

実際の応用例は多岐にわたります。自分の興味に合ったコンテンツを推奨する場合でも、人間味あふれる会話型 AI を強化する場合でも、さらには大量のテキスト内の微妙なパターンを検出する場合でも、埋め込みが鍵となります。これらにより、機械は感情分析、言語翻訳、そしてますます微妙で洗練された言語理解などのタスクを実行できるようになります。`])},what_is_a_token:n=>{const{normalize:r}=n;return r(["テキスト処理におけるトークンは単位であり、通常は単語です。たとえば、「Jina AI はすごいです!」は句読点を含めて 5 つのトークンになります。"])},why_do_you_need:n=>{const{normalize:r}=n;return r(["最適なベクトル モデルを選択する"])},why_do_you_need_after:n=>{const{normalize:r}=n;return r(["深層学習と高度な言語処理テクノロジーを通じて、当社のベクトル モデルは、複雑なマルチモーダル データを簡素化された形式に変換できます。これにより、機械の理解が向上するだけでなく、以下を含むより複雑な AI アプリケーションを実装する可能性も提供されます。データ解析機能の向上、ユーザー対話の増加、言語の壁の排除、開発プロセスの改善などです。"])},why_do_you_need_before:n=>{const{normalize:r}=n;return r(["当社の埋め込みモデルは、さまざまな検索および GenAI アプリケーションをカバーするように設計されています。"])},why_need_1_description:n=>{const{normalize:r}=n;return r(["私たちは、JinaBERT によって作成されたベクトル ベース モデルを利用して、さまざまなシナリオに合わせて設計します。長いテキストの解析に優れており、意味検索、内容分類、深い言語分析などのタスクに適しています。この多用途性により、センチメント分析ツール、テキスト要約、およびパーソナライズされた推奨システムの開発に最適です。"])},why_need_1_title:n=>{const{normalize:r}=n;return r(["普遍的なベクトル"])},why_need_2_description:n=>{const{normalize:r}=n;return r(["当社のバイリンガル モデルは、言語の壁を取り除き、コミュニケーション効率、グローバルな顧客サポート、多言語プラットフォーム全体での言語を超えたコンテンツの発見を向上させるように設計されています。ドイツ語-英語、中国語-英語の双方向翻訳に重点を置いており、異なる言語のユーザーがより簡単に理解してコミュニケーションをとることができます。"])},why_need_2_title:n=>{const{normalize:r}=n;return r(["バイリンガルベクトル"])},why_need_3_description:n=>{const{normalize:r}=n;return r(["コードの要約、コード生成、自動コード レビューなどのタスクを簡素化するために開発者向けに特別に設計されたコード ベクトル モデル。コード構造を徹底的に分析し、改善提案を提供することにより、開発効率が大幅に向上します。これは、高度な IDE プラグイン、自動生成ドキュメント、革新的なデバッグ ツールを開発するための鍵となります。"])},why_need_3_title:n=>{const{normalize:r}=n;return r(["コードベクトル"])},why_need_4_description:n=>{const{normalize:r}=n;return r(["Jina CLIP は、画像とテキストの最新のマルチモーダル埋め込みモデルです。 OpenAI CLIP に対する大きな改善点は、この 1 つのモデルがテキストからテキストの検索だけでなく、テキストから画像、画像からテキスト、画像から画像の検索タスクにも使用できることです。したがって、1 つのモデル、2 つのモード、4 つの検索方向になります。"])},why_need_4_title:n=>{const{normalize:r}=n;return r(["マルチモーダル埋め込み"])},write_email_here:n=>{const{normalize:r}=n;return r(["完了時にダウンロードリンクを受け取りたい電子メールを入力してください。"])},you_can_leave:n=>{const{normalize:r}=n;return r(["このページから離れても構いません。完了したら、ダウンロード リンクを送信します。"])}},embeddings:{description:n=>{const{normalize:r}=n;return r(["世界クラスのマルチモーダル、多言語埋め込み。"])}},faq:{answer1:n=>{const{normalize:r}=n;return r(["Jina AI は、大規模なモデル ベクトルの調整と展開、プロンプト ワードの調整と展開など、マルチモーダル AI テクノロジーに焦点を当てています。当社は、Kubernetes やサーバーレス アーキテクチャなどの高度なツールを活用して、強力でスケーラブルで実稼働対応のソリューションを作成します。"])},answer10:n=>{const{normalize:r}=n;return r(["プロジェクトの性質とクライアントのニーズに応じて、さまざまなライセンス オプションを提供します。詳細な条件については、当社の営業チームにご相談ください。"])},answer11:n=>{const{normalize:r}=n;return r(["当社はヨーロッパのベルリンに本社を置き、北京と深センにオフィスを構え、世界中でサービスを提供しています。"])},answer12:n=>{const{normalize:r}=n;return r(["はい、特にベルリン、北京、深センのオフィス近くにお住まいのお客様にオンサイト サポートを提供しています。他の拠点については、可能な限り最高のリモート サポートを提供するよう努め、必要に応じてオンサイト サポートを手配します。"])},answer2:n=>{const{normalize:r}=n;return r(["当社の専門知識は、大規模な言語モデル、テキスト、画像、ビデオ、音声理解、ニューラル検索、生成 AI など、幅広い分野に及びます。"])},answer3:n=>{const{normalize:r}=n;return r(["はい、当社のソリューションはスケーラブルで実稼働対応できるように設計されています。当社はクラウドネイティブ テクノロジーを使用してソリューションを構築し、実稼働環境で効率的なスケーリングと信頼性の高いパフォーマンスを実現します。"])},answer4:n=>{const{normalize:r}=n;return r(["当社のサービスは多用途で、電子商取引、リーガルテック、デジタルマーケティング、ゲーム、ヘルスケア、金融など、さまざまな業界に適応できます。"])},answer5:n=>{const{normalize:r}=n;return r(["このページのお問い合わせフォームから当社の営業チームにご連絡いただけます。お客様のプロジェクトのニーズや、当社のソリューションがお客様のビジネスにどのように役立つかについて喜んでご相談させていただきます。"])},answer6:n=>{const{normalize:r}=n;return r(["当社は、ソリューションがスムーズに実行されるように継続的なサポートを提供します。これには、トラブルシューティング、定期的な更新、フィードバックやニーズに基づく改善が含まれます。"])},answer7:n=>{const{normalize:r}=n;return r(["プロジェクトの期間は、プロジェクトの複雑さと範囲によって異なります。お客様のご要望を理解できましたら、より正確なお見積りをご提供させていただきます。"])},answer8:n=>{const{normalize:r}=n;return r(["データのセキュリティは当社の最優先事項です。当社は、お客様のデータの安全性と機密性を確保するために、厳格なデータ保護ポリシーと規制を遵守しています。"])},answer9:n=>{const{normalize:r}=n;return r(["価格はプロジェクトの複雑さと要件によって異なります。当社では、プロジェクトベースの価格モデルと維持価格モデルを提供しています。詳細については、当社の営業チームにお問い合わせください。"])},question1:n=>{const{normalize:r}=n;return r(["ジナAIは何が得意ですか?"])},question10:n=>{const{normalize:r}=n;return r(["ソリューションのライセンス条件は何ですか?"])},question11:n=>{const{normalize:r}=n;return r(["サービスエリアはどこですか?"])},question12:n=>{const{normalize:r}=n;return r(["オンサイトサポートはありますか?"])},question2:n=>{const{normalize:r}=n;return r(["Jina AI はどのような種類の人工知能に適していますか?"])},question3:n=>{const{normalize:r}=n;return r(["あなたのソリューションはスケーラブルで、実稼働の準備ができていますか?"])},question4:n=>{const{normalize:r}=n;return r(["Jina AI のソリューションから恩恵を受けるのはどの業界ですか?"])},question5:n=>{const{normalize:r}=n;return r(["Jina AI を使用してプロジェクトを開始するにはどうすればよいですか?"])},question6:n=>{const{normalize:r}=n;return r(["ソリューション導入後はどのようなサポートを提供しますか?"])},question7:n=>{const{normalize:r}=n;return r(["プロジェクトの通常の期間はどれくらいですか?"])},question8:n=>{const{normalize:r}=n;return r(["Jina AI は私のデータをどのように保護しますか?"])},question9:n=>{const{normalize:r}=n;return r(["サービスの料金体系は何ですか?"])}},faq_button:n=>{const{normalize:r}=n;return r(["よくある質問"])},farewell:{text:n=>{const{normalize:r}=n;return r(["別れを告げる。"])}},finetuner:{description:n=>{const{normalize:r}=n;return r(["検索品質を向上させるためにドメイン固有のデータに合わせて大規模なモデル ベクトルを調整する"])},intro:n=>{const{normalize:r}=n;return r(["あなたの会社、データ、モデル"])}},finetuner_plus:{description:n=>{const{normalize:r}=n;return r(["ビジネス向けのローカルチューニングソリューション"])}},finetuning:{api_key:n=>{const{normalize:r}=n;return r(["API キーを入力します。"])},back:n=>{const{normalize:r}=n;return r(["戻る"])},base_model_selected:n=>{const{normalize:r}=n;return r(["ベースモデルを選択してください"])},click_start:n=>{const{normalize:r}=n;return r(["規約に同意して微調整を開始します。"])},confirm_title:n=>{const{normalize:r}=n;return r(["微調整作業の確認"])},confirm_your_email:n=>{const{normalize:r}=n;return r(["電子メール アドレスを再入力して、調整が機能していることを確認します。アップデートとダウンロード リンクはこのメールに送信されます。"])},consent0:n=>{const{normalize:r}=n;return r(["私の指示に従って、モデル微調整用の合成データを生成することに同意します。"])},consent1:n=>{const{normalize:r}=n;return r(["最終モデルと合成データはHugging Faceで公開されることを了承します。"])},consent2:n=>{const{normalize:r}=n;return r(["この機能はベータ版であり、Jina AI はいかなる保証もしないことを理解しています。価格とユーザーエクスペリエンスは変更される場合があります。"])},continue:n=>{const{normalize:r}=n;return r(["続く"])},cost_1m_token:n=>{const{normalize:r}=n;return r(["各微調整ジョブは 100 万トークンを消費します。十分なトークンがあることを確認するか、リチャージしてください。新しい API キーを生成することもできます。各 API キーには 100 万の無料トークンが付属しています。"])},doc_explain:n=>{const{normalize:r}=n;return r(["一致するドキュメントがどのように見えるべきかを説明します。"])},domain_explain:n=>{const{normalize:r}=n;return r(["微調整されたベクトル モデルの使用方法の詳細な説明。これは、ベクトル モデルのパフォーマンスを向上させる高品質の合成データを生成するために重要です。"])},domain_explain2:n=>{const{normalize:r}=n;return r(["要件を指定するには、一般的な説明、URL、またはクエリ ドキュメントの説明の 3 つの方法があります。一つ選んでください。"])},domain_hint:n=>{const{normalize:r}=n;return r(["微調整したいドメインを説明します。"])},email_not_match:n=>{const{normalize:r}=n;return r(["メールアドレスが一致しません。確認してください。"])},failed_job:n=>{const{normalize:r}=n;return r(["微調整リクエストが失敗しました。その理由を以下でご覧ください。"])},find_on_huggingface:n=>{const{normalize:r}=n;return r(["ハグフェイスに関する検索結果"])},general_instruction:n=>{const{normalize:r}=n;return r(["または、一般的な指示"])},general_instruction_caption:n=>{const{normalize:r}=n;return r(["トリム ベクトルの使用方法について詳しく説明します。"])},general_instruction_explain:n=>{const{normalize:r}=n;return r(["ドメイン名を自由形式のテキストで説明します。 ChatGPT の「プロンプト」のようなものと考えることができます。"])},how_it_works:n=>{const{normalize:r}=n;return r(["微調整プロセスを理解します。"])},job_acknowledged:n=>{const{normalize:r}=n;return r(["微調整ジョブはキューに入れられています。課題が開始されるとメールが届きます。通常、プロセス全体が完了するまでに 20 分かかります。"])},new_key:n=>{const{normalize:r}=n;return r(["新しいキーを取得する"])},not_enough_token:n=>{const{normalize:r}=n;return r(["この API キーには十分なトークンがありません。追加するか、別の API キーを使用してください。"])},placeholder:n=>{const{normalize:r}=n;return r(["自動車保険の請求"])},preview:n=>{const{normalize:r}=n;return r(["プレビュー"])},query_doc:n=>{const{normalize:r}=n;return r(["クエリ文書の説明"])},query_doc_caption:n=>{const{normalize:r}=n;return r(["クエリがどのようなものであるか、およびドメイン内で一致するドキュメントがどのようなものであるかを説明します。"])},query_explain:n=>{const{normalize:r}=n;return r(["クエリがどのようなものかを説明します。"])},reset:n=>{const{normalize:r}=n;return r(["また"])},select_base_model:n=>{const{normalize:r}=n;return r(["微調整する基底ベクトル モデルを選択します。"])},select_base_model_explain:n=>{const{normalize:r}=n;return r(["微調整の開始点としてベース モデルを選択します。一般に、base-en が適切な選択ですが、他の言語でのタスクの場合は、バイリンガル モデルの使用を検討してください。"])},start_tuning:n=>{const{normalize:r}=n;return r(["微調整を開始する"])},url:n=>{const{normalize:r}=n;return r(["または、Web ページの URL"])},url_caption:n=>{const{normalize:r}=n;return r(["微調整については、URL の内容を参照してください。"])},url_explain:n=>{const{normalize:r}=n;return r(["微調整するコンテンツを含むページのパブリック URL。"])},use_url:n=>{const{normalize:r}=n;return r(["代わりに URL を使用してください。このオプションを有効にすると、微調整のためにこの URL のページ コンテンツに基づいて合成データが生成されます。"])},wait_for_processing:n=>{const{normalize:r}=n;return r(["リクエストを処理するまでお待ちください..."])},which_domain:n=>{const{normalize:r}=n;return r(["ドメインの微調整"])},write_email_explain:n=>{const{normalize:r}=n;return r(["微調整には時間がかかります。微調整作業の開始、進行状況、完了、問題点、および微調整されたモデルとトレーニング データセットの詳細を電子メールでお知らせします。"])}},footer:{address_beijing:n=>{const{normalize:r}=n;return r(["中国、北京"])},address_berlin:n=>{const{normalize:r}=n;return r(["ドイツ、ベルリン（本社）"])},address_shenzhen:n=>{const{normalize:r}=n;return r(["深セン、中国"])},all_rights_reserved:n=>{const{normalize:r}=n;return r(["無断転載を禁じます"])},company:n=>{const{normalize:r}=n;return r(["会社"])},developers:n=>{const{normalize:r}=n;return r(["開発者向け"])},docs:n=>{const{normalize:r}=n;return r(["書類"])},enterprise:n=>{const{normalize:r}=n;return r(["ビジネスのための"])},get_api_key:n=>{const{normalize:r}=n;return r(["Jina AI API キーを取得する"])},offices:n=>{const{normalize:r}=n;return r(["オフィス"])},power_users:n=>{const{normalize:r}=n;return r(["上級ユーザー向け"])},privacy:n=>{const{normalize:r}=n;return r(["プライバシー"])},privacy_policy:n=>{const{normalize:r}=n;return r(["プライバシーポリシー"])},privacy_settings:n=>{const{normalize:r}=n;return r(["Cookieを管理する"])},security:n=>{const{normalize:r}=n;return r(["安全性"])},sefo:n=>{const{normalize:r}=n;return r(["検索ベース"])},soc2:n=>{const{normalize:r}=n;return r(["当社は米国公認会計士協会 (AICPA) の SOC 2 Type 1 に準拠しています。"])},status:n=>{const{normalize:r}=n;return r(["APIステータス"])},status_short:n=>{const{normalize:r}=n;return r(["サービス状況"])},tc:n=>{const{normalize:r}=n;return r(["利用規約"])},tc1:n=>{const{normalize:r}=n;return r(["条項"])}},get_new_key:n=>{const{normalize:r}=n;return r(["APIキーを取得する"])},github:{stars:n=>{const{normalize:r}=n;return r(["出演者"])}},header:{about_us:n=>{const{normalize:r}=n;return r(["私たちについて"])},company:n=>{const{normalize:r}=n;return r(["会社"])},contact_us:n=>{const{normalize:r}=n;return r(["営業担当者に問い合わせる"])},developers_others:n=>{const{normalize:r}=n;return r(["その他の開発者ツール"])},enterprise_others:n=>{const{normalize:r}=n;return r(["その他のエンタープライズ ツール"])},for_developers:n=>{const{normalize:r}=n;return r(["開発者に力を与える"])},for_developers_description:n=>{const{normalize:r}=n;return r(["開発者向けに特別に構築されたマルチモーダルなオープンソース テクノロジー スタック。"])},for_enterprise:n=>{const{normalize:r}=n;return r(["ビジネスに力を与える"])},for_enterprise_description:n=>{const{normalize:r}=n;return r(["企業向けにカスタマイズされたマルチモーダル ソリューションを検討してください。"])},for_power_users:n=>{const{normalize:r}=n;return r(["パワーユーザーに権限を与える"])},for_power_users_description:n=>{const{normalize:r}=n;return r(["マルチモーダル ツールを使用して、日々の生産性を向上させます。"])},internship1:n=>{const{normalize:r}=n;return r(["インターンプログラム"])},jobs:n=>{const{normalize:r}=n;return r(["参加しませんか"])},join_discord:n=>{const{normalize:r}=n;return r(["Discord コミュニティに参加してください"])},logos:n=>{const{normalize:r}=n;return r(["ロゴをダウンロード"])},maximize:n=>{const{normalize:r}=n;return r(["⇧1"])},maximize_btn:n=>{const{normalize:r}=n;return r(["最大化する"])},news:n=>{const{normalize:r}=n;return r(["ニュース"])},open_day:n=>{const{normalize:r}=n;return r(["オープンデー"])},open_in_full:n=>{const{normalize:r}=n;return r(["すべてのエンタープライズ製品を新しいウィンドウで表示する"])},power_users_others:n=>{const{normalize:r}=n;return r(["より高度なユーザー ツール"])},products:n=>{const{normalize:r}=n;return r(["製品"])}},hub:{description:n=>{const{normalize:r}=n;return r(["マルチモーダル AI アプリケーションの構成要素を共有および発見する"])}},huggingface:{sentence_similarity:n=>{const{normalize:r}=n;return r(["文ベクトルモデル"])},updated_about:n=>{const{normalize:r}=n;return r(["について更新されました"])}},impact_snapshots:{project1:n=>{const{normalize:r}=n;return r(["点群情報を利用し、3Dメッシュデータの高精度検索を実現します。"])},project10:n=>{const{normalize:r}=n;return r(["コンピューター ビジョンを使用して政府 Web サイトのデジタル アクセシビリティを向上させます。"])},project11:n=>{const{normalize:r}=n;return r(["コンサルティング会社の財務データ分析を最適化するために大規模な言語モデルを調整します。"])},project12:n=>{const{normalize:r}=n;return r(["スタイル転送用にテキストから画像へのモデルを調整することで、高度なマーケティング戦略を実現します。"])},project2:n=>{const{normalize:r}=n;return r(["短編アニメーション映画向けのコンテンツベースの検索エンジンを設計しました。"])},project3:n=>{const{normalize:r}=n;return r(["ベクトル モデルを調整することで、電子商取引のコンバージョン率を向上させます。"])},project4:n=>{const{normalize:r}=n;return r(["ビジネス コンサルティング会社の効率を向上させるためにタイムリーな調整を行います。"])},project5:n=>{const{normalize:r}=n;return r(["大手ゲーム会社向けの先駆的なゲームシーンの理解と自動アノテーション。"])},project6:n=>{const{normalize:r}=n;return r(["ユーザー エクスペリエンスを向上させるために、チャットボット会社向けにリアルタイム入力拡張機能を実装しました。"])},project7:n=>{const{normalize:r}=n;return r(["長い法的文書内での効率的な検索を可能にする。"])},project8:n=>{const{normalize:r}=n;return r(["大規模な運用をサポートする高スループットのジェネレーティブ アート サービス。"])},project9:n=>{const{normalize:r}=n;return r(["高級言語モデルを使用したプロセスマイニングとモデリング。"])}},inference:{description:n=>{const{normalize:r}=n;return r(["最先端のマルチモーダル推論モデル"])}},integrations:{embedding:n=>{const{normalize:r}=n;return r(["ベクトルモデル"])},reranker:n=>{const{normalize:r}=n;return r(["並べ替え者"])},which_to_go:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_vendor"))," と統合できるのはどれですか?"])}},internship_faq:{answer1:n=>{const{normalize:r}=n;return r(["学部、修士、博士 研究、エンジニアリング、マーケティング、販売などの分野に興味のある世界中の学生の応募を奨励します。また、マーケティング、販売、事務アシスタントなどの分野での非技術的なインターンシップの機会も歓迎します。私たちは、マルチモーダル AI を一緒に開拓する意欲のある情熱的な人材を探しています。"])},answer10:n=>{const{normalize:r}=n;return r(["はい、当社のインターンシップ プログラムは競争力のある給与を提供します。"])},answer11:n=>{const{normalize:r}=n;return r(["Jina AI インターンとして、挑戦的なプロジェクトに取り組む実践的な経験を積み、業界の専門家から学び、活気に満ちたコミュニティの一員となり、マルチモーダル AI における画期的な取り組みに真の貢献をする機会を得ることができます。"])},answer2:n=>{const{normalize:r}=n;return r(["インターンシップは、ベルリン、北京、深センにある当社のオフィスのいずれかで現地で行う必要があります。"])},answer3:n=>{const{normalize:r}=n;return r(["はい、Jina AI はビザの手続きにおいて合格した申請者に適切な支援を提供します。"])},answer4:n=>{const{normalize:r}=n;return r(["はい、Jina AI はインターンシップ中に妥当な生活費をインターン生に提供します。"])},answer5:n=>{const{normalize:r}=n;return r(["はい、Jina AI でのインターンシップ中に修士論文を完成させることができます。このインターンシップはドイツの大学の学生が一般的に利用できます。ただし、大学の指導教員に事前に連絡し、同意を得る必要があります。私たちは学生がアドバイザーを見つけるお手伝いはしませんのでご了承ください。"])},answer6:n=>{const{normalize:r}=n;return r(["応募プロセスには、応募フォーム、履歴書、興味や動機を表明するカバーレター、および GitHub や LinkedIn などの関連する専門リンクの提出が含まれます。私たちは候補者を面接での成績と大学での成績に基づいて評価します。"])},answer7:n=>{const{normalize:r}=n;return r(["はい、成功したインターンは、インターンシップ終了時に CEO が署名した推薦状を受け取ることができます。"])},answer8:n=>{const{normalize:r}=n;return r(["インターンシップの期間は、役割やプロジェクトによって異なります。ただし、通常は 3 ～ 6 か月かかります。"])},answer9:n=>{const{normalize:r}=n;return r(["はい、あらゆる学歴からのご応募を歓迎いたします。私たちは、これまでの経験と同様に、学習に対するあなたの情熱と取り組みを尊重します。"])},question1:n=>{const{normalize:r}=n;return r(["Jina AI インターンシップ プログラムには誰が応募できますか?"])},question10:n=>{const{normalize:r}=n;return r(["これは有給のインターンシップですか？"])},question11:n=>{const{normalize:r}=n;return r(["Jina AI インターンとしてどのような機会がありますか?"])},question2:n=>{const{normalize:r}=n;return r(["インターンシップはどこで行われますか?"])},question3:n=>{const{normalize:r}=n;return r(["Jina AI はビザ手続きをサポートしますか?"])},question4:n=>{const{normalize:r}=n;return r(["Jina AI はインターンに特典や福利厚生を提供していますか?"])},question5:n=>{const{normalize:r}=n;return r(["Jina AIでのインターンシップ中に修士論文を書くことはできますか?"])},question6:n=>{const{normalize:r}=n;return r(["申請プロセスには何が関係しますか?"])},question7:n=>{const{normalize:r}=n;return r(["Jina AI インターンシップ後に推薦状はありますか?"])},question8:n=>{const{normalize:r}=n;return r(["インターンシップの期間はどれくらいですか？"])},question9:n=>{const{normalize:r}=n;return r(["人工知能の経験がなくても応募できますか?"])}},internship_page:{about_internship_program:n=>{const{normalize:r}=n;return r(["インターンシッププログラムについて"])},about_internship_program_desc1:n=>{const{normalize:r}=n;return r(["私たちは、才能ある人材に当社のダイナミックなチームに参加し、人工知能分野の画期的なプロジェクトに貢献するこのユニークな機会を提供できることを嬉しく思います。このインターンシップは、貴重な実践的な経験、指導、人工知能の未来を形作る最先端のテクノロジーに触れることを目的に設計されています。"])},about_internship_program_desc2:n=>{const{normalize:r}=n;return r(["Jina AI では、若い才能を育成し、活用することの重要性を理解しています。私たちは、インターンが新しい視点、熱意、創造性をもたらし、新しいアイデアやアプローチで私たちのチームにインスピレーションを与えることを認識しています。インターンシップの機会を提供することで、私たちは AI 業界の将来のリーダーの成長を促進し、支援的でやりがいのある環境で実際の経験を提供することを目指しています。"])},alumni:n=>{const{normalize:r}=n;return r(["卒業生"])},alumni_network:n=>{const{normalize:r}=n;return r(["活発な同窓生ネットワーク"])},application:n=>{const{normalize:r}=n;return r(["応用"])},application_desc:n=>{const{normalize:r}=n;return r(["Jina AI とともに変革の旅に乗り出しましょう。当社の包括的なインターンシップ プログラムには、人工知能の未来を形作ることを熱望するすべての情熱的な従業員が招待されます。私たちに参加して、現実世界での経験を積み、挑戦的なプロジェクトに取り組み、AI 業界で最も優秀な人材と一緒に働きましょう。"])},apply:n=>{const{normalize:r}=n;return r(["今すぐお申し込みください"])},autumn:n=>{const{normalize:r}=n;return r(["秋"])},description:n=>{const{normalize:r}=n;return r(["世界中で学生を募集しています: 研究、エンジニアリング、マーケティング、セールスなどのインターンシップ。"])},dev_rel_intern:n=>{const{normalize:r}=n;return r(["開発者関係インターン"])},enthusiastic:n=>{const{normalize:r}=n;return r(["情熱的"])},explore_stories_from_our_interns:n=>{const{normalize:r}=n;return r(["インターン生のストーリーをご覧ください"])},explore_stories_from_our_interns1:n=>{const{normalize:r}=n;return r(["インターンたちの旅からインスピレーションを得てください"])},innovative:n=>{const{normalize:r}=n;return r(["革新的な"])},intern_work1:n=>{const{normalize:r}=n;return r(["LLM モデルを微調整してより良い文ベクトル モデルを実現する"])},intern_work2:n=>{const{normalize:r}=n;return r(["検索拡張生成 (RAG) アルゴリズムの可能性を探る"])},intern_work3:n=>{const{normalize:r}=n;return r(["文ベクトルに関する論文を発表しました"])},intern_work4:n=>{const{normalize:r}=n;return r(["若いエネルギーをチームに着実に注入する"])},intern_work5:n=>{const{normalize:r}=n;return r(["圧縮 LLM のベンチマーク量子化手法"])},intern_work6:n=>{const{normalize:r}=n;return r(["PromptPerfect の魅力的なキャンペーンを作成して宣伝する"])},intern_work7:n=>{const{normalize:r}=n;return r(["JinaColBERT V2 を迅速に開発および改善する"])},recruiting_and_administrative_intern:n=>{const{normalize:r}=n;return r(["採用および管理インターン"])},researcher_intern:n=>{const{normalize:r}=n;return r(["インターン研究員"])},self_motivated:n=>{const{normalize:r}=n;return r(["セルフモチベーション"])},software_engineer_intern:n=>{const{normalize:r}=n;return r(["ソフトウェアエンジニアインターン"])},spring:n=>{const{normalize:r}=n;return r(["春"])},submit_application:n=>{const{normalize:r}=n;return r(["Jina AI で冒険を始めましょう"])},subtitle:n=>{const{normalize:r}=n;return r(["当社のフルタイム インターンシップ プログラムでは、慎重に設計された幅広いインターンシップ プロジェクトを通じて実践的な就業体験を提供します。"])},subtitle1:n=>{const{normalize:r}=n;return r(["研究、エンジニアリング、マーケティング、営業などの分野のインターンを世界中から募集し、マルチモーダル AI を共同で作成します。"])},summer:n=>{const{normalize:r}=n;return r(["夏"])},title:n=>{const{normalize:r}=n;return r(["インターンプログラム"])},who_do_we_look_for:n=>{const{normalize:r}=n;return r(["私たちが探しているのは誰ですか?"])},who_do_we_look_for_desc:n=>{const{normalize:r}=n;return r(["私たちは多様性を重視しており、あらゆる背景や経歴の応募者がインターンシップ プログラムに参加することを奨励しています。インターンシップの機会は、エンジニアリング、設計、製品管理、販売およびアカウント管理、マーケティング、コミュニティ管理など、複数の部門にわたって利用できます。"])},winter:n=>{const{normalize:r}=n;return r(["冬"])}},jcloud:{description:n=>{const{normalize:r}=n;return r(["ローカル プロジェクトをクラウド サービスとしてデプロイします。非常にシンプルで、不快な驚きはありません。"])}},jerboa:{description:n=>{const{normalize:r}=n;return r(["LLM 用のオープンソース実験チューナー"])}},jina:{description:n=>{const{normalize:r}=n;return r(["クラウドでマルチモーダル AI アプリケーションを構築する"])}},jina_chat:{description:n=>{const{normalize:r}=n;return r(["より多くのモード、より長いメモリ、より低いコスト"])},example_1:n=>{const{normalize:r}=n;return r(["あなたは誰ですか？"])},example_2:n=>{const{normalize:r}=n;return r(["私はJina AIが作ったLLMチャットサービスです"])}},lab_dialog:{GlobalQA:{description:n=>{const{normalize:r}=n;return r(["任意のページで「/」キーを押して質問を開きます。クエリを入力して「Enter」を押すと、ページのコンテンツに関連する回答が表示されます。この機能は PromptPerfect によって強化されています。"])},title:n=>{const{normalize:r}=n;return r(["ページラグ"])}},Recommender:{description:n=>{const{normalize:r}=n;return r(["ニュース ページでおすすめボックスを開くには、「Shift+2」を使用します。このニュース ページに関連する上位 5 つの記事を見つけるには、再ランク付けモデルを選択します。この機能は、Reranker API によってリアルタイムで利用されます。"])},title:n=>{const{normalize:r}=n;return r(["関連記事"])}},SceneXplainTooltip:{description:n=>{const{normalize:r}=n;return r(["ニュース ページまたはニュースルーム ディレクトリ内の画像の上にマウスを置くと、その画像の説明が表示されます。説明は SceneXplain によって事前に計算され、画像の ALT 属性で量子化されます。"])},title:n=>{const{normalize:r}=n;return r(["画像の注釈"])}},explain:n=>{const{normalize:r}=n;return r(["私たちのウェブサイトの隠れた機能を探索してください"])}},landing_page:{also_available_on:n=>{const{normalize:r}=n;return r(["App Marketでも入手可能"])},also_available_on1:n=>{const{normalize:r}=n;return r(["アプリケーション マーケットを通じてワンクリックでエンタープライズ クラウドに導入できます。"])},ask_how_your_question:n=>{const{normalize:r}=n;return r(["問題について説明してください"])},autotune:n=>{const{normalize:r}=n;return r(["セルフチューニング"])},badge:{v2:n=>{const{normalize:r}=n;return r(["第二弾が発売されました！"])},v3:n=>{const{normalize:r}=n;return r(["v3がリリースされました！"])}},build_js:n=>{const{normalize:r}=n;return r(["JavaScriptを使用して開発"])},build_python:n=>{const{normalize:r}=n;return r(["Pythonを使用して開発"])},ccbync:n=>{const{normalize:r}=n;return r(["このモデルは CC BY-NC 4.0 に基づいてライセンスされています。 API または公式 AWS/Azure イメージを介して使用するか、オンプレミス展開については営業にお問い合わせください。"])},checkout_our_solution_for_you:n=>{const{normalize:r}=n;return r(["お客様に合わせた当社のソリューションについてご覧ください"])},classifier:n=>{const{normalize:r}=n;return r(["分類子"])},coming_soon:n=>{const{normalize:r}=n;return r(["乞うご期待"])},contact_sales:n=>{const{normalize:r}=n;return r(["お問い合わせ"])},copied_to_clipboard:n=>{const{normalize:r}=n;return r(["クリップボードにコピーされました"])},copy:n=>{const{normalize:r}=n;return r(["コピー"])},developers:n=>{const{normalize:r}=n;return r(["開発者"])},developers_desc:n=>{const{normalize:r}=n;return r(["最先端のクラウドネイティブ テクノロジーとオープンソース インフラストラクチャを使用して、マルチモーダル AI の能力を最大限に引き出します。"])},download_pdf:n=>{const{normalize:r}=n;return r(["PDFをダウンロード"])},embedding:n=>{const{normalize:r}=n;return r(["埋め込む"])},embedding_desc1:n=>{const{normalize:r}=n;return r(["検索、RAG、エージェント アプリケーション向けの最先端のマルチモーダルな多言語ロング コンテキスト ベクトル モデル。"])},embedding_paper_desc:n=>{const{normalize:r}=n;return r(["Jina Embeddings は、さまざまなテキスト入力を数値表現に変換することに優れた高性能テキスト ベクトル モデルのセットを構成し、それによってテキストの意味論的な本質を捉えます。これらのモデルはテキスト生成用に特別に設計されたものではありませんが、高密度検索や意味論的なテキストの類似性などのアプリケーションで良好に機能します。この記事では、高品質のペアごとおよびトリプレット データセットの作成から始まる、Jina Embeddings の開発について詳しく説明します。データセットの準備におけるデータ クリーニングの重要な役割を強調し、モデル トレーニング プロセスについての洞察を提供し、大規模テキスト ベクトル ベンチマーク (MTEB) を使用して包括的なパフォーマンス評価を実施します。"])},embedding_paper_title:n=>{const{normalize:r}=n;return r(["Jina Embeddings: 高性能テキスト ベクトル モデルの新しいセット"])},embeddings:n=>{const{normalize:r}=n;return r(["ベクトルモデル"])},enterprise:n=>{const{normalize:r}=n;return r(["企業"])},enterprise_desc:n=>{const{normalize:r}=n;return r(["スケーラブルで安全、カスタマイズ可能なマルチモーダル AI ソリューションでビジネスを強化します。"])},enterprise_desc_v2:n=>{const{normalize:r}=n;return r(["世界クラスのベクトル モデルを使用して、検索システムと RAG システムを改善します。まずは無料トライアルから始めましょう！"])},enterprise_desc_v3:n=>{const{normalize:r}=n;return r(["当社の最先端のモデルは、高品質のエンタープライズ検索および RAG システムの検索基盤を形成します。"])},error:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["問題が発生しました: ",e(o("message"))])},find_your_portal:n=>{const{normalize:r}=n;return r(["独自のポータルを探索する"])},finding_faq:n=>{const{normalize:r}=n;return r(["次の FAQ の知識に基づいて回答を生成します。"])},for:n=>{const{normalize:r}=n;return r(["のために"])},for_developers:n=>{const{normalize:r}=n;return r(["開発者向け"])},for_enterprise:n=>{const{normalize:r}=n;return r(["ビジネスのための"])},for_power_users:n=>{const{normalize:r}=n;return r(["上級ユーザー向け"])},get_api_now:n=>{const{normalize:r}=n;return r(["APIインターフェース"])},get_started:n=>{const{normalize:r}=n;return r(["使い始める"])},go_to_product_homepage:n=>{const{normalize:r}=n;return r(["製品ホームページへ"])},how_to:n=>{const{normalize:r}=n;return r(["どうやって"])},include_experiment:n=>{const{normalize:r}=n;return r(["ソリューション内の実験プロジェクトとアーカイブされたプロジェクトについて言及します。"])},join_community:n=>{const{normalize:r}=n;return r(["コミュニティ"])},learn_more_embeddings:n=>{const{normalize:r}=n;return r(["ベクトルモデルについて学ぶ"])},learn_more_reader:n=>{const{normalize:r}=n;return r(["読者について詳しく見る"])},learn_more_reranker:n=>{const{normalize:r}=n;return r(["再注文者について学ぶ"])},llm:n=>{const{normalize:r}=n;return r(["LLM ラージ モデル ベクトル モデル"])},llm_desc:n=>{const{normalize:r}=n;return r(["当社は、3,500 万から 60 億のパラメータを備えた高性能テキスト ベクトル モデル ファミリを提供します。これらは、ニューラル検索、並べ替え、文の類似性、推奨事項などを強化するのに最適です。 AI エクスペリエンスを向上させる準備をしましょう。"])},mentioned_products:n=>{const{normalize:r}=n;return r(["言及された製品:"])},mmstack:n=>{const{normalize:r}=n;return r(["マルチモーダル技術スタック"])},mmstack_desc:n=>{const{normalize:r}=n;return r(["私たちは長年にわたり、開発者がより優れた GenAI と検索アプリケーションをより迅速に構築できるようにするオープン ソース ソフトウェアを開発してきました。"])},models:n=>{const{normalize:r}=n;return r(["モデル"])},more:n=>{const{normalize:r}=n;return r(["もっと"])},multimodal:n=>{const{normalize:r}=n;return r(["マルチモーダル"])},multimodal_ai:n=>{const{normalize:r}=n;return r(["マルチモーダル AI"])},new:n=>{const{normalize:r}=n;return r(["新しい"])},newsroom:n=>{const{normalize:r}=n;return r(["ニュース"])},num_publications:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["合計 ",e(o("_total"))," 件の出版物。"])},"on-prem-deploy":n=>{const{normalize:r}=n;return r(["プライベート展開"])},"on-premises":n=>{const{normalize:r}=n;return r(["地元"])},opensource:n=>{const{normalize:r}=n;return r(["オープンソース"])},our_customer:n=>{const{normalize:r}=n;return r(["私たちの顧客"])},our_customer_explain:n=>{const{normalize:r}=n;return r(["企業の大小を問わず、Jina AI の検索インフラストラクチャ テクノロジーを信頼してツールや製品を構築しています。そして、あなたも私たちを信頼してください。"])},our_publications:n=>{const{normalize:r}=n;return r(["私たちの論文"])},parameters:n=>{const{normalize:r}=n;return r(["パラメータ"])},podcast:n=>{const{normalize:r}=n;return r(["ポッドキャスト"])},power_users:n=>{const{normalize:r}=n;return r(["VIP"])},power_users_desc:n=>{const{normalize:r}=n;return r(["自動ワードプロンプトプロジェクトにより、日々の作業効率が向上します。"])},powered_by_promptperfect:n=>{const{normalize:r}=n;return r(["PromptPerfect のプロンプトワード最適化および Prompts-as-a-Service 機能を活用"])},pricing:n=>{const{normalize:r}=n;return r(["価格表"])},proposing_solution:n=>{const{normalize:r}=n;return r(["Jina AI 製品ラインに基づいて考案されたソリューション..."])},read_more:n=>{const{normalize:r}=n;return r(["もっとニュース"])},reader:n=>{const{normalize:r}=n;return r(["読者"])},require_full_question:n=>{const{normalize:r}=n;return r(["問題をさらに詳しく説明してください。"])},reranker:n=>{const{normalize:r}=n;return r(["並べ替え者"])},researcher_desc:n=>{const{normalize:r}=n;return r(["最先端の検索モデルがゼロからトレーニングされる方法を学び、最新の出版物をチェックしてください。 EMNLP、SIGIR、ICLR、NeurIPS、ICML のチームをご紹介します。"])},researchers:n=>{const{normalize:r}=n;return r(["研究者"])},sdk:n=>{const{normalize:r}=n;return r(["ソフトウェア開発キット"])},sdk_desc:n=>{const{normalize:r}=n;return r(["PromptPerfect、SceneXplain、BestBanner、JinaChat、Rationale API を使用して高度な AIGC アプリケーションを構築したいですか?私たちはあなたのお手伝いをいたします！使いやすい SDK を試して、数分で使い始めてください。"])},sdk_docs:n=>{const{normalize:r}=n;return r(["ドキュメントを読む"])},sdk_example:n=>{const{normalize:r}=n;return r(["例"])},search_foundation:n=>{const{normalize:r}=n;return r(["検索ベース"])},source_code:n=>{const{normalize:r}=n;return r(["ソースコード"])},starter_kit:n=>{const{normalize:r}=n;return r(["新規パッケージ"])},supercharged1:n=>{const{normalize:r}=n;return r(["もう二度と同じことはありません！"])},tokenizer:n=>{const{normalize:r}=n;return r(["スライサー"])},trusted_by:n=>{const{normalize:r}=n;return r(["私たちは信頼できる"])},try_it_for_free:n=>{const{normalize:r}=n;return r(["今すぐ始めましょう - クレジット カードや登録は必要ありません。"])},try_our_saas:n=>{const{normalize:r}=n;return r(["OpenAI API を 1:1 で置き換える、マネージドのクラウドネイティブ推論ソリューションをお試しください。"])},your_portal_to:n=>{const{normalize:r}=n;return r(["ご招待します"])},your_search_foundation1:n=>{const{normalize:r}=n;return r(["あなたの検索ベース"])}},langchain_serve:{description:n=>{const{normalize:r}=n;return r(["Jina と FastAPI を使用して実稼働グレードの Langchain アプリケーションを作成する"])}},model_graph:{api:n=>{const{normalize:r}=n;return r(["ジナAI API"])},contact_sales_about_it:n=>{const{normalize:r}=n;return r(["詳細については営業担当者にお問い合わせください"])},deploy_it_on:n=>{const{normalize:r}=n;return r(["デプロイ先"])},description:n=>{const{normalize:r}=n;return r(["長年にわたり、私たちは検索の限界を押し広げ続けてきました。私たちがリリースしたモデルは次のとおりです。各モデルにカーソルを合わせるかクリックすると、詳細が表示されます。"])},find_on_hf:n=>{const{normalize:r}=n;return r(["HuggingFace で見つけてください"])},search_for:n=>{const{normalize:r}=n;return r(["私たちのサイトを検索"])},search_models:n=>{const{normalize:r}=n;return r(["モデル名でフィルタリングする"])},title:n=>{const{normalize:r}=n;return r(["検索ベースモデル"])},use_it_via:n=>{const{normalize:r}=n;return r(["を使用することで"])}},news_page:{back_to_newsroom:n=>{const{normalize:r}=n;return r(["ニュースホームページに戻る"])},categories:n=>{const{normalize:r}=n;return r(["カテゴリー"])},copy_link:n=>{const{normalize:r}=n;return r(["このセクションへのリンクをコピーします"])},in_this_article:n=>{const{normalize:r}=n;return r(["記事ナビゲーション"])},learn_more:n=>{const{normalize:r}=n;return r(["もっと詳しく知る"])},news_not_found:n=>{const{normalize:r}=n;return r(["おっとっと！記事が見つかりませんでした"])},redirect_to_news:n=>{const{normalize:r}=n;return r(["5 秒後にニュースのホームページにリダイレクトされます..."])}},newsroom_page:{academic:n=>{const{normalize:r}=n;return r(["アカデミック"])},academic_research:n=>{const{normalize:r}=n;return r(["学術論文"])},author:n=>{const{normalize:r}=n;return r(["著者でフィルタリングする"])},description:n=>{const{normalize:r}=n;return r(["Jina AI からの最新ニュースとアップデートをお読みください。"])},description1:n=>{const{normalize:r}=n;return r(["AI テクノロジーのイノベーションについて一言一句書きます。"])},engineering_group:n=>{const{normalize:r}=n;return r(["エンジニアリングチーム"])},engineering_group_date:n=>{const{normalize:r}=n;return r(["2021年5月31日"])},minutes_read:n=>{const{normalize:r}=n;return r(["数分間の読書"])},most_recent_articles:n=>{const{normalize:r}=n;return r(["最新記事"])},news_description:n=>{const{normalize:r}=n;return r(["Jina 2.0 では、コミュニティの声に耳を傾けました。確かに、深く聞いてしまいました。 「あなたの課題は何ですか?」と尋ね、貴重なフィードバックをお待ちしています。"])},news_title:n=>{const{normalize:r}=n;return r(["すべてのコンテンツを検索: Jina 2.0 の MEME コンテストを開催しています。"])},photos:n=>{const{normalize:r}=n;return r(["写真"])},product:n=>{const{normalize:r}=n;return r(["製品でフィルタリングする"])},search:n=>{const{normalize:r}=n;return r(["タイトルから探す"])},tech_blog:n=>{const{normalize:r}=n;return r(["技術記事"])},title:n=>{const{normalize:r}=n;return r(["ニュース"])},top_stories:n=>{const{normalize:r}=n;return r(["記事を選択する"])}},notice:n=>{const{normalize:r}=n;return r(["🎉 私たちの最初の本『Neural Search – From Prototype to Production with Jina』が本日正式にリリースされました!"])},open_day:{description:n=>{const{normalize:r}=n;return r(["Jina AI 内部への独占アクセス。"])},engage:n=>{const{normalize:r}=n;return r(["私たちは、一日を通して双方向の会話を強く推奨します。アイデアや視点の交換は私たちにとって非常に貴重です。これらの議論から生まれる潜在的な協力は、より統合された革新的な未来に大きく貢献する可能性があります。"])},engage_title:n=>{const{normalize:r}=n;return r(["ブレーンストーミング"])},experience:n=>{const{normalize:r}=n;return r(["ゲスト向けに、ドイツ語、英語、フランス語、スペイン語、中国語、ロシア語でご利用いただける 3 時間の没入型ツアーを企画しました。このツアーでは、マルチモーダル AI における当社の進歩と人工知能分野に関する当社の見解を詳しく説明し、その後、特定のプロジェクトの詳細なレビューを提供します。最後にグループディスカッションを行い、アイデアや洞察の交換を促進します。リクエストに応じてランチのオプションも利用できます。"])},experience_title:n=>{const{normalize:r}=n;return r(["インサイダーズツアー"])},group_size:n=>{const{normalize:r}=n;return r(["推定来場者数"])},impact:n=>{const{normalize:r}=n;return r(["オープンソース コミュニティへの貢献とマルチモーダル AI テクノロジーへの取り組みにより、Jina AI が人工知能イノベーションにおいてどのように影響力のあるプレーヤーになったかをご覧ください。私たちの目標は、意思決定において重要な役割を果たし、AI テクノロジーの進歩がすべての人に利益をもたらすようにすることです。"])},impact_title:n=>{const{normalize:r}=n;return r(["業界への影響"])},introduction:n=>{const{normalize:r}=n;return r(["Jina AI は、人工知能の将来に関心のある機関に門戸を開くことを嬉しく思います。私たちは、政治、NGO、非営利、投資部門の人々に公開日を提供しています。弊社の運営、ビジョン、業界の洞察について知るために、ぜひベルリン本社を訪問してください。"])},motivation_min_length_v1:n=>{const{normalize:r}=n;return r(["詳しい動機を教えてください。"])},motivation_placeholder_v2:n=>{const{normalize:r}=n;return r(["あなたのモチベーションを共有していただくと、あなたのエクスペリエンスを向上させることができます。"])},motivation_to_attend_v2:n=>{const{normalize:r}=n;return r(["なぜ私たちのオープンデーに興味を持ったのですか？"])},one_hour:n=>{const{normalize:r}=n;return r(["1時間"])},organization:n=>{const{normalize:r}=n;return r(["機構"])},organization_website:n=>{const{normalize:r}=n;return r(["機関のウェブサイト"])},organization_website_placeholder:n=>{const{normalize:r}=n;return r(["組織のホームページまたは LinkedIn プロフィールの URL"])},preferred_date:n=>{const{normalize:r}=n;return r(["希望日"])},preferred_language:n=>{const{normalize:r}=n;return r(["優先言語"])},preferred_products:n=>{const{normalize:r}=n;return r(["どのような製品に興味がありますか?"])},subtitle:n=>{const{normalize:r}=n;return r(["マルチモーダル AI の未来を垣間見る"])},title:n=>{const{normalize:r}=n;return r(["オープンデー"])},tutor_subtitle:n=>{const{normalize:r}=n;return r(["この慎重に厳選された 3 時間のツアーでは、Jina AI のマルチモーダル AI テクノロジーにおける先駆的な取り組みの核心に迫ることができます。"])},tutor_title:n=>{const{normalize:r}=n;return r(["独占的な徹底したディスカッション"])},vision:n=>{const{normalize:r}=n;return r(["私たちが考える人工知能の未来について包括的に見てみましょう。私たちの議論は、大規模な言語モデル、マルチモーダル AI の可能性、そして世界的なイノベーションの未来を形作る上でのオープンソース テクノロジーの影響に焦点を当てます。"])},vision_title:n=>{const{normalize:r}=n;return r(["将来のビジョン"])}},open_day_faq:{answer1:n=>{const{normalize:r}=n;return r(["ドイツ語、英語、フランス語、スペイン語、中国語、ロシア語でのガイド付きツアーを提供しています。"])},answer2:n=>{const{normalize:r}=n;return r(["講義は通常約 3 時間かかります。"])},answer3:n=>{const{normalize:r}=n;return r(["ランチはオプションで、リクエストに応じて手配可能です。"])},answer4:n=>{const{normalize:r}=n;return r(["私たちの公開日は主に、政治家、NGO、非営利団体、投資家などの専門家グループを対象に設計されています。ただし、個人のプロフィールに基づいて例外を設ける場合があります。"])},answer5:n=>{const{normalize:r}=n;return r(["あらゆる規模のグループに対応できます。登録フォームにグループの人数をご記入ください。詳細を確認させていただきます。"])},answer6:n=>{const{normalize:r}=n;return r(["登録フォームには、興味のある分野や特別な要件を指定できるセクションがあります。お客様のニーズに合わせて旅程を調整できるよう最善を尽くします。"])},answer7:n=>{const{normalize:r}=n;return r(["現在、ベルリンのクロイツベルク本社でのみオープンデーを提供しています。北京および深センのオフィスは現在ツアーを停止しています。"])},question1:n=>{const{normalize:r}=n;return r(["ツアーサービスは何語で提供されますか?"])},question2:n=>{const{normalize:r}=n;return r(["講義時間はどれくらいですか？"])},question3:n=>{const{normalize:r}=n;return r(["昼食は提供されますか?"])},question4:n=>{const{normalize:r}=n;return r(["個人でもオープンデーに登録できますか?"])},question5:n=>{const{normalize:r}=n;return r(["オープンデーには何人までグループに参加できますか?"])},question6:n=>{const{normalize:r}=n;return r(["チュートリアルの対象分野を指定するにはどうすればよいですか?"])},question7:n=>{const{normalize:r}=n;return r(["北京または深センのオフィスには営業日がありますか?"])}},open_gpt:{description:n=>{const{normalize:r}=n;return r(["オープンソース、クラウドネイティブの大規模マルチモーダル モデル サービス フレームワーク"])}},paywall:{commercial_licence:{chip_label:n=>{const{normalize:r}=n;return r(["中小企業向けに設計"])},company_size_note:n=>{const{normalize:r}=n;return r(["従業員数が 100 人未満、収益が 500 万ドル未満の企業向けに設計されています。"])},cta_button:n=>{const{normalize:r}=n;return r(["今すぐ始めましょう"])},download_title:n=>{const{normalize:r}=n;return r(["商用ライセンスをダウンロード"])},feature_api_desc:n=>{const{normalize:r}=n;return r(["購入前にテストしてください"])},feature_api_title:n=>{const{normalize:r}=n;return r(["無料の API テスト アクセス"])},feature_consulting:n=>{const{normalize:r}=n;return r(["当社のモデル専門家による四半期ごとの 2 時間のコンサルティング セッション"])},feature_consulting_desc:n=>{const{normalize:r}=n;return r(["ライセンス期間ごとに 3 時間の技術コンサルティング サービス。"])},feature_future_support:n=>{const{normalize:r}=n;return r(["将来の CC BY-NC モデルに許可なくアクセスする"])},feature_future_support_desc:n=>{const{normalize:r}=n;return r(["ライセンス期間中に CC-BY-NC-4.0 に基づいてライセンサーによってリリースされた新しいモデル。"])},feature_models:n=>{const{normalize:r}=n;return r(["CC BY-NC モデルによる無制限の商用利用"])},feature_models_desc:n=>{const{normalize:r}=n;return r(["内部使用や顧客向けアプリケーションへの組み込みなど、ビジネス目的でモデルを使用します。"])},price_amount:n=>{const{normalize:r}=n;return r(["1,000ドル"])},price_period:n=>{const{normalize:r}=n;return r(["/ 四半期ごと"])},read_the_terms:n=>{const{normalize:r}=n;return r(["ライセンス条項を表示する"])},read_the_terms_btn:n=>{const{normalize:r}=n;return r(["条項"])},read_the_terms_desc:n=>{const{normalize:r}=n;return r(["購入前に商用ライセンスの権利と制限を確認してください"])},subtitle:n=>{const{normalize:r}=n;return r(["より良い検索に必要なすべてのモデル"])},test_before_purchase:n=>{const{normalize:r}=n;return r(["購入する前にお試しください"])},test_before_purchase_desc:n=>{const{normalize:r}=n;return r(["100 万の無料 API トークンを取得するか、Hugging Face モデルを使用してパフォーマンスを検証してください"])},title:n=>{const{normalize:r}=n;return r(["商用ライセンス"])},try_api:n=>{const{normalize:r}=n;return r(["まずはAPIを試してみる"])}},free_hour_consult:n=>{const{normalize:r}=n;return r(["1時間無料相談"])},free_hour_consult_description:n=>{const{normalize:r}=n;return r(["当社の製品チームおよびエンジニアリング チームとの 1 時間の無料コンサルティングを設定して、お客様のシナリオのベスト プラクティスについて話し合ってください。"])},full_commercial:n=>{const{normalize:r}=n;return r(["無制限の商用利用"])},full_commercial_description:n=>{const{normalize:r}=n;return r(["API は商用目的で制限なく使用できます。"])},higher_limit:n=>{const{normalize:r}=n;return r(["より高速に！"])},higher_limit_description:n=>{const{normalize:r}=n;return r(["r.jina.ai の場合は最大 1000 RPM、s.jina.ai の場合は最大 100 RPM。詳細については「レート制限」セクションを参照してください。"])},no_commercial:n=>{const{normalize:r}=n;return r(["非営利目的のみ (CC-BY-NC)"])},no_commercial_description:n=>{const{normalize:r}=n;return r(["API は非営利目的でのみ使用できます。営利目的で使用するには、API キーを追加してください。"])},on_prem:n=>{const{normalize:r}=n;return r(["オンプレミス展開用の商用ライセンスを持っている"])},on_prem_explain:n=>{const{normalize:r}=n;return r(["現場で当社のモデルを使用するには、商用ライセンスを購入してください。"])},priority_support:n=>{const{normalize:r}=n;return r(["優先的な顧客サポート"])},priority_support_description:n=>{const{normalize:r}=n;return r(["24 時間以内 (週末を含む) に電子メールで返信することを保証します。"])},secured_by_stripe:n=>{const{normalize:r}=n;return r(["Stripe で安全に支払い"])},via_api:n=>{const{normalize:r}=n;return r(["Jina Search Foundation API の使用"])},via_api_explain:n=>{const{normalize:r}=n;return r(["すべての製品にアクセスする最も簡単な方法。いつでもトークンを補充してください。"])}},powered_by:n=>{const{normalize:r}=n;return r(["に基づく"])},print:n=>{const{normalize:r}=n;return r(["印刷する"])},project_status:{archived:n=>{const{normalize:r}=n;return r(["アーカイブ済み"])},cloud_native:n=>{const{normalize:r}=n;return r(["クラウドネイティブ"])},core:n=>{const{normalize:r}=n;return r(["草の根コア"])},data_structure:n=>{const{normalize:r}=n;return r(["データ構造"])},embedding_serving:n=>{const{normalize:r}=n;return r(["大規模なモデル ベクトルの展開"])},embedding_tuning:n=>{const{normalize:r}=n;return r(["大規模モデルのベクトル調整"])},graduated:n=>{const{normalize:r}=n;return r(["卒業"])},incubating:n=>{const{normalize:r}=n;return r(["孵化中"])},kubernetes:n=>{const{normalize:r}=n;return r(["Kubernetes"])},large_size_model:n=>{const{normalize:r}=n;return r(["大型モデル"])},linux_foundation:n=>{const{normalize:r}=n;return r(["Linux財団"])},llm1:n=>{const{normalize:r}=n;return r(["LLM フレームワーク"])},mid_size_model:n=>{const{normalize:r}=n;return r(["ミディアムモデル"])},model_serving:n=>{const{normalize:r}=n;return r(["モデルの展開"])},model_tuning:n=>{const{normalize:r}=n;return r(["モデルのチューニング"])},observability:n=>{const{normalize:r}=n;return r(["可観測性"])},orchestration:n=>{const{normalize:r}=n;return r(["クラウドオーケストレーション"])},prompt_serving:n=>{const{normalize:r}=n;return r(["プロンプトワード展開"])},prompt_tuning:n=>{const{normalize:r}=n;return r(["即時単語チューニング"])},rag1:n=>{const{normalize:r}=n;return r(["RAGアプリケーション"])},sandbox:n=>{const{normalize:r}=n;return r(["サンドボックス"])},small_size_model:n=>{const{normalize:r}=n;return r(["小型モデル"])},vector_database:n=>{const{normalize:r}=n;return r(["ベクトルデータベース"])},vector_store:n=>{const{normalize:r}=n;return r(["ベクトルデータベース"])}},prompt_perfect:{description:n=>{const{normalize:r}=n;return r(["プレミアプロンプトワードツールボックス"])},image_model:n=>{const{normalize:r}=n;return r(["イメージモデル"])},intro:n=>{const{normalize:r}=n;return r(["プレミアプロンプトワードツールボックス"])},intro1:n=>{const{normalize:r}=n;return r(["プロンプトワードエンジニアリングのための最高のツール"])},optimized:n=>{const{normalize:r}=n;return r(["あなたの役割は、私のブレーンストーミングのパートナーとなり、特定のトピックや問題に対して創造的なアイデアや提案を提供することです。回答には、問題を解決したり、興味深い方法でトピックをさらに探求したりするのに役立つ、独創的でユニークな関連性の高いアイデアが含まれている必要があります。回答では、タスクの特定の要件や制限も考慮する必要があることに注意してください。"])},optimized_title:n=>{const{normalize:r}=n;return r(["最適化されたプロンプトワード"])},original:n=>{const{normalize:r}=n;return r(["あなたの役割は、私のブレインストーミングパートナーになることです。"])},original_title:n=>{const{normalize:r}=n;return r(["元のプロンプトワード"])},text_model:n=>{const{normalize:r}=n;return r(["テキストモデル"])}},promptperfect:{features:[{description:n=>{const{normalize:r}=n;return r(["コンテンツの生成とプロンプトワードの最適化を簡単に切り替えて、コンテンツの品質を次のレベルに引き上げます。"])},name:n=>{const{normalize:r}=n;return r(["スマートアシスタント"])},title:n=>{const{normalize:r}=n;return r(["毎日の生産性向上。"])}},{description:n=>{const{normalize:r}=n;return r(["効果的なプロンプトワードの書き方がわかりませんか?考えを入力するだけで、マウスをクリックするだけでより適切な言葉が得られます。"])},name:n=>{const{normalize:r}=n;return r(["プロンプトワードの最適化"])},title:n=>{const{normalize:r}=n;return r(["より良いインプット、より良いアウトプット"])}},{description:n=>{const{normalize:r}=n;return r(["同じプロンプト単語に対する出力を比較することで、各 AI モデルの個性を理解します。"])},name:n=>{const{normalize:r}=n;return r(["模型コンテスト"])},title:n=>{const{normalize:r}=n;return r(["モデルを並べて比較。"])}},{description:n=>{const{normalize:r}=n;return r(["これはおそらく、プロンプト ワードを API として展開する最も簡単な方法です。"])},name:n=>{const{normalize:r}=n;return r(["導入プロンプトの単語"])},title:n=>{const{normalize:r}=n;return r(["面倒な Ops に別れを告げて、直接デプロイします。"])}},{description:n=>{const{normalize:r}=n;return r(["独自の LLM エージェントをカスタマイズし、マルチエージェント シミュレーションを起動します。目標を達成するために仮想環境でどのように協力または競争するかをご覧ください。"])},name:n=>{const{normalize:r}=n;return r(["マルチエージェント"])},title:n=>{const{normalize:r}=n;return r(["エージェントがどのように連携するかを確認する"])}}],get_started:n=>{const{normalize:r}=n;return r(["PromptPerfect を使ってみる"])}},purchase:{success:n=>{const{normalize:r}=n;return r(["ご購入いただきありがとうございます！"])},success_caption:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_purchasedTime")),"に注文を完了しました。 API キーを使用する準備ができました。"])}},purchase_now:n=>{const{normalize:r}=n;return r(["即購入"])},rate_limit:{batch_explain:n=>{const{normalize:r}=n;return r(["この API はバッチ操作をサポートしており、リクエストごとに最大 512 個のドキュメントを許可し、ドキュメントごとに最大 8192 個のトークンを使用できます。バッチ操作を賢く使用すると、リクエストの数が大幅に削減され、パフォーマンスが向上します。"])},classifier:n=>{const{normalize:r}=n;return r(["ラベル付きの例を使用して分類器をトレーニングする"])},classifier_few_shot:n=>{const{normalize:r}=n;return r(["トレーニングされた少数ショット分類器を使用して入力を分類する"])},classifier_few_shot_token_counting:n=>{const{normalize:r}=n;return r(["トークン数は次のとおりです: input_tokens"])},classifier_latency:n=>{const{normalize:r}=n;return r(["応答時間は入力サイズによって異なります"])},classifier_token_counting:n=>{const{normalize:r}=n;return r(["トークン数は、input_tokens × num_iters です。"])},classifier_zero_shot:n=>{const{normalize:r}=n;return r(["ゼロショット分類を使用して入力を分類する"])},classifier_zero_shot_token_counting:n=>{const{normalize:r}=n;return r(["トークン数は次のとおりです: input_tokens + label_tokens"])},depends:n=>{const{normalize:r}=n;return r(["入力サイズに依存"])},description:n=>{const{normalize:r}=n;return r(["説明する"])},embeddings:n=>{const{normalize:r}=n;return r(["テキスト/画像を固定長ベクトルに変換する"])},endpoint:n=>{const{normalize:r}=n;return r(["APIポート"])},explain:n=>{const{normalize:r}=n;return r(["レート制限は、<b>RPM</b> (1 分あたりのリクエスト数) と <b>TPM</b> (1 分あたりのターム数) の 2 つの方法で追跡されます。制限は IP ごとに適用され、最初にどのしきい値 (RPM または TPM) に到達するかに基づいて制限に達する可能性があります。"])},gjinaai:n=>{const{normalize:r}=n;return r(["ネットワークの知識を利用して発言を裏付ける"])},input_token_counting:n=>{const{normalize:r}=n;return r(["入力リクエスト内のトークンの数に基づきます。"])},latency:n=>{const{normalize:r}=n;return r(["平均遅延"])},no_token_counting:n=>{const{normalize:r}=n;return r(["トークンの使用量はカウントされません。"])},output_token_counting:n=>{const{normalize:r}=n;return r(["出力応答内のトークンの数に基づきます。"])},premium_rate:n=>{const{normalize:r}=n;return r(["レート制限を増やすことが可能"])},product:n=>{const{normalize:r}=n;return r(["製品"])},requestType:n=>{const{normalize:r}=n;return r(["リクエストの種類"])},reranker:n=>{const{normalize:r}=n;return r(["クエリによるドキュメントの絞り込み"])},rjinaai:n=>{const{normalize:r}=n;return r(["URL を LLM フレンドリーなテキストに変換する"])},sjinaai:n=>{const{normalize:r}=n;return r(["Web を検索し、結果を LLM に適したテキストに変換します"])},tbd:n=>{const{normalize:r}=n;return r(["未定"])},title:n=>{const{normalize:r}=n;return r(["レート制限"])},tokenCounting:n=>{const{normalize:r}=n;return r(["単語の使用数"])},tokenizer:n=>{const{normalize:r}=n;return r(["長いテキストを単語や文に分割する"])},total_token_counting:n=>{const{normalize:r}=n;return r(["プロセス全体のトークンの総数をカウントします。"])},understanding:n=>{const{normalize:r}=n;return r(["レート制限について学ぶ"])},understanding_description:n=>{const{normalize:r}=n;return r(["レート制限は、各 IP アドレスが 1 分間に API に対して実行できるリクエストの最大数 (RPM) です。各製品およびレベルのレート制限の詳細については、以下をご覧ください。"])},wAPIkey:n=>{const{normalize:r}=n;return r(["APIキーを使用する"])},wPremium:n=>{const{normalize:r}=n;return r(["プレミアムAPIキー付属"])},woAPIkey:n=>{const{normalize:r}=n;return r(["APIキーがありません"])}},rationale:{decision:n=>{const{normalize:r}=n;return r(["決める"])},description:n=>{const{normalize:r}=n;return r(["LLM 支援のインテリジェントな意思決定ツール"])},intro:n=>{const{normalize:r}=n;return r(["コインの両面を見て合理的な意思決定を行う"])}},reader:{beta:n=>{const{normalize:r}=n;return r(["実験"])},better_input:n=>{const{normalize:r}=n;return r(["最初から入力品質を向上させる"])},better_input_description:n=>{const{normalize:r}=n;return r(["Agent または RAG システムの出力に問題がありますか?これは入力品質が低いことが原因である可能性があります。"])},check_price_table:n=>{const{normalize:r}=n;return r(["価格表を見る"])},copy:n=>{const{normalize:r}=n;return r(["コピー"])},demo:{advanced_usage:n=>{const{normalize:r}=n;return r(["高度な使用法"])},ask_llm:n=>{const{normalize:r}=n;return r(["検索ベースが必要かどうか LLM に問い合わせてください"])},ask_llm_directly:n=>{const{normalize:r}=n;return r(["LLMに直接質問してください"])},ask_llm_with_search_grounding:n=>{const{normalize:r}=n;return r(["検索経由で LLM に問い合わせる"])},ask_question:n=>{const{normalize:r}=n;return r(["質問する"])},ask_question_hint:n=>{const{normalize:r}=n;return r(["質問を入力し、取得した LLM コンテンツと組み合わせて回答を生成します"])},basic_usage:n=>{const{normalize:r}=n;return r(["基本的な使い方"])},basic_usage1:n=>{const{normalize:r}=n;return r(["URLを読む"])},basic_usage2:n=>{const{normalize:r}=n;return r(["検索クエリ"])},basic_usage3:n=>{const{normalize:r}=n;return r(["地面"])},copy:n=>{const{normalize:r}=n;return r(["コピー"])},fetch:n=>{const{normalize:r}=n;return r(["コンテンツを取得する"])},get_response:n=>{const{normalize:r}=n;return r(["応答を取得する"])},headers:{auth_token:n=>{const{normalize:r}=n;return r(["レート制限を高めるには API キーを追加します"])},auth_token_explain:n=>{const{normalize:r}=n;return r(["より高いレート制限にアクセスするには、Jina API キーを入力してください。最新のレート制限情報については、以下の表を参照してください。"])},browser_locale:n=>{const{normalize:r}=n;return r(["ブラウザのロケール"])},browser_locale_explain:n=>{const{normalize:r}=n;return r(["ページをレンダリングするためのブラウザーのロケール設定を制御します。多くの Web サイトは、ロケール設定に基づいて異なるコンテンツを提供します。"])},default:n=>{const{normalize:r}=n;return r(["デフォルト"])},default_explain:n=>{const{normalize:r}=n;return r(["デフォルトのパイプラインは、ほとんどの Web サイトおよび LLM 入力に対して最適化されています。"])},file:n=>{const{normalize:r}=n;return r(["ローカル PDF/HTML ファイル"])},file_explain:n=>{const{normalize:r}=n;return r(["Reader を使用してローカルの PDF および HTML ファイルをアップロードして読み取ります。 PDF および HTML ファイルのみがサポートされています。"])},html:n=>{const{normalize:r}=n;return r(["HTML"])},html_explain:n=>{const{normalize:r}=n;return r(["documentElement.outerHTML を返します。"])},image_caption:n=>{const{normalize:r}=n;return r(["説明する"])},image_caption_explain:n=>{const{normalize:r}=n;return r(["指定された URL にあるすべての画像にキャプションを追加し、キャプションのない画像に alt タグとして「Image [idx]: [caption]」を追加します。これにより、下流の LLM が推論や要約などのアクティビティで画像を操作できるようになります。"])},images_summary:n=>{const{normalize:r}=n;return r(["すべての画像を最後までまとめてください"])},images_summary_explain:n=>{const{normalize:r}=n;return r(["最後に「画像」セクションが作成されます。これにより、ダウンストリーム LLM は概要ページ上のすべてのビジュアルの概要を把握できるようになり、推論機能が向上します。"])},json_response:n=>{const{normalize:r}=n;return r(["JSON応答"])},json_response_explain:n=>{const{normalize:r}=n;return r(["応答は JSON 形式で、URL、ヘッダー、コンテンツ、およびタイムスタンプ (利用可能な場合) が含まれます。検索モードでは、記述された JSON 構造にそれぞれ従う 5 つのエントリのリストが返されます。"])},links_summary:n=>{const{normalize:r}=n;return r(["すべてのリンクを最後までグループ化する"])},links_summary_explain:n=>{const{normalize:r}=n;return r(["最後に、「ボタンとリンク」セクションが作成されます。これは、ダウンストリーム LLM または Web エージェントがページに移動したり、さらなるアクションを実行したりするのに役立ちます。"])},markdown:n=>{const{normalize:r}=n;return r(["マークダウン"])},markdown_explain:n=>{const{normalize:r}=n;return r(["可読性フィルタリングをバイパスして、HTML から直接マークダウンを返します。"])},mode:n=>{const{normalize:r}=n;return r(["読み取りまたは検索モード"])},mode_explain:n=>{const{normalize:r}=n;return r(["読み取りモードは URL のコンテンツにアクセスするために使用されますが、検索モードを使用すると、Web でクエリを検索し、各検索結果 URL に読み取りモードを適用できます。"])},no_cache:n=>{const{normalize:r}=n;return r(["キャッシュのバイパス"])},no_cache_explain:n=>{const{normalize:r}=n;return r(["当社の API サーバーは、読み取りモードと検索モードのコンテンツを一定期間キャッシュします。このキャッシュをバイパスするには、このヘッダーを true に設定します。"])},pageshot:n=>{const{normalize:r}=n;return r(["ページのスナップショット"])},pageshot_explain:n=>{const{normalize:r}=n;return r(["ページ全体のスクリーンショットの画像 URL を返します (ベストエフォート)。"])},post_with_url:n=>{const{normalize:r}=n;return r(["POSTメソッドを使用する"])},post_with_url_explain:n=>{const{normalize:r}=n;return r(["GET メソッドの代わりに POST メソッドを使用し、本文に URL を渡します。ハッシュベースのルーティングを備えた SPA を構築する場合に役立ちます。"])},proxy_server:n=>{const{normalize:r}=n;return r(["プロキシサーバーを使用する"])},proxy_server_explain:n=>{const{normalize:r}=n;return r(["API サーバーはプロキシを利用して URL にアクセスできます。これは、特定のプロキシ経由でのみアクセスできるページに役立ちます。"])},references:n=>{const{normalize:r}=n;return r(["参照"])},references_explain:n=>{const{normalize:r}=n;return r(["ユーザー指定の参照 (URL) のカンマ区切りリスト"])},remove_selector:n=>{const{normalize:r}=n;return r(["セレクターを除外する"])},remove_selector_explain:n=>{const{normalize:r}=n;return r(["指定された要素をページから削除するための CSS セレクターのリストを提供します。ページの特定の部分 (ヘッダー、フッターなど) を除外する場合に便利です。"])},return_format:n=>{const{normalize:r}=n;return r(["コンテンツ形式"])},return_format_explain:n=>{const{normalize:r}=n;return r(["過剰なフィルタリングを防ぐために、応答の詳細レベルを制御できます。デフォルトのパイプラインは、ほとんどの Web サイトおよび LLM 入力に対して最適化されています。"])},screenshot:n=>{const{normalize:r}=n;return r(["スクリーンショット"])},screenshot_explain:n=>{const{normalize:r}=n;return r(["最初の画面の画像 URL を返します。"])},set_cookie:n=>{const{normalize:r}=n;return r(["転送クッキー"])},set_cookie_explain:n=>{const{normalize:r}=n;return r(["弊社の API サーバーは、URL にアクセスするときにカスタム Cookie 設定を転送できます。これは、追加の認証が必要なページに役立ちます。 Cookie を含むリクエストはキャッシュされないことに注意してください。"])},site_selector:n=>{const{normalize:r}=n;return r(["サイト検索"])},site_selector_explain:n=>{const{normalize:r}=n;return r(["指定された Web サイトまたはドメインの検索結果のみを返します。デフォルトでは、Web 全体を検索します。"])},stream_mode:n=>{const{normalize:r}=n;return r(["ストリーミングモード"])},stream_mode_explain:n=>{const{normalize:r}=n;return r(["ストリーミング モードでは、ターゲット ページを大きくすることが容易になり、ページが完全にレンダリングされるまでにより多くの時間を費やすことができます。標準モードでコンテンツが不完全になる場合は、ストリーミング モードの使用を検討してください。"])},target_selector:n=>{const{normalize:r}=n;return r(["ターゲットセレクター"])},target_selector_explain:n=>{const{normalize:r}=n;return r(["ページのより具体的な部分に焦点を当てるための CSS セレクターのリストを提供します。デフォルト設定では必要なコンテンツが表示されない場合に便利です。"])},text:n=>{const{normalize:r}=n;return r(["文章"])},text_explain:n=>{const{normalize:r}=n;return r(["document.body.innerText を返します。"])},wait_for_selector:n=>{const{normalize:r}=n;return r(["セレクターを待つ"])},wait_for_selector_explain:n=>{const{normalize:r}=n;return r(["特定の要素が表示されるまで待機してそれを返す CSS セレクターのリストを提供します。デフォルトの設定では目的のコンテンツが表示できない場合に便利な機能です。"])},with_iframe:n=>{const{normalize:r}=n;return r(["iframe"])},with_iframe_explain:n=>{const{normalize:r}=n;return r(["返される結果には、ページ上の iframe のコンテンツも含まれます。"])},with_shadow_dom:n=>{const{normalize:r}=n;return r(["シャドウDOM"])},with_shadow_dom_explain:n=>{const{normalize:r}=n;return r(["返される結果には、ページ上のシャドウ DOM の内容も含まれます。"])},x_timeout:n=>{const{normalize:r}=n;return r(["タイムアウト"])},x_timeout_explain:n=>{const{normalize:r}=n;return r(["Web ページの読み込みを待機する最大時間。これは、エンドツーエンドのリクエスト全体の合計時間ではないことに注意してください。"])}},how_to_stream:n=>{const{normalize:r}=n;return r(["コンテンツが利用可能になったときに処理するには、リクエスト ヘッダーをストリーミング モードに設定します。これにより、最初のバイトの受信にかかる時間が最小限に抑えられます。カールの例:"])},how_to_use1:n=>{const{normalize:r}=n;return r(["LLM アクセスが必要なコードまたはツール内の URL に https://r.jina.ai/ を追加します。これにより、ページのメインコンテンツがクリーンな LLM フレンドリーなテキストで返されます。"])},how_to_use2:n=>{const{normalize:r}=n;return r(["https://s.jina.ai/ をクエリに追加します。これにより、検索エンジンが呼び出され、URL とコンテンツを含む上位 5 件の結果が返され、それぞれが簡潔で LLM に適したテキストで表示されます。"])},how_to_use3:n=>{const{normalize:r}=n;return r(["https://g.jina.ai/ をステートメントに追加します。これにより、意思決定エンジンが呼び出され、真実のパーセンテージ、ステートメントが真か偽かを示すブール値、理由の概要、および参照リストが返されます。"])},key_required:n=>{const{normalize:r}=n;return r(["このエンドポイントを使用するには API キーが必要です"])},learn_more:n=>{const{normalize:r}=n;return r(["もっと詳しく知る"])},open:n=>{const{normalize:r}=n;return r(["新しいタブで開く"])},raw_html:n=>{const{normalize:r}=n;return r(["生のHTML"])},reader_output:n=>{const{normalize:r}=n;return r(["リーダー出力"])},reader_response:n=>{const{normalize:r}=n;return r(["読者の反応"])},reader_search_hint:n=>{const{normalize:r}=n;return r(["コードでこの URL を使用する場合は、URL をエンコードすることを忘れないでください。"])},reader_url:n=>{const{normalize:r}=n;return r(["リーダーの URL"])},reader_url_hint:n=>{const{normalize:r}=n;return r(["リーダー API 経由でコンテンツを取得するには、以下をクリックしてください"])},requires_post_method:n=>{const{normalize:r}=n;return r(["この機能には POST メソッドが必要です。ローカル ファイルをアップロードすると、POST メソッドが自動的に有効になります。"])},search_params:n=>{const{normalize:r}=n;return r(["検索パラメータ"])},search_query_rewrite:n=>{const{normalize:r}=n;return r(["上記のデモとは異なり、実際には、根拠を得るために元の質問を Web で検索することはないことに注意してください。よく行われるのは、元の問題を書き直すか、マルチホップ問題を使用することです。取得した結果を読み取り、追加のクエリを生成して、最終的な答えに到達する前に、必要に応じてさらに多くの情報を収集します。"])},select_mode:n=>{const{normalize:r}=n;return r(["モード選択"])},show_read_demo:n=>{const{normalize:r}=n;return r(["Reader が URL を読み取る方法を学ぶ"])},show_search_demo:n=>{const{normalize:r}=n;return r(["読者がネットワークをどのように検索するかを理解する"])},slow_warning:n=>{const{normalize:r}=n;return r(["これには最大 30 秒かかる場合があり、リクエストごとに最大 300K のトークンが必要になります。"])},standard_usage:n=>{const{normalize:r}=n;return r(["標準的な使用方法"])},stream_mode:n=>{const{normalize:r}=n;return r(["ストリーミングモード"])},stream_mode_explain:n=>{const{normalize:r}=n;return r(["ストリーミング モードは、ターゲット ページが大きすぎてレンダリングできない場合に便利です。標準モードで提供される機能が不完全であると思われる場合は、ストリーミング モードを試してください。"])},stream_mode_explain1:n=>{const{normalize:r}=n;return r(["ストリーミング モードは、標準モードでは不完全な結果が得られることがわかった場合に便利です。これは、ストリーミング モードでは、ページが完全にレンダリングされるまで待機する時間が長くなるためです。 accept-header を使用してストリーミング モードを切り替えます。"])},tagline:n=>{const{normalize:r}=n;return r(["デモを試してみる"])},try_demo:n=>{const{normalize:r}=n;return r(["デモ"])},use_headers:n=>{const{normalize:r}=n;return r(["リクエスト ヘッダーを使用して、Reader API の動作を制御できます。以下は、サポートされているヘッダーの完全なリストです。"])},waiting_for_reader:n=>{const{normalize:r}=n;return r(["まず Reader API の結果を待ちます..."])},warn_grounding_message:n=>{const{normalize:r}=n;return r(["このプロセスには最大 30 秒かかり、グラウンディング要求ごとに最大 300K のトークンが消費されます。一部のブラウザーでは長時間の遅延によりリクエストが終了する場合があるため、コードをコピーしてターミナルから実行することをお勧めします。"])},warn_grounding_title:n=>{const{normalize:r}=n;return r(["高いレイテンシとトークン使用量"])},your_query:n=>{const{normalize:r}=n;return r(["クエリを入力してください"])},your_query_hint:n=>{const{normalize:r}=n;return r(["最新の情報や世界の知識が必要な質問を入力してください。"])},your_url:n=>{const{normalize:r}=n;return r(["URLを入力してください"])},your_url_hint:n=>{const{normalize:r}=n;return r(["ページのソースコードに直接アクセスするには、以下をクリックしてください"])}},description:n=>{const{normalize:r}=n;return r(["URL を読んで、より適切な基本的な LLM をオンラインで検索してください。"])},dont_panic_api_key_is_free:n=>{const{normalize:r}=n;return r(["パニックにならない！すべての新しい API キーには 100 万個の無料トークンが含まれています。"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["Reader API は無料であり、API キーは必要ありません。 URL の前に「https://r.jina.ai/」を追加するだけです。"])},answer10:n=>{const{normalize:r}=n;return r(["いいえ、Reader API は、公的にアクセス可能な URL からのコンテンツのみを処理できます。"])},answer11:n=>{const{normalize:r}=n;return r(["5 分以内に同じ URL をリクエストすると、Reader API はキャッシュされたコンテンツを返します。"])},answer12:n=>{const{normalize:r}=n;return r(["残念だけど違う。"])},answer13:n=>{const{normalize:r}=n;return r(["はい、リーダーでネイティブ PDF サポート (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) を使用するか、arXiv で HTML バージョン (https:// r. jina.ai/https://arxiv.org/html/2310.19923v4)"])},answer14:n=>{const{normalize:r}=n;return r(["Reader は、指定された URL にあるすべての画像にキャプションを追加します。もともとキャプションがない場合は、`Image [idx]: [caption]` を alt タグとして追加します。これにより、下流の LLM が推論や要約などのために画像を操作できるようになります。"])},answer15:n=>{const{normalize:r}=n;return r(["Reader API は、高度に拡張できるように設計されています。リアルタイムのトラフィックに基づいて自動的に拡張され、同時リクエストの最大数は約 4,000 になりました。当社は、Jina AI のコア製品の 1 つとして積極的に維持しています。したがって、本番環境で自由に使用してください。"])},answer16:n=>{const{normalize:r}=n;return r(["最新のレート制限情報は以下の表で確認してください。私たちは Reader API のレート制限とパフォーマンスの改善に積極的に取り組んでおり、それに応じてこの表も更新されることに注意してください。"])},answer2:n=>{const{normalize:r}=n;return r(["Reader API は、プロキシを使用して URL を取得し、そのコンテンツをブラウザーでレンダリングして、高品質のプライマリ コンテンツを抽出します。"])},answer3:n=>{const{normalize:r}=n;return r(["はい、リーダー API はオープンソースであり、Jina AI GitHub リポジトリにあります。"])},answer4:n=>{const{normalize:r}=n;return r(["Reader API は通常、URL を処理して 2 秒以内にコンテンツを返しますが、複雑なページや動的なページの場合はさらに時間がかかる場合があります。"])},answer5:n=>{const{normalize:r}=n;return r(["特に複雑なページや動的なページの場合、クロールは複雑で信頼性が低い場合があります。リーダー API は、簡潔で信頼性の高い、クリーンな LLM レベルのテキスト出力を提供します。"])},answer6:n=>{const{normalize:r}=n;return r(["Reader API は、URL のコンテンツを元の言語で返します。翻訳サービスは提供しておりません。"])},answer7:n=>{const{normalize:r}=n;return r(["ブロックの問題が発生した場合は、サポート チームに問い合わせて解決策を求めてください。"])},answer8:n=>{const{normalize:r}=n;return r(["Reader API は主に Web ページを対象としており、arXiv などのサイトで HTML で表示される PDF からコンテンツを抽出できますが、一般的な PDF 抽出には最適化されていません。"])},answer9:n=>{const{normalize:r}=n;return r(["現在、リーダー API はメディア コンテンツを処理しませんが、将来の機能強化には画像のキャプションやビデオの要約が含まれる予定です。"])},question1:n=>{const{normalize:r}=n;return r(["Reader API の使用に関連するコストはいくらですか?"])},question10:n=>{const{normalize:r}=n;return r(["ローカル HTML ファイルで Reader API を使用することはできますか?"])},question11:n=>{const{normalize:r}=n;return r(["Reader API はコンテンツをキャッシュしますか?"])},question12:n=>{const{normalize:r}=n;return r(["ログイン後に Reader API を使用してコンテンツにアクセスできますか?"])},question13:n=>{const{normalize:r}=n;return r(["Reader API を使用して arXiv 上の PDF にアクセスできますか?"])},question14:n=>{const{normalize:r}=n;return r(["画像の注釈はリーダーでどのように機能しますか?"])},question15:n=>{const{normalize:r}=n;return r(["リーダーの拡張性はどの程度ですか?これを本番環境で使用できますか?"])},question16:n=>{const{normalize:r}=n;return r(["Reader API のレート制限は何ですか?"])},question2:n=>{const{normalize:r}=n;return r(["Reader API はどのように機能しますか?"])},question3:n=>{const{normalize:r}=n;return r(["リーダー API はオープンソースですか?"])},question4:n=>{const{normalize:r}=n;return r(["Reader API の一般的なレイテンシはどれくらいですか?"])},question5:n=>{const{normalize:r}=n;return r(["自分でページをスクレイピングする代わりに Reader API を使用する必要があるのはなぜですか?"])},question6:n=>{const{normalize:r}=n;return r(["Reader API は複数の言語をサポートしていますか?"])},question7:n=>{const{normalize:r}=n;return r(["Web サイトが Reader API をブロックした場合はどうすればよいですか?"])},question8:n=>{const{normalize:r}=n;return r(["Reader API は PDF ファイルからコンテンツを抽出できますか?"])},question9:n=>{const{normalize:r}=n;return r(["Reader API は Web ページのメディア コンテンツを処理できますか?"])},title:n=>{const{normalize:r}=n;return r(["リーダーに関するよくある質問"])}},fast:n=>{const{normalize:r}=n;return r(["素早く"])},fast_stream:n=>{const{normalize:r}=n;return r(["リアルタイムのデータフロー"])},fast_stream_description:n=>{const{normalize:r}=n;return r(["データをすぐに取得する必要がありますか?当社のリーダー API は、遅延を最小限に抑えるためにデータを転送できます。"])},free:n=>{const{normalize:r}=n;return r(["いつでも無料"])},free_description:n=>{const{normalize:r}=n;return r(["Reader API は無料です。クレジット カードや API パスワードは必要ありません。トークン クォータは消費されません。"])},is_free:n=>{const{normalize:r}=n;return r(["そしてそれは実際には無料です！"])},is_free_description:n=>{const{normalize:r}=n;return r(["Reader API は無料で使用でき、柔軟なレート制限と価格設定を提供します。これは、高いアクセシビリティ、同時実行性、信頼性を備えたスケーラブルなインフラストラクチャ上に構築されています。当社は、LLM にとって頼りになる基盤ソリューションとなるよう努めています。"])},open:n=>{const{normalize:r}=n;return r(["新しいタブで開く"])},original_pdf:n=>{const{normalize:r}=n;return r(["オリジナルPDF"])},rate_limit:n=>{const{normalize:r}=n;return r(["レート制限"])},read_grounding_release_note:n=>{const{normalize:r}=n;return r(["リリースノートを読む"])},reader_also_read_images:n=>{const{normalize:r}=n;return r(["Web ページ上の画像には、リーダーの視覚言語モデルを使用して自動的にキャプションが付けられ、出力では画像の alt タグとしてフォーマットされます。これにより、ダウンストリーム LLM に、これらの画像を推論および要約プロセスに組み込むための十分なヒントが与えられます。つまり、画像について質問したり、特定の画像を選択したり、より詳細な分析のために画像の URL をより強力な VLM に転送したりすることもできます。"])},reader_description:n=>{const{normalize:r}=n;return r(["URL を LLM 対応の入力に変換するには、先頭に <code>r.jina.ai</code> を追加するだけです。"])},reader_do_grounding:n=>{const{normalize:r}=n;return r(["ファクトチェックリーダー"])},reader_do_grounding_explain:n=>{const{normalize:r}=n;return r(["新しいベンチマーク エンドポイントは、エンドツーエンドのほぼリアルタイムのファクトチェック エクスペリエンスを提供します。指定されたステートメントを取得し、リアルタイムの Web 検索結果を使用してベンチマークを実行し、事実スコアと使用された正確な参照を返します。ステートメントのベンチマークを簡単に実行して、LLM 幻覚を軽減したり、人間が書いたコンテンツの完全性を向上したりできます。"])},reader_do_pdf_explain:n=>{const{normalize:r}=n;return r(["はい、Reader は PDF の読み取りをネイティブにサポートしています。多くの画像を含む PDF を含むほとんどの PDF と互換性があり、驚くほど高速です。 LLM と組み合わせることで、ChatPDF や文書分析 AI を簡単かつ迅速に構築できます。"])},reader_do_search:n=>{const{normalize:r}=n;return r(["検索トレーサビリティリーダー"])},reader_do_search_explain:n=>{const{normalize:r}=n;return r(["LLM には知識の限界があり、世界の最新知識にアクセスできないことを意味します。これにより、誤った情報、時代遅れの対応、幻覚、その他の事実問題などの問題が発生する可能性があります。 GenAI アプリケーションには基盤が絶対に不可欠です。 Reader を使用すると、Web 上の最新情報を使用して LLM の基礎を築くことができます。クエリの前に https://s.jina.ai/ を追加するだけで、Reader が Web を検索し、URL とコンテンツを含む上位 5 件の結果を返します。各結果は、クリーンで LLM フレンドリーなテキスト表示で始まります。 。こうすることで、LLM を常に最新の状態に保つことができ、LLM をより事実に近く、幻想を少なくすることができます。"])},reader_reads_images:n=>{const{normalize:r}=n;return r(["絵も読める！"])},reader_reads_pdf:n=>{const{normalize:r}=n;return r(["ReaderはPDFも読める！"])},reader_result:n=>{const{normalize:r}=n;return r(["リーダーの結果"])},table:{td_1_0:n=>{const{normalize:r}=n;return r(["URL を読み取り、単一チャネルごとにそのコンテンツを返します。"])},td_1_1:n=>{const{normalize:r}=n;return r(["1 分あたり 20 リクエスト"])},td_1_2:n=>{const{normalize:r}=n;return r(["1 分あたり 200 リクエスト"])},td_1_3:n=>{const{normalize:r}=n;return r(["出力トークンによると"])},td_1_4:n=>{const{normalize:r}=n;return r(["3秒"])},td_1_5:n=>{const{normalize:r}=n;return r(["3秒"])},td_2_0:n=>{const{normalize:r}=n;return r(["Web を検索すると上位 5 件の結果が返され、世界中の知識を獲得し、証拠を検索するのに役立ちます"])},td_2_1:n=>{const{normalize:r}=n;return r(["1 分あたり 5 リクエスト"])},td_2_2:n=>{const{normalize:r}=n;return r(["1 分あたり 40 リクエスト"])},td_2_3:n=>{const{normalize:r}=n;return r(["5 つの検索結果すべてに基づいてトークン数を出力します。"])},td_2_4:n=>{const{normalize:r}=n;return r(["10秒"])},td_2_5:n=>{const{normalize:r}=n;return r(["10秒"])},th0:n=>{const{normalize:r}=n;return r(["終点"])},th1:n=>{const{normalize:r}=n;return r(["説明する"])},th2:n=>{const{normalize:r}=n;return r(["APIキーを使用しないレート制限"])},th3:n=>{const{normalize:r}=n;return r(["APIキーを使用したレート制限"])},th4:n=>{const{normalize:r}=n;return r(["トークンカウントスキーム"])},th5:n=>{const{normalize:r}=n;return r(["平均遅延"])},th6:n=>{const{normalize:r}=n;return r(["平均遅延"])}},title:n=>{const{normalize:r}=n;return r(["リーダーAPI"])},usage:n=>{const{normalize:r}=n;return r(["使用法"])},usage_details_false:n=>{const{normalize:r}=n;return r(["基本的な使い方のみを表示"])},usage_details_null:n=>{const{normalize:r}=n;return r(["基本的な使い方と高度な使い方を表示する"])},usage_details_true:n=>{const{normalize:r}=n;return r(["高度な使用法のみを表示"])},want_higher_rate_limit:n=>{const{normalize:r}=n;return r(["より高いレート制限 (最大 1000 RPM) が必要ですか?私たちはあなたをサポートできます！"])},what_is1:n=>{const{normalize:r}=n;return r(["リーダーとは何ですか?"])},what_is_answer_long:n=>{const{normalize:r}=n;return r(["LLM へのネットワーク情報の入力は、基礎を築くための重要なステップですが、難しい場合もあります。最も簡単な方法は、Web ページをスクレイピングして生の HTML をフィードすることです。ただし、クロールは複雑でブロックされることが多く、生の HTML にはマークアップやスクリプトなどの無関係な要素が含まれています。 Reader API は、URL からコア コンテンツを抽出し、それをクリーンな LLM フレンドリーなテキストに変換することでこれらの問題を解決し、エージェントおよび RAG システムへの高品質な入力を保証します。"])},what_is_desc:n=>{const{normalize:r}=n;return r(["任意の URL にアクセスし、そのメイン コンテンツを LLM に最適化されたテキストに抽出します。"])}},recommender:{confirm_message:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["API キーには ",e(o("_leftTokens"))," トークンが残っています。 ",e(o("_numArticles"))," 個の記事の全文を Reranker API に送信し、",e(o("_selectedReranker"))," モデルを使用して現在のページに関連する記事を検索します。これにより、API キー ",e(o("_APIKey"))," のトークン カウントが大幅に消費されます。続けたいですか？"])},confirm_title:n=>{const{normalize:r}=n;return r(["警告: 大量のトークンを消費します"])},out_of_quota:n=>{const{normalize:r}=n;return r(["この API キーのトークンが不足しています。アカウントに資金を投入するか、別の API キーを使用してください。"])},recommend:n=>{const{normalize:r}=n;return r(["トップ5を獲得する"])},recommended_articles:n=>{const{normalize:r}=n;return r(["類似記事トップ 5"])}},reranker:{benchmark:{description0:n=>{const{normalize:r}=n;return r(["LlamaIndex は、RAG のベクトル モデルとリオーダラーのさまざまな組み合わせを評価し、それを再現します。結果は、Jina Reranker が検索品質を大幅に向上させ、これは上流で使用される特定のベクトル モデルに依存しない利点であることを示しています。"])},description1:n=>{const{normalize:r}=n;return r(["BIER (ベンチマーク IR) は、関連性や NDCG を含むモデルの検索有効性を評価します。 BIER スコアが高いほど、一致および検索結果のランキングがより正確になります。"])},description2:n=>{const{normalize:r}=n;return r(["LoCo ベンチマークを使用して、ローカルの一貫性とコンテキスト、およびクエリ固有のランキングに対するモデルの理解を測定します。 LoCo スコアが高いほど、関連情報を特定して優先順位を付ける能力が優れていることを示します。"])},description3:n=>{const{normalize:r}=n;return r(["MTEB (Multilingual Text Vector Model Benchmark) は通常、クラスタリング、分類、検索、その他のメトリクスを含む、テキスト ベクトル モデリングにおけるモデルの機能をテストします。ただし、比較のために、MTEB の並べ替えタスクのみを使用します。"])},title:n=>{const{normalize:r}=n;return r(["基準"])},title0:n=>{const{normalize:r}=n;return r(["ラマインデックス"])},title1:n=>{const{normalize:r}=n;return r(["ビア"])},title2:n=>{const{normalize:r}=n;return r(["ロコ"])},title3:n=>{const{normalize:r}=n;return r(["MTEB"])}},benchmark_description:n=>{const{normalize:r}=n;return r(["比較のために、BGE (Beijing Intelligent Source Research Institute)、BCE (NetEase Youdao)、および Cohere の他の 3 つの主要な再順序付け会社をベンチマークに含めました。以下のグラフからわかるように、Jina Reranker は関連するすべてのリランキング カテゴリで最高の平均スコアを獲得しており、同業他社の中で明らかにリードしています。"])},benchmark_title:n=>{const{normalize:r}=n;return r(["パフォーマンスのベンチマーク"])},choose_turbo:n=>{const{normalize:r}=n;return r(["ターボバージョンは5倍高速"])},choose_turbo_description:n=>{const{normalize:r}=n;return r(["また、2 つの新しいオープンソースの再ランキング モデル、jina-reranker-v1-turbo-en と jina-reranker-v1-tiny-en も提供します。後者には 3,000 万のパラメーターと 4 つのレイヤーしかありません。 2 つの新しい再配置機能は、品質のわずかな低下のみで、ベース モデルよりも最大 5 倍高速に推論を実行します。リアルタイムの並べ替えが必要なアプリケーションに最適です。以下のレビューをお読みください。"])},customize_urself:n=>{const{normalize:r}=n;return r(["変更してみて、応答がどのように変化するかを確認してください。"])},customize_urself_pl:n=>{const{normalize:r}=n;return r(["変更してみて、応答がどのように変化するかを確認してください。"])},description:n=>{const{normalize:r}=n;return r(["検索の関連性を最大化する世界クラスのニューラルレトリーバー。"])},description_rich:n=>{const{normalize:r}=n;return r(["高度な並べ替え API を使用して、検索の関連性と RAG の精度を最大化します。"])},example_input_document:n=>{const{normalize:r}=n;return r(["仕分け候補文書の例"])},example_input_query:n=>{const{normalize:r}=n;return r(["サンプルクエリ"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["Reranker API の価格は、Vector Model API の価格構造と一致しています。新しい API キーにはそれぞれ 100 万個の無料トークンが付属しています。無料のトークンに加えて、さまざまなパッケージも購入できます。詳細については、価格セクションをご覧ください。"])},answer10:n=>{const{normalize:r}=n;return r(["はい、Jina Reranker は AWS にデプロイできます。エンタープライズ環境でオンプレミスの展開が必要な場合は、AWS Marketplace サービスを通じて簡単に行うことができます。"])},answer11:n=>{const{normalize:r}=n;return r(["特定のドメインデータに合わせて調整されたリフォーマーに興味がある場合は、当社の営業チームまでお問い合わせください。弊社チームがお客様のお問い合わせに迅速に対応させていただきます。"])},answer3:n=>{const{normalize:r}=n;return r(["主な違いはアーキテクチャにあります。パフォーマンスの点では、競合他社に対して広範にテストおよびベンチマークが行われている jina-reranker-v1 をお勧めします。 Jina-reranker-v1 はクロスエンコーダー アーキテクチャを採用し、Jina-colbert-v1 は ColBERTv2 アーキテクチャに基づいていますが、クエリとドキュメントのコンテキストの長さを 8192 まで拡張し、元の ColBERTv2 モデルよりも優れたパフォーマンスを実現します。"])},answer4:n=>{const{normalize:r}=n;return r(["はい、jina-colbert-v1 はオープンソースであり、Huggingface からアクセスできます。ただし、jina-reranker-v1 はオープンソースではありません。"])},answer5:n=>{const{normalize:r}=n;return r(["現時点では英語のみをサポートしています。ただし、一部のユーザーは中国語でも機能すると報告しています。これは、jina-reranker-v1-base-en が jina-embeddings-v2-base-zh ベクトル モデル モデルと一部の重みを共有しているためである可能性があります。"])},answer6:n=>{const{normalize:r}=n;return r(["クエリ トークンの最大長は 512 です。ドキュメントにはトークンの制限はありません。"])},answer7:n=>{const{normalize:r}=n;return r(["各クエリでは、最大 2048 個のドキュメントを並べ替えることができます。"])},answer8:n=>{const{normalize:r}=n;return r(["ベクター モデル API とは異なり、バッチ サイズの概念はありません。リクエストごとに送信できるクエリ ドキュメント タプルは 1 つだけですが、タプルには最大 2048 個の候補ドキュメントを含めることができます。"])},answer9:n=>{const{normalize:r}=n;return r(["待ち時間は、ドキュメントとクエリの長​​さに応じて、100 ミリ秒から 7 秒の範囲です。たとえば、64 語のクエリを使用して 256 個のトークンを持つ 100 個のドキュメントを並べ替えるには、約 150 ミリ秒かかります。ドキュメントの長さを 4096 トークンに増やすと、時間は 3.5 秒に増加します。クエリの長​​さが 512 トークンに増加すると、時間はさらに 7 秒に増加します。"])},question1:n=>{const{normalize:r}=n;return r(["Reranker API の料金はいくらですか?"])},question10:n=>{const{normalize:r}=n;return r(["Jina Reranker を AWS にデプロイできますか?"])},question11:n=>{const{normalize:r}=n;return r(["ドメイン固有のデータに対して微調整された再配列ツールを提供していますか?"])},question3:n=>{const{normalize:r}=n;return r(["これら 2 つの再配置ツールの違いは何ですか?"])},question4:n=>{const{normalize:r}=n;return r(["Jina Reranker はオープンソースですか?"])},question5:n=>{const{normalize:r}=n;return r(["リフラワーは複数の言語をサポートしていますか?"])},question6:n=>{const{normalize:r}=n;return r(["クエリとドキュメントの最大長はどれくらいですか?"])},question7:n=>{const{normalize:r}=n;return r(["クエリごとに並べ替えできるドキュメントの最大数はいくつですか?"])},question8:n=>{const{normalize:r}=n;return r(["バッチ サイズはどれくらいですか? 1 つのリクエストで送信できるクエリ ドキュメント タプルの数はどれくらいですか?"])},question9:n=>{const{normalize:r}=n;return r(["100 個のドキュメントをリフローする場合に予想される待ち時間はどれくらいですか?"])},title:n=>{const{normalize:r}=n;return r(["リランカーに関するよくある質問"])}},feature_on_premises_description2:n=>{const{normalize:r}=n;return r(["当社の再スケジュール モデルを AWS Sagemaker にデプロイし、まもなく Microsoft Azure および Google Cloud Services にデプロイするか、当社の営業チームに連絡して、仮想プライベート クラウドおよびオンプレミス サーバー用のカスタム Kubernetes デプロイメントを入手してください。"])},feature_on_premises_description3:n=>{const{normalize:r}=n;return r(["Jina Reranker を AWS Sagemaker と Microsoft Azure にデプロイし、まもなく Google Cloud サービスにもデプロイするか、当社の営業チームに連絡して、仮想プライベート クラウドとオンプレミス サーバー用のカスタム Kubernetes デプロイメントを入手してください。"])},feature_solid_description:n=>{const{normalize:r}=n;return r(["当社の最先端の学術研究によって開発され、比類のないパフォーマンスを保証するために SOTA 再配列に対して厳密にテストされています。"])},how_it_works:n=>{const{normalize:r}=n;return r(["検索システムでは、並べ替え機能は次のように動作します。"])},how_it_works_v1:{description1:n=>{const{normalize:r}=n;return r(["ユーザーのクエリに基づいて、BM25 や TF-IDF などのベクトル モデルまたはディメンションを使用して、データベース内の関連ドキュメントを大まかに照合します。"])},description2:n=>{const{normalize:r}=n;return r(["再配置モデルは、これらの予備的なランキング結果を取得し、クエリ用語がドキュメント コンテンツとどのように相互作用するかなどのニュアンスを考慮して、より細かい粒度でドキュメントとクエリの相関分析を実行します。"])},description3:n=>{const{normalize:r}=n;return r(["再ランキング モデルは、最も関連性が高いと思われる結果を上位に配置することで検索品質を向上させます。"])},title1:n=>{const{normalize:r}=n;return r(["初期検索"])},title2:n=>{const{normalize:r}=n;return r(["並べ替える"])},title3:n=>{const{normalize:r}=n;return r(["結果の改善"])}},improve_performance:n=>{const{normalize:r}=n;return r(["検索品質が他よりも優れている"])},improve_performance_description:n=>{const{normalize:r}=n;return r(["私たちの評価では、リランカーを使用した検索システムが大幅に改善され、ヒット率が 8%、平均逆ランキング (MRR) が 33% 向上したことがわかりました。"])},learning1:n=>{const{normalize:r}=n;return r(["再注文者について学ぶ"])},learning1_description:n=>{const{normalize:r}=n;return r(["再配置モデルとは何ですか?ベクトル検索やペアごとのコサイン類似性が十分ではないのはなぜですか?包括的なガイドでリシーケンサーについて基礎から学びましょう。"])},read_more_about_benchmark:n=>{const{normalize:r}=n;return r(["ベンチマークについて詳しく読む"])},read_more_about_turbo:n=>{const{normalize:r}=n;return r(["ターボモデルとマイクロモデルについて詳しく見る"])},read_more_about_v2:n=>{const{normalize:r}=n;return r(["Jina Reranker v2 は、2024 年 6 月 25 日にリリースされたクラス最高のリランカーであり、Agentic RAG 用に構築されています。関数呼び出しのサポート、100 を超える言語での多言語検索、コード検索機能が特徴で、v1 よりも 6 倍高速です。 v2 モデルの詳細については、こちらをご覧ください。"])},reranker_description:n=>{const{normalize:r}=n;return r(["高度な 並べ替え者 API を試して、検索の関連性と RAG の精度を最大化してください。無料でお試しください!"])},show_v2benchmark:n=>{const{normalize:r}=n;return r(["v2 モデル (最新) のベースラインを表示します。"])},table:{number_token_document:n=>{const{normalize:r}=n;return r(["各ドキュメント内のトークンの数"])},number_token_query:n=>{const{normalize:r}=n;return r(["クエリ内のトークンの数"])},title:n=>{const{normalize:r}=n;return r(["クエリと 100 個のドキュメントを並べ替えるのにかかる時間コスト (ミリ秒) は次のとおりです。"])}},title:n=>{const{normalize:r}=n;return r(["リオーダラー API"])},top_n:n=>{const{normalize:r}=n;return r(["並べ替えられたドキュメントの最適な数を返します。"])},top_n_explain:n=>{const{normalize:r}=n;return r(["クエリに最も関連するドキュメントの数。"])},try_embedding:n=>{const{normalize:r}=n;return r(["ベクターモデルAPIの無償利用"])},try_reranker:n=>{const{normalize:r}=n;return r(["並べ替え者 API の無料トライアル"])},v2_features:{description1:n=>{const{normalize:r}=n;return r(["Reranker v2 は、クエリ言語に関係なく、100 以上の言語でのドキュメント検索をサポートしています。"])},description2:n=>{const{normalize:r}=n;return r(["Reranker v2 は、自然言語クエリに基づいてコード スニペットと関数シグネチャをランク付けするため、Agentic RAG アプリケーションに最適です。"])},description3:n=>{const{normalize:r}=n;return r(["Reranker v2 は、自然言語クエリに基づいて最も関連性の高いテーブルをランク付けし、さまざまなテーブル スキーマをランク付けし、SQL クエリを生成する前に最も関連性の高いテーブル スキーマを決定するのに役立ちます。"])},title1:n=>{const{normalize:r}=n;return r(["多言語検索"])},title2:n=>{const{normalize:r}=n;return r(["関数呼び出しとコード検索"])},title3:n=>{const{normalize:r}=n;return r(["表形式および構造化データのサポート"])}},v2benchmark:{descBeir:n=>{const{normalize:r}=n;return r(["Beir データセットのさまざまな再配列者によって報告された NDCG 10 スコア"])},descCodeSearchNet:n=>{const{normalize:r}=n;return r(["CodeSearchNet データセット内の再配置されたさまざまなモデルの MRR 10 スコア レポート"])},descMKQA:n=>{const{normalize:r}=n;return r(["MKQA データセット内のさまざまな並べ替えによって報告された 10 個のスコアを思い出してください。"])},descNSText2SQL:n=>{const{normalize:r}=n;return r(["NSText2SQL データセット内のさまざまな並べ替え者によって報告された 3 つのスコアを確認する"])},descRTX4090:n=>{const{normalize:r}=n;return r(["RTX 4090 GPU 上のさまざまな再ランキング モデルについて報告されたスループット (50 ミリ秒で取得されたドキュメント) スコア。"])},descToolBench:n=>{const{normalize:r}=n;return r(["ToolBench データセット内のさまざまな並べ替えによって報告された 3 つのスコアを思い出してください。"])},titleBeir:n=>{const{normalize:r}=n;return r(["BEIR (さまざまな IR タスクの異種ベンチマーク)"])},titleCodeSearchNet:n=>{const{normalize:r}=n;return r(["コードサーチネット。ベンチマークは、自然言語形式のドキュメント文字列とクエリを組み合わせたもので、クエリに関連するタグ付きスニペットが含まれます。"])},titleMKQA:n=>{const{normalize:r}=n;return r(["MKQA (多言語知識の質問と回答)"])},titleNSText2SQL:n=>{const{normalize:r}=n;return r(["NSText2SQL"])},titleRTX4090:n=>{const{normalize:r}=n;return r(["RTX4090 での Jina Reranker v2 スループット"])},titleToolBench:n=>{const{normalize:r}=n;return r(["ツールベンチ。このベンチマークは、16,000 を超えるパブリック API と、それらをシングル API およびマルチ API 設定で使用するための対応する合成ビルド命令を収集します。"])}},vs_table:{col0:n=>{const{normalize:r}=n;return r(["並べ替え者"])},col0_1:n=>{const{normalize:r}=n;return r(["検索の精度と関連性の向上"])},col0_2:n=>{const{normalize:r}=n;return r(["初期の迅速なフィルタリング"])},col0_3:n=>{const{normalize:r}=n;return r(["幅広いクエリにわたる一般的なテキスト検索"])},col1:n=>{const{normalize:r}=n;return r(["ベクトル検索"])},col1_1:n=>{const{normalize:r}=n;return r(["詳細: サブドキュメントとクエリセグメント"])},col1_2:n=>{const{normalize:r}=n;return r(["広範囲: 文書全体"])},col1_3:n=>{const{normalize:r}=n;return r(["中級: さまざまなテキストの断片"])},col2:n=>{const{normalize:r}=n;return r(["BM25"])},col2_1:n=>{const{normalize:r}=n;return r(["高い"])},col2_2:n=>{const{normalize:r}=n;return r(["適度"])},col2_3:n=>{const{normalize:r}=n;return r(["低い"])},col3_1:n=>{const{normalize:r}=n;return r(["不要"])},col3_2:n=>{const{normalize:r}=n;return r(["高い"])},col3_3:n=>{const{normalize:r}=n;return r(["低い、事前に構築されたインデックスを利用する"])},col4_1:n=>{const{normalize:r}=n;return r(["高い"])},col4_2:n=>{const{normalize:r}=n;return r(["高い"])},col4_3:n=>{const{normalize:r}=n;return r(["不要"])},col5_1:n=>{const{normalize:r}=n;return r(["より詳細な問い合わせに最適"])},col5_2:n=>{const{normalize:r}=n;return r(["効率と精度のバランス"])},col5_3:n=>{const{normalize:r}=n;return r(["幅広いクエリに対する一貫性と信頼性"])},col6_1:n=>{const{normalize:r}=n;return r(["深い文脈理解による高精度"])},col6_2:n=>{const{normalize:r}=n;return r(["中程度の精度で高速かつ効率的"])},col6_3:n=>{const{normalize:r}=n;return r(["確立された機能で拡張性が高い"])},col7_1:n=>{const{normalize:r}=n;return r(["リソースが大量に消費され、実装が複雑"])},col7_2:n=>{const{normalize:r}=n;return r(["深いクエリのコンテキストやニュアンスを捉えられない可能性がある"])},col7_3:n=>{const{normalize:r}=n;return r(["非常に具体的な検索や文脈に応じた検索ではパフォーマンスが低下する可能性があります"])},header0:n=>{const{normalize:r}=n;return r(["シーンに最適"])},header1:n=>{const{normalize:r}=n;return r(["粒度"])},header2:n=>{const{normalize:r}=n;return r(["クエリ時間の複雑さ"])},header3:n=>{const{normalize:r}=n;return r(["インデックス作成時間の複雑さ"])},header4:n=>{const{normalize:r}=n;return r(["トレーニング時間の複雑さ"])},header5:n=>{const{normalize:r}=n;return r(["検索品質"])},header6:n=>{const{normalize:r}=n;return r(["アドバンテージ"])},header7:n=>{const{normalize:r}=n;return r(["弱さ"])},subtitle:n=>{const{normalize:r}=n;return r(["以下の表は、リオーダラー、ベクトル検索、BM25 の包括的な比較を示し、各カテゴリの長所と短所を示しています。"])},title:n=>{const{normalize:r}=n;return r(["再配列器、ベクトル検索、BM25の比較"])}},what_is:n=>{const{normalize:r}=n;return r(["リアレンジャーとは何ですか？"])},what_is_answer_long:n=>{const{normalize:r}=n;return r([`検索の本質は、ほとんどのユーザーが望む結果を迅速かつ効率的に見つけることです。前世紀の BM25 や tf-idf などのキーワード マッチング アルゴリズムは、さまざまな検索結果のランク付けに成熟して使用されてきました。近年、ベクトル モデルに基づくコサイン類似度が非常に普及しており、多くのベクトル データベースで標準となっています。ただし、これらの方法は本質的に比較的単純であり、多くの場合、自然言語の微妙な点、そして最も重要なことに、ドキュメントとクエリの意図の間の相関情報が無視されます。

そこで誕生したのが「並べ替えモデル」です！再ランキング モデルは、実際には、検索から候補の初期セット (通常はベクトルベース/用語ベースの検索結果によって提供される) を取得し、ユーザーの検索意図との関連性を再評価する高度な AI モデルです。リフラワーは、テキストの表面レベルの一致を超えて、クエリとドキュメント コンテンツ間のより深い相互作用を調査します。`])},what_is_answer_long_ending:n=>{const{normalize:r}=n;return r(["並べ替え者 はサブドキュメントおよびサブクエリ レベルで動作するため、検索品質を大幅に向上させることができます。つまり、個々の単語やフレーズ、その意味、およびクエリとドキュメント内での相互の関連性が調べられます。これにより、より正確で状況に応じた一連の検索結果が得られます。"])},what_is_desc:n=>{const{normalize:r}=n;return r(["Reranker は、BM25 検索またはベクトルリコールの検索結果を最適化する AI モデルです。詳細については、記事をご覧ください。"])}},scenex:{caption_image_desc:n=>{const{normalize:r}=n;return r(["画像のテキスト説明を生成します。"])},caption_image_title:n=>{const{normalize:r}=n;return r(["ヘッダー画像"])},description:n=>{const{normalize:r}=n;return r(["あらゆるピクセルの背後にあるストーリーを発見する"])},example1:n=>{const{normalize:r}=n;return r(["このビデオは、牧草地で魅力的な白ウサギと蝶をフィーチャーした自然のショットのようです。ウサギはさまざまな方法で蝶と対話し、その独特の関係を示しています。周囲の自然は、このシンプルでありながら魅力的なシーンの美しさを高める絵のような背景を提供します。"])},generate_story_desc:n=>{const{normalize:r}=n;return r(["イメージに基づいてストーリーを作成し、通常はキャラクターの会話やモノローグをフィーチャーします。"])},generate_story_title:n=>{const{normalize:r}=n;return r(["ストーリーを生成する"])},intro1:n=>{const{normalize:r}=n;return r(["最先端の画像・動画理解AI"])},json_image_desc:n=>{const{normalize:r}=n;return r(["事前定義されたスキーマを使用して、画像から構造化された JSON 形式を生成します。これにより、画像から特定のデータを抽出できます。"])},json_image_title:n=>{const{normalize:r}=n;return r(["画像からJSONを抽出する"])},summarize_video_desc:n=>{const{normalize:r}=n;return r(["主要なイベントを強調して、ビデオの簡潔な概要を生成します。"])},summarize_video_title:n=>{const{normalize:r}=n;return r(["まとめ動画"])},visual_q_a_desc:n=>{const{normalize:r}=n;return r(["画像の内容に基づいて質問に答えます。"])},visual_q_a_title:n=>{const{normalize:r}=n;return r(["ビジュアルQ&A"])}},searchbar:{ask_on_current_page:n=>{const{normalize:r}=n;return r(["このページについて質問する..."])},find_solution:n=>{const{normalize:r}=n;return r(["対応するソリューションを生成..."])},hint:n=>{const{normalize:r}=n;return r(["製品、ニュース、質問を検索します"])},hotkey:n=>{const{normalize:r}=n;return r(["このページで質問するには / キーを押してください"])},hotkey1:n=>{const{normalize:r}=n;return r(["によると"])},hotkey2:n=>{const{normalize:r}=n;return r(["スイッチ"])},hotkey_long1:n=>{const{normalize:r}=n;return r(["任意のページで、 を押します。"])},hotkey_long3:n=>{const{normalize:r}=n;return r(["検索バーを開く"])},more_results:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["さらに ",e(o("_numMore"))," 件の結果"])},placeholder:n=>{const{normalize:r}=n;return r(["このページの内容について質問する"])},proposing_solution:n=>{const{normalize:r}=n;return r(["現在のページのコンテンツに基づいて回答を生成します..."])},required:n=>{const{normalize:r}=n;return r(["問題をさらに詳しく説明してください。"])},results:n=>{const{normalize:r}=n;return r(["結果"])}},searchscape:{description:n=>{const{normalize:r}=n;return r(["ナビゲーション、インタラクション、最適化: 製品検索の再定義"])}},semantic:{description:n=>{const{normalize:r}=n;return r(["既存の検索インフラストラクチャにおけるセマンティック ギャップを埋める"])}},share:{"Hacker News":n=>{const{normalize:r}=n;return r(["HNニュース"])},LinkedIn:n=>{const{normalize:r}=n;return r(["リンクトイン"])},facebook:n=>{const{normalize:r}=n;return r(["フェイスブック"])},reddit:n=>{const{normalize:r}=n;return r(["レディット"])},rss:n=>{const{normalize:r}=n;return r(["RSS購読"])},share_btn:n=>{const{normalize:r}=n;return r(["共有"])},twitter:n=>{const{normalize:r}=n;return r(["X（旧ツイッター）"])}},spectrum:{click_to_learn_more:n=>{const{normalize:r}=n;return r(["クリックして詳細を確認する"])},contextualization:n=>{const{normalize:r}=n;return r(["文脈の理解"])},contextualization_desc:n=>{const{normalize:r}=n;return r(["リランカーは、クエリの深い文脈上の関連性に基づいて、最初の検索結果を調整します。これにより、ユーザーが役立つと思われるコンテンツにさらに適合するようにランキングを最適化できます。"])},coreInfra:n=>{const{normalize:r}=n;return r(["コアインフラストラクチャ"])},coreInfra_desc:n=>{const{normalize:r}=n;return r(["コア インフラストラクチャは、パブリック クラウドおよびオンプレミスで検索インフラストラクチャ モデルを開発、展開、調整するためのクラウド ネイティブ レイヤーを提供し、サービスを簡単にスケールアップおよびスケールダウンできるようにします。"])},embedding_serving:n=>{const{normalize:r}=n;return r(["大規模なモデル ベクトルの展開"])},embedding_serving_description:n=>{const{normalize:r}=n;return r(["クラウドネイティブ テクノロジーを使用して、強力でスケーラブルなマイクロサービスを使用して大規模なモデルのベクトル推論を展開します。"])},embedding_tech:n=>{const{normalize:r}=n;return r(["ベクトルモデル"])},embedding_tech_description:n=>{const{normalize:r}=n;return r([`Jina AI では、ベクトル モデル テクノロジーを通じて人工知能アプリケーションの側面に革命を起こしています。このテクノロジーは、重要な情報が失われないようにしながら、複数の種類のデータを効果的に表現および圧縮する統合手段として機能します。私たちの中心的な目標は、複雑なデータセットを普遍的に理解可能なベクトルモデル形式に変換して、正確で詳細な人工知能分析をサポートすることです。

ベクトル モデルは、AI の分野で基本的かつ重要な役割を果たします。正確な画像認識や音声認識などの分野では、より微妙な詳細や違いを認識するのに役立ちます。自然言語処理では、文脈と感情の理解を強化し、会話型 AI と言語翻訳ツールをより正確にします。さらに、テキスト、オーディオ、ビデオなどのさまざまなコンテンツ形式に対するユーザーの好みを深く理解する必要がある複雑な推奨システムを構築する場合、この点でベクトル モデルが重要な役割を果たします。`])},embedding_tuning:n=>{const{normalize:r}=n;return r(["大規模モデルのベクトル微調整"])},embedding_tuning_description:n=>{const{normalize:r}=n;return r(["専門知識と業界データを組み込んで高品質の大規模モデル ベクトルをトレーニングし、特定のタスクのパフォーマンスを向上させます。"])},embeddings:n=>{const{normalize:r}=n;return r(["ベクトルモデル"])},embeddings_desc:n=>{const{normalize:r}=n;return r(["ベクトル モデルは現代の検索システムの基礎であり、マルチモーダル データを数値ベクトルとして表現します。このプロセスにより、単純なキーワードの一致をはるかに超えた、コンテンツのより微妙な理解が可能になります。"])},for_developers:n=>{const{normalize:r}=n;return r(["開発者向け"])},for_enterprise:n=>{const{normalize:r}=n;return r(["ビジネスのための"])},for_power_users:n=>{const{normalize:r}=n;return r(["上級ユーザー向け"])},grounding:n=>{const{normalize:r}=n;return r(["トレーサビリティ"])},grounding_desc:n=>{const{normalize:r}=n;return r(["読者は LLM を通じて入力と結果を洗練します。これらにより、最終的な回答の品質、読みやすさ、信頼性が向上します。"])},model_serving:n=>{const{normalize:r}=n;return r(["モデルの展開"])},model_serving_description:n=>{const{normalize:r}=n;return r(["調整されたモデルを運用環境にデプロイするには、多くの場合、GPU ホスティングなどの大量のリソースが必要になります。 MLOps は、スケーラブルで効率的かつ信頼性の高い方法で中規模から大規模のモデルを提供することに重点を置いています。"])},model_tuning:n=>{const{normalize:r}=n;return r(["モデルのチューニング"])},model_tuning_description:n=>{const{normalize:r}=n;return r(["タスク固有のデータセットで事前トレーニングされたモデルのパラメーターを調整して、パフォーマンスを向上させ、特定のアプリケーションに適応させます。"])},personalization:n=>{const{normalize:r}=n;return r(["パーソナライズする"])},personalization_desc:n=>{const{normalize:r}=n;return r(["ユーザーの指示に従って合成データを使用して、ドメイン固有のベクトル化機能と再配置機能を自動的にトレーニングします。"])},preprocessing:n=>{const{normalize:r}=n;return r(["前処理"])},preprocessing_desc:n=>{const{normalize:r}=n;return r(["前処理には、生データのクリーニング、正規化、検索システムが理解できる形式への変換が含まれます。"])},promptOps:n=>{const{normalize:r}=n;return r(["迅速な操作"])},promptOps_desc:n=>{const{normalize:r}=n;return r(["Prompt Ops は、クエリ拡張、LLM 入力、結果の書き換えなど、検索システムの入出力を改善します。これにより、検索がよりわかりやすくなり、より良い結果が得られます。"])},prompt_serving:n=>{const{normalize:r}=n;return r(["プロンプトワード展開"])},prompt_serving_description:n=>{const{normalize:r}=n;return r(["API を介してヒントをラップして提供することで、重いモデルをホストする必要がなくなります。この API は、共通の大規模言語モデル サービスを呼び出し、一連の操作における入出力のオーケストレーションを処理します。"])},prompt_tech:n=>{const{normalize:r}=n;return r(["即効性のある言葉とエージェント エンジニアリング"])},prompt_tech_description:n=>{const{normalize:r}=n;return r([`Jina AI では、大規模言語モデル (LLM) と通信する際のプロンプト ワード エンジニアリングの重要性を理解しています。これらのモデルが進化し続けるにつれて、私たちが発する言葉はますます複雑になり、深い推論や論理的思考が含まれるようになりました。この進歩は、LLM とプロンプトワードエンジニアリングの相互強化関係を浮き彫りにしています。

将来的には、LLM がコンパイラーの役割を引き受け、プロンプト ワードが新しいタイプのプログラミング言語に進化すると考えられます。これは、将来の技術スキルが従来のプログラミング スキルだけではなく、プロンプト ワードの技術を習得することに重点が置かれる可能性があることを意味します。 Jina AI の目標は、この技術革命をリードし、この新たな「言語」に習熟することで高度な人工知能を理解し、応用しやすくすることです。`])},prompt_tuning:n=>{const{normalize:r}=n;return r(["即時単語チューニング"])},prompt_tuning_description:n=>{const{normalize:r}=n;return r(["入力プロンプトを慎重に設計および調整して、その出力を特定の望ましい応答に向けるプロセスです。"])},representation:n=>{const{normalize:r}=n;return r(["表現学習"])},representation_desc:n=>{const{normalize:r}=n;return r(["ベクトル化は、マルチモーダル データを統一されたベクトル形式に変換します。これにより、検索システムは単純なキーワードを超えてコンテンツを理解して分類できるようになります。"])},rerankers:n=>{const{normalize:r}=n;return r(["並べ替え者"])},rerankers_desc:n=>{const{normalize:r}=n;return r(["再配置機能は、ベクトル モデルから初期結果を取得し、それらを最適化して、最も関連性の高い結果がユーザーに表示されるようにします。これは、ユーザーの意図に一致する高品質の検索結果を提供するために重要です。"])}},subscribe_system:{care_most:n=>{const{normalize:r}=n;return r(["一番大切にしていることは何ですか?"])},care_most_options:{accuracy:n=>{const{normalize:r}=n;return r(["正確さ"])},cost:n=>{const{normalize:r}=n;return r(["料金"])},other:n=>{const{normalize:r}=n;return r(["他の"])},scalability:n=>{const{normalize:r}=n;return r(["スループット"])},speed:n=>{const{normalize:r}=n;return r(["スピード"])}},care_most_required:n=>{const{normalize:r}=n;return r(["APIサービスを選ぶ際に一番気になることは何ですか?"])},company_size:n=>{const{normalize:r}=n;return r(["あなたの会社の規模はどれくらいですか?"])},company_size_required:n=>{const{normalize:r}=n;return r(["貴社の規模を教えていただくと、より良いサービスを提供することができます"])},company_url:n=>{const{normalize:r}=n;return r(["あなたの会社のウェブサイトは何ですか?"])},company_url_required:n=>{const{normalize:r}=n;return r(["貴社のウェブサイトについてお知らせいただくと、より良いサービスを提供することができます"])},contactName:n=>{const{normalize:r}=n;return r(["あなたの名前"])},contactName_required:n=>{const{normalize:r}=n;return r(["何と呼ぼうか？"])},contactTitle:n=>{const{normalize:r}=n;return r(["社内でどのように溶け込んでいますか?"])},contactTitle_required:n=>{const{normalize:r}=n;return r(["役職は必須です"])},contact_us:n=>{const{normalize:r}=n;return r(["お問い合わせ"])},domain_required:n=>{const{normalize:r}=n;return r(["あなたの仕事分野を教えていただくと、より良いサービスを提供することができます"])},email:n=>{const{normalize:r}=n;return r(["Eメール"])},email_contact:n=>{const{normalize:r}=n;return r(["あなたの連絡先メールアドレス"])},email_invalid:n=>{const{normalize:r}=n;return r(["無効な電子メール"])},email_required:n=>{const{normalize:r}=n;return r(["メールアドレスは必須です"])},fine_tuned_embedding:n=>{const{normalize:r}=n;return r(["プライベート ドメイン データ用の排他的なベクトル モデルが必要ですか?いつでもお待ちしております！"])},fine_tuned_reranker:n=>{const{normalize:r}=n;return r(["あなたの個人データを専門に再注文する人が必要ですか?来る！話し合ってみましょう！"])},full_survey:n=>{const{normalize:r}=n;return r(["アンケートにすべて回答すると、チームからより迅速な回答が得られます"])},get_new_key:n=>{const{normalize:r}=n;return r(["APIキーを取得する"])},get_update_blog_posts:n=>{const{normalize:r}=n;return r(["ブログ投稿の最新の更新を通知する"])},get_update_embeddings:n=>{const{normalize:r}=n;return r(["ベクトル モデルに関する最新ニュースを思い出してください"])},send:n=>{const{normalize:r}=n;return r(["送信"])},sign_up:n=>{const{normalize:r}=n;return r(["サブスクリプション"])},subscribe:n=>{const{normalize:r}=n;return r(["サブスクリプション"])},tell_domain:n=>{const{normalize:r}=n;return r(["自分の分野や方向性の微調整"])},usage_type:n=>{const{normalize:r}=n;return r(["どの用法があなたに最もよく当てはまりますか?"])},usage_type_options:{other:n=>{const{normalize:r}=n;return r(["他の"])},poc:n=>{const{normalize:r}=n;return r(["プロトタイピングまたは概念実証"])},production:n=>{const{normalize:r}=n;return r(["本番環境"])},research:n=>{const{normalize:r}=n;return r(["研究段階"])}},usage_type_required:n=>{const{normalize:r}=n;return r(["より良いサービスを提供するために、お客様の使用パターンをお知らせください。"])},used_product:n=>{const{normalize:r}=n;return r(["どのモデルを使用していますか?"])},used_product_required:n=>{const{normalize:r}=n;return r(["使用しているモデルまたは興味のあるモデルを選択してください"])}},think_gpt:{description:n=>{const{normalize:r}=n;return r(["LLM を強化して限界まで押し上げる"])}},toc:n=>{const{normalize:r}=n;return r(["目次"])},tokenizer:{advance_usage:n=>{const{normalize:r}=n;return r(["その他の機能については POST リクエストを使用してください"])},basic_usage:n=>{const{normalize:r}=n;return r(["GET リクエストを使用してトークンの数を直接返します"])},basic_usage_explain:n=>{const{normalize:r}=n;return r(["GET リクエストを送信するだけで、テキスト内のトークンの数をカウントできます。"])},change_content:n=>{const{normalize:r}=n;return r(["「コンテンツ」パラメータを変更してライブ結果を確認する"])},chars:n=>{const{normalize:r}=n;return r(["キャラクター"])},chinese:n=>{const{normalize:r}=n;return r(["中国語"])},chunk:n=>{const{normalize:r}=n;return r(["細かく切る"])},chunk_all:n=>{const{normalize:r}=n;return r(["すべてのブロック"])},chunking:n=>{const{normalize:r}=n;return r(["長い文書を稲妻の鞭のように速く切り分けます。"])},chunking_explain:n=>{const{normalize:r}=n;return r(["また、スプリッターを使用して長いドキュメントを小さなチャンクに分割し、ベクター モデルや並べ替えで処理しやすくすることもできます。私たちは共通の構造的ヒントを取り入れ、Markdown、HTML、LaTeX、CJK 言語など、さまざまな種類のコンテンツにわたって適切に機能する一連のルールとヒューリスティックを構築しました。"])},chunking_short:n=>{const{normalize:r}=n;return r(["細かく切る"])},chunks_in_total:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["合計チャンク数 ",e(o("_numChunks"))])},count_tokens_hint:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["<b>",e(o("_numTokens")),"</b> トークン、",e(o("_numChars"))," 文字。"])},description:n=>{const{normalize:r}=n;return r(["長いテキストをいくつかの塊に切り分けてマークアップします。"])},description_long:n=>{const{normalize:r}=n;return r(["当社のスライサーは、LLM がコンテキスト上の制約内で入力を管理し、モデルのパフォーマンスを最適化するのを支援するために重要です。これにより、開発者はトークンをカウントし、関連するテキスト セグメントを抽出できるため、効率的なデータ処理とコスト管理が保証されます。"])},description_long1:n=>{const{normalize:r}=n;return r(["長いテキストをチャンクに分割し、単語を分割するための無料 API。"])},english:n=>{const{normalize:r}=n;return r(["英語"])},explain:n=>{const{normalize:r}=n;return r(["セグメンタは、テキストをトークンまたはチャンクに変換する際の重要なコンポーネントです。トークンまたはチャンクは、ベクトル モデル/再配列器または LLM によって処理される基本的なデータ単位です。トークンは、単語全体、単語の一部、または単一の文字を表すことができます。"])},faq_v1:{answer1:n=>{const{normalize:r}=n;return r(["スライサーは無料でご利用いただけます。 API キーを提供すると、より高いレート制限にアクセスでき、キーは請求されません。"])},answer10:n=>{const{normalize:r}=n;return r(["チャンキング技術は、西洋言語に加えて、中国語、日本語、韓国語でも機能します。"])},answer2:n=>{const{normalize:r}=n;return r(["API キーを使用しない場合は、20 RPM のレート制限でスライサーにアクセスできます。"])},answer3:n=>{const{normalize:r}=n;return r(["API キーを使用すると、200 RPM のレート制限でスライサーにアクセスできます。プレミアム有料ユーザーの場合、レート制限は 1000 RPM です。"])},answer4:n=>{const{normalize:r}=n;return r(["いいえ、API キーはより高いレート制限にアクセスするためにのみ使用されます。"])},answer5:n=>{const{normalize:r}=n;return r(["はい、スライサーは多言語対応で、100 以上の言語をサポートしています。"])},answer6:n=>{const{normalize:r}=n;return r(["GET リクエストはテキスト内のトークンの数をカウントするためにのみ使用されるため、これをカウンターとしてアプリケーションに簡単に統合できます。 POST リクエストは、最初と最後の N 個のトークンを返すなど、より多くのパラメーターと機能をサポートします。"])},answer7:n=>{const{normalize:r}=n;return r(["リクエストごとに最大 64,000 文字を送信できます。"])},answer8:n=>{const{normalize:r}=n;return r(["タイル機能は、共通の構造上の手がかりに基づいて長い文書を小さなチャンクに分割し、テキストが意味のあるチャンクに正確に分割されるようにします。基本的に、これは、意味上の境界 (文末、段落区切り文字、句読点、および特定の接続詞など) と一般に一致する特定の構文上の特徴に基づいてテキストを分割する (大きな!) 正規表現パターンです。それは意味論的な分割ではありません。この (大きな) 正規表現は、正規表現の制限内で可能な限り強力です。複雑さとパフォーマンスのバランスをとります。正規表現は真の意味の理解を達成することはできませんが、共通の構造上の手がかりを通じてコン​​テキストの適切な近似を提供できます。"])},answer9:n=>{const{normalize:r}=n;return r(["入力に特別なトークンが含まれている場合、トークナイザーはそれらを「special_tokens」フィールドに入れます。こうすることで、それらを簡単に識別し、インジェクション攻撃を防ぐために LLM に入力する前にテキストを削除するなど、下流のタスクに基づいて適切に処理できます。"])},question1:n=>{const{normalize:r}=n;return r(["スライサーの値段はいくらですか？"])},question10:n=>{const{normalize:r}=n;return r(["チャンキングは英語以外の言語もサポートしていますか?"])},question2:n=>{const{normalize:r}=n;return r(["API キーを提供しない場合のレート制限は何ですか?"])},question3:n=>{const{normalize:r}=n;return r(["API キーを指定した場合、レート制限はどのくらいになりますか?"])},question4:n=>{const{normalize:r}=n;return r(["私の API キーからトークンを請求してくれますか?"])},question5:n=>{const{normalize:r}=n;return r(["スライサーは複数の言語をサポートしていますか?"])},question6:n=>{const{normalize:r}=n;return r(["GET リクエストと POST リクエストの違いは何ですか?"])},question7:n=>{const{normalize:r}=n;return r(["リクエストごとに分割できる単語の最大長はどれくらいですか?"])},question8:n=>{const{normalize:r}=n;return r(["ダイシング機能はどのように機能しますか?それはセマンティックダイシングですか？"])},question9:n=>{const{normalize:r}=n;return r(["スプリッターで「endoftext」のような特別なトークンを処理するにはどうすればよいですか?"])},title:n=>{const{normalize:r}=n;return r(["セグメンターに関するよくある質問"])}},free_api:n=>{const{normalize:r}=n;return r(["スライサーは無料でご利用いただけます。 API キーを提供すると、より高いレート制限にアクセスでき、キーは請求されません。"])},input_text:n=>{const{normalize:r}=n;return r(["テキストを入力してください"])},is_free:n=>{const{normalize:r}=n;return r(["スライサーは無料です！"])},is_free_description:n=>{const{normalize:r}=n;return r(["API キーを提供すると、より高いレート制限にアクセスでき、キーは請求されません。"])},japanese:n=>{const{normalize:r}=n;return r(["日本語"])},korean:n=>{const{normalize:r}=n;return r(["韓国人"])},parameters:{auth_token:n=>{const{normalize:r}=n;return r(["レート制限を高めるには API キーを追加します"])},auth_token_explain:n=>{const{normalize:r}=n;return r(["より高いレート制限にアクセスするには、Jina API キーを入力してください。最新のレート制限情報については、以下の表を参照してください。"])},head:n=>{const{normalize:r}=n;return r(["最初の N 個のトークンを返す"])},head_explain:n=>{const{normalize:r}=n;return r(["指定されたコンテンツの最初の N 個のトークンを返します。ボーダー専用。 「しっぽ」とは併用できません。"])},learn_more:n=>{const{normalize:r}=n;return r(["もっと詳しく知る"])},max_chunk_length:n=>{const{normalize:r}=n;return r(["各ブロックの最大長"])},max_chunk_length_explain:n=>{const{normalize:r}=n;return r(["各ブロック内の最大文字数。実際、テキスト内に自然な境界がある場合、ブロックの長さはこの値よりも小さくなる可能性があります。"])},return_chunks:n=>{const{normalize:r}=n;return r(["サイコロに戻る"])},return_chunks_explain:n=>{const{normalize:r}=n;return r(["共通の構造上の手がかりに基づいて、さまざまなテキスト タイプや特殊なケースに適応するヒューリスティック ルールを使用して、入力を意味的に意味のある部分にスライスします。"])},return_tokens:n=>{const{normalize:r}=n;return r(["単語分割結果を返すかどうか"])},return_tokens_explain:n=>{const{normalize:r}=n;return r(["トークンとそれに対応する ID を応答で返します。切り替えて結果の視覚化を表示します。"])},tail:n=>{const{normalize:r}=n;return r(["最後の N 個のトークンを返します"])},tail_explain:n=>{const{normalize:r}=n;return r(["指定されたコンテンツの最後の N 個のトークンを返します。ボーダー専用。 「ヘッド」では使用できません。"])},type:n=>{const{normalize:r}=n;return r(["セグメンタ"])},type_explain:n=>{const{normalize:r}=n;return r(["使用するトークナイザーを選択します。"])},used_by_models:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_usedBy"))," の場合。"])}},remove_boundary_cues:n=>{const{normalize:r}=n;return r(["改行を削除する"])},remove_boundary_cues_explain:n=>{const{normalize:r}=n;return r(["入力からすべての改行を削除します (主要な境界のヒント)。これにより、質問がより難しくなり、応答がどのように変化するかを確認してください。"])},show_space:n=>{const{normalize:r}=n;return r(["先頭/末尾のスペースを表示する"])},table:{td_1_0:n=>{const{normalize:r}=n;return r(["テキストをセグメント化し、最初と最後の N 個のトークンを数えて取得します。"])},td_1_1:n=>{const{normalize:r}=n;return r(["20rpm"])},td_1_2:n=>{const{normalize:r}=n;return r(["200rpm"])},td_1_3:n=>{const{normalize:r}=n;return r(["1000rpm"])},td_1_4:n=>{const{normalize:r}=n;return r(["無料"])},td_1_5:n=>{const{normalize:r}=n;return r(["800ミリ秒"])}},title:n=>{const{normalize:r}=n;return r(["セグメンタ API"])},token_index:n=>{const{normalize:r,interpolate:e,named:o}=n;return r(["トークンコード: ",e(o("_index"))])},usage:n=>{const{normalize:r}=n;return r(["使用法"])},visualization:n=>{const{normalize:r}=n;return r(["視覚化"])},what_is:n=>{const{normalize:r}=n;return r(["セグメンタとは何ですか?"])}},translator:{cta:n=>{const{normalize:r,interpolate:e,named:o}=n;return r([e(o("_lang"))," コードに翻訳されました"])},select_language:n=>{const{normalize:r}=n;return r(["言語"])}},vectordb:{description:n=>{const{normalize:r}=n;return r(["必要なのは Python ベクトル データベースだけです - それ以上でもそれ以下でもありません"])}},zzz:n=>{const{normalize:r}=n;return r(["zzz"])}};export{t as default};
