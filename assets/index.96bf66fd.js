var t={PRODUCT_DESCRIPTION:n=>{const{normalize:e}=n;return e(["Wir bieten erstklassige Einbettungen, Reranker, LLM-Reader und Prompt-Optimierer sowie bahnbrechende Such-KI f\xFCr multimodale Daten."])},SEO_TAG_LINE:n=>{const{normalize:e}=n;return e(["Ihre Suchgrundlage, aufgeladen."])},about_us_page:{approach:n=>{const{normalize:e}=n;return e(["Unser Vorgehen"])},approach_connect_dots:n=>{const{normalize:e}=n;return e(["Zusammenh\xE4nge: Von Power-Usern zu Unternehmen"])},approach_connect_dots_description:n=>{const{normalize:e}=n;return e(["Warum ist der Fokus auf Power-User f\xFCr unser unternehmensorientiertes Modell so wichtig? Weil es darum geht, fr\xFChe Beziehungen aufzubauen. Indem wir uns jetzt an Power-User wenden, bauen wir Br\xFCcken zu den Unternehmen, die sie in Zukunft beeinflussen werden. Es handelt sich um eine strategische Ma\xDFnahme \u2013 eine langfristige Investition, um sicherzustellen, dass unser Unternehmensangebot im Vordergrund steht, wenn diese Power-User in Entscheidungsrollen innerhalb von Organisationen aufsteigen."])},approach_content1:n=>{const{normalize:e}=n;return e(["In der sich schnell entwickelnden Welt der KI m\xFCssen Strategien sowohl flexibel als auch zukunftsorientiert sein. W\xE4hrend sich unser Kernangebot weiterhin auf Unternehmen konzentriert, hat sich die KI-Landschaft in einer Weise ver\xE4ndert, die ein \xDCberdenken unseres Ansatzes zur Kundenakquise erforderlich macht. Aus diesem Grund ist die Einf\xFChrung von Power-Usern als Einstiegspunkt in unseren Funnel nicht nur innovativ, sondern auch entscheidend f\xFCr unser nachhaltiges Wachstum im Unternehmenssektor."])},approach_content2:n=>{const{normalize:e}=n;return e(["Bei Jina AI besteht unsere Strategie darin, proaktiv statt reaktiv zu sein. Durch die Einbeziehung von Power-Usern als Einstiegspunkt in den Funnel stellen wir sicher, dass wir nicht nur aktuelle Markttrends erfassen, sondern auch strategisch f\xFCr zuk\xFCnftiges Unternehmenswachstum ger\xFCstet sind. Unser Engagement f\xFCr Unternehmen bleibt unersch\xFCtterlich; Unser Ansatz zur Erreichung dieser Ziele ist jedoch innovativ, robust und vor allem zukunftsorientiert."])},approach_content4:n=>{const{normalize:e}=n;return e(['Jeder m\xF6chte eine bessere Suche. Bei Jina AI erm\xF6glichen wir eine bessere Suche, indem wir die <span class="text-primary text-bold">Search Foundation</span> bereitstellen, die aus Embeddings, Rerankers, Prompt Ops und Infra besteht. Diese Komponenten arbeiten zusammen, um die Art und Weise zu revolutionieren, wie wir Daten suchen und verstehen. Dies f\xFChrt zu einem verbesserten Sucherlebnis, Benutzervertrauen, einer direkten Umsatzsteigerung und der Erschlie\xDFung neuen Gesch\xE4ftswachstums.'])},approach_miss_mark:n=>{const{normalize:e}=n;return e(["Warum traditionelle MLOps das Ziel verfehlen"])},approach_miss_mark_description:n=>{const{normalize:e}=n;return e(["Obwohl der Zustrom von Power-Usern betr\xE4chtlich ist, sind herk\xF6mmliche MLOps-Tools nicht in der Lage, deren Anforderungen zu erf\xFCllen. Diese Werkzeuge erinnern an die Verwendung eines Traktors zum Navigieren durch die Stra\xDFen der Stadt \u2013 sie sind schwer und oft \xFCbertrieben. Die Entwickler der neuen Generation verlangen agile, intuitive Tools, die ihr schnelles Entwicklungstempo erg\xE4nzen."])},approach_new_paradigm:n=>{const{normalize:e}=n;return e(["Aufforderungsbasierte Technologie: Ein neues Paradigma"])},approach_new_paradigm_description:n=>{const{normalize:e}=n;return e([`Das Jahr 2023 l\xE4utete eine bedeutende Ver\xE4nderung ein: den Aufstieg der prompt-basierten Technologie. Durch die Vereinfachung des KI-Entwicklungsprozesses wurde der Zugang zu KI-Tools demokratisiert. Jetzt k\xF6nnen auch diejenigen ohne umfangreiche Programmiererfahrung \u2013 sogenannte \u201EPower-User\u201C \u2013 an der KI-Entwicklung teilnehmen, ohne die steilen Lernkurven zu durchlaufen, die mit Tools wie Pytorch, Docker oder Kubernetes verbunden sind.

Wenn man eine Parallele zieht, \xE4hnelt dies der Entwicklung des Personal Computing. Urspr\xFCnglich bedienten nur Technikexperten Computer. Aber mit dem Aufkommen benutzerfreundlicher Schnittstellen k\xF6nnte ein breiteres Publikum teilnehmen. Heute erleben wir mit der auf Eingabeaufforderungen basierenden Technologie eine \xE4hnliche Demokratisierung der KI.`])},awards:n=>{const{normalize:e}=n;return e(["Auszeichnungen und Anerkennung"])},berlin:n=>{const{normalize:e}=n;return e(["Berlin, Deutschland"])},berlin_address:n=>{const{normalize:e}=n;return e(["Prinzessinnenstra\xDFe 19-20, 10969 Berlin, Deutschland"])},berlin_address2:n=>{const{normalize:e}=n;return e(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berlin, Deutschland"])},bj:n=>{const{normalize:e}=n;return e(["Peking, China"])},bj_address:n=>{const{normalize:e}=n;return e(["Ebene 5, Geb\xE4ude 6, Nr. 48 Haidian West St. Peking Haidian, China"])},brochure_info:n=>{const{normalize:e}=n;return e(["Ihr Leitfaden zu unserem Unternehmen erwartet Sie"])},description:n=>{const{normalize:e}=n;return e(["Die Zukunft beginnt hier."])},download_brochure1:n=>{const{normalize:e}=n;return e(["Brosch\xFCre herunterladen"])},download_docarray_logo:n=>{const{normalize:e}=n;return e(["Laden Sie das DocArray-Logo herunter"])},download_docarray_logo_desc:n=>{const{normalize:e}=n;return e(["Greifen Sie auf das DocArray-Logo zu, ein Open-Source-Projekt, das von Jina AI initiiert und im Dezember 2022 zur Linux Foundation beigetragen hat. Verf\xFCgbar im Hell- und Dunkelmodus, in den Formaten PNG und SVG."])},download_jina_logo:n=>{const{normalize:e}=n;return e(["Laden Sie das Jina AI-Logo herunter"])},download_jina_logo_desc:n=>{const{normalize:e}=n;return e(["Holen Sie sich das Jina AI-Logo sowohl im hellen als auch im dunklen Modus, verf\xFCgbar in den Formaten PNG und SVG. Dieses Logo ist eine eingetragene Marke beim Amt der Europ\xE4ischen Union f\xFCr geistiges Eigentum (EUIPO)."])},download_logo:n=>{const{normalize:e}=n;return e(["Logos herunterladen"])},employees:n=>{const{normalize:e}=n;return e(["Mitarbeiter"])},empower_developers:n=>{const{normalize:e}=n;return e(["unterst\xFCtzte Entwickler"])},fastApiCaption:n=>{const{normalize:e}=n;return e(["Seit 2021 \xFCber 20.000 US-Dollar gespendet."])},founded:n=>{const{normalize:e}=n;return e(["Gegr\xFCndet"])},founded_in:n=>{const{normalize:e}=n;return e(["Gegr\xFCndet in"])},investors:n=>{const{normalize:e}=n;return e(["Unsere Investoren"])},linuxFoundationCaption:n=>{const{normalize:e}=n;return e(["Leistet ab 2022 einen j\xE4hrlichen Beitrag von 10.000 US-Dollar."])},mission:n=>{const{normalize:e}=n;return e(["Unsere Aufgabe"])},mission_content1:n=>{const{normalize:e}=n;return e(["Unsere Schl\xFCsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Model-Tuning und Model-Serving, verk\xF6rpern unser Engagement f\xFCr die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative wollen wir Innovation, Zusammenarbeit und Transparenz f\xF6rdern und skalierbare, effiziente und robuste L\xF6sungen gew\xE4hrleisten. Jina AI ist mehr als nur ein Unternehmen; es ist eine Community, die sich daf\xFCr einsetzt, Unternehmen dabei zu unterst\xFCtzen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein."])},mission_content2:n=>{const{normalize:e}=n;return e(["Im Mittelpunkt von Jina AI steht unsere Mission, das Portal zur multimodalen KI f\xFCr eine vielf\xE4ltige Kundschaft zu sein, von Power-Usern und Entwicklern bis hin zu Unternehmen. Wir glauben fest an die Leistungsf\xE4higkeit von Open Source und widmen uns der Entwicklung fortschrittlicher, zug\xE4nglicher Tools f\xFCr die KI-Community. Unsere Schl\xFCsseltechnologien, darunter Prompt-Tuning, Prompt-Serving, Embedding-Tuning und Embedding-Serving, verk\xF6rpern unser Engagement f\xFCr die Demokratisierung des Zugangs zu KI. Mit unserer Open-Source-Initiative streben wir danach, Innovation, Zusammenarbeit und Transparenz zu f\xF6rdern und skalierbare, effiziente und robuste L\xF6sungen sicherzustellen. Jina AI ist mehr als nur ein Unternehmen; Es handelt sich um eine Community, deren Ziel es ist, Unternehmen dabei zu unterst\xFCtzen, die dynamischen Herausforderungen des digitalen Zeitalters zu meistern und in ihren Bereichen erfolgreich zu sein."])},mission_content3:n=>{const{normalize:e}=n;return e(["Unsere Mission bei Jina AI besteht darin, die Weiterentwicklung der multimodalen KI durch innovative Einbettungs- und Eingabeaufforderungstechnologien voranzutreiben und uns dabei insbesondere auf Bereiche wie die Verarbeitung nat\xFCrlicher Sprache, Bild- und Videoanalyse sowie modal\xFCbergreifende Dateninteraktion zu konzentrieren. Diese Spezialisierung erm\xF6glicht es uns, einzigartige L\xF6sungen bereitzustellen, die komplexe Daten aus mehreren Quellen in umsetzbare Erkenntnisse und bahnbrechende Anwendungen umwandeln."])},mit_report_title:n=>{const{normalize:e}=n;return e(["Multimodal: die neue Grenze der KI"])},mit_techreview:n=>{const{normalize:e}=n;return e(["MIT Technology Review"])},numfocusCaption:n=>{const{normalize:e}=n;return e(["Spendet ab 2022 regelm\xE4\xDFig jeden Monat."])},office:n=>{const{normalize:e}=n;return e(["Unsere B\xFCros"])},otherProjectsCaption:n=>{const{normalize:e}=n;return e(["\xDCber Github Sponsorship \xFCber 3.000 US-Dollar gespendet."])},our_answer:n=>{const{normalize:e}=n;return e(["Auf jeden Fall, Yann. Wir sind dabei und bauen Br\xFCcken in eine multimodale KI-Zukunft!"])},pythonSoftwareFoundationCaption:n=>{const{normalize:e}=n;return e(["Hat eine einmalige Spende in H\xF6he von 10.000 US-Dollar geleistet und mehrere PyCon-Veranstaltungen gesponsert, darunter in Deutschland, Italien, China und den USA."])},sefo:{layer0:n=>{const{normalize:e}=n;return e(["Endbenutzeranwendungen"])},layer1:n=>{const{normalize:e}=n;return e(["RAG / Orchestrierung"])},layer3:n=>{const{normalize:e}=n;return e(["GPU / Mobil / Edge / lokales Computing"])}},segmentFaultCaption:n=>{const{normalize:e}=n;return e(["Hat eine einmalige Spende in H\xF6he von 6.000 US-Dollar geleistet."])},stats_1:n=>{const{normalize:e}=n;return e(["Jina AI wurde im Februar 2020 gegr\xFCndet und hat sich schnell zu einem globalen Pionier der multimodalen KI-Technologie entwickelt. Innerhalb eines beeindruckenden Zeitrahmens von 20 Monaten haben wir erfolgreich 37,5 Millionen US-Dollar eingesammelt und damit unsere starke Position in der KI-Branche unterstrichen. Unsere bahnbrechende Technologie, Open-Source auf GitHub, hat \xFCber 40.000 Entwicklern auf der ganzen Welt die M\xF6glichkeit gegeben, anspruchsvolle multimodale Anwendungen nahtlos zu erstellen und bereitzustellen."])},stats_2:n=>{const{normalize:e}=n;return e(["Im Jahr 2023 haben wir erhebliche Fortschritte bei der Weiterentwicklung von Tools zur KI-Generierung gemacht, die auf multimodaler Technologie basieren. Von dieser Innovation haben \xFCber 250.000 Benutzer weltweit profitiert und eine Vielzahl einzigartiger Gesch\xE4ftsanforderungen erf\xFCllt. Von der Erleichterung des Gesch\xE4ftswachstums \xFCber die Verbesserung der betrieblichen Effizienz bis hin zur Kostenoptimierung setzt sich Jina AI daf\xFCr ein, Unternehmen zu bef\xE4higen, im multimodalen Zeitalter hervorragende Leistungen zu erbringen."])},stats_4:n=>{const{normalize:e}=n;return e(['Jina AI wurde 2020 in Berlin gegr\xFCndet und ist ein f\xFChrendes Unternehmen f\xFCr Such-KI. Wir stellen die <span class="text-primary text-bold">Search Foundation</span> bereit, den Kern f\xFCr GenAI und multimodale Anwendungen. Unsere Mission ist es, Unternehmen und Entwicklern dabei zu helfen, multimodale Daten mit einer besseren Suche zur Wertsch\xF6pfung freizusetzen. Als kommerzielles Open-Source-Unternehmen m\xF6gen wir offene Innovation.'])},stats_v1:n=>{const{normalize:e}=n;return e(["Suche/account"])},subtitle:n=>{const{normalize:e}=n;return e(["Revolutionierung der Inhaltserstellung durch KI-generierte L\xF6sungen, um unendliche M\xF6glichkeiten zu erschlie\xDFen. Die Zukunft KI-generierter Inhalte gestalten und die menschliche Kreativit\xE4t f\xF6rdern."])},sz:n=>{const{normalize:e}=n;return e(["Shenzhen, China"])},sz_address:n=>{const{normalize:e}=n;return e(["402, Etage 4, Fu'an Technology Building, Shenzhen Nanshan, China"])},team:n=>{const{normalize:e}=n;return e(["Im Portal von Jina AI"])},team_content1:n=>{const{normalize:e}=n;return e(["Von verschiedenen Orten der Welt aus gestalten wir die Zukunft der KI. Unsere unterschiedlichen Perspektiven bereichern unsere Arbeit und bringen Innovationen hervor. In diesem Portal leben wir unsere Individualit\xE4t und verfolgen leidenschaftlich unsere Tr\xE4ume. Willkommen im Portal der KI-Zukunft."])},team_join:n=>{const{normalize:e}=n;return e(["Begleiten Sie uns"])},technologies:n=>{const{normalize:e}=n;return e(["Technologien"])},title:n=>{const{normalize:e}=n;return e(["\xDCber Jina AI"])},title0:n=>{const{normalize:e}=n;return e(["Die Zukunft"])},title1:n=>{const{normalize:e}=n;return e(["Beginnt"])},title2:n=>{const{normalize:e}=n;return e(["Hier"])},title3:n=>{const{normalize:e}=n;return e(["Beginnt hier"])},understand_our_strength:n=>{const{normalize:e}=n;return e(["Verstehen Sie unsere St\xE4rke"])},understand_our_view2:n=>{const{normalize:e}=n;return e(["Verstehen Sie die Grundlagen der Suche"])},users:n=>{const{normalize:e}=n;return e(["registrierte Benutzer"])},value:n=>{const{normalize:e}=n;return e(["Unser Wert"])},value_content1:n=>{const{normalize:e}=n;return e([`Wir glauben, dass Offenheit Innovationen beschleunigen und die Zusammenarbeit f\xF6rdern kann. Wir sind nicht nur Bef\xFCrworter, sondern aktive Mitwirkende, die erheblich in die Open-Source-Community investieren.

Von unserer fr\xFChen Spenderrolle f\xFCr FastAPI bis hin zur aktiven Unterst\xFCtzung der Linux Foundation und der Python Software Foundation ist es uns ein Herzensanliegen, etwas zur\xFCckzugeben. Aber das ist noch nicht alles: Wir haben unsere Modelle und Projekte auch als Open Source freigegeben und teilen unser Fachwissen mit der Welt.`])},vision:n=>{const{normalize:e}=n;return e(["Unsere Aufgabe"])},vision_content1:n=>{const{normalize:e}=n;return e(["Inspiriert von Yann LeCuns Einsicht, dass \u201E"])},vision_content3:n=>{const{normalize:e}=n;return e(['Die Zukunft der KI ist <span class="text-primary text-bold">multimodal</span>, und wir sind ein Teil davon. Wir sind uns bewusst, dass Unternehmen bei der Nutzung multimodaler Daten vor Herausforderungen stehen. Als Reaktion darauf engagieren wir uns in der <span class="text-primary text-bold">Search Foundation</span>, um Unternehmen und Entwicklern dabei zu helfen, besser zu suchen und multimodale Daten f\xFCr das Unternehmenswachstum zu nutzen.'])},yannlecun_quote:n=>{const{normalize:e}=n;return e(["Ein k\xFCnstliches Intelligenzsystem, das allein auf W\xF6rter und S\xE4tze trainiert wird, wird niemals ann\xE4hernd das menschliche Verst\xE4ndnis erreichen."])}},api_general_faq:{answer1:n=>{const{normalize:e}=n;return e(["Ja, derselbe API-Schl\xFCssel ist f\xFCr alle Suchgrundlagenprodukte von Jina AI g\xFCltig. Dies umfasst die APIs zum Einbetten, Neuranking, Lesen und Feinabstimmen, wobei die Token zwischen allen Diensten geteilt werden."])},answer12:n=>{const{normalize:e}=n;return e(["Wir halten uns an strenge Datenschutzrichtlinien und verwenden keine Benutzereingabedaten zum Training unserer Modelle."])},answer3:n=>{const{normalize:e}=n;return e(["Ja, die Token-Nutzung kann auf der Registerkarte \u201EToken kaufen\u201C durch Eingabe Ihres API-Schl\xFCssels \xFCberwacht werden, sodass Sie den Nutzungsverlauf und die verbleibenden Token anzeigen k\xF6nnen."])},answer4:n=>{const{normalize:e}=n;return e(["Wenn Sie einen aufgeladenen Schl\xFCssel verloren haben und ihn zur\xFCckholen m\xF6chten, wenden Sie sich bitte mit Ihrer registrierten E-Mail-Adresse an den Support von jina.ai, um Hilfe zu erhalten."])},answer5:n=>{const{normalize:e}=n;return e(["Nein, unsere API-Schl\xFCssel haben kein Ablaufdatum. Wenn Sie jedoch den Verdacht haben, dass Ihr Schl\xFCssel kompromittiert wurde und Sie ihn zur\xFCckziehen oder seine Token auf einen neuen Schl\xFCssel \xFCbertragen m\xF6chten, wenden Sie sich bitte an unser Support-Team, um Hilfe zu erhalten."])},answer6:n=>{const{normalize:e}=n;return e(["Dies liegt daran, dass unsere serverlose Architektur bestimmte Modelle in Zeiten geringer Nutzung entlastet. Die erste Anfrage aktiviert oder \u201Ew\xE4rmt\u201C das Modell auf, was einige Sekunden dauern kann. Nach dieser ersten Aktivierung werden nachfolgende Anfragen viel schneller bearbeitet."])},question1:n=>{const{normalize:e}=n;return e(["Kann ich denselben API-Schl\xFCssel zum Einbetten, Neuranking, f\xFCr Reader und zur Feinabstimmung von APIs verwenden?"])},question12:n=>{const{normalize:e}=n;return e(["Werden Benutzereingabedaten zum Training Ihrer Modelle verwendet?"])},question3:n=>{const{normalize:e}=n;return e(["Kann ich die Token-Nutzung meines API-Schl\xFCssels \xFCberwachen?"])},question4:n=>{const{normalize:e}=n;return e(["Was soll ich tun, wenn ich meinen API-Schl\xFCssel vergesse?"])},question5:n=>{const{normalize:e}=n;return e(["Laufen API-Schl\xFCssel ab?"])},question6:n=>{const{normalize:e}=n;return e(["Warum ist die erste Anfrage bei manchen Modellen langsam?"])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufige Fragen zu APIs"])}},autotune:{base_model:n=>{const{normalize:e}=n;return e(["Basismodell zum Feintuning"])},check_data:n=>{const{normalize:e}=n;return e(["Synthetische Daten herunterladen"])},check_model:n=>{const{normalize:e}=n;return e(["Feinabgestimmtes Modell herunterladen"])},data_size:n=>{const{normalize:e}=n;return e(["Synthetische Daten generiert"])},description:n=>{const{normalize:e}=n;return e(["Erhalten Sie fein abgestimmte Einbettungen f\xFCr jede gew\xFCnschte Dom\xE4ne."])},description_long:n=>{const{normalize:e}=n;return e(["Sagen Sie uns einfach, in welchem \u200B\u200BBereich Ihre Einbettungen herausragend sein sollen, und wir liefern automatisch ein gebrauchsfertiges, fein abgestimmtes Einbettungsmodell f\xFCr diesen Bereich."])},does_it_work_tho:n=>{const{normalize:e}=n;return e(["Aber funktioniert es trotzdem?"])},does_it_work_tho_explain:n=>{const{normalize:e}=n;return e(["Die automatische Feinabstimmung verspricht wie durch Zauberhand feinabgestimmte Einbettungen f\xFCr jede gew\xFCnschte Dom\xE4ne. Aber funktioniert das wirklich? Das ist durchaus fraglich. Um das herauszufinden, haben wir es an einer Vielzahl von Dom\xE4nen und Basismodellen getestet. Sehen Sie sich unten die Rosinenpickerei und die Zitronenpickerei an."])},domain_instruction:n=>{const{normalize:e}=n;return e(["Dom\xE4nenanweisung"])},embedding_provider:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie ein Basis-Einbettungsmodell"])},eval_evaluation:n=>{const{normalize:e}=n;return e(["Validierung"])},eval_map:n=>{const{normalize:e}=n;return e(["KARTE"])},eval_mrr:n=>{const{normalize:e}=n;return e(["MRR"])},eval_ndcg:n=>{const{normalize:e}=n;return e(["NDCG"])},eval_performance_before_after:n=>{const{normalize:e}=n;return e(["Leistung im synthetischen Validierungssatz vor und nach der Feinabstimmung"])},eval_syntheticDataSize:n=>{const{normalize:e}=n;return e(["Gesamt"])},eval_test:n=>{const{normalize:e}=n;return e(["Echte Daten zum Testen"])},eval_training:n=>{const{normalize:e}=n;return e(["Ausbildung"])},faq_v1:{answer1:n=>{const{normalize:e}=n;return e(["Die Funktion befindet sich derzeit in der Betaphase und kostet 1 Mio. Token pro fein abgestimmtem Modell. Sie k\xF6nnen Ihren vorhandenen API-Schl\xFCssel aus der Embedding/Reranker-API verwenden, wenn dieser \xFCber gen\xFCgend Token verf\xFCgt, oder Sie k\xF6nnen einen neuen API-Schl\xFCssel erstellen, der 1 Mio. kostenlose Token enth\xE4lt."])},answer10:n=>{const{normalize:e}=n;return e(["Derzeit nicht. Beachten Sie, dass sich diese Funktion noch in der Betaphase befindet. Die \xF6ffentliche Speicherung der fein abgestimmten Modelle und synthetischen Daten im Hugging Face-Modell-Hub hilft uns und der Community, die Qualit\xE4t des Trainings zu bewerten. In Zukunft planen wir, eine private Speicheroption anzubieten."])},answer11:n=>{const{normalize:e}=n;return e(["Da alle feinabgestimmten Modelle auf Hugging Face hochgeladen werden, k\xF6nnen Sie \xFCber SentenceTransformers darauf zugreifen, indem Sie einfach den Modellnamen angeben."])},answer12:n=>{const{normalize:e}=n;return e(["Bitte \xFCberpr\xFCfen Sie Ihren Spam-Ordner. Wenn Sie ihn immer noch nicht finden k\xF6nnen, wenden Sie sich bitte \xFCber die von Ihnen angegebene E-Mail-Adresse an unser Support-Team."])},answer2:n=>{const{normalize:e}=n;return e(["Sie m\xFCssen keine Trainingsdaten bereitstellen. Beschreiben Sie einfach Ihre Zieldom\xE4ne (die Dom\xE4ne, f\xFCr die die fein abgestimmten Einbettungen optimiert werden sollen) in nat\xFCrlicher Sprache oder verwenden Sie eine URL als Referenz. Unser System generiert dann synthetische Daten zum Trainieren des Modells."])},answer3:n=>{const{normalize:e}=n;return e(["Etwa 30 Minuten."])},answer4:n=>{const{normalize:e}=n;return e(["Die feinabgestimmten Modelle und synthetischen Daten werden \xF6ffentlich im Hugging Face-Modell-Hub gespeichert."])},answer5:n=>{const{normalize:e}=n;return e(["Das System verwendet die Reader-API, um den Inhalt von der URL abzurufen. Anschlie\xDFend analysiert es den Inhalt, um den Ton und die Dom\xE4ne zusammenzufassen, die es als Richtlinien zum Generieren synthetischer Daten verwendet. Daher sollte die URL \xF6ffentlich zug\xE4nglich und repr\xE4sentativ f\xFCr die Zieldom\xE4ne sein."])},answer6:n=>{const{normalize:e}=n;return e(["Ja, Sie k\xF6nnen ein Modell f\xFCr eine andere Sprache als Englisch optimieren. Das System erkennt automatisch die Sprache Ihrer Dom\xE4nenanweisungen und generiert entsprechend synthetische Daten. Wir empfehlen au\xDFerdem, das entsprechende Basismodell f\xFCr die Zielsprache auszuw\xE4hlen. Wenn Sie beispielsweise eine deutsche Dom\xE4ne als Ziel haben, sollten Sie als Basismodell \u201Ejina-embeddings-v2-base-de\u201C ausw\xE4hlen."])},answer7:n=>{const{normalize:e}=n;return e(["Nein, unsere Feinabstimmungs-API unterst\xFCtzt nur Jina v2-Modelle."])},answer8:n=>{const{normalize:e}=n;return e(["Am Ende des Feinabstimmungsprozesses wertet das System das Modell anhand eines zur\xFCckgehaltenen Testsatzes aus und meldet Leistungsmesswerte. Sie erhalten eine E-Mail mit detaillierten Angaben zur Leistung vor/nach diesem Testsatz. Sie werden au\xDFerdem ermutigt, das Modell anhand Ihres eigenen Testsatzes auszuwerten, um seine Qualit\xE4t sicherzustellen."])},answer9:n=>{const{normalize:e}=n;return e(["Das System generiert synthetische Daten, indem es die von Ihnen bereitgestellten Zieldom\xE4nenanweisungen mit den Argumenten der LLM-Agenten integriert. Es erzeugt harte negative Tripletts, die f\xFCr das Training hochwertiger Einbettungsmodelle unerl\xE4sslich sind. Weitere Einzelheiten finden Sie in unserem kommenden Forschungspapier auf Arxiv."])},question1:n=>{const{normalize:e}=n;return e(["Wie viel kostet die Fine-Tuning-API?"])},question10:n=>{const{normalize:e}=n;return e(["Kann ich meine fein abgestimmten Modelle und synthetischen Daten vertraulich behandeln?"])},question11:n=>{const{normalize:e}=n;return e(["Wie kann ich das feinabgestimmte Modell verwenden?"])},question12:n=>{const{normalize:e}=n;return e(["Ich habe die E-Mail mit den Bewertungsergebnissen nie erhalten. Was soll ich tun?"])},question2:n=>{const{normalize:e}=n;return e(["Welche Eingaben muss ich machen? Muss ich Trainingsdaten angeben?"])},question3:n=>{const{normalize:e}=n;return e(["Wie lange dauert die Feinabstimmung eines Modells?"])},question4:n=>{const{normalize:e}=n;return e(["Wo werden die feinabgestimmten Modelle gespeichert?"])},question5:n=>{const{normalize:e}=n;return e(["Wenn ich eine Referenz-URL angebe, wie verwendet das System diese?"])},question6:n=>{const{normalize:e}=n;return e(["Kann ich ein Modell f\xFCr eine bestimmte Sprache optimieren?"])},question7:n=>{const{normalize:e}=n;return e(["Kann ich Nicht-Jina-Einbettungen, z.\xA0B. bge-M3, feinabstimmen?"])},question8:n=>{const{normalize:e}=n;return e(["Wie stellen Sie die Qualit\xE4t der optimierten Modelle sicher?"])},question9:n=>{const{normalize:e}=n;return e(["Wie generieren Sie synthetische Daten?"])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufige Fragen zur automatischen Feinabstimmung"])}},find_on_hf:n=>{const{normalize:e}=n;return e(["Liste der fein abgestimmten Modelle"])},temporarily_unavailable:n=>{const{normalize:e}=n;return e(["Vor\xFCbergehend nicht verf\xFCgbar. Wir aktualisieren unser automatisches Feinabstimmungssystem, um Ihnen einen besseren Service bieten zu k\xF6nnen. Bitte schauen Sie sp\xE4ter noch einmal vorbei."])},test_on:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Getestet an ",r(i("_dataSize"))," Zufallsstichproben aus ",r(i("_dataName"))])},test_performance_before_after:n=>{const{normalize:e}=n;return e(["Leistung im zur\xFCckgehaltenen Testsatz vor und nach der Feinabstimmung"])},title:n=>{const{normalize:e}=n;return e(["API f\xFCr automatische Feinabstimmung"])},total_improve:n=>{const{normalize:e}=n;return e(["Durchschnittliche Verbesserung"])},usage:n=>{const{normalize:e}=n;return e(["Verwendung"])},what_is:n=>{const{normalize:e}=n;return e(["Was ist automatische Feinabstimmung?"])},what_is_answer_long:n=>{const{normalize:e}=n;return e(["Durch Feinabstimmung k\xF6nnen Sie ein vorab trainiertes Modell nehmen und es an eine bestimmte Aufgabe oder Dom\xE4ne anpassen, indem Sie es an einem neuen Datensatz trainieren. In der Praxis ist es f\xFCr viele Benutzer nicht einfach, effektive Trainingsdaten zu finden. F\xFCr ein effektives Training ist mehr erforderlich, als einfach nur Roh-PDFs und HTMLs in das Modell einzugeben. Und es ist schwer, es richtig zu machen. Die automatische Feinabstimmung l\xF6st dieses Problem, indem sie mithilfe einer erweiterten LLM-Agent-Pipeline automatisch effektive Trainingsdaten generiert und das Modell innerhalb eines ML-Workflows feinabstimmt. Sie k\xF6nnen es sich als eine Kombination aus synthetischer Datengenerierung und AutoML vorstellen. Sie m\xFCssen also nur Ihre Zieldom\xE4ne in nat\xFCrlicher Sprache beschreiben und unser System den Rest erledigen lassen."])}},best_banner:{description:n=>{const{normalize:e}=n;return e(["Vom Blog-Artikel zum Banner, ohne eigene Prompts!"])},example_description:n=>{const{normalize:e}=n;return e(["Alice wurde es langsam sehr leid, neben ihrer Schwester am Ufer zu sitzen und nichts zu tun zu haben: Ein- oder zweimal hatte sie in das Buch geguckt, das ihre Schwester las, aber es enthielt weder Bilder noch Gespr\xE4che. \u201EUnd was n\xFCtzt ein Buch\u201C, dachte Alice, \u201Eohne Bilder oder Gespr\xE4che?\u201C So \xFCberlegte sie in Gedanken (so gut sie konnte, denn der hei\xDFe Tag machte sie sehr schl\xE4frig und dumm), ob das Vergn\xFCgen, eine G\xE4nsebl\xFCmchenkette zu machen, die M\xFChe wert w\xE4re, aufzustehen und die G\xE4nsebl\xFCmchen zu pfl\xFCcken, als pl\xF6tzlich ein wei\xDFes Kaninchen mit rosa Augen dicht an ihr vorbeilief."])},example_title:n=>{const{normalize:e}=n;return e(["Alices Abenteuer im Wunderland \u2013 Kapitel 1"])}},beta:n=>{const{normalize:e}=n;return e(["Beta"])},billing_general_faq:{answer10:n=>{const{normalize:e}=n;return e(["Wir bieten neuen Benutzern eine einladende kostenlose Testversion an, die eine Million Token zur Verwendung mit jedem unserer Modelle umfasst und durch einen automatisch generierten API-Schl\xFCssel erleichtert wird. Sobald das kostenlose Token-Limit erreicht ist, k\xF6nnen Benutzer \xFCber die Registerkarte \u201EToken kaufen\u201C ganz einfach zus\xE4tzliche Token f\xFCr ihre API-Schl\xFCssel erwerben."])},answer13:n=>{const{normalize:e}=n;return e(["Nein, f\xFCr fehlgeschlagene Anfragen werden keine Token abgezogen."])},answer14:n=>{const{normalize:e}=n;return e(["Zahlungen werden \xFCber Stripe abgewickelt und unterst\xFCtzen zu Ihrer Bequemlichkeit eine Vielzahl von Zahlungsmethoden, darunter Kreditkarten, Google Pay und PayPal."])},answer15:n=>{const{normalize:e}=n;return e(["Ja, beim Kauf von Tokens wird eine Rechnung an die E-Mail-Adresse ausgestellt, die mit Ihrem Stripe-Konto verkn\xFCpft ist."])},answer9:n=>{const{normalize:e}=n;return e(["Unser Preismodell basiert auf der Gesamtzahl der verarbeiteten Token und bietet Benutzern die Flexibilit\xE4t, diese Token auf eine beliebige Anzahl von S\xE4tzen zu verteilen. Dies bietet eine kosteng\xFCnstige L\xF6sung f\xFCr unterschiedliche Textanalyseanforderungen."])},question10:n=>{const{normalize:e}=n;return e(["Gibt es eine kostenlose Testversion f\xFCr neue Benutzer?"])},question13:n=>{const{normalize:e}=n;return e(["Werden f\xFCr fehlgeschlagene Anfragen Token berechnet?"])},question14:n=>{const{normalize:e}=n;return e(["Welche Zahlungsmethoden werden akzeptiert?"])},question15:n=>{const{normalize:e}=n;return e(["Ist eine Rechnungsstellung f\xFCr Token-K\xE4ufe verf\xFCgbar?"])},question9:n=>{const{normalize:e}=n;return e(["Erfolgt die Abrechnung nach der Anzahl der S\xE4tze bzw. Anfragen?"])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufige Fragen zur Abrechnung"])}},blog_tags:{all:n=>{const{normalize:e}=n;return e(["Alle"])},events:n=>{const{normalize:e}=n;return e(["Ereignis"])},featured:n=>{const{normalize:e}=n;return e(["Hervorgehoben"])},insights:n=>{const{normalize:e}=n;return e(["Meinung"])},"knowledge-base":n=>{const{normalize:e}=n;return e(["Wissen"])},latest:n=>{const{normalize:e}=n;return e(["Neueste"])},press:n=>{const{normalize:e}=n;return e(["Pressemitteilung"])},releases:n=>{const{normalize:e}=n;return e(["Software-Aktualisierung"])},"tech-blog":n=>{const{normalize:e}=n;return e(["Tech-Blog"])}},clip_as_service:{description:n=>{const{normalize:e}=n;return e(["Erzeugen Sie Embedding-Vektoren in konstanter l\xE4nge f\xFCr Bilder und S\xE4tze mit CLIP"])}},cloud:{description:n=>{const{normalize:e}=n;return e(["Cloud-Hosting-Plattform f\xFCr multimodale KI-Anwendungen"])}},contact_us_page:{agreement:n=>{const{normalize:e}=n;return e(["Mit dem Absenden best\xE4tigen Sie, dass Sie mit der Verarbeitung Ihrer personenbezogenen Daten durch Jina AI wie im Abschnitt beschrieben einverstanden sind"])},anything_else:n=>{const{normalize:e}=n;return e(["Erz\xE4hlen Sie uns mehr \xFCber Ihr Projekt"])},company:n=>{const{normalize:e}=n;return e(["Unternehmen"])},company_size:n=>{const{normalize:e}=n;return e(["Firmengr\xF6\xDFe"])},company_website:n=>{const{normalize:e}=n;return e(["Unternehmenswebseite"])},company_website_placeholder:n=>{const{normalize:e}=n;return e(["URL f\xFCr die Homepage oder das LinkedIn-Profil Ihres Unternehmens"])},country:n=>{const{normalize:e}=n;return e(["Land"])},department:n=>{const{normalize:e}=n;return e(["Abteilung"])},description:n=>{const{normalize:e}=n;return e(["Erweitern Sie Ihr Gesch\xE4ft mit Jina AI."])},faq:n=>{const{normalize:e}=n;return e(["FAQ"])},field_required:n=>{const{normalize:e}=n;return e(["Feld ist erforderlich"])},impact_snapshots:n=>{const{normalize:e}=n;return e(["Impact-Schnappsch\xFCsse"])},invalid_date_format:n=>{const{normalize:e}=n;return e(["Ung\xFCltiges Datumsformat. Bitte verwenden Sie das Format TT-MM-JJJJ."])},invalid_email:n=>{const{normalize:e}=n;return e(["E-Mail ist ung\xFCltig"])},invalid_number:n=>{const{normalize:e}=n;return e(["Ung\xFCltige Nummer. Bitte geben Sie erneut ein"])},invalid_url:n=>{const{normalize:e}=n;return e(["Die URL ist ung\xFCltig"])},name:n=>{const{normalize:e}=n;return e(["Name"])},preferred_products:n=>{const{normalize:e}=n;return e(["F\xFCr welche Produkte interessieren Sie sich?"])},private_statement:n=>{const{normalize:e}=n;return e(["Datenschutzerkl\xE4rung"])},role:n=>{const{normalize:e}=n;return e(["Position"])},submit:n=>{const{normalize:e}=n;return e(["Einreichen"])},submit_failed:n=>{const{normalize:e}=n;return e(["Die \xDCbermittlung ist fehlgeschlagen. Bitte versuchen Sie es sp\xE4ter noch einmal."])},submit_success:n=>{const{normalize:e}=n;return e(["Vielen Dank f\xFCr Ihre Einreichung. Wir kommen bald auf Sie zur\xFCck."])},subtitle:n=>{const{normalize:e}=n;return e(["Jina AI, ein f\xFChrendes Unternehmen im Bereich multimodale KI, zeichnet sich durch Modell-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite L\xF6sungen. Mit unserer Expertise in gro\xDFen Sprachmodellen, Text-, Bild-, Video- und Audioverst\xE4ndnis, neuronaler Suche und generativer Kunst bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen."])},subtitle1:n=>{const{normalize:e}=n;return e(["Jina AI, ein f\xFChrender Anbieter multimodaler KI, zeichnet sich durch Embedding-Tuning, Embedding-Serving, Prompt-Tuning und Prompt-Serving aus. Durch den Einsatz cloudnativer Technologien wie Kubernetes und serverloser Architekturen liefern wir robuste, skalierbare und produktionsbereite L\xF6sungen. Mit unserer Expertise in gro\xDFen Sprachmodellen, Text-, Bild-, Video- und Audioverst\xE4ndnis, neuronaler Suche und generativer KI bieten wir innovative, zukunftssichere Strategien, um Ihr Unternehmen voranzubringen."])},subtitle2:n=>{const{normalize:e}=n;return e(["Entdecken Sie Jina AI, die Spitze der multimodalen KI. Wir zeichnen uns durch die Einbettung und Bereitstellung von Technologien aus und nutzen Cloud-native L\xF6sungen wie Kubernetes f\xFCr robuste, skalierbare Systeme. Wir sind auf gro\xDFe Sprachmodelle und Medienverarbeitung spezialisiert und bieten mit unserer fortschrittlichen KI-Expertise innovative, zukunftsf\xE4hige Gesch\xE4ftsstrategien."])},title:n=>{const{normalize:e}=n;return e(["Kontaktieren Sie unseren Vertrieb"])},trusted_by:n=>{const{normalize:e}=n;return e(["Unsere Partner"])},work_email:n=>{const{normalize:e}=n;return e(["Arbeits Email"])}},copy:n=>{const{normalize:e}=n;return e(["Kopieren"])},copy_to_clipboard_success:n=>{const{normalize:e}=n;return e(["In die Zwischenablage kopiert"])},dalle_flow:{description:n=>{const{normalize:e}=n;return e(["Ein Human-in-the-Loop-Workflow zum Erstellen von HD-Bildern aus Text"])}},"dev-gpt":{description:n=>{const{normalize:e}=n;return e(["Ihr virtuelles Entwicklungsteam"])}},disco_art:{description:n=>{const{normalize:e}=n;return e(["Erstellen Sie \xFCberzeugende Disco Diffusion-Kunstwerke in einer Codezeile"])}},doc_array:{description:n=>{const{normalize:e}=n;return e(["Die Datenstruktur f\xFCr multimodale Daten"])}},embedding:{"11B tokens":n=>{const{normalize:e}=n;return e(["11 Milliarden"])},"11B tokens_intuition1":n=>{const{normalize:e}=n;return e(["\xC4hnlich wie das Lesen aller englischsprachigen Artikel auf Wikipedia."])},"11B tokens_targetUser":n=>{const{normalize:e}=n;return e(["Produktionsbereitstellung"])},"1B tokens":n=>{const{normalize:e}=n;return e(["1 Milliarde"])},"1B tokens_intuition1":n=>{const{normalize:e}=n;return e(["Ungef\xE4hr so, als w\xFCrde man die Gesamtwerke Shakespeares und die komplette \u201EHarry Potter\u201C-Reihe lesen."])},"1B tokens_targetUser":n=>{const{normalize:e}=n;return e(["Prototypenentwicklung"])},"1M tokens":n=>{const{normalize:e}=n;return e(["1 Million"])},"1M tokens_intuition1":n=>{const{normalize:e}=n;return e(["Entspricht dem Lesen des gesamten Textes von \u201EDer Hobbit\u201C und \u201EDer gro\xDFe Gatsby\u201C."])},"1M tokens_targetUser":n=>{const{normalize:e}=n;return e(["Spielzeug-Experiment"])},"1M_free":n=>{const{normalize:e}=n;return e(["1 Million kostenlose Token"])},"1M_free_description":n=>{const{normalize:e}=n;return e(["Genie\xDFen Sie kostenlose Token in Ihrem neuen API-Schl\xFCssel, keine Kreditkarte erforderlich."])},"2_5B tokens":n=>{const{normalize:e}=n;return e(["2,5 Milliarden Token"])},"2_5B tokens_intuition1":n=>{const{normalize:e}=n;return e([`Vergleichbar mit der 1.000-fachen Transkription jedes gesprochenen Wortes aus der Filmtrilogie \u201EDer Herr der Ringe\u201C.
`])},"3p_integration":n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Mit <b>",r(i("_numPartners")),"</b> Drittanbieterdiensten"])},"3p_integration_desc":n=>{const{normalize:e}=n;return e(["Integrieren Sie unsere Suchgrundlage in Ihre vorhandenen Dienste. Unsere Partner haben Konnektoren zu unserer API erstellt, sodass Sie unsere Modelle ganz einfach in Ihren Anwendungen verwenden k\xF6nnen."])},"500M tokens":n=>{const{normalize:e}=n;return e(["500 Millionen Token"])},"500M tokens_intuition1":n=>{const{normalize:e}=n;return e(["\xC4hnlich wie das Anschauen aller Folgen der \u201ESimpsons\u201C von Staffel 1 bis Staffel 30."])},"59B tokens":n=>{const{normalize:e}=n;return e(["59B-Token"])},"59B tokens_intuition1":n=>{const{normalize:e}=n;return e(["Entspricht allen Tweets, die weltweit innerhalb eines Zeitraums von zwei Tagen gepostet werden."])},"5_5B tokens":n=>{const{normalize:e}=n;return e(["5,5 Milliarden Token"])},"5_5B tokens_intuition1":n=>{const{normalize:e}=n;return e(["Entspricht dem Lesen des gesamten Textes der Encyclopaedia Britannica."])},Free1M:n=>{const{normalize:e}=n;return e(["1 Mio. Token"])},add_pair:n=>{const{normalize:e}=n;return e(["Neu"])},api_integration_short:n=>{const{normalize:e}=n;return e(["Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert."])},api_integrations:n=>{const{normalize:e}=n;return e(["API-Integrationen"])},auto_recharge:n=>{const{normalize:e}=n;return e(["Automatisches Aufladen bei niedrigem Tokenstand"])},auto_recharge_confirm_message:n=>{const{normalize:e}=n;return e(["M\xF6chten Sie die automatische Aufladung wirklich deaktivieren? Dadurch werden automatische Aufladungen verhindert, wenn Ihr Token-Guthaben niedrig ist."])},auto_recharge_confirm_title:n=>{const{normalize:e}=n;return e(["Automatisches Aufladen deaktivieren"])},auto_recharge_description:n=>{const{normalize:e}=n;return e(["Empfohlen f\xFCr einen unterbrechungsfreien Betrieb in der Produktion. Wenn Ihr Token-Guthaben unter dem von Ihnen festgelegten Schwellenwert liegt, laden wir Ihre Kreditkarte automatisch mit dem gleichen Betrag wie bei Ihrer letzten Aufladung auf. Wenn Sie bei der letzten Aufladung mehrere Pakete gekauft haben, laden wir nur ein Paket auf."])},auto_recharge_enable:n=>{const{normalize:e}=n;return e(["Sie haben die automatische Aufladung bei niedrigen Token aktiviert"])},auto_recharge_enable_message:n=>{const{normalize:e}=n;return e(["Um die automatische Aufladung zu aktivieren, kaufen Sie bitte ein Paket, bei dem die automatische Aufladung auf \u201ETrue\u201C eingestellt ist."])},auto_recharge_enable_title:n=>{const{normalize:e}=n;return e(["Automatisches Aufladen aktivieren"])},auto_request:n=>{const{normalize:e}=n;return e(["Automatische Vorschau"])},auto_request_tooltip:n=>{const{normalize:e}=n;return e(["Automatische Vorschau der API-Antwort beim \xC4ndern des Modells unter Verwendung von Hunderten von Token aus Ihrem API-Schl\xFCssel. Deaktivieren Sie das manuelle Senden einer Anfrage, indem Sie auf \u201EAntwort abrufen\u201C klicken."])},autostart:n=>{const{normalize:e}=n;return e(["Die Einbettung beginnt nach einer kurzen Verz\xF6gerung automatisch"])},base64_description:n=>{const{normalize:e}=n;return e(["Die Einbettungen werden als Base64-codierte Zeichenfolge zur\xFCckgegeben. Effizienter f\xFCr die \xDCbertragung."])},batch_job:n=>{const{normalize:e}=n;return e(["Batch-Job"])},batch_upload_hint:n=>{const{normalize:e}=n;return e(["Wir werden den API-Schl\xFCssel und das untenstehende Modell verwenden, um die Dokumente zu verarbeiten."])},"bge-base-en-v1_5_description":n=>{const{normalize:e}=n;return e(["Ein robustes englisches Modell mit der richtigen Balance zwischen Leistung und Effizienz f\xFCr den vielseitigen Einsatz."])},"bge-base-en_description":n=>{const{normalize:e}=n;return e(["Ein ausgewogenes englisches Modell, das f\xFCr solide und zuverl\xE4ssige Leistung ausgelegt ist."])},"bge-base-zh-v1_5_description":n=>{const{normalize:e}=n;return e(["Ein abgerundetes chinesisches Modell, das Leistungsf\xE4higkeit und Effizienz in Einklang bringt."])},"bge-base-zh_description":n=>{const{normalize:e}=n;return e(["Ein vielseitiges chinesisches Modell, das Effizienz und robuste Leistung kombiniert."])},"bge-large-en-v1_5_description":n=>{const{normalize:e}=n;return e(["Ein leistungsstarkes englisches Modell, das erstklassige Einbettungen mit au\xDFergew\xF6hnlicher Qualit\xE4t bietet."])},"bge-large-en_description":n=>{const{normalize:e}=n;return e(["Ein leistungsstarkes englisches Modell, das f\xFCr Einbettungen in Premiumqualit\xE4t entwickelt wurde."])},"bge-large-zh-v1_5_description":n=>{const{normalize:e}=n;return e(["Ein chinesisches Modell mit hoher Kapazit\xE4t, das hervorragende und detaillierte Einbettungen liefert."])},"bge-large-zh_description":n=>{const{normalize:e}=n;return e(["Ein leistungsstarkes chinesisches Modell, optimiert f\xFCr Einbettungen der Spitzenklasse."])},"bge-m3_description":n=>{const{normalize:e}=n;return e(["Ein vielseitiges mehrsprachiges Modell mit umfangreichen Funktionen und hochwertigen Einbettungen."])},"bge-small-en-v1_5_description":n=>{const{normalize:e}=n;return e(["Ein optimiertes englisches Modell, das effiziente und qualitativ hochwertige Einbettungen liefert."])},"bge-small-en_description":n=>{const{normalize:e}=n;return e(["Ein effizientes englisches Modell f\xFCr optimierte und genaue Einbettungen."])},"bge-small-zh-v1_5_description":n=>{const{normalize:e}=n;return e(["Ein kompaktes chinesisches Modell, das flinke und pr\xE4zise Einbettungen erm\xF6glicht."])},"bge-small-zh_description":n=>{const{normalize:e}=n;return e(["Ein agiles chinesisches Modell f\xFCr effiziente und pr\xE4zise Einbettungen."])},binary_description:n=>{const{normalize:e}=n;return e(["Die Einbettungen werden als int8 gepackt. Viel effizienter f\xFCr Speicherung, Suche und \xDCbertragung."])},bulk:n=>{const{normalize:e}=n;return e(["Batch-Einbettung"])},bulk_embedding_failed:n=>{const{normalize:e}=n;return e(["Batch-Einbettungsauftrag konnte nicht erstellt werden"])},buy_more_quota:n=>{const{normalize:e}=n;return e(["Laden Sie diesen API-Schl\xFCssel mit weiteren Token auf"])},buy_poster:n=>{const{normalize:e}=n;return e(["Kaufen Sie eine gedruckte Kopie"])},cancel_button:n=>{const{normalize:e}=n;return e(["Stornieren"])},click_upload_btn_above:n=>{const{normalize:e}=n;return e(["Klicken Sie oben auf die Schaltfl\xE4che \u201EHochladen\u201C, um zu beginnen."])},code:n=>{const{normalize:e}=n;return e(["Code"])},compatible:n=>{const{normalize:e}=n;return e(["Kompatibler Modus"])},compatible_explain:n=>{const{normalize:e}=n;return e(["Folgt demselben Anfrageformat wie unsere Texteinbettungsmodelle. So k\xF6nnen Sie zwischen Modellen wechseln, ohne die Anfrage zu \xE4ndern. Beachten Sie, dass Bildeingaben in diesem Modus nicht unterst\xFCtzt werden."])},cosine_similarity:n=>{const{normalize:e}=n;return e(["Kosinus\xE4hnlichkeit"])},debugging:n=>{const{normalize:e}=n;return e(["Pr\xFCfen"])},delete_pair:n=>{const{normalize:e}=n;return e(["L\xF6schen"])},description:n=>{const{normalize:e,linked:r,type:i}=n;return e([r("landing_page.embedding_desc1",void 0,i)])},document:n=>{const{normalize:e}=n;return e(["Dokumentieren"])},download:n=>{const{normalize:e}=n;return e(["Herunterladen"])},edit_text1_text:n=>{const{normalize:e}=n;return e(["Linken Text bearbeiten"])},edit_text2_text:n=>{const{normalize:e}=n;return e(["Bearbeiten Sie den richtigen Text"])},embedding_done:n=>{const{normalize:e,interpolate:r,named:i}=n;return e([r(i("_Count"))," S\xE4tze erfolgreich eingebettet."])},embedding_none_description:n=>{const{normalize:e}=n;return e(["Verwenden Sie kein Einbettungsmodell"])},example_inputs:n=>{const{normalize:e}=n;return e(["Beispieleingaben"])},faq:n=>{const{normalize:e,linked:r,type:i}=n;return e([r("contact_us_page.faq",void 0,i)])},faqs_v2:{answer0:n=>{const{normalize:e}=n;return e(["Detaillierte Informationen zu unseren Schulungsprozessen, Datenquellen und Auswertungen finden Sie in unserem technischen Bericht, der auf arXiv verf\xFCgbar ist."])},answer1:n=>{const{normalize:e}=n;return e(["Jeder Benutzer darf bis zu 100 Anfragen pro Sekunde stellen, was 204.800 Eingabes\xE4tzen pro Sekunde entspricht."])},answer17:n=>{const{normalize:e}=n;return e(["Wir entwickeln derzeit multimodale Einbettungen, die Text, Bilder und Audio gemeinsam verarbeiten. Updates werden bald bekannt gegeben!"])},answer18:n=>{const{normalize:e}=n;return e(["Bei Fragen zur Feinabstimmung unserer Modelle mit spezifischen Daten kontaktieren Sie uns bitte, um Ihre Anforderungen zu besprechen. Wir sind offen daf\xFCr, herauszufinden, wie unsere Modelle an Ihre Bed\xFCrfnisse angepasst werden k\xF6nnen."])},answer19:n=>{const{normalize:e}=n;return e(["Ja, unsere Dienste sind auf dem AWS-Marktplatz verf\xFCgbar und wir sind dabei, auf die Azure- und GCP-Marktpl\xE4tze zu expandieren. Wenn Sie besondere Anforderungen haben, kontaktieren Sie uns bitte unter sales AT jina.ai."])},answer3:n=>{const{normalize:e}=n;return e(["Unsere Modelle unterst\xFCtzen Englisch, Deutsch, Spanisch, Chinesisch und verschiedene Programmiersprachen. Weitere Einzelheiten finden Sie in unserer Publikation zu bilingualen Modellen."])},answer4:n=>{const{normalize:e}=n;return e(["Unsere Modelle erm\xF6glichen eine Eingabel\xE4nge von bis zu 8192 Token, was deutlich h\xF6her ist als bei den meisten anderen Modellen. Ein Token kann von einem einzelnen Zeichen wie \u201Ea\u201C bis zu einem ganzen Wort wie \u201Eapple\u201C reichen. Die Gesamtzahl der eingebbaren Zeichen h\xE4ngt von der L\xE4nge und Komplexit\xE4t der verwendeten W\xF6rter ab. Diese erweiterte Eingabef\xE4higkeit erm\xF6glicht unseren jina-embeddings-v2-Modellen eine umfassendere Textanalyse und eine h\xF6here Genauigkeit beim Kontextverst\xE4ndnis, insbesondere bei umfangreichen Textdaten."])},answer5:n=>{const{normalize:e}=n;return e(["Ein einzelner API-Aufruf kann bis zu 2048 S\xE4tze oder Texte verarbeiten und erm\xF6glicht so eine umfassende Textanalyse in einer Anfrage."])},answer6:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen entweder <code>url</code> oder <code>bytes</code> im Feld <code>input</code> der API-Anfrage verwenden. Geben Sie f\xFCr <code>url</code> die URL des Bildes an, das Sie verarbeiten m\xF6chten. F\xFCr <code>bytes</code> kodieren Sie das Bild im Base64-Format und schlie\xDFen Sie es in die Anfrage ein. Das Modell gibt die Einbettungen des Bildes in der Antwort zur\xFCck."])},answer7:n=>{const{normalize:e}=n;return e(["Laut MTEB-Bestenliste konkurriert unser Basismodell eng mit text-embedding-ada-002 von OpenAI und weist im Durchschnitt eine vergleichbare Leistung auf. Dar\xFCber hinaus zeichnet sich unser Basismodell bei mehreren Aufgaben aus, darunter Klassifizierung, Paarklassifizierung, Neubewertung und Zusammenfassung, und \xFCbertrifft damit das Modell von OpenAI."])},answer8:n=>{const{normalize:e}=n;return e(["Der \xDCbergang wird rationalisiert, da unser API-Endpunkt https://api.jina.ai/v1/embeddings mit den Eingabe- und Ausgabe-JSON-Schemas des text-embeddings-ada-002-Modells von OpenAI \xFCbereinstimmt. Diese Kompatibilit\xE4t stellt sicher, dass Benutzer das OpenAI-Modell problemlos durch unseres ersetzen k\xF6nnen, wenn sie den Endpunkt von OpenAI verwenden."])},answer9:n=>{const{normalize:e}=n;return e([`Die Token werden basierend auf der Textl\xE4nge und der Bildgr\xF6\xDFe berechnet. F\xFCr Text in der Anfrage werden die Token auf die Standardweise gez\xE4hlt. F\xFCr Bilder in der Anfrage werden die folgenden Schritte ausgef\xFChrt:
1. Kachelgr\xF6\xDFe: Jedes Bild wird in Kacheln der Gr\xF6\xDFe 224 x 224 Pixel unterteilt.
2. Abdeckung: Die Anzahl der Kacheln, die erforderlich sind, um das Eingabebild vollst\xE4ndig abzudecken, wird berechnet. Auch wenn die Bildabmessungen nicht perfekt durch 224 teilbar sind, z\xE4hlen wir Teilkacheln als vollst\xE4ndige Kacheln.
3. Gesamtzahl der Kacheln: Die Gesamtzahl der Kacheln, die das Bild abdecken, bestimmt die Kosten. Wenn ein Bild beispielsweise 500 x 500 Pixel gro\xDF ist, wird es von 3 x 3 Kacheln abgedeckt, was 9 Kacheln ergibt.
4. Kostenberechnung: Jede Kachel tr\xE4gt zu den endg\xFCltigen Kosten der Bildverarbeitung bei. Die Kosten pro Kachel betragen 1000 Token.

Beispiel:
F\xFCr ein Bild mit den Abmessungen 500 x 500 Pixel:

\u2022 Das Bild wird in Kacheln mit 224 x 224 Pixeln unterteilt.
\u2022 Die Gesamtzahl der ben\xF6tigten Kacheln betr\xE4gt 3 (horizontal) x 3 (vertikal) = 9 Kacheln.

\u2022 Die Kosten betragen 9*1000 = 9000 Token`])},question0:n=>{const{normalize:e}=n;return e(["Wie wurden die jina-embeddings-v2-Modelle trainiert?"])},question1:n=>{const{normalize:e}=n;return e(["Wie viele API-Anfragen kann ich pro Sekunde stellen?"])},question17:n=>{const{normalize:e}=n;return e(["Bieten Sie Modelle zum Einbetten von Bildern oder Audio an?"])},question18:n=>{const{normalize:e}=n;return e(["K\xF6nnen Jina Embedding-Modelle mit privaten oder Unternehmensdaten verfeinert werden?"])},question19:n=>{const{normalize:e}=n;return e(["K\xF6nnen Ihre Endpunkte privat auf AWS, Azure oder GCP gehostet werden?"])},question3:n=>{const{normalize:e}=n;return e(["Welche Sprachen unterst\xFCtzen Ihre Modelle?"])},question4:n=>{const{normalize:e}=n;return e(["Was ist die maximale L\xE4nge f\xFCr die Eingabe eines einzelnen Satzes?"])},question5:n=>{const{normalize:e}=n;return e(["Wie viele S\xE4tze kann ich maximal in eine einzelne Anfrage einf\xFCgen?"])},question6:n=>{const{normalize:e}=n;return e(["Wie sende ich Bilder an das Modell jina-clip-v1?"])},question7:n=>{const{normalize:e}=n;return e(["Wie vergleichen sich Jina Embeddings-Modelle mit dem text-embedding-ada-002-Modell von OpenAI?"])},question8:n=>{const{normalize:e}=n;return e(["Wie nahtlos verl\xE4uft der \xDCbergang von text-embedding-ada-002 von OpenAI zu Ihrer L\xF6sung?"])},question9:n=>{const{normalize:e}=n;return e(["Wie werden Token bei Verwendung von jina-clip-v1 berechnet?"])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufige Fragen zu Einbettungen"])}},feature_8k1:n=>{const{normalize:e}=n;return e(["8192 Token-L\xE4nge"])},feature_8k_description1:n=>{const{normalize:e}=n;return e(["Pionierarbeit beim ersten Open-Source-Einbettungsmodell mit einer L\xE4nge von 8192 Token, das die Darstellung eines gesamten Kapitels in einem einzigen Vektor erm\xF6glicht."])},feature_cheap:n=>{const{normalize:e}=n;return e(["20x g\xFCnstiger"])},feature_cheap_v1:n=>{const{normalize:e}=n;return e(["5x g\xFCnstiger"])},feature_cheap_v1_description1:n=>{const{normalize:e}=n;return e(["Beginnen Sie mit kostenlosen Testversionen und genie\xDFen Sie eine unkomplizierte Preisstruktur. Erhalten Sie Zugang zu leistungsstarken Einbettungen f\xFCr nur 20 % der OpenAI-Kosten."])},feature_multilingual:n=>{const{normalize:e}=n;return e(["Bietet unter anderem zweisprachige Modelle f\xFCr Deutsch-Englisch, Chinesisch-Englisch, ideal f\xFCr mehrsprachige Anwendungen."])},feature_on_premises:n=>{const{normalize:e}=n;return e(["Datenschutz zuerst"])},feature_on_premises_description1:n=>{const{normalize:e}=n;return e(["Stellen Sie unsere Einbettungsmodelle nahtlos direkt in Ihrer Virtual Private Cloud (VPC) bereit. Wird derzeit auf AWS Sagemaker unterst\xFCtzt, mit bevorstehenden Integrationen f\xFCr Microsoft Azure und Google Cloud Platform. F\xFCr ma\xDFgeschneiderte Kubernetes-Bereitstellungen wenden Sie sich f\xFCr spezielle Unterst\xFCtzung an unser Vertriebsteam."])},feature_on_premises_description2:n=>{const{normalize:e}=n;return e(["Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um ma\xDFgeschneiderte Kubernetes-Bereitstellungen f\xFCr Ihre Virtual Private Cloud und lokale Server zu erhalten."])},feature_on_premises_description3:n=>{const{normalize:e}=n;return e(["Stellen Sie Jina Embeddings-Modelle in AWS Sagemaker und Microsoft Azure und bald auch in Google Cloud Services bereit, oder wenden Sie sich an unser Vertriebsteam, um angepasste Kubernetes-Bereitstellungen f\xFCr Ihre Virtual Private Cloud und Ihre lokalen Server zu erhalten."])},feature_on_premises_description4:n=>{const{normalize:e}=n;return e(["Stellen Sie Jina Embedding- und Reranker-Modelle vor Ort mit AWS SageMaker, Microsoft Azure oder Google Cloud Services bereit und stellen Sie sicher, dass Ihre Daten sicher unter Ihrer Kontrolle bleiben."])},feature_solid:n=>{const{normalize:e}=n;return e(["Klassenbester"])},feature_solid_description1:n=>{const{normalize:e}=n;return e(["Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests anhand der SOTA-Modelle, um eine beispiellose Leistung zu gew\xE4hrleisten."])},feature_top_perform1:n=>{const{normalize:e}=n;return e(["Nahtlose Integration"])},feature_top_perform_description1:n=>{const{normalize:e}=n;return e(["Vollst\xE4ndig kompatibel mit der API von OpenAI. L\xE4sst sich m\xFChelos in \xFCber 10 Vektordatenbanken und RAG-Systeme integrieren und sorgt so f\xFCr ein reibungsloses Benutzererlebnis."])},file_required:n=>{const{normalize:e}=n;return e(["Datei ist erforderlich"])},file_size_exceed:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Maximale Dateigr\xF6\xDFe ",r(i("_size"))," \xFCberschritten"])},file_type_not_supported:n=>{const{normalize:e}=n;return e(["Dateityp nicht unterst\xFCtzt"])},fill_example:n=>{const{normalize:e}=n;return e(["F\xFCllen Sie ein Beispiel aus"])},float_description:n=>{const{normalize:e}=n;return e(["Die Einbettungen werden als Liste von Gleitkommazahlen zur\xFCckgegeben. Am gebr\xE4uchlichsten und am einfachsten zu verwenden."])},free:n=>{const{normalize:e}=n;return e(["Frei"])},generate_api_key_error:n=>{const{normalize:e}=n;return e(["Die Generierung des API-Schl\xFCssels ist fehlgeschlagen."])},generating_visualization:n=>{const{normalize:e}=n;return e(["Visualisierung wird erstellt..."])},get_new_key_button:n=>{const{normalize:e}=n;return e(["Holen Sie sich einen neuen Schl\xFCssel"])},get_new_key_button_explain:n=>{const{normalize:e}=n;return e(["Wenn Sie sich f\xFCr einen neuen Schl\xFCssel entscheiden, geht der mit dem alten Schl\xFCssel verbundene Nutzungsverlauf verloren."])},get_new_key_survey:n=>{const{normalize:e}=n;return e(["Nehmen Sie an der Umfrage teil, helfen Sie uns, Ihre Nutzung zu verstehen, und erhalten Sie kostenlos einen neuen API-Schl\xFCssel!"])},includes:n=>{const{normalize:e}=n;return e(["Token g\xFCltig f\xFCr:"])},index_and_search:n=>{const{normalize:e}=n;return e(["Index & Suche"])},index_and_search1:n=>{const{normalize:e}=n;return e(["Index & Suche"])},input:n=>{const{normalize:e}=n;return e(["Anfrage"])},input_api_key_error1:n=>{const{normalize:e}=n;return e(["Ihr API-Schl\xFCssel ist ung\xFCltig!"])},input_length:n=>{const{normalize:e}=n;return e(["Eingabel\xE4nge"])},input_type:n=>{const{normalize:e}=n;return e(["Als Abfrage oder Dokument einbetten"])},input_type_explain:n=>{const{normalize:e}=n;return e(["Einige Einbettungsmodelle verf\xFCgen \xFCber spezielle Einbettungsstrategien f\xFCr Abfragen und Dokumente. Dieselbe Zeichenfolge kann je nach ihrer Rolle in Ihrer Anwendung als Abfrage oder Dokument eingebettet werden."])},integrate:n=>{const{normalize:e}=n;return e(["Integrieren"])},"jina-clip-v1_description":n=>{const{normalize:e}=n;return e(["Unsere neuesten multimodalen Einbettungen f\xFCr die Text- und Bildsuche."])},"jina-colbert-v1-en_description":n=>{const{normalize:e}=n;return e(["Verbessertes ColBERT mit 8K-Token-L\xE4nge zum Einbetten und Neuordnen von Aufgaben"])},"jina-embeddings-v2-base-code_description":n=>{const{normalize:e}=n;return e(["Optimiert f\xFCr die Suche nach Code und Dokumentzeichenfolgen"])},"jina-embeddings-v2-base-de_description":n=>{const{normalize:e}=n;return e(["Zweisprachige Einbettungen Deutsch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-base-en_description":n=>{const{normalize:e}=n;return e(["Auf Augenh\xF6he mit text-embedding-ada002 von OpenAI"])},"jina-embeddings-v2-base-es_description":n=>{const{normalize:e}=n;return e(["Zweisprachige Einbettungen Spanisch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-base-zh_description":n=>{const{normalize:e}=n;return e(["Zweisprachige Einbettungen Chinesisch-Englisch mit SOTA-Leistung"])},"jina-embeddings-v2-small-en_description":n=>{const{normalize:e}=n;return e(["Optimiert f\xFCr geringe Latenz und geringen Speicherbedarf"])},"jina-reranker-v1-base-en_description":n=>{const{normalize:e}=n;return e(["Unser erstes Reranker-Modell maximiert die Such- und RAG-Relevanz"])},"jina-reranker-v1-tiny-en_description":n=>{const{normalize:e}=n;return e(["Das schnellste Reranker-Modell, am besten geeignet f\xFCr die zuverl\xE4ssige Bewertung einer gro\xDFen Anzahl von Dokumenten"])},"jina-reranker-v1-turbo-en_description":n=>{const{normalize:e}=n;return e(["Die beste Kombination aus schneller Inferenzgeschwindigkeit und pr\xE4zisen Relevanzwerten"])},"jina-reranker-v2-base-multilingual_description":n=>{const{normalize:e}=n;return e(["Das neueste und beste Reranker-Modell mit mehrsprachiger Unterst\xFCtzung f\xFCr Funktionsaufrufe und Codesuche."])},key:n=>{const{normalize:e}=n;return e(["API-Schl\xFCssel"])},key_enter_placeholder:n=>{const{normalize:e}=n;return e(["Bitte geben Sie Ihren API-Schl\xFCssel ein"])},key_enter_placeholder_to_topup:n=>{const{normalize:e}=n;return e(["Geben Sie den API-Schl\xFCssel ein, den Sie aufladen m\xF6chten"])},key_to_top_up:n=>{const{normalize:e}=n;return e(["Sie haben bereits einen Schl\xFCssel? Zum Aufladen hier einlegen"])},key_warn:n=>{const{normalize:e}=n;return e(["Stellen Sie sicher, dass Sie Ihren API-Schl\xFCssel an einem sicheren Ort aufbewahren. Andernfalls m\xFCssen Sie einen neuen Schl\xFCssel generieren"])},key_warn_v2:n=>{const{normalize:e}=n;return e(["Bewahren Sie Ihren API-Schl\xFCssel an einem sicheren Ort auf!"])},language_explain:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Dieses Modell unterst\xFCtzt am besten die Sprache ",r(i("_Language")),"."])},last_7_days:n=>{const{normalize:e}=n;return e(["Nutzung in den letzten 7 Tagen"])},learn_more:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr"])},learn_poster:n=>{const{normalize:e}=n;return e(["Erfahren Sie, wie wir es gemacht haben"])},learning1:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr \xFCber Einbettungen"])},learning1_description:n=>{const{normalize:e}=n;return e(["Wo soll man mit Einbettungen anfangen? Wir geben dir Deckung. Erfahren Sie mehr \xFCber Einbettungen von Grund auf mit unserem umfassenden Leitfaden."])},length:n=>{const{normalize:e}=n;return e(["Tokenl\xE4nge"])},manage_billing:n=>{const{normalize:e}=n;return e(["Rechnung verwalten"])},manage_billing_tip:n=>{const{normalize:e}=n;return e(["Verwalten Sie Ihre Rechnungsinformationen, erhalten Sie Rechnungen und richten Sie die automatische Aufladung ein."])},manage_quota1:n=>{const{normalize:e}=n;return e(["API-Schl\xFCssel und Abrechnung"])},max_file_size:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Maximal zul\xE4ssige Gr\xF6\xDFe: ",r(i("_maxSize")),"."])},maximize_tooltip:n=>{const{normalize:e}=n;return e(["Maximieren Sie dieses Panel"])},mistake_contact:n=>{const{normalize:e}=n;return e(["Wenn Sie glauben, dass es sich hierbei um einen Fehler handelt, nehmen Sie bitte Kontakt mit uns auf."])},model_required:n=>{const{normalize:e}=n;return e(["Modell ist erforderlich"])},more_than_two2:n=>{const{normalize:e}=n;return e(["Bitte geben Sie mehr als zwei Dokumente ein, also mehr als zwei Zeilen."])},multi_embedding:n=>{const{normalize:e}=n;return e(["Multi-Vektor"])},multi_embedding_explain:n=>{const{normalize:e}=n;return e(["Dieses Modell gibt eine Reihe kontextualisierter Einbettungen f\xFCr eine bestimmte Eingabe zur\xFCck. Jedes Token in der Eingabe wird einem Vektor in der Ausgabe zugeordnet."])},multilingual:n=>{const{normalize:e}=n;return e(["Mehrsprachiger Support"])},multimodal:n=>{const{normalize:e}=n;return e(["Multimodal"])},multimodal_explain:n=>{const{normalize:e}=n;return e(["Dieses Modell kann sowohl Text- als auch Bildeingaben kodieren und ist daher ideal f\xFCr multimodale Suchaufgaben."])},new:n=>{const{normalize:e}=n;return e(["Neues Modell"])},no_data1:n=>{const{normalize:e}=n;return e(["F\xFCgen Sie ein Satzpaar hinzu, um die \xC4hnlichkeit zu berechnen"])},none:n=>{const{normalize:e}=n;return e(["Keiner"])},normalized:n=>{const{normalize:e}=n;return e(["L2-Normalisierung"])},normalized_explain:n=>{const{normalize:e}=n;return e(["Skaliert die Einbettung so, dass ihre euklidische (L2) Norm 1 wird, wobei die Richtung erhalten bleibt. N\xFCtzlich, wenn es im weiteren Verlauf um Skalarprodukt, Klassifizierung und Visualisierung geht."])},onprem:n=>{const{normalize:e}=n;return e(["Vor Ort"])},open_tensorboard:n=>{const{normalize:e}=n;return e(["\xD6ffnen Sie den Visualizer"])},opensource:n=>{const{normalize:e}=n;return e(["Betriebssystem"])},opensource_explain:n=>{const{normalize:e}=n;return e(["Dieses Modell ist Open Source und auf Hugging Face verf\xFCgbar. Klicken Sie auf diese Schaltfl\xE4che, um das Modell auf Hugging Face anzuzeigen."])},original_documents:n=>{const{normalize:e}=n;return e(["Einzubettende S\xE4tze"])},original_documents_hint:n=>{const{normalize:e}=n;return e(["Geben Sie hier Ihre S\xE4tze ein. Jede neue Zeile wird als separater Satz/Dokument betrachtet."])},output:n=>{const{normalize:e}=n;return e(["Antwort"])},output_dim:n=>{const{normalize:e}=n;return e(["Ma\xDFe"])},output_dim_explain:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Die Ausgabedimension eines Einbettungsvektors aus diesem Modell ist ",r(i("_outputDim")),"."])},output_dimension:n=>{const{normalize:e}=n;return e(["Ausgabedimensionen"])},pairwise_test:n=>{const{normalize:e}=n;return e(["Paarweise"])},per_k:n=>{const{normalize:e}=n;return e(["/ 1K-Token"])},per_m:n=>{const{normalize:e}=n;return e(["/ 1 Mio. Token"])},please_fill_docs_first:n=>{const{normalize:e}=n;return e(["Bitte geben Sie vor der Suche unten einige S\xE4tze ein."])},please_select_model:n=>{const{normalize:e}=n;return e(["Bitte w\xE4hlen Sie ein Einbettungsmodell oder ein Reranker-Modell aus"])},poster:n=>{const{normalize:e}=n;return e(["Die Evolution des Einbettungsplakats"])},poster_description:n=>{const{normalize:e}=n;return e(["Entdecken Sie das ideale Poster f\xFCr Ihren Raum mit fesselnden Infografiken oder atemberaubenden Bildern, die die Entwicklung der Texteinbettungsmodelle seit 1950 nachzeichnen."])},pricing:n=>{const{normalize:e}=n;return e(["API-Preise"])},pricing_desc:n=>{const{normalize:e}=n;return e(["Unsere API-Preise richten sich nach der Anzahl der in den Anfragen gesendeten Token. Bei der Reader-API ist es die Anzahl der Token in den Antworten. Dieses Preismodell gilt f\xFCr alle Produkte in der Suchgrundlage von Jina AI: Embedding-, Reranking-, Reader- und Auto Fine-Tuning-APIs. Mit demselben API-Schl\xFCssel haben Sie Zugriff auf alle API-Dienste."])},protectData1:n=>{const{normalize:e}=n;return e(["Anforderungsdaten und Dokumente werden nicht f\xFCr Trainingsmodelle verwendet."])},protectData2:n=>{const{normalize:e}=n;return e(["Datenverschl\xFCsselung w\xE4hrend der \xDCbertragung (TLS 1.2+) und im Ruhezustand (AES-GCM 256)."])},protectData3:n=>{const{normalize:e}=n;return e(["SOC 2 und DSGVO-konform."])},protect_data:n=>{const{normalize:e}=n;return e(["Sch\xFCtzen Sie Ihre Daten"])},public_cloud_integration:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Mit <b>",r(i("_numPartners")),"</b> Cloud-Service-Anbietern"])},public_cloud_integration_desc:n=>{const{normalize:e}=n;return e(["Verwendet Ihr Unternehmen AWS oder Azure? Dann setzen Sie unsere Suchgrundlagenmodelle direkt auf diesen Plattformen in Ihrem Unternehmen ein, damit Ihre Daten sicher und konform bleiben."])},query:n=>{const{normalize:e}=n;return e(["Abfrage"])},rank_none_description:n=>{const{normalize:e}=n;return e(["Verwenden Sie kein Reranker-Modell"])},read_api_docs:n=>{const{normalize:e}=n;return e(["Lesen Sie die Dokumente"])},recharge_threshold:n=>{const{normalize:e}=n;return e(["Aufladeschwelle"])},refresh:n=>{const{normalize:e}=n;return e(["Aktualisierung"])},refresh_key_tooltip1:n=>{const{normalize:e}=n;return e(["Holen Sie sich kostenlos einen neuen API-Schl\xFCssel"])},refresh_token_count1:n=>{const{normalize:e}=n;return e(["Aktualisieren Sie, um verf\xFCgbare Token des aktuellen API-Schl\xFCssels zu erhalten"])},regenerate:n=>{const{normalize:e}=n;return e(["Regenerieren"])},remaining:n=>{const{normalize:e}=n;return e(["Verf\xFCgbare Token"])},remaining_left:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Sie haben noch <b>",r(i("_leftTokens")),"</b> Token im unten stehenden API-Schl\xFCssel \xFCbrig."])},results_as_final_result:n=>{const{normalize:e}=n;return e(["#docs als Endergebnis"])},results_fed_to_reranker:n=>{const{normalize:e}=n;return e(["#docs an Reranker weitergeleitet"])},retry:n=>{const{normalize:e}=n;return e(["Wiederholen"])},return_base64:n=>{const{normalize:e}=n;return e(["Base64 (als String)"])},return_binary:n=>{const{normalize:e}=n;return e(["Bin\xE4r (als int8 gepackt)"])},return_float:n=>{const{normalize:e}=n;return e(["Standard (als Float)"])},return_format:n=>{const{normalize:e}=n;return e(["Einbettungsformat"])},return_format_explain:n=>{const{normalize:e}=n;return e(["Neben dem Float k\xF6nnen Sie auch die R\xFCckgabe als Bin\xE4rwert f\xFCr einen schnelleren Vektorabruf oder als Base64-Kodierung f\xFCr eine schnellere \xDCbertragung anfordern."])},return_format_title:n=>{const{normalize:e}=n;return e(["Zur\xFCckgebender Datentyp"])},return_ubinary:n=>{const{normalize:e}=n;return e(["Bin\xE4r (als uint8 gepackt)"])},right_api_key_to_charge:n=>{const{normalize:e}=n;return e(["Bitte geben Sie zum Aufladen den richtigen API-Schl\xFCssel ein"])},running:n=>{const{normalize:e}=n;return e(["Aktiv"])},score:n=>{const{normalize:e}=n;return e(["Punktzahl"])},search:n=>{const{normalize:e}=n;return e(["Suchen"])},search_hint:n=>{const{normalize:e}=n;return e(["Geben Sie Ihre Suche in die unten aufgef\xFChrten S\xE4tze ein."])},select_embedding_model:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie Einbettungen aus"])},select_rerank_model:n=>{const{normalize:e}=n;return e(["Reranker ausw\xE4hlen"])},show_api_key:n=>{const{normalize:e}=n;return e(["API-Schl\xFCssel anzeigen"])},size:n=>{const{normalize:e}=n;return e(["Parameter"])},size_explain:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Die Anzahl der Parameter im Modell betr\xE4gt ",r(i("_size")),". Beachten Sie, dass dies nicht die Gr\xF6\xDFe der Modelldatei ist."])},sleeping:n=>{const{normalize:e}=n;return e(["Inaktiv"])},start_batch:n=>{const{normalize:e}=n;return e(["Starten Sie die Batch-Einbettung"])},start_embedding:n=>{const{normalize:e}=n;return e(["Index"])},status_explain:n=>{const{normalize:e}=n;return e(["Unsere serverlose Architektur kann in Zeiten geringer Nutzung bestimmte Modelle entlasten. Bei aktiven Modellen erfolgt die Reaktion sofort. Inaktive Modelle ben\xF6tigen bei der ersten Anfrage einige Sekunden zum Laden. Nach der Aktivierung werden Folgeanfragen schneller bearbeitet."])},tax_may_apply:n=>{const{normalize:e}=n;return e(["Abh\xE4ngig von Ihrem Standort werden Ihnen m\xF6glicherweise USD, EUR oder andere W\xE4hrungen in Rechnung gestellt. Es k\xF6nnen Steuern anfallen."])},text1:n=>{const{normalize:e}=n;return e(["Links"])},text2:n=>{const{normalize:e}=n;return e(["Rechts"])},title:n=>{const{normalize:e}=n;return e(["Einbettungs-API"])},token_example:n=>{const{normalize:e}=n;return e(["Ein Tweet kostet etwa 20 Token, ein Nachrichtenartikel etwa 1000 Token und Charles Dickens\u2018 Roman \u201EEine Geschichte zweier St\xE4dte\u201C hat \xFCber eine Million Token."])},token_length_explain:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Die maximale L\xE4nge der Eingabe-Token-Sequenz betr\xE4gt f\xFCr dieses Modell ",r(i("_tokenLength")),"."])},tokens:n=>{const{normalize:e}=n;return e(["Token"])},top_up_button:n=>{const{normalize:e}=n;return e(["Alten Schl\xFCssel aufladen"])},top_up_button_explain:n=>{const{normalize:e}=n;return e(["Die Integration dieses API-Schl\xFCssels bietet eine professionellere L\xF6sung und macht h\xE4ufige Schl\xFCssel\xE4nderungen \xFCberfl\xFCssig. Nutzungsdaten werden gespeichert und sind jederzeit abrufbar."])},top_up_warning_message1:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Der aktuelle API-Schl\xFCssel hat noch ",r(i("_remainedTokens"))," Token und wird durch einen neuen Schl\xFCssel mit ",r(i("_freeTokens"))," Token ersetzt. Sie k\xF6nnen den alten Schl\xFCssel weiterhin verwenden oder aufladen, wenn Sie ihn sicher aufbewahrt haben. Wie wollen Sie fortfahren?"])},top_up_warning_title:n=>{const{normalize:e}=n;return e(["Ersetzen Sie den alten API-Schl\xFCssel"])},total_documents:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Einbettungsfortschritt: ",r(i("_Verarbeitet")),"/",r(i("_Count"))," S\xE4tze."])},tuning:n=>{const{normalize:e}=n;return e(["Feinabstimmung"])},turnstile_error:n=>{const{normalize:e}=n;return e(["Wir k\xF6nnen keinen API-Schl\xFCssel generieren, da wir nicht \xFCberpr\xFCfen konnten, ob Sie ein Mensch sind."])},turnstile_unsupported:n=>{const{normalize:e}=n;return e(["Wir k\xF6nnen keinen API-Schl\xFCssel generieren, da Ihr Browser nicht unterst\xFCtzt wird."])},ubinary_description:n=>{const{normalize:e}=n;return e(["Die Einbettungen werden als uint8 gepackt. Viel effizienter f\xFCr Speicherung, Suche und \xDCbertragung."])},upload:n=>{const{normalize:e}=n;return e(["Hochladen"])},upload_file:n=>{const{normalize:e}=n;return e(["Klicken Sie hier, um eine Datei hochzuladen"])},usage:n=>{const{normalize:e}=n;return e(["Verwendung"])},usage_amount:n=>{const{normalize:e}=n;return e(["Token"])},usage_history:n=>{const{normalize:e}=n;return e(["Nutzung in den letzten 7 Tagen"])},usage_history_explain:n=>{const{normalize:e}=n;return e(["Die Daten liegen nicht in Echtzeit vor und k\xF6nnen einige Minuten verz\xF6gert sein."])},usage_reason:n=>{const{normalize:e}=n;return e(["Beschreibung"])},usage_reason_consume:n=>{const{normalize:e}=n;return e(["Gebraucht"])},usage_reason_purchase:n=>{const{normalize:e}=n;return e(["Gekauft"])},usage_reason_trial:n=>{const{normalize:e}=n;return e(["Versuch"])},usage_rerank:n=>{const{normalize:e}=n;return e(["Verwendung"])},usage_time:n=>{const{normalize:e}=n;return e(["Terminzeit"])},vector_database_integration1:n=>{const{normalize:e}=n;return e(["Integrationen"])},vector_database_integration2:n=>{const{normalize:e}=n;return e(["Unsere Einbettungs-API ist nativ in verschiedene renommierte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Kopieren Sie zun\xE4chst einfach Ihren API-Schl\xFCssel und f\xFCgen Sie ihn in eine der aufgef\xFChrten Integrationen ein, um einen schnellen und reibungslosen Start zu erm\xF6glichen."])},vector_database_integration3:n=>{const{normalize:e}=n;return e(["Unsere Embedding & Reranker API ist nativ in verschiedene bekannte Datenbanken, Vektorspeicher, RAG- und LLMOps-Frameworks integriert. Um zu beginnen, kopieren Sie einfach Ihren API-Schl\xFCssel und f\xFCgen Sie ihn in eine der aufgelisteten Integrationen ein, um schnell und nahtlos zu starten."])},vector_database_integration_description:n=>{const{normalize:e}=n;return e(["Integrieren Sie die Jina Embeddings API nahtlos und einfach in alle unten aufgef\xFChrten Vektordatenbanken, LLM-Orchestrierungs-Frameworks und RAG-Anwendungen. Unsere Tutorials zeigen Ihnen wie."])},view_details:n=>{const{normalize:e}=n;return e(["Details anzeigen"])},visualization_example:n=>{const{normalize:e}=n;return e(["Zuordnung aller S\xE4tze aus diesem Abschnitt zu einem 3D-Vektorraum"])},visualization_example_you_can:n=>{const{normalize:e}=n;return e(["Nutzen Sie unsere API unten, Sie k\xF6nnen es auch tun!"])},visualize:n=>{const{normalize:e}=n;return e(["Visualisieren"])},visualize_done:n=>{const{normalize:e}=n;return e(["Die Visualisierung ist abgeschlossen. Sie k\xF6nnen nun auf die obere Schaltfl\xE4che klicken, um den Visualizer zu \xF6ffnen."])},wait_for_processing:n=>{const{normalize:e}=n;return e(["Ihre Anfrage wird bearbeitet."])},wait_stripe:n=>{const{normalize:e}=n;return e(["Stripe-Zahlung wird ge\xF6ffnet, bitte warten"])},what_are_embedding:n=>{const{normalize:e}=n;return e(["Was sind Einbettungen?"])},what_are_embedding_answer:n=>{const{normalize:e}=n;return e([`Stellen Sie sich vor, Sie bringen einem Computer bei, die nuancierten Bedeutungen von W\xF6rtern und Phrasen zu erfassen. Traditionelle Methoden, die auf starren, regelbasierten Systemen basieren, scheitern, weil Sprache zu komplex und flie\xDFend ist. Hier kommen Text-Embeddings ins Spiel: eine leistungsstarke L\xF6sung, die Text in eine Sprache der Zahlen \xFCbersetzt \u2013 genauer gesagt in Vektoren in einem hochdimensionalen Raum.

Betrachten Sie die Ausdr\xFCcke \u201Esonniges Wetter\u201C und \u201Eklarer Himmel\u201C. F\xFCr uns zeichnen sie ein \xE4hnliches Bild. Durch die Linse der Embeddings werden diese Ausdr\xFCcke in numerische Vektoren umgewandelt, die in diesem mehrdimensionalen Raum nahe beieinander liegen und ihre semantische Verwandtschaft erfassen. Bei dieser N\xE4he im Vektorraum geht es nicht nur darum, dass W\xF6rter oder Ausdr\xFCcke \xE4hnlich sind; es geht darum, Kontext, Stimmung und sogar subtile Bedeutungsnuancen zu verstehen.

Warum ist dieser Durchbruch wichtig? Zun\xE4chst einmal \xFCberbr\xFCckt er die L\xFCcke zwischen der Vielfalt der menschlichen Sprache und der Rechenleistung von Algorithmen. Algorithmen sind hervorragend darin, Zahlen zu verarbeiten, nicht darin, Texte zu interpretieren. Durch die Umwandlung von Text in Vektoren erm\xF6glichen Einbettungen diesen Algorithmen, Sprache auf eine Weise zu \u201Everstehen\u201C und zu verarbeiten, die zuvor unerreichbar war.

Die praktischen Anwendungen sind umfangreich und vielf\xE4ltig. Ob es darum geht, Inhalte zu empfehlen, die Ihren Interessen entsprechen, eine Konversations-KI zu betreiben, die \xFCberraschend menschlich wirkt, oder sogar subtile Muster in gro\xDFen Textmengen zu erkennen \u2013 Einbettungen sind der Schl\xFCssel. Sie erm\xF6glichen Maschinen, Aufgaben wie Stimmungsanalyse, Sprach\xFCbersetzung und vieles mehr auszuf\xFChren, mit einem immer nuancierteren und verfeinerten Sprachverst\xE4ndnis.`])},what_is_a_token:n=>{const{normalize:e}=n;return e(["Ein Token ist in der Textverarbeitung eine Einheit, oft ein Wort. Zum Beispiel: \u201EJina AI ist gro\xDFartig!\u201C wird zu f\xFCnf Token, einschlie\xDFlich der Interpunktion."])},why_do_you_need:n=>{const{normalize:e}=n;return e(["Auswahl der richtigen Einbettungen"])},why_do_you_need_after:n=>{const{normalize:e}=n;return e(["Mithilfe tiefer neuronaler Netze und LLMs stellen unsere Einbettungsmodelle multimodale Daten in einem optimierten Format dar, verbessern das Maschinenverst\xE4ndnis, die effiziente Speicherung und erm\xF6glichen fortschrittliche KI-Anwendungen. Diese Einbettungen spielen eine entscheidende Rolle beim Verst\xE4ndnis der Daten, der Verbesserung des Benutzerengagements, der \xDCberwindung von Sprachbarrieren und der Optimierung von Entwicklungsprozessen."])},why_do_you_need_before:n=>{const{normalize:e}=n;return e(["Unsere Einbettungsmodelle sind f\xFCr die Abdeckung vielf\xE4ltiger Such- und GenAI-Anwendungen konzipiert."])},why_need_1_description:n=>{const{normalize:e}=n;return e(["Unser von JinaBERT bereitgestelltes Kerneinbettungsmodell ist f\xFCr ein breites Anwendungsspektrum konzipiert. Es zeichnet sich durch das Verst\xE4ndnis detaillierter Texte aus und eignet sich daher ideal f\xFCr die semantische Suche, Inhaltsklassifizierung und komplexe Sprachanalyse. Seine Vielseitigkeit ist un\xFCbertroffen und unterst\xFCtzt die Erstellung fortschrittlicher Stimmungsanalysetools, Textzusammenfassungen und personalisierter Empfehlungssysteme."])},why_need_1_title:n=>{const{normalize:e}=n;return e(["Allgemeine Einbettungen"])},why_need_2_description:n=>{const{normalize:e}=n;return e(["Unsere zweisprachigen Modelle erleichtern die Kommunikation \xFCber Sprachen hinweg und verbessern mehrsprachige Plattformen, globalen Kundensupport und die Entdeckung mehrsprachiger Inhalte. Diese Modelle wurden f\xFCr die Beherrschung von Deutsch-Englisch- und Chinesisch-Englisch-\xDCbersetzungen entwickelt. Sie vereinfachen die Interaktion und f\xF6rdern das Verst\xE4ndnis zwischen verschiedenen Sprachgruppen."])},why_need_2_title:n=>{const{normalize:e}=n;return e(["Zweisprachige Einbettungen"])},why_need_3_description:n=>{const{normalize:e}=n;return e(["Unser auf Entwickler zugeschnittenes Code-Einbettungsmodell optimiert Codierungsaufgaben wie Zusammenfassung, Codegenerierung und automatische \xDCberpr\xFCfungen. Es steigert die Produktivit\xE4t, indem es tiefere Einblicke in Codestrukturen bietet und Verbesserungen vorschl\xE4gt, was es f\xFCr die Entwicklung fortschrittlicher IDE-Plugins, automatischer Dokumentation und modernster Debugging-Tools unerl\xE4sslich macht."])},why_need_3_title:n=>{const{normalize:e}=n;return e(["Code-Einbettungen"])},why_need_4_description:n=>{const{normalize:e}=n;return e(["Jina CLIP ist unser neuestes multimodales Einbettungsmodell f\xFCr Bild und Text. Eine gro\xDFe Verbesserung gegen\xFCber OpenAI CLIP besteht darin, dass dieses einzelne Modell sowohl f\xFCr Text-Text-Abrufe als auch f\xFCr Text-Bild-, Bild-Text- und Bild-Bild-Abrufaufgaben verwendet werden kann! Also ein Modell, zwei Modalit\xE4ten, vier Suchrichtungen!"])},why_need_4_title:n=>{const{normalize:e}=n;return e(["Multimodale Einbettungen"])},write_email_here:n=>{const{normalize:e}=n;return e(["Bitte geben Sie die E-Mail-Adresse ein, an die Sie nach Abschluss den Download-Link erhalten m\xF6chten."])},you_can_leave:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen diese Seite verlassen und wir senden Ihnen nach Abschluss den Download-Link zu."])}},embeddings:{description:n=>{const{normalize:e}=n;return e(["Unsere erstklassigen Einbettungen f\xFCr Such-, RAG- und Agentensysteme."])}},faq:{answer1:n=>{const{normalize:e}=n;return e(["Jina AI ist auf multimodale KI-Technologien spezialisiert, darunter Model-Tuning, Model-Serving, Prompt-Tuning und Prompt-Serving. Wir nutzen fortschrittliche Tools wie Kubernetes und serverlose Architekturen, um robuste, skalierbare und produktionsbereite L\xF6sungen zu erstellen."])},answer10:n=>{const{normalize:e}=n;return e(["Je nach Art des Projekts und den Bed\xFCrfnissen des Kunden bieten wir verschiedene Lizenzoptionen an. Detaillierte Konditionen k\xF6nnen mit unserem Vertriebsteam besprochen werden."])},answer11:n=>{const{normalize:e}=n;return e(["Wir bieten Dienstleistungen weltweit an, mit unserem Hauptsitz in Berlin, Europa, und weiteren B\xFCros in Peking und Shenzhen."])},answer12:n=>{const{normalize:e}=n;return e(["Ja, wir bieten Vor-Ort-Support an, insbesondere f\xFCr Kunden in der N\xE4he unserer B\xFCros in Berlin, Peking und Shenzhen. F\xFCr andere Standorte streben wir einen bestm\xF6glichen Remote-Support an und k\xF6nnen bei Bedarf auch einen Vor-Ort-Support arrangieren."])},answer2:n=>{const{normalize:e}=n;return e(["Unsere Expertise erstreckt sich \xFCber ein breites Spektrum und umfasst gro\xDFe Sprachmodelle, Text-, Bild-, Video- und Audioverst\xE4ndnis, neuronale Suche und generative Kunst."])},answer3:n=>{const{normalize:e}=n;return e(["Ja, unsere L\xF6sungen sind skalierbar und produktionsbereit. Wir erstellen unsere L\xF6sungen mithilfe cloudnativer Technologien, die eine effiziente Skalierung und zuverl\xE4ssige Leistung in Produktionsumgebungen erm\xF6glichen."])},answer4:n=>{const{normalize:e}=n;return e(["Unsere Dienstleistungen sind vielseitig und anpassungsf\xE4hig und eignen sich daher f\xFCr eine Vielzahl von Branchen, darunter E-Commerce, Legal Tech, digitales Marketing, Gaming, Gesundheitswesen, Finanzen und viele mehr."])},answer5:n=>{const{normalize:e}=n;return e(["\xDCber das Kontaktformular auf dieser Seite k\xF6nnen Sie mit unserem Vertriebsteam in Kontakt treten. Wir besprechen gerne Ihre Projektanforderungen und wie unsere L\xF6sungen Ihrem Unternehmen helfen k\xF6nnen."])},answer6:n=>{const{normalize:e}=n;return e(["Wir bieten kontinuierliche Unterst\xFCtzung, um den reibungslosen Betrieb unserer L\xF6sungen sicherzustellen. Dazu geh\xF6ren Fehlerbehebung, regelm\xE4\xDFige Updates und Verbesserungen basierend auf Ihrem Feedback und Ihren Bed\xFCrfnissen."])},answer7:n=>{const{normalize:e}=n;return e(["Die Projektdauer variiert je nach Komplexit\xE4t und Umfang des Projekts. Nachdem wir Ihre Anforderungen verstanden haben, k\xF6nnen wir einen genaueren Kostenvoranschlag erstellen."])},answer8:n=>{const{normalize:e}=n;return e(["Datensicherheit hat f\xFCr uns oberste Priorit\xE4t. Wir halten uns an strenge Datenschutzrichtlinien und -vorschriften, um sicherzustellen, dass Ihre Daten sicher und vertraulich sind."])},answer9:n=>{const{normalize:e}=n;return e(["Die Preisgestaltung richtet sich nach der Komplexit\xE4t und den Anforderungen des Projekts. Wir bieten sowohl projektbasierte als auch Retainer-Preismodelle an. F\xFCr weitere Informationen wenden Sie sich bitte an unser Vertriebsteam."])},question1:n=>{const{normalize:e}=n;return e(["Worauf ist Jina AI spezialisiert?"])},question10:n=>{const{normalize:e}=n;return e(["Welche Lizenzbedingungen gelten f\xFCr Ihre L\xF6sungen?"])},question11:n=>{const{normalize:e}=n;return e(["Was ist Ihr Servicegebiet?"])},question12:n=>{const{normalize:e}=n;return e(["Bieten Sie Vor-Ort-Support an?"])},question2:n=>{const{normalize:e}=n;return e(["Mit welchen Arten von KI arbeitet Jina AI?"])},question3:n=>{const{normalize:e}=n;return e(["Sind Ihre L\xF6sungen skalierbar und produktionsreif?"])},question4:n=>{const{normalize:e}=n;return e(["Welche Branchen k\xF6nnen von den L\xF6sungen von Jina AI profitieren?"])},question5:n=>{const{normalize:e}=n;return e(["Wie starten wir ein Projekt mit Jina AI?"])},question6:n=>{const{normalize:e}=n;return e(["Welche Unterst\xFCtzung leisten Sie nach der Implementierung einer L\xF6sung?"])},question7:n=>{const{normalize:e}=n;return e(["Was ist die typische Dauer f\xFCr ein Projekt?"])},question8:n=>{const{normalize:e}=n;return e(["Wie sch\xFCtzt Jina AI meine Daten?"])},question9:n=>{const{normalize:e}=n;return e(["Wie ist die Preisstruktur f\xFCr Ihre Dienstleistungen?"])}},faq_button:n=>{const{normalize:e}=n;return e(["FAQ"])},finetuner:{description:n=>{const{normalize:e}=n;return e(["Optimieren Sie die Einbettungen dom\xE4nenspezifischer Daten f\xFCr eine bessere Suchqualit\xE4t"])},intro:n=>{const{normalize:e}=n;return e(["Ihr Unternehmen. Deine Daten. Ihr Modell"])}},finetuner_plus:{description:n=>{const{normalize:e}=n;return e(["St\xE4rken Sie Ihr Unternehmen mit gro\xDFen Sprachmodellen die genau auf Ihre Daten zugeschnitten sind"])}},finetuning:{api_key:n=>{const{normalize:e}=n;return e(["Geben Sie Ihren API-Schl\xFCssel ein."])},back:n=>{const{normalize:e}=n;return e(["Zur\xFCck"])},base_model_selected:n=>{const{normalize:e}=n;return e(["Basismodell ausgew\xE4hlt"])},click_start:n=>{const{normalize:e}=n;return e(["Stimmen Sie den Bedingungen zu und beginnen Sie mit der Feinabstimmung."])},confirm_title:n=>{const{normalize:e}=n;return e(["Feinabstimmung best\xE4tigen"])},confirm_your_email:n=>{const{normalize:e}=n;return e(["Geben Sie Ihre E-Mail-Adresse erneut ein, um die Feinabstimmung zu best\xE4tigen. Updates und der Download-Link werden an diese E-Mail-Adresse gesendet."])},consent0:n=>{const{normalize:e}=n;return e(["Ich bin damit einverstanden, dass nach meinen Vorgaben synthetische Daten zur Modellfeinabstimmung generiert werden."])},consent1:n=>{const{normalize:e}=n;return e(["Ich erkenne an, dass das endg\xFCltige Modell und die synthetischen Daten auf Hugging Face \xF6ffentlich zug\xE4nglich sein werden."])},consent2:n=>{const{normalize:e}=n;return e(["Ich verstehe, dass diese Funktion sich in der Betaphase befindet und Jina AI keine Garantien bietet. Preise und UX k\xF6nnen sich \xE4ndern."])},continue:n=>{const{normalize:e}=n;return e(["Weitermachen"])},cost_1m_token:n=>{const{normalize:e}=n;return e(["Jeder Feinabstimmungsjob verbraucht 1 Million Token. Stellen Sie sicher, dass Sie \xFCber gen\xFCgend Token verf\xFCgen, oder laden Sie Ihr Guthaben auf. Sie k\xF6nnen auch einen neuen API-Schl\xFCssel generieren. Jeder API-Schl\xFCssel enth\xE4lt 1 Million kostenlose Token."])},doc_explain:n=>{const{normalize:e}=n;return e(["Beschreiben Sie, wie ein \xFCbereinstimmendes Dokument aussehen sollte."])},domain_explain:n=>{const{normalize:e}=n;return e(["Geben Sie eine detaillierte Beschreibung an, wie die fein abgestimmten Einbettungen verwendet werden. Dies ist wichtig, um qualitativ hochwertige synthetische Daten zu generieren, die die Leistung Ihrer Einbettungen verbessern."])},domain_explain2:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen Ihre Anforderung auf drei Arten angeben: eine allgemeine Anweisung, eine URL oder eine Abfragedokumentbeschreibung. W\xE4hlen Sie eine aus."])},domain_hint:n=>{const{normalize:e}=n;return e(["Beschreiben Sie die Dom\xE4ne, f\xFCr die Sie die Feinabstimmung vornehmen m\xF6chten."])},email_not_match:n=>{const{normalize:e}=n;return e(["Die E-Mail-Adressen stimmen nicht \xFCberein. Bitte \xFCberpr\xFCfen Sie."])},failed_job:n=>{const{normalize:e}=n;return e(["Die Feinabstimmungsanforderung ist fehlgeschlagen. Den Grund finden Sie weiter unten."])},find_on_huggingface:n=>{const{normalize:e}=n;return e(["Ergebnisse finden zu Hugging Face"])},general_instruction:n=>{const{normalize:e}=n;return e(["Oder allgemeine Anweisung"])},general_instruction_caption:n=>{const{normalize:e}=n;return e(["Geben Sie eine detaillierte Beschreibung der Verwendung der feinabgestimmten Einbettungen an."])},general_instruction_explain:n=>{const{normalize:e}=n;return e(["Beschreiben Sie Ihre Domain in freiem Text. Sie k\xF6nnen es sich als eine \u201EEingabeaufforderung\u201C wie in ChatGPT vorstellen."])},how_it_works:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr \xFCber den Feinabstimmungsprozess."])},job_acknowledged:n=>{const{normalize:e}=n;return e(["Ihr Feinabstimmungsauftrag wurde in die Warteschlange gestellt. Sie erhalten eine E-Mail, wenn der Auftrag beginnt. Der gesamte Vorgang dauert oft 20 Minuten."])},new_key:n=>{const{normalize:e}=n;return e(["Neuen Schl\xFCssel anfordern"])},not_enough_token:n=>{const{normalize:e}=n;return e(["Nicht gen\xFCgend Token in diesem API-Schl\xFCssel. Bitte laden Sie Ihr Guthaben auf oder verwenden Sie einen anderen API-Schl\xFCssel."])},placeholder:n=>{const{normalize:e}=n;return e(["Anspr\xFCche aus der Kfz-Versicherung"])},preview:n=>{const{normalize:e}=n;return e(["Vorschau"])},query_doc:n=>{const{normalize:e}=n;return e(["Abfrage-Dokumentbeschreibung"])},query_doc_caption:n=>{const{normalize:e}=n;return e(["Beschreiben Sie, wie die Abfrage aussieht und wie das \xFCbereinstimmende Dokument in Ihrer Dom\xE4ne aussieht."])},query_explain:n=>{const{normalize:e}=n;return e(["Beschreiben Sie, wie eine Abfrage aussieht."])},reset:n=>{const{normalize:e}=n;return e(["Von vorn anfangen"])},select_base_model:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie zur Feinabstimmung ein Basis-Einbettungsmodell."])},select_base_model_explain:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie ein Basismodell als Ausgangspunkt f\xFCr die Feinabstimmung aus. Normalerweise ist Base-en eine gute Wahl, aber f\xFCr Aufgaben in anderen Sprachen sollten Sie die Verwendung eines zweisprachigen Modells in Betracht ziehen."])},start_tuning:n=>{const{normalize:e}=n;return e(["Beginnen Sie mit der Feinabstimmung"])},url:n=>{const{normalize:e}=n;return e(["Oder Webseiten-URL"])},url_caption:n=>{const{normalize:e}=n;return e(["Zur Feinabstimmung k\xF6nnen Sie den Inhalt einer URL konsultieren."])},url_explain:n=>{const{normalize:e}=n;return e(["\xD6ffentliche URL einer Webseite, die den Inhalt enth\xE4lt, den Sie optimieren m\xF6chten."])},use_url:n=>{const{normalize:e}=n;return e(["Verwenden Sie stattdessen die URL. Wenn Sie diese Option aktivieren, werden wir auf Grundlage des Seiteninhalts dieser URL synthetische Daten zur Feinabstimmung generieren."])},wait_for_processing:n=>{const{normalize:e}=n;return e(["Bitte warten Sie, w\xE4hrend wir Ihre Anfrage verarbeiten..."])},which_domain:n=>{const{normalize:e}=n;return e(["Feinabstimmung der Dom\xE4ne"])},write_email_explain:n=>{const{normalize:e}=n;return e(["Die Feinabstimmung braucht Zeit. Wir informieren Sie per E-Mail \xFCber den Beginn, den Fortschritt, die Fertigstellung und etwaige Probleme Ihrer Feinabstimmungsarbeit sowie \xFCber Einzelheiten zum feinabgestimmten Modell und Trainingsdatensatz."])}},footer:{address_beijing:n=>{const{normalize:e}=n;return e(["Peking, China"])},address_berlin:n=>{const{normalize:e}=n;return e(["Berlin, Deutschland (Hauptsitz)"])},address_shenzhen:n=>{const{normalize:e}=n;return e(["Shenzhen, China"])},all_rights_reserved:n=>{const{normalize:e}=n;return e(["Alle Rechte vorbehalten."])},company:n=>{const{normalize:e}=n;return e(["Unternehmen"])},developers:n=>{const{normalize:e}=n;return e(["Entwickler"])},docs:n=>{const{normalize:e}=n;return e(["Dokumente"])},enterprise:n=>{const{normalize:e}=n;return e(["Unternehmen"])},get_api_key:n=>{const{normalize:e}=n;return e(["Holen Sie sich den Jina AI API-Schl\xFCssel"])},offices:n=>{const{normalize:e}=n;return e(["B\xFCros"])},power_users:n=>{const{normalize:e}=n;return e(["Power-User"])},privacy:n=>{const{normalize:e}=n;return e(["Privatsph\xE4re"])},privacy_policy:n=>{const{normalize:e}=n;return e(["Datenschutz-Bestimmungen"])},privacy_settings:n=>{const{normalize:e}=n;return e(["Cookie-Einstellungen"])},status:n=>{const{normalize:e}=n;return e(["API-Status"])},tc:n=>{const{normalize:e}=n;return e(["Terms & amp; Bedingungen"])},tc1:n=>{const{normalize:e}=n;return e(["Bedingungen"])}},get_new_key:n=>{const{normalize:e}=n;return e(["Holen Sie sich Ihren API-Schl\xFCssel"])},github:{stars:n=>{const{normalize:e}=n;return e(["Sterne"])}},header:{about_us:n=>{const{normalize:e}=n;return e(["\xDCber uns"])},company:n=>{const{normalize:e}=n;return e(["Unternehmen"])},contact_us:n=>{const{normalize:e}=n;return e(["Kontaktieren Sie unseren Vertrieb"])},developers_others:n=>{const{normalize:e}=n;return e(["Weitere Entwicklertools"])},enterprise_others:n=>{const{normalize:e}=n;return e(["Weitere Enterprise-Tools"])},for_developers:n=>{const{normalize:e}=n;return e(["F\xFCr Entwickler"])},for_developers_description:n=>{const{normalize:e}=n;return e(["Erleben Sie einen umfassenden multimodalen Open-Source-KI-Stack, der f\xFCr Entwickler entwickelt wurde."])},for_enterprise:n=>{const{normalize:e}=n;return e(["F\xFCr Firmen"])},for_enterprise_description:n=>{const{normalize:e}=n;return e(["Entdecken Sie skalierbare multimodale KI-Strategien, die auf die Gesch\xE4ftsanforderungen zugeschnitten sind."])},for_power_users:n=>{const{normalize:e}=n;return e(["F\xFCr Power-User"])},for_power_users_description:n=>{const{normalize:e}=n;return e(["Nutzen Sie unsere optimierten multimodalen Tools, um Ihre Produktivit\xE4t zu steigern."])},internship1:n=>{const{normalize:e}=n;return e(["Praktikantenprogramm"])},jobs:n=>{const{normalize:e}=n;return e(["Begleiten Sie uns"])},join_discord:n=>{const{normalize:e}=n;return e(["Treten Sie unserer Discord-Community bei"])},logos:n=>{const{normalize:e}=n;return e(["Logo herunterladen"])},news:n=>{const{normalize:e}=n;return e(["Pressemitteilungen"])},open_day:n=>{const{normalize:e}=n;return e(["Tag der offenen T\xFCr"])},open_in_full:n=>{const{normalize:e}=n;return e(["Alle Enterprise-Produkte in einem neuen Fenster anzeigen"])},power_users_others:n=>{const{normalize:e}=n;return e(["Mehr Power-User-Tools"])},products:n=>{const{normalize:e}=n;return e(["Produkte"])}},hub:{description:n=>{const{normalize:e}=n;return e(["Teilen und entdecken Sie Bausteine \u200B\u200Bf\xFCr multimodale KI-Anwendungen"])}},huggingface:{sentence_similarity:n=>{const{normalize:e}=n;return e(["Text-Embedding"])},updated_about:n=>{const{normalize:e}=n;return e(["Aktualisiert \xFCber"])}},impact_snapshots:{project1:n=>{const{normalize:e}=n;return e(["Erm\xF6glicht eine hochpr\xE4zise Suche in 3D-Netzdaten unter Verwendung von Punktwolkeninformationen."])},project10:n=>{const{normalize:e}=n;return e(["Nutzung von Computer Vision zur Verbesserung der digitalen Zug\xE4nglichkeit von Regierungswebsites."])},project11:n=>{const{normalize:e}=n;return e(["Fein abgestimmtes LLM f\xFCr ein Beratungsunternehmen zur Optimierung der Finanzdatenanalyse."])},project12:n=>{const{normalize:e}=n;return e(["Fortschrittliche Marketingstrategien durch Feinabstimmung von Text-zu-Bild-Modellen f\xFCr die Stil\xFCbertragung."])},project2:n=>{const{normalize:e}=n;return e(["Entwickelte eine inhaltsbasierte Suchmaschine f\xFCr kurze Animationsfilme."])},project3:n=>{const{normalize:e}=n;return e(["Verbesserte E-Commerce-Conversion-Rates durch Feinabstimmung der Embedding-Modelle."])},project4:n=>{const{normalize:e}=n;return e(["Durchf\xFChrung zeitnaher Optimierungen zur Effizienzsteigerung f\xFCr ein Unternehmensberatungen."])},project5:n=>{const{normalize:e}=n;return e(["Pionierarbeit beim Verst\xE4ndnis von Spielszenen und automatischer Annotation f\xFCr ein f\xFChrendes Gaming-Unternehmen."])},project6:n=>{const{normalize:e}=n;return e(["Implementierung einer Echtzeit-Prompt-Erweiterung f\xFCr ein Chatbot-Unternehmen, um das Benutzererlebnis zu verbessern."])},project7:n=>{const{normalize:e}=n;return e(["Revolutionierte die Rechtstechnologie, indem es eine effiziente Suche in umfangreichen Rechtsdokumenten erm\xF6glichte."])},project8:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzung eines generativen Kunstdienstes mit hohem Durchsatz f\xFCr gro\xDF angelegte Operationen."])},project9:n=>{const{normalize:e}=n;return e(["Durchf\xFChrung von Process-Mining und Modellierung unter Verwendung fortschrittlicher Sprachmodelle."])}},inference:{description:n=>{const{normalize:e}=n;return e(["Hochmoderne multimodale KI-Modelle stehen f\xFCr Sie \xFCber unsere API zur Verf\xFCgung"])}},integrations:{embedding:n=>{const{normalize:e}=n;return e(["Einbettungen"])},reranker:n=>{const{normalize:e}=n;return e(["Neubewerter"])},which_to_go:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Welches soll mit ",r(i("_vendor"))," integriert werden?"])}},internship_faq:{answer1:n=>{const{normalize:e}=n;return e(["Bachelor-, Master- und Ph.D.-Studieng\xE4nge Studierende aus der ganzen Welt mit Interesse an Bereichen wie Forschung, Ingenieurwesen, Marketing und Vertrieb werden aufgefordert, sich zu bewerben. Wir freuen uns auch \xFCber nicht-technische Praktika in den Bereichen Marketing, Vertrieb, Assistenz von F\xFChrungskr\xE4ften und mehr. Wir suchen leidenschaftliche Menschen, die bereit sind, mit uns Pionierarbeit in der multimodalen KI zu leisten."])},answer10:n=>{const{normalize:e}=n;return e(["Ja, unser Praktikumsprogramm bietet eine wettbewerbsf\xE4hige Verg\xFCtung."])},answer11:n=>{const{normalize:e}=n;return e(["Als Jina AI-Praktikant sammeln Sie praktische Erfahrungen bei der Arbeit an anspruchsvollen Projekten, lernen von Branchenexperten, werden Teil einer lebendigen Community und haben die M\xF6glichkeit, echte Beitr\xE4ge zu unserer Pionierarbeit in der multimodalen KI zu leisten."])},answer2:n=>{const{normalize:e}=n;return e(["Praktika m\xFCssen vor Ort in einem unserer B\xFCros in Berlin, Peking und Shenzhen absolviert werden."])},answer3:n=>{const{normalize:e}=n;return e(["Ja, Jina AI bietet erfolgreichen Antragstellern angemessene Unterst\xFCtzung im Visumverfahren."])},answer4:n=>{const{normalize:e}=n;return e(["Ja, Jina AI bietet Praktikanten w\xE4hrend des Praktikums eine angemessene Deckung der Lebenshaltungskosten an."])},answer5:n=>{const{normalize:e}=n;return e(["Ja, die Anfertigung Ihrer Masterarbeit w\xE4hrend Ihres Praktikums bei Jina AI ist in der Regel f\xFCr Studierende deutscher Hochschulen m\xF6glich. Sie ben\xF6tigen jedoch eine vorherige Mitteilung und Zustimmung des Betreuers Ihrer Universit\xE4t. Beachten Sie, dass wir Studierenden nicht bei der Suche nach Beratern helfen."])},answer6:n=>{const{normalize:e}=n;return e(["Der Bewerbungsprozess umfasst die Einreichung Ihres Bewerbungsformulars, eines Lebenslaufs, eines Anschreibens, in dem Sie Ihr Interesse und Ihre Motivation zum Ausdruck bringen, sowie aller relevanten beruflichen Links wie GitHub oder LinkedIn. Wir bewerten Kandidaten anhand ihrer Leistung w\xE4hrend des Vorstellungsgespr\xE4chs und ihrer Leistung an ihrer Universit\xE4t."])},answer7:n=>{const{normalize:e}=n;return e(["Ja, erfolgreiche Praktikanten k\xF6nnen am Ende ihres Praktikums ein Empfehlungsschreiben erhalten, das von unserem CEO unterzeichnet wird."])},answer8:n=>{const{normalize:e}=n;return e(["Die Dauer des Praktikums variiert je nach Rolle und Projekt. In der Regel liegt sie jedoch zwischen drei und sechs Monaten."])},answer9:n=>{const{normalize:e}=n;return e(["Ja, wir freuen uns \xFCber Bewerbungen mit allen akademischen Hintergr\xFCnden. Wir sch\xE4tzen Ihre Leidenschaft und Ihr Engagement f\xFCr das Lernen ebenso wie Ihre vorherige Erfahrung."])},question1:n=>{const{normalize:e}=n;return e(["Wer kann sich f\xFCr das Jina AI-Praktikumsprogramm bewerben?"])},question10:n=>{const{normalize:e}=n;return e(["Ist das ein bezahltes Praktikum?"])},question11:n=>{const{normalize:e}=n;return e(["Welche M\xF6glichkeiten habe ich als Jina AI-Praktikant?"])},question2:n=>{const{normalize:e}=n;return e(["Wo findet das Praktikum statt?"])},question3:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzt Jina AI bei Visa-Prozessen?"])},question4:n=>{const{normalize:e}=n;return e(["Bietet Jina AI Praktikanten Zulagen oder Vorteile?"])},question5:n=>{const{normalize:e}=n;return e(["Kann ich w\xE4hrend des Praktikums bei Jina AI an meiner Masterarbeit arbeiten?"])},question6:n=>{const{normalize:e}=n;return e(["Wie l\xE4uft der Bewerbungsprozess ab?"])},question7:n=>{const{normalize:e}=n;return e(["Stellt Jina AI nach dem Praktikum ein Empfehlungsschreiben aus?"])},question8:n=>{const{normalize:e}=n;return e(["Wie lange dauert das Praktikum?"])},question9:n=>{const{normalize:e}=n;return e(["Kann ich mich bewerben, wenn ich noch keine Erfahrung im Bereich KI habe?"])}},internship_page:{about_internship_program:n=>{const{normalize:e}=n;return e(["\xDCber das Praktikumsprogramm"])},about_internship_program_desc1:n=>{const{normalize:e}=n;return e(["Wir freuen uns, talentierten Menschen diese einzigartige Gelegenheit bieten zu k\xF6nnen, Teil unseres dynamischen Teams zu werden und an bahnbrechenden Projekten im Bereich der k\xFCnstlichen Intelligenz mitzuwirken. Dieses Praktikum soll Ihnen wertvolle praktische Erfahrungen, Mentoring und Einblick in modernste Technologien bieten, die die Zukunft der KI pr\xE4gen."])},about_internship_program_desc2:n=>{const{normalize:e}=n;return e(["Bei Jina AI wissen wir, wie wichtig es ist, junge Talente zu f\xF6rdern und zu gewinnen. Wir wissen, dass Praktikanten neue Perspektiven, Begeisterung und Kreativit\xE4t einbringen und unser Team mit neuen Ideen und Ans\xE4tzen beleben. Durch die Bereitstellung von Praktika wollen wir das Wachstum zuk\xFCnftiger F\xFChrungskr\xE4fte in der KI-Branche f\xF6rdern und ihnen gleichzeitig praktische Erfahrungen in einem unterst\xFCtzenden und herausfordernden Umfeld bieten."])},alumni:n=>{const{normalize:e}=n;return e(["ALUMNI"])},alumni_network:n=>{const{normalize:e}=n;return e(["Unser florierendes Alumni-Netzwerk"])},application:n=>{const{normalize:e}=n;return e(["Anwendung"])},application_desc:n=>{const{normalize:e}=n;return e(["Begeben Sie sich mit Jina AI auf eine transformative Reise. Unser umfassendes Praktikumsprogramm l\xE4dt alle leidenschaftlichen K\xF6pfe ein, die die Zukunft der k\xFCnstlichen Intelligenz mitgestalten m\xF6chten. Kommen Sie zu uns, um praktische Erfahrungen zu sammeln, an anspruchsvollen Projekten zu arbeiten und mit einigen der kl\xFCgsten K\xF6pfe der KI-Branche zusammenzuarbeiten."])},apply:n=>{const{normalize:e}=n;return e(["Jetzt bewerben"])},autumn:n=>{const{normalize:e}=n;return e(["Herbst"])},description:n=>{const{normalize:e}=n;return e(["Weltweite Ausschreibung f\xFCr Studenten: Praktika in Forschung, Entwicklung, Marketing, Vertrieb und mehr."])},dev_rel_intern:n=>{const{normalize:e}=n;return e(["Praktikant im Bereich Developer Relations"])},enthusiastic:n=>{const{normalize:e}=n;return e(["ENTHUSIASTISCH"])},explore_stories_from_our_interns:n=>{const{normalize:e}=n;return e(["Entdecken Sie Geschichten unserer Praktikanten"])},explore_stories_from_our_interns1:n=>{const{normalize:e}=n;return e(["Lassen Sie sich von den Reisen unserer Praktikanten inspirieren"])},innovative:n=>{const{normalize:e}=n;return e(["INNOVATIV"])},intern_work1:n=>{const{normalize:e}=n;return e(["Fein abgestimmte LLM-Modelle f\xFCr bessere Einbettungen"])},intern_work2:n=>{const{normalize:e}=n;return e(["Erkundete das Potenzial der Retrieval Augmented Generation"])},intern_work3:n=>{const{normalize:e}=n;return e(["Ver\xF6ffentlichung eines Artikels zum Thema Satzeinbettungen"])},intern_work4:n=>{const{normalize:e}=n;return e(["Der Mannschaft kontinuierlich jugendliche Vitalit\xE4t verleihen"])},intern_work5:n=>{const{normalize:e}=n;return e(["Benchmarked-Quantisierungstechniken zur Komprimierung von LLM"])},intern_work6:n=>{const{normalize:e}=n;return e(["Erstellen und Bewerben einer \xFCberzeugenden Kampagne f\xFCr PromptPerfect"])},recruiting_and_administrative_intern:n=>{const{normalize:e}=n;return e(["Praktikant im Bereich Personalbeschaffung und Verwaltung"])},self_motivated:n=>{const{normalize:e}=n;return e(["SELBST MOTIVIERT"])},software_engineer_intern:n=>{const{normalize:e}=n;return e(["Praktikant im Bereich Software-Ingenieur"])},spring:n=>{const{normalize:e}=n;return e(["Fr\xFChling"])},submit_application:n=>{const{normalize:e}=n;return e(["Starten Sie Ihr Abenteuer mit Jina AI"])},subtitle:n=>{const{normalize:e}=n;return e(["Unser Vollzeit-Praktikumsprogramm bietet praktische Arbeitserfahrung durch gut konzipierte Praktikumsprojekte in einem breiten Spektrum."])},subtitle1:n=>{const{normalize:e}=n;return e(["Weltweiter Aufruf f\xFCr Studenten: Praktikanten in Forschung, Technik, Marketing, Vertrieb und mehr, um gemeinsam Pionierarbeit f\xFCr multimodale KI zu leisten."])},summer:n=>{const{normalize:e}=n;return e(["Sommer"])},title:n=>{const{normalize:e}=n;return e(["Praktikantenprogramm"])},who_do_we_look_for:n=>{const{normalize:e}=n;return e(["Wen suchen wir?"])},who_do_we_look_for_desc:n=>{const{normalize:e}=n;return e(["Wir legen Wert auf Vielfalt und ermutigen Bewerber mit unterschiedlichen Profilen und Hintergr\xFCnden, an unserem Praktikumsprogramm teilzunehmen. Die Praktikumsm\xF6glichkeiten werden in mehreren Abteilungen angeboten, darunter Technik, Design, Produktmanagement, Vertrieb und Account Management, Marketing und Community Management."])},winter:n=>{const{normalize:e}=n;return e(["Winter"])}},jcloud:{description:n=>{const{normalize:e}=n;return e(["Stellen Sie ein lokales Projekt als Cloud-Dienst bereit. Radikal einfach, keine b\xF6sen \xDCberraschungen."])}},jerboa:{description:n=>{const{normalize:e}=n;return e(["Ein experimenteller Finetuner f\xFCr Open-Source-LLMs"])}},jina:{description:n=>{const{normalize:e}=n;return e(["Erstellen Sie multimodale KI-Anwendungen in der Cloud"])}},jina_chat:{description:n=>{const{normalize:e}=n;return e(["Mehr Modalit\xE4ten, l\xE4ngerer Speicher, weniger Kosten"])},example_1:n=>{const{normalize:e}=n;return e(["Wer bist du?"])},example_2:n=>{const{normalize:e}=n;return e(["Ich bin ein LLM-Chat-Dienst von Jina AI"])}},lab_dialog:{GlobalQA:{description:n=>{const{normalize:e}=n;return e(["Dr\xFCcken Sie auf einer beliebigen Seite die Taste \u201E/\u201C, um das Fragenfeld zu \xF6ffnen. Geben Sie Ihre Anfrage ein und dr\xFCcken Sie die Eingabetaste, um Antworten zu erhalten, die sich direkt auf den Seiteninhalt beziehen. Diese Funktion wird von PromptPerfect unterst\xFCtzt."])},title:n=>{const{normalize:e}=n;return e(["On-Page-RAG"])}},Recommender:{description:n=>{const{normalize:e}=n;return e(["\xD6ffnen Sie das Empfehlungsfeld auf einer beliebigen Nachrichtenseite mit \u201EUmschalt+2\u201C. W\xE4hlen Sie das Reranker-Modell aus, um die Top-5-Artikel zu dieser Nachrichtenseite zu entdecken. Genie\xDFen Sie diese Echtzeitfunktion, die von unserer Reranker-API unterst\xFCtzt wird."])},title:n=>{const{normalize:e}=n;return e(["Verwandter Artikel"])}},SceneXplainTooltip:{description:n=>{const{normalize:e}=n;return e(["Bewegen Sie Ihren Mauszeiger \xFCber ein beliebiges Bild auf Nachrichtenseiten oder in unserem Newsroom-Katalog, um die Beschreibung dieses Bildes anzuzeigen. Beschreibungen werden von SceneXplain vorberechnet und zur Barrierefreiheit in das ALT-Attribut des Bildes eingebettet."])},title:n=>{const{normalize:e}=n;return e(["Bildunterschrift"])}},explain:n=>{const{normalize:e}=n;return e(["Entdecken Sie versteckte Funktionen auf unserer Website"])}},landing_page:{also_available_on:n=>{const{normalize:e}=n;return e(["Auch auf den Marktpl\xE4tzen erh\xE4ltlich"])},also_available_on1:n=>{const{normalize:e}=n;return e(["Verf\xFCgbar auf den Marktpl\xE4tzen Ihrer Enterprise Cloud"])},ask_how_your_question:n=>{const{normalize:e}=n;return e(["Bitte beschreibe dein Problem"])},autotune:n=>{const{normalize:e}=n;return e(["Automatische Feinabstimmung"])},badge:{v2:n=>{const{normalize:e}=n;return e(["V2-Version!"])}},build_js:n=>{const{normalize:e}=n;return e(["JavaScript SDK verwenden"])},build_python:n=>{const{normalize:e}=n;return e(["Python SDK verwenden"])},checkout_our_solution_for_you:n=>{const{normalize:e}=n;return e(["Entdecken Sie unsere auf Sie zugeschnittene L\xF6sung"])},coming_soon:n=>{const{normalize:e}=n;return e(["Demn\xE4chst"])},contact_sales:n=>{const{normalize:e}=n;return e(["Kontakt"])},copied_to_clipboard:n=>{const{normalize:e}=n;return e(["In die Zwischenablage kopiert"])},copy:n=>{const{normalize:e}=n;return e(["Kopieren"])},developers:n=>{const{normalize:e}=n;return e(["Entwickler"])},developers_desc:n=>{const{normalize:e}=n;return e(["Nutzen Sie die volle Leistungsf\xE4higkeit multimodaler KI mit modernsten Cloud-Technologien und Open-Source-Infrastruktur."])},download_pdf:n=>{const{normalize:e}=n;return e(["PDF Herunterladen"])},embedding_desc1:n=>{const{normalize:e}=n;return e(["Das weltweit erste Open-Source-Einbettungsmodell mit einer L\xE4nge von 8192 Token, das mit text-embedding-ada002 von OpenAI im Massive Text Embedding Benchmark (MTEB) \xFCbereinstimmt."])},embedding_paper_desc:n=>{const{normalize:e}=n;return e(["Jina Embeddings stellt eine Reihe leistungsstarker Text-Embedding-odelle dar, die in der Lage sind, verschiedene Texteingaben in numerische Darstellungen zu \xFCbersetzen und so die semantische Essenz des Textes zu erfassen. Obwohl diese Modelle nicht ausschlie\xDFlich f\xFCr die Textgenerierung konzipiert sind, zeichnen sie sich durch Anwendungen wie Dense Retrieval und semantische Text\xE4hnlichkeit aus. In diesem Artikel wird die Entwicklung von Jina Embeddings detailliert beschrieben, beginnend mit der Erstellung eines hochwertigen Paar- und Triplett-Datensatzes. Es unterstreicht die entscheidende Rolle der Datenbereinigung bei der Datensatzvorbereitung, gibt detaillierte Einblicke in den Modelltrainingsprozess und schlie\xDFt mit einer umfassenden Leistungsbewertung mithilfe des Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:n=>{const{normalize:e}=n;return e(["Jina Embeddings: Ein neuartiger Satz leistungsstarker Text-Embedding-Modelle"])},embeddings:n=>{const{normalize:e}=n;return e(["Einbettungen"])},enterprise:n=>{const{normalize:e}=n;return e(["Unternehmen"])},enterprise_desc:n=>{const{normalize:e}=n;return e(["Steigern Sie Ihr Gesch\xE4ft mit skalierbaren, sicheren und ma\xDFgeschneiderten multimodalen KI-L\xF6sungen."])},enterprise_desc_v2:n=>{const{normalize:e}=n;return e(["Probieren Sie unsere erstklassigen Einbettungsmodelle aus, um Ihre Such- und RAG-Systeme zu verbessern. Beginnen Sie mit einer kostenlosen Testversion!"])},enterprise_desc_v3:n=>{const{normalize:e}=n;return e(["Wir entwickeln hochmoderne Suchgrundlagen f\xFCr hochwertige Enterprise-Such- und RAG-L\xF6sungen. Beginnen Sie mit einer kostenlosen Testversion!"])},error:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Beim Abrufvorgang ist ein Problem aufgetreten: ",r(i("message"))])},find_your_portal:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie Ihr Portal"])},finding_faq:n=>{const{normalize:e}=n;return e(["Generieren einer Antwort basierend auf dem FAQ-Wissen unten"])},for:n=>{const{normalize:e}=n;return e(["F\xFCr"])},for_developers:n=>{const{normalize:e}=n;return e(["F\xFCr Entwickler"])},for_enterprise:n=>{const{normalize:e}=n;return e(["F\xFCr Unternehmen"])},for_power_users:n=>{const{normalize:e}=n;return e(["F\xFCr Power-User"])},get_api_now:n=>{const{normalize:e}=n;return e(["API"])},get_started:n=>{const{normalize:e}=n;return e(["Loslegen"])},how_to:n=>{const{normalize:e}=n;return e(["Wie man"])},include_experiment:n=>{const{normalize:e}=n;return e(["Bezieht unsere experimentellen und archivierten Projekte in die L\xF6sung ein."])},join_community:n=>{const{normalize:e}=n;return e(["Gemeinschaft"])},learn_more_embeddings:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr \xFCber Einbettungen"])},learn_more_reader:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr \xFCber den Reader"])},learn_more_reranker:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr \xFCber Reranker"])},llm:n=>{const{normalize:e}=n;return e(["LLM-Embedding-Modelle"])},llm_desc:n=>{const{normalize:e}=n;return e(["Wir bieten eine Sammlung leistungsstarker Text-Embedding-Modelle mit 35 Millionen bis 6 Milliarden Parametern. Sie eignen sich hervorragend zur Verbesserung der neuronalen Suche, Neuordnung, Satz\xE4hnlichkeit, Empfehlungen usw. Machen Sie sich bereit, Ihr KI-Erlebnis zu verbessern!"])},mentioned_products:n=>{const{normalize:e}=n;return e(["Erw\xE4hnte Produkte:"])},mmstack:n=>{const{normalize:e}=n;return e(["Multimodaler Stapel"])},mmstack_desc:n=>{const{normalize:e}=n;return e(["Im Laufe der Jahre haben wir eine Vielzahl von Open-Source-Software entwickelt, die Entwicklern hilft, schneller bessere GenAI- und Suchanwendungen zu erstellen."])},more:n=>{const{normalize:e}=n;return e(["Mehr"])},multimodal:n=>{const{normalize:e}=n;return e(["Multimodal"])},multimodal_ai:n=>{const{normalize:e}=n;return e(["Multimodalen KI"])},new:n=>{const{normalize:e}=n;return e(["Neu"])},newsroom:n=>{const{normalize:e}=n;return e(["Pressemitteilungen"])},"on-prem-deploy":n=>{const{normalize:e}=n;return e(["Bereitstellung vor Ort"])},"on-premises":n=>{const{normalize:e}=n;return e(["Auf dem Gel\xE4nde"])},opensource:n=>{const{normalize:e}=n;return e(["Open Source"])},our_publications:n=>{const{normalize:e}=n;return e(["Unsere Ver\xF6ffentlichungen"])},parameters:n=>{const{normalize:e}=n;return e(["Parameter"])},podcast:n=>{const{normalize:e}=n;return e(["Podcast"])},power_users:n=>{const{normalize:e}=n;return e(["Power-User"])},power_users_desc:n=>{const{normalize:e}=n;return e(["Auto-Prompt-Engineering f\xFCr Ihre t\xE4gliche Produktivit\xE4t."])},powered_by_promptperfect:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzt durch die Funktionen \u201EPrompt-Optimierung\u201C und \u201EPrompt as a Service\u201C von PromptPerfect"])},pricing:n=>{const{normalize:e}=n;return e(["Preisgestaltung"])},proposing_solution:n=>{const{normalize:e}=n;return e(["Vorschlag einer L\xF6sung basierend auf Jina AI-Produkten..."])},read_more:n=>{const{normalize:e}=n;return e(["Weiterlesen"])},reader:n=>{const{normalize:e}=n;return e(["Leser"])},require_full_question:n=>{const{normalize:e}=n;return e(["Bitte beschreiben Sie Ihr Problem detaillierter."])},reranker:n=>{const{normalize:e}=n;return e(["Reranker"])},researcher_desc:n=>{const{normalize:e}=n;return e(["Erfahren Sie, wie unsere Suchgrundlagen von Grund auf trainiert wurden, und sehen Sie sich unsere neuesten Ver\xF6ffentlichungen an. Lernen Sie unser Team bei EMNLP, SIGIR, ICLR, NeurIPS und ICML kennen!"])},researchers:n=>{const{normalize:e}=n;return e(["Forscher"])},sdk:n=>{const{normalize:e}=n;return e(["SDK"])},sdk_desc:n=>{const{normalize:e}=n;return e(["M\xF6chten Sie zukunftsweisende AIGC-Anwendungen erstellen? Mit den APIs PromptPerfect, SceneXplain, BestBanner, JinaChat und Rationale ist das einfach. Probieren Sie unser benutzerfreundliches SDK aus und legen Sie in wenigen Minuten los."])},sdk_docs:n=>{const{normalize:e}=n;return e(["Lesen Sie die Dokumente"])},sdk_example:n=>{const{normalize:e}=n;return e(["Beispiel"])},search_foundation:n=>{const{normalize:e}=n;return e(["Stiftung durchsuchen"])},source_code:n=>{const{normalize:e}=n;return e(["Quellcode"])},starter_kit:n=>{const{normalize:e}=n;return e(["Starter-Kit"])},supercharged1:n=>{const{normalize:e}=n;return e(["Aufgeladen."])},tokenizer:n=>{const{normalize:e}=n;return e(["Tokenisierer"])},trusted_by:n=>{const{normalize:e}=n;return e(["UNSERE PARTNER"])},try_it_for_free:n=>{const{normalize:e}=n;return e(["Probieren Sie es kostenlos aus, keine Kreditkarte erforderlich"])},try_our_saas:n=>{const{normalize:e}=n;return e(["Probieren Sie unsere gehostete L\xF6sung aus, einen direkten Ersatz f\xFCr die Einbettungs-API von OpenAI."])},your_portal_to:n=>{const{normalize:e}=n;return e(["Ihr Portal zur"])},your_search_foundation1:n=>{const{normalize:e}=n;return e(["Ihre Suchgrundlage"])}},langchain_serve:{description:n=>{const{normalize:e}=n;return e(["Langchain-Apps in der Produktion mit Jina und FastAPI"])}},news_page:{back_to_newsroom:n=>{const{normalize:e}=n;return e(["Zur\xFCck zum Newsroom"])},categories:n=>{const{normalize:e}=n;return e(["Kategorien"])},copy_link:n=>{const{normalize:e}=n;return e(["Kopieren Sie den Link zu diesem Abschnitt"])},in_this_article:n=>{const{normalize:e}=n;return e(["In diesem Artikel"])},learn_more:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr"])},news_not_found:n=>{const{normalize:e}=n;return e(["Artikel nicht gefunden"])},redirect_to_news:n=>{const{normalize:e}=n;return e(["Weiterleitung zum Newsroom in 5 Sekunden..."])}},newsroom_page:{academic:n=>{const{normalize:e}=n;return e(["Akademisch"])},academic_research:n=>{const{normalize:e}=n;return e(["Wissenschaftliche Publikationen"])},author:n=>{const{normalize:e}=n;return e(["Filtern nach Autor"])},description:n=>{const{normalize:e}=n;return e(["Lesen Sie die neuesten Nachrichten und Updates von Jina AI."])},description1:n=>{const{normalize:e}=n;return e(["KI-Innovationen entwickeln, Wort f\xFCr Wort."])},engineering_group:n=>{const{normalize:e}=n;return e(["Engineering-Gruppe"])},engineering_group_date:n=>{const{normalize:e}=n;return e(["31. Mai 2021"])},minutes_read:n=>{const{normalize:e}=n;return e(["Minuten gelesen"])},most_recent_articles:n=>{const{normalize:e}=n;return e(["Neueste Artikel"])},news_description:n=>{const{normalize:e}=n;return e(["Bei Jina 2.0 haben wir auf die Community geh\xF6rt. Wirklich tief zugeh\xF6rt. \u201EWas sind Ihre Schmerzpunkte?\u201C \u201E, fragten wir und waren gespannt auf wertvolles Feedback.\u201C"])},news_title:n=>{const{normalize:e}=n;return e(["Durchsuchen Sie alle Dinge: Wir veranstalten einen MEME-Wettbewerb f\xFCr Jina 2.0"])},photos:n=>{const{normalize:e}=n;return e(["Fotos"])},product:n=>{const{normalize:e}=n;return e(["Nach Produkt filtern"])},search:n=>{const{normalize:e}=n;return e(["Suche nach Titel"])},tech_blog:n=>{const{normalize:e}=n;return e(["Tech-Blog"])},title:n=>{const{normalize:e}=n;return e(["Pressemitteilungen"])},top_stories:n=>{const{normalize:e}=n;return e(["Top-Geschichten"])}},notice:n=>{const{normalize:e}=n;return e(["\u{1F389} Unser erstes Buch \u201ENeural Search \u2013 From Prototype to Production with Jina\u201C ist heute offiziell erh\xE4ltlich!"])},open_day:{description:n=>{const{normalize:e}=n;return e(["Eine exklusive Gelegenheit, einen Insider-Einblick in Jina AI zu gewinnen."])},engage:n=>{const{normalize:e}=n;return e(["Wir f\xF6rdern den interaktiven Dialog den ganzen Tag \xFCber. Der Austausch von Gedanken und Perspektiven ist f\xFCr uns von unsch\xE4tzbarem Wert. M\xF6gliche Kooperationen, die sich aus diesen Diskussionen ergeben, k\xF6nnten erheblich zu einer st\xE4rker integrierten und innovativeren Zukunft beitragen."])},engage_title:n=>{const{normalize:e}=n;return e(["Beteiligen Sie sich an uns"])},experience:n=>{const{normalize:e}=n;return e(["Wir haben f\xFCr unsere G\xE4ste eine immersive dreist\xFCndige Tour zusammengestellt, die auf Deutsch, Englisch, Franz\xF6sisch, Spanisch, Chinesisch und Russisch verf\xFCgbar ist. Die Tour bietet einen detaillierten Einblick in unsere Fortschritte in der multimodalen KI, unsere Sicht auf die KI-Landschaft, gefolgt von einer detaillierten Untersuchung spezifischer Projekte. Wir schlie\xDFen mit einer Gruppendiskussion ab, um den Austausch von Ideen und Erkenntnissen zu erleichtern. Auf Anfrage ist auch ein Mittagessen erh\xE4ltlich."])},experience_title:n=>{const{normalize:e}=n;return e(["Die Reise eines Insiders"])},group_size:n=>{const{normalize:e}=n;return e(["Gesch\xE4tzte Besucherzahl"])},impact:n=>{const{normalize:e}=n;return e(["Erfahren Sie, wie unsere Beitr\xE4ge zur Open-Source-Community und unsere Arbeit in der multimodalen KI-Technologie Jina AI als einflussreichen Akteur bei KI-Innovationen etablieren. Unser Ziel ist es, eine wichtige Rolle in Entscheidungsprozessen zu spielen und sicherzustellen, dass die Weiterentwicklung der KI-Technologie allen zugute kommt."])},impact_title:n=>{const{normalize:e}=n;return e(["Wirkung und Einfluss"])},introduction:n=>{const{normalize:e}=n;return e(["Jina AI freut sich, unsere T\xFCren f\xFCr angesehene Unternehmen und Organisationen zu \xF6ffnen, die sich f\xFCr den Fortschritt und die Zukunft der k\xFCnstlichen Intelligenz interessieren. Diese exklusive Gelegenheit bieten wir Vertretern aus Politik, NGOs, NPOs und der Investmentbranche an, hier in unserem Berliner Hauptsitz einen Insider-Blick auf unsere Aktivit\xE4ten und Visionen zu erhalten."])},motivation_min_length_v1:n=>{const{normalize:e}=n;return e(["Bitte geben Sie eine detailliertere Motivation an."])},motivation_placeholder_v2:n=>{const{normalize:e}=n;return e(["Wenn Sie uns Ihre Beweggr\xFCnde mitteilen, k\xF6nnen wir Ihr Erlebnis verbessern."])},motivation_to_attend_v2:n=>{const{normalize:e}=n;return e(["Warum interessieren Sie sich f\xFCr unseren Tag der offenen T\xFCr?"])},one_hour:n=>{const{normalize:e}=n;return e(["1 Stunde"])},organization:n=>{const{normalize:e}=n;return e(["Organisation"])},organization_website:n=>{const{normalize:e}=n;return e(["Website der Organisation"])},organization_website_placeholder:n=>{const{normalize:e}=n;return e(["URL f\xFCr die Homepage oder das LinkedIn-Profil Ihrer Organisation"])},preferred_date:n=>{const{normalize:e}=n;return e(["Bevorzugtes Datum"])},preferred_language:n=>{const{normalize:e}=n;return e(["Bevorzugte Sprache der Tour"])},preferred_products:n=>{const{normalize:e}=n;return e(["F\xFCr welche Produkte interessieren Sie sich?"])},subtitle:n=>{const{normalize:e}=n;return e(["Ein Blick in die Zukunft der multimodalen KI"])},title:n=>{const{normalize:e}=n;return e(["Tag der offenen T\xFCr"])},tutor_subtitle:n=>{const{normalize:e}=n;return e(["Eine sorgf\xE4ltig kuratierte dreist\xFCndige Tour, die Ihnen den Kern der bahnbrechenden Arbeit von Jina AI in der multimodalen KI-Technologie n\xE4her bringt."])},tutor_title:n=>{const{normalize:e}=n;return e(["Ein exklusiver tiefer Einblick in"])},vision:n=>{const{normalize:e}=n;return e(["Verschaffen Sie sich mit uns einen umfassenden \xDCberblick \xFCber die KI-Landschaft aus unserer Sicht. Unsere Diskussion konzentriert sich auf das Potenzial gro\xDFer Sprachmodelle, multimodaler KI und den Einfluss von Open-Source-Technologie auf die Gestaltung der Zukunft globaler Innovation."])},vision_title:n=>{const{normalize:e}=n;return e(["Unsere Vision f\xFCr die Zukunft"])}},open_day_faq:{answer1:n=>{const{normalize:e}=n;return e(["Wir bieten F\xFChrungen auf Deutsch, Englisch, Franz\xF6sisch, Spanisch, Chinesisch und Russisch an."])},answer2:n=>{const{normalize:e}=n;return e(["Die Tour dauert normalerweise etwa drei Stunden."])},answer3:n=>{const{normalize:e}=n;return e(["Das Mittagessen ist optional und kann auf Anfrage arrangiert werden."])},answer4:n=>{const{normalize:e}=n;return e(["Unser Tag der offenen T\xFCr richtet sich in erster Linie an Berufsgruppen wie Politiker, NGOs, NPOs und Investoren. Allerdings machen wir gelegentlich Ausnahmen basierend auf dem Profil der Person."])},answer5:n=>{const{normalize:e}=n;return e(["Wir k\xF6nnen unterschiedliche Gruppengr\xF6\xDFen unterbringen. Bitte geben Sie im Anmeldeformular die Gr\xF6\xDFe Ihrer Gruppe an und wir kl\xE4ren die Einzelheiten mit Ihnen ab."])},answer6:n=>{const{normalize:e}=n;return e(["Im Anmeldeformular gibt es einen Abschnitt, in dem Sie Ihre Interessengebiete oder spezielle W\xFCnsche angeben k\xF6nnen. Wir werden unser Bestes tun, um die Tour Ihren Bed\xFCrfnissen anzupassen."])},answer7:n=>{const{normalize:e}=n;return e(["Derzeit bieten wir F\xFChrungen nur in unserem Berliner Hauptsitz in Kreuzberg an. Unsere B\xFCros in Peking und Shenzhen sind derzeit nicht f\xFCr F\xFChrungen ge\xF6ffnet."])},question1:n=>{const{normalize:e}=n;return e(["Welche Sprachen bieten Sie f\xFCr die Tour an?"])},question2:n=>{const{normalize:e}=n;return e(["Wie lange dauert die Tour?"])},question3:n=>{const{normalize:e}=n;return e(["Wird Mittagessen angeboten?"])},question4:n=>{const{normalize:e}=n;return e(["K\xF6nnen sich Einzelpersonen f\xFCr den Tag der offenen T\xFCr anmelden?"])},question5:n=>{const{normalize:e}=n;return e(["Aus wie vielen Personen darf eine Gruppe am Tag der offenen T\xFCr bestehen?"])},question6:n=>{const{normalize:e}=n;return e(["Wie kann ich Interessengebiete f\xFCr die Tour angeben?"])},question7:n=>{const{normalize:e}=n;return e(["Sind F\xFChrungen in Ihren B\xFCros in Peking oder Shenzhen verf\xFCgbar?"])}},open_gpt:{description:n=>{const{normalize:e}=n;return e(["Ein Open-Source-Cloud-natives Framework f\xFCr die Bereitstellung gro\xDFer multimodaler KI-Modelle"])}},paywall:{free_hour_consult:n=>{const{normalize:e}=n;return e(["Kostenlose 1-st\xFCndige Beratung"])},free_hour_consult_description:n=>{const{normalize:e}=n;return e(["Eine Stunde kostenlose Beratung mit unseren Produkt- und Entwicklungsteams, um die Best Practice f\xFCr Ihren Anwendungsfall zu besprechen"])},higher_limit:n=>{const{normalize:e}=n;return e(["Deutlich h\xF6here Ratenbegrenzung"])},higher_limit_description:n=>{const{normalize:e}=n;return e(["Erhalten Sie bis zu 1000 RPM f\xFCr r.jina.ai und 100 RPM f\xFCr s.jina.ai"])},priority_support:n=>{const{normalize:e}=n;return e(["Vorrangiger Kundensupport"])},priority_support_description:n=>{const{normalize:e}=n;return e(["Garantierte E-Mail-Antwort innerhalb von 24 Stunden, auch am Wochenende"])}},powered_by:n=>{const{normalize:e}=n;return e(["Angetrieben von"])},print:n=>{const{normalize:e}=n;return e(["Drucken"])},project_status:{archived:n=>{const{normalize:e}=n;return e(["Archiviert"])},cloud_native:n=>{const{normalize:e}=n;return e(["Cloud-nativ"])},core:n=>{const{normalize:e}=n;return e(["Kern"])},data_structure:n=>{const{normalize:e}=n;return e(["Datenstruktur"])},embedding_serving:n=>{const{normalize:e}=n;return e(["Servieren einbetten"])},embedding_tuning:n=>{const{normalize:e}=n;return e(["Tuning einbetten"])},graduated:n=>{const{normalize:e}=n;return e(["Absolvent"])},incubating:n=>{const{normalize:e}=n;return e(["Inkubieren"])},kubernetes:n=>{const{normalize:e}=n;return e(["Kubernetes"])},large_size_model:n=>{const{normalize:e}=n;return e(["Gro\xDFes Modell"])},linux_foundation:n=>{const{normalize:e}=n;return e(["Linux Foundation"])},llm1:n=>{const{normalize:e}=n;return e(["LLMOps"])},mid_size_model:n=>{const{normalize:e}=n;return e(["Mittelgro\xDFes Modell"])},model_serving:n=>{const{normalize:e}=n;return e(["Modelldienst"])},model_tuning:n=>{const{normalize:e}=n;return e(["Modelltuning"])},observability:n=>{const{normalize:e}=n;return e(["Beobachtbarkeit"])},orchestration:n=>{const{normalize:e}=n;return e(["Orchestrierung"])},prompt_serving:n=>{const{normalize:e}=n;return e(["Prompt-Serving"])},prompt_tuning:n=>{const{normalize:e}=n;return e(["Prompt-Verbesserung"])},rag1:n=>{const{normalize:e}=n;return e(["LAPPEN"])},sandbox:n=>{const{normalize:e}=n;return e(["Sandkasten"])},small_size_model:n=>{const{normalize:e}=n;return e(["Kleines Modell"])},vector_database:n=>{const{normalize:e}=n;return e(["Vektordatenbank"])},vector_store:n=>{const{normalize:e}=n;return e(["Vector Store"])}},prompt_perfect:{description:n=>{const{normalize:e}=n;return e(["Erstklassiges Tool f\xFCr schnelles Engineering"])},image_model:n=>{const{normalize:e}=n;return e(["Bildmodelle"])},intro:n=>{const{normalize:e}=n;return e(["Erstklassiges Tool f\xFCr schnelles Engineering"])},intro1:n=>{const{normalize:e}=n;return e(["Das erstklassige Tool f\xFCr schnelles Engineering"])},optimized:n=>{const{normalize:e}=n;return e(["Ihre Aufgabe ist es, mein Brainstorming-Partner zu sein und kreative Ideen und Vorschl\xE4ge zu einem bestimmten Thema oder Problem zu liefern. Ihre Antwort sollte originelle, einzigartige und relevante Ideen enthalten, die zur L\xF6sung des Problems beitragen oder das Thema auf interessante Weise weiter vertiefen k\xF6nnen. Bitte beachten Sie, dass Ihre Antwort auch etwaige spezifische Anforderungen oder Einschr\xE4nkungen der Aufgabe ber\xFCcksichtigen sollte."])},optimized_title:n=>{const{normalize:e}=n;return e(["Optimierte Eingabeaufforderung"])},original:n=>{const{normalize:e}=n;return e(["Sei mein Brainstorming-Partner."])},original_title:n=>{const{normalize:e}=n;return e(["Urspr\xFCngliche Aufforderung"])},text_model:n=>{const{normalize:e}=n;return e(["Textmodelle"])}},promptperfect:{features:[{description:n=>{const{normalize:e}=n;return e(["Wechseln Sie einfach zwischen Inhaltserstellung und sofortiger Optimierung und heben Sie die Qualit\xE4t Ihrer Inhalte auf die n\xE4chste Stufe."])},name:n=>{const{normalize:e}=n;return e(["Assistent"])},title:n=>{const{normalize:e}=n;return e(["T\xE4gliche Dosis Produktivit\xE4t."])}},{description:n=>{const{normalize:e}=n;return e(["Sie wissen nicht, wie Sie eine effektive Anleitung schreiben? Geben Sie einfach Ihre Idee ein, ein Klick und Sie erhalten eine bessere Anleitung."])},name:n=>{const{normalize:e}=n;return e(["Schnelle Optimierung"])},title:n=>{const{normalize:e}=n;return e(["Bessere Eing\xE4nge, bessere Ausg\xE4nge"])}},{description:n=>{const{normalize:e}=n;return e(["Verstehen Sie die Stimmung jedes KI-Modells, indem Sie die Ausgaben derselben Eingabeaufforderung vergleichen."])},name:n=>{const{normalize:e}=n;return e(["Modelle vergleichen"])},title:n=>{const{normalize:e}=n;return e(["Nebeneinanderstellung der Modelle."])}},{description:n=>{const{normalize:e}=n;return e(["Dies ist m\xF6glicherweise die einfachste M\xF6glichkeit, Ihre Eingabeaufforderungen als API zur Integration bereitzustellen."])},name:n=>{const{normalize:e}=n;return e(["Bereitstellen von Eingabeaufforderungen"])},title:n=>{const{normalize:e}=n;return e(["Keine Operationen, einfach bereitstellen."])}},{description:n=>{const{normalize:e}=n;return e(["Passen Sie Ihre eigenen LLM-Agenten an und starten Sie eine Multi-Agenten-Simulation. Sehen Sie, wie sie in einer virtuellen Umgebung zusammenarbeiten oder konkurrieren, um das Ziel zu erreichen."])},name:n=>{const{normalize:e}=n;return e(["Mehrere Agenten"])},title:n=>{const{normalize:e}=n;return e(["Erfahren Sie, wie Agenten zusammenarbeiten"])}}],get_started:n=>{const{normalize:e}=n;return e(["Erste Schritte mit PromptPerfect"])}},purchase:{success:n=>{const{normalize:e}=n;return e(["Danke f\xFCr Ihren Einkauf!"])},success_caption:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Wir haben Ihre Bestellung am ",r(i("_purchasedTime"))," abgeschlossen. Ihr API-Schl\xFCssel ist einsatzbereit!"])}},purchase_now:n=>{const{normalize:e}=n;return e(["Jetzt kaufen"])},rationale:{decision:n=>{const{normalize:e}=n;return e(["Entscheidung"])},description:n=>{const{normalize:e}=n;return e(["Ultimative KI-Tools zur Entscheidungsfindung"])},intro:n=>{const{normalize:e}=n;return e(["Sehen Sie die zwei Seiten der Medaille und treffen Sie rationale Entscheidungen"])}},reader:{better_input:n=>{const{normalize:e}=n;return e(["Verbessern Sie die Eingabequalit\xE4t von Anfang an"])},better_input_description:n=>{const{normalize:e}=n;return e(["Haben Sie Probleme mit der Ausgabe Ihres Agenten oder RAG-Systems? Dies kann an der schlechten Eingabequalit\xE4t liegen."])},check_price_table:n=>{const{normalize:e}=n;return e(["\xDCberpr\xFCfen Sie die Preistabelle"])},copy:n=>{const{normalize:e}=n;return e(["Kopieren"])},demo:{advanced_usage:n=>{const{normalize:e}=n;return e(["Erweiterte Nutzung"])},ask_llm:n=>{const{normalize:e}=n;return e(["Fragen Sie LLM mit und ohne Suchgrundlage"])},ask_llm_directly:n=>{const{normalize:e}=n;return e(["Fragen Sie LLM direkt"])},ask_llm_with_search_grounding:n=>{const{normalize:e}=n;return e(["Ask LLM mit Suchgrundierung"])},ask_question:n=>{const{normalize:e}=n;return e(["Stellen Sie eine Frage"])},ask_question_hint:n=>{const{normalize:e}=n;return e(["Geben Sie eine Frage ein und kombinieren Sie sie mit dem abgerufenen Inhalt f\xFCr LLM, um eine Antwort zu generieren"])},basic_usage:n=>{const{normalize:e}=n;return e(["Grundlegende Verwendung"])},basic_usage1:n=>{const{normalize:e}=n;return e(["Lesen einer URL"])},basic_usage2:n=>{const{normalize:e}=n;return e(["Suchen nach einer Abfrage"])},copy:n=>{const{normalize:e}=n;return e(["Kopieren"])},fetch:n=>{const{normalize:e}=n;return e(["Inhalt abrufen"])},get_response:n=>{const{normalize:e}=n;return e(["Erhalten Antwort"])},headers:{auth_token:n=>{const{normalize:e}=n;return e(["API-Schl\xFCssel f\xFCr h\xF6here Ratenbegrenzung hinzuf\xFCgen"])},auth_token_explain:n=>{const{normalize:e}=n;return e(["Geben Sie Ihren Jina-API-Schl\xFCssel ein, um auf eine h\xF6here Ratenbegrenzung zuzugreifen. Aktuelle Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle."])},default:n=>{const{normalize:e}=n;return e(["Standard"])},default_explain:n=>{const{normalize:e}=n;return e(["Die f\xFCr die meisten Websites und LLM-Eingaben optimierte Standard-Pipeline."])},html:n=>{const{normalize:e}=n;return e(["HTML"])},html_explain:n=>{const{normalize:e}=n;return e(["Gibt documentElement.outerHTML zur\xFCck."])},image_caption:n=>{const{normalize:e}=n;return e(["Bildbeschreibung"])},image_caption_explain:n=>{const{normalize:e}=n;return e(["Beschriftet alle Bilder unter der angegebenen URL und f\xFCgt f\xFCr Bilder ohne einen Alt-Tag \u201EBild [idx]: [Beschriftung]\u201C hinzu. Dies erm\xF6glicht nachgelagerten LLMs die Interaktion mit den Bildern bei Aktivit\xE4ten wie Argumentation und Zusammenfassung."])},images_summary:n=>{const{normalize:e}=n;return e(["Sammeln Sie am Ende alle Bilder"])},images_summary_explain:n=>{const{normalize:e}=n;return e(["Am Ende wird ein Abschnitt \u201EBilder\u201C erstellt. Dies gibt den nachgelagerten LLMs einen \xDCberblick \xFCber alle visuellen Elemente auf der Seite, was das Denken erleichtern kann."])},json_response:n=>{const{normalize:e}=n;return e(["JSON-Antwort"])},json_response_explain:n=>{const{normalize:e}=n;return e(["Die Antwort erfolgt im JSON-Format und enth\xE4lt URL, Titel, Inhalt und Zeitstempel (sofern verf\xFCgbar). Im Suchmodus wird eine Liste mit f\xFCnf Eintr\xE4gen zur\xFCckgegeben, die jeweils der beschriebenen JSON-Struktur folgen."])},links_summary:n=>{const{normalize:e}=n;return e(["Sammeln Sie alle Links am Ende"])},links_summary_explain:n=>{const{normalize:e}=n;return e(["Am Ende wird ein Abschnitt \u201EButtons & Links\u201C erstellt. Dies erleichtert den nachgelagerten LLMs oder Webagenten die Navigation auf der Seite oder das Ausf\xFChren weiterer Aktionen."])},markdown:n=>{const{normalize:e}=n;return e(["Markdown"])},markdown_explain:n=>{const{normalize:e}=n;return e(["Gibt das Markdown direkt aus dem HTML zur\xFCck und umgeht dabei die Lesbarkeitsfilterung."])},mode:n=>{const{normalize:e}=n;return e(["Lese- oder Suchmodus"])},mode_explain:n=>{const{normalize:e}=n;return e(["Der Lesemodus dient zum Zugriff auf den Inhalt einer URL, w\xE4hrend Sie im Suchmodus eine Abfrage im Web eingeben k\xF6nnen, indem Sie den Lesemodus auf jede URL mit Suchergebnis anwenden."])},no_cache:n=>{const{normalize:e}=n;return e(["Umgehen des Cache"])},no_cache_explain:n=>{const{normalize:e}=n;return e(["Unser API-Server speichert sowohl Inhalte im Lese- als auch im Suchmodus f\xFCr eine bestimmte Zeit im Cache. Um diesen Cache zu umgehen, setzen Sie diesen Header auf \u201Etrue\u201C."])},pageshot:n=>{const{normalize:e}=n;return e(["Seitenfoto"])},pageshot_explain:n=>{const{normalize:e}=n;return e(["Gibt die Bild-URL des Screenshots der gesamten Seite zur\xFCck (mit bestm\xF6glicher Leistung)."])},post_with_url:n=>{const{normalize:e}=n;return e(["POST-Methode verwenden"])},post_with_url_explain:n=>{const{normalize:e}=n;return e(["Verwenden Sie POST statt GET mit einer im Text \xFCbergebenen URL. N\xFCtzlich zum Erstellen von SPAs mit hashbasiertem Routing."])},proxy_server:n=>{const{normalize:e}=n;return e(["Verwenden Sie einen Proxyserver"])},proxy_server_explain:n=>{const{normalize:e}=n;return e(["Unser API-Server kann Ihren Proxy nutzen, um auf URLs zuzugreifen, was f\xFCr Seiten hilfreich ist, auf die nur \xFCber bestimmte Proxys zugegriffen werden kann."])},return_format:n=>{const{normalize:e}=n;return e(["Inhaltsformat"])},return_format_explain:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen den Detaillierungsgrad der Antwort steuern, um eine \xDCberfilterung zu verhindern. Die Standardpipeline ist f\xFCr die meisten Websites und LLM-Eingaben optimiert."])},screenshot:n=>{const{normalize:e}=n;return e(["Bildschirmfoto"])},screenshot_explain:n=>{const{normalize:e}=n;return e(["Gibt die Bild-URL des ersten Bildschirms zur\xFCck."])},set_cookie:n=>{const{normalize:e}=n;return e(["Weiterleiten Cookie"])},set_cookie_explain:n=>{const{normalize:e}=n;return e(["Unser API-Server kann Ihre benutzerdefinierten Cookie-Einstellungen beim Zugriff auf die URL weiterleiten, was f\xFCr Seiten n\xFCtzlich ist, die eine zus\xE4tzliche Authentifizierung erfordern. Beachten Sie, dass Anfragen mit Cookies nicht zwischengespeichert werden."])},site_selector:n=>{const{normalize:e}=n;return e(["In-Site-Suche"])},site_selector_explain:n=>{const{normalize:e}=n;return e(["Gibt nur Suchergebnisse von der angegebenen Website oder Dom\xE4ne zur\xFCck. Standardm\xE4\xDFig wird das gesamte Web durchsucht."])},stream_mode:n=>{const{normalize:e}=n;return e(["Stream-Modus"])},stream_mode_explain:n=>{const{normalize:e}=n;return e(["Der Stream-Modus ist f\xFCr gro\xDFe Zielseiten von Vorteil, da er mehr Zeit f\xFCr die vollst\xE4ndige Darstellung der Seite bietet. Wenn der Standardmodus unvollst\xE4ndige Inhalte ergibt, sollten Sie den Stream-Modus verwenden."])},target_selector:n=>{const{normalize:e}=n;return e(["Zielauswahl"])},target_selector_explain:n=>{const{normalize:e}=n;return e(["Stellen Sie einen CSS-Selektor bereit, um sich auf einen spezifischeren Teil der Seite zu konzentrieren. N\xFCtzlich, wenn der gew\xFCnschte Inhalt in den Standardeinstellungen nicht angezeigt wird."])},text:n=>{const{normalize:e}=n;return e(["Text"])},text_explain:n=>{const{normalize:e}=n;return e(["Gibt document.body.innerText zur\xFCck."])},wait_for_selector:n=>{const{normalize:e}=n;return e(["Auf Selektor warten"])},wait_for_selector_explain:n=>{const{normalize:e}=n;return e(["Warten Sie, bis ein bestimmtes Element angezeigt wird, bevor Sie zur\xFCckkehren. N\xFCtzlich, wenn der gew\xFCnschte Inhalt in den Standardeinstellungen nicht angezeigt wird."])},x_timeout:n=>{const{normalize:e}=n;return e(["Benutzerdefiniertes Timeout"])},x_timeout_explain:n=>{const{normalize:e}=n;return e(["Kann n\xFCtzlich sein, wenn das Rendern der Seite zu langsam ist. F\xFCr den Suchendpunkt ist dies die maximale Wartezeit f\xFCr das Lesen aller Suchergebnisse."])}},how_to_stream:n=>{const{normalize:e}=n;return e(["Um Inhalte zu verarbeiten, sobald sie verf\xFCgbar sind, setzen Sie den Anforderungsheader auf den Stream-Modus. Dadurch wird die Zeit bis zum Empfang des ersten Bytes minimiert. Beispiel in curl:"])},how_to_use1:n=>{const{normalize:e}=n;return e(["F\xFCgen Sie <code>https://r.jina.ai/</code> zu jeder URL in Ihrem Code oder Tool hinzu, bei der LLM-Zugriff erwartet wird. Dadurch wird der Hauptinhalt der Seite in sauberem, LLM-freundlichem Text zur\xFCckgegeben."])},how_to_use2:n=>{const{normalize:e}=n;return e(["F\xFCgen Sie Ihrer Abfrage <code>https://s.jina.ai/</code> hinzu. Dadurch wird die Suchmaschine aufgerufen und die Top-5-Ergebnisse mit ihren URLs und Inhalten zur\xFCckgegeben, jeweils in sauberem, LLM-freundlichem Text."])},learn_more:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr"])},open:n=>{const{normalize:e}=n;return e(["In einer neuen Registerkarte \xF6ffnen"])},raw_html:n=>{const{normalize:e}=n;return e(["Rohes HTML"])},reader_output:n=>{const{normalize:e}=n;return e(["Reader-Ausgabe"])},reader_response:n=>{const{normalize:e}=n;return e(["Leserreaktion"])},reader_search_hint:n=>{const{normalize:e}=n;return e(["Wenn Sie diese URL im Code verwenden, vergessen Sie nicht, die URL zu kodieren."])},reader_url:n=>{const{normalize:e}=n;return e(["Leser-URL"])},reader_url_hint:n=>{const{normalize:e}=n;return e(["Klicken Sie unten, um den Inhalt \xFCber unsere Reader-API abzurufen"])},search_query_rewrite:n=>{const{normalize:e}=n;return e(["Bitte beachten Sie, dass Sie im Gegensatz zur oben gezeigten Demo in der Praxis nicht die urspr\xFCngliche Frage im Internet nach einer Grundlage durchsuchen. H\xE4ufig wird die urspr\xFCngliche Frage umgeschrieben oder es werden Multi-Hop-Fragen verwendet. Die abgerufenen Ergebnisse werden gelesen und anschlie\xDFend werden zus\xE4tzliche Abfragen erstellt, um bei Bedarf weitere Informationen zu sammeln, bevor eine endg\xFCltige Antwort gefunden wird."])},show_read_demo:n=>{const{normalize:e}=n;return e(["Sehen Sie, wie Reader eine URL liest"])},show_search_demo:n=>{const{normalize:e}=n;return e(["Sehen Sie, wie Reader im Web sucht"])},standard_usage:n=>{const{normalize:e}=n;return e(["Standardverwendung"])},stream_mode:n=>{const{normalize:e}=n;return e(["Stream-Modus"])},stream_mode_explain:n=>{const{normalize:e}=n;return e(["Der Stream-Modus ist n\xFCtzlich, wenn die Zielseite zu gro\xDF zum Rendern ist. Wenn Sie feststellen, dass der Standardmodus unvollst\xE4ndige Inhalte liefert, versuchen Sie es mit dem Stream-Modus."])},stream_mode_explain1:n=>{const{normalize:e}=n;return e(["Der Streaming-Modus ist n\xFCtzlich, wenn Sie feststellen, dass der Standardmodus ein unvollst\xE4ndiges Ergebnis liefert. Dies liegt daran, dass der Streaming-Modus etwas l\xE4nger wartet, bis die Seite vollst\xE4ndig gerendert ist. Verwenden Sie den Accept-Header, um den Streaming-Modus umzuschalten:"])},tagline:n=>{const{normalize:e}=n;return e(["Testen Sie die Demo"])},try_demo:n=>{const{normalize:e}=n;return e(["Demo"])},use_headers:n=>{const{normalize:e}=n;return e(["Das Verhalten der Reader-API kann mit Anforderungsheadern gesteuert werden. Hier ist eine vollst\xE4ndige Liste der unterst\xFCtzten Header."])},waiting_for_reader:n=>{const{normalize:e}=n;return e(["Warte zuerst auf das Ergebnis der Reader-API ..."])},your_query:n=>{const{normalize:e}=n;return e(["Geben Sie Ihre Suchanfrage ein"])},your_query_hint:n=>{const{normalize:e}=n;return e(["Geben Sie eine Frage ein, die aktuelle Informationen oder Weltwissen erfordert."])},your_url:n=>{const{normalize:e}=n;return e(["Geben Sie Ihre URL ein"])},your_url_hint:n=>{const{normalize:e}=n;return e(["Klicken Sie unten, um den Quellcode der Seite direkt abzurufen"])}},description:n=>{const{normalize:e}=n;return e(["Lesen Sie URLs oder durchsuchen Sie das Internet, um sich eine bessere Grundlage f\xFCr ein LLM-Studium zu verschaffen."])},dont_panic_api_key_is_free:n=>{const{normalize:e}=n;return e(["Keine Panik! Jeder neue API-Schl\xFCssel enth\xE4lt eine Million kostenlose Token!"])},faq_v1:{answer1:n=>{const{normalize:e}=n;return e(["Die Reader-API ist kostenlos und erfordert keinen API-Schl\xFCssel. F\xFCgen Sie Ihrer URL einfach \u201Ehttps://r.jina.ai/\u201C voran."])},answer10:n=>{const{normalize:e}=n;return e(["Nein, die Reader-API kann nur Inhalte von \xF6ffentlich zug\xE4nglichen URLs verarbeiten."])},answer11:n=>{const{normalize:e}=n;return e(["Wenn Sie innerhalb von 5 Minuten dieselbe URL anfordern, gibt die Reader-API den zwischengespeicherten Inhalt zur\xFCck."])},answer12:n=>{const{normalize:e}=n;return e(["Leider nicht."])},answer13:n=>{const{normalize:e}=n;return e(["Ja, Sie k\xF6nnen entweder die native PDF-Unterst\xFCtzung des Readers (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) oder die HTML-Version von arXiv (https://r.jina.ai/https://arxiv.org/html/2310.19923v4) verwenden."])},answer14:n=>{const{normalize:e}=n;return e(["Der Reader betitelt alle Bilder unter der angegebenen URL und f\xFCgt `Image [idx]: [caption]` als Alt-Tag hinzu (falls urspr\xFCnglich keiner vorhanden ist). Dies erm\xF6glicht nachgelagerten LLMs, beim Denken, Zusammenfassen usw. mit den Bildern zu interagieren."])},answer15:n=>{const{normalize:e}=n;return e(["Die Reader-API ist auf hohe Skalierbarkeit ausgelegt. Sie wird automatisch auf Basis des Echtzeitverkehrs skaliert und die maximale Anzahl gleichzeitiger Anfragen liegt derzeit bei etwa 4000. Wir pflegen sie aktiv als eines der Kernprodukte von Jina AI. Sie k\xF6nnen sie also gerne in der Produktion verwenden."])},answer16:n=>{const{normalize:e}=n;return e(["Die neuesten Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle. Beachten Sie, dass wir aktiv an der Verbesserung der Ratenbegrenzung und der Leistung der Reader-API arbeiten. Die Tabelle wird entsprechend aktualisiert."])},answer2:n=>{const{normalize:e}=n;return e(["Die Reader-API verwendet einen Proxy, um jede beliebige URL abzurufen und ihren Inhalt in einem Browser darzustellen, um hochwertigen Hauptinhalt zu extrahieren."])},answer3:n=>{const{normalize:e}=n;return e(["Ja, die Reader-API ist Open Source und im Jina AI GitHub-Repository verf\xFCgbar."])},answer4:n=>{const{normalize:e}=n;return e(["Die Reader-API verarbeitet URLs im Allgemeinen innerhalb von 2 Sekunden und gibt Inhalte zur\xFCck. Komplexe oder dynamische Seiten k\xF6nnen jedoch mehr Zeit ben\xF6tigen."])},answer5:n=>{const{normalize:e}=n;return e(["Scraping kann kompliziert und unzuverl\xE4ssig sein, insbesondere bei komplexen oder dynamischen Seiten. Die Reader-API bietet eine optimierte, zuverl\xE4ssige Ausgabe von sauberem, LLM-f\xE4higem Text."])},answer6:n=>{const{normalize:e}=n;return e(["Die Reader-API gibt Inhalte in der Originalsprache der URL zur\xFCck. Sie bietet keine \xDCbersetzungsdienste an."])},answer7:n=>{const{normalize:e}=n;return e(["Wenn bei Ihnen Blockierungsprobleme auftreten, wenden Sie sich f\xFCr Unterst\xFCtzung und L\xF6sung bitte an unser Supportteam."])},answer8:n=>{const{normalize:e}=n;return e(["Obwohl die Reader-API in erster Linie f\xFCr Webseiten entwickelt wurde, kann sie auch Inhalte aus PDF-Dateien extrahieren, die auf Websites wie arXiv im HTML-Format angezeigt werden. Sie ist jedoch nicht f\xFCr die allgemeine PDF-Extraktion optimiert."])},answer9:n=>{const{normalize:e}=n;return e(["Derzeit verarbeitet die Reader-API keine Medieninhalte, zuk\xFCnftige Erweiterungen werden jedoch Bildunterschriften und Videozusammenfassungen umfassen."])},question1:n=>{const{normalize:e}=n;return e(["Welche Kosten sind mit der Nutzung der Reader-API verbunden?"])},question10:n=>{const{normalize:e}=n;return e(["Ist es m\xF6glich, die Reader-API auf lokale HTML-Dateien anzuwenden?"])},question11:n=>{const{normalize:e}=n;return e(["Speichert die Reader-API den Inhalt im Cache?"])},question12:n=>{const{normalize:e}=n;return e(["Kann ich die Reader-API verwenden, um auf Inhalte hinter einer Anmeldung zuzugreifen?"])},question13:n=>{const{normalize:e}=n;return e(["Kann ich die Reader-API verwenden, um auf arXiv auf PDF zuzugreifen?"])},question14:n=>{const{normalize:e}=n;return e(["Wie funktionieren Bildunterschriften im Reader?"])},question15:n=>{const{normalize:e}=n;return e(["Wie skalierbar ist der Reader? Kann ich ihn in der Produktion einsetzen?"])},question16:n=>{const{normalize:e}=n;return e(["Wie hoch ist die Ratenbegrenzung der Reader-API?"])},question2:n=>{const{normalize:e}=n;return e(["Wie funktioniert die Reader-API?"])},question3:n=>{const{normalize:e}=n;return e(["Ist die Reader-API Open Source?"])},question4:n=>{const{normalize:e}=n;return e(["Wie hoch ist die typische Latenz f\xFCr die Reader-API?"])},question5:n=>{const{normalize:e}=n;return e(["Warum sollte ich die Reader-API verwenden, anstatt die Seite selbst zu scrapen?"])},question6:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzt die Reader-API mehrere Sprachen?"])},question7:n=>{const{normalize:e}=n;return e(["Was soll ich tun, wenn eine Website die Reader-API blockiert?"])},question8:n=>{const{normalize:e}=n;return e(["Kann die Reader-API Inhalte aus PDF-Dateien extrahieren?"])},question9:n=>{const{normalize:e}=n;return e(["Kann die Reader-API Medieninhalte von Webseiten verarbeiten?"])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufig gestellte Fragen zum Leser"])}},fast:n=>{const{normalize:e}=n;return e(["Schnell"])},fast_stream:n=>{const{normalize:e}=n;return e(["Sofortiges Daten-Streaming"])},fast_stream_description:n=>{const{normalize:e}=n;return e(["Sie ben\xF6tigen Daten schnell? Unsere Reader-API kann Daten streamen, um die Latenz zu minimieren."])},free:n=>{const{normalize:e}=n;return e(["F\xFCr immer frei"])},free_description:n=>{const{normalize:e}=n;return e(["Die Reader-API ist kostenlos! Sie erfordert weder eine Kreditkarte noch ein API-Geheimnis. Ihr Token-Kontingent wird dadurch nicht verbraucht."])},is_free:n=>{const{normalize:e}=n;return e(["Und das Beste daran? Es ist kostenlos!"])},is_free_description:n=>{const{normalize:e}=n;return e(["Die Reader API ist kostenlos erh\xE4ltlich und bietet flexible Ratenbegrenzungen und Preise. Sie basiert auf einer skalierbaren Infrastruktur und bietet hohe Zug\xE4nglichkeit, Parallelit\xE4t und Zuverl\xE4ssigkeit. Wir m\xF6chten Ihre bevorzugte Grundl\xF6sung f\xFCr Ihre LLMs sein."])},open:n=>{const{normalize:e}=n;return e(["In neuem Tab \xF6ffnen"])},original_pdf:n=>{const{normalize:e}=n;return e(["Original PDF"])},rate_limit:n=>{const{normalize:e}=n;return e(["Bewertungslimit"])},reader_also_read_images:n=>{const{normalize:e}=n;return e(["Bilder auf der Webseite werden mithilfe eines Vision Language Model im Reader automatisch mit Bildunterschriften versehen und in der Ausgabe als Bild-Alt-Tags formatiert. Dadurch erh\xE4lt Ihr nachgelagertes LLM gerade genug Hinweise, um diese Bilder in seine Denk- und Zusammenfassungsprozesse einzubeziehen. Das bedeutet, dass Sie Fragen zu den Bildern stellen, bestimmte Bilder ausw\xE4hlen oder sogar ihre URLs zur tieferen Analyse an ein leistungsf\xE4higeres VLM weiterleiten k\xF6nnen!"])},reader_description:n=>{const{normalize:e}=n;return e(["Erhalten Sie LLM-freundliche Eingaben von einer URL oder einer Websuche, indem Sie einfach <code>r.jina.ai</code> davor hinzuf\xFCgen."])},reader_do_pdf_explain:n=>{const{normalize:e}=n;return e(["Ja, Reader unterst\xFCtzt das Lesen von PDFs nativ. Es ist mit den meisten PDFs kompatibel, auch mit denen mit vielen Bildern, und es ist blitzschnell! In Kombination mit einem LLM k\xF6nnen Sie im Handumdrehen ganz einfach eine ChatPDF- oder Dokumentenanalyse-KI erstellen."])},reader_do_search:n=>{const{normalize:e}=n;return e(["Reader zur Sucheingrenzung"])},reader_do_search_explain:n=>{const{normalize:e}=n;return e(["LLMs haben einen Wissens-Cut-off, das hei\xDFt, sie haben keinen Zugriff auf das neueste Weltwissen. Dies f\xFChrt zu Problemen wie Fehlinformationen, veralteten Antworten, Halluzinationen und anderen Sachlichkeitsproblemen. F\xFCr GenAI-Anwendungen ist eine Grundlage absolut unerl\xE4sslich. Reader erm\xF6glicht es Ihnen, Ihren LLM mit den neuesten Informationen aus dem Internet zu verankern. Stellen Sie Ihrer Abfrage einfach <code>https://s.jina.ai/</code> voran, und Reader durchsucht das Internet und gibt die f\xFCnf besten Ergebnisse mit ihren URLs und Inhalten zur\xFCck, jeweils in sauberem, LLM-freundlichem Text. Auf diese Weise k\xF6nnen Sie Ihren LLM immer auf dem neuesten Stand halten, seine Sachlichkeit verbessern und Halluzinationen reduzieren."])},reader_reads_images:n=>{const{normalize:e}=n;return e(["Reader liest auch Bilder!"])},reader_reads_pdf:n=>{const{normalize:e}=n;return e(["Reader liest auch PDFs!"])},reader_result:n=>{const{normalize:e}=n;return e(["Leserergebnis"])},table:{td_1_0:n=>{const{normalize:e}=n;return e(["Lesen einer URL und Zur\xFCckgeben des Inhalts, n\xFCtzlich zur \xDCberpr\xFCfung der Erdung"])},td_1_1:n=>{const{normalize:e}=n;return e(["20 U/min"])},td_1_2:n=>{const{normalize:e}=n;return e(["200 U/min"])},td_1_3:n=>{const{normalize:e}=n;return e(["Basierend auf den Ausgabetoken"])},td_1_4:n=>{const{normalize:e}=n;return e(["3 Sekunden"])},td_1_5:n=>{const{normalize:e}=n;return e(["3 Sekunden"])},td_2_0:n=>{const{normalize:e}=n;return e(["Bei einer Suche im Web werden die f\xFCnf besten Ergebnisse zur\xFCckgegeben, was zur Eingrenzung der Suche n\xFCtzlich ist."])},td_2_1:n=>{const{normalize:e}=n;return e(["5 U/min"])},td_2_2:n=>{const{normalize:e}=n;return e(["40 U/min"])},td_2_3:n=>{const{normalize:e}=n;return e(["Basierend auf den Ausgabetoken f\xFCr alle 5 Suchergebnisse"])},td_2_4:n=>{const{normalize:e}=n;return e(["10 Sekunden"])},td_2_5:n=>{const{normalize:e}=n;return e(["10 Sekunden"])},th0:n=>{const{normalize:e}=n;return e(["Endpunkt"])},th1:n=>{const{normalize:e}=n;return e(["Beschreibung"])},th2:n=>{const{normalize:e}=n;return e(["Ratenbegrenzung ohne API-Schl\xFCssel"])},th3:n=>{const{normalize:e}=n;return e(["Ratenbegrenzung mit API-Schl\xFCssel"])},th4:n=>{const{normalize:e}=n;return e(["Token-Z\xE4hlschema"])},th5:n=>{const{normalize:e}=n;return e(["Durchschnittliche Latenz"])},th6:n=>{const{normalize:e}=n;return e(["Durchschnittliche Latenz"])}},title:n=>{const{normalize:e}=n;return e(["Leser-API"])},usage:n=>{const{normalize:e}=n;return e(["Verwendung"])},usage_details_false:n=>{const{normalize:e}=n;return e(["Nur grundlegende Verwendungen anzeigen"])},usage_details_null:n=>{const{normalize:e}=n;return e(["Grundlegende und erweiterte Verwendungsm\xF6glichkeiten anzeigen"])},usage_details_true:n=>{const{normalize:e}=n;return e(["Nur erweiterte Verwendungen anzeigen"])},want_higher_rate_limit:n=>{const{normalize:e}=n;return e(["Sie m\xF6chten eine h\xF6here Ratenbegrenzung bis 1000 RPM? Wir unterst\xFCtzen Sie!"])},what_is1:n=>{const{normalize:e}=n;return e(["Was ist Reader?"])},what_is_answer_long:n=>{const{normalize:e}=n;return e(["Das Einspeisen von Webinformationen in LLMs ist ein wichtiger Schritt zur Einarbeitung, kann aber auch eine Herausforderung sein. Die einfachste Methode besteht darin, die Webseite zu scrapen und das Roh-HTML einzuspeisen. Das Scraping kann jedoch komplex und oft blockiert sein, und Roh-HTML ist mit irrelevanten Elementen wie Markups und Skripten \xFCberladen. Die Reader-API behebt diese Probleme, indem sie den Kerninhalt aus einer URL extrahiert und in sauberen, LLM-freundlichen Text umwandelt, wodurch eine qualitativ hochwertige Eingabe f\xFCr Ihre Agent- und RAG-Systeme sichergestellt wird."])},what_is_desc:n=>{const{normalize:e}=n;return e(["Ein Proxy, der auf jede URL zugreift und den Hauptinhalt in f\xFCr LLMs optimierten Klartext umwandelt."])}},recommender:{confirm_message:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["F\xFCr Ihren API-Schl\xFCssel sind noch ",r(i("_leftTokens"))," Token \xFCbrig. Wenn Sie den vollst\xE4ndigen Text von ",r(i("_numArticles")),"-Artikeln an die Reranker-API senden und dabei das Modell ",r(i("_selectedReranker"))," verwenden, um verwandte Artikel f\xFCr die aktuelle Seite zu ermitteln, wird die Tokenanzahl Ihres API-Schl\xFCssels ",r(i("_APIKey"))," erheblich reduziert. M\xF6chten Sie fortfahren?"])},confirm_title:n=>{const{normalize:e}=n;return e(["Warnung: Hohe Token-Nutzung"])},out_of_quota:n=>{const{normalize:e}=n;return e(["F\xFCr diesen API-Schl\xFCssel sind keine Token mehr vorhanden. Bitte laden Sie Ihr Konto auf oder verwenden Sie einen anderen API-Schl\xFCssel."])},recommend:n=>{const{normalize:e}=n;return e(["Holen Sie sich die Top 5"])},recommended_articles:n=>{const{normalize:e}=n;return e(["Top-5 \xE4hnliche Artikel"])}},reranker:{benchmark:{description0:n=>{const{normalize:e}=n;return e(["LlamaIndex bewertete verschiedene Kombinationen von Einbettungen und Rerankern f\xFCr RAG und f\xFChrte eine Replikationsstudie durch, in der der mittlere reziproke Rang gemessen wurde. Die Ergebnisse unterstreichen die deutliche Verbesserung der Suchqualit\xE4t durch den Jina Reranker, ein Vorteil, der unabh\xE4ngig von den verwendeten spezifischen Einbettungen ist."])},description1:n=>{const{normalize:e}=n;return e(["BIER (Benchmarking IR) bewertet die Abrufeffektivit\xE4t eines Modells, einschlie\xDFlich Relevanz und NDCG. Ein h\xF6herer BIER-Score korreliert mit genaueren \xDCbereinstimmungen und Suchergebnissen."])},description2:n=>{const{normalize:e}=n;return e(["Mithilfe des LoCo-Benchmarks haben wir das Verst\xE4ndnis eines Modells f\xFCr lokale Koh\xE4renz und Kontext sowie das abfragespezifische Ranking gemessen. Eine h\xF6here LoCo-Bewertung spiegelt eine bessere F\xE4higkeit wider, relevante Informationen zu identifizieren und zu priorisieren."])},description3:n=>{const{normalize:e}=n;return e(["Der MTEB (Multilingual Text Embedding Benchmark) testet im Gro\xDFen und Ganzen die F\xE4higkeiten eines Modells bei Texteinbettungen, einschlie\xDFlich Clustering, Klassifizierung, Abruf und anderen Metriken. F\xFCr unseren Vergleich haben wir jedoch nur die Reranking-Aufgaben des MTEB herangezogen."])},title:n=>{const{normalize:e}=n;return e(["Benchmark"])},title0:n=>{const{normalize:e}=n;return e(["LamaIndex"])},title1:n=>{const{normalize:e}=n;return e(["BEIR"])},title2:n=>{const{normalize:e}=n;return e(["Lok"])},title3:n=>{const{normalize:e}=n;return e(["MTBB"])}},benchmark_description:n=>{const{normalize:e}=n;return e(["Zum Vergleich haben wir drei weitere f\xFChrende Reranker von BGE (BAAI), BCE (Netease Youdao) und Cohere in die Benchmark einbezogen. Wie aus den folgenden Ergebnissen hervorgeht, erzielt Jina Reranker in allen relevanten Kategorien f\xFCr das Reranking die h\xF6chste Durchschnittspunktzahl und ist damit klarer Spitzenreiter unter seinen Mitbewerbern."])},benchmark_title:n=>{const{normalize:e}=n;return e(["Leistungsbenchmark"])},choose_turbo:n=>{const{normalize:e}=n;return e(["Bis zu 5-fache Geschwindigkeitssteigerung mit Reranker-Turbo"])},choose_turbo_description:n=>{const{normalize:e}=n;return e(["Wir bieten au\xDFerdem zwei neue Open-Source-Reranker-Modelle an: jina-reranker-v1-turbo-en und jina-reranker-v1-tiny-en. Letzteres hat nur 30 Millionen Parameter und vier Schichten. Diese beiden neuen Reranker bieten eine 5-mal schnellere Inferenzgeschwindigkeit als das Basismodell bei nur sehr geringen Qualit\xE4tseinbu\xDFen. Sie eignen sich perfekt f\xFCr Anwendungen, die ein Reranking in Echtzeit erfordern. Lesen Sie den Benchmark unten."])},customize_urself:n=>{const{normalize:e}=n;return e(["\xC4ndern Sie es und sehen Sie, wie sich die Reaktion \xE4ndert!"])},customize_urself_pl:n=>{const{normalize:e}=n;return e(["\xC4ndern Sie sie und sehen Sie, wie sich die Reaktion \xE4ndert!"])},description:n=>{const{normalize:e}=n;return e(["Maximieren Sie m\xFChelos die Suchrelevanz und RAG-Genauigkeit."])},description_rich:n=>{const{normalize:e}=n;return e(["Maximieren Sie die Suchrelevanz und RAG-Genauigkeit mit unserer hochmodernen Reranker-API. Beginnen Sie mit 1 Million kostenlosen Token."])},example_input_document:n=>{const{normalize:e}=n;return e(["Beispieldokumente von Kandidaten zum Ranking"])},example_input_query:n=>{const{normalize:e}=n;return e(["Beispielabfrage"])},faq_v1:{answer1:n=>{const{normalize:e}=n;return e(["Die Preise f\xFCr die Reranker-API richten sich nach unserer Preisstruktur f\xFCr die Embedding-API. Es beginnt mit 1 Million kostenlosen Token f\xFCr jeden neuen API-Schl\xFCssel. \xDCber die kostenlosen Token hinaus stehen verschiedene Pakete zum Kauf zur Verf\xFCgung. Weitere Informationen finden Sie in unserem Abschnitt \u201EPreise\u201C."])},answer10:n=>{const{normalize:e}=n;return e(["Ja, Jina Reranker kann auf AWS bereitgestellt werden. Wenn Sie eine lokale Bereitstellung in einer Unternehmensumgebung ben\xF6tigen, k\xF6nnen Sie dies ganz einfach \xFCber unser AWS Marketplace-Angebot tun."])},answer11:n=>{const{normalize:e}=n;return e(["Wenn Sie an einem fein abgestimmten Reranker interessiert sind, der auf bestimmte Domaindaten zugeschnitten ist, wenden Sie sich bitte an unser Vertriebsteam. Unser Team wird Ihre Anfrage zeitnah beantworten."])},answer3:n=>{const{normalize:e}=n;return e(["Der Hauptunterschied liegt in ihrer Architektur. F\xFCr die Leistung empfehlen wir jina-reranker-v1, das ausgiebig getestet und mit Wettbewerbern verglichen wurde. Jina-reranker-v1 nutzt eine Cross-Encoder-Architektur, w\xE4hrend Jina-colbert-v1 auf der ColBERTv2-Architektur basiert, aber die Kontextl\xE4nge sowohl der Abfrage als auch des Dokuments auf 8192 erweitert, wodurch eine noch bessere Leistung als das urspr\xFCngliche ColBERTv2-Modell erzielt wird."])},answer4:n=>{const{normalize:e}=n;return e(["Ja, jina-colbert-v1 ist Open Source und kann \xFCber Huggingface aufgerufen werden. Allerdings ist jina-reranker-v1 kein Open Source."])},answer5:n=>{const{normalize:e}=n;return e(["Derzeit wird nur Englisch unterst\xFCtzt. Einige Benutzer haben jedoch berichtet, dass es auch mit Chinesisch gut funktioniert. Dies kann teilweise daran liegen, dass jina-reranker-v1-base-en einige Gewichtungen mit unserem Einbettungsmodell jina-embeddings-v2-base-zh teilt."])},answer6:n=>{const{normalize:e}=n;return e(["Die maximale L\xE4nge des Abfragetokens betr\xE4gt 512. F\xFCr Dokumente gibt es keine Tokenbeschr\xE4nkung."])},answer7:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen bis zu 2048 Dokumente pro Abfrage neu einordnen."])},answer8:n=>{const{normalize:e}=n;return e(["Im Gegensatz zu unserer Einbettungs-API gibt es kein Konzept der Stapelgr\xF6\xDFe. Sie k\xF6nnen pro Anfrage nur ein Abfrage-Dokument-Tupel senden, das Tupel kann jedoch bis zu 2048 Kandidatendokumente enthalten."])},answer9:n=>{const{normalize:e}=n;return e(["Die Latenz variiert zwischen 100 Millisekunden und 7 Sekunden und h\xE4ngt weitgehend von der L\xE4nge der Dokumente und der Abfrage ab. Beispielsweise dauert das Neuranking von 100 Dokumenten mit jeweils 256 Token bei einer 64-Token-Abfrage etwa 150 Millisekunden. Durch Erh\xF6hen der Dokumentl\xE4nge auf 4096 Token erh\xF6ht sich die Zeit auf 3,5 Sekunden. Wenn die Abfragel\xE4nge auf 512 Token erh\xF6ht wird, erh\xF6ht sich die Zeit weiter auf 7 Sekunden."])},question1:n=>{const{normalize:e}=n;return e(["Wie viel kostet die Reranker-API?"])},question10:n=>{const{normalize:e}=n;return e(["Kann ich Jina Reranker auf AWS bereitstellen?"])},question11:n=>{const{normalize:e}=n;return e(["Bieten Sie einen genau abgestimmten Reranker f\xFCr dom\xE4nenspezifische Daten an?"])},question3:n=>{const{normalize:e}=n;return e(["Was ist der Unterschied zwischen den beiden Rerankern?"])},question4:n=>{const{normalize:e}=n;return e(["Ist Jina Reranker Open Source?"])},question5:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzt der Reranker mehrere Sprachen?"])},question6:n=>{const{normalize:e}=n;return e(["Wie lang d\xFCrfen Anfragen und Dokumente maximal sein?"])},question7:n=>{const{normalize:e}=n;return e(["Wie viele Dokumente kann ich pro Abfrage maximal neu einordnen?"])},question8:n=>{const{normalize:e}=n;return e(["Wie gro\xDF ist die Stapelgr\xF6\xDFe und wie viele Abfrage-Dokument-Tupel kann ich in einer Anfrage senden?"])},question9:n=>{const{normalize:e}=n;return e(["Mit welcher Latenz kann ich rechnen, wenn ich 100 Dokumente neu einordne?"])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufige Fragen zum Reranker"])}},feature_on_premises_description2:n=>{const{normalize:e}=n;return e(["Stellen Sie Jina Reranker auf AWS Sagemaker und bald auch in Microsoft Azure und Google Cloud Services bereit oder kontaktieren Sie unser Vertriebsteam, um ma\xDFgeschneiderte Kubernetes-Bereitstellungen f\xFCr Ihre Virtual Private Cloud und lokale Server zu erhalten."])},feature_on_premises_description3:n=>{const{normalize:e}=n;return e(["Stellen Sie Jina Reranker auf AWS Sagemaker und Microsoft Azure und bald auch in Google Cloud Services bereit, oder wenden Sie sich an unser Vertriebsteam, um angepasste Kubernetes-Bereitstellungen f\xFCr Ihre Virtual Private Cloud und Ihre lokalen Server zu erhalten."])},feature_solid_description:n=>{const{normalize:e}=n;return e(["Entwickelt auf der Grundlage unserer hochmodernen akademischen Forschung und strengen Tests mit den SOTA-Rerankern, um eine beispiellose Leistung zu gew\xE4hrleisten."])},how_it_works:n=>{const{normalize:e}=n;return e(["So funktioniert das:"])},how_it_works_v1:{description1:n=>{const{normalize:e}=n;return e(["Ein Suchsystem verwendet Einbettungen/BM25, um basierend auf der Anfrage des Benutzers eine breite Palette potenziell relevanter Dokumente zu finden."])},description2:n=>{const{normalize:e}=n;return e(["Anschlie\xDFend analysiert der Reranker diese Ergebnisse auf einer detaillierteren Ebene und ber\xFCcksichtigt dabei die Nuancen der Interaktion der Abfragebegriffe mit dem Dokumentinhalt."])},description3:n=>{const{normalize:e}=n;return e(["Es ordnet die Suchergebnisse neu und platziert diejenigen, die es auf der Grundlage dieser tiefergehenden Analyse f\xFCr am relevantesten h\xE4lt, ganz oben."])},title1:n=>{const{normalize:e}=n;return e(["Erster Abruf"])},title2:n=>{const{normalize:e}=n;return e(["Neueinstufung"])},title3:n=>{const{normalize:e}=n;return e(["Verbesserte Ergebnisse"])}},improve_performance:n=>{const{normalize:e}=n;return e(["Garantierte Verbesserung gegen\xFCber der Vektorsuche"])},improve_performance_description:n=>{const{normalize:e}=n;return e(["Unsere Auswertungen zeigten Verbesserungen f\xFCr Suchsysteme, die den Jina Reranker verwenden, mit +8 % bei der Trefferquote und +33 % beim mittleren reziproken Rang."])},learning1:n=>{const{normalize:e}=n;return e(["Erfahren Sie mehr \xFCber Reranker"])},learning1_description:n=>{const{normalize:e}=n;return e(["Was ist ein Reranker? Warum reicht die Vektorsuche oder die Kosinus\xE4hnlichkeit nicht aus? Erfahren Sie mit unserem umfassenden Leitfaden mehr \xFCber Reranker von Grund auf."])},read_more_about_benchmark:n=>{const{normalize:e}=n;return e(["Lesen Sie mehr \xFCber den Benchmark"])},read_more_about_turbo:n=>{const{normalize:e}=n;return e(["Lesen Sie mehr \xFCber die Turbo- und Tiny-Modelle"])},read_more_about_v2:n=>{const{normalize:e}=n;return e(["Jina Reranker v2 ist der beste Reranker seiner Klasse, der am 25. Juni 2024 ver\xF6ffentlicht wurde. Er wurde f\xFCr Agentic RAG entwickelt. Er bietet Funktionsaufrufunterst\xFCtzung, mehrsprachigen Abruf f\xFCr \xFCber 100 Sprachen, Codesuchfunktionen und ist 6-mal schneller als v1. Lesen Sie mehr \xFCber das v2-Modell."])},reranker_description:n=>{const{normalize:e}=n;return e(["Probieren Sie unsere hochmoderne Reranker-API aus, um Ihre Suchrelevanz und RAG-Genauigkeit zu maximieren. Kostenlos starten!"])},show_v2benchmark:n=>{const{normalize:e}=n;return e(["Benchmark f\xFCr Modell v2 (neueste) anzeigen"])},table:{number_token_document:n=>{const{normalize:e}=n;return e(["Anzahl der Token in jedem Dokument"])},number_token_query:n=>{const{normalize:e}=n;return e(["Anzahl der Token in der Abfrage"])},title:n=>{const{normalize:e}=n;return e(["Unten ist der Zeitaufwand f\xFCr das Reranking einer Abfrage und 100 Dokumenten in Millisekunden aufgef\xFChrt:"])}},title:n=>{const{normalize:e}=n;return e(["Reranker-API"])},top_n:n=>{const{normalize:e}=n;return e(["Anzahl der zur\xFCckgegebenen Dokumente"])},top_n_explain:n=>{const{normalize:e}=n;return e(["Die Anzahl der relevantesten Dokumente, die f\xFCr die Abfrage zur\xFCckgegeben werden sollen."])},try_embedding:n=>{const{normalize:e}=n;return e(["Probieren Sie die Einbettungs-API kostenlos aus"])},try_reranker:n=>{const{normalize:e}=n;return e(["Testen Sie die Reranker-API kostenlos"])},v2_features:{description1:n=>{const{normalize:e}=n;return e(["Reranker v2 erm\xF6glicht die Dokumentensuche in \xFCber 100 Sprachen, unabh\xE4ngig von der Abfragesprache."])},description2:n=>{const{normalize:e}=n;return e(["Reranker v2 bewertet Codeausschnitte und Funktionssignaturen auf der Grundlage von Abfragen in nat\xFCrlicher Sprache und ist somit ideal f\xFCr Agentic RAG-Anwendungen."])},description3:n=>{const{normalize:e}=n;return e(["Reranker v2 erstellt eine Rangfolge der relevantesten Tabellen auf der Grundlage von Abfragen in nat\xFCrlicher Sprache und hilft so dabei, verschiedene Tabellenschemata zu sortieren und das relevanteste zu identifizieren, bevor eine SQL-Abfrage generiert wird."])},title1:n=>{const{normalize:e}=n;return e(["Mehrsprachiger Abruf"])},title2:n=>{const{normalize:e}=n;return e(["Funktionsaufruf und Codesuche"])},title3:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzung tabellarischer und strukturierter Daten"])}},v2benchmark:{descBeir:n=>{const{normalize:e}=n;return e(["NDCG 10-Wertungen f\xFCr verschiedene Neurankingmodelle f\xFCr den Beir-Datensatz gemeldet"])},descCodeSearchNet:n=>{const{normalize:e}=n;return e(["MRR 10-Werte f\xFCr verschiedene Reranking-Modelle f\xFCr den CodeSearchNet-Datensatz gemeldet"])},descMKQA:n=>{const{normalize:e}=n;return e(["Erinnern Sie sich an 10 Ergebnisse, die f\xFCr verschiedene Reranking-Modelle f\xFCr den MKQA-Datensatz gemeldet wurden"])},descNSText2SQL:n=>{const{normalize:e}=n;return e(["Erinnern Sie sich an 3 Ergebnisse, die f\xFCr verschiedene Neurankingmodelle f\xFCr den NSText2SQL-Datensatz gemeldet wurden"])},descRTX4090:n=>{const{normalize:e}=n;return e(["Durchsatzwerte (Abruf von Dokumenten in 50\xA0ms), die f\xFCr verschiedene Neurankingmodelle auf einer RTX\xA04090-GPU gemeldet wurden."])},descToolBench:n=>{const{normalize:e}=n;return e(["Erinnern Sie sich an 3 Bewertungen, die f\xFCr verschiedene Neurankingmodelle f\xFCr den ToolBench-Datensatz gemeldet wurden"])},titleBeir:n=>{const{normalize:e}=n;return e(["BEIR (Heterogener Benchmark f\xFCr verschiedene IR-Aufgaben)"])},titleCodeSearchNet:n=>{const{normalize:e}=n;return e(["CodeSearchNet. Der Benchmark ist eine Kombination aus Abfragen in Docstring- und nat\xFCrlichen Sprachformaten mit gekennzeichneten Codesegmenten, die f\xFCr die Abfragen relevant sind."])},titleMKQA:n=>{const{normalize:e}=n;return e(["MKQA (Fragen und Antworten zum mehrsprachigen Wissen)"])},titleNSText2SQL:n=>{const{normalize:e}=n;return e(["NSText2SQL"])},titleRTX4090:n=>{const{normalize:e}=n;return e(["Durchsatz von Jina Reranker v2 auf RTX4090"])},titleToolBench:n=>{const{normalize:e}=n;return e(["ToolBench. Der Benchmark sammelt \xFCber 16.000 \xF6ffentliche APIs und entsprechende synthetisch generierte Anweisungen f\xFCr deren Verwendung in Einzel- und Multi-API-Einstellungen."])}},vs_table:{col0:n=>{const{normalize:e}=n;return e(["Reranker"])},col0_1:n=>{const{normalize:e}=n;return e(["Verbesserte Suchpr\xE4zision und Relevanz"])},col0_2:n=>{const{normalize:e}=n;return e(["Erste, schnelle Filterung"])},col0_3:n=>{const{normalize:e}=n;return e(["Allgemeine Textsuche f\xFCr weitreichende Abfragen"])},col1:n=>{const{normalize:e}=n;return e(["Vektorsuche"])},col1_1:n=>{const{normalize:e}=n;return e(["Detailliert: Unterdokument und Abfragesegment"])},col1_2:n=>{const{normalize:e}=n;return e(["Breit: Ganze Dokumente"])},col1_3:n=>{const{normalize:e}=n;return e(["Mittelstufe: Verschiedene Textsegmente"])},col2:n=>{const{normalize:e}=n;return e(["BM25"])},col2_1:n=>{const{normalize:e}=n;return e(["Hoch"])},col2_2:n=>{const{normalize:e}=n;return e(["Mittel"])},col2_3:n=>{const{normalize:e}=n;return e(["Niedrig"])},col3_1:n=>{const{normalize:e}=n;return e(["Nicht ben\xF6tigt"])},col3_2:n=>{const{normalize:e}=n;return e(["Hoch"])},col3_3:n=>{const{normalize:e}=n;return e(["Niedrig, nutzt vorgefertigten Index"])},col4_1:n=>{const{normalize:e}=n;return e(["Hoch"])},col4_2:n=>{const{normalize:e}=n;return e(["Hoch"])},col4_3:n=>{const{normalize:e}=n;return e(["Nicht ben\xF6tigt"])},col5_1:n=>{const{normalize:e}=n;return e(["Hervorragend f\xFCr differenzierte Abfragen"])},col5_2:n=>{const{normalize:e}=n;return e(["Ausgewogen zwischen Effizienz und Genauigkeit"])},col5_3:n=>{const{normalize:e}=n;return e(["Konsistent und zuverl\xE4ssig f\xFCr eine breite Palette von Abfragen"])},col6_1:n=>{const{normalize:e}=n;return e(["Sehr pr\xE4zise mit tiefem Kontextverst\xE4ndnis"])},col6_2:n=>{const{normalize:e}=n;return e(["Schnell und effizient, mit m\xE4\xDFiger Genauigkeit"])},col6_3:n=>{const{normalize:e}=n;return e(["Hoch skalierbar, mit nachgewiesener Wirksamkeit"])},col7_1:n=>{const{normalize:e}=n;return e(["Ressourcenintensiv bei komplexer Umsetzung"])},col7_2:n=>{const{normalize:e}=n;return e(["Erfasst m\xF6glicherweise keinen tiefen Abfragekontext oder keine Nuancen"])},col7_3:n=>{const{normalize:e}=n;return e(["Bei sehr spezifischen oder kontextbezogenen Suchen ist die Leistung m\xF6glicherweise unterdurchschnittlich"])},header0:n=>{const{normalize:e}=n;return e(["Beste f\xFCr"])},header1:n=>{const{normalize:e}=n;return e(["Die Granularit\xE4t"])},header2:n=>{const{normalize:e}=n;return e(["Komplexit\xE4t der Abfragezeit"])},header3:n=>{const{normalize:e}=n;return e(["Zeitkomplexit\xE4t indizieren"])},header4:n=>{const{normalize:e}=n;return e(["Komplexit\xE4t der Trainingszeit"])},header5:n=>{const{normalize:e}=n;return e(["Suchqualit\xE4t"])},header6:n=>{const{normalize:e}=n;return e(["St\xE4rken"])},header7:n=>{const{normalize:e}=n;return e(["Schw\xE4chen"])},subtitle:n=>{const{normalize:e}=n;return e(["Die folgende Tabelle bietet einen umfassenden Vergleich von Reranker, Vector/Embeddings Search und BM25 und hebt deren St\xE4rken und Schw\xE4chen in verschiedenen Kategorien hervor."])},title:n=>{const{normalize:e}=n;return e(["Vergleich von Reranker, Vector Search und BM25"])}},what_is:n=>{const{normalize:e}=n;return e(["Was ist ein Reranker?"])},what_is_answer_long:n=>{const{normalize:e}=n;return e([`Ziel eines Suchsystems ist es, schnell und effizient die relevantesten Ergebnisse zu finden. Traditionell wurden Methoden wie BM25 oder tf-idf verwendet, um Suchergebnisse basierend auf der Keyword-\xDCbereinstimmung zu ordnen. Neuere Methoden, wie beispielsweise die einbettungsbasierte Kosinus\xE4hnlichkeit, wurden in vielen Vektordatenbanken implementiert. Diese Methoden sind unkompliziert, k\xF6nnen jedoch manchmal die Feinheiten der Sprache und vor allem die Interaktion zwischen Dokumenten und der Absicht einer Abfrage au\xDFer Acht lassen.

Hier gl\xE4nzt der \u201EReranker\u201C. Ein Reranker ist ein fortschrittliches KI-Modell, das die anf\xE4nglichen Ergebnisse einer Suche \u2013 oft bereitgestellt durch eine einbettungs-/tokenbasierte Suche \u2013 und sie neu bewertet, um sicherzustellen, dass sie besser mit der Absicht des Benutzers \xFCbereinstimmen. Es geht \xFCber den oberfl\xE4chlichen Abgleich von Begriffen hinaus und ber\xFCcksichtigt die tiefere Interaktion zwischen der Suchanfrage und dem Inhalt der Dokumente.`])},what_is_answer_long_ending:n=>{const{normalize:e}=n;return e(["Der Reranker kann die Suchqualit\xE4t erheblich verbessern, da er auf Unterdokument- und Unterabfrageebene arbeitet, d. h. die einzelnen W\xF6rter und Phrasen, ihre Bedeutung und ihre Beziehung zueinander innerhalb der Abfrage und der Dokumente untersucht. Dies f\xFChrt zu pr\xE4ziseren und kontextbezogeneren Suchergebnissen."])},what_is_desc:n=>{const{normalize:e}=n;return e(["Ein Reranker ist ein KI-Modell, das die Suchergebnisse aus einer Vektorsuche oder einem Dense-Retrieval-Modell verfeinert. Mehr lesen."])}},scenex:{caption_image_desc:n=>{const{normalize:e}=n;return e(["Generieren Sie eine Textbeschreibung des Bildes."])},caption_image_title:n=>{const{normalize:e}=n;return e(["Bildunterschrift"])},description:n=>{const{normalize:e}=n;return e(["Entdecken Sie auf Bildern basierende Geschichtenerz\xE4hlungen jenseits von Pixeln"])},example1:n=>{const{normalize:e}=n;return e(["Bei diesem Video handelt es sich offenbar um eine Naturaufnahme mit einem bezaubernden wei\xDFen Hasen und einem Schmetterling auf einer Wiese. Der Hase interagiert auf unterschiedliche Weise mit dem Schmetterling und zeigt so ihre einzigartige Beziehung. Die nat\xFCrliche Umgebung bietet eine malerische Kulisse und unterstreicht die Sch\xF6nheit dieser einfachen, aber faszinierenden Szene."])},generate_story_desc:n=>{const{normalize:e}=n;return e(["Erstellen Sie eine vom Bild inspirierte Geschichte, die h\xE4ufig Dialoge oder Monologe der Charaktere enth\xE4lt."])},generate_story_title:n=>{const{normalize:e}=n;return e(["Geschichte generieren"])},intro1:n=>{const{normalize:e}=n;return e(["F\xFChrende KI-L\xF6sung f\xFCr Bildunterschriften und Videozusammenfassungen"])},json_image_desc:n=>{const{normalize:e}=n;return e(["Generieren Sie mithilfe eines vordefinierten Schemas ein strukturiertes JSON-Format aus dem Bild. Dies erm\xF6glicht eine gezielte Datenextraktion aus dem Bild."])},json_image_title:n=>{const{normalize:e}=n;return e(["Extrahieren Sie JSON aus dem Bild"])},summarize_video_desc:n=>{const{normalize:e}=n;return e(["Erstellen Sie eine pr\xE4gnante Zusammenfassung des Videos und heben Sie wichtige Ereignisse hervor."])},summarize_video_title:n=>{const{normalize:e}=n;return e(["Video zusammenfassen"])},visual_q_a_desc:n=>{const{normalize:e}=n;return e(["Beantworten Sie eine Frage basierend auf dem Bildinhalt."])},visual_q_a_title:n=>{const{normalize:e}=n;return e(["Visuelle Fragen und Antworten"])}},searchbar:{ask_on_current_page:n=>{const{normalize:e}=n;return e(["Fragen Sie auf der aktuellen Seite nach..."])},find_solution:n=>{const{normalize:e}=n;return e(["Generieren Sie eine L\xF6sung f\xFCr..."])},hint:n=>{const{normalize:e}=n;return e(["Durchsuchen Sie Produkte, Neuigkeiten und Ihre Fragen"])},hotkey:n=>{const{normalize:e}=n;return e(["Dr\xFCcken Sie die Taste /, um auf dieser Seite zu suchen"])},hotkey1:n=>{const{normalize:e}=n;return e(["Dr\xFCcken Sie"])},hotkey2:n=>{const{normalize:e}=n;return e(["Umschalten"])},hotkey_long1:n=>{const{normalize:e}=n;return e(["Dr\xFCcken Sie jederzeit"])},hotkey_long3:n=>{const{normalize:e}=n;return e(["um die Suchleiste zu \xF6ffnen"])},more_results:n=>{const{normalize:e,interpolate:r,named:i}=n;return e([r(i("_numMore"))," weitere Ergebnisse"])},placeholder:n=>{const{normalize:e}=n;return e(["Stellen Sie auf dieser Seite Fragen"])},proposing_solution:n=>{const{normalize:e}=n;return e(["Generierung einer Antwort basierend auf dem Seiteninhalt ..."])},required:n=>{const{normalize:e}=n;return e(["Bitte beschreiben Sie Ihre Frage genauer."])},results:n=>{const{normalize:e}=n;return e(["Ergebnisse"])}},searchscape:{description:n=>{const{normalize:e}=n;return e(["Navigieren, interagieren, verfeinern: Produktentdeckung neu denken"])}},semantic:{description:n=>{const{normalize:e}=n;return e(["\xDCberbr\xFCckung der semantischen L\xFCcke in Ihrer vorhandenen Suchinfrastruktur"])}},share:{"Hacker News":n=>{const{normalize:e}=n;return e(["Hacker-News"])},LinkedIn:n=>{const{normalize:e}=n;return e(["LinkedIn"])},facebook:n=>{const{normalize:e}=n;return e(["Facebook"])},reddit:n=>{const{normalize:e}=n;return e(["Reddit"])},rss:n=>{const{normalize:e}=n;return e(["RSS-Feed"])},share_btn:n=>{const{normalize:e}=n;return e(["Aktie"])},twitter:n=>{const{normalize:e}=n;return e(["X (Twitter)"])}},spectrum:{click_to_learn_more:n=>{const{normalize:e}=n;return e(["Klicke, um mehr zu lernen"])},contextualization:n=>{const{normalize:e}=n;return e(["Kontextualisierung"])},contextualization_desc:n=>{const{normalize:e}=n;return e(["Reranker passen anf\xE4ngliche Suchergebnisse basierend auf tiefer kontextueller Relevanz in Bezug auf die Abfrage an. Dadurch wird das Ranking verfeinert, um besser zu dem zu passen, was Benutzer wahrscheinlich n\xFCtzlich finden."])},coreInfra:n=>{const{normalize:e}=n;return e(["Kerninfrastruktur"])},coreInfra_desc:n=>{const{normalize:e}=n;return e(["Core Infra bietet eine Cloud-native Ebene f\xFCr die Entwicklung, Bereitstellung und Orchestrierung von Suchgrundlagenmodellen sowohl in der \xF6ffentlichen Cloud als auch vor Ort, sodass Dienste problemlos nach oben und unten skaliert werden k\xF6nnen."])},embedding_serving:n=>{const{normalize:e}=n;return e(["Servieren einbetten"])},embedding_serving_description:n=>{const{normalize:e}=n;return e(["Bereitstellung von Einbettungen \xFCber einen robusten, skalierbaren Mikroservice unter Verwendung cloudnativer Technologien."])},embedding_tech:n=>{const{normalize:e}=n;return e(["Einbettungen"])},embedding_tech_description:n=>{const{normalize:e}=n;return e([`Bei Jina AI nutzen wir die Leistungsf\xE4higkeit der Einbettungstechnologie, um verschiedene KI-Anwendungen zu revolutionieren. Diese Technologie dient als einheitliche Methode zur effizienten Darstellung und Komprimierung verschiedener Datentypen und stellt sicher, dass keine wichtigen Informationen verloren gehen. Unser Fokus liegt auf der Transformation komplexer Datens\xE4tze in ein allgemein verst\xE4ndliches Einbettungsformat, das f\xFCr eine pr\xE4zise und aufschlussreiche KI-Analyse unerl\xE4sslich ist.

Einbettungen sind von grundlegender Bedeutung, insbesondere bei Anwendungen wie der pr\xE4zisen Bild- und Spracherkennung, wo sie dabei helfen, feink\xF6rnige Details und Nuancen zu erkennen. Bei der Verarbeitung nat\xFCrlicher Sprache verbessern Einbettungen das Verst\xE4ndnis von Kontext und Stimmung und f\xFChren zu genaueren Konversations-KI- und Sprach\xFCbersetzungstools. Sie sind auch von entscheidender Bedeutung bei der Entwicklung anspruchsvoller Empfehlungssysteme, die ein tiefes Verst\xE4ndnis der Benutzerpr\xE4ferenzen in verschiedenen Inhaltsformen wie Text, Audio und Video erfordern.`])},embedding_tuning:n=>{const{normalize:e}=n;return e(["Tuning einbetten"])},embedding_tuning_description:n=>{const{normalize:e}=n;return e(["Optimierung hochwertiger Einbettungen durch Integration von Fachwissen f\xFCr eine verbesserte aufgabenspezifische Leistung."])},embeddings:n=>{const{normalize:e}=n;return e(["Einbettungen"])},embeddings_desc:n=>{const{normalize:e}=n;return e(["Einbettungen sind die Eckpfeiler moderner Suchsysteme und stellen multimodale Daten in Zahlenvektoren dar. Dieser Prozess erm\xF6glicht ein differenzierteres und kontextbezogeneres Verst\xE4ndnis von Inhalten, das weit \xFCber die einfache Keyword-\xDCbereinstimmung hinausgeht."])},for_developers:n=>{const{normalize:e}=n;return e(["F\xFCr Entwickler"])},for_enterprise:n=>{const{normalize:e}=n;return e(["F\xFCr Unternehmen"])},for_power_users:n=>{const{normalize:e}=n;return e(["F\xFCr Power-User"])},grounding:n=>{const{normalize:e}=n;return e(["Erdung"])},grounding_desc:n=>{const{normalize:e}=n;return e(["Der Leser verfeinert Eingaben und Ergebnisse durch LLMs. Sie verbessern die Qualit\xE4t, Lesbarkeit und Sachlichkeit der endg\xFCltigen Antwort."])},model_serving:n=>{const{normalize:e}=n;return e(["Modelldienst"])},model_serving_description:n=>{const{normalize:e}=n;return e(["Die Bereitstellung fein abgestimmter Modelle in einer Produktionsumgebung, die in der Regel erhebliche Ressourcen wie GPU-Hosting erfordert. MLOps, wobei der Schwerpunkt auf der skalierbaren, effizienten und zuverl\xE4ssigen Bereitstellung mittelgro\xDFer bis gro\xDFer Modelle liegt."])},model_tuning:n=>{const{normalize:e}=n;return e(["Modelltuning"])},model_tuning_description:n=>{const{normalize:e}=n;return e(["Bei der Feinabstimmung, auch Feinabstimmung genannt, werden die Parameter eines vorab trainierten Modells an einem neuen, oft aufgabenspezifischen Datensatz angepasst, um dessen Leistung zu verbessern und es an eine bestimmte Anwendung anzupassen."])},personalization:n=>{const{normalize:e}=n;return e(["Personalisierung"])},personalization_desc:n=>{const{normalize:e}=n;return e(["Verwenden Sie synthetische Daten und trainieren Sie anhand von Benutzeranweisungen automatisch ein dom\xE4nenspezifisches Einbettungs- und Reranking-Modell."])},promptOps:n=>{const{normalize:e}=n;return e(["PromptOps"])},promptOps_desc:n=>{const{normalize:e}=n;return e(["Prompt Ops verbessern die Eingabe und Ausgabe des Suchsystems, einschlie\xDFlich der bei der Abfrageerweiterung, der LLM-Eingabe und der Ergebnisumschreibung verwendeten. Dies stellt sicher, dass die Suche besser versteht und bessere Ergebnisse liefert."])},prompt_serving:n=>{const{normalize:e}=n;return e(["Prompte Bedienung"])},prompt_serving_description:n=>{const{normalize:e}=n;return e(["Verpacken und Bereitstellen von Prompts \xFCber eine API, ohne umfangreiche Modelle zu hosten. Die API ruft einen \xF6ffentlichen Modelldienst f\xFCr gro\xDFe Sprachen auf und \xFCbernimmt die Orchestrierung von Ein- und Ausgaben in einer Operationskette."])},prompt_tech:n=>{const{normalize:e}=n;return e(["Prompt- und Agent-Engineering"])},prompt_tech_description:n=>{const{normalize:e}=n;return e([`Bei Jina AI erkennen wir, dass Prompt Engineering f\xFCr die Interaktion mit gro\xDFen Sprachmodellen (LLMs) von entscheidender Bedeutung ist. Mit der Weiterentwicklung dieser Modelle nimmt die Komplexit\xE4t der Eingabeaufforderungen zu und umfasst komplexe \xDCberlegungen und Logik. Dieser Fortschritt unterstreicht das miteinander verflochtene Wachstum von LLMs und die schnelle Weiterentwicklung.

Wir sehen eine Zukunft voraus, in der LLMs als Compiler fungieren und Eingabeaufforderungen zur neuen Programmiersprache werden. Diese Verschiebung deutet darauf hin, dass sich zuk\xFCnftige technologische Kompetenzen mehr auf die schnelle Beherrschung als auf die traditionelle Codierung konzentrieren k\xF6nnten. Unser Ziel bei Jina AI ist es, in diesem transformativen Bereich eine F\xFChrungsrolle zu \xFCbernehmen und durch die Beherrschung dieser aufstrebenden \u201ESprache\u201C fortschrittliche KI f\xFCr den t\xE4glichen Gebrauch zug\xE4nglich und praktisch zu machen.`])},prompt_tuning:n=>{const{normalize:e}=n;return e(["Prompte Abstimmung"])},prompt_tuning_description:n=>{const{normalize:e}=n;return e(["Der Prozess der Erstellung und Verfeinerung der Prompts, um die Ausgabe auf bestimmte, gew\xFCnschte Antworten auszurichten."])},representation:n=>{const{normalize:e}=n;return e(["Darstellung"])},representation_desc:n=>{const{normalize:e}=n;return e(["Embeddings transformieren multimodale Daten in ein einheitliches, vektorisiertes Format. Dadurch ist das Suchsystem in der Lage, Inhalte \xFCber einfache Schlagw\xF6rter hinaus zu verstehen und zu kategorisieren."])},rerankers:n=>{const{normalize:e}=n;return e(["Neubewerter"])},rerankers_desc:n=>{const{normalize:e}=n;return e(["Reranker \xFCbernehmen die anf\xE4nglichen Ergebnisse aus den Einbettungen und verfeinern sie, um sicherzustellen, dass dem Benutzer die relevantesten Ergebnisse pr\xE4sentiert werden. Dies ist entscheidend, um qualitativ hochwertige Suchergebnisse zu liefern, die der Absicht des Benutzers entsprechen."])}},subscribe_system:{care_most:n=>{const{normalize:e}=n;return e(["Was liegt Ihnen am meisten am Herzen?"])},care_most_options:{accuracy:n=>{const{normalize:e}=n;return e(["Genauigkeit"])},cost:n=>{const{normalize:e}=n;return e(["Kosten"])},other:n=>{const{normalize:e}=n;return e(["Andere"])},scalability:n=>{const{normalize:e}=n;return e(["Skalierbarkeit"])},speed:n=>{const{normalize:e}=n;return e(["Geschwindigkeit"])}},care_most_required:n=>{const{normalize:e}=n;return e(["Was ist Ihnen bei der Auswahl einer Dienstleistung am wichtigsten?"])},company_size:n=>{const{normalize:e}=n;return e(["Wie gro\xDF ist Ihr Unternehmen?"])},company_size_required:n=>{const{normalize:e}=n;return e(["Teilen Sie uns mit, dass die Gr\xF6\xDFe Ihres Unternehmens uns hilft, einen besseren Service zu bieten"])},company_url:n=>{const{normalize:e}=n;return e(["Wie lautet die Website Ihres Unternehmens?"])},company_url_required:n=>{const{normalize:e}=n;return e(["Sagen Sie uns, dass die Website Ihres Unternehmens uns hilft, einen besseren Service zu bieten"])},contactName:n=>{const{normalize:e}=n;return e(["Ihr Name"])},contactName_required:n=>{const{normalize:e}=n;return e(["Wie sollen wir Sie ansprechen?"])},contactTitle:n=>{const{normalize:e}=n;return e(["Wie lautet deine Jobbezeichnung?"])},contactTitle_required:n=>{const{normalize:e}=n;return e(["Ihre Berufsbezeichnung ist erforderlich"])},contact_us:n=>{const{normalize:e}=n;return e(["Kontaktiere uns"])},domain_required:n=>{const{normalize:e}=n;return e(["Teilen Sie uns mit, dass Ihre Arbeitsdom\xE4ne uns hilft, einen besseren Service zu bieten"])},email:n=>{const{normalize:e}=n;return e(["Email"])},email_contact:n=>{const{normalize:e}=n;return e(["Ihre Kontakt-E-Mail"])},email_invalid:n=>{const{normalize:e}=n;return e(["E-Mail ist ung\xFCltig"])},email_required:n=>{const{normalize:e}=n;return e(["E-Mail ist erforderlich"])},fine_tuned_embedding:n=>{const{normalize:e}=n;return e(["Sind Sie an fein abgestimmten Einbettungen interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!"])},fine_tuned_reranker:n=>{const{normalize:e}=n;return e(["Sind Sie an fein abgestimmten Rerankern interessiert, die auf Ihre Daten und Ihren Anwendungsfall zugeschnitten sind? Lass uns diskutieren!"])},full_survey:n=>{const{normalize:e}=n;return e(["Nehmen Sie an der vollst\xE4ndigen Umfrage teil und erhalten Sie schnellere Antworten von unserem Team"])},get_new_key:n=>{const{normalize:e}=n;return e(["Holen Sie sich Ihren API-Schl\xFCssel"])},get_update_blog_posts:n=>{const{normalize:e}=n;return e(["Erhalten Sie die neuesten Updates f\xFCr die Blogbeitr\xE4ge"])},get_update_embeddings:n=>{const{normalize:e}=n;return e(["Erhalten Sie die neuesten Updates f\xFCr die Einbettungen"])},send:n=>{const{normalize:e}=n;return e(["Schicken"])},sign_up:n=>{const{normalize:e}=n;return e(["Melden Sie sich an"])},subscribe:n=>{const{normalize:e}=n;return e(["Abonnieren"])},tell_domain:n=>{const{normalize:e}=n;return e(["Teilen Sie uns Ihre Domain mit"])},usage_type:n=>{const{normalize:e}=n;return e(["Welche Art der Nutzung beschreibt Sie am besten?"])},usage_type_options:{other:n=>{const{normalize:e}=n;return e(["Andere"])},poc:n=>{const{normalize:e}=n;return e(["Konzeptioneller Bewei\xDF"])},production:n=>{const{normalize:e}=n;return e(["Produktion"])},research:n=>{const{normalize:e}=n;return e(["Forschung"])}},usage_type_required:n=>{const{normalize:e}=n;return e(["Teilen Sie uns mit, dass Ihre Nutzungsart uns hilft, einen besseren Service zu bieten"])},used_product:n=>{const{normalize:e}=n;return e(["Welches Modell verwenden Sie?"])},used_product_required:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie das Modell aus, das Sie verwenden oder an dem Sie interessiert sind"])}},think_gpt:{description:n=>{const{normalize:e}=n;return e(["Agententechniken zur Erweiterung Ihres LLM und zur \xDCberschreitung seiner Grenzen"])}},tokenizer:{advance_usage:n=>{const{normalize:e}=n;return e(["Verwenden Sie die POST-Anfrage f\xFCr weitere Funktionen"])},basic_usage:n=>{const{normalize:e}=n;return e(["Verwenden Sie eine GET-Anfrage, um Token zu z\xE4hlen"])},basic_usage_explain:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen einfach eine GET-Anfrage senden, um die Anzahl der Token in Ihrem Text zu z\xE4hlen."])},change_content:n=>{const{normalize:e}=n;return e(["\xC4ndern Sie den \u201EInhalt\u201C und sehen Sie sich das Live-Ergebnis an"])},chunk:n=>{const{normalize:e}=n;return e(["Brocken"])},chunking:n=>{const{normalize:e}=n;return e(["Blitzschnelles Zerlegen langer Dokumente in Bl\xF6cke!"])},chunking_explain:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen die Tokenizer-API auch verwenden, um lange Dokumente in kleinere Segmente aufzuteilen, sodass sie leichter in Einbettungen oder Rerankern verarbeitet werden k\xF6nnen. Wir nutzen g\xE4ngige Strukturhinweise und erstellen eine Reihe von Regeln und Heuristiken, die bei unterschiedlichen Inhaltstypen, darunter Markdown, HTML, LaTeX und mehr, au\xDFergew\xF6hnlich gut funktionieren und eine genaue Segmentierung des Textes in sinnvolle Abschnitte gew\xE4hrleisten."])},chunks_in_total:n=>{const{normalize:e,interpolate:r,named:i}=n;return e([r(i("_numChunks"))," Chunks insgesamt"])},count_tokens_hint:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["<b>",r(i("_numTokens")),"</b> Token, ",r(i("_numChars"))," Zeichen."])},description:n=>{const{normalize:e}=n;return e(["Kostenlose API zum Tokenisieren von Texten, Z\xE4hlen und Abrufen der ersten/letzten N-Token."])},description_long:n=>{const{normalize:e}=n;return e(["Unsere Tokenizer-API ist entscheidend, um LLMs dabei zu helfen, Eingaben innerhalb von Kontextgrenzen zu verwalten und die Modellleistung zu optimieren. Sie erm\xF6glicht Entwicklern, Token zu z\xE4hlen und relevante Textsegmente zu extrahieren, was eine effiziente Datenverarbeitung und Kostenverwaltung gew\xE4hrleistet."])},explain:n=>{const{normalize:e}=n;return e(["Ein Tokenizer ist eine wichtige Komponente, die Text in Token umwandelt. Dabei handelt es sich um die grundlegenden Dateneinheiten, die ein Embedding-/Reranker-Modell oder LLM verarbeitet. Token k\xF6nnen ganze W\xF6rter, Wortteile oder sogar einzelne Zeichen darstellen."])},faq_v1:{answer1:n=>{const{normalize:e}=n;return e(["Die Nutzung der Tokenizer-API ist kostenlos. Durch die Angabe Ihres API-Schl\xFCssels k\xF6nnen Sie auf ein h\xF6heres Ratenlimit zugreifen, und Ihr Schl\xFCssel wird nicht in Rechnung gestellt."])},answer2:n=>{const{normalize:e}=n;return e(["Ohne API-Schl\xFCssel k\xF6nnen Sie auf die Tokenizer-API mit einer Ratenbegrenzung von 20 RPM zugreifen."])},answer3:n=>{const{normalize:e}=n;return e(["Mit einem API-Schl\xFCssel k\xF6nnen Sie auf die Tokenizer-API mit einer Ratenbegrenzung von 200 RPM zugreifen. F\xFCr Premium-Benutzer betr\xE4gt die Ratenbegrenzung 1000 RPM."])},answer4:n=>{const{normalize:e}=n;return e(["Nein, Ihr API-Schl\xFCssel wird nur verwendet, um auf ein h\xF6heres Ratenlimit zuzugreifen."])},answer5:n=>{const{normalize:e}=n;return e(["Ja, die Tokenizer-API ist mehrsprachig und unterst\xFCtzt \xFCber 100 Sprachen."])},answer6:n=>{const{normalize:e}=n;return e(["GET-Anfragen werden ausschlie\xDFlich zum Z\xE4hlen der Anzahl von Token in einem Text verwendet und erm\xF6glichen Ihnen die einfache Integration als Z\xE4hler in Ihre Anwendung. POST-Anfragen unterst\xFCtzen mehr Parameter und Funktionen, wie z. B. die R\xFCckgabe der ersten/letzten N Token."])},answer7:n=>{const{normalize:e}=n;return e(["Sie k\xF6nnen bis zu 4 Millionen Zeichen pro Anfrage senden."])},answer8:n=>{const{normalize:e}=n;return e(["Die Chunking-Funktion segmentiert lange Dokumente anhand gemeinsamer Strukturmerkmale in kleinere Chunks und stellt so eine genaue Segmentierung des Textes in sinnvolle Chunks sicher. Im Wesentlichen handelt es sich um ein (gro\xDFes!) Regex-Muster, das Text anhand bestimmter syntaktischer Merkmale segmentiert, die h\xE4ufig mit semantischen Grenzen \xFCbereinstimmen, wie etwa Satzenden, Absatzumbr\xFCchen, Zeichensetzung und bestimmten Konjunktionen. Es handelt sich nicht um semantisches Chunking. Dieser (gro\xDFe) Regex ist so leistungsf\xE4hig, wie er im Rahmen der Beschr\xE4nkungen regul\xE4rer Ausdr\xFCcke sein kann. Er schafft ein Gleichgewicht zwischen Komplexit\xE4t und Leistung. W\xE4hrend mit Regex kein echtes semantisches Verst\xE4ndnis m\xF6glich ist, wird der Kontext anhand gemeinsamer Strukturmerkmale gut angen\xE4hert."])},answer9:n=>{const{normalize:e}=n;return e(["Wenn die Eingabe spezielle Token enth\xE4lt, werden diese von unserer Tokenizer-API in das Feld \u201Especial_tokens\u201C eingef\xFCgt. So k\xF6nnen Sie sie leicht identifizieren und f\xFCr Ihre nachfolgenden Aufgaben entsprechend behandeln, z. B. indem Sie sie entfernen, bevor Sie den Text in ein LLM eingeben, um Injektionsangriffe zu verhindern."])},question1:n=>{const{normalize:e}=n;return e(["Wie viel kostet die Tokenizer-API?"])},question2:n=>{const{normalize:e}=n;return e(["Wenn ich keinen API-Schl\xFCssel angebe, wie hoch ist dann die Ratenbegrenzung?"])},question3:n=>{const{normalize:e}=n;return e(["Wie hoch ist die Ratenbegrenzung, wenn ich einen API-Schl\xFCssel angebe?"])},question4:n=>{const{normalize:e}=n;return e(["Werden die Token von meinem API-Schl\xFCssel abgezogen?"])},question5:n=>{const{normalize:e}=n;return e(["Unterst\xFCtzt die Tokenizer-API mehrere Sprachen?"])},question6:n=>{const{normalize:e}=n;return e(["Was ist der Unterschied zwischen GET- und POST-Anfragen?"])},question7:n=>{const{normalize:e}=n;return e(["Was ist die maximale L\xE4nge, die ich pro Anfrage tokenisieren kann?"])},question8:n=>{const{normalize:e}=n;return e(["Wie funktioniert die Chunking-Funktion? Handelt es sich dabei um semantisches Chunking?"])},question9:n=>{const{normalize:e,plural:r}=n;return r([e(["Wie handhaben Sie spezielle Token wie <"]),e(["endoftext"]),e(["> in der Tokenizer-API?"])])},title:n=>{const{normalize:e}=n;return e(["H\xE4ufige Fragen zum Tokenizer"])}},free_api:n=>{const{normalize:e}=n;return e(["Die Nutzung der Tokenizer-API ist kostenlos. Durch die Angabe Ihres API-Schl\xFCssels k\xF6nnen Sie auf ein h\xF6heres Ratenlimit zugreifen und f\xFCr Ihren Schl\xFCssel werden keine Geb\xFChren erhoben."])},input_text:n=>{const{normalize:e}=n;return e(["Eingabetext"])},is_free:n=>{const{normalize:e}=n;return e(["Die Tokenizer-API ist kostenlos!"])},is_free_description:n=>{const{normalize:e}=n;return e(["Durch die Angabe Ihres API-Schl\xFCssels k\xF6nnen Sie auf eine h\xF6here Ratenbegrenzung zugreifen und f\xFCr Ihren Schl\xFCssel fallen keine Kosten an."])},parameters:{auth_token:n=>{const{normalize:e}=n;return e(["API-Schl\xFCssel f\xFCr h\xF6here Ratenbegrenzung hinzuf\xFCgen"])},auth_token_explain:n=>{const{normalize:e}=n;return e(["Geben Sie Ihren Jina-API-Schl\xFCssel ein, um auf eine h\xF6here Ratenbegrenzung zuzugreifen. Aktuelle Informationen zur Ratenbegrenzung finden Sie in der folgenden Tabelle."])},head:n=>{const{normalize:e}=n;return e(["Die ersten N Token zur\xFCckgeben"])},head_explain:n=>{const{normalize:e}=n;return e(["Gibt die ersten N Token des angegebenen Inhalts zur\xFCck. Grenzenexklusiv. Kann nicht mit \u201Etail\u201C verwendet werden."])},learn_more:n=>{const{normalize:e}=n;return e(["Mehr erfahren"])},return_chunks:n=>{const{normalize:e}=n;return e(["Die Brocken zur\xFCckgeben"])},return_chunks_explain:n=>{const{normalize:e}=n;return e(["Aufteilung der Eingabe in semantisch sinnvolle Segmente bei gleichzeitiger Verarbeitung einer gro\xDFen Vielfalt an Textarten und Randf\xE4llen auf der Grundlage gemeinsamer Strukturhinweise."])},return_tokens:n=>{const{normalize:e}=n;return e(["Die Token zur\xFCckgeben"])},return_tokens_explain:n=>{const{normalize:e}=n;return e(["Gibt die Token und ihre entsprechenden IDs in der Antwort zur\xFCck. Schalten Sie um, um die Ergebnisvisualisierung anzuzeigen."])},tail:n=>{const{normalize:e}=n;return e(["Die letzten N Token zur\xFCckgeben"])},tail_explain:n=>{const{normalize:e}=n;return e(["Gibt die letzten N Token des angegebenen Inhalts zur\xFCck. Grenzenexklusiv. Kann nicht mit \u201Ehead\u201C verwendet werden."])},type:n=>{const{normalize:e}=n;return e(["Tokenisierer"])},type_explain:n=>{const{normalize:e}=n;return e(["W\xE4hlen Sie den zu verwendenden Tokenizer aus."])},used_by_models:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Wird in ",r(i("_usedBy"))," verwendet."])}},show_space:n=>{const{normalize:e}=n;return e(["F\xFChrende/nachfolgende Leerzeichen anzeigen"])},table:{td_1_0:n=>{const{normalize:e}=n;return e(["Texte tokenisieren, z\xE4hlen und die ersten/letzten N Token abrufen."])},td_1_1:n=>{const{normalize:e}=n;return e(["20 U/min"])},td_1_2:n=>{const{normalize:e}=n;return e(["200 U/min"])},td_1_3:n=>{const{normalize:e}=n;return e(["1000 U/min"])},td_1_4:n=>{const{normalize:e}=n;return e(["Keine Geb\xFChr"])},td_1_5:n=>{const{normalize:e}=n;return e(["800 ms"])}},title:n=>{const{normalize:e}=n;return e(["Tokenizer-API"])},token_index:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["Token-Index: ",r(i("_index"))])},usage:n=>{const{normalize:e}=n;return e(["Verwendung"])},visualization:n=>{const{normalize:e}=n;return e(["Visualisierung"])},what_is:n=>{const{normalize:e}=n;return e(["Was ist ein Tokenizer?"])}},translator:{cta:n=>{const{normalize:e,interpolate:r,named:i}=n;return e(["In ",r(i("_lang")),"-Code \xFCbersetzen"])},select_language:n=>{const{normalize:e}=n;return e(["Sprache"])}},vectordb:{description:n=>{const{normalize:e}=n;return e(["Eine Python-Vektordatenbank, die Sie brauchen \u2013 nicht mehr und nicht weniger"])}},zzz:n=>{const{normalize:e}=n;return e(["zzz"])}};export{t as default};
