const e="Мы предоставляем лучшие в своем классе встраивания, средства изменения ранжирования, LLM-считыватели и быстрые оптимизаторы, а также новаторский поисковый искусственный интеллект для мультимодальных данных.",n="Ваша поисковая основа, полный вперёд!",a={approach:"Наш подход",approach_connect_dots:"Соединение точек: опытные пользователи для предприятий",approach_connect_dots_description:"Итак, почему для нашей модели, ориентированной на предприятие, так важна ориентация на опытных пользователей? Потому что речь идет об установлении ранних отношений. Угождая опытным пользователям сейчас, мы наводим мосты с предприятиями, на которые они будут влиять в будущем. Это стратегическая игра — долгосрочные инвестиции, чтобы наши корпоративные предложения оставались в центре внимания, когда эти опытные пользователи поднимаются на руководящие должности в организациях.",approach_content1:"В быстро развивающемся мире ИИ стратегии должны быть одновременно гибкими и дальновидными. В то время как наше основное предложение по-прежнему сосредоточено на предприятиях, ландшафт ИИ изменился таким образом, что это требует переосмысления нашего подхода к привлечению клиентов. Вот почему введение опытных пользователей в качестве точки входа в нашу воронку не только инновационно, но и имеет решающее значение для нашего устойчивого роста в корпоративном секторе.",approach_content2:"В Jina AI наша стратегия заключается в том, чтобы действовать на опережение, а не реагировать. Включение опытных пользователей в качестве точки входа в воронку гарантирует, что мы не только улавливаем текущие рыночные тенденции, но и стратегически готовы к будущему росту предприятия. Наша приверженность предприятиям остается непоколебимой; однако наш подход к их достижению является инновационным, надежным и, прежде всего, дальновидным.",approach_content4:'Каждый хочет лучшего поиска. В Jina AI мы обеспечиваем лучший поиск, предоставляя <span class="text-primary text-bold">Search Foundation</span>, который состоит из Embeddings, Rerankers, Reader и Prompt Ops. Эти компоненты работают сообща, чтобы произвести революцию в том, как мы ищем и понимаем данные.',approach_miss_mark:"Почему традиционные MLOps промахиваются",approach_miss_mark_description:"Хотя приток опытных пользователей значителен, традиционные инструменты MLOps плохо приспособлены для удовлетворения их потребностей. Эти инструменты напоминают использование трактора для передвижения по городским улицам — они тяжелые и часто чрезмерные. Разработчикам нового поколения требуются гибкие, интуитивно понятные инструменты, дополняющие их быстрый темп разработки.",approach_new_paradigm:"Технология на основе подсказок: новая парадигма",approach_new_paradigm_description:`2023 год ознаменовался значительным изменением: появлением технологий, основанных на подсказках. Упростив процесс разработки ИИ, он демократизировал доступ к инструментам ИИ. Теперь те, у кого нет обширного опыта программирования, называемые «опытными пользователями», могут заниматься разработкой ИИ без крутых кривых обучения, связанных с такими инструментами, как Pytorch, Docker или Kubernetes.

Проводя параллель, это похоже на эволюцию персональных компьютеров. Первоначально компьютерами управляли только технические специалисты. Но с появлением удобных интерфейсов в нем могла участвовать более широкая аудитория. Сегодня, с технологией, основанной на подсказках, мы наблюдаем аналогичную демократизацию в ИИ.`,awards:"Награды и признание",berlin:"Берлин, Германия (штаб-квартира)",berlin_address:"Prinzessinnenstraße 19-20, 10969 Берлин, Германия",berlin_address2:"Geschäftsanschrift: Leipzigerstr. 96, 10117 Берлин, Германия",bj:"Пекин, Китай",bj_address:"Уровень 5, здание 6, ул. Хайдянь Вест, д. 48, Пекин, Китай",brochure_info:"Ваш путеводитель по нашей компании ждет",description:"Будущее начинается здесь.",download_brochure1:"Скачать брошюру",download_docarray_logo:"Загрузите логотип DocArray",download_docarray_logo_desc:"Получите доступ к логотипу DocArray — проекту с открытым исходным кодом, инициированному Jina AI и предоставленному Linux Foundation в декабре 2022 года. Доступно в светлом и темном режимах, в форматах PNG и SVG.",download_jina_logo:"Загрузите логотип Jina AI",download_jina_logo_desc:"Получите логотип Jina AI как в светлом, так и в темном режимах, доступный в форматах PNG и SVG. Этот логотип является зарегистрированной торговой маркой в ​​Ведомстве интеллектуальной собственности Европейского Союза (EUIPO).",download_logo:"Скачать логотипы",employees:"Сотрудники сегодня",empower_developers:"Расширение возможностей разработчиков",fastApiCaption:"С 2021 года пожертвовал более 20 000 долларов.",founded:"Основан",founded_in:"Основан в",investors:"Наши инвесторы",linuxFoundationCaption:"Вносит ежегодный взнос в размере 10 000 долларов США, начиная с 2022 года.",many:"Много",media:{video:"Видео интервью"},mission:"Наша миссия",mission_content1:"Мы. Наши ключевые технологии, включая быструю настройку, оперативное обслуживание, настройку моделей и обслуживание моделей, воплощают нашу приверженность демократизации доступа к ИИ. Посредством нашей инициативы с открытым исходным кодом мы стремимся способствовать инновациям, сотрудничеству и прозрачности, обеспечивая масштабируемые, эффективные и надежные решения. Jina AI — это больше, чем просто компания; это сообщество, призванное дать компаниям возможность решать динамичные задачи цифровой эпохи и процветать в своих областях.",mission_content2:"В основе Jina AI лежит наша миссия — стать порталом к ​​мультимодальному ИИ для самых разных клиентов: от опытных пользователей и разработчиков до предприятий. Мы глубоко верим в силу открытого исходного кода и стремимся создавать передовые и доступные инструменты для сообщества искусственного интеллекта. Наши ключевые технологии, в том числе быстрая настройка, оперативное обслуживание, встраивание-настройка и встраивание-обслуживание, воплощают нашу приверженность демократизации доступа к ИИ. Посредством нашей инициативы с открытым исходным кодом мы стремимся способствовать инновациям, сотрудничеству и прозрачности, обеспечивая масштабируемые, эффективные и надежные решения. Jina AI — это больше, чем просто компания; это сообщество, призванное дать компаниям возможность решать динамичные задачи цифровой эпохи и процветать в своих областях.",mission_content3:"Наша миссия в Jina AI — возглавлять развитие мультимодального искусственного интеллекта с помощью инновационных технологий внедрения и подсказок, уделяя особое внимание таким областям, как обработка естественного языка, анализ изображений и видео, а также кросс-модальное взаимодействие данных. Эта специализация позволяет нам предоставлять уникальные решения, которые превращают сложные данные из нескольких источников в действенные идеи и новаторские приложения.",mit_report_title:"Мультимодальность: новый рубеж ИИ",mit_techreview:"Обзор технологий Массачусетского технологического института",numfocusCaption:"Регулярно жертвует каждый месяц, начиная с 2022 года.",office:"Наши офисы",otherProjectsCaption:"Пожертвовал более 3000 долларов через спонсорство Github.",our_answer:"Абсолютно, Ян. Мы работаем над этим, строим мосты в будущее мультимодального ИИ!",pythonSoftwareFoundationCaption:"Предоставил единовременное пожертвование в размере 10 000 долларов и спонсировал несколько мероприятий PyCon, в том числе в Германии, Италии, Китае и США.",sectors:{ecommerceRetail:"Торговые площадки следующего поколения",ecommerceRetail_description:"Лидеры электронной коммерции и розничной торговли сотрудничают с Jina AI для предоставления точных рекомендаций по продуктам и углубленного поиска. Наши многоязычные вставки и рераннеры на основе ИИ помогают оптимизировать обнаружение, повысить конверсию и сократить время на понимание для глобальных каталогов продуктов.",ecommerceRetail_short:"Электронная коммерция и розничная торговля",financeConsulting:"Дальновидные консультанты и аналитики",financeConsulting_description:"Финансовые компании и консалтинговые компании используют крупномасштабную очистку данных Jina AI и обучение модели, ориентированной на домен, чтобы получать информацию в режиме реального времени. Наше корпоративное лицензирование и безопасные локальные развертывания позволяют им сохранять конфиденциальность, одновременно получая выгоду от расширенного поиска и аналитики.",financeConsulting_short:"Фин & Консалт",media:"Увлекательные создатели контента",media_description:"Медиаорганизации используют Jina AI для преобразования обширных мультимедийных ресурсов в доступные для поиска знания, оптимизируя внутренние исследования и обогащая пользовательский опыт. Наши специализированные службы чтения и переоценки обеспечивают точное, контекстно-зависимое обнаружение в статьях, видео и архивах.",media_short:"СМИ",misc:"Дальновидные пионеры",misc_description:"Организации, охватывающие сферу образования, сельского хозяйства, недвижимости и т. д., используют гибкие решения Jina AI для очистки, извлечения и преобразования данных в масштабе. Используя наш передовой стек нейронного поиска, они открывают новые возможности и остаются впереди в своих областях.",misc_short:"Другие",technology:"Новаторы-новаторы в области технологий",technology_description:"Лидеры в области программного обеспечения, облака, ИИ и данных полагаются на решения нейронного поиска Jina AI для поддержки своих систем поиска на основе LLM, RAG и агентов ИИ. Наши передовые считыватели, встраивания, рераннеры, небольшие LM помогают им быстрее, чем когда-либо, перейти от POC к корпоративной готовности.",technology_short:"Технологический"},sefo:{layer0:"Приложения для конечных пользователей",layer1:"РАГ / оркестровка",layer3:"Графический процессор / мобильные / периферийные / локальные вычисления"},segmentFaultCaption:"Сделал единовременное пожертвование в размере 6000 долларов.",show_position:"Как искать фундаментальные позиции в экосистеме?",stats_1:"Компания Jina AI, основанная в феврале 2020 года, быстро стала мировым пионером в области мультимодальных технологий искусственного интеллекта. В течение впечатляющих 20 месяцев мы успешно привлекли 37,5 млн долларов, что подтверждает нашу сильную позицию в индустрии искусственного интеллекта. Наша новаторская технология с открытым исходным кодом на GitHub позволила более чем 40 000 разработчиков по всему миру беспрепятственно создавать и развертывать сложные мультимодальные приложения.",stats_2:"В 2023 году мы добились значительных успехов в совершенствовании инструментов создания ИИ, основанных на мультимодальных технологиях. Эта инновация принесла пользу более чем 250 000 пользователей по всему миру, удовлетворяя множество уникальных бизнес-требований. От содействия росту бизнеса и повышения операционной эффективности до оптимизации затрат — Jina AI стремится помочь компаниям преуспеть в эпоху мультимодальных перевозок.",stats_4:'Основанная в 2020 году, Jina AI является ведущей компанией в области поискового ИИ. Наша платформа <span class="text-primary text-bold">Search Foundation</span> объединяет Embeddings, Rerankers и Small Language Models, чтобы помочь компаниям создавать надежные и высококачественные приложения GenAI и мультимодального поиска.',stats_v1:"Поиск/акк",subtitle:"Революционное создание контента с помощью решений, созданных на основе искусственного интеллекта, чтобы открыть безграничные возможности. Формирование будущего контента, созданного искусственным интеллектом, и расширение человеческого творчества.",sues_und_sauer:"Süẞ & Sauer",sues_und_sauer_tooltip:"Süß-Sauer, популярный (хотя и стереотипный) вкус в немецко-китайской кухне, означает сладкий и кислый. Это метафора взлетов и падений стартап-жизни.",sunnyvale_address:"710 Lakeway Dr, Ste 200, Саннивейл, Калифорния 94085, США",sz:"Шэньчжэнь, Китай",sz_address:"402, этаж 4, здание Fu'an Technology, Шэньчжэнь, Китай",team:"Внутри портала Джины ИИ",team_content1:"Из разных уголков земного шара мы строим будущее искусственного интеллекта. Наши различные точки зрения обогащают нашу работу, порождая инновации. На этом портале мы раскрываем свою индивидуальность и страстно преследуем свои мечты. Добро пожаловать на портал будущего искусственного интеллекта.",team_join:"Присоединяйтесь к нам",team_size:"На этих фотографиях — наши бывшие коллеги и стажеры — мы ценим каждого из них.",technologies:"Технологии",title:"О Джине А.И.",title0:"Будущее",title1:"Старт",title2:"Здесь",title3:"начинается здесь",understand_our_strength:"Поймите нашу силу",understand_our_view2:"Понимание Фонда Поиска",users:"Пользователи зарегистрированы",value:"Наши награды",value_content1:"Мы не останавливаемся. Мы не идем на компромисс. Мы стремимся к совершенству.",vision:"Наша миссия",vision_content1:"Вдохновленный выводом Яна Лекуна о том, что «",vision_content3:'Будущее искусственного интеллекта — <span class="text-primary text-bold">мультимодальное</span>, и мы являемся его частью. Мы понимаем, что предприятия сталкиваются с проблемами при использовании мультимодальных данных. В ответ мы стремимся к тому, чтобы <span class="text-primary text-bold">Search Foundation</span> помогал предприятиям и разработчикам лучше осуществлять поиск и использовать мультимодальные данные для развития бизнеса.',yannlecun_quote:"Система искусственного интеллекта, обученная только словам и предложениям, никогда не приблизится к человеческому пониманию."},i={answer1:"Да, тот же ключ API действителен для всех продуктов search foundation от Jina AI. Это включает в себя API считывателя, встраивания, переранжирования, классификации и тонкой настройки, с общими токенами для всех сервисов.",answer10:"Это происходит потому, что наша архитектура Serverless выгружает определенные модели в периоды низкого использования. Первоначальный запрос активирует или «разогревает» модель, что может занять несколько секунд. После этой первоначальной активации последующие запросы обрабатываются гораздо быстрее.",answer12:"Мы придерживаемся строгой политики конфиденциальности и не используем данные пользовательского ввода для обучения наших моделей. Мы также соответствуем требованиям SOC 2 Type I и Type II, обеспечивая высокие стандарты безопасности и конфиденциальности.",answer3:"Да, использование токенов можно отслеживать на вкладке «API Key & Billing», введя свой API-ключ, что позволит вам просматривать недавнюю историю использования и оставшиеся токены. Если вы вошли в панель управления API, эти данные также можно просмотреть на вкладке «Manage API Key».",answer4:"Если вы потеряли пополненный ключ и хотите его восстановить, обратитесь в службу поддержки AT jina.ai, указав зарегистрированный адрес электронной почты, чтобы получить помощь. Рекомендуется войти в систему, чтобы ваш ключ API был надежно сохранен и легко доступен.",answer5:"Нет, наши ключи API не имеют срока действия. Однако, если вы подозреваете, что ваш ключ был скомпрометирован, и хотите его удалить, обратитесь в нашу службу поддержки за помощью. Вы также можете отозвать свой ключ в <a class='text-primary' href='https://jina.ai/api-dashboard'>панели управления ключами API</a>.",answer6:"Да, вы можете перенести токены с одного премиум-ключа на другой. После входа в свою учетную запись на <a class='text-primary' href='https://jina.ai/api-dashboard'>панели управления ключами API</a> используйте настройки ключа, который вы хотите перенести, чтобы переместить все оставшиеся оплаченные токены.",answer7:"Да, вы можете отозвать свой ключ API, если считаете, что он был скомпрометирован. Отзыв ключа немедленно отключит его для всех пользователей, которые его сохранили, а весь оставшийся баланс и связанные с ним свойства станут навсегда непригодными для использования. Если ключ является премиум-ключом, у вас есть возможность перевести оставшийся оплаченный баланс на другой ключ перед отзывом. Обратите внимание, что это действие нельзя отменить. Чтобы отозвать ключ, перейдите к настройкам ключа на <a class='text-primary' href='https://jina.ai/api-dashboard'>панели управления ключами API</a>.",question1:"Могу ли я использовать один и тот же ключ API для чтения, встраивания, переранжирования, классификации и тонкой настройки API?",question10:"Почему первый запрос для некоторых моделей выполняется медленно?",question12:"Используются ли входные данные пользователя для обучения ваших моделей?",question3:"Могу ли я отслеживать использование токена моего ключа API?",question4:"Что мне делать, если я забуду свой ключ API?",question5:"Срок действия ключей API истекает?",question6:"Могу ли я передавать токены между ключами API?",question7:"Могу ли я отозвать свой ключ API?",title:"Общие вопросы, связанные с API"},t={base_model:"Базовая модель для доводки",check_data:"Скачать синтетические данные",check_model:"Скачать доработанную модель",data_size:"Созданы синтетические данные",description:"Получите точно настроенные встраивания для любого желаемого домена.",description_long:"Просто сообщите нам, в каком домене вы хотите, чтобы ваши внедрения преуспели, и мы автоматически предоставим готовую к использованию, точно настроенную модель внедрения для этого домена.",does_it_work_tho:"Но работает ли это?",does_it_work_tho_explain:"Автоматическая точная настройка дает волшебное обещание предоставить точно настроенные встраивания для любого домена, который вы захотите. Но действительно ли это работает? Это вполне обоснованное сомнение. Чтобы выяснить это, мы протестировали его на различных доменах и базовых моделях. Посмотрите результаты, собранные вишнями и лимонами ниже.",domain_instruction:"Инструкция домена",embedding_provider:"Выберите базовую модель внедрения",eval_evaluation:"Проверка",eval_map:"КАРТА",eval_mrr:"МРР",eval_ndcg:"НДЦГ",eval_performance_before_after:"Производительность при синтетической проверке, установленной до и после тонкой настройки",eval_syntheticDataSize:"Общий",eval_test:"Реальные данные для тестирования",eval_training:"Обучение",faq_v1:{answer1:"Эта функция в настоящее время находится на стадии бета-тестирования и стоит 1 миллион токенов за каждую настроенную модель. Вы можете использовать существующий ключ API из API внедрения/переранжирования, если в нем достаточно токенов, или вы можете создать новый ключ API, который включает 1 миллион бесплатных токенов.",answer10:"В данный момент нет. Обратите внимание, что эта функция все еще находится в стадии бета-тестирования. Публичное хранение точно настроенных моделей и синтетических данных в центре моделей Hugging Face помогает нам и сообществу оценить качество обучения. В будущем мы планируем предложить вариант частного хранения.",answer11:"Поскольку все доработанные модели загружаются в Hugging Face, вы можете получить к ним доступ через SentenceTransformers, просто указав имя модели.",answer12:"Пожалуйста, проверьте папку со спамом. Если вы все еще не можете его найти, свяжитесь с нашей службой поддержки, используя указанный вами адрес электронной почты.",answer2:"Вам не нужно предоставлять какие-либо данные для обучения. Просто опишите свой целевой домен (домен, для которого вы хотите оптимизировать точно настроенные внедрения) на естественном языке или используйте URL-адрес в качестве ссылки, и наша система сгенерирует синтетические данные для обучения модели.",answer3:"Около 30 минут.",answer4:"Точно настроенные модели и синтетические данные хранятся публично в хабе моделей Hugging Face.",answer5:"Система использует API Reader для получения контента по URL-адресу. Затем он анализирует контент, чтобы обобщить тон и предметную область, которые он использует в качестве ориентиров для создания синтетических данных. Следовательно, URL-адрес должен быть общедоступным и представлять целевой домен.",answer6:"Да, вы можете настроить модель для языка, отличного от английского. Система автоматически определяет язык инструкций вашего домена и соответствующим образом генерирует синтетические данные. Мы также рекомендуем выбрать подходящую базовую модель для целевого языка. Например, если вы ориентируетесь на немецкий домен, вам следует выбрать jina-embeddings-v2-base-de в качестве базовой модели.",answer7:"Нет, наш API тонкой настройки поддерживает только модели Jina v2.",answer8:"В конце процесса точной настройки система оценивает модель с использованием отложенного набора тестов и сообщает показатели производительности. Вы получите электронное письмо с подробным описанием производительности до и после этого набора тестов. Вам также рекомендуется оценить модель на собственном тестовом наборе, чтобы убедиться в ее качестве.",answer9:"Система генерирует синтетические данные путем интеграции предоставленных вами инструкций целевой области с рассуждениями агентов LLM. Он создает жесткие отрицательные триплеты, которые необходимы для обучения высококачественных моделей внедрения. Для получения более подробной информации, пожалуйста, обратитесь к нашему предстоящему исследованию Arxiv.",question1:"Сколько стоит API тонкой настройки?",question10:"Могу ли я сохранить конфиденциальность своих точно настроенных моделей и синтетических данных?",question11:"Как я могу использовать доработанную модель?",question12:"Я так и не получил письмо с результатами оценки. Что я должен делать?",question2:"Что мне нужно ввести? Нужно ли мне предоставлять данные обучения?",question3:"Сколько времени занимает доводка модели?",question4:"Где хранятся доработанные модели?",question5:"Если я предоставлю ссылочный URL-адрес, как система его будет использовать?",question6:"Могу ли я точно настроить модель для конкретного языка?",question7:"Могу ли я точно настроить встраивания, отличные от Jina, например, bge-M3?",question8:"Как вы обеспечиваете качество доработанных моделей?",question9:"Как генерировать синтетические данные?",title:"Распространенные вопросы, связанные с автоматической точной настройкой"},find_on_hf:"Список доработанных моделей",temporarily_unavailable:"Временно недоступен. Мы модернизируем нашу систему автоматической настройки, чтобы лучше обслуживать вас. Пожалуйста, зайдите позже.",test_on:"Протестировано на случайных выборках {_dataSize} из {_dataName}.",test_performance_before_after:"Производительность на продолжительном тестовом наборе до и после тонкой настройки",title:"API автоматической точной настройки",total_improve:"Среднее улучшение",usage:"Применение",what_is:"Что такое автоматическая точная настройка?",what_is_answer_long:"Точная настройка позволяет вам взять предварительно обученную модель и адаптировать ее к конкретной задаче или предметной области, обучая ее на новом наборе данных. На практике поиск эффективных обучающих данных не является простой задачей для многих пользователей. Для эффективного обучения требуется нечто большее, чем просто добавление в модель необработанных PDF-файлов и HTML-файлов; и это трудно сделать правильно. Автоматическая точная настройка решает эту проблему, автоматически генерируя эффективные обучающие данные с помощью расширенного конвейера агентов LLM; и точная настройка модели в рамках рабочего процесса машинного обучения. Вы можете рассматривать это как комбинацию генерации синтетических данных и AutoML, поэтому все, что вам нужно сделать, это описать целевой домен на естественном языке, а наша система сделает все остальное."},r={auth_required:"Для использования генерации аватара требуется аутентификация",classificationError:"Ошибка классификации изображения. Попробуйте еще раз.",clickToDownload:"Нажмите, чтобы загрузить SVG",customize:"Настроить функции",description:"Создавайте уникальные аватары с настраиваемыми функциями",downloadError:"Ошибка загрузки аватара",downloadSuccess:"Аватар успешно загружен",download_success:"Аватар успешно загружен",error_loading:"Не удалось загрузить аватары. Попробуйте еще раз.",error_processing:"Ошибка обработки изображения",file_hint:"Поддерживаемые форматы: JPG, PNG, GIF, WebP",generate:"Создать аватар",how_does_it_work:"Как это работает?",noImageSelected:"Сначала выберите изображение.",select_file:"Выберите файл портретного изображения",title:"Генератор аватаров",upload_description:"Выберите изображение для преобразования в base64 (256x256)",upload_title:"Загрузить изображение",usage:"Генерация Аватара"},o={description:"Блог на баннере, без подсказок!",example_description:"Алиса начинала очень уставать сидеть рядом с сестрой на берегу и от нечего делать: раз или два она заглядывала в книгу, которую читала сестра, но в ней не было ни картинок, ни разговоров, «а что толку в книге, — думала Алиса, — без картинок и разговоров?» И вот она размышляла про себя (как могла, потому что жаркий день вызывал у нее сонливость и глупость), стоит ли удовольствие плести маргаритку труда встать и сорвать маргаритки, как вдруг рядом с ней пробежал Белый Кролик с розовыми глазами.",example_title:"Приключения Алисы в стране чудес - Глава 1"},s="Бета",_={answer10:"Мы предлагаем новым пользователям приветственную бесплатную пробную версию, которая включает один миллион токенов для использования с любой из наших моделей, чему способствует автоматически сгенерированный ключ API. Как только лимит бесплатных токенов будет достигнут, пользователи смогут легко приобрести дополнительные токены для своих ключей API через вкладку «Купить токены».",answer13:"Нет, токены не снимаются за неудачные запросы.",answer14:"Платежи обрабатываются через Stripe, поддерживающий для вашего удобства различные способы оплаты, включая кредитные карты, Google Pay и PayPal.",answer15:"Да, после покупки токенов на адрес электронной почты, связанный с вашей учетной записью Stripe, будет выставлен счет.",answer9:"Наша модель ценообразования основана на общем количестве обработанных токенов, что позволяет пользователям гибко распределять эти токены по любому количеству предложений, предлагая экономически эффективное решение для разнообразных требований к анализу текста.",question10:"Доступна ли бесплатная пробная версия для новых пользователей?",question13:"Взимаются ли токены за неудачные запросы?",question14:"Какие способы оплаты принимаются?",question15:"Доступно ли выставление счетов за покупку токенов?",question9:"Выставление счетов зависит от количества предложений или запросов?",title:"Общие вопросы, связанные с выставлением счетов"},d={all:"Все",events:"Событие",featured:"Избранное",insights:"Мнение","knowledge-base":"База знаний",latest:"Последний",press:"пресс-релиз",releases:"Обновление программного обеспечения","tech-blog":"Технический блог"},c={caption:"Откройте для себя «Re·Search» — наш великолепно оформленный ежегодник, в котором представлены наши лучшие исследовательские статьи и модели фундаментальных исследований за 2024 год.",order_now:"Заказать сейчас"},l={api_free_trial:"Бесплатный API-ключ",api_paid:"Платный API-ключ",api_paid_or_free:"Используете ли вы платный ключ API или бесплатный пробный ключ?",are_you:"Ты:",commercial_contact_sales:"Это коммерческое предложение. Свяжитесь с нашим отделом продаж.",contact_sales_for_licensing:"Для получения лицензии свяжитесь с нашим отделом продаж.",csp_user:"Используете ли вы наши официальные образы моделей в AWS и Azure?",educational_teaching:"Образовательное учреждение, использующее его для обучения?",for_profit_internal_use:"Коммерческая компания, использующая его для внутренних целей?",free_use:"Вы можете свободно использовать модели.",government_public_services:"Государственное учреждение использует его для оказания государственных услуг?",is_use_commercial:"Является ли Ваше использование коммерческим?",may_be_commercial_contact:"Это может быть коммерческим. Пожалуйста, свяжитесь с нами для уточнения.",no:"Нет",no1:"Нет",no2:"Нет",no3:"Нет",no_restrictions:"Никаких ограничений. Используйте согласно текущему соглашению.",no_restrictions_apply:"Ограничения не применяются.",non_commercial_free_use:"Это некоммерческое использование. Вы можете использовать модели свободно.",non_profit_ngo_mission:"Некоммерческая или неправительственная организация использует его для своей миссии?",not_sure:"Не уверен",personal_hobby_projects:"Используете ли вы его для личных или любительских проектов?",product_service_sale:"Используете ли вы его в продаваемом вами продукте или услуге?",title:"Самостоятельная проверка лицензии CC BY-NC",trial_key_restrictions:"Бесплатный пробный ключ можно использовать только в некоммерческих целях. Для коммерческого использования приобретите платный пакет.",typically_non_commercial_check:"Обычно это некоммерческое использование, но если вы не уверены, свяжитесь с нами.",typically_non_commercial_free_use:"Это обычно некоммерческое использование. Вы можете свободно использовать модели.",using_api_or_cloud:"Используете ли вы наш официальный API или официальные образы на Azure или AWS?",using_cc_by_nc_models:"Используете ли вы эти модели?",yes:"Да",yes1:"Да",yes2:"Да",yes3:"Да"},p={access:"Публичный доступ",access_explain:"Публичные классификаторы могут использоваться любым человеком с <code>classifier_id</code>, и их использование будет потреблять квоту токенов вызывающего, а не вашу. Частные классификаторы доступны только вам.",access_private:"Частный",access_public:"Публичный",api_delete:"Удалить классификатор",api_delete_explain:"Удалить классификатор по его идентификатору.",api_list:"Список классификаторов",api_list_explain:"Перечислите все созданные вами классификаторы.",classifier_id:"Идентификатор классификатора",classify_inputs:"Входные данные для классификации",classify_inputs_explain:"Для текста это может быть предложение длиной до 8192 токенов. Для изображений это может быть URL или изображение в кодировке base64.",classify_labels:"Кандидатские ярлыки",classify_labels_explain:"Входные данные будут категоризированы по этим меткам. Может быть до 256 классов. Используйте семантические метки для лучшей производительности.",compare_table:{access_control:"Контроль доступа",classifier_id_required:"Требуется идентификатор классификатора",continuous_updates:"Непрерывные обновления модели",default_solution:"Решение по умолчанию для общей классификации",feature:"Особенность",few_shot:"Несколько выстрелов",image_multi_lingual_support:"Мультимодальная и многоязычная поддержка",labels_required_classify:"Метки, необходимые в /classify",labels_required_train:"Метки, необходимые в /train",max_classes:"Максимальное количество классов",max_classifiers:"Максимальные классификаторы",max_inputs_request:"Максимальное количество входов на запрос",max_token_length:"Максимальная длина токена на вход",na:"Н/Д",no:"Нет",out_of_domain_solution:"Для данных за пределами домена v3/clip-v1 или чувствительных ко времени данных",primary_use_case:"Основной вариант использования",semantic_labels_required:"Требуются семантические метки",state_management:"Государственное управление",stateful:"С сохранением состояния",stateless:"Без гражданства",token_count:"{count} жетонов",training_data_required:"Требуются данные для обучения",yes:"Да",zero_shot:"Нулевой выстрел"},create_classifier:"Новый малокадровый классификатор",create_classifier_explain:"Создайте новый классификатор с несколькими результатами и обучите его с помощью маркированных примеров.",description:"Классификация изображений и текста по нулевому и небольшому количеству кадров.",description_long:"Попробуйте нашу площадку API, чтобы увидеть, как работает наш классификатор.",description_long1:"Высокопроизводительный классификатор с нулевым и малым числом выборок для мультимодальных и многоязычных данных.",explain:"Классификатор — это API-сервис, который классифицирует текст и изображения с использованием моделей встраивания (<code>jina-embeddings-v3</code> и <code>jina-clip-v1</code>), поддерживая как классификацию с нуля без обучающих данных, так и обучение с несколькими попытками и минимальным количеством примеров.",faq_v1:{answer1:"Zero-shot требует семантических меток во время классификации и ничего во время обучения, в то время как few-shot требует меток во время обучения, но не классификации. Это означает, что zero-shot лучше подходит для гибких, немедленных потребностей в классификации, в то время как few-shot лучше подходит для фиксированных, специфичных для домена категорий, которые могут меняться со временем.",answer10:"Да, вы можете выбрать между <code>jina-embeddings-v3</code> для классификации текста (особенно хорошо для многоязычных) и <code>jina-clip-v1</code> для мультимодальной классификации. Новые модели, такие как <code>jina-clip-v2</code>, будут автоматически доступны через API после выпуска.",answer2:"<code>num_iters</code> контролирует интенсивность обучения — более высокие значения усиливают важные примеры, а более низкие значения минимизируют влияние менее надежных данных. Его можно использовать для внедрения обучения с учетом времени, предоставляя недавним примерам более высокие числа итераций, что делает его ценным для развивающихся шаблонов данных.",answer3:"Публичные классификаторы могут использоваться любым человеком с <code>classifier_id</code>, потребляя собственную квоту токенов. Пользователи не могут получить доступ к данным обучения или конфигурации и не могут видеть запросы классификации других, что позволяет безопасно делиться классификаторами.",answer4:"Few-shot требует 200-400 обучающих примеров, чтобы превзойти классификацию zero-shot. Хотя в конечном итоге он достигает более высокой точности, ему необходим этот период разминки, чтобы стать эффективным. Zero-shot обеспечивает постоянную производительность немедленно без обучающих данных.",answer5:"Да — API поддерживает многоязычные запросы с использованием <code>jina-embeddings-v3</code> и мультимодальную (текст/изображение) классификацию с использованием <code>jina-clip-v1</code>, с поддержкой URL или изображений в кодировке base64 в одном запросе.",answer6:"Zero-shot поддерживает 256 классов без ограничения по классификаторам, в то время как few-shot ограничен 16 классами и 16 классификаторами. Оба поддерживают 1024 входа на запрос и 8192 токена на вход.",answer7:"Режим Few-shot позволяет непрерывно обновлять конечную точку <code>/train</code> для адаптации к изменяющимся шаблонам данных. Вы можете постепенно добавлять новые примеры или классы при изменении распределения данных, не перестраивая весь классификатор.",answer8:"API использует однопроходное онлайн-обучение — обучающие примеры обновляют веса классификатора, но не сохраняются после этого. Это означает, что вы не можете извлечь исторические обучающие данные, но это обеспечивает конфиденциальность и эффективность ресурсов.",answer9:"Начните с нулевого выстрела для немедленных результатов и когда вам нужна гибкая классификация с семантическими метками. Переключитесь на несколько выстрелов, когда у вас 200-400 примеров, нужна более высокая точность или вам нужно обрабатывать доменно-зависимые/временные данные.",question1:"Чем отличаются метки в нулевом и малом количестве снимков?",question10:"Могу ли я использовать разные модели для разных языков/задач?",question2:"Для чего нужен num_iters и как его использовать?",question3:"Как работает публичный обмен классификаторами?",question4:"Сколько данных мне нужно для эффективной работы метода few-shot?",question5:"Может ли он обрабатывать несколько языков и текст/изображения?",question6:"О каких жестких ограничениях мне следует знать?",question7:"Как обрабатывать изменения данных с течением времени?",question8:"Что происходит с моими тренировочными данными после их отправки?",question9:"Нулевой или малый выстрел — когда какой использовать?",title:"Общие вопросы, связанные с классификатором"},more:"более",num_iters:"Итерации обучения",num_iters_explain:"Контролирует интенсивность обучения — более высокие значения повышают точность на текущих примерах, но увеличивают стоимость токена. Значение по умолчанию 10 обычно работает хорошо.",read_notes:"Прочитать примечания к выпуску",select_classifier_or_model:"Выберите классификатор или модель внедрения",task_classify:"Классифицировать",task_classify_explain:"Используйте классификатор с нулевым или малым числом повторов для классификации текста или изображений по определенным классам.",task_manage:"Управлять",task_manage_explain:"Перечислите или удалите несколько классификаторов.",task_select:"Выберите задачу",task_train:"Тренироваться",task_train_explain:"Создайте или обновите классификатор из нескольких снимков с помеченными примерами.",title:"API классификатора",train_inputs:"Данные обучения",train_inputs_explain:"Примеры текста или изображений с метками для обучения. Вы можете постепенно обновлять классификатор новыми примерами и метками с течением времени.",train_label:"Этикетка",what_is:"Что такое классификатор?",when_to_use_what:"Когда использовать «ноль выстрелов» или «несколько выстрелов»?",when_to_use_what_explain:"Используйте классификацию с нулевым числом повторов в качестве решения по умолчанию для получения немедленных результатов в общих задачах классификации с использованием до 256 классов, в то время как обучение с малым числом повторов лучше подходит при работе с данными, относящимися к предметной области, за пределами знаний моделей внедрения или когда вам необходимо обрабатывать чувствительные ко времени данные, требующие постоянного обновления модели."},u={description:"Встраивайте изображения и предложения в векторы фиксированной длины с помощью CLIP"},m={description:"Платформа облачного хостинга для мультимодальных приложений ИИ"},g={agreement:"Отправляя заявку, вы подтверждаете свое согласие на обработку ваших персональных данных компанией Jina AI, как описано в",anything_else:"Расскажите нам больше о своей идее",cc_by_nc:"Запросить коммерческое использование моделей CC BY-NC",cc_by_nc_description:"Наши последние модели обычно имеют лицензию CC BY-NC. Для коммерческого использования получите к ним доступ через наш API, Azure Marketplace или AWS SageMaker. Установите этот флажок для локального использования за пределами этих каналов.",company:"Организация",company_size:"Размер организации",company_website:"Сайт организации",company_website_placeholder:"URL-адрес домашней страницы вашей компании или профиля LinkedIn.",country:"Страна",department:"Отделение",description:"Развивайте свой бизнес с Jina AI.",drop_area_for_image:"Перетащите сюда свои изображения",faq:"Часто задаваемые вопросы",feedback_sent:"Отправлено! Мы свяжемся с вами в ближайшее время.",field_required:"Поле, обязательное для заполнения",get_api_key:"Как получить мой ключ API?",image_upload:"Прикрепить изображения",image_validate:"Вы можете прикрепить до {_num} изображений. Только JPG, JPEG, PNG, WEBP.",impact_snapshots:"Моментальные снимки воздействия",invalid_date_format:"Неверный формат даты. Пожалуйста, используйте формат ДД-ММ-ГГГГ.",invalid_email:"Электронная почта недействительна",invalid_number:"Неправильный номер. Пожалуйста, введите еще раз",invalid_url:"URL-адрес недействителен",name:"Имя",nc_check:"Нужна ли мне коммерческая лицензия?",other_questions:"Другие вопросы",preferred_models:"Какие модели вас интересуют?",preferred_products:"Какие продукты вас интересуют?",pricing:"Цены?",priority:"Приоритетная поддержка для платных пользователей",private_statement:"Заявление о конфиденциальности",rate_limit:"Каков предел ставки?",role:"Роль работы",self_check:"Самопроверка",sending_feedback:"Отправка...",shortcut:"Ярлык",submit:"Представлять на рассмотрение",submit_failed:"Отправка не удалась. Пожалуйста, повторите попытку позже.",submit_success:"Спасибо за ваш вклад. Мы скоро к тебе вернемся.",subtitle:"Jina AI, лидер в области мультимодального ИИ, преуспевает в настройке моделей, обслуживании моделей, настройке подсказок и подсказках. Используя облачные технологии, такие как Kubernetes и бессерверные архитектуры, мы предоставляем надежные, масштабируемые и готовые к работе решения. Имея опыт работы с крупными языковыми моделями, текстом, изображениями, видео, аудио, нейронным поиском и генеративным искусством, мы предлагаем инновационные, ориентированные на будущее стратегии для развития вашего бизнеса.",subtitle1:"Jina AI, лидер в области мультимодального искусственного интеллекта, превосходно справляется с настройкой внедрения, обслуживанием внедрения, быстрой настройкой и быстрым обслуживанием. Используя облачные технологии, такие как Kubernetes, и бессерверные архитектуры, мы предоставляем надежные, масштабируемые и готовые к использованию решения. Обладая опытом в области больших языковых моделей, понимания текста, изображений, видео, аудио, нейронного поиска и генеративного искусственного интеллекта, мы предлагаем инновационные, перспективные стратегии для развития вашего бизнеса.",subtitle2:"Исследуйте Jina AI, передовую разработку мультимодального искусственного интеллекта. Мы преуспеваем во внедрении и оперативном использовании технологий, используя облачные решения, такие как Kubernetes, для создания надежных и масштабируемых систем. Специализируясь на больших языковых моделях и обработке мультимедиа, мы предлагаем инновационные, перспективные бизнес-стратегии, основанные на нашем передовом опыте в области искусственного интеллекта.",title:"Связаться с отделом продаж",trusted_by:"Нам доверяют",turn_on_volume:"Увеличьте громкость",work_email:"Рабочий адрес электронной почты"},h="Копировать",b="Скопировано в буфер обмена",A={description:"Рабочий процесс «человек в цикле» для создания HD-изображений из текста."},k={api_endpoint:"Конечная точка API",api_key:"API-ключ",api_tagline:"Полностью совместим со схемой API чата OpenAI, просто замените <code>chat.openai.com</code> на <code>deepsearch.jina.ai</code>, чтобы начать.",api_title:"API глубокого поиска",assistant_message:"Помощник",chat_ui:{clear_context_message:"Вы уверены, что хотите очистить контекст? Это сбросит разговор.",clear_context_title:"Новый чат?",description:"Проверка Vibe с помощью простого пользовательского интерфейса чата. DeepSearch лучше всего подходит для сложных вопросов, требующих итеративного рассуждения, знания мира или актуальной информации.",example_q1:"Какая последняя запись в блоге OpenAI?",example_q2:"Какова идея проекта node-deepresearch?",example_q3:"что именно jina-colbert-v2 улучшает по сравнению с jina-colbert-v1?",input_cant_be_empty:"Ввод не может быть пустым",input_placeholder:"Введите свой вопрос здесь",keyman:"Менеджер по ключевым вопросам",new_chat:"Очистить текущий чат и начать новый разговор",payment_required:"У вас недостаточно токенов в вашем ключе API. Если у вас несколько ключей API, вы можете переключиться на тот, у которого достаточно токенов в менеджере ключей. В противном случае вы можете пополнить свой ключ API, чтобы продолжить.",purchase:"Пополнить API-ключ",thinking:"Думаю...",thinking_done:"Цепочка мыслей",title:"Чат DeepSearch"},client_3p:"Интеграция клиента",client_3p_explain:"DeepSearch полностью совместим со схемой API чата OpenAI. DeepSearch легко использовать с любым чат-клиентом, совместимым с OpenAI.",comparison:{group1:{bestFor:"Быстрые ответы на вопросы общего уровня знаний",feature1:"Ответы генерируются исключительно на основе предварительно обученных знаний с фиксированной датой окончания.",limitations:"Невозможно получить доступ к информации в режиме реального времени или после обучения",timeCost:"около 1с",title:"Стандартные LLM",tokenCost:"около 1000 токенов"},group2:{bestFor:"Вопросы, требующие актуальной или специфической для предметной области информации",feature1:"Ответы, полученные путем суммирования результатов однократного поиска",feature2:"Может получить доступ к текущей информации после окончания обучения",limitations:"Проблемы со сложными вопросами, требующими многоэтапного рассуждения",timeCost:"около 3с",title:"RAG и обоснованные LLM",tokenCost:"около 10 000 токенов"},group3:{bestFor:"Сложные вопросы, требующие тщательного исследования и рассуждения",feature1:"Автономный агент, который итеративно ищет, читает и рассуждает",feature2:"Динамично принимает решения о следующих шагах на основе текущих результатов",feature3:"Самостоятельно оценивает качество ответа перед возвращением результатов",feature4:"Может выполнять глубокое погружение в темы посредством множественных циклов поиска и рассуждений.",limitations:"Занимает больше времени, чем простые подходы LLM или RAG",timeCost:"около 50-х",title:"Глубокий поиск",tokenCost:"около 500 000 токенов"}},demo:"Чат с DeepSearch",demo_description:"Проверка Vibe с помощью простого пользовательского интерфейса чата. DeepSearch лучше всего подходит для сложных вопросов, требующих итеративного рассуждения, знания мира или актуальной информации.",description:"Ищите, читайте и рассуждайте, пока не найдете лучший ответ.",explain:"DeepSearch объединяет веб-поиск, чтение и рассуждения для всестороннего исследования. Представьте его как агента, которому вы даете исследовательское задание — он проводит обширный поиск и проходит несколько итераций, прежде чем предоставить ответ. Этот процесс включает в себя непрерывное исследование, рассуждения и подход к проблеме с разных сторон. Это принципиально отличается от стандартных LLM, которые генерируют ответы непосредственно из предварительно обученных данных, и от традиционных систем RAG, которые полагаются на одноразовые поиски на поверхностном уровне.",faq:{answer1:"DeepSearch — это API LLM, который выполняет итеративный поиск, чтение и рассуждения до тех пор, пока не найдет точный ответ на запрос или не достигнет лимита бюджета токенов.",answer10:"Ограничения скорости зависят от уровня ключа API и составляют от 10 RPM до 30 RPM. Это важно учитывать для приложений с большим объемом запросов.",answer11:"DeepSearch оборачивает шаги мышления в теги XML <think>...</think> и затем предоставляет окончательный ответ, следуя формату потоковой передачи OpenAI, но с этими специальными маркерами для цепочки мыслей.",answer12:"Да. Jina Reader используется для веб-поиска и чтения, предоставляя системе возможность эффективного доступа и обработки веб-контента.",answer14:"Да, использование токенов DeepSearch в сложных запросах, возможно, высоко — в среднем 70 000 токенов по сравнению с 500 для базовых ответов LLM. Это показывает глубину исследования, но также имеет финансовые последствия.",answer18:"Система в первую очередь контролируется бюджетом токенов, а не количеством шагов. После превышения бюджета токенов она переходит в режим Beast Mode для генерации окончательного ответа. Проверьте <code>reasoning_effort</code> для получения более подробной информации.",answer19:"Ссылки считаются настолько важными, что если ответ считается окончательным, но не имеет ссылок, система продолжает поиск, а не принимает ответ.",answer2:"В отличие от OpenAI и Gemini, DeepSearch специально фокусируется на предоставлении точных ответов посредством итерации, а не на создании длинных статей. Он оптимизирован для быстрых, точных ответов из глубокого веб-поиска, а не для создания всесторонних отчетов.",answer20:"Да, но с обширными этапами исследования. Пример «кто будет президентом в 2028 году» показывает, что он может обрабатывать спекулятивные вопросы посредством нескольких итераций исследования, хотя точность таких прогнозов не гарантируется.",answer3:"Вам нужен ключ API Jina. Мы предлагаем 1M бесплатных токенов для новых ключей API.",answer5:"Он генерирует окончательный ответ на основе всех накопленных знаний, а не просто отказывается от ответа или возвращает неполный ответ.",answer6:"Нет. Хотя для повышения точности используется итеративный процесс поиска, оценка показывает, что он достигает 75%-ного процента успешных ответов на тестовых вопросах, что значительно лучше базового показателя в 0% (gemini-2.0-flash), но не идеально.",answer7:"Он значительно варьируется - запросы могут занимать от 1 до 42 шагов, в среднем 4 шага на основе данных оценки. Это 20 секунд. Простые запросы могут быть решены быстро, в то время как сложные исследовательские вопросы могут включать много итераций и до 120 секунд.",answer9:"Да, официальный API DeepSearch по адресу deepsearch.jina.ai/v1/chat/completions полностью совместим со схемой API OpenAI, используя 'jina-deepsearch-v1' в качестве имени модели. Поэтому очень легко переключиться с OpenAI на DeepSearch и использовать с локальными клиентами или любым клиентом, совместимым с OpenAI. Мы настоятельно рекомендуем Chatwise для бесперебойного опыта.",question1:"Что такое DeepSearch?",question10:"Каковы ограничения скорости для API?",question11:"Каково содержимое тега <think>?",question12:"Использует ли DeepSearch Jina Reader для веб-поиска и чтения?",question14:"Почему DeepSearch использует так много токенов для моих запросов?",question18:"Есть ли способ контролировать или ограничивать количество шагов?",question19:"Насколько надежны ссылки в ответах?",question2:"Чем DeepSearch отличается от возможностей глубоких исследований OpenAI и Gemini?",question20:"Может ли DeepSearch обрабатывать вопросы о будущих событиях?",question3:"Какой ключ API мне нужен для использования DeepSearch?",question5:"Что происходит, когда DeepSearch достигает своего бюджета токенов? Возвращает ли он неполный ответ?",question6:"Гарантирует ли DeepSearch точные ответы?",question7:"Сколько времени занимает типичный запрос DeepSearch?",question9:"Может ли DeepSearch работать с любым совместимым с OpenAI клиентом, таким как Chatwise, CherryStudio или ChatBox?",title:"Распространенные вопросы, связанные с DeepSearch"},high_explain:"Максимальное обоснование и поиск сложных запросов (2 млн токенов/запрос)",low_explain:"Базовые рассуждения и поиск простых запросов (макс. 500 тыс. токенов/запрос)",medium_explain:"Умеренная глубина рассуждений и поиска (1 млн токенов/запрос)",message:"Сообщение",messages:"Сообщения",messages_explain:"Список сообщений между пользователем и помощником, составляющих беседу на данный момент.",model:"Модель",model_explain:"Идентификатор используемой модели.",model_name:"Название модели",open:"Открыть",reasoning_effort:"Усилие по рассуждению",reasoning_effort_explain:"Ограничивает усилия по рассуждению для моделей рассуждений. В настоящее время поддерживаются значения low, medium и high. Уменьшение усилий по рассуждению может привести к более быстрым ответам и меньшему количеству токенов, используемых для рассуждений в ответе.",stream:"Потоковое вещание",stream_explain:"Если значение равно true, возвращает поток событий, происходящих во время выполнения в качестве событий, отправленных сервером, завершающийся, когда выполнение переходит в конечное состояние с сообщением data: [DONE].",tagline:"@:deepsearch.description",title:"Глубокий поиск",user_message:"Пользователь",what_is:"Что такое DeepSearch?"},I={description:"Создавайте привлекательные произведения искусства Disco Diffusion в одной строке кода"},v={description:"Структура данных для мультимодальных данных"},P="Загрузить аттестацию SOC 2 Type 1",w={"11B tokens":"11 миллиардов","11B tokens_intuition1":"Это похоже на чтение всех англоязычных статей в Википедии.","11B tokens_targetUser":"Развертывание производства","1B tokens":"1000000000","1B tokens_intuition1":"Примерно то же самое, что читать полное собрание сочинений Шекспира и всю серию «Гарри Поттер».","1B tokens_targetUser":"Разработка прототипа","1M tokens":"1 миллион","1M tokens_intuition1":"Эквивалентно прочтению всего текста «Хоббита» и «Великого Гэтсби».","1M tokens_targetUser":"Игрушечный эксперимент","1M_free":"1 миллион бесплатных токенов","1M_free_description":"Наслаждайтесь новым ключом API с бесплатными токенами, кредитная карта не требуется.","2_5B tokens":"2,5 млрд токенов","2_5B tokens_intuition1":`Это сравнимо с 1000-кратной расшифровкой каждого слова, сказанного в трилогии «Властелин колец».
`,"3p_integration":"С помощью <b>{_numPartners}</b> сторонних сервисов","3p_integration_desc":"Интегрируйте нашу базу поиска с существующими службами. Наши партнеры создали коннекторы для нашего API, что упрощает использование наших моделей в ваших приложениях.","500M tokens":"500 миллионов токенов","500M tokens_intuition1":"Аналогично просмотру каждой серии «Симпсонов» с 1 по 30 сезон.","59B tokens":"59B токенов","59B tokens_intuition1":"Равно всем твитам, опубликованным по всему миру за двухдневный период.","5_5B tokens":"5,5 млрд токенов","5_5B tokens_intuition1":"Эквивалентно чтению всего текста Британской энциклопедии.",Free1M:"1 млн токенов","ReaderLM-v2_description":"Небольшая языковая модель для преобразования сырого HTML в markdown или JSON",add_pair:"Новый",add_time_explain:"Дата добавления данной модели в Search Foundation.",api_integration_short:"Наш API для встраивания изначально интегрирован с различными известными базами данных, векторными хранилищами, платформами RAG и LLMOps.",api_integrations:"API-интеграция",api_key_update_message:"Заменив старый ключ API, новый ключ будет отображаться в пользовательском интерфейсе всякий раз, когда вы посещаете jina.ai. Будущие пополнения будут применяться к этому новому ключу. Ваш старый ключ остается действительным, поэтому, если вы планируете использовать его снова, пожалуйста, сохраните его в надежном месте.",api_key_update_title:"Замена ключа API",auto_recharge:"Автоматическое пополнение при низком балансе токенов",auto_recharge_confirm_message:"Вы уверены, что хотите отключить автоматическое пополнение? Это остановит автоматическое пополнение, когда баланс ваших токенов низок, и может прервать работу вашего сервиса или приложения.",auto_recharge_confirm_title:"Отключить автоматическое пополнение",auto_recharge_description:"Рекомендуется для бесперебойной работы в производстве. Когда баланс вашего токена опустится ниже установленного порога, мы автоматически пополним ваш сохраненный способ оплаты за последний приобретенный пакет, пока порог не будет достигнут.",auto_recharge_enable:"Вы включили автоматическое пополнение при низком уровне токенов",auto_recharge_enable_message:"Чтобы включить функцию автоматического пополнения, приобретите пакет, в котором для функции автоматического пополнения установлено значение true.",auto_recharge_enable_message2:"Выберите пакет, который будет приобретен при срабатывании функции автоматического пополнения баланса.",auto_recharge_enable_title:"Включить автоматическое пополнение",auto_request:"Автоматический предварительный просмотр",auto_request_tooltip:"Автоматически просматривайте ответ API при изменении модели, используя сотни токенов из вашего ключа API. Отключите отправку запроса вручную, нажав «Получить ответ».",autostart:"Встраивание начнется автоматически после небольшой задержки.",base64_description:"Вложения возвращаются в виде строки в кодировке Base64. Более эффективен для передачи.",batch_job:"Пакетное задание",batch_upload_hint:"Мы будем использовать ключ API и модель ниже для обработки документов.","bge-base-en-v1_5_description":"Надежная английская модель, сочетающая в себе производительность и эффективность для универсального использования.","bge-base-en_description":"Сбалансированная английская модель, созданная для прочной и надежной работы.","bge-base-zh-v1_5_description":"Всесторонняя китайская модель, сочетающая в себе возможности и эффективность.","bge-base-zh_description":"Универсальная китайская модель, сочетающая в себе эффективность и надежность.","bge-large-en-v1_5_description":"Мощная английская модель, предлагающая первоклассные встраиваемые системы исключительного качества.","bge-large-en_description":"Высокопроизводительная английская модель, созданная для встраивания премиум-класса.","bge-large-zh-v1_5_description":"Высокопроизводительная китайская модель с превосходными и детальными встраиваниями.","bge-large-zh_description":"Высокопроизводительная китайская модель, оптимизированная для встраивания высшего уровня.","bge-m3_description":"Универсальная многоязычная модель, предлагающая широкие возможности и высококачественные встраивания.","bge-small-en-v1_5_description":"Оптимизированная английская модель, обеспечивающая эффективное и высококачественное встраивание.","bge-small-en_description":"Эффективная английская модель для упрощенного и точного встраивания.","bge-small-zh-v1_5_description":"Компактная китайская модель, обеспечивающая маневренность и точность встраивания.","bge-small-zh_description":"Гибкая китайская модель для эффективного и точного встраивания.",binary_description:"Вложения упакованы как int8. Гораздо эффективнее для хранения, поиска и передачи.",bulk:"Пакетное встраивание",bulk_embedding_failed:"Не удалось создать задание пакетного внедрения.",buy_more_quota:"Пополните этот ключ API дополнительными токенами",buy_poster:"Купить бумажную копию",cancel_button:"Отмена",click_upload_btn_above:"Нажмите кнопку загрузки выше, чтобы начать.",clip_v2_description:"jina-clip-v2 — это модель в стиле CLIP размером 0,9 Б, которая обеспечивает три основных преимущества: многоязыковую поддержку 89 языков, высокое разрешение изображений 512x512 и обучение представлению «матрешка» для усеченных вложений.",clip_v2_title:"clip-v2: Многоязычные мультимодальные вложения",code:"код",colbert_dimensions_explain:"Размер измерения вложения на токен.",compatible:"Совместимый режим",compatible_explain:"Соответствует тому же формату запроса, что и наши модели встраивания текста. Это позволяет переключаться между моделями без изменения запроса. Обратите внимание, что в этом режиме не поддерживается ввод изображений.",cosine_similarity:"Косинусное подобие",debugging:"Тест",delete_pair:"Удалить",description:"@:landing_page.embedding_desc1",dimensions:"Размеры вывода",dimensions_error:"Размер измерения должен быть в диапазоне от 1 до 1024.",dimensions_explain:"Меньшие размеры обеспечивают эффективное хранение и извлечение с минимальным воздействием благодаря представлению в виде матрешки.",dimensions_warning:"Для повышения производительности мы рекомендуем поддерживать размер измерения выше {_minDimension}.",document:"Документ",download:"Скачать",edit_text1_text:"Редактировать левый текст",edit_text2_text:"Редактировать правильный текст",embedding_done:"Предложений успешно внедрено: {_Count}.",embedding_none_description:"Не используйте никакую модель внедрения",example_inputs:"Пример входных данных",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"Подробную информацию о наших процессах обучения, источниках данных и оценках можно найти в нашем техническом отчете, доступном на arXiv.",answer1:"Jina CLIP <code>jina-clip-v2</code> — это усовершенствованная модель мультимодального встраивания, которая поддерживает задачи поиска текст-текст, текст-изображение, изображение-изображение и изображение-текст. В отличие от оригинального OpenAI CLIP, который испытывает трудности с поиском текст-текст, Jina CLIP преуспевает в качестве извлекателя текста. <code>jina-clip-v2</code> обеспечивает повышение производительности на 3% по сравнению с <code>jina-clip-v1</code> в задачах поиска текст-изображение и текст-текст, поддерживает 89 языков для многоязычного поиска изображений, обрабатывает изображения с более высоким разрешением (512x512) и снижает требования к хранению с помощью представлений Matryoshka. Подробнее об этом можно прочитать в нашем техническом отчете.",answer17:"Да, <code>jina-clip-v2</code> и <code>jina-clip-v1</code> могут встраивать как изображения, так и тексты. Скоро будет объявлено о встраивании моделей в большем количестве модальностей!",answer18:"По вопросам точной настройки наших моделей с использованием конкретных данных свяжитесь с нами, чтобы обсудить ваши требования. Мы открыты для изучения того, как наши модели могут быть адаптированы к вашим потребностям.",answer19:"Да, наши услуги доступны на торговых площадках AWS, Azure и GCP. Если у вас есть особые требования, свяжитесь с нами по адресу sales AT jina.ai.",answer3:"На момент выпуска 18 сентября 2024 года <code>jina-embeddings-v3</code> является лучшей многоязычной моделью и занимает 2-е место в рейтинге MTEB English для моделей с менее чем 1 миллиардом параметров. v3 поддерживает в общей сложности 89 языков, включая 30 лучших с лучшей производительностью: арабский, бенгальский, китайский, датский, голландский, английский, финский, французский, грузинский, немецкий, греческий, хинди, индонезийский, итальянский, японский, корейский, латышский, норвежский, польский, португальский, румынский, русский, словацкий, испанский, шведский, тайский, турецкий, украинский, урду и вьетнамский. Более подробную информацию см. в техническом отчете <code>jina-embeddings-v3</code>.",answer4:"Наши модели допускают длину ввода до 8192 токенов, что значительно больше, чем у большинства других моделей. Токен может быть от одного символа, например «a», до целого слова, например «apple». Общее количество символов, которые можно ввести, зависит от длины и сложности используемых слов. Эта расширенная возможность ввода позволяет нашим моделям <code>jina-embeddings-v3</code> и <code>jina-clip</code> выполнять более полный анализ текста и достигать более высокой точности в понимании контекста, особенно для обширных текстовых данных.",answer5:"Один вызов API может обрабатывать до 2048 предложений или текстов, что позволяет выполнить обширный анализ текста за один запрос.",answer6:"Вы можете использовать либо <code>url</code>, либо <code>bytes</code> в поле <code>input</code> запроса API. В поле <code>url</code> укажите URL-адрес изображения, которое вы хотите обработать. Для <code>bytes</code> закодируйте изображение в формате base64 и включите его в запрос. Модель вернет вложения изображения в ответ.",answer7:"В оценках на бенчмарках MTEB English, Multilingual и LongEmbed <code>jina-embeddings-v3</code> превосходит новейшие фирменные вложения от OpenAI и Cohere на задачах на английском языке и превосходит <code>multilingual-e5-large-instruct</code> на всех многоязычных задачах. С выходным измерением по умолчанию 1024 пользователи могут урезать измерения вложения до 32 без ущерба для производительности благодаря интеграции Matryoshka Representation Learning (MRL).",answer8:"Переход оптимизирован, так как <a class='text-primary' href='https://api.jina.ai/v1/embeddings'>наша конечная точка API</a> соответствует входным и выходным схемам JSON модели OpenAI <code>text-embedding-3-large</code>. Эта совместимость гарантирует, что пользователи могут легко заменить модель OpenAI на нашу при использовании конечной точки OpenAI.",answer9:`Токены рассчитываются на основе длины текста и размера изображения. Для текста в запросе токены подсчитываются стандартным образом. Для изображений выполняются следующие шаги:

1. Размер плитки: каждое изображение делится на плитки. Для <code>jina-clip-v2</code> плитки имеют размер 512x512 пикселей, а для <code>jina-clip-v1</code> — 224x224 пикселя.
2. Покрытие: вычисляется количество плиток, необходимых для покрытия входного изображения. Даже если размеры изображения не делятся на размер плитки, частичные плитки считаются полными плитками.
3. Общее количество плиток: общее количество плиток, покрывающих изображение, определяет стоимость. Например, изображение размером 600x600 пикселей будет покрыто плитками 2x2 (4 плитки) в v2 и плитками 3x3 (9 плиток) в v1.
4. Расчет стоимости: для <code>jina-clip-v2</code> каждая плитка стоит 4000 токенов, а для <code>jina-clip-v1</code> каждая плитка стоит 1000 токенов.

Пример:
Для изображения с размерами 600x600 пикселей:

• С <code>jina-clip-v2</code>
• Изображение делится на плитки размером 512x512 пикселей.
• Общее количество требуемых плиток составляет 2 (по горизонтали) x 2 (по вертикали) = 4 плитки.
• Стоимость для <code>jina-clip-v2</code> составит 4*4000 = 16000 токенов.

• С <code>jina-clip-v1</code>
• Изображение делится на плитки размером 224x224 пикселей.
• Общее количество требуемых плиток составляет 3 (по горизонтали) x 3 (по вертикали) = 9 плиток.
• Стоимость jina-clip-v1 составит 9*1000 = 9000 токенов.`,question0:"Как обучались модели jina-embeddings-v3?",question1:"Что такое модели jina-clip и можно ли их использовать для поиска текста и изображений?",question17:"Предоставляете ли вы модели для встраивания изображений или аудио?",question18:"Можно ли точно настроить модели Jina Embedding с использованием частных данных или данных компании?",question19:"Могут ли ваши конечные точки размещаться в частном порядке на AWS, Azure или GCP?",question3:"Какие языки поддерживают ваши модели?",question4:"Какова максимальная длина ввода одного предложения?",question5:"Какое максимальное количество предложений я могу включить в один запрос?",question6:"Как отправить изображения моделям jina-clip?",question7:"Как модели Jina Embeddings соотносятся с новейшими встраиваниями OpenAI и Cohere?",question8:"Насколько плавным будет переход от text-embedding-3-large от OpenAI к вашему решению?",question9:"Как рассчитываются токены при использовании моделей jina-clip?",title:"Общие вопросы, связанные с встраиваниями"},feature_8k1:"длина токена 8192",feature_8k_description1:"Впервые появилась первая модель внедрения с открытым исходным кодом длиной 8192 токена, позволяющая представить всю главу в одном векторе.",feature_cheap:"в 20 раз дешевле",feature_cheap_v1:"в 5 раз дешевле",feature_cheap_v1_description1:"Начните с бесплатных пробных версий и наслаждайтесь простой структурой ценообразования. Получите доступ к мощным встроенным компонентам всего за 20 % от стоимости OpenAI.",feature_multilingual:"Предлагает двуязычные модели для немецкого-английского, китайского-английского и других языков, идеально подходящие для межъязыковых приложений.",feature_on_premises:"Конфиденциальность прежде всего",feature_on_premises_description1:"Легко развертывайте наши модели внедрения непосредственно в своем виртуальном частном облаке (VPC). В настоящее время поддерживается на AWS Sagemaker, в ближайшее время будет реализована интеграция с Microsoft Azure и Google Cloud Platform. Для индивидуального развертывания Kubernetes обратитесь в наш отдел продаж за специализированной помощью.",feature_on_premises_description2:"Развертывайте модели Jina Embeddings в AWS Sagemaker, а вскоре и в Microsoft Azure и Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов.",feature_on_premises_description3:"Развертывайте модели Jina Embeddings в AWS Sagemaker и Microsoft Azure, а вскоре и в Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов.",feature_on_premises_description4:"Развертывайте модели Jina Embedding и Reranker локально с помощью AWS SageMaker, Microsoft Azure или облачных сервисов Google, гарантируя, что ваши данные останутся под вашим контролем.",feature_solid:"Лучшие в своем классе",feature_solid_description1:"Разработано на основе передовых научных исследований и тщательно протестировано на соответствие моделям SOTA, чтобы обеспечить непревзойденную производительность.",feature_top_perform1:"Бесшовная интеграция",feature_top_perform_description1:"Полностью совместим с API OpenAI. Легко интегрируется с более чем 10 векторными базами данных и системами RAG, обеспечивая удобство работы с пользователем.",file_required:"Требуется файл",file_size_exceed:"Превышен максимальный размер файла {_size}",file_type_not_supported:"Тип файла не поддерживается",fill_example:"Заполните пример",float_description:"Вложения возвращаются в виде списка чисел с плавающей запятой. Самый распространенный и простой в использовании.",free:"Бесплатно",generate_api_key_error:"Не удалось создать ключ API.",generating_visualization:"Создание визуализации...",get_new_key_button:"Получить новый ключ",get_new_key_button_explain:"Выбор нового ключа приведет к потере истории использования, связанной со старым ключом.",get_new_key_survey:"Заполните опрос, помогите нам понять ваше использование и получите новый ключ API бесплатно!",includes:"Токены действительны для:",index_and_search:"Индекс и поиск",index_and_search1:"Индекс и поиск",input:"Запрос",input_api_key_error1:"Ваш ключ API недействителен!",input_length:"Входная длина",input_type:"Встроить как документ/запрос",input_type_explain:"Одни и те же входные данные могут служить как запросом, так и внедрением документа, в зависимости от их поисковой роли.",integrate:"Интегрировать","jina-clip-v1_description":"Мультимодальные модели встраивания для изображений и английского текста","jina-clip-v2_description":"Многоязычные мультимодальные вложения для текстов и изображений","jina-colbert-v1-en_description":"Улучшенный ColBERT с длиной токена 8 КБ для внедрения и изменения ранжирования задач.","jina-colbert-v2_description":"Лучший многоязычный ColBERT с высочайшей производительностью при встраивании и переоценке","jina-embedding-b-en-v1_description":"Первая версия модели Jina Embedding, OG.","jina-embeddings-v2-base-code_description":"Оптимизирован для поиска кода и строки документации.","jina-embeddings-v2-base-de_description":"Немецко-английские двуязычные встраивания с производительностью SOTA","jina-embeddings-v2-base-en_description":"На одном уровне с text-embedding-ada002 от OpenAI.","jina-embeddings-v2-base-es_description":"Двуязычные встраивания на испанском и английском языках с производительностью SOTA","jina-embeddings-v2-base-zh_description":"Китайско-английское двуязычное встраивание с производительностью SOTA","jina-embeddings-v2-small-en_description":"Оптимизирован для низкой задержки и использования памяти.","jina-embeddings-v3_description":"Модель многоязыкового встраивания Frontier с производительностью SOTA","jina-reranker-v1-base-en_description":"Наша первая модель реранкера, максимизирующая поиск и релевантность RAG.","jina-reranker-v1-tiny-en_description":"Самая быстрая модель реранжирования, лучше всего подходящая для надежного ранжирования большого количества документов.","jina-reranker-v1-turbo-en_description":"Лучшее сочетание быстрой скорости вывода и точных оценок релевантности.","jina-reranker-v2-base-multilingual_description":"Новейшая и лучшая модель реранкера с многоязычной поддержкой вызова функций и поиска кода.",key:"API-ключ",key_enter_placeholder:"Пожалуйста, введите свой ключ API",key_enter_placeholder_to_topup:"Введите ключ API, который вы хотите пополнить.",key_to_top_up:"Хотите пополнить счет другим ключом API? Вставьте его выше и нажмите «Сохранить».",key_warn:"Обязательно сохраните ключ API в безопасном месте. В противном случае вам нужно будет сгенерировать новый ключ.",key_warn_v2:"Это ваш уникальный ключ. Храните его в надежном месте!",language_explain:"Эта модель лучше всего поддерживает язык {_language}.",last_7_days:"Использование",late_chunking:"Позднее дробление",late_chunking_explain:"Примените метод позднего фрагментирования, чтобы использовать возможности длинного контекста модели для генерации контекстных внедрений фрагментов.",learn_more:"Узнать больше",learn_poster:"Узнайте, как мы это сделали",learning1:"Изучение вложений",learning1_description:"С чего начать встраивание? Мы вас прикроем. Узнайте о встраиваниях с нуля с помощью нашего подробного руководства.",length:"Длина токена",manage_billing:"Управление счетом",manage_billing_tip:"Управляйте своей платежной информацией, получайте счета и настраивайте автоматическое пополнение счета.",manage_quota1:"Ключ API и биллинг",max_file_size:"Максимально допустимый размер: {_maxSize}.",maximize_tooltip:"Разверните эту панель с помощью Shift+1",mistake_contact:"Если вы считаете, что это ошибка, свяжитесь с нами.",mminput_placeholder:"Текст, URL-адрес изображения, строка base64 изображения",model_required:"Требуется модель",more_models:"{_numMore} больше моделей",more_than_two2:"Пожалуйста, введите более двух документов, т.е. более двух строк.",multi_embedding:"Многовекторный",multi_embedding_explain:"Эта модель вернет пакет контекстуализированных вложений для данного ввода. Каждый токен на входе сопоставляется с вектором на выходе.",multilingual:"Многоязычная поддержка",multimodal:"Мультимодальный",multimodal_explain:"Эта модель может кодировать как текстовые, так и графические входные данные, что делает ее идеальной для задач мультимодального поиска.",new:"Новая модель",no_data1:"Добавьте пару предложений, чтобы вычислить сходство.",none:"Никто",normalized:"Нормализация L2",normalized_explain:"Масштабирует вложение так, что его евклидова (L2) норма становится 1, сохраняя направление. Полезно, когда нисходящий поток включает скалярное произведение, классификацию, визуализацию.",oncsp:"На CSP",onprem:"Локально",open_tensorboard:"Открыть визуализатор",opensource:"Операционные системы",opensource_explain:"Эта модель имеет открытый исходный код и доступна на Hugging Face. Нажмите эту кнопку, чтобы просмотреть модель на Hugging Face.",original_documents:"Предложения для вставки",original_documents_hint:"Введите сюда свои предложения. Каждая новая строка будет считаться отдельным предложением/документом.",output:"Ответ",output_dim:"Размеры",output_dim_explain:"Выходная размерность вектора внедрения из этой модели — {_outputDim}.",output_dimension:"Выходные размеры",pairwise_test:"Попарно",per_k:"/ 1 тыс. токенов",per_m:"/ 1 млн токенов",please_fill_docs_first:"Пожалуйста, сначала введите несколько предложений ниже, прежде чем искать.",please_select_model:"Пожалуйста, выберите модель внедрения или модель реранкера",poster:"Плакат «Эволюция вложений»",poster_description:"Откройте для себя идеальный плакат для вашего помещения с увлекательной инфографикой или захватывающими визуальными эффектами, прослеживающими эволюцию моделей встраивания текста с 1950 года.",pricing:"Цены на API",pricing_desc:"Цены на API основаны на использовании токена. Один ключ API дает вам доступ ко всем продуктам Search Foundation.",protectData1:"Данные запроса и документы не используются для обучения моделей.",protectData2:"Шифрование данных при передаче (TLS 1.2+) и при хранении (AES-GCM 256).",protectData3:"Соответствует SOC 2 и GDPR.",protect_data:"Защитите свои данные",public_cloud_integration:"С <b>{_numPartners}</b> поставщиками облачных услуг",public_cloud_integration_desc:"Ваша компания использует AWS или Azure? Затем напрямую разверните наши модели базы поиска на этих платформах в вашей компании, чтобы ваши данные оставались в безопасности и соответствовали требованиям.",query:"Запрос",raise_issue:"Поднять вопрос",rank_none_description:"Не используйте модели реранкера",read_api_docs:"Спецификация API",read_release_note:"Прочитать примечание к выпуску","reader-lm-05b_description":"Небольшая языковая модель для преобразования сырого HTML в разметку","reader-lm-15b_description":"Небольшая языковая модель для преобразования сырого HTML в разметку",recharge_threshold:"Порог пополнения",refresh:"Обновить",refresh_key_tooltip1:"Получите новый ключ API бесплатно",refresh_token_count1:"Обновите, чтобы получить доступные токены текущего ключа API.",regenerate:"Регенерировать",remaining:"Доступные токены",remaining_left:"У вас осталось <b>{_leftTokens}</b> токенов в ключе API, указанном ниже.",request_number:"Запрос времени",request_path:"Запрос конечной точки",results_as_final_result:"#docs как конечный результат",results_fed_to_reranker:"#docs переданы в программу реранкинга",retry:"Повторить попытку",return_base64:"Base64 (как строка)",return_binary:"Двоичный (упакованный как int8)",return_float:"По умолчанию (как плавающее значение)",return_format:"Формат встраивания",return_format_explain:"Помимо числа с плавающей запятой, вы можете попросить его вернуть двоичный формат для более быстрого поиска векторов или кодировку Base64 для более быстрой передачи.",return_format_title:"Возвращаемый тип данных",return_ubinary:"Двоичный (упакованный как uint8)",right_api_key_to_charge:"Пожалуйста, введите правильный ключ API для пополнения счета.",running:"Активный",score:"Счет",search:"Поиск",search_hint:"Введите текст для поиска в предложениях, перечисленных ниже",select_classify_model:"Выберите классификатор",select_embedding_model:"Выберите вложения",select_rerank_model:"Выберите средство изменения рейтинга",show_api_key:"Показать ключ API",size:"Параметры",size_explain:"Количество параметров в модели — {_size}. Обратите внимание, что это не размер файла модели.",sleeping:"Неактивный",start_batch:"Начать пакетное внедрение",start_embedding:"Индекс",status_explain:"Наша бессерверная архитектура может разгружать определенные модели в периоды низкой нагрузки. Для активных моделей реакция немедленная. Неактивным моделям требуется несколько секунд для загрузки после первоначального запроса. После активации последующие запросы обрабатываются быстрее.",task_type:"Задача ниже по течению",task_type_classification:"Классификация",task_type_classification_explain:"Классификация текста.",task_type_explain:"Выберите задачу ниже по потоку, для которой будут использоваться вложения. Модель вернет оптимизированные вложения для этой задачи.",task_type_none_explain:"Адаптер не будет использоваться. Будет возвращено общее вложение, полезное для отладки или взлома.",task_type_retrieval_passage:"Проход для извлечения",task_type_retrieval_passage_explain:"Внедрение документов в задачу поиска документов по запросу.",task_type_retrieval_query:"Запрос на поиск",task_type_retrieval_query_explain:"Встраивание запросов в задачу поиска документов по запросу.",task_type_separation:"Разделение",task_type_separation_explain:"Кластеризация документов, визуализация корпуса.","task_type_text-matching":"Сопоставление текста","task_type_text-matching_explain":"Семантическое сходство текста, общий симетрический поиск, рекомендация, поиск похожего, дедупликация.",tax_may_apply:"В зависимости от вашего местоположения с вас может взиматься плата в долларах США, евро или других валютах. Могут взиматься налоги.",text1:"Левый",text2:"Верно",three_ways:"Три способа покупки",three_ways_desc:"Оформите подписку на наш API, приобретите его у поставщиков облачных услуг или получите коммерческую лицензию для своей организации.",title:"Встраивание API",token_example:"Твит стоит около 20 токенов, новостная статья — около 1000 токенов, а роман Чарльза Диккенса «Повесть о двух городах» — более миллиона токенов.",token_length_explain:"Максимальная длина входной последовательности токенов – {_tokenLength} для этой модели.",tokens:"Токены",tools:"Инструменты",top_up_button:"Пополнить старый ключ",top_up_button_explain:"Интеграция этого ключа API предлагает более профессиональное решение, устраняющее необходимость частой смены ключа. Данные об использовании сохраняются и доступны в любое время.",top_up_warning_message1:"В текущем ключе API осталось токенов {_remainedTokens}, и он будет заменен новым ключом с токенами {_freeTokens}. Вы можете продолжать использовать или пополнять старый ключ, если сохранили его в надежном месте. Как вы хотите продолжить?",top_up_warning_title:"Заменить старый ключ API",total_documents:"Ход внедрения: {_Processed}/{_Count} предложений.",tuning:"Тонкая настройка",turnstile_error:"Мы не можем сгенерировать ключ API, поскольку не можем проверить, являетесь ли вы человеком.",turnstile_unsupported:"Мы не можем сгенерировать ключ API, поскольку ваш браузер не поддерживается.",ubinary_description:"Вложения упакованы как uint8. Гораздо эффективнее для хранения, поиска и передачи.",upload:"Загрузить",upload_file:"Нажмите здесь, чтобы загрузить файл",usage:"Применение",usage_amount:"Токены",usage_history:"Использование за последние 7 дней",usage_history_explain:"Данные не поступают в режиме реального времени и могут задерживаться на несколько минут.",usage_reason:"Описание",usage_reason_consume:"Использовал",usage_reason_purchase:"Куплено",usage_reason_transfer_in:"Перевод в",usage_reason_transfer_out:"Перевод из",usage_reason_trial:"Пробный",usage_rerank:"Применение",usage_time:"Дата время",v3_description:"<code>jina-embeddings-v3</code> — это передовая многоязычная модель встраивания текста с 570 млн параметров и длиной токена 8192, превосходящая последние фирменные встраивания от OpenAI и Cohere на MTEB. Прочитайте наш блог и исследовательскую работу ниже.",v3_title:"v3: Frontier Многоязычные Вложения",vector_database_integration1:"Интеграции",vector_database_integration2:"Наш API для встраивания изначально интегрирован с различными известными базами данных, векторными хранилищами, платформами RAG и LLMOps. Для начала просто скопируйте и вставьте свой ключ API в любую из перечисленных интеграций для быстрого и беспроблемного запуска.",vector_database_integration3:"Наш API для встраивания и переранжирования изначально интегрирован с различными известными базами данных, векторными хранилищами, платформами RAG и LLMOps. Для начала просто скопируйте и вставьте свой ключ API в любую из перечисленных интеграций для быстрого и беспроблемного запуска.",vector_database_integration_description:"Беспрепятственно и легко интегрируйте Jina Embeddings API с любой векторной базой данных, структурами оркестрации LLM и приложениями RAG, указанными ниже. Наши уроки покажут вам, как это сделать.",view_details:"Посмотреть детали",visualization_example:"Отображение всех предложений из этого раздела в трехмерном векторном пространстве.",visualization_example_you_can:"Используйте наш API ниже, вы тоже можете это сделать!",visualize:"Визуализируйте",visualize_done:"Визуализация завершена, теперь вы можете нажать верхнюю кнопку, чтобы открыть визуализатор.",wait_for_processing:"Ваш запрос обрабатывается.",wait_stripe:"Открытие платежа Stripe, пожалуйста, подождите",what_are_embedding:"Что такое вложения?",what_are_embedding_answer:`Представьте себе, что вы учите компьютер понимать нюансы значений слов и фраз. Традиционные методы, опиравшиеся на жесткие, основанные на правилах системы, потерпели неудачу, поскольку язык слишком сложен и изменчив. Введите встраивание текста: мощное решение, которое переводит текст на язык чисел, в частности, в векторы в многомерном пространстве.

Рассмотрим фразы «солнечная погода» и «ясное небо». Нам они рисуют аналогичную картину. Через призму вложений эти фразы преобразуются в числовые векторы, находящиеся близко друг к другу в этом многомерном пространстве, фиксируя их семантическое родство. Эта близость в векторном пространстве связана не только со схожестью слов или фраз; речь идет о понимании контекста, настроений и даже тонких смысловых нюансов.

Почему этот прорыв важен? Во-первых, он устраняет разрыв между богатством человеческого языка и вычислительной эффективностью алгоритмов. Алгоритмы превосходно обрабатывают цифры, а не интерпретируют тексты. Преобразуя текст в векторы, встраивания позволяют этим алгоритмам «понимать» и обрабатывать язык способами, которые ранее были недоступны.

Практическое применение обширно и разнообразно. Будь то рекомендация контента, который соответствует вашим интересам, активация диалогового искусственного интеллекта, который кажется удивительно человечным, или даже обнаружение тонких закономерностей в больших объемах текста, встраивание является ключевым моментом. Они позволяют машинам выполнять такие задачи, как анализ настроений, языковой перевод и многое другое, при этом понимание языка становится все более тонким и тонким.`,what_is_a_token:"Токен в обработке текста — это единица, часто слово. Например: «Джина ИИ великолепен!» становится пятью знаками, включая знаки препинания.",why_do_you_need:"Выбор правильных вложений",why_do_you_need_after:"Используя глубокие нейронные сети и LLM, наши модели внедрения представляют мультимодальные данные в оптимизированном формате, улучшая машинное понимание, эффективное хранение и позволяя использовать передовые приложения искусственного интеллекта. Эти внедрения играют решающую роль в понимании данных, повышении вовлеченности пользователей, преодолении языковых барьеров и оптимизации процессов разработки.",why_do_you_need_before:"Наши модели внедрения предназначены для охвата разнообразных приложений поиска и GenAI.",why_need_1_description:"Наша базовая модель внедрения, основанная на JinaBERT, создана для широкого спектра приложений. Он превосходно понимает подробный текст, что делает его идеальным для семантического поиска, классификации контента и сложного языкового анализа. Его универсальность не имеет себе равных: он поддерживает создание передовых инструментов анализа настроений, обобщения текста и систем персонализированных рекомендаций.",why_need_1_title:"Вложения общего назначения",why_need_2_description:"Наши двуязычные модели облегчают общение на разных языках, расширяя возможности многоязычных платформ, глобальную поддержку клиентов и обнаружение межъязыкового контента. Эти модели, предназначенные для освоения немецко-английского и китайско-английского переводов, упрощают взаимодействие и способствуют взаимопониманию между различными языковыми группами.",why_need_2_title:"Двуязычные встраивания",why_need_3_description:"Наша модель внедрения кода, специально разработанная для разработчиков, оптимизирует такие задачи кодирования, как суммирование, генерация кода и автоматические проверки. Он повышает производительность, предлагая более глубокое понимание структур кода и предлагая улучшения, что делает его незаменимым для разработки расширенных плагинов IDE, автоматической документации и передовых инструментов отладки.",why_need_3_title:"Встраивание кода",why_need_4_description:"Jina CLIP — наша новейшая мультимодальная модель внедрения изображений и текста. Большим улучшением по сравнению с OpenAI CLIP является то, что эту единую модель можно использовать для извлечения текста-текста, а также задач извлечения текста-изображения, изображения-текста и изображения-изображения! Итак, одна модель, две модальности, четыре направления поиска!",why_need_4_title:"Мультимодальные вложения",write_email_here:"Пожалуйста, введите адрес электронной почты, на который вы хотите получить ссылку для скачивания после завершения.",you_can_leave:"Вы можете покинуть эту страницу, и после завершения мы вышлем вам ссылку для скачивания."},f={description:"Мультимодальные многоязычные вложения мирового класса."},y={contractType:{department:"Лицензия Департамента",poc:"Проверка концепции (3–6 месяцев)",standard:"Стандартная корпоративная лицензия",title:"Тип контракта"},department:{businessSponsor:"Спонсор бизнес-подразделения",executionModel:"Модель исполнения",growth:{high:"Ясный потенциал всего предприятия",highDesc:"Стратегическая инициатива с запланированным внедрением в масштабах всей компании",limited:"Ограничено Департаментом",limitedDesc:"Сосредоточьтесь на потребностях одного отдела со стандартной поддержкой",steady:"Потенциал для других отделов",steadyDesc:"Планируемое расширение до 2-3 отделов в течение 12 месяцев"},growthTitle:"Траектория роста",sponsorDescription:"Выделенный руководитель-спонсор, который поддерживает реализацию, обеспечивает стратегическое направление и обеспечивает распределение ресурсов"},descriptions:{contractType:{department:"Развертывание в рамках одного отдела с возможностью дальнейшего расширения",poc:"Пробное развертывание для тестирования моделей в вашей конкретной среде и вариантах использования",standard:"Полное корпоративное развертывание с неограниченным использованием модели"},department:{growth:"Планы по расширению использования модели в других департаментах",sponsorship:"Указывает, поддерживает ли развертывание отдел, приносящий доход"},features:{csm:"Персональный менеджер по работе с клиентами для стратегического руководства и поддержки",priority:"Гарантированно быстрое реагирование на критические проблемы",training:"Помощь с предварительной подготовкой или настройкой моделей для ваших конкретных данных"},models:{clip:"Обрабатывайте изображения и текст для мультимодальных приложений",colbert:"Специализированная модель для высокоточного поиска документов",embeddings:"Модель встраивания текста для семантического поиска и схожести текста",reader:"Преобразует HTML-контент в чистый формат markdown",reranker:"Тонкая настройка результатов поиска для лучшей релевантности"},payment:{annual:"Единовременный ежегодный платеж за упрощенный учет",quarterly:"Регулярные платежи каждые три месяца"},poc:{duration:"Временная шкала для тестирования и проверки производительности модели в вашей среде",metrics:"Отслеживайте ключевые показатели эффективности и эффективность модели"},support:{enterprise:"Полная поддержка с наивысшим приоритетом",premium:"Дополнительные часы консультаций и более быстрое время ответа",standard:"Базовая техническая поддержка и руководство по внедрению"},usage:{business:"Сколько различных предприятий будут использовать приложения, работающие на основе наших моделей?",consumer:"Сколько конечных пользователей будут взаимодействовать с нашими моделями ежемесячно?"}},features:{csm:"Выделенный менеджер по работе с клиентами",priority:"SLA с приоритетным ответом (4 часа)",title:"Дополнительные возможности",training:"Поддержка обучения по индивидуальной модели"},interests:"Меня интересует это настроенное коммерческое лицензирование (${_Price})",labels:{basePrice:"Базовая цена",custom:"Свяжитесь с отделом продаж для уточнения индивидуальных цен",discountApplied:"Скидка применяется",included:"Включено в базовую цену",learnMore:"Узнать больше",priceQuarterly:"Цена за квартал",selectAll:"Выбрать все модели",selectSupport:"Выберите уровень поддержки",totalPrice:"Общая стоимость",upTo:"До {количество}"},messaging:{additionalFeatures:"Дополнительные функции:",baseModelIncluded:"Включена базовая модель встраивания (jina-embeddings-v3)",deptIncludes:"Лицензия департамента включает в себя:",deptReviews:"Ежеквартальные встречи по обзору деловой активности",deptRoadmap:"Планирование дорожной карты расширения предприятия",deptSponsor:"Сессии по согласованию с исполнительным спонсором",deptWorkshops:"Семинары по межведомственному сотрудничеству",enterpriseAlert:"Ваш уровень использования предполагает возможность для всего предприятия. Давайте запланируем звонок, чтобы обсудить индивидуальное корпоративное соглашение.",noModelsSelected:"Дополнительные модели не выбраны. Используется базовая модель вложений.",pocCheckins:"Проверки дважды в неделю с технической командой",pocIncludes:"Пакет POC включает в себя:",pocMetrics:"Панель мониторинга показателей успеха",pocMigration:"Поддержка перехода на полную лицензию",pocTemplate:"Шаблон документации результатов POC",selectedModels:"Выбранные модели:",standardFeatures:"Возможности стандартной лицензии:",supportTierIncluded:"{tier} уровень поддержки включен {hours}",usageTierBusiness:"Уровень использования для бизнеса: до {count} бизнес-аккаунтов",usageTierConsumer:"Уровень использования потребителя: до {count} активных пользователей в месяц"},models:{clip:"jina-клип-v2",colbert:"джина-кольбер-v2",description:"Выберите модели для включения в ваш коммерческий пакет",embeddings:"jina-внедрения-v3",lm:"читатель-лм",reranker:"jina-reranker-v2",title:"Выбрать модели"},payment:{annual:"Ежегодная оплата (скидка 10%)",features:"Включенные функции",quarterly:"Ежеквартальное выставление счетов",title:"Условия оплаты"},poc:{description:"POC включает отслеживание показателей успеха и путь обновления до полной лицензии",duration:"Продолжительность POC (месяцы)"},pricing:{annual:"год",cta:"Поговорите с нашим отделом продаж",disclaimer:"Этот калькулятор цен дает оценку. Ваша окончательная цена может варьироваться в зависимости от конкретных требований, обязательств по объему и индивидуальных конфигураций. Свяжитесь с нашей командой по продажам для получения подробной сметы.",frequency:"${price} / {frequency}",oneTime:"${price} единоразово",pocTotal:"{months}-месячная цена POC: ${price}",quarterly:"четверть",title:"Предполагаемая цена"},short_title:"Конфигурация лицензии",subtitle:"Настройте корпоративную лицензию для моделей Jina AI",support:{enterprise:"Премиум",hoursQuarter:"{hours} часов/квартал",premium:"Стандарт",standard:"Лайт",title:"Уровень поддержки"},title:"Конфигуратор корпоративной лицензии",tooltips:{annualDiscount:"Сэкономьте 10%, оплачивая ежегодно",businessSponsor:"Наличие спонсора бизнес-подразделения может претендовать на дополнительные скидки.",pocDuration:"Выберите продолжительность периода проверки концепции",supportTier:"Выберите уровень поддержки, который наилучшим образом соответствует вашим потребностям",usageLimit:"Свяжитесь с нами для индивидуальной цены, если вы превышаете эти лимиты."},usage:{business:"B2B (Бизнес-аккаунты)",businessCount:"Количество бизнес-счетов",businessDescription:"Количество отдельных бизнес-аккаунтов, использующих наши модели",consumer:"B2C (Конечные пользователи)",consumerCount:"Ежемесячно активных пользователей",consumerDescription:"Количество активных конечных пользователей в месяц во всех приложениях",title:"Конфигурация использования"}},L={answer1:"Jina AI специализируется на мультимодальных технологиях искусственного интеллекта, включая настройку моделей, обслуживание моделей, настройку подсказок и обслуживание подсказок. Мы используем передовые инструменты, такие как Kubernetes и бессерверные архитектуры, для создания надежных, масштабируемых и готовых к работе решений.",answer10:"Мы предоставляем различные варианты лицензирования в зависимости от характера проекта и потребностей клиента. Подробные условия можно обсудить с нашим отделом продаж.",answer11:"Мы предоставляем услуги по всему миру, наша штаб-квартира находится в Берлине, Европа, а дополнительные офисы — в Пекине и Шэньчжэне.",answer12:"Да, мы предлагаем поддержку на месте, особенно для клиентов, находящихся рядом с нашими офисами в Берлине, Пекине и Шэньчжэне. В других местах мы стремимся обеспечить наилучшую удаленную поддержку и при необходимости можем организовать поддержку на месте.",answer2:"Наш опыт охватывает широкий спектр, включая большие языковые модели, текст, изображения, видео, понимание звука, нейронный поиск и генеративное искусство.",answer3:"Да, наши решения масштабируются и готовы к работе. Мы создаем наши решения с использованием облачных технологий, которые обеспечивают эффективное масштабирование и надежную работу в производственных средах.",answer4:"Наши услуги универсальны и адаптируемы, что делает их подходящими для широкого круга отраслей, включая электронную коммерцию, юридические технологии, цифровой маркетинг, игры, здравоохранение, финансы и многие другие.",answer5:"Вы можете связаться с нашим отделом продаж через контактную форму на этой странице. Мы хотели бы обсудить требования вашего проекта и то, как наши решения могут помочь вашему бизнесу.",answer6:"Мы предоставляем постоянную поддержку для обеспечения бесперебойной работы наших решений. Это включает в себя устранение неполадок, регулярные обновления и улучшения на основе ваших отзывов и потребностей.",answer7:"Продолжительность проекта варьируется в зависимости от сложности и объема проекта. После понимания ваших требований, мы можем предоставить более точную оценку.",answer8:"Безопасность данных является нашим главным приоритетом. Мы придерживаемся строгих политик и правил защиты данных, чтобы обеспечить безопасность и конфиденциальность ваших данных.",answer9:"Цена зависит от сложности проекта и требований. Мы предлагаем модели ценообразования как на основе проекта, так и на основе авансовых платежей. Пожалуйста, свяжитесь с нашим отделом продаж для получения дополнительной информации.",question1:"На чем специализируется Jina AI?",question10:"Каковы условия лицензирования ваших решений?",question11:"Какова ваша зона обслуживания?",question12:"Вы предлагаете поддержку на месте?",question2:"С какими типами ИИ работает Jina AI?",question3:"Ваши решения масштабируемы и готовы к работе?",question4:"Какие отрасли могут извлечь выгоду из решений Jina AI?",question5:"Как нам начать проект с Jina AI?",question6:"Какую поддержку вы оказываете после внедрения решения?",question7:"Какова типичная продолжительность проекта?",question8:"Как Jina AI защищает мои данные?",question9:"Какова структура ценообразования на ваши услуги?"},R="Часто задаваемые вопросы",M={text:"Прощание.",toggle_btn:"Оставьте эту панель открытой при следующем посещении.",warning_message:"Эта панель автоматически откроется при посещении jina.ai. Вам нужно будет закрыть ее, чтобы увидеть содержимое веб-сайта. Включить эту настройку?",warning_title:"Показывать при запуске"},x={description:"Точная настройка встраивания данных для конкретного домена для повышения качества поиска",intro:"Ваша компания. Ваши данные. Ваша модель"},S={description:"Расширьте возможности своего предприятия с помощью локальных решений для точной настройки"},q={api_key:"Введите свой ключ API.",back:"Назад",base_model_selected:"Выбрана базовая модель",click_start:"Согласитесь с условиями и приступайте к тонкой настройке.",confirm_title:"Подтвердить работу по тонкой настройке",confirm_your_email:"Повторно введите свой адрес электронной почты, чтобы подтвердить работу по тонкой настройке. Обновления и ссылка для скачивания будут отправлены на этот адрес электронной почты.",consent0:"Я согласен, что по моим инструкциям будут сформированы синтетические данные для тонкой настройки модели.",consent1:"Я подтверждаю, что окончательная модель и синтетические данные будут общедоступны на Hugging Face.",consent2:"Я понимаю, что эта функция находится в стадии бета-тестирования, и Jina AI не предоставляет никаких гарантий. Цены и UX могут измениться.",continue:"Продолжать",cost_1m_token:"Каждая работа по тонкой настройке потребляет 1 миллион токенов. Убедитесь, что у вас достаточно жетонов, или пополните свой баланс. Вы также можете создать новый ключ API. Каждый ключ API поставляется с 1 млн бесплатных токенов.",doc_explain:"Опишите, как должен выглядеть согласованный документ.",domain_explain:"Предоставьте подробное описание того, как будут использоваться точно настроенные встраивания. Это важно для создания высококачественных синтетических данных, которые улучшат производительность ваших внедрений.",domain_explain2:"Существует три способа указать ваше требование: общая инструкция, URL-адрес или описание запроса-документа. Выбери один.",domain_hint:"Опишите домен, для которого вы хотите выполнить точную настройку.",email_not_match:"Адреса электронной почты не совпадают. Пожалуйста, подтвердите.",failed_job:"Запрос на тонкую настройку не выполнен. См. причину ниже.",find_on_huggingface:"Найдите результаты на Hugging Face",general_instruction:"Или общая инструкция",general_instruction_caption:"Предоставьте подробное описание того, как будут использоваться точно настроенные встраивания.",general_instruction_explain:"Опишите свой домен в свободной форме. Вы можете представить это как «подсказку», как в ChatGPT.",how_it_works:"Узнайте о процессе тонкой настройки.",job_acknowledged:"Ваша работа по тонкой настройке поставлена ​​в очередь. Вы получите электронное письмо, когда задание начнется. Весь процесс часто занимает 20 минут.",new_key:"Получить новый ключ",not_enough_token:"Недостаточно токенов в этом ключе API. Пожалуйста, пополните свой баланс или используйте другой ключ API.",placeholder:"Претензии по страхованию автомобиля",preview:"Предварительный просмотр",query_doc:"Описание документа-запроса",query_doc_caption:"Опишите, как выглядит запрос и как выглядит соответствующий документ в вашем домене.",query_explain:"Опишите, как выглядит запрос.",reset:"Начать сначала",select_base_model:"Выберите базовую модель внедрения для тонкой настройки.",select_base_model_explain:"Выберите базовую модель в качестве отправной точки для тонкой настройки. Обычно хорошим выбором является base-en, но для задач на других языках рассмотрите возможность использования двуязычной модели.",start_tuning:"Начать тонкую настройку",url:"Или URL веб-страницы",url_caption:"Обратитесь к содержимому URL-адреса для точной настройки.",url_explain:"Публичный URL-адрес веб-страницы, содержащей контент, который вы хотите настроить.",use_url:"Вместо этого используйте URL-адрес. Включение этого параметра означает, что мы будем использовать содержимое страницы этого URL-адреса для создания синтетических данных для точной настройки.",wait_for_processing:"Пожалуйста подождите, пока мы обрабатываем ваш запрос...",which_domain:"Тонкая настройка домена",write_email_explain:"Точная настройка требует времени. Мы будем сообщать по электронной почте о начале, ходе, завершении и любых проблемах вашей работы по точной настройке, а также о подробностях точно настроенной модели и наборе обучающих данных."},C={address_beijing:"Пекин, Китай",address_berlin:"Берлин, Германия (штаб-квартира)",address_shenzhen:"Шэньчжэнь, Китай",address_sunnyvale:"Саннивейл, Калифорния",all_rights_reserved:"Все права защищены.",api_documentation:"API-документация",company:"Компания",developers:"Разработчики",docs:"Документы",enterprise:"Предприятие",get_api_key:"Получить API-ключ Jina",offices:"Офисы",power_users:"Опытные пользователи",privacy:"Конфиденциальность",privacy_policy:"политика конфиденциальности",privacy_settings:"Управление файлами cookie",security:"Безопасность",sefo:"Поиск Фонда",soc2:"Мы соответствуем требованиям SOC 2 Type 1 и 2 Американского института сертифицированных бухгалтеров (AICPA).",status:"Статус API",status_short:"Статус",tc:"Условия использования",tc1:"Условия"},j="Получите свой API-ключ",T={stars:"Звезды"},J={description:"Основные заявления с веб-знанием",title:"Проверка фактов",usage:"Использование заземления"},B={about_us:"О нас",api_docs:"API-документы",api_docs_explain:"Автоматическая генерация кода для вашего второго пилота IDE или LLM",company:"Компания",contact_us:"Связаться с отделом продаж",developers_others:"Дополнительные инструменты разработчика",enterprise_others:"Больше корпоративных инструментов",for_developers:"Для разработчиков",for_developers_description:"Испытайте комплексный стек мультимодального ИИ с открытым исходным кодом, разработанный для разработчиков.",for_enterprise:"Для предприятий",for_enterprise_description:"Откройте для себя масштабируемые мультимодальные стратегии искусственного интеллекта, адаптированные к потребностям бизнеса.",for_power_users:"Для опытных пользователей",for_power_users_description:"Используйте наши оптимизированные мультимодальные инструменты для повышения производительности.",internship1:"Стажерская программа",jobs:"Присоединяйтесь к нам",join_discord:"Присоединяйтесь к нашему сообществу Discord",logos:"Скачать логотип",maximize:"⇧1",maximize_btn:"Увеличить",news:"Новости",open_day:"День открытых дверей",open_in_full:"Показать все корпоративные продукты в новом окне",power_users_others:"Больше инструментов для опытных пользователей",products:"Продукты"},E={description:"Делитесь и открывайте строительные блоки для мультимодальных приложений ИИ"},G={sentence_similarity:"Встраивание предложения",updated_about:"Обновлено о"},O={project1:"Включен высокоточный поиск в данных 3D-сетки с использованием информации об облаке точек.",project10:"Использование компьютерного зрения для улучшения цифровой доступности государственных веб-сайтов.",project11:"Тонкая настройка LLM для консалтинговой фирмы для оптимизации анализа финансовых данных.",project12:"Расширенные маркетинговые стратегии за счет точной настройки моделей преобразования текста в изображение для передачи стиля.",project2:"Разработан поисковик по контенту для короткометражных анимационных фильмов.",project3:"Улучшенные показатели конверсии электронной коммерции за счет точной настройки моделей встраивания.",project4:"Выполнена оперативная настройка для повышения эффективности бизнес-консалтинговой компании.",project5:"Первопроходец в понимании игровых сцен и автоматических аннотаций для ведущего игрового предприятия.",project6:"Реализовано расширение ввода в реальном времени для чат-ботов, улучшающее взаимодействие с пользователем.",project7:"Революция в области юридических технологий, обеспечивающая эффективный поиск в длинных юридических документах.",project8:"Поддержка высокопроизводительного генеративного художественного сервиса для крупномасштабных операций.",project9:"Осуществлял интеллектуальный анализ и моделирование процессов с использованием передовых языковых моделей."},z={description:"Современные мультимодальные модели, доступные для логического вывода"},D={copy_full_prompt:"Копировать полную подсказку",embedding:"Вложения",how_to_use_meta_prompt:"Как использовать",meta_prompt:"Используйте Meta-prompt для генерации кода",meta_prompt_description:"Мета-подсказка проводит LLM-специалистов (таких как ChatGPT и Claude) через все наши API Search Foundation, упрощая генерацию кода и повышая ее качество.",reranker:"Реранкер",which_to_go:"Какой из них интегрировать с {_vendor}?"},U={answer1:"Бакалавриат, магистратура и доктор философии. студентам со всего мира, интересующимся такими областями, как исследования, инженерия, маркетинг и продажи, рекомендуется подавать заявки. Мы также приветствуем нетехнические стажировки в области маркетинга, продаж, помощи руководителям и т. д. Мы ищем увлеченных людей, готовых стать пионерами мультимодального ИИ вместе с нами.",answer10:"Да, наша программа стажировок предлагает конкурентоспособное вознаграждение.",answer11:"Став стажером Jina AI, вы получите практический опыт работы над сложными проектами, поучитесь у отраслевых экспертов, станете частью динамичного сообщества и получите возможность внести реальный вклад в нашу новаторскую работу в области мультимодального ИИ.",answer2:"Стажировку необходимо проводить на месте в одном из наших офисов, расположенных в Берлине, Пекине и Шэньчжэне.",answer3:"Да, Jina AI предлагает разумную помощь в процессе получения визы для успешных заявителей.",answer4:"Да, Jina AI обеспечивает разумное покрытие расходов на проживание для стажеров в течение периода стажировки.",answer5:"Да, во время стажировки в Jina AI можно работать над магистерской диссертацией, что обычно применимо к студентам немецких университетов. Тем не менее, вы должны получить предварительное уведомление и согласие от научного руководителя вашего университета. Обратите внимание, что мы не помогаем студентам найти консультантов.",answer6:"Процесс подачи заявки включает отправку формы заявки, резюме, сопроводительного письма, выражающего ваш интерес и мотивацию, а также любых соответствующих профессиональных ссылок, таких как GitHub или LinkedIn. Мы оцениваем кандидатов на основе их результатов во время собеседования и их результатов в их университете.",answer7:"Да, успешные стажеры могут получить рекомендательное письмо по окончании стажировки, подписанное нашим генеральным директором.",answer8:"Продолжительность стажировки зависит от роли и проекта. Однако обычно он составляет от трех до шести месяцев.",answer9:"Да, мы приветствуем заявки от всех ученых. Мы ценим вашу страсть и стремление учиться так же, как предыдущий опыт.",question1:"Кто может подать заявку на участие в программе стажировки Jina AI?",question10:"Это оплачиваемая стажировка?",question11:"Какие возможности я получу в качестве стажера Jina AI?",question2:"Где будет проходить стажировка?",question3:"Помогает ли Jina AI с оформлением визы?",question4:"Предоставляет ли Jina AI какие-либо надбавки или льготы для стажеров?",question5:"Могу ли я работать над магистерской диссертацией во время стажировки в Jina AI?",question6:"Что включает в себя процесс подачи заявки?",question7:"Предоставляет ли Jina AI какое-либо рекомендательное письмо после стажировки?",question8:"Какова продолжительность стажировки?",question9:"Могу ли я подать заявку, если у меня нет опыта работы с ИИ?"},F={about_internship_program:"О программе стажировки",about_internship_program_desc1:"Мы рады предложить эту уникальную возможность талантливым людям присоединиться к нашей динамичной команде и внести свой вклад в новаторские проекты в области искусственного интеллекта. Эта стажировка предназначена для того, чтобы предоставить вам ценный практический опыт, наставничество и знакомство с передовыми технологиями, формирующими будущее ИИ.",about_internship_program_desc2:"В Jina AI мы понимаем важность воспитания и использования молодых талантов. Мы понимаем, что стажеры привносят свежие взгляды, энтузиазм и креативность, вдохновляя нашу команду новыми идеями и подходами. Предоставляя стажировки, мы стремимся способствовать росту будущих лидеров индустрии искусственного интеллекта, предлагая им реальный опыт в благоприятной и сложной среде.",alumni:"ВЫПУСКНИКИ",alumni_network:"Наша процветающая сеть выпускников",application:"Приложение",application_desc:"Отправляйтесь в преобразующее путешествие вместе с Jina AI. Наша комплексная программа стажировок приглашает всех страстных умов, которые стремятся формировать будущее искусственного интеллекта. Присоединяйтесь к нам, чтобы получить реальный опыт, работать над сложными проектами и сотрудничать с некоторыми из самых ярких умов в индустрии искусственного интеллекта.",apply:"Применить сейчас",autumn:"Осень",description:"Призыв студентов по всему миру: стажировка в области исследований, инженерии, маркетинга, продаж и т. д.",dev_rel_intern:"Стажер по связям с разработчиками",enthusiastic:"ЭНТУЗИАСТИЧНЫЙ",explore_stories_from_our_interns:"Ознакомьтесь с историями наших стажеров",explore_stories_from_our_interns1:"Вдохновитесь путешествиями наших стажеров",innovative:"ИННОВАЦИОННЫЙ",intern_work1:"Точно настроенные модели LLM для лучшего встраивания",intern_work2:"Изучил потенциал поисковой дополненной генерации",intern_work3:"Опубликована статья на тему встраивания предложений.",intern_work4:"Привнесение постоянной юношеской жизненной энергии в команду",intern_work5:"Тестируемые методы квантования для сжатия LLM",intern_work6:"Создание и продвижение привлекательной кампании для PromptPerfect",intern_work7:"Быстро разработанный и улучшенный JinaColBERT V2",recruiting_and_administrative_intern:"Рекрутинговый и административный стажер",researcher_intern:"Стажер-исследователь",self_motivated:"САМОМОТИВИРОВАННЫЙ",software_engineer_intern:"Инженер-программист Стажер",spring:"Весна",submit_application:"Начните свое приключение с Jina AI",subtitle:"Наша программа стажировок на полный рабочий день позволяет получить практический опыт работы благодаря хорошо продуманным проектам стажировок в самых разных областях.",subtitle1:"Всемирный конкурс для студентов: стажируйтесь в области исследований, инженерии, маркетинга, продаж и т. д., чтобы вместе разработать мультимодальный ИИ.",summer:"Лето",title:"Стажерская программа",who_do_we_look_for:"Кого мы ищем?",who_do_we_look_for_desc:"Мы ценим разнообразие и призываем соискателей из разных профилей и опыта присоединиться к нашей программе стажировок. Возможности стажировки предлагаются в нескольких отделах, включая проектирование, дизайн, управление продуктами, управление продажами и учетными записями, маркетинг и управление сообществом.",winter:"Зима"},H={description:"Разверните локальный проект как облачный сервис. Радикально просто, без неприятных сюрпризов."},N={description:"Экспериментальный точный тюнер для LLM с открытым исходным кодом"},W={description:"Создавайте мультимодальные приложения ИИ в облаке"},K={description:"Больше модальности, больше памяти, меньше затрат",example_1:"Кто ты?",example_2:"Я чат-сервис LLM, созданный Jina AI."},Q={add:"Добавить ключ",add_key_explain:"Добавьте еще один ключ API к своей учетной записи. Добавленными ключами можно управлять, пополнять или удалять в любое время.",add_shared_key:"Добавить в мои ключи",add_success:"Успешно добавлен ключ {_key}.",advance_settings:"Открыть расширенные настройки",advanced_feature:"Расширенная функция доступна только для премиум-ключа.",auto_recharge_enable_success:"Успешно включено автоматическое пополнение баланса ключа {_key}.",auto_recharge_title:"Включить автоматическое пополнение счета?",auto_reminder:"Напоминание о низком балансе",auto_reminder_cancel_message:"Вы уверены, что хотите отменить автоматическое напоминание для этой клавиши?",auto_reminder_cancel_title:"Отменить автоматическое напоминание",auto_reminder_description:"Получайте автоматические оповещения по электронной почте, когда баланс ваших токенов падает ниже установленных вами порогов. Вы можете настроить до трех порогов.",auto_reminder_email:"Адрес электронной почты для напоминаний",auto_reminder_info:"Уведомление будет отправлено на {_email}, когда баланс токенов опустится ниже {_threshold} токенов.",auto_reminder_threshold:"Напомнить, если",auto_reminder_threshold_error:"Порог должен быть в пределах от 1 до 1Т.",auto_reminder_toggle:"Включите функцию автоматического напоминания. Обратите внимание, что эту функцию можно включить только при наличии премиум-ключа.",available_resources:"Доступные токены",balance:"Доступные токены",balance_primary_key:"Баланс первичного ключа",cancel:"Отмена",confirm:"Подтверждать",copy:"Копировать ключ",copy_share_link:"Копировать ссылку",description:"Управляйте ключами API для всех служб Jina AI — Embeddings, Reader, Reranker и других.",do_it_later:"Сделай это позже",email:"Электронная почта",existing_key:"Существующий ключ",filter_by:"Фильтр по ключу",free_key:"Бесплатный ключ",generate_new_key:"Сгенерировать новый ключ",generate_new_key_tooltip:"Сгенерируйте новый API-ключ с пустым балансом. Вы сможете пополнить баланс позже.",generate_success:"Успешно сгенерирован новый ключ {_key}.",get_free_key:"Создать API-ключ",ignore:"Игнорировать",invalid_email:"Неверный адрес электронной почты",invalid_key:"Неверный ключ",is_primary:"Ваш основной ключ API. Вы можете изменить его после входа в систему.",last_used:"Последнее использование",last_used_at:"Последняя активность",login:"Авторизоваться",login_explain:"Управляйте несколькими ключами API и отслеживайте использование — все в одной учетной записи.",login_explain_long:"Войдите в систему, чтобы безопасно хранить и управлять своими ключами API. Отслеживайте историю использования, управляйте несколькими ключами и никогда не теряйте доступ к своим учетным данным.",login_required:"Пожалуйста, войдите в систему перед добавлением общего ключа.",login_via:"вошел через {_provider}",logout:"Выйти",logout_message:"Ваши ключи API надежно хранятся в вашей учетной записи. Войдите в систему в любое время, чтобы управлять ими.",logout_success:"Успешно вышел",no_key_title:"Нужен ключ API?",no_key_with_login:"Вы еще не создали ключ API. Сгенерируйте его сейчас и получите бесплатные токены для начала.",no_key_without_login:"У вас уже есть учетная запись? Войдите в систему, чтобы получить доступ к своим ключам API, или нажмите «{_button}», чтобы создать новую.",no_transferable_keys:"Других ключей для переноса нет, сначала добавьте новый ключ.",ok:"ХОРОШО",primary_key:"Установить как первичный ключ",primary_key_set:"Успешно установите {_apiKey} в качестве первичного ключа.",primary_key_set_caption:"Этот ключ будет использоваться во всех демонстрациях, примерах и игровых площадках на jina.ai.",purchase:"Купить токены",recharge_threshold_confirm_message:"Вы уверены, что хотите изменить порог автоматического пополнения баланса на {_threshold} токенов?",recharge_threshold_confirm_title:"Изменить порог автопополнения",remove:"Удалить ключ",remove_explain:"Удаление ключа из вашего списка не повлияет на службу, зависимые операции или других пользователей, которые его сохранили. Ключ остается функциональным и может быть добавлен обратно в любое время.",remove_message:"Вы уверены, что хотите удалить этот ключ? Ключ остается функциональным и может быть добавлен обратно в любое время.",remove_primary_key:"Перед удалением текущего первичного ключа установите другой ключ в качестве первичного.",remove_success:"Ключ {_key} успешно удален.",remove_title:"Удалить ключ",revoke:"Отозвать ключ",revoke_error:"Введенный вами ключ не соответствует ключу, который вы пытаетесь отозвать.",revoke_explain:"Отзыв ключа немедленно отключит его для всех пользователей, которые его сохранили, а весь оставшийся баланс и связанные с ним свойства станут навсегда непригодными для использования. Это действие не может быть отменено.",revoke_label:"Пожалуйста, подтвердите отзыв этого ключа, введя его ниже",revoke_message:"Вы уверены, что хотите отозвать этот ключ? После отзыва этот ключ станет навсегда недействительным для всех пользователей, которые его сохранили. Весь оставшийся баланс и связанные с ним свойства будут навсегда непригодны для использования. Это действие нельзя отменить.",revoke_success:"Ключ {_key} успешно отозван.",revoke_title:"Отозвать ключ",save:"Сохранять",settings:"Настройки",share:"Поделиться ключом",share_key_confirm_message:`Получатель сможет просматривать, управлять и пополнять баланс этого ключа. Вы сохраните те же возможности. 
Обратите внимание, что ссылка истекает через 24 часа.`,share_key_confirm_title:"Поделиться API-ключом",share_key_expired_at:"Срок действия общей ссылки истечет {_time}!",share_key_expired_message:"Срок действия общей ссылки ключа истек. Пожалуйста, попросите владельца ключа поделиться ею снова.",share_key_expired_title:"Срок действия общей ссылки истек",share_key_message:"{_user} поделился с вами ключом API. Добавьте его для управления ключом и его балансом.",share_link_copied:"Поделиться ссылкой скопировано",shared_from:"Ключ предоставлен {_user}",shared_key:"Общий ключ",subscribed_key:"Премиум ключ",title:"API-интерфейс Jina Search Foundation",to_dashboard:"Управление ключами",top_up:"Пополнить",total_keys:"Всего ключей",transfer_before_revoke:"Перед отзывом ключа переведите оставшиеся оплаченные токены.",transfer_explain:"Легко переводите оставшиеся оплаченные токены на другой счет, чтобы обеспечить большую гибкость и безопасность управления ресурсами.",transfer_label:"Передача в",transfer_message:"Вы уверены, что хотите перевести оставшиеся оплаченные токены {_tokens} из {_source} в {_target}?",transfer_success:"Токены успешно переведены из {_source} в {_target}.",transfer_title:"Передача токенов",usage_history:"История использования",usage_summary:"Последние 7 дней: {_usage} токенов"},X={GlobalQA:{description:"Нажмите клавишу «/» на любой странице, чтобы открыть окно вопроса. Введите свой запрос и нажмите «Ввод», чтобы получить ответы, непосредственно связанные с содержимым страницы. Эта функция поддерживается PromptPerfect.",title:"RAG на странице"},Recommender:{description:"Откройте окно рекомендаций на любой странице новостей, нажав «Shift+2». Выберите модель реранкера, чтобы просмотреть топ-5 статей, связанных с этой новостной страницей. Наслаждайтесь этой функцией в реальном времени, основанной на нашем API Reranker.",title:"Связанная статья"},SceneXplainTooltip:{description:"Наведите курсор на любое изображение на страницах новостей или в каталоге нашей редакции, чтобы просмотреть описание этого изображения. Описания предварительно вычисляются SceneXplain и встраиваются в атрибут ALT изображения для обеспечения доступности.",title:"Подпись к изображению"},explain:"Откройте для себя скрытые функции на нашем сайте"},V={also_available_on:"Также доступно на торговых площадках",also_available_on1:"Доступно на торговых площадках вашего корпоративного облака.",ask_how_your_question:"Пожалуйста, опишите вашу проблему",autotune:"Автоматическая точная настройка",avatar:"Генератор аватаров",badge:{"clip-v2":"релиз clip-v2!","readerlm-v2":"Выпуск ReaderLM-v2!",v2:"релиз v2!",v3:"Релиз v3!"},browser_info_title:"Информация о браузере",build_js:"Создавайте с помощью JavaScript",build_python:"Создавайте с помощью Python",ccbync:"Эта модель лицензирована по лицензии CC BY-NC 4.0. Используйте ее через API или наш официальный образ AWS/Azure; или свяжитесь с отделом продаж для локального развертывания.",checkout_our_solution_for_you:"Узнайте о нашем решении, разработанном специально для вас",classifier:"Классификатор",coming_soon:"Вскоре",contact_sales:"Контакт",copied_to_clipboard:"Скопировано в буфер обмена",copy:"Копировать",developers:"Разработчики",developers_desc:"Раскройте всю мощь мультимодального ИИ с помощью передовых облачных технологий и инфраструктуры с открытым исходным кодом.",download_pdf:"Скачать PDF",embedding:"Вложения",embedding_desc1:"Высокопроизводительные мультимодальные многоязычные встраивания с длинным контекстом для приложений поиска, RAG и агентов.",embedding_paper_desc:"Jina Embeddings представляет собой набор высокопроизводительных моделей встраивания предложений, способных преобразовывать различные текстовые входные данные в числовые представления, тем самым улавливая семантическую сущность текста. Хотя эти модели предназначены не только для генерации текста, они превосходны в таких приложениях, как плотный поиск и семантическое сходство текста. В этом документе подробно описывается разработка Jina Embeddings, начиная с создания высококачественного парного и тройного набора данных. В нем подчеркивается решающая роль очистки данных при подготовке наборов данных, подробно рассматривается процесс обучения модели и завершается всесторонней оценкой производительности с использованием теста массового встраивания текста (MTEB).",embedding_paper_title:"Jina Embeddings: новый набор высокопроизводительных моделей встраивания предложений",embeddings:"Вложения",enterprise:"Предприятие",enterprise_desc:"Расширьте свой бизнес с помощью масштабируемых, безопасных и индивидуальных мультимодальных решений на базе ИИ.",enterprise_desc_v2:"Попробуйте наши модели внедрения мирового класса, чтобы улучшить свои системы поиска и RAG. Начните с бесплатной пробной версии!",enterprise_desc_v3:"Наши передовые модели формируют поисковую основу для высококачественных систем корпоративного поиска и RAG.",error:"Возникла проблема с операцией выборки: {message}",find_your_portal:"Найдите свой портал",finding_faq:"Генерация ответа на основе знаний часто задаваемых вопросов ниже",for:"Для",for_better_search:"Для лучшего поиска",for_developers:"Для разработчиков",for_enterprise:"Для предприятия",for_power_users:"Для опытных пользователей",get_api_now:"API",get_started:"Начать",go_to_product_homepage:"Перейти на домашнюю страницу продукта",grounding:"Заземление",how_to:"Как",include_experiment:"Включает в решение наши экспериментальные и архивные проекты.",join_community:"Сообщество",key_manager:"Управление ключом API",learn_more_embeddings:"Узнайте больше о встраиваниях",learn_more_reader:"Узнать больше о читателе",learn_more_reranker:"Узнать больше о реранкере",llm:"Модели встраивания LLM",llm_desc:"Мы предоставляем коллекцию высокопроизводительных моделей встраивания предложений, содержащих от 35 миллионов до 6 миллиардов параметров. Они отлично подходят для улучшения нейронного поиска, повторного ранжирования, схожести предложений, рекомендаций и т. д. Приготовьтесь улучшить свой опыт работы с ИИ!",mentioned_products:"Упомянутые продукты:",mmstack:"Мультимодальный стек",mmstack_desc:"За прошедшие годы мы разработали разнообразное программное обеспечение с открытым исходным кодом, которое помогает разработчикам быстрее создавать лучшие приложения GenAI и поисковые приложения.",models:"Модели",more:"Более",multimodal:"Мультимодальный",multimodal_ai:"Мультимодальный ИИ",new:"Новый",newsroom:"отдел новостей",num_publications:"Всего публикаций {_total}.","on-prem-deploy":"Локальное развертывание","on-premises":"Локально",opensource:"Открытый источник",our_customer:"Наши клиенты",our_customer_explain:"Компании всех размеров доверяют Jina AI Search Foundation в обеспечении работы своих инструментов и продуктов — можете и вы.",our_publications:"Наши публикации",parameters:"Параметры",podcast:"Подкаст",power_users:"Опытные пользователи",power_users_desc:"Автоматическое оперативное проектирование для вашей повседневной производительности.",powered_by_promptperfect:"Работает на основе функций PromptPerfect «Быстрая оптимизация» и «Подсказка как услуга».",pricing:"Цены",proposing_solution:"Предлагаем решение на основе продуктов Jina AI...",read_more:"Читать далее",reader:"Читатель",require_full_question:"Пожалуйста, опишите вашу проблему более подробно.",reranker:"Реранкер",researcher_desc:"Поймите, как наши модели поиска на границе были обучены с нуля, ознакомьтесь с нашими последними публикациями. Познакомьтесь с нашей командой в EMNLP, SIGIR, ICLR, NeurIPS и ICML!",researchers:"Исследователи",sdk:"SDK",sdk_desc:"Хотите создавать высокоуровневые приложения AIGC, используя API PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale? Мы вас прикрыли! Попробуйте наш простой в использовании SDK и начните работу за считанные минуты.",sdk_docs:"Читать документы",sdk_example:"Пример",search_foundation:"Поисковый фонд",source_code:"Исходный код",starter_kit:"Стартовый комплект",supercharged1:"полный вперёд!",tokenizer:"Сегментатор",trusted_by:"ДОВЕРЯЕТ",try_it_for_free:"Начните прямо сейчас — кредитная карта или регистрация не требуются!",try_our_saas:"Попробуйте наше размещенное решение — замену API встраивания OpenAI.",version_notify:"Вы просматриваете старую версию этого веб-сайта. Для последних функций перейдите по ссылке {_link}",view_browser_info:"Посмотреть информацию о браузере",your_portal_to:"Ваш портал в",your_search_foundation1:"Ваш фонд поиска"},Y={description:"Приложения Langchain в производстве с Jina и FastAPI"},Z={description:"Юридическая информация, условия обслуживания, политика конфиденциальности и другие важные документы о продуктах и услугах Jina AI.",download_type1:"Загрузить аттестацию SOC 2 Type 1",download_type2:"Загрузить аттестацию SOC 2 Type 2",request_audit:"Запросить аудиторский отчет",title:"Юридическая информация"},$={api:"Jina AI API",browse_catalog:"Просмотреть каталог",contact_sales_about_it:"Свяжитесь с отделом продаж по этому поводу",deploy_it_on:"Разверните его на",description:"Мы двигаем иглу в моделях поиска с самого первого дня. Взгляните на эволюцию нашей модели ниже — наведите курсор или щелкните, чтобы увидеть каждую веху.",find_on_hf:"Найдите это на HuggingFace",search_for:"Поиск на нашем сайте",search_models:"Фильтр по названию модели",title:"Наши модели фундамента поиска",use_it_via:"Используйте его через"},ee={back_to_models:"Вернуться к моделям",comparison:{btn:"Сравнивать",select_models:"Выберите модели для сравнения"},error:"Не удалось загрузить модель",input_type:{"3d":"3D",audio:"Аудио",code:"Код",document:"Документ",graph:"График",image:"Изображение","multi-vector":"Многовекторный",other:"Другой",ranking:"Рейтинги",tabular:"Табличный",text:"Текст","text (code)":"Текст (Код)","text (document)":"Текст (Документ)","text (html)":"Текст (HTML)","text (json)":"Текст (JSON)","text (markdown)":"Текст (разметка)","text (query)":"Текст (Запрос)",timeseries:"Временной ряд",vector:"Вектор",video:"Видео"},loading:"Загрузка сведений о модели...",metadata:{api_link:"API Джина",arxiv:"ArXiv-бумага",aws_link:"AWS SageMaker",azure_link:"Microsoft Azure",deprecated_by:"Устаревшее",gcp_link:"Google Облако",huggingface_link:"Обнимающее лицо",input_type:"Вход",license:"Лицензия",license_link:"Коммерческая лицензия",output_type:"Выход","reader-api_link":"API Джина",related_models:"Похожие модели",release_blog:"Выпуск Пост",release_date:"Дата выпуска"},search:{no_results:'Не найдено ни одной модели, соответствующей "{query}"',placeholder:"Поиск по имени, тегам или типу..."},sections:{availability:"Доступность",blogs:"Блоги, в которых упоминается эта модель",external_links:"Внешние ссылки и ресурсы",guidance:{"ReaderLM-v2":"Модель доступна через блокнот Google Colab, демонстрирующий преобразование HTML в Markdown, извлечение JSON и выполнение инструкций. Для задач HTML в Markdown пользователи могут вводить необработанный HTML без префиксных инструкций, тогда как извлечение JSON требует определенного форматирования схемы. Вспомогательная функция create_prompt упрощает создание подсказок для обеих задач. Хотя модель работает на бесплатном уровне графического процессора T4 Colab (требуется vllm и triton), она имеет ограничения без поддержки bfloat16 или flash attention 2. Для использования в производстве рекомендуется RTX 3090/4090. Модель будет доступна на AWS SageMaker, Azure и GCP marketplace по лицензии CC BY-NC 4.0 для некоммерческого использования.","jina-clip-v1":"Для эффективного развертывания Jina CLIP v1 команды должны учитывать как ее возможности, так и требования к ресурсам. Модель обрабатывает изображения в плитках размером 224x224 пикселя, при этом каждая плитка потребляет 1000 токенов вычислительной мощности. Для оптимальной производительности реализуйте эффективную предварительную обработку изображений для соответствия этим размерам. Хотя модель отлично справляется как с обработкой коротких, так и длинных текстов, в настоящее время она поддерживает только ввод на английском языке. Командам следует тщательно продумать использование токенов: текст требует приблизительно 1,1 токена на слово, тогда как изображения обрабатываются плитками (например, изображение размером 750x500 пикселей требует 12 плиток, потребляя 12 000 токенов). Модель доступна как через Jina Embeddings API, так и в виде релиза с открытым исходным кодом на Hugging Face по лицензии Apache 2.0, что обеспечивает гибкость в вариантах развертывания. Для производственных сред рассмотрите возможность использования вариантов развертывания AWS Marketplace или Azure, которые обеспечивают оптимизированные настройки инфраструктуры.","jina-clip-v2":"Для оптимального развертывания пользователи должны учитывать несколько ключевых факторов. Для эффективной обработки модели требуется оборудование с поддержкой CUDA, а требования к памяти масштабируются на основе размера пакета и разрешения изображения. Чтобы оптимизировать затраты и производительность API, измените размер изображений до 512x512 пикселей перед обработкой — более крупные изображения автоматически разбиваются на плитки, что увеличивает использование токенов и время обработки. Модель отлично сопоставляет изображения с описательным текстом на разных языках, но может испытывать трудности с абстрактными концепциями или узкоспециализированным контентом, специфичным для домена. Она особенно эффективна для поиска товаров в электронной коммерции, систем рекомендаций контента и приложений визуального поиска, но может не подходить для задач, требующих детального визуального анализа деталей или узкоспециализированной экспертизы домена. При использовании функции представления Matryoshka рассмотрите компромисс между уменьшением размерности и производительностью — в то время как 64-мерные вложения сохраняют высокую производительность, критически важные приложения могут выиграть от более высоких размерностей.","jina-colbert-v1-en":"Для эффективного развертывания Jina-ColBERT-v1-en командам следует рассмотреть несколько практических аспектов. Для оптимальной производительности модели требуется графический процессор с поддержкой CUDA, хотя для разработки возможен вывод на CPU. Для обработки документов ограничение в 8192 токена соответствует примерно 6000 слов, что делает его подходящим для большинства типов документов, включая научные статьи, техническую документацию и длинный контент. Командам следует реализовать эффективную предварительную обработку документов для обработки ограничений токенов и рассмотреть пакетную обработку для крупномасштабной индексации. Хотя модель отлично подходит для контента на английском языке, она не предназначена для многоязычных приложений или кросс-языкового поиска. Для производственных развертываний реализуйте надлежащие стратегии фрагментации документов и рассмотрите возможность использования индексов векторного сходства (например, FAISS) для эффективного поиска. Модель особенно эффективна при интеграции в конвейеры RAG с использованием таких фреймворков, как RAGatouille, что упрощает реализацию сложных шаблонов поиска.","jina-colbert-v2":"Для эффективного развертывания Jina-ColBERT-v2 команды должны рассмотреть несколько практических аспектов. Для оптимальной производительности модели требуется оборудование с поддержкой CUDA, а также она поддерживает длину документов до 8192 токенов (с возможностью расширения до 12288) при ограничении запросов 32 токенами. Для производственного развертывания модель доступна через API Jina Search Foundation, AWS marketplace и Azure, а некоммерческая версия доступна через Hugging Face. При реализации команды должны указать, внедряют ли они запросы или документы, поскольку модель использует асимметричное кодирование. Модель не предназначена для обработки в реальном времени очень больших коллекций документов без надлежащего индексирования, и хотя она отлично подходит для многоязычного поиска, она может показывать немного более низкую производительность при выполнении специализированных задач, специфичных для доменов, по сравнению с моделями, настроенными для этих конкретных доменов.","jina-embedding-b-en-v1":"Для оптимального развертывания модели требуется графический процессор с поддержкой CUDA, хотя его умеренный размер позволяет эффективно выводить данные на стандартном оборудовании. Модель принимает входные последовательности длиной до 512 токенов и особенно хорошо подходит для производственных сред, где решающее значение имеет последовательная и надежная генерация встраивания. Она лучше всего работает с контентом на английском языке и идеально подходит для таких приложений, как семантический поиск, сравнение схожести документов и системы рекомендаций по контенту. Командам следует рассмотреть возможность использования более новых версий v2 или v3 для новых проектов, поскольку они предлагают улучшенную производительность и более широкую языковую поддержку. Модель не рекомендуется для задач, требующих многоязычного понимания или специальных знаний в области за пределами общего английского текста.","jina-embeddings-v2-base-code":"Для эффективного развертывания базового кода Jina Embeddings v2 командам следует рассмотреть несколько практических аспектов. Модель легко интегрируется с популярными векторными базами данных, такими как MongoDB, Qdrant и Weaviate, что упрощает создание масштабируемых систем поиска кода. Для оптимальной производительности реализуйте надлежащую предварительную обработку кода для обработки ограничения в 8192 токена, которое обычно охватывает большинство определений функций и классов. Хотя модель поддерживает 30 языков программирования, она демонстрирует наивысшую производительность на шести основных языках: Python, JavaScript, Java, PHP, Go и Ruby. Командам следует рассмотреть возможность использования пакетной обработки для крупномасштабной индексации кода с целью оптимизации производительности. Совместимость модели с RAG делает ее особенно эффективной для задач автоматизированной генерации документации и понимания кода, хотя командам следует реализовать соответствующие стратегии фрагментации для очень больших кодовых баз. Для производственных развертываний рассмотрите возможность использования конечной точки AWS SageMaker для управляемого вывода и реализуйте соответствующие стратегии кэширования для оптимизации производительности запросов.","jina-embeddings-v2-base-de":"Для эффективного развертывания Jina Embeddings v2 Base German организациям следует рассмотреть несколько практических аспектов. Модель легко интегрируется с популярными векторными базами данных, такими как MongoDB, Qdrant и Weaviate, что упрощает создание масштабируемых двуязычных поисковых систем. Для оптимальной производительности реализуйте надлежащую предварительную обработку текста для эффективной обработки ограничения в 8192 токена — обычно это вмещает около 15–20 страниц текста. Хотя модель отлично подходит как для немецкого, так и для английского контента, она особенно эффективна при использовании для задач поиска на разных языках, где языки запросов и документов могут различаться. Организациям следует рассмотреть возможность внедрения стратегий кэширования для часто используемого контента и использования пакетной обработки для крупномасштабной индексации документов. Интеграция модели с AWS SageMaker обеспечивает надежный путь к развертыванию в рабочей среде, хотя команды должны отслеживать использование токенов и внедрять соответствующие ограничения скорости для приложений с высоким трафиком. При использовании модели для приложений RAG рассмотрите возможность внедрения определения языка для оптимизации построения подсказок на основе языка ввода.","jina-embeddings-v2-base-en":"Для эффективного развертывания Jina Embeddings v2 Base English командам следует учесть несколько практических аспектов. Для оптимальной производительности модели требуется оборудование с поддержкой CUDA, хотя ее эффективная архитектура означает, что она может работать на графических процессорах потребительского уровня. Она доступна по нескольким каналам: прямая загрузка с Hugging Face, развертывание AWS Marketplace или API Jina AI с 1 млн бесплатных токенов. Для производственных развертываний AWS SageMaker в регионе us-east-1 предлагает наиболее масштабируемое решение. Модель отлично подходит для анализа текста общего назначения, но может быть не лучшим выбором для узкоспециализированной научной терминологии или жаргона, специфичного для предметной области, без тонкой настройки. При обработке длинных документов рассмотрите возможность разбиения их на осмысленные семантические фрагменты, а не на произвольные разделения, чтобы сохранить целостность контекста. Для достижения оптимальных результатов реализуйте надлежащую предварительную обработку текста и обеспечьте чистые, хорошо отформатированные входные данные.","jina-embeddings-v2-base-es":"Для эффективного использования этой модели организации должны обеспечить доступ к инфраструктуре GPU с поддержкой CUDA для оптимальной производительности. Модель легко интегрируется с основными векторными базами данных и фреймворками RAG, включая MongoDB, Qdrant, Weaviate и Haystack, что делает ее легко развертываемой в производственных средах. Она отлично подходит для таких приложений, как поиск двуязычных документов, системы рекомендаций по контенту и кросс-языковой анализ документов. Хотя модель демонстрирует впечатляющую универсальность, она особенно оптимизирована для двуязычных сценариев испанского и английского языков и может быть не лучшим выбором для одноязычных приложений или сценариев, включающих другие языковые пары. Для получения оптимальных результатов входные тексты должны быть правильно отформатированы на испанском или английском языках, хотя модель эффективно обрабатывает контент на разных языках. Модель поддерживает тонкую настройку для приложений, специфичных для домена, но к этому следует подходить с тщательным учетом качества и распределения обучающих данных.","jina-embeddings-v2-base-zh":"Для модели требуется 322 МБ памяти, и ее можно развернуть через несколько каналов, включая AWS SageMaker (регион us-east-1) и Jina AI API. Хотя ускорение GPU не является обязательным, оно может значительно повысить скорость обработки для производственных рабочих нагрузок. Модель отлично подходит для различных приложений, включая анализ документов, многоязычный поиск и кросс-языковой поиск информации, но пользователи должны учитывать, что она специально оптимизирована для двуязычных сценариев с китайским и английским языками. Для достижения оптимальных результатов входной текст должен быть правильно сегментирован, и хотя модель может обрабатывать до 8192 токенов, для лучшей производительности рекомендуется разбивать очень длинные документы на семантически значимые фрагменты. Модель может не подходить для задач, требующих обработки в реальном времени очень коротких текстов, где более подходящими могут быть специализированные модели с меньшей задержкой.","jina-embeddings-v3":"Для эффективного развертывания Jina Embeddings v3 команды должны рассмотреть свой конкретный вариант использования, чтобы выбрать подходящий адаптер задач: retrieval.query и retrieval.passage для поисковых приложений, разделение для задач кластеризации, классификация для категоризации и сопоставление текста для семантического сходства. Для оптимальной производительности модели требуется оборудование с поддержкой CUDA, хотя ее эффективная архитектура означает, что ей требуется значительно меньше памяти GPU, чем более крупным альтернативам. Для производственного развертывания интеграция AWS SageMaker обеспечивает оптимизированный путь к масштабируемости. Модель отлично работает в многоязычных приложениях, но может потребовать дополнительной оценки для языков с низкими ресурсами. Хотя она поддерживает длинные документы до 8192 токенов, оптимальная производительность достигается с помощью функции позднего фрагментирования для очень длинных текстов. Командам следует избегать использования модели для задач, требующих генерации в реальном времени или сложных рассуждений — она предназначена для встраивания и извлечения, а не для генерации текста или прямых ответов на вопросы.","jina-reranker-v1-base-en":"Для оптимальной производительности модели требуется оборудование с поддержкой CUDA, и она доступна как через конечные точки API, так и через варианты развертывания AWS SageMaker. Хотя она может обрабатывать очень длинные последовательности, пользователям следует учитывать компромисс между длиной контекста и временем обработки — задержка модели заметно увеличивается с более длинными документами, с 156 мс для 256 токенов до 7068 мс для 4096 токенов при запросе из 512 токенов. Для производственных развертываний рекомендуется реализовать двухэтапный конвейер, в котором векторный поиск предоставляет начальных кандидатов для повторного ранжирования. Модель специально оптимизирована для английского контента и может работать неоптимально на многоязычных или насыщенных кодом документах. При интеграции с системами RAG пользователям следует тщательно настраивать количество документов, отправляемых на повторное ранжирование, на основе своих требований к задержке, при этом 100–200 документов обычно обеспечивают хороший баланс между качеством и производительностью.","jina-reranker-v1-tiny-en":"Для эффективного развертывания этой модели организации должны отдавать приоритет сценариям, где скорость обработки и эффективность ресурсов являются критически важными факторами. Модель особенно хорошо подходит для развертываний периферийных вычислений, мобильных приложений и высокопроизводительных поисковых систем, где требования к задержке строгие. Хотя она исключительно хорошо выполняет большинство задач переранжирования, важно отметить, что для приложений, требующих абсолютно высочайшего уровня точности ранжирования, базовая модель все равно может быть предпочтительнее. Для оптимальной производительности модели требуется инфраструктура графического процессора с поддержкой CUDA, хотя ее эффективная архитектура означает, что она может эффективно работать на менее мощном оборудовании, чем ее более крупные аналоги. Для развертывания модель легко интегрируется с основными векторными базами данных и фреймворками RAG, и она доступна как через API Reranker, так и через AWS SageMaker. При тонкой настройке для определенных доменов пользователи должны тщательно сбалансировать качество обучающих данных с компактной архитектурой модели, чтобы сохранить ее характеристики производительности.","jina-reranker-v1-turbo-en":"Для оптимальной производительности модели требуется оборудование с поддержкой CUDA, и ее можно развернуть через AWS SageMaker или получить доступ через конечные точки API. Для производственных развертываний организациям следует реализовать двухэтапный конвейер, в котором векторный поиск предоставляет начальные кандидаты для повторного ранжирования. Хотя модель поддерживает 8192 токена, пользователи должны учитывать влияние задержки более длинных последовательностей — время обработки увеличивается с длиной документа. Оптимальным вариантом для большинства приложений является повторное ранжирование 100–200 кандидатов на запрос, что обеспечивает баланс качества и скорости. Модель специально оптимизирована для английского контента и может работать неоптимально с многоязычными документами. Требования к памяти значительно ниже, чем у базовой модели, обычно требуется всего 150 МБ памяти графического процессора по сравнению с 550 МБ, что делает ее пригодной для развертывания на меньших экземплярах и обеспечивает значительную экономию средств в облачных средах.","jina-reranker-v2-base-multilingual":"Для оптимального развертывания модель требует GPU с поддержкой CUDA и может быть доступна через несколько каналов, включая API Reranker, основные фреймворки RAG, такие как Haystack и LangChain, или развернута в частном порядке через облачные торговые площадки. Модель отлично подходит для сценариев, требующих точного понимания языковых барьеров и типов данных, что делает ее идеальной для глобальных предприятий, работающих с многоязычным контентом, документацией API или репозиториями кода. Ее обширное контекстное окно из 524 288 токенов позволяет обрабатывать большие документы или целые кодовые базы за один проход. Командам следует рассмотреть возможность использования этой модели, когда им необходимо повысить точность поиска на разных языках, требуются возможности вызова функций для агентских систем RAG или требуется улучшить функциональность поиска кода на разных языках. Модель особенно эффективна при использовании в сочетании с векторными поисковыми системами, где она может значительно улучшить окончательный рейтинг извлеченных документов.","reader-lm-05b":"Для эффективного развертывания Reader LM 0.5B организации должны убедиться, что их инфраструктура может справиться с требованиями модели CUDA, хотя ее эффективная архитектура означает, что она может работать на графических процессорах потребительского уровня. Модель лучше всего работает с необработанным вводом HTML и не требует специальных префиксов или инструкций. Для оптимальной производительности реализуйте предоставленный механизм обнаружения повторений, чтобы предотвратить потенциальные циклы токенов при генерации выходных данных. Хотя модель поддерживает несколько языков и различные структуры HTML, она специально разработана для извлечения контента и преобразования в разметку — ее не следует использовать для таких задач, как генерация текста, реферирование или прямые ответы на вопросы. Модель доступна через AWS SageMaker для развертывания в рабочей среде, а для тестирования и экспериментов предоставляется блокнот Google Colab. Команды должны знать, что, хотя модель может обрабатывать чрезвычайно длинные документы размером до 256 тыс. токенов, обработка таких больших входных данных может потребовать дополнительных стратегий управления памятью.","reader-lm-15b":"Для эффективного развертывания Reader LM 1.5B организации должны сосредоточиться на сценариях, включающих сложную обработку HTML-документов, где точность и эффективность имеют первостепенное значение. Для оптимальной производительности модели требуется инфраструктура графического процессора с поддержкой CUDA, хотя ее эффективная архитектура означает, что она может эффективно работать на более скромном оборудовании по сравнению с более крупными альтернативами. Для производственных развертываний модель доступна как через AWS SageMaker, так и через Azure Marketplace, предлагая гибкие возможности интеграции. Хотя модель отлично справляется с преобразованием HTML в markdown, важно отметить, что она специально оптимизирована для этой задачи и может не подходить для генерации текста общего назначения или других задач обработки естественного языка. При обработке очень длинных документов (приближающихся к 512 тыс. токенов) пользователи должны знать, что производительность может ухудшиться, поскольку это превышает параметры обучения модели. Для достижения оптимальных результатов реализуйте предоставленные механизмы обнаружения повторений и рассмотрите возможность использования сопоставительного поиска во время вывода для поддержания качества вывода.",title:"Руководство"},image_size:"Размер входного изображения",language:"Поддержка языков",methods:{"ReaderLM-v2":"Обучение ReaderLM-v2, основанное на Qwen2.5-1.5B-Instruction, включало набор данных html-markdown-1m из одного миллиона HTML-документов, в среднем 56 000 токенов каждый. Процесс обучения включал: 1) долгосрочное контекстное предварительное обучение с использованием внимания Ring-Zag и RoPE для расширения контекста с 32K до 256K токенов, 2) контролируемую тонкую настройку с уточненными наборами данных, 3) прямую оптимизацию предпочтений для выравнивания выходных данных и 4) настройку подкрепления самостоятельной игры. Подготовка данных следовала трехэтапному конвейеру (Draft-Refine-Critique) на базе Qwen2.5-32B-Instruction, со специализированными моделями, обученными для определенных задач перед слиянием с помощью линейной интерполяции параметров.","jina-clip-v1":"Архитектура модели представляет собой значительное новшество в дизайне мультимодального ИИ, объединяя адаптированный текстовый кодер Jina BERT v2 с передовым кодером изображений EVA-02 из Пекинской академии искусственного интеллекта. Текстовый кодер поддерживает последовательности до 12 288 токенов — более чем в 100 раз длиннее, чем предел в 77 токенов оригинального CLIP — в то время как кодер изображений эффективно обрабатывает 16 токенов патчей. Процесс обучения следует новому трехэтапному подходу: во-первых, выравнивание пар изображение-подпись с сохранением понимания текста посредством чередующегося обучения пар текста; во-вторых, включение более длинных текстовых описаний изображений, сгенерированных ИИ; и, наконец, использование жестких отрицательных текстовых триплетов для улучшения возможностей семантического различия. Эта уникальная методология обучения позволяет модели поддерживать высокую производительность как для коротких подписей, так и для подробных текстовых описаний с сохранением сильного визуального понимания.","jina-clip-v2":"В своей основе Jina CLIP v2 использует сложную архитектуру с двумя кодировщиками, которая объединяет текстовый кодировщик Jina XLM-RoBERTa (561 млн параметров) с видеокодировщиком EVA02-L14 (304 млн параметров). Текстовый кодировщик обрабатывает контент на 89 языках с огромным контекстным окном из 696 320 токенов, в то время как видеокодер обрабатывает изображения с высоким разрешением до 512x512 пикселей. Модель представляет инновационное обучение представлению Matryoshka, которое позволяет динамически корректировать размерность встраивания с 1024 до 64 измерений, сохраняя производительность. Эта архитектура обрабатывает как текст, так и изображения через соответствующие кодировщики, проецируя их в общее семантическое пространство, где схожие концепции выравниваются независимо от их исходной модальности или языка.","jina-colbert-v1-en":"Модель использует инновационную архитектуру позднего взаимодействия, которая кардинально меняет то, как работает поиск документов. Вместо того, чтобы сравнивать целые документы сразу, она обрабатывает запросы и документы независимо до финальной стадии сопоставления, используя адаптированную версию подхода ColBERT. Архитектура объединяет два ключевых компонента: кодировщик документов, который обрабатывает текст до 8192 токенов (более чем в 16 раз дольше, чем стандартные преобразователи), и кодировщик запросов, который создает точные представления на уровне токенов. Каждый токен как в запросе, так и в документе получает свой собственный 128-мерный вектор внедрения, сохраняя мелкозернистую семантическую информацию, которая была бы потеряна в одновекторных моделях. Затем механизм позднего взаимодействия обеспечивает эффективное сопоставление токенов между запросами и документами, используя операции максимального пула и суммирования для вычисления окончательных оценок релевантности без необходимости дорогостоящих сравнений всех со всеми.","jina-colbert-v2":"Модель основана на архитектуре ColBERT, внедряя сложный механизм позднего взаимодействия, который кардинально меняет способ сопоставления запросов и документов. В своей основе она использует модифицированную основу XLM-RoBERTa с 560M параметрами, улучшенную вращающимися позиционными вложениями и оптимизированную с помощью флэш-внимания. Процесс обучения включает два ключевых этапа: начальное предварительное обучение с разнообразными слабо контролируемыми данными из разных языков, за которым следует тонкая настройка с маркированными триплетными данными и контролируемой дистилляцией. Уникальность этого подхода заключается в реализации обучения представлению Matryoshka, которое позволяет модели производить вложения в нескольких измерениях (128, 96 или 64) из одного процесса обучения, что позволяет проводить динамическую оптимизацию хранения без повторного обучения.","jina-embedding-b-en-v1":"Модель использует архитектуру на основе кодировщика T5, улучшенную с помощью объединения средних значений для генерации представлений фиксированной длины. Обученная на тщательно подобранном наборе данных Linnaeus-Clean, который содержит 385 миллионов высококачественных пар предложений, отфильтрованных из исходных 1,6 миллиарда пар, модель прошла двухфазный процесс обучения. На первом этапе использовалось контрастное обучение с потерей InfoNCE на текстовых парах, а на втором этапе было включено обучение триплетами для уточнения способности модели различать похожий и разный контент. Этот инновационный подход к обучению в сочетании со строгой фильтрацией данных, включая обнаружение языка и проверку согласованности, позволяет модели эффективно улавливать тонкие семантические отношения.","jina-embeddings-v2-base-code":"Модель достигает своей впечатляющей производительности благодаря специализированной архитектуре, разработанной специально для понимания кода. В своей основе она использует нейронную сеть на основе трансформатора с 161 миллионом параметров, обученную на различных наборах данных языков программирования с упором на шесть основных языков: Python, JavaScript, Java, PHP, Go и Ruby. Уникальность этой архитектуры заключается в ее расширенном окне контекста из 8192 токенов, что позволяет ей обрабатывать целые функции или несколько файлов одновременно, сохраняя семантическое понимание. Модель генерирует плотные 768-мерные вложения, которые фиксируют как синтаксическую структуру, так и семантическое значение кода, что позволяет ей понимать отношения между различными сегментами кода, даже если они используют разные шаблоны программирования или синтаксис для достижения одной и той же цели.","jina-embeddings-v2-base-de":"Модель достигает своих впечатляющих двуязычных возможностей благодаря инновационной архитектуре, которая обрабатывает как немецкий, так и английский текст в едином 768-мерном пространстве встраивания. В своей основе она использует нейронную сеть на основе трансформатора с 161 миллионом параметров, тщательно обученную понимать семантические отношения в обоих языках. Что делает эту архитектуру особенно эффективной, так это ее подход минимизации смещения, специально разработанный для того, чтобы избежать распространенной ошибки предпочтения английских грамматических структур — проблемы, выявленной в недавнем исследовании с многоязычными моделями. Расширенное контекстное окно модели из 8192 токенов позволяет ей обрабатывать целые документы или несколько страниц текста за один проход, сохраняя семантическую согласованность в длинном контенте на обоих языках.","jina-embeddings-v2-base-en":"Архитектура модели объединяет базовую модель BERT Small с инновационным симметричным двунаправленным механизмом ALiBi (Attention with Linear Biases), устраняя необходимость в традиционных позиционных встраиваниях. Этот архитектурный выбор позволяет модели экстраполировать далеко за пределы ее длины обучения в 512 токенов, обрабатывая последовательности до 8192 токенов без ухудшения производительности. Процесс обучения включал два ключевых этапа: первоначальное предварительное обучение на наборе данных C4, за которым следовало уточнение на курируемой коллекции Jina AI из более чем 40 специализированных наборов данных. Эти разнообразные данные обучения, включая сложные отрицательные примеры и разнообразные пары предложений, обеспечивают надежную производительность в различных областях и вариантах использования. Модель создает 768-мерные плотные векторы, которые фиксируют тонкие семантические отношения, достигаемые с помощью относительно скромных 137M параметров.","jina-embeddings-v2-base-es":"В основе этой модели лежит инновационная архитектура, основанная на симметричном двунаправленном ALiBi (Attention with Linear Biases), сложном подходе, который позволяет обрабатывать последовательности до 8192 токенов без традиционных позиционных вложений. Модель использует модифицированную архитектуру BERT с 161 млн параметров, включающую Gated Linear Units (GLU) и специализированные методы нормализации слоев. Обучение следует трехэтапному процессу: первоначальное предварительное обучение на массивном текстовом корпусе, за которым следует тонкая настройка с тщательно отобранными парами текстов и, наконец, жестко-отрицательное обучение для улучшения различения похожего, но семантически различного контента. Этот подход в сочетании с 768-мерными вложениями позволяет модели улавливать тонкие семантические отношения, сохраняя при этом вычислительную эффективность.","jina-embeddings-v2-base-zh":"Архитектура модели объединяет остов на основе BERT с симметричным двунаправленным ALiBi (Attention with Linear Biases), что позволяет эффективно обрабатывать длинные последовательности без традиционного ограничения в 512 токенов. Процесс обучения следует тщательно организованному трехфазному подходу: первоначальное предварительное обучение на высококачественных двуязычных данных, за которым следуют первичные и вторичные этапы тонкой настройки. Эта методическая стратегия обучения в сочетании с 161 млн параметров модели и 768-мерным выводом достигает замечательной эффективности, сохраняя при этом сбалансированную производительность на обоих языках. Симметричный двунаправленный механизм ALiBi представляет собой значительное новшество, позволяющее модели обрабатывать документы длиной до 8192 токенов — возможность, ранее ограниченная фирменными решениями.","jina-embeddings-v3":"Архитектура модели представляет собой значительное новшество в технологии встраивания, построенное на основе jina-XLM-RoBERTa с 24 слоями и улучшенное с помощью адаптеров Low-Rank Adaptation (LoRA) для конкретных задач. Адаптеры LoRA — это специализированные компоненты нейронной сети, которые оптимизируют модель для различных задач, таких как поиск, классификация или кластеризация, без значительного увеличения количества параметров — они добавляют менее 3% к общему количеству параметров. Модель включает в себя Matryoshka Representation Learning (MRL), что позволяет гибко сокращать встраивания с 1024 до 32 измерений, сохраняя производительность. Обучение включало трехэтапный процесс: начальное предварительное обучение на многоязычном тексте из 89 языков, тонкую настройку на парных текстах для качества встраивания и специализированное обучение адаптера для оптимизации задач. Модель поддерживает длину контекста до 8192 токенов с помощью Rotary Position Embeddings (RoPE) с инновационной методикой регулировки базовой частоты, которая повышает производительность как для коротких, так и для длинных текстов.","jina-reranker-v1-base-en":"Модель использует архитектуру перекрестного внимания на основе BERT, которая принципиально отличается от традиционных подходов на основе встраивания. Вместо сравнения предварительно вычисленных встраиваний документов она выполняет динамические взаимодействия на уровне токенов между запросами и документами, что позволяет ей улавливать контекстные нюансы, которые упускают простые метрики сходства. 137 млн параметров архитектуры тщательно структурированы для обеспечения глубокого семантического понимания при сохранении вычислительной эффективности. Выдающимся нововведением является ее способность обрабатывать последовательности до 262 144 токенов — намного превышая типичные ограничения модели — достигаемая с помощью сложных методов оптимизации, которые поддерживают высокую скорость вывода, несмотря на увеличенное контекстное окно.","jina-reranker-v1-tiny-en":"Модель использует оптимизированную четырехслойную архитектуру на основе JinaBERT с симметричным двунаправленным ALiBi (Attention with Linear Biases), что позволяет эффективно обрабатывать длинные последовательности. Ее разработка использует продвинутый подход к дистилляции знаний, где более крупная, высокопроизводительная модель учителя (jina-reranker-v1-base-en) направляет процесс обучения, позволяя меньшей модели изучать оптимальное поведение ранжирования без необходимости в обширных реальных данных обучения. Эта инновационная методология обучения в сочетании с архитектурными оптимизациями, такими как сокращение скрытых слоев и эффективные механизмы внимания, позволяет модели поддерживать высококачественные ранжирования при значительном снижении вычислительных требований. Результатом является модель, которая достигает замечательной эффективности без ущерба для ее способности понимать сложные взаимосвязи документов.","jina-reranker-v1-turbo-en":"Модель достигает своей эффективности за счет инновационной шестислойной архитектуры, которая сжимает сложные возможности переранжирования своего более крупного аналога всего в 37,8 миллионов параметров — резкое сокращение по сравнению с 137 миллионами базовой модели. Эта оптимизированная конструкция использует дистилляцию знаний, где более крупная базовая модель действует как учитель, обучая турбо-вариант соответствовать своему поведению, используя меньше ресурсов. Архитектура поддерживает основной механизм перекрестного внимания на основе BERT для взаимодействия на уровне токенов между запросами и документами, но оптимизирует его для скорости за счет сокращения количества слоев и эффективного распределения параметров. Модель поддерживает последовательности до 8192 токенов, обеспечивая комплексный анализ документов, сохраняя при этом высокую скорость вывода за счет сложных методов оптимизации.","jina-reranker-v2-base-multilingual":"Модель использует архитектуру кросс-кодировщика, улучшенную с помощью Flash Attention 2, что позволяет напрямую сравнивать запросы и документы для более точной оценки релевантности. Обученная с помощью четырехэтапного процесса, модель сначала устанавливает возможности английского языка, затем постепенно включает кросс-языковые и многоязычные данные, перед окончательной доработкой с помощью жестких отрицательных примеров. Этот инновационный подход к обучению в сочетании с реализацией Flash Attention 2 позволяет модели обрабатывать последовательности до 524 288 токенов, сохраняя при этом исключительную скорость. Эффективность архитектуры позволяет ей справляться со сложными задачами переранжирования на нескольких языках с пропускной способностью в 6 раз выше по сравнению с ее предшественником, обеспечивая при этом точную оценку релевантности посредством прямого взаимодействия запроса и документа.","reader-lm-05b":"Модель использует инновационную архитектуру «неглубокая, но широкая», специально оптимизированную для операций выборочного копирования, а не для творческой генерации текста. Созданная на основе только декодера с 24 слоями и 896 скрытыми измерениями, модель использует специализированные механизмы внимания с 14 головками запросов и 2 головками ключ-значение для эффективной обработки входных последовательностей. Процесс обучения включал два отдельных этапа: сначала с более коротким, более простым HTML (32K токенов) для изучения основных шаблонов преобразования, затем со сложным, реальным HTML (128K токенов) для обработки сложных случаев. Модель включает в себя контрастный поиск во время обучения и реализует механизм обнаружения повторений для предотвращения проблем вырождения, таких как циклы токенов. Уникальным аспектом ее архитектуры является механизм зигзагообразного кольца-внимания, который позволяет модели обрабатывать чрезвычайно длинные последовательности до 256K токенов, сохраняя при этом стабильную производительность.","reader-lm-15b":"Модель использует инновационную архитектуру «неглубокая, но широкая», которая бросает вызов традиционным подходам к масштабированию в разработке языковой модели. В ее основе лежат 28 слоев преобразователя, настроенных с 12 головками запросов и 2 головками ключ-значение, что создает уникальный баланс, который оптимизирует операции выборочного копирования, сохраняя при этом глубокое семантическое понимание. Архитектура имеет скрытый размер 1536 и промежуточный размер 8960, тщательно настроенные для обработки последовательностей до 256 тыс. токенов. Процесс обучения включал два отдельных этапа: сначала фокусировка на коротком и простом HTML с последовательностями из 32 тыс. токенов, затем переход к длинному и сложному HTML с 128 тыс. токенов, реализация зигзагообразного кольца-внимания для эффективной обработки. Этот подход в сочетании с контрастным поиском и специализированными механизмами обнаружения повторений позволяет модели избегать распространенных проблем, таких как вырождение и скучные циклы, которые обычно мешают небольшим языковым моделям обрабатывать сложные задачи обработки документов.",title:"Методы"},model_comparison:"Сравнение моделей",model_details:"Подробности модели",model_io_graph:"График ввода-вывода {_number}",model_name:"Имя",output_dimension:"Выходной размер",overview:{"ReaderLM-v2":"ReaderLM-v2 — это языковая модель с 1,5 млрд параметров, которая преобразует необработанный HTML в markdown или JSON, обрабатывая до 512 тыс. токенов общей длины ввода/вывода с поддержкой 29 языков. В отличие от своего предшественника, который рассматривал HTML-в-markdown как задачу «выборочного копирования», v2 рассматривает его как процесс перевода, обеспечивая превосходную обработку сложных элементов, таких как кодовые ограждения, вложенные списки, таблицы и уравнения LaTeX. Модель поддерживает постоянную производительность при различной длине контекста и вводит возможности прямой генерации HTML-в-JSON с предопределенными схемами.","jina-clip-v1":"Jina CLIP v1 производит революцию в мультимодальном ИИ, став первой моделью, которая одинаково хорошо справляется как с задачами поиска текста в текст, так и с задачами поиска текста в изображение. В отличие от традиционных моделей CLIP, которые испытывают трудности с текстовыми сценариями, эта модель достигает высочайшей производительности во всех комбинациях поиска, сохраняя при этом удивительно компактный размер параметра 223M. Модель решает важнейшую отраслевую задачу, устраняя необходимость в отдельных моделях для обработки текста и изображений, снижая сложность системы и вычислительные издержки. Для команд, создающих поисковые системы, рекомендательные системы или инструменты анализа контента, Jina CLIP v1 предлагает единое эффективное решение, которое обрабатывает как текст, так и визуальный контент с исключительной точностью.","jina-clip-v2":"Jina CLIP v2 производит революцию в мультимодальном ИИ, преодолевая разрыв между визуальным и текстовым пониманием на 89 языках. Эта модель решает критические проблемы в глобальной электронной коммерции, управлении контентом и межкультурной коммуникации, обеспечивая точное сопоставление изображений и текста независимо от языковых барьеров. Для компаний, расширяющихся на международном уровне или управляющих многоязычным контентом, она устраняет необходимость в отдельных моделях для каждого языка или сложных конвейерах перевода. Модель особенно хороша в сценариях, требующих точного визуального поиска через языковые границы, таких как обнаружение продуктов на глобальном рынке или многоязычное управление цифровыми активами.","jina-colbert-v1-en":"Jina-ColBERT-v1-en производит революцию в текстовом поиске, решая критическую задачу в поиске информации: достижение высокой точности без ущерба для вычислительной эффективности. В отличие от традиционных моделей, которые сжимают целые документы в отдельные векторы, эта модель поддерживает точное понимание на уровне токенов, требуя всего 137 млн параметров. Для команд, создающих поисковые приложения, рекомендательные системы или платформы обнаружения контента, Jina-ColBERT-v1-en устраняет традиционный компромисс между качеством поиска и производительностью системы. Модель особенно хороша в сценариях, где решающее значение имеет тонкое понимание текста, например, поиск технической документации, поиск академических статей или любое приложение, где захват тонких семантических связей может иметь значение между поиском нужной информации и потерей критически важного контента.","jina-colbert-v2":"Jina-ColBERT-v2 — это новаторская многоязычная модель поиска информации, которая решает критическую задачу эффективного, высококачественного поиска на нескольких языках. Как первая многоязычная модель ColBERT, которая генерирует компактные вложения, она удовлетворяет растущую потребность в масштабируемых, экономически эффективных многоязычных поисковых решениях в глобальных приложениях. Организации, работающие с многоязычным контентом, от платформ электронной коммерции до систем управления контентом, могут использовать эту модель для предоставления точных результатов поиска на 89 языках, при этом значительно сокращая затраты на хранение и вычисления благодаря ее инновационным возможностям сокращения размерности.","jina-embedding-b-en-v1":"Jina Embedding B v1 — это специализированная модель встраивания текста, разработанная для преобразования английского текста в многомерные числовые представления с сохранением семантического значения. Модель удовлетворяет критическую потребность в эффективных и точных встраиваниях текста в производственных средах, что особенно ценно для организаций, которым требуется баланс между вычислительной эффективностью и качеством встраивания. Благодаря 110 млн параметров, генерирующих 768-мерные встраивания, она служит практическим решением для групп, внедряющих семантический поиск, кластеризацию документов или системы рекомендаций по контенту, не требуя при этом значительных вычислительных ресурсов.","jina-embeddings-v2-base-code":"Jina Embeddings v2 Base Code решает важнейшую задачу в современной разработке программного обеспечения: эффективное перемещение и понимание больших кодовых баз. Для команд разработчиков, которые борются с обнаружением и документированием кода, эта модель преобразует то, как разработчики взаимодействуют с кодом, обеспечивая поиск на естественном языке по 30 языкам программирования. В отличие от традиционных инструментов поиска кода, которые полагаются на точное сопоставление с образцом, эта модель понимает семантическое значение кода, позволяя разработчикам находить соответствующие фрагменты кода с помощью описаний на простом английском языке. Эта возможность особенно ценна для команд, поддерживающих большие устаревшие кодовые базы, разработчиков, подключающихся к новым проектам, или организаций, стремящихся улучшить методы повторного использования и документирования кода.","jina-embeddings-v2-base-de":"Jina Embeddings v2 Base German решает важную задачу в международном бизнесе: преодоление языкового разрыва между немецким и английским рынками. Для немецких компаний, выходящих на англоязычные территории, где треть предприятий генерирует более 20% своих мировых продаж, точное двуязычное понимание имеет важное значение. Эта модель преобразует то, как организации обрабатывают кросс-языковой контент, обеспечивая бесперебойное понимание и поиск текста как на немецком, так и на английском языках, что делает ее бесценной для компаний, внедряющих международные системы документирования, платформы поддержки клиентов или решения по управлению контентом. В отличие от традиционных подходов, основанных на переводе, эта модель напрямую сопоставляет эквивалентные значения на обоих языках с одним и тем же пространством встраивания, обеспечивая более точные и эффективные двуязычные операции.","jina-embeddings-v2-base-en":"Jina Embeddings v2 Base English — это новаторская модель встраивания текста с открытым исходным кодом, которая решает критическую задачу обработки длинных документов, сохраняя при этом высокую точность. Организации, испытывающие трудности с анализом обширных юридических документов, исследовательских работ или финансовых отчетов, найдут эту модель особенно ценной. Она выделяется тем, что обрабатывает документы длиной до 8192 токенов — в 16 раз больше, чем традиционные модели — и при этом соответствует производительности фирменных решений OpenAI. Благодаря компактному размеру 0,27 ГБ и эффективному использованию ресурсов она предлагает доступное решение для групп, стремящихся реализовать расширенный анализ документов без чрезмерных вычислительных затрат.","jina-embeddings-v2-base-es":"Jina Embeddings v2 Base Spanish — это новаторская модель встраивания двуязычного текста, которая решает критическую задачу кросс-языкового поиска и анализа информации между испанским и английским контентом. В отличие от традиционных многоязычных моделей, которые часто демонстрируют предвзятость в отношении определенных языков, эта модель обеспечивает действительно сбалансированную производительность как на испанском, так и на английском языках, что делает ее незаменимой для организаций, работающих на испаноязычных рынках или обрабатывающих двуязычный контент. Наиболее примечательной особенностью модели является ее способность генерировать геометрически выровненные встраивания — когда тексты на испанском и английском языках выражают одно и то же значение, их векторные представления естественным образом группируются вместе в пространстве встраивания, обеспечивая бесшовный кросс-языковой поиск и анализ.","jina-embeddings-v2-base-zh":"Jina Embeddings v2 Base Chinese открывает новые горизонты как первая модель с открытым исходным кодом, которая легко обрабатывает как китайский, так и английский текст с беспрецедентной длиной контекста в 8192 маркера. Этот двуязычный источник решает важнейшую задачу в глобальном бизнесе: необходимость точной обработки длинных документов в китайском и английском контенте. В отличие от традиционных моделей, которые испытывают трудности с кросс-языковым пониманием или требуют отдельных моделей для каждого языка, эта модель сопоставляет эквивалентные значения на обоих языках с одним и тем же пространством встраивания, что делает ее бесценной для организаций, расширяющихся глобально или управляющих многоязычным контентом.","jina-embeddings-v3":"Jina Embeddings v3 — это новаторская многоязычная модель встраивания текста, которая преобразует то, как организации справляются с пониманием и поиском текста на разных языках. По своей сути, она решает критическую задачу поддержания высокой производительности на разных языках и задачах, сохраняя при этом управляемость вычислительных требований. Модель особенно блестит в производственных средах, где важна эффективность — она достигает самой современной производительности всего с 570 млн параметров, что делает ее доступной для команд, которые не могут позволить себе вычислительные издержки более крупных моделей. Организации, которым необходимо создавать масштабируемые многоязычные поисковые системы или анализировать контент, несмотря на языковые барьеры, найдут эту модель особенно ценной.","jina-reranker-v1-base-en":"Jina Reranker v1 Base English производит революцию в уточнении результатов поиска, устраняя критическое ограничение в традиционных системах векторного поиска: невозможность улавливать тонкие связи между запросами и документами. Хотя векторный поиск с косинусным сходством обеспечивает быстрые начальные результаты, он часто пропускает тонкие сигналы релевантности, которые интуитивно понимают пользователи-люди. Этот рераннер устраняет этот пробел, выполняя сложный анализ на уровне токенов как запросов, так и документов, обеспечивая замечательное улучшение точности поиска на 20%. Для организаций, борющихся с точностью поиска или внедряющих системы RAG, эта модель предлагает мощное решение, которое значительно улучшает качество результатов, не требуя полной перестройки существующей инфраструктуры поиска.","jina-reranker-v1-tiny-en":"Jina Reranker v1 Tiny English представляет собой прорыв в эффективном уточнении поиска, разработанный специально для организаций, которым требуется высокопроизводительное повторное ранжирование в средах с ограниченными ресурсами. Эта модель решает критическую задачу поддержания качества поиска, при этом значительно сокращая вычислительные накладные расходы и затраты на развертывание. Имея всего 33 млн параметров — часть типичных размеров реранжера — он обеспечивает исключительно конкурентоспособную производительность за счет инновационных методов извлечения знаний. Самая удивительная особенность модели — ее способность обрабатывать документы почти в пять раз быстрее, чем базовые модели, сохраняя при этом более 92% их точности, что делает уточнение поиска корпоративного уровня доступным для приложений, где вычислительные ресурсы имеют первостепенное значение.","jina-reranker-v1-turbo-en":"Jina Reranker v1 Turbo English решает критическую проблему в системах производственного поиска: компромисс между качеством результата и вычислительной эффективностью. Хотя традиционные переранжеры обеспечивают улучшенную точность поиска, их вычислительные требования часто делают их непрактичными для приложений реального времени. Эта модель преодолевает этот барьер, обеспечивая 95% точности базовой модели, обрабатывая документы в три раза быстрее и используя на 75% меньше памяти. Для организаций, борющихся с задержкой поиска или вычислительными затратами, эта модель предлагает убедительное решение, которое поддерживает высококачественное уточнение поиска, при этом значительно снижая требования к инфраструктуре и эксплуатационные расходы.","jina-reranker-v2-base-multilingual":"Jina Reranker v2 Base Multilingual — это модель кросс-кодировщика, разработанная для повышения точности поиска вне зависимости от языковых барьеров и типов данных. Этот реранкер решает критическую задачу точного поиска информации в многоязычных средах, что особенно ценно для глобальных предприятий, которым необходимо уточнять результаты поиска по разным языкам и типам контента. Благодаря поддержке более 100 языков и уникальным возможностям вызова функций и поиска кода он служит унифицированным решением для групп, которым требуется точное уточнение поиска по международному контенту, документации API и многоязычным кодовым базам. Компактная конструкция модели с 278 млн параметров делает ее особенно привлекательной для организаций, стремящихся сбалансировать высокую производительность с эффективностью использования ресурсов.","reader-lm-05b":"Reader LM 0.5B — это специализированная языковая модель, разработанная для решения сложной задачи преобразования HTML-документов в чистый, структурированный текст markdown. Эта модель решает критическую потребность в современных конвейерах обработки данных: эффективное преобразование беспорядочного веб-контента в формат, который идеально подходит для LLM и систем документирования. В отличие от универсальных языковых моделей, требующих огромных вычислительных ресурсов, Reader LM 0.5B достигает обработки HTML профессионального уровня всего с 494 млн параметров, что делает ее доступной для групп с ограниченными вычислительными ресурсами. Организации, занимающиеся обработкой веб-контента, автоматизацией документации или созданием приложений на базе LLM, найдут эту модель особенно ценной для оптимизации рабочих процессов подготовки контента.","reader-lm-15b":"Reader LM 1.5B представляет собой прорыв в эффективной обработке документов, решая критическую задачу преобразования сложного веб-контента в чистые, структурированные форматы. Эта специализированная языковая модель решает фундаментальную проблему современных конвейеров ИИ: необходимость эффективной обработки и очистки HTML-контента для последующих задач без использования хрупких систем на основе правил или ресурсоемких больших языковых моделей. Что делает эту модель по-настоящему замечательной, так это ее способность превосходить модели в 50 раз по размеру, сохраняя при этом удивительно компактный размер параметров в 1,54 млрд. Организации, занимающиеся крупномасштабной обработкой веб-контента, автоматизацией документации или системами управления контентом, найдут эту модель особенно ценной из-за ее способности обрабатывать чрезвычайно длинные документы, обеспечивая при этом превосходную точность преобразования HTML в разметку.",title:"Обзор"},parameter_size:"Параметры",performance:{"ReaderLM-v2":"В комплексных тестах ReaderLM-v2 превосходит более крупные модели, такие как Qwen2.5-32B-Instruct и Gemini2-flash-expr, в задачах HTML-to-Markdown. Для извлечения основного контента он достигает ROUGE-L 0,84, Jaro-Winkler 0,82 и значительно меньшего расстояния Левенштейна (0,22) по сравнению с конкурентами. В задачах HTML-to-JSON он сохраняет конкурентоспособную производительность с оценками F1 0,81 и 98% проходным баллом. Модель обрабатывает 67 токенов/с на входе и 36 токенов/с на выходе на T4 GPU, со значительно уменьшенными проблемами вырождения за счет обучения с контрастными потерями.","jina-clip-v1":"Jina CLIP v1 демонстрирует значительные улучшения по сравнению с оригинальным CLIP OpenAI во всех тестах. В поиске только текста он достигает 165% прироста производительности с результатом 0,429 по сравнению с 0,162 у CLIP. Для задач, связанных с изображениями, он показывает последовательные улучшения: на 2% лучше в поиске текста в изображение (0,899), на 6% в поиске изображения в текст (0,803) и на 12% в поиске изображения в изображение (0,916). Модель особенно хороша в задачах визуальной классификации с нулевого выстрела, успешно классифицируя изображения без предварительного обучения по определенным доменам. При оценке по стандартным тестам, таким как MTEB для поиска текста, CIFAR-100 для задач с изображениями, а также Flickr8k/30k и MSCOCO Captions для кросс-модальной производительности, он неизменно превосходит специализированные одномодальные модели, сохраняя при этом конкурентоспособную производительность в кросс-модальных задачах.","jina-clip-v2":"Модель достигает самой современной производительности с точностью 98,0% в задачах поиска изображений в текст Flickr30k, превосходя как своего предшественника, так и NLLB-CLIP-SigLIP. В многоязычных сценариях она демонстрирует улучшение до 4% по сравнению с NLLB-CLIP-SigLIP в кросс-языковых задачах поиска изображений, несмотря на то, что имеет меньше параметров, чем ее крупнейший конкурент. Модель сохраняет высокую производительность даже при сжатии вложений — уменьшение размеров на 75% по-прежнему сохраняет более 99% производительности в текстовых, графических и кросс-модальных задачах. В комплексных многоязычных бенчмарках MTEB она достигает 69,86% в задачах поиска и 67,77% в задачах семантического сходства, выступая на равных со специализированными моделями встраивания текста.","jina-colbert-v1-en":"Jina-ColBERT-v1-en демонстрирует значительные улучшения по сравнению с базовыми моделями в различных тестах. В коллекции наборов данных BEIR он достигает превосходной производительности в нескольких категориях: 49,4% на Arguana (против 46,5% для ColBERTv2), 79,5% на FEVER (против 78,8%) и 75,0% на TREC-COVID (против 72,6%). Что наиболее впечатляюще, он показывает резкое улучшение на тесте LoCo для понимания длинного контекста, набрав 83,7% по сравнению с 74,3% у ColBERTv2. Модель особенно преуспевает в сценариях, требующих детального семантического понимания, превосходя традиционные модели встраивания, сохраняя вычислительную эффективность благодаря своему инновационному подходу позднего взаимодействия. Эти улучшения достигаются при сохранении количества параметров модели на скромном уровне 137 млн, что делает ее одновременно мощной и практичной для производственных развертываний.","jina-colbert-v2":"В реальных тестах Jina-ColBERT-v2 демонстрирует исключительные возможности в нескольких тестах. Он достигает 6,5% улучшения по сравнению с оригинальным ColBERT-v2 в задачах на английском языке, со средним баллом 0,521 по 14 тестам BEIR. Что еще более впечатляюще, он превосходит традиционные методы поиска на основе BM25 по всем протестированным языкам в тестах MIRACL, показывая особую силу в кросс-языковых сценариях. Модель сохраняет эту высокую производительность даже при использовании сокращенных измерений встраивания — снижение со 128 до 64 измерений приводит всего к 1,5% снижению производительности при сокращении вдвое требований к хранению. Это приводит к значительной экономии затрат в производстве: например, хранение 100 миллионов документов с 64-мерными векторами стоит 659,62 долл. США в месяц на AWS по сравнению с 1319,24 долл. США для 128 измерений.","jina-embedding-b-en-v1":"В реальных оценках Jina Embedding B v1 демонстрирует впечатляющие возможности, особенно в задачах семантического текстового сходства. Модель достигает самой современной производительности на STS12 с результатом 0,751, превосходя такие устоявшиеся модели, как all-mpnet-base-v2 и all-minilm-l6-v2. Она показывает высокую производительность в различных тестах, сохраняя при этом эффективное время вывода. Однако пользователи должны учитывать, что модель специально оптимизирована для англоязычного контента и может не работать оптимально на многоязычных или специфичных для кода задачах. С тех пор модель была заменена на jina-embeddings-v2-base-en и jina-embeddings-v3, которые предлагают улучшенную производительность в более широком диапазоне вариантов использования.","jina-embeddings-v2-base-code":"В реальных тестах Jina Embeddings v2 Base Code демонстрирует исключительные возможности, лидируя в девяти из пятнадцати важнейших тестов CodeNetSearch. По сравнению с моделями от таких гигантов отрасли, как Microsoft и Salesforce, он достигает превосходной производительности, сохраняя при этом более эффективный след. Модель особенно выделяется в межъязыковом понимании кода, успешно сопоставляя функционально эквивалентные фрагменты кода на разных языках программирования. Его контекстное окно из 8192 токенов оказывается особенно ценным для больших функций и сложных файлов кода, значительно превосходя традиционные модели, которые обычно обрабатывают всего несколько сотен токенов. Эффективность модели очевидна в ее компактном размере 307 МБ (неквантованный), что позволяет быстро делать выводы, сохраняя высокую точность в задачах сходства кода и поиска.","jina-embeddings-v2-base-de":"В реальных тестах Jina Embeddings v2 Base German демонстрирует исключительную эффективность и точность, особенно в задачах поиска между языками. Модель превосходит базовую модель E5 от Microsoft, будучи менее чем в треть от ее размера, и соответствует производительности E5 large, несмотря на то, что она в семь раз меньше. В ключевых тестах, включая WikiCLIR для поиска с английского на немецкий, STS17 и STS22 для двунаправленного понимания языка и BUCC для точного двуязычного выравнивания текста, модель постоянно демонстрирует превосходные возможности. Ее компактный размер 322 МБ позволяет развертывать ее на стандартном оборудовании, сохраняя при этом самую современную производительность, что делает ее особенно эффективной для производственных сред, где вычислительные ресурсы являются важным фактором.","jina-embeddings-v2-base-en":"В реальных тестах Jina Embeddings v2 Base English демонстрирует исключительные возможности в нескольких бенчмарках. Он превосходит text-embedding-ada-002 от OpenAI по нескольким ключевым показателям: классификация (73,45% против 70,93%), переранжирование (85,38% против 84,89%), поиск (56,98% против 56,32%) и резюмирование (31,6% против 30,8%). Эти цифры транслируются в практические преимущества в таких задачах, как классификация документов, где модель демонстрирует превосходную способность категоризировать сложные тексты, и в поисковых приложениях, где она лучше понимает запросы пользователей и находит релевантные документы. Однако пользователи должны учитывать, что производительность может меняться при работе с узкоспециализированным доменно-специфическим контентом, не представленным в обучающих данных.","jina-embeddings-v2-base-es":"В комплексных бенчмарк-оценках модель демонстрирует исключительные возможности, особенно в задачах поиска на разных языках, где она превосходит значительно более крупные многоязычные модели, такие как E5 и BGE-M3, несмотря на то, что составляет всего 15–30 % от их размера. Модель достигает превосходной производительности в задачах поиска и кластеризации, демонстрируя особую силу в сопоставлении семантически эквивалентного контента на разных языках. При тестировании на бенчмарке MTEB она демонстрирует надежную производительность в различных задачах, включая классификацию, кластеризацию и семантическую схожесть. Расширенное контекстное окно из 8192 токенов оказывается особенно ценным для обработки длинных документов, демонстрируя стабильную производительность даже с документами, охватывающими несколько страниц — возможность, которой не хватает большинству конкурирующих моделей.","jina-embeddings-v2-base-zh":"В бенчмарках на китайском рейтинге MTEB (C-MTEB) модель демонстрирует исключительную производительность среди моделей размером менее 0,5 ГБ, особенно преуспев в задачах на китайском языке. Она значительно превосходит text-embedding-ada-002 от OpenAI в приложениях, специфичных для китайского языка, при этом сохраняя конкурентоспособную производительность в задачах на английском языке. Заметным улучшением в этом выпуске является уточненное распределение оценок сходства, устраняющее проблемы инфляции оценок, присутствующие в предварительной версии. Теперь модель предоставляет более четкие и логичные оценки сходства, обеспечивая более точное представление семантических связей между текстами. Это улучшение особенно очевидно в сравнительных тестах, где модель демонстрирует превосходное различение между связанным и не связанным контентом на обоих языках.","jina-embeddings-v3":"Модель демонстрирует исключительное соотношение эффективности и производительности в реальных тестах, превосходя как альтернативы с открытым исходным кодом, так и фирменные решения от OpenAI и Cohere в задачах на английском языке, при этом превосходя в многоязычных сценариях. Самое удивительное, что она достигает лучших результатов, чем e5-mistral-7b-instruct, которая имеет в 12 раз больше параметров, что подчеркивает ее замечательную эффективность. В оценках MTEB она достигает среднего балла 65,52 по всем задачам, с особенно высокими показателями точности классификации (82,58) и сходства предложений (85,80). Модель сохраняет стабильную производительность на разных языках, набрав 64,44 балла на многоязычных задачах. При использовании MRL для сокращения размерности она сохраняет высокую производительность даже в более низких размерностях - например, сохраняя 92% своей производительности поиска при 64 измерениях по сравнению с полными 1024 измерениями.","jina-reranker-v1-base-en":"В комплексных бенчмарках модель демонстрирует исключительные улучшения по ключевым показателям, достигая 8%-ного увеличения частоты попаданий и 33%-ного увеличения среднего обратного ранга по сравнению с базовым векторным поиском. В бенчмарке BEIR она достигает среднего балла 0,5588, превосходя другие реранжеры от BGE (0,5032), BCE (0,4969) и Cohere (0,5141). Особенно впечатляет ее производительность в бенчмарке LoCo, где она набирает 0,873 в среднем, значительно опережая конкурентов в понимании локальной согласованности и контекстно-зависимом ранжировании. Модель демонстрирует особую силу в оценке технического контента, достигая баллов 0,996 по задачам qasper_abstract и 0,962 по анализу правительственных отчетов, хотя она показывает относительно более низкую производительность (0,466) при выполнении задач резюмирования.","jina-reranker-v1-tiny-en":"В комплексных оценках бенчмарков модель демонстрирует исключительные возможности, которые бросают вызов традиционному компромиссу между размером и производительностью. В бенчмарке BEIR она достигает оценки NDCG-10 48,54, сохраняя 92,5% производительности базовой модели, будучи всего в четверть от ее размера. Еще более впечатляюще, в бенчмарках LlamaIndex RAG она сохраняет 83,16% попаданий, почти соответствуя более крупным моделям, при этом обрабатывая документы значительно быстрее. Модель особенно выделяется по пропускной способности, обрабатывая документы почти в пять раз быстрее базовой модели, используя на 13% меньше памяти, чем даже турбо-вариант. Эти показатели соответствуют реальной производительности, которая соперничает или превосходит гораздо более крупные модели, такие как mxbai-rerank-base-v1 (184M параметров) и bge-reranker-base (278M параметров).","jina-reranker-v1-turbo-en":"В комплексных тестах турбо-вариант демонстрирует замечательную эффективность без значительных компромиссов в отношении точности. В тесте BEIR он достигает оценки NDCC-10 49,60, сохраняя 95% производительности базовой модели (52,45), при этом превосходя многих более крупных конкурентов, таких как bge-reranker-base (47,89, 278M параметров). В приложениях RAG он сохраняет впечатляющий процент попаданий 83,51% и 0,6498 MRR, демонстрируя особую силу в практических задачах поиска. Улучшения скорости модели еще более поразительны — она обрабатывает документы в три раза быстрее, чем базовая модель, с пропускной способностью, масштабируемой почти линейно с уменьшенным количеством параметров. Однако пользователи должны отметить немного более низкую производительность в чрезвычайно тонких задачах ранжирования, где полное количество параметров более крупных моделей обеспечивает незначительные преимущества.","jina-reranker-v2-base-multilingual":"В реальных оценках модель демонстрирует исключительные возможности в различных бенчмарках. Она достигает самой современной производительности в таблице лидеров AirBench для систем RAG и показывает высокие результаты в многоязычных задачах, включая набор данных MKQA, охватывающий 26 языков. Модель особенно выделяется в задачах со структурированными данными, достигая высоких оценок полноты как при вызове функций (бенчмарк ToolBench), так и при сопоставлении схем SQL (бенчмарк NSText2SQL). Самое впечатляющее, что она обеспечивает эти результаты при обработке документов в 15 раз быстрее, чем сопоставимые модели, такие как bge-reranker-v2-m3, что делает ее практичной для приложений реального времени. Однако пользователи должны учитывать, что для оптимальной производительности требуется графический процессор с поддержкой CUDA для вывода.","reader-lm-05b":"В реальных тестах Reader LM 0.5B демонстрирует впечатляющие соотношения эффективности и производительности по нескольким показателям. Модель достигает оценки ROUGE-L 0,56, что указывает на надежное сохранение контента, и поддерживает низкий уровень ошибок токенов 0,34, показывая минимальную галлюцинацию. В качественных оценках по 22 различным источникам HTML, включая новостные статьи, записи в блогах и страницы электронной коммерции на нескольких языках, она показывает особую силу в сохранении структуры и использовании синтаксиса markdown. Модель отлично справляется с обработкой сложных современных веб-страниц, где встроенные CSS и скрипты могут расширяться до сотен тысяч токенов — сценарий, в котором традиционные подходы на основе правил часто терпят неудачу. Однако важно отметить, что, хотя модель исключительно хорошо выполняет простые задачи преобразования HTML в markdown, для высокодинамичных или насыщенных JavaScript страниц может потребоваться дополнительная обработка.","reader-lm-15b":"В комплексных бенчмарк-оценках Reader LM 1.5B демонстрирует исключительные возможности, бросающие вызов отраслевым стандартам. Модель достигает оценки ROUGE-L 0,72 и коэффициента ошибок токенов 0,19, значительно превосходя более крупные модели, такие как GPT-4 (0,43 ROUGE-L, 0,50 TER) и Gemini-1.5-Pro (0,42 ROUGE-L, 0,48 TER) в задачах преобразования HTML в разметку. Ее производительность особенно блестит в качественных оценках по четырем ключевым измерениям: извлечение заголовка, извлечение основного контента, сохранение расширенной структуры и использование синтаксиса разметки. Модель постоянно поддерживает высокую точность для различных типов документов, от новостных статей и сообщений в блогах до целевых страниц и сообщений на форумах, на нескольких языках, включая английский, немецкий, японский и китайский. Такая производительность достигается при обработке документов длиной до 256 тыс. токенов, что устраняет необходимость в дорогостоящих операциях по фрагментации, которые обычно требуются для более крупных моделей.",title:"Производительность"},performance_metrics:"Показатели производительности",publications:"Публикации",tags:"Теги",token_length:"Длина входного токена",usage_requirements:"Использование и требования",using_model:"Доступно через"},select_model:"Выберите модель из списка, чтобы просмотреть подробности",sort:{direction:{asc:"По возрастанию",desc:"По убыванию",name:"Направление"},label:"Сортировать",name:"Имя",parameter_size:"Размер",release_date:"Дата"},title:"{_modelName} - Поиск моделей фундамента",warnings:{deprecated:"Эта модель устарела из-за появления новых моделей."}},ne={back_to_newsroom:"Назад в отдел новостей",categories:"Категории",copy_link:"Скопируйте ссылку на этот раздел",in_this_article:"В этой статье",learn_more:"Узнать больше",news_not_found:"Статья не найдена",redirect_to_news:"Перенаправление в редакцию через 5 секунд..."},ae={academic:"Академический",academic_research:"Академические публикации",author:"Фильтровать по автору",description:"Читайте последние новости и обновления от Jina AI.",description1:"Создание инноваций в области ИИ, одно слово за раз.",engineering_group:"Инженерная группа",engineering_group_date:"31 мая 2021 г.",minutes_read:"минуты чтения",most_recent_articles:"Последние статьи",news_description:"Для Jina 2.0 мы прислушались к сообществу. Верно, глубоко выслушал. «Каковы ваши болевые точки?» — спросили мы, с нетерпением ожидая ценных отзывов.",news_title:"Искать все: мы проводим конкурс MEME для Jina 2.0",photos:"Фото",product:"Фильтровать по продукту",search:"Поиск по названию",tech_blog:"Технический блог",title:"отдел новостей",top_stories:"Главные новости"},ie="🎉 Сегодня официально вышла наша первая книга «Нейронный поиск — от прототипа к производству с Джиной»!",te={description:"Эксклюзивная возможность получить представление о Jina AI изнутри.",engage:"Мы настоятельно рекомендуем интерактивный диалог в течение дня. Обмен мыслями и взглядами бесценен для нас. Потенциальное сотрудничество, вытекающее из этих дискуссий, могло бы внести значительный вклад в более интегрированное и инновационное будущее.",engage_title:"Взаимодействуйте с нами",experience:"Мы организовали для наших гостей трехчасовую иммерсивную экскурсию, доступную на немецком, английском, французском, испанском, китайском и русском языках. Экскурсия охватывает углубленный взгляд на наши достижения в области мультимодального ИИ, нашу точку зрения на ландшафт ИИ, после чего следует подробное изучение конкретных проектов. Мы завершим обсуждение групповым обсуждением, чтобы облегчить обмен идеями и идеями. Обед также предоставляется по запросу.",experience_title:"Путешествие инсайдера",group_size:"Предполагаемое количество посетителей",impact:"Узнайте, как наш вклад в сообщество с открытым исходным кодом и наша работа в области мультимодальных технологий искусственного интеллекта делают Jina AI влиятельным игроком в области инноваций в области искусственного интеллекта. Мы стремимся играть важную роль в процессах принятия решений, гарантируя, что развитие технологий искусственного интеллекта принесет пользу всем.",impact_title:"Воздействие и влияние",introduction:"Jina AI рада открыть наши двери для уважаемых лиц и организаций, заинтересованных в прогрессе и будущем искусственного интеллекта. Мы предоставляем эту эксклюзивную возможность тем, кто занимается политикой, НКО, НКО и инвестиционным сектором, чтобы получить инсайдерскую информацию о нашей деятельности и видении здесь, в нашей штаб-квартире в Берлине.",motivation_min_length_v1:"Пожалуйста, предоставьте более подробную мотивацию.",motivation_placeholder_v2:"Если вы поделитесь своими мотивами, это поможет нам улучшить ваш опыт.",motivation_to_attend_v2:"Почему вам интересен наш День открытых дверей?",one_hour:"1 час",organization:"Организация",organization_website:"Сайт организации",organization_website_placeholder:"URL-адрес домашней страницы вашей организации или профиля LinkedIn.",preferred_date:"Желаемая дата",preferred_language:"Предпочтительный язык тура",preferred_products:"Какие продукты вас интересуют?",subtitle:"Взгляд в будущее мультимодального ИИ",title:"День открытых дверей",tutor_subtitle:"Тщательно подобранный трехчасовой тур, который приблизит вас к сердцу новаторской работы Jina AI в области мультимодальной технологии искусственного интеллекта.",tutor_title:"Эксклюзивное глубокое погружение в",vision:"Присоединяйтесь к нам, чтобы получить исчерпывающий обзор ландшафта ИИ, каким мы его видим. Наше обсуждение будет сосредоточено на потенциале больших языковых моделей, мультимодального ИИ и влиянии технологий с открытым исходным кодом на формирование будущего глобальных инноваций.",vision_title:"Наше видение будущего"},re={answer1:"Мы предлагаем туры на немецком, английском, французском, испанском, китайском и русском языках.",answer2:"Экскурсия обычно длится около трех часов.",answer3:"Обед не является обязательным и может быть организован по запросу.",answer4:"Наш День открытых дверей предназначен в первую очередь для профессиональных групп, таких как политики, НПО, НКО и инвесторы. Тем не менее, мы иногда делаем исключения на основе профиля человека.",answer5:"Мы можем разместить группы разного размера. Пожалуйста, укажите размер вашей группы в регистрационной форме, и мы согласуем с вами детали.",answer6:"В регистрационной форме есть раздел, где вы можете указать свои интересы или любые особые пожелания. Мы сделаем все возможное, чтобы адаптировать тур в соответствии с вашими потребностями.",answer7:"В настоящее время мы предлагаем туры только в нашу берлинскую штаб-квартиру, расположенную в Кройцберге. Наши офисы в Пекине и Шэньчжэне в настоящее время закрыты для экскурсий.",question1:"Какие языки вы предлагаете для тура?",question2:"Какова продолжительность тура?",question3:"Предоставляется ли обед?",question4:"Могут ли физические лица зарегистрироваться на День открытых дверей?",question5:"Сколько человек может состоять в группе на День открытых дверей?",question6:"Как я могу указать области интереса для тура?",question7:"Доступны ли туры в ваших офисах в Пекине или Шэньчжэне?"},oe={description:"Облачная платформа с открытым исходным кодом для больших мультимодальных моделей, обслуживающая платформу"},se={commercial_licence:{chip_label:"Эксклюзивно для малых компаний",company_size_note:"Эксклюзивно для компаний с доходом менее 50 человек или доходом менее 500 тыс. долларов США",cta_button:"Начать",download_title:"Загрузить коммерческую лицензию",feature_api_desc:"Тест перед покупкой",feature_api_title:"Бесплатный доступ к тестированию API",feature_consulting:"Два часа консультаций с нашими экспертами по моделям",feature_consulting_desc:"Два (2) часа технических консультационных услуг за период действия лицензии.",feature_future_support:"Доступ к будущим моделям CC BY-NC без разрешения",feature_future_support_desc:"Любые новые модели, выпущенные Лицензиаром в соответствии с CC-BY-NC-4.0 в течение Срока действия лицензии.",feature_models:"Неограниченное коммерческое использование наших моделей CC BY-NC",feature_models_desc:"Использовать Модели в коммерческих целях, включая внутреннее использование или включение в клиентские приложения.",price_amount:"1000 долларов США",price_period:"/ четверть",read_the_terms:"Ознакомьтесь с условиями лицензии",read_the_terms_btn:"Условия",read_the_terms_desc:"Перед покупкой ознакомьтесь с правами и ограничениями коммерческой лицензии.",subtitle:"Каждая модель, которая вам нужна для лучшего поиска",test_before_purchase:"Попробуйте перед покупкой",test_before_purchase_desc:"Получите 1 млн бесплатных токенов API или используйте нашу модель Hugging Face для проверки производительности",title:"Лицензия команды",try_api:"Попробуйте сначала API"},free_hour_consult:"Бесплатная часовая консультация",free_hour_consult_description:"Один час бесплатной консультации с нашими командами по продуктам и инженерам для обсуждения наилучшей практики для вашего варианта использования",full_commercial:"Неограниченное коммерческое использование",full_commercial_description:"Вы можете использовать API в коммерческих целях без каких-либо ограничений.",higher_limit:"Гораздо более высокий предел скорости",higher_limit_description:"Получите до 1000 об/мин для r.jina.ai и 100 об/мин для s.jina.ai; более подробная информация в разделе «Ограничение скорости».",key_manager:"Базовое управление ключами",key_manager_description:"Управляйте несколькими ключами API в одной учетной записи, отслеживайте историю использования и пополняйте токены.",no_commercial:"Только для некоммерческого использования (CC-BY-NC)",no_commercial_description:"Вы можете использовать API только в некоммерческих целях. Для коммерческого использования, пожалуйста, пополните свой ключ API.",on_prem:"С коммерческой лицензией для локального использования",on_prem_explain:"Приобретите коммерческую лицензию для использования наших моделей локально.",premium_key:"Премиум-ключ с гораздо более высокими лимитами скорости",premium_key_description:"Получите гораздо более высокие лимиты скорости и доступ к премиум-функциям. Подробности смотрите в таблице лимитов скорости.",premium_key_manager:"Расширенное управление ключами",premium_key_manager_description:"Базовые и расширенные функции, такие как автоматическое напоминание, отзыв, передача токенов.",priority_support:"Приоритетная техническая поддержка",priority_support_description:"Гарантированный ответ по электронной почте по техническим вопросам и инцидентам в течение 24 часов.",secured_by_stripe:"Безопасная оплата через Stripe",standard_key:"Стандартный ключ",standard_key_description:"Доступ ко всем продуктам API Jina Search Foundation со стандартным ограничением скорости.",via_api:"С API Jina Search Foundation",via_api_explain:"Самый простой способ получить доступ ко всем нашим продуктам. Пополняйте токены по мере использования."},_e="Питаться от",de="Распечатать",ce={archived:"В архиве",cloud_native:"Облако Собственный",core:"Основной",data_structure:"Структура данных",embedding_serving:"Встраивание обслуживания",embedding_tuning:"Встраивание настройки",graduated:"Окончил",incubating:"Инкубация",kubernetes:"Кубернетес",large_size_model:"Модель большого размера",linux_foundation:"Фонд Linux",llm1:"LLMOps",mid_size_model:"Модель среднего размера",model_serving:"Обслуживание моделей",model_tuning:"Настройка модели",observability:"Наблюдаемость",orchestration:"Оркестровка",prompt_serving:"Быстрое обслуживание",prompt_tuning:"Оперативная настройка",rag1:"ТРЯПКА",sandbox:"Песочница",small_size_model:"Модель маленького размера",vector_database:"База данных векторов",vector_store:"Векторный магазин"},le={description:"Первоклассный инструмент для быстрого инжиниринга",image_model:"Модели изображений",intro:"Первоклассный инструмент для быстрого инжиниринга",intro1:"Главный инструмент для быстрого проектирования",optimized:"Ваша задача — быть моим партнером по мозговому штурму и предлагать творческие идеи и предложения по заданной теме или проблеме. Ваш ответ должен включать оригинальные, уникальные и актуальные идеи, которые могут помочь решить проблему или продолжить интересное изучение темы. Обратите внимание, что ваш ответ должен также учитывать любые конкретные требования или ограничения задачи.",optimized_title:"Оптимизированная подсказка",original:"Твоя роль — быть моим партнером по мозговому штурму.",original_title:"Оригинальная подсказка",text_model:"Текстовые модели"},pe={features:[{description:"Легко переключайтесь между созданием контента и быстрой оптимизацией, поднимите качество вашего контента на новый уровень.",name:"Ассистент",title:"Ежедневная доза продуктивности."},{description:"Не знаете, как написать эффективную инструкцию? Просто внесите свою идею в один клик и получите более подробную инструкцию.",name:"Оперативная оптимизация",title:"Лучшие входы, лучшие результаты"},{description:"Поймите атмосферу каждой модели ИИ, сравнив их результаты при выполнении одной и той же подсказки.",name:"Сравнить модели",title:"Параллельное сравнение моделей."},{description:"Возможно, это самый простой способ развернуть ваши подсказки в качестве API для интеграции.",name:"Развертывание подсказок",title:"Никаких операций, просто развертывание."},{description:"Настройте своих собственных агентов LLM и запустите мультиагентное моделирование. Посмотрите, как они сотрудничают или конкурируют в виртуальной среде для достижения цели.",name:"Мультиагент",title:"Узнайте, как агенты сотрудничают"}],get_started:"Начните работу с PromptPerfect"},ue={api_key:"Пополненный API-ключ",free_key:"Бесплатный API-ключ",generation:"Ваш API-ключ готов!",generation_caption:"Ваш ключ API был сгенерирован {_purchasedTime} и готов к использованию!",success:"Спасибо за покупку!",success_caption:"Ваш заказ был выполнен в {_purchasedTime}. Ваш ключ API пополнен и готов к использованию!"},me="Купить сейчас",ge={batch_explain:"Этот API поддерживает пакетные операции, позволяя обрабатывать до 512 документов на запрос, при этом каждый документ может содержать до 8192 токенов. Разумное использование пакетных операций может значительно сократить количество запросов и повысить производительность.",classifier:"Обучить классификатор с использованием маркированных примеров",classifier_few_shot:"Классифицируйте входные данные с помощью обученного классификатора с несколькими попытками",classifier_few_shot_token_counting:"Токены учитываются как: input_tokens",classifier_latency:"Время отклика зависит от размера входных данных",classifier_token_counting:"Токены подсчитываются как: input_tokens × num_iters",classifier_zero_shot:"Классифицируйте входные данные, используя классификацию с нулевым результатом",classifier_zero_shot_token_counting:"Токены считаются как: input_tokens + label_tokens",deepsearch:"Рассуждайте, ищите и повторяйте, чтобы найти лучший ответ.",depends:"зависит от размера входных данных",description:"Описание",embeddings:"Преобразование текста/изображений в векторы фиксированной длины",endpoint:"Конечная точка API",explain:"Ограничения скорости отслеживаются двумя способами: <b>RPM</b> (запросы в минуту) и <b>TPM</b> (токены в минуту). Ограничения применяются по ключу IP/API и могут быть достигнуты в зависимости от того, какой порог — RPM или TPM — будет достигнут первым. Обратите внимание: когда в запросе указан ключ API, ограничения скорости отслеживаются по ключу, а не по IP-адресу.",gjinaai:"Подтверждение заявления знаниями в области Интернета",input_token_counting:"Подсчитайте количество токенов во входном запросе.",latency:"Средняя задержка",no_token_counting:"Токен не считается использованием.",output_token_counting:"Подсчитайте количество токенов в выходном ответе.",premium_rate:"С потенциалом для более высоких лимитов ставок",product:"Продукт",requestType:"Разрешенный запрос",reranker:"Ранжировать документы по запросу",rjinaai:"Преобразовать URL в текст, понятный LLM",sjinaai:"Поиск в Интернете и преобразование результатов в текст, понятный LLM",tbd:"Будет определено",title:"Ограничение скорости",tokenCounting:"Подсчет использования токенов",tokenizer:"Токенизация и сегментация длинного текста",total_token_counting:"Подсчитайте общее количество токенов за весь процесс.",understanding:"Понять ограничение скорости",understanding_description:"Ограничения скорости — это максимальное количество запросов, которые можно сделать к API в течение минуты на IP-адрес/ключ API (RPM). Узнайте больше об ограничениях скорости для каждого продукта и уровня ниже.",wAPIkey:"с API-ключом",wPremium:"с премиум-ключом API",woAPIkey:"без API-ключа"},he={decision:"Решение",description:"Совершенные инструменты для принятия решений с помощью ИИ",intro:"Видите две стороны медали, принимайте рациональные решения"},be={beta:"Экспериментальный",better_input:"Повышайте качество ввода с самого начала",better_input_description:"Возникли проблемы с выходными данными вашего агента или системы RAG? Возможно, это связано с плохим качеством ввода.",check_price_table:"Проверьте таблицу цен",copy:"Копировать",demo:{advanced_parameter_explain:"Конкретные параметры, которые используются только для {_product}.",advanced_parameters:"Специфический",advanced_usage:"Расширенное использование",ask_llm:"Спросите LLM без и с заземлением поиска",ask_llm_directly:"Спросите LLM напрямую",ask_llm_with_search_grounding:"Спросите LLM с обоснованием поиска",ask_question:"Задать вопрос",ask_question_hint:"Введите вопрос и объедините его с полученным контентом, чтобы LLM сгенерировал ответ.",basic_usage:"Основное использование",basic_usage1:"Чтение URL-адреса",basic_usage2:"Поиск запроса",basic_usage3:"Заземление",common_parameter_explain:"Общие параметры, которые можно использовать для {_product1}, {_product2} и {_product3}.",common_parameters:"Общий",copy:"Копировать",fetch:"Получить контент",get_response:"Получить ответ",grounding_result_false:"Это утверждение ложно.",grounding_result_true:"Это утверждение верно.",headers:{auth_token:"Добавьте ключ API для более высокого лимита скорости",auth_token_explain:"Введите свой ключ API Jina, чтобы получить доступ к более высокому лимиту скорости. Актуальную информацию об ограничениях скорости можно найти в таблице ниже.",auto:"Авто",auto_explain:"Автоматически выбирает оптимальный движок для URL.",base:"Перенаправление резолюции",base_explain:"Выберите, следует ли разрешать конечный целевой URL после прохождения всех перенаправлений. Включите, чтобы следовать полной цепочке перенаправлений.",browser:"По умолчанию",browser_explain:"Наиболее совместимый движок, обеспечивающий хороший баланс между качеством и скоростью.",browser_locale:"Язык браузера",browser_locale_explain:"Управляйте локалью браузера для отображения страницы. Множество веб-сайтов предоставляют разный контент в зависимости от локали.",custom_script:"Предварительное выполнение пользовательского JavaScript",custom_script_explain:"Выполняет предварительную обработку кода JavaScript, принимая либо встроенную строку кода, либо удаленную конечную точку URL скрипта.",deepdive:"Глубокий анализ источника",deepdive_explain:"Ищет больше источников и читает полные документы для тщательной проверки фактов. Немного медленнее, но точнее и больше ссылок.",default:"По умолчанию",default_explain:"Стандартный конвейер, оптимизированный для большинства веб-сайтов и ввода LLM.",direct:"Скорость прежде всего",direct_explain:"Самый быстрый движок, но может испытывать трудности с некоторыми сайтами, насыщенными JavaScript.",engine:"Читать Двигатель",engine_explain:"Выберите движок, который будет использоваться для анализа контента для указанного URL. Влияет на качество, скорость, совместимость результата.",file:"Локальный файл PDF/HTML",file_explain:"Используйте Reader на локальных файлах PDF и HTML, загрузив их. Поддерживает только файлы PDF и HTML.",html:"HTML",html_explain:"Возвращает documentElement.outerHTML.",image_caption:"Подпись к изображению",image_caption_explain:"Подписывает все изображения по указанному URL-адресу, добавляя «Image [idx]: [caption]» в качестве альтернативного тега для тех, у кого его нет. Это позволяет последующим LLM взаимодействовать с изображениями в таких действиях, как рассуждение и подведение итогов.",images_summary:"Соберите все изображения в конце",images_summary_all:"Резюме (Все изображения)",images_summary_all_explain:"Включена сводка собранных изображений без фильтрации дубликатов.",images_summary_explain:"В конце будет создан раздел «Изображения». Это дает последующим специалистам LLM обзор всех визуальных элементов на странице, что может улучшить логику.",images_summary_true:"Резюме (отфильтровано)",images_summary_true_explain:"Включена сводка собранных изображений, но дубликаты изображений отфильтровываются.",instruction_explain:"Извлечение информации по инструкции",invalid_json:"Неверная схема JSON",json_response:"JSON-ответ",json_response_explain:"Ответ будет в формате JSON, содержащий URL-адрес, заголовок, контент и временную метку (если имеется). В режиме поиска он возвращает список из пяти записей, каждая из которых соответствует описанной структуре JSON.",json_schema_explain:"Извлечение HTML в JSON с помощью схемы JSON",links_summary:"Соберите все ссылки в конце",links_summary_all:"Резюме (Все ссылки)",links_summary_all_explain:"Включена сводка собранных ссылок без фильтрации дубликатов.",links_summary_explain:"В конце будет создан раздел «Кнопки и ссылки». Это помогает нижестоящим LLM или веб-агентам перемещаться по странице или предпринимать дальнейшие действия.",links_summary_no:"Нет резюме (по умолчанию)",links_summary_no_explain:"В конце не будет создан раздел с резюме.",links_summary_true:"Резюме (отфильтровано)",links_summary_true_explain:"Включена сводка собранных ссылок, но дублирующиеся ссылки отфильтровываются.",markdown:"Уценка",markdown_explain:"Возвращает разметку непосредственно из HTML, минуя фильтрацию читабельности.",mode:"Режим чтения или поиска",mode_explain:"Режим чтения предназначен для доступа к содержимому URL-адреса, а режим поиска позволяет выполнять поиск по запросу в Интернете, применяя режим чтения к каждому URL-адресу результата поиска.",no_cache:"Обход кэша",no_cache_explain:"Наш сервер API кэширует содержимое режима чтения и поиска в течение определенного периода времени. Чтобы обойти этот кеш, установите для этого заголовка значение true.",no_gfm:"Неполноценный",no_gfm_explain:"Функции GFM (Github Flavored Markdown) отключены.",no_gfm_table:"Нет таблицы GFM",no_gfm_table_explain:"Отказаться от таблицы GFM, но сохранить элементы HTML таблицы в ответе.",opt_out_gfm:"Github Flavored Markdown",opt_out_gfm_explain:"Включение/отключение функций GFM (Github Flavored Markdown).",pageshot:"Снимок страницы",pageshot_explain:"Возвращает URL-адрес изображения полного снимка экрана страницы (с максимальной эффективностью).",post_with_url:"Использовать метод POST",post_with_url_explain:"Используйте POST вместо метода GET с URL-адресом, переданным в теле. Полезно для создания SPA с маршрутизацией на основе хеша.",proxy_server:"Используйте прокси-сервер",proxy_server_explain:"Наш сервер API может использовать ваш прокси-сервер для доступа к URL-адресам, что полезно для страниц, доступных только через определенные прокси.",references:"Ссылки",references_explain:"Список ссылок (URL), предоставленных пользователем, разделенных запятыми.",remove_all_images:"Удалить все изображения",remove_all_images_explain:"Удалить все изображения из ответа.",remove_selector:"Исключенный селектор",remove_selector_explain:"Предоставьте список селекторов CSS для удаления указанных элементов страницы. Полезно, когда вы хотите исключить определенные части страницы, такие как заголовки, нижние колонтитулы и т. д.",respond_with:"Использовать ReaderLM-v2",respond_with_explain:"Использует ReaderLM-v2 для преобразования HTML в Markdown, чтобы обеспечить высококачественные результаты для веб-сайтов со сложной структурой и содержимым. Стоит 3x токенов!",result_count:"Результат Лимит",result_count_explain:"Количество возвращаемых результатов поиска.",return_format:"Формат контента",return_format_explain:"Вы можете контролировать уровень детализации ответа, чтобы предотвратить чрезмерную фильтрацию. Конвейер по умолчанию оптимизирован для большинства веб-сайтов и входных данных LLM.",screenshot:"Скриншот",screenshot_explain:"Возвращает URL-адрес изображения первого экрана.",search_engine:"Поисковая система",search_engine_explain:"Выберите поисковую систему, которая будет использоваться. Влияет на качество, скорость, совместимость результата.",set_cookie:"Переслать файл cookie",set_cookie_explain:"Наш сервер API может пересылать ваши пользовательские настройки файлов cookie при доступе к URL-адресу, что полезно для страниц, требующих дополнительной аутентификации. Обратите внимание, что запросы с файлами cookie не кэшируются.",site_selector:"Поиск по сайту",site_selector_explain:"Возвращает результаты поиска только с указанного веб-сайта или домена. По умолчанию он выполняет поиск по всей сети.",stream_mode:"Режим потока",stream_mode_explain:"Режим потока полезен для больших целевых страниц, поскольку дает больше времени для полной визуализации страницы. Если в стандартном режиме контент получается неполным, рассмотрите возможность использования режима Stream.",target_selector:"Целевой селектор",target_selector_explain:"Предоставьте список селекторов CSS, чтобы сосредоточиться на более конкретных частях страницы. Полезно, когда желаемый вами контент не отображается при настройках по умолчанию.",text:"Текст",text_explain:"Возвращает document.body.innerText.",token_budget:"Бюджет токенов",token_budget_explain:"Ограничивает максимальное количество токенов, используемых для этого запроса. Превышение этого лимита приведет к сбою запроса.",viewport:"Конфигурация области просмотра",viewport_explain:"Настройте размеры области просмотра браузера для адаптивного рендеринга",vlm:"ВЛМ",vlm_explain:"Идеально подходит для коротких страниц с насыщенным контентом и сложной компоновкой.",wait_for_selector:"Подождите селектора",wait_for_selector_explain:"Предоставьте список селекторов CSS для ожидания появления определенных элементов перед возвратом. Полезно, когда желаемый вами контент не отображается при настройках по умолчанию.",with_gfm:"Включено",with_gfm_explain:"Включены функции GFM (Github Flavored Markdown).",with_iframe:"Включить извлечение iframe",with_iframe_explain:"Извлекает и обрабатывает содержимое из всех встроенных фреймов в дереве DOM.",with_shadow_dom:"Включить извлечение теневого DOM",with_shadow_dom_explain:"Обходит и извлекает содержимое из всех корневых элементов Shadow DOM в документе.",x_timeout:"Тайм-аут",x_timeout_explain:"Максимальное время ожидания загрузки веб-страницы. Обратите внимание, что это НЕ общее время для всего сквозного запроса."},how_to_stream:"Чтобы обрабатывать контент по мере его поступления, установите для заголовка запроса потоковый режим. Это минимизирует время до получения первого байта. Пример в локоне:",how_to_use1:"Добавьте https://r.jina.ai/ к любому URL-адресу в вашем коде или инструменте, где ожидается доступ к LLM. Это вернет основное содержимое страницы в чистом, удобном для LLM тексте.",how_to_use2:"Добавьте https://s.jina.ai/ в свой запрос. Это вызовет поисковую систему и вернет 5 лучших результатов с их URL-адресами и содержимым, каждый в чистом, удобном для LLM тексте.",how_to_use3:"Добавьте https://g.jina.ai/ к вашему утверждению. Это вызовет механизм суждений и вернет процент правдивости, логическое значение, указывающее, является ли утверждение истинным или ложным, краткое изложение причин и список ссылок.",key_required:"Для использования этой конечной точки требуется ключ API",learn_more:"Узнать больше",open:"Открыть в новой вкладке",params_classification:"Параметры",raw_html:"Необработанный HTML",reader_output:"Вывод считывателя",reader_response:"Ответ читателя",reader_search_hint:"Если вы используете этот URL-адрес в коде, не забудьте его закодировать.",reader_url:"URL-адрес читателя",reader_url_hint:"Нажмите ниже, чтобы получить контент через наш Reader API.",requires_post_method:"Эта функция требует метод POST. При загрузке локального файла метод POST будет включен автоматически.",search_params:"Параметры поиска/Заголовки",search_query_rewrite:"Обратите внимание: в отличие от демонстрации, показанной выше, на практике вам не нужно искать в Интернете исходный вопрос для обоснования. Люди часто переписывают исходный вопрос или используют вопросы с несколькими переходами. Они считывают полученные результаты, а затем генерируют дополнительные запросы для сбора дополнительной информации по мере необходимости, прежде чем прийти к окончательному ответу.",select_mode:"Выбрать режим",show_read_demo:"Посмотрите, как Reader читает URL-адрес",show_search_demo:"Посмотрите, как Reader выполняет поиск в Интернете",slow_warning:"Это может занять до 30 секунд и стоить до 300 тыс. токенов за запрос.",standard_usage:"Стандартное использование",stream_mode:"Режим потока",stream_mode_explain:"Режим потока полезен, когда целевая страница имеет большой размер для визуализации. Если вы обнаружите, что стандартный режим дает неполный контент, попробуйте потоковый режим.",stream_mode_explain1:"Режим потоковой передачи полезен, когда вы обнаружите, что стандартный режим дает неполный результат. Это связано с тем, что режим потоковой передачи будет ждать немного дольше, пока страница не будет полностью отображена. Используйте заголовок Accept для переключения режима потоковой передачи:",tagline:"Попробуйте демо",try_demo:"Демо",use_headers:"Поведением Reader API можно управлять с помощью заголовков запросов. Вот полный список поддерживаемых заголовков.",waiting_for_reader:"Сначала ожидание результата API Reader...",warn_grounding_message:"Этот процесс может занять до 30 секунд и потреблять до 300 тыс. токенов на запрос заземления. Некоторые браузеры могут завершить запрос из-за большой задержки, поэтому мы рекомендуем скопировать код и запустить его с вашего терминала.",warn_grounding_title:"Высокая задержка и использование токенов",your_query:"Введите ваш запрос",your_query_hint:"Введите вопрос, который требует новейшей информации или мировых знаний.",your_statement:"Ваше заявление о проверке фактов",your_url:"Введите свой URL",your_url_hint:"Нажмите ниже, чтобы получить исходный код страницы напрямую."},description:"Читайте URL-адреса и ищите информацию в Интернете для получения более подходящей подготовки для получения степени магистра права.",dont_panic_api_key_is_free:"Не паникуйте! Каждый новый ключ API содержит один миллион бесплатных токенов!",faq_v1:{answer1:"API Reader предоставляется бесплатно и не требует ключа API. Просто добавьте https://r.jina.ai/ к своему URL-адресу.",answer10:"Нет, Reader API может обрабатывать контент только с общедоступных URL-адресов.",answer11:"Если вы запросите тот же URL-адрес в течение 5 минут, Reader API вернет кэшированный контент.",answer12:"К сожалению нет.",answer13:"Да, вы можете использовать встроенную поддержку PDF в Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) или HTML-версию из arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)",answer14:"Reader подписывает все изображения по указанному URL-адресу и добавляет `Image [idx]: [caption]` в качестве альтернативного тега (если он изначально отсутствует). Это позволяет последующим LLM-специалистам взаимодействовать с изображениями при рассуждениях, обобщениях и т. д.",answer15:"Reader API разработан с учетом высокой масштабируемости. Он автоматически масштабируется на основе трафика в реальном времени, а максимальное количество параллельных запросов сейчас составляет около 4000. Мы активно поддерживаем его как один из основных продуктов Jina AI. Так что смело используйте его в производстве.",answer16:"Актуальную информацию об ограничениях скорости можно найти в таблице ниже. Обратите внимание, что мы активно работаем над улучшением ограничения скорости и производительности Reader API, таблица будет соответствующим образом обновлена.",answer17:"Reader-LM — это новая модель малого языка (SLM), разработанная для извлечения и очистки данных из открытого Интернета. Она преобразует сырой, шумный HTML в чистый markdown, черпая вдохновение из Jina Reader. С упором на экономическую эффективность и небольшой размер модели, Reader-LM является как практичным, так и мощным. В настоящее время он доступен на торговых площадках AWS, Azure и GCP. Если у вас есть особые требования, свяжитесь с нами по адресу sales AT jina.ai.",answer2:"API Reader использует прокси-сервер для получения любого URL-адреса, отображая его содержимое в браузере для извлечения высококачественного основного контента.",answer3:"Да, Reader API имеет открытый исходный код и доступен в репозитории Jina AI GitHub.",answer4:"Reader API обычно обрабатывает URL-адреса и возвращает контент в течение 2 секунд, хотя для сложных или динамических страниц может потребоваться больше времени.",answer5:"Парсинг может быть сложным и ненадежным, особенно для сложных или динамических страниц. Reader API обеспечивает оптимизированный и надежный вывод чистого текста, готового к LLM.",answer6:"API Reader возвращает контент на исходном языке URL-адреса. Он не предоставляет услуги перевода.",answer7:"Если у вас возникли проблемы с блокировкой, обратитесь в нашу службу поддержки для помощи и решения.",answer8:"Хотя Reader API в первую очередь предназначен для веб-страниц, он может извлекать контент из PDF-файлов, просматриваемых в формате HTML на таких веб-сайтах, как arXiv, но он не оптимизирован для общего извлечения PDF-файлов.",answer9:"В настоящее время Reader API не обрабатывает мультимедийный контент, но будущие улучшения будут включать субтитры к изображениям и обобщение видео.",question1:"Каковы затраты, связанные с использованием Reader API?",question10:"Можно ли использовать Reader API для локальных файлов HTML?",question11:"Кэширует ли Reader API контент?",question12:"Могу ли я использовать API Reader для доступа к контенту после входа в систему?",question13:"Могу ли я использовать Reader API для доступа к PDF-файлам на arXiv?",question14:"Как работает подпись к изображению в Reader?",question15:"Какова масштабируемость Reader? Могу ли я использовать его в производстве?",question16:"Каков предел скорости API Reader?",question17:"Что такое Reader-LM? Как им пользоваться?",question2:"Как работает API Reader?",question3:"Является ли Reader API открытым исходным кодом?",question4:"Какова типичная задержка для Reader API?",question5:"Почему мне следует использовать Reader API вместо того, чтобы самостоятельно очищать страницу?",question6:"Поддерживает ли Reader API несколько языков?",question7:"Что делать, если веб-сайт блокирует Reader API?",question8:"Может ли Reader API извлекать контент из PDF-файлов?",question9:"Может ли Reader API обрабатывать медиаконтент с веб-страниц?",title:"Общие вопросы, связанные с читателями"},fast:"Быстрый",fast_stream:"Немедленная потоковая передача данных",fast_stream_description:"Нужны данные быстро? Наш Reader API может передавать данные в потоковом режиме, чтобы минимизировать задержку.",free:"Бесплатно навсегда",free_description:"Reader API бесплатен! Для этого не требуется кредитная карта или секрет API. Он не будет использовать вашу квоту токена.",is_free:"Лучшая часть? Это бесплатно!",is_free_description:"Reader API доступен бесплатно и предлагает гибкие ограничения по скорости и ценам. Построенный на основе масштабируемой инфраструктуры, он обеспечивает высокую доступность, параллелизм и надежность. Мы стремимся быть вашим предпочтительным решением по заземлению для ваших студентов LLM.",lm_v2_description:"ReaderLM-v2 — это языковая модель с 1,5 млрд параметров, специализирующаяся на преобразовании HTML в Markdown и извлечении HTML в JSON. Она поддерживает документы размером до 512 тыс. токенов на 29 языках и обеспечивает точность на 20 % выше по сравнению с предыдущей моделью.",lm_v2_title:"ReaderLM v2: небольшая языковая модель для преобразования HTML в Markdown и JSON",open:"Открыть в новой вкладке",original_pdf:"Исходный PDF-файл",rate_limit:"Ограничение скорости",read_grounding_release_note:"Прочитать примечание к выпуску",reader_also_read_images:"Изображения на веб-странице автоматически снабжаются подписями с использованием языковой модели видения в программе чтения и форматируются в виде тегов alt изображения на выходе. Это дает вашему последующему LLM достаточно подсказок, чтобы включить эти изображения в процессы рассуждения и обобщения. Это означает, что вы можете задавать вопросы об изображениях, выбирать конкретные изображения или даже пересылать их URL-адреса более мощному VLM для более глубокого анализа!",reader_description:"Преобразуйте URL-адрес в формат ввода, удобный для LLM, просто добавив <code>r.jina.ai</code> в начало.",reader_do_grounding:"Читатель для проверки фактов",reader_do_grounding_explain:"Новая конечная точка заземления предлагает сквозной, практически в реальном времени опыт проверки фактов. Она берет заданное утверждение, обосновывает его с помощью результатов веб-поиска в реальном времени и возвращает оценку фактичности и точные использованные ссылки. Вы можете легко обосновать утверждения, чтобы уменьшить галлюцинации LLM или улучшить целостность контента, написанного человеком.",reader_do_pdf_explain:"Да, Reader изначально поддерживает чтение PDF-файлов. Он совместим с большинством PDF-файлов, в том числе с большим количеством изображений, и работает молниеносно! В сочетании с LLM вы можете легко создать ChatPDF или ИИ для анализа документов в кратчайшие сроки.",reader_do_search:"Читалка для заземления поиска",reader_do_search_explain:"У LLM есть ограничение на знания, что означает, что они не могут получить доступ к новейшим мировым знаниям. Это приводит к таким проблемам, как дезинформация, устаревшие ответы, галлюцинации и другие проблемы с фактами. Заземление абсолютно необходимо для приложений GenAI. Reader позволяет вам снабжать свой LLM самой последней информацией из Интернета. Просто добавьте https://s.jina.ai/ к своему запросу, и Reader выполнит поиск в Интернете и вернет пять лучших результатов с их URL-адресами и содержимым, каждый в чистом, удобном для LLM тексте. Таким образом, вы всегда сможете поддерживать свой LLM в актуальном состоянии, повышать его достоверность и уменьшать количество галлюцинаций.",reader_reads_images:"Ридер тоже читает изображения!",reader_reads_pdf:"Ридер также читает PDF-файлы!",reader_result:"Результат чтения",table:{td_1_0:"Прочитайте URL-адрес и верните его содержимое, что полезно для проверки заземления.",td_1_1:"20 об/мин",td_1_2:"200 об/мин",td_1_3:"На основе выходных токенов",td_1_4:"3 секунды",td_1_5:"3 секунды",td_2_0:"Поиск в Интернете возвращает топ-5 результатов, что полезно для обоснования поиска.",td_2_1:"5 об/мин",td_2_2:"40 об/мин",td_2_3:"На основе токенов вывода для всех 5 результатов поиска.",td_2_4:"10 секунд",td_2_5:"10 секунд",th0:"Конечная точка",th1:"Описание",th2:"Ограничение скорости без ключа API",th3:"Ограничение скорости с ключом API",th4:"Схема подсчета токенов",th5:"Средняя задержка",th6:"Средняя задержка"},title:"API-интерфейс читателя",usage:"Применение",usage_details_false:"Показать только основные варианты использования",usage_details_null:"Показать базовое и расширенное использование",usage_details_true:"Показывать только расширенное использование",want_higher_rate_limit:"Хотите более высокий предел скорости до 1000 об/мин? Мы можем поддержать вас!",what_is1:"Что такое Ридер?",what_is_answer_long:"Предоставление веб-информации в программы LLM является важным шагом в обучении, однако это может быть непросто. Самый простой метод — очистить веб-страницу и передать ей необработанный HTML-код. Однако парсинг может быть сложным и часто блокируется, а необработанный HTML загроможден посторонними элементами, такими как разметка и скрипты. Reader API решает эти проблемы, извлекая основной контент из URL-адреса и преобразуя его в чистый, удобный для LLM текст, обеспечивая высококачественный ввод для вашего агента и систем RAG.",what_is_desc:"Прокси-сервер, который обращается к любому URL-адресу и преобразует основной контент в обычный текст, оптимизированный для LLM."},Ae={confirm_message:"В вашем ключе API осталось токенов {_leftTokens}. Отправка полного текста статей {_numArticles} в API Reranker с использованием модели {_selectedReranker} для обнаружения связанных статей для текущей страницы значительно уменьшит количество токенов вашего ключа API {_APIKey}. Вы хотите продолжить?",confirm_title:"Предупреждение: высокий уровень использования токенов",out_of_quota:"В этом ключе API закончились токены. Пополните свой аккаунт или используйте другой ключ API.",recommend:"Получить топ-5",recommended_articles:"Топ-5 похожих статей"},ke={benchmark:{description0:"LlamaIndex оценил различные комбинации встраивания и реранкинга для RAG, проведя исследование репликации, в котором измерялся средний обратный ранг. Результаты подчеркивают значительное улучшение качества поиска с помощью Jina Reranker, преимущество, которое не зависит от конкретных используемых вложений.",description1:"BIER (Benchmarking IR) оценивает эффективность поиска модели, включая релевантность и NDCG. Более высокий показатель BIER коррелирует с более точными совпадениями и рейтингом результатов поиска.",description2:"С помощью теста LoCo мы измерили понимание модели локальной связности и контекста, а также ранжирование по конкретному запросу. Более высокий балл LoCo отражает лучшую способность выявлять и расставлять приоритеты в соответствующей информации.",description3:"Тест MTEB (Multilingual Text Embedding Benchmark) в целом проверяет возможности модели по встраиванию текста, включая кластеризацию, классификацию, поиск и другие показатели. Однако для нашего сравнения мы использовали только задачи переранжирования MTEB.",title:"Контрольный показатель",title0:"ЛамаИндекс",title1:"БЕЙР",title2:"ЛоКо",title3:"МТЕБ"},benchmark_description:"Для сравнения мы включили в тест три других ведущих ререйнера от BGE (BAAI), BCE (Netease Youdao) и Cohere. Как показывают результаты ниже, Jina Reranker имеет самый высокий средний балл во всех соответствующих категориях для ререйтинга, что делает его явным лидером среди аналогов.",benchmark_title:"Тест производительности",choose_turbo:"Получите ускорение до 5 раз с помощью Reranker-Turbo",choose_turbo_description:"Мы также предлагаем две новые модели реранкера с открытым исходным кодом: jina-reranker-v1-turbo-en и jina-reranker-v1-tiny-en, последняя имеет всего 30 миллионов параметров и четыре слоя. Эти два новых устройства реранкинга имеют в 5 раз более высокую скорость вывода, чем базовая модель, при очень небольших затратах на качество. Они идеально подходят для приложений, требующих изменения ранжирования в реальном времени. Прочтите тест ниже.",customize_urself:"Измените его и посмотрите, как изменится реакция!",customize_urself_pl:"Измените их и посмотрите, как изменится реакция!",description:"Нейронный ретривер мирового класса для максимального повышения релевантности поиска.",description_rich:"Увеличьте релевантность поиска и точность RAG с помощью нашего передового API-интерфейса реранжировщика.",example_input_document:"Примеры документов кандидата для ранжирования",example_input_query:"Пример запроса",faq_v1:{answer1:"Цены на Reranker API соответствуют нашей структуре ценообразования API для встраивания. Он начинается с 1 миллиона бесплатных токенов за каждый новый ключ API. Помимо бесплатных жетонов, для покупки доступны различные пакеты. Для более подробной информации посетите наш раздел цен.",answer10:"Да, наши услуги доступны на торговых площадках AWS, Azure и GCP. Если у вас есть особые требования, свяжитесь с нами по адресу sales AT jina.ai.",answer11:"Если вы заинтересованы в точно настроенном механизме изменения рейтинга, адаптированном к конкретным данным домена, свяжитесь с нашим отделом продаж. Наша команда оперативно ответит на ваш запрос.",answer3:"<code>jina-reranker-v2-base-multilingual</code> отличается многоязычной поддержкой, превосходя <code>bge-reranker-v2-m3</code> и предлагая в 15 раз более высокую пропускную способность, чем <code>jina-reranker-v1-base-en</code>. Он также поддерживает агентские задачи и извлечение кода. <code>jina-colbert-v2</code> превосходит <code>ColBERTv2</code>, обеспечивая на 6,5% лучшую производительность извлечения и добавляя многоязычную поддержку для 89 языков. Он имеет контролируемые пользователем размеры встраивания для оптимальной эффективности и точности.",answer4:"Да, <code>jina-reranker-v2-base-multilingual</code> и <code>jina-colbert-v2</code> имеют открытый исходный код и доступны по лицензии CC-BY-NC 4.0. Вы можете свободно использовать, делиться и адаптировать модели в некоммерческих целях.",answer5:"Да, и <code>jina-reranker-v2-base-multilingual</code>, и <code>jina-colbert-v2</code> поддерживают более 100 языков, включая английский, китайский и другие основные мировые языки. Они оптимизированы для многоязычных задач и превосходят предыдущие модели.",answer6:"Максимальная длина токена запроса — 512. Для документов ограничения на токен не существует.",answer7:"Вы можете переоценить до 2048 документов по одному запросу.",answer8:"В отличие от нашего API внедрения, понятия размера пакета не существует. Вы можете отправить только один кортеж запроса-документа за запрос, но кортеж может включать до 2048 документов-кандидатов.",answer9:"Задержка варьируется от 100 миллисекунд до 7 секунд и во многом зависит от длины документов и запроса. Например, переоценка 100 документов по 256 токенов каждый с помощью запроса из 64 токенов занимает около 150 миллисекунд. Увеличение длины документа до 4096 токенов увеличивает время до 3,5 секунд. Если длина запроса увеличивается до 512 токенов, время увеличивается до 7 секунд.",question1:"Сколько стоит API Reranker?",question10:"Можно ли разместить ваши конечные точки в частном порядке на AWS, Azure или GCP?",question11:"Предлагаете ли вы точно настроенный механизм изменения рейтинга на основе данных, специфичных для конкретного домена?",question3:"В чем разница между двумя реранкерами?",question4:"Имеют ли Jina Rerankers открытый исходный код?",question5:"Поддерживают ли рераннеры несколько языков?",question6:"Какова максимальная длина запросов и документов?",question7:"Какое максимальное количество документов я могу переоценить по одному запросу?",question8:"Каков размер пакета и сколько кортежей документов-запросов я могу отправить в одном запросе?",question9:"Какую задержку можно ожидать при изменении ранжирования 100 документов?",title:"Общие вопросы, связанные с реранкером"},feature_on_premises_description2:"Разверните Jina Reranker на AWS Sagemaker, а вскоре и в Microsoft Azure и Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов.",feature_on_premises_description3:"Разверните Jina Reranker на AWS Sagemaker и Microsoft Azure, а вскоре и в Google Cloud Services, или свяжитесь с нашим отделом продаж, чтобы получить индивидуальные развертывания Kubernetes для вашего виртуального частного облака и локальных серверов.",feature_solid_description:"Разработано на основе наших передовых академических исследований и тщательно протестировано с помощью реранкеров SOTA, чтобы обеспечить беспрецедентную производительность.",how_it_works:"Вот как это работает:",how_it_works_v1:{description1:"Поисковая система использует embeddings/BM25 для поиска широкого набора потенциально релевантных документов на основе запроса пользователя.",description2:"Затем программа реранкинга берет эти результаты и анализирует их на более детальном уровне, учитывая нюансы взаимодействия условий запроса с содержимым документа.",description3:"На основе более глубокого анализа он меняет порядок результатов поиска, помещая вверху те, которые он считает наиболее релевантными.",title1:"Первоначальное получение",title2:"Изменение рейтинга",title3:"Улучшенные результаты"},improve_performance:"Гарантированное улучшение по сравнению с векторным поиском",improve_performance_description:"Наши оценки продемонстрировали улучшение поисковых систем, использующих Jina Reranker, с +8% по показателю результативности и +33% по среднему взаимному рейтингу.",learning1:"Изучение реранкера",learning1_description:"Что такое реранкер? Почему недостаточно векторного поиска или косинусного сходства? Узнайте о реранкерах с нуля с помощью нашего подробного руководства.",read_more_about_benchmark:"Подробнее о тесте",read_more_about_turbo:"Подробнее о турбо- и миниатюрных моделях",read_more_about_v2:"Jina Reranker v2 — лучший в своем классе инструмент для изменения рейтинга, выпущенный 25 июня 2024 года; он создан для Agentic RAG. Он поддерживает вызов функций, многоязычный поиск для более чем 100 языков, возможности поиска кода и обеспечивает шестикратное ускорение по сравнению с версией v1. Подробнее о модели v2.",reranker_description:"Попробуйте наш передовой API-интерфейс для изменения рейтинга, чтобы максимизировать релевантность поиска и точность RAG. Стартуем бесплатно!",show_v2benchmark:"Показать тест для модели v2 (последней)",table:{number_token_document:"Количество токенов в каждом документе",number_token_query:"Количество токенов в запросе",title:"Ниже приведены временные затраты на переоценку одного запроса и 100 документов в миллисекундах:"},title:"API реранкера",top_n:"Количество возвращенных документов",top_n_explain:"Количество наиболее релевантных документов, возвращаемых по запросу.",try_embedding:"Попробуйте встроить API бесплатно",try_reranker:"Попробуйте API реранкера бесплатно",v2_features:{description1:"Reranker v2 позволяет извлекать документы на более чем 100 языках, независимо от языка запроса.",description2:"Reranker v2 ранжирует фрагменты кода и сигнатуры функций на основе запросов на естественном языке, что идеально подходит для приложений Agentic RAG.",description3:"Reranker v2 ранжирует наиболее релевантные таблицы на основе запросов на естественном языке, помогая сортировать различные схемы таблиц и определять наиболее релевантную перед созданием SQL-запроса.",title1:"Многоязычный поиск",title2:"Вызов функций и поиск кода",title3:"Поддержка табличных и структурированных данных"},v2benchmark:{descBeir:"Представлены оценки NDCG 10 для различных моделей реранжирования набора данных Beir.",descCodeSearchNet:"Оценки MRR 10 представлены для различных моделей реранжирования набора данных CodeSearchNet.",descMKQA:"Напомним, 10 оценок были получены для различных моделей реранжирования для набора данных MKQA.",descNSText2SQL:"Напомним, что для различных моделей реранжирования для набора данных NSText2SQL сообщалось о трех оценках.",descRTX4090:"Показатели пропускной способности (документы извлекаются за 50 мс) представлены для различных моделей реранжирования на графическом процессоре RTX 4090.",descToolBench:"Напомним, что для различных моделей реранжирования для набора данных ToolBench было получено 3 балла.",titleBeir:"BEIR (гетерогенный тест для различных задач IR)",titleCodeSearchNet:"CodeSearchNet. Тест представляет собой комбинацию запросов в форматах строк документации и естественном языке с помеченными сегментами кода, соответствующими запросам.",titleMKQA:"MKQA (Многоязычные вопросы и ответы)",titleNSText2SQL:"НСтекст2SQL",titleRTX4090:"Пропускная способность Jina Reranker v2 на RTX4090",titleToolBench:"ИнструментБенч. Тест собирает более 16 тысяч общедоступных API и соответствующих синтетически сгенерированных инструкций для их использования в настройках с одним и несколькими API."},vs_table:{col0:"Реранкер",col0_1:"Повышенная точность и релевантность поиска",col0_2:"Начальная, быстрая фильтрация",col0_3:"Общий поиск текста по широкому кругу запросов",col1:"Векторный поиск",col1_1:"Подробно: вложенный документ и сегмент запроса.",col1_2:"Широкий: все документы.",col1_3:"Средний уровень: различные фрагменты текста.",col2:"БМ25",col2_1:"Высокий",col2_2:"Середина",col2_3:"Низкий",col3_1:"Не требуется",col3_2:"Высокий",col3_3:"Низкий, использует готовый индекс",col4_1:"Высокий",col4_2:"Высокий",col4_3:"Не требуется",col5_1:"Превосходно для тонких запросов",col5_2:"Баланс между эффективностью и точностью",col5_3:"Согласованность и надежность для широкого круга запросов",col6_1:"Высокая точность и глубокое понимание контекста",col6_2:"Быстро и эффективно, с умеренной точностью.",col6_3:"Высокая масштабируемость и доказанная эффективность",col7_1:"Ресурсоемкость со сложной реализацией",col7_2:"Может не улавливать глубокий контекст или нюансы запроса.",col7_3:"Может быть неэффективным для узкоспециализированного или контекстного поиска.",header0:"Лучшее для",header1:"Детализация",header2:"Сложность времени запроса",header3:"Индексация временной сложности",header4:"Сложность времени обучения",header5:"Качество поиска",header6:"Сильные стороны",header7:"Недостатки",subtitle:"В таблице ниже представлено всестороннее сравнение Reranker, Vector/Embeddings Search и BM25, подчеркивая их сильные и слабые стороны в различных категориях.",title:"Сравнение реранкера, векторного поиска и BM25"},what_is:"Что такое реранкер?",what_is_answer_long:`Цель поисковой системы — быстро и эффективно находить наиболее релевантные результаты. Традиционно для ранжирования результатов поиска на основе соответствия ключевых слов использовались такие методы, как BM25 или tf-idf. Последние методы, такие как косинусное сходство на основе встраивания, были реализованы во многих векторных базах данных. Эти методы просты, но иногда могут упускать из виду тонкости языка и, что наиболее важно, взаимодействие между документами и целью запроса.

Вот тут-то и сияет «реранкер». Реранкер — это усовершенствованная модель искусственного интеллекта, которая берет первоначальный набор результатов поиска (часто предоставляемого поиском на основе внедрений/токенов) и повторно оценивает их, чтобы убедиться, что они более точно соответствуют намерениям пользователя. Он выходит за рамки сопоставления терминов на поверхностном уровне и рассматривает более глубокое взаимодействие между поисковым запросом и содержанием документов.`,what_is_answer_long_ending:"Средство повторного ранжирования может значительно улучшить качество поиска, поскольку оно работает на уровне поддокумента и подзапроса, то есть анализирует отдельные слова и фразы, их значения и то, как они соотносятся друг с другом в запросе и документах. Это приводит к более точному и контекстуально релевантному набору результатов поиска.",what_is_desc:"Реранкер — это модель искусственного интеллекта, которая уточняет результаты поиска на основе векторного поиска или модели плотного поиска. Читать далее."},Ie={caption_image_desc:"Создайте текстовое описание изображения.",caption_image_title:"Подпись к изображению",description:"Исследуйте рассказывание историй изображениями за пределами пикселей",example1:"Это видео представляет собой кадры природы, на которых изображены очаровательный белый кролик и бабочка в травянистом поле. Зайчик по-разному взаимодействует с бабочкой, демонстрируя их уникальные отношения. Природная среда создает живописный фон, подчеркивая красоту этой простой, но захватывающей сцены.",generate_story_desc:"Создайте историю, вдохновленную изображением, часто включающую диалоги или монологи персонажей.",generate_story_title:"Создать историю",intro1:"Ведущее решение искусственного интеллекта для подписей к изображениям и обзоров видео",json_image_desc:"Создайте структурированный формат JSON из изображения, используя предопределенную схему. Это позволяет извлекать конкретные данные из изображения.",json_image_title:"Извлечь JSON из изображения",summarize_video_desc:"Создайте краткое изложение видео, выделив ключевые события.",summarize_video_title:"Подведение итогов видео",visual_q_a_desc:"Ответьте на запрос, основанный на содержимом изображения.",visual_q_a_title:"Визуальные вопросы и ответы"},ve={ask_on_current_page:"Спросите текущую страницу о...",find_solution:"Создайте решение для...",hint:"Поиск по продуктам, новостям и вашим вопросам",hotkey:"Нажмите клавишу / для поиска на этой странице.",hotkey1:"Нажимать",hotkey2:"переключать",hotkey_long1:"В любой момент нажмите",hotkey_long3:"открыть панель поиска",more_results:"{_numMore} ещё результатов",placeholder:"Задайте любой вопрос на этой странице",proposing_solution:"Генерация ответа на основе содержимого страницы...",required:"Пожалуйста, опишите свой вопрос более подробно.",results:"Результаты"},Pe={description:"Навигация, взаимодействие, уточнение: переосмыслите поиск продукта"},we={description:"Преодоление семантического разрыва в существующей поисковой инфраструктуре"},fe={"Hacker News":"Хакерские новости",LinkedIn:"LinkedIn",facebook:"Фейсбук",reddit:"Реддит",rss:"Новостная лента",share_btn:"Делиться",twitter:"Х (Твиттер)"},ye={click_to_learn_more:"Нажмите, чтобы узнать больше",contextualization:"Контекстуализация",contextualization_desc:"Реранкеры корректируют первоначальные результаты поиска на основе глубокой контекстуальной релевантности. запрос. Это улучшает рейтинг, чтобы лучше соответствовать тому, что пользователи могут найти полезным.",coreInfra:"Базовая инфраструктура",coreInfra_desc:"Core infra обеспечивает облачный уровень для разработки, развертывания и оркестрации моделей платформы поиска как в общедоступном облаке, так и локально, что позволяет легко масштабировать сервисы вверх и вниз.",embedding_serving:"Встраивание обслуживания",embedding_serving_description:"Встраивание с помощью надежного масштабируемого микросервиса с использованием облачных технологий.",embedding_tech:"Вложения",embedding_tech_description:`В Jina AI мы используем возможности внедрения технологий, чтобы произвести революцию в различных приложениях искусственного интеллекта. Эта технология служит унифицированным методом эффективного представления и сжатия различных типов данных, гарантируя отсутствие потери важной информации. Наше внимание сосредоточено на преобразовании сложных наборов данных в универсально понятный формат внедрения, который необходим для точного и глубокого анализа ИИ.

Встраивание имеет основополагающее значение, особенно в таких приложениях, как точное распознавание изображений и голоса, где оно помогает различать мелкие детали и нюансы. При обработке естественного языка встраивания улучшают понимание контекста и настроений, что приводит к созданию более точных инструментов разговорного искусственного интеллекта и языкового перевода. Они также имеют решающее значение для разработки сложных систем рекомендаций, которые требуют глубокого понимания предпочтений пользователей в различных формах контента, таких как текст, аудио и видео.`,embedding_tuning:"Встраивание настройки",embedding_tuning_description:"Оптимизация высококачественных внедрений за счет интеграции опыта предметной области для повышения производительности конкретных задач.",embeddings:"Вложения",embeddings_desc:"Вложения — это краеугольный камень современной поисковой системы, представляющий мультимодальные данные в векторы чисел. Этот процесс обеспечивает более детальное и контекстуальное понимание контента, выходящее далеко за рамки простого сопоставления ключевых слов.",for_developers:"Для разработчиков",for_enterprise:"Для предприятий",for_power_users:"Для опытных пользователей",grounding:"Заземление",grounding_desc:"Читатель уточняет исходные данные и результаты с помощью LLM. Они улучшают качество, читабельность и актуальность окончательного ответа.",model_serving:"Обслуживание моделей",model_serving_description:"Развертывание точно настроенных моделей в производственной среде, обычно требующее значительных ресурсов, таких как хостинг на графическом процессоре. MLOps, уделяя особое внимание обслуживанию моделей среднего и крупного размера масштабируемым, эффективным и надежным способом.",model_tuning:"Настройка модели",model_tuning_description:"Также известная как тонкая настройка, включает в себя настройку параметров предварительно обученной модели на новом, часто специфичном для задачи наборе данных, чтобы улучшить ее производительность и адаптировать ее к конкретному приложению.",personalization:"Персонализация",personalization_desc:"Использование синтетических данных в соответствии с инструкциями пользователя для автоматического обучения модели внедрения и переранжирования для конкретной предметной области.",preprocessing:"Предварительная обработка",preprocessing_desc:"Предварительная обработка включает в себя очистку, нормализацию и преобразование необработанных данных в формат, удобный для восприятия поисковой системой.",promptOps:"PromptOps",promptOps_desc:"Prompt Ops улучшает ввод и вывод поисковой системы, в том числе те, которые используются при расширении запросов, LLM-вводе и переписывании результатов. Это гарантирует, что поиск будет лучше понимать и давать лучшие результаты.",prompt_serving:"Быстрое обслуживание",prompt_serving_description:"Обтекание и обслуживание подсказок через API без размещения тяжелых моделей. API вызывает общедоступную службу модели большого языка и управляет согласованием входных и выходных данных в цепочке операций.",prompt_tech:"Оперативная и агентская разработка",prompt_tech_description:`В Jina AI мы считаем, что оперативное проектирование жизненно важно для взаимодействия с большими языковыми моделями (LLM). По мере развития этих моделей сложность подсказок возрастает, включая сложные рассуждения и логику. Этот прогресс подчеркивает переплетение роста LLM и быстрого развития.

Мы предвидим будущее, в котором LLM будут действовать как компиляторы, а подсказки станут новым языком программирования. Этот сдвиг предполагает, что будущие технологические навыки могут быть больше ориентированы на быстрое освоение, чем на традиционное программирование. Наша цель в Jina AI — стать лидером в этой преобразующей области, делая передовой искусственный интеллект доступным и практичным для повседневного использования путем освоения этого нового «языка».`,prompt_tuning:"Оперативная настройка",prompt_tuning_description:"Процесс создания и уточнения входных подсказок для направления его вывода в сторону конкретных желаемых ответов.",representation:"Представление",representation_desc:"Встраивания преобразуют мультимодальные данные в единый векторизованный формат. Это позволяет поисковой системе понимать и классифицировать контент, помимо простых ключевых слов.",rerankers:"Реранкер",rerankers_desc:"Реранкеры берут первоначальные результаты из вложений и уточняют их, гарантируя, что наиболее релевантные результаты будут представлены пользователю. Это крайне важно для предоставления высококачественных результатов поиска, соответствующих намерениям пользователя."},Le={care_most:"Что вас больше всего волнует?",care_most_options:{accuracy:"Точность",cost:"Расходы",other:"Другой",scalability:"Масштабируемость",speed:"Скорость"},care_most_required:"Что вас больше всего волнует при выборе услуги?",company_size:"Каков размер вашей компании?",company_size_required:"Сообщите нам, что размер вашей компании помогает нам предоставлять лучший сервис.",company_url:"Какой у вашей компании сайт?",company_url_required:"Сообщите нам, что веб-сайт вашей компании помогает нам предоставлять лучший сервис.",contactName:"Ваше имя",contactName_required:"Как нам следует обратиться к вам?",contactTitle:"Какова ваша должность?",contactTitle_required:"Требуется ваша должность",contact_us:"Связаться с нами",domain_required:"Сообщите нам, что ваша область работы помогает нам предоставлять лучший сервис.",email:"Электронная почта",email_contact:"Ваш контактный адрес электронной почты",email_invalid:"Электронная почта недействительна",email_required:"Требуется электронная почта",fine_tuned_embedding:"Заинтересованы в тонко настроенных внедрениях, адаптированных к вашим данным и варианту использования? Давайте обсудим!",fine_tuned_reranker:"Заинтересованы в точно настроенных программах реранкинга, адаптированных к вашим данным и варианту использования? Давайте обсудим!",full_survey:"Пройдите полный опрос и получите более быстрый ответ от нашей команды",get_new_key:"Получите свой API-ключ",get_update_blog_posts:"Получайте последние обновления для сообщений в блоге",get_update_embeddings:"Получайте последние обновления для встраивания",send:"Отправлять",sign_up:"Зарегистрироваться",subscribe:"Подписаться",tell_domain:"Сообщите нам свой домен",usage_type:"Какой тип использования лучше всего описывает вас?",usage_type_options:{other:"Другой",poc:"Доказательство концепции",production:"Производство",research:"Исследовать"},usage_type_required:"Сообщите нам, что ваш тип использования помогает нам предоставлять лучший сервис.",used_product:"Какую модель вы используете?",used_product_required:"Выберите модель, которую вы используете или которая вас интересует"},Re={description:"Методы агента для расширения вашего LLM и выхода за его пределы"},Me="Содержание",xe={advance_usage:"Используйте POST-запрос для получения дополнительных функций",basic_usage:"Используйте GET-запрос для подсчета токенов",basic_usage_explain:"Вы можете просто отправить GET-запрос, чтобы подсчитать количество токенов в вашем тексте.",change_content:"Измените «контент» и посмотрите результат в реальном времени",chars:"персонажи",chinese:"китайский",chunk:"Кусок",chunk_all:"Все куски",chunking:"Молниеносная обработка длинных документов!",chunking_explain:"Вы также можете использовать API Segmenter для разрезания длинных документов на более мелкие фрагменты, что упрощает их обработку в встраиваниях или рераннерах. Мы используем общие структурные подсказки и создаем набор правил и эвристик, которые хорошо работают с различными типами контента, например, языками Markdown, HTML, LaTeX и CJK.",chunking_short:"Разделение на части",chunks_in_total:"{_numChunks} кусков всего",count_tokens_hint:"<b>{_numTokens}</b> токенов, {_numChars} символов.",description:"Разрежьте длинный текст на куски и выполните токенизацию.",description_long:"Наш API Segmenter имеет решающее значение для помощи LLM в управлении вводом в рамках контекстных ограничений и оптимизации производительности модели. Он позволяет разработчикам подсчитывать токены и извлекать соответствующие текстовые сегменты, обеспечивая эффективную обработку данных и управление затратами.",description_long1:"Бесплатный API для сегментации длинного текста на фрагменты и токенизации.",english:"Английский",explain:"Сегментатор — это важный компонент, который преобразует текст в токены или фрагменты, которые являются основными единицами данных, обрабатываемыми моделью внедрения/переранжирования или LLM. Токены могут представлять целые слова, части слов или даже отдельные символы.",faq_v1:{answer1:"API Segmenter можно использовать бесплатно. Предоставляя свой ключ API, вы можете получить доступ к более высокому пределу скорости, и ваш ключ не будет оплачиваться.",answer10:"Помимо западных языков, разбиение на фрагменты также хорошо работает с китайским, японским и корейским языками.",answer2:"Без ключа API вы можете получить доступ к API Segmenter со скоростью 20 об/мин.",answer3:"С помощью API-ключа вы можете получить доступ к API Segmenter с ограничением скорости 200 RPM. Для платных пользователей премиум-подписки ограничение скорости составляет 1000 RPM.",answer4:"Нет, ваш ключ API используется только для доступа к более высокому лимиту скорости.",answer5:"Да, API Segmenter многоязычен и поддерживает более 100 языков.",answer6:"Запросы GET используются исключительно для подсчета количества токенов в тексте, что позволяет вам легко интегрировать его в качестве счетчика в ваше приложение. Запросы POST поддерживают больше параметров и функций, таких как возврат первых/последних N токенов.",answer7:"Вы можете отправить до 64 тыс. символов за один запрос.",answer8:"Функция фрагментации сегментирует длинные документы на более мелкие фрагменты на основе общих структурных сигналов, обеспечивая точную сегментацию текста на значимые фрагменты. По сути, это (большой!) шаблон регулярного выражения, который сегментирует текст на основе определенных синтаксических признаков, которые часто совпадают с семантическими границами, такими как окончания предложений, разрывы абзацев, пунктуация и определенные союзы. Это не семантическое фрагментирование. Это (большое) регулярное выражение настолько мощно, насколько это возможно в рамках ограничений регулярных выражений. Оно уравновешивает сложность и производительность. Хотя истинное семантическое понимание невозможно с помощью регулярных выражений, оно хорошо аппроксимирует контекст с помощью общих структурных сигналов.",answer9:"Если входные данные содержат специальные токены, наш API Segmenter поместит их в поле «special_tokens». Это позволяет вам легко идентифицировать их и обрабатывать соответствующим образом для ваших последующих задач, например, удаляя их перед подачей текста в LLM для предотвращения атак с инъекциями.",question1:"Сколько стоит API Segmenter?",question10:"Поддерживает ли функция фрагментации другие языки, кроме английского?",question2:"Если я не предоставлю ключ API, каков предел скорости?",question3:"Если я предоставлю ключ API, каков предел скорости?",question4:"Будете ли вы взимать плату за токены с моего ключа API?",question5:"Поддерживает ли API Segmenter несколько языков?",question6:"В чем разница между запросами GET и POST?",question7:"Какую максимальную длину я могу токенизировать за один запрос?",question8:"Как работает функция фрагментации? Это семантическая фрагментация?",question9:"Как вы обрабатываете специальные токены, такие как «endoftext» в API Segmenter?",title:"Распространенные вопросы, связанные с сегментатором"},free_api:"Segmenter API можно использовать бесплатно. Предоставляя свой ключ API, вы можете получить доступ к более высокому пределу скорости, и ваш ключ не будет оплачиваться.",input_text:"Введите текст",is_free:"API сегментатора бесплатен!",is_free_description:"Указав свой ключ API, вы сможете получить доступ к более высокому лимиту скорости, и плата за ваш ключ взиматься не будет.",japanese:"японский",korean:"корейский",parameters:{auth_token:"Добавьте ключ API для более высокого лимита скорости",auth_token_explain:"Введите свой ключ API Jina, чтобы получить доступ к более высокому пределу скорости. Для получения последней информации о пределе скорости см. таблицу ниже.",head:"Верните первые N токенов",head_explain:"Возвращает первые N токенов указанного содержимого. Исключает границу. Не может использоваться с 'tail'.",learn_more:"Узнать больше",max_chunk_length:"Максимальная длина каждого фрагмента",max_chunk_length_explain:"Максимальное количество символов в каждом фрагменте. На практике длина фрагмента может быть меньше этого значения, если в тексте есть естественная граница.",return_chunks:"Верните куски",return_chunks_explain:"Разделение входных данных на семантически значимые сегменты с обработкой широкого спектра типов текста и пограничных случаев на основе общих структурных признаков.",return_tokens:"Верните жетоны.",return_tokens_explain:"Верните токены и соответствующие им идентификаторы в ответе. Переключите, чтобы увидеть визуализацию результата.",tail:"Верните последние N токенов",tail_explain:"Возвращает последние N токенов указанного контента. Исключает границу. Не может использоваться с 'head'.",type:"Сегментатор",type_explain:"Выберите токенизатор для использования.",used_by_models:"Используется в {_usedBy}."},remove_boundary_cues:"Удалить переносы строк",remove_boundary_cues_explain:"Удалите все разрывы строк (основные граничные сигналы) из входных данных, это усложнит задачу, и посмотрите, как изменится ответ!",show_space:"Показать начальные/конечные пробелы",table:{td_1_0:"Токенизируйте тексты, подсчитывайте и получайте первые/последние N токенов.",td_1_1:"20 об/мин",td_1_2:"200 об/мин",td_1_3:"1000 об/мин",td_1_4:"Бесплатно",td_1_5:"800мс"},title:"API сегментатора",token_index:"Индекс токена: {_index}",usage:"Использование",visualization:"Визуализация",what_is:"Что такое сегментатор?"},Se={cta:"Перевести на {_lang} код",select_language:"Язык"},qe={description:"База данных векторов Python, которая вам просто необходима — ни больше, ни меньше"},Ce="zzz",je={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:a,api_general_faq:i,autotune:t,avatar:r,best_banner:o,beta:s,billing_general_faq:_,blog_tags:d,book2024:c,cclicence:l,classifier:p,clip_as_service:u,cloud:m,contact_us_page:g,copy:h,copy_to_clipboard_success:b,dalle_flow:A,deepsearch:k,"dev-gpt":{description:"Ваша виртуальная команда разработчиков"},disco_art:I,doc_array:v,download:P,embedding:w,embeddings:f,estimator:y,faq:L,faq_button:R,farewell:M,finetuner:x,finetuner_plus:S,finetuning:q,footer:C,get_new_key:j,github:T,grounding:J,header:B,hub:E,huggingface:G,impact_snapshots:O,inference:z,integrations:D,internship_faq:U,internship_page:F,jcloud:H,jerboa:N,jina:W,jina_chat:K,key_manager:Q,lab_dialog:X,landing_page:V,langchain_serve:Y,legal_page:Z,model_graph:$,models:ee,news_page:ne,newsroom_page:ae,notice:ie,open_day:te,open_day_faq:re,open_gpt:oe,paywall:se,powered_by:_e,print:de,project_status:ce,prompt_perfect:le,promptperfect:pe,purchase:ue,purchase_now:me,rate_limit:ge,rationale:he,reader:be,recommender:Ae,reranker:ke,scenex:Ie,searchbar:ve,searchscape:Pe,semantic:we,share:fe,spectrum:ye,subscribe_system:Le,think_gpt:Re,toc:Me,tokenizer:xe,translator:Se,vectordb:qe,zzz:Ce};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,a as about_us_page,i as api_general_faq,t as autotune,r as avatar,o as best_banner,s as beta,_ as billing_general_faq,d as blog_tags,c as book2024,l as cclicence,p as classifier,u as clip_as_service,m as cloud,g as contact_us_page,h as copy,b as copy_to_clipboard_success,A as dalle_flow,k as deepsearch,je as default,I as disco_art,v as doc_array,P as download,w as embedding,f as embeddings,y as estimator,L as faq,R as faq_button,M as farewell,x as finetuner,S as finetuner_plus,q as finetuning,C as footer,j as get_new_key,T as github,J as grounding,B as header,E as hub,G as huggingface,O as impact_snapshots,z as inference,D as integrations,U as internship_faq,F as internship_page,H as jcloud,N as jerboa,W as jina,K as jina_chat,Q as key_manager,X as lab_dialog,V as landing_page,Y as langchain_serve,Z as legal_page,$ as model_graph,ee as models,ne as news_page,ae as newsroom_page,ie as notice,te as open_day,re as open_day_faq,oe as open_gpt,se as paywall,_e as powered_by,de as print,ce as project_status,le as prompt_perfect,pe as promptperfect,ue as purchase,me as purchase_now,ge as rate_limit,he as rationale,be as reader,Ae as recommender,ke as reranker,Ie as scenex,ve as searchbar,Pe as searchscape,we as semantic,fe as share,ye as spectrum,Le as subscribe_system,Re as think_gpt,Me as toc,xe as tokenizer,Se as translator,qe as vectordb,Ce as zzz};
