const r={PRODUCT_DESCRIPTION:e=>{const{normalize:i}=e;return i(["Forniamo incorporamenti, riclassificatori, lettori LLM e ottimizzatori tempestivi di altissimo livello, un'intelligenza artificiale di ricerca pionieristica per dati multimodali."])},SEO_TAG_LINE:e=>{const{normalize:i}=e;return i(["La tua base di ricerca, potenziata."])},about_us_page:{approach:e=>{const{normalize:i}=e;return i(["Il nostro approccio"])},approach_connect_dots:e=>{const{normalize:i}=e;return i(["Collegare i punti: Power Users alle imprese"])},approach_connect_dots_description:e=>{const{normalize:i}=e;return i(["Quindi, perché l'attenzione per gli utenti esperti è essenziale per il nostro modello incentrato sull'azienda? Perché si tratta di stabilire relazioni precoci. Rivolgendoci ora agli utenti esperti, stiamo costruendo ponti verso le imprese che influenzeranno in futuro. È un gioco strategico: un investimento a lungo termine per garantire che la nostra offerta aziendale rimanga al primo posto quando questi utenti esperti salgono a ruoli decisionali all'interno delle organizzazioni."])},approach_content1:e=>{const{normalize:i}=e;return i(["Nel mondo in rapida evoluzione dell'IA, le strategie devono essere agili e lungimiranti. Sebbene la nostra offerta principale rimanga incentrata sulle aziende, il panorama dell'IA è cambiato in modi che richiedono un ripensamento del nostro approccio all'acquisizione dei clienti. Ecco perché introdurre gli utenti esperti come punto di ingresso della nostra canalizzazione non è solo innovativo, ma cruciale per la nostra crescita sostenuta nel settore aziendale."])},approach_content2:e=>{const{normalize:i}=e;return i(["In Jina AI, la nostra strategia è quella di essere proattivi piuttosto che reattivi. L'inclusione degli utenti esperti come punto di ingresso della canalizzazione garantisce che non solo catturiamo le attuali tendenze del mercato, ma siamo anche strategicamente pronti per la futura crescita aziendale. Il nostro impegno nei confronti delle imprese rimane incrollabile; tuttavia, il nostro approccio per raggiungerli è innovativo, robusto e, soprattutto, lungimirante."])},approach_content4:e=>{const{normalize:i}=e;return i(['Tutti vogliono una ricerca migliore. In Jina AI, rendiamo possibile una ricerca migliore fornendo la <span class="text-primary text-bold">Search Foundation</span>, che consiste in Embeddings, Rerankers, Reader e Prompt Ops. Questi componenti lavorano di concerto per rivoluzionare il modo in cui cerchiamo e comprendiamo i dati.'])},approach_miss_mark:e=>{const{normalize:i}=e;return i(["Perché i MLOps tradizionali mancano il bersaglio"])},approach_miss_mark_description:e=>{const{normalize:i}=e;return i(["Sebbene l'afflusso di utenti esperti sia significativo, gli strumenti MLOps tradizionali non sono attrezzati per soddisfare le loro esigenze. Questi strumenti ricordano l'uso di un trattore per spostarsi nelle strade della città: sono pesanti e spesso eccessivi. Gli sviluppatori di nuova generazione richiedono strumenti agili e intuitivi che completino il loro rapido ritmo di sviluppo."])},approach_new_paradigm:e=>{const{normalize:i}=e;return i(["Tecnologia basata su prompt: un nuovo paradigma"])},approach_new_paradigm_description:e=>{const{normalize:i}=e;return i([`Il 2023 ha annunciato un cambiamento significativo: l'ascesa della tecnologia basata sul prompt. Semplificando il processo di sviluppo dell'IA, ha democratizzato l'accesso agli strumenti di intelligenza artificiale. Ora, coloro che non hanno una vasta esperienza di programmazione, definiti "utenti esperti", possono dedicarsi allo sviluppo dell'IA senza le ripide curve di apprendimento associate a strumenti come Pytorch, Docker o Kubernetes.

Facendo un parallelo, questo è simile all'evoluzione del personal computer. Inizialmente, solo gli esperti di tecnologia gestivano i computer. Ma con l'avvento delle interfacce user-friendly, potrebbe partecipare un pubblico più ampio. Oggi, con la tecnologia basata sul prompt, stiamo assistendo a una democratizzazione simile nell'IA.`])},awards:e=>{const{normalize:i}=e;return i(["Premi e riconoscimenti"])},berlin:e=>{const{normalize:i}=e;return i(["Berlino, Germania"])},berlin_address:e=>{const{normalize:i}=e;return i(["Prinzessinnenstraße 19-20, 10969 Berlino, Germania"])},berlin_address2:e=>{const{normalize:i}=e;return i(["Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlino, Germania"])},bj:e=>{const{normalize:i}=e;return i(["Pechino, Cina"])},bj_address:e=>{const{normalize:i}=e;return i(["Livello 5, Edificio 6, No.48 Haidian West St. Beijing Haidian, Cina"])},brochure_info:e=>{const{normalize:i}=e;return i(["La tua guida alla nostra azienda ti aspetta"])},description:e=>{const{normalize:i}=e;return i(["Il futuro inizia qui."])},download_brochure1:e=>{const{normalize:i}=e;return i(["Scarica l'opuscolo"])},download_docarray_logo:e=>{const{normalize:i}=e;return i(["Scarica il logo DocArray"])},download_docarray_logo_desc:e=>{const{normalize:i}=e;return i(["Accedi al logo DocArray, un progetto open source avviato da Jina AI e contribuito alla Linux Foundation nel dicembre 2022. Disponibile in modalità chiara e scura, nei formati PNG e SVG."])},download_jina_logo:e=>{const{normalize:i}=e;return i(["Scarica il logo Jina AI"])},download_jina_logo_desc:e=>{const{normalize:i}=e;return i(["Ottieni il logo Jina AI sia in modalità chiara che scura, disponibile nei formati PNG e SVG. Questo logo è un marchio registrato presso l'Ufficio dell'Unione europea per la proprietà intellettuale (EUIPO)."])},download_logo:e=>{const{normalize:i}=e;return i(["Scarica loghi"])},employees:e=>{const{normalize:i}=e;return i(["Dipendenti oggi"])},empower_developers:e=>{const{normalize:i}=e;return i(["Sviluppatori potenziati"])},fastApiCaption:e=>{const{normalize:i}=e;return i(["Ha contribuito con oltre $ 20.000 dal 2021."])},founded:e=>{const{normalize:i}=e;return i(["Fondato"])},founded_in:e=>{const{normalize:i}=e;return i(["Fondato nel"])},investors:e=>{const{normalize:i}=e;return i(["I nostri investitori"])},linuxFoundationCaption:e=>{const{normalize:i}=e;return i(["Versa un contributo annuo di $ 10.000 a partire dal 2022."])},many:e=>{const{normalize:i}=e;return i(["Molti"])},media:{video:e=>{const{normalize:i}=e;return i(["Intervista video"])}},mission:e=>{const{normalize:i}=e;return i(["La nostra missione"])},mission_content1:e=>{const{normalize:i}=e;return i(["Le nostre tecnologie chiave, tra cui prompt-tuning, prompt-serving, model-tuning e model-serving, incarnano il nostro impegno a democratizzare l'accesso all'intelligenza artificiale. Attraverso la nostra iniziativa open source, ci impegniamo a promuovere l'innovazione, la collaborazione e la trasparenza, garantendo soluzioni scalabili, efficienti e robuste. Jina AI è più di una semplice azienda; è una comunità dedicata a consentire alle aziende di affrontare le sfide dinamiche dell'era digitale e prosperare nei loro settori."])},mission_content2:e=>{const{normalize:i}=e;return i(["Al centro di Jina AI c'è la nostra missione di essere il portale dell'intelligenza artificiale multimodale per una clientela diversificata, dagli utenti esperti e dagli sviluppatori alle imprese. Crediamo profondamente nella potenza dell'open source e ci dedichiamo alla creazione di strumenti avanzati e accessibili per la comunità AI. Le nostre tecnologie chiave, tra cui prompt-tuning, prompt-serving, embedding-tuning e embedding-serving, incarnano il nostro impegno per la democratizzazione dell'accesso all'intelligenza artificiale. Attraverso la nostra iniziativa open source, ci impegniamo a promuovere l'innovazione, la collaborazione e la trasparenza, garantendo soluzioni scalabili, efficienti e robuste. Jina AI è più di una semplice azienda; è una comunità dedicata a consentire alle aziende di affrontare le sfide dinamiche dell'era digitale e prosperare nei loro settori."])},mission_content3:e=>{const{normalize:i}=e;return i(["In Jina AI, la nostra missione è guidare il progresso dell'intelligenza artificiale multimodale attraverso tecnologie innovative di incorporamento e basate su prompt, concentrandoci specificamente su aree come l'elaborazione del linguaggio naturale, l'analisi di immagini e video e l'interazione intermodale dei dati. Questa specializzazione ci consente di fornire soluzioni uniche che trasformano dati complessi provenienti da più fonti in informazioni fruibili e applicazioni rivoluzionarie."])},mit_report_title:e=>{const{normalize:i}=e;return i(["Multimodale: la nuova frontiera dell’IA"])},mit_techreview:e=>{const{normalize:i}=e;return i(["Revisione della tecnologia del MIT"])},numfocusCaption:e=>{const{normalize:i}=e;return i(["Dona regolarmente ogni mese a partire dal 2022."])},office:e=>{const{normalize:i}=e;return i(["I nostri uffici"])},otherProjectsCaption:e=>{const{normalize:i}=e;return i(["Donati oltre $ 3.000 tramite Github Sponsorship."])},our_answer:e=>{const{normalize:i}=e;return i(["Assolutamente, Yann. Ci stiamo lavorando, costruendo ponti verso un futuro di intelligenza artificiale multimodale!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:i}=e;return i(["Ha fornito una donazione una tantum di $ 10.000 e ha sponsorizzato numerosi eventi PyCon, inclusi quelli in Germania, Italia, Cina e Stati Uniti."])},sefo:{layer0:e=>{const{normalize:i}=e;return i(["Applicazioni per l'utente finale"])},layer1:e=>{const{normalize:i}=e;return i(["RAG/orchestrazione"])},layer3:e=>{const{normalize:i}=e;return i(["GPU/mobile/edge/elaborazione locale"])}},segmentFaultCaption:e=>{const{normalize:i}=e;return i(["Ha contribuito con una donazione una tantum di $ 6.000."])},show_position:e=>{const{normalize:i}=e;return i(["Come si posizionano le fondamenta della ricerca nell'ecosistema?"])},stats_1:e=>{const{normalize:i}=e;return i(["Fondata nel febbraio 2020, Jina AI è rapidamente emersa come pioniere globale nella tecnologia AI multimodale. Nell'impressionante lasso di tempo di 20 mesi, abbiamo raccolto con successo 37,5 milioni di dollari, segnando la nostra posizione di forza nel settore dell'IA. La nostra rivoluzionaria tecnologia, open-source su GitHub, ha consentito a oltre 40.000 sviluppatori in tutto il mondo di creare e distribuire senza problemi sofisticate applicazioni multimodali."])},stats_2:e=>{const{normalize:i}=e;return i(["Nel 2023, abbiamo fatto passi da gigante nel far progredire gli strumenti di generazione dell'IA basati sulla tecnologia multimodale. Questa innovazione ha beneficiato di oltre 250.000 utenti in tutto il mondo, soddisfacendo una pletora di requisiti aziendali unici. Dalla facilitazione della crescita aziendale e dal miglioramento dell'efficienza operativa all'ottimizzazione dei costi, Jina AI è dedicata a consentire alle aziende di eccellere nell'era multimodale."])},stats_4:e=>{const{normalize:i}=e;return i([`Fondata nel 2020 a Berlino, Jina AI è un'azienda leader nel settore dell'intelligenza artificiale per la ricerca. Forniamo <span class="text-primary text-bold">Search Foundation</span>, il nucleo per GenAI e applicazioni multimodali. La nostra missione è aiutare le aziende e gli sviluppatori a sbloccare i dati multimodali per la creazione di valore con una ricerca migliore. In quanto azienda commerciale open source, ci piace l'innovazione aperta.`])},stats_v1:e=>{const{normalize:i}=e;return i(["Cerca/acc"])},subtitle:e=>{const{normalize:i}=e;return i(["Rivoluzionando la creazione di contenuti attraverso soluzioni generate dall'intelligenza artificiale per sbloccare infinite possibilità. Plasmare il futuro dei contenuti generati dall'intelligenza artificiale e migliorare la creatività umana."])},sues_und_sauer:e=>{const{normalize:i}=e;return i(["Suẞ & Sauer"])},sues_und_sauer_tooltip:e=>{const{normalize:i}=e;return i(["Süß-Sauer, un sapore popolare (ma stereotipato) nella cucina tedesco-cinese, significa agrodolce. È una metafora degli alti e bassi della vita da startup."])},sz:e=>{const{normalize:i}=e;return i(["Shenzen, Cina"])},sz_address:e=>{const{normalize:i}=e;return i(["402, Piano 4, Fu'an Technology Building, Shenzhen Nanshan, Cina"])},team:e=>{const{normalize:i}=e;return i(["All'interno del Portale di Jina AI"])},team_content1:e=>{const{normalize:i}=e;return i(["Da diversi angoli del globo, stiamo costruendo il futuro dell'intelligenza artificiale. Le nostre prospettive distinte arricchiscono il nostro lavoro, innescando innovazioni. All'interno di questo portale, abbracciamo la nostra individualità e perseguiamo con passione i nostri sogni. Benvenuti nel portale del futuro dell'IA."])},team_join:e=>{const{normalize:i}=e;return i(["Unisciti a noi"])},team_size:e=>{const{normalize:i}=e;return i(["Queste foto includono i nostri ex colleghi e stagisti: li apprezziamo tutti."])},technologies:e=>{const{normalize:i}=e;return i(["Tecnologie"])},title:e=>{const{normalize:i}=e;return i(["A proposito di Jina AI"])},title0:e=>{const{normalize:i}=e;return i(["Il futuro"])},title1:e=>{const{normalize:i}=e;return i(["Inizia"])},title2:e=>{const{normalize:i}=e;return i(["Qui"])},title3:e=>{const{normalize:i}=e;return i(["Inizia qui"])},understand_our_strength:e=>{const{normalize:i}=e;return i(["Comprendi la nostra forza"])},understand_our_view2:e=>{const{normalize:i}=e;return i(["Comprendere il fondamento della ricerca"])},users:e=>{const{normalize:i}=e;return i(["Utenti registrati"])},value:e=>{const{normalize:i}=e;return i(["Il nostro valore"])},value_content1:e=>{const{normalize:i}=e;return i(["L'apertura stimola l'innovazione e alimenta la collaborazione. Non ci limitiamo a supportare questa idea, la viviamo. Abbiamo reso open source i nostri modelli e progetti, condividendo la nostra competenza con il mondo. E andiamo oltre: dall'essere uno dei primi donatori di FastAPI, al sostenere attivamente la Linux Foundation e la Python Software Foundation, siamo profondamente impegnati a restituire."])},vision:e=>{const{normalize:i}=e;return i(["La nostra missione"])},vision_content1:e=>{const{normalize:i}=e;return i(["Ispirato dall'intuizione di Yann LeCun che '"])},vision_content3:e=>{const{normalize:i}=e;return i([`Il futuro dell'intelligenza artificiale è <span class="text-primary text-bold">multimodale</span> e noi ne facciamo parte. Ci rendiamo conto che le aziende devono affrontare sfide nello sfruttamento dei dati multimodali. In risposta, ci impegniamo a favore della <span class="text-primary text-bold">Search Foundation</span> per aiutare le aziende e gli sviluppatori a effettuare ricerche migliori e a utilizzare dati multimodali per la crescita aziendale.`])},yannlecun_quote:e=>{const{normalize:i}=e;return i(["Un sistema di intelligenza artificiale addestrato solo su parole e frasi non si avvicinerà mai alla comprensione umana."])}},api_general_faq:{answer1:e=>{const{normalize:i}=e;return i(["Sì, la stessa chiave API è valida per tutti i prodotti di base di ricerca di Jina AI. Ciò include l'incorporamento, il riclassificazione, il lettore e l'ottimizzazione delle API, con token condivisi tra tutti i servizi."])},answer12:e=>{const{normalize:i}=e;return i(["Aderiamo a una rigorosa politica sulla privacy e non utilizziamo i dati di input degli utenti per addestrare i nostri modelli."])},answer3:e=>{const{normalize:i}=e;return i([`Sì, l'utilizzo dei token può essere monitorato nella scheda "Acquista token" inserendo la chiave API, consentendoti di visualizzare la cronologia di utilizzo e i token rimanenti.`])},answer4:e=>{const{normalize:i}=e;return i(["Se hai smarrito una chiave ricaricata e desideri recuperarla, contatta il supporto AT jina.ai con la tua e-mail registrata per ricevere assistenza."])},answer5:e=>{const{normalize:i}=e;return i(["No, le nostre chiavi API non hanno una data di scadenza. Tuttavia, se sospetti che la tua chiave sia stata compromessa e desideri ritirarla o trasferire i suoi token su una nuova chiave, contatta il nostro team di supporto per assistenza."])},answer6:e=>{const{normalize:i}=e;return i(['Questo perché la nostra architettura serverless scarica determinati modelli durante i periodi di scarso utilizzo. La richiesta iniziale attiva o "riscalda" il modello, operazione che potrebbe richiedere alcuni secondi. Dopo questa attivazione iniziale, le richieste successive vengono elaborate molto più rapidamente.'])},question1:e=>{const{normalize:i}=e;return i(["Posso utilizzare la stessa chiave API per incorporare, riclassificare, leggere e ottimizzare le API?"])},question12:e=>{const{normalize:i}=e;return i(["I dati di input dell'utente vengono utilizzati per addestrare i tuoi modelli?"])},question3:e=>{const{normalize:i}=e;return i(["Posso monitorare l'utilizzo del token della mia chiave API?"])},question4:e=>{const{normalize:i}=e;return i(["Cosa devo fare se dimentico la mia chiave API?"])},question5:e=>{const{normalize:i}=e;return i(["Le chiavi API scadono?"])},question6:e=>{const{normalize:i}=e;return i(["Perché la prima richiesta per alcuni modelli è lenta?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative all'API"])}},autotune:{base_model:e=>{const{normalize:i}=e;return i(["Modello base per la messa a punto"])},check_data:e=>{const{normalize:i}=e;return i(["Scarica i dati sintetici"])},check_model:e=>{const{normalize:i}=e;return i(["Scarica il modello ottimizzato"])},data_size:e=>{const{normalize:i}=e;return i(["Dati sintetici generati"])},description:e=>{const{normalize:i}=e;return i(["Ottieni incorporamenti ottimizzati per qualsiasi dominio desideri."])},description_long:e=>{const{normalize:i}=e;return i(["Dicci semplicemente in quale dominio desideri che i tuoi incorporamenti eccellano e noi forniremo automaticamente un modello di incorporamento pronto all'uso e ottimizzato per quel dominio."])},does_it_work_tho:e=>{const{normalize:i}=e;return i(["Ma funziona comunque?"])},does_it_work_tho_explain:e=>{const{normalize:i}=e;return i(["La regolazione fine automatica mantiene la promessa auto-magica di fornire incorporamenti ottimizzati per qualsiasi dominio tu voglia. Ma funziona veramente? Questo è un dubbio abbastanza ragionevole. Lo abbiamo testato su una varietà di domini e modelli base per scoprirlo. Dai un'occhiata ai risultati selezionati con la ciliegia e con il limone qui sotto."])},domain_instruction:e=>{const{normalize:i}=e;return i(["Istruzioni sul dominio"])},embedding_provider:e=>{const{normalize:i}=e;return i(["Seleziona un modello di incorporamento di base"])},eval_evaluation:e=>{const{normalize:i}=e;return i(["Validazione"])},eval_map:e=>{const{normalize:i}=e;return i(["CARTA GEOGRAFICA"])},eval_mrr:e=>{const{normalize:i}=e;return i(["MRR"])},eval_ndcg:e=>{const{normalize:i}=e;return i(["NDCG"])},eval_performance_before_after:e=>{const{normalize:i}=e;return i(["Prestazioni sul set di validazione sintetica prima e dopo la messa a punto"])},eval_syntheticDataSize:e=>{const{normalize:i}=e;return i(["Totale"])},eval_test:e=>{const{normalize:i}=e;return i(["Dati reali per i test"])},eval_training:e=>{const{normalize:i}=e;return i(["Formazione"])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i(["La funzionalità è attualmente in versione beta e costa 1 milione di token per modello ottimizzato. Puoi utilizzare la chiave API esistente dall'API Embedding/Reranker se dispone di token sufficienti oppure puoi creare una nuova chiave API, che include 1 milione di token gratuiti."])},answer10:e=>{const{normalize:i}=e;return i(["Attualmente no. Tieni presente che questa funzionalità è ancora in versione beta. L'archiviazione pubblica dei modelli ottimizzati e dei dati sintetici nell'hub del modello Hugging Face aiuta noi e la comunità a valutare la qualità della formazione. In futuro, prevediamo di offrire un'opzione di archiviazione privata."])},answer11:e=>{const{normalize:i}=e;return i(["Poiché tutti i modelli ottimizzati vengono caricati su Hugging Face, puoi accedervi tramite SentenceTransformers semplicemente specificando il nome del modello."])},answer12:e=>{const{normalize:i}=e;return i(["Per favore controlla la tua cartella spam. Se ancora non riesci a trovarlo, contatta il nostro team di supporto utilizzando l'indirizzo email che hai fornito."])},answer2:e=>{const{normalize:i}=e;return i(["Non è necessario fornire alcun dato di addestramento. Descrivi semplicemente il tuo dominio di destinazione (il dominio per il quale desideri ottimizzare gli incorporamenti) in linguaggio naturale o utilizza un URL come riferimento e il nostro sistema genererà dati sintetici per addestrare il modello."])},answer3:e=>{const{normalize:i}=e;return i(["Circa 30 minuti."])},answer4:e=>{const{normalize:i}=e;return i(["I modelli ottimizzati e i dati sintetici vengono archiviati pubblicamente nell'hub del modello Hugging Face."])},answer5:e=>{const{normalize:i}=e;return i(["Il sistema utilizza l'API Reader per recuperare il contenuto dall'URL. Quindi analizza il contenuto per riassumere il tono e il dominio, che utilizza come linee guida per la generazione di dati sintetici. Pertanto, l'URL dovrebbe essere accessibile al pubblico e rappresentativo del dominio di destinazione."])},answer6:e=>{const{normalize:i}=e;return i([`Sì, puoi mettere a punto un modello per una lingua diversa dall'inglese. Il sistema rileva automaticamente la lingua delle istruzioni del tuo dominio e genera di conseguenza dati sintetici. Raccomandiamo inoltre di scegliere il modello base appropriato per la lingua di destinazione. Ad esempio, se scegli come target un dominio tedesco, dovresti selezionare "jina-embeddings-v2-base-de" come modello base.`])},answer7:e=>{const{normalize:i}=e;return i(["No, la nostra API di ottimizzazione supporta solo i modelli Jina v2."])},answer8:e=>{const{normalize:i}=e;return i(["Al termine del processo di messa a punto, il sistema valuta il modello utilizzando un set di test e segnala le metriche delle prestazioni. Riceverai un'e-mail con i dettagli delle prestazioni prima/dopo su questo set di test. Ti invitiamo inoltre a valutare il modello sul tuo set di test per garantirne la qualità."])},answer9:e=>{const{normalize:i}=e;return i(["Il sistema genera dati sintetici integrando le istruzioni del dominio di destinazione fornite con il ragionamento degli agenti LLM. Produce triplette negative rigide, essenziali per l'addestramento di modelli di incorporamento di alta qualità. Per maggiori dettagli, fare riferimento al nostro prossimo documento di ricerca su Arxiv."])},question1:e=>{const{normalize:i}=e;return i(["Quanto costa l'API di fine-tuning?"])},question10:e=>{const{normalize:i}=e;return i(["Posso mantenere privati ​​i miei modelli ottimizzati e i dati sintetici?"])},question11:e=>{const{normalize:i}=e;return i(["Come posso utilizzare il modello ottimizzato?"])},question12:e=>{const{normalize:i}=e;return i(["Non ho mai ricevuto l'e-mail con i risultati della valutazione. Cosa dovrei fare?"])},question2:e=>{const{normalize:i}=e;return i(["Cosa devo inserire? Devo fornire i dati di allenamento?"])},question3:e=>{const{normalize:i}=e;return i(["Quanto tempo ci vuole per mettere a punto un modello?"])},question4:e=>{const{normalize:i}=e;return i(["Dove vengono archiviati i modelli ottimizzati?"])},question5:e=>{const{normalize:i}=e;return i(["Se fornisco un URL di riferimento, come lo utilizza il sistema?"])},question6:e=>{const{normalize:i}=e;return i(["Posso mettere a punto un modello per una lingua specifica?"])},question7:e=>{const{normalize:i}=e;return i(["Posso ottimizzare gli incorporamenti non Jina, ad esempio bge-M3?"])},question8:e=>{const{normalize:i}=e;return i(["Come garantite la qualità dei modelli perfezionati?"])},question9:e=>{const{normalize:i}=e;return i(["Come si generano dati sintetici?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative alla regolazione fine automatica"])}},find_on_hf:e=>{const{normalize:i}=e;return i(["Elenca i modelli ottimizzati"])},temporarily_unavailable:e=>{const{normalize:i}=e;return i(["Temporaneamente non disponibile. Stiamo aggiornando il nostro sistema di regolazione automatica per offrirti un servizio migliore. Per favore controllare più tardi."])},test_on:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Testato su campioni casuali ",n(o("_dataSize"))," da ",n(o("_dataName"))])},test_performance_before_after:e=>{const{normalize:i}=e;return i(["Prestazioni sul test impostato prima e dopo la messa a punto"])},title:e=>{const{normalize:i}=e;return i(["API di regolazione fine automatica"])},total_improve:e=>{const{normalize:i}=e;return i(["Media miglioramento"])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},what_is:e=>{const{normalize:i}=e;return i(["Che cos'è la sintonizzazione fine automatica?"])},what_is_answer_long:e=>{const{normalize:i}=e;return i(["L'ottimizzazione consente di prendere un modello pre-addestrato e adattarlo a un'attività o dominio specifico addestrandolo su un nuovo set di dati. In pratica, trovare dati di addestramento efficaci non è semplice per molti utenti. Una formazione efficace richiede molto più che il semplice inserimento di PDF grezzi e HTML nel modello; ed è difficile farlo bene. La regolazione fine automatica risolve questo problema generando automaticamente dati di addestramento efficaci utilizzando una pipeline di agenti LLM avanzata; e mettere a punto il modello all'interno di un flusso di lavoro ML. Puoi pensarlo come una combinazione di generazione di dati sintetici e AutoML, quindi tutto ciò che devi fare è descrivere il tuo dominio di destinazione in linguaggio naturale e lasciare che il nostro sistema faccia il resto."])}},best_banner:{description:e=>{const{normalize:i}=e;return i(["Dal blog al banner, senza i prompt!"])},example_description:e=>{const{normalize:i}=e;return i([`Alice cominciava a stancarsi molto di stare seduta accanto a sua sorella sulla riva e di non avere niente da fare: una o due volte aveva sbirciato nel libro che sua sorella stava leggendo, ma non conteneva immagini o conversazioni, "e a che serve un libro", pensò Alice "senza immagini o conversazioni?" Quindi stava valutando tra sé (come meglio poteva, perché la giornata calda la faceva sentire molto assonnata e stupida), se il piacere di fare una catena di margherite sarebbe valsa la pena di alzarsi e raccogliere le margherite, quando all'improvviso un Bianconiglio con gli occhi rosa le corse vicino.`])},example_title:e=>{const{normalize:i}=e;return i(["Le avventure di Alice nel paese delle meraviglie - Capitolo 1"])}},beta:e=>{const{normalize:i}=e;return i(["Beta"])},billing_general_faq:{answer10:e=>{const{normalize:i}=e;return i([`Offriamo un'accogliente prova gratuita ai nuovi utenti, che include un milione di token da utilizzare con qualsiasi dei nostri modelli, facilitata da una chiave API generata automaticamente. Una volta raggiunto il limite di token gratuiti, gli utenti possono facilmente acquistare token aggiuntivi per le proprie chiavi API tramite la scheda "Acquista token".`])},answer13:e=>{const{normalize:i}=e;return i(["No, i token non vengono detratti per le richieste non riuscite."])},answer14:e=>{const{normalize:i}=e;return i(["I pagamenti vengono elaborati tramite Stripe, che supporta una varietà di metodi di pagamento tra cui carte di credito, Google Pay e PayPal per la tua comodità."])},answer15:e=>{const{normalize:i}=e;return i(["Sì, al momento dell'acquisto dei token verrà emessa una fattura all'indirizzo e-mail associato al tuo account Stripe."])},answer9:e=>{const{normalize:i}=e;return i(["Il nostro modello di prezzo si basa sul numero totale di token elaborati, consentendo agli utenti la flessibilità di allocare questi token su qualsiasi numero di frasi, offrendo una soluzione economicamente vantaggiosa per diversi requisiti di analisi del testo."])},question10:e=>{const{normalize:i}=e;return i(["È disponibile una prova gratuita per i nuovi utenti?"])},question13:e=>{const{normalize:i}=e;return i(["Vengono addebitati i token per le richieste non riuscite?"])},question14:e=>{const{normalize:i}=e;return i(["Quali metodi di pagamento sono accettati?"])},question15:e=>{const{normalize:i}=e;return i(["È disponibile la fatturazione per gli acquisti di token?"])},question9:e=>{const{normalize:i}=e;return i(["La fatturazione è basata sul numero di frasi o richieste?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative alla fatturazione"])}},blog_tags:{all:e=>{const{normalize:i}=e;return i(["Tutto"])},events:e=>{const{normalize:i}=e;return i(["Evento"])},featured:e=>{const{normalize:i}=e;return i(["In primo piano"])},insights:e=>{const{normalize:i}=e;return i(["Opinione"])},"knowledge-base":e=>{const{normalize:i}=e;return i(["Base di conoscenza"])},latest:e=>{const{normalize:i}=e;return i(["Ultimo"])},press:e=>{const{normalize:i}=e;return i(["comunicato stampa"])},releases:e=>{const{normalize:i}=e;return i(["Aggiornamento del software"])},"tech-blog":e=>{const{normalize:i}=e;return i(["Blog tecnico"])}},cclicence:{api_free_trial:e=>{const{normalize:i}=e;return i(["Chiave API gratuita"])},api_paid:e=>{const{normalize:i}=e;return i(["Chiave API a pagamento"])},api_paid_or_free:e=>{const{normalize:i}=e;return i(["Stai utilizzando una chiave API a pagamento o una chiave di prova gratuita?"])},are_you:e=>{const{normalize:i}=e;return i(["Sei:"])},commercial_contact_sales:e=>{const{normalize:i}=e;return i(["Questo è commerciale. Contatta il nostro team di vendita."])},contact_sales_for_licensing:e=>{const{normalize:i}=e;return i(["Contatta il nostro team commerciale per le licenze."])},csp_user:e=>{const{normalize:i}=e;return i(["Stai utilizzando le nostre immagini modello ufficiali su AWS e Azure?"])},educational_teaching:e=>{const{normalize:i}=e;return i(["Un istituto scolastico che lo utilizza per l'insegnamento?"])},for_profit_internal_use:e=>{const{normalize:i}=e;return i(["Un'azienda a scopo di lucro che lo utilizza internamente?"])},free_use:e=>{const{normalize:i}=e;return i(["Puoi utilizzare i modelli liberamente."])},government_public_services:e=>{const{normalize:i}=e;return i(["Un ente governativo che lo utilizza per servizi pubblici?"])},is_use_commercial:e=>{const{normalize:i}=e;return i(["Il tuo utilizzo è commerciale?"])},may_be_commercial_contact:e=>{const{normalize:i}=e;return i(["Potrebbe essere commerciale. Vi preghiamo di contattarci per chiarimenti."])},no:e=>{const{normalize:i}=e;return i(["NO"])},no1:e=>{const{normalize:i}=e;return i(["NO"])},no2:e=>{const{normalize:i}=e;return i(["NO"])},no3:e=>{const{normalize:i}=e;return i(["NO"])},no_restrictions:e=>{const{normalize:i}=e;return i(["Nessuna restrizione. Utilizza secondo il tuo attuale accordo."])},no_restrictions_apply:e=>{const{normalize:i}=e;return i(["Non si applicano restrizioni."])},non_commercial_free_use:e=>{const{normalize:i}=e;return i(["Questo non è commerciale. Puoi usare i modelli liberamente."])},non_profit_ngo_mission:e=>{const{normalize:i}=e;return i(["Un'organizzazione non-profit o una ONG che lo utilizza per la propria missione?"])},not_sure:e=>{const{normalize:i}=e;return i(["Non è sicuro"])},personal_hobby_projects:e=>{const{normalize:i}=e;return i(["Lo usi per progetti personali o hobbistici?"])},product_service_sale:e=>{const{normalize:i}=e;return i(["Lo stai utilizzando in un prodotto o servizio che vendi?"])},title:e=>{const{normalize:i}=e;return i(["Autoverifica della licenza CC BY-NC"])},trial_key_restrictions:e=>{const{normalize:i}=e;return i(["La chiave di prova gratuita può essere utilizzata solo per scopi non commerciali. Acquista un pacchetto a pagamento per uso commerciale."])},typically_non_commercial_check:e=>{const{normalize:i}=e;return i(["In genere non si tratta di un'attività commerciale, ma in caso di dubbi contattateci."])},typically_non_commercial_free_use:e=>{const{normalize:i}=e;return i(["Questo è tipicamente non commerciale. Puoi usare i modelli liberamente."])},using_api_or_cloud:e=>{const{normalize:i}=e;return i(["Stai utilizzando la nostra API ufficiale o le immagini ufficiali su Azure o AWS?"])},using_cc_by_nc_models:e=>{const{normalize:i}=e;return i(["Stai utilizzando questi modelli?"])},yes:e=>{const{normalize:i}=e;return i(["SÌ"])},yes1:e=>{const{normalize:i}=e;return i(["SÌ"])},yes2:e=>{const{normalize:i}=e;return i(["SÌ"])},yes3:e=>{const{normalize:i}=e;return i(["SÌ"])}},classifier:{access:e=>{const{normalize:i}=e;return i(["Accesso pubblico"])},access_explain:e=>{const{normalize:i}=e;return i(["I classificatori pubblici possono essere utilizzati da chiunque abbia <code>classifier_id</code> e il loro utilizzo consumerà la quota di token del chiamante anziché la tua. I classificatori privati sono accessibili solo a te."])},access_private:e=>{const{normalize:i}=e;return i(["Privato"])},access_public:e=>{const{normalize:i}=e;return i(["Pubblico"])},api_delete:e=>{const{normalize:i}=e;return i(["Elimina classificatore"])},api_delete_explain:e=>{const{normalize:i}=e;return i(["Elimina un classificatore in base al suo ID."])},api_list:e=>{const{normalize:i}=e;return i(["Elenca classificatori"])},api_list_explain:e=>{const{normalize:i}=e;return i(["Elenca tutti i classificatori che hai creato."])},classifier_id:e=>{const{normalize:i}=e;return i(["ID classificatore"])},classify_inputs:e=>{const{normalize:i}=e;return i(["Input per classificare"])},classify_inputs_explain:e=>{const{normalize:i}=e;return i(["Per il testo, può essere una frase fino a 8192 token. Per le immagini, può essere un URL o un'immagine codificata in base64."])},classify_labels:e=>{const{normalize:i}=e;return i(["Etichette dei candidati"])},classify_labels_explain:e=>{const{normalize:i}=e;return i(["Gli input saranno categorizzati in queste etichette. Possono essere fino a 256 classi. Utilizza etichette semantiche per prestazioni migliori."])},compare_table:{access_control:e=>{const{normalize:i}=e;return i(["Controllo degli accessi"])},classifier_id_required:e=>{const{normalize:i}=e;return i(["ID classificatore obbligatorio"])},continuous_updates:e=>{const{normalize:i}=e;return i(["Aggiornamenti continui del modello"])},default_solution:e=>{const{normalize:i}=e;return i(["Soluzione predefinita per la classificazione generale"])},feature:e=>{const{normalize:i}=e;return i(["Caratteristica"])},few_shot:e=>{const{normalize:i}=e;return i(["Pochi colpi"])},image_multi_lingual_support:e=>{const{normalize:i}=e;return i(["Supporto multimodale e multilingue"])},labels_required_classify:e=>{const{normalize:i}=e;return i(["Etichette richieste in /classify"])},labels_required_train:e=>{const{normalize:i}=e;return i(["Etichette richieste in /train"])},max_classes:e=>{const{normalize:i}=e;return i(["Classi massime"])},max_classifiers:e=>{const{normalize:i}=e;return i(["Classificatori massimi"])},max_inputs_request:e=>{const{normalize:i}=e;return i(["Input massimi per richiesta"])},max_token_length:e=>{const{normalize:i}=e;return i(["Lunghezza massima del token per input"])},na:e=>{const{normalize:i}=e;return i(["N / A"])},no:e=>{const{normalize:i}=e;return i(["NO"])},out_of_domain_solution:e=>{const{normalize:i}=e;return i(["Per dati esterni al dominio v3/clip-v1 o dati sensibili al tempo"])},primary_use_case:e=>{const{normalize:i}=e;return i(["Caso d'uso primario"])},semantic_labels_required:e=>{const{normalize:i}=e;return i(["Etichette semantiche richieste"])},state_management:e=>{const{normalize:i}=e;return i(["Gestione dello Stato"])},stateful:e=>{const{normalize:i}=e;return i(["Con stato"])},stateless:e=>{const{normalize:i}=e;return i(["Apolide"])},token_count:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("count"))," token"])},training_data_required:e=>{const{normalize:i}=e;return i(["Dati di formazione richiesti"])},yes:e=>{const{normalize:i}=e;return i(["SÌ"])},zero_shot:e=>{const{normalize:i}=e;return i(["Colpo zero"])}},create_classifier:e=>{const{normalize:i}=e;return i(["Nuovo classificatore a pochi colpi"])},create_classifier_explain:e=>{const{normalize:i}=e;return i(["Crea un nuovo classificatore a pochi scatti e addestralo con esempi etichettati."])},description:e=>{const{normalize:i}=e;return i(["Classificazione zero-shot e few-shot per immagini e testo."])},description_long:e=>{const{normalize:i}=e;return i(["Prova il nostro API playground per vedere come funziona il nostro classificatore."])},description_long1:e=>{const{normalize:i}=e;return i(["Classificatore zero-shot e few-shot ad alte prestazioni per dati multimodali e multilingue."])},explain:e=>{const{normalize:i}=e;return i(["Classifier è un servizio API che categorizza testo e immagini utilizzando modelli di incorporamento (<code>jina-embeddings-v3</code> e <code>jina-clip-v1</code>), supportando sia la classificazione zero-shot senza dati di addestramento sia l'apprendimento few-shot con esempi minimi."])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i(["Zero-shot richiede etichette semantiche durante la classificazione e nessuna durante l'addestramento, mentre few-shot richiede etichette durante l'addestramento ma non la classificazione. Ciò significa che zero-shot è migliore per esigenze di classificazione flessibili e immediate, mentre few-shot è migliore per categorie fisse e specifiche del dominio che possono evolversi nel tempo."])},answer10:e=>{const{normalize:i}=e;return i(["Sì, puoi scegliere tra <code>jina-embeddings-v3</code> per la classificazione del testo (particolarmente adatta per il multilingua) e <code>jina-clip-v1</code> per la classificazione multimodale. Nuovi modelli come <code>jina-clip-v2</code> saranno automaticamente disponibili tramite l'API quando saranno rilasciati."])},answer2:e=>{const{normalize:i}=e;return i(["<code>num_iters</code> controlla l'intensità dell'allenamento: valori più alti rafforzano esempi importanti mentre valori più bassi riducono al minimo l'impatto di dati meno affidabili. Può essere utilizzato per implementare l'apprendimento basato sul tempo assegnando agli esempi recenti conteggi di iterazioni più elevati, rendendolo prezioso per l'evoluzione dei modelli di dati."])},answer3:e=>{const{normalize:i}=e;return i(["I classificatori pubblici possono essere utilizzati da chiunque abbia <code>classifier_id</code>, consumando la propria quota di token. Gli utenti non possono accedere ai dati di training o alla configurazione e non possono vedere le richieste di classificazione degli altri, consentendo una condivisione sicura dei classificatori."])},answer4:e=>{const{normalize:i}=e;return i(["Few-shot richiede 200-400 esempi di training per superare la classificazione zero-shot. Sebbene alla fine raggiunga una maggiore accuratezza, ha bisogno di questo periodo di riscaldamento per diventare efficace. Zero-shot fornisce prestazioni costanti immediatamente senza dati di training."])},answer5:e=>{const{normalize:i}=e;return i(["Sì, l'API supporta query multilingue utilizzando <code>jina-embeddings-v3</code> e classificazione multimodale (testo/immagine) utilizzando <code>jina-clip-v1</code>, con supporto per URL o immagini codificate in base64 nella stessa richiesta."])},answer6:e=>{const{normalize:i}=e;return i(["Zero-shot supporta 256 classi senza limiti di classificatori, mentre few-shot è limitato a 16 classi e 16 classificatori. Entrambi supportano 1.024 input per richiesta e 8.192 token per input."])},answer7:e=>{const{normalize:i}=e;return i(["La modalità Few-shot consente l'aggiornamento continuo tramite l'endpoint <code>/train</code> per adattarsi ai modelli di dati in evoluzione. È possibile aggiungere gradualmente nuovi esempi o classi quando cambia la distribuzione dei dati, senza ricostruire l'intero classificatore."])},answer8:e=>{const{normalize:i}=e;return i(["L'API utilizza l'apprendimento online one-pass: gli esempi di training aggiornano i pesi del classificatore ma non vengono archiviati in seguito. Ciò significa che non è possibile recuperare i dati di training storici, ma garantisce privacy ed efficienza delle risorse."])},answer9:e=>{const{normalize:i}=e;return i(["Inizia con zero-shot per risultati immediati e quando hai bisogno di una classificazione flessibile con etichette semantiche. Passa a few-shot quando hai 200-400 esempi, hai bisogno di una maggiore accuratezza o devi gestire dati specifici del dominio/sensibili al tempo."])},question1:e=>{const{normalize:i}=e;return i(["Qual è la differenza tra le etichette zero-shot e few-shot?"])},question10:e=>{const{normalize:i}=e;return i(["Posso usare modelli diversi per lingue/attività diverse?"])},question2:e=>{const{normalize:i}=e;return i(["A cosa serve num_iters e come dovrei utilizzarlo?"])},question3:e=>{const{normalize:i}=e;return i(["Come funziona la condivisione del classificatore pubblico?"])},question4:e=>{const{normalize:i}=e;return i(["Di quanti dati ho bisogno affinché few-shot funzioni bene?"])},question5:e=>{const{normalize:i}=e;return i(["Può gestire più lingue e sia testo che immagini?"])},question6:e=>{const{normalize:i}=e;return i(["Quali sono i limiti rigorosi che dovrei conoscere?"])},question7:e=>{const{normalize:i}=e;return i(["Come posso gestire le modifiche dei dati nel tempo?"])},question8:e=>{const{normalize:i}=e;return i(["Cosa succede ai miei dati di allenamento dopo averli inviati?"])},question9:e=>{const{normalize:i}=e;return i(["Zero-shot vs few-shot: quando usare quale?"])},title:e=>{const{normalize:i}=e;return i(["Domande frequenti relative al classificatore"])}},more:e=>{const{normalize:i}=e;return i(["Di più"])},num_iters:e=>{const{normalize:i}=e;return i(["Iterazioni di formazione"])},num_iters_explain:e=>{const{normalize:i}=e;return i(["Controlla l'intensità dell'allenamento: valori più alti migliorano la precisione negli esempi correnti ma aumentano il costo dei token. Il valore predefinito di 10 in genere funziona bene."])},read_notes:e=>{const{normalize:i}=e;return i(["Leggi le note di rilascio"])},select_classifier_or_model:e=>{const{normalize:i}=e;return i(["Seleziona un classificatore o un modello di incorporamento"])},task_classify:e=>{const{normalize:i}=e;return i(["Classificare"])},task_classify_explain:e=>{const{normalize:i}=e;return i(["Utilizzare un classificatore zero-shot o few-shot per categorizzare testo o immagini in classi definite."])},task_manage:e=>{const{normalize:i}=e;return i(["Maneggio"])},task_manage_explain:e=>{const{normalize:i}=e;return i(["Elenca o elimina i tuoi classificatori di pochi scatti."])},task_select:e=>{const{normalize:i}=e;return i(["Seleziona un'attività"])},task_train:e=>{const{normalize:i}=e;return i(["Treno"])},task_train_explain:e=>{const{normalize:i}=e;return i(["Crea o aggiorna un classificatore di pochi scatti con esempi etichettati."])},title:e=>{const{normalize:i}=e;return i(["API del classificatore"])},train_inputs:e=>{const{normalize:i}=e;return i(["Dati di formazione"])},train_inputs_explain:e=>{const{normalize:i}=e;return i(["Esempi di testo o immagini con etichette per l'addestramento. È possibile aggiornare gradualmente il classificatore con nuovi esempi ed etichette nel tempo."])},train_label:e=>{const{normalize:i}=e;return i(["Etichetta"])},what_is:e=>{const{normalize:i}=e;return i(["Che cos'è il classificatore?"])},when_to_use_what:e=>{const{normalize:i}=e;return i(["Quando usare il metodo zero-shot o few-shot?"])},when_to_use_what_explain:e=>{const{normalize:i}=e;return i(["Utilizza la classificazione zero-shot come soluzione predefinita per risultati immediati su attività di classificazione generali con un massimo di 256 classi, mentre l'apprendimento few-shot è più adatto quando si gestiscono dati specifici di dominio al di fuori delle conoscenze dei modelli di incorporamento o quando è necessario gestire dati sensibili al fattore tempo che richiedono continui aggiornamenti del modello."])}},clip_as_service:{description:e=>{const{normalize:i}=e;return i(["Incorpora immagini e frasi in vettori di lunghezza fissa con CLIP"])}},cloud:{description:e=>{const{normalize:i}=e;return i(["Piattaforma di cloud hosting per applicazioni AI multimodali"])}},contact_us_page:{agreement:e=>{const{normalize:i}=e;return i(["Inviando, confermi di accettare il trattamento dei tuoi dati personali da parte di Jina AI come descritto nell'"])},anything_else:e=>{const{normalize:i}=e;return i(["Raccontaci di più sulla tua idea"])},cc_by_nc:e=>{const{normalize:i}=e;return i(["Richiedi l'uso commerciale dei modelli CC BY-NC"])},cc_by_nc_description:e=>{const{normalize:i}=e;return i(["I nostri ultimi modelli sono in genere con licenza CC BY-NC. Per uso commerciale, accedi tramite la nostra API, Azure Marketplace o AWS SageMaker. Seleziona questa casella per l'uso in locale al di fuori di questi canali."])},company:e=>{const{normalize:i}=e;return i(["Organizzazione"])},company_size:e=>{const{normalize:i}=e;return i(["Dimensioni dell'organizzazione"])},company_website:e=>{const{normalize:i}=e;return i(["Sito web dell'organizzazione"])},company_website_placeholder:e=>{const{normalize:i}=e;return i(["URL della home page o del profilo LinkedIn della tua azienda"])},country:e=>{const{normalize:i}=e;return i(["Paese"])},department:e=>{const{normalize:i}=e;return i(["Dipartimento"])},description:e=>{const{normalize:i}=e;return i(["Fai crescere la tua attività con Jina AI."])},faq:e=>{const{normalize:i}=e;return i(["FAQ"])},field_required:e=>{const{normalize:i}=e;return i(["Il campo è obbligatiorio"])},get_api_key:e=>{const{normalize:i}=e;return i(["Come posso ottenere la mia chiave API?"])},impact_snapshots:e=>{const{normalize:i}=e;return i(["Istantanee di impatto"])},invalid_date_format:e=>{const{normalize:i}=e;return i(["Formato data non valido. Utilizza il formato GG-MM-AAAA."])},invalid_email:e=>{const{normalize:i}=e;return i(["L'email non è valida"])},invalid_number:e=>{const{normalize:i}=e;return i(["Numero non valido. Si prega di inserire di nuovo"])},invalid_url:e=>{const{normalize:i}=e;return i(["L'URL non è valido"])},name:e=>{const{normalize:i}=e;return i(["Nome"])},nc_check:e=>{const{normalize:i}=e;return i(["Ho bisogno di una licenza commerciale?"])},other_questions:e=>{const{normalize:i}=e;return i(["Altre domande"])},preferred_models:e=>{const{normalize:i}=e;return i(["A quali modelli sei interessato?"])},preferred_products:e=>{const{normalize:i}=e;return i(["A quali prodotti sei interessato?"])},priority:e=>{const{normalize:i}=e;return i(["Supporto prioritario per gli utenti paganti"])},private_statement:e=>{const{normalize:i}=e;return i(["Informativa sulla Privacy"])},rate_limit:e=>{const{normalize:i}=e;return i(["Qual è il limite di tariffa?"])},role:e=>{const{normalize:i}=e;return i(["Ruolo"])},self_check:e=>{const{normalize:i}=e;return i(["Autocontrollo"])},shortcut:e=>{const{normalize:i}=e;return i(["Scorciatoia"])},submit:e=>{const{normalize:i}=e;return i(["Invia"])},submit_failed:e=>{const{normalize:i}=e;return i(["Invio non riuscito. Per favore riprova più tardi."])},submit_success:e=>{const{normalize:i}=e;return i(["Grazie per la vostra presentazione. Vi risponderemo al più presto."])},subtitle:e=>{const{normalize:i}=e;return i(["Jina AI, leader nell'IA multimodale, eccelle nell'ottimizzazione dei modelli, nel servizio dei modelli, nella messa a punto rapida e nel servizio rapido. Sfruttando le tecnologie native del cloud come Kubernetes e le architetture serverless, forniamo soluzioni robuste, scalabili e pronte per la produzione. Con esperienza in modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione audio, ricerca neurale e arte generativa, forniamo strategie innovative e a prova di futuro per elevare la tua attività."])},subtitle1:e=>{const{normalize:i}=e;return i(["Jina AI, leader nell'intelligenza artificiale multimodale, eccelle nell'ottimizzazione dell'incorporamento, dell'incorporamento, dell'ottimizzazione e del servizio tempestivo. Sfruttando tecnologie native del cloud come Kubernetes e architetture serverless, forniamo soluzioni robuste, scalabili e pronte per la produzione. Con esperienza in modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione dell'audio, ricerca neurale e intelligenza artificiale generativa, forniamo strategie innovative e a prova di futuro per far crescere il tuo business."])},subtitle2:e=>{const{normalize:i}=e;return i(["Esplora Jina AI, l'avanguardia dell'IA multimodale. Eccelliamo nell'incorporamento e nell'immediatezza delle tecnologie, utilizzando soluzioni native del cloud come Kubernetes per sistemi robusti e scalabili. Specializzati in modelli linguistici di grandi dimensioni e nell'elaborazione dei media, offriamo strategie aziendali innovative e pronte per il futuro con la nostra competenza avanzata in materia di intelligenza artificiale."])},title:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},trusted_by:e=>{const{normalize:i}=e;return i(["Scelto da"])},turn_on_volume:e=>{const{normalize:i}=e;return i(["Alza il volume"])},work_email:e=>{const{normalize:i}=e;return i(["E-mail di lavoro"])}},copy:e=>{const{normalize:i}=e;return i(["copia"])},copy_to_clipboard_success:e=>{const{normalize:i}=e;return i(["Copiato negli appunti"])},dalle_flow:{description:e=>{const{normalize:i}=e;return i(["Un flusso di lavoro human-in-the-Loop per la creazione di immagini HD dal testo"])}},"dev-gpt":{description:e=>{const{normalize:i}=e;return i(["Il tuo team di sviluppo virtuale"])}},disco_art:{description:e=>{const{normalize:i}=e;return i(["Crea avvincenti opere d'arte Disco Diffusion in una riga di codice"])}},doc_array:{description:e=>{const{normalize:i}=e;return i(["La struttura dei dati per i dati multimodali"])}},download:e=>{const{normalize:i}=e;return i(["Scarica l'attestazione SOC 2 Tipo 1"])},embedding:{"11B tokens":e=>{const{normalize:i}=e;return i(["11 miliardi"])},"11B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Simile alla lettura di tutti gli articoli in lingua inglese su Wikipedia."])},"11B tokens_targetUser":e=>{const{normalize:i}=e;return i(["Distribuzione della produzione"])},"1B tokens":e=>{const{normalize:i}=e;return i(["1 miliardo"])},"1B tokens_intuition1":e=>{const{normalize:i}=e;return i([`Più o meno come leggere l'opera completa di Shakespeare e l'intera serie "Harry Potter".`])},"1B tokens_targetUser":e=>{const{normalize:i}=e;return i(["Sviluppo del prototipo"])},"1M tokens":e=>{const{normalize:i}=e;return i(["1 milione"])},"1M tokens_intuition1":e=>{const{normalize:i}=e;return i([`Equivale a leggere l'intero testo de "Lo Hobbit" e "Il Grande Gatsby".`])},"1M tokens_targetUser":e=>{const{normalize:i}=e;return i(["Esperimento di giocattoli"])},"1M_free":e=>{const{normalize:i}=e;return i(["1 milione di token gratuiti"])},"1M_free_description":e=>{const{normalize:i}=e;return i(["Goditi la tua nuova chiave API con token gratuiti, senza bisogno di carta di credito."])},"2_5B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 2,5 miliardi"])},"2_5B tokens_intuition1":e=>{const{normalize:i}=e;return i([`Paragonabile a trascrivere 1.000 volte ogni parola pronunciata nella trilogia del film "Il Signore degli Anelli".
`])},"3p_integration":e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Con <b>",n(o("_numPartners")),"</b> servizi di terze parti"])},"3p_integration_desc":e=>{const{normalize:i}=e;return i(["Integra la nostra base di ricerca con i tuoi servizi esistenti. I nostri partner hanno creato connettori per la nostra API, semplificando l'utilizzo dei nostri modelli nelle tue applicazioni."])},"500M tokens":e=>{const{normalize:i}=e;return i(["500 milioni di gettoni"])},"500M tokens_intuition1":e=>{const{normalize:i}=e;return i(['È simile a guardare ogni episodio di "I Simpson" dalla stagione 1 alla stagione 30.'])},"59B tokens":e=>{const{normalize:i}=e;return i(["59 miliardi di gettoni"])},"59B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Uguale a tutti i tweet pubblicati in tutto il mondo in un periodo di due giorni."])},"5_5B tokens":e=>{const{normalize:i}=e;return i(["Gettoni da 5,5 miliardi"])},"5_5B tokens_intuition1":e=>{const{normalize:i}=e;return i(["Equivale a leggere l'intero testo dell'Enciclopedia Britannica."])},Free1M:e=>{const{normalize:i}=e;return i(["Gettoni da 1 milione"])},add_pair:e=>{const{normalize:i}=e;return i(["Nuovo"])},add_time_explain:e=>{const{normalize:i}=e;return i(["Data in cui questo modello è stato aggiunto alla Search Foundation."])},api_integration_short:e=>{const{normalize:i}=e;return i(["La nostra API di incorporamento è integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps."])},api_integrations:e=>{const{normalize:i}=e;return i(["Integrazioni API"])},api_key_update_message:e=>{const{normalize:i}=e;return i(["Sostituendo la tua vecchia chiave API, la nuova chiave apparirà nell'interfaccia utente ogni volta che visiti jina.ai. Le ricariche future si applicheranno a questa nuova chiave. La tua vecchia chiave rimane valida, quindi se hai intenzione di usarla di nuovo, conservala in modo sicuro."])},api_key_update_title:e=>{const{normalize:i}=e;return i(["Sostituzione della chiave API"])},auto_recharge:e=>{const{normalize:i}=e;return i(["Ricarica automatica quando i gettoni sono bassi"])},auto_recharge_confirm_message:e=>{const{normalize:i}=e;return i(["Vuoi davvero disattivare la ricarica automatica? Questo impedirà le ricariche automatiche quando il tuo saldo token è basso."])},auto_recharge_confirm_title:e=>{const{normalize:i}=e;return i(["Disattiva la ricarica automatica"])},auto_recharge_description:e=>{const{normalize:i}=e;return i(["Consigliato per un servizio ininterrotto in produzione. Quando il saldo del tuo token è inferiore alla soglia impostata, ricaricheremo automaticamente la tua carta di credito per lo stesso importo dell'ultima ricarica. Se hai acquistato più pacchetti nell'ultima ricarica, ricaricheremo solo un pacchetto."])},auto_recharge_enable:e=>{const{normalize:i}=e;return i(["Hai abilitato la ricarica automatica sui token bassi"])},auto_recharge_enable_message:e=>{const{normalize:i}=e;return i(["Per abilitare la ricarica automatica, acquista un pacchetto con la ricarica automatica impostata su vero."])},auto_recharge_enable_title:e=>{const{normalize:i}=e;return i(["Abilita la ricarica automatica"])},auto_request:e=>{const{normalize:i}=e;return i(["Anteprima automatica"])},auto_request_tooltip:e=>{const{normalize:i}=e;return i(['Visualizza in anteprima automaticamente la risposta API quando cambi il modello, utilizzando centinaia di token dalla tua chiave API. Disattiva per inviare manualmente una richiesta facendo clic su "Ricevi risposta".'])},autostart:e=>{const{normalize:i}=e;return i(["L'incorporamento verrà avviato automaticamente dopo un breve ritardo"])},base64_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti vengono restituiti come stringa con codifica base64. Più efficiente per la trasmissione."])},batch_job:e=>{const{normalize:i}=e;return i(["Lavoro in batch"])},batch_upload_hint:e=>{const{normalize:i}=e;return i(["Utilizzeremo la chiave API e il modello seguente per elaborare i documenti."])},"bge-base-en-v1_5_description":e=>{const{normalize:i}=e;return i(["Un robusto modello inglese che bilancia prestazioni ed efficienza per un utilizzo versatile."])},"bge-base-en_description":e=>{const{normalize:i}=e;return i(["Un modello inglese equilibrato progettato per prestazioni solide e affidabili."])},"bge-base-zh-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello cinese a tutto tondo che bilancia capacità ed efficienza."])},"bge-base-zh_description":e=>{const{normalize:i}=e;return i(["Un modello cinese versatile che unisce efficienza e prestazioni robuste."])},"bge-large-en-v1_5_description":e=>{const{normalize:i}=e;return i(["Un potente modello inglese che offre incastri di alto livello con una qualità eccezionale."])},"bge-large-en_description":e=>{const{normalize:i}=e;return i(["Un modello inglese dalle prestazioni elevate, realizzato per incorporamenti di alta qualità."])},"bge-large-zh-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello cinese ad alta capacità che offre incorporamenti superiori e dettagliati."])},"bge-large-zh_description":e=>{const{normalize:i}=e;return i(["Un modello cinese ad alte prestazioni ottimizzato per incorporamenti di alto livello."])},"bge-m3_description":e=>{const{normalize:i}=e;return i(["Un modello multilingue versatile che offre funzionalità estese e incorporamenti di alta qualità."])},"bge-small-en-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello inglese semplificato che offre incorporamenti efficienti e di alta qualità."])},"bge-small-en_description":e=>{const{normalize:i}=e;return i(["Un modello inglese efficiente per incorporamenti snelli e accurati."])},"bge-small-zh-v1_5_description":e=>{const{normalize:i}=e;return i(["Un modello cinese compatto che fornisce incorporamenti agili e precisi."])},"bge-small-zh_description":e=>{const{normalize:i}=e;return i(["Un modello cinese agile per incorporamenti efficienti e precisi."])},binary_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti sono impacchettati come int8. Molto più efficiente per l'archiviazione, la ricerca e la trasmissione."])},bulk:e=>{const{normalize:i}=e;return i(["Incorporamento batch"])},bulk_embedding_failed:e=>{const{normalize:i}=e;return i(["Impossibile creare il processo di incorporamento batch"])},buy_more_quota:e=>{const{normalize:i}=e;return i(["Ricarica questa chiave API con più token"])},buy_poster:e=>{const{normalize:i}=e;return i(["Acquista una copia cartacea"])},cancel_button:e=>{const{normalize:i}=e;return i(["Annulla"])},click_upload_btn_above:e=>{const{normalize:i}=e;return i(["Fai clic sul pulsante di caricamento in alto per iniziare."])},code:e=>{const{normalize:i}=e;return i(["codice"])},colbert_dimensions_explain:e=>{const{normalize:i}=e;return i(["La dimensione dell'incorporamento per token."])},compatible:e=>{const{normalize:i}=e;return i(["Modalità compatibile"])},compatible_explain:e=>{const{normalize:i}=e;return i(["Segue lo stesso formato di richiesta dei nostri modelli di incorporamento del testo. Ciò consente di passare da un modello all'altro senza modificare la richiesta. Nota, l'input di immagini non è supportato in questa modalità."])},cosine_similarity:e=>{const{normalize:i}=e;return i(["Somiglianza del coseno"])},debugging:e=>{const{normalize:i}=e;return i(["Test"])},delete_pair:e=>{const{normalize:i}=e;return i(["Eliminare"])},description:e=>{const{normalize:i,linked:n,type:o}=e;return i([n("landing_page.embedding_desc1",void 0,o)])},dimensions:e=>{const{normalize:i}=e;return i(["Dimensioni di uscita"])},dimensions_error:e=>{const{normalize:i}=e;return i(["La dimensione deve essere compresa tra 1 e 1024."])},dimensions_explain:e=>{const{normalize:i}=e;return i(["Le dimensioni ridotte rendono più facile lo stoccaggio e il recupero, con un impatto minimo sulle prestazioni grazie alla tecnologia MRL."])},dimensions_warning:e=>{const{normalize:i}=e;return i(["Per un'esecuzione efficace delle attività, consigliamo di mantenere la dimensione superiore a 32."])},document:e=>{const{normalize:i}=e;return i(["Documento"])},download:e=>{const{normalize:i}=e;return i(["Scaricamento"])},edit_text1_text:e=>{const{normalize:i}=e;return i(["Modifica il testo a sinistra"])},edit_text2_text:e=>{const{normalize:i}=e;return i(["Modifica il testo corretto"])},embedding_done:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_Count"))," frasi incorporate correttamente."])},embedding_none_description:e=>{const{normalize:i}=e;return i(["Non utilizzare alcun modello di incorporamento"])},example_inputs:e=>{const{normalize:i}=e;return i(["Ingressi di esempio"])},faq:e=>{const{normalize:i,linked:n,type:o}=e;return i([n("contattaci_pagina.faq",void 0,o)])},faqs_v2:{answer0:e=>{const{normalize:i}=e;return i(["Per informazioni dettagliate sui nostri processi di formazione, fonti di dati e valutazioni, fare riferimento al nostro rapporto tecnico disponibile su arXiv."])},answer1:e=>{const{normalize:i}=e;return i(["Ogni utente può effettuare fino a 100 richieste al secondo, pari a 204.800 frasi di input al secondo."])},answer17:e=>{const{normalize:i}=e;return i(["Attualmente stiamo sviluppando incorporamenti multimodali che elaboreranno congiuntamente testo, immagini e audio. Gli aggiornamenti saranno annunciati presto!"])},answer18:e=>{const{normalize:i}=e;return i(["Per domande sulla messa a punto dei nostri modelli con dati specifici, contattaci per discutere le tue esigenze. Siamo aperti a esplorare come i nostri modelli possono essere adattati per soddisfare le vostre esigenze."])},answer19:e=>{const{normalize:i}=e;return i(["Sì, i nostri servizi sono disponibili sul marketplace AWS e siamo in fase di espansione sui marketplace Azure e GCP. Se hai esigenze particolari, contattaci all'ufficio vendite AT jina.ai."])},answer3:e=>{const{normalize:i}=e;return i(["I nostri modelli supportano inglese, tedesco, spagnolo, cinese e vari linguaggi di programmazione. Per maggiori dettagli si rimanda alla nostra pubblicazione sui modelli bilingui."])},answer4:e=>{const{normalize:i}=e;return i([`I nostri modelli consentono una lunghezza di input fino a 8192 token, che è significativamente più alta rispetto alla maggior parte degli altri modelli. Un token può variare da un singolo carattere, come "a", a un'intera parola, come "mela". Il numero totale di caratteri che possono essere immessi dipende dalla lunghezza e dalla complessità delle parole utilizzate. Questa funzionalità di input estesa consente ai nostri modelli jina-embeddings-v2 di eseguire analisi del testo più complete e ottenere una maggiore precisione nella comprensione del contesto, in particolare per dati testuali estesi.`])},answer5:e=>{const{normalize:i}=e;return i(["Una singola chiamata API può elaborare fino a 2048 frasi o testi, facilitando un'analisi approfondita del testo in un'unica richiesta."])},answer6:e=>{const{normalize:i}=e;return i(["Puoi utilizzare <code>url</code> o <code>bytes</code> nel campo <code>input</code> della richiesta API. Per <code>url</code>, fornisci l'URL dell'immagine che desideri elaborare. Per <code>bytes</code>, codifica l'immagine in formato base64 e includila nella richiesta. Il modello restituirà gli incorporamenti dell'immagine nella risposta."])},answer7:e=>{const{normalize:i}=e;return i(["Secondo la classifica MTEB, il nostro modello Base compete strettamente con il text-embedding-ada-002 di OpenAI, mostrando in media prestazioni comparabili. Inoltre, il nostro modello Base eccelle in diversi compiti, tra cui classificazione, classificazione di coppie, riclassificazione e riepilogo, superando il modello di OpenAI."])},answer8:e=>{const{normalize:i}=e;return i(["La transizione è semplificata, poiché il nostro endpoint API, https://api.jina.ai/v1/embeddings, corrisponde agli schemi JSON di input e output del modello text-embeddings-ada-002 di OpenAI. Questa compatibilità garantisce che gli utenti possano facilmente sostituire il modello OpenAI con il nostro quando utilizzano l'endpoint OpenAI."])},answer9:e=>{const{normalize:i}=e;return i([`I token vengono calcolati in base alla lunghezza del testo e alla dimensione dell'immagine. Per il testo nella richiesta, i token vengono conteggiati in modo standard. Per l'immagine nella richiesta, vengono eseguiti i seguenti passaggi:
1. Dimensione tessera: ogni immagine è divisa in tessere di dimensione 224x224 pixel.
	2. Copertura: viene calcolato il numero di tessere necessarie per coprire completamente l'immagine in ingresso. Anche se le dimensioni dell'immagine non sono perfettamente divisibili per 224, conteremo le tessere parziali come tessere intere.
	3. Tessere totali: il numero totale di tessere che coprono l'immagine determina il costo. Ad esempio, se un'immagine è 500x500 pixel, sarebbe coperta da riquadri 3x3, risultando in 9 riquadri.
	4. Calcolo del costo: Ogni tessera contribuisce al costo finale dell'elaborazione dell'immagine. Il costo per tessera è di 1000 gettoni.

Esempio:
Per un'immagine con dimensioni 500x500 pixel:

	• L'immagine è divisa in riquadri da 224x224 pixel.
	• Il numero totale di tessere richieste è 3 (orizzontale) x 3 (verticale) = 9 tessere.
	• Il costo sarà 9*1000 = 9000 token`])},question0:e=>{const{normalize:i}=e;return i(["Come sono stati addestrati i modelli jina-embeddings-v2?"])},question1:e=>{const{normalize:i}=e;return i(["Quante richieste API posso effettuare al secondo?"])},question17:e=>{const{normalize:i}=e;return i(["Fornite modelli per incorporare immagini o audio?"])},question18:e=>{const{normalize:i}=e;return i(["I modelli Jina Embedding possono essere ottimizzati con dati privati ​​o aziendali?"])},question19:e=>{const{normalize:i}=e;return i(["I tuoi endpoint possono essere ospitati privatamente su AWS, Azure o GCP?"])},question3:e=>{const{normalize:i}=e;return i(["Quali lingue supportano i vostri modelli?"])},question4:e=>{const{normalize:i}=e;return i(["Qual è la lunghezza massima per una singola frase inserita?"])},question5:e=>{const{normalize:i}=e;return i(["Qual è il numero massimo di frasi che posso includere in una singola richiesta?"])},question6:e=>{const{normalize:i}=e;return i(["Come posso inviare immagini al modello jina-clip-v1?"])},question7:e=>{const{normalize:i}=e;return i(["Come si confrontano i modelli Jina Embeddings con il modello text-embedding-ada-002 di OpenAI?"])},question8:e=>{const{normalize:i}=e;return i(["Quanto è fluida la transizione da text-embedding-ada-002 di OpenAI alla tua soluzione?"])},question9:e=>{const{normalize:i}=e;return i(["Come vengono calcolati i token quando si utilizza jina-clip-v1?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative agli incorporamenti"])}},feature_8k1:e=>{const{normalize:i}=e;return i(["8192 lunghezza del token"])},feature_8k_description1:e=>{const{normalize:i}=e;return i(["Pioniere del primo modello di incorporamento open source con una lunghezza di 8192 token, che consente la rappresentazione di un intero capitolo in un unico vettore."])},feature_cheap:e=>{const{normalize:i}=e;return i(["20 volte più economico"])},feature_cheap_v1:e=>{const{normalize:i}=e;return i(["5 volte più economico"])},feature_cheap_v1_description1:e=>{const{normalize:i}=e;return i(["Inizia con prove gratuite e goditi una struttura dei prezzi semplice. Ottieni l'accesso a potenti incorporamenti a solo il 20% del costo di OpenAI."])},feature_multilingual:e=>{const{normalize:i}=e;return i(["Offre modelli bilingui tedesco-inglese, cinese-inglese, tra gli altri, ideali per applicazioni multilingue."])},feature_on_premises:e=>{const{normalize:i}=e;return i(["La privacy prima di tutto"])},feature_on_premises_description1:e=>{const{normalize:i}=e;return i(["Distribuisci senza problemi i nostri modelli di incorporamento direttamente nel tuo Virtual Private Cloud (VPC). Attualmente supportato su AWS Sagemaker, con prossime integrazioni per Microsoft Azure e Google Cloud Platform. Per implementazioni Kubernetes personalizzate, contatta il nostro team di vendita per assistenza specializzata."])},feature_on_premises_description2:e=>{const{normalize:i}=e;return i(["Distribuisci i modelli Jina Embeddings in AWS Sagemaker e presto anche in Microsoft Azure e nei servizi cloud di Google, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_on_premises_description3:e=>{const{normalize:i}=e;return i(["Distribuisci i modelli Jina Embeddings in AWS Sagemaker e Microsoft Azure, e presto anche nei servizi Google Cloud, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_on_premises_description4:e=>{const{normalize:i}=e;return i(["Distribuisci modelli Jina Embedding e Reranker in locale utilizzando AWS SageMaker, Microsoft Azure o Google Cloud Services, garantendo che i tuoi dati rimangano saldamente sotto il tuo controllo."])},feature_solid:e=>{const{normalize:i}=e;return i(["Migliore della classe"])},feature_solid_description1:e=>{const{normalize:i}=e;return i(["Sviluppato dalla nostra ricerca accademica all'avanguardia e rigorosamente testato rispetto ai modelli SOTA per garantire prestazioni senza pari."])},feature_top_perform1:e=>{const{normalize:i}=e;return i(["Integrazione senza problemi"])},feature_top_perform_description1:e=>{const{normalize:i}=e;return i(["Pienamente compatibile con l'API di OpenAI. Si integra facilmente con oltre 10 database vettoriali e sistemi RAG per un'esperienza utente fluida."])},file_required:e=>{const{normalize:i}=e;return i(["Il file è obbligatorio"])},file_size_exceed:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Supera la dimensione massima del file ",n(o("_size"))])},file_type_not_supported:e=>{const{normalize:i}=e;return i(["Tipo di file non supportato"])},fill_example:e=>{const{normalize:i}=e;return i(["Compila un esempio"])},float_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti vengono restituiti come un elenco di numeri a virgola mobile. Il più comune e facile da usare."])},free:e=>{const{normalize:i}=e;return i(["Gratuito"])},generate_api_key_error:e=>{const{normalize:i}=e;return i(["La generazione della chiave API non è riuscita."])},generating_visualization:e=>{const{normalize:i}=e;return i(["Generazione della visualizzazione..."])},get_new_key_button:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave"])},get_new_key_button_explain:e=>{const{normalize:i}=e;return i(["La scelta di una nuova chiave comporterà la perdita della cronologia di utilizzo associata alla vecchia chiave."])},get_new_key_survey:e=>{const{normalize:i}=e;return i(["Compila il sondaggio, aiutaci a comprendere il tuo utilizzo e ottieni una nuova chiave API gratuitamente!"])},includes:e=>{const{normalize:i}=e;return i(["Gettoni validi per:"])},index_and_search:e=>{const{normalize:i}=e;return i(["Indicizza e cerca"])},index_and_search1:e=>{const{normalize:i}=e;return i(["Indicizza e cerca"])},input:e=>{const{normalize:i}=e;return i(["Richiesta"])},input_api_key_error1:e=>{const{normalize:i}=e;return i(["La tua chiave API non è valida!"])},input_length:e=>{const{normalize:i}=e;return i(["Lunghezza immessa"])},input_type:e=>{const{normalize:i}=e;return i(["Incorpora come query o documento"])},input_type_explain:e=>{const{normalize:i}=e;return i(["Alcuni modelli di incorporamento dispongono di strategie di incorporamento dedicate per query e documenti. La stessa stringa può essere incorporata come query o documento a seconda del suo ruolo nell'applicazione."])},integrate:e=>{const{normalize:i}=e;return i(["Integrare"])},"jina-clip-v1_description":e=>{const{normalize:i}=e;return i(["I nostri ultimi incorporamenti multimodali per il recupero di testo e immagini."])},"jina-colbert-v1-en_description":e=>{const{normalize:i}=e;return i(["ColBERT migliorato con token di lunghezza 8K per attività di incorporamento e riclassificazione"])},"jina-colbert-v2_description":e=>{const{normalize:i}=e;return i(["Il miglior ColBERT multilingue con le massime prestazioni nell'incorporamento e nella riclassificazione"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:i}=e;return i(["Ottimizzato per la ricerca di codici e stringhe di documenti"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue tedesco-inglese con prestazioni SOTA"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:i}=e;return i(["Alla pari con text-embedding-ada002 di OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue spagnolo-inglese con prestazioni SOTA"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue cinese-inglese con prestazioni SOTA"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:i}=e;return i(["Ottimizzato per bassa latenza e ingombro di memoria"])},"jina-embeddings-v3_description":e=>{const{normalize:i}=e;return i(["Modello di incorporamento multilingue di frontiera con prestazioni SOTA"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:i}=e;return i(["Il nostro primo modello di riclassificazione che massimizza la ricerca e la pertinenza RAG"])},"jina-reranker-v1-tiny-en_description":e=>{const{normalize:i}=e;return i(["Il modello di riclassificazione più veloce, più adatto per classificare in modo affidabile un gran numero di documenti"])},"jina-reranker-v1-turbo-en_description":e=>{const{normalize:i}=e;return i(["La migliore combinazione di elevata velocità di inferenza e punteggi di pertinenza accurati"])},"jina-reranker-v2-base-multilingual_description":e=>{const{normalize:i}=e;return i(["L'ultimo e migliore modello di riclassificazione con supporto multilingue, chiamata di funzioni e ricerca di codice."])},key:e=>{const{normalize:i}=e;return i(["Chiave API"])},key_enter_placeholder:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API"])},key_enter_placeholder_to_topup:e=>{const{normalize:i}=e;return i(["Inserisci la chiave API che desideri ricaricare"])},key_to_top_up:e=>{const{normalize:i}=e;return i(['Hai una chiave API diversa da ricaricare? Incollala qui sopra e clicca su "Salva".'])},key_warn:e=>{const{normalize:i}=e;return i(["Assicurati di conservare la chiave API in un luogo sicuro. Altrimenti dovrai generare una nuova chiave"])},key_warn_v2:e=>{const{normalize:i}=e;return i(["Questa è la tua chiave unica. Conservala in modo sicuro!"])},language_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Questo modello supporta al meglio la lingua ",n(o("_lingual")),"."])},last_7_days:e=>{const{normalize:i}=e;return i(["Utilizzo negli ultimi 7 giorni"])},late_chunking:e=>{const{normalize:i}=e;return i(["Chunking tardivo"])},late_chunking_explain:e=>{const{normalize:i}=e;return i(["Applicare la tecnica del late chunking per sfruttare le capacità del modello in contesti lunghi per generare incorporamenti di chunk contestuali."])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di più"])},learn_poster:e=>{const{normalize:i}=e;return i(["Scopri come l'abbiamo realizzato"])},learning1:e=>{const{normalize:i}=e;return i(["Conoscere gli incorporamenti"])},learning1_description:e=>{const{normalize:i}=e;return i(["Da dove cominciare con gli incorporamenti? Ti abbiamo coperto. Scopri di più sugli incorporamenti con la nostra guida completa."])},length:e=>{const{normalize:i}=e;return i(["Lunghezza del token"])},manage_billing:e=>{const{normalize:i}=e;return i(["Gestisci la fattura"])},manage_billing_tip:e=>{const{normalize:i}=e;return i(["Gestisci i tuoi dati di fatturazione, ricevi fatture e imposta la ricarica automatica."])},manage_quota1:e=>{const{normalize:i}=e;return i(["Chiave API e fatturazione"])},max_file_size:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Dimensione massima consentita: ",n(o("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:i}=e;return i(["Massimizza questo pannello con Maiusc+1"])},mistake_contact:e=>{const{normalize:i}=e;return i(["Se ritieni che si tratti di un errore, contattaci."])},model_required:e=>{const{normalize:i}=e;return i(["Il modello è obbligatorio"])},more_than_two2:e=>{const{normalize:i}=e;return i(["Inserisci più di due documenti, ovvero più di due righe."])},multi_embedding:e=>{const{normalize:i}=e;return i(["Multivettore"])},multi_embedding_explain:e=>{const{normalize:i}=e;return i(["Questo modello restituirà un pacchetto di incorporamenti contestualizzati per un dato input. Ogni token nell'input viene mappato su un vettore nell'output."])},multilingual:e=>{const{normalize:i}=e;return i(["Supporto multilingue"])},multimodal:e=>{const{normalize:i}=e;return i(["Multimodale"])},multimodal_explain:e=>{const{normalize:i}=e;return i(["Questo modello può codificare input sia di testo che di immagini, rendendolo ideale per attività di ricerca multimodale."])},new:e=>{const{normalize:i}=e;return i(["Nuovo modello"])},no_data1:e=>{const{normalize:i}=e;return i(["Aggiungi un paio di frasi per calcolare la somiglianza"])},none:e=>{const{normalize:i}=e;return i(["Nessuno"])},normalized:e=>{const{normalize:i}=e;return i(["Normalizzazione L2"])},normalized_explain:e=>{const{normalize:i}=e;return i(["Scala l'incorporamento in modo che la sua norma euclidea (L2) diventi 1, preservando la direzione. Utile quando downstream coinvolge prodotto scalare, classificazione, visualizzazione."])},oncsp:e=>{const{normalize:i}=e;return i(["Su CSP"])},onprem:e=>{const{normalize:i}=e;return i(["In sede"])},open_tensorboard:e=>{const{normalize:i}=e;return i(["Apri visualizzatore"])},opensource:e=>{const{normalize:i}=e;return i(["sistema operativo"])},opensource_explain:e=>{const{normalize:i}=e;return i(["Questo modello è open source e disponibile su Hugging Face. Fare clic su questo pulsante per visualizzare il modello su Hugging Face."])},original_documents:e=>{const{normalize:i}=e;return i(["Frasi da incorporare"])},original_documents_hint:e=>{const{normalize:i}=e;return i(["Inserisci qui le tue frasi. Ogni nuova riga sarà considerata una frase/documento separato."])},output:e=>{const{normalize:i}=e;return i(["Risposta"])},output_dim:e=>{const{normalize:i}=e;return i(["Dimensioni"])},output_dim_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["La dimensione di output di un vettore di incorporamento da questo modello è ",n(o("_outputDim")),"."])},output_dimension:e=>{const{normalize:i}=e;return i(["Dimensioni di uscita"])},pairwise_test:e=>{const{normalize:i}=e;return i(["A coppie"])},per_k:e=>{const{normalize:i}=e;return i(["/ Gettoni da 1K"])},per_m:e=>{const{normalize:i}=e;return i(["/1 milione di gettoni"])},please_fill_docs_first:e=>{const{normalize:i}=e;return i(["Per favore inserisci alcune frasi qui sotto prima della ricerca."])},please_select_model:e=>{const{normalize:i}=e;return i(["Seleziona un modello di incorporamento o un modello di riclassificazione"])},poster:e=>{const{normalize:i}=e;return i(["Poster L'evoluzione degli incorporamenti"])},poster_description:e=>{const{normalize:i}=e;return i(["Scopri il poster ideale per il tuo spazio, con infografiche accattivanti o immagini mozzafiato che tracciano l'evoluzione dei modelli di incorporamento del testo dal 1950."])},pricing:e=>{const{normalize:i}=e;return i(["Prezzi dell'API"])},pricing_desc:e=>{const{normalize:i}=e;return i(["I nostri prezzi API sono strutturati in base alla quantità di token inviati nelle richieste. Per l'API Reader, è la quantità di token nelle risposte. Questo modello di prezzo è applicabile a tutti i prodotti nella base di ricerca di Jina AI: API di incorporamento, riclassificazione, lettore e ottimizzazione automatica. Con la stessa chiave API hai accesso a tutti i servizi API."])},protectData1:e=>{const{normalize:i}=e;return i(["I dati e i documenti della richiesta non vengono utilizzati per i modelli di training."])},protectData2:e=>{const{normalize:i}=e;return i(["Crittografia dei dati in transito (TLS 1.2+) e a riposo (AES-GCM 256)."])},protectData3:e=>{const{normalize:i}=e;return i(["Conforme a SOC 2 e GDPR."])},protect_data:e=>{const{normalize:i}=e;return i(["Proteggi i tuoi dati"])},public_cloud_integration:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Con <b>",n(o("_numPartners")),"</b> fornitori di servizi cloud"])},public_cloud_integration_desc:e=>{const{normalize:i}=e;return i(["La tua azienda utilizza AWS o Azure? Quindi distribuisci direttamente i nostri modelli di base di ricerca su queste piattaforme nella tua azienda, in modo che i tuoi dati rimangano sicuri e conformi."])},query:e=>{const{normalize:i}=e;return i(["Domanda"])},raise_issue:e=>{const{normalize:i}=e;return i(["Sollevare la questione"])},rank_none_description:e=>{const{normalize:i}=e;return i(["Non utilizzare alcun modello di riclassificazione"])},read_api_docs:e=>{const{normalize:i}=e;return i(["Specifiche API"])},read_release_note:e=>{const{normalize:i}=e;return i(["Leggi la nota di rilascio"])},recharge_threshold:e=>{const{normalize:i}=e;return i(["Soglia di ricarica"])},refresh:e=>{const{normalize:i}=e;return i(["ricaricare"])},refresh_key_tooltip1:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave API gratuitamente"])},refresh_token_count1:e=>{const{normalize:i}=e;return i(["Aggiorna per ottenere i token disponibili della chiave API corrente"])},regenerate:e=>{const{normalize:i}=e;return i(["Rigenerare"])},remaining:e=>{const{normalize:i}=e;return i(["Gettoni disponibili"])},remaining_left:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Hai <b>",n(o("_leftTokens")),"</b> token rimasti nella chiave API di seguito."])},request_number:e=>{const{normalize:i}=e;return i(["Tempi di richiesta"])},request_path:e=>{const{normalize:i}=e;return i(["Richiedi endpoint"])},results_as_final_result:e=>{const{normalize:i}=e;return i(["#docs come risultato finale"])},results_fed_to_reranker:e=>{const{normalize:i}=e;return i(["#documenti alimentati a Reranker"])},retry:e=>{const{normalize:i}=e;return i(["Riprova"])},return_base64:e=>{const{normalize:i}=e;return i(["Base64 (come stringa)"])},return_binary:e=>{const{normalize:i}=e;return i(["Binario (compresso come int8)"])},return_float:e=>{const{normalize:i}=e;return i(["Predefinito (come float)"])},return_format:e=>{const{normalize:i}=e;return i(["Formato degli incorporamenti"])},return_format_explain:e=>{const{normalize:i}=e;return i(["Oltre al float, puoi chiedergli di restituire come binario per un recupero vettoriale più veloce o come codifica base64 per una trasmissione più veloce."])},return_format_title:e=>{const{normalize:i}=e;return i(["Tipo di dati restituito"])},return_ubinary:e=>{const{normalize:i}=e;return i(["Binario (compresso come uint8)"])},right_api_key_to_charge:e=>{const{normalize:i}=e;return i(["Inserisci la chiave API corretta per ricaricare"])},running:e=>{const{normalize:i}=e;return i(["Attivo"])},score:e=>{const{normalize:i}=e;return i(["Punto"])},search:e=>{const{normalize:i}=e;return i(["Ricerca"])},search_hint:e=>{const{normalize:i}=e;return i(["Digita per cercare all'interno delle frasi elencate di seguito"])},select_classify_model:e=>{const{normalize:i}=e;return i(["Seleziona classificatore"])},select_embedding_model:e=>{const{normalize:i}=e;return i(["Seleziona incorporamenti"])},select_rerank_model:e=>{const{normalize:i}=e;return i(["Seleziona riclassificazione"])},show_api_key:e=>{const{normalize:i}=e;return i(["Mostra chiave API"])},size:e=>{const{normalize:i}=e;return i(["Parametri"])},size_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Il numero di parametri nel modello è ",n(o("_size")),", tieni presente che questa non è la dimensione del file del modello."])},sleeping:e=>{const{normalize:i}=e;return i(["Inattivo"])},start_batch:e=>{const{normalize:i}=e;return i(["Avvia l'incorporamento batch"])},start_embedding:e=>{const{normalize:i}=e;return i(["Indice"])},status_explain:e=>{const{normalize:i}=e;return i(["La nostra architettura serverless potrebbe scaricare alcuni modelli durante i periodi di scarso utilizzo. Per i modelli attivi, le risposte sono immediate. I modelli inattivi richiedono alcuni secondi per essere caricati alla richiesta iniziale. Dopo l'attivazione, le richieste successive vengono elaborate più rapidamente."])},task_type:e=>{const{normalize:i}=e;return i(["Attività a valle"])},task_type_classification:e=>{const{normalize:i}=e;return i(["Classificazione"])},task_type_classification_explain:e=>{const{normalize:i}=e;return i(["Classificazione del testo."])},task_type_explain:e=>{const{normalize:i}=e;return i(["Seleziona l'attività downstream per cui verranno utilizzati gli embedding. Il modello restituirà gli embedding ottimizzati per tale attività."])},task_type_none_explain:e=>{const{normalize:i}=e;return i(["Non verrà utilizzato alcun adattatore. Verrà restituito un embedding generico, utile per il debug o l'hacking."])},task_type_retrieval_passage:e=>{const{normalize:i}=e;return i(["Passaggio di recupero"])},task_type_retrieval_passage_explain:e=>{const{normalize:i}=e;return i(["Incorporamento di documenti in un'attività di recupero di query-documenti."])},task_type_retrieval_query:e=>{const{normalize:i}=e;return i(["Query di recupero"])},task_type_retrieval_query_explain:e=>{const{normalize:i}=e;return i(["Incorporamento di query in un'attività di recupero di documenti di query."])},task_type_separation:e=>{const{normalize:i}=e;return i(["Separazione"])},task_type_separation_explain:e=>{const{normalize:i}=e;return i(["Raggruppamento di documenti, visualizzazione del corpus."])},"task_type_text-matching":e=>{const{normalize:i}=e;return i(["Corrispondenza del testo"])},"task_type_text-matching_explain":e=>{const{normalize:i}=e;return i(["Somiglianza semantica del testo, recupero simbolico generale, raccomandazione, ricerca di elementi simili, deduplicazione."])},tax_may_apply:e=>{const{normalize:i}=e;return i(["A seconda della tua posizione, l'addebito potrebbe essere effettuato in USD, EUR o altre valute. Potrebbero essere applicate tasse."])},text1:e=>{const{normalize:i}=e;return i(["Sinistra"])},text2:e=>{const{normalize:i}=e;return i(["Giusto"])},title:e=>{const{normalize:i}=e;return i(["Incorporamento dell'API"])},token_example:e=>{const{normalize:i}=e;return i(['Un tweet è di circa 20 token, un articolo di notizie è di circa 1000 token e il romanzo di Charles Dickens "A Tale of Two Cities" ha oltre un milione di token.'])},token_length_explain:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["La lunghezza massima della sequenza del token di input è ",n(o("_tokenLength"))," per questo modello."])},tokens:e=>{const{normalize:i}=e;return i(["Gettoni"])},tools:e=>{const{normalize:i}=e;return i(["Utensili"])},top_up_button:e=>{const{normalize:i}=e;return i(["Ricarica la vecchia chiave"])},top_up_button_explain:e=>{const{normalize:i}=e;return i(["L'integrazione di questa chiave API offre una soluzione più professionale, eliminando la necessità di frequenti modifiche della chiave. I dati di utilizzo vengono conservati e accessibili in qualsiasi momento."])},top_up_warning_message1:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Alla chiave API corrente sono rimasti token ",n(o("_remainedTokens"))," e verrà sostituita da una nuova chiave con token ",n(o("_freeTokens")),". Puoi continuare a utilizzare o ricaricare la vecchia chiave se l'hai conservata in modo sicuro. Come vuoi procedere?"])},top_up_warning_title:e=>{const{normalize:i}=e;return i(["Sostituisci la vecchia chiave API"])},total_documents:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Avanzamento incorporamento: ",n(o("_Processed")),"/",n(o("_Count"))," frasi."])},tuning:e=>{const{normalize:i}=e;return i(["Sintonizzare"])},turnstile_error:e=>{const{normalize:i}=e;return i(["Non possiamo generare una chiave API perché non siamo riusciti a verificare se sei un essere umano."])},turnstile_unsupported:e=>{const{normalize:i}=e;return i(["Non possiamo generare una chiave API perché il tuo browser non è supportato."])},ubinary_description:e=>{const{normalize:i}=e;return i(["Gli incorporamenti sono impacchettati come uint8. Molto più efficiente per l'archiviazione, la ricerca e la trasmissione."])},upload:e=>{const{normalize:i}=e;return i(["Caricamento"])},upload_file:e=>{const{normalize:i}=e;return i(["Fare clic qui per caricare un file"])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},usage_amount:e=>{const{normalize:i}=e;return i(["Gettoni"])},usage_history:e=>{const{normalize:i}=e;return i(["Utilizzo negli ultimi 7 giorni"])},usage_history_explain:e=>{const{normalize:i}=e;return i(["I dati non sono in tempo reale e possono subire ritardi di alcuni minuti."])},usage_reason:e=>{const{normalize:i}=e;return i(["Descrizione"])},usage_reason_consume:e=>{const{normalize:i}=e;return i(["Usato"])},usage_reason_purchase:e=>{const{normalize:i}=e;return i(["Acquistato"])},usage_reason_trial:e=>{const{normalize:i}=e;return i(["Prova"])},usage_rerank:e=>{const{normalize:i}=e;return i(["Utilizzo"])},usage_time:e=>{const{normalize:i}=e;return i(["Appuntamento"])},v3_description:e=>{const{normalize:i}=e;return i(["<code>jina-embeddings-v3</code> è un modello di incorporamento di testo multilingue di frontiera con 570M di parametri e 8192 token-length, che supera gli ultimi incorporamenti proprietari di OpenAI e Cohere su MTEB. Leggi il nostro post sul blog e il documento di ricerca qui sotto."])},v3_title:e=>{const{normalize:i}=e;return i(["v3: Incorporamenti multilingue di Frontier"])},vector_database_integration1:e=>{const{normalize:i}=e;return i(["Integrazioni"])},vector_database_integration2:e=>{const{normalize:i}=e;return i(["La nostra API di incorporamento è integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps. Per iniziare, copia e incolla la tua chiave API in una qualsiasi delle integrazioni elencate per un avvio rapido e senza intoppi."])},vector_database_integration3:e=>{const{normalize:i}=e;return i(["La nostra API Embedding & Reranker è integrata nativamente con vari database rinomati, archivi di vettori, framework RAG e LLMOps. Per iniziare, copia e incolla la tua chiave API in una qualsiasi delle integrazioni elencate per un avvio rapido e senza intoppi."])},vector_database_integration_description:e=>{const{normalize:i}=e;return i(["Integra in modo semplice e senza soluzione di continuità l'API Jina Embeddings con qualsiasi database vettoriale, framework di orchestrazione LLM e applicazioni RAG riportati di seguito. I nostri tutorial ti mostreranno come."])},view_details:e=>{const{normalize:i}=e;return i(["Visualizza dettagli"])},visualization_example:e=>{const{normalize:i}=e;return i(["Mappare tutte le frasi di questa sezione in uno spazio vettoriale 3D"])},visualization_example_you_can:e=>{const{normalize:i}=e;return i(["Utilizza la nostra API qui sotto, puoi farlo anche tu!"])},visualize:e=>{const{normalize:i}=e;return i(["Visualizzare"])},visualize_done:e=>{const{normalize:i}=e;return i(["La visualizzazione è terminata, ora puoi fare clic sul pulsante in alto per aprire il visualizzatore."])},wait_for_processing:e=>{const{normalize:i}=e;return i(["La tua richiesta sta per essere eseguita."])},wait_stripe:e=>{const{normalize:i}=e;return i(["Apertura pagamento Stripe, attendere prego"])},what_are_embedding:e=>{const{normalize:i}=e;return i(["Cosa sono gli incorporamenti?"])},what_are_embedding_answer:e=>{const{normalize:i}=e;return i([`Immagina di insegnare a un computer a cogliere le sfumature dei significati di parole e frasi. I metodi tradizionali, che si basavano su sistemi rigidi e basati su regole, non erano all’altezza perché il linguaggio è troppo complesso e fluido. Inserisci gli incorporamenti di testo: una soluzione potente che traduce il testo in un linguaggio di numeri, in particolare in vettori in uno spazio ad alta dimensione.

Considera le frasi "tempo soleggiato" e "cielo sereno". Per noi dipingono un quadro simile. Attraverso la lente degli incorporamenti, queste frasi vengono trasformate in vettori numerici che risiedono vicini gli uni agli altri in questo spazio multidimensionale, catturandone la parentela semantica. Questa vicinanza nello spazio vettoriale non riguarda solo la somiglianza di parole o frasi; si tratta di comprendere il contesto, il sentimento e persino le sottili sfumature di significato.

Perché è importante questa svolta? Per cominciare, colma il divario tra la ricchezza del linguaggio umano e l’efficienza computazionale degli algoritmi. Gli algoritmi eccellono nell’elaborazione dei numeri, non nell’interpretazione dei testi. Convertendo il testo in vettori, gli incorporamenti consentono a questi algoritmi di "comprendere" ed elaborare il linguaggio in un modo che prima era fuori portata.

Le applicazioni pratiche sono vaste e variegate. Che si tratti di consigliare contenuti che siano in sintonia con i tuoi interessi, di potenziare un'intelligenza artificiale conversazionale che sembri sorprendentemente umana o addirittura di rilevare modelli sottili in grandi volumi di testo, gli incorporamenti sono la chiave. Consentono alle macchine di eseguire attività come l'analisi del sentiment, la traduzione linguistica e molto altro, con una comprensione del linguaggio sempre più sfumata e raffinata.`])},what_is_a_token:e=>{const{normalize:i}=e;return i([`Un token nell'elaborazione del testo è un'unità, spesso una parola. Ad esempio, "Jina AI è fantastica!" diventa cinque gettoni, compresa la punteggiatura.`])},why_do_you_need:e=>{const{normalize:i}=e;return i(["Scegliere gli incorporamenti giusti"])},why_do_you_need_after:e=>{const{normalize:i}=e;return i(["Sfruttando reti neurali profonde e LLM, i nostri modelli di incorporamento rappresentano dati multimodali in un formato semplificato, migliorando la comprensione automatica, l'archiviazione efficiente e consentendo applicazioni IA avanzate. Questi incorporamenti svolgono un ruolo cruciale nella comprensione dei dati, nel miglioramento del coinvolgimento degli utenti, nel superamento delle barriere linguistiche e nell'ottimizzazione dei processi di sviluppo."])},why_do_you_need_before:e=>{const{normalize:i}=e;return i(["I nostri modelli di incorporamento sono progettati per coprire diverse applicazioni di ricerca e GenAI."])},why_need_1_description:e=>{const{normalize:i}=e;return i(["Il nostro modello di incorporamento del core, basato su JinaBERT, è costruito per un ampio spettro di applicazioni. Eccelle nella comprensione di testi dettagliati, rendendolo ideale per la ricerca semantica, la classificazione dei contenuti e l'analisi linguistica complessa. La sua versatilità non ha eguali e supporta la creazione di strumenti avanzati di analisi del sentiment, riepilogo del testo e sistemi di consigli personalizzati."])},why_need_1_title:e=>{const{normalize:i}=e;return i(["Incorporamenti per uso generale"])},why_need_2_description:e=>{const{normalize:i}=e;return i(["I nostri modelli bilingui facilitano la comunicazione tra le lingue, migliorando le piattaforme multilingue, l'assistenza clienti globale e la scoperta di contenuti multilinguistici. Progettati per padroneggiare le traduzioni tedesco-inglese e cinese-inglese, questi modelli semplificano le interazioni e favoriscono la comprensione tra diversi gruppi linguistici."])},why_need_2_title:e=>{const{normalize:i}=e;return i(["Incorporamenti bilingue"])},why_need_3_description:e=>{const{normalize:i}=e;return i(["Progettato su misura per gli sviluppatori, il nostro modello di incorporamento del codice ottimizza le attività di codifica come il riepilogo, la generazione di codice e le revisioni automatiche. Aumenta la produttività offrendo approfondimenti sulle strutture del codice e suggerendo miglioramenti, rendendolo essenziale per lo sviluppo di plug-in IDE avanzati, documentazione automatica e strumenti di debug all'avanguardia."])},why_need_3_title:e=>{const{normalize:i}=e;return i(["Incorporamenti di codice"])},why_need_4_description:e=>{const{normalize:i}=e;return i(["Jina CLIP è il nostro ultimo modello di incorporamento multimodale per immagini e testo. Un grande miglioramento rispetto a OpenAI CLIP è che questo singolo modello può essere utilizzato per il recupero di testo-testo, nonché per attività di recupero di testo-immagine, immagine-testo e immagine-immagine! Quindi un modello, due modalità, quattro direzioni di ricerca!"])},why_need_4_title:e=>{const{normalize:i}=e;return i(["Incorporamenti multimodali"])},write_email_here:e=>{const{normalize:i}=e;return i(["Inserisci l'e-mail in cui desideri ricevere il collegamento per il download al termine."])},you_can_leave:e=>{const{normalize:i}=e;return i(["Puoi lasciare questa pagina e al termine ti invieremo il collegamento per il download."])}},embeddings:{description:e=>{const{normalize:i}=e;return i(["Incorporamenti multilingue multimodali di livello mondiale."])}},faq:{answer1:e=>{const{normalize:i}=e;return i(["Jina AI è specializzata in tecnologie AI multimodali, tra cui ottimizzazione dei modelli, servizio dei modelli, messa a punto rapida e servizio rapido. Sfruttiamo strumenti avanzati come Kubernetes e architetture serverless per creare soluzioni robuste, scalabili e pronte per la produzione."])},answer10:e=>{const{normalize:i}=e;return i(["Forniamo diverse opzioni di licenza in base alla natura del progetto e alle esigenze del cliente. I termini dettagliati possono essere discussi con il nostro team di vendita."])},answer11:e=>{const{normalize:i}=e;return i(["Forniamo servizi a livello globale, con la nostra sede centrale a Berlino, in Europa, e uffici aggiuntivi a Pechino e Shenzhen."])},answer12:e=>{const{normalize:i}=e;return i(["Sì, offriamo assistenza in loco, in particolare per i clienti che si trovano vicino ai nostri uffici di Berlino, Pechino e Shenzhen. Per altre località, ci sforziamo di fornire il miglior supporto remoto possibile e, se necessario, possiamo organizzare il supporto in loco."])},answer2:e=>{const{normalize:i}=e;return i(["La nostra esperienza copre un ampio spettro, comprendendo modelli linguistici di grandi dimensioni, testo, immagini, video, comprensione audio, ricerca neurale e arte generativa."])},answer3:e=>{const{normalize:i}=e;return i(["Sì, le nostre soluzioni sono progettate per essere scalabili e pronte per la produzione. Costruiamo le nostre soluzioni utilizzando tecnologie cloud-native che consentono una scalabilità efficiente e prestazioni affidabili negli ambienti di produzione."])},answer4:e=>{const{normalize:i}=e;return i(["I nostri servizi sono versatili e adattabili, il che li rende adatti a un'ampia gamma di settori, tra cui e-commerce, tecnologia legale, marketing digitale, giochi, assistenza sanitaria, finanza e molti altri."])},answer5:e=>{const{normalize:i}=e;return i(["Puoi metterti in contatto con il nostro team di vendita tramite il modulo di contatto in questa pagina. Ci piacerebbe discutere i requisiti del tuo progetto e come le nostre soluzioni possono aiutare la tua azienda."])},answer6:e=>{const{normalize:i}=e;return i(["Forniamo supporto continuo per garantire il buon funzionamento delle nostre soluzioni. Ciò include la risoluzione dei problemi, aggiornamenti regolari e miglioramenti in base al tuo feedback e alle tue esigenze."])},answer7:e=>{const{normalize:i}=e;return i(["La durata del progetto varia a seconda della complessità e della portata del progetto. Dopo aver compreso le vostre esigenze, possiamo fornire una stima più accurata."])},answer8:e=>{const{normalize:i}=e;return i(["La sicurezza dei dati è la nostra massima priorità. Aderiamo a rigide politiche e normative sulla protezione dei dati per garantire che i tuoi dati siano sicuri e riservati."])},answer9:e=>{const{normalize:i}=e;return i(["Il prezzo dipende dalla complessità e dai requisiti del progetto. Offriamo sia modelli di prezzi basati su progetto che di trattenuta. Si prega di contattare il nostro team di vendita per ulteriori informazioni."])},question1:e=>{const{normalize:i}=e;return i(["In cosa è specializzata Jina AI?"])},question10:e=>{const{normalize:i}=e;return i(["Quali sono i termini di licenza per le vostre soluzioni?"])},question11:e=>{const{normalize:i}=e;return i(["Qual è la tua area di servizio?"])},question12:e=>{const{normalize:i}=e;return i(["Offrite supporto in loco?"])},question2:e=>{const{normalize:i}=e;return i(["Con quali tipi di IA funziona Jina AI?"])},question3:e=>{const{normalize:i}=e;return i(["Le tue soluzioni sono scalabili e pronte per la produzione?"])},question4:e=>{const{normalize:i}=e;return i(["Quali settori possono trarre vantaggio dalle soluzioni di Jina AI?"])},question5:e=>{const{normalize:i}=e;return i(["Come si avvia un progetto con Jina AI?"])},question6:e=>{const{normalize:i}=e;return i(["Quale supporto fornite dopo aver implementato una soluzione?"])},question7:e=>{const{normalize:i}=e;return i(["Qual è la durata tipica di un progetto?"])},question8:e=>{const{normalize:i}=e;return i(["In che modo Jina AI protegge i miei dati?"])},question9:e=>{const{normalize:i}=e;return i(["Qual è la struttura dei prezzi per i vostri servizi?"])}},faq_button:e=>{const{normalize:i}=e;return i(["FAQ"])},finetuner:{description:e=>{const{normalize:i}=e;return i(["Ottimizza gli incorporamenti sui dati specifici del dominio per una migliore qualità della ricerca"])},intro:e=>{const{normalize:i}=e;return i(["La tua azienda. I tuoi dati. Il tuo modello"])}},finetuner_plus:{description:e=>{const{normalize:i}=e;return i(["Potenzia la tua azienda con soluzioni di fine tuning on-premise"])}},finetuning:{api_key:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API."])},back:e=>{const{normalize:i}=e;return i(["Indietro"])},base_model_selected:e=>{const{normalize:i}=e;return i(["Modello base selezionato"])},click_start:e=>{const{normalize:i}=e;return i(["Accetta i termini e inizia la messa a punto."])},confirm_title:e=>{const{normalize:i}=e;return i(["Conferma il lavoro di regolazione fine"])},confirm_your_email:e=>{const{normalize:i}=e;return i(["Inserisci nuovamente il tuo indirizzo email per confermare il lavoro di perfezionamento. Gli aggiornamenti e il collegamento per il download verranno inviati a questa email."])},consent0:e=>{const{normalize:i}=e;return i(["Accetto che i dati sintetici per la messa a punto del modello vengano generati in base alle mie istruzioni."])},consent1:e=>{const{normalize:i}=e;return i(["Riconosco che il modello finale e i dati sintetici saranno accessibili pubblicamente su Hugging Face."])},consent2:e=>{const{normalize:i}=e;return i(["Comprendo che questa funzionalità è in versione beta e Jina AI non offre garanzie. Il prezzo e l'UX potrebbero cambiare."])},continue:e=>{const{normalize:i}=e;return i(["Continua"])},cost_1m_token:e=>{const{normalize:i}=e;return i(["Ogni lavoro di perfezionamento consuma 1 milione di token. Assicurati di avere gettoni sufficienti o ricarica il tuo saldo. Puoi anche generare una nuova chiave API. Ogni chiave API viene fornita con 1 milione di token gratuiti."])},doc_explain:e=>{const{normalize:i}=e;return i(["Descrivi come dovrebbe apparire un documento abbinato."])},domain_explain:e=>{const{normalize:i}=e;return i(["Fornire una descrizione dettagliata di come verranno utilizzati gli incorporamenti ottimizzati. Ciò è essenziale per generare dati sintetici di alta qualità che miglioreranno le prestazioni dei tuoi incorporamenti."])},domain_explain2:e=>{const{normalize:i}=e;return i(["Esistono tre modi per specificare le tue esigenze: un'istruzione generale, un URL o una descrizione del documento di query. Scegline uno."])},domain_hint:e=>{const{normalize:i}=e;return i(["Descrivi il dominio per il quale desideri ottimizzare."])},email_not_match:e=>{const{normalize:i}=e;return i(["Gli indirizzi email non combaciano. Si prega di verificare."])},failed_job:e=>{const{normalize:i}=e;return i(["La richiesta di perfezionamento non è riuscita. Vedi il motivo qui sotto."])},find_on_huggingface:e=>{const{normalize:i}=e;return i(["Trova risultati su Abbracciare il viso"])},general_instruction:e=>{const{normalize:i}=e;return i(["Oppure istruzioni generali"])},general_instruction_caption:e=>{const{normalize:i}=e;return i(["Fornire una descrizione dettagliata di come verranno utilizzati gli incorporamenti ottimizzati."])},general_instruction_explain:e=>{const{normalize:i}=e;return i(['Descrivi il tuo dominio in testo in formato libero. Puoi immaginarlo come un "prompt" come in ChatGPT.'])},how_it_works:e=>{const{normalize:i}=e;return i(["Scopri il processo di perfezionamento."])},job_acknowledged:e=>{const{normalize:i}=e;return i(["Il tuo lavoro di perfezionamento è stato messo in coda. Riceverai un'e-mail all'inizio del lavoro. Il completamento dell'intero processo richiede spesso 20 minuti."])},new_key:e=>{const{normalize:i}=e;return i(["Ottieni una nuova chiave"])},not_enough_token:e=>{const{normalize:i}=e;return i(["Token insufficienti in questa chiave API. Ricarica il tuo saldo o utilizza una chiave API diversa."])},placeholder:e=>{const{normalize:i}=e;return i(["Sinistri di assicurazione auto"])},preview:e=>{const{normalize:i}=e;return i(["Anteprima"])},query_doc:e=>{const{normalize:i}=e;return i(["Descrizione del documento di query"])},query_doc_caption:e=>{const{normalize:i}=e;return i(["Descrivi come appare la query e come appare il documento corrispondente nel tuo dominio."])},query_explain:e=>{const{normalize:i}=e;return i(["Descrivi come appare una query."])},reset:e=>{const{normalize:i}=e;return i(["Ricominciare"])},select_base_model:e=>{const{normalize:i}=e;return i(["Scegli un modello di incorporamento di base per la messa a punto."])},select_base_model_explain:e=>{const{normalize:i}=e;return i(["Selezionare un modello base come punto di partenza per la messa a punto. In genere, base-en è una buona scelta, ma per attività in altre lingue, considera l'utilizzo di un modello bilingue."])},start_tuning:e=>{const{normalize:i}=e;return i(["Inizia la messa a punto"])},url:e=>{const{normalize:i}=e;return i(["Oppure l'URL della pagina web"])},url_caption:e=>{const{normalize:i}=e;return i(["Fare riferimento al contenuto di un URL per la messa a punto."])},url_explain:e=>{const{normalize:i}=e;return i(["URL pubblico di una pagina Web che contiene il contenuto che desideri ottimizzare."])},use_url:e=>{const{normalize:i}=e;return i(["Utilizza invece l'URL. Attivarlo significa che ci baseremo sul contenuto della pagina di quell'URL per generare dati sintetici per la messa a punto."])},wait_for_processing:e=>{const{normalize:i}=e;return i(["Si prega di attendere l'elaborazione della tua richiesta..."])},which_domain:e=>{const{normalize:i}=e;return i(["Dominio di messa a punto"])},write_email_explain:e=>{const{normalize:i}=e;return i(["La messa a punto richiede tempo. Comunicheremo via e-mail l'inizio, l'avanzamento, il completamento e tutti i problemi del lavoro di ottimizzazione, insieme ai dettagli sul modello ottimizzato e sul set di dati di addestramento."])}},footer:{address_beijing:e=>{const{normalize:i}=e;return i(["Pechino, Cina"])},address_berlin:e=>{const{normalize:i}=e;return i(["Berlino, Germania (sede centrale)"])},address_shenzhen:e=>{const{normalize:i}=e;return i(["Shenzen, Cina"])},all_rights_reserved:e=>{const{normalize:i}=e;return i(["Tutti i diritti riservati."])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},developers:e=>{const{normalize:i}=e;return i(["Sviluppatori"])},docs:e=>{const{normalize:i}=e;return i(["Documenti"])},enterprise:e=>{const{normalize:i}=e;return i(["Impresa"])},get_api_key:e=>{const{normalize:i}=e;return i(["Ottieni la chiave API Jina AI"])},offices:e=>{const{normalize:i}=e;return i(["Uffici"])},power_users:e=>{const{normalize:i}=e;return i(["Utenti esperti"])},privacy:e=>{const{normalize:i}=e;return i(["Privacy"])},privacy_policy:e=>{const{normalize:i}=e;return i(["politica sulla riservatezza"])},privacy_settings:e=>{const{normalize:i}=e;return i(["Gestisci i cookie"])},security:e=>{const{normalize:i}=e;return i(["Sicurezza"])},sefo:e=>{const{normalize:i}=e;return i(["Fondazione di ricerca"])},soc2:e=>{const{normalize:i}=e;return i(["Siamo conformi allo standard SOC 2 Tipo 1 dell'American Institute of Certified Public Accountants (AICPA)."])},status:e=>{const{normalize:i}=e;return i(["Stato dell'API"])},status_short:e=>{const{normalize:i}=e;return i(["Stato"])},tc:e=>{const{normalize:i}=e;return i(["Termini & Condizioni"])},tc1:e=>{const{normalize:i}=e;return i(["Termini"])}},get_new_key:e=>{const{normalize:i}=e;return i(["Ottieni la tua chiave API"])},github:{stars:e=>{const{normalize:i}=e;return i(["Stelle"])}},header:{about_us:e=>{const{normalize:i}=e;return i(["Chi siamo"])},company:e=>{const{normalize:i}=e;return i(["Azienda"])},contact_us:e=>{const{normalize:i}=e;return i(["Contatta le vendite"])},developers_others:e=>{const{normalize:i}=e;return i(["Altri strumenti per sviluppatori"])},enterprise_others:e=>{const{normalize:i}=e;return i(["Altri strumenti aziendali"])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_developers_description:e=>{const{normalize:i}=e;return i(["Sperimenta uno stack IA multimodale open source completo progettato per gli sviluppatori."])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le Imprese"])},for_enterprise_description:e=>{const{normalize:i}=e;return i(["Scopri strategie AI multimodali scalabili su misura per soddisfare le esigenze aziendali."])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},for_power_users_description:e=>{const{normalize:i}=e;return i(["Utilizza i nostri strumenti multimodali ottimizzati per migliorare la tua produttività."])},internship1:e=>{const{normalize:i}=e;return i(["Programma di stagista"])},jobs:e=>{const{normalize:i}=e;return i(["Unisciti a noi"])},join_discord:e=>{const{normalize:i}=e;return i(["Unisciti alla nostra comunità Discord"])},logos:e=>{const{normalize:i}=e;return i(["Scarica il logo"])},maximize:e=>{const{normalize:i}=e;return i(["⇧1"])},maximize_btn:e=>{const{normalize:i}=e;return i(["Massimizzare"])},news:e=>{const{normalize:i}=e;return i(["Notizia"])},open_day:e=>{const{normalize:i}=e;return i(["Giornata aperta"])},open_in_full:e=>{const{normalize:i}=e;return i(["Mostra tutti i prodotti aziendali in una nuova finestra"])},power_users_others:e=>{const{normalize:i}=e;return i(["Più strumenti per utenti esperti"])},products:e=>{const{normalize:i}=e;return i(["Prodotti"])}},hub:{description:e=>{const{normalize:i}=e;return i(["Condividi e scopri elementi costitutivi per applicazioni IA multimodali"])}},huggingface:{sentence_similarity:e=>{const{normalize:i}=e;return i(["Incorporamento di frasi"])},updated_about:e=>{const{normalize:i}=e;return i(["Aggiornato circa"])}},impact_snapshots:{project1:e=>{const{normalize:i}=e;return i(["Ricerca ad alta precisione abilitata all'interno dei dati mesh 3D utilizzando le informazioni sulla nuvola di punti."])},project10:e=>{const{normalize:i}=e;return i(["Sfruttata la computer vision per migliorare l'accessibilità digitale dei siti web governativi."])},project11:e=>{const{normalize:i}=e;return i(["LLM perfezionato per una società di consulenza per ottimizzare l'analisi dei dati finanziari."])},project12:e=>{const{normalize:i}=e;return i(["Strategie di marketing avanzate perfezionando i modelli di testo in immagine per il trasferimento dello stile."])},project2:e=>{const{normalize:i}=e;return i(["Progettato un motore di ricerca basato sui contenuti per cortometraggi di animazione."])},project3:e=>{const{normalize:i}=e;return i(["Miglioramento dei tassi di conversione dell'e-commerce perfezionando i modelli di incorporamento."])},project4:e=>{const{normalize:i}=e;return i(["Messa a punto rapida eseguita per aumentare l'efficienza per una società di consulenza aziendale."])},project5:e=>{const{normalize:i}=e;return i(["Precursore della comprensione delle scene di gioco e dell'annotazione automatica per un'azienda leader nel settore dei giochi."])},project6:e=>{const{normalize:i}=e;return i(["Implementata l'espansione dell'input in tempo reale per un'azienda di chatbot, migliorando l'esperienza dell'utente."])},project7:e=>{const{normalize:i}=e;return i(["Tecnologia legale rivoluzionata consentendo una ricerca efficiente all'interno di lunghi documenti legali."])},project8:e=>{const{normalize:i}=e;return i(["Supporto di un servizio di arte generativa ad alto rendimento per operazioni su larga scala."])},project9:e=>{const{normalize:i}=e;return i(["Eseguito il process mining e la modellazione utilizzando modelli linguistici avanzati."])}},inference:{description:e=>{const{normalize:i}=e;return i(["Modelli multimodali all'avanguardia disponibili per l'inferenza"])}},integrations:{embedding:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},reranker:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},which_to_go:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Quale integrare con ",n(o("_vendor")),"?"])}},internship_faq:{answer1:e=>{const{normalize:i}=e;return i(["Laurea, master e dottorato di ricerca. studenti provenienti da tutto il mondo, con interesse in campi come la ricerca, l'ingegneria, il marketing e le vendite, sono incoraggiati ad applicare. Accogliamo con favore anche stage non tecnici in marketing, vendite, assistenza esecutiva e altro ancora. Cerchiamo persone appassionate pronte a fare da pionieri nell'IA multimodale con noi."])},answer10:e=>{const{normalize:i}=e;return i(["Sì, il nostro programma di tirocinio offre una remunerazione competitiva."])},answer11:e=>{const{normalize:i}=e;return i(["In qualità di stagista Jina AI, acquisirai esperienza pratica lavorando su progetti stimolanti, imparerai da esperti del settore, entrerai a far parte di una vivace comunità e avrai l'opportunità di dare un contributo reale al nostro lavoro pionieristico nell'IA multimodale."])},answer2:e=>{const{normalize:i}=e;return i(["Gli stage devono essere svolti in loco presso uno dei nostri uffici, che si trovano a Berlino, Pechino e Shenzhen."])},answer3:e=>{const{normalize:i}=e;return i(["Sì, Jina AI offre un'assistenza ragionevole nel processo di visto per i richiedenti selezionati."])},answer4:e=>{const{normalize:i}=e;return i(["Sì, Jina AI fornisce una ragionevole copertura del costo della vita per gli stagisti durante il periodo di tirocinio."])},answer5:e=>{const{normalize:i}=e;return i(["Sì, è possibile lavorare alla tua tesi di Master durante il tirocinio presso Jina AI, tipicamente applicabile agli studenti delle università tedesche. Tuttavia, è necessario disporre di una comunicazione preventiva e del consenso del supervisore della propria università. Tieni presente che non aiutiamo gli studenti a trovare consulenti."])},answer6:e=>{const{normalize:i}=e;return i(["Il processo di candidatura include l'invio del modulo di candidatura, un curriculum, una lettera di presentazione che esprima il tuo interesse e la tua motivazione e qualsiasi link professionale pertinente come GitHub o LinkedIn. Valutiamo i candidati in base alle loro prestazioni durante il colloquio e alle loro prestazioni nella loro università."])},answer7:e=>{const{normalize:i}=e;return i(["Sì, gli stagisti di successo possono ricevere una lettera di raccomandazione alla fine del loro tirocinio, firmata dal nostro CEO."])},answer8:e=>{const{normalize:i}=e;return i(["La durata dello stage varia in base al ruolo e al progetto. Tuttavia, in genere varia da tre a sei mesi."])},answer9:e=>{const{normalize:i}=e;return i(["Sì, accogliamo candidature di ogni estrazione accademica. Apprezziamo la tua passione e il tuo impegno per imparare tanto quanto l'esperienza precedente."])},question1:e=>{const{normalize:i}=e;return i(["Chi può fare domanda per il programma di tirocinio Jina AI?"])},question10:e=>{const{normalize:i}=e;return i(["È uno stage retribuito?"])},question11:e=>{const{normalize:i}=e;return i(["Quali opportunità avrò come stagista Jina AI?"])},question2:e=>{const{normalize:i}=e;return i(["Dove si svolgerà il tirocinio?"])},question3:e=>{const{normalize:i}=e;return i(["Jina AI assiste con le procedure di visto?"])},question4:e=>{const{normalize:i}=e;return i(["Jina AI fornisce indennità o benefici per gli stagisti?"])},question5:e=>{const{normalize:i}=e;return i(["Posso lavorare alla mia tesi di Master durante lo stage presso Jina AI?"])},question6:e=>{const{normalize:i}=e;return i(["Cosa prevede il processo di candidatura?"])},question7:e=>{const{normalize:i}=e;return i(["Jina AI fornisce una lettera di raccomandazione dopo lo stage?"])},question8:e=>{const{normalize:i}=e;return i(["Qual è la durata del tirocinio?"])},question9:e=>{const{normalize:i}=e;return i(["Posso candidarmi se non ho precedenti esperienze in IA?"])}},internship_page:{about_internship_program:e=>{const{normalize:i}=e;return i(["Informazioni sul programma di tirocinio"])},about_internship_program_desc1:e=>{const{normalize:i}=e;return i(["Siamo entusiasti di offrire questa opportunità unica a persone di talento per entrare a far parte del nostro team dinamico e contribuire a progetti innovativi nel campo dell'Intelligenza Artificiale. Questo stage è progettato per fornirti preziosa esperienza pratica, tutoraggio ed esposizione a tecnologie all'avanguardia che stanno plasmando il futuro dell'IA."])},about_internship_program_desc2:e=>{const{normalize:i}=e;return i(["In Jina AI, comprendiamo l'importanza di coltivare e sfruttare i giovani talenti. Riconosciamo che i tirocinanti portano sul tavolo nuove prospettive, entusiasmo e creatività, rinvigorendo il nostro team con nuove idee e approcci. Fornendo stage, miriamo a favorire la crescita dei futuri leader nel settore dell'intelligenza artificiale, offrendo loro un'esperienza del mondo reale in un ambiente stimolante e stimolante."])},alumni:e=>{const{normalize:i}=e;return i(["ALUNNI"])},alumni_network:e=>{const{normalize:i}=e;return i(["La nostra fiorente rete di ex studenti"])},application:e=>{const{normalize:i}=e;return i(["Applicazione"])},application_desc:e=>{const{normalize:i}=e;return i(["Intraprendi un viaggio di trasformazione con Jina AI. Il nostro programma di tirocinio completo invita tutte le menti appassionate che aspirano a plasmare il futuro dell'intelligenza artificiale. Unisciti a noi per fare esperienza nel mondo reale, lavorare su progetti stimolanti e collaborare con alcune delle menti più brillanti del settore dell'IA."])},apply:e=>{const{normalize:i}=e;return i(["Applica ora"])},autumn:e=>{const{normalize:i}=e;return i(["Autunno"])},description:e=>{const{normalize:i}=e;return i(["Bando mondiale per studenti: stage in ricerca, ingegneria, marketing, vendite e altro ancora."])},dev_rel_intern:e=>{const{normalize:i}=e;return i(["Stagista nelle relazioni con gli sviluppatori"])},enthusiastic:e=>{const{normalize:i}=e;return i(["ENTUSIASTA"])},explore_stories_from_our_interns:e=>{const{normalize:i}=e;return i(["Esplora le storie dei nostri stagisti"])},explore_stories_from_our_interns1:e=>{const{normalize:i}=e;return i(["Lasciati ispirare dai viaggi dei nostri stagisti"])},innovative:e=>{const{normalize:i}=e;return i(["INNOVATIVO"])},intern_work1:e=>{const{normalize:i}=e;return i(["Modelli LLM ottimizzati per incorporamenti migliori"])},intern_work2:e=>{const{normalize:i}=e;return i(["Esplorato il potenziale di Retrieval Augmented Generation"])},intern_work3:e=>{const{normalize:i}=e;return i(["Ha pubblicato un articolo sul tema dell'incorporamento di frasi"])},intern_work4:e=>{const{normalize:i}=e;return i(["Infondere continua vitalità giovanile nella squadra"])},intern_work5:e=>{const{normalize:i}=e;return i(["Tecniche di quantizzazione benchmark per comprimere LLM"])},intern_work6:e=>{const{normalize:i}=e;return i(["Creazione e promozione di una campagna avvincente per PromptPerfect"])},intern_work7:e=>{const{normalize:i}=e;return i(["JinaColBERT V2 sviluppato e migliorato rapidamente"])},recruiting_and_administrative_intern:e=>{const{normalize:i}=e;return i(["Stagista reclutamento e amministrazione"])},researcher_intern:e=>{const{normalize:i}=e;return i(["Ricercatore tirocinante"])},self_motivated:e=>{const{normalize:i}=e;return i(["AUTOMOTIVATO"])},software_engineer_intern:e=>{const{normalize:i}=e;return i(["Tirocinante Ingegnere informatico"])},spring:e=>{const{normalize:i}=e;return i(["Primavera"])},submit_application:e=>{const{normalize:i}=e;return i(["Dai il via alla tua avventura con Jina AI"])},subtitle:e=>{const{normalize:i}=e;return i(["Il nostro programma di tirocinio a tempo pieno offre un'esperienza lavorativa pratica attraverso progetti di tirocinio ben progettati in una vasta gamma di ambiti."])},subtitle1:e=>{const{normalize:i}=e;return i(["Bando mondiale per studenti: stagista in ricerca, ingegneria, marketing, vendite e altro ancora per aprire la strada all'IA multimodale insieme."])},summer:e=>{const{normalize:i}=e;return i(["Estate"])},title:e=>{const{normalize:i}=e;return i(["Programma di stagista"])},who_do_we_look_for:e=>{const{normalize:i}=e;return i(["Chi cerchiamo?"])},who_do_we_look_for_desc:e=>{const{normalize:i}=e;return i(["Apprezziamo la diversità e incoraggiamo i candidati con profili e background diversi a partecipare al nostro programma di tirocinio. Le opportunità di tirocinio sono offerte in più dipartimenti, tra cui ingegneria, design, gestione del prodotto, gestione delle vendite e dell'account, marketing e gestione della comunità."])},winter:e=>{const{normalize:i}=e;return i(["Inverno"])}},jcloud:{description:e=>{const{normalize:i}=e;return i(["Distribuisci un progetto locale come servizio cloud. Radicalmente facile, senza brutte sorprese."])}},jerboa:{description:e=>{const{normalize:i}=e;return i(["Un finetuner sperimentale per LLM open source"])}},jina:{description:e=>{const{normalize:i}=e;return i(["Crea applicazioni IA multimodali nel cloud"])}},jina_chat:{description:e=>{const{normalize:i}=e;return i(["Più modalità, memoria più lunga, meno costi"])},example_1:e=>{const{normalize:i}=e;return i(["Chi sei?"])},example_2:e=>{const{normalize:i}=e;return i(["Sono un servizio di chat LLM creato da Jina AI"])}},lab_dialog:{GlobalQA:{description:e=>{const{normalize:i}=e;return i(['Premi il tasto "/" su qualsiasi pagina per aprire la casella delle domande. Digita la tua query e premi "Invio" per ricevere risposte direttamente correlate al contenuto della pagina. Questa funzionalità è fornita da PromptPerfect.'])},title:e=>{const{normalize:i}=e;return i(["RAG a pagina"])}},Recommender:{description:e=>{const{normalize:i}=e;return i(['Apri la casella dei consigli su qualsiasi pagina di notizie con "Shift+2". Seleziona il modello di riclassificazione per scoprire i primi 5 articoli relativi a quella pagina di notizie. Goditi questa funzionalità in tempo reale, basata sulla nostra API Reranker.'])},title:e=>{const{normalize:i}=e;return i(["Articolo correlato"])}},SceneXplainTooltip:{description:e=>{const{normalize:i}=e;return i(["Passa il cursore su qualsiasi immagine nelle pagine delle notizie o nel nostro catalogo della redazione per rivelare la descrizione di quell'immagine. Le descrizioni sono precalcolate da SceneXplain e incorporate nell'attributo ALT dell'immagine per l'accessibilità."])},title:e=>{const{normalize:i}=e;return i(["Didascalie delle immagini"])}},explain:e=>{const{normalize:i}=e;return i(["Scopri le funzionalità nascoste sul nostro sito web"])}},landing_page:{also_available_on:e=>{const{normalize:i}=e;return i(["Disponibile anche sui marketplace"])},also_available_on1:e=>{const{normalize:i}=e;return i(["Disponibile sui marketplace del tuo cloud aziendale"])},ask_how_your_question:e=>{const{normalize:i}=e;return i(["Descrivi il tuo problema"])},autotune:e=>{const{normalize:i}=e;return i(["Sintonia automatica"])},badge:{v2:e=>{const{normalize:i}=e;return i(["Versione v2!"])},v3:e=>{const{normalize:i}=e;return i(["versione v3!"])}},build_js:e=>{const{normalize:i}=e;return i(["Costruisci con JavaScript"])},build_python:e=>{const{normalize:i}=e;return i(["Costruisci con Python"])},ccbync:e=>{const{normalize:i}=e;return i(["Questo modello è concesso in licenza con licenza CC BY-NC 4.0. Utilizzalo tramite API o la nostra immagine ufficiale AWS/Azure; oppure contatta il reparto vendite per la distribuzione in locale."])},checkout_our_solution_for_you:e=>{const{normalize:i}=e;return i(["Scopri la nostra soluzione su misura per te"])},classifier:e=>{const{normalize:i}=e;return i(["Classificatore"])},coming_soon:e=>{const{normalize:i}=e;return i(["Prossimamente"])},contact_sales:e=>{const{normalize:i}=e;return i(["Contatto"])},copied_to_clipboard:e=>{const{normalize:i}=e;return i(["Copiato negli appunti"])},copy:e=>{const{normalize:i}=e;return i(["copia"])},developers:e=>{const{normalize:i}=e;return i(["Sviluppatori"])},developers_desc:e=>{const{normalize:i}=e;return i(["Libera tutta la potenza dell'intelligenza artificiale multimodale con tecnologie cloud-native all'avanguardia e un'infrastruttura open source."])},download_pdf:e=>{const{normalize:i}=e;return i(["Scarica il pdf"])},embedding:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},embedding_desc1:e=>{const{normalize:i}=e;return i(["Incorporamenti multimodali multilingue a contesto lungo ad alte prestazioni per applicazioni di ricerca, RAG e agenti."])},embedding_paper_desc:e=>{const{normalize:i}=e;return i(["Jina Embeddings costituisce un insieme di modelli di incorporamento di frasi ad alte prestazioni abili nel tradurre vari input testuali in rappresentazioni numeriche, catturando così l'essenza semantica del testo. Sebbene questi modelli non siano progettati esclusivamente per la generazione di testo, eccellono in applicazioni come il recupero denso e la somiglianza testuale semantica. Questo documento descrive in dettaglio lo sviluppo di Jina Embeddings, a partire dalla creazione di un set di dati pairwise e triplet di alta qualità. Sottolinea il ruolo cruciale della pulizia dei dati nella preparazione del set di dati, fornisce approfondimenti sul processo di addestramento del modello e si conclude con una valutazione completa delle prestazioni utilizzando il Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:i}=e;return i(["Jina Embedding: un nuovo set di modelli di incorporamento di frasi ad alte prestazioni"])},embeddings:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},enterprise:e=>{const{normalize:i}=e;return i(["Impresa"])},enterprise_desc:e=>{const{normalize:i}=e;return i(["Potenzia il tuo business con soluzioni AI multimodali scalabili, sicure e su misura."])},enterprise_desc_v2:e=>{const{normalize:i}=e;return i(["Prova i nostri modelli di incorporamento di livello mondiale per migliorare i tuoi sistemi di ricerca e RAG. Inizia con una prova gratuita!"])},enterprise_desc_v3:e=>{const{normalize:i}=e;return i(["I nostri modelli di frontiera costituiscono la base di ricerca per sistemi di ricerca aziendale e RAG di alta qualità."])},error:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Si è verificato un problema con l'operazione di recupero: ",n(o("messaggio"))])},find_your_portal:e=>{const{normalize:i}=e;return i(["Trova il tuo portale"])},finding_faq:e=>{const{normalize:i}=e;return i(["Generazione di una risposta in base alla conoscenza delle domande frequenti riportate di seguito"])},for:e=>{const{normalize:i}=e;return i(["Per"])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le imprese"])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},get_api_now:e=>{const{normalize:i}=e;return i(["API"])},get_started:e=>{const{normalize:i}=e;return i(["Iniziare"])},go_to_product_homepage:e=>{const{normalize:i}=e;return i(["Vai alla home page del prodotto"])},how_to:e=>{const{normalize:i}=e;return i(["Come"])},include_experiment:e=>{const{normalize:i}=e;return i(["Include i nostri progetti sperimentali e archiviati nella soluzione."])},join_community:e=>{const{normalize:i}=e;return i(["Comunità"])},learn_more_embeddings:e=>{const{normalize:i}=e;return i(["Ulteriori informazioni sugli incorporamenti"])},learn_more_reader:e=>{const{normalize:i}=e;return i(["Scopri di più sul lettore"])},learn_more_reranker:e=>{const{normalize:i}=e;return i(["Scopri di più sul riclassificazione"])},llm:e=>{const{normalize:i}=e;return i(["Modelli di incorporamento LLM"])},llm_desc:e=>{const{normalize:i}=e;return i(["Forniamo una raccolta di modelli di incorporamento di frasi ad alte prestazioni, che vantano tra 35 milioni e 6 miliardi di parametri. Sono eccellenti per migliorare la ricerca neurale, la riclassificazione, la somiglianza delle frasi, i consigli, ecc. Preparati a migliorare la tua esperienza AI!"])},mentioned_products:e=>{const{normalize:i}=e;return i(["Prodotti menzionati:"])},mmstack:e=>{const{normalize:i}=e;return i(["Pila multimodale"])},mmstack_desc:e=>{const{normalize:i}=e;return i(["Nel corso degli anni, abbiamo sviluppato una varietà di software open source per aiutare gli sviluppatori a creare una migliore GenAI e a cercare le applicazioni più velocemente."])},models:e=>{const{normalize:i}=e;return i(["Modelli"])},more:e=>{const{normalize:i}=e;return i(["Di più"])},multimodal:e=>{const{normalize:i}=e;return i(["Multimodale"])},multimodal_ai:e=>{const{normalize:i}=e;return i(["IA multimodale"])},new:e=>{const{normalize:i}=e;return i(["Nuovo"])},newsroom:e=>{const{normalize:i}=e;return i(["Sala stampa"])},num_publications:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_total"))," pubblicazioni in totale."])},"on-prem-deploy":e=>{const{normalize:i}=e;return i(["Distribuzione locale"])},"on-premises":e=>{const{normalize:i}=e;return i(["In sede"])},opensource:e=>{const{normalize:i}=e;return i(["Fonte aperta"])},our_customer:e=>{const{normalize:i}=e;return i(["I nostri clienti"])},our_customer_explain:e=>{const{normalize:i}=e;return i(["Le aziende di tutte le dimensioni si affidano alla Search Foundation di Jina AI per potenziare i propri strumenti e prodotti: puoi farlo anche tu."])},our_publications:e=>{const{normalize:i}=e;return i(["Le nostre pubblicazioni"])},parameters:e=>{const{normalize:i}=e;return i(["Parametri"])},podcast:e=>{const{normalize:i}=e;return i(["Podcast"])},power_users:e=>{const{normalize:i}=e;return i(["Utenti esperti"])},power_users_desc:e=>{const{normalize:i}=e;return i(["Ingegneria automatica per la tua produttività quotidiana."])},powered_by_promptperfect:e=>{const{normalize:i}=e;return i(['Alimentato dalla funzione "Prompt optimization" e "Prompt as a service" di PromptPerfect'])},pricing:e=>{const{normalize:i}=e;return i(["Prezzi"])},proposing_solution:e=>{const{normalize:i}=e;return i(["Proporre una soluzione basata sui prodotti Jina AI..."])},read_more:e=>{const{normalize:i}=e;return i(["Per saperne di più"])},reader:e=>{const{normalize:i}=e;return i(["Lettore"])},require_full_question:e=>{const{normalize:i}=e;return i(["Descrivi il tuo problema con maggiori dettagli."])},reranker:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},researcher_desc:e=>{const{normalize:i}=e;return i(["Scopri come i nostri modelli di ricerca di frontiera sono stati addestrati da zero, dai un'occhiata alle nostre ultime pubblicazioni. Incontra il nostro team presso EMNLP, SIGIR, ICLR, NeurIPS e ICML!"])},researchers:e=>{const{normalize:i}=e;return i(["Ricercatori"])},sdk:e=>{const{normalize:i}=e;return i(["SDK"])},sdk_desc:e=>{const{normalize:i}=e;return i(["Vuoi creare applicazioni AIGC di alto livello utilizzando le API PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale? Ti abbiamo coperto! Prova il nostro SDK facile da usare e inizia in pochi minuti."])},sdk_docs:e=>{const{normalize:i}=e;return i(["Leggi i documenti"])},sdk_example:e=>{const{normalize:i}=e;return i(["Esempio"])},search_foundation:e=>{const{normalize:i}=e;return i(["Cerca Fondazione"])},source_code:e=>{const{normalize:i}=e;return i(["Codice sorgente"])},starter_kit:e=>{const{normalize:i}=e;return i(["Kit di partenza"])},supercharged1:e=>{const{normalize:i}=e;return i(["Sovralimentato."])},tokenizer:e=>{const{normalize:i}=e;return i(["Segmentatore"])},trusted_by:e=>{const{normalize:i}=e;return i(["AFFIDATO DA"])},try_it_for_free:e=>{const{normalize:i}=e;return i(["Inizia subito: non serve alcuna carta di credito o registrazione!"])},try_our_saas:e=>{const{normalize:i}=e;return i(["Prova la nostra soluzione ospitata, un sostituto immediato dell'API di incorporamento di OpenAI."])},your_portal_to:e=>{const{normalize:i}=e;return i(["Il tuo portale per"])},your_search_foundation1:e=>{const{normalize:i}=e;return i(["La tua base di ricerca"])}},langchain_serve:{description:e=>{const{normalize:i}=e;return i(["App Langchain in produzione con Jina e FastAPI"])}},model_graph:{api:e=>{const{normalize:i}=e;return i(["API di intelligenza artificiale Jina"])},contact_sales_about_it:e=>{const{normalize:i}=e;return i(["Contatta il reparto vendite a riguardo"])},deploy_it_on:e=>{const{normalize:i}=e;return i(["Distribuiscilo su"])},description:e=>{const{normalize:i}=e;return i(["Nel corso degli anni, abbiamo continuato a spingere i confini della ricerca. Di seguito sono riportati i modelli che abbiamo rilasciato: passa il mouse o fai clic su ciascuno di essi per vedere maggiori dettagli."])},find_on_hf:e=>{const{normalize:i}=e;return i(["Trovalo su HuggingFace"])},search_for:e=>{const{normalize:i}=e;return i(["Cercalo sul nostro sito"])},search_models:e=>{const{normalize:i}=e;return i(["Filtra per nome modello"])},title:e=>{const{normalize:i}=e;return i(["I nostri modelli di fondazione di ricerca"])},use_it_via:e=>{const{normalize:i}=e;return i(["Usalo tramite"])}},news_page:{back_to_newsroom:e=>{const{normalize:i}=e;return i(["Torniamo alla redazione"])},categories:e=>{const{normalize:i}=e;return i(["Categorie"])},copy_link:e=>{const{normalize:i}=e;return i(["Copia il collegamento a questa sezione"])},in_this_article:e=>{const{normalize:i}=e;return i(["In questo articolo"])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di più"])},news_not_found:e=>{const{normalize:i}=e;return i(["Articolo non trovato"])},redirect_to_news:e=>{const{normalize:i}=e;return i(["Reindirizzamento alla redazione tra 5 secondi..."])}},newsroom_page:{academic:e=>{const{normalize:i}=e;return i(["Accademico"])},academic_research:e=>{const{normalize:i}=e;return i(["Pubblicazioni accademiche"])},author:e=>{const{normalize:i}=e;return i(["Filtra per autore"])},description:e=>{const{normalize:i}=e;return i(["Leggi le ultime notizie e gli aggiornamenti da Jina AI."])},description1:e=>{const{normalize:i}=e;return i(["Realizzare innovazioni legate all'intelligenza artificiale, una parola alla volta."])},engineering_group:e=>{const{normalize:i}=e;return i(["Gruppo Ingegneria"])},engineering_group_date:e=>{const{normalize:i}=e;return i(["31 maggio 2021"])},minutes_read:e=>{const{normalize:i}=e;return i(["minuti letti"])},most_recent_articles:e=>{const{normalize:i}=e;return i(["Articoli più recenti"])},news_description:e=>{const{normalize:i}=e;return i(['Per Jina 2.0, abbiamo ascoltato la community. Veramente, profondamente ascoltato. "Quali sono i tuoi punti dolenti?" abbiamo chiesto, aspettando con impazienza un prezioso feedback'])},news_title:e=>{const{normalize:i}=e;return i(["Cerca tutte le cose: stiamo organizzando un concorso MEME per Jina 2.0"])},photos:e=>{const{normalize:i}=e;return i(["Fotografie"])},product:e=>{const{normalize:i}=e;return i(["Filtra per prodotto"])},search:e=>{const{normalize:i}=e;return i(["Cerca per titolo"])},tech_blog:e=>{const{normalize:i}=e;return i(["Blog tecnico"])},title:e=>{const{normalize:i}=e;return i(["Sala stampa"])},top_stories:e=>{const{normalize:i}=e;return i(["Le migliori storie"])}},notice:e=>{const{normalize:i}=e;return i(['🎉 Il nostro primo libro, "Neural Search — From Prototype to Production with Jina" è ufficialmente uscito oggi!'])},open_day:{description:e=>{const{normalize:i}=e;return i(["Un'opportunità esclusiva per ottenere una visione dall'interno di Jina AI."])},engage:e=>{const{normalize:i}=e;return i(["Incoraggiamo vivamente un dialogo interattivo durante tutta la giornata. Lo scambio di pensieri e prospettive è inestimabile per noi. Le potenziali collaborazioni derivanti da queste discussioni potrebbero contribuire in modo significativo a un futuro più integrato e innovativo."])},engage_title:e=>{const{normalize:i}=e;return i(["Interagisci con noi"])},experience:e=>{const{normalize:i}=e;return i(["Abbiamo organizzato un coinvolgente tour di tre ore per i nostri ospiti, disponibile in tedesco, inglese, francese, spagnolo, cinese e russo. Il tour copre uno sguardo approfondito ai nostri progressi nell'IA multimodale, la nostra prospettiva sul panorama dell'IA, seguito da un esame dettagliato di progetti specifici. Concluderemo con una discussione di gruppo per facilitare lo scambio di idee e approfondimenti. Su richiesta è disponibile anche un'opzione per il pranzo."])},experience_title:e=>{const{normalize:i}=e;return i(["Il viaggio di un insider"])},group_size:e=>{const{normalize:i}=e;return i(["Numero stimato di visitatori"])},impact:e=>{const{normalize:i}=e;return i(["Scopri come i nostri contributi alla comunità open source e il nostro lavoro nella tecnologia IA multimodale stanno facendo di Jina AI un attore influente nell'innovazione IA. Miriamo a svolgere un ruolo significativo nei processi decisionali, assicurandoci che il progresso della tecnologia AI sia vantaggioso per tutti."])},impact_title:e=>{const{normalize:i}=e;return i(["Impatto e influenza"])},introduction:e=>{const{normalize:i}=e;return i(["Jina AI è lieta di aprire le nostre porte a entità e organizzazioni stimate interessate al progresso e al futuro dell'Intelligenza Artificiale. Estendiamo questa opportunità esclusiva per coloro che operano in politica, ONG, NPO e settori di investimento per ottenere una visione dall'interno delle nostre operazioni e visioni qui presso la nostra sede di Berlino."])},motivation_min_length_v1:e=>{const{normalize:i}=e;return i(["Si prega di fornire una motivazione più dettagliata."])},motivation_placeholder_v2:e=>{const{normalize:i}=e;return i(["Condividere le tue motivazioni ci aiuterà a migliorare la tua esperienza."])},motivation_to_attend_v2:e=>{const{normalize:i}=e;return i(["Perché sei interessato al nostro Open Day?"])},one_hour:e=>{const{normalize:i}=e;return i(["1 ora"])},organization:e=>{const{normalize:i}=e;return i(["Organizzazione"])},organization_website:e=>{const{normalize:i}=e;return i(["Sito web dell'organizzazione"])},organization_website_placeholder:e=>{const{normalize:i}=e;return i(["URL della home page o del profilo LinkedIn della tua organizzazione"])},preferred_date:e=>{const{normalize:i}=e;return i(["Data preferita"])},preferred_language:e=>{const{normalize:i}=e;return i(["Lingua preferita del tour"])},preferred_products:e=>{const{normalize:i}=e;return i(["A quali prodotti sei interessato?"])},subtitle:e=>{const{normalize:i}=e;return i(["Uno sguardo al futuro dell'IA multimodale"])},title:e=>{const{normalize:i}=e;return i(["Giornata delle porte aperte"])},tutor_subtitle:e=>{const{normalize:i}=e;return i(["Un tour di tre ore meticolosamente curato, che ti avvicina al cuore del lavoro rivoluzionario di Jina AI nella tecnologia AI multimodale."])},tutor_title:e=>{const{normalize:i}=e;return i(["Un'esclusiva immersione profonda in"])},vision:e=>{const{normalize:i}=e;return i(["Unisciti a noi per una panoramica completa del panorama dell'IA come lo vediamo noi. La nostra discussione si concentrerà sul potenziale dei modelli linguistici di grandi dimensioni, dell'IA multimodale e dell'impatto della tecnologia open source nel plasmare il futuro dell'innovazione globale."])},vision_title:e=>{const{normalize:i}=e;return i(["La nostra visione per il futuro"])}},open_day_faq:{answer1:e=>{const{normalize:i}=e;return i(["Offriamo tour in tedesco, inglese, francese, spagnolo, cinese e russo."])},answer2:e=>{const{normalize:i}=e;return i(["Il tour dura in genere circa tre ore."])},answer3:e=>{const{normalize:i}=e;return i(["Il pranzo è facoltativo e può essere organizzato su richiesta."])},answer4:e=>{const{normalize:i}=e;return i(["Il nostro Open Day è progettato principalmente per gruppi professionali, come politici, ONG, NPO e investitori. Tuttavia, occasionalmente facciamo delle eccezioni in base al profilo dell'individuo."])},answer5:e=>{const{normalize:i}=e;return i(["Siamo in grado di ospitare una varietà di dimensioni di gruppo. Indica la dimensione del tuo gruppo nel modulo di registrazione e confermeremo i dettagli con te."])},answer6:e=>{const{normalize:i}=e;return i(["C'è una sezione nel modulo di registrazione dove puoi specificare le tue aree di interesse o eventuali richieste particolari. Faremo del nostro meglio per personalizzare il tour in base alle vostre esigenze."])},answer7:e=>{const{normalize:i}=e;return i(["Al momento, offriamo tour solo presso la nostra sede di Berlino situata a Kreuzberg. I nostri uffici di Pechino e Shenzhen non sono attualmente aperti per i tour."])},question1:e=>{const{normalize:i}=e;return i(["Quali lingue offrite per il tour?"])},question2:e=>{const{normalize:i}=e;return i(["Qual è la durata del tour?"])},question3:e=>{const{normalize:i}=e;return i(["Il pranzo è previsto?"])},question4:e=>{const{normalize:i}=e;return i(["Le persone possono iscriversi all'Open Day?"])},question5:e=>{const{normalize:i}=e;return i(["Da quante persone può essere composto un gruppo per l'Open Day?"])},question6:e=>{const{normalize:i}=e;return i(["Come posso specificare le aree di interesse per il tour?"])},question7:e=>{const{normalize:i}=e;return i(["I tour sono disponibili presso i vostri uffici di Pechino o Shenzhen?"])}},open_gpt:{description:e=>{const{normalize:i}=e;return i(["Un cloud-native open source di grandi modelli multimodali al servizio del framework"])}},paywall:{commercial_licence:{chip_label:e=>{const{normalize:i}=e;return i(["Esclusivo per le piccole aziende"])},company_size_note:e=>{const{normalize:i}=e;return i(["Esclusivo per aziende con meno di 100 dipendenti e un fatturato di 5 milioni di $"])},cta_button:e=>{const{normalize:i}=e;return i(["Iniziare"])},feature_api_desc:e=>{const{normalize:i}=e;return i(["Prova prima dell'acquisto"])},feature_api_title:e=>{const{normalize:i}=e;return i(["Accesso gratuito ai test API"])},feature_consulting:e=>{const{normalize:i}=e;return i(["Sessione di consulenza trimestrale di 2 ore con i nostri esperti di modelli"])},feature_consulting_desc:e=>{const{normalize:i}=e;return i(["2 ore al trimestre (non rimborsabili, non trasferibili)"])},feature_future_support:e=>{const{normalize:i}=e;return i(["Utilizzo immediato dei nostri modelli futuri senza dover chiedere nuovamente il permesso"])},feature_future_support_desc:e=>{const{normalize:i}=e;return i(["Inclusi patch e aggiornamenti del modello"])},feature_models:e=>{const{normalize:i}=e;return i(["Utilizzo commerciale dei nostri modelli CC-by-NC esistenti e futuri"])},feature_models_desc:e=>{const{normalize:i}=e;return i(["Sebbene l'uso commerciale dei nostri modelli sia consentito, la rivendita, la ridistribuzione e la sublicenza degli stessi sono vietate."])},price_amount:e=>{const{normalize:i}=e;return i(["1.000 dollari"])},price_period:e=>{const{normalize:i}=e;return i(["/ quarto"])},read_the_terms:e=>{const{normalize:i}=e;return i(["Rivedi i termini della licenza"])},read_the_terms_btn:e=>{const{normalize:i}=e;return i(["Termini"])},read_the_terms_desc:e=>{const{normalize:i}=e;return i(["Esaminare i diritti e le limitazioni della licenza commerciale prima dell'acquisto"])},subtitle:e=>{const{normalize:i}=e;return i(["Ogni modello di cui hai bisogno per una ricerca migliore"])},test_before_purchase:e=>{const{normalize:i}=e;return i(["Prova prima di acquistare"])},test_before_purchase_desc:e=>{const{normalize:i}=e;return i(["Ottieni 1 milione di token API gratuiti o usa il nostro modello Hugging Face per convalidare le prestazioni"])},title:e=>{const{normalize:i}=e;return i(["Licenza commerciale"])}},free_hour_consult:e=>{const{normalize:i}=e;return i(["Consulenza gratuita di 1 ora"])},free_hour_consult_description:e=>{const{normalize:i}=e;return i(["Un'ora di consulenza gratuita con i nostri team di prodotto e ingegneria per discutere le best practice per il tuo caso d'uso"])},full_commercial:e=>{const{normalize:i}=e;return i(["Uso commerciale senza restrizioni"])},full_commercial_description:e=>{const{normalize:i}=e;return i(["È possibile utilizzare l'API per scopi commerciali senza alcuna restrizione."])},higher_limit:e=>{const{normalize:i}=e;return i(["Limite di velocità molto più alto"])},higher_limit_description:e=>{const{normalize:i}=e;return i(["Ottieni fino a 1000 RPM per r.jina.ai e 100 RPM per s.jina.ai; maggiori dettagli nella sezione sui limiti di velocità."])},no_commercial:e=>{const{normalize:i}=e;return i(["Solo per uso non commerciale (CC-BY-NC)"])},no_commercial_description:e=>{const{normalize:i}=e;return i(["Puoi usare l'API solo per scopi non commerciali. Per uso commerciale, ricarica la tua chiave API."])},on_prem:e=>{const{normalize:i}=e;return i(["Con una licenza commerciale per la distribuzione on-prem"])},on_prem_explain:e=>{const{normalize:i}=e;return i(["Acquista una licenza commerciale per utilizzare i nostri modelli in sede."])},priority_support:e=>{const{normalize:i}=e;return i(["Assistenza clienti prioritaria"])},priority_support_description:e=>{const{normalize:i}=e;return i(["Risposta via email garantita entro 24 ore, compresi i fine settimana"])},secured_by_stripe:e=>{const{normalize:i}=e;return i(["Pagamento sicuro tramite Stripe"])},via_api:e=>{const{normalize:i}=e;return i(["Con l'API Jina Search Foundation"])},via_api_explain:e=>{const{normalize:i}=e;return i(["Il modo più semplice per accedere a tutti i nostri prodotti. Ricarica i token man mano che procedi."])}},powered_by:e=>{const{normalize:i}=e;return i(["Offerto da"])},print:e=>{const{normalize:i}=e;return i(["Stampa"])},project_status:{archived:e=>{const{normalize:i}=e;return i(["Archiviato"])},cloud_native:e=>{const{normalize:i}=e;return i(["Nativo del cloud"])},core:e=>{const{normalize:i}=e;return i(["Nucleo"])},data_structure:e=>{const{normalize:i}=e;return i(["Struttura dati"])},embedding_serving:e=>{const{normalize:i}=e;return i(["Incorporamento della pubblicazione"])},embedding_tuning:e=>{const{normalize:i}=e;return i(["Incorporamento dell'ottimizzazione"])},graduated:e=>{const{normalize:i}=e;return i(["Laureato"])},incubating:e=>{const{normalize:i}=e;return i(["Incubazione"])},kubernetes:e=>{const{normalize:i}=e;return i(["Kubernetes"])},large_size_model:e=>{const{normalize:i}=e;return i(["Modello di grandi dimensioni"])},linux_foundation:e=>{const{normalize:i}=e;return i(["Fondazione Linux"])},llm1:e=>{const{normalize:i}=e;return i(["LLMOps"])},mid_size_model:e=>{const{normalize:i}=e;return i(["Modello di taglia media"])},model_serving:e=>{const{normalize:i}=e;return i(["Modello che serve"])},model_tuning:e=>{const{normalize:i}=e;return i(["Messa a punto del modello"])},observability:e=>{const{normalize:i}=e;return i(["Osservabilità"])},orchestration:e=>{const{normalize:i}=e;return i(["Orchestrazione"])},prompt_serving:e=>{const{normalize:i}=e;return i(["Servizio rapido"])},prompt_tuning:e=>{const{normalize:i}=e;return i(["Sintonizzazione rapida"])},rag1:e=>{const{normalize:i}=e;return i(["STRACCIO"])},sandbox:e=>{const{normalize:i}=e;return i(["Sabbiera"])},small_size_model:e=>{const{normalize:i}=e;return i(["Modello di piccole dimensioni"])},vector_database:e=>{const{normalize:i}=e;return i(["Banca dati vettoriale"])},vector_store:e=>{const{normalize:i}=e;return i(["Negozio di vettore"])}},prompt_perfect:{description:e=>{const{normalize:i}=e;return i(["Strumento principale per l'ingegneria rapida"])},image_model:e=>{const{normalize:i}=e;return i(["Modelli di immagine"])},intro:e=>{const{normalize:i}=e;return i(["Strumento principale per l'ingegneria rapida"])},intro1:e=>{const{normalize:i}=e;return i(["Lo strumento principale per un'ingegneria tempestiva"])},optimized:e=>{const{normalize:i}=e;return i(["Il tuo compito è essere il mio compagno di brainstorming e fornire idee e suggerimenti creativi per un determinato argomento o problema. La tua risposta dovrebbe includere idee originali, uniche e pertinenti che potrebbero aiutare a risolvere il problema o esplorare ulteriormente l'argomento in modo interessante. Tieni presente che la tua risposta dovrebbe anche tenere conto di eventuali requisiti o vincoli specifici dell'attività."])},optimized_title:e=>{const{normalize:i}=e;return i(["Prompt ottimizzato"])},original:e=>{const{normalize:i}=e;return i(["Il tuo ruolo è quello di essere il mio compagno di brainstorming."])},original_title:e=>{const{normalize:i}=e;return i(["Richiesta originale"])},text_model:e=>{const{normalize:i}=e;return i(["Modelli testuali"])}},promptperfect:{features:[{description:e=>{const{normalize:i}=e;return i(["Passa facilmente dalla generazione di contenuti all'ottimizzazione rapida e porta la qualità dei tuoi contenuti a un livello superiore."])},name:e=>{const{normalize:i}=e;return i(["Assistente"])},title:e=>{const{normalize:i}=e;return i(["Dose giornaliera di produttività."])}},{description:e=>{const{normalize:i}=e;return i(["Non sai come scrivere un'istruzione efficace? Inserisci semplicemente la tua idea, con un clic ottieni istruzioni migliori."])},name:e=>{const{normalize:i}=e;return i(["Ottimizzazione immediata"])},title:e=>{const{normalize:i}=e;return i(["Migliori input, migliori risultati"])}},{description:e=>{const{normalize:i}=e;return i(["Comprendi l'atmosfera di ogni modello di intelligenza artificiale confrontando l'output dello stesso prompt."])},name:e=>{const{normalize:i}=e;return i(["Confronta i modelli"])},title:e=>{const{normalize:i}=e;return i(["Confronto dei modelli affiancati."])}},{description:e=>{const{normalize:i}=e;return i(["Forse il modo più semplice per distribuire le tue richieste come API per l'integrazione."])},name:e=>{const{normalize:i}=e;return i(["Distribuire i prompt"])},title:e=>{const{normalize:i}=e;return i(["Nessuna operazione, basta schierarsi."])}},{description:e=>{const{normalize:i}=e;return i(["Personalizza i tuoi agenti LLM e avvia una simulazione multi-agente. Guarda come collaborano o competono in un ambiente virtuale per raggiungere l'obiettivo."])},name:e=>{const{normalize:i}=e;return i(["Multiagente"])},title:e=>{const{normalize:i}=e;return i(["Scopri come collaborano gli agenti"])}}],get_started:e=>{const{normalize:i}=e;return i(["Inizia con PromptPerfect"])}},purchase:{success:e=>{const{normalize:i}=e;return i(["Grazie per il vostro acquisto!"])},success_caption:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Abbiamo completato il tuo ordine alle ",n(o("_purchasedTime")),". La tua chiave API è pronta per l'uso!"])}},purchase_now:e=>{const{normalize:i}=e;return i(["Acquista adesso"])},rate_limit:{batch_explain:e=>{const{normalize:i}=e;return i(["Questa API supporta operazioni batch, consentendo fino a 512 documenti per richiesta, con ogni documento contenente fino a 8192 token. Sfruttare in modo intelligente le operazioni batch può ridurre significativamente il numero di richieste e migliorare le prestazioni."])},classifier:e=>{const{normalize:i}=e;return i(["Addestrare un classificatore utilizzando esempi etichettati"])},classifier_few_shot:e=>{const{normalize:i}=e;return i(["Classificare gli input utilizzando un classificatore addestrato a pochi scatti"])},classifier_few_shot_token_counting:e=>{const{normalize:i}=e;return i(["I token sono conteggiati come: input_tokens"])},classifier_latency:e=>{const{normalize:i}=e;return i(["Il tempo di risposta varia in base alla dimensione dell'input"])},classifier_token_counting:e=>{const{normalize:i}=e;return i(["I token vengono conteggiati come: input_tokens × num_iters"])},classifier_zero_shot:e=>{const{normalize:i}=e;return i(["Classificare gli input utilizzando la classificazione zero-shot"])},classifier_zero_shot_token_counting:e=>{const{normalize:i}=e;return i(["I token vengono conteggiati come: input_tokens + label_tokens"])},depends:e=>{const{normalize:i}=e;return i(["dipende dalla dimensione dell'input"])},description:e=>{const{normalize:i}=e;return i(["Descrizione"])},embeddings:e=>{const{normalize:i}=e;return i(["Convertire testo/immagini in vettori di lunghezza fissa"])},endpoint:e=>{const{normalize:i}=e;return i(["Punto finale API"])},explain:e=>{const{normalize:i}=e;return i(["I limiti di velocità vengono monitorati in due modi: <b>RPM</b> (richieste al minuto) e <b>TPM</b> (token al minuto). I limiti vengono applicati per IP e possono essere raggiunti in base alla soglia (RPM o TPM) raggiunta per prima."])},gjinaai:e=>{const{normalize:i}=e;return i(["Basare un'affermazione sulla conoscenza del web"])},input_token_counting:e=>{const{normalize:i}=e;return i(["Conta il numero di token nella richiesta di input."])},latency:e=>{const{normalize:i}=e;return i(["Latenza media"])},no_token_counting:e=>{const{normalize:i}=e;return i(["Il token non viene conteggiato come utilizzo."])},output_token_counting:e=>{const{normalize:i}=e;return i(["Contare il numero di token nella risposta di output."])},premium_rate:e=>{const{normalize:i}=e;return i(["Con possibilità di limiti di velocità più elevati"])},product:e=>{const{normalize:i}=e;return i(["Prodotto"])},requestType:e=>{const{normalize:i}=e;return i(["Richiesta consentita"])},reranker:e=>{const{normalize:i}=e;return i(["Classifica i documenti per query"])},rjinaai:e=>{const{normalize:i}=e;return i(["Convertire l'URL in testo compatibile con LLM"])},sjinaai:e=>{const{normalize:i}=e;return i(["Cerca sul web e converti i risultati in testo compatibile con LLM"])},tbd:e=>{const{normalize:i}=e;return i(["Da determinare"])},title:e=>{const{normalize:i}=e;return i(["Limite di velocità"])},tokenCounting:e=>{const{normalize:i}=e;return i(["Conteggio dell'utilizzo del token"])},tokenizer:e=>{const{normalize:i}=e;return i(["Tokenizzare e segmentare il testo lungo"])},total_token_counting:e=>{const{normalize:i}=e;return i(["Contare il numero totale di token nell'intero processo."])},understanding:e=>{const{normalize:i}=e;return i(["Comprendere il limite di velocità"])},understanding_description:e=>{const{normalize:i}=e;return i(["I limiti di velocità sono il numero massimo di richieste che possono essere effettuate a un'API in un minuto per indirizzo IP (RPM). Scopri di più sui limiti di velocità per ogni prodotto e livello qui sotto."])},wAPIkey:e=>{const{normalize:i}=e;return i(["con chiave API"])},wPremium:e=>{const{normalize:i}=e;return i(["con chiave API Premium"])},woAPIkey:e=>{const{normalize:i}=e;return i(["senza chiave API"])}},rationale:{decision:e=>{const{normalize:i}=e;return i(["Decisione"])},description:e=>{const{normalize:i}=e;return i(["Strumenti decisionali IA all'avanguardia"])},intro:e=>{const{normalize:i}=e;return i(["Guarda i due lati della medaglia, prendi decisioni razionali"])}},reader:{beta:e=>{const{normalize:i}=e;return i(["Sperimentale"])},better_input:e=>{const{normalize:i}=e;return i(["Migliora la qualità dell'input fin dall'inizio"])},better_input_description:e=>{const{normalize:i}=e;return i(["Riscontri problemi con l'output del tuo agente o del sistema RAG? Potrebbe essere dovuto alla scarsa qualità dell'input."])},check_price_table:e=>{const{normalize:i}=e;return i(["Controlla la tabella dei prezzi"])},copy:e=>{const{normalize:i}=e;return i(["copia"])},demo:{advanced_usage:e=>{const{normalize:i}=e;return i(["Utilizzo avanzato"])},ask_llm:e=>{const{normalize:i}=e;return i(["Chiedi a LLM senza e con ricerca messa a terra"])},ask_llm_directly:e=>{const{normalize:i}=e;return i(["Chiedi direttamente a LLM"])},ask_llm_with_search_grounding:e=>{const{normalize:i}=e;return i(["Chiedi a LLM con la messa a terra della ricerca"])},ask_question:e=>{const{normalize:i}=e;return i(["Poni una domanda"])},ask_question_hint:e=>{const{normalize:i}=e;return i(["Inserisci una domanda e combinala con il contenuto recuperato affinché LLM generi una risposta"])},basic_usage:e=>{const{normalize:i}=e;return i(["Utilizzo di base"])},basic_usage1:e=>{const{normalize:i}=e;return i(["Leggi un URL"])},basic_usage2:e=>{const{normalize:i}=e;return i(["Cerca una query"])},basic_usage3:e=>{const{normalize:i}=e;return i(["Messa a terra"])},copy:e=>{const{normalize:i}=e;return i(["copia"])},fetch:e=>{const{normalize:i}=e;return i(["Recupera contenuto"])},get_response:e=>{const{normalize:i}=e;return i(["Ottieni risposta"])},headers:{auth_token:e=>{const{normalize:i}=e;return i(["Aggiungi chiave API per un limite di velocità più elevato"])},auth_token_explain:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API Jina per accedere a un limite di velocità più elevato. Per le informazioni più recenti sui limiti di tariffa, fare riferimento alla tabella seguente."])},browser_locale:e=>{const{normalize:i}=e;return i(["Impostazioni locali del browser"])},browser_locale_explain:e=>{const{normalize:i}=e;return i(["Controlla le impostazioni locali del browser per il rendering della pagina. Molti siti web offrono contenuti diversi in base alle impostazioni locali."])},default:e=>{const{normalize:i}=e;return i(["Predefinito"])},default_explain:e=>{const{normalize:i}=e;return i(["Pipeline predefinita ottimizzata per la maggior parte dei siti web e input LLM."])},file:e=>{const{normalize:i}=e;return i(["File PDF/HTML locale"])},file_explain:e=>{const{normalize:i}=e;return i(["Utilizza Reader sul tuo file PDF e HTML locale caricandoli. Supporta solo file PDF e HTML."])},html:e=>{const{normalize:i}=e;return i(["HTML"])},html_explain:e=>{const{normalize:i}=e;return i(["Restituisce documentElement.outerHTML."])},image_caption:e=>{const{normalize:i}=e;return i(["Didascalia immagine"])},image_caption_explain:e=>{const{normalize:i}=e;return i([`Sottotitola tutte le immagini all'URL specificato, aggiungendo "Immagine [idx]: [didascalia]" come tag alt per quelle senza. Ciò consente ai LLM a valle di interagire con le immagini in attività come il ragionamento e il riepilogo.`])},images_summary:e=>{const{normalize:i}=e;return i(["Raccogli tutte le immagini alla fine"])},images_summary_explain:e=>{const{normalize:i}=e;return i(['Alla fine verrà creata una sezione "Immagini". Ciò fornisce ai LLM a valle una panoramica di tutti gli elementi visivi sulla pagina, il che può migliorare il ragionamento.'])},json_response:e=>{const{normalize:i}=e;return i(["Risposta JSON"])},json_response_explain:e=>{const{normalize:i}=e;return i(["La risposta sarà in formato JSON, contenente l'URL, il titolo, il contenuto e il timestamp (se disponibile). Nella modalità di ricerca, restituisce un elenco di cinque voci, ciascuna seguendo la struttura JSON descritta."])},links_summary:e=>{const{normalize:i}=e;return i(["Raccogli tutti i collegamenti alla fine"])},links_summary_explain:e=>{const{normalize:i}=e;return i(['Alla fine verrà creata una sezione "Pulsanti e collegamenti". Ciò aiuta i LLM downstream o gli agenti web a navigare nella pagina o a intraprendere ulteriori azioni.'])},markdown:e=>{const{normalize:i}=e;return i(["Ribasso"])},markdown_explain:e=>{const{normalize:i}=e;return i(["Restituisce il markdown direttamente dall'HTML, aggirando il filtro di leggibilità."])},mode:e=>{const{normalize:i}=e;return i(["Modalità di lettura o ricerca"])},mode_explain:e=>{const{normalize:i}=e;return i(["La modalità di lettura consente di accedere al contenuto di un URL, mentre la modalità di ricerca consente di cercare una query sul Web, applicando la modalità di lettura a ciascun URL dei risultati di ricerca."])},no_cache:e=>{const{normalize:i}=e;return i(["Bypassa la cache"])},no_cache_explain:e=>{const{normalize:i}=e;return i(["Il nostro server API memorizza nella cache sia i contenuti in modalità Lettura che quelli in modalità Ricerca per un certo periodo di tempo. Per ignorare questa cache, imposta questa intestazione su true."])},pageshot:e=>{const{normalize:i}=e;return i(["Pagina scattata"])},pageshot_explain:e=>{const{normalize:i}=e;return i(["Restituisce l'URL dell'immagine dello screenshot a pagina intera (con il massimo impegno)."])},post_with_url:e=>{const{normalize:i}=e;return i(["Utilizza il metodo POST"])},post_with_url_explain:e=>{const{normalize:i}=e;return i(["Utilizza il metodo POST anziché GET con un URL passato nel corpo. Utile per creare SPA con routing basato su hash."])},proxy_server:e=>{const{normalize:i}=e;return i(["Utilizza un server proxy"])},proxy_server_explain:e=>{const{normalize:i}=e;return i(["Il nostro server API può utilizzare il tuo proxy per accedere agli URL, il che è utile per le pagine accessibili solo tramite proxy specifici."])},references:e=>{const{normalize:i}=e;return i(["Riferimenti"])},references_explain:e=>{const{normalize:i}=e;return i(["Elenco separato da virgole dei riferimenti forniti dall'utente (URL)"])},remove_selector:e=>{const{normalize:i}=e;return i(["Selettore escluso"])},remove_selector_explain:e=>{const{normalize:i}=e;return i(["Fornisci un elenco di selettori CSS per rimuovere gli elementi specificati della pagina. Utile quando vuoi escludere parti specifiche della pagina come intestazioni, piè di pagina, ecc."])},return_format:e=>{const{normalize:i}=e;return i(["Formato del contenuto"])},return_format_explain:e=>{const{normalize:i}=e;return i(["Puoi controllare il livello di dettaglio nella risposta per evitare un filtro eccessivo. La pipeline predefinita è ottimizzata per la maggior parte dei siti Web e per l'input LLM."])},screenshot:e=>{const{normalize:i}=e;return i(["Immagine dello schermo"])},screenshot_explain:e=>{const{normalize:i}=e;return i(["Restituisce l'URL dell'immagine della prima schermata."])},set_cookie:e=>{const{normalize:i}=e;return i(["Cookie in avanti"])},set_cookie_explain:e=>{const{normalize:i}=e;return i(["Il nostro server API può inoltrare le tue impostazioni personalizzate dei cookie quando accedi all'URL, il che è utile per le pagine che richiedono un'autenticazione aggiuntiva. Tieni presente che le richieste con cookie non verranno memorizzate nella cache."])},site_selector:e=>{const{normalize:i}=e;return i(["Ricerca nel sito"])},site_selector_explain:e=>{const{normalize:i}=e;return i(["Restituisce i risultati della ricerca solo dal sito Web o dal dominio specificato. Per impostazione predefinita esegue la ricerca in tutto il Web."])},stream_mode:e=>{const{normalize:i}=e;return i(["Modalità flusso"])},stream_mode_explain:e=>{const{normalize:i}=e;return i(["La modalità streaming è vantaggiosa per le pagine di destinazione di grandi dimensioni, poiché consente più tempo per il rendering completo della pagina. Se la modalità standard genera contenuti incompleti, prendi in considerazione l'utilizzo della modalità Stream."])},target_selector:e=>{const{normalize:i}=e;return i(["Selettore di destinazione"])},target_selector_explain:e=>{const{normalize:i}=e;return i(["Fornisci un elenco di selettori CSS per concentrarti su parti più specifiche della pagina. Utile quando il contenuto desiderato non viene visualizzato nelle impostazioni predefinite."])},text:e=>{const{normalize:i}=e;return i(["Testo"])},text_explain:e=>{const{normalize:i}=e;return i(["Restituisce document.body.innerText."])},wait_for_selector:e=>{const{normalize:i}=e;return i(["Attendi il selettore"])},wait_for_selector_explain:e=>{const{normalize:i}=e;return i(["Fornisci un elenco di selettori CSS per attendere che elementi specifici appaiano prima di tornare. Utile quando il contenuto desiderato non viene visualizzato nelle impostazioni predefinite."])},with_iframe:e=>{const{normalize:i}=e;return i(["Iframe"])},with_iframe_explain:e=>{const{normalize:i}=e;return i(["Il risultato restituito includerà anche il contenuto degli iframe presenti sulla pagina."])},with_shadow_dom:e=>{const{normalize:i}=e;return i(["Ombra DOM"])},with_shadow_dom_explain:e=>{const{normalize:i}=e;return i(["Il risultato restituito includerà anche il contenuto dello shadow DOM sulla pagina."])},x_timeout:e=>{const{normalize:i}=e;return i(["Tempo scaduto"])},x_timeout_explain:e=>{const{normalize:i}=e;return i(["Tempo massimo di attesa per il caricamento della pagina web. Nota che questo NON è il tempo totale per l'intera richiesta end-to-end."])}},how_to_stream:e=>{const{normalize:i}=e;return i(["Per elaborare il contenuto non appena diventa disponibile, imposta l'intestazione della richiesta sulla modalità streaming. Ciò riduce al minimo il tempo necessario alla ricezione del primo byte. Esempio nell'arricciatura:"])},how_to_use1:e=>{const{normalize:i}=e;return i(["Aggiungi https://r.jina.ai/ a qualsiasi URL nel tuo codice o strumento in cui è previsto l'accesso LLM. Ciò restituirà il contenuto principale della pagina in un testo pulito e compatibile con LLM."])},how_to_use2:e=>{const{normalize:i}=e;return i(["Aggiungi https://s.jina.ai/ alla tua query. Questo chiamerà il motore di ricerca e restituirà i primi 5 risultati con i relativi URL e contenuti, ciascuno in testo pulito e compatibile con LLM."])},how_to_use3:e=>{const{normalize:i}=e;return i(["Aggiungi https://g.jina.ai/ alla tua affermazione. Questo chiamerà il motore di giudizio e restituirà la percentuale di veridicità, un valore booleano che indica se l'affermazione è vera o falsa, un riepilogo della motivazione e un elenco di riferimenti."])},key_required:e=>{const{normalize:i}=e;return i(["Chiave API richiesta per utilizzare questo endpoint"])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di più"])},open:e=>{const{normalize:i}=e;return i(["Apri in una nuova scheda"])},raw_html:e=>{const{normalize:i}=e;return i(["HTML grezzo"])},reader_output:e=>{const{normalize:i}=e;return i(["Uscita del lettore"])},reader_response:e=>{const{normalize:i}=e;return i(["La risposta del lettore"])},reader_search_hint:e=>{const{normalize:i}=e;return i(["Se utilizzi questo URL nel codice, non dimenticare di codificare l'URL."])},reader_url:e=>{const{normalize:i}=e;return i(["URL del lettore"])},reader_url_hint:e=>{const{normalize:i}=e;return i(["Fai clic di seguito per ottenere il contenuto tramite la nostra API Reader"])},requires_post_method:e=>{const{normalize:i}=e;return i(["Questa funzione richiede il metodo POST. Caricando il tuo file locale, il metodo POST verrà attivato automaticamente."])},search_params:e=>{const{normalize:i}=e;return i(["Parametri di ricerca/intestazioni"])},search_query_rewrite:e=>{const{normalize:i}=e;return i(["Tieni presente che, a differenza della demo mostrata sopra, in pratica non cerchi la domanda originale sul web per il grounding. Ciò che le persone fanno spesso è riscrivere la domanda originale o utilizzare domande multi-hop. Leggono i risultati recuperati e quindi generano ulteriori query per raccogliere più informazioni necessarie prima di arrivare a una risposta finale."])},select_mode:e=>{const{normalize:i}=e;return i(["Seleziona modalità"])},show_read_demo:e=>{const{normalize:i}=e;return i(["Scopri come Reader legge un URL"])},show_search_demo:e=>{const{normalize:i}=e;return i(["Scopri come Reader effettua ricerche sul Web"])},slow_warning:e=>{const{normalize:i}=e;return i(["Questa operazione potrebbe richiedere fino a 30 secondi e costare fino a 300.000 token per richiesta."])},standard_usage:e=>{const{normalize:i}=e;return i(["Utilizzo standard"])},stream_mode:e=>{const{normalize:i}=e;return i(["Modalità flusso"])},stream_mode_explain:e=>{const{normalize:i}=e;return i(["La modalità stream è utile quando la pagina di destinazione è grande da visualizzare. Se ritieni che la modalità standard ti fornisca contenuti incompleti, prova la modalità streaming."])},stream_mode_explain1:e=>{const{normalize:i}=e;return i(["La modalità streaming è utile quando si riscontra che la modalità standard fornisce un risultato incompleto. Questo perché la modalità streaming attenderà un po' più a lungo finché la pagina non sarà completamente renderizzata. Utilizza l'intestazione di accettazione per attivare/disattivare la modalità di streaming:"])},tagline:e=>{const{normalize:i}=e;return i(["Prova la demo"])},try_demo:e=>{const{normalize:i}=e;return i(["Dimostrazione"])},use_headers:e=>{const{normalize:i}=e;return i(["Il comportamento dell'API Reader può essere controllato con le intestazioni della richiesta. Ecco un elenco completo delle intestazioni supportate."])},waiting_for_reader:e=>{const{normalize:i}=e;return i(["In attesa prima del risultato dell'API Reader..."])},warn_grounding_message:e=>{const{normalize:i}=e;return i(["Questo processo potrebbe richiedere fino a 30 secondi e consumare fino a 300K token per richiesta di grounding. Alcuni browser potrebbero terminare la richiesta a causa della lunga latenza, quindi ti consigliamo di copiare il codice ed eseguirlo dal tuo terminale."])},warn_grounding_title:e=>{const{normalize:i}=e;return i(["Elevata latenza e utilizzo di token"])},your_query:e=>{const{normalize:i}=e;return i(["Inserisci la tua domanda"])},your_query_hint:e=>{const{normalize:i}=e;return i(["Digita una domanda che richiede le informazioni più recenti o la conoscenza del mondo."])},your_url:e=>{const{normalize:i}=e;return i(["Inserisci il tuo URL"])},your_url_hint:e=>{const{normalize:i}=e;return i(["Fai clic di seguito per recuperare direttamente il codice sorgente della pagina"])}},description:e=>{const{normalize:i}=e;return i(["Leggi gli URL e cerca sul web per ottenere LLM più approfonditi."])},dont_panic_api_key_is_free:e=>{const{normalize:i}=e;return i(["Niente panico! Ogni nuova chiave API contiene un milione di token gratuiti!"])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i([`L'API Reader è gratuita e non richiede una chiave API. Basta anteporre "https://r.jina.ai/" al tuo URL.`])},answer10:e=>{const{normalize:i}=e;return i(["No, l'API Reader può elaborare solo contenuti provenienti da URL accessibili pubblicamente."])},answer11:e=>{const{normalize:i}=e;return i(["Se richiedi lo stesso URL entro 5 minuti, l'API Reader restituirà il contenuto memorizzato nella cache."])},answer12:e=>{const{normalize:i}=e;return i(["Sfortunatamente no."])},answer13:e=>{const{normalize:i}=e;return i(["Sì, puoi utilizzare il supporto PDF nativo dal Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) o utilizzare la versione HTML da arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)"])},answer14:e=>{const{normalize:i}=e;return i([`Reader sottotitola tutte le immagini all'URL specificato e aggiunge "Immagine [idx]: [didascalia]" come tag alt (se inizialmente ne manca uno). Ciò consente ai LLM a valle di interagire con le immagini nel ragionamento, nel riepilogo, ecc.`])},answer15:e=>{const{normalize:i}=e;return i(["L'API Reader è progettata per essere altamente scalabile. Viene ridimensionato automaticamente in base al traffico in tempo reale e il numero massimo di richieste simultanee è ora di circa 4000. Lo manteniamo attivamente come uno dei prodotti principali di Jina AI. Quindi sentitevi liberi di usarlo in produzione."])},answer16:e=>{const{normalize:i}=e;return i(["Puoi trovare le informazioni più recenti sui limiti di tariffa nella tabella seguente. Tieni presente che stiamo lavorando attivamente per migliorare il limite di velocità e le prestazioni dell'API Reader, la tabella verrà aggiornata di conseguenza."])},answer2:e=>{const{normalize:i}=e;return i(["L'API Reader utilizza un proxy per recuperare qualsiasi URL, visualizzandone il contenuto in un browser per estrarre contenuti principali di alta qualità."])},answer3:e=>{const{normalize:i}=e;return i(["Sì, l'API Reader è open source e disponibile nel repository Jina AI GitHub."])},answer4:e=>{const{normalize:i}=e;return i(["L'API Reader generalmente elabora gli URL e restituisce il contenuto entro 2 secondi, sebbene le pagine complesse o dinamiche potrebbero richiedere più tempo."])},answer5:e=>{const{normalize:i}=e;return i(["Lo scraping può essere complicato e inaffidabile, in particolare con pagine complesse o dinamiche. L'API Reader fornisce un output ottimizzato e affidabile di testo pulito e pronto per LLM."])},answer6:e=>{const{normalize:i}=e;return i(["L'API Reader restituisce il contenuto nella lingua originale dell'URL. Non fornisce servizi di traduzione."])},answer7:e=>{const{normalize:i}=e;return i(["Se riscontri problemi di blocco, contatta il nostro team di supporto per assistenza e risoluzione."])},answer8:e=>{const{normalize:i}=e;return i(["Sebbene progettata principalmente per le pagine Web, l'API Reader può estrarre contenuto dai PDF visualizzati in formato HTML su siti Web come arXiv, ma non è ottimizzata per l'estrazione PDF generale."])},answer9:e=>{const{normalize:i}=e;return i(["Attualmente, l'API Reader non elabora i contenuti multimediali, ma i miglioramenti futuri includeranno i sottotitoli delle immagini e il riepilogo dei video."])},question1:e=>{const{normalize:i}=e;return i(["Quali sono i costi associati all'utilizzo dell'API Reader?"])},question10:e=>{const{normalize:i}=e;return i(["È possibile utilizzare l'API Reader su file HTML locali?"])},question11:e=>{const{normalize:i}=e;return i(["L'API Reader memorizza nella cache il contenuto?"])},question12:e=>{const{normalize:i}=e;return i(["Posso utilizzare l'API Reader per accedere ai contenuti dietro un login?"])},question13:e=>{const{normalize:i}=e;return i(["Posso utilizzare l'API Reader per accedere ai PDF su arXiv?"])},question14:e=>{const{normalize:i}=e;return i(["Come funziona la didascalia delle immagini in Reader?"])},question15:e=>{const{normalize:i}=e;return i(["Qual è la scalabilità del Reader? Posso usarlo in produzione?"])},question16:e=>{const{normalize:i}=e;return i(["Qual è il limite di velocità dell'API Reader?"])},question2:e=>{const{normalize:i}=e;return i(["Come funziona l'API Reader?"])},question3:e=>{const{normalize:i}=e;return i(["L'API Reader è open source?"])},question4:e=>{const{normalize:i}=e;return i(["Qual è la latenza tipica per l'API Reader?"])},question5:e=>{const{normalize:i}=e;return i(["Perché dovrei utilizzare l'API Reader invece di raschiare la pagina da solo?"])},question6:e=>{const{normalize:i}=e;return i(["L'API Reader supporta più lingue?"])},question7:e=>{const{normalize:i}=e;return i(["Cosa devo fare se un sito web blocca l'API Reader?"])},question8:e=>{const{normalize:i}=e;return i(["L'API Reader può estrarre il contenuto dai file PDF?"])},question9:e=>{const{normalize:i}=e;return i(["L'API Reader può elaborare i contenuti multimediali dalle pagine Web?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative ai lettori"])}},fast:e=>{const{normalize:i}=e;return i(["Veloce"])},fast_stream:e=>{const{normalize:i}=e;return i(["Streaming immediato dei dati"])},fast_stream_description:e=>{const{normalize:i}=e;return i(["Hai bisogno di dati velocemente? La nostra API Reader può eseguire lo streaming dei dati per ridurre al minimo la latenza."])},free:e=>{const{normalize:i}=e;return i(["Libero per sempre"])},free_description:e=>{const{normalize:i}=e;return i(["L'API Reader è gratuita! Non richiede carta di credito o segreto API. Non consumerà la tua quota di token."])},is_free:e=>{const{normalize:i}=e;return i(["La parte migliore? È gratis!"])},is_free_description:e=>{const{normalize:i}=e;return i(["L'API Reader è disponibile gratuitamente e offre limiti di tariffa e prezzi flessibili. Costruito su un'infrastruttura scalabile, offre elevata accessibilità, concorrenza e affidabilità. Ci sforziamo di essere la soluzione di messa a terra preferita per i tuoi LLM."])},open:e=>{const{normalize:i}=e;return i(["Apri in una nuova scheda"])},original_pdf:e=>{const{normalize:i}=e;return i(["PDF originale"])},rate_limit:e=>{const{normalize:i}=e;return i(["Limite di tariffa"])},read_grounding_release_note:e=>{const{normalize:i}=e;return i(["Leggi la nota di rilascio"])},reader_also_read_images:e=>{const{normalize:i}=e;return i(["Le immagini sulla pagina Web vengono automaticamente sottotitolate utilizzando un modello di linguaggio visivo nel lettore e formattate come tag alt dell'immagine nell'output. Ciò fornisce al tuo LLM a valle suggerimenti sufficienti per incorporare tali immagini nei suoi processi di ragionamento e riepilogo. Ciò significa che puoi porre domande sulle immagini, selezionarne di specifiche o persino inoltrare i loro URL a un VLM più potente per un'analisi più approfondita!"])},reader_description:e=>{const{normalize:i}=e;return i(["Converti un URL in un input compatibile con LLM, semplicemente aggiungendo <code>r.jina.ai</code> davanti."])},reader_do_grounding:e=>{const{normalize:i}=e;return i(["Lettore per la verifica dei fatti"])},reader_do_grounding_explain:e=>{const{normalize:i}=e;return i(["Il nuovo endpoint di grounding offre un'esperienza di fact-checking end-to-end, quasi in tempo reale. Prende una data affermazione, la fonda utilizzando risultati di ricerca web in tempo reale e restituisce un punteggio di fattualità e i riferimenti esatti utilizzati. Puoi facilmente fondare le affermazioni per ridurre le allucinazioni LLM o migliorare l'integrità dei contenuti scritti da esseri umani."])},reader_do_pdf_explain:e=>{const{normalize:i}=e;return i(["Sì, Reader supporta nativamente la lettura di PDF. È compatibile con la maggior parte dei PDF, compresi quelli con molte immagini, ed è velocissimo! In combinazione con un LLM, puoi facilmente creare un ChatPDF o un'intelligenza artificiale per l'analisi dei documenti in pochissimo tempo."])},reader_do_search:e=>{const{normalize:i}=e;return i(["Lettore per la ricerca di messa a terra"])},reader_do_search_explain:e=>{const{normalize:i}=e;return i(["Gli LLM hanno un limite di conoscenza, il che significa che non possono accedere alle ultime conoscenze del mondo. Ciò porta a problemi come disinformazione, risposte obsolete, allucinazioni e altri problemi di fattualità. La messa a terra è assolutamente essenziale per le applicazioni GenAI. Reader ti consente di radicare il tuo LLM con le informazioni più recenti dal web. Basta anteporre https://s.jina.ai/ alla tua query e Reader effettuerà una ricerca sul Web e restituirà i primi cinque risultati con i relativi URL e contenuti, ciascuno in testo pulito e compatibile con LLM. In questo modo, puoi sempre mantenere aggiornato il tuo LLM, migliorarne la fattualità e ridurre le allucinazioni."])},reader_reads_images:e=>{const{normalize:i}=e;return i(["Il lettore legge anche le immagini!"])},reader_reads_pdf:e=>{const{normalize:i}=e;return i(["Reader legge anche i PDF!"])},reader_result:e=>{const{normalize:i}=e;return i(["Risultato del lettore"])},table:{td_1_0:e=>{const{normalize:i}=e;return i(["Leggere un URL e restituirne il contenuto, utile per verificare la messa a terra"])},td_1_1:e=>{const{normalize:i}=e;return i(["20 giri al minuto"])},td_1_2:e=>{const{normalize:i}=e;return i(["200 giri al minuto"])},td_1_3:e=>{const{normalize:i}=e;return i(["In base ai token di output"])},td_1_4:e=>{const{normalize:i}=e;return i(["3 secondi"])},td_1_5:e=>{const{normalize:i}=e;return i(["3 secondi"])},td_2_0:e=>{const{normalize:i}=e;return i(["La ricerca sul Web restituisce i primi 5 risultati, utili per radicare la ricerca"])},td_2_1:e=>{const{normalize:i}=e;return i(["5 giri al minuto"])},td_2_2:e=>{const{normalize:i}=e;return i(["40 giri al minuto"])},td_2_3:e=>{const{normalize:i}=e;return i(["In base ai token di output per tutti e 5 i risultati della ricerca"])},td_2_4:e=>{const{normalize:i}=e;return i(["10 secondi"])},td_2_5:e=>{const{normalize:i}=e;return i(["10 secondi"])},th0:e=>{const{normalize:i}=e;return i(["Punto finale"])},th1:e=>{const{normalize:i}=e;return i(["Descrizione"])},th2:e=>{const{normalize:i}=e;return i(["Limite di velocità senza chiave API"])},th3:e=>{const{normalize:i}=e;return i(["Limite di velocità con chiave API"])},th4:e=>{const{normalize:i}=e;return i(["Schema di conteggio dei token"])},th5:e=>{const{normalize:i}=e;return i(["Latenza media"])},th6:e=>{const{normalize:i}=e;return i(["Latenza media"])}},title:e=>{const{normalize:i}=e;return i(["API del lettore"])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},usage_details_false:e=>{const{normalize:i}=e;return i(["Mostra solo gli utilizzi di base"])},usage_details_null:e=>{const{normalize:i}=e;return i(["Mostra gli usi di base e avanzati"])},usage_details_true:e=>{const{normalize:i}=e;return i(["Mostra solo gli usi avanzati"])},want_higher_rate_limit:e=>{const{normalize:i}=e;return i(["Desideri un limite di velocità più elevato fino a 1000 RPM? Possiamo supportarti!"])},what_is1:e=>{const{normalize:i}=e;return i(["Cos'è Reader?"])},what_is_answer_long:e=>{const{normalize:i}=e;return i(["L'inserimento delle informazioni web nei LLM è un passo importante per radicarsi, ma può essere impegnativo. Il metodo più semplice è raschiare la pagina web e alimentare l'HTML grezzo. Tuttavia, lo scraping può essere complesso e spesso bloccato e l'HTML grezzo è ingombro di elementi estranei come markup e script. L'API Reader risolve questi problemi estraendo il contenuto principale da un URL e convertendolo in testo pulito e compatibile con LLM, garantendo input di alta qualità per il tuo agente e i sistemi RAG."])},what_is_desc:e=>{const{normalize:i}=e;return i(["Un proxy che accede a qualsiasi URL e trasforma il contenuto principale in testo semplice ottimizzato per LLM."])}},recommender:{confirm_message:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Nella tua chiave API restano ",n(o("_leftTokens"))," token. L'invio del testo completo degli articoli ",n(o("_numArticles"))," all'API Reranker, utilizzando il modello ",n(o("_selectedReranker"))," per scoprire articoli correlati per la pagina corrente, ridurrà in modo significativo il conteggio dei token della tua chiave API ",n(o("_APIKey")),". Vuoi procedere?"])},confirm_title:e=>{const{normalize:i}=e;return i(["Avvertenza: utilizzo elevato di token"])},out_of_quota:e=>{const{normalize:i}=e;return i(["Questa chiave API ha esaurito i token. Ricarica il tuo account o utilizza una chiave API diversa."])},recommend:e=>{const{normalize:i}=e;return i(["Ottieni i primi 5"])},recommended_articles:e=>{const{normalize:i}=e;return i(["Primi 5 articoli simili"])}},reranker:{benchmark:{description0:e=>{const{normalize:i}=e;return i(["LlamaIndex ha valutato varie combinazioni di incorporamenti e reranker per RAG, conducendo uno studio di replica che ha misurato il rango reciproco medio. I risultati evidenziano il significativo miglioramento della qualità della ricerca apportato da Jina Reranker, un vantaggio indipendente dagli specifici incorporamenti utilizzati."])},description1:e=>{const{normalize:i}=e;return i(["BIER (Benchmarking IR) valuta l'efficacia del recupero di un modello, inclusi la pertinenza e l'NDCG. Un punteggio BIER più elevato è correlato a corrispondenze e classifiche dei risultati di ricerca più accurate."])},description2:e=>{const{normalize:i}=e;return i(["Attraverso il benchmark LoCo, abbiamo misurato la comprensione di un modello della coerenza e del contesto locale, insieme alla classificazione specifica della query. Un punteggio LoCo più alto riflette una migliore capacità di identificare e dare priorità alle informazioni rilevanti."])},description3:e=>{const{normalize:i}=e;return i(["L'MTEB (Multilingual Text Embedding Benchmark), nel complesso, mette alla prova le capacità di un modello negli incorporamenti di testo, inclusi clustering, classificazione, recupero e altri parametri. Tuttavia, per il nostro confronto, abbiamo utilizzato solo le attività di riclassificazione di MTEB."])},title:e=>{const{normalize:i}=e;return i(["Segno di riferimento"])},title0:e=>{const{normalize:i}=e;return i(["LlamaIndex"])},title1:e=>{const{normalize:i}=e;return i(["BEIR"])},title2:e=>{const{normalize:i}=e;return i(["LoCo"])},title3:e=>{const{normalize:i}=e;return i(["MTEB"])}},benchmark_description:e=>{const{normalize:i}=e;return i(["Per fare un confronto, abbiamo incluso nel benchmark altri tre principali reranker di BGE (BAAI), BCE (Netease Youdao) e Cohere. Come mostrato dai risultati di seguito, Jina Reranker detiene il punteggio medio più alto in tutte le categorie rilevanti per il riranking, rendendolo un chiaro leader tra i suoi pari."])},benchmark_title:e=>{const{normalize:i}=e;return i(["Benchmark delle prestazioni"])},choose_turbo:e=>{const{normalize:i}=e;return i(["Ottieni una velocità fino a 5 volte superiore con reranker-turbo"])},choose_turbo_description:e=>{const{normalize:i}=e;return i(["Offriamo anche due nuovi modelli di reranker open source: jina-reranker-v1-turbo-en e jina-reranker-v1-tiny-en, quest'ultimo ha solo 30 milioni di parametri e quattro livelli. Questi due nuovi reranker godono di una velocità di inferenza 5 volte più veloce rispetto al modello base con un costo molto basso in termini di qualità. Sono perfetti per le applicazioni che richiedono il riclassificazione in tempo reale. Leggi il benchmark qui sotto."])},customize_urself:e=>{const{normalize:i}=e;return i(["Cambialo e guarda come cambia la risposta!"])},customize_urself_pl:e=>{const{normalize:i}=e;return i(["Cambiali e guarda come cambia la risposta!"])},description:e=>{const{normalize:i}=e;return i(["Recupero neurale di livello mondiale per massimizzare la pertinenza della ricerca."])},description_rich:e=>{const{normalize:i}=e;return i(["Massimizza la pertinenza della ricerca e la precisione del RAG con la nostra API di riclassificazione all'avanguardia."])},example_input_document:e=>{const{normalize:i}=e;return i(["Esempi di documenti candidati da classificare"])},example_input_query:e=>{const{normalize:i}=e;return i(["Interrogazione di esempio"])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i(["I prezzi per l'API Reranker sono in linea con la nostra struttura dei prezzi dell'API Embedding. Si inizia con 1 milione di token gratuiti per ogni nuova chiave API. Oltre ai token gratuiti, sono disponibili per l'acquisto diversi pacchetti. Per maggiori dettagli, visita la nostra sezione prezzi."])},answer10:e=>{const{normalize:i}=e;return i(["Sì, Jina Reranker può essere distribuito su AWS. Se hai bisogno di una distribuzione locale in un ambiente aziendale, puoi farlo facilmente tramite la nostra offerta AWS Marketplace."])},answer11:e=>{const{normalize:i}=e;return i(["Se sei interessato a un reranking ottimizzato su misura per dati di dominio specifici, contatta il nostro team di vendita. Il nostro team risponderà tempestivamente alla tua richiesta."])},answer3:e=>{const{normalize:i}=e;return i(["La differenza principale sta nella loro architettura. Per quanto riguarda le prestazioni, consigliamo jina-reranker-v1, che è stato ampiamente testato e confrontato con la concorrenza. Jina-reranker-v1 utilizza un'architettura cross-encoder, mentre Jina-colbert-v1 si basa sull'architettura ColBERTv2 ma estende la lunghezza del contesto sia della query che del documento a 8192, ottenendo prestazioni ancora migliori rispetto al modello ColBERTv2 originale."])},answer4:e=>{const{normalize:i}=e;return i(["Sì, jina-colbert-v1 è open source ed è possibile accedervi tramite Huggingface. Tuttavia, jina-reranker-v1 non è open source."])},answer5:e=>{const{normalize:i}=e;return i(["Attualmente supporta solo l'inglese. Tuttavia, alcuni utenti hanno segnalato che funziona bene anche con il cinese. Ciò potrebbe essere in parte dovuto al fatto che jina-reranker-v1-base-en condivide alcuni pesi con il nostro modello di incorporamento jina-embeddings-v2-base-zh."])},answer6:e=>{const{normalize:i}=e;return i(["La lunghezza massima del token di query è 512. Non esiste alcun limite di token per i documenti."])},answer7:e=>{const{normalize:i}=e;return i(["Puoi riclassificare fino a 2048 documenti per query."])},answer8:e=>{const{normalize:i}=e;return i(["Non esiste il concetto di dimensione batch a differenza della nostra API di incorporamento. È possibile inviare solo una tupla di documento di query per richiesta, ma la tupla può includere fino a 2048 documenti candidati."])},answer9:e=>{const{normalize:i}=e;return i(["La latenza varia da 100 millisecondi a 7 secondi, a seconda in gran parte della lunghezza dei documenti e della query. Ad esempio, la riclassificazione di 100 documenti di 256 token ciascuno con una query da 64 token richiede circa 150 millisecondi. Aumentando la lunghezza del documento a 4096 token, il tempo aumenta a 3,5 secondi. Se la lunghezza della query viene aumentata a 512 token, il tempo aumenta ulteriormente a 7 secondi."])},question1:e=>{const{normalize:i}=e;return i(["Quanto costa l'API Reranker?"])},question10:e=>{const{normalize:i}=e;return i(["Posso distribuire Jina Reranker su AWS?"])},question11:e=>{const{normalize:i}=e;return i(["Offrite un reranking ottimizzato sui dati specifici del dominio?"])},question3:e=>{const{normalize:i}=e;return i(["Qual è la differenza tra i due reranker?"])},question4:e=>{const{normalize:i}=e;return i(["Jina Reranker è open source?"])},question5:e=>{const{normalize:i}=e;return i(["Il reranker supporta più lingue?"])},question6:e=>{const{normalize:i}=e;return i(["Qual è la lunghezza massima per query e documenti?"])},question7:e=>{const{normalize:i}=e;return i(["Qual è il numero massimo di documenti che posso riclassificare per query?"])},question8:e=>{const{normalize:i}=e;return i(["Qual è la dimensione del batch e quante tuple di documenti di query posso inviare in una richiesta?"])},question9:e=>{const{normalize:i}=e;return i(["Quale latenza posso aspettarmi quando riclassifico 100 documenti?"])},title:e=>{const{normalize:i}=e;return i(["Domande comuni relative al riclassificazione"])}},feature_on_premises_description2:e=>{const{normalize:i}=e;return i(["Distribuisci Jina Reranker su AWS Sagemaker e presto anche su Microsoft Azure e sui servizi cloud di Google oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_on_premises_description3:e=>{const{normalize:i}=e;return i(["Distribuisci Jina Reranker su AWS Sagemaker e Microsoft Azure e presto nei servizi cloud di Google, oppure contatta il nostro team di vendita per ottenere distribuzioni Kubernetes personalizzate per il tuo cloud privato virtuale e i server locali."])},feature_solid_description:e=>{const{normalize:i}=e;return i(["Sviluppato dalla nostra ricerca accademica all'avanguardia e rigorosamente testato rispetto ai reranker SOTA per garantire prestazioni senza precedenti."])},how_it_works:e=>{const{normalize:i}=e;return i(["Ecco come funziona:"])},how_it_works_v1:{description1:e=>{const{normalize:i}=e;return i(["Un sistema di ricerca utilizza embeddings/BM25 per trovare un'ampia serie di documenti potenzialmente rilevanti in base alla query dell'utente."])},description2:e=>{const{normalize:i}=e;return i(["Il reranker prende quindi questi risultati e li analizza a un livello più granulare, considerando le sfumature di come i termini della query interagiscono con il contenuto del documento."])},description3:e=>{const{normalize:i}=e;return i(["Riordina i risultati della ricerca, posizionando quelli che ritiene più rilevanti in alto, sulla base di questa analisi più approfondita."])},title1:e=>{const{normalize:i}=e;return i(["Recupero iniziale"])},title2:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},title3:e=>{const{normalize:i}=e;return i(["Risultati migliorati"])}},improve_performance:e=>{const{normalize:i}=e;return i(["Miglioramento garantito rispetto alla ricerca vettoriale"])},improve_performance_description:e=>{const{normalize:i}=e;return i(["Le nostre valutazioni hanno dimostrato miglioramenti per i sistemi di ricerca che utilizzano Jina Reranker con +8% nel tasso di successo e +33% nel ranking reciproco medio."])},learning1:e=>{const{normalize:i}=e;return i(["Imparare a conoscere Reranker"])},learning1_description:e=>{const{normalize:i}=e;return i(["Cos'è un reranker? Perché la ricerca vettoriale o la somiglianza del coseno non sono sufficienti? Scopri i reranker da zero con la nostra guida completa."])},read_more_about_benchmark:e=>{const{normalize:i}=e;return i(["Ulteriori informazioni sul benchmark"])},read_more_about_turbo:e=>{const{normalize:i}=e;return i(["Maggiori informazioni sui modelli turbo e tiny"])},read_more_about_v2:e=>{const{normalize:i}=e;return i(["Jina Reranker v2 è il miglior reranker della categoria rilasciato il 25 giugno 2024; è costruito per Agentic RAG. È dotato di supporto per chiamate di funzioni, recupero multilingue per oltre 100 lingue, funzionalità di ricerca di codice e offre una velocità 6 volte superiore rispetto alla versione v1. Ulteriori informazioni sul modello v2."])},reranker_description:e=>{const{normalize:i}=e;return i(["Prova la nostra API di riclassificazione all'avanguardia per massimizzare la pertinenza della ricerca e la precisione del RAG. A partire gratis!"])},show_v2benchmark:e=>{const{normalize:i}=e;return i(["Mostra benchmark per il modello v2 (più recente)"])},table:{number_token_document:e=>{const{normalize:i}=e;return i(["Numero di token in ciascun documento"])},number_token_query:e=>{const{normalize:i}=e;return i(["Numero di token nella query"])},title:e=>{const{normalize:i}=e;return i(["Di seguito è riportato il tempo impiegato per riclassificare una query e 100 documenti in millisecondi:"])}},title:e=>{const{normalize:i}=e;return i(["API di riclassificazione"])},top_n:e=>{const{normalize:i}=e;return i(["Numero di documenti restituiti"])},top_n_explain:e=>{const{normalize:i}=e;return i(["Il numero di documenti più rilevanti da restituire per la query."])},try_embedding:e=>{const{normalize:i}=e;return i(["Prova a incorporare l'API gratuitamente"])},try_reranker:e=>{const{normalize:i}=e;return i(["Prova gratuitamente l'API reranker"])},v2_features:{description1:e=>{const{normalize:i}=e;return i(["Reranker v2 consente il recupero di documenti in oltre 100 lingue, indipendentemente dalla lingua della query."])},description2:e=>{const{normalize:i}=e;return i(["Reranker v2 classifica i frammenti di codice e le firme delle funzioni in base a query in linguaggio naturale, ideali per le applicazioni Agentic RAG."])},description3:e=>{const{normalize:i}=e;return i(["Reranker v2 classifica le tabelle più rilevanti in base a query in linguaggio naturale, aiutando a ordinare diversi schemi di tabelle e a identificare quello più rilevante prima di generare una query SQL."])},title1:e=>{const{normalize:i}=e;return i(["Recupero multilingue"])},title2:e=>{const{normalize:i}=e;return i(["Chiamata di funzioni e ricerca di codici"])},title3:e=>{const{normalize:i}=e;return i(["Supporto dati tabulari e strutturati"])}},v2benchmark:{descBeir:e=>{const{normalize:i}=e;return i(["Punteggi NDCG 10 riportati per diversi modelli di riclassificazione per il set di dati Beir"])},descCodeSearchNet:e=>{const{normalize:i}=e;return i(["Punteggi MRR 10 riportati per diversi modelli di riclassificazione per il set di dati CodeSearchNet"])},descMKQA:e=>{const{normalize:i}=e;return i(["Richiama 10 punteggi riportati per diversi modelli di riclassificazione per il set di dati MKQA"])},descNSText2SQL:e=>{const{normalize:i}=e;return i(["Richiama 3 punteggi riportati per diversi modelli di riclassificazione per il set di dati NSText2SQL"])},descRTX4090:e=>{const{normalize:i}=e;return i(["Punteggi di throughput (documenti recuperati in 50 ms) riportati per diversi modelli di riclassificazione su una GPU RTX 4090."])},descToolBench:e=>{const{normalize:i}=e;return i(["Richiama 3 punteggi riportati per diversi modelli di riclassificazione per il set di dati ToolBench"])},titleBeir:e=>{const{normalize:i}=e;return i(["BEIR (Benchmark eterogeneo su diversi compiti IR)"])},titleCodeSearchNet:e=>{const{normalize:i}=e;return i(["CodeSearchNet. Il benchmark è una combinazione di query in formato docstring e linguaggio naturale, con segmenti di codice etichettati pertinenti alle query."])},titleMKQA:e=>{const{normalize:i}=e;return i(["MKQA (Domande e risposte sulla conoscenza multilingue)"])},titleNSText2SQL:e=>{const{normalize:i}=e;return i(["NSText2SQL"])},titleRTX4090:e=>{const{normalize:i}=e;return i(["Velocità effettiva di Jina Reranker v2 su RTX4090"])},titleToolBench:e=>{const{normalize:i}=e;return i(["Banco degli attrezzi. Il benchmark raccoglie oltre 16mila API pubbliche e le corrispondenti istruzioni generate sinteticamente per utilizzarle in impostazioni API singole e multi-API."])}},vs_table:{col0:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},col0_1:e=>{const{normalize:i}=e;return i(["Maggiore precisione e pertinenza della ricerca"])},col0_2:e=>{const{normalize:i}=e;return i(["Filtraggio iniziale rapido"])},col0_3:e=>{const{normalize:i}=e;return i(["Recupero generale del testo attraverso query ad ampio raggio"])},col1:e=>{const{normalize:i}=e;return i(["Ricerca vettoriale"])},col1_1:e=>{const{normalize:i}=e;return i(["Dettagliato: documento secondario e segmento di query"])},col1_2:e=>{const{normalize:i}=e;return i(["Ampio: interi documenti"])},col1_3:e=>{const{normalize:i}=e;return i(["Intermedio: vari segmenti di testo"])},col2:e=>{const{normalize:i}=e;return i(["BM25"])},col2_1:e=>{const{normalize:i}=e;return i(["Alto"])},col2_2:e=>{const{normalize:i}=e;return i(["medio"])},col2_3:e=>{const{normalize:i}=e;return i(["Basso"])},col3_1:e=>{const{normalize:i}=e;return i(["Non richiesto"])},col3_2:e=>{const{normalize:i}=e;return i(["Alto"])},col3_3:e=>{const{normalize:i}=e;return i(["Basso, utilizza un indice predefinito"])},col4_1:e=>{const{normalize:i}=e;return i(["Alto"])},col4_2:e=>{const{normalize:i}=e;return i(["Alto"])},col4_3:e=>{const{normalize:i}=e;return i(["Non richiesto"])},col5_1:e=>{const{normalize:i}=e;return i(["Superiore per query sfumate"])},col5_2:e=>{const{normalize:i}=e;return i(["In equilibrio tra efficienza e precisione"])},col5_3:e=>{const{normalize:i}=e;return i(["Coerente e affidabile per un'ampia gamma di query"])},col6_1:e=>{const{normalize:i}=e;return i(["Altamente accurato con una profonda comprensione del contesto"])},col6_2:e=>{const{normalize:i}=e;return i(["Veloce ed efficiente, con una precisione moderata"])},col6_3:e=>{const{normalize:i}=e;return i(["Altamente scalabile, con efficacia consolidata"])},col7_1:e=>{const{normalize:i}=e;return i(["Ad alta intensità di risorse con implementazione complessa"])},col7_2:e=>{const{normalize:i}=e;return i(["Potrebbe non acquisire il contesto o le sfumature approfondite della query"])},col7_3:e=>{const{normalize:i}=e;return i(["Potrebbe avere prestazioni inferiori per ricerche altamente specifiche o contestuali"])},header0:e=>{const{normalize:i}=e;return i(["Ideale per"])},header1:e=>{const{normalize:i}=e;return i(["Granularità"])},header2:e=>{const{normalize:i}=e;return i(["Complessità temporale delle query"])},header3:e=>{const{normalize:i}=e;return i(["Complessità temporale dell'indicizzazione"])},header4:e=>{const{normalize:i}=e;return i(["Complessità del tempo di allenamento"])},header5:e=>{const{normalize:i}=e;return i(["Ricerca di qualità"])},header6:e=>{const{normalize:i}=e;return i(["Punti di forza"])},header7:e=>{const{normalize:i}=e;return i(["Punti deboli"])},subtitle:e=>{const{normalize:i}=e;return i(["La tabella seguente fornisce un confronto completo tra Reranker, ricerca di vettori/incorporamenti e BM25, evidenziandone i punti di forza e di debolezza nelle varie categorie."])},title:e=>{const{normalize:i}=e;return i(["Confronto tra Reranker, Ricerca vettoriale e BM25"])}},what_is:e=>{const{normalize:i}=e;return i(["Cos'è un reranker?"])},what_is_answer_long:e=>{const{normalize:i}=e;return i([`L'obiettivo di un sistema di ricerca è trovare i risultati più pertinenti in modo rapido ed efficiente. Tradizionalmente, metodi come BM25 o tf-idf sono stati utilizzati per classificare i risultati di ricerca in base alla corrispondenza delle parole chiave. Metodi recenti, come la somiglianza del coseno basata sull'incorporamento, sono stati implementati in molti database vettoriali. Questi metodi sono semplici ma a volte possono non cogliere le sottigliezze del linguaggio e, soprattutto, l'interazione tra i documenti e l'intento di una query.

È qui che brilla il "reranker". Un reranker è un modello di intelligenza artificiale avanzato che prende il set iniziale di risultati da una ricerca, spesso forniti da una ricerca basata su incorporamenti/token, e li rivaluta per garantire che siano più allineati con l'intento dell'utente. Si guarda oltre la corrispondenza superficiale dei termini per considerare l'interazione più profonda tra la query di ricerca e il contenuto dei documenti.`])},what_is_answer_long_ending:e=>{const{normalize:i}=e;return i(["Il reranker può migliorare significativamente la qualità della ricerca perché opera a livello di sottodocumento e sottoquery, il che significa che esamina le singole parole e frasi, i loro significati e il modo in cui si relazionano tra loro all'interno della query e dei documenti. Ciò si traduce in un insieme di risultati di ricerca più precisi e contestualmente pertinenti."])},what_is_desc:e=>{const{normalize:i}=e;return i(["Un reranker è un modello di intelligenza artificiale che affina i risultati della ricerca da una ricerca vettoriale o da un modello di recupero denso. Per saperne di più."])}},scenex:{caption_image_desc:e=>{const{normalize:i}=e;return i(["Genera una descrizione testuale dell'immagine."])},caption_image_title:e=>{const{normalize:i}=e;return i(["Immagine della didascalia"])},description:e=>{const{normalize:i}=e;return i(["Esplora la narrazione di immagini oltre i pixel"])},example1:e=>{const{normalize:i}=e;return i(["Questo video sembra essere un filmato naturalistico con un affascinante coniglietto bianco e una farfalla in un campo erboso. Il coniglietto viene visto interagire con la farfalla in diversi modi, mostrando la loro relazione unica. L'ambiente naturale offre uno sfondo pittoresco, esaltando la bellezza di questa scena semplice ma accattivante."])},generate_story_desc:e=>{const{normalize:i}=e;return i(["Crea una storia ispirata all'immagine, spesso con dialoghi o monologhi dei suoi personaggi."])},generate_story_title:e=>{const{normalize:i}=e;return i(["Genera storia"])},intro1:e=>{const{normalize:i}=e;return i(["Soluzione AI leader per didascalie di immagini e riepiloghi video"])},json_image_desc:e=>{const{normalize:i}=e;return i(["Genera un formato JSON strutturato dall'immagine utilizzando uno schema predefinito. Ciò consente l'estrazione di dati specifici dall'immagine."])},json_image_title:e=>{const{normalize:i}=e;return i(["Estrai JSON dall'immagine"])},summarize_video_desc:e=>{const{normalize:i}=e;return i(["Genera un riepilogo conciso del video, evidenziando gli eventi chiave."])},summarize_video_title:e=>{const{normalize:i}=e;return i(["Riepiloga il video"])},visual_q_a_desc:e=>{const{normalize:i}=e;return i(["Rispondi a una domanda in base al contenuto dell'immagine."])},visual_q_a_title:e=>{const{normalize:i}=e;return i(["Domande e risposte visive"])}},searchbar:{ask_on_current_page:e=>{const{normalize:i}=e;return i(["Chiedi alla pagina corrente informazioni su..."])},find_solution:e=>{const{normalize:i}=e;return i(["Genera una soluzione per..."])},hint:e=>{const{normalize:i}=e;return i(["Cerca tra prodotti, novità e le tue domande"])},hotkey:e=>{const{normalize:i}=e;return i(["Premere il tasto / per effettuare la ricerca in questa pagina"])},hotkey1:e=>{const{normalize:i}=e;return i(["Premere"])},hotkey2:e=>{const{normalize:i}=e;return i(["per attivare"])},hotkey_long1:e=>{const{normalize:i}=e;return i(["In qualsiasi momento, premere"])},hotkey_long3:e=>{const{normalize:i}=e;return i(["per aprire la barra di ricerca"])},more_results:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_numMore"))," altri risultati"])},placeholder:e=>{const{normalize:i}=e;return i(["Fai qualsiasi domanda in questa pagina"])},proposing_solution:e=>{const{normalize:i}=e;return i(["Generazione della risposta in base al contenuto della pagina..."])},required:e=>{const{normalize:i}=e;return i(["Descrivi la tua domanda con maggiori dettagli."])},results:e=>{const{normalize:i}=e;return i(["risultati"])}},searchscape:{description:e=>{const{normalize:i}=e;return i(["Naviga, interagisci, perfeziona: reinventa la scoperta del prodotto"])}},semantic:{description:e=>{const{normalize:i}=e;return i(["Colmare il divario semantico nella tua infrastruttura di ricerca esistente"])}},share:{"Hacker News":e=>{const{normalize:i}=e;return i(["Notizie sugli hacker"])},LinkedIn:e=>{const{normalize:i}=e;return i(["LinkedIn"])},facebook:e=>{const{normalize:i}=e;return i(["Facebook"])},reddit:e=>{const{normalize:i}=e;return i(["Reddit"])},rss:e=>{const{normalize:i}=e;return i(["RSS Feed"])},share_btn:e=>{const{normalize:i}=e;return i(["Condividere"])},twitter:e=>{const{normalize:i}=e;return i(["X (Twitter)"])}},spectrum:{click_to_learn_more:e=>{const{normalize:i}=e;return i(["Clicca per saperne di più"])},contextualization:e=>{const{normalize:i}=e;return i(["Contestualizzazione"])},contextualization_desc:e=>{const{normalize:i}=e;return i(["I reranker regolano i risultati della ricerca iniziale in base alla profonda pertinenza contestuale. domanda. Ciò perfeziona la classifica per corrispondere meglio a ciò che gli utenti potrebbero trovare utile."])},coreInfra:e=>{const{normalize:i}=e;return i(["Core Infra"])},coreInfra_desc:e=>{const{normalize:i}=e;return i(["Core Infra fornisce un livello cloud-native per lo sviluppo, l'implementazione e l'orchestrazione di modelli di base della ricerca sia nel cloud pubblico che on-premise, consentendo ai servizi di scalare verso l'alto e verso il basso senza sforzo."])},embedding_serving:e=>{const{normalize:i}=e;return i(["Incorporamento della pubblicazione"])},embedding_serving_description:e=>{const{normalize:i}=e;return i(["Fornire incorporamenti tramite un microservizio robusto e scalabile utilizzando tecnologie native del cloud."])},embedding_tech:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},embedding_tech_description:e=>{const{normalize:i}=e;return i([`In Jina AI, sfruttiamo la potenza dell'integrazione della tecnologia per rivoluzionare diverse applicazioni di intelligenza artificiale. Questa tecnologia funge da metodo unificato per rappresentare e comprimere in modo efficiente vari tipi di dati, garantendo l'assenza di perdita di informazioni critiche. Il nostro obiettivo è trasformare set di dati complessi in un formato di incorporamento universalmente comprensibile, essenziale per un'analisi AI precisa e approfondita.

Gli incorporamenti sono fondamentali, soprattutto in applicazioni come il riconoscimento preciso di immagini e voce, dove aiutano a distinguere dettagli e sfumature a grana fine. Nell'elaborazione del linguaggio naturale, gli incorporamenti migliorano la comprensione del contesto e del sentimento, portando a strumenti di intelligenza artificiale conversazionale e di traduzione linguistica più accurati. Sono inoltre cruciali nello sviluppo di sofisticati sistemi di raccomandazione che richiedono una profonda comprensione delle preferenze degli utenti attraverso diverse forme di contenuto, come testo, audio e video.`])},embedding_tuning:e=>{const{normalize:i}=e;return i(["Incorporamento dell'ottimizzazione"])},embedding_tuning_description:e=>{const{normalize:i}=e;return i(["Ottimizzazione degli incorporamenti di alta qualità integrando le competenze del settore per migliorare le prestazioni specifiche delle attività."])},embeddings:e=>{const{normalize:i}=e;return i(["Incorporamenti"])},embeddings_desc:e=>{const{normalize:i}=e;return i(["Gli incorporamenti sono i pilastri del moderno sistema di ricerca, rappresentando dati multimodali in vettori di numeri. Questo processo consente una comprensione più sfumata e contestuale dei contenuti, ben oltre la semplice corrispondenza delle parole chiave."])},for_developers:e=>{const{normalize:i}=e;return i(["Per gli sviluppatori"])},for_enterprise:e=>{const{normalize:i}=e;return i(["Per le Imprese"])},for_power_users:e=>{const{normalize:i}=e;return i(["Per utenti esperti"])},grounding:e=>{const{normalize:i}=e;return i(["Messa a terra"])},grounding_desc:e=>{const{normalize:i}=e;return i(["Lettore che perfeziona input e risultati attraverso LLM. Migliorano la qualità, la leggibilità e la fattualità della risposta finale."])},model_serving:e=>{const{normalize:i}=e;return i(["Modello che serve"])},model_serving_description:e=>{const{normalize:i}=e;return i(["La distribuzione di modelli ottimizzati in un ambiente di produzione, che in genere richiede risorse sostanziali come l'hosting GPU. MLOps, enfatizzando la fornitura di modelli di medie e grandi dimensioni in modo scalabile, efficiente e affidabile."])},model_tuning:e=>{const{normalize:i}=e;return i(["Messa a punto del modello"])},model_tuning_description:e=>{const{normalize:i}=e;return i(["Conosciuto anche come fine tuning, comporta la regolazione dei parametri di un modello preaddestrato su un nuovo set di dati, spesso specifico per attività, per migliorarne le prestazioni e adattarlo a un'applicazione specifica."])},personalization:e=>{const{normalize:i}=e;return i(["Personalizzazione"])},personalization_desc:e=>{const{normalize:i}=e;return i(["Utilizzo di dati sintetici guidati dalle istruzioni dell'utente per addestrare automaticamente un modello di incorporamento e riclassificazione specifico del dominio."])},preprocessing:e=>{const{normalize:i}=e;return i(["Pre-elaborazione"])},preprocessing_desc:e=>{const{normalize:i}=e;return i(["La pre-elaborazione comporta la pulizia, la normalizzazione e la trasformazione dei dati grezzi in un formato digeribile dal sistema di ricerca."])},promptOps:e=>{const{normalize:i}=e;return i(["PromptOps"])},promptOps_desc:e=>{const{normalize:i}=e;return i(["Prompt Ops migliora l'input e l'output del sistema di ricerca, compresi quelli utilizzati nell'espansione delle query, nell'input LLM e nella riscrittura dei risultati. Ciò garantisce che la ricerca sia compresa meglio e dia risultati migliori."])},prompt_serving:e=>{const{normalize:i}=e;return i(["Servizio rapido"])},prompt_serving_description:e=>{const{normalize:i}=e;return i(["Wrapping e fornitura di prompt tramite un'API, senza ospitare modelli pesanti. L'API chiama un servizio di modello di linguaggio di grandi dimensioni pubblico e gestisce l'orchestrazione di input e output in una catena di operazioni."])},prompt_tech:e=>{const{normalize:i}=e;return i(["Ingegneria dei prompt e degli agenti"])},prompt_tech_description:e=>{const{normalize:i}=e;return i([`In Jina AI, riconosciamo che il prompt engineering è vitale per interagire con modelli linguistici di grandi dimensioni (LLM). Man mano che questi modelli avanzano, la complessità dei suggerimenti aumenta, comprendendo ragionamenti e logiche intricati. Questo progresso sottolinea la crescita intrecciata degli LLM e la rapida sofisticazione.

Prevediamo un futuro in cui gli LLM fungeranno da compilatori, con i prompt che diventeranno il nuovo linguaggio di programmazione. Questo cambiamento suggerisce che la futura competenza tecnologica potrebbe concentrarsi maggiormente sulla padronanza tempestiva rispetto alla codifica tradizionale. Il nostro impegno in Jina AI è quello di guidare in quest'area di trasformazione, rendendo l'intelligenza artificiale avanzata accessibile e pratica per l'uso quotidiano attraverso la padronanza di questo "linguaggio" emergente.`])},prompt_tuning:e=>{const{normalize:i}=e;return i(["Sintonizzazione rapida"])},prompt_tuning_description:e=>{const{normalize:i}=e;return i(["Il processo di creazione e raffinamento dell'input richiede al fine di guidare il suo output verso risposte specifiche e desiderate."])},representation:e=>{const{normalize:i}=e;return i(["Rappresentazione"])},representation_desc:e=>{const{normalize:i}=e;return i(["Gli incorporamenti trasformano i dati multimodali in un formato uniforme e vettoriale. Ciò consente al sistema di ricerca di comprendere e classificare i contenuti oltre le semplici parole chiave."])},rerankers:e=>{const{normalize:i}=e;return i(["Riclassificazione"])},rerankers_desc:e=>{const{normalize:i}=e;return i(["I reranker prendono i risultati iniziali dagli incorporamenti e li perfezionano, garantendo che all'utente vengano presentati i risultati più rilevanti. Questo è fondamentale per fornire risultati di ricerca di alta qualità che soddisfino le intenzioni dell'utente."])}},subscribe_system:{care_most:e=>{const{normalize:i}=e;return i(["Cosa ti interessa di più?"])},care_most_options:{accuracy:e=>{const{normalize:i}=e;return i(["Precisione"])},cost:e=>{const{normalize:i}=e;return i(["Costo"])},other:e=>{const{normalize:i}=e;return i(["Altro"])},scalability:e=>{const{normalize:i}=e;return i(["Scalabilità"])},speed:e=>{const{normalize:i}=e;return i(["Velocità"])}},care_most_required:e=>{const{normalize:i}=e;return i(["Quando scegli un servizio, cosa ti interessa di più?"])},company_size:e=>{const{normalize:i}=e;return i(["Qual è la dimensione della tua azienda?"])},company_size_required:e=>{const{normalize:i}=e;return i(["Raccontaci che le dimensioni della tua azienda ci aiutano a fornire un servizio migliore"])},company_url:e=>{const{normalize:i}=e;return i(["Qual è il sito web della tua azienda?"])},company_url_required:e=>{const{normalize:i}=e;return i(["Raccontaci che il sito web della tua azienda ci aiuta a fornire un servizio migliore"])},contactName:e=>{const{normalize:i}=e;return i(["Il tuo nome"])},contactName_required:e=>{const{normalize:i}=e;return i(["Come dovremmo rivolgerci a te?"])},contactTitle:e=>{const{normalize:i}=e;return i(["Qual è la tua mansione?"])},contactTitle_required:e=>{const{normalize:i}=e;return i(["Il tuo titolo professionale è obbligatorio"])},contact_us:e=>{const{normalize:i}=e;return i(["Contattaci"])},domain_required:e=>{const{normalize:i}=e;return i(["Raccontaci che il tuo dominio di lavoro ci aiuta a fornire un servizio migliore"])},email:e=>{const{normalize:i}=e;return i(["E-mail"])},email_contact:e=>{const{normalize:i}=e;return i(["La tua e-mail di contatto"])},email_invalid:e=>{const{normalize:i}=e;return i(["L'email non è valida"])},email_required:e=>{const{normalize:i}=e;return i(["L'e-mail è obbligatoria"])},fine_tuned_embedding:e=>{const{normalize:i}=e;return i(["Sei interessato a incorporamenti ottimizzati su misura per i tuoi dati e il tuo caso d'uso? Discutiamone!"])},fine_tuned_reranker:e=>{const{normalize:i}=e;return i(["Ti interessano riranker ottimizzati su misura per i tuoi dati e il tuo caso d'uso? Discutiamone!"])},full_survey:e=>{const{normalize:i}=e;return i(["Partecipa al sondaggio completo e ottieni una risposta più rapida dal nostro team"])},get_new_key:e=>{const{normalize:i}=e;return i(["Ottieni la tua chiave API"])},get_update_blog_posts:e=>{const{normalize:i}=e;return i(["Ricevi gli ultimi aggiornamenti per i post del blog"])},get_update_embeddings:e=>{const{normalize:i}=e;return i(["Ottieni gli ultimi aggiornamenti per gli incorporamenti"])},send:e=>{const{normalize:i}=e;return i(["Inviare"])},sign_up:e=>{const{normalize:i}=e;return i(["Iscrizione"])},subscribe:e=>{const{normalize:i}=e;return i(["sottoscrivi"])},tell_domain:e=>{const{normalize:i}=e;return i(["Raccontaci il tuo dominio"])},usage_type:e=>{const{normalize:i}=e;return i(["Quale tipo di utilizzo ti descrive meglio?"])},usage_type_options:{other:e=>{const{normalize:i}=e;return i(["Altro"])},poc:e=>{const{normalize:i}=e;return i(["Verifica teorica"])},production:e=>{const{normalize:i}=e;return i(["Produzione"])},research:e=>{const{normalize:i}=e;return i(["Ricerca"])}},usage_type_required:e=>{const{normalize:i}=e;return i(["Comunicaci che il tuo tipo di utilizzo ci aiuta a fornire un servizio migliore"])},used_product:e=>{const{normalize:i}=e;return i(["Quale modello stai utilizzando?"])},used_product_required:e=>{const{normalize:i}=e;return i(["Seleziona il modello che stai utilizzando o a cui sei interessato"])}},think_gpt:{description:e=>{const{normalize:i}=e;return i(["Tecniche di agente per aumentare il tuo LLM e spingerlo oltre i suoi limiti"])}},tokenizer:{advance_usage:e=>{const{normalize:i}=e;return i(["Utilizza la richiesta POST per altre funzionalità"])},basic_usage:e=>{const{normalize:i}=e;return i(["Utilizzare la richiesta GET per contare i token"])},basic_usage_explain:e=>{const{normalize:i}=e;return i(["Puoi semplicemente inviare una richiesta GET per contare il numero di token nel tuo testo."])},change_content:e=>{const{normalize:i}=e;return i(["Cambia 'contenuto' e guarda il risultato in tempo reale"])},chars:e=>{const{normalize:i}=e;return i(["caratteri"])},chinese:e=>{const{normalize:i}=e;return i(["cinese"])},chunk:e=>{const{normalize:i}=e;return i(["Pezzo"])},chunk_all:e=>{const{normalize:i}=e;return i(["Tutti i pezzi"])},chunking:e=>{const{normalize:i}=e;return i(["Suddividere documenti lunghi in frammenti, alla velocità della luce!"])},chunking_explain:e=>{const{normalize:i}=e;return i(["Puoi anche usare Segmenter API per tagliare documenti lunghi in blocchi più piccoli, rendendone più facile l'elaborazione in incorporamenti o reranker. Sfruttiamo spunti strutturali comuni e creiamo un set di regole ed euristiche che funzionano bene su diversi tipi di contenuto, ad esempio Markdown, HTML, LaTeX e linguaggi CJK."])},chunking_short:e=>{const{normalize:i}=e;return i(["suddivisione in blocchi"])},chunks_in_total:e=>{const{normalize:i,interpolate:n,named:o}=e;return i([n(o("_numChunks"))," blocchi in totale"])},count_tokens_hint:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["<b>",n(o("_numTokens")),"</b> token, ",n(o("_numChars"))," caratteri."])},description:e=>{const{normalize:i}=e;return i(["Tagliare il testo lungo in blocchi ed effettuare la tokenizzazione."])},description_long:e=>{const{normalize:i}=e;return i(["La nostra API Segmenter è fondamentale per aiutare gli LLM a gestire l'input entro i limiti del contesto e ottimizzare le prestazioni del modello. Consente agli sviluppatori di contare i token ed estrarre segmenti di testo rilevanti, garantendo un'elaborazione efficiente dei dati e una gestione dei costi."])},description_long1:e=>{const{normalize:i}=e;return i(["API gratuita per la segmentazione di testi lunghi in blocchi e tokenizzazione."])},english:e=>{const{normalize:i}=e;return i(["Inglese"])},explain:e=>{const{normalize:i}=e;return i(["Un segmentatore è un componente cruciale che converte il testo in token o blocchi, che sono le unità di dati di base che un modello di incorporamento/reranker o LLM elabora. I token possono rappresentare parole intere, parti di parole o persino singoli caratteri."])},faq_v1:{answer1:e=>{const{normalize:i}=e;return i(["L'API Segmenter è gratuita. Fornendo la tua chiave API, puoi accedere a un limite di tariffa più elevato e la tua chiave non verrà addebitata."])},answer10:e=>{const{normalize:i}=e;return i(["Oltre alle lingue occidentali, la suddivisione in blocchi funziona bene anche con il cinese, il giapponese e il coreano."])},answer2:e=>{const{normalize:i}=e;return i(["Senza una chiave API, è possibile accedere all'API Segmenter a una velocità massima di 20 RPM."])},answer3:e=>{const{normalize:i}=e;return i(["Con una chiave API, puoi accedere alla Segmenter API a un limite di velocità di 200 RPM. Per gli utenti premium a pagamento, il limite di velocità è di 1000 RPM."])},answer4:e=>{const{normalize:i}=e;return i(["No, la tua chiave API viene utilizzata solo per accedere a un limite di velocità più elevato."])},answer5:e=>{const{normalize:i}=e;return i(["Sì, l'API Segmenter è multilingue e supporta oltre 100 lingue."])},answer6:e=>{const{normalize:i}=e;return i(["Le richieste GET sono utilizzate esclusivamente per contare il numero di token in un testo, consentendoti di integrarlo facilmente come contatore nella tua applicazione. Le richieste POST supportano più parametri e funzionalità, come la restituzione dei primi/ultimi N token."])},answer7:e=>{const{normalize:i}=e;return i(["È possibile inviare fino a 64.000 caratteri per richiesta."])},answer8:e=>{const{normalize:i}=e;return i(["La funzione di chunking segmenta i documenti lunghi in blocchi più piccoli in base a comuni indizi strutturali, assicurando una segmentazione accurata del testo in blocchi significativi. In sostanza, si tratta di un (grande!) modello regex che segmenta il testo in base a determinate caratteristiche sintattiche che spesso si allineano con i confini semantici, come terminazioni di frase, interruzioni di paragrafo, punteggiatura e determinate congiunzioni. Non è un chunking semantico. Questa (grande) regex è potente quanto può esserlo entro i limiti delle espressioni regolari. Bilancia complessità e prestazioni. Mentre una vera comprensione semantica non è possibile con regex, approssima bene il contesto tramite comuni indizi strutturali."])},answer9:e=>{const{normalize:i}=e;return i(["Se l'input contiene token speciali, la nostra API Segmenter li inserirà nel campo 'special_tokens'. Ciò ti consente di identificarli facilmente e gestirli di conseguenza per le tue attività downstream, ad esempio rimuovendoli prima di immettere il testo in un LLM per prevenire attacchi di iniezione."])},question1:e=>{const{normalize:i}=e;return i(["Quanto costa l'API Segmenter?"])},question10:e=>{const{normalize:i}=e;return i(["La suddivisione in blocchi supporta anche altre lingue oltre all'inglese?"])},question2:e=>{const{normalize:i}=e;return i(["Se non fornisco una chiave API, qual è il limite di velocità?"])},question3:e=>{const{normalize:i}=e;return i(["Se fornisco una chiave API, qual è il limite di velocità?"])},question4:e=>{const{normalize:i}=e;return i(["Addebiterete i token dalla mia chiave API?"])},question5:e=>{const{normalize:i}=e;return i(["L'API Segmenter supporta più lingue?"])},question6:e=>{const{normalize:i}=e;return i(["Qual è la differenza tra le richieste GET e POST?"])},question7:e=>{const{normalize:i}=e;return i(["Qual è la lunghezza massima che posso tokenizzare per richiesta?"])},question8:e=>{const{normalize:i}=e;return i(["Come funziona la funzione di chunking? È un chunking semantico?"])},question9:e=>{const{normalize:i}=e;return i(["Come si gestiscono i token speciali come 'endoftext' nella Segmenter API?"])},title:e=>{const{normalize:i}=e;return i(["Domande frequenti relative al segmentatore"])}},free_api:e=>{const{normalize:i}=e;return i(["L'API Segmenter è gratuita. Fornendo la tua chiave API, puoi accedere a un limite di tariffa più elevato e la tua chiave non verrà addebitata."])},input_text:e=>{const{normalize:i}=e;return i(["Testo di input"])},is_free:e=>{const{normalize:i}=e;return i(["L'API Segmenter è gratuita!"])},is_free_description:e=>{const{normalize:i}=e;return i(["Fornendo la tua chiave API, potrai accedere a un limite di tariffa più elevato e la tua chiave non verrà addebitata."])},japanese:e=>{const{normalize:i}=e;return i(["giapponese"])},korean:e=>{const{normalize:i}=e;return i(["coreano"])},parameters:{auth_token:e=>{const{normalize:i}=e;return i(["Aggiungi la chiave API per un limite di velocità più elevato"])},auth_token_explain:e=>{const{normalize:i}=e;return i(["Inserisci la tua chiave API Jina per accedere a un limite di velocità più elevato. Per le informazioni più recenti sul limite di velocità, fai riferimento alla tabella sottostante."])},head:e=>{const{normalize:i}=e;return i(["Restituisci i primi N token"])},head_explain:e=>{const{normalize:i}=e;return i(["Restituisce i primi N token del contenuto specificato. Esclusivo di confine. Non può essere utilizzato con 'tail'."])},learn_more:e=>{const{normalize:i}=e;return i(["Saperne di più"])},max_chunk_length:e=>{const{normalize:i}=e;return i(["Lunghezza massima di ogni blocco"])},max_chunk_length_explain:e=>{const{normalize:i}=e;return i(["Numero massimo di caratteri in ogni blocco. In pratica la lunghezza del blocco può essere inferiore a questo valore, se c'è un confine naturale nel testo."])},return_chunks:e=>{const{normalize:i}=e;return i(["Restituisci i pezzi"])},return_chunks_explain:e=>{const{normalize:i}=e;return i(["Suddividere l'input in segmenti semanticamente significativi, gestendo al contempo un'ampia gamma di tipologie di testo e casi limite in base a spunti strutturali comuni."])},return_tokens:e=>{const{normalize:i}=e;return i(["Restituisci i token"])},return_tokens_explain:e=>{const{normalize:i}=e;return i(["Restituisci i token e i loro ID corrispondenti nella risposta. Attiva/disattiva per vedere la visualizzazione del risultato."])},tail:e=>{const{normalize:i}=e;return i(["Restituisce gli ultimi N token"])},tail_explain:e=>{const{normalize:i}=e;return i(["Restituisce gli ultimi N token del contenuto specificato. Esclusivo di confine. Non può essere utilizzato con 'head'."])},type:e=>{const{normalize:i}=e;return i(["Segmentatore"])},type_explain:e=>{const{normalize:i}=e;return i(["Scegli il tokenizzatore da utilizzare."])},used_by_models:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Utilizzato in ",n(o("_usedBy")),"."])}},remove_boundary_cues:e=>{const{normalize:i}=e;return i(["Rimuovi le interruzioni di riga"])},remove_boundary_cues_explain:e=>{const{normalize:i}=e;return i(["Rimuovi tutte le interruzioni di riga (i principali segnali di confine) dall'input: questo rende il problema più impegnativo e osserva come cambia la risposta!"])},show_space:e=>{const{normalize:i}=e;return i(["Mostra spazi iniziali/finali"])},table:{td_1_0:e=>{const{normalize:i}=e;return i(["Tokenizza i testi, conta e ottieni i primi/ultimi N token."])},td_1_1:e=>{const{normalize:i}=e;return i(["20 giri al minuto"])},td_1_2:e=>{const{normalize:i}=e;return i(["200 giri al minuto"])},td_1_3:e=>{const{normalize:i}=e;return i(["1000 giri al minuto"])},td_1_4:e=>{const{normalize:i}=e;return i(["Nessun costo"])},td_1_5:e=>{const{normalize:i}=e;return i(["800 ms"])}},title:e=>{const{normalize:i}=e;return i(["API del segmentatore"])},token_index:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Indice token: ",n(o("_index"))])},usage:e=>{const{normalize:i}=e;return i(["Utilizzo"])},visualization:e=>{const{normalize:i}=e;return i(["Visualizzazione"])},what_is:e=>{const{normalize:i}=e;return i(["Che cosa è un Segmenter?"])}},translator:{cta:e=>{const{normalize:i,interpolate:n,named:o}=e;return i(["Traduci in codice ",n(o("_lang"))])},select_language:e=>{const{normalize:i}=e;return i(["Lingua"])}},vectordb:{description:e=>{const{normalize:i}=e;return i(["Un database vettoriale Python di cui hai solo bisogno, né più né meno"])}},zzz:e=>{const{normalize:i}=e;return i(["zzz"])}};export{r as default};
