var r={PRODUCT_DESCRIPTION:e=>{const{normalize:a}=e;return a(["Proporcionamos las mejores incorporaciones, reclasificadores, lectores de LLM y optimizadores r\xE1pidos de su clase, siendo pioneros en la b\xFAsqueda de IA para datos multimodales."])},SEO_TAG_LINE:e=>{const{normalize:a}=e;return a(["Su base de b\xFAsqueda, sobrealimentada."])},about_us_page:{approach:e=>{const{normalize:a}=e;return a(["Nuestro enfoque"])},approach_connect_dots:e=>{const{normalize:a}=e;return a(["Conectando los puntos: usuarios avanzados para empresas"])},approach_connect_dots_description:e=>{const{normalize:a}=e;return a(["Entonces, \xBFpor qu\xE9 es esencial un enfoque en el usuario avanzado para nuestro modelo centrado en la empresa? Porque se trata de establecer relaciones tempranas. Al atender a los usuarios avanzados ahora, estamos construyendo puentes hacia las empresas en las que influir\xE1n en el futuro. Es una jugada estrat\xE9gica: una inversi\xF3n a largo plazo para garantizar que nuestra oferta empresarial siga siendo una prioridad cuando estos usuarios avanzados asciendan a roles de toma de decisiones dentro de las organizaciones."])},approach_content1:e=>{const{normalize:a}=e;return a(["En el mundo de la IA en r\xE1pida evoluci\xF3n, las estrategias deben ser \xE1giles y con visi\xF3n de futuro. Si bien nuestra oferta principal sigue centrada en las empresas, el panorama de la IA ha cambiado de manera que es necesario repensar nuestro enfoque para la adquisici\xF3n de clientes. He aqu\xED por qu\xE9 presentar a los usuarios avanzados como el punto de entrada de nuestro embudo no solo es innovador, sino crucial para nuestro crecimiento sostenido en el sector empresarial."])},approach_content2:e=>{const{normalize:a}=e;return a(["En Jina AI, nuestra estrategia es ser proactivos en lugar de reactivos. La inclusi\xF3n de usuarios avanzados como punto de entrada del embudo garantiza que no solo capturamos las tendencias actuales del mercado, sino que tambi\xE9n estamos estrat\xE9gicamente preparados para el crecimiento empresarial futuro. Nuestro compromiso con las empresas sigue siendo inquebrantable; sin embargo, nuestro enfoque para llegar a ellos es innovador, s\xF3lido y, sobre todo, con visi\xF3n de futuro."])},approach_content4:e=>{const{normalize:a}=e;return a(['Todos quieren una mejor b\xFAsqueda. En Jina AI, facilitamos una mejor b\xFAsqueda al proporcionar la <span class="text-primary text-bold">Base de b\xFAsqueda</span>, que consta de incrustaciones, reclasificadores, lectores y operaciones de aviso. Estos componentes funcionan en conjunto para revolucionar la forma en que buscamos y entendemos los datos. Esto conduce a una mejor experiencia de b\xFAsqueda, confianza del usuario, un aumento directo de las ventas y la activaci\xF3n de un nuevo crecimiento comercial.'])},approach_miss_mark:e=>{const{normalize:a}=e;return a(["Por qu\xE9 los MLOps tradicionales no dan en el blanco"])},approach_miss_mark_description:e=>{const{normalize:a}=e;return a(["Si bien la afluencia de usuarios avanzados es significativa, las herramientas tradicionales de MLOps est\xE1n mal equipadas para satisfacer sus necesidades. Estas herramientas recuerdan el uso de un tractor para moverse por las calles de la ciudad: son pesadas y, a menudo, excesivas. Los desarrolladores de nueva generaci\xF3n exigen herramientas \xE1giles e intuitivas que complementen su r\xE1pido ritmo de desarrollo."])},approach_new_paradigm:e=>{const{normalize:a}=e;return a(["Tecnolog\xEDa basada en avisos: un nuevo paradigma"])},approach_new_paradigm_description:e=>{const{normalize:a}=e;return a([`2023 anunci\xF3 un cambio significativo: el surgimiento de la tecnolog\xEDa basada en avisos. Al simplificar el proceso de desarrollo de IA, ha democratizado el acceso a las herramientas de IA. Ahora, aquellos que no tienen una amplia experiencia en programaci\xF3n, denominados "usuarios avanzados", pueden participar en el desarrollo de IA sin las pronunciadas curvas de aprendizaje asociadas con herramientas como Pytorch, Docker o Kubernetes.

Trazando un paralelo, esto es similar a la evoluci\xF3n de la computaci\xF3n personal. Inicialmente, solo los expertos en tecnolog\xEDa operaban computadoras. Pero con la llegada de las interfaces f\xE1ciles de usar, podr\xEDa participar una audiencia m\xE1s amplia. Hoy, con la tecnolog\xEDa basada en avisos, estamos presenciando una democratizaci\xF3n similar en la IA.`])},awards:e=>{const{normalize:a}=e;return a(["Premios y reconocimientos"])},berlin:e=>{const{normalize:a}=e;return a(["Berl\xEDn, Alemania"])},berlin_address:e=>{const{normalize:a}=e;return a(["Prinzessinnenstra\xDFe 19-20, 10969 Berl\xEDn, Alemania"])},berlin_address2:e=>{const{normalize:a}=e;return a(["Gesch\xE4ftsanschrift: Leipziger str. 96, 10117 Berl\xEDn, Alemania"])},bj:e=>{const{normalize:a}=e;return a(["Beijing, China"])},bj_address:e=>{const{normalize:a}=e;return a(["Nivel 5, Edificio 6, No.48 Haidian West St. Beijing Haidian, China"])},brochure_info:e=>{const{normalize:a}=e;return a(["Su gu\xEDa de nuestra empresa le espera"])},description:e=>{const{normalize:a}=e;return a(["El futuro comienza aqu\xED."])},download_brochure1:e=>{const{normalize:a}=e;return a(["Descargar folleto"])},download_docarray_logo:e=>{const{normalize:a}=e;return a(["Descargue el logotipo de DocArray"])},download_docarray_logo_desc:e=>{const{normalize:a}=e;return a(["Acceda al logotipo de DocArray, un proyecto de c\xF3digo abierto iniciado por Jina AI y contribuido a la Fundaci\xF3n Linux en diciembre de 2022. Disponible en modos claro y oscuro, en formatos PNG y SVG."])},download_jina_logo:e=>{const{normalize:a}=e;return a(["Descargue el logotipo de Jina AI"])},download_jina_logo_desc:e=>{const{normalize:a}=e;return a(["Obtenga el logotipo de Jina AI en modo claro y oscuro, disponible en formatos PNG y SVG. Este logotipo es una marca registrada en la Oficina de Propiedad Intelectual de la Uni\xF3n Europea (EUIPO)."])},download_logo:e=>{const{normalize:a}=e;return a(["Descargar logotipos"])},employees:e=>{const{normalize:a}=e;return a(["Los empleados hoy"])},empower_developers:e=>{const{normalize:a}=e;return a(["Desarrolladores empoderados"])},fastApiCaption:e=>{const{normalize:a}=e;return a(["Contribuy\xF3 con m\xE1s de $ 20,000 desde 2021."])},founded:e=>{const{normalize:a}=e;return a(["Fundado"])},founded_in:e=>{const{normalize:a}=e;return a(["Fundado en"])},investors:e=>{const{normalize:a}=e;return a(["Nuestros inversores"])},linuxFoundationCaption:e=>{const{normalize:a}=e;return a(["Realiza un aporte anual de $10,000 a partir de 2022."])},many:e=>{const{normalize:a}=e;return a(["Muchos"])},mission:e=>{const{normalize:a}=e;return a(["Nuestra misi\xF3n"])},mission_content1:e=>{const{normalize:a}=e;return a(["Nosotros Nuestras tecnolog\xEDas clave, que incluyen el ajuste r\xE1pido, el servicio r\xE1pido, el ajuste de modelos y el servicio de modelos, encarnan nuestro compromiso de democratizar el acceso a la IA. A trav\xE9s de nuestra iniciativa de c\xF3digo abierto, nos esforzamos por fomentar la innovaci\xF3n, la colaboraci\xF3n y la transparencia, garantizando soluciones escalables, eficientes y s\xF3lidas. Jina AI es m\xE1s que una simple empresa; es una comunidad dedicada a capacitar a las empresas para que enfrenten los desaf\xEDos din\xE1micos de la era digital y prosperen en sus dominios."])},mission_content2:e=>{const{normalize:a}=e;return a(["En el coraz\xF3n de Jina AI se encuentra nuestra misi\xF3n de ser el portal hacia la IA multimodal para una clientela diversa, desde usuarios avanzados y desarrolladores hasta empresas. Creemos profundamente en el poder del c\xF3digo abierto y estamos dedicados a crear herramientas avanzadas y accesibles para la comunidad de IA. Nuestras tecnolog\xEDas clave, que incluyen el ajuste r\xE1pido, el servicio r\xE1pido, el ajuste integrado y el servicio integrado, encarnan nuestro compromiso de democratizar el acceso a la IA. A trav\xE9s de nuestra iniciativa de c\xF3digo abierto, nos esforzamos por fomentar la innovaci\xF3n, la colaboraci\xF3n y la transparencia, garantizando soluciones escalables, eficientes y s\xF3lidas. Jina AI es m\xE1s que una simple empresa; es una comunidad dedicada a capacitar a las empresas para que enfrenten los desaf\xEDos din\xE1micos de la era digital y prosperen en sus dominios."])},mission_content3:e=>{const{normalize:a}=e;return a(["En Jina AI, nuestra misi\xF3n es liderar el avance de la IA multimodal a trav\xE9s de tecnolog\xEDas innovadoras de integraci\xF3n y basadas en avisos, centr\xE1ndonos espec\xEDficamente en \xE1reas como el procesamiento del lenguaje natural, el an\xE1lisis de im\xE1genes y videos y la interacci\xF3n de datos intermodales. Esta especializaci\xF3n nos permite ofrecer soluciones \xFAnicas que convierten datos complejos de m\xFAltiples fuentes en conocimientos pr\xE1cticos y aplicaciones innovadoras."])},mit_report_title:e=>{const{normalize:a}=e;return a(["Multimodal: la nueva frontera de la IA"])},mit_techreview:e=>{const{normalize:a}=e;return a(["Revisi\xF3n de tecnolog\xEDa del MIT"])},numfocusCaption:e=>{const{normalize:a}=e;return a(["Dona regularmente cada mes a partir de 2022."])},office:e=>{const{normalize:a}=e;return a(["Nuestras oficinas"])},otherProjectsCaption:e=>{const{normalize:a}=e;return a(["Don\xF3 m\xE1s de $ 3,000 a trav\xE9s del patrocinio de Github."])},our_answer:e=>{const{normalize:a}=e;return a(["Absolutamente Yann. \xA1Estamos en ello, construyendo puentes hacia un futuro de IA multimodal!"])},pythonSoftwareFoundationCaption:e=>{const{normalize:a}=e;return a(["Proporcion\xF3 una donaci\xF3n \xFAnica de $ 10,000 y patrocin\xF3 m\xFAltiples eventos de PyCon, incluidos los de Alemania, Italia, China y los EE. UU."])},sefo:{layer0:e=>{const{normalize:a}=e;return a(["Aplicaciones de usuario final"])},layer1:e=>{const{normalize:a}=e;return a(["RAG / orquestaci\xF3n"])},layer3:e=>{const{normalize:a}=e;return a(["GPU/m\xF3vil/borde/computaci\xF3n local"])}},segmentFaultCaption:e=>{const{normalize:a}=e;return a(["Contribuy\xF3 con una donaci\xF3n \xFAnica de $ 6,000."])},stats_1:e=>{const{normalize:a}=e;return a(["Fundada en febrero de 2020, Jina AI se ha convertido r\xE1pidamente en pionera mundial en tecnolog\xEDa de IA multimodal. En un per\xEDodo impresionante de 20 meses, recaudamos con \xE9xito $37,5 millones, lo que marca nuestra s\xF3lida posici\xF3n en la industria de la IA. Nuestra tecnolog\xEDa innovadora, de c\xF3digo abierto en GitHub, ha permitido a m\xE1s de 40\xA0000 desarrolladores de todo el mundo crear e implementar aplicaciones multimodales sofisticadas sin problemas."])},stats_2:e=>{const{normalize:a}=e;return a(["En 2023, hemos logrado avances significativos en el avance de las herramientas de generaci\xF3n de IA basadas en tecnolog\xEDa multimodal. Esta innovaci\xF3n ha beneficiado a m\xE1s de 250 000 usuarios en todo el mundo, atendiendo a una pl\xE9tora de requisitos comerciales \xFAnicos. Desde facilitar el crecimiento empresarial y mejorar la eficiencia operativa hasta optimizar los costos, Jina AI se dedica a empoderar a las empresas para que sobresalgan en la era multimodal."])},stats_4:e=>{const{normalize:a}=e;return a(['Fundada en 2020 en Berl\xEDn, Jina AI es una empresa l\xEDder en inteligencia artificial de b\xFAsqueda. Proporcionamos la <span class="text-primary text-bold">Search Foundation</span>, el n\xFAcleo de GenAI y aplicaciones multimodales. Nuestra misi\xF3n es ayudar a las empresas y desarrolladores a desbloquear datos multimodales para la creaci\xF3n de valor con una mejor b\xFAsqueda. Como empresa comercial de c\xF3digo abierto, nos gusta la innovaci\xF3n abierta.'])},stats_v1:e=>{const{normalize:a}=e;return a(["Buscar/cuenta"])},subtitle:e=>{const{normalize:a}=e;return a(["Revolucionando la creaci\xF3n de contenido a trav\xE9s de soluciones generadas por IA para desbloquear infinitas posibilidades. Dando forma al futuro del contenido generado por IA y mejorando la creatividad humana."])},sues_und_sauer:e=>{const{normalize:a}=e;return a(["Su\xE9 y Sauer"])},sues_und_sauer_tooltip:e=>{const{normalize:a}=e;return a(["S\xFC\xDF-Sauer, un sabor popular (aunque estereotipado) en la cocina chino-alemana, significa agridulce. Es una met\xE1fora de los altibajos de la vida de una startup."])},sz:e=>{const{normalize:a}=e;return a(["Shenzhen, China"])},sz_address:e=>{const{normalize:a}=e;return a(["402, Piso 4, Edificio de Tecnolog\xEDa Fu'an, Shenzhen Nanshan, China"])},team:e=>{const{normalize:a}=e;return a(["Dentro del Portal de Jina AI"])},team_content1:e=>{const{normalize:a}=e;return a(["Desde diversos rincones del mundo, estamos construyendo el futuro de la IA. Nuestras distintas perspectivas enriquecen nuestro trabajo y generan innovaciones. Dentro de este portal, abrazamos nuestra individualidad y perseguimos apasionadamente nuestros sue\xF1os. Bienvenido al portal del futuro de la IA."])},team_join:e=>{const{normalize:a}=e;return a(["\xDAnete a nosotros"])},team_size:e=>{const{normalize:a}=e;return a(["Estas fotograf\xEDas incluyen a nuestros antiguos compa\xF1eros y pasantes; agradecemos a cada uno de ellos."])},technologies:e=>{const{normalize:a}=e;return a(["Tecnolog\xEDas"])},title:e=>{const{normalize:a}=e;return a(["Acerca de Jina AI"])},title0:e=>{const{normalize:a}=e;return a(["El futuro"])},title1:e=>{const{normalize:a}=e;return a(["Empieza"])},title2:e=>{const{normalize:a}=e;return a(["Aqu\xED"])},title3:e=>{const{normalize:a}=e;return a(["Comienza aqu\xED"])},understand_our_strength:e=>{const{normalize:a}=e;return a(["Comprender nuestra fuerza"])},understand_our_view2:e=>{const{normalize:a}=e;return a(["Comprender la Fundaci\xF3n de B\xFAsqueda"])},users:e=>{const{normalize:a}=e;return a(["Usuarios Registrados"])},value:e=>{const{normalize:a}=e;return a(["Nuestro valor"])},value_content1:e=>{const{normalize:a}=e;return a(["La apertura impulsa la innovaci\xF3n y fomenta la colaboraci\xF3n. No solo apoyamos esta idea, sino que la vivimos. Hemos abierto el c\xF3digo fuente de nuestros modelos y proyectos y compartimos nuestra experiencia con el mundo. Y vamos m\xE1s all\xE1: desde ser uno de los primeros donantes de FastAPI hasta respaldar activamente a la Linux Foundation y a la Python Software Foundation, estamos profundamente comprometidos con la retribuci\xF3n."])},vision:e=>{const{normalize:a}=e;return a(["Nuestra misi\xF3n"])},vision_content1:e=>{const{normalize:a}=e;return a(["Inspirado por la idea de Yann LeCun de que '"])},vision_content3:e=>{const{normalize:a}=e;return a(['El futuro de la IA es <span class="text-primary text-bold">multimodal</span> y nosotros somos parte de \xE9l. Sabemos que las empresas enfrentan desaf\xEDos al aprovechar los datos multimodales. En respuesta, estamos comprometidos con la <span class="text-primary text-bold">Search Foundation</span> para ayudar a las empresas y desarrolladores a buscar mejor y utilizar datos multimodales para el crecimiento empresarial.'])},yannlecun_quote:e=>{const{normalize:a}=e;return a(["Un sistema de inteligencia artificial entrenado solo con palabras y oraciones nunca se aproximar\xE1 a la comprensi\xF3n humana."])}},api_general_faq:{answer1:e=>{const{normalize:a}=e;return a(["S\xED, la misma clave API es v\xE1lida para todos los productos b\xE1sicos de b\xFAsqueda de Jina AI. Esto incluye las API de integraci\xF3n, reclasificaci\xF3n, lectura y ajuste, con tokens compartidos entre todos los servicios."])},answer12:e=>{const{normalize:a}=e;return a(["Nos adherimos a una estricta pol\xEDtica de privacidad y no utilizamos datos ingresados \u200B\u200Bpor el usuario para entrenar nuestros modelos."])},answer3:e=>{const{normalize:a}=e;return a(['S\xED, el uso de tokens se puede monitorear en la pesta\xF1a "Comprar tokens" ingresando su clave API, lo que le permite ver el historial de uso y los tokens restantes.'])},answer4:e=>{const{normalize:a}=e;return a(["Si extravi\xF3 una clave de recarga y desea recuperarla, comun\xEDquese con el soporte t\xE9cnico de jina.ai con su correo electr\xF3nico registrado para obtener ayuda."])},answer5:e=>{const{normalize:a}=e;return a(["No, nuestras claves API no tienen fecha de vencimiento. Sin embargo, si sospecha que su clave se ha visto comprometida y desea retirarla o transferir sus tokens a una nueva clave, comun\xEDquese con nuestro equipo de soporte para obtener ayuda."])},answer6:e=>{const{normalize:a}=e;return a(['Esto se debe a que nuestra arquitectura sin servidor descarga ciertos modelos durante per\xEDodos de bajo uso. La solicitud inicial activa o "calienta" el modelo, lo que puede tardar unos segundos. Despu\xE9s de esta activaci\xF3n inicial, las solicitudes posteriores se procesan mucho m\xE1s r\xE1pidamente.'])},question1:e=>{const{normalize:a}=e;return a(["\xBFPuedo usar la misma clave API para incrustar, reclasificar, leer y ajustar las API?"])},question12:e=>{const{normalize:a}=e;return a(["\xBFSe utilizan los datos de entrada del usuario para entrenar sus modelos?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFPuedo monitorear el uso del token de mi clave API?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 debo hacer si olvido mi clave API?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFCaducan las claves API?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFPor qu\xE9 la primera solicitud de algunos modelos es lenta?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con API"])}},autotune:{base_model:e=>{const{normalize:a}=e;return a(["Modelo base para ajuste fino"])},check_data:e=>{const{normalize:a}=e;return a(["Descargar datos sint\xE9ticos"])},check_model:e=>{const{normalize:a}=e;return a(["Descargar modelo ajustado"])},data_size:e=>{const{normalize:a}=e;return a(["Datos sint\xE9ticos generados"])},description:e=>{const{normalize:a}=e;return a(["Obtenga incorporaciones optimizadas para cualquier dominio que desee."])},description_long:e=>{const{normalize:a}=e;return a(["Simplemente d\xEDganos en qu\xE9 dominio desea que sus incrustaciones destaquen y le entregaremos autom\xE1ticamente un modelo de incrustaci\xF3n optimizado y listo para usar para ese dominio."])},does_it_work_tho:e=>{const{normalize:a}=e;return a(["\xBFPero funciona?"])},does_it_work_tho_explain:e=>{const{normalize:a}=e;return a(["El ajuste autom\xE1tico tiene la promesa autom\xE1tica de ofrecer incrustaciones ajustadas para cualquier dominio que desee. pero de verdad funciona? Esta es una duda bastante razonable. Lo hemos probado en una variedad de dominios y modelos base para averiguarlo. Echa un vistazo a los resultados seleccionados con cereza y lim\xF3n a continuaci\xF3n."])},domain_instruction:e=>{const{normalize:a}=e;return a(["Instrucci\xF3n de dominio"])},embedding_provider:e=>{const{normalize:a}=e;return a(["Seleccione un modelo de incrustaci\xF3n base"])},eval_evaluation:e=>{const{normalize:a}=e;return a(["Validaci\xF3n"])},eval_map:e=>{const{normalize:a}=e;return a(["MAPA"])},eval_mrr:e=>{const{normalize:a}=e;return a(["MRR"])},eval_ndcg:e=>{const{normalize:a}=e;return a(["NDCG"])},eval_performance_before_after:e=>{const{normalize:a}=e;return a(["Rendimiento en el conjunto de validaci\xF3n sint\xE9tica antes y despu\xE9s del ajuste"])},eval_syntheticDataSize:e=>{const{normalize:a}=e;return a(["Total"])},eval_test:e=>{const{normalize:a}=e;return a(["Datos reales para realizar pruebas."])},eval_training:e=>{const{normalize:a}=e;return a(["Capacitaci\xF3n"])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["La funci\xF3n se encuentra actualmente en versi\xF3n beta y cuesta 1 mill\xF3n de tokens por modelo ajustado. Puede usar su clave API existente de la API Embedding/Reranker si tiene suficientes tokens, o puede crear una nueva clave API, que incluye 1 mill\xF3n de tokens gratuitos."])},answer10:e=>{const{normalize:a}=e;return a(["Actualmente no. Tenga en cuenta que esta funci\xF3n a\xFAn est\xE1 en versi\xF3n beta. Almacenar los modelos ajustados y los datos sint\xE9ticos p\xFAblicamente en el centro de modelos de Hugging Face nos ayuda a nosotros y a la comunidad a evaluar la calidad de la capacitaci\xF3n. En el futuro, planeamos ofrecer una opci\xF3n de almacenamiento privado."])},answer11:e=>{const{normalize:a}=e;return a(["Dado que todos los modelos ajustados se cargan en Hugging Face, puedes acceder a ellos a trav\xE9s de SentenceTransformers simplemente especificando el nombre del modelo."])},answer12:e=>{const{normalize:a}=e;return a(["Por favor revisa tu carpeta de spam. Si a\xFAn no puede encontrarlo, comun\xEDquese con nuestro equipo de soporte utilizando la direcci\xF3n de correo electr\xF3nico que proporcion\xF3."])},answer2:e=>{const{normalize:a}=e;return a(["No es necesario proporcionar ning\xFAn dato de entrenamiento. Simplemente describa su dominio de destino (el dominio para el cual desea que se optimicen las incrustaciones ajustadas) en lenguaje natural, o use una URL como referencia, y nuestro sistema generar\xE1 datos sint\xE9ticos para entrenar el modelo."])},answer3:e=>{const{normalize:a}=e;return a(["Unos 30 minutos."])},answer4:e=>{const{normalize:a}=e;return a(["Los modelos ajustados y los datos sint\xE9ticos se almacenan p\xFAblicamente en el centro de modelos de Hugging Face."])},answer5:e=>{const{normalize:a}=e;return a(["El sistema utiliza la API Reader para recuperar el contenido de la URL. Luego analiza el contenido para resumir el tono y el dominio, que utiliza como pautas para generar datos sint\xE9ticos. Por lo tanto, la URL debe ser de acceso p\xFAblico y representativa del dominio de destino."])},answer6:e=>{const{normalize:a}=e;return a(["S\xED, puede ajustar un modelo para un idioma distinto del ingl\xE9s. El sistema detecta autom\xE1ticamente el idioma de las instrucciones de su dominio y genera datos sint\xE9ticos en consecuencia. Tambi\xE9n recomendamos elegir el modelo base adecuado para el idioma de destino. Por ejemplo, si se dirige a un dominio alem\xE1n, debe seleccionar 'jina-embeddings-v2-base-de' como modelo base."])},answer7:e=>{const{normalize:a}=e;return a(["No, nuestra API de ajuste solo admite modelos Jina v2."])},answer8:e=>{const{normalize:a}=e;return a(["Al final del proceso de ajuste, el sistema eval\xFAa el modelo utilizando un conjunto de pruebas disponible e informa las m\xE9tricas de rendimiento. Recibir\xE1 un correo electr\xF3nico detallando el rendimiento antes y despu\xE9s de este equipo de prueba. Tambi\xE9n le recomendamos que eval\xFAe el modelo en su propio equipo de prueba para garantizar su calidad."])},answer9:e=>{const{normalize:a}=e;return a(["El sistema genera datos sint\xE9ticos integrando la instrucci\xF3n del dominio objetivo que usted proporciona con el razonamiento de los agentes de LLM. Produce tripletes negativos duros, que son esenciales para entrenar modelos de incrustaci\xF3n de alta calidad. Para obtener m\xE1s detalles, consulte nuestro pr\xF3ximo art\xEDculo de investigaci\xF3n sobre Arxiv."])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1nto cuesta la API de ajuste fino?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFPuedo mantener la privacidad de mis modelos ajustados y mis datos sint\xE9ticos?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo puedo utilizar el modelo ajustado?"])},question12:e=>{const{normalize:a}=e;return a(["Nunca recib\xED el correo electr\xF3nico con los resultados de la evaluaci\xF3n. \xBFQu\xE9 tengo que hacer?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 necesito ingresar? \xBFNecesito proporcionar datos de entrenamiento?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1nto tiempo lleva perfeccionar un modelo?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFD\xF3nde se almacenan los modelos ajustados?"])},question5:e=>{const{normalize:a}=e;return a(["Si proporciono una URL de referencia, \xBFc\xF3mo la usa el sistema?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFPuedo ajustar un modelo para un idioma espec\xEDfico?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFPuedo ajustar incrustaciones que no sean de Jina, por ejemplo, bge-M3?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se garantiza la calidad de los modelos ajustados?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se generan datos sint\xE9ticos?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con el ajuste autom\xE1tico"])}},find_on_hf:e=>{const{normalize:a}=e;return a(["Lista de modelos ajustados"])},temporarily_unavailable:e=>{const{normalize:a}=e;return a(["Temporalmente no disponible. Estamos actualizando nuestro sistema de ajuste autom\xE1tico para brindarle un mejor servicio. Por favor, vuelva m\xE1s tarde."])},test_on:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Probado en ",n(o("_dataSize"))," muestras aleatorias de ",n(o("_dataName"))])},test_performance_before_after:e=>{const{normalize:a}=e;return a(["Rendimiento en el conjunto de pruebas retenido antes y despu\xE9s del ajuste fino"])},title:e=>{const{normalize:a}=e;return a(["API de ajuste autom\xE1tico"])},total_improve:e=>{const{normalize:a}=e;return a(["Promedio mejora"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},what_is:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es el ajuste fino autom\xE1tico?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a(["El ajuste fino le permite tomar un modelo previamente entrenado y adaptarlo a una tarea o dominio espec\xEDfico entren\xE1ndolo en un nuevo conjunto de datos. En la pr\xE1ctica, encontrar datos de entrenamiento efectivos no es sencillo para muchos usuarios. La formaci\xF3n eficaz requiere algo m\xE1s que simplemente incluir archivos PDF y HTML sin formato en el modelo; y es dif\xEDcil hacerlo bien. El ajuste autom\xE1tico resuelve este problema al generar autom\xE1ticamente datos de capacitaci\xF3n efectivos utilizando una canalizaci\xF3n avanzada de agentes LLM; y ajustar el modelo dentro de un flujo de trabajo de ML. Puede pensarlo como una combinaci\xF3n de generaci\xF3n de datos sint\xE9ticos y AutoML, por lo que todo lo que necesita hacer es describir su dominio de destino en lenguaje natural y dejar que nuestro sistema haga el resto."])}},best_banner:{description:e=>{const{normalize:a}=e;return a(["\xA1Blog a banner, sin las indicaciones!"])},example_description:e=>{const{normalize:a}=e;return a(['Alicia empezaba a cansarse mucho de estar sentada junto a su hermana en la orilla y de no tener nada que hacer: una o dos veces hab\xEDa echado un vistazo al libro que su hermana estaba leyendo, pero no ten\xEDa dibujos ni conversaciones, "y de qu\xE9 sirve un libro", pens\xF3 Alicia, "sin dibujos ni conversaciones". As\xED que estaba considerando en su propia mente (lo mejor que pod\xEDa, porque el d\xEDa caluroso la hac\xEDa sentir muy so\xF1olienta y est\xFApida), si el placer de hacer una cadena de margaritas valdr\xEDa la pena de levantarse y recoger las margaritas, cuando de repente un Conejo Blanco con ojos rosados \u200B\u200Bcorri\xF3 cerca de ella.'])},example_title:e=>{const{normalize:a}=e;return a(["Las aventuras de Alicia en el pa\xEDs de las maravillas - Cap\xEDtulo 1"])}},beta:e=>{const{normalize:a}=e;return a(["Beta"])},billing_general_faq:{answer10:e=>{const{normalize:a}=e;return a(['Ofrecemos una prueba gratuita de bienvenida a nuevos usuarios, que incluye un mill\xF3n de tokens para usar con cualquiera de nuestros modelos, facilitada por una clave API generada autom\xE1ticamente. Una vez que se alcanza el l\xEDmite de tokens gratuitos, los usuarios pueden comprar f\xE1cilmente tokens adicionales para sus claves API a trav\xE9s de la pesta\xF1a "Comprar tokens".'])},answer13:e=>{const{normalize:a}=e;return a(["No, los tokens no se deducen por solicitudes fallidas."])},answer14:e=>{const{normalize:a}=e;return a(["Los pagos se procesan a trav\xE9s de Stripe y admiten una variedad de m\xE9todos de pago que incluyen tarjetas de cr\xE9dito, Google Pay y PayPal para su comodidad."])},answer15:e=>{const{normalize:a}=e;return a(["S\xED, se emitir\xE1 una factura a la direcci\xF3n de correo electr\xF3nico asociada a su cuenta de Stripe tras la compra de tokens."])},answer9:e=>{const{normalize:a}=e;return a(["Nuestro modelo de precios se basa en la cantidad total de tokens procesados, lo que permite a los usuarios la flexibilidad de asignar estos tokens en cualquier cantidad de oraciones, ofreciendo una soluci\xF3n rentable para diversos requisitos de an\xE1lisis de texto."])},question10:e=>{const{normalize:a}=e;return a(["\xBFHay una prueba gratuita disponible para nuevos usuarios?"])},question13:e=>{const{normalize:a}=e;return a(["\xBFSe cobran tokens por solicitudes fallidas?"])},question14:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 m\xE9todos de pago se aceptan?"])},question15:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 disponible la facturaci\xF3n para compras de tokens?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFLa facturaci\xF3n se basa en el n\xFAmero de sentencias o solicitudes?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con la facturaci\xF3n"])}},blog_tags:{all:e=>{const{normalize:a}=e;return a(["Todo"])},events:e=>{const{normalize:a}=e;return a(["Evento"])},featured:e=>{const{normalize:a}=e;return a(["Presentado"])},insights:e=>{const{normalize:a}=e;return a(["Opini\xF3n"])},"knowledge-base":e=>{const{normalize:a}=e;return a(["Base de conocimientos"])},latest:e=>{const{normalize:a}=e;return a(["El \xFAltimo"])},press:e=>{const{normalize:a}=e;return a(["presione soltar"])},releases:e=>{const{normalize:a}=e;return a(["Actualizaci\xF3n de software"])},"tech-blog":e=>{const{normalize:a}=e;return a(["Blog de tecnolog\xEDa"])}},clip_as_service:{description:e=>{const{normalize:a}=e;return a(["Incruste im\xE1genes y oraciones en vectores de longitud fija con CLIP"])}},cloud:{description:e=>{const{normalize:a}=e;return a(["Plataforma de alojamiento en la nube para aplicaciones de IA multimodal"])}},contact_us_page:{agreement:e=>{const{normalize:a}=e;return a(["Al enviar, confirma que est\xE1 de acuerdo con el procesamiento de sus datos personales por parte de Jina AI como se describe en el"])},anything_else:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos m\xE1s sobre tu proyecto"])},company:e=>{const{normalize:a}=e;return a(["Compa\xF1\xEDa"])},company_size:e=>{const{normalize:a}=e;return a(["Tama\xF1o de la empresa"])},company_website:e=>{const{normalize:a}=e;return a(["P\xE1gina Web de la compa\xF1\xEDa"])},company_website_placeholder:e=>{const{normalize:a}=e;return a(["URL de la p\xE1gina de inicio de su empresa o del perfil de LinkedIn"])},country:e=>{const{normalize:a}=e;return a(["Pa\xEDs"])},department:e=>{const{normalize:a}=e;return a(["Departamento"])},description:e=>{const{normalize:a}=e;return a(["Haga crecer su negocio con Jina AI."])},faq:e=>{const{normalize:a}=e;return a(["Preguntas m\xE1s frecuentes"])},field_required:e=>{const{normalize:a}=e;return a(["Se requiere campo"])},impact_snapshots:e=>{const{normalize:a}=e;return a(["Instant\xE1neas de impacto"])},invalid_date_format:e=>{const{normalize:a}=e;return a(["Formato de fecha no v\xE1lido. Utilice el formato DD-MM-AAAA."])},invalid_email:e=>{const{normalize:a}=e;return a(["el correo electr\xF3nico es invalido"])},invalid_number:e=>{const{normalize:a}=e;return a(["N\xFAmero invalido. Por favor ingrese de nuevo"])},invalid_url:e=>{const{normalize:a}=e;return a(["La URL no es v\xE1lida."])},name:e=>{const{normalize:a}=e;return a(["Nombre"])},preferred_products:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 productos est\xE1s interesado?"])},private_statement:e=>{const{normalize:a}=e;return a(["Declaracion de privacidad"])},role:e=>{const{normalize:a}=e;return a(["Puesto de trabajo"])},submit:e=>{const{normalize:a}=e;return a(["Entregar"])},submit_failed:e=>{const{normalize:a}=e;return a(["Env\xEDo fallido. Por favor, int\xE9ntelo de nuevo m\xE1s tarde."])},submit_success:e=>{const{normalize:a}=e;return a(["Gracias por tu env\xEDo. Nos pondremos en contacto con usted en breve."])},subtitle:e=>{const{normalize:a}=e;return a(["Jina AI, l\xEDder en IA multimodal, se destaca en el ajuste de modelos, el servicio de modelos, el ajuste de avisos y el servicio de avisos. Al aprovechar las tecnolog\xEDas nativas de la nube como Kubernetes y las arquitecturas sin servidor, ofrecemos soluciones s\xF3lidas, escalables y listas para producci\xF3n. Con experiencia en modelos de lenguaje grande, texto, imagen, video, comprensi\xF3n de audio, b\xFAsqueda neuronal y arte generativo, brindamos estrategias innovadoras y preparadas para el futuro para elevar su negocio."])},subtitle1:e=>{const{normalize:a}=e;return a(["Jina AI, l\xEDder en IA multimodal, se destaca en el ajuste de integraci\xF3n, el servicio de integraci\xF3n, el ajuste r\xE1pido y el servicio r\xE1pido. Aprovechando tecnolog\xEDas nativas de la nube como Kubernetes y arquitecturas sin servidor, ofrecemos soluciones s\xF3lidas, escalables y listas para producci\xF3n. Con experiencia en modelos de lenguaje grandes, texto, im\xE1genes, video, comprensi\xF3n de audio, b\xFAsqueda neuronal e inteligencia artificial generativa, brindamos estrategias innovadoras y preparadas para el futuro para elevar su negocio."])},subtitle2:e=>{const{normalize:a}=e;return a(["Explore Jina AI, la vanguardia de la IA multimodal. Nos destacamos en la integraci\xF3n y rapidez de tecnolog\xEDas, utilizando soluciones nativas de la nube como Kubernetes para sistemas robustos y escalables. Especializados en grandes modelos de lenguaje y procesamiento de medios, ofrecemos estrategias comerciales innovadoras y preparadas para el futuro con nuestra experiencia avanzada en IA."])},title:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},trusted_by:e=>{const{normalize:a}=e;return a(["Confiado por"])},work_email:e=>{const{normalize:a}=e;return a(["Correo electr\xF3nico del trabajo"])}},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},copy_to_clipboard_success:e=>{const{normalize:a}=e;return a(["Copiado al portapapeles"])},dalle_flow:{description:e=>{const{normalize:a}=e;return a(["Un flujo de trabajo human-in-the-Loop para crear im\xE1genes HD a partir de texto"])}},"dev-gpt":{description:e=>{const{normalize:a}=e;return a(["Tu equipo de desarrollo virtual"])}},disco_art:{description:e=>{const{normalize:a}=e;return a(["Cree atractivas obras de arte de Disco Diffusion en una l\xEDnea de c\xF3digo"])}},doc_array:{description:e=>{const{normalize:a}=e;return a(["La estructura de datos para datos multimodales"])}},embedding:{"11B tokens":e=>{const{normalize:a}=e;return a(["11 mil millones"])},"11B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Similar a leer todos los art\xEDculos en ingl\xE9s en Wikipedia."])},"11B tokens_targetUser":e=>{const{normalize:a}=e;return a(["Despliegue de producci\xF3n"])},"1B tokens":e=>{const{normalize:a}=e;return a(["1 mil millones"])},"1B tokens_intuition1":e=>{const{normalize:a}=e;return a(['Casi lo mismo que leer las obras completas de Shakespeare y toda la serie "Harry Potter".'])},"1B tokens_targetUser":e=>{const{normalize:a}=e;return a(["Desarrollo de prototipos"])},"1M tokens":e=>{const{normalize:a}=e;return a(["1 mill\xF3n"])},"1M tokens_intuition1":e=>{const{normalize:a}=e;return a(['Equivale a leer el texto completo de "El Hobbit" y "El gran Gatsby".'])},"1M tokens_targetUser":e=>{const{normalize:a}=e;return a(["experimento de juguete"])},"1M_free":e=>{const{normalize:a}=e;return a(["1 mill\xF3n de fichas gratis"])},"1M_free_description":e=>{const{normalize:a}=e;return a(["Disfrute de tokens gratis en su nueva clave API, no se necesita tarjeta de cr\xE9dito."])},"2_5B tokens":e=>{const{normalize:a}=e;return a(["2.500 millones de fichas"])},"2_5B tokens_intuition1":e=>{const{normalize:a}=e;return a([`Comparable a transcribir cada palabra pronunciada en la trilog\xEDa de la pel\xEDcula "El Se\xF1or de los Anillos" 1.000 veces.
`])},"3p_integration":e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Con <b>",n(o("_numPartners")),"</b> servicios de terceros"])},"3p_integration_desc":e=>{const{normalize:a}=e;return a(["Integre nuestra base de b\xFAsqueda con sus servicios existentes. Nuestros socios han creado conectores para nuestra API, lo que facilita el uso de nuestros modelos en sus aplicaciones."])},"500M tokens":e=>{const{normalize:a}=e;return a(["500 millones de fichas"])},"500M tokens_intuition1":e=>{const{normalize:a}=e;return a(['Similar a ver todos los episodios de "Los Simpson" desde la temporada 1 hasta la temporada 30.'])},"59B tokens":e=>{const{normalize:a}=e;return a(["59 mil millones de fichas"])},"59B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Igual a todos los tweets publicados en todo el mundo durante un per\xEDodo de dos d\xEDas."])},"5_5B tokens":e=>{const{normalize:a}=e;return a(["5.500 millones de fichas"])},"5_5B tokens_intuition1":e=>{const{normalize:a}=e;return a(["Equivale a leer el texto completo de la Encyclopaedia Britannica."])},Free1M:e=>{const{normalize:a}=e;return a(["1 mill\xF3n de fichas"])},add_pair:e=>{const{normalize:a}=e;return a(["Nuevo"])},api_integration_short:e=>{const{normalize:a}=e;return a(["Nuestra API de incrustaci\xF3n est\xE1 integrada de forma nativa con varias bases de datos, almacenes de vectores, marcos RAG y LLMOps de renombre."])},api_integrations:e=>{const{normalize:a}=e;return a(["Integraciones API"])},auto_recharge:e=>{const{normalize:a}=e;return a(["Recarga autom\xE1tica cuando las fichas est\xE1n bajas"])},auto_recharge_confirm_message:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 seguro de que desea desactivar la recarga autom\xE1tica? Esto evitar\xE1 las recargas autom\xE1ticas cuando el saldo de su token sea bajo."])},auto_recharge_confirm_title:e=>{const{normalize:a}=e;return a(["Desactivar recarga autom\xE1tica"])},auto_recharge_description:e=>{const{normalize:a}=e;return a(["Recomendado para servicio ininterrumpido en producci\xF3n. Cuando el saldo de su token est\xE9 por debajo del umbral que estableci\xF3, recargaremos autom\xE1ticamente su tarjeta de cr\xE9dito por el mismo monto que su \xFAltima recarga. Si compraste varios paquetes en la \xFAltima recarga, recargaremos solo un paquete."])},auto_recharge_enable:e=>{const{normalize:a}=e;return a(["Habilitaste la recarga autom\xE1tica en tokens bajos"])},auto_recharge_enable_message:e=>{const{normalize:a}=e;return a(["Para habilitar la recarga autom\xE1tica, compre un paquete con la recarga autom\xE1tica configurada como verdadera."])},auto_recharge_enable_title:e=>{const{normalize:a}=e;return a(["Habilitar recarga autom\xE1tica"])},auto_request:e=>{const{normalize:a}=e;return a(["Vista previa autom\xE1tica"])},auto_request_tooltip:e=>{const{normalize:a}=e;return a(['Obtenga una vista previa autom\xE1tica de la respuesta de la API al cambiar el modelo, utilizando cientos de tokens de su clave API. Desactive el env\xEDo manual de una solicitud haciendo clic en "Obtener respuesta".'])},autostart:e=>{const{normalize:a}=e;return a(["La inserci\xF3n comenzar\xE1 autom\xE1ticamente despu\xE9s de un breve retraso."])},base64_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones se devuelven como una cadena codificada en base64. M\xE1s eficiente para la transmisi\xF3n."])},batch_job:e=>{const{normalize:a}=e;return a(["Trabajo por lotes"])},batch_upload_hint:e=>{const{normalize:a}=e;return a(["Usaremos la clave API y el modelo siguiente para procesar los documentos."])},"bge-base-en-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo ingl\xE9s robusto que equilibra rendimiento y eficiencia para un uso vers\xE1til."])},"bge-base-en_description":e=>{const{normalize:a}=e;return a(["Un modelo ingl\xE9s equilibrado dise\xF1ado para un rendimiento s\xF3lido y fiable."])},"bge-base-zh-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo chino completo que equilibra capacidad y eficiencia."])},"bge-base-zh_description":e=>{const{normalize:a}=e;return a(["Un modelo chino vers\xE1til que combina eficiencia y rendimiento robusto."])},"bge-large-en-v1_5_description":e=>{const{normalize:a}=e;return a(["Un potente modelo ingl\xE9s que ofrece incrustaciones de primer nivel con una calidad excepcional."])},"bge-large-en_description":e=>{const{normalize:a}=e;return a(["Un modelo ingl\xE9s de alto rendimiento dise\xF1ado para incrustaciones de primera calidad."])},"bge-large-zh-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo chino de alta capacidad que ofrece incrustaciones superiores y detalladas."])},"bge-large-zh_description":e=>{const{normalize:a}=e;return a(["Un modelo chino de alto rendimiento optimizado para incrustaciones de primer nivel."])},"bge-m3_description":e=>{const{normalize:a}=e;return a(["Un modelo multiling\xFCe vers\xE1til que ofrece amplias capacidades e incorporaciones de alta calidad."])},"bge-small-en-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo ingl\xE9s simplificado que ofrece incrustaciones eficientes y de alta calidad."])},"bge-small-en_description":e=>{const{normalize:a}=e;return a(["Un modelo ingl\xE9s eficiente para incrustaciones optimizadas y precisas."])},"bge-small-zh-v1_5_description":e=>{const{normalize:a}=e;return a(["Un modelo chino compacto que proporciona incrustaciones \xE1giles y precisas."])},"bge-small-zh_description":e=>{const{normalize:a}=e;return a(["Un modelo chino \xE1gil para incrustaciones eficientes y precisas."])},binary_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones est\xE1n empaquetadas como int8. Mucho m\xE1s eficiente para almacenamiento, b\xFAsqueda y transmisi\xF3n."])},bulk:e=>{const{normalize:a}=e;return a(["Incrustaci\xF3n por lotes"])},bulk_embedding_failed:e=>{const{normalize:a}=e;return a(["No se pudo crear el trabajo de incrustaci\xF3n por lotes"])},buy_more_quota:e=>{const{normalize:a}=e;return a(["Recarga esta clave API con m\xE1s tokens"])},buy_poster:e=>{const{normalize:a}=e;return a(["Compre una copia impresa"])},cancel_button:e=>{const{normalize:a}=e;return a(["Cancelar"])},click_upload_btn_above:e=>{const{normalize:a}=e;return a(["Haga clic en el bot\xF3n de carga de arriba para comenzar."])},code:e=>{const{normalize:a}=e;return a(["c\xF3digo"])},compatible:e=>{const{normalize:a}=e;return a(["Modo compatible"])},compatible_explain:e=>{const{normalize:a}=e;return a(["Sigue el mismo formato de solicitud que nuestros modelos de incrustaci\xF3n de texto. Esto le permite cambiar entre modelos sin cambiar la solicitud. Tenga en cuenta que la entrada de im\xE1genes no es compatible con este modo."])},cosine_similarity:e=>{const{normalize:a}=e;return a(["Similitud del coseno"])},debugging:e=>{const{normalize:a}=e;return a(["Prueba"])},delete_pair:e=>{const{normalize:a}=e;return a(["Borrar"])},description:e=>{const{normalize:a,linked:n,type:o}=e;return a([n("landing_page.embedding_desc1",void 0,o)])},document:e=>{const{normalize:a}=e;return a(["Documento"])},download:e=>{const{normalize:a}=e;return a(["Descargar"])},edit_text1_text:e=>{const{normalize:a}=e;return a(["Editar texto de la izquierda"])},edit_text2_text:e=>{const{normalize:a}=e;return a(["Editar texto correcto"])},embedding_done:e=>{const{normalize:a,interpolate:n,named:o}=e;return a([n(o("_Count"))," oraciones insertadas correctamente."])},embedding_none_description:e=>{const{normalize:a}=e;return a(["No utilice ning\xFAn modelo de incrustaci\xF3n."])},example_inputs:e=>{const{normalize:a}=e;return a(["Entradas de ejemplo"])},faq:e=>{const{normalize:a,linked:n,type:o}=e;return a([n("contact_us_page.faq",void 0,o)])},faqs_v2:{answer0:e=>{const{normalize:a}=e;return a(["Para obtener informaci\xF3n detallada sobre nuestros procesos de capacitaci\xF3n, fuentes de datos y evaluaciones, consulte nuestro informe t\xE9cnico disponible en arXiv."])},answer1:e=>{const{normalize:a}=e;return a(["Cada usuario puede realizar hasta 100 solicitudes por segundo, lo que equivale a 204.800 frases de entrada por segundo."])},answer17:e=>{const{normalize:a}=e;return a(["Actualmente estamos desarrollando incrustaciones multimodales que procesar\xE1n conjuntamente texto, im\xE1genes y audio. \xA1Las actualizaciones se anunciar\xE1n pronto!"])},answer18:e=>{const{normalize:a}=e;return a(["Si tiene consultas sobre c\xF3mo ajustar nuestros modelos con datos espec\xEDficos, cont\xE1ctenos para analizar sus requisitos. Estamos abiertos a explorar c\xF3mo nuestros modelos se pueden adaptar para satisfacer sus necesidades."])},answer19:e=>{const{normalize:a}=e;return a(["S\xED, nuestros servicios est\xE1n disponibles en el mercado de AWS y estamos en el proceso de expandirnos a los mercados de Azure y GCP. Si tiene requisitos particulares, cont\xE1ctenos en ventas AT jina.ai."])},answer3:e=>{const{normalize:a}=e;return a(["Nuestros modelos admiten ingl\xE9s, alem\xE1n, espa\xF1ol, chino y varios lenguajes de programaci\xF3n. Para obtener m\xE1s detalles, consulte nuestra publicaci\xF3n sobre modelos biling\xFCes."])},answer4:e=>{const{normalize:a}=e;return a(['Nuestros modelos permiten una longitud de entrada de hasta 8192 tokens, que es significativamente mayor que la mayor\xEDa de los otros modelos. Un token puede variar desde un solo car\xE1cter, como "a", hasta una palabra completa, como "manzana". La cantidad total de caracteres que se pueden ingresar depende de la longitud y complejidad de las palabras utilizadas. Esta capacidad de entrada extendida permite que nuestros modelos jina-embeddings-v2 realicen an\xE1lisis de texto m\xE1s completos y logren una mayor precisi\xF3n en la comprensi\xF3n del contexto, especialmente para datos textuales extensos.'])},answer5:e=>{const{normalize:a}=e;return a(["Una sola llamada API puede procesar hasta 2048 oraciones o textos, lo que facilita un an\xE1lisis de texto extenso en una sola solicitud."])},answer6:e=>{const{normalize:a}=e;return a(["Puede utilizar <code>url</code> o <code>bytes</code> en el campo <code>input</code> de la solicitud de API. Para <code>url</code>, proporcione la URL de la imagen que desea procesar. Para <code>bytes</code>, codifique la imagen en formato base64 e incl\xFAyala en la solicitud. El modelo devolver\xE1 las incrustaciones de la imagen en la respuesta."])},answer7:e=>{const{normalize:a}=e;return a(["Seg\xFAn la tabla de clasificaci\xF3n MTEB, nuestro modelo Base compite estrechamente con el text-embedding-ada-002 de OpenAI, mostrando un rendimiento comparable en promedio. Adem\xE1s, nuestro modelo Base sobresale en varias tareas, incluida la clasificaci\xF3n, clasificaci\xF3n por pares, reclasificaci\xF3n y resumen, superando al modelo de OpenAI."])},answer8:e=>{const{normalize:a}=e;return a(["La transici\xF3n se simplifica, ya que nuestro punto final API, https://api.jina.ai/v1/embeddings, coincide con los esquemas JSON de entrada y salida del modelo text-embeddings-ada-002 de OpenAI. Esta compatibilidad garantiza que los usuarios puedan reemplazar f\xE1cilmente el modelo OpenAI por el nuestro cuando utilizan el punto final de OpenAI."])},answer9:e=>{const{normalize:a}=e;return a([`Los tokens se calculan en funci\xF3n de la longitud del texto y el tama\xF1o de la imagen. Para el texto de la solicitud, los tokens se cuentan de la forma est\xE1ndar. Para la imagen en la solicitud, se llevan a cabo los siguientes pasos:
1. Tama\xF1o del mosaico: cada imagen se divide en mosaicos de tama\xF1o 224x224 p\xEDxeles.
	2. Cobertura: se calcula la cantidad de mosaicos necesarios para cubrir completamente la imagen de entrada. Incluso si las dimensiones de la imagen no son perfectamente divisibles por 224, contaremos mosaicos parciales como mosaicos completos.
	3. Total de mosaicos: el n\xFAmero total de mosaicos que cubren la imagen determina el costo. Por ejemplo, si una imagen tiene 500x500 p\xEDxeles, estar\xEDa cubierta por mosaicos de 3x3, lo que dar\xEDa como resultado 9 mosaicos.
	4. C\xE1lculo de costos: Cada mosaico contribuye al costo final de procesamiento de la imagen. El coste por ficha es de 1000 fichas.

Ejemplo:
Para una imagen con dimensiones de 500x500 p\xEDxeles:

	\u2022 La imagen se divide en mosaicos de 224x224 p\xEDxeles.
	\u2022 El n\xFAmero total de mosaicos requeridos es 3 (horizontal) x 3 (vertical) = 9 mosaicos.
	\u2022 El costo ser\xE1 9*1000 = 9000 tokens`])},question0:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se entrenaron los modelos jina-embeddings-v2?"])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1ntas solicitudes de API puedo realizar por segundo?"])},question17:e=>{const{normalize:a}=e;return a(["\xBFProporcionan modelos para incrustar im\xE1genes o audio?"])},question18:e=>{const{normalize:a}=e;return a(["\xBFSe pueden ajustar los modelos de Jina Embedding con datos privados o de la empresa?"])},question19:e=>{const{normalize:a}=e;return a(["\xBFSe pueden alojar sus puntos finales de forma privada en AWS, Azure o GCP?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 idiomas admiten sus modelos?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la longitud m\xE1xima para la entrada de una sola oraci\xF3n?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el n\xFAmero m\xE1ximo de frases que puedo incluir en una sola solicitud?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo env\xEDo im\xE1genes al modelo jina-clip-v1?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se comparan los modelos de Jina Embeddings con el modelo text-embedding-ada-002 de OpenAI?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 tan fluida es la transici\xF3n desde text-embedding-ada-002 de OpenAI a su soluci\xF3n?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se calculan los tokens cuando se usa jina-clip-v1?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con incrustaciones"])}},feature_8k1:e=>{const{normalize:a}=e;return a(["8192 longitud del token"])},feature_8k_description1:e=>{const{normalize:a}=e;return a(["Ser pionero en el primer modelo de integraci\xF3n de c\xF3digo abierto con una longitud de 8192 tokens, que permite la representaci\xF3n de un cap\xEDtulo completo en un solo vector."])},feature_cheap:e=>{const{normalize:a}=e;return a(["20 veces m\xE1s barato"])},feature_cheap_v1:e=>{const{normalize:a}=e;return a(["5 veces m\xE1s barato"])},feature_cheap_v1_description1:e=>{const{normalize:a}=e;return a(["Comience con pruebas gratuitas y disfrute de una estructura de precios sencilla. Obtenga acceso a potentes incorporaciones por solo el 20 % del coste de OpenAI."])},feature_multilingual:e=>{const{normalize:a}=e;return a(["Ofreciendo modelos biling\xFCes para alem\xE1n-ingl\xE9s, chino-ingl\xE9s, entre otros, ideales para aplicaciones multiling\xFCes."])},feature_on_premises:e=>{const{normalize:a}=e;return a(["Privacidad primero"])},feature_on_premises_description1:e=>{const{normalize:a}=e;return a(["Implemente sin problemas nuestros modelos integrados directamente dentro de su nube privada virtual (VPC). Actualmente es compatible con AWS Sagemaker, con pr\xF3ximas integraciones para Microsoft Azure y Google Cloud Platform. Para implementaciones personalizadas de Kubernetes, comun\xEDquese con nuestro equipo de ventas para obtener asistencia especializada."])},feature_on_premises_description2:e=>{const{normalize:a}=e;return a(["Implemente modelos de Jina Embeddings en AWS Sagemaker y pronto en Microsoft Azure y Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description3:e=>{const{normalize:a}=e;return a(["Implemente modelos de Jina Embeddings en AWS Sagemaker y Microsoft Azure, y pronto en Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description4:e=>{const{normalize:a}=e;return a(["Implemente modelos Jina Embedding y Reranker en las instalaciones utilizando AWS SageMaker, Microsoft Azure o Google Cloud Services, garantizando que sus datos permanezcan seguros bajo su control."])},feature_solid:e=>{const{normalize:a}=e;return a(["Mejor en clase"])},feature_solid_description1:e=>{const{normalize:a}=e;return a(["Desarrollado a partir de nuestra investigaci\xF3n acad\xE9mica de vanguardia y probado rigurosamente con los modelos SOTA para garantizar un rendimiento incomparable."])},feature_top_perform1:e=>{const{normalize:a}=e;return a(["Integraci\xF3n perfecta"])},feature_top_perform_description1:e=>{const{normalize:a}=e;return a(["Totalmente compatible con la API de OpenAI. Se integra sin esfuerzo con m\xE1s de 10 bases de datos vectoriales y sistemas RAG para una experiencia de usuario fluida."])},file_required:e=>{const{normalize:a}=e;return a(["Se requiere archivo"])},file_size_exceed:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Superar el tama\xF1o m\xE1ximo de archivo ",n(o("_size"))])},file_type_not_supported:e=>{const{normalize:a}=e;return a(["Tipo de archivo no compatible"])},fill_example:e=>{const{normalize:a}=e;return a(["Complete un ejemplo"])},float_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones se devuelven como una lista de n\xFAmeros de punto flotante. El m\xE1s com\xFAn y f\xE1cil de usar."])},free:e=>{const{normalize:a}=e;return a(["Gratis"])},generate_api_key_error:e=>{const{normalize:a}=e;return a(["Error al generar la clave API."])},generating_visualization:e=>{const{normalize:a}=e;return a(["Generando visualizaci\xF3n..."])},get_new_key_button:e=>{const{normalize:a}=e;return a(["Obtener nueva clave"])},get_new_key_button_explain:e=>{const{normalize:a}=e;return a(["Optar por una nueva clave resultar\xE1 en la p\xE9rdida del historial de uso asociado con la clave anterior."])},get_new_key_survey:e=>{const{normalize:a}=e;return a(["Complete la encuesta, ay\xFAdenos a comprender su uso y obtenga una nueva clave API gratis."])},includes:e=>{const{normalize:a}=e;return a(["Fichas v\xE1lidas para:"])},index_and_search:e=>{const{normalize:a}=e;return a(["\xCDndice y b\xFAsqueda"])},index_and_search1:e=>{const{normalize:a}=e;return a(["\xCDndice y b\xFAsqueda"])},input:e=>{const{normalize:a}=e;return a(["Pedido"])},input_api_key_error1:e=>{const{normalize:a}=e;return a(["\xA1Su clave API no es v\xE1lida!"])},input_length:e=>{const{normalize:a}=e;return a(["Longitud de entrada"])},input_type:e=>{const{normalize:a}=e;return a(["Insertar como consulta o documento"])},input_type_explain:e=>{const{normalize:a}=e;return a(["Algunos modelos de integraci\xF3n tienen estrategias de integraci\xF3n dedicadas para consultas y documentos. La misma cadena se puede incrustar como una consulta o un documento seg\xFAn su funci\xF3n en su aplicaci\xF3n."])},integrate:e=>{const{normalize:a}=e;return a(["Integrar"])},"jina-clip-v1_description":e=>{const{normalize:a}=e;return a(["Nuestras \xFAltimas incorporaciones multimodales para recuperaci\xF3n de texto e im\xE1genes."])},"jina-colbert-v1-en_description":e=>{const{normalize:a}=e;return a(["ColBERT mejorado con una longitud de token de 8K para tareas de incrustaci\xF3n y reclasificaci\xF3n"])},"jina-embeddings-v2-base-code_description":e=>{const{normalize:a}=e;return a(["Optimizado para b\xFAsqueda de c\xF3digo y cadenas de documentos"])},"jina-embeddings-v2-base-de_description":e=>{const{normalize:a}=e;return a(["Integraciones biling\xFCes alem\xE1n-ingl\xE9s con rendimiento SOTA"])},"jina-embeddings-v2-base-en_description":e=>{const{normalize:a}=e;return a(["A la par con text-embedding-ada002 de OpenAI"])},"jina-embeddings-v2-base-es_description":e=>{const{normalize:a}=e;return a(["Incorporaciones biling\xFCes espa\xF1ol-ingl\xE9s con rendimiento SOTA"])},"jina-embeddings-v2-base-zh_description":e=>{const{normalize:a}=e;return a(["Integraciones biling\xFCes chino-ingl\xE9s con rendimiento SOTA"])},"jina-embeddings-v2-small-en_description":e=>{const{normalize:a}=e;return a(["Optimizado para baja latencia y uso de memoria"])},"jina-reranker-v1-base-en_description":e=>{const{normalize:a}=e;return a(["Nuestro primer modelo de reranker que maximiza la b\xFAsqueda y la relevancia de RAG"])},"jina-reranker-v1-tiny-en_description":e=>{const{normalize:a}=e;return a(["El modelo de reordenaci\xF3n m\xE1s r\xE1pido, m\xE1s adecuado para clasificar una gran cantidad de documentos de manera confiable"])},"jina-reranker-v1-turbo-en_description":e=>{const{normalize:a}=e;return a(["La mejor combinaci\xF3n de velocidad de inferencia r\xE1pida y puntuaciones de relevancia precisas"])},"jina-reranker-v2-base-multilingual_description":e=>{const{normalize:a}=e;return a(["El \xFAltimo y mejor modelo de reranker con soporte multiling\xFCe, llamadas de funciones y b\xFAsqueda de c\xF3digos."])},key:e=>{const{normalize:a}=e;return a(["Clave API"])},key_enter_placeholder:e=>{const{normalize:a}=e;return a(["Por favor ingrese su clave API"])},key_enter_placeholder_to_topup:e=>{const{normalize:a}=e;return a(["Ingresa la clave API que deseas recargar"])},key_to_top_up:e=>{const{normalize:a}=e;return a(["\xBFYa tienes una llave? Ponlo aqu\xED para recargar."])},key_warn:e=>{const{normalize:a}=e;return a(["Aseg\xFArese de guardar su clave API en un lugar seguro. De lo contrario, deber\xE1 generar una nueva clave."])},key_warn_v2:e=>{const{normalize:a}=e;return a(["\xA1Aseg\xFArese de guardar su clave API en un lugar seguro!"])},language_explain:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Este modelo es el que mejor admite el idioma ",n(o("_language")),"."])},last_7_days:e=>{const{normalize:a}=e;return a(["Uso en los \xFAltimos 7 d\xEDas"])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende m\xE1s"])},learn_poster:e=>{const{normalize:a}=e;return a(["Aprende c\xF3mo lo hicimos"])},learning1:e=>{const{normalize:a}=e;return a(["Aprendiendo sobre incrustaciones"])},learning1_description:e=>{const{normalize:a}=e;return a(["\xBFPor d\xF3nde empezar con las incrustaciones? Te tenemos cubierto. Aprenda sobre las incrustaciones desde cero con nuestra gu\xEDa completa."])},length:e=>{const{normalize:a}=e;return a(["Longitud del token"])},manage_billing:e=>{const{normalize:a}=e;return a(["Gestionar factura"])},manage_billing_tip:e=>{const{normalize:a}=e;return a(["Administre su informaci\xF3n de facturaci\xF3n, obtenga facturas y configure la recarga autom\xE1tica."])},manage_quota1:e=>{const{normalize:a}=e;return a(["Clave API y facturaci\xF3n"])},max_file_size:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Tama\xF1o m\xE1ximo permitido: ",n(o("_maxSize")),"."])},maximize_tooltip:e=>{const{normalize:a}=e;return a(["Maximizar este panel"])},mistake_contact:e=>{const{normalize:a}=e;return a(["Si cree que esto es un error, por favor cont\xE1ctenos."])},model_required:e=>{const{normalize:a}=e;return a(["Se requiere modelo"])},more_than_two2:e=>{const{normalize:a}=e;return a(["Introduzca m\xE1s de dos documentos, es decir, m\xE1s de dos l\xEDneas."])},multi_embedding:e=>{const{normalize:a}=e;return a(["Multivector"])},multi_embedding_explain:e=>{const{normalize:a}=e;return a(["Este modelo devolver\xE1 una bolsa de incrustaciones contextualizadas para una entrada determinada. Cada token en la entrada se asigna a un vector en la salida."])},multilingual:e=>{const{normalize:a}=e;return a(["Soporte multiling\xFCe"])},multimodal:e=>{const{normalize:a}=e;return a(["Multimodal"])},multimodal_explain:e=>{const{normalize:a}=e;return a(["Este modelo puede codificar entradas de texto e im\xE1genes, lo que lo hace ideal para tareas de b\xFAsqueda multimodal."])},new:e=>{const{normalize:a}=e;return a(["Nuevo modelo"])},no_data1:e=>{const{normalize:a}=e;return a(["Agrega un par de oraciones para calcular la similitud."])},none:e=>{const{normalize:a}=e;return a(["Ninguno"])},normalized:e=>{const{normalize:a}=e;return a(["Normalizaci\xF3n L2"])},normalized_explain:e=>{const{normalize:a}=e;return a(["Escala la incrustaci\xF3n de modo que su norma euclidiana (L2) se convierta en 1, lo que preserva la direcci\xF3n. Resulta \xFAtil cuando el proceso posterior implica un producto escalar, una clasificaci\xF3n y una visualizaci\xF3n."])},onprem:e=>{const{normalize:a}=e;return a(["Local"])},open_tensorboard:e=>{const{normalize:a}=e;return a(["Visualizador abierto"])},opensource:e=>{const{normalize:a}=e;return a(["SO"])},opensource_explain:e=>{const{normalize:a}=e;return a(["Este modelo es de c\xF3digo abierto y est\xE1 disponible en Hugging Face. Haga clic en este bot\xF3n para ver el modelo en Hugging Face."])},original_documents:e=>{const{normalize:a}=e;return a(["Oraciones para insertar"])},original_documents_hint:e=>{const{normalize:a}=e;return a(["Introduzca aqu\xED sus frases. Cada nueva l\xEDnea se considerar\xE1 una oraci\xF3n/documento independiente."])},output:e=>{const{normalize:a}=e;return a(["Respuesta"])},output_dim:e=>{const{normalize:a}=e;return a(["Dimensiones"])},output_dim_explain:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["La dimensi\xF3n de salida de un vector de incrustaci\xF3n de este modelo es ",n(o("_outputDim")),"."])},output_dimension:e=>{const{normalize:a}=e;return a(["Dimensiones de salida"])},pairwise_test:e=>{const{normalize:a}=e;return a(["Por parejas"])},per_k:e=>{const{normalize:a}=e;return a(["/ 1K fichas"])},per_m:e=>{const{normalize:a}=e;return a(["/ 1 mill\xF3n de fichas"])},please_fill_docs_first:e=>{const{normalize:a}=e;return a(["Primero ingrese algunas oraciones a continuaci\xF3n antes de realizar la b\xFAsqueda."])},please_select_model:e=>{const{normalize:a}=e;return a(["Seleccione un modelo de incrustaci\xF3n o un modelo de Reranker"])},poster:e=>{const{normalize:a}=e;return a(["La evoluci\xF3n de las incrustaciones P\xF3ster"])},poster_description:e=>{const{normalize:a}=e;return a(["Descubra el p\xF3ster ideal para su espacio, con infograf\xEDas cautivadoras o im\xE1genes impresionantes que rastrean la evoluci\xF3n de los modelos de incrustaci\xF3n de texto desde 1950."])},pricing:e=>{const{normalize:a}=e;return a(["Precios de API"])},pricing_desc:e=>{const{normalize:a}=e;return a(["El precio de nuestra API se estructura en funci\xF3n de la cantidad de tokens enviados en las solicitudes. Para Reader API, es la cantidad de tokens en las respuestas. Este modelo de precios es aplicable a todos los productos de la base de b\xFAsqueda de Jina AI: API de incrustaci\xF3n, reclasificaci\xF3n, lector y ajuste autom\xE1tico. Con la misma clave API, tienes acceso a todos los servicios API."])},protectData1:e=>{const{normalize:a}=e;return a(["Los datos y documentos de la solicitud no se utilizan para los modelos de capacitaci\xF3n."])},protectData2:e=>{const{normalize:a}=e;return a(["Cifrado de datos en tr\xE1nsito (TLS 1.2+) y en reposo (AES-GCM 256)."])},protectData3:e=>{const{normalize:a}=e;return a(["Cumple con SOC 2 y GDPR."])},protect_data:e=>{const{normalize:a}=e;return a(["Proteja sus datos"])},public_cloud_integration:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Con <b>",n(o("_numPartners")),"</b> proveedores de servicios en la nube"])},public_cloud_integration_desc:e=>{const{normalize:a}=e;return a(["\xBFSu empresa utiliza AWS o Azure? Luego, implemente directamente nuestros modelos b\xE1sicos de b\xFAsqueda en estas plataformas de su empresa, para que sus datos se mantengan seguros y cumplan con las normas."])},query:e=>{const{normalize:a}=e;return a(["Consulta"])},raise_issue:e=>{const{normalize:a}=e;return a(["Plantear un problema"])},rank_none_description:e=>{const{normalize:a}=e;return a(["No utilices ning\xFAn modelo de reranker."])},read_api_docs:e=>{const{normalize:a}=e;return a(["Leer documentos"])},recharge_threshold:e=>{const{normalize:a}=e;return a(["Umbral de recarga"])},refresh:e=>{const{normalize:a}=e;return a(["Actualizar"])},refresh_key_tooltip1:e=>{const{normalize:a}=e;return a(["Obtenga una nueva clave API gratis"])},refresh_token_count1:e=>{const{normalize:a}=e;return a(["Actualice para obtener tokens disponibles de la clave API actual"])},regenerate:e=>{const{normalize:a}=e;return a(["Regenerado"])},remaining:e=>{const{normalize:a}=e;return a(["Fichas disponibles"])},remaining_left:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Te quedan <b>",n(o("_leftTokens")),"</b> tokens en la clave API a continuaci\xF3n."])},results_as_final_result:e=>{const{normalize:a}=e;return a(["#docs como resultado final"])},results_fed_to_reranker:e=>{const{normalize:a}=e;return a(["#docs enviados al reranker"])},retry:e=>{const{normalize:a}=e;return a(["Rever"])},return_base64:e=>{const{normalize:a}=e;return a(["Base64 (como cadena)"])},return_binary:e=>{const{normalize:a}=e;return a(["Binario (empaquetado como int8)"])},return_float:e=>{const{normalize:a}=e;return a(["Predeterminado (como flotante)"])},return_format:e=>{const{normalize:a}=e;return a(["Formato de incrustaciones"])},return_format_explain:e=>{const{normalize:a}=e;return a(["Adem\xE1s del flotante, puede pedirle que regrese como binario para una recuperaci\xF3n de vectores m\xE1s r\xE1pida o como codificaci\xF3n base64 para una transmisi\xF3n m\xE1s r\xE1pida."])},return_format_title:e=>{const{normalize:a}=e;return a(["Tipo de datos de retorno"])},return_ubinary:e=>{const{normalize:a}=e;return a(["Binario (empaquetado como uint8)"])},right_api_key_to_charge:e=>{const{normalize:a}=e;return a(["Ingrese la clave API correcta para recargar"])},running:e=>{const{normalize:a}=e;return a(["Activo"])},score:e=>{const{normalize:a}=e;return a(["Puntaje"])},search:e=>{const{normalize:a}=e;return a(["Buscar"])},search_hint:e=>{const{normalize:a}=e;return a(["Escriba para buscar dentro de las oraciones que se enumeran a continuaci\xF3n"])},select_embedding_model:e=>{const{normalize:a}=e;return a(["Seleccionar incrustaciones"])},select_rerank_model:e=>{const{normalize:a}=e;return a(["Seleccionar reclasificador"])},show_api_key:e=>{const{normalize:a}=e;return a(["Mostrar clave API"])},size:e=>{const{normalize:a}=e;return a(["Par\xE1metros"])},size_explain:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["La cantidad de par\xE1metros en el modelo es ",n(o("_size")),"; tenga en cuenta que este no es el tama\xF1o del archivo del modelo."])},sleeping:e=>{const{normalize:a}=e;return a(["Inactivo"])},start_batch:e=>{const{normalize:a}=e;return a(["Iniciar la incrustaci\xF3n por lotes"])},start_embedding:e=>{const{normalize:a}=e;return a(["\xCDndice"])},status_explain:e=>{const{normalize:a}=e;return a(["Nuestra arquitectura sin servidor puede descargar ciertos modelos durante per\xEDodos de bajo uso. Para los modelos activos, las respuestas son inmediatas. Los modelos inactivos requieren unos segundos para cargarse tras la solicitud inicial. Despu\xE9s de la activaci\xF3n, las solicitudes posteriores se procesan m\xE1s r\xE1pidamente."])},tax_may_apply:e=>{const{normalize:a}=e;return a(["Dependiendo de su ubicaci\xF3n, es posible que se le cobre en USD, EUR u otras monedas. Se pueden aplicar impuestos."])},text1:e=>{const{normalize:a}=e;return a(["Izquierda"])},text2:e=>{const{normalize:a}=e;return a(["Bien"])},title:e=>{const{normalize:a}=e;return a(["API de incrustaci\xF3n"])},token_example:e=>{const{normalize:a}=e;return a(['Un tweet equivale a aproximadamente 20 tokens, un art\xEDculo de noticias equivale a aproximadamente 1000 tokens y la novela de Charles Dickens "A Tale of Two Cities" tiene m\xE1s de un mill\xF3n de tokens.'])},token_length_explain:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["La longitud m\xE1xima de la secuencia del token de entrada es ",n(o("_tokenLength"))," para este modelo."])},tokens:e=>{const{normalize:a}=e;return a(["Fichas"])},top_up_button:e=>{const{normalize:a}=e;return a(["Recargar clave antigua"])},top_up_button_explain:e=>{const{normalize:a}=e;return a(["La integraci\xF3n de esta clave API ofrece una soluci\xF3n m\xE1s profesional, eliminando la necesidad de cambios frecuentes de clave. Los datos de uso se conservan y son accesibles en cualquier momento."])},top_up_warning_message1:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["A la clave API actual le quedan ",n(o("_remainedTokens"))," tokens y ser\xE1 reemplazada por una nueva clave con tokens ",n(o("_freeTokens")),". Puede continuar usando o recargar la clave anterior si la ha almacenado de forma segura. \xBFComo quieres proceder?"])},top_up_warning_title:e=>{const{normalize:a}=e;return a(["Reemplazar la antigua clave API"])},total_documents:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Progreso de la incrustaci\xF3n: ",n(o("_Processed")),"/",n(o("_Count"))," oraciones."])},tuning:e=>{const{normalize:a}=e;return a(["Afinar"])},turnstile_error:e=>{const{normalize:a}=e;return a(["No podemos generar una clave API porque no pudimos verificar si eres humano."])},turnstile_unsupported:e=>{const{normalize:a}=e;return a(["No podemos generar una clave API porque su navegador no es compatible."])},ubinary_description:e=>{const{normalize:a}=e;return a(["Las incrustaciones se empaquetan como uint8. Mucho m\xE1s eficiente para almacenamiento, b\xFAsqueda y transmisi\xF3n."])},upload:e=>{const{normalize:a}=e;return a(["Subir"])},upload_file:e=>{const{normalize:a}=e;return a(["Haga clic aqu\xED para cargar un archivo"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},usage_amount:e=>{const{normalize:a}=e;return a(["Fichas"])},usage_history:e=>{const{normalize:a}=e;return a(["Uso en los \xFAltimos 7 d\xEDas"])},usage_history_explain:e=>{const{normalize:a}=e;return a(["Los datos no est\xE1n en tiempo real y pueden sufrir un retraso de unos minutos."])},usage_reason:e=>{const{normalize:a}=e;return a(["Descripci\xF3n"])},usage_reason_consume:e=>{const{normalize:a}=e;return a(["Usado"])},usage_reason_purchase:e=>{const{normalize:a}=e;return a(["Comprado"])},usage_reason_trial:e=>{const{normalize:a}=e;return a(["Ensayo"])},usage_rerank:e=>{const{normalize:a}=e;return a(["Uso"])},usage_time:e=>{const{normalize:a}=e;return a(["Fecha y hora"])},vector_database_integration1:e=>{const{normalize:a}=e;return a(["Integraciones"])},vector_database_integration2:e=>{const{normalize:a}=e;return a(["Nuestra API de incrustaci\xF3n est\xE1 integrada de forma nativa con varias bases de datos, almacenes de vectores, marcos RAG y LLMOps de renombre. Para comenzar, simplemente copie y pegue su clave API en cualquiera de las integraciones enumeradas para un comienzo r\xE1pido y sin problemas."])},vector_database_integration3:e=>{const{normalize:a}=e;return a(["Nuestra API Embedding & Reranker est\xE1 integrada de forma nativa con varias bases de datos, almacenes de vectores, RAG y marcos LLMOps de renombre. Para comenzar, simplemente copie y pegue su clave API en cualquiera de las integraciones enumeradas para un comienzo r\xE1pido y sin problemas."])},vector_database_integration_description:e=>{const{normalize:a}=e;return a(["Integre f\xE1cil y perfectamente la API de Jina Embeddings con cualquiera de las bases de datos vectoriales, marcos de orquestaci\xF3n LLM y aplicaciones RAG que aparecen a continuaci\xF3n. Nuestros tutoriales le mostrar\xE1n c\xF3mo."])},view_details:e=>{const{normalize:a}=e;return a(["Ver detalles"])},visualization_example:e=>{const{normalize:a}=e;return a(["Mapear todas las oraciones de esta secci\xF3n a un espacio vectorial 3D"])},visualization_example_you_can:e=>{const{normalize:a}=e;return a(["Utilice nuestra API a continuaci\xF3n, \xA1usted tambi\xE9n puede hacerlo!"])},visualize:e=>{const{normalize:a}=e;return a(["Visualizar"])},visualize_done:e=>{const{normalize:a}=e;return a(["La visualizaci\xF3n ha terminado, ahora puede hacer clic en el bot\xF3n superior para abrir el visualizador."])},wait_for_processing:e=>{const{normalize:a}=e;return a(["Se est\xE1 procesando su petici\xF3n."])},wait_stripe:e=>{const{normalize:a}=e;return a(["Abriendo pago de Stripe, por favor espere"])},what_are_embedding:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 son las incrustaciones?"])},what_are_embedding_answer:e=>{const{normalize:a}=e;return a([`Imag\xEDnese ense\xF1arle a una computadora a captar los significados matizados de palabras y frases. Los m\xE9todos tradicionales, que se basaban en sistemas r\xEDgidos basados \u200B\u200Ben reglas, se quedaron cortos porque el lenguaje es demasiado complejo y fluido. Ingrese a las incrustaciones de texto: una poderosa soluci\xF3n que traduce texto a un lenguaje de n\xFAmeros, espec\xEDficamente, a vectores en un espacio de alta dimensi\xF3n.

Considere las frases "clima soleado" y "cielo despejado". Para nosotros, nos pintan un cuadro similar. A trav\xE9s de la lente de las incrustaciones, estas frases se transforman en vectores num\xE9ricos que residen cerca unos de otros en este espacio multidimensional, capturando su parentesco sem\xE1ntico. Esta cercan\xEDa en el espacio vectorial no se trata solo de que las palabras o frases sean similares; se trata de comprender el contexto, el sentimiento e incluso los matices sutiles del significado.

\xBFPor qu\xE9 es importante este avance? Para empezar, cierra la brecha entre la riqueza del lenguaje humano y la eficiencia computacional de los algoritmos. Los algoritmos destacan por procesar n\xFAmeros, no por interpretar textos. Al convertir texto en vectores, las incrustaciones hacen posible que estos algoritmos "comprendan" y procesen el lenguaje de una manera que antes estaba fuera de su alcance.

Las aplicaciones pr\xE1cticas son amplias y variadas. Ya sea recomendar contenido que resuene con sus intereses, impulsar una IA conversacional que parezca sorprendentemente humana o incluso detectar patrones sutiles en grandes vol\xFAmenes de texto, las incrustaciones son la clave. Permiten que las m\xE1quinas realicen tareas como an\xE1lisis de sentimientos, traducci\xF3n de idiomas y mucho m\xE1s, con una comprensi\xF3n del lenguaje cada vez m\xE1s matizada y refinada.`])},what_is_a_token:e=>{const{normalize:a}=e;return a(['Un token en el procesamiento de textos es una unidad, a menudo una palabra. Por ejemplo, "\xA1Jina AI es genial!" se convierte en cinco fichas, incluida la puntuaci\xF3n.'])},why_do_you_need:e=>{const{normalize:a}=e;return a(["Elegir las incrustaciones adecuadas"])},why_do_you_need_after:e=>{const{normalize:a}=e;return a(["Aprovechando las redes neuronales profundas y los LLM, nuestros modelos integrados representan datos multimodales en un formato optimizado, lo que mejora la comprensi\xF3n de las m\xE1quinas, el almacenamiento eficiente y permite aplicaciones avanzadas de IA. Estas incorporaciones desempe\xF1an un papel crucial en la comprensi\xF3n de los datos, la mejora de la participaci\xF3n del usuario, la superaci\xF3n de las barreras del idioma y la optimizaci\xF3n de los procesos de desarrollo."])},why_do_you_need_before:e=>{const{normalize:a}=e;return a(["Nuestros modelos de integraci\xF3n est\xE1n dise\xF1ados para cubrir diversas aplicaciones de b\xFAsqueda y GenAI."])},why_need_1_description:e=>{const{normalize:a}=e;return a(["Nuestro modelo de integraci\xF3n central, impulsado por JinaBERT, est\xE1 dise\xF1ado para un amplio espectro de aplicaciones. Destaca en la comprensi\xF3n de textos detallados, lo que lo hace ideal para b\xFAsqueda sem\xE1ntica, clasificaci\xF3n de contenido y an\xE1lisis de lenguaje complejo. Su versatilidad es incomparable y admite la creaci\xF3n de herramientas avanzadas de an\xE1lisis de sentimientos, res\xFAmenes de texto y sistemas de recomendaci\xF3n personalizados."])},why_need_1_title:e=>{const{normalize:a}=e;return a(["Incrustaciones de uso general"])},why_need_2_description:e=>{const{normalize:a}=e;return a(["Nuestros modelos biling\xFCes facilitan la comunicaci\xF3n entre idiomas, mejorando las plataformas multiling\xFCes, la atenci\xF3n al cliente global y el descubrimiento de contenido en varios idiomas. Dise\xF1ados para dominar las traducciones alem\xE1n-ingl\xE9s y chino-ingl\xE9s, estos modelos simplifican las interacciones y fomentan la comprensi\xF3n entre diversos grupos ling\xFC\xEDsticos."])},why_need_2_title:e=>{const{normalize:a}=e;return a(["Incorporaciones biling\xFCes"])},why_need_3_description:e=>{const{normalize:a}=e;return a(["Dise\xF1ado para desarrolladores, nuestro modelo de incorporaci\xF3n de c\xF3digo optimiza las tareas de codificaci\xF3n como el resumen, la generaci\xF3n de c\xF3digo y las revisiones autom\xE1ticas. Aumenta la productividad al ofrecer informaci\xF3n m\xE1s profunda sobre las estructuras del c\xF3digo y sugerir mejoras, lo que lo hace esencial para desarrollar complementos IDE avanzados, documentaci\xF3n autom\xE1tica y herramientas de depuraci\xF3n de vanguardia."])},why_need_3_title:e=>{const{normalize:a}=e;return a(["Incorporaciones de c\xF3digo"])},why_need_4_description:e=>{const{normalize:a}=e;return a(["Jina CLIP es nuestro \xFAltimo modelo de incrustaci\xF3n multimodal para im\xE1genes y texto. Una gran mejora con respecto a OpenAI CLIP es que este modelo \xFAnico se puede utilizar para la recuperaci\xF3n de texto-texto, as\xED como para tareas de recuperaci\xF3n de texto-imagen, imagen-texto e imagen-imagen. \xA1As\xED que un modelo, dos modalidades, cuatro direcciones de b\xFAsqueda!"])},why_need_4_title:e=>{const{normalize:a}=e;return a(["Incrustaciones multimodales"])},write_email_here:e=>{const{normalize:a}=e;return a(["Ingrese el correo electr\xF3nico donde desea recibir el enlace de descarga al finalizar."])},you_can_leave:e=>{const{normalize:a}=e;return a(["Puede abandonar esta p\xE1gina y le enviaremos el enlace de descarga una vez finalizada."])}},embeddings:{description:e=>{const{normalize:a}=e;return a(["Nuestras incorporaciones de clase mundial para sistemas de b\xFAsqueda, RAG y agentes."])}},faq:{answer1:e=>{const{normalize:a}=e;return a(["Jina AI se especializa en tecnolog\xEDas de IA multimodales, incluido el ajuste de modelos, el servicio de modelos, el ajuste de avisos y el servicio de avisos. Aprovechamos herramientas avanzadas como Kubernetes y arquitecturas sin servidor para crear soluciones robustas, escalables y listas para producci\xF3n."])},answer10:e=>{const{normalize:a}=e;return a(["Brindamos diferentes opciones de licencia seg\xFAn la naturaleza del proyecto y las necesidades del cliente. Los t\xE9rminos detallados se pueden discutir con nuestro equipo de ventas."])},answer11:e=>{const{normalize:a}=e;return a(["Brindamos servicios a nivel mundial, con nuestra sede central en Berl\xEDn, Europa, y oficinas adicionales en Beijing y Shenzhen."])},answer12:e=>{const{normalize:a}=e;return a(["S\xED, ofrecemos soporte en el sitio, especialmente para clientes ubicados cerca de nuestras oficinas en Berl\xEDn, Beijing y Shenzhen. Para otras ubicaciones, nos esforzamos por brindar el mejor soporte remoto posible y podemos organizar el soporte en el sitio si es necesario."])},answer2:e=>{const{normalize:a}=e;return a(["Nuestra experiencia abarca un amplio espectro, que abarca grandes modelos de lenguaje, texto, imagen, video, comprensi\xF3n de audio, b\xFAsqueda neuronal y arte generativo."])},answer3:e=>{const{normalize:a}=e;return a(["S\xED, nuestras soluciones est\xE1n dise\xF1adas para ser escalables y listas para la producci\xF3n. Creamos nuestras soluciones utilizando tecnolog\xEDas nativas de la nube que permiten un escalado eficiente y un rendimiento confiable en entornos de producci\xF3n."])},answer4:e=>{const{normalize:a}=e;return a(["Nuestros servicios son vers\xE1tiles y adaptables, lo que los hace adecuados para una amplia gama de industrias, que incluyen comercio electr\xF3nico, tecnolog\xEDa legal, marketing digital, juegos, atenci\xF3n m\xE9dica, finanzas y muchas m\xE1s."])},answer5:e=>{const{normalize:a}=e;return a(["Puede ponerse en contacto con nuestro equipo comercial a trav\xE9s del formulario de contacto de esta p\xE1gina. Nos encantar\xEDa discutir los requisitos de su proyecto y c\xF3mo nuestras soluciones pueden ayudar a su negocio."])},answer6:e=>{const{normalize:a}=e;return a(["Brindamos soporte continuo para garantizar el buen funcionamiento de nuestras soluciones. Esto incluye resoluci\xF3n de problemas, actualizaciones peri\xF3dicas y mejoras basadas en sus comentarios y necesidades."])},answer7:e=>{const{normalize:a}=e;return a(["La duraci\xF3n del proyecto var\xEDa seg\xFAn la complejidad y el alcance del proyecto. Despu\xE9s de comprender sus requisitos, podemos proporcionarle una estimaci\xF3n m\xE1s precisa."])},answer8:e=>{const{normalize:a}=e;return a(["La seguridad de los datos es nuestra m\xE1xima prioridad. Nos adherimos a estrictas pol\xEDticas y regulaciones de protecci\xF3n de datos para garantizar que sus datos est\xE9n seguros y confidenciales."])},answer9:e=>{const{normalize:a}=e;return a(["El precio depende de la complejidad y los requisitos del proyecto. Ofrecemos modelos de precios basados \u200B\u200Ben proyectos y de retenci\xF3n. P\xF3ngase en contacto con nuestro equipo de ventas para obtener m\xE1s informaci\xF3n."])},question1:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 se especializa Jina AI?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1les son los t\xE9rminos de licencia para sus soluciones?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es su \xE1rea de servicio?"])},question12:e=>{const{normalize:a}=e;return a(["\xBFOfrecen soporte en el sitio?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFCon qu\xE9 tipos de IA trabaja Jina AI?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFSus soluciones son escalables y est\xE1n listas para la producci\xF3n?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 industrias pueden beneficiarse de las soluciones de Jina AI?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo comenzamos un proyecto con Jina AI?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 apoyo brindan despu\xE9s de implementar una soluci\xF3n?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la duraci\xF3n t\xEDpica de un proyecto?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo protege Jina AI mis datos?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la estructura de precios de sus servicios?"])}},faq_button:e=>{const{normalize:a}=e;return a(["Preguntas m\xE1s frecuentes"])},finetuner:{description:e=>{const{normalize:a}=e;return a(["Ajuste las incrustaciones en datos espec\xEDficos del dominio para una mejor calidad de b\xFAsqueda"])},intro:e=>{const{normalize:a}=e;return a(["Tu compa\xF1\xEDa. Tu informaci\xF3n. tu modelo"])}},finetuner_plus:{description:e=>{const{normalize:a}=e;return a(["Potencie su empresa con soluciones de ajuste fino en las instalaciones"])}},finetuning:{api_key:e=>{const{normalize:a}=e;return a(["Ingrese su clave API."])},back:e=>{const{normalize:a}=e;return a(["Atr\xE1s"])},base_model_selected:e=>{const{normalize:a}=e;return a(["Modelo base seleccionado"])},click_start:e=>{const{normalize:a}=e;return a(["Acepte los t\xE9rminos y comience a realizar ajustes."])},confirm_title:e=>{const{normalize:a}=e;return a(["Confirmar el trabajo de ajuste"])},confirm_your_email:e=>{const{normalize:a}=e;return a(["Vuelva a ingresar su direcci\xF3n de correo electr\xF3nico para confirmar el trabajo de ajuste. Las actualizaciones y el enlace de descarga se enviar\xE1n a este correo electr\xF3nico."])},consent0:e=>{const{normalize:a}=e;return a(["Acepto que se generen datos sint\xE9ticos para el ajuste del modelo seg\xFAn mis instrucciones."])},consent1:e=>{const{normalize:a}=e;return a(["Reconozco que el modelo final y los datos sint\xE9ticos estar\xE1n accesibles p\xFAblicamente en Hugging Face."])},consent2:e=>{const{normalize:a}=e;return a(["Entiendo que esta funci\xF3n est\xE1 en versi\xF3n beta y Jina AI no ofrece garant\xEDas. El precio y la UX pueden cambiar."])},continue:e=>{const{normalize:a}=e;return a(["Continuar"])},cost_1m_token:e=>{const{normalize:a}=e;return a(["Cada trabajo de ajuste consume 1 mill\xF3n de tokens. Aseg\xFArese de tener suficientes tokens o recargue su saldo. Tambi\xE9n puede generar una nueva clave API. Cada clave API viene con 1 mill\xF3n de tokens gratuitos."])},doc_explain:e=>{const{normalize:a}=e;return a(["Describe c\xF3mo deber\xEDa verse un documento coincidente."])},domain_explain:e=>{const{normalize:a}=e;return a(["Proporcione una descripci\xF3n detallada de c\xF3mo se utilizar\xE1n las incrustaciones ajustadas. Esto es esencial para generar datos sint\xE9ticos de alta calidad que mejorar\xE1n el rendimiento de sus incrustaciones."])},domain_explain2:e=>{const{normalize:a}=e;return a(["Hay tres formas de especificar sus requisitos: una instrucci\xF3n general, una URL o una descripci\xF3n del documento de consulta. Elige uno."])},domain_hint:e=>{const{normalize:a}=e;return a(["Describe el dominio que deseas ajustar."])},email_not_match:e=>{const{normalize:a}=e;return a(["Las direcciones de correo no coinciden. Por favor verificar."])},failed_job:e=>{const{normalize:a}=e;return a(["La solicitud de ajuste fall\xF3. Vea el motivo a continuaci\xF3n."])},find_on_huggingface:e=>{const{normalize:a}=e;return a(["Encuentra resultados en Abrazar la cara"])},general_instruction:e=>{const{normalize:a}=e;return a(["O instrucci\xF3n general"])},general_instruction_caption:e=>{const{normalize:a}=e;return a(["Proporcione una descripci\xF3n detallada de c\xF3mo se utilizar\xE1n las incrustaciones ajustadas."])},general_instruction_explain:e=>{const{normalize:a}=e;return a(['Describe tu dominio en texto de formato libre. Puedes imaginarlo como un "mensaje" como en ChatGPT.'])},how_it_works:e=>{const{normalize:a}=e;return a(["Obtenga m\xE1s informaci\xF3n sobre el proceso de ajuste."])},job_acknowledged:e=>{const{normalize:a}=e;return a(["Su trabajo de ajuste ha sido puesto en cola. Recibir\xE1s un correo electr\xF3nico cuando comience el trabajo. El proceso completo suele tardar 20 minutos en completarse."])},new_key:e=>{const{normalize:a}=e;return a(["Obtener nueva clave"])},not_enough_token:e=>{const{normalize:a}=e;return a(["No hay suficientes tokens en esta clave API. Recargue su saldo o utilice una clave API diferente."])},placeholder:e=>{const{normalize:a}=e;return a(["Reclamaciones de seguros de autom\xF3viles"])},preview:e=>{const{normalize:a}=e;return a(["Avance"])},query_doc:e=>{const{normalize:a}=e;return a(["Descripci\xF3n del documento de consulta"])},query_doc_caption:e=>{const{normalize:a}=e;return a(["Describe c\xF3mo se ve la consulta y c\xF3mo se ve el documento coincidente en tu dominio."])},query_explain:e=>{const{normalize:a}=e;return a(["Describe c\xF3mo se ve una consulta."])},reset:e=>{const{normalize:a}=e;return a(["Comenzar de nuevo"])},select_base_model:e=>{const{normalize:a}=e;return a(["Elija un modelo de incrustaci\xF3n base para realizar ajustes."])},select_base_model_explain:e=>{const{normalize:a}=e;return a(["Seleccione un modelo base como punto de partida para el ajuste fino. Normalmente, base-en es una buena opci\xF3n, pero para tareas en otros idiomas, considere utilizar un modelo biling\xFCe."])},start_tuning:e=>{const{normalize:a}=e;return a(["Comience a realizar ajustes"])},url:e=>{const{normalize:a}=e;return a(["O URL de la p\xE1gina web"])},url_caption:e=>{const{normalize:a}=e;return a(["Consulte el contenido de una URL para realizar ajustes."])},url_explain:e=>{const{normalize:a}=e;return a(["URL p\xFAblica de una p\xE1gina web que contiene el contenido que desea ajustar."])},use_url:e=>{const{normalize:a}=e;return a(["Utilice URL en su lugar. Activarlo significa que nos basaremos en el contenido de la p\xE1gina de esa URL para generar datos sint\xE9ticos para realizar ajustes."])},wait_for_processing:e=>{const{normalize:a}=e;return a(["Espere mientras procesamos su solicitud..."])},which_domain:e=>{const{normalize:a}=e;return a(["Dominio de ajuste"])},write_email_explain:e=>{const{normalize:a}=e;return a(["El ajuste fino lleva tiempo. Nos comunicaremos por correo electr\xF3nico sobre el inicio, el progreso, la finalizaci\xF3n y cualquier problema relacionado con su trabajo de ajuste, junto con detalles sobre el modelo ajustado y el conjunto de datos de entrenamiento."])}},footer:{address_beijing:e=>{const{normalize:a}=e;return a(["Beijing, China"])},address_berlin:e=>{const{normalize:a}=e;return a(["Berl\xEDn, Alemania (sede central)"])},address_shenzhen:e=>{const{normalize:a}=e;return a(["Shenzhen, China"])},all_rights_reserved:e=>{const{normalize:a}=e;return a(["Reservados todos los derechos."])},company:e=>{const{normalize:a}=e;return a(["Compa\xF1\xEDa"])},developers:e=>{const{normalize:a}=e;return a(["Desarrolladores"])},docs:e=>{const{normalize:a}=e;return a(["Documentos"])},enterprise:e=>{const{normalize:a}=e;return a(["Empresa"])},get_api_key:e=>{const{normalize:a}=e;return a(["Obtenga la clave API de Jina AI"])},offices:e=>{const{normalize:a}=e;return a(["Oficinas"])},power_users:e=>{const{normalize:a}=e;return a(["Usuarios avanzados"])},privacy:e=>{const{normalize:a}=e;return a(["Privacidad"])},privacy_policy:e=>{const{normalize:a}=e;return a(["pol\xEDtica de privacidad"])},privacy_settings:e=>{const{normalize:a}=e;return a(["Administrar cookies"])},sefo:e=>{const{normalize:a}=e;return a(["Fundaci\xF3n de b\xFAsqueda"])},status:e=>{const{normalize:a}=e;return a(["Estado de la API"])},tc:e=>{const{normalize:a}=e;return a(["T\xE9rminos y condiciones"])},tc1:e=>{const{normalize:a}=e;return a(["T\xE9rminos"])}},get_new_key:e=>{const{normalize:a}=e;return a(["Obtenga su clave API"])},github:{stars:e=>{const{normalize:a}=e;return a(["Estrellas"])}},header:{about_us:e=>{const{normalize:a}=e;return a(["Sobre nosotros"])},company:e=>{const{normalize:a}=e;return a(["Compa\xF1\xEDa"])},contact_us:e=>{const{normalize:a}=e;return a(["Contactar con ventas"])},developers_others:e=>{const{normalize:a}=e;return a(["M\xE1s herramientas para desarrolladores"])},enterprise_others:e=>{const{normalize:a}=e;return a(["M\xE1s herramientas empresariales"])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_developers_description:e=>{const{normalize:a}=e;return a(["Experimente una pila integral de IA multimodal de c\xF3digo abierto dise\xF1ada para desarrolladores."])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para Empresas"])},for_enterprise_description:e=>{const{normalize:a}=e;return a(["Descubra estrategias escalables de IA multimodal dise\xF1adas para satisfacer las necesidades comerciales."])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},for_power_users_description:e=>{const{normalize:a}=e;return a(["Utilice nuestras herramientas multimodales optimizadas para mejorar su productividad."])},internship1:e=>{const{normalize:a}=e;return a(["Programa de pr\xE1cticas"])},jobs:e=>{const{normalize:a}=e;return a(["\xDAnete a nosotros"])},join_discord:e=>{const{normalize:a}=e;return a(["\xDAnete a nuestra comunidad de Discord"])},logos:e=>{const{normalize:a}=e;return a(["Descargar logotipo"])},news:e=>{const{normalize:a}=e;return a(["Noticias"])},open_day:e=>{const{normalize:a}=e;return a(["D\xEDa abierto"])},open_in_full:e=>{const{normalize:a}=e;return a(["Mostrar todos los productos empresariales en una nueva ventana"])},power_users_others:e=>{const{normalize:a}=e;return a(["M\xE1s herramientas para usuarios avanzados"])},products:e=>{const{normalize:a}=e;return a(["Productos"])}},hub:{description:e=>{const{normalize:a}=e;return a(["Comparta y descubra componentes b\xE1sicos para aplicaciones de IA multimodal"])}},huggingface:{sentence_similarity:e=>{const{normalize:a}=e;return a(["incrustaci\xF3n de oraciones"])},updated_about:e=>{const{normalize:a}=e;return a(["actualizado sobre"])}},impact_snapshots:{project1:e=>{const{normalize:a}=e;return a(["B\xFAsqueda de alta precisi\xF3n habilitada dentro de datos de malla 3D utilizando informaci\xF3n de nube de puntos."])},project10:e=>{const{normalize:a}=e;return a(["Aprovech\xF3 la visi\xF3n artificial para mejorar la accesibilidad digital de los sitios web gubernamentales."])},project11:e=>{const{normalize:a}=e;return a(["LLM ajustado para una firma de consultor\xEDa para optimizar el an\xE1lisis de datos financieros."])},project12:e=>{const{normalize:a}=e;return a(["Estrategias de marketing avanzadas mediante el ajuste fino de los modelos de texto a imagen para la transferencia de estilo."])},project2:e=>{const{normalize:a}=e;return a(["Dise\xF1\xE9 un motor de b\xFAsqueda basado en contenido para cortometrajes de animaci\xF3n."])},project3:e=>{const{normalize:a}=e;return a(["Tasas de conversi\xF3n de comercio electr\xF3nico mejoradas mediante el ajuste fino de los modelos integrados."])},project4:e=>{const{normalize:a}=e;return a(["Realic\xE9 ajustes r\xE1pidos para aumentar la eficiencia de una empresa de consultor\xEDa empresarial."])},project5:e=>{const{normalize:a}=e;return a(["Pionero en la comprensi\xF3n de la escena del juego y la anotaci\xF3n autom\xE1tica para una empresa de juegos l\xEDder."])},project6:e=>{const{normalize:a}=e;return a(["Implement\xE9 la expansi\xF3n de entrada en tiempo real para una empresa de chatbot, mejorando la experiencia del usuario."])},project7:e=>{const{normalize:a}=e;return a(["Revolucion\xF3 la tecnolog\xEDa legal al permitir una b\xFAsqueda eficiente en documentos legales extensos."])},project8:e=>{const{normalize:a}=e;return a(["Apoy\xF3 un servicio de arte generativo de alto rendimiento para operaciones a gran escala."])},project9:e=>{const{normalize:a}=e;return a(["Realizaci\xF3n de miner\xEDa y modelado de procesos utilizando modelos de lenguaje avanzado."])}},inference:{description:e=>{const{normalize:a}=e;return a(["Modelos multimodales de \xFAltima generaci\xF3n disponibles para inferencia"])}},integrations:{embedding:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},reranker:e=>{const{normalize:a}=e;return a(["reclasificador"])},which_to_go:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["\xBFCu\xE1l integrar con ",n(o("_vendor")),"?"])}},internship_faq:{answer1:e=>{const{normalize:a}=e;return a(["Licenciatura, maestr\xEDa y doctorado. Se alienta a los estudiantes de todo el mundo, con inter\xE9s en campos como la investigaci\xF3n, la ingenier\xEDa, el marketing y las ventas, a postularse. Tambi\xE9n damos la bienvenida a pasant\xEDas no t\xE9cnicas en marketing, ventas, asistencia ejecutiva y m\xE1s. Estamos buscando personas apasionadas listas para ser pioneros en la IA multimodal con nosotros."])},answer10:e=>{const{normalize:a}=e;return a(["S\xED, nuestro programa de pr\xE1cticas ofrece una remuneraci\xF3n competitiva."])},answer11:e=>{const{normalize:a}=e;return a(["Como pasante de Jina AI, obtendr\xE1 experiencia pr\xE1ctica trabajando en proyectos desafiantes, aprender\xE1 de expertos de la industria, ser\xE1 parte de una comunidad vibrante y tendr\xE1 la oportunidad de hacer contribuciones reales a nuestro trabajo pionero en AI multimodal."])},answer2:e=>{const{normalize:a}=e;return a(["Las pasant\xEDas deben llevarse a cabo en el sitio en una de nuestras oficinas, que se encuentran en Berl\xEDn, Beijing y Shenzhen."])},answer3:e=>{const{normalize:a}=e;return a(["S\xED, Jina AI ofrece asistencia razonable en el proceso de visa para los solicitantes seleccionados."])},answer4:e=>{const{normalize:a}=e;return a(["S\xED, Jina AI brinda una cantidad razonable de cobertura de costo de vida para los pasantes durante el per\xEDodo de pasant\xEDa."])},answer5:e=>{const{normalize:a}=e;return a(["S\xED, es posible trabajar en su tesis de maestr\xEDa durante su pasant\xEDa en Jina AI, generalmente aplicable a estudiantes en universidades alemanas. Sin embargo, debe tener una comunicaci\xF3n previa y acuerdo del supervisor de su universidad. Tenga en cuenta que no ayudamos a los estudiantes a encontrar asesores."])},answer6:e=>{const{normalize:a}=e;return a(["El proceso de solicitud incluye enviar su formulario de solicitud, un curr\xEDculum, una carta de presentaci\xF3n que exprese su inter\xE9s y motivaci\xF3n, y cualquier enlace profesional relevante como GitHub o LinkedIn. Evaluamos a los candidatos en funci\xF3n de su desempe\xF1o durante la entrevista y su desempe\xF1o en su universidad."])},answer7:e=>{const{normalize:a}=e;return a(["S\xED, los pasantes exitosos pueden recibir una carta de recomendaci\xF3n al final de su pasant\xEDa, firmada por nuestro CEO."])},answer8:e=>{const{normalize:a}=e;return a(["La duraci\xF3n de la pasant\xEDa var\xEDa seg\xFAn el rol y el proyecto. Sin embargo, por lo general oscila entre tres y seis meses."])},answer9:e=>{const{normalize:a}=e;return a(["S\xED, aceptamos solicitudes de todos los antecedentes acad\xE9micos. Valoramos su pasi\xF3n y compromiso por aprender tanto como su experiencia previa."])},question1:e=>{const{normalize:a}=e;return a(["\xBFQui\xE9n puede solicitar el programa de pasant\xEDas de Jina AI?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFEs esta una pasant\xEDa remunerada?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 oportunidades tendr\xE9 como pasante de Jina AI?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFD\xF3nde se realizar\xE1 la pasant\xEDa?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFJina AI ayuda con los procesos de visa?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFJina AI proporciona asignaciones o beneficios para los pasantes?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFPuedo trabajar en mi tesis de maestr\xEDa durante la pasant\xEDa en Jina AI?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 consiste el proceso de solicitud?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFJina AI proporciona alguna carta de recomendaci\xF3n posterior a la pasant\xEDa?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la duraci\xF3n de la pasant\xEDa?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFPuedo presentar una solicitud si no tengo experiencia previa en IA?"])}},internship_page:{about_internship_program:e=>{const{normalize:a}=e;return a(["Acerca del programa de pasant\xEDas"])},about_internship_program_desc1:e=>{const{normalize:a}=e;return a(["Estamos emocionados de ofrecer esta oportunidad \xFAnica para que personas talentosas se unan a nuestro equipo din\xE1mico y contribuyan a proyectos innovadores en el campo de la Inteligencia Artificial. Esta pasant\xEDa est\xE1 dise\xF1ada para brindarle una valiosa experiencia pr\xE1ctica, tutor\xEDa y exposici\xF3n a tecnolog\xEDas de vanguardia que est\xE1n dando forma al futuro de la IA."])},about_internship_program_desc2:e=>{const{normalize:a}=e;return a(["En Jina AI, entendemos la importancia de nutrir y aprovechar el talento joven. Reconocemos que los pasantes aportan nuevas perspectivas, entusiasmo y creatividad a la mesa, fortaleciendo a nuestro equipo con nuevas ideas y enfoques. Al proporcionar pasant\xEDas, nuestro objetivo es fomentar el crecimiento de los futuros l\xEDderes en la industria de la IA al tiempo que les ofrecemos una experiencia del mundo real en un entorno estimulante y de apoyo."])},alumni:e=>{const{normalize:a}=e;return a(["ALUMNOS"])},alumni_network:e=>{const{normalize:a}=e;return a(["Nuestra pr\xF3spera red de antiguos alumnos"])},application:e=>{const{normalize:a}=e;return a(["Solicitud"])},application_desc:e=>{const{normalize:a}=e;return a(["Emb\xE1rquese en un viaje transformador con Jina AI. Nuestro completo programa de pasant\xEDas invita a todas las mentes apasionadas que aspiran a dar forma al futuro de la inteligencia artificial. \xDAnase a nosotros para obtener experiencia en el mundo real, trabajar en proyectos desafiantes y colaborar con algunas de las mentes m\xE1s brillantes de la industria de la IA."])},apply:e=>{const{normalize:a}=e;return a(["Aplica ya"])},autumn:e=>{const{normalize:a}=e;return a(["Oto\xF1o"])},description:e=>{const{normalize:a}=e;return a(["Convocatoria mundial para estudiantes: Pr\xE1cticas en investigaci\xF3n, ingenier\xEDa, marketing, ventas y m\xE1s."])},dev_rel_intern:e=>{const{normalize:a}=e;return a(["Pasante de Relaciones con Desarrolladores"])},enthusiastic:e=>{const{normalize:a}=e;return a(["ENTUSIASTA"])},explore_stories_from_our_interns:e=>{const{normalize:a}=e;return a(["Explore las historias de nuestros pasantes"])},explore_stories_from_our_interns1:e=>{const{normalize:a}=e;return a(["Insp\xEDrate con los viajes de nuestros pasantes"])},innovative:e=>{const{normalize:a}=e;return a(["INNOVADOR"])},intern_work1:e=>{const{normalize:a}=e;return a(["Modelos LLM ajustados para mejores incrustaciones"])},intern_work2:e=>{const{normalize:a}=e;return a(["Explor\xF3 el potencial de recuperaci\xF3n de generaci\xF3n aumentada"])},intern_work3:e=>{const{normalize:a}=e;return a(["Public\xF3 un art\xEDculo sobre el tema de las incrustaciones de oraciones."])},intern_work4:e=>{const{normalize:a}=e;return a(["Inyectar vitalidad juvenil continua al equipo."])},intern_work5:e=>{const{normalize:a}=e;return a(["T\xE9cnicas de cuantificaci\xF3n comparadas para comprimir LLM"])},intern_work6:e=>{const{normalize:a}=e;return a(["Creaci\xF3n y promoci\xF3n de campa\xF1as atractivas para PromptPerfect"])},recruiting_and_administrative_intern:e=>{const{normalize:a}=e;return a(["Practicante de Reclutamiento y Administraci\xF3n"])},self_motivated:e=>{const{normalize:a}=e;return a(["AUTO MOTIVADO"])},software_engineer_intern:e=>{const{normalize:a}=e;return a(["Pasante de ingenier\xEDa de software"])},spring:e=>{const{normalize:a}=e;return a(["Primavera"])},submit_application:e=>{const{normalize:a}=e;return a(["Comienza tu aventura con Jina AI"])},subtitle:e=>{const{normalize:a}=e;return a(["Nuestro programa de pasant\xEDas de tiempo completo brinda experiencia laboral pr\xE1ctica a trav\xE9s de proyectos de pasant\xEDas bien dise\xF1ados en una amplia gama de alcances."])},subtitle1:e=>{const{normalize:a}=e;return a(["Convocatoria mundial para estudiantes: Pasantes en investigaci\xF3n, ingenier\xEDa, marketing, ventas y m\xE1s para ser pioneros juntos en la IA multimodal."])},summer:e=>{const{normalize:a}=e;return a(["Verano"])},title:e=>{const{normalize:a}=e;return a(["Programa de pasant\xEDas"])},who_do_we_look_for:e=>{const{normalize:a}=e;return a(["\xBFA qui\xE9n buscamos?"])},who_do_we_look_for_desc:e=>{const{normalize:a}=e;return a(["Valoramos la diversidad y alentamos a los solicitantes de diversos perfiles y antecedentes a unirse a nuestro Programa de pasant\xEDas. Las oportunidades de pasant\xEDas se ofrecen en varios departamentos, incluidos ingenier\xEDa, dise\xF1o, gesti\xF3n de productos, gesti\xF3n de ventas y cuentas, marketing y gesti\xF3n comunitaria."])},winter:e=>{const{normalize:a}=e;return a(["Invierno"])}},jcloud:{description:e=>{const{normalize:a}=e;return a(["Implemente un proyecto local como un servicio en la nube. Radicalmente f\xE1cil, sin sorpresas desagradables."])}},jerboa:{description:e=>{const{normalize:a}=e;return a(["Un perfeccionador experimental para LLM de c\xF3digo abierto"])}},jina:{description:e=>{const{normalize:a}=e;return a(["Cree aplicaciones de IA multimodales en la nube"])}},jina_chat:{description:e=>{const{normalize:a}=e;return a(["M\xE1s modalidad, m\xE1s memoria, menos costo"])},example_1:e=>{const{normalize:a}=e;return a(["\xBFQui\xE9n eres?"])},example_2:e=>{const{normalize:a}=e;return a(["Soy un servicio de chat LLM creado por Jina AI"])}},lab_dialog:{GlobalQA:{description:e=>{const{normalize:a}=e;return a(["Presione la tecla '/' en cualquier p\xE1gina para abrir el cuadro de preguntas. Escriba su consulta y presione 'Entrar' para recibir respuestas directamente relacionadas con el contenido de la p\xE1gina. Esta caracter\xEDstica est\xE1 impulsada por PromptPerfect."])},title:e=>{const{normalize:a}=e;return a(["RAG en la p\xE1gina"])}},Recommender:{description:e=>{const{normalize:a}=e;return a(["Abra el cuadro de recomendaci\xF3n en cualquier p\xE1gina de noticias con 'Shift+2'. Seleccione el modelo de reranker para descubrir los 5 art\xEDculos principales relacionados con esa p\xE1gina de noticias. Disfrute de esta funci\xF3n en tiempo real, impulsada por nuestra API Reranker."])},title:e=>{const{normalize:a}=e;return a(["Art\xEDculo relacionado"])}},SceneXplainTooltip:{description:e=>{const{normalize:a}=e;return a(["Pase el cursor sobre cualquier imagen en las p\xE1ginas de noticias o en nuestro cat\xE1logo de redacci\xF3n para revelar la descripci\xF3n de esa imagen. Las descripciones las calcula previamente SceneXplain y las incrustan en el atributo ALT de la imagen para mayor accesibilidad."])},title:e=>{const{normalize:a}=e;return a(["Subt\xEDtulos de im\xE1genes"])}},explain:e=>{const{normalize:a}=e;return a(["Descubra funciones ocultas en nuestro sitio web"])}},landing_page:{also_available_on:e=>{const{normalize:a}=e;return a(["Tambi\xE9n disponible en los mercados."])},also_available_on1:e=>{const{normalize:a}=e;return a(["Disponible en los mercados de su nube empresarial"])},ask_how_your_question:e=>{const{normalize:a}=e;return a(["Por favor describe tu problema"])},autotune:e=>{const{normalize:a}=e;return a(["Ajuste fino autom\xE1tico"])},badge:{v2:e=>{const{normalize:a}=e;return a(["Lanzamiento v2!"])}},build_js:e=>{const{normalize:a}=e;return a(["Construir con JavaScript"])},build_python:e=>{const{normalize:a}=e;return a(["Construir con Python"])},checkout_our_solution_for_you:e=>{const{normalize:a}=e;return a(["Descubra nuestra soluci\xF3n a su medida"])},coming_soon:e=>{const{normalize:a}=e;return a(["Muy pronto"])},contact_sales:e=>{const{normalize:a}=e;return a(["Contacto"])},copied_to_clipboard:e=>{const{normalize:a}=e;return a(["Copiado al portapapeles"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},developers:e=>{const{normalize:a}=e;return a(["Desarrolladores"])},developers_desc:e=>{const{normalize:a}=e;return a(["Libere todo el poder de la IA multimodal con tecnolog\xEDas nativas de la nube de vanguardia e infraestructura de c\xF3digo abierto."])},download_pdf:e=>{const{normalize:a}=e;return a(["Descargar PDF"])},embedding_desc1:e=>{const{normalize:a}=e;return a(["El primer modelo de incrustaci\xF3n de c\xF3digo abierto del mundo con una longitud de 8192 tokens, que coincide con text-embedding-ada002 de OpenAI en Massive Text Embedding Benchmark (MTEB)."])},embedding_paper_desc:e=>{const{normalize:a}=e;return a(["Jina Embeddings constituye un conjunto de modelos de incrustaci\xF3n de oraciones de alto rendimiento, expertos en traducir varias entradas textuales en representaciones num\xE9ricas, capturando as\xED la esencia sem\xE1ntica del texto. Si bien estos modelos no est\xE1n dise\xF1ados exclusivamente para la generaci\xF3n de texto, se destacan en aplicaciones como la recuperaci\xF3n densa y la similitud textual sem\xE1ntica. Este documento detalla el desarrollo de Jina Embeddings, comenzando con la creaci\xF3n de un conjunto de datos de pares y triples de alta calidad. Subraya el papel crucial de la limpieza de datos en la preparaci\xF3n del conjunto de datos, brinda informaci\xF3n detallada sobre el proceso de capacitaci\xF3n del modelo y concluye con una evaluaci\xF3n integral del rendimiento utilizando Massive Textual Embedding Benchmark (MTEB)."])},embedding_paper_title:e=>{const{normalize:a}=e;return a(["Jina Embeddings: un novedoso conjunto de modelos de incrustaci\xF3n de oraciones de alto rendimiento"])},embeddings:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},enterprise:e=>{const{normalize:a}=e;return a(["Empresa"])},enterprise_desc:e=>{const{normalize:a}=e;return a(["Impulse su negocio con soluciones de IA multimodal escalables, seguras y personalizadas."])},enterprise_desc_v2:e=>{const{normalize:a}=e;return a(["Pruebe nuestros modelos de integraci\xF3n de clase mundial para mejorar sus sistemas de b\xFAsqueda y RAG. \xA1Empiece con una prueba gratuita!"])},enterprise_desc_v3:e=>{const{normalize:a}=e;return a(["Desarrollamos una base de b\xFAsqueda de vanguardia para soluciones RAG y b\xFAsqueda empresarial de alta calidad. \xA1Empiece con una prueba gratuita!"])},error:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Hubo un problema con la operaci\xF3n de b\xFAsqueda: ",n(o("mensaje"))])},find_your_portal:e=>{const{normalize:a}=e;return a(["Encuentre su Portal"])},finding_faq:e=>{const{normalize:a}=e;return a(["Generando respuestas basadas en el conocimiento de las preguntas frecuentes a continuaci\xF3n"])},for:e=>{const{normalize:a}=e;return a(["Para"])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para empresas"])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},get_api_now:e=>{const{normalize:a}=e;return a(["API"])},get_started:e=>{const{normalize:a}=e;return a(["Empezar"])},go_to_product_homepage:e=>{const{normalize:a}=e;return a(["Ir a la p\xE1gina de inicio del producto"])},how_to:e=>{const{normalize:a}=e;return a(["C\xF3mo"])},include_experiment:e=>{const{normalize:a}=e;return a(["Incluye nuestros proyectos experimentales y archivados en la soluci\xF3n."])},join_community:e=>{const{normalize:a}=e;return a(["Comunidad"])},learn_more_embeddings:e=>{const{normalize:a}=e;return a(["M\xE1s informaci\xF3n sobre incrustaciones"])},learn_more_reader:e=>{const{normalize:a}=e;return a(["M\xE1s informaci\xF3n sobre el lector"])},learn_more_reranker:e=>{const{normalize:a}=e;return a(["M\xE1s informaci\xF3n sobre el cambio de rango"])},llm:e=>{const{normalize:a}=e;return a(["Modelos de inclusi\xF3n LLM"])},llm_desc:e=>{const{normalize:a}=e;return a(["Proporcionamos una colecci\xF3n de modelos de incrustaci\xF3n de oraciones de alto rendimiento, con entre 35 millones y 6 mil millones de par\xE1metros. Son excelentes para mejorar la b\xFAsqueda neuronal, la reclasificaci\xF3n, la similitud de oraciones, las recomendaciones, etc. \xA1Prep\xE1rate para mejorar tu experiencia de IA!"])},mentioned_products:e=>{const{normalize:a}=e;return a(["Productos mencionados:"])},mmstack:e=>{const{normalize:a}=e;return a(["Stack multimodal"])},mmstack_desc:e=>{const{normalize:a}=e;return a(["A lo largo de los a\xF1os, hemos desarrollado una variedad de software de c\xF3digo abierto para ayudar a los desarrolladores a crear mejores aplicaciones GenAI y de b\xFAsqueda m\xE1s r\xE1pido."])},more:e=>{const{normalize:a}=e;return a(["M\xE1s"])},multimodal:e=>{const{normalize:a}=e;return a(["Multimodal"])},multimodal_ai:e=>{const{normalize:a}=e;return a(["IA multimodal"])},new:e=>{const{normalize:a}=e;return a(["Nuevo"])},newsroom:e=>{const{normalize:a}=e;return a(["Sala de prensa"])},"on-prem-deploy":e=>{const{normalize:a}=e;return a(["Implementaci\xF3n local"])},"on-premises":e=>{const{normalize:a}=e;return a(["En las instalaciones"])},opensource:e=>{const{normalize:a}=e;return a(["C\xF3digo abierto"])},our_customer:e=>{const{normalize:a}=e;return a(["Nuestros clientes"])},our_customer_explain:e=>{const{normalize:a}=e;return a(["Empresas de todos los tama\xF1os conf\xEDan en la Fundaci\xF3n de b\xFAsqueda de Jina AI para potenciar sus herramientas y productos; usted tambi\xE9n puede hacerlo."])},our_publications:e=>{const{normalize:a}=e;return a(["Nuestras Publicaciones"])},parameters:e=>{const{normalize:a}=e;return a(["Par\xE1metros"])},podcast:e=>{const{normalize:a}=e;return a(["Podcast"])},power_users:e=>{const{normalize:a}=e;return a(["Usuarios avanzados"])},power_users_desc:e=>{const{normalize:a}=e;return a(["Ingenier\xEDa autom\xE1tica r\xE1pida para su productividad diaria."])},powered_by_promptperfect:e=>{const{normalize:a}=e;return a(['Desarrollado por la funci\xF3n "Optimizaci\xF3n de solicitud" y "Solicitud como servicio" de PromptPerfect'])},pricing:e=>{const{normalize:a}=e;return a(["Precios"])},proposing_solution:e=>{const{normalize:a}=e;return a(["Proponiendo una soluci\xF3n basada en los productos Jina AI..."])},read_more:e=>{const{normalize:a}=e;return a(["Leer m\xE1s"])},reader:e=>{const{normalize:a}=e;return a(["Lector"])},require_full_question:e=>{const{normalize:a}=e;return a(["Describe tu problema con m\xE1s detalles."])},reranker:e=>{const{normalize:a}=e;return a(["reclasificador"])},researcher_desc:e=>{const{normalize:a}=e;return a(["Comprenda c\xF3mo se capacit\xF3 nuestra base de b\xFAsqueda desde cero, consulte nuestras \xFAltimas publicaciones. \xA1Conozca a nuestro equipo en EMNLP, SIGIR, ICLR, NeurIPS e ICML!"])},researchers:e=>{const{normalize:a}=e;return a(["Investigadores"])},sdk:e=>{const{normalize:a}=e;return a(["SDK"])},sdk_desc:e=>{const{normalize:a}=e;return a(["\xBFQuiere crear aplicaciones AIGC de alto nivel con las API de PromptPerfect, SceneXplain, BestBanner, JinaChat y Rationale? \xA1Le tenemos cubierto! Pruebe nuestro SDK f\xE1cil de usar y comience en minutos."])},sdk_docs:e=>{const{normalize:a}=e;return a(["Leer documentos"])},sdk_example:e=>{const{normalize:a}=e;return a(["Ejemplo"])},search_foundation:e=>{const{normalize:a}=e;return a(["Fundaci\xF3n de b\xFAsqueda"])},source_code:e=>{const{normalize:a}=e;return a(["C\xF3digo fuente"])},starter_kit:e=>{const{normalize:a}=e;return a(["Kit de inicio"])},supercharged1:e=>{const{normalize:a}=e;return a(["Sobrealimentado."])},tokenizer:e=>{const{normalize:a}=e;return a(["Tokenizador"])},trusted_by:e=>{const{normalize:a}=e;return a(["DE CONFIANZA PARA"])},try_it_for_free:e=>{const{normalize:a}=e;return a(["Pru\xE9balo gratis, no se requiere tarjeta de cr\xE9dito"])},try_our_saas:e=>{const{normalize:a}=e;return a(["Pruebe nuestra soluci\xF3n alojada, un reemplazo directo de la API integrada de OpenAI."])},your_portal_to:e=>{const{normalize:a}=e;return a(["Tu Portal a"])},your_search_foundation1:e=>{const{normalize:a}=e;return a(["Tu base de b\xFAsqueda"])}},langchain_serve:{description:e=>{const{normalize:a}=e;return a(["Aplicaciones Langchain en producci\xF3n con Jina y FastAPI"])}},news_page:{back_to_newsroom:e=>{const{normalize:a}=e;return a(["Volver a la sala de prensa"])},categories:e=>{const{normalize:a}=e;return a(["Categor\xEDas"])},copy_link:e=>{const{normalize:a}=e;return a(["Copia el enlace a esta secci\xF3n."])},in_this_article:e=>{const{normalize:a}=e;return a(["En este articulo"])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende m\xE1s"])},news_not_found:e=>{const{normalize:a}=e;return a(["Art\xEDculo no encontrado"])},redirect_to_news:e=>{const{normalize:a}=e;return a(["Redirigiendo a la sala de redacci\xF3n en 5 segundos..."])}},newsroom_page:{academic:e=>{const{normalize:a}=e;return a(["Acad\xE9mico"])},academic_research:e=>{const{normalize:a}=e;return a(["Publicaciones Acad\xE9micas"])},author:e=>{const{normalize:a}=e;return a(["Filtrar por autor"])},description:e=>{const{normalize:a}=e;return a(["Lea las \xFAltimas noticias y actualizaciones de Jina AI."])},description1:e=>{const{normalize:a}=e;return a(["Creando innovaciones en IA, palabra a palabra."])},engineering_group:e=>{const{normalize:a}=e;return a(["Grupo de Ingenier\xEDa"])},engineering_group_date:e=>{const{normalize:a}=e;return a(["31 mayo, 2021"])},minutes_read:e=>{const{normalize:a}=e;return a(["minutos de lectura"])},most_recent_articles:e=>{const{normalize:a}=e;return a(["Art\xEDculos m\xE1s recientes"])},news_description:e=>{const{normalize:a}=e;return a(['Para Jina 2.0, escuchamos a la comunidad. Verdaderamente, profundamente escuchado. "\xBFCu\xE1les son tus puntos d\xE9biles?" preguntamos, esperando ansiosamente comentarios valiosos'])},news_title:e=>{const{normalize:a}=e;return a(["Buscar todas las cosas: estamos organizando un concurso MEME para Jina 2.0"])},photos:e=>{const{normalize:a}=e;return a(["Fotos"])},product:e=>{const{normalize:a}=e;return a(["Filtrar por producto"])},search:e=>{const{normalize:a}=e;return a(["Buscar por t\xEDtulo"])},tech_blog:e=>{const{normalize:a}=e;return a(["Blog de tecnolog\xEDa"])},title:e=>{const{normalize:a}=e;return a(["Sala de prensa"])},top_stories:e=>{const{normalize:a}=e;return a(["Historias destacadas"])}},notice:e=>{const{normalize:a}=e;return a(['\u{1F389} \xA1Nuestro primer libro, "B\xFAsqueda neuronal: del prototipo a la producci\xF3n con Jina" sale oficialmente hoy!'])},open_day:{description:e=>{const{normalize:a}=e;return a(["Una oportunidad exclusiva para obtener una visi\xF3n privilegiada de Jina AI."])},engage:e=>{const{normalize:a}=e;return a(["Recomendamos encarecidamente un di\xE1logo interactivo durante todo el d\xEDa. El intercambio de pensamientos y perspectivas es invaluable para nosotros. Las colaboraciones potenciales derivadas de estas discusiones podr\xEDan contribuir significativamente a un futuro m\xE1s integrado e innovador."])},engage_title:e=>{const{normalize:a}=e;return a(["Participa con nosotros"])},experience:e=>{const{normalize:a}=e;return a(["Hemos organizado un recorrido inmersivo de tres horas para nuestros hu\xE9spedes, disponible en alem\xE1n, ingl\xE9s, franc\xE9s, espa\xF1ol, chino y ruso. El recorrido cubre una mirada en profundidad a nuestros avances en IA multimodal, nuestra perspectiva sobre el panorama de la IA, seguido de un examen detallado de proyectos espec\xEDficos. Concluiremos con una discusi\xF3n grupal para facilitar el intercambio de ideas y puntos de vista. Una opci\xF3n de almuerzo tambi\xE9n est\xE1 disponible bajo petici\xF3n."])},experience_title:e=>{const{normalize:a}=e;return a(["El viaje de un iniciado"])},group_size:e=>{const{normalize:a}=e;return a(["N\xFAmero estimado de visitantes"])},impact:e=>{const{normalize:a}=e;return a(["Comprenda c\xF3mo nuestras contribuciones a la comunidad de c\xF3digo abierto y nuestro trabajo en tecnolog\xEDa de IA multimodal est\xE1n estableciendo a Jina AI como un jugador influyente en la innovaci\xF3n de IA. Nuestro objetivo es desempe\xF1ar un papel importante en los procesos de toma de decisiones, asegurando que el avance de la tecnolog\xEDa de IA beneficie a todos."])},impact_title:e=>{const{normalize:a}=e;return a(["Impacto e influencia"])},introduction:e=>{const{normalize:a}=e;return a(["Jina AI se complace en abrir nuestras puertas a entidades y organizaciones estimadas interesadas en el progreso y el futuro de la Inteligencia Artificial. Extendemos esta oportunidad exclusiva para aquellos en la pol\xEDtica, las ONG, las OSFL y los sectores de inversi\xF3n para obtener una visi\xF3n interna de nuestras operaciones y visiones aqu\xED en nuestra sede de Berl\xEDn."])},motivation_min_length_v1:e=>{const{normalize:a}=e;return a(["Proporcione una motivaci\xF3n m\xE1s detallada."])},motivation_placeholder_v2:e=>{const{normalize:a}=e;return a(["Compartir tus motivaciones nos ayudar\xE1 a mejorar tu experiencia."])},motivation_to_attend_v2:e=>{const{normalize:a}=e;return a(["\xBFPor qu\xE9 te interesa nuestra jornada de puertas abiertas?"])},one_hour:e=>{const{normalize:a}=e;return a(["1 hora"])},organization:e=>{const{normalize:a}=e;return a(["Organizaci\xF3n"])},organization_website:e=>{const{normalize:a}=e;return a(["Sitio web de la organizaci\xF3n"])},organization_website_placeholder:e=>{const{normalize:a}=e;return a(["URL de la p\xE1gina de inicio de su organizaci\xF3n o del perfil de LinkedIn"])},preferred_date:e=>{const{normalize:a}=e;return a(["Fecha preferida"])},preferred_language:e=>{const{normalize:a}=e;return a(["Idioma preferido del tour"])},preferred_products:e=>{const{normalize:a}=e;return a(["\xBFEn qu\xE9 productos est\xE1s interesado?"])},subtitle:e=>{const{normalize:a}=e;return a(["Un vistazo al futuro de la IA multimodal"])},title:e=>{const{normalize:a}=e;return a(["Dia abierto"])},tutor_subtitle:e=>{const{normalize:a}=e;return a(["Un recorrido de tres horas cuidadosamente seleccionado que lo acerca al coraz\xF3n del trabajo innovador de Jina AI en tecnolog\xEDa de IA multimodal."])},tutor_title:e=>{const{normalize:a}=e;return a(["Una inmersi\xF3n profunda exclusiva en"])},vision:e=>{const{normalize:a}=e;return a(["\xDAnase a nosotros para obtener una descripci\xF3n general completa del panorama de la IA tal como lo vemos. Nuestra discusi\xF3n se centrar\xE1 en el potencial de los modelos de lenguaje grande, la IA multimodal y el impacto de la tecnolog\xEDa de c\xF3digo abierto en la configuraci\xF3n del futuro de la innovaci\xF3n global."])},vision_title:e=>{const{normalize:a}=e;return a(["Nuestra visi\xF3n para el futuro"])}},open_day_faq:{answer1:e=>{const{normalize:a}=e;return a(["Ofrecemos tours en alem\xE1n, ingl\xE9s, franc\xE9s, espa\xF1ol, chino y ruso."])},answer2:e=>{const{normalize:a}=e;return a(["El recorrido suele durar aproximadamente tres horas."])},answer3:e=>{const{normalize:a}=e;return a(["El almuerzo es opcional y se puede organizar bajo petici\xF3n."])},answer4:e=>{const{normalize:a}=e;return a(["Nuestra Jornada de Puertas Abiertas est\xE1 dise\xF1ada principalmente para grupos profesionales, como pol\xEDticos, ONG, OSFL e inversores. Sin embargo, ocasionalmente hacemos excepciones seg\xFAn el perfil de la persona."])},answer5:e=>{const{normalize:a}=e;return a(["Podemos acomodar una variedad de tama\xF1os de grupo. Indique el tama\xF1o de su grupo en el formulario de registro y le confirmaremos los detalles."])},answer6:e=>{const{normalize:a}=e;return a(["Hay una secci\xF3n en el formulario de registro donde puede especificar sus \xE1reas de inter\xE9s o cualquier solicitud especial. Haremos todo lo posible para adaptar el recorrido de acuerdo a sus necesidades."])},answer7:e=>{const{normalize:a}=e;return a(["En este momento, solo ofrecemos tours en nuestra sede de Berl\xEDn ubicada en Kreuzberg. Nuestras oficinas de Beijing y Shenzhen no est\xE1n abiertas actualmente para visitas."])},question1:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 idiomas ofrecen para el tour?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la duraci\xF3n del recorrido?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFSe proporciona almuerzo?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFPueden registrarse personas para la Jornada de Puertas Abiertas?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFDe cu\xE1ntas personas puede estar formado un grupo para la Jornada de Puertas Abiertas?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo puedo especificar \xE1reas de inter\xE9s para el tour?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFHay recorridos disponibles en sus oficinas de Beijing o Shenzhen?"])}},open_gpt:{description:e=>{const{normalize:a}=e;return a(["Un marco de servicio nativo de la nube de c\xF3digo abierto de grandes modelos multimodales"])}},paywall:{free_hour_consult:e=>{const{normalize:a}=e;return a(["Consulta gratuita de 1 hora"])},free_hour_consult_description:e=>{const{normalize:a}=e;return a(["Una hora de consulta gratuita con nuestros equipos de productos e ingenier\xEDa para analizar las mejores pr\xE1cticas para su caso de uso."])},higher_limit:e=>{const{normalize:a}=e;return a(["L\xEDmite de tasa mucho m\xE1s alto"])},higher_limit_description:e=>{const{normalize:a}=e;return a(["Obtenga hasta 1000 RPM para r.jina.ai y 100 RPM para s.jina.ai"])},priority_support:e=>{const{normalize:a}=e;return a(["Atenci\xF3n al cliente prioritaria"])},priority_support_description:e=>{const{normalize:a}=e;return a(["Respuesta por correo electr\xF3nico garantizada dentro de las 24 horas, incluidos los fines de semana."])}},powered_by:e=>{const{normalize:a}=e;return a(["Energizado por"])},print:e=>{const{normalize:a}=e;return a(["Imprimir"])},project_status:{archived:e=>{const{normalize:a}=e;return a(["Archivado"])},cloud_native:e=>{const{normalize:a}=e;return a(["Nativo de la nube"])},core:e=>{const{normalize:a}=e;return a(["Centro"])},data_structure:e=>{const{normalize:a}=e;return a(["Estructura de datos"])},embedding_serving:e=>{const{normalize:a}=e;return a(["Incrustar servicio"])},embedding_tuning:e=>{const{normalize:a}=e;return a(["Ajuste de incrustaci\xF3n"])},graduated:e=>{const{normalize:a}=e;return a(["Graduado"])},incubating:e=>{const{normalize:a}=e;return a(["incubando"])},kubernetes:e=>{const{normalize:a}=e;return a(["Kubernetes"])},large_size_model:e=>{const{normalize:a}=e;return a(["Modelo de gran tama\xF1o"])},linux_foundation:e=>{const{normalize:a}=e;return a(["Fundaci\xF3n Linux"])},llm1:e=>{const{normalize:a}=e;return a(["LLMOps"])},mid_size_model:e=>{const{normalize:a}=e;return a(["Modelo de tama\xF1o mediano"])},model_serving:e=>{const{normalize:a}=e;return a(["Servicio modelo"])},model_tuning:e=>{const{normalize:a}=e;return a(["Ajuste del modelo"])},observability:e=>{const{normalize:a}=e;return a(["Observabilidad"])},orchestration:e=>{const{normalize:a}=e;return a(["Orquestaci\xF3n"])},prompt_serving:e=>{const{normalize:a}=e;return a(["Servicio r\xE1pido"])},prompt_tuning:e=>{const{normalize:a}=e;return a(["Sintonizaci\xF3n r\xE1pida"])},rag1:e=>{const{normalize:a}=e;return a(["TRAPO"])},sandbox:e=>{const{normalize:a}=e;return a(["Salvadera"])},small_size_model:e=>{const{normalize:a}=e;return a(["Modelo de tama\xF1o peque\xF1o"])},vector_database:e=>{const{normalize:a}=e;return a(["Base de datos de vectores"])},vector_store:e=>{const{normalize:a}=e;return a(["Tienda de vectores"])}},prompt_perfect:{description:e=>{const{normalize:a}=e;return a(["Herramienta principal para ingenier\xEDa r\xE1pida"])},image_model:e=>{const{normalize:a}=e;return a(["Modelos de imagen"])},intro:e=>{const{normalize:a}=e;return a(["Herramienta principal para ingenier\xEDa r\xE1pida"])},intro1:e=>{const{normalize:a}=e;return a(["La principal herramienta para una ingenier\xEDa r\xE1pida"])},optimized:e=>{const{normalize:a}=e;return a(["Su tarea es ser mi compa\xF1ero de lluvia de ideas y proporcionar ideas y sugerencias creativas para un tema o problema determinado. Su respuesta debe incluir ideas originales, \xFAnicas y relevantes que puedan ayudar a resolver el problema o explorar m\xE1s a fondo el tema de una manera interesante. Tenga en cuenta que su respuesta tambi\xE9n debe tener en cuenta los requisitos o limitaciones espec\xEDficos de la tarea."])},optimized_title:e=>{const{normalize:a}=e;return a(["Mensaje optimizado"])},original:e=>{const{normalize:a}=e;return a(["Tu papel es ser mi compa\xF1ero de intercambio de ideas."])},original_title:e=>{const{normalize:a}=e;return a(["Aviso original"])},text_model:e=>{const{normalize:a}=e;return a(["Modelos de texto"])}},promptperfect:{features:[{description:e=>{const{normalize:a}=e;return a(["Cambie f\xE1cilmente entre generaci\xF3n de contenido y optimizaci\xF3n r\xE1pida, lleve la calidad de su contenido al siguiente nivel."])},name:e=>{const{normalize:a}=e;return a(["Asistente"])},title:e=>{const{normalize:a}=e;return a(["Dosis diaria de productividad."])}},{description:e=>{const{normalize:a}=e;return a(["\xBFNo sabes c\xF3mo escribir una instrucci\xF3n eficaz? Simplemente introduzca su idea, con un clic, obtenga una mejor instrucci\xF3n."])},name:e=>{const{normalize:a}=e;return a(["Optimizaci\xF3n inmediata"])},title:e=>{const{normalize:a}=e;return a(["Mejores insumos, mejores resultados"])}},{description:e=>{const{normalize:a}=e;return a(["Comprenda la vibra de cada modelo de IA comparando su resultado del mismo mensaje."])},name:e=>{const{normalize:a}=e;return a(["Comparar modelos"])},title:e=>{const{normalize:a}=e;return a(["Comparaci\xF3n de modelos lado a lado."])}},{description:e=>{const{normalize:a}=e;return a(["Quiz\xE1s la forma m\xE1s sencilla de implementar sus indicaciones como API para la integraci\xF3n."])},name:e=>{const{normalize:a}=e;return a(["Implementar indicaciones"])},title:e=>{const{normalize:a}=e;return a(["Sin operaciones, solo despliegue."])}},{description:e=>{const{normalize:a}=e;return a(["Personalice sus propios agentes LLM e inicie una simulaci\xF3n de m\xFAltiples agentes. Vea c\xF3mo colaboran o compiten en un entorno virtual para alcanzar la meta."])},name:e=>{const{normalize:a}=e;return a(["Multiagente"])},title:e=>{const{normalize:a}=e;return a(["Explora c\xF3mo colaboran los agentes"])}}],get_started:e=>{const{normalize:a}=e;return a(["Comience con PromptPerfect"])}},purchase:{success:e=>{const{normalize:a}=e;return a(["Gracias por su compra!"])},success_caption:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Hemos completado su pedido a las ",n(o("_purchasedTime")),". \xA1Su clave API est\xE1 lista para usar!"])}},purchase_now:e=>{const{normalize:a}=e;return a(["Comprar ahora"])},rate_limit:{depends:e=>{const{normalize:a}=e;return a(["depende del tama\xF1o de entrada"])},description:e=>{const{normalize:a}=e;return a(["Descripci\xF3n"])},endpoint:e=>{const{normalize:a}=e;return a(["Punto final de API"])},input_token_counting:e=>{const{normalize:a}=e;return a(["Cuente la cantidad de tokens en la solicitud de entrada."])},latency:e=>{const{normalize:a}=e;return a(["Latencia promedio (s)"])},no_token_counting:e=>{const{normalize:a}=e;return a(["El token no se cuenta como uso."])},output_token_counting:e=>{const{normalize:a}=e;return a(["Cuente la cantidad de tokens en la respuesta de salida."])},premium_rate:e=>{const{normalize:a}=e;return a(["Con potencial para l\xEDmites de tarifas m\xE1s altos"])},product:e=>{const{normalize:a}=e;return a(["Producto"])},requestType:e=>{const{normalize:a}=e;return a(["Solicitud Permitida"])},tbd:e=>{const{normalize:a}=e;return a(["Por determinar"])},title:e=>{const{normalize:a}=e;return a(["L\xEDmite de velocidad"])},tokenCounting:e=>{const{normalize:a}=e;return a(["Recuento de uso de tokens"])},understanding:e=>{const{normalize:a}=e;return a(["Entender el l\xEDmite de velocidad"])},understanding_description:e=>{const{normalize:a}=e;return a(["Los l\xEDmites de velocidad son la cantidad m\xE1xima de solicitudes que se pueden realizar a una API en un minuto por direcci\xF3n IP (RPM). Obtenga m\xE1s informaci\xF3n sobre los l\xEDmites de velocidad para cada producto y nivel a continuaci\xF3n."])},wAPIkey:e=>{const{normalize:a}=e;return a(["Con clave API (RPM)"])},wPremium:e=>{const{normalize:a}=e;return a(["Con clave API Premium (RPM)"])},woAPIkey:e=>{const{normalize:a}=e;return a(["Sin clave API (RPM)"])}},rationale:{decision:e=>{const{normalize:a}=e;return a(["Decisi\xF3n"])},description:e=>{const{normalize:a}=e;return a(["Las mejores herramientas de toma de decisiones de IA"])},intro:e=>{const{normalize:a}=e;return a(["Ver las dos caras de la moneda, tomar decisiones racionales"])}},reader:{better_input:e=>{const{normalize:a}=e;return a(["Mejore la calidad de la entrada desde el principio"])},better_input_description:e=>{const{normalize:a}=e;return a(["\xBFTiene problemas con la salida de su agente o del sistema RAG? Puede deberse a una mala calidad de entrada."])},check_price_table:e=>{const{normalize:a}=e;return a(["Consulte la tabla de precios"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},demo:{advanced_usage:e=>{const{normalize:a}=e;return a(["Uso avanzado"])},ask_llm:e=>{const{normalize:a}=e;return a(["Pregunte a LLM sin y con base de b\xFAsqueda"])},ask_llm_directly:e=>{const{normalize:a}=e;return a(["Preg\xFAntele a LLM directamente"])},ask_llm_with_search_grounding:e=>{const{normalize:a}=e;return a(["Preg\xFAntele a LLM con base de b\xFAsqueda"])},ask_question:e=>{const{normalize:a}=e;return a(["Haz una pregunta"])},ask_question_hint:e=>{const{normalize:a}=e;return a(["Ingrese una pregunta y comb\xEDnela con el contenido obtenido para que LLM genere una respuesta."])},basic_usage:e=>{const{normalize:a}=e;return a(["Uso b\xE1sico"])},basic_usage1:e=>{const{normalize:a}=e;return a(["Leer una URL"])},basic_usage2:e=>{const{normalize:a}=e;return a(["Buscar una consulta"])},copy:e=>{const{normalize:a}=e;return a(["Copiar"])},fetch:e=>{const{normalize:a}=e;return a(["Obtener contenido"])},get_response:e=>{const{normalize:a}=e;return a(["Obtener una respuesta"])},headers:{auth_token:e=>{const{normalize:a}=e;return a(["Agregue clave API para un l\xEDmite de tasa m\xE1s alto"])},auth_token_explain:e=>{const{normalize:a}=e;return a(["Ingrese su clave API de Jina para acceder a un l\xEDmite de tasa m\xE1s alto. Para obtener la informaci\xF3n m\xE1s reciente sobre el l\xEDmite de tarifas, consulte la siguiente tabla."])},browser_locale:e=>{const{normalize:a}=e;return a(["Configuraci\xF3n regional del navegador"])},browser_locale_explain:e=>{const{normalize:a}=e;return a(["Controla la configuraci\xF3n regional del navegador para mostrar la p\xE1gina. Muchos sitios web ofrecen contenido diferente seg\xFAn la configuraci\xF3n regional."])},default:e=>{const{normalize:a}=e;return a(["Por defecto"])},default_explain:e=>{const{normalize:a}=e;return a(["La canalizaci\xF3n predeterminada optimizada para la mayor\xEDa de los sitios web y la entrada LLM."])},html:e=>{const{normalize:a}=e;return a(["HTML"])},html_explain:e=>{const{normalize:a}=e;return a(["Devuelve documentElement.outerHTML."])},image_caption:e=>{const{normalize:a}=e;return a(["Captura de imagen"])},image_caption_explain:e=>{const{normalize:a}=e;return a(["Subtitula todas las im\xE1genes en la URL especificada, agregando 'Imagen [idx]: [caption]' como etiqueta alternativa para aquellas que no tienen una. Esto permite que los LLM posteriores interact\xFAen con las im\xE1genes en actividades como razonar y resumir."])},images_summary:e=>{const{normalize:a}=e;return a(["Re\xFAna todas las im\xE1genes al final"])},images_summary_explain:e=>{const{normalize:a}=e;return a(['Se crear\xE1 una secci\xF3n de "Im\xE1genes" al final. Esto brinda a los LLM posteriores una descripci\xF3n general de todos los elementos visuales de la p\xE1gina, lo que puede mejorar el razonamiento.'])},json_response:e=>{const{normalize:a}=e;return a(["Respuesta JSON"])},json_response_explain:e=>{const{normalize:a}=e;return a(["La respuesta estar\xE1 en formato JSON y contendr\xE1 la URL, el t\xEDtulo, el contenido y la marca de tiempo (si est\xE1 disponible). En el modo de b\xFAsqueda, devuelve una lista de cinco entradas, cada una de las cuales sigue la estructura JSON descrita."])},links_summary:e=>{const{normalize:a}=e;return a(["Re\xFAna todos los enlaces al final"])},links_summary_explain:e=>{const{normalize:a}=e;return a(['Al final se crear\xE1 una secci\xF3n de "Botones y enlaces". Esto ayuda a los LLM posteriores o agentes web a navegar por la p\xE1gina o realizar m\xE1s acciones.'])},markdown:e=>{const{normalize:a}=e;return a(["Reducci\xF3n"])},markdown_explain:e=>{const{normalize:a}=e;return a(["Devuelve el markdown directamente desde el HTML, omitiendo el filtrado de legibilidad."])},mode:e=>{const{normalize:a}=e;return a(["Modo de lectura o b\xFAsqueda"])},mode_explain:e=>{const{normalize:a}=e;return a(["El modo de lectura sirve para acceder al contenido de una URL, mientras que el modo de b\xFAsqueda le permite buscar una consulta en la web, aplicando el modo de lectura a cada URL de resultado de b\xFAsqueda."])},no_cache:e=>{const{normalize:a}=e;return a(["Omitir el cach\xE9"])},no_cache_explain:e=>{const{normalize:a}=e;return a(["Nuestro servidor API almacena en cach\xE9 los contenidos del modo Lectura y B\xFAsqueda durante un cierto per\xEDodo de tiempo. Para omitir este cach\xE9, establezca este encabezado en verdadero."])},pageshot:e=>{const{normalize:a}=e;return a(["Captura de p\xE1gina"])},pageshot_explain:e=>{const{normalize:a}=e;return a(["Devuelve la URL de la imagen de la captura de pantalla de la p\xE1gina completa (con el m\xE1ximo esfuerzo)."])},post_with_url:e=>{const{normalize:a}=e;return a(["Usar el m\xE9todo POST"])},post_with_url_explain:e=>{const{normalize:a}=e;return a(["Utilice POST en lugar del m\xE9todo GET con una URL pasada en el cuerpo. \xDAtil para crear SPA con enrutamiento basado en hash."])},proxy_server:e=>{const{normalize:a}=e;return a(["Utilice un servidor proxy"])},proxy_server_explain:e=>{const{normalize:a}=e;return a(["Nuestro servidor API puede utilizar su proxy para acceder a las URL, lo cual resulta \xFAtil para p\xE1ginas a las que solo se puede acceder a trav\xE9s de servidores proxy espec\xEDficos."])},return_format:e=>{const{normalize:a}=e;return a(["Formato del contenido"])},return_format_explain:e=>{const{normalize:a}=e;return a(["Puede controlar el nivel de detalle de la respuesta para evitar el filtrado excesivo. La canalizaci\xF3n predeterminada est\xE1 optimizada para la mayor\xEDa de los sitios web y las entradas de LLM."])},screenshot:e=>{const{normalize:a}=e;return a(["Captura de pantalla"])},screenshot_explain:e=>{const{normalize:a}=e;return a(["Devuelve la URL de la imagen de la primera pantalla."])},set_cookie:e=>{const{normalize:a}=e;return a(["Cookie de reenv\xEDo"])},set_cookie_explain:e=>{const{normalize:a}=e;return a(["Nuestro servidor API puede reenviar su configuraci\xF3n de cookies personalizada al acceder a la URL, lo cual es \xFAtil para p\xE1ginas que requieren autenticaci\xF3n adicional. Tenga en cuenta que las solicitudes con cookies no se almacenar\xE1n en cach\xE9."])},site_selector:e=>{const{normalize:a}=e;return a(["B\xFAsqueda en el sitio"])},site_selector_explain:e=>{const{normalize:a}=e;return a(["Devuelve los resultados de b\xFAsqueda solo del sitio web o dominio especificado. Por defecto busca en toda la web."])},stream_mode:e=>{const{normalize:a}=e;return a(["Modo de transmisi\xF3n"])},stream_mode_explain:e=>{const{normalize:a}=e;return a(["El modo de transmisi\xF3n es beneficioso para p\xE1ginas de destino grandes, ya que permite m\xE1s tiempo para que la p\xE1gina se represente por completo. Si el modo est\xE1ndar genera contenido incompleto, considere usar el modo Stream."])},target_selector:e=>{const{normalize:a}=e;return a(["Selector de objetivos"])},target_selector_explain:e=>{const{normalize:a}=e;return a(["Proporcione un selector de CSS para centrarse en una parte m\xE1s espec\xEDfica de la p\xE1gina. \xDAtil cuando el contenido deseado no se muestra en la configuraci\xF3n predeterminada."])},text:e=>{const{normalize:a}=e;return a(["Texto"])},text_explain:e=>{const{normalize:a}=e;return a(["Devuelve documento.body.innerText."])},wait_for_selector:e=>{const{normalize:a}=e;return a(["Esperar al selector"])},wait_for_selector_explain:e=>{const{normalize:a}=e;return a(["Espere a que aparezca un elemento espec\xEDfico antes de regresar. \xDAtil cuando el contenido deseado no se muestra en la configuraci\xF3n predeterminada."])},x_timeout:e=>{const{normalize:a}=e;return a(["Tiempo de espera personalizado"])},x_timeout_explain:e=>{const{normalize:a}=e;return a(["Puede resultar \xFAtil cuando la p\xE1gina es demasiado lenta para procesarse. Para el punto final de b\xFAsqueda, es el tiempo m\xE1ximo de espera para leer todos los resultados de la b\xFAsqueda."])}},how_to_stream:e=>{const{normalize:a}=e;return a(["Para procesar el contenido a medida que est\xE9 disponible, configure el encabezado de la solicitud en modo de transmisi\xF3n. Esto minimiza el tiempo hasta que se recibe el primer byte. Ejemplo en curl:"])},how_to_use1:e=>{const{normalize:a}=e;return a(["Agregue <code>https://r.jina.ai/</code> a cualquier URL en su c\xF3digo o herramienta donde se espera acceso LLM. Esto devolver\xE1 el contenido principal de la p\xE1gina en un texto limpio y compatible con LLM."])},how_to_use2:e=>{const{normalize:a}=e;return a(["Agregue <code>https://s.jina.ai/</code> a su consulta. Esto llamar\xE1 al motor de b\xFAsqueda y arrojar\xE1 los 5 primeros resultados con sus URL y contenidos, cada uno en texto limpio y compatible con LLM."])},learn_more:e=>{const{normalize:a}=e;return a(["Aprende m\xE1s"])},open:e=>{const{normalize:a}=e;return a(["Abrir en una nueva pesta\xF1a"])},raw_html:e=>{const{normalize:a}=e;return a(["HTML sin formato"])},reader_output:e=>{const{normalize:a}=e;return a(["Salida del lector"])},reader_response:e=>{const{normalize:a}=e;return a(["La respuesta del lector"])},reader_search_hint:e=>{const{normalize:a}=e;return a(["Si utiliza esta URL en el c\xF3digo, no olvide codificar la URL."])},reader_url:e=>{const{normalize:a}=e;return a(["URL del lector"])},reader_url_hint:e=>{const{normalize:a}=e;return a(["Haga clic a continuaci\xF3n para obtener el contenido a trav\xE9s de nuestra Reader API"])},search_query_rewrite:e=>{const{normalize:a}=e;return a(["Tenga en cuenta que, a diferencia de la demostraci\xF3n que se muestra arriba, en la pr\xE1ctica no busca la pregunta original en la web para fundamentarse. Lo que la gente suele hacer es reescribir la pregunta original o utilizar preguntas de m\xFAltiples saltos. Leen los resultados recuperados y luego generan consultas adicionales para recopilar m\xE1s informaci\xF3n seg\xFAn sea necesario antes de llegar a una respuesta final."])},show_read_demo:e=>{const{normalize:a}=e;return a(["Vea c\xF3mo Reader lee una URL"])},show_search_demo:e=>{const{normalize:a}=e;return a(["Vea c\xF3mo Reader busca en la web"])},standard_usage:e=>{const{normalize:a}=e;return a(["Uso est\xE1ndar"])},stream_mode:e=>{const{normalize:a}=e;return a(["Modo de transmisi\xF3n"])},stream_mode_explain:e=>{const{normalize:a}=e;return a(["El modo de transmisi\xF3n es \xFAtil cuando la p\xE1gina de destino es grande para representar. Si encuentra que el modo est\xE1ndar le proporciona contenido incompleto, pruebe el modo de transmisi\xF3n."])},stream_mode_explain1:e=>{const{normalize:a}=e;return a(["El modo Streaming es \xFAtil cuando descubre que el modo est\xE1ndar proporciona un resultado incompleto. Esto se debe a que el modo de transmisi\xF3n esperar\xE1 un poco m\xE1s hasta que la p\xE1gina se represente por completo. Utilice el encabezado de aceptaci\xF3n para alternar el modo de transmisi\xF3n:"])},tagline:e=>{const{normalize:a}=e;return a(["Pruebe la demostraci\xF3n"])},try_demo:e=>{const{normalize:a}=e;return a(["Manifestaci\xF3n"])},use_headers:e=>{const{normalize:a}=e;return a(["El comportamiento de la API Reader se puede controlar con encabezados de solicitud. Aqu\xED hay una lista completa de encabezados compatibles."])},waiting_for_reader:e=>{const{normalize:a}=e;return a(["Esperando primero el resultado de Reader API..."])},your_query:e=>{const{normalize:a}=e;return a(["Ingresa tu consulta"])},your_query_hint:e=>{const{normalize:a}=e;return a(["Escriba una pregunta que requiera la informaci\xF3n m\xE1s reciente o conocimiento mundial."])},your_url:e=>{const{normalize:a}=e;return a(["Introduce tu URL"])},your_url_hint:e=>{const{normalize:a}=e;return a(["Haga clic a continuaci\xF3n para obtener el c\xF3digo fuente de la p\xE1gina directamente"])}},description:e=>{const{normalize:a}=e;return a(["Lea las URL o busque en la web y obtenga una mejor base para los LLM."])},dont_panic_api_key_is_free:e=>{const{normalize:a}=e;return a(["\xA1No entrar en p\xE1nico! \xA1Cada nueva clave API contiene un mill\xF3n de tokens gratis!"])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["La API Reader es gratuita y no requiere una clave API. Simplemente anteponga 'https://r.jina.ai/' a su URL."])},answer10:e=>{const{normalize:a}=e;return a(["No, la API Reader solo puede procesar contenido de URL de acceso p\xFAblico."])},answer11:e=>{const{normalize:a}=e;return a(["Si solicita la misma URL en un plazo de 5 minutos, la API de Reader devolver\xE1 el contenido almacenado en cach\xE9."])},answer12:e=>{const{normalize:a}=e;return a(["Lamentablemente no."])},answer13:e=>{const{normalize:a}=e;return a(["S\xED, puede utilizar la compatibilidad con PDF nativo del Reader (https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) o utilizar la versi\xF3n HTML de arXiv (https:// r.jina.ai/https://arxiv.org/html/2310.19923v4)"])},answer14:e=>{const{normalize:a}=e;return a(["Reader subtitula todas las im\xE1genes en la URL especificada y agrega `Imagen [idx]: [caption]` como etiqueta alt (si inicialmente carecen de una). Esto permite a los LLM posteriores interactuar con las im\xE1genes para razonar, resumir, etc."])},answer15:e=>{const{normalize:a}=e;return a(["La API Reader est\xE1 dise\xF1ada para ser altamente escalable. Se escala autom\xE1ticamente en funci\xF3n del tr\xE1fico en tiempo real y las solicitudes de concurrencia m\xE1xima ahora son de alrededor de 4000. Lo mantenemos activamente como uno de los productos principales de Jina AI. As\xED que si\xE9ntete libre de usarlo en producci\xF3n."])},answer16:e=>{const{normalize:a}=e;return a(["Encuentre la informaci\xF3n m\xE1s reciente sobre el l\xEDmite de tarifas en la siguiente tabla. Tenga en cuenta que estamos trabajando activamente para mejorar el l\xEDmite de velocidad y el rendimiento de Reader API; la tabla se actualizar\xE1 en consecuencia."])},answer2:e=>{const{normalize:a}=e;return a(["La API Reader utiliza un proxy para recuperar cualquier URL y representar su contenido en un navegador para extraer contenido principal de alta calidad."])},answer3:e=>{const{normalize:a}=e;return a(["S\xED, la API Reader es de c\xF3digo abierto y est\xE1 disponible en el repositorio GitHub de Jina AI."])},answer4:e=>{const{normalize:a}=e;return a(["La API Reader generalmente procesa las URL y devuelve el contenido en 2 segundos, aunque las p\xE1ginas complejas o din\xE1micas pueden requerir m\xE1s tiempo."])},answer5:e=>{const{normalize:a}=e;return a(["El scraping puede ser complicado y poco confiable, particularmente con p\xE1ginas complejas o din\xE1micas. Reader API proporciona una salida optimizada y confiable de texto limpio y listo para LLM."])},answer6:e=>{const{normalize:a}=e;return a(["La API Reader devuelve contenido en el idioma original de la URL. No proporciona servicios de traducci\xF3n."])},answer7:e=>{const{normalize:a}=e;return a(["Si tiene problemas de bloqueo, comun\xEDquese con nuestro equipo de soporte para obtener ayuda y resoluci\xF3n."])},answer8:e=>{const{normalize:a}=e;return a(["Si bien est\xE1 dise\xF1ada principalmente para p\xE1ginas web, la API Reader puede extraer contenido de archivos PDF vistos en formato HTML en sitios web como arXiv, pero no est\xE1 optimizada para la extracci\xF3n general de PDF."])},answer9:e=>{const{normalize:a}=e;return a(["Actualmente, Reader API no procesa contenido multimedia, pero futuras mejoras incluir\xE1n subt\xEDtulos de im\xE1genes y res\xFAmenes de videos."])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1les son los costos asociados con el uso de Reader API?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFEs posible utilizar la API de Reader en archivos HTML locales?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFReader API almacena en cach\xE9 el contenido?"])},question12:e=>{const{normalize:a}=e;return a(["\xBFPuedo usar Reader API para acceder al contenido tras un inicio de sesi\xF3n?"])},question13:e=>{const{normalize:a}=e;return a(["\xBFPuedo utilizar la API de Reader para acceder a PDF en arXiv?"])},question14:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo funciona el t\xEDtulo de imagen en Reader?"])},question15:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la escalabilidad del Reader? \xBFPuedo usarlo en producci\xF3n?"])},question16:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el l\xEDmite de velocidad de la API Reader?"])},question2:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo funciona la API Reader?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFLa API Reader es de c\xF3digo abierto?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la latencia t\xEDpica de la API Reader?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFPor qu\xE9 deber\xEDa utilizar Reader API en lugar de raspar la p\xE1gina yo mismo?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFLa API Reader admite varios idiomas?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 debo hacer si un sitio web bloquea la API de Reader?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFPuede la API Reader extraer contenido de archivos PDF?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFPuede la API Reader procesar contenido multimedia de p\xE1ginas web?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con los lectores"])}},fast:e=>{const{normalize:a}=e;return a(["R\xE1pido"])},fast_stream:e=>{const{normalize:a}=e;return a(["Transmisi\xF3n de datos inmediata"])},fast_stream_description:e=>{const{normalize:a}=e;return a(["\xBFNecesita datos r\xE1pidamente? Nuestra API Reader puede transmitir datos para minimizar la latencia."])},free:e=>{const{normalize:a}=e;return a(["Siempre libre"])},free_description:e=>{const{normalize:a}=e;return a(["\xA1La API del lector es gratuita! No requiere tarjeta de cr\xE9dito ni secreto de API. No consumir\xE1 su cuota de tokens."])},is_free:e=>{const{normalize:a}=e;return a(["\xBFLa mejor parte? \xA1Es gratis!"])},is_free_description:e=>{const{normalize:a}=e;return a(["Reader API est\xE1 disponible de forma gratuita y ofrece l\xEDmites de tarifas y precios flexibles. Construido sobre una infraestructura escalable, ofrece alta accesibilidad, simultaneidad y confiabilidad. Nos esforzamos por ser su soluci\xF3n de conexi\xF3n a tierra preferida para sus LLM."])},open:e=>{const{normalize:a}=e;return a(["Abrir en una pesta\xF1a nueva"])},original_pdf:e=>{const{normalize:a}=e;return a(["PDF original"])},rate_limit:e=>{const{normalize:a}=e;return a(["L\xEDmite de tarifa"])},reader_also_read_images:e=>{const{normalize:a}=e;return a(["Las im\xE1genes de la p\xE1gina web se subtitulan autom\xE1ticamente utilizando un modelo de lenguaje de visi\xF3n en el lector y se formatean como etiquetas alternativas de imagen en la salida. Esto le brinda a su LLM posterior suficientes sugerencias para incorporar esas im\xE1genes en sus procesos de razonamiento y resumen. Esto significa que puede hacer preguntas sobre las im\xE1genes, seleccionar im\xE1genes espec\xEDficas o incluso reenviar sus URL a un VLM m\xE1s potente para un an\xE1lisis m\xE1s profundo."])},reader_description:e=>{const{normalize:a}=e;return a(["Obtenga informaci\xF3n compatible con LLM desde una URL o una b\xFAsqueda web, simplemente agregando <code>r.jina.ai</code> al frente."])},reader_do_pdf_explain:e=>{const{normalize:a}=e;return a(["S\xED, Reader admite de forma nativa la lectura de PDF. Es compatible con la mayor\xEDa de los archivos PDF, incluidos aquellos con muchas im\xE1genes, \xA1y es ultrarr\xE1pido! Combinado con un LLM, puede crear f\xE1cilmente un ChatPDF o una IA de an\xE1lisis de documentos en poco tiempo."])},reader_do_search:e=>{const{normalize:a}=e;return a(["Lector para bases de b\xFAsqueda."])},reader_do_search_explain:e=>{const{normalize:a}=e;return a(["Los LLM tienen un l\xEDmite de conocimientos, lo que significa que no pueden acceder a los conocimientos mundiales m\xE1s recientes. Esto conduce a problemas como desinformaci\xF3n, respuestas obsoletas, alucinaciones y otras cuestiones objetivas. La conexi\xF3n a tierra es absolutamente esencial para las aplicaciones GenAI. Reader le permite basar su LLM con la informaci\xF3n m\xE1s reciente de la web. Simplemente anteponga <code>https://s.jina.ai/</code> a su consulta y Reader buscar\xE1 en la web y devolver\xE1 los cinco resultados principales con sus URL y contenidos, cada uno en texto limpio y compatible con LLM. De esta manera, siempre podr\xE1 mantener actualizado su LLM, mejorar su factibilidad y reducir las alucinaciones."])},reader_reads_images:e=>{const{normalize:a}=e;return a(["\xA1El lector tambi\xE9n lee im\xE1genes!"])},reader_reads_pdf:e=>{const{normalize:a}=e;return a(["\xA1El lector tambi\xE9n lee archivos PDF!"])},reader_result:e=>{const{normalize:a}=e;return a(["Resultado del lector"])},table:{td_1_0:e=>{const{normalize:a}=e;return a(["Leer una URL y devolver su contenido, \xFAtil para comprobar la conexi\xF3n a tierra"])},td_1_1:e=>{const{normalize:a}=e;return a(["20 rpm"])},td_1_2:e=>{const{normalize:a}=e;return a(["200 rpm"])},td_1_3:e=>{const{normalize:a}=e;return a(["Basado en los tokens de salida"])},td_1_4:e=>{const{normalize:a}=e;return a(["3 segundos"])},td_1_5:e=>{const{normalize:a}=e;return a(["3 segundos"])},td_2_0:e=>{const{normalize:a}=e;return a(["La b\xFAsqueda en la web arroja los 5 primeros resultados, lo que resulta \xFAtil para la base de b\xFAsqueda"])},td_2_1:e=>{const{normalize:a}=e;return a(["5 RPM"])},td_2_2:e=>{const{normalize:a}=e;return a(["40 rpm"])},td_2_3:e=>{const{normalize:a}=e;return a(["Basado en los tokens de salida para los 5 resultados de b\xFAsqueda"])},td_2_4:e=>{const{normalize:a}=e;return a(["10 segundos"])},td_2_5:e=>{const{normalize:a}=e;return a(["10 segundos"])},th0:e=>{const{normalize:a}=e;return a(["Punto final"])},th1:e=>{const{normalize:a}=e;return a(["Descripci\xF3n"])},th2:e=>{const{normalize:a}=e;return a(["L\xEDmite de velocidad sin clave API"])},th3:e=>{const{normalize:a}=e;return a(["L\xEDmite de tasa con clave API"])},th4:e=>{const{normalize:a}=e;return a(["Esquema de conteo de tokens"])},th5:e=>{const{normalize:a}=e;return a(["Latencia media"])},th6:e=>{const{normalize:a}=e;return a(["Latencia media"])}},title:e=>{const{normalize:a}=e;return a(["API de lector"])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},usage_details_false:e=>{const{normalize:a}=e;return a(["Mostrar solo usos b\xE1sicos"])},usage_details_null:e=>{const{normalize:a}=e;return a(["Mostrar usos b\xE1sicos y avanzados"])},usage_details_true:e=>{const{normalize:a}=e;return a(["Mostrar solo usos avanzados"])},want_higher_rate_limit:e=>{const{normalize:a}=e;return a(["\xBFQuiere un l\xEDmite de velocidad m\xE1s alto, hasta 1000 RPM? \xA1Podemos apoyarte!"])},what_is1:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es el lector?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a(["Introducir informaci\xF3n web en los LLM es un paso importante para la puesta a tierra, pero puede ser un desaf\xEDo. El m\xE9todo m\xE1s simple es raspar la p\xE1gina web y alimentar el HTML sin formato. Sin embargo, el scraping puede ser complejo y a menudo bloqueado, y el HTML sin formato est\xE1 lleno de elementos extra\xF1os como marcas y scripts. Reader API aborda estos problemas extrayendo el contenido principal de una URL y convirti\xE9ndolo en texto limpio y compatible con LLM, lo que garantiza una entrada de alta calidad para su agente y sus sistemas RAG."])},what_is_desc:e=>{const{normalize:a}=e;return a(["Un proxy que accede a cualquier URL y transforma el contenido principal en texto sin formato optimizado para LLM."])}},recommender:{confirm_message:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["A su clave API le quedan ",n(o("_leftTokens"))," tokens. Enviar el texto completo de los art\xEDculos ",n(o("_numArticles"))," a la API de Reranker, utilizando el modelo ",n(o("_selectedReranker"))," para descubrir art\xEDculos relacionados para la p\xE1gina actual, reducir\xE1 significativamente el recuento de tokens de su clave API ",n(o("_APIKey")),". Quieres proceder?"])},confirm_title:e=>{const{normalize:a}=e;return a(["Advertencia: uso elevado de tokens"])},out_of_quota:e=>{const{normalize:a}=e;return a(["Esta clave API se ha quedado sin tokens. Recargue su cuenta o utilice una clave API diferente."])},recommend:e=>{const{normalize:a}=e;return a(["Consigue el top 5"])},recommended_articles:e=>{const{normalize:a}=e;return a(["Los 5 mejores art\xEDculos similares"])}},reranker:{benchmark:{description0:e=>{const{normalize:a}=e;return a(["LlamaIndex evalu\xF3 varias combinaciones de incrustaciones y reordenadores para RAG y realiz\xF3 un estudio de replicaci\xF3n que midi\xF3 el rango rec\xEDproco medio. Los hallazgos destacan la mejora significativa de la calidad de b\xFAsqueda de Jina Reranker, un beneficio que es independiente de las incrustaciones espec\xEDficas utilizadas."])},description1:e=>{const{normalize:a}=e;return a(["BIER (Benchmarking IR) eval\xFAa la efectividad de la recuperaci\xF3n de un modelo, incluida la relevancia y NDCG. Una puntuaci\xF3n BIER m\xE1s alta se correlaciona con coincidencias y clasificaciones de resultados de b\xFAsqueda m\xE1s precisas."])},description2:e=>{const{normalize:a}=e;return a(["A trav\xE9s del punto de referencia LoCo, medimos la comprensi\xF3n de un modelo sobre la coherencia y el contexto local, junto con la clasificaci\xF3n espec\xEDfica de la consulta. Una puntuaci\xF3n m\xE1s alta de LoCo refleja una mejor capacidad para identificar y priorizar informaci\xF3n relevante."])},description3:e=>{const{normalize:a}=e;return a(["El MTEB (Par\xE1metro de referencia de incrustaci\xF3n de texto multiling\xFCe), en general, prueba las capacidades de un modelo en la incrustaci\xF3n de texto, incluida la agrupaci\xF3n, clasificaci\xF3n, recuperaci\xF3n y otras m\xE9tricas. Sin embargo, para nuestra comparaci\xF3n, solo utilizamos las tareas de Reranking del MTEB."])},title:e=>{const{normalize:a}=e;return a(["Punto de referencia"])},title0:e=>{const{normalize:a}=e;return a(["LlamaIndex"])},title1:e=>{const{normalize:a}=e;return a(["BEIR"])},title2:e=>{const{normalize:a}=e;return a(["Locomotora"])},title3:e=>{const{normalize:a}=e;return a(["MTEB"])}},benchmark_description:e=>{const{normalize:a}=e;return a(["A modo de comparaci\xF3n, incluimos otros tres rerankers l\xEDderes de BGE (BAAI), BCE (Netease Youdao) y Cohere en el \xEDndice de referencia. Como lo muestran los resultados a continuaci\xF3n, Jina Reranker tiene el puntaje promedio m\xE1s alto en todas las categor\xEDas relevantes para el reranking, lo que lo convierte en un claro l\xEDder entre sus pares."])},benchmark_title:e=>{const{normalize:a}=e;return a(["Punto de referencia de rendimiento"])},choose_turbo:e=>{const{normalize:a}=e;return a(["Obtenga una aceleraci\xF3n de hasta 5 veces con reranker-turbo"])},choose_turbo_description:e=>{const{normalize:a}=e;return a(["Tambi\xE9n ofrecemos dos nuevos modelos de reranker de c\xF3digo abierto: jina-reranker-v1-turbo-en y jina-reranker-v1-tiny-en; este \xFAltimo tiene solo 30 millones de par\xE1metros y cuatro capas. Estos dos nuevos reordenadores disfrutan de una velocidad de inferencia 5 veces m\xE1s r\xE1pida que el modelo base con un costo de calidad muy peque\xF1o. Son perfectos para aplicaciones que requieren reclasificaci\xF3n en tiempo real. Lea el punto de referencia a continuaci\xF3n."])},customize_urself:e=>{const{normalize:a}=e;return a(["\xA1C\xE1mbialo y ver\xE1s c\xF3mo cambia la respuesta!"])},customize_urself_pl:e=>{const{normalize:a}=e;return a(["\xA1C\xE1mbialos y observa c\xF3mo cambia la respuesta!"])},description:e=>{const{normalize:a}=e;return a(["Maximice la relevancia de la b\xFAsqueda y la precisi\xF3n de RAG c\xF3modamente."])},description_rich:e=>{const{normalize:a}=e;return a(["Maximice la relevancia de la b\xFAsqueda y la precisi\xF3n de RAG con nuestra API de reclasificaci\xF3n de vanguardia. Comience con 1 mill\xF3n de tokens gratis."])},example_input_document:e=>{const{normalize:a}=e;return a(["Ejemplos de documentos candidatos para clasificar"])},example_input_query:e=>{const{normalize:a}=e;return a(["Consulta de ejemplo"])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["El precio de la API Reranker est\xE1 alineado con nuestra estructura de precios de API integrada. Comienza con 1 mill\xF3n de tokens gratis por cada nueva clave API. M\xE1s all\xE1 de los tokens gratuitos, hay diferentes paquetes disponibles para su compra. Para obtener m\xE1s detalles, visite nuestra secci\xF3n de precios."])},answer10:e=>{const{normalize:a}=e;return a(["S\xED, Jina Reranker se puede implementar en AWS. Si necesita una implementaci\xF3n local en un entorno empresarial, puede hacerlo f\xE1cilmente a trav\xE9s de nuestra oferta de AWS Marketplace."])},answer11:e=>{const{normalize:a}=e;return a(["Si est\xE1 interesado en un reranker ajustado y adaptado a datos de dominio espec\xEDficos, comun\xEDquese con nuestro equipo de ventas. Nuestro equipo responder\xE1 a su consulta con prontitud."])},answer3:e=>{const{normalize:a}=e;return a(["La principal diferencia radica en su arquitectura. En cuanto al rendimiento, recomendamos jina-reranker-v1, que ha sido ampliamente probado y comparado con la competencia. Jina-reranker-v1 utiliza una arquitectura de codificador cruzado, mientras que Jina-colbert-v1 se basa en la arquitectura ColBERTv2 pero extiende la longitud del contexto tanto de la consulta como del documento a 8192, logrando un rendimiento a\xFAn mejor que el modelo ColBERTv2 original."])},answer4:e=>{const{normalize:a}=e;return a(["S\xED, jina-colbert-v1 es de c\xF3digo abierto y se puede acceder a \xE9l a trav\xE9s de Huggingface. Sin embargo, jina-reranker-v1 no es de c\xF3digo abierto."])},answer5:e=>{const{normalize:a}=e;return a(["Actualmente, solo admite ingl\xE9s. Sin embargo, algunos usuarios han informado que tambi\xE9n funciona bien con el chino. Esto puede deberse en parte a que jina-reranker-v1-base-en comparte algunos pesos con nuestro modelo de incrustaci\xF3n jina-embeddings-v2-base-zh."])},answer6:e=>{const{normalize:a}=e;return a(["La longitud m\xE1xima del token de consulta es 512. No hay l\xEDmite de token para los documentos."])},answer7:e=>{const{normalize:a}=e;return a(["Puede reclasificar hasta 2048 documentos por consulta."])},answer8:e=>{const{normalize:a}=e;return a(["No existe un concepto de tama\xF1o de lote a diferencia de nuestra API de incrustaci\xF3n. Puede enviar solo una tupla de documento de consulta por solicitud, pero la tupla puede incluir hasta 2048 documentos candidatos."])},answer9:e=>{const{normalize:a}=e;return a(["La latencia var\xEDa de 100 milisegundos a 7 segundos, dependiendo en gran medida de la longitud de los documentos y de la consulta. Por ejemplo, reclasificar 100 documentos de 256 tokens cada uno con una consulta de 64 tokens lleva unos 150 milisegundos. Aumentar la longitud del documento a 4096 tokens aumenta el tiempo a 3,5 segundos. Si la longitud de la consulta aumenta a 512 tokens, el tiempo aumenta a\xFAn m\xE1s a 7 segundos."])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1nto cuesta la API de Reranker?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFPuedo implementar Jina Reranker en AWS?"])},question11:e=>{const{normalize:a}=e;return a(["\xBFOfrecen un reranker ajustado en datos espec\xEDficos del dominio?"])},question3:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la diferencia entre los dos rerankers?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFJina Reranker es de c\xF3digo abierto?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFEl reranker admite varios idiomas?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la extensi\xF3n m\xE1xima para consultas y documentos?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la cantidad m\xE1xima de documentos que puedo reclasificar por consulta?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el tama\xF1o del lote y cu\xE1ntas tuplas de documentos de consulta puedo enviar en una solicitud?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 latencia puedo esperar al reclasificar 100 documentos?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas comunes relacionadas con el reranker"])}},feature_on_premises_description2:e=>{const{normalize:a}=e;return a(["Implemente Jina Reranker en AWS Sagemaker y pronto en Microsoft Azure y Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_on_premises_description3:e=>{const{normalize:a}=e;return a(["Implemente Jina Reranker en AWS Sagemaker y Microsoft Azure y pronto en Google Cloud Services, o comun\xEDquese con nuestro equipo de ventas para obtener implementaciones personalizadas de Kubernetes para su nube privada virtual y servidores locales."])},feature_solid_description:e=>{const{normalize:a}=e;return a(["Desarrollado a partir de nuestra investigaci\xF3n acad\xE9mica de vanguardia y probado rigurosamente con los reclasificadores SOTA para garantizar un rendimiento incomparable."])},how_it_works:e=>{const{normalize:a}=e;return a(["As\xED es como funciona:"])},how_it_works_v1:{description1:e=>{const{normalize:a}=e;return a(["Un sistema de b\xFAsqueda utiliza embeddings/BM25 para encontrar un amplio conjunto de documentos potencialmente relevantes en funci\xF3n de la consulta del usuario."])},description2:e=>{const{normalize:a}=e;return a(["Luego, el reclasificador toma estos resultados y los analiza a un nivel m\xE1s granular, considerando los matices de c\xF3mo los t\xE9rminos de consulta interact\xFAan con el contenido del documento."])},description3:e=>{const{normalize:a}=e;return a(["Reordena los resultados de la b\xFAsqueda, colocando en la parte superior los que considera m\xE1s relevantes, en base a este an\xE1lisis m\xE1s profundo."])},title1:e=>{const{normalize:a}=e;return a(["Recuperaci\xF3n inicial"])},title2:e=>{const{normalize:a}=e;return a(["Reclasificaci\xF3n"])},title3:e=>{const{normalize:a}=e;return a(["Resultados mejorados"])}},improve_performance:e=>{const{normalize:a}=e;return a(["Mejora garantizada sobre la b\xFAsqueda de vectores"])},improve_performance_description:e=>{const{normalize:a}=e;return a(["Nuestras evaluaciones demostraron mejoras en los sistemas de b\xFAsqueda que emplean Jina Reranker con un +8 % en la tasa de aciertos y un +33 % en la clasificaci\xF3n rec\xEDproca media."])},learning1:e=>{const{normalize:a}=e;return a(["Aprendiendo sobre Reranker"])},learning1_description:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es un reranker? \xBFPor qu\xE9 no es suficiente la b\xFAsqueda de vectores o la similitud de cosenos? Aprenda sobre los rerankers desde cero con nuestra gu\xEDa completa."])},read_more_about_benchmark:e=>{const{normalize:a}=e;return a(["Leer m\xE1s sobre el punto de referencia"])},read_more_about_turbo:e=>{const{normalize:a}=e;return a(["Lea m\xE1s sobre los modelos turbo y tiny"])},read_more_about_v2:e=>{const{normalize:a}=e;return a(["Jina Reranker v2 es el mejor reranker de su clase lanzado el 25 de junio de 2024; est\xE1 dise\xF1ado para Agentic RAG. Cuenta con soporte de llamada de funciones, recuperaci\xF3n multiling\xFCe para m\xE1s de 100 idiomas, capacidades de b\xFAsqueda de c\xF3digos y ofrece una velocidad 6 veces mayor que la v1. Lea m\xE1s sobre el modelo v2."])},reranker_description:e=>{const{normalize:a}=e;return a(["Pruebe nuestra API de reranker de vanguardia para maximizar la relevancia de su b\xFAsqueda y la precisi\xF3n de RAG. \xA1Empezando gratis!"])},show_v2benchmark:e=>{const{normalize:a}=e;return a(["Mostrar punto de referencia para el modelo v2 (m\xE1s reciente)"])},table:{number_token_document:e=>{const{normalize:a}=e;return a(["N\xFAmero de tokens en cada documento"])},number_token_query:e=>{const{normalize:a}=e;return a(["N\xFAmero de tokens en la consulta"])},title:e=>{const{normalize:a}=e;return a(["A continuaci\xF3n se muestra el costo de tiempo de reclasificar una consulta y 100 documentos en milisegundos:"])}},title:e=>{const{normalize:a}=e;return a(["API de reclasificaci\xF3n"])},top_n:e=>{const{normalize:a}=e;return a(["N\xFAmero de documentos devueltos"])},top_n_explain:e=>{const{normalize:a}=e;return a(["El n\xFAmero de documentos m\xE1s relevantes que se devolver\xE1n para la consulta."])},try_embedding:e=>{const{normalize:a}=e;return a(["Pruebe incorporar API de forma gratuita"])},try_reranker:e=>{const{normalize:a}=e;return a(["Pruebe la API de reranker gratis"])},v2_features:{description1:e=>{const{normalize:a}=e;return a(["Reranker v2 permite la recuperaci\xF3n de documentos en m\xE1s de 100 idiomas, independientemente del idioma de consulta."])},description2:e=>{const{normalize:a}=e;return a(["Reranker v2 clasifica fragmentos de c\xF3digo y firmas de funciones en funci\xF3n de consultas en lenguaje natural, ideal para aplicaciones Agentic RAG."])},description3:e=>{const{normalize:a}=e;return a(["Reranker v2 clasifica las tablas m\xE1s relevantes bas\xE1ndose en consultas en lenguaje natural, lo que ayuda a ordenar diferentes esquemas de tablas e identificar el m\xE1s relevante antes de generar una consulta SQL."])},title1:e=>{const{normalize:a}=e;return a(["Recuperaci\xF3n multiling\xFCe"])},title2:e=>{const{normalize:a}=e;return a(["Llamada de funciones y b\xFAsqueda de c\xF3digos"])},title3:e=>{const{normalize:a}=e;return a(["Soporte de datos tabulares y estructurados"])}},v2benchmark:{descBeir:e=>{const{normalize:a}=e;return a(["Puntuaciones NDCG 10 reportadas para diferentes modelos de reclasificaci\xF3n para el conjunto de datos de Beir"])},descCodeSearchNet:e=>{const{normalize:a}=e;return a(["Puntuaciones de MRR 10 informadas para diferentes modelos de reclasificaci\xF3n para el conjunto de datos CodeSearchNet"])},descMKQA:e=>{const{normalize:a}=e;return a(["Recuerde 10 puntuaciones reportadas para diferentes modelos de reclasificaci\xF3n para el conjunto de datos MKQA"])},descNSText2SQL:e=>{const{normalize:a}=e;return a(["Recuerde 3 puntuaciones reportadas para diferentes modelos de reclasificaci\xF3n para el conjunto de datos NSText2SQL"])},descRTX4090:e=>{const{normalize:a}=e;return a(["Puntuaciones de rendimiento (documentos recuperados en 50 ms) informadas para diferentes modelos de reclasificaci\xF3n en una GPU RTX 4090."])},descToolBench:e=>{const{normalize:a}=e;return a(["Recuerde 3 puntuaciones reportadas para diferentes modelos de reclasificaci\xF3n para el conjunto de datos de ToolBench"])},titleBeir:e=>{const{normalize:a}=e;return a(["BEIR (Par\xE1metro de referencia heterog\xE9neo en diversas tareas de RI)"])},titleCodeSearchNet:e=>{const{normalize:a}=e;return a(["C\xF3digoSearchNet. El punto de referencia es una combinaci\xF3n de consultas en formatos de cadena de documentaci\xF3n y lenguaje natural, con segmentos de c\xF3digo etiquetados relevantes para las consultas."])},titleMKQA:e=>{const{normalize:a}=e;return a(["MKQA (Preguntas y respuestas sobre conocimientos multiling\xFCes)"])},titleNSText2SQL:e=>{const{normalize:a}=e;return a(["NSText2SQL"])},titleRTX4090:e=>{const{normalize:a}=e;return a(["Rendimiento de Jina Reranker v2 en RTX4090"])},titleToolBench:e=>{const{normalize:a}=e;return a(["Banco de herramientas. El punto de referencia recopila m\xE1s de 16 mil API p\xFAblicas y las correspondientes instrucciones generadas sint\xE9ticamente para usarlas en configuraciones de API \xFAnica y m\xFAltiple."])}},vs_table:{col0:e=>{const{normalize:a}=e;return a(["reclasificador"])},col0_1:e=>{const{normalize:a}=e;return a(["Precisi\xF3n y relevancia de b\xFAsqueda mejoradas"])},col0_2:e=>{const{normalize:a}=e;return a(["Filtrado inicial y r\xE1pido"])},col0_3:e=>{const{normalize:a}=e;return a(["Recuperaci\xF3n de texto general en consultas de amplio alcance"])},col1:e=>{const{normalize:a}=e;return a(["B\xFAsqueda de vectores"])},col1_1:e=>{const{normalize:a}=e;return a(["Detallado: subdocumento y segmento de consulta"])},col1_2:e=>{const{normalize:a}=e;return a(["Amplio: documentos completos"])},col1_3:e=>{const{normalize:a}=e;return a(["Intermedio: varios segmentos de texto"])},col2:e=>{const{normalize:a}=e;return a(["BM25"])},col2_1:e=>{const{normalize:a}=e;return a(["Alto"])},col2_2:e=>{const{normalize:a}=e;return a(["Medio"])},col2_3:e=>{const{normalize:a}=e;return a(["Bajo"])},col3_1:e=>{const{normalize:a}=e;return a(["No requerido"])},col3_2:e=>{const{normalize:a}=e;return a(["Alto"])},col3_3:e=>{const{normalize:a}=e;return a(["Bajo, utiliza \xEDndice predise\xF1ado"])},col4_1:e=>{const{normalize:a}=e;return a(["Alto"])},col4_2:e=>{const{normalize:a}=e;return a(["Alto"])},col4_3:e=>{const{normalize:a}=e;return a(["No requerido"])},col5_1:e=>{const{normalize:a}=e;return a(["Superior para consultas matizadas"])},col5_2:e=>{const{normalize:a}=e;return a(["Equilibrado entre eficiencia y precisi\xF3n"])},col5_3:e=>{const{normalize:a}=e;return a(["Consistente y confiable para un amplio conjunto de consultas"])},col6_1:e=>{const{normalize:a}=e;return a(["Altamente preciso con una profunda comprensi\xF3n contextual."])},col6_2:e=>{const{normalize:a}=e;return a(["R\xE1pido y eficiente, con precisi\xF3n moderada."])},col6_3:e=>{const{normalize:a}=e;return a(["Altamente escalable, con eficacia establecida"])},col7_1:e=>{const{normalize:a}=e;return a(["Uso intensivo de recursos con implementaci\xF3n compleja"])},col7_2:e=>{const{normalize:a}=e;return a(["Es posible que no capture el contexto o los matices de la consulta profunda"])},col7_3:e=>{const{normalize:a}=e;return a(["Puede tener un rendimiento inferior en b\xFAsquedas muy espec\xEDficas o contextuales"])},header0:e=>{const{normalize:a}=e;return a(["Mejor para"])},header1:e=>{const{normalize:a}=e;return a(["Granularidad"])},header2:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de consulta"])},header3:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de indexaci\xF3n"])},header4:e=>{const{normalize:a}=e;return a(["Complejidad del tiempo de entrenamiento"])},header5:e=>{const{normalize:a}=e;return a(["Calidad de b\xFAsqueda"])},header6:e=>{const{normalize:a}=e;return a(["Fortalezas"])},header7:e=>{const{normalize:a}=e;return a(["Debilidades"])},subtitle:e=>{const{normalize:a}=e;return a(["La siguiente tabla proporciona una comparaci\xF3n completa de Reranker, Vector/Inbeddings Search y BM25, destacando sus fortalezas y debilidades en varias categor\xEDas."])},title:e=>{const{normalize:a}=e;return a(["Comparaci\xF3n de Reranker, Vector Search y BM25"])}},what_is:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es un reranker?"])},what_is_answer_long:e=>{const{normalize:a}=e;return a([`El objetivo de un sistema de b\xFAsqueda es encontrar los resultados m\xE1s relevantes de forma r\xE1pida y eficaz. Tradicionalmente, se han utilizado m\xE9todos como BM25 o tf-idf para clasificar los resultados de b\xFAsqueda seg\xFAn la concordancia de palabras clave. En muchas bases de datos vectoriales se han implementado m\xE9todos recientes, como la similitud de coseno basada en incrustaci\xF3n. Estos m\xE9todos son sencillos, pero a veces pueden pasar por alto las sutilezas del lenguaje y, lo m\xE1s importante, la interacci\xF3n entre los documentos y la intenci\xF3n de una consulta.

Aqu\xED es donde brilla el "reranker". Un reranker es un modelo de IA avanzado que toma el conjunto inicial de resultados de una b\xFAsqueda (a menudo proporcionado por una b\xFAsqueda incrustada/basada en tokens) y los reeval\xFAa para garantizar que se alineen m\xE1s estrechamente con la intenci\xF3n del usuario. Mira m\xE1s all\xE1 de la coincidencia superficial de t\xE9rminos para considerar la interacci\xF3n m\xE1s profunda entre la consulta de b\xFAsqueda y el contenido de los documentos.`])},what_is_answer_long_ending:e=>{const{normalize:a}=e;return a(["El reclasificador puede mejorar significativamente la calidad de la b\xFAsqueda porque opera a nivel de subdocumento y subconsulta, lo que significa que analiza las palabras y frases individuales, sus significados y c\xF3mo se relacionan entre s\xED dentro de la consulta y los documentos. Esto da como resultado un conjunto de resultados de b\xFAsqueda m\xE1s preciso y contextualmente relevante."])},what_is_desc:e=>{const{normalize:a}=e;return a(["Un reranker es un modelo de IA que refina los resultados de la b\xFAsqueda a partir de una b\xFAsqueda vectorial o un modelo de recuperaci\xF3n denso. Leer m\xE1s."])}},scenex:{caption_image_desc:e=>{const{normalize:a}=e;return a(["Generar una descripci\xF3n textual de la imagen."])},caption_image_title:e=>{const{normalize:a}=e;return a(["Imagen de t\xEDtulo"])},description:e=>{const{normalize:a}=e;return a(["Explore la narraci\xF3n de im\xE1genes m\xE1s all\xE1 de los p\xEDxeles"])},example1:e=>{const{normalize:a}=e;return a(["Este v\xEDdeo parece ser un metraje de la naturaleza que muestra un encantador conejito blanco y una mariposa en un campo de hierba. Se ve al conejito interactuando con la mariposa de diferentes maneras, mostrando su relaci\xF3n \xFAnica. El entorno natural proporciona un tel\xF3n de fondo pintoresco que realza la belleza de esta escena sencilla pero cautivadora."])},generate_story_desc:e=>{const{normalize:a}=e;return a(["Elabora una historia inspirada en la imagen, que a menudo incluye di\xE1logos o mon\xF3logos de sus personajes."])},generate_story_title:e=>{const{normalize:a}=e;return a(["Generar historia"])},intro1:e=>{const{normalize:a}=e;return a(["Soluci\xF3n l\xEDder de IA para subt\xEDtulos de im\xE1genes y res\xFAmenes de v\xEDdeos"])},json_image_desc:e=>{const{normalize:a}=e;return a(["Genere un formato JSON estructurado a partir de la imagen utilizando un esquema predefinido. Esto permite la extracci\xF3n de datos espec\xEDficos de la imagen."])},json_image_title:e=>{const{normalize:a}=e;return a(["Extraer JSON de la imagen"])},summarize_video_desc:e=>{const{normalize:a}=e;return a(["Genere un resumen conciso del v\xEDdeo, destacando los eventos clave."])},summarize_video_title:e=>{const{normalize:a}=e;return a(["Resumir v\xEDdeo"])},visual_q_a_desc:e=>{const{normalize:a}=e;return a(["Responda una consulta basada en el contenido de la imagen."])},visual_q_a_title:e=>{const{normalize:a}=e;return a(["Preguntas y respuestas visuales"])}},searchbar:{ask_on_current_page:e=>{const{normalize:a}=e;return a(["Pregunte a la p\xE1gina actual sobre..."])},find_solution:e=>{const{normalize:a}=e;return a(["Generar una soluci\xF3n para..."])},hint:e=>{const{normalize:a}=e;return a(["Busque productos, noticias y sus preguntas."])},hotkey:e=>{const{normalize:a}=e;return a(["Presione la tecla / para buscar en esta p\xE1gina"])},hotkey1:e=>{const{normalize:a}=e;return a(["Prensa"])},hotkey2:e=>{const{normalize:a}=e;return a(["para alternar"])},hotkey_long1:e=>{const{normalize:a}=e;return a(["En cualquier momento, presione"])},hotkey_long3:e=>{const{normalize:a}=e;return a(["para abrir la barra de b\xFAsqueda"])},more_results:e=>{const{normalize:a,interpolate:n,named:o}=e;return a([n(o("_numMore"))," m\xE1s resultados"])},placeholder:e=>{const{normalize:a}=e;return a(["Haga cualquier pregunta en esta p\xE1gina"])},proposing_solution:e=>{const{normalize:a}=e;return a(["Generando respuesta basada en el contenido de la p\xE1gina..."])},required:e=>{const{normalize:a}=e;return a(["Describe tu pregunta con m\xE1s detalles."])},results:e=>{const{normalize:a}=e;return a(["resultados"])}},searchscape:{description:e=>{const{normalize:a}=e;return a(["Navegue, interact\xFAe, perfeccione: vuelva a imaginar el descubrimiento de productos"])}},semantic:{description:e=>{const{normalize:a}=e;return a(["Cerrar la brecha sem\xE1ntica en su infraestructura de b\xFAsqueda existente"])}},share:{"Hacker News":e=>{const{normalize:a}=e;return a(["Noticias de piratas inform\xE1ticos"])},LinkedIn:e=>{const{normalize:a}=e;return a(["LinkedIn"])},facebook:e=>{const{normalize:a}=e;return a(["Facebook"])},reddit:e=>{const{normalize:a}=e;return a(["Reddit"])},rss:e=>{const{normalize:a}=e;return a(["RSS Feed"])},share_btn:e=>{const{normalize:a}=e;return a(["Compartir"])},twitter:e=>{const{normalize:a}=e;return a(["X (Twitter)"])}},spectrum:{click_to_learn_more:e=>{const{normalize:a}=e;return a(["Haz click para aprender mas"])},contextualization:e=>{const{normalize:a}=e;return a(["Contextualizaci\xF3n"])},contextualization_desc:e=>{const{normalize:a}=e;return a(["Los rerankers ajustan los resultados de b\xFAsqueda iniciales en funci\xF3n de una profunda relevancia contextual. consulta. Esto refina la clasificaci\xF3n para que coincida mejor con lo que los usuarios probablemente encuentren \xFAtil."])},coreInfra:e=>{const{normalize:a}=e;return a(["Infraestructura central"])},coreInfra_desc:e=>{const{normalize:a}=e;return a(["Core Infra proporciona una capa nativa de la nube para desarrollar, implementar y orquestar modelos b\xE1sicos de b\xFAsqueda tanto en la nube p\xFAblica como en las instalaciones, lo que permite que los servicios aumenten y disminuyan sin esfuerzo."])},embedding_serving:e=>{const{normalize:a}=e;return a(["Incrustar servicio"])},embedding_serving_description:e=>{const{normalize:a}=e;return a(["Entrega de incorporaciones a trav\xE9s de un microservicio robusto y escalable que utiliza tecnolog\xEDas nativas de la nube."])},embedding_tech:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},embedding_tech_description:e=>{const{normalize:a}=e;return a([`En Jina AI, aprovechamos el poder de la tecnolog\xEDa integrada para revolucionar diversas aplicaciones de IA. Esta tecnolog\xEDa sirve como un m\xE9todo unificado para representar y comprimir de manera eficiente varios tipos de datos, garantizando que no se pierda informaci\xF3n cr\xEDtica. Nuestro objetivo es transformar conjuntos de datos complejos en un formato de incrustaci\xF3n universalmente comprensible, lo cual es esencial para un an\xE1lisis de IA preciso y revelador.

Las incrustaciones son fundamentales, especialmente en aplicaciones como el reconocimiento preciso de im\xE1genes y voz, donde ayudan a discernir detalles y matices finos. En el procesamiento del lenguaje natural, las incorporaciones mejoran la comprensi\xF3n del contexto y el sentimiento, lo que lleva a herramientas de traducci\xF3n de idiomas e inteligencia artificial conversacional m\xE1s precisas. Tambi\xE9n son cruciales para desarrollar sistemas de recomendaci\xF3n sofisticados que requieren una comprensi\xF3n profunda de las preferencias del usuario en diferentes formas de contenido, como texto, audio y video.`])},embedding_tuning:e=>{const{normalize:a}=e;return a(["Ajuste de incrustaci\xF3n"])},embedding_tuning_description:e=>{const{normalize:a}=e;return a(["Optimizaci\xF3n de incorporaciones de alta calidad mediante la integraci\xF3n de experiencia en el dominio para mejorar el rendimiento de tareas espec\xEDficas."])},embeddings:e=>{const{normalize:a}=e;return a(["Incrustaciones"])},embeddings_desc:e=>{const{normalize:a}=e;return a(["Las incrustaciones son la piedra angular del sistema de b\xFAsqueda moderno y representan datos multimodales en vectores de n\xFAmeros. Este proceso permite una comprensi\xF3n m\xE1s matizada y contextual del contenido, mucho m\xE1s all\xE1 de la simple coincidencia de palabras clave."])},for_developers:e=>{const{normalize:a}=e;return a(["Para desarrolladores"])},for_enterprise:e=>{const{normalize:a}=e;return a(["Para Empresas"])},for_power_users:e=>{const{normalize:a}=e;return a(["Para usuarios avanzados"])},grounding:e=>{const{normalize:a}=e;return a(["Toma de tierra"])},grounding_desc:e=>{const{normalize:a}=e;return a(["Lector refinando entradas y resultados a trav\xE9s de LLM. Mejoran la calidad, legibilidad y factibilidad de la respuesta final."])},model_serving:e=>{const{normalize:a}=e;return a(["Servicio modelo"])},model_serving_description:e=>{const{normalize:a}=e;return a(["La implementaci\xF3n de modelos ajustados en un entorno de producci\xF3n, que generalmente requiere recursos sustanciales, como el alojamiento de GPU. MLOps, enfatizando el servicio de modelos medianos a grandes de una manera escalable, eficiente y confiable."])},model_tuning:e=>{const{normalize:a}=e;return a(["Ajuste del modelo"])},model_tuning_description:e=>{const{normalize:a}=e;return a(["Tambi\xE9n conocido como ajuste fino, implica ajustar los par\xE1metros de un modelo previamente entrenado en un nuevo conjunto de datos, a menudo espec\xEDfico de una tarea, para mejorar su rendimiento y adaptarlo a una aplicaci\xF3n espec\xEDfica."])},personalization:e=>{const{normalize:a}=e;return a(["Personalizaci\xF3n"])},personalization_desc:e=>{const{normalize:a}=e;return a(["Uso de datos sint\xE9ticos guiados por las instrucciones del usuario para entrenar autom\xE1ticamente un modelo de incrustaci\xF3n y reclasificaci\xF3n espec\xEDfico del dominio."])},preprocessing:e=>{const{normalize:a}=e;return a(["Preprocesamiento"])},preprocessing_desc:e=>{const{normalize:a}=e;return a(["El preprocesamiento implica limpiar, normalizar y transformar datos sin procesar en un formato que el sistema de b\xFAsqueda pueda digerir."])},promptOps:e=>{const{normalize:a}=e;return a(["Operaciones inmediatas"])},promptOps_desc:e=>{const{normalize:a}=e;return a(["Prompt Ops mejora la entrada y salida del sistema de b\xFAsqueda, incluidas las utilizadas en la expansi\xF3n de consultas, la entrada de LLM y la reescritura de resultados. Esto garantiza que la b\xFAsqueda se comprenda mejor y obtenga mejores resultados."])},prompt_serving:e=>{const{normalize:a}=e;return a(["Servicio r\xE1pido"])},prompt_serving_description:e=>{const{normalize:a}=e;return a(["Envolviendo y entregando avisos a trav\xE9s de una API, sin alojar modelos pesados. La API llama a un servicio de modelo de lenguaje grande p\xFAblico y maneja la orquestaci\xF3n de entradas y salidas en una cadena de operaciones."])},prompt_tech:e=>{const{normalize:a}=e;return a(["Ingenier\xEDa r\xE1pida y de agentes"])},prompt_tech_description:e=>{const{normalize:a}=e;return a([`En Jina AI, reconocemos que la ingenier\xEDa r\xE1pida es vital para interactuar con grandes modelos de lenguaje (LLM). A medida que estos modelos avanzan, la complejidad de las indicaciones aumenta, abarcando razonamiento y l\xF3gica intrincados. Este avance subraya el crecimiento entrelazado de los LLM y la sofisticaci\xF3n inmediata.

Prevemos un futuro en el que los LLM actuar\xE1n como compiladores y los mensajes se convertir\xE1n en el nuevo lenguaje de programaci\xF3n. Este cambio sugiere que el dominio tecnol\xF3gico futuro puede centrarse m\xE1s en el dominio r\xE1pido que en la codificaci\xF3n tradicional. Nuestro compromiso en Jina AI es liderar esta \xE1rea transformadora, haciendo que la IA avanzada sea accesible y pr\xE1ctica para el uso diario al dominar este "lenguaje" emergente.`])},prompt_tuning:e=>{const{normalize:a}=e;return a(["Sintonizaci\xF3n r\xE1pida"])},prompt_tuning_description:e=>{const{normalize:a}=e;return a(["El proceso de elaborar y refinar las indicaciones de entrada para guiar su salida hacia respuestas espec\xEDficas y deseadas."])},representation:e=>{const{normalize:a}=e;return a(["Representaci\xF3n"])},representation_desc:e=>{const{normalize:a}=e;return a(["Las incrustaciones transforman datos multimodales en un formato vectorizado uniforme. Esto permite que el sistema de b\xFAsqueda comprenda y categorice el contenido m\xE1s all\xE1 de simples palabras clave."])},rerankers:e=>{const{normalize:a}=e;return a(["reclasificador"])},rerankers_desc:e=>{const{normalize:a}=e;return a(["Los rerankers toman los resultados iniciales de las incrustaciones y los refinan, asegurando que se presenten los resultados m\xE1s relevantes al usuario. Esto es crucial para ofrecer resultados de b\xFAsqueda de alta calidad que cumplan con la intenci\xF3n del usuario."])}},subscribe_system:{care_most:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es lo que m\xE1s te importa?"])},care_most_options:{accuracy:e=>{const{normalize:a}=e;return a(["Exactitud"])},cost:e=>{const{normalize:a}=e;return a(["Costo"])},other:e=>{const{normalize:a}=e;return a(["Otro"])},scalability:e=>{const{normalize:a}=e;return a(["Escalabilidad"])},speed:e=>{const{normalize:a}=e;return a(["Velocidad"])}},care_most_required:e=>{const{normalize:a}=e;return a(["A la hora de elegir un servicio, \xBFqu\xE9 es lo que m\xE1s te importa?"])},company_size:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el tama\xF1o de su empresa?"])},company_size_required:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos el tama\xF1o de tu empresa nos ayuda a dar un mejor servicio"])},company_url:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es el sitio web de su empresa?"])},company_url_required:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos que la web de tu empresa nos ayuda a dar un mejor servicio"])},contactName:e=>{const{normalize:a}=e;return a(["Su nombre"])},contactName_required:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo deber\xEDamos dirigirnos a usted?"])},contactTitle:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es su profesi\xF3n?"])},contactTitle_required:e=>{const{normalize:a}=e;return a(["Su t\xEDtulo de trabajo es requerido"])},contact_us:e=>{const{normalize:a}=e;return a(["Cont\xE1ctenos"])},domain_required:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos tu dominio de trabajo nos ayuda a dar un mejor servicio"])},email:e=>{const{normalize:a}=e;return a(["Correo electr\xF3nico"])},email_contact:e=>{const{normalize:a}=e;return a(["Tu correo electr\xF3nico de contacto"])},email_invalid:e=>{const{normalize:a}=e;return a(["el correo electr\xF3nico es invalido"])},email_required:e=>{const{normalize:a}=e;return a(["correo electronico es requerido"])},fine_tuned_embedding:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 interesado en incorporaciones optimizadas y adaptadas a sus datos y caso de uso? \xA1Vamos a discutir!"])},fine_tuned_reranker:e=>{const{normalize:a}=e;return a(["\xBFEst\xE1 interesado en reclasificadores ajustados y adaptados a sus datos y caso de uso? \xA1Vamos a discutir!"])},full_survey:e=>{const{normalize:a}=e;return a(["Responda la encuesta completa y obtenga una respuesta m\xE1s r\xE1pida de nuestro equipo"])},get_new_key:e=>{const{normalize:a}=e;return a(["Obtenga su clave API"])},get_update_blog_posts:e=>{const{normalize:a}=e;return a(["Obtenga las \xFAltimas actualizaciones de las publicaciones del blog."])},get_update_embeddings:e=>{const{normalize:a}=e;return a(["Obtenga las \xFAltimas actualizaciones para las incorporaciones"])},send:e=>{const{normalize:a}=e;return a(["Enviar"])},sign_up:e=>{const{normalize:a}=e;return a(["Inscribirse"])},subscribe:e=>{const{normalize:a}=e;return a(["Suscribir"])},tell_domain:e=>{const{normalize:a}=e;return a(["Cu\xE9ntanos tu dominio"])},usage_type:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 tipo de uso te describe mejor?"])},usage_type_options:{other:e=>{const{normalize:a}=e;return a(["Otro"])},poc:e=>{const{normalize:a}=e;return a(["Prueba de concepto"])},production:e=>{const{normalize:a}=e;return a(["Producci\xF3n"])},research:e=>{const{normalize:a}=e;return a(["Investigaci\xF3n"])}},usage_type_required:e=>{const{normalize:a}=e;return a(["D\xEDganos que su tipo de uso nos ayuda a brindar un mejor servicio."])},used_product:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 modelo est\xE1s usando?"])},used_product_required:e=>{const{normalize:a}=e;return a(["Selecciona el modelo que est\xE1s utilizando o te interesa"])}},think_gpt:{description:e=>{const{normalize:a}=e;return a(["T\xE9cnicas de agentes para aumentar su LLM y llevarlo m\xE1s all\xE1 de sus l\xEDmites"])}},tokenizer:{advance_usage:e=>{const{normalize:a}=e;return a(["Utilice la solicitud POST para obtener m\xE1s funciones"])},basic_usage:e=>{const{normalize:a}=e;return a(["Utilice la solicitud GET para contar tokens"])},basic_usage_explain:e=>{const{normalize:a}=e;return a(["Simplemente puede enviar una solicitud GET para contar la cantidad de tokens en su texto."])},change_content:e=>{const{normalize:a}=e;return a(["Cambie el 'contenido' y vea el resultado en vivo"])},chars:e=>{const{normalize:a}=e;return a(["personajes"])},chinese:e=>{const{normalize:a}=e;return a(["Chino"])},chunk:e=>{const{normalize:a}=e;return a(["Pedazo"])},chunk_all:e=>{const{normalize:a}=e;return a(["Todos los trozos"])},chunking:e=>{const{normalize:a}=e;return a(["\xA1Agrupe documentos largos a la velocidad del rayo!"])},chunking_explain:e=>{const{normalize:a}=e;return a(["Tambi\xE9n puede utilizar la API Tokenizer para dividir documentos largos en segmentos m\xE1s peque\xF1os, lo que facilita su procesamiento en incrustaciones o reclasificadores. Aprovechamos las se\xF1ales estructurales comunes y creamos un conjunto de reglas y heur\xEDsticas que deber\xEDan funcionar excepcionalmente bien en diversos tipos de contenido, incluidos Markdown, HTML, LaTeX y m\xE1s, lo que garantiza una segmentaci\xF3n precisa del texto en fragmentos significativos."])},chunking_short:e=>{const{normalize:a}=e;return a(["Fragmentaci\xF3n"])},chunks_in_total:e=>{const{normalize:a,interpolate:n,named:o}=e;return a([n(o("_numChunks"))," fragmentos en total"])},count_tokens_hint:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["<b>",n(o("_numTokens")),"</b> tokens, ",n(o("_numChars"))," caracteres."])},description:e=>{const{normalize:a}=e;return a(["API gratuita para tokenizar textos, contar y obtener los primeros/\xFAltimos N tokens."])},description_long:e=>{const{normalize:a}=e;return a(["Nuestra API Tokenizer es fundamental para ayudar a los LLM a gestionar la entrada dentro de los l\xEDmites del contexto y optimizar el rendimiento del modelo. Permite a los desarrolladores contar tokens y extraer segmentos de texto relevantes, lo que garantiza un procesamiento de datos eficiente y una gesti\xF3n de costos."])},english:e=>{const{normalize:a}=e;return a(["Ingl\xE9s"])},explain:e=>{const{normalize:a}=e;return a(["Un tokenizador es un componente crucial que convierte texto en tokens, que son las unidades b\xE1sicas de datos que procesa un modelo de incrustaci\xF3n/reclasificaci\xF3n o LLM. Los tokens pueden representar palabras completas, partes de palabras o incluso caracteres individuales."])},faq_v1:{answer1:e=>{const{normalize:a}=e;return a(["La API de Tokenizer es de uso gratuito. Si proporciona su clave API, podr\xE1 acceder a un l\xEDmite de tasa m\xE1s alto y no se le cobrar\xE1 por su clave."])},answer10:e=>{const{normalize:a}=e;return a(["Adem\xE1s de los idiomas occidentales, la fragmentaci\xF3n tambi\xE9n funciona bien con el chino, el japon\xE9s y el coreano."])},answer2:e=>{const{normalize:a}=e;return a(["Sin una clave API, puede acceder a la API de Tokenizer con un l\xEDmite de velocidad de 20 RPM."])},answer3:e=>{const{normalize:a}=e;return a(["Con una clave API, puedes acceder a la API de Tokenizer con un l\xEDmite de velocidad de 200 RPM. Para los usuarios premium pagos, el l\xEDmite de velocidad es de 1000 RPM."])},answer4:e=>{const{normalize:a}=e;return a(["No, su clave API solo se utiliza para acceder a un l\xEDmite de velocidad m\xE1s alto."])},answer5:e=>{const{normalize:a}=e;return a(["S\xED, la API de Tokenizer es multiling\xFCe y admite m\xE1s de 100 idiomas."])},answer6:e=>{const{normalize:a}=e;return a(["Las solicitudes GET se utilizan \xFAnicamente para contar la cantidad de tokens en un texto, lo que le permite integrarlo f\xE1cilmente como un contador en su aplicaci\xF3n. Las solicitudes POST admiten m\xE1s par\xE1metros y funciones, como devolver los primeros/\xFAltimos N tokens."])},answer7:e=>{const{normalize:a}=e;return a(["Puede enviar hasta 4 millones de caracteres por solicitud."])},answer8:e=>{const{normalize:a}=e;return a(["La funci\xF3n de fragmentaci\xF3n segmenta documentos largos en fragmentos m\xE1s peque\xF1os seg\xFAn se\xF1ales estructurales comunes, lo que garantiza una segmentaci\xF3n precisa del texto en fragmentos significativos. B\xE1sicamente, se trata de un patr\xF3n de expresiones regulares (\xA1grande!) que segmenta el texto seg\xFAn ciertas caracter\xEDsticas sint\xE1cticas que suelen coincidir con los l\xEDmites sem\xE1nticos, como los finales de las oraciones, los saltos de p\xE1rrafo, la puntuaci\xF3n y ciertas conjunciones. No se trata de fragmentaci\xF3n sem\xE1ntica. Esta expresi\xF3n regular (grande) es tan potente como puede serlo dentro de las limitaciones de las expresiones regulares. Equilibra la complejidad y el rendimiento. Si bien la verdadera comprensi\xF3n sem\xE1ntica no es posible con las expresiones regulares, se aproxima bien al contexto mediante se\xF1ales estructurales comunes."])},answer9:e=>{const{normalize:a}=e;return a(["Si la entrada contiene tokens especiales, nuestra API Tokenizer los colocar\xE1 en el campo 'special_tokens'. Esto le permite identificarlos f\xE1cilmente y manejarlos como corresponde para sus tareas posteriores, por ejemplo, eliminarlos antes de introducir el texto en un LLM para evitar ataques de inyecci\xF3n."])},question1:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1nto cuesta la API de Tokenizer?"])},question10:e=>{const{normalize:a}=e;return a(["\xBFLa funci\xF3n de chunking admite otros idiomas adem\xE1s del ingl\xE9s?"])},question2:e=>{const{normalize:a}=e;return a(["Si no proporciono una clave API, \xBFcu\xE1l es el l\xEDmite de velocidad?"])},question3:e=>{const{normalize:a}=e;return a(["Si proporciono una clave API, \xBFcu\xE1l es el l\xEDmite de velocidad?"])},question4:e=>{const{normalize:a}=e;return a(["\xBFCobrar\xE1s los tokens de mi clave API?"])},question5:e=>{const{normalize:a}=e;return a(["\xBFLa API de Tokenizer admite varios idiomas?"])},question6:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la diferencia entre las solicitudes GET y POST?"])},question7:e=>{const{normalize:a}=e;return a(["\xBFCu\xE1l es la longitud m\xE1xima que puedo tokenizar por solicitud?"])},question8:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo funciona la funci\xF3n de fragmentaci\xF3n? \xBFSe trata de fragmentaci\xF3n sem\xE1ntica?"])},question9:e=>{const{normalize:a}=e;return a(["\xBFC\xF3mo se manejan tokens especiales como 'endoftext' en la API Tokenizer?"])},title:e=>{const{normalize:a}=e;return a(["Preguntas frecuentes relacionadas con Tokenizer"])}},free_api:e=>{const{normalize:a}=e;return a(["La API de Tokenizer es de uso gratuito. Si proporciona su clave API, podr\xE1 acceder a un l\xEDmite de tasa m\xE1s alto y no se le cobrar\xE1 por su clave."])},input_text:e=>{const{normalize:a}=e;return a(["Texto de entrada"])},is_free:e=>{const{normalize:a}=e;return a(["\xA1La API de Tokenizer es gratuita!"])},is_free_description:e=>{const{normalize:a}=e;return a(["Al proporcionar su clave API, podr\xE1 acceder a un l\xEDmite de tarifa m\xE1s alto y no se le cobrar\xE1 su clave."])},japanese:e=>{const{normalize:a}=e;return a(["japon\xE9s"])},korean:e=>{const{normalize:a}=e;return a(["coreano"])},parameters:{auth_token:e=>{const{normalize:a}=e;return a(["Agregar clave API para l\xEDmite de velocidad m\xE1s alto"])},auth_token_explain:e=>{const{normalize:a}=e;return a(["Ingresa tu clave API de Jina para acceder a un l\xEDmite de velocidad m\xE1s alto. Para obtener la informaci\xF3n m\xE1s actualizada sobre el l\xEDmite de velocidad, consulta la siguiente tabla."])},head:e=>{const{normalize:a}=e;return a(["Devuelve los primeros N tokens"])},head_explain:e=>{const{normalize:a}=e;return a(["Devuelve los primeros N tokens del contenido indicado. Excluye l\xEDmites. No se puede utilizar con 'tail'."])},learn_more:e=>{const{normalize:a}=e;return a(["M\xE1s informaci\xF3n"])},max_chunk_length:e=>{const{normalize:a}=e;return a(["Longitud m\xE1xima de cada fragmento"])},max_chunk_length_explain:e=>{const{normalize:a}=e;return a(["N\xFAmero m\xE1ximo de caracteres en cada fragmento. En la pr\xE1ctica, la longitud del fragmento puede ser menor que este valor, si existe un l\xEDmite natural en el texto."])},return_chunks:e=>{const{normalize:a}=e;return a(["Devolver los trozos"])},return_chunks_explain:e=>{const{normalize:a}=e;return a(["Dividir la entrada en segmentos sem\xE1nticamente significativos mientras se maneja una amplia variedad de tipos de texto y casos extremos basados en se\xF1ales estructurales comunes."])},return_tokens:e=>{const{normalize:a}=e;return a(["Devolver las fichas"])},return_tokens_explain:e=>{const{normalize:a}=e;return a(["Devuelve los tokens y sus identificadores correspondientes en la respuesta. Activa o desactiva esta opci\xF3n para ver la visualizaci\xF3n del resultado."])},tail:e=>{const{normalize:a}=e;return a(["Devuelve los \xFAltimos N tokens"])},tail_explain:e=>{const{normalize:a}=e;return a(["Devuelve los \xFAltimos N tokens del contenido indicado. Excluye l\xEDmites. No se puede utilizar con 'head'."])},type:e=>{const{normalize:a}=e;return a(["Tokenizador"])},type_explain:e=>{const{normalize:a}=e;return a(["Seleccione el tokenizador a utilizar."])},used_by_models:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Utilizado en ",n(o("_usedBy")),"."])}},remove_boundary_cues:e=>{const{normalize:a}=e;return a(["Eliminar saltos de l\xEDnea"])},remove_boundary_cues_explain:e=>{const{normalize:a}=e;return a(["Elimine todos los saltos de l\xEDnea (las principales se\xF1ales de l\xEDmite) de la entrada, esto hace que el problema sea m\xE1s desafiante y observe c\xF3mo cambia la respuesta."])},show_space:e=>{const{normalize:a}=e;return a(["Mostrar espacios iniciales y finales"])},table:{td_1_0:e=>{const{normalize:a}=e;return a(["Tokeniza textos, cuenta y obt\xE9n los primeros/\xFAltimos N tokens."])},td_1_1:e=>{const{normalize:a}=e;return a(["20 RPM"])},td_1_2:e=>{const{normalize:a}=e;return a(["200 RPM"])},td_1_3:e=>{const{normalize:a}=e;return a(["1000 RPM"])},td_1_4:e=>{const{normalize:a}=e;return a(["Sin cargo"])},td_1_5:e=>{const{normalize:a}=e;return a(["800 ms"])}},title:e=>{const{normalize:a}=e;return a(["API de tokenizador"])},token_index:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["\xCDndice de token: ",n(o("_index"))])},usage:e=>{const{normalize:a}=e;return a(["Uso"])},visualization:e=>{const{normalize:a}=e;return a(["Visualizaci\xF3n"])},what_is:e=>{const{normalize:a}=e;return a(["\xBFQu\xE9 es un Tokenizador?"])}},translator:{cta:e=>{const{normalize:a,interpolate:n,named:o}=e;return a(["Traducir al c\xF3digo ",n(o("_lang"))])},select_language:e=>{const{normalize:a}=e;return a(["Idioma"])}},vectordb:{description:e=>{const{normalize:a}=e;return a(["Una base de datos vectorial de Python que solo necesita, ni m\xE1s ni menos"])}},zzz:e=>{const{normalize:a}=e;return a(["zzz"])}};export{r as default};
