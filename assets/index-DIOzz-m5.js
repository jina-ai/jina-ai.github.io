const e="우리는 최첨단 벡터 모델, 재배열기, LLM 판독기 및 프롬프트 단어 최적화 기능을 제공하여 다중 모드 데이터에 대한 최첨단 검색 AI를 강화합니다.",n="귀하의 검색은 다시는 동일하지 않습니다.",t={approach:"우리의 전략",approach_connect_dots:"드로잉 와이어: 고급 사용자에서 엔터프라이즈 사용자로",approach_connect_dots_description:"전반적인 전략에서 고급 사용자를 그토록 강조하는 이유는 무엇입니까? 이는 사전 계획에 대한 고려 사항입니다. 내일의 기업에 대한 영향력을 위해 오늘 투자하십시오. 이러한 고급 사용자가 기업의 목소리를 맡을 때 우리는 여전히 그들을 위해 존재하도록 보장하는 것이 우리의 비전입니다.",approach_content1:"끊임없이 변화하는 인공지능 환경에서 전략은 유연해야 하며 미래에 대한 통찰력을 갖춰야 합니다. 진아AI는 기업 중심이지만 AI 분야도 진화했고, 고객 유치 전략도 시대에 발맞춰야 한다. 따라서 고급 사용자를 돌파구로 삼는 것은 우리의 전략적 혁신일 뿐만 아니라 기업 발전에 대한 우리의 끈기를 반영하는 것이기도 합니다.",approach_content2:"Jina AI에서는 성공에 안주하지 않고 과감하게 혁신을 시도합니다. 고급 사용자와 함께 선도하면 현재를 파악하고 미래를 예측할 수 있습니다. 기업에 있어서 우리의 결심은 확고부동하지만, 성공을 향한 길에서 우리는 꾸준하고 미래지향적인 새로운 길을 가고 있습니다.",approach_content4:'누구나 더 나은 검색 경험을 원합니다. Jina AI에서는 벡터 모델, 재배열기, 리더기, 프롬프트 단어 엔지니어링 경험으로 구성된 <span class="text-primary text-bold">검색 기반</span>을 제공하여 더 나은 검색을 가능하게 합니다. 이러한 구성 요소는 함께 작동하여 데이터를 검색하고 이해하는 방식을 혁신합니다.',approach_miss_mark:"기존 MLOps의 단점",approach_miss_mark_description:"고급 사용자 수가 증가함에도 불구하고 기존 MLOps 도구는 불안정하고 요구 사항을 충족하지 못하는 경우가 많습니다. 그들은 새로운 시대의 빠른 경쟁에 대처할 수 없는 낡은 말과 같습니다. 새로운 세대의 개발자들은 더 가볍고 직관적인 무기를 원합니다.",approach_new_paradigm:"프롬프트 프로젝트: AI 개발의 새로운 트렌드",approach_new_paradigm_description:"2023년에는 AI 세상이 새로운 장을 열고, 프롬프트 워드 프로젝트가 빠르게 추진되어 AI 도구의 대중화 과정이 실현될 것이다. 프로그래밍 기초가 부족한 고급 사용자라도 Pytorch, Docker 또는 Kubernetes에 겁을 먹을 필요 없이 AI에 쉽게 참여할 수 있습니다. 이러한 상황은 개인용 컴퓨팅의 부상과 매우 유사합니다. 그 당시에는 기술 엘리트만이 컴퓨터와 통신할 수 있었지만, 보다 사용자 친화적인 인터페이스의 출현으로 대중도 그 대열에 합류할 수 있게 되었습니다. 오늘날 우리는 프롬프트 엔지니어링의 인기와 함께 AI 분야에서도 새로운 인기의 물결을 목격하고 있습니다.",awards:"수상 및 우수성",berlin:"독일 베를린(본사)",berlin_address:"Prinzessinnenstraße 19-20, 10969 베를린, 독일",berlin_address2:"등록된 주소: Leipzigerstr. 96, 10117 베를린, 독일",bj:"중국 베이징",bj_address:"중국 베이징 하이뎬구 서가 48호 6호관 5층",brochure_info:"우리 회사 가이드가 당신을 기다립니다",description:"미래는 여기서 시작됩니다.",download_brochure1:"브로셔 다운로드",download_docarray_logo:"DocArray 로고 다운로드",download_docarray_logo_desc:"Jina AI가 시작하고 2022년 12월 Linux 재단에 기부한 오픈소스 프로젝트인 DocArray 로고를 받으세요. 밝고 어두운 모드, PNG 및 SVG 형식으로 제공됩니다.",download_jina_logo:"지나AI 로고 다운로드",download_jina_logo_desc:"PNG 및 SVG 형식으로 제공되는 밝은 모드와 어두운 모드의 Jina AI 로고를 받으세요. 이 마크는 유럽연합 지적재산권청(EUIPO)의 등록 상표입니다.",download_logo:"로고 다운로드",employees:"오늘의 직원",empower_developers:"개발자 생태계",fastApiCaption:"2021년부터 $20,000 이상 기부했습니다.",founded:"설립연도",founded_in:"에 설립되었습니다",investors:"우리 투자자들",linuxFoundationCaption:"2022년부터 연간 $10,000를 기부하세요.",many:"많은",media:{video:"비디오 인터뷰"},mission:"우리의 미션",mission_content1:"우리의 핵심 기술에는 빠른 튜닝, 빠른 서빙, 모델 튜닝 및 모델 서빙이 포함되며 이는 인공 지능을 민주화하려는 우리의 노력을 반영합니다. 오픈 소스 프로그램을 통해 우리는 확장 가능하고 효율적이며 강력한 솔루션을 보장하기 위해 혁신, 협업 및 투명성을 촉진하기 위해 노력하고 있습니다. Jina AI는 단순한 회사가 아니라 기업이 디지털 시대의 역동적인 과제를 해결하고 해당 분야에서 성공할 수 있도록 돕는 데 전념하는 커뮤니티입니다.",mission_content2:"Jina AI의 핵심 철학은 파워 유저와 개발자부터 대기업까지 다양한 모드의 AI 채널이 되는 것입니다. 우리는 오픈 소스의 힘을 믿으며 AI 커뮤니티를 위한 접근 가능한 최첨단 도구를 구축하는 데 최선을 다하고 있습니다. 프롬프트 단어 미세 조정, 모델 벡터 튜닝 및 배포 등 핵심 기술은 AI 대중화에 대한 확고한 믿음을 보여줍니다. 오픈 소스 접근 방식을 통해 우리는 혁신, 협업 및 투명성을 추구하여 확장 가능하고 효율적이며 강력한 접근 방식을 보장하는 것을 목표로 합니다. Jina AI는 단순한 회사가 아닌, 기업이 디지털 시대의 도전에 대처하고 해당 분야에서 계속 선두를 유지할 수 있도록 돕는 커뮤니티입니다.",mission_content3:"Jina AI의 임무는 혁신적인 벡터 모델과 힌트 기반 기술을 통해 멀티모달 AI 개발을 선도하는 것입니다. 우리는 자연어 처리, 이미지 및 비디오 분석, 교차 모드 데이터 상호 작용과 같은 영역에 특히 중점을 두고 있습니다. 우리의 전문 분야는 복잡한 다중 소스 데이터를 실제 실행 가능한 가치를 지닌 통찰력과 혁신적인 애플리케이션으로 변환하는 고유한 솔루션을 제공하는 데 중점을 두고 있습니다.",mit_report_title:"다중 방식: 인공 지능의 새로운 개척지",mit_techreview:"MIT 기술 검토",numfocusCaption:"2022년부터 매달 정기적으로 기부해 보세요.",office:"우리 사무실",otherProjectsCaption:"Github 후원을 통해 $3,000 이상 기부했습니다.",our_answer:"더 이상 동의할 수 없습니다, Yann. 우리는 멀티모달 AI 미래를 향한 가교를 구축하기 위해 열심히 노력하고 있습니다!",pythonSoftwareFoundationCaption:"일회성으로 10,000달러를 기부하고 독일, 이탈리아, 중국, 미국을 포함한 여러 PyCon 이벤트를 후원했습니다.",sefo:{layer0:"사용자 지향 애플리케이션",layer1:"RAG/편곡 시스템",layer3:"GPU/모바일/엣지/로컬 컴퓨팅"},segmentFaultCaption:"6,000달러를 일회성으로 기부해 보세요.",show_position:"생태계에서 Search Foundation의 위치는 무엇입니까?",stats_1:"진아AI는 2020년 2월 설립됐다. 단 20개월 만에 멀티모달 AI 기술 분야의 선두주자로 성장했다. 이 기간 동안 우리는 3,750만 달러의 자금을 성공적으로 조달하여 AI 업계의 리더로 자리매김했습니다. GitHub에서는 혁신적인 오픈 소스 기술을 통해 40,000명 이상의 개발자가 아무런 장벽 없이 다중 모드 앱을 구축하고 배포할 수 있습니다.",stats_2:"2023년까지 우리는 멀티모달 기술을 기반으로 AI 도구 분야에서 도약을 이루었습니다. 이 혁신은 250,000명 이상의 사용자에게 혜택을 주어 다양한 비즈니스 요구 사항을 충족시켰습니다. 비즈니스 성장을 주도하든, 운영 효율성을 개선하든, 비용을 최적화하든, Jina AI는 기업이 다중 모드 시대에서 앞서 나갈 수 있도록 지원하는 데 최선을 다하고 있습니다.",stats_4:'지나AI는 2020년 설립된 검색 AI 선도 기업이다. 당사의 <span class="text-primary text-bold">검색 기반</span> 플랫폼에는 벡터 모델, 재배열기 및 작은 언어 모델이 포함되어 있어 기업이 신뢰할 수 있는 고품질 생성 AI 및 다중 모델 A 상태를 구축하는 데 도움이 됩니다. - 최신 검색 응용 프로그램입니다.',stats_v1:"검색이 가속주의와 충돌할 때",subtitle:"AI 기반 솔루션으로 콘텐츠 제작을 혁신하고 무한한 가능성을 열어보세요. AI 생성 콘텐츠의 미래를 형성하고 인간의 창의성을 강화합니다.",sues_und_sauer:"고소하고 사우어",sues_und_sauer_tooltip:"Süß-Sauer는 독일식 중국 음식에서 인기 있는 맛(이 맛은 정통 중국 음식에서는 흔하지 않으며 독일식 중국 음식에 대한 고정관념에 속함)으로 달콤하고 신맛을 의미합니다. 이는 기업가로서의 경력의 기복에 대한 은유입니다.",sunnyvale_address:"710 Lakeway Dr, Ste 200, 서니베일, CA 94085, 미국",sz:"중국 선전",sz_address:"중국 선전 푸안 테크놀로지 빌딩 4층 402호",team:"우리 팀",team_content1:"우리는 전 세계 곳곳에서 AI의 미래를 구축합니다. 우리의 독특한 관점은 우리의 업무를 풍요롭게 하고 혁신을 불러일으킵니다. 이 포털에서 우리는 개성을 포용하고 열정적으로 꿈을 추구합니다. AI의 미래 포털에 오신 것을 환영합니다.",team_join:"우리와 함께",team_size:"이 사진에는 이전 동료와 인턴이 포함되어 있습니다. 한 분 한 분 모두에게 감사드립니다.",technologies:"핵심기술",title:"지나테크놀로지 소개",title0:"미래",title1:"기원",title2:"여기",title3:"다음에서 시작됨",understand_our_strength:"우리의 강점에 대해 알아보세요",understand_our_view2:"검색 기반에 대해 알아보기",users:"등록 된 사용자",value:"우리의 상",value_content1:"우리는 우리의 영예에 안주하지 않을 것입니다. 우리는 타협하지 않을 것입니다. 우리는 우수성을 위해 노력합니다.",vision:"우리의 미션",vision_content1:'AI에 대한 Yann LeCun의 관점에서 영감을 받은 "',vision_content3:'AI의 미래는 <span class="text-primary text-bold">다중 모드</span>이며 우리는 그 일부입니다. 우리는 기업이 다중 모드 데이터를 활용하는 데 직면하는 과제를 인식하고 있습니다. 이를 위해 Google은 <span class="text-primary text-bold">검색 재단</span>을 통해 기업과 개발자가 더 나은 검색을 하고 다중 모드 데이터를 활용하여 비즈니스 성장을 촉진할 수 있도록 노력하고 있습니다.',yannlecun_quote:"단어와 문장만으로 훈련된 AI 시스템은 결코 인간의 이해에 근접할 수 없습니다."},i={answer1:"예. Jina AI의 모든 검색 기반 제품에 동일한 API 키가 작동합니다. 여기에는 모든 서비스 간에 공유되는 토큰과 함께 벡터, 순위 재지정, 판독기 및 미세 조정 API가 포함됩니다.",answer12:"우리는 엄격한 개인 정보 보호 정책을 준수하며 사용자 입력 데이터를 사용하여 모델을 교육하지 않습니다.",answer3:"예, API 키를 입력하여 토큰 구매 탭에서 토큰 사용량을 모니터링하면 사용 내역과 남은 토큰을 볼 수 있습니다.",answer4:"재충전 키를 분실하여 되찾고 싶으신 경우, 등록된 이메일을 통해 지원팀에 문의해 도움을 받으시기 바랍니다.",answer5:"아니요, API 키에는 만료일이 없습니다. 그러나 키가 손상되었다고 의심되어 이를 폐기하거나 토큰을 새 키로 전송하려는 경우 지원 팀에 문의하여 도움을 받으십시오.",answer6:'이는 서버리스 아키텍처가 사용량이 적은 기간 동안 특정 모델을 오프로드하기 때문입니다. 초기 요청은 모델을 활성화하거나 "준비"하는데 몇 초가 걸릴 수 있습니다. 초기 활성화 후 후속 요청이 더 빠르게 처리됩니다.',question1:"벡터, 순위 재지정, 리더 및 미세 조정 API에 동일한 API 키를 사용할 수 있습니까?",question12:"모델을 훈련하는 데 사용자 입력 데이터가 사용됩니까?",question3:"API 키의 토큰 사용량을 볼 수 있나요?",question4:"API 키를 잊어버린 경우 어떻게 해야 합니까?",question5:"API 키가 만료되나요?",question6:"일부 모델의 경우 첫 번째 요청이 느린 이유는 무엇입니까?",title:"API 관련 FAQ"},a={base_model:"기본 모델 미세 조정",check_data:"합성 데이터 다운로드",check_model:"미세 조정된 모델 다운로드",data_size:"합성 데이터 생성",description:"원하는 모든 도메인에 대해 미세 조정된 벡터 모델을 얻으세요.",description_long:"귀하의 벡터 모델이 어떤 영역에서 탁월하길 원하는지 알려주시면 해당 영역에 대해 바로 사용할 수 있고 미세 조정된 벡터 모델 모델을 자동으로 제공해드립니다.",does_it_work_tho:"하지만 정말 효과가 있나요?",does_it_work_tho_explain:"Auto-Spin에는 원하는 모든 도메인에 대해 미세 조정된 벡터를 제공하는 마법의 자동 효과가 있습니다. 하지만 정말 효과가 있나요? 이것은 상당히 합리적인 질문입니다. 이를 알아보기 위해 다양한 분야와 기본 모델에서 테스트했습니다. 아래에서 주요 및 주요 결과를 확인하세요.",domain_instruction:"도메인 지시어",embedding_provider:"기본 벡터 모델 선택",eval_evaluation:"확인하다",eval_map:"지도",eval_mrr:"월 평균 수입",eval_ndcg:"신경교세포암종",eval_performance_before_after:"미세 조정 전후의 합성 검증 세트 성능",eval_syntheticDataSize:"모두",eval_test:"실제 데이터 테스트",eval_training:"기차",faq_v1:{answer1:"이 기능은 현재 베타 버전이며 미세 조정된 모델당 100만 개의 토큰이 필요합니다. Embedding/Reranker API에 충분한 토큰이 있는 경우 기존 API 키를 사용하거나 100만 개의 무료 토큰으로 새 API 키를 생성할 수 있습니다.",answer10:"지금은 아무것도 없다. 이 기능은 아직 베타 버전입니다. Hugging Face Model Center에 미세 조정된 모델과 합성 데이터를 공개적으로 저장하면 우리와 커뮤니티가 교육 품질을 평가하는 데 도움이 됩니다. 앞으로는 개인 저장소 옵션을 제공할 계획입니다.",answer11:"미세 조정된 모든 모델은 이미 Hugging Face에 업로드되어 있으므로 SentenceTransformers를 통해 액세스하려면 모델 이름만 지정하면 됩니다.",answer12:"스팸 폴더를 확인해 보세요. 그래도 찾을 수 없으면 제공한 이메일 주소를 사용하여 지원팀에 문의하세요.",answer2:"학습 데이터를 제공할 필요가 없습니다. 대상 도메인(미세 조정된 벡터 모델을 최적화하려는 도메인)을 자연어로 설명하거나 URL을 참조로 사용하기만 하면 당사 시스템이 모델 학습을 위한 합성 데이터를 생성합니다.",answer3:"약 30분.",answer4:"미세 조정된 모델과 합성 데이터는 Hugging Face Model Center에 공개적으로 저장됩니다.",answer5:"시스템은 Reader API를 사용하여 URL에서 콘텐츠를 가져옵니다. 그런 다음 내용을 분석하여 어조와 영역을 요약하고 종합 데이터를 생성하기 위한 지침으로 사용했습니다. 따라서 URL은 공개적으로 액세스할 수 있어야 하며 대상 도메인을 나타내야 합니다.",answer6:'예, 영어가 아닌 언어에 맞게 모델을 미세 조정할 수 있습니다. 시스템은 도메인 명령의 언어를 자동으로 감지하고 그에 따라 합성 데이터를 생성합니다. 또한 대상 언어에 적합한 기본 모델을 선택하는 것이 좋습니다. 예를 들어 독일 도메인을 대상으로 하는 경우 "jina-embeddings-v2-base-de"를 기본 모델로 선택해야 합니다.',answer7:"아니요. 미세 조정 API는 Jina v2 모델만 지원합니다.",answer8:"미세 조정 프로세스가 끝나면 유지 테스트 세트를 사용하여 모델이 평가되고 성능 지표가 보고됩니다. 이 테스트 세트의 성능 전후에 대해 자세히 설명하는 이메일을 받게 됩니다. 또한 품질을 보장하기 위해 자체 테스트 세트에서 모델을 평가하는 것이 좋습니다.",answer9:"시스템은 귀하가 제공한 대상 도메인 지침과 LLM 에이전트의 추론을 결합하여 합성 데이터를 생성합니다. 이는 고품질 벡터 모델 모델을 훈련하는 데 중요한 까다로운 트리플을 생성합니다. 자세한 내용은 Arxiv에 대한 향후 연구 논문을 참조하세요.",question1:"API를 미세 조정하는 데 비용이 얼마나 드나요?",question10:"미세 조정된 모델과 합성 데이터를 비공개로 유지할 수 있나요?",question11:"미세 조정된 모델을 사용하는 방법은 무엇입니까?",question12:"평가 결과가 포함된 이메일을 받은 적이 없습니다. 나는 무엇을 해야 합니까?",question2:"무엇을 입력해야 합니까? 훈련 데이터를 제공해야 합니까?",question3:"모델을 미세 조정하는 데 시간이 얼마나 걸리나요?",question4:"미세 조정된 모델은 어디에 저장되나요?",question5:"참조 URL을 제공하면 시스템에서 이를 어떻게 사용합니까?",question6:"특정 언어에 맞게 모델을 미세 조정할 수 있나요?",question7:"bge-M3와 같은 Jina가 아닌 벡터 모델을 미세 조정할 수 있나요?",question8:"미세 조정된 모델의 품질을 보장하는 방법은 무엇입니까?",question9:"합성 데이터를 생성하는 방법은 무엇입니까?",title:"자체 튜닝에 관해 자주 묻는 질문(FAQ)"},find_on_hf:"미세 조정된 모델 나열",temporarily_unavailable:"일시적으로 사용할 수 없습니다. 보다 나은 서비스 제공을 위해 자동 미세 조정 시스템을 업그레이드하고 있습니다. 나중에 다시 확인해 주세요.",test_on:"{_dataName}의 {_dataSize} 무작위 샘플에서 테스트되었습니다.",test_performance_before_after:"미세 조정 전후의 유지 테스트 세트의 성능",title:"자체 튜닝 API",total_improve:"평균 개선",usage:"용법",what_is:"셀프 튜닝이란 무엇입니까?",what_is_answer_long:"미세 조정을 사용하면 사전 훈련된 모델을 가져와 새 데이터 세트에 대한 훈련을 통해 특정 작업이나 도메인에 적응할 수 있습니다. 실제로 많은 사용자에게 효과적인 훈련 데이터를 찾는 것은 쉬운 일이 아닙니다. 효과적인 교육을 위해서는 원본 PDF, HTML을 모델에 넣는 것 이상이 필요하며 이를 올바르게 수행하는 것도 어렵습니다. 자체 조정은 고급 LLM 에이전트 파이프라인을 사용하여 유효한 훈련 데이터를 자동으로 생성하고 ML 워크플로 내에서 모델을 미세 조정함으로써 이 문제를 해결합니다. 이를 합성 데이터 생성과 AutoML의 조합으로 생각할 수 있으므로 대상 도메인을 자연어로 설명하고 나머지는 시스템에서 처리하도록 맡기기만 하면 됩니다."},r={description:"기사에서 직접 일러스트레이션을 생성하고 프롬프트 단어가 필요하지 않습니다.",example_description:'앨리스는 할 일 없이 해변에 있는 여동생 옆에 앉아 있는 것에 싫증이 나기 시작했습니다. 그녀는 여동생이 읽고 있는 책을 한두 번 슬쩍 보았지만 그 안에는 그림이나 대화가 전혀 없었습니다. "책이 무슨 소용이 있겠는가?"라고 생각했습니다. 앨리스, "그림도 없고 대사도 없어요. ?" 그래서 그녀는 데이지 체인을 만드는 기쁨이 그만한 가치가 있는지 마음 속으로 궁금해했습니다(더운 날씨 때문에 졸리고 멍청한 기분이 들었습니다). 일어나서 데이지를 따느라 애쓰던 중, 갑자기 분홍빛 눈을 가진 흰 토끼가 달려왔습니다.',example_title:"이상한 나라의 앨리스 - 1장"},_="평가판",o={answer10:'우리는 자동 생성된 API 키를 통해 모든 모델에서 사용할 수 있는 100만 개의 토큰이 포함된 무료 평가판을 신규 사용자에게 제공합니다. 무료 토큰 한도에 도달하면 사용자는 "토큰 구매" 탭을 통해 API 키에 대한 추가 토큰을 쉽게 구매할 수 있습니다.',answer13:"아니요, 실패한 요청에 대해서는 토큰이 차감되지 않습니다.",answer14:"결제는 Stripe을 통해 처리되며 귀하의 편의를 위해 신용 카드, Google Pay, PayPal을 포함한 다양한 결제 방법을 지원합니다.",answer15:"예, 토큰을 구매한 후 Stripe 계정과 연결된 이메일 주소로 청구서가 전송됩니다.",answer9:"우리의 가격 모델은 처리된 총 토큰 수를 기반으로 하므로 사용자는 이러한 토큰을 원하는 수의 문장에 유연하게 할당할 수 있으며 다양한 텍스트 분석 요구에 맞는 비용 효율적인 솔루션을 제공합니다.",question10:"신규 사용자가 무료 평가판을 받을 수 있나요?",question13:"실패한 요청에 대해 토큰이 차감되나요?",question14:"어떤 결제 방법이 허용되나요?",question15:"Ci Yuan 구매 후 송장을 발행할 수 있나요?",question9:"API 요금은 문장 수나 요청 수에 따라 청구되나요?",title:"청구 관련 자주 묻는 질문"},s={all:"모두",events:"활동",featured:"선택",insights:"보다","knowledge-base":"지식 기반",latest:"최신",press:"보도 자료",releases:"소프트웨어 업데이트","tech-blog":"기술 기사"},c={api_free_trial:"무료 API 키",api_paid:"유료 API 키",api_paid_or_free:"유료 API 키를 사용하시나요, 아니면 무료 평가판 키를 사용하시나요?",are_you:"누구세요:",commercial_contact_sales:"이는 상업적 성격을 띤다. 당사 영업팀에 문의해 주세요.",contact_sales_for_licensing:"라이선스에 대해서는 영업팀에 문의하세요.",csp_user:"AWS 및 Azure에서 공식 모델을 사용하고 계십니까?",educational_teaching:"교육 기관에서 이를 교육에 사용하고 있나요?",for_profit_internal_use:"영리회사에서도 내부적으로 사용하나요?",free_use:"이 모델을 자유롭게 사용할 수 있습니다.",government_public_services:"공공 서비스를 제공하기 위해 정부 기관에서 사용합니까?",is_use_commercial:"상업적인 사용인가요?",may_be_commercial_contact:"이는 상업적인 용도일 수 있습니다. 자세한 내용은 당사에 문의하시기 바랍니다.",no:"아니요",no1:"아니요",no2:"아니요",no3:"아니요",no_restrictions:"제한이 없습니다. 현재 계약에 따라 사용하시기 바랍니다.",no_restrictions_apply:"제한은 없습니다.",non_commercial_free_use:"본 모델은 비상업적 모델이므로 자유롭게 사용하실 수 있습니다.",non_profit_ngo_mission:"비영리 단체나 NGO가 귀하의 임무를 수행하기 위해 이를 사용하고 있습니까?",not_sure:"확실하지 않다",personal_hobby_projects:"개인 프로젝트나 취미 프로젝트에 사용하시나요?",product_service_sale:"판매하는 제품이나 서비스에 사용하시겠습니까?",title:"CC BY-NC 라이센스 자가 점검",trial_key_restrictions:"무료 평가판 키는 비상업적인 용도로만 사용할 수 있습니다. 상업적인 용도로 사용하려면 유료 패키지를 구매하세요.",typically_non_commercial_check:"이는 일반적으로 비상업적이지만 확실하지 않은 경우 당사에 문의하십시오.",typically_non_commercial_free_use:"이는 일반적으로 비상업적입니다. 이 모델을 자유롭게 사용할 수 있습니다.",using_api_or_cloud:"Azure 또는 AWS에서 공식 API나 공식 미러를 사용하고 계십니까?",using_cc_by_nc_models:"이 모델을 사용하고 있나요?",yes:"예",yes1:"예",yes2:"예",yes3:"예"},d={access:"공개 액세스",access_explain:"공개 분류자는 <code>classifier_id</code>가 있는 누구나 사용할 수 있으며 이를 사용하면 귀하의 토큰 할당량이 아닌 호출자의 토큰 할당량이 소비됩니다. 비공개 분류자는 귀하만 접근할 수 있습니다.",access_private:"사적인",access_public:"사람들",api_delete:"분류자 삭제",api_delete_explain:"분류자 ID를 기준으로 분류자를 삭제합니다.",api_list:"목록 분류자",api_list_explain:"생성한 모든 분류자를 나열합니다.",classifier_id:"분류자 ID",classify_inputs:"분류할 입력",classify_inputs_explain:"텍스트의 경우 최대 8192개의 토큰으로 구성된 문장이 될 수 있습니다. 이미지의 경우 URL 또는 base64로 인코딩된 이미지일 수 있습니다.",classify_labels:"후보 주석",classify_labels_explain:"입력은 다음 범주로 분류됩니다. 최대 256개의 범주가 있을 수 있습니다. 더 나은 성능을 위해 의미 범주를 사용하십시오.",compare_table:{access_control:"접근 제어",classifier_id_required:"필수 분류자 ID",continuous_updates:"지속적인 모델 업데이트",default_solution:"일반 분류 문제에 대한 기본 솔루션",feature:"특징",few_shot:"작은 샘플",image_multi_lingual_support:"다중 모드 및 다중 언어 지원",labels_required_classify:"/classify에 필요한 주석",labels_required_train:"/train에 필요한 주석",max_classes:"최대 수업 수",max_classifiers:"최대 분류기",max_inputs_request:"요청당 최대 입력",max_token_length:"입력당 최대 토큰 길이",na:"해당 없음",no:"아니요",out_of_domain_solution:"v3/clip-v1 도메인 외부 데이터 또는 시간에 민감한 데이터의 경우",primary_use_case:"주요 사용 사례",semantic_labels_required:"의미 주석이 필요합니다.",state_management:"현황관리",stateful:"상태 저장",stateless:"무국적",token_count:"{count} 태그",training_data_required:"훈련 데이터가 필요합니다",yes:"예",zero_shot:"제로 샘플"},create_classifier:"새로운 퓨샷 분류기",create_classifier_explain:"새로운 퓨샷 분류기를 만들고 레이블이 지정된 예를 사용하여 훈련시킵니다.",description:"이미지와 텍스트의 제로샷 및 퓨샷 분류.",description_long:"API 샌드박스를 사용해 분류자가 어떻게 작동하는지 알아보세요.",description_long1:"다중 모드 및 다국어 데이터를 위한 고성능 제로샷 및 퓨샷 분류기입니다.",explain:"Classifier는 임베딩 모델(<code>jina-embeddings-v3</code> 및 <code>jina-clip-v1</code>)을 사용하여 데이터 학습 없이 텍스트와 이미지를 분류하는 API 서비스입니다. 최소한의 예시를 활용한 분류 및 퓨샷 학습.",faq_v1:{answer1:"제로 샷 분류에는 의미 체계 라벨이 필요하지만 훈련 중에는 필요하지 않으며, 소수 샷 분류에는 훈련 중에 레이블이 필요하지만 분류 중에는 필요하지 않습니다. 이는 제로샷 분류가 유연하고 즉각적인 분류 요구에 더 적합한 반면, 퓨샷 분류는 시간이 지남에 따라 발전할 수 있는 고정된 도메인별 범주에 더 적합하다는 것을 의미합니다.",answer10:"예, 텍스트 분류(특히 다중 언어에 적합)에는 <code>jina-embeddings-v3</code>를 선택하고 다중 모드 분류에는 <code>jina-clip-v1</code>을 선택할 수 있습니다. 새 모델(예: <code>jina-clip-v2</code>)은 출시되면 API를 통해 자동으로 사용할 수 있습니다.",answer2:"<code>num_iters</code>는 훈련 강도를 제어합니다. 값이 높을수록 중요한 예가 강조되고 값이 낮을수록 신뢰성이 떨어지는 데이터의 영향이 최소화됩니다. 최근 예제에 더 많은 반복 횟수를 제공하여 시간 인식 학습을 달성하는 데 사용할 수 있으므로 데이터 패턴을 발전시키는 데 유용합니다.",answer3:"<code>classifier_id</code>가 있는 사람은 누구나 공개 분류자를 사용하고 자신의 토큰 할당량을 사용할 수 있습니다. 사용자는 교육 데이터 또는 구성에 액세스할 수 없으며 다른 사람의 분류 요청을 볼 수 없으므로 안전한 분류자 공유가 가능합니다.",answer4:"소수의 샘플이 제로샷 분류를 능가하려면 200-400개의 훈련 샘플이 필요합니다. 결국 더 높은 정확도를 달성하게 되지만 효과적이려면 이 준비 기간이 필요합니다. 제로샷은 훈련 데이터 없이도 일관된 성능을 제공합니다.",answer5:"예 - API는 동일한 지원에서 <code>jina-embeddings-v3</code>를 사용한 다중 언어 쿼리와 <code>jina-clip-v1</code>을 사용한 다중 모드(텍스트/이미지) 분류를 지원합니다. 요청의 URL 또는 base64 인코딩 이미지.",answer6:"제로샷은 분류자 제한 없이 256개 카테고리를 지원하는 반면, 퓨샷은 16개 카테고리와 16개 분류자로 제한됩니다. 둘 다 요청당 1,024개의 입력과 입력당 8,192개의 토큰을 지원합니다.",answer7:"소수 샘플 패턴을 사용하면 <code>/train</code> 엔드포인트를 통해 지속적인 업데이트를 통해 변화하는 데이터 패턴에 적응할 수 있습니다. 데이터 분포가 변경되면 전체 분류기를 다시 구축하지 않고도 새로운 예시나 카테고리를 점진적으로 추가할 수 있습니다.",answer8:"API는 일회성 온라인 학습을 사용합니다. 훈련 예제는 분류기 가중치를 업데이트하지만 나중에 저장되지는 ​​않습니다. 즉, 과거 훈련 데이터를 검색할 수는 없지만 개인정보 보호와 리소스 효율성은 보장됩니다.",answer9:"의미 체계 레이블을 사용하여 유연한 분류가 필요한 경우 즉각적인 결과를 얻으려면 0개의 샘플로 시작하세요. 200~400개의 예시가 있거나 더 높은 정확도가 필요하거나 도메인별/시간에 민감한 데이터를 처리해야 하는 경우 몇 가지 샘플로 전환하세요.",question1:"제로 샘플 레이블과 작은 샘플 레이블의 차이점은 무엇입니까?",question10:"언어/작업별로 다른 모델을 사용할 수 있나요?",question2:"num_iters는 무엇을 위해 사용되며 어떻게 사용합니까?",question3:"공개 분류자 공유는 어떻게 작동하나요?",question4:"소규모 표본 연구가 제대로 작동하려면 얼마나 많은 데이터가 필요합니까?",question5:"여러 언어와 텍스트/이미지를 처리할 수 있나요?",question6:"내가 알아야 할 엄격한 제한은 무엇입니까?",question7:"시간이 지남에 따라 데이터 변경 사항을 어떻게 처리합니까?",question8:"훈련 데이터를 보낸 후에는 어떻게 되나요?",question9:"제로 샘플과 작은 샘플 - 언제 어느 것을 사용해야 합니까?",title:"분류자에 대해 자주 묻는 질문(FAQ)"},more:"더",num_iters:"훈련 반복",num_iters_explain:"훈련 강도를 제어합니다. 값이 높을수록 현재 예의 정확도가 향상되지만 토큰 비용이 증가합니다. 일반적으로 기본값인 10이 잘 작동합니다.",read_notes:"릴리스 노트 읽기",select_classifier_or_model:"분류자 또는 임베딩 모델 선택",task_classify:"분류",task_classify_explain:"제로샷 또는 퓨샷 분류기를 사용하여 텍스트나 이미지를 정의된 카테고리로 분류합니다.",task_manage:"관리하다",task_manage_explain:"퓨샷 분류기를 나열하거나 제거하세요.",task_select:"작업 선택",task_train:"기차",task_train_explain:"레이블이 지정된 예를 사용하여 소수의 분류자를 생성하거나 업데이트합니다.",title:"분류자 API",train_inputs:"훈련 데이터",train_inputs_explain:"학습을 위해 라벨이 지정된 텍스트 또는 이미지 예시입니다. 시간이 지남에 따라 새로운 예시와 라벨을 사용하여 분류기를 점진적으로 업데이트할 수 있습니다.",train_label:"상표",what_is:"분류기란 무엇입니까?",when_to_use_what:"0개 또는 작은 샘플을 언제 사용해야 합니까?",when_to_use_what_explain:"제로샷 분류를 기본 솔루션으로 사용하면 최대 256개 범주의 일반 분류 작업에서 즉각적인 결과를 얻을 수 있는 반면, 퓨샷 학습은 내장된 모델 지식 외부에 있거나 시간 집약적인 도메인별 데이터를 처리하는 데 더 적합합니다. 모델 업데이트가 필요합니다. 민감한 데이터."},l={description:"CLIP을 사용하여 벡터 이미지와 텍스트를 고정 길이 벡터로 변환"},p={description:"다중 모드 AI 애플리케이션을 위한 클라우드 호스팅 플랫폼"},u={agreement:"제출함으로써 귀하는 Jina AI가 다음 조항에 따라 귀하의 개인 데이터를 처리하는 데 동의함을 확인합니다.",anything_else:"귀하의 아이디어에 대해 더 자세히 알려주십시오.",cc_by_nc:"상업용 CC BY-NC 모델 요청",cc_by_nc_description:"당사의 최신 모델은 CC BY-NC에 따라 라이선스가 부여되는 경우가 많습니다. 상업적 용도로 사용하려면 API, Azure Marketplace 또는 AWS SageMaker를 통해 액세스하세요. 이러한 채널 외부에서 로컬로 사용하려면 이 상자를 선택하십시오.",company:"정리하다",company_size:"조직 규모",company_website:"조직 웹사이트",company_website_placeholder:"회사 홈페이지 또는 LinkedIn 프로필의 URL",country:"국가",department:"부서",description:"Jina AI와 함께 비즈니스를 성장시키세요.",drop_area_for_image:"여기에 이미지를 드래그 앤 드롭하세요.",faq:"자주하는 질문",feedback_sent:"제출된! 최대한 빨리 연락드리겠습니다.",field_required:"필드는 필수입니다",get_api_key:"API 키를 어떻게 얻나요?",image_upload:"사진 첨부",image_validate:"최대 {_num}개의 이미지를 첨부할 수 있습니다. JPG, JPEG, PNG, WEBP만 가능합니다.",impact_snapshots:"실제 사례",invalid_date_format:"날짜 형식이 잘못되었습니다. DD-MM-YYYY 형식을 사용하세요.",invalid_email:"잘못된 이메일",invalid_number:"잘못된 번호. 다시 입력해주세요",invalid_url:"잘못된 URL",name:"이름",nc_check:"상업용 라이센스가 필요합니까?",other_questions:"기타 질문",preferred_models:"어떤 모델에 관심이 있으신가요?",preferred_products:"어떤 제품에 관심이 있으신가요?",pricing:"가격?",priority:"유료 사용자에 대한 지원 우선순위 지정",private_statement:"개인 정보 보호 정책",rate_limit:"속도 제한은 무엇입니까?",role:"전문적인 역할",self_check:"자가 테스트",sending_feedback:"배상...",shortcut:"지름길",submit:"제출하다",submit_failed:"제출에 실패했습니다. 나중에 다시 시도 해주십시오.",submit_success:"당신의 의견에 대해 감사합니다. 최대한 빨리 연락드리겠습니다.",subtitle:"진아AI는 모델 튜닝, 모델 서비스, 프롬프트 단어 튜닝 및 배포를 전문으로 하는 멀티모달 AI 분야의 선두주자입니다. Kubernetes 및 서버리스 아키텍처와 같은 클라우드 기반 기술을 활용하여 강력하고 확장 가능하며 프로덕션에 즉시 사용할 수 있는 솔루션을 제공합니다. 대규모 언어 모델, 텍스트, 이미지, 비디오, 오디오 이해, 신경 검색 및 생성 예술에 대한 전문 지식을 바탕으로 당사는 귀하의 비즈니스를 향상시킬 수 있는 혁신적이고 미래 지향적인 전략을 제공합니다.",subtitle1:"Jina AI는 멀티모달 AI 분야의 선두주자로서 대형 모델 벡터 튜닝 및 배포, 프롬프트 단어 튜닝 및 배포를 전문으로 합니다. Kubernetes 및 서버리스 아키텍처와 같은 클라우드 기반 기술을 활용하여 강력하고 확장 가능하며 프로덕션에 즉시 사용할 수 있는 솔루션을 제공합니다. 대규모 언어 모델, 텍스트, 이미지, 비디오, 오디오 이해, 신경 검색 및 생성 AI에 대한 전문 지식을 바탕으로 당사는 귀하의 비즈니스를 향상시킬 수 있는 혁신적이고 미래 지향적인 전략을 제공합니다.",subtitle2:"최첨단 멀티모달 AI, 지나 AI에 대해 알아보세요. 우리는 벡터화 및 프롬프트 단어 기술을 전문으로 하며 Kubernetes와 같은 클라우드 기반 솔루션을 활용하여 강력하고 확장 가능한 시스템을 구축합니다. 우리는 대규모 언어 모델 및 미디어 처리를 전문으로 하며 고급 인공 지능 전문 지식을 활용하여 혁신적이고 미래 지향적인 비즈니스 전략을 제공합니다.",title:"영업팀에 문의",trusted_by:"우리는 믿을 만하다",turn_on_volume:"볼륨을 높여보세요",work_email:"직장 이메일"},m="복사",g="클립보드에 복사됨",A={description:"텍스트에서 고화질 이미지를 생성하기 위한 인간-컴퓨터 상호 작용 워크플로"},h={description:"한 줄의 코드로 시선을 사로잡는 Disco Diffusion 아트워크 만들기"},I={description:"다중 모드 데이터의 데이터 구조"},b="SOC 2 Type 1 인증 다운로드",f={"11B tokens":"1010억","11B tokens_intuition1":"Wikipedia의 모든 영어 기사를 읽는 것과 유사합니다.","11B tokens_targetUser":"프로덕션 배포","1B tokens":"일억","1B tokens_intuition1":"아마도 셰익스피어 전집과 '해리포터' 시리즈 전체를 읽는 것과 같을 것이다.","1B tokens_targetUser":"프로토타입 개발","1M tokens":"백만","1M tokens_intuition1":"이는 <호빗>과 <위대한 개츠비>의 전체 텍스트를 읽는 것과 같습니다.","1M tokens_targetUser":"장난감 실험","1M_free":"원하는 대로 사용할 수 있는 수백만 단어의 무료","1M_free_description":"신용카드 없이 무료 토큰으로 새로운 API 키를 즐겨보세요.","2_5B tokens":"2.5B 단어 요소","2_5B tokens_intuition1":'이는 "반지의 제왕" 3부작에 나오는 모든 단어를 1,000번 복사하는 것과 같습니다.',"3p_integration":"<b>{_numPartners}</b>개의 타사 서비스 보유","3p_integration_desc":"당사의 검색 인프라를 기존 서비스와 통합하세요. 우리 파트너는 귀하의 애플리케이션에서 우리 모델을 쉽게 사용할 수 있도록 API에 대한 커넥터를 구축했습니다.","500M tokens":"5억 토큰","500M tokens_intuition1":"시즌 1부터 시즌 30까지 심슨 가족의 모든 에피소드를 시청하는 것과 유사합니다.","59B tokens":"59B 워드 요소","59B tokens_intuition1":"이는 이틀 동안 전 세계에 게시된 모든 트윗에 해당합니다.","5_5B tokens":"5.5B 단어 요소","5_5B tokens_intuition1":"브리태니커 백과사전 전체를 읽는 것과 같습니다.",Free1M:"100만 토큰",add_pair:"새로운",add_time_explain:"이 모델이 검색 기반에 추가된 시간입니다.",api_integration_short:"널리 사용되는 데이터베이스, 벡터 데이터베이스, RAG 및 LLMOps 프레임워크에서 벡터 모델 API를 쉽게 사용할 수 있습니다.",api_integrations:"API 통합",api_key_update_message:"이전 API 키를 교체하면 jina.ai를 방문할 때마다 UI에 새 키가 나타납니다. 향후 충전은 이 새 키에 적용됩니다. 이전 키는 여전히 유효하므로 다시 사용할 계획이라면 안전하게 보관하세요.",api_key_update_title:"API 키 변경",auto_recharge:"단어 요소가 낮을 때 자동으로 재충전됩니다.",auto_recharge_confirm_message:"자동 충전을 비활성화하시겠습니까? 이렇게 하면 토큰 잔액이 부족한 경우 자동 충전이 방지됩니다.",auto_recharge_confirm_title:"자동 충전 비활성화",auto_recharge_description:"프로덕션 환경에서 사용해야 하는 경우 이 옵션을 활성화하십시오. 이러한 방식으로 귀하의 토큰 잔액이 귀하가 설정한 임계값 미만으로 떨어지면 마지막 재충전과 동일한 금액이 신용카드에 자동으로 재충전됩니다. 마지막 재충전에서 여러 토큰 패키지를 구매한 경우, 이 API에는 하나의 패키지만 재충전됩니다.",auto_recharge_enable:"자동 충전을 활성화했습니다.",auto_recharge_enable_message:"자동충전을 활성화하려면 요금제 구매 시 자동충전 스위치를 켜주세요.",auto_recharge_enable_title:"자동 충전 활성화",auto_request:"자동 미리보기",auto_request_tooltip:"API 키에 있는 수백 개의 토큰을 사용하여 모델을 변경할 때 API 응답을 자동으로 미리 봅니다. 종료되면 응답 받기를 클릭하여 요청을 수동으로 보냅니다.",autostart:"벡터화가 자동으로 시작됩니다",base64_description:"벡터는 base64로 인코딩된 문자열로 반환됩니다. 전송 효율이 더 높습니다.",batch_job:"일괄 처리",batch_upload_hint:"일괄 처리를 위해 아래 API 키와 모델을 사용하겠습니다.","bge-base-en-v1_5_description":"성능과 효율성의 균형을 맞추고 다양한 용도에 적합한 강력한 영어 모델입니다.","bge-base-en_description":"안정적인 성능을 위해 설계된 균형 잡힌 영어 모델입니다.","bge-base-zh-v1_5_description":"성능과 효율성을 종합적으로 균형잡은 중국형 모델입니다.","bge-base-zh_description":"효율성과 강력한 성능을 결합한 다재다능한 중국 모델입니다.","bge-large-en-v1_5_description":"탁월한 품질의 상위 벡터를 제공하는 강력한 영어 모델입니다.","bge-large-en_description":"고품질 벡터용으로 제작된 최고 수준의 영어 모델입니다.","bge-large-zh-v1_5_description":"우수하고 상세한 벡터를 갖춘 대용량 중국 모델을 제공합니다.","bge-large-zh_description":"상위 벡터에 최적화된 고성능 중국 모델입니다.","bge-m3_description":"광범위한 기능과 고품질 벡터를 제공하는 다용도 다국어 모델입니다.","bge-small-en-v1_5_description":"효율적인 고품질 벡터를 제공하는 간소화된 영어 모델입니다.","bge-small-en_description":"단순화되고 정확한 벡터를 위한 효율적인 영어 모델입니다.","bge-small-zh-v1_5_description":"유연하고 정확한 벡터링을 제공하는 소형 중국 모델입니다.","bge-small-zh_description":"효율적이고 정확한 벡터화를 위한 민첩한 중국 모델입니다.",binary_description:"벡터는 int8로 패킹됩니다. 저장, 검색, 전송이 더욱 효율적입니다.",bulk:"일괄 처리",bulk_embedding_failed:"배치를 생성하지 못했습니다.",buy_more_quota:"더 많은 토큰으로 이 API 키를 충전하세요",buy_poster:"포스터 구매",cancel_button:"취소",click_upload_btn_above:"시작하려면 위의 업로드 버튼을 클릭하세요.",clip_v2_description:"jina-clip-v2는 89개 언어에 대한 다국어 지원, 512x512의 높은 이미지 해상도, 잘린 임베딩을 위한 Matryoshka 표현 학습이라는 세 가지 주요 발전을 제공하는 0.9B CLIP 스타일 모델입니다.",clip_v2_title:"Clip-v2: 다중 언어 다중 모드 임베딩",code:"암호",colbert_dimensions_explain:"각 마커 임베딩의 차원 크기입니다.",compatible:"호환 모드",compatible_explain:"텍스트 벡터 모델과 동일한 요청 형식을 따릅니다. 이를 통해 요청을 변경하지 않고도 모델 간에 전환할 수 있습니다. 이 모드에서는 이미지 입력이 지원되지 않습니다.",cosine_similarity:"코사인 유사성",debugging:"시험",delete_pair:"삭제",description:"@:landing_page.embedding_desc1",dimensions:"출력 크기",dimensions_error:"크기는 1에서 1024 사이여야 합니다.",dimensions_explain:"크기가 작을수록 Matryoshka 표현으로 인한 영향을 최소화하면서 효율적인 저장 및 검색이 가능합니다.",dimensions_warning:"성능을 향상하려면 측정기준 크기를 {_minDimension} 이상으로 유지하는 것이 좋습니다.",document:"문서",download:"다운로드",edit_text1_text:"왼쪽 텍스트 편집",edit_text2_text:"오른쪽의 텍스트를 편집하세요.",embedding_done:"{_Count}개의 문장을 성공적으로 벡터화했습니다.",embedding_none_description:"벡터 모델을 사용하지 마세요",example_inputs:"입력 예",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"교육 프로세스, 데이터 소스 및 평가에 대한 자세한 내용은 arXiv에서 제공되는 기술 보고서를 참조하세요.",answer1:"각 사용자는 초당 최대 100개의 요청을 할 수 있으며 이는 초당 204,800개의 입력 문장에 해당합니다.",answer17:"우리는 현재 텍스트, 이미지, 오디오를 공동으로 처리할 다중 모드 벡터 모델을 개발 중입니다. 업데이트는 곧 발표될 예정입니다!",answer18:"특정 데이터로 모델을 미세 조정하는 방법에 대한 질문이 있는 경우 당사에 문의하여 요구 사항을 논의하세요. 우리는 귀하의 요구 사항에 맞게 모델을 어떻게 조정할 수 있는지 알아보고 싶습니다.",answer19:"예, 우리 서비스는 AWS Marketplace에서 사용할 수 있으며 Azure 및 GCP Marketplace로 확장하고 있습니다. 특별한 요구 사항이 있는 경우 jina.ai 영업팀에 문의하세요.",answer3:"우리 모델은 영어, 독일어, 스페인어, 중국어 및 다양한 프로그래밍 언어를 지원합니다. 자세한 내용은 이중 언어 모델에 대한 논문을 참조하세요.",answer4:'우리 모델은 최대 8192개의 토큰까지 입력 길이를 허용하며 이는 대부분의 다른 모델보다 훨씬 높습니다. 토큰의 범위는 단일 문자(예: "a")부터 전체 단어(예: "apple")까지 가능합니다. 입력할 수 있는 총 문자 수는 사용된 단어의 길이와 복잡성에 따라 다릅니다. 이러한 확장된 입력 기능을 통해 jina-embeddings-v2 모델은 보다 포괄적인 텍스트 분석을 수행하고 특히 대용량 텍스트 데이터의 경우 컨텍스트 이해에서 더 높은 정확도를 달성할 수 있습니다.',answer5:"API 호출은 최대 2048개의 문장 또는 텍스트를 처리할 수 있으므로 단일 요청으로 광범위한 텍스트 분석을 용이하게 합니다.",answer6:"API 요청의 <code>입력</code> 필드에 <code>url</code> 또는 <code>bytes</code>를 사용할 수 있습니다. <code>url</code>에 처리할 이미지의 URL을 제공하세요. <code>바이트</code>의 경우 이미지를 base64 형식으로 인코딩하고 요청에 포함합니다. 모델은 응답에 이미지 임베딩을 반환합니다.",answer7:"MTEB 순위에 따르면 우리 모델은 OpenAI의 text-embedding-ada-002와 긴밀하게 경쟁하며 비슷한 평균 성능을 보여줍니다. 또한 우리 모델은 분류, 쌍별 분류, 재배열 및 요약을 포함한 여러 작업에서 OpenAI 모델보다 성능이 뛰어납니다.",answer8:"API 인터페이스 https://api.jina.ai/v1/embeddings가 OpenAI text-embeddings-ada-002 모델의 입력 및 출력 JSON 스키마와 일치하기 때문에 변환이 단순화됩니다. 이러한 호환성을 통해 사용자는 OpenAI 인터페이스를 사용할 때 OpenAI 모델을 우리 모델로 쉽게 교체할 수 있습니다.",answer9:`토큰은 텍스트 길이와 이미지 크기를 기준으로 계산됩니다. 요청 텍스트의 경우 토큰은 표준 방식으로 계산됩니다. 요청의 이미지에 대해 다음 단계를 수행하세요.
1. 타일 크기: 각 이미지는 224x224 픽셀 크기의 타일로 나뉩니다.
2. 적용 범위: 입력 이미지를 완전히 덮는 데 필요한 타일 수를 계산합니다. 이미지 크기가 224로 정확히 나누어지지 않더라도 부분 타일을 전체 타일로 계산합니다.
3. 총 타일 수: 이미지를 덮는 총 타일 수에 따라 비용이 결정됩니다. 예를 들어 이미지가 500x500픽셀인 경우 3x3 타일로 덮여 결과적으로 9개의 타일이 됩니다.
4. 비용 계산: 각 타일은 이미지 처리의 최종 비용에 영향을 미칩니다. 각 타일의 가격은 1000토큰입니다.

예:
500x500픽셀 크기의 이미지의 경우:

• 이미지는 224x224 픽셀의 타일로 나누어집니다.
• 필요한 총 타일 수는 3(가로) x 3(세로) = 9개의 타일입니다.
• 비용은 9*1000 = 9000 토큰입니다.`,question0:"jina-embeddings-v2 모델은 어떻게 훈련되나요?",question1:"초당 몇 개의 API 요청을 할 수 있나요?",question17:"벡터 모델 이미지 또는 오디오 모델을 제공합니까?",question18:"개인 또는 회사 데이터를 사용하여 Jina 벡터 모델 모델을 미세 조정할 수 있습니까?",question19:"인터페이스를 AWS, Azure 또는 GCP에서 비공개로 호스팅할 수 있나요?",question3:"귀하의 모델은 어떤 언어를 지원합니까?",question4:"단일 문장 입력의 최대 길이는 얼마입니까?",question5:"단일 요청에 몇 개의 문장을 포함할 수 있나요?",question6:"jina-clip-v1 모델에 이미지를 보내는 방법은 무엇입니까?",question7:"Jina Embeddings 모델은 OpenAI의 text-embedding-ada-002 모델과 어떻게 비교됩니까?",question8:"OpenAI의 text-embedding-ada-002에서 귀하의 솔루션으로의 마이그레이션이 얼마나 원활하게 이루어졌습니까?",question9:"jina-clip-v1을 사용할 때 토큰을 어떻게 계산하나요?",title:"벡터 모델에 대해 자주 묻는 질문(FAQ)"},feature_8k1:"8192 길이",feature_8k_description1:"8192 단어 길이의 세계 최초 오픈 소스 벡터 모델은 인민일보 전체 페이지를 벡터로 압축할 수 있습니다.",feature_cheap:"비용을 50배 절감",feature_cheap_v1:"5배의 비용 절감",feature_cheap_v1_description1:"무료 평가판, 간단한 가격 구조, 빠른 결제로 시작해 보세요. OpenAI 비용의 20%에 불과한 비용으로 강력한 벡터 모델을 얻으세요.",feature_multilingual:"이는 해외 기업의 교차 언어 적용에 필수적인 독일어-영어, 중국어-영어 및 기타 이중 언어 모델을 제공합니다.",feature_on_premises:"개인 정보 보호 우선",feature_on_premises_description1:"Virtual Private Cloud(VPC)에 벡터 모델을 직접 원활하게 배포하세요. AWS Sagemaker에 쉽게 배포할 수 있으며 곧 Microsoft Azure 및 Google Cloud Platform과 통합될 예정입니다. Kubernetes 배포를 맞춤 설정하려면 영업팀에 문의하여 전문적인 지원을 받으세요.",feature_on_premises_description2:"AWS Sagemaker에 벡터 모델을 쉽게 배포할 수 있으며 곧 Microsoft Azure 및 Google Cloud Services에서 지원을 제공할 예정입니다. Kubernetes 배포를 맞춤 설정하려면 영업팀에 문의하여 전문적인 지원을 받으세요.",feature_on_premises_description3:"AWS Sagemaker 및 Microsoft Azure와 곧 Google Cloud Services에 Jina Embeddings 모델을 배포하거나 영업팀에 문의하여 가상 프라이빗 클라우드 및 온프레미스 서버에 대한 맞춤형 Kubernetes 배포를 받으세요.",feature_on_premises_description4:"AWS SageMaker, Microsoft Azure 또는 Google Cloud Services를 사용하여 Jina Embedding 및 Reranker 모델을 로컬로 배포하여 데이터를 안전하게 제어할 수 있습니다.",feature_solid:"뛰어난",feature_solid_description1:"탄탄한 AI 과학 연구 성과를 바탕으로 모델의 최고의 성능을 보장하기 위해 유사한 모델과 엄격한 비교 테스트를 수행했습니다.",feature_top_perform1:"원활한 통합",feature_top_perform_description1:"OpenAI의 API와 완벽하게 호환됩니다. 원활한 개발자 경험을 위해 10개 이상의 벡터 데이터베이스 및 RAG 시스템과 쉽게 통합됩니다.",file_required:"파일을 업로드해주세요",file_size_exceed:"파일 크기가 {_size} 한도를 초과했습니다.",file_type_not_supported:"지원되지 않는 파일 형식",fill_example:"예시를 작성하세요",float_description:"벡터는 부동 소수점 숫자 목록으로 반환됩니다. 가장 일반적이고 사용하기 쉽습니다.",free:"무료",generate_api_key_error:"API 키 생성에 실패했습니다.",generating_visualization:"시각화 생성...",get_new_key_button:"새 키 받기",get_new_key_button_explain:"새 키를 선택하면 이전 키와 관련된 사용 기록이 손실됩니다.",get_new_key_survey:"귀하의 사용량을 이해하는 데 도움이 되도록 설문조사를 작성하고 무료로 새로운 API 키를 받으세요!",includes:"구매한 단어 요소는 다음 제품에서 사용할 수 있습니다.",index_and_search:"인덱싱 및 검색",index_and_search1:"인덱싱 및 검색",input:"묻다",input_api_key_error1:"API 키가 잘못되었습니다!",input_length:"길이를 입력하세요",input_type:"문서/쿼리로 포함",input_type_explain:"검색 역할에 따라 동일한 입력이 쿼리 또는 문서에 포함될 수 있습니다.",integrate:"통합","jina-clip-v1_description":"이미지 및 영어 텍스트에 대한 다중 모드 벡터 모델","jina-clip-v2_description":"텍스트 및 이미지에 대한 다국어 다중 모드 벡터 모델","jina-colbert-v1-en_description":"개선된 ColBERT 모델은 8K 길이 컨텍스트를 지원하며 벡터화 및 재배열 작업에 사용할 수 있습니다.","jina-colbert-v2_description":"벡터화 및 재정렬에서 최고의 성능을 갖춘 최신 다국어 ColBERT","jina-embeddings-v2-base-code_description":"코드 및 기술 문서 검색을 위한 벡터 모델","jina-embeddings-v2-base-de_description":"독일어 및 영어 이중 언어를 지원하는 8K 최고의 벡터 모델","jina-embeddings-v2-base-en_description":"OpenAI의 text-embedding-ada002와 비교 가능","jina-embeddings-v2-base-es_description":"스페인어-영어 이중 언어를 지원하는 8K 최고의 벡터 모델","jina-embeddings-v2-base-zh_description":"중국어 및 영어 이중 언어를 지원하는 8K 최고의 벡터 모델","jina-embeddings-v2-small-en_description":"낮은 대기 시간과 작은 메모리에 최적화됨","jina-embeddings-v3_description":"텍스트와 코드 모두에서 최적의 성능을 제공하는 최고의 최신 벡터화 모델","jina-reranker-v1-base-en_description":"첫 번째 reranker는 검색 및 RAG 관련성을 극대화합니다.","jina-reranker-v1-tiny-en_description":"대량의 문서를 안정적으로 정렬할 수 있는 가장 빠른 재정렬기","jina-reranker-v1-turbo-en_description":"속도와 정확성 사이의 최선의 균형","jina-reranker-v2-base-multilingual_description":"동급 최고의 정확성과 속도 성능을 갖춘 최첨단 다국어 문서 및 쿼리 리포머",key:"API 키",key_enter_placeholder:"API 키를 입력하세요",key_enter_placeholder_to_topup:"충전하려는 API 키를 입력하세요.",key_to_top_up:"충전할 다른 API 키가 있나요? 위 내용을 붙여넣고 '저장'을 클릭하세요.",key_warn:"API Key를 안전한 곳에 보관하시기 바랍니다. 그렇지 않으면 새 키를 생성해야 합니다.",key_warn_v2:"이것이 당신의 고유한 열쇠입니다. 안전하게 보관해주세요!",language_explain:"이 모델은 {_language} 언어를 가장 잘 지원합니다.",last_7_days:"용법",late_chunking:"포스트 청킹",late_chunking_explain:"사후 차단 기술은 모델의 긴 컨텍스트 기능을 활용하여 컨텍스트 블록 벡터화를 생성하는 데 적용됩니다.",learn_more:"더 알아보기",learn_poster:"포스터를 알아보세요",learning1:"벡터 모델 학습",learning1_description:"벡터란 무엇이며 벡터화해야 하는 이유는 무엇입니까? 시작하는 데 도움이 되는 몇 가지 기사가 있습니다. 당사의 종합 가이드를 통해 벡터 모델에 대해 처음부터 자세히 알아보세요.",length:"길이",manage_billing:"송장 관리",manage_billing_tip:"청구 정보를 관리하고 청구서를 받고 자동 충전을 설정하세요.",manage_quota1:"열쇠와 청구",max_file_size:"최대 허용 크기: {_maxSize}.",maximize_tooltip:"이 패널을 최대화하려면 Shift+1을 사용하세요.",mistake_contact:"이것이 버그라고 생각되면 저희에게 연락해주세요.",mminput_placeholder:"텍스트, 이미지 URL, 이미지 base64 문자열",model_required:"모델을 선택하세요.",more_models:"{_numMore}개의 다른 모델",more_than_two2:"문서를 2개 이상, 즉 2줄 이상 입력해주세요.",multi_embedding:"다중 캐리어",multi_embedding_explain:"모델은 입력에 대한 벡터 세트를 반환합니다. 입력 문장의 각 토큰은 별도의 벡터에 매핑됩니다.",multilingual:"다국어 지원",multimodal:"복합운송",multimodal_explain:"이 모델은 텍스트 및 이미지 입력을 인코딩할 수 있으므로 다중 모드 검색 작업에 이상적입니다.",new:"신형",no_data1:"유사성을 계산하려면 한 쌍의 문장을 추가하세요.",none:"전혀",normalized:"L2 정규화",normalized_explain:"방향을 유지하면서 유클리드(L2) 표준이 1이 되도록 임베딩의 크기를 조정합니다. 다운스트림에 내적, 분류, 시각화가 포함될 때 유용합니다.",oncsp:"CSP 소개",onprem:"비공개 배포",open_tensorboard:"시각화 도구 열기",opensource:"오픈 소스",opensource_explain:"모델은 오픈 소스이며 Hugging Face에서 다운로드할 수 있습니다. Hugging Face의 모델을 보려면 이 버튼을 클릭하세요.",original_documents:"벡터화된 문장",original_documents_hint:"여기에 문장을 입력하세요. 각각의 새 줄은 별도의 문장/문서로 처리됩니다.",output:"응답",output_dim:"출력 크기",output_dim_explain:"이 모델의 벡터 출력에는 {_outputDim} 차원이 있습니다.",output_dimension:"출력 크기",pairwise_test:"페어링 테스트",per_k:"천 단어당",per_m:"백만당 단어",please_fill_docs_first:"검색하기 전에 아래 문장을 입력해 주세요.",please_select_model:"임베딩 모델 또는 Reranker 모델을 선택하세요.",poster:"벡터 모델 70년",poster_description:"세심하게 제작된 포스터 중 하나를 사무실 공간이나 거실에 걸어두고 1950년 이후 텍스트 벡터 모델의 진화와 진화에서 다음 영감을 찾아보세요.",pricing:"API 가격표",pricing_desc:"API 가격은 요청 시 전송된 토큰 수를 기준으로 책정됩니다. Reader API의 경우 이는 응답의 토큰 수입니다. 이 가격 모델은 Jina AI 검색 기반의 모든 제품(Vector, Rerank, Reader, Auto-Nudge API)에 적용됩니다. 동일한 API 키를 사용하여 모든 API 서비스에 액세스할 수 있습니다.",protectData1:"귀하가 당사에 보내는 데이터나 문서는 모델 교육에 사용되지 않습니다.",protectData2:"데이터는 전송 중(TLS 1.2+) 및 저장 중(AES-GCM 256) 암호화됩니다.",protectData3:"SOC 2 및 GDPR 준수.",protect_data:"데이터를 보호하세요",public_cloud_integration:"<b>{_numPartners}</b> 클라우드 서비스 제공업체와 협력",public_cloud_integration_desc:"귀하의 회사는 AWS 또는 Azure를 사용하고 있습니까? 그런 다음 회사 내의 이러한 플랫폼에 직접 검색 인프라 모델을 배포하여 데이터를 안전하게 유지하고 규정을 준수하세요.",query:"쿼리 문장",raise_issue:"문제 피드백",rank_none_description:"재배치 모델을 사용하지 마십시오",read_api_docs:"API 사양",read_release_note:"릴리스 노트 읽기",recharge_threshold:"재충전 임계값",refresh:"새로 고치다",refresh_key_tooltip1:"무료로 새 API 키 받기",refresh_token_count1:"현재 API 키에 사용 가능한 토큰을 가져오려면 새로고침하세요.",regenerate:"새 키 생성",remaining:"남은 토큰 금액",remaining_left:"아래 API 키에 <b>{_leftTokens}</b>개의 토큰이 남아 있습니다.",request_number:"요청 수",request_path:"요청 엔드포인트",results_as_final_result:"#docs를 최종 결과로",results_fed_to_reranker:"#docs 피드를 재순위 지정자에게 제공",retry:"다시 해 보다",return_base64:"Base64(문자열)",return_binary:"바이너리(int8로 팩킹됨)",return_float:"기본값(부동 소수점)",return_format:"벡터 형식",return_format_explain:"부동 소수점 외에도 더 빠른 벡터 검색을 위해 바이너리로 반환되도록 요청하거나 더 빠른 전송을 위해 base64로 인코딩하도록 요청할 수 있습니다.",return_format_title:"반환 데이터 유형",return_ubinary:"바이너리(uint8로 팩킹됨)",right_api_key_to_charge:"재충전하려면 올바른 API 키를 입력하세요.",running:"달리기",score:"분수",search:"찾다",search_hint:"다음 문장에 검색하고 싶은 내용을 입력하세요",select_classify_model:"분류기 선택",select_embedding_model:"삽입 선택",select_rerank_model:"재주문자 선택",show_api_key:"API 키 표시",size:"매개변수",size_explain:"모델의 매개변수 개수는 {_size}입니다. 이는 모델의 파일 ​​크기를 나타내지 않습니다.",sleeping:"자고 있는",start_batch:"일괄 처리 시작",start_embedding:"인덱싱 시작",status_explain:"우리의 서버리스 아키텍처는 사용량에 따라 현재 사용되지 않는 메모리에서 일부 모델을 즉시 오프로드할 수 있습니다. 활성 모델의 경우 반응이 즉각적입니다. 휴면 모델은 첫 번째 요청을 받을 때까지 로드되지 않으며 이 프로세스는 수십 초 동안 지속될 수 있습니다. 모델이 활성화된 후 후속 요청이 더 빠르게 처리됩니다.",task_type:"다운스트림 작업",task_type_classification:"분류",task_type_classification_explain:"텍스트 분류.",task_type_explain:"벡터 모델을 사용할 다운스트림 작업을 선택합니다. 모델은 작업에 최적화된 벡터를 반환합니다.",task_type_none_explain:"어댑터는 사용되지 않습니다. 디버깅이나 해킹에 사용할 수 있는 일반 포함을 반환합니다.",task_type_retrieval_passage:"채널 검색",task_type_retrieval_passage_explain:"쿼리 문서 검색 작업에서 문서를 벡터화합니다.",task_type_retrieval_query:"검색어",task_type_retrieval_query_explain:"쿼리 문서 검색 작업에서 쿼리를 벡터화합니다.",task_type_separation:"분리",task_type_separation_explain:"클러스터링 문서, 시각화 말뭉치.","task_type_text-matching":"텍스트 일치","task_type_text-matching_explain":"의미론적 텍스트 유사성, 일반화된 대칭 검색, 추천, 유사한 항목 찾기 및 중복 제거.",tax_may_apply:"위치에 따라 미국 달러, 유로 또는 기타 통화로 요금이 청구될 수 있습니다. 세금이 적용될 수 있습니다.",text1:"왼쪽",text2:"오른쪽",three_ways:"구매하는 세 가지 방법",three_ways_desc:"API를 구독하거나, 클라우드 공급자를 통해 구매하거나, 조직을 위한 상용 라이선스를 얻으세요.",title:"벡터 모델 API",token_example:"Weibo 게시물에는 약 20개의 토큰이 있고 인민일보 뉴스 기사에는 약 1,000개의 토큰이 있으며 Charles Dickens의 소설 A Tale of Two Cities에는 백만 개가 넘는 토큰이 있습니다.",token_length_explain:"이 모델에서 지원하는 입력 토큰의 최대 길이는 {_tokenLength}입니다.",tokens:"단어 요소",tools:"도구",top_up_button:"기존 키 충전",top_up_button_explain:"이 API 키를 통합하면 키를 자주 변경할 필요 없이 더욱 전문적인 솔루션이 제공됩니다. 사용 데이터는 보관되며 언제든지 액세스할 수 있습니다.",top_up_warning_message1:"현재 API 키에는 {_remainedTokens} 토큰이 남아 있으며 {_freeTokens} 토큰이 있는 새 키로 대체됩니다. 기존 키를 안전한 곳에 보관하셨다면 계속해서 기존 키를 사용하거나 충전하실 수 있습니다. 어떻게 진행하시겠습니까?",top_up_warning_title:"기존 키를 교체하시겠습니까?",total_documents:"벡터화 진행률: {_Processed}/{_Count} 문장.",tuning:"미세 조정",turnstile_error:"귀하가 사람인지 확인할 수 없기 때문에 API 키를 생성할 수 없습니다.",turnstile_unsupported:"귀하의 브라우저가 지원되지 않기 때문에 API 키를 생성할 수 없습니다.",ubinary_description:"벡터는 uint8로 압축됩니다. 저장, 검색, 전송이 더욱 효율적입니다.",upload:"업로드",upload_file:"파일을 업로드하려면 여기를 클릭하세요.",usage:"용법",usage_amount:"단어 요소",usage_history:"지난 7일 동안의 사용량",usage_history_explain:"데이터는 실시간이 아니며 몇 분 정도 지연될 수 있습니다.",usage_reason:"설명하다",usage_reason_consume:"사용된",usage_reason_purchase:"구입했다",usage_reason_trial:"사용",usage_rerank:"용법",usage_time:"시간 날짜",v3_description:"<code>jina-embeddings-v3</code>는 MTEB의 OpenAI 및 Cohere의 최신 독점 벡터 모델보다 성능이 뛰어난 570M 매개변수와 8192개의 토큰 길이를 갖춘 최첨단 다국어 텍스트 벡터 모델입니다. 아래 블로그 게시물과 연구 논문을 읽어보세요.",v3_title:"v3: 최상위 다국어 벡터 모델",vector_database_integration1:"통합",vector_database_integration2:"널리 사용되는 데이터베이스, 벡터 데이터베이스, RAG 및 LLMOps 프레임워크에서 벡터 모델 API를 쉽게 사용할 수 있습니다. 시작하려면 API 키를 아래 통합에 복사하기만 하면 모델을 빠르게 사용할 수 있습니다.",vector_database_integration3:"당사의 Embedding & Reranker API는 잘 알려진 다양한 데이터베이스, 벡터 저장소, RAG 및 LLMOps 프레임워크와 기본적으로 통합됩니다. 먼저, 빠르고 원활하게 시작하려면 나열된 통합 중 하나에 API 키를 복사하여 붙여넣기만 하면 됩니다.",vector_database_integration_description:"Jina Embeddings API를 다음 벡터 데이터베이스, LLM 오케스트레이션 프레임워크 및 RAG 애플리케이션과 원활하고 쉽게 통합합니다. 우리의 튜토리얼이 그 방법을 보여줄 것입니다.",view_details:"세부 사항을 확인하세요",visualization_example:"이 섹션의 모든 문장을 3D 벡터 공간에 매핑",visualization_example_you_can:"아래 API를 사용하면 여러분도 그렇게 할 수 있습니다!",visualize:"심상",visualize_done:"시각화가 완료되었으며 이제 상단 버튼을 클릭하여 시각화 도우미를 열 수 있습니다.",wait_for_processing:"귀하의 요청을 처리 중입니다.",wait_stripe:"Stripe 결제를 여는 중입니다. 잠시 기다려 주세요.",what_are_embedding:"벡터화란 무엇입니까?",what_are_embedding_answer:`컴퓨터에게 단어와 구문의 미묘한 의미를 가르친다고 상상해 보세요. 전통적인 접근 방식은 언어가 너무 복잡하고 유동적이기 때문에 원하는 결과를 얻지 못하는 엄격한 규칙 기반 시스템에 의존합니다. 입력 텍스트 임베딩: 텍스트를 숫자 언어, 특히 고차원 공간의 벡터로 변환하기 위한 강력한 솔루션입니다.

"맑은 날씨"와 "맑은 하늘"이라는 문구를 생각해 보세요. 우리에게 그들은 비슷한 그림을 그립니다. 임베딩 관점을 통해 이러한 문구는 다차원 공간에서 서로 가까운 수치 벡터로 변환되어 의미적 유사성을 포착합니다. 벡터 공간에서의 이러한 근접성은 단순한 단어나 구문의 유사성 이상이며, 맥락, 감정, 심지어 의미의 뉘앙스까지 이해하는 것과 관련이 있습니다.

이 돌파구가 왜 중요한가요? 첫째, 인간 언어의 풍부함과 알고리즘의 계산 효율성 사이의 격차를 해소합니다. 알고리즘은 텍스트를 해석하는 것이 아니라 숫자를 처리하는 데 능숙합니다. 임베딩을 통해 텍스트를 벡터로 변환함으로써 이러한 알고리즘은 이전에는 불가능했던 방식으로 언어를 "이해"하고 처리할 수 있습니다.

실제 적용 범위는 넓고 다양합니다. 귀하의 관심사에 맞는 콘텐츠를 추천하든, 인간미가 짙은 대화형 AI를 강화하든, 대량의 텍스트에서 미묘한 패턴을 탐지하든, 임베딩이 핵심입니다. 이를 통해 기계는 감정 분석, 언어 번역, 점점 더 미묘하고 정교한 언어 이해와 같은 작업을 수행할 수 있습니다.`,what_is_a_token:'텍스트 처리에서 토큰은 단위, 일반적으로 단어입니다. 예를 들어, "Jina AI is awesome!"은 구두점을 포함하여 5개의 토큰이 됩니다.',why_do_you_need:"가장 적합한 벡터 모델 선택",why_do_you_need_after:"딥 러닝과 고급 언어 처리 기술을 통해 당사의 벡터 모델은 복잡한 다중 모드 데이터를 단순화된 형식으로 변환할 수 있습니다. 이는 기계 이해를 향상시킬 뿐만 아니라 다음을 포함하여 보다 복잡한 AI 애플리케이션을 구현할 수 있는 가능성을 제공합니다. 데이터 구문 분석 기능 개선, 사용자 상호 작용 증가, 언어 장벽 제거 및 개발 프로세스 개선.",why_do_you_need_before:"우리의 임베딩 모델은 다양한 검색 및 GenAI 애플리케이션을 포괄하도록 설계되었습니다.",why_need_1_description:"우리는 JinaBERT가 만든 벡터 기반 모델을 사용하여 다양한 시나리오에 맞게 설계합니다. 긴 텍스트를 구문 분석하는 데 탁월하며 의미 검색, 콘텐츠 분류, 심층 언어 분석 등의 작업에 적합합니다. 이러한 다용성으로 인해 감정 분석 도구, 텍스트 요약 및 개인화된 추천 시스템을 개발하는 데 이상적입니다.",why_need_1_title:"보편적인 벡터",why_need_2_description:"당사의 이중 언어 모델은 언어 장벽을 허물고 커뮤니케이션 효율성, 글로벌 고객 지원 및 다국어 플랫폼 전반에 걸쳐 언어 간 콘텐츠 검색을 향상하도록 설계되었습니다. 독일어-영어, 중국어-영어의 양방향 번역에 중점을 두고, 다양한 언어를 사용하는 사용자가 보다 쉽게 ​​이해하고 소통할 수 있습니다.",why_need_2_title:"이중 언어 벡터",why_need_3_description:"개발자가 코드 요약, 코드 생성, 자동화된 코드 검토 등의 작업을 단순화할 수 있도록 특별히 설계된 코드 벡터 모델입니다. 코드 구조를 심층적으로 분석하고 개선 제안을 제공함으로써 개발 효율성이 크게 향상됩니다. 이는 고급 IDE 플러그인, 자동 생성 문서 및 혁신적인 디버깅 도구 개발의 핵심입니다.",why_need_3_title:"코드 벡터",why_need_4_description:"Jina CLIP은 이미지와 텍스트를 위한 최신 멀티모달 임베딩 모델입니다. OpenAI CLIP에 비해 크게 개선된 점은 이 단일 모델을 텍스트-텍스트 검색은 물론 텍스트-이미지, 이미지-텍스트, 이미지-이미지 검색 작업에 사용할 수 있다는 것입니다! 따라서 하나의 모델, 두 가지 모드, 네 가지 검색 방향!",why_need_4_title:"다중 모드 임베딩",write_email_here:"완료 후 다운로드 링크를 받고 싶은 이메일을 입력하세요.",you_can_leave:"이 페이지를 떠나시면 완료되면 다운로드 링크를 보내드리겠습니다."},w={description:"세계적 수준의 다중 모드 다중 언어 임베딩."},k={answer1:"Jina AI는 대형 모델 벡터의 튜닝 및 배포, 프롬프트 단어의 튜닝 및 배포를 포함한 다중 모드 AI 기술에 중점을 둡니다. 우리는 Kubernetes 및 서버리스 아키텍처와 같은 고급 도구를 활용하여 강력하고 확장 가능하며 프로덕션에 즉시 사용할 수 있는 솔루션을 만듭니다.",answer10:"우리는 프로젝트의 성격과 고객의 요구에 따라 다양한 라이센스 옵션을 제공합니다. 자세한 조건은 영업팀과 논의할 수 있습니다.",answer11:"우리는 유럽 베를린에 본사를 두고 베이징과 선전에 지사를 두고 전 세계적으로 서비스를 제공하고 있습니다.",answer12:"예, 특히 베를린, 베이징, 선전 사무실 근처에 있는 고객을 위해 현장 지원을 제공합니다. 다른 지역의 경우 가능한 최고의 원격 지원을 제공하고 필요할 경우 현장 지원을 마련하기 위해 노력하고 있습니다.",answer2:"우리의 전문 지식은 대규모 언어 모델, 텍스트, 이미지, 비디오, 오디오 이해, 신경 검색 및 생성 AI를 포함한 광범위한 영역에 걸쳐 있습니다.",answer3:"예, 당사의 솔루션은 확장 가능하고 생산 준비가 가능하도록 설계되었습니다. 우리는 프로덕션 환경에서 효율적인 확장과 안정적인 성능을 달성하기 위해 클라우드 네이티브 기술을 사용하여 솔루션을 구축합니다.",answer4:"당사의 서비스는 전자상거래, 법률 기술, 디지털 마케팅, 게임, 의료, 금융 등을 포함한 다양한 산업 분야에 다양하고 적용 가능합니다.",answer5:"이 페이지의 문의 양식을 통해 영업팀에 연락하실 수 있습니다. 귀하의 프로젝트 요구 사항과 당사 솔루션이 귀하의 비즈니스에 어떻게 도움이 될 수 있는지 기꺼이 논의해 드리겠습니다.",answer6:"우리는 솔루션이 원활하게 실행될 수 있도록 지속적인 지원을 제공합니다. 여기에는 피드백과 요구 사항에 따른 문제 해결, 정기적인 업데이트 및 개선이 포함됩니다.",answer7:"프로젝트 기간은 프로젝트의 복잡성과 범위에 따라 다릅니다. 귀하의 요구 사항을 이해하면 보다 정확한 견적을 제공할 수 있습니다.",answer8:"데이터 보안은 우리의 최우선 과제입니다. 우리는 귀하의 데이터가 안전하고 기밀인지 확인하기 위해 엄격한 데이터 보호 정책 및 규정을 준수합니다.",answer9:"가격은 프로젝트 복잡성과 요구 사항에 따라 다릅니다. 우리는 프로젝트 기반 가격 모델과 유지 가격 모델을 제공합니다. 자세한 내용은 영업팀에 문의하세요.",question1:"지나AI는 무엇을 잘하나요?",question10:"귀하의 솔루션에 대한 라이센스 조건은 무엇입니까?",question11:"귀하의 서비스 지역은 무엇입니까?",question12:"현장 지원을 제공합니까?",question2:"지나AI는 어떤 종류의 인공지능에 적합한가요?",question3:"귀하의 솔루션은 확장 가능하고 생산 준비가 되어 있습니까?",question4:"Jina AI의 솔루션으로 어떤 산업이 혜택을 받을 수 있나요?",question5:"Jina AI를 사용하여 프로젝트를 어떻게 시작하나요?",question6:"솔루션 구현 후 어떤 지원을 제공하나요?",question7:"일반적인 프로젝트 기간은 얼마나 됩니까?",question8:"Jina AI는 내 데이터를 어떻게 보호하나요?",question9:"귀하의 서비스 가격 구조는 어떻게 됩니까?"},P="FAQ",y={text:"작별 인사를 하세요.",toggle_btn:"다음에 방문할 때 이 패널을 열어두세요",warning_message:"jina.ai를 방문하면 이 패널이 자동으로 열립니다. 웹사이트 콘텐츠를 보려면 해당 페이지를 닫아야 합니다. 이 설정을 사용하시겠습니까?",warning_title:"시작 시 표시됨"},v={description:"더 나은 검색 품질을 위해 도메인별 데이터에 대한 대규모 모델 벡터 조정",intro:"귀하의 회사, 귀하의 데이터, 귀하의 모델"},L={description:"귀하의 비즈니스를 위한 로컬 튜닝 솔루션"},x={api_key:"API 키를 입력하세요.",back:"뒤쪽에",base_model_selected:"기본 모델 선택",click_start:"약관에 동의하고 미세 조정을 시작합니다.",confirm_title:"미세 조정 작업 확인",confirm_your_email:"조정이 작동하는지 확인하려면 이메일 주소를 다시 입력하세요. 업데이트 및 다운로드 링크가 이 이메일로 전송됩니다.",consent0:"본인의 지시에 따라 모델 미세 조정을 위한 합성 데이터를 생성하는 데 동의합니다.",consent1:"나는 최종 모델과 합성 데이터가 Hugging Face에서 공개적으로 제공될 것임을 인정합니다.",consent2:"나는 이 기능이 베타 버전이며 Jina AI가 어떠한 보장도 하지 않는다는 것을 이해합니다. 가격과 사용자 경험은 변경될 수 있습니다.",continue:"계속하다",cost_1m_token:"각 미세 조정 작업에는 100만 개의 토큰이 사용됩니다. 토큰이 충분한지 확인하거나 재충전하세요. 새 API 키를 생성할 수도 있습니다. 각 API 키에는 100만 개의 무료 토큰이 제공됩니다.",doc_explain:"일치하는 문서가 어떤 모습이어야 하는지 설명합니다.",domain_explain:"미세 조정된 벡터 모델을 사용하는 방법에 대한 자세한 설명입니다. 이는 벡터 모델의 성능을 향상시키는 고품질 합성 데이터를 생성하는 데 중요합니다.",domain_explain2:"요구 사항을 지정하는 방법에는 일반 설명, URL 또는 쿼리 문서 설명의 세 가지가 있습니다. 하나를 선택해 주세요.",domain_hint:"미세 조정하려는 도메인을 설명하세요.",email_not_match:"이메일 주소가 일치하지 않습니다. 확인 부탁합니다.",failed_job:"미세 조정 요청이 실패했습니다. 아래에서 이유를 확인하세요.",find_on_huggingface:"포옹 얼굴에 대한 결과 찾기",general_instruction:"또는 일반 지침",general_instruction_caption:"트림 벡터를 사용하는 방법에 대한 자세한 설명을 제공합니다.",general_instruction_explain:'자유 형식의 텍스트로 도메인 이름을 설명하세요. ChatGPT의 "프롬프트"처럼 생각하면 됩니다.',how_it_works:"미세 조정 프로세스를 이해합니다.",job_acknowledged:"미세 조정 작업이 대기 중입니다. 과제가 시작되면 이메일을 받게 됩니다. 전체 프로세스를 완료하는 데 일반적으로 20분이 소요됩니다.",new_key:"새 키 받기",not_enough_token:"이 API 키에 토큰이 충분하지 않습니다. 충전하거나 다른 API 키를 사용하세요.",placeholder:"자동차 보험 청구",preview:"시사",query_doc:"쿼리 문서 설명",query_doc_caption:"쿼리의 모양과 도메인에서 일치하는 문서의 모양을 설명하세요.",query_explain:"쿼리의 모양을 설명합니다.",reset:"다시",select_base_model:"미세 조정을 위한 기본 벡터 모델을 선택합니다.",select_base_model_explain:"미세 조정을 위한 출발점으로 기본 모델을 선택합니다. 일반적으로 base-en이 좋은 선택이지만, 다른 언어로 작업하는 경우 이중 언어 모델 사용을 고려해보세요.",start_tuning:"미세 조정 시작",url:"또는 웹페이지 URL",url_caption:"미세 조정은 URL의 내용을 참조하세요.",url_explain:"미세 조정하려는 콘텐츠가 포함된 페이지의 공개 URL입니다.",use_url:"대신 URL을 사용하세요. 이 옵션을 활성화하면 미세 조정을 위해 이 URL의 페이지 콘텐츠를 기반으로 합성 데이터가 생성됩니다.",wait_for_processing:"귀하의 요청을 처리하는 동안 잠시 기다려 주십시오...",which_domain:"미세 조정 도메인",write_email_explain:"미세 조정에는 시간이 걸립니다. 미세 조정 작업의 시작, 진행, 완료 및 문제는 물론 미세 조정 모델 및 학습 데이터세트의 세부정보를 이메일로 알려드리겠습니다."},q={address_beijing:"중국 베이징",address_berlin:"독일 베를린(본사)",address_shenzhen:"중국 선전",address_sunnyvale:"캘리포니아주 서니베일",all_rights_reserved:"판권 소유",company:"회사",developers:"개발자를 위한",docs:"문서",enterprise:"비즈니스를위한",get_api_key:"Jina AI API 키 받기",offices:"사무실",power_users:"고급 사용자용",privacy:"은둔",privacy_policy:"개인 정보 정책",privacy_settings:"쿠키 관리",security:"안전",sefo:"검색 기반",soc2:"우리는 미국공인회계사협회(AICPA)의 SOC 2 Type 1을 준수합니다.",status:"API 상태",status_short:"서비스 상태",tc:"이용약관",tc1:"자귀"},R="API 키 받기",M={stars:"별"},S={about_us:"회사 소개",company:"회사",contact_us:"영업팀에 문의",developers_others:"더 많은 개발자 도구",enterprise_others:"더 많은 기업용 도구",for_developers:"개발자 역량 강화",for_developers_description:"개발자를 위해 특별히 구축된 다중 모드 오픈 소스 기술 스택입니다.",for_enterprise:"비즈니스 역량 강화",for_enterprise_description:"귀하의 기업에 맞게 맞춤화된 다중 모드 솔루션을 살펴보세요.",for_power_users:"파워 유저의 역량 강화",for_power_users_description:"당사의 다중 모드 도구를 사용하여 일일 생산성을 높이십시오.",internship1:"인턴 프로그램",jobs:"우리와 함께",join_discord:"Discord 커뮤니티에 가입하세요",logos:"로고 다운로드",maximize:"⇧1",maximize_btn:"최대화하다",news:"소식",open_day:"개장일",open_in_full:"새 창에 모든 기업 제품 표시",power_users_others:"더욱 발전된 사용자 도구",products:"제품"},C={description:"멀티모달 AI 애플리케이션의 빌딩 블록을 공유하고 발견하세요."},j={sentence_similarity:"문장 벡터 모델",updated_about:"업데이트됨"},z={project1:"포인트 클라우드 정보를 사용하여 3D 메시 데이터에서 고정밀 검색을 수행합니다.",project10:"컴퓨터 비전을 사용하여 정부 웹사이트의 디지털 접근성을 개선합니다.",project11:"컨설팅 회사의 재무 데이터 분석을 최적화하기 위해 대규모 언어 모델을 조정합니다.",project12:"스타일 전송을 위해 텍스트-이미지 모델을 조정하여 고급 마케팅 전략을 지원합니다.",project2:"단편 애니메이션 영화를 위한 콘텐츠 기반 검색 엔진을 설계했습니다.",project3:"벡터 모델을 조정하여 전자상거래 전환율을 향상시킵니다.",project4:"비즈니스 컨설팅 회사의 효율성을 높이기 위해 적시에 조정합니다.",project5:"선도적인 게임 회사를 위한 선구적인 게임 장면 이해 및 자동 주석입니다.",project6:"사용자 경험을 향상시키기 위해 챗봇 회사를 위한 실시간 입력 확장을 구현했습니다.",project7:"긴 법률 문서 내에서 효율적인 검색을 가능하게 합니다.",project8:"대규모 작업을 지원하는 처리량이 높은 생성 아트 서비스입니다.",project9:"고급 언어 모델을 사용한 프로세스 마이닝 및 모델링."},T={description:"최첨단 다중모달 추론 모델"},J={copy_full_prompt:"전체 프롬프트 단어를 복사하세요.",embedding:"벡터 모델",how_to_use_meta_prompt:"사용방법",meta_prompt:"코드 생성을 위해 메타힌트 사용",meta_prompt_description:"메타 힌트는 모든 API 사용을 대형 모델(예: ChatGPT 및 Claude)에 알려 코드 생성을 더 쉽게 만들고 품질을 향상시킵니다.",reranker:"재배열자",which_to_go:"어느 것이 {_vendor}와 통합되나요?"},G={answer1:"학부, 석사, 박사 연구, 엔지니어링, 마케팅, 영업 등의 분야에 관심이 있는 전 세계 학생들의 지원을 권장합니다. 또한 마케팅, 영업, 행정 보조 등과 같은 분야의 비기술적 인턴십 기회도 환영합니다. 우리와 함께 멀티모달 AI를 개척할 열정적인 인재를 찾고 있습니다.",answer10:"네, 저희 인턴십 프로그램은 경쟁력 있는 급여를 제공합니다.",answer11:"Jina AI 인턴으로서 당신은 도전적인 프로젝트에 대한 실무 경험을 쌓고, 업계 전문가로부터 배우고, 활발한 커뮤니티의 일원이 되며, 멀티모달 AI 분야의 선구적인 작업에 실질적인 기여를 할 수 있는 기회를 갖게 됩니다.",answer2:"인턴십은 베를린, 베이징, 선전에 있는 사무실 중 한 곳에서 현장에서 이루어져야 합니다.",answer3:"네, Jina AI는 비자 절차에서 성공적인 신청자에게 합리적인 지원을 제공합니다.",answer4:"네, 지나AI는 인턴십 기간 동안 합리적인 생활비를 제공합니다.",answer5:"예, 일반적으로 독일 대학의 학생들에게 제공되는 Jina AI의 인턴십 기간 동안 석사 논문을 완성할 수 있습니다. 단, 소속 대학 지도교수로부터 사전 연락과 동의를 얻어야 합니다. 우리는 학생들이 조언자를 찾는 것을 돕지 않는다는 점에 유의하십시오.",answer6:"지원 절차에는 지원서, 이력서, 관심사와 동기를 표현하는 자기 소개서, GitHub 또는 LinkedIn과 같은 관련 전문 링크 제출이 포함됩니다. 우리는 면접에서의 성과와 대학에서의 성과를 바탕으로 후보자를 평가합니다.",answer7:"네, 성공적인 인턴은 인턴십이 끝나면 CEO가 서명한 추천서를 받을 수 있습니다.",answer8:"인턴십 기간은 역할과 프로젝트에 따라 다릅니다. 그러나 보통 3~6개월 정도 소요됩니다.",answer9:"네, 모든 학문적 배경을 가진 지원자를 환영합니다. 우리는 귀하의 이전 경험만큼 학습에 대한 귀하의 열정과 헌신을 소중히 여깁니다.",question1:"지나AI 인턴십 프로그램은 누가 신청할 수 있나요?",question10:"유급 인턴십인가요?",question11:"지나 AI 인턴으로서 어떤 기회를 얻게 되나요?",question2:"인턴십은 어디에서 진행되나요?",question3:"지나 AI가 비자 절차를 도와주나요?",question4:"지나AI는 인턴에게 특혜나 혜택을 제공하나요?",question5:"진아아이 인턴십 중에 석사논문을 쓸 수 있나요?",question6:"신청 절차에는 무엇이 포함됩니까?",question7:"지나AI 인턴십 후 추천서가 있나요?",question8:"인턴십 기간은 얼마나 되나요?",question9:"인공지능 관련 경험이 없어도 지원할 수 있나요?"},U={about_internship_program:"인턴십 프로그램에 대해",about_internship_program_desc1:"우리는 재능 있는 개인들이 우리의 역동적인 팀에 합류하여 인공 지능 분야의 획기적인 프로젝트에 기여할 수 있는 특별한 기회를 제공하게 된 것을 기쁘게 생각합니다. 이 인턴십은 귀중한 실무 경험, 멘토링, 인공 지능의 미래를 형성하는 최첨단 기술에 대한 노출을 제공하기 위해 고안되었습니다.",about_internship_program_desc2:"지나AI는 젊은 인재를 육성하고 활용하는 것의 중요성을 잘 알고 있습니다. 우리는 인턴이 새로운 관점, 열정, 창의성을 가져오고 새로운 아이디어와 접근 방식으로 팀에 영감을 준다는 것을 알고 있습니다. 인턴십 기회를 제공함으로써 AI 업계의 미래 리더의 성장을 육성하는 동시에 지원적이고 도전적인 환경에서 실제 경험을 제공하는 것을 목표로 합니다.",alumni:"동문",alumni_network:"우리의 활발한 동문 네트워크",application:"애플리케이션",application_desc:"Jina AI와 함께 혁신적인 여정을 시작해보세요. 우리의 포괄적인 인턴십 프로그램은 인공 지능의 미래를 형성하기를 열망하는 모든 열정적인 동료를 초대합니다. 실제 경험을 쌓고, 도전적인 프로젝트에 참여하고, AI 업계에서 가장 뛰어난 인재들과 함께 일하려면 우리와 함께 하세요.",apply:"지금 신청하세요",autumn:"가을",description:"전 세계적으로 학생 모집: 연구, 엔지니어링, 마케팅, 영업 등 분야의 인턴십.",dev_rel_intern:"개발자 관계 인턴",enthusiastic:"열렬한",explore_stories_from_our_interns:"인턴들의 이야기를 살펴보세요",explore_stories_from_our_interns1:"인턴들의 여정에서 영감을 얻으세요",innovative:"혁신적인",intern_work1:"더 나은 문장 벡터 모델을 위한 LLM 모델 미세 조정",intern_work2:"검색 증강 생성(RAG) 알고리즘의 잠재력 탐구",intern_work3:"문장 벡터에 관한 논문 출판",intern_work4:"팀에 젊은 에너지를 꾸준히 주입합니다.",intern_work5:"압축된 LLM을 위한 벤치마크 양자화 기술",intern_work6:"PromptPerfect를 위한 매력적인 캠페인을 만들고 홍보하세요.",intern_work7:"JinaColBERT V2의 신속한 개발 및 개선",recruiting_and_administrative_intern:"채용 및 행정 인턴",researcher_intern:"인턴연구원",self_motivated:"자기 동기 부여",software_engineer_intern:"소프트웨어 엔지니어 인턴",spring:"봄",submit_application:"지나 AI와 함께 모험을 시작해보세요",subtitle:"우리의 풀타임 인턴십 프로그램은 세심하게 설계된 다양한 인턴십 프로젝트를 통해 실질적인 업무 경험을 제공합니다.",subtitle1:"전 세계에서 학생을 모집합니다. 연구, 엔지니어링, 마케팅, 영업 및 기타 분야의 인턴을 모집하여 다중 모드 AI를 공동으로 만듭니다.",summer:"여름",title:"인턴 프로그램",who_do_we_look_for:"우리는 누구를 찾고 있나요?",who_do_we_look_for_desc:"우리는 다양성을 중요시하며 모든 배경과 배경의 지원자가 인턴십 프로그램에 참여하도록 권장합니다. 엔지니어링, 디자인, 제품 관리, 영업 및 계정 관리, 마케팅, 커뮤니티 관리 등 여러 부서에서 인턴십 기회를 얻을 수 있습니다.",winter:"겨울"},B={description:"로컬 프로젝트를 클라우드 서비스로 배포합니다. 매우 간단하고 불쾌한 놀라움이 없습니다."},O={description:"LLM용 오픈 소스 실험용 튜너"},D={description:"클라우드에서 다중 모드 AI 애플리케이션 구축"},E={description:"더 많은 모드, 더 긴 메모리, 더 낮은 비용",example_1:"누구세요?",example_2:"저는 지나아이가 만든 LLM 채팅 서비스 입니다"},N={add:"키 추가",add_key_explain:"계정에 다른 API 키를 추가하세요. 추가된 키는 언제든지 관리, 충전, 삭제할 수 있습니다.",auto_recharge_title:"자동 충전을 활성화하시겠습니까?",available_resources:"사용 가능한 토큰",balance:"사용 가능한 토큰",balance_primary_key:"마스터 키 밸런스",cancel:"취소",copy:"복사 키",description:"임베딩, 리더, 리랭커 등 모든 Jina AI 서비스에 대한 API 키를 관리하세요.",do_it_later:"나중에 해라",email:"이메일",existing_key:"기존 키",filter_by:"키로 필터링",free_key:"무료 키",generate_new_key:"새 키 생성",generate_new_key_tooltip:"잔액이 비어 있는 새 API 키를 생성합니다. 나중에 충전할 수 있습니다.",invalid_key:"잘못된 키",is_primary:"당신의 마스터 키. 로그인 후 변경하실 수 있습니다.",last_used:"마지막으로 사용한",last_used_at:"마지막 활동",login:"로그인",login_explain:"여러 API 키를 관리하고 사용량을 추적하세요. 모두 하나의 계정에서 가능합니다.",login_explain_long:"API 키를 안전하게 저장하고 관리하려면 로그인하세요. 사용 내역을 추적하고, 여러 키를 관리하고, 자격 증명에 대한 액세스를 잃지 마세요.",login_via:"{_provider}를 통해 로그인하세요.",logout:"로그아웃",logout_message:"귀하의 API 키는 귀하의 계정에 안전하게 저장됩니다. 언제든지 로그인하여 관리할 수 있습니다.",logout_success:"성공적으로 로그아웃되었습니다",ok:"좋아요",primary_key:"기본 키로 설정",primary_key_set:"{_apiKey}를 마스터 키로 설정했습니다.",primary_key_set_caption:"이 키는 jina.ai의 모든 데모, 예제 및 샌드박스 랩에 사용됩니다.",purchase:"단어 요소 구매",remove:"키 제거",remove_message:"이 키를 삭제하시겠습니까? 키는 여전히 유효하며 나중에 다시 추가할 수 있습니다.",remove_primary_key:"현재 마스터 키를 삭제하기 전에 다른 키를 마스터 키로 설정하세요.",remove_title:"키 제거",revoke:"키 취소",revoke__message:"이 키를 취소하시겠습니까? 일단 취소되면 이 키는 영구적으로 유효하지 않습니다.",subscribed_key:"유료 열쇠",title:"지나 검색베이스 API",to_dashboard:"키 관리",total_keys:"키 수",usage_history:"이용내역",usage_summary:"지난 7일: {_usage} 토큰"},F={GlobalQA:{description:'질문을 열려면 아무 페이지에서나 "/" 키를 누르세요. 페이지 내용과 관련된 답변을 얻으려면 검색어를 입력하고 "Enter"를 누르세요. 이 기능은 PromptPerfect에 의해 제공됩니다.',title:"페이지래그"},Recommender:{description:'뉴스 페이지에서 추천 상자를 열려면 "Shift+2"를 누르세요. 이 뉴스 페이지와 관련된 상위 5개 기사를 검색하려면 순위 재지정 모델을 선택하세요. 이 기능은 Reranker API를 통해 실시간으로 제공됩니다.',title:"관련 기사"},SceneXplainTooltip:{description:"뉴스 페이지나 뉴스룸 디렉토리에 있는 이미지 위로 마우스를 가져가면 해당 이미지에 대한 설명이 표시됩니다. 설명은 SceneXplain에 의해 미리 계산되고 이미지의 ALT 속성에서 양자화됩니다.",title:"이미지 주석"},explain:"웹사이트의 숨겨진 기능을 살펴보세요"},H={also_available_on:"앱마켓에서도 이용 가능",also_available_on1:"애플리케이션 마켓을 통해 한 번의 클릭으로 엔터프라이즈 클라우드에 배포",ask_how_your_question:"문제를 설명해 주세요.",autotune:"자가 조정",badge:{"clip-v2":"Clip-v2 출시!",v2:"두 번째 에디션이 출시되었습니다!",v3:"v3 출시!"},build_js:"JavaScript를 사용하여 개발됨",build_python:"Python을 사용하여 개발",ccbync:"이 모델은 CC BY-NC 4.0에 따라 라이센스가 부여되었습니다. API 또는 공식 AWS/Azure 이미지를 통해 사용하거나 온프레미스 배포에 대해 영업팀에 문의하세요.",checkout_our_solution_for_you:"귀하에게 꼭 맞는 솔루션에 대해 알아보세요",classifier:"분류자",coming_soon:"계속 지켜봐 주시기 바랍니다",contact_sales:"문의하기",copied_to_clipboard:"클립보드에 복사됨",copy:"복사",developers:"개발자",developers_desc:"최첨단 클라우드 네이티브 기술과 오픈 소스 인프라를 통해 다중 모드 AI의 모든 기능을 활용하세요.",download_pdf:"PDF 다운로드",embedding:"포함시키다",embedding_desc1:"검색, RAG, 에이전트 애플리케이션을 위한 최첨단 다중 모드 다국어 긴 컨텍스트 벡터 모델입니다.",embedding_paper_desc:"Jina Embeddings는 다양한 텍스트 입력을 수치 표현으로 변환하여 텍스트의 의미론적 본질을 포착하는 데 탁월한 고성능 텍스트 벡터 모델 세트를 구성합니다. 이러한 모델은 텍스트 생성을 위해 특별히 설계되지는 않았지만 밀집 검색 및 의미론적 텍스트 유사성과 같은 응용 프로그램에서 잘 수행됩니다. 이 문서에서는 고품질 쌍별 및 삼중항 데이터 세트 생성부터 시작하여 Jina Embeddings의 개발에 대해 자세히 설명합니다. 데이터 세트 준비에서 데이터 정리의 중요한 역할을 강조하고, 모델 교육 프로세스에 대한 통찰력을 제공하며, MTEB(대규모 텍스트 벡터 벤치마크)를 사용하여 포괄적인 성능 평가를 수행합니다.",embedding_paper_title:"Jina Embeddings: 새로운 고성능 텍스트 벡터 모델 세트",embeddings:"벡터 모델",enterprise:"기업",enterprise_desc:"확장 가능하고 안전하며 맞춤화된 다중 모드 AI 솔루션으로 비즈니스를 강화하십시오.",enterprise_desc_v2:"세계적 수준의 벡터 모델을 사용하여 검색 및 RAG 시스템을 개선하세요. 무료 평가판으로 시작해보세요!",enterprise_desc_v3:"당사의 최첨단 모델은 고품질 기업 검색 및 RAG 시스템을 위한 검색 기반을 형성합니다.",error:"문제가 발생했습니다. {message}",find_your_portal:"나만의 포털 탐색",finding_faq:"다음 FAQ에 대한 지식을 바탕으로 답변을 생성하세요.",for:"~을 위한",for_developers:"개발자를 위한",for_enterprise:"비즈니스를위한",for_power_users:"고급 사용자용",get_api_now:"API",get_started:"사용을 시작하다",go_to_product_homepage:"제품 홈페이지로 이동",how_to:"어떻게",include_experiment:"솔루션에서 우리의 실험적이고 보관된 프로젝트를 언급하세요.",join_community:"지역 사회",key_manager:"API 키 관리",learn_more_embeddings:"벡터 모델에 대해 알아보기",learn_more_reader:"독자에 대해 자세히 알아보기",learn_more_reranker:"재주문자에 대해 알아보기",llm:"LLM 대형 모델 벡터 모델",llm_desc:"우리는 3,500만 ~ 60억 개의 매개변수를 갖춘 고성능 텍스트 벡터 모델 제품군을 제공합니다. 신경 검색, 재정렬, 문장 유사성, 권장 사항 등을 강화하는 데 유용합니다. AI 경험을 향상시킬 준비를 하세요!",mentioned_products:"언급된 제품:",mmstack:"다중 모드 기술 스택",mmstack_desc:"수년에 걸쳐 우리는 개발자가 더 나은 GenAI 및 검색 애플리케이션을 더 빠르게 구축하는 데 도움이 되는 오픈 소스 소프트웨어를 개발해 왔습니다.",models:"모델",more:"더",multimodal:"다중 모드",multimodal_ai:"멀티모달 AI",new:"새로운",newsroom:"소식",num_publications:"총 {_total} 출판물.","on-prem-deploy":"비공개 배포","on-premises":"현지의",opensource:"오픈 소스",our_customer:"우리 고객",our_customer_explain:"크고 작은 기업은 도구와 제품을 구축하기 위해 Jina AI의 검색 기반 기술을 신뢰하며 귀하도 우리를 신뢰할 수 있습니다.",our_publications:"우리의 논문",parameters:"매개변수",podcast:"팟캐스트",power_users:"요인",power_users_desc:"자동 단어 프롬프트 프로젝트는 일상 업무 효율성을 향상시킵니다.",powered_by_promptperfect:"PromptPerfect의 프롬프트 단어 최적화 및 서비스로서의 프롬프트 기능으로 구동",pricing:"가격표",proposing_solution:"Jina AI 제품군을 기반으로 고안된 솔루션...",read_more:"더 많은 뉴스",reader:"리더",require_full_question:"문제를 더 자세히 설명해 주세요.",reranker:"재배열자",researcher_desc:"당사의 최첨단 검색 모델이 처음부터 어떻게 학습되는지 알아보고 최신 간행물을 확인하세요. EMNLP, SIGIR, ICLR, NeurIPS 및 ICML에서 우리 팀을 만나보세요!",researchers:"연구원",sdk:"소프트웨어 개발 키트",sdk_desc:"PromptPerfect, SceneXplain, BestBanner, JinaChat, Rationale API를 사용하여 고급 AIGC 애플리케이션을 구축하고 싶으십니까? 우리는 당신의 서비스에 있습니다! 사용하기 쉬운 SDK를 사용해 보고 몇 분 안에 시작해 보세요.",sdk_docs:"문서 읽기",sdk_example:"예",search_foundation:"검색 기반",source_code:"소스 코드",starter_kit:"신입생 패키지",supercharged1:"다시는 같지 않습니다!",tokenizer:"얇게 써는 기계",trusted_by:"우리는 믿을 만하다",try_it_for_free:"지금 시작하세요. 신용카드나 등록이 필요하지 않습니다!",try_our_saas:"OpenAI API를 1:1로 대체하는 관리형 클라우드 네이티브 추론 솔루션을 사용해 보세요.",your_portal_to:"당신을 초대합니다",your_search_foundation1:"검색 기반"},K={description:"Jina 및 FastAPI를 사용하여 프로덕션급 Langchain 애플리케이션 만들기"},W={description:"Jina AI 제품 및 서비스에 관한 법률 정보, 서비스 약관, 개인 정보 보호 정책 및 기타 중요한 문서입니다.",title:"법률 정보"},Q={api:"지나 AI API",contact_sales_about_it:"자세한 내용은 영업팀에 문의하세요.",deploy_it_on:"배포됨",description:"수년에 걸쳐 우리는 계속해서 검색의 한계를 확장해 왔습니다. 우리가 출시한 모델은 다음과 같습니다. 각 모델을 마우스로 가리키거나 클릭하면 자세한 내용을 볼 수 있습니다.",find_on_hf:"HuggingFace에서 찾아보세요.",search_for:"우리 사이트 검색",search_models:"모델명으로 필터링",title:"검색 기반 모델",use_it_via:"사용하여"},Y={back_to_newsroom:"뉴스 홈페이지로 돌아가기",categories:"범주",copy_link:"이 섹션에 대한 링크 복사",in_this_article:"기사 탐색",learn_more:"더 알아보기",news_not_found:"이런! 기사를 찾을 수 없습니다.",redirect_to_news:"5초 후에 뉴스 홈 페이지로 리디렉션됩니다..."},X={academic:"학생",academic_research:"학술 논문",author:"작성자별로 필터링",description:"Jina AI의 최신 뉴스와 업데이트를 읽어보세요.",description1:"AI 기술 혁신에 대해 한마디로 적어보세요.",engineering_group:"엔지니어링 팀",engineering_group_date:"2021년 5월 31일",minutes_read:"독서 시간",most_recent_articles:"최신 기사",news_description:"Jina 2.0에서는 커뮤니티의 의견을 경청했습니다. 실제로 나는 깊이 들었다. “당신의 문제점은 무엇입니까?”라고 묻고 귀중한 피드백을 간절히 기다립니다.",news_title:"모든 콘텐츠 검색: Jina 2.0 MEME 콘테스트를 진행 중입니다.",photos:"사진",product:"제품별로 필터링",search:"제목으로 검색",tech_blog:"기술 기사",title:"소식",top_stories:"기사 선택"},V="🎉 우리의 첫 번째 책, Neural Search – Prototype to Production with Jina가 오늘 공식 출시되었습니다!",$={description:"Jina AI 내부에 독점적으로 접근할 수 있습니다.",engage:"우리는 하루 종일 대화형 대화를 적극 권장합니다. 아이디어와 관점의 교환은 우리에게 매우 중요합니다. 이러한 논의를 통해 발생하는 잠재적인 협력은 더욱 통합되고 혁신적인 미래에 크게 기여할 수 있습니다.",engage_title:"브레인스토밍",experience:"우리는 손님들을 위해 독일어, 영어, 프랑스어, 스페인어, 중국어, 러시아어로 제공되는 3시간짜리 몰입형 투어를 준비했습니다. 이 투어에서는 멀티모달 AI의 진행 상황과 인공 지능 분야에 대한 견해를 심층적으로 살펴보고 특정 프로젝트에 대한 자세한 리뷰를 제공합니다. 우리는 아이디어와 통찰력의 교환을 촉진하기 위해 그룹 토론으로 마무리할 것입니다. 요청 시 점심 식사도 가능합니다.",experience_title:"내부자 투어",group_size:"예상 방문객 수",impact:"오픈 소스 커뮤니티에 대한 우리의 기여와 다중 모달 AI 기술에 대한 우리의 노력이 어떻게 Jina AI를 인공 지능 혁신의 영향력 있는 플레이어로 만들었는지 알아보세요. 우리의 목표는 의사 결정에서 중요한 역할을 하고 AI 기술의 발전이 모든 사람에게 이익이 되도록 하는 것입니다.",impact_title:"업계 영향력",introduction:"지나 AI는 인공지능의 미래에 관심이 있는 기관에 문을 열게 되어 기쁘게 생각합니다. 우리는 정치, NGO, 비영리 및 투자 부문의 사람들에게 공개일을 제공합니다. 여기에서 베를린 본사를 방문하여 당사의 운영, 비전 및 업계 통찰력에 대해 알아보시기 바랍니다.",motivation_min_length_v1:"좀 더 자세한 동기를 기재해주세요.",motivation_placeholder_v2:"동기를 공유하면 경험을 개선하는 데 도움이 됩니다.",motivation_to_attend_v2:"오픈데이에 관심을 갖는 이유는 무엇인가요?",one_hour:"1 시간",organization:"기구",organization_website:"기관 웹사이트",organization_website_placeholder:"조직의 홈페이지 또는 LinkedIn 프로필의 URL",preferred_date:"선호하는 날짜",preferred_language:"선호하는 언어",preferred_products:"어떤 제품에 관심이 있으신가요?",subtitle:"멀티모달 AI의 미래를 엿보세요",title:"개장일",tutor_subtitle:"신중하게 선별된 3시간짜리 투어를 통해 Jina AI의 다중 모드 AI 기술 선구적인 작업의 핵심에 더 가까이 다가갈 수 있습니다.",tutor_title:"독점 심층 토론",vision:"인공 지능의 미래에 대해 우리가 보는 포괄적인 시각에 참여해 보세요. 우리의 토론은 대규모 언어 모델, 다중 모드 AI의 잠재력, 글로벌 혁신의 미래를 형성하는 오픈 소스 기술의 영향에 중점을 둘 것입니다.",vision_title:"미래 비전"},Z={answer1:"우리는 독일어, 영어, 프랑스어, 스페인어, 중국어, 러시아어로 가이드 투어를 제공합니다.",answer2:"강의는 보통 3시간 정도 진행됩니다.",answer3:"점심 식사는 선택 사항이며 요청 시 준비해드릴 수 있습니다.",answer4:"우리의 공개일은 주로 정치인, NGO, 비영리 단체 및 투자자와 같은 전문 그룹을 위해 설계되었습니다. 그러나 때때로 개인의 프로필에 따라 예외가 적용될 수 있습니다.",answer5:"우리는 모든 규모의 그룹을 수용할 수 있습니다. 등록 양식에 그룹 규모를 기재해 주시면 자세한 내용을 확인해 드리겠습니다.",answer6:"등록 양식에는 관심 분야나 특별한 요구 사항을 지정할 수 있는 섹션이 있습니다. 우리는 귀하의 필요에 맞게 여행 일정을 조정하기 위해 최선을 다할 것입니다.",answer7:"현재 우리는 Kreuzberg에 있는 베를린 본사에서만 영업일을 제공하고 있습니다. 베이징과 선전 사무실은 현재 견학을 위해 문을 닫았습니다.",question1:"어떤 언어로 투어 서비스를 제공하나요?",question2:"강의는 얼마나 걸리나요?",question3:"점심은 제공되나요?",question4:"개인이 오픈데이에 등록할 수 있나요?",question5:"오픈일에는 몇 명이 그룹에 참여할 수 있나요?",question6:"튜토리얼의 관심 영역을 어떻게 지정합니까?",question7:"베이징이나 선전 사무실에 영업일이 있나요?"},ee={description:"오픈 소스, 클라우드 기반 대규모 다중 모드 모델 서비스 프레임워크"},ne={commercial_licence:{chip_label:"소규모 회사를 위해 설계되었습니다.",company_size_note:"직원이 100명 미만이고 매출이 500만 달러 미만인 회사를 위해 설계되었습니다.",cta_button:"지금 시작하세요",download_title:"상용 라이센스 다운로드",feature_api_desc:"구매 전 테스트",feature_api_title:"무료 API 테스트 액세스",feature_consulting:"모델 전문가와의 분기별 2시간 컨설팅 세션",feature_consulting_desc:"라이센스 기간당 3시간의 기술 컨설팅 서비스.",feature_future_support:"허가 없이 향후 CC BY-NC 모델에 액세스",feature_future_support_desc:"라이선스 기간 동안 CC-BY-NC-4.0에 따라 라이선스 허가자가 출시한 모든 새 모델.",feature_models:"CC BY-NC 모델을 통한 무제한 상업적 사용",feature_models_desc:"내부 사용 또는 고객 대면 애플리케이션에 통합을 포함하여 비즈니스 목적으로 모델을 사용하십시오.",price_amount:"$1,000",price_period:"/ 분기별",read_the_terms:"라이센스 조건 보기",read_the_terms_btn:"자귀",read_the_terms_desc:"구매하기 전에 상업용 라이선스 권리 및 제한 사항을 검토하세요.",subtitle:"더 나은 검색을 위해 필요한 모든 모델",test_before_purchase:"구매하기 전에 시도해 보세요",test_before_purchase_desc:"100만 개의 무료 API 토큰을 받거나 Hugging Face 모델을 사용하여 성능을 확인하세요.",title:"상업용 라이센스",try_api:"API를 먼저 사용해 보세요"},free_hour_consult:"1시간 무료 상담",free_hour_consult_description:"귀하의 시나리오에 대한 모범 사례를 논의하기 위해 제품 및 엔지니어링 팀과의 무료 1시간 상담을 예약하세요.",full_commercial:"상업적 이용 제한 없음",full_commercial_description:"어떠한 제한 없이 상업적 목적으로 API를 사용할 수 있습니다.",higher_limit:"더 빠른 속도!",higher_limit_description:"r.jina.ai의 경우 최대 1000RPM, s.jina.ai의 경우 최대 100RPM입니다. 자세한 내용은 속도 제한 섹션을 참조하세요.",key_manager:"API 키 관리",key_manager_description:"하나의 계정에서 여러 API 키를 관리하고, 사용 내역을 추적하고, 토큰을 충전하세요.",no_commercial:"비상업적 용도로만 사용 가능(CC-BY-NC)",no_commercial_description:"비상업적 목적으로만 API를 사용할 수 있습니다. 상업적 목적으로 사용하려면 API 키를 충전하세요.",on_prem:"온프레미스 배포를 위한 상용 라이선스 보유",on_prem_explain:"현장에서 당사 모델을 사용하려면 상용 라이센스를 구입하세요.",priority_support:"우선 기술 지원",priority_support_description:"기술적 질문 및 사고에 대해 24시간 이내에 이메일을 통해 응답을 보장합니다.",secured_by_stripe:"Stripe로 안전하게 결제하세요",via_api:"Jina 검색 재단 API 사용",via_api_explain:"당사의 모든 제품에 접근할 수 있는 가장 쉬운 방법입니다. 언제든지 토큰을 재충전하세요."},te="기반으로",ie="인쇄",ae={archived:"보관됨",cloud_native:"클라우드 네이티브",core:"풀뿌리 핵심",data_structure:"데이터 구조",embedding_serving:"대형 모델 벡터 배포",embedding_tuning:"대형 모델 벡터 튜닝",graduated:"졸업",incubating:"잠복기",kubernetes:"쿠버네티스",large_size_model:"대형 모델",linux_foundation:"리눅스 재단",llm1:"LLM 프레임워크",mid_size_model:"중간 모델",model_serving:"모델 배포",model_tuning:"모델 튜닝",observability:"관찰 가능성",orchestration:"클라우드 오케스트레이션",prompt_serving:"프롬프트 단어 전개",prompt_tuning:"프롬프트 단어 조정",rag1:"RAG 적용",sandbox:"모래 상자",small_size_model:"작은 모델",vector_database:"벡터 데이터베이스",vector_store:"벡터 데이터베이스"},re={description:"최고의 프롬프트 단어 도구 상자",image_model:"이미지 모델",intro:"최고의 프롬프트 단어 도구 상자",intro1:"프롬프트 단어 엔지니어링을 위한 최고의 도구",optimized:"귀하의 역할은 특정 주제나 문제에 대한 창의적인 아이디어와 제안을 제공하는 브레인스토밍 파트너가 되는 것입니다. 귀하의 답변에는 문제를 해결하거나 흥미로운 방식으로 주제를 추가로 탐색하는 데 도움이 되는 독창적이고 독특하며 관련성 있는 아이디어가 포함되어야 합니다. 귀하의 답변은 작업의 특정 요구 사항이나 제한 사항도 고려해야 합니다.",optimized_title:"최적화된 프롬프트 단어",original:"당신의 역할은 나의 브레인스토밍 파트너가 되는 것입니다.",original_title:"원래 프롬프트 단어",text_model:"텍스트 모델"},_e={features:[{description:"콘텐츠 생성과 프롬프트 단어 최적화 사이를 쉽게 전환하여 콘텐츠 품질을 한 단계 끌어올릴 수 있습니다.",name:"스마트 어시스턴트",title:"일일 생산성 향상."},{description:"효과적인 프롬프트 단어를 작성하는 방법을 모르시나요? 생각을 입력하고 마우스 클릭 한 번으로 더 나은 프롬프트 단어를 얻으세요.",name:"프롬프트 단어 최적화",title:"더 나은 입력, 더 나은 출력"},{description:"동일한 프롬프트 단어에 대한 출력을 비교하여 각 AI 모델의 성격을 이해합니다.",name:"모델경쟁",title:"나란히 모델 비교."},{description:"이는 프롬프트 단어를 API로 배포하는 가장 간단한 방법일 것입니다.",name:"프롬프트 단어 배포",title:"번거로운 Ops에 작별을 고하고 직접 배포하세요."},{description:"자신만의 LLM 에이전트를 맞춤화하고 다중 에이전트 시뮬레이션을 시작하세요. 목표를 달성하기 위해 가상 환경에서 어떻게 협력하거나 경쟁하는지 알아보세요.",name:"다중 에이전트",title:"상담원이 어떻게 협업하는지 살펴보세요."}],get_started:"PromptPerfect 시작하기"},oe={api_key:"API 키 충전",success:"구입 주셔서 감사합니다!",success_caption:"{_purchasedTime}에 주문이 완료되었습니다. API 키를 사용할 준비가 되었습니다!"},se="지금 구매하세요",ce={batch_explain:"이 API는 일괄 작업을 지원하여 요청당 최대 512개의 문서와 문서당 최대 8192개의 토큰을 허용합니다. 일괄 작업을 현명하게 사용하면 요청 수를 크게 줄이고 성능을 향상할 수 있습니다.",classifier:"레이블이 지정된 예제를 사용하여 분류기 학습",classifier_few_shot:"훈련된 퓨샷 분류기를 사용하여 입력을 분류합니다.",classifier_few_shot_token_counting:"토큰 수는 input_tokens입니다.",classifier_latency:"응답 시간은 입력 크기에 따라 다릅니다.",classifier_token_counting:"토큰 수는 input_tokens × num_iters입니다.",classifier_zero_shot:"제로샷 분류를 사용하여 입력 분류",classifier_zero_shot_token_counting:"토큰 수는 input_tokens + label_tokens입니다.",depends:"입력 크기에 따라 다름",description:"설명하다",embeddings:"텍스트/이미지를 고정 길이 벡터로 변환",endpoint:"API 포트",explain:"속도 제한은 <b>RPM</b>(분당 요청)과 <b>TPM</b>(분당 기간)의 두 가지 방식으로 추적됩니다. 제한은 IP별로 적용되며 먼저 도달한 임계값(RPM 또는 TPM)에 따라 도달할 수 있습니다.",gjinaai:"진술을 뒷받침하기 위해 네트워크 지식을 사용하십시오.",input_token_counting:"입력 요청의 토큰 수를 기준으로 합니다.",latency:"평균 지연",no_token_counting:"토큰 사용은 계산되지 않습니다.",output_token_counting:"출력 응답의 토큰 수를 기준으로 합니다.",premium_rate:"한도 상향 조정 가능",product:"제품",requestType:"요청 유형",reranker:"쿼리로 문서 구체화",rjinaai:"URL을 LLM 친화적인 텍스트로 변환",sjinaai:"웹을 검색하고 결과를 LLM 친화적인 텍스트로 변환하세요.",tbd:"결정될 것",title:"비율 제한",tokenCounting:"단어 사용 횟수",tokenizer:"긴 텍스트를 단어와 문장으로 분할",total_token_counting:"전체 프로세스에서 총 토큰 수를 계산합니다.",understanding:"비율 제한에 대해 알아보기",understanding_description:"속도 제한은 각 IP 주소가 1분 동안 API에 보낼 수 있는 최대 요청 수(RPM)입니다. 아래에서 각 제품 및 계층의 요금 제한에 대해 자세히 알아보세요.",wAPIkey:"API 키 사용",wPremium:"프리미엄 API 키와 함께 제공",woAPIkey:"API 키 없음"},de={decision:"결정하다",description:"LLM 지원 지능형 의사 결정 도구",intro:"동전의 양면을 보고 합리적인 결정을 내리세요"},le={beta:"실험",better_input:"처음부터 입력 품질 개선",better_input_description:"Agent 또는 RAG 시스템 출력에 문제가 있습니까? 이는 입력 품질이 좋지 않기 때문일 수 있습니다.",check_price_table:"가격표 보기",copy:"복사",demo:{advanced_parameter_explain:"{_product}에만 해당하는 특정 매개변수입니다.",advanced_parameters:"특정한",advanced_usage:"고급 사용법",ask_llm:"검색 기반이 필요한 경우 LLM에 문의하세요.",ask_llm_directly:"LLM에게 직접 물어보세요",ask_llm_with_search_grounding:"검색을 통해 LLM에 문의하기",ask_question:"질문하기",ask_question_hint:"질문을 입력하고 획득한 LLM 콘텐츠와 결합하여 답변을 생성하세요.",basic_usage:"기본 사용법",basic_usage1:"URL 읽기",basic_usage2:"검색어",basic_usage3:"확인하고 토론하세요",common_parameter_explain:"{_product1}, {_product2} 및 {_product3}에 사용할 수 있는 공통 매개변수입니다.",common_parameters:"공통 매개변수",copy:"복사",fetch:"콘텐츠 받기",get_response:"응답 받기",grounding_result_false:"이것은 잘못된 것입니다.",grounding_result_true:"이 진술은 정확합니다.",headers:{auth_token:"더 높은 비율 제한을 위해 API 키 추가",auth_token_explain:"더 높은 비율 제한에 액세스하려면 Jina API 키를 입력하세요. 최신 속도 제한 정보는 아래 표를 참조하세요.",browser_locale:"브라우저 로케일",browser_locale_explain:"페이지 렌더링을 위한 브라우저 로캘 설정을 제어합니다. 많은 웹사이트는 로캘 설정에 따라 다양한 콘텐츠를 제공합니다.",custom_script:"맞춤 JavaScript 사전 실행",custom_script_explain:"인라인 코드 문자열 또는 원격 스크립트 URL 엔드포인트를 허용하여 전처리된 JavaScript 코드를 실행합니다.",deepdive:"심층적인 소스 코드 분석",deepdive_explain:"철저한 사실 확인을 위해 더 많은 출처를 검색하고 전체 문서를 읽어보세요. 약간 느리지만 더 정확하고 참조가 더 많습니다.",default:"기본",default_explain:"대부분의 웹사이트 및 LLM 입력에 최적화된 기본 파이프라인입니다.",file:"로컬 PDF/HTML 파일",file_explain:"Reader를 사용하여 로컬 PDF 및 HTML 파일을 업로드하여 읽어보세요. pdf 및 html 파일만 지원됩니다.",html:"HTML",html_explain:"documentElement.outerHTML을 반환합니다.",image_caption:"설명하다",image_caption_explain:'캡션이 없는 이미지에 대체 태그로 "이미지 [idx]: [캡션]"을 추가하여 지정된 URL의 모든 이미지에 캡션을 추가합니다. 이를 통해 다운스트림 LLM은 추론 및 요약과 같은 활동에서 이미지와 상호 작용할 수 있습니다.',images_summary:"모든 이미지를 끝까지 모아보세요",images_summary_explain:'마지막으로 "이미지" 섹션이 생성됩니다. 이를 통해 다운스트림 LLM은 개요 페이지에서 모든 시각적 개체에 대한 개요를 볼 수 있으므로 추론 기능이 향상됩니다.',json_response:"JSON 응답",json_response_explain:"응답은 JSON 형식이며 URL, 헤더, 콘텐츠 및 타임스탬프(사용 가능한 경우)를 포함합니다. 검색 모드에서는 각각 설명된 JSON 구조를 따르는 5개의 항목 목록을 반환합니다.",links_summary:"모든 링크를 끝까지 그룹화",links_summary_explain:'마지막으로 "버튼 및 링크" 섹션이 생성됩니다. 이는 다운스트림 LLM 또는 웹 에이전트가 페이지를 탐색하거나 추가 조치를 취하는 데 도움이 될 수 있습니다.',markdown:"가격 인하",markdown_explain:"가독성 필터링을 우회하여 HTML에서 직접 마크다운을 반환합니다.",mode:"읽기 또는 검색 모드",mode_explain:"읽기 모드는 URL의 콘텐츠에 액세스하는 데 사용되는 반면, 검색 모드를 사용하면 웹에서 검색어를 검색하고 각 검색 결과 URL에 읽기 모드를 적용할 수 있습니다.",no_cache:"캐싱 우회",no_cache_explain:"당사의 API 서버는 일정 기간 동안 읽기 및 검색 모드를 위해 콘텐츠를 캐시합니다. 이 캐시를 우회하려면 이 헤더를 true로 설정하세요.",no_gfm:"장애가 있는",no_gfm_explain:"GFM(Github Flavored Markdown) 기능이 비활성화되었습니다.",no_gfm_table:"GFM 테이블 없음",no_gfm_table_explain:"GFM 테이블을 선택 해제하되 응답 테이블 HTML 요소를 유지하세요.",opt_out_gfm:"Github 스타일 마크다운",opt_out_gfm_explain:"GFM(Github Flavored Markdown) 기능을 옵트인/아웃합니다.",pageshot:"페이지 스냅샷",pageshot_explain:"전체 페이지 스크린샷의 이미지 URL을 반환합니다(최선의 노력).",post_with_url:"POST 방법을 사용하세요",post_with_url_explain:"GET 방식 대신 POST 방식을 사용하고 본문에 URL을 전달합니다. 해시 기반 라우팅을 사용하여 SPA를 구축하는 데 유용합니다.",proxy_server:"프록시 서버 사용",proxy_server_explain:"당사의 API 서버는 귀하의 프록시를 활용하여 URL에 액세스할 수 있는데, 이는 특정 프록시를 통해서만 액세스할 수 있는 페이지에 유용합니다.",references:"참조하다",references_explain:"사용자 제공 참조(URL)의 쉼표로 구분된 목록",remove_all_images:"모든 사진 삭제",remove_all_images_explain:"응답에서 모든 이미지를 제거합니다.",remove_selector:"제외 선택기",remove_selector_explain:"페이지에서 지정된 요소를 제거하기 위한 CSS 선택기 목록을 제공합니다. 페이지의 특정 부분(예: 머리글, 바닥글 등)을 제외하려는 경우 유용합니다.",result_count:"결과 제한",result_count_explain:"반환된 검색 결과 수입니다.",return_format:"콘텐츠 형식",return_format_explain:"과도한 필터링을 방지하기 위해 응답의 세부정보 수준을 제어할 수 있습니다. 기본 파이프라인은 대부분의 웹사이트 및 LLM 입력에 최적화되어 있습니다.",screenshot:"스크린샷",screenshot_explain:"첫 화면의 이미지 URL을 반환합니다.",set_cookie:"쿠키 전달",set_cookie_explain:"당사의 API 서버는 URL에 액세스할 때 사용자 정의 쿠키 설정을 전달할 수 있으며 이는 추가 인증이 필요한 페이지에 유용합니다. 쿠키가 포함된 요청은 캐시되지 않습니다.",site_selector:"사이트 검색",site_selector_explain:"지정된 웹사이트 또는 도메인에 대한 검색 결과만 반환합니다. 기본적으로 전체 웹을 검색합니다.",stream_mode:"스트리밍 모드",stream_mode_explain:"스트리밍 모드는 더 큰 대상 페이지를 지원하므로 페이지가 완전히 렌더링되는 데 더 많은 시간을 허용합니다. 표준 모드로 인해 콘텐츠가 불완전한 경우 스트리밍 모드 사용을 고려해 보세요.",target_selector:"대상 선택기",target_selector_explain:"페이지의 보다 구체적인 부분에 집중할 수 있는 CSS 선택기 목록을 제공합니다. 원하는 콘텐츠가 기본 설정에서 표시되지 않을 때 유용합니다.",text:"텍스트",text_explain:"document.body.innerText를 반환합니다.",wait_for_selector:"선택기를 기다리세요",wait_for_selector_explain:"특정 요소가 반환되기 전에 나타날 때까지 기다리는 CSS 선택기 목록을 제공합니다. 이 기능은 기본 설정에서 원하는 콘텐츠를 표시할 수 없을 때 유용합니다.",with_gfm:"활성화됨",with_gfm_explain:"GFM(Github Flavored Markdown) 기능이 활성화되었습니다.",with_iframe:"iframe 추출 활성화",with_iframe_explain:"DOM 트리에 포함된 모든 iframe의 콘텐츠를 추출하고 처리합니다.",with_shadow_dom:"Shadow DOM 추출 활성화",with_shadow_dom_explain:"문서의 모든 Shadow DOM 루트를 탐색하고 콘텐츠를 추출합니다.",x_timeout:"시간 초과",x_timeout_explain:"웹페이지가 로드될 때까지 기다리는 최대 시간입니다. 이는 전체 엔드투엔드 요청에 대한 총 시간이 아닙니다."},how_to_stream:"콘텐츠가 제공될 때 처리하려면 요청 헤더를 스트리밍 모드로 설정하세요. 이렇게 하면 첫 번째 바이트를 수신하는 데 걸리는 시간이 최소화됩니다. 컬의 예:",how_to_use1:"LLM 액세스가 필요한 코드나 도구의 모든 URL에 https://r.jina.ai/를 추가하세요. 그러면 페이지의 주요 내용이 LLM에 적합한 깨끗한 텍스트로 반환됩니다.",how_to_use2:"쿼리에 https://s.jina.ai/를 추가하세요. 그러면 검색 엔진이 호출되어 URL 및 콘텐츠와 함께 상위 5개 결과가 반환되며 각각 간결하고 LLM 친화적인 텍스트로 표시됩니다.",how_to_use3:"명세서에 https://g.jina.ai/를 추가하세요. 이는 의사결정 엔진을 호출하고 진실률, 진술이 참인지 거짓인지를 나타내는 부울 값, 이유 요약 및 참조 목록을 반환합니다.",key_required:"이 엔드포인트를 사용하려면 API 키가 필요합니다.",learn_more:"더 알아보기",open:"새 탭에서 열기",params_classification:"매개변수",raw_html:"원시 HTML",reader_output:"리더 출력",reader_response:"독자 반응",reader_search_hint:"코드에서 이 URL을 사용하는 경우 URL을 인코딩하는 것을 잊지 마세요.",reader_url:"독자 URL",reader_url_hint:"리더 API를 통해 콘텐츠를 얻으려면 아래를 클릭하세요.",requires_post_method:"이 기능에는 POST 메서드가 필요합니다. 로컬 파일을 업로드하면 POST 메서드가 자동으로 활성화됩니다.",search_params:"검색 매개변수",search_query_rewrite:"위의 데모와는 달리 실제로는 기초를 얻기 위해 원래 질문을 웹에서 검색하지 않을 것입니다. 사람들이 자주 하는 일은 원래 문제를 다시 작성하거나 다중 홉 문제를 사용하는 것입니다. 검색된 결과를 읽은 다음 추가 쿼리를 생성하여 최종 답변에 도달하기 전에 필요에 따라 추가 정보를 수집합니다.",select_mode:"모드 선택",show_read_demo:"리더가 URL을 읽는 방법 알아보기",show_search_demo:"독자가 네트워크를 검색하는 방법 이해",slow_warning:"이 작업은 최대 30초가 소요될 수 있으며 요청당 최대 300,000개의 토큰이 필요합니다.",standard_usage:"표준 사용량",stream_mode:"스트리밍 모드",stream_mode_explain:"스트리밍 모드는 대상 페이지가 너무 커서 렌더링할 수 없을 때 유용합니다. 표준 모드가 제공하는 기능이 불완전하다고 생각되면 스트리밍 모드를 사용해 보세요.",stream_mode_explain1:"스트리밍 모드는 표준 모드가 불완전한 결과를 제공하는 경우 유용합니다. 이는 스트리밍 모드가 페이지가 완전히 렌더링될 때까지 더 오래 기다리기 때문입니다. 스트리밍 모드를 전환하려면 accept-header를 사용하세요.",tagline:"데모를 사용해 보세요",try_demo:"데모",use_headers:"요청 헤더를 사용하여 Reader API의 동작을 제어할 수 있습니다. 다음은 지원되는 헤더의 전체 목록입니다.",waiting_for_reader:"먼저 Reader API 결과를 기다립니다...",warn_grounding_message:"이 프로세스는 최대 30초가 걸릴 수 있으며 쿼리 요청당 최대 300,000개의 토큰을 소비합니다. 일부 브라우저에서는 지연 시간이 길어 요청을 종료할 수 있으므로 코드를 복사하여 터미널에서 실행하는 것을 권장합니다.",warn_grounding_title:"높은 대기 시간 및 토큰 사용량",your_query:"쿼리를 입력하세요",your_query_hint:"최신 정보나 세계 지식이 필요한 질문을 입력하세요.",your_statement:"귀하의 사실 확인 진술",your_url:"URL을 입력하세요",your_url_hint:"아래를 클릭하시면 페이지 소스코드에 바로 접속하실 수 있습니다"},description:"더 나은 기본 LLM을 찾으려면 URL을 읽고 온라인으로 검색하세요.",dont_panic_api_key_is_free:"공포에 질리지 말 것! 모든 새로운 API 키에는 백만 개의 무료 토큰이 포함되어 있습니다!",faq_v1:{answer1:'Reader API는 무료이며 API 키가 필요하지 않습니다. URL 앞에 "https://r.jina.ai/"를 추가하시면 됩니다.',answer10:"아니요, Reader API는 공개적으로 액세스 가능한 URL의 콘텐츠만 처리할 수 있습니다.",answer11:"5분 이내에 동일한 URL을 요청하면 Reader API가 캐시된 콘텐츠를 반환합니다.",answer12:"불행하게도.",answer13:"예, 리더에서 기본 PDF 지원을 사용하거나(https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4) arXiv에서 HTML 버전을 사용할 수 있습니다(https://r. jina.ai/https://arxiv.org/html/2310.19923v4)",answer14:"리더는 지정된 URL의 모든 이미지에 캡션을 추가하고 원래 캡션이 없는 경우 `이미지 [idx]: [캡션]`을 대체 태그로 추가합니다. 이를 통해 다운스트림 LLM은 추론, 요약 등을 위해 이미지와 상호 작용할 수 있습니다.",answer15:"Reader API는 확장성이 뛰어나도록 설계되었습니다. 실시간 트래픽을 기반으로 자동으로 확장되며, 최대 동시 요청 수는 현재 약 4,000개입니다. 진아AI의 핵심 제품 중 하나로 적극적으로 유지하고 있습니다. 그러니 제작에 자유롭게 사용해 보세요.",answer16:"아래 표에서 최신 속도 제한 정보를 확인하세요. 우리는 Reader API의 속도 제한과 성능을 개선하기 위해 적극적으로 노력하고 있으므로 이에 따라 이 표도 업데이트될 예정입니다.",answer2:"Reader API는 프록시를 사용하여 모든 URL을 가져오고 브라우저에서 해당 콘텐츠를 렌더링하여 고품질 기본 콘텐츠를 추출합니다.",answer3:"예, 리더 API는 오픈 소스이며 Jina AI GitHub 저장소에서 찾을 수 있습니다.",answer4:"Reader API는 일반적으로 URL을 처리하고 2초 이내에 콘텐츠를 반환하지만 복잡하거나 동적 페이지는 시간이 더 걸릴 수 있습니다.",answer5:"크롤링은 특히 복잡하거나 동적 페이지의 경우 복잡하고 신뢰할 수 없습니다. 리더 API는 간결하고 신뢰할 수 있는 깔끔한 LLM 수준 텍스트 출력을 제공합니다.",answer6:"Reader API는 URL의 내용을 원래 언어로 반환합니다. 번역 서비스를 제공하지 않습니다.",answer7:"차단 문제가 발생하는 경우 지원팀에 문의하여 도움과 해결 방법을 문의하세요.",answer8:"Reader API는 주로 웹 페이지용으로 제작되었지만 arXiv와 같은 사이트에서 HTML로 표시된 PDF에서 콘텐츠를 추출할 수 있지만 일반 PDF 추출에는 최적화되어 있지 않습니다.",answer9:"현재 리더 API는 미디어 콘텐츠를 처리하지 않지만 향후 개선 사항에는 이미지 캡션 및 비디오 요약이 포함될 예정입니다.",question1:"Reader API 사용과 관련된 비용은 얼마입니까?",question10:"로컬 HTML 파일에서 Reader API를 사용할 수 있습니까?",question11:"Reader API는 콘텐츠를 캐시합니까?",question12:"로그인 후 Reader API를 사용하여 콘텐츠에 액세스할 수 있나요?",question13:"Reader API를 사용하여 arXiv의 PDF에 액세스할 수 있나요?",question14:"리더에서 이미지 주석이 어떻게 작동하나요?",question15:"리더는 얼마나 확장 가능합니까? 이것을 프로덕션에 사용할 수 있나요?",question16:"Reader API의 속도 제한은 무엇입니까?",question2:"리더 API는 어떻게 작동하나요?",question3:"리더 API는 오픈 소스인가요?",question4:"Reader API의 일반적인 대기 시간은 얼마나 됩니까?",question5:"페이지를 직접 스크랩하는 대신 Reader API를 사용해야 하는 이유는 무엇입니까?",question6:"Reader API는 여러 언어를 지원합니까?",question7:"웹사이트에서 Reader API를 차단하는 경우 어떻게 해야 합니까?",question8:"Reader API가 PDF 파일에서 콘텐츠를 추출할 수 있습니까?",question9:"Reader API가 웹페이지의 미디어 콘텐츠를 처리할 수 있나요?",title:"독자에 대해 자주 묻는 질문"},fast:"빠르게",fast_stream:"실시간 데이터 흐름",fast_stream_description:"데이터를 빠르게 가져와야 합니까? 우리의 리더 API는 대기 시간을 최소화하기 위해 데이터를 전송할 수 있습니다.",free:"항상 무료",free_description:"리더 API는 무료입니다! 신용카드나 API 비밀번호가 필요하지 않습니다. 토큰 할당량을 소비하지 않습니다.",is_free:"그리고 그것은 실제로 무료입니다!",is_free_description:"Reader API는 무료로 사용할 수 있으며 유연한 요금 제한과 가격을 제공합니다. 높은 접근성, 동시성 및 안정성을 갖춘 확장 가능한 인프라를 기반으로 구축되었습니다. 우리는 귀하의 LLM을 위한 기초 솔루션이 되기 위해 노력하고 있습니다.",open:"새 탭에서 열기",original_pdf:"원본 PDF",rate_limit:"비율 제한",read_grounding_release_note:"릴리스 노트 읽기",reader_also_read_images:"웹 페이지의 이미지는 리더의 시각적 언어 모델을 사용하여 자동으로 캡션이 추가되고 출력에서 ​​이미지 대체 태그 형식으로 지정됩니다. 이렇게 하면 다운스트림 LLM에 이러한 이미지를 추론 및 요약 프로세스에 통합할 수 있는 충분한 힌트가 제공됩니다. 즉, 이미지에 대해 질문하고, 특정 이미지를 선택하고, 더 깊은 분석을 위해 URL을 더욱 강력한 VLM으로 전달할 수도 있습니다!",reader_description:"URL을 LLM 친화적인 입력으로 변환하려면 앞에 <code>r.jina.ai</code>를 추가하기만 하면 됩니다.",reader_do_grounding:"사실확인 독자",reader_do_grounding_explain:"새로운 벤치마크 엔드포인트는 실시간에 가까운 사실 확인 경험을 엔드 투 엔드로 제공합니다. 주어진 진술을 가져와 실시간 웹 검색 결과를 사용하여 벤치마킹하고 사실성 점수와 사용된 정확한 참조를 반환합니다. 문장을 쉽게 벤치마킹하여 LLM 환각을 줄이거나 사람이 작성한 콘텐츠의 완성도를 높일 수 있습니다.",reader_do_pdf_explain:"예, Reader는 기본적으로 PDF 읽기를 지원합니다. 이미지가 많은 PDF를 포함해 대부분의 PDF와 호환되며 놀라울 정도로 빠릅니다! LLM과 결합하면 ChatPDF 또는 문서 분석 AI를 쉽고 빠르게 구축할 수 있습니다.",reader_do_search:"추적성 리더 검색",reader_do_search_explain:"LLM에는 지식 제한이 있습니다. 즉, 최신 세계 지식에 접근할 수 없습니다. 이로 인해 잘못된 정보, 오래된 응답, 환각 및 기타 사실적 문제와 같은 문제가 발생할 수 있습니다. 기초는 GenAI 애플리케이션에 절대적으로 필수적입니다. Reader를 사용하면 웹상의 최신 정보를 사용하여 LLM의 기초를 다질 수 있습니다. 쿼리 앞에 https://s.jina.ai/를 추가하면 Reader가 웹을 검색하고 URL 및 콘텐츠와 함께 상위 5개 결과를 반환합니다. 각 결과는 깨끗하고 LLM 친화적인 텍스트 표시로 시작됩니다. . 이렇게 하면 LLM을 항상 최신 상태로 유지하여 더욱 사실적이고 덜 환상적으로 만들 수 있습니다.",reader_reads_images:"독자는 사진도 읽을 수 있습니다!",reader_reads_pdf:"리더는 PDF도 읽을 수 있습니다!",reader_result:"독자 결과",table:{td_1_0:"단일 채널 기반의 URL을 읽고 해당 콘텐츠를 반환합니다.",td_1_1:"분당 요청 20개",td_1_2:"분당 요청 200개",td_1_3:"출력 토큰에 따르면",td_1_4:"3초",td_1_5:"3초",td_2_0:"웹을 검색하면 상위 5개의 결과가 반환되어 세계 지식과 검색 증거를 얻는 데 도움이 됩니다.",td_2_1:"분당 요청 5개",td_2_2:"분당 요청 40개",td_2_3:"5개의 검색 결과를 모두 기반으로 한 출력 토큰 수",td_2_4:"10 초",td_2_5:"10 초",th0:"끝점",th1:"설명하다",th2:"API 키 없이 속도 제한",th3:"API 키를 사용한 속도 제한",th4:"토큰 계산 방식",th5:"평균 지연",th6:"평균 지연"},title:"리더 API",usage:"용법",usage_details_false:"기본 사용법만 표시",usage_details_null:"기본 및 고급 사용법 표시",usage_details_true:"고급 사용량만 표시",want_higher_rate_limit:"더 높은 속도 제한(최대 1000RPM)을 원하시나요? 우리는 당신을 지원할 수 있습니다!",what_is1:"독자란 무엇인가?",what_is_answer_long:"LLM에 네트워크 정보를 입력하는 것은 기반을 마련하는 중요한 단계이지만 어려울 수 있습니다. 가장 쉬운 방법은 웹페이지를 스크랩하고 원시 HTML로 피드하는 것입니다. 그러나 크롤링은 복잡하고 종종 차단될 수 있으며 원시 HTML은 마크업 및 스크립트와 같은 관련 없는 요소로 채워집니다. Reader API는 URL에서 핵심 콘텐츠를 추출하고 이를 깨끗한 LLM 친화적인 텍스트로 변환하여 에이전트 및 RAG 시스템에 대한 고품질 입력을 보장함으로써 이러한 문제를 해결합니다.",what_is_desc:"어떤 URL이든 방문하여 주요 콘텐츠를 LLM에 최적화된 텍스트로 추출하세요."},pe={confirm_message:"API 키에 {_leftTokens}개의 토큰이 남아 있습니다. 기사 {_numArticles}개의 전체 텍스트를 Reranker API로 보내고 {_selectedReranker} 모델을 사용하여 현재 페이지와 관련된 기사를 찾으면 API 키 {_APIKey}의 토큰 수가 크게 소모됩니다. 계속하시겠습니까?",confirm_title:"경고: 많은 토큰을 소비합니다.",out_of_quota:"이 API 키에 토큰이 부족합니다. 계정에 자금을 입금하거나 다른 API 키를 사용하세요.",recommend:"상위 5위 획득",recommended_articles:"유사한 기사 상위 5개"},ue={benchmark:{description0:"LlamaIndex는 RAG의 벡터 모델과 우리가 재현한 재정렬기의 다양한 조합을 평가합니다. 결과는 Jina Reranker가 검색 품질을 크게 향상시키는 것으로 나타났습니다. 이는 업스트림에서 사용되는 특정 벡터 모델과 무관한 이점입니다.",description1:"BIER(Benchmarking IR)은 관련성 및 NDCG를 포함하여 모델의 검색 효율성을 평가합니다. BIER 점수가 높을수록 일치 항목이 더 정확하고 검색 결과 순위가 높아집니다.",description2:"LoCo 벤치마크를 사용하여 로컬 일관성 및 컨텍스트에 대한 모델의 이해는 물론 쿼리별 순위도 측정합니다. LoCo 점수가 높을수록 관련 정보를 식별하고 우선순위를 지정하는 능력이 더 우수하다는 것을 반영합니다.",description3:"MTEB(다국어 텍스트 벡터 모델 벤치마크)는 일반적으로 클러스터링, 분류, 검색 및 기타 측정항목을 포함하여 텍스트 벡터 모델링에서 모델의 기능을 테스트합니다. 그러나 비교를 위해 MTEB의 재배열 작업만 사용합니다.",title:"기준",title0:"라마인덱스",title1:"관대",title2:"미친",title3:"MTEB"},benchmark_description:"비교를 위해 BGE(Beijing Intelligent Source Research Institute), BCE(NetEase Youdao) 및 Cohere의 다른 세 가지 주요 재배열업체를 벤치마크에 포함했습니다. 아래 차트에서 볼 수 있듯이 Jina Reranker는 모든 관련 재순위 카테고리에서 가장 높은 평균 점수를 획득하여 동종 업체 중에서 확실한 선두를 달리고 있습니다.",benchmark_title:"성능 벤치마크",choose_turbo:"터보 버전은 5배 더 빠릅니다.",choose_turbo_description:"또한 우리는 jina-reranker-v1-turbo-en과 jina-reranker-v1-tiny-en이라는 두 가지 새로운 오픈 소스 순위 재지정 모델을 제공합니다. 후자는 30M 매개변수와 4개 레이어만 포함합니다. 두 개의 새로운 재배열기는 기본 모델보다 최대 5배 빠르게 추론을 수행하며 품질은 약간 저하됩니다. 실시간 재정렬이 필요한 애플리케이션에 이상적입니다. 아래 리뷰를 읽어보세요.",customize_urself:"바꿔보고 반응이 어떻게 변하는지 확인해 보세요!",customize_urself_pl:"변경해 보고 반응이 어떻게 바뀌는지 확인하세요!",description:"검색 관련성을 극대화하는 세계적 수준의 신경 검색기입니다.",description_rich:"고급 재정렬 API를 사용하여 검색 관련성과 RAG 정확성을 극대화하세요.",example_input_document:"분류 대상 문서의 예",example_input_query:"샘플 쿼리",faq_v1:{answer1:"Reranker API 가격은 Vector Model API 가격 구조와 일치합니다. 각각의 새로운 API 키에는 1백만 개의 무료 토큰이 제공됩니다. 무료 토큰 외에도 다양한 패키지를 구매할 수도 있습니다. 자세한 내용은 가격 섹션을 참조하세요.",answer10:"예, Jina Reranker는 AWS에 배포할 수 있습니다. 엔터프라이즈 환경에서 온프레미스 배포가 필요한 경우 AWS Marketplace 제품을 통해 쉽게 배포할 수 있습니다.",answer11:"귀하의 특정 도메인 데이터에 맞춰 미세 조정된 리포머에 관심이 있으시면 영업팀에 문의해 주세요. 우리 팀은 귀하의 문의에 신속하게 답변해 드리겠습니다.",answer3:"주요 차이점은 아키텍처에 있습니다. 성능 측면에서는 경쟁사와 비교하여 광범위한 테스트와 벤치마킹을 거친 jina-reranker-v1을 권장합니다. Jina-reranker-v1은 크로스 인코더 아키텍처를 채택한 반면, Jina-colbert-v1은 ColBERTv2 아키텍처를 기반으로 하지만 쿼리 및 문서 컨텍스트 길이를 8192로 확장하여 원래 ColBERTv2 모델보다 더 나은 성능을 달성합니다.",answer4:"예, jina-colbert-v1은 오픈 소스이며 Huggingface를 통해 액세스할 수 있습니다. 하지만 jina-reranker-v1은 오픈소스가 아닙니다.",answer5:"현재는 영어만 지원합니다. 그러나 일부 사용자는 중국어로도 작동한다고 보고합니다. 이는 부분적으로 jina-reranker-v1-base-en이 jina-embeddings-v2-base-zh 벡터 모델 모델과 일부 가중치를 공유하기 때문일 수 있습니다.",answer6:"최대 쿼리 토큰 길이는 512입니다. 문서에는 토큰 제한이 없습니다.",answer7:"각 쿼리는 최대 2048개의 문서를 재정렬할 수 있습니다.",answer8:"벡터 모델 API와 달리 배치 크기 개념이 없습니다. 요청당 하나의 쿼리 문서 튜플만 보낼 수 있지만 튜플에는 최대 2048개의 후보 문서가 포함될 수 있습니다.",answer9:"지연 시간은 문서 및 쿼리의 길이에 따라 100밀리초에서 7초까지입니다. 예를 들어 64개 용어 쿼리를 사용하여 256개의 토큰이 있는 100개의 문서를 재정렬하는 데 약 150밀리초가 걸립니다. 문서 길이를 토큰 4096개로 늘리면 시간이 3.5초로 늘어납니다. 쿼리 길이를 512개 토큰으로 늘리면 시간은 7초로 더 늘어납니다.",question1:"Reranker API 비용은 얼마입니까?",question10:"AWS에 Jina Reranker를 배포할 수 있습니까?",question11:"도메인별 데이터에 대해 미세 조정된 재배열기를 제공합니까?",question3:"이 두 재배열기의 차이점은 무엇입니까?",question4:"Jina Reranker는 오픈 소스인가요?",question5:"리플라워는 다국어를 지원하나요?",question6:"쿼리 및 문서의 최대 길이는 얼마입니까?",question7:"쿼리당 재정렬할 수 있는 최대 문서 수는 몇 개입니까?",question8:"배치 크기는 얼마이며 하나의 요청으로 보낼 수 있는 쿼리 문서 튜플 수는 얼마입니까?",question9:"100개의 문서를 리플로우할 때 예상되는 대기 시간은 얼마나 됩니까?",title:"Reranker 관련 자주 묻는 질문"},feature_on_premises_description2:"AWS Sagemaker와 곧 Microsoft Azure 및 Google Cloud Services에 일정 조정 모델을 배포하거나 영업팀에 문의하여 가상 프라이빗 클라우드 및 온프레미스 서버에 대한 맞춤형 Kubernetes 배포를 받으십시오.",feature_on_premises_description3:"AWS Sagemaker 및 Microsoft Azure에 Jina Reranker를 배포하고 곧 Google Cloud Services에도 배포하거나 영업팀에 문의하여 가상 사설 클라우드 및 온프레미스 서버에 대한 맞춤형 Kubernetes 배포를 받으십시오.",feature_solid_description:"최첨단 학술 연구를 통해 개발되었으며 SOTA 재배열기에 대해 엄격한 테스트를 거쳐 탁월한 성능을 보장합니다.",how_it_works:"검색 시스템에서 재배열자는 다음과 같이 작동합니다.",how_it_works_v1:{description1:"사용자의 쿼리에 따라 BM25 또는 TF-IDF와 같은 벡터 모델이나 차원을 사용하여 데이터베이스의 관련 문서를 대략적으로 일치시킵니다.",description2:"재배열 모델은 이러한 예비 순위 결과를 사용하고 쿼리 용어가 문서 콘텐츠와 상호 작용하는 방식과 같은 미묘한 차이를 고려하여 문서와 쿼리에 대한 상관 분석을 더 세밀하게 수행합니다.",description3:"순위 재지정 모델은 가장 관련성이 있다고 판단되는 결과를 맨 위에 배치하여 검색 품질을 향상시킵니다.",title1:"초기 검색",title2:"재배열하다",title3:"향상된 결과"},improve_performance:"검색 품질이 다른 것보다 우수합니다.",improve_performance_description:"우리의 평가에 따르면 reranker를 사용한 검색 시스템은 적중률이 8% 향상되고 평균 역순위(MRR)가 33% 향상되는 등 크게 개선되었습니다.",learning1:"재주문자에 대해 알아보기",learning1_description:"재배치 모델이란 무엇입니까? 벡터 검색이나 쌍별 코사인 유사성이 충분하지 않은 이유는 무엇입니까? 포괄적인 가이드를 통해 리시퀀서에 대해 처음부터 자세히 알아보세요.",read_more_about_benchmark:"벤치마킹에 대해 자세히 알아보기",read_more_about_turbo:"터보 및 마이크로 모델에 대해 자세히 알아보기",read_more_about_v2:"Jina Reranker v2는 2024년 6월 25일에 출시된 동급 최고의 reranker이며 Agentic RAG용으로 제작되었습니다. 함수 호출 지원, 100개 이상의 언어로 된 다국어 검색, 코드 검색 기능을 갖추고 있으며 v1보다 6배 빠릅니다. v2 모델에 대해 자세히 알아보세요.",reranker_description:"검색 관련성과 RAG 정확성을 극대화하려면 고급 재정렬 API를 사용해 보세요. 무료로 사용해 보세요!",show_v2benchmark:"v2 모델(최신)에 대한 기준선 표시",table:{number_token_document:"각 문서의 토큰 수",number_token_query:"쿼리의 토큰 수",title:"쿼리와 100개의 문서를 재정렬하는 데 드는 시간 비용(밀리초)은 다음과 같습니다."},title:"재정렬 API",top_n:"재정렬된 문서의 최적 수를 반환합니다.",top_n_explain:"쿼리와 가장 관련성이 높은 문서 수입니다.",try_embedding:"벡터 모델 API 무료 사용",try_reranker:"재배열자 API 무료 평가판",v2_features:{description1:"Reranker v2는 쿼리 언어에 관계없이 100개 이상의 언어로 문서 검색을 지원합니다.",description2:"Reranker v2는 자연어 쿼리를 기반으로 코드 조각 및 함수 서명의 순위를 지정하므로 Agentic RAG 애플리케이션에 이상적입니다.",description3:"Reranker v2는 자연어 쿼리를 기반으로 가장 관련성이 높은 테이블의 순위를 지정하여 SQL 쿼리를 생성하기 전에 다양한 테이블 스키마를 정렬하고 가장 관련성이 높은 테이블 스키마를 결정하는 데 도움을 줍니다.",title1:"다국어 검색",title2:"함수 호출 및 코드 검색",title3:"표 형식 및 구조화된 데이터 지원"},v2benchmark:{descBeir:"Beir 데이터세트에 대해 다양한 재배열자가 보고한 NDCG 10 점수",descCodeSearchNet:"CodeSearchNet 데이터 세트의 다양한 재배열 모델에 대한 MRR 10 점수 보고서",descMKQA:"MKQA 데이터세트의 다양한 재배열자가 보고한 10개 점수를 상기해 보세요.",descNSText2SQL:"NSText2SQL 데이터 세트에서 다양한 재정렬자가 ​​보고한 3개 점수를 검토합니다.",descRTX4090:"RTX 4090 GPU의 다양한 순위 재지정 모델에 대해 보고된 처리량(50ms에 검색된 문서) 점수.",descToolBench:"ToolBench 데이터 세트의 다양한 재배열기에 의해 보고된 3개 점수를 불러옵니다.",titleBeir:"BEIR(다양한 IR 작업에 대한 이기종 벤치마크)",titleCodeSearchNet:"코드서치넷. 벤치마크는 쿼리와 관련된 태그가 지정된 코드 조각이 포함된 자연어 형식의 쿼리와 독스트링의 조합입니다.",titleMKQA:"MKQA(다국어 지식 질문 및 답변)",titleNSText2SQL:"NSText2SQL",titleRTX4090:"RTX4090의 Jina Reranker v2 처리량",titleToolBench:"툴벤치. 벤치마크는 단일 API 및 다중 API 설정에서 이를 사용하기 위한 16,000개 이상의 공개 API와 해당 합성 빌드 지침을 수집합니다."},vs_table:{col0:"재배열자",col0_1:"향상된 검색 정밀도 및 관련성",col0_2:"초기, 빠른 필터링",col0_3:"광범위한 쿼리에 대한 일반 텍스트 검색",col1:"벡터 검색",col1_1:"세부 정보: 하위 문서 및 쿼리 세그먼트",col1_2:"광범위: 전체 문서",col1_3:"중급: 다양한 텍스트 조각",col2:"BM25",col2_1:"높은",col2_2:"보통의",col2_3:"낮은",col3_1:"불필요한",col3_2:"높은",col3_3:"낮음, 사전 구축된 인덱스 활용",col4_1:"높은",col4_2:"높은",col4_3:"불필요한",col5_1:"자세한 문의에 더 적합",col5_2:"효율성과 정확성 사이의 균형",col5_3:"다양한 쿼리에 대해 일관되고 안정적임",col6_1:"깊은 맥락 이해로 매우 정확함",col6_2:"적당한 정확도로 빠르고 효율적",col6_3:"확립된 기능으로 확장성이 뛰어남",col7_1:"리소스 집약적이고 구현이 복잡함",col7_2:"깊은 쿼리 컨텍스트나 미묘한 차이를 포착하지 못할 수 있음",col7_3:"매우 구체적이거나 문맥에 맞는 검색에서는 실적이 좋지 않을 수 있습니다.",header0:"장면에 가장 적합",header1:"세분성",header2:"쿼리 시간 복잡도",header3:"인덱스 시간 복잡도",header4:"훈련 시간 복잡도",header5:"검색 품질",header6:"이점",header7:"약점",subtitle:"아래 표는 재정렬기, 벡터 검색 및 BM25를 포괄적으로 비교하여 각 범주의 강점과 약점을 강조합니다.",title:"재배열기, 벡터 검색 및 BM25의 비교"},what_is:"재배열기란 무엇입니까?",what_is_answer_long:`검색의 본질은 대부분의 사용자가 원하는 결과를 빠르고 효율적으로 찾는 것입니다. 지난 세기에는 BM25나 tf-idf와 같은 키워드 매칭 알고리즘이 다양한 검색 결과의 순위를 매기는 데 성숙하게 사용되었습니다. 최근에는 벡터 모델을 기반으로 한 코사인 유사성이 매우 대중화되었으며 많은 벡터 데이터베이스에서 표준이 되었습니다. 그러나 이러한 방법은 본질적으로 상대적으로 단순하며 자연어의 미묘함과 가장 중요하게는 문서와 쿼리 의도 간의 상관 정보를 무시하는 경우가 많습니다.

'재배치 모델'이 탄생한 곳! 순위 재지정 모델은 실제로 검색에서 초기 후보 세트(일반적으로 벡터 기반/용어 기반 검색 결과로 제공됨)를 가져와 사용자의 검색 의도와의 관련성을 재평가하는 고급 AI 모델입니다. 리플라워는 표면 수준의 텍스트 일치를 넘어 쿼리와 문서 콘텐츠 간의 더 깊은 상호 작용을 탐색합니다.`,what_is_answer_long_ending:"재정렬기는 하위 문서 및 하위 쿼리 수준에서 작동하기 때문에 검색 품질을 크게 향상시킬 수 있습니다. 즉, 개별 단어와 구, 그 의미, 쿼리와 문서에서 이들이 서로 어떻게 연관되어 있는지 확인합니다. 그 결과 더욱 정확하고 상황에 맞는 검색 결과가 생성됩니다.",what_is_desc:"Reranker는 BM25 검색 또는 벡터 리콜에 대한 검색 결과를 최적화하는 AI 모델입니다. 우리 기사에서 자세히 알아보세요."},me={caption_image_desc:"이미지에 대한 텍스트 설명을 생성합니다.",caption_image_title:"헤더 이미지",description:"모든 픽셀 뒤에 숨은 이야기를 알아보세요",example1:"공개된 영상에는 매력적인 흰 토끼와 초원의 나비가 등장하는 자연을 담은 듯하다. 토끼는 나비와 다양한 방식으로 상호작용하며 그들의 독특한 관계를 보여줍니다. 주변 자연은 이 단순하면서도 매력적인 장면의 아름다움을 더욱 돋보이게 하는 그림 같은 배경을 제공합니다.",generate_story_desc:"일반적으로 캐릭터의 대화나 독백이 포함된 이미지를 기반으로 스토리를 만듭니다.",generate_story_title:"이야기를 생성하다",intro1:"이미지·영상 이해 AI 선도",json_image_desc:"사전 정의된 스키마를 사용하여 이미지에서 구조화된 JSON 형식을 생성합니다. 이를 통해 이미지에서 특정 데이터를 추출할 수 있습니다.",json_image_title:"이미지에서 JSON 추출",summarize_video_desc:"주요 이벤트를 강조하여 비디오에 대한 간결한 요약을 생성합니다.",summarize_video_title:"요약 영상",visual_q_a_desc:"이미지 콘텐츠를 기반으로 쿼리에 응답합니다.",visual_q_a_title:"시각적 Q&A"},ge={ask_on_current_page:"이 페이지에 대해 질문하세요...",find_solution:"해당 솔루션 생성...",hint:"제품, 뉴스, 질문 검색",hotkey:"이 페이지에서 질문하려면 / 키를 누르세요.",hotkey1:"~에 따르면",hotkey2:"스위치",hotkey_long1:"어느 페이지에서나",hotkey_long3:"검색창 열기",more_results:"추가 결과 {_numMore}개",placeholder:"이 페이지의 콘텐츠에 대해 질문하세요.",proposing_solution:"현재 페이지 콘텐츠를 기반으로 답변을 생성합니다...",required:"문제를 더 자세히 설명해 주세요.",results:"결과"},Ae={description:"탐색, 상호 작용, 최적화: 제품 검색 재정의"},he={description:"기존 검색 인프라의 의미적 격차 해소"},Ie={"Hacker News":"HN뉴스",LinkedIn:"링크드인",facebook:"페이스북",reddit:"레딧",rss:"RSS 구독",share_btn:"공유하다",twitter:"X(이전 트위터)"},be={click_to_learn_more:"자세히 알아보려면 클릭하세요.",contextualization:"상황에 따른 이해",contextualization_desc:"reranker는 쿼리의 깊은 문맥 관련성을 기반으로 초기 검색 결과를 조정합니다. 이를 통해 사용자가 유용하다고 생각할 수 있는 콘텐츠와 더 잘 일치하도록 순위를 최적화할 수 있습니다.",coreInfra:"핵심 인프라",coreInfra_desc:"핵심 인프라는 퍼블릭 클라우드 및 온프레미스에서 검색 인프라 모델을 개발, 배포 및 조정하기 위한 클라우드 네이티브 계층을 제공하여 서비스를 쉽게 확장 및 축소할 수 있도록 합니다.",embedding_serving:"대형 모델 벡터 배포",embedding_serving_description:"클라우드 네이티브 기술을 사용하여 강력하고 확장 가능한 마이크로서비스로 대규모 모델 벡터 추론을 배포합니다.",embedding_tech:"벡터 모델",embedding_tech_description:`지나AI에서는 벡터모델 기술을 통해 인공지능 응용의 면모를 혁신하고 있습니다. 이 기술은 중요한 정보가 손실되지 않도록 하면서 여러 유형의 데이터를 효과적으로 표현하고 압축하는 통합 수단 역할을 할 수 있습니다. 우리의 핵심 목표는 복잡한 데이터 세트를 보편적으로 이해할 수 있는 벡터 모델 형식으로 변환하여 정확하고 심층적인 인공 지능 분석을 지원하는 것입니다.

벡터 모델은 AI 분야에서 기본적이면서도 중요한 역할을 합니다. 정밀한 이미지 인식 및 음성 인식과 같은 영역에서는 보다 미묘한 세부 사항과 차이점을 인식하는 데 도움이 됩니다. 자연어 처리에서는 상황적, 정서적 이해를 향상시켜 대화형 AI 및 언어 번역 도구를 더욱 정확하게 만듭니다. 또한 텍스트, 오디오, 비디오 등 다양한 콘텐츠 형식에 대한 사용자 선호도를 깊이 이해해야 하는 복잡한 추천 시스템을 구축할 때 벡터 모델이 중요한 역할을 합니다.`,embedding_tuning:"대형 모델 벡터 미세 조정",embedding_tuning_description:"특정 작업의 성능을 향상시키기 위해 전문 지식과 업계 데이터를 통합하여 고품질 대형 모델 벡터를 교육합니다.",embeddings:"벡터 모델",embeddings_desc:"벡터 모델은 다중 모드 데이터를 수치 벡터로 표현하는 최신 검색 시스템의 초석입니다. 이 과정을 통해 단순한 키워드 매칭을 훨씬 넘어서는 콘텐츠에 대한 보다 미묘한 이해가 가능해집니다.",for_developers:"개발자용",for_enterprise:"비즈니스를위한",for_power_users:"고급 사용자용",grounding:"추적성",grounding_desc:"독자는 LLM을 통해 입력과 결과를 구체화합니다. 최종 답변의 품질, 가독성 및 신뢰성을 향상시킵니다.",model_serving:"모델 배포",model_serving_description:"조정된 모델을 프로덕션에 배포하려면 GPU 호스팅과 같은 상당한 리소스가 필요한 경우가 많습니다. MLOps는 확장 가능하고 효율적이며 안정적인 방식으로 중대형 모델을 제공하는 데 중점을 둡니다.",model_tuning:"모델 튜닝",model_tuning_description:"작업별 데이터세트에서 사전 훈련된 모델의 매개변수를 조정하여 성능을 향상하고 특정 애플리케이션에 적용합니다.",personalization:"개인화하다",personalization_desc:"사용자 지침에 따라 합성 데이터를 사용하여 도메인별 벡터화 도구 및 재배열기를 자동으로 교육합니다.",preprocessing:"전처리",preprocessing_desc:"전처리에는 원시 데이터를 검색 시스템에서 이해할 수 있는 형식으로 정리, 정규화 및 변환하는 작업이 포함됩니다.",promptOps:"신속한 운영",promptOps_desc:"Prompt Ops는 쿼리 확장, LLM 입력 및 결과 재작성을 포함하여 검색 시스템의 입력 및 출력을 개선합니다. 이렇게 하면 검색을 더 쉽게 이해하고 더 나은 결과를 얻을 수 있습니다.",prompt_serving:"프롬프트 단어 전개",prompt_serving_description:"API를 통해 힌트를 래핑하고 제공하면 무거운 모델을 호스팅할 필요가 없습니다. 이 API는 일반적인 대규모 언어 모델 서비스를 호출하고 작업 체인에서 입력 및 출력의 조정을 처리합니다.",prompt_tech:"프롬프트 단어 및 에이전트 엔지니어링",prompt_tech_description:`Jina AI에서는 LLM(대형 언어 모델)과의 의사소통에 있어 신속한 단어 엔지니어링의 중요성을 이해하고 있습니다. 이러한 모델이 계속 발전함에 따라 심층적인 추론과 논리적 사고를 다루는 프롬프트 단어가 점점 더 복잡해졌습니다. 이러한 진전은 LLM과 프롬프트 워드 엔지니어링 간의 상호 강화 관계를 강조합니다.

미래에는 LLM이 컴파일러의 역할을 맡게 될 것이며 프롬프트 단어는 새로운 유형의 프로그래밍 언어로 진화할 것이라고 믿습니다. 이는 미래의 기술이 전통적인 프로그래밍 기술보다는 프롬프트 단어의 기술을 익히는 데 더 중점을 둘 수 있음을 의미합니다. Jina AI의 목표는 이 기술 혁명을 주도하고 이 새로운 "언어"에 능숙해지면서 고급 인공 지능을 더 쉽게 이해하고 적용할 수 있도록 만드는 것입니다.`,prompt_tuning:"프롬프트 단어 조정",prompt_tuning_description:"입력 프롬프트를 신중하게 설계하고 개선하여 출력이 원하는 특정 응답으로 향하도록 하는 프로세스입니다.",representation:"표현 학습",representation_desc:"벡터화는 다중 모드 데이터를 통합된 벡터 형식으로 변환합니다. 이를 통해 검색 시스템은 단순한 키워드를 넘어 콘텐츠를 이해하고 분류할 수 있습니다.",rerankers:"재배열자",rerankers_desc:"재배열기는 벡터 모델의 초기 결과를 가져와 최적화하여 가장 관련성이 높은 결과가 사용자에게 제공되도록 합니다. 이는 사용자 의도와 일치하는 고품질 검색 결과를 제공하는 데 중요합니다."},fe={care_most:"당신은 무엇에 가장 관심이 있습니까?",care_most_options:{accuracy:"정확성",cost:"비용",other:"다른",scalability:"처리량",speed:"속도"},care_most_required:"API 서비스를 선택할 때 가장 고려하는 점은 무엇입니까?",company_size:"당신의 회사는 얼마나 큰가요?",company_size_required:"회사 규모를 알려주시면 더 나은 서비스를 제공하는 데 도움이 됩니다.",company_url:"귀하의 회사 웹사이트는 무엇입니까?",company_url_required:"회사 웹사이트에 대해 알려주시면 더 나은 서비스를 제공하는 데 도움이 됩니다.",contactName:"당신의 이름",contactName_required:"당신을 뭐라고 부를까요?",contactTitle:"회사 내에서는 어떻게 적응하시나요?",contactTitle_required:"귀하의 직위는 필수 항목입니다.",contact_us:"문의하기",domain_required:"귀하의 근무 분야를 알려주시면 더 나은 서비스를 제공하는 데 도움이 됩니다",email:"이메일",email_contact:"귀하의 연락처 이메일",email_invalid:"잘못된 이메일",email_required:"이메일은 필수입니다",fine_tuned_embedding:"귀하의 개인 도메인 데이터를 위한 독점적인 벡터 모델을 원하십니까? 우리는 항상 당신을 위해 여기 있습니다!",fine_tuned_reranker:"귀하의 개인 데이터에 대한 전담 재정렬자를 원하십니까? 오다! 토론해 봅시다!",full_survey:"전체 설문조사에 참여하고 우리 팀으로부터 더 빠른 답변을 받으세요",get_new_key:"API 키 받기",get_update_blog_posts:"블로그 게시물의 최신 업데이트 알림",get_update_embeddings:"벡터 모델에 관한 최신 뉴스를 알려주세요.",send:"보내다",sign_up:"신청",subscribe:"신청",tell_domain:"귀하의 분야 또는 미세 조정 방향",usage_type:"귀하를 가장 잘 설명하는 사용법은 무엇입니까?",usage_type_options:{other:"다른",poc:"프로토타이핑 또는 개념 증명",production:"생산 환경",research:"연구 단계"},usage_type_required:"귀하의 사용 패턴을 알려주시면 더 나은 서비스를 제공하는 데 도움이 됩니다.",used_product:"어떤 모델을 사용하고 있나요?",used_product_required:"사용 중이거나 관심 있는 모델을 선택하세요."},we={description:"LLM을 강화하고 한계까지 밀어붙이세요"},ke="목차",Pe={advance_usage:"더 많은 기능을 보려면 POST 요청을 사용하세요.",basic_usage:"GET 요청을 사용하여 토큰 수를 직접 반환",basic_usage_explain:"간단히 GET 요청을 보내 텍스트의 토큰 수를 계산할 수 있습니다.",change_content:'"content" 매개변수를 변경하고 실시간 결과를 확인하세요.',chars:"성격",chinese:"중국인",chunk:"조각으로 자르다",chunk_all:"모든 블록",chunking:"번개처럼 빠른 속도로 긴 문서를 덩어리로 자르세요!",chunking_explain:"또한 분할기를 사용하여 긴 문서를 더 작은 덩어리로 분할하여 벡터 모델이나 재정렬기에서 처리하기 쉽게 만들 수도 있습니다. 우리는 공통의 구조적 단서를 가져와 Markdown, HTML, LaTeX, CJK 언어 등 다양한 유형의 콘텐츠에서 잘 작동하는 일련의 규칙과 경험적 방법을 구축했습니다.",chunking_short:"조각으로 자르다",chunks_in_total:"{_numChunks} 총 청크",count_tokens_hint:"<b>{_numTokens}</b> 토큰, {_numChars}자.",description:"긴 텍스트를 덩어리로 자르고 표시하세요.",description_long:"당사의 슬라이서는 LLM이 상황별 제약 조건 내에서 입력을 관리하고 모델 성능을 최적화하도록 돕는 데 중요합니다. 이를 통해 개발자는 토큰을 계산하고 관련 텍스트 세그먼트를 추출하여 효율적인 데이터 처리 및 비용 관리를 보장할 수 있습니다.",description_long1:"긴 텍스트를 덩어리로 나누고 단어 분할을 위한 무료 API입니다.",english:"영어",explain:"세그먼트화기는 텍스트를 벡터 모델/재배열기 또는 LLM에서 처리되는 기본 데이터 단위인 토큰 또는 청크로 변환하는 핵심 구성 요소입니다. 토큰은 전체 단어, 단어의 일부 또는 단일 문자를 나타낼 수 있습니다.",faq_v1:{answer1:"슬라이서는 무료로 사용할 수 있습니다. API 키를 제공하면 더 높은 요금 한도에 액세스할 수 있으며 키에 요금이 청구되지 않습니다.",answer10:"청킹 기술은 서양 언어 외에도 중국어, 일본어, 한국어에도 적용됩니다.",answer2:"API 키가 없으면 20RPM 속도 제한으로 슬라이서에 액세스할 수 있습니다.",answer3:"API 키를 사용하면 200RPM 속도 제한으로 슬라이서에 액세스할 수 있습니다. 프리미엄 유료 사용자의 경우 속도 제한은 1000RPM입니다.",answer4:"아니요. API 키는 더 높은 비율 제한에 액세스하는 데에만 사용됩니다.",answer5:"예, 슬라이서는 다국어이며 100개 이상의 언어를 지원합니다.",answer6:"GET 요청은 텍스트의 토큰 수를 계산하는 데만 사용되므로 이를 애플리케이션에 카운터로 쉽게 통합할 수 있습니다. POST 요청은 첫 번째/마지막 N 토큰 반환과 같은 더 많은 매개변수와 기능을 지원합니다.",answer7:"요청당 최대 64,000자를 보낼 수 있습니다.",answer8:"타일 ​​기능은 긴 문서를 일반적인 구조적 단서에 따라 작은 덩어리로 분할하여 텍스트가 의미 있는 덩어리로 정확하게 분할되도록 합니다. 본질적으로 이는 일반적으로 의미 경계(예: 문장 끝, 단락 구분 기호, 구두점 및 특정 접속사)와 일치하는 특정 구문 기능을 기반으로 텍스트를 분할하는 (큰!) 정규식 패턴입니다. 의미론적 다이싱이 아닙니다. 이 (큰) 정규식은 정규식의 한계 내에서 최대한 강력합니다. 복잡성과 성능의 균형을 유지합니다. 정규식은 진정한 의미론적 이해를 얻을 수는 없지만 일반적인 구조적 단서를 통해 컨텍스트에 대한 좋은 근사치를 제공할 수 있습니다.",answer9:'입력에 특수 토큰이 포함된 경우 토크나이저는 이를 "special_tokens" 필드에 넣습니다. 이렇게 하면 삽입 공격을 방지하기 위해 LLM에 입력하기 전에 텍스트를 제거하는 등 다운스트림 작업에 따라 쉽게 식별하고 적절하게 처리할 수 있습니다.',question1:"슬라이서 비용은 얼마입니까?",question10:"청킹은 영어 이외의 언어도 지원하나요?",question2:"API 키를 제공하지 않는 경우 속도 제한은 어떻게 됩니까?",question3:"API 키를 제공하는 경우 비율 제한은 어떻게 됩니까?",question4:"내 API 키로 토큰을 청구하나요?",question5:"슬라이서는 여러 언어를 지원합니까?",question6:"GET 요청과 POST 요청의 차이점은 무엇입니까?",question7:"요청당 분할할 수 있는 최대 단어 길이는 얼마입니까?",question8:"다이싱 기능은 어떻게 작동하나요? 시맨틱 다이싱인가요?",question9:'스플리터에서 "endoftext"와 같은 특수 토큰을 처리하는 방법은 무엇입니까?',title:"세그먼트화기에 대해 자주 묻는 질문"},free_api:"슬라이서는 무료로 사용할 수 있습니다. API 키를 제공하면 더 높은 요금 한도에 액세스할 수 있으며 키에 요금이 청구되지 않습니다.",input_text:"텍스트를 입력하세요",is_free:"슬라이서는 무료입니다!",is_free_description:"API 키를 제공하면 더 높은 요금 한도에 액세스할 수 있으며 키에 요금이 청구되지 않습니다.",japanese:"일본어",korean:"한국인",parameters:{auth_token:"더 높은 비율 제한을 위해 API 키 추가",auth_token_explain:"더 높은 비율 제한에 액세스하려면 Jina API 키를 입력하세요. 최신 속도 제한 정보는 아래 표를 참조하세요.",head:"처음 N개의 토큰을 반환합니다.",head_explain:'지정된 콘텐츠의 처음 N개 토큰을 반환합니다. 국경 독점. "꼬리"와 함께 사용할 수 없습니다.',learn_more:"자세히 알아보기",max_chunk_length:"각 블록의 최대 길이",max_chunk_length_explain:"각 블록의 최대 문자 수입니다. 실제로 텍스트에 자연스러운 경계가 있는 경우 블록 길이는 이 값보다 작을 수 있습니다.",return_chunks:"다이싱으로 돌아가기",return_chunks_explain:"입력을 의미상 의미 있는 조각으로 나누고 경험적 규칙을 사용하여 일반적인 구조적 단서를 기반으로 다양한 텍스트 유형과 극단적 사례에 적응합니다.",return_tokens:"단어 분할 결과를 반환할지 여부",return_tokens_explain:"응답에 토큰과 해당 ID를 반환합니다. 결과를 시각화하려면 전환하세요.",tail:"마지막 N개의 토큰을 반환합니다.",tail_explain:'지정된 콘텐츠의 마지막 N개 토큰을 반환합니다. 국경 독점. "머리"와 함께 사용할 수 없습니다.',type:"분할기",type_explain:"사용할 토크나이저를 선택합니다.",used_by_models:"{_usedBy}에 대해."},remove_boundary_cues:"개행 제거",remove_boundary_cues_explain:"입력(주요 경계 힌트)에서 모든 줄바꿈을 제거하면 질문이 더 어려워지고 응답이 어떻게 변하는지 확인하세요!",show_space:"선행/후행 공백 표시",table:{td_1_0:"텍스트를 분할하고 첫 번째/마지막 N 토큰을 계산하고 가져옵니다.",td_1_1:"20rpm",td_1_2:"200rpm",td_1_3:"1000rpm",td_1_4:"무료",td_1_5:"800밀리초"},title:"분할기 API",token_index:"토큰 코드: {_index}",usage:"용법",visualization:"심상",what_is:"세그먼터란 무엇입니까?"},ye={cta:"{_lang} 코드로 번역됨",select_language:"언어"},ve={description:"필요한 것은 Python 벡터 데이터베이스뿐입니다. 그 이상도 그 이하도 아닙니다."},Le="zzz",xe={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:t,api_general_faq:i,autotune:a,best_banner:r,beta:_,billing_general_faq:o,blog_tags:s,cclicence:c,classifier:d,clip_as_service:l,cloud:p,contact_us_page:u,copy:m,copy_to_clipboard_success:g,dalle_flow:A,"dev-gpt":{description:"가상 개발팀"},disco_art:h,doc_array:I,download:b,embedding:f,embeddings:w,faq:k,faq_button:P,farewell:y,finetuner:v,finetuner_plus:L,finetuning:x,footer:q,get_new_key:R,github:M,header:S,hub:C,huggingface:j,impact_snapshots:z,inference:T,integrations:J,internship_faq:G,internship_page:U,jcloud:B,jerboa:O,jina:D,jina_chat:E,key_manager:N,lab_dialog:F,landing_page:H,langchain_serve:K,legal_page:W,model_graph:Q,news_page:Y,newsroom_page:X,notice:V,open_day:$,open_day_faq:Z,open_gpt:ee,paywall:ne,powered_by:te,print:ie,project_status:ae,prompt_perfect:re,promptperfect:_e,purchase:oe,purchase_now:se,rate_limit:ce,rationale:de,reader:le,recommender:pe,reranker:ue,scenex:me,searchbar:ge,searchscape:Ae,semantic:he,share:Ie,spectrum:be,subscribe_system:fe,think_gpt:we,toc:ke,tokenizer:Pe,translator:ye,vectordb:ve,zzz:Le};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,t as about_us_page,i as api_general_faq,a as autotune,r as best_banner,_ as beta,o as billing_general_faq,s as blog_tags,c as cclicence,d as classifier,l as clip_as_service,p as cloud,u as contact_us_page,m as copy,g as copy_to_clipboard_success,A as dalle_flow,xe as default,h as disco_art,I as doc_array,b as download,f as embedding,w as embeddings,k as faq,P as faq_button,y as farewell,v as finetuner,L as finetuner_plus,x as finetuning,q as footer,R as get_new_key,M as github,S as header,C as hub,j as huggingface,z as impact_snapshots,T as inference,J as integrations,G as internship_faq,U as internship_page,B as jcloud,O as jerboa,D as jina,E as jina_chat,N as key_manager,F as lab_dialog,H as landing_page,K as langchain_serve,W as legal_page,Q as model_graph,Y as news_page,X as newsroom_page,V as notice,$ as open_day,Z as open_day_faq,ee as open_gpt,ne as paywall,te as powered_by,ie as print,ae as project_status,re as prompt_perfect,_e as promptperfect,oe as purchase,se as purchase_now,ce as rate_limit,de as rationale,le as reader,pe as recommender,ue as reranker,me as scenex,ge as searchbar,Ae as searchscape,he as semantic,Ie as share,be as spectrum,fe as subscribe_system,we as think_gpt,ke as toc,Pe as tokenizer,ye as translator,ve as vectordb,Le as zzz};
