{
  "slug": "query-expansion-with-llms-searching-better-by-saying-more",
  "id": "67af53142962d20001d63c71",
  "uuid": "581110d6-5791-42f7-b754-16d597390ff7",
  "title": "Расширение поисковых запросов с помощью LLM: улучшаем поиск, говоря больше",
  "html": "<p>Расширение запросов долгое время было проверенным методом улучшения поисковых систем, хотя оно отошло на второй план после появления семантических эмбеддингов. Хотя некоторые могут считать его устаревшим в современных реалиях RAG и агентного поиска, не стоит его списывать со счетов. В этом глубоком анализе мы рассмотрим, как сочетание автоматического расширения запросов с <code>jina-embeddings-v3</code> и LLM может поднять ваш поиск на новый уровень и обеспечить точные результаты.</p><h2 id=\"what-is-query-expansion\">Что такое расширение запросов?</h2><p>Расширение запросов было разработано для поисковых систем, которые оценивают релевантность путем сопоставления слов из запросов с документами, содержащими их, как <a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\">tf-idf</a> или другие схемы \"разреженных векторов\". Это имеет очевидные ограничения. Различные формы слов мешают сопоставлению, например \"бежал\" и \"бегущий\", или \"оптимизировать\" и \"optimize\". Предварительная обработка с учетом особенностей языка может смягчить некоторые из этих проблем, но не все. Технические термины, синонимы и связанные слова гораздо сложнее обрабатывать. Например, запрос медицинских исследований о \"коронавирусе\" не будет автоматически идентифицировать документы, в которых говорится о \"COVID\" или \"SARS-CoV-2\", хотя это были бы очень хорошие совпадения.</p><p>Расширение запросов было изобретено как решение.</p><p>Идея заключается в добавлении дополнительных слов и фраз к запросам для увеличения вероятности нахождения хороших совпадений. Таким образом, к запросу \"коронавирус\" могут быть добавлены термины \"COVID\" и \"SARS-CoV-2\". Это может значительно улучшить эффективность поиска.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"700\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/QueryExpansion1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/QueryExpansion1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/QueryExpansion1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion1.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Рисунок 1: Блок-схема расширения запросов с тезаурусом</span></figcaption></figure><p>Нелегко решить, какие термины следует добавить к запросу, и было проведено много работы над тем, как определить хорошие термины и как их взвешивать для поиска в стиле tf-idf. Общие подходы включают:</p><ul><li>Использование тезауруса, составленного человеком.</li><li>Интеллектуальный анализ больших текстовых корпусов для поиска связанных слов.</li><li>Выявление других терминов, используемых в похожих запросах из журнала запросов.</li><li>Обучение тому, какие слова и фразы подходят для расширения запросов <a href=\"https://en.wikipedia.org/wiki/Rocchio_algorithm\">на основе обратной связи от пользователей</a>.</li></ul><p>Однако предполагается, что семантические модели эмбеддингов устраняют необходимость в расширении запросов. Хорошие текстовые эмбеддинги для \"коронавирус\", \"COVID\" и \"SARS-CoV-2\" должны быть очень близки друг к другу в векторном пространстве эмбеддингов. Они должны естественным образом совпадать без какого-либо дополнения.</p><p>Но хотя теоретически это должно быть так, реальные эмбеддинги, созданные реальными моделями, часто не дотягивают до этого уровня. Слова в эмбеддингах могут быть неоднозначными, и добавление слов к запросу может подтолкнуть его к лучшим совпадениям, если использовать правильные слова. Например, эмбеддинг для \"кожная сыпь\" может идентифицировать документы о \"поспешных действиях\" и \"креме для кожи\", пропуская при этом медицинскую статью о \"дерматите\". Добавление релевантных терминов, вероятно, подтолкнет эмбеддинг от несвязанных совпадений к лучшим.</p><h2 id=\"llm-query-expansion\">Расширение запросов с помощью LLM</h2><p>Вместо использования тезауруса или лексического интеллектуального анализа данных мы рассмотрели использование LLM для расширения запросов. LLM имеют несколько важных потенциальных преимуществ:</p><ul><li><strong>Широкие лексические знания</strong>: Поскольку они обучены на больших, разнообразных наборах данных, меньше беспокойства о выборе подходящего тезауруса или получении правильных данных.</li><li><strong>Способность к суждению</strong>: Не все предложенные термины расширения обязательно подходят к конкретному запросу. LLM могут не делать идеальных суждений о тематической релевантности, но альтернативы вообще не могут делать суждений.</li><li><strong>Гибкость</strong>: Вы можете настроить ваш промпт под потребности задачи поиска, в то время как другие подходы жесткие и могут требовать много работы для адаптации к новым доменам или источникам данных.</li></ul><p>После того как LLM предложила список терминов, расширение запросов для эмбеддингов работает так же, как традиционные схемы расширения запросов: мы добавляем термины к тексту запроса, а затем используем модель эмбеддингов для создания вектора эмбеддинга запроса.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"850\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/QueryExpansion2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/QueryExpansion2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/QueryExpansion2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion2.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Рисунок 2: Расширение запросов эмбеддингов с помощью LLM</span></figcaption></figure><p>Для работы этого подхода вам нужно:</p><ul><li>Доступ к LLM.</li><li>Шаблон промпта для получения терминов расширения от LLM.</li><li>Модель текстовых эмбеддингов.</li></ul><h2 id=\"trying-it-out\">Пробуем на практике</h2><p>Мы провели несколько экспериментов, чтобы проверить, добавляет ли этот подход ценность при поиске текстовой информации. В наших тестах использовались:</p><ul><li>Одна LLM: <a href=\"https://deepmind.google/technologies/gemini/flash/\">Gemini 2.0 Flash</a> от Google.</li><li>Две модели эмбеддингов, чтобы проверить, обобщается ли расширение запросов LLM на разные модели: <code>jina-embeddings-v3</code> и <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\"><code>all-MiniLM-L6-v2</code></a>.</li><li>Подмножество <a href=\"https://github.com/beir-cellar/beir\">бенчмарков BEIR</a> для информационного поиска.</li></ul><p>Мы проводили наши эксперименты в двух условиях промптинга:</p><ul><li>Использование общего шаблона промпта для получения терминов расширения.</li><li>Использование специфичных для задачи шаблонов промптов.</li></ul><p>Наконец, мы написали наши промпты для получения разного количества добавляемых терминов: 100, 150 и 250.</p><p>Наш код и результаты <a href=\"https://github.com/jina-ai/llm-query-expansion/\">доступны на GitHub</a> для воспроизведения.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/llm-query-expansion/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/llm-query-expansion: Query Expension for Better Query Embedding using LLMs</div><div class=\"kg-bookmark-description\">Query Expension for Better Query Embedding using LLMs - jina-ai/llm-query-expansion</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-1.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/llm-query-expansion\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"results\">Результаты</h2><h3 id=\"using-a-general-prompt\">Использование общего промпта</h3><p>После нескольких проб и ошибок мы обнаружили, что следующий промпт хорошо работает с Gemini 2.0 Flash:</p>\n<!--kg-card-begin: html-->\n<pre>\nPlease provide additional search keywords and phrases for \neach of the key aspects of the following queries that make \nit easier to find the relevant documents (about <span style=\"color:#AADB1E\">{size}</span> words \nper query):\n<span style=\"color:#AADB1E\">{query}</span>\n\nPlease respond in the following JSON schema:\nExpansion = {\"qid\": str, \"additional_info\": str}\nReturn: list [Expansion]\n</pre>\n<!--kg-card-end: html-->\n<p>Этот промпт позволяет нам пакетно обрабатывать наши запросы группами по 20-50 штук, присваивая каждому ID и получая обратно строку JSON, которая связывает каждый запрос со списком терминов расширения. Если вы используете другую LLM, возможно, вам придется поэкспериментировать, чтобы найти промпт, который работает для нее.</p><p>Мы применили эту настройку с <code>jina-embeddings-v3</code>, используя <a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\">адаптер асимметричного поиска</a>. При таком подходе запросы и документы кодируются по-разному — используя одну и ту же модель, но разные расширения LoRA — для оптимизации результирующих эмбеддингов для информационного поиска.</p><p>Наши результаты по различным бенчмаркам BEIR приведены в таблице ниже. Оценки представляют собой nDCG@10 (<a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain\">нормализованный накопленный дисконтированный выигрыш</a> по десяти лучшим найденным элементам).</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Бенчмарк</th>\n<th>Без расширения</th>\n<th>100 терминов</th>\n<th>150 терминов</th>\n<th>250 терминов</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>SciFact</strong><br/>(Задача проверки фактов)</td>\n<td>72.74</td>\n<td>73.39</td>\n<td>74.16</td>\n<td><strong>74.33</strong></td>\n</tr>\n<tr>\n<td><strong>TRECCOVID</strong><br/>(Задача медицинского поиска)</td>\n<td>77.55</td>\n<td>76.74</td>\n<td>77.12</td>\n<td><strong>79.28</strong></td>\n</tr>\n<tr>\n<td><strong>FiQA</strong><br/>(Поиск финансовых опционов)</td>\n<td>47.34</td>\n<td><strong>47.76</strong></td>\n<td>46.03</td>\n<td>47.34</td>\n</tr>\n<tr>\n<td><strong>NFCorpus</strong><br/>(Поиск медицинской информации)</td>\n<td>36.46</td>\n<td><strong>40.62</strong></td>\n<td>39.63</td>\n<td>39.20</td>\n</tr>\n<tr>\n<td><strong>Touche2020</strong><br/>(Задача поиска аргументов)</td>\n<td>26.24</td>\n<td>26.91</td>\n<td>27.15</td>\n<td><strong>27.54</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><p>Как видно, расширение запросов в большинстве случаев привело к улучшению поиска.</p><p>Чтобы проверить надежность этого подхода, мы повторили те же тесты с <code>all-MiniLM-L6-v2</code>, гораздо меньшей моделью, которая создает векторы вложений меньшего размера.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">sentence-transformers/all-MiniLM-L6-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-29.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/all-MiniLM-L6-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Результаты представлены в таблице ниже:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>No Expansion</th>\n<th>100 terms</th>\n<th>150 terms</th>\n<th>250 terms</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>SciFact</strong><br/>(Fact Checking Task)</td>\n<td>64.51</td>\n<td><strong>68.72</strong></td>\n<td>66.27</td>\n<td>68.50</td>\n</tr>\n<tr>\n<td><strong>TRECCOVID</strong><br/>(Medical Retrieval Task)</td>\n<td>47.25</td>\n<td>67.90</td>\n<td><strong>70.18</strong></td>\n<td>69.60</td>\n</tr>\n<tr>\n<td><strong>FiQA</strong><br/>(Financial Option Retrieval)</td>\n<td><strong>36.87</strong></td>\n<td>33.96</td>\n<td>32.60</td>\n<td>31.84</td>\n</tr>\n<tr>\n<td><strong>NFCorpus</strong><br/>(Medical Information Retrieval)</td>\n<td>31.59</td>\n<td><strong>33.76</strong></td>\n<td>33.76</td>\n<td>33.35</td>\n</tr>\n<tr>\n<td><strong>Touche2020</strong><br/>(Argument Retrieval Task)</td>\n<td>16.90</td>\n<td><strong>25.31</strong></td>\n<td>23.52</td>\n<td>23.23</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Здесь мы видим еще большее улучшение показателей поиска. В целом, меньшая модель получила больше пользы от расширения запросов. Среднее улучшение по всем задачам представлено в таблице ниже:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>100 terms</th>\n<th>150 terms</th>\n<th>250 terms</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>jina-embeddings-v3</code></td>\n<td>+1.02</td>\n<td>+0.75</td>\n<td><strong>+1.48</strong></td>\n</tr>\n<tr>\n<td><code>all-MiniLM-L6-v2</code></td>\n<td><strong>+6.51</strong></td>\n<td>+5.84</td>\n<td>+5.88</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Большая разница в чистом улучшении между двумя моделями, вероятно, связана с тем, что <code>all-MiniLM-L6-v2</code> начинала с более низкого уровня производительности. Векторы запросов, создаваемые <code>jina-embeddings-v3</code> в асимметричном режиме поиска, лучше способны улавливать ключевые семантические связи, и, следовательно, расширению запроса остается меньше пространства для добавления информации. Но этот результат показывает, насколько расширение запроса может улучшить производительность более компактных моделей, которые в некоторых случаях могут быть предпочтительнее больших моделей.</p><p>Тем не менее, расширение запроса принесло значимое улучшение поиска даже для высокопроизводительных моделей, таких как <code>jina-embeddings-v3</code>, хотя этот результат не идеально согласуется по всем задачам и условиям.</p><p>Для <code>jina-embeddings-v3</code> добавление более 100 терминов к запросу было контрпродуктивным для тестов FiQA и NFCorpus. Мы не можем сказать, что больше терминов всегда лучше, но результаты по другим тестам показывают, что больше терминов как минимум иногда лучше.</p><p>Для <code>all-MiniLM-L6-v2</code> добавление более 150 терминов всегда было контрпродуктивным, а в трех тестах добавление более 100 не улучшало показатели. В одном тесте (FiQA) добавление даже 100 терминов привело к значительно худшим результатам. Мы полагаем, это связано с тем, что <code>jina-embeddings-v3</code> лучше справляется с захватом семантической информации в длинных текстах запросов.</p><p>Обе модели показали меньшую реакцию на расширение запросов в тестах FiQA и NFCorpus.</p><h2 id=\"using-task-specific-prompting\">Использование специфичных для задачи промптов</h2><p>Характер результатов, представленных выше, предполагает, что хотя расширение запросов полезно, использование LLM рискует добавить бесполезные термины запроса, которые снижают производительность. Это может быть вызвано общим характером промпта.</p><p>Мы взяли два теста — SciFact и FiQA — и создали более специфичные для предметной области промпты, как показано ниже:</p>\n<!--kg-card-begin: html-->\n<pre>\nPlease provide additional search keywords and phrases for \neach of the key aspects of the following queries that make\nit easier to find the <span style=\"background-color:red\">relevant documents</span> <span style=\"background-color:green\">scientific document \nthat supports or rejects the scientific fact in the query \nfield</span> (about <span style=\"color:#AADB1E\">{size}</span> words per query):\n<span style=\"color:#AADB1E\">{query}</span>\nPlease respond in the following JSON schema:\nExpansion = {\"qid\": str, \"additional_info\": str}\nReturn: list [Expansion]\n</pre>\n<!--kg-card-end: html-->\n<p>Этот подход улучшил производительность поиска практически по всем показателям:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>No Expansion</th>\n<th>100<br/>terms</th>\n<th>150<br/>terms</th>\n<th>250<br/>terms</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>SciFact</td>\n<td><code>jina-embeddings-v3</code></td>\n<td>72.74</td>\n<td><strong>75.85 (+2.46)</strong></td>\n<td>75.07 (+0.91)</td>\n<td>75.13 (+0.80)</td>\n</tr>\n<tr>\n<td>SciFact</td>\n<td><code>all-MiniLM-L6-v2</code></td>\n<td>64.51</td>\n<td><strong>69.12 (+0.40)</strong></td>\n<td>68.10 (+1.83)</td>\n<td>67.83 (-0.67)</td>\n</tr>\n<tr>\n<td>FiQA</td>\n<td><code>jina-embeddings-v3</code></td>\n<td>47.34</td>\n<td>47.77 (+0.01)</td>\n<td><strong>48.20 (+1.99)</strong></td>\n<td>47.75 (+0.41)</td>\n</tr>\n<tr>\n<td>FiQA</td>\n<td><code>all-MiniLM-L6-v2</code></td>\n<td><strong>36.87</strong></td>\n<td>34.71 (+0.75)</td>\n<td>34.68 (+2.08)</td>\n<td>34.50 (+2.66)</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Показатели улучшились во всех условиях, кроме добавления 250 терминов к запросам SciFact с <code>all-MiniLM-L6-v2</code>. Более того, этого улучшения было недостаточно, чтобы <code>all-MiniLM-L6-v2</code> превзошла свой собственный базовый уровень на FiQA.</p><p>Для <code>jina-embeddings-v3</code> мы видим, что лучшие результаты были получены при добавлении 100 или 150 терминов. Добавление 250 терминов было контрпродуктивным. Это подтверждает нашу интуицию о том, что можно добавить слишком много терминов в запрос, особенно если их значение начинает отклоняться от цели.</p><h2 id=\"key-considerations-in-query-expansion\">Ключевые аспекты расширения запросов</h2><p>Расширение запросов явно может принести выгоду для поиска на основе эмбеддингов, но имеет некоторые оговорки:</p><h3 id=\"expense\">Затраты</h3><p>Взаимодействие с LLM добавляет задержку и вычислительные затраты к информационному поиску, и может добавить реальные затраты, если вы используете коммерческую LLM. Умеренное улучшение, которое оно приносит, может не оправдывать расходы.</p><h3 id=\"prompt-engineering\">Инжиниринг промптов</h3><p>Разработка хороших шаблонов промптов — это эмпирическое и экспериментальное искусство. Мы не утверждаем, что те, которые мы использовали в этой работе, являются оптимальными или переносимыми на другие LLM. Наши эксперименты со специфичными для задач промптами показывают, что изменение промптов может иметь очень значительное влияние на качество результата. Результаты также значительно различаются между доменами.</p><p>Эти неопределенности увеличивают стоимость разработки и подрывают поддерживаемость. Любое изменение в системе — смена LLM, моделей эмбеддингов или информационного домена — означает необходимость перепроверки и возможно переработки всего процесса.</p><h3 id=\"alternatives\">Альтернативы</h3><p>Мы видим здесь, что расширение запросов добавило наибольшее улучшение модели эмбеддингов с самой низкой начальной производительностью. Расширение запросов, по крайней мере в этом эксперименте, не смогло закрыть разрыв в производительности между <code>all-MiniLM-L6-v2</code> и <code>jina-embeddings-v3</code>, в то время как <code>jina-embeddings-v3</code> увидела более скромные улучшения от расширения запросов.</p><p>В этих обстоятельствах пользователь <code>all-MiniLM-L6-v2</code> получил бы лучшие результаты при меньших затратах, перейдя на <code>jina-embeddings-v3</code>, а не преследуя расширение запросов.</p><h2 id=\"future-directions\">Будущие направления</h2><p>Мы показали здесь, что расширение запросов может улучшить эмбеддинги запросов, и что LLM предлагают простой и гибкий способ получения хороших терминов для расширения запросов. Но относительно скромные улучшения предполагают, что предстоит еще много работы. Мы рассматриваем ряд направлений для будущих исследований:</p><ul><li>Тестирование ценности терминологического улучшения при генерации эмбеддингов документов.</li><li>Изучение возможностей улучшения запросов в других методах AI-поиска, таких как переранжирование.</li><li>Сравнение расширения запросов на основе LLM с более старыми и вычислительно менее затратными источниками терминов, например, тезаурусом.</li><li>Обучение языковых моделей специально для лучшего расширения запросов и предоставление им более специфичного для домена обучения.</li><li>Ограничение количества добавляемых терминов. 100 может быть слишком много для начала.</li><li>Поиск способов идентификации полезных и бесполезных терминов расширения. Любое фиксированное число, которое мы накладываем на расширение запроса, не будет идеально подходить, и если бы мы могли динамически оценивать предлагаемые термины и сохранять только хорошие, результат, вероятно, привел бы к повышению производительности.</li></ul><p>Это очень предварительное исследование, и мы оптимистично настроены на то, что такие методы принесут дальнейшие улучшения в базовые продукты поиска Jina AI.</p>",
  "comment_id": "67af53142962d20001d63c71",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/query-banner.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-02-14T15:28:36.000+01:00",
  "updated_at": "2025-02-18T03:24:20.000+01:00",
  "published_at": "2025-02-18T03:24:20.000+01:00",
  "custom_excerpt": "Search has changed a lot since embedding models were introduced. Is there still a role for lexical techniques like query expansion in AI? We think so.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "636409b554b68a003dfbdef8",
    "name": "Michael Günther",
    "slug": "michael",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
    "cover_image": null,
    "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
    "website": "https://github.com/guenthermi",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/query-expansion-with-llms-searching-better-by-saying-more/",
  "excerpt": "Поиск сильно изменился с момента появления моделей эмбеддингов. Есть ли все еще место для лексических методов, таких как расширение запросов, в эпоху AI? Мы считаем, что да.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}