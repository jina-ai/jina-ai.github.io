{
  "slug": "readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json",
  "id": "6785bfd62defad0001fb5f22",
  "uuid": "a8e2e140-18e5-49e6-aa8f-71bf4c9e3293",
  "title": "ReaderLM v2: Передовая малая языковая модель для преобразования HTML в Markdown и JSON",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/ReaderLM-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/ReaderLM-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">Мы находимся в пути к развитию и демократизации искусственного интеллекта через открытый исходный код и открытую науку.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-24.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/ReaderLM-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>В апреле 2024 года мы запустили <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a>, API, который преобразует любую веб-страницу в LLM-совместимый markdown, просто добавляя префикс URL <code>r.jina.ai</code>. В сентябре 2024 года <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown?ref=jina-ai-gmbh.ghost.io\">мы выпустили две малые языковые модели, <code>reader-lm-0.5b</code> и <code>reader-lm-1.5b</code>, специально разработанные для преобразования необработанного HTML в чистый markdown.</a> Сегодня мы рады представить второе поколение ReaderLM — языковую модель с 1,5 млрд параметров, которая преобразует необработанный HTML в красиво отформатированный markdown или JSON с превосходной точностью и улучшенной обработкой длинного контекста. <code>ReaderLM-v2</code> обрабатывает до 512 тыс. токенов общей длины входных и выходных данных. Модель обеспечивает многоязычную поддержку для 29 языков, включая английский, китайский, японский, корейский, французский, испанский, португальский, немецкий, итальянский, русский, вьетнамский, тайский, арабский и другие.</p><p>Благодаря своей <strong>новой парадигме обучения</strong> и <strong>более качественным обучающим данным</strong>, <code>ReaderLM-v2</code> представляет собой значительный шаг вперед по сравнению с предшественником, особенно в обработке длинных текстов и генерации markdown-синтаксиса. В то время как первое поколение рассматривало преобразование HTML в markdown как <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#:~:text=primarily%20needs%20to-,selective%2Dcopy,-from%20the%20input\">задачу \"выборочного копирования\"</a>, <strong>v2 рассматривает это как настоящий процесс перевода.</strong> Этот сдвиг позволяет модели мастерски использовать синтаксис markdown, особенно при<strong> генерации сложных элементов, таких как блоки кода, вложенные списки, таблицы и уравнения LaTex.</strong></p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-.mp4\" poster=\"https://img.spacergif.org/v1/1500x1000/0a/spacer.png\" width=\"1500\" height=\"1000\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:21</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Сравнение результатов преобразования HTML в markdown главной страницы HackerNews между ReaderLM v2, ReaderLM 1.5b, Claude 3.5 Sonnet и Gemini 2.0 Flash показывает уникальный стиль и производительность ReaderLM v2. ReaderLM v2 отлично сохраняет полную информацию из исходного HTML, включая оригинальные ссылки HackerNews, при этом умело структурируя контент с помощью синтаксиса markdown. Модель использует вложенные списки для организации локальных элементов (очки, временные метки и комментарии), сохраняя при этом последовательное глобальное форматирование через правильную иерархию заголовков (теги h1 и h2).</span></p></figcaption>\n        </figure><p>Основной проблемой в нашей первой версии была <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#degeneration-and-dull-loops\"><strong>дегенерация</strong></a><strong> </strong>после генерации длинных последовательностей, особенно в форме повторений и зацикливания. Модель либо начинала повторять один и тот же токен, либо зацикливалась, проходя через короткую последовательность токенов до достижения максимальной длины вывода. <code>ReaderLM-v2</code> значительно снижает эту проблему путем добавления контрастных потерь во время обучения — его производительность остается стабильной независимо от длины контекста или количества уже сгенерированных токенов.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Мы протестировали ReaderLM v2, преобразовав </span><a href=\"https://jina.ai/legal?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">нашу юридическую страницу</span></a><span style=\"white-space: pre-wrap;\"> в markdown — страницу примерно в 20 раз длиннее, чем главная страница HackerNews, включая большую таблицу субпроцессоров в конце страницы. Несмотря на эту серьезную задачу, ReaderLM v2 успешно сгенерировал полную таблицу в markdown, сохраняя при этом согласованную структуру документа, поддерживая как иерархию заголовков, так и форматирование списков даже после таблицы. Такой уровень производительности был недостижим с предыдущим поколением </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>reader-lm-1.5b</span></code><span style=\"white-space: pre-wrap;\">, которое деградировало после генерации длинных последовательностей.</span></figcaption></figure><p>Помимо преобразования в markdown, <code>ReaderLM-v2</code> представляет <strong>прямую генерацию HTML в JSON</strong>, позволяя пользователям извлекать определенную информацию из необработанного HTML в соответствии с заданной JSON-схемой. Этот сквозной подход устраняет необходимость в промежуточном преобразовании markdown, что является частым требованием во многих конвейерах очистки и извлечения данных на основе LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">В этом примере мы предоставили ReaderLM v2 исходный HTML с главной страницы HackerNews и JSON-схему, определяющую заголовок темы, URL, краткое содержание, ключевые слова, автора и количество комментариев. В то время как некоторые поля доступны непосредственно в HTML, другие — такие как ключевые слова — должны быть получены из содержимого. ReaderLM v2 успешно извлекает и генерирует все поля с замечательной точностью.</span></figcaption></figure><p>Как в количественных, так и в качественных тестах <code>ReaderLM-v2</code> превосходит гораздо более крупные модели, такие как <code>Qwen2.5-32B-Instruct</code>, <code>Gemini2-flash-expr</code> и <code>GPT-4o-2024-08-06</code> в задачах преобразования HTML в Markdown, демонстрируя сопоставимую производительность в задачах извлечения HTML в JSON, при этом используя значительно меньше параметров.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ReaderLM-v2-pro</span></code><span style=\"white-space: pre-wrap;\"> — это эксклюзивная премиум-версия, зарезервированная для наших корпоративных клиентов, включающая дополнительное обучение и оптимизации.</span></figcaption></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Instructed-HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2JSON.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Qualitative-Evaluation--2-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"620\"><figcaption><span style=\"white-space: pre-wrap;\">Наша ручная оценка охватывала 10 различных HTML-источников, включая новостные статьи, блог-посты, целевые страницы продуктов, сайты электронной коммерции и юридические документы на английском, японском и китайском языках. Тестовый корпус включал сложные элементы, такие как многострочные таблицы, динамические макеты, связанные таблицы, математические формулы (как встроенные, так и выводимые), блоки кода и глубоко вложенные списки. Качественная оценка фокусировалась на трех ключевых измерениях, где модели оценивались по шкале от 1 (низший) до 5 (высший). Затем баллы были нормализованы до максимума 1.0 по каждому аспекту для упрощения сравнения.</span></figcaption></figure><p>Эти результаты показывают, что хорошо спроектированная модель с 1.5B параметров может не только соответствовать, но и часто превосходить производительность гораздо более крупных моделей в задачах извлечения структурированных данных. Прогрессивные улучшения от <code>ReaderLM-v2</code> до <code>ReaderLM-v2-pro</code> демонстрируют эффективность нашей новой стратегии обучения в повышении производительности модели при сохранении вычислительной эффективности.</p><h2 id=\"get-started\">Начало работы</h2><h3 id=\"via-reader-api\">Через Reader API</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Читайте URL-адреса и ищите в интернете для лучшего заземления LLM.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-17.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>ReaderLM-v2</code> теперь интегрирован с нашим Reader API. Чтобы использовать его, просто укажите <code>x-engine: readerlm-v2</code> в заголовках запроса и включите потоковую передачу ответов с помощью <code>-H 'Accept: text/event-stream'</code>:</p><pre><code class=\"language-bash\">curl https://r.jina.ai/https://news.ycombinator.com/ -H 'x-engine: readerlm-v2' -H 'Accept: text/event-stream'\n</code></pre><p>Вы можете попробовать его без API-ключа с более низким ограничением скорости. <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\">Для более высоких ограничений скорости</a> вы можете приобрести API-ключ. <strong>Обратите внимание, что запросы ReaderLM-v2 потребляют в 3 раза больше токенов из вашего API-ключа, чем обычно.</strong> Эта функция сейчас находится в бета-версии, пока мы сотрудничаем с командой GCP для оптимизации эффективности GPU и увеличения доступности модели.</p><h3 id=\"on-google-colab\">В Google Colab</h3><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1FfPjZwkMSocOLsEYH45B3B4NxDryKLGI?usp=sharing&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-22.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-6.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Обратите внимание, что бесплатный GPU T4 имеет ограничения — он не поддерживает </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>bfloat16</span></code><span style=\"white-space: pre-wrap;\"> или flash attention 2, что приводит к большему использованию памяти и более медленной обработке длинных входных данных. Тем не менее, ReaderLM v2 успешно обрабатывает всю нашу юридическую страницу в этих условиях, достигая скорости обработки 67 токенов/с на входе и 36 токенов/с на выходе. Для производственного использования мы рекомендуем RTX 3090/4090 для оптимальной производительности.</span></p></figcaption></figure><p>Самый простой способ попробовать <code>ReaderLM-v2</code> в хостинговой среде — через наш блокнот Colab, который демонстрирует преобразование HTML в markdown, извлечение JSON и выполнение инструкций на примере главной страницы HackerNews. Блокнот оптимизирован для бесплатного уровня GPU T4 в Colab и требует <code>vllm</code> и <code>triton</code> для ускорения и запуска. Не стесняйтесь тестировать его с любым веб-сайтом.</p><h4 id=\"html-to-markdown-conversion\">Преобразование HTML в Markdown</h4><p>Вы можете использовать вспомогательную функцию <code>create_prompt</code> для легкого создания промпта для преобразования HTML в Markdown:</p><pre><code class=\"language-python\">prompt = create_prompt(html)\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p><code>result</code> будет строкой, обернутой в обратные кавычки Markdown как код. Вы также можете переопределить настройки по умолчанию для получения различных выходных данных, например:</p><pre><code class=\"language-python\">prompt = create_prompt(html, instruction=\"Extract the first three news and put into in the makdown list\")\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p>Однако, поскольку наши обучающие данные могут не охватывать все типы инструкций, особенно задачи, требующие многошагового рассуждения, наиболее надежные результаты получаются при преобразовании HTML в Markdown. Для наиболее эффективного извлечения информации мы рекомендуем использовать JSON-схему, как показано ниже:</p><h4 id=\"html-to-json-extraction-with-json-schema\">Извлечение HTML в JSON с помощью JSON-схемы</h4><pre><code class=\"language-python\">import json\n\nschema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"title\": {\"type\": \"string\", \"description\": \"News thread title\"},\n        \"url\": {\"type\": \"string\", \"description\": \"Thread URL\"},\n        \"summary\": {\"type\": \"string\", \"description\": \"Article summary\"},\n        \"keywords\": {\"type\": \"list\", \"description\": \"Descriptive keywords\"},\n        \"author\": {\"type\": \"string\", \"description\": \"Thread author\"},\n        \"comments\": {\"type\": \"integer\", \"description\": \"Comment count\"}\n    },\n    \"required\": [\"title\", \"url\", \"date\", \"points\", \"author\", \"comments\"]\n}\n\nprompt = create_prompt(html, schema=json.dumps(schema, indent=2))\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()\n</code></pre><p><code>result</code> будет строкой, обернутой в обратные кавычки в формате JSON, а не фактическим объектом JSON/dict. Вы можете использовать Python для преобразования строки в правильный словарь или JSON-объект для дальнейшей обработки.</p><h3 id=\"in-production-available-on-csp\">В продакшене: Доступно на CSP</h3><p><code>ReaderLM-v2</code> доступен на AWS SageMaker, Azure и GCP marketplace. Если вам нужно использовать эти модели за пределами этих платформ или локально в вашей компании, обратите внимание, что эта модель и <code>ReaderLM-v2-pro</code> лицензированы под CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">По вопросам коммерческого использования или доступа к <code>ReaderLM-v2-pro</code> не стесняйтесь связаться с нами.</a></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-jwfct4j4rvxk2?sr=0-21&ref_=beagle&applicationId=AWSMPContessa&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Reader-LM v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-23.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"quantitative-evaluation\">Количественная оценка</h2><p>Мы оцениваем ReaderLM-v2 по трем задачам извлечения структурированных данных в сравнении с современными моделями: <code>GPT-4o-2024-08-06</code>, <code>Gemini2-flash-expr</code> и <code>Qwen2.5-32B-Instruct</code>. Наша система оценки сочетает метрики, измеряющие как точность содержания, так и структурную точность. <code>ReaderLM-v2</code> - это публично доступная версия с открытыми весами, в то время как <code>ReaderLM-v2-pro</code> - это эксклюзивная премиум-версия, зарезервированная для наших корпоративных клиентов, с дополнительным обучением и оптимизациями. Обратите внимание, что наша первая версия <code>reader-lm-1.5b</code> оценивается только по основной задаче извлечения контента, так как она не поддерживает возможности извлечения по инструкциям или извлечения JSON.</p><h3 id=\"evaluation-metrics\">Метрики оценки</h3><p>Для задач HTML-в-Markdown мы используем семь взаимодополняющих метрик. Примечание: ↑ означает, что большее значение лучше, ↓ означает, что меньшее значение лучше</p><ul><li><strong>ROUGE-L</strong> (↑): Измеряет самую длинную общую последовательность между сгенерированным и эталонным текстом, отражая сохранение содержания и структурное сходство. Диапазон: 0-1, более высокие значения указывают на лучшее совпадение последовательностей.</li><li><strong>WER (Word Error Rate)</strong> (↓): Определяет минимальное количество правок на уровне слов, необходимых для преобразования сгенерированного текста в эталонный. Меньшие значения указывают на меньшее количество необходимых исправлений.</li><li><strong>SUB (Substitutions)</strong> (↓): Подсчитывает количество необходимых замен слов. Меньшие значения предполагают лучшую точность на уровне слов.</li><li><strong>INS (Insertions)</strong> (↓): Измеряет количество слов, которые необходимо вставить для соответствия эталону. Меньшие значения указывают на лучшую полноту.</li><li><strong>Levenshtein Distance</strong> (↓): Рассчитывает минимальное количество необходимых правок на уровне символов. Меньшие значения предполагают лучшую точность на уровне символов.</li><li><strong>Damerau-Levenshtein Distance</strong> (↓): Аналогично Levenshtein, но также учитывает перестановки символов. Меньшие значения указывают на лучшее совпадение на уровне символов.</li><li><strong>Jaro-Winkler Similarity</strong> (↑): Подчеркивает совпадение символов в начале строк, особенно полезно для оценки сохранения структуры документа. Диапазон: 0-1, более высокие значения указывают на лучшее сходство.</li></ul><p>Для задач HTML-в-JSON мы рассматриваем это как задачу поиска и используем четыре метрики из информационного поиска:</p><ul><li><strong>F1 Score</strong> (↑): Среднее гармоническое точности и полноты, обеспечивающее общую точность. Диапазон: 0-1.</li><li><strong>Precision</strong> (↑): Доля правильно извлеченной информации среди всех извлечений. Диапазон: 0-1.</li><li><strong>Recall</strong> (↑): Доля правильно извлеченной информации из всей доступной информации. Диапазон: 0-1.</li><li><strong>Pass-Rate</strong> (↑): Доля выходных данных, которые являются валидным JSON и соответствуют схеме. Диапазон: 0-1.</li></ul><h3 id=\"main-content-html-to-markdown-task\">Задача преобразования основного контента из HTML в Markdown</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.69</td>\n<td>0.62</td>\n<td>131.06</td>\n<td>372.34</td>\n<td>0.40</td>\n<td>1341.14</td>\n<td>0.74</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td>0.41</td>\n<td><strong>88.66</strong></td>\n<td><strong>88.69</strong></td>\n<td>0.40</td>\n<td>1283.54</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.71</td>\n<td>0.47</td>\n<td>158.26</td>\n<td>123.47</td>\n<td>0.41</td>\n<td>1354.33</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>reader-lm-1.5b</td>\n<td>0.72</td>\n<td>1.14</td>\n<td>260.29</td>\n<td>1182.97</td>\n<td>0.35</td>\n<td>1733.11</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.84</td>\n<td>0.62</td>\n<td>135.28</td>\n<td>867.14</td>\n<td>0.22</td>\n<td>1262.75</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.86</strong></td>\n<td><strong>0.39</strong></td>\n<td>162.92</td>\n<td>500.44</td>\n<td><strong>0.20</strong></td>\n<td><strong>928.15</strong></td>\n<td><strong>0.83</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"instructed-html-to-markdown-task\">Задача преобразования HTML в Markdown по инструкции</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.64</td>\n<td>1.64</td>\n<td>122.64</td>\n<td>533.12</td>\n<td>0.45</td>\n<td>766.62</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td><strong>0.82</strong></td>\n<td><strong>87.53</strong></td>\n<td><strong>180.61</strong></td>\n<td>0.42</td>\n<td><strong>451.10</strong></td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.68</td>\n<td>0.73</td>\n<td>98.72</td>\n<td>177.23</td>\n<td>0.43</td>\n<td>501.50</td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.70</td>\n<td>1.28</td>\n<td>75.10</td>\n<td>443.70</td>\n<td>0.38</td>\n<td>673.62</td>\n<td><strong>0.75</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.72</strong></td>\n<td>1.48</td>\n<td><strong>70.16</strong></td>\n<td>570.38</td>\n<td><strong>0.37</strong></td>\n<td>748.10</td>\n<td><strong>0.75</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"schema-based-html-to-json-task\">Задача преобразования HTML в JSON на основе схемы</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>F1↑</th>\n<th>Precision↑</th>\n<th>Recall↑</th>\n<th>Pass-Rate↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.81</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td><strong>0.83</strong></td>\n<td>0.84</td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td><strong>0.83</strong></td>\n<td><strong>0.85</strong></td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.81</td>\n<td>0.98</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td>0.82</td>\n<td>0.83</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>ReaderLM-v2</code> представляет значительный прогресс во всех задачах. Для извлечения основного контента <code>ReaderLM-v2-pro</code> достигает наилучших результатов по пяти из семи метрик, с превосходными показателями ROUGE-L (0.86), WER (0.39), Levenshtein (0.20), Damerau (928.15) и Jaro-Winkler (0.83). Эти результаты демонстрируют комплексные улучшения как в сохранении содержания, так и в структурной точности по сравнению с базовой версией и более крупными моделями.</p><p>В извлечении по инструкции <code>ReaderLM-v2</code> и <code>ReaderLM-v2-pro</code> лидируют по показателям ROUGE-L (0.72), коэффициенту замен (70.16), расстоянию Левенштейна (0.37) и сходству Джаро-Винклера (0.75, наравне с базовой версией). Хотя GPT-4o показывает преимущества в WER и расстоянии Дамерау, <code>ReaderLM-v2-pro</code> сохраняет лучшую общую структуру и точность контента. В извлечении JSON модель показывает конкурентоспособные результаты, отставая всего на 0.01-0.02 пункта F1 от более крупных моделей при достижении высоких показателей успешности (0.99).</p><h2 id=\"qualitative-evaluation\">Качественная оценка</h2><p>В ходе нашего анализаПри тестировании <code>reader-lm-1.5b</code> мы обнаружили, что <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#qualitative-study\">количественные метрики не всегда полностью отражают производительность модели</a>. Числовые оценки иногда не соответствовали визуальному качеству — были случаи, когда низкие метрические показатели давали визуально удовлетворительный markdown, или высокие показатели приводили к неоптимальным результатам. Чтобы устранить это несоответствие, мы провели систематическую качественную оценку на 10 различных HTML-источниках, включая новостные статьи, блог-посты, страницы продуктов, сайты электронной коммерции и юридические документы на английском, японском и китайском языках. Тестовый корпус включал сложные элементы форматирования, такие как многострочные таблицы, динамические макеты, формулы LaTeX, связанные таблицы и вложенные списки, что обеспечило более полное представление о возможностях модели в реальных условиях.</p><h3 id=\"evaluation-metrics-1\">Метрики оценки</h3><p>Наша человеческая оценка сфокусировалась на трех ключевых аспектах, с оценкой выходных данных по шкале от 1 до 5:</p><p><strong>Целостность контента</strong> - Оценивает сохранение семантической информации при конвертации HTML в markdown, включая:</p><ul><li>Точность и полнота текстового содержания</li><li>Сохранение ссылок, изображений, блоков кода, формул и цитат</li><li>Сохранение форматирования текста и URL ссылок/изображений</li></ul><p><strong>Структурная точность</strong> - Оценивает точность преобразования структурных элементов HTML в Markdown:</p><ul><li>Сохранение иерархии заголовков</li><li>Точность вложенности списков</li><li>Точность структуры таблиц</li><li>Форматирование блоков кода и цитат</li></ul><p><strong>Соответствие формату</strong> - Измеряет соблюдение стандартов синтаксиса Markdown:</p><ul><li>Правильное использование синтаксиса для заголовков (#), списков (*, +, -), таблиц, блоков кода (```)</li><li>Чистое форматирование без лишних пробелов или нестандартного синтаксиса</li><li>Последовательный и читаемый отображаемый результат</li></ul><p>При ручной оценке более 10 HTML-страниц максимальный балл по каждому критерию оценки составляет 50 баллов. <code>ReaderLM-v2</code> продемонстрировала высокие результаты по всем параметрам:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Content Integrity</th>\n<th>Structural Accuracy</th>\n<th>Format Compliance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>reader-lm-v2</td>\n<td>39</td>\n<td>35</td>\n<td>36</td>\n</tr>\n<tr>\n<td>reader-lm-v2-pro</td>\n<td>35</td>\n<td>37</td>\n<td>37</td>\n</tr>\n<tr>\n<td>reader-lm-v1</td>\n<td>35</td>\n<td>34</td>\n<td>31</td>\n</tr>\n<tr>\n<td>Claude 3.5 Sonnet</td>\n<td>26</td>\n<td>31</td>\n<td>33</td>\n</tr>\n<tr>\n<td>gemini-2.0-flash-expr</td>\n<td>35</td>\n<td>31</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>32</td>\n<td>33</td>\n<td>34</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>38</td>\n<td>41</td>\n<td>42</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>По полноте контента она отлично справлялась с распознаванием сложных элементов, особенно формул LaTeX, вложенных списков и блоков кода. Модель сохраняла высокую точность при обработке сложных структур контента, в то время как конкурирующие модели часто пропускали заголовки H1 (<code>reader-lm-1.5b</code>), обрезали контент (Claude 3.5) или сохраняли необработанные HTML-теги (Gemini-2.0-flash).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--92-.png\" width=\"2000\" height=\"1477\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--92-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--92-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--92-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--92-.png 2400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png\" width=\"2000\" height=\"1765\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--93--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--93--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--93--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png 2268w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><a href=\"https://iclr-blogposts.github.io/2024/blog/bench-hvp/?ref=jina-ai-gmbh.ghost.io\">Блог-пост ICLR</a> со сложными уравнениями LaTeX, встроенными в markdown, показывающий исходный HTML-код на правой панели.</p></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--94--2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1033\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--94--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--94--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--94--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--94--2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Сравнение Markdown-вывода ReaderLM-v2 с его визуализированным отображением.</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"821\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Мы можем идеально восстановить исходный контент через простые шаги постобработки после ReaderLM-v2, включая преобразование уравнений LaTeX из HTML-формата в Markdown-формат. Например, замена <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">\\[...\\]</code> (и его HTML-эквивалентов) на стандартные разделители Markdown, такие как <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">$...$</code> для встроенных уравнений и <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">$$...$$</code> для выделенных уравнений. Это помогает избежать конфликтов синтаксиса при интерпретации Markdown.</figcaption></figure><p>В структурной точности ReaderLM-v2 показала оптимизацию для распространенных веб-структур. Например, в случаях с Hacker News она успешно восстанавливала полные ссылки и оптимизировала представление списков. Модель справлялась со сложными не-блоговыми HTML-структурами, которые были проблематичны для ReaderLM-v1.</p><p>По соответствию формату ReaderLM-v2 продемонстрировала особую силу в обработке контента типа Hacker News, блогов и статей WeChat. В то время как другие большие языковые модели хорошо справлялись с markdown-подобными источниками, они испытывали трудности с традиционными веб-сайтами, требующими большей интерпретации и переформатирования.</p><p>Наш анализ показал, что <code>gpt-4o</code> отлично справляется с обработкой более коротких веб-сайтов, демонстрируя превосходное понимание структуры сайта и форматирования по сравнению с другими моделями. Однако при обработке более длинного контента <code>gpt-4o</code> испытывает трудности с полнотой, часто пропуская части в начале и конце текста. Мы включили сравнительный анализ выходных данных от <code>gpt-4o</code>, ReaderLM-v2 и ReaderLM-v2-pro на примере веб-сайта Zillow.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1382\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png 2356w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Исходная HTML-страница Zillow</figcaption></figure><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png\" width=\"1400\" height=\"1576\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--95-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--95-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png 1400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png\" width=\"1550\" height=\"1578\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png 1550w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png\" width=\"1562\" height=\"1582\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--97-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--97-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png 1562w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Сравнение rendered Markdown-выводов от gpt-4o (слева), ReaderLM-v2 (в центре) и ReaderLM-v2-pro (справа).</span></p></figcaption></figure><p>Для некоторых сложных случаев, таких как продуктовые лендинги и правительственные документы, производительность ReaderLM-v2 и ReaderLM-v2-pro оставалась надежной, но все еще есть возможности для улучшения. Сложные математические формулы и код в блог-постах ICLR представляли трудности для большинства моделей, хотя ReaderLM-v2 справлялся с этими случаями лучше, чем базовый Reader API.</p><h2 id=\"how-we-trained-readerlm-v2\">Как мы обучали ReaderLM v2</h2><p>ReaderLM-v2 построен на базе <code><strong>Qwen2.5-1.5B-Instruction</strong></code>, компактной базовой модели, известной своей эффективностью в выполнении инструкций и задач с длинным контекстом. В этом разделе мы описываем, как мы обучали <code>ReaderLM-v2</code>, фокусируясь на подготовке данных, методах обучения и встреченных проблемах.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model Parameter</th>\n<th>ReaderLM-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Parameters</td>\n<td>1.54B</td>\n</tr>\n<tr>\n<td>Max Context Length (Input+Output)</td>\n<td>512K</td>\n</tr>\n<tr>\n<td>Hidden Size</td>\n<td>1536</td>\n</tr>\n<tr>\n<td>Number of Layers</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Query Heads</td>\n<td>12</td>\n</tr>\n<tr>\n<td>KV Heads</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Head Size</td>\n<td>128</td>\n</tr>\n<tr>\n<td>Intermediate Size</td>\n<td>8960</td>\n</tr>\n<tr>\n<td>Multilingual Support</td>\n<td>29 languages</td>\n</tr>\n<tr>\n<td>HuggingFace Repository</td>\n<td>Link</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"data-preparation\">Подготовка данных</h3><p>Успех ReaderLM-v2 во многом зависел от качества тренировочных данных. Мы создали датасет <code>html-markdown-1m</code>, который включал миллион HTML-документов, собранных из интернета. В среднем каждый документ содержал 56 000 токенов, отражая длину и сложность реальных веб-данных. При подготовке этого датасета мы очистили HTML-файлы, удалив ненужные элементы, такие как JavaScript и CSS, сохранив при этом ключевые структурные и семантические элементы. После очистки мы использовали <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> для конвертации HTML-файлов в Markdown, используя регулярные выражения и эвристики.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--76-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--76-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Гистограмма длины токенов HTML-файлов в датасете </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>html-markdown-1m</span></code></figcaption></figure><p>Хотя это создало функциональный базовый датасет, это выявило критическое ограничение: <strong>модели, обученные исключительно на этих прямых преобразованиях, по сути, просто учились имитировать регулярные выражения и эвристики, используемые Jina Reader.</strong> Это стало очевидным с моделями <code>reader-lm-0.5b/1.5b</code>, чей потолок производительности был ограничен качеством этих правило-основанных преобразований.</p><p>Чтобы решить эти ограничения, мы разработали трехэтапный конвейер, основанный на модели <code>Qwen2.5-32B-Instruction</code>, который важен для создания высококачественного синтетического датасета.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--73-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--73-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Конвейер генерации синтетических данных для ReaderLM-v2, работающий на </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Qwen2.5-32B-Instruction</span></code></figcaption></figure><ol><li><strong>Черновик</strong>: Мы генерировали начальные Markdown и JSON выводы на основе предоставленных модели инструкций. Эти выводы, хотя и разнообразные, часто были шумными или непоследовательными.</li><li><strong>Уточнение</strong>: Сгенерированные черновики улучшались путем удаления избыточного контента, обеспечения структурной согласованности и приведения в соответствие с желаемыми форматами. Этот шаг обеспечивал чистоту данных и соответствие требованиям задачи.</li><li><strong>Критика</strong>: Уточненные выводы оценивались на соответствие исходным инструкциям. Только данные, прошедшие эту оценку, включались в финальный датасет. Этот итеративный подход обеспечивал соответствие тренировочных данных необходимым стандартам качества для структурированного извлечения данных.</li></ol><h3 id=\"training-process\">Процесс обучения</h3><p>Наш процесс обучения включал множество этапов, адаптированных к проблемам обработки документов с длинным контекстом.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--75-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--75-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Обучение ReaderLM v2 следует итеративному процессу, сочетающему трехэтапную генерацию данных (Черновик-Уточнение-Критика) с самообучающимся улучшением, обеспечивая непрерывное совершенствование.</span></figcaption></figure><p>Мы начали с <strong>предварительного обучения на длинном контексте</strong>, используя датасет <code>html-markdown-1m</code>. Для постепенного расширения контекстной длины модели с 32 768 токенов до 256 000 токенов использовались такие техники, как ring-zag attention и rotary positional encoding (RoPE). Для поддержания стабильности и эффективности мы приняли постепенный подход к обучению, начиная с более коротких последовательностей и постепенно увеличивая длину контекста.</p><p>После предварительного обучения мы перешли к <strong>supervised fine-tuning (SFT)</strong>. На этом этапе использовались уточненные датасеты, созданные в процессе подготовки данных. Эти датасеты включали подробные инструкции для задач извлечения Markdown и JSON, а также примеры для уточнения черновиков. Каждый датасет был тщательно разработан, чтобы помочь модели изучить конкретные задачи, такие как определение основного содержания или соблюдение структур JSON на основе схем.</p><p>Затем мы применили <strong>direct preference optimization (DPO)</strong> для приведения выводов модели в соответствие с высококачественными результатами. На этом этапе модель обучалась на парах черновых и уточненных ответов. Научившись приоритизировать уточненные выводы, модель усвоила тонкие различия, определяющие отшлифованные и специфичные для задачи результаты.</p><p>Наконец, мы внедрили <strong>самообучающуюся настройку с подкреплением</strong>, итеративный процесс, где модель генерировала, уточняла и оценивала свои собственные выводы. Этот цикл позволил модели постоянно совершенствоваться без необходимости дополнительного внешнего надзора. Используя собственные критические замечания и уточнения, модель постепенно улучшала свою способность создавать точные и структурированные выводы.</p><h2 id=\"conclusion\">Заключение</h2><p>В апреле 2024 года Jina Reader стал первым LLM-дружественным markdown API. Он задал новый тренд, получил широкое признание сообщества и, что наиболее важно, вдохновил нас на создание малых языковых моделей для очистки и извлечения данных. Сегодня мы снова поднимаем планку с ReaderLM-v2, выполняя обещания, данные в прошлом сентябре: лучшая обработка длинного контекста, поддержка входных инструкций и способность извлекать конкретное содержимое веб-страниц в формат markdown. Мы снова продемонстрировали, что при тщательном обучении и калибровке малые языковые модели могут достигать современной производительности, превосходящей более крупные модели.</p><p>В процессе обучения ReaderLM-v2 мы выявили два важных наблюдения. Одной эффективной стратегией было обучение специализированных моделей на отдельных датасетах, адаптированных под конкретные задачи. Эти специализированные по задачам модели позже <em>объединялись</em> с использованием линейной интерполяции параметров. Хотя этот подход требовал дополнительных усилий, он помог сохранить уникальные сильные стороны каждой специализированной модели в финальной объединенной системе.</p><p>Итеративный процесс синтеза данных оказался ключевым для успеха нашей модели. Благодаря многократному улучшению и оценке синтетических данных мы значительно повысили производительность модели по сравнению с простыми подходами на основе правил. Эта итеративная стратегия, хотя и представляла сложности в поддержании согласованности оценок критики и управлении вычислительными затратами, была необходима для преодоления ограничений использования обучающих данных на основе регулярных выражений и эвристик из Jina Reader. Это наглядно демонстрируется разницей в производительности между <code>reader-lm-1.5b</code>, которая сильно полагается на преобразования на основе правил Jina Reader, и <code>ReaderLM-v2</code>, которая выигрывает от этого итеративного процесса улучшения.</p><p>Мы с нетерпением ждем ваших отзывов о том, как ReaderLM-v2 улучшает качество ваших данных. В дальнейшем мы планируем расширить мультимодальные возможности, особенно для сканированных документов, и дополнительно оптимизировать скорость генерации. Если вы заинтересованы в получении специальной версии ReaderLM, адаптированной под вашу конкретную область, пожалуйста, свяжитесь с нами.</p>",
  "comment_id": "6785bfd62defad0001fb5f22",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/readerlm-v2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-01-14T02:37:26.000+01:00",
  "updated_at": "2025-01-15T11:35:18.000+01:00",
  "published_at": "2025-01-15T11:35:18.000+01:00",
  "custom_excerpt": "ReaderLM-v2 is a 1.5B small language model for HTML-to-Markdown conversion and HTML-to-JSON extraction with exceptional accuracy.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json/",
  "excerpt": "ReaderLM-v2 — это небольшая языковая модель размером 1.5B, предназначенная для конвертации HTML в Markdown и извлечения данных из HTML в JSON с исключительной точностью.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}