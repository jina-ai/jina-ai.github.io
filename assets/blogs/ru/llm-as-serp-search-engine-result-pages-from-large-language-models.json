{
  "slug": "llm-as-serp-search-engine-result-pages-from-large-language-models",
  "id": "67c02c3b343c560001efca6e",
  "uuid": "ec03076e-dc8a-44ea-bd09-57c5e6a6d593",
  "title": "LLM как SERP: страницы результатов поиска на основе больших языковых моделей",
  "html": "<figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/llm-serp-demo\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">LLM as SERP</div><div class=\"kg-bookmark-description\">Large language model as search result page</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">LLMSERP</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-llm-serp.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">Попробуйте интерактивную демонстрацию и посмотрите, как ваш сайт отображается в LLM SERP.</span></p></figcaption></figure><p>С момента появления RAG тенденция заключается в использовании LLM для улучшения поиска. От Perplexity до DeepSearch и DeepResearch, идея внедрения результатов поисковой системы в процесс генерации стала де-факто стандартом. Многие пользователи также утверждают, что они больше не используют Google так часто, как раньше, считая его классический дизайн с пагинацией скучным, перегруженным или утомительным. Вместо этого они привыкли к высокой точности и полноте результатов в формате вопросов-ответов из поискового интерфейса в стиле чата, что говорит о том, что эта философия дизайна может быть правильным путем вперед.</p><p><strong>Но что, если сама LLM <em>является</em> поисковой системой?</strong> </p><p>Что, если бы вы могли исследовать знания, встроенные в LLM, как будто вы используете Google? Пагинация, ссылки и всё остальное - как в старые добрые времена, к которым вы привыкли. Если вы не уверены, что я имею в виду, сначала посмотрите демонстрацию ниже.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp.mp4\" poster=\"https://img.spacergif.org/v1/1426x976/0a/spacer.png\" width=\"1426\" height=\"976\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Ссылки, заголовки и сниппеты полностью сгенерированы LLM. Вы можете посетить </span><a href=\"https://jina.ai/llm-serp-demo\"><span style=\"white-space: pre-wrap;\">https://jina.ai/llm-serp-demo</span></a><span style=\"white-space: pre-wrap;\"> и попробовать некоторые запросы самостоятельно! </span></p></figcaption>\n        </figure><p>Прежде чем поднимать вопросы о галлюцинациях, давайте сначала объясним, почему эта идея имеет <em>некоторые</em> достоинства: LLM обучены на огромных хранилищах веб-знаний. Модели как DeepSeek-R1, GPT-4, Claude-3.7 и Gemini-2.0 были обучены на триллионах токенов со всего публичного интернета. По грубым оценкам, <strong>от &lt;1% до ~5% высококачественного, публично доступного веб-текста</strong> было использовано для обучения ведущих моделей.</p><p>Если вам кажется, что это число слишком мало, рассмотрите такое сравнение: если мы используем индекс Google как эталон (представляющий 100% пользовательских данных в мире), то индекс Bing составляет примерно 30-50% от Google. Baidu охватывает около 5-10%, а Yandex - 3-5%. Brave Search индексирует менее 1%. Так что если LLM обучена на 1-5% качественных публичных данных, это потенциально равно тому же объему данных, который может предоставить decent небольшая поисковая система.</p><p>Поскольку эти модели эффективно \"запомнили\" эти веб-данные, нам просто нужно подсказать им таким образом, чтобы \"активировать\" их память, позволяя им функционировать как поисковые системы и генерировать результаты, подобные странице результатов поисковой системы (SERP).</p><p>Так что да, галлюцинации - это проблема, но по мере улучшения возможностей моделей с каждой итерацией мы можем разумно ожидать, что эта проблема уменьшится. В X люди часто одержимы генерацией SVG с нуля каждый раз, когда выпускается новая модель, надеясь, что каждая версия создает лучшие иллюстрации, чем предыдущая. Эта идея поисковой системы следует аналогичной надежде на постепенное улучшение понимания цифрового мира LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1176\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/02/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://x.com/huybery/status/1893996258760527882\"><span style=\"white-space: pre-wrap;\">Binyuan Hui </span></a><span style=\"white-space: pre-wrap;\">(один из основных разработчиков моделей Qwen) демонстрирует способность </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>qwen-2.5-max</span></code><span style=\"white-space: pre-wrap;\"> рисовать SVG свиньи в один проход.</span></figcaption></figure><p>Даты отсечения знаний представляют еще одно ограничение. Поисковые системы должны возвращать информацию практически в реальном времени, но поскольку веса LLM заморожены после обучения, они не могут предоставлять точную информацию после даты отсечения. Как правило, чем ближе запрос к этой дате отсечения, тем вероятнее становятся галлюцинации. Поскольку более старая информация, вероятно, чаще цитировалась и перефразировалась, потенциально увеличивая ее веса в обучающих данных. (Это предполагает, что информация взвешивается равномерно; последние новости могут получать непропорциональное внимание независимо от новизны.) <strong>Однако это ограничение фактически определяет именно то, где этот подход может быть наиболее полезным — для информации, которая хорошо вписывается во временные рамки знаний модели.</strong></p><h2 id=\"where-llm-as-serp-can-be-useful\">Где LLM-как-SERP может быть полезным?</h2><p>В DeepSearch/RAG или любых системах с поисковым заземлением основная проблема заключается в определении того, нужна ли вопросу внешняя информация или на него можно ответить из знаний модели. Текущие системы обычно используют маршрутизацию на основе промптов с инструкциями типа:</p><pre><code>- For greetings, casual conversation, or general knowledge questions, answer directly without references.\n- For all other questions, provide a verified answer with external knowledge. Each reference must include exactQuote and url.</code></pre><p>Этот подход терпит неудачу в обоих направлениях - иногда вызывая ненужные поиски, а иногда пропуская критически важные потребности в информации. Особенно с новыми моделями рассуждений часто не очевидно до середины генерации, нужны ли внешние данные.</p><p>Что если бы мы просто в любом случае выполняли поиск? Мы могли бы сделать один запрос к реальному поисковому API и другой к системе LLM-как-поиск. Это устраняет необходимость принятия решения о маршрутизации заранее и переносит его ниже по потоку, где у нас есть фактические результаты для сравнения - недавние данные из реального поиска, знания в пределах даты отсечения модели и потенциально некоторая неверная информация.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/Heading--41-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p>Затем на финальном этапе рассуждений можно выявить несоответствия и оценить источники на основе их актуальности, надежности и согласованности между результатами, что нам не нужно явно программировать — это то, в чем LLM уже преуспевают. Также можно посетить каждый URL в результатах поиска (например, с помощью Jina Reader) для дополнительной проверки источников. В практических реализациях этот шаг проверки всегда необходим в любом случае; никогда не следует полагаться исключительно на выдержки из поисковых систем, независимо от того, реальные они или фиктивные.</p><h2 id=\"conclusion\">Заключение</h2><p>Используя LLM-as-SERP, <strong>мы преобразуем бинарный вопрос \"находится ли это в пределах знаний модели или нет?\" в более надежный процесс взвешивания доказательств.</strong></p><p>Мы предоставляем <a href=\"https://jina.ai/llm-serp-demo\" rel=\"noreferrer\">площадку для экспериментов</a>, а также <a href=\"https://jina.ai/api-dashiboard/llm-serp\" rel=\"noreferrer\">API-endpoint, размещенный нами</a>, с которым вы можете экспериментировать. Также не стесняйтесь интегрировать его в свои собственные реализации DeepSearch/DeepResearch, чтобы лично увидеть любые улучшения.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/node-serp\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/node-serp: LLMs-as-SERPs</div><div class=\"kg-bookmark-description\">LLMs-as-SERPs. Contribute to jina-ai/node-serp development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-3.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/node-serp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>API имитирует полноценную конечную точку SERP, где вы можете определить количество результатов, пагинацию, страну, язык и т.д. Вы можете найти его реализацию на GitHub. Мы с нетерпением ждем ваших отзывов об этом интересном подходе.</p>",
  "comment_id": "67c02c3b343c560001efca6e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/llmserp-banner.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-02-27T10:11:23.000+01:00",
  "updated_at": "2025-02-27T13:38:43.000+01:00",
  "published_at": "2025-02-27T13:36:57.000+01:00",
  "custom_excerpt": "This is either an extremely smart idea or an extremely stupid one—there's no in-between.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/llm-as-serp-search-engine-result-pages-from-large-language-models/",
  "excerpt": "Это либо очень умная идея, либо очень глупая — середины тут нет.",
  "reading_time": 5,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}