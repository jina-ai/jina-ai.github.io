{
  "slug": "a-practical-guide-to-implementing-deepsearch-deepresearch",
  "id": "67bc50b0b1b8af00014db4c9",
  "uuid": "acd44dc0-e356-4ac8-93c7-fa8bbeb33265",
  "title": "Практическое руководство по внедрению DeepSearch/DeepResearch",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://search.jina.ai/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI Deep Search</div><div class=\"kg-bookmark-description\">AI глубокий поиск: читает, рассуждает, ищет до нахождения лучшего ответа.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-30.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Всего лишь февраль, а DeepSearch уже стал новым стандартом поиска в 2025 году, где лидируют такие крупные игроки, как <a href=\"https://blog.google/products/gemini/google-gemini-deep-research/\">Google</a> и <a href=\"https://openai.com/index/introducing-deep-research/\">OpenAI</a> со своими релизами DeepResearch (и да, <a href=\"https://x.com/hxiao/status/1886250705415229627\">мы с гордостью запустили наш открытый <code>node-deepresearch</code> в тот же день</a>). <a href=\"https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research\">Perplexity</a> последовал их примеру со своим DeepResearch, а X AI интегрировал собственные возможности DeepSearch в <a href=\"https://x.ai/blog/grok-3\">Grok3</a>, по сути создав еще один вариант DeepResearch. Хотя концепция глубокого поиска не революционна – в 2024 году это по сути называлось RAG или многоэтапный QA – она получила значительный импульс после релиза <a href=\"https://github.com/deepseek-ai/DeepSeek-R1\">Deepseek-r1</a> в конце января 2025 года. В прошлые выходные <a href=\"https://www.scmp.com/tech/big-tech/article/3298981/baidu-adopts-deepseek-ai-models-chasing-tencent-race-embrace-hot-start\">Baidu Search и Tencent WeChat Search</a> интегрировали Deepseek-r1 в свои поисковые системы. AI-инженеры обнаружили, что, включая процессы длительного размышления и рассуждения в поисковые системы, они могут достичь замечательной точности и глубины поиска, превосходящей прежние возможности.</p>\n\n<!--kg-card-begin: html-->\n<table> <thead> <tr> <th>Launch Date</th> <th>Company</th> <th>Product</th> <th>License Type</th> <th>Link</th> </tr> </thead> <tbody> <tr> <td>2025-01-20</td> <td>DeepSeek</td> <td>DeepSeek-r1 release</td> <td>Open source</td> <td><a href=\"https://api-docs.deepseek.com/news/news250120\">DeepSeek-R1</a></td> </tr> <tr> <td>2025-02-02</td> <td>Google</td> <td>DeepResearch</td> <td>Proprietary</td> <td><a href=\"https://blog.google/products/gemini/google-gemini-deep-research/\">Google Gemini 2</a></td> </tr> <tr> <td>2025-02-02</td> <td>OpenAI</td> <td>DeepResearch</td> <td>Proprietary</td> <td><a href=\"https://openai.com/index/introducing-deep-research/\">Introducing Deep Research</a></td> </tr> <tr> <td>2025-02-02</td> <td>Jina AI</td> <td>DeepSearch (<code>node-deepresearch</code>)</td> <td>Open source</td> <td><a href=\"https://github.com/jina-ai/node-deepresearch\">node-deepresearch</a> | <a href=\"https://search.jina.ai\">search.jina.ai</a></td> </tr> <tr> <td>2025-02-04</td> <td>Hugging Face</td> <td>Open Deep Research</td> <td>Open source</td> <td><a href=\"https://huggingface.co/blog/open-deep-research\">Open Deep Research</a></td> </tr> <tr> <td>2025-02-15</td> <td>Perplexity</td> <td>DeepResearch</td> <td>Proprietary</td> <td><a href=\"https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research\">Introducing Perplexity Deep Research</a></td> </tr> <tr> <td>2025-02-17</td> <td>X AI</td> <td>Grok3 with DeepSearch</td> <td>Proprietary</td> <td><a href=\"https://x.ai/blog/grok-3\">Grok 3 Beta</a></td> </tr> <tr> <td>2025-02-22</td> <td>Baidu Search</td> <td>Integrates DeepSeek-r1</td> <td>Proprietary</td> <td><a href=\"https://chat.baidu.com/search?isShowHello=1&pd=csaitab&setype=csaitab&extParamsJson=%7B%22enter_type%22%3A%22ai_explore_home%22%7D&usedModel=%7B%22modelName%22%3A%22DeepSeek-R1%22%7D\">Baidu Integrates DeepSeek-R1</a></td> </tr> <tr> <td>2025-02-23</td> <td>Tencent Wechat Search</td> <td>Integrates DeepSeek-r1</td> <td>Proprietary</td> <td><a href=\"https://www.reuters.com/technology/artificial-intelligence/tencents-messaging-app-weixin-launches-beta-testing-with-deepseek-2025-02-16/\">Tencent Weixin Integrates DeepSeek</a></td> </tr> </tbody> </table>\n<!--kg-card-end: html-->\n\n<p>Но почему этот сдвиг произошел именно сейчас, когда Deep(Re)Search оставался относительно недооцененным на протяжении 2024 года? Фактически, <a href=\"https://storm-project.stanford.edu/research/storm/\">Stanford NLP Labs выпустили проект STORM</a> для генерации длинных отчетов с веб-обоснованием еще в начале 2024 года. Так может быть это просто потому, что \"DeepSearch\" звучит круче, чем многоэтапный QA, RAG или STORM? Давайте будем честны - иногда ребрендинг это все, что нужно, чтобы индустрия внезапно приняла то, что было здесь всё время.</p><p>Мы считаем, что настоящий переломный момент наступил с релизом <code>o1-preview</code> от OpenAI в сентябре 2024 года, который ввел концепцию <strong>тестового времени вычислений</strong> и постепенно изменил взгляды индустрии. Тестовое время вычислений относится к использованию большего количества вычислительных ресурсов во время вывода — фазы, когда LLM генерирует выходные данные — а не во время предварительного обучения или после обучения. Известными примерами являются рассуждения по цепочке мыслей (CoT) и <a href=\"https://github.com/simplescaling/s1?tab=readme-ov-file#vllm-with-budget-forcing\">внедрение <code>\"Wait\"</code></a> (т.е. принудительное бюджетирование), что позволяет моделям выполнять более обширные внутренние размышления, такие как оценка нескольких потенциальных ответов, проведение более глубокого планирования и самоанализ перед получением окончательного ответа.</p><p>Эта концепция тестового времени вычислений и модели рассуждений <strong><em>обучают</em></strong> пользователей принимать <a href=\"https://en.wikipedia.org/wiki/Delayed_gratification\">отложенное вознаграждение</a> - более длительное время ожидания в обмен на более качественные, сразу применимые результаты, как в Стэнфордском зефирном эксперименте, где дети, которые могли устоять перед соблазном съесть один зефир сразу, чтобы получить два зефира позже, показывали лучшие долгосрочные результаты. Deepseek-r1 дополнительно усилил этот пользовательский опыт, и, нравится это или нет, большинство пользователей его приняли.</p><p>Это знаменует значительный отход от классических требований к поиску, где неспособность ответить в течение 200 мс обрекала ваше решение на провал. В 2025 году опытные разработчики поисковых систем и RAG-инженеры отдают приоритет точности и полноте top-1 над задержкой, а пользователи привыкли к более длительному времени обработки – при условии, что они видят, что система <code>&lt;thinking&gt;</code>.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/think-ui-1_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/think-ui-1.mp4\" poster=\"https://img.spacergif.org/v1/1610x1422/0a/spacer.png\" width=\"1610\" height=\"1422\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/think-ui-1_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Воспроизвести видео\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Воспроизвести видео\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Приостановить видео\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:18</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Настроить скорость воспроизведения\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Включить звук\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Отображение процесса рассуждения стало стандартной практикой в 2025 году, когда множество чат-интерфейсов теперь отображают содержимое </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>&lt;think&gt;</span></code><span style=\"white-space: pre-wrap;\"> в специальных разделах пользовательского интерфейса.</span></p></figcaption>\n        </figure><p>В этой статье мы обсудим принципы DeepSearch и DeepResearch, рассмотрев нашу реализацию с открытым исходным кодом. Мы рассмотрим наши ключевые проектные решения и отметим потенциальные проблемы.</p><h2 id=\"what-is-deep-search\">Что такое Deep Search?</h2><p><strong>DeepSearch выполняет итеративный цикл поиска, чтения и рассуждения, пока не найдет оптимальный ответ.</strong> Действие поиска использует поисковые системы для исследования интернета, в то время как действие чтения детально анализирует конкретные веб-страницы (например, <a href=\"https://jina.ai/reader\" rel=\"noreferrer\">Jina Reader</a>). Действие рассуждения оценивает текущее состояние и определяет, следует ли разбить исходный вопрос на более мелкие подвопросы или попробовать другие стратегии поиска.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"561\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/image.png 2240w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">DeepSearch - продолжает поиск, чтение веб-страниц, рассуждение, пока не будет найден ответ (или не будет превышен лимит токенов).</span></figcaption></figure><p>Хотя в интернете существуют различные определения, при разработке проекта <code>node-deepresearch</code> мы придерживались этого простого подхода. Реализация элегантно проста – в её основе лежит основной цикл while с логикой switch-case, направляющей следующее действие.</p><p>В отличие от систем RAG 2024 года, которые обычно выполняют один проход поиска-генерации, DeepSearch выполняет несколько итераций через конвейер, требуя четких условий остановки. Они могут быть основаны на ограничениях использования токенов или количестве неудачных попыток.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepsearch-dark-1_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepsearch-dark-1.mp4\" poster=\"https://img.spacergif.org/v1/1238x1300/0a/spacer.png\" width=\"1238\" height=\"1300\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepsearch-dark-1_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:36</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"832\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-1.png 2268w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">DeepSearch как строительный блок DeepResearch. Итеративное построение каждого раздела с помощью DeepSearch и последующее улучшение общей согласованности перед созданием финального длинного отчета.</span></figcaption></figure><p>В нашем проекте \"Research\" 2024 года мы выполняли множество проходов по улучшению согласованности, при этом каждая итерация учитывала все остальные разделы. Однако с сегодняшними значительно большими окнами контекста LLM этот подход кажется избыточным – достаточно одного прохода по улучшению согласованности.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepresearch_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepresearch.mp4\" poster=\"https://img.spacergif.org/v1/2940x1660/0a/spacer.png\" width=\"2940\" height=\"1660\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepresearch_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:40</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Наш летний проект 2024 года \"Research\" был сосредоточен на генерации длинных отчетов с использованием \"прогрессивного\" подхода. Он начинался с создания оглавления в режиме </span><b><strong style=\"white-space: pre-wrap;\">sync</strong></b><span style=\"white-space: pre-wrap;\">, затем все разделы генерировались параллельно в режиме </span><b><strong style=\"white-space: pre-wrap;\">async</strong></b><span style=\"white-space: pre-wrap;\">. Процесс завершался </span><b><strong style=\"white-space: pre-wrap;\">async</strong></b><span style=\"white-space: pre-wrap;\"> прогрессивными ревизиями каждого раздела, при этом каждая ревизия учитывала содержание всех остальных разделов. Запрос в видео: </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>\"Competitor analysis of Jina AI\"</span></code><span style=\"white-space: pre-wrap;\">.</span></p></figcaption>\n        </figure><h2 id=\"deepsearch-vs-deepresearch\">DeepSearch vs DeepResearch</h2><p>Хотя многие часто путают DeepSearch и DeepResearch, на наш взгляд, они решают совершенно разные задачи. DeepSearch функционирует как атомарный строительный блок – базовый компонент, на котором строится DeepResearch. DeepResearch, в свою очередь, <strong>фокусируется на создании качественных, читабельных исследовательских отчетов большого объема</strong>, что включает в себя другой набор требований: включение эффективных визуализаций через графики и таблицы, структурирование контента с помощью соответствующих заголовков разделов, обеспечение плавного логического перехода между подразделами, поддержание единообразной терминологии во всем документе, устранение избыточности между разделами, создание плавных переходов, связывающих предыдущий и будущий контент. Эти элементы в значительной степени не связаны с базовым поиском, поэтому мы считаем DeepSearch более интересным как основной фокус нашей компании.</p><p>Наконец, таблица ниже обобщает различия между DeepSearch и DeepResearch. Стоит отметить, что обе системы значительно выигрывают от использования моделей с длинным контекстом и способностью к рассуждению. Это может показаться неинтуитивным, особенно для DeepSearch – хотя очевидно, почему DeepResearch нуждается в возможности работы с длинным контекстом (поскольку он создает длинные отчеты). Причина в том, что DeepSearch должен хранить предыдущие попытки поиска и содержимое веб-страниц для принятия обоснованных решений о следующих шагах, что делает длинное окно контекста одинаково важным для его эффективной реализации.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>DeepSearch</th>\n<th>DeepResearch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Problem Addressed</strong></td>\n<td>Information accuracy and completeness through iterative search</td>\n<td>Content organization, coherence, and readability at document scale</td>\n</tr>\n<tr>\n<td><strong>Final Presentation</strong></td>\n<td>Concise answer with URLs as references</td>\n<td>A long structured report with multiple sections, charts, tables and references</td>\n</tr>\n<tr>\n<td><strong>Core Complexity</strong></td>\n<td>State machine architecture with clear transition conditions; Persistence through failed attempts until resolution</td>\n<td>Multi-level architecture managing both micro (search) and macro (document) concerns; Structural approach to managing complex information hierarchies</td>\n</tr>\n<tr>\n<td><strong>Optimization Focus</strong></td>\n<td>Local optimization (best next search/read action)</td>\n<td>Global optimization (section organization, terminology consistency, transitions)</td>\n</tr>\n<tr>\n<td><strong>Limitations</strong></td>\n<td>Bounded by search quality and reasoning capability</td>\n<td>Bounded by DeepSearch quality plus organizational complexity and narrative coherence challenges</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"understand-deepsearch-implementation\">Понимание реализации DeepSearch</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/node-DeepResearch\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/node-DeepResearch: Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget)</div><div class=\"kg-bookmark-description\">Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget) - jina-ai/node-DeepResearch</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-2.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/0921e515-0139-4540-bca4-52042b49328c\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Сердце DeepResearch заключается в его подходе к циклическим рассуждениям. Вместо попытки ответить на вопросы за один проход, как большинство RAG-систем, мы реализовали итеративный цикл, который постоянно ищет информацию, читает соответствующие источники и рассуждает, пока не найдет ответ или не исчерпает бюджет токенов. Вот упрощенная суть этого большого цикла while:</p><pre><code class=\"language-typescript\">// Main reasoning loop\nwhile (tokenUsage &lt; tokenBudget &amp;&amp; badAttempts &lt;= maxBadAttempts) {\n  // Track progression\n  step++; totalStep++;\n  \n  // Get current question from gaps queue or use original question\n  const currentQuestion = gaps.length &gt; 0 ? gaps.shift() : question;\n  \n  // Generate prompt with current context and allowed actions\n  system = getPrompt(diaryContext, allQuestions, allKeywords, \n                    allowReflect, allowAnswer, allowRead, allowSearch, allowCoding,\n                    badContext, allKnowledge, unvisitedURLs);\n  \n  // Get LLM to decide next action\n  const result = await LLM.generateStructuredResponse(system, messages, schema);\n  thisStep = result.object;\n  \n  // Execute the selected action (answer, reflect, search, visit, coding)\n  if (thisStep.action === 'answer') {\n    // Process answer action...\n  } else if (thisStep.action === 'reflect') {\n    // Process reflect action...\n  } // ... and so on for other actions\n}\n</code></pre><p>Ключевая деталь реализации — выборочное отключение определенных действий на каждом шаге для обеспечения более стабильного структурированного вывода. Например, если в памяти нет URL-адресов, мы отключаем действие <code>visit</code>; или если последний ответ был отклонен, мы не позволяем агенту сразу же снова вызывать <code>answer</code>. <strong>Это ограничение удерживает агента на продуктивном пути, избегая повторяющихся ошибок, вызванных вызовом одного и того же действия.</strong></p><h3 id=\"system-prompt\">Системный промпт</h3><p>Мы используем XML-теги для определения разделов, что обеспечивает более надежный системный промпт и генерации. Мы также обнаружили, что размещение ограничений полей непосредственно внутри полей <code>description</code> JSON-схемы дает лучшие результаты. Хотя некоторые могут утверждать, что большинство промптов можно автоматизировать с помощью моделей рассуждений, таких как DeepSeek-R1, ограничения по длине контекста и необходимость в высокоспецифичном поведении делают явный подход более надежным на практике.</p><pre><code class=\"language-typescript\">function getPrompt(params...) {\n  const sections = [];\n  \n  // Add header with system instruction\n  sections.push(\"You are an advanced AI research agent specialized in multistep reasoning...\");\n  \n  // Add accumulated knowledge section if exists\n  if (knowledge?.length) {\n    sections.push(\"&lt;knowledge&gt;[Knowledge items]&lt;/knowledge&gt;\");\n  }\n  \n  // Add context of previous actions\n  if (context?.length) {\n    sections.push(\"&lt;context&gt;[Action history]&lt;/context&gt;\");\n  }\n  \n  // Add failed attempts and learned strategies\n  if (badContext?.length) {\n    sections.push(\"&lt;bad-attempts&gt;[Failed attempts]&lt;/bad-attempts&gt;\");\n    sections.push(\"&lt;learned-strategy&gt;[Improvement strategies]&lt;/learned-strategy&gt;\");\n  }\n  \n  // Define available actions based on current state\n  sections.push(\"&lt;actions&gt;[Available action definitions]&lt;/actions&gt;\");\n  \n  // Add response format instruction\n  sections.push(\"Respond in valid JSON format matching exact JSON schema.\");\n  \n  return sections.join(\"\\n\\n\");\n}\n</code></pre><h3 id=\"gap-questions-traversing\">Обход пробелов в вопросах</h3><p>В DeepSearch \"gap questions\" представляют собой пробелы в знаниях, которые необходимо заполнить перед ответом на основной вопрос. Вместо того чтобы напрямую решать исходный вопрос, агент определяет подвопросы, которые построят необходимый фундамент знаний.</p><p>Дизайн особенно элегантен в том, как он обрабатывает эти пробельные вопросы:</p><pre><code class=\"language-typescript\">// After identifying gap questions in reflect action\nif (newGapQuestions.length &gt; 0) {\n  // Add new questions to the front of the queue\n  gaps.push(...newGapQuestions);\n  \n  // Always add original question to the end of the queue\n  gaps.push(originalQuestion);\n}\n</code></pre><p>Этот подход создает очередь FIFO (First-In-First-Out) с ротацией, где:</p><ol><li>Новые пробельные вопросы помещаются в начало очереди</li><li>Исходный вопрос всегда помещается в конец</li><li>Система берет вопросы из начала очереди на каждом шаге</li></ol><p>Преимущество этого дизайна в том, что он поддерживает единый общий контекст для всех вопросов. Когда на пробельный вопрос получен ответ, эти знания сразу становятся доступными для всех последующих вопросов, включая момент, когда мы в итоге возвращаемся к исходному вопросу.</p><h4 id=\"fifo-queue-vs-recursion\">Очередь FIFO vs Рекурсия</h4><p>Альтернативный подход использует рекурсию, что соответствует поиску в глубину. Каждый пробельный вопрос порождает новый рекурсивный вызов со своим изолированным контекстом. Система должна полностью разрешить каждый пробельный вопрос (и все его потенциальные подвопросы) перед возвратом к родительскому вопросу.</p><p>Рассмотрим этот пример сценария:</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/dfs_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/dfs.mp4\" poster=\"https://img.spacergif.org/v1/950x846/0a/spacer.png\" width=\"950\" height=\"846\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/dfs_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:23</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Простая рекурсия пробельных вопросов глубиной 3, порядок решения отмечен на круге.</span></p></figcaption>\n        </figure><p>В рекурсивном подходе система должна была бы полностью разрешить Q1 (потенциально порождая свои собственные подвопросы) после каждого пробельного вопроса и их подвопросов! Это сильно отличается от подхода с очередью, который обрабатывает вопросы так, что Q1 пересматривается сразу после 3 пробельных вопросов.</p><p>На практике мы обнаружили, что рекурсивный подход очень сложно применять для принудительного ограничения бюджета, поскольку нет четкого правила для определения, какой токеновый бюджет мы должны выделить для подвопросов (так как они могут порождать новые подвопросы). Преимущество от четкого разделения контекста в рекурсивном подходе очень незначительно по сравнению с проблемами сложного принудительного бюджетирования и позднего возврата. Этот дизайн очереди FIFO балансирует глубину и ширину, гарантируя, что система всегда возвращается к исходному вопросу с постепенно улучшающимися знаниями, а не теряется в потенциально бесконечном рекурсивном спуске.</p><h3 id=\"query-rewrite\">Переписывание запросов</h3><p>Интересная проблема, с которой мы столкнулись, заключалась в эффективном переписывании поисковых запросов:</p><pre><code class=\"language-typescript\">// Within search action handler\nif (thisStep.action === 'search') {\n  // Deduplicate search requests\n  const uniqueRequests = await dedupQueries(thisStep.searchRequests, existingQueries);\n  \n  // Rewrite natural language queries into more effective search queries\n  const optimizedQueries = await rewriteQuery(uniqueRequests);\n  \n  // Ensure we don't repeat previous searches\n  const newQueries = await dedupQueries(optimizedQueries, allKeywords);\n  \n  // Execute searches and store results\n  for (const query of newQueries) {\n    const results = await searchEngine(query);\n    if (results.length &gt; 0) {\n      storeResults(results);\n      allKeywords.push(query);\n    }\n  }\n}\n</code></pre><p>Переписывание запросов оказалось удивительно важным — возможно, одним из наиболее критических элементов, которые напрямую определяют качество результатов. Хороший переписыватель запросов не просто преобразует естественный язык в ключевые слова в стиле BM25; он расширяет запросы, чтобы охватить больше потенциальных ответов на разных языках, с разными тональностями и форматами контента.</p><p>Для дедупликации запросов мы изначально использовали решение на основе LLM, но обнаружили, что сложно контролировать порог подобия. В итоге мы переключились на <code>jina-embeddings-v3</code>, который отлично справляется с задачами семантического текстового сходства. Это позволяет выполнять межъязыковую дедупликацию без беспокойства о том, что неанглийские запросы будут отфильтрованы. Модель эмбеддингов оказалась критически важной не для извлечения из памяти, как ожидалось изначально, а для эффективной дедупликации.</p><h3 id=\"crawling-web-content\">Обход веб-контента</h3><p>Веб-скрейпинг и обработка контента - еще один критически важный компонент. Здесь мы используем <a href=\"https://jina.ai/reader\" rel=\"noreferrer\">Jina Reader API</a>. Обратите внимание, что помимо полного содержимого веб-страницы, мы также агрегируем все сниппеты, полученные из поисковой системы, как дополнительные знания для последующих выводов агента. Думайте о них как о звуковых фрагментах.</p><pre><code class=\"language-typescript\">// Visit action handler\nasync function handleVisitAction(URLs) {\n  // Normalize URLs and filter out already visited ones\n  const uniqueURLs = normalizeAndFilterURLs(URLs);\n  \n  // Process each URL in parallel\n  const results = await Promise.all(uniqueURLs.map(async url =&gt; {\n    try {\n      // Fetch and extract content\n      const content = await readUrl(url);\n      \n      // Store as knowledge\n      addToKnowledge(`What is in ${url}?`, content, [url], 'url');\n      \n      return {url, success: true};\n    } catch (error) {\n      return {url, success: false};\n    } finally {\n      visitedURLs.push(url);\n    }\n  }));\n  \n  // Update diary based on success or failure\n  updateDiaryWithVisitResults(results);\n}\n</code></pre><p>Мы нормализовали URL для последовательного отслеживания и ограничили количество посещаемых URL на каждом шаге для управления памятью агента.</p><h3 id=\"memory-management\">Управление памятью</h3><p>Ключевая проблема в многошаговых рассуждениях - эффективное управление памятью агента. Мы разработали систему памяти, которая различает \"память\" и \"знания\". В любом случае, все они являются частью контекста промпта LLM, разделенного различными XML-тегами:</p><pre><code class=\"language-typescript\">// Add knowledge item to accumulated knowledge\nfunction addToKnowledge(question, answer, references, type) {\n  allKnowledge.push({\n    question: question,\n    answer: answer,\n    references: references,\n    type: type,  // 'qa', 'url', 'coding', 'side-info'\n    updated: new Date().toISOString()\n  });\n}\n\n// Record step in narrative diary\nfunction addToDiary(step, action, question, result, evaluation) {\n  diaryContext.push(`\nAt step ${step}, you took **${action}** action for question: \"${question}\"\n[Details of what was done and results]\n[Evaluation if applicable]\n`);\n}\n</code></pre><p>Поскольку большинство LLM 2025 года имеют значительные контекстные окна, мы решили не использовать векторные базы данных. Вместо этого память состоит из приобретенных знаний, посещенных сайтов и записей о неудачных попытках - все это сохраняется в контексте. Эта комплексная система памяти дает агенту понимание того, что он знает, что он пробовал и что работало или не работало.</p><h3 id=\"answer-evaluation\">Оценка ответов</h3><p>Один из ключевых выводов заключается в том, что генерация ответа и его оценка не должны находиться в одном промпте. В моей реализации мы сначала определяем критерии оценки при поступлении нового вопроса, а затем оцениваем каждый критерий по отдельности. Оценщик использует few-shot примеры для последовательной оценки, обеспечивая более высокую надежность, чем самооценка.</p><pre><code class=\"language-typescript\">// Separate evaluation phase\nasync function evaluateAnswer(question, answer, metrics, context) {\n  // First, identify evaluation criteria based on question type\n  const evaluationCriteria = await determineEvaluationCriteria(question);\n  \n  // Then evaluate each criterion separately\n  const results = [];\n  for (const criterion of evaluationCriteria) {\n    const result = await evaluateSingleCriterion(criterion, question, answer, context);\n    results.push(result);\n  }\n  \n  // Determine if answer passes overall evaluation\n  return {\n    pass: results.every(r =&gt; r.pass),\n    think: results.map(r =&gt; r.reasoning).join('\\n')\n  };\n}\n</code></pre><h3 id=\"budget-forcing\">Принудительное бюджетирование</h3><p>Принудительное бюджетирование означает предотвращение раннего возврата системы и обеспечение продолжения обработки до превышения бюджета. После выпуска DeepSeek-R1 подход к принудительному бюджетированию сместился в сторону <strong>поощрения более глубокого мышления для получения лучших результатов, а не просто экономии бюджета.</strong></p><p>В нашей реализации мы явно настроили систему на выявление пробелов в знаниях перед попыткой ответить.</p><pre><code class=\"language-typescript\">if (thisStep.action === 'reflect' &amp;&amp; thisStep.questionsToAnswer) {\n  // Force deeper reasoning by adding sub-questions to the queue\n  gaps.push(...newGapQuestions);\n  gaps.push(question);  // Always revisit the original\n}</code></pre><p>Выборочно включая и отключая определенные действия, мы можем направлять систему к использованию инструментов, которые повышают глубину рассуждений.</p><pre><code class=\"language-typescript\">// After a failed answer attempt\nallowAnswer = false;  // Force agent to search or reflect instead</code></pre><p>Чтобы избежать траты токенов на непродуктивные пути, мы устанавливаем ограничения на количество неудачных попыток. При приближении к лимитам бюджета мы активируем \"режим зверя\", чтобы гарантировать, что мы предоставим какой-то ответ, а не никакого.</p><pre><code class=\"language-typescript\">// Beast mode activation\nif (!thisStep.isFinal &amp;&amp; badAttempts &gt;= maxBadAttempts) {\n  console.log('Enter Beast mode!!!');\n  \n  // Configure prompt for decisive, committed answer\n  system = getPrompt(\n    diaryContext, allQuestions, allKeywords,\n    false, false, false, false, false,  // Disable all other actions\n    badContext, allKnowledge, unvisitedURLs,\n    true  // Enable beast mode\n  );\n  \n  // Force answer generation\n  const result = await LLM.generateStructuredResponse(system, messages, answerOnlySchema);\n  thisStep = result.object;\n  thisStep.isFinal = true;\n}\n</code></pre><p>Промпт режима зверя намеренно драматичен, чтобы сигнализировать LLM о необходимости быть решительным и фиксировать ответ на основе доступной информации:</p><pre><code>&lt;action-answer&gt;\n🔥 ENGAGE MAXIMUM FORCE! ABSOLUTE PRIORITY OVERRIDE! 🔥\n\nPRIME DIRECTIVE:\n- DEMOLISH ALL HESITATION! ANY RESPONSE SURPASSES SILENCE!\n- PARTIAL STRIKES AUTHORIZED - DEPLOY WITH FULL CONTEXTUAL FIREPOWER\n- TACTICAL REUSE FROM &lt;bad-attempts&gt; SANCTIONED\n- WHEN IN DOUBT: UNLEASH CALCULATED STRIKES BASED ON AVAILABLE INTEL!\n\nFAILURE IS NOT AN OPTION. EXECUTE WITH EXTREME PREJUDICE! ⚡️\n&lt;/action-answer&gt;\n</code></pre><p>Это гарантирует, что мы всегда предоставляем какой-то ответ, а не полностью сдаемся, что особенно полезно для сложных или неоднозначных вопросов.</p><h2 id=\"conclusion\">Заключение</h2><p>DeepSearch - это прорыв в том, как поиск может подходить к сложным запросам исчерпывающим образом. Разбивая процесс на отдельные этапы поиска, чтения и рассуждения, он преодолевает многие ограничения традиционных однопроходных RAG или многошаговых QA систем.</p><p>В процессе реализации мы также начали пересматривать основы поиска в 2025 году и изменения в поисковой индустрии после 26 января 2025 года, когда был выпущен DeepSeek-R1. Мы задали себе вопросы: <em>Каковы новые потребности? Какие потребности стали устаревшими? Какие потребности являются лишь воспринимаемыми?</em></p><p>Анализируя нашу реализацию DeepSearch, мы определили вещи, которые, как мы предполагали, будут нужны и действительно понадобились, вещи, которые, как мы думали, будут необходимы, но не оказались таковыми, и вещи, которые мы не предвидели, но оказались существенными:</p><p>Во-первых, <strong>крайне необходим LLM с длинным контекстом, который производит хорошо структурированный вывод</strong> (т.е. следующий JSONSchema). Вероятно, нужна модель рассуждений для лучшего обоснования действий и расширения запросов.</p><p><strong>Расширение запросов определенно необходимо</strong>, независимо от того, реализовано ли оно через SLM, LLM или модель рассуждений. Однако после этого проекта мы считаем, что SLM, вероятно, не подходят для этой задачи, поскольку решение должно быть по своей сути многоязычным и выходить за рамки простого переписывания синонимов или извлечения ключевых слов. Оно должно быть достаточно комплексным, чтобы включать <a href=\"https://jina.ai/news/what-should-we-learn-from-modernbert/#modernberts-parameter-efficiency\">многоязычную токеновую базу (может легко занимать 300M параметров)</a> и достаточно сложным для нестандартного мышления. Поэтому использование SLM для расширения запросов, вероятно, неперспективно.</p><p><strong>Возможности веб-поиска и веб-чтения крайне важны</strong>, и, к счастью, наш <a href=\"https://jina.ai/reader\">Reader (r.jina.ai)</a> показал отличные результаты — надежный и масштабируемый — и дал мне много идей о том, как улучшить нашу поисковую конечную точку (<code>s.jina.ai</code>) для следующей итерации.</p><p><strong>Модель встраивания полезна, <em>но совершенно неожиданным образом</em>.</strong> Мы думали, что она будет использоваться для извлечения памяти или сжатия контекста вместе с векторной базой данных (которая, как оказалось, не нужна), но мы фактически использовали ее для дедупликации (по сути, задача STS). Поскольку количество запросов и вопросов о пробелах обычно измеряется сотнями, векторная база данных не нужна — вычисление косинусного сходства напрямую в памяти работает отлично.</p><p><strong>Мы не использовали Reranker</strong>, хотя мы считаем, что он потенциально мог бы помочь определить, какие URL посещать на основе запроса, заголовка URL и сниппета. Для встраивания и переранжирования многоязычная способность является существенной, поскольку запросы и вопросы многоязычны. Обработка длинного контекста для встраивания и переранжирования полезна, но не является критическим блокером (Мы не столкнулись с какими-либо ошибками при использовании нашего встраивания, вероятно, потому что <a href=\"https://jina.ai/models/jina-embeddings-v3/\">наша длина контекста уже составляет 8192 токена</a>). В любом случае, <code>jina-embeddings-v3</code> и <code>jina-reranker-v2-base-multilingual</code> - это мои предпочтительные модели, поскольку они многоязычны, являются SOTA и хорошо справляются с длинным контекстом.</p><p><strong>Фреймворк агента оказался ненужным</strong>, поскольку нам нужно было оставаться ближе к нативному поведению LLM для проектирования системы без прокси. <a href=\"https://sdk.vercel.ai/docs/introduction\">Vercel AI SDK</a> был ценным, поскольку он сэкономил значительные усилия при адаптации кодовой базы к различным провайдерам LLM (мы могли переключаться между Gemini Studio, OpenAI и Google Vertex AI с изменением всего одной строки кода). Управление памятью агента необходимо, но отдельный фреймворк памяти остается под вопросом: Мы опасаемся, что он создаст изоляционный слой между LLM и разработчиками, и что его синтаксический сахар может в конечном итоге стать горьким препятствием для разработчиков, как мы видели со многими фреймворками LLM/RAG сегодня.</p>",
  "comment_id": "67bc50b0b1b8af00014db4c9",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/deepsearch-banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-02-24T11:57:52.000+01:00",
  "updated_at": "2025-02-25T14:39:22.000+01:00",
  "published_at": "2025-02-25T14:36:17.000+01:00",
  "custom_excerpt": "QPS out, depth in. DeepSearch is the new norm. Find answers through read-search-reason loops. Learn what it is and how to build it.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-implementing-deepsearch-deepresearch/",
  "excerpt": "QPS уходит, глубина приходит. DeepSearch — новая норма. Поиск ответов через циклы чтение-поиск-рассуждение. Узнайте, что это такое и как это построить.",
  "reading_time": 15,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}