{
  "slug": "model-soups-recipe-for-embeddings",
  "id": "681b63a077c406000104263b",
  "uuid": "e3fc45b3-6cf9-4a0b-863f-bc4a8417c436",
  "title": "Рецепт \"супа\" моделей для эмбеддингов",
  "html": "<p>В эти трудные времена нет ничего лучше хорошей тарелки теплого супа.</p><p>Минестроне — один из классических итальянских супов: густой, сытный, ароматный, сочетающий в себе фасоль, сочные овощи и рис или пасту. Его вкус — результат сочетания разнообразных ингредиентов. Он немного похож на борщ в Восточной Европе, запеканки в Америке или домашнюю жареную смесь в Тихоокеанской Азии в том смысле, что он сочетает в себе доступные недорогие ингредиенты в любимое блюдо.</p><p>Мы можем использовать примерно тот же рецепт для моделей нейронных сетей, согласно серии статей, начиная с <a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://proceedings.mlr.press/v162/wortsman22a.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</div><div class=\"kg-bookmark-description\">The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-pmlr.ico\" alt=\"\"><span class=\"kg-bookmark-author\">PMLR</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://proceedings.mlr.press/v162/assets/images/logo-pmlr.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>«Model soups» (увы, не «model casseroles» или «model stir-fries») — это класс методов ансамблирования моделей, предназначенных для снижения затрат на оптимизацию обучающих данных и гиперпараметров модели. При обучении нейронной сети вы обычно перебираете различные данные и значения гиперпараметров и обучаете несколько раз, ища наилучший результат. Обучение требует больших вычислительных затрат, и расходы быстро растут.</p><p>Вместо этого «model soups» предполагает обучение нескольких моделей с различными гиперпараметрами и вариантами обучающих данных — как обычно, — но затем их объединение. Результатом является более производительная и надежная модель, чем одна лучшая. Это не экономит затраты, потому что вы все равно обучаете несколько моделей, но вы можете получить лучший результат за ту же цену.</p><p>Подход «model soup» уже доказал свою полезность для текстово-изобразительных мультимодальных моделей встраивания <a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">(Wortsman et al. 2022)</a> и генеративных больших языковых моделей. (<a href=\"https://doi.org/10.1038/s42256-024-00975-8\">Takuya et al. 2025</a>) В Jina AI мы начали использовать этот метод для обучения наших собственных моделей, и <code>jina-embeddings-v3</code>, и <code>reader-lm-v2</code> включают в себя «model soups».</p><p>В этой статье мы рассмотрим «model soups» и покажем результаты некоторых наших работ с ними. В частности:</p><ol><li>Можем ли мы использовать «model soups» для повышения производительности путем объединения моделей в разных точках их обучения?</li><li>Можем ли мы объединить модели, обученные на разных наборах данных и для разных задач, чтобы получить лучшую производительность и более высокую эффективность обучения, чем при обучении одной модели?</li></ol><p>Это имеет важные потенциальные преимущества:</p><ul><li>«Model soups» могут иметь лучшую и более надежную производительность.</li><li>Многоязычные модели встраивания часто страдают от предвзятости и сбоев в производительности, вызванных неравномерным объемом обучающих данных. Было бы большим преимуществом иметь возможность обучать лучшую модель, которую мы можем, для каждой задачи или набора данных по отдельности, а затем объединять их в равной степени.</li><li>Мы можем добиться лучшего непрерывного обучения и обновления модели, внося изменения в наши модели модульным способом, обновляя одну модель компонента за раз, а затем снова объединяя ее с другими.</li></ul><h2 id=\"how-does-it-work\">Как это работает?</h2><p>Объединение выходных данных нескольких моделей — старый метод в теории статистических решений. Например, в прогнозировании погоды обычной практикой является создание нескольких моделей, часто сделанных разными людьми с разными предположениями, а затем использование различных механизмов для усреднения их прогнозов. Если ошибки каждой модели распределены случайным образом, то усреднение моделей приведет к ответам с меньшим количеством ошибок.</p><p>Например, если у вас есть три разные модели, которые выдают бинарный ответ «да» или «нет», и каждая из них ошибается в 10% случаев, то две из трех ошибутся только в 2,8% случаев. Пять моделей с критерием принятия решения большинством голосов будут ошибаться только в 0,856% случаев.</p><p>Усреднение моделей работает по тому же принципу, но вместо объединения выходных данных разных моделей оно объединяет сами модели.</p><p>Используемый подход является расширением <em>stochastic weight averaging</em> (<a href=\"https://auai.org/uai2018/proceedings/papers/313.pdf\">Izmailov et al. 2018</a>), который опирается на понимание ландшафтов потерь нейронных сетей, чтобы показать, что простое усреднение весов может улучшить обобщающую способность модели при общих условиях.</p><p>Фактическая механика усреднения моделей до смешного проста: вы просто усредняете веса нескольких моделей.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"380\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/image.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"><figcaption><span style=\"white-space: pre-wrap;\">Как объединяются модели для создания «model soup». Этот пример очень маленький и простой, но все же показывает процедуру: сложите веса и разделите на количество объединяемых моделей.</span></figcaption></figure><p>Если это кажется слишком простым, важно отметить, что при объединении моделей таким образом существуют ограничения. Вы не можете просто объединить веса любых двух нейронных сетей и ожидать, что это сработает.</p><p>Усреднение моделей работает только на очень похожих моделях, то есть на моделях, веса которых изначально не сильно отличаются друг от друга. Чтобы обеспечить это, необходимо предварительно обучить одну модель, а затем создать несколько вариантов этой модели путем ее точной настройки с различными гиперпараметрами или различными данными. Эти модели, как правило, будут достаточно похожи, чтобы их можно было усреднить.</p><p>В более технических терминах, предварительное обучение обычно создает модель, веса которой находятся вблизи нижней части области потерь, а точная настройка не приводит к легкому выходу из этой области потерь. Если все модели, подлежащие объединению, имеют веса в одной и той же области потерь, то их веса будут достаточно близки к одинаковым, и их усреднение, вероятно, сработает. Это не гарантируется, но эмпирически кажется, что это достаточно часто бывает правдой, чтобы быть полезным.</p><h2 id=\"experimental-setup\">Экспериментальная установка</h2><p><strong>Базовая модель</strong>: Для экспериментов, описанных здесь, мы использовали <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code> от FacebookAI</a> (<a href=\"https://aclanthology.org/2020.acl-main.747/\">Conneau et al. 2020</a>) в качестве нашей предварительно обученной базовой модели. Эта модель имеет 280 миллионов параметров и была предварительно обучена на 2,5 ТБ данных Common Crawl, содержащих текст примерно на 100 языках.</p><p>Мы выполнили тонкую настройку <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code></a> на нашем специально подобранном наборе обучающих пар предложений для обучения встраиваниям перед выполнением наших экспериментов.</p><p><strong>Обучающие данные</strong>: Jina AI поддерживает специально подобранные наборы данных для обучения. Для первого эксперимента мы использовали триплеты предложений, специально подобранные для контрастного обучения на шести языках: английском, арабском, немецком, испанском, японском и китайском. Для второго эксперимента мы использовали наборы обучающих данных для конкретных задач на английском языке.</p><p><strong>Оценка</strong>: Мы использовали соответствующие части <a href=\"https://github.com/embeddings-benchmark/mteb/tree/main/docs/mmteb\">набора тестов MMTEB</a> (<a href=\"https://arxiv.org/abs/2502.13595\">Enevoldsen et al. 2025</a>) и <a href=\"https://project-miracl.github.io/\">набора тестов MIRACL</a> (<a href=\"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00595/117438/MIRACL-A-Multilingual-Retrieval-Dataset-Covering\">Zhang et al. 2023</a>) для оценки моделей, полученных в результате нашего обучения и объединения.</p><h3 id=\"experiment-1-single-run-averaging\">Эксперимент 1: Усреднение одиночного прогона</h3><p>Для этого эксперимента мы использовали контрастные триплеты предложений на всех шести языках, смешанные вместе, в общей сложности 6000 шагов обучения с размером пакета 1024 элемента. На каждом 2000-м шаге мы сохраняли состояние модели для усреднения, получая 3 модели, каждая из которых отражает разные точки в процессе обучения.</p><p>Мы усреднили три модели, чтобы получить окончательную модель. Затем мы протестировали объединенную модель и три сохраненные контрольные точки на наборах тестов MMTEB-STS и MIRACL.</p><p>Наши результаты представлены в таблице ниже:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>MIRACL<br>(avg 6 languages)</th>\n<th>MMTEB-STS English<br>(avg 8 benchmarks)</th>\n<th>MMTEB-STS Multilingual<br>(avg 6 benchmarks)</th>\n<th>Average of 20 benchmarks</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>No triplet training</td>\n<td>0.3163</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.6276</td>\n</tr>\n<tr>\n<td>Step 2000</td>\n<td>0.4631</td>\n<td><strong>0.7924</strong></td>\n<td>0.7561</td>\n<td>0.6813</td>\n</tr>\n<tr>\n<td>Step 4000</td>\n<td>0.4639</td>\n<td>0.7902</td>\n<td><strong>0.7583</strong></td>\n<td>0.6812</td>\n</tr>\n<tr>\n<td>Step 6000 (final)</td>\n<td><strong>0.4680</strong></td>\n<td>0.7891</td>\n<td>0.7575</td>\n<td>0.6818</td>\n</tr>\n<tr>\n<td>Merged model<br>(all 3 stored checkpoints)</td>\n<td>0.4669</td>\n<td>0.7910</td>\n<td>0.7579</td>\n<td><strong>0.6823</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Объединение с предыдущими контрольными точками обычно не приводило к созданию модели с более высокой производительностью, чем лучшая среди сохраненных контрольных точек на отдельных тестах или на любой из трех используемых батарей тестов. Однако это привело к созданию лучшей модели по всем тестам, усредненным вместе.</p><p>В отдельных тестах разница между объединенной моделью и контрольной точкой с наилучшей производительностью в каждом случае составляет менее 0,01. Это верно не только для средних значений в таблице выше, но и для каждого отдельного теста.</p><p>Это демонстрирует, что объединение различных контрольных точек обучения может создать более надежную модель при очень небольших затратах на производительность.</p><p>Кроме того, объединив различные контрольные точки, мы можем эффективно защититься от переобучения. Переобучение в последнее время стало важной темой в нейронных сетях. (<a href=\"https://arxiv.org/abs/2503.19206v2\">Springer et al., 2025</a>) Сеть можно обучить таким образом, что она станет сложнее и хуже работать после дальнейшей тонкой настройки.</p><p>Поскольку контрольная точка с наилучшей производительностью в нашем эксперименте часто не является последней, мы, вероятно, переобучили нашу модель на 6000 шагах обучения. Объединенная модель очень близка к соответствию производительности лучшей контрольной точки во всех тестах, устраняя недостатки переобучения.</p><h3 id=\"experiment-2-averaging-models-trained-for-different-tasks\">Эксперимент 2: Усреднение моделей, обученных для разных задач</h3><p>Для этого эксперимента мы обучили три модели, каждая для своей распространенной задачи встраивания:</p><ul><li><strong>Семантическая схожесть</strong>: Измерение относительного перекрытия или сходства смысла между двумя текстами, обычно сопоставимой длины.</li><li><strong>Поиск документов на основе текстовых запросов</strong>: Нахождение документов, наилучшим образом удовлетворяющих запросу. Запросы, как правило, намного короче, чем документы, с которыми они сопоставляются.</li><li><strong>Вопросно-ответные системы</strong>: Нахождение документа, который лучше всего отвечает на вопрос на естественном языке. Вопросы также, как правило, намного короче, чем тексты, с которыми они сопоставляются.</li></ul><p>Обучение моделей для всех трех задач одновременно довольно сложно, поскольку цели очень разные, и мы надеемся, что model soups улучшат этот процесс.</p><p>Основываясь на предыдущем опыте, мы знали, что для каждой задачи требуется разное количество эпох обучения. Обучение обобщено ниже:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Задача</th>\n<th>Шаги обучения<br>(batchsize = 1,024)</th>\n<th>Размер обучающего набора данных<br>(в элементах)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Question Answering (QA)</td>\n<td>2,000</td>\n<td>256,000</td>\n</tr>\n<tr>\n<td>Document Retrieval</td>\n<td>3,000</td>\n<td>384,000</td>\n</tr>\n<tr>\n<td>Semantic Similarity (STS)</td>\n<td>1,000</td>\n<td>128,000</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Это позволило получить три модели, которые мы затем объединили в одну. Мы протестировали полученную модель на частях набора тестов MMTEB, относящихся к этим трем задачам: <a href=\"https://project-miracl.github.io/\">MIRACL</a>, <a href=\"https://huggingface.co/collections/zeta-alpha-ai/nanobeir-66e1a0af21dfd93e620cd9f6\">NanoBEIR</a> и STSEval (английская и многоязычная части MMTEB).</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(в среднем по 6 языкам)</th>\n<th>NanoBEIR<br>(в среднем по 13 тестам)</th>\n<th>MMTEB-STS English<br>(в среднем по 9 тестам)</th>\n<th>MMTEB-STS Multilingual<br>(в среднем по 6 тестам)</th>\n<th>Среднее по 34 тестам</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Нет обучения на триплетах</td>\n<td>0.3163</td>\n<td>0.5089</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.5876</td>\n</tr>\n<tr>\n<td>Обучение QA</td>\n<td><strong>0.4489</strong></td>\n<td>0.5332</td>\n<td>0.7843</td>\n<td>0.7535</td>\n<td>0.6237</td>\n</tr>\n<tr>\n<td>Обучение Retrieval</td>\n<td>0.4272</td>\n<td><strong>0.5360</strong></td>\n<td>0.7766</td>\n<td>0.7340</td>\n<td>0.6154</td>\n</tr>\n<tr>\n<td>Обучение STS</td>\n<td>0.1779</td>\n<td>0.4519</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.5508</td>\n</tr>\n<tr>\n<td>Объединенная модель</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td><strong>0.6240</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Здесь мы видим, что обученные для конкретных задач модели имеют наилучшие результаты для каждой задачи. MIRACL — это, прежде всего, тест для вопросно-ответных систем, даже если он называется поисковым, и обученная QA-модель превосходит все остальные, включая объединенную модель. NanoBEIR — это более традиционный набор тестов для информационного поиска, и мы видим, что обученная для поиска модель показывает лучшие результаты. Модель семантической схожести (STS) показывает довольно плохие результаты в этих тестах, но превосходит другие в явных задачах STS. Для каждой категории объединенная модель работает хуже, чем модель, обученная для одной задачи.</p><p>Но опять же, если усреднить результаты по всем тестам, объединенная модель превосходит другие, хотя ее результат представляет собой лишь очень небольшое улучшение по сравнению с QA-обученной моделью, и она очень плохо справляется с задачами STS.</p><p>Мы также объединили только модели QA и retrieval и оценили полученную модель на тех же тестах:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(в среднем по 6 языкам)</th>\n<th>NanoBEIR<br>(в среднем по 13 тестам)</th>\n<th>MMTEB-STS English<br>(в среднем по 9 тестам)</th>\n<th>MMTEB-STS Multilingual<br>(в среднем по 6 тестам)</th>\n<th>Среднее по 34 тестам</th>\n<th>Среднее<br>QA &amp; IR<br>(19 тестов)</th>\n<th>Среднее STS<br>(15 тестов)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Лучшая модель, обученная для задачи</td>\n<td>0.4489</td>\n<td>0.5360</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.6237</td>\n<td>0.5066</td>\n<td><strong>0.7857</strong></td>\n</tr>\n<tr>\n<td>Объединенная модель</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td>0.6240</td>\n<td>0.4973</td>\n<td>0.7845</td>\n</tr>\n<tr>\n<td>QA+Retrieval объединенная модель</td>\n<td><strong>0.4610</strong></td>\n<td><strong>0.5404</strong></td>\n<td>0.7878</td>\n<td>0.7498</td>\n<td><strong>0.6288</strong></td>\n<td><strong>0.5153</strong></td>\n<td>0.7726</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Здесь мы видим, что, хотя мы можем улучшить производительность как вопросно-ответных систем, так и систем поиска, объединив обученные модели для этих двух задач, добавление обученных STS-моделей снижает производительность для конкретных задач во всех категориях. Это говорит о том, что семантическая схожесть в некотором важном отношении отличается от QA и retrieval, и STS-обученная модель не подходит для объединения с двумя другими.</p><p>Вероятно, это связано с тем, что вопросно-ответные системы и системы поиска включают сопоставление коротких текстов — вопросов и запросов — с более длинными документами, в то время как семантическая схожесть включает сравнение документов более схожей длины.</p><p><a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a> описывают селективный подход к усреднению, который они называют “greedy” merging. Он включает в себя взятие одной модели, обычно лучшей из набора моделей, а затем добавление к ней только тех моделей, которые индивидуально улучшают производительность. При наличии всего трех моделей не было особого смысла использовать greedy merging для этого эксперимента. Однако мы можем представить себе случай с большим количеством моделей и использованием такой техники в качестве основы для определения степени сходства между задачами. Здесь мы обнаружили, что семантическая схожесть отличается от двух других. Затем мы могли бы оценить, когда одна модель может выполнять множество задач, а когда более экономично использовать другую модель.</p><h2 id=\"soup%E2%80%99s-on\">Soup’s on!</h2><p>Model soups сочетают разнообразие, создавая нечто большее, чем сумма их частей. Ценность этого подхода заключается в его способности обеспечивать большую согласованность, надежность и действовать в качестве защиты от переобучения без дополнительных затрат на обучение. Наши эксперименты показывают, что объединение контрольных точек или моделей, специализирующихся на задачах, может повысить общую производительность, даже если это иногда достигается за счет пиков производительности для конкретных задач.</p><p>В конечном счете, model soups предлагают практичный и очень простой способ создания более адаптивных моделей, хотя и с некоторыми оговорками. Это не панацея, и она применима только тогда, когда модели уже очень похожи.</p><p>Как говорят в интернете, <em>Your Mileage May Vary</em>. Но это дешево и легко узнать, могут ли model soups помочь, когда вы обучаете свои модели.</p>",
  "comment_id": "681b63a077c406000104263b",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/Heading--6-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-07T15:44:00.000+02:00",
  "updated_at": "2025-05-07T19:56:02.000+02:00",
  "published_at": "2025-05-07T18:43:10.000+02:00",
  "custom_excerpt": "Boost robustness and performance with model soups: averaging weights. No extra cost, better results.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "authors": [
    {
      "id": "6360e7e05e0f6e004d70bd99",
      "name": "Bo Wang",
      "slug": "bo",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
      "cover_image": null,
      "bio": "Developer @Jina, Contributor to open source ",
      "website": "https://bwanglzu.github.io/",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@bo_wangbo",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "primary_author": {
    "id": "6360e7e05e0f6e004d70bd99",
    "name": "Bo Wang",
    "slug": "bo",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
    "cover_image": null,
    "bio": "Developer @Jina, Contributor to open source ",
    "website": "https://bwanglzu.github.io/",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@bo_wangbo",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/model-soups-recipe-for-embeddings/",
  "excerpt": "Повысьте надежность и производительность с помощью model soups: усреднение весов. Никаких дополнительных затрат, лучшие результаты.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}