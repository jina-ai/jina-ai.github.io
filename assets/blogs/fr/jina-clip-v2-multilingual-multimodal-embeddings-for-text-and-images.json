{
  "slug": "jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images",
  "id": "673cc4a7a7c46d00015cf1f5",
  "uuid": "6ca44950-b989-494a-b587-70847f24edd2",
  "title": "Jina CLIP v2 : Embeddings multilingues et multimodales pour le texte et les images",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-clip-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">Nous sommes en mission pour faire progresser et démocratiser l'intelligence artificielle grâce à l'open source et la science ouverte.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-11.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-clip-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?sui=&model=jina-clip-v2&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - Votre base de recherche, surpuissante.</div><div class=\"kg-bookmark-description\">Les meilleurs embeddings, rerankers, LLM-reader, web scraper, classificateurs. La meilleure IA de recherche pour les données multilingues et multimodales.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">Votre base de recherche, surpuissante.</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> API est disponible sous l'onglet \"Embeddings\".</span></p></figcaption></figure><p>Les embeddings multimodaux permettent de rechercher et de comprendre les données à travers différentes modalités grâce à une représentation cohérente. Ils constituent la colonne vertébrale de la recherche d'information neuronale et des applications GenAI multimodales. Aujourd'hui, nous sommes ravis de publier <code>jina-clip-v2</code>, de nouveaux embeddings multimodaux multilingues à usage général construits sur <code>jina-clip-v1</code> et notre récent <code>jina-embeddings-3</code>, présentant plusieurs améliorations clés :</p><ul><li><strong>Performance améliorée</strong> : v2 montre une amélioration de 3 % par rapport à v1 dans les tâches de recherche texte-image et texte-texte. Comme pour v1, l'encodeur de texte v2 peut servir de récupérateur dense multilingue efficace pour les contextes longs. Il offre des performances équivalentes à notre modèle phare <code>jina-embeddings-v3</code> (actuellement les meilleurs embeddings multilingues de moins d'1B paramètres sur MTEB).</li><li><strong>Support multilingue</strong> : Propulsé par <code>jina-embeddings-v3</code> comme tour de texte, <code>jina-clip-v2</code> prend en charge 89 langues pour la recherche multilingue d'images, montrant une amélioration jusqu'à 4 % par rapport à <code>nllb-clip-large-siglip</code> sur les tâches de recherche d'images multilingues.</li><li><strong>Résolution d'image plus élevée</strong> : v2 prend désormais en charge une résolution d'image d'entrée de 512x512, une augmentation significative par rapport au 224x224 de v1. Cette résolution plus élevée permet un meilleur traitement des images détaillées, une meilleure extraction des caractéristiques et une reconnaissance plus précise des éléments visuels détaillés.</li><li><strong>Représentations Matryoshka</strong> : v2 permet aux utilisateurs de tronquer les dimensions de sortie des embeddings de texte et d'image de 1024 à 64, réduisant ainsi les coûts de stockage et de traitement tout en maintenant de fortes performances.</li></ul><h2 id=\"model-architecture\">Architecture du modèle</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--35-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p><code>jina-clip-v2</code> est un modèle de style CLIP de 0,9B qui combine deux puissants encodeurs : l'encodeur de texte <code>Jina XLM-RoBERTa</code> (la base de <code>jina-embeddings-v3</code>) et l'encodeur de vision <code>EVA02-L14</code> (un Transformer de vision efficace développé par BAAI). Ces encodeurs sont entraînés conjointement pour créer des représentations alignées d'images et de texte.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Text Encoder</th>\n<th>Image Encoder</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base Model</td>\n<td>Jina XLM-RoBERTa</td>\n<td>EVA02-L</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>561M</td>\n<td>304M</td>\n</tr>\n<tr>\n<td>Input Specification</td>\n<td>8,192 tokens (max)</td>\n<td>512×512 pixels</td>\n</tr>\n<tr>\n<td>Min Output Dimensions</td>\n<td>64</td>\n<td>64</td>\n</tr>\n<tr>\n<td>Max Output Dimensions</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Layers</td>\n<td>24</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Attention Mechanism</td>\n<td>FlashAttention2</td>\n<td>xFormers</td>\n</tr>\n<tr>\n<td>Pooling Strategy</td>\n<td>Mean pooling</td>\n<td>CLS pooling</td>\n</tr>\n<tr>\n<td>Additional Features</td>\n<td>89 languages supported</td>\n<td>Patch size 14x14</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"cross-modal-retrieval-performance\">Performance de recherche intermodale</h2><p>Jina CLIP v2 offre un support multilingue pour 89 langues avec des performances de pointe dans les principales langues, notamment l'arabe, le chinois, l'anglais, le français, l'allemand, le japonais, le russe et l'espagnol. Dans les benchmarks de recherche d'images multilingues, il montre des performances égales ou supérieures à <a href=\"https://huggingface.co/visheratin/nllb-clip-large-siglip?ref=jina-ai-gmbh.ghost.io\">NLLB-CLIP-SigLIP</a>, un modèle de style CLIP état de l'art légèrement plus grand (1,3B, 44 % plus grand que <code>jina-clip-v2</code>) qui utilise un encodeur de texte pré-entraîné des modèles NLLB.</p><h3 id=\"english-only-text-and-images\">Texte et images en anglais uniquement</h3><p>Sur les benchmarks standard de recherche intermodale (Flickr30k et COCO), <code>jina-clip-v2</code> démontre de fortes améliorations dans tous les domaines. Il atteint une performance état de l'art de 98,0 % sur la recherche image-vers-texte Flickr30k, surpassant à la fois son prédécesseur et NLLB-CLIP-SigLIP. Le modèle montre des gains constants dans tous les scénarios de recherche, avec des améliorations notables allant jusqu'à 3,3 % par rapport à v1 sur la recherche image-vers-texte COCO, tout en maintenant des performances compétitives avec NLLB-CLIP-SigLIP à travers différents benchmarks et directions de modalité.</p><p><strong>Performance Flickr30k Recall@5 :</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>98.0</td>\n<td>+1.7%</td>\n<td>+0.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>96.4</td>\n<td>-</td>\n<td>-0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>97.1</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>89.8</td>\n<td>+0.9%</td>\n<td>-2.6%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>89.0</td>\n<td>-</td>\n<td>-3.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>92.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>Performance COCO Recall@5 :</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>81.5</td>\n<td>+3.3%</td>\n<td>+2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>78.9</td>\n<td>-</td>\n<td>-0.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>79.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>68.4</td>\n<td>+2.9%</td>\n<td>-3.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>66.5</td>\n<td>-</td>\n<td>-6.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>70.8</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"multilingual-text-and-images\">Texte et images multilingues</h3><p>Sur les benchmarks intermodaux multilingues, <code>jina-clip-v2</code> démontre des performances robustes, excellant particulièrement dans la recherche image-vers-texte où il surpasse NLLB-SigLIP sur tous les jeux de données, avec une amélioration allant jusqu'à +3,8 % sur Crossmodal 3600. Bien que NLLB-SigLIP montre des capacités légèrement plus fortes en recherche texte-vers-image, l'écart de performance reste faible, généralement inférieur à 3 %.</p><p><strong>Performance Image2Text Recall@5 :</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>83.23</td>\n<td>+3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>80.16</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>86.03</td>\n<td>+0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.37</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.98</td>\n<td>+0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.41</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>Performance Text2Image Recall@5 :</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>81.43</td>\n<td>-0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>82.07</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>84.87</td>\n<td>-3.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.60</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.03</td>\n<td>-3.0%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.63</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"text-only-dense-retriever-performance\">Performance du Retrieveur Dense Text-Only</h2>\n<p>Comme son prédécesseur, l'encodeur de texte de <code>jina-clip-v2</code> peut servir de retrieveur multilingue dense efficace. Sur les benchmarks complets Multilingual MTEB, il atteint de bonnes performances, avec 69,86 % sur la récupération et 67,77 % sur les tâches de similarité sémantique. Ces résultats démontrent sa polyvalence, performant de manière compétitive avec notre modèle spécialisé d'embedding de texte <code>jina-embeddings-v3</code> :</p>\n<table>\n<thead>\n<tr>\n<th>Tâche</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>69.86</td>\n<td>-3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>72.59</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Similarité Sémantique</td>\n<td>jina-clip-v2</td>\n<td>67.77</td>\n<td>-2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>69.81</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p>Sur les tâches en anglais, <code>jina-clip-v2</code> montre des améliorations constantes par rapport à son prédécesseur et à NLLB-SigLIP, avec des avantages particulièrement importants en termes de performance de récupération (presque le double du score de NLLB-SigLIP).</p>\n<table>\n<thead>\n<tr>\n<th>Tâche</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>STS</td>\n<td>jina-clip-v2</td>\n<td>81.29</td>\n<td>+0.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>80.92</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>74.65</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>49.33</td>\n<td>+2.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>48.33</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>24.92</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"matryoshka-representation-performance\">Performance de la Représentation Matryoshka</h2>\n<p>Les encodeurs de texte et d'image prennent en charge MRL, et leurs dimensions de sortie peuvent être tronquées à 64 tout en maintenant de bonnes performances. Notre évaluation de la troncature des embeddings a révélé un potentiel de compression remarquable. Même une réduction dimensionnelle agressive de 75 % a maintenu plus de 99 % des performances sur les tâches de texte, d'image et cross-modales.</p>\n<h3 id=\"image-classification\">Classification d'Images</h3>\n<p>Sur 37 benchmarks divers de classification d'images, l'encodeur d'images montre une forte résilience aux dimensions tronquées. La compression de 1024 à 64 dimensions (réduction de 94 %) n'entraîne qu'une baisse de 8 % de la précision top-5 et de 12,5 % en top-1, soulignant son potentiel pour un déploiement efficace avec une perte de performance minimale.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/accuracy_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption>Pour la <b><strong style=\"white-space: pre-wrap;\">classification d'images</strong></b>, nous avons utilisé les 19 benchmarks du jeu de données <a href=\"https://github.com/google-research/task_adaptation?ref=jina-ai-gmbh.ghost.io\">VTAB</a>, <a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/?ref=jina-ai-gmbh.ghost.io\">VOC 2007</a>, <a href=\"https://www.tensorflow.org/datasets/catalog/sun397?ref=jina-ai-gmbh.ghost.io\">SUN397</a>, <a href=\"https://cs.stanford.edu/~acoates/stl10/?ref=jina-ai-gmbh.ghost.io\">STL10</a>, <a href=\"https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md?ref=jina-ai-gmbh.ghost.io\">Rendered SST2</a>, <a href=\"https://objectnet.dev/?ref=jina-ai-gmbh.ghost.io\">ObjectNet</a>, <a href=\"https://github.com/cvdfoundation/mnist?ref=jina-ai-gmbh.ghost.io\">MNIST</a>, German Traffic Sign Recognition Benchmark (<a href=\"https://benchmark.ini.rub.de/gtsrb_dataset.html?ref=jina-ai-gmbh.ghost.io\">GTSRB</a>), Fine-Grained Visual Classification of Aircraft (<a href=\"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/?ref=jina-ai-gmbh.ghost.io\">FGVC-Aircraft</a>), <a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge?ref=jina-ai-gmbh.ghost.io\">FER 2013</a>, <a href=\"https://github.com/openai/CLIP/blob/main/data/country211.md?ref=jina-ai-gmbh.ghost.io\">Country211</a>, <a href=\"https://www.tensorflow.org/datasets/catalog/cars196?ref=jina-ai-gmbh.ghost.io\">Cars196</a>, <a href=\"https://github.com/hendrycks/natural-adv-examples?ref=jina-ai-gmbh.ghost.io\">ImageNet-A, ImageNet-O,</a><a href=\"https://huggingface.co/datasets/ILSVRC/imagenet-1k?ref=jina-ai-gmbh.ghost.io\">IxmageNet1k</a>, <a href=\"https://github.com/HaohanWang/ImageNet-Sketch?ref=jina-ai-gmbh.ghost.io\">ImageNet Sketch</a>, et <a href=\"https://imagenetv2.org/?ref=jina-ai-gmbh.ghost.io\">ImageNet v2</a>.</figcaption></figure><h3 id=\"cross-modal-retrieval\">Recherche Cross-Modale</h3><p>Malgré une réduction drastique de 94 % à seulement 64 dimensions, la recherche cross-modale utilisant les embeddings d'images et de textes tronqués est restée remarquablement robuste, conservant 93 % des performances image-vers-texte et 90 % des performances texte-vers-image.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/crossmodal_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption>Nous avons utilisé six benchmarks, dont trois sont multilingues : <a href=\"https://google.github.io/crossmodal-3600/?ref=jina-ai-gmbh.ghost.io\">Crossmodal-3600</a> (36 langues), <a href=\"https://shannon.cs.illinois.edu/DenotationGraph/?ref=jina-ai-gmbh.ghost.io\">flickr30k</a> (anglais uniquement), <a href=\"https://hockenmaier.cs.illinois.edu/8k-pictures.html?ref=jina-ai-gmbh.ghost.io\">flickr8k</a> (anglais uniquement), <a href=\"https://arxiv.org/abs/1504.00325?ref=jina-ai-gmbh.ghost.io\">MS COCO Captions</a> (anglais uniquement), <a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\">Multilingual MS COCO Captions</a> (10 langues), <a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\">XTD 200</a> (27 langues)</figcaption></figure><h3 id=\"text-only-retrieval\">Recherche Texte Uniquement</h3><p>Sur les <strong>benchmarks MTEB en anglais uniquement</strong>, les embeddings de texte à 64 dimensions (compressés à partir de 1024) ont remarquablement bien préservé la similarité sémantique, avec une baisse de seulement 2,1 %, tandis que la recherche a connu une modeste diminution de 17,5 %.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/mteb_performance.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"></figure><h2 id=\"getting-started\">Pour Commencer</h2><h3 id=\"via-api\">Via API</h3><p>Le code montre comment générer des embeddings en utilisant <code>requests</code> en Python. Passez une chaîne de texte avec soit une image en base64 soit une URL, plus la taille de dimension souhaitée (1024 par défaut, 768 montré ci-dessous).</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-Python\">import requests\nimport numpy as np\nfrom numpy.linalg import norm\n\ncos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n\nurl = 'https://api.jina.ai/v1/embeddings'\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Authorization': 'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'\n}\n\ndata = {\n  'input': [\n     {\"text\": \"Bridge close-shot\"},\n     {\"url\": \"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s\"}],\n  'model': 'jina-clip-v2',\n  'encoding_type': 'float',\n  'dimensions': '768' \n}\n\nresponse = requests.post(url, headers=headers, json=data)\nsim = cos_sim(np.array(response.json()['data'][0]['embedding']), np.array(response.json()['data'][1]['embedding']))\nprint(f\"Cosine text&lt;-&gt;image: {sim}\")</code></pre><figcaption><p>N'oubliez pas de remplacer &lt;YOUR_JINA_AI_API_KEY&gt; par une clé API Jina activée. Vous pouvez obtenir <a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">une clé API gratuite avec un million de tokens gratuits ici.</a></p></figcaption></figure><h3 id=\"image-tokens-pricing\">Tarification des Tokens d'Image</h3><p>Notre API compte les tokens à la fois pour le texte et les images. Pour les images, la consommation de tokens est basée sur le nombre de tuiles de 512x512 pixels nécessaires pour couvrir toute la surface de l'image. Chaque tuile coûte 4 000 tokens à traiter, y compris les tuiles partiellement remplies. <strong>Pour une efficacité optimale des coûts, nous recommandons aux utilisateurs de l'API de redimensionner leurs images à 512x512 avant d'envoyer les requêtes.</strong></p><table>\n<thead>\n<tr>\n<th>Résolution d'Image</th>\n<th>Tuiles Requises</th>\n<th>Coût en Tokens</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>512x512</td>\n<td>1</td>\n<td>4,000</td>\n</tr>\n<tr>\n<td>720x720</td>\n<td>4</td>\n<td>16,000</td>\n</tr>\n<tr>\n<td>1080x1080</td>\n<td>9</td>\n<td>36,000</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--37-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption>Pour les images carrées, redimensionnez à 512x512 pour une meilleure efficacité des coûts. Pour les tâches sensibles au ratio d'aspect, mettez à l'échelle le bord le plus long à 512, centrez l'image et complétez avec du noir. Pour les usages généraux, le redimensionnement direct à 512x512 fonctionne bien.</figcaption></figure><h3 id=\"via-csp-marketplaces\">Via les Places de Marché CSP</h3><p>Jina CLIP v2 est disponible directement sur AWS, Azure et GCP aux prix indiqués.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-bfbctuqmky676?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina CLIP v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-10.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-9.ico\" alt=\"\"></div></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://console.cloud.google.com/marketplace/browse?q=jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Cloud console</div><div class=\"kg-bookmark-description\">Dépensez intelligemment, procurez-vous plus rapidement et utilisez les dépenses engagées sur Google Cloud avec Google Cloud Marketplace. Parcourez le catalogue de plus de 2000 applications SaaS, VMs, stacks de développement et applications Kubernetes optimisées pour fonctionner sur Google Cloud.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/default.png\" alt=\"\"></div></div></a></figure><h3 id=\"via-vectordb\"><strong>Via VectorDB</strong></h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">La base de données vectorielle pour construire une IA intelligente | Pinecone</div><div class=\"kg-bookmark-description\">Recherchez parmi des milliards d'éléments des correspondances similaires à n'importe quel objet, en millisecondes. C'est la prochaine génération de recherche, accessible via une API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-3.png\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://weaviate.io/developers/weaviate/model-providers/jinaai/embeddings-multimodal?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embeddings Multimodaux | Weaviate</div><div class=\"kg-bookmark-description\">L'intégration de Weaviate avec les API de Jina AI vous permet d'accéder directement aux capacités de leurs modèles depuis Weaviate.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-12.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Weaviate</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/provider_integrations_jinaai.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant est une base de données vectorielle et un moteur de recherche vectorielle Open Source écrit en Rust. Il fournit un service de recherche de similarité vectorielle rapide et évolutif avec une API pratique.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-4.png\" alt=\"\"><span class=\"kg-bookmark-author\">edit</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">Conclusion</h2><p>S'appuyant sur notre version <code>jina-clip-v1</code> de juin, qui a étendu le modèle CLIP d'OpenAI avec une entrée de texte allant jusqu'à 8 192 tokens, et le pionnier multilingue <code>jina-embeddings-v3</code>, <code>jina-clip-v2</code> apporte trois avancées majeures : le support multilingue pour 89 langues, une résolution d'image accrue à 512x512, et l'apprentissage de représentation Matryoshka pour des embeddings plus tronqués.</p><p>Les modèles de type CLIP se sont imposés comme la colonne vertébrale des applications multimodales à usage général. Avec <code>jina-clip-v2</code>, nous portons ces capacités au niveau supérieur, en brisant les barrières linguistiques pour offrir une compréhension et une recherche cross-modale plus précises. Nous pensons que cette version tient la promesse de rendre la recherche et la récupération multimodales à la fois plus puissantes et plus accessibles aux développeurs du monde entier.</p>",
  "comment_id": "673cc4a7a7c46d00015cf1f5",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/11/clipv2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-11-19T18:02:31.000+01:00",
  "updated_at": "2024-11-21T17:29:45.000+01:00",
  "published_at": "2024-11-21T17:29:45.000+01:00",
  "custom_excerpt": "Jina-CLIP v2, a 0.9B multimodal embedding model with multilingual support of 89 languages, high image resolution at 512x512, and Matryoshka representations.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/",
  "excerpt": "Jina-CLIP v2, un modèle d'embedding multimodal de 0,9B avec un support multilingue de 89 langues, une haute résolution d'image à 512x512, et des représentations Matryoshka.",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}