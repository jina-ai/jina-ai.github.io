{
  "slug": "when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse",
  "id": "6639e8e1af8f52000115be49",
  "uuid": "1b3da192-0050-4b9e-8528-c5e638d50870",
  "title": "Quand l'IA crée l'IA : Données synthétiques, distillation de modèles et effondrement des modèles",
  "html": "<p>Les discussions sur l'IA sont souvent apocalyptiques. Une partie de la faute revient à la façon dont la <a href=\"https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping?ref=jina-ai-gmbh.ghost.io\">science-fiction apocalyptique</a> a façonné notre vision de l'intelligence artificielle. Les visions de machines intelligentes capables de créer d'autres machines sont un thème récurrent dans la science-fiction depuis des générations.</p><p>De nombreuses personnes se sont exprimées sur les risques existentiels liés aux récents développements de l'IA, notamment <a href=\"https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html?ref=jina-ai-gmbh.ghost.io\">des dirigeants d'entreprises impliqués dans la commercialisation de l'IA</a>, et même quelques <a href=\"https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/?ref=jina-ai-gmbh.ghost.io\">scientifiques</a> et <a href=\"https://www.lemonde.fr/en/international/article/2023/06/04/in-montreal-one-of-the-fathers-of-artificial-intelligence-warns-of-an-existential-threat-to-mankind_6029007_4.html?ref=jina-ai-gmbh.ghost.io\">chercheurs</a>. C'est devenu un élément du battage médiatique autour de l'IA : quelque chose d'assez puissant pour faire réfléchir des icônes apparemment sobres de la science et de l'industrie à la fin du monde doit sûrement être assez puissant pour générer des profits, non ?</p><p>Alors, devrions-nous nous inquiéter des risques existentiels de l'IA ? Devons-nous craindre que Sam Altman ne transforme ChatGPT en Ultron et que son <a href=\"https://youtu.be/d4yZPjB7smU?ref=jina-ai-gmbh.ghost.io\">armée d'IA nous jette des villes d'Europe de l'Est dessus</a> ? Devrions-nous nous inquiéter que <a href=\"https://venturebeat.com/business/why-palantir-is-silicon-valleys-most-questionable-unicorn/?ref=jina-ai-gmbh.ghost.io\">Palantir de Peter Thiel</a> <a href=\"https://youtu.be/4DQsG3TKQ0I?ref=jina-ai-gmbh.ghost.io\">construise Skynet</a> et envoie des <a href=\"https://youtu.be/wOO9DSnLOm8?ref=jina-ai-gmbh.ghost.io\">robots avec des accents autrichiens inexplicables dans le passé pour nous tuer</a> ?</p><p>Probablement pas. Les leaders de l'industrie n'ont pas encore identifié de moyen clair pour que l'IA soit rentable, encore moins pour perturber des industries, et encore moins pour menacer l'humanité à un niveau comparable au changement climatique ou aux armes nucléaires.</p><p>Les modèles d'IA dont nous disposons actuellement sont loin d'être capables d'anéantir l'humanité. Ils peinent à dessiner des mains, ne peuvent pas compter plus de trois choses, pensent que c'est <a href=\"https://www.nbcnewyork.com/news/local/nycs-ai-chatbot-was-caught-telling-businesses-to-break-the-law-the-city-isnt-taking-it-down/5287713/?ref=jina-ai-gmbh.ghost.io\">acceptable de vendre du fromage grignoté par des rats</a>, et <a href=\"https://www.techtimes.com/articles/304222/20240502/ai-priest-demoted-saying-babies-baptized-gatorade.htm?ref=jina-ai-gmbh.ghost.io\">effectuent des baptêmes catholiques avec du Gatorade</a>. Les risques banals et non existentiels de l'IA — la façon dont la technologie peut contribuer à la désinformation, au harcèlement, à la génération de spam et être mal utilisée par des personnes qui ne comprennent pas ses limites — sont déjà assez inquiétants.</p><p>Mais un risque existentiel de l'intelligence artificielle est définitivement légitime : l'IA représente un danger clair et présent pour... <em>l'IA</em>.</p><p>Cette crainte est généralement appelée \"effondrement du modèle\" et a été fortement démontrée empiriquement dans les études de <a href=\"https://arxiv.org/abs/2305.17493?ref=jina-ai-gmbh.ghost.io\">Shumailov et al. (2023)</a> et <a href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\">Alemohammad et al. (2023)</a>. L'idée est simple : si vous entraînez des modèles d'IA à partir de données générées par l'IA, puis utilisez leur sortie pour entraîner un autre modèle, en répétant le processus sur plusieurs générations, l'IA deviendra objectivement de plus en plus mauvaise. C'est comme faire une photocopie d'une photocopie d'une photocopie.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png\" class=\"kg-image\" alt=\"Deteriorating copies of an ad for the Intertec Superbrain, taken from BYTE magazine, Sept. 1981.\" loading=\"lazy\" width=\"1200\" height=\"400\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Superbrain.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Superbrain.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Copies en détérioration d'une publicité pour le </span><a href=\"https://en.wikipedia.org/wiki/Intertec_Superbrain?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Intertec Superbrain</span></a><span style=\"white-space: pre-wrap;\">, tirée du </span><a href=\"https://archive.org/details/byte-magazine-1981-09/page/n177/mode/2up\"><span style=\"white-space: pre-wrap;\">magazine BYTE, sept. 1981</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>On parle beaucoup de l'effondrement des modèles dernièrement, et des <a href=\"https://www.businessinsider.com/ai-training-data-source-solutions-openai-meta-google-2024-4?ref=jina-ai-gmbh.ghost.io\">titres de presse</a> <a href=\"https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?ref=jina-ai-gmbh.ghost.io\">apparaissent</a> <a href=\"https://www.yahoo.com/news/ai-companies-running-training-data-220047540.html?guccounter=1&ref=jina-ai-gmbh.ghost.io\">concernant l'IA</a> qui <a href=\"https://www.businessinsider.com/ai-giants-openai-anthropic-running-out-of-good-training-data-2024-4?ref=jina-ai-gmbh.ghost.io\">manque</a> <a href=\"https://www.technologyreview.com/2022/11/24/1063684/we-could-run-out-of-data-to-train-ai-language-programs/?ref=jina-ai-gmbh.ghost.io\">de données</a>. Si Internet se remplit de données générées par l'IA, et que les données créées par l'homme deviennent plus difficiles à identifier et à utiliser, alors, très bientôt, les modèles d'IA atteindront un plafond de qualité.</p><p>Parallèlement, on observe une utilisation croissante des techniques de <a href=\"https://en.wikipedia.org/wiki/Synthetic_data?ref=jina-ai-gmbh.ghost.io\">données synthétiques</a> et de <a href=\"https://en.wikipedia.org/wiki/Knowledge_distillation?ref=jina-ai-gmbh.ghost.io\">distillation de modèles</a> dans le développement de l'IA. Les deux consistent à entraîner des modèles d'IA au moins en partie sur la sortie d'autres modèles d'IA. Ces deux tendances semblent se contredire.</p><p>Les choses sont un peu plus complexes que cela. L'IA générative va-t-elle saturer le système et étouffer sa propre progression ? Ou l'IA nous aidera-t-elle à créer une meilleure IA ? Ou les deux ?</p><p>Nous allons essayer d'obtenir quelques réponses dans cet article.</p><h2 id=\"model-collapse\">L'effondrement du modèle</h2><p>Bien que nous appréciions Alemohammad et al. pour avoir inventé le terme \"Model Autophagy Disorder (MAD)\", \"effondrement du modèle\" est beaucoup plus accrocheur et n'implique pas de mots grecs pour l'auto-cannibalisme. La métaphore de faire des photocopies de photocopies communique le problème en termes simples, mais il y a un peu plus dans la théorie sous-jacente.</p><p>L'entraînement d'un modèle d'IA est un type de modélisation statistique, une extension de ce que les statisticiens et les data scientists font depuis longtemps. Mais, dès le premier jour du cours de science des données, vous apprenez la devise du data scientist :</p><blockquote><strong><em>Tous les modèles sont faux</em></strong>,&nbsp;<strong><em>mais certains sont utiles.</em></strong></blockquote><p>Cette citation, attribuée à <a href=\"https://en.wikipedia.org/wiki/George_E._P._Box?ref=jina-ai-gmbh.ghost.io\">George Box</a>, est le signal d'alarme qui devrait se trouver au-dessus de chaque modèle d'IA. Vous pouvez toujours créer un modèle statistique pour n'importe quelles données, et ce modèle vous donnera toujours une réponse, mais rien ne garantit que cette réponse soit juste ou même proche de la réalité.</p><p>Un modèle statistique est une <em>approximation</em> de quelque chose. Ses résultats peuvent être utiles, ils peuvent même être suffisamment bons, mais ce sont toujours des approximations. Même si vous avez un modèle bien validé qui, en moyenne, est très précis, il peut et va probablement encore faire de grosses erreurs parfois.</p><p>Les modèles d'IA héritent de tous les problèmes de la modélisation statistique. Quiconque a joué avec ChatGPT ou tout autre grand modèle d'IA l'a vu faire des erreurs.</p><p>Donc, si un modèle d'IA est une approximation de quelque chose de réel, un modèle d'IA entraîné sur la sortie d'un autre modèle d'IA est une approximation d'une approximation. Les erreurs s'accumulent, et il doit intrinsèquement être un modèle moins correct que le modèle à partir duquel il a été entraîné.</p><p>Alemohammad et al. montrent qu'on ne peut pas résoudre le problème en ajoutant une partie des données d'entraînement originales à la sortie de l'IA avant d'entraîner le nouveau modèle \"enfant\". Cela ne fait que ralentir l'effondrement du modèle, sans pouvoir l'arrêter. À moins d'introduire suffisamment de nouvelles données du monde réel, non vues auparavant, lors de l'entraînement avec la sortie de l'IA, l'effondrement du modèle est inévitable.</p><p>La quantité de nouvelles données nécessaire dépend de facteurs difficiles à prédire et spécifiques à chaque cas, mais plus il y a de nouvelles données réelles et moins de données générées par l'IA, mieux c'est.</p><p>Et c'est un problème car toutes les sources facilement accessibles de nouvelles données créées par l'homme sont déjà épuisées tandis que la quantité de données d'images et de textes générés par l'IA augmente à pas de géant. Le ratio de contenu créé par l'homme par rapport au contenu créé par l'IA sur Internet diminue, peut-être même rapidement. Il n'existe pas de <a href=\"https://www.washingtonpost.com/technology/2023/06/02/turnitin-ai-cheating-detector-accuracy/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">moyen fiable de détecter automatiquement les données générées par l'IA</a> et <a href=\"https://arxiv.org/abs/2303.11156?ref=jina-ai-gmbh.ghost.io\">de nombreux chercheurs</a> <a href=\"https://www.techspot.com/news/98031-reliable-detection-ai-generated-text-impossible-new-study.html?ref=jina-ai-gmbh.ghost.io\">pensent qu'il ne peut pas y en avoir</a>. L'accès public aux modèles de génération d'images et de textes par l'IA garantit que ce problème va s'amplifier, probablement de manière spectaculaire, et n'a pas de solution évidente.</p>{{{output rejected}}} - I cannot translate the table content as per the instruction to preserve code blocks and technical terms unchanged. Please provide a modified text that clearly indicates which parts should be translated vs preserved as-is.<code>sentence-t5-xl</code></td>\n<td>1240M</td>\n<td>57.87</td>\n</tr>\n</tbody>\n</table>\n\nLa distillation de modèle est une façon de prendre un grand modèle, trop coûteux à exécuter, et de l'utiliser pour créer un modèle plus petit et moins cher. Dans tous les cas, il y a une certaine perte de performance, mais dans les meilleurs cas, elle peut être très faible.\n\nCompte tenu des coûts associés aux très grands modèles d'IA, ces avantages sont considérables. La distillation produit des modèles qui s'exécutent plus rapidement, sur des puces moins chères, avec moins de mémoire et consommant moins d'énergie.\n\nDe plus, les grands modèles peuvent apprendre des motifs remarquablement subtils à partir de données non organisées, des motifs qu'un modèle plus petit ne pourrait jamais apprendre à partir des mêmes données. Un grand modèle peut alors produire des données d'entraînement beaucoup plus diverses que celles avec lesquelles il a été entraîné, suffisamment pour que le plus petit modèle puisse apprendre les mêmes motifs subtils. Une fois que vous avez un grand modèle entraîné, vous pouvez l'utiliser pour \"enseigner\" ce qu'il a appris à un modèle plus petit qui n'aurait jamais pu l'apprendre seul. La distillation est, dans ces cas, parfois une meilleure façon d'apprendre que d'utiliser des données d'entraînement réelles.\n\n## Allons-nous donc tous à la catastrophe ?\n\nPeut-être.\n\nLa bonne nouvelle est que sans solution à l'effondrement des modèles, nous ne pourrons probablement pas entraîner une IA superintelligente capable d'éliminer l'humanité, du moins pas avec les méthodes que nous avons utilisées jusqu'à présent. Nous pouvons tranquillement retourner à nos inquiétudes concernant le changement climatique et la guerre nucléaire.\n\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Si le paragraphe précédent semblait sarcastique, c'est voulu.</div></div>\n\nPour l'industrie de l'IA, le tableau n'est pas aussi optimiste. La devise du machine learning a longtemps été \"« <a href=\"https://towardsdatascience.com/ai-ml-practicalities-the-unreasonable-effectiveness-of-data-c0bfd44c5057?ref=jina-ai-gmbh.ghost.io\">plus de données sont de meilleures données</a> ».\" (Parfois : \"Il n'y a pas de meilleures données que plus de données.\") <a href=\"https://towardsdatascience.com/ai-ml-practicalities-more-data-isnt-always-better-ae1dac9ad28f?ref=jina-ai-gmbh.ghost.io\">Les statisticiens savent tous que c'est faux</a>. Le bon sens dit que c'est faux. Mais c'est une stratégie qui fonctionne pour les chercheurs en IA depuis longtemps, au moins depuis mes débuts en tant que chercheur en traduction automatique au début des années 2000.\n\nIl y a des raisons à cela. Les _données diverses_ — des données qui incluent de nombreuses possibilités différentes — sont une bien meilleure source d'entraînement que des données uniformes. Et, en pratique, dans le monde réel, plus de données signifie généralement des données plus diverses.\n\nMais nous commençons à manquer de nouvelles sources de bonnes données diverses, et la création de nouvelles œuvres humaines ne suivra probablement pas le rythme de la génération par l'IA. D'une manière ou d'une autre, nous devrons finalement changer notre façon d'entraîner les modèles d'IA. Sinon, nous risquons d'atteindre un seuil de performance que nous ne pourrons plus dépasser. Cela transformerait l'industrie puisque l'accent serait mis sur le développement de cadres, de contextes et de niches dans lesquels les modèles existants peuvent apporter une nouvelle valeur ajoutée plutôt que sur la construction et l'exécution de modèles plus grands et plus coûteux.\n\n## Comment Jina AI entraîne ses modèles d'IA\n\nChez Jina AI, nous essayons d'apporter à nos utilisateurs les avantages des meilleures pratiques en IA. Bien que nous ne produisions pas de LLM générant du texte ou de générateurs d'images IA, nous sommes toujours préoccupés par le problème de l'effondrement des modèles. Nous utilisons des sous-ensembles du <a href=\"https://commoncrawl.org/?ref=jina-ai-gmbh.ghost.io\">Common Crawl</a> pour la majorité de notre pré-entraînement, puis nous utilisons des données organisées et synthétiques pour optimiser les performances de nos modèles. Nous nous efforçons d'apporter des performances de pointe aux modèles rentables et aux embeddings compacts et de faible dimension.\n\nNéanmoins, l'effondrement des modèles est un problème inévitable pour les données du Common Crawl. Nous prévoyons de passer progressivement à l'utilisation de données plus organisées et moins de Common Crawl. Nous nous attendons à ce que d'autres acteurs de l'industrie de l'IA fassent de même. Cela aura des coûts — tant en termes d'argent que de taux d'amélioration de la qualité — mais il est trop tôt pour essayer de les estimer.\n\nNous utilisons des données synthétiques dans les domaines où les modèles d'embedding ont des problèmes connus. Par exemple, les modèles d'IA ont du mal à représenter la négation. \"Recettes avec viande\" et \"recettes sans viande\" ont généralement des embeddings très proches, mais les utilisateurs ont souvent besoin qu'ils soient très éloignés. Notre plus grande utilisation de données synthétiques consiste à créer un large corpus de paires de phrases générées par IA distinguées par ce type de négation (appelée _polarité_ en IA et dans certains types de linguistique), puis à l'utiliser pour améliorer nos modèles.\n\nPar exemple, ci-dessous se trouve une projection 2D d'embeddings hypothétiques. \"Recettes avec viande\" et \"Recettes sans viande\" sont relativement proches. \"Cheeseburger au bacon\" est beaucoup plus proche de \"Recettes avec viande\" que de tout autre chose, et \"Falafel\" est plus proche de \"Recettes sans viande\" que de \"Recettes avec viande.\" Cependant, \"Cheeseburger au bacon\" est beaucoup plus proche de \"Recettes sans viande\" que \"Falafel.\"\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png\" class=\"kg-image\" alt=\"Une projection 2D d'embeddings hypothétiques.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--61-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Une projection 2D d'embeddings hypothétiques.</span></figcaption></figure>\n\nEn regardant uniquement les embeddings, nous pourrions conclure que les cheeseburgers au bacon sont un meilleur exemple de recette sans viande que le falafel.\n\nPour éviter cela, nous entraînons nos modèles avec des données synthétiques. Nous utilisons un LLM pour générer des paires de phrases avec des polarités opposées – comme \"X avec Y\" / \"X sans Y\" – et entraînons nos modèles d'embedding à éloigner ces paires. Nous utilisons également des données synthétiques pour d'autres types de <a href=\"https://finetuner.jina.ai/advanced-topics/negative-mining/?ref=jina-ai-gmbh.ghost.io\">negative mining</a> ciblé, un ensemble de techniques utilisées pour améliorer des aspects spécifiques des performances des modèles d'IA en leur présentant des données organisées.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png\" class=\"kg-image\" alt=\"Une projection 2D d'embeddings hypothétiques après amélioration du modèle sous-jacent.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--62-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Une projection 2D d'embeddings hypothétiques après amélioration du modèle sous-jacent avec des paires de phrases à polarité inversée.</span></figcaption></figure>\n\nNous utilisons également l'IA générative pour entraîner des <a href=\"https://jina.ai/news/elevate-your-code-search-with-new-jina-code-embeddings/?ref=jina-ai-gmbh.ghost.io\">modèles d'embedding pour les langages de programmation</a>, tirant parti des grands modèles qui génèrent de nombreux exemples de code, afin que nous puissions correctement intégrer même les fonctionnalités assez obscures de langages et frameworks spécifiques.\n\nLa distillation de modèle est essentielle à notre façon de produire des <a href=\"https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny?ref=jina-ai-gmbh.ghost.io\">modèles compacts qui économisent les ressources informatiques</a>. La distillation est beaucoup plus efficace et fiable que l'entraînement à partir de zéro, et nos résultats montrent qu'un modèle distillé peut toujours avoir des performances de premier ordre. Le tableau ci-dessous montre les modèles de reranking distillés de Jina AI comparés au reranker de base utilisé pour les entraîner et à d'autres modèles avec beaucoup plus de paramètres mais des performances plus faibles.\n\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Modèle</th>\n<th>Score BEIR</th>\n<th>Nombre de paramètres</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td><code>jina-reranker-v1-base-en</code></td>\n<td>52.45</td>\n<td>137M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distillé</td>\n<td><code>jina-reranker-v1-turbo-en</code></td>\n<td>49.60</td>\n<td>38M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distillé</td>\n<td><code>jina-reranker-v1-tiny-en</code></td>\n<td>48.54</td>\n<td>33M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-base-v1</code></td>\n<td>49.19</td>\n<td>184M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-xsmall-v1</code></td>\n<td>48.80</td>\n<td>71M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>bge-reranker-base</code></td>\n<td>47.89</td>\n<td>278M</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n\nNous savons que l'IA peut être un investissement coûteux et que les entreprises sont de plus en plus conscientes de leurs obligations morales et légales de réduire leurs émissions de carbone. Nous en sommes également conscients. La distillation de modèle est un élément important de notre réponse à ces préoccupations.\n\n## Laissez-nous vous aider à naviguer dans l'IA\n\nJina AI s'engage à apporter aux entreprises des solutions d'IA abordables, efficaces et fonctionnelles. Nous pouvons nous intégrer à votre infrastructure cloud existante sur <a href=\"https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions?ref=jina-ai-gmbh.ghost.io\">Azure</a> et <a href=\"https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker?ref=jina-ai-gmbh.ghost.io\">AWS</a>. Nous fournissons des <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">API web</a> qui respectent des normes strictes de sécurité et de confidentialité et ne conservent pas vos données pour notre propre entraînement. Nous pouvons vous aider à installer nos <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">modèles open source</a> sur votre propre matériel, gardant toute votre opération en interne.\n\nIl peut être difficile de séparer le battage médiatique de la technologie et de rester au fait des meilleures pratiques dans ce domaine en rapide évolution. Laissez-nous faire cela pour vous.",
  "comment_id": "6639e8e1af8f52000115be49",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-05-07T10:40:01.000+02:00",
  "updated_at": "2024-07-08T21:10:35.000+02:00",
  "published_at": "2024-05-07T16:00:26.000+02:00",
  "custom_excerpt": "AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let’s find out!",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "6342c5b4393501004d1c8b2c",
      "name": "Insights",
      "slug": "insights",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "6342c5b4393501004d1c8b2c",
    "name": "Insights",
    "slug": "insights",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/",
  "excerpt": "L'IA qui crée de l'IA ! Est-ce la fin du monde ? Ou simplement un nouvel outil permettant aux modèles de réaliser un travail à valeur ajoutée ? Découvrons-le !",
  "reading_time": 12,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract depiction of a brain in purple and pink hues with a fluid, futuristic design against a blue and purple background.",
  "feature_image_caption": null
}