{
  "slug": "jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking",
  "id": "66cd8fc6e84873000133d63d",
  "uuid": "e995c4d9-1832-4e2a-8108-e8453f5c82c5",
  "title": "Jina ColBERT v2 : Système de recherche par interaction tardive multilingue pour l'embedding et le reranking",
  "html": "<p>Aujourd'hui, nous sommes ravis de présenter Jina ColBERT v2 (<code>jina-colbert-v2</code>), un modèle avancé de recherche à interaction tardive basé sur l'architecture ColBERT. Ce nouveau modèle de langage améliore les performances de <code>jina-colbert-v1-en</code> et ajoute le support multilingue ainsi que des dimensions de sortie dynamiques.</p><p>Cette nouvelle version met en avant les fonctionnalités suivantes :</p><ul><li><strong>Performances de recherche supérieures</strong> par rapport au ColBERT-v2 original (+6,5 %) et à notre version précédente, <code>jina-colbert-v1-en</code> (+5,4 %).</li><li><strong>Support multilingue</strong> pour 89 langues, offrant de solides performances dans les principales langues mondiales.</li><li><strong>Tailles d'embedding de sortie contrôlables par l'utilisateur</strong> grâce à l'apprentissage de représentation Matryoshka, permettant aux utilisateurs d'équilibrer flexiblement entre efficacité et précision.</li></ul><h2 id=\"technical-summary-of-jina-colbert-v2\">Résumé Technique de <code>jina-colbert-v2</code></h2><p>Le rapport technique complet est disponible sur arXiv :</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2408.16672?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever</div><div class=\"kg-bookmark-description\">Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Rohan Jha</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th><code>jina-colbert-v2</code></th>\n<th><code>jina-colbert-v1-en</code></th>\n<th>Original ColBERTv2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Moyenne de 14 tâches<br/>BEIR en anglais</td>\n<td><b>0.521</b></td>\n<td>0.494</td>\n<td>0.489</td>\n</tr>\n<tr>\n<td>Multilingue</td>\n<td><b>89 langues</b></td>\n<td>Anglais uniquement</td>\n<td>Anglais uniquement</td>\n</tr>\n<tr>\n<td>Dimensions de sortie</td>\n<td><b>128, 96, ou 64</b></td>\n<td>128 fixe</td>\n<td>128 fixe</td>\n</tr>\n<tr>\n<td>Longueur max. requête</td>\n<td>32 tokens</td>\n<td>32 tokens</td>\n<td>32 tokens</td>\n</tr>\n<tr>\n<td>Longueur max. document</td>\n<td>8192 tokens</td>\n<td>8192 tokens</td>\n<td>512 tokens</td>\n</tr>  \n\n<tr>\n<td>Paramètres</td>\n<td>560M</td>\n<td>137M</td>\n<td>110M</td>\n</tr>\n<tr>\n<td>Taille du modèle</td>\n<td>1.1GB</td>\n<td>550MB</td>\n<td>438MB</td>\n</tr>\n\n\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"asymmetric-embedding-in-colbert\">Embedding Asymétrique dans ColBERT</h2><p>ColBERT s'appuie sur l'architecture BERT en ajoutant une <strong>interaction tardive</strong> et un encodage <strong>asymétrique</strong> requête-document.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">What is ColBERT and Late Interaction and Why They Matter in Search?</div><div class=\"kg-bookmark-description\">Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>La nature asymétrique de ColBERT signifie que lors de l'utilisation de modèles comme <code>jina-colbert-v2</code> ou <code>jina-colbert-v1-en</code>, vous devez spécifier si vous intégrez une requête, un document, ou les deux (à des fins de reclassement). Cette flexibilité supplémentaire améliore les performances par rapport aux modèles d'embedding homogènes dans les tâches de recherche.</p><h2 id=\"multilingual-support-for-over-89-languages\">Support Multilingue Pour Plus de 89 Langues</h2><p>Jina ColBERT v2 dispose de capacités multilingues étendues, conçues pour répondre aux exigences des applications modernes de recherche d'information et d'IA globalisées. Le corpus d'entraînement de <code>jina-colbert-v2</code> intègre 89 langues, avec des étapes d'entraînement supplémentaires pour les principales langues internationales, notamment <strong>l'arabe, le chinois, l'anglais, le français, l'allemand, le japonais, le russe et l'espagnol</strong>, ainsi que les <strong>langages de programmation</strong>. L'entraînement incluait également un corpus de textes bilingues alignés pour exploiter les potentiels multilingues, permettant la correspondance entre requêtes et documents dans différentes langues lors des tâches de reclassement/recherche.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Distribution-of-the-languages-in-the-training-corpus-at-the-pretrained-stage--3-.svg\" class=\"kg-image\" alt=\"Graphique de la distribution des langues dans les données d'entraînement, soulignant la dominance de l'anglais et du chinois.\" loading=\"lazy\" width=\"1456\" height=\"743\"><figcaption><span style=\"white-space: pre-wrap;\">Distribution des données du dataset de pré-entraînement par langue (spécifiée par le code </span><a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ISO-639</span></a><span style=\"white-space: pre-wrap;\">) en échelle logarithmique.</span></figcaption></figure><p>Aujourd'hui, Jina ColBERT v2 se distingue comme <strong>le seul modèle de type ColBERT multilingue</strong> qui génère des embeddings compacts, surpassant significativement la recherche basée sur BM25 dans toutes les langues testées sur les benchmarks MIRACL.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-Multilingual-Data--1-.svg\" class=\"kg-image\" alt=\"Graphique en barres comparant les performances de jina-colbert-v2 et BM25 sur 20 langues pour des tâches multilingues.\" loading=\"lazy\" width=\"691\" height=\"426\"><figcaption><span style=\"white-space: pre-wrap;\">Performance de Jina ColBERT v2 sur 16 langues, comparée à BM25, sur les benchmarks MIRACL.</span></figcaption></figure><p>De plus, sur les tâches de recherche en langue anglaise, Jina ColBERT v2 dépasse les performances de son prédécesseur <code>jina-colbert-v1-en</code> et du modèle ColBERT v2 original, avec des performances comparables au modèle anglais hautement spécialisé <a href=\"https://huggingface.co/answerdotai/answerai-colbert-small-v1?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">AnswerAI-ColBERT-small</a>.</p>\n<!--kg-card-begin: html-->\n<table class=\"simple-table\">\n  <tbody>\n<thead>\n<tr>\n      <th><strong>Nom du Modèle</strong></th>\n      <th><strong>Score moyen<br>(14 benchmarks BEIR anglais)<br></strong></th>\n      <th><strong>Support Multilingue</strong></th>\n  </tr>\n    </thead>\n    <tr>\n      <td><code>jina-colbert-v2</code></td>\n      <td>0.521</td>\n      <td>Multilingue</td>\n    </tr>\n    <tr>\n      <td><code>jina-colbert-v1-en</code></td>\n      <td>0.494</td>\n      <td>Anglais uniquement</td>\n    </tr>\n    <tr>\n      <td>ColBERT v2.0</td>\n      <td>0.489</td>\n      <td>Anglais uniquement</td>\n    </tr>\n    <tr>\n      <td>AnswerAI-ColBERT-small</td>\n      <td>0.549</td>\n      <td>Anglais uniquement</td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-English-only-datasets-from-BEIR--2-.svg\" class=\"kg-image\" alt=\"Graphique en barres montrant les évaluations des modèles sur les datasets BEIR en anglais, avec plusieurs modèles comme 'jina-colbert' et 'BM25'.\" loading=\"lazy\" width=\"1088\" height=\"712\"><figcaption><span style=\"white-space: pre-wrap;\">Évaluation de jina-colbert-v2 sur une sélection de datasets en anglais du benchmark BEIR.</span></figcaption></figure><h2 id=\"matryoshka-representation-learning\">Apprentissage de Représentation Matryoshka</h2><p>L'<a href=\"https://arxiv.org/abs/2205.13147?ref=jina-ai-gmbh.ghost.io\">Apprentissage de Représentation Matryoshka</a> est une technique d'entraînement de modèles permettant de supporter différentes tailles de vecteurs de sortie tout en minimisant toute perte de précision. Nous entraînons les couches cachées du réseau avec plusieurs têtes de projection linéaire différentes — les couches finales d'un réseau de neurones — chacune supportant une taille de sortie différente. <strong>Jina ColBERT v2 supporte des vecteurs de sortie de 128, 96 et 64 dimensions.</strong></p><p>Jina ColBERT v2 produit par défaut des embeddings de sortie de 128 dimensions, mais peut produire des dimensions de 96 et 64 qui ont des performances presque identiques tout en étant respectivement 25 % et 50 % plus courts.</p><p>Le tableau ci-dessous montre la performance <a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain?ref=jina-ai-gmbh.ghost.io\">nDGC</a> du<code>jina-colbert-v2</code> pour les dix premiers résultats (<em>nDGC@10</em>) sur six jeux de données du benchmark BEIR. Vous pouvez constater que la différence de performance entre 128 dimensions et 96 est à peine de 1% et moins de 1,5% entre 128 et 64 dimensions.</p>\n<!--kg-card-begin: html-->\n<table id=\"b838dc78-1321-499e-98e7-63e3b5c8e910\" class=\"simple-table\"><tbody><thead id=\"177f4349-0620-4947-a3ce-01e598395ed7\"><tr><th id=\"<\\ml\" class=\"\"><strong>Dimensions de Sortie</strong></th><th id=\"<NYX\" class=\"\"><strong>Score </strong><strong>Moyen</strong><strong><br>(nDGC@10 pour 6 benchmarks)<br></strong></th></tr></thead><tr id=\"9199b56b-0513-4c99-a2a7-29cde915c3b9\"><td id=\"<\\ml\" class=\"\">128</td><td id=\"<NYX\" class=\"\">0.565</td></tr><tr id=\"af4d45fc-ebf4-4e1f-b5b0-1807a1cb889b\"><td id=\"<\\ml\" class=\"\">96</td><td id=\"<NYX\" class=\"\">0.558</td></tr><tr id=\"ecf7eac9-5c56-47e6-ab27-0ddb4659e263\"><td id=\"<\\ml\" class=\"\">64</td><td id=\"<NYX\" class=\"\">0.556</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Performance-on-selected-BEIR-benchmarks.svg\" class=\"kg-image\" alt=\"Graphique à barres des benchmarks BEIR, mettant en évidence les scores des jeux de données de nfcorpus à msmarco, avec jina-colbert-v2.64 excellant.\" loading=\"lazy\" width=\"732\" height=\"538\"><figcaption><span style=\"white-space: pre-wrap;\">Performance de Jina ColBERT v2 à différentes dimensions de sortie.</span></figcaption></figure><p>Réduire la taille des vecteurs de sortie permet d'économiser de l'espace et d'accélérer les applications comme la recherche d'informations basée sur les vecteurs qui doivent comparer différents vecteurs ou mesurer la distance entre eux.</p><p>Cela a des conséquences significatives sur les coûts, ne serait-ce qu'en termes de stockage réduit. Par exemple, en utilisant <a href=\"https://cloud.qdrant.io/calculator?ref=jina-ai-gmbh.ghost.io\">le calculateur de coûts cloud de Qdrant</a>, le stockage de 100 millions de documents sur AWS avec des vecteurs de 128 dimensions pour chacun a un <a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=128&ref=jina-ai-gmbh.ghost.io\">coût estimé de 1 319,24 USD par mois</a>. À 64 dimensions, ce coût <a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=64&ref=jina-ai-gmbh.ghost.io\">tombe à 659,62 USD</a>.</p><h2 id=\"getting-started-with-jina-colbert-v2\">Débuter avec Jina ColBERT v2</h2><p>Jina ColBERT v2 est disponible via l'API Jina Search Foundation, le <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">marketplace AWS</a>, et <a href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\">sur Azure</a>. Il est également disponible pour une <em>utilisation non commerciale uniquement</em> (<a href=\"https://www.creativecommons.org/licenses/by-nc/4.0/deed.en?ref=jina-ai-gmbh.ghost.io\">CC BY-NC-4.0</a>) via <a href=\"https://huggingface.co/jinaai/jina-colbert-v2?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>.</p><h3 id=\"via-jina-search-foundation-api\">Via l'API Jina Search Foundation</h3><h4 id=\"for-embedding\">Pour l'Embedding</h4><p>La commande <code>curl</code> suivante montre comment spécifier l'entrée et les options pour obtenir des embeddings de documents à partir de <code>jina-colbert-v2</code> via l'API Jina Embeddings. Pour obtenir des vecteurs de la taille souhaitée, spécifiez 128 ou 64 pour le paramètre <code>dimensions</code>. Ce paramètre est optionnel et la valeur par défaut est 128.</p><p>Les documents d'entrée seront tronqués s'ils dépassent 8192 tokens.</p><p>Spécifiez votre clé API Jina dans l'en-tête d'autorisation <code>Authorization: Bearer &lt;YOUR JINA API KEY&gt;</code> :</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # Ou 64 pour des vecteurs de taille réduite\n\t\"input_type\": \"document\", # Pour les embeddings de requête voir ci-dessous\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your document text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each text can be up to 8192 tokens long\"\n    ]}'\n</code></pre><p>Pour obtenir des embeddings de requête, définissez le paramètre <code>input_type</code> sur <code>query</code> au lieu de <code>document</code>. Notez que les requêtes ont des limites de taille beaucoup plus strictes que les documents. Elles seront tronquées à 32 tokens. L'encodage des requêtes renverra <em>toujours</em> 32 tokens, y compris les embeddings pour le padding si la longueur est inférieure à 32 tokens.</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # Ou 64 pour des vecteurs de taille réduite\t\n\t\"input_type\": \"query\", # Doit être spécifié pour les embeddings de requête\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your query text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each query text can be up to 32 tokens long\"\n    ]}'\n</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">API d'Embedding</div><div class=\"kg-bookmark-description\">Embeddings multimodaux et bilingues à contexte long pour votre recherche et RAG.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"for-reranking\">Pour le Reranking</h4><p>Pour utiliser <code>jina-colbert-v2</code> via l'API Jina Reranker, en passant une requête et plusieurs documents et en obtenant des scores de correspondance classables, construisez votre requête comme celle ci-dessous :</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/rerank \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n      \"model\": \"jina-colbert-v2\",\n      \"query\": \"What is the population of Berlin?\",\n      \"top_n\": 3,\n      \"documents\": [\n        \"Berlin's population grew by 0.7 percent in 2023 compared with the previous year. Accordingly, around 27,300 more residents lived in Berlin at the end of the last year than in 2022. Those of 30 to under 40 years old form the numerically largest age group. With roughly 881,000 foreign residents from around 170 nations and an average age of the population of 42.5 years old.\",\n        \"Mount Berlin is a glacier-covered volcano in Marie Byrd Land, Antarctica, 100 kilometres (62 mi) from the Amundsen Sea. It is a roughly 20-kilometre-wide (12 mi) mountain with parasitic vents that consists of two coalesced volcanoes: Berlin proper with the 2-kilometre-wide (1.2 mi) Berlin Crater and Merrem Peak with a 2.5-by-1-kilometre-wide (1.55 mi × 0.62 mi) crater, 3.5 kilometres (2.2 mi) away from Berlin.\",\n        \"Population as of 31.12.2023 by nationality and federal states Land\\\\tTotal\\\\tGermans\\\\tForeigners\\\\tincluding EU-states number\\\\t%\\\\tnumber\\\\t%\",\n        \"The urban area of Berlin has a population of over 4.5 million and is therefore the most populous urban area in Germany. The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region, and the sixth-biggest metropolitan region by GDP in the European Union.\",\n        \"Irving Berlin (born Israel Beilin) was an American composer and songwriter. His music forms a large part of the Great American Songbook. Berlin received numerous honors including an Academy Award, a Grammy Award, and a Tony Award.\",\n        \"Berlin is a town in the Capitol Planning Region, Connecticut, United States. The population was 20,175 at the 2020 census.\",\n        \"Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\",\n        \"Berlin, Berlin ist eine für die ARD produzierte Fernsehserie, die von 2002 bis 2005 im Vorabendprogramm des Ersten ausgestrahlt wurde. Regie führten unter anderem Franziska Meyer Price, Christoph Schnee, Sven Unterwaldt Jr. und Titus Selge.\"\n        ]\n    }'</code></pre><p>Notez l'argument <code>top_n</code>, qui spécifie le nombre de documents que vous souhaitez récupérer. Par exemple, si votre application n'utilise que la meilleure correspondance, définissez <code>top_n</code> à 1.</p><p>Pour des exemples de code en Python et autres langages et frameworks de programmation, rendez-vous sur la <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\">page de l'API Jina AI Embeddings</a>, ou sélectionnez <code>jina-colbert-v2</code> dans le menu déroulant sur la <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">page de l'API Jina Reranker</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">API Reranker</div><div class=\"kg-bookmark-description\">Maximisez la pertinence de la recherche et la précision du RAG en toute simplicité.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-reranker-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"via-stanford-colbert\">Via Stanford ColBERT</h3><p>Vous pouvez aussi utiliser Jina ColBERT v2 comme remplacement direct de <a href=\"https://github.com/stanford-futuredata/ColBERT?ref=jina-ai-gmbh.ghost.io\">ColBERT v2</a> dans la bibliothèque Stanford ColBERT. Spécifiez simplement <code>jinaai/jina-colbert-v2</code> comme source du modèle :</p><pre><code class=\"language-python\">from colbert.infra import ColBERTConfig\nfrom colbert.modeling.checkpoint import Checkpoint\n\nckpt = Checkpoint(\"jinaai/jina-colbert-v2\", colbert_config=ColBERTConfig())\ndocs = [\"Your list of texts\"] \nquery_vectors = ckpt.queryFromText(docs)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Vous devez installer <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> et <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code> pour utiliser le code ci-dessus.</div></div><h3 id=\"via-ragatouille\">Via RAGatouille</h3><p>Jina ColBERT v2 est également intégré à <a href=\"https://github.com/AnswerDotAI/RAGatouille?ref=jina-ai-gmbh.ghost.io\">RAGatouille</a>. Vous pouvez le télécharger et l'utiliser via la méthode <code>RAGPretrainedModel.from_pretrained()</code> :</p><pre><code class=\"language-python\">from ragatouille import RAGPretrainedModel\n\nRAG = RAGPretrainedModel.from_pretrained(\"jinaai/jina-colbert-v2\")\ndocs = [\"Your list of texts\"]\nRAG.index(docs, index_name=\"your_index_name\")\nquery = \"Your query\"\nresults = RAG.search(query)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Vous devez installer <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> et <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code> pour utiliser le code ci-dessus.</div></div><h3 id=\"via-qdrant\">Via Qdrant</h3><p>Depuis la version 1.10, Qdrant a ajouté le <a href=\"https://qdrant.tech/blog/qdrant-1.10.x/?ref=jina-ai-gmbh.ghost.io\">support</a> pour les multi-vecteurs et les modèles à interaction tardive. Les utilisateurs existants des moteurs Qdrant, qu'ils soient locaux ou en version cloud gérée, peuvent en bénéficier en intégrant directement <code>jina-colbert-v2</code> en utilisant le client Qdrant.</p><p><strong>Création d'une nouvelle Collection utilisant l'opération MAX_SIM</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nqdrant_client.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config={\n        \"colbert\": models.VectorParams(\n            size=128,\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM\n            ),\n        )\n    }\n)</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Il est essentiel de définir correctement le paramètre <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">multivector_config</code> pour utiliser les modèles de type ColBERT dans Qdrant.</div></div><p><strong>Insertion de Documents Dans les Collections Multi-vecteurs</strong></p><pre><code class=\"language-Python\">import requests\nfrom qdrant_client import QdrantClient, models\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\ndata = {\n    'model': 'jina-colbert-v2',\n    'input_type': 'query',\n    'embedding_type': 'float',\n    'input': [\n        'Your text string goes here',\n        'You can send multiple texts',\n        'Each text can be up to 8192 tokens long'\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nrows = response.json()[\"data\"]\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nfor i, row in enumerate(rows):\n    qdrant_client.upsert(\n        collection_name=\"{collection_name}\",\n        points=[\n            models.PointStruct(\n                id=i,  \n                vector=row[\"embeddings\"],  \n                payload={\"text\": data[\"input\"][i]} \n            )\n        ],\n    )</code></pre><p><strong>Interrogation des Collections</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\nimport requests\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\n\ndata = {\n    'model': 'jina-colbert-v2',\n    \"input_type\": \"query\",\n    \"embedding_type\": \"float\",\n    \"input\": [\n        \"how many tokens in an input do Jina AI's embedding models support?\"\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nvector = response.json()[\"data\"][0][\"embeddings\"]\n\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nresults = qdrant_client.query_points(\n    collection_name=\"{collection_name}\",\n    query=vector,\n)\n\nprint(results)</code></pre><h3 id=\"summary\">Résumé</h3><p>Jina ColBERT v2 (<code>jina-colbert-v2</code>) s'appuie sur les hautes performances de <code>jina-colbert-v1-en</code> et étend ses capacités à un large éventail de langues mondiales. Avec la prise en charge de plusieurs tailles d'embedding, <code>jina-colbert-v2</code> permet aux utilisateurs d'ajuster le compromis précision/efficacité pour répondre à leurs cas d'utilisation spécifiques, offrant potentiellement des économies significatives en temps et en coûts de calcul.</p><p>Ce modèle combine toutes ces fonctionnalités dans un package unique à prix compétitif, accessible via une API web intuitive et compatible avec tout framework de calcul prenant en charge les requêtes HTTP. <a href=\"https://jina.ai/?sui=&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Essayez-le par vous-même</a> avec 1 million de tokens gratuits pour voir comment il peut améliorer vos applications et processus.</p>",
  "comment_id": "66cd8fc6e84873000133d63d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-08-27T10:35:18.000+02:00",
  "updated_at": "2024-09-09T07:43:38.000+02:00",
  "published_at": "2024-08-30T09:19:58.000+02:00",
  "custom_excerpt": "Jina ColBERT v2 supports 89 languages with superior retrieval performance, user-controlled output dimensions, and 8192 token-length. ",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking/",
  "excerpt": "Jina ColBERT v2 prend en charge 89 langues avec des performances de recherche supérieures, des dimensions de sortie contrôlées par l'utilisateur et une longueur de token de 8192.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dark-themed coding interface displaying English and Japanese characters with \"JINA COLBERT V2\" highlighted in the center.",
  "feature_image_caption": null
}