{
  "slug": "jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face",
  "id": "65b3adb510ff9f0001c50c4d",
  "uuid": "b082269a-4358-4a82-a70c-02da2ebcb6d3",
  "title": "Les modèles bilingues Jina Embeddings v2 sont maintenant open source sur Hugging Face",
  "html": "<p>Jina AI a publié ses modèles d'embedding bilingues open-source à la pointe de la technologie pour les paires de langues <a href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\">allemand-anglais</a> et <a href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\">chinois-anglais</a> via Hugging Face.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ich bin ein Berliner: German-English Bilingual Embeddings with 8K Token Length</div><div class=\"kg-bookmark-description\">Jina AI introduces a German/English bilingual embedding model, featuring an extensive 8,192-token length, specifically designed to support German businesses thriving in the U.S. market.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Explore-image-storytelling-beyond-pixels--33-.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">8K Token-Length Bilingual Embeddings Break Language Barriers in Chinese and English</div><div class=\"kg-bookmark-description\">The first bilingual Chinese-English embedding model with 8192 token-length.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><p>Dans ce tutoriel, nous allons passer en revue une installation et un cas d'utilisation très simples qui couvriront :</p><ol><li>Le téléchargement des modèles Jina Embedding depuis Hugging Face.</li><li>L'utilisation des modèles pour obtenir des encodages de textes en allemand et en anglais.</li><li>La création d'un moteur de recherche neuronal rudimentaire basé sur les embeddings pour des requêtes multilingues.</li></ol><p>Nous vous montrerons comment utiliser Jina Embeddings pour écrire des requêtes en anglais qui retrouvent des textes correspondants en allemand et vice-versa.</p><p>Ce tutoriel fonctionne de la même manière pour le modèle chinois. Suivez simplement les instructions dans la section (vers la fin) intitulée <a href=\"#querying-in-chinese\" rel=\"noreferrer\"><strong>Querying in Chinese</strong></a> pour obtenir le modèle bilingue chinois-anglais et un exemple de document en chinois.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-de?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-de · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-de.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-zh?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-zh · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><h2 id=\"bilingual-embedding-models\">Modèles d'Embedding Bilingues</h2><p>Un modèle d'embedding bilingue est un modèle qui projette des textes dans deux langues — l'allemand et l'anglais dans ce tutoriel, le chinois et l'anglais pour le modèle chinois — dans le même espace d'embedding. Et il le fait de telle sorte que si un texte allemand et un texte anglais signifient la même chose, leurs vecteurs d'embedding correspondants seront proches l'un de l'autre.</p><p>Ces modèles sont très bien adaptés aux applications de recherche d'information multilingue, ce que nous montrerons dans ce tutoriel, mais peuvent également servir de base pour les chatbots basés sur RAG, la catégorisation de textes multilingues, la synthèse, l'analyse des sentiments et toute autre application utilisant des embeddings. En utilisant ces modèles, vous pouvez traiter les textes dans les deux langues comme s'ils étaient écrits dans la même langue.</p><p>Bien que de nombreux grands modèles de langage prétendent prendre en charge de nombreuses langues différentes, ils ne les supportent pas toutes de manière égale. Il y a des questions croissantes concernant les <a href=\"https://aclanthology.org/2023.findings-eacl.89/?ref=jina-ai-gmbh.ghost.io\">biais causés par la domination de l'anglais sur Internet</a> et les sources d'entrée déformées par la <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">publication généralisée en ligne de textes traduits automatiquement</a>. En se concentrant sur deux langues, nous pouvons mieux contrôler la qualité des embeddings pour les deux, minimisant les biais tout en produisant des modèles beaucoup plus petits avec des performances similaires ou supérieures aux modèles géants qui prétendent gérer des dizaines de langues.</p><p>Les modèles bilingues Jina Embeddings v2 prennent en charge 8 192 tokens de contexte d'entrée, leur permettant non seulement de supporter deux langues, mais aussi de traiter des segments de texte relativement importants par rapport aux modèles comparables. Cela les rend idéaux pour des cas d'utilisation plus complexes où beaucoup plus d'informations textuelles doivent être traitées en embeddings.</p><h2 id=\"follow-along-on-google-colab\">Suivez le tutoriel sur Google Colab</h2><p>Ce tutoriel dispose d'un <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">notebook d'accompagnement</a> que vous pouvez exécuter sur <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>, ou localement sur votre propre système.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/feat-embeddings-notebook/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colaboratory</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://ssl.gstatic.com/colaboratory-static/common/cce4fce8bbe78d8bdc0c77a288df9fa7/img/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" alt=\"\"></div></a></figure><h2 id=\"installing-the-prerequisites\">Installation des Prérequis</h2><p>Assurez-vous que l'environnement actuel dispose des bibliothèques nécessaires installées. Vous aurez besoin de la dernière version de <a href=\"https://pypi.org/project/transformers/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>transformers</code></a>, donc même si elle est déjà installée, exécutez :</p><pre><code class=\"language-bash\">pip install -U transformers \n</code></pre><p>Ce tutoriel utilisera la <a href=\"https://faiss.ai/?ref=jina-ai-gmbh.ghost.io\">bibliothèque FAISS de Meta</a> pour effectuer la recherche et la comparaison de vecteurs. Pour l'installer, exécutez :</p><pre><code class=\"language-bash\">pip install faiss-cpu\n</code></pre><p>Nous utiliserons également <a href=\"https://www.crummy.com/software/BeautifulSoup/?ref=jina-ai-gmbh.ghost.io\">Beautiful Soup</a> pour traiter les données d'entrée dans ce tutoriel, donc assurez-vous qu'il est installé :</p><pre><code class=\"language-bash\">pip install bs4\n</code></pre><h2 id=\"access-to-hugging-face\">Accès à Hugging Face</h2><p>Vous aurez besoin d'un accès à Hugging Face, en particulier d'un compte et d'un jeton d'accès pour télécharger les modèles.</p><p><strong>Si vous n'avez pas de compte sur Hugging Face :</strong></p><p>Allez sur <a href=\"https://huggingface.co/?ref=jina-ai-gmbh.ghost.io\">https://huggingface.co/</a> et vous devriez voir un bouton \"Sign Up\" en haut à droite de la page. Cliquez dessus et suivez les instructions pour créer un nouveau compte.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png\" class=\"kg-image\" alt=\"La page d'accueil de Hugging Face, avec le bouton &quot;Sign Up&quot; mis en évidence.\" loading=\"lazy\" width=\"1088\" height=\"887\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/01/Untitled--26-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/01/Untitled--26-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png 1088w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Une fois connecté à votre compte :</strong></p><p>Suivez les instructions <a href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\">sur le site web de Hugging Face</a> pour obtenir un jeton d'accès.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">User access tokens</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://huggingface.co/front/thumbnails/docs/hub.png\" alt=\"\"></div></a></figure><p>Vous devez copier ce jeton dans une variable d'environnement appelée <code>HF_TOKEN</code>. Si vous travaillez dans un notebook (sur <a href=\"https://colab.research.google.com/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>, par exemple) ou si vous le définissez en interne dans un programme Python, utilisez le code Python suivant :</p><pre><code class=\"language-python\">import os\n\nos.environ['HF_TOKEN'] = \"&lt;your token here&gt;\"\n</code></pre><p>Dans votre shell, utilisez la syntaxe fournie pour définir une variable d'environnement. Dans <code>bash</code> :</p><pre><code class=\"language-bash\">export HF_TOKEN=\"&lt;your token here&gt;\"\n</code></pre><h2 id=\"download-jina-embeddings-v2-for-german-and-english\">Télécharger Jina Embeddings v2 pour l'allemand et l'anglais</h2><p>Une fois votre jeton défini, vous pouvez télécharger le modèle bilingue allemand-anglais Jina Embeddings en utilisant la bibliothèque <code>transformers</code> :</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-de', trust_remote_code=True)\n</code></pre><p>Cela peut prendre plusieurs minutes la première fois que vous le faites, mais le modèle sera ensuite mis en cache localement, donc ne vous inquiétez pas si vous redémarrez ce tutoriel plus tard.</p><h2 id=\"download-english-language-data\">Télécharger les données en langue anglaise</h2><p>Pour ce tutoriel, nous allons obtenir la version anglaise du livre <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git : Everything You Need to Know About Git</em></a>. Ce livre est également disponible en chinois et en allemand, que nous utiliserons plus tard dans ce tutoriel.</p><p>Pour télécharger la version EPUB, exécutez la commande suivante :</p><pre><code class=\"language-bash\">wget -O progit-en.epub https://open.umn.edu/opentextbooks/formats/3437</code></pre><p>Cela copie le livre dans un fichier nommé <code>progit-en.epub</code> dans le répertoire local.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--27-.png\" class=\"kg-image\" alt=\"La couverture de l'édition papier de &quot;Pro Git&quot; par Scott Chacon et Ben Straub.\" loading=\"lazy\" width=\"490\" height=\"647\"><figcaption><span style=\"white-space: pre-wrap;\">La couverture de l'édition papier.</span></figcaption></figure><p>Alternativement, vous pouvez simplement visiter le lien <a href=\"https://open.umn.edu/opentextbooks/formats/3437?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">https://open.umn.edu/opentextbooks/formats/3437</a> pour le télécharger sur un disque local. Il est disponible sous la <a href=\"https://creativecommons.org/licenses/by-nc-sa/3.0/?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">licence Creative Commons Attribution Non Commercial Share Alike 3.0</a>.</p><h2 id=\"processing-the-data\">Traitement des données</h2><p>Ce texte particulier a une structure interne de sections hiérarchiques, que nous pouvons facilement trouver en recherchant la balise <code>&lt;section&gt;</code> dans les données XHTML sous-jacentes. Le code ci-dessous lit le fichier EPUB et le divise en utilisant la structure interne d'un fichier EPUB et la balise <code>&lt;section&gt;</code>, puis convertit chaque section en texte brut sans balises XHTML. Il crée un dictionnaire Python dont les clés sont un ensemble de chaînes indiquant l'emplacement de chaque section dans le livre, et dont les valeurs sont le contenu en texte brut de cette section.</p><pre><code class=\"language-python\">from zipfile import ZipFile\nfrom bs4 import BeautifulSoup\nimport copy\n\ndef decompose_epub(file_name):\n    \n    def to_top_text(section):\n        selected = copy.copy(section)\n\t\t\t\twhile next_section := selected.find(\"section\"):\n            next_section.decompose()\n        return selected.get_text().strip()\n\n    ret = {}\n    with ZipFile(file_name, 'r') as zip:\n        for name in zip.namelist():\n            if name.endswith(\".xhtml\"):\n                data = zip.read(name)\n                doc = BeautifulSoup(data.decode('utf-8'), 'html.parser')\n                ret[name + \":top\"] = to_top_text(doc)\n                for num, sect in enumerate(doc.find_all(\"section\")):\n                    ret[name + f\"::{num}\"] = to_top_text(sect)\n    return ret\n</code></pre><p>Ensuite, exécutez la fonction <code>decompose_epub</code> sur le fichier EPUB que vous avez téléchargé précédemment :</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-en.epub\")\n</code></pre><p>La variable <code>book_data</code> contiendra maintenant 583 sections. Par exemple :</p><pre><code class=\"language-python\">print(book_data['EPUB/ch01-getting-started.xhtml::12'])\n</code></pre><p>Résultat :</p><pre><code class=\"language-Text\">The Command Line\nThere are a lot of different ways to use Git.\nThere are the original command-line tools, and there are many graphical user interfaces of varying capabilities.\nFor this book, we will be using Git on the command line.\nFor one, the command line is the only place you can run all Git commands — most of the GUIs implement only a partial subset of Git functionality for simplicity.\nIf you know how to run the command-line version, you can probably also figure out how to run the GUI version, while the opposite is not necessarily true.\nAlso, while your choice of graphical client is a matter of personal taste, all users will have the command-line tools installed and available.\nSo we will expect you to know how to open Terminal in macOS or Command Prompt or PowerShell in Windows.\nIf you don't know what we're talking about here, you may need to stop and research that quickly so that you can follow the rest of the examples and descriptions in this book.\n</code></pre><h2 id=\"generating-and-indexing-embeddings-with-jina-embeddings-v2-and-faiss\">Génération et indexation des embeddings avec Jina Embeddings v2 et FAISS</h2><p>Pour chacune des 583 sections, nous allons générer un embedding et le stocker dans un index FAISS. Les modèles Jina Embeddings v2 acceptent des entrées jusqu'à 8192 tokens, une taille suffisante pour qu'avec un livre comme celui-ci, nous n'ayons pas besoin de faire de segmentation de texte supplémentaire ni de vérifier si une section a trop de tokens. La section la plus longue du livre compte environ 12 000 caractères, ce qui, pour l'anglais normal, devrait être bien en dessous de la limite de 8k tokens.</p><p>Pour générer un seul embedding, vous utilisez la méthode <code>encode</code> du modèle que nous avons téléchargé. Par exemple :</p><pre><code class=\"language-python\">model.encode([book_data['EPUB/ch01-getting-started.xhtml::12']])\n</code></pre><p>Cela renvoie un tableau contenant un seul vecteur de 768 dimensions :</p><pre><code class=\"language-python\">array([[ 6.11135997e-02,  1.67829826e-01, -1.94809273e-01,\n         4.45595086e-02,  3.28837298e-02, -1.33441269e-01,\n         1.35364473e-01, -1.23119736e-02,  7.51526654e-02,\n        -4.25386652e-02, -6.91794455e-02,  1.03527725e-01,\n        -2.90831417e-01, -6.21018047e-03, -2.16205455e-02,\n        -2.20803712e-02,  1.50471330e-01, -3.31433356e-01,\n        -1.48741454e-01, -2.10959971e-01,  8.80039856e-02,\n\t\t\t\t....\n</code></pre><p>C'est un embedding.</p><p>Les modèles Jina Embeddings sont configurés pour permettre le traitement par lots. La taille optimale des lots dépend du matériel que vous utilisez lors de l'exécution. Une taille de lot importante risque d'épuiser la mémoire. Une petite taille de lot prendra plus de temps à traiter.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Définir <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">batch_size=5</code> a fonctionné sur Google Colab en version gratuite sans GPU, et a pris <b><strong style=\"white-space: pre-wrap;\">environ une heure</strong></b> pour générer l'ensemble complet des embeddings.</div></div><p>En production, nous recommandons d'utiliser du matériel beaucoup plus puissant ou d'utiliser le <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">service API Embedding</a> de Jina AI. Suivez le lien ci-dessous pour découvrir comment il fonctionne et comment commencer avec un accès gratuit.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">API d'Embedding</div><div class=\"kg-bookmark-description\">Performances optimales, longueur de contexte de 8192 tokens, 100 $ pour 1,25 milliard de tokens, alternative transparente à OpenAI, essai gratuit</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>Le code ci-dessous génère les embeddings et les stocke dans un index FAISS. Définissez la variable <code>batch_size</code> en fonction de vos ressources.</p><pre><code class=\"language-python\">import faiss\n\nbatch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>Dans un environnement de production, un dictionnaire Python n'est pas une façon adéquate ou performante de gérer les documents et les embeddings. Vous devriez utiliser une base de données vectorielle dédiée, qui aura ses propres instructions pour l'insertion des données.</p><h2 id=\"querying-in-german-for-english-results\">Requêtes en allemand pour des résultats en anglais</h2><p>Lorsque nous faisons une requête dans cet ensemble de textes, voici ce qui se passera :</p><ol><li>Le modèle Jina Embeddings allemand-anglais créera un embedding pour la requête.</li><li>Nous utiliserons l'index FAISS (<code>faiss_index</code>) pour obtenir l'embedding stocké ayant le cosinus le plus élevé avec l'embedding de la requête et renvoyer sa place dans l'index.</li><li>Nous rechercherons le texte correspondant dans le tableau de données vectorielles (<code>vector_data</code>) et afficherons le cosinus, l'emplacement du texte et le texte lui-même.</li></ol><p>C'est ce que fait la fonction <code>query</code> ci-dessous.</p><pre><code class=\"language-python\">def query(query_str):\n    query = model.encode([query_str], normalize_embeddings=True)\n    cosine, index = faiss_index.search(query, 1)\n    print(f\"Cosine: {cosine[0][0]}\")\n    loc, txt = vector_data[index[0][0]]\n    print(f\"Location: {loc}\\\\nText:\\\\n\\\\n{txt}\")\n</code></pre><p>Essayons-le maintenant.</p><pre><code class=\"language-python\"># Translation: \"How do I roll back to a previous version?\"\nquery(\"Wie kann ich auf eine frühere Version zurücksetzen?\")\n</code></pre><p>Résultat :</p><pre><code class=\"language-text\">Cosine: 0.5202275514602661\nLocation: EPUB/ch02-git-basics-chapter.xhtml::20\nText:\n\nUndoing things with git restore\nGit version 2.23.0 introduced a new command: git restore.\nIt's basically an alternative to git reset which we just covered.\nFrom Git version 2.23.0 onwards, Git will use git restore instead of git reset for many undo operations.\nLet's retrace our steps, and undo things with git restore instead of git reset.\n</code></pre><p>C'est un très bon choix pour répondre à la question. Essayons-en un autre :</p><pre><code class=\"language-python\"># Translation: \"What does 'version control' mean?\"\nquery(\"Was bedeutet 'Versionsverwaltung'?\")\n</code></pre><p>Résultat :</p><pre><code class=\"language-text\">Cosine: 0.5001817941665649\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nAbout Version Control\n\nWhat is \"version control\", and why should you care?\nVersion control is a system that records changes to a file or set of files over time so that you can recall specific versions later.\nFor the examples in this book, you will use software source code as the files being version controlled, though in reality you can do this with nearly any type of file on a computer.\nIf you are a graphic or web designer and want to keep every version of an image or layout (which you would most certainly want to), a Version Control System (VCS) is a very wise thing to use.\nIt allows you to revert selected files back to a previous state, revert the entire project back to a previous state, compare changes over time, see who last modified something that might be causing a problem, who introduced an issue and when, and more.\nUsing a VCS also generally means that if you screw things up or lose files, you can easily recover.\nIn addition, you get all this for very little overhead.\n</code></pre><p>Essayez avec vos propres questions en allemand pour voir à quel point cela fonctionne bien. En règle générale, lorsque vous traitez la recherche d'informations textuelles, vous devriez demander trois à cinq réponses au lieu d'une seule. La meilleure réponse n'est souvent pas la première.</p><h2 id=\"reversing-the-roles-querying-german-documents-with-english\">Inverser les rôles : Interroger des documents allemands en anglais</h2><p>Le livre <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git: Everything You Need to Know About Git</em></a> est également <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git-german?ref=jina-ai-gmbh.ghost.io\">disponible en allemand</a>. Nous pouvons utiliser ce même modèle pour faire cette démonstration avec les langues inversées.</p><p>Téléchargez l'ebook :</p><pre><code class=\"language-bash\">wget -O progit-de.epub https://open.umn.edu/opentextbooks/formats/3454\n</code></pre><p>Cela copie le livre dans un fichier nommé <code>progit-de.epub</code>. Nous le traitons ensuite de la même manière que pour le livre anglais :</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-de.epub\")\n</code></pre><p>Puis nous générons les embeddings de la même manière qu'auparavant :</p><pre><code class=\"language-python\">batch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>Nous pouvons maintenant utiliser la même fonction <code>query</code> pour rechercher en anglais des réponses en allemand :</p><pre><code class=\"language-python\">query(\"What is version control?\")\n</code></pre><p>Résultat :</p><pre><code class=\"language-text\">Cosine: 0.6719034910202026\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nWas ist Versionsverwaltung?\n\nWas ist „Versionsverwaltung\", und warum sollten Sie sich dafür interessieren?\nVersionsverwaltung ist ein System, welches die Änderungen an einer oder einer Reihe von Dateien über die Zeit hinweg protokolliert, sodass man später auf eine bestimmte Version zurückgreifen kann.\nDie Dateien, die in den Beispielen in diesem Buch unter Versionsverwaltung gestellt werden, enthalten Quelltext von Software, tatsächlich kann in der Praxis nahezu jede Art von Datei per Versionsverwaltung nachverfolgt werden.\nAls Grafik- oder Webdesigner möchte man zum Beispiel in der Lage sein, jede Version eines Bildes oder Layouts nachverfolgen zu können. Als solcher wäre es deshalb ratsam, ein Versionsverwaltungssystem (engl. Version Control System, VCS) einzusetzen.\nEin solches System erlaubt es, einzelne Dateien oder auch ein ganzes Projekt in einen früheren Zustand zurückzuversetzen, nachzuvollziehen, wer zuletzt welche Änderungen vorgenommen hat, die möglicherweise Probleme verursachen, herauszufinden wer eine Änderung ursprünglich vorgenommen hat und viele weitere Dinge.\nEin Versionsverwaltungssystem bietet allgemein die Möglichkeit, jederzeit zu einem vorherigen, funktionierenden Zustand zurückzukehren, auch wenn man einmal Mist gebaut oder aus irgendeinem Grund Dateien verloren hat.\nAll diese Vorteile erhält man für einen nur sehr geringen, zusätzlichen Aufwand.\n</code></pre><p>Le titre de cette section se traduit par <em>\"Qu'est-ce que le contrôle de version ?\"</em>, c'est donc une bonne réponse.</p><h2 id=\"querying-in-chinese\">Interrogation en chinois</h2><p>Ces exemples fonctionneront exactement de la même manière avec Jina Embeddings v2 pour le chinois et l'anglais. Pour utiliser le modèle chinois à la place, exécutez simplement :</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)\n</code></pre><p>Et pour obtenir l'édition chinoise de <em>Pro Git: Everything You Need to Know About Git</em> :</p><pre><code class=\"language-python\">wget -O progit-zh.epub https://open.umn.edu/opentextbooks/formats/3455\n</code></pre><p>Puis, traitez le livre chinois :</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-zh.epub\")\n</code></pre><p>Tout le reste du code de ce tutoriel fonctionnera de la même manière.</p><h2 id=\"the-future-more-languages-including-programming\">L'avenir : Plus de langues, y compris la programmation</h2><p>Nous déploierons davantage de modèles bilingues dans un avenir immédiat, avec l'espagnol et le japonais déjà en développement, ainsi qu'un modèle qui prend en charge l'anglais et plusieurs langages de programmation majeurs. Ces modèles sont idéalement adaptés aux entreprises internationales qui gèrent des informations multilingues, et peuvent servir de pierre angulaire pour la recherche d'informations basée sur l'IA et les modèles de langage génératifs basés sur RAG, s'intégrant dans une variété de cas d'utilisation d'IA de pointe.</p><p>Les modèles de Jina AI sont compacts et comptent parmi les meilleurs de leur catégorie, montrant qu'il n'est pas nécessaire d'avoir le plus grand modèle pour obtenir les meilleures performances. En se concentrant sur les performances bilingues, nous produisons des modèles qui sont à la fois meilleurs dans ces langues, plus faciles à adapter et plus rentables que les grands modèles entraînés sur des données non organisées.</p><p>Les Jina Embeddings sont disponibles sur <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>, sur l'<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS marketplace</a> pour une utilisation dans Sagemaker, et via l'<a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">API web Jina Embeddings</a>. Ils sont entièrement intégrés dans de nombreux frameworks de processus d'IA et bases de données vectorielles.</p><p>Consultez le <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">site web de Jina Embeddings</a> pour plus d'informations, ou contactez-nous pour discuter de la façon dont les offres de Jina AI peuvent s'intégrer dans vos processus d'entreprise.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Top-performing, 8192-token context length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure>",
  "comment_id": "65b3adb510ff9f0001c50c4d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/01/Blog-images--32-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-01-26T14:03:49.000+01:00",
  "updated_at": "2024-02-05T17:19:35.000+01:00",
  "published_at": "2024-01-26T17:14:56.000+01:00",
  "custom_excerpt": "Jina AI's open-source bilingual embedding models for German-English and Chinese-English are now on Hugging Face.\nWe’re going to walk through installation and cross-language retrieval.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face/",
  "excerpt": "Les modèles d'embedding bilingues open-source de Jina AI pour l'allemand-anglais et le chinois-anglais sont maintenant disponibles sur Hugging Face.\nNous allons voir l'installation et la recherche inter-langues.",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Colorful \"EMBEDDINGS\" text above a pile of yellow smileys on a black background with decorative lines at the top.",
  "feature_image_caption": null
}