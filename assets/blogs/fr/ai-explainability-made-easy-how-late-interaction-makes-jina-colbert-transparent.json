{
  "slug": "ai-explainability-made-easy-how-late-interaction-makes-jina-colbert-transparent",
  "id": "6672af263ce1950001eed6a7",
  "uuid": "44371108-082d-4fb0-a28d-4f86fc02ac14",
  "title": "L'explicabilité de l'IA simplifiée : Comment l'interaction tardive rend Jina-ColBERT transparent",
  "html": "<p>L'un des problèmes persistants des modèles d'IA est que les réseaux neuronaux n'expliquent pas comment ils produisent leurs résultats. Il n'est pas toujours évident de savoir dans quelle mesure cela constitue un réel problème pour l'intelligence artificielle. Quand nous demandons aux humains d'expliquer leur raisonnement, ils rationalisent systématiquement, généralement sans même se rendre compte qu'ils le font, donnant des explications les plus plausibles sans aucune indication de ce qui se passe réellement dans leur tête.</p><p>Nous savons déjà comment faire en sorte que les modèles d'IA inventent des réponses plausibles. Peut-être que l'intelligence artificielle est plus semblable aux humains à cet égard que nous ne voudrions l'admettre.</p><p>Il y a cinquante ans, le philosophe américain Thomas Nagel a écrit un essai influent intitulé <em>What Is It Like To Be A Bat?</em> Il affirmait qu'il doit y avoir quelque chose que cela fait d'être une chauve-souris : voir le monde comme une chauve-souris le voit et percevoir l'existence comme le fait une chauve-souris. Cependant, selon Nagel, même si nous connaissions tous les faits possibles sur le fonctionnement du cerveau, des sens et du corps des chauves-souris, nous ne saurions toujours pas ce que cela fait d'être une chauve-souris.</p><p>L'explicabilité de l'IA est le même type de problème. Nous connaissons tous les faits sur un modèle d'IA donné. Ce n'est qu'un ensemble de nombres à précision finie organisés en une séquence de matrices. Nous pouvons trivialement vérifier que chaque sortie du modèle est le résultat d'un calcul arithmétique correct, mais cette information est inutile comme explication.</p><p>Il n'existe pas plus de solution générale à ce problème pour l'IA que pour les humains. Cependant, l'architecture ColBERT, et particulièrement sa façon d'utiliser l'\"interaction tardive\" lorsqu'elle est utilisée comme reranker, vous permet d'obtenir des insights significatifs de vos modèles sur les raisons pour lesquelles il donne des résultats spécifiques dans des cas particuliers.</p><p>Cet article vous montre comment l'interaction tardive permet l'explicabilité, en utilisant le modèle Jina-ColBERT <a href=\"https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io\"><code>jina-colbert-v1-en</code></a> et la <a href=\"https://matplotlib.org/?ref=jina-ai-gmbh.ghost.io\">bibliothèque Python Matplotlib</a>.</p><h2 id=\"a-brief-overview-of-colbert\">Aperçu rapide de ColBERT</h2><p>ColBERT a été introduit dans <a href=\"https://doi.org/10.1145/3397271.3401075?ref=jina-ai-gmbh.ghost.io\">Khattab & Zaharia (2020)</a> comme une extension du <a href=\"https://doi.org/10.18653/v1/N19-1423?ref=jina-ai-gmbh.ghost.io\">modèle BERT introduit en 2018</a> par Google. Les modèles <a href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\">Jina-ColBERT de Jina AI</a> s'appuient sur ce travail et sur l'architecture ColBERT v2 ultérieure proposée dans <a href=\"https://arxiv.org/abs/2112.01488?ref=jina-ai-gmbh.ghost.io\">Santhanam, et al. (2021)</a>. Les modèles de type ColBERT peuvent être utilisés pour créer des embeddings, mais ils ont des fonctionnalités supplémentaires lorsqu'ils sont utilisés comme modèle de reranking. Le principal avantage est l'<em>interaction tardive</em>, qui est une façon de structurer le problème de la similarité sémantique de texte différemment des modèles d'embedding standard.</p><h3 id=\"embedding-models\">Les modèles d'Embedding</h3><p>Dans un modèle d'embedding traditionnel, nous comparons deux textes en générant des vecteurs représentatifs appelés <em>embeddings</em>, puis nous comparons ces embeddings via des métriques de distance comme la distance cosinus ou de Hamming. La quantification de la similarité sémantique de deux textes suit généralement une procédure commune.</p><p>D'abord, nous créons des embeddings pour les deux textes séparément. Pour chaque texte :</p><ol><li>Un tokenizer découpe le texte en morceaux de la taille approximative d'un mot.</li><li>Chaque token est mappé à un vecteur.</li><li>Les vecteurs de tokens interagissent via le système d'attention et les couches de convolution, ajoutant des informations contextuelles à la représentation de chaque token.</li><li>Une couche de pooling transforme ces vecteurs de tokens modifiés en un seul vecteur d'embedding.</li></ol><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings_pooling_dark_small-1.png\" class=\"kg-image\" alt=\"Diagram of text classification model with convolutional, attention, pooling layers, and text tokens on a black background.\" loading=\"lazy\" width=\"550\" height=\"900\"><figcaption><span style=\"white-space: pre-wrap;\">Un modèle d'embedding schématisé qui crée un embedding unique pour un texte.</span></figcaption></figure><p>Ensuite, lorsqu'il y a un embedding pour chaque texte, nous les comparons entre eux, généralement en utilisant la métrique cosinus ou la distance de Hamming.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings2_simpler_dark_small.png\" class=\"kg-image\" alt=\"Flowchart describing a text similarity calculation process with tokenization, embedding models, and scoring.\" loading=\"lazy\" width=\"775\" height=\"825\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Embeddings2_simpler_dark_small.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings2_simpler_dark_small.png 775w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Dans un modèle d'embedding conventionnel, les documents sont comparés en comparant directement leurs embeddings.</span></figcaption></figure><p>Le scoring se fait en comparant les deux embeddings complets entre eux, sans information spécifique sur les tokens. Toute l'interaction entre les tokens est \"précoce\" puisqu'elle se produit avant que les deux textes ne soient comparés entre eux.</p><h3 id=\"reranking-models\">Les modèles de Reranking</h3><p>Les modèles de reranking fonctionnent différemment.</p><p>Tout d'abord, au lieu de créer un embedding pour chaque texte, il prend un texte, appelé <em>requête</em>, et une collection d'autres textes que nous appellerons <em>documents cibles</em> puis attribue un score à chaque document cible par rapport au texte de la requête. Ces nombres ne sont pas normalisés et ne sont pas comme la comparaison d'embeddings, mais ils peuvent être triés. Les documents cibles qui obtiennent les scores les plus élevés par rapport à la requête sont les textes qui sont les plus sémantiquement liés à la requête selon le modèle.</p><p>Voyons comment cela fonctionne concrètement avec le modèle de reranking <code>jina-colbert-v1-en</code>, en utilisant l'API Jina Reranker et Python.</p><p>Le code ci-dessous est également disponible dans un notebook que vous pouvez <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">télécharger</a> ou <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">exécuter dans Google Colab</a>.</p><p>Vous devez d'abord installer la version la plus récente de la bibliothèque <code>requests</code> dans votre environnement Python. Vous pouvez le faire avec la commande suivante :</p><pre><code class=\"language-bash\">pip install requests -U\n</code></pre><p>Ensuite, visitez la <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">page de l'API Jina Reranker</a> et obtenez un token API gratuit, valable pour jusqu'à un million de tokens de traitement de texte. Copiez la clé du token API depuis le bas de la page, comme montré ci-dessous :</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/jina_reranker_api.png\" class=\"kg-image\" alt=\"Screenshot of Reranker API's interface with explanatory text and red-highlighted code segment for search optimization.\" loading=\"lazy\" width=\"1650\" height=\"1800\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/jina_reranker_api.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/jina_reranker_api.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/jina_reranker_api.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/jina_reranker_api.png 1650w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Comment obtenir votre clé API personnelle depuis la page de l'API Jina Reranker.</span></figcaption></figure><p>Nous utiliserons le texte de requête suivant :</p><ul><li>\"Elephants eat 150 kg of food per day.\"</li></ul><p>Et comparerons cette requête à trois textes :</p><ul><li>\"Elephants eat 150 kg of food per day.\"</li><li>\"Every day, the average elephant consumes roughly 150 kg of plants.\"</li><li>\"The rain in Spain falls mainly on the plain.\"</li></ul><p>Le premier document est identique à la requête, le second est une reformulation du premier, et le dernier texte est complètement sans rapport.</p><p>Utilisez le code Python suivant pour obtenir les scores, en assignant votre token API Jina Reranker à la variable <code>jina_api_key</code> :</p><pre><code class=\"language-Python\">import requests\n\nurl = \"&lt;https://api.jina.ai/v1/rerank&gt;\"\njina_api_key = \"&lt;VOTRE TOKEN API JINA RERANKER ICI&gt;\"\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {jina_api_key}\"\n}\ndata = {\n    \"model\": \"jina-colbert-v1-en\",\n    \"query\": \"Elephants eat 150 kg of food per day.\",\n    \"documents\": [\n        \"Elephants eat 150 kg of food per day.\",\n        \"Every day, the average elephant consumes roughly 150 kg of food.\",\n        \"The rain in Spain falls mainly on the plain.\",\n    ],\n    \"top_n\": 3\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nfor item in response.json()['results']:\n    print(f\"{item['relevance_score']} : {item['document']['text']}\")\n</code></pre><p>L'exécution de ce code depuis un fichier Python ou dans un notebook devrait produire le résultat suivant :</p><pre><code class=\"language-Text\">11.15625 : Elephants eat 150 kg of food per day.\n9.6328125 : Every day, the average elephant consumes roughly 150 kg of food.\n1.568359375 : The rain in Spain falls mainly on the plain.\n</code></pre><p>La correspondance exacte a le score le plus élevé, comme on pouvait s'y attendre, tandis que la reformulation a le deuxième score le plus élevé, et un texte complètement sans rapport a un score beaucoup plus bas.</p><h3 id=\"scoring-using-colbert\">Scoring avec ColBERT</h3><p>Ce qui rend le reranking ColBERT différent du scoring basé sur les embeddings, c'est que les tokens des deux textes sont comparés les uns aux autres pendant le processus de scoring. Les deux textes n'ont jamais leurs propres embeddings.</p><p>D'abord, nous utilisons la même architecture que les modèles d'embedding pour créer de nouvelles représentations pour chaque token qui incluent des informations contextuelles du texte. Ensuite, nous comparons chaque token de la requête avec chaque token du document.</p><p>Pour chaque token de la requête, nous identifions le token dans le document qui a l'interaction la plus forte avec lui, et nous additionnons ces scores d'interaction pour calculer une valeur numérique finale.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/ColBERT_dual_dark_small.png\" class=\"kg-image\" alt=\"Detailed diagram showing computational model with tokens, scored and categorized into &quot;Early&quot; and &quot;Late&quot; interactions.\" loading=\"lazy\" width=\"1325\" height=\"1200\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/ColBERT_dual_dark_small.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/ColBERT_dual_dark_small.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/ColBERT_dual_dark_small.png 1325w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Cette interaction est « tardive » : les tokens interagissent entre les deux textes lorsque nous les comparons. Mais rappelons que l'interaction « tardive » n'exclut pas l'interaction « précoce ». Les paires de vecteurs de tokens comparées contiennent déjà des informations sur leurs contextes spécifiques.</p><p>Ce schéma d'interaction tardive préserve l'information au niveau des tokens, même si cette information est spécifique au contexte. Cela nous permet de voir, en partie, comment le modèle ColBERT calcule son score car nous pouvons identifier quelles paires de tokens contextualisés contribuent au score final.</p><h2 id=\"explaining-rankings-with-heat-maps\">Expliquer les classements avec des cartes thermiques</h2><p>Les cartes thermiques sont une technique de visualisation utile pour voir ce qui se passe dans Jina-ColBERT lors de la création des scores. Dans cette section, nous utiliserons les bibliothèques <a href=\"https://seaborn.pydata.org/?ref=jina-ai-gmbh.ghost.io\"><code>seaborn</code></a> et <a href=\"https://matplotlib.org/?ref=jina-ai-gmbh.ghost.io\"><code>matplotlib</code></a> pour créer des cartes thermiques à partir de la couche d'interaction tardive de <a href=\"https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io\"><code>jina-colbert-v1-en</code></a>, montrant comment les tokens de la requête interagissent avec chaque token du texte cible.</p><h3 id=\"set-up\">Configuration</h3><p>Nous avons créé un fichier de bibliothèque Python contenant le code pour accéder au modèle <code>jina-colbert-v1-en</code> et utiliser <code>seaborn</code>, <code>matplotlib</code> et <code>Pillow</code> pour créer des cartes thermiques. Vous pouvez <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">télécharger cette bibliothèque directement depuis GitHub</a>, ou <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">utiliser le notebook fourni</a> sur votre propre système, ou sur <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>.</p><p>D'abord, installez les prérequis. Vous aurez besoin de la dernière version de la bibliothèque <code>requests</code> dans votre environnement Python. Donc, si vous ne l'avez pas déjà fait, exécutez :</p><pre><code class=\"language-bash\">pip install requests -U \n</code></pre><p>Ensuite, installez les bibliothèques principales :</p><pre><code class=\"language-bash\">pip install matplotlib seaborn torch Pillow\n</code></pre><p>Ensuite, téléchargez <code>jina_colbert_heatmaps.py</code> depuis GitHub. Vous pouvez le faire <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">via un navigateur web</a> ou en ligne de commande si <code>wget</code> est installé :</p><pre><code class=\"language-bash\">wget https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py\n</code></pre><p>Avec les bibliothèques en place, nous n'avons plus qu'à déclarer une fonction pour le reste de cet article :</p><pre><code class=\"language-Python\">from jina_colbert_heatmaps import JinaColbertHeatmapMaker\n\ndef create_heatmap(query, document, figsize=None):\n    heat_map_maker = JinaColbertHeatmapMaker(jina_api_key=jina_api_key)\n    # get token embeddings for the query\n    query_emb = heat_map_maker.embed(query, is_query=True)\n    # get token embeddings for the target document\n    document_emb = heat_map_maker.embed(document, is_query=False)\n    return heat_map_maker.compute_heatmap(document_emb[0], query_emb[0], figsize)\n</code></pre><h3 id=\"results\">Résultats</h3><p>Maintenant que nous pouvons créer des cartes thermiques, créons-en quelques-unes et voyons ce qu'elles nous disent.</p><p>Exécutez la commande suivante en Python :</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Elephants eat 150 kg of food per day.\")</code></pre><p>Le résultat sera une carte thermique qui ressemble à ceci :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--68-.png\" class=\"kg-image\" alt=\"Heatmap visualizing relationships between phrases like &quot;elephants eat 150 kg of food per day&quot; with color gradients indicating\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--68-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--68-.png 640w\"></figure><p>Ceci est une carte thermique des niveaux d'activation entre les paires de tokens lorsque nous comparons deux textes identiques. Chaque carré montre l'interaction entre deux tokens, un de chaque texte. Les tokens supplémentaires <code>[CLS]</code> et <code>[SEP]</code> indiquent respectivement le début et la fin du texte, et <code>q</code> et <code>d</code> sont insérés juste après le token <code>[CLS]</code> dans les requêtes et les documents cibles respectivement. Cela permet au modèle de prendre en compte les interactions entre les tokens et le début et la fin des textes, mais permet également aux représentations des tokens d'être sensibles à leur présence dans les requêtes ou les cibles.</p><p>Plus le carré est lumineux, plus l'interaction entre les deux tokens est forte, ce qui indique qu'ils sont sémantiquement liés. Le score d'interaction de chaque paire de tokens est compris entre -1.0 et 1.0. Les carrés encadrés en rouge sont ceux qui comptent pour le score final : pour chaque token dans la requête, c'est son niveau d'interaction le plus élevé avec n'importe quel token du document qui compte.</p><p>Les meilleures correspondances — les points les plus lumineux — et les valeurs maximales encadrées en rouge sont presque toutes exactement sur la diagonale, et elles ont une très forte interaction. Les seules exceptions sont les tokens « techniques » <code>[CLS]</code>, <code>q</code>, et <code>d</code>, ainsi que le mot « of » qui est un « mot vide » très fréquent en anglais qui porte très peu d'information indépendante.</p><p>Prenons une phrase structurellement similaire — \"Cats eat 50 g of food per day.\" — et voyons comment les tokens interagissent :</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Cats eat 50 g of food per day.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/download.png\" class=\"kg-image\" alt=\"Heatmap visualizing the relevance of keywords like &quot;elephants&quot;, &quot;food&quot;, and &quot;kg&quot; with varying intensity colors, indicating da\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/download.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/download.png 640w\"></figure><p>Encore une fois, les meilleures correspondances sont principalement sur la diagonale car les mots sont souvent les mêmes et la structure de la phrase est presque identique. Même « cats » et « elephants » correspondent, en raison de leurs contextes communs, bien que pas très bien.</p><p>Moins le contexte est similaire, moins la correspondance est bonne. Considérons le texte \"Employees eat at the company canteen.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Employees eat at the company canteen.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--69-.png\" class=\"kg-image\" alt=\"Heatmap visualization showing word correlations from news articles, including topics like food, elephants, and work environme\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--69-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--69-.png 640w\"></figure><p>Bien que structurellement similaire, la seule correspondance forte ici est entre les deux instances de « eat ». Thématiquement, ce sont des phrases très différentes, même si leurs structures sont très parallèles.</p><p>En regardant l'obscurité des couleurs dans les carrés encadrés en rouge, nous pouvons voir comment le modèle les classerait comme correspondances pour \"Elephants eat 150 kg of food per day\", et <code>jina-colbert-v1-en</code> confirme cette intuition :</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Score</th>\n<th>Text</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>11.15625</td>\n<td>Elephants eat 150 kg of food per day.</td>\n</tr>\n<tr>\n<td>8.3671875</td>\n<td>Cats eat 50 g of food per day.</td>\n</tr>\n<tr>\n<td>3.734375</td>\n<td>Employees eat at the company canteen.</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Maintenant, comparons \"Elephants eat 150 kg of food per day.\" à une phrase qui a essentiellement le même sens mais une formulation différente : \"Every day, the average elephant consumes roughly 150 kg of food.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Every day, the average elephant consumes roughly 150 kg of food.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--70-.png\" class=\"kg-image\" alt=\"Colorful heatmap visualizing the relationship between elephant consumption metrics and other variables.\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--70-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--70-.png 640w\"></figure><p>Notez la forte interaction entre \"eat\" dans la première phrase et \"consume\" dans la seconde. La différence de vocabulaire n'empêche pas Jina-ColBERT de reconnaître le sens commun.</p><p>De plus, \"every day\" correspond fortement à \"per day\", même s'ils sont à des endroits complètement différents. Seul le mot de faible valeur \"of\" est une correspondance anormalement faible.</p><p>Maintenant, comparons la même requête avec un texte totalement sans rapport : \"The rain in Spain falls mainly on the plain.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"The rain in Spain falls mainly on the plain.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/download-1.png\" class=\"kg-image\" alt=\"Carte thermique Seaborn visualisant les fréquences des discussions sur les sujets au fil des mois, nuancée du rouge au bleu foncé.\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/download-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/download-1.png 640w\"></figure><p>Vous pouvez voir que les interactions de \"meilleure correspondance\" ont des scores beaucoup plus faibles pour cette paire, et il y a très peu d'interaction entre les mots des deux textes. Intuitivement, nous nous attendrions à ce qu'il obtienne un score faible par rapport à \"Every day, the average elephant consumes roughly 150 kg of food\", et <code>jina-colbert-v1-en</code> est d'accord :</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Score</th>\n<th>Text</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>9.6328125</td>\n<td>Every day, the average elephant consumes roughly 150 kg of food.</td>\n</tr>\n<tr>\n<td>1.568359375</td>\n<td>The rain in Spain falls mainly on the plain.</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"long-texts\">Textes longs</h3><p>Ce sont des exemples simples pour démontrer le fonctionnement des modèles de reclassement de type ColBERT. Dans les contextes de recherche d'information, comme la génération augmentée par récupération, les requêtes ont tendance à être des textes courts tandis que les documents candidats correspondants sont plus longs, souvent aussi longs que la fenêtre de contexte d'entrée du modèle.</p><p>Les modèles Jina-ColBERT prennent tous en charge des contextes d'entrée de 8192 tokens, ce qui équivaut à environ 16 pages standard de texte à simple interligne.</p><p>Nous pouvons également générer des cartes thermiques pour ces cas asymétriques. Par exemple, prenons la première section de la <a href=\"https://en.wikipedia.org/wiki/Indian_elephant?ref=jina-ai-gmbh.ghost.io\">page Wikipedia sur les éléphants indiens</a> :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png\" class=\"kg-image\" alt=\"Capture d'écran de la page Wikipedia sur les éléphants indiens, présentant des articles, trois images d'éléphants et le statut de conservation.\" loading=\"lazy\" width=\"2000\" height=\"1870\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 2188w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Pour voir ceci en texte brut, tel que transmis à <code>jina-colbert-v1-en</code>, cliquez sur <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/docs-heatmaps/notebooks/heatmaps/wikipedia_indian_elephant.txt?ref=jina-ai-gmbh.ghost.io\">ce lien</a>.</p><p>Ce texte fait 364 mots, donc notre carte thermique ne sera pas très carrée :</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", wikipedia_elephants, figsize=(50,7))</code></pre><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--71--2.png\" class=\"kg-image\" alt=\"Carte thermique graphique affichant des données génétiques, avec des points rouges et orange indiquant différents niveaux d'expression à travers les paires de bases\" loading=\"lazy\" width=\"2000\" height=\"378\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--71--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Untitled--71--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Untitled--71--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/06/Untitled--71--2.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Nous voyons que \"elephants\" correspond à beaucoup d'endroits dans le texte. Ce n'est pas surprenant dans un texte sur les éléphants. Mais nous pouvons aussi voir une zone où il y a beaucoup plus d'interaction :</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--72--1.png\" class=\"kg-image\" alt=\"Carte thermique génomique avec motifs rouges et noirs, axe étiqueté 'XNTY', et régions surlignées indiquant des points de données.\" loading=\"lazy\" width=\"2000\" height=\"443\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--72--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Untitled--72--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Untitled--72--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/06/Untitled--72--1.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Que se passe-t-il ici ? Avec Jina-ColBERT, nous pouvons trouver la partie du texte plus long qui y correspond. Il s'avère que c'est la quatrième phrase du deuxième paragraphe :</p><blockquote>The species is classified as a megaherbivore and consume up to 150 kg (330 lb) of plant matter per day.</blockquote><p>Cela réaffirme la même information que dans le texte de la requête. Si nous regardons la carte thermique pour cette seule phrase, nous pouvons voir les correspondances fortes :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--74-.png\" class=\"kg-image\" alt=\"Carte thermique montrant la co-occurrence des mots avec un focus sur &quot;elephants&quot;, &quot;food&quot;, et &quot;day&quot;, l'intensité de la couleur indiquant la force\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--74-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--74-.png 640w\"></figure><p>Jina-ColBERT vous fournit les moyens de voir exactement quelles zones d'un texte long ont provoqué sa correspondance avec la requête. Cela conduit à un meilleur débogage, mais aussi à une plus grande explicabilité. Il ne faut pas beaucoup de sophistication pour voir comment une correspondance est établie.</p><h2 id=\"explaining-ai-outcomes-with-jina-colbert\">Expliquer les résultats de l'IA avec Jina-ColBERT</h2><p>Les embeddings sont une technologie fondamentale dans l'IA moderne. Presque tout ce que nous faisons est basé sur l'idée que des relations complexes et apprenables dans les données d'entrée peuvent être exprimées dans la géométrie d'espaces de haute dimension. Cependant, il est très difficile pour les simples humains de donner un sens aux relations spatiales dans des milliers à des millions de dimensions.</p><p>ColBERT est un pas en arrière par rapport à ce niveau d'abstraction. Ce n'est pas une réponse complète au problème d'explication de ce qu'un modèle d'IA fait, mais il nous montre directement quelles parties de nos données sont responsables de nos résultats.</p><p>Parfois, l'IA doit être une boîte noire. Les matrices géantes qui font tout le travail lourd sont trop grandes pour qu'un humain puisse les garder en tête. Mais l'architecture ColBERT projette un peu de lumière dans la boîte et démontre que plus est possible.</p><p>Le modèle Jina-ColBERT n'est actuellement disponible qu'en anglais (<code>jina-colbert-v1-en</code>) mais d'autres langues et contextes d'utilisation sont en cours de développement. Cette ligne de modèles, qui non seulement effectue une recherche d'information à la pointe de la technologie mais peut vous dire pourquoi ils ont trouvé une correspondance, démontre l'engagement de Jina AI à rendre les technologies d'IA à la fois accessibles et utiles.</p>",
  "comment_id": "6672af263ce1950001eed6a7",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/06/Search-acc--3-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-06-19T12:12:54.000+02:00",
  "updated_at": "2024-07-08T21:08:21.000+02:00",
  "published_at": "2024-06-19T16:01:36.000+02:00",
  "custom_excerpt": "AI explainability and transparency are hot topics. How can we trust AI if we can't see how it works? Jina-ColBERT shows you how, with the right model architecture, you can easily make your AI spill its secrets.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "6360e8495e0f6e004d70bd9e",
      "name": "Maximilian Werk",
      "slug": "maximilian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/Profile-Picture.jpg",
      "cover_image": null,
      "bio": "I love bringing business value with ML powered solutions as well as broad strategic and deep technical discussions. I also care a lot about our company culture and enjoy pair programming.",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/maximilian/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "6360e8495e0f6e004d70bd9e",
    "name": "Maximilian Werk",
    "slug": "maximilian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/Profile-Picture.jpg",
    "cover_image": null,
    "bio": "I love bringing business value with ML powered solutions as well as broad strategic and deep technical discussions. I also care a lot about our company culture and enjoy pair programming.",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/maximilian/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/ai-explainability-made-easy-how-late-interaction-makes-jina-colbert-transparent/",
  "excerpt": "L'explicabilité et la transparence de l'IA sont des sujets brûlants. Comment pouvons-nous faire confiance à l'IA si nous ne pouvons pas voir comment elle fonctionne ? Jina-ColBERT vous montre comment, avec la bonne architecture de modèle, vous pouvez facilement faire révéler ses secrets à votre IA.",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Digital representation of a golden building seen through a blue and yellow mesh pattern, evoking a technological vibe.",
  "feature_image_caption": null
}