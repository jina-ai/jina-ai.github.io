{
  "slug": "readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json",
  "id": "6785bfd62defad0001fb5f22",
  "uuid": "a8e2e140-18e5-49e6-aa8f-71bf4c9e3293",
  "title": "ReaderLM v2 : Un petit modèle de langage de pointe pour la conversion HTML vers Markdown et JSON",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/ReaderLM-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/ReaderLM-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">Nous sommes en mission pour faire progresser et démocratiser l'intelligence artificielle grâce à l'open source et à la science ouverte.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-24.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/ReaderLM-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>En avril 2024, nous avons lancé <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a>, une API qui transforme n'importe quelle page web en markdown compatible avec les LLM en ajoutant simplement <code>r.jina.ai</code> comme préfixe d'URL. En septembre 2024, <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown?ref=jina-ai-gmbh.ghost.io\">nous avons lancé deux petits modèles de langage, <code>reader-lm-0.5b</code> et <code>reader-lm-1.5b</code>, spécialement conçus pour convertir le HTML brut en markdown propre.</a> Aujourd'hui, nous sommes ravis de présenter la deuxième génération de ReaderLM, un modèle de langage de 1,5B paramètres qui convertit le HTML brut en markdown ou JSON parfaitement formaté avec une précision supérieure et une meilleure gestion des contextes longs. <code>ReaderLM-v2</code> gère jusqu'à 512K tokens combinés en entrée et en sortie. Le modèle offre un support multilingue pour 29 langues, notamment l'anglais, le chinois, le japonais, le coréen, le français, l'espagnol, le portugais, l'allemand, l'italien, le russe, le vietnamien, le thaï, l'arabe, et plus encore.</p><p>Grâce à son <strong>nouveau paradigme d'entraînement</strong> et à des <strong>données d'entraînement de meilleure qualité</strong>, <code>ReaderLM-v2</code> représente un bond en avant significatif par rapport à son prédécesseur, particulièrement dans la gestion du contenu long et la génération de syntaxe markdown. Alors que la première génération abordait la conversion HTML-vers-markdown comme <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#:~:text=primarily%20needs%20to-,selective%2Dcopy,-from%20the%20input\">une tâche de « copie sélective »</a>, <strong>v2 la traite comme un véritable processus de traduction.</strong> Ce changement permet au modèle d'exploiter magistralement la syntaxe markdown, excellant dans<strong> </strong>la génération<strong> d'éléments complexes comme les blocs de code, les listes imbriquées, les tableaux et les équations LaTex.</strong></p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-.mp4\" poster=\"https://img.spacergif.org/v1/1500x1000/0a/spacer.png\" width=\"1500\" height=\"1000\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:21</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">La comparaison des résultats de conversion HTML-vers-markdown de la page d'accueil de HackerNews entre ReaderLM v2, ReaderLM 1.5b, Claude 3.5 Sonnet et Gemini 2.0 Flash révèle l'ambiance unique et les performances de ReaderLM v2. ReaderLM v2 excelle dans la préservation des informations complètes du HTML brut, y compris les liens originaux de HackerNews, tout en structurant intelligemment le contenu avec la syntaxe markdown. Le modèle utilise des listes imbriquées pour organiser les éléments locaux (points, horodatages et commentaires) tout en maintenant un formatage global cohérent grâce à une hiérarchie appropriée des titres (balises h1 et h2).</span></p></figcaption>\n        </figure><p>Un défi majeur dans notre première version était la <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#degeneration-and-dull-loops\"><strong>dégénérescence</strong></a><strong> </strong>après la génération de longues séquences, particulièrement sous forme de répétition et de boucles. Le modèle commençait soit à répéter le même token, soit à se bloquer dans une boucle, parcourant une courte séquence de tokens jusqu'à atteindre la longueur maximale de sortie. <code>ReaderLM-v2</code> atténue considérablement ce problème en ajoutant une perte contrastive pendant l'entraînement—ses performances restent cohérentes quelle que soit la longueur du contexte ou la quantité de tokens déjà générés.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Nous avons testé ReaderLM v2 en convertissant </span><a href=\"https://jina.ai/legal?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">notre page légale</span></a><span style=\"white-space: pre-wrap;\"> en markdown—une page environ 20 fois plus longue que la page d'accueil de HackerNews, incluant un tableau extensif de sous-traitants vers la fin de la page. Malgré ce grand défi, ReaderLM v2 a réussi à générer le tableau complet en markdown tout en maintenant une structure de document cohérente, préservant à la fois la hiérarchie des titres et le formatage des listes même après le tableau. Ce niveau de performance était inatteignable avec la génération précédente </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>reader-lm-1.5b</span></code><span style=\"white-space: pre-wrap;\">, qui dégénérait après la génération de longues séquences.</span></figcaption></figure><p>Au-delà de la conversion markdown, <code>ReaderLM-v2</code> introduit la <strong>génération directe HTML-vers-JSON</strong>, permettant aux utilisateurs d'extraire des informations spécifiques du HTML brut selon un schéma JSON donné. Cette approche de bout en bout élimine le besoin de conversion markdown intermédiaire, une exigence courante dans de nombreux pipelines de nettoyage et d'extraction de données basés sur les LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Dans cet exemple, nous avons fourni à ReaderLM v2 du HTML brut de la page d'accueil de HackerNews et un schéma JSON spécifiant le titre du fil, l'URL, le résumé, les mots-clés, l'auteur et le nombre de commentaires. Bien que certains champs soient directement disponibles dans le HTML, d'autres — comme les mots-clés — doivent être déduits du contenu. ReaderLM v2 extrait et génère tous les champs avec une précision remarquable.</span></figcaption></figure><p>Dans les évaluations quantitatives et qualitatives, <code>ReaderLM-v2</code> surpasse des modèles beaucoup plus grands comme <code>Qwen2.5-32B-Instruct</code>, <code>Gemini2-flash-expr</code>, et <code>GPT-4o-2024-08-06</code> sur les tâches de conversion HTML vers Markdown tout en montrant des performances comparables sur les tâches d'extraction HTML vers JSON, le tout en utilisant significativement moins de paramètres.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ReaderLM-v2-pro</span></code><span style=\"white-space: pre-wrap;\"> est un point de contrôle premium exclusif réservé à nos clients entreprise, comprenant des entraînements et optimisations supplémentaires.</span></figcaption></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Instructed-HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2JSON.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Qualitative-Evaluation--2-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"620\"><figcaption><span style=\"white-space: pre-wrap;\">Notre évaluation manuelle a couvert 10 sources HTML diverses, incluant des articles d'actualités, des blogs, des pages de produits, des sites e-commerce et des documents juridiques en anglais, japonais et chinois. Le corpus de test comportait des éléments complexes tels que des tableaux multi-lignes, des mises en page dynamiques, des tableaux liés, des formules mathématiques (en ligne et affichées), des blocs de code et des listes profondément imbriquées. L'évaluation qualitative s'est concentrée sur trois dimensions clés, avec des notes allant de 1 (plus bas) à 5 (plus haut) pour les modèles. Les scores ont ensuite été normalisés à un maximum de 1,0 par aspect pour faciliter la comparaison.</span></figcaption></figure><p>Ces résultats établissent qu'un modèle bien conçu de 1,5B paramètres peut non seulement égaler mais souvent dépasser les performances de modèles beaucoup plus grands dans les tâches d'extraction de données structurées. Les améliorations progressives de <code>ReaderLM-v2</code> à <code>ReaderLM-v2-pro</code> démontrent l'efficacité de notre nouvelle stratégie d'entraînement pour améliorer les performances du modèle tout en maintenant l'efficacité computationnelle.</p><h2 id=\"get-started\">Commencer</h2><h3 id=\"via-reader-api\">Via l'API Reader</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs and search web for better grounding LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-17.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>ReaderLM-v2</code> est maintenant intégré à notre API Reader. Pour l'utiliser, spécifiez simplement <code>x-engine: readerlm-v2</code> dans vos en-têtes de requête et activez le streaming de réponse avec <code>-H 'Accept: text/event-stream'</code> :</p><pre><code class=\"language-bash\">curl https://r.jina.ai/https://news.ycombinator.com/ -H 'x-engine: readerlm-v2' -H 'Accept: text/event-stream'\n</code></pre><p>Vous pouvez l'essayer sans clé API avec une limite de taux inférieure. <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\">Pour des limites de taux plus élevées</a>, vous pouvez acheter une clé API. <strong>Veuillez noter que les requêtes ReaderLM-v2 consomment 3 fois le nombre normal de tokens de votre clé API.</strong> Cette fonctionnalité est actuellement en version bêta pendant que nous collaborons avec l'équipe GCP pour optimiser l'efficacité GPU et augmenter la disponibilité du modèle.</p><h3 id=\"on-google-colab\">Sur Google Colab</h3><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1FfPjZwkMSocOLsEYH45B3B4NxDryKLGI?usp=sharing&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-22.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-6.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Notez que le GPU T4 gratuit a des limitations — il ne prend pas en charge </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>bfloat16</span></code><span style=\"white-space: pre-wrap;\"> ou flash attention 2, ce qui entraîne une utilisation mémoire plus élevée et un traitement plus lent des entrées longues. Néanmoins, ReaderLM v2 traite avec succès notre page juridique complète dans ces conditions, atteignant des vitesses de traitement de 67 tokens/s en entrée et 36 tokens/s en sortie. Pour une utilisation en production, nous recommandons une RTX 3090/4090 pour des performances optimales.</span></p></figcaption></figure><p>La façon la plus simple d'essayer <code>ReaderLM-v2</code> dans un environnement hébergé est via notre notebook Colab, qui démontre la conversion HTML vers Markdown, l'extraction JSON et le suivi d'instructions en utilisant la page d'accueil de HackerNews comme exemple. Le notebook est optimisé pour le niveau GPU T4 gratuit de Colab et nécessite <code>vllm</code> et <code>triton</code> pour l'accélération et l'exécution. N'hésitez pas à le tester avec n'importe quel site web.</p><h4 id=\"html-to-markdown-conversion\">Conversion HTML vers Markdown</h4><p>Vous pouvez utiliser la fonction d'aide <code>create_prompt</code> pour créer facilement une invite pour convertir HTML en Markdown :</p><pre><code class=\"language-python\">prompt = create_prompt(html)\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p><code>result</code> sera une chaîne enveloppée dans des backticks Markdown comme bloc de code. Vous pouvez également remplacer les paramètres par défaut pour explorer différentes sorties, par exemple :</p><pre><code class=\"language-python\">prompt = create_prompt(html, instruction=\"Extract the first three news and put into in the makdown list\")\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p>Cependant, comme nos données d'entraînement peuvent ne pas couvrir tous les types d'instructions, en particulier les tâches nécessitant un raisonnement en plusieurs étapes, les résultats les plus fiables proviennent de la conversion HTML vers Markdown. Pour l'extraction d'informations la plus efficace, nous recommandons d'utiliser un schéma JSON comme montré ci-dessous :</p><h4 id=\"html-to-json-extraction-with-json-schema\">Extraction HTML vers JSON avec schéma JSON</h4><pre><code class=\"language-python\">import json\n\nschema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"title\": {\"type\": \"string\", \"description\": \"News thread title\"},\n        \"url\": {\"type\": \"string\", \"description\": \"Thread URL\"},\n        \"summary\": {\"type\": \"string\", \"description\": \"Article summary\"},\n        \"keywords\": {\"type\": \"list\", \"description\": \"Descriptive keywords\"},\n        \"author\": {\"type\": \"string\", \"description\": \"Thread author\"},\n        \"comments\": {\"type\": \"integer\", \"description\": \"Comment count\"}\n    },\n    \"required\": [\"title\", \"url\", \"date\", \"points\", \"author\", \"comments\"]\n}\n\nprompt = create_prompt(html, schema=json.dumps(schema, indent=2))\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()\n</code></pre><p><code>result</code> sera une chaîne enveloppée dans des backticks de bloc de code formaté JSON, pas un véritable objet JSON/dict. Vous pouvez utiliser Python pour analyser la chaîne en un dictionnaire ou un objet JSON approprié pour un traitement ultérieur.</p><h3 id=\"in-production-available-on-csp\">En Production : Disponible sur CSP</h3><p><code>ReaderLM-v2</code> est disponible sur AWS SageMaker, Azure et GCP marketplace. Si vous devez utiliser ces modèles au-delà de ces plateformes ou sur site au sein de votre entreprise, notez que ce modèle et <code>ReaderLM-v2-pro</code> sont tous deux sous licence CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Pour les demandes d'utilisation commerciale ou l'accès à <code>ReaderLM-v2-pro</code>, n'hésitez pas à nous contacter.</a></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-jwfct4j4rvxk2?sr=0-21&ref_=beagle&applicationId=AWSMPContessa&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Reader-LM v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-23.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"quantitative-evaluation\">Évaluation Quantitative</h2><p>Nous évaluons ReaderLM-v2 sur trois tâches d'extraction de données structurées en le comparant aux modèles de pointe : <code>GPT-4o-2024-08-06</code>, <code>Gemini2-flash-expr</code>, et <code>Qwen2.5-32B-Instruct</code>. Notre cadre d'évaluation combine des métriques qui mesurent à la fois la précision du contenu et la fidélité structurelle. <code>ReaderLM-v2</code> est la version publiquement disponible avec des poids ouverts, tandis que <code>ReaderLM-v2-pro</code> est un point de contrôle premium exclusif réservé à nos clients entreprise, comprenant des entraînements et des optimisations supplémentaires. Notez que notre première génération <code>reader-lm-1.5b</code> n'est évaluée que sur la tâche d'extraction de contenu principal, car elle ne prend pas en charge les capacités d'extraction par instruction ou JSON.</p><h3 id=\"evaluation-metrics\">Métriques d'Évaluation</h3><p>Pour les tâches HTML-vers-Markdown, nous utilisons sept métriques complémentaires. Note : ↑ indique que plus c'est élevé, mieux c'est, ↓ indique que plus c'est bas, mieux c'est</p><ul><li><strong>ROUGE-L</strong> (↑) : Mesure la plus longue sous-séquence commune entre le texte généré et le texte de référence, capturant la préservation du contenu et la similarité structurelle. Plage : 0-1, les valeurs plus élevées indiquent une meilleure correspondance des séquences.</li><li><strong>WER (Taux d'Erreur de Mots)</strong> (↓) : Quantifie le nombre minimum d'éditions au niveau des mots nécessaires pour transformer le texte généré en référence. Les valeurs plus basses indiquent moins de corrections nécessaires.</li><li><strong>SUB (Substitutions)</strong> (↓) : Compte le nombre de substitutions de mots nécessaires. Les valeurs plus basses suggèrent une meilleure précision au niveau des mots.</li><li><strong>INS (Insertions)</strong> (↓) : Mesure le nombre de mots qui doivent être insérés pour correspondre à la référence. Les valeurs plus basses indiquent une meilleure complétude.</li><li><strong>Distance de Levenshtein</strong> (↓) : Calcule le nombre minimum d'éditions de caractères individuels nécessaires. Les valeurs plus basses suggèrent une meilleure précision au niveau des caractères.</li><li><strong>Distance de Damerau-Levenshtein</strong> (↓) : Similaire à Levenshtein mais prend aussi en compte les transpositions de caractères. Les valeurs plus basses indiquent une meilleure correspondance au niveau des caractères.</li><li><strong>Similarité Jaro-Winkler</strong> (↑) : Met l'accent sur la correspondance des caractères au début des chaînes, particulièrement utile pour évaluer la préservation de la structure du document. Plage : 0-1, les valeurs plus élevées indiquent une meilleure similarité.</li></ul><p>Pour les tâches HTML-vers-JSON, nous la considérons comme une tâche de recherche d'information et adoptons quatre métriques :</p><ul><li><strong>Score F1</strong> (↑) : Moyenne harmonique de la précision et du rappel, fournissant une précision globale. Plage : 0-1.</li><li><strong>Précision</strong> (↑) : Proportion d'informations correctement extraites parmi toutes les extractions. Plage : 0-1.</li><li><strong>Rappel</strong> (↑) : Proportion d'informations correctement extraites parmi toutes les informations disponibles. Plage : 0-1.</li><li><strong>Taux de Réussite</strong> (↑) : Proportion de sorties qui sont des JSON valides et conformes au schéma. Plage : 0-1.</li></ul><h3 id=\"main-content-html-to-markdown-task\">Tâche de Conversion HTML-vers-Markdown du Contenu Principal</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.69</td>\n<td>0.62</td>\n<td>131.06</td>\n<td>372.34</td>\n<td>0.40</td>\n<td>1341.14</td>\n<td>0.74</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td>0.41</td>\n<td><strong>88.66</strong></td>\n<td><strong>88.69</strong></td>\n<td>0.40</td>\n<td>1283.54</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.71</td>\n<td>0.47</td>\n<td>158.26</td>\n<td>123.47</td>\n<td>0.41</td>\n<td>1354.33</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>reader-lm-1.5b</td>\n<td>0.72</td>\n<td>1.14</td>\n<td>260.29</td>\n<td>1182.97</td>\n<td>0.35</td>\n<td>1733.11</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.84</td>\n<td>0.62</td>\n<td>135.28</td>\n<td>867.14</td>\n<td>0.22</td>\n<td>1262.75</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.86</strong></td>\n<td><strong>0.39</strong></td>\n<td>162.92</td>\n<td>500.44</td>\n<td><strong>0.20</strong></td>\n<td><strong>928.15</strong></td>\n<td><strong>0.83</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"instructed-html-to-markdown-task\">Tâche de Conversion HTML-vers-Markdown par Instructions</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.64</td>\n<td>1.64</td>\n<td>122.64</td>\n<td>533.12</td>\n<td>0.45</td>\n<td>766.62</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td><strong>0.82</strong></td>\n<td><strong>87.53</strong></td>\n<td><strong>180.61</strong></td>\n<td>0.42</td>\n<td><strong>451.10</strong></td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.68</td>\n<td>0.73</td>\n<td>98.72</td>\n<td>177.23</td>\n<td>0.43</td>\n<td>501.50</td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.70</td>\n<td>1.28</td>\n<td>75.10</td>\n<td>443.70</td>\n<td>0.38</td>\n<td>673.62</td>\n<td><strong>0.75</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.72</strong></td>\n<td>1.48</td>\n<td><strong>70.16</strong></td>\n<td>570.38</td>\n<td><strong>0.37</strong></td>\n<td>748.10</td>\n<td><strong>0.75</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"schema-based-html-to-json-task\">Tâche de Conversion HTML-vers-JSON basée sur un Schéma</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>F1↑</th>\n<th>Precision↑</th>\n<th>Recall↑</th>\n<th>Pass-Rate↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.81</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td><strong>0.83</strong></td>\n<td>0.84</td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td><strong>0.83</strong></td>\n<td><strong>0.85</strong></td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.81</td>\n<td>0.98</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td>0.82</td>\n<td>0.83</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>ReaderLM-v2</code> représente une avancée significative dans toutes les tâches. Pour l'extraction du contenu principal, <code>ReaderLM-v2-pro</code> obtient les meilleures performances dans cinq métriques sur sept, avec des scores supérieurs en ROUGE-L (0,86), WER (0,39), Levenshtein (0,20), Damerau (928,15), et Jaro-Winkler (0,83). Ces résultats démontrent des améliorations globales dans la préservation du contenu et la précision structurelle par rapport à sa version de base et aux modèles plus grands.</p><p>Dans l'extraction par instructions, <code>ReaderLM-v2</code> et <code>ReaderLM-v2-pro</code> sont en tête pour le ROUGE-L (0,72), le taux de substitution (70,16), la distance de Levenshtein (0,37), et la similarité Jaro-Winkler (0,75, à égalité avec la version de base). Bien que GPT-4o montre des avantages en WER et distance Damerau, <code>ReaderLM-v2-pro</code> maintient une meilleure structure globale et précision du contenu. Dans l'extraction JSON, le modèle est compétitif, restant à 0,01-0,02 points F1 des modèles plus grands tout en atteignant des taux de réussite élevés (0,99).</p><h2 id=\"qualitative-evaluation\">Évaluation Qualitative</h2><p>Durant notre analyse dePour <code>reader-lm-1.5b</code>, nous avons observé que <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#qualitative-study\">les métriques quantitatives seules ne capturent pas pleinement les performances du modèle</a>. Les évaluations numériques ne reflétaient parfois pas la qualité perceptuelle — des cas où de faibles scores métriques produisaient un markdown visuellement satisfaisant, ou des scores élevés donnaient des résultats sous-optimaux. Pour remédier à cette disparité, nous avons mené des évaluations qualitatives systématiques sur 10 sources HTML diverses, incluant des articles d'actualité, des billets de blog, des pages de produits, des sites e-commerce et des documents juridiques en anglais, japonais et chinois. Le corpus de test mettait l'accent sur des éléments de formatage complexes tels que des tableaux multi-lignes, des mises en page dynamiques, des formules LaTeX, des tableaux liés et des listes imbriquées, offrant une vision plus complète des capacités réelles du modèle.</p><h3 id=\"evaluation-metrics-1\">Métriques d'évaluation</h3><p>Notre évaluation humaine s'est concentrée sur trois dimensions clés, avec des notes sur une échelle de 1 à 5 :</p><p><strong>Intégrité du contenu</strong> - Évalue la préservation des informations sémantiques lors de la conversion HTML vers markdown, incluant :</p><ul><li>Précision et exhaustivité du contenu textuel</li><li>Préservation des liens, images, blocs de code, formules et citations</li><li>Conservation du formatage du texte et des URLs des liens/images</li></ul><p><strong>Précision structurelle</strong> - Évalue la conversion précise des éléments structurels HTML vers Markdown :</p><ul><li>Préservation de la hiérarchie des en-têtes</li><li>Précision de l'imbrication des listes</li><li>Fidélité de la structure des tableaux</li><li>Formatage des blocs de code et des citations</li></ul><p><strong>Conformité du format</strong> - Mesure le respect des standards de syntaxe Markdown :</p><ul><li>Utilisation correcte de la syntaxe pour les en-têtes (#), listes (*, +, -), tableaux, blocs de code (```)</li><li>Formatage propre sans espaces superflus ou syntaxe non standard</li><li>Rendu cohérent et lisible</li></ul><p>Lors de notre évaluation manuelle de plus de 10 pages HTML, chaque critère d'évaluation a un score maximum de 50 points. <code>ReaderLM-v2</code> a démontré de solides performances dans toutes les dimensions :</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Content Integrity</th>\n<th>Structural Accuracy</th>\n<th>Format Compliance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>reader-lm-v2</td>\n<td>39</td>\n<td>35</td>\n<td>36</td>\n</tr>\n<tr>\n<td>reader-lm-v2-pro</td>\n<td>35</td>\n<td>37</td>\n<td>37</td>\n</tr>\n<tr>\n<td>reader-lm-v1</td>\n<td>35</td>\n<td>34</td>\n<td>31</td>\n</tr>\n<tr>\n<td>Claude 3.5 Sonnet</td>\n<td>26</td>\n<td>31</td>\n<td>33</td>\n</tr>\n<tr>\n<td>gemini-2.0-flash-expr</td>\n<td>35</td>\n<td>31</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>32</td>\n<td>33</td>\n<td>34</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>38</td>\n<td>41</td>\n<td>42</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Pour l'exhaustivité du contenu, il a excellé dans la reconnaissance d'éléments complexes, particulièrement les formules LaTeX, les listes imbriquées et les blocs de code. Le modèle a maintenu une haute fidélité dans le traitement des structures de contenu complexes alors que les modèles concurrents omettaient souvent les en-têtes H1 (<code>reader-lm-1.5b</code>), tronquaient le contenu (Claude 3.5), ou conservaient les balises HTML brutes (Gemini-2.0-flash).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--92-.png\" width=\"2000\" height=\"1477\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--92-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--92-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--92-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--92-.png 2400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png\" width=\"2000\" height=\"1765\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--93--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--93--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--93--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png 2268w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><a href=\"https://iclr-blogposts.github.io/2024/blog/bench-hvp/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Un article de blog ICLR</span></a><span style=\"white-space: pre-wrap;\"> avec des équations LaTeX complexes intégrées en markdown, montrant le code source HTML dans le panneau de droite.</span></p></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--94--2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1033\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--94--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--94--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--94--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--94--2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Une vue partagée comparant la sortie Markdown de ReaderLM-v2 avec sa visualisation rendue.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"821\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Nous pouvons parfaitement restaurer le contenu original grâce à des étapes simples de post-traitement après ReaderLM-v2, notamment en convertissant les équations LaTeX du format HTML au format Markdown. Par exemple, en remplaçant </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>\\[...\\]</span></code><span style=\"white-space: pre-wrap;\"> (et ses équivalents HTML) par des délimiteurs standard Markdown comme </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>$...$</span></code><span style=\"white-space: pre-wrap;\"> pour les équations en ligne et </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>$$...$$</span></code><span style=\"white-space: pre-wrap;\"> pour les équations en affichage. Cela aide à prévenir les conflits de syntaxe dans l'interprétation Markdown.</span></figcaption></figure><p>En termes de précision structurelle, ReaderLM-v2 a montré une optimisation pour les structures web courantes. Par exemple, dans les cas Hacker News, il a réussi à reconstruire les liens complets et optimisé la présentation des listes. Le modèle a géré des structures HTML complexes non-blog qui mettaient au défi ReaderLM-v1.</p><p>Pour la conformité du format, ReaderLM-v2 a démontré une force particulière dans le traitement de contenus comme Hacker News, les blogs et les articles WeChat. Alors que d'autres grands modèles de langage performaient bien sur les sources de type markdown, ils peinaient avec les sites web traditionnels nécessitant plus d'interprétation et de reformatage.</p><p>Notre analyse a révélé que <code>gpt-4o</code> excelle dans le traitement des sites web plus courts, démontrant une compréhension supérieure de la structure et du formatage du site par rapport aux autres modèles. Cependant, lors du traitement de contenus plus longs, <code>gpt-4o</code> a des difficultés avec l'exhaustivité, omettant souvent des portions au début et à la fin du texte. Nous avons inclus une analyse comparative des sorties de <code>gpt-4o</code>, ReaderLM-v2 et ReaderLM-v2-pro en utilisant le site web de Zillow comme exemple.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1382\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png 2356w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">La page HTML originale de Zillow</span></figcaption></figure><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png\" width=\"1400\" height=\"1576\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--95-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--95-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png 1400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png\" width=\"1550\" height=\"1578\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png 1550w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png\" width=\"1562\" height=\"1582\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--97-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--97-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png 1562w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Une comparaison des sorties Markdown rendues par gpt-4o (gauche), ReaderLM-v2 (milieu) et ReaderLM-v2-pro (droite).</span></p></figcaption></figure><p>Pour certains cas complexes comme les pages de présentation de produits et les documents gouvernementaux, les performances de ReaderLM-v2 et ReaderLM-v2-pro sont restées robustes mais peuvent encore être améliorées. Les formules mathématiques complexes et le code dans les articles de blog ICLR ont posé des défis pour la plupart des modèles, bien que ReaderLM-v2 ait mieux géré ces cas que l'API Reader de référence.</p><h2 id=\"how-we-trained-readerlm-v2\">Comment nous avons entraîné ReaderLM v2</h2><p>ReaderLM-v2 est construit sur <code><strong>Qwen2.5-1.5B-Instruction</strong></code>, un modèle de base compact connu pour son efficacité dans le suivi des instructions et les tâches à contexte long. Dans cette section, nous décrivons comment nous avons entraîné le <code>ReaderLM-v2</code>, en mettant l'accent sur la préparation des données, les méthodes d'entraînement et les défis rencontrés.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model Parameter</th>\n<th>ReaderLM-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Parameters</td>\n<td>1.54B</td>\n</tr>\n<tr>\n<td>Max Context Length (Input+Output)</td>\n<td>512K</td>\n</tr>\n<tr>\n<td>Hidden Size</td>\n<td>1536</td>\n</tr>\n<tr>\n<td>Number of Layers</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Query Heads</td>\n<td>12</td>\n</tr>\n<tr>\n<td>KV Heads</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Head Size</td>\n<td>128</td>\n</tr>\n<tr>\n<td>Intermediate Size</td>\n<td>8960</td>\n</tr>\n<tr>\n<td>Multilingual Support</td>\n<td>29 languages</td>\n</tr>\n<tr>\n<td>HuggingFace Repository</td>\n<td>Link</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"data-preparation\">Préparation des données</h3><p>Le succès de ReaderLM-v2 dépendait largement de la qualité de ses données d'entraînement. Nous avons créé le jeu de données <code>html-markdown-1m</code>, qui comprenait un million de documents HTML collectés sur Internet. En moyenne, chaque document contenait 56 000 tokens, reflétant la longueur et la complexité des données web réelles. Pour préparer ce jeu de données, nous avons nettoyé les fichiers HTML en supprimant les éléments inutiles comme JavaScript et CSS, tout en préservant les éléments structurels et sémantiques clés. Après le nettoyage, nous avons utilisé <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> pour convertir les fichiers HTML en Markdown en utilisant des motifs regex et des heuristiques.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--76-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--76-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">L'histogramme de la longueur des tokens des fichiers HTML dans le jeu de données </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>html-markdown-1m</span></code></figcaption></figure><p>Bien que cela ait créé un jeu de données de base fonctionnel, cela a mis en évidence une limitation critique : <strong>les modèles entraînés uniquement sur ces conversions directes apprendraient essentiellement à imiter les motifs regex et les heuristiques utilisés par Jina Reader.</strong> Cela est devenu évident avec <code>reader-lm-0.5b/1.5b</code>, dont le plafond de performance était limité par la qualité de ces conversions basées sur des règles.</p><p>Pour résoudre ces limitations, nous avons développé un pipeline en trois étapes s'appuyant sur le modèle <code>Qwen2.5-32B-Instruction</code>, qui est essentiel pour créer un jeu de données synthétiques de haute qualité.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--73-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--73-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Pipeline de génération de données synthétiques pour ReaderLM-v2, propulsé par </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Qwen2.5-32B-Instruction</span></code></figcaption></figure><ol><li><strong>Ébauche</strong> : Nous avons généré des sorties Markdown et JSON initiales basées sur les instructions fournies au modèle. Ces sorties, bien que diverses, étaient souvent bruitées ou incohérentes.</li><li><strong>Raffinement</strong> : Les ébauches générées ont été améliorées en supprimant le contenu redondant, en imposant une cohérence structurelle et en alignant les formats souhaités. Cette étape a assuré que les données étaient propres et alignées avec les exigences des tâches.</li><li><strong>Critique</strong> : Les sorties raffinées ont été évaluées par rapport aux instructions originales. Seules les données ayant passé cette évaluation ont été incluses dans le jeu de données final. Cette approche itérative a assuré que les données d'entraînement répondaient aux normes de qualité nécessaires pour l'extraction de données structurées.</li></ol><h3 id=\"training-process\">Processus d'entraînement</h3><p>Notre processus d'entraînement comprenait plusieurs étapes adaptées aux défis du traitement des documents à contexte long.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--75-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--75-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">L'entraînement de ReaderLM v2 suit un processus itératif combinant la génération de données en trois étapes (Ébauche-Raffinement-Critique) avec un raffinement par auto-apprentissage, permettant une amélioration continue.</span></figcaption></figure><p>Nous avons commencé par le <strong>pré-entraînement à contexte long</strong>, en utilisant le jeu de données <code>html-markdown-1m</code>. Des techniques comme l'attention ring-zag et l'encodage positionnel rotatif (RoPE) ont été utilisées pour étendre progressivement la longueur de contexte du modèle de 32 768 tokens à 256 000 tokens. Pour maintenir la stabilité et l'efficacité, nous avons adopté une approche d'entraînement graduelle, commençant par des séquences plus courtes et augmentant progressivement la longueur du contexte.</p><p>Après le pré-entraînement, nous sommes passés au <strong>fine-tuning supervisé (SFT)</strong>. Cette étape a utilisé les jeux de données raffinés générés dans le processus de préparation des données. Ces jeux de données incluaient des instructions détaillées pour les tâches d'extraction Markdown et JSON, ainsi que des exemples pour raffiner les ébauches. Chaque jeu de données a été soigneusement conçu pour aider le modèle à apprendre des tâches spécifiques, comme l'identification du contenu principal ou l'adhésion aux structures JSON basées sur des schémas.</p><p>Nous avons ensuite appliqué l'<strong>optimisation directe des préférences (DPO)</strong> pour aligner les sorties du modèle avec des résultats de haute qualité. Dans cette phase, le modèle a été entraîné sur des paires d'ébauches et de réponses raffinées. En apprenant à privilégier les sorties raffinées, le modèle a intériorisé les subtiles distinctions qui définissent des résultats polis et adaptés aux tâches.</p><p>Enfin, nous avons mis en œuvre un <strong>fine-tuning par renforcement en auto-apprentissage</strong>, un processus itératif où le modèle générait, raffinait et évaluait ses propres sorties. Ce cycle a permis au modèle de s'améliorer continuellement sans nécessiter de supervision externe supplémentaire. En s'appuyant sur ses propres critiques et raffinements, le modèle a progressivement amélioré sa capacité à produire des sorties précises et structurées.</p><h2 id=\"conclusion\">Conclusion</h2><p>En avril 2024, Jina Reader est devenu la première API markdown compatible avec les LLM. Elle a établi une nouvelle tendance, a gagné une large adoption communautaire et, plus important encore, nous a inspiré à construire de petits modèles de langage pour le nettoyage et l'extraction de données. Aujourd'hui, nous repoussons à nouveau les limites avec ReaderLM-v2, tenant les promesses que nous avons faites en septembre dernier : une meilleure gestion des contextes longs, la prise en charge des instructions d'entrée et la capacité d'extraire du contenu spécifique des pages web au format markdown. Une fois de plus, nous avons démontré qu'avec un entraînement et un calibrage soigneux, les petits modèles de langage peuvent atteindre des performances état de l'art qui dépassent celles des modèles plus grands.</p><p>Tout au long du processus d'entraînement de ReaderLM-v2, nous avons identifié deux insights. Une stratégie efficace consistait à entraîner des modèles spécialisés sur des jeux de données séparés adaptés à des tâches spécifiques. Ces modèles spécialisés ont ensuite été <em>fusionnés</em> en utilisant une interpolation linéaire des paramètres. Bien que cette approche ait nécessité des efforts supplémentaires, elle a aidé à préserver les forces uniques de chaque modèle spécialisé dans le système unifié final.</p><p>Le processus itératif de synthèse des données s'est avéré crucial pour le succès de notre modèle. Grâce à l'affinage et à l'évaluation répétés des données synthétiques, nous avons considérablement amélioré les performances du modèle au-delà des simples approches basées sur des règles. Cette stratégie itérative, bien que présentant des défis dans le maintien d'évaluations critiques cohérentes et la gestion des coûts de calcul, était essentielle pour transcender les limitations de l'utilisation des données d'entraînement basées sur regex et heuristiques de Jina Reader. Cela est clairement démontré par l'écart de performance entre <code>reader-lm-1.5b</code>, qui s'appuie fortement sur les conversions basées sur des règles de Jina Reader, et <code>ReaderLM-v2</code> qui bénéficie de ce processus d'affinage itératif.</p><p>Nous sommes impatients de recevoir vos retours sur la façon dont ReaderLM-v2 améliore la qualité de vos données. Pour l'avenir, nous prévoyons d'étendre les capacités multimodales, particulièrement pour les documents numérisés, et d'optimiser davantage la vitesse de génération. Si vous êtes intéressé par une version personnalisée de ReaderLM adaptée à votre domaine spécifique, n'hésitez pas à nous contacter.</p>",
  "comment_id": "6785bfd62defad0001fb5f22",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/readerlm-v2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-01-14T02:37:26.000+01:00",
  "updated_at": "2025-01-15T11:35:18.000+01:00",
  "published_at": "2025-01-15T11:35:18.000+01:00",
  "custom_excerpt": "ReaderLM-v2 is a 1.5B small language model for HTML-to-Markdown conversion and HTML-to-JSON extraction with exceptional accuracy.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json/",
  "excerpt": "ReaderLM-v2 est un petit modèle de langage de 1,5B destiné à la conversion HTML-vers-Markdown et à l'extraction HTML-vers-JSON avec une précision exceptionnelle.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}