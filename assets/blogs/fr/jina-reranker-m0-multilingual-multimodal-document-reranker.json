{
  "slug": "jina-reranker-m0-multilingual-multimodal-document-reranker",
  "id": "67ea5eb45dcba60001c30f0a",
  "uuid": "b710acf7-f8e7-4588-bc54-30a1fbe42eca",
  "title": "jina-reranker-m0 : Reclasseur multilingue et multimodal de documents",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-reranker-m0\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-reranker-m0 · Hugging Face</div><div class=\"kg-bookmark-description\">Nous sommes en mission pour faire progresser et démocratiser l'intelligence artificielle grâce à l'open source et la science ouverte.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-34.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-reranker-m0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Aujourd'hui, nous publions <code>jina-reranker-m0</code>, notre nouveau modèle de réorganisation multilingue et multimodal pour <strong>le classement de documents visuels dans plusieurs langues : </strong>il accepte une requête ainsi qu'une collection d'images de documents riches en contenu visuel, y compris des pages contenant du texte, des figures, des tableaux, des infographies et diverses mises en page dans de multiples domaines et plus de 29 langues. Il produit une liste classée de documents ordonnés selon leur pertinence par rapport à la requête d'entrée. Par rapport à <code>jina-reranker-v2-base-multilingual</code>, <code>jina-reranker-m0</code> améliore également le reclassement de texte pour le contenu multilingue, les longs documents et les tâches de recherche de code.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/all-benchmarks--6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1714\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/all-benchmarks--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/all-benchmarks--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/04/all-benchmarks--6-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/04/all-benchmarks--6-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Les performances de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> sur les benchmarks de recherche visuelle ViDoRe, MBEIR et Winoground démontrent ses capacités dans diverses tâches de recherche multimodale couvrant plusieurs domaines et langues. Chaque point représente les scores de performance pour différents types/tâches de documents visuels. Les boîtes à moustaches illustrent la distribution de ces scores, les nombres mis en évidence indiquant la performance moyenne. Pour les résultats complets des benchmarks, veuillez consulter l'annexe de cet article.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/model-perf-boxplot--13-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"2338\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/model-perf-boxplot--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/model-perf-boxplot--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/04/model-perf-boxplot--13-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/04/model-perf-boxplot--13-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Ce graphique en boîte montre les performances de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> sur quatre benchmarks de reclassement uniquement textuel. Chaque benchmark peut inclure plusieurs jeux de données, langues ou tâches, représentés par des points individuels dans la boîte. La boîte montre la distribution de ces scores, le nombre mis en évidence indiquant la performance moyenne. Bien que la plupart des benchmarks utilisent NDCG@10 comme métrique de performance, MKQA utilise recall@10, car les données d'annotation de MKQA ne permettent pas le calcul du NDCG (l'évaluation officielle utilise le recall, qui détermine la pertinence des documents par des heuristiques). Les résultats complets des benchmarks sont disponibles dans l'annexe de cet article.</span></figcaption></figure><h2 id=\"new-architecture\">Nouvelle Architecture</h2><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/2.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">L'architecture de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> est basée sur Qwen2-VL-2B et comprend 2,1 milliards de paramètres. Ce modèle classe efficacement les documents en évaluant leurs éléments visuels et textuels par rapport aux requêtes, en utilisant une comparaison par paires.</span></figcaption></figure><p>Contrairement à <code>jina-reranker-v2-base-multilingual</code>, <code>jina-reranker-m0</code> passe de l'architecture classique cross-encoder à un modèle de langage visuel decoder-only. Il utilise l'encodeur et le projecteur de vision préentraînés de Qwen2-VL, a affiné son LLM avec LoRA, et a post-entraîné un MLP pour générer des logits de classement qui mesurent la pertinence requête-document. Cela donne un <strong>modèle discriminatif</strong> optimisé pour les tâches de classement.</p>\n<!--kg-card-begin: html-->\n<table><thead>\n  <tr>\n    <th></th>\n    <th><code>jina-reranker-m0</code></th>\n    <th><code>jina-reranker-v2</code></th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td>Architecture</td>\n    <td>Vision Language Model</td>\n    <td>Cross-Encoder</td>\n  </tr>\n  <tr>\n    <td>Base model</td>\n    <td>Qwen2-VL-2B</td>\n    <td>Jina-XLM-RoBERTa</td>\n  </tr>\n  <tr>\n    <td>Parameters</td>\n    <td>2.4 B</td>\n    <td>278 M</td>\n  </tr>\n  <tr>\n    <td>Max context length (query + document)</td>\n    <td>10,240</td>\n    <td>8,192</td>\n  </tr>\n  <tr>\n    <td>Max image patches (dynamic resolution)</td>\n    <td>768 × 28 × 28</td>\n    <td>❌</td>\n  </tr>\n  <tr>\n    <td>Multilingual support</td>\n    <td>✅</td>\n    <td>✅</td>\n  </tr>\n  <tr>\n    <td>Tasks supported</td>\n    <td>Text2Text, Text2Image, Image2Text, Text2Mixed</td>\n    <td>Text2Text</td>\n  </tr>\n</tbody></table>\n<!--kg-card-end: html-->\n<p>Cette nouvelle architecture permet à <code>jina-reranker-m0</code> de gérer jusqu'à 32K tokens, combinant harmonieusement les entrées visuelles et textuelles. Le modèle prend en charge des images allant d'une taille minimale de 56×56 pixels jusqu'à une résolution 4K. Lors du traitement des images, le ViT et le projecteur condensent les tokens adjacents 2×2 en tokens visuels uniques pour l'entrée du LLM. Des tokens spéciaux comme <code>&lt;|vision_start|&gt;</code> et <code>&lt;|vision_end|&gt;</code> marquent clairement les limites des tokens visuels, permettant au modèle de langage de traiter correctement les informations visuelles et d'effectuer un raisonnement multimodal sophistiqué qui intègre à la fois les éléments visuels et textuels.</p><p>Cette architecture résout également efficacement <a href=\"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models\">le problème d'écart entre modalités</a> qui affectait les modèles précédents comme <code>jina-clip-v1</code> et <code>jina-clip-v2</code>. Auparavant, les images se regroupaient près d'autres images tandis que le texte se regroupait près d'autre texte dans l'espace de représentation, créant une déconnexion. Cela signifiait que lorsque vos documents candidats contenaient à la fois des images et du texte, la recherche d'images à l'aide de requêtes textuelles était problématique. Avec <code>jina-reranker-m0</code>, vous pouvez désormais classer les images et les documents ensemble sans vous soucier de cet écart, créant une expérience de recherche multimodale véritablement unifiée.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/3.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">Dans les systèmes de recherche multimodale, un \"écart de modalité\" fait référence à la différence dans la façon dont le modèle évalue la similarité texte-texte par rapport à la similarité texte-image. En regardant l'image de gauche (</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">), il y a une séparation claire entre les deux distributions : La distribution de similarité texte-texte (rouge) culmine autour de 0,35. La similarité texte-image (bleue) culmine autour de 0,65-0,7. Cette séparation significative indique un grand écart de modalité - le modèle évalue les paires texte-texte et texte-image dans des plages fondamentalement différentes. Cela rend difficile la comparaison directe des scores entre les modalités. Dans un système sans écart de modalité, nous nous attendrions à ce que les distributions se chevauchent largement, ce qui signifie que le modèle évalue les deux types de paires dans des plages similaires basées uniquement sur la pertinence, et non sur le type de modalité.</span></figcaption></figure><p>Il convient de noter que notre entraînement était limité à un maximum de 10K tokens d'entrée, avec jusqu'à 768 tokens par image (entre les marqueurs <code>&lt;|vision_start|&gt;</code> et <code>&lt;|vision_end|&gt;</code>). De plus, nous n'avons pas spécifiquement entraîné le modèle pour les tâches de reclassement <code>image-to-image</code>, <code>image-to-multimodal</code>, ou <code>text-to-multimodal</code>. Dans ce contexte, \"multimodal\" fait référence à un document unique contenant à la fois des tokens d'image et de texte en entrée. En examinant toutes les combinaisons possibles de tokens d'image et de texte dans les requêtes et les documents, nous pouvons résumer la gamme complète des tâches prises en charge par <code>jina-reranker-m0</code> dans le tableau ci-dessous.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading--96-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/Heading--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/Heading--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading--96-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> prend en charge une large gamme de combinaisons de requêtes et de documents pour le reclassement. Il atteint des performances de pointe dans les tâches texte-texte, texte-image, image-texte et texte-mixte-unimodal, grâce à un entraînement approfondi. Le modèle gère également d'autres combinaisons d'entrées de manière zero-shot - l'architecture s'adapte à ces combinaisons de tokens, bien que nous ne l'ayons pas spécifiquement entraîné pour ces tâches.</span></figcaption></figure><p>Dans nos tests, nous avons trouvé des indices suggérant que le modèle peut extrapoler à ces tâches de classement non entraînées, mais toute efficacité dans ces domaines doit être considérée comme le résultat de la transférabilité zero-shot du modèle ou d'effets secondaires non intentionnels de l'entraînement. Nous n'avons pas effectué d'évaluations sérieuses des performances du modèle sur ces tâches, et prévoyons d'explorer ces capacités plus en profondeur dans de futures recherches.</p><h2 id=\"getting-started\">Pour Commencer</h2><h3 id=\"via-api\">Via API</h3><p>Le code ci-dessous montre comment calculer les scores de pertinence entre la requête <code>\"small language model data extraction\"</code> et une collection d'images et de documents textuels. Vous pouvez passer une chaîne de texte, une image encodée en base64 ou une URL d'image. Les nouveaux utilisateurs peuvent obtenir une clé API Jina avec 1 million de tokens gratuits. Bien que notre API ne prenne pas en charge l'utilisation d'images comme requêtes, vous pouvez utiliser des images comme requêtes lors de l'accès au modèle via la bibliothèque Hugging Face Transformers.</p><pre><code class=\"language-bash\">curl -X POST \\\n  https://api.jina.ai/v1/rerank \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer JINA_API_KEY\" \\\n  -d '{\n  \"model\": \"jina-reranker-m0\",\n  \"query\": \"small language model data extraction\",\n  \"documents\": [\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/handelsblatt-preview.png\"\n    },\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\"\n    },\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/wired-preview.png\"\n    },\n    {\n      \"text\": \"We present ReaderLM-v2, a compact 1.5 billion parameter language model designed for efficient web content extraction. Our model processes documents up to 512K tokens, transforming messy HTML into clean Markdown or JSON formats with high accuracy -- making it an ideal tool for grounding large language models. The models effectiveness results from two key innovations: (1) a three-stage data synthesis pipeline that generates high quality, diverse training data by iteratively drafting, refining, and critiquing web content extraction; and (2) a unified training framework combining continuous pre-training with multi-objective optimization. Intensive evaluation demonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger models by 15-20% on carefully curated benchmarks, particularly excelling at documents exceeding 100K tokens, while maintaining significantly lower computational requirements.\"\n    },\n    {\n      \"image\": \"https://jina.ai/blog-banner/using-deepseek-r1-reasoning-model-in-deepsearch.webp\"\n    },\n    {\n      \"text\": \"数据提取么？为什么不用正则啊，你用正则不就全解决了么？\"\n    },\n    {\n      \"text\": \"During the California Gold Rush, some merchants made more money selling supplies to miners than the miners made finding gold.\"\n    },\n    {\n      \"text\": \"Die wichtigsten Beiträge unserer Arbeit sind zweifach: Erstens führen wir eine neuartige dreistufige Datensynthese-Pipeline namens Draft-Refine-Critique ein, die durch iterative Verfeinerung hochwertige Trainingsdaten generiert; und zweitens schlagen wir eine umfassende Trainingsstrategie vor, die kontinuierliches Vortraining zur Längenerweiterung, überwachtes Feintuning mit spezialisierten Kontrollpunkten, direkte Präferenzoptimierung (DPO) und iteratives Self-Play-Tuning kombiniert. Um die weitere Forschung und Anwendung der strukturierten Inhaltsextraktion zu erleichtern, ist das Modell auf Hugging Face öffentlich verfügbar.\"\n    }\n  ],\n  \"return_documents\": false\n}'</code></pre><p>La réponse est affichée ci-dessous, où le premier résultat <code>index=1</code> correspond à notre capture d'écran du papier ReaderLM-v2 <a href=\"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\">paper screenshot</a>. </p><pre><code class=\"language-json\">{\"model\":\"jina-reranker-m0\",\"usage\":{\"total_tokens\":2829},\"results\":[{\"index\":1,\"relevance_score\":0.9587112551898949},{\"index\":3,\"relevance_score\":0.9337408271911014},{\"index\":7,\"relevance_score\":0.8922925217195924},{\"index\":2,\"relevance_score\":0.8891905997562045},{\"index\":0,\"relevance_score\":0.8827516945848907},{\"index\":4,\"relevance_score\":0.8701035914834407},{\"index\":6,\"relevance_score\":0.8676828987527296},{\"index\":5,\"relevance_score\":0.8455347349164652}]}</code></pre><h3 id=\"via-csp-marketplaces\">Via les Places de Marché CSP</h3><p><code>jina-reranker-m0</code> sera bientôt disponible directement sur AWS, Azure et GCP aux prix indiqués.</p><h3 id=\"via-huggingface\">Via HuggingFace</h3><p>Vous pouvez également utiliser le modèle localement depuis notre page Hugging Face. Nous avons préparé un notebook Google Colab qui démontre son fonctionnement. Par rapport à notre API web, l'utilisation locale du modèle offre une plus grande flexibilité, comme la possibilité d'utiliser des images comme requêtes et de travailler avec des documents multimodaux.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1gNTJHbdYSdgOEAea7kB6XaW56Zala0vk?usp=sharing\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-33.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-8.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"evaluation\">Évaluation</h2><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1KrCD7l0lhzMkyg3z-gEDmymxe4Eun9Z-C0kU3_cxw7Q/edit?usp=sharing\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">[public]-jina-reranker-m0-evaluation-results</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4-1.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyKUKD8mc67_5eRgiiBYvZFKdug_jMKmBHiEesOvQ3bVWmAAKMu-afa1748S_WJXuc4UdNjKMqEsIQnlnf2X5OQsA0dmDJirjwvEkrgBMhQlJwXS8VM-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">Les évaluations complètes sont disponibles dans ce Google Spreadsheet.</span></p></figcaption></figure><h3 id=\"beir-text2text-english-only\">BEIR (Texte2Texte, Anglais uniquement)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2104.08663\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models</div><div class=\"kg-bookmark-description\">Existing neural information retrieval (IR) models have often been studied in homogeneous and narrow settings, which has considerably limited insights into their out-of-distribution (OOD) generalization capabilities. To address this, and to facilitate researchers to broadly evaluate the effectiveness of their models, we introduce Benchmarking-IR (BEIR), a robust and heterogeneous evaluation benchmark for information retrieval. We leverage a careful selection of 18 publicly available datasets from diverse text retrieval tasks and domains and evaluate 10 state-of-the-art retrieval systems including lexical, sparse, dense, late-interaction and re-ranking architectures on the BEIR benchmark. Our results show BM25 is a robust baseline and re-ranking and late-interaction-based models on average achieve the best zero-shot performances, however, at high computational costs. In contrast, dense and sparse-retrieval models are computationally more efficient but often underperform other approaches, highlighting the considerable room for improvement in their generalization capabilities. We hope this framework allows us to better evaluate and understand existing retrieval systems, and contributes to accelerating progress towards better robust and generalizable systems in the future. BEIR is publicly available at https://github.com/UKPLab/beir.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-13.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Nandan Thakur</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-9.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>BEIR est un référentiel hétérogène pour la recherche d'informations, conçu pour évaluer la polyvalence et la robustesse des modèles IR. Il contient un ensemble diversifié de jeux de données provenant de différents domaines et se concentre sur l'évaluation zero-shot. Des métriques d'évaluation standardisées telles que NDCG, Recall@K et MRR sont utilisées.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">TREC-COVID</th>\n<th style=\"text-align: right\">NFCorpus</th>\n<th style=\"text-align: right\">NQ</th>\n<th style=\"text-align: right\">HotpotQA</th>\n<th style=\"text-align: right\">FiQA</th>\n<th style=\"text-align: right\">ArguAna</th>\n<th style=\"text-align: right\">Touche-2020</th>\n<th style=\"text-align: right\">DBPedia</th>\n<th style=\"text-align: right\">SCIDOCS</th>\n<th style=\"text-align: right\">FEVER</th>\n<th style=\"text-align: right\">Climate-FEVER</th>\n<th style=\"text-align: right\">SciFact</th>\n<th style=\"text-align: right\">Quora</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\"><strong>58.95</strong></td>\n<td style=\"text-align: right\"><strong>84.17</strong></td>\n<td style=\"text-align: right\"><strong>41.03</strong></td>\n<td style=\"text-align: right\"><strong>72.25</strong></td>\n<td style=\"text-align: right\">76.99</td>\n<td style=\"text-align: right\"><strong>51.62</strong></td>\n<td style=\"text-align: right\">40.69</td>\n<td style=\"text-align: right\">31.79</td>\n<td style=\"text-align: right\"><strong>49.34</strong></td>\n<td style=\"text-align: right\"><strong>22.91</strong></td>\n<td style=\"text-align: right\">91.14</td>\n<td style=\"text-align: right\">36.42</td>\n<td style=\"text-align: right\"><strong>79.94</strong></td>\n<td style=\"text-align: right\">88.01</td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (1024 tokens)</td>\n<td style=\"text-align: right\">55.81</td>\n<td style=\"text-align: right\">77.81</td>\n<td style=\"text-align: right\">36.65</td>\n<td style=\"text-align: right\">64.31</td>\n<td style=\"text-align: right\">64.63</td>\n<td style=\"text-align: right\">47.47</td>\n<td style=\"text-align: right\"><strong>54.31</strong></td>\n<td style=\"text-align: right\">26.55</td>\n<td style=\"text-align: right\">41.07</td>\n<td style=\"text-align: right\">19.91</td>\n<td style=\"text-align: right\">89.00</td>\n<td style=\"text-align: right\"><strong>42.33</strong></td>\n<td style=\"text-align: right\">72.4</td>\n<td style=\"text-align: right\"><strong>89.06</strong></td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\">56.51</td>\n<td style=\"text-align: right\">82.19</td>\n<td style=\"text-align: right\">34.33</td>\n<td style=\"text-align: right\">69.52</td>\n<td style=\"text-align: right\"><strong>77.89</strong></td>\n<td style=\"text-align: right\">45.45</td>\n<td style=\"text-align: right\">36.21</td>\n<td style=\"text-align: right\"><strong>33.12</strong></td>\n<td style=\"text-align: right\">46.72</td>\n<td style=\"text-align: right\">17.79</td>\n<td style=\"text-align: right\">91.03</td>\n<td style=\"text-align: right\">38.69</td>\n<td style=\"text-align: right\">72.64</td>\n<td style=\"text-align: right\">89.10</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">57.06</td>\n<td style=\"text-align: right\">80.53</td>\n<td style=\"text-align: right\">37.17</td>\n<td style=\"text-align: right\">67.39</td>\n<td style=\"text-align: right\">76.17</td>\n<td style=\"text-align: right\">46.48</td>\n<td style=\"text-align: right\">39.28</td>\n<td style=\"text-align: right\">32.35</td>\n<td style=\"text-align: right\">47.81</td>\n<td style=\"text-align: right\">20.03</td>\n<td style=\"text-align: right\"><strong>93.02</strong></td>\n<td style=\"text-align: right\">37.17</td>\n<td style=\"text-align: right\">76.50</td>\n<td style=\"text-align: right\">87.83</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"miracl-text2text-multilingual-18-languages\">MIRACL (Text2Text, Multilingue, 18 langues)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2210.09984\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Making a MIRACL : Recherche d'information multilingue à travers un continuum de langues</div><div class=\"kg-bookmark-description\">MIRACL (Recherche d'information multilingue à travers un continuum de langues) est un jeu de données multilingue que nous avons construit pour le challenge WSDM 2023 Cup qui se concentre sur la recherche ad hoc dans 18 langues différentes, qui représentent collectivement plus de trois milliards de locuteurs natifs dans le monde. Ces langues ont des typologies diverses, proviennent de nombreuses familles linguistiques différentes et sont associées à des quantités variables de ressources disponibles -- incluant ce que les chercheurs caractérisent généralement comme des langues très dotées et peu dotées. Notre jeu de données est conçu pour soutenir la création et l'évaluation de modèles de recherche monolingue, où les requêtes et les corpus sont dans la même langue. Au total, nous avons rassemblé plus de 700k jugements de pertinence de haute qualité pour environ 77k requêtes sur Wikipedia dans ces 18 langues, où toutes les évaluations ont été effectuées par des locuteurs natifs embauchés par notre équipe. Notre objectif est de stimuler la recherche qui améliorera la recherche à travers un continuum de langues, améliorant ainsi les capacités d'accès à l'information pour diverses populations à travers le monde, en particulier celles qui ont été traditionnellement mal desservies. Cet article de présentation décrit le jeu de données et les références que nous partageons avec la communauté. Le site web MIRACL est accessible sur http://miracl.ai/.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-12.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Xinyu Zhang</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-8.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MIRACL est un large jeu de données multilingue pour la recherche d'informations ad hoc couvrant 18 langues. Il englobe plus de trois milliards de locuteurs natifs et comprend des annotations humaines approfondies. L'accent est mis sur les tâches de recherche monolingue.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">ar</th>\n<th style=\"text-align: right\">bn</th>\n<th style=\"text-align: right\">en</th>\n<th style=\"text-align: right\">es</th>\n<th style=\"text-align: right\">fa</th>\n<th style=\"text-align: right\">fi</th>\n<th style=\"text-align: right\">fr</th>\n<th style=\"text-align: right\">hi</th>\n<th style=\"text-align: right\">id</th>\n<th style=\"text-align: right\">ja</th>\n<th style=\"text-align: right\">ko</th>\n<th style=\"text-align: right\">ru</th>\n<th style=\"text-align: right\">sw</th>\n<th style=\"text-align: right\">te</th>\n<th style=\"text-align: right\">th</th>\n<th style=\"text-align: right\">zh</th>\n<th style=\"text-align: right\">de</th>\n<th style=\"text-align: right\">yo</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\">66.75</td>\n<td style=\"text-align: right\">79.78</td>\n<td style=\"text-align: right\">78.01</td>\n<td style=\"text-align: right\">59.21</td>\n<td style=\"text-align: right\">53.56</td>\n<td style=\"text-align: right\">58.80</td>\n<td style=\"text-align: right\">78.00</td>\n<td style=\"text-align: right\">56.66</td>\n<td style=\"text-align: right\">62.83</td>\n<td style=\"text-align: right\">54.92</td>\n<td style=\"text-align: right\">66.51</td>\n<td style=\"text-align: right\">72.86</td>\n<td style=\"text-align: right\">67.26</td>\n<td style=\"text-align: right\">59.04</td>\n<td style=\"text-align: right\">70.19</td>\n<td style=\"text-align: right\">80.37</td>\n<td style=\"text-align: right\">64.51</td>\n<td style=\"text-align: right\">58.50</td>\n<td style=\"text-align: right\">80.44</td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align: right\">58.90</td>\n<td style=\"text-align: right\">71.53</td>\n<td style=\"text-align: right\">69.86</td>\n<td style=\"text-align: right\">48.37</td>\n<td style=\"text-align: right\">46.91</td>\n<td style=\"text-align: right\">54.13</td>\n<td style=\"text-align: right\">71.15</td>\n<td style=\"text-align: right\">50.90</td>\n<td style=\"text-align: right\">55.05</td>\n<td style=\"text-align: right\">47.83</td>\n<td style=\"text-align: right\">56.46</td>\n<td style=\"text-align: right\">64.76</td>\n<td style=\"text-align: right\">55.63</td>\n<td style=\"text-align: right\">54.07</td>\n<td style=\"text-align: right\">70.48</td>\n<td style=\"text-align: right\">73.56</td>\n<td style=\"text-align: right\">55.29</td>\n<td style=\"text-align: right\">49.18</td>\n<td style=\"text-align: right\">65.01</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\"><strong>69.32</strong></td>\n<td style=\"text-align: right\"><strong>80.51</strong></td>\n<td style=\"text-align: right\"><strong>81.85</strong></td>\n<td style=\"text-align: right\"><strong>57.67</strong></td>\n<td style=\"text-align: right\"><strong>57.64</strong></td>\n<td style=\"text-align: right\"><strong>61.92</strong></td>\n<td style=\"text-align: right\"><strong>80.38</strong></td>\n<td style=\"text-align: right\"><strong>59.60</strong></td>\n<td style=\"text-align: right\"><strong>67.66</strong></td>\n<td style=\"text-align: right\"><strong>58.86</strong></td>\n<td style=\"text-align: right\"><strong>67.37</strong></td>\n<td style=\"text-align: right\"><strong>75.14</strong></td>\n<td style=\"text-align: right\"><strong>67.61</strong></td>\n<td style=\"text-align: right\"><strong>68.92</strong></td>\n<td style=\"text-align: right\"><strong>76.69</strong></td>\n<td style=\"text-align: right\"><strong>82.29</strong></td>\n<td style=\"text-align: right\"><strong>64.46</strong></td>\n<td style=\"text-align: right\"><strong>58.32</strong></td>\n<td style=\"text-align: right\"><strong>80.85</strong></td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">63.65</td>\n<td style=\"text-align: right\">72.50</td>\n<td style=\"text-align: right\">79.42</td>\n<td style=\"text-align: right\">46.66</td>\n<td style=\"text-align: right\">51.54</td>\n<td style=\"text-align: right\">57.81</td>\n<td style=\"text-align: right\">73.05</td>\n<td style=\"text-align: right\">50.90</td>\n<td style=\"text-align: right\">60.94</td>\n<td style=\"text-align: right\">56.66</td>\n<td style=\"text-align: right\">59.15</td>\n<td style=\"text-align: right\">72.60</td>\n<td style=\"text-align: right\">53.43</td>\n<td style=\"text-align: right\">66.47</td>\n<td style=\"text-align: right\">74.62</td>\n<td style=\"text-align: right\">77.75</td>\n<td style=\"text-align: right\">62.49</td>\n<td style=\"text-align: right\">53.06</td>\n<td style=\"text-align: right\">76.69</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"mldr-text2text-multilingual-long-documents-13-languages\">MLDR (Text2Text, Documents longs multilingues, 13 langues)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2402.03216\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BGE M3-Embedding : Embeddings de texte Multi-Lingues, Multi-Fonctionnels, Multi-Granularité par auto-distillation de connaissances</div><div class=\"kg-bookmark-description\">Dans cet article, nous présentons un nouveau modèle d'embedding, appelé M3-Embedding, qui se distingue par sa polyvalence en termes de Multi-Lingualité, Multi-Fonctionnalité et Multi-Granularité. Il peut prendre en charge plus de 100 langues de travail, établissant de nouveaux records de performance sur les tâches de recherche multilingues et interlingues. Il peut simultanément exécuter les trois fonctionnalités de recherche courantes du modèle d'embedding : recherche dense, recherche multi-vecteurs et recherche éparse, fournissant ainsi une base de modèle unifiée pour les applications IR du monde réel. Il est capable de traiter des entrées de différentes granularités, allant des phrases courtes aux documents longs jusqu'à 8192 tokens. L'entraînement efficace de M3-Embedding implique les contributions techniques suivantes. Nous proposons une nouvelle approche d'auto-distillation des connaissances, où les scores de pertinence de différentes fonctionnalités de recherche peuvent être intégrés comme signal d'apprentissage. Nous optimisons également la stratégie de traitement par lots, permettant une grande taille de lot et un débit d'entraînement élevé pour assurer le caractère discriminant des embeddings. À notre connaissance, M3-Embedding est le premier modèle d'embedding qui réalise une telle polyvalence. Le modèle et le code seront disponibles publiquement sur https://github.com/FlagOpen/FlagEmbedding.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-18.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Jianlv Chen</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-14.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MLDR est un jeu de données multilingue spécialement conçu pour la recherche de documents longs, couvrant 13 langues. Il utilise GPT-3.5 pour générer des questions pour les documents. Le jeu de données est construit à partir de Wikipedia, Wudao et mC4.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">ar</th>\n<th style=\"text-align: right\">de</th>\n<th style=\"text-align: right\">en</th>\n<th style=\"text-align: right\">es</th>\n<th style=\"text-align: right\">fr</th>\n<th style=\"text-align: right\">hi</th>\n<th style=\"text-align: right\">it</th>\n<th style=\"text-align: right\">ja</th>\n<th style=\"text-align: right\">ko</th>\n<th style=\"text-align: right\">pt</th>\n<th style=\"text-align: right\">ru</th>\n<th style=\"text-align: right\">th</th>\n<th style=\"text-align: right\">zh</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\"><strong>59.83</strong></td>\n<td style=\"text-align: right\"><strong>55.86</strong></td>\n<td style=\"text-align: right\"><strong>51.25</strong></td>\n<td style=\"text-align: right\"><strong>54.67</strong></td>\n<td style=\"text-align: right\"><strong>87.63</strong></td>\n<td style=\"text-align: right\"><strong>82.59</strong></td>\n<td style=\"text-align: right\"><strong>32.76</strong></td>\n<td style=\"text-align: right\"><strong>73.25</strong></td>\n<td style=\"text-align: right\"><strong>58.93</strong></td>\n<td style=\"text-align: right\"><strong>55.73</strong></td>\n<td style=\"text-align: right\"><strong>86.08</strong></td>\n<td style=\"text-align: right\"><strong>66.73</strong></td>\n<td style=\"text-align: right\"><strong>39.17</strong></td>\n<td style=\"text-align: right\"><strong>33.14</strong></td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align: right\">39.71</td>\n<td style=\"text-align: right\">28.44</td>\n<td style=\"text-align: right\">31.57</td>\n<td style=\"text-align: right\">29.07</td>\n<td style=\"text-align: right\">62.08</td>\n<td style=\"text-align: right\">59.79</td>\n<td style=\"text-align: right\">25.47</td>\n<td style=\"text-align: right\">53.72</td>\n<td style=\"text-align: right\">38.36</td>\n<td style=\"text-align: right\">32.37</td>\n<td style=\"text-align: right\">63.26</td>\n<td style=\"text-align: right\">49.65</td>\n<td style=\"text-align: right\">25.15</td>\n<td style=\"text-align: right\">17.26</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\">53.53</td>\n<td style=\"text-align: right\">49.19</td>\n<td style=\"text-align: right\">45.39</td>\n<td style=\"text-align: right\">43.92</td>\n<td style=\"text-align: right\">74.57</td>\n<td style=\"text-align: right\">68.67</td>\n<td style=\"text-align: right\">44.75</td>\n<td style=\"text-align: right\">62.79</td>\n<td style=\"text-align: right\">49.27</td>\n<td style=\"text-align: right\">48.24</td>\n<td style=\"text-align: right\">76.45</td>\n<td style=\"text-align: right\">62.84</td>\n<td style=\"text-align: right\">38.82</td>\n<td style=\"text-align: right\">31.02</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">59.50</td>\n<td style=\"text-align: right\">51.96</td>\n<td style=\"text-align: right\">50.13</td>\n<td style=\"text-align: right\">46.85</td>\n<td style=\"text-align: right\">86.34</td>\n<td style=\"text-align: right\">82.25</td>\n<td style=\"text-align: right\">49.50</td>\n<td style=\"text-align: right\">69.00</td>\n<td style=\"text-align: right\">59.07</td>\n<td style=\"text-align: right\">52.19</td>\n<td style=\"text-align: right\">85.26</td>\n<td style=\"text-align: right\">68.06</td>\n<td style=\"text-align: right\">38.73</td>\n<td style=\"text-align: right\">34.15</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"mkqa-text2text-multilingual-question-answering-24-languages-3-variants-for-chinese\">MKQA (Text2Text, Question-Réponse Multilingue, 24 langues, 3 variantes pour le chinois)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2007.15207\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">MKQA : Un benchmark linguistiquement diversifié pour les questions-réponses multilingues en domaine ouvert</div><div class=\"kg-bookmark-description\">Les progrès en modélisation multilingue dépendent d'ensembles d'évaluation stimulants, réalistes et diversifiés. Nous présentons Multilingual Knowledge Questions and Answers (MKQA), un ensemble d'évaluation de questions-réponses en domaine ouvert comprenant 10k paires de questions-réponses alignées sur 26 langues typologiquement diverses (260k paires de questions-réponses au total). Les réponses sont basées sur une représentation de données indépendante de la langue et fortement organisée, rendant les résultats comparables entre les langues et indépendants des passages spécifiques à chaque langue. Avec 26 langues, ce jeu de données offre la plus large gamme de langues à ce jour pour évaluer les systèmes de questions-réponses. Nous évaluons diverses méthodes et références de l'état de l'art pour les questions-réponses génératives et extractives, entraînées sur Natural Questions, dans des contextes zero-shot et de traduction. Les résultats indiquent que ce jeu de données est difficile même en anglais, mais particulièrement dans les langues peu dotées.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Shayne Longpre</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-7.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MKQA est un ensemble d'évaluation de questions-réponses en domaine ouvert comprenant 10 000 paires de questions-réponses alignées sur 26 langues typologiquement diverses. Les paires de questions-réponses sont échantillonnées à partir de Google Natural Questions.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align:right\">AVG (recall@10)</th>\n<th style=\"text-align:right\">ar</th>\n<th style=\"text-align:right\">da</th>\n<th style=\"text-align:right\">de</th>\n<th style=\"text-align:right\">es</th>\n<th style=\"text-align:right\">en</th>\n<th style=\"text-align:right\">fi</th>\n<th style=\"text-align:right\">fr</th>\n<th style=\"text-align:right\">he</th>\n<th style=\"text-align:right\">hu</th>\n<th style=\"text-align:right\">it</th>\n<th style=\"text-align:right\">ja</th>\n<th style=\"text-align:right\">km</th>\n<th style=\"text-align:right\">ko</th>\n<th style=\"text-align:right\">ms</th>\n<th style=\"text-align:right\">nl</th>\n<th style=\"text-align:right\">no</th>\n<th style=\"text-align:right\">pl</th>\n<th style=\"text-align:right\">pt</th>\n<th style=\"text-align:right\">ru</th>\n<th style=\"text-align:right\">sv</th>\n<th style=\"text-align:right\">th</th>\n<th style=\"text-align:right\">tr</th>\n<th style=\"text-align:right\">vi</th>\n<th style=\"text-align:right\">zh_cn</th>\n<th style=\"text-align:right\">zh_hk</th>\n<th style=\"text-align:right\">zh_tw</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align:right\"><strong>68.19</strong></td>\n<td style=\"text-align:right\"><strong>63.88</strong></td>\n<td style=\"text-align:right\"><strong>70.57</strong></td>\n<td style=\"text-align:right\"><strong>70.52</strong></td>\n<td style=\"text-align:right\"><strong>71.26</strong></td>\n<td style=\"text-align:right\"><strong>73.47</strong></td>\n<td style=\"text-align:right\">64.10</td>\n<td style=\"text-align:right\"><strong>71.11</strong></td>\n<td style=\"text-align:right\">63.68</td>\n<td style=\"text-align:right\">63.23</td>\n<td style=\"text-align:right\"><strong>70.30</strong></td>\n<td style=\"text-align:right\"><strong>69.13</strong></td>\n<td style=\"text-align:right\">50.43</td>\n<td style=\"text-align:right\"><strong>64.30</strong></td>\n<td style=\"text-align:right\"><strong>70.78</strong></td>\n<td style=\"text-align:right\"><strong>71.73</strong></td>\n<td style=\"text-align:right\"><strong>70.25</strong></td>\n<td style=\"text-align:right\"><strong>69.72</strong></td>\n<td style=\"text-align:right\"><strong>70.57</strong></td>\n<td style=\"text-align:right\"><strong>70.78</strong></td>\n<td style=\"text-align:right\"><strong>70.69</strong></td>\n<td style=\"text-align:right\"><strong>69.80</strong></td>\n<td style=\"text-align:right\">67.90</td>\n<td style=\"text-align:right\"><strong>69.68</strong></td>\n<td style=\"text-align:right\"><strong>69.12</strong></td>\n<td style=\"text-align:right\"><strong>68.23</strong></td>\n<td style=\"text-align:right\"><strong>67.79</strong></td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align:right\">65.63</td>\n<td style=\"text-align:right\">59.00</td>\n<td style=\"text-align:right\">69.12</td>\n<td style=\"text-align:right\">68.27</td>\n<td style=\"text-align:right\">68.15</td>\n<td style=\"text-align:right\">71.14</td>\n<td style=\"text-align:right\">65.66</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">59.51</td>\n<td style=\"text-align:right\">63.23</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">64.36</td>\n<td style=\"text-align:right\">56.13</td>\n<td style=\"text-align:right\">58.98</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">69.53</td>\n<td style=\"text-align:right\">68.65</td>\n<td style=\"text-align:right\">67.26</td>\n<td style=\"text-align:right\">67.93</td>\n<td style=\"text-align:right\">67.06</td>\n<td style=\"text-align:right\">68.68</td>\n<td style=\"text-align:right\">66.32</td>\n<td style=\"text-align:right\">66.97</td>\n<td style=\"text-align:right\">66.87</td>\n<td style=\"text-align:right\">63.38</td>\n<td style=\"text-align:right\">63.59</td>\n<td style=\"text-align:right\">61.55</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align:right\">67.88</td>\n<td style=\"text-align:right\">63.09</td>\n<td style=\"text-align:right\">70.15</td>\n<td style=\"text-align:right\">68.91</td>\n<td style=\"text-align:right\">68.92</td>\n<td style=\"text-align:right\">73.00</td>\n<td style=\"text-align:right\"><strong>68.71</strong></td>\n<td style=\"text-align:right\">68.71</td>\n<td style=\"text-align:right\"><strong>70.27</strong></td>\n<td style=\"text-align:right\">64.00</td>\n<td style=\"text-align:right\">68.15</td>\n<td style=\"text-align:right\">68.47</td>\n<td style=\"text-align:right\"><strong>60.43</strong></td>\n<td style=\"text-align:right\">63.95</td>\n<td style=\"text-align:right\">68.80</td>\n<td style=\"text-align:right\">70.77</td>\n<td style=\"text-align:right\">69.10</td>\n<td style=\"text-align:right\">67.44</td>\n<td style=\"text-align:right\">67.40</td>\n<td style=\"text-align:right\">69.77</td>\n<td style=\"text-align:right\">70.03</td>\n<td style=\"text-align:right\">69.68</td>\n<td style=\"text-align:right\">66.04</td>\n<td style=\"text-align:right\">68.29</td>\n<td style=\"text-align:right\">67.84</td>\n<td style=\"text-align:right\">66.70</td>\n<td style=\"text-align:right\">66.34</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align:right\">67.90</td>\n<td style=\"text-align:right\">63.88</td>\n<td style=\"text-align:right\">70.31</td>\n<td style=\"text-align:right\">70.09</td>\n<td style=\"text-align:right\">70.51</td>\n<td style=\"text-align:right\">73.09</td>\n<td style=\"text-align:right\">67.50</td>\n<td style=\"text-align:right\">70.38</td>\n<td style=\"text-align:right\">63.00</td>\n<td style=\"text-align:right\"><strong>64.59</strong></td>\n<td style=\"text-align:right\">69.90</td>\n<td style=\"text-align:right\">67.34</td>\n<td style=\"text-align:right\">57.79</td>\n<td style=\"text-align:right\">62.14</td>\n<td style=\"text-align:right\">70.36</td>\n<td style=\"text-align:right\">71.58</td>\n<td style=\"text-align:right\">69.51</td>\n<td style=\"text-align:right\">68.61</td>\n<td style=\"text-align:right\">70.13</td>\n<td style=\"text-align:right\">70.07</td>\n<td style=\"text-align:right\">70.15</td>\n<td style=\"text-align:right\">68.80</td>\n<td style=\"text-align:right\"><strong>68.02</strong></td>\n<td style=\"text-align:right\">69.39</td>\n<td style=\"text-align:right\">67.23</td>\n<td style=\"text-align:right\">65.77</td>\n<td style=\"text-align:right\">65.37</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"coir-text2text-code-information-retrieval\">CoIR (Text2Text, Recherche d'Information dans le Code)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2407.02883\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">CoIR : Un benchmark complet pour les modèles de recherche d'information dans le code</div><div class=\"kg-bookmark-description\">Malgré le succès substantiel de la Recherche d'Information (RI) dans diverses tâches de TALN, la plupart des systèmes de RI traitent principalement des requêtes et des corpus en langage naturel, négligeant le domaine de la recherche de code. La recherche de code est d'une importance critique mais reste peu explorée, les méthodes et benchmarks existants ne représentant pas adéquatement la diversité du code dans divers domaines et tâches. Pour combler cette lacune, nous présentons COIR (Code Information Retrieval Benchmark), un benchmark robuste et complet spécifiquement conçu pour évaluer les capacités de recherche de code. COIR comprend dix jeux de données de code méticuleusement organisés, couvrant huit tâches distinctes de recherche à travers sept domaines différents. Nous discutons d'abord de la construction de COIR et de la composition diverse de ses jeux de données. De plus, nous évaluons neuf modèles de recherche largement utilisés avec COIR, révélant des difficultés significatives dans l'exécution des tâches de recherche de code, même avec des systèmes à la pointe de la technologie. Pour faciliter son adoption et son intégration dans les flux de recherche existants, COIR a été développé comme un framework Python convivial, facilement installable via pip. Il partage le même schéma de données que d'autres benchmarks populaires comme MTEB et BEIR, permettant des évaluations transparentes entre benchmarks. Avec COIR, nous visons à dynamiser la recherche dans le domaine de la recherche de code, en fournissant un outil de benchmarking polyvalent qui encourage le développement et l'exploration des systèmes de recherche de code https://github.com/CoIR-team/coir.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-14.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Xiangyang Li</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-10.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>CoIR est un benchmark complet conçu pour évaluer les capacités des modèles en matière de recherche de code. Il comprend 10 jeux de données de code couvrant 8 tâches de recherche dans 7 domaines différents. Un framework Python est fourni pour ce benchmark.</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th rowspan=\"3\">Model Name</th>\n      <th rowspan=\"3\">Avg (NDCG@10)</th>\n      <th colspan=\"3\">Text-to-Code</th>\n      <th colspan=\"7\">Code-to-Text</th>\n      <th colspan=\"9\">Code-to-Code</th>\n      <th colspan=\"3\">Hybrid Code</th>\n    </tr>\n    <tr>\n      <th rowspan=\"2\">Apps</th>\n      <th rowspan=\"2\">CosQA</th>\n      <th rowspan=\"2\">SQL</th>\n      <th colspan=\"7\">CSN</th>\n      <th colspan=\"7\">CSN-CCR</th>\n      <th colspan=\"2\">CodeTransOcean</th>\n      <th rowspan=\"2\">StackOver<br>Flow</th>\n      <th colspan=\"2\">CodeFeedBack</th>\n    </tr>\n    <tr>\n      <th>AVG</th>\n      <th>python</th>\n      <th>javascript</th>\n      <th>go</th>\n      <th>ruby</th>\n      <th>java</th>\n      <th>php</th>\n      <th>AVG</th>\n      <th>python</th>\n      <th>javascript</th>\n      <th>go</th>\n      <th>ruby</th>\n      <th>java</th>\n      <th>php</th>\n      <th>-Contest</th>\n      <th>-DL</th>\n      <th>-MT</th>\n      <th>-ST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>63.55</strong></td>\n      <td style=\"text-align: right\"><strong>26.21</strong></td>\n      <td style=\"text-align: right\">37.75</td>\n      <td style=\"text-align: right\"><strong>57.92</strong></td>\n      <td style=\"text-align: right\">80.76</td>\n      <td style=\"text-align: right\"><strong>98.37</strong></td>\n      <td style=\"text-align: right\">71.16</td>\n      <td style=\"text-align: right\">86.14</td>\n      <td style=\"text-align: right\">72.74</td>\n      <td style=\"text-align: right\">79.02</td>\n      <td style=\"text-align: right\">77.14</td>\n      <td style=\"text-align: right\"><strong>74.57</strong></td>\n      <td style=\"text-align: right\"><strong>81.66</strong></td>\n      <td style=\"text-align: right\"><strong>77.92</strong></td>\n      <td style=\"text-align: right\"><strong>68.71</strong></td>\n      <td style=\"text-align: right\"><strong>75.44</strong></td>\n      <td style=\"text-align: right\"><strong>77.54</strong></td>\n      <td style=\"text-align: right\"><strong>66.13</strong></td>\n      <td style=\"text-align: right\"><strong>79.79</strong></td>\n      <td style=\"text-align: right\"><strong>31.89</strong></td>\n      <td style=\"text-align: right\">90.41</td>\n      <td style=\"text-align: right\"><strong>72.25</strong></td>\n      <td style=\"text-align: right\"><strong>83.95</strong></td>\n    </tr>\n    <tr>\n      <td>jina-embeddings-v2-base-code<br>(top 100)</td>\n      <td style=\"text-align: right\">56.90</td>\n      <td style=\"text-align: right\">16.34</td>\n      <td style=\"text-align: right\"><strong>41.72</strong></td>\n      <td style=\"text-align: right\">49.79</td>\n      <td style=\"text-align: right\"><strong>83.95</strong></td>\n      <td style=\"text-align: right\">94.71</td>\n      <td style=\"text-align: right\"><strong>76.35</strong></td>\n      <td style=\"text-align: right\"><strong>87.39</strong></td>\n      <td style=\"text-align: right\"><strong>78.23</strong></td>\n      <td style=\"text-align: right\"><strong>82.69</strong></td>\n      <td style=\"text-align: right\"><strong>84.35</strong></td>\n      <td style=\"text-align: right\">59.65</td>\n      <td style=\"text-align: right\">68.23</td>\n      <td style=\"text-align: right\">62.31</td>\n      <td style=\"text-align: right\">49.15</td>\n      <td style=\"text-align: right\">65.40</td>\n      <td style=\"text-align: right\">63.89</td>\n      <td style=\"text-align: right\">48.92</td>\n      <td style=\"text-align: right\">79.20</td>\n      <td style=\"text-align: right\">30.35</td>\n      <td style=\"text-align: right\">89.42</td>\n      <td style=\"text-align: right\">49.62</td>\n      <td style=\"text-align: right\">68.93</td>\n    </tr>\n    <tr>\n      <td>bge-reranker-v2-m3</td>\n      <td style=\"text-align: right\">35.97</td>\n      <td style=\"text-align: right\">8.33</td>\n      <td style=\"text-align: right\">30.06</td>\n      <td style=\"text-align: right\">50.63</td>\n      <td style=\"text-align: right\">49.26</td>\n      <td style=\"text-align: right\">67.62</td>\n      <td style=\"text-align: right\">39.55</td>\n      <td style=\"text-align: right\">58.11</td>\n      <td style=\"text-align: right\">41.37</td>\n      <td style=\"text-align: right\">44.77</td>\n      <td style=\"text-align: right\">44.13</td>\n      <td style=\"text-align: right\">40.81</td>\n      <td style=\"text-align: right\">42.57</td>\n      <td style=\"text-align: right\">42.75</td>\n      <td style=\"text-align: right\">38.04</td>\n      <td style=\"text-align: right\">38.04</td>\n      <td style=\"text-align: right\">41.73</td>\n      <td style=\"text-align: right\">41.73</td>\n      <td style=\"text-align: right\">34.93</td>\n      <td style=\"text-align: right\">5.09</td>\n      <td style=\"text-align: right\">60.12</td>\n      <td style=\"text-align: right\">16.44</td>\n      <td style=\"text-align: right\">64.05</td>\n    </tr>\n    <tr>\n      <td>jina-reranker-v2-multilingual</td>\n      <td style=\"text-align: right\">56.14</td>\n      <td style=\"text-align: right\">21.90</td>\n      <td style=\"text-align: right\">37.26</td>\n      <td style=\"text-align: right\">53.56</td>\n      <td style=\"text-align: right\">78.88</td>\n      <td style=\"text-align: right\">97.83</td>\n      <td style=\"text-align: right\">67.43</td>\n      <td style=\"text-align: right\">84.64</td>\n      <td style=\"text-align: right\">68.93</td>\n      <td style=\"text-align: right\">75.73</td>\n      <td style=\"text-align: right\">78.71</td>\n      <td style=\"text-align: right\">63.59</td>\n      <td style=\"text-align: right\">72.62</td>\n      <td style=\"text-align: right\">67.80</td>\n      <td style=\"text-align: right\">55.07</td>\n      <td style=\"text-align: right\">67.25</td>\n      <td style=\"text-align: right\">64.25</td>\n      <td style=\"text-align: right\">54.54</td>\n      <td style=\"text-align: right\">73.67</td>\n      <td style=\"text-align: right\">25.74</td>\n      <td style=\"text-align: right\"><strong>91.24</strong></td>\n      <td style=\"text-align: right\">42.03</td>\n      <td style=\"text-align: right\">73.59</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"vidore-text2image-visual-document-retrieval-benchmark\">ViDoRe (Benchmark de recherche de documents visuels Text2Image)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2407.01449\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">ColPali : Recherche efficace de documents avec des modèles de vision et de langage</div><div class=\"kg-bookmark-description\">Les documents sont des structures visuellement riches qui transmettent l'information à travers le texte, mais aussi les figures, les mises en page, les tableaux, ou même les polices. Comme les systèmes de recherche modernes s'appuient principalement sur l'information textuelle qu'ils extraient des pages de documents pour les indexer - souvent par des processus longs et fragiles - ils peinent à exploiter efficacement les indices visuels clés. Cela limite leurs capacités dans de nombreuses applications pratiques de recherche de documents comme la Génération Augmentée par Recherche (RAG). Pour évaluer les systèmes actuels sur la recherche de documents visuellement riches, nous présentons le benchmark de recherche de documents visuels ViDoRe, composé de diverses tâches de recherche au niveau des pages couvrant plusieurs domaines, langues et contextes pratiques. La complexité inhérente et les lacunes de performance des systèmes modernes motivent un nouveau concept : effectuer la recherche de documents en incorporant directement les images des pages de documents. Nous publions ColPali, un modèle de vision et de langage entraîné à produire des embeddings multi-vecteurs de haute qualité à partir d'images de pages de documents. Combiné à un mécanisme de correspondance à interaction tardive, ColPali surpasse largement les pipelines modernes de recherche de documents tout en étant drastiquement plus simple, plus rapide et entraînable de bout en bout. Nous publions les modèles, données, code et benchmarks sous licences ouvertes sur https://hf.co/vidore.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-16.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Manuel Faysse</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-12.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ViDoRe est un benchmark conçu pour évaluer la capacité des systèmes de recherche à faire correspondre des requêtes avec des documents pertinents en utilisant des caractéristiques visuelles. Il couvre diverses tâches de recherche au niveau de la page dans plusieurs domaines et langues. Le benchmark se concentre sur les éléments visuels des documents.</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th style=\"text-align: right\">AVG<br>(NDCG@5)</th>\n      <th style=\"text-align: right\">TAT-DQA</th>\n      <th style=\"text-align: right\">Shift<br>Project</th>\n      <th style=\"text-align: right\">Artificial<br>Intelligence</th>\n      <th style=\"text-align: right\">Government<br>Reports</th>\n      <th style=\"text-align: right\">ArxivQA</th>\n      <th style=\"text-align: right\">DocVQA</th>\n      <th style=\"text-align: right\">Healthcare<br>Industry</th>\n      <th style=\"text-align: right\">InfoVQA</th>\n      <th style=\"text-align: right\">Energy</th>\n      <th style=\"text-align: right\">TabFQuad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>91.02</strong></td>\n      <td style=\"text-align: right\"><strong>81.83</strong></td>\n      <td style=\"text-align: right\"><strong>93.22</strong></td>\n      <td style=\"text-align: right\"><strong>99.63</strong></td>\n      <td style=\"text-align: right\"><strong>97.59</strong></td>\n      <td style=\"text-align: right\"><strong>89.82</strong></td>\n      <td style=\"text-align: right\"><strong>62.58</strong></td>\n      <td style=\"text-align: right\"><strong>99.26</strong></td>\n      <td style=\"text-align: right\"><strong>92.88</strong></td>\n      <td style=\"text-align: right\"><strong>96.06</strong></td>\n      <td style=\"text-align: right\"><strong>97.32</strong></td>\n    </tr>\n    <tr>\n      <td>MrLight/dse-qwen2-2b-mr1-v1</td>\n      <td style=\"text-align: right\">84.48</td>\n      <td style=\"text-align: right\">66.64</td>\n      <td style=\"text-align: right\">79.39</td>\n      <td style=\"text-align: right\">96.45</td>\n      <td style=\"text-align: right\">95.30</td>\n      <td style=\"text-align: right\">84.53</td>\n      <td style=\"text-align: right\">55.47</td>\n      <td style=\"text-align: right\">96.85</td>\n      <td style=\"text-align: right\">86.39</td>\n      <td style=\"text-align: right\">91.80</td>\n      <td style=\"text-align: right\">92.03</td>\n    </tr>\n  \n    <tr>\n      <td>MonoQwen2-VL-v0.1</td>\n      <td style=\"text-align: right\">87.64</td>\n      <td style=\"text-align: right\">79.50</td>\n      <td style=\"text-align: right\">76.38</td>\n      <td style=\"text-align: right\">98.39</td>\n      <td style=\"text-align: right\">93.63</td>\n      <td style=\"text-align: right\">89.50</td>\n      <td style=\"text-align: right\">57.47</td>\n      <td style=\"text-align: right\">98.39</td>\n      <td style=\"text-align: right\">92.12</td>\n      <td style=\"text-align: right\">95.29</td>\n      <td style=\"text-align: right\">95.75</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"m-beir-text2image-image2text-multimodal-benchmark-for-instructed-retrieval\">M-BEIR (Text2Image, Image2Text, Benchmark Multimodal pour la Recherche par Instructions)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2311.17136\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">UniIR : Formation et Évaluation de Systèmes Universels de Recherche d'Information Multimodale</div><div class=\"kg-bookmark-description\">Les modèles de recherche d'information (RI) existants supposent souvent un format homogène, limitant leur applicabilité aux divers besoins des utilisateurs, comme la recherche d'images avec des descriptions textuelles, la recherche d'un article d'actualité avec une image d'en-tête, ou la recherche d'une photo similaire avec une image en requête. Pour répondre à ces différentes demandes de recherche d'information, nous présentons UniIR, un système unifié de recherche multimodale guidé par instructions capable de gérer huit tâches de recherche distinctes à travers les modalités. UniIR, un système de recherche unique entraîné conjointement sur dix ensembles de données multimodales-RI diverses, interprète les instructions des utilisateurs pour exécuter diverses tâches de recherche, démontrant des performances robustes sur les ensembles de données existants et une généralisation zero-shot à de nouvelles tâches. Nos expériences soulignent que l'entraînement multi-tâches et l'ajustement des instructions sont les clés de la capacité de généralisation d'UniIR. De plus, nous construisons M-BEIR, un benchmark de recherche multimodale avec des résultats complets, pour standardiser l'évaluation de la recherche d'information multimodale universelle.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Cong Wei</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-15.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>M-BEIR est un benchmark complet à grande échelle conçu pour former et évaluer des modèles de recherche multimodale. Il comprend huit tâches de recherche multimodale et dix ensembles de données provenant de divers domaines et sources. Le benchmark se concentre sur la recherche guidée par instructions.</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n        <tr>\n          <th>Model</th>\n            <th>MBEIR t2i VisualNews<br>Recall@5</th>\n            <th>MBEIR t2i MSCOCO<br>Recall@5</th>\n            <th>MBEIR t2i Fashion200K<br>Recall@10</th>\n            <th>MBEIR i2t VisualNews<br>Recall@5</th>\n            <th>MBEIR i2t MSCOCO<br>Recall@5</th>\n            <th>MBEIR i2t Fashion200K<br>Recall@10</th>\n        </tr>\n    </thead>\n        <tr>\n            <td>jina-reranker-m0</td>\n            <td align=\"right\"><b>23.89</b></td>\n            <td align=\"right\"><b>72.19</b></td>\n            <td align=\"right\">9.79</td>\n            <td align=\"right\"><b>17.61</b></td>\n            <td align=\"right\">41.21</td>\n            <td align=\"right\"><b>11.56</b></td>\n        </tr>\n        <tr>\n            <td>jinaai/jina-clip-v2</td>\n            <td align=\"right\">15.42</td>\n            <td align=\"right\">52.28</td>\n            <td align=\"right\">7.03</td>\n            <td align=\"right\">11.63</td>\n            <td align=\"right\">28.80</td>\n            <td align=\"right\">8.78</td>\n        </tr>\n        <tr>\n            <td>MonoQwen2-VL-v0.1</td>\n            <td align=\"right\">22.74</td>\n            <td align=\"right\">71.29</td>\n            <td align=\"right\"><b>10.00</b></td>\n            <td align=\"right\">15.08</td>\n            <td align=\"right\"><b>42.24</b></td>\n            <td align=\"right\">11.25</td>\n        </tr>\n    </table>\n<!--kg-card-end: html-->\n<h3 id=\"winoground-text2text-text2image\">Winoground (Text2Text, Text2Image)</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2204.03162\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Winoground : Évaluation des Modèles de Vision et de Langage pour la Composition Visio-Linguistique</div><div class=\"kg-bookmark-description\">Nous présentons une nouvelle tâche et un nouveau jeu de données pour évaluer la capacité des modèles de vision et de langage à effectuer un raisonnement compositionnel visio-linguistique, que nous appelons Winoground. Étant donné deux images et deux légendes, l'objectif est de les faire correspondre correctement - mais crucialement, les deux légendes contiennent un ensemble de mots complètement identique, uniquement dans un ordre différent. Le jeu de données a été soigneusement créé manuellement par des annotateurs experts et est étiqueté avec un riche ensemble de balises détaillées pour faciliter l'analyse des performances des modèles. Nous testons une gamme diverse de modèles de vision et de langage à la pointe de la technologie et constatons que, étonnamment, aucun d'entre eux ne fait beaucoup mieux que le hasard. Manifestement, ces modèles ne sont pas aussi compétents en raisonnement compositionnel visio-linguistique que nous aurions pu l'espérer. Nous effectuons une analyse approfondie pour obtenir des insights sur la façon dont les travaux futurs pourraient tenter d'atténuer les lacunes de ces modèles. Nous visons à ce que Winoground serve d'ensemble d'évaluation utile pour faire progresser l'état de l'art et stimuler les progrès dans ce domaine. Le jeu de données est disponible sur https://huggingface.co/datasets/facebook/winoground.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-15.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Tristan Thrush</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-11.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Winoground est une tâche et un jeu de données novateurs pour évaluer la capacité des modèles de vision et de langage à effectuer un raisonnement compositionnel visio-linguistique. Il utilise des légendes jumelles avec un contenu lexical identique et emploie des paires image-légende contrastives. L'accent est mis sur le raisonnement compositionnel.</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>Text</th>\n      <th>Image</th>\n      <th>Group</th>\n      <th>Avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>57.00</strong></td>\n      <td style=\"text-align: right\"><strong>40.75</strong></td>\n      <td style=\"text-align: right\"><strong>34.00</strong></td>\n      <td style=\"text-align: right\"><strong>43.92</strong></td>\n    </tr>\n    <tr>\n      <td>MrLight/dse-qwen2-2b-mrl-v1</td>\n      <td style=\"text-align: right\">7.50</td>\n      <td style=\"text-align: right\">9.25</td>\n      <td style=\"text-align: right\">1.75</td>\n      <td style=\"text-align: right\">6.17</td>\n    </tr>\n    <tr>\n      <td>MonoQwen2-VL-v0.1</td>\n      <td style=\"text-align: right\">52.00</td>\n      <td style=\"text-align: right\">36.25</td>\n      <td style=\"text-align: right\">31.50</td>\n      <td style=\"text-align: right\">39.92</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Winoground évalue les modèles vision-langage selon trois métriques clés : le Score Textuel, le Score d'Image et le Score de Groupe. Le Score Textuel mesure si un modèle associe correctement les légendes aux images, tandis que le Score d'Image évalue s'il sélectionne la bonne image pour une légende. Le Score de Groupe, la métrique la plus rigoureuse, exige que toutes les relations légende-image soient correctement identifiées. Les scores sont des pourcentages représentant les taux de précision, les valeurs plus élevées indiquant de meilleures capacités de raisonnement.</p><h2 id=\"conclusion\">Conclusion</h2><p><code>jina-reranker-m0</code> est notre première tentative d'unifier les modalités textuelles et visuelles dans un modèle decoder-only unique. Cette nouvelle architecture intègre les leçons tirées de nos précédents modèles de récupération encoder-only, notamment <code>jina-clip-v2</code>, <code>jina-embeddings-v3</code>, <code>jina-reranker-v2-base-multilingual</code> et <code>jina-embeddings-v2-base-code</code>.</p><p>Le nouveau modèle débloque non seulement des capacités pour les tâches de recherche multimodale, comme le reclassement texte-image et le reclassement de documents visuels, mais démontre également une performance améliorée par rapport à <code>jina-reranker-v2-base-multilingual</code> sur les tâches de reclassement texte-texte et texte-code. Nous désignons cette nouvelle série de modèles comme la « série m » pour souligner sa nature multimodale.</p><p>En comparant <code>jina-reranker-m0</code> avec <code>jina-reranker-v2-base-multilingual</code>, notre objectif pour la série m est d'atteindre la multimodalité tout en améliorant les performances sur les tâches uniquement textuelles à un niveau comparable aux modèles spécialisés texte uniquement. Certains pourraient questionner l'intérêt d'utiliser un modèle 8 fois plus grand si l'amélioration des performances sur les tâches textuelles semble marginale. Bien qu'il soit vrai pour le moment que <code>m0</code> n'apporte peut-être pas une valeur ajoutée substantielle par rapport à <code>v2</code> pour les applications uniquement textuelles, l'architecture decoder-only ouvre de nombreuses nouvelles possibilités qui n'étaient pas réalisables avec les architectures encoder-only, notamment :</p><ul><li>Un véritable reclassement multimodal</li><li>Reclassement par liste et déduplication des documents</li><li>Explicabilité des scores de classement via le mécanisme d'attention</li></ul><p>Nos travaux futurs se concentreront sur l'amélioration du reclasseur texte uniquement et l'exploitation complète des nouvelles fonctionnalités rendues possibles par cette architecture multimodale pour obtenir une recherche meilleure et plus <em>étendue</em>.</p>",
  "comment_id": "67ea5eb45dcba60001c30f0a",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/04/banner-reranker-m0--1-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-03-31T11:21:56.000+02:00",
  "updated_at": "2025-04-08T13:21:13.000+02:00",
  "published_at": "2025-04-08T13:10:38.000+02:00",
  "custom_excerpt": "Introducing jina-reranker-m0, our new multilingual multimodal reranker for retrieving visual documents, with SOTA performance on multilingual long documents and code searching tasks.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-reranker-m0-multilingual-multimodal-document-reranker/",
  "excerpt": "Présentation de jina-reranker-m0, notre nouveau réordonnanceur multimodal multilingue pour la recherche de documents visuels, offrant des performances à l'état de l'art sur la recherche de longs documents multilingues et de code source.",
  "reading_time": 20,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}