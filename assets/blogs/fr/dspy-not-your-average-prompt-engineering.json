{
  "slug": "dspy-not-your-average-prompt-engineering",
  "id": "66077bf0a5c39b0001044181",
  "uuid": "e242c77c-f712-462c-9745-3e9269eb8a8b",
  "title": "DSPy : Au-delà du simple prompt engineering",
  "html": "<div class=\"kg-card kg-file-card\"><a class=\"kg-file-card-container\" href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/04/DSPy-Not-Your-Average-Prompt-Engineering--1-.pdf\" title=\"Download\" download=\"\"><div class=\"kg-file-card-contents\"><div class=\"kg-file-card-title\">[Diapositives] DSPy : Au-delà de l'ingénierie de prompts classique</div><div class=\"kg-file-card-caption\">Une présentation faite par Han le 15 avril 2024 à Mountain View.</div><div class=\"kg-file-card-metadata\"><div class=\"kg-file-card-filename\">DSPy Not Your Average Prompt Engineering (1).pdf</div><div class=\"kg-file-card-filesize\">7 MB</div></div></div><div class=\"kg-file-card-icon\"><svg viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"></polyline><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"></line><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"></circle></svg></div></a></div><p>J'ai récemment étudié DSPy, un framework de pointe développé par le groupe Stanford NLP visant à optimiser algorithmiquement les prompts des modèles de langage (LM). Au cours des trois derniers jours, j'ai recueilli quelques premières impressions et des insights précieux sur DSPy. Notez que mes observations ne sont pas destinées à remplacer la documentation officielle de DSPy. En fait, je recommande vivement de lire <a href=\"https://dspy-docs.vercel.app/?ref=jina-ai-gmbh.ghost.io\">leur documentation</a> et leur <a href=\"https://github.com/stanfordnlp/dspy/blob/main/README.md?ref=jina-ai-gmbh.ghost.io\">README</a> au moins une fois avant de plonger dans cet article. Ma discussion ici reflète une compréhension préliminaire de DSPy, après avoir passé quelques jours à explorer ses capacités. Il existe plusieurs fonctionnalités avancées, telles que les DSPy Assertions, le Typed Predictor et l'ajustement des poids LM, que je n'ai pas encore explorées en profondeur.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/stanfordnlp/dspy?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - stanfordnlp/dspy: DSPy: The framework for programming—not prompting—foundation models</div><div class=\"kg-bookmark-description\">DSPy: The framework for programming—not prompting—foundation models - stanfordnlp/dspy</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">stanfordnlp</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/b8c1b2b4b3ff9c22d486f5c69dbda5fee6cc8dda8a42aaf1c2e154c17b7dc159/stanfordnlp/dspy\" alt=\"\"></div></a></figure><p>Malgré mon expérience avec Jina AI, qui se concentre principalement sur les fondamentaux de la recherche, mon intérêt pour DSPy n'a pas été directement motivé par son potentiel en matière de Retrieval-Augmented Generation (RAG). J'étais plutôt intrigué par la possibilité d'utiliser DSPy pour l'ajustement automatique des prompts afin de résoudre certaines tâches de génération.</p><p>Si vous débutez avec DSPy et cherchez un point d'entrée accessible, ou si vous connaissez déjà le framework mais trouvez la documentation officielle confuse ou overwhelming, cet article est fait pour vous. J'ai également choisi de ne pas suivre strictement l'idiome de DSPy, qui peut sembler intimidant pour les nouveaux venus. Cela étant dit, plongeons plus profondément.</p><h2 id=\"what-i-like-about-dspy\">Ce que j'apprécie dans DSPy</h2><h3 id=\"dspy-closing-the-loop-of-prompt-engineering\">DSPy ferme la boucle de l'ingénierie de prompts</h3><p>Ce qui m'enthousiasme le plus avec DSPy, c'est son approche pour fermer la boucle du cycle d'ingénierie de prompts, transformant ce qui est souvent un processus <em>manuel</em> et <em>artisanal</em> en un workflow <em>structuré</em> et <em>bien défini</em> d'apprentissage automatique : c'est-à-dire la préparation des datasets, la définition du modèle, l'entraînement, l'évaluation et les tests. <strong>À mon avis, c'est l'aspect le plus révolutionnaire de DSPy.</strong></p><p>En voyageant dans la Bay Area et en parlant à de nombreux fondateurs de startups focalisés sur l'évaluation des LLM, j'ai souvent entendu des discussions sur les métriques, les hallucinations, l'observabilité et la conformité. Cependant, ces conversations ne progressent souvent pas vers les étapes cruciales suivantes : <strong>Avec toutes ces métriques en main, que faisons-nous ensuite ?</strong> Peut-on considérer comme une approche stratégique le fait de modifier la formulation de nos prompts, en espérant que certains mots magiques (par exemple, « ma grand-mère est mourante ») pourraient améliorer nos métriques ? Cette question est restée sans réponse pour de nombreuses startups d'évaluation LLM, et c'était une question que je ne pouvais pas non plus aborder — jusqu'à ce que je découvre DSPy. DSPy introduit une méthode claire et programmatique pour optimiser les prompts basée sur des métriques spécifiques, ou même pour optimiser l'ensemble du pipeline LLM, y compris les prompts et les poids LLM.</p><p>Harrison, le PDG de LangChain, et Logan, l'ancien responsable des relations développeurs d'OpenAI, ont tous deux déclaré sur le <a href=\"https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924?ref=jina-ai-gmbh.ghost.io\">podcast Unsupervised Learning</a> que 2024 devrait être une année charnière pour l'évaluation des LLM. C'est pour cette raison que je pense que DSPy mérite plus d'attention qu'il n'en reçoit actuellement, car DSPy fournit la pièce manquante cruciale du puzzle.</p><h3 id=\"dspy-separating-logic-from-textual-representation\">DSPy sépare la logique de la représentation textuelle</h3><p>Un autre aspect de DSPy qui m'impressionne est qu'il transforme l'ingénierie de prompts en un module reproductible et agnostique aux LLM. Pour y parvenir, <strong>il extrait la logique du prompt, créant une séparation claire des préoccupations entre la <em>logique</em> et la <em>représentation textuelle</em></strong>, comme illustré ci-dessous.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png\" class=\"kg-image\" alt=\"Flowchart depicting sentiment analysis process with steps such as Prompt, Logic, and Textual Representation on a black backgr\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--5-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--5-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Dans DSPy, le Prompt se compose de la logique intrinsèque (c'est-à-dire </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>dspy.Module</span></code><span style=\"white-space: pre-wrap;\">) et de sa représentation textuelle. La logique est immuable, reproductible, testable et agnostique au LLM. La représentation textuelle n'est que la conséquence de la logique.</span></figcaption></figure><p><strong>Le concept de DSPy de la logique comme \"cause\" immuable, testable et agnostique au LLM, avec la représentation textuelle simplement comme sa \"conséquence\"</strong>, peut sembler initialement déroutant. C'est particulièrement vrai à la lumière de la croyance répandue selon laquelle \"le futur du langage de programmation est le langage naturel\". En adhérant à l'idée que \"l'ingénierie de prompts est l'avenir\", on pourrait éprouver un moment de confusion face à la philosophie de conception de DSPy. Contrairement à l'attente de simplification, DSPy introduit une gamme de modules et de syntaxes de signatures, semblant faire régresser le prompting en langage naturel vers la complexité de la programmation en C !</p><p>Mais pourquoi adopter cette approche ? Selon ma compréhension, <strong>au cœur de la programmation de prompts se trouve la logique fondamentale, la communication servant d'amplificateur</strong>, pouvant potentiellement améliorer ou diminuer son efficacité. La directive <code>\"Do sentiment classification\"</code> représente la logique fondamentale, tandis qu'une phrase comme <code>\"Follow these demonstrations or I will fire you\"</code> est une façon de la communiquer. Comme dans les interactions réelles, les difficultés à accomplir les choses proviennent souvent non pas d'une logique défaillante mais d'une communication problématique. Cela explique pourquoi beaucoup, particulièrement les non-natifs, trouvent l'ingénierie de prompts difficile. J'ai observé des ingénieurs logiciels très compétents dans mon entreprise lutter avec l'ingénierie de prompts, non pas par manque de logique, mais parce qu'ils ne \"parlent pas le même langage\". En séparant la logique du prompt, <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/modules?ref=jina-ai-gmbh.ghost.io\">DSPy permet une programmation déterministe de la logique via <code>dspy.Module</code></a>, permettant aux développeurs de se concentrer sur la logique de la même manière qu'en ingénierie traditionnelle, quel que soit le LLM utilisé.</p><p>Alors, si les développeurs se concentrent sur la logique, qui gère la représentation textuelle ? <strong>DSPy assume ce rôle, utilisant vos données et métriques d'évaluation pour affiner la représentation textuelle</strong>—tout, de la détermination du focus narratif à l'optimisation des indices, en passant par le choix de bonnes démonstrations. Remarquablement, DSPy peut même utiliser des métriques d'évaluation pour affiner les poids du LLM !</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png\" class=\"kg-image\" alt=\"Flowchart illustrating a language model with branches for training data, logic, textual representation, and final results.\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Pour moi, les contributions clés de DSPy — fermer la boucle d'entraînement et d'évaluation dans l'ingénierie de prompts et séparer la logique de la représentation textuelle — soulignent son importance potentielle pour les systèmes LLM/Agent. Une vision ambitieuse certes, mais définitivement nécessaire !</p><h2 id=\"what-i-think-dspy-can-improve\">Ce que je pense que DSPy peut améliorer</h2><p>Premièrement, DSPy présente une courbe d'apprentissage abrupte pour les nouveaux venus en raison de ses idiomes. Des termes comme <code>signature</code>, <code>module</code>, <code>program</code>, <code>teleprompter</code>, <code>optimization</code>, et <code>compile</code> peuvent être overwhelming. Même pour ceux qui maîtrisent l'ingénierie de prompts, naviguer parmi ces concepts dans DSPy peut être un véritable labyrinthe.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Yeah, DSPy really needs someone to come in and explain everything without suitcase words. <a href=\"https://twitter.com/CShorten30?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">@CShorten30</a> does a great job, but we need more.</p>— Jonathan Mugan (@jmugan) <a href=\"https://twitter.com/jmugan/status/1773036172723236895?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">March 27, 2024</a></blockquote>\n<script async=\"\" src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></figure><p>Cette complexité fait écho à mon expérience avec <a href=\"https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io\">Jina 1.0</a>, où nous avions introduit une série d'expressions idiomatiques telles que <code>chunk</code>, <code>document</code>, <code>driver</code>, <code>executor</code>, <code>pea</code>, <code>pod</code>, <code>querylang</code> et <code>flow</code> (nous avions même conçu d'adorables autocollants pour aider les utilisateurs à s'en souvenir !).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Document-FLAT--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pea-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/QueryLang--FLAT.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png 700w\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--3-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pod-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--5-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png 700w\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">La plupart de ces concepts initiaux ont été supprimés lors des restructurations ultérieures de Jina. Aujourd'hui, seuls </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Executor</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Document</span></code><span style=\"white-space: pre-wrap;\">, et </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Flow</span></code><span style=\"white-space: pre-wrap;\"> ont survécu à la \"grande purge.\" Nous avons ajouté un nouveau concept, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Deployment</span></code><span style=\"white-space: pre-wrap;\">, dans Jina 3.0 ; donc cela équilibre les choses. 🤷</span></p></figcaption></figure><p>Ce problème n'est pas unique à DSPy ou Jina ; rappelez-vous la myriade de concepts et d'abstractions introduits par TensorFlow entre les versions 0.x et 1.x. Je pense que ce problème émerge souvent dans les premiers stades des frameworks logiciels, où il y a une volonté <strong>de refléter directement les notations académiques dans le code pour assurer une précision et une reproductibilité maximales</strong>. Cependant, tous les utilisateurs ne valorisent pas ces abstractions granulaires, les préférences variant du désir de lignes de code simples aux demandes de plus grande flexibilité. J'ai discuté en détail de ce sujet d'abstraction dans les frameworks logiciels dans un article de blog de 2020, que les lecteurs intéressés pourraient trouver utile.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/?ref=jina-ai-gmbh.ghost.io#layer-of-abstraction\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Layer of Abstraction When Building \"Tensorflow\" for Search · Han Xiao Tech Blog - Neural Search &amp; AI Engineering</div><div class=\"kg-bookmark-description\">Since Feb. 2020, I started a new venture called Jina AI. Our mission is to build an open-source neural search ecosystem for businesses and developers, ... · Han Xiao</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://hanxiao.io/wechaticon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/blog-abstraction-banner.jpg\" alt=\"\"></div></a></figure><p>Deuxièmement, la documentation de DSPy manque parfois de cohérence. Des termes comme <code>module</code> et <code>program</code>, <code>teleprompter</code> et <code>optimizer</code>, ou <code>optimize</code> et <code>compile</code> (parfois appelés <code>training</code> ou <code>bootstrapping</code>) sont utilisés de manière interchangeable, ajoutant à la confusion. Par conséquent, j'ai passé mes premières heures avec DSPy à essayer de comprendre exactement ce qu'il <code>optimizes</code> et ce que le processus de <code>bootstrapping</code> implique.</p><p>Malgré ces obstacles, en approfondissant DSPy et en revenant sur la documentation, vous vivrez probablement des moments de clarté où tout commence à prendre sens, révélant les connexions entre sa terminologie unique et les constructions familières vues dans des frameworks comme PyTorch. Cependant, DSPy a indéniablement une marge d'amélioration pour les versions futures, particulièrement pour rendre le framework plus accessible aux ingénieurs de prompts <em>sans</em> expérience préalable avec PyTorch.</p><h2 id=\"common-stumbling-blocks-for-dspy-newbies\">Points d'achoppement courants pour les débutants avec DSPy</h2><p>Dans les sections ci-dessous, j'ai compilé une liste de questions qui ont initialement entravé ma progression avec DSPy. Mon but est de partager ces insights dans l'espoir qu'ils puissent clarifier des défis similaires pour d'autres apprenants.</p><h3 id=\"what-are-teleprompter-optimization-and-compile-whats-exactly-being-optimized-in-dspy\">Que sont <code>teleprompter</code>, <code>optimization</code>, et <code>compile</code> ? Qu'est-ce qui est exactement optimisé dans DSPy ?</h3><p>Dans DSPy, \"Teleprompters\" est l'optimiseur (et il semble que <a href=\"https://twitter.com/lateinteraction?ref=jina-ai-gmbh.ghost.io\">@lateinteraction</a> remanie la documentation et le code pour clarifier cela). La fonction <code>compile</code> agit au cœur de cet optimiseur, similaire à l'appel de <code>optimizer.optimize()</code>. Pensez-y comme l'équivalent de l'entraînement dans DSPy. Ce processus de <code>compile()</code> vise à ajuster : </p><ul><li>les démonstrations few-shot,</li><li>les instructions, </li><li>les poids du LLM </li></ul><p>Cependant, la plupart des tutoriels DSPy pour débutants n'abordent pas l'ajustement des poids et des instructions, ce qui mène à la question suivante.</p><h3 id=\"whats-bootstrap-in-dspy-all-about\">Qu'est-ce que <code>bootstrap</code> dans DSPy ?</h3><p>Bootstrap fait référence à la création de démonstrations auto-générées pour l'apprentissage few-shot en contexte, une partie cruciale du processus <code>compile()</code> (c'est-à-dire, l'optimisation/entraînement comme mentionné ci-dessus). Ces démos few-shot sont générées à partir de données étiquetées fournies par l'utilisateur ; et une démo comprend souvent l'entrée, la sortie, le raisonnement (par exemple, dans les Chaînes de Pensée), et les entrées & sorties intermédiaires (pour les prompts multi-étapes). Bien sûr, des démos few-shot de qualité sont essentielles pour l'excellence des résultats. Pour cela, DSPy permet des fonctions métriques définies par l'utilisateur pour s'assurer que seules les démos répondant à certains critères sont choisies, ce qui mène à la question suivante.</p><h3 id=\"whats-dspy-metric-function\">Qu'est-ce que la fonction métrique de DSPy ?</h3><p>Après une expérience pratique avec DSPy, j'en suis venu à croire que la fonction métrique mérite beaucoup plus d'attention que ce que la documentation actuelle lui accorde. La fonction métrique dans DSPy joue un rôle crucial dans les phases d'évaluation <em>et</em> d'entraînement, agissant également comme une fonction de \"perte\", grâce à sa nature implicite (contrôlée par <code>trace=None</code>) :</p><pre><code class=\"language-python\">def keywords_match_jaccard_metric(example, pred, trace=None):  \n    # Jaccard similarity between example keywords and predicted keywords  \n    A = set(normalize_text(example.keywords).split())  \n    B = set(normalize_text(pred.keywords).split())  \n    j = len(A &amp; B) / len(A | B)\n    if trace is not None:\n        # act as a \"loss\" function\n        return j  \n    return j &gt; 0.8  # act as evaluation</code></pre><p>Cette approche diffère significativement de l'apprentissage automatique traditionnel, où la fonction de perte est généralement continue et dérivable (par exemple, hinge/MSE), tandis que la métrique d'évaluation peut être totalement différente et discrète (par exemple, NDCG). Dans DSPy, les fonctions d'évaluation et de perte sont unifiées dans la fonction métrique, qui peut être discrète et renvoie le plus souvent une valeur booléenne. La fonction métrique peut également intégrer un LLM ! Dans l'exemple ci-dessous, j'ai implémenté une correspondance approximative utilisant un LLM pour déterminer si la valeur prédite et la réponse de référence sont similaires en magnitude, par exemple, \"1 million de dollars\" et \"1M$\" renverraient vrai.</p><pre><code class=\"language-python\">class Assess(dspy.Signature):  \n    \"\"\"Assess the if the prediction is in the same magnitude to the gold answer.\"\"\"  \n  \n    gold_answer = dspy.InputField(desc='number, could be in natural language')  \n    prediction = dspy.InputField(desc='number, could be in natural language')  \n    assessment = dspy.OutputField(desc='yes or no, focus on the number magnitude, not the unit or exact value or wording')  \n  \ndef same_magnitude_correct(example, pred, trace=None):  \n    return dspy.Predict(Assess)(gold_answer=example.answer, prediction=pred.answer).assessment.lower() == 'yes'</code></pre><p>Aussi puissante soit-elle, la fonction métrique influence significativement l'expérience utilisateur de DSPy, déterminant non seulement l'évaluation finale de la qualité mais affectant également les résultats d'optimisation. Une fonction métrique bien conçue peut conduire à des prompts optimisés, tandis qu'une fonction mal conçue peut faire échouer l'optimisation. Lorsque vous abordez un nouveau problème avec DSPy, vous pourriez passer autant de temps à concevoir la logique (c'est-à-dire <code>DSPy.Module</code>) que sur la fonction métrique. Cette double attention portée à la logique et aux métriques peut être intimidante pour les débutants.</p><h3 id=\"bootstrapped-0-full-traces-after-20-examples-in-round-0-what-does-this-mean\"><code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code> que signifie ce message ?</h3><p>Ce message qui apparaît discrètement pendant <code>compile()</code> mérite toute votre attention, car il signifie essentiellement que l'optimisation/compilation a échoué, et que le prompt que vous obtenez n'est pas meilleur qu'un simple few-shot. Que se passe-t-il ? J'ai résumé quelques conseils pour vous aider à déboguer votre programme DSPy lorsque vous rencontrez ce message :</p><h4 id=\"your-metric-function-is-incorrect\">Votre fonction métrique est incorrecte</h4><p>Est-ce que la fonction <code>your_metric</code>, utilisée dans <code>BootstrapFewShot(metric=your_metric)</code>, est correctement implémentée ? Effectuez quelques tests unitaires. Est-ce que <code>your_metric</code> renvoie parfois <code>True</code>, ou renvoie-t-elle toujours <code>False</code> ? Notez que renvoyer <code>True</code> est crucial car c'est le critère pour que DSPy considère l'exemple bootstrappé comme un \"succès\". Si vous renvoyez chaque évaluation comme <code>True</code>, alors chaque exemple est considéré comme un \"succès\" dans le bootstrapping ! Ce n'est pas idéal, bien sûr, mais c'est ainsi que vous pouvez ajuster la rigueur de la fonction métrique pour modifier le résultat <code>\"Bootstrapped 0 full traces\"</code>. Notez que bien que la documentation de DSPy indique que les métriques peuvent également renvoyer des valeurs scalaires, après avoir examiné le code sous-jacent, je ne le recommanderais pas aux débutants.</p><h4 id=\"your-logic-dspymodule-is-incorrect\">Votre logique (<code>DSPy.Module</code>) est incorrecte</h4><p>Si la fonction métrique est correcte, vous devez alors vérifier si votre logique <code>dspy.Module</code> est correctement implémentée. Tout d'abord, vérifiez que la <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io\">signature DSPy</a> est correctement attribuée pour chaque étape. Les signatures en ligne, comme <code>dspy.Predict('question->answer')</code>, sont faciles à utiliser, mais pour la qualité, je suggère fortement d'implémenter avec des <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io#class-based-dspy-signatures\">signatures basées sur des classes</a>. Plus précisément, ajoutez des docstrings descriptives à la classe, remplissez les champs desc pour <code>InputField</code> et <code>OutputField</code>—tout cela fournit au LM des indices sur chaque champ. Ci-dessous, j'ai implémenté deux <code>DSPy.Module</code> multi-étapes pour résoudre des <a href=\"https://en.wikipedia.org/wiki/Fermi_problem?ref=jina-ai-gmbh.ghost.io\">problèmes de Fermi</a>, l'un avec une signature en ligne, l'autre avec une signature basée sur des classes.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiSolver(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict('question -> initial_guess')\n        self.step2 = dspy.Predict('question, initial_guess -> calculated_estimation')\n        self.step3 = dspy.Predict('question, initial_guess, calculated_estimation -> variables_and_formulae')\n        self.step4 = dspy.ReAct('question, initial_guess, calculated_estimation, variables_and_formulae -> gathering_data')\n        self.step5 = dspy.Predict('question, initial_guess, calculated_estimation, variables_and_formulae, gathering_data -> answer')\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Solveur de problèmes de Fermi utilisant uniquement une signature en ligne</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiStep1(dspy.Signature):\n    question = dspy.InputField(desc='Fermi problems involve the use of estimation and reasoning')\n    initial_guess = dspy.OutputField(desc='Have a guess – don't do any calculations yet')\n\nclass FermiStep2(FermiStep1):\n    initial_guess = dspy.InputField(desc='Have a guess – don't do any calculations yet')\n    calculated_estimation = dspy.OutputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n\nclass FermiStep3(FermiStep2):\n    calculated_estimation = dspy.InputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n    variables_and_formulae = dspy.OutputField(desc='Write a formula or procedure to solve your problem')\n\nclass FermiStep4(FermiStep3):\n    variables_and_formulae = dspy.InputField(desc='Write a formula or procedure to solve your problem')\n    gathering_data = dspy.OutputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n\nclass FermiStep5(FermiStep4):\n    gathering_data = dspy.InputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n    answer = dspy.OutputField(desc='the final answer, must be a numerical value')\n\nclass FermiSolver2(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict(FermiStep1)\n        self.step2 = dspy.Predict(FermiStep2)\n        self.step3 = dspy.Predict(FermiStep3)\n        self.step4 = dspy.Predict(FermiStep4)\n        self.step5 = dspy.Predict(FermiStep5)\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Solveur de problèmes de Fermi utilisant une signature basée sur des classes avec une description plus complète de chaque champ.</span></p></figcaption></figure><p>Vérifiez également la partie <code>def forward(self, )</code>. Pour les Modules multi-étapes, assurez-vous que la sortie (ou <em>toutes</em> les sorties comme dans <code>FermiSolver</code>) de la dernière étape est fournie comme entrée à l'étape suivante.</p><h4 id=\"your-problem-is-just-too-hard\">Votre problème est simplement trop difficile</h4><p>Si la métrique et le module semblent corrects, il est possible que votre problème soit simplement trop difficile et que la logique que vous avez implémentée ne soit pas suffisante pour le résoudre. Par conséquent, DSPy trouve qu'il est impossible de bootstrapper une démonstration avec votre logique et votre fonction métrique. À ce stade, voici quelques options à considérer :</p><ul><li><strong>Utilisez un LM plus puissant.</strong> Par exemple, remplacez <code>gpt-35-turbo-instruct</code> par <code>gpt-4-turbo</code> comme LM étudiant, utilisez un LM plus puissant comme professeur. Cela peut souvent être très efficace. Après tout, un modèle plus puissant signifie une meilleure compréhension des prompts.</li><li><strong>Améliorez votre logique.</strong> Ajoutez ou remplacez certaines étapes dans votre <code>dspy.Module</code> par des étapes plus complexes. Par exemple, remplacez <code>Predict</code> par <code>ChainOfThought</code> <code>ProgramOfThought</code>, ajoutez une étape <code>Retrieval</code>.</li><li><strong>Ajoutez plus d'exemples d'entraînement</strong>. Si 20 exemples ne suffisent pas, visez-en 100 ! Vous pouvez alors espérer qu'un exemple passe la vérification métrique et soit sélectionné par <code>BootstrapFewShot</code>.</li><li><strong>Reformulez le problème.</strong> Souvent, un problème devient insoluble lorsque la formulation est incorrecte. Mais si vous changez d'angle pour le regarder, les choses pourraient être beaucoup plus faciles et plus évidentes.</li></ul><p>En pratique, le processus implique un mélange d'essais et d'erreurs. Par exemple, j'ai abordé un problème particulièrement difficile : générer une icône SVG similaire aux icônes Google Material Design basée sur deux ou trois mots-clés. Ma stratégie initiale était d'utiliser un simple <code>DSPy.Module</code> qui utilise <code>dspy.ChainOfThought('keywords -> svg')</code>, couplé à une fonction métrique qui évaluait la similarité visuelle entre le SVG généré et le SVG Material Design de référence, similaire à un algorithme pHash. J'ai commencé avec 20 exemples d'entraînement, mais après le premier tour, j'ai obtenu <code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code>, indiquant que l'optimisation avait échoué. En augmentant le jeu de données à 100 exemples, en révisant mon module pour incorporer plusieurs étapes, et en ajustant le seuil de la fonction métrique, j'ai finalement obtenu 2 démonstrations bootstrappées et réussi à obtenir des prompts optimisés.</p>",
  "comment_id": "66077bf0a5c39b0001044181",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-03-30T03:41:52.000+01:00",
  "updated_at": "2024-04-23T10:46:48.000+02:00",
  "published_at": "2024-03-30T06:22:42.000+01:00",
  "custom_excerpt": "Heads up, Bay Area guys ditched their AVP already and buzz about DSPy now. Could DSPy be the new go-to framework for prompt engineering after LangChain and LlamaIndex?",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/dspy-not-your-average-prompt-engineering/",
  "excerpt": "Attention, les gars de la Bay Area ont déjà abandonné AVP et parlent maintenant de DSPy. DSPy pourrait-il être le nouveau framework de référence pour le prompt engineering après LangChain et LlamaIndex ?",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Screenshot of a Tetris-like game with \"Score: 40\" and \"Press Start 2P\" text on display.",
  "feature_image_caption": null
}