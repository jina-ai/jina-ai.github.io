{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "Ce que nous avons appris à ICML2024 avec PLaG, XRM, tinyBenchmark, MagicLens, Prompt Sketching etc.",
  "html": "<p>La <a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">Conférence Internationale sur l'Apprentissage Automatique</a> est l'une des conférences les plus prestigieuses de la communauté de l'apprentissage automatique et de l'intelligence artificielle, et a tenu sa réunion 2024 à Vienne du 21 au 27 juillet cette année.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Intérieur d'une salle de conférence académique animée avec de nombreux participants, certains portant des sacs à dos, et des posters de recherche affichés\" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>La conférence a été une expérience d'apprentissage intensive de 7 jours, avec des présentations orales et des opportunités d'échanger des idées directement avec d'autres chercheurs. Il y a beaucoup de travaux intéressants en cours dans l'apprentissage par renforcement, l'IA pour les sciences de la vie, l'apprentissage des représentations, les modèles multimodaux, et bien sûr dans les éléments fondamentaux du développement des modèles d'IA. Le tutoriel sur la <a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">Physique des Grands Modèles de Langage</a> était particulièrement important, explorant en profondeur le fonctionnement interne des LLM et offrant des réponses convaincantes à la question de savoir si les LLM mémorisent l'information ou appliquent un raisonnement lorsqu'ils s'expriment.</p><h2 id=\"our-work-on-jina-clip-v1\">Notre travail sur Jina-CLIP-v1</h2><p>Nous avons fait une <a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">présentation par poster</a> de <a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">notre travail sur notre nouveau modèle multimodal</a> <code>jina-clip-v1</code> dans le cadre de l'atelier <a href=\"https://icml.cc/virtual/2024/workshop/29957?ref=jina-ai-gmbh.ghost.io\">Multi-modal Foundation Models meet Embodied AI</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>La rencontre et la discussion de notre travail avec des collègues internationaux travaillant dans de nombreux domaines ont été très inspirantes. Notre présentation a reçu beaucoup de retours positifs, avec de nombreuses personnes intéressées par la façon dont Jina CLIP unifie les paradigmes d'apprentissage contrastif multimodal et unimodal. Les discussions ont porté sur les limites de l'architecture CLIP jusqu'aux extensions à d'autres modalités et aux applications dans l'appariement des peptides et des protéines.</p>[Video section preserved as is]<h2 id=\"our-favorites\">Nos Favoris</h2><p>Nous avons eu l'opportunité de discuter de nombreux projets et présentations d'autres chercheurs, et voici quelques-uns de nos favoris :</p><h3 id=\"plan-like-a-graph-plag\">Plan Like a Graph (PLaG)</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., & Pierrehumbert, J. B. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Graph-Enhanced Large Language Models in Asynchronous Plan Reasoning.</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>Beaucoup connaissent le « Few-Shot Prompting » ou le « Chain of Thought prompting ». <a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> a présenté une nouvelle méthode plus efficace à l'ICML : <em>Plan Like a Graph (PLaG)</em>.</p><p>Son idée est simple : une tâche donnée à un LLM est décomposée en sous-tâches que le LLM peut résoudre soit en parallèle, soit séquentiellement. Ces sous-tâches forment un graphe d'exécution. L'exécution du graphe complet résout la tâche de haut niveau.</p><p>Dans la vidéo ci-dessus, Fangru Lin explique la méthode à l'aide d'un exemple facilement compréhensible. Notez que même si cela améliore vos résultats, les LLM souffrent toujours d'une dégradation drastique lorsque la complexité des tâches augmente. Cela dit, c'est tout de même un grand pas dans la bonne direction qui apporte des avantages pratiques immédiats.</p><p>Pour nous, il est intéressant de voir comment son travail fait écho à nos applications de prompts chez <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a>. Nous avons déjà implémenté une structure de prompt similaire à un graphe, cependant, la génération dynamique d'un graphe d'exécution comme elle l'a fait est une nouvelle direction que nous explorerons.</p><h3 id=\"discovering-environments-with-xrm\">Découverte d'environnements avec XRM</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., &amp; Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>Cet article présente un algorithme simple pour découvrir des environnements d'entraînement qui peuvent amener un modèle à s'appuyer sur des caractéristiques qui corrèlent avec les étiquettes mais n'induisent pas une classification/pertinence précise. Un exemple célèbre est le jeu de données waterbirds (voir <a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a>), qui contient des photos d'oiseaux sur différents arrière-plans qui doivent être classés comme oiseaux aquatiques ou terrestres. Pendant l'entraînement, le classificateur détecte si l'arrière-plan des images montre de l'eau ou non au lieu de s'appuyer sur les caractéristiques des oiseaux eux-mêmes. Un tel modèle va mal classer les oiseaux aquatiques s'il n'y a pas d'eau en arrière-plan.</p><p>Pour atténuer ce comportement, il faut détecter les échantillons où le modèle s'appuie sur des caractéristiques d'arrière-plan trompeuses. Cet article présente l'algorithme XRM pour faire cela.</p><p>L'algorithme entraîne deux modèles sur deux parties distinctes du jeu de données d'entraînement. Pendant l'entraînement, les étiquettes de certains échantillons sont inversées. Plus précisément, cela se produit si l'autre modèle (qui n'est pas entraîné sur l'échantillon en question) classifie un échantillon différemment. De cette façon, les modèles sont encouragés à s'appuyer sur des corrélations fallacieuses. Ensuite, vous pouvez extraire des échantillons des données d'entraînement où une étiquette prédite par l'un des modèles diffère de la vérité terrain. Par la suite, on peut utiliser cette information pour entraîner des modèles de classification plus robustes, par exemple avec l'<a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">algorithme Group DRO</a>.</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">Réduisez vos coûts d'évaluation LLM d'un facteur 140 !</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., &amp; Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>Oui, vous avez bien entendu. Avec cette astuce, le coût d'évaluation des LLM peut être réduit à une infime fraction.</p><p>L'idée principale est simple : Supprimez tous les échantillons d'évaluation qui testent la même capacité du modèle. Les mathématiques derrière sont moins évidentes mais bien expliquées par <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a> qui a présenté son travail lors de la session poster. Notez que la réduction d'un facteur 140 s'applique au populaire jeu de données MMLU (Massive Multitask Language Understanding). Pour vos propres jeux de données d'évaluation, cela dépend du degré de corrélation entre les résultats d'évaluation des échantillons. Vous pourrez peut-être ignorer de nombreux échantillons ou seulement quelques-uns.</p><p>Essayez simplement. Nous vous tiendrons informés de la réduction d'échantillons d'évaluation que nous aurons pu réaliser chez <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a>.</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">Contraster des représentations multiples avec le Multi-Marginal Matching Gap</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., &amp; Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Diagramme de document de recherche illustrant les concepts du Multi-Marginal Matching Gap, avec des titres, des descriptions et des organigrammes en bleu\" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Ce travail aborde un défi courant dans l'apprentissage contrastif : La plupart des fonctions de perte contrastive comme la perte InfoNCE opèrent sur des paires de points de données et mesurent la distance entre les paires positives. Pour étendre aux tuples positifs de taille k > 2, l'apprentissage contrastif essaie généralement de réduire le problème à plusieurs paires et d'accumuler les pertes par paires pour toutes les paires positives. Les auteurs proposent ici la perte M3G (Multi-Marginal Matching Gap), une version modifiée de l'algorithme de Sinkhorn, qui résout le problème du Transport Optimal Multi-Marginal. Cette fonction de perte peut être utilisée dans des scénarios où les jeux de données consistent en tuples positifs de taille k > 2, par exemple, >2 images du même objet, des problèmes multi-modaux avec trois modalités ou plus, ou une extension SimCLR avec trois augmentations ou plus de la même image. Les résultats empiriques montrent que cette méthode surpasse la réduction naïve du problème aux paires.</p><h3 id=\"no-need-for-ground-truth\">Pas besoin de vérité terrain !</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p><a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a> de <a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">Stanford University</a> a présenté son travail sur l'évaluation des LLM sans données étiquetées. Notez que même s'il s'agit d'un travail théorique, il a beaucoup de potentiel pour la surveillance à grande échelle des systèmes d'IA avancés. Ce n'est pas pour les utilisateurs occasionnels de LLM, mais si vous travaillez sur l'évaluation des LLM, c'est définitivement quelque chose à explorer. Nous voyons déjà que nous pourrions évaluer nos agents chez Jina AI de cette manière. Nous partagerons les résultats une fois que nous aurons effectué les premières expériences.</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">L'effondrement du modèle est-il inévitable ? Briser la malédiction de la récursion en accumulant des données réelles et synthétiques</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration de deux processus de données d'apprentissage automatique : &quot;Remplacer les données&quot; et &quot;Accumuler les données&quot;, avec des organigrammes détaillés et un modèle\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Plusieurs articles (comme cet article de <a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em></a>) ont récemment prédit que les performances des nouveaux modèles entraînés pourraient se dégrader avec le temps car les données d'entraînement issues du web contiennent une quantité croissante de données synthétiques.</p><p>Notre collègue Scott Martens a également publié <a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">un article sur l'effondrement des modèles</a> et a discuté des cas où les données synthétiques peuvent être utiles pour l'entraînement des modèles.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>Les entraînements des modèles pourraient s'effondrer car les données d'entraînement sont produites par une version antérieure du modèle ou un modèle entraîné sur les mêmes données. Cette étude présente des expériences qui montrent une image légèrement différente : un effondrement ne se produit que lors du <em>remplacement</em> des données réelles par des données synthétiques, ce qui était le cas dans les expériences précédentes. Cependant, lors de l'<em>augmentation</em> des données réelles avec des données synthétiques supplémentaires, aucun changement dans les performances des modèles résultants n'a été mesuré. Ces résultats suggèrent qu'un effondrement des modèles ne se produira pas. Toutefois, cela prouve à nouveau que l'utilisation de données synthétiques supplémentaires n'aidera pas à entraîner un modèle généralement supérieur au modèle utilisé pour créer ces points de données synthétiques.</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">La Chirurgie Cérébrale pour l'IA est Maintenant Possible</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., &amp; Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>Disons que vous voulez prédire la profession de quelqu'un mais pas son genre. Ce travail de Google Research, ETH Zürich, International Institute of Information Technology Hyderabad (IIITH), et Bar-Ilan University montre comment les vecteurs de direction et l'appariement de covariance peuvent être utilisés pour contrôler les biais.</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - Recherche d'Images Auto-Supervisée avec Instructions Ouvertes</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., &amp; Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Cet article présente les modèles MagicLens, une série de modèles de recherche d'images auto-supervisés entraînés sur des triplets image de requête + instruction + image cible.</p><p>Les auteurs présentent un pipeline de collecte/curation de données qui recueille des paires d'images du web et utilise des LLMs pour synthétiser des instructions textuelles ouvertes qui relient les images avec diverses relations sémantiques au-delà de la simple similarité visuelle. Ce pipeline est utilisé pour produire 36,7M de triplets de haute qualité sur une large distribution. Le jeu de données est ensuite utilisé pour entraîner une architecture simple à double encodeur avec des paramètres partagés. Les encodeurs de vision et de langage sont initialisés avec soit CoCa soit des variantes CLIP base et large. Un pooler d'attention multi-têtes unique est introduit pour compresser les deux entrées multimodales en un seul embedding. L'objectif d'entraînement compare la paire image-requête et instruction avec l'image cible et l'instruction vide avec une simple perte InfoNCE pour entraîner MagicLens. Les auteurs présentent des résultats d'évaluation sur la recherche d'images basée sur les instructions.</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - La Nouvelle Façon de Prompting</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., &amp; Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>La façon dont nous interrogeons les LLMs évolue. Le Prompt Sketching nous permet de donner des contraintes fixes aux modèles génératifs. Au lieu de simplement fournir une instruction en espérant que le modèle fera ce que vous voulez, vous définissez un modèle complet, forçant le modèle à générer ce que vous souhaitez.</p><p>Ne confondez pas cela avec les LLMs fine-tunés pour fournir un format JSON structuré. Avec l'approche du fine-tuning, le modèle a toujours la liberté de générer ce qu'il veut. Ce n'est pas le cas avec le Prompt Sketching. Il fournit une boîte à outils complètement nouvelle pour les ingénieurs prompt et ouvre des domaines de recherche qui doivent être explorés. Dans la vidéo ci-dessus, Mark Müller explique en détail ce qu'est ce nouveau paradigme.</p><p>Vous pouvez également consulter <a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">leur projet open-source LMQL</a>.</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - Récupération Sélective pour la Complétion de Code au Niveau du Dépôt</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., &amp; Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>Pour de nombreuses requêtes, le RAG n'aide pas vraiment le modèle car la requête est soit trop simple, soit le système de récupération ne peut pas trouver de documents pertinents, possiblement parce qu'il n'y en a pas. Cela conduit à des temps de génération plus longs et des performances plus faibles si le modèle s'appuie sur des sources trompeuses ou absentes.</p><p>Cet article aborde le problème en permettant aux LLMs d'auto-évaluer si la récupération est utile. Ils démontrent cette approche sur un modèle de complétion de code qui est entraîné à remplir un vide dans un modèle de code. Pour un modèle donné, le système décide d'abord si les résultats de la récupération sont utiles et, si oui, fait appel au récupérateur. Enfin, le LLM de code génère le contexte manquant que les résultats de la récupération soient ajoutés ou non à son prompt.</p><h3 id=\"the-platonic-representation-hypothesis\">L'Hypothèse de la Représentation Platonicienne</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., &amp; Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration de &quot;L'Hypothèse de la Représentation Platonicienne&quot; avec des formes géométriques, du texte mathématique et des diagrammes expliquant une\" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p>L'<em>Hypothèse de la Représentation Platonicienne</em> soutient que les réseaux de neurones artificiels auront tendance à converger vers une représentation commune du monde. S'inspirant de la <a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">Théorie des Formes de Platon</a>, l'idée qu'il existe un royaume d'\"idéaux\", qui nous apparaît sous une forme déformée que nous ne pouvons observer qu'indirectement, les auteurs affirment que nos modèles d'IA semblent converger vers une représentation unique de la réalité, indépendamment de l'architecture d'entraînement, des données d'entraînement, ou même de la modalité d'entrée. Plus l'échelle des données et la taille du modèle sont importantes, plus leurs représentations semblent devenir similaires.</p><p>Les auteurs considèrent les représentations vectorielles et mesurent l'alignement des représentations en utilisant des métriques d'alignement de noyaux, en particulier une métrique des plus proches voisins mutuels qui mesure l'intersection moyenne des ensembles de <em>k</em>-plus proches voisins induits par deux noyaux, <em>K1</em> et <em>K2</em>, normalisée par <em>k</em>. Ce travail présente des preuves empiriques montrant qu'à mesure que la taille des modèles et des jeux de données augmente et que les performances s'améliorent, les noyaux deviennent plus alignés. Cet alignement peut également être observé même lors de la comparaison de modèles de différentes modalités, comme les modèles de texte et les modèles d'images.</p><h2 id=\"summary\">Résumé</h2><p>Une partie de l'enthousiasme initial suscité par la loi d'échelle commence à s'estomper, mais ICML 2024 a démontré que tant de nouveaux talents, divers et créatifs, sont entrés dans notre domaine que nous pouvons être sûrs que le progrès est loin d'être terminé.</p><p>Nous avons passé un excellent moment à ICML 2024 et vous pouvez être sûrs que nous serons de retour en 2025 🇨🇦.</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "Nous avons passé des moments incroyables à l'ICML 2024 à Vienne, et nous souhaitons partager avec vous tout ce que nous avons dit, vu et appris.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}