{
  "slug": "implementing-a-chat-history-rag-with-jina-ai-and-milvus-lite",
  "id": "665d76034b4b4c0001ba1bb3",
  "uuid": "851bc948-281c-4fab-bc11-941c900b086b",
  "title": "Implémentation d'un système RAG avec historique de conversation utilisant Jina AI et Milvus Lite",
  "html": "<p>Les développeurs et les ingénieurs opérationnels accordent une grande importance à une infrastructure facile à configurer, rapide à démarrer et, par la suite, efficace à déployer dans un environnement de production à grande échelle sans complications supplémentaires. Pour cette raison, <a href=\"https://milvus.io/docs/milvus_lite.md?ref=jina-ai-gmbh.ghost.io\"><u>Milvus Lite</u></a>, la dernière base de données vectorielle légère de notre partenaire <a href=\"https://milvus.io/?ref=jina-ai-gmbh.ghost.io\"><u>Milvus</u></a>, est un outil important pour les développeurs Python qui souhaitent développer rapidement des applications de recherche, en particulier lorsqu'il est utilisé avec des modèles de recherche fondamentaux de haute qualité et faciles à utiliser.</p><p>Dans cet article, nous décrirons comment Milvus Lite intègre <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><u>Jina Embeddings v2</u></a> et <a href=\"https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io\"><u>Jina Reranker v1</u></a> en utilisant l'exemple d'une application de <a href=\"https://jina.ai/news/albus-by-springworks-empowering-employees-with-enterprise-search?ref=jina-ai-gmbh.ghost.io\"><u>Retrieval Augmented Generation (RAG)</u></a> construite sur les discussions des canaux publics internes d'une entreprise fictive pour permettre aux employés d'obtenir des réponses précises et utiles à leurs questions liées à l'organisation.</p><h2 id=\"overview-of-milvus-lite-jina-embeddings-and-jina-reranker\">Aperçu de Milvus Lite, Jina Embeddings et Jina Reranker</h2><p>Milvus Lite est une nouvelle version légère de la base de données vectorielle leader Milvus, qui est maintenant également proposée comme bibliothèque Python. Milvus Lite partage la même API que Milvus déployé sur Docker ou Kubernetes mais peut être facilement installé via une simple commande pip, sans configuration de serveur.</p><p>Avec l'intégration de Jina Embeddings v2 et Jina Reranker v1 dans <a href=\"https://github.com/milvus-io/pymilvus?ref=jina-ai-gmbh.ghost.io\"><u>pymilvus</u></a>, le SDK Python de Milvus, vous avez maintenant la possibilité d'intégrer directement des documents en utilisant le même client Python pour n'importe quel mode de déploiement de Milvus, y compris Milvus Lite. Vous pouvez trouver les détails de l'intégration de Jina Embeddings et Reranker sur les <a href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><u>pages de documentation</u></a> de pymilvus.</p><p>Avec sa fenêtre de contexte de 8k tokens et ses capacités multilingues, Jina Embeddings v2 encode la sémantique large du texte et assure une récupération précise. En ajoutant Jina Reranker v1 au pipeline, vous pouvez affiner davantage vos résultats en effectuant un encodage croisé des résultats récupérés directement avec la requête pour une compréhension contextuelle plus approfondie.</p><h2 id=\"milvus-and-jina-ai-models-in-action\">Milvus et les Modèles Jina AI en Action</h2><p>Ce tutoriel se concentrera sur un cas d'utilisation pratique : l'interrogation de l'historique des conversations Slack d'une entreprise pour répondre à un large éventail de questions basées sur les conversations passées.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/E-R-slack--2-.jpg\" class=\"kg-image\" alt=\"Flowchart detailing the Rust community's model training process, featuring steps from the &quot;Next training step?&quot; query through\" loading=\"lazy\" width=\"1600\" height=\"900\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/E-R-slack--2-.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/E-R-slack--2-.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/E-R-slack--2-.jpg 1600w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Flux de processus pour interroger les données Slack en utilisant un exemple de requête</span></figcaption></figure><p>Par exemple, un employé pourrait poser des questions sur la prochaine étape d'un processus de formation en IA, comme dans le schéma de processus ci-dessus. En utilisant Jina Embeddings, Jina Reranker et Milvus, nous pouvons identifier avec précision les informations pertinentes dans les messages Slack enregistrés. Cette application peut améliorer votre productivité au travail en facilitant l'accès aux informations précieuses des communications passées.</p><p>Pour générer les réponses, nous utiliserons <a href=\"https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io\"><u>Mixtral 7B Instruct</u></a> via <a href=\"https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_endpoint/?ref=jina-ai-gmbh.ghost.io\"><u>l'intégration HuggingFace dans Langchain</u></a>. Pour utiliser le modèle, vous avez besoin d'un token d'accès HuggingFace que vous pouvez générer comme décrit <a href=\"https://huggingface.co/docs/hub/en/security-tokens?ref=jina-ai-gmbh.ghost.io\"><u>ici</u></a>.</p><p>Vous pouvez suivre dans <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/milvus/milvus_lite_jina_integration.ipynb?ref=jina-ai-gmbh.ghost.io\"><u>Colab</u></a> ou en <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/milvus/milvus_lite_jina_integration.ipynb?ref=jina-ai-gmbh.ghost.io\"><u>téléchargeant le notebook</u></a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/milvus/milvus_lite_jina_integration.ipynb?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://ssl.gstatic.com/colaboratory-static/common/0d8af74d4089ab8b6d127bd74854be98/img/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" alt=\"\"></div></a></figure><h3 id=\"about-the-dataset\">À propos du Dataset</h3><p>Le dataset utilisé dans ce tutoriel a été généré en utilisant GPT-4 et est destiné à reproduire l'historique des conversations des canaux Slack de Blueprint AI. Blueprint est une startup fictive d'IA développant ses propres modèles fondamentaux. Vous pouvez télécharger le dataset <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/milvus/chat_history.json?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><u>ici</u></a>.</p><p>Les données sont organisées en <em>canaux</em>, chacun représentant une collection de fils de discussion Slack connexes. Chaque canal a une étiquette thématique, parmi dix options : <em>model distribution</em>, <em>model training</em>, <em>model fine-tuning</em>, <em>ethics and bias mitigation</em>, <em>user feedback</em>, <em>sales</em>, <em>marketing</em>, <em>model onboarding</em>, <em>creative design</em>, et <em>product management</em>. Un participant est désigné comme \"expert user\". Vous pouvez utiliser ce champ pour valider les résultats de la recherche de l'utilisateur le plus expert dans un domaine, ce que nous vous montrerons ci-dessous.</p><p>Chaque canal contient également un historique de chat avec des fils de conversation allant jusqu'à 100 messages par canal. Chaque message dans le dataset contient les informations suivantes :</p><ul><li>L'<strong>utilisateur</strong> qui a envoyé le message</li><li>Le <strong>texte du message</strong> envoyé par l'utilisateur</li><li>L'<strong>horodatage</strong> du message</li><li>Le <strong>nom du fichier</strong> que l'utilisateur a pu joindre au message</li><li>L'<strong>ID du message</strong></li><li>L'<strong>ID du message parent</strong> si le message faisait partie d'un fil issu d'un autre message</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/image-1.png\" class=\"kg-image\" alt=\"Diagram showing the structure of a messaging system, detailing the relationship between 'Channel' and 'Message' entities, wit\" loading=\"lazy\" width=\"780\" height=\"450\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/image-1.png 780w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Un diagramme UML de la structure des données de chat.</span></figcaption></figure><h3 id=\"set-up-the-environment\">Configuration de l'Environnement</h3><p>Pour commencer, installez tous les composants nécessaires :</p><pre><code class=\"language-Python\">pip install -U pymilvus\npip install -U \"pymilvus[model]\"\npip install langchain\npip install langchain-community\n</code></pre><p>Téléchargez le dataset :</p><pre><code class=\"language-Python\">import os\n\nif not os.path.exists(\"chat_history.json\"):\n    !wget https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/milvus/chat_history.json</code></pre><p>Définissez votre clé API Jina AI dans une variable d'environnement. Vous pouvez en générer une <a href=\"https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io\"><u>ici</u></a>.</p><pre><code class=\"language-Python\">import os\nimport getpass\n\nos.environ[\"JINAAI_API_KEY\"] = getpass.getpass(prompt=\"Jina AI API Key: \")</code></pre><p>Faites de même pour votre Token Hugging Face. Vous pouvez trouver comment en générer un <a href=\"https://huggingface.co/docs/hub/en/security-tokens?ref=jina-ai-gmbh.ghost.io\"><u>ici</u></a>. Assurez-vous qu'il est défini sur <code>READ</code> pour accéder au <a href=\"https://huggingface.co/docs/hub/en/index?ref=jina-ai-gmbh.ghost.io\"><u>Hugging Face Hub</u></a>.</p><pre><code class=\"language-Python\">os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(prompt=\"Hugging Face Token: \")</code></pre><h3 id=\"create-the-milvus-collection\">Création de la Collection Milvus</h3><p>Créez la Collection Milvus pour indexer les données :</p><pre><code class=\"language-Python\">from pymilvus import MilvusClient, DataType\n\n# Specify a local file name as uri parameter of MilvusClient to use Milvus Lite\nclient = MilvusClient(\"milvus_jina.db\")\n\nschema = MilvusClient.create_schema(\n    auto_id=True,\n    enable_dynamic_field=True,\n)\n\nschema.add_field(field_name=\"id\", datatype=DataType.INT64, description=\"The Primary Key\", is_primary=True)\nschema.add_field(field_name=\"embedding\", datatype=DataType.FLOAT_VECTOR, description=\"The Embedding Vector\", dim=768)\n\nindex_params = client.prepare_index_params()\nindex_params.add_index(field_name=\"embedding\", metric_type=\"COSINE\", index_type=\"AUTOINDEX\")\n\nclient.create_collection(collection_name=\"milvus_jina\", schema=schema, index_params=index_params)</code></pre><h3 id=\"prepare-the-data\">Préparer les données</h3><p>Analyser l'historique des conversations et extraire les métadonnées :</p><pre><code class=\"language-Python\">import json\n\nwith open(\"chat_history.json\", \"r\", encoding=\"utf-8\") as file:\n    chat_data = json.load(file)\n\nmessages = []\nmetadatas = []\n\nfor channel in chat_data:\n  chat_history = channel[\"chat_history\"]\n  chat_topic = channel[\"topic\"]\n  chat_expert = channel[\"expert_user\"]\n  for message in chat_history:\n    text = f\"\"\"{message[\"user\"]}: {message[\"message\"]}\"\"\"\n    messages.append(text)\n    meta = {\n        \"time_stamp\": message[\"time_stamp\"],\n        \"file_name\": message[\"file_name\"],\n        \"parent_message_nr\": message[\"parent_message_nr\"],\n        \"channel\": chat_topic,\n        \"expert\": True if message[\"user\"] == chat_expert else False\n    }\n    metadatas.append(meta)\n</code></pre><h3 id=\"embed-the-chat-data\">Intégrer les données de chat</h3><p>Créer des embeddings pour chaque message en utilisant Jina Embeddings v2 pour récupérer les informations pertinentes des conversations :</p><pre><code class=\"language-Python\">from pymilvus.model.dense import JinaEmbeddingFunction\n\njina_ef = JinaEmbeddingFunction(\"jina-embeddings-v2-base-en\")\n\nembeddings = jina_ef.encode_documents(messages)</code></pre><h3 id=\"index-the-chat-data\">Indexer les données de chat</h3><p>Indexer les messages, leurs embeddings et les métadonnées associées :</p><pre><code class=\"language-Python\">collection_data = [{\n    \"message\": message,\n    \"embedding\": embedding,\n    \"metadata\": metadata\n} for message, embedding, metadata in zip(messages, embeddings, metadatas)]\n\ndata = client.insert(\n    collection_name=\"milvus_jina\",\n    data=collection_data\n)</code></pre><h3 id=\"query-the-chat-history\">Interroger l'historique des conversations</h3><p>Il est temps de poser une question :</p><pre><code class=\"language-Python\">query = \"Who knows the most about encryption protocols in my team?\"</code></pre><p>Maintenant, intégrer la requête et récupérer les messages pertinents. Ici, nous récupérons les cinq messages les plus pertinents et les reclassons en utilisant Jina Reranker v1 :</p><pre><code class=\"language-Python\">from pymilvus.model.reranker import JinaRerankFunction\n\nquery_vectors = jina_ef.encode_queries([query])\n\nresults = client.search(\n    collection_name=\"milvus_jina\",\n    data=query_vectors,\n    limit=5,\n)\n\nresults = results[0]\n\nids = [results[i][\"id\"] for i in range(len(results))]\n\nresults = client.get(\n    collection_name=\"milvus_jina\",\n    ids=ids,\n    output_fields=[\"id\", \"message\", \"metadata\"]\n)\n\njina_rf = JinaRerankFunction(\"jina-reranker-v1-base-en\")\n\ndocuments = [results[i][\"message\"] for i in range(len(results))]\nreranked_documents = jina_rf(query, documents)\n\nreranked_messages = []\nfor reranked_document in reranked_documents:\n  idx = reranked_document.index\n  reranked_messages.append(results[idx])</code></pre><p>Enfin, générer une réponse à la requête en utilisant Mixtral 7B Instruct et les messages reclassés comme contexte :</p><pre><code class=\"language-Python\">from langchain.prompts import PromptTemplate\nfrom langchain_community.llms import HuggingFaceEndpoint\n\nllm = HuggingFaceEndpoint(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n\nprompt = \"\"\"&lt;s&gt;[INST] Context information is below.\\\\n\n        It includes the five most relevant messages to the query, sorted based on their relevance to the query.\\\\n\n        ---------------------\\\\n\n        {context_str}\\\\\\\\n\n        ---------------------\\\\n\n        Given the context information and not prior knowledge,\n        answer the query. Please be brief, concise, and complete.\\\\n\n        If the context information does not contain an answer to the query,\n        respond with \\\\\"No information\\\\\".\\\\n\n        Query: {query_str}[/INST] &lt;/s&gt;\"\"\"\n\nprompt = PromptTemplate(template=prompt, input_variables=[\"query_str\", \"context_str\"])\n\nllm_chain = prompt | llm\n\nanswer = llm_chain.invoke({\"query_str\":query, \"context_str\":reranked_messages})\n\nprint(f\"\\n\\nANSWER:\\n\\n{answer}\")</code></pre><p>La réponse à notre question est :</p><blockquote>« D'après les informations contextuelles, User5 semble être le plus compétent en matière de protocoles de chiffrement dans votre équipe. Ils ont mentionné que les nouveaux protocoles améliorent significativement la sécurité des données, en particulier pour les déploiements cloud. »</blockquote><p>Si vous lisez les messages dans <code>chat_history.json</code>, vous pouvez vérifier par vous-même si User5 est l'utilisateur le plus expert.</p><h2 id=\"summary\">Résumé</h2><p>Nous avons vu comment configurer Milvus Lite, intégrer des données de chat en utilisant Jina Embeddings v2 et affiner les résultats de recherche avec Jina Reranker v1, le tout dans un cas d'utilisation pratique de recherche dans un historique de chat Slack. Milvus Lite simplifie le développement d'applications Python sans nécessiter de configurations serveur complexes. Son intégration avec Jina Embeddings et Reranker vise à augmenter la productivité en facilitant l'accès aux informations précieuses de votre lieu de travail.</p><h2 id=\"use-jina-ai-models-and-milvus-now\"><strong>Utilisez les modèles Jina AI et Milvus maintenant</strong></h2><p><a href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><u>Milvus Lite</u></a> avec l'intégration de <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\"><u>Jina Embeddings</u></a> et <a href=\"https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io\"><u>Reranker</u></a> vous fournit un pipeline de traitement complet, prêt à l'emploi avec seulement quelques lignes de code.</p><p>Nous aimerions beaucoup entendre parler de vos cas d'utilisation et discuter de la façon dont l'extension Jina AI Milvus peut répondre à vos besoins professionnels. Contactez-nous via <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io\"><u>notre site web</u></a> ou <a href=\"https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>notre canal Discord</u></a> pour partager vos commentaires et rester à jour avec nos derniers modèles. Pour les questions concernant l'intégration de Milvus et Jina AI, rejoignez la <a href=\"https://milvus.io/community?ref=jina-ai-gmbh.ghost.io\"><u>communauté Milvus</u></a>.</p>",
  "comment_id": "665d76034b4b4c0001ba1bb3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/06/Blog-images--39-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-06-03T09:51:31.000+02:00",
  "updated_at": "2024-07-08T21:08:43.000+02:00",
  "published_at": "2024-06-03T16:09:33.000+02:00",
  "custom_excerpt": "Enhance your search applications in Python with Jina Embeddings and Reranker and lightweight, easy-to-deploy Milvus Lite.\n",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "65e85e35b22368000152a4bf",
      "name": "Francesco Kruk",
      "slug": "francesco",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Portrait-Picture_Low.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/francesco/"
    },
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "65e85e35b22368000152a4bf",
    "name": "Francesco Kruk",
    "slug": "francesco",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Portrait-Picture_Low.jpg",
    "cover_image": null,
    "bio": null,
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/francesco/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/implementing-a-chat-history-rag-with-jina-ai-and-milvus-lite/",
  "excerpt": "Améliorez vos applications de recherche en Python avec Jina Embeddings et Reranker et Milvus Lite, léger et facile à déployer.",
  "reading_time": 6,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Black background with vivid geometric shapes on the sides and central logos \"Embeddings,\" \"Reranker,\" and \"Milvus.\"",
  "feature_image_caption": null
}