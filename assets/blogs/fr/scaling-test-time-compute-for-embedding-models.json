{
  "slug": "scaling-test-time-compute-for-embedding-models",
  "id": "675a84f80ce9930001b86f09",
  "uuid": "49f876f3-0d50-4555-8f9e-136473f720ac",
  "title": "Augmenter les ressources de calcul au moment du test pour les mod√®les d'embedding",
  "html": "<p>Depuis la sortie du mod√®le <a href=\"https://openai.com/o1/?ref=jina-ai-gmbh.ghost.io\">O1</a> par OpenAI, l'un des sujets les plus discut√©s dans la communaut√© IA a √©t√© le <strong>scaling test-time compute</strong>. Cela fait r√©f√©rence √† l'allocation de ressources de calcul suppl√©mentaires pendant l'inf√©rence ‚Äî la phase o√π un mod√®le d'IA g√©n√®re des sorties en r√©ponse √† des entr√©es ‚Äî plut√¥t que pendant le pr√©-entra√Ænement. Un exemple bien connu est le raisonnement multi-√©tapes \"chain of thought\", qui permet aux mod√®les d'effectuer des d√©lib√©rations internes plus approfondies, comme l'√©valuation de plusieurs r√©ponses potentielles, une planification plus pouss√©e, une auto-r√©flexion avant d'arriver √† une r√©ponse finale. Cette strat√©gie am√©liore la qualit√© des r√©ponses, particuli√®rement dans les t√¢ches de raisonnement complexe. Le mod√®le <a href=\"https://huggingface.co/Qwen/QwQ-32B-Preview?ref=jina-ai-gmbh.ghost.io\">QwQ-32B-Preview</a> r√©cemment publi√© par Alibaba suit cette tendance d'am√©lioration du raisonnement de l'IA gr√¢ce √† l'augmentation du test-time compute.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Dans ce contexte, \"scaling\" signifie principalement augmenter la capacit√© de calcul (comme la puissance de traitement ou le temps) disponible pendant l'inf√©rence. Il ne fait pas r√©f√©rence au <b><strong style=\"white-space: pre-wrap;\">scaling out</strong></b> (distribution des t√¢ches sur plusieurs syst√®mes) ou √† l'obtention d'une <b><strong style=\"white-space: pre-wrap;\">speedup</strong></b> (r√©duction du temps de traitement).</div></div><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/12/o1_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/12/o1.mp4\" poster=\"https://img.spacergif.org/v1/900x432/0a/spacer.png\" width=\"900\" height=\"432\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/12/o1_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1√ó</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Lors de l'utilisation du mod√®le O1 d'OpenAI, les utilisateurs peuvent clairement remarquer que l'inf√©rence multi-√©tapes n√©cessite du temps suppl√©mentaire pendant que le mod√®le construit des cha√Ænes de raisonnement pour r√©soudre les probl√®mes.</span></p></figcaption>\n        </figure><p>Chez Jina AI, nous nous concentrons davantage sur les embeddings et les rerankers que sur les LLM, donc pour nous, il est naturel d'envisager le scaling test-time compute dans ce contexte : <em>Comment le \"chain-of-thought\" peut-il √™tre appliqu√© aux mod√®les d'embedding ?</em> Bien que cela puisse ne pas sembler intuitif au premier abord, cet article explore une nouvelle perspective et d√©montre comment le scaling test-time compute peut √™tre appliqu√© √† <code>jina-clip</code> pour classifier des images hors distribution (OOD) ‚Äî r√©solvant des t√¢ches qui seraient autrement impossibles.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--14-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/banner--14-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/banner--14-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--14-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Notre exp√©rience s'est concentr√©e sur la reconnaissance des Pokemon, qui pr√©sente un d√©fi int√©ressant pour les mod√®les d'embedding. Alors que les mod√®les de type CLIP excellent dans la correspondance g√©n√©rale image-texte, ils peuvent avoir des difficult√©s avec des domaines sp√©cialis√©s ou des images OOD sans fine-tuning. En donnant aux mod√®les plus de temps pour \"r√©fl√©chir\", nous avons d√©couvert que la classification multi-cibles ‚Äî analogue √† une \"cha√Æne de pens√©e\" ‚Äî pouvait am√©liorer la pr√©cision sans aucun ajustement du mod√®le d'embedding lui-m√™me.</span></figcaption></figure><h2 id=\"case-study\">√âtude de cas</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1zP6FZRm2mN1pf7PsID-EtGDc5gP_hm4Z?ref=jina-ai-gmbh.ghost.io#scrollTo=CJt5zwA9E2jB\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-15.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-4.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Notre exp√©rience s'est concentr√©e sur la classification des Pokemon en utilisant le <a href=\"https://huggingface.co/datasets/TheFusion21/PokemonCards?ref=jina-ai-gmbh.ghost.io\">dataset TheFusion21/PokemonCards</a>, qui contient des milliers d'images de cartes Pokemon. <strong>La t√¢che est la classification d'images</strong> o√π l'entr√©e est une illustration de carte Pokemon recadr√©e (avec tous les textes/descriptions supprim√©s) et la sortie est le nom correct du Pokemon parmi un ensemble pr√©d√©fini de noms. Cette t√¢che pr√©sente un d√©fi particuli√®rement int√©ressant pour les mod√®les d'embedding CLIP car :</p><ul><li>Les noms et les visuels des Pokemon repr√©sentent des concepts de niche, hors distribution pour le mod√®le, rendant la classification directe difficile</li><li>Chaque Pokemon poss√®de des traits visuels clairs qui peuvent √™tre d√©compos√©s en √©l√©ments de base (formes, couleurs, poses) que CLIP pourrait mieux comprendre</li><li>L'illustration de la carte fournit un format visuel coh√©rent tout en introduisant de la complexit√© √† travers des arri√®re-plans, poses et styles artistiques vari√©s</li><li>La t√¢che n√©cessite d'int√©grer simultan√©ment plusieurs caract√©ristiques visuelles, similaire aux cha√Ænes de raisonnement complexes dans les mod√®les de langage</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-5.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"835\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-5.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Nous recadrons les images des cartes Pokemon pour supprimer toutes les informations textuelles (en-t√™te, pied de page, description) afin d'√©viter toute devinette triviale due √† l'apparition des noms de Pokemon dans ces textes. Les √©tiquettes de classe de ces Pokemon sont [</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Absol G</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Aerodactyl</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Weedle</span></code><span style=\"white-space: pre-wrap;\">, </span></figcaption></figure><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Caterpie</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Azumarill</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Bulbasaur</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Venusaur</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Absol</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Aggron</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Beedrill Œ¥</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Alakazam</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Ampharos</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Dratini</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Ampharos</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Ampharos</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Arcanine</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Blaine's Moltres</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Aerodactyl</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Celebi & Venusaur-GX</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Caterpie</span></code><span style=\"white-space: pre-wrap;\">]</span></figcaption></figure><h3 id=\"baseline\">Base de r√©f√©rence</h3><p>L'approche de base utilise une simple comparaison directe entre l'illustration des cartes Pok√©mon et les noms. Tout d'abord, nous recadrons chaque image de carte Pok√©mon pour supprimer toutes les informations textuelles (en-t√™te, pied de page, description) afin d'√©viter toute devinette triviale du mod√®le CLIP due √† l'apparition des noms de Pok√©mon dans ces textes. Ensuite, nous encodons √† la fois les images recadr√©es et les noms des Pok√©mon √† l'aide des mod√®les <code>jina-clip-v1</code> et <code>jina-clip-v2</code> pour obtenir leurs embeddings respectifs. La classification est effectu√©e en calculant la similarit√© cosinus entre ces embeddings d'images et de textes - chaque image est associ√©e au nom qui a le score de similarit√© le plus √©lev√©. Cela cr√©e une correspondance directe un-√†-un entre l'illustration de la carte et les noms de Pok√©mon, sans aucune information contextuelle ou d'attribut suppl√©mentaire. Le pseudo-code ci-dessous r√©sume la m√©thode de base.</p><pre><code class=\"language-python\"># Preprocessing\ncropped_images = [crop_artwork(img) for img in pokemon_cards]  # Remove text, keep only art\npokemon_names = [\"Absol\", \"Aerodactyl\", ...]  # Raw Pokemon names\n\n# Get embeddings using jina-clip-v1\nimage_embeddings = model.encode_image(cropped_images)\ntext_embeddings = model.encode_text(pokemon_names)\n\n# Classification by cosine similarity\nsimilarities = cosine_similarity(image_embeddings, text_embeddings)\npredicted_names = [pokemon_names[argmax(sim)] for sim in similarities]\n\n# Evaluate\naccuracy = mean(predicted_names == ground_truth_names)</code></pre><h3 id=\"chain-of-thoughts-for-classification\">\"Cha√Æne de Pens√©es\" pour la Classification</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--10-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/banner--10-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/banner--10-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--10-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Au lieu de faire correspondre directement les images aux noms, nous d√©composons la reconnaissance des Pok√©mon en un syst√®me structur√© d'attributs visuels. Nous d√©finissons cinq groupes d'attributs cl√©s : la couleur dominante (par exemple, \"blanc\", \"bleu\"), la forme primaire (par exemple, \"un loup\", \"un reptile ail√©\"), le trait caract√©ristique (par exemple, \"une seule corne blanche\", \"grandes ailes\"), la forme du corps (par exemple, \"semblable √† un loup sur quatre pattes\", \"ail√© et √©lanc√©\"), et la sc√®ne d'arri√®re-plan (par exemple, \"l'espace\", \"for√™t verte\").</p><p>Pour chaque groupe d'attributs, nous cr√©ons des prompts textuels sp√©cifiques (par exemple, \"Ce Pok√©mon a un corps principalement de couleur {}\") associ√©s √† des options pertinentes. Nous utilisons ensuite le mod√®le pour calculer les scores de similarit√© entre l'image et chaque option d'attribut. Ces scores sont convertis en probabilit√©s √† l'aide de softmax pour obtenir une mesure plus calibr√©e de la confiance.</p><p>La structure compl√®te de la Cha√Æne de Pens√©es (CoT) se compose de deux parties : <code>classification_groups</code> qui d√©crit les groupes de prompts, et <code>pokemon_rules</code> qui d√©finit quelles options d'attributs chaque Pok√©mon devrait correspondre. Par exemple, Absol devrait correspondre √† \"blanc\" pour la couleur et \"semblable √† un loup\" pour la forme. La CoT compl√®te est montr√©e ci-dessous (nous expliquerons comment elle est construite plus tard) :</p><pre><code class=\"language-python\">pokemon_system = {\n    \"classification_cot\": {\n        \"dominant_color\": {\n            \"prompt\": \"This Pok√©mon's body is mainly {} in color.\",\n            \"options\": [\n                \"white\",    # Absol, Absol G\n                \"gray\",     # Aggron\n                \"brown\",    # Aerodactyl, Weedle, Beedrill Œ¥\n                \"blue\",     # Azumarill\n                \"green\",    # Bulbasaur, Venusaur, Celebi&Venu, Caterpie\n                \"yellow\",   # Alakazam, Ampharos\n                \"red\",      # Blaine's Moltres\n                \"orange\",   # Arcanine\n                \"light blue\"# Dratini\n            ]\n        },\n        \"primary_form\": {\n            \"prompt\": \"It looks like {}.\",\n            \"options\": [\n                \"a wolf\",         # Absol, Absol G\n                \"an armored dinosaur\",  # Aggron\n                \"a winged reptile\",     # Aerodactyl\n                \"a rabbit-like creature\", # Azumarill\n                \"a toad-like creature\",   # Bulbasaur, Venusaur, Celebi&Venu\n                \"a caterpillar larva\",    # Weedle, Caterpie\n                \"a wasp-like insect\",     # Beedrill Œ¥\n                \"a fox-like humanoid\",     # Alakazam\n                \"a sheep-like biped\",      # Ampharos\n                \"a dog-like beast\",        # Arcanine\n                \"a flaming bird\",          # Blaine's Moltres\n                \"a serpentine dragon\"      # Dratini\n            ]\n        },\n        \"key_trait\": {\n            \"prompt\": \"Its most notable feature is {}.\",\n            \"options\": [\n                \"a single white horn\", # Absol, Absol G\n                \"metal armor plates\",  # Aggron\n                \"large wings\",         # Aerodactyl, Beedrill Œ¥\n                \"rabbit ears\",         # Azumarill\n                \"a green plant bulb\",  # Bulbasaur, Venusaur, Celebi&Venu\n                \"a small red spike\",   # Weedle\n                \"big green eyes\",      # Caterpie\n                \"a mustache and spoons\", # Alakazam\n                \"a glowing tail orb\",  # Ampharos\n                \"a fiery mane\",        # Arcanine\n                \"flaming wings\",       # Blaine's Moltres\n                \"a tiny white horn on head\" # Dratini\n            ]\n        },\n        \"body_shape\": {\n            \"prompt\": \"The body shape can be described as {}.\",\n            \"options\": [\n                \"wolf-like on four legs\",   # Absol, Absol G\n                \"bulky and armored\",        # Aggron\n                \"winged and slender\",       # Aerodactyl, Beedrill Œ¥\n                \"round and plump\",          # Azumarill\n                \"sturdy and four-legged\",   # Bulbasaur, Venusaur, Celebi&Venu\n                \"long and worm-like\",       # Weedle, Caterpie\n                \"upright and humanoid\",     # Alakazam, Ampharos\n                \"furry and canine\",         # Arcanine\n                \"bird-like with flames\",    # Blaine's Moltres\n                \"serpentine\"                # Dratini\n            ]\n        },\n        \"background_scene\": {\n            \"prompt\": \"The background looks like {}.\",\n            \"options\": [\n                \"outer space\",      # Absol G, Beedrill Œ¥\n                \"green forest\",     # Azumarill, Bulbasaur, Venusaur, Weedle, Caterpie, Celebi&Venu\n                \"a rocky battlefield\", # Absol, Aggron, Aerodactyl\n                \"a purple psychic room\", # Alakazam\n                \"a sunny field\",     # Ampharos\n                \"volcanic ground\",   # Arcanine\n                \"a red sky with embers\", # Blaine's Moltres\n                \"a calm blue lake\"   # Dratini\n            ]\n        }\n    },\n    \n    \"pokemon_rules\": {\n        \"Absol\": {\n            \"dominant_color\": 0,      \n            \"primary_form\": 0,   \n            \"key_trait\": 0,      \n            \"body_shape\": 0,    \n            \"background_scene\": 2   \n        },\n        \"Absol G\": {\n            \"dominant_color\": 0,      \n            \"primary_form\": 0,   \n            \"key_trait\": 0,       \n            \"body_shape\": 0,     \n            \"background_scene\": 0    \n        },\n        // ...\n    }\n}\n</code></pre><p>La classification finale combine ces probabilit√©s d'attributs - au lieu d'une seule comparaison de similarit√©, nous faisons maintenant plusieurs comparaisons structur√©es et agr√©geons leurs probabilit√©s pour prendre une d√©cision plus √©clair√©e.</p><pre><code class=\"language-python\"># Classification process\ndef classify_pokemon(image):\n   # Generate all text prompts\n   all_prompts = []\n   for group in classification_cot:\n       for option in group[\"options\"]:\n           prompt = group[\"prompt\"].format(option)\n           all_prompts.append(prompt)\n\n   # Get embeddings and similarities\n   image_embedding = model.encode_image(image)\n   text_embeddings = model.encode_text(all_prompts)\n   similarities = cosine_similarity(image_embedding, text_embeddings)\n\n   # Convert to probabilities per attribute group\n   probabilities = {}\n   for group_name, group_sims in group_similarities:\n       probabilities[group_name] = softmax(group_sims)\n\n   # Score each Pokemon based on matching attributes\n   scores = {}\n   for pokemon, rules in pokemon_rules.items():\n       score = 0\n       for group, target_idx in rules.items():\n           score += probabilities[group][target_idx]\n       scores[pokemon] = score\n\n   return max(scores, key=scores.get)</code></pre><h3 id=\"complexity-analysis\">Analyse de la complexit√©</h3><p>Supposons que nous voulions classer une image parmi <code>N</code> noms de Pok√©mon. L'approche de base n√©cessite de calculer <code>N</code> embeddings de texte (un pour chaque nom de Pok√©mon). En revanche, notre approche de calcul √† l'√©chelle du temps de test n√©cessite de calculer <code>Q</code> embeddings de texte, o√π</p><code>Q</code> repr√©sente le nombre total de combinaisons question-option pour toutes les questions. Les deux m√©thodes n√©cessitent le calcul d'un embedding d'image et une √©tape finale de classification, donc nous excluons ces op√©rations communes de notre comparaison. Dans cette √©tude de cas, notre <code>N=13</code> et <code>Q=52</code>.</p><p>Dans un cas extr√™me o√π <code>Q = N</code>, notre approche se r√©duirait essentiellement √† la baseline. Cependant, la cl√© pour faire √©voluer efficacement le calcul au moment du test est de : </p><ul><li>Construire des questions soigneusement choisies qui augmentent <code>Q</code> </li><li>S'assurer que chaque question fournit des indices distincts et informatifs sur la r√©ponse finale </li><li>Concevoir des questions aussi orthogonales que possible pour maximiser leur gain d'information conjoint.</li></ul><p>Cette approche est analogue au jeu des \"Vingt Questions\", o√π chaque question est strat√©giquement choisie pour r√©duire efficacement les r√©ponses possibles.</p><h3 id=\"evaluation\">√âvaluation</h3><p>Notre √©valuation a √©t√© men√©e sur 117 images de test couvrant 13 classes diff√©rentes de Pok√©mon. Et le r√©sultat est le suivant :</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>jina-clip-v1</th>\n<th>jina-clip-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Baseline</td>\n<td>31.36%</td>\n<td>16.10%</td>\n</tr>\n<tr>\n<td>CoT</td>\n<td>46.61%</td>\n<td>38.14%</td>\n</tr>\n<tr>\n<td>Improvement</td>\n<td>+15.25%</td>\n<td>+22.04%</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>On peut voir que la m√™me classification CoT offre des am√©liorations significatives pour les deux mod√®les (+15,25 % et +22,04 % respectivement) sur cette t√¢che inhabituelle ou OOD. Cela sugg√®re √©galement qu'une fois que le <code>pokemon_system</code> est construit, <strong>le m√™me syst√®me CoT peut √™tre efficacement transf√©r√© entre diff√©rents mod√®les ; et aucun fine-tuning ou post-training n'est n√©cessaire.</strong></p><p>La performance relativement forte de la baseline de v1 (31,36 %) sur la classification Pok√©mon est remarquable. Ce mod√®le a √©t√© entra√Æn√© sur <a href=\"https://www.youtube.com/watch?v=HsGyxVUN1SA&ref=jina-ai-gmbh.ghost.io\">LAION-400M, qui incluait du contenu li√© aux Pok√©mon</a>. En revanche, v2 a √©t√© entra√Æn√© sur DFN-2B (sous-√©chantillonnage de 400M instances), un jeu de donn√©es de meilleure qualit√© mais plus filtr√© qui a peut-√™tre exclu le contenu li√© aux Pok√©mon, expliquant la performance de baseline plus faible de V2 (16,10 %) sur cette t√¢che sp√©cifique. </p><h3 id=\"constructing-pokemonsystem-effectively\">Construire <code>pokemon_system</code> efficacement</h3><p>L'efficacit√© de notre approche de calcul au moment du test d√©pend fortement de la qualit√© de construction du <code>pokemon_system</code>. Il existe diff√©rentes approches pour construire ce syst√®me, de manuelle √† enti√®rement automatis√©e.</p><h4 id=\"manual-construction\">Construction manuelle</h4><p>L'approche la plus directe consiste √† analyser manuellement le jeu de donn√©es Pok√©mon et √† cr√©er des groupes d'attributs, des prompts et des r√®gles. Un expert du domaine devrait identifier les attributs visuels cl√©s tels que la couleur, la forme et les caract√©ristiques distinctives. Il √©crirait ensuite des prompts en langage naturel pour chaque attribut, √©num√©rerait les options possibles pour chaque groupe d'attributs et associerait chaque Pok√©mon √† ses options d'attributs correctes. Bien que cela fournisse des r√®gles de haute qualit√©, c'est chronophage et ne s'adapte pas bien √† un <code>N</code> plus grand.</p><h4 id=\"llm-assisted-construction\">Construction assist√©e par LLM</h4><p>Nous pouvons utiliser les LLM pour acc√©l√©rer ce processus en les incitant √† g√©n√©rer le syst√®me de classification. Un prompt bien structur√© demanderait des groupes d'attributs bas√©s sur des caract√©ristiques visuelles, des mod√®les de prompts en langage naturel, des options compl√®tes et mutuellement exclusives, et des r√®gles de mapping pour chaque Pok√©mon. Le LLM peut rapidement g√©n√©rer une premi√®re version, bien que sa sortie puisse n√©cessiter une v√©rification.</p><pre><code class=\"language-txt\">I need help creating a structured system for Pokemon classification. For each Pokemon in this list: [Absol, Aerodactyl, Weedle, Caterpie, Azumarill, ...], create a classification system with:\n\n1. Classification groups that cover these visual attributes:\n   - Dominant color of the Pokemon\n   - What type of creature it appears to be (primary form)\n   - Its most distinctive visual feature\n   - Overall body shape\n   - What kind of background/environment it's typically shown in\n\n2. For each group:\n   - Create a natural language prompt template using \"{}\" for the option\n   - List all possible options that could apply to these Pokemon\n   - Make sure options are mutually exclusive and comprehensive\n\n3. Create rules that map each Pokemon to exactly one option per attribute group, using indices to reference the options\n\nPlease output this as a Python dictionary with two main components:\n- \"classification_groups\": containing prompts and options for each attribute\n- \"pokemon_rules\": mapping each Pokemon to its correct attribute indices\n\nExample format:\n{\n    \"classification_groups\": {\n        \"dominant_color\": {\n            \"prompt\": \"This Pokemon's body is mainly {} in color\",\n            \"options\": [\"white\", \"gray\", ...]\n        },\n        ...\n    },\n    \"pokemon_rules\": {\n        \"Absol\": {\n            \"dominant_color\": 0,  # index for \"white\"\n            ...\n        },\n        ...\n    }\n}</code></pre><p>Une approche plus robuste combine la g√©n√©ration par LLM avec la validation humaine. D'abord, le LLM g√©n√®re un syst√®me initial. Ensuite, les experts humains examinent et corrigent les groupements d'attributs, l'exhaustivit√© des options et l'exactitude des r√®gles. Le LLM affine le syst√®me en fonction de ce feedback, et le processus se r√©p√®te jusqu'√† l'obtention d'une qualit√© satisfaisante. Cette approche √©quilibre efficacit√© et pr√©cision.</p><h4 id=\"automated-construction-with-dspy\">Construction automatis√©e avec DSPy</h4><p>Pour une approche enti√®rement automatis√©e, nous pouvons utiliser DSPy pour optimiser it√©rativement <code>pokemon_system</code>. Le processus commence avec un <code>pokemon_system</code> simple √©crit soit manuellement soit par LLMs comme prompt initial. Chaque version est √©valu√©e sur un ensemble de validation, utilisant la pr√©cision comme signal de feedback pour DSPy. Sur la base de cette performance, des prompts optimis√©s (c'est-√†-dire de nouvelles versions de <code>pokemon_system</code>) sont g√©n√©r√©s. Ce cycle se r√©p√®te jusqu'√† convergence, et pendant tout le processus, le mod√®le d'embedding reste compl√®tement fixe.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--13-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/banner--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/banner--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--13-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Utilisation de DSPy pour trouver la meilleure conception CoT de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>pokemon_system</span></code><span style=\"white-space: pre-wrap;\"> ; le processus d'optimisation ne doit √™tre effectu√© qu'une seule fois pour chaque t√¢che.</span></figcaption></figure><h2 id=\"why-scale-test-time-compute-for-embedding-models\">Pourquoi faire √©voluer le calcul au moment du test pour les mod√®les d'embedding ?</h2><p>Parce que l'augmentation du pr√©-entra√Ænement devient finalement √©conomiquement impossible. </p><p>Depuis la sortie de la suite d'embeddings Jina ‚Äî incluant <code>jina-embeddings-v1</code>, <code>v2</code>, <code>v3</code>, <code>jina-clip-v1</code>, <code>v2</code>, et <code>jina-ColBERT-v1</code>, <code>v2</code> ‚Äî chaque mise √† niveau de mod√®le par le biais d'un pr√©-entra√Ænement √† grande √©chelle s'est accompagn√©e de co√ªts plus √©lev√©s. Par exemple, notre premier mod√®le, <code>jina-embeddings-v1</code>, sorti en juin 2023 avec 110M param√®tres. Son entra√Ænement √† l'√©poque co√ªtait entre 5 000 et 10 000 $ selon la fa√ßon de mesurer. Avec <code>jina-embeddings-v3</code>, les am√©liorations sont significatives, mais elles proviennent principalement des ressources accrues investies. La trajectoire des co√ªts pour les mod√®les de pointe est pass√©e de milliers √† des dizaines de milliers de dollars et, pour les plus grandes entreprises d'IA, m√™me des centaines de millions aujourd'hui. Bien que l'investissement de plus d'argent, de ressources et de donn√©es dans le pr√©-entra√Ænement produise de meilleurs mod√®les, les rendements marginaux rendent finalement toute mise √† l'√©chelle suppl√©mentaire √©conomiquement insoutenable.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/plot--1-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"2003\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/plot--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/plot--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/plot--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/plot--1-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Loi d'√©chelle des mod√®les d'embedding. La performance moyenne MTEB sur les t√¢ches en anglais est trac√©e en fonction du nombre de param√®tres du mod√®le. Chaque point repr√©sente un mod√®le d'embedding. La ligne de tendance, repr√©sentant tous les mod√®les, est mise en √©vidence, avec les mod√®les multilingues en points cyan. Ce graphique a √©t√© cr√©√© en s√©lectionnant les 100 meilleurs mod√®les d'embedding du classement MTEB, en excluant ceux sans information de taille, typiquement les mod√®les propri√©taires ou √† code source ferm√©. Les soumissions identifi√©es comme du trolling √©vident ont √©galement √©t√© filtr√©es. </span></figcaption></figure><p>D'autre part, les mod√®les d'embedding modernes deviennent de plus en plus puissants : multilingues, multit√¢ches, multimodaux et capables de performances zero-shot et de suivi d'instructions solides. Cette versatilit√© laisse une grande marge pour les am√©liorations algorithmiques et l'augmentation du calcul au moment du test.</p><p>La question devient alors : quel est le co√ªt que les utilisateurs sont pr√™ts √† payer pour une requ√™te qui leur tient particuli√®rement √† c≈ìur ? Si tol√©rer des temps d'inf√©rence plus longs pour des mod√®les pr√©-entra√Æn√©s fixes am√©liore significativement la qualit√© des r√©sultats, beaucoup trouveraient cela valable. √Ä notre avis, il existe un potentiel substantiel inexploit√© dans l'augmentation du calcul au moment du test pour les mod√®les d'embedding. Cela repr√©sente un changement, passant de la simple augmentation de la taille du mod√®le pendant l'entra√Ænement √† l'am√©lioration de l'effort de calcul pendant la phase d'inf√©rence pour obtenir de meilleures performances.</p><h2 id=\"conclusion\">Conclusion</h2><p>Notre √©tude de cas sur le calcul au moment du test de <code>jina-clip-v1/v2</code> montre plusieurs conclusions cl√©s :</p><ol><li>Nous avons obtenu de meilleures performances sur des donn√©es inhabituelles ou hors distribution (OOD) sans aucun fine-tuning ou post-training sur les embeddings.</li><li>Le syst√®me a fait des distinctions plus nuanc√©es en affinant it√©rativement les recherches de similarit√© et les crit√®res de classification.</li><li>En incorporant des ajustements dynamiques de prompts et un raisonnement it√©ratif, nous avons transform√© le processus d'inf√©rence du mod√®le d'embedding d'une simple requ√™te en une cha√Æne de pens√©e plus sophistiqu√©e.</li></ol><p>Cette √©tude de cas ne fait qu'effleurer la surface de ce qui est possible avec le calcul au moment du test. Il reste une marge substantielle pour l'√©volution algorithmique. Par exemple, nous pourrions d√©velopper des m√©thodes pour s√©lectionner it√©rativement les questions qui r√©duisent le plus efficacement l'espace des r√©ponses, similaire √† la strat√©gie optimale dans le jeu des \"Vingt Questions\". En faisant √©voluer le calcul au moment du test, nous pouvons pousser les mod√®les d'embedding au-del√† de leurs limitations actuelles et leur permettre d'aborder des t√¢ches plus complexes et nuanc√©es qui semblaient autrefois hors de port√©e.</p>",
  "comment_id": "675a84f80ce9930001b86f09",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/12/test-time-compute.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-12-12T07:38:48.000+01:00",
  "updated_at": "2024-12-12T17:54:17.000+01:00",
  "published_at": "2024-12-12T17:54:17.000+01:00",
  "custom_excerpt": "Better results scale with compute‚Äîmore on learning, more on search. A good pretrained model takes you far, but test-time compute takes you further. It's important to recognize this new paradigm of scaling test-time compute, even for embedding models.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/scaling-test-time-compute-for-embedding-models/",
  "excerpt": "Les meilleurs r√©sultats augmentent avec la puissance de calcul‚Äîplus d'apprentissage, plus de recherche. Un bon mod√®le pr√©-entra√Æn√© vous m√®ne loin, mais le calcul lors de l'inf√©rence vous m√®ne encore plus loin. Il est important de reconna√Ætre ce nouveau paradigme d'augmentation de la puissance de calcul lors de l'inf√©rence, m√™me pour les mod√®les d'embedding.",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}