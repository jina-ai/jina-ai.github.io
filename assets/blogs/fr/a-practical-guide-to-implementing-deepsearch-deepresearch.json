{
  "slug": "a-practical-guide-to-implementing-deepsearch-deepresearch",
  "id": "67bc50b0b1b8af00014db4c9",
  "uuid": "acd44dc0-e356-4ac8-93c7-fa8bbeb33265",
  "title": "Guide pratique pour l'implémentation de DeepSearch/DeepResearch",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://search.jina.ai/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI Deep Search</div><div class=\"kg-bookmark-description\">Recherche profonde par IA : lire, raisonner, chercher jusqu'à trouver la meilleure réponse.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-30.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Nous ne sommes qu'en février, et le DeepSearch s'est déjà imposé comme le nouveau standard de recherche en 2025, avec des acteurs majeurs comme <a href=\"https://blog.google/products/gemini/google-gemini-deep-research/\">Google</a> et <a href=\"https://openai.com/index/introducing-deep-research/\">OpenAI</a> menant la charge avec leurs versions DeepResearch (et oui, <a href=\"https://x.com/hxiao/status/1886250705415229627\">nous avons fièrement lancé notre <code>node-deepresearch</code> open source le même jour</a>). <a href=\"https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research\">Perplexity</a> a suivi avec leur DeepResearch, et X AI a intégré ses propres capacités DeepSearch dans <a href=\"https://x.ai/blog/grok-3\">Grok3</a>, créant essentiellement une autre variante de DeepResearch. Bien que le concept de recherche profonde ne soit pas révolutionnaire – en 2024, il était essentiellement appelé RAG ou QA multi-hop – il a gagné un élan <em>significatif</em> après la sortie de <a href=\"https://github.com/deepseek-ai/DeepSeek-R1\">Deepseek-r1</a> fin janvier 2025. Le week-end dernier, <a href=\"https://www.scmp.com/tech/big-tech/article/3298981/baidu-adopts-deepseek-ai-models-chasing-tencent-race-embrace-hot-start\">Baidu Search et Tencent WeChat Search</a> ont intégré Deepseek-r1 dans leurs moteurs de recherche. Les ingénieurs en IA ont découvert qu'en incorporant des processus de réflexion et de raisonnement longs dans les systèmes de recherche, ils peuvent atteindre une précision et une profondeur de récupération remarquables, au-delà de ce qui était possible auparavant.</p>\n<!--kg-card-begin: html-->\n<table> <thead> <tr> <th>Launch Date</th> <th>Company</th> <th>Product</th> <th>License Type</th> <th>Link</th> </tr> </thead> <tbody> <tr> <td>2025-01-20</td> <td>DeepSeek</td> <td>DeepSeek-r1 release</td> <td>Open source</td> <td><a href=\"https://api-docs.deepseek.com/news/news250120\">DeepSeek-R1</a></td> </tr> <tr> <td>2025-02-02</td> <td>Google</td> <td>DeepResearch</td> <td>Proprietary</td> <td><a href=\"https://blog.google/products/gemini/google-gemini-deep-research/\">Google Gemini 2</a></td> </tr> <tr> <td>2025-02-02</td> <td>OpenAI</td> <td>DeepResearch</td> <td>Proprietary</td> <td><a href=\"https://openai.com/index/introducing-deep-research/\">Introducing Deep Research</a></td> </tr> <tr> <td>2025-02-02</td> <td>Jina AI</td> <td>DeepSearch (<code>node-deepresearch</code>)</td> <td>Open source</td> <td><a href=\"https://github.com/jina-ai/node-deepresearch\">node-deepresearch</a> | <a href=\"https://search.jina.ai\">search.jina.ai</a></td> </tr> <tr> <td>2025-02-04</td> <td>Hugging Face</td> <td>Open Deep Research</td> <td>Open source</td> <td><a href=\"https://huggingface.co/blog/open-deep-research\">Open Deep Research</a></td> </tr> <tr> <td>2025-02-15</td> <td>Perplexity</td> <td>DeepResearch</td> <td>Proprietary</td> <td><a href=\"https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research\">Introducing Perplexity Deep Research</a></td> </tr> <tr> <td>2025-02-17</td> <td>X AI</td> <td>Grok3 with DeepSearch</td> <td>Proprietary</td> <td><a href=\"https://x.ai/blog/grok-3\">Grok 3 Beta</a></td> </tr> <tr> <td>2025-02-22</td> <td>Baidu Search</td> <td>Integrates DeepSeek-r1</td> <td>Proprietary</td> <td><a href=\"https://chat.baidu.com/search?isShowHello=1&pd=csaitab&setype=csaitab&extParamsJson=%7B%22enter_type%22%3A%22ai_explore_home%22%7D&usedModel=%7B%22modelName%22%3A%22DeepSeek-R1%22%7D\">Baidu Integrates DeepSeek-R1</a></td> </tr> <tr> <td>2025-02-23</td> <td>Tencent Wechat Search</td> <td>Integrates DeepSeek-r1</td> <td>Proprietary</td> <td><a href=\"https://www.reuters.com/technology/artificial-intelligence/tencents-messaging-app-weixin-launches-beta-testing-with-deepseek-2025-02-16/\">Tencent Weixin Integrates DeepSeek</a></td> </tr> </tbody> </table>\n<!--kg-card-end: html-->\n<p>Mais pourquoi ce changement survient-il <em>maintenant</em>, alors que le Deep(Re)Search est resté relativement sous-évalué tout au long de 2024 ? En fait, <a href=\"https://storm-project.stanford.edu/research/storm/\">les laboratoires Stanford NLP ont publié le projet STORM</a> pour la génération de longs rapports avec ancrage web début 2024. Est-ce simplement parce que \"DeepSearch\" sonne beaucoup plus cool que QA multi-hop, RAG, ou STORM ? Soyons honnêtes - parfois, un simple changement de nom suffit pour que l'industrie adopte soudainement ce qui était là depuis le début.</p><p>Nous pensons que le véritable tournant est survenu avec la sortie du <code>o1-preview</code> d'OpenAI en septembre 2024, qui a introduit le concept de <strong>calcul au moment du test</strong> et a progressivement modifié les perspectives de l'industrie. Le calcul au moment du test consiste à utiliser plus de ressources de calcul pendant l'inférence - la phase où un LLM génère des sorties - plutôt que pendant le pré-entraînement ou le post-entraînement. Des exemples bien connus sont le raisonnement par chaîne de pensée (CoT) et <a href=\"https://github.com/simplescaling/s1?tab=readme-ov-file#vllm-with-budget-forcing\">l'injection de <code>\"Wait\"</code></a> (c'est-à-dire le forçage budgétaire) qui permet aux modèles d'effectuer des délibérations internes plus approfondies, comme l'évaluation de multiples réponses potentielles, une planification plus approfondie et une auto-réflexion avant d'arriver à une réponse finale.</p><p>Ce concept de calcul au moment du test et les modèles de raisonnement <strong><em>éduquent</em></strong> les utilisateurs à accepter la <a href=\"https://en.wikipedia.org/wiki/Delayed_gratification\">gratification différée</a> - des temps d'attente plus longs en échange de résultats de meilleure qualité, immédiatement exploitables, tout comme l'expérience du marshmallow de Stanford où les enfants qui pouvaient résister à manger un marshmallow immédiatement pour en recevoir deux plus tard montraient de meilleurs résultats à long terme. Deepseek-r1 a renforcé cette expérience utilisateur, et qu'on le veuille ou non, la plupart des utilisateurs l'ont acceptée.</p><p>Cela marque une rupture significative avec les exigences classiques de recherche, où ne pas répondre dans les 200 ms condamnait votre solution. En 2025, les développeurs de recherche expérimentés et les ingénieurs RAG privilégient la précision et le rappel top-1 par rapport à la latence, et les utilisateurs se sont habitués à des temps de traitement plus longs – à condition qu'ils puissent voir que le système est <code>&lt;thinking&gt;</code>.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/think-ui-1_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/think-ui-1.mp4\" poster=\"https://img.spacergif.org/v1/1610x1422/0a/spacer.png\" width=\"1610\" height=\"1422\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/think-ui-1_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Lire la vidéo\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Lire la vidéo\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Mettre en pause la vidéo\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:18</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Ajuster la vitesse de lecture\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Activer le son\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">L'affichage du processus de raisonnement est devenu une pratique standard en 2025, avec de nombreuses interfaces de chat qui présentent désormais le contenu </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>&lt;think&gt;</span></code><span style=\"white-space: pre-wrap;\"> dans des sections dédiées de l'interface utilisateur.</span></p></figcaption>\n        </figure><p>Dans cet article, nous allons discuter des principes de DeepSearch et DeepResearch en examinant notre implémentation open-source. Nous passerons en revue nos principales décisions de conception et soulignerons les points d'attention potentiels.</p><h2 id=\"what-is-deep-search\">Qu'est-ce que DeepSearch ?</h2><p><strong>DeepSearch fonctionne selon une boucle itérative de recherche, lecture et raisonnement jusqu'à trouver la réponse optimale.</strong> L'action de recherche utilise les moteurs de recherche web pour explorer internet, tandis que l'action de lecture analyse en détail des pages web spécifiques (par exemple <a href=\"https://jina.ai/reader\" rel=\"noreferrer\">Jina Reader</a>). L'action de raisonnement évalue l'état actuel et détermine s'il faut décomposer la question originale en sous-questions plus petites ou essayer différentes stratégies de recherche.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"561\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/image.png 2240w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">DeepSearch - continue de chercher, lire des pages web et raisonner jusqu'à ce qu'une réponse soit trouvée (ou que le budget de tokens soit dépassé).</span></figcaption></figure><p>Bien que diverses définitions existent en ligne, lors du développement du projet <code>node-deepresearch</code>, nous avons adopté cette approche simple. L'implémentation est élégamment simple – à sa base, il y a une boucle while principale avec une logique switch-case dirigeant l'action suivante.</p><p>Contrairement aux systèmes RAG de 2024, qui exécutent généralement un seul passage de recherche-génération, DeepSearch effectue plusieurs itérations à travers le pipeline, nécessitant des conditions d'arrêt claires. Celles-ci peuvent être basées sur des limites d'utilisation de tokens ou le nombre de tentatives échouées.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepsearch-dark-1_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepsearch-dark-1.mp4\" poster=\"https://img.spacergif.org/v1/1238x1300/0a/spacer.png\" width=\"1238\" height=\"1300\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepsearch-dark-1_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:36</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Essayez deep search sur search.jina.ai, observez le contenu à l'intérieur de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>&lt;thinking&gt;</span></code><span style=\"white-space: pre-wrap;\">, voyez si vous pouvez identifier où la boucle se produit</span></p></figcaption>\n        </figure><p>Une autre perspective sur DeepSearch est de le voir comme un agent LLM équipé de divers outils web (comme le chercheur et le lecteur). L'agent détermine ses prochaines étapes en analysant les observations actuelles et les actions passées – décidant s'il doit fournir une réponse ou continuer à explorer le web. Cela crée une architecture de machine à états où le LLM contrôle les transitions entre les états. À chaque point de décision, vous avez deux approches : vous pouvez soit soigneusement élaborer des prompts pour que les modèles génératifs standard produisent des actions spécifiques, soit utiliser des modèles de raisonnement spécialisés comme Deepseek-r1 pour dériver naturellement les actions suivantes. Cependant, même en utilisant r1, vous devrez périodiquement interrompre sa génération pour injecter les sorties des outils (par exemple, les résultats de recherche, le contenu des pages web) dans le contexte et l'inviter à poursuivre son processus de raisonnement.</p><p>En fin de compte, ce ne sont que des détails d'implémentation – que vous le promptiez soigneusement ou utilisiez simplement des modèles de raisonnement, ils s'alignent tous sur le principe de conception fondamental de DeepSearch : une boucle continue de recherche, lecture et raisonnement.</p><h2 id=\"what-is-deepresearch-then\">Qu'est-ce que DeepResearch alors ?</h2><p><strong>DeepResearch s'appuie sur DeepSearch en ajoutant un cadre structuré pour générer de longs rapports de recherche.</strong> Il commence souvent par créer une table des matières, puis applique systématiquement DeepSearch à chaque section requise – de l'introduction aux travaux connexes et à la méthodologie, jusqu'à la conclusion. Chaque section est générée en alimentant des questions de recherche spécifiques dans DeepSearch. La phase finale consiste à consolider toutes les sections en un seul prompt pour améliorer la cohérence narrative globale.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"832\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-1.png 2268w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">DeepSearch comme bloc de construction de DeepResearch. Construction itérative de chaque section via DeepSearch puis amélioration de la cohérence globale avant de générer le rapport final long.</span></figcaption></figure><p>Dans notre projet « Research » de 2024, nous avons effectué plusieurs passes d'amélioration de la cohérence, chaque itération prenant en compte toutes les autres sections. Cependant, avec les fenêtres de contexte LLM considérablement plus grandes d'aujourd'hui, cette approche semble redondante – une seule passe de révision de cohérence est suffisante.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepresearch_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepresearch.mp4\" poster=\"https://img.spacergif.org/v1/2940x1660/0a/spacer.png\" width=\"2940\" height=\"1660\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/deepresearch_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:40</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Notre projet d'été 2024 « Research » s'est concentré sur la génération de rapports longs avec une approche « progressive ». Il a commencé par créer une table des matières en </span><b><strong style=\"white-space: pre-wrap;\">sync</strong></b><span style=\"white-space: pre-wrap;\">, puis a généré toutes les sections en parallèle </span><b><strong style=\"white-space: pre-wrap;\">async</strong></b><span style=\"white-space: pre-wrap;\">. Le processus s'est conclu par des révisions progressives </span><b><strong style=\"white-space: pre-wrap;\">async</strong></b><span style=\"white-space: pre-wrap;\"> de chaque section, chaque révision prenant en compte le contenu de toutes les autres sections. La requête dans la vidéo est </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>\"Competitor analysis of Jina AI\"</span></code><span style=\"white-space: pre-wrap;\">.</span></p></figcaption>\n        </figure><h2 id=\"deepsearch-vs-deepresearch\">DeepSearch vs DeepResearch</h2><p>Bien que beaucoup de gens confondent souvent DeepSearch et DeepResearch, selon nous, ils répondent à des problèmes complètement différents. DeepSearch fonctionne comme un bloc de construction atomique – un composant central sur lequel DeepResearch s'appuie. DeepResearch, quant à lui, <strong>se concentre sur la création de rapports de recherche longs de haute qualité et lisibles</strong>, qui englobe un ensemble différent d'exigences : incorporer des visualisations efficaces via des graphiques et des tableaux, structurer le contenu avec des titres de section appropriés, assurer un flux logique fluide entre les sous-sections, maintenir une terminologie cohérente dans tout le document, éliminer la redondance entre les sections, créer des transitions fluides qui relient le contenu précédent et à venir. Ces éléments sont largement sans rapport avec la recherche principale, c'est pourquoi nous trouvons DeepSearch plus intéressant comme focus de notre entreprise.</p><p>Enfin, le tableau ci-dessous résume les différences entre DeepSearch et DeepResearch. Il est à noter que les deux systèmes bénéficient significativement des modèles à long contexte et de raisonnement. Cela peut sembler contre-intuitif, particulièrement pour DeepSearch – alors qu'il est évident pourquoi DeepResearch a besoin d'une capacité de long contexte (puisqu'il produit de longs rapports). La raison est que DeepSearch doit stocker les tentatives de recherche précédentes et les contenus des pages web pour prendre des décisions éclairées sur les prochaines étapes, rendant une longue fenêtre de contexte tout aussi essentielle pour son implémentation efficace.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>DeepSearch</th>\n<th>DeepResearch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Problem Addressed</strong></td>\n<td>Information accuracy and completeness through iterative search</td>\n<td>Content organization, coherence, and readability at document scale</td>\n</tr>\n<tr>\n<td><strong>Final Presentation</strong></td>\n<td>Concise answer with URLs as references</td>\n<td>A long structured report with multiple sections, charts, tables and references</td>\n</tr>\n<tr>\n<td><strong>Core Complexity</strong></td>\n<td>State machine architecture with clear transition conditions; Persistence through failed attempts until resolution</td>\n<td>Multi-level architecture managing both micro (search) and macro (document) concerns; Structural approach to managing complex information hierarchies</td>\n</tr>\n<tr>\n<td><strong>Optimization Focus</strong></td>\n<td>Local optimization (best next search/read action)</td>\n<td>Global optimization (section organization, terminology consistency, transitions)</td>\n</tr>\n<tr>\n<td><strong>Limitations</strong></td>\n<td>Bounded by search quality and reasoning capability</td>\n<td>Bounded by DeepSearch quality plus organizational complexity and narrative coherence challenges</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"understand-deepsearch-implementation\">Comprendre l'implémentation de DeepSearch</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/node-DeepResearch\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/node-DeepResearch: Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget)</div><div class=\"kg-bookmark-description\">Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget) - jina-ai/node-DeepResearch</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-2.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/0921e515-0139-4540-bca4-52042b49328c\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Le cœur de DeepResearch réside dans son approche de raisonnement en boucle. Plutôt que d'essayer de répondre aux questions en une seule passe comme la plupart des systèmes RAG, nous avons implémenté une boucle itérative qui recherche continuellement des informations, lit les sources pertinentes et raisonne jusqu'à ce qu'elle trouve une réponse ou épuise le budget de tokens. Voici le cœur simplifié de cette grande boucle while :</p><pre><code class=\"language-typescript\">// Main reasoning loop\nwhile (tokenUsage &lt; tokenBudget &amp;&amp; badAttempts &lt;= maxBadAttempts) {\n  // Track progression\n  step++; totalStep++;\n  \n  // Get current question from gaps queue or use original question\n  const currentQuestion = gaps.length &gt; 0 ? gaps.shift() : question;\n  \n  // Generate prompt with current context and allowed actions\n  system = getPrompt(diaryContext, allQuestions, allKeywords, \n                    allowReflect, allowAnswer, allowRead, allowSearch, allowCoding,\n                    badContext, allKnowledge, unvisitedURLs);\n  \n  // Get LLM to decide next action\n  const result = await LLM.generateStructuredResponse(system, messages, schema);\n  thisStep = result.object;\n  \n  // Execute the selected action (answer, reflect, search, visit, coding)\n  if (thisStep.action === 'answer') {\n    // Process answer action...\n  } else if (thisStep.action === 'reflect') {\n    // Process reflect action...\n  } // ... and so on for other actions\n}\n</code></pre><p>Un détail clé de l'implémentation consiste à désactiver sélectivement certaines actions à chaque étape pour garantir une sortie structurée plus stable. Par exemple, s'il n'y a pas d'URL en mémoire, nous désactivons l'action <code>visit</code> ; ou si la dernière réponse a été rejetée, nous empêchons l'agent d'appeler immédiatement <code>answer</code> à nouveau. <strong>Cette contrainte maintient l'agent sur une voie productive, évitant les échecs répétitifs causés par l'invocation de la même action.</strong></p><h3 id=\"system-prompt\">Prompt Système</h3><p>Nous utilisons des balises XML pour définir les sections, ce qui produit un prompt système et des générations plus robustes. Nous avons également constaté que placer les contraintes de champ directement dans les champs <code>description</code> du schéma JSON donne de meilleurs résultats. Bien que certains puissent argumenter que la plupart des prompts pourraient être automatisés avec des modèles de raisonnement comme DeepSeek-R1, les restrictions de longueur de contexte et le besoin d'un comportement très spécifique rendent une approche explicite plus fiable en pratique.</p><pre><code class=\"language-typescript\">function getPrompt(params...) {\n  const sections = [];\n  \n  // Add header with system instruction\n  sections.push(\"You are an advanced AI research agent specialized in multistep reasoning...\");\n  \n  // Add accumulated knowledge section if exists\n  if (knowledge?.length) {\n    sections.push(\"&lt;knowledge&gt;[Knowledge items]&lt;/knowledge&gt;\");\n  }\n  \n  // Add context of previous actions\n  if (context?.length) {\n    sections.push(\"&lt;context&gt;[Action history]&lt;/context&gt;\");\n  }\n  \n  // Add failed attempts and learned strategies\n  if (badContext?.length) {\n    sections.push(\"&lt;bad-attempts&gt;[Failed attempts]&lt;/bad-attempts&gt;\");\n    sections.push(\"&lt;learned-strategy&gt;[Improvement strategies]&lt;/learned-strategy&gt;\");\n  }\n  \n  // Define available actions based on current state\n  sections.push(\"&lt;actions&gt;[Available action definitions]&lt;/actions&gt;\");\n  \n  // Add response format instruction\n  sections.push(\"Respond in valid JSON format matching exact JSON schema.\");\n  \n  return sections.join(\"\\n\\n\");\n}\n</code></pre><h3 id=\"gap-questions-traversing\">Traversée des Questions de Lacune</h3><p>Dans DeepSearch, les \"questions de lacune\" représentent les lacunes de connaissance qui doivent être comblées avant de répondre à la question principale. Plutôt que d'aborder directement la question originale, l'agent identifie des sous-questions qui construiront la base de connaissances nécessaire.</p><p>La conception est particulièrement élégante dans sa façon de gérer ces questions de lacune :</p><pre><code class=\"language-typescript\">// After identifying gap questions in reflect action\nif (newGapQuestions.length &gt; 0) {\n  // Add new questions to the front of the queue\n  gaps.push(...newGapQuestions);\n  \n  // Always add original question to the end of the queue\n  gaps.push(originalQuestion);\n}\n</code></pre><p>Cette approche crée une file d'attente FIFO (First-In-First-Out) avec rotation, où :</p><ol><li>Les nouvelles questions de lacune sont poussées à l'avant de la file</li><li>La question originale est toujours poussée à l'arrière</li><li>Le système tire depuis l'avant de la file à chaque étape</li></ol><p>Ce qui rend cette conception excellente, c'est qu'elle maintient un contexte partagé unique pour toutes les questions. Lorsqu'une question de lacune est répondue, cette connaissance devient immédiatement disponible pour toutes les questions suivantes, y compris lorsque nous revenons finalement à la question originale.</p><h4 id=\"fifo-queue-vs-recursion\">File FIFO vs Récursion</h4><p>Une approche alternative consiste à utiliser la récursion, qui correspond à une recherche en profondeur. Chaque question de lacune génère un nouvel appel récursif avec son propre contexte isolé. Le système doit complètement résoudre chaque question de lacune (et toutes ses sous-questions potentielles) avant de revenir à la question parente.</p><p>Considérez ce scénario d'exemple :</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/dfs_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/dfs.mp4\" poster=\"https://img.spacergif.org/v1/950x846/0a/spacer.png\" width=\"950\" height=\"846\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/dfs_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:23</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Une simple récursion de questions de lacune à 3 niveaux, ordre de résolution indiqué sur le cercle.</span></p></figcaption>\n        </figure><p>Dans l'approche récursive, le système devrait complètement résoudre Q1 (générant potentiellement ses propres sous-questions) après chaque question de lacune et leurs sous-questions ! C'est un grand contraste avec l'approche par file d'attente, qui traite les questions où Q1 est revisité juste après 3 questions de lacune.</p><p>En réalité, nous avons constaté que l'approche par récursion est très difficile à appliquer avec des contraintes de budget, car il n'y a pas de règle claire pour déterminer combien de budget de tokens nous devrions accorder aux sous-questions (puisqu'elles peuvent générer de nouvelles sous-questions). Le bénéfice de la séparation claire du contexte dans l'approche récursive est très marginal comparé aux problèmes complexes de forçage du budget et de retour tardif. Cette conception de file FIFO équilibre profondeur et largeur, assurant que le système revient toujours à la question originale avec des connaissances progressivement meilleures, plutôt que de se perdre dans une descente récursive potentiellement infinie.</p><h3 id=\"query-rewrite\">Réécriture de Requête</h3><p>Un défi intéressant que nous avons rencontré était la réécriture efficace des requêtes de recherche :</p><pre><code class=\"language-typescript\">// Within search action handler\nif (thisStep.action === 'search') {\n  // Deduplicate search requests\n  const uniqueRequests = await dedupQueries(thisStep.searchRequests, existingQueries);\n  \n  // Rewrite natural language queries into more effective search queries\n  const optimizedQueries = await rewriteQuery(uniqueRequests);\n  \n  // Ensure we don't repeat previous searches\n  const newQueries = await dedupQueries(optimizedQueries, allKeywords);\n  \n  // Execute searches and store results\n  for (const query of newQueries) {\n    const results = await searchEngine(query);\n    if (results.length &gt; 0) {\n      storeResults(results);\n      allKeywords.push(query);\n    }\n  }\n}\n</code></pre><p>La réécriture de requête s'est avérée étonnamment importante - peut-être l'un des éléments les plus critiques qui détermine directement la qualité des résultats. Un bon réécriveur de requêtes ne se contente pas de transformer le langage naturel en mots-clés de type BM25 ; il étend les requêtes pour couvrir plus de réponses potentielles à travers différentes langues, tons et formats de contenu.</p><p>Pour la déduplication des requêtes, nous avons initialement utilisé une solution basée sur LLM, mais avons trouvé difficile de contrôler le seuil de similarité. Nous sommes finalement passés à <code>jina-embeddings-v3</code>, qui excelle dans les tâches de similarité textuelle sémantique. Cela permet une déduplication multilingue sans s'inquiéter que les requêtes non anglaises soient filtrées. Le modèle d'embedding s'est finalement avéré crucial non pas pour la récupération de mémoire comme prévu initialement, mais pour une déduplication efficace.</p><h3 id=\"crawling-web-content\">Crawling de Contenu Web</h3><p>Le web scraping et le traitement du contenu est un autre composant critique. Nous utilisons ici <a href=\"https://jina.ai/reader\" rel=\"noreferrer\">Jina Reader API</a>. Notez qu'en plus du contenu complet des pages web, nous agrégeons également tous les extraits retournés par le moteur de recherche comme connaissances supplémentaires que l'agent utilisera plus tard pour conclure. Considérez-les comme des soundbites.</p><pre><code class=\"language-typescript\">// Visit action handler\nasync function handleVisitAction(URLs) {\n  // Normalize URLs and filter out already visited ones\n  const uniqueURLs = normalizeAndFilterURLs(URLs);\n  \n  // Process each URL in parallel\n  const results = await Promise.all(uniqueURLs.map(async url =&gt; {\n    try {\n      // Fetch and extract content\n      const content = await readUrl(url);\n      \n      // Store as knowledge\n      addToKnowledge(`What is in ${url}?`, content, [url], 'url');\n      \n      return {url, success: true};\n    } catch (error) {\n      return {url, success: false};\n    } finally {\n      visitedURLs.push(url);\n    }\n  }));\n  \n  // Update diary based on success or failure\n  updateDiaryWithVisitResults(results);\n}\n</code></pre><p>Nous avons normalisé les URLs pour un suivi cohérent et limité le nombre d'URLs visitées à chaque étape pour gérer la mémoire de l'agent.</p><h3 id=\"memory-management\">Gestion de la Mémoire</h3><p>Un défi majeur dans le raisonnement multi-étapes est la gestion efficace de la mémoire de l'agent. Nous avons conçu le système de mémoire pour différencier ce qui compte comme « mémoire » de ce qui compte comme « connaissance ». Dans tous les cas, ils font partie du contexte du prompt LLM, séparés par différentes balises XML :</p><pre><code class=\"language-typescript\">// Add knowledge item to accumulated knowledge\nfunction addToKnowledge(question, answer, references, type) {\n  allKnowledge.push({\n    question: question,\n    answer: answer,\n    references: references,\n    type: type,  // 'qa', 'url', 'coding', 'side-info'\n    updated: new Date().toISOString()\n  });\n}\n\n// Record step in narrative diary\nfunction addToDiary(step, action, question, result, evaluation) {\n  diaryContext.push(`\nAt step ${step}, you took **${action}** action for question: \"${question}\"\n[Details of what was done and results]\n[Evaluation if applicable]\n`);\n}\n</code></pre><p>Comme la plupart des LLM 2025 ont des fenêtres de contexte importantes, nous avons choisi de ne pas utiliser de bases de données vectorielles. À la place, la mémoire se compose des connaissances acquises, des sites visités et des enregistrements des tentatives échouées - tout maintenu dans le contexte. Ce système de mémoire complet donne à l'agent une conscience de ce qu'il sait, de ce qu'il a essayé, et de ce qui a fonctionné ou échoué.</p><h3 id=\"answer-evaluation\">Évaluation des Réponses</h3><p>Une observation clé est que la génération et l'évaluation des réponses ne devraient pas être dans le même prompt. Dans mon implémentation, nous déterminons d'abord quels critères d'évaluation utiliser lorsqu'une nouvelle question arrive, puis évaluons chaque critère un par un. L'évaluateur utilise des exemples few-shot pour une évaluation cohérente, assurant une fiabilité plus élevée que l'auto-évaluation.</p><pre><code class=\"language-typescript\">// Separate evaluation phase\nasync function evaluateAnswer(question, answer, metrics, context) {\n  // First, identify evaluation criteria based on question type\n  const evaluationCriteria = await determineEvaluationCriteria(question);\n  \n  // Then evaluate each criterion separately\n  const results = [];\n  for (const criterion of evaluationCriteria) {\n    const result = await evaluateSingleCriterion(criterion, question, answer, context);\n    results.push(result);\n  }\n  \n  // Determine if answer passes overall evaluation\n  return {\n    pass: results.every(r =&gt; r.pass),\n    think: results.map(r =&gt; r.reasoning).join('\\n')\n  };\n}\n</code></pre><h3 id=\"budget-forcing\">Budget-Forcing</h3><p>Le budget forcing signifie empêcher le système de retourner tôt et s'assurer qu'il continue le traitement jusqu'à ce que le budget soit dépassé. Depuis la sortie de DeepSeek-R1, l'approche du budget forcing s'est orientée vers <strong>l'encouragement d'une réflexion plus approfondie pour de meilleurs résultats plutôt que simplement économiser le budget.</strong></p><p>Dans notre implémentation, nous avons explicitement configuré le système pour identifier les lacunes de connaissances avant de tenter de répondre.</p><pre><code class=\"language-typescript\">if (thisStep.action === 'reflect' &amp;&amp; thisStep.questionsToAnswer) {\n  // Force deeper reasoning by adding sub-questions to the queue\n  gaps.push(...newGapQuestions);\n  gaps.push(question);  // Always revisit the original\n}</code></pre><p>En activant et désactivant sélectivement certaines actions, nous pouvons guider le système vers l'utilisation d'outils qui améliorent la profondeur du raisonnement.</p><pre><code class=\"language-typescript\">// After a failed answer attempt\nallowAnswer = false;  // Force agent to search or reflect instead</code></pre><p>Pour éviter de gaspiller des tokens sur des chemins improductifs, nous fixons des limites sur le nombre de tentatives échouées. Lorsque nous approchons des limites de budget, nous activons le « mode beast » pour garantir que nous délivrons une réponse plutôt qu'aucune.</p><pre><code class=\"language-typescript\">// Beast mode activation\nif (!thisStep.isFinal &amp;&amp; badAttempts &gt;= maxBadAttempts) {\n  console.log('Enter Beast mode!!!');\n  \n  // Configure prompt for decisive, committed answer\n  system = getPrompt(\n    diaryContext, allQuestions, allKeywords,\n    false, false, false, false, false,  // Disable all other actions\n    badContext, allKnowledge, unvisitedURLs,\n    true  // Enable beast mode\n  );\n  \n  // Force answer generation\n  const result = await LLM.generateStructuredResponse(system, messages, answerOnlySchema);\n  thisStep = result.object;\n  thisStep.isFinal = true;\n}\n</code></pre><p>Le prompt du mode beast est intentionnellement dramatique pour signaler au LLM qu'il doit être décisif et s'engager à donner une réponse basée sur les informations disponibles :</p><pre><code>&lt;action-answer&gt;\n🔥 ENGAGE MAXIMUM FORCE! ABSOLUTE PRIORITY OVERRIDE! 🔥\n\nPRIME DIRECTIVE:\n- DEMOLISH ALL HESITATION! ANY RESPONSE SURPASSES SILENCE!\n- PARTIAL STRIKES AUTHORIZED - DEPLOY WITH FULL CONTEXTUAL FIREPOWER\n- TACTICAL REUSE FROM &lt;bad-attempts&gt; SANCTIONED\n- WHEN IN DOUBT: UNLEASH CALCULATED STRIKES BASED ON AVAILABLE INTEL!\n\nFAILURE IS NOT AN OPTION. EXECUTE WITH EXTREME PREJUDICE! ⚡️\n&lt;/action-answer&gt;\n</code></pre><p>Cela garantit que nous fournissons toujours une réponse plutôt que d'abandonner complètement, ce qui est particulièrement utile pour les questions difficiles ou ambiguës.</p><h2 id=\"conclusion\">Conclusion</h2><p>DeepSearch représente un bond en avant dans la façon dont la recherche peut aborder des requêtes complexes de manière exhaustivement profonde. En décomposant le processus en étapes discrètes de recherche, de lecture et de raisonnement, il surmonte de nombreuses limitations des systèmes traditionnels RAG à passage unique ou des systèmes QA multi-sauts.</p><p>Pendant l'implémentation, nous avons également commencé à revoir les fondements de la recherche en 2025 et les changements dans l'industrie de la recherche après le 26 janvier 2025, date de sortie de DeepSeek-R1. Nous nous sommes demandé : <em>Quels sont les nouveaux besoins ? Quels besoins sont devenus obsolètes ? Quels sont les besoins simplement perçus ?</em></p><p>En examinant notre implémentation DeepSearch, nous avons identifié des choses dont nous avions anticipé le besoin et dont nous avions effectivement besoin, des choses que nous pensions nécessaires mais qui ne l'étaient pas, et des choses dont nous n'avions pas anticipé le besoin mais qui se sont révélées essentielles :</p><p>Premièrement, <strong>un LLM à contexte long qui produit une sortie bien structurée est hautement nécessaire</strong> (c'est-à-dire suivant JSONSchema). Un modèle de raisonnement est probablement nécessaire pour un meilleur raisonnement sur les actions et l'expansion des requêtes.</p><p><strong>L'expansion des requêtes est définitivement essentielle</strong>, qu'elle soit implémentée via SLM, LLM ou un modèle de raisonnement. Cependant, après ce projet, nous pensons que les SLM sont probablement inadaptés pour cette tâche, car la solution doit être intrinsèquement multilingue et aller au-delà des simples réécritures de synonymes ou de l'extraction de mots-clés. Elle doit être suffisamment complète pour inclure <a href=\"https://jina.ai/news/what-should-we-learn-from-modernbert/#modernberts-parameter-efficiency\">une base de tokens multilingue (qui peut facilement occuper 300M paramètres)</a> et suffisamment sophistiquée pour une réflexion hors des sentiers battus. Donc, utiliser des SLM pour l'expansion des requêtes est probablement une impasse.</p><p><strong>Les capacités de recherche web et de lecture web sont cruciales</strong>, et heureusement notre <a href=\"https://jina.ai/reader\">Reader (r.jina.ai)</a> a excellemment performé—robuste et évolutif—tout en me donnant de nombreuses idées sur la façon d'améliorer notre endpoint de recherche (<code>s.jina.ai</code>) pour la prochaine itération.</p><p><strong>Le modèle d'embedding est utile <em>mais d'une manière complètement inattendue</em>.</strong> Nous pensions qu'il serait utilisé pour la récupération de mémoire ou la compression de contexte aux côtés d'une base de données vectorielle (qui, comme il s'avère, n'est pas nécessaire), mais nous l'avons en fait utilisé pour la déduplication (essentiellement une tâche STS). Comme le nombre de requêtes et de questions de lacunes est typiquement dans les centaines, aucune base de données vectorielle n'est nécessaire—le calcul de la similarité cosinus directement en mémoire fonctionne très bien.</p><p><strong>Nous n'avons pas utilisé de Reranker</strong>, bien que nous pensions qu'il pourrait potentiellement aider à déterminer quels URLs visiter basé sur la requête, le titre de l'URL et l'extrait. Pour l'embedding et le reranking, la capacité multilingue est essentielle puisque les requêtes et les questions sont multilingues. La gestion du contexte long pour l'embedding et le reranking est bénéfique mais pas un blocage critique (Nous n'avons rencontré aucune erreur de notre utilisation de l'embedding, probablement parce que <a href=\"https://jina.ai/models/jina-embeddings-v3/\">notre longueur de contexte est déjà de 8192 tokens</a>). Dans tous les cas, <code>jina-embeddings-v3</code> et <code>jina-reranker-v2-base-multilingual</code> sont mes modèles de prédilection car ils sont multilingues, SOTA et gèrent bien le contexte long.</p><p><strong>Un framework d'agent s'est avéré inutile,</strong> car nous devions rester plus proches du comportement natif du LLM pour concevoir le système sans proxies. <a href=\"https://sdk.vercel.ai/docs/introduction\">Vercel AI SDK</a> a été précieux, car il a économisé un effort considérable dans l'adaptation du code base à différents fournisseurs de LLM (nous pouvions passer de Gemini Studio à OpenAI à Google Vertex AI avec juste une ligne de code changée). La gestion de la mémoire de l'agent est nécessaire, mais un framework de mémoire dédié reste questionnable : Nous craignons qu'il ne crée une couche d'isolation entre les LLM et les développeurs, et que son sucre syntaxique ne devienne éventuellement un obstacle amer pour les développeurs, comme nous l'avons vu avec de nombreux frameworks LLM/RAG aujourd'hui.</p>",
  "comment_id": "67bc50b0b1b8af00014db4c9",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/deepsearch-banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-02-24T11:57:52.000+01:00",
  "updated_at": "2025-02-25T14:39:22.000+01:00",
  "published_at": "2025-02-25T14:36:17.000+01:00",
  "custom_excerpt": "QPS out, depth in. DeepSearch is the new norm. Find answers through read-search-reason loops. Learn what it is and how to build it.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-implementing-deepsearch-deepresearch/",
  "excerpt": "Exit le QPS, place à la profondeur. DeepSearch devient la nouvelle norme. Trouvez des réponses à travers des boucles de lecture, recherche et raisonnement. Découvrez ce que c'est et comment le construire.",
  "reading_time": 15,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}