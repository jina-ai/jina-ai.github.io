{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3 : Un modèle d'embedding multilingue à la pointe",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">Nous sommes en mission pour faire progresser et démocratiser l'intelligence artificielle grâce à l'open source et la science ouverte.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3 : Embeddings Multilingues avec Task LoRA</div><div class=\"kg-bookmark-description\">Nous présentons jina-embeddings-v3, un nouveau modèle d'embedding de texte avec 570 millions de paramètres, qui atteint des performances état de l'art sur les données multilingues et les tâches de recherche à contexte long, supportant des longueurs de contexte jusqu'à 8192 tokens. Le modèle inclut un ensemble d'adaptateurs Low-Rank Adaptation (LoRA) spécifiques aux tâches pour générer des embeddings de haute qualité pour la recherche requête-document, le clustering, la classification et la correspondance de texte. De plus, l'apprentissage de représentation Matryoshka est intégré au processus d'entraînement, permettant une troncature flexible des dimensions d'embedding sans compromettre les performances. L'évaluation sur le benchmark MTEB montre que jina-embeddings-v3 surpasse les derniers embeddings propriétaires d'OpenAI et Cohere sur les tâches en anglais, tout en obtenant des performances supérieures par rapport à multilingual-e5-large-instruct sur toutes les tâches multilingues.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Aujourd'hui, nous sommes ravis d'annoncer <code>jina-embeddings-v3</code>, un modèle d'embedding de texte de pointe avec 570 millions de paramètres. Il atteint des performances état de l'art sur les données <strong>multilingues</strong> et les tâches de recherche à <strong>contexte long</strong>, supportant une longueur d'entrée jusqu'à 8192 tokens. Le modèle dispose d'adaptateurs Low-Rank Adaptation (LoRA) spécifiques aux tâches, lui permettant de générer des embeddings de haute qualité pour diverses tâches dont la <strong>recherche requête-document</strong>, le <strong>clustering</strong>, la <strong>classification</strong> et la <strong>correspondance de texte</strong>.</p><p>Dans les évaluations sur MTEB English, Multilingual et LongEmbed, <code>jina-embeddings-v3</code> surpasse les derniers embeddings propriétaires d'OpenAI et Cohere sur les tâches en anglais, tout en dépassant également <code>multilingual-e5-large-instruct</code> sur toutes les tâches multilingues. Avec une dimension de sortie par défaut de 1024, les utilisateurs peuvent arbitrairement tronquer les dimensions d'embedding jusqu'à 32 sans sacrifier les performances, grâce à l'intégration du Matryoshka Representation Learning (MRL).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\">Les performances de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> comparées à d'autres modèles d'embedding sur toutes les tâches MTEB en anglais. Les résultats complets d'évaluation par tâche sont disponibles dans </span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">notre article arXiv</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">Les performances de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> ont été évaluées sur une large sélection de tâches MTEB multilingues et interlingues. Notez que </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2-(zh/es/de)</span></code><span style=\"white-space: pre-wrap;\"> fait référence à notre suite de modèles bilingues, qui n'a été testée que sur les tâches monolingues et interlingues en chinois, espagnol et allemand, excluant toutes les autres langues. De plus, nous ne rapportons pas les scores pour </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>openai-text-embedding-3-large</span></code><span style=\"white-space: pre-wrap;\"> et </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>cohere-embed-multilingual-v3.0</span></code><span style=\"white-space: pre-wrap;\">, car ces modèles n'ont pas été évalués sur l'ensemble complet des tâches MTEB multilingues et interlingues.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">Les performances de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> sur six tâches de recherche de documents longs du benchmark LongEmbed montrent une amélioration significative par rapport aux autres modèles. Les scores sont en nDCG@10 ; plus le score est élevé, meilleur c'est. Cela suggère l'efficacité de nos embeddings positionnels basés sur RoPE, qui surpassent à la fois les embeddings positionnels fixes utilisés par </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>baai-bge-m3</span></code><span style=\"white-space: pre-wrap;\"> et l'approche basée sur ALiBi utilisée dans </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>À sa sortie le 18 septembre 2024, <code>jina-embeddings-v3</code> est <strong>le meilleur</strong> modèle multilingue et se classe <strong>2ème</strong> sur le classement MTEB English pour les modèles de moins d'un milliard de paramètres. v3 prend en charge 89 langues au total, dont 30 langues avec les meilleures performances : arabe, bengali, chinois, danois, néerlandais, anglais, finnois, français, géorgien, allemand, grec, hindi, indonésien, italien, japonais, coréen, letton, norvégien, polonais, portugais, roumain, russe, slovaque, espagnol, suédois, thaï, turc, ukrainien, ourdou et vietnamien.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">À sa sortie le 18 septembre 2024, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\">, avec ses 570 millions de paramètres et 1024 dimensions de sortie, s'impose comme le modèle d'embedding multilingue le plus efficace, puissant et fiable avec moins d'un milliard de paramètres.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">Loi d'échelle des modèles d'embedding. La performance moyenne sur les tâches MTEB en anglais est représentée en fonction du nombre de paramètres du modèle. Chaque point représente un modèle d'embedding. La ligne de tendance, représentant tous les modèles, est mise en évidence, avec les modèles multilingues soulignés en cyan. On peut voir que </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> démontre des performances supérieures par rapport aux modèles de taille similaire, montrant également une amélioration superlinéaire par rapport à son prédécesseur, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\">. Ce graphique a été créé en sélectionnant les 100 meilleurs modèles d'embedding du classement MTEB, excluant ceux sans information de taille, généralement des modèles propriétaires ou fermés. Les soumissions identifiées comme du trolling évident ont également été filtrées.</span></figcaption></figure><p>De plus, comparé aux embeddings basés sur les LLM qui ont récemment attiré l'attention, comme <code>e5-mistral-7b-instruct</code>, qui a une taille de paramètres de 7,1 milliards (12x plus grand) et une dimension de sortie de 4096 (4x plus grande) mais n'offre qu'une amélioration de 1% sur les tâches MTEB en anglais, <code>jina-embeddings-v3</code> est une solution beaucoup plus rentable, la rendant plus adaptée à la production et au calcul en périphérie.</p><h2 id=\"model-architecture\">Architecture du Modèle</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Caractéristique</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>Paramètres Base</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>Paramètres avec LoRA</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>Tokens d'entrée max</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>Dimensions de sortie max</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>Couches</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Vocabulaire</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>Langues prises en charge</td>\n<td>89</td>\n</tr>\n<tr>\n<td>Attention</td>\n<td>FlashAttention2, fonctionne aussi sans</td>\n</tr>\n<tr>\n<td>Pooling</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>L'architecture de <code>jina-embeddings-v3</code> est présentée dans la figure ci-dessous. Pour implémenter l'architecture de base, nous avons adapté le modèle <code>XLM-RoBERTa</code> avec plusieurs modifications clés : (1) permettre l'encodage efficace de longues séquences de texte, (2) permettre l'encodage d'embeddings spécifiques à la tâche, et (3) améliorer l'efficacité globale du modèle avec les techniques les plus récentes. Nous continuons à utiliser le tokenizer original de <code>XLM-RoBERTa</code>. Bien que <code>jina-embeddings-v3</code>, avec ses 570 millions de paramètres, soit plus grand que <code>jina-embeddings-v2</code> avec ses 137 millions, il reste beaucoup plus petit que les modèles d'embedding fine-tunés à partir des LLMs.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\">L'architecture de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> est basée sur le modèle </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\">, avec cinq adaptateurs LoRA pour quatre tâches différentes.</span></figcaption></figure><p>L'innovation clé dans <code>jina-embeddings-v3</code> est l'utilisation des adaptateurs LoRA. <strong>Cinq</strong> adaptateurs LoRA spécifiques aux tâches sont introduits pour optimiser les embeddings pour <strong>quatre</strong> tâches. L'entrée du modèle se compose de deux parties : le texte (le long document à encoder) et la tâche. <code>jina-embeddings-v3</code> prend en charge quatre tâches et implémente cinq adaptateurs au choix : <code>retrieval.query</code> et <code>retrieval.passage</code> pour les embeddings de requêtes et de passages dans les tâches de recherche asymétrique, <code>separation</code> pour les tâches de clustering, <code>classification</code> pour les tâches de classification, et <code>text-matching</code> pour les tâches impliquant la similarité sémantique, comme STS ou la recherche symétrique. Les adaptateurs LoRA représentent moins de 3 % du total des paramètres, ajoutant très peu de surcharge au calcul.</p><p>Pour améliorer davantage les performances et réduire la consommation de mémoire, nous intégrons FlashAttention 2, prenons en charge le checkpointing des activations et utilisons le framework DeepSpeed pour un entraînement distribué efficace.</p><h2 id=\"get-started\">Pour Commencer</h2><h3 id=\"via-jina-ai-search-foundation-api\">Via l'API Search Foundation de Jina AI</h3><p>La façon la plus simple d'utiliser <code>jina-embeddings-v3</code> est de visiter la <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">page d'accueil de Jina AI</a> et de naviguer vers la section API Search Foundation. À partir d'aujourd'hui, ce modèle est défini par défaut pour tous les nouveaux utilisateurs. Vous pouvez explorer différents paramètres et fonctionnalités directement à partir de là.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>Par rapport à v2, v3 introduit trois nouveaux paramètres dans l'API : <code>task</code>, <code>dimensions</code> et <code>late_chunking</code>. </p><h4 id=\"parameter-task\">Paramètre <code>task</code></h4><p>Le paramètre <code>task</code> est crucial et doit être défini en fonction de la tâche en aval. Les embeddings résultants seront optimisés pour cette tâche spécifique. Pour plus de détails, référez-vous à la liste ci-dessous.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>Valeur de <code>task</code></strong></th>\n<th><strong>Description de la tâche</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>Embedding des <b>documents</b> dans une tâche de recherche requête-document</td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>Embedding des <b>requêtes</b> dans une tâche de recherche requête-document</td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>Clustering de documents, visualisation d'un corpus</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>Classification de texte</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(Par défaut)</b> Similarité sémantique de texte, recherche symétrique générale, recommandation, recherche d'éléments similaires, déduplication</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Notez que l'API ne génère <em>pas</em> d'abord un meta-embedding générique pour ensuite l'adapter avec un MLP fine-tuné additionnel. Au lieu de cela, elle insère l'adaptateur LoRA spécifique à la tâche dans chaque couche transformeur (un total de 24 couches) et effectue l'encodage en une seule fois. Plus de détails peuvent être trouvés dans <a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">notre article arXiv</a>.</p><h4 id=\"parameter-dimensions\">Paramètre <code>dimensions</code></h4><p>Le paramètre <code>dimensions</code> permet aux utilisateurs de choisir un compromis entre l'efficacité spatiale et les performances au moindre coût. Grâce à la technique MRL utilisée dans <code>jina-embeddings-v3</code>, vous pouvez réduire les dimensions des embeddings autant que vous le souhaitez (même jusqu'à une seule dimension !). Des embeddings plus petits sont plus économes en stockage pour les bases de données vectorielles, et leur coût en performance peut être estimé à partir de la figure ci-dessous.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">Paramètre <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Late Chunking dans les modèles d'embedding à contexte long</div><div class=\"kg-bookmark-description\">Le découpage de longs documents tout en préservant l'information contextuelle est un défi. Nous introduisons le \"Late Chunking\" qui exploite les modèles d'embedding à contexte long pour générer des embeddings de chunks contextuels pour de meilleures applications de recherche.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Enfin, le paramètre <code>late_chunking</code> contrôle l'utilisation de la nouvelle méthode de découpage <a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">que nous avons introduite le mois dernier</a> pour l'encodage d'un lot de phrases. Lorsqu'il est défini sur <code>true</code>, notre API concaténera toutes les phrases dans le champ <code>input</code> et les alimentera comme une seule chaîne au modèle. En d'autres termes, <strong>nous traitons les phrases en entrée comme si elles provenaient originellement de la même section, paragraphe ou document.</strong> En interne, le modèle encode cette longue chaîne concaténée puis effectue le découpage tardif, retournant une liste d'embeddings qui correspond à la taille de la liste d'entrée. Chaque embedding dans la liste est donc conditionné par les embeddings précédents.</p><p>Du point de vue de l'utilisateur, la définition de <code>late_chunking</code> ne change <em>pas</em> le format d'entrée ou de sortie. Vous ne remarquerez qu'un changement dans les valeurs des embeddings, car elles sont maintenant calculées en fonction de tout le contexte précédent plutôt qu'indépendamment. Ce qu'il est important de savoir lors de l'utilisation de<code>late_chunking=True</code> signifie que le nombre total de tokens (en additionnant tous les tokens dans <code>input</code>) par requête est limité à 8192, qui est la longueur maximale de contexte autorisée pour <code>jina-embeddings-v3</code>. Lorsque <code>late_chunking=False</code>, il n'y a pas une telle restriction; le nombre total de tokens est uniquement soumis à <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">la limite de débit de l'API Embedding</a>.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking activé vs désactivé : Le format d'entrée et de sortie reste le même, la seule différence étant les valeurs d'embedding. Lorsque </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\"> est activé, les embeddings sont influencés par tout le contexte précédent dans </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\">, alors que sans lui, les embeddings sont calculés indépendamment.</span></p></figcaption></figure><h3 id=\"via-azure-aws\">Via Azure & AWS</h3><p><code>jina-embeddings-v3</code> est maintenant disponible sur AWS SageMaker et Azure Marketplace.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>Si vous devez l'utiliser au-delà de ces plateformes ou sur site au sein de votre entreprise, notez que le modèle est sous licence CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Pour toute demande d'utilisation commerciale, n'hésitez pas à nous contacter.</a></p><h3 id=\"via-vector-databases-partners\">Via les bases de données vectorielles & partenaires</h3><p>Nous collaborons étroitement avec les fournisseurs de bases de données vectorielles comme Pinecone, Qdrant et Milvus, ainsi qu'avec les frameworks d'orchestration LLM comme LlamaIndex, Haystack et Dify. Au moment de la sortie, nous sommes heureux d'annoncer que Pinecone, Qdrant, Milvus et Haystack ont déjà intégré le support de <code>jina-embeddings-v3</code>, y compris les trois nouveaux paramètres : <code>task</code>, <code>dimensions</code> et <code>late_chunking</code>. Les autres partenaires qui ont déjà intégré l'API <code>v2</code> devraient également supporter <code>v3</code> en changeant simplement le nom du modèle en <code>jina-embeddings-v3</code>. Cependant, ils ne prennent peut-être pas encore en charge les nouveaux paramètres introduits dans <code>v3</code>.</p><h4 id=\"via-pinecone\">Via Pinecone</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">Via Qdrant</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">Via Milvus</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">Via Haystack</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">Conclusion</h2><p>En octobre 2023, nous avons publié <code>jina-embeddings-v2-base-en</code>, <a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">le premier modèle d'embedding open-source au monde avec une longueur de contexte de 8K</a>. C'était le <em>seul</em> modèle d'embedding de texte qui supportait un long contexte et égalait le <code>text-embedding-ada-002</code> d'OpenAI. Aujourd'hui, après une année d'apprentissage, d'expérimentation et de leçons précieuses, nous sommes fiers de publier <code>jina-embeddings-v3</code> — une nouvelle frontière dans les modèles d'embedding de texte et une étape importante pour notre entreprise.</p><p>Avec cette version, nous continuons d'exceller dans ce pour quoi nous sommes connus : les <strong>embeddings à long contexte</strong>, tout en répondant également à la fonctionnalité la plus demandée par l'industrie et la communauté — les <strong>embeddings multilingues</strong>. En même temps, nous poussons les performances vers de nouveaux sommets. Avec de nouvelles fonctionnalités telles que le LoRA spécifique aux tâches, le MRL et le late chunking, nous pensons que <code>jina-embeddings-v3</code> servira véritablement de modèle d'embedding fondamental pour diverses applications, y compris le RAG, les agents et plus encore. Comparé aux embeddings récents basés sur les LLM comme <code>NV-embed-v1/v2</code>, notre modèle est très efficace en termes de paramètres, le rendant beaucoup plus adapté à la production et aux appareils edge.</p><p>À l'avenir, nous prévoyons de nous concentrer sur l'évaluation et l'amélioration des performances de <code>jina-embeddings-v3</code> sur les langues à ressources limitées et d'analyser davantage les échecs systématiques causés par la disponibilité limitée des données. De plus, les poids du modèle de <code>jina-embeddings-v3</code>, ainsi que ses fonctionnalités innovantes et ses points forts, serviront de base pour nos prochains modèles, y compris <code>jina-clip-v2</code>,<code>jina-reranker-v3</code>, et <code>reader-lm-v2</code>.</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 est un modèle d'embedding de texte multilingue de pointe avec 570M paramètres et une longueur de token de 8192, surpassant les derniers embeddings propriétaires d'OpenAI et Cohere sur MTEB.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}