{
  "slug": "finding-optimal-breakpoints-in-long-documents-using-small-language-models",
  "id": "67126986708dbe00019249f2",
  "uuid": "b7e55a5d-f267-4a4a-b861-27221c0f3827",
  "title": "Trouver les points de coupure optimaux dans les longs documents √† l'aide de petits mod√®les de langage",
  "html": "<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Ceci est la partie III de notre s√©rie sur le d√©coupage. <b><strong style=\"white-space: pre-wrap;\">Ordre de lecture recommand√© : </strong></b><a href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><b><strong style=\"white-space: pre-wrap;\">partie I</strong></b></a><b><strong style=\"white-space: pre-wrap;\">, </strong></b><a href=\"https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii?ref=jina-ai-gmbh.ghost.io\"><b><strong style=\"white-space: pre-wrap;\">partie II</strong></b></a><b><strong style=\"white-space: pre-wrap;\">, </strong></b><a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\"><b><strong style=\"white-space: pre-wrap;\">article de recherche</strong></b></a><b><strong style=\"white-space: pre-wrap;\">, partie III.</strong></b></div></div><p>Dans nos articles pr√©c√©dents, nous avons explor√© les d√©fis du d√©coupage et <a href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\">introduit le concept de d√©coupage tardif</a>, qui aide √† r√©duire la perte de contexte lors de l'int√©gration des segments. Dans cet article, nous nous concentrerons sur un autre d√©fi : trouver les points de coupure optimaux. Bien que <a href=\"https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/?ref=jina-ai-gmbh.ghost.io#late-chunking-is-resilient-to-poor-boundary-cues\" rel=\"noreferrer\">notre strat√©gie de d√©coupage tardif se soit r√©v√©l√©e assez r√©sistante aux limites mal d√©finies</a>, cela ne signifie pas que nous pouvons les ignorer ‚Äî elles restent importantes tant pour la lisibilit√© humaine que pour celle des LLM. Voici notre perspective : lors de la d√©termination des points de coupure, nous pouvons d√©sormais nous concentrer pleinement sur la lisibilit√© sans nous soucier de la perte s√©mantique ou contextuelle. Le d√©coupage tardif peut g√©rer √† la fois les bons et les mauvais points de coupure, donc la lisibilit√© devient votre pr√©occupation principale.</p><p>Dans cette optique, nous avons entra√Æn√© trois petits mod√®les de langage sp√©cifiquement con√ßus pour segmenter de longs documents tout en maintenant la coh√©rence s√©mantique et en g√©rant des structures de contenu complexes. Ce sont :</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/text-seg-lm-qwen2-0.5b ¬∑ Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/text-seg-lm-qwen2-0.5b.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>simple-qwen-0.5</span></code><span style=\"white-space: pre-wrap;\">, qui segmente le texte en fonction des √©l√©ments structurels du document.</span></p></figcaption></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking ¬∑ Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>topic-qwen-0.5</span></code><span style=\"white-space: pre-wrap;\">, qui segmente le texte en fonction des sujets pr√©sents dans le texte.</span></p></figcaption></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b-summary-chunking?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/text-seg-lm-qwen2-0.5b-summary-chunking ¬∑ Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/text-seg-lm-qwen2-0.5b-summary-chunking.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>summary-qwen-0.5</span></code><span style=\"white-space: pre-wrap;\">, qui g√©n√®re des r√©sum√©s pour chaque segment.</span></p></figcaption></figure><p>Dans cet article, nous discuterons des raisons qui nous ont pouss√©s √† d√©velopper ce mod√®le, de notre approche pour ses trois variantes, et de leurs performances par rapport √† <a href=\"https://www.notion.so/Advancing-Segmentation-Strategies-in-RAG-with-a-Custom-Small-Language-Model-Restructure-638b84ae461d412eb6889cfa7f54cce1?pvs=21&ref=jina-ai-gmbh.ghost.io\">l'API Segmenter de Jina AI</a>. Enfin, nous partagerons ce que nous avons appris et quelques r√©flexions pour l'avenir.</p><h2 id=\"segmentation-problem\">Probl√®me de Segmentation</h2><p>La segmentation est un √©l√©ment fondamental des syst√®mes RAG. La fa√ßon dont nous d√©coupons les longs documents en segments coh√©rents et g√©rables affecte directement la qualit√© des √©tapes de r√©cup√©ration et de g√©n√©ration, influen√ßant tout, de la pertinence des r√©ponses √† la qualit√© des r√©sum√©s. Les m√©thodes traditionnelles de segmentation ont produit des r√©sultats corrects mais ne sont pas sans limitations.</p><p>Pour paraphraser notre <a href=\"https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/?ref=jina-ai-gmbh.ghost.io\">article pr√©c√©dent</a> :</p><blockquote>Lors de la segmentation d'un long document, un d√©fi majeur est de d√©cider o√π cr√©er les segments. Cela peut √™tre fait en utilisant des longueurs fixes de tokens, un nombre d√©fini de phrases, ou des m√©thodes plus avanc√©es comme les regex et les mod√®les de segmentation s√©mantique. √âtablir des limites de segment pr√©cises est crucial, car cela am√©liore non seulement la lisibilit√© des r√©sultats de recherche mais garantit aussi que les segments fournis √† un LLM dans un syst√®me RAG sont √† la fois pr√©cis et suffisants.</blockquote><p>Bien que le d√©coupage tardif am√©liore les performances de r√©cup√©ration, <strong>dans les applications RAG, il est crucial de s'assurer que, autant que possible, chaque segment est significatif en soi, et pas seulement un morceau al√©atoire de texte.</strong> Les LLM s'appuient sur des donn√©es coh√©rentes et bien structur√©es pour g√©n√©rer des r√©ponses pr√©cises. Si les segments sont incomplets ou manquent de sens, le LLM peut avoir des difficult√©s avec le contexte et la pr√©cision, impactant les performances globales malgr√© les avantages du d√©coupage tardif. En bref, que vous utilisiez ou non le d√©coupage tardif, avoir une strat√©gie de segmentation solide est essentiel pour construire un syst√®me RAG efficace (comme vous le verrez dans la section benchmark plus bas).</p><p>Les m√©thodes traditionnelles de segmentation, qu'il s'agisse de couper le contenu √† des limites simples comme les nouvelles lignes ou les phrases, ou d'utiliser des r√®gles rigides bas√©es sur les tokens, font souvent face aux m√™mes limitations. Les deux approches ne tiennent pas compte des limites s√©mantiques et peinent avec les sujets ambigus, conduisant √† des segments fragment√©s. Pour relever ces d√©fis, nous avons d√©velopp√© et entra√Æn√© un petit mod√®le de langage sp√©cifiquement pour la segmentation, con√ßu pour capturer les changements de sujet et maintenir la coh√©rence tout en restant efficace et adaptable √† diverses t√¢ches.</p><h2 id=\"why-small-language-model\">Pourquoi un Petit Mod√®le de Langage ?</h2><p>Nous avons d√©velopp√© un Petit Mod√®le de Langage (SLM) pour r√©pondre aux limitations sp√©cifiques que nous avons rencontr√©es avec les techniques de segmentation traditionnelles, particuli√®rement lors du traitement des extraits de code et d'autres structures complexes comme les tableaux, les listes et les formules. Dans les approches traditionnelles, qui s'appuient souvent sur le comptage de tokens ou des r√®gles structurelles rigides, il √©tait difficile de maintenir l'int√©grit√© du contenu s√©mantiquement coh√©rent. Par exemple, les extraits de code √©taient fr√©quemment segment√©s en plusieurs parties, brisant leur contexte et rendant plus difficile pour les syst√®mes en aval de les comprendre ou de les r√©cup√©rer avec pr√©cision.</p><p>En entra√Ænant un SLM sp√©cialis√©, nous visions √† cr√©er un mod√®le qui pourrait intelligemment reconna√Ætre et pr√©server ces limites significatives, assurant que les √©l√©ments li√©s restent ensemble. Cela am√©liore non seulement la qualit√© de r√©cup√©ration dans les syst√®mes RAG mais aussi les t√¢ches en aval comme la r√©sumation et les r√©ponses aux questions, o√π maintenir des segments coh√©rents et contextuellement pertinents est crucial. L'approche SLM offre une solution plus adaptable et sp√©cifique √† la t√¢che que les m√©thodes de segmentation traditionnelles, avec leurs limites rigides, ne peuvent simplement pas fournir.</p><h2 id=\"training-slms-three-approaches\">Entra√Ænement des SLM : Trois Approches</h2><p>Nous avons entra√Æn√© trois versions de notre SLM :</p><ul><li><code>simple-qwen-0.5</code> est le mod√®le le plus simple, con√ßu pour identifier les limites bas√©es sur les √©l√©ments structurels du document. Sa simplicit√© en fait une solution efficace pour les besoins de segmentation de base.</li><li><code>topic-qwen-0.5</code>, inspir√© par le raisonnement Chain-of-Thought, pousse la segmentation plus loin en identifiant les sujets dans le texte, comme \"le d√©but de la Seconde Guerre mondiale\", et en utilisant ces sujets pour d√©finir les limites des segments. Ce mod√®le assure que chaque segment est coh√©rent th√©matiquement, le rendant bien adapt√© aux documents complexes √† sujets multiples. Les tests initiaux ont montr√© qu'il excelle dans la segmentation du contenu d'une mani√®re qui refl√®te √©troitement l'intuition humaine.</li><li><code>summary-qwen-0.5</code> non seulement identifie les limites du texte mais g√©n√®re aussi des r√©sum√©s pour chaque segment. R√©sumer les segments est tr√®s avantageux dans les applications RAG, particuli√®rement pour les t√¢ches comme les questions-r√©ponses sur de longs documents, bien que cela s'accompagne d'un compromis n√©cessitant plus de donn√©es lors de l'entra√Ænement.</li></ul><p>Tous les mod√®les ne retournent que les <em>t√™tes de segment</em> ‚Äî une version tronqu√©e de chaque segment. Au lieu de g√©n√©rer des segments entiers, les mod√®les produisent des points cl√©s ou des sous-sujets, ce qui am√©liore la d√©tection des limites et la coh√©rence en se concentrant sur les transitions s√©mantiques plut√¥t que de simplement copier le contenu d'entr√©e. Lors de la r√©cup√©ration des segments, le texte du document est divis√© sur la base de ces t√™tes de segment, et les segments complets sont reconstruits en cons√©quence.</p><h3 id=\"dataset\">Jeu de donn√©es</h3><p>Nous avons utilis√© le jeu de donn√©es <a href=\"https://github.com/koomri/text-segmentation?ref=jina-ai-gmbh.ghost.io\">wiki727k</a>, une collection √† grande √©chelle d'extraits de texte structur√©s tir√©s d'articles Wikip√©dia. Il contient plus de 727 000 sections de texte, chacune repr√©sentant une partie distincte d'un article Wikip√©dia, comme une introduction, une section ou une sous-section.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/koomri/text-segmentation?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - koomri/text-segmentation : Impl√©mentation de l'article : Text Segmentation as a Supervised Learning Task</div><div class=\"kg-bookmark-description\">Impl√©mentation de l'article : Text Segmentation as a Supervised Learning Task - koomri/text-segmentation</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">koomri</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/a0a75db005774d424366f3fa2d4c70930927a0b2d8032ef3c04cb0f3beebcb8e/koomri/text-segmentation\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"data-augmentation\">Augmentation des donn√©es</h3><p>Pour g√©n√©rer des paires d'entra√Ænement pour chaque variante du mod√®le, nous avons utilis√© GPT-4 pour augmenter nos donn√©es. Pour chaque article de notre jeu de donn√©es d'entra√Ænement, nous avons envoy√© l'invite :</p><pre><code class=\"language-python\">f\"\"\"\nGenerate a five to ten words topic and a one sentence summary for this chunk of text.\n```\n{text}\n```\nMake sure the topic is concise and the summary covers the main topic as much as possible.\n\nPlease respond in the following format:\n```\nTopic: ...\nSummary: ...\n```\n\nDirectly respond with the required topic and summary, do not include any other details, and do not surround your response with quotes, backticks or other separators.\n   \"\"\".strip()</code></pre><p>Nous avons utilis√© un d√©coupage simple pour g√©n√©rer des sections √† partir de chaque article, en d√©coupant sur <code>\\\\n\\\\n\\\\n</code>, puis en sous-d√©coupant sur <code>\\\\n\\\\n</code> pour obtenir ce qui suit (dans ce cas, un article sur Common Gateway Interface) :</p><pre><code>[\n    [\n      \"In computing, Common Gateway Interface (CGI) offers a standard protocol for web servers to execute programs that execute like Console applications (also called Command-line interface programs) running on a server that generates web pages dynamically.\",\n      \"Such programs are known as \\\\\"CGI scripts\\\\\" or simply as \\\\\"CGIs\\\\\".\",\n      \"The specifics of how the script is executed by the server are determined by the server.\",\n      \"In the common case, a CGI script executes at the time a request is made and generates HTML.\"\n    ],\n    [\n      \"In 1993 the National Center for Supercomputing Applications (NCSA) team wrote the specification for calling command line executables on the www-talk mailing list; however, NCSA no longer hosts the specification.\",\n      \"The other Web server developers adopted it, and it has been a standard for Web servers ever since.\",\n      \"A work group chaired by Ken Coar started in November 1997 to get the NCSA definition of CGI more formally defined.\",\n      \"This work resulted in RFC 3875, which specified CGI Version 1.1.\",\n      \"Specifically mentioned in the RFC are the following contributors: \\\\n1. Alice Johnson\\\\n2. Bob Smith\\\\n3. Carol White\\\\n4. David Nguyen\\\\n5. Eva Brown\\\\n6. Frank Lee\\\\n7. Grace Kim\\\\n8. Henry Carter\\\\n9. Ingrid Martinez\\\\n10. Jack Wilson\",\n      \"Historically CGI scripts were often written using the C language.\",\n      \"RFC 3875 \\\\\"The Common Gateway Interface (CGI)\\\\\" partially defines CGI using C, as in saying that environment variables \\\\\"are accessed by the C library routine getenv() or variable environ\\\\\".\"\n    ],\n    [\n      \"CGI is often used to process inputs information from the user and produce the appropriate output.\",\n      \"An example of a CGI program is one implementing a Wiki.\",\n      \"The user agent requests the name of an entry; the Web server executes the CGI; the CGI program retrieves the source of that entry's page (if one exists), transforms it into HTML, and prints the result.\",\n      \"The web server receives the input from the CGI and transmits it to the user agent.\",\n      \"If the \\\\\"Edit this page\\\\\" link is clicked, the CGI populates an HTML textarea or other editing control with the page's contents, and saves it back to the server when the user submits the form in it.\\\\n\",\n      \"\\\\n# CGI script to handle editing a page\\\\ndef handle_edit_request(page_content):\\\\n    html_form = f'''\\\\n    &lt;html&gt;\\\\n    &lt;body&gt;\\\\n        &lt;form action=\\\\\"/save_page\\\\\" method=\\\\\"post\\\\\"&gt;\\\\n            &lt;textarea name=\\\\\"page_content\\\\\" rows=\\\\\"20\\\\\" cols=\\\\\"80\\\\\"&gt;\\\\n            {page_content}\\\\n            &lt;/textarea&gt;\\\\n            &lt;br&gt;\\\\n            &lt;input type=\\\\\"submit\\\\\" value=\\\\\"Save\\\\\"&gt;\\\\n        &lt;/form&gt;\\\\n    &lt;/body&gt;\\\\n    &lt;/html&gt;\\\\n    '''\\\\n    return html_form\\\\n\\\\n# Example usage\\\\npage_content = \\\\\"Existing content of the page.\\\\\"\\\\nhtml_output = handle_edit_request(page_content)\\\\nprint(\\\\\"Generated HTML form:\\\\\")\\\\nprint(html_output)\\\\n\\\\ndef save_page(page_content):\\\\n    with open(\\\\\"page_content.txt\\\\\", \\\\\"w\\\\\") as file:\\\\n        file.write(page_content)\\\\n    print(\\\\\"Page content saved.\\\\\")\\\\n\\\\n# Simulating form submission\\\\nsubmitted_content = \\\\\"Updated content of the page.\\\\\"\\\\nsave_page(submitted_content)\"\n    ],\n    [\n      \"Calling a command generally means the invocation of a newly created process on the server.\",\n      \"Starting the process can consume much more time and memory than the actual work of generating the output, especially when the program still needs to be interpreted or compiled.\",\n      \"If the command is called often, the resulting workload can quickly overwhelm the server.\",\n      \"The overhead involved in process creation can be reduced by techniques such as FastCGI that \\\\\"prefork\\\\\" interpreter processes, or by running the application code entirely within the web server, using extension modules such as mod_perl or mod_php.\",\n      \"Another way to reduce the overhead is to use precompiled CGI programs, e.g.\",\n      \"by writing them in languages such as C or C++, rather than interpreted or compiled-on-the-fly languages such as Perl or PHP, or by implementing the page generating software as a custom webserver module.\",\n      \"Several approaches can be adopted for remedying this: \\\\n1. Implementing stricter regulations\\\\n2. Providing better education and training\\\\n3. Enhancing technology and infrastructure\\\\n4. Increasing funding and resources\\\\n5. Promoting collaboration and partnerships\\\\n6. Conducting regular audits and assessments\",\n      \"The optimal configuration for any Web application depends on application-specific details, amount of traffic, and complexity of the transaction; these tradeoffs need to be analyzed to determine the best implementation for a given task and time budget.\"\n    ]\n  ],\n</code></pre><p>Nous avons ensuite g√©n√©r√© une structure JSON avec les sections, les sujets et les r√©sum√©s :</p><pre><code>{\n  \"sections\": [\n    [\n      \"In computing, Common Gateway Interface (CGI) offers a standard protocol for web servers to execute programs that execute like Console applications (also called Command-line interface programs) running on a server that generates web pages dynamically.\",\n      \"Such programs are known as \\\\\"CGI scripts\\\\\" or simply as \\\\\"CGIs\\\\\".\",\n      \"The specifics of how the script is executed by the server are determined by the server.\",\n      \"In the common case, a CGI script executes at the time a request is made and generates HTML.\"\n    ],\n    [\n      \"In 1993 the National Center for Supercomputing Applications (NCSA) team wrote the specification for calling command line executables on the www-talk mailing list; however, NCSA no longer hosts the specification.\",\n      \"The other Web server developers adopted it, and it has been a standard for Web servers ever since.\",\n      \"A work group chaired by Ken Coar started in November 1997 to get the NCSA definition of CGI more formally defined.\",\n      \"This work resulted in RFC 3875, which specified CGI Version 1.1.\",\n      \"Specifically mentioned in the RFC are the following contributors: \\\\n1. Alice Johnson\\\\n2. Bob Smith\\\\n3. Carol White\\\\n4. David Nguyen\\\\n5. Eva Brown\\\\n6. Frank Lee\\\\n7. Grace Kim\\\\n8. Henry Carter\\\\n9. Ingrid Martinez\\\\n10. Jack Wilson\",\n      \"Historically CGI scripts were often written using the C language.\",\n      \"RFC 3875 \\\\\"The Common Gateway Interface (CGI)\\\\\" partially defines CGI using C, as in saying that environment variables \\\\\"are accessed by the C library routine getenv() or variable environ\\\\\".\"\n    ],\n    [\n      \"CGI is often used to process inputs information from the user and produce the appropriate output.\",\n      \"An example of a CGI program is one implementing a Wiki.\",\n      \"The user agent requests the name of an entry; the Web server executes the CGI; the CGI program retrieves the source of that entry's page (if one exists), transforms it into HTML, and prints the result.\",\n      \"The web server receives the input from the CGI and transmits it to the user agent.\",\n      \"If the \\\\\"Edit this page\\\\\" link is clicked, the CGI populates an HTML textarea or other editing control with the page's contents, and saves it back to the server when the user submits the form in it.\\\\n\",\n      \"\\\\n# CGI script to handle editing a page\\\\ndef handle_edit_request(page_content):\\\\n    html_form = f'''\\\\n    &lt;html&gt;\\\\n    &lt;body&gt;\\\\n        &lt;form action=\\\\\"/save_page\\\\\" method=\\\\\"post\\\\\"&gt;\\\\n            &lt;textarea name=\\\\\"page_content\\\\\" rows=\\\\\"20\\\\\" cols=\\\\\"80\\\\\"&gt;\\\\n            {page_content}\\\\n            &lt;/textarea&gt;\\\\n            &lt;br&gt;\\\\n            &lt;input type=\\\\\"submit\\\\\" value=\\\\\"Save\\\\\"&gt;\\\\n        &lt;/form&gt;\\\\n    &lt;/body&gt;\\\\n    &lt;/html&gt;\\\\n    '''\\\\n    return html_form\\\\n\\\\n# Example usage\\\\npage_content = \\\\\"Existing content of the page.\\\\\"\\\\nhtml_output = handle_edit_request(page_content)\\\\nprint(\\\\\"Generated HTML form:\\\\\")\\\\nprint(html_output)\\\\n\\\\ndef save_page(page_content):\\\\n    with open(\\\\\"page_content.txt\\\\\", \\\\\"w\\\\\") as file:\\\\n        file.write(page_content)\\\\n    print(\\\\\"Page content saved.\\\\\")\\\\n\\\\n# Simulating form submission\\\\nsubmitted_content = \\\\\"Updated content of the page.\\\\\"\\\\nsave_page(submitted_content)\"\n    ],\n    [\n      \"Calling a command generally means the invocation of a newly created process on the server.\",\n      \"Starting the process can consume much more time and memory than the actual work of generating the output, especially when the program still needs to be interpreted or compiled.\",\n      \"If the command is called often, the resulting workload can quickly overwhelm the server.\",\n      \"The overhead involved in process creation can be reduced by techniques such as FastCGI that \\\\\"prefork\\\\\" interpreter processes, or by running the application code entirely within the web server, using extension modules such as mod_perl or mod_php.\",\n      \"Another way to reduce the overhead is to use precompiled CGI programs, e.g.\",\n      \"by writing them in languages such as C or C++, rather than interpreted or compiled-on-the-fly languages such as Perl or PHP, or by implementing the page generating software as a custom webserver module.\",\n      \"Several approaches can be adopted for remedying this: \\\\n1. Implementing stricter regulations\\\\n2. Providing better education and training\\\\n3. Enhancing technology and infrastructure\\\\n4. Increasing funding and resources\\\\n5. Promoting collaboration and partnerships\\\\n6. Conducting regular audits and assessments\",\n      \"The optimal configuration for any Web application depends on application-specific details, amount of traffic, and complexity of the transaction; these tradeoffs need to be analyzed to determine the best implementation for a given task and time budget.\"\n    ]\n  ],\n  \"topics\": [\n    \"Common Gateway Interface in Web Servers\",\n    \"The History and Standardization of CGI\",\n    \"CGI Scripts for Editing Web Pages\",\n    \"Reducing Web Server Overhead in Command Invocation\"\n  ],\n  \"summaries\": [\n    \"CGI provides a protocol for web servers to run programs that generate dynamic web pages.\",\n    \"The NCSA initially defined CGI in 1993, leading to its adoption as a standard for Web servers and later formalization in RFC 3875 chaired by Ken Coar.\",\n    \"This text describes how a CGI script can handle editing and saving web page content through HTML forms.\",\n    \"The text discusses techniques to minimize server overhead from frequent command invocation, including process preforking, using precompiled CGI programs, and implementing custom web server modules.\"\n  ]\n}\n</code></pre><p>Nous avons √©galement ajout√© du bruit en m√©langeant les donn√©es, en ajoutant des caract√®res/mots/lettres al√©atoires, en supprimant al√©atoirement la ponctuation, et en supprimant <em>syst√©matiquement</em> les caract√®res de nouvelle ligne.</p><p>Tout cela peut contribuer en partie au d√©veloppement d'un bon mod√®le - mais seulement jusqu'√† un certain point. Pour vraiment optimiser les performances, nous avions besoin que le mod√®le cr√©e des segments coh√©rents sans d√©structurer les extraits de code. Pour cela, nous avons enrichi le jeu de donn√©es avec du code, des formules et des listes g√©n√©r√©s par GPT-4o.</p><h3 id=\"the-training-setup\">La Configuration de l'Entra√Ænement</h3><p>Pour l'entra√Ænement des mod√®les, nous avons mis en place la configuration suivante :</p><ul><li><strong>Framework</strong> : Nous avons utilis√© la biblioth√®que <code>transformers</code> de Hugging Face int√©gr√©e √† <code>Unsloth</code> pour l'optimisation du mod√®le. Cela a √©t√© crucial pour optimiser l'utilisation de la m√©moire et acc√©l√©rer l'entra√Ænement, rendant possible l'entra√Ænement efficace de petits mod√®les avec de grands jeux de donn√©es.</li><li><strong>Optimiseur et Planificateur</strong> : Nous avons utilis√© l'optimiseur AdamW avec un taux d'apprentissage lin√©aire et des √©tapes de pr√©chauffage, nous permettant de stabiliser le processus d'entra√Ænement pendant les √©poques initiales.</li><li><strong>Suivi des Exp√©riences</strong> : Nous avons suivi tous les entra√Ænements en utilisant <a href=\"https://wandb.ai/?ref=jina-ai-gmbh.ghost.io\">Weights & Biases</a>, et enregistr√© les m√©triques cl√©s comme les pertes d'entra√Ænement et de validation, les changements de taux d'apprentissage et la performance globale du mod√®le. Ce suivi en temps r√©el nous a fourni des insights sur la progression des mod√®les, permettant des ajustements rapides si n√©cessaire pour optimiser les r√©sultats d'apprentissage.</li></ul><h3 id=\"the-training-itself\">L'Entra√Ænement en Lui-m√™me</h3><p>En utilisant <a href=\"https://huggingface.co/Qwen/Qwen2-0.5B-Instruct?ref=jina-ai-gmbh.ghost.io\"><code>qwen2-0.5b-instruct</code></a> comme mod√®le de base, nous avons entra√Æn√© trois variantes de notre SLM avec Unsloth, chacune avec une strat√©gie de segmentation diff√©rente. Pour nos √©chantillons, nous avons utilis√© des paires d'entra√Ænement, compos√©es du texte d'un article de wiki727k et des <code>sections</code>, <code>topics</code>, ou <code>summaries</code> r√©sultants (mentionn√©s ci-dessus dans la section \"Augmentation des Donn√©es\") selon le mod√®le entra√Æn√©.</p><ul><li><code><strong>simple-qwen-0.5</strong></code> : Nous avons entra√Æn√© <code>simple-qwen-0.5</code> sur 10 000 √©chantillons avec 5 000 √©tapes, obtenant une convergence rapide et d√©tectant efficacement les fronti√®res entre les sections coh√©rentes du texte. La perte d'entra√Ænement √©tait de 0,16.</li><li><code><strong>topic-qwen-0.5</strong></code> : Comme <code>simple-qwen-0.5</code>, nous avons entra√Æn√© <code>topic-qwen-0.5</code> sur 10 000 √©chantillons avec 5 000 √©tapes, obtenant une perte d'entra√Ænement de 0,45.</li><li><code><strong>summary-qwen-0.5</strong></code> : Nous avons entra√Æn√© <code>summary-qwen-0.5</code> sur 30 000 √©chantillons avec 15 000 √©tapes. Ce mod√®le s'est montr√© prometteur mais a eu une perte plus √©lev√©e (0,81) pendant l'entra√Ænement, sugg√©rant le besoin de plus de donn√©es (environ le double de notre compte d'√©chantillons initial) pour atteindre son plein potentiel.</li></ul><h2 id=\"the-segments-themselves\">Les Segments Eux-m√™mes</h2><p>Voici des exemples de trois segments cons√©cutifs pour chaque strat√©gie de segmentation, avec l'API Jina Segmenter. Pour produire ces segments, nous avons d'abord utilis√© <a href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> pour extraire un article du blog Jina AI en texte brut (incluant toutes les donn√©es de la page, comme les en-t√™tes, pieds de page, etc.), puis nous l'avons pass√© √† chaque m√©thode de segmentation.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/can-embedding-reranker-models-compare-numbers/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Can Embedding/Reranker Models Compare Numbers?</div><div class=\"kg-bookmark-description\">A lot of LLMs can't figure out that 9.11 is actually smaller than 9.9. Can our embedding and reranker models do any better?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/07/number-heading.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"jina-segmenter-api\">API Jina Segmenter</h3><p>L'API Jina Segmenter a adopt√© une approche tr√®s granulaire pour segmenter l'article, divisant sur des caract√®res comme <code>\\n</code>, <code>\\t</code>, etc., pour d√©couper le texte en segments souvent tr√®s petits. En regardant simplement les trois premiers, elle a extrait <code>search\\\\n</code>, <code>notifications\\\\n</code> et <code>NEWS\\\\n</code> de la barre de navigation du site, mais rien de pertinent au contenu de l'article lui-m√™me :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-1.png\" class=\"kg-image\" alt=\"Minimalist navigation bar with &quot;NEWS&quot;, &quot;PRODUCTS&quot;, and &quot;COMPANY&quot; text on a black background, accented by colorful stripes to \" loading=\"lazy\" width=\"1164\" height=\"68\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-1.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Plus loin, nous avons enfin obtenu quelques segments du contenu r√©el de l'article, bien que peu de contexte ait √©t√© conserv√© dans chacun :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-2.png\" class=\"kg-image\" alt=\"Webpage discussing if embedding/reranker models can compare numbers, with a grid of numbered circles and references to an ICM\" loading=\"lazy\" width=\"1164\" height=\"1180\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-2.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><p>(Par souci d'√©quit√©, nous avons montr√© plus de segments pour l'API Segmenter que pour les mod√®les, simplement parce qu'autrement elle aurait eu tr√®s peu de segments significatifs √† montrer)</p><h3 id=\"simple-qwen-05\"><code>simple-qwen-0.5</code></h3><p><code>simple-qwen-0.5</code> a d√©compos√© l'article de blog en se basant sur la structure s√©mantique, extrayant des segments beaucoup plus longs qui avaient un sens coh√©rent :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-3.png\" class=\"kg-image\" alt=\"Webpage screenshot with green background, top navigation bar, scientific graphs, and headers discussing model number comparis\" loading=\"lazy\" width=\"1164\" height=\"4590\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-3.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"topic-qwen-05\"><code>topic-qwen-0.5</code></h3><p><code>topic-qwen-0.5</code> a d'abord identifi√© les sujets bas√©s sur le contenu du document, puis segment√© le document en fonction de ces sujets :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-4.png\" class=\"kg-image\" alt=\"Webpage showcasing a scientific paper titled &quot;Can Embedding/Keras Models Compare Numbers?&quot; featuring plots, text blocks, and \" loading=\"lazy\" width=\"1164\" height=\"4526\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-4.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"summary-qwen-05\"><code>summary-qwen-0.5</code></h3><p><code>summary-qwen-0.5</code> a identifi√© les limites des segments et g√©n√©r√© un r√©sum√© du contenu au sein de chaque segment :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-5.png\" class=\"kg-image\" alt=\"Green and gold-themed academic webpage discussing embedding/reranker models and experiment setup.\" loading=\"lazy\" width=\"1164\" height=\"3734\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-5.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"benchmarking-the-models\">√âvaluation Comparative des Mod√®les</h2><p>Pour √©valuer les performances de nos mod√®les, nous avons extrait huit articles de blog du blog Jina AI et g√©n√©r√© six questions et r√©ponses de r√©f√©rence en utilisant GPT-4o.</p><p>Nous avons appliqu√© chaque m√©thode de segmentation, y compris l'API Jina Segmenter, √† ces articles de blog, puis g√©n√©r√© des embeddings pour les segments r√©sultants en utilisant <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\"><code>jina-embeddings-v3</code></a>, sans d√©coupage tardif ni reclassement.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class=\"kg-bookmark-description\">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Chaque ensemble de segments a ensuite √©t√© index√© s√©par√©ment et nous avons utilis√© un syst√®me RAG pour interroger chaque index avec les questions pr√©c√©demment g√©n√©r√©es.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Pour garantir des comparaisons √©quitables, lors des tests de <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">topic-qwen-0.5</code> et <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">summary-qwen-0.5</code>, nous avons index√© uniquement les segments eux-m√™mes, et <i>non</i> les r√©sum√©s ou sujets g√©n√©r√©s. L'indexation de ces donn√©es suppl√©mentaires aurait probablement am√©lior√© davantage les performances.</div></div><p>Pour mesurer les performances, nous avons compar√© les r√©ponses g√©n√©r√©es √† partir de l'index de chaque m√©thode de segmentation avec les r√©ponses de r√©f√©rence en utilisant les scores F1 de l'<a href=\"https://en.wikipedia.org/wiki/ROUGE_(metric)?ref=jina-ai-gmbh.ghost.io\">√©valuation ROUGE-L</a>, o√π des scores plus √©lev√©s indiquent de meilleures performances.</p><p>Par exemple, pour la question : \"Quels facteurs influencent les capacit√©s de comparaison num√©rique du mod√®le <code>jina-embeddings-v2-base-en</code> ?\", nous avons re√ßu les r√©ponses suivantes :</p><h3 id=\"ground-truth-generated-by-gpt-4o-from-the-full-post-text\">V√©rit√© terrain (G√©n√©r√©e par GPT-4o √† partir du texte complet) :</h3><pre><code>\"The two key factors are tokenization and training data. Tokenization determines how numbers are segmented into tokens, and training data influences numerical reasoning abilities.\"\n</code></pre><h3 id=\"jina-segmenter-api-score-0166667\">Jina Segmenter API (score : 0,166667)</h3><pre><code>\"The context does not provide specific factors that impact the numerical comparison abilities of the jina-embeddings-v2-base-en model.\"\n</code></pre><h3 id=\"simple-qwen-05-score-0279070\"><code>simple-qwen-0.5</code> (score : 0,279070)</h3><pre><code>\"The numerical comparison abilities of the jina-embeddings-v2-base-en model are impacted by tokenization and training data.\"\n</code></pre><h3 id=\"topic-qwen-05-score-0190476\"><code>topic-qwen-0.5</code> (score : 0,190476)</h3><pre><code>\"The numerical comparison abilities of the jina-embeddings-v2-base-en model are impacted by factors such as tokenization and its ability to handle different numerical formats, including small integers, large numbers, floats, negative numbers, currency, dates, and times.\"\n</code></pre><h3 id=\"summary-qwen-05-0318182\"><code>summary-qwen-0.5</code> (0,318182)</h3><pre><code>\"The factors impacting the numerical comparison abilities of the jina-embeddings-v2-base-en model are tokenization and training data.\"\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\"><b>Pourquoi le score de </b><b><code>topic-qwen-0.5</code></b><b> est-il si bas ?</b><br>C'est principalement d√ª au hasard bas√© sur la question particuli√®re que nous avons pos√©e au mod√®le. Comme vous pouvez le voir dans le tableau ci-dessous, le score ROUGE <i>moyen</i> de <code>topic-qwen-0.5</code> est le plus √©lev√© de toutes les m√©thodologies de segmentation.</div></div><p>Nous avons √©galement √©valu√© la vitesse de chaque m√©thode (en chronom√©trant le temps n√©cessaire pour g√©n√©rer et int√©grer les segments) et estim√© l'espace disque (en multipliant le nombre d'embeddings par la taille d'un seul embedding de 1024 dimensions de <code>jina-embeddings-v3</code>). Cela nous a permis d'√©valuer √† la fois la pr√©cision et l'efficacit√© des diff√©rentes strat√©gies de segmentation.</p><h2 id=\"key-findings\">Principales conclusions</h2><p>Apr√®s avoir test√© les variantes du mod√®le les unes contre les autres et contre l'API Jina Segmenter, nous avons constat√© que les nouveaux mod√®les montraient effectivement des scores am√©lior√©s avec les trois m√©thodes, particuli√®rement la segmentation par sujet :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-7.png\" class=\"kg-image\" alt=\"Bar chart comparing average ROUGE scores for Jina Segmenter, Simple, COATopic, and Summary Segmentation.\" loading=\"lazy\" width=\"1690\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-7.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-7.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-7.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-7.png 1690w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>M√©thode de segmentation</strong></th>\n<th><strong>Score ROUGE moyen</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina Segmenter</td>\n<td>0,352126</td>\n</tr>\n<tr>\n<td><code>simple-qwen-0.5</code></td>\n<td>0,386096</td>\n</tr>\n<tr>\n<td><code>topic-qwen-0.5</code></td>\n<td><strong>0,398340</strong></td>\n</tr>\n<tr>\n<td><code>summary-qwen-0.5</code></td>\n<td>0,328143</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Pourquoi <code>summary-qwen-0.5</code> a-t-il un score ROUGE inf√©rieur √† <code>topic-qwen-0.5</code> ? En bref, <code>summary-qwen-0.5</code> a montr√© une perte plus √©lev√©e pendant l'entra√Ænement, r√©v√©lant le besoin de plus d'entra√Ænement pour obtenir de meilleurs r√©sultats. Cela pourrait faire l'objet d'exp√©rimentations futures.</div></div><p>Cependant, il serait int√©ressant d'examiner les r√©sultats avec la fonction de chunking tardif de <code>jina-embeddings-v3</code>, qui augmente la pertinence contextuelle des embeddings de segments, fournissant des r√©sultats plus pertinents. Cela pourrait faire l'objet d'un futur article de blog.</p><p>Concernant la vitesse, il peut √™tre difficile de comparer les nouveaux mod√®les √† Jina Segmenter, puisque ce dernier est une API, tandis que nous avons ex√©cut√© les trois mod√®les sur un GPU Nvidia 3090. Comme vous pouvez le voir, tout gain de performance pendant l'√©tape rapide de segmentation de l'API Segmenter est rapidement d√©pass√© par le besoin de g√©n√©rer des embeddings pour autant de segments :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-8.png\" class=\"kg-image\" alt=\"Bar chart showing time for text segmentation methods: Jina Segmenter, Simple, CoT Topic, and Summary Segmentation, with notab\" loading=\"lazy\" width=\"1682\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-8.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-8.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-8.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-8.png 1682w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-9.png\" class=\"kg-image\" alt=\"Vertical bar chart displaying the embedding times for Jina Segmenter, Simple, CoT Topic, and Summary Segmentation.\" loading=\"lazy\" width=\"1698\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-9.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-9.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-9.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-9.png 1698w\" sizes=\"(min-width: 720px) 720px\"></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\"><b>Notes</b><br>‚Ä¢ Nous utilisons diff√©rents axes Y sur les deux graphiques car il n'√©tait pas possible de pr√©senter des √©chelles de temps si diff√©rentes avec un seul graphique ou des axes Y coh√©rents.<br>‚Ä¢ Comme nous r√©alisions cela uniquement comme une exp√©rience, nous n'avons pas utilis√© le traitement par lots lors de la g√©n√©ration des embeddings. Le faire acc√©l√©rerait consid√©rablement les op√©rations pour toutes les m√©thodes.</div></div><p>Naturellement, plus de segments signifie plus d'embeddings. Et ces embeddings prennent beaucoup d'espace : les embeddings pour les huit articles de blog que nous avons test√©s ont pris plus de 21 Mo avec l'API Segmenter, tandis que la segmentation par r√©sum√© n'en prenait que 468 Ko. Cela, plus les scores ROUGE plus √©lev√©s de nos mod√®les, signifie moins de segments mais de meilleurs segments, √©conomisant de l'argent et augmentant les performances :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-6.png\" class=\"kg-image\" alt=\"Diagramme √† barres verticales comparant la taille totale des embeddings des m√©thodes de segmentation, avec &quot;Jina Segmenter&quot; significativement plus √©lev√© √† 20.0\" loading=\"lazy\" width=\"1690\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-6.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-6.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-6.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-6.png 1690w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>Segmentation Method</strong></th>\n<th><strong>Segment Count</strong></th>\n<th><strong>Average Length (characters)</strong></th>\n<th><strong>Segmentation Time (minutes/seconds)</strong></th>\n<th><strong>Embedding Time (hours/minutes)</strong></th>\n<th><strong>Total Embedding Size</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina Segmenter</td>\n<td>1,755</td>\n<td>82</td>\n<td>3.8s</td>\n<td>1h 46m</td>\n<td>21.06 MB</td>\n</tr>\n<tr>\n<td><code>simple-qwen-0.5</code></td>\n<td>48</td>\n<td>1,692</td>\n<td>49s</td>\n<td>1h 2m</td>\n<td>576 KB</td>\n</tr>\n<tr>\n<td><code>topic-qwen-0.5</code></td>\n<td>69</td>\n<td>1,273</td>\n<td>2m 3s</td>\n<td>1h 6m</td>\n<td>828 KB</td>\n</tr>\n<tr>\n<td><code>summary-qwen-0.5</code></td>\n<td>39</td>\n<td>1,799</td>\n<td>2m 40s</td>\n<td>53m</td>\n<td>468 KB</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"what-we-learned\">Ce que nous avons appris</h3><h3 id=\"problem-formulation-is-critical\">La formulation du probl√®me est cruciale</h3><p>Une d√©couverte cl√© a √©t√© l'impact de notre fa√ßon de cadrer la t√¢che. En faisant g√©n√©rer les en-t√™tes de segments par le mod√®le, nous avons am√©lior√© la d√©tection des limites et la coh√©rence en nous concentrant sur les transitions s√©mantiques plut√¥t que de simplement copier-coller le contenu d'entr√©e en segments distincts. Cela a √©galement permis d'obtenir un mod√®le de segmentation plus rapide, car la g√©n√©ration de moins de texte a permis au mod√®le de terminer la t√¢che plus rapidement.</p><h3 id=\"llm-generated-data-is-effective\">Les donn√©es g√©n√©r√©es par LLM sont efficaces</h3><p>L'utilisation de donn√©es g√©n√©r√©es par LLM, en particulier pour du contenu complexe comme les listes, les formules et les extraits de code, a √©largi l'ensemble d'entra√Ænement du mod√®le et am√©lior√© sa capacit√© √† g√©rer diverses structures de documents. Cela a rendu le mod√®le plus adaptable √† diff√©rents types de contenu, un avantage crucial lors du traitement de documents techniques ou structur√©s.</p><h3 id=\"output-only-data-collation\">Collationnement des donn√©es de sortie uniquement</h3><p>En utilisant un <a href=\"https://huggingface.co/docs/transformers/en/main_classes/data_collator?ref=jina-ai-gmbh.ghost.io\">collateur de donn√©es</a> de sortie uniquement, nous avons veill√© √† ce que le mod√®le se concentre sur la pr√©diction des tokens cibles pendant l'entra√Ænement, plut√¥t que de simplement copier depuis l'entr√©e. Le collateur de sortie uniquement a permis au mod√®le d'apprendre √† partir des s√©quences cibles r√©elles, en mettant l'accent sur les compl√©tions ou les limites correctes. Cette distinction a permis au mod√®le de converger plus rapidement en √©vitant le surajustement √† l'entr√©e et l'a aid√© √† mieux g√©n√©raliser sur diff√©rents jeux de donn√©es.</p><h3 id=\"efficient-training-with-unsloth\">Entra√Ænement efficace avec Unsloth</h3><p>Avec <a href=\"https://github.com/unslothai/unsloth?ref=jina-ai-gmbh.ghost.io\">Unsloth</a>, nous avons rationalis√© l'entra√Ænement de notre petit mod√®le de langage, r√©ussissant √† l'ex√©cuter sur un GPU Nvidia 4090. Ce pipeline optimis√© nous a permis d'entra√Æner un mod√®le efficace et performant sans avoir besoin de ressources de calcul massives.</p><h3 id=\"handling-complex-texts\">Gestion des textes complexes</h3><p>Les mod√®les de segmentation ont excell√© dans le traitement de documents complexes contenant du code, des tableaux et des listes, qui sont g√©n√©ralement difficiles √† g√©rer avec des m√©thodes plus traditionnelles. Pour le contenu technique, des strat√©gies sophistiqu√©es comme <code>topic-qwen-0.5</code> et <code>summary-qwen-0.5</code> se sont r√©v√©l√©es plus efficaces, avec le potentiel d'am√©liorer les t√¢ches RAG en aval.</p><h3 id=\"simple-methods-for-simpler-content\">M√©thodes simples pour du contenu plus simple</h3><p>Pour du contenu simple ax√© sur la narration, des m√©thodes plus basiques comme l'API Segmenter sont souvent suffisantes. Les strat√©gies de segmentation avanc√©es peuvent n'√™tre n√©cessaires que pour du contenu plus complexe et structur√©, permettant une flexibilit√© selon le cas d'utilisation.</p><h2 id=\"next-steps\">Prochaines √©tapes</h2><p>Bien que cette exp√©rience ait √©t√© con√ßue principalement comme une preuve de concept, si nous devions la poursuivre, nous pourrions apporter plusieurs am√©liorations. Premi√®rement, bien que la poursuite de cette exp√©rience sp√©cifique soit peu probable, l'entra√Ænement de <code>summary-qwen-0.5</code> sur un jeu de donn√©es plus important ‚Äî id√©alement 60 000 √©chantillons au lieu de 30 000 ‚Äî conduirait probablement √† des performances plus optimales. De plus, affiner notre processus d'√©valuation serait b√©n√©fique. Au lieu d'√©valuer les r√©ponses g√©n√©r√©es par le LLM du syst√®me RAG, nous nous concentrerions plut√¥t sur la comparaison directe des segments r√©cup√©r√©s avec la v√©rit√© terrain. Enfin, nous irions au-del√† des scores ROUGE et adopterions des m√©triques plus avanc√©es (possiblement une combinaison de ROUGE et de scoring LLM) qui captent mieux les nuances de la qualit√© de la r√©cup√©ration et de la segmentation.</p><h2 id=\"conclusion\">Conclusion</h2><p>Dans cette exp√©rience, nous avons explor√© comment des mod√®les de segmentation personnalis√©s con√ßus pour des t√¢ches sp√©cifiques peuvent am√©liorer les performances du RAG. En d√©veloppant et en entra√Ænant des mod√®les comme <code>simple-qwen-0.5</code>, <code>topic-qwen-0.5</code>, et <code>summary-qwen-0.5</code>, nous avons abord√© les d√©fis cl√©s rencontr√©s dans les m√©thodes de segmentation traditionnelles, particuli√®rement en maintenant la coh√©rence s√©mantique et en g√©rant efficacement le contenu complexe comme les extraits de code. Parmi les mod√®les test√©s, <code>topic-qwen-0.5</code> a constamment fourni la segmentation la plus significative et contextuellement pertinente, en particulier pour les documents multi-th√©matiques.</p><p>Bien que les mod√®les de segmentation fournissent la base structurelle n√©cessaire aux syst√®mes RAG, ils servent une fonction diff√©rente par rapport au d√©coupage tardif, qui optimise les performances de r√©cup√©ration en maintenant la pertinence contextuelle entre les segments. Ces deux approches peuvent √™tre compl√©mentaires, mais la segmentation est particuli√®rement cruciale lorsque vous avez besoin d'une m√©thode qui se concentre sur la division des documents pour des flux de travail de g√©n√©ration coh√©rents et sp√©cifiques √† la t√¢che.</p>",
  "comment_id": "67126986708dbe00019249f2",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/breakpoints.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-18T15:58:30.000+02:00",
  "updated_at": "2024-10-25T20:14:53.000+02:00",
  "published_at": "2024-10-25T10:35:07.000+02:00",
  "custom_excerpt": "We trained three small language models to better segment long documents into chunks, and here are the key lessons we learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ade4a3e4e55003d525971",
      "name": "Alex C-G",
      "slug": "alexcg",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
      "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
      "website": null,
      "location": "Berlin, Germany",
      "facebook": null,
      "twitter": "@alexcg",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    },
    {
      "id": "64ae64a4733bc60001949ca4",
      "name": "Andrei Ungureanu",
      "slug": "andrei",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/07/Me.jpg",
      "cover_image": null,
      "bio": "Software / AI Engineer, with a passion for content creation.",
      "website": null,
      "location": "Beijing, China",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/andrei/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ade4a3e4e55003d525971",
    "name": "Alex C-G",
    "slug": "alexcg",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
    "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
    "website": null,
    "location": "Berlin, Germany",
    "facebook": null,
    "twitter": "@alexcg",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/finding-optimal-breakpoints-in-long-documents-using-small-language-models/",
  "excerpt": "Nous avons entra√Æn√© trois petits mod√®les de langage pour mieux segmenter les longs documents en fragments, et voici les le√ßons essentielles que nous avons apprises.",
  "reading_time": 19,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "A pattern of yellow file icons on a blue background with one icon displaying a smiley face creating an emotive contrast.",
  "feature_image_caption": null
}