{
  "slug": "jina-classifier-for-high-performance-zero-shot-and-few-shot-classification",
  "id": "6711fbbd708dbe0001924974",
  "uuid": "65c883e0-556a-4079-b07a-66e9e9926717",
  "title": "API de classification Jina pour la classification zéro-shot et few-shot haute performance",
  "html": "<p>La classification est une tâche en aval courante pour les embeddings. Les embeddings de texte peuvent catégoriser le texte en étiquettes prédéfinies pour la détection de spam ou l'analyse de sentiment. Les embeddings multimodaux comme <code>jina-clip-v1</code> peuvent être appliqués au filtrage basé sur le contenu ou à l'annotation de tags. Récemment, la classification a également trouvé une utilité dans le routage des requêtes vers les LLM appropriés en fonction de leur complexité et de leur coût, par exemple les requêtes arithmétiques simples peuvent être dirigées vers un petit modèle de langage. Les tâches de raisonnement complexe pourraient être dirigées vers des LLM plus puissants mais plus coûteux.</p><p>Aujourd'hui, nous présentons la nouvelle <strong>API Classifier</strong> de Jina AI's Search Foundation. Supportant la classification <strong>zero-shot</strong> et <strong>few-shot</strong> en ligne, elle est construite sur nos derniers modèles d'embedding comme <code>jina-embeddings-v3</code> et <code>jina-clip-v1</code>. L'API Classifier s'appuie sur <a href=\"https://jmlr.org/papers/v7/crammer06a.html?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">l'apprentissage passif-agressif en ligne</a>, lui permettant de s'adapter aux nouvelles données en temps réel. Les utilisateurs peuvent commencer avec un classificateur zero-shot et l'utiliser immédiatement. Ils peuvent ensuite mettre à jour progressivement le classificateur en soumettant de nouveaux exemples ou lorsqu'une dérive conceptuelle se produit. Cela permet une classification efficace et évolutive à travers divers types de contenu <em>sans</em> données étiquetées initiales importantes. Les utilisateurs peuvent également publier leurs classificateurs pour un usage public. Lorsque nos nouveaux embeddings sont publiés, comme le prochain <code>jina-clip-v2</code> multilingue, les utilisateurs peuvent y accéder immédiatement via l'API Classifier, garantissant des capacités de classification à jour.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/classifier?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Classifier API</div><div class=\"kg-bookmark-description\">High performance classifier for image and text classification.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-classifier.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"zero-shot-classification\">Classification Zero-Shot</h2><p>L'API Classifier offre de puissantes capacités de classification zero-shot, vous permettant de catégoriser du texte ou des images sans pré-entraînement sur des données étiquetées. Chaque classificateur commence avec des capacités zero-shot, qui peuvent ensuite être améliorées avec des données d'entraînement supplémentaires ou des mises à jour - un sujet que nous explorerons dans la section suivante.</p><h3 id=\"example-1-route-llm-requests\">Exemple 1 : Routage des requêtes LLM</h3><p>Voici un exemple utilisant l'API classifier pour le routage des requêtes LLM :</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-embeddings-v3\",\n    \"labels\": [\n      \"Simple task\",\n      \"Complex reasoning\",\n      \"Creative writing\"\n    ],\n    \"input\": [\n      \"Calculate the compound interest on a principal of $10,000 invested for 5 years at an annual rate of 5%, compounded quarterly.\",\n      \"分析使用CRISPR基因编辑技术在人类胚胎中的伦理影响。考虑潜在的医疗益处和长期社会后果。\",\n      \"AIが自意識を持つディストピアの未来を舞台にした短編小説を書いてください。人間とAIの関係や意識の本質をテーマに探求してください。\",\n      \"Erklären Sie die Unterschiede zwischen Merge-Sort und Quicksort-Algorithmen in Bezug auf Zeitkomplexität, Platzkomplexität und Leistung in der Praxis.\",\n      \"Write a poem about the beauty of nature and its healing power on the human soul.\",\n      \"Translate the following sentence into French: The quick brown fox jumps over the lazy dog.\"\n    ]\n  }'</code></pre><p>Cet exemple démontre l'utilisation de <code>jina-embeddings-v3</code> pour router les requêtes utilisateur en plusieurs langues (anglais, chinois, japonais et allemand) en trois catégories, qui correspondent à trois tailles différentes de LLM. Le format de réponse de l'API est le suivant :</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 256, \"prompt_tokens\": 256},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Simple task\", \"score\": 0.35216382145881653},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Complex reasoning\", \"score\": 0.34310275316238403},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Creative writing\", \"score\": 0.3487184941768646},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Complex reasoning\", \"score\": 0.35207709670066833},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Creative writing\", \"score\": 0.3638903796672821},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Simple task\", \"score\": 0.3561534285545349}\n  ]\n}</code></pre><p>La réponse inclut :</p><ul><li><code>usage</code> : Informations sur l'utilisation des tokens.</li><li><code>data</code> : Un tableau de résultats de classification, un pour chaque entrée.<ul><li>Chaque résultat contient l'étiquette prédite (<code>prediction</code>) et un score de confiance (<code>score</code>). Le <code>score</code> pour chaque classe est calculé via la normalisation softmax - pour le zero-shot, il est basé sur les similarités cosinus entre les embeddings d'entrée et d'étiquette <a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model?ref=jina-ai-gmbh.ghost.io#parameter-task\" rel=\"noreferrer\">sous le task-LoRA <code>classification</code></a> ; tandis que pour le few-shot, il est basé sur les transformations linéaires apprises de l'embedding d'entrée pour chaque classe - résultant en des probabilités qui somment à 1 sur toutes les classes.</li><li>L'<code>index</code> correspond à la position de l'entrée dans la requête originale.</li></ul></li></ul><h3 id=\"example-2-categorize-image-text\">Exemple 2 : Catégorisation d'Images et de Textes</h3><p>Explorons un exemple multimodal utilisant <code>jina-clip-v1</code>. Ce modèle peut classifier à la fois du texte et des images, ce qui le rend idéal pour la catégorisation de contenu à travers différents types de médias. Considérons l'appel API suivant :</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-clip-v1\",\n    \"labels\": [\n      \"Food and Dining\",\n      \"Technology and Gadgets\",\n      \"Nature and Outdoors\",\n      \"Urban and Architecture\"\n    ],\n    \"input\": [\n      {\"text\": \"A sleek smartphone with a high-resolution display and multiple camera lenses\"},\n      {\"text\": \"Fresh sushi rolls served on a wooden board with wasabi and ginger\"},\n      {\"image\": \"https://picsum.photos/id/11/367/267\"},\n      {\"image\": \"https://picsum.photos/id/22/367/267\"},\n      {\"text\": \"Vibrant autumn leaves in a dense forest with sunlight filtering through\"},\n      {\"image\": \"https://picsum.photos/id/8/367/267\"}\n    ]\n  }'</code></pre><p>Notez comment nous téléchargeons des images dans la requête, vous pouvez également utiliser une chaîne <code>base64</code> pour représenter une image. L'API renvoie les résultats de classification suivants :</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 12125, \"prompt_tokens\": 12125},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Technology and Gadgets\", \"score\": 0.30329811573028564},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Food and Dining\", \"score\": 0.2765541970729828},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Nature and Outdoors\", \"score\": 0.29503118991851807},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Urban and Architecture\", \"score\": 0.2648046910762787},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Nature and Outdoors\", \"score\": 0.3133063316345215},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Technology and Gadgets\", \"score\": 0.27474141120910645}\n  ]\n}</code></pre><h3 id=\"example-3-detect-if-jina-reader-gets-genuine-content\">Exemple 3 : Détecter si Jina Reader obtient du contenu authentique</h3><p>Une application intéressante de la classification zero-shot est la détermination de l'accessibilité des sites web via <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>. Bien que cela puisse sembler une tâche simple, c'est étonnamment complexe en pratique. Les messages de blocage varient largement d'un site à l'autre, apparaissant dans différentes langues et citant diverses raisons (paywalls, limites de taux, pannes de serveur). Cette diversité rend difficile de s'appuyer sur des regex ou des règles fixes pour capturer tous les scénarios.</p><pre><code class=\"language-python\">import requests\nimport json\n\nresponse1 = requests.get('https://r.jina.ai/https://jina.ai')\n\nurl = 'https://api.jina.ai/v1/classify'\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer $YOUR_API_KEY_HERE'\n}\ndata = {\n    'model': 'jina-embeddings-v3',\n    'labels': ['Blocked', 'Accessible'],\n    'input': [{'text': response1.text[:8000]}]\n}\nresponse2 = requests.post(url, headers=headers, data=json.dumps(data))\n\nprint(response2.text)</code></pre><p>Le script récupère le contenu via <code>r.jina.ai</code> et le classe comme <code>\"Blocked\"</code> ou <code>\"Accessible\"</code> en utilisant l'API Classifier. Par exemple, <a href=\"https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai</a> serait probablement <code>\"Blocked\"</code> en raison des restrictions d'accès, tandis que <a href=\"https://r.jina.ai/https://jina.ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://jina.ai</a> devrait être \"Accessible\".</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\"usage\":{\"total_tokens\":185,\"prompt_tokens\":185},\"data\":[{\"object\":\"classification\",\"index\":0,\"prediction\":\"Blocked\",\"score\":0.5392698049545288}]}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">L'API Classifier peut efficacement distinguer entre le contenu authentique et les résultats bloqués de Jina Reader.</span></p></figcaption></figure><p>Cet exemple utilise <code>jina-embeddings-v3</code> et offre un moyen rapide et automatisé de surveiller l'accessibilité des sites web, utile pour les systèmes d'agrégation de contenu ou de web scraping, particulièrement dans des contextes multilingues.</p><h3 id=\"example-4-filtering-statements-from-opinions-for-grounding\">Exemple 4 : Filtrage des déclarations et des opinions pour le grounding</h3><p>Une autre application intrigante de la classification zéro-shot est le filtrage des affirmations de type factuel par rapport aux opinions dans les longs documents. Notez que le classificateur ne peut pas déterminer si quelque chose est factuellement vrai. Au lieu de cela, il identifie le texte qui est <em>écrit dans le style d'une affirmation factuelle</em>, qui peut ensuite être vérifié via une API de grounding, souvent très coûteuse. Ce processus en deux étapes est essentiel pour une vérification des faits efficace : d'abord filtrer toutes les opinions et sentiments, puis envoyer les affirmations restantes pour vérification.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/fact-checking-with-new-grounding-api-in-jina-reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Fact-Checking with New Grounding API in Jina Reader</div><div class=\"kg-bookmark-description\">With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Considérez ce paragraphe sur la Course à l'Espace des années 1960 :</p><pre><code class=\"language-json\">The Space Race of the 1960s was a breathtaking testament to human ingenuity. When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era. The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance. NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973. While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent. On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars. The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination. The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle.\n</code></pre><p>Ce texte mélange intentionnellement différents types d'écriture - des affirmations de type factuel (comme \"Sputnik 1 a été lancé le 4 octobre 1959\"), des opinions claires (\"témoignage époustouflant\"), un langage émotionnel (\"a semé la peur dans les cœurs\"), et des affirmations interprétatives (\"marquant le début indéniable d'une nouvelle ère\").</p><p>Le rôle du classificateur zéro-shot <strong>est purement sémantique</strong> - il identifie si un texte est écrit comme une affirmation ou comme une opinion/interprétation. Par exemple, <code>\"The Soviet Union launched Sputnik 1 on October 4, 1959\"</code> est écrit comme une affirmation, tandis que <code>\"The Space Race was a breathtaking testament\"</code> est clairement écrit comme une opinion.</p><pre><code class=\"language-python\">headers = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {API_KEY}'\n}\n\n# Step 1: Split text and classify\nchunks = [chunk.strip() for chunk in text.split('.') if chunk.strip()]\nlabels = [\n    \"subjective, opinion, feeling, personal experience, creative writing, position\",\n    \"fact\"\n]\n\n# Classify chunks\nclassify_response = requests.post(\n    'https://api.jina.ai/v1/classify',\n    headers=headers,\n    json={\n        \"model\": \"jina-embeddings-v3\",\n        \"input\": [{\"text\": chunk} for chunk in chunks],\n        \"labels\": labels\n    }\n)\n\n# Sort chunks\nsubjective_chunks = []\nfactual_chunks = []\nfor chunk, classification in zip(chunks, classify_response.json()['data']):\n    if classification['prediction'] == labels[0]:\n        subjective_chunks.append(chunk)\n    else:\n        factual_chunks.append(chunk)\n\nprint(\"\\nSubjective statements:\", subjective_chunks)\nprint(\"\\nFactual statements:\", factual_chunks)</code></pre><p>Et vous obtiendrez :</p><pre><code class=\"language-json\">Subjective statements: ['The Space Race of the 1960s was a breathtaking testament to human ingenuity', 'The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance', 'While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent', \"The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination\"]\n\nFactual statements: ['When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era', \"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\", \"On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars\", 'The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle']</code></pre><p>Rappelez-vous, ce n'est pas parce que quelque chose est écrit comme une affirmation que c'est vrai. C'est pourquoi nous avons besoin de la deuxième étape - alimenter ces affirmations de type factuel dans une API de grounding pour une vérification factuelle réelle. Par exemple, vérifions cette affirmation : <code>\"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\"</code> avec le code ci-dessous.</p><pre><code class=\"language-python\">ground_headers = {\n        'Accept': 'application/json',\n        'Authorization': f'Bearer {API_KEY}'\n    }\n\nground_response = requests.get(\n    f'https://g.jina.ai/{quote(factual_chunks[1])}',\n    headers=ground_headers\n)\n\nprint(ground_response.json())</code></pre><p>qui vous donne :</p><pre><code class=\"language-json\">{'code': 200, 'status': 20000, 'data': {'factuality': 1, 'result': True, 'reason': \"The statement is supported by multiple references confirming NASA's founding in 1958 and the significant financial investment in the Apollo program. The $28 billion figure aligns with the data provided in the references, which detail NASA's expenditures during the Apollo program from 1960 to 1973. Additionally, the context of NASA's budget peaking during this period further substantiates the claim. Therefore, the statement is factually correct based on the available evidence.\", 'references': [{'url': 'https://en.wikipedia.org/wiki/Budget_of_NASA', 'keyQuote': \"NASA's budget peaked in 1964–66 when it consumed roughly 4% of all federal spending. The agency was building up to the first Moon landing and the Apollo program was a top national priority, consuming more than half of NASA's budget.\", 'isSupportive': True}, {'url': 'https://en.wikipedia.org/wiki/NASA', 'keyQuote': 'Established in 1958, it succeeded the National Advisory Committee for Aeronautics (NACA)', 'isSupportive': True}, {'url': 'https://nssdc.gsfc.nasa.gov/planetary/lunar/apollo.html', 'keyQuote': 'More details on Apollo lunar landings', 'isSupportive': True}, {'url': 'https://usafacts.org/articles/50-years-after-apollo-11-moon-landing-heres-look-nasas-budget-throughout-its-history/', 'keyQuote': 'NASA has spent its money so far.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/history/', 'keyQuote': 'Discover the history of our human spaceflight, science, technology, and aeronautics programs.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/the-apollo-program/', 'keyQuote': 'Commander for Apollo 11, first to step on the lunar surface.', 'isSupportive': True}, {'url': 'https://www.planetary.org/space-policy/cost-of-apollo', 'keyQuote': 'A rich data set tracking the costs of Project Apollo, free for public use. Includes unprecedented program-by-program cost breakdowns.', 'isSupportive': True}, {'url': 'https://www.statista.com/statistics/1342862/nasa-budget-project-apollo-costs/', 'keyQuote': 'NASA&amp;#x27;s monetary obligations compared to Project Apollo&amp;#x27;s total costs from 1960 to 1973 (in million U.S. dollars)', 'isSupportive': True}], 'usage': {'tokens': 10640}}}</code></pre><p>Avec un score de factualité de 1, l'API de grounding confirme que cette affirmation est bien fondée historiquement. Cette approche ouvre des possibilités fascinantes, de l'analyse de documents historiques à la vérification des faits dans les articles d'actualité en temps réel. En combinant la classification zéro-shot avec la vérification des faits, nous créons un pipeline puissant pour l'analyse automatisée de l'information - d'abord en filtrant les opinions, puis en vérifiant les affirmations restantes auprès de sources fiables.</p><h3 id=\"remarks-on-zero-shot-classification\">Remarques sur la Classification Zéro-Shot</h3><h4 id=\"using-semantic-labels\">Utilisation des Étiquettes Sémantiques</h4><p>Lorsque vous travaillez avec la classification zéro-shot, <strong>il est crucial d'utiliser des étiquettes sémantiquement significatives plutôt que des symboles abstraits ou des nombres.</strong> Par exemple, <code>\"Technology\"</code>, <code>\"Nature\"</code>, et <code>\"Food\"</code> sont beaucoup plus efficaces que <code>\"Class1\"</code>, <code>\"Class2\"</code>, <code>\"Class3\"</code> ou <code>\"0\"</code>, <code>\"1\"</code>, <code>\"2\"</code>. <code>\"Positive sentiment\"</code> est plus efficace que <code>\"Positive\"</code> et <code>\"True\"</code>. Les modèles d'embedding comprennent les relations sémantiques, donc des étiquettes descriptives permettent au modèle d'exploiter ses connaissances pré-entraînées pour des classifications plus précises. Notre article précédent explore comment créer des étiquettes sémantiques efficaces pour de meilleurs résultats de classification.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/rephrased-labels-improve-zero-shot-text-classification-30?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Rephrased Labels Improve Zero-Shot Text Classification by 30%</div><div class=\"kg-bookmark-description\">When using embedding models for zero-shot classification, rephrasing the class label to \"This is seriously about 'LABEL'\" gives higher accuracy vs. using LABEL alone. But how, and why?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/07/Heading.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"stateless-nature\">Nature Sans État</h4><p>La classification zéro-shot est fondamentalement sans état, contrairement aux approches traditionnelles d'apprentissage automatique. <strong>Cela signifie que pour une même entrée et un même modèle, les résultats seront toujours cohérents, peu importe qui utilise l'API ou quand.</strong> Le modèle n'apprend pas et ne se met pas à jour en fonction des classifications qu'il effectue ; chaque tâche est indépendante. Cela permet une utilisation immédiate sans configuration ni entraînement, et offre la flexibilité de changer de catégories entre les appels API.</p><p>Cette nature sans état contraste fortement avec les approches d'apprentissage few-shot et en ligne, que nous explorerons ensuite. Dans ces méthodes, les modèles peuvent s'adapter à de nouveaux exemples, donnant potentiellement des résultats différents au fil du temps ou entre les utilisateurs.</p><h2 id=\"few-shot-classification\">Classification Few-Shot</h2><p>La classification few-shot offre une approche facile pour créer et mettre à jour des classificateurs avec un minimum de données étiquetées. Cette méthode fournit deux points d'accès principaux : <code>train</code> et <code>classify</code>.</p><p>Le point d'accès <code>train</code> vous permet de créer ou de mettre à jour un classificateur avec un petit ensemble d'exemples. Votre premier appel à <code>train</code> retournera un</p><code>classifier_id</code>, que vous pouvez utiliser pour les entraînements ultérieurs lorsque vous avez de nouvelles données, constatez des changements dans la distribution des données ou devez ajouter de nouvelles classes. Cette approche flexible permet à votre classifieur d'évoluer au fil du temps, s'adaptant à de nouveaux modèles et catégories sans repartir de zéro.</p><p>Comme pour la classification zero-shot, vous utiliserez le point de terminaison <code>classify</code> pour faire des prédictions. La principale différence est que vous devrez inclure votre <code>classifier_id</code> dans la requête, mais vous n'aurez pas besoin de fournir des labels candidats puisqu'ils font déjà partie de votre modèle entraîné.</p><h3 id=\"example-train-a-support-ticket-assigner\">Exemple : Entraîner un Assignateur de Tickets de Support</h3><p>Explorons ces fonctionnalités à travers un exemple de classification des tickets de support client pour l'attribution à différentes équipes dans une startup technologique en pleine croissance.</p><h4 id=\"initial-training\">Entraînement initial</h4><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"model\": \"jina-embeddings-v3\",\n  \"access\": \"private\",\n  \"input\": [\n    {\n      \"text\": \"I cant log into my account after the latest app update.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"My subscription renewal failed due to an expired credit card.\",\n      \"label\": \"team2\"\n    },\n    {\n      \"text\": \"How do I export my data from the platform?\",\n      \"label\": \"team3\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><p>Notez que dans l'apprentissage few-shot, nous sommes libres d'utiliser <code>team1</code> <code>team2</code> comme labels de classe même s'ils n'ont pas de signification sémantique intrinsèque. Dans la réponse, vous obtiendrez un <code>classifier_id</code> qui représente ce nouveau classifieur.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"classifier_id\": \"918c0846-d6ae-4f34-810d-c0c7a59aee14\",\n  \"num_samples\": 3,\n}\n</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Notez bien le </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>classifier_id</span></code><span style=\"white-space: pre-wrap;\">, vous en aurez besoin pour faire référence à ce classifieur plus tard.</span></p></figcaption></figure><h4 id=\"updating-classifier-to-adapt-team-restructuring\">Mise à jour du Classifieur pour Adapter la Restructuration d'Équipe</h4><p>À mesure que l'entreprise exemple grandit, de nouveaux types de problèmes émergent et la structure de l'équipe change également. La beauté de la classification few-shot réside dans sa capacité à s'adapter rapidement à ces changements. Nous pouvons facilement mettre à jour le classifieur en donnant le <code>classifier_id</code> et de nouveaux exemples, introduisant de nouvelles catégories d'équipes (par exemple <code>team4</code>) ou réaffectant les types de problèmes existants à différentes équipes au fur et à mesure que l'organisation évolue. </p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"Im getting a 404 error when trying to access the new AI chatbot feature.\",\n      \"label\": \"team4\"\n    },\n    {\n      \"text\": \"The latest security patch is conflicting with my company firewall.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"I need help setting up SSO for my organization account.\",\n      \"label\": \"team5\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><h4 id=\"using-a-trained-classifier\">Utilisation d'un Classifieur Entraîné</h4><p>Pendant l'inférence, vous n'avez besoin que de fournir le texte d'entrée et le <code>classifier_id</code>. L'API gère la correspondance entre votre entrée et les classes précédemment entraînées, renvoyant le label le plus approprié basé sur l'état actuel du classifieur.</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/classify' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"The new feature is causing my dashboard to load slowly.\"\n    },\n    {\n      \"text\": \"I need to update my billing information for tax purposes.\"\n    }\n  ]\n}'</code></pre><p>Le mode few-shot a deux paramètres uniques.</p><h3 id=\"parameter-numiters\">Paramètre <code>num_iters</code></h3><p>Le paramètre <code>num_iters</code> ajuste l'intensité avec laquelle le classifieur apprend de vos exemples d'entraînement. Bien que la valeur par défaut de 10 fonctionne bien dans la plupart des cas, vous pouvez ajuster stratégiquement cette valeur en fonction de <strong>votre confiance dans les données d'entraînement</strong>. Pour des exemples de haute qualité qui sont cruciaux pour la classification, augmentez <code>num_iters</code> pour renforcer leur importance. À l'inverse, pour des exemples moins fiables, diminuez <code>num_iters</code> pour minimiser leur impact sur les performances du classifieur. Ce paramètre peut également être utilisé pour implémenter un apprentissage tenant compte du temps, où les exemples plus récents obtiennent des nombres d'itérations plus élevés pour s'adapter aux modèles évolutifs tout en maintenant les connaissances historiques.</p><h3 id=\"parameter-access\">Paramètre <code>access</code></h3><p>Le paramètre <code>access</code> vous permet de contrôler qui peut utiliser votre classifieur. Par défaut, les classifieurs sont privés et uniquement accessibles à vous. Le réglage de l'accès sur \"public\" permet à quiconque possédant votre <code>classifier_id</code> de <strong>l'utiliser avec sa propre clé API et son quota de jetons.</strong> Cela permet le partage des classifieurs tout en maintenant la confidentialité - les utilisateurs ne peuvent pas voir vos données d'entraînement ou votre configuration, et vous ne pouvez pas voir leurs requêtes de classification. Ce paramètre n'est pertinent que pour la classification few-shot, car les classifieurs zero-shot sont sans état. Il n'est pas nécessaire de partager les classifieurs zero-shot puisque des requêtes identiques donneront toujours les mêmes réponses, quel que soit leur auteur.</p><h3 id=\"remarks-on-few-shot-learning\">Remarques sur l'Apprentissage Few-Shot</h3><p>La classification few-shot dans notre API présente certaines caractéristiques uniques à noter. Contrairement aux modèles d'apprentissage automatique traditionnels, notre implémentation utilise un apprentissage en ligne en une passe - les exemples d'entraînement sont traités pour mettre à jour les poids du classifieur mais ne sont pas stockés par la suite. Cela signifie que vous ne pouvez pas récupérer les données d'entraînement historiques, mais cela garantit une meilleure confidentialité et efficacité des ressources.</p><p>Bien que l'apprentissage few-shot soit puissant, il nécessite une période de mise en route pour surpasser la classification zero-shot. Nos tests de référence montrent que 200-400 exemples d'entraînement fournissent généralement assez de données pour voir des performances supérieures. Cependant, vous n'avez pas besoin de fournir des exemples pour toutes les classes dès le départ - le classifieur peut évoluer pour accueillir de nouvelles classes au fil du temps. Sachez simplement que les classes nouvellement ajoutées peuvent connaître une brève période de démarrage à froid ou un déséquilibre de classes jusqu'à ce que suffisamment d'exemples soient fournis.</p><h2 id=\"benchmark\">Benchmark</h2><p>Pour notre analyse comparative, nous avons évalué les approches zero-shot et few-shot sur divers jeux de données, incluant des tâches de classification de texte comme la détection d'émotions (6 classes) et la détection de spam (2 classes), ainsi que des tâches de classification d'images comme CIFAR10 (10 classes). Le cadre d'évaluation a utilisé des divisions standard train-test, le zero-shot ne nécessitant aucune donnée d'entraînement et le few-shot utilisant des portions de l'ensemble d'entraînement. Nous avons suivi des métriques clés comme la taille d'entraînement et le nombre de classes cibles, permettant des comparaisons contrôlées. Pour assurer la robustesse, particulièrement pour l'apprentissage few-shot, chaque entrée est passée par plusieurs itérations d'entraînement. Nous avons comparé ces approches modernes avec des références traditionnelles comme le SVM Linéaire et le SVM RBF pour donner un contexte à leurs performances.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Multi-class-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Image-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Text-classification--1-.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Les scores F1 sont représentés. Pour les paramètres complets du benchmark, veuillez consulter </span><a href=\"https://docs.google.com/spreadsheets/d/15vK6VPlcAM4e7lSJw6IeVtTtyariXEVQurDTFKXwwtY/edit?gid=249584681&ref=jina-ai-gmbh.ghost.io#gid=249584681\"><span style=\"white-space: pre-wrap;\">ce tableur Google</span></a><span style=\"white-space: pre-wrap;\">.</span></p></figcaption></figure><p>Les graphiques F1 révèlent des tendances intéressantes à travers trois tâches. Sans surprise, la classification zero-shot montre une performance constante dès le départ, indépendamment de la taille des données d'entraînement. En revanche, l'apprentissage few-shot démontre une courbe d'apprentissage rapide, commençant plus bas mais dépassant rapidement les performances du zero-shot à mesure que les données d'entraînement augmentent. Les deux méthodes finissent par <strong>atteindre une précision comparable autour des 400 échantillons</strong>, avec un léger avantage pour le few-shot. Ce modèle se vérifie tant pour les scénarios de classification multi-classes que pour la classification d'images, suggérant que l'apprentissage few-shot peut être particulièrement avantageux lorsque des données d'entraînement sont disponibles, tandis que le zero-shot offre des performances fiables même sans exemples d'entraînement. Le tableau ci-dessous résume la différence entre la classification zero-shot et few-shot du point de vue de l'utilisateur de l'API.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Zero-shot</th>\n<th>Few-shot</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Primary Use Case</td>\n<td>Default solution for general classification</td>\n<td>For data outside v3/clip-v1's domain or time-sensitive data</td>\n</tr>\n<tr>\n<td>Training Data Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /train</td>\n<td>N/A</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /classify</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Classifier ID Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Semantic Labels Required</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>State Management</td>\n<td>Stateless</td>\n<td>Stateful</td>\n</tr>\n<tr>\n<td>Continuous Model Updates</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Access Control</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Maximum Classes</td>\n<td>256</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Classifiers</td>\n<td>N/A</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Inputs per Request</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Maximum Token Length per Input</td>\n<td>8,192 tokens</td>\n<td>8,192 tokens</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"summary\">Résumé</h2><p>L'API Classifier offre une classification zero-shot et few-shot puissante pour le contenu textuel et les images, alimentée par des modèles d'embedding avancés comme <code>jina-embeddings-v3</code> et <code>jina-clip-v1</code>. Nos tests de performance montrent que la classification zero-shot fournit des performances fiables sans données d'entraînement, ce qui en fait un excellent point de départ pour la plupart des tâches avec une prise en charge jusqu'à 256 classes. Bien que l'apprentissage few-shot puisse atteindre une précision légèrement meilleure avec des données d'entraînement, nous recommandons de commencer par la classification zero-shot pour ses résultats immédiats et sa flexibilité.</p><p>La polyvalence de l'API prend en charge diverses applications, du routage des requêtes LLM à la détection de l'accessibilité des sites web et à la catégorisation de contenu multilingue. Que vous commenciez avec le zero-shot ou que vous passiez à l'apprentissage few-shot pour des cas spécialisés, l'API maintient une interface cohérente pour une intégration transparente dans votre pipeline. Nous sommes particulièrement impatients de voir comment les développeurs exploiteront cette API dans leurs applications, et nous déploierons prochainement la prise en charge de nouveaux modèles d'embedding comme <code>jina-clip-v2</code>.</p>",
  "comment_id": "6711fbbd708dbe0001924974",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/classifier-header-1.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-10-18T08:10:05.000+02:00",
  "updated_at": "2024-10-24T11:04:33.000+02:00",
  "published_at": "2024-10-22T10:57:15.000+02:00",
  "custom_excerpt": "New Classifier API offers zero-shot and few-shot classification for text and images. Start classifying content instantly or train it with your own examples.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-classifier-for-high-performance-zero-shot-and-few-shot-classification/",
  "excerpt": "La nouvelle API Classifier propose une classification zero-shot et few-shot pour le texte et les images. Commencez à classifier du contenu instantanément ou entraînez-la avec vos propres exemples.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract artistic portrait using a montage of colorful squares and scattered text.",
  "feature_image_caption": null
}