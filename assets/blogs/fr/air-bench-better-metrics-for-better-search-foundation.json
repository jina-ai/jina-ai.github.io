{
  "slug": "air-bench-better-metrics-for-better-search-foundation",
  "id": "664c53c684f9e40001a6d96c",
  "uuid": "551df773-da01-406e-981b-ea8ef11c352d",
  "title": "AIR-Bench : de meilleurs indicateurs pour une meilleure fondation de recherche",
  "html": "<blockquote>Tard dans la nuit, un policier trouve un homme ivre qui rampe à quatre pattes sous un réverbère. L'homme ivre dit à l'agent qu'il cherche son portefeuille. Lorsque l'agent lui demande s'il est sûr d'avoir perdu son portefeuille à cet endroit, l'homme répond qu'il pense l'avoir plutôt perdu de l'autre côté de la rue. Alors pourquoi cherchez-vous ici ? demande l'agent déconcerté. Parce que la lumière est meilleure ici, explique l'homme ivre.<br><br>David H. Friedman, <a href=\"https://www.discovermagazine.com/the-sciences/why-scientific-studies-are-so-often-wrong-the-streetlight-effect?ref=jina-ai-gmbh.ghost.io\"><em>Why Scientific Studies Are So Often Wrong: The Streetlight Effect</em></a>, Discover magazine, déc. 2010</blockquote><p>Les benchmarks sont une composante essentielle des pratiques modernes d'apprentissage automatique depuis un certain temps, mais ils présentent un problème très sérieux : nous ne pouvons pas dire si nos benchmarks mesurent quelque chose d'utile.</p><p>C'est un problème majeur, et cet article présentera une partie de la solution : l'AIR-Bench. Ce projet conjoint avec la <a href=\"https://www.baai.ac.cn/english.html?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">Beijing Academy of Artificial Intelligence</a> est une approche novatrice des métriques d'IA conçue pour améliorer la qualité et l'utilité de nos benchmarks.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - Your Search Foundation, Supercharged.</div><div class=\"kg-bookmark-description\">Jina AI offers best-in-class embeddings, reranker and prompt optimizer, enabling advanced multimodal AI.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-author\">Your Search Foundation, Supercharged.</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.baai.ac.cn/english.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">北京智源人工智能研究院</div><div class=\"kg-bookmark-description\">智源研究院是人工智能领域的新型研发机构，汇集国际顶尖人工智能学者，聚焦核心技术与原始创新，旨在推动人工智能领域发展政策、学术思想、理论基础、顶尖人才与产业生态的五大源头创新。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.baai.ac.cn/home/images/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.baai.ac.cn/home/images/logo.svg\" alt=\"\"></div></a></figure><h2 id=\"the-streetlight-effect\">L'effet Réverbère</h2><p>La recherche scientifique et opérationnelle met beaucoup l'accent sur les mesures, mais les mesures ne sont pas simples. Dans une étude de santé, vous pourriez vouloir savoir si un médicament ou un traitement a rendu les patients plus sains, a prolongé leur vie ou a amélioré leur condition d'une manière ou d'une autre. Mais la santé et l'amélioration de la qualité de vie sont des choses difficiles à mesurer directement, et il peut falloir des décennies pour savoir si un traitement a prolongé la vie de quelqu'un.</p><p>Les chercheurs utilisent donc des indicateurs indirects. Dans une étude de santé, il peut s'agir de la force physique, de la réduction de la douleur, de la baisse de la pression artérielle ou d'une autre variable facilement mesurable. L'un des problèmes de la recherche en santé est que l'indicateur indirect peut ne pas être vraiment représentatif du meilleur résultat de santé que vous souhaitez obtenir avec un médicament ou un traitement.</p><p>Une mesure est un indicateur indirect de quelque chose d'utile qui compte pour vous. Vous ne pouvez peut-être pas mesurer cette chose, alors vous mesurez autre chose, quelque chose que vous <em>pouvez</em> mesurer, et que vous avez des raisons de croire corrélée avec la chose utile qui vous importe vraiment.</p><p>L'accent mis sur la mesure a été un développement majeur de la recherche opérationnelle du 20e siècle et a eu des effets profonds et positifs. Le <a href=\"https://en.wikipedia.org/wiki/Total_quality_management?ref=jina-ai-gmbh.ghost.io\">Total Quality Management</a>, un ensemble de doctrines crédité de la montée du Japon à la domination économique dans les années 1980, concerne presque entièrement la mesure constante de variables indirectes et l'optimisation des pratiques sur cette base.</p><p>Mais l'accent mis sur la mesure pose certains problèmes connus et importants :</p><ul><li>Une mesure peut cesser d'être un bon indicateur indirect lorsque vous prenez des décisions basées sur elle.</li><li>Il existe souvent des moyens de gonfler une mesure qui n'améliorent rien, ce qui peut mener à la tricherie ou à croire que l'on progresse en faisant des choses qui n'aident pas.</li></ul><p>Certains pensent que <a href=\"https://journals.plos.org/plosmedicine/article?id=10.1371%2Fjournal.pmed.0020124&ref=jina-ai-gmbh.ghost.io\">la plupart des recherches médicales pourraient être tout simplement erronées</a> en partie à cause de ce problème. La déconnexion entre les choses que vous pouvez mesurer et les objectifs réels est l'une des raisons citées <a href=\"https://en.wikipedia.org/wiki/McNamara_fallacy?ref=jina-ai-gmbh.ghost.io\">pour la catastrophe de la guerre américaine au Vietnam</a>.</p><p>On appelle parfois cela \"l'effet Réverbère\", d'après les histoires, comme celle en haut de cette page, de l'ivrogne qui cherche quelque chose non pas là où il l'a perdu, mais là où la lumière est meilleure. Une mesure indirecte, c'est comme regarder là où il y a de la lumière parce qu'il n'y a pas de lumière sur la chose que nous voulons voir.</p><p>Dans la littérature plus technique, \"l'effet Réverbère\" est généralement lié à la <a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law?ref=jina-ai-gmbh.ghost.io\">Loi de Goodhart</a>, attribuée aux critiques de l'économiste britannique <a href=\"https://en.wikipedia.org/wiki/Charles_Goodhart?ref=jina-ai-gmbh.ghost.io\">Charles Goodhart</a> envers le gouvernement Thatcher, qui avait mis beaucoup l'accent sur les mesures indirectes de la prospérité. La Loi de Goodhart a plusieurs formulations, mais celle ci-dessous est la plus citée :</p><blockquote>Toute mesure qui devient un objectif devient une mauvaise mesure [...]<br><br><em>Keith Hoskins, 1996 The 'awful idea of accountability': inscribing people into the measurement of objects.</em></blockquote><p>Dans l'IA, un exemple célèbre est la métrique BLEU utilisée dans la recherche en traduction automatique. Développé en 2001 chez IBM, BLEU est un moyen d'automatiser l'évaluation des systèmes de traduction automatique, et ce fut un facteur déterminant dans l'essor de la traduction automatique des années 2000. Une fois qu'il était facile de donner un score à votre système, vous pouviez travailler à l'améliorer. Et les scores BLEU se sont constamment améliorés. Vers 2010, il était presque impossible de faire publier un article de recherche sur la traduction automatique dans une revue ou une conférence s'il ne battait pas le score BLEU de l'état de l'art, peu importe à quel point l'article était innovant ou à quel point il pouvait gérer un problème spécifique que d'autres systèmes géraient mal.</p><p>Le moyen le plus facile d'être accepté dans une conférence était de trouver une façon mineure de modifier les paramètres de votre modèle, d'obtenir un score BLEU légèrement supérieur à celui de Google Translate, puis de soumettre. Ces résultats étaient essentiellement inutiles. Il suffisait de prendre quelques nouveaux textes à traduire pour montrer qu'ils étaient rarement meilleurs et souvent pires que l'état de l'art.</p><p>Au lieu d'utiliser BLEU pour évaluer les progrès en traduction automatique, obtenir un meilleur score BLEU est devenu l'objectif. Dès que cela s'est produit, il a cessé d'être un moyen utile d'évaluer les progrès.</p><h2 id=\"are-our-ai-benchmarks-good-proxies\">Nos benchmarks d'IA sont-ils de bons indicateurs indirects ?</h2><p>Le benchmark le plus utilisé pour les modèles d'embedding est l'ensemble de tests MTEB, qui comprend 56 tests spécifiques. Ceux-ci sont moyennés par catégorie et tous ensemble pour produire une collection de scores spécifiques aux classes. Au moment de la rédaction, le haut du classement MTEB ressemble à ceci :</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-15-at-16.22.08.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-15 at 16.22.08.png\" loading=\"lazy\" width=\"1942\" height=\"1454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-15-at-16.22.08.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-15-at-16.22.08.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Screenshot-2024-05-15-at-16.22.08.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-15-at-16.22.08.png 1942w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Le modèle d'embedding le mieux classé a un score moyen global de 68,28, le suivant est à 67,56. Il est très difficile, en regardant ce tableau, de savoir si c'est une grande différence ou non. Si c'est une petite différence, alors d'autres facteurs peuvent être plus importants que le modèle ayant le score le plus élevé :</p><ul><li><strong>Taille du modèle :</strong> Les modèles ont différentes tailles, reflétant différentes demandes en ressources de calcul. Les petits modèles s'exécutent plus rapidement, utilisent moins de mémoire et nécessitent du matériel moins coûteux. Nous voyons, dans ce top 10, des modèles allant de 434 millions à plus de 46 milliards de paramètres — une différence de 100 fois !</li><li><strong>Taille de l'embedding :</strong> Les dimensions d'embedding varient. Une dimensionnalité plus petite fait que les vecteurs d'embedding utilisent moins de mémoire et de stockage et rend les comparaisons de vecteurs (l'utilisation principale des embeddings) beaucoup plus rapides. Dans cette liste, nous voyons des dimensions d'embedding de 768 à 4096 — seulement une différence de cinq fois mais toujours significative lors de la construction d'applications commerciales.</li><li><strong>Taille de la fenêtre de contexte d'entrée :</strong> Les fenêtres de contexte varient en taille et en qualité, de 2048 tokens à 32768. De plus, différents modèles utilisent différentes approches pour l'encodage positionnel et la gestion des entrées, ce qui peut créer des biais en faveur de parties spécifiques de l'entrée.</li></ul><p>En bref, la moyenne globale est une manière très incomplète de déterminer quel modèle d'embedding est le meilleur.</p><p>Même si nous regardons les scores spécifiques aux tâches, comme ceux ci-dessous pour la recherche, nous faisons face aux mêmes problèmes encore et encore. Quel que soit le score d'un modèle sur cet ensemble de tests, il n'y a aucun moyen de savoir quels modèles fonctionneront le mieux pour votre cas d'utilisation unique particulier.</p>Mais ce n'est pas la fin des problèmes avec ce type de benchmarks.\n\nL'idée principale de la Loi de Goodhart est qu'une métrique peut toujours être détournée, souvent sans intention. Par exemple, les benchmarks MTEB contiennent des données provenant de sources publiques qui sont probablement présentes dans vos données d'entraînement. À moins de travailler spécifiquement pour retirer les données de benchmark de votre entraînement, vos scores de benchmark seront statistiquement peu fiables.\n\nIl n'existe pas de solution simple et complète. Un benchmark est un indicateur indirect et nous ne pouvons jamais être certains qu'il reflète ce que nous voulons savoir mais ne pouvons pas mesurer directement.\n\nCependant, nous identifions trois problèmes fondamentaux avec les benchmarks d'IA que nous pouvons atténuer :\n\n1. Les benchmarks sont fixes par nature : les mêmes tâches, utilisant les mêmes textes.\n2. Les benchmarks sont génériques : ils ne sont pas très informatifs sur des scénarios réels.\n3. Les benchmarks sont rigides : ils ne peuvent pas s'adapter à des cas d'utilisation divers.\n\nL'IA crée ce type de problèmes, mais elle crée parfois aussi des solutions. Nous pensons pouvoir utiliser les modèles d'IA pour résoudre ces problèmes, du moins en ce qui concerne les benchmarks d'IA.\n\n## Utiliser l'IA pour évaluer l'IA : AIR-Bench\n\nAIR-Bench est open source et disponible sous la [Licence MIT](https://opensource.org/license/mit?ref=jina-ai-gmbh.ghost.io). Vous pouvez consulter ou télécharger le code depuis son [dépôt sur GitHub](https://github.com/AIR-Bench/AIR-Bench/?ref=jina-ai-gmbh.ghost.io).\n\n### Que fait-il ?\n\nAIR-Bench apporte des fonctionnalités importantes aux benchmarks d'IA :\n\n* **Spécialisation pour les Applications de Recherche et RAG** \nCe benchmark est orienté vers des applications réalistes de recherche d'information et des pipelines de génération augmentée par recherche.\n\n* **Flexibilité de Domaine et de Langue** \nAIR facilite grandement la création de benchmarks à partir de données spécifiques à un domaine ou pour une autre langue, ou même à partir de vos propres données spécifiques à une tâche.\n\n* **Génération Automatisée de Données** \nAIR-Bench génère des données de test et le jeu de données reçoit des mises à jour régulières, réduisant le risque de fuite de données.\n\n## Classement AIR-Bench sur HuggingFace\n\n⚠️ Explorez la version bêta publique du Classement AIR-Bench dans [l'espace HuggingFace d'AIR-Bench](https://huggingface.co/spaces/AIR-Bench/leaderboard?ref=jina-ai-gmbh.ghost.io).\n\nNous gérons un [classement](https://huggingface.co/spaces/AIR-Bench/leaderboard?ref=jina-ai-gmbh.ghost.io), similaire à celui de [MTEB](https://huggingface.co/spaces/mteb/leaderboard?ref=jina-ai-gmbh.ghost.io), pour la version actuelle des tâches générées par AIR-Bench. Nous régénérerons régulièrement les benchmarks, en ajouterons de nouveaux et étendrons la couverture à davantage de modèles d'IA.\n\n### Comment fonctionne-t-il ?\n\nL'idée centrale de l'approche AIR est que nous pouvons utiliser les grands modèles de langage (LLM) pour *générer* de nouveaux textes et de nouvelles tâches qui ne peuvent pas être dans un ensemble d'entraînement.\n\nAIR-Bench tire parti des capacités créatives des LLM en leur demandant de jouer un scénario. L'utilisateur choisit une collection de documents — une collection réelle qui peut faire partie des données d'entraînement de certains modèles — puis imagine un utilisateur avec un rôle défini, et une situation dans laquelle il aurait besoin d'utiliser ce corpus de documents.\n\nEnsuite, l'utilisateur sélectionne un document du corpus et le transmet au LLM avec le profil utilisateur et la description de la situation. Le LLM est invité à créer des requêtes appropriées à cet utilisateur et à cette situation et qui devraient permettre de trouver ce document.\n\nLe pipeline AIR-Bench sollicite ensuite le LLM avec le document et la requête et crée des documents synthétiques qui sont *similaires* à celui fourni mais qui *ne devraient pas* correspondre à la requête.\n\nNous avons maintenant :\n\n* Une collection de requêtes\n* Un document réel correspondant pour chaque requête\n* Une petite collection de documents synthétiques non correspondants attendus\n\nAIR-Bench fusionne les documents synthétiques avec la collection de documents réels puis utilise un ou plusieurs modèles d'embedding et de reranking pour vérifier que les requêtes *devraient* pouvoir retrouver les documents correspondants. Il utilise également le LLM pour vérifier que chaque requête est pertinente pour les documents qu'elle devrait retrouver.\n\nPour plus de détails sur ce processus de génération et de contrôle qualité centré sur l'IA, consultez la [documentation sur la Génération de Données](https://github.com/AIR-Bench/AIR-Bench/blob/main/docs/data_generation.md?ref=jina-ai-gmbh.ghost.io) dans le [dépôt AIR-Bench sur GitHub](https://github.com/AIR-Bench/AIR-Bench/?ref=jina-ai-gmbh.ghost.io).<div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">AIR-Bench</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://repository-images.githubusercontent.com/796154919/063cb803-f83f-4fcf-b860-132a73c4c2d9\" alt=\"\"></div></a></figure><p>Le résultat est un ensemble de paires requête-correspondance de haute qualité et un jeu de données semi-synthétique pour les tester. Même si la collection de documents réels d'origine fait partie de son entraînement, les documents synthétiques ajoutés et les requêtes elles-mêmes sont des données nouvelles et jamais vues auparavant qu'il n'aurait pas pu apprendre précédemment.</p><h3 id=\"domain-specific-benchmarks-and-reality-based-testing\">Benchmarks spécifiques au domaine et tests basés sur la réalité</h3><p>La synthèse des requêtes et des documents empêche les données de benchmark de fuiter dans l'entraînement, mais elle contribue également largement à résoudre le problème des benchmarks génériques.</p><p>En fournissant aux LLMs des données choisies, un profil utilisateur et un scénario, AIR-Bench facilite grandement la construction de benchmarks pour des cas d'utilisation particuliers. De plus, en construisant des requêtes pour un type d'utilisateur et un scénario d'utilisation spécifiques, AIR-Bench peut produire des requêtes de test plus fidèles à l'utilisation réelle que les benchmarks traditionnels. La créativité et l'imagination limitées d'un LLM peuvent ne pas correspondre entièrement à un scénario réel, mais c'est une meilleure correspondance qu'un jeu de données de test statique constitué de données disponibles pour les chercheurs.</p><p>En tant que sous-produit de cette flexibilité, AIR-Bench prend en charge toutes les langues supportées par GPT-4.</p><p>De plus, AIR-Bench se concentre spécifiquement sur la recherche d'informations réaliste basée sur l'IA, de loin l'application la plus répandue des modèles d'embedding. Il ne fournit pas de scores pour d'autres types de tâches comme le clustering ou la classification.</p><h2 id=\"the-air-bench-distribution\">La distribution AIR-Bench</h2><p>AIR-Bench est disponible en téléchargement, utilisation et modification via son <a href=\"https://github.com/AIR-Bench/AIR-Bench/?ref=jina-ai-gmbh.ghost.io\">dépôt GitHub</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/AIR-Bench/AIR-Bench/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - AIR-Bench/AIR-Bench: AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark</div><div class=\"kg-bookmark-description\">AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark - AIR-Bench/AIR-Bench</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">AIR-Bench</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://repository-images.githubusercontent.com/796154919/063cb803-f83f-4fcf-b860-132a73c4c2d9\" alt=\"\"></div></a></figure><p>AIR-Bench prend en charge deux types de benchmarks :</p><ul><li>Une tâche de recherche d'informations basée sur l'évaluation de la récupération correcte des documents pertinents pour des requêtes spécifiques.</li><li>Une tâche \"document long\" qui imite la partie recherche d'informations d'un pipeline de génération augmentée par récupération.</li></ul><p>Nous avons également <a href=\"https://github.com/AIR-Bench/AIR-Bench/blob/main/docs/available_tasks.md?ref=jina-ai-gmbh.ghost.io\">pré-généré un ensemble de benchmarks</a>, en anglais et en chinois, ainsi que les scripts pour les générer comme exemples concrets d'utilisation d'AIR-Bench. Ils utilisent des ensembles de données facilement disponibles.</p><p>Par exemple, pour une <a href=\"https://huggingface.co/datasets/NeuML/wikipedia-20240101?ref=jina-ai-gmbh.ghost.io\">sélection de 6 738 498 pages Wikipédia en anglais</a>, nous avons généré 1 727 requêtes correspondant à 4 260 documents et 7 882 documents synthétiques supplémentaires non correspondants mais similaires. Nous proposons des benchmarks de recherche d'informations conventionnels pour huit jeux de données en anglais et six en chinois. Pour les tâches \"document long\", nous fournissons quinze benchmarks, tous en anglais.</p><p>Pour voir la liste complète et plus de détails, visitez la <a href=\"https://github.com/AIR-Bench/AIR-Bench/blob/main/docs/available_tasks.md?ref=jina-ai-gmbh.ghost.io\">page des tâches disponibles dans le dépôt AIR-Bench sur GitHub</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/AIR-Bench/AIR-Bench/blob/main/docs/available_tasks.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AIR-Bench/docs/available_tasks.md at main · AIR-Bench/AIR-Bench</div><div class=\"kg-bookmark-description\">AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark - AIR-Bench/AIR-Bench</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">AIR-Bench</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://repository-images.githubusercontent.com/796154919/063cb803-f83f-4fcf-b860-132a73c4c2d9\" alt=\"\"></div></a></figure><h2 id=\"get-involved\">Participez</h2><p>L'AIR-Benchmark a été conçu comme un outil pour la communauté Search Foundations afin que les utilisateurs engagés puissent créer des benchmarks mieux adaptés à leurs besoins. Lorsque vos tests sont informatifs sur vos cas d'utilisation, ils nous informent également, nous permettant ainsi de construire des produits qui répondent mieux à vos besoins.</p>",
  "comment_id": "664c53c684f9e40001a6d96c",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/05/cosmic--1-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-05-21T09:56:54.000+02:00",
  "updated_at": "2024-05-22T20:29:00.000+02:00",
  "published_at": "2024-05-21T16:26:11.000+02:00",
  "custom_excerpt": "AIR-Bench is a new approach to AI metrics that uses generative AI to make more realistic and flexible benchmarks. With AIR-Bench, you can create your own benchmarks for your own domain, and know that benchmarks data hasn't leaked into model training data.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/air-bench-better-metrics-for-better-search-foundation/",
  "excerpt": "AIR-Bench est une nouvelle approche des métriques d'IA qui utilise l'IA générative pour créer des benchmarks plus réalistes et flexibles. Avec AIR-Bench, vous pouvez créer vos propres benchmarks pour votre domaine spécifique, et avoir l'assurance que les données de benchmark n'ont pas fuité dans les données d'entraînement du modèle.",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract design with geometric shapes, white clouds, and colorful gradients on a black background, suggesting a futuristic am",
  "feature_image_caption": null
}