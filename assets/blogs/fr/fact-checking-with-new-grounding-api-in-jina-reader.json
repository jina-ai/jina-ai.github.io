{
  "slug": "fact-checking-with-new-grounding-api-in-jina-reader",
  "id": "670cd94952567c0001d0f33e",
  "uuid": "20c36ec7-687f-47c8-8cfd-8da526a70859",
  "title": "Vérification des faits avec la nouvelle API Grounding dans Jina Reader",
  "html": "<p>L'ancrage est <em>absolument essentiel</em> pour les applications d'IA générative.</p><p>Sans ancrage, les LLM sont plus enclins aux hallucinations et à générer des informations inexactes, en particulier lorsque leurs données d'entraînement manquent de connaissances actualisées ou spécifiques. Peu importe la puissance de raisonnement d'un LLM, il ne peut tout simplement pas fournir une réponse correcte si l'information a été introduite <em>après</em> sa date limite de connaissance.</p><p>L'ancrage n'est pas seulement important pour les LLM mais aussi pour le contenu rédigé par des humains afin de prévenir la désinformation. Un excellent exemple est <a href=\"https://communitynotes.x.com/guide/en/about/introduction?ref=jina-ai-gmbh.ghost.io\">Community Notes de X</a>, où les utilisateurs ajoutent collaborativement du contexte aux publications potentiellement trompeuses. Cela souligne la valeur de l'ancrage, qui garantit l'exactitude factuelle en fournissant des sources et références claires, tout comme Community Notes aide à maintenir l'intégrité de l'information.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png\" class=\"kg-image\" alt=\"Screenshot of a mobile chat in the Sage app discussing whether whales are mammals and how they hydrate, with options to rate \" loading=\"lazy\" width=\"2000\" height=\"1113\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Avec <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>, nous avons activement développé une solution d'ancrage facile à utiliser. Par exemple, <code>r.jina.ai</code> convertit les pages web en markdown adapté aux LLM, et <code>s.jina.ai</code> agrège les résultats de recherche dans un format markdown unifié basé sur une requête donnée.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs or search the web, get better grounding for LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-9.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><strong>Aujourd'hui, nous sommes ravis de présenter un nouveau point de terminaison à cette suite : <code>g.jina.ai</code>. </strong>La nouvelle API prend un énoncé donné, l'ancre en utilisant des résultats de recherche web en temps réel, et renvoie un score de factualité et <strong>les références exactes utilisées</strong>. Nos expériences montrent que cette API atteint un score F1 plus élevé pour la vérification des faits par rapport aux modèles comme GPT-4, o1-mini et Gemini 1.5 Flash & Pro avec ancrage de recherche.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Evaluation-of-grounding-solutions-on-fact-checking-100-statements--1-.svg\" class=\"kg-image\" alt=\"Bar graph illustrating the evaluation of various grounding solutions for fact-checking 100 statements, with software scores r\" loading=\"lazy\" width=\"1218\" height=\"371\"><figcaption><span style=\"white-space: pre-wrap;\">Nous avons collecté manuellement 100 énoncés avec des étiquettes de vérité terrain soit \"vrai\" soit \"faux\" et utilisé différentes méthodes pour déterminer s'ils pouvaient être vérifiés. Ce processus convertit essentiellement la tâche en un problème de classification binaire, où la performance finale est mesurée par le score F1—plus il est élevé, meilleur c'est.</span></figcaption></figure><p>Ce qui distingue <code>g.jina.ai</code> de la recherche ancrée de Gemini, c'est que chaque résultat inclut jusqu'à 30 URLs (fournissant généralement au moins 10), chacune accompagnée de citations directes qui contribuent à la conclusion. Voici un exemple d'ancrage de l'énoncé, <code>\"The latest model released by Jina AI is jina-embeddings-v3,\"</code> utilisant <code>g.jina.ai</code> (au 14 octobre 2024). Explorez le <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">terrain de jeu de l'API</a> pour découvrir toutes les fonctionnalités. Notez que des <a href=\"#limitations\" rel=\"noreferrer\">limitations</a> s'appliquent :</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-bash\">curl -X POST https://g.jina.ai \\\n     -H \"Content-Type: application/json\" \\\n     -H \"Authorization: Bearer $YOUR_JINA_TOKEN\" \\\n     -d '{\n           \"statement\":\"the last model released by Jina AI is jina-embeddings-v3\"\n         }'</code></pre><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>YOUR_JINA_TOKEN</span></code><span style=\"white-space: pre-wrap;\"> est votre clé API Jina AI. Vous pouvez </span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">obtenir 1M de jetons gratuits sur notre page d'accueil</span></a><span style=\"white-space: pre-wrap;\">, ce qui permet environ trois ou quatre essais gratuits. Avec le prix actuel de l'API de 0,02 USD par million de jetons, chaque requête d'ancrage coûte environ 0,006 USD.</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"code\": 200,\n  \"status\": 20000,\n  \"data\": {\n    \"factuality\": 0.95,\n    \"result\": true,\n    \"reason\": \"The majority of the references explicitly support the statement that the last model released by Jina AI is jina-embeddings-v3. Multiple sources, such as the arXiv paper, Jina AI's news, and various model documentation pages, confirm this assertion. Although there are a few references to the jina-embeddings-v2 model, they do not provide evidence contradicting the release of a subsequent version (jina-embeddings-v3). Therefore, the statement that 'the last model released by Jina AI is jina-embeddings-v3' is well-supported by the provided documentation.\",\n    \"references\": [\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"arXiv September 18, 2024 jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"We introduce jina-embeddings-v3, a novel text embedding model with 570 million parameters, achieves state-of-the-art performance on multilingual data and long-context retrieval tasks, supporting context lengths of up to 8192 tokens.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview\",\n        \"keyQuote\": \"jina-embeddings-v3 is a multilingual multi-task text embedding model designed for a variety of NLP applications.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://docs.pinecone.io/models/jina-embeddings-v3\",\n        \"keyQuote\": \"Jina Embeddings v3 is the latest iteration in the Jina AI's text embedding model series, building upon Jina Embedding v2.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://haystack.deepset.ai/integrations/jina\",\n        \"keyQuote\": \"Recommended Model: jina-embeddings-v3 : We recommend jina-embeddings-v3 as the latest and most performant embedding model from Jina AI.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"The embedding model was trained using 512 sequence length, but extrapolates to 8k sequence length (or even longer) thanks to ALiBi.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"With a standard size of 137 million parameters, the model enables fast inference while delivering better performance than our small model.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"We offer an `encode` function to deal with this.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jinaai/jina-embeddings-v3 Feature Extraction • Updated 3 days ago • 278k • 375\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"the latest version (3.1.0) of [SentenceTransformers] also supports jina-embeddings-v3\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/embeddings/\",\n        \"keyQuote\": \"v3: Frontier Multilingual Embeddings is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\",\n        \"keyQuote\": \"Jina Embeddings v3: A Frontier Multilingual Embedding Model jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/\",\n        \"keyQuote\": \"As of its release on September 18, 2024, jina-embeddings-v3 is the best multilingual model ...\",\n        \"isSupportive\": true\n      }\n    ],\n    \"usage\": {\n      \"tokens\": 112073\n    }\n  }\n}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">La réponse de l'ancrage de l'énoncé \"The latest model released by Jina AI is jina-embeddings-v3\", utilisant </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>g.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> (au 14 octobre 2024).</span></p></figcaption></figure><h2 id=\"how-does-it-work\">Comment ça marche ?</h2><p>À sa base, <code>g.jina.ai</code> enveloppe <code>s.jina.ai</code> et <code>r.jina.ai</code><strong> </strong>, ajoutant un raisonnement multi-étapes grâce à la Chaîne de Pensée (CoT). Cette approche garantit que chaque énoncé ancré est analysé en profondeur à l'aide de recherches en ligne et de lecture de documents.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/User-Render.svg\" class=\"kg-image\" alt=\"UI of Jina AI reader app, displaying three panels: User Input, Response, and User Render with interactive links and buttons a\" loading=\"lazy\" width=\"1400\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">L'API Grounding est une surcouche de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>s.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> et </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>r.jina.ai</span></code><span style=\"white-space: pre-wrap;\">, ajoutant CoT pour la planification et le raisonnement.</span></figcaption></figure><h3 id=\"step-by-step-explanation\">Explication étape par étape</h3><p>Examinons l'ensemble du processus pour mieux comprendre comment <code>g.jina.ai</code> gère la vérification des faits, de l'entrée à la sortie finale :</p><ol><li><strong>Déclaration d'entrée</strong> :<br>Le processus commence lorsqu'un utilisateur fournit une déclaration qu'il souhaite vérifier, comme <em>\"Le dernier modèle publié par Jina AI est jina-embeddings-v3.\"</em> Notez qu'il n'est pas nécessaire d'ajouter des instructions de vérification des faits avant la déclaration.</li><li><strong>Génération des requêtes de recherche</strong> :<br>Un LLM est utilisé pour générer une liste de requêtes de recherche uniques pertinentes pour la déclaration. Ces requêtes visent à cibler différents éléments factuels, assurant une recherche complète couvrant tous les aspects clés de la déclaration.</li><li><strong>Appel à <code>s.jina.ai</code> pour chaque requête</strong> :<br>Pour chaque requête générée, <code>g.jina.ai</code> effectue une recherche web en utilisant <code>s.jina.ai</code>. Les résultats de recherche comprennent un ensemble diversifié de sites web ou de documents liés aux requêtes. En arrière-plan, <code>s.jina.ai</code> appelle <code>r.jina.ai</code> pour récupérer le contenu de la page.</li><li><strong>Extraction des références des résultats de recherche</strong> :<br>Pour chaque document récupéré lors de la recherche, un LLM extrait les références clés. Ces références incluent :<ul><li><strong><code>url</code></strong> : L'adresse web de la source.</li><li><strong><code>keyQuote</code></strong> : Une citation directe ou un extrait du document.</li><li><strong><code>isSupportive</code></strong> : Une valeur booléenne indiquant si la référence soutient ou contredit la déclaration originale.</li></ul></li><li><strong>Agrégation et tri des références</strong> :<br>Toutes les références des documents récupérés sont combinées en une seule liste. Si le nombre total de références dépasse 30, le système sélectionne 30 références aléatoires pour maintenir une sortie gérable.</li><li><strong>Évaluation de la déclaration</strong> :<br>Le processus d'évaluation implique l'utilisation d'un LLM pour évaluer la déclaration sur la base des références recueillies (jusqu'à 30). En plus de ces références externes, les connaissances internes du modèle jouent également un rôle dans l'évaluation. Le résultat final comprend :<ul><li><strong><code>factuality</code></strong> : Un score entre 0 et 1 qui estime l'exactitude factuelle de la déclaration.</li><li><strong><code>result</code></strong> : Une valeur booléenne indiquant si la déclaration est vraie ou fausse.</li><li><strong><code>reason</code></strong> : Une explication détaillée de pourquoi la déclaration est jugée correcte ou incorrecte, avec référence aux sources qui la soutiennent ou la contredisent.</li></ul></li><li><strong>Production du résultat</strong> :<br>Une fois la déclaration entièrement évaluée, la sortie est générée. Celle-ci inclut le <strong>score de factualité</strong>, l'<strong>assertion de la déclaration</strong>, un <strong>raisonnement détaillé</strong>, et une liste de <strong>références</strong> avec citations et URLs. Les références sont limitées à la citation, l'URL, et si elles soutiennent ou non la déclaration, maintenant la sortie claire et concise.</li></ol><h2 id=\"benchmark\">Benchmark</h2><p>Nous avons manuellement collecté 100 déclarations avec des étiquettes de vérité terrain soit <code>true</code> (62 déclarations) soit <code>false</code> (38 déclarations) et utilisé différentes méthodes pour déterminer si elles pouvaient être vérifiées. Ce processus convertit essentiellement la tâche en un problème de classification binaire, où la performance finale est mesurée par la précision, le rappel et le score F1 — plus ils sont élevés, meilleurs ils sont.</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1xE-uCTQ4G0cYRw_g781zZXHO8eRYi31HbCb-3BPlNh8/edit?gid=1283553680&ref=jina-ai-gmbh.ghost.io#gid=1283553680\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Grounding Validation Dataset</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyJpf4HNZ3zF1snMGetpmkt0oOTQGGviY1-ZTOrq5dXuafT8uWLmZ806MU1A_agTpgO52Z_xZ-iDougmFm0ViL0sVSqDxe3C4fVuPcYXKoS5O90jN3Qy-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">La liste complète des déclarations peut être trouvée ici.</span></p></figcaption></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Precision</th>\n<th>Recall</th>\n<th>F1 Score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Jina AI Grounding API (g.jina.ai)</strong></td>\n<td>0.96</td>\n<td><strong>0.88</strong></td>\n<td><strong>0.92</strong></td>\n</tr>\n<tr>\n<td>Gemini-flash-1.5-002 w/ grounding</td>\n<td><strong>1.00</strong></td>\n<td>0.73</td>\n<td>0.84</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-002 w/ grounding</td>\n<td>0.98</td>\n<td>0.71</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>gpt-o1-mini</td>\n<td>0.87</td>\n<td>0.66</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>0.95</td>\n<td>0.58</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001 w/ grounding</td>\n<td>0.97</td>\n<td>0.52</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001</td>\n<td>0.95</td>\n<td>0.32</td>\n<td>0.48</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Notez qu'en pratique, certains LLMs renvoient une troisième classe, <em>Je ne sais pas</em>, dans leurs prédictions. Pour l'évaluation, ces instances sont exclues du calcul du score. Cette approche évite de pénaliser l'incertitude aussi sévèrement que les réponses incorrectes. Admettre l'incertitude est préféré à la devinette, pour décourager les modèles de faire des prédictions incertaines.</p><h2 id=\"limitations\">Limitations</h2><p>Malgré les résultats prometteurs, nous souhaitons souligner certaines limitations de la version actuelle de l'API de grounding :</p><ul><li><strong>Latence élevée et consommation de tokens</strong> : Un seul appel à <code>g.jina.ai</code> peut prendre environ <strong>30 secondes</strong> et utiliser jusqu'à <strong>300K tokens</strong>, en raison de la recherche web active, de la lecture des pages et du raisonnement multi-étapes par le LLM. Avec une clé API gratuite de 1M de tokens, cela signifie que vous ne pouvez le tester que trois ou quatre fois. Pour maintenir la disponibilité du service pour les utilisateurs payants, nous avons également mis en place <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\" rel=\"noreferrer\">une limite de taux conservative pour <code>g.jina.ai</code></a>. Avec notre tarification API actuelle de 0,02 $ par 1M de tokens, chaque requête de grounding coûte environ 0,006 USD.</li><li><strong>Contraintes d'applicabilité</strong> : <em>Toutes les déclarations ne peuvent pas ou ne devraient pas être vérifiées.</em> Les opinions ou expériences personnelles, comme \"Je me sens paresseux\", ne se prêtent pas à la vérification. De même, les événements futurs ou les déclarations hypothétiques ne s'appliquent pas. Il existe de nombreux cas où la vérification serait non pertinente ou absurde. Pour éviter les appels API inutiles, nous recommandons aux utilisateurs de soumettre sélectivement uniquement les phrases ou sections qui nécessitent réellement une vérification des faits. Côté serveur, nous avons mis en place un ensemble complet de codes d'erreur pour expliquer pourquoi une déclaration pourrait être rejetée pour la vérification.</li><li><strong>Dépendance à la qualité des données web</strong> : La précision de l'API de grounding n'est que aussi bonne que la qualité des sources qu'elle récupère. Si les résultats de recherche contiennent des informations de faible qualité ou biaisées, le processus de vérification pourrait le refléter, conduisant potentiellement à des conclusions inexactes ou trompeuses. Pour prévenir ce problème, nous permettons aux utilisateurs de spécifier manuellement le paramètre <code>references</code> et de restreindre les URLs que le système recherche. Cela donne aux utilisateurs plus de contrôle sur les sources utilisées pour la vérification, assurant un processus de vérification des faits plus ciblé et pertinent.</li></ul><h2 id=\"conclusion\">Conclusion</h2><p>L'API de grounding offre une expérience de vérification des faits de bout en bout, quasi en temps réel. Les chercheurs peuvent l'utiliser pour trouver des références qui soutiennent ou remettent en question leurs hypothèses, ajoutant de la crédibilité à leur travail. Dans les réunions d'entreprise, elle garantit que les stratégies sont construites sur des informations précises et à jour en validant les hypothèses et les données. Dans les discussions politiques, elle vérifie rapidement les affirmations, apportant plus de responsabilité aux débats.</p><p>Pour l'avenir, nous prévoyons d'améliorer l'API en intégrant des sources de données privées comme les rapports internes, les bases de données et les PDFs pour une vérification des faits plus personnalisée. Nous visons également à augmenter le nombre de sources vérifiées par requête pour des évaluations plus approfondies. L'amélioration des questions-réponses multi-étapes ajoutera de la profondeur à l'analyse, et l'augmentation de la cohérence est une priorité pour garantir que les requêtes répétées produisent des résultats plus fiables et cohérents.</p>",
  "comment_id": "670cd94952567c0001d0f33e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-14T10:41:45.000+02:00",
  "updated_at": "2024-10-15T20:11:23.000+02:00",
  "published_at": "2024-10-15T10:08:02.000+02:00",
  "custom_excerpt": "With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fact-checking-with-new-grounding-api-in-jina-reader/",
  "excerpt": "Avec le nouveau g.jina.ai, vous pouvez facilement ancrer les déclarations pour réduire les hallucinations des LLM ou améliorer l'intégrité du contenu rédigé par les humains.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Jina developer interface showing \"Jina AI was founded in 2020\" with controls labeled true and false, and web address on top.",
  "feature_image_caption": null
}