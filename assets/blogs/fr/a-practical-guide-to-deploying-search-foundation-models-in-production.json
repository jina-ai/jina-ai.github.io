{
  "slug": "a-practical-guide-to-deploying-search-foundation-models-in-production",
  "id": "679b56ba42b46600019a86e3",
  "uuid": "458c0de5-aedb-4513-8ffd-47c027d204ad",
  "title": "Guide pratique pour le d√©ploiement des mod√®les fondamentaux de recherche en production",
  "html": "<p>Chez Jina AI, notre mission est de fournir aux entreprises des solutions de recherche de haute qualit√©. Pour y parvenir, nous rendons nos mod√®les accessibles via diff√©rents canaux. Cependant, choisir le bon canal pour votre cas d'usage sp√©cifique peut s'av√©rer d√©licat. Dans cet article, nous vous guiderons √† travers le processus d√©cisionnel et d√©taillerons les compromis, en vous donnant des conseils pratiques sur la meilleure fa√ßon d'acc√©der √† nos mod√®les de recherche selon votre profil et vos besoins.</p><h2 id=\"jina-search-foundation-models\">Mod√®les de Recherche Fondamentaux de Jina</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Nos Mod√®les de Recherche Fondamentaux</div><div class=\"kg-bookmark-description\">Nous faisons progresser les mod√®les de recherche depuis le premier jour. D√©couvrez l'√©volution de nos mod√®les ci-dessous‚Äîsurvolez ou cliquez pour d√©couvrir chaque √©tape.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-18.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Jina AI</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-models.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Nos mod√®les de recherche fondamentaux incluent :</p><ul><li><strong>Embeddings</strong> : Ils convertissent les informations sur les objets num√©riques en vecteurs d'embedding, capturant leurs caract√©ristiques essentielles.</li><li><strong>Rerankers</strong> : Ils effectuent une analyse s√©mantique approfondie des ensembles requ√™te-document pour am√©liorer la pertinence de la recherche.</li><li><strong>Small language models</strong> : Ils incluent des SLM sp√©cialis√©s comme <code>ReaderLM-v2</code> pour des t√¢ches sp√©cifiques comme HTML2Markdown ou l'extraction d'informations.</li></ul><p>Dans cet article, nous examinerons diff√©rentes options de d√©ploiement pour <code>jina-embeddings-v3</code>, en comparant trois approches principales :</p><ul><li>Utilisation de <a href=\"https://jina.ai/api-dashboard\" rel=\"noreferrer\">l'API Jina</a></li><li>D√©ploiement via un CSP comme <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS SageMaker</a></li><li>Auto-h√©bergement sur un cluster Kubernetes <a href=\"https://jina.ai/api-dashboard/license-config\">sous licence commerciale</a></li></ul><p>La comparaison √©valuera les implications en termes de co√ªts et les avantages de chaque approche pour vous aider √† d√©terminer l'option la plus adapt√©e √† vos besoins.</p><h2 id=\"key-performance-metrics\">M√©triques de Performance Cl√©s</h2><p>Nous avons √©valu√© cinq m√©triques de performance cl√©s dans diff√©rents sc√©narios d'utilisation :</p><ul><li><strong>Taux de Succ√®s des Requ√™tes</strong> : Le pourcentage de requ√™tes r√©ussies vers le serveur d'embedding</li><li><strong>Latence des Requ√™tes</strong> : Le temps n√©cessaire au serveur d'embedding pour traiter et renvoyer une requ√™te</li><li><strong>D√©bit de Tokens</strong> : Le nombre de tokens que le serveur d'embedding peut traiter par seconde</li><li><strong>Co√ªt par Token</strong> : Le co√ªt total de traitement par unit√© de texte</li></ul><p>Pour les embeddings Jina auto-h√©berg√©s sur des clusters Kubernetes, nous avons √©galement examin√© l'impact du <em>dynamic batching</em>. Cette fonctionnalit√© met en file d'attente les requ√™tes jusqu'√† atteindre la taille maximale de lot (8 192 pour <code>jina-embeddings-v3</code>) avant de g√©n√©rer les embeddings.</p><p>Nous avons intentionnellement exclu deux facteurs de performance importants de notre analyse :</p><ul><li><em>Auto-scaling</em> : Bien que crucial pour les d√©ploiements cloud avec des charges variables, son efficacit√© d√©pend de nombreuses variables‚Äîefficacit√© mat√©rielle, architecture r√©seau, latence et choix d'impl√©mentation. Ces complexit√©s d√©passent notre port√©e actuelle. <strong>Notez que l'API Jina inclut la mise √† l'√©chelle automatique, et nos r√©sultats en tiennent compte.</strong></li><li><em>Quantization</em> : Bien que cette technique cr√©e des vecteurs d'embedding plus petits et r√©duise le transfert de donn√©es, les principaux avantages proviennent d'autres composants du syst√®me (stockage des donn√©es et calculs de distance vectorielle) plut√¥t que de la r√©duction du transfert de donn√©es. Comme nous nous concentrons sur les co√ªts d'utilisation directs des mod√®les, nous avons laiss√© la quantization hors de cette analyse.</li></ul><p>Enfin, nous examinerons les implications financi√®res de chaque approche, en consid√©rant √† la fois les co√ªts totaux de possession et les d√©penses par token/requ√™te.</p><h2 id=\"deployment-setup\">Configuration du D√©ploiement</h2><p>Nous avons √©valu√© trois sc√©narios de d√©ploiement et d'utilisation avec <code>jina-embeddings-v3</code> :</p><h3 id=\"using-the-jina-api\">Utilisation de l'API Jina</h3><p>Tous les mod√®les d'embedding de Jina AI sont accessibles via <a href=\"https://jina.ai/api-dashboard/embeddings\" rel=\"noreferrer\">l'API Jina</a>. L'acc√®s fonctionne sur un syst√®me de tokens pr√©pay√©s, avec un million de tokens gratuits pour les tests. Nous avons √©valu√© les performances en effectuant des appels API via Internet depuis nos bureaux en Allemagne.</p><h3 id=\"using-aws-sagemaker\">Utilisation d'AWS SageMaker</h3><p>Jina Embeddings v3 est <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">disponible pour les utilisateurs AWS via SageMaker</a>. L'utilisation n√©cessite un abonnement AWS √† ce mod√®le. Pour le code exemple, nous avons <a href=\"https://github.com/jina-ai/jina-sagemaker/blob/main/notebooks/Real-time%20embedding.ipynb\">fourni un notebook</a> qui montre comment s'abonner et utiliser les mod√®les Jina AI avec un compte AWS.</p><p>Bien que les mod√®les soient √©galement disponibles sur <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Microsoft Azure</a> et <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">Google Cloud Platform</a>, nous avons concentr√© nos tests sur AWS. Nous attendons des performances similaires sur les autres plateformes. Tous les tests ont √©t√© effectu√©s sur une instance <code>ml.g5.xlarge</code> dans la r√©gion <code>us-east-1</code>.</p><h3 id=\"self-hosting-on-kubernetes\">Auto-h√©bergement sur Kubernetes</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Pour obtenir une licence commerciale pour nos mod√®les CC-BY-NC, vous devez d'abord obtenir une licence de notre part. <a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">N'h√©sitez pas √† contacter notre √©quipe commerciale.</a></div></div><p>Nous avons construit une application FastAPI en Python qui <a href=\"https://huggingface.co/jinaai/jina-embeddings-v3\">charge <code>jina-embeddings-v3</code> depuis HuggingFace</a> en utilisant la biblioth√®que <code>SentenceTransformer</code>. L'application inclut deux endpoints :</p><ul><li><code>/embed</code> : Prend des passages de texte en entr√©e et renvoie leurs embeddings</li><li><code>/health</code> : Fournit une surveillance de base de la sant√©</li></ul><p>Nous avons d√©ploy√© cela comme un service Kubernetes sur Amazon Elastic Kubernetes Service, en utilisant une instance <code>g5.xlarge</code> dans <code>us-east-1</code>.</p><h4 id=\"with-and-without-dynamic-batching\">Avec et Sans Dynamic Batching</h4><p>Nous avons test√© les performances dans un cluster Kubernetes dans deux configurations : Une o√π chaque requ√™te √©tait trait√©e imm√©diatement √† sa r√©ception, et une o√π le dynamic batching √©tait utilis√©. Dans le cas du dynamic batching, le service attend jusqu'√† ce que <code>MAX_TOKENS</code> (8192) soient collect√©s dans une file d'attente, ou qu'un timeout pr√©d√©fini de 2 secondes soit atteint, avant d'invoquer le mod√®le et de calculer les embeddings. Cette approche augmente l'utilisation du GPU et r√©duit la fragmentation de la m√©moire GPU.</p><p>Pour chaque sc√©nario de d√©ploiement, nous avons effectu√© des tests en faisant varier trois param√®tres cl√©s :</p><ul><li><strong>Taille de lot</strong> : Chaque requ√™te contenait soit 1, 32, ou 128 passages de texte √† encoder</li><li><strong>Longueur des passages</strong> : Nous avons utilis√© des passages de texte contenant 128, 512, ou 1 024 tokens</li><li><strong>Requ√™tes concurrentes</strong> : Nous avons envoy√© 1, 5, ou 10 requ√™tes simultan√©ment</li></ul><h2 id=\"benchmark-results\">R√©sultats des Tests</h2><p>Le tableau ci-dessous est un r√©sum√© des r√©sultats pour chaque sc√©nario d'utilisation, moyenn√©s sur tous les param√®tres des trois variables ci-dessus.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>M√©trique</th>\n<th>API Jina</th>\n<th>SageMaker</th>\n<th>Auto-h√©berg√©<br>avec Batching</th>\n<th>Auto-h√©berg√©<br>Standard</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Taux de Succ√®s des Requ√™tes</td>\n<td>87,6%</td>\n<td><strong>99,9%</strong></td>\n<td>55,7%</td>\n<td>58,3%</td>\n</tr>\n<tr>\n<td>Latence<br>(secondes)</td>\n<td>11,4</td>\n<td>3,9</td>\n<td>2,7</td>\n<td><strong>2,6</strong></td>\n</tr>\n<tr>\n<td>Latence Normalis√©e par Taux de Succ√®s<br>(secondes)</td>\n<td>13,0</td>\n<td><strong>3,9</strong></td>\n<td>4,9</td>\n<td>4,4</td>\n</tr>\n<tr>\n<td>D√©bit de Tokens<br>(tokens/seconde)</td>\n<td>13,8K</td>\n<td><strong>15,0K</strong></td>\n<td>2,2K</td>\n<td>2,6K</td>\n</tr>\n<tr>\n<td>D√©bit Maximum de Tokens<br>(tokens/seconde)</td>\n<td><strong>63,0K</strong></td>\n<td>32,2K</td>\n<td>10,9K</td>\n<td>10,5K</td>\n</tr>\n<tr>\n<td>Prix<br>(USD par 1M tokens)</td>\n<td>0,02 $</td>\n<td>0,07 $</td>\n<td>0,32 $</td>\n<td>0,32 $</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"request-success-rate\">Taux de Succ√®s des Requ√™tes</h2><p>Les taux de succ√®s dans nos tests vont de pr√®s de 99,9 % pour SageMaker √† un modeste 56-58 % pour les solutions auto-h√©berg√©es, soulignant pourquoi une fiabilit√© √† 100 % reste insaisissable dans les syst√®mes de production. Trois facteurs cl√©s contribuent √† cela :</p><ul><li>L'instabilit√© du r√©seau cause des √©checs in√©vitables m√™me dans les environnements cloud</li><li>La contention des ressources, en particulier la m√©moire GPU, conduit √† des √©checs de requ√™tes sous charge</li><li>Les limites de timeout n√©cessaires signifient que certaines requ√™tes doivent √©chouer pour maintenir la sant√© du syst√®me</li></ul><h3 id=\"success-rate-by-batch-size\">Taux de Succ√®s par Taille de Lot</h3><p>Les grandes tailles de lot causent fr√©quemment des erreurs de m√©moire insuffisante dans la configuration Kubernetes auto-h√©berg√©e. Sans dynamic batching, toutes les requ√™tes contenant 32 ou 128 √©l√©ments par lot ont √©chou√© pour cette raison. M√™me avec le dynamic batching impl√©ment√©, le taux d'√©chec pour les grands lots est rest√© significativement √©lev√©.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8017-ba56-e35215a76fc4\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8064-ab87-e44fc044673d\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">Taille de Lot</th><th id=\"zt<p\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"kPia\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"wgj>\" class=\"simple-table-header-color simple-table-header\">Auto-h√©berg√©<br>(Batching Dynamique)<br></th><th id=\"OwMn\" class=\"simple-table-header-color simple-table-header\">Auto-h√©berg√©<br>(Sans Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-80e1-b4a8-c6f8a3b03117\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"zt<p\" class=\"\">100%</td><td id=\"kPia\" class=\"\">100%</td><td id=\"wgj>\" class=\"\">97.1%</td><td id=\"OwMn\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8096-93c6-deff80bbeffc\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">32</th><td id=\"zt<p\" class=\"\">86.7%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">50.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr><tr id=\"1847c956-b7d2-80fe-a61d-ea3923f34aac\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"zt<p\" class=\"\">76.2%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">24.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr></tbody></table>\n\n<p>Bien que ce probl√®me puisse √™tre facilement r√©solu par l'auto-scaling, nous avons choisi de ne pas explorer cette option ici. L'auto-scaling entra√Ænerait des augmentations de co√ªts impr√©visibles, et il serait difficile de fournir des informations exploitables √©tant donn√© le grand nombre d'options de configuration d'auto-scaling disponibles.</p>\n\n<h3 id=\"success-rate-by-concurrency-level\">Taux de r√©ussite par niveau de concurrence</h3>\n\n<p>La concurrence ‚Äî la capacit√© √† g√©rer plusieurs requ√™tes simultan√©ment ‚Äî n'a eu ni un impact fort ni constant sur les taux de r√©ussite des requ√™tes dans les configurations Kubernetes auto-h√©berg√©es, et seulement un effet minimal sur AWS SageMaker, au moins jusqu'√† un niveau de concurrence de 10.</p>\n\n<table id=\"1847c956-b7d2-80a7-9beb-f1ebe6e1e529\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8011-bcc1-d295e87b8e54\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">Concurrence</th><th id=\"KV|=\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"G@`e\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"[~nZ\" class=\"simple-table-header-color simple-table-header\">Auto-h√©berg√©<br>(Batching Dynamique)<br></th><th id=\"mHG:\" class=\"simple-table-header-color simple-table-header\">Auto-h√©berg√©<br>(Sans Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8041-9a23-c1338c5d3f23\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"KV|=\" class=\"\">93.3%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">57.5%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80eb-86a9-f249c86ddfdf\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">5</th><td id=\"KV|=\" class=\"\">85.7%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">58.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80ac-a3ad-eadd81c69cb2\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">10</th><td id=\"KV|=\" class=\"\">83.8%</td><td id=\"G@`e\" class=\"\">99.6%</td><td id=\"[~nZ\" class=\"\">55.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr></tbody></table>\n\n<h3 id=\"success-rate-by-token-length\">Taux de r√©ussite par longueur de token</h3>\n\n<p>Les longs passages avec un nombre √©lev√© de tokens affectent √† la fois la Jina Embedding API et Kubernetes avec batching dynamique de mani√®re similaire aux grands lots : √† mesure que la taille augmente, le taux d'√©chec augmente consid√©rablement. Cependant, alors que les solutions auto-h√©berg√©es sans batching dynamique √©chouent presque invariablement avec de grands lots, elles fonctionnent mieux avec des passages longs individuels. Quant √† SageMaker, les longueurs de passage importantes - comme la concurrence et la taille des lots - n'ont eu aucun impact notable sur les taux de r√©ussite des requ√™tes.</p>\n\n<table id=\"1847c956-b7d2-8003-8d50-eddc36a83d33\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-804b-8352-d65d5e6bdd0e\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">Longueur du passage<br>(tokens)<br></th><th id=\"CDn]\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"@nCV\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"H?G{\" class=\"simple-table-header-color simple-table-header\">Auto-h√©berg√©<br>(Batching Dynamique)<br></th><th id=\"]{Mf\" class=\"simple-table-header-color simple-table-header\">Auto-h√©berg√©<br>(Sans Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8011-8a92-d0986d045c79\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">98.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-809f-b073-fa48e7287c13\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">512</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">66.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8019-9f1f-cefd810c520d\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">1024</th><td id=\"CDn]\" class=\"\">99.3%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">33.3%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80c7-a745-fcdaf408f3d0\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">8192</th><td id=\"CDn]\" class=\"\">51.1%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">29.4%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr></tbody></table>\n\n<h2 id=\"request-latency\">Latence des requ√™tes</h2>\n\n<p>Tous les tests de latence ont √©t√© r√©p√©t√©s cinq fois √† des niveaux de concurrence de 1, 5 et 10. Le temps de r√©ponse est la moyenne sur cinq tentatives. Le d√©bit des requ√™tes est l'inverse du temps de r√©ponse en secondes, multipli√© par la concurrence.</p>\n\n<h3 id=\"jina-api\">Jina API</h3>\n\n<p>Les temps de r√©ponse dans la Jina API sont principalement influenc√©s par la taille du lot, quel que soit le niveau de concurrence. Bien que la longueur du passage affecte √©galement les performances, son impact n'est pas simple. En r√®gle g√©n√©rale, les requ√™tes contenant plus de donn√©es - que ce soit par des tailles de lots plus importantes ou des passages plus longs - prennent plus de temps √† traiter.</p>\n\n<h4 id=\"concurrency-1\">Concurrence 1 :</h4>\n\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (en tokens)</th>\n<th>Temps de r√©ponse en ms</th>\n<th>D√©bit des requ√™tes (requ√™tes/seconde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>801</td>\n<td>1.25</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>724</td>\n<td>1.38</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>614</td>\n<td>1.63</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1554</td>\n<td>0.64</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1620</td>\n<td>0.62</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2283</td>\n<td>0.44</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4441</td>\n<td>0.23</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5430</td>\n<td>0.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>6332</td>\n<td>0.16</td>\n</tr>\n</tbody>\n</table><h4 id=\"concurrency-5\">Concurrence 5 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (en tokens)</th>\n<th>Temps de r√©ponse en ms</th>\n<th>D√©bit de requ√™tes (requ√™tes/seconde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>689</td>\n<td>7,26</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>599</td>\n<td>8,35</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>876</td>\n<td>5,71</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1639</td>\n<td>3,05</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2511</td>\n<td>1,99</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4728</td>\n<td>1,06</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2766</td>\n<td>1,81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5911</td>\n<td>0,85</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>18621</td>\n<td>0,27</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10\">Concurrence 10 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (en tokens)</th>\n<th>Temps de r√©ponse en ms</th>\n<th>D√©bit de requ√™tes (requ√™tes/seconde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>790</td>\n<td>12,66</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>669</td>\n<td>14,94</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>649</td>\n<td>15,41</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1384</td>\n<td>7,23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3409</td>\n<td>2,93</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>8484</td>\n<td>1,18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3441</td>\n<td>2,91</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>13070</td>\n<td>0,77</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>17886</td>\n<td>0,56</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Pour les requ√™tes individuelles (taille de lot de 1) :</p><ul><li>Les temps de r√©ponse restent relativement stables, variant de 600 √† 800 ms environ, quelle que soit la longueur du passage</li><li>Une concurrence plus √©lev√©e (5 ou 10 requ√™tes simultan√©es) ne d√©grade pas significativement les performances par requ√™te</li></ul><p>Pour les lots plus importants (32 et 128 √©l√©ments) :</p><ul><li>Les temps de r√©ponse augmentent consid√©rablement, avec une taille de lot de 128 prenant environ 4 √† 6 fois plus de temps que les requ√™tes individuelles</li><li>L'impact de la longueur du passage devient plus prononc√© avec des lots plus importants</li><li>√Ä haute concurrence (10) et grands lots (128), la combinaison conduit √† des temps de r√©ponse significativement plus longs, atteignant pr√®s de 18 secondes pour les passages les plus longs</li></ul><p>Pour le d√©bit :</p><ul><li>Les petits lots obtiennent g√©n√©ralement un meilleur d√©bit lors de l'ex√©cution de requ√™tes concurrentes</li><li>√Ä une concurrence de 10 avec une taille de lot de 1, le syst√®me atteint son d√©bit le plus √©lev√© d'environ 15 requ√™tes/seconde</li><li>Les lots plus importants montrent syst√©matiquement un d√©bit plus faible, descendant √† moins d'une requ√™te/seconde dans plusieurs sc√©narios</li></ul><h3 id=\"aws-sagemaker\">AWS SageMaker</h3><p>Les tests AWS SageMaker ont √©t√© effectu√©s avec une instance <code>ml.g5.xlarge</code>.</p><h4 id=\"concurrency-1-1\">Concurrence 1 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (en tokens)</th>\n<th>Temps de r√©ponse en ms</th>\n<th>D√©bit de requ√™tes (requ√™tes/seconde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>189</td>\n<td>5,28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>219</td>\n<td>4,56</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>221</td>\n<td>4,53</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>377</td>\n<td>2,66</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3931</td>\n<td>0,33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2215</td>\n<td>0,45</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>1120</td>\n<td>0,89</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>3408</td>\n<td>0,29</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>5765</td>\n<td>0,17</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-1\">Concurrence 5 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (en tokens)</th>\n<th>Temps de r√©ponse en ms</th>\n<th>D√©bit de requ√™tes (requ√™tes/seconde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>443</td>\n<td>11,28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>426</td>\n<td>11,74</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>487</td>\n<td>10,27</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1257</td>\n<td>3,98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2245</td>\n<td>2,23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4159</td>\n<td>1,20</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2444</td>\n<td>2,05</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>6967</td>\n<td>0,72</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>14438</td>\n<td>0,35</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-1\">Concurrence 10 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (en tokens)</th>\n<th>Temps de r√©ponse en ms</th>\n<th>D√©bit de requ√™tes (requ√™tes/seconde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>585</td>\n<td>17,09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>602</td>\n<td>16,60</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>687</td>\n<td>14,56</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1650</td>\n<td>6,06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3555</td>\n<td>2,81</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>7070</td>\n<td>1,41</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3867</td>\n<td>2,59</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>12421</td>\n<td>0,81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>25989</td>\n<td>0,38</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Diff√©rences principales par rapport √† l'API Jina :</p><ul><li>Performance de base : SageMaker est significativement plus rapide pour les petites requ√™tes (√©l√©ments uniques, passages courts) - environ 200 ms contre 700-800 ms pour Jina.</li><li>Comportement √† l'√©chelle :<ul><li>Les deux services ralentissent avec des lots plus importants et des passages plus longs</li><li>SageMaker montre un ralentissement plus drastique avec des lots importants (128) et des passages longs (1024 tokens)</li><li>√Ä haute concurrence (10) avec une charge maximale (lot 128, 1024 tokens), SageMaker prend ~26s contre ~18s pour Jina</li></ul></li><li>Impact de la concurrence :<ul><li>Les deux services b√©n√©ficient d'une concurrence accrue pour le d√©bit</li><li>Les deux maintiennent des mod√®les de d√©bit similaires √† travers les niveaux de concurrence</li></ul></li><li>SageMaker atteint un d√©bit de pointe l√©g√®rement sup√©rieur (17 req/s contre 15 req/s) √† une concurrence de 10</li></ul></li></ul><h3 id=\"self-hosted-kubernetes-cluster\">Cluster Kubernetes auto-h√©berg√©</h3><p>Les tests d'auto-h√©bergement ont √©t√© effectu√©s sur le <a href=\"https://aws.amazon.com/eks/\">Service Kubernetes Elastic d'Amazon</a> avec une instance <code>g5.xlarge</code>.</p><h4 id=\"concurrency-1-2\">Concurrence 1 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (tokens)</th>\n<th>Temps sans lot (ms)</th>\n<th>D√©bit sans lot (req/s)</th>\n<th>Temps dynamique (ms)</th>\n<th>D√©bit dynamique (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>416</td>\n<td>2.40</td>\n<td>2389</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>397</td>\n<td>2.52</td>\n<td>2387</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>396</td>\n<td>2.52</td>\n<td>2390</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1161</td>\n<td>0.86</td>\n<td>3059</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1555</td>\n<td>0.64</td>\n<td>1496</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2424</td>\n<td>0.41</td>\n<td>2270</td>\n<td>0.44</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-2\">Concurrence 5 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (tokens)</th>\n<th>Temps sans lot (ms)</th>\n<th>D√©bit sans lot (req/s)</th>\n<th>Temps dynamique (ms)</th>\n<th>D√©bit dynamique (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>451</td>\n<td>11.08</td>\n<td>2401</td>\n<td>2.08</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>453</td>\n<td>11.04</td>\n<td>2454</td>\n<td>2.04</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>478</td>\n<td>10.45</td>\n<td>2520</td>\n<td>1.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1447</td>\n<td>3.46</td>\n<td>1631</td>\n<td>3.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2867</td>\n<td>1.74</td>\n<td>2669</td>\n<td>1.87</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4154</td>\n<td>1.20</td>\n<td>4026</td>\n<td>1.24</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-2\">Concurrence 10 :</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (tokens)</th>\n<th>Temps sans lot (ms)</th>\n<th>D√©bit sans lot (req/s)</th>\n<th>Temps dynamique (ms)</th>\n<th>D√©bit dynamique (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>674</td>\n<td>14.84</td>\n<td>2444</td>\n<td>4.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>605</td>\n<td>16.54</td>\n<td>2498</td>\n<td>4.00</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>601</td>\n<td>16.64</td>\n<td>781*</td>\n<td>12.80</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>2089</td>\n<td>4.79</td>\n<td>2200</td>\n<td>4.55</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>5005</td>\n<td>2.00</td>\n<td>4450</td>\n<td>2.24</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>7331</td>\n<td>1.36</td>\n<td>7127</td>\n<td>1.40</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">‚Ä† Ce r√©sultat anormal est d√ª au d√©lai d'attente de 2 secondes du traitement par lots dynamique. Avec une concurrence de 10, chacun envoyant 1024 tokens de donn√©es, la file d'attente se remplit presque imm√©diatement et le syst√®me de traitement par lots n'a jamais √† attendre un d√©lai d'expiration. Pour des tailles et des concurrences plus faibles, il le fait, ajoutant automatiquement deux secondes gaspill√©es √† chaque requ√™te. Ce type de non-lin√©arit√© est courant dans les processus par lots sous-optimis√©s.</div></div><p>Lorsque des requ√™tes de plus de 16 384 tokens ont √©t√© soumises, notre configuration auto-h√©berg√©e a √©chou√© avec des erreurs serveur, g√©n√©ralement des erreurs de m√©moire insuffisante. Cela √©tait vrai ind√©pendamment des niveaux de concurrence. Par cons√©quent, aucun test avec plus de donn√©es n'est affich√©.</p><p>Une concurrence √©lev√©e a augment√© les temps de r√©ponse de mani√®re globalement lin√©aire : les niveaux de concurrence de 5 ont pris environ cinq fois plus de temps pour r√©pondre que 1. Les niveaux de 10, dix fois plus longtemps.</p><p>Le traitement par lots dynamique ralentit les temps de r√©ponse d'environ deux secondes pour les petits lots. Cela est attendu car la file d'attente de traitement par lots attend 2 secondes avant de traiter un lot incomplet. Cependant, pour des tailles de lots plus importantes, il apporte des am√©liorations mod√©r√©es du temps de r√©ponse.</p><h2 id=\"token-throughput\">D√©bit de tokens</h2><p>Le d√©bit de tokens augmente avec des tailles de lots plus importantes, des longueurs de passage plus longues et des niveaux de concurrence plus √©lev√©s sur toutes les plateformes. Par cons√©quent, nous ne pr√©senterons que les r√©sultats √† des niveaux d'utilisation √©lev√©s, car les niveaux inf√©rieurs ne fourniraient pas d'indication significative des performances en conditions r√©elles.</p><p>Tous les tests ont √©t√© effectu√©s avec un niveau de concurrence de 10, avec 16 384 tokens par requ√™te, moyenn√©s sur cinq requ√™tes. Nous avons test√© deux configurations : taille de lot 32 avec des passages de 512 tokens, et taille de lot 128 avec des passages de 128 tokens. Le nombre total de tokens reste constant dans les deux configurations.</p><p>D√©bit de tokens (tokens par seconde) :</p><table>\n<thead>\n<tr>\n<th>Taille du lot</th>\n<th>Longueur du passage (tokens)</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>Auto-h√©berg√© (Sans lot)</th>\n<th>Auto-h√©berg√© (Lot dynamique)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>46K</td>\n<td>28,5K</td>\n<td>14,3K</td>\n<td>16,1K</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>42,3K</td>\n<td>27,6K</td>\n<td>9,7K</td>\n<td>10,4K</td>\n</tr>\n</tbody>\n</table>\n<p>Dans des conditions de charge √©lev√©e, l'API Jina surpasse significativement les alternatives, tandis que les solutions auto-h√©berg√©es test√©es ici montrent des performances nettement inf√©rieures.</p><h2 id=\"costs-per-million-tokens\">Co√ªts par million de tokens</h2><p>Le co√ªt est sans doute le facteur le plus critique lors du choix d'une solution d'embedding. Bien que le calcul des co√ªts des mod√®les d'IA puisse √™tre complexe, voici une analyse comparative des diff√©rentes options :</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Type de service</th>\n<th>Co√ªt par million de tokens</th>\n<th>Co√ªt d'infrastructure</th>\n<th>Co√ªt de licence</th>\n<th>Co√ªt horaire total</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina API</td>\n<td>0,018-0,02 $</td>\n<td>N/A</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>SageMaker (US East)</td>\n<td>0,0723 $</td>\n<td>1,408 $/heure</td>\n<td>2,50 $/heure</td>\n<td>3,908 $/heure</td>\n</tr>\n<tr>\n<td>SageMaker (EU)</td>\n<td>0,0788 $</td>\n<td>1,761 $/heure</td>\n<td>2,50 $/heure</td>\n<td>4,261 $/heure</td>\n</tr>\n<tr>\n<td>Auto-h√©berg√© (US East)</td>\n<td>0,352 $</td>\n<td>1,006 $/heure</td>\n<td>2,282 $/heure</td>\n<td>3,288 $/heure</td>\n</tr>\n<tr>\n<td>Auto-h√©berg√© (EU)</td>\n<td>0,379 $</td>\n<td>1,258 $/heure</td>\n<td>2,282 $/heure</td>\n<td>3,540 $/heure</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"jina-api-1\">Jina API</h3><p>Le service suit un mod√®le de tarification bas√© sur les tokens avec deux niveaux pr√©pay√©s :</p><ul><li>20 $ pour 1 milliard de tokens (0,02 $ par million) - Un tarif d'entr√©e id√©al pour le prototypage et le d√©veloppement</li><li>200 $ pour 11 milliards de tokens (0,018 $ par million) - Un tarif plus √©conomique pour les volumes plus importants</li></ul><p>Il est √† noter que ces tokens fonctionnent sur l'ensemble de la suite de produits Jina, y compris les lecteurs, les reclasseurs et les classificateurs zero-shot.</p><h3 id=\"aws-sagemaker-1\">AWS SageMaker</h3><p>La tarification SageMaker combine les co√ªts horaires des instances avec les frais de licence du mod√®le. En utilisant une instance <code>ml.g5.xlarge</code> :</p><ul><li>Co√ªt de l'instance : 1,408 $/heure (US Est) ou 1,761 $/heure (UE Francfort)</li><li>Licence <code>jina-embeddings-v3</code> : 2,50 $/heure</li><li>Co√ªt horaire total : 3,908-4,261 $ selon la r√©gion</li></ul><p>Avec un d√©bit moyen de 15 044 tokens/seconde (54,16M tokens/heure), le co√ªt par million de tokens varie de 0,0723 $ √† 0,0788 $.</p><h3 id=\"self-hosting-with-kubernetes\">Auto-h√©bergement avec Kubernetes</h3><p>Les co√ªts d'auto-h√©bergement varient consid√©rablement selon votre choix d'infrastructure. En prenant comme r√©f√©rence l'instance <code>g5.xlarge</code> d'AWS EC2 :</p><ul><li>Co√ªt de l'instance : 1,006 $/heure (US Est) ou 1,258 $/heure (UE Francfort)</li><li>Licence <code>jina-embeddings-v3</code> : 5000 $/trimestre (2,282 $/heure)</li><li>Co√ªt horaire total : 3,288-3,540 $ selon la r√©gion</li></ul><p>√Ä 2 588 tokens/seconde (9,32M tokens/heure), le co√ªt par million de tokens s'√©l√®ve √† 0,352-0,379 $. Bien que le taux horaire soit inf√©rieur √† SageMaker, le d√©bit r√©duit entra√Æne des co√ªts par token plus √©lev√©s.</p><p>Consid√©rations importantes pour l'auto-h√©bergement :</p><ul><li>Les co√ªts fixes (licences, infrastructure) continuent ind√©pendamment de l'utilisation</li><li>L'h√©bergement sur site n√©cessite toujours des frais de licence et des co√ªts de personnel</li><li>Les charges de travail variables peuvent avoir un impact significatif sur l'efficacit√© des co√ªts</li></ul><h3 id=\"key-takeaways\">Points cl√©s</h3><p>L'API Jina s'av√®re √™tre la solution la plus rentable, m√™me sans tenir compte des temps de d√©marrage √† froid et en supposant un d√©bit optimal pour les alternatives.</p><p>L'auto-h√©bergement peut √™tre pertinent pour les organisations disposant d√©j√† d'une infrastructure robuste o√π les co√ªts marginaux des serveurs sont minimes. De plus, l'exploration de fournisseurs cloud autres qu'AWS pourrait offrir de meilleurs prix.</p><p>Cependant, pour la plupart des entreprises, en particulier les PME √† la recherche de solutions cl√©s en main, l'API Jina offre une efficacit√© des co√ªts in√©gal√©e.</p><h2 id=\"security-and-data-privacy-considerations\">Consid√©rations sur la s√©curit√© et la confidentialit√© des donn√©es</h2><p>Lors du choix d'une strat√©gie de d√©ploiement pour les mod√®les d'embedding, les exigences en mati√®re de s√©curit√© et de confidentialit√© des donn√©es peuvent jouer un r√¥le d√©cisif aux c√¥t√©s des consid√©rations de performance et de co√ªt. Nous proposons des options de d√©ploiement flexibles pour r√©pondre √† diff√©rents besoins de s√©curit√© :</p><h3 id=\"cloud-service-providers\">Fournisseurs de services cloud</h3><p>Pour les <strong>entreprises travaillant d√©j√† avec les principaux fournisseurs cloud</strong>, nos offres sur les places de march√© cloud (comme <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS Marketplace</a>, <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Azure</a>, et <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">GCP</a>) fournissent une solution naturelle pour le d√©ploiement dans les cadres de s√©curit√© pr√©existants. Ces d√©ploiements b√©n√©ficient de :</p><ul><li>Contr√¥les de s√©curit√© et conformit√© h√©rit√©s de votre relation avec le CSP</li><li>Int√©gration facile avec les politiques de s√©curit√© et les r√®gles de gouvernance des donn√©es existantes</li><li>N√©cessite peu ou pas de changements aux accords de traitement des donn√©es existants</li><li>Alignement avec les consid√©rations de souverainet√© des donn√©es pr√©existantes</li></ul><h3 id=\"self-hosting-and-local-deployment\">Auto-h√©bergement et d√©ploiement local</h3><p>Les <strong>organisations ayant des exigences de s√©curit√© strictes ou des obligations r√©glementaires sp√©cifiques</strong> pr√©f√®rent souvent un contr√¥le physique complet sur leur infrastructure. Notre option d'auto-h√©bergement permet :</p><ul><li>Un contr√¥le total sur l'environnement de d√©ploiement</li><li>Le traitement des donn√©es enti√®rement dans votre p√©rim√®tre de s√©curit√©</li><li>L'int√©gration avec les contr√¥les et la surveillance de s√©curit√© existants</li></ul><p>Pour obtenir une licence commerciale pour nos mod√®les CC-BY-NC, vous devez d'abord obtenir une licence aupr√®s de nous. <a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">N'h√©sitez pas √† contacter notre √©quipe commerciale.</a></p><h3 id=\"jina-api-service\">Service API Jina</h3><p>Pour les <strong>startups et PME</strong> cherchant √† √©quilibrer s√©curit√© et commodit√© par rapport aux co√ªts, notre service API fournit une s√©curit√© de niveau entreprise sans ajouter de charge op√©rationnelle :</p><ul><li><a href=\"https://jina.ai/Jina_AI_GmbH_Letter_of_Attestation_SOC_2_Type_1.pdf\" rel=\"noreferrer\">Certification SOC2</a> assurant des contr√¥les de s√©curit√© robustes</li><li><a href=\"https://gdpr-info.eu/\" rel=\"noreferrer\">Conformit√© RGPD compl√®te</a> pour le traitement des donn√©es</li><li>Politique de r√©tention z√©ro des donn√©es - nous ne stockons ni ne journalisons vos requ√™tes</li><li>Transmission de donn√©es chiffr√©e et infrastructure s√©curis√©e</li></ul><p>Les offres de mod√®les de Jina AI permettent aux organisations de choisir la strat√©gie de d√©ploiement qui s'aligne le mieux avec leurs exigences de s√©curit√© tout en maintenant l'efficacit√© op√©rationnelle.</p><h2 id=\"choosing-your-solution\">Choisir votre solution</h2><p>L'organigramme ci-dessous r√©sume les r√©sultats de tous les tests empiriques et tableaux que vous avez vus :</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1256\" height=\"1980\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png 1256w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Avec ces informations en main, l'organigramme ci-dessus devrait vous donner une bonne indication des types de solutions √† envisager.</span></figcaption></figure><p>Commencez par consid√©rer vos besoins en s√©curit√© et la flexibilit√© que vous pouvez sacrifier pour les satisfaire.</p><p>Ensuite, consid√©rez comment vous pr√©voyez d'utiliser l'IA dans votre entreprise :</p><ol><li>Indexation hors ligne et cas d'utilisation non sensibles au temps qui peuvent utiliser de mani√®re optimale le traitement par lots.</li><li>Utilisations sensibles √† la fiabilit√© et √† l'√©volutivit√© comme la g√©n√©ration augment√©e par r√©cup√©ration et l'int√©gration LLM.</li><li>Utilisations sensibles au temps comme la recherche et la r√©cup√©ration en ligne.</li></ol><p>Consid√©rez √©galement votre expertise interne et l'infrastructure existante :</p><ol><li>Votre stack technique est-elle d√©j√† fortement d√©pendante du cloud ?</li><li>Disposez-vous d'une grande op√©ration IT interne capable d'auto-h√©berger ?</li></ol><p>Enfin, consid√©rez vos volumes de donn√©es attendus. √ätes-vous un utilisateur √† grande √©chelle qui pr√©voit d'effectuer des millions d'op√©rations utilisant des mod√®les d'IA chaque jour ?</p><h2 id=\"conclusion\">Conclusion</h2><p>L'int√©gration de l'IA dans les d√©cisions op√©rationnelles reste un territoire inexplor√© pour de nombreux d√©partements IT, car le march√© manque de solutions cl√©s en main √©tablies. Cette incertitude peut rendre la planification strat√©gique difficile. Notre analyse quantitative vise √† fournir des conseils concrets sur l'incorporation de nos mod√®les de recherche fondamentaux dans vos flux de travail et applications sp√©cifiques.</p><p>En termes de co√ªt unitaire, l'API Jina se distingue comme l'une des options les plus √©conomiques disponibles pour les entreprises. Peu d'alternatives peuvent √©galer notre prix tout en offrant des fonctionnalit√©s comparables.</p><p>Nous nous engageons √† fournir des capacit√©s de recherche qui sont non seulement puissantes et conviviales, mais aussi rentables pour les organisations de toutes tailles. Que ce soit via les principaux fournisseurs cloud ou des d√©ploiements auto-h√©berg√©s, nos solutions s'adaptent m√™me aux exigences d'entreprise les plus complexes qui vont au-del√† des simples consid√©rations de co√ªt. Cette analyse d√©compose les diff√©rents facteurs de co√ªt pour aider √† √©clairer votre prise de d√©cision.</p><p>√âtant donn√© que chaque organisation a ses propres exigences uniques, nous reconnaissons qu'un seul article ne peut pas couvrir tous les sc√©narios. Si vous avez des besoins sp√©cifiques non couverts ici, n'h√©sitez pas √† nous contacter pour discuter de la meilleure fa√ßon de soutenir votre mise en ≈ìuvre.</p>",
  "comment_id": "679b56ba42b46600019a86e3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-01-30T11:38:50.000+01:00",
  "updated_at": "2025-01-31T05:32:29.000+01:00",
  "published_at": "2025-01-31T05:32:29.000+01:00",
  "custom_excerpt": "We offer detailed cost and performance breakdowns for three deployment strategies: Jina API, self-hosted K8s, and AWS SageMaker, to help you make the right decision.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "641c23a2f4d50d003d590474",
    "name": "Saahil Ognawala",
    "slug": "saahil",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
    "cover_image": null,
    "bio": "Senior Product Manager at Jina AI",
    "website": "http://www.saahilognawala.com/",
    "location": "Munich, DE",
    "facebook": null,
    "twitter": "@saahil",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-deploying-search-foundation-models-in-production/",
  "excerpt": "Nous proposons des analyses d√©taill√©es des co√ªts et des performances pour trois strat√©gies de d√©ploiement : l'API Jina, l'h√©bergement autonome sur K8s et AWS SageMaker, pour vous aider √† prendre la bonne d√©cision.",
  "reading_time": 14,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}