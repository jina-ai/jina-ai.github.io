{
  "slug": "fact-checking-with-new-grounding-api-in-jina-reader",
  "id": "670cd94952567c0001d0f33e",
  "uuid": "20c36ec7-687f-47c8-8cfd-8da526a70859",
  "title": "Faktenprüfung mit der neuen Grounding API in Jina Reader",
  "html": "<p>Grounding ist für GenAI-Anwendungen <em>absolut essentiell</em>.</p><p>Ohne Grounding neigen LLMs stärker zu Halluzinationen und der Generierung ungenauer Informationen, besonders wenn ihre Trainingsdaten aktuelles oder spezifisches Wissen nicht enthalten. Egal wie stark die Schlussfolgerungsfähigkeit eines LLM ist, es kann einfach keine korrekte Antwort liefern, wenn die Information <em>nach</em> seinem Wissens-Stichtag eingeführt wurde.</p><p>Grounding ist nicht nur für LLMs wichtig, sondern auch für von Menschen geschriebene Inhalte, um Fehlinformationen zu verhindern. Ein hervorragendes Beispiel sind <a href=\"https://communitynotes.x.com/guide/en/about/introduction?ref=jina-ai-gmbh.ghost.io\">X's Community Notes</a>, wo Nutzer gemeinsam Kontext zu potenziell irreführenden Beiträgen hinzufügen. Dies unterstreicht den Wert von Grounding, das die faktische Genauigkeit durch klare Quellen und Referenzen sicherstellt, ähnlich wie Community Notes hilft, die Informationsintegrität zu wahren.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png\" class=\"kg-image\" alt=\"Screenshot of a mobile chat in the Sage app discussing whether whales are mammals and how they hydrate, with options to rate \" loading=\"lazy\" width=\"2000\" height=\"1113\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Mit <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a> haben wir aktiv an einer benutzerfreundlichen Grounding-Lösung gearbeitet. Zum Beispiel wandelt <code>r.jina.ai</code> Webseiten in LLM-freundliches Markdown um, und <code>s.jina.ai</code> aggregiert Suchergebnisse basierend auf einer gegebenen Anfrage in ein einheitliches Markdown-Format.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs or search the web, get better grounding for LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-9.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><strong>Heute freuen wir uns, einen neuen Endpunkt zu dieser Suite vorzustellen: <code>g.jina.ai</code>. </strong>Die neue API nimmt eine gegebene Aussage, überprüft sie mithilfe von Echtzeit-Websuchen und gibt einen Faktizitätswert sowie <strong>die genauen verwendeten Referenzen</strong> zurück. Unsere Experimente zeigen, dass diese API im Vergleich zu Modellen wie GPT-4, o1-mini und Gemini 1.5 Flash & Pro mit Suchgrounding einen höheren F1-Score beim Fact-Checking erreicht.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Evaluation-of-grounding-solutions-on-fact-checking-100-statements--1-.svg\" class=\"kg-image\" alt=\"Bar graph illustrating the evaluation of various grounding solutions for fact-checking 100 statements, with software scores r\" loading=\"lazy\" width=\"1218\" height=\"371\"><figcaption><span style=\"white-space: pre-wrap;\">Wir haben manuell 100 Aussagen mit Ground-Truth-Labels „wahr\" oder „falsch\" gesammelt und verschiedene Methoden verwendet, um zu bestimmen, ob sie überprüft werden konnten. Dieser Prozess verwandelt die Aufgabe im Wesentlichen in ein binäres Klassifikationsproblem, wobei die endgültige Leistung durch den F1-Score gemessen wird – je höher, desto besser.</span></figcaption></figure><p>Was <code>g.jina.ai</code> von Geminis Search Grounding unterscheidet, ist, dass jedes Ergebnis bis zu 30 URLs enthält (typischerweise mindestens 10), jeweils mit direkten Zitaten, die zur Schlussfolgerung beitragen. Hier ist ein Beispiel für das Grounding der Aussage <code>\"The latest model released by Jina AI is jina-embeddings-v3,\"</code> mit <code>g.jina.ai</code> (Stand 14. Oktober 2024). Erkunden Sie den <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">API-Playground</a>, um die vollständigen Funktionen zu entdecken. Beachten Sie, dass <a href=\"#limitations\" rel=\"noreferrer\">Einschränkungen</a> gelten:</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-bash\">curl -X POST https://g.jina.ai \\\n     -H \"Content-Type: application/json\" \\\n     -H \"Authorization: Bearer $YOUR_JINA_TOKEN\" \\\n     -d '{\n           \"statement\":\"the last model released by Jina AI is jina-embeddings-v3\"\n         }'</code></pre><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>YOUR_JINA_TOKEN</span></code><span style=\"white-space: pre-wrap;\"> ist Ihr Jina AI API-Schlüssel. Sie können </span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">1M kostenlose Token von unserer Homepage erhalten</span></a><span style=\"white-space: pre-wrap;\">, was etwa drei bis vier kostenlose Versuche ermöglicht. Mit dem aktuellen API-Preis von 0,02 USD pro 1M Token kostet jede Grounding-Anfrage etwa 0,006 USD.</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"code\": 200,\n  \"status\": 20000,\n  \"data\": {\n    \"factuality\": 0.95,\n    \"result\": true,\n    \"reason\": \"The majority of the references explicitly support the statement that the last model released by Jina AI is jina-embeddings-v3. Multiple sources, such as the arXiv paper, Jina AI's news, and various model documentation pages, confirm this assertion. Although there are a few references to the jina-embeddings-v2 model, they do not provide evidence contradicting the release of a subsequent version (jina-embeddings-v3). Therefore, the statement that 'the last model released by Jina AI is jina-embeddings-v3' is well-supported by the provided documentation.\",\n    \"references\": [\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"arXiv September 18, 2024 jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"We introduce jina-embeddings-v3, a novel text embedding model with 570 million parameters, achieves state-of-the-art performance on multilingual data and long-context retrieval tasks, supporting context lengths of up to 8192 tokens.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview\",\n        \"keyQuote\": \"jina-embeddings-v3 is a multilingual multi-task text embedding model designed for a variety of NLP applications.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://docs.pinecone.io/models/jina-embeddings-v3\",\n        \"keyQuote\": \"Jina Embeddings v3 is the latest iteration in the Jina AI's text embedding model series, building upon Jina Embedding v2.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://haystack.deepset.ai/integrations/jina\",\n        \"keyQuote\": \"Recommended Model: jina-embeddings-v3 : We recommend jina-embeddings-v3 as the latest and most performant embedding model from Jina AI.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"The embedding model was trained using 512 sequence length, but extrapolates to 8k sequence length (or even longer) thanks to ALiBi.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"With a standard size of 137 million parameters, the model enables fast inference while delivering better performance than our small model.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"We offer an `encode` function to deal with this.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jinaai/jina-embeddings-v3 Feature Extraction • Updated 3 days ago • 278k • 375\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"the latest version (3.1.0) of [SentenceTransformers] also supports jina-embeddings-v3\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/embeddings/\",\n        \"keyQuote\": \"v3: Frontier Multilingual Embeddings is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\",\n        \"keyQuote\": \"Jina Embeddings v3: A Frontier Multilingual Embedding Model jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/\",\n        \"keyQuote\": \"As of its release on September 18, 2024, jina-embeddings-v3 is the best multilingual model ...\",\n        \"isSupportive\": true\n      }\n    ],\n    \"usage\": {\n      \"tokens\": 112073\n    }\n  }\n}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Die Antwort auf das Grounding der Aussage „The latest model released by Jina AI is jina-embeddings-v3\" mit </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>g.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> (Stand 14. Oktober 2024).</span></p></figcaption></figure><h2 id=\"how-does-it-work\">Wie funktioniert es?</h2><p>Im Kern umschließt <code>g.jina.ai</code> die Dienste <code>s.jina.ai</code> und <code>r.jina.ai</code><strong> </strong>und fügt mehrstufiges Reasoning durch Chain of Thought (CoT) hinzu. Dieser Ansatz stellt sicher, dass jede überprüfte Aussage mit Hilfe von Online-Suchen und Dokumentenlesung gründlich analysiert wird.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/User-Render.svg\" class=\"kg-image\" alt=\"UI of Jina AI reader app, displaying three panels: User Input, Response, and User Render with interactive links and buttons a\" loading=\"lazy\" width=\"1400\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">Die Grounding API ist ein Wrapper über </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>s.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> und </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>r.jina.ai</span></code><span style=\"white-space: pre-wrap;\">, der CoT für Planung und Argumentation hinzufügt.</span></figcaption></figure><h3 id=\"step-by-step-explanation\">Schritt-für-Schritt-Erklärung</h3><p>Lassen Sie uns den gesamten Prozess durchgehen, um besser zu verstehen, wie <code>g.jina.ai</code> das Grounding von der Eingabe bis zur endgültigen Ausgabe handhabt:</p><ol><li><strong>Eingabeerklärung</strong>:<br>Der Prozess beginnt, wenn ein Benutzer eine Aussage eingibt, die er überprüfen möchte, wie zum Beispiel <em>\"Das neueste von Jina AI veröffentlichte Modell ist jina-embeddings-v3.\"</em> Beachten Sie, dass keine Faktencheckinganleitungen vor der Aussage hinzugefügt werden müssen.</li><li><strong>Suchanfragen generieren</strong>:<br>Ein LLM wird eingesetzt, um eine Liste einzigartiger Suchanfragen zu generieren, die für die Aussage relevant sind. Diese Anfragen zielen darauf ab, verschiedene faktische Elemente abzudecken und sicherzustellen, dass die Suche alle wichtigen Aspekte der Aussage umfassend abdeckt.</li><li><strong>Aufruf von <code>s.jina.ai</code> für jede Anfrage</strong>:<br>Für jede generierte Anfrage führt <code>g.jina.ai</code> eine Websuche mit <code>s.jina.ai</code> durch. Die Suchergebnisse bestehen aus einer vielfältigen Sammlung von Websites oder Dokumenten, die mit den Anfragen in Verbindung stehen. Im Hintergrund ruft <code>s.jina.ai</code> <code>r.jina.ai</code> auf, um den Seiteninhalt abzurufen.</li><li><strong>Referenzen aus Suchergebnissen extrahieren</strong>:<br>Aus jedem während der Suche abgerufenen Dokument extrahiert ein LLM die wichtigsten Referenzen. Diese Referenzen beinhalten:<ul><li><strong><code>url</code></strong>: Die Webadresse der Quelle.</li><li><strong><code>keyQuote</code></strong>: Ein direktes Zitat oder ein Auszug aus dem Dokument.</li><li><strong><code>isSupportive</code></strong>: Ein Boolean-Wert, der angibt, ob die Referenz die ursprüngliche Aussage unterstützt oder widerlegt.</li></ul></li><li><strong>Referenzen zusammenfassen und kürzen</strong>:<br>Alle Referenzen aus den abgerufenen Dokumenten werden in einer einzigen Liste zusammengefasst. Wenn die Gesamtzahl der Referenzen 30 übersteigt, wählt das System 30 zufällige Referenzen aus, um eine handhabbare Ausgabe zu gewährleisten.</li><li><strong>Aussage auswerten</strong>:<br>Der Auswertungsprozess umfasst die Verwendung eines LLM zur Bewertung der Aussage basierend auf den gesammelten Referenzen (bis zu 30). Zusätzlich zu diesen externen Referenzen spielt auch das interne Wissen des Modells eine Rolle bei der Auswertung. Das Endergebnis enthält:<ul><li><strong><code>factuality</code></strong>: Eine Punktzahl zwischen 0 und 1, die die faktische Genauigkeit der Aussage einschätzt.</li><li><strong><code>result</code></strong>: Ein Boolean-Wert, der angibt, ob die Aussage wahr oder falsch ist.</li><li><strong><code>reason</code></strong>: Eine detaillierte Erklärung, warum die Aussage als korrekt oder inkorrekt beurteilt wird, mit Verweisen auf die unterstützenden oder widersprechenden Quellen.</li></ul></li><li><strong>Ergebnis ausgeben</strong>:<br>Sobald die Aussage vollständig ausgewertet wurde, wird die Ausgabe generiert. Diese enthält den <strong>Faktualitätswert</strong>, die <strong>Beurteilung der Aussage</strong>, eine <strong>detaillierte Begründung</strong> und eine Liste von <strong>Referenzen</strong> mit Zitaten und URLs. Die Referenzen beschränken sich auf das Zitat, die URL und die Information, ob sie die Aussage unterstützen oder nicht, um die Ausgabe klar und präzise zu halten.</li></ol><h2 id=\"benchmark\">Benchmark</h2><p>Wir haben manuell 100 Aussagen mit Wahrheitswerten von entweder <code>true</code> (62 Aussagen) oder <code>false</code> (38 Aussagen) gesammelt und verschiedene Methoden verwendet, um zu bestimmen, ob sie überprüft werden können. Dieser Prozess verwandelt die Aufgabe im Wesentlichen in ein binäres Klassifikationsproblem, wobei die endgültige Leistung durch Präzision, Recall und F1-Score gemessen wird – je höher, desto besser.</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1xE-uCTQ4G0cYRw_g781zZXHO8eRYi31HbCb-3BPlNh8/edit?gid=1283553680&ref=jina-ai-gmbh.ghost.io#gid=1283553680\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Grounding Validation Dataset</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyJpf4HNZ3zF1snMGetpmkt0oOTQGGviY1-ZTOrq5dXuafT8uWLmZ806MU1A_agTpgO52Z_xZ-iDougmFm0ViL0sVSqDxe3C4fVuPcYXKoS5O90jN3Qy-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">Die vollständige Liste der Aussagen finden Sie hier.</span></p></figcaption></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Precision</th>\n<th>Recall</th>\n<th>F1 Score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Jina AI Grounding API (g.jina.ai)</strong></td>\n<td>0.96</td>\n<td><strong>0.88</strong></td>\n<td><strong>0.92</strong></td>\n</tr>\n<tr>\n<td>Gemini-flash-1.5-002 w/ grounding</td>\n<td><strong>1.00</strong></td>\n<td>0.73</td>\n<td>0.84</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-002 w/ grounding</td>\n<td>0.98</td>\n<td>0.71</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>gpt-o1-mini</td>\n<td>0.87</td>\n<td>0.66</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>0.95</td>\n<td>0.58</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001 w/ grounding</td>\n<td>0.97</td>\n<td>0.52</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001</td>\n<td>0.95</td>\n<td>0.32</td>\n<td>0.48</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Beachten Sie, dass in der Praxis einige LLMs eine dritte Klasse, <em>Ich weiß es nicht</em>, in ihren Vorhersagen zurückgeben. Für die Evaluierung werden diese Fälle von der Bewertungsberechnung ausgeschlossen. Dieser Ansatz vermeidet es, Unsicherheit so hart zu bestrafen wie falsche Antworten. Das Eingestehen von Unsicherheit wird gegenüber dem Raten bevorzugt, um Modelle davon abzuhalten, unsichere Vorhersagen zu treffen.</p><h2 id=\"limitations\">Einschränkungen</h2><p>Trotz der vielversprechenden Ergebnisse möchten wir einige Einschränkungen der aktuellen Version der Grounding API hervorheben:</p><ul><li><strong>Hohe Latenz &amp; Token-Verbrauch</strong>: Ein einzelner Aufruf von <code>g.jina.ai</code> kann etwa <strong>30 Sekunden</strong> dauern und bis zu <strong>300K Token</strong> verbrauchen, aufgrund der aktiven Websuche, des Seitenlesens und der mehrstufigen Argumentation durch das LLM. Mit einem kostenlosen 1M-Token-API-Schlüssel bedeutet dies, dass Sie es nur etwa drei- bis viermal testen können. Um die Dienstverfügbarkeit für zahlende Nutzer aufrechtzuerhalten, haben wir auch <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\" rel=\"noreferrer\">ein konservatives Rate-Limit für <code>g.jina.ai</code></a> implementiert. Bei unseren aktuellen API-Preisen von 0,02 USD pro 1M Token kostet jede Grounding-Anfrage ungefähr 0,006 USD.</li><li><strong>Anwendungseinschränkungen</strong>: <em>Nicht jede Aussage kann oder sollte überprüft werden.</em> Persönliche Meinungen oder Erfahrungen, wie \"Ich fühle mich faul\", eignen sich nicht für Grounding. Ebenso wenig gelten zukünftige Ereignisse oder hypothetische Aussagen. Es gibt viele Fälle, in denen Grounding irrelevant oder sinnlos wäre. Um unnötige API-Aufrufe zu vermeiden, empfehlen wir Benutzern, nur Sätze oder Abschnitte einzureichen, die tatsächlich eine Faktenprüfung erfordern. Serverseitig haben wir einen umfassenden Satz von Fehlercodes implementiert, um zu erklären, warum eine Aussage für Grounding abgelehnt werden könnte.</li><li><strong>Abhängigkeit von der Qualität der Webdaten</strong>: Die Genauigkeit der Grounding API ist nur so gut wie die Qualität der Quellen, die sie abruft. Wenn die Suchergebnisse qualitativ minderwertige oder voreingenommene Informationen enthalten, könnte sich dies im Grounding-Prozess widerspiegeln und möglicherweise zu ungenauen oder irreführenden Schlussfolgerungen führen. Um dieses Problem zu vermeiden, erlauben wir Benutzern, den Parameter <code>references</code> manuell festzulegen und die URLs einzuschränken, nach denen das System sucht. Dies gibt Benutzern mehr Kontrolle über die für das Grounding verwendeten Quellen und gewährleistet einen gezielteren und relevanteren Faktenprüfungsprozess.</li></ul><h2 id=\"conclusion\">Fazit</h2><p>Die Grounding API bietet eine End-to-End, nahezu Echtzeit-Faktenprüfungserfahrung. Forscher können sie nutzen, um Referenzen zu finden, die ihre Hypothesen unterstützen oder in Frage stellen und damit die Glaubwürdigkeit ihrer Arbeit erhöhen. In Unternehmensmeetings stellt sie sicher, dass Strategien auf genauen, aktuellen Informationen basieren, indem Annahmen und Daten validiert werden. In politischen Diskussionen überprüft sie schnell Behauptungen und bringt mehr Verantwortlichkeit in Debatten.</p><p>Für die Zukunft planen wir, die API durch die Integration privater Datenquellen wie interner Berichte, Datenbanken und PDFs für eine maßgeschneidertere Faktenprüfung zu verbessern. Wir streben auch an, die Anzahl der pro Anfrage überprüften Quellen für tiefere Auswertungen zu erweitern. Die Verbesserung der mehrstufigen Frage-Antwort-Funktion wird die Analyse vertiefen, und die Erhöhung der Konsistenz ist eine Priorität, um sicherzustellen, dass wiederholte Anfragen zuverlässigere, konsistentere Ergebnisse liefern.</p>",
  "comment_id": "670cd94952567c0001d0f33e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-14T10:41:45.000+02:00",
  "updated_at": "2024-10-15T20:11:23.000+02:00",
  "published_at": "2024-10-15T10:08:02.000+02:00",
  "custom_excerpt": "With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fact-checking-with-new-grounding-api-in-jina-reader/",
  "excerpt": "Mit dem neuen g.jina.ai können Sie ganz einfach Aussagen verifizieren, um LLM-Halluzinationen zu reduzieren oder die Integrität von menschlich verfasstem Content zu verbessern.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Jina developer interface showing \"Jina AI was founded in 2020\" with controls labeled true and false, and web address on top.",
  "feature_image_caption": null
}