{
  "slug": "revolutionizing-bilingual-text-embeddings-with-multi-task-contrastive-learning",
  "id": "65df105ab22368000152a1b9",
  "uuid": "b209f99c-bf24-40d3-9cea-d9fc4d6bc640",
  "title": "Revolutionierung zweisprachiger Text-Embeddings durch kontrastives Multi-Task-Lernen",
  "html": "<p>In unserer aktuellen Publikation, <a href=\"https://arxiv.org/abs/2402.17016?ref=jina-ai-gmbh.ghost.io\">Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings</a>, haben wir die Entwicklung unserer <a href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\">Deutsch-Englisch</a> und <a href=\"https://jina.ai/news/aqui-se-habla-espanol-top-quality-spanish-english-embeddings-and-8k-context?ref=jina-ai-gmbh.ghost.io\">Spanisch-Englisch</a> bilingualen Text-Embedding-Modelle detailliert beschrieben.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2402.17016?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings</div><div class=\"kg-bookmark-description\">We introduce a novel suite of state-of-the-art bilingual text embedding models that are designed to support English and another target language. These models are capable of processing lengthy text inputs with up to 8192 tokens, making them highly versatile for a range of natural language processing tasks such as text retrieval, clustering, and semantic textual similarity (STS) calculations. By focusing on bilingual models and introducing a unique multi-task learning objective, we have significantly improved the model performance on STS tasks, which outperforms the capabilities of existing multilingual models in both target language understanding and cross-lingual evaluation tasks. Moreover, our bilingual models are more efficient, requiring fewer parameters and less memory due to their smaller vocabulary needs. Furthermore, we have expanded the Massive Text Embedding Benchmark (MTEB) to include benchmarks for German and Spanish embedding models. This integration aims to stimulate further research and advancement in text embedding technologies for these languages.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Isabelle Mohr</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Start with 1M free tokens. Top-performing, 8192 context length bilingual embeddings for your search and RAG systems.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>Unser Ansatz nutzt Multi-Task Contrastive Learning und eine fortschrittliche Datenkuratierungs-Pipeline, wobei der Fokus auf bilinguale Fähigkeiten gerichtet ist und die Unterstützung auf 8192 Token erweitert wurde. Diese Methode ermöglicht es unseren Modellen, sowohl im Verständnis der Zielsprachen als auch bei der effizienten Durchführung sprachübergreifender Evaluierungen hervorragende Leistungen zu erbringen.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/aqui-se-habla-espanol-top-quality-spanish-english-embeddings-and-8k-context?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Aquí Se Habla Español: Top-Quality Spanish-English Embeddings and 8k Context</div><div class=\"kg-bookmark-description\">Jina AI's new bilingual Spanish-English embedding model brings the state-of-the-art in AI to half a billion Spanish speakers.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/1334.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ich bin ein Berliner: German-English Bilingual Embeddings with 8K Token Length</div><div class=\"kg-bookmark-description\">Jina AI introduces a German/English bilingual embedding model, featuring an extensive 8,192-token length, specifically designed to support German businesses thriving in the U.S. market.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Explore-image-storytelling-beyond-pixels--33-.png\" alt=\"\"></div></a></figure><p>Zusätzlich zu den in der Publikation behandelten bilingualen Modellen haben wir auch bilinguale <a href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english?ref=jina-ai-gmbh.ghost.io\">Chinesisch-Englisch</a> und <a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">monolinguale Englisch</a> Modelle entwickelt. Diese Ergänzungen zeigen unser Engagement für die Abdeckung eines breiten Spektrums sprachlicher Anforderungen und die Weiterentwicklung unserer Fähigkeiten in der Sprachverarbeitung.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">8K Token-Length Bilingual Embeddings Break Language Barriers in Chinese and English</div><div class=\"kg-bookmark-description\">The first bilingual Chinese-English embedding model with 8192 token-length.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI Launches World's First Open-Source 8K Text Embedding, Rivaling OpenAI</div><div class=\"kg-bookmark-description\">Jina AI introduces jina-embeddings-v2, the world's first open-source model boasting an 8K context length. Matching the prowess of OpenAI's proprietary models, this innovation is now publicly accessible on Huggingface, signaling a significant milestone in the landscape of text embeddings.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2023/10/Explore-image-storytelling-beyond-pixels--11-.png\" alt=\"\"></div></a></figure><p>Unsere bilingualen Modelle zeichnen sich durch ihre Effizienz aus, da sie mit optimierten Vokabulargrößen arbeiten und dadurch weniger Parameter und Speicher benötigen. Diese Effizienz unterstreicht unser Engagement für die Entwicklung leistungsstarker und gleichzeitig ressourceneffizienter Werkzeuge für die Sprachverarbeitung.</p><p>Nach der Veröffentlichung unserer Publikation haben wir den <a href=\"https://huggingface.co/spaces/mteb/leaderboard?ref=jina-ai-gmbh.ghost.io\">Massive Text Embedding Benchmark (MTEB)</a> um Benchmarks für unsere Englisch-Deutsch und Englisch-Spanisch Embedding-Modelle erweitert. Diese Erweiterung ist Teil unserer Bemühungen, weitere Forschung und Fortschritte in der Text-Embedding-Technologie für nicht-englische Sprachen anzuregen.</p><p>Bei Jina AI ist es unser Ziel, die Verarbeitung und das Verständnis mehrerer Sprachen zu verbessern und mit unseren Entwicklungen im Bereich bilingualer und monolingualer Text-Embedding-Modelle zum NLP-Bereich beizutragen.</p>",
  "comment_id": "65df105ab22368000152a1b9",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/02/banner-4models-02.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-02-28T11:52:10.000+01:00",
  "updated_at": "2024-03-03T01:55:04.000+01:00",
  "published_at": "2024-02-28T16:00:41.000+01:00",
  "custom_excerpt": "Our new paper explores how our Spanish-English and German-English models use multi-task contrastive learning and a sophisticated data pipeline to master language understanding and cross-lingual efficiency for texts up to 8192 tokens",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/revolutionizing-bilingual-text-embeddings-with-multi-task-contrastive-learning/",
  "excerpt": "Unsere neue Forschungsarbeit untersucht, wie unsere Spanisch-Englisch- und Deutsch-Englisch-Modelle mithilfe von Multi-Task Contrastive Learning und einer ausgefeilten Data Pipeline das Sprachverständnis und die sprachübergreifende Effizienz für Texte bis zu 8192 Token beherrschen.",
  "reading_time": 3,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Composite image of four colorful, stylized landmarks: Brandenburg Gate, St. Peter's Basilica, Tiananmen, and Golden Gate Brid",
  "feature_image_caption": null
}