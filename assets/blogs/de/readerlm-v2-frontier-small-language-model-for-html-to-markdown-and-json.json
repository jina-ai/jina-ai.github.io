{
  "slug": "readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json",
  "id": "6785bfd62defad0001fb5f22",
  "uuid": "a8e2e140-18e5-49e6-aa8f-71bf4c9e3293",
  "title": "ReaderLM v2: Fortschrittliches kleines Sprachmodell für HTML zu Markdown und JSON",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/ReaderLM-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/ReaderLM-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">Wir sind auf einer Reise zur Förderung und Demokratisierung künstlicher Intelligenz durch Open Source und Open Science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-24.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/ReaderLM-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Im April 2024 haben wir <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> eingeführt，eine API，die jede Webseite in LLM-freundliches Markdown umwandelt，indem einfach <code>r.jina.ai</code> als URL-Präfix hinzugefügt wird. Im September 2024 <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown?ref=jina-ai-gmbh.ghost.io\">haben wir zwei kleine Sprachmodelle，<code>reader-lm-0.5b</code> und <code>reader-lm-1.5b</code>，veröffentlicht，die speziell für die Umwandlung von rohem HTML in sauberes Markdown entwickelt wurden.</a> Heute stellen wir die zweite Generation von ReaderLM vor，ein Sprachmodell mit 1，5B Parametern，das rohes HTML mit überlegener Genauigkeit und verbesserter Handhabung längerer Kontexte in schön formatiertes Markdown oder JSON umwandelt. <code>ReaderLM-v2</code> verarbeitet bis zu 512K Token kombinierte Ein- und Ausgabelänge. Das Modell bietet mehrsprachige Unterstützung für 29 Sprachen，einschließlich Englisch，Chinesisch，Japanisch，Koreanisch，Französisch，Spanisch，Portugiesisch，Deutsch，Italienisch，Russisch，Vietnamesisch，Thai，Arabisch und mehr.</p><p>Dank seines <strong>neuen Trainingsparadigmas</strong> und <strong>hochwertigeren Trainingsdaten</strong> stellt <code>ReaderLM-v2</code> einen bedeutenden Fortschritt gegenüber seinem Vorgänger dar，besonders bei der Verarbeitung von Langform-Inhalten und der Markdown-Syntax-Generierung. Während die erste Generation die HTML-zu-Markdown-Konvertierung als <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#:~:text=primarily%20needs%20to-,selective%2Dcopy,-from%20the%20input\">eine „selektive Kopier\"-Aufgabe</a> betrachtete，<strong>behandelt v2 es als echten Übersetzungsprozess.</strong> Diese Änderung ermöglicht es dem Modell，die Markdown-Syntax meisterhaft zu nutzen und bei der <strong>Generierung komplexer Elemente wie Code-Fences，verschachtelter Listen，Tabellen und LaTex-Gleichungen</strong> zu brillieren.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-.mp4\" poster=\"https://img.spacergif.org/v1/1500x1000/0a/spacer.png\" width=\"1500\" height=\"1000\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Video abspielen\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Video abspielen\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Video pausieren\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:21</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Wiedergabegeschwindigkeit anpassen\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Ton einschalten\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Ton ausschalten\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Der Vergleich der HTML-zu-Markdown-Ergebnisse der HackerNews-Startseite zwischen ReaderLM v2，ReaderLM 1.5b，Claude 3.5 Sonnet und Gemini 2.0 Flash zeigt ReaderLM v2's einzigartigen Charakter und Leistung. ReaderLM v2 überzeugt durch die umfassende Bewahrung von Informationen aus dem rohen HTML，einschließlich der ursprünglichen HackerNews-Links，während es den Inhalt intelligent mithilfe der Markdown-Syntax strukturiert. Das Modell verwendet verschachtelte Listen zur Organisation lokaler Elemente (Punkte，Zeitstempel und Kommentare) und behält gleichzeitig eine konsistente globale Formatierung durch eine angemessene Überschriftenhierarchie (h1- und h2-Tags) bei.</span></p></figcaption>\n        </figure><p>Eine große Herausforderung in unserer ersten Version war die <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#degeneration-and-dull-loops\"><strong>Degeneration</strong></a> nach der Generierung langer Sequenzen，besonders in Form von Wiederholungen und Schleifen. Das Modell begann entweder，dasselbe Token zu wiederholen oder blieb in einer Schleife stecken，wobei es eine kurze Tokensequenz durchlief，bis die maximale Ausgabelänge erreicht war. <code>ReaderLM-v2</code> mildert dieses Problem deutlich durch das Hinzufügen von kontrastivem Verlust während des Trainings—seine Leistung bleibt konsistent，unabhängig von der Kontextlänge oder der Menge der bereits generierten Token.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Wir haben ReaderLM v2 getestet，indem wir </span><a href=\"https://jina.ai/legal?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">unsere Rechtsseite</span></a><span style=\"white-space: pre-wrap;\"> in Markdown umgewandelt haben—eine Seite，die etwa 20-mal länger ist als die HackerNews-Startseite，einschließlich einer umfangreichen Subprozessor-Tabelle am Ende der Seite. Trotz dieser großen Herausforderung generierte ReaderLM v2 erfolgreich die vollständige Tabelle in Markdown，während die konsistente Dokumentstruktur durchgehend beibehalten wurde，einschließlich der Überschriftenhierarchie und Listenformatierung auch nach der Tabelle. Dieses Leistungsniveau war mit der vorherigen Generation </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>reader-lm-1.5b</span></code><span style=\"white-space: pre-wrap;\">，die nach der Generierung langer Sequenzen degenerierte，nicht erreichbar.</span></figcaption></figure><p>Über die Markdown-Konvertierung hinaus führt <code>ReaderLM-v2</code> die <strong>direkte HTML-zu-JSON-Generierung</strong> ein，die es Benutzern ermöglicht，spezifische Informationen aus rohem HTML entsprechend einem vorgegebenen JSON-Schema zu extrahieren. Dieser End-to-End-Ansatz eliminiert die Notwendigkeit einer intermediären Markdown-Konvertierung，eine häufige Anforderung in vielen LLM-gestützten Datenreinigungs- und Extraktions-Pipelines.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">In diesem Beispiel haben wir ReaderLM v2 mit rohem HTML von der HackerNews-Startseite und einem JSON-Schema versorgt, das den Thread-Titel, URL, Zusammenfassung, Schlüsselwörter, Autor und die Anzahl der Kommentare spezifiziert. Während einige Felder direkt im HTML verfügbar sind, müssen andere – wie Schlüsselwörter – aus dem Inhalt abgeleitet werden. ReaderLM v2 extrahiert und generiert alle Felder mit bemerkenswerter Genauigkeit.</span></figcaption></figure><p>In sowohl quantitativen als auch qualitativen Benchmarks übertrifft <code>ReaderLM-v2</code> weitaus größere Modelle wie <code>Qwen2.5-32B-Instruct</code>, <code>Gemini2-flash-expr</code> und <code>GPT-4o-2024-08-06</code> bei HTML-zu-Markdown-Aufgaben, während es bei HTML-zu-JSON-Extraktionsaufgaben vergleichbare Leistung zeigt – und das alles mit deutlich weniger Parametern.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ReaderLM-v2-pro</span></code><span style=\"white-space: pre-wrap;\"> ist ein exklusiver Premium-Checkpoint, der unseren Enterprise-Kunden vorbehalten ist und zusätzliches Training sowie Optimierungen bietet. </span></figcaption></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Instructed-HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2JSON.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Qualitative-Evaluation--2-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"620\"><figcaption><span style=\"white-space: pre-wrap;\">Unsere manuelle Evaluierung umfasste 10 verschiedene HTML-Quellen, darunter Nachrichtenartikel, Blogbeiträge, Produkt-Landingpages, E-Commerce-Seiten und juristische Dokumente in Englisch, Japanisch und Chinesisch. Das Testkorpus enthielt anspruchsvolle Elemente wie mehrzeilige Tabellen, dynamische Layouts, verknüpfte Tabellen, mathematische Formeln (sowohl inline als auch display), Code-Blöcke und tief verschachtelte Listen. Die qualitative Bewertung konzentrierte sich auf drei Schlüsseldimensionen, wobei die Modelle auf einer Skala von 1 (niedrigste) bis 5 (höchste) bewertet wurden. Die Ergebnisse wurden dann auf maximal 1,0 pro Aspekt normalisiert, um einen einfacheren Vergleich zu ermöglichen.</span></figcaption></figure><p>Diese Ergebnisse zeigen, dass ein gut konzipiertes Modell mit 1,5B Parametern die Leistung von viel größeren Modellen bei strukturierten Datenextraktionsaufgaben nicht nur erreichen, sondern oft übertreffen kann. Die fortschreitenden Verbesserungen von <code>ReaderLM-v2</code> zu <code>ReaderLM-v2-pro</code> demonstrieren die Effektivität unserer neuen Trainingsstrategie bei der Verbesserung der Modellleistung bei gleichzeitiger Beibehaltung der Recheneffizienz.</p><h2 id=\"get-started\">Erste Schritte</h2><h3 id=\"via-reader-api\">Über die Reader API</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs and search web for better grounding LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-17.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>ReaderLM-v2</code> ist jetzt in unsere Reader API integriert. Um es zu nutzen, geben Sie einfach <code>x-engine: readerlm-v2</code> in Ihren Request-Headers an und aktivieren Sie Response-Streaming mit <code>-H 'Accept: text/event-stream'</code>:</p><pre><code class=\"language-bash\">curl https://r.jina.ai/https://news.ycombinator.com/ -H 'x-engine: readerlm-v2' -H 'Accept: text/event-stream'\n</code></pre><p>Sie können es ohne API-Schlüssel mit einer niedrigeren Rate-Limit testen. <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\">Für höhere Rate-Limits</a> können Sie einen API-Schlüssel erwerben. <strong>Bitte beachten Sie, dass ReaderLM-v2-Anfragen die 3-fache normale Token-Anzahl von Ihrem API-Schlüssel verbrauchen.</strong> Diese Funktion befindet sich derzeit in der Beta-Phase, während wir mit dem GCP-Team zusammenarbeiten, um die GPU-Effizienz zu optimieren und die Modellverfügbarkeit zu erhöhen.</p><h3 id=\"on-google-colab\">Auf Google Colab</h3><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1FfPjZwkMSocOLsEYH45B3B4NxDryKLGI?usp=sharing&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-22.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-6.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Beachten Sie, dass die kostenlose T4 GPU Einschränkungen hat—sie unterstützt kein </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>bfloat16</span></code><span style=\"white-space: pre-wrap;\"> oder Flash Attention 2, was zu höherem Speicherverbrauch und langsamerer Verarbeitung längerer Eingaben führt. Dennoch verarbeitet ReaderLM v2 erfolgreich unsere gesamte Rechtsseite unter diesen Einschränkungen und erreicht Verarbeitungsgeschwindigkeiten von 67 Token/s Eingabe und 36 Token/s Ausgabe. Für den Produktiveinsatz empfehlen wir eine RTX 3090/4090 für optimale Leistung.</span></p></figcaption></figure><p>Der einfachste Weg, <code>ReaderLM-v2</code> in einer gehosteten Umgebung zu testen, ist über unser Colab-Notebook, das HTML-zu-Markdown-Konvertierung, JSON-Extraktion und instruktionsbasierte Verarbeitung am Beispiel der HackerNews-Startseite demonstriert. Das Notebook ist für Colabs kostenlosen T4 GPU-Tier optimiert und benötigt <code>vllm</code> und <code>triton</code> für Beschleunigung und Ausführung. Sie können es gerne mit jeder beliebigen Website testen.</p><h4 id=\"html-to-markdown-conversion\">HTML zu Markdown Konvertierung</h4><p>Sie können die <code>create_prompt</code> Hilfsfunktion verwenden, um einfach einen Prompt für die Konvertierung von HTML zu Markdown zu erstellen:</p><pre><code class=\"language-python\">prompt = create_prompt(html)\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p><code>result</code> wird ein String sein, der in Markdown-Backticks als Code-Fence eingeschlossen ist. Sie können auch die Standardeinstellungen überschreiben, um verschiedene Ausgaben zu erkunden, zum Beispiel:</p><pre><code class=\"language-python\">prompt = create_prompt(html, instruction=\"Extract the first three news and put into in the makdown list\")\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p>Da unsere Trainingsdaten möglicherweise nicht alle Arten von Anweisungen abdecken, insbesondere Aufgaben, die mehrstufiges Denken erfordern, kommen die zuverlässigsten Ergebnisse von der HTML-zu-Markdown-Konvertierung. Für die effektivste Informationsextraktion empfehlen wir die Verwendung von JSON-Schema wie unten gezeigt:</p><h4 id=\"html-to-json-extraction-with-json-schema\">HTML zu JSON Extraktion mit JSON Schema</h4><pre><code class=\"language-python\">import json\n\nschema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"title\": {\"type\": \"string\", \"description\": \"News thread title\"},\n        \"url\": {\"type\": \"string\", \"description\": \"Thread URL\"},\n        \"summary\": {\"type\": \"string\", \"description\": \"Article summary\"},\n        \"keywords\": {\"type\": \"list\", \"description\": \"Descriptive keywords\"},\n        \"author\": {\"type\": \"string\", \"description\": \"Thread author\"},\n        \"comments\": {\"type\": \"integer\", \"description\": \"Comment count\"}\n    },\n    \"required\": [\"title\", \"url\", \"date\", \"points\", \"author\", \"comments\"]\n}\n\nprompt = create_prompt(html, schema=json.dumps(schema, indent=2))\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()\n</code></pre><p><code>result</code> wird ein String sein, der in JSON-formatierten Code-Fence-Backticks eingeschlossen ist, nicht ein tatsächliches JSON/dict-Objekt. Sie können Python verwenden, um den String in ein richtiges Dictionary oder JSON-Objekt für die weitere Verarbeitung zu parsen.</p><h3 id=\"in-production-available-on-csp\">In Produktion: Verfügbar auf CSP</h3><p><code>ReaderLM-v2</code> ist auf AWS SageMaker, Azure und GCP Marketplace verfügbar. Wenn Sie diese Modelle über diese Plattformen hinaus oder On-Premises in Ihrem Unternehmen nutzen möchten, beachten Sie, dass dieses Modell und <code>ReaderLM-v2-pro</code> beide unter CC BY-NC 4.0 lizenziert sind. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Für Anfragen zur kommerziellen Nutzung oder den Zugang zu <code>ReaderLM-v2-pro</code> kontaktieren Sie uns gerne.</a></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-jwfct4j4rvxk2?sr=0-21&ref_=beagle&applicationId=AWSMPContessa&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Reader-LM v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-23.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"quantitative-evaluation\">Quantitative Evaluation</h2><p>Wir evaluieren ReaderLM-v2 in drei strukturierten Datenextraktionsaufgaben im Vergleich zu State-of-the-Art Modellen: <code>GPT-4o-2024-08-06</code>, <code>Gemini2-flash-expr</code> und <code>Qwen2.5-32B-Instruct</code>. Unser Bewertungsrahmen kombiniert Metriken, die sowohl die Genauigkeit des Inhalts als auch die strukturelle Treue messen. <code>ReaderLM-v2</code> ist die öffentlich verfügbare Version mit offenen Gewichten, während <code>ReaderLM-v2-pro</code> ein exklusiver Premium-Checkpoint für unsere Unternehmenskunden ist, der zusätzliches Training und Optimierungen enthält. Beachten Sie, dass unser <code>reader-lm-1.5b</code> der ersten Generation nur bei der Hauptinhaltsextraktionsaufgabe evaluiert wird, da es keine Funktionen für instruierte Extraktion oder JSON-Extraktion unterstützt.</p><h3 id=\"evaluation-metrics\">Evaluationsmetriken</h3><p>Für HTML-zu-Markdown-Aufgaben verwenden wir sieben komplementäre Metriken. Hinweis: ↑ bedeutet höher ist besser, ↓ bedeutet niedriger ist besser</p><ul><li><strong>ROUGE-L</strong> (↑): Misst die längste gemeinsame Teilsequenz zwischen generiertem und Referenztext und erfasst Inhaltserhaltung und strukturelle Ähnlichkeit. Bereich: 0-1, höhere Werte zeigen bessere Sequenzübereinstimmung.</li><li><strong>WER (Word Error Rate)</strong> (↓): Quantifiziert die minimale Anzahl von Wort-Level-Bearbeitungen, die erforderlich sind, um den generierten Text in die Referenz umzuwandeln. Niedrigere Werte bedeuten weniger notwendige Korrekturen.</li><li><strong>SUB (Substitutions)</strong> (↓): Zählt die Anzahl der erforderlichen Wortsubstitutionen. Niedrigere Werte deuten auf bessere Wortgenauigkeit hin.</li><li><strong>INS (Insertions)</strong> (↓): Misst die Anzahl der Wörter, die eingefügt werden müssen, um der Referenz zu entsprechen. Niedrigere Werte zeigen bessere Vollständigkeit.</li><li><strong>Levenshtein Distance</strong> (↓): Berechnet die minimale Anzahl von Einzelzeichen-Bearbeitungen. Niedrigere Werte deuten auf bessere Zeichengenauigkeit hin.</li><li><strong>Damerau-Levenshtein Distance</strong> (↓): Ähnlich wie Levenshtein, berücksichtigt aber auch Zeichenvertauschungen. Niedrigere Werte zeigen bessere Zeichenübereinstimmung.</li><li><strong>Jaro-Winkler Similarity</strong> (↑): Betont übereinstimmende Zeichen am Stringanfang, besonders nützlich für die Bewertung der Dokumentstrukturerhaltung. Bereich: 0-1, höhere Werte zeigen bessere Ähnlichkeit.</li></ul><p>Für HTML-zu-JSON-Aufgaben betrachten wir es als Retrieval-Aufgabe und verwenden vier Metriken aus dem Information Retrieval:</p><ul><li><strong>F1 Score</strong> (↑): Harmonisches Mittel von Precision und Recall, liefert Gesamtgenauigkeit. Bereich: 0-1.</li><li><strong>Precision</strong> (↑): Anteil der korrekt extrahierten Informationen an allen Extraktionen. Bereich: 0-1.</li><li><strong>Recall</strong> (↑): Anteil der korrekt extrahierten Informationen aus allen verfügbaren Informationen. Bereich: 0-1.</li><li><strong>Pass-Rate</strong> (↑): Anteil der Ausgaben, die valides JSON sind und dem Schema entsprechen. Bereich: 0-1.</li></ul><h3 id=\"main-content-html-to-markdown-task\">Hauptinhalt HTML-zu-Markdown-Aufgabe</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.69</td>\n<td>0.62</td>\n<td>131.06</td>\n<td>372.34</td>\n<td>0.40</td>\n<td>1341.14</td>\n<td>0.74</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td>0.41</td>\n<td><strong>88.66</strong></td>\n<td><strong>88.69</strong></td>\n<td>0.40</td>\n<td>1283.54</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.71</td>\n<td>0.47</td>\n<td>158.26</td>\n<td>123.47</td>\n<td>0.41</td>\n<td>1354.33</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>reader-lm-1.5b</td>\n<td>0.72</td>\n<td>1.14</td>\n<td>260.29</td>\n<td>1182.97</td>\n<td>0.35</td>\n<td>1733.11</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.84</td>\n<td>0.62</td>\n<td>135.28</td>\n<td>867.14</td>\n<td>0.22</td>\n<td>1262.75</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.86</strong></td>\n<td><strong>0.39</strong></td>\n<td>162.92</td>\n<td>500.44</td>\n<td><strong>0.20</strong></td>\n<td><strong>928.15</strong></td>\n<td><strong>0.83</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"instructed-html-to-markdown-task\">Instruierte HTML-zu-Markdown-Aufgabe</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.64</td>\n<td>1.64</td>\n<td>122.64</td>\n<td>533.12</td>\n<td>0.45</td>\n<td>766.62</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td><strong>0.82</strong></td>\n<td><strong>87.53</strong></td>\n<td><strong>180.61</strong></td>\n<td>0.42</td>\n<td><strong>451.10</strong></td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.68</td>\n<td>0.73</td>\n<td>98.72</td>\n<td>177.23</td>\n<td>0.43</td>\n<td>501.50</td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.70</td>\n<td>1.28</td>\n<td>75.10</td>\n<td>443.70</td>\n<td>0.38</td>\n<td>673.62</td>\n<td><strong>0.75</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.72</strong></td>\n<td>1.48</td>\n<td><strong>70.16</strong></td>\n<td>570.38</td>\n<td><strong>0.37</strong></td>\n<td>748.10</td>\n<td><strong>0.75</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"schema-based-html-to-json-task\">Schema-basierte HTML-zu-JSON-Aufgabe</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>F1↑</th>\n<th>Precision↑</th>\n<th>Recall↑</th>\n<th>Pass-Rate↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.81</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td><strong>0.83</strong></td>\n<td>0.84</td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td><strong>0.83</strong></td>\n<td><strong>0.85</strong></td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.81</td>\n<td>0.98</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td>0.82</td>\n<td>0.83</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>ReaderLM-v2</code> stellt einen bedeutenden Fortschritt in allen Aufgaben dar. Bei der Hauptinhaltsextraktion erzielt <code>ReaderLM-v2-pro</code> die beste Leistung in fünf von sieben Metriken, mit überlegenen ROUGE-L (0,86), WER (0,39), Levenshtein (0,20), Damerau (928,15) und Jaro-Winkler (0,83) Werten. Diese Ergebnisse zeigen umfassende Verbesserungen sowohl in der Inhaltserhaltung als auch in der strukturellen Genauigkeit im Vergleich zu seiner Basisversion und größeren Modellen.</p><p>Bei der instruierten Extraktion führt <code>ReaderLM-v2</code> und <code>ReaderLM-v2-pro</code> bei ROUGE-L (0,72), Substitutionsrate (70,16), Levenshtein-Distanz (0,37) und Jaro-Winkler-Ähnlichkeit (0,75, gleichauf mit Basisversion). Während GPT-4o Vorteile bei WER und Damerau-Distanz zeigt, behält <code>ReaderLM-v2-pro</code> eine bessere Gesamtstruktur und Genauigkeit bei. Bei der JSON-Extraktion zeigt das Modell eine wettbewerbsfähige Leistung und bleibt innerhalb von 0,01-0,02 F1-Punkten von größeren Modellen, während es hohe Pass-Raten (0,99) erreicht.</p><h2 id=\"qualitative-evaluation\">Qualitative Evaluation</h2><p>Während unserer Analyse vonBei <code>reader-lm-1.5b</code> haben wir beobachtet, dass <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#qualitative-study\">quantitative Metriken allein die Modellleistung nicht vollständig erfassen</a>. Numerische Auswertungen spiegelten manchmal nicht die wahrgenommene Qualität wider - Fälle, in denen niedrige Metrikwerte visuell zufriedenstellendes Markdown produzierten oder hohe Werte suboptimale Ergebnisse lieferten. Um diese Diskrepanz zu beheben, führten wir systematische qualitative Bewertungen über 10 verschiedene HTML-Quellen durch, darunter Nachrichtenartikel, Blogbeiträge, Produktseiten, E-Commerce-Websites und juristische Dokumente in Englisch, Japanisch und Chinesisch. Das Testkorpus legte den Schwerpunkt auf anspruchsvolle Formatierungselemente wie mehrzeilige Tabellen, dynamische Layouts, LaTeX-Formeln, verlinkte Tabellen und verschachtelte Listen und bot einen umfassenderen Einblick in die realen Fähigkeiten des Modells.</p><h3 id=\"evaluation-metrics-1\">Evaluierungsmetriken</h3><p>Unsere menschliche Bewertung konzentrierte sich auf drei Hauptdimensionen, wobei die Outputs auf einer Skala von 1-5 bewertet wurden:</p><p><strong>Inhaltsintegrität</strong> - Bewertet die Bewahrung semantischer Informationen während der HTML-zu-Markdown-Konvertierung, einschließlich:</p><ul><li>Genauigkeit und Vollständigkeit des Textinhalts</li><li>Erhaltung von Links, Bildern, Code-Blöcken, Formeln und Zitaten</li><li>Beibehaltung der Textformatierung und Link/Bild-URLs</li></ul><p><strong>Strukturelle Genauigkeit</strong> - Beurteilt die korrekte Konvertierung von HTML-Strukturelementen zu Markdown:</p><ul><li>Erhaltung der Header-Hierarchie</li><li>Genauigkeit der Listenverschachtelung</li><li>Tabellentreue</li><li>Formatierung von Code-Blöcken und Zitaten</li></ul><p><strong>Formatkonformität</strong> - Misst die Einhaltung von Markdown-Syntaxstandards:</p><ul><li>Korrekte Syntaxverwendung für Header (#), Listen (*, +, -), Tabellen, Code-Blöcke (```)</li><li>Saubere Formatierung ohne überflüssige Leerzeichen oder nicht standardmäßige Syntax</li><li>Konsistente und lesbare gerenderte Ausgabe</li></ul><p>Bei der manuellen Bewertung von über 10 HTML-Seiten hat jedes Bewertungskriterium eine maximale Punktzahl von 50 Punkten. <code>ReaderLM-v2</code> zeigte in allen Dimensionen eine starke Leistung:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Content Integrity</th>\n<th>Structural Accuracy</th>\n<th>Format Compliance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>reader-lm-v2</td>\n<td>39</td>\n<td>35</td>\n<td>36</td>\n</tr>\n<tr>\n<td>reader-lm-v2-pro</td>\n<td>35</td>\n<td>37</td>\n<td>37</td>\n</tr>\n<tr>\n<td>reader-lm-v1</td>\n<td>35</td>\n<td>34</td>\n<td>31</td>\n</tr>\n<tr>\n<td>Claude 3.5 Sonnet</td>\n<td>26</td>\n<td>31</td>\n<td>33</td>\n</tr>\n<tr>\n<td>gemini-2.0-flash-expr</td>\n<td>35</td>\n<td>31</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>32</td>\n<td>33</td>\n<td>34</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>38</td>\n<td>41</td>\n<td>42</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Bei der Inhaltsvollständigkeit überzeugte es besonders bei der Erkennung komplexer Elemente, insbesondere bei LaTeX-Formeln, verschachtelten Listen und Code-Blöcken. Das Modell behielt eine hohe Genauigkeit bei der Verarbeitung komplexer Inhaltsstrukturen bei, während konkurrierende Modelle oft H1-Header wegließen (<code>reader-lm-1.5b</code>), Inhalte abschnitten (Claude 3.5) oder rohe HTML-Tags beibehielten (Gemini-2.0-flash).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--92-.png\" width=\"2000\" height=\"1477\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--92-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--92-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--92-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--92-.png 2400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png\" width=\"2000\" height=\"1765\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--93--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--93--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--93--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png 2268w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><a href=\"https://iclr-blogposts.github.io/2024/blog/bench-hvp/?ref=jina-ai-gmbh.ghost.io\">Ein ICLR-Blogbeitrag</a> mit komplexen LaTeX-Gleichungen in Markdown, der den HTML-Quellcode im rechten Panel zeigt.</p></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--94--2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1033\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--94--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--94--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--94--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--94--2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Eine geteilte Ansicht, die ReaderLM-v2's Markdown-Output mit seiner gerenderten Visualisierung vergleicht.</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"821\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Wir können den ursprünglichen Inhalt durch einfache Nachbearbeitungsschritte nach ReaderLM-v2 perfekt wiederherstellen, einschließlich der Konvertierung von LaTeX-Gleichungen vom HTML-Format in das Markdown-Format. Zum Beispiel ersetzen wir <code>\\[...\\]</code> (und seine HTML-Äquivalente) durch Markdown-Standardbegrenzer wie <code>$...$</code> für Inline-Gleichungen und <code>$$...$$</code> für Display-Gleichungen. Dies hilft, Syntaxkonflikte in der Markdown-Interpretation zu vermeiden.</figcaption></figure><p>In der strukturellen Genauigkeit zeigte ReaderLM-v2 eine Optimierung für gängige Web-Strukturen. Bei Hacker News-Fällen rekonstruierte es beispielsweise erfolgreich vollständige Links und optimierte die Listendarstellung. Das Modell bewältigte komplexe Nicht-Blog-HTML-Strukturen, die für ReaderLM-v1 eine Herausforderung darstellten.</p><p>Bei der Formatkonformität zeigte ReaderLM-v2 besondere Stärke im Umgang mit Inhalten wie Hacker News, Blogs und WeChat-Artikeln. Während andere große Sprachmodelle gut mit markdown-ähnlichen Quellen umgehen konnten, hatten sie Schwierigkeiten mit traditionellen Websites, die mehr Interpretation und Neuformatierung erforderten.</p><p>Unsere Analyse ergab, dass <code>gpt-4o</code> bei der Verarbeitung kürzerer Websites hervorragend ist und im Vergleich zu anderen Modellen ein überlegenes Verständnis von Website-Struktur und Formatierung zeigt. Bei längeren Inhalten hat <code>gpt-4o</code> jedoch Schwierigkeiten mit der Vollständigkeit und lässt oft Teile am Anfang und Ende des Textes weg. Wir haben eine vergleichende Analyse der Outputs von <code>gpt-4o</code>, ReaderLM-v2 und ReaderLM-v2-pro am Beispiel der Zillow-Website beigefügt.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1382\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png 2356w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Die ursprüngliche Zillow HTML-Seite</figcaption></figure><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png\" width=\"1400\" height=\"1576\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--95-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--95-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png 1400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png\" width=\"1550\" height=\"1578\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png 1550w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png\" width=\"1562\" height=\"1582\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--97-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--97-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png 1562w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Ein Vergleich der gerenderten Markdown-Ausgaben von gpt-4o (links), ReaderLM-v2 (Mitte) und ReaderLM-v2-pro (rechts).</span></p></figcaption></figure><p>Für bestimmte anspruchsvolle Fälle wie Produkt-Landingpages und Behördendokumente blieb die Leistung von ReaderLM-v2 und ReaderLM-v2-pro robust, hat aber noch Verbesserungspotenzial. Komplexe mathematische Formeln und Code in ICLR-Blogbeiträgen stellten für die meisten Modelle eine Herausforderung dar, wobei ReaderLM-v2 diese Fälle besser handhabte als die Baseline Reader API.</p><h2 id=\"how-we-trained-readerlm-v2\">Wie wir ReaderLM v2 trainiert haben</h2><p>ReaderLM-v2 basiert auf <code><strong>Qwen2.5-1.5B-Instruction</strong></code>, einem kompakten Basismodell, das für seine Effizienz bei der Anweisungsbefolgung und bei Aufgaben mit langem Kontext bekannt ist. In diesem Abschnitt beschreiben wir, wie wir das <code>ReaderLM-v2</code> trainiert haben, mit Fokus auf Datenvorbereitung, Trainingsmethoden und den Herausforderungen, denen wir begegnet sind.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model Parameter</th>\n<th>ReaderLM-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Parameters</td>\n<td>1.54B</td>\n</tr>\n<tr>\n<td>Max Context Length (Input+Output)</td>\n<td>512K</td>\n</tr>\n<tr>\n<td>Hidden Size</td>\n<td>1536</td>\n</tr>\n<tr>\n<td>Number of Layers</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Query Heads</td>\n<td>12</td>\n</tr>\n<tr>\n<td>KV Heads</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Head Size</td>\n<td>128</td>\n</tr>\n<tr>\n<td>Intermediate Size</td>\n<td>8960</td>\n</tr>\n<tr>\n<td>Multilingual Support</td>\n<td>29 languages</td>\n</tr>\n<tr>\n<td>HuggingFace Repository</td>\n<td>Link</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"data-preparation\">Datenvorbereitung</h3><p>Der Erfolg von ReaderLM-v2 hing größtenteils von der Qualität seiner Trainingsdaten ab. Wir erstellten den <code>html-markdown-1m</code> Datensatz, der eine Million HTML-Dokumente aus dem Internet enthielt. Im Durchschnitt enthielt jedes Dokument 56.000 Token, was die Länge und Komplexität realer Webdaten widerspiegelt. Zur Vorbereitung dieses Datensatzes bereinigten wir die HTML-Dateien durch Entfernen unnötiger Elemente wie JavaScript und CSS, während wir wichtige Struktur- und semantische Elemente beibehielten. Nach der Bereinigung verwendeten wir <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a>, um HTML-Dateien mithilfe von Regex-Mustern und Heuristiken in Markdown umzuwandeln.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--76-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--76-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Das Token-Längen-Histogramm der HTML-Dateien im </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>html-markdown-1m</span></code><span style=\"white-space: pre-wrap;\"> Datensatz</span></figcaption></figure><p>Während dies einen funktionalen Basis-Datensatz schuf, zeigte sich eine kritische Einschränkung: <strong>Modelle, die ausschließlich mit diesen direkten Konvertierungen trainiert wurden, würden im Wesentlichen nur lernen, die von Jina Reader verwendeten Regex-Muster und Heuristiken nachzuahmen.</strong> Dies wurde bei <code>reader-lm-0.5b/1.5b</code> deutlich, deren Leistungsgrenze durch die Qualität dieser regelbasierten Konvertierungen eingeschränkt war.</p><p>Um diese Einschränkungen zu adressieren, entwickelten wir eine dreistufige Pipeline, die sich auf das <code>Qwen2.5-32B-Instruction</code> Modell stützte, was für die Erstellung eines hochwertigen synthetischen Datensatzes essentiell war.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--73-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--73-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Synthetische Datengenerierungs-Pipeline für ReaderLM-v2, angetrieben von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Qwen2.5-32B-Instruction</span></code></figcaption></figure><ol><li><strong>Entwurf</strong>: Wir generierten erste Markdown- und JSON-Ausgaben basierend auf den dem Modell gegebenen Anweisungen. Diese Ausgaben waren zwar vielfältig, aber oft verrauscht oder inkonsistent.</li><li><strong>Verfeinerung</strong>: Die generierten Entwürfe wurden durch Entfernen redundanter Inhalte, Durchsetzen struktureller Konsistenz und Ausrichtung an gewünschten Formaten verbessert. Dieser Schritt stellte sicher, dass die Daten sauber und mit den Aufgabenanforderungen übereinstimmten.</li><li><strong>Kritik</strong>: Verfeinerte Ausgaben wurden anhand der ursprünglichen Anweisungen evaluiert. Nur Daten, die diese Evaluierung bestanden, wurden in den finalen Datensatz aufgenommen. Dieser iterative Ansatz stellte sicher, dass die Trainingsdaten die notwendigen Qualitätsstandards für strukturierte Datenextraktion erfüllten.</li></ol><h3 id=\"training-process\">Trainingsprozess</h3><p>Unser Trainingsprozess umfasste mehrere Phasen, die auf die Herausforderungen der Verarbeitung von Dokumenten mit langem Kontext zugeschnitten waren.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--75-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--75-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Das Training von ReaderLM v2 folgt einem iterativen Prozess, der dreistufige Datengenerierung (Entwurf-Verfeinerung-Kritik) mit Selbstspiel-Verfeinerung kombiniert und kontinuierliche Verbesserung ermöglicht.</span></figcaption></figure><p>Wir begannen mit dem <strong>Vortraining für langen Kontext</strong>, unter Verwendung des <code>html-markdown-1m</code> Datensatzes. Techniken wie Ring-Zag-Attention und Rotary Positional Encoding (RoPE) wurden verwendet, um die Kontextlänge des Modells schrittweise von 32.768 Token auf 256.000 Token zu erweitern. Um Stabilität und Effizienz zu gewährleisten, verwendeten wir einen graduellen Trainingsansatz, beginnend mit kürzeren Sequenzen und schrittweiser Erhöhung der Kontextlänge.</p><p>Nach dem Vortraining gingen wir zum <strong>überwachten Feintuning (SFT)</strong> über. Diese Phase nutzte die verfeinerten Datensätze, die im Datenvorbereitungsprozess generiert wurden. Diese Datensätze enthielten detaillierte Anweisungen für Markdown- und JSON-Extraktionsaufgaben sowie Beispiele für die Verfeinerung von Entwürfen. Jeder Datensatz wurde sorgfältig konzipiert, um dem Modell beim Lernen spezifischer Aufgaben zu helfen, wie etwa der Identifizierung von Hauptinhalten oder der Einhaltung schemabasierter JSON-Strukturen.</p><p>Dann wendeten wir <strong>Direct Preference Optimization (DPO)</strong> an, um die Ausgaben des Modells mit hochwertigen Ergebnissen in Einklang zu bringen. In dieser Phase wurde das Modell mit Paaren von Entwurfs- und verfeinerten Antworten trainiert. Durch das Lernen, die verfeinerten Ausgaben zu priorisieren, verinnerlichte das Modell die subtilen Unterschiede, die polierte und aufgabenspezifische Ergebnisse definieren.</p><p>Schließlich implementierten wir <strong>Selbstspiel-Reinforcement-Tuning</strong>, einen iterativen Prozess, bei dem das Modell seine eigenen Ausgaben generierte, verfeinerte und evaluierte. Dieser Zyklus ermöglichte es dem Modell, sich kontinuierlich zu verbessern, ohne zusätzliche externe Überwachung zu benötigen. Durch die Nutzung seiner eigenen Kritiken und Verfeinerungen verbesserte das Modell schrittweise seine Fähigkeit, genaue und strukturierte Ausgaben zu produzieren.</p><h2 id=\"conclusion\">Fazit</h2><p>Im April 2024 wurde Jina Reader die erste LLM-freundliche Markdown-API. Sie setzte einen neuen Trend, erlangte breite Community-Akzeptanz und inspirierte uns vor allem dazu, kleine Sprachmodelle für Datenbereinigung und -extraktion zu entwickeln. Heute setzen wir mit ReaderLM-v2 erneut neue Maßstäbe und erfüllen die Versprechen, die wir im letzten September gegeben haben: bessere Handhabung langer Kontexte, Unterstützung für Eingabeanweisungen und die Fähigkeit, spezifische Webseiteninhalte in Markdown-Format zu extrahieren. Einmal mehr haben wir gezeigt, dass kleine Sprachmodelle mit sorgfältigem Training und Kalibrierung eine State-of-the-Art-Leistung erreichen können, die größere Modelle übertrifft.</p><p>Während des Trainingsprozesses von ReaderLM-v2 identifizierten wir zwei Erkenntnisse. Eine effektive Strategie war das Training spezialisierter Modelle auf separaten Datensätzen, die auf spezifische Aufgaben zugeschnitten waren. Diese aufgabenspezifischen Modelle wurden später durch lineare Parameterinterpolation <em>verschmolzen</em>. Während dieser Ansatz zusätzlichen Aufwand erforderte, half er dabei, die einzigartigen Stärken jedes spezialisierten Modells im endgültigen vereinheitlichten System zu bewahren.</p><p>Der iterative Datensyntheseprozess erwies sich als entscheidend für den Erfolg unseres Modells. Durch wiederholte Verfeinerung und Auswertung synthetischer Daten konnten wir die Modellleistung deutlich über einfache regelbasierte Ansätze hinaus verbessern. Diese iterative Strategie war, trotz der Herausforderungen bei der Aufrechterhaltung konsistenter Kritikauswertungen und der Verwaltung von Rechenkosten, essentiell, um die Grenzen der Verwendung von regex- und heuristikbasierten Trainingsdaten aus Jina Reader zu überwinden. Dies zeigt sich deutlich am Leistungsunterschied zwischen <code>reader-lm-1.5b</code>, das stark auf den regelbasierten Konvertierungen von Jina Reader basiert, und <code>ReaderLM-v2</code>, das von diesem iterativen Verfeinerungsprozess profitiert.</p><p>Wir freuen uns auf Ihr Feedback, wie ReaderLM-v2 Ihre Datenqualität verbessert. Mit Blick auf die Zukunft planen wir die Erweiterung um multimodale Fähigkeiten, insbesondere für gescannte Dokumente, und eine weitere Optimierung der Generierungsgeschwindigkeit. Wenn Sie an einer auf Ihren spezifischen Bereich zugeschnittenen Version von ReaderLM interessiert sind, kontaktieren Sie uns bitte.</p>",
  "comment_id": "6785bfd62defad0001fb5f22",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/readerlm-v2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-01-14T02:37:26.000+01:00",
  "updated_at": "2025-01-15T11:35:18.000+01:00",
  "published_at": "2025-01-15T11:35:18.000+01:00",
  "custom_excerpt": "ReaderLM-v2 is a 1.5B small language model for HTML-to-Markdown conversion and HTML-to-JSON extraction with exceptional accuracy.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json/",
  "excerpt": "ReaderLM-v2 ist ein kleines Sprachmodell mit 1,5 Milliarden Parametern für HTML-to-Markdown-Konvertierung und HTML-to-JSON-Extraktion mit außergewöhnlicher Genauigkeit.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}