{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "Was wir bei der ICML2024 gelernt haben - mit PLaG, XRM, tinyBenchmark, MagicLens, Prompt Sketching und mehr",
  "html": "<p>Die <a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">International Conference on Machine Learning</a> ist eine der renommiertesten Konferenzen in der Machine Learning- und Künstliche-Intelligenz-Community und fand dieses Jahr vom 21. bis 27. Juli in Wien statt.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Interior of a bustling academic conference hall with many attendees, some carrying backpacks, and research posters displayed \" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Die Konferenz war eine 7-tägige intensive Lernerfahrung mit Vorträgen und Gelegenheiten zum direkten Ideenaustausch mit anderen Forschern. Es gibt viele interessante Arbeiten im Bereich Reinforcement Learning, KI für Biowissenschaften, Representation Learning, Multi-modale Modelle und natürlich in den Kernbereichen der KI-Modellentwicklung. Besonders wichtig war das Tutorial über die <a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">Physik von Large Language Models</a>, das die inneren Funktionsweisen von LLMs ausführlich untersuchte und überzeugende Antworten auf die Frage lieferte, ob LLMs Informationen memorieren oder logisches Denken anwenden, wenn sie Aussagen treffen.</p><h2 id=\"our-work-on-jina-clip-v1\">Unsere Arbeit an Jina-CLIP-v1</h2><p>Wir hielten eine <a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">Poster-Präsentation</a> über <a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">die Arbeit hinter unserem neuen multi-modalen Modell</a> <code>jina-clip-v1</code> im Rahmen des Workshops <a href=\"https://icml.cc/virtual/2024/workshop/29957?ref=jina-ai-gmbh.ghost.io\">Multi-modal Foundation Models meet Embodied AI</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>Das Treffen und die Diskussion unserer Arbeit mit internationalen Kollegen aus vielen Bereichen war sehr inspirierend. Unsere Präsentation erhielt viel positives Feedback, wobei viele Menschen sich für die Art und Weise interessierten, wie Jina CLIP multi-modale und uni-modale kontrastive Lernparadigmen vereint. Die Diskussionen reichten von den Grenzen der CLIP-Architektur über Erweiterungen auf zusätzliche Modalitäten bis hin zu Anwendungen im Peptid- und Protein-Matching.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster.mp4\" poster=\"https://img.spacergif.org/v1/1138x640/0a/spacer.png\" width=\"1138\" height=\"640\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">3:09</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Michael Günther präsentiert Jina CLIP</span></p></figcaption>\n        </figure><h2 id=\"our-favorites\">Unsere Favoriten</h2><p>Wir hatten die Gelegenheit, viele Projekte und Präsentationen anderer Forscher zu diskutieren. Hier sind einige unserer Favoriten:</p><h3 id=\"plan-like-a-graph-plag\">Plan Like a Graph (PLaG)</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., & Pierrehumbert, J. B. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Graph-Enhanced Large Language Models in Asynchronous Plan Reasoning.</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>Viele kennen \"Few-Shot Prompting\" oder \"Chain of Thought Prompting\". <a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> präsentierte auf der ICML eine neue und bessere Methode: <em>Plan Like a Graph (PLaG)</em>.</p><p>Ihre Idee ist einfach: Eine Aufgabe, die einem LLM gegeben wird, wird in Teilaufgaben zerlegt, die ein LLM entweder parallel oder sequentiell lösen kann. Diese Teilaufgaben bilden einen Ausführungsgraphen. Die Ausführung des gesamten Graphen löst die übergeordnete Aufgabe.</p><p>Im obigen Video erklärt Fangru Lin die Methode anhand eines leicht verständlichen Beispiels. Beachten Sie, dass LLMs trotz dieser Verbesserung immer noch unter drastischer Leistungsabnahme leiden, wenn die Aufgabenkomplexität zunimmt. Dennoch ist es ein wichtiger Schritt in die richtige Richtung und bietet unmittelbare praktische Vorteile.</p><p>Für uns ist es interessant zu sehen, wie ihre Arbeit Parallelen zu unseren Prompt-Anwendungen bei <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> aufweist. Wir haben bereits eine graphenähnliche Prompt-Struktur implementiert, aber die dynamische Generierung eines Ausführungsgraphen, wie sie es gemacht hat, ist eine neue Richtung, die wir erkunden werden.</p><h3 id=\"discovering-environments-with-xrm\">Entdeckung von Umgebungen mit XRM</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., &amp; Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>Diese Arbeit präsentiert einen einfachen Algorithmus zur Entdeckung von Trainingsumgebungen, die ein Modell dazu bringen können, sich auf Merkmale zu verlassen, die zwar mit den Labels korrelieren, aber keine genaue Klassifizierung/Relevanz erzeugen. Ein bekanntes Beispiel ist der Waterbirds-Datensatz (siehe <a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a>), der Fotos von Vögeln vor verschiedenen Hintergründen enthält, die entweder als Wasservögel oder Landvögel klassifiziert werden sollen. Während des Trainings erkennt der Klassifikator, ob der Hintergrund in den Bildern Wasser zeigt oder nicht, anstatt sich auf die Merkmale der Vögel selbst zu verlassen. Ein solches Modell wird Wasservögel falsch klassifizieren, wenn sich kein Wasser im Hintergrund befindet.</p><p>Um dieses Verhalten zu mindern, muss man Proben erkennen, bei denen sich das Modell auf irreführende Hintergrundmerkmale stützt. Dieses Paper stellt den XRM-Algorithmus vor, um dies zu erreichen.</p><p>Der Algorithmus trainiert zwei Modelle auf zwei verschiedenen Teilen des Trainingsdatensatzes. Während des Trainings werden die Labels einiger Proben umgekehrt. Dies geschieht speziell dann, wenn das andere Modell (das nicht auf der jeweiligen Probe trainiert wurde) eine Probe anders klassifiziert. Auf diese Weise werden die Modelle ermutigt, sich auf irreführende Korrelationen zu verlassen. Anschließend können Sie Proben aus den Trainingsdaten extrahieren, bei denen sich ein von einem der Modelle vorhergesagtes Label vom Ground Truth unterscheidet. Später kann man diese Information nutzen, um robustere Klassifikationsmodelle zu trainieren, zum Beispiel mit dem <a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">Group DRO Algorithmus</a>.</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">Reduzieren Sie Ihre LLM-Evaluierungskosten um den Faktor 140!</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., &amp; Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>Ja, Sie haben richtig gehört. Mit diesem einen Trick können die Kosten der LLM-Evaluierung auf einen winzigen Bruchteil reduziert werden.</p><p>Die Kernidee ist einfach: Entfernen Sie alle Evaluierungsbeispiele, die die gleiche Modellfähigkeit testen. Die Mathematik dahinter ist weniger geradlinig, wird aber von <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a>, der seine Arbeit während der Poster-Session vorstellte, gut erklärt. Beachten Sie, dass die Reduzierung um den Faktor 140 für den populären MMLU-Datensatz (Massive Multitask Language Understanding) gilt. Für Ihre eigenen Evaluierungsdatensätze hängt es davon ab, wie stark die Evaluierungsergebnisse der Proben miteinander korrelieren. Vielleicht können Sie viele Proben überspringen oder nur wenige.</p><p>Probieren Sie es einfach aus. Wir werden Sie auf dem Laufenden halten, wie stark wir bei <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> die Evaluierungsbeispiele reduzieren konnten.</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">Kontrastierung multipler Repräsentationen mit der Multi-Marginal Matching Gap</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., &amp; Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Research paper diagram illustrating Multi-Marginal Matching Gap concepts, with titles, descriptions, and flow charts in blue \" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Diese Arbeit behandelt eine häufige Herausforderung im kontrastiven Lernen: Die meisten kontrastiven Verlustfunktionen wie der InfoNCE-Loss arbeiten mit Datenpaaren und messen den Abstand zwischen positiven Paaren. Um auf positive Tupel der Größe k &gt; 2 zu erweitern, versucht kontrastives Lernen üblicherweise, das Problem auf mehrere Paare zu reduzieren und paarweise Verluste für alle positiven Paare zu akkumulieren. Die Autoren schlagen hier den M3G (Multi-Marginal Matching Gap) Loss vor, eine modifizierte Version des Sinkhorn-Algorithmus, der das Multi-Marginale Optimale Transport-Problem löst. Diese Verlustfunktion kann in Szenarien verwendet werden, in denen die Datensätze aus positiven Tupeln mit Größe k &gt; 2 bestehen, zum Beispiel &gt;2 Bilder desselben Objekts, multimodale Probleme mit drei oder mehr Modalitäten oder eine SimCLR-Erweiterung mit drei oder mehr Augmentierungen desselben Bildes. Empirische Ergebnisse zeigen, dass diese Methode die naive Reduktion des Problems auf Paare übertrifft.</p><h3 id=\"no-need-for-ground-truth\">Keine Ground Truth erforderlich!</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p><a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a> von der <a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">Stanford University</a> präsentierte seine Arbeit zur Evaluierung von LLMs ohne gelabelte Daten. Beachten Sie, dass dies zwar theoretische Arbeit ist, aber ein großes Potenzial für die skalierbare Überwachung fortgeschrittener KI-Systeme hat. Dies ist nichts für gelegentliche LLM-Nutzer, aber wenn Sie an LLM-Evaluierung arbeiten, sollten Sie sich definitiv damit beschäftigen. Wir sehen bereits, dass wir unsere Agenten bei Jina AI auf diese Weise evaluieren könnten. Wir werden die Ergebnisse teilen, sobald wir die ersten Experimente durchgeführt haben.</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">Ist Modellkollaps unvermeidlich? Durchbrechen des Rekursionsfluchs durch Akkumulation realer und synthetischer Daten</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration of two machine learning data processes: &quot;Replace Data&quot; and &quot;Accumulate Data&quot;, with detailed flowcharts and model\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Mehrere Artikel (wie dieser <a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em> Artikel</a>) haben kürzlich vorhergesagt, dass die Leistung neu trainierter Modelle mit der Zeit schlechter werden könnte, da die aus dem Web gecrawlten Trainingsdaten einen zunehmend hohen Anteil an synthetischen Daten enthalten.</p><p>Unser Kollege Scott Martens hat auch <a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">einen Artikel über Model Collapse</a> veröffentlicht und Fälle diskutiert, in denen synthetische Daten für das Modelltraining nützlich sein können.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>Modelltraining-Durchläufe könnten kollabieren, weil die Trainingsdaten von einer früheren Version des Modells oder einem Modell produziert wurden, das mit denselben Daten trainiert wurde. Diese Studie zeigt durch Experimente ein etwas anderes Bild: Ein Kollaps tritt nur auf, wenn echte Daten durch synthetische ersetzt werden, wie es in früheren Experimenten gemacht wurde. Wenn jedoch echte Daten mit zusätzlichen synthetischen Daten ergänzt werden, gibt es keine messbare Veränderung in der Leistung der resultierenden Modelle. Diese Ergebnisse deuten darauf hin, dass so etwas wie ein Model Collapse nicht eintreten wird. Es beweist jedoch erneut, dass die Verwendung zusätzlicher synthetischer Daten nicht hilft, ein Modell zu trainieren, das dem Modell, das zur Erstellung dieser synthetischen Datenpunkte verwendet wurde, allgemein überlegen ist.</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">Gehirnchirurgie für KI ist jetzt möglich</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., & Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>Angenommen, Sie möchten den Beruf einer Person vorhersagen, aber nicht ihr Geschlecht. Diese Arbeit von Google Research, ETH Zürich, International Institute of Information Technology Hyderabad (IIITH) und Bar-Ilan University zeigt, wie Steering-Vektoren und Kovarianz-Matching zur Kontrolle von Bias eingesetzt werden können.</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - Selbstüberwachtes Bildsuchsystem mit offenen Anweisungen</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., & Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Diese Arbeit stellt die MagicLens-Modelle vor, eine Reihe von selbstüberwachten Bildsuchmodellen, die auf Tripeln aus Abfragebild + Anweisung + Zielbild trainiert wurden.</p><p>Die Autoren stellen eine Datenerstellungs-/Kuratierungspipeline vor, die Bildpaare aus dem Web sammelt und LLMs verwendet, um offene Textanweisungen zu synthetisieren, die die Bilder mit verschiedenen semantischen Beziehungen jenseits bloßer visueller Ähnlichkeit verknüpfen. Diese Pipeline wird verwendet, um 36,7 Millionen qualitativ hochwertige Tripel über eine breite Verteilung zu erzeugen. Der Datensatz wird dann verwendet, um eine einfache Dual-Encoder-Architektur mit gemeinsamen Parametern zu trainieren. Die Backbone Vision- und Language-Encoder werden entweder mit CoCa- oder CLIP-Base- und Large-Varianten initialisiert. Ein einzelner Multi-Head-Attention-Pooler wird eingeführt, um die beiden multimodalen Eingaben in ein einziges Embedding zu komprimieren. Das Trainingsziel kontrastiert das Abfragebild und die Anweisungspaar mit dem Zielbild und der leeren Zeichenkettenanweisung mit einem einfachen InfoNCE-Loss, um MagicLens zu trainieren. Die Autoren präsentieren Evaluierungsergebnisse zur anweisungsbasierten Bildsuche.</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - Die neue Art des Prompting</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., & Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>Die Art und Weise, wie wir LLMs prompten, verändert sich. Prompt Sketching ermöglicht es uns, generativen Modellen feste Einschränkungen zu geben. Anstatt nur eine Anweisung zu geben und zu hoffen, dass das Modell das tut, was Sie möchten, definieren Sie eine vollständige Vorlage, die das Modell zwingt, das zu generieren, was Sie möchten.</p><p>Verwechseln Sie dies nicht mit LLMs, die darauf trainiert wurden, ein strukturiertes JSON-Format bereitzustellen. Bei dem Fine-Tuning-Ansatz hat das Modell immer noch die Freiheit zu generieren, was es möchte. Nicht so beim Prompt Sketching. Es bietet einen völlig neuen Werkzeugkasten für Prompt Engineers und eröffnet Forschungsbereiche, die noch erkundet werden müssen. Im obigen Video erklärt Mark Müller im Detail, worum es bei diesem neuen Paradigma geht.</p><p>Sie können auch <a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">ihr Open-Source-Projekt LMQL</a> ausprobieren.</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - Selektives Retrieval für Repository-Level Code Completion</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., & Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>Für viele Anfragen hilft RAG dem Modell nicht wirklich, weil die Anfrage entweder zu einfach ist oder das Retrieval-System keine relevanten Dokumente finden kann, möglicherweise weil es keine gibt. Dies führt zu längeren Generierungszeiten und geringerer Leistung, wenn sich das Modell auf irreführende oder fehlende Quellen verlässt.</p><p>Diese Arbeit adressiert das Problem, indem sie LLMs ermöglicht, selbst zu evaluieren, ob Retrieval nützlich ist. Sie demonstrieren diesen Ansatz an einem Code-Completion-Modell, das darauf trainiert ist, eine Lücke in einer Code-Vorlage zu füllen. Für eine gegebene Vorlage entscheidet das System zunächst, ob Retrieval-Ergebnisse nützlich sind und ruft gegebenenfalls den Retriever auf. Schließlich generiert das Code-LLM den fehlenden Kontext, unabhängig davon, ob Retrieval-Ergebnisse zu seinem Prompt hinzugefügt wurden oder nicht.</p><h3 id=\"the-platonic-representation-hypothesis\">Die Platonische Repräsentationshypothese</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., & Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration of &quot;The Platonic Representation Hypothesis&quot; with geometric shapes, mathematical text, and diagrams explaining a \" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Die <em>Platonische Repräsentationshypothese</em> argumentiert, dass neuronale Netzwerkmodelle dazu tendieren, zu einer gemeinsamen Repräsentation der Welt zu konvergieren. In Anlehnung an <a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">Platons Ideenlehre</a>, die Vorstellung, dass es eine Welt der \"Ideale\" gibt, die uns nur in verzerrter Form erscheint und die wir nur indirekt beobachten können, behaupten die Autoren, dass unsere KI-Modelle zu einer einzigen Repräsentation der Realität zu konvergieren scheinen, unabhängig von Trainingsarchitektur, Trainingsdaten oder sogar Eingabemodalität. Je größer der Datenumfang und die Modellgröße, desto ähnlicher scheinen ihre Repräsentationen zu werden.</p><p>Die Autoren betrachten Vektorrepräsentationen und messen die Ausrichtung der Repräsentationen mithilfe von Kernel-Alignment-Metriken, insbesondere einer Mutual-Nearest-Neighbor-Metrik, die die mittlere Schnittmenge der k-nächsten Nachbarmengen misst, die von zwei Kernels, K1 und K2, induziert werden, normalisiert durch k. Diese Arbeit präsentiert empirische Belege dafür, dass die Kernels umso stärker ausgerichtet sind, je größer die Modell- und Datensatzgrößen werden und je besser die Leistung wird. Diese Ausrichtung lässt sich auch beim Vergleich von Modellen unterschiedlicher Modalitäten beobachten, wie Text- und Bildmodellen.</p><h2 id=\"summary\">Zusammenfassung</h2><p>Die anfängliche Begeisterung für das Scaling-Law beginnt zwar nachzulassen, aber die ICML 2024 hat gezeigt, dass so viele neue, vielfältige, kreative Talente in unser Fachgebiet eingetreten sind, dass wir sicher sein können, dass der Fortschritt noch lange nicht zu Ende ist.</p><p>Wir hatten eine großartige Zeit bei der ICML 2024 und Sie können sicher sein, dass wir 2025 wieder dabei sein werden 🇨🇦.</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "Wir hatten eine großartige Zeit bei der ICML 2024 in Wien und möchten mit Ihnen alles teilen, was wir gesagt, gesehen und gelernt haben.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}