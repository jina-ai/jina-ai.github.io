{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3: Ein wegweisendes mehrsprachiges Embedding-Modell",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3: Multilingual Embeddings With Task LoRA</div><div class=\"kg-bookmark-description\">Wir stellen jina-embeddings-v3 vor, ein neuartiges Text-Embedding-Modell mit 570 Millionen Parametern, das Spitzenleistungen bei mehrsprachigen Daten und Long-Context-Retrieval-Aufgaben erzielt und Kontextlängen von bis zu 8192 Token unterstützt. Das Modell enthält eine Reihe aufgabenspezifischer Low-Rank Adaptation (LoRA) Adapter zur Generierung hochwertiger Embeddings für Query-Dokument-Retrieval, Clustering, Klassifizierung und Text-Matching. Zusätzlich wurde Matryoshka Representation Learning in den Trainingsprozess integriert, was eine flexible Kürzung der Embedding-Dimensionen ohne Leistungseinbußen ermöglicht. Die Evaluation auf dem MTEB-Benchmark zeigt, dass jina-embeddings-v3 die neuesten proprietären Embeddings von OpenAI und Cohere bei englischen Aufgaben übertrifft und im Vergleich zu multilingual-e5-large-instruct bei allen mehrsprachigen Aufgaben überlegene Leistung erzielt.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Heute freuen wir uns, <code>jina-embeddings-v3</code> vorzustellen, ein wegweisendes Text-Embedding-Modell mit 570 Millionen Parametern. Es erzielt Spitzenleistungen bei **mehrsprachigen** Daten und **Long-Context** Retrieval-Aufgaben und unterstützt eine Eingabelänge von bis zu 8192 Token. Das Modell verfügt über aufgabenspezifische Low-Rank Adaptation (LoRA) Adapter, die es ermöglichen, hochwertige Embeddings für verschiedene Aufgaben wie **Query-Document Retrieval**, **Clustering**, **Klassifizierung** und **Text-Matching** zu generieren.</p><p>In Evaluierungen auf MTEB English, Multilingual und LongEmbed übertrifft <code>jina-embeddings-v3</code> die neuesten proprietären Embeddings von OpenAI und Cohere bei englischen Aufgaben und übertrifft gleichzeitig <code>multilingual-e5-large-instruct</code> bei allen mehrsprachigen Aufgaben. Mit einer Standard-Ausgabedimension von 1024 können Benutzer die Embedding-Dimensionen dank der Integration von Matryoshka Representation Learning (MRL) beliebig bis auf 32 reduzieren, ohne Leistungseinbußen in Kauf nehmen zu müssen.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\">Die Leistung von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> im Vergleich zu anderen Embedding-Modellen über alle MTEB English Tasks. Vollständige Evaluierungsergebnisse pro Aufgabe finden Sie in </span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">unserem arXiv Paper</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">Die Leistung von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> wurde über eine breite Auswahl von mehrsprachigen und cross-lingualen MTEB-Aufgaben evaluiert. Bitte beachten Sie, dass sich </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2-(zh/es/de)</span></code><span style=\"white-space: pre-wrap;\"> auf unsere zweisprachige Modell-Suite bezieht, die nur für chinesische, spanische und deutsche monolinguale und cross-linguale Aufgaben getestet wurde, unter Ausschluss aller anderen Sprachen. Zusätzlich berichten wir keine Scores für </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>openai-text-embedding-3-large</span></code><span style=\"white-space: pre-wrap;\"> und </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>cohere-embed-multilingual-v3.0</span></code><span style=\"white-space: pre-wrap;\">, da diese Modelle nicht auf der vollen Bandbreite mehrsprachiger und cross-lingualer MTEB-Aufgaben evaluiert wurden.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">Die Leistung von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> bei sechs Long-Document-Retrieval-Aufgaben aus dem LongEmbed-Benchmark zeigt eine signifikante Verbesserung gegenüber anderen Modellen. Die Scores sind nDCG@10; höher ist besser. Dies deutet auf die Effektivität unserer RoPE-basierten Positions-Embeddings hin, die sowohl die festen Positions-Embeddings von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>baai-bge-m3</span></code><span style=\"white-space: pre-wrap;\"> als auch den ALiBi-basierten Ansatz von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\"> übertreffen.</span></figcaption></figure><p>Mit seiner Veröffentlichung am 18. September 2024 ist <code>jina-embeddings-v3</code> **das beste** mehrsprachige Modell und belegt den **2. Platz** auf der MTEB English Leaderboard für Modelle mit weniger als 1 Milliarde Parametern. v3 unterstützt insgesamt 89 Sprachen, darunter 30 Sprachen mit der besten Leistung: Arabisch, Bengalisch, Chinesisch, Dänisch, Niederländisch, Englisch, Finnisch, Französisch, Georgisch, Deutsch, Griechisch, Hindi, Indonesisch, Italienisch, Japanisch, Koreanisch, Lettisch, Norwegisch, Polnisch, Portugiesisch, Rumänisch, Russisch, Slowakisch, Spanisch, Schwedisch, Thai, Türkisch, Ukrainisch, Urdu und Vietnamesisch.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Mit seiner Veröffentlichung am 18. September 2024 ist </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\">, mit 570 Millionen Parametern und 1024 Ausgabedimensionen, das effizienteste, leistungsfähigste und zuverlässigste mehrsprachige Embedding-Modell mit weniger als 1 Milliarde Parametern.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">Skalierungsgesetz der Embedding-Modelle. Die durchschnittliche MTEB-Leistung bei englischen Aufgaben ist gegen die Anzahl der Modellparameter aufgetragen. Jeder Punkt repräsentiert ein Embedding-Modell. Die Trendlinie, die alle Modelle repräsentiert, ist hervorgehoben, wobei mehrsprachige Modelle in Cyan betont sind. Man kann sehen, dass </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> im Vergleich zu Modellen ähnlicher Größe überlegene Leistung zeigt und auch eine überlineare Verbesserung gegenüber seinem Vorgänger </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\"> aufweist. Diese Grafik wurde durch Auswahl der Top-100 Embedding-Modelle aus der MTEB-Leaderboard erstellt, unter Ausschluss derjenigen ohne Größeninformation, typischerweise closed-source oder proprietäre Modelle. Einreichungen, die als offensichtliches Trolling identifiziert wurden, wurden ebenfalls herausgefiltert.</span></figcaption></figure><p>Im Vergleich zu LLM-basierten Embeddings, die kürzlich Aufmerksamkeit erregt haben, wie <code>e5-mistral-7b-instruct</code>, das eine Parametergröße von 7,1 Milliarden (12x größer) und eine Ausgabedimension von 4096 (4x größer) hat, aber nur 1% Verbesserung bei MTEB English Tasks bietet, ist <code>jina-embeddings-v3</code> eine weitaus kosteneffizientere Lösung, die es besser für den Produktionseinsatz und Edge-Computing geeignet macht.</p><h2 id=\"model-architecture\">Modellarchitektur</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>Parameter Basis</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>Parameter mit LoRA</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>Max. Input-Token</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>Max. Output-Dimensionen</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>Layer</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Vokabular</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>Unterstützte Sprachen</td>\n<td>89</td>\n</tr>\n<tr>\n<td>Attention</td>\n<td>FlashAttention2, funktioniert auch ohne</td>\n</tr>\n<tr>\n<td>Pooling</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Die Architektur von <code>jina-embeddings-v3</code> ist in der folgenden Abbildung dargestellt. Zur Implementierung der Backbone-Architektur haben wir das <code>XLM-RoBERTa</code> Modell mit mehreren wichtigen Modifikationen angepasst: (1) Ermöglichung der effektiven Kodierung langer Textsequenzen, (2) Erlaubnis aufgabenspezifischer Kodierung von Embeddings und (3) Verbesserung der allgemeinen Modelleffizienz mit neuesten Techniken. Wir verwenden weiterhin den originalen <code>XLM-RoBERTa</code> Tokenizer. Während <code>jina-embeddings-v3</code> mit seinen 570 Millionen Parametern größer ist als <code>jina-embeddings-v2</code> mit 137 Millionen, ist es immer noch deutlich kleiner als Embedding-Modelle, die von LLMs feinabgestimmt wurden.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\">Die Architektur von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> basiert auf dem </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\"> Modell mit fünf LoRA-Adaptern für vier verschiedene Aufgaben.</span></figcaption></figure><p>Die wichtigste Innovation in <code>jina-embeddings-v3</code> ist die Verwendung von LoRA-Adaptern. <strong>Fünf</strong> aufgabenspezifische LoRA-Adapter wurden eingeführt, um Embeddings für <strong>vier</strong> Aufgaben zu optimieren. Die Eingabe des Modells besteht aus zwei Teilen: dem Text (das lange Dokument, das eingebettet werden soll) und der Aufgabe. <code>jina-embeddings-v3</code> unterstützt vier Aufgaben und implementiert fünf Adapter zur Auswahl: <code>retrieval.query</code> und <code>retrieval.passage</code> für Query- und Passage-Embeddings in asymmetrischen Retrieval-Aufgaben, <code>separation</code> für Clustering-Aufgaben, <code>classification</code> für Klassifizierungsaufgaben und <code>text-matching</code> für Aufgaben mit semantischer Ähnlichkeit wie STS oder symmetrisches Retrieval. Die LoRA-Adapter machen weniger als 3% der Gesamtparameter aus und fügen nur minimalen Overhead zur Berechnung hinzu.</p><p>Zur weiteren Verbesserung der Leistung und Reduzierung des Speicherverbrauchs integrieren wir FlashAttention 2, unterstützen Activation Checkpointing und verwenden das DeepSpeed-Framework für effizientes verteiltes Training.</p><h2 id=\"get-started\">Erste Schritte</h2><h3 id=\"via-jina-ai-search-foundation-api\">Über die Jina AI Search Foundation API</h3><p>Der einfachste Weg, <code>jina-embeddings-v3</code> zu nutzen, ist ein Besuch der <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">Jina AI Homepage</a> und Navigation zum Search Foundation API-Bereich. Ab heute ist dieses Modell die Standardeinstellung für alle neuen Benutzer. Sie können verschiedene Parameter und Funktionen direkt von dort aus erkunden.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>Im Vergleich zu v2 führt v3 drei neue Parameter in der API ein: <code>task</code>, <code>dimensions</code> und <code>late_chunking</code>.</p><h4 id=\"parameter-task\">Parameter <code>task</code></h4><p>Der <code>task</code> Parameter ist entscheidend und muss entsprechend der nachgelagerten Aufgabe gesetzt werden. Die resultierenden Embeddings werden für diese spezifische Aufgabe optimiert. Weitere Details finden Sie in der Liste unten.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong><code>task</code> Wert</strong></th>\n<th><strong>Aufgabenbeschreibung</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>Embedding von <b>Dokumenten</b> in einer Query-Dokument-Retrieval-Aufgabe</td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>Embedding von <b>Anfragen</b> in einer Query-Dokument-Retrieval-Aufgabe</td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>Clustering von Dokumenten, Visualisierung eines Korpus</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>Textklassifikation</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(Standard)</b> Semantische Textähnlichkeit, allgemeines symmetrisches Retrieval, Empfehlungen, ähnliche Elemente finden, Deduplizierung</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Beachten Sie, dass die API <em>nicht</em> zuerst ein generisches Meta-Embedding erzeugt und es dann mit einem zusätzlichen feinabgestimmten MLP anpasst. Stattdessen fügt sie den aufgabenspezifischen LoRA-Adapter in jede Transformer-Schicht (insgesamt 24 Schichten) ein und führt die Kodierung in einem Durchgang durch. Weitere Details finden Sie in <a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">unserem arXiv-Paper</a>.</p><h4 id=\"parameter-dimensions\">Parameter <code>dimensions</code></h4><p>Der <code>dimensions</code> Parameter ermöglicht es Benutzern, einen Kompromiss zwischen Speichereffizienz und Leistung zu den niedrigsten Kosten zu wählen. Dank der in <code>jina-embeddings-v3</code> verwendeten MRL-Technik können Sie die Dimensionen der Embeddings beliebig reduzieren (sogar auf eine einzige Dimension!). Kleinere Embeddings sind speicherfreundlicher für Vektordatenbanken, und ihre Leistungskosten können aus der Abbildung unten abgeschätzt werden.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">Parameter <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Late Chunking in Long-Context Embedding Models</div><div class=\"kg-bookmark-description\">Chunking long documents while preserving contextual information is challenging. We introduce the \"Late Chunking\" that leverages long-context embedding models to generate contextual chunk embeddings for better retrieval applications.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Schließlich steuert der <code>late_chunking</code> Parameter, ob die neue Chunking-Methode verwendet werden soll, die wir <a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">letzten Monat eingeführt haben</a>, um einen Batch von Sätzen zu kodieren. Wenn auf <code>true</code> gesetzt, wird unsere API alle Sätze im <code>input</code> Feld verknüpfen und sie als einzelnen String an das Modell übergeben. Mit anderen Worten, <strong>wir behandeln die Sätze in der Eingabe so, als ob sie ursprünglich aus demselben Abschnitt, Absatz oder Dokument stammen.</strong> Intern bettet das Modell diesen langen verknüpften String ein und führt dann spätes Chunking durch, wobei eine Liste von Embeddings zurückgegeben wird, die der Größe der Eingabeliste entspricht. Jedes Embedding in der Liste ist daher von den vorherigen Embeddings abhängig.</p><p>Aus Benutzersicht ändert das Setzen von <code>late_chunking</code> <em>nicht</em> das Ein- oder Ausgabeformat. Sie werden nur eine Änderung in den Embedding-Werten bemerken, da diese nun basierend auf dem gesamten vorherigen Kontext berechnet werden und nicht unabhängig voneinander. Was wichtig ist zu wissen bei der Verwendung von<code>late_chunking=True</code> bedeutet, dass die Gesamtanzahl der Tokens (durch Summierung aller Tokens in <code>input</code>) pro Anfrage auf 8192 beschränkt ist, was der maximalen Kontextlänge für <code>jina-embeddings-v3</code> entspricht. Bei <code>late_chunking=False</code> gibt es keine solche Beschränkung; die Gesamtanzahl der Tokens unterliegt nur <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">dem Rate-Limit der Embedding-API</a>.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking Ein vs. Aus: Das Ein- und Ausgabeformat bleibt gleich, der einzige Unterschied liegt in den Embedding-Werten. Wenn </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\"> aktiviert ist, werden die Embeddings vom gesamten vorherigen Kontext in </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\"> beeinflusst, während ohne dies die Embeddings unabhängig berechnet werden.</span></p></figcaption></figure><h3 id=\"via-azure-aws\">Über Azure & AWS</h3><p><code>jina-embeddings-v3</code> ist jetzt auf AWS SageMaker und im Azure Marketplace verfügbar.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>Falls Sie es über diese Plattformen hinaus oder On-Premises in Ihrem Unternehmen nutzen möchten, beachten Sie, dass das Modell unter CC BY-NC 4.0 lizenziert ist. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Für kommerzielle Nutzungsanfragen kontaktieren Sie uns gerne.</a></p><h3 id=\"via-vector-databases-partners\">Über Vektordatenbanken & Partner</h3><p>Wir arbeiten eng mit Vektordatenbank-Anbietern wie Pinecone, Qdrant und Milvus sowie LLM-Orchestrierungs-Frameworks wie LlamaIndex, Haystack und Dify zusammen. Zum Zeitpunkt der Veröffentlichung freuen wir uns bekannt zu geben, dass Pinecone, Qdrant, Milvus und Haystack bereits die Unterstützung für <code>jina-embeddings-v3</code> integriert haben, einschließlich der drei neuen Parameter: <code>task</code>, <code>dimensions</code> und <code>late_chunking</code>. Andere Partner, die bereits die <code>v2</code> API integriert haben, sollten auch <code>v3</code> unterstützen, indem sie einfach den Modellnamen zu <code>jina-embeddings-v3</code> ändern. Allerdings unterstützen sie möglicherweise noch nicht die in <code>v3</code> neu eingeführten Parameter.</p><h4 id=\"via-pinecone\">Über Pinecone</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">Über Qdrant</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">Über Milvus</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">Über Haystack</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">Fazit</h2><p>Im Oktober 2023 veröffentlichten wir <code>jina-embeddings-v2-base-en</code>, <a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">das weltweit erste Open-Source-Embedding-Modell mit einer 8K-Kontextlänge</a>. Es war das <em>einzige</em> Text-Embedding-Modell, das langen Kontext unterstützte und mit OpenAIs <code>text-embedding-ada-002</code> mithalten konnte. Heute, nach einem Jahr des Lernens, Experimentierens und wertvoller Erkenntnisse, sind wir stolz darauf, <code>jina-embeddings-v3</code> zu veröffentlichen—einen neuen Meilenstein in Text-Embedding-Modellen und einen großen Meilenstein für unser Unternehmen.</p><p>Mit dieser Veröffentlichung bleiben wir weiterhin führend in dem, wofür wir bekannt sind: <strong>lange Kontext</strong>-<strong>Embeddings</strong>, während wir gleichzeitig die am häufigsten nachgefragte Funktion sowohl aus der Industrie als auch aus der Community adressieren—<strong>multilinguale Embeddings</strong>. Gleichzeitig treiben wir die Leistung auf ein neues Niveau. Mit neuen Funktionen wie aufgabenspezifischem LoRA, MRL und Late Chunking glauben wir, dass <code>jina-embeddings-v3</code> wirklich als grundlegendes Embedding-Modell für verschiedene Anwendungen dienen wird, einschließlich RAG, Agents und mehr. Im Vergleich zu neueren LLM-basierten Embeddings wie <code>NV-embed-v1/v2</code> ist unser Modell hochgradig parametereffizient, was es für die Produktion und Edge-Geräte viel besser geeignet macht.</p><p>In Zukunft planen wir, uns auf die Evaluierung und Verbesserung der <code>jina-embeddings-v3</code>-Leistung bei ressourcenarmen Sprachen zu konzentrieren und systemische Fehler aufgrund begrenzter Datenverfügbarkeit weiter zu analysieren. Darüber hinaus werden die Modellgewichte von <code>jina-embeddings-v3</code>, zusammen mit seinen innovativen Funktionen und neuen Ansätzen, als Grundlage für unsere kommenden Modelle dienen, einschließlich <code>jina-clip-v2</code>,<code>jina-reranker-v3</code> und <code>reader-lm-v2</code>.</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 ist ein wegweisendes mehrsprachiges Text-Embedding-Modell mit 570M Parametern und einer Token-Länge von 8192, das die neuesten proprietären Embeddings von OpenAI und Cohere bei MTEB übertrifft.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}