{
  "slug": "when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse",
  "id": "6639e8e1af8f52000115be49",
  "uuid": "1b3da192-0050-4b9e-8528-c5e638d50870",
  "title": "Wenn KI KI erschafft: Synthetische Daten, Model Distillation und Model Collapse",
  "html": "<p>Gespräche über KI sind oft apokalyptisch. Ein Teil der Schuld liegt darin, wie <a href=\"https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping?ref=jina-ai-gmbh.ghost.io\">apokalyptische Science-Fiction</a> unser mentales Bild von künstlicher Intelligenz geprägt hat. Visionen von intelligenten Maschinen, die weitere Maschinen herstellen können, sind seit Generationen ein häufiges Motiv in der Science-Fiction.</p><p>Viele Menschen haben sich zu existenziellen Risiken durch die jüngsten Entwicklungen in der KI geäußert, viele davon <a href=\"https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html?ref=jina-ai-gmbh.ghost.io\">Wirtschaftsführer, die an der Kommerzialisierung von KI beteiligt sind</a>, und sogar einige <a href=\"https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/?ref=jina-ai-gmbh.ghost.io\">Wissenschaftler</a> und <a href=\"https://www.lemonde.fr/en/international/article/2023/06/04/in-montreal-one-of-the-fathers-of-artificial-intelligence-warns-of-an-existential-threat-to-mankind_6029007_4.html?ref=jina-ai-gmbh.ghost.io\">Forscher</a>. Es ist zu einem Bestandteil des KI-Hypes geworden: Etwas, das mächtig genug ist, um nüchtern wirkende Ikonen aus Wissenschaft und Industrie über das Ende der Welt nachdenken zu lassen, muss sicherlich auch mächtig genug sein, um Profit zu machen, oder?</p><p>Sollten wir uns also Sorgen über existenzielle Risiken durch KI machen? Müssen wir befürchten, dass Sam Altman aus ChatGPT einen Ultron erschafft und dessen <a href=\"https://youtu.be/d4yZPjB7smU?ref=jina-ai-gmbh.ghost.io\">KI-Armee osteuropäische Städte auf uns wirft</a>? Sollten wir uns Sorgen machen, dass <a href=\"https://venturebeat.com/business/why-palantir-is-silicon-valleys-most-questionable-unicorn/?ref=jina-ai-gmbh.ghost.io\">Peter Thiels Palantir</a> <a href=\"https://youtu.be/4DQsG3TKQ0I?ref=jina-ai-gmbh.ghost.io\">Skynet aufbaut</a> und <a href=\"https://youtu.be/wOO9DSnLOm8?ref=jina-ai-gmbh.ghost.io\">Roboter mit unerklärlichem österreichischem Akzent in die Vergangenheit schickt, um uns zu töten</a>?</p><p>Wahrscheinlich nicht. Wirtschaftsführer haben bisher noch keinen klaren Weg gefunden, wie KI ihre eigenen Rechnungen bezahlen kann, geschweige denn Industrien durcheinanderbringen, und noch weniger die Menschheit in einem Ausmaß bedrohen kann, das mit dem Klimawandel oder Atomwaffen vergleichbar wäre.</p><p>Die KI-Modelle, die wir tatsächlich haben, sind kaum in der Lage, die Menschheit auszulöschen. Sie haben Schwierigkeiten, Hände zu zeichnen, können nicht mehr als drei Dinge zählen, denken, es sei <a href=\"https://www.nbcnewyork.com/news/local/nycs-ai-chatbot-was-caught-telling-businesses-to-break-the-law-the-city-isnt-taking-it-down/5287713/?ref=jina-ai-gmbh.ghost.io\">in Ordnung, Menschen Käse zu verkaufen, an dem Ratten genagt haben</a>, und <a href=\"https://www.techtimes.com/articles/304222/20240502/ai-priest-demoted-saying-babies-baptized-gatorade.htm?ref=jina-ai-gmbh.ghost.io\">führen katholische Taufen mit Gatorade durch</a>. Die mundanen, nicht-existenziellen Risiken der KI – die Art und Weise, wie die Technologie dabei helfen kann, Fehlinformationen zu verbreiten, zu belästigen, Spam zu generieren und von Menschen, die sich ihrer Grenzen nicht bewusst sind, schlecht eingesetzt zu werden – sind besorgniserregend genug.</p><p>Aber ein existenzielles Risiko der künstlichen Intelligenz ist definitiv legitim: KI stellt eine klare und gegenwärtige Gefahr für... <em>KI</em> dar.</p><p>Diese Befürchtung wird normalerweise als \"Model Collapse\" bezeichnet und wurde in <a href=\"https://arxiv.org/abs/2305.17493?ref=jina-ai-gmbh.ghost.io\">Shumailov et al. (2023)</a> und <a href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\">Alemohammad et al. (2023)</a> empirisch nachgewiesen. Die Idee ist einfach: Wenn man KI-Modelle mit KI-generierten Daten trainiert und dann die resultierende KI verwendet, um ein weiteres Modell zu trainieren, wobei dieser Prozess über mehrere Generationen wiederholt wird, wird die KI objektiv immer schlechter. Es ist wie eine Fotokopie einer Fotokopie einer Fotokopie.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png\" class=\"kg-image\" alt=\"Deteriorating copies of an ad for the Intertec Superbrain, taken from BYTE magazine, Sept. 1981.\" loading=\"lazy\" width=\"1200\" height=\"400\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Superbrain.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Superbrain.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Sich verschlechternde Kopien einer Werbung für den </span><a href=\"https://en.wikipedia.org/wiki/Intertec_Superbrain?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Intertec Superbrain</span></a><span style=\"white-space: pre-wrap;\">, aus der </span><a href=\"https://archive.org/details/byte-magazine-1981-09/page/n177/mode/2up\"><span style=\"white-space: pre-wrap;\">BYTE Zeitschrift, Sept. 1981</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>In letzter Zeit gab es einige Diskussionen über den Model Collapse, und es erscheinen <a href=\"https://www.businessinsider.com/ai-training-data-source-solutions-openai-meta-google-2024-4?ref=jina-ai-gmbh.ghost.io\">Schlagzeilen</a> <a href=\"https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?ref=jina-ai-gmbh.ghost.io\">darüber</a>, dass <a href=\"https://www.yahoo.com/news/ai-companies-running-training-data-220047540.html?guccounter=1&ref=jina-ai-gmbh.ghost.io\">KI-Unternehmen</a> <a href=\"https://www.businessinsider.com/ai-giants-openai-anthropic-running-out-of-good-training-data-2024-4?ref=jina-ai-gmbh.ghost.io\">die Trainingsdaten</a> <a href=\"https://www.technologyreview.com/2022/11/24/1063684/we-could-run-out-of-data-to-train-ai-language-programs/?ref=jina-ai-gmbh.ghost.io\">ausgehen</a>. Wenn das Internet mit KI-generierten Daten überfüllt wird und von Menschen erstellte Daten schwieriger zu identifizieren und zu nutzen sind, werden KI-Modelle bald an eine Qualitätsgrenze stoßen.</p><p>Gleichzeitig gibt es eine zunehmende Verwendung von <a href=\"https://en.wikipedia.org/wiki/Synthetic_data?ref=jina-ai-gmbh.ghost.io\">synthetischen Daten</a> und <a href=\"https://en.wikipedia.org/wiki/Knowledge_distillation?ref=jina-ai-gmbh.ghost.io\">Model Distillation</a> Techniken in der KI-Entwicklung. Beide bestehen darin, KI-Modelle zumindest teilweise mit der Ausgabe anderer KI-Modelle zu trainieren. Diese beiden Trends scheinen sich zu widersprechen.</p><p>Die Dinge sind etwas komplizierter als das. Wird generative KI den Fortschritt durch Spam ersticken und seinen eigenen Fortschritt behindern? Oder wird KI uns helfen, bessere KI zu entwickeln? Oder beides?</p><p>Wir werden versuchen, in diesem Artikel einige Antworten zu finden.</p><h2 id=\"model-collapse\">Model Collapse</h2><p>So sehr wir Alemohammad et al. dafür schätzen, dass sie den Begriff \"Model Autophagy Disorder (MAD)\" erfunden haben, \"Model Collapse\" ist viel eingängiger und kommt ohne griechische Wörter für Selbstkannibalismus aus. Die Metapher vom Anfertigen von Fotokopien von Fotokopien vermittelt das Problem in einfachen Worten, aber es steckt noch etwas mehr hinter der zugrunde liegenden Theorie.</p><p>Das Training eines KI-Modells ist eine Art der statistischen Modellierung, eine Erweiterung dessen, was Statistiker und Data Scientists schon lange tun. Aber am ersten Tag der Data Science-Klasse lernt man das Motto des Data Scientists:</p><blockquote><strong><em>Alle Modelle sind falsch</em></strong>,&nbsp;<strong><em>aber einige sind nützlich.</em></strong></blockquote><p>Dieses Zitat, das <a href=\"https://en.wikipedia.org/wiki/George_E._P._Box?ref=jina-ai-gmbh.ghost.io\">George Box</a> zugeschrieben wird, ist das blinkende rote Licht, das über jedem KI-Modell stehen sollte. Man kann immer ein statistisches Modell für beliebige Daten erstellen, und dieses Modell wird immer eine Antwort geben, aber absolut nichts garantiert, dass diese Antwort richtig oder auch nur annähernd richtig ist.</p><p>Ein statistisches Modell ist eine <em>Annäherung</em> an etwas. Seine Ausgaben können nützlich sein, sie könnten sogar gut genug sein, aber es bleiben Annäherungen. Selbst wenn man ein gut validiertes Modell hat, das im Durchschnitt sehr genau ist, kann und wird es wahrscheinlich trotzdem manchmal große Fehler machen.</p><p>KI-Modelle erben alle Probleme der statistischen Modellierung. Jeder, der mit ChatGPT oder einem anderen großen KI-Modell gespielt hat, hat gesehen, wie es Fehler macht.</p><p>Wenn also ein KI-Modell eine Annäherung an etwas Reales ist, dann ist ein KI-Modell, das mit der Ausgabe eines anderen KI-Modells trainiert wurde, eine Annäherung an eine Annäherung. Die Fehler häufen sich, und es muss zwangsläufig ein weniger korrektes Modell sein als das Modell, von dem es trainiert wurde.</p><p>Alemohammad et al. zeigen, dass man das Problem nicht beheben kann, indem man einige der ursprünglichen Trainingsdaten zur KI-Ausgabe hinzufügt, bevor man das neue \"Kind\"-Modell trainiert. Das verlangsamt den Model Collapse nur, kann ihn aber nicht aufhalten. Wenn nicht genügend neue, bisher ungesehene Daten aus der realen Welt beim Training mit KI-Ausgabe eingeführt werden, ist der Model Collapse unvermeidlich.</p><p>Wie viele neue Daten ausreichend sind, hängt von schwer vorhersehbaren, fallspezifischen Faktoren ab, aber mehr neue, echte Daten und weniger KI-generierte Daten sind immer besser als das Gegenteil.</p><p>Und das ist ein Problem, weil alle leicht zugänglichen Quellen für neue, von Menschen erstellte Daten bereits ausgeschöpft sind, während die Menge an KI-generierten Bild- und Textdaten dort draußen sprunghaft zunimmt. Das Verhältnis von menschlich erstellten zu KI-erstellten Inhalten im Internet sinkt, möglicherweise sogar schnell. Es gibt keine <a href=\"https://www.washingtonpost.com/technology/2023/06/02/turnitin-ai-cheating-detector-accuracy/?ref=jina-ai-gmbh.ghost.io\">zuverlässige Möglichkeit, KI-generierte Daten automatisch zu erkennen</a>, und <a href=\"https://arxiv.org/abs/2303.11156?ref=jina-ai-gmbh.ghost.io\">viele Forscher</a> <a href=\"https://www.techspot.com/news/98031-reliable-detection-ai-generated-text-impossible-new-study.html?ref=jina-ai-gmbh.ghost.io\">glauben, dass es keine geben kann</a>. Der öffentliche Zugang zu KI-Bild- und Textgenerierungsmodellen sorgt dafür, dass dieses Problem wachsen wird, wahrscheinlich dramatisch wachsen wird, und keine offensichtliche Lösung hat.</p><p>Die <a href=\"https://www.vice.com/en/article/y3w4gw/a-shocking-amount-of-the-web-is-already-ai-translated-trash-scientists-determine?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Menge an maschineller Übersetzung im Internet</a> könnte bedeuten, dass es bereits zu spät ist. Maschinell übersetzte Texte im Internet verschmutzen unsere Datenquellen schon seit Jahren, lange vor der generativen KI-Revolution. Laut <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">Thompson et al., 2024</a> könnte möglicherweise die Hälfte der Texte im Internet aus einer anderen Sprache übersetzt sein, und ein sehr großer Teil dieser Übersetzungen ist von schlechter Qualität und zeigt Anzeichen maschineller Erzeugung. Dies kann ein Sprachmodell, das mit solchen Daten trainiert wurde, verzerren.</p><p>Als Beispiel sehen Sie unten einen Screenshot von <a href=\"https://ww1.habsburger.net/en/chapters/hamster-buying-queuing-do-it-yourself-individual-strategies-provide-food-become?ref=jina-ai-gmbh.ghost.io\">einer Seite der Website <em>Die Welt der Habsburger</em></a>, der deutliche Anzeichen maschineller Übersetzung zeigt. \"Hamster buying\" ist eine zu wörtliche Übersetzung des deutschen Wortes <em>hamstern</em>, das <em>to hoard</em> oder <em>panic-buying</em> bedeutet. Zu viele solcher Fälle werden dazu führen, dass ein KI-Modell denkt, \"hamster buying\" sei eine echte Sache im Englischen und das deutsche <em>hamstern</em> hätte etwas mit Haustierhamstern zu tun.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.07.20.png\" loading=\"lazy\" width=\"1532\" height=\"1074\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.07.20.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1532w\" sizes=\"(min-width: 720px) 720px\"></figure><p>In fast allen Fällen ist es schlecht, mehr KI-Output in Ihren Trainingsdaten zu haben. Das <em>fast</em> ist wichtig, und wir werden unten zwei Ausnahmen besprechen.</p><h2 id=\"synthetic-data\">Synthetische Daten</h2><p>Synthetische Daten sind KI-Trainings- oder Evaluierungsdaten, die künstlich erzeugt wurden, anstatt in der realen Welt gefunden zu werden. <a href=\"https://doi.org/10.1007/978-3-030-75178-4?ref=jina-ai-gmbh.ghost.io\">Nikolenko (2021)</a> datiert synthetische Daten zurück zu frühen Computer-Vision-Projekten in den 1960er Jahren und skizziert ihre Geschichte als wichtiges Element dieses Feldes.</p><p>Es gibt viele Gründe, synthetische Daten zu verwenden. Einer der wichtigsten ist die Bekämpfung von Voreingenommenheit.</p><p>Große Sprachmodelle und Bildgeneratoren haben viele <a href=\"https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/?ref=jina-ai-gmbh.ghost.io\">bekannte</a> <a href=\"https://www.washington.edu/news/2023/11/29/ai-image-generator-stable-diffusion-perpetuates-racial-and-gendered-stereotypes-bias/?ref=jina-ai-gmbh.ghost.io\">Beschwerden</a> <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">über Voreingenommenheit</a> erhalten. Das Wort <em>Voreingenommenheit</em> hat eine strenge Bedeutung in der Statistik, aber diese Beschwerden spiegeln oft moralische, soziale und politische Überlegungen wider, die keine einfache mathematische Form oder technische Lösung haben.</p><p>Die Voreingenommenheit, die man nicht leicht sieht, ist weitaus schädlicher und viel schwieriger zu beheben. Die Muster, die KI-Modelle lernen zu replizieren, sind diejenigen, die in ihren Trainingsdaten zu sehen sind, und wo diese Daten systematische Mängel aufweisen, ist Voreingenommenheit eine unvermeidliche Folge. Je mehr verschiedene Dinge wir von KI erwarten - je vielfältiger die Eingaben für das Modell - desto größer ist die Chance, dass es etwas falsch macht, weil es nie genug ähnliche Fälle in seinem Training gesehen hat.</p><p>Die Hauptrolle synthetischer Daten im KI-Training heute besteht darin, genügend Beispiele für bestimmte Arten von Situationen in den Trainingsdaten zu gewährleisten, Situationen, die in verfügbaren natürlichen Daten möglicherweise nicht ausreichend vorhanden sind.</p><p>Unten ist ein Bild, das MidJourney produzierte, als es mit \"doctor\" aufgefordert wurde: vier Männer, drei weiß, drei in weißen Kitteln mit Stethoskopen, und einer tatsächlich alt. Dies spiegelt nicht die tatsächliche Rasse, das Alter, das Geschlecht oder die Kleidung echter Ärzte in den meisten Ländern und Kontexten wider, ist aber wahrscheinlich ein Spiegelbild der beschrifteten Bilder, die man im Internet findet.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--59-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--59-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--59-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Bei erneuter Aufforderung produzierte es eine Frau und drei Männer, alle weiß, obwohl einer ein Cartoon ist. KI kann seltsam sein.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--60-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--60-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--60-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Diese besondere Art von Voreingenommenheit ist eine, die KI-Bildgeneratoren zu verhindern versuchen, sodass wir nicht mehr so deutlich voreingenommene Ergebnisse erhalten wie vielleicht noch vor einem Jahr von denselben Systemen. Eine Voreingenommenheit ist sichtbar noch vorhanden, aber es ist nicht offensichtlich, wie ein unvoreingenommenes Ergebnis aussehen würde.</p><p>Dennoch ist es nicht schwer zu erkennen, wie eine KI diese Art von Vorurteilen entwickeln könnte. Unten sind die ersten drei Bilder für \"doctor\" auf der Shutterstock-Foto-Website: Drei Männer, zwei älter und weiß. Die Vorurteile der KI sind die Vorurteile ihres Trainings, und wenn Sie Modelle mit unkurierten Daten trainieren, werden Sie immer diese Art von Voreingenommenheit finden.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.21.21.png\" loading=\"lazy\" width=\"1740\" height=\"860\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1740w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Eine Möglichkeit, dieses Problem zu mindern, besteht darin, einen KI-Bildgenerator zu verwenden, um Bilder von jüngeren Ärzten, Ärztinnen, Ärzten verschiedener Hautfarben und Ärzten in OP-Kleidung, Anzügen oder anderer Kleidung zu erstellen und diese dann ins Training einzubeziehen. Auf diese Weise verwendete synthetische Daten können die KI-Modellleistung verbessern, zumindest in Bezug auf eine externe Norm, anstatt zum Modellkollaps zu führen. Allerdings kann die künstliche Verzerrung von Trainingsdatenverteilungen unbeabsichtigte Nebenwirkungen haben, <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">wie Google kürzlich feststellte</a>.</p><h2 id=\"model-distillation\">Modelldestillation</h2><p><a href=\"https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones/?ref=jina-ai-gmbh.ghost.io\">Modelldestillation</a> ist eine Technik zum direkten Training eines Modells von einem anderen. Ein trainiertes generatives Modell - der \"Lehrer\" - erstellt so viele Daten wie nötig, um ein untrainiertes oder weniger trainiertes \"Schüler\"-Modell zu trainieren.</p><p>Wie zu erwarten, kann das \"Schüler\"-Modell nie besser sein als der \"Lehrer\". Auf den ersten Blick erscheint es wenig sinnvoll, ein Modell auf diese Weise zu trainieren, aber es gibt Vorteile. Der wichtigste ist, dass das \"Schüler\"-Modell viel kleiner, schneller oder effizienter sein kann als der \"Lehrer\", während es seine Leistung immer noch eng approximiert.</p><p>Die Beziehung zwischen Modellgröße, Trainingsdaten und endgültiger Leistung ist kompliziert. Im Großen und Ganzen gilt jedoch unter sonst gleichen Bedingungen:</p><ol><li>Ein größeres Modell leistet mehr als ein kleines.</li><li>Ein Modell, das mit mehr oder besseren Trainingsdaten (oder zumindest vielfältigeren Trainingsdaten) trainiert wurde, leistet mehr als eines mit weniger oder schlechteren Daten.</li></ol><p>Dies bedeutet, dass ein kleines Modell manchmal genauso gut funktionieren kann wie ein großes. Zum Beispiel übertrifft <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>jina-embeddings-v2-base-en</code></a> viele viel größere Modelle bei Standard-Benchmarks deutlich:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Size in parameters</th>\n<th>MTEB average score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>jina-embeddings-v2-base-en</code></td>\n<td>137M</td>\n<td>60.38</td>\n</tr>\n<tr>\n<td><code>multilingual-e5-base</code></td>\n<td>278M</td>\n<td>59.45</td>\n</tr>\n<tr>\n<td><code>sentence-t5-xl</code></td>\n<td>1240M</td>\n<td>57.87</td>\n</tr>\n</tbody>\n</table>\n\nDie Modell-Destillation ist eine Methode, um aus einem großen, zu kostenintensiven Modell ein kleineres, kostengünstigeres Modell zu erstellen. In jedem Fall gibt es einen gewissen Leistungsverlust, der in den besten Fällen jedoch sehr gering sein kann.\n\nAngesichts der Kosten, die mit sehr großen KI-Modellen verbunden sind, sind diese Vorteile beträchtlich. Destillation führt zu Modellen, die schneller laufen, auf günstigeren Chips, mit weniger Speicher und geringerem Stromverbrauch.\n\nDarüber hinaus können große Modelle bemerkenswert subtile Muster aus unkurierten Daten lernen - Muster, die ein kleineres Modell aus denselben Daten niemals lernen könnte. Ein großes Modell kann dann weitaus vielfältigere Trainingsdaten produzieren als die, mit denen es trainiert wurde, genug damit das kleinere Modell dieselben subtilen Muster lernen kann. Sobald man ein großes trainiertes Modell hat, kann man es nutzen, um einem kleineren Modell das \"beizubringen\", was es gelernt hat - etwas, das das kleinere Modell alleine nie hätte lernen können. In solchen Fällen ist Destillation manchmal ein besserer Lernweg als die Verwendung echter Trainingsdaten.\n\n## Gehen wir also alle den Bach runter?\n\nVielleicht.\n\nDie gute Nachricht ist, dass wir ohne eine Lösung für den Modell-Kollaps wahrscheinlich keine superintelligente KI trainieren können, die die Menschheit auslöschen könnte - zumindest nicht mit den Methoden, die wir bisher verwendet haben. Wir können uns wieder sicher dem Klimawandel und Atomkrieg widmen.\n\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Wenn der vorherige Absatz sarkastisch klang, war das Absicht.</div></div>\n\nFür die KI-Branche sieht das Bild nicht ganz so optimistisch aus. Das Motto des maschinellen Lernens war lange Zeit \"<a href=\"https://towardsdatascience.com/ai-ml-practicalities-the-unreasonable-effectiveness-of-data-c0bfd44c5057?ref=jina-ai-gmbh.ghost.io\">mehr Daten sind bessere Daten</a>.\" (Manchmal auch: \"Es gibt keine besseren Daten als mehr Daten.\") <a href=\"https://towardsdatascience.com/ai-ml-practicalities-more-data-isnt-always-better-ae1dac9ad28f?ref=jina-ai-gmbh.ghost.io\">Statistiker wissen alle, dass das falsch ist</a>. Der gesunde Menschenverstand sagt, dass das falsch ist. Aber es ist eine Strategie, die für KI-Forscher lange Zeit funktioniert hat, mindestens seit ich Anfang der 2000er Jahre als Forscher in der maschinellen Übersetzung begonnen habe.\n\nEs gibt Gründe dafür. _Diverse Daten_ - Daten, die viele verschiedene Möglichkeiten beinhalten - sind eine viel bessere Trainingsquelle als einheitliche Daten. Und in der Praxis bedeuten mehr Daten in der realen Welt normalerweise auch vielfältigere Daten.\n\nAber uns gehen die neuen Quellen für gute, diverse Daten aus, und die Schaffung neuer menschengemachter Werke wird wahrscheinlich nicht mit der KI-Generierung Schritt halten können. Früher oder später werden wir die Art und Weise, wie wir KI-Modelle trainieren, ändern müssen. Andernfalls erreichen wir möglicherweise eine Leistungsgrenze, die wir nicht mehr überschreiten können. Dies würde die Branche transformieren, da der Fokus sich vom Aufbau und Betrieb größerer, teurerer Modelle zur Entwicklung von Frameworks, Kontexten und Nischen verlagern würde, in denen bestehende Modelle neuen Mehrwert schaffen können.\n\n## Wie Jina AI seine KI-Modelle trainiert\n\nBei Jina AI versuchen wir, unseren Nutzern die Vorteile der KI-Best-Practices zu bieten. Obwohl wir keine textgenerierenden LLMs oder KI-Bildgeneratoren produzieren, beschäftigt uns das Problem des Modell-Kollapses. Wir verwenden Teilmengen des <a href=\"https://commoncrawl.org/?ref=jina-ai-gmbh.ghost.io\">Common Crawl</a> für den Großteil unseres Pre-Trainings und nutzen dann kuratierte und synthetische Daten, um die Leistung unserer Modelle zu optimieren. Wir streben danach, State-of-the-Art-Performance in kosteneffektiven Modellen und kompakten, niedrigdimensionalen Embeddings zu erreichen.\n\nDennoch ist der Modell-Kollaps ein unvermeidliches Problem für Common Crawl Daten. Wir erwarten, dass wir mit der Zeit zu mehr kuratierten Daten und weniger Common Crawl übergehen werden. Wir erwarten, dass andere Akteure in der KI-Branche dasselbe tun werden. Dies wird Kosten verursachen - sowohl in Bezug auf Geld als auch auf die Rate der Qualitätsverbesserung - aber es ist zu früh, um diese zu schätzen.\n\nWir verwenden synthetische Daten in Bereichen, wo Embedding-Modelle bekannte Probleme haben. Zum Beispiel haben KI-Modelle Schwierigkeiten mit der Darstellung von Verneinung. \"Rezepte mit Fleisch\" und \"Rezepte ohne Fleisch\" haben typischerweise Embeddings, die sehr nahe beieinander liegen, aber Benutzer brauchen oft, dass sie sehr weit auseinander liegen. Unsere größte Nutzung synthetischer Daten besteht darin, ein großes Korpus von KI-generierten Satzpaaren zu erstellen, die sich durch diese Art von Verneinung unterscheiden (in KI und einigen Arten der Linguistik _Polarität_ genannt), und es dann zu verwenden, um unsere Modelle zu verbessern.\n\nZum Beispiel zeigt die folgende 2D-Projektion hypothetische Embeddings. \"Rezepte mit Fleisch\" und \"Rezepte ohne Fleisch\" liegen relativ nahe beieinander. \"Bacon Cheeseburger\" ist viel näher an \"Rezepte mit Fleisch\" als an allem anderen, und \"Falafel\" ist näher an \"Rezepte ohne Fleisch\" als an \"Rezepte mit Fleisch\". Allerdings ist \"Bacon Cheeseburger\" viel näher an \"Rezepte ohne Fleisch\" als \"Falafel\".\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png\" class=\"kg-image\" alt=\"Eine 2D-Projektion hypothetischer Embeddings.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--61-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Eine 2D-Projektion hypothetischer Embeddings.</span></figcaption></figure>\n\nWenn man nur die Embeddings betrachtet, könnte man schlussfolgern, dass Bacon Cheeseburger ein besseres Beispiel für ein Rezept ohne Fleisch ist als Falafel.\n\nUm dies zu verhindern, trainieren wir unsere Modelle mit synthetischen Daten. Wir verwenden ein LLM, um Satzpaare mit entgegengesetzten Polaritäten zu generieren - wie \"X mit Y\" / \"X ohne Y\" - und trainieren unsere Embedding-Modelle darauf, diese Paare auseinander zu bewegen. Wir verwenden synthetische Daten auch für andere Arten des gezielten <a href=\"https://finetuner.jina.ai/advanced-topics/negative-mining/?ref=jina-ai-gmbh.ghost.io\">Negative Mining</a>, einer Sammlung von Techniken zur Verbesserung spezifischer Aspekte der KI-Modellleistung durch die Präsentation kuratierter Daten.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png\" class=\"kg-image\" alt=\"Eine 2D-Projektion hypothetischer Embeddings nach Verbesserung des zugrundeliegenden Modells.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--62-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Eine 2D-Projektion hypothetischer Embeddings nach Verbesserung des zugrundeliegenden Modells mit polaritätsinvertierten Satzpaaren.</span></figcaption></figure>\n\nWir nutzen generative KI auch zum Training von <a href=\"https://jina.ai/news/elevate-your-code-search-with-new-jina-code-embeddings/?ref=jina-ai-gmbh.ghost.io\">Embedding-Modellen für Programmiersprachen</a>, indem wir große Modelle einsetzen, die umfangreiche Codebeispiele generieren, damit wir auch ziemlich obskure Features spezifischer Sprachen und Frameworks korrekt einbetten können.\n\nModell-Destillation ist der Schlüssel dafür, wie wir <a href=\"https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny?ref=jina-ai-gmbh.ghost.io\">kompakte Modelle produzieren, die Computerressourcen sparen</a>. Destillation ist viel effizienter und zuverlässiger als Training von Grund auf, und unsere Ergebnisse zeigen, dass ein destilliertes Modell immer noch Top-Qualität-Performance haben kann. Die folgende Tabelle zeigt Jina AIs destillierte <a href=\"https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io\">Reranker-Modelle</a> im Vergleich zum Basis-Reranker, der zu ihrem Training verwendet wurde, und zu anderen Modellen mit weitaus mehr Parametern aber schlechterer Performance.\n\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Model</th>\n<th>BEIR Score</th>\n<th>Parameter count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td><code>jina-reranker-v1-base-en</code></td>\n<td>52.45</td>\n<td>137M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-turbo-en</code></td>\n<td>49.60</td>\n<td>38M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-tiny-en</code></td>\n<td>48.54</td>\n<td>33M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-base-v1</code></td>\n<td>49.19</td>\n<td>184M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-xsmall-v1</code></td>\n<td>48.80</td>\n<td>71M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>bge-reranker-base</code></td>\n<td>47.89</td>\n<td>278M</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n\nWir wissen, dass KI eine teure Investition sein kann und dass Unternehmen sich zunehmend ihrer moralischen und rechtlichen Verpflichtungen zur Reduzierung von CO2-Emissionen bewusst sind. Auch wir sind uns dieser Dinge bewusst. Modell-Destillation ist ein wichtiger Teil unserer Antwort auf diese Bedenken.\n\n## Lassen Sie uns Ihnen bei der Navigation durch KI helfen\n\nJina AI hat sich verpflichtet, Unternehmen erschwingliche, effiziente, funktionierende KI-Lösungen zu bieten. Wir können uns in Ihre bestehende Cloud-Infrastruktur auf <a href=\"https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions?ref=jina-ai-gmbh.ghost.io\">Azure</a> und <a href=\"https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker?ref=jina-ai-gmbh.ghost.io\">AWS</a> integrieren. Wir bieten <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Web-APIs</a> an, die strenge Sicherheits- und Datenschutzstandards einhalten und Ihre Daten nicht für unser eigenes Training speichern. Wir können Ihnen helfen, unsere <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">Open-Source-Modelle</a> auf Ihrer eigenen Hardware zu installieren, sodass Ihr gesamter Betrieb intern bleibt.\n\nEs kann schwierig sein, den Hype von der Technik zu trennen und in diesem sich schnell verändernden Bereich mit den Best Practices Schritt zu halten. Lassen Sie uns das für Sie tun.",
  "comment_id": "6639e8e1af8f52000115be49",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-05-07T10:40:01.000+02:00",
  "updated_at": "2024-07-08T21:10:35.000+02:00",
  "published_at": "2024-05-07T16:00:26.000+02:00",
  "custom_excerpt": "AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let’s find out!",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "6342c5b4393501004d1c8b2c",
      "name": "Insights",
      "slug": "insights",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "6342c5b4393501004d1c8b2c",
    "name": "Insights",
    "slug": "insights",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/",
  "excerpt": "KI erschafft KI! Ist es das Ende der Welt? Oder nur ein weiteres Werkzeug, mit dem Modelle wertschöpfende Arbeit leisten können? Finden wir es heraus!",
  "reading_time": 12,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract depiction of a brain in purple and pink hues with a fluid, futuristic design against a blue and purple background.",
  "feature_image_caption": null
}