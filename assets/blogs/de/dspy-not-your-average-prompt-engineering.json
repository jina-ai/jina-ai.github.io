{
  "slug": "dspy-not-your-average-prompt-engineering",
  "id": "66077bf0a5c39b0001044181",
  "uuid": "e242c77c-f712-462c-9745-3e9269eb8a8b",
  "title": "DSPy: Nicht Ihr gewöhnliches Prompt Engineering",
  "html": "<div class=\"kg-card kg-file-card\"><a class=\"kg-file-card-container\" href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/04/DSPy-Not-Your-Average-Prompt-Engineering--1-.pdf\" title=\"Download\" download=\"\"><div class=\"kg-file-card-contents\"><div class=\"kg-file-card-title\">[Folien] DSPy: Nicht Ihr gewöhnliches Prompt Engineering</div><div class=\"kg-file-card-caption\">Eine Präsentation von Han am 15. April 2024 in Mountain View.</div><div class=\"kg-file-card-metadata\"><div class=\"kg-file-card-filename\">DSPy Not Your Average Prompt Engineering (1).pdf</div><div class=\"kg-file-card-filesize\">7 MB</div></div></div><div class=\"kg-file-card-icon\"><svg viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"></polyline><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"></line><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"></circle></svg></div></a></div><p>Ich habe mich kürzlich mit DSPy beschäftigt, einem hochmodernen Framework der Stanford NLP-Gruppe, das darauf abzielt, Language Model (LM) Prompts algorithmisch zu optimieren. In den letzten drei Tagen habe ich einige erste Eindrücke und wertvolle Erkenntnisse über DSPy gesammelt. Beachten Sie, dass meine Beobachtungen nicht die offizielle Dokumentation von DSPy ersetzen sollen. Ich empfehle sogar dringend, <a href=\"https://dspy-docs.vercel.app/?ref=jina-ai-gmbh.ghost.io\">ihre Dokumentation</a> und <a href=\"https://github.com/stanfordnlp/dspy/blob/main/README.md?ref=jina-ai-gmbh.ghost.io\">README</a> mindestens einmal zu lesen, bevor Sie sich in diesen Beitrag vertiefen. Meine Ausführungen hier spiegeln ein vorläufiges Verständnis von DSPy wider, nachdem ich einige Tage seine Möglichkeiten erkundet habe. Es gibt mehrere fortgeschrittene Funktionen wie DSPy Assertions, Typed Predictor und LM-Gewichtsanpassung, die ich noch nicht gründlich erforscht habe.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/stanfordnlp/dspy?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - stanfordnlp/dspy: DSPy: The framework for programming—not prompting—foundation models</div><div class=\"kg-bookmark-description\">DSPy: The framework for programming—not prompting—foundation models - stanfordnlp/dspy</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">stanfordnlp</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/b8c1b2b4b3ff9c22d486f5c69dbda5fee6cc8dda8a42aaf1c2e154c17b7dc159/stanfordnlp/dspy\" alt=\"\"></div></a></figure><p>Trotz meines Hintergrunds bei Jina AI, das sich hauptsächlich auf die Search-Grundlagen konzentriert, wurde mein Interesse an DSPy nicht direkt durch sein Potenzial im Retrieval-Augmented Generation (RAG) geweckt. Stattdessen hat mich die Möglichkeit fasziniert, DSPy für automatisches Prompt-Tuning zu nutzen, um bestimmte Generierungsaufgaben zu lösen.</p><p>Wenn Sie neu bei DSPy sind und einen zugänglichen Einstiegspunkt suchen, oder wenn Sie mit dem Framework vertraut sind, aber die offizielle Dokumentation verwirrend oder überwältigend finden, ist dieser Artikel für Sie gedacht. Ich entscheide mich auch dafür, mich nicht streng an DSPys Idiom zu halten, das für Neulinge einschüchternd erscheinen mag. Lassen Sie uns nun tiefer eintauchen.</p><h2 id=\"what-i-like-about-dspy\">Was mir an DSPy gefällt</h2><h3 id=\"dspy-closing-the-loop-of-prompt-engineering\">DSPy schließt den Kreislauf des Prompt Engineering</h3><p>Was mich an DSPy am meisten begeistert, ist sein Ansatz, den Kreislauf des Prompt-Engineering-Zyklus zu schließen und einen oft manuellen, handgefertigten Prozess in einen strukturierten, klar definierten Machine-Learning-Workflow zu verwandeln: d.h. Datensätze vorbereiten, Modell definieren, trainieren, evaluieren und testen. In meinen Augen ist dies der revolutionärste Aspekt von DSPy.</p><p>Auf meinen Reisen in der Bay Area und in Gesprächen mit vielen Startup-Gründern, die sich auf LLM-Evaluation konzentrieren, bin ich häufig auf Diskussionen über Metriken, Halluzinationen, Beobachtbarkeit und Compliance gestoßen. Diese Gespräche gehen jedoch oft nicht zu den kritischen nächsten Schritten über: Was machen wir mit all diesen Metriken in der Hand? Kann das Anpassen der Formulierung in unseren Prompts, in der Hoffnung, dass bestimmte magische Wörter (z.B. \"meine Oma stirbt\") unsere Metriken verbessern könnten, als strategischer Ansatz betrachtet werden? Diese Frage blieb von vielen LLM-Evaluations-Startups unbeantwortet, und auch ich konnte sie nicht angehen - bis ich DSPy entdeckte. DSPy führt eine klare, programmatische Methode zur Optimierung von Prompts basierend auf spezifischen Metriken ein, oder sogar zur Optimierung der gesamten LLM-Pipeline, einschließlich Prompts und LLM-Gewichten.</p><p>Harrison, der CEO von LangChain, und Logan, der ehemalige OpenAI Head of Developer Relations, haben beide im <a href=\"https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924?ref=jina-ai-gmbh.ghost.io\">Unsupervised Learning Podcast</a> erklärt, dass 2024 voraussichtlich ein entscheidendes Jahr für die LLM-Evaluation sein wird. Aus diesem Grund glaube ich, dass DSPy mehr Aufmerksamkeit verdient als es derzeit bekommt, da DSPy das entscheidende fehlende Puzzlestück liefert.</p><h3 id=\"dspy-separating-logic-from-textual-representation\">DSPy trennt Logik von textueller Darstellung</h3><p>Ein weiterer Aspekt von DSPy, der mich beeindruckt, ist, dass es Prompt Engineering in ein reproduzierbares und LLM-unabhängiges Modul umwandelt. Um das zu erreichen, trennt es die Logik vom Prompt und schafft eine klare Trennung zwischen der Logik und der textuellen Darstellung, wie unten dargestellt.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png\" class=\"kg-image\" alt=\"Flowchart depicting sentiment analysis process with steps such as Prompt, Logic, and Textual Representation on a black backgr\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--5-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--5-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">In DSPy besteht der Prompt aus der intrinsischen Logik (d.h. </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>dspy.Module</span></code><span style=\"white-space: pre-wrap;\">) und ihrer textuellen Darstellung. Die Logik ist unveränderlich, reproduzierbar, testbar und LLM-unabhängig. Die textuelle Darstellung ist lediglich die Konsequenz der Logik.</span></figcaption></figure><p>DSPys Konzept der Logik als unveränderliche, testbare und LLM-unabhängige \"Ursache\", mit textueller Darstellung lediglich als deren \"Konsequenz\", mag zunächst verwirrend erscheinen. Dies gilt besonders angesichts der weit verbreiteten Überzeugung, dass \"die Zukunft der Programmiersprache die natürliche Sprache ist\". Wenn man die Idee vertritt, dass \"Prompt Engineering die Zukunft ist\", könnte man beim Kennenlernen von DSPys Designphilosophie einen Moment der Verwirrung erleben. Entgegen der Erwartung einer Vereinfachung führt DSPy eine Reihe von Modulen und Signatur-Syntaxen ein, die das natürlichsprachliche Prompting scheinbar zur Komplexität der C-Programmierung zurückführen!</p><p>Aber warum dieser Ansatz? Mein Verständnis ist, dass im Kern des Prompt-Programmierens die grundlegende Logik liegt, wobei die Kommunikation als Verstärker dient, der ihre Effektivität potenziell verbessern oder verschlechtern kann. Die Anweisung <code>\"Do sentiment classification\"</code> repräsentiert die Kernlogik, während ein Satz wie <code>\"Follow these demonstrations or I will fire you\"</code> eine Art ist, diese zu kommunizieren. Ähnlich wie bei realen Interaktionen entstehen Schwierigkeiten bei der Aufgabenbewältigung oft nicht aus fehlerhafter Logik, sondern aus problematischer Kommunikation. Dies erklärt, warum viele, besonders Nicht-Muttersprachler, Prompt Engineering als herausfordernd empfinden. Ich habe beobachtet, wie hochkompetente Softwareingenieure in meinem Unternehmen mit Prompt Engineering kämpfen, nicht wegen mangelnder Logik, sondern weil sie nicht \"den richtigen Ton treffen\". Durch die Trennung der Logik vom Prompt ermöglicht <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/modules?ref=jina-ai-gmbh.ghost.io\">DSPy die deterministische Programmierung von Logik über <code>dspy.Module</code></a>, sodass sich Entwickler auf die Logik konzentrieren können, wie sie es in der traditionellen Entwicklung tun würden, unabhängig vom verwendeten LLM.</p><p>Wenn sich also Entwickler auf die Logik konzentrieren, wer kümmert sich dann um die textuelle Darstellung? DSPy übernimmt diese Rolle und nutzt Ihre Daten und Evaluationsmetriken, um die textuelle Darstellung zu verfeinern - von der Bestimmung des narrativen Fokus bis zur Optimierung von Hinweisen und der Auswahl guter Demonstrationen. Bemerkenswerterweise kann DSPy sogar Evaluationsmetriken verwenden, um die LLM-Gewichte feinzutunen!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png\" class=\"kg-image\" alt=\"Flowchart illustrating a language model with branches for training data, logic, textual representation, and final results.\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Für mich unterstreichen DSPys Hauptbeiträge - das Schließen des Kreislaufs von Training und Evaluation im Prompt Engineering und die Trennung von Logik und textueller Darstellung - seine potenzielle Bedeutung für LLM/Agent-Systeme. Eine ambitionierte Vision, aber definitiv notwendig!</p><h2 id=\"what-i-think-dspy-can-improve\">Was DSPy meiner Meinung nach verbessern kann</h2><p>Erstens präsentiert DSPy für Neueinsteiger eine steile Lernkurve aufgrund seiner Idiome. Begriffe wie <code>signature</code>, <code>module</code>, <code>program</code>, <code>teleprompter</code>, <code>optimization</code> und <code>compile</code> können überwältigend sein. Selbst für diejenigen, die im Prompt Engineering versiert sind, kann die Navigation durch diese Konzepte innerhalb von DSPy ein herausforderndes Labyrinth sein.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Yeah, DSPy really needs someone to come in and explain everything without suitcase words. <a href=\"https://twitter.com/CShorten30?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">@CShorten30</a> does a great job, but we need more.</p>— Jonathan Mugan (@jmugan) <a href=\"https://twitter.com/jmugan/status/1773036172723236895?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">March 27, 2024</a></blockquote>\n<script async=\"\" src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></figure><p>Diese Komplexität spiegelt meine Erfahrung mit <a href=\"https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io\">Jina 1.0</a> wider, wo wir eine Reihe von Konzepten wie <code>chunk</code>, <code>document</code>, <code>driver</code>, <code>executor</code>, <code>pea</code>, <code>pod</code>, <code>querylang</code> und <code>flow</code> einführten (wir haben sogar niedliche Sticker entworfen, um den Nutzern beim Merken zu helfen!).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Document-FLAT--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pea-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/QueryLang--FLAT.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png 700w\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--3-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pod-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--5-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png 700w\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Die meisten dieser frühen Konzepte wurden in späteren Jina-Überarbeitungen entfernt. Heute haben nur </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Executor</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Document</span></code><span style=\"white-space: pre-wrap;\"> und </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Flow</span></code><span style=\"white-space: pre-wrap;\"> \"die große Säuberung\" überlebt. Wir haben in Jina 3.0 ein neues Konzept, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Deployment</span></code><span style=\"white-space: pre-wrap;\">, hinzugefügt; das gleicht die Sache wieder aus. 🤷</span></p></figcaption></figure><p>Dieses Problem ist nicht einzigartig für DSPy oder Jina; erinnern Sie sich an die unzähligen Konzepte und Abstraktionen, die TensorFlow zwischen den Versionen 0.x und 1.x einführte. Ich glaube, dieses Problem tritt häufig in den frühen Phasen von Software-Frameworks auf, wo es einen Drang gibt, <strong>akademische Notationen direkt im Codebase widerzuspiegeln, um maximale Genauigkeit und Reproduzierbarkeit zu gewährleisten</strong>. Allerdings schätzen nicht alle Nutzer solch granulare Abstraktionen, wobei die Präferenzen von dem Wunsch nach einfachen Einzeilern bis hin zu Forderungen nach größerer Flexibilität reichen. Ich habe dieses Thema der Abstraktion in Software-Frameworks ausführlich in einem Blog-Beitrag von 2020 diskutiert, den interessierte Leser vielleicht aufschlussreich finden.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/?ref=jina-ai-gmbh.ghost.io#layer-of-abstraction\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Layer of Abstraction When Building \"Tensorflow\" for Search · Han Xiao Tech Blog - Neural Search &amp; AI Engineering</div><div class=\"kg-bookmark-description\">Since Feb. 2020, I started a new venture called Jina AI. Our mission is to build an open-source neural search ecosystem for businesses and developers, ... · Han Xiao</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://hanxiao.io/wechaticon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/blog-abstraction-banner.jpg\" alt=\"\"></div></a></figure><p>Zweitens lässt die Dokumentation von DSPy manchmal in Bezug auf Konsistenz zu wünschen übrig. Begriffe wie <code>module</code> und <code>program</code>, <code>teleprompter</code> und <code>optimizer</code>, oder <code>optimize</code> und <code>compile</code> (manchmal auch als <code>training</code> oder <code>bootstrapping</code> bezeichnet) werden austauschbar verwendet, was zur Verwirrung beiträgt. Folglich verbrachte ich meine ersten Stunden mit DSPy damit, genau zu entschlüsseln, was es <code>optimizes</code> und was der Prozess des <code>bootstrapping</code> beinhaltet.</p><p>Trotz dieser Hürden werden Sie wahrscheinlich, wenn Sie tiefer in DSPy eintauchen und die Dokumentation erneut durchgehen, Momente der Klarheit erleben, in denen alles anfängt, Sinn zu ergeben, und die Verbindungen zwischen seiner einzigartigen Terminologie und den vertrauten Konstrukten aus Frameworks wie PyTorch deutlich werden. Allerdings hat DSPy zweifellos Verbesserungspotenzial für zukünftige Versionen, insbesondere um das Framework für Prompt-Engineers <em>ohne</em> PyTorch-Hintergrund zugänglicher zu machen.</p><h2 id=\"common-stumbling-blocks-for-dspy-newbies\">Häufige Stolpersteine für DSPy-Neulinge</h2><p>In den folgenden Abschnitten habe ich eine Liste von Fragen zusammengestellt, die anfangs meinen Fortschritt mit DSPy behinderten. Mein Ziel ist es, diese Erkenntnisse zu teilen, in der Hoffnung, dass sie ähnliche Herausforderungen für andere Lernende klären können.</p><h3 id=\"what-are-teleprompter-optimization-and-compile-whats-exactly-being-optimized-in-dspy\">Was sind <code>teleprompter</code>, <code>optimization</code> und <code>compile</code>? Was genau wird in DSPy optimiert?</h3><p>In DSPy ist \"Teleprompters\" der Optimizer (und es sieht so aus, als würde <a href=\"https://twitter.com/lateinteraction?ref=jina-ai-gmbh.ghost.io\">@lateinteraction</a> die Dokumentation und den Code überarbeiten, um dies zu klären). Die <code>compile</code>-Funktion agiert im Zentrum dieses Optimizers, ähnlich wie der Aufruf von <code>optimizer.optimize()</code>. Denken Sie daran als DSPy-Äquivalent zum Training. Dieser <code>compile()</code>-Prozess zielt darauf ab, folgendes zu optimieren:</p><ul><li>die Few-Shot-Demonstrationen,</li><li>die Anweisungen,</li><li>die Gewichte des LLM</li></ul><p>Allerdings werden die meisten DSPy-Tutorials für Anfänger nicht auf die Gewichts- und Anweisungsoptimierung eingehen, was zur nächsten Frage führt.</p><h3 id=\"whats-bootstrap-in-dspy-all-about\">Worum geht es bei <code>bootstrap</code> in DSPy?</h3><p>Bootstrap bezieht sich auf die Erstellung selbst generierter Demonstrationen für Few-Shot In-Context Learning, ein entscheidender Teil des <code>compile()</code>-Prozesses (d.h. Optimierung/Training wie oben erwähnt). Diese Few-Shot-Demos werden aus benutzerdefinierten gelabelten Daten generiert; und eine Demo besteht oft aus Input, Output, Begründung (z.B. in Chains of Thought) und Zwischen-Inputs & -Outputs (für mehrstufige Prompts). Natürlich sind qualitativ hochwertige Few-Shot-Demos der Schlüssel zur Outputexzellenz. Dafür erlaubt DSPy benutzerdefinierte Metrik-Funktionen, um sicherzustellen, dass nur Demos ausgewählt werden, die bestimmte Kriterien erfüllen, was zur nächsten Frage führt.</p><h3 id=\"whats-dspy-metric-function\">Was ist die DSPy Metrik-Funktion?</h3><p>Nach praktischer Erfahrung mit DSPy bin ich zu der Überzeugung gelangt, dass die Metrik-Funktion weit mehr Beachtung verdient als in der aktuellen Dokumentation. Die Metrik-Funktion in DSPy spielt eine entscheidende Rolle in <em>beiden</em> Phasen, Evaluation und Training, und fungiert dank ihrer impliziten Natur (gesteuert durch <code>trace=None</code>) auch als \"Loss\"-Funktion:</p><pre><code class=\"language-python\">def keywords_match_jaccard_metric(example, pred, trace=None):  \n    # Jaccard similarity between example keywords and predicted keywords  \n    A = set(normalize_text(example.keywords).split())  \n    B = set(normalize_text(pred.keywords).split())  \n    j = len(A &amp; B) / len(A | B)\n    if trace is not None:\n        # act as a \"loss\" function\n        return j  \n    return j &gt; 0.8  # act as evaluation</code></pre><p>Dieser Ansatz unterscheidet sich deutlich vom traditionellen maschinellen Lernen, wo die Loss-Funktion normalerweise kontinuierlich und differenzierbar ist (z.B. Hinge/MSE), während die Evaluationsmetrik völlig anders und diskret sein kann (z.B. NDCG). In DSPy sind die Evaluations- und Loss-Funktionen in der Metrik-Funktion vereint, die diskret sein kann und meist einen booleschen Wert zurückgibt. Die Metrik-Funktion kann auch ein LLM integrieren! Im folgenden Beispiel habe ich einen Fuzzy Match mit LLM implementiert, um zu bestimmen, ob der vorhergesagte Wert und die Goldstandard-Antwort in der Größenordnung ähnlich sind, z.B. würden \"1 Million Dollar\" und \"$1M\" true zurückgeben.</p><pre><code class=\"language-python\">class Assess(dspy.Signature):  \n    \"\"\"Assess the if the prediction is in the same magnitude to the gold answer.\"\"\"  \n  \n    gold_answer = dspy.InputField(desc='number, could be in natural language')  \n    prediction = dspy.InputField(desc='number, could be in natural language')  \n    assessment = dspy.OutputField(desc='yes or no, focus on the number magnitude, not the unit or exact value or wording')  \n  \ndef same_magnitude_correct(example, pred, trace=None):  \n    return dspy.Predict(Assess)(gold_answer=example.answer, prediction=pred.answer).assessment.lower() == 'yes'</code></pre><p>So leistungsfähig sie auch ist, die Metrik-Funktion beeinflusst die DSPy Benutzererfahrung maßgeblich, indem sie nicht nur die finale Qualitätsbewertung bestimmt, sondern auch die Optimierungsergebnisse beeinflusst. Eine gut entwickelte Metrik-Funktion kann zu optimierten Prompts führen, während eine schlecht gestaltete zum Scheitern der Optimierung führen kann. Wenn Sie ein neues Problem mit DSPy angehen, werden Sie möglicherweise genauso viel Zeit mit dem Entwickeln der Logik (d.h. <code>DSPy.Module</code>) wie mit der Metrik-Funktion verbringen. Diese doppelte Fokussierung auf Logik und Metriken kann für Neulinge entmutigend sein.</p><h3 id=\"bootstrapped-0-full-traces-after-20-examples-in-round-0-what-does-this-mean\"><code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code> was bedeutet das?</h3><p>Diese Meldung, die während <code>compile()</code> leise erscheint, verdient Ihre höchste Aufmerksamkeit, da sie im Wesentlichen bedeutet, dass die Optimierung/Kompilierung fehlgeschlagen ist und der Prompt, den Sie erhalten, nicht besser ist als einfaches Few-Shot-Learning. Was läuft schief? Ich habe einige Tipps zusammengefasst, die Ihnen beim Debugging Ihres DSPy-Programms helfen, wenn Sie auf diese Meldung stoßen:</p><h4 id=\"your-metric-function-is-incorrect\">Ihre Metrik-Funktion ist fehlerhaft</h4><p>Ist die Funktion <code>your_metric</code>, die in <code>BootstrapFewShot(metric=your_metric)</code> verwendet wird, korrekt implementiert? Führen Sie einige Unit-Tests durch. Gibt <code>your_metric</code> jemals <code>True</code> zurück, oder gibt sie immer <code>False</code> zurück? Beachten Sie, dass die Rückgabe von <code>True</code> entscheidend ist, da dies das Kriterium für DSPy ist, um das Bootstrapping-Beispiel als \"erfolgreich\" zu betrachten. Wenn Sie jede Auswertung als <code>True</code> zurückgeben, wird jedes Beispiel im Bootstrapping als \"Erfolg\" gewertet! Das ist natürlich nicht ideal, aber so können Sie die Strenge der Metrik-Funktion anpassen, um das <code>\"Bootstrapped 0 full traces\"</code> Ergebnis zu ändern. Beachten Sie, dass, obwohl DSPy dokumentiert, dass Metriken auch Skalare zurückgeben können, ich nach Durchsicht des zugrunde liegenden Codes dies für Anfänger nicht empfehlen würde.</p><h4 id=\"your-logic-dspymodule-is-incorrect\">Ihre Logik (<code>DSPy.Module</code>) ist fehlerhaft</h4><p>Wenn die Metrik-Funktion korrekt ist, müssen Sie überprüfen, ob Ihre Logik <code>dspy.Module</code> korrekt implementiert ist. Überprüfen Sie zunächst, ob die <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io\">DSPy signature</a> für jeden Schritt korrekt zugewiesen ist. Inline-Signatures wie <code>dspy.Predict('question->answer')</code> sind einfach zu verwenden, aber aus Qualitätsgründen empfehle ich dringend die Implementierung mit <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io#class-based-dspy-signatures\">klassenbasierten Signatures</a>. Fügen Sie insbesondere einige beschreibende Docstrings zur Klasse hinzu, füllen Sie die desc-Felder für <code>InputField</code> und <code>OutputField</code> aus - all dies gibt dem LM Hinweise zu jedem Feld. Unten habe ich zwei mehrstufige <code>DSPy.Module</code> zur Lösung von <a href=\"https://en.wikipedia.org/wiki/Fermi_problem?ref=jina-ai-gmbh.ghost.io\">Fermi-Problemen</a> implementiert, eines mit Inline-Signature, eines mit klassenbasierter Signature.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiSolver(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict('question -> initial_guess')\n        self.step2 = dspy.Predict('question, initial_guess -> calculated_estimation')\n        self.step3 = dspy.Predict('question, initial_guess, calculated_estimation -> variables_and_formulae')\n        self.step4 = dspy.ReAct('question, initial_guess, calculated_estimation, variables_and_formulae -> gathering_data')\n        self.step5 = dspy.Predict('question, initial_guess, calculated_estimation, variables_and_formulae, gathering_data -> answer')\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Fermi-Problemlöser nur mit Inline-Signature</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiStep1(dspy.Signature):\n    question = dspy.InputField(desc='Fermi problems involve the use of estimation and reasoning')\n    initial_guess = dspy.OutputField(desc='Have a guess – don't do any calculations yet')\n\nclass FermiStep2(FermiStep1):\n    initial_guess = dspy.InputField(desc='Have a guess – don't do any calculations yet')\n    calculated_estimation = dspy.OutputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n\nclass FermiStep3(FermiStep2):\n    calculated_estimation = dspy.InputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n    variables_and_formulae = dspy.OutputField(desc='Write a formula or procedure to solve your problem')\n\nclass FermiStep4(FermiStep3):\n    variables_and_formulae = dspy.InputField(desc='Write a formula or procedure to solve your problem')\n    gathering_data = dspy.OutputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n\nclass FermiStep5(FermiStep4):\n    gathering_data = dspy.InputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n    answer = dspy.OutputField(desc='the final answer, must be a numerical value')\n\nclass FermiSolver2(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict(FermiStep1)\n        self.step2 = dspy.Predict(FermiStep2)\n        self.step3 = dspy.Predict(FermiStep3)\n        self.step4 = dspy.Predict(FermiStep4)\n        self.step5 = dspy.Predict(FermiStep5)\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Fermi-Problemlöser mit klassenbasierter Signature und umfassenderer Beschreibung für jedes Feld.</span></p></figcaption></figure><p>Überprüfen Sie auch den <code>def forward(self, )</code> Teil. Bei mehrstufigen Modulen stellen Sie sicher, dass die Ausgabe (oder <em>alle</em> Ausgaben wie im <code>FermiSolver</code>) vom letzten Schritt als Eingabe für den nächsten Schritt verwendet wird.</p><h4 id=\"your-problem-is-just-too-hard\">Ihr Problem ist einfach zu schwierig</h4><p>Wenn sowohl die Metrik als auch das Modul korrekt erscheinen, dann ist es möglich, dass Ihr Problem einfach zu anspruchsvoll ist und die implementierte Logik nicht ausreicht, um es zu lösen. Daher findet DSPy es unmöglich, ein Demo mit Ihrer Logik und Metrik-Funktion zu bootstrappen. An diesem Punkt können Sie folgende Optionen in Betracht ziehen:</p><ul><li><strong>Verwenden Sie ein leistungsfähigeres LM.</strong> Zum Beispiel ersetzen Sie <code>gpt-35-turbo-instruct</code> durch <code>gpt-4-turbo</code> als Student-LM, verwenden Sie ein stärkeres LM als Lehrer. Dies kann oft sehr effektiv sein. Schließlich bedeutet ein stärkeres Modell ein besseres Verständnis der Prompts.</li><li><strong>Verbessern Sie Ihre Logik.</strong> Fügen Sie Schritte in Ihrem <code>dspy.Module</code> hinzu oder ersetzen Sie sie durch komplexere. Z.B. ersetzen Sie <code>Predict</code> durch <code>ChainOfThought</code> <code>ProgramOfThought</code>, fügen Sie einen <code>Retrieval</code>-Schritt hinzu.</li><li><strong>Fügen Sie mehr Trainingsbeispiele hinzu.</strong> Wenn 20 Beispiele nicht ausreichen, zielen Sie auf 100! Sie können dann hoffen, dass ein Beispiel die Metrik-Prüfung besteht und von <code>BootstrapFewShot</code> ausgewählt wird.</li><li><strong>Formulieren Sie das Problem um.</strong> Oft wird ein Problem unlösbar, wenn die Formulierung falsch ist. Aber wenn Sie es aus einem anderen Blickwinkel betrachten, können die Dinge viel einfacher und offensichtlicher werden.</li></ul><p>In der Praxis beinhaltet der Prozess eine Mischung aus Versuch und Irrtum. Zum Beispiel habe ich mich mit einem besonders anspruchsvollen Problem befasst: der Generierung eines SVG-Icons ähnlich den Google Material Design Icons basierend auf zwei oder drei Schlüsselwörtern. Meine anfängliche Strategie war die Verwendung eines einfachen <code>DSPy.Module</code>, das <code>dspy.ChainOfThought('keywords -> svg')</code> verwendet, gepaart mit einer Metrik-Funktion, die die visuelle Ähnlichkeit zwischen dem generierten SVG und dem Ground Truth Material Design SVG bewertete, ähnlich einem pHash-Algorithmus. Ich begann mit 20 Trainingsbeispielen, aber nach der ersten Runde endete ich mit <code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code>, was darauf hinwies, dass die Optimierung fehlgeschlagen war. Durch die Erhöhung des Datensatzes auf 100 Beispiele, die Überarbeitung meines Moduls zur Einbeziehung mehrerer Stufen und die Anpassung des Schwellenwerts der Metrik-Funktion erreichte ich schließlich 2 bootstrapped Demonstrationen und konnte einige optimierte Prompts erhalten.</p>",
  "comment_id": "66077bf0a5c39b0001044181",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-03-30T03:41:52.000+01:00",
  "updated_at": "2024-04-23T10:46:48.000+02:00",
  "published_at": "2024-03-30T06:22:42.000+01:00",
  "custom_excerpt": "Heads up, Bay Area guys ditched their AVP already and buzz about DSPy now. Could DSPy be the new go-to framework for prompt engineering after LangChain and LlamaIndex?",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/dspy-not-your-average-prompt-engineering/",
  "excerpt": "Aufgepasst: Die Leute aus der Bay Area haben AVP bereits aufgegeben und sprechen jetzt über DSPy. Könnte DSPy nach LangChain und LlamaIndex das neue Standard-Framework für Prompt Engineering werden?",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Screenshot of a Tetris-like game with \"Score: 40\" and \"Press Start 2P\" text on display.",
  "feature_image_caption": null
}