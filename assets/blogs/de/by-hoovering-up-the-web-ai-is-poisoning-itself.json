{
  "slug": "by-hoovering-up-the-web-ai-is-poisoning-itself",
  "id": "66acf331864a9b0001745edc",
  "uuid": "feb50d6f-21ea-4f11-b1e4-1d13df01706f",
  "title": "Durch das Aufsaugen des Webs vergiftet sich die KI selbst",
  "html": "<p>In letzter Zeit wurde viel √ºber die Gefahren diskutiert, wie KI-Unternehmen alle Daten aus dem Internet absaugen - ob sie nun die \"Erlaubnis\" dazu haben oder nicht. Auf das Thema \"Erlaubnis\" kommen wir sp√§ter noch zu sprechen - es gibt einen Grund, warum wir das Wort in Anf√ºhrungszeichen gesetzt haben. Aber was bedeutet es f√ºr LLMs, wenn das offene Web komplett ausgesch√∂pft ist, Content-Anbieter ihre T√ºren verschlie√üen und es kaum noch neue Daten zum Scrapen gibt?</p><h2 id=\"the-dangers-of-ai-scraping\">Die Gefahren des KI-Scrapings</h2><p>KI-Unternehmen behandeln das Internet wie ein All-you-can-eat-Datenbuffet und k√ºmmern sich nicht um Tischmanieren. Man schaue sich nur an, wie <a href=\"https://www.404media.co/runway-ai-image-generator-training-data-youtube/?ref=jina-ai-gmbh.ghost.io\">Runway YouTube-Videos f√ºr das Training ihres Modells erntet</a> (gegen YouTubes Nutzungsbedingungen), wie <a href=\"https://www.404media.co/anthropic-ai-scraper-hits-ifixits-website-a-million-times-in-a-day/?ref=jina-ai-gmbh.ghost.io\">Anthropic iFixit eine Million Mal am Tag aufruft</a> und wie <a href=\"https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html?ref=jina-ai-gmbh.ghost.io\">die New York Times OpenAI und Microsoft wegen der Nutzung urheberrechtlich gesch√ºtzter Werke verklagt</a>.</p><p>Der Versuch, Scraper in Ihrer <code>robots.txt</code> oder in den Nutzungsbedingungen zu blockieren, hilft nicht wirklich. Die Scraper, denen es egal ist, scrapen trotzdem, w√§hrend die r√ºcksichtsvolleren blockiert werden. Es gibt keinen Anreiz f√ºr Scraper, sich fair zu verhalten. Das sehen wir in der aktuellen Studie der <a href=\"https://www.dataprovenance.org/?ref=jina-ai-gmbh.ghost.io\">Data Provenance Initiative</a>:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.dataprovenance.org/consent-in-crisis-paper?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Data Provenance Initiative</div><div class=\"kg-bookmark-description\">Auditing the data used to train AI models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.dataprovenance.org/logo192.png\" alt=\"\"></div></div></a></figure><p>Dies ist kein abstraktes Problem - iFixit verliert Geld und bindet DevOps-Ressourcen. <a href=\"https://about.readthedocs.com/blog/2024/07/ai-crawlers-abuse/?ref=jina-ai-gmbh.ghost.io\">ReadTheDocs verursachte √ºber 5.000 Dollar Bandbreitenkosten in nur einem Monat, mit fast 10 TB an einem einzigen Tag, aufgrund missbr√§uchlicher Crawler</a>. Wenn Sie eine Website betreiben und von einem Crawler getroffen werden, der sich nicht an die Regeln h√§lt? Das k√∂nnte das Aus bedeuten.</p><p>Was also soll eine Website tun? Wenn sich KI-Unternehmen nicht an die Regeln halten wollen, werden mehr Paywalls entstehen und frei verf√ºgbare Inhalte abnehmen. Das freie Web gibt es nicht mehr. Alles was bleibt ist Pay-to-play.</p><h2 id=\"is-scraping-even-legal\">Ist Scraping √ºberhaupt legal?</h2><div class=\"kg-card kg-callout-card kg-callout-card-yellow\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Wir sind keine Anw√§lte und k√∂nnen keine Rechtsberatung anbieten. Das Folgende ist ein √úberblick √ºber bestehendes Recht zu Informationszwecken.</div></div>[Fortsetzung folgt...]<li>In Europa scheint <a href=\"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32019L0790&ref=jina-ai-gmbh.ghost.io#d1e986-92-1\">Artikel 4 der EU-Urheberrechtsrichtlinie von 2019</a> dies mit einigen Einschr√§nkungen legal zu machen.</li><li>In Japan wird <a href=\"https://www.japaneselawtranslation.go.jp/en/laws/view/3379?ref=jina-ai-gmbh.ghost.io#je_ch2sc3sb5at4\">Artikel 30(4) des Urheberrechtsgesetzes</a>, ge√§ndert im Jahr 2018, dahingehend ausgelegt, dass urheberrechtlich gesch√ºtzte Werke ohne Erlaubnis zum Training von KI verwendet werden d√ºrfen.</li><li>In den USA gibt es kein Gesetz, das diese Situation spezifisch regelt, jedoch wird seit vielen Jahren als selbstverst√§ndlich angenommen, dass die statistische Analyse urheberrechtlich gesch√ºtzter Materialien legal ist, auch wenn das Ergebnis ein kommerzielles Produkt ist. Obwohl die Gerichtsverfahren <a href=\"https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc.?ref=jina-ai-gmbh.ghost.io\"><em>Authors Guild, Inc. v. Google, Inc.</em></a> und <a href=\"https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._HathiTrust?ref=jina-ai-gmbh.ghost.io\"><em>Authors Guild, Inc. v. HathiTrust</em></a> KI nicht speziell behandeln, erweitern sie den Umfang der ‚ÄûFair Use\" unter US-Recht so stark, dass es schwer vorstellbar ist, wie KI-Training illegal sein k√∂nnte. Das amerikanische Rechtssystem bietet keine explizite Antwort, und mehrere F√§lle, die diese Schlussfolgerung pr√ºfen, durchlaufen derzeit die Gerichte.</li></ul><p>Eine Reihe kleinerer Rechtsordnungen hat ebenfalls festgestellt, dass es legal ist, und nach meinem besten Wissen hat bisher keine es f√ºr illegal erkl√§rt.</p><p>Das europ√§ische Urheberrecht erlaubt es Inhabern urheberrechtlich gesch√ºtzter Daten, die Verwendung ihrer Werke f√ºr KI-Training einzuschr√§nken, indem sie dies ‚Äûin geeigneter Weise\" anzeigen. Derzeit gibt es keine Anleitung, wie sie dies tun sollten.</p><p>Das japanische Urheberrecht beschr√§nkt die Verwendung urheberrechtlich gesch√ºtzter Materialien, wenn dies ‚Äûdie Interessen des Urheberrechtsinhabers unangemessen beeintr√§chtigen k√∂nnte\". Dies bedeutet typischerweise, dass ein Urheberrechtsinhaber nachweisen m√ºsste, wie ein bestimmtes KI-Modell den wirtschaftlichen Wert ihres Werks mindert, um einen Fall aufbauen zu k√∂nnen.</p><p>Wir sollten beachten, dass <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification?ref=jina-ai-gmbh.ghost.io\">Google</a>, <a href=\"https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/?ref=jina-ai-gmbh.ghost.io\">Microsoft</a>, <a href=\"https://www.jdsupra.com/legalnews/openai-joins-other-generative-ai-1871431/?ref=jina-ai-gmbh.ghost.io\">OpenAI</a>, <a href=\"https://techcrunch.com/2023/06/26/adobe-indemnity-clause-designed-to-ease-enterprise-fears-about-ai-generated-art/?ref=jina-ai-gmbh.ghost.io\">Adobe</a> und <a href=\"https://www.shutterstock.com/blog/ai-generated-images-indemnification?ref=jina-ai-gmbh.ghost.io\">Shutterstock</a> angeboten haben, jeden Nutzer ihrer generativen KI-Produkte zu entsch√§digen, der mit rechtlichen Herausforderungen bez√ºglich des Urheberrechts konfrontiert wird. Dies ist ein starker Hinweis darauf, dass ihre Anw√§lte der Meinung sind, dass ihr Handeln nach US-Recht legal ist.</p><h2 id=\"what-voracious-scraping-means-for-ai\">Was gefr√§√üiges Scraping f√ºr KI bedeutet</h2><p>Der KI-Scraping-Boom verwandelt das Web in einen digitalen Wilden Westen. Diese Scraper behandeln <code>robots.txt</code> wie Schnee von gestern und bombardieren Websites wie iFixit mit endlosen Anfragen. Das ist nicht nur l√§stig - es ist potenziell web-zerst√∂rend und zwingt uns, die Funktionsweise des offenen Internets zu √ºberdenken. Oder wie es in naher Zukunft m√∂glicherweise nicht mehr funktionieren wird. Allein aus wirtschaftlicher und sozialer Sicht k√∂nnte sich vieles √§ndern:</p><p><strong>Vertrauensverlust:</strong> Dieser KI-F√ºtterungswahn k√∂nnte zu einem massiven Vertrauensbruch im Web f√ºhren. Stellen Sie sich eine Zukunft vor, in der jede Website Sie mit skeptischem Blick begr√º√üt und Sie beweisen m√ºssen, dass Sie ein Mensch sind, bevor Sie √ºberhaupt einen Blick auf deren Inhalte werfen k√∂nnen. Wir sprechen von mehr CAPTCHAs, mehr Login-Walls, mehr \"Klicken Sie alle Ampeln an\"-Tests. Es ist, als w√ºrde man versuchen, in eine Speakeasy zu kommen, aber statt eines geheimen Passworts muss man den T√ºrsteher davon √ºberzeugen, dass man keine sehr clevere Maschine ist.</p><p><strong>Eingeschr√§nkte von Menschen generierte Inhalte:</strong> Content-Ersteller, die bereits vorsichtig sind, dass ihre Arbeit geklaut wird, beginnen, die Luken zu schlie√üen. Wir k√∂nnten einen Anstieg von Paywalls, Nur-f√ºr-Abonnenten-Bereichen und Content-Sperren sehen. Die Tage des freien Surfens und Lernens k√∂nnten zu einer nostalgischen Erinnerung werden, wie Einwahlmodem-Ger√§usche oder AIM-Away-Messages. Wenn normale Menschen nicht darauf zugreifen k√∂nnen, macht es das f√ºr einen abtr√ºnnigen Scraper umso schwieriger, hineinzukommen.</p><p><strong>Rechtsf√§lle:</strong> Es k√∂nnte Jahre oder sogar Jahrzehnte dauern, bis alle rechtlichen Fragen rund um KI gekl√§rt sind. Wir haben das Internet seit etwa drei√üig Jahren, und einige seiner rechtlichen Fragen sind <em>heute noch</em> ungekl√§rt. Ob Sie nun im Recht sind oder nicht, wenn Sie es sich nicht leisten k√∂nnen, jahrelang vor Gericht herauszufinden, was erlaubt ist und was nicht, haben Sie Grund zur Sorge.</p><p><strong>Kleine gehen pleite, Gro√üe werden fetter:</strong> Diese Scraping-Manie ist nicht nur l√§stig - sie belastet die Web-Infrastruktur real. Websites, die mit KI-induzierten Verkehrsstaus zu k√§mpfen haben, m√ºssen m√∂glicherweise auf leistungsf√§higere Server aufr√ºsten, was nicht billig ist. Kleinere Websites und coole Hobbyprojekte k√∂nnten aus dem Spiel gedr√§ngt werden, was uns ein Web (und LLM-Trainingsdaten) hinterl√§sst, das von denen dominiert wird, die gro√ü genug sind, um den Sturm zu √ºberstehen oder Lizenzvertr√§ge mit den KI-Unternehmen abzuschlie√üen. Es ist ein \"√úberleben der Reichsten\"-Szenario, das das Internet (und LLM-Wissen) viel weniger vielf√§ltig und interessant machen k√∂nnte. Indem sie die T√ºr zu frei verf√ºgbaren Daten schlie√üen, k√∂nnen sie dann eine Eintrittsgeb√ºhr von den KI-Unternehmen verlangen oder einfach an den H√∂chstbietenden lizenzieren. Kein Geld? Der T√ºrsteher wird Ihnen den Weg zur T√ºr zeigen.</p><h2 id=\"ai-generated-data-to-the-rescue\">KI-generierte Daten zur Rettung?</h2><p>Der Daten-Grab ersch√ºttert nicht nur Websites - er bereitet den Boden f√ºr eine potenzielle KI-Wissensd√ºrre. W√§hrend das offene Web seine Zugbr√ºcken hochzieht, werden KI-Modelle nach frischen, hochwertigen Daten hungern.</p><p>Diese Datenknappheit k√∂nnte zu einem √ºblen Fall von KI-Tunnelblick f√ºhren. Ohne einen stetigen Strom neuer Informationen riskieren KI-Modelle, zu Echokammern veralteten Wissens zu werden. Stellen Sie sich vor, Sie fragen eine KI nach aktuellen Ereignissen und bekommen Antworten, die klingen, als w√§ren sie vom letzten Jahr - oder schlimmer, aus einem Paralleluniversum, in dem Fakten Urlaub machen.</p><p>Wenn von Menschen generierte Daten weggesperrt sind, m√ºssen Unternehmen ihre Trainingsdaten trotzdem <em>irgendwoher</em> bekommen. Ein Beispiel daf√ºr sind <a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">synthetische Daten</a>: Daten, die von LLMs erstellt wurden, um andere LLMs zu trainieren. Dies umfasst weit verbreitete Techniken wie Modelldestillation und die Generierung von Trainingsdaten zum Ausgleich von Verzerrungen.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>Die Verwendung synthetischer Daten bedeutet, dass man keine Hindernisse √ºberwinden muss, um von Menschen generierte Daten zu lizenzieren, was, wie wir gesehen haben, zunehmend schwieriger wird. Es hilft auch dabei, Dinge auszugleichen - viele Daten im Internet repr√§sentieren nicht die Vielfalt der realen Welt. Die Generierung synthetischer Daten kann dazu beitragen, ein Modell repr√§sentativer f√ºr die Realit√§t zu machen (<a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">oder manchmal auch nicht</a>). Schlie√ülich eliminiert es f√ºr <a href=\"https://www.nature.com/articles/s41746-023-00927-3?ref=jina-ai-gmbh.ghost.io\">Gesundheits-</a> und rechtliche Anwendungsf√§lle die Notwendigkeit, Daten zu bereinigen, um personenbezogene Informationen zu entfernen.</p><p>Die Kehrseite der Medaille ist jedoch, dass zuk√ºnftige Modelle auch mit KI-generierten Daten trainiert werden, die Sie wirklich <em>nicht</em> f√ºr das Training verwenden m√∂chten, n√§mlich \"<a href=\"https://www.garbageday.email/p/slop-void?ref=jina-ai-gmbh.ghost.io\">Slop</a>\": minderwertige KI-generierte Daten, wie ein <a href=\"https://www.404media.co/a-beloved-tech-blog-tuaw-is-now-publishing-ai-articles-under-the-names-of-its-old-human-staff/?ref=jina-ai-gmbh.ghost.io\">einst beliebter Tech-Blog, der jetzt minderwertige KI-generierte Artikel unter den Namen seiner ehemaligen Mitarbeiter ver√∂ffentlicht</a>, <a href=\"https://www.theguardian.com/food/article/2024/jul/31/one-of-the-most-disgusting-meals-ive-ever-eaten-ai-recipes-tested?ref=jina-ai-gmbh.ghost.io\">KI-generierte Rezepte f√ºr unwahrscheinliche Gerichte wie Crockpot-Mojitos und Bratwurst-Eiscreme</a> oder <a href=\"https://www.404media.co/email/1cdf7620-2e2f-4450-9cd9-e041f4f0c27f/?ref=jina-ai-gmbh.ghost.io\">Garnelen-Jesus, der Facebook √ºbernimmt</a>.</p><p>Da dies viel billiger und einfacher zu erstellen ist als gute altmodische handgefertigte Inhalte, √ºberflutet es das Internet rapide.</p><p>Basierend auf dem, was wir heute sehen, √ºberholen KI-generierte Inhalte die verf√ºgbaren von Menschen generierten Inhalte. GPT-5 wird (teilweise) mit Daten trainiert werden, die von GPT-4 erstellt wurden. GPT-6 wird wiederum mit Daten trainiert werden, die von GPT-5 erstellt wurden. Und so weiter und so fort.</p><h2 id=\"model-collapse-and-how-to-avoid-it\">Modell-Kollaps und wie man ihn vermeidet</h2><p>Die Verwendung der eigenen Outputs als Inputs ist sowohl f√ºr Menschen als auch f√ºr LLMs schlecht. Selbst wenn Sie sehr selektiv sind, wie viele synthetische Daten Sie verwenden und welcher Art, k√∂nnen Sie nicht garantieren, dass Ihr Modell nicht schlechter wird.</p><p>F√ºr generative KI-Modelle als Ganzes ist der Qualit√§ts- und Diversit√§tsverlust der Outputs experimentell messbar und <a href=\"https://arxiv.org/abs/2305.17493?ref=jina-ai-gmbh.ghost.io\">passiert ziemlich schnell</a>. Bildgenerierende Modelle entwickeln nach wenigen Generationen Anomalien, und <a href=\"https://doi.org/10.1038/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\">in einer Studie</a> antwortete ein gro√ües Sprachmodell, das mit Wikipedia-Daten trainiert wurde und koh√§rente und akkurate Antworten auf Prompts gab, in der neunten Generation des Trainings mit seinen eigenen Outputs nur noch mit der st√§ndigen Wiederholung der Worte \"tailed jackrabbits\".</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://doi.org/10.1038/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">KI-Modelle kollabieren, wenn sie mit rekursiv generierten Daten trainiert werden - Nature</div><div class=\"kg-bookmark-description\">&amp;nbsp;Analysen zeigen, dass das wahllose Training generativer k√ºnstlicher Intelligenz mit echten und generierten Inhalten, das √ºblicherweise durch das Scraping von Daten aus dem Internet erfolgt, zu einem Zusammenbruch der F√§higkeit der Modelle f√ºhren kann, vielf√§ltige qualitativ hochwertige Ausgaben zu generieren.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://static.ghost.org/v5.0.0/images/link-icon.svg\" alt=\"\"><span class=\"kg-bookmark-author\">Nature</span><span class=\"kg-bookmark-publisher\">Ilia Shumailov</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png\" alt=\"\"></div></a></figure><p>Das ist einfach zu erkl√§ren: Ein KI-Modell ist eine Approximation seiner Trainingsdaten. Ein KI-Modell, das mit KI-Modell-Output trainiert wird, ist eine Approximation einer Approximation. Bei jedem Trainingszyklus wird die Differenz zwischen der Approximation und den \"wahren\" realen Daten immer gr√∂√üer.</p><p>Wir nennen dies \"Model Collapse\".</p><p>Da KI-generierte Daten immer weiter verbreitet werden, riskiert das Training neuer Modelle mit aus dem Internet gescrapter Daten eine Verschlechterung der Modellleistung. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">Wir haben Grund zur Annahme</a>, dass solange die Menge echter, von Menschen erstellter Daten nicht abnimmt, unsere Modelle nicht viel schlechter werden, aber sie werden auch nicht besser. Sie werden jedoch l√§nger zum Trainieren brauchen, wenn wir KI-erstellte Daten nicht von menschengemachten Daten trennen k√∂nnen. Neue Modelle werden teurer in der Herstellung, ohne sich zu verbessern.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</div><div class=\"kg-bookmark-description\">The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops proposed that such loops would lead to a phenomenon termed model collapse, under which performance progressively degrades with each model-data feedback iteration until fitted models become useless. However, those studies largely assumed that new data replace old data over time, where an arguably more realistic assumption is that data accumulate over time. In this paper, we ask: what effect does accumulating data have on model collapse? We empirically study this question by pretraining sequences of language models on text corpora. We confirm that replacing the original real data by each generation's synthetic data does indeed tend towards model collapse, then demonstrate that accumulating the successive generations of synthetic data alongside the original real data avoids model collapse; these results hold across a range of model sizes, architectures, and hyperparameters. We obtain similar results for deep generative models on other types of real data: diffusion models for molecule conformation generation and variational autoencoders for image generation. To understand why accumulating data can avoid model collapse, we use an analytically tractable framework introduced by prior work in which a sequence of linear models are fit to the previous models' outputs. Previous work used this framework to show that if data are replaced, the test error increases with the number of model-fitting iterations; we extend this argument to prove that if data instead accumulate, the test error has a finite upper bound independent of the number of iterations, meaning model collapse no longer occurs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Matthias Gerstgrasser</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>Die Ironie ist hier deutlich zu sp√ºren. Der uners√§ttliche Datenhunger der KI k√∂nnte zu einer Datenhungersnot f√ºhren. <a href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\">Model Autophagy Disorder</a> ist wie <a href=\"https://en.wikipedia.org/wiki/Bovine_spongiform_encephalopathy?ref=jina-ai-gmbh.ghost.io\">BSE (Rinderwahnsinn)</a> f√ºr KI: Genau wie die Verf√ºtterung von Rinderabf√§llen an K√ºhe zu einer neuen Art von parasit√§rer Gehirnkrankheit f√ºhrte, f√ºhrt das Training von KI mit wachsenden Mengen an KI-Output zu verheerenden mentalen Pathologien.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Self-Consuming Generative Models Go MAD</div><div class=\"kg-bookmark-description\">Seismic advances in generative AI algorithms for imagery, text, and other data types has led to the temptation to use synthetic data to train next-generation models. Repeating this process creates an autophagous (self-consuming) loop whose properties are poorly understood. We conduct a thorough analytical and empirical analysis using state-of-the-art generative image models of three families of autophagous loops that differ in how fixed or fresh real training data is available through the generations of training and in whether the samples from previous generation models have been biased to trade off data quality versus diversity. Our primary conclusion across all scenarios is that without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD), making analogy to mad cow disease.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Sina Alemohammad</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>Die gute Nachricht ist, dass KI die Menschheit nicht ersetzen kann, weil sie unsere Daten braucht. Die schlechte Nachricht ist, dass sie ihr eigenes Wachstum hemmen k√∂nnte, indem sie ihre Datenquellen ruiniert.</p><p>Um diese absehbare KI-Wissenshungersnot zu vermeiden, m√ºssen wir √ºberdenken, wie wir KI-Modelle trainieren und nutzen. Wir sehen bereits L√∂sungen wie <a href=\"https://dl.acm.org/doi/abs/10.5555/3495724.3496517?ref=jina-ai-gmbh.ghost.io\">Retrieval-Augmented Generation</a>, die versucht, KI-Modelle nicht als Quelle faktischer Informationen zu nutzen, sondern sie stattdessen als Werkzeuge zur Bewertung und Reorganisation externer Informationsquellen zu sehen. Ein anderer Weg f√ºhrt √ºber Spezialisierung, bei der wir Modelle anpassen, um bestimmte Arten von Aufgaben auszuf√ºhren, unter Verwendung kuratierter Trainingsdaten, die sich auf enge Dom√§nen konzentrieren. Wir k√∂nnten vermeintliche Allzweckmodelle wie ChatGPT durch Spezial-KIs ersetzen: LawLLM, MedLLM, MyLittlePonyLLM und so weiter.</p><p>Es gibt andere M√∂glichkeiten, und es ist schwer zu sagen, welche neuen Techniken Forscher noch entdecken werden. Vielleicht gibt es einen besseren Weg, synthetische Daten zu generieren oder Wege, bessere Modelle aus weniger Daten zu erhalten. Aber es gibt keine Garantie, dass mehr Forschung das Problem l√∂sen wird.</p><p>Letztendlich k√∂nnte diese Herausforderung die KI-Community dazu zwingen, kreativ zu werden. Schlie√ülich ist Not die Mutter der Erfindung, und eine datenarme KI-Landschaft k√∂nnte einige wirklich innovative L√∂sungen hervorbringen. Wer wei√ü? Der n√§chste gro√üe Durchbruch in der KI k√∂nnte nicht aus mehr Daten kommen, sondern daraus, wie man mehr mit weniger erreicht.</p><h2 id=\"what-happens-if-only-megacorps-can-afford-to-scrape\">Was passiert, wenn nur Megakonzerne sich Scraping leisten k√∂nnen?</h2><p>F√ºr viele Menschen heute ist das Internet Facebook, Instagram und X, betrachtet durch ein schwarzes Glasrechteck, das sie in der Hand halten. Es ist homogenisiert, \"sicher\" und wird von Torw√§chtern kontrolliert, die (durch Richtlinien und ihre Algorithmen) entscheiden, was (und wen) man sieht und was nicht.</p><p>Das war nicht immer so. Vor nur ein paar Jahrzehnten hatten wir nutzergenerierte Blogs, unabh√§ngige Websites und vieles mehr. In den Achtzigern gab es Dutzende von konkurrierenden Betriebssystemen und Hardware-Standards. Aber bis in die 2010er Jahre hatten Apple und Microsoft die Oberhand gewonnen und den Trend zur Homogenisierung eingeleitet.</p><p>Dasselbe sehen wir bei Webbrowsern, Smartphones und Social-Media-Seiten. Wir beginnen mit einer Explosion von Vielfalt und neuen Ideen, bevor die gro√üen Spieler den Ball an sich rei√üen und es allen anderen schwer machen mitzuspielen.</p><p>Allerdings konnten sich, w√§hrend diese Spieler ein Monopol <em>hatten</em>, trotzdem einige kleinere Fische durchsetzen. (Nehmen wir Linux und Firefox als Beispiel). Bei LLMs ist es jedoch unwahrscheinlich, dass der \"Underdog\" erfolgreich sein wird. Wenn kleinen Akteuren die finanziellen Mittel fehlen, um Zugang zu vielf√§ltigen und aktuellen Trainingsdaten zu erhalten, k√∂nnen sie keine hochwertigen Modelle erstellen. Und ohne das, wie k√∂nnen sie im Gesch√§ft bleiben?</p><p>Die Giganten haben die Ressourcen, ihre KI-Modelle weiterhin mit einer stetigen Di√§t frischer Informationen zu f√ºttern, w√§hrend das weitere Web den G√ºrtel enger schnallt. W√§hrenddessen m√ºssen sich kleinere Akteure und Startups mit den Resten am Boden des Datenfasses begn√ºgen und sich abm√ºhen, ihre Algorithmen mit abgestandenen Kr√ºmeln zu ern√§hren. Es ist eine Wissensl√ºcke, die sich aufschaukeln k√∂nnte. W√§hrend die Datenreichen in Bezug auf Erkenntnisse und F√§higkeiten reicher werden, laufen die Datenarmen Gefahr, weiter zur√ºckzufallen, wobei ihre KIs von Tag zu Tag veralteter und weniger wettbewerbsf√§hig werden. Dabei geht es nicht nur darum, wer das gl√§nzendste KI-Spielzeug hat - es geht darum, wer die Zukunft von Technologie, Handel und sogar unseren Informationszugang gestalten darf. Wir blicken in eine Zukunft, in der eine Handvoll Tech-Giganten die Schl√ºssel zu den fortschrittlichsten KI-K√∂nigreichen halten k√∂nnte, w√§hrend alle anderen aus dem digitalen Mittelalter heraus zusehen m√ºssen.</p><p>Bei all den interessanten Inhalten, die lizenziert werden k√∂nnen, ist es unwahrscheinlich, dass ein einziger Megakonzern alles lizenziert, wie Netflix in den alten Zeiten. Erinnern Sie sich? Man abonnierte einen Dienst und bekam jede Show, von der man je getr√§umt hatte. Heute sind Shows √ºber Hulu, Netflix, Disney+ und wie auch immer HBO Max gerade hei√üt, verteilt. Manchmal kann eine Show, die man liebt, einfach <a href=\"https://www.theguardian.com/tv-and-radio/2023/jun/28/why-are-movies-and-tv-shows-disappearing-from-streaming-services?ref=jina-ai-gmbh.ghost.io\">in der Luft verschwinden</a>. Dies k√∂nnte die Zukunft der LLMs sein: <a href=\"https://www.404media.co/google-is-the-only-search-engine-that-works-on-reddit-now-thanks-to-ai-deal/?ref=jina-ai-gmbh.ghost.io\">Google hat bevorzugten Zugang zu Reddit</a>, w√§hrend <a href=\"https://archive.is/20240430231312/https://www.ft.com/content/33328743-ba3b-470f-a2e3-f41c3a366613?ref=jina-ai-gmbh.ghost.io\">OpenAI Zugang zur Financial Times</a> bekommt. iFixit? Diese Daten gibt es einfach nicht mehr, sie sind nur noch als verstaubte Embeddings gespeichert und werden nie aktualisiert. Statt einem Modell, sie alle zu beherrschen, k√∂nnten wir auf Fragmentierung und wechselnde F√§higkeiten blicken, w√§hrend Lizenzrechte zwischen KI-Anbietern hin und her geschoben werden.</p><h2 id=\"in-conclusion\">Fazit</h2><p>Ob es uns gef√§llt oder nicht - Scraping wird bleiben. Bereits jetzt errichten Content-Anbieter Barrieren, um den Zugang zu beschr√§nken, w√§hrend sie die T√ºren nur f√ºr diejenigen √∂ffnen, die sich die Lizenzierung der Inhalte leisten k√∂nnen. Dies schr√§nkt die Ressourcen, von denen ein LLM lernen kann, erheblich ein. Gleichzeitig werden kleinere Unternehmen aus dem Bieterkrieg um lukrative Inhalte verdr√§ngt, w√§hrend der Rest der Beute zwischen den LLMs der Tech-Giganten aufgeteilt wird. Es ist wie die Post-Netflix-Streaming-√Ñra, nur diesmal geht es um Wissen.</p><p>W√§hrend verf√ºgbare von Menschen generierte Daten schwinden, boomt KI-generierter \"Datenschrott\". Das Training von Modellen damit kann zu einer Verlangsamung der Verbesserung oder sogar zum Modellkollaps f√ºhren. Der einzige Ausweg ist, √ºber den Tellerrand hinauszudenken - etwas, wof√ºr Startups mit ihrer Kultur der Innovation und Disruption ideal geeignet sind. Doch genau die Daten, die nur an die gro√üen Player lizenziert werden, sind der Lebenssaft, den solche Startups zum √úberleben brauchen.</p><p>Indem sie den fairen Zugang zu Daten einschr√§nken, ersticken die Mega-Konzerne nicht nur den Wettbewerb - sie w√ºrgen die Zukunft der KI selbst ab und erdrosseln genau die Innovation, die uns √ºber dieses potenzielle digitale dunkle Zeitalter hinausbringen k√∂nnte.</p><p>Die KI-Revolution ist nicht die Zukunft, KI ist Gegenwart. In den Worten von William Gibson: \"[D]ie Zukunft ist bereits hier, sie ist nur nicht gleichm√§√üig verteilt.\" Sie kann leicht noch ungleichm√§√üiger verteilt werden.</p>",
  "comment_id": "66acf331864a9b0001745edc",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-02T16:54:41.000+02:00",
  "updated_at": "2024-08-15T20:10:15.000+02:00",
  "published_at": "2024-08-14T22:44:46.000+02:00",
  "custom_excerpt": "What does it mean for LLMs when the web has been strip-mined clean, content providers have locked their doors, and there‚Äôs barely a trickle of new data to scrape? ",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ade4a3e4e55003d525971",
      "name": "Alex C-G",
      "slug": "alexcg",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
      "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
      "website": null,
      "location": "Berlin, Germany",
      "facebook": null,
      "twitter": "@alexcg",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "6342c5b4393501004d1c8b2c",
      "name": "Insights",
      "slug": "insights",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
    }
  ],
  "primary_author": {
    "id": "632ade4a3e4e55003d525971",
    "name": "Alex C-G",
    "slug": "alexcg",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
    "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
    "website": null,
    "location": "Berlin, Germany",
    "facebook": null,
    "twitter": "@alexcg",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
  },
  "primary_tag": {
    "id": "6342c5b4393501004d1c8b2c",
    "name": "Insights",
    "slug": "insights",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/by-hoovering-up-the-web-ai-is-poisoning-itself/",
  "excerpt": "Was bedeutet es f√ºr LLMs, wenn das Web komplett ausgesch√∂pft wurde, Content-Anbieter ihre T√ºren verschlossen haben und es kaum noch neue Daten zum Scrapen gibt?",
  "reading_time": 17,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Illustration of a cartoonish robot vacuum cleaner with big eyes and an open mouth, humorously sticking out a tongue to clean,",
  "feature_image_caption": null
}