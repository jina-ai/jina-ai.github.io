{
  "slug": "jina-classifier-for-high-performance-zero-shot-and-few-shot-classification",
  "id": "6711fbbd708dbe0001924974",
  "uuid": "65c883e0-556a-4079-b07a-66e9e9926717",
  "title": "Jina Classifier API für High-Performance Zero-Shot- und Few-Shot-Klassifizierung",
  "html": "<p>Klassifizierung ist eine häufige nachgelagerte Aufgabe für Embeddings. Text-Embeddings können Text für Spam-Erkennung oder Stimmungsanalyse in vordefinierte Labels kategorisieren. Multimodale Embeddings wie <code>jina-clip-v1</code> können für inhaltsbasierte Filterung oder Tag-Annotation eingesetzt werden. In letzter Zeit wird Klassifizierung auch verwendet, um Anfragen basierend auf Komplexität und Kosten an geeignete LLMs weiterzuleiten - einfache arithmetische Anfragen könnten beispielsweise an ein kleines Sprachmodell geleitet werden. Komplexe Denkaufgaben könnten an leistungsfähigere, aber kostspieligere LLMs weitergeleitet werden.</p><p>Heute stellen wir die neue <strong>Classifier API</strong> von Jina AI's Search Foundation vor. Sie unterstützt <strong>Zero-Shot</strong> und <strong>Few-Shot</strong> Online-Klassifizierung und basiert auf unseren neuesten Embedding-Modellen wie <code>jina-embeddings-v3</code> und <code>jina-clip-v1</code>. Die Classifier API baut auf dem <a href=\"https://jmlr.org/papers/v7/crammer06a.html?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Online Passive-Aggressive Learning</a> auf und ermöglicht so die Anpassung an neue Daten in Echtzeit. Benutzer können mit einem Zero-Shot-Klassifizierer beginnen und ihn sofort einsetzen. Sie können den Klassifizierer dann schrittweise aktualisieren, indem sie neue Beispiele einreichen oder wenn Concept Drift auftritt. Dies ermöglicht eine effiziente, skalierbare Klassifizierung verschiedener Inhaltstypen <em>ohne</em> umfangreiche anfängliche gelabelte Daten. Benutzer können ihre Klassifizierer auch für die öffentliche Nutzung freigeben. Wenn unsere neuen Embeddings erscheinen, wie das kommende multilinguale <code>jina-clip-v2</code>, können Benutzer sofort über die Classifier API darauf zugreifen und stellen so aktuelle Klassifizierungsfähigkeiten sicher.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/classifier?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Classifier API</div><div class=\"kg-bookmark-description\">High performance classifier for image and text classification.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-classifier.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"zero-shot-classification\">Zero-Shot-Klassifizierung</h2><p>Die Classifier API bietet leistungsstarke Zero-Shot-Klassifizierungsfähigkeiten, die es ermöglichen, Text oder Bilder ohne vorheriges Training mit gelabelten Daten zu kategorisieren. Jeder Klassifizierer beginnt mit Zero-Shot-Fähigkeiten, die später durch zusätzliche Trainingsdaten oder Updates erweitert werden können - ein Thema, das wir im nächsten Abschnitt behandeln werden.</p><h3 id=\"example-1-route-llm-requests\">Beispiel 1: LLM-Anfragen weiterleiten</h3><p>Hier ist ein Beispiel für die Verwendung der Classifier API zum Routing von LLM-Anfragen:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-embeddings-v3\",\n    \"labels\": [\n      \"Simple task\",\n      \"Complex reasoning\",\n      \"Creative writing\"\n    ],\n    \"input\": [\n      \"Calculate the compound interest on a principal of $10,000 invested for 5 years at an annual rate of 5%, compounded quarterly.\",\n      \"分析使用CRISPR基因编辑技术在人类胚胎中的伦理影响。考虑潜在的医疗益处和长期社会后果。\",\n      \"AIが自意識を持つディストピアの未来を舞台にした短編小説を書いてください。人間とAIの関係や意識の本質をテーマに探求してください。\",\n      \"Erklären Sie die Unterschiede zwischen Merge-Sort und Quicksort-Algorithmen in Bezug auf Zeitkomplexität, Platzkomplexität und Leistung in der Praxis.\",\n      \"Write a poem about the beauty of nature and its healing power on the human soul.\",\n      \"Translate the following sentence into French: The quick brown fox jumps over the lazy dog.\"\n    ]\n  }'</code></pre><p>Dieses Beispiel demonstriert die Verwendung von <code>jina-embeddings-v3</code> zur Weiterleitung von Benutzeranfragen in mehreren Sprachen (Englisch, Chinesisch, Japanisch und Deutsch) in drei Kategorien, die drei verschiedenen LLM-Größen entsprechen. Das API-Antwortformat sieht wie folgt aus:</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 256, \"prompt_tokens\": 256},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Simple task\", \"score\": 0.35216382145881653},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Complex reasoning\", \"score\": 0.34310275316238403},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Creative writing\", \"score\": 0.3487184941768646},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Complex reasoning\", \"score\": 0.35207709670066833},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Creative writing\", \"score\": 0.3638903796672821},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Simple task\", \"score\": 0.3561534285545349}\n  ]\n}</code></pre><p>Die Antwort enthält:</p><ul><li><code>usage</code>: Informationen über die Token-Nutzung.</li><li><code>data</code>: Ein Array von Klassifizierungsergebnissen, eines für jede Eingabe.<ul><li>Jedes Ergebnis enthält das vorhergesagte Label (<code>prediction</code>) und einen Konfidenzwert (<code>score</code>). Der <code>score</code> für jede Klasse wird durch Softmax-Normalisierung berechnet - für Zero-Shot basiert er auf Kosinus-Ähnlichkeiten zwischen Eingabe- und Label-Embeddings <a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model?ref=jina-ai-gmbh.ghost.io#parameter-task\" rel=\"noreferrer\">unter <code>classification</code> task-LoRA</a>; während er für Few-Shot auf gelernten linearen Transformationen des Eingabe-Embeddings für jede Klasse basiert - was zu Wahrscheinlichkeiten führt, die sich über alle Klassen zu 1 summieren.</li><li>Der <code>index</code> entspricht der Position der Eingabe in der ursprünglichen Anfrage.</li></ul></li></ul><h3 id=\"example-2-categorize-image-text\">Beispiel 2: Bild & Text kategorisieren</h3><p>Lassen Sie uns ein multimodales Beispiel mit <code>jina-clip-v1</code> untersuchen. Dieses Modell kann sowohl Text als auch Bilder klassifizieren und eignet sich damit ideal für die Inhaltskategorisierung über verschiedene Medientypen hinweg. Betrachten Sie den folgenden API-Aufruf:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-clip-v1\",\n    \"labels\": [\n      \"Food and Dining\",\n      \"Technology and Gadgets\",\n      \"Nature and Outdoors\",\n      \"Urban and Architecture\"\n    ],\n    \"input\": [\n      {\"text\": \"A sleek smartphone with a high-resolution display and multiple camera lenses\"},\n      {\"text\": \"Fresh sushi rolls served on a wooden board with wasabi and ginger\"},\n      {\"image\": \"https://picsum.photos/id/11/367/267\"},\n      {\"image\": \"https://picsum.photos/id/22/367/267\"},\n      {\"text\": \"Vibrant autumn leaves in a dense forest with sunlight filtering through\"},\n      {\"image\": \"https://picsum.photos/id/8/367/267\"}\n    ]\n  }'</code></pre><p>Beachten Sie, wie wir Bilder in der Anfrage hochladen. Sie können auch einen <code>base64</code>-String verwenden, um ein Bild darzustellen. Die API gibt die folgenden Klassifizierungsergebnisse zurück:</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 12125, \"prompt_tokens\": 12125},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Technology and Gadgets\", \"score\": 0.30329811573028564},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Food and Dining\", \"score\": 0.2765541970729828},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Nature and Outdoors\", \"score\": 0.29503118991851807},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Urban and Architecture\", \"score\": 0.2648046910762787},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Nature and Outdoors\", \"score\": 0.3133063316345215},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Technology and Gadgets\", \"score\": 0.27474141120910645}\n  ]\n}</code></pre><h3 id=\"example-3-detect-if-jina-reader-gets-genuine-content\">Beispiel 3: Erkennen, ob Jina Reader echte Inhalte erhält</h3><p>Eine interessante Anwendung der Zero-Shot-Klassifizierung ist die Bestimmung der Website-Zugänglichkeit durch <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>. Während dies wie eine einfache Aufgabe erscheinen mag, ist es in der Praxis überraschend komplex. Blockierte Nachrichten variieren stark von Site zu Site, erscheinen in verschiedenen Sprachen und nennen verschiedene Gründe (Bezahlschranken, Rate-Limits, Server-Ausfälle). Diese Vielfalt macht es schwierig, sich auf Regex oder feste Regeln zu verlassen, um alle Szenarien zu erfassen.</p><pre><code class=\"language-python\">import requests\nimport json\n\nresponse1 = requests.get('https://r.jina.ai/https://jina.ai')\n\nurl = 'https://api.jina.ai/v1/classify'\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer $YOUR_API_KEY_HERE'\n}\ndata = {\n    'model': 'jina-embeddings-v3',\n    'labels': ['Blocked', 'Accessible'],\n    'input': [{'text': response1.text[:8000]}]\n}\nresponse2 = requests.post(url, headers=headers, data=json.dumps(data))\n\nprint(response2.text)</code></pre><p>Das Skript ruft Inhalte über <code>r.jina.ai</code> ab und klassifiziert sie mit der Classifier API als <code>\"Blocked\"</code> oder <code>\"Accessible\"</code>. Zum Beispiel würde <a href=\"https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai</a> wahrscheinlich aufgrund von Zugriffseinschränkungen als <code>\"Blocked\"</code> eingestuft, während <a href=\"https://r.jina.ai/https://jina.ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://jina.ai</a> \"Accessible\" sein sollte. </p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\"usage\":{\"total_tokens\":185,\"prompt_tokens\":185},\"data\":[{\"object\":\"classification\",\"index\":0,\"prediction\":\"Blocked\",\"score\":0.5392698049545288}]}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Die Classifier API kann effektiv zwischen echten Inhalten und blockierten Ergebnissen von Jina Reader unterscheiden.</span></p></figcaption></figure><p>Dieses Beispiel nutzt <code>jina-embeddings-v3</code> und bietet eine schnelle, automatisierte Möglichkeit zur Überwachung der Website-Zugänglichkeit, was besonders für Content-Aggregation oder Web-Scraping-Systeme in mehrsprachigen Umgebungen nützlich ist.</p><h3 id=\"example-4-filtering-statements-from-opinions-for-grounding\">Beispiel 4: Filtern von Aussagen aus Meinungen für Grounding</h3><p>Eine weitere spannende Anwendung der Zero-Shot-Klassifizierung ist das Filtern von aussageähnlichen Behauptungen aus Meinungen in langen Dokumenten. Beachten Sie, dass der Klassifizierer selbst nicht bestimmen kann, ob etwas faktisch wahr ist. Stattdessen identifiziert er Text, der <em>im Stil einer faktischen Aussage geschrieben ist</em>, der dann über eine Grounding API verifiziert werden kann, was oft recht aufwändig ist. Dieser zweistufige Prozess ist der Schlüssel zu effektivem Fact-Checking: Zunächst werden alle Meinungen und Gefühle herausgefiltert, dann werden die verbleibenden Aussagen zur Verifizierung gesendet.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/fact-checking-with-new-grounding-api-in-jina-reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Fact-Checking with New Grounding API in Jina Reader</div><div class=\"kg-bookmark-description\">With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Betrachten Sie diesen Absatz über das Wettrüsten im Weltraum in den 1960er Jahren:</p><pre><code class=\"language-json\">The Space Race of the 1960s was a breathtaking testament to human ingenuity. When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era. The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance. NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973. While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent. On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars. The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination. The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle.\n</code></pre><p>Dieser Text vermischt absichtlich verschiedene Schreibstile - von aussageähnlichen Behauptungen (wie \"Sputnik 1 wurde am 4. Oktober 1959 gestartet\") bis hin zu eindeutigen Meinungen (\"atemberaugendes Zeugnis\"), emotionaler Sprache (\"versetzte Angst in die Herzen\") und interpretativen Behauptungen (\"markierte den unbestreitbaren Beginn einer neuen Ära\").</p><p>Die Aufgabe des Zero-Shot-Klassifizierers <strong>ist rein semantisch</strong> - er identifiziert, ob ein Textstück als Aussage oder als Meinung/Interpretation geschrieben ist. Zum Beispiel ist <code>\"The Soviet Union launched Sputnik 1 on October 4, 1959\"</code> als Aussage geschrieben, während <code>\"The Space Race was a breathtaking testament\"</code> eindeutig als Meinung geschrieben ist.</p><pre><code class=\"language-python\">headers = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {API_KEY}'\n}\n\n# Step 1: Split text and classify\nchunks = [chunk.strip() for chunk in text.split('.') if chunk.strip()]\nlabels = [\n    \"subjective, opinion, feeling, personal experience, creative writing, position\",\n    \"fact\"\n]\n\n# Classify chunks\nclassify_response = requests.post(\n    'https://api.jina.ai/v1/classify',\n    headers=headers,\n    json={\n        \"model\": \"jina-embeddings-v3\",\n        \"input\": [{\"text\": chunk} for chunk in chunks],\n        \"labels\": labels\n    }\n)\n\n# Sort chunks\nsubjective_chunks = []\nfactual_chunks = []\nfor chunk, classification in zip(chunks, classify_response.json()['data']):\n    if classification['prediction'] == labels[0]:\n        subjective_chunks.append(chunk)\n    else:\n        factual_chunks.append(chunk)\n\nprint(\"\\nSubjective statements:\", subjective_chunks)\nprint(\"\\nFactual statements:\", factual_chunks)</code></pre><p>Und Sie erhalten:</p><pre><code class=\"language-json\">Subjective statements: ['The Space Race of the 1960s was a breathtaking testament to human ingenuity', 'The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance', 'While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent', \"The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination\"]\n\nFactual statements: ['When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era', \"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\", \"On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars\", 'The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle']</code></pre><p>Denken Sie daran, nur weil etwas als Aussage geschrieben ist, bedeutet das nicht, dass es wahr ist. Deshalb benötigen wir den zweiten Schritt - diese aussageähnlichen Behauptungen in eine Grounding API einzuspeisen, um die tatsächlichen Fakten zu überprüfen. Überprüfen wir zum Beispiel diese Aussage: <code>\"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\"</code> mit dem Code unten.</p><pre><code class=\"language-python\">ground_headers = {\n        'Accept': 'application/json',\n        'Authorization': f'Bearer {API_KEY}'\n    }\n\nground_response = requests.get(\n    f'https://g.jina.ai/{quote(factual_chunks[1])}',\n    headers=ground_headers\n)\n\nprint(ground_response.json())</code></pre><p>was Ihnen Folgendes liefert:</p><pre><code class=\"language-json\">{'code': 200, 'status': 20000, 'data': {'factuality': 1, 'result': True, 'reason': \"The statement is supported by multiple references confirming NASA's founding in 1958 and the significant financial investment in the Apollo program. The $28 billion figure aligns with the data provided in the references, which detail NASA's expenditures during the Apollo program from 1960 to 1973. Additionally, the context of NASA's budget peaking during this period further substantiates the claim. Therefore, the statement is factually correct based on the available evidence.\", 'references': [{'url': 'https://en.wikipedia.org/wiki/Budget_of_NASA', 'keyQuote': \"NASA's budget peaked in 1964–66 when it consumed roughly 4% of all federal spending. The agency was building up to the first Moon landing and the Apollo program was a top national priority, consuming more than half of NASA's budget.\", 'isSupportive': True}, {'url': 'https://en.wikipedia.org/wiki/NASA', 'keyQuote': 'Established in 1958, it succeeded the National Advisory Committee for Aeronautics (NACA)', 'isSupportive': True}, {'url': 'https://nssdc.gsfc.nasa.gov/planetary/lunar/apollo.html', 'keyQuote': 'More details on Apollo lunar landings', 'isSupportive': True}, {'url': 'https://usafacts.org/articles/50-years-after-apollo-11-moon-landing-heres-look-nasas-budget-throughout-its-history/', 'keyQuote': 'NASA has spent its money so far.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/history/', 'keyQuote': 'Discover the history of our human spaceflight, science, technology, and aeronautics programs.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/the-apollo-program/', 'keyQuote': 'Commander for Apollo 11, first to step on the lunar surface.', 'isSupportive': True}, {'url': 'https://www.planetary.org/space-policy/cost-of-apollo', 'keyQuote': 'A rich data set tracking the costs of Project Apollo, free for public use. Includes unprecedented program-by-program cost breakdowns.', 'isSupportive': True}, {'url': 'https://www.statista.com/statistics/1342862/nasa-budget-project-apollo-costs/', 'keyQuote': 'NASA&amp;#x27;s monetary obligations compared to Project Apollo&amp;#x27;s total costs from 1960 to 1973 (in million U.S. dollars)', 'isSupportive': True}], 'usage': {'tokens': 10640}}}</code></pre><p>Mit einem Faktualitätswert von 1 bestätigt die Grounding API, dass diese Aussage in historischen Fakten gut begründet ist. Dieser Ansatz eröffnet faszinierende Möglichkeiten, von der Analyse historischer Dokumente bis hin zur Echtzeitüberprüfung von Nachrichtenartikeln. Durch die Kombination von Zero-Shot-Klassifizierung mit Faktenüberprüfung schaffen wir eine leistungsfähige Pipeline für die automatisierte Informationsanalyse - zunächst werden Meinungen herausgefiltert, dann werden die verbleibenden Aussagen anhand vertrauenswürdiger Quellen überprüft.</p><h3 id=\"remarks-on-zero-shot-classification\">Anmerkungen zur Zero-Shot-Klassifizierung</h3><h4 id=\"using-semantic-labels\">Verwendung semantischer Labels</h4><p>Bei der Arbeit mit Zero-Shot-Klassifizierung <strong>ist es entscheidend, semantisch aussagekräftige Labels anstelle von abstrakten Symbolen oder Zahlen zu verwenden.</strong> Zum Beispiel sind <code>\"Technology\"</code>, <code>\"Nature\"</code> und <code>\"Food\"</code> weitaus effektiver als <code>\"Class1\"</code>, <code>\"Class2\"</code>, <code>\"Class3\"</code> oder <code>\"0\"</code>, <code>\"1\"</code>, <code>\"2\"</code>. <code>\"Positive sentiment\"</code> ist effektiver als <code>\"Positive\"</code> und <code>\"True\"</code>. Embedding-Modelle verstehen semantische Beziehungen, daher ermöglichen beschreibende Labels dem Modell, sein vortrainiertes Wissen für genauere Klassifizierungen zu nutzen. Unser vorheriger Beitrag untersucht, wie man effektive semantische Labels für bessere Klassifizierungsergebnisse erstellt.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/rephrased-labels-improve-zero-shot-text-classification-30?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Rephrased Labels Improve Zero-Shot Text Classification by 30%</div><div class=\"kg-bookmark-description\">When using embedding models for zero-shot classification, rephrasing the class label to \"This is seriously about 'LABEL'\" gives higher accuracy vs. using LABEL alone. But how, and why?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/07/Heading.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"stateless-nature\">Zustandslose Natur</h4><p>Zero-Shot-Klassifizierung ist grundsätzlich zustandslos, anders als traditionelle maschinelle Lernansätze. <strong>Das bedeutet, dass bei gleicher Eingabe und gleichem Modell die Ergebnisse immer konsistent sind, unabhängig davon, wer die API nutzt oder wann.</strong> Das Modell lernt oder aktualisiert sich nicht basierend auf den Klassifizierungen, die es durchführt; jede Aufgabe ist unabhängig. Dies ermöglicht die sofortige Nutzung ohne Einrichtung oder Training und bietet die Flexibilität, Kategorien zwischen API-Aufrufen zu ändern.</p><p>Diese Zustandslosigkeit steht in starkem Kontrast zu Few-Shot- und Online-Learning-Ansätzen, die wir als nächstes untersuchen werden. Bei diesen Methoden können sich Modelle an neue Beispiele anpassen und möglicherweise im Laufe der Zeit oder zwischen Benutzern unterschiedliche Ergebnisse liefern.</p><h2 id=\"few-shot-classification\">Few-Shot-Klassifizierung</h2><p>Few-Shot-Klassifizierung bietet einen einfachen Ansatz zum Erstellen und Aktualisieren von Klassifizierern mit minimalen gelabelten Daten. Diese Methode stellt zwei primäre Endpunkte bereit: <code>train</code> und <code>classify</code>.</p><p>Der <code>train</code>-Endpunkt ermöglicht es Ihnen, einen Klassifizierer mit einer kleinen Menge von Beispielen zu erstellen oder zu aktualisieren. Ihr erster Aufruf von <code>train</code> wird eine<code>classifier_id</code>, den Sie für nachfolgende Trainings verwenden können, wenn Sie neue Daten haben, Änderungen in der Datenverteilung bemerken oder neue Klassen hinzufügen müssen. Dieser flexible Ansatz ermöglicht es Ihrem Klassifizierer, sich im Laufe der Zeit weiterzuentwickeln und sich an neue Muster und Kategorien anzupassen, ohne von vorne beginnen zu müssen.</p><p>Ähnlich wie bei der Zero-Shot-Klassifizierung verwenden Sie den <code>classify</code> Endpunkt für Vorhersagen. Der Hauptunterschied besteht darin, dass Sie Ihre <code>classifier_id</code> in der Anfrage angeben müssen, aber keine Kandidaten-Labels bereitstellen müssen, da diese bereits Teil Ihres trainierten Modells sind.</p><h3 id=\"example-train-a-support-ticket-assigner\">Beispiel: Training eines Support-Ticket-Zuweisers</h3><p>Lassen Sie uns diese Funktionen anhand eines Beispiels zur Klassifizierung von Kundenservice-Tickets für die Zuweisung an verschiedene Teams in einem schnell wachsenden Tech-Startup erkunden.</p><h4 id=\"initial-training\">Initiales Training</h4><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"model\": \"jina-embeddings-v3\",\n  \"access\": \"private\",\n  \"input\": [\n    {\n      \"text\": \"I cant log into my account after the latest app update.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"My subscription renewal failed due to an expired credit card.\",\n      \"label\": \"team2\"\n    },\n    {\n      \"text\": \"How do I export my data from the platform?\",\n      \"label\": \"team3\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><p>Beachten Sie, dass wir beim Few-Shot-Learning <code>team1</code> <code>team2</code> als Klassenbezeichnungen verwenden können, auch wenn diese keine inhärente semantische Bedeutung haben. In der Antwort erhalten Sie eine <code>classifier_id</code>, die diesen neu erstellten Klassifizierer repräsentiert.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"classifier_id\": \"918c0846-d6ae-4f34-810d-c0c7a59aee14\",\n  \"num_samples\": 3,\n}\n</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Notieren Sie sich die </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>classifier_id</span></code><span style=\"white-space: pre-wrap;\">, Sie werden sie später benötigen, um auf diesen Klassifizierer zu verweisen.</span></p></figcaption></figure><h4 id=\"updating-classifier-to-adapt-team-restructuring\">Aktualisierung des Klassifizierers zur Anpassung an Team-Umstrukturierungen</h4><p>Während das Beispielunternehmen wächst, entstehen neue Arten von Problemen und auch die Teamstruktur ändert sich. Die Schönheit der Few-Shot-Klassifizierung liegt in ihrer Fähigkeit, sich schnell an diese Änderungen anzupassen. Wir können den Klassifizierer einfach aktualisieren, indem wir <code>classifier_id</code> und neue Beispiele angeben, neue Team-Kategorien einführen (z.B. <code>team4</code>) oder bestehende Problemtypen verschiedenen Teams neu zuweisen, während sich die Organisation weiterentwickelt.</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"Im getting a 404 error when trying to access the new AI chatbot feature.\",\n      \"label\": \"team4\"\n    },\n    {\n      \"text\": \"The latest security patch is conflicting with my company firewall.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"I need help setting up SSO for my organization account.\",\n      \"label\": \"team5\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><h4 id=\"using-a-trained-classifier\">Verwendung eines trainierten Klassifizierers</h4><p>Während der Inferenz müssen Sie nur den Eingabetext und die <code>classifier_id</code> bereitstellen. Die API übernimmt die Zuordnung zwischen Ihrer Eingabe und den zuvor trainierten Klassen und gibt das am besten geeignete Label basierend auf dem aktuellen Zustand des Klassifizierers zurück.</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/classify' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"The new feature is causing my dashboard to load slowly.\"\n    },\n    {\n      \"text\": \"I need to update my billing information for tax purposes.\"\n    }\n  ]\n}'</code></pre><p>Der Few-Shot-Modus hat zwei einzigartige Parameter.</p><h3 id=\"parameter-numiters\">Parameter <code>num_iters</code></h3><p>Der Parameter <code>num_iters</code> bestimmt, wie intensiv der Klassifizierer aus Ihren Trainingsbeispielen lernt. Während der Standardwert von 10 für die meisten Fälle gut funktioniert, können Sie diesen Wert strategisch basierend auf <strong>Ihrem Vertrauen in die Trainingsdaten</strong> anpassen. Für qualitativ hochwertige Beispiele, die für die Klassifizierung wichtig sind, erhöhen Sie <code>num_iters</code>, um deren Bedeutung zu verstärken. Umgekehrt können Sie für weniger zuverlässige Beispiele <code>num_iters</code> senken, um deren Einfluss auf die Leistung des Klassifizierers zu minimieren. Dieser Parameter kann auch verwendet werden, um zeitbewusstes Lernen zu implementieren, bei dem aktuellere Beispiele höhere Iterationszahlen erhalten, um sich an sich entwickelnde Muster anzupassen, während historisches Wissen erhalten bleibt.</p><h3 id=\"parameter-access\">Parameter <code>access</code></h3><p>Mit dem Parameter <code>access</code> können Sie steuern, wer Ihren Klassifizierer verwenden kann. Standardmäßig sind Klassifizierer privat und nur für Sie zugänglich. Wenn Sie den Zugriff auf \"public\" setzen, kann jeder mit Ihrer <code>classifier_id</code> den Klassifizierer <strong>mit seinem eigenen API-Schlüssel und Token-Kontingent verwenden.</strong> Dies ermöglicht das Teilen von Klassifizierern bei gleichzeitiger Wahrung der Privatsphäre - Benutzer können Ihre Trainingsdaten oder Konfiguration nicht sehen, und Sie können deren Klassifizierungsanfragen nicht sehen. Dieser Parameter ist nur für Few-Shot-Klassifizierung relevant, da Zero-Shot-Klassifizierer zustandslos sind. Es besteht keine Notwendigkeit, Zero-Shot-Klassifizierer zu teilen, da identische Anfragen immer die gleichen Antworten liefern, unabhängig davon, wer sie stellt.</p><h3 id=\"remarks-on-few-shot-learning\">Anmerkungen zum Few-Shot-Learning</h3><p>Die Few-Shot-Klassifizierung in unserer API hat einige bemerkenswerte Eigenschaften. Im Gegensatz zu traditionellen Machine-Learning-Modellen verwendet unsere Implementierung One-Pass-Online-Learning - Trainingsbeispiele werden verarbeitet, um die Gewichte des Klassifizierers zu aktualisieren, werden aber danach nicht gespeichert. Dies bedeutet, dass Sie keine historischen Trainingsdaten abrufen können, aber es gewährleistet bessere Privatsphäre und Ressourceneffizienz.</p><p>Obwohl Few-Shot-Learning leistungsfähig ist, benötigt es eine Aufwärmphase, um die Zero-Shot-Klassifizierung zu übertreffen. Unsere Benchmarks zeigen, dass 200-400 Trainingsbeispiele typischerweise genügend Daten liefern, um eine überlegene Leistung zu sehen. Sie müssen jedoch nicht von Anfang an Beispiele für alle Klassen bereitstellen - der Klassifizierer kann mit der Zeit neue Klassen aufnehmen. Beachten Sie nur, dass neu hinzugefügte Klassen möglicherweise eine kurze Kaltstartphase oder Klassenungleichgewicht erfahren, bis ausreichend Beispiele bereitgestellt werden.</p><h2 id=\"benchmark\">Benchmark</h2><p>Für unsere Benchmark-Analyse haben wir Zero-Shot- und Few-Shot-Ansätze über verschiedene Datensätze hinweg evaluiert, einschließlich Textklassifizierungsaufgaben wie Emotionserkennung (6 Klassen) und Spam-Erkennung (2 Klassen) sowie Bildklassifizierungsaufgaben wie CIFAR10 (10 Klassen). Das Evaluierungsframework verwendete Standard-Train-Test-Splits, wobei Zero-Shot keine Trainingsdaten benötigte und Few-Shot Teile des Trainingssatzes verwendete. Wir verfolgten wichtige Metriken wie Trainingsgröße und Zielklassenanzahl, was kontrollierte Vergleiche ermöglichte. Um die Robustheit sicherzustellen, insbesondere beim Few-Shot-Learning, durchlief jede Eingabe mehrere Trainingsiterationen. Wir verglichen diese modernen Ansätze mit traditionellen Baselines wie Linear SVM und RBF SVM, um den Kontext ihrer Leistung zu verdeutlichen.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Multi-class-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Image-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Text-classification--1-.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">F1-Scores sind aufgetragen. Die vollständigen Benchmark-Einstellungen finden Sie in </span><a href=\"https://docs.google.com/spreadsheets/d/15vK6VPlcAM4e7lSJw6IeVtTtyariXEVQurDTFKXwwtY/edit?gid=249584681&ref=jina-ai-gmbh.ghost.io#gid=249584681\"><span style=\"white-space: pre-wrap;\">dieser Google-Tabelle</span></a><span style=\"white-space: pre-wrap;\">.</span></p></figcaption></figure><p>Die F1-Diagramme zeigen interessante Muster über drei Aufgaben hinweg. Erwartungsgemäß zeigt die Zero-Shot-Klassifizierung von Anfang an konstante Leistung, unabhängig von der Trainingsdatenmenge. Im Gegensatz dazu weist Few-Shot-Learning eine schnelle Lernkurve auf, beginnt zunächst niedriger, übertrifft aber schnell die Zero-Shot-Leistung mit zunehmenden Trainingsdaten. Beide Methoden <strong>erreichen letztendlich eine vergleichbare Genauigkeit bei etwa 400 Proben</strong>, wobei Few-Shot einen leichten Vorsprung behält. Dieses Muster gilt sowohl für Mehrklassen- als auch für Bildklassifizierungsszenarien, was darauf hindeutet, dass Few-Shot-Learning besonders vorteilhaft sein kann, wenn Trainingsdaten verfügbar sind, während Zero-Shot auch ohne Trainingsbeispiele zuverlässige Leistung bietet. Die folgende Tabelle fasst die Unterschiede zwischen Zero-Shot- und Few-Shot-Klassifizierung aus Sicht des API-Benutzers zusammen.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Zero-shot</th>\n<th>Few-shot</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Primary Use Case</td>\n<td>Default solution for general classification</td>\n<td>For data outside v3/clip-v1's domain or time-sensitive data</td>\n</tr>\n<tr>\n<td>Training Data Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /train</td>\n<td>N/A</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /classify</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Classifier ID Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Semantic Labels Required</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>State Management</td>\n<td>Stateless</td>\n<td>Stateful</td>\n</tr>\n<tr>\n<td>Continuous Model Updates</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Access Control</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Maximum Classes</td>\n<td>256</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Classifiers</td>\n<td>N/A</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Inputs per Request</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Maximum Token Length per Input</td>\n<td>8,192 tokens</td>\n<td>8,192 tokens</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"summary\">Zusammenfassung</h2><p>Die Classifier API bietet leistungsstarke Zero-Shot- und Few-Shot-Klassifizierung sowohl für Text- als auch für Bildinhalte, angetrieben von fortschrittlichen Embedding-Modellen wie <code>jina-embeddings-v3</code> und <code>jina-clip-v1</code>. Unsere Benchmarks zeigen, dass die Zero-Shot-Klassifizierung zuverlässige Leistung ohne Trainingsdaten bietet und damit ein ausgezeichneter Ausgangspunkt für die meisten Aufgaben mit Unterstützung für bis zu 256 Klassen ist. Während Few-Shot-Learning mit Trainingsdaten eine etwas bessere Genauigkeit erreichen kann, empfehlen wir, mit Zero-Shot-Klassifizierung zu beginnen, da sie sofortige Ergebnisse und Flexibilität bietet.</p><p>Die Vielseitigkeit der API unterstützt verschiedene Anwendungen, vom Routing von LLM-Anfragen bis zur Erkennung von Website-Zugänglichkeit und Kategorisierung mehrsprachiger Inhalte. Ob Sie mit Zero-Shot beginnen oder für spezielle Fälle zu Few-Shot-Learning übergehen, die API behält eine konsistente Schnittstelle für die nahtlose Integration in Ihre Pipeline bei. Wir sind besonders gespannt darauf zu sehen, wie Entwickler diese API in ihren Anwendungen einsetzen werden, und wir werden in Zukunft Unterstützung für neue Embedding-Modelle wie <code>jina-clip-v2</code> einführen.</p>",
  "comment_id": "6711fbbd708dbe0001924974",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/classifier-header-1.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-10-18T08:10:05.000+02:00",
  "updated_at": "2024-10-24T11:04:33.000+02:00",
  "published_at": "2024-10-22T10:57:15.000+02:00",
  "custom_excerpt": "New Classifier API offers zero-shot and few-shot classification for text and images. Start classifying content instantly or train it with your own examples.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-classifier-for-high-performance-zero-shot-and-few-shot-classification/",
  "excerpt": "Die neue Classifier API ermöglicht Zero-Shot- und Few-Shot-Klassifizierung für Text und Bilder. Beginnen Sie sofort mit der Klassifizierung von Inhalten oder trainieren Sie die API mit Ihren eigenen Beispielen.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract artistic portrait using a montage of colorful squares and scattered text.",
  "feature_image_caption": null
}