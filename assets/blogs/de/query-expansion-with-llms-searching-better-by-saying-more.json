{
  "slug": "query-expansion-with-llms-searching-better-by-saying-more",
  "id": "67af53142962d20001d63c71",
  "uuid": "581110d6-5791-42f7-b754-16d597390ff7",
  "title": "Query-Expansion mit LLMs: Bessere Suchergebnisse durch ausführlichere Anfragen",
  "html": "<p>Die Query-Expansion war lange Zeit eine bewährte Technik zur Verbesserung von Suchsystemen, trat aber in den Hintergrund, als semantische Embeddings auf den Plan traten. Auch wenn einige sie im aktuellen Umfeld von RAG und Agent-basierter Suche für überholt halten könnten, sollte man sie nicht vorschnell abschreiben. In dieser ausführlichen Analyse untersuchen wir, wie die Kombination von automatischer Query-Expansion mit <code>jina-embeddings-v3</code> und LLMs Ihre Suche verbessern und zielgenauere Ergebnisse liefern kann.</p><h2 id=\"what-is-query-expansion\">Was ist Query-Expansion?</h2><p>Query-Expansion wurde für Suchsysteme entwickelt, die Relevanz durch den Abgleich von Wörtern aus Anfragen mit Dokumenten ermitteln, die diese enthalten, wie <a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\">tf-idf</a> oder andere \"Sparse Vector\"-Verfahren. Das hat einige offensichtliche Einschränkungen. Unterschiedliche Wortformen beeinträchtigen den Abgleich, wie \"lief\" und \"laufen\" oder \"optimieren\" vs. \"optimiert\". Sprachbewusste Vorverarbeitung kann einige dieser Probleme mildern, aber nicht alle. Fachbegriffe, Synonyme und verwandte Wörter sind viel schwieriger zu behandeln. Eine Suche nach medizinischer Forschung über \"Coronavirus\" identifiziert zum Beispiel nicht automatisch Dokumente, die über \"COVID\" oder \"SARS-CoV-2\" sprechen, obwohl dies sehr gute Treffer wären.</p><p>Query-Expansion wurde als Lösung erfunden.</p><p>Die Idee ist, zusätzliche Wörter und Phrasen zu Anfragen hinzuzufügen, um die Wahrscheinlichkeit zu erhöhen, gute Treffer zu identifizieren. So könnte eine Anfrage nach \"Coronavirus\" um die Begriffe \"COVID\" und \"SARS-CoV-2\" erweitert werden. Dies kann die Suchleistung dramatisch verbessern.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"700\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/QueryExpansion1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/QueryExpansion1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/QueryExpansion1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion1.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Abbildung 1: Query-Expansion Flussdiagramm mit Thesaurus</span></figcaption></figure><p>Es ist nicht einfach zu entscheiden, welche Begriffe zu einer Anfrage hinzugefügt werden sollen, und es gab viel Arbeit daran, wie man gute Begriffe identifiziert und wie man sie für tf-idf-artige Abrufe gewichtet. Übliche Ansätze umfassen:</p><ul><li>Verwendung eines manuell gepflegten Thesaurus.</li><li>Data-Mining großer Textkorpora für verwandte Wörter.</li><li>Identifizierung anderer Begriffe aus ähnlichen Anfragen in Query-Logs.</li><li>Lernen, welche Wörter und Phrasen sich gut für Query-Expansion eignen <a href=\"https://en.wikipedia.org/wiki/Rocchio_algorithm\">durch Nutzer-Feedback</a>.</li></ul><p>Semantische Embedding-Modelle sollen jedoch die Notwendigkeit für Query-Expansion eliminieren. Gute Text-Embeddings für \"Coronavirus\", \"COVID\" und \"SARS-CoV-2\" sollten im Embedding-Vektorraum sehr nahe beieinander liegen. Sie sollten natürlich ohne Erweiterung übereinstimmen.</p><p>Während dies theoretisch zutreffen sollte, bleiben reale Embeddings von realen Modellen oft hinter den Erwartungen zurück. Wörter in Embeddings können mehrdeutig sein, und das Hinzufügen von Wörtern zu einer Anfrage kann sie zu besseren Treffern führen, wenn man die richtigen Wörter verwendet. Ein Embedding für \"Hautausschlag\" könnte zum Beispiel Dokumente über \"vorschnelles Handeln\" und \"Hautcreme\" identifizieren, während ein medizinischer Fachartikel über \"Dermatitis\" übersehen wird. Das Hinzufügen relevanter Begriffe wird das Embedding wahrscheinlich von unverwandten Treffern weg zu besseren hinführen.</p><h2 id=\"llm-query-expansion\">LLM Query-Expansion</h2><p>Anstatt einen Thesaurus zu verwenden oder lexikalisches Data-Mining zu betreiben, haben wir untersucht, wie ein LLM für Query-Expansion eingesetzt werden kann. LLMs haben einige wichtige potenzielle Vorteile:</p><ul><li><strong>Breites lexikalisches Wissen</strong>: Da sie auf großen, vielfältigen Datensätzen trainiert wurden, gibt es weniger Bedenken hinsichtlich der Auswahl eines geeigneten Thesaurus oder der richtigen Daten.</li><li><strong>Urteilsvermögen</strong>: Nicht alle vorgeschlagenen Erweiterungsbegriffe sind notwendigerweise für eine spezifische Anfrage geeignet. LLMs treffen vielleicht keine perfekten Urteile über die Themenzugehörigkeit, aber die Alternativen können überhaupt keine Urteile fällen.</li><li><strong>Flexibilität</strong>: Sie können Ihren Prompt an die Anforderungen der Abrufaufgabe anpassen, während andere Ansätze starr sind und viel Arbeit erfordern können, um sie an neue Domänen oder Datenquellen anzupassen.</li></ul><p>Sobald das LLM eine Liste von Begriffen vorgeschlagen hat, funktioniert die Query-Expansion für Embeddings genauso wie traditionelle Query-Expansion-Schemata: Wir fügen Begriffe zum Anfragetext hinzu und verwenden dann ein Embedding-Modell, um einen Query-Embedding-Vektor zu erstellen.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"850\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/QueryExpansion2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/QueryExpansion2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/QueryExpansion2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/02/QueryExpansion2.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Abbildung 2: Query-Expansion von Embeddings mit einem LLM</span></figcaption></figure><p>Um dies umzusetzen, benötigen Sie:</p><ul><li>Zugang zu einem LLM.</li><li>Eine Prompt-Vorlage, um Erweiterungsbegriffe vom LLM anzufordern.</li><li>Ein Text-Embedding-Modell.</li></ul><h2 id=\"trying-it-out\">Praktische Erprobung</h2><p>Wir haben einige Experimente durchgeführt, um zu sehen, ob dieser Ansatz einen Mehrwert für die Textinformationssuche bietet. Unsere Tests verwendeten:</p><ul><li>Ein LLM: <a href=\"https://deepmind.google/technologies/gemini/flash/\">Gemini 2.0 Flash</a> von Google.</li><li>Zwei Embedding-Modelle, um zu sehen, ob LLM Query-Expansion über Modelle hinweg generalisiert: <code>jina-embeddings-v3</code> und <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\"><code>all-MiniLM-L6-v2</code></a>.</li><li>Eine Teilmenge der <a href=\"https://github.com/beir-cellar/beir\">BEIR Benchmarks</a> für Information Retrieval.</li></ul><p>Wir führten unsere Experimente unter zwei Prompt-Bedingungen durch:</p><ul><li>Verwendung einer allgemeinen Prompt-Vorlage zur Anforderung von Erweiterungsbegriffen.</li><li>Verwendung aufgabenspezifischer Prompt-Vorlagen.</li></ul><p>Schließlich formulierten wir unsere Prompts so, dass sie unterschiedliche Anzahlen von hinzuzufügenden Begriffen anforderten: 100, 150 und 250.</p><p>Unser Code und die Ergebnisse sind <a href=\"https://github.com/jina-ai/llm-query-expansion/\">auf GitHub</a> zur Reproduktion verfügbar.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/llm-query-expansion/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/llm-query-expansion: Query Expension for Better Query Embedding using LLMs</div><div class=\"kg-bookmark-description\">Query Expension for Better Query Embedding using LLMs - jina-ai/llm-query-expansion</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-1.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/llm-query-expansion\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"results\">Ergebnisse</h2><h3 id=\"using-a-general-prompt\">Verwendung eines allgemeinen Prompts</h3><p>Nach einigem Experimentieren stellten wir fest, dass der folgende Prompt mit Gemini 2.0 Flash gut genug funktionierte:</p>\n<!--kg-card-begin: html-->\n<pre>\nPlease provide additional search keywords and phrases for \neach of the key aspects of the following queries that make \nit easier to find the relevant documents (about <span style=\"color:#AADB1E\">{size}</span> words \nper query):\n<span style=\"color:#AADB1E\">{query}</span>\n\nPlease respond in the following JSON schema:\nExpansion = {\"qid\": str, \"additional_info\": str}\nReturn: list [Expansion]\n</pre>\n<!--kg-card-end: html-->\n<p>Dieser Prompt ermöglicht es uns, unsere Anfragen in Bündeln von 20-50 zu verarbeiten, jeder eine ID zuzuweisen und einen JSON-String zurückzuerhalten, der jede Anfrage mit einer Liste von Erweiterungsbegriffen verbindet. Wenn Sie ein anderes LLM verwenden, müssen Sie möglicherweise experimentieren, um einen Prompt zu finden, der dafür funktioniert.</p><p>Wir wendeten dieses Setup mit <code>jina-embeddings-v3</code> unter Verwendung des <a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\">asymmetrischen Retrieval-Adapters</a> an. Bei diesem Ansatz werden Anfragen und Dokumente unterschiedlich kodiert - unter Verwendung desselben Modells, aber verschiedener LoRA-Erweiterungen - um die resultierenden Embeddings für Information Retrieval zu optimieren.</p><p>Unsere Ergebnisse für verschiedene BEIR-Benchmarks sind in der folgenden Tabelle aufgeführt. Die Scores sind nDCG@10 (<a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain\">normalisierter Discounted Cumulative Gain</a> für die zehn besten abgerufenen Elemente).</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Keine Expansion</th>\n<th>100 Begriffe</th>\n<th>150 Begriffe</th>\n<th>250 Begriffe</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>SciFact</strong><br/>(Faktencheckaufgabe)</td>\n<td>72,74</td>\n<td>73,39</td>\n<td>74,16</td>\n<td><strong>74,33</strong></td>\n</tr>\n<tr>\n<td><strong>TRECCOVID</strong><br/>(Medizinische Suchaufgabe)</td>\n<td>77,55</td>\n<td>76,74</td>\n<td>77,12</td>\n<td><strong>79,28</strong></td>\n</tr>\n<tr>\n<td><strong>FiQA</strong><br/>(Finanzoptionen-Suche)</td>\n<td>47,34</td>\n<td><strong>47,76</strong></td>\n<td>46,03</td>\n<td>47,34</td>\n</tr>\n<tr>\n<td><strong>NFCorpus</strong><br/>(Medizinische Informationssuche)</td>\n<td>36,46</td>\n<td><strong>40,62</strong></td>\n<td>39,63</td>\n<td>39,20</td>\n</tr>\n<tr>\n<td><strong>Touche2020</strong><br/>(Argumentationssuche)</td>\n<td>26,24</td>\n<td>26,91</td>\n<td>27,15</td>\n<td><strong>27,54</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><p>Wir sehen hier, dass die Query-Expansion in fast allen Fällen zu einer verbesserten Abrufleistung geführt hat.</p><p>Um die Robustheit dieses Ansatzes zu testen, wiederholten wir dieselben Tests mit <code>all-MiniLM-L6-v2</code>, einem deutlich kleineren Modell, das kleinere Embedding-Vektoren erzeugt.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">sentence-transformers/all-MiniLM-L6-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-29.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/all-MiniLM-L6-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Die Ergebnisse sind in der folgenden Tabelle dargestellt:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>No Expansion</th>\n<th>100 terms</th>\n<th>150 terms</th>\n<th>250 terms</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>SciFact</strong><br/>(Fact Checking Task)</td>\n<td>64.51</td>\n<td><strong>68.72</strong></td>\n<td>66.27</td>\n<td>68.50</td>\n</tr>\n<tr>\n<td><strong>TRECCOVID</strong><br/>(Medical Retrieval Task)</td>\n<td>47.25</td>\n<td>67.90</td>\n<td><strong>70.18</strong></td>\n<td>69.60</td>\n</tr>\n<tr>\n<td><strong>FiQA</strong><br/>(Financial Option Retrieval)</td>\n<td><strong>36.87</strong></td>\n<td>33.96</td>\n<td>32.60</td>\n<td>31.84</td>\n</tr>\n<tr>\n<td><strong>NFCorpus</strong><br/>(Medical Information Retrieval)</td>\n<td>31.59</td>\n<td><strong>33.76</strong></td>\n<td>33.76</td>\n<td>33.35</td>\n</tr>\n<tr>\n<td><strong>Touche2020</strong><br/>(Argument Retrieval Task)</td>\n<td>16.90</td>\n<td><strong>25.31</strong></td>\n<td>23.52</td>\n<td>23.23</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Hier sehen wir eine noch größere Verbesserung der Retrieval-Scores. Insgesamt profitierte das kleinere Modell mehr von der Query-Expansion. Die durchschnittliche Verbesserung über alle Aufgaben ist in der folgenden Tabelle zusammengefasst:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>100 terms</th>\n<th>150 terms</th>\n<th>250 terms</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>jina-embeddings-v3</code></td>\n<td>+1.02</td>\n<td>+0.75</td>\n<td><strong>+1.48</strong></td>\n</tr>\n<tr>\n<td><code>all-MiniLM-L6-v2</code></td>\n<td><strong>+6.51</strong></td>\n<td>+5.84</td>\n<td>+5.88</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Der große Unterschied in der Netto-Verbesserung zwischen den beiden Modellen liegt wahrscheinlich daran, dass <code>all-MiniLM-L6-v2</code> von einem niedrigeren Leistungsniveau startet. Die von <code>jina-embeddings-v3</code> im asymmetrischen Retrieval-Modus erzeugten Query-Embeddings sind besser in der Lage, wichtige semantische Beziehungen zu erfassen, wodurch weniger Raum für Query-Expansion bleibt, um Informationen hinzuzufügen. Aber dieses Ergebnis zeigt, wie sehr Query-Expansion die Leistung kompakterer Modelle verbessern kann, die in manchen Anwendungsfällen großen Modellen vorzuziehen sind.</p><p>Dennoch brachte Query-Expansion auch bei leistungsstarken Modellen wie <code>jina-embeddings-v3</code> eine bedeutende Verbesserung beim Retrieval, wobei dieses Ergebnis nicht bei allen Aufgaben und Bedingungen völlig konsistent ist.</p><p>Für <code>jina-embeddings-v3</code> war das Hinzufügen von mehr als 100 Begriffen zu einer Query bei den FiQA- und NFCorpus-Benchmarks kontraproduktiv. Wir können nicht sagen, dass mehr Begriffe immer besser sind, aber die Ergebnisse der anderen Benchmarks zeigen, dass mehr Begriffe zumindest manchmal besser sind.</p><p>Für <code>all-MiniLM-L6-v2</code> war das Hinzufügen von mehr als 150 Begriffen immer kontraproduktiv, und bei drei Tests brachte das Hinzufügen von mehr als 100 keine Verbesserung der Scores. Bei einem Test (FiQA) führte das Hinzufügen von selbst 100 Begriffen zu deutlich schlechteren Ergebnissen. Wir glauben, dass dies daran liegt, dass <code>jina-embeddings-v3</code> semantische Informationen in langen Query-Texten besser erfasst.</p><p>Beide Modelle zeigten bei den FiQA- und NFCorpus-Benchmarks weniger Reaktion auf Query-Expansion.</p><h2 id=\"using-task-specific-prompting\">Verwendung aufgabenspezifischer Prompts</h2><p>Das oben beschriebene Ergebnismuster legt nahe, dass Query-Expansion zwar hilfreich ist, aber die Verwendung von LLMs riskiert, unbrauchbare Query-Begriffe hinzuzufügen, die die Leistung reduzieren. Dies könnte durch die generische Natur des Prompts verursacht sein.</p><p>Wir nahmen zwei Benchmarks — SciFact und FiQA — und erstellten domänenspezifischere Prompts, wie den folgenden:</p>\n<!--kg-card-begin: html-->\n<pre>\nPlease provide additional search keywords and phrases for \neach of the key aspects of the following queries that make\nit easier to find the <span style=\"background-color:red\">relevant documents</span> <span style=\"background-color:green\">scientific document \nthat supports or rejects the scientific fact in the query \nfield</span> (about <span style=\"color:#AADB1E\">{size}</span> words per query):\n<span style=\"color:#AADB1E\">{query}</span>\nPlease respond in the following JSON schema:\nExpansion = {\"qid\": str, \"additional_info\": str}\nReturn: list [Expansion]\n</pre>\n<!--kg-card-end: html-->\n<p>Dieser Ansatz verbesserte die Retrieval-Leistung fast durchgehend:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>No Expansion</th>\n<th>100<br/>terms</th>\n<th>150<br/>terms</th>\n<th>250<br/>terms</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>SciFact</td>\n<td><code>jina-embeddings-v3</code></td>\n<td>72.74</td>\n<td><strong>75.85 (+2.46)</strong></td>\n<td>75.07 (+0.91)</td>\n<td>75.13 (+0.80)</td>\n</tr>\n<tr>\n<td>SciFact</td>\n<td><code>all-MiniLM-L6-v2</code></td>\n<td>64.51</td>\n<td><strong>69.12 (+0.40)</strong></td>\n<td>68.10 (+1.83)</td>\n<td>67.83 (-0.67)</td>\n</tr>\n<tr>\n<td>FiQA</td>\n<td><code>jina-embeddings-v3</code></td>\n<td>47.34</td>\n<td>47.77 (+0.01)</td>\n<td><strong>48.20 (+1.99)</strong></td>\n<td>47.75 (+0.41)</td>\n</tr>\n<tr>\n<td>FiQA</td>\n<td><code>all-MiniLM-L6-v2</code></td>\n<td><strong>36.87</strong></td>\n<td>34.71 (+0.75)</td>\n<td>34.68 (+2.08)</td>\n<td>34.50 (+2.66)</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Die Scores verbesserten sich unter allen Bedingungen, außer beim Hinzufügen von 250 Begriffen zu SciFact-Queries mit <code>all-MiniLM-L6-v2</code>. Darüber hinaus reichte diese Verbesserung nicht aus, damit <code>all-MiniLM-L6-v2</code> seine eigene Baseline bei FiQA übertraf.</p><p>Bei <code>jina-embeddings-v3</code> sehen wir, dass die besten Ergebnisse mit 100 oder 150 hinzugefügten Begriffen erzielt wurden. Das Hinzufügen von 250 Begriffen war kontraproduktiv. Dies unterstützt unsere Intuition, dass man zu viele Begriffe zu einer Query hinzufügen kann, besonders wenn deren Bedeutung vom Ziel abzudriften beginnt.</p><h2 id=\"key-considerations-in-query-expansion\">Wichtige Überlegungen zur Query-Expansion</h2><p>Query-Expansion kann eindeutig Verbesserungen für das Embedding-basierte Suchen bringen, kommt aber mit einigen Einschränkungen:</p><h3 id=\"expense\">Kosten</h3><p>Die Interaktion mit einem LLM fügt dem Information Retrieval Latenz und Rechenkosten hinzu und kann bei Verwendung eines kommerziellen LLM tatsächliche Kosten verursachen. Die moderate Verbesserung rechtfertigt möglicherweise nicht die Kosten.</p><h3 id=\"prompt-engineering\">Prompt Engineering</h3><p>Das Entwerfen guter Prompt-Templates ist eine empirische und experimentelle Kunst. Wir machen keine Aussage darüber, dass die von uns für diese Arbeit verwendeten optimal oder auf andere LLMs übertragbar sind. Unsere Experimente mit aufgabenspezifischen Prompts zeigen, dass die Änderung der Prompts sehr signifikante Auswirkungen auf die Qualität des Ergebnisses haben kann. Die Ergebnisse variieren auch erheblich zwischen den Domänen.</p><p>Diese Unsicherheiten erhöhen die Entwicklungskosten und untergraben die Wartbarkeit. Jede Änderung am System — Wechsel von LLMs, Embedding-Modellen oder Informationsdomäne — bedeutet eine Überprüfung und möglicherweise Neuimplementierung des gesamten Prozesses.</p><h3 id=\"alternatives\">Alternativen</h3><p>Wir sehen hier, dass Query-Expansion die größte Verbesserung bei dem Embedding-Modell mit der schwächsten Ausgangsleistung brachte. Query-Expansion war, zumindest in diesem Experiment, nicht in der Lage, die Leistungslücke zwischen <code>all-MiniLM-L6-v2</code> und <code>jina-embeddings-v3</code> zu schließen, während <code>jina-embeddings-v3</code> bescheidenere Verbesserungen durch Query-Expansion sah.</p><p>Unter diesen Umständen würde ein Benutzer von <code>all-MiniLM-L6-v2</code> bessere Ergebnisse zu geringeren Kosten erzielen, indem er <code>jina-embeddings-v3</code> einsetzt, anstatt Query-Expansion zu verfolgen.</p><h2 id=\"future-directions\">Zukünftige Richtungen</h2><p>Wir haben hier gezeigt, dass Query-Expansion Query-Embeddings verbessern kann und dass LLMs eine einfache und flexible Möglichkeit bieten, gute Query-Expansion-Begriffe zu erhalten. Aber die relativ bescheidenen Gewinne deuten auf weiteren Forschungsbedarf hin. Wir untersuchen eine Reihe von Richtungen für zukünftige Forschung:</p><ul><li>Testen des Wertes der terminologischen Erweiterung bei der Generierung von Dokument-Embeddings.</li><li>Untersuchung der Möglichkeiten für Query-Erweiterung in anderen KI-Suchtechniken wie Reranking.</li><li>Vergleich der LLM-basierten Query-Expansion mit älteren und rechnerisch weniger aufwändigen Quellen für Begriffe, wie einem Thesaurus.</li><li>Training von Sprachmodellen speziell für bessere Query-Expansion und Bereitstellung domänenspezifischeren Trainings.</li><li>Begrenzung der Anzahl der hinzugefügten Begriffe. 100 könnten zum Start zu viele sein.</li><li>Finden von Wegen zur Identifizierung hilfreicher und unhilfreicher Expansions-Begriffe. Jede feste Anzahl, die wir der Query-Expansion auferlegen, wird nicht perfekt passen, und wenn wir vorgeschlagene Begriffe dynamisch bewerten und nur die guten behalten könnten, würde das Ergebnis wahrscheinlich zu einer Leistungssteigerung führen.</li></ul><p>Dies ist eine sehr vorläufige Forschung, und wir sind optimistisch, dass Techniken wie diese weitere Verbesserungen für Jina AIs Search-Foundation-Produkte bringen werden.</p>",
  "comment_id": "67af53142962d20001d63c71",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/query-banner.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-02-14T15:28:36.000+01:00",
  "updated_at": "2025-02-18T03:24:20.000+01:00",
  "published_at": "2025-02-18T03:24:20.000+01:00",
  "custom_excerpt": "Search has changed a lot since embedding models were introduced. Is there still a role for lexical techniques like query expansion in AI? We think so.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "636409b554b68a003dfbdef8",
    "name": "Michael Günther",
    "slug": "michael",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
    "cover_image": null,
    "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
    "website": "https://github.com/guenthermi",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/query-expansion-with-llms-searching-better-by-saying-more/",
  "excerpt": "Die Suche hat sich seit der Einführung von Embedding-Modellen stark verändert. Gibt es in der KI noch eine Rolle für lexikalische Techniken wie Query Expansion? Wir denken schon.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}