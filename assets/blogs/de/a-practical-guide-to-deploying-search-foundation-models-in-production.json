{
  "slug": "a-practical-guide-to-deploying-search-foundation-models-in-production",
  "id": "679b56ba42b46600019a86e3",
  "uuid": "458c0de5-aedb-4513-8ffd-47c027d204ad",
  "title": "Ein praktischer Leitfaden zum Deployment von Search Foundation Models in der Produktion",
  "html": "<p>Bei Jina AI ist es unsere Mission, Unternehmensanwendern hochwertige Suchl√∂sungen bereitzustellen. Um dies zu erreichen, machen wir unsere Modelle √ºber verschiedene Kan√§le zug√§nglich. Die Wahl des richtigen Kanals f√ºr Ihren spezifischen Anwendungsfall kann jedoch knifflig sein. In diesem Beitrag f√ºhren wir Sie durch den Entscheidungsprozess, erl√§utern die Vor- und Nachteile und geben Ihnen praktische Hinweise, wie Sie basierend auf Ihrem Nutzerprofil und Ihren Anforderungen am besten auf unsere Search Foundation Models zugreifen k√∂nnen.</p><h2 id=\"jina-search-foundation-models\">Jina Search Foundation Models</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Our Search Foundation Models</div><div class=\"kg-bookmark-description\">We've been moving the needle in search models since day one. Take a look at our model evolution below‚Äîhover or click to discover each milestone.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-18.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Jina AI</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-models.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Unsere Search Foundation Models umfassen:</p><ul><li><strong>Embeddings</strong>: Diese wandeln Informationen √ºber digitale Objekte in Embedding-Vektoren um und erfassen dabei deren wesentliche Eigenschaften.</li><li><strong>Rerankers</strong>: Diese f√ºhren eine eingehende semantische Analyse von Query-Dokument-Sets durch, um die Suchrelevanz zu verbessern.</li><li><strong>Small Language Models</strong>: Diese umfassen spezialisierte SLM wie <code>ReaderLM-v2</code> f√ºr Nischenaufgaben wie HTML2Markdown oder Informationsextraktion.</li></ul><p>In diesem Beitrag untersuchen wir verschiedene Bereitstellungsoptionen f√ºr <code>jina-embeddings-v3</code> und vergleichen drei zentrale Ans√§tze:</p><ul><li>Nutzung der <a href=\"https://jina.ai/api-dashboard\" rel=\"noreferrer\">Jina API</a></li><li>Bereitstellung √ºber CSP wie <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS SageMaker</a></li><li>Self-Hosting auf einem Kubernetes-Cluster <a href=\"https://jina.ai/api-dashboard/license-config\">unter einer kommerziellen Lizenz</a></li></ul><p>Der Vergleich wird die Kostenauswirkungen und Vorteile jedes Ansatzes bewerten, um Ihnen bei der Bestimmung der f√ºr Sie am besten geeigneten Option zu helfen.</p><h2 id=\"key-performance-metrics\">Wichtige Leistungsmetriken</h2><p>Wir haben f√ºnf wichtige Leistungsmetriken in verschiedenen Nutzungsszenarien ausgewertet:</p><ul><li><strong>Request Success Rate</strong>: Der Prozentsatz erfolgreicher Anfragen an den Embedding-Server</li><li><strong>Request Latency</strong>: Die Zeit, die der Embedding-Server f√ºr die Verarbeitung und R√ºckgabe einer Anfrage ben√∂tigt</li><li><strong>Token Throughput</strong>: Die Anzahl der Token, die der Embedding-Server pro Sekunde verarbeiten kann</li><li><strong>Cost per Token</strong>: Die gesamten Verarbeitungskosten pro Texteinheit</li></ul><p>F√ºr selbst gehostete Jina Embeddings auf Kubernetes-Clustern haben wir auch die Auswirkungen von <em>Dynamic Batching</em> untersucht. Diese Funktion reiht Anfragen in eine Warteschlange ein, bis die maximale Batch-Gr√∂√üe (8.192 f√ºr <code>jina-embeddings-v3</code>) erreicht ist, bevor Embeddings generiert werden.</p><p>Wir haben bewusst zwei wichtige Leistungsfaktoren von unserer Analyse ausgeschlossen:</p><ul><li><em>Auto-scaling</em>: W√§hrend dies f√ºr Cloud-Bereitstellungen mit variablen Workloads entscheidend ist, h√§ngt seine Effektivit√§t von zahlreichen Variablen ab ‚Äì Hardware-Effizienz, Netzwerkarchitektur, Latenz und Implementierungsentscheidungen. Diese Komplexit√§ten gehen √ºber unseren aktuellen Rahmen hinaus. <strong>Beachten Sie, dass Jina API automatische Skalierung beinhaltet und unsere Ergebnisse dies widerspiegeln.</strong></li><li><em>Quantisierung</em>: W√§hrend diese Technik kleinere Embedding-Vektoren erzeugt und den Datentransfer reduziert, kommen die haupts√§chlichen Vorteile von anderen Systemkomponenten (Datenspeicherung und Vektor-Distanzberechnungen) anstatt von reduziertem Datentransfer. Da wir uns auf direkte Modellnutzungskosten konzentrieren, haben wir die Quantisierung aus dieser Analyse ausgelassen.</li></ul><p>Schlie√ülich werden wir die finanziellen Auswirkungen jedes Ansatzes untersuchen, wobei sowohl die Gesamtbetriebskosten als auch die Kosten pro Token/Anfrage ber√ºcksichtigt werden.</p><h2 id=\"deployment-setup\">Deployment-Setup</h2><p>Wir haben drei Bereitstellungs- und Nutzungsszenarien mit <code>jina-embeddings-v3</code> evaluiert:</p><h3 id=\"using-the-jina-api\">Nutzung der Jina API</h3><p>Alle Jina AI Embedding-Modelle sind √ºber die <a href=\"https://jina.ai/api-dashboard/embeddings\" rel=\"noreferrer\">Jina API</a> zug√§nglich. Der Zugriff funktioniert √ºber ein Prepaid-Token-System, wobei eine Million Token kostenlos zum Testen zur Verf√ºgung stehen. Wir haben die Leistung durch API-Aufrufe √ºber das Internet von unseren deutschen B√ºros aus evaluiert.</p><h3 id=\"using-aws-sagemaker\">Nutzung von AWS SageMaker</h3><p>Jina Embeddings v3 ist <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">f√ºr AWS-Benutzer √ºber SageMaker verf√ºgbar</a>. Die Nutzung erfordert ein AWS-Abonnement f√ºr dieses Modell. F√ºr Beispielcode haben wir ein <a href=\"https://github.com/jina-ai/jina-sagemaker/blob/main/notebooks/Real-time%20embedding.ipynb\">Notebook bereitgestellt</a>, das zeigt, wie man Jina AI-Modelle mit einem AWS-Konto abonniert und nutzt.</p><p>W√§hrend die Modelle auch auf <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Microsoft Azure</a> und <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">Google Cloud Platform</a> verf√ºgbar sind, haben wir uns bei unseren Tests auf AWS konzentriert. Wir erwarten √§hnliche Leistung auf anderen Plattformen. Alle Tests liefen auf einer <code>ml.g5.xlarge</code> Instanz in der Region <code>us-east-1</code>.</p><h3 id=\"self-hosting-on-kubernetes\">Self-Hosting auf Kubernetes</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Um eine kommerzielle Lizenz f√ºr unsere CC-BY-NC Modelle zu erhalten, m√ºssen Sie zun√§chst eine Lizenz von uns bekommen. <a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">Bitte kontaktieren Sie unser Sales-Team.</a></div></div><p>Wir haben eine FastAPI-Anwendung in Python entwickelt, die <a href=\"https://huggingface.co/jinaai/jina-embeddings-v3\"><code>jina-embeddings-v3</code> von HuggingFace</a> unter Verwendung der <code>SentenceTransformer</code> Bibliothek l√§dt. Die App enth√§lt zwei Endpunkte:</p><ul><li><code>/embed</code>: Nimmt Textpassagen als Input und gibt deren Embeddings zur√ºck</li><li><code>/health</code>: Bietet grundlegendes Gesundheitsmonitoring</li></ul><p>Wir haben dies als Kubernetes-Service auf Amazon's Elastic Kubernetes Service bereitgestellt, unter Verwendung einer <code>g5.xlarge</code> Instanz in <code>us-east-1</code>.</p><h4 id=\"with-and-without-dynamic-batching\">Mit und ohne Dynamic Batching</h4><p>Wir haben die Leistung in einem Kubernetes-Cluster in zwei Konfigurationen getestet: Eine, bei der jede Anfrage sofort nach Erhalt verarbeitet wurde, und eine mit Dynamic Batching. Beim Dynamic Batching wartet der Service, bis <code>MAX_TOKENS</code> (8192) in einer Warteschlange gesammelt sind oder ein vordefiniertes Timeout von 2 Sekunden erreicht ist, bevor das Modell aufgerufen und die Embeddings berechnet werden. Dieser Ansatz erh√∂ht die GPU-Auslastung und reduziert die Fragmentierung des GPU-Speichers.</p><p>F√ºr jedes Bereitstellungsszenario f√ºhrten wir Tests mit drei Schl√ºsselparametern durch:</p><ul><li><strong>Batch-Gr√∂√üe</strong>: Jede Anfrage enthielt entweder 1, 32 oder 128 Textpassagen f√ºr Embedding</li><li><strong>Passagenl√§nge</strong>: Wir verwendeten Textpassagen mit 128, 512 oder 1.024 Token</li><li><strong>Gleichzeitige Anfragen</strong>: Wir sendeten 1, 5 oder 10 Anfragen gleichzeitig</li></ul><h2 id=\"benchmark-results\">Benchmark-Ergebnisse</h2><p>Die folgende Tabelle ist eine Zusammenfassung der Ergebnisse f√ºr jedes Nutzungsszenario, gemittelt √ºber alle Einstellungen der drei Variablen oben.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Metrik</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>Self-Hosted<br>mit Batching</th>\n<th>Self-Hosted<br>Standard</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Request Success Rate</td>\n<td>87,6%</td>\n<td><strong>99,9%</strong></td>\n<td>55,7%</td>\n<td>58,3%</td>\n</tr>\n<tr>\n<td>Latency<br>(Sekunden)</td>\n<td>11,4</td>\n<td>3,9</td>\n<td>2,7</td>\n<td><strong>2,6</strong></td>\n</tr>\n<tr>\n<td>Normalized Latency by Success Rate<br>(Sekunden)</td>\n<td>13,0</td>\n<td><strong>3,9</strong></td>\n<td>4,9</td>\n<td>4,4</td>\n</tr>\n<tr>\n<td>Token Throughput<br>(Token/Sekunde)</td>\n<td>13,8K</td>\n<td><strong>15,0K</strong></td>\n<td>2,2K</td>\n<td>2,6K</td>\n</tr>\n<tr>\n<td>Peak Token Throughput<br>(Token/Sekunde)</td>\n<td><strong>63,0K</strong></td>\n<td>32,2K</td>\n<td>10,9K</td>\n<td>10,5K</td>\n</tr>\n<tr>\n<td>Preis<br>(USD pro 1M Token)</td>\n<td>$0,02</td>\n<td>$0,07</td>\n<td>$0,32</td>\n<td>$0,32</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"request-success-rate\">Request Success Rate</h2><p>Die Erfolgsraten in unserem Test reichen von SageMakers nahezu perfekten 99,9% bis zu den bescheidenen 56-58% der Self-Hosted-L√∂sungen, was zeigt, warum 100% Zuverl√§ssigkeit in Produktionssystemen weiterhin schwer erreichbar bleibt. Drei Hauptfaktoren tragen dazu bei:</p><ul><li>Netzwerkinstabilit√§t verursacht unvermeidbare Ausf√§lle selbst in Cloud-Umgebungen</li><li>Ressourcenkonflikte, insbesondere beim GPU-Speicher, f√ºhren zu Anfrage-Fehlern unter Last</li><li>Notwendige Timeout-Limits bedeuten, dass einige Anfragen fehlschlagen m√ºssen, um die Systemgesundheit zu erhalten</li></ul><h3 id=\"success-rate-by-batch-size\">Erfolgsrate nach Batch-Gr√∂√üe</h3><p>Gro√üe Batch-Gr√∂√üen verursachen h√§ufig Out-of-Memory-Fehler in der selbst gehosteten Kubernetes-Konfiguration. Ohne Dynamic Batching schlugen alle Anfragen mit 32 oder 128 Items pro Batch aus diesem Grund fehl. Selbst mit implementiertem Dynamic Batching blieb die Fehlerrate f√ºr gro√üe Batches signifikant hoch.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8017-ba56-e35215a76fc4\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8064-ab87-e44fc044673d\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">Batch Size</th><th id=\"zt<p\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"kPia\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"wgj>\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"OwMn\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-80e1-b4a8-c6f8a3b03117\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"zt<p\" class=\"\">100%</td><td id=\"kPia\" class=\"\">100%</td><td id=\"wgj>\" class=\"\">97,1%</td><td id=\"OwMn\" class=\"\">58,3%</td></tr><tr id=\"1847c956-b7d2-8096-93c6-deff80bbeffc\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">32</th><td id=\"zt<p\" class=\"\">86,7%</td><td id=\"kPia\" class=\"\">99,8%</td><td id=\"wgj>\" class=\"\">50,0%</td><td id=\"OwMn\" class=\"\">0,0%</td></tr><tr id=\"1847c956-b7d2-80fe-a61d-ea3923f34aac\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"zt<p\" class=\"\">76,2%</td><td id=\"kPia\" class=\"\">99,8%</td><td id=\"wgj>\" class=\"\">24,0%</td><td id=\"OwMn\" class=\"\">0,0%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<p>Obwohl dieses Problem durch Auto-Scaling leicht behoben werden k√∂nnte, haben wir uns entschieden, diese Option hier nicht zu untersuchen. Auto-Scaling w√ºrde zu unvorhersehbaren Kostensteigerungen f√ºhren, und es w√§re schwierig, angesichts der gro√üen Anzahl verf√ºgbarer Auto-Scaling-Konfigurationsoptionen praktische Erkenntnisse zu liefern.</p><h3 id=\"success-rate-by-concurrency-level\">Erfolgsrate nach Parallelit√§tsgrad</h3><p>Parallelit√§t ‚Äì die F√§higkeit, mehrere Anfragen gleichzeitig zu verarbeiten ‚Äì hatte weder einen starken noch einen konsistenten Einfluss auf die Erfolgsraten der Anfragen in den selbst gehosteten Kubernetes-Konfigurationen und nur minimale Auswirkungen auf AWS SageMaker, zumindest bis zu einem Parallelit√§tsgrad von 10.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-80a7-9beb-f1ebe6e1e529\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8011-bcc1-d295e87b8e54\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">Parallelit√§t</th><th id=\"KV|=\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"G@`e\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"[~nZ\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"mHG:\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8041-9a23-c1338c5d3f23\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"KV|=\" class=\"\">93,3%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">57,5%</td><td id=\"mHG:\" class=\"\">58,3%</td></tr><tr id=\"1847c956-b7d2-80eb-86a9-f249c86ddfdf\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">5</th><td id=\"KV|=\" class=\"\">85,7%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">58,3%</td><td id=\"mHG:\" class=\"\">58,3%</td></tr><tr id=\"1847c956-b7d2-80ac-a3ad-eadd81c69cb2\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">10</th><td id=\"KV|=\" class=\"\">83,8%</td><td id=\"G@`e\" class=\"\">99,6%</td><td id=\"[~nZ\" class=\"\">55,3%</td><td id=\"mHG:\" class=\"\">58,3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h3 id=\"success-rate-by-token-length\">Erfolgsrate nach Token-L√§nge</h3><p>Lange Passagen mit hoher Token-Anzahl beeinflussen sowohl die Jina Embedding API als auch Kubernetes mit dynamischem Batching √§hnlich wie gro√üe Batches: Mit zunehmender Gr√∂√üe steigt die Fehlerrate erheblich. W√§hrend selbst gehostete L√∂sungen ohne dynamisches Batching bei gro√üen Batches fast immer fehlschlagen, funktionieren sie bei einzelnen langen Passagen besser. Bei SageMaker hatten lange Passagenl√§ngen ‚Äì wie Parallelit√§t und Batch-Gr√∂√üe ‚Äì keinen nennenswerten Einfluss auf die Erfolgsraten der Anfragen.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8003-8d50-eddc36a83d33\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-804b-8352-d65d5e6bdd0e\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">Passagenl√§nge<br>(Tokens)<br></th><th id=\"CDn]\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"@nCV\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"H?G{\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"]{Mf\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8011-8a92-d0986d045c79\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99,8%</td><td id=\"H?G{\" class=\"\">98,7%</td><td id=\"]{Mf\" class=\"\">58,3%</td></tr><tr id=\"1847c956-b7d2-809f-b073-fa48e7287c13\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">512</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99,8%</td><td id=\"H?G{\" class=\"\">66,7%</td><td id=\"]{Mf\" class=\"\">58,3%</td></tr><tr id=\"1847c956-b7d2-8019-9f1f-cefd810c520d\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">1024</th><td id=\"CDn]\" class=\"\">99,3%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">33,3%</td><td id=\"]{Mf\" class=\"\">58,3%</td></tr><tr id=\"1847c956-b7d2-80c7-a745-fcdaf408f3d0\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">8192</th><td id=\"CDn]\" class=\"\">51,1%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">29,4%</td><td id=\"]{Mf\" class=\"\">58,3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h2 id=\"request-latency\">Anfrage-Latenz</h2><p>Alle Latenztests wurden f√ºnfmal bei Parallelit√§tsgraden von 1, 5 und 10 wiederholt. Die Antwortzeit ist der Durchschnitt √ºber f√ºnf Versuche. Der Anfragedurchsatz ist der Kehrwert der Antwortzeit in Sekunden, multipliziert mit der Parallelit√§t.</p><h3 id=\"jina-api\">Jina API</h3><p>Die Antwortzeiten in der Jina API werden haupts√§chlich von der Batch-Gr√∂√üe beeinflusst, unabh√§ngig vom Parallelit√§tsgrad. W√§hrend die Passagenl√§nge auch die Leistung beeinflusst, ist ihre Auswirkung nicht geradlinig. Als allgemeines Prinzip gilt: Anfragen mit mehr Daten ‚Äì sei es durch gr√∂√üere Batch-Gr√∂√üen oder l√§ngere Passagen ‚Äì ben√∂tigen mehr Verarbeitungszeit.</p><h4 id=\"concurrency-1\">Parallelit√§t 1:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch-Gr√∂√üe</th>\n<th>Passagenl√§nge (in Tokens)</th>\n<th>Antwortzeit in ms</th>\n<th>Anfragedurchsatz (Anfragen/Sekunde)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>801</td>\n<td>1,25</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>724</td>\n<td>1,38</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>614</td>\n<td>1,63</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1554</td>\n<td>0,64</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1620</td>\n<td>0,62</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2283</td>\n<td>0,44</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4441</td>\n<td>0,23</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5430</td>\n<td>0,18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>6332</td>\n<td>0,16</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><h4 id=\"concurrency-5\">Parallelit√§t 5:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>689</td>\n<td>7.26</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>599</td>\n<td>8.35</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>876</td>\n<td>5.71</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1639</td>\n<td>3.05</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2511</td>\n<td>1.99</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4728</td>\n<td>1.06</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2766</td>\n<td>1.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5911</td>\n<td>0.85</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>18621</td>\n<td>0.27</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10\">Parallelit√§t 10:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>790</td>\n<td>12.66</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>669</td>\n<td>14.94</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>649</td>\n<td>15.41</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1384</td>\n<td>7.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3409</td>\n<td>2.93</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>8484</td>\n<td>1.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3441</td>\n<td>2.91</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>13070</td>\n<td>0.77</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>17886</td>\n<td>0.56</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>F√ºr einzelne Anfragen (Batch Size 1):</p><ul><li>Die Antwortzeiten bleiben relativ stabil bei etwa 600-800 ms, unabh√§ngig von der Passagenl√§nge</li><li>H√∂here Parallelit√§t (5 oder 10 gleichzeitige Anfragen) beeintr√§chtigt die Leistung pro Anfrage nicht wesentlich</li></ul><p>F√ºr gr√∂√üere Batches (32 und 128 Elemente):</p><ul><li>Die Antwortzeiten steigen erheblich an, wobei Batch Size 128 etwa 4-6 mal l√§nger dauert als einzelne Anfragen</li><li>Der Einfluss der Passagenl√§nge wird bei gr√∂√üeren Batches deutlicher</li><li>Bei hoher Parallelit√§t (10) und gro√üen Batches (128) f√ºhrt die Kombination zu deutlich l√§ngeren Antwortzeiten, die bei den l√§ngsten Passagen fast 18 Sekunden erreichen</li></ul><p>F√ºr den Durchsatz:</p><ul><li>Kleinere Batches erzielen im Allgemeinen einen besseren Durchsatz bei parallel laufenden Anfragen</li><li>Bei Parallelit√§t 10 mit Batch Size 1 erreicht das System seinen h√∂chsten Durchsatz von etwa 15 Anfragen pro Sekunde</li><li>Gr√∂√üere Batches zeigen durchgehend niedrigeren Durchsatz, der in mehreren Szenarien auf weniger als 1 Anfrage pro Sekunde sinkt</li></ul><h3 id=\"aws-sagemaker\">AWS SageMaker</h3><p>AWS SageMaker Tests wurden mit einer <code>ml.g5.xlarge</code> Instanz durchgef√ºhrt.</p><h4 id=\"concurrency-1-1\">Parallelit√§t 1:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>189</td>\n<td>5.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>219</td>\n<td>4.56</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>221</td>\n<td>4.53</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>377</td>\n<td>2.66</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3931</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2215</td>\n<td>0.45</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>1120</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>3408</td>\n<td>0.29</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>5765</td>\n<td>0.17</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-1\">Parallelit√§t 5:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>443</td>\n<td>11.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>426</td>\n<td>11.74</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>487</td>\n<td>10.27</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1257</td>\n<td>3.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2245</td>\n<td>2.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4159</td>\n<td>1.20</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2444</td>\n<td>2.05</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>6967</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>14438</td>\n<td>0.35</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-1\">Parallelit√§t 10:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>585</td>\n<td>17.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>602</td>\n<td>16.60</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>687</td>\n<td>14.56</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1650</td>\n<td>6.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3555</td>\n<td>2.81</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>7070</td>\n<td>1.41</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3867</td>\n<td>2.59</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>12421</td>\n<td>0.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>25989</td>\n<td>0.38</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Wesentliche Unterschiede zur Jina API:</p><ul><li>Basis-Performance: SageMaker ist deutlich schneller bei kleinen Anfragen (einzelne Elemente, kurze Passagen) - etwa 200 ms gegen√ºber 700-800 ms bei Jina.</li><li>Skalierungsverhalten:<ul><li>Beide Dienste werden mit gr√∂√üeren Batches und l√§ngeren Passagen langsamer</li><li>SageMaker zeigt eine drastischere Verlangsamung bei gro√üen Batches (128) und langen Passagen (1024 Tokens)</li><li>Bei hoher Parallelit√§t (10) mit maximaler Last (Batch 128, 1024 Tokens) ben√∂tigt SageMaker ~26s gegen√ºber Jinas ~18s</li></ul></li><li>Auswirkungen der Parallelit√§t:<ul><li>Beide Dienste profitieren von erh√∂hter Parallelit√§t beim Durchsatz</li><li>Beide behalten √§hnliche Durchsatzmuster √ºber verschiedene Parallelit√§tsstufen hinweg bei</li><li>SageMaker erreicht bei Parallelit√§t 10 einen etwas h√∂heren Spitzendurchsatz (17 Anfr./s vs. 15 Anfr./s)</li></ul></li></ul><h3 id=\"self-hosted-kubernetes-cluster\">Self-Hosted Kubernetes Cluster</h3><p>Die Self-Hosting-Tests wurden auf <a href=\"https://aws.amazon.com/eks/\">Amazon's Elastic Kubernetes Service</a> mit einer <code>g5.xlarge</code> Instanz durchgef√ºhrt.</p><h4 id=\"concurrency-1-2\">Parallelit√§t 1:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>No Batching Time (ms)</th>\n<th>No Batching Throughput (req/s)</th>\n<th>Dynamic Time (ms)</th>\n<th>Dynamic Throughput (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>416</td>\n<td>2.40</td>\n<td>2389</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>397</td>\n<td>2.52</td>\n<td>2387</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>396</td>\n<td>2.52</td>\n<td>2390</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1161</td>\n<td>0.86</td>\n<td>3059</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1555</td>\n<td>0.64</td>\n<td>1496</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2424</td>\n<td>0.41</td>\n<td>2270</td>\n<td>0.44</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-2\">Parallelit√§t 5:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>No Batching Time (ms)</th>\n<th>No Batching Throughput (req/s)</th>\n<th>Dynamic Time (ms)</th>\n<th>Dynamic Throughput (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>451</td>\n<td>11.08</td>\n<td>2401</td>\n<td>2.08</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>453</td>\n<td>11.04</td>\n<td>2454</td>\n<td>2.04</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>478</td>\n<td>10.45</td>\n<td>2520</td>\n<td>1.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1447</td>\n<td>3.46</td>\n<td>1631</td>\n<td>3.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2867</td>\n<td>1.74</td>\n<td>2669</td>\n<td>1.87</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4154</td>\n<td>1.20</td>\n<td>4026</td>\n<td>1.24</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-2\">Parallelit√§t 10:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>No Batching Time (ms)</th>\n<th>No Batching Throughput (req/s)</th>\n<th>Dynamic Time (ms)</th>\n<th>Dynamic Throughput (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>674</td>\n<td>14.84</td>\n<td>2444</td>\n<td>4.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>605</td>\n<td>16.54</td>\n<td>2498</td>\n<td>4.00</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>601</td>\n<td>16.64</td>\n<td>781*</td>\n<td>12.80</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>2089</td>\n<td>4.79</td>\n<td>2200</td>\n<td>4.55</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>5005</td>\n<td>2.00</td>\n<td>4450</td>\n<td>2.24</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>7331</td>\n<td>1.36</td>\n<td>7127</td>\n<td>1.40</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">‚Ä† Dieses anomale Ergebnis ist ein Nebenprodukt des 2-Sekunden-Timeouts beim dynamischen Batching. Bei einer Parallelit√§t von 10, wobei jede Anfrage 1024 Token an Daten sendet, f√ºllt sich die Warteschlange fast sofort und das Batching-System muss nie auf einen Timeout warten. Bei kleineren Gr√∂√üen und Parallelit√§ten geschieht dies jedoch, wodurch automatisch zwei verschwendete Sekunden zu jeder Anfrage hinzugef√ºgt werden. Diese Art von Nichtlinearit√§t ist bei nicht optimierten Batch-Prozessen √ºblich.</div></div><p>Bei Anfragen mit mehr als 16.384 Token scheiterte unser Self-Hosting-Setup mit Serverfehlern, typischerweise Out-of-Memory-Fehlern. Dies galt unabh√§ngig von der Parallelit√§t. Daher werden keine Tests mit mehr Daten als diese angezeigt.</p><p>Hohe Parallelit√§t erh√∂hte die Antwortzeiten weitgehend linear: Parallelit√§tsstufen von 5 brauchten ungef√§hr f√ºnfmal so lange zum Antworten wie 1. Stufen von 10 brauchten zehnmal so lange.</p><p>Dynamisches Batching verlangsamt die Antwortzeiten bei kleinen Batches um etwa zwei Sekunden. Dies ist zu erwarten, da die Batching-Warteschlange 2 Sekunden wartet, bevor sie einen nicht vollen Batch verarbeitet. Bei gr√∂√üeren Batch-Gr√∂√üen bringt es jedoch moderate Verbesserungen in der Antwortzeit.</p><h2 id=\"token-throughput\">Token-Durchsatz</h2><p>Der Token-Durchsatz steigt mit gr√∂√üeren Batch-Gr√∂√üen, l√§ngeren Passagenl√§ngen und h√∂herer Parallelit√§t √ºber alle Plattformen hinweg. Daher pr√§sentieren wir nur Ergebnisse bei hoher Auslastung, da niedrigere Levels keine aussagekr√§ftige Indikation der realen Performance liefern w√ºrden.</p><p>Alle Tests wurden bei einer Parallelit√§t von 10 mit 16.384 Token pro Anfrage durchgef√ºhrt, gemittelt √ºber f√ºnf Anfragen. Wir testeten zwei Konfigurationen: Batch-Gr√∂√üe 32 mit 512-Token-Passagen und Batch-Gr√∂√üe 128 mit 128-Token-Passagen. Die Gesamtzahl der Token bleibt √ºber beide Konfigurationen konstant.</p><p>Token-Durchsatz (Token pro Sekunde):</p><table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>Self-Hosted (No Batching)</th>\n<th>Self-Hosted (Dynamic Batching)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>46K</td>\n<td>28,5K</td>\n<td>14,3K</td>\n<td>16,1K</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>42,3K</td>\n<td>27,6K</td>\n<td>9,7K</td>\n<td>10,4K</td>\n</tr>\n</tbody>\n</table>\n<p>Unter hoher Last √ºbertrifft die Jina API die Alternativen deutlich, w√§hrend die hier getesteten Self-Hosted-L√∂sungen eine wesentlich niedrigere Leistung zeigen.</p><h2 id=\"costs-per-million-tokens\">Kosten pro Million Token</h2><p>Die Kosten sind wohl der wichtigste Faktor bei der Wahl einer Embedding-L√∂sung. W√§hrend die Berechnung von KI-Modellkosten komplex sein kann, hier eine vergleichende Analyse verschiedener Optionen:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Service Type</th>\n<th>Cost per Million Tokens</th>\n<th>Infrastructure Cost</th>\n<th>License Cost</th>\n<th>Total Hourly Cost</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina API</td>\n<td>$0,018-0,02</td>\n<td>N/A</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>SageMaker (US East)</td>\n<td>$0,0723</td>\n<td>$1,408/hour</td>\n<td>$2,50/hour</td>\n<td>$3,908/hour</td>\n</tr>\n<tr>\n<td>SageMaker (EU)</td>\n<td>$0,0788</td>\n<td>$1,761/hour</td>\n<td>$2,50/hour</td>\n<td>$4,261/hour</td>\n</tr>\n<tr>\n<td>Self-Hosted (US East)</td>\n<td>$0,352</td>\n<td>$1,006/hour</td>\n<td>$2,282/hour</td>\n<td>$3,288/hour</td>\n</tr>\n<tr>\n<td>Self-Hosted (EU)</td>\n<td>$0,379</td>\n<td>$1,258/hour</td>\n<td>$2,282/hour</td>\n<td>$3,540/hour</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"jina-api-1\">Jina API</h3><p>Der Service folgt einem tokenbasierten Preismodell mit zwei vorausbezahlten Stufen:</p><ul><li>$20 f√ºr 1 Milliarde Token ($0,02 pro Million) - Ein Einstiegstarif, ideal f√ºr Prototyping und Entwicklung</li><li>$200 f√ºr 11 Milliarden Token ($0,018 pro Million) - Ein wirtschaftlicherer Tarif f√ºr gr√∂√üere Volumen</li></ul><p>Es ist erw√§hnenswert, dass diese Token f√ºr Jinas gesamte Produktpalette verwendet werden k√∂nnen, einschlie√ülich Reader, Reranker und Zero-Shot-Klassifikatoren.</p><h3 id=\"aws-sagemaker-1\">AWS SageMaker</h3><p>Die SageMaker-Preisgestaltung kombiniert st√ºndliche Instanzkosten mit Modell-Lizenzgeb√ºhren. Bei Verwendung einer <code>ml.g5.xlarge</code> Instanz:</p><ul><li>Instanzkosten: $1,408/Stunde (US East) oder $1,761/Stunde (EU Frankfurt)</li><li><code>jina-embeddings-v3</code> Lizenz: $2,50/Stunde</li><li>Gesamtst√ºndliche Kosten: $3,908-$4,261 je nach Region</li></ul><p>Mit einem durchschnittlichen Durchsatz von 15.044 Token/Sekunde (54,16M Token/Stunde) liegen die Kosten pro Million Token zwischen $0,0723 und $0,0788.</p><h3 id=\"self-hosting-with-kubernetes\">Self-Hosting mit Kubernetes</h3><p>Die Kosten f√ºr Self-Hosting variieren erheblich je nach Infrastrukturwahl. Mit einer AWS EC2 <code>g5.xlarge</code> Instanz als Referenz:</p><ul><li>Instanzkosten: $1,006/Stunde (US East) oder $1,258/Stunde (EU Frankfurt)</li><li><code>jina-embeddings-v3</code> Lizenz: $5000/Quartal ($2,282/Stunde)</li><li>Gesamtst√ºndliche Kosten: $3,288-$3,540 je nach Region</li></ul><p>Bei 2.588 Token/Sekunde (9,32M Token/Stunde) betragen die Kosten pro Million Token $0,352-$0,379. W√§hrend der Stundensatz niedriger ist als bei SageMaker, f√ºhrt der reduzierte Durchsatz zu h√∂heren Kosten pro Token.</p><p>Wichtige √úberlegungen f√ºr Self-Hosting:</p><ul><li>Fixkosten (Lizenzierung, Infrastruktur) fallen unabh√§ngig von der Nutzung an</li><li>On-Premises-Hosting erfordert weiterhin Lizenzgeb√ºhren und Personalkosten</li><li>Variable Arbeitslasten k√∂nnen die Kosteneffizienz erheblich beeinflussen</li></ul><h3 id=\"key-takeaways\">Wichtige Erkenntnisse</h3><p>Die Jina API erweist sich als die kosteng√ºnstigste L√∂sung, selbst ohne Ber√ºcksichtigung von Kaltstartzeiten und unter Annahme optimalen Durchsatzes f√ºr Alternativen.</p><p>Self-Hosting k√∂nnte f√ºr Organisationen mit bestehender robuster Infrastruktur sinnvoll sein, bei denen die marginalen Serverkosten minimal sind. Zus√§tzlich k√∂nnte die Erkundung von Cloud-Anbietern jenseits von AWS bessere Preise ergeben.</p><p>F√ºr die meisten Unternehmen, insbesondere KMUs, die schl√ºsselfertige L√∂sungen suchen, bietet die Jina API jedoch un√ºbertroffene Kosteneffizienz.</p><h2 id=\"security-and-data-privacy-considerations\">Sicherheits- und Datenschutzaspekte</h2><p>Bei der Wahl einer Deploymentstrategie f√ºr Embedding-Modelle k√∂nnen Sicherheits- und Datenschutzanforderungen neben Performance und Kosten√ºberlegungen eine entscheidende Rolle spielen. Wir bieten flexible Deployment-Optionen f√ºr verschiedene Sicherheitsanforderungen:</p><h3 id=\"cloud-service-providers\">Cloud Service Provider</h3><p>F√ºr <strong>Unternehmen, die bereits mit gro√üen Cloud-Anbietern arbeiten</strong>, bieten unsere Cloud-Marketplace-Angebote (wie <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS Marketplace</a>, <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Azure</a> und <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">GCP</a>) eine nat√ºrliche L√∂sung f√ºr das Deployment innerhalb bestehender Sicherheitsframeworks. Diese Deployments profitieren von:</p><ul><li>Vererbten Sicherheitskontrollen und Compliance aus Ihrer CSP-Beziehung</li><li>Einfacher Integration mit bestehenden Sicherheitsrichtlinien und Datenverwaltungsregeln</li><li>Erfordern wenig oder keine √Ñnderungen an bestehenden Datenverarbeitungsvereinbarungen</li><li>Abstimmung mit bestehenden Datensouver√§nit√§tsaspekten</li></ul><h3 id=\"self-hosting-and-local-deployment\">Self-Hosting und lokales Deployment</h3><p><strong>Organisationen mit strengen Sicherheitsanforderungen oder spezifischen regulatorischen Verpflichtungen</strong> bevorzugen oft vollst√§ndige physische Kontrolle √ºber ihre Infrastruktur. Unsere Self-Hosted-Option erm√∂glicht:</p><ul><li>Volle Kontrolle √ºber die Deployment-Umgebung</li><li>Datenverarbeitung vollst√§ndig innerhalb Ihres Sicherheitsperimeters</li><li>Integration mit bestehender Sicherheits√ºberwachung und -kontrollen</li></ul><p>Um eine kommerzielle Lizenz f√ºr unsere CC-BY-NC-Modelle zu erhalten, m√ºssen Sie zun√§chst eine Lizenz von uns erwerben. <a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">Bitte kontaktieren Sie unser Vertriebsteam.</a></p><h3 id=\"jina-api-service\">Jina API Service</h3><p>F√ºr <strong>Startups und KMUs</strong>, die Sicherheit und Komfort gegen Kosten abw√§gen m√ºssen, bietet unser API-Service Sicherheit auf Unternehmensebene ohne zus√§tzlichen operativen Aufwand:</p><ul><li><a href=\"https://jina.ai/Jina_AI_GmbH_Letter_of_Attestation_SOC_2_Type_1.pdf\" rel=\"noreferrer\">SOC2-Zertifizierung</a> f√ºr robuste Sicherheitskontrollen</li><li><a href=\"https://gdpr-info.eu/\" rel=\"noreferrer\">Volle DSGVO-Konformit√§t</a> f√ºr die Datenverarbeitung</li><li>Null-Daten-Aufbewahrungsrichtlinie - wir speichern oder protokollieren Ihre Anfragen nicht</li><li>Verschl√ºsselte Daten√ºbertragung und sichere Infrastruktur</li></ul><p>Die Modellangebote von Jina AI erm√∂glichen es Organisationen, die Deploymentstrategie zu w√§hlen, die am besten mit ihren Sicherheitsanforderungen √ºbereinstimmt und dabei die betriebliche Effizienz aufrechterh√§lt.</p><h2 id=\"choosing-your-solution\">Auswahl Ihrer L√∂sung</h2><p>Das folgende Flussdiagramm fasst die Ergebnisse aller empirischen Tests und Tabellen zusammen, die Sie gesehen haben:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1256\" height=\"1980\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png 1256w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Mit diesen Informationen sollte Ihnen das obige Flussdiagramm einen guten Hinweis darauf geben, welche Art von L√∂sungen Sie in Betracht ziehen sollten.</span></figcaption></figure><p>Ber√ºcksichtigen Sie zun√§chst Ihre Sicherheitsanforderungen und wie viel Flexibilit√§t Sie opfern k√∂nnen, um diese zu erf√ºllen.</p><p>√úberlegen Sie dann, wie Sie KI in Ihrem Unternehmen einsetzen m√∂chten:</p><ol><li>Offline-Indexierung und nicht zeitsensitive Anwendungsf√§lle, die Batch-Verarbeitung optimal nutzen k√∂nnen.</li><li>Zuverl√§ssigkeits- und skalierbarkeitssensitive Verwendungen wie Retrieval-Augmented Generation und LLM-Integration.</li><li>Zeitsensitive Nutzungen wie Online-Suche und -Abruf.</li></ol><p>Ber√ºcksichtigen Sie auch Ihr internes Fachwissen und bestehende Infrastruktur:</p><ol><li>Ist Ihr Technologie-Stack bereits stark Cloud-abh√§ngig?</li><li>Verf√ºgen Sie √ºber einen gro√üen internen IT-Betrieb, der Self-Hosting durchf√ºhren kann?</li></ol><p>Ber√ºcksichtigen Sie schlie√ülich Ihr erwartetes Datenvolumen. Sind Sie ein Gro√ünutzer, der t√§glich Millionen von Operationen mit KI-Modellen durchf√ºhren m√∂chte?</p><h2 id=\"conclusion\">Fazit</h2><p>Die Integration von KI in operative Entscheidungen bleibt f√ºr viele IT-Abteilungen Neuland, da der Markt keine etablierten schl√ºsselfertigen L√∂sungen bietet. Diese Unsicherheit kann die strategische Planung erschweren. Unsere quantitative Analyse zielt darauf ab, konkrete Orientierung f√ºr die Integration unserer Such-Foundation-Models in Ihre spezifischen Workflows und Anwendungen zu geben.</p><p>Was die Kosten pro Einheit betrifft, sticht die Jina API als eine der wirtschaftlichsten Optionen f√ºr Unternehmen hervor. Nur wenige Alternativen k√∂nnen unseren Preis bei vergleichbarer Funktionalit√§t erreichen.</p><p>Wir sind bestrebt, Suchfunktionen zu liefern, die nicht nur leistungsstark und benutzerfreundlich, sondern auch kosteneffektiv f√ºr Organisationen aller Gr√∂√üen sind. Ob √ºber gro√üe Cloud-Anbieter oder Self-Hosted-Deployments, unsere L√∂sungen erf√ºllen selbst die komplexesten Unternehmensanforderungen, die √ºber reine Kosten√ºberlegungen hinausgehen. Diese Analyse schl√ºsselt die verschiedenen Kostenfaktoren auf, um Ihre Entscheidungsfindung zu unterst√ºtzen.</p><p>Da jede Organisation ihre eigenen einzigartigen Anforderungen hat, sind wir uns bewusst, dass ein einzelner Artikel nicht jedes Szenario abdecken kann. Wenn Sie spezifische Bed√ºrfnisse haben, die hier nicht behandelt wurden, kontaktieren Sie uns bitte, um zu besprechen, wie wir Ihre Implementierung am besten unterst√ºtzen k√∂nnen.</p>",
  "comment_id": "679b56ba42b46600019a86e3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-01-30T11:38:50.000+01:00",
  "updated_at": "2025-01-31T05:32:29.000+01:00",
  "published_at": "2025-01-31T05:32:29.000+01:00",
  "custom_excerpt": "We offer detailed cost and performance breakdowns for three deployment strategies: Jina API, self-hosted K8s, and AWS SageMaker, to help you make the right decision.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "641c23a2f4d50d003d590474",
    "name": "Saahil Ognawala",
    "slug": "saahil",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
    "cover_image": null,
    "bio": "Senior Product Manager at Jina AI",
    "website": "http://www.saahilognawala.com/",
    "location": "Munich, DE",
    "facebook": null,
    "twitter": "@saahil",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-deploying-search-foundation-models-in-production/",
  "excerpt": "Wir bieten detaillierte Kosten- und Leistungsaufschl√ºsselungen f√ºr drei Bereitstellungsstrategien an: Jina API, selbst gehostetes K8s und AWS SageMaker, um Ihnen bei der richtigen Entscheidung zu helfen.",
  "reading_time": 14,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}