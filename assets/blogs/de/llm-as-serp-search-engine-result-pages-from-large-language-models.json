{
  "slug": "llm-as-serp-search-engine-result-pages-from-large-language-models",
  "id": "67c02c3b343c560001efca6e",
  "uuid": "ec03076e-dc8a-44ea-bd09-57c5e6a6d593",
  "title": "LLM-als-SERP: Suchergebnisseiten aus Large Language Models",
  "html": "<figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/llm-serp-demo\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">LLM as SERP</div><div class=\"kg-bookmark-description\">Large language model as search result page</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">LLMSERP</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-llm-serp.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">Testen Sie die interaktive Demo und sehen Sie, wie Ihre Website in LLM SERP erscheint.</span></p></figcaption></figure><p>Seit RAG ist der Trend, LLMs zur Verbesserung der Suche einzusetzen. Von Perplexity bis zu DeepSearch und DeepResearch ist die Idee, Suchmaschinenergebnisse in den Generierungsprozess einzubinden, zum Standard geworden. Viele Nutzer geben auch an, dass sie Google nicht mehr so häufig wie früher nutzen und das klassische Seitendesign als lahm, überwältigend oder mühsam empfinden. Stattdessen haben sie sich an die hohe Präzision und Trefferquote von QA-artigen Ergebnissen mit einer Chat-ähnlichen Such-Benutzeroberfläche gewöhnt, was darauf hindeutet, dass diese Design-Philosophie der richtige Weg sein könnte.</p><p><strong>Aber was wäre, wenn das LLM selbst die Suchmaschine <em>ist</em>?</strong></p><p>Was wäre, wenn Sie das in LLMs eingebettete Wissen wie beim Google-Suchen erkunden könnten? Seitennummerierung, Links und alles andere – genau wie in den alten Zeiten, die Sie kennen. Wenn Sie nicht sicher sind, was ich meine, schauen Sie sich zuerst die Demo unten an.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp.mp4\" poster=\"https://img.spacergif.org/v1/1426x976/0a/spacer.png\" width=\"1426\" height=\"976\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Die Links, Titel und Snippets werden vollständig von einem LLM generiert. Sie können </span><a href=\"https://jina.ai/llm-serp-demo\"><span style=\"white-space: pre-wrap;\">https://jina.ai/llm-serp-demo</span></a><span style=\"white-space: pre-wrap;\"> besuchen und selbst einige Anfragen ausprobieren!</span></p></figcaption>\n        </figure><p>Bevor wir Bedenken wegen Halluzinationen äußern, erklären wir zunächst, warum diese Idee einen gewissen Wert hat: LLMs werden mit riesigen Mengen an Web-Wissen trainiert. Modelle wie DeepSeek-R1, GPT-4, Claude-3.7 und Gemini-2.0 wurden mit Billionen von Tokens aus dem öffentlichen Internet trainiert. Eine grobe Schätzung ist, dass <strong>&lt;1% bis ~5% der hochwertigen, öffentlich zugänglichen Web-Texte</strong> zum Training führender Modelle verwendet wurden.</p><p>Wenn Sie denken, diese Zahl erscheint zu klein, betrachten Sie diesen Vergleich: Wenn wir Googles Index als Maßstab nehmen (der 100% der nutzerorientierten Daten der Welt repräsentiert), dann entspricht Bings Index etwa 30-50% von Google. Baidu deckt etwa 5-10% ab und Yandex 3-5%. Brave Search indexiert weniger als 1%. Wenn also ein LLM mit 1-5% hochwertiger öffentlicher Daten trainiert wird, entspricht dies potenziell der gleichen Datenmenge, die eine anständige kleine Suchmaschine bereitstellen kann.</p><p>Da diese Modelle diese Web-Daten effektiv \"gespeichert\" haben, müssen wir sie nur auf eine Weise promten, die ihr Gedächtnis \"aktiviert\", sodass sie wie Suchmaschinen funktionieren und Ergebnisse ähnlich einer Suchergebnisseite (SERP) generieren können.</p><p>Ja, Halluzination ist eine Herausforderung, aber mit der Verbesserung der Modellfähigkeiten bei jeder Iteration können wir vernünftigerweise erwarten, dass sich dieses Problem abschwächt. Auf X sind Menschen oft besessen davon, SVGs von Grund auf zu generieren, wenn ein neues Modell veröffentlicht wird, in der Hoffnung, dass jede Version bessere Illustrationen als die letzte produziert. Diese Suchmaschinenidee folgt einer ähnlichen Hoffnung auf schrittweise Verbesserung des LLM-Verständnisses der digitalen Welt.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1176\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/02/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://x.com/huybery/status/1893996258760527882\"><span style=\"white-space: pre-wrap;\">Binyuan Hui </span></a><span style=\"white-space: pre-wrap;\">(einer der Kernentwickler hinter den Qwen-Modellen) zeigt die Fähigkeit von </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>qwen-2.5-max</span></code><span style=\"white-space: pre-wrap;\">, ein Schwein-SVG in einem Durchgang zu zeichnen.</span></figcaption></figure><p>Wissensstichtage stellen eine weitere Einschränkung dar. Suchmaschinen sollten Echtzeit-Informationen liefern, aber da LLM-Gewichte nach dem Training eingefroren sind, können sie keine genauen Informationen über ihren Stichtag hinaus liefern. Im Allgemeinen gilt: Je näher eine Anfrage an diesem Stichtag liegt, desto wahrscheinlicher werden Halluzinationen. Da ältere Informationen wahrscheinlich häufiger zitiert und umformuliert wurden, was möglicherweise ihre Gewichtung in den Trainingsdaten erhöht. (Dies setzt voraus, dass Informationen einheitlich gewichtet sind; aktuelle Nachrichten können unabhängig von der Aktualität unverhältnismäßig viel Aufmerksamkeit erhalten.) <strong>Diese Einschränkung definiert jedoch genau, wo dieser Ansatz am nützlichsten sein könnte – für Informationen, die gut innerhalb des Wissenszeitraums des Modells liegen.</strong></p><h2 id=\"where-llm-as-serp-can-be-useful\">Wo kann LLM-as-SERP nützlich sein?</h2><p>Bei DeepSearch/RAG oder anderen Search-Grounding-Systemen besteht eine zentrale Herausforderung darin, zu bestimmen, ob eine Frage externe Informationen benötigt oder aus dem Wissen des Modells beantwortet werden kann. Aktuelle Systeme verwenden typischerweise Prompt-basiertes Routing mit Anweisungen wie:</p><pre><code>- For greetings, casual conversation, or general knowledge questions, answer directly without references.\n- For all other questions, provide a verified answer with external knowledge. Each reference must include exactQuote and url.</code></pre><p>Dieser Ansatz scheitert in beide Richtungen – manchmal löst er unnötige Suchen aus, andere Male übersieht er kritische Informationsbedürfnisse. Besonders bei neueren Reasoning-Modellen ist oft erst während der Generierung klar, ob externe Daten benötigt werden.</p><p>Was wäre, wenn wir einfach die Suche trotzdem durchführen würden? Wir könnten einen Aufruf an eine echte Such-API und einen weiteren an ein LLM-as-Search-System machen. Dies eliminiert die vorgelagerte Routing-Entscheidung und verlagert sie nach hinten, wo wir tatsächliche Ergebnisse zum Vergleich haben – aktuelle Daten aus der echten Suche, Wissen innerhalb des Trainings-Stichtags des Modells und möglicherweise einige falsche Informationen.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/Heading--41-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p>Der finale Schlussfolgerungsschritt kann dann Unstimmigkeiten identifizieren und Quellen nach Aktualität, Zuverlässigkeit und Übereinstimmung zwischen den Ergebnissen gewichten - was wir nicht explizit programmieren müssen, da dies bereits eine Stärke von LLMs ist. Man kann auch jede URL in den Suchergebnissen besuchen (z.B. mit Jina Reader), um die Quellen weiter zu validieren. In praktischen Implementierungen ist dieser Verifizierungsschritt ohnehin immer notwendig; man sollte sich nie ausschließlich auf Auszüge von Suchmaschinen verlassen, egal ob es sich um echte oder künstliche Suchmaschinen handelt.</p><h2 id=\"conclusion\">Fazit</h2><p>Durch die Verwendung von LLM-as-SERP <strong>verwandeln wir die binäre Frage \"liegt dies innerhalb des Modellwissens oder nicht?\" in einen robusteren Prozess der Evidenzgewichtung.</strong></p><p>Wir stellen <a href=\"https://jina.ai/llm-serp-demo\" rel=\"noreferrer\">einen Playground</a> sowie <a href=\"https://jina.ai/api-dashiboard/llm-serp\" rel=\"noreferrer\">einen von uns gehosteten API-Endpunkt</a> zur Verfügung, mit dem Sie experimentieren können. Sie können dies auch gerne in Ihre eigenen DeepSearch/DeepResearch-Implementierungen integrieren, um Verbesserungen aus erster Hand zu sehen.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/node-serp\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/node-serp: LLMs-as-SERPs</div><div class=\"kg-bookmark-description\">LLMs-as-SERPs. Contribute to jina-ai/node-serp development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-3.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/node-serp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Die API ahmt einen vollständigen SERP-Endpunkt nach, bei dem Sie die Anzahl der Ergebnisse, Paginierung, Land, Sprache etc. definieren können. Die Implementierung finden Sie auf GitHub. Wir sind gespannt auf Ihr Feedback zu diesem interessanten Ansatz.</p>",
  "comment_id": "67c02c3b343c560001efca6e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/llmserp-banner.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-02-27T10:11:23.000+01:00",
  "updated_at": "2025-02-27T13:38:43.000+01:00",
  "published_at": "2025-02-27T13:36:57.000+01:00",
  "custom_excerpt": "This is either an extremely smart idea or an extremely stupid one—there's no in-between.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/llm-as-serp-search-engine-result-pages-from-large-language-models/",
  "excerpt": "Das ist entweder eine äußerst kluge oder eine äußerst dumme Idee – dazwischen gibt es nichts.",
  "reading_time": 5,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}