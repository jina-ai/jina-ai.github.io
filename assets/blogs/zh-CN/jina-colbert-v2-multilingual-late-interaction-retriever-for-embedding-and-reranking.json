{
  "slug": "jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking",
  "id": "66cd8fc6e84873000133d63d",
  "uuid": "e995c4d9-1832-4e2a-8108-e8453f5c82c5",
  "title": "Jina ColBERT v2：用于向量检索和重排序的多语言后期交互检索器",
  "html": "<p>今天，我们很高兴发布 Jina ColBERT v2（<code>jina-colbert-v2</code>），这是一个基于 ColBERT 架构的高级后期交互检索模型。这个新的语言模型提升了 <code>jina-colbert-v1-en</code> 的性能，并添加了多语言支持和动态输出维度。</p><p>这个新版本具有以下特点：</p><ul><li>与原始 ColBERT-v2（+6.5%）和我们之前的版本 <code>jina-colbert-v1-en</code>（+5.4%）相比，具有<strong>更优的检索性能</strong>。</li><li>支持 89 种语言的<strong>多语言能力</strong>，在主要全球语言中都表现出色。</li><li>通过套娃表示学习实现<strong>用户可控的输出嵌入维度</strong>，使用户能够灵活平衡效率和精度。</li></ul><h2 id=\"technical-summary-of-jina-colbert-v2\"><code>jina-colbert-v2</code> 技术总结</h2><p>完整的技术报告可在 arXiv 上找到：</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2408.16672?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever</div><div class=\"kg-bookmark-description\">Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Rohan Jha</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th><code>jina-colbert-v2</code></th>\n<th><code>jina-colbert-v1-en</code></th>\n<th>Original ColBERTv2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Average of 14 English<br/>BEIR tasks</td>\n<td><b>0.521</b></td>\n<td>0.494</td>\n<td>0.489</td>\n</tr>\n<tr>\n<td>Multilingual</td>\n<td><b>89 languages</b></td>\n<td>English-only</td>\n<td>English-only</td>\n</tr>\n<tr>\n<td>Output dimensions</td>\n<td><b>128, 96, or 64</b></td>\n<td>Fixed 128</td>\n<td>Fixed 128</td>\n</tr>\n<tr>\n<td>Max query length</td>\n<td>32 tokens</td>\n<td>32 tokens</td>\n<td>32 tokens</td>\n</tr>\n<tr>\n<td>Max document length</td>\n<td>8192 tokens</td>\n<td>8192 tokens</td>\n<td>512 tokens</td>\n</tr>  \n\n<tr>\n<td>Parameters</td>\n<td>560M</td>\n<td>137M</td>\n<td>110M</td>\n</tr>\n<tr>\n<td>Model size</td>\n<td>1.1GB</td>\n<td>550MB</td>\n<td>438MB</td>\n</tr>\n\n\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"asymmetric-embedding-in-colbert\">ColBERT 中的非对称嵌入</h2><p>ColBERT 在 BERT 架构的基础上增加了<strong>后期交互</strong>和<strong>非对称</strong>查询-文档编码。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">What is ColBERT and Late Interaction and Why They Matter in Search?</div><div class=\"kg-bookmark-description\">Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ColBERT 的非对称性质意味着，在使用 <code>jina-colbert-v2</code> 或 <code>jina-colbert-v1-en</code> 等模型时，你需要指定是在进行查询嵌入、文档嵌入，还是两者都需要（用于重排序）。这种额外的灵活性提升了检索任务中相对于同质嵌入模型的性能。</p><h2 id=\"multilingual-support-for-over-89-languages\">支持超过 89 种语言</h2><p>Jina ColBERT v2 具有广泛的多语言能力，旨在满足现代全球化信息检索和 AI 应用的需求。<code>jina-colbert-v2</code> 的训练语料库包含 89 种语言，并对主要国际语言进行了额外的训练阶段，包括<strong>阿拉伯语、中文、英语、法语、德语、日语、俄语和西班牙语</strong>，以及<strong>编程语言</strong>。训练还包括了对齐的双语文本语料库，以实现跨语言潜力，允许在重排序/检索任务中匹配不同语言的查询和文档。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Distribution-of-the-languages-in-the-training-corpus-at-the-pretrained-stage--3-.svg\" class=\"kg-image\" alt=\"Chart of language distribution in training data, highlighting dominance of English and Chinese.\" loading=\"lazy\" width=\"1456\" height=\"743\"><figcaption><span style=\"white-space: pre-wrap;\">按语言（使用 </span><a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ISO-639</span></a><span style=\"white-space: pre-wrap;\"> 代码指定）的预训练数据集分布情况（对数刻度）。</span></figcaption></figure><p>如今，Jina ColBERT v2 作为<strong>唯一一个生成紧凑嵌入的多语言 ColBERT 类模型</strong>，在 MIRACL 基准测试中测试的所有语言中都显著优于基于 BM25 的检索。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-Multilingual-Data--1-.svg\" class=\"kg-image\" alt=\"Bar chart comparing jina-colbert-v2 and BM25 performance across 20 languages on multilingual tasks.\" loading=\"lazy\" width=\"691\" height=\"426\"><figcaption><span style=\"white-space: pre-wrap;\">在 MIRACL 基准测试中，Jina ColBERT v2 在 16 种语言上与 BM25 的性能对比。</span></figcaption></figure><p>此外，在英语检索任务中，Jina ColBERT v2 的性能超过了其前身 <code>jina-colbert-v1-en</code> 和原始 ColBERT v2 模型，与高度专门化的仅英语 <a href=\"https://huggingface.co/answerdotai/answerai-colbert-small-v1?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">AnswerAI-ColBERT-small</a> 模型的性能相当。</p>\n<!--kg-card-begin: html-->\n<table class=\"simple-table\">\n  <tbody>\n<thead>\n<tr>\n      <th><strong>模型名称</strong></th>\n      <th><strong>平均分数<br>(14 个 BEIR 英语基准测试)<br></strong></th>\n      <th><strong>多语言支持</strong></th>\n  </tr>\n    </thead>\n    <tr>\n      <td><code>jina-colbert-v2</code></td>\n      <td>0.521</td>\n      <td>多语言</td>\n    </tr>\n    <tr>\n      <td><code>jina-colbert-v1-en</code></td>\n      <td>0.494</td>\n      <td>仅英语</td>\n    </tr>\n    <tr>\n      <td>ColBERT v2.0</td>\n      <td>0.489</td>\n      <td>仅英语</td>\n    </tr>\n    <tr>\n      <td>AnswerAI-ColBERT-small</td>\n      <td>0.549</td>\n      <td>仅英语</td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-English-only-datasets-from-BEIR--2-.svg\" class=\"kg-image\" alt=\"Bar chart showing model evaluations on English BEIR datasets, with several models like 'jina-colbert' and 'BM25'.\" loading=\"lazy\" width=\"1088\" height=\"712\"><figcaption><span style=\"white-space: pre-wrap;\">jina-colbert-v2 在 BEIR 基准英语数据集上的评估。</span></figcaption></figure><h2 id=\"matryoshka-representation-learning\">套娃表示学习</h2><p><a href=\"https://arxiv.org/abs/2205.13147?ref=jina-ai-gmbh.ghost.io\">套娃表示学习</a>是一种训练模型以支持不同输出向量大小同时最小化精度损失的技术。我们用几个不同的线性投影头（神经网络的最终层）训练网络的隐藏层，每个投影头支持不同的输出大小。<strong>Jina ColBERT v2 支持 128、96 和 64 维的输出向量。</strong></p><p>Jina ColBERT v2 默认生成 128 维的输出嵌入，但也可以生成 96 和 64 维的嵌入，这些嵌入的性能几乎相同，但分别短了 25% 和 50%。</p><p>下表显示了 <a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain?ref=jina-ai-gmbh.ghost.io\">nDGC</a> 的性能<code>jina-colbert-v2</code> 在六个 BEIR 基准测试中的前十结果（<em>nDGC@10</em>）。在此可以看到，128 维度和 96 维度之间的性能差异仅略高于 1%，而 128 维度和 64 维度之间的差异不到 1.5%。\n\n<!--kg-card-begin: html-->\n<table id=\"b838dc78-1321-499e-98e7-63e3b5c8e910\" class=\"simple-table\"><tbody><thead id=\"177f4349-0620-4947-a3ce-01e598395ed7\"><tr><th id=\"<\\ml\" class=\"\"><strong>输出维度</strong></th><th id=\"<NYX\" class=\"\"><strong>平均分数</strong><strong><br>(6 个基准测试的 nDGC@10)<br></strong></th></tr></thead><tr id=\"9199b56b-0513-4c99-a2a7-29cde915c3b9\"><td id=\"<\\ml\" class=\"\">128</td><td id=\"<NYX\" class=\"\">0.565</td></tr><tr id=\"af4d45fc-ebf4-4e1f-b5b0-1807a1cb889b\"><td id=\"<\\ml\" class=\"\">96</td><td id=\"<NYX\" class=\"\">0.558</td></tr><tr id=\"ecf7eac9-5c56-47e6-ab27-0ddb4659e263\"><td id=\"<\\ml\" class=\"\">64</td><td id=\"<NYX\" class=\"\">0.556</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Performance-on-selected-BEIR-benchmarks.svg\" class=\"kg-image\" alt=\"BEIR 基准测试的条形图，突出显示从 nfcorpus 到 msmarco 等数据集的分数，其中 jina-colbert-v2.64 表现出色。\" loading=\"lazy\" width=\"732\" height=\"538\"><figcaption><span style=\"white-space: pre-wrap;\">不同输出维度下的 Jina ColBERT v2 性能。</span></figcaption></figure><p>减小输出向量的大小可以节省空间，并加快需要比较不同向量或测量向量之间距离的应用程序（如基于向量的信息检索）的速度。</p><p>这带来了显著的成本影响，即使仅考虑存储成本的减少。例如，使用 <a href=\"https://cloud.qdrant.io/calculator?ref=jina-ai-gmbh.ghost.io\">Qdrant 的云成本计算器</a>，在 AWS 上存储 1 亿个文档（每个文档具有 128 维向量）的<a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=128&ref=jina-ai-gmbh.ghost.io\">预估成本为每月 1,319.24 美元</a>。而在 64 维度下，这个成本<a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=64&ref=jina-ai-gmbh.ghost.io\">降至 659.62 美元</a>。</p><h2 id=\"getting-started-with-jina-colbert-v2\">开始使用 Jina ColBERT v2</h2><p>Jina ColBERT v2 可通过 Jina Search Foundation API、<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS marketplace</a> 和 <a href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\">Azure</a> 获取。它也可在 <a href=\"https://huggingface.co/jinaai/jina-colbert-v2?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a> 上获得，但仅供<em>非商业用途</em>（<a href=\"https://www.creativecommons.org/licenses/by-nc/4.0/deed.en?ref=jina-ai-gmbh.ghost.io\">CC BY-NC-4.0</a>）。</p><h3 id=\"via-jina-search-foundation-api\">通过 Jina Search Foundation API</h3><h4 id=\"for-embedding\">用于嵌入</h4><p>以下 <code>curl</code> 命令展示了如何通过 Jina Embeddings API 指定输入和选项来获取 <code>jina-colbert-v2</code> 的文档嵌入。要获取您所需大小的向量，请在 <code>dimensions</code> 参数中指定 128 或 64。此参数是可选的，默认值为 128。</p><p>如果输入文档超过 8192 个标记，将被截断。</p><p>在授权头中指定您的 Jina API 密钥 <code>Authorization: Bearer &lt;YOUR JINA API KEY&gt;</code>：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # 或 64 用于半尺寸向量\n\t\"input_type\": \"document\", # 查询嵌入见下文\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your document text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each text can be up to 8192 tokens long\"\n    ]}'\n</code></pre><p>要获取查询嵌入，请将 <code>input_type</code> 参数设置为 <code>query</code> 而不是 <code>document</code>。请注意，查询的大小限制比文档更严格。它们将在 32 个标记处被截断。查询编码将<em>始终</em>返回 32 个标记，如果少于 32 个标记，则包括填充的嵌入。</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # 或 64 用于半尺寸向量\t\n\t\"input_type\": \"query\", # 查询嵌入必须指定此项\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your query text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each query text can be up to 32 tokens long\"\n    ]}'\n</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Multimodal, bilingual long-context embeddings for your search and RAG.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"for-reranking\">用于重排序</h4><p>要通过 Jina Reranker API 使用 <code>jina-colbert-v2</code>，输入一个查询和多个文档并获取可排序的匹配分数，请按如下方式构造您的请求：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/rerank \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n      \"model\": \"jina-colbert-v2\",\n      \"query\": \"What is the population of Berlin?\",\n      \"top_n\": 3,\n      \"documents\": [\n        \"Berlin's population grew by 0.7 percent in 2023 compared with the previous year. Accordingly, around 27,300 more residents lived in Berlin at the end of the last year than in 2022. Those of 30 to under 40 years old form the numerically largest age group. With roughly 881,000 foreign residents from around 170 nations and an average age of the population of 42.5 years old.\",\n        \"Mount Berlin is a glacier-covered volcano in Marie Byrd Land, Antarctica, 100 kilometres (62 mi) from the Amundsen Sea. It is a roughly 20-kilometre-wide (12 mi) mountain with parasitic vents that consists of two coalesced volcanoes: Berlin proper with the 2-kilometre-wide (1.2 mi) Berlin Crater and Merrem Peak with a 2.5-by-1-kilometre-wide (1.55 mi × 0.62 mi) crater, 3.5 kilometres (2.2 mi) away from Berlin.\",\n        \"Population as of 31.12.2023 by nationality and federal states Land\\\\tTotal\\\\tGermans\\\\tForeigners\\\\tincluding EU-states number\\\\t%\\\\tnumber\\\\t%\",\n        \"The urban area of Berlin has a population of over 4.5 million and is therefore the most populous urban area in Germany. The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region, and the sixth-biggest metropolitan region by GDP in the European Union.\",\n        \"Irving Berlin (born Israel Beilin) was an American composer and songwriter. His music forms a large part of the Great American Songbook. Berlin received numerous honors including an Academy Award, a Grammy Award, and a Tony Award.\",\n        \"Berlin is a town in the Capitol Planning Region, Connecticut, United States. The population was 20,175 at the 2020 census.\",\n        \"Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\",\n        \"Berlin, Berlin ist eine für die ARD produzierte Fernsehserie, die von 2002 bis 2005 im Vorabendprogramm des Ersten ausgestrahlt wurde. Regie führten unter anderem Franziska Meyer Price, Christoph Schnee, Sven Unterwaldt Jr. und Titus Selge.\"\n        ]\n    }'</code></pre><p>注意 <code>top_n</code> 参数，它指定了您想要检索的文档数量。例如，如果您的应用程序只使用最佳匹配，请将 <code>top_n</code> 设置为 1。</p><p>要获取 Python 和其他编程语言及框架的代码片段，请访问 <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina AI Embeddings API 页面</a>，或在 <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina Reranker API 页面</a>的下拉菜单中选择 <code>jina-colbert-v2</code>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reranker API</div><div class=\"kg-bookmark-description\">Maximize the search relevancy and RAG accuracy at ease.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-reranker-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"via-stanford-colbert\">通过 Stanford ColBERT</h3><p>你也可以在 Stanford ColBERT 库中使用 Jina ColBERT v2 作为 <a href=\"https://github.com/stanford-futuredata/ColBERT?ref=jina-ai-gmbh.ghost.io\">ColBERT v2</a> 的直接替代品。只需指定 <code>jinaai/jina-colbert-v2</code> 作为模型来源：</p><pre><code class=\"language-python\">from colbert.infra import ColBERTConfig\nfrom colbert.modeling.checkpoint import Checkpoint\n\nckpt = Checkpoint(\"jinaai/jina-colbert-v2\", colbert_config=ColBERTConfig())\ndocs = [\"Your list of texts\"] \nquery_vectors = ckpt.queryFromText(docs)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">要使用上述代码，你必须安装 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code>。</div></div><h3 id=\"via-ragatouille\">通过 RAGatouille</h3><p>Jina ColBERT v2 同样集成到了 <a href=\"https://github.com/AnswerDotAI/RAGatouille?ref=jina-ai-gmbh.ghost.io\">RAGatouille</a> 中。你可以通过 <code>RAGPretrainedModel.from_pretrained()</code> 方法下载和使用它：</p><pre><code class=\"language-python\">from ragatouille import RAGPretrainedModel\n\nRAG = RAGPretrainedModel.from_pretrained(\"jinaai/jina-colbert-v2\")\ndocs = [\"Your list of texts\"]\nRAG.index(docs, index_name=\"your_index_name\")\nquery = \"Your query\"\nresults = RAG.search(query)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">要使用上述代码，你必须安装 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code>。</div></div><h3 id=\"via-qdrant\">通过 Qdrant</h3><p>从 1.10 版本开始，Qdrant 添加了对多向量和延迟交互模型的<a href=\"https://qdrant.tech/blog/qdrant-1.10.x/?ref=jina-ai-gmbh.ghost.io\">支持</a>。无论是本地还是托管的云版本，Qdrant 引擎的现有用户都可以通过 Qdrant 的客户端直接集成 <code>jina-colbert-v2</code>。</p><p><strong>使用 MAX_SIM 操作创建新的 Collection</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nqdrant_client.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config={\n        \"colbert\": models.VectorParams(\n            size=128,\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM\n            ),\n        )\n    }\n)</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">正确设置 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">multivector_config</code> 参数对在 Qdrant 中使用 ColBERT 风格的模型至关重要。</div></div><p><strong>向多向量集合插入文档</strong></p><pre><code class=\"language-Python\">import requests\nfrom qdrant_client import QdrantClient, models\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\ndata = {\n    'model': 'jina-colbert-v2',\n    'input_type': 'query',\n    'embedding_type': 'float',\n    'input': [\n        'Your text string goes here',\n        'You can send multiple texts',\n        'Each text can be up to 8192 tokens long'\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nrows = response.json()[\"data\"]\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nfor i, row in enumerate(rows):\n    qdrant_client.upsert(\n        collection_name=\"{collection_name}\",\n        points=[\n            models.PointStruct(\n                id=i,  \n                vector=row[\"embeddings\"],  \n                payload={\"text\": data[\"input\"][i]} \n            )\n        ],\n    )</code></pre><p><strong>查询集合</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\nimport requests\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\n\ndata = {\n    'model': 'jina-colbert-v2',\n    \"input_type\": \"query\",\n    \"embedding_type\": \"float\",\n    \"input\": [\n        \"how many tokens in an input do Jina AI's embedding models support?\"\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nvector = response.json()[\"data\"][0][\"embeddings\"]\n\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nresults = qdrant_client.query_points(\n    collection_name=\"{collection_name}\",\n    query=vector,\n)\n\nprint(results)</code></pre><h3 id=\"summary\">总结</h3><p>Jina ColBERT v2（<code>jina-colbert-v2</code>）在 <code>jina-colbert-v1-en</code> 的高性能基础上，将其功能扩展到了更广泛的全球语言。通过支持多种嵌入维度，<code>jina-colbert-v2</code> 允许用户根据具体使用场景调整精度和效率的平衡，这可能会在时间和计算成本方面带来显著节省。</p><p>该模型将所有这些功能整合到一个价格具有竞争力的包中，可通过直观的 Web API 访问，并且与支持 HTTP 请求的任何计算框架兼容。<a href=\"https://jina.ai/?sui=&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">立即试用</a>，获得 100 万个免费 token，看看它如何提升你的应用和流程。</p>",
  "comment_id": "66cd8fc6e84873000133d63d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-08-27T10:35:18.000+02:00",
  "updated_at": "2024-09-09T07:43:38.000+02:00",
  "published_at": "2024-08-30T09:19:58.000+02:00",
  "custom_excerpt": "Jina ColBERT v2 supports 89 languages with superior retrieval performance, user-controlled output dimensions, and 8192 token-length. ",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking/",
  "excerpt": "Jina ColBERT v2 支持 89 种语言，具有卓越的检索性能、用户可控的输出维度以及 8192 的 token 长度。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dark-themed coding interface displaying English and Japanese characters with \"JINA COLBERT V2\" highlighted in the center.",
  "feature_image_caption": null
}