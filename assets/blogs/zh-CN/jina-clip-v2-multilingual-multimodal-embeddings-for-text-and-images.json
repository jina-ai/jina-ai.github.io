{
  "slug": "jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images",
  "id": "673cc4a7a7c46d00015cf1f5",
  "uuid": "6ca44950-b989-494a-b587-70847f24edd2",
  "title": "Jina CLIP v2：用于文本和图像的多语言多模态嵌入",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-clip-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">我们正在通过开源和开放科学推进和普及人工智能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-11.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-clip-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?sui=&model=jina-clip-v2&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - 您的搜索底座，超级加强版</div><div class=\"kg-bookmark-description\">同类最佳的嵌入、重排序器、LLM 阅读器、网页抓取器、分类器。适用于多语言和多模态数据的最佳搜索 AI。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">您的搜索底座，超级加强版</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> API 可在\"Embeddings\"标签页下使用。</span></p></figcaption></figure><p>多模态嵌入通过统一的表示方式实现了跨不同模态数据的搜索和理解。它们是神经信息检索和多模态生成式 AI 应用的基础。今天，我们很高兴发布 <code>jina-clip-v2</code>，这是一个基于 <code>jina-clip-v1</code> 和我们最近发布的 <code>jina-embeddings-3</code> 构建的新型通用多语言多模态嵌入，具有以下几个关键改进：</p><ul><li><strong>性能提升</strong>：v2 在文本-图像和文本-文本检索任务中相比 v1 提升了 3% 的性能。与 v1 类似，v2 的文本编码器可以作为有效的多语言长文本密集检索器。它的性能与我们的前沿模型 <code>jina-embeddings-v3</code>（目前在 MTEB 上参数量低于 1B 的最佳多语言嵌入）相当。</li><li><strong>多语言支持</strong>：以 <code>jina-embeddings-v3</code> 作为文本塔，<code>jina-clip-v2</code> 支持 89 种语言的多语言图像检索，在多语言图像检索任务上相比 <code>nllb-clip-large-siglip</code> 提升了高达 4% 的性能。</li><li><strong>更高图像分辨率</strong>：v2 现在支持 512x512 的输入图像分辨率，相比 v1 的 224x224 有显著提升。这种更高的分辨率能够更好地处理细节图像，提升特征提取能力，并更准确地识别细粒度视觉元素。</li><li><strong>套娃式表示</strong>：v2 允许用户将文本和图像嵌入的输出维度从 1024 截断到 64，在保持强大性能的同时减少存储和处理开销。</li></ul><h2 id=\"model-architecture\">模型架构</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--35-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p><code>jina-clip-v2</code> 是一个 0.9B 参数的 CLIP 风格模型，它结合了两个强大的编码器：文本编码器 <code>Jina XLM-RoBERTa</code>（<code>jina-embeddings-v3</code> 的骨干网络）和视觉编码器 <code>EVA02-L14</code>（由 BAAI 开发的高效视觉 Transformer）。这些编码器经过联合训练，创建图像和文本的对齐表示。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Text Encoder</th>\n<th>Image Encoder</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base Model</td>\n<td>Jina XLM-RoBERTa</td>\n<td>EVA02-L</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>561M</td>\n<td>304M</td>\n</tr>\n<tr>\n<td>Input Specification</td>\n<td>8,192 tokens (max)</td>\n<td>512×512 pixels</td>\n</tr>\n<tr>\n<td>Min Output Dimensions</td>\n<td>64</td>\n<td>64</td>\n</tr>\n<tr>\n<td>Max Output Dimensions</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Layers</td>\n<td>24</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Attention Mechanism</td>\n<td>FlashAttention2</td>\n<td>xFormers</td>\n</tr>\n<tr>\n<td>Pooling Strategy</td>\n<td>Mean pooling</td>\n<td>CLS pooling</td>\n</tr>\n<tr>\n<td>Additional Features</td>\n<td>89 languages supported</td>\n<td>Patch size 14x14</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"cross-modal-retrieval-performance\">跨模态检索性能</h2><p>Jina CLIP v2 支持 89 种语言，在主要语言（包括阿拉伯语、中文、英语、法语、德语、日语、俄语和西班牙语）中都表现出色。在多语言图像检索基准测试中，它的性能能够匹配或超过 <a href=\"https://huggingface.co/visheratin/nllb-clip-large-siglip?ref=jina-ai-gmbh.ghost.io\">NLLB-CLIP-SigLIP</a>，后者是一个稍大的（1.3B，比 <code>jina-clip-v2</code> 大 44%）最先进的 CLIP 风格模型，使用来自 NLLB 模型的预训练文本编码器。</p><h3 id=\"english-only-text-and-images\">仅英语文本和图像</h3><p>在标准跨模态检索基准（Flickr30k 和 COCO）上，<code>jina-clip-v2</code> 展现了全面的性能提升。它在 Flickr30k 图像到文本检索上达到了 98.0% 的最先进性能，超过了其前身和 NLLB-CLIP-SigLIP。该模型在所有检索场景中都显示出一致的提升，在 COCO 图像到文本检索上相比 v1 提升了高达 3.3%，同时在不同基准和模态方向上保持与 NLLB-CLIP-SigLIP 的竞争性能。</p><p><strong>Flickr30k Recall@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>98.0</td>\n<td>+1.7%</td>\n<td>+0.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>96.4</td>\n<td>-</td>\n<td>-0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>97.1</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>89.8</td>\n<td>+0.9%</td>\n<td>-2.6%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>89.0</td>\n<td>-</td>\n<td>-3.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>92.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>COCO Recall@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>81.5</td>\n<td>+3.3%</td>\n<td>+2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>78.9</td>\n<td>-</td>\n<td>-0.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>79.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>68.4</td>\n<td>+2.9%</td>\n<td>-3.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>66.5</td>\n<td>-</td>\n<td>-6.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>70.8</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"multilingual-text-and-images\">多语言文本和图像</h3><p>在多语言跨模态基准测试中，<code>jina-clip-v2</code> 展现了强大的性能，特别是在图像到文本检索方面表现出色，在所有数据集上都优于 NLLB-SigLIP，在 Crossmodal 3600 上提升高达 3.8%。虽然 NLLB-SigLIP 在文本到图像检索能力上略强，但性能差距仍然很小，通常在 3% 以内。</p><p><strong>图像到文本召回率@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>基准测试</th>\n<th>模型</th>\n<th>得分</th>\n<th>相比 NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>83.23</td>\n<td>+3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>80.16</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>86.03</td>\n<td>+0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.37</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.98</td>\n<td>+0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.41</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>文本到图像召回率@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>基准测试</th>\n<th>模型</th>\n<th>得分</th>\n<th>相比 NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>81.43</td>\n<td>-0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>82.07</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>84.87</td>\n<td>-3.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.60</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.03</td>\n<td>-3.0%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.63</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"text-only-dense-retriever-performance\">纯文本密集检索器性能</h2><p>与其前代产品类似，<code>jina-clip-v2</code> 的文本编码器可以作为一个有效的多语言密集检索器。在综合性的多语言 MTEB 基准测试中，它表现出色，在检索任务中达到 69.86%，在语义相似度任务中达到 67.77%。这些结果展示了它的多功能性，与我们专门的文本嵌入模型 <code>jina-embeddings-v3</code> 相比表现具有竞争力：</p><table>\n<thead>\n<tr>\n<th>任务</th>\n<th>模型</th>\n<th>得分</th>\n<th>相比 v3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>检索</td>\n<td>jina-clip-v2</td>\n<td>69.86</td>\n<td>-3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>72.59</td>\n<td>-</td>\n</tr>\n<tr>\n<td>语义相似度</td>\n<td>jina-clip-v2</td>\n<td>67.77</td>\n<td>-2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>69.81</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p>在英语任务中，<code>jina-clip-v2</code> 相比其前代产品和 NLLB-SigLIP 都显示出持续的改进，在检索性能方面表现尤为突出（几乎是 NLLB-SigLIP 分数的两倍）。</p><table>\n<thead>\n<tr>\n<th>任务</th>\n<th>模型</th>\n<th>得分</th>\n<th>相比 v1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>STS</td>\n<td>jina-clip-v2</td>\n<td>81.29</td>\n<td>+0.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>80.92</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>74.65</td>\n<td>-</td>\n</tr>\n<tr>\n<td>检索</td>\n<td>jina-clip-v2</td>\n<td>49.33</td>\n<td>+2.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>48.33</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>24.92</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"matryoshka-representation-performance\">套娃表示性能</h2><p>文本和图像编码器都支持 MRL，它们的输出维度可以被截断至 64 维度的同时保持强劲的性能。我们的嵌入截断评估显示出显著的压缩潜力。即使是激进的 75% 维度削减也能在文本、图像和跨模态任务中保持超过 99% 的性能。</p><h3 id=\"image-classification\">图像分类</h3><p>在 37 个多样化的图像分类基准测试中，图像编码器表现出对维度截断的强大适应性。从 1024 维压缩到 64 维（94% 的压缩率）仅导致 top-5 准确率下降 8%，top-1 准确率下降 12.5%，突显了其在最小性能损失下高效部署的潜力。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/accuracy_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption><span style=\"white-space: pre-wrap;\">对于</span><b><strong style=\"white-space: pre-wrap;\">图像分类</strong></b><span style=\"white-space: pre-wrap;\">，我们使用了 </span><a href=\"https://github.com/google-research/task_adaptation?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">VTAB 数据集</span></a><span style=\"white-space: pre-wrap;\">中的 19 个基准测试、</span><a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">VOC 2007</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://www.tensorflow.org/datasets/catalog/sun397?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">SUN397</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://cs.stanford.edu/~acoates/stl10/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">STL10</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Rendered SST2</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://objectnet.dev/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ObjectNet</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://github.com/cvdfoundation/mnist?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">MNIST</span></a><span style=\"white-space: pre-wrap;\">、德国交通标志识别基准（</span><a href=\"https://benchmark.ini.rub.de/gtsrb_dataset.html?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">GTSRB</span></a><span style=\"white-space: pre-wrap;\">）、飞机细粒度视觉分类（</span><a href=\"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">FGVC-Aircraft</span></a><span style=\"white-space: pre-wrap;\">）、</span><a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">FER 2013</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://github.com/openai/CLIP/blob/main/data/country211.md?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Country211</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://www.tensorflow.org/datasets/catalog/cars196?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Cars196</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://github.com/hendrycks/natural-adv-examples?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet-A、ImageNet-O、</span></a><a href=\"https://huggingface.co/datasets/ILSVRC/imagenet-1k?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet1k</span></a><span style=\"white-space: pre-wrap;\">、</span><a href=\"https://github.com/HaohanWang/ImageNet-Sketch?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet Sketch</span></a><span style=\"white-space: pre-wrap;\">和</span><a href=\"https://imagenetv2.org/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet v2</span></a><span style=\"white-space: pre-wrap;\">。</span></figcaption></figure><h3 id=\"cross-modal-retrieval\">跨模态检索</h3><p>尽管维度大幅减少了 94%（降至仅 64 维），使用截断后的图像和文本嵌入进行的跨模态检索仍然表现出色，保持了 93% 的图像到文本和 90% 的文本到图像性能。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/crossmodal_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption><span style=\"white-space: pre-wrap;\">我们使用了六个基准测试，其中三个是多语言的：</span><a href=\"https://google.github.io/crossmodal-3600/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Crossmodal-3600</span></a><span style=\"white-space: pre-wrap;\">（36 种语言）、</span><a href=\"https://shannon.cs.illinois.edu/DenotationGraph/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">flickr30k</span></a><span style=\"white-space: pre-wrap;\">（仅英语）、</span><a href=\"https://hockenmaier.cs.illinois.edu/8k-pictures.html?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">flickr8k</span></a><span style=\"white-space: pre-wrap;\">（仅英语）、</span><a href=\"https://arxiv.org/abs/1504.00325?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">MS COCO Captions</span></a><span style=\"white-space: pre-wrap;\">（仅英语）、</span><a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Multilingual MS COCO Captions</span></a><span style=\"white-space: pre-wrap;\">（10 种语言）、</span><a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">XTD 200</span></a><span style=\"white-space: pre-wrap;\">（27 种语言）</span></figcaption></figure><h3 id=\"text-only-retrieval\">纯文本检索</h3><p>在<strong>仅英语的 MTEB 基准测试</strong>中，64 维文本嵌入（从 1024 维压缩而来）很好地保持了语义相似性，仅下降 2.1%，而检索性能则适度降低了 17.5%。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/mteb_performance.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"></figure><h2 id=\"getting-started\">快速开始</h2><h3 id=\"via-api\">通过 API</h3><p>以下代码演示了如何使用 Python 的 <code>requests</code> 生成嵌入。传入文本字符串和 base64 图像或 URL，以及所需的维度大小（默认 1024，下面示例中为 768）。</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-Python\">import requests\nimport numpy as np\nfrom numpy.linalg import norm\n\ncos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n\nurl = 'https://api.jina.ai/v1/embeddings'\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Authorization': 'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'\n}\n\ndata = {\n  'input': [\n     {\"text\": \"Bridge close-shot\"},\n     {\"url\": \"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s\"}],\n  'model': 'jina-clip-v2',\n  'encoding_type': 'float',\n  'dimensions': '768' \n}\n\nresponse = requests.post(url, headers=headers, json=data)\nsim = cos_sim(np.array(response.json()['data'][0]['embedding']), np.array(response.json()['data'][1]['embedding']))\nprint(f\"Cosine text&lt;-&gt;image: {sim}\")</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">请记得将 &lt;YOUR_JINA_AI_API_KEY&gt; 替换为已激活的 Jina API 密钥。您可以</span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">在这里获取一个包含一百万个免费令牌的 API 密钥。</span></a></p></figcaption></figure><h3 id=\"image-tokens-pricing\">图像令牌定价</h3><p>我们的 API 会计算文本和图像令牌。对于图像，令牌消耗基于覆盖整个图像区域所需的 512x512 像素切片数量。每个切片需要 4,000 个令牌来处理，包括部分填充的切片。<strong>为了获得最佳成本效益，我们建议 API 用户在发送请求前将图像调整为 512x512。</strong></p><table>\n<thead>\n<tr>\n<th>图像分辨率</th>\n<th>所需切片数</th>\n<th>令牌成本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>512x512</td>\n<td>1</td>\n<td>4,000</td>\n</tr>\n<tr>\n<td>720x720</td>\n<td>4</td>\n<td>16,000</td>\n</tr>\n<tr>\n<td>1080x1080</td>\n<td>9</td>\n<td>36,000</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--37-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">对于方形图像，调整为 512x512 可获得最佳成本效益。对于需要保持宽高比的任务，将最长边缩放到 512，居中图像，并用黑色填充。对于一般用途，直接调整为 512x512 效果很好。</span></figcaption></figure><h3 id=\"via-csp-marketplaces\">通过 CSP 市场</h3><p>Jina CLIP v2 可直接在 AWS、Azure 和 GCP 上使用，价格以各平台列出的为准。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-bfbctuqmky676?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina CLIP v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-10.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-9.ico\" alt=\"\"></div></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://console.cloud.google.com/marketplace/browse?q=jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Cloud console</div><div class=\"kg-bookmark-description\">在 Google Cloud Marketplace 上明智消费、快速采购并利用 Google Cloud 承诺的支出。浏览目录中超过 2000 个优化运行在 Google Cloud 上的 SaaS、VM、开发堆栈和 Kubernetes 应用。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/default.png\" alt=\"\"></div></div></a></figure><h3 id=\"via-vectordb\"><strong>通过 VectorDB</strong></h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">构建智能 AI 的向量数据库 | Pinecone</div><div class=\"kg-bookmark-description\">在毫秒内搜索数十亿个项目中与任何对象相似的匹配。这是下一代搜索，只需一个 API 调用即可。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-3.png\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://weaviate.io/developers/weaviate/model-providers/jinaai/embeddings-multimodal?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">多模态嵌入 | Weaviate</div><div class=\"kg-bookmark-description\">Weaviate 与 Jina AI 的 API 集成允许您直接从 Weaviate 访问其模型的功能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-12.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Weaviate</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/provider_integrations_jinaai.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant 是一个用 Rust 编写的开源向量数据库和向量搜索引擎。它提供快速且可扩展的向量相似度搜索服务，并具有便捷的 API。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-4.png\" alt=\"\"><span class=\"kg-bookmark-author\">edit</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">结论</h2><p>在 6 月发布的 <code>jina-clip-v1</code>（将 OpenAI 的 CLIP 模型文本输入扩展到 8,192 个 token）和前沿多语言模型 <code>jina-embeddings-v3</code> 的基础上，<code>jina-clip-v2</code> 带来了三个主要进展：支持 89 种语言的多语言功能、提升到 512x512 的图像分辨率，以及用于更多截断嵌入的套娃表示学习。</p><p>类 CLIP 模型已经成为通用多模态应用的基础。通过 <code>jina-clip-v2</code>，我们将这些功能提升到了新的水平，打破语言障碍，实现更准确的跨模态理解和检索。我们相信这次发布兑现了承诺，让全球开发者能够使用更强大、更易用的多模态搜索和检索功能。</p>",
  "comment_id": "673cc4a7a7c46d00015cf1f5",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/11/clipv2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-11-19T18:02:31.000+01:00",
  "updated_at": "2024-11-21T17:29:45.000+01:00",
  "published_at": "2024-11-21T17:29:45.000+01:00",
  "custom_excerpt": "Jina-CLIP v2, a 0.9B multimodal embedding model with multilingual support of 89 languages, high image resolution at 512x512, and Matryoshka representations.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/",
  "excerpt": "Jina-CLIP v2，这是一个 0.9B 参数的多模态嵌入模型，支持 89 种语言的多语言处理，可处理 512x512 的高分辨率图像，并具有俄罗斯套娃式表征能力。",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}