{
  "slug": "jina-reranker-m0-multilingual-multimodal-document-reranker",
  "id": "67ea5eb45dcba60001c30f0a",
  "uuid": "b710acf7-f8e7-4588-bc54-30a1fbe42eca",
  "title": "jina-reranker-m0：多语言多模态文档重排模型",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-reranker-m0\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-reranker-m0 · Hugging Face</div><div class=\"kg-bookmark-description\">我们正在通过开源和开放科学推进和民主化人工智能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-34.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-reranker-m0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>今天我们发布了 <code>jina-reranker-m0</code>，这是我们新的多语言多模态重排模型，用于<strong>跨多语言的视觉文档排序：</strong>它接受一个查询以及一系列包含丰富视觉内容的文档图像，包括带有文本、图表、表格、信息图表的页面，以及跨越多个领域和超过 29 种语言的各种布局。它输出一个按照与输入查询相关性排序的文档列表。与 <code>jina-reranker-v2-base-multilingual</code> 相比，<code>jina-reranker-m0</code> 在多语言内容、长文档和代码搜索任务的文本重排方面也有所改进。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/all-benchmarks--6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1714\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/all-benchmarks--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/all-benchmarks--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/04/all-benchmarks--6-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/04/all-benchmarks--6-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-reranker-m0</code> 在 ViDoRe、MBEIR 和 Winoground 视觉检索基准测试上的表现展示了其在跨多个领域和语言的多模态检索任务中的能力。每个点代表不同类型/任务的视觉文档的性能得分。箱线图展示了这些得分的分布，高亮数字表示平均（均值）性能。完整的基准测试结果请参见本文附录。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/model-perf-boxplot--13-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"2338\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/model-perf-boxplot--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/model-perf-boxplot--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/04/model-perf-boxplot--13-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/04/model-perf-boxplot--13-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">这个箱线图展示了 </span><code>jina-reranker-m0</code><span style=\"white-space: pre-wrap;\"> 在四个纯文本重排基准测试中的表现。每个基准测试可能包含多个数据集、语言或任务，由箱线图内的单个点表示。箱线图显示了这些得分的分布，高亮数字显示平均（均值）性能。虽然大多数基准测试使用 NDCG@10 作为性能指标，但 MKQA 使用的是 recall@10，因为 MKQA 的标注数据不支持 NDCG 计算（官方评估使用 recall，通过启发式方法确定文档相关性）。完整的基准测试结果可在本文附录中找到。</span></figcaption></figure><h2 id=\"new-architecture\">新架构</h2><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/2.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-reranker-m0</code> 的架构基于 Qwen2-VL-2B，包含 21 亿参数。该模型通过评估文档的视觉和文本元素与查询的关系，使用成对比较方法高效地对文档进行排序。</span></figcaption></figure><p>与 <code>jina-reranker-v2-base-multilingual</code> 不同，<code>jina-reranker-m0</code> 从经典的交叉编码器架构转向了仅解码器的视觉语言模型。它利用了预训练的 Qwen2-VL 的视觉编码器和投影器，使用 LoRA 微调了其 LLM，并后训练了一个 MLP 来生成衡量查询-文档相关性的排序 logits。这提供了一个针对排序任务优化的<strong>判别模型</strong>。</p>\n<!--kg-card-begin: html-->\n<table><thead>\n  <tr>\n    <th></th>\n    <th><code>jina-reranker-m0</code></th>\n    <th><code>jina-reranker-v2</code></th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td>架构</td>\n    <td>视觉语言模型</td>\n    <td>交叉编码器</td>\n  </tr>\n  <tr>\n    <td>基础模型</td>\n    <td>Qwen2-VL-2B</td>\n    <td>Jina-XLM-RoBERTa</td>\n  </tr>\n  <tr>\n    <td>参数量</td>\n    <td>2.4 B</td>\n    <td>278 M</td>\n  </tr>\n  <tr>\n    <td>最大上下文长度（查询 + 文档）</td>\n    <td>10,240</td>\n    <td>8,192</td>\n  </tr>\n  <tr>\n    <td>最大图像块（动态分辨率）</td>\n    <td>768 × 28 × 28</td>\n    <td>❌</td>\n  </tr>\n  <tr>\n    <td>多语言支持</td>\n    <td>✅</td>\n    <td>✅</td>\n  </tr>\n  <tr>\n    <td>支持的任务</td>\n    <td>Text2Text, Text2Image, Image2Text, Text2Mixed</td>\n    <td>Text2Text</td>\n  </tr>\n</tbody></table>\n<!--kg-card-end: html-->\n<p>这种新架构使 <code>jina-reranker-m0</code> 能够处理多达 32K 个 token，无缝地结合视觉和文本输入。该模型支持从最小 56×56 像素到 4K 分辨率的图像。在处理图像时，ViT 和投影器将相邻的 2×2 token 压缩为单个视觉 token 作为 LLM 输入。特殊 token 如 <code>&lt;|vision_start|&gt;</code> 和 <code>&lt;|vision_end|&gt;</code> 清晰地标记了视觉 token 的边界，使语言模型能够正确处理视觉信息并执行结合视觉和文本元素的复杂多模态推理。</p><p>这种架构还有效地解决了之前困扰 <code>jina-clip-v1</code> 和 <code>jina-clip-v2</code> 等模型的<a href=\"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models\">模态差距问题</a>。以前，图像会在表示空间中聚集在其他图像附近，而文本会聚集在其他文本附近，造成断开。这意味着当你的候选文档同时包含图像和文本时，使用文本查询检索图像会有问题。使用 <code>jina-reranker-m0</code>，你现在可以一起对图像和文档进行排序而无需担心这个差距，创造真正统一的多模态搜索体验。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/3.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">在多模态检索系统中，\"模态差距\"指的是模型对文本到文本相似度与文本到图像相似度的评分差异。看左图（</span><code>jina-clip-v2</code><span style=\"white-space: pre-wrap;\">），两个分布之间有明显的分离：文本到文本相似度分布（红色）在 0.35 左右达到峰值。文本到图像相似度（蓝色）在 0.65-0.7 左右达到峰值。这种显著的分离表明存在较大的模态差距 - 模型对文本到文本和文本到图像对的评分范围从根本上不同。这使得直接比较跨模态的分数变得困难。在没有模态差距的系统中（例如 `），我们期望这些分布在很大程度上重叠，这意味着模型仅基于相关性而不是模态类型来对这两种类型的对进行相似范围的评分。</span></figcaption></figure><p>值得注意的是，我们的训练限制在最多 10K 输入 token，每个图像最多 768 个 token（在 <code>&lt;|vision_start|&gt;</code> 和 <code>&lt;|vision_end|&gt;</code> 标记之间）。此外，我们没有专门训练模型用于 <code>image-to-image</code>、<code>image-to-multimodal</code> 或 <code>text-to-multimodal</code> 重排任务。在这种情况下，\"多模态\"指的是输入中的单个文档同时包含图像和文本 token。查看查询和文档中图像和文本 token 的所有可能组合，我们可以在下表中总结 <code>jina-reranker-m0</code> 支持的完整任务范围。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading--96-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/Heading--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/Heading--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading--96-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> 支持广泛的查询和文档输入组合用于重排序。得益于大量训练，它在文本到文本、文本到图像、图像到文本和文本到混合单模态任务中都达到了最先进的性能。该模型还以零样本方式处理其他输入组合 - 虽然我们没有专门针对这些任务进行训练，但模型架构可以适应这些token组合。</span></figcaption></figure><p>在我们的测试中，我们发现一些证据表明该模型可以推广到这些未经训练的排序任务，但这些领域的任何效果都应被视为模型零样本迁移能力或意外训练副作用的结果。我们尚未对模型在这些任务上的表现进行严格评估，并计划在未来的研究中更深入地探索这些能力。</p><h2 id=\"getting-started\">入门</h2><h3 id=\"via-api\">通过 API</h3><p>下面的代码展示了如何计算查询 <code>\"small language model data extraction\"</code> 与一系列图像和文本文档之间的相关性分数。你可以传入文本字符串、base64 编码的图像或图像 URL。新用户可以获得一个包含 100 万个免费 token 的 Jina API 密钥。虽然我们的 API 不支持使用图像作为查询，但当通过 Hugging Face Transformers 库访问模型时，你可以使用图像作为查询。</p><pre><code class=\"language-bash\">curl -X POST \\\n  https://api.jina.ai/v1/rerank \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer JINA_API_KEY\" \\\n  -d '{\n  \"model\": \"jina-reranker-m0\",\n  \"query\": \"small language model data extraction\",\n  \"documents\": [\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/handelsblatt-preview.png\"\n    },\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\"\n    },\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/wired-preview.png\"\n    },\n    {\n      \"text\": \"We present ReaderLM-v2, a compact 1.5 billion parameter language model designed for efficient web content extraction. Our model processes documents up to 512K tokens, transforming messy HTML into clean Markdown or JSON formats with high accuracy -- making it an ideal tool for grounding large language models. The models effectiveness results from two key innovations: (1) a three-stage data synthesis pipeline that generates high quality, diverse training data by iteratively drafting, refining, and critiquing web content extraction; and (2) a unified training framework combining continuous pre-training with multi-objective optimization. Intensive evaluation demonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger models by 15-20% on carefully curated benchmarks, particularly excelling at documents exceeding 100K tokens, while maintaining significantly lower computational requirements.\"\n    },\n    {\n      \"image\": \"https://jina.ai/blog-banner/using-deepseek-r1-reasoning-model-in-deepsearch.webp\"\n    },\n    {\n      \"text\": \"数据提取么？为什么不用正则啊，你用正则不就全解决了么？\"\n    },\n    {\n      \"text\": \"During the California Gold Rush, some merchants made more money selling supplies to miners than the miners made finding gold.\"\n    },\n    {\n      \"text\": \"Die wichtigsten Beiträge unserer Arbeit sind zweifach: Erstens führen wir eine neuartige dreistufige Datensynthese-Pipeline namens Draft-Refine-Critique ein, die durch iterative Verfeinerung hochwertige Trainingsdaten generiert; und zweitens schlagen wir eine umfassende Trainingsstrategie vor, die kontinuierliches Vortraining zur Längenerweiterung, überwachtes Feintuning mit spezialisierten Kontrollpunkten, direkte Präferenzoptimierung (DPO) und iteratives Self-Play-Tuning kombiniert. Um die weitere Forschung und Anwendung der strukturierten Inhaltsextraktion zu erleichtern, ist das Modell auf Hugging Face öffentlich verfügbar.\"\n    }\n  ],\n  \"return_documents\": false\n}'</code></pre><p>响应如下所示，其中第一个结果 <code>index=1</code> 对应我们的 ReaderLM-v2 <a href=\"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\">论文截图</a>。</p><pre><code class=\"language-json\">{\"model\":\"jina-reranker-m0\",\"usage\":{\"total_tokens\":2829},\"results\":[{\"index\":1,\"relevance_score\":0.9587112551898949},{\"index\":3,\"relevance_score\":0.9337408271911014},{\"index\":7,\"relevance_score\":0.8922925217195924},{\"index\":2,\"relevance_score\":0.8891905997562045},{\"index\":0,\"relevance_score\":0.8827516945848907},{\"index\":4,\"relevance_score\":0.8701035914834407},{\"index\":6,\"relevance_score\":0.8676828987527296},{\"index\":5,\"relevance_score\":0.8455347349164652}]}</code></pre><h3 id=\"via-csp-marketplaces\">通过云服务提供商市场</h3><p><code>jina-reranker-m0</code> 很快将直接在 AWS、Azure 和 GCP 上提供，价格将在那里列出。</p><h3 id=\"via-huggingface\">通过 HuggingFace</h3><p>你也可以从我们的 Hugging Face 页面本地使用该模型。我们准备了一个 Google Colab 笔记本来演示它是如何工作的。与我们的 Web API 相比，本地使用模型提供了更大的灵活性，比如能够使用图像作为查询并处理多模态文档。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1gNTJHbdYSdgOEAea7kB6XaW56Zala0vk?usp=sharing\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-33.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-8.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"evaluation\">评估</h2><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1KrCD7l0lhzMkyg3z-gEDmymxe4Eun9Z-C0kU3_cxw7Q/edit?usp=sharing\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">[public]-jina-reranker-m0-evaluation-results</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4-1.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyKUKD8mc67_5eRgiiBYvZFKdug_jMKmBHiEesOvQ3bVWmAAKMu-afa1748S_WJXuc4UdNjKMqEsIQnlnf2X5OQsA0dmDJirjwvEkrgBMhQlJwXS8VM-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">完整评估结果可在此 Google 电子表格中找到。</span></p></figcaption></figure><h3 id=\"beir-text2text-english-only\">BEIR（文本到文本，仅英语）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2104.08663\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models</div><div class=\"kg-bookmark-description\">现有的神经信息检索（IR）模型通常在同质且狭窄的设置中进行研究，这极大地限制了对它们分布外（OOD）泛化能力的洞察。为了解决这个问题，并帮助研究人员广泛评估其模型的有效性，我们引入了 Benchmarking-IR（BEIR），一个稳健且异构的信息检索评估基准。我们精心选择了 18 个来自不同文本检索任务和领域的公开数据集，并在 BEIR 基准上评估了 10 个最先进的检索系统，包括词法、稀疏、密集、后期交互和重排序架构。我们的结果表明，BM25 是一个稳健的基线，重排序和基于后期交互的模型平均实现了最佳零样本性能，但计算成本较高。相比之下，密集和稀疏检索模型在计算效率上更高，但通常表现不如其他方法，这突显了它们在泛化能力方面有相当大的改进空间。我们希望这个框架能让我们更好地评估和理解现有的检索系统，并有助于加速向更稳健和可泛化系统的发展。BEIR 在 https://github.com/UKPLab/beir 上公开可用。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-13.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Nandan Thakur</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-9.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>BEIR 是一个异构的信息检索基准，旨在评估 IR 模型的通用性和稳健性。它包含来自各个领域的多样化数据集，并专注于零样本评估。使用标准化的评估指标，如 NDCG、Recall@K 和 MRR。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">TREC-COVID</th>\n<th style=\"text-align: right\">NFCorpus</th>\n<th style=\"text-align: right\">NQ</th>\n<th style=\"text-align: right\">HotpotQA</th>\n<th style=\"text-align: right\">FiQA</th>\n<th style=\"text-align: right\">ArguAna</th>\n<th style=\"text-align: right\">Touche-2020</th>\n<th style=\"text-align: right\">DBPedia</th>\n<th style=\"text-align: right\">SCIDOCS</th>\n<th style=\"text-align: right\">FEVER</th>\n<th style=\"text-align: right\">Climate-FEVER</th>\n<th style=\"text-align: right\">SciFact</th>\n<th style=\"text-align: right\">Quora</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\"><strong>58.95</strong></td>\n<td style=\"text-align: right\"><strong>84.17</strong></td>\n<td style=\"text-align: right\"><strong>41.03</strong></td>\n<td style=\"text-align: right\"><strong>72.25</strong></td>\n<td style=\"text-align: right\">76.99</td>\n<td style=\"text-align: right\"><strong>51.62</strong></td>\n<td style=\"text-align: right\">40.69</td>\n<td style=\"text-align: right\">31.79</td>\n<td style=\"text-align: right\"><strong>49.34</strong></td>\n<td style=\"text-align: right\"><strong>22.91</strong></td>\n<td style=\"text-align: right\">91.14</td>\n<td style=\"text-align: right\">36.42</td>\n<td style=\"text-align: right\"><strong>79.94</strong></td>\n<td style=\"text-align: right\">88.01</td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (1024 tokens)</td>\n<td style=\"text-align: right\">55.81</td>\n<td style=\"text-align: right\">77.81</td>\n<td style=\"text-align: right\">36.65</td>\n<td style=\"text-align: right\">64.31</td>\n<td style=\"text-align: right\">64.63</td>\n<td style=\"text-align: right\">47.47</td>\n<td style=\"text-align: right\"><strong>54.31</strong></td>\n<td style=\"text-align: right\">26.55</td>\n<td style=\"text-align: right\">41.07</td>\n<td style=\"text-align: right\">19.91</td>\n<td style=\"text-align: right\">89.00</td>\n<td style=\"text-align: right\"><strong>42.33</strong></td>\n<td style=\"text-align: right\">72.4</td>\n<td style=\"text-align: right\"><strong>89.06</strong></td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\">56.51</td>\n<td style=\"text-align: right\">82.19</td>\n<td style=\"text-align: right\">34.33</td>\n<td style=\"text-align: right\">69.52</td>\n<td style=\"text-align: right\"><strong>77.89</strong></td>\n<td style=\"text-align: right\">45.45</td>\n<td style=\"text-align: right\">36.21</td>\n<td style=\"text-align: right\"><strong>33.12</strong></td>\n<td style=\"text-align: right\">46.72</td>\n<td style=\"text-align: right\">17.79</td>\n<td style=\"text-align: right\">91.03</td>\n<td style=\"text-align: right\">38.69</td>\n<td style=\"text-align: right\">72.64</td>\n<td style=\"text-align: right\">89.10</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">57.06</td>\n<td style=\"text-align: right\">80.53</td>\n<td style=\"text-align: right\">37.17</td>\n<td style=\"text-align: right\">67.39</td>\n<td style=\"text-align: right\">76.17</td>\n<td style=\"text-align: right\">46.48</td>\n<td style=\"text-align: right\">39.28</td>\n<td style=\"text-align: right\">32.35</td>\n<td style=\"text-align: right\">47.81</td>\n<td style=\"text-align: right\">20.03</td>\n<td style=\"text-align: right\"><strong>93.02</strong></td>\n<td style=\"text-align: right\">37.17</td>\n<td style=\"text-align: right\">76.50</td>\n<td style=\"text-align: right\">87.83</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"miracl-text2text-multilingual-18-languages\">MIRACL（文本到文本，多语言，18 种语言）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2210.09984\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">创造 MIRACL：跨语言连续体的多语言信息检索</div><div class=\"kg-bookmark-description\">MIRACL（跨语言连续体的多语言信息检索）是我们为 WSDM 2023 Cup 挑战赛构建的多语言数据集，专注于 18 种不同语言的即席检索，这些语言的母语使用者总数超过 30 亿。这些语言具有不同的类型学特征，来自多个语系，并且具有不同程度的可用资源——包括研究人员通常称为高资源和低资源的语言。我们的数据集旨在支持创建和评估单语检索模型，其中查询和语料库使用相同的语言。总共，我们为这 18 种语言的维基百科收集了超过 77k 个查询的 70 万多个高质量相关性判断，所有评估都由我们团队聘请的母语者完成。我们的目标是促进能够改进跨语言连续体检索的研究，从而提升全球各地人群的信息访问能力，特别是那些传统上服务不足的人群。本概述论文描述了我们与社区共享的数据集和基线。MIRACL 网站已上线，地址为 http://miracl.ai/。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-12.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Xinyu Zhang</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-8.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MIRACL 是一个大规模的多语言信息检索数据集，覆盖了 18 种语言。它涵盖了超过 30 亿母语使用者，并具有完整的人工标注。该数据集主要关注单语言检索任务。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">ar</th>\n<th style=\"text-align: right\">bn</th>\n<th style=\"text-align: right\">en</th>\n<th style=\"text-align: right\">es</th>\n<th style=\"text-align: right\">fa</th>\n<th style=\"text-align: right\">fi</th>\n<th style=\"text-align: right\">fr</th>\n<th style=\"text-align: right\">hi</th>\n<th style=\"text-align: right\">id</th>\n<th style=\"text-align: right\">ja</th>\n<th style=\"text-align: right\">ko</th>\n<th style=\"text-align: right\">ru</th>\n<th style=\"text-align: right\">sw</th>\n<th style=\"text-align: right\">te</th>\n<th style=\"text-align: right\">th</th>\n<th style=\"text-align: right\">zh</th>\n<th style=\"text-align: right\">de</th>\n<th style=\"text-align: right\">yo</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\">66.75</td>\n<td style=\"text-align: right\">79.78</td>\n<td style=\"text-align: right\">78.01</td>\n<td style=\"text-align: right\">59.21</td>\n<td style=\"text-align: right\">53.56</td>\n<td style=\"text-align: right\">58.80</td>\n<td style=\"text-align: right\">78.00</td>\n<td style=\"text-align: right\">56.66</td>\n<td style=\"text-align: right\">62.83</td>\n<td style=\"text-align: right\">54.92</td>\n<td style=\"text-align: right\">66.51</td>\n<td style=\"text-align: right\">72.86</td>\n<td style=\"text-align: right\">67.26</td>\n<td style=\"text-align: right\">59.04</td>\n<td style=\"text-align: right\">70.19</td>\n<td style=\"text-align: right\">80.37</td>\n<td style=\"text-align: right\">64.51</td>\n<td style=\"text-align: right\">58.50</td>\n<td style=\"text-align: right\">80.44</td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align: right\">58.90</td>\n<td style=\"text-align: right\">71.53</td>\n<td style=\"text-align: right\">69.86</td>\n<td style=\"text-align: right\">48.37</td>\n<td style=\"text-align: right\">46.91</td>\n<td style=\"text-align: right\">54.13</td>\n<td style=\"text-align: right\">71.15</td>\n<td style=\"text-align: right\">50.90</td>\n<td style=\"text-align: right\">55.05</td>\n<td style=\"text-align: right\">47.83</td>\n<td style=\"text-align: right\">56.46</td>\n<td style=\"text-align: right\">64.76</td>\n<td style=\"text-align: right\">55.63</td>\n<td style=\"text-align: right\">54.07</td>\n<td style=\"text-align: right\">70.48</td>\n<td style=\"text-align: right\">73.56</td>\n<td style=\"text-align: right\">55.29</td>\n<td style=\"text-align: right\">49.18</td>\n<td style=\"text-align: right\">65.01</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\"><strong>69.32</strong></td>\n<td style=\"text-align: right\"><strong>80.51</strong></td>\n<td style=\"text-align: right\"><strong>81.85</strong></td>\n<td style=\"text-align: right\"><strong>57.67</strong></td>\n<td style=\"text-align: right\"><strong>57.64</strong></td>\n<td style=\"text-align: right\"><strong>61.92</strong></td>\n<td style=\"text-align: right\"><strong>80.38</strong></td>\n<td style=\"text-align: right\"><strong>59.60</strong></td>\n<td style=\"text-align: right\"><strong>67.66</strong></td>\n<td style=\"text-align: right\"><strong>58.86</strong></td>\n<td style=\"text-align: right\"><strong>67.37</strong></td>\n<td style=\"text-align: right\"><strong>75.14</strong></td>\n<td style=\"text-align: right\"><strong>67.61</strong></td>\n<td style=\"text-align: right\"><strong>68.92</strong></td>\n<td style=\"text-align: right\"><strong>76.69</strong></td>\n<td style=\"text-align: right\"><strong>82.29</strong></td>\n<td style=\"text-align: right\"><strong>64.46</strong></td>\n<td style=\"text-align: right\"><strong>58.32</strong></td>\n<td style=\"text-align: right\"><strong>80.85</strong></td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">63.65</td>\n<td style=\"text-align: right\">72.50</td>\n<td style=\"text-align: right\">79.42</td>\n<td style=\"text-align: right\">46.66</td>\n<td style=\"text-align: right\">51.54</td>\n<td style=\"text-align: right\">57.81</td>\n<td style=\"text-align: right\">73.05</td>\n<td style=\"text-align: right\">50.90</td>\n<td style=\"text-align: right\">60.94</td>\n<td style=\"text-align: right\">56.66</td>\n<td style=\"text-align: right\">59.15</td>\n<td style=\"text-align: right\">72.60</td>\n<td style=\"text-align: right\">53.43</td>\n<td style=\"text-align: right\">66.47</td>\n<td style=\"text-align: right\">74.62</td>\n<td style=\"text-align: right\">77.75</td>\n<td style=\"text-align: right\">62.49</td>\n<td style=\"text-align: right\">53.06</td>\n<td style=\"text-align: right\">76.69</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"mldr-text2text-multilingual-long-documents-13-languages\">MLDR（Text2Text，多语言长文档，13 种语言）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2402.03216\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BGE M3-Embedding：通过自知识蒸馏实现多语言、多功能、多粒度的文本嵌入</div><div class=\"kg-bookmark-description\">本文介绍了一个新的嵌入模型，称为 M3-Embedding，它以多语言性、多功能性和多粒度性为特色。该模型支持超过 100 种工作语言，在多语言和跨语言检索任务上达到了新的最优性能。它可以同时执行嵌入模型的三种常见检索功能：密集检索、多向量检索和稀疏检索，为实际的 IR 应用提供了统一的模型基础。它能够处理不同粒度的输入，从短句到最多 8192 个 token 的长文档。M3-Embedding 的有效训练包含以下技术贡献。我们提出了一种新的自知识蒸馏方法，其中来自不同检索功能的相关性分数可以作为教师信号集成，以提高训练质量。我们还优化了批处理策略，实现大批量和高训练吞吐量，确保嵌入的区分性。据我们所知，M3-Embedding 是第一个实现如此强大通用性的嵌入模型。模型和代码将在 https://github.com/FlagOpen/FlagEmbedding 上公开。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-18.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Jianlv Chen</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-14.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MLDR 是一个专门为长文档检索设计的多语言数据集，涵盖 13 种语言。它使用 GPT-3.5 为文档生成问题。该数据集基于 Wikipedia、Wudao 和 mC4 构建。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">ar</th>\n<th style=\"text-align: right\">de</th>\n<th style=\"text-align: right\">en</th>\n<th style=\"text-align: right\">es</th>\n<th style=\"text-align: right\">fr</th>\n<th style=\"text-align: right\">hi</th>\n<th style=\"text-align: right\">it</th>\n<th style=\"text-align: right\">ja</th>\n<th style=\"text-align: right\">ko</th>\n<th style=\"text-align: right\">pt</th>\n<th style=\"text-align: right\">ru</th>\n<th style=\"text-align: right\">th</th>\n<th style=\"text-align: right\">zh</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\"><strong>59.83</strong></td>\n<td style=\"text-align: right\"><strong>55.86</strong></td>\n<td style=\"text-align: right\"><strong>51.25</strong></td>\n<td style=\"text-align: right\"><strong>54.67</strong></td>\n<td style=\"text-align: right\"><strong>87.63</strong></td>\n<td style=\"text-align: right\"><strong>82.59</strong></td>\n<td style=\"text-align: right\"><strong>32.76</strong></td>\n<td style=\"text-align: right\"><strong>73.25</strong></td>\n<td style=\"text-align: right\"><strong>58.93</strong></td>\n<td style=\"text-align: right\"><strong>55.73</strong></td>\n<td style=\"text-align: right\"><strong>86.08</strong></td>\n<td style=\"text-align: right\"><strong>66.73</strong></td>\n<td style=\"text-align: right\"><strong>39.17</strong></td>\n<td style=\"text-align: right\"><strong>33.14</strong></td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align: right\">39.71</td>\n<td style=\"text-align: right\">28.44</td>\n<td style=\"text-align: right\">31.57</td>\n<td style=\"text-align: right\">29.07</td>\n<td style=\"text-align: right\">62.08</td>\n<td style=\"text-align: right\">59.79</td>\n<td style=\"text-align: right\">25.47</td>\n<td style=\"text-align: right\">53.72</td>\n<td style=\"text-align: right\">38.36</td>\n<td style=\"text-align: right\">32.37</td>\n<td style=\"text-align: right\">63.26</td>\n<td style=\"text-align: right\">49.65</td>\n<td style=\"text-align: right\">25.15</td>\n<td style=\"text-align: right\">17.26</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\">53.53</td>\n<td style=\"text-align: right\">49.19</td>\n<td style=\"text-align: right\">45.39</td>\n<td style=\"text-align: right\">43.92</td>\n<td style=\"text-align: right\">74.57</td>\n<td style=\"text-align: right\">68.67</td>\n<td style=\"text-align: right\">44.75</td>\n<td style=\"text-align: right\">62.79</td>\n<td style=\"text-align: right\">49.27</td>\n<td style=\"text-align: right\">48.24</td>\n<td style=\"text-align: right\">76.45</td>\n<td style=\"text-align: right\">62.84</td>\n<td style=\"text-align: right\">38.82</td>\n<td style=\"text-align: right\">31.02</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">59.50</td>\n<td style=\"text-align: right\">51.96</td>\n<td style=\"text-align: right\">50.13</td>\n<td style=\"text-align: right\">46.85</td>\n<td style=\"text-align: right\">86.34</td>\n<td style=\"text-align: right\">82.25</td>\n<td style=\"text-align: right\">49.50</td>\n<td style=\"text-align: right\">69.00</td>\n<td style=\"text-align: right\">59.07</td>\n<td style=\"text-align: right\">52.19</td>\n<td style=\"text-align: right\">85.26</td>\n<td style=\"text-align: right\">68.06</td>\n<td style=\"text-align: right\">38.73</td>\n<td style=\"text-align: right\">34.15</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"mkqa-text2text-multilingual-question-answering-24-languages-3-variants-for-chinese\">MKQA（Text2Text，多语言问答，24 种语言，中文有 3 种变体）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2007.15207\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">MKQA：一个语言多样性的多语言开放域问答基准测试</div><div class=\"kg-bookmark-description\">跨语言建模的进展依赖于具有挑战性、真实性和多样性的评估集。我们推出了多语言知识问答（MKQA），这是一个开放域问答评估集，包含 10k 个问答对，跨越 26 种类型学多样性语言（总共 26 万个问答对）。答案基于经过严格审核的、与语言无关的数据表示，使结果在不同语言之间具有可比性，且独立于特定语言的文本段落。该数据集以其 26 种语言的规模，为问答评估提供了迄今为止最广泛的语言范围。我们对各种最先进的方法和基线进行了基准测试，这些方法和基线是在 Natural Questions 上训练的生成式和抽取式问答，包括零样本和翻译设置。结果表明，即使在英语中这个数据集也具有挑战性，在低资源语言中尤其具有挑战性</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Shayne Longpre</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-7.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MKQA 是一个开放域问答评估集，包含了 10k 个问答对，这些问答对在 26 种具有不同类型特征的语言之间进行了对齐。问答对是从 Google Natural Questions 中采样得到的。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align:right\">AVG (recall@10)</th>\n<th style=\"text-align:right\">ar</th>\n<th style=\"text-align:right\">da</th>\n<th style=\"text-align:right\">de</th>\n<th style=\"text-align:right\">es</th>\n<th style=\"text-align:right\">en</th>\n<th style=\"text-align:right\">fi</th>\n<th style=\"text-align:right\">fr</th>\n<th style=\"text-align:right\">he</th>\n<th style=\"text-align:right\">hu</th>\n<th style=\"text-align:right\">it</th>\n<th style=\"text-align:right\">ja</th>\n<th style=\"text-align:right\">km</th>\n<th style=\"text-align:right\">ko</th>\n<th style=\"text-align:right\">ms</th>\n<th style=\"text-align:right\">nl</th>\n<th style=\"text-align:right\">no</th>\n<th style=\"text-align:right\">pl</th>\n<th style=\"text-align:right\">pt</th>\n<th style=\"text-align:right\">ru</th>\n<th style=\"text-align:right\">sv</th>\n<th style=\"text-align:right\">th</th>\n<th style=\"text-align:right\">tr</th>\n<th style=\"text-align:right\">vi</th>\n<th style=\"text-align:right\">zh_cn</th>\n<th style=\"text-align:right\">zh_hk</th>\n<th style=\"text-align:right\">zh_tw</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align:right\"><strong>68.19</strong></td>\n<td style=\"text-align:right\"><strong>63.88</strong></td>\n<td style=\"text-align:right\"><strong>70.57</strong></td>\n<td style=\"text-align:right\"><strong>70.52</strong></td>\n<td style=\"text-align:right\"><strong>71.26</strong></td>\n<td style=\"text-align:right\"><strong>73.47</strong></td>\n<td style=\"text-align:right\">64.10</td>\n<td style=\"text-align:right\"><strong>71.11</strong></td>\n<td style=\"text-align:right\">63.68</td>\n<td style=\"text-align:right\">63.23</td>\n<td style=\"text-align:right\"><strong>70.30</strong></td>\n<td style=\"text-align:right\"><strong>69.13</strong></td>\n<td style=\"text-align:right\">50.43</td>\n<td style=\"text-align:right\"><strong>64.30</strong></td>\n<td style=\"text-align:right\"><strong>70.78</strong></td>\n<td style=\"text-align:right\"><strong>71.73</strong></td>\n<td style=\"text-align:right\"><strong>70.25</strong></td>\n<td style=\"text-align:right\"><strong>69.72</strong></td>\n<td style=\"text-align:right\"><strong>70.57</strong></td>\n<td style=\"text-align:right\"><strong>70.78</strong></td>\n<td style=\"text-align:right\"><strong>70.69</strong></td>\n<td style=\"text-align:right\"><strong>69.80</strong></td>\n<td style=\"text-align:right\">67.90</td>\n<td style=\"text-align:right\"><strong>69.68</strong></td>\n<td style=\"text-align:right\"><strong>69.12</strong></td>\n<td style=\"text-align:right\"><strong>68.23</strong></td>\n<td style=\"text-align:right\"><strong>67.79</strong></td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align:right\">65.63</td>\n<td style=\"text-align:right\">59.00</td>\n<td style=\"text-align:right\">69.12</td>\n<td style=\"text-align:right\">68.27</td>\n<td style=\"text-align:right\">68.15</td>\n<td style=\"text-align:right\">71.14</td>\n<td style=\"text-align:right\">65.66</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">59.51</td>\n<td style=\"text-align:right\">63.23</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">64.36</td>\n<td style=\"text-align:right\">56.13</td>\n<td style=\"text-align:right\">58.98</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">69.53</td>\n<td style=\"text-align:right\">68.65</td>\n<td style=\"text-align:right\">67.26</td>\n<td style=\"text-align:right\">67.93</td>\n<td style=\"text-align:right\">67.06</td>\n<td style=\"text-align:right\">68.68</td>\n<td style=\"text-align:right\">66.32</td>\n<td style=\"text-align:right\">66.97</td>\n<td style=\"text-align:right\">66.87</td>\n<td style=\"text-align:right\">63.38</td>\n<td style=\"text-align:right\">63.59</td>\n<td style=\"text-align:right\">61.55</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align:right\">67.88</td>\n<td style=\"text-align:right\">63.09</td>\n<td style=\"text-align:right\">70.15</td>\n<td style=\"text-align:right\">68.91</td>\n<td style=\"text-align:right\">68.92</td>\n<td style=\"text-align:right\">73.00</td>\n<td style=\"text-align:right\"><strong>68.71</strong></td>\n<td style=\"text-align:right\">68.71</td>\n<td style=\"text-align:right\"><strong>70.27</strong></td>\n<td style=\"text-align:right\">64.00</td>\n<td style=\"text-align:right\">68.15</td>\n<td style=\"text-align:right\">68.47</td>\n<td style=\"text-align:right\"><strong>60.43</strong></td>\n<td style=\"text-align:right\">63.95</td>\n<td style=\"text-align:right\">68.80</td>\n<td style=\"text-align:right\">70.77</td>\n<td style=\"text-align:right\">69.10</td>\n<td style=\"text-align:right\">67.44</td>\n<td style=\"text-align:right\">67.40</td>\n<td style=\"text-align:right\">69.77</td>\n<td style=\"text-align:right\">70.03</td>\n<td style=\"text-align:right\">69.68</td>\n<td style=\"text-align:right\">66.04</td>\n<td style=\"text-align:right\">68.29</td>\n<td style=\"text-align:right\">67.84</td>\n<td style=\"text-align:right\">66.70</td>\n<td style=\"text-align:right\">66.34</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align:right\">67.90</td>\n<td style=\"text-align:right\">63.88</td>\n<td style=\"text-align:right\">70.31</td>\n<td style=\"text-align:right\">70.09</td>\n<td style=\"text-align:right\">70.51</td>\n<td style=\"text-align:right\">73.09</td>\n<td style=\"text-align:right\">67.50</td>\n<td style=\"text-align:right\">70.38</td>\n<td style=\"text-align:right\">63.00</td>\n<td style=\"text-align:right\"><strong>64.59</strong></td>\n<td style=\"text-align:right\">69.90</td>\n<td style=\"text-align:right\">67.34</td>\n<td style=\"text-align:right\">57.79</td>\n<td style=\"text-align:right\">62.14</td>\n<td style=\"text-align:right\">70.36</td>\n<td style=\"text-align:right\">71.58</td>\n<td style=\"text-align:right\">69.51</td>\n<td style=\"text-align:right\">68.61</td>\n<td style=\"text-align:right\">70.13</td>\n<td style=\"text-align:right\">70.07</td>\n<td style=\"text-align:right\">70.15</td>\n<td style=\"text-align:right\">68.80</td>\n<td style=\"text-align:right\"><strong>68.02</strong></td>\n<td style=\"text-align:right\">69.39</td>\n<td style=\"text-align:right\">67.23</td>\n<td style=\"text-align:right\">65.77</td>\n<td style=\"text-align:right\">65.37</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"coir-text2text-code-information-retrieval\">CoIR（文本到文本，代码信息检索）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2407.02883\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">CoIR：代码信息检索模型的综合基准</div><div class=\"kg-bookmark-description\">尽管信息检索（IR）在各种 NLP 任务中取得了显著成功，但大多数 IR 系统主要处理自然语言的查询和语料库，忽视了代码检索领域。代码检索至关重要但仍未得到充分探索，现有方法和基准测试不能充分代表各个领域和任务中代码的多样性。为解决这一问题，我们提出了 COIR（代码信息检索基准），这是一个专门设计用于评估代码检索能力的健壮而全面的基准。COIR 包含了十个精心策划的代码数据集，涵盖了七个不同领域的八个独特检索任务。我们首先讨论了 COIR 的构建和其多样化的数据集组成。此外，我们使用 COIR 评估了九个广泛使用的检索模型，发现即使是最先进的系统在执行代码检索任务时也存在显著困难。为了便于现有研究工作流程中的轻松采用和集成，COIR 已开发为一个用户友好的 Python 框架，可通过 pip 轻松安装。它与其他流行的基准测试（如 MTEB 和 BEIR）共享相同的数据模式，实现了跨基准评估的无缝衔接。通过 COIR，我们旨在激发代码检索领域的研究，提供一个多功能的基准测试工具，鼓励进一步开发和探索代码检索系统 https://github.com/CoIR-team/coir。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-14.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Xiangyang Li</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-10.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>CoIR 是一个综合性基准测试，旨在评估模型在代码检索方面的能力。它包含 10 个精选的代码数据集，涵盖 7 个不同领域的 8 个检索任务。该基准测试提供了一个 Python 框架。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th rowspan=\"3\">Model Name</th>\n      <th rowspan=\"3\">Avg (NDCG@10)</th>\n      <th colspan=\"3\">Text-to-Code</th>\n      <th colspan=\"7\">Code-to-Text</th>\n      <th colspan=\"9\">Code-to-Code</th>\n      <th colspan=\"3\">Hybrid Code</th>\n    </tr>\n    <tr>\n      <th rowspan=\"2\">Apps</th>\n      <th rowspan=\"2\">CosQA</th>\n      <th rowspan=\"2\">SQL</th>\n      <th colspan=\"7\">CSN</th>\n      <th colspan=\"7\">CSN-CCR</th>\n      <th colspan=\"2\">CodeTransOcean</th>\n      <th rowspan=\"2\">StackOver<br>Flow</th>\n      <th colspan=\"2\">CodeFeedBack</th>\n    </tr>\n    <tr>\n      <th>AVG</th>\n      <th>python</th>\n      <th>javascript</th>\n      <th>go</th>\n      <th>ruby</th>\n      <th>java</th>\n      <th>php</th>\n      <th>AVG</th>\n      <th>python</th>\n      <th>javascript</th>\n      <th>go</th>\n      <th>ruby</th>\n      <th>java</th>\n      <th>php</th>\n      <th>-Contest</th>\n      <th>-DL</th>\n      <th>-MT</th>\n      <th>-ST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>63.55</strong></td>\n      <td style=\"text-align: right\"><strong>26.21</strong></td>\n      <td style=\"text-align: right\">37.75</td>\n      <td style=\"text-align: right\"><strong>57.92</strong></td>\n      <td style=\"text-align: right\">80.76</td>\n      <td style=\"text-align: right\"><strong>98.37</strong></td>\n      <td style=\"text-align: right\">71.16</td>\n      <td style=\"text-align: right\">86.14</td>\n      <td style=\"text-align: right\">72.74</td>\n      <td style=\"text-align: right\">79.02</td>\n      <td style=\"text-align: right\">77.14</td>\n      <td style=\"text-align: right\"><strong>74.57</strong></td>\n      <td style=\"text-align: right\"><strong>81.66</strong></td>\n      <td style=\"text-align: right\"><strong>77.92</strong></td>\n      <td style=\"text-align: right\"><strong>68.71</strong></td>\n      <td style=\"text-align: right\"><strong>75.44</strong></td>\n      <td style=\"text-align: right\"><strong>77.54</strong></td>\n      <td style=\"text-align: right\"><strong>66.13</strong></td>\n      <td style=\"text-align: right\"><strong>79.79</strong></td>\n      <td style=\"text-align: right\"><strong>31.89</strong></td>\n      <td style=\"text-align: right\">90.41</td>\n      <td style=\"text-align: right\"><strong>72.25</strong></td>\n      <td style=\"text-align: right\"><strong>83.95</strong></td>\n    </tr>\n    <tr>\n      <td>jina-embeddings-v2-base-code<br>(top 100)</td>\n      <td style=\"text-align: right\">56.90</td>\n      <td style=\"text-align: right\">16.34</td>\n      <td style=\"text-align: right\"><strong>41.72</strong></td>\n      <td style=\"text-align: right\">49.79</td>\n      <td style=\"text-align: right\"><strong>83.95</strong></td>\n      <td style=\"text-align: right\">94.71</td>\n      <td style=\"text-align: right\"><strong>76.35</strong></td>\n      <td style=\"text-align: right\"><strong>87.39</strong></td>\n      <td style=\"text-align: right\"><strong>78.23</strong></td>\n      <td style=\"text-align: right\"><strong>82.69</strong></td>\n      <td style=\"text-align: right\"><strong>84.35</strong></td>\n      <td style=\"text-align: right\">59.65</td>\n      <td style=\"text-align: right\">68.23</td>\n      <td style=\"text-align: right\">62.31</td>\n      <td style=\"text-align: right\">49.15</td>\n      <td style=\"text-align: right\">65.40</td>\n      <td style=\"text-align: right\">63.89</td>\n      <td style=\"text-align: right\">48.92</td>\n      <td style=\"text-align: right\">79.20</td>\n      <td style=\"text-align: right\">30.35</td>\n      <td style=\"text-align: right\">89.42</td>\n      <td style=\"text-align: right\">49.62</td>\n      <td style=\"text-align: right\">68.93</td>\n    </tr>\n    <tr>\n      <td>bge-reranker-v2-m3</td>\n      <td style=\"text-align: right\">35.97</td>\n      <td style=\"text-align: right\">8.33</td>\n      <td style=\"text-align: right\">30.06</td>\n      <td style=\"text-align: right\">50.63</td>\n      <td style=\"text-align: right\">49.26</td>\n      <td style=\"text-align: right\">67.62</td>\n      <td style=\"text-align: right\">39.55</td>\n      <td style=\"text-align: right\">58.11</td>\n      <td style=\"text-align: right\">41.37</td>\n      <td style=\"text-align: right\">44.77</td>\n      <td style=\"text-align: right\">44.13</td>\n      <td style=\"text-align: right\">40.81</td>\n      <td style=\"text-align: right\">42.57</td>\n      <td style=\"text-align: right\">42.75</td>\n      <td style=\"text-align: right\">38.04</td>\n      <td style=\"text-align: right\">38.04</td>\n      <td style=\"text-align: right\">41.73</td>\n      <td style=\"text-align: right\">41.73</td>\n      <td style=\"text-align: right\">34.93</td>\n      <td style=\"text-align: right\">5.09</td>\n      <td style=\"text-align: right\">60.12</td>\n      <td style=\"text-align: right\">16.44</td>\n      <td style=\"text-align: right\">64.05</td>\n    </tr>\n    <tr>\n      <td>jina-reranker-v2-multilingual</td>\n      <td style=\"text-align: right\">56.14</td>\n      <td style=\"text-align: right\">21.90</td>\n      <td style=\"text-align: right\">37.26</td>\n      <td style=\"text-align: right\">53.56</td>\n      <td style=\"text-align: right\">78.88</td>\n      <td style=\"text-align: right\">97.83</td>\n      <td style=\"text-align: right\">67.43</td>\n      <td style=\"text-align: right\">84.64</td>\n      <td style=\"text-align: right\">68.93</td>\n      <td style=\"text-align: right\">75.73</td>\n      <td style=\"text-align: right\">78.71</td>\n      <td style=\"text-align: right\">63.59</td>\n      <td style=\"text-align: right\">72.62</td>\n      <td style=\"text-align: right\">67.80</td>\n      <td style=\"text-align: right\">55.07</td>\n      <td style=\"text-align: right\">67.25</td>\n      <td style=\"text-align: right\">64.25</td>\n      <td style=\"text-align: right\">54.54</td>\n      <td style=\"text-align: right\">73.67</td>\n      <td style=\"text-align: right\">25.74</td>\n      <td style=\"text-align: right\"><strong>91.24</strong></td>\n      <td style=\"text-align: right\">42.03</td>\n      <td style=\"text-align: right\">73.59</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"vidore-text2image-visual-document-retrieval-benchmark\">ViDoRe（文本到图像、视觉文档检索基准）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2407.01449\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">ColPali：利用视觉语言模型进行高效文档检索</div><div class=\"kg-bookmark-description\">文档是富有视觉信息的结构，不仅通过文本传递信息，还通过图表、页面布局、表格，甚至字体来传递信息。由于现代检索系统主要依赖于从文档页面提取的文本信息来建立索引（通常通过耗时且脆弱的过程），它们难以有效利用关键的视觉线索。这限制了它们在许多实际文档检索应用中的能力，如检索增强生成（RAG）。为了对当前系统在视觉丰富的文档检索方面进行基准测试，我们引入了视觉文档检索基准 ViDoRe，它由跨越多个领域、语言和实际场景的各种页面级检索任务组成。现代系统固有的复杂性和性能不足促使我们提出一个新概念：通过直接嵌入文档页面的图像来进行文档检索。我们发布了 ColPali，这是一个经过训练的视觉语言模型，可以从文档页面的图像生成高质量的多向量嵌入。结合后期交互匹配机制，ColPali 在性能上大大超过现代文档检索流程，同时更加简单、快速，并且可以端到端训练。我们在 https://hf.co/vidore 以开放许可的方式发布模型、数据、代码和基准测试。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-16.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Manuel Faysse</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-12.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ViDoRe 是一个专门设计的基准测试，用于评估检索系统在使用视觉特征匹配查询与相关文档的能力。它涵盖了多个领域和语言的各种页面级检索任务。该基准测试重点关注文档的视觉元素。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th style=\"text-align: right\">AVG<br>(NDCG@5)</th>\n      <th style=\"text-align: right\">TAT-DQA</th>\n      <th style=\"text-align: right\">Shift<br>Project</th>\n      <th style=\"text-align: right\">Artificial<br>Intelligence</th>\n      <th style=\"text-align: right\">Government<br>Reports</th>\n      <th style=\"text-align: right\">ArxivQA</th>\n      <th style=\"text-align: right\">DocVQA</th>\n      <th style=\"text-align: right\">Healthcare<br>Industry</th>\n      <th style=\"text-align: right\">InfoVQA</th>\n      <th style=\"text-align: right\">Energy</th>\n      <th style=\"text-align: right\">TabFQuad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>91.02</strong></td>\n      <td style=\"text-align: right\"><strong>81.83</strong></td>\n      <td style=\"text-align: right\"><strong>93.22</strong></td>\n      <td style=\"text-align: right\"><strong>99.63</strong></td>\n      <td style=\"text-align: right\"><strong>97.59</strong></td>\n      <td style=\"text-align: right\"><strong>89.82</strong></td>\n      <td style=\"text-align: right\"><strong>62.58</strong></td>\n      <td style=\"text-align: right\"><strong>99.26</strong></td>\n      <td style=\"text-align: right\"><strong>92.88</strong></td>\n      <td style=\"text-align: right\"><strong>96.06</strong></td>\n      <td style=\"text-align: right\"><strong>97.32</strong></td>\n    </tr>\n    <tr>\n      <td>MrLight/dse-qwen2-2b-mr1-v1</td>\n      <td style=\"text-align: right\">84.48</td>\n      <td style=\"text-align: right\">66.64</td>\n      <td style=\"text-align: right\">79.39</td>\n      <td style=\"text-align: right\">96.45</td>\n      <td style=\"text-align: right\">95.30</td>\n      <td style=\"text-align: right\">84.53</td>\n      <td style=\"text-align: right\">55.47</td>\n      <td style=\"text-align: right\">96.85</td>\n      <td style=\"text-align: right\">86.39</td>\n      <td style=\"text-align: right\">91.80</td>\n      <td style=\"text-align: right\">92.03</td>\n    </tr>\n  \n    <tr>\n      <td>MonoQwen2-VL-v0.1</td>\n      <td style=\"text-align: right\">87.64</td>\n      <td style=\"text-align: right\">79.50</td>\n      <td style=\"text-align: right\">76.38</td>\n      <td style=\"text-align: right\">98.39</td>\n      <td style=\"text-align: right\">93.63</td>\n      <td style=\"text-align: right\">89.50</td>\n      <td style=\"text-align: right\">57.47</td>\n      <td style=\"text-align: right\">98.39</td>\n      <td style=\"text-align: right\">92.12</td>\n      <td style=\"text-align: right\">95.29</td>\n      <td style=\"text-align: right\">95.75</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"m-beir-text2image-image2text-multimodal-benchmark-for-instructed-retrieval\">M-BEIR（文本到图像、图像到文本、多模态指令检索基准）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2311.17136\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">UniIR: Training and Benchmarking Universal Multimodal Information Retrievers</div><div class=\"kg-bookmark-description\">现有的信息检索 (IR) 模型通常假设单一格式，限制了它们在满足不同用户需求方面的应用，例如使用文本描述搜索图像、使用标题图像搜索新闻文章或使用查询图像寻找类似照片。为了应对这些不同的信息搜索需求，我们推出了 UniIR，这是一个统一的指令引导多模态检索器，能够处理跨模态的八种不同检索任务。UniIR 是一个在十个不同多模态 IR 数据集上联合训练的单一检索系统，它能够解释用户指令来执行各种检索任务，在现有数据集上展示出强大的性能，并能零样本泛化到新任务。我们的实验强调，多任务训练和指令调优是 UniIR 泛化能力的关键。此外，我们构建了 M-BEIR，这是一个具有全面结果的多模态检索基准，用于标准化通用多模态信息检索的评估。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Cong Wei</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-15.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>M-BEIR 是一个全面的大规模检索基准，旨在训练和评估多模态检索模型。它包含八个多模态检索任务和来自各种领域和来源的十个数据集。该基准测试重点关注指令遵循检索。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n        <tr>\n          <th>Model</th>\n            <th>MBEIR t2i VisualNews<br>Recall@5</th>\n            <th>MBEIR t2i MSCOCO<br>Recall@5</th>\n            <th>MBEIR t2i Fashion200K<br>Recall@10</th>\n            <th>MBEIR i2t VisualNews<br>Recall@5</th>\n            <th>MBEIR i2t MSCOCO<br>Recall@5</th>\n            <th>MBEIR i2t Fashion200K<br>Recall@10</th>\n        </tr>\n    </thead>\n        <tr>\n            <td>jina-reranker-m0</td>\n            <td align=\"right\"><b>23.89</b></td>\n            <td align=\"right\"><b>72.19</b></td>\n            <td align=\"right\">9.79</td>\n            <td align=\"right\"><b>17.61</b></td>\n            <td align=\"right\">41.21</td>\n            <td align=\"right\"><b>11.56</b></td>\n        </tr>\n        <tr>\n            <td>jinaai/jina-clip-v2</td>\n            <td align=\"right\">15.42</td>\n            <td align=\"right\">52.28</td>\n            <td align=\"right\">7.03</td>\n            <td align=\"right\">11.63</td>\n            <td align=\"right\">28.80</td>\n            <td align=\"right\">8.78</td>\n        </tr>\n        <tr>\n            <td>MonoQwen2-VL-v0.1</td>\n            <td align=\"right\">22.74</td>\n            <td align=\"right\">71.29</td>\n            <td align=\"right\"><b>10.00</b></td>\n            <td align=\"right\">15.08</td>\n            <td align=\"right\"><b>42.24</b></td>\n            <td align=\"right\">11.25</td>\n        </tr>\n    </table>\n<!--kg-card-end: html-->\n<h3 id=\"winoground-text2text-text2image\">Winoground（文本到文本、文本到图像）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2204.03162\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality</div><div class=\"kg-bookmark-description\">我们提出了一个新颖的任务和数据集，用于评估视觉和语言模型进行视觉语言组合推理的能力，我们称之为 Winoground。给定两张图像和两个标题，目标是正确匹配它们——但关键的是，两个标题包含完全相同的词集，只是顺序不同。该数据集由专家注释者精心策划，并标注了丰富的细粒度标签，以帮助分析模型性能。我们测试了一系列最先进的视觉和语言模型，令人惊讶的是，发现它们都没有比随机猜测表现得更好。显然，这些模型在视觉语言组合推理方面的技能并不如我们期望的那样出色。我们进行了广泛的分析，以获得洞见，了解未来的工作如何尝试减轻这些模型的缺陷。我们期望 Winoground 能够作为一个有用的评估集，推动该领域的技术进步和进一步发展。该数据集可在 https://huggingface.co/datasets/facebook/winoground 获取。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-15.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Tristan Thrush</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-11.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Winoground 是一个新颖的任务和数据集，用于评估视觉和语言模型进行视觉语言组合推理的能力。它使用具有相同词汇内容的双胞胎标题，并采用对比性的图像-标题配对。其重点在于组合推理。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>Text</th>\n      <th>Image</th>\n      <th>Group</th>\n      <th>Avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>57.00</strong></td>\n      <td style=\"text-align: right\"><strong>40.75</strong></td>\n      <td style=\"text-align: right\"><strong>34.00</strong></td>\n      <td style=\"text-align: right\"><strong>43.92</strong></td>\n    </tr>\n    <tr>\n      <td>MrLight/dse-qwen2-2b-mrl-v1</td>\n      <td style=\"text-align: right\">7.50</td>\n      <td style=\"text-align: right\">9.25</td>\n      <td style=\"text-align: right\">1.75</td>\n      <td style=\"text-align: right\">6.17</td>\n    </tr>\n    <tr>\n      <td>MonoQwen2-VL-v0.1</td>\n      <td style=\"text-align: right\">52.00</td>\n      <td style=\"text-align: right\">36.25</td>\n      <td style=\"text-align: right\">31.50</td>\n      <td style=\"text-align: right\">39.92</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Winoground 使用三个关键指标来评估视觉语言模型：文本得分、图像得分和组合得分。文本得分衡量模型是否正确地将标题与图像匹配，而图像得分评估模型是否为标题选择了正确的图像。组合得分是最严格的指标，要求所有标题-图像关系都被正确识别。得分以百分比表示准确率，分数越高表示推理能力越强。</p><h2 id=\"conclusion\">结论</h2><p><code>jina-reranker-m0</code> 是我们首次尝试在单个仅解码器模型中统一文本和视觉模态。这种新架构吸收了我们之前仅编码器检索模型的经验教训，包括 <code>jina-clip-v2</code>、<code>jina-embeddings-v3</code>、<code>jina-reranker-v2-base-multilingual</code> 和 <code>jina-embeddings-v2-base-code</code>。</p><p>新模型不仅解锁了多模态检索任务的能力，如文本到图像重排序和视觉文档重排序，而且在文本到文本和文本到代码重排序任务上相比 <code>jina-reranker-v2-base-multilingual</code> 展现出更好的性能。我们将这个新模型系列命名为\"m 系列\"以突出其多模态特性。</p><p>在比较 <code>jina-reranker-m0</code> 与 <code>jina-reranker-v2-base-multilingual</code> 时，我们对 m 系列的目标是在实现多模态的同时，在纯文本任务上达到与专门的纯文本模型相当的性能提升。有人可能会质疑，如果在纯文本任务上性能提升看似不大，使用 8 倍大的模型是否值得。虽然目前对于纯文本应用来说，<code>m0</code> 相比 <code>v2</code> 可能没有提供显著的附加价值，但仅解码器架构开启了许多在仅编码器架构下无法实现的新可能性，包括：</p><ul><li>真正的混合模态重排序</li><li>列表式重排序和文档去重</li><li>通过注意力机制实现排序分数可解释性</li></ul><p>我们未来的工作将专注于进一步升级纯文本重排序器，并充分利用这种多模态架构开启的新特性，以实现更好且更加广泛的搜索。</p>",
  "comment_id": "67ea5eb45dcba60001c30f0a",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/04/banner-reranker-m0--1-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-03-31T11:21:56.000+02:00",
  "updated_at": "2025-04-08T13:21:13.000+02:00",
  "published_at": "2025-04-08T13:10:38.000+02:00",
  "custom_excerpt": "Introducing jina-reranker-m0, our new multilingual multimodal reranker for retrieving visual documents, with SOTA performance on multilingual long documents and code searching tasks.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-reranker-m0-multilingual-multimodal-document-reranker/",
  "excerpt": "介绍我们的新型多语言多模态重排序器 jina-reranker-m0，它专门用于视觉文档检索，在多语言长文档和代码搜索任务中达到了最先进的性能水平。",
  "reading_time": 20,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}