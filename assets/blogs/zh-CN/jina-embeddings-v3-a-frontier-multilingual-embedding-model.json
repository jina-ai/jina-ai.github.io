{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3：前沿的多语言嵌入模型",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">我们正在通过开源和开放科学来推进和普及人工智能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3：具有 Task LoRA 的多语言嵌入</div><div class=\"kg-bookmark-description\">我们推出了 jina-embeddings-v3，这是一个拥有 5.7 亿参数的新型文本嵌入模型，在多语言数据和长文本检索任务上实现了最先进的性能，支持长达 8192 个 token 的上下文长度。该模型包含一组特定任务的低秩适应（LoRA）适配器，可为查询-文档检索、聚类、分类和文本匹配生成高质量的嵌入。此外，在训练过程中集成了套娃表示学习，允许在不影响性能的情况下灵活截断嵌入维度。在 MTEB 基准测试中的评估显示，jina-embeddings-v3 在英语任务上优于 OpenAI 和 Cohere 最新的专有嵌入，同时在所有多语言任务上的表现都优于 multilingual-e5-large-instruct。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>今天，我们很高兴宣布 <code>jina-embeddings-v3</code>，这是一个拥有 5.7 亿参数的前沿文本嵌入模型。它在**多语言**数据和**长文本**检索任务上实现了最先进的性能，支持长达 8192 个 token 的输入长度。该模型具有特定任务的低秩适应（LoRA）适配器，使其能够为**查询-文档检索**、**聚类**、**分类**和**文本匹配**等各种任务生成高质量嵌入。</p><p>在 MTEB 英语、多语言和 LongEmbed 评估中，<code>jina-embeddings-v3</code> 在英语任务上优于 OpenAI 和 Cohere 最新的专有嵌入，同时在所有多语言任务上的表现都超过了 <code>multilingual-e5-large-instruct</code>。借助套娃表示学习（MRL）的集成，用户可以在不影响性能的情况下，将默认 1024 维的输出任意截断至 32 维。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 与其他嵌入模型在所有 MTEB 英语任务上的性能比较。完整的每项任务评估结果可以在<a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">我们的 arXiv 论文</a>中找到。</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 已在广泛的多语言和跨语言 MTEB 任务中进行了评估。请注意，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2-(zh/es/de)</code> 指的是我们的双语模型套件，该套件仅在中文、西班牙语和德语的单语言和跨语言任务上进行了测试，不包括其他语言。此外，我们没有报告 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">openai-text-embedding-3-large</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">cohere-embed-multilingual-v3.0</code> 的分数，因为这些模型未在全部多语言和跨语言 MTEB 任务上进行评估。</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 在 LongEmbed 基准测试的六个长文档检索任务上的表现显示出相对于其他模型的显著改进。分数为 nDCG@10；越高越好。这表明我们基于 RoPE 的位置嵌入的效果优于 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">baai-bge-m3</code> 使用的固定位置嵌入和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2</code> 使用的基于 ALiBi 的方法。</figcaption></figure><p>截至 2024 年 9 月 18 日发布时，<code>jina-embeddings-v3</code> 是**最佳**多语言模型，并在参数少于 10 亿的模型中在 MTEB 英语排行榜上排名**第二**。v3 总共支持 89 种语言，其中包括 30 种性能最佳的语言：阿拉伯语、孟加拉语、中文、丹麦语、荷兰语、英语、芬兰语、法语、格鲁吉亚语、德语、希腊语、印地语、印尼语、意大利语、日语、韩语、拉脱维亚语、挪威语、波兰语、葡萄牙语、罗马尼亚语、俄语、斯洛伐克语、西班牙语、瑞典语、泰语、土耳其语、乌克兰语、乌尔都语和越南语。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>截至 2024 年 9 月 18 日发布时，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 拥有 5.7 亿参数和 1024 维输出，是参数少于 10 亿的模型中最高效、最强大和最可靠的多语言嵌入模型。</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption>嵌入模型的缩放规律。图中展示了英语任务上的平均 MTEB 性能与模型参数数量的关系。每个点代表一个嵌入模型。突出显示了代表所有模型的趋势线，多语言模型用青色强调。可以看到，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 相比同等规模的模型表现出更优异的性能，并且相比其前身 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2</code> 展现出超线性的改进。该图表是通过从 MTEB 排行榜中选择前 100 个嵌入模型创建的，排除了那些没有规模信息的模型（通常是闭源或专有模型）。明显的恶意提交也被过滤掉了。</figcaption></figure><p>此外，与最近受到关注的基于 LLM 的嵌入（如 <code>e5-mistral-7b-instruct</code>）相比，后者参数量为 71 亿（大 12 倍）、输出维度为 4096（大 4 倍），但在 MTEB 英语任务上仅提高了 1%，<code>jina-embeddings-v3</code> 是一个更具成本效益的解决方案，更适合生产和边缘计算环境。</p><h2 id=\"model-architecture\">模型架构</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>基础</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>基础参数量</td>\n<td>559M</td>\n</tr>  \n<tr>\n<td>含 LoRA 参数量</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>最大输入 tokens</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>最大输出维度</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>层数</td>\n<td>24</td>\n</tr>\n<tr>\n<td>词表大小</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>支持的语言数</td>\n<td>89</td>\n</tr>\n<tr>\n<td>注意力机制</td>\n<td>FlashAttention2，也可不使用</td>\n</tr>\n<tr>\n<td>池化方式</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>jina-embeddings-v3</code> 的架构如下图所示。为实现骨干网络架构，我们对 <code>XLM-RoBERTa</code> 模型进行了几个关键修改：(1) 支持长文本序列的高效编码，(2) 允许针对特定任务的嵌入编码，(3) 采用最新技术提升整体模型效率。我们继续使用原始的 <code>XLM-RoBERTa</code> 分词器。虽然 <code>jina-embeddings-v3</code> 的参数量为 5.7 亿，比 1.37 亿参数的 <code>jina-embeddings-v2</code> 更大，但仍远小于从 LLM 微调得到的嵌入模型。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-embeddings-v3</code> 的架构基于 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\"> 模型，包含用于四个不同任务的五个 LoRA 适配器。</span></figcaption></figure><p><code>jina-embeddings-v3</code> 的关键创新在于使用 LoRA 适配器。我们引入了<strong>五个</strong>任务特定的 LoRA 适配器来优化<strong>四种</strong>任务的嵌入。模型的输入包含两部分：文本（待嵌入的长文档）和任务。<code>jina-embeddings-v3</code> 支持四种任务，实现了五个可选的适配器：<code>retrieval.query</code> 和 <code>retrieval.passage</code> 用于非对称检索任务中的查询和段落嵌入，<code>separation</code> 用于聚类任务，<code>classification</code> 用于分类任务，以及 <code>text-matching</code> 用于涉及语义相似度的任务，如 STS 或对称检索。LoRA 适配器仅占总参数量的不到 3%，对计算带来的额外开销极小。</p><p>为进一步提升性能并减少内存消耗，我们集成了 FlashAttention 2，支持激活检查点，并使用 DeepSpeed 框架进行高效的分布式训练。</p><h2 id=\"get-started\">开始使用</h2><h3 id=\"via-jina-ai-search-foundation-api\">通过 Jina AI Search Foundation API</h3><p>使用 <code>jina-embeddings-v3</code> 最简单的方式是访问 <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">Jina AI 主页</a>并导航至 Search Foundation API 部分。从今天开始，该模型将成为所有新用户的默认选项。您可以直接在那里探索不同的参数和功能。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>与 v2 相比，v3 在 API 中引入了三个新参数：<code>task</code>、<code>dimensions</code> 和 <code>late_chunking</code>。</p><h4 id=\"parameter-task\">参数 <code>task</code></h4><p><code>task</code> 参数至关重要，必须根据下游任务进行设置。生成的嵌入将针对该特定任务进行优化。详细信息请参考下面的列表。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong><code>task</code> 值</strong></th>\n<th><strong>任务描述</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>在查询-文档检索任务中嵌入<b>文档</b></td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>在查询-文档检索任务中嵌入<b>查询</b></td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>文档聚类、语料库可视化</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>文本分类</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(默认)</b> 语义文本相似度、通用对称检索、推荐、查找相似项、去重</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>请注意，API <em>不是</em>先生成通用的元嵌入，然后用额外的微调 MLP 来适配它。相反，它将特定任务的 LoRA 适配器插入到每个 transformer 层（共 24 层）中，并一次性完成编码。更多详细信息可以在<a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">我们的 arXiv 论文</a>中找到。</p><h4 id=\"parameter-dimensions\">参数 <code>dimensions</code></h4><p><code>dimensions</code> 参数允许用户以最低成本在空间效率和性能之间做出权衡。得益于 <code>jina-embeddings-v3</code> 中使用的 MRL 技术，您可以根据需要减少嵌入的维度（甚至可以降到单个维度！）。较小的嵌入对向量数据库更友好，其性能成本可以从下图中估算。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">参数 <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">长上下文嵌入模型中的迟分技术</div><div class=\"kg-bookmark-description\">在保留上下文信息的同时对长文档进行分块具有挑战性。我们引入了\"迟分技术\"技术，利用长上下文嵌入模型生成上下文化的块嵌入，以实现更好的检索应用。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>最后，<code>late_chunking</code> 参数控制是否使用<a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">我们上个月引入的</a>新分块方法来编码一批句子。当设置为 <code>true</code> 时，我们的 API 将连接 <code>input</code> 字段中的所有句子，并将它们作为单个字符串输入模型。换句话说，<strong>我们将输入中的句子视为原本来自同一个章节、段落或文档。</strong>在内部，模型嵌入这个长的连接字符串，然后执行迟分技术，返回一个与输入列表大小相匹配的嵌入列表。因此，列表中的每个嵌入都受到前面嵌入的影响。</p><p>从用户的角度来看，设置 <code>late_chunking</code> <em>不会</em>改变输入或输出格式。您只会注意到嵌入值的变化，因为它们现在是基于整个前文上下文而不是独立计算的。在使用时需要重要注意的是<code>late_chunking=True</code> 意味着每个请求中所有 <code>input</code> 的令牌总数限制为 8192，这是 <code>jina-embeddings-v3</code> 允许的最大上下文长度。当 <code>late_chunking=False</code> 时，没有这样的限制；令牌总数仅受制于<a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">Embedding API 的速率限制</a>。</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p>晚期分块开启与关闭对比：输入和输出格式保持相同，唯一的区别在于嵌入值。当启用 <code>late_chunking</code> 时，嵌入会受到 <code>input</code> 中整个前文上下文的影响，而不启用时，嵌入则是独立计算的。</p></figcaption></figure><h3 id=\"via-azure-aws\">通过 Azure 和 AWS</h3><p><code>jina-embeddings-v3</code> 现已在 AWS SageMaker 和 Azure Marketplace 上线。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>如果您需要在这些平台之外或在公司内部使用它，请注意该模型是在 CC BY-NC 4.0 许可下发布的。<a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">如有商业使用需求，请随时与我们联系。</a></p><h3 id=\"via-vector-databases-partners\">通过向量数据库和合作伙伴</h3><p>我们与 Pinecone、Qdrant 和 Milvus 等向量数据库提供商，以及 LlamaIndex、Haystack 和 Dify 等 LLM 编排框架密切合作。在发布时，我们很高兴地宣布 Pinecone、Qdrant、Milvus 和 Haystack 已经集成了对 <code>jina-embeddings-v3</code> 的支持，包括三个新参数：<code>task</code>、<code>dimensions</code> 和 <code>late_chunking</code>。其他已经集成了 <code>v2</code> API 的合作伙伴只需将模型名称改为 <code>jina-embeddings-v3</code> 即可支持 <code>v3</code>。不过，他们可能还未支持 <code>v3</code> 中引入的新参数。</p><h4 id=\"via-pinecone\">通过 Pinecone</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">通过 Qdrant</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">通过 Milvus</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">通过 Haystack</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">总结</h2><p>2023 年 10 月，我们发布了 <code>jina-embeddings-v2-base-en</code>，<a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">这是世界上第一个支持 8K 上下文长度的开源嵌入模型</a>。它是唯一一个支持长上下文并能与 OpenAI 的 <code>text-embedding-ada-002</code> 相媲美的文本嵌入模型。今天，经过一年的学习、实验和宝贵经验，我们很自豪地发布 <code>jina-embeddings-v3</code>——这是文本嵌入模型的一个新境界，也是我们公司的一个重要里程碑。</p><p>通过这次发布，我们继续在我们擅长的领域保持卓越：<strong>长上下文嵌入</strong>，同时也满足了来自行业和社区最迫切的需求——<strong>多语言嵌入</strong>。与此同时，我们将性能推向新高。通过任务特定 LoRA、MRL 和晚期分块等新功能，我们相信 <code>jina-embeddings-v3</code> 将真正成为各种应用的基础嵌入模型，包括 RAG、智能代理等。与近期基于 LLM 的嵌入模型（如 <code>NV-embed-v1/v2</code>）相比，我们的模型参数效率非常高，使其更适合生产和边缘设备部署。</p><p>展望未来，我们计划专注于评估和改进 <code>jina-embeddings-v3</code> 在低资源语言上的性能，并进一步分析由数据可用性限制导致的系统性失败。此外，<code>jina-embeddings-v3</code> 的模型权重及其创新功能和独特见解，将作为我们即将推出的模型的基础，包括 <code>jina-clip-v2</code>，<code>jina-reranker-v3</code> 和 <code>reader-lm-v2</code>。</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 是一个前沿的多语言文本嵌入模型，拥有 5.7 亿参数和 8192 个 token 长度，在 MTEB 上的性能超过了 OpenAI 和 Cohere 最新的专有嵌入模型。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}