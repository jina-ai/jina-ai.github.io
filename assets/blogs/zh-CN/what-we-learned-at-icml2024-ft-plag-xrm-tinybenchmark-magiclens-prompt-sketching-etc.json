{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "ICML2024 见闻：PLaG、XRM、tinyBenchmark、MagicLens、Prompt Sketching 等研究亮点",
  "html": "<p><a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">国际机器学习会议</a>是机器学习和人工智能领域最负盛名的会议之一，今年于 7 月 21 日至 27 日在维也纳举行。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Interior of a bustling academic conference hall with many attendees, some carrying backpacks, and research posters displayed \" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>这次会议是为期 7 天的密集学习体验，包含口头报告和与其他研究人员直接交流想法的机会。在强化学习、生命科学 AI、表示学习、多模态模型以及 AI 模型开发核心要素等领域都有大量有趣的工作。特别重要的是关于<a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">大语言模型物理学</a>的教程，该教程深入探讨了 LLM 的内部工作原理，并对 LLM 是记忆信息还是运用推理来生成内容这一问题给出了令人信服的答案。</p><h2 id=\"our-work-on-jina-clip-v1\">我们在 Jina-CLIP-v1 上的工作</h2><p>我们在\"多模态基础模型与具身 AI\"研讨会上以<a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">海报展示</a>的形式介绍了<a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">我们新的多模态模型</a> <code>jina-clip-v1</code> 背后的工作。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>与来自各个领域的国际同行会面并讨论我们的工作让人备受启发。我们的展示获得了许多积极的反馈，很多人对 Jina CLIP 统一多模态和单模态对比学习范式的方式很感兴趣。讨论内容涵盖了从 CLIP 架构的局限性到对其他模态的扩展，以及在肽和蛋白质匹配中的应用等方面。</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster.mp4\" poster=\"https://img.spacergif.org/v1/1138x640/0a/spacer.png\" width=\"1138\" height=\"640\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">3:09</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Michael Günther 展示 Jina CLIP</span></p></figcaption>\n        </figure><h2 id=\"our-favorites\">我们的最爱</h2><p>我们有机会讨论了许多其他研究人员的项目和演示，以下是我们最喜欢的几个：</p><h3 id=\"plan-like-a-graph-plag\">图式规划（PLaG）</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., & Pierrehumbert, J. B. (2024)。<i><em class=\"italic\" style=\"white-space: pre-wrap;\">异步规划推理中的图增强大语言模型。</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>许多人都知道\"少样本提示\"或\"思维链提示\"。<a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> 在 ICML 上展示了一个更好的新方法：<em>图式规划（PLaG）</em>。</p><p>她的想法很简单：给 LLM 的任务被分解成可以并行或顺序解决的子任务。这些子任务形成一个执行图。执行整个图就能解决高层次的任务。</p><p>在上面的视频中，Fangru Lin 通过一个易于理解的示例解释了这个方法。请注意，虽然这改进了结果，但当任务复杂度增加时，LLM 仍然会出现严重的性能下降。尽管如此，这仍是朝着正确方向迈出的重要一步，并能带来直接的实践收益。</p><p>对我们来说，有趣的是看到她的工作与我们在 <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> 的 prompt 应用如此相似。我们已经实现了类似图的 prompt 结构，不过，像她那样动态生成执行图是一个我们将要探索的新方向。</p><h3 id=\"discovering-environments-with-xrm\">使用 XRM 发现环境</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., &amp; Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>这篇论文提出了一个简单的算法，用于发现那些可能导致模型依赖于与标签相关但不能产生准确分类/相关性的特征的训练环境。一个著名的例子是水鸟数据集（参见 <a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a>），其中包含了在不同背景下的鸟类照片，这些鸟需要被分类为水鸟或陆鸟。在训练过程中，分类器检测图像中的背景是否显示水域，而不是依赖鸟类本身的特征。这样的模型在背景中没有水的情况下会错误分类水鸟。</p><p>为了缓解这种情况，需要检测模型依赖误导性背景特征的样本。这篇论文提出的 XRM 算法就是用来做这件事的。</p><p>该算法在训练数据集的两个不同部分训练两个模型。在训练过程中，某些样本的标签会被翻转。具体来说，如果另一个模型（未在相应样本上训练）对样本的分类不同，就会发生这种情况。通过这种方式，鼓励模型依赖虚假相关性。之后，你可以从训练数据中提取那些一个模型预测的标签与真实标签不同的样本。随后，可以使用这些信息来训练更稳健的分类模型，例如使用 <a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">Group DRO 算法</a>。</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">将你的 LLM 评估成本降低 140 倍！</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., &amp; Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>没错，你没听错。只用这一个技巧，LLM 评估的成本就可以降低到原来的很小一部分。</p><p>核心思想很简单：移除所有测试相同模型能力的评估样本。背后的数学原理不那么直观，但被在海报环节展示工作的 <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a> 解释得很清楚。注意，降低 140 倍的数据适用于流行的 MMLU 数据集（Massive Multitask Language Understanding）。对于你自己的评估数据集，这取决于样本的评估结果之间的相关程度。也许你可以跳过很多样本，或者只能跳过几个。</p><p>不妨试一试。我们会持续关注 <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> 能够减少多少评估样本。</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">使用多边际匹配间隙对比多重表征</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., &amp; Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Research paper diagram illustrating Multi-Marginal Matching Gap concepts, with titles, descriptions, and flow charts in blue \" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>这项工作解决了对比学习中的一个常见挑战：大多数对比损失函数（如 InfoNCE 损失）都是在数据点对之间运作，并测量正样本对之间的距离。为了扩展到大小为 k > 2 的正样本元组，对比学习通常试图将问题简化为多个配对，并累积所有正样本对的成对损失。作者在这里提出了 M3G（多边际匹配间隙）损失，这是 Sinkhorn 算法的一个修改版本，用于解决多边际最优传输问题。这个损失函数可以用于数据集包含大小为 k > 2 的正样本元组的场景，例如，同一对象的 >2 个图像、具有三个或更多模态的多模态问题，或带有三个或更多同一图像增强的 SimCLR 扩展。实验结果表明，这种方法优于将问题简单地归约为配对的方法。</p><h3 id=\"no-need-for-ground-truth\">不再需要真实标签！</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p>来自 <a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">斯坦福大学</a> 的 <a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a> 展示了他关于无需标注数据评估 LLM 的工作。请注意，虽然这是理论性工作，但它对高级 AI 系统的可扩展监督具有巨大潜力。这并不适合普通的 LLM 用户，但如果你从事 LLM 评估工作，这绝对值得关注。我们已经看到可以用这种方式评估 Jina AI 的智能体。一旦我们运行首批实验，我们会分享结果。</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">模型崩塌是否不可避免？通过积累真实和合成数据打破递归诅咒</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration of two machine learning data processes: &quot;Replace Data&quot; and &quot;Accumulate Data&quot;, with detailed flowcharts and model\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>最近多篇文章（如这篇<a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em></a>文章）预测，由于训练数据是从网络爬取的并且包含越来越多的合成数据，新训练的模型性能可能会随时间变差。</p><p>我们的同事 Scott Martens 也发表了<a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">一篇关于模型崩溃的文章</a>，并讨论了合成数据在模型训练中可能有用的情况。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>模型训练可能会崩溃，因为训练数据是由模型的早期版本或在相同数据上训练的模型产生的。这篇论文的实验展示了一个略微不同的情况：崩溃只在用合成数据<em>替换</em>真实数据时发生，这是之前实验中所做的。然而，当用额外的合成数据<em>增强</em>真实数据时，并未观察到结果模型性能的变化。这些结果表明类似模型崩溃的情况不会发生。不过，这再次证明，使用额外的合成数据并不能帮助训练出一个普遍优于用于创建这些合成数据点的模型。</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">AI 的脑部手术现在成为可能</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., &amp; Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>假设你想预测某人的职业但不想预测其性别。这项来自 Google Research、ETH Zürich、International Institute of Information Technology Hyderabad (IIITH) 和 Bar-Ilan University 的研究展示了如何使用引导向量和协方差匹配来控制偏差。</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - 基于开放式指令的自监督图像检索</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., &amp; Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>这篇论文介绍了 MagicLens 模型，这是一系列在查询图像 + 指令 + 目标图像三元组上训练的自监督图像检索模型。</p><p>作者介绍了一个数据收集/整理流程，该流程从网络收集图像对，并使用 LLM 合成开放式文本指令，这些指令将图像与超越单纯视觉相似性的多样化语义关系联系起来。这个流程用于生成 3670 万个高质量的广泛分布的三元组。然后使用这个数据集来训练一个具有共享参数的简单双编码器架构。视觉和语言编码器的主干网络使用 CoCa 或 CLIP base 和 large 变体进行初始化。引入了单个多头注意力池化器，将两个多模态输入压缩成单个嵌入。MagicLens 的训练目标是使用简单的 InfoNCE 损失，将查询图像和指令对与目标图像和空字符串指令进行对比。作者展示了基于指令的图像检索的评估结果。</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - 提示的新方式</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., &amp; Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>我们给 LLM 提示的方式正在改变。Prompt Sketching 让我们能够给生成模型提供固定约束。不是仅仅提供一个指令并希望模型按你想要的方式执行，而是定义一个完整的模板，强制模型生成你想要的内容。</p><p>不要将此与微调后提供结构化 JSON 格式的 LLM 混淆。使用微调方法，模型仍然可以自由生成任何内容。但 Prompt Sketching 不是这样。它为提示工程师提供了一个全新的工具箱，并开辟了需要探索的研究领域。在上面的视频中，Mark Müller 详细解释了这个新范式。</p><p>你也可以查看<a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">他们的开源项目 LMQL</a>。</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - 用于仓库级代码补全的选择性检索</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., &amp; Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>对于许多查询来说，RAG 并不能真正帮助模型，因为查询要么太简单，要么检索系统找不到相关文档，可能是因为根本没有相关文档。如果模型依赖误导性或缺失的来源，这会导致更长的生成时间和更低的性能。</p><p>这篇论文通过使 LLM 能够自我评估检索是否有用来解决这个问题。他们在一个训练用于填充代码模板空白的代码补全模型上展示了这种方法。对于给定的模板，系统首先决定检索结果是否有用，如果有用，则调用检索器。最后，无论是否向提示中添加检索结果，代码 LLM 都会生成缺失的上下文。</p><h3 id=\"the-platonic-representation-hypothesis\">柏拉图表征假说</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., &amp; Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration of &quot;The Platonic Representation Hypothesis&quot; with geometric shapes, mathematical text, and diagrams explaining a \" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p><em>柏拉图表征假说</em>认为神经网络模型会倾向于收敛到对世界的共同表征。借鉴<a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">柏拉图的形式理论</a>中存在\"理想\"领域的观点（这种理想以扭曲的形式出现在我们面前，我们只能间接观察），作者声称我们的 AI 模型似乎会收敛到对现实的单一表征，无论训练架构、训练数据甚至输入模态如何。数据规模和模型规模越大，它们的表征似乎越相似。</p><p>作者考虑向量表示，并使用核对齐度量来衡量表示对齐程度，特别是使用互近邻度量，该度量计算由两个核 <em>K1</em> 和 <em>K2</em> 所产生的 <em>k</em> 近邻集合的平均交集，并通过 <em>k</em> 进行归一化。这项研究提供了实证证据，表明随着模型和数据集规模的增长以及性能的提升，核之间的对齐程度越来越高。这种对齐甚至可以在比较不同模态的模型时观察到，比如文本模型和图像模型。</p><h2 id=\"summary\">总结</h2><p>虽然最初对扩展定律的热情开始减退，但 ICML 2024 展示了大量新的、多样化的、富有创造力的人才已经进入我们的领域，这让我们确信进展远未结束。</p><p>我们在 ICML 2024 玩得很开心，你可以打赌我们 2025 年一定会再来 🇨🇦。</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "我们在维也纳的 ICML 2024 度过了一段精彩的时光，现在想要与你分享我们所说、所见和所学的一切。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}