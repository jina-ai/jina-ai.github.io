{
  "slug": "model-soups-recipe-for-embeddings",
  "id": "681b63a077c406000104263b",
  "uuid": "e3fc45b3-6cf9-4a0b-863f-bc4a8417c436",
  "title": "Model Soup 的 Embedding 配方",
  "html": "<p>在这些艰难的时刻，没有什么比一碗美味的热汤更让人感到安慰了。</p><p>蔬菜汤是经典的意大利汤品之一：浓稠、丰盛、美味，结合了豆类、丰富的蔬菜以及米饭或面食。它的味道是多种食材组合的产物。这有点像东欧的罗宋汤、美国的砂锅菜，或泛亚洲地区的自制炒菜，它们都将现成的、廉价的食材结合成一道受欢迎的菜肴。</p><p>根据一系列论文（始于<a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a>）的观点，我们可以使用非常相似的配方来制作神经网络模型。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://proceedings.mlr.press/v162/wortsman22a.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time （模型汤：平均多个微调模型的权重可提高准确性，而不会增加推理时间）</div><div class=\"kg-bookmark-description\">The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set… （最大化模型准确性的传统方法是（1）使用各种超参数训练多个模型，以及（2）选择在预留验证集中表现最佳的单个模型……）</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-pmlr.ico\" alt=\"\"><span class=\"kg-bookmark-author\">PMLR</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://proceedings.mlr.press/v162/assets/images/logo-pmlr.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>“模型汤”（可惜不是“模型砂锅菜”或“模型炒菜”）是一类模型集成技术，旨在减轻优化训练数据和模型超参数的成本。在训练神经网络时，您通常会尝试不同的数据和超参数值并多次训练，以寻找性能最佳的结果。训练在计算上非常昂贵，并且成本会迅速增加。</p><p>相反，“模型汤”涉及使用不同的超参数和训练数据选择来训练多个模型——与您通常的做法相同——然后将它们组合起来。结果是比单个最佳模型性能更高、更稳健的模型。它不会节省成本，因为您仍然需要训练多个模型，但是您可以用相同的价格获得更好的结果。</p><p>模型汤方法已被证明对文本-图像多模态嵌入模型<a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">(Wortsman et al. 2022)</a>和生成式大型语言模型非常有用。（<a href=\"https://doi.org/10.1038/s42256-024-00975-8\">Takuya et al. 2025</a>）在 Jina AI，我们已经开始使用此技术来训练我们自己的模型，并且 <code>jina-embeddings-v3</code> 和 <code>reader-lm-v2</code> 都采用了模型汤。</p><p>在本文中，我们将研究模型汤，并展示我们使用它们的一些工作成果。具体来说：</p><ol><li>我们是否可以使用模型汤，通过合并训练过程中不同阶段的模型来提高性能？</li><li>我们是否可以合并使用不同数据集和针对不同任务训练的模型，以获得比训练单个模型更好的性能和更高的训练效率？</li></ol><p>这具有重要的潜在优势：</p><ul><li>模型汤可以具有更好、更稳健的性能。</li><li>多语言嵌入模型通常会因训练数据量不均而导致偏差和性能下降。如果能够单独训练每个任务或数据集上最好的模型，然后平等地组合它们，这将是一个福音。</li><li>通过以模块化的方式更改模型，一次更新一个组件模型，然后将其与其他模型重新合并，我们或许可以更好地进行持续学习和模型更新。</li></ul><h2 id=\"how-does-it-work\">它是如何工作的？</h2><p>合并多个模型的输出是统计决策理论中的一种古老技术。例如，在天气预报中，通常的做法是创建多个模型（通常由具有不同假设的不同人员创建），然后使用各种机制来平均它们的预测。如果每个模型的误差是随机分布的，则平均这些模型将导致误差更少的答案。</p><p>例如，如果您有三个不同的模型，它们输出二进制的“是”或“否”，并且每个模型在 10% 的时间内是错误的，那么三个模型中有两个是错误的概率仅为 2.8%。五个模型，采用多数决策标准，只有 0.856% 的时间会出错。</p><p>平均模型的工作原理相同，但不是组合不同模型的输出，而是组合模型本身。</p><p>使用的方法是<em>随机权重平均</em>的扩展 (<a href=\"https://auai.org/uai2018/proceedings/papers/313.pdf\">Izmailov et al. 2018</a>)，它依赖于对神经网络损失情况的深入了解，以表明在常见条件下，简单的权重平均可以提高模型的泛化性能。</p><p>平均模型的实际机制非常简单：您只需平均多个模型的权重。</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"380\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/image.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"><figcaption><span style=\"white-space: pre-wrap;\">如何合并模型以制作模型汤。这个例子非常小而简单，但仍然显示了该过程：将权重相加，然后除以要合并的模型的数量。</span></figcaption></figure><p>如果这看起来太容易了，那么重要的是要注意，以这种方式合并模型时存在局限性。您不能只是合并任意两个神经网络的权重，并期望它能够工作。</p><p>模型平均仅适用于非常相似的模型，即权重一开始彼此差异不大的模型。确保这一点的最好方法是预训练一个模型，然后通过使用不同的超参数或不同的数据对它们进行微调，来创建该模型的多个变体。这些模型通常足够相似，可以进行平均。</p><p>用更专业的术语来说，预训练通常会生成一个权重接近损失盆地底部的模型，而微调则不容易导致逃离该损失盆地。如果要合并的所有模型在同一个损失盆地中都有权重，那么它们的权重将非常接近，并且平均它们很可能会起作用。这不能保证，但根据经验，它似乎经常足够有效。</p><h2 id=\"experimental-setup\">实验设置</h2><p><strong>基础模型</strong>：对于此处描述的实验，我们使用了来自 FacebookAI 的 <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code></a> (<a href=\"https://aclanthology.org/2020.acl-main.747/\">Conneau et al. 2020</a>) 作为我们的预训练基础模型。该模型具有 2.8 亿个参数，并且已在包含大约 100 种语言文本的 2.5TB Common Crawl 数据上进行了预训练。</p><p>在执行实验之前，我们对我们整理的句子对训练集进行了微调 <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code></a>，用于嵌入训练。</p><p><strong>训练数据</strong>：Jina AI 维护着用于训练的自定义整理数据集。对于第一个实验，我们使用了专门为六种语言（英语、阿拉伯语、德语、西班牙语、日语和中文）的对比训练而整理的句子三元组。对于第二个实验，我们使用了英语中特定于任务的训练数据集。</p><p><strong>评估</strong>：我们使用了 <a href=\"https://github.com/embeddings-benchmark/mteb/tree/main/docs/mmteb\">MMTEB 基准集</a>的相关部分 (<a href=\"https://arxiv.org/abs/2502.13595\">Enevoldsen et al. 2025</a>) 和 <a href=\"https://project-miracl.github.io/\">MIRACL 基准</a> (<a href=\"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00595/117438/MIRACL-A-Multilingual-Retrieval-Dataset-Covering\">Zhang et al. 2023</a>) 来评估通过我们的训练和合并产生的模型。</p><h3 id=\"experiment-1-single-run-averaging\">实验 1：单次运行平均</h3><p>对于此实验，我们使用了所有六种语言的对比句子三元组，混合在一起，总共进行了 6,000 个训练步骤，批处理大小为 1,024 个项目。在每 2,000 个步骤时，我们保存模型状态以进行平均，从而生成 3 个模型，每个模型都反映了训练过程中的不同点。</p><p>我们平均了这三个模型以生成最终模型。然后，我们针对 MMTEB-STS 和 MIRACL 基准集测试了合并的模型和三个保存的检查点。</p><p>我们的结果总结在下表中：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>MIRACL<br>(avg 6 languages) （平均 6 种语言）</th>\n<th>MMTEB-STS English<br>(avg 8 benchmarks) （平均 8 个基准）</th>\n<th>MMTEB-STS Multilingual<br>(avg 6 benchmarks) （平均 6 个基准）</th>\n<th>Average of 20 benchmarks （20 个基准的平均值）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>No triplet training （没有三元组训练）</td>\n<td>0.3163</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.6276</td>\n</tr>\n<tr>\n<td>Step 2000 （步骤 2000）</td>\n<td>0.4631</td>\n<td><strong>0.7924</strong></td>\n<td>0.7561</td>\n<td>0.6813</td>\n</tr>\n<tr>\n<td>Step 4000 （步骤 4000）</td>\n<td>0.4639</td>\n<td>0.7902</td>\n<td><strong>0.7583</strong></td>\n<td>0.6812</td>\n</tr>\n<tr>\n<td>Step 6000 (final) （步骤 6000（最终））</td>\n<td><strong>0.4680</strong></td>\n<td>0.7891</td>\n<td>0.7575</td>\n<td>0.6818</td>\n</tr>\n<tr>\n<td>Merged model<br>(all 3 stored checkpoints) （合并的模型<br>（所有 3 个存储的检查点））</td>\n<td>0.4669</td>\n<td>0.7910</td>\n<td>0.7579</td>\n<td><strong>0.6823</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>与存储的检查点中在单个基准或使用的三个基准电池中的任何一个中表现最佳的模型相比，与以前的检查点合并通常不会产生性能更好的模型。但是，它确实产生了所有基准平均在一起的最佳模型。</p><p>在单个基准中，合并模型与性能最佳的检查点之间的差异在每种情况下都小于 0.01。这不仅适用于上表中的平均值，而且适用于每个单独的测试。</p><p>这表明合并不同的训练检查点可以以非常小的性能成本生成更健壮的模型。</p><p>此外，通过合并不同的检查点，我们可以有效地防止过度训练。过度训练最近已成为神经网络中的一个重要课题。（<a href=\"https://arxiv.org/abs/2503.19206v2\">Springer et al., 2025</a>）可以以某种方式训练网络，使其在进一步微调后变得更难且性能更差。</p><p>由于我们实验中表现最佳的检查点通常不是最后一个检查点，因此我们可能在 6,000 个训练步骤中过度训练了我们的模型。合并的模型非常接近于匹配所有测试中最佳检查点的性能，从而消除了过度训练的缺陷。</p><h3 id=\"experiment-2-averaging-models-trained-for-different-tasks\">实验 2：平均针对不同任务训练的模型</h3><p>对于此实验，我们训练了三个模型，每个模型用于一个不同的常见嵌入任务：</p><ul><li><strong>语义相似度</strong>：测量两个文本之间含义的相对重叠或相似度，通常长度相当。</li><li><strong>基于文本查询的文档检索</strong>：查找最能满足查询的文档。查询通常比它们匹配的文档短得多。</li><li><strong>问答</strong>：查找最能回答自然语言问题的文档。问题通常也比它们匹配的文本短得多。</li></ul><p>同时训练所有三个任务的模型是相当困难的，因为目标非常不同，我们希望模型融合能够改善这个过程。</p><p>根据之前的经验，我们知道每个任务都需要不同数量的训练周期。训练总结如下：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>任务</th>\n<th>训练步数<br>(batchsize = 1,024)</th>\n<th>训练数据集大小<br>(以项目计)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>问答 (QA)</td>\n<td>2,000</td>\n<td>256,000</td>\n</tr>\n<tr>\n<td>文档检索</td>\n<td>3,000</td>\n<td>384,000</td>\n</tr>\n<tr>\n<td>语义相似度 (STS)</td>\n<td>1,000</td>\n<td>128,000</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>这产生了三个模型，然后我们将它们合并为一个模型。我们使用 MMTEB 基准集中与这三个任务相关的部分测试了生成的模型：<a href=\"https://project-miracl.github.io/\">MIRACL</a>、<a href=\"https://huggingface.co/collections/zeta-alpha-ai/nanobeir-66e1a0af21dfd93e620cd9f6\">NanoBEIR</a> 和 STSEval（MMTEB 的英语和多语言部分）。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(平均 6 种语言)</th>\n<th>NanoBEIR<br>(平均 13 个基准)</th>\n<th>MMTEB-STS 英语<br>(平均 9 个基准)</th>\n<th>MMTEB-STS 多语言<br>(平均 6 个基准)</th>\n<th>平均 34 个基准</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>无三元组训练</td>\n<td>0.3163</td>\n<td>0.5089</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.5876</td>\n</tr>\n<tr>\n<td>QA 训练</td>\n<td><strong>0.4489</strong></td>\n<td>0.5332</td>\n<td>0.7843</td>\n<td>0.7535</td>\n<td>0.6237</td>\n</tr>\n<tr>\n<td>检索训练</td>\n<td>0.4272</td>\n<td><strong>0.5360</strong></td>\n<td>0.7766</td>\n<td>0.7340</td>\n<td>0.6154</td>\n</tr>\n<tr>\n<td>STS 训练</td>\n<td>0.1779</td>\n<td>0.4519</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.5508</td>\n</tr>\n<tr>\n<td>合并模型</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td><strong>0.6240</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>我们在此看到，特定于任务的训练模型在每个任务上都具有最佳性能。MIRACL 主要是一个问答基准，即使它被称为检索基准，并且经过 QA 训练的模型在它上面的表现优于所有其他模型，包括合并模型。NanoBEIR 是一个更传统的信息检索基准集，我们看到经过检索训练的模型在它上面表现最佳。语义相似度 (STS) 模型在这些基准上的得分非常低，但在显式的 STS 任务上击败了其他模型。对于每个类别，合并模型的性能都比单任务训练模型差。</p><p>但再次，如果我们在所有基准上取平均值，合并模型的表现优于其他模型，尽管它的得分仅比经过 QA 训练的模型略有提高，并且它在 STS 任务上的表现非常差。</p><p>我们还仅合并了 QA 和检索模型，并在相同的基准上对生成的模型进行了评分：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(平均 6 种语言)</th>\n<th>NanoBEIR<br>(平均 13 个基准)</th>\n<th>MMTEB-STS 英语<br>(平均 9 个基准)</th>\n<th>MMTEB-STS 多语言<br>(平均 6 个基准)</th>\n<th>平均 34 个测试</th>\n<th>平均<br>QA &amp; IR<br>(19 个测试)</th>\n<th>平均 STS<br>(15 个测试)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>最佳任务训练模型</td>\n<td>0.4489</td>\n<td>0.5360</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.6237</td>\n<td>0.5066</td>\n<td><strong>0.7857</strong></td>\n</tr>\n<tr>\n<td>合并模型</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td>0.6240</td>\n<td>0.4973</td>\n<td>0.7845</td>\n</tr>\n<tr>\n<td>QA+检索合并模型</td>\n<td><strong>0.4610</strong></td>\n<td><strong>0.5404</strong></td>\n<td>0.7878</td>\n<td>0.7498</td>\n<td><strong>0.6288</strong></td>\n<td><strong>0.5153</strong></td>\n<td>0.7726</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>我们在此看到，虽然我们可以通过合并两个任务的训练模型来提高问答和检索的性能，但添加经过 STS 训练的模型会降低所有类别的特定于任务的性能。这表明语义相似度在某些重要方面与 QA 和检索不同，并且经过 STS 训练的模型不适合与其他两个模型合并。</p><p>这可能是因为问答和检索涉及将短文本（问题和查询）与较长的文档进行匹配，而语义相似度涉及比较长度更相似的文档。</p><p><a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a> 描述了一种选择性的平均方法，他们称之为“贪婪”合并。它涉及采用一个模型，通常是一组模型中性能最佳的模型，然后仅将那些单独提高性能的模型添加到其中。只有三个模型，因此在此实验中使用贪婪合并意义不大。但是，我们可以想象一个有更多模型的情况，并使用类似这样的技术作为确定任务之间相似程度的基础。我们在此发现语义相似度与其他两个不同。然后，我们可以评估一个模型何时可以执行许多任务，以及何时使用不同的模型更具成本效益。</p><h2 id=\"soup%E2%80%99s-on\">模型融合开始！</h2><p>模型融合将多样性融入到大于其各部分之和的东西中。这种方法的价值在于它能够提供更大的一致性、鲁棒性，并充当防止过度训练的保障，而无需额外的训练成本。我们的实验表明，合并检查点或特定于任务的模型可以提高整体性能，即使它有时会以牺牲特定于任务的峰值为代价。</p><p>最后，模型融合提供了一种实用且非常简单的方法来构建更具适应性的模型，尽管它有一些注意事项。它不是万能药，并且仅适用于模型已经非常相似的情况。</p><p>正如他们在互联网上所说，<em>Your Mileage May Vary</em>。但是在您训练模型时，找出模型融合是否有帮助既便宜又容易。</p>",
  "comment_id": "681b63a077c406000104263b",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/Heading--6-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-07T15:44:00.000+02:00",
  "updated_at": "2025-05-07T19:56:02.000+02:00",
  "published_at": "2025-05-07T18:43:10.000+02:00",
  "custom_excerpt": "Boost robustness and performance with model soups: averaging weights. No extra cost, better results.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "authors": [
    {
      "id": "6360e7e05e0f6e004d70bd99",
      "name": "Bo Wang",
      "slug": "bo",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
      "cover_image": null,
      "bio": "Developer @Jina, Contributor to open source ",
      "website": "https://bwanglzu.github.io/",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@bo_wangbo",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "primary_author": {
    "id": "6360e7e05e0f6e004d70bd99",
    "name": "Bo Wang",
    "slug": "bo",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
    "cover_image": null,
    "bio": "Developer @Jina, Contributor to open source ",
    "website": "https://bwanglzu.github.io/",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@bo_wangbo",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/model-soups-recipe-for-embeddings/",
  "excerpt": "使用模型汤 (Model Soups) 提升稳健性和性能：平均权重。 无需额外成本，效果更佳。",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}