{
  "slug": "a-practical-guide-to-deploying-search-foundation-models-in-production",
  "id": "679b56ba42b46600019a86e3",
  "uuid": "458c0de5-aedb-4513-8ffd-47c027d204ad",
  "title": "在生产环境中部署搜索基础模型的实用指南",
  "html": "<p>在 Jina AI，我们的使命是为企业用户提供高质量的搜索解决方案。为实现这一目标，我们通过多种渠道提供模型访问。然而，为特定用例选择合适的渠道可能比较困难。在这篇文章中，我们将带您了解决策过程并分析权衡，根据您的用户画像和需求为您提供选择访问搜索基础模型最佳方式的实用指导。</p><h2 id=\"jina-search-foundation-models\">Jina 搜索基础模型</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">我们的搜索基础模型</div><div class=\"kg-bookmark-description\">我们从一开始就在推动搜索模型的发展。查看下面我们的模型演进历程—悬停或点击以了解每个里程碑。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-18.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Jina AI</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-models.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>我们的搜索基础模型包括：</p><ul><li><strong>Embeddings</strong>：将数字对象的信息转换为 embedding 向量，捕获其基本特征。</li><li><strong>Rerankers</strong>：对查询-文档集进行深入语义分析，提高搜索相关性。</li><li><strong>小型语言模型</strong>：包括专门的 SLM，如用于 HTML2Markdown 或信息提取等特定任务的 <code>ReaderLM-v2</code>。</li></ul><p>在本文中，我们将探讨 <code>jina-embeddings-v3</code> 的不同部署选项，比较三种主要方法：</p><ul><li>使用 <a href=\"https://jina.ai/api-dashboard\" rel=\"noreferrer\">Jina API</a></li><li>通过 CSP 部署，如 <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS SageMaker</a></li><li>在 Kubernetes 集群上<a href=\"https://jina.ai/api-dashboard/license-config\">使用商业许可</a>自行托管</li></ul><p>我们将评估每种方法的成本影响和优势，帮助您确定最适合您需求的选项。</p><h2 id=\"key-performance-metrics\">关键性能指标</h2><p>我们在不同使用场景下评估了五个关键性能指标：</p><ul><li><strong>请求成功率</strong>：向嵌入服务器发送的成功请求百分比</li><li><strong>请求延迟</strong>：嵌入服务器处理并返回请求所需的时间</li><li><strong>Token 吞吐量</strong>：嵌入服务器每秒可处理的 token 数量</li><li><strong>每 Token 成本</strong>：每个文本单元的总处理成本</li></ul><p>对于在 Kubernetes 集群上自托管的 Jina embeddings，我们还研究了<em>动态批处理</em>的影响。这个功能会将请求排队直到达到最大批量大小（<code>jina-embeddings-v3</code> 为 8,192）再生成 embeddings。</p><p>我们有意从分析中排除了两个重要的性能因素：</p><ul><li><em>自动扩展</em>：虽然这对于工作负载变化的云部署至关重要，但其有效性取决于多个变量—硬件效率、网络架构、延迟和实现选择。这些复杂性超出了我们当前的讨论范围。<strong>请注意 Jina API 包含自动扩展功能，我们的结果反映了这一点。</strong></li><li><em>量化</em>：虽然这种技术可以创建更小的 embedding 向量并减少数据传输，但主要优势来自其他系统组件（数据存储和向量距离计算），而不是减少的数据传输。由于我们专注于直接模型使用成本，因此在本分析中未包含量化。</li></ul><p>最后，我们将研究每种方法的财务影响，同时考虑总拥有成本和每 token/每请求的费用。</p><h2 id=\"deployment-setup\">部署设置</h2><p>我们评估了 <code>jina-embeddings-v3</code> 的三种部署和使用场景：</p><h3 id=\"using-the-jina-api\">使用 Jina API</h3><p>所有 Jina AI embedding 模型都可以通过 <a href=\"https://jina.ai/api-dashboard/embeddings\" rel=\"noreferrer\">Jina API</a> 访问。访问采用预付费 token 系统，提供一百万个免费 token 用于测试。我们通过从德国办公室通过互联网进行 API 调用来评估性能。</p><h3 id=\"using-aws-sagemaker\">使用 AWS SageMaker</h3><p>Jina Embeddings v3 <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">可供 AWS 用户通过 SageMaker 使用</a>。使用需要订阅此模型的 AWS 服务。对于示例代码，我们<a href=\"https://github.com/jina-ai/jina-sagemaker/blob/main/notebooks/Real-time%20embedding.ipynb\">提供了一个笔记本</a>，展示如何使用 AWS 账户订阅和使用 Jina AI 模型。</p><p>虽然这些模型也在 <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Microsoft Azure</a> 和 <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">Google Cloud Platform</a> 上提供，但我们的测试重点是 AWS。我们预计在其他平台上会有类似的性能。所有测试都在 <code>us-east-1</code> 区域的 <code>ml.g5.xlarge</code> 实例上运行。</p><h3 id=\"self-hosting-on-kubernetes\">在 Kubernetes 上自托管</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">要获取我们的 CC-BY-NC 模型的商业许可，您首先需要从我们获得许可证。<a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">请随时联系我们的销售团队。</a></div></div><p>我们用 Python 构建了一个 FastAPI 应用程序，该应用程序<a href=\"https://huggingface.co/jinaai/jina-embeddings-v3\">使用 <code>SentenceTransformer</code> 库从 HuggingFace 加载 <code>jina-embeddings-v3</code></a>。该应用程序包含两个端点：</p><ul><li><code>/embed</code>：接收文本段落作为输入并返回其 embeddings</li><li><code>/health</code>：提供基本的健康监控</li></ul><p>我们将其作为 Kubernetes 服务部署在 Amazon 的 Elastic Kubernetes Service 上，使用 <code>us-east-1</code> 区域的 <code>g5.xlarge</code> 实例。</p><h4 id=\"with-and-without-dynamic-batching\">有无动态批处理</h4><p>我们在 Kubernetes 集群中测试了两种配置的性能：一种是收到请求时立即处理，另一种是使用动态批处理。在动态批处理的情况下，服务会等待直到队列中收集了 <code>MAX_TOKENS</code>（8192）个 token，或达到预定义的 2 秒超时，然后才调用模型并计算 embeddings。这种方法提高了 GPU 利用率并减少了 GPU 内存的碎片化。</p><p>对于每个部署场景，我们通过改变三个关键参数进行测试：</p><ul><li><strong>批量大小</strong>：每个请求包含 1、32 或 128 个文本段落用于 embedding</li><li><strong>段落长度</strong>：我们使用包含 128、512 或 1,024 个 token 的文本段落</li><li><strong>并发请求</strong>：我们同时发送 1、5 或 10 个请求</li></ul><h2 id=\"benchmark-results\">基准测试结果</h2><p>下表是每个使用场景的结果汇总，对上述三个变量的所有设置取平均值。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>指标</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>自托管<br>带批处理</th>\n<th>自托管<br>标准</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>请求成功率</td>\n<td>87.6%</td>\n<td><strong>99.9%</strong></td>\n<td>55.7%</td>\n<td>58.3%</td>\n</tr>\n<tr>\n<td>延迟<br>（秒）</td>\n<td>11.4</td>\n<td>3.9</td>\n<td>2.7</td>\n<td><strong>2.6</strong></td>\n</tr>\n<tr>\n<td>按成功率标准化的延迟<br>（秒）</td>\n<td>13.0</td>\n<td><strong>3.9</strong></td>\n<td>4.9</td>\n<td>4.4</td>\n</tr>\n<tr>\n<td>Token 吞吐量<br>（tokens/秒）</td>\n<td>13.8K</td>\n<td><strong>15.0K</strong></td>\n<td>2.2K</td>\n<td>2.6K</td>\n</tr>\n<tr>\n<td>峰值 Token 吞吐量<br>（tokens/秒）</td>\n<td><strong>63.0K</strong></td>\n<td>32.2K</td>\n<td>10.9K</td>\n<td>10.5K</td>\n</tr>\n<tr>\n<td>价格<br>（每百万 token 的 USD）</td>\n<td>$0.02</td>\n<td>$0.07</td>\n<td>$0.32</td>\n<td>$0.32</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"request-success-rate\">请求成功率</h2><p>我们的测试中，成功率从 SageMaker 接近完美的 99.9% 到自托管解决方案的 56-58% 不等，这突出表明了在生产系统中实现 100% 可靠性仍然难以实现。三个关键因素导致了这一点：</p><ul><li>网络不稳定性在云环境中也会导致不可避免的失败</li><li>资源竞争，特别是 GPU 内存，在负载下会导致请求失败</li><li>必要的超时限制意味着某些请求必须失败以维护系统健康</li></ul><h3 id=\"success-rate-by-batch-size\">按批量大小划分的成功率</h3><p>在自托管 Kubernetes 配置中，大批量大小经常导致内存不足错误。在没有动态批处理的情况下，所有包含 32 或 128 个项目的批量请求都因此原因而失败。即使实施了动态批处理，大批量的失败率仍然显著较高。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8017-ba56-e35215a76fc4\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8064-ab87-e44fc044673d\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">批量大小</th><th id=\"zt<p\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"kPia\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"wgj>\" class=\"simple-table-header-color simple-table-header\">自托管<br>(动态批处理)<br></th><th id=\"OwMn\" class=\"simple-table-header-color simple-table-header\">自托管<br>(无批处理)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-80e1-b4a8-c6f8a3b03117\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"zt<p\" class=\"\">100%</td><td id=\"kPia\" class=\"\">100%</td><td id=\"wgj>\" class=\"\">97.1%</td><td id=\"OwMn\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8096-93c6-deff80bbeffc\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">32</th><td id=\"zt<p\" class=\"\">86.7%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">50.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr><tr id=\"1847c956-b7d2-80fe-a61d-ea3923f34aac\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"zt<p\" class=\"\">76.2%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">24.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr></tbody></table>\n\n<p>虽然这个问题可以通过自动扩展轻松解决，但我们在这里选择不探讨该选项。自动扩展会导致不可预测的成本增加，而且考虑到可用的自动扩展配置选项数量众多，很难提供切实可行的见解。</p>\n\n<h3 id=\"success-rate-by-concurrency-level\">并发级别的成功率</h3>\n\n<p>并发性（同时处理多个请求的能力）对自托管 Kubernetes 配置的请求成功率既没有显著影响也没有一致性影响，对 AWS SageMaker 的影响也很小，至少在并发级别为 10 的情况下是这样。</p>\n\n<table id=\"1847c956-b7d2-80a7-9beb-f1ebe6e1e529\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8011-bcc1-d295e87b8e54\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">并发数</th><th id=\"KV|=\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"G@`e\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"[~nZ\" class=\"simple-table-header-color simple-table-header\">自托管<br>(动态批处理)<br></th><th id=\"mHG:\" class=\"simple-table-header-color simple-table-header\">自托管<br>(无批处理)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8041-9a23-c1338c5d3f23\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"KV|=\" class=\"\">93.3%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">57.5%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80eb-86a9-f249c86ddfdf\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">5</th><td id=\"KV|=\" class=\"\">85.7%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">58.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80ac-a3ad-eadd81c69cb2\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">10</th><td id=\"KV|=\" class=\"\">83.8%</td><td id=\"G@`e\" class=\"\">99.6%</td><td id=\"[~nZ\" class=\"\">55.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr></tbody></table>\n\n<h3 id=\"success-rate-by-token-length\">按 Token 长度的成功率</h3>\n\n<p>具有高 token 数量的长段落对 Jina Embedding API 和具有动态批处理的 Kubernetes 的影响与大批量类似：随着大小增加，失败率显著上升。然而，虽然没有动态批处理的自托管解决方案在处理大批量时几乎总是失败，但它们在处理单个长段落时表现更好。至于 SageMaker，长段落长度——就像并发性和批量大小一样——对请求成功率没有明显影响。</p>\n\n<table id=\"1847c956-b7d2-8003-8d50-eddc36a83d33\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-804b-8352-d65d5e6bdd0e\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">段落长度<br>(tokens)<br></th><th id=\"CDn]\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"@nCV\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"H?G{\" class=\"simple-table-header-color simple-table-header\">自托管<br>(动态批处理)<br></th><th id=\"]{Mf\" class=\"simple-table-header-color simple-table-header\">自托管<br>(无批处理)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8011-8a92-d0986d045c79\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">98.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-809f-b073-fa48e7287c13\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">512</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">66.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8019-9f1f-cefd810c520d\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">1024</th><td id=\"CDn]\" class=\"\">99.3%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">33.3%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80c7-a745-fcdaf408f3d0\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">8192</th><td id=\"CDn]\" class=\"\">51.1%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">29.4%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr></tbody></table>\n\n<h2 id=\"request-latency\">请求延迟</h2>\n\n<p>所有延迟测试都在并发级别 1、5 和 10 下重复进行了五次。响应时间是五次尝试的平均值。请求吞吐量是响应时间（秒）的倒数乘以并发数。</p>\n\n<h3 id=\"jina-api\">Jina API</h3>\n\n<p>Jina API 的响应时间主要受批量大小的影响，与并发级别无关。虽然段落长度也会影响性能，但其影响并不简单直接。作为一般原则，包含更多数据的请求（无论是通过更大的批量还是更长的段落）都需要更长的处理时间。</p>\n\n<h4 id=\"concurrency-1\">并发数 1：</h4>\n\n<table>\n<thead>\n<tr>\n<th>批量大小</th>\n<th>段落长度（tokens）</th>\n<th>响应时间（毫秒）</th>\n<th>请求吞吐量（请求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>801</td>\n<td>1.25</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>724</td>\n<td>1.38</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>614</td>\n<td>1.63</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1554</td>\n<td>0.64</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1620</td>\n<td>0.62</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2283</td>\n<td>0.44</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4441</td>\n<td>0.23</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5430</td>\n<td>0.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>6332</td>\n<td>0.16</td>\n</tr>\n</tbody>\n</table><h4 id=\"concurrency-5\">并发 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（按 token）</th>\n<th>响应时间（毫秒）</th>\n<th>请求吞吐量（请求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>689</td>\n<td>7.26</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>599</td>\n<td>8.35</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>876</td>\n<td>5.71</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1639</td>\n<td>3.05</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2511</td>\n<td>1.99</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4728</td>\n<td>1.06</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2766</td>\n<td>1.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5911</td>\n<td>0.85</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>18621</td>\n<td>0.27</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10\">并发 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（按 token）</th>\n<th>响应时间（毫秒）</th>\n<th>请求吞吐量（请求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>790</td>\n<td>12.66</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>669</td>\n<td>14.94</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>649</td>\n<td>15.41</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1384</td>\n<td>7.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3409</td>\n<td>2.93</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>8484</td>\n<td>1.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3441</td>\n<td>2.91</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>13070</td>\n<td>0.77</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>17886</td>\n<td>0.56</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>对于单个请求（批大小为 1）：</p><ul><li>响应时间保持相对稳定，无论段落长度如何，都在约 600-800 毫秒范围内</li><li>更高的并发（5 或 10 个同时请求）不会显著降低每个请求的性能</li></ul><p>对于较大的批量（32 和 128 项）：</p><ul><li>响应时间显著增加，批大小为 128 时所需时间大约是单个请求的 4-6 倍</li><li>段落长度对大批量的影响更为明显</li><li>在高并发（10）和大批量（128）的情况下，这种组合导致响应时间显著延长，最长段落的处理时间接近 18 秒</li></ul><p>对于吞吐量：</p><ul><li>在运行并发请求时，较小的批量通常能实现更好的吞吐量</li><li>在并发度为 10、批大小为 1 时，系统达到最高吞吐量，约为每秒 15 个请求</li><li>较大的批量始终显示较低的吞吐量，在多个场景中降至每秒不到 1 个请求</li></ul><h3 id=\"aws-sagemaker\">AWS SageMaker</h3><p>AWS SageMaker 测试使用 <code>ml.g5.xlarge</code> 实例进行。</p><h4 id=\"concurrency-1-1\">并发 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（按 token）</th>\n<th>响应时间（毫秒）</th>\n<th>请求吞吐量（请求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>189</td>\n<td>5.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>219</td>\n<td>4.56</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>221</td>\n<td>4.53</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>377</td>\n<td>2.66</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3931</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2215</td>\n<td>0.45</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>1120</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>3408</td>\n<td>0.29</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>5765</td>\n<td>0.17</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-1\">并发 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（按 token）</th>\n<th>响应时间（毫秒）</th>\n<th>请求吞吐量（请求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>443</td>\n<td>11.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>426</td>\n<td>11.74</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>487</td>\n<td>10.27</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1257</td>\n<td>3.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2245</td>\n<td>2.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4159</td>\n<td>1.20</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2444</td>\n<td>2.05</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>6967</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>14438</td>\n<td>0.35</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-1\">并发 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（按 token）</th>\n<th>响应时间（毫秒）</th>\n<th>请求吞吐量（请求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>585</td>\n<td>17.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>602</td>\n<td>16.60</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>687</td>\n<td>14.56</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1650</td>\n<td>6.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3555</td>\n<td>2.81</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>7070</td>\n<td>1.41</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3867</td>\n<td>2.59</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>12421</td>\n<td>0.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>25989</td>\n<td>0.38</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>与 Jina API 相比的主要差异：</p><ul><li>基础性能：SageMaker 在处理小请求时（单个项目、短段落）明显更快 - 约 200 毫秒，而 Jina 需要 700-800 毫秒。</li><li>扩展行为：<ul><li>两种服务在处理更大的批量和更长的段落时都会变慢</li><li>SageMaker 在处理大批量（128）和长段落（1024 token）时显示出更显著的性能下降</li><li>在高并发（10）和最大负载（批量 128，1024 token）下，SageMaker 需要约 26 秒，而 Jina 需要约 18 秒</li></ul></li><li>并发影响：<ul><li>两种服务的吞吐量都从增加的并发中受益</li><li>两种服务在不同并发级别上保持类似的吞吐量模式</li><li>在并发度为 10 时，SageMaker 实现了稍高的峰值吞吐量（17 req/s vs 15 req/s）</li></ul></li></ul><h3 id=\"self-hosted-kubernetes-cluster\">自托管 Kubernetes 集群</h3><p>自托管测试在 <a href=\"https://aws.amazon.com/eks/\">Amazon 的 Elastic Kubernetes Service</a> 上使用 <code>g5.xlarge</code> 实例进行。</p><h4 id=\"concurrency-1-2\">并发度 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（tokens）</th>\n<th>无批处理时间（ms）</th>\n<th>无批处理吞吐量（req/s）</th>\n<th>动态时间（ms）</th>\n<th>动态吞吐量（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>416</td>\n<td>2.40</td>\n<td>2389</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>397</td>\n<td>2.52</td>\n<td>2387</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>396</td>\n<td>2.52</td>\n<td>2390</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1161</td>\n<td>0.86</td>\n<td>3059</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1555</td>\n<td>0.64</td>\n<td>1496</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2424</td>\n<td>0.41</td>\n<td>2270</td>\n<td>0.44</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-2\">并发度 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（tokens）</th>\n<th>无批处理时间（ms）</th>\n<th>无批处理吞吐量（req/s）</th>\n<th>动态时间（ms）</th>\n<th>动态吞吐量（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>451</td>\n<td>11.08</td>\n<td>2401</td>\n<td>2.08</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>453</td>\n<td>11.04</td>\n<td>2454</td>\n<td>2.04</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>478</td>\n<td>10.45</td>\n<td>2520</td>\n<td>1.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1447</td>\n<td>3.46</td>\n<td>1631</td>\n<td>3.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2867</td>\n<td>1.74</td>\n<td>2669</td>\n<td>1.87</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4154</td>\n<td>1.20</td>\n<td>4026</td>\n<td>1.24</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-2\">并发度 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（tokens）</th>\n<th>无批处理时间（ms）</th>\n<th>无批处理吞吐量（req/s）</th>\n<th>动态时间（ms）</th>\n<th>动态吞吐量（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>674</td>\n<td>14.84</td>\n<td>2444</td>\n<td>4.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>605</td>\n<td>16.54</td>\n<td>2498</td>\n<td>4.00</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>601</td>\n<td>16.64</td>\n<td>781*</td>\n<td>12.80</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>2089</td>\n<td>4.79</td>\n<td>2200</td>\n<td>4.55</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>5005</td>\n<td>2.00</td>\n<td>4450</td>\n<td>2.24</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>7331</td>\n<td>1.36</td>\n<td>7127</td>\n<td>1.40</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">† 这个异常结果是动态批处理 2 秒超时的副产品。在并发度为 10，每个请求发送 1024 个 tokens 的数据时，队列几乎立即填满，批处理系统无需等待超时。在较低的大小和并发度下，它需要等待，自动为每个请求增加两秒的浪费时间。这种非线性在未优化的批处理过程中很常见。</div></div><p>当处理超过 16,384 个 tokens 的请求时，我们的自托管设置会因服务器错误（通常是内存不足）而失败。这与并发度水平无关。因此，这里没有显示更多数据的测试。</p><p>高并发度会使响应时间大致呈线性增加：并发度为 5 的响应时间大约是 1 的五倍。并发度为 10 时，响应时间约为十倍。</p><p>动态批处理会使小批量的响应时间增加约两秒。这是因为批处理队列在处理未满的批次前会等待 2 秒。然而，对于较大的批量，它在响应时间上带来了适度的改进。</p><h2 id=\"token-throughput\">Token 吞吐量</h2><p>在所有平台上，Token 吞吐量都随着批量大小增加、段落长度增加和并发度提高而增加。因此，我们只展示高使用率水平的结果，因为较低水平无法提供有意义的实际性能指标。</p><p>所有测试都在并发度为 10 的情况下进行，每个请求 16,384 个 tokens，对五个请求取平均值。我们测试了两种配置：批大小 32 配合 512-token 段落，以及批大小 128 配合 128-token 段落。两种配置的 tokens 总数保持不变。</p><p>Token 吞吐量（tokens/秒）：</p><table>\n<thead>\n<tr>\n<th>批大小</th>\n<th>段落长度（tokens）</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>自托管（无批处理）</th>\n<th>自托管（动态批处理）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>46K</td>\n<td>28.5K</td>\n<td>14.3K</td>\n<td>16.1K</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>42.3K</td>\n<td>27.6K</td>\n<td>9.7K</td>\n<td>10.4K</td>\n</tr>\n</tbody>\n</table>\n<p>在高负载条件下，Jina API 的性能显著优于其他方案，而这里测试的自托管解决方案显示出明显较低的性能。</p><h2 id=\"costs-per-million-tokens\">每百万 Tokens 成本</h2><p>成本可能是选择嵌入解决方案时最关键的因素。虽然计算 AI 模型成本可能很复杂，以下是不同选项的比较分析：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>服务类型</th>\n<th>每百万 Tokens 成本</th>\n<th>基础设施成本</th>\n<th>许可成本</th>\n<th>总小时成本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina API</td>\n<td>$0.018-0.02</td>\n<td>N/A</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>SageMaker（美东）</td>\n<td>$0.0723</td>\n<td>$1.408/小时</td>\n<td>$2.50/小时</td>\n<td>$3.908/小时</td>\n</tr>\n<tr>\n<td>SageMaker（欧盟）</td>\n<td>$0.0788</td>\n<td>$1.761/小时</td>\n<td>$2.50/小时</td>\n<td>$4.261/小时</td>\n</tr>\n<tr>\n<td>自托管（美东）</td>\n<td>$0.352</td>\n<td>$1.006/小时</td>\n<td>$2.282/小时</td>\n<td>$3.288/小时</td>\n</tr>\n<tr>\n<td>自托管（欧盟）</td>\n<td>$0.379</td>\n<td>$1.258/小时</td>\n<td>$2.282/小时</td>\n<td>$3.540/小时</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"jina-api-1\">Jina API</h3><p>该服务采用基于 token 的预付费定价模型，有两个层级：</p><ul><li>10 亿 tokens 收费 $20（每百万 $0.02）- 适合原型开发和开发阶段的入门级价格</li><li>110 亿 tokens 收费 $200（每百万 $0.018）- 更适合大量使用的经济价格</li></ul><p>值得注意的是，这些 tokens 可以在 Jina 的整个产品套件中使用，包括 readers、rerankers 和零样本分类器。</p><h3 id=\"aws-sagemaker-1\">AWS SageMaker</h3><p>SageMaker 定价包含每小时实例成本和模型许可费用。使用 <code>ml.g5.xlarge</code> 实例：</p><ul><li>实例成本：$1.408/小时（美东）或 $1.761/小时（欧洲法兰克福）</li><li><code>jina-embeddings-v3</code> 许可：$2.50/小时</li><li>总小时成本：$3.908-$4.261 取决于地区</li></ul><p>按平均吞吐量 15,044 个 tokens/秒（54.16M tokens/小时）计算，每百万 tokens 的成本在 $0.0723 到 $0.0788 之间。</p><h3 id=\"self-hosting-with-kubernetes\">使用 Kubernetes 自托管</h3><p>自托管成本因基础设施选择而异。以 AWS EC2 的 <code>g5.xlarge</code> 实例为例：</p><ul><li>实例成本：$1.006/小时（美东）或 $1.258/小时（欧洲法兰克福）</li><li><code>jina-embeddings-v3</code> 许可：$5000/季度（$2.282/小时）</li><li>总小时成本：$3.288-$3.540 取决于地区</li></ul><p>以 2,588 个 tokens/秒（9.32M tokens/小时）的速度，每百万 tokens 的成本为 $0.352-$0.379。尽管每小时费率低于 SageMaker，但由于吞吐量较低导致每个 token 的成本更高。</p><p>自托管的重要考虑因素：</p><ul><li>固定成本（许可、基础设施）与使用量无关</li><li>本地托管仍需要支付许可费和人员成本</li><li>工作负载变化可能显著影响成本效率</li></ul><h3 id=\"key-takeaways\">关键要点</h3><p>即使不考虑冷启动时间并假设替代方案达到最佳吞吐量，Jina API 仍然是最具成本效益的解决方案。</p><p>对于已有强大基础设施、边际服务器成本较低的组织来说，自托管可能是合理的选择。此外，探索 AWS 以外的云服务提供商可能会获得更好的定价。</p><p>但是，对于大多数企业，尤其是寻求一站式解决方案的中小企业来说，Jina API 提供了无与伦比的成本效益。</p><h2 id=\"security-and-data-privacy-considerations\">安全和数据隐私考虑</h2><p>在选择嵌入模型的部署策略时，除了性能和成本考虑外，安全和数据隐私要求可能起到决定性作用。我们提供灵活的部署选项以满足不同的安全需求：</p><h3 id=\"cloud-service-providers\">云服务提供商</h3><p>对于<strong>已经在使用主流云服务提供商的企业</strong>，我们在云市场的产品（如 <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS Marketplace</a>、<a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Azure</a> 和 <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">GCP</a>）在现有安全框架内提供了自然的部署解决方案。这些部署的优势包括：</p><ul><li>继承云服务提供商的安全控制和合规性</li><li>可轻松集成现有安全策略和数据治理规则</li><li>几乎无需更改现有数据处理协议</li><li>符合既定的数据主权考虑</li></ul><h3 id=\"self-hosting-and-local-deployment\">自托管和本地部署</h3><p><strong>具有严格安全要求或特定监管义务的组织</strong>通常更倾向于对其基础设施进行完全的物理控制。我们的自托管选项可以实现：</p><ul><li>对部署环境的完全控制</li><li>数据处理完全在您的安全边界内</li><li>与现有安全监控和控制的集成</li></ul><p>要获取我们 CC-BY-NC 模型的商业许可，您首先需要从我们这里获取许可。<a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">请随时联系我们的销售团队。</a></p><h3 id=\"jina-api-service\">Jina API 服务</h3><p>对于试图在安全性、便利性和成本之间取得平衡的<strong>初创企业和中小企业</strong>，我们的 API 服务提供企业级安全保护，无需增加运营开销：</p><ul><li><a href=\"https://jina.ai/Jina_AI_GmbH_Letter_of_Attestation_SOC_2_Type_1.pdf\" rel=\"noreferrer\">SOC2 认证</a>确保强大的安全控制</li><li>完全符合 <a href=\"https://gdpr-info.eu/\" rel=\"noreferrer\">GDPR</a> 的数据处理</li><li>零数据保留政策 - 我们不存储或记录您的请求</li><li>加密数据传输和安全基础设施</li></ul><p>Jina AI 的模型产品使组织能够选择最符合其安全要求的部署策略，同时保持运营效率。</p><h2 id=\"choosing-your-solution\">选择您的解决方案</h2><p>下面的流程图总结了您已经看到的所有实证测试和表格的结果：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1256\" height=\"1980\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png 1256w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">有了这些信息，上面的流程图应该能为您提供应考虑哪些类型解决方案的良好指示。</span></figcaption></figure><p>首先，考虑您的安全需求以及为满足这些需求可以做出多少灵活性的牺牲。</p><p>然后，考虑您计划如何在企业中使用 AI：</p><ol><li>离线索引和可以优化使用批处理的非时间敏感用例。</li><li>需要可靠性和可扩展性的用途，如检索增强生成和 LLM 集成。</li><li>时间敏感的用途，如在线搜索和检索。</li></ol><p>同时，也要考虑您的内部专业知识和现有基础设施：</p><ol><li>您的技术栈是否已经高度依赖云服务？</li><li>您是否拥有能够进行自托管的大规模内部 IT 运营？</li></ol><p>最后，考虑您预期的数据量。您是否是每天需要使用 AI 模型执行数百万次操作的大规模用户？</p><h2 id=\"conclusion\">结论</h2><p>对于许多 IT 部门来说，将 AI 整合到运营决策中仍是一个未知领域，因为市场缺乏成熟的一站式解决方案。这种不确定性可能使战略规划变得具有挑战性。我们的定量分析旨在为将我们的搜索基础模型整合到您特定的工作流程和应用中提供具体指导。</p><p>就单位成本而言，Jina API 是企业可用的最经济选择之一。很少有替代方案能够在提供相comparable功能的同时匹配我们的价位。</p><p>我们致力于提供不仅功能强大、用户友好，而且对各种规模的组织都具有成本效益的搜索功能。无论是通过主要云提供商还是自托管部署，我们的解决方案都能满足超出纯成本考虑的最复杂企业需求。这个分析分解了各种成本因素，以帮助您做出决策。</p><p>鉴于每个组织都有其独特的需求，我们认识到单篇文章无法涵盖每种情况。如果您有本文未涉及的具体需求，请联系我们，讨论如何最好地支持您的实施。</p>",
  "comment_id": "679b56ba42b46600019a86e3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-01-30T11:38:50.000+01:00",
  "updated_at": "2025-01-31T05:32:29.000+01:00",
  "published_at": "2025-01-31T05:32:29.000+01:00",
  "custom_excerpt": "We offer detailed cost and performance breakdowns for three deployment strategies: Jina API, self-hosted K8s, and AWS SageMaker, to help you make the right decision.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "641c23a2f4d50d003d590474",
    "name": "Saahil Ognawala",
    "slug": "saahil",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
    "cover_image": null,
    "bio": "Senior Product Manager at Jina AI",
    "website": "http://www.saahilognawala.com/",
    "location": "Munich, DE",
    "facebook": null,
    "twitter": "@saahil",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-deploying-search-foundation-models-in-production/",
  "excerpt": "我们针对三种部署策略提供详细的成本和性能分析：Jina API、自托管 K8s 和 AWS SageMaker，以帮助您做出正确的选择。",
  "reading_time": 14,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}