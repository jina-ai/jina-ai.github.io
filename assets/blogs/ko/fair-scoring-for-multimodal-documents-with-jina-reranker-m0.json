{
  "slug": "fair-scoring-for-multimodal-documents-with-jina-reranker-m0",
  "id": "682b34d62caa92000178b523",
  "uuid": "434b7cc3-713d-4f2e-843a-6270f0e27604",
  "title": "jina-reranker-m0으로 멀티모달 문서에 대한 공정한 점수 매기기",
  "html": "<p>여러분이 스포츠 뉴스 검색 시스템을 구축하고 있다고 상상해 보세요. 사용자가 \"테니스 선수권 대회 우승을 축하하는 테니스 선수들\"을 검색하고 데이터베이스에서 가장 관련성이 높은 기사를 찾아야 합니다. 각 기사에는 텍스트 캡션과 이미지가 모두 포함되어 있습니다. 이는 현대 스포츠 보도의 일반적인 특징입니다.</p><p>여러분의 시스템은 <strong>텍스트 쿼리</strong>를 받아 코퍼스에서 가장 관련성이 높은 멀티모달 문서의 <strong>순위가 매겨진 목록</strong>을 반환해야 합니다. 간단하게 들리지만, 모든 명백한 접근 방식을 무너뜨리는 근본적인 문제가 있습니다.</p><p>이러한 문서의 순위를 매기려고 할 때 발생하는 상황은 다음과 같습니다. 여러분의 向量模型 (Embedding) 모델인 <code>jina-clip-v2</code>는 다음과 같은 유사도 점수를 생성합니다.</p>\n<!--kg-card-begin: html-->\n<table>\n    <thead>\n        <tr>\n            <th>기사</th>\n            <th>콘텐츠 유형</th>\n            <th>설명</th>\n            <th>유사도 점수</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>A</td>\n            <td>텍스트</td>\n            <td>노박 조코비치가 호주 오픈 결승에서 스트레이트 세트로 승리</td>\n            <td>0.72</td>\n        </tr>\n        <tr>\n            <td>A</td>\n            <td>이미지</td>\n            <td>[트로피를 들고 웃고 있는 선수의 사진]</td>\n            <td>0.31</td>\n        </tr>\n        <tr>\n            <td>B</td>\n            <td>텍스트</td>\n            <td>날씨 지연으로 인해 야외 토너먼트 일정에 차질</td>\n            <td>0.23</td>\n        </tr>\n        <tr>\n            <td>B</td>\n            <td>이미지</td>\n            <td>[점프하고 축하하는 테니스 선수들의 사진]</td>\n            <td>0.54</td>\n        </tr>\n    </tbody>\n</table>\n<!--kg-card-end: html-->\n<p>어떤 기사가 더 관련성이 높을까요? 기사 A는 텍스트 점수는 높지만 이미지 점수는 낮습니다. 기사 B는 텍스트 점수는 낮지만 이미지 점수는 더 높습니다. 근본적인 문제는 <strong>0.72(텍스트)와 0.54(이미지)를 비교할 수 없다</strong>는 것입니다. 왜냐하면 이러한 유사도 점수는 완전히 다른 척도에 존재하기 때문입니다.</p><h2 id=\"when-trivial-solutions-fail\">사소한 해결 방법이 실패하는 경우</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">CLIP 모델에서 텍스트-이미지 양식 격차의 원인과 이유</div><div class=\"kg-bookmark-description\">CLIP 모델을 사용하여 텍스트와 이미지를 검색하고 점수별로 결과를 정렬할 수는 없습니다. 왜일까요? 양식 격차 때문입니다. 이것은 무엇이며, 어디에서 오는 것일까요?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-32.png\" alt=\"\"><span class=\"kg-bookmark-author\">Jina AI</span><span class=\"kg-bookmark-publisher\">Bo Wang, Scott Martens</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/the-what-and-why-of-text-image-modality-gap-in-clip-models.webp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>jina-clip-v2</code> 또는 거의 모든 다른 CLIP 유사 모델의 <strong>양식 격차 때문에</strong> 시도할 수 있는 명백한 접근 방식은 작동하지 않습니다. 더 높은 점수를 사용하면 텍스트 점수는 0.2-0.8 주위에, 이미지 점수는 0.4-0.6 주위에 모인다는 사실에 직면하게 됩니다. 즉, 평범한 텍스트 일치(0.6)는 항상 뛰어난 이미지 일치(0.5)를 이깁니다.</p><p>점수를 평균화하는 것도 도움이 되지 않습니다. (0.7 + 0.3)/2 = 0.5를 계산하면 숫자가 나오지만 실제로 무엇을 의미할까요? 근본적으로 의미 없는 양을 평균화하는 것입니다. 마찬가지로, 고정 가중치 체계는 임의적입니다. 때로는 텍스트가 더 중요하고 때로는 이미지가 더 중요하며, 이는 특정 쿼리 및 문서에 따라 완전히 달라집니다.</p><p>점수를 먼저 정규화하더라도 핵심 문제는 해결되지 않습니다. 여전히 관련성의 다른 측면을 캡처하는 근본적으로 다른 유사성 측정값을 결합하려고 시도하는 것입니다.</p><h2 id=\"what-actually-happens\">실제로 일어나는 일</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2305.13631\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">EDIS: 멀티모달 웹 콘텐츠에 대한 엔티티 기반 이미지 검색</div><div class=\"kg-bookmark-description\">실제 검색 애플리케이션에 이미지 검색 방법을 적용하려면 데이터 세트 규모, 엔티티 이해 및 멀티모달 정보 융합에서 상당한 진전이 필요합니다. 이 연구에서는 뉴스 도메인에서 교차 모달 이미지 검색을 위한 도전적인 데이터 세트인 \\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch(EDIS)를 소개합니다. EDIS는 실제 검색 엔진 결과 및 선별된 데이터 세트에서 가져온 100만 개의 웹 이미지로 구성되며, 각 이미지는 텍스트 설명과 쌍을 이룹니다. 단일 모달 후보의 작은 세트를 가정하는 데이터 세트와 달리 EDIS는 100만 개의 멀티모달 이미지-텍스트 쌍을 후보로 포함하여 실제 웹 이미지 검색 시나리오를 반영합니다. EDIS는 교차 모달 정보 융합 및 매칭을 동시에 처리하는 검색 모델의 개발을 장려합니다. 정확한 순위 결과를 얻으려면 모델은 1) 텍스트 쿼리에서 명명된 엔티티 및 이벤트를 이해하고, 2) 엔티티를 이미지 또는 텍스트 설명에 연결하고, 3) 텍스트 및 시각적 표현을 효과적으로 융합해야 합니다. 우리의 실험 결과는 EDIS가 밀집된 엔티티와 대규모 후보 세트로 최첨단 방법을 어렵게 만든다는 것을 보여줍니다. 제거 연구는 또한 검색 결과를 개선하는 데 텍스트 특징과 시각적 특징을 융합하는 것이 중요하다는 것을 증명합니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-20.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Siqi Liu</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-16.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>우리가 무엇을 다루고 있는지 더 잘 이해하기 위해 <a href=\"https://arxiv.org/abs/2305.13631\">EDIS 데이터 세트</a>의 예제 문서를 보여드리겠습니다. 여기에는 이미지(독일 축구 경기)와 캡션(<code>One More Field Where the Content Trails Germany</code>)이 있습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"928\" height=\"261\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-1.png 928w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 1: 이미지 및 텍스트 콘텐츠를 모두 포함하는 멀티모달 문서의 예입니다. 두 가지 양식이 있으므로 주어진 쿼리에 대해 이제 </span><i><em class=\"italic\" style=\"white-space: pre-wrap;\">두 개</em></i><span style=\"white-space: pre-wrap;\">의 의미론적 격차가 있습니다(쿼리와 텍스트 사이, 쿼리와 이미지 사이). 최상의 결과를 얻으려면 문서의 텍스트 콘텐츠를 검색해야 할까요, 아니면 이미지 콘텐츠를 검색해야 할까요?</span></figcaption></figure><p>전반적으로 <code>jina-clip-v2</code>는 모델이 훈련된 방식과 데이터 세트 자체 때문에 EDIS 데이터 세트에서 쿼리-텍스트를 비교할 때 쿼리-이미지보다 훨씬 더 높은 유사성을 보입니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"964\" height=\"679\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-2.png 964w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 2: </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">를 사용하여 쿼리-이미지(빨간색)와 쿼리-텍스트(파란색) 간의 유사도 점수입니다.</span></figcaption></figure><p>따라서 텍스트가 아닌 이미지를 기반으로 문서를 검색하는 것이 논리적으로 보입니다. 그리고 아래 그림에서 볼 수 있듯이 <code>... for undocumented immigrants helping to establish legal status in the United States</code> 텍스트 쿼리를 코퍼스의 텍스트 내용과 비교하면 훨씬 더 나은 결과를 얻을 수 있습니다. 실제로 이미지로 검색하면 정답 문서(노란색으로 강조 표시됨)를 전혀 검색하지 못합니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1767\" height=\"2454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-3.png 1767w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 3: </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\">가 3일 때 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">의 쿼리-텍스트 검색을 통해서만 정답 문서(노란색 테두리로 강조 표시됨)를 검색할 수 있는 예입니다.</span></figcaption></figure><p>하지만 속지 마세요. 쿼리-텍스트가 더 높은 유사도 점수를 보여주더라도 쿼리-텍스트 및 쿼리-이미지 유사도 점수는 <em>비교할 수 없습니다</em>. <code>jina-clip-v2</code>를 사용하여 EDIS 데이터 세트에서 32개의 문서를 검색할 때 recall@10을 살펴보면 이를 알 수 있습니다. 분명히 리콜은 쿼리-<em>이미지</em>에서 더 높습니다.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Recall@10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>쿼리-텍스트</td>\n<td>14.55</td>\n</tr>\n<tr>\n<td>쿼리-이미지</td>\n<td><strong>22.38</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>아래에서 볼 수 있듯이 데이터 세트에서 쿼리 <code>Ear ear An elephant is decorated with Bhartiya Janta Party symbols near the BJP headquarters in New Delhi.</code>를 사용하는 경우 이미지 콘텐츠를 통해서만 정답 문서를 검색할 수 있습니다. 텍스트 콘텐츠로 검색하면 일치하는 항목이 반환되지 않습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1753\" height=\"2454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-4.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-4.png 1753w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 4: </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\">가 3일 때 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">의 쿼리-이미지 검색을 통해서만 정답 문서(노란색 테두리로 강조 표시됨)를 검색할 수 있는 예입니다.</span></figcaption></figure><p>따라서 유사도 점수가 텍스트에서 문서를 검색해야 함을 암시하고, 재현율이 이미지에서 문서를 검색해야 함을 암시한다면, 무엇을 선택해야 할까요? 분명히 그림 3과 4는 명확한 승자가 없음을 보여줍니다. 어떤 양식 (modality) 이 <em>정말로</em> 쿼리와 우리가 찾고 있는 문서 사이의 가장 가까운 일치 항목을 나타낼까요? 그리고 쿼리-텍스트 및 쿼리-이미지 검색 <em>모두</em>에서 후보를 병합하고 싶다면 점수를 비교할 수조차 없다면 어떻게 의미 있게 상위 일치 항목을 선택할 수 있을까요? 분명히 <code>jina-clip-v2</code>만으로는 충분하지 않습니다. 다른 모델을 믹스에 투입해야 합니다.</p><h2 id=\"a-simple-two-stage-pipeline\">간단한 2단계 파이프라인</h2><p>2025년 4월에 시각적 문서를 검색하기 위한 다국어 멀티모달 재정렬기 (Reranker)인 <code>jina-reranker-m0</code>를 출시했습니다. 아래에서 <code>jina-reranker-m0</code>가 쿼리-텍스트 및 쿼리-이미지 유사도 점수를 비슷하게 보여주는 더 좁은 양식 간 격차를 볼 수 있습니다. 이는 <code>jina-clip-v2</code>에서 보이는 훨씬 더 넓은 격차와 대조됩니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"964\" height=\"679\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png 964w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 6: </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">와 비교하여 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\">는 쿼리-이미지 (빨간색) 및 쿼리-텍스트 (파란색) 유사도 점수 간의 차이가 훨씬 적습니다.</span></figcaption></figure><p>이 점을 염두에 두고 <code>jina-clip-v2</code>에서 초기 결과를 검색한 후 검색 체인에서 두 번째 패스에 <code>jina-reranker-m0</code>를 사용할 수 있습니다.</p><p><strong>1단계: 양식 (Modality) 모두에서 후보 검색</strong></p><ul><li><code>jina-clip-v2</code>를 사용하여 텍스트 검색을 통해 16개의 문서 + 이미지 검색을 통해 16개의 문서 가져오기</li><li>아직 점수를 비교할 수 없음을 인정</li></ul><p><strong>2단계: 통합 재정렬</strong></p><ul><li>각 (쿼리 + 전체 문서) 쌍을 <code>jina-reranker-m0</code>에 공급</li><li>재정렬기는 텍스트와 이미지를 함께 처리</li><li>출력: 통합된 스케일의 단일 관련성 점수</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-5.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1305\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-5.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-5.png 2048w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 5: </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> 및 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\">를 사용한 멀티모달 문서 인덱싱 및 2단계 멀티모달 검색 프로세스.</span></figcaption></figure><p>테이블 1의 실험을 확장하여 이제 <code>jina-clip-v2</code>를 사용하여 코퍼스에서 문서를 검색한 다음 <code>jina-reranker-m0</code>를 사용하여 재정렬합니다.</p><ol><li>쿼리-텍스트를 통해 32개의 문서를 검색한 다음 쿼리-텍스트 점수를 기준으로 재정렬합니다.</li><li>쿼리-이미지를 통해 32개의 문서를 검색한 다음 쿼리-이미지 점수를 기준으로 재정렬합니다.</li><li>쿼리-텍스트를 통해 16개의 문서를 검색하고 쿼리-이미지를 통해 16개의 문서를 검색합니다. 쿼리 양식 (modality)에 따라 쿼리-텍스트 또는 쿼리-이미지 점수를 기준으로 재정렬합니다.</li><li>쿼리-텍스트를 통해 16개의 문서를 검색하고 쿼리-이미지를 통해 16개의 문서를 검색합니다. 각 문서의 평균 쿼리-텍스트 및 쿼리-이미지 점수를 기준으로 재정렬하여 최종 점수는 (쿼리-텍스트 + 쿼리-이미지)/2가 됩니다.</li></ol><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">EDIS에서 제로샷 성능을 측정하고 있습니다. 데이터 세트를 사용하여 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-clip-v2</code> 또는 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-reranker-m0</code>를 미세 조정하지 않았습니다.</div></div>\n<!--kg-card-begin: html-->\n\n<table>\n  <thead>\n    <tr>\n      <th>실험</th>\n      <th>설명</th>\n      <th>jina-clip-v2 사용 시 Recall@10</th>\n      <th>jina-reranker-m0 사용 시 Recall@10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>32개 문서: 쿼리-텍스트</td>\n      <td>14.55</td>\n      <td>17.42</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>32개 문서: 쿼리-이미지</td>\n      <td>22.38</td>\n      <td>28.94</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>16개 문서: 쿼리-텍스트<br>16개 문서: 쿼리-이미지</td>\n      <td>14.55</td>\n      <td>33.81</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>16개 문서: 쿼리-텍스트<br>16개 문서: 쿼리-이미지<br>결합된 평균 재정렬기 (Reranker) 점수</td>\n      <td>14.55</td>\n      <td><strong>36.24</strong></td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">실험 1, 3 및 4는 쿼리-텍스트 점수가 쿼리-이미지 점수보다 높기 때문에 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-clip-v2</code>에서 recall@10에 대해 동일한 결과를 보여줍니다. 따라서 상위 10개 결과는 텍스트를 통해 검색된 문서가 지배합니다.</div></div><p>보시다시피 <code>jina-reranker-m0</code>를 사용하여 두 번째 패스를 수행하면 양식 (modality)에 관계없이 전체적으로 재현율이 증가합니다. 그러나 <strong>검색된 문서의 텍스트 및 이미지 콘텐츠를 모두 결합할 때 가장 큰 증가를 볼 수 있으며</strong>, recall@10은 36.24에 도달합니다. 시각적 예는 <code>jina-reranker-m0</code>가 텍스트 또는 이미지 콘텐츠를 검색하든 일관되게 실제 근거 (ground truth) 문서를 1위로 평가한다는 것을 보여줍니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/clip-vs-reranker.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1146\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/clip-vs-reranker.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/clip-vs-reranker.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/clip-vs-reranker.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/clip-vs-reranker.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">그림 7: 샘플 쿼리 (왼쪽) 및 각 재정렬 방법론에 대한 1개의 결과의 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\"> (오른쪽의 4개 열)은 이미지 및 텍스트 유사도 점수를 결합하면 일관되게 실제 근거 (ground truth) 문서를 1위로 평가합니다.</span></figcaption></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">그림 3과 4는 다양한 검색 방법에 대한 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">top_k</code>가 3인 반면, 공간상의 이유로 그림 7은 각 쿼리에 대해 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">top_k</code>가 1인 경우만 보여줍니다.</div></div><h2 id=\"conclusions\">결론</h2><p>이 간단한 2단계 접근 방식은 시스템이 마침내 인간이 자연스럽게 하는 것, 즉 관련성을 결정하기 위해 읽는 것과 보는 것을 모두 고려하기 때문에 재현율이 62% 향상됩니다. 교훈은 검색을 넘어 확장됩니다. 멀티모달 AI 시스템을 처리할 때 양식 (modality)을 개별적으로 처리하는 단일 패스 접근 방식은 항상 이 점수 비호환성 문제에 부딪힐 것입니다. 광범위하게 검색한 다음 지능적으로 순위를 매기는 2단계 아키텍처가 필수가 되고 있습니다. API 또는 AWS, GCP 및 Azure를 통해 <code>jina-reranker-m0</code>를 사용해 보십시오.</p>",
  "comment_id": "682b34d62caa92000178b523",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/fair-scoring.webp",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-19T15:40:38.000+02:00",
  "updated_at": "2025-05-25T08:26:31.000+02:00",
  "published_at": "2025-05-25T08:25:10.000+02:00",
  "custom_excerpt": "Text similarity: 0.7. Image similarity: 0.5. Which document is more relevant? You literally cannot tell—and that's the core problem breaking multimodal search. We solve it with unified reranking.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "678e14a78f6bb40001a63595",
      "name": "Nan Wang",
      "slug": "nan",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg",
      "cover_image": null,
      "bio": "Co-founder & CTO @JinaAI | Ex-Zalando & Tencent | Build AI models & systems | Open-source enthusiast | Speaker & contributor (40+ talks) | PhD in Computational Neuroscience @ Ruhr University Bochum",
      "website": null,
      "location": "Global",
      "facebook": null,
      "twitter": "@nanwang_t",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
    },
    {
      "id": "632ade4a3e4e55003d525971",
      "name": "Alex C-G",
      "slug": "alexcg",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
      "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
      "website": null,
      "location": "Berlin, Germany",
      "facebook": null,
      "twitter": "@alexcg",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "678e14a78f6bb40001a63595",
    "name": "Nan Wang",
    "slug": "nan",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg",
    "cover_image": null,
    "bio": "Co-founder & CTO @JinaAI | Ex-Zalando & Tencent | Build AI models & systems | Open-source enthusiast | Speaker & contributor (40+ talks) | PhD in Computational Neuroscience @ Ruhr University Bochum",
    "website": null,
    "location": "Global",
    "facebook": null,
    "twitter": "@nanwang_t",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fair-scoring-for-multimodal-documents-with-jina-reranker-m0/",
  "excerpt": "텍스트 유사성: 0.7. 이미지 유사성: 0.5. 어떤 문서가 더 관련성이 높을까요? 말 그대로 알 수 없습니다. 이것이 바로 멀티모달 검색을 망치는 핵심 문제입니다. 당사는 통합 재정렬 (Reranking)로 이 문제를 해결합니다.",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}