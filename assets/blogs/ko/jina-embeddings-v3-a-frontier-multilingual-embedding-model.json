{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3: 첨단 다국어 임베딩 모델",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">우리는 오픈 소스와 오픈 사이언스를 통해 인공지능을 발전시키고 민주화하는 여정을 걷고 있습니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3: Task LoRA를 활용한 다국어 임베딩</div><div class=\"kg-bookmark-description\">우리는 5억 7천만 개의 매개변수를 가진 새로운 텍스트 임베딩 모델인 jina-embeddings-v3를 소개합니다. 이 모델은 다국어 데이터와 긴 문맥 검색 작업에서 최고 수준의 성능을 달성하며, 최대 8192 토큰의 문맥 길이를 지원합니다. 이 모델은 쿼리-문서 검색, 클러스터링, 분류, 텍스트 매칭을 위한 고품질 임베딩을 생성하기 위한 작업별 Low-Rank Adaptation (LoRA) 어댑터 세트를 포함합니다. 또한 Matryoshka Representation Learning이 훈련 과정에 통합되어 성능 저하 없이 임베딩 차원의 유연한 절단이 가능합니다. MTEB 벤치마크 평가에서 jina-embeddings-v3는 영어 작업에서 OpenAI와 Cohere의 최신 독점 임베딩을 능가하며, 모든 다국어 작업에서 multilingual-e5-large-instruct보다 우수한 성능을 달성했습니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>오늘 우리는 5억 7천만 개의 매개변수를 가진 획기적인 텍스트 임베딩 모델인 <code>jina-embeddings-v3</code>를 발표하게 되어 기쁩니다. 이 모델은 **다국어** 데이터와 **긴 문맥** 검색 작업에서 최고 수준의 성능을 달성하며, 최대 8192 토큰의 입력 길이를 지원합니다. 이 모델은 작업별 Low-Rank Adaptation (LoRA) 어댑터를 특징으로 하여 **쿼리-문서 검색**, **클러스터링**, **분류**, **텍스트 매칭**과 같은 다양한 작업을 위한 고품질 임베딩을 생성할 수 있습니다.</p><p>MTEB 영어, 다국어 및 LongEmbed 평가에서 <code>jina-embeddings-v3</code>는 영어 작업에서 OpenAI와 Cohere의 최신 독점 임베딩을 능가하며, 모든 다국어 작업에서 <code>multilingual-e5-large-instruct</code>를 뛰어넘었습니다. 기본 출력 차원이 1024인 이 모델은 Matryoshka Representation Learning (MRL) 통합 덕분에 성능 저하 없이 임베딩 차원을 32까지 임의로 줄일 수 있습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code>와 다른 임베딩 모델들의 모든 MTEB 영어 작업에 대한 성능 비교. 작업별 전체 평가 결과는</span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">우리의 arXiv 논문</span></a><span style=\"white-space: pre-wrap;\">에서 확인할 수 있습니다.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code>의 성능은 광범위한 다국어 및 교차 언어 MTEB 작업에서 평가되었습니다. <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2-(zh/es/de)</code>는 우리의 이중언어 모델 스위트를 지칭하며, 중국어, 스페인어, 독일어의 단일 언어 및 교차 언어 작업에서만 테스트되었고 다른 모든 언어는 제외되었음을 참고해 주시기 바랍니다. 또한, <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">openai-text-embedding-3-large</code>와 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">cohere-embed-multilingual-v3.0</code>의 점수는 전체 다국어 및 교차 언어 MTEB 작업에서 평가되지 않았기 때문에 보고하지 않습니다.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">LongEmbed 벤치마크의 6가지 긴 문서 검색 작업에서 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code>의 성능은 다른 모델들에 비해 상당한 개선을 보여줍니다. 점수는 nDCG@10이며, 높을수록 좋습니다. 이는 우리의 RoPE 기반 위치 임베딩의 효과를 보여주며, <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">baai-bge-m3</code>에서 사용된 고정 위치 임베딩과 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2</code>에서 사용된 ALiBi 기반 접근 방식을 모두 능가합니다.</span></figcaption></figure><p>2024년 9월 18일 출시 기준으로, <code>jina-embeddings-v3</code>는 **최고의** 다국어 모델이며 10억 개 미만의 매개변수를 가진 모델 중 MTEB 영어 리더보드에서 **2위**를 차지했습니다. v3는 총 89개 언어를 지원하며, 그 중 30개 언어에서 최고의 성능을 보입니다: 아랍어, 벵골어, 중국어, 덴마크어, 네덜란드어, 영어, 핀란드어, 프랑스어, 조지아어, 독일어, 그리스어, 힌디어, 인도네시아어, 이탈리아어, 일본어, 한국어, 라트비아어, 노르웨이어, 폴란드어, 포르투갈어, 루마니아어, 러시아어, 슬로바키아어, 스페인어, 스웨덴어, 태국어, 터키어, 우크라이나어, 우르두어, 베트남어.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">2024년 9월 18일 출시 기준으로, 5억 7천만 개의 매개변수와 1024 출력 차원을 가진 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code>는 10억 개 미만의 매개변수를 가진 모델 중 가장 효율적이고 강력하며 신뢰할 수 있는 다국어 임베딩 모델입니다.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">임베딩 모델의 스케일링 법칙. 영어 작업에 대한 평균 MTEB 성능이 모델 매개변수 수에 대해 플롯되었습니다. 각 점은 임베딩 모델을 나타냅니다. 모든 모델을 대표하는 추세선이 강조되어 있으며, 다국어 모델은 청록색으로 강조되어 있습니다. <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code>가 비슷한 크기의 모델들과 비교하여 우수한 성능을 보여주며, 이전 모델인 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2</code>에 비해 초선형적 개선을 보여주는 것을 확인할 수 있습니다. 이 그래프는 MTEB 리더보드에서 상위 100개 임베딩 모델을 선택하여 작성되었으며, 크기 정보가 없는 모델(일반적으로 폐쇄 소스 또는 독점 모델)은 제외되었습니다. 명백한 트롤링으로 확인된 제출물도 필터링되었습니다.</span></figcaption></figure><p>또한, <code>e5-mistral-7b-instruct</code>와 같이 최근 주목받고 있는 LLM 기반 임베딩과 비교했을 때, <code>jina-embeddings-v3</code>는 훨씬 더 비용 효율적인 솔루션입니다. e5-mistral-7b-instruct는 71억 개의 매개변수(12배 더 큼)와 4096의 출력 차원(4배 더 큼)을 가지고 있지만 MTEB 영어 작업에서 단 1%의 개선만을 제공하여, 프로덕션과 엣지 컴퓨팅에 더 적합합니다.</p><h2 id=\"model-architecture\">모델 아키텍처</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>특징</th>\n<th>설명</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>기반</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>기본 매개변수</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>LoRA 포함 매개변수</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>최대 입력 토큰</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>최대 출력 차원</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>레이어</td>\n<td>24</td>\n</tr>\n<tr>\n<td>어휘</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>지원 언어</td>\n<td>89</td>\n</tr>\n<tr>\n<td>어텐션</td>\n<td>FlashAttention2, 없이도 작동</td>\n</tr>\n<tr>\n<td>풀링</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>jina-embeddings-v3</code>의 아키텍처는 아래 그림과 같습니다. 백본 아키텍처를 구현하기 위해 우리는 <code>XLM-RoBERTa</code> 모델을 다음과 같은 주요 수정사항과 함께 채택했습니다: (1) 긴 텍스트 시퀀스의 효과적인 인코딩 가능, (2) 태스크별 임베딩 인코딩 허용, (3) 최신 기술로 전반적인 모델 효율성 개선. 우리는 기존 <code>XLM-RoBERTa</code> 토크나이저를 계속 사용합니다. <code>jina-embeddings-v3</code>는 5억 7천만 개의 매개변수로 1억 3천 7백만 개의 매개변수를 가진 <code>jina-embeddings-v2</code>보다 크지만, 여전히 LLM에서 미세 조정된 임베딩 모델들보다는 훨씬 작습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-embeddings-v3</code>의 아키텍처는 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\"> 모델을 기반으로 하며, 4가지 다른 태스크를 위한 5개의 LoRA 어댑터를 포함합니다.</span></figcaption></figure><p><code>jina-embeddings-v3</code>의 핵심 혁신은 LoRA 어댑터의 사용입니다. <strong>4가지</strong> 태스크를 최적화하기 위해 <strong>5개</strong>의 태스크별 LoRA 어댑터가 도입되었습니다. 모델의 입력은 텍스트(임베딩될 긴 문서)와 태스크 두 부분으로 구성됩니다. <code>jina-embeddings-v3</code>는 4가지 태스크를 지원하며 5개의 어댑터를 구현합니다: 비대칭 검색 태스크에서의 쿼리와 문서 임베딩을 위한 <code>retrieval.query</code>와 <code>retrieval.passage</code>, 클러스터링 태스크를 위한 <code>separation</code>, 분류 태스크를 위한 <code>classification</code>, STS나 대칭 검색과 같은 의미적 유사도 태스크를 위한 <code>text-matching</code>. LoRA 어댑터는 전체 매개변수의 3% 미만을 차지하여 계산에 매우 미미한 오버헤드만 추가합니다.</p><p>성능을 더욱 향상시키고 메모리 소비를 줄이기 위해, 우리는 FlashAttention 2를 통합하고, 활성화 체크포인팅을 지원하며, 효율적인 분산 학습을 위해 DeepSpeed 프레임워크를 사용합니다.</p><h2 id=\"get-started\">시작하기</h2><h3 id=\"via-jina-ai-search-foundation-api\">Jina AI Search Foundation API를 통해</h3><p><code>jina-embeddings-v3</code>를 사용하는 가장 쉬운 방법은 <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">Jina AI 홈페이지</a>를 방문하여 Search Foundation API 섹션으로 이동하는 것입니다. 오늘부터 이 모델은 모든 새로운 사용자를 위한 기본값으로 설정됩니다. 거기에서 직접 다양한 매개변수와 기능을 탐색할 수 있습니다.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n     -H \"Content-Type: application/json\" \\\n     -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n     -d '{\n    \"model\": \"jina-embeddings-v3\",\n    \"task\": \"text-matching\",\n    \"dimensions\": 1024,\n    \"late_chunking\": true,\n    \"input\": [\n        \"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n        \"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n        \"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n        \"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n        \"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'</code></pre><p>v2와 비교하여 v3는 API에서 <code>task</code>, <code>dimensions</code>, <code>late_chunking</code>이라는 세 가지 새로운 매개변수를 도입했습니다.</p><h4 id=\"parameter-task\">매개변수 <code>task</code></h4><p><code>task</code> 매개변수는 중요하며 다운스트림 태스크에 따라 설정되어야 합니다. 결과적인 임베딩은 해당 특정 태스크에 최적화될 것입니다. 자세한 내용은 아래 목록을 참조하세요.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong><code>task</code> 값</strong></th>\n<th><strong>태스크 설명</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>쿼리-문서 검색 태스크에서 <b>문서</b> 임베딩</td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>쿼리-문서 검색 태스크에서 <b>쿼리</b> 임베딩</td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>문서 클러스터링, 코퍼스 시각화</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>텍스트 분류</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(기본값)</b> 의미적 텍스트 유사도, 일반 대칭 검색, 추천, 유사 항목 찾기, 중복 제거</td>\n</tr>\n</tbody>\n</table>\n\n<!--kg-card-end: html-->\n<p>API는 먼저 일반적인 메타 임베딩을 생성한 다음 추가적인 미세 조정된 MLP로 조정하는 것이 <em>아닙니다</em>. 대신, 태스크별 LoRA 어댑터를 모든 트랜스포머 레이어(총 24개 레이어)에 삽입하고 한 번에 인코딩을 수행합니다. 자세한 내용은 <a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">우리의 arXiv 논문</a>에서 확인할 수 있습니다.</p><h4 id=\"parameter-dimensions\">매개변수 <code>dimensions</code></h4><p><code>dimensions</code> 매개변수를 통해 사용자는 최저 비용으로 공간 효율성과 성능 사이의 균형을 선택할 수 있습니다. <code>jina-embeddings-v3</code>에서 사용된 MRL 기술 덕분에 임베딩의 차원을 원하는 만큼(심지어 단일 차원까지도!) 줄일 수 있습니다. 작은 임베딩은 벡터 데이터베이스에 더 저장 친화적이며, 그 성능 비용은 아래 그림에서 추정할 수 있습니다.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">매개변수 <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">긴 컨텍스트 임베딩 모델에서의 Late Chunking</div><div class=\"kg-bookmark-description\">문맥 정보를 보존하면서 긴 문서를 청킹하는 것은 도전적인 과제입니다. 우리는 긴 컨텍스트 임베딩 모델을 활용하여 더 나은 검색 애플리케이션을 위한 문맥적 청크 임베딩을 생성하는 \"Late Chunking\"을 소개합니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>마지막으로, <code>late_chunking</code> 매개변수는 <a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">지난달 우리가 소개한</a> 새로운 청킹 방법을 문장 배치를 인코딩하는 데 사용할지 여부를 제어합니다. <code>true</code>로 설정하면, 우리의 API는 <code>input</code> 필드의 모든 문장을 연결하여 단일 문자열로 모델에 공급합니다. 다시 말해, <strong>입력의 문장들을 마치 동일한 섹션, 단락 또는 문서에서 원래 나온 것처럼 취급합니다.</strong> 내부적으로, 모델은 이 긴 연결된 문자열을 임베딩하고 나중에 청킹을 수행하여 입력 리스트의 크기와 일치하는 임베딩 리스트를 반환합니다. 따라서 리스트의 각 임베딩은 이전 임베딩들의 조건부가 됩니다.</p><p>사용자 관점에서, <code>late_chunking</code>을 설정하는 것은 입력이나 출력 형식을 <em>변경하지 않습니다</em>. 임베딩 값의 변화만 볼 수 있는데, 이는 이제 독립적으로가 아닌 전체 이전 컨텍스트를 기반으로 계산되기 때문입니다. late_chunking 사용 시 알아야 할 중요한 점은<code>late_chunking=True</code>에서는 <code>input</code>의 모든 토큰을 합한 총 토큰 수가 <code>jina-embeddings-v3</code>에서 허용되는 최대 컨텍스트 길이인 8192로 제한됩니다. <code>late_chunking=False</code>일 때는 이러한 제한이 없으며, 총 토큰 수는 <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">Embedding API의 비율 제한</a>에만 영향을 받습니다.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking On vs Off: 입력과 출력 형식은 동일하며 임베딩 값만 차이가 있습니다. </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\">이 활성화되면 임베딩은 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\">의 전체 이전 컨텍스트의 영향을 받지만, 비활성화되면 임베딩은 독립적으로 계산됩니다.</span></p></figcaption></figure><h3 id=\"via-azure-aws\">Azure 및 AWS를 통해</h3><p><code>jina-embeddings-v3</code>는 이제 AWS SageMaker와 Azure Marketplace에서 사용할 수 있습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>해당 플랫폼 외에서 사용하거나 기업 내 온프레미스에서 사용해야 하는 경우, 이 모델은 CC BY-NC 4.0 라이선스로 제공됩니다. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">상업적 사용 문의는 저희에게 연락 주시기 바랍니다.</a></p><h3 id=\"via-vector-databases-partners\">벡터 데이터베이스 및 파트너사를 통해</h3><p>우리는 Pinecone, Qdrant, Milvus와 같은 벡터 데이터베이스 제공업체들과 LlamaIndex, Haystack, Dify와 같은 LLM 오케스트레이션 프레임워크와 긴밀히 협력하고 있습니다. 출시 시점에 Pinecone, Qdrant, Milvus, Haystack이 이미 <code>jina-embeddings-v3</code>에 대한 지원을 통합했으며, 여기에는 <code>task</code>, <code>dimensions</code>, <code>late_chunking</code>의 세 가지 새로운 매개변수가 포함됩니다. <code>v2</code> API와 이미 통합된 다른 파트너들도 모델 이름을 <code>jina-embeddings-v3</code>로 변경하는 것만으로 <code>v3</code>를 지원할 수 있습니다. 다만, <code>v3</code>에서 새로 도입된 매개변수들은 아직 지원하지 않을 수 있습니다.</p><h4 id=\"via-pinecone\">Pinecone을 통해</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">Qdrant를 통해</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">Milvus를 통해</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">Haystack을 통해</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">결론</h2><p>2023년 10월, 우리는 <code>jina-embeddings-v2-base-en</code>을 출시했으며, 이는 <a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">8K 컨텍스트 길이를 지원하는 세계 최초의 오픈소스 임베딩 모델</a>이었습니다. 이는 긴 컨텍스트를 지원하고 OpenAI의 <code>text-embedding-ada-002</code>와 대등한 성능을 보이는 유일한 텍스트 임베딩 모델이었습니다. 오늘날, 1년간의 학습과 실험, 그리고 소중한 교훈을 바탕으로, 우리는 텍스트 임베딩 모델의 새로운 지평을 여는 <code>jina-embeddings-v3</code>를 자랑스럽게 출시하며, 이는 우리 회사의 중요한 이정표가 되었습니다.</p><p>이번 출시를 통해 우리는 우리가 잘 알려진 분야인 <strong>긴 컨텍스트</strong> <strong>임베딩</strong>에서 계속해서 뛰어난 성과를 보이면서, 동시에 산업계와 커뮤니티로부터 가장 많이 요청받았던 기능인 <strong>다국어 임베딩</strong>도 구현했습니다. 동시에 성능도 새로운 수준으로 끌어올렸습니다. Task-specific LoRA, MRL, late chunking과 같은 새로운 기능들과 함께, 우리는 <code>jina-embeddings-v3</code>가 RAG, 에이전트 등 다양한 애플리케이션을 위한 진정한 기반 임베딩 모델이 될 것이라고 믿습니다. <code>NV-embed-v1/v2</code>와 같은 최근의 LLM 기반 임베딩과 비교했을 때, 우리 모델은 매개변수 효율성이 매우 높아 프로덕션과 엣지 디바이스에 더욱 적합합니다.</p><p>앞으로 우리는 저자원 언어에서의 <code>jina-embeddings-v3</code> 성능을 평가하고 개선하는 것과 제한된 데이터 가용성으로 인한 체계적 실패를 분석하는 데 초점을 맞출 계획입니다. 또한, <code>jina-embeddings-v3</code>의 모델 가중치와 혁신적인 기능들, 그리고 새로운 관점들은 <code>jina-clip-v2</code>를 포함한 향후 모델들의 기반이 될 것입니다.</p><code>jina-reranker-v3</code>, 그리고 <code>reader-lm-v2</code>.</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3는 570M 파라미터와 8192 토큰 길이를 가진 최첨단 다국어 텍스트 임베딩 모델로, MTEB에서 OpenAI와 Cohere의 최신 독점 임베딩보다 뛰어난 성능을 보입니다.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}