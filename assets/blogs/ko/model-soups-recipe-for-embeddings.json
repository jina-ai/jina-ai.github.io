{
  "slug": "model-soups-recipe-for-embeddings",
  "id": "681b63a077c406000104263b",
  "uuid": "e3fc45b3-6cf9-4a0b-863f-bc4a8417c436",
  "title": "임베딩을 위한 Model Soup 레시피",
  "html": "<p>이 어려운 시기에 따뜻한 수프 한 그릇만큼 좋은 것은 없습니다.</p><p>미네스트로네는 이탈리아의 대표적인 수프로，콩，푸짐한 채소，쌀 또는 파스타를 결합하여 풍성하고 맛이 좋습니다. 그 맛은 다양한 재료를 조합한 결과입니다. 동유럽의 보르시，미국의 캐서롤，태평양 아시아의 집에서 만든 볶음 요리와 마찬가지로，구하기 쉽고 저렴한 재료를 결합하여 사랑받는 요리를 만드는 것과 같습니다.</p><p><a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a>의 논문을 시작으로，신경망 모델에도 거의 같은 종류의 레시피를 사용할 수 있습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://proceedings.mlr.press/v162/wortsman22a.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">모델 수프: 여러 미세 조정된 모델의 가중치를 평균하면 추론 시간 증가 없이 정확도 향상</div><div class=\"kg-bookmark-description\">모델 정확도를 극대화하기 위한 기존의 레시피는 (1) 다양한 하이퍼파라미터를 사용하여 여러 모델을 훈련하고 (2) 보류된 검증 세트에서 가장 잘 수행되는 개별 모델을 선택하는 것입니다…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-pmlr.ico\" alt=\"\"><span class=\"kg-bookmark-author\">PMLR</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://proceedings.mlr.press/v162/assets/images/logo-pmlr.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>“모델 수프”(아쉽게도 “모델 캐서롤”이나 “모델 볶음”은 아님)는 훈련 데이터 및 모델 하이퍼파라미터 최적화 비용을 줄이기 위해 설계된 모델 앙상블 기술의 한 종류입니다. 신경망을 훈련할 때 일반적으로 다양한 데이터와 하이퍼파라미터 값을 시도하고 여러 번 훈련하여 가장 성능이 좋은 결과를 찾습니다. 훈련은 계산 비용이 매우 많이 들고 비용이 빠르게 증가합니다.</p><p>대신，모델 수프는 다양한 하이퍼파라미터와 훈련 데이터 선택으로 여러 모델을 훈련한 다음 (일반적으로 하는 것과 동일) 결합합니다. 그 결과는 단일 최고 성능 모델보다 성능이 더 높고 강력한 모델입니다. 여러 모델을 훈련하므로 비용이 절감되지는 않지만 동일한 가격으로 더 나은 결과를 얻을 수 있습니다.</p><p>모델 수프 접근 방식은 이미 텍스트-이미지 멀티모달 임베딩 모델 <a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">(Wortsman et al. 2022)</a> 및 생성적 대규모 언어 모델에 유용한 것으로 입증되었습니다. (<a href=\"https://doi.org/10.1038/s42256-024-00975-8\">Takuya et al. 2025</a>) Jina AI에서는 이 기술을 사용하여 자체 모델을 훈련하기 시작했으며，<code>jina-embeddings-v3</code> 및 <code>reader-lm-v2</code> 모두 모델 수프를 통합합니다.</p><p>이 문서에서는 모델 수프를 살펴보고 모델 수프를 사용한 작업 결과를 보여드리겠습니다. 특히:</p><ol><li>모델을 훈련하는 동안 여러 지점에서 모델을 병합하여 모델 수프를 사용하여 성능을 향상시킬 수 있을까요?</li><li>단일 모델을 훈련하는 것보다 더 나은 성능과 더 높은 훈련 효율성을 얻기 위해 서로 다른 데이터 세트와 서로 다른 작업에 대해 훈련된 모델을 병합할 수 있을까요?</li></ol><p>여기에는 중요한 잠재적 이점이 있습니다.</p><ul><li>모델 수프는 더 나은 성능과 더 강력한 성능을 가질 수 있습니다.</li><li>다국어 임베딩 모델은 종종 불균형한 양의 훈련 데이터로 인해 편향 및 성능 저하가 발생합니다. 각 작업 또는 데이터 세트에서 개별적으로 최상의 모델을 훈련한 다음 동일하게 결합할 수 있다면 큰 도움이 될 것입니다.</li><li>모델을 모듈식으로 변경하고，한 번에 하나의 구성 요소 모델을 업데이트한 다음 다른 모델과 다시 병합하여 더 나은 지속적인 학습 및 모델 업데이트를 수행할 수 있습니다.</li></ul><h2 id=\"how-does-it-work\">작동 방식</h2><p>여러 모델의 출력을 병합하는 것은 통계적 의사 결정 이론에서 오래된 기술입니다. 예를 들어，서로 다른 가정으로 다른 사람들이 만든 여러 모델을 만든 다음 다양한 메커니즘을 사용하여 예측을 평균하는 것이 일기 예보에서 일반적인 방법입니다. 각 모델의 오류가 무작위로 분포되어 있으면 모델을 평균하면 오류가 더 적은 답변을 얻을 수 있습니다.</p><p>예를 들어，이진 “예” 또는 “아니요”를 출력하는 세 개의 다른 모델이 있고 각 모델이 10%의 시간 동안 잘못된 경우 3개 중 2개가 잘못될 확률은 2.8%에 불과합니다. 과반수 결정 기준을 사용하는 5개의 모델은 0.856%의 시간 동안만 잘못될 것입니다.</p><p>모델 평균은 동일한 원리로 작동하지만 서로 다른 모델의 출력을 결합하는 대신 모델 자체를 결합합니다.</p><p>사용되는 접근 방식은 <em>확률적 가중치 평균</em>(<a href=\"https://auai.org/uai2018/proceedings/papers/313.pdf\">Izmailov et al. 2018</a>)의 확장으로，신경망의 손실 지형에 대한 통찰력을 바탕으로 일반적인 조건에서 간단한 가중치 평균이 모델 일반화 성능을 향상시킬 수 있음을 보여줍니다.</p><p>모델 평균의 실제 메커니즘은 놀라울 정도로 간단합니다. 여러 모델의 가중치를 평균하면 됩니다.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"380\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/image.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"><figcaption><span style=\"white-space: pre-wrap;\">모델 수프를 만들기 위해 모델을 병합하는 방법. 이 예는 매우 작고 간단하지만 여전히 절차를 보여줍니다. 가중치를 합산하고 병합할 모델 수로 나눕니다.</span></figcaption></figure><p>이것이 너무 쉬워 보인다면 이러한 방식으로 모델을 병합할 때 제한 사항이 있다는 점에 유의해야 합니다. 임의의 두 신경망의 가중치를 병합하고 작동할 것으로 기대할 수는 없습니다.</p><p>모델 평균은 매우 유사한 모델，즉 가중치가 처음부터 서로 크게 다르지 않은 모델에서만 작동합니다. 이를 보장하는 방법은 하나의 모델을 사전 훈련한 다음 다양한 하이퍼파라미터 또는 다양한 데이터로 미세 조정하여 해당 모델의 여러 변형을 만드는 것입니다. 이러한 모델은 일반적으로 평균화할 수 있을 만큼 충분히 유사합니다.</p><p>더 기술적인 용어로，사전 훈련은 일반적으로 손실 영역의 맨 아래에 가까운 가중치가 있는 모델을 생성하고 미세 조정은 해당 손실 영역에서 쉽게 벗어나지 않습니다. 병합할 모든 모델의 가중치가 동일한 손실 영역에 있으면 가중치가 거의 동일해지고 평균화가 작동할 가능성이 높습니다. 이것은 보장되지는 않지만 경험적으로 유용할 만큼 자주 사실인 것으로 보입니다.</p><h2 id=\"experimental-setup\">실험 설정</h2><p><strong>기본 모델</strong>: 여기에 설명된 실험에서는 <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\">FacebookAI의 <code>xlm-roberta-base</code></a>(<a href=\"https://aclanthology.org/2020.acl-main.747/\">Conneau et al. 2020</a>)를 사전 훈련된 기본 모델로 사용했습니다. 이 모델에는 2억 8천만 개의 파라미터가 있으며 약 100개 언어의 텍스트를 포함하는 2.5TB의 Common Crawl 데이터에서 사전 훈련되었습니다.</p><p>실험을 수행하기 전에 임베딩 훈련을 위해 큐레이트된 문장 쌍 훈련 세트에서 <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code></a>를 미세 조정했습니다.</p><p><strong>훈련 데이터</strong>: Jina AI는 훈련을 위해 사용자 지정 큐레이트된 데이터 세트를 유지 관리합니다. 첫 번째 실험에서는 영어，아랍어，독일어，스페인어，일본어，중국어의 6개 언어로 대조 훈련을 위해 특별히 큐레이트된 문장 삼중 항을 사용했습니다. 두 번째 실험에서는 영어로 된 작업별 훈련 데이터 세트를 사용했습니다.</p><p><strong>평가</strong>: <a href=\"https://github.com/embeddings-benchmark/mteb/tree/main/docs/mmteb\">MMTEB 벤치마크 세트</a>(<a href=\"https://arxiv.org/abs/2502.13595\">Enevoldsen et al. 2025</a>) 및 <a href=\"https://project-miracl.github.io/\">MIRACL 벤치마크</a>(<a href=\"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00595/117438/MIRACL-A-Multilingual-Retrieval-Dataset-Covering\">Zhang et al. 2023</a>)의 관련 부분을 사용하여 훈련 및 병합으로 생성된 모델을 평가했습니다.</p><h3 id=\"experiment-1-single-run-averaging\">실험 1: 단일 실행 평균</h3><p>이 실험에서는 6개 언어의 대조 문장 삼중 항을 모두 함께 혼합하여 총 6,000회의 훈련 단계를 거쳤으며 배치 크기는 1,024개 항목이었습니다. 매 2,000단계마다 평균화를 위해 모델 상태를 저장하여 3개의 모델을 생성했으며 각 모델은 훈련 과정의 서로 다른 지점을 반영합니다.</p><p>세 모델을 평균하여 최종 모델을 생성했습니다. 그런 다음 병합된 모델과 세 개의 저장된 체크포인트를 MMTEB-STS 및 MIRACL 벤치마크 세트에 대해 테스트했습니다.</p><p>결과는 아래 표에 요약되어 있습니다.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>모델</th>\n<th>MIRACL<br>(평균 6개 언어)</th>\n<th>MMTEB-STS 영어<br>(평균 8개 벤치마크)</th>\n<th>MMTEB-STS 다국어<br>(평균 6개 벤치마크)</th>\n<th>평균 20개 벤치마크</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>삼중 항 훈련 없음</td>\n<td>0.3163</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.6276</td>\n</tr>\n<tr>\n<td>2000단계</td>\n<td>0.4631</td>\n<td><strong>0.7924</strong></td>\n<td>0.7561</td>\n<td>0.6813</td>\n</tr>\n<tr>\n<td>4000단계</td>\n<td>0.4639</td>\n<td>0.7902</td>\n<td><strong>0.7583</strong></td>\n<td>0.6812</td>\n</tr>\n<tr>\n<td>6000단계(최종)</td>\n<td><strong>0.4680</strong></td>\n<td>0.7891</td>\n<td>0.7575</td>\n<td>0.6818</td>\n</tr>\n<tr>\n<td>병합된 모델<br>(저장된 모든 3개의 체크포인트)</td>\n<td>0.4669</td>\n<td>0.7910</td>\n<td>0.7579</td>\n<td><strong>0.6823</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>이전 체크포인트와 병합해도 일반적으로 개별 벤치마크 또는 사용된 세 개의 벤치마크 배터리에서 저장된 체크포인트 중 최고 성능 모델보다 더 나은 성능의 모델이 생성되지는 않았습니다. 그러나 모든 벤치마크를 함께 평균한 결과 최고의 모델이 생성되었습니다.</p><p>개별 벤치마크에서 병합된 모델과 최고 성능 체크포인트 간의 차이는 모든 경우에 0.01 미만입니다. 이는 위의 표의 평균뿐만 아니라 각 개별 테스트에도 해당됩니다.</p><p>이는 다양한 훈련 체크포인트를 병합하면 성능 비용이 거의 들지 않고 더 강력한 모델을 생성할 수 있음을 보여줍니다.</p><p>또한 다양한 체크포인트를 병합하여 효과적으로 과적합을 방지할 수 있습니다. 과적합은 최근 신경망에서 중요한 주제가 되었습니다. (<a href=\"https://arxiv.org/abs/2503.19206v2\">Springer et al., 2025</a>) 네트워크는 추가 미세 조정 후 더 어렵고 성능이 저하되는 방식으로 훈련될 수 있습니다.</p><p>우리 실험에서 최고 성능 체크포인트가 종종 마지막 체크포인트가 아니기 때문에 6,000회의 훈련 단계에서 모델을 과적합했을 가능성이 높습니다. 병합된 모델은 모든 테스트에서 최고의 체크포인트의 성능과 매우 근접하여 과적합의 결함을 제거합니다.</p><h3 id=\"experiment-2-averaging-models-trained-for-different-tasks\">실험 2: 서로 다른 작업에 대해 훈련된 모델 평균</h3><p>이 실험에서는 각각 다른 일반적인 임베딩 작업에 대해 세 개의 모델을 훈련했습니다.</p><ul><li><strong>의미론적 유사성</strong>: 일반적으로 길이가 비슷한 두 텍스트 간의 의미론적 중복 또는 유사성을 측정합니다.</li><li><strong>텍스트 쿼리를 기반으로 한 문서 검색</strong>: 쿼리를 가장 잘 충족하는 문서를 찾습니다. 일반적으로 쿼리는 일치하는 문서보다 훨씬 짧은 텍스트입니다.</li><li><strong>질의 응답</strong>: 자연어 질문에 가장 적합한 문서를 찾습니다. 질문 또한 일반적으로 텍스트보다 훨씬 짧습니다.</li></ul><p>세 가지 작업 모두에 대해 한 번에 모델을 훈련하는 것은 목표가 매우 다르기 때문에 매우 어렵고, 모델 수프가 프로세스를 개선할 수 있기를 바랍니다.</p><p>이전 경험을 바탕으로 각 작업에 필요한 훈련 epoch 수가 다르다는 것을 알고 있었습니다. 훈련은 다음과 같이 요약됩니다.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>작업</th>\n<th>훈련 단계<br>(batchsize = 1,024)</th>\n<th>훈련 데이터 세트 크기<br>(항목 기준)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>질의 응답 (QA)</td>\n<td>2,000</td>\n<td>256,000</td>\n</tr>\n<tr>\n<td>문서 검색</td>\n<td>3,000</td>\n<td>384,000</td>\n</tr>\n<tr>\n<td>의미 유사성 (STS)</td>\n<td>1,000</td>\n<td>128,000</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>이를 통해 세 개의 모델이 생성되었고, 이를 하나의 모델로 병합했습니다. 그런 다음 해당 모델을 세 가지 작업과 관련된 MMTEB 벤치마크 세트 부분인 <a href=\"https://project-miracl.github.io/\">MIRACL</a>, <a href=\"https://huggingface.co/collections/zeta-alpha-ai/nanobeir-66e1a0af21dfd93e620cd9f6\">NanoBEIR</a> 및 STSEval (MMTEB의 영어 및 다국어 부분)에 대해 테스트했습니다.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(평균 6개 언어)</th>\n<th>NanoBEIR<br>(평균 13개 벤치마크)</th>\n<th>MMTEB-STS 영어<br>(평균 9개 벤치마크)</th>\n<th>MMTEB-STS 다국어<br>(평균 6개 벤치마크)</th>\n<th>평균 34개 벤치마크</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>삼중항 훈련 없음</td>\n<td>0.3163</td>\n<td>0.5089</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.5876</td>\n</tr>\n<tr>\n<td>QA 훈련</td>\n<td><strong>0.4489</strong></td>\n<td>0.5332</td>\n<td>0.7843</td>\n<td>0.7535</td>\n<td>0.6237</td>\n</tr>\n<tr>\n<td>검색 훈련</td>\n<td>0.4272</td>\n<td><strong>0.5360</strong></td>\n<td>0.7766</td>\n<td>0.7340</td>\n<td>0.6154</td>\n</tr>\n<tr>\n<td>STS 훈련</td>\n<td>0.1779</td>\n<td>0.4519</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.5508</td>\n</tr>\n<tr>\n<td>병합된 모델</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td><strong>0.6240</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>여기서 작업별로 훈련된 모델이 각 작업에서 최고의 성능을 보이는 것을 알 수 있습니다. MIRACL은 검색이라고 불리지만 주로 질의 응답 벤치마크이며, QA 훈련된 모델이 병합된 모델을 포함하여 다른 모든 모델보다 성능이 뛰어납니다. NanoBEIR은 보다 일반적인 정보 검색 벤치마크 세트이며, 검색 훈련된 모델이 최고 성능을 보이는 것을 알 수 있습니다. 의미 유사성 (STS) 모델은 해당 벤치마크에서 매우 낮은 점수를 보이지만 명시적으로 STS 작업에서 다른 모델을 능가합니다. 각 범주에서 병합된 모델은 단일 작업 훈련된 모델보다 성능이 떨어집니다.</p><p>그러나 다시 한 번 모든 벤치마크에서 평균을 내면 병합된 모델이 다른 모델보다 성능이 뛰어나지만, 해당 점수는 QA 훈련된 모델보다 아주 약간 향상된 수준이며, STS 작업에서는 매우 낮은 성능을 보입니다.</p><p>또한 QA 및 검색 모델만 병합하고 동일한 벤치마크에서 결과 모델의 점수를 매겼습니다.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(평균 6개 언어)</th>\n<th>NanoBEIR<br>(평균 13개 벤치마크)</th>\n<th>MMTEB-STS 영어<br>(평균 9개 벤치마크)</th>\n<th>MMTEB-STS 다국어<br>(평균 6개 벤치마크)</th>\n<th>평균 34개 테스트</th>\n<th>평균<br>QA &amp; IR<br>(19개 테스트)</th>\n<th>평균 STS<br>(15개 테스트)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>최고 작업 훈련된 모델</td>\n<td>0.4489</td>\n<td>0.5360</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.6237</td>\n<td>0.5066</td>\n<td><strong>0.7857</strong></td>\n</tr>\n<tr>\n<td>병합된 모델</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td>0.6240</td>\n<td>0.4973</td>\n<td>0.7845</td>\n</tr>\n<tr>\n<td>QA+검색 병합된 모델</td>\n<td><strong>0.4610</strong></td>\n<td><strong>0.5404</strong></td>\n<td>0.7878</td>\n<td>0.7498</td>\n<td><strong>0.6288</strong></td>\n<td><strong>0.5153</strong></td>\n<td>0.7726</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>여기서 두 작업에 대해 훈련된 모델을 병합하여 질의 응답 및 검색 모두에서 성능을 향상시킬 수 있지만, STS 훈련된 모델을 추가하면 모든 범주에서 작업별 성능이 저하되는 것을 알 수 있습니다. 이는 의미 유사성이 몇 가지 중요한 측면에서 QA 및 검색과 다르며, STS 훈련된 모델은 다른 두 모델과 병합하는 데 적합하지 않음을 시사합니다.</p><p>이는 질의 응답 및 검색은 짧은 텍스트 (질문 및 쿼리)를 더 긴 문서와 일치시키는 반면, 의미 유사성은 길이가 더 비슷한 문서를 비교하는 것과 관련이 있기 때문일 수 있습니다.</p><p><a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a>은 \"탐욕적\" 병합이라고 부르는 선택적 평균화 접근 방식을 설명합니다. 여기에는 일반적으로 모델 세트에서 최고의 성능을 보이는 모델을 하나 선택한 다음 개별적으로 성능을 향상시키는 모델만 추가하는 것이 포함됩니다. 모델이 3개밖에 없었기 때문에 이 실험에 탐욕적 병합을 사용하는 것은 의미가 없었습니다. 그러나 더 많은 모델이 있고 이러한 기술을 작업 간의 유사성 정도를 결정하기 위한 기준으로 사용하는 경우를 상상할 수 있습니다. 여기서 의미 유사성이 다른 두 모델과 다르다는 것을 발견했습니다. 그런 다음 하나의 모델이 많은 작업을 수행할 수 있는 경우와 다른 모델을 사용하는 것이 더 비용 효율적인 경우를 평가할 수 있습니다.</p><h2 id=\"soup%E2%80%99s-on\">수프가 준비되었습니다!</h2><p>모델 수프는 다양성을 혼합하여 부분의 합보다 더 큰 것을 만듭니다. 이 접근 방식의 가치는 추가 훈련 비용 없이 더 큰 일관성, 견고성을 제공하고 과도한 훈련에 대한 보호 장치 역할을 할 수 있다는 것입니다. 우리의 실험은 체크포인트 또는 작업 전문 모델을 병합하면 작업별 최고점에 희생될 수 있지만 전반적인 성능을 향상시킬 수 있음을 보여줍니다.</p><p>결론적으로 모델 수프는 몇 가지 주의 사항이 있지만 더 적응력이 뛰어난 모델을 구축하는 실용적이고 매우 간단한 방법을 제공합니다. 만병통치약은 아니며 모델이 이미 매우 유사한 경우에만 적용할 수 있습니다.</p><p>인터넷에서 말하듯이 <em>Your Mileage May Vary</em>입니다. 그러나 모델을 훈련할 때 모델 수프가 도움이 될 수 있는지 확인하는 것은 저렴하고 쉽습니다.</p>",
  "comment_id": "681b63a077c406000104263b",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/Heading--6-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-07T15:44:00.000+02:00",
  "updated_at": "2025-05-07T19:56:02.000+02:00",
  "published_at": "2025-05-07T18:43:10.000+02:00",
  "custom_excerpt": "Boost robustness and performance with model soups: averaging weights. No extra cost, better results.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "authors": [
    {
      "id": "6360e7e05e0f6e004d70bd99",
      "name": "Bo Wang",
      "slug": "bo",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
      "cover_image": null,
      "bio": "Developer @Jina, Contributor to open source ",
      "website": "https://bwanglzu.github.io/",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@bo_wangbo",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "primary_author": {
    "id": "6360e7e05e0f6e004d70bd99",
    "name": "Bo Wang",
    "slug": "bo",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
    "cover_image": null,
    "bio": "Developer @Jina, Contributor to open source ",
    "website": "https://bwanglzu.github.io/",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@bo_wangbo",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/model-soups-recipe-for-embeddings/",
  "excerpt": "모델 수프(model soups)로 견고성과 성능을 향상시키세요: 가중치 평균화. 추가 비용 없이 더 나은 결과를 얻을 수 있습니다.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}