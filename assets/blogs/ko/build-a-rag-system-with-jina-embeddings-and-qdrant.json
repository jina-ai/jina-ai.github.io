{
  "slug": "build-a-rag-system-with-jina-embeddings-and-qdrant",
  "id": "65ddadd039a5b70001810ea3",
  "uuid": "e3419a3e-4a7c-43c3-ac69-6f65f00a7ad8",
  "title": "Jina Embeddings와 Qdrant를 사용한 RAG 시스템 구축",
  "html": "<p>데이터 검색 강화 생성(Retrieval-augmented generation)은 원래 대규모 언어 모델(LLM)의 확장으로 <a href=\"https://dl.acm.org/doi/abs/10.5555/3495724.3496517?ref=jina-ai-gmbh.ghost.io\"><u>처음 고안되었지만</u></a>, 이제는 AI 모델의 역할을 완전히 재구상하는 대안적 패러다임으로 빠르게 발전하고 있는 기술입니다.</p><p>우리는 <a href=\"https://www.llamaindex.ai/?ref=jina-ai-gmbh.ghost.io\">LlamaIndex 프레임워크</a>, 오픈소스 <a href=\"https://docs.mistral.ai/?ref=jina-ai-gmbh.ghost.io\">Mistral LLM</a>, <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2</a>, 그리고 <a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\">Qdrant의 AI 지원 벡터 데이터베이스</a>를 사용하여 기본적인 RAG 엔진을 만드는 방법을 보여드리겠습니다.</p><h2 id=\"rag-in-context\"><strong>RAG의 맥락</strong></h2><p>RAG 시스템에서 AI 모델의 역할은 여전히 중심적이지만 훨씬 더 제한적입니다. 학습 데이터에서 얻은 내부 지식을 바탕으로 프롬프트에 답하는 대신, 프롬프트에 관련 정보가 제시됩니다. 그러면 모델의 역할은 정보를 이해하고 종합하여 출력하는 것입니다.</p><p>이는 AI 모델의 강점을 살리고 약점을 최소화합니다.</p><p>예를 들어, <a href=\"https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io\"><u>Mistral-Instruct 모델</u></a>에 다음과 같은 프롬프트를 제시할 수 있습니다:</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\nQuery: Why is Taylor Swift planning to attend the Superbowl?\nAnswer:\n</code></pre><p>이때 모델은 다음과 같이 응답했습니다:</p><pre><code class=\"language-text\">I don't have real-time information. However, as of my last update,&nbsp;\nTaylor Swift is not officially confirmed to attend or perform at&nbsp;\nthe Superbowl. If there are any updates, I recommend checking the&nbsp;\nlatest news sources.</code></pre><p>대규모 언어 모델은 업데이트와 재학습이 비용이 많이 들기 때문에, 내부 정보가 완전히 최신 상태일 수 없습니다.</p><p>또한, 대규모 언어 모델은 \"환각\"을 일으키는 것으로 잘 알려져 있습니다. 즉, 부분적으로 또는 전체적으로 잘못될 수 있는 그럴듯한 답변을 만들어내며 이는 검증이 필요합니다.</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\nQuery: What was Weird Al Yankovic's first Taylor Swift parody?\nAnswer:\n\nWeird Al Yankovic's first Taylor Swift parody was \"TMZ,\" a spoof&nbsp;\nof Swift's song \"Blank Space.\" The parody was released in 2014&nbsp;\nas part of Yankovic's album \"Mandatory Fun.\" The song humorously&nbsp;\naddresses the obsession with celebrity gossip and scandals, as&nbsp;\nreported by the tabloid news website TMZ.</code></pre><p>Weird Al Yankovic의 <em>TMZ</em>는 2011년 <em>Alpocalypse</em> 앨범에서 발매되었으며 Swift의 <a href=\"https://youtu.be/vwp8Ur6tO-8?ref=jina-ai-gmbh.ghost.io\"><em><u>You Belong with Me</u></em></a>의 패러디입니다.</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/BwqFgnl4rMs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\" title=\"TMZ (Parody of &quot;You Belong With Me&quot; by Taylor Swift) (Official 4K Video)\"></iframe></figure><p>신경망의 특성상 환각을 완전히 방지하는 것은 어렵거나 불가능하며, 이는 AI 모델을 정보 소스로 사용하려는 계획을 크게 약화시킵니다.</p><p>OpenAI의 CEO인 Sam Altman의 <a href=\"https://youtu.be/uaQZIK9gvNo?t=1130&ref=jina-ai-gmbh.ghost.io\"><u>말</u></a>에 따르면:</p><blockquote class=\"kg-blockquote-alt\">\"사람들이 이러한 모델들[LLM]을 데이터베이스로 생각하는 것은 큰 실수라고 봅니다. [...] 어느 정도는 작동할 것입니다. 하지만 그것은 세상에서 가장 비싸고, 가장 느리며, 가장 부정확한 데이터베이스입니다.\"</blockquote><p>RAG는 세상에 대한 AI 모델의 내부 지식에 대한 의존도를 최소화하고 자연어 이해와 유창한 언어 생성이라는 가장 큰 강점을 활용합니다.</p><p>Mistral-Instruct가 답할 수 없는 또 다른 질문의 예를 보겠습니다:</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\n\nQuery: What is the title of Taylor Swift's next album?\nAnswer:\n\nAs of the time I am providing this answer, Taylor Swift has&nbsp;\nnot yet announced the title of her next album. She has released&nbsp;\nseveral re-recorded albums, but the title of her next original&nbsp;\nalbum remains unknown. I recommend checking her official social&nbsp;\nmedia channels or website for the latest updates.</code></pre><p>이제 RAG 시스템은 최근 뉴스 기사의 데이터베이스를 가지고 있거나 Taylor Swift의 다음 앨범 제목과 관련된 텍스트를 인터넷에서 검색할 수 있습니다. 그런 다음 찾은 텍스트를 프롬프트에 삽입합니다.</p><p><a href=\"https://apnews.com/article/taylor-swift-new-album-5e219107982b1498a3656caeea85e0eb?ref=jina-ai-gmbh.ghost.io\"><u>이 AP 기사</u></a>가 질문과 관련이 있다고 판단하고 다음과 같은 프롬프트를 구성했다고 가정해 봅시다:</p><pre><code class=\"language-text\">Context information is below.\n---------------------\nFebruary 6, 2024\nLOS ANGELES (AP) — Forget her \"Reputation.\" Taylor Swift has&nbsp;\nwhole new album coming out.\n\nAccepting the Grammy for best pop vocal album on Sunday night,&nbsp;\nTaylor said she'd been keeping a secret for two years.\n\n\"My brand-new album comes out April 19. It's called 'The Tortured&nbsp;\nPoets Department.' I'm going to go and post the cover right now&nbsp;\nbackstage,\" she announced.\n\nAnd so she did.\n\n---------------------\nGiven the context information and not prior knowledge, answer the query.&nbsp;\nPlease be brief, concise, and complete.\nIf the context information does not contain an answer to the query,&nbsp;\nrespond with \"No information\".\nQuery: What is the title of Taylor Swift's next album?\nAnswer:</code></pre><p>Mistral-Instruct는 다음과 같이 응답했습니다:</p><pre><code class=\"language-text\">The title of Taylor Swift's next album is 'The Tortured Poets Department'.</code></pre><p>이러한 종류의 프롬프팅은 환각이 발생할 가능성도 크게 줄입니다. 예를 들어:</p><pre><code class=\"language-text\">Context information is below.\n---------------------\nAlpocalypse is the thirteenth studio album by American parody&nbsp;\nmusician \"Weird Al\" Yankovic, released on June 21, 2011.\n\nTrack List\n\n1. Perform This Way (Parody of \"Born This Way\" by Lady Gaga)\n2. CNR\n3. TMZ (Parody of \"You Belong with Me\" by Taylor Swift)\n4. Skipper Dan\n5. Polka Face (Polka medley including songs by artists such as&nbsp;\n&nbsp;&nbsp;&nbsp;Lady Gaga, Justin Bieber, Britney Spears, Ke$ha, and others)\n6. Craigslist\n7. Party in the CIA (Parody of \"Party in the U.S.A.\" by Miley&nbsp;\n&nbsp;&nbsp;&nbsp;Cyrus)\n8. Ringtone\n9. Another Tattoo (Parody of \"Nothin' on You\" by B.o.B featuring&nbsp;\n&nbsp;&nbsp;&nbsp;Bruno Mars)\n10. If That Isn't Love\n11. Whatever You Like (Parody of \"Whatever You Like\" by T.I.)\n12. Stop Forwarding That Crap to Me\n\n---------------------\nGiven the context information and not prior knowledge, answer the&nbsp;\nquery. Please be brief, concise, and complete.\nIf the context information does not contain an answer to the query,&nbsp;\nrespond with \"No information\".\nQuery: What was Weird Al Yankovic's first Taylor Swift parody, what&nbsp;\nyear was it released, and what song was he parodying?\nAnswer:\n\nWeird Al Yankovic's first Taylor Swift parody was \"TMZ,\" and it was&nbsp;\nreleased in 2011. He was parodying \"You Belong with Me\" by Taylor&nbsp;\nSwift.\n</code></pre><h2 id=\"anatomy-of-a-rag-system\"><strong>RAG 시스템의 구조</strong></h2><p>RAG 시스템은 최소한 두 가지 구성 요소가 있습니다:</p><ul><li>생성형 AI 모델</li><li>정보 검색 시스템</li></ul><p>이 글에서는 <a href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2?ref=jina-ai-gmbh.ghost.io\">Mistral-Instruct</a>를 생성형 AI 모델로 사용하고 <a href=\"https://huggingface.co/docs/api-inference/index?ref=jina-ai-gmbh.ghost.io\">Hugging Face Inference API</a>를 통해 접근할 것입니다. 정보 검색 시스템으로는 <a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\">Qdrant 벡터 데이터베이스</a>와 <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings</a>를 함께 사용할 것입니다.</p><p>데이터 소스로는 2023년 5월 미국 대통령의 과학 기술 자문 기구인 <a href=\"https://www.whitehouse.gov/ostp/ostps-teams/nstc/?ref=jina-ai-gmbh.ghost.io\">국가과학기술위원회</a>가 발표한 <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf?ref=jina-ai-gmbh.ghost.io\"><em><u>국가 인공지능 연구개발 전략 계획 2023 업데이트</u></em></a>를 사용할 것입니다. 이 약 25,000단어의 문서는 미국의 AI 정책과 개발을 위한 정책 및 전략 계획 문서입니다.</p><p>이는 또한 전형적인 \"tl;dr\" 정부 정책 문서입니다. 대부분이 매우 지루하며, 이 분야에 특별한 이해관계나 관심이 없다면 아마 읽지 않을 것입니다. 하지만 여전히 그 내용이 무엇인지 알고 싶을 수 있습니다.</p><p>이 글에서는 텍스트와 그 내용에 대한 질문에 답할 수 있는 RAG 시스템을 만드는 단계를 안내할 것입니다.</p><h2 id=\"install-the-prerequisites\"><strong>필수 요소 설치</strong></h2><p>먼저 관련된 모든 Python 라이브러리가 설치되어 있는지 확인하세요. Python 환경에서 다음을 실행하세요:</p><pre><code class=\"language-shell\">pip install llama-index qdrant-client \npip install pdfminer.six llama-index-vector-stores-qdrant\npip install llama-index-llms-openai llama-index-embeddings-jinaai \npip install llama-index-llms-huggingface \"huggingface_hub[inference]\"</code></pre><p>우리는 LlamaIndex를 사용하여 Mistral-Instruct 대규모 언어 모델을 중심으로 RAG 시스템을 구축하고, <a href=\"https://pypi.org/project/pdfminer.six/?ref=jina-ai-gmbh.ghost.io\"><u>pdfminer.six</u></a>를 사용하여 PDF 파일을 Qdrant 벡터 스토어로 처리할 것입니다.</p><h2 id=\"connect-to-mistral-instruct-via-the-hugging-face-inference-api\"><strong>Hugging Face Inference API를 통해 Mistral-Instruct에 연결하기</strong></h2><p>먼저 LLM을 설정합니다. Hugging Face Inference API에 접근하려면 액세스 토큰이 필요합니다. Hugging Face 계정이 있다면 <a href=\"https://huggingface.co/settings/tokens.?ref=jina-ai-gmbh.ghost.io\">계정 설정 페이지</a>에서 받을 수 있습니다.</p><p>계정이 없다면 먼저 <a href=\"https://huggingface.co/join?ref=jina-ai-gmbh.ghost.io\">계정을 만든 다음</a>, <a href=\"https://huggingface.co/settings/tokens?ref=jina-ai-gmbh.ghost.io\">액세스 토큰</a>을 생성하세요.</p><p>나중에 사용할 수 있도록 토큰을 변수에 저장하세요:</p><pre><code class=\"language-python\">hf_inference_api_key = '&lt;your HuggingFace Inference API token&gt;'</code></pre><p>다음으로 프롬프트 템플릿을 구성합니다:</p><pre><code class=\"language-python\">from llama_index.core import PromptTemplate\n\nqa_prompt_tmpl = (\n    \"Context information is below.\\n\"\n    \"---------------------\\n\"\n    \"{context_str}\\\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the query. Please be brief, concise, and complete.\\n\"\n    \"If the context information does not contain an answer to the query, \"\n    \"respond with \\\"No information\\\".\\n\"\n    \"Query: {query_str}\\n\"\n    \"Answer: \"\n)\nqa_prompt = PromptTemplate(qa_prompt_tmpl)</code></pre><p>이 템플릿은 LLM에게 질문에 답하기 위해 프롬프트에 제공된 컨텍스트 정보만을 사용하도록 지시합니다. 이 프롬프트는 Mistral-Instruct와의 작업에서 잘 작동했지만, 여러분의 사용 사례에 맞게 다른 문구를 실험해볼 수 있습니다.</p><pre><code class=\"language-python\">from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n\nmixtral_llm = HuggingFaceInferenceAPI(\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n    token=hf_inference_api_key\n)</code></pre><p>마지막으로 Mistral-Instruct에 대한 연결을 보유하는 LlamaIndex 프레임워크용 객체를 생성하고 초기화합니다. 아래 코드는 <a href=\"https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/?ref=jina-ai-gmbh.ghost.io\"><u>LlamaIndex를 사용한 RAG 시스템 구축에 관한 이전 게시물</u></a>에서 가져온 것입니다.</p><p>이는 Mistral LLM에 대한 연결을 <code>mistral_llm</code> 변수에 저장합니다.</p><h2 id=\"information-retrieval-with-qdrant-and-jina-embeddings\"><strong>Qdrant와 Jina Embeddings를 사용한 정보 검색</strong></h2><p>검색 시스템을 설정하려면 Jina Embeddings API 키가 필요합니다. <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings 웹사이트</a>에서 100만 토큰의 선불 예산으로 무료로 얻을 수 있습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Start with 1M free tokens. Top-performing, 8192 context length bilingual embeddings for your search and RAG systems.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>나중에 사용할 수 있도록 Jina Embeddings 키를 변수에 저장하세요:</p><pre><code class=\"language-python\">jina_emb_api_key = \"&lt;your Jina Embeddings API key&gt;\"</code></pre><p>그런 다음, LlamaIndex를 사용하여 Jina Embeddings 서버용 커넥터 객체를 생성하고, 영어 단일어 모델을 특별히 선택합니다:</p><pre><code class=\"language-python\">from llama_index.embeddings.jinaai import JinaEmbedding\n\njina_embedding_model = JinaEmbedding(\n    api_key=jina_emb_api_key,\n    model=\"jina-embeddings-v2-base-en\",\n)</code></pre><h3 id=\"load-text-data\"><strong>텍스트 데이터 로드</strong></h3><p>다음으로, 문서를 로드하고 단락으로 나눌 것입니다. 먼저 White House 웹사이트에서 PDF를 다운로드하여 <code>pdf_data</code> 변수에 저장합니다:</p><pre><code class=\"language-python\">import urllib.request\n\nuri = \"https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf\"\npdf_data = urllib.request.urlopen(uri).read()</code></pre><p>다음으로, PDF를 페이지별로 처리하여 텍스트를 추출한 다음 이중 줄바꿈을 기준으로 분할하여 단락으로 나눕니다. 이들은 <code>text_paras</code> 리스트에 저장됩니다:</p><pre><code class=\"language-python\">import regex as re\nfrom io import BytesIO, StringIO\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfdocument import PDFDocument\nfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.pdfpage import PDFPage\nfrom pdfminer.pdfparser import PDFParser\n\ntext_paras = []\nparser = PDFParser(BytesIO(pdf_data))\ndoc = PDFDocument(parser)\nrsrcmgr = PDFResourceManager()\nfor page in PDFPage.create_pages(doc):\n    output_string = StringIO()\n    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    interpreter.process_page(page)\n    page_text = output_string.getvalue()\n    text_paras.extend(re.split(r'\\n\\s*\\n', page_text))\n</code></pre><p>모든 것이 로드되었는지 확인합니다:</p><pre><code class=\"language-python\">assert len(text_paras) == 615</code></pre><p>다음으로, 이 짧은 텍스트 리스트를 <a href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/root.html?ref=jina-ai-gmbh.ghost.io\">LlamaIndex Document 객체</a>로 변환할 것입니다:</p><pre><code class=\"language-python\">from llama_index.core.readers import StringIterableReader\n\nrag_docs = StringIterableReader().load_data(text_paras)</code></pre><p>텍스트를 검사할 수 있습니다:</p><pre><code class=\"language-python\">print(rag_docs[0].text)</code></pre><p>결과:</p><pre><code class=\"language-text\">NATIONAL ARTIFICIAL INTELLIGENCE \nRESEARCH AND DEVELOPMENT \nSTRATEGIC PLAN \n2023 UPDATE</code></pre><h3 id=\"set-up-a-qdrant-vector-database\"><strong>Qdrant 벡터 데이터베이스 설정</strong></h3><p>이 글에서는 RAG 시스템의 데이터베이스를 구현하기 위해 <a href=\"https://cloud.qdrant.io/?ref=jina-ai-gmbh.ghost.io\"><u>Qdrant Vector Search Cloud</u></a>를 사용할 것입니다. Qdrant의 무료 티어에는 1GB의 저장 공간이 포함되어 있어 이 튜토리얼에 충분합니다.</p><p>계속하기 전에 <a href=\"https://cloud.qdrant.io/login?ref=jina-ai-gmbh.ghost.io\"><u>Qdrant Cloud 웹사이트에서 계정을 만들어야</u></a> 합니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://cloud.qdrant.io/login?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Vector Search Database | Qdrant Cloud</div><div class=\"kg-bookmark-description\">Managed cloud solution of the Qdrant vector search engine. Cloud-native vector database for high performant vector similarity search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cloud.qdrant.io/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Qdrant Cloud</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cloud.qdrant.io/social.png\" alt=\"\"></div></a></figure><p>계정이 있고 로그인한 후에는 클러스터를 생성해야 합니다. Qdrant 웹사이트의 <a href=\"https://qdrant.tech/documentation/cloud/quickstart-cloud/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>\"quick start\" 지침</u></a>을 따라 무료 클러스터를 설정하고 API와 Qdrant 호스트 서버 이름을 받으세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/cloud/quickstart-cloud/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Quickstart - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://qdrant.tech/images/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Edit on GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://qdrant.tech/documentation/cloud/quickstart-cloud-social-preview.png\" alt=\"\"></div></a></figure><p>키와 호스트네임을 변수에 저장하세요:</p><pre><code class=\"language-python\">qdrant_api_key = \"&lt;your API key&gt;\"\nqdrant_server = \"https://&lt;your server&gt;\"</code></pre><p>다음으로, <code>qdrant_client</code>와 <code>llama_index</code> 패키지에서 관련 컴포넌트를 임포트해야 합니다:</p><pre><code class=\"language-python\">import qdrant_client\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\n\nclient = qdrant_client.QdrantClient(qdrant_server, api_key=qdrant_api_key)\nvector_store = QdrantVectorStore(client=client, collection_name=\"NTSC\")</code></pre><p>이것은 무료 클러스터에 <code>NTSC</code>라는 이름의 컬렉션을 생성합니다.</p><p>메모리나 디스크에 로컬 데이터 저장소를 구성하고 web API를 통해 docker 컨테이너에서 자체 Qdrant 서버 인스턴스를 호스팅하는 방법에 대한 정보는 <a href=\"https://qdrant.tech/documentation/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>Qdrant 문서</u></a>를 참조하세요.</p><h3 id=\"complete-the-rag-system\"><strong>RAG 시스템 완성하기</strong></h3><p>이제 LlamaIndex의 기본 코드를 사용하여 이러한 구성 요소들을 완전한 RAG 시스템으로 조립해보겠습니다:</p><pre><code class=\"language-python\">from llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.storage.storage_context import StorageContext\nfrom llama_index.core import (\n\t\tVectorStoreIndex,\n\t\tServiceContext,\n\t\tget_response_synthesizer,\n)\n\n# set up the service and storage contexts\nservice_context = ServiceContext.from_defaults(\n&nbsp;&nbsp;&nbsp;&nbsp;llm=mixtral_llm, embed_model=jina_embedding_model\n)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n# create an index\nindex = VectorStoreIndex.from_documents(\n&nbsp;&nbsp;&nbsp;&nbsp;rag_docs, storage_context=storage_context, service_context=service_context\n)\n\n# configure retriever\nretriever = VectorIndexRetriever(\n&nbsp;&nbsp;&nbsp;&nbsp;index=index,\n&nbsp;&nbsp;&nbsp;&nbsp;similarity_top_k=2,\n)\n\n# configure response synthesizer\nresponse_synthesizer = get_response_synthesizer(\n&nbsp;&nbsp;&nbsp;&nbsp;service_context=service_context,\n&nbsp;&nbsp;&nbsp;&nbsp;text_qa_template=qa_prompt,\n&nbsp;&nbsp;&nbsp;&nbsp;response_mode=\"compact\",\n)\n\n# assemble query engine\nquery_engine = RetrieverQueryEngine(\n&nbsp;&nbsp;&nbsp;&nbsp;retriever=retriever,\n&nbsp;&nbsp;&nbsp;&nbsp;response_synthesizer=response_synthesizer,\n)\n</code></pre><p>이 시스템은 Jina Embeddings를 사용하여 텍스트 소스의 단락을 인덱싱하고 모든 프롬프트의 컨텍스트에 가장 일치하는 두 개의 결과를 포함시킵니다. 예를 들어 가장 일치하는 세 개의 결과로 변경하려면 위의 <code>VectorIndexRetriever</code> 초기화에서 <code>similarity_top_k</code> 매개변수만 수정하면 됩니다:</p><pre><code class=\"language-python\"># configure retriever\nretriever = VectorIndexRetriever(\n&nbsp;&nbsp;&nbsp;&nbsp;index=index,\n&nbsp;&nbsp;&nbsp;&nbsp;similarity_top_k=3,\n)</code></pre><p>이제 시스템을 사용할 준비가 되었습니다.</p><h3 id=\"query-a-document\"><strong>문서 쿼리하기</strong></h3><p>간단한 쿼리를 시도해보겠습니다:</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat is the Biden Administration's policy with regard to AI?&nbsp;\n\"\"\")\nprint(response.response)</code></pre><p>결과 (귀하의 결과와 동일하지 않을 수 있습니다):</p><pre><code class=\"language-text\">The Biden Administration prioritizes responsible AI systems that&nbsp;\nare ethical, trustworthy, and safe, and serve the public good. \nThe Administration has committed to substantial funding for AI \nR&amp;D, and has established the National AI Initiative Office to \ncoordinate AI activities across the federal government.&nbsp;\n\nThe Administration's AI policy focuses on developing evaluative\ntechniques for AI, workforce development, public-private\npartnerships, and international collaboration in AI research.</code></pre><p>더 구체적인 쿼리:</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat protections does the AI Bill of Rights propose to offer?\n\"\"\")\n\nprint(response.response)</code></pre><pre><code class=\"language-text\">The AI Bill of Rights proposes five core protections: Safe and&nbsp;\nEffective Systems; Algorithmic Discrimination Protections; Data&nbsp;\nPrivacy; Notice and Explanation; and Human Alternatives,&nbsp;\nConsideration, and Fallback.</code></pre><p>또는 매우 구체적인 쿼리:</p><pre><code class=\"language-python\">response = query_engine.query(\"Who is Kei Koizumi?\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">Kei Koizumi is the Principal Deputy Director for Policy at the Office&nbsp;\nof Science and Technology Policy (OSTP).</code></pre><p>더 창의적인 질문도 할 수 있습니다:</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat rights will AI's receive under President Biden's proposed&nbsp;\nAI Bill of Rights?\n\"\"\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">The proposed AI Bill of Rights does not grant rights to AI systems, but&nbsp;\nrather outlines principles to ensure that AI technologies are&nbsp;\ndeveloped and used in a manner that respects human rights and values.&nbsp;\nThe principles include safety, transparency, fairness, disclosure,&nbsp;\ndata privacy, non-discrimination, and the ability for individuals to&nbsp;\nopt out of certain AI systems.</code></pre><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhy is President Biden's proposing an AI Bill of Rights?\nDoes AI really need rights?\n\"\"\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">President Biden's proposed AI Bill of Rights aims to ensure that AI&nbsp;\ntechnologies are developed and used ethically, legally, and with&nbsp;\nsocietal considerations in mind. The Bill of Rights is not granting&nbsp;\n\"rights\" to AI, but rather setting guidelines for the responsible&nbsp;\ndevelopment and deployment of AI systems to protect individuals and&nbsp;\ncommunities from potential negative impacts.</code></pre><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nHas Donald Trump weighed in on AI?\nWill he Make Humans Great Again?\n\"\"\")\nprint(response.response)\n</code></pre><pre><code class=\"language-text\">No information. The context information does not mention Donald&nbsp;\nTrump's views on AI.</code></pre><h2 id=\"jina-ai-and-qdrant\"><strong>Jina AI와 Qdrant</strong></h2><p>Jina Embeddings의 8k 토큰 컨텍스트 윈도우는 훨씬 더 큰 텍스트 블록을 처리할 수 있어 검색 증강 생성에 특히 적합합니다. 다른 RAG 애플리케이션이 개별 문장이나 문장 쌍을 저장해야 하는 경우가 많은 반면, 이 튜토리얼에서는 크기를 걱정하지 않고 전체 단락을 사용할 수 있었습니다.</p><p>이는 동일한 정보를 전달하는 데 필요한 텍스트 항목의 수를 줄여 계산 비용을 낮추고, 메모리를 절약하며, 검색을 더 빠르게 만듭니다.</p><p>Qdrant의 벡터 데이터베이스는 구성이 간단하고, 빠르며, 비용 효율적이며, 보셨듯이 Python 코드 몇 줄만으로 RAG 시스템에 통합할 수 있습니다.</p><p>Qdrant의 AI 지원 데이터베이스와 클라우드 서비스에 대해 자세히 알아보려면 <a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>웹사이트를 방문</u></a>하세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Qdrant - Vector Database</div><div class=\"kg-bookmark-description\">Qdrant는 Rust로 작성된 오픈소스 벡터 데이터베이스이자 벡터 검색 엔진입니다. 편리한 API로 빠르고 확장 가능한 벡터 유사도 검색 서비스를 제공합니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://qdrant.tech/images/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Vector Database</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://qdrant.tech/images/previews/social-preview-P.png\" alt=\"\"></div></a></figure><h2 id=\"get-in-touch\"><strong>연락하기</strong></h2><p>Jina AI는 모든 규모와 유형의 기업에 신뢰할 수 있고 저렴한 AI 기술을 제공하기 위해 노력하고 있습니다. 귀하의 사용 사례에 대해 듣고 AI를 비즈니스 프로세스에 맞추는 데 도움을 드리고 싶습니다. Jina AI의 제품에 대한 자세한 정보와 연락처는 <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>Jina AI 웹사이트</u></a>를 확인하거나 <a href=\"https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>Discord 커뮤니티</u></a>에 참여하세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - 최고의 임베딩과 완벽한 프롬프트</div><div class=\"kg-bookmark-description\">Jina AI는 최고 수준의 임베딩 API와 프롬프트 최적화 도구를 제공하여 멀티모달 AI 애플리케이션 개발을 용이하게 합니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-author\">Best Embeddings and Perfect Prompts</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI Discord 서버에 참여하세요!</div><div class=\"kg-bookmark-description\">Discord의 Jina AI 커뮤니티를 확인해보세요 - 4493명의 다른 멤버들과 함께 무료 음성 및 텍스트 채팅을 즐기세요.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://discord.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512\" alt=\"\"></div></a></figure>",
  "comment_id": "65ddadd039a5b70001810ea3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/02/Blog-images--26-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-02-27T10:39:28.000+01:00",
  "updated_at": "2024-03-06T15:41:18.000+01:00",
  "published_at": "2024-03-04T16:00:13.000+01:00",
  "custom_excerpt": "Create a RAG system with Jina Embeddings v2, Qdrant vector database, LlamaIndex, and Mistral LLM.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/build-a-rag-system-with-jina-embeddings-and-qdrant/",
  "excerpt": "Jina Embeddings v2, Qdrant 벡터 데이터베이스, LlamaIndex, 그리고 Mistral LLM을 사용하여 RAG 시스템 만들기",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Promotional graphic with \"EMBEDDINGS 2\" and Drant logo separated by a red cross, symbolizing a partnership.",
  "feature_image_caption": null
}