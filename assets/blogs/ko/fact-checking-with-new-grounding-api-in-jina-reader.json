{
  "slug": "fact-checking-with-new-grounding-api-in-jina-reader",
  "id": "670cd94952567c0001d0f33e",
  "uuid": "20c36ec7-687f-47c8-8cfd-8da526a70859",
  "title": "Jina Reader의 새로운 Grounding API를 활용한 팩트체킹",
  "html": "<p>GenAI 애플리케이션에서 그라운딩은 <em>절대적으로 필수적</em>입니다.</p><p>그라운딩이 없으면 LLM은 환각을 일으키고 부정확한 정보를 생성하기 쉽습니다. 특히 학습 데이터에 최신 정보나 특정 지식이 부족할 때 그렇습니다. LLM의 추론 능력이 아무리 뛰어나더라도, 해당 정보가 지식 컷오프 날짜 <em>이후에</em> 도입된 경우에는 올바른 답을 제공할 수 없습니다.</p><p>그라운딩은 LLM뿐만 아니라 허위 정보를 방지하기 위한 사람이 작성한 콘텐츠에도 중요합니다. <a href=\"https://communitynotes.x.com/guide/en/about/introduction?ref=jina-ai-gmbh.ghost.io\">X의 Community Notes</a>가 좋은 예시인데, 사용자들이 협력하여 잠재적으로 오해의 소지가 있는 게시물에 맥락을 추가합니다. Community Notes가 정보의 무결성을 유지하는 데 도움이 되는 것처럼, 명확한 출처와 참조를 제공하여 사실의 정확성을 보장하는 그라운딩의 가치를 잘 보여줍니다.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png\" class=\"kg-image\" alt=\"Screenshot of a mobile chat in the Sage app discussing whether whales are mammals and how they hydrate, with options to rate \" loading=\"lazy\" width=\"2000\" height=\"1113\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><p><a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>를 통해 우리는 사용하기 쉬운 그라운딩 솔루션을 적극적으로 개발해왔습니다. 예를 들어, <code>r.jina.ai</code>는 웹 페이지를 LLM 친화적인 마크다운으로 변환하고, <code>s.jina.ai</code>는 주어진 쿼리를 기반으로 검색 결과를 통합된 마크다운 형식으로 집계합니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs or search the web, get better grounding for LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-9.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><strong>오늘, 우리는 이 제품군에 새로운 엔드포인트인 <code>g.jina.ai</code>를 소개하게 되어 기쁩니다.</strong> 이 새로운 API는 주어진 문장을 실시간 웹 검색 결과를 사용하여 검증하고, 사실성 점수와 <strong>사용된 정확한 참조</strong>를 반환합니다. 우리의 실험에 따르면 이 API는 검색 그라운딩을 사용하는 GPT-4, o1-mini, Gemini 1.5 Flash & Pro와 같은 모델들과 비교했을 때 사실 확인에서 더 높은 F1 점수를 달성했습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Evaluation-of-grounding-solutions-on-fact-checking-100-statements--1-.svg\" class=\"kg-image\" alt=\"Bar graph illustrating the evaluation of various grounding solutions for fact-checking 100 statements, with software scores r\" loading=\"lazy\" width=\"1218\" height=\"371\"><figcaption><span style=\"white-space: pre-wrap;\">우리는 수동으로 '참' 또는 '거짓'의 실제 레이블이 있는 100개의 문장을 수집하고 다양한 방법을 사용하여 사실 확인이 가능한지 확인했습니다. 이 과정은 본질적으로 작업을 이진 분류 문제로 변환하며, 최종 성능은 F1 점수로 측정됩니다—점수가 높을수록 더 좋습니다.</span></figcaption></figure><p><code>g.jina.ai</code>가 Gemini의 Search Grounding과 다른 점은 각 결과에 최대 30개의 URL(일반적으로 최소 10개)이 포함되며, 각각에 결론에 기여한 직접적인 인용문이 함께 제공된다는 것입니다. 아래는 <code>g.jina.ai</code>를 사용하여 <code>\"The latest model released by Jina AI is jina-embeddings-v3,\"</code>라는 문장을 그라운딩한 예시입니다(2024년 10월 14일 기준). <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">API 플레이그라운드</a>에서 전체 기능을 살펴보세요. <a href=\"#limitations\" rel=\"noreferrer\">제한 사항</a>이 적용됨을 참고하세요:</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-bash\">curl -X POST https://g.jina.ai \\\n     -H \"Content-Type: application/json\" \\\n     -H \"Authorization: Bearer $YOUR_JINA_TOKEN\" \\\n     -d '{\n           \"statement\":\"the last model released by Jina AI is jina-embeddings-v3\"\n         }'</code></pre><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>YOUR_JINA_TOKEN</span></code><span style=\"white-space: pre-wrap;\">은 귀하의 Jina AI API 키입니다. </span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">홈페이지에서 100만 개의 무료 토큰을 받을 수 있으며</span></a><span style=\"white-space: pre-wrap;\">, 이는 약 3-4번의 무료 시도를 할 수 있는 양입니다. 현재 API 가격인 100만 토큰당 0.02USD로, 각 그라운딩 요청은 약 $0.006의 비용이 듭니다.</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"code\": 200,\n  \"status\": 20000,\n  \"data\": {\n    \"factuality\": 0.95,\n    \"result\": true,\n    \"reason\": \"The majority of the references explicitly support the statement that the last model released by Jina AI is jina-embeddings-v3. Multiple sources, such as the arXiv paper, Jina AI's news, and various model documentation pages, confirm this assertion. Although there are a few references to the jina-embeddings-v2 model, they do not provide evidence contradicting the release of a subsequent version (jina-embeddings-v3). Therefore, the statement that 'the last model released by Jina AI is jina-embeddings-v3' is well-supported by the provided documentation.\",\n    \"references\": [\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"arXiv September 18, 2024 jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"We introduce jina-embeddings-v3, a novel text embedding model with 570 million parameters, achieves state-of-the-art performance on multilingual data and long-context retrieval tasks, supporting context lengths of up to 8192 tokens.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview\",\n        \"keyQuote\": \"jina-embeddings-v3 is a multilingual multi-task text embedding model designed for a variety of NLP applications.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://docs.pinecone.io/models/jina-embeddings-v3\",\n        \"keyQuote\": \"Jina Embeddings v3 is the latest iteration in the Jina AI's text embedding model series, building upon Jina Embedding v2.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://haystack.deepset.ai/integrations/jina\",\n        \"keyQuote\": \"Recommended Model: jina-embeddings-v3 : We recommend jina-embeddings-v3 as the latest and most performant embedding model from Jina AI.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"The embedding model was trained using 512 sequence length, but extrapolates to 8k sequence length (or even longer) thanks to ALiBi.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"With a standard size of 137 million parameters, the model enables fast inference while delivering better performance than our small model.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"We offer an `encode` function to deal with this.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jinaai/jina-embeddings-v3 Feature Extraction • Updated 3 days ago • 278k • 375\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"the latest version (3.1.0) of [SentenceTransformers] also supports jina-embeddings-v3\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/embeddings/\",\n        \"keyQuote\": \"v3: Frontier Multilingual Embeddings is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\",\n        \"keyQuote\": \"Jina Embeddings v3: A Frontier Multilingual Embedding Model jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/\",\n        \"keyQuote\": \"As of its release on September 18, 2024, jina-embeddings-v3 is the best multilingual model ...\",\n        \"isSupportive\": true\n      }\n    ],\n    \"usage\": {\n      \"tokens\": 112073\n    }\n  }\n}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">2024년 10월 14일 기준 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>g.jina.ai</span></code><span style=\"white-space: pre-wrap;\">를 사용하여 \"The latest model released by Jina AI is jina-embeddings-v3\"라는 문장을 그라운딩한 응답입니다.</span></p></figcaption></figure><h2 id=\"how-does-it-work\">어떻게 작동하나요?</h2><p>핵심적으로, <code>g.jina.ai</code>는 <code>s.jina.ai</code>와 <code>r.jina.ai</code>를 래핑하고<strong> </strong>Chain of Thought (CoT)를 통한 다중 홉 추론을 추가합니다. 이 접근 방식은 각 그라운딩된 문장이 온라인 검색과 문서 읽기를 통해 철저히 분석되도록 보장합니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/User-Render.svg\" class=\"kg-image\" alt=\"UI of Jina AI reader app, displaying three panels: User Input, Response, and User Render with interactive links and buttons a\" loading=\"lazy\" width=\"1400\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">Grounding API는 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>s.jina.ai</span></code><span style=\"white-space: pre-wrap;\">와 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>r.jina.ai</span></code><span style=\"white-space: pre-wrap;\">를 기반으로 하여 계획과 추론을 위한 CoT를 추가한 래퍼입니다.</span></figcaption></figure><h3 id=\"step-by-step-explanation\">단계별 설명</h3><p><code>g.jina.ai</code>가 입력에서 최종 출력까지 어떻게 근거를 제시하는지 전체 프로세스를 살펴보겠습니다:</p><ol><li><strong>입력 진술</strong>:<br>사용자가 근거를 제시하고 싶은 진술을 제공하면서 프로세스가 시작됩니다. 예를 들어 <em>\"Jina AI가 출시한 최신 모델은 jina-embeddings-v3입니다.\"</em> 참고로 진술 앞에 사실 확인 지시를 추가할 필요는 없습니다.</li><li><strong>검색 쿼리 생성</strong>:<br>LLM을 사용하여 진술과 관련된 고유한 검색 쿼리 목록을 생성합니다. 이러한 쿼리들은 진술의 모든 핵심 측면을 포괄적으로 검색할 수 있도록 다양한 사실적 요소를 대상으로 합니다.</li><li><strong>각 쿼리에 대해 <code>s.jina.ai</code> 호출</strong>:<br>생성된 각 쿼리에 대해 <code>g.jina.ai</code>는 <code>s.jina.ai</code>를 사용하여 웹 검색을 수행합니다. 검색 결과는 쿼리와 관련된 다양한 웹사이트나 문서로 구성됩니다. 백그라운드에서 <code>s.jina.ai</code>는 페이지 콘텐츠를 가져오기 위해 <code>r.jina.ai</code>를 호출합니다.</li><li><strong>검색 결과에서 참조 추출</strong>:<br>검색 중에 검색된 각 문서에서 LLM이 주요 참조를 추출합니다. 이러한 참조에는 다음이 포함됩니다:<ul><li><strong><code>url</code></strong>: 소스의 웹 주소</li><li><strong><code>keyQuote</code></strong>: 문서에서 직접 인용하거나 발췌한 내용</li><li><strong><code>isSupportive</code></strong>: 참조가 원래 진술을 지지하거나 모순되는지를 나타내는 부울 값</li></ul></li><li><strong>참조 집계 및 정리</strong>:<br>검색된 문서의 모든 참조가 단일 목록으로 결합됩니다. 총 참조 수가 30개를 초과하면 시스템은 관리 가능한 출력을 유지하기 위해 30개의 무작위 참조를 선택합니다.</li><li><strong>진술 평가</strong>:<br>평가 프로세스는 수집된 참조(최대 30개)를 기반으로 LLM을 사용하여 진술을 평가하는 것을 포함합니다. 이러한 외부 참조 외에도 모델의 내부 지식이 평가에 역할을 합니다. 최종 결과에는 다음이 포함됩니다:<ul><li><strong><code>factuality</code></strong>: 진술의 사실 정확도를 0에서 1 사이의 점수로 추정</li><li><strong><code>result</code></strong>: 진술이 참인지 거짓인지를 나타내는 부울 값</li><li><strong><code>reason</code></strong>: 지지하거나 모순되는 출처를 참조하여 진술이 옳거나 틀린 이유에 대한 상세한 설명</li></ul></li><li><strong>결과 출력</strong>:<br>진술이 완전히 평가되면 출력이 생성됩니다. 여기에는 <strong>사실성 점수</strong>, <strong>진술의 주장</strong>, <strong>상세한 추론</strong> 및 인용문과 URL이 포함된 <strong>참조 목록</strong>이 포함됩니다. 참조는 인용, URL 및 진술을 지지하는지 여부로 제한되어 출력을 명확하고 간결하게 유지합니다.</li></ol><h2 id=\"benchmark\">벤치마크</h2><p>우리는 수동으로 <code>true</code>(62개 진술)와 <code>false</code>(38개 진술) 중 하나의 실제 레이블이 있는 100개의 진술을 수집하고 다양한 방법을 사용하여 사실 확인이 가능한지 확인했습니다. 이 프로세스는 본질적으로 작업을 이진 분류 문제로 변환하며, 최종 성능은 정밀도, 재현율 및 F1 점수로 측정됩니다—점수가 높을수록 좋습니다.</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1xE-uCTQ4G0cYRw_g781zZXHO8eRYi31HbCb-3BPlNh8/edit?gid=1283553680&ref=jina-ai-gmbh.ghost.io#gid=1283553680\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Grounding Validation Dataset</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyJpf4HNZ3zF1snMGetpmkt0oOTQGGviY1-ZTOrq5dXuafT8uWLmZ806MU1A_agTpgO52Z_xZ-iDougmFm0ViL0sVSqDxe3C4fVuPcYXKoS5O90jN3Qy-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">전체 진술 목록은 여기에서 확인할 수 있습니다.</span></p></figcaption></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Precision</th>\n<th>Recall</th>\n<th>F1 Score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Jina AI Grounding API (g.jina.ai)</strong></td>\n<td>0.96</td>\n<td><strong>0.88</strong></td>\n<td><strong>0.92</strong></td>\n</tr>\n<tr>\n<td>Gemini-flash-1.5-002 w/ grounding</td>\n<td><strong>1.00</strong></td>\n<td>0.73</td>\n<td>0.84</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-002 w/ grounding</td>\n<td>0.98</td>\n<td>0.71</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>gpt-o1-mini</td>\n<td>0.87</td>\n<td>0.66</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>0.95</td>\n<td>0.58</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001 w/ grounding</td>\n<td>0.97</td>\n<td>0.52</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001</td>\n<td>0.95</td>\n<td>0.32</td>\n<td>0.48</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>참고로 실제로는 일부 LLM이 예측에서 세 번째 클래스인 <em>모르겠습니다</em>를 반환합니다. 평가를 위해 이러한 인스턴스는 점수 계산에서 제외됩니다. 이 접근 방식은 불확실성을 잘못된 답변만큼 엄격하게 처벌하지 않습니다. 모델이 불확실한 예측을 하지 않도록 하기 위해 추측하는 것보다 불확실성을 인정하는 것이 선호됩니다.</p><h2 id=\"limitations\">한계</h2><p>유망한 결과에도 불구하고, 현재 버전의 grounding API의 몇 가지 한계를 강조하고자 합니다:</p><ul><li><strong>높은 지연 시간 및 토큰 소비</strong>: 활성 웹 검색, 페이지 읽기 및 LLM의 다중 홉 추론으로 인해 <code>g.jina.ai</code>에 대한 단일 호출은 약 <strong>30초</strong>가 걸리고 최대 <strong>300K 토큰</strong>을 사용할 수 있습니다. 100만 토큰의 무료 API 키로는 3-4번 정도만 테스트할 수 있다는 의미입니다. 유료 사용자의 서비스 가용성을 유지하기 위해 <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\" rel=\"noreferrer\"><code>g.jina.ai</code>에 대해 보수적인 속도 제한을 구현</a>했습니다. 현재 API 가격인 100만 토큰당 0.02 USD로 각 grounding 요청은 약 0.006 USD의 비용이 듭니다.</li><li><strong>적용 가능성 제약</strong>: <em>모든 진술이 근거를 제시할 수 있거나 제시해야 하는 것은 아닙니다.</em> \"나는 게으르다\"와 같은 개인적인 의견이나 경험은 근거 제시에 적합하지 않습니다. 마찬가지로 미래의 사건이나 가정적인 진술도 적용되지 않습니다. grounding이 무의미하거나 의미가 없는 많은 경우가 있습니다. 불필요한 API 호출을 피하기 위해 사용자는 실제로 사실 확인이 필요한 문장이나 섹션만 선별적으로 제출하는 것이 좋습니다. 서버 측에서는 진술이 grounding을 거부받을 수 있는 이유를 설명하는 포괄적인 오류 코드 세트를 구현했습니다.</li><li><strong>웹 데이터 품질에 대한 의존성</strong>: grounding API의 정확도는 검색하는 소스의 품질에 따라 달라집니다. 검색 결과에 낮은 품질이나 편향된 정보가 포함되어 있다면, grounding 프로세스가 이를 반영하여 부정확하거나 오해의 소지가 있는 결론으로 이어질 수 있습니다. 이 문제를 방지하기 위해 사용자가 <code>references</code> 매개변수를 수동으로 지정하고 시스템이 검색하는 URL을 제한할 수 있도록 합니다. 이를 통해 사용자는 grounding에 사용되는 소스를 더 잘 제어할 수 있어 더 집중적이고 관련성 있는 사실 확인 프로세스를 보장할 수 있습니다.</li></ul><h2 id=\"conclusion\">결론</h2><p>grounding API는 종단간의 거의 실시간 사실 확인 경험을 제공합니다. 연구자들은 이를 사용하여 자신의 가설을 지지하거나 도전하는 참조를 찾아 연구의 신뢰성을 높일 수 있습니다. 회사 회의에서는 가정과 데이터를 검증하여 전략이 정확하고 최신 정보를 기반으로 구축되도록 보장합니다. 정치적 토론에서는 주장을 신속하게 검증하여 토론에 더 많은 책임감을 부여합니다.</p><p>향후 더 맞춤화된 사실 확인을 위해 내부 보고서, 데이터베이스, PDF와 같은 비공개 데이터 소스를 통합하여 API를 개선할 계획입니다. 또한 더 깊이 있는 평가를 위해 요청당 확인하는 소스 수를 늘리고자 합니다. 다중 홉 질의응답을 개선하여 분석의 깊이를 더하고, 반복된 요청이 더 신뢰할 수 있고 일관된 결과를 생성하도록 일관성을 높이는 것이 우선순위입니다.</p>",
  "comment_id": "670cd94952567c0001d0f33e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-14T10:41:45.000+02:00",
  "updated_at": "2024-10-15T20:11:23.000+02:00",
  "published_at": "2024-10-15T10:08:02.000+02:00",
  "custom_excerpt": "With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fact-checking-with-new-grounding-api-in-jina-reader/",
  "excerpt": "새로운 g.jina.ai를 사용하면 LLM의 환각을 줄이거나 사람이 작성한 콘텐츠의 무결성을 개선하기 위해 진술을 쉽게 근거화할 수 있습니다.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Jina developer interface showing \"Jina AI was founded in 2020\" with controls labeled true and false, and web address on top.",
  "feature_image_caption": null
}