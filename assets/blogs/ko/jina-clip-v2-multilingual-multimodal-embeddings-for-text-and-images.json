{
  "slug": "jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images",
  "id": "673cc4a7a7c46d00015cf1f5",
  "uuid": "6ca44950-b989-494a-b587-70847f24edd2",
  "title": "Jina CLIP v2: 텍스트와 이미지를 위한 다국어 멀티모달 임베딩",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-clip-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">우리는 오픈소스와 오픈 사이언스를 통해 인공지능을 발전시키고 민주화하는 여정을 걸어가고 있습니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-11.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-clip-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?sui=&model=jina-clip-v2&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - 향상된 검색 기반</div><div class=\"kg-bookmark-description\">최고 수준의 임베딩, 재순위 매기기, LLM 리더, 웹 스크래퍼, 분류기. 다국어 및 멀티모달 데이터를 위한 최고의 검색 AI.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">향상된 검색 기반</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> API는 \"Embeddings\" 탭에서 사용할 수 있습니다.</span></p></figcaption></figure><p>멀티모달 임베딩은 일관된 표현을 통해 서로 다른 모달리티 간의 데이터 검색과 이해를 가능하게 합니다. 이는 신경 정보 검색과 멀티모달 GenAI 애플리케이션의 근간이 됩니다. 오늘 우리는 <code>jina-clip-v1</code>과 최근 출시한 <code>jina-embeddings-3</code>을 기반으로 구축된 새로운 범용 다국어 멀티모달 임베딩인 <code>jina-clip-v2</code>를 발표하게 되어 기쁩니다. 주요 개선 사항은 다음과 같습니다:</p><ul><li><strong>성능 향상</strong>: v2는 텍스트-이미지 및 텍스트-텍스트 검색 작업에서 v1보다 3% 향상된 성능을 보여줍니다. v1과 마찬가지로 v2의 텍스트 인코더는 효과적인 다국어 장문 밀집 검색기로 사용될 수 있습니다. MTEB에서 1B 파라미터 미만의 최고 다국어 임베딩인 <code>jina-embeddings-v3</code>와 대등한 성능을 보입니다.</li><li><strong>다국어 지원</strong>: 텍스트 타워로 <code>jina-embeddings-v3</code>를 사용하여 89개 언어에 대한 다국어-이미지 검색을 지원하며, 다국어 이미지 검색 작업에서 <code>nllb-clip-large-siglip</code>보다 최대 4% 향상된 성능을 보여줍니다.</li><li><strong>높은 이미지 해상도</strong>: v2는 이제 v1의 224x224에서 크게 향상된 512x512 입력 이미지 해상도를 지원합니다. 이러한 높은 해상도로 상세한 이미지 처리, 향상된 특징 추출, 더 정확한 세부 시각 요소 인식이 가능합니다.</li><li><strong>마트료시카 표현</strong>: v2는 사용자가 텍스트와 이미지 임베딩의 출력 차원을 1024에서 64까지 줄일 수 있게 하여, 강력한 성능을 유지하면서 저장 공간과 처리 오버헤드를 줄일 수 있습니다.</li></ul><h2 id=\"model-architecture\">모델 아키텍처</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--35-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p><code>jina-clip-v2</code>는 두 개의 강력한 인코더를 결합한 0.9B CLIP 스타일 모델입니다: 텍스트 인코더 <code>Jina XLM-RoBERTa</code>(<code>jina-embeddings-v3</code>의 백본)와 비전 인코더 <code>EVA02-L14</code>(BAAI에서 개발한 효율적인 비전 트랜스포머). 이 인코더들은 이미지와 텍스트의 정렬된 표현을 생성하도록 함께 학습됩니다.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Text Encoder</th>\n<th>Image Encoder</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base Model</td>\n<td>Jina XLM-RoBERTa</td>\n<td>EVA02-L</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>561M</td>\n<td>304M</td>\n</tr>\n<tr>\n<td>Input Specification</td>\n<td>8,192 tokens (max)</td>\n<td>512×512 pixels</td>\n</tr>\n<tr>\n<td>Min Output Dimensions</td>\n<td>64</td>\n<td>64</td>\n</tr>\n<tr>\n<td>Max Output Dimensions</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Layers</td>\n<td>24</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Attention Mechanism</td>\n<td>FlashAttention2</td>\n<td>xFormers</td>\n</tr>\n<tr>\n<td>Pooling Strategy</td>\n<td>Mean pooling</td>\n<td>CLS pooling</td>\n</tr>\n<tr>\n<td>Additional Features</td>\n<td>89 languages supported</td>\n<td>Patch size 14x14</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"cross-modal-retrieval-performance\">교차 모달 검색 성능</h2><p>Jina CLIP v2는 89개 언어에 대한 다국어 지원을 제공하며 아랍어, 중국어, 영어, 프랑스어, 독일어, 일본어, 러시아어, 스페인어를 포함한 주요 언어에서 최고 성능을 보여줍니다. 다국어 이미지 검색 벤치마크에서, NLLB 모델의 사전 학습된 텍스트 인코더를 사용하는 약간 더 큰 (1.3B, <code>jina-clip-v2</code>보다 44% 더 큼) 최신 CLIP 스타일 모델인 <a href=\"https://huggingface.co/visheratin/nllb-clip-large-siglip?ref=jina-ai-gmbh.ghost.io\">NLLB-CLIP-SigLIP</a>와 비슷하거나 더 나은 성능을 보여줍니다.</p><h3 id=\"english-only-text-and-images\">영어 전용 텍스트 및 이미지</h3><p>표준 교차 모달 검색 벤치마크(Flickr30k와 COCO)에서, <code>jina-clip-v2</code>는 전반적으로 강력한 개선을 보여줍니다. Flickr30k 이미지-텍스트 검색에서 98.0%의 최고 성능을 달성하여 전작과 NLLB-CLIP-SigLIP 모두를 능가합니다. 이 모델은 COCO 이미지-텍스트 검색에서 v1보다 최대 3.3% 향상된 성능을 보이면서, 다양한 벤치마크와 모달리티 방향에서 NLLB-CLIP-SigLIP와 경쟁력 있는 성능을 유지합니다.</p><p><strong>Flickr30k Recall@5 성능:</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>98.0</td>\n<td>+1.7%</td>\n<td>+0.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>96.4</td>\n<td>-</td>\n<td>-0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>97.1</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>89.8</td>\n<td>+0.9%</td>\n<td>-2.6%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>89.0</td>\n<td>-</td>\n<td>-3.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>92.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>COCO Recall@5 성능:</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>81.5</td>\n<td>+3.3%</td>\n<td>+2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>78.9</td>\n<td>-</td>\n<td>-0.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>79.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>68.4</td>\n<td>+2.9%</td>\n<td>-3.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>66.5</td>\n<td>-</td>\n<td>-6.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>70.8</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"multilingual-text-and-images\">다국어 텍스트 및 이미지</h3><p>다국어 교차 모달 벤치마크에서, <code>jina-clip-v2</code>는 강력한 성능을 보여주며, 특히 이미지-텍스트 검색에서 모든 데이터셋에서 NLLB-SigLIP를 능가하여 Crossmodal 3600에서 최대 +3.8% 향상을 보여줍니다. NLLB-SigLIP가 텍스트-이미지 검색에서 약간 더 강한 성능을 보이지만, 성능 차이는 일반적으로 3% 이내로 작습니다.</p><p><strong>이미지->텍스트 Recall@5 성능:</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>83.23</td>\n<td>+3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>80.16</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>86.03</td>\n<td>+0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.37</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.98</td>\n<td>+0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.41</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>텍스트->이미지 Recall@5 성능:</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>81.43</td>\n<td>-0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>82.07</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>84.87</td>\n<td>-3.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.60</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.03</td>\n<td>-3.0%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.63</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"text-only-dense-retriever-performance\">텍스트 전용 Dense Retriever 성능</h2><p>이전 버전과 마찬가지로, <code>jina-clip-v2</code>의 텍스트 인코더는 효과적인 다국어 dense retriever로 사용될 수 있습니다. 포괄적인 다국어 MTEB 벤치마크에서 검색 작업에서 69.86%, 의미적 유사도 작업에서 67.77%를 달성하며 강력한 성능을 보여줍니다. 이러한 결과는 전문 텍스트 임베딩 모델인 <code>jina-embeddings-v3</code>와 경쟁력 있는 성능을 보여주며 그 다용도성을 입증합니다:</p><table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>69.86</td>\n<td>-3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>72.59</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Semantic Similarity</td>\n<td>jina-clip-v2</td>\n<td>67.77</td>\n<td>-2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>69.81</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p>영어 작업에서 <code>jina-clip-v2</code>는 이전 버전과 NLLB-SigLIP 모두를 능가하는 일관된 개선을 보여주며, 특히 검색 성능에서 NLLB-SigLIP 점수의 거의 2배에 달하는 강력한 이점을 보여줍니다.</p><table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>STS</td>\n<td>jina-clip-v2</td>\n<td>81.29</td>\n<td>+0.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>80.92</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>74.65</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>49.33</td>\n<td>+2.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>48.33</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>24.92</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"matryoshka-representation-performance\">Matryoshka 표현 성능</h2><p>텍스트와 이미지 인코더 모두 MRL을 지원하며, 강력한 성능을 유지하면서 출력 차원을 64로 줄일 수 있습니다. 임베딩 축소 평가에서 놀라운 압축 가능성이 드러났습니다. 75%의 공격적인 차원 축소에도 텍스트, 이미지, 크로스모달 작업 전반에 걸쳐 99% 이상의 성능을 유지했습니다.</p><h3 id=\"image-classification\">이미지 분류</h3><p>37개의 다양한 이미지 분류 벤치마크에서, 이미지 인코더는 차원 축소에 대한 강한 회복력을 보여줍니다. 1024에서 64 차원으로의 압축(94% 감소)은 top-5 정확도에서 단 8% 하락과 top-1에서 12.5% 하락만을 보여, 성능 손실을 최소화하면서 효율적인 배포가 가능함을 강조합니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/accuracy_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption><span style=\"white-space: pre-wrap;\">이미지 분류</span><b><strong style=\"white-space: pre-wrap;\">를 위해</strong></b><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://github.com/google-research/task_adaptation?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">VTAB 데이터셋</span></a><span style=\"white-space: pre-wrap;\">의 19개 벤치마크, </span><a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">VOC 2007</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://www.tensorflow.org/datasets/catalog/sun397?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">SUN397</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://cs.stanford.edu/~acoates/stl10/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">STL10</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Rendered SST2</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://objectnet.dev/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ObjectNet</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://github.com/cvdfoundation/mnist?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">MNIST</span></a><span style=\"white-space: pre-wrap;\">, German Traffic Sign Recognition Benchmark (</span><a href=\"https://benchmark.ini.rub.de/gtsrb_dataset.html?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">GTSRB</span></a><span style=\"white-space: pre-wrap;\">), Fine-Grained Visual Classification of Aircraft (</span><a href=\"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">FGVC-Aircraft</span></a><span style=\"white-space: pre-wrap;\">), </span><a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">FER 2013</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://github.com/openai/CLIP/blob/main/data/country211.md?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Country211</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://www.tensorflow.org/datasets/catalog/cars196?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Cars196</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://github.com/hendrycks/natural-adv-examples?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet-A, ImageNet-O,</span></a><a href=\"https://huggingface.co/datasets/ILSVRC/imagenet-1k?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet1k</span></a><span style=\"white-space: pre-wrap;\">, </span><a href=\"https://github.com/HaohanWang/ImageNet-Sketch?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet Sketch</span></a><span style=\"white-space: pre-wrap;\">, 그리고 </span><a href=\"https://imagenetv2.org/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ImageNet v2</span></a><span style=\"white-space: pre-wrap;\">를 사용했습니다.</span></figcaption></figure><h3 id=\"cross-modal-retrieval\">크로스 모달 검색</h3><p>차원을 94%나 대폭 축소하여 64차원으로 줄였음에도 불구하고, 잘린 이미지와 텍스트 임베딩을 사용한 크로스 모달 검색은 놀랍도록 강건하게 유지되어 이미지-텍스트 성능의 93%와 텍스트-이미지 성능의 90%를 보존했습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/crossmodal_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption><span style=\"white-space: pre-wrap;\">6개의 벤치마크를 사용했으며, 그 중 3개는 다국어를 지원합니다: </span><a href=\"https://google.github.io/crossmodal-3600/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Crossmodal-3600</span></a><span style=\"white-space: pre-wrap;\"> (36개 언어), </span><a href=\"https://shannon.cs.illinois.edu/DenotationGraph/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">flickr30k</span></a><span style=\"white-space: pre-wrap;\"> (영어만), </span><a href=\"https://hockenmaier.cs.illinois.edu/8k-pictures.html?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">flickr8k</span></a><span style=\"white-space: pre-wrap;\"> (영어만), </span><a href=\"https://arxiv.org/abs/1504.00325?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">MS COCO Captions</span></a><span style=\"white-space: pre-wrap;\"> (영어만), </span><a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Multilingual MS COCO Captions</span></a><span style=\"white-space: pre-wrap;\"> (10개 언어), </span><a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">XTD 200</span></a><span style=\"white-space: pre-wrap;\"> (27개 언어)</span></figcaption></figure><h3 id=\"text-only-retrieval\">텍스트 전용 검색</h3><p><strong>영어 전용 MTEB 벤치마크</strong>에서, 1024차원에서 64차원으로 압축된 텍스트 임베딩은 의미적 유사성을 놀랍도록 잘 보존하여 단 2.1%만 감소했으며, 검색은 17.5%의 적정 수준의 감소를 보였습니다.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/mteb_performance.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"></figure><h2 id=\"getting-started\">시작하기</h2><h3 id=\"via-api\">API를 통한 사용</h3><p>이 코드는 Python의 <code>requests</code>를 사용하여 임베딩을 생성하는 방법을 보여줍니다. 텍스트 문자열과 base64 이미지 또는 URL을 전달하고, 원하는 차원 크기를 지정하면 됩니다(기본값 1024, 아래에서는 768로 표시).</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-Python\">import requests\nimport numpy as np\nfrom numpy.linalg import norm\n\ncos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n\nurl = 'https://api.jina.ai/v1/embeddings'\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Authorization': 'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'\n}\n\ndata = {\n  'input': [\n     {\"text\": \"Bridge close-shot\"},\n     {\"url\": \"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s\"}],\n  'model': 'jina-clip-v2',\n  'encoding_type': 'float',\n  'dimensions': '768' \n}\n\nresponse = requests.post(url, headers=headers, json=data)\nsim = cos_sim(np.array(response.json()['data'][0]['embedding']), np.array(response.json()['data'][1]['embedding']))\nprint(f\"Cosine text&lt;-&gt;image: {sim}\")</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">반드시 &lt;YOUR_JINA_AI_API_KEY&gt;를 활성화된 Jina API 키로 교체하세요. </span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">여기에서 100만 개의 무료 토큰이 포함된 무료 API 키를 받을 수 있습니다.</span></a></p></figcaption></figure><h3 id=\"image-tokens-pricing\">이미지 토큰 가격 책정</h3><p>우리 API는 텍스트와 이미지 토큰을 모두 계산합니다. 이미지의 경우, 토큰 소비량은 전체 이미지 영역을 커버하는 데 필요한 512x512 픽셀 타일의 수를 기준으로 합니다. 각 타일은 부분적으로 채워진 타일을 포함하여 처리하는 데 4,000 토큰이 소비됩니다. <strong>최적의 비용 효율성을 위해, API 사용자들이 요청을 보내기 전에 이미지를 512x512로 리사이즈할 것을 권장합니다.</strong></p><table>\n<thead>\n<tr>\n<th>이미지 해상도</th>\n<th>필요한 타일 수</th>\n<th>토큰 비용</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>512x512</td>\n<td>1</td>\n<td>4,000</td>\n</tr>\n<tr>\n<td>720x720</td>\n<td>4</td>\n<td>16,000</td>\n</tr>\n<tr>\n<td>1080x1080</td>\n<td>9</td>\n<td>36,000</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--37-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">정사각형 이미지의 경우, 최적의 비용 효율을 위해 512x512로 리사이즈하세요. 종횡비에 민감한 작업의 경우, 가장 긴 변을 512로 조정하고 이미지를 중앙에 두고 검은색으로 패딩하세요. 일반적인 용도의 경우, 직접 512x512로 리사이징하는 것이 잘 작동합니다.</span></figcaption></figure><h3 id=\"via-csp-marketplaces\">CSP 마켓플레이스를 통한 사용</h3><p>Jina CLIP v2는 AWS, Azure 및 GCP에서 직접 사용할 수 있으며, 해당 플랫폼에 명시된 가격으로 제공됩니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-bfbctuqmky676?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina CLIP v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-10.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-9.ico\" alt=\"\"></div></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://console.cloud.google.com/marketplace/browse?q=jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Cloud console</div><div class=\"kg-bookmark-description\">Google Cloud Marketplace에서 스마트하게 지출하고 더 빠르게 조달하며 Google Cloud 약정 지출을 관리하세요. Google Cloud에서 실행되도록 최적화된 2000개 이상의 SaaS, VM, 개발 스택 및 Kubernetes 앱 카탈로그를 둘러보세요.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/default.png\" alt=\"\"></div></div></a></figure><h3 id=\"via-vectordb\"><strong>VectorDB를 통해</strong></h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">지식이 풍부한 AI를 구축하기 위한 벡터 데이터베이스 | Pinecone</div><div class=\"kg-bookmark-description\">수백만 개의 항목을 밀리초 단위로 검색하여 모든 객체와 유사한 매치를 찾아보세요. API 호출 하나로 차세대 검색을 경험하실 수 있습니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-3.png\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://weaviate.io/developers/weaviate/model-providers/jinaai/embeddings-multimodal?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">멀티모달 임베딩 | Weaviate</div><div class=\"kg-bookmark-description\">Weaviate의 Jina AI API 통합을 통해 Weaviate에서 직접 모델 기능에 액세스할 수 있습니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-12.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Weaviate</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/provider_integrations_jinaai.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina 임베딩 - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant는 Rust로 작성된 오픈소스 벡터 데이터베이스 및 벡터 검색 엔진입니다. 편리한 API로 빠르고 확장 가능한 벡터 유사도 검색 서비스를 제공합니다.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-4.png\" alt=\"\"><span class=\"kg-bookmark-author\">edit</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">결론</h2><p>6월에 출시한 <code>jina-clip-v1</code>은 OpenAI의 CLIP 모델을 확장하여 8,192 토큰까지의 텍스트 입력을 지원했고, 최첨단 다국어 <code>jina-embeddings-v3</code>를 기반으로, <code>jina-clip-v2</code>는 세 가지 주요 발전을 이루었습니다: 89개 언어에 대한 다국어 지원, 512x512 해상도의 이미지 지원 확대, 그리고 더 잘린 임베딩을 위한 마트료시카 표현 학습입니다.</p><p>CLIP 계열 모델들은 범용 멀티모달 애플리케이션의 중추로 자리잡았습니다. <code>jina-clip-v2</code>와 함께, 우리는 이러한 기능을 한 단계 발전시켜 언어 장벽을 허물고 더 정확한 크로스 모달 이해와 검색을 제공합니다. 이번 출시를 통해 전 세계 개발자들에게 멀티모달 검색과 검색 기능을 더욱 강력하고 접근하기 쉽게 만들어 주는 약속을 이행한다고 믿습니다.</p>",
  "comment_id": "673cc4a7a7c46d00015cf1f5",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/11/clipv2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-11-19T18:02:31.000+01:00",
  "updated_at": "2024-11-21T17:29:45.000+01:00",
  "published_at": "2024-11-21T17:29:45.000+01:00",
  "custom_excerpt": "Jina-CLIP v2, a 0.9B multimodal embedding model with multilingual support of 89 languages, high image resolution at 512x512, and Matryoshka representations.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/",
  "excerpt": "Jina-CLIP v2는 89개 언어를 지원하는 다국어 기능, 512x512의 고해상도 이미지 처리, 그리고 Matryoshka 표현을 갖춘 0.9B 규모의 멀티모달 임베딩 모델입니다.",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}