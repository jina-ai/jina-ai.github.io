{
  "slug": "next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker",
  "id": "65fabb91502fd000011c667e",
  "uuid": "45cd5187-838d-46b7-a8a0-d890fcda9041",
  "title": "차세대 클라우드 AI: Amazon SageMaker의 Jina Embeddings와 Rerankers",
  "html": "<p><a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings</a>와 <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io\">Jina Reranker</a>가 이제 <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS Marketplace</a>를 통해 <a href=\"https://aws.amazon.com/pm/sagemaker/?ref=jina-ai-gmbh.ghost.io\">Amazon SageMaker</a>에서 사용할 수 있게 되었습니다. 보안, 신뢰성, 클라우드 운영의 일관성을 중요시하는 기업 사용자들은 이제 Jina AI의 최첨단 AI를 자신들의 private AWS 배포 환경에서 사용할 수 있으며, AWS의 안정적인 인프라의 모든 장점을 누릴 수 있습니다.</p><p>AWS Marketplace에서 제공되는 모든 임베딩 및 재순위화 모델을 통해, SageMaker 사용자들은 8k 입력 컨텍스트 윈도우와 최고 수준의 다국어 임베딩을 경쟁력 있는 가격으로 온디맨드로 활용할 수 있습니다. AWS로 모델을 전송하거나 AWS에서 모델을 전송하는 데 비용을 지불할 필요가 없으며, 가격이 투명하고 AWS 계정과 통합된 청구 시스템을 이용할 수 있습니다.</p><p>현재 Amazon SageMaker에서 사용 가능한 모델은 다음과 같습니다:</p><ul><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2 Base - English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-6w6k6ckusixpw?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2 Small - English</a></li><li>Jina Embeddings v2 Bilingual Models:<ul><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-dz3ubvmivnwry?ref=jina-ai-gmbh.ghost.io\">German/English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-hxalozh37jka4?ref=jina-ai-gmbh.ghost.io\">Chinese/English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-rnb324fpie3n6?ref=jina-ai-gmbh.ghost.io\">Spanish/English</a></li></ul></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-tk7t7bz6fp5ng?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2 Base - Code</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-avmxk2wxbygd6?ref=jina-ai-gmbh.ghost.io\">Jina Reranker v1 Base - English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-6kxbf5xqrluf4?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina ColBERT v1 - English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-mgomngrh4c4k4?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina ColBERT Reranker v1 - English</a></li></ul><p>전체 모델 목록은 <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS Marketplace의 Jina AI 벤더 페이지</a>에서 확인할 수 있으며, 7일 무료 평가판을 이용할 수 있습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina AI</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><p>이 글에서는 Amazon SageMaker의 구성 요소만을 사용하여 <a href=\"https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/?ref=jina-ai-gmbh.ghost.io\">Retrieval-augmented generation</a>(RAG) 애플리케이션을 만드는 방법을 안내합니다. 우리가 사용할 모델은 <strong>Jina Embeddings v2 - English</strong>, <strong>Jina Reranker v1</strong>, 그리고 <a href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io\">Mistral-7B-Instruct</a> 대규모 언어 모델입니다.</p><p>Python Notebook을 통해서도 따라할 수 있으며, <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/sagemaker/sagemaker.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">다운로드</a>하거나 <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/sagemaker/sagemaker.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab에서 실행</a>할 수 있습니다.</p><h2 id=\"retrieval-augmented-generation\">Retrieval-Augmented Generation</h2><p>Retrieval-augmented generation은 생성형 AI의 대안적 패러다임입니다. 대규모 언어 모델(LLM)이 학습한 내용을 바탕으로 사용자 요청에 직접 답변하는 대신, 유창한 언어 생성 능력을 활용하면서 로직과 정보 검색을 더 적합한 외부 장치로 이전합니다.</p><p>RAG 시스템은 LLM을 호출하기 전에 외부 데이터 소스에서 관련 정보를 적극적으로 검색하여 프롬프트의 일부로 LLM에 제공합니다. LLM의 역할은 외부 정보를 사용자 요청에 대한 일관된 응답으로 합성하여 환각 위험을 최소화하고 결과의 관련성과 유용성을 높이는 것입니다.</p><p>RAG 시스템은 기본적으로 다음 네 가지 구성 요소를 가집니다:</p><ul><li>일반적으로 AI 지원 정보 검색에 적합한 벡터 데이터베이스와 같은 데이터 소스</li><li>사용자의 요청을 쿼리로 취급하여 답변에 관련된 데이터를 검색하는 정보 검색 시스템</li><li>AI 기반 재순위화 모델을 포함하여 검색된 데이터 중 일부를 선택하고 LLM용 프롬프트로 처리하는 시스템</li><li>사용자 요청과 제공된 데이터를 받아 사용자에게 응답을 생성하는 LLM(예: GPT 모델이나 Mistral과 같은 오픈소스 LLM)</li></ul><p>임베딩 모델은 정보 검색에 매우 적합하며 이러한 목적으로 자주 사용됩니다. 텍스트 임베딩 모델은 텍스트를 입력으로 받아 <a href=\"https://jina.ai/news/how-embeddings-drive-ai-a-guide?ref=jina-ai-gmbh.ghost.io\">임베딩</a>(고차원 벡터)을 출력하는데, 이 임베딩들 간의 공간적 관계가 의미적 유사성(즉, 유사한 주제, 내용 및 관련 의미)을 나타냅니다. 임베딩이 가까울수록 사용자가 응답에 만족할 가능성이 높기 때문에 정보 검색에 자주 사용되며, 특정 도메인에서의 성능을 향상시키기 위해 비교적 쉽게 미세 조정할 수 있습니다.</p><p><a href=\"https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">텍스트 재순위화</a> 모델은 유사한 AI 원리를 사용하여 텍스트 모음을 쿼리와 비교하고 의미적 유사성에 따라 정렬합니다. 임베딩 모델에만 의존하는 대신 작업별 재순위화 모델을 사용하면 검색 결과의 정확도가 크게 향상되는 경우가 많습니다. RAG 애플리케이션의 재순위화 모델은 LLM 프롬프트에 올바른 정보가 포함될 확률을 최대화하기 위해 정보 검색 결과 중 일부를 선택합니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Maximizing Search Relevance and RAG Accuracy with Jina Reranker</div><div class=\"kg-bookmark-description\">Boost your search and RAG accuracy with Jina Reranker. Our new model improves the accuracy and relevance by 20% over simple vector search. Try it now for free!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Reranker1.png\" alt=\"\"></div></a></figure><h2 id=\"benchmarking-performance-of-embedding-models-as-sagemaker-endpoints\"><strong>SageMaker 엔드포인트로서의 임베딩 모델 성능 벤치마킹</strong></h2><p>우리는 <strong>Jina Embeddings v2 Base - English</strong> 모델의 SageMaker 엔드포인트 성능과 신뢰성을 <a href=\"https://aws.amazon.com/ec2/instance-types/g4/?ref=jina-ai-gmbh.ghost.io\">g4dn.xlarge</a> 인스턴스에서 테스트했습니다. 이 실험에서는 매초마다 새로운 사용자를 지속적으로 생성하여, 각 사용자가 요청을 보내고 응답을 기다린 후 응답을 받으면 반복하도록 했습니다.</p><ul><li><em>100 토큰 미만</em>의 요청의 경우, 최대 150명의 동시 사용자까지는 요청당 응답 시간이 100ms 미만으로 유지되었습니다. 이후 동시 사용자가 증가함에 따라 응답 시간이 100ms에서 1500ms까지 선형적으로 증가했습니다.<ul><li>약 <em>300명의 동시 사용자</em>에서 API에서 5회 이상의 실패가 발생하여 테스트를 종료했습니다.</li></ul></li><li>1K에서 8K 토큰 사이의 요청의 경우, 최대 20명의 동시 사용자까지는 요청당 응답 시간이 8초 미만으로 유지되었습니다. 이후 동시 사용자가 증가함에 따라 응답 시간이 8초에서 60초까지 선형적으로 증가했습니다.<ul><li>약 <em>140명의 동시 사용자</em>에서 API에서 5회 이상의 실패가 발생하여 테스트를 종료했습니다.</li></ul></li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/image-3.png\" class=\"kg-image\" alt=\"Four comparative graphs displaying &quot;Small Context&quot; versus &quot;Large Context&quot; results over time, assessing performance metrics.\" loading=\"lazy\" width=\"2000\" height=\"1250\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/03/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/image-3.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">테스트 실행 중 성능 (왼쪽: 작은 컨텍스트, 오른쪽: 큰 컨텍스트), 시간에 따른 사용자 증가가 응답 시간과 실패율에 미치는 영향을 보여줍니다.</span></figcaption></figure><p>이러한 결과를 바탕으로, 일반적인 임베딩 워크로드를 가진 대부분의 사용자에게는 g4dn.xlarge 또는 g5.xlarge 인스턴스가 일상적인 요구를 충족시킬 수 있다고 결론 내릴 수 있습니다. 하지만 <em>검색</em> 작업보다 훨씬 덜 자주 실행되는 대규모 <em>인덱싱</em> 작업의 경우, 사용자들은 더 높은 성능의 옵션을 선호할 수 있습니다. 사용 가능한 모든 Sagemaker 인스턴스 목록은 AWS의 <a href=\"https://aws.amazon.com/ec2/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">EC2</a> 개요를 참조하세요.</p><h2 id=\"configure-your-aws-account\">AWS 계정 구성하기</h2><p>먼저, AWS 계정이 필요합니다. 아직 AWS 사용자가 아니라면, AWS 웹사이트에서 계정에 <a href=\"https://portal.aws.amazon.com/billing/signup?ref=jina-ai-gmbh.ghost.io\">가입</a>할 수 있습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://portal.aws.amazon.com/billing/signup?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Console - Signup</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://portal.aws.amazon.com/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Signup</span></div></div></a></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Amazon이 SageMaker에 대한 무료 액세스를 제공하지 않기 때문에 Free Tier 계정으로는 이 튜토리얼을 완료할 수 없습니다. <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">7일 무료 체험판</a>을 사용하더라도 Jina AI의 모델을 구독하려면 계정에 결제 수단을 추가해야 합니다.</div></div><h3 id=\"set-up-aws-tools-in-your-python-environment\">Python 환경에서 AWS 도구 설정하기</h3><p>이 튜토리얼에 필요한 AWS 도구와 라이브러리를 Python 환경에 설치하세요:</p><pre><code class=\"language-bash\">pip install awscli jina-sagemaker\n</code></pre><p>AWS 계정의 액세스 키와 시크릿 액세스 키가 필요합니다. <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?ref=jina-ai-gmbh.ghost.io\">AWS 웹사이트의 지침</a>에 따라 이를 얻을 수 있습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Managing access keys for IAM users - AWS Identity and Access Management</div><div class=\"kg-bookmark-description\">Create, modify, view, or update access keys (credentials) for programmatic calls to AWS.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.aws.amazon.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">AWS Identity and Access Management</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.aws.amazon.com/images/IAM/latest/UserGuide/images/security-credentials-user.shared.console.png\" alt=\"\"></div></a></figure><p>또한 작업할 <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html?ref=jina-ai-gmbh.ghost.io\">AWS 리전</a>을 선택해야 합니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Regions, Availability Zones, and Local Zones - Amazon Relational Database Service</div><div class=\"kg-bookmark-description\">Learn how Amazon cloud computing resources are hosted in multiple locations world-wide, including AWS Regions and Availability Zones.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.aws.amazon.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Amazon Relational Database Service</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.aws.amazon.com/images/AmazonRDS/latest/UserGuide/images/Con-AZ-Local.png\" alt=\"\"></div></a></figure><p>그런 다음 환경 변수에 값을 설정하세요. Python 또는 Python 노트북에서는 다음 코드로 설정할 수 있습니다:</p><pre><code class=\"language-bash\">import os\n\nos.environ[\"AWS_ACCESS_KEY_ID\"] = &lt;YOUR_ACCESS_KEY_ID&gt;\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = &lt;YOUR_SECRET_ACCESS_KEY&gt;\nos.environ[\"AWS_DEFAULT_REGION\"] = &lt;YOUR_AWS_REGION&gt;\nos.environ[\"AWS_DEFAULT_OUTPUT\"] = \"json\"\n</code></pre><p>기본 출력을 <code>json</code>으로 설정하세요.</p><p>이는 <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html?ref=jina-ai-gmbh.ghost.io\">AWS 명령줄 애플리케이션</a>을 통해서나 로컬 파일시스템에 <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html?ref=jina-ai-gmbh.ghost.io\">AWS 구성 파일</a>을 설정하여 수행할 수도 있습니다. 자세한 내용은 <a href=\"https://docs.aws.amazon.com/index.html?ref=jina-ai-gmbh.ghost.io\">AWS 웹사이트의 문서</a>를 참조하세요.</p><h3 id=\"create-a-role\">역할 생성하기</h3><p>이 튜토리얼에 필요한 리소스를 사용하기 위해 충분한 권한을 가진 <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html?ref=jina-ai-gmbh.ghost.io\">AWS 역할</a>도 필요합니다.</p><p>이 역할은 다음을 갖추어야 합니다:</p><ol><li><strong>AmazonSageMakerFullAccess</strong>가 활성화되어 있어야 함</li><li>다음 중 하나:<ol><li>AWS Marketplace 구독을 할 수 있는 권한이 있고 다음 세 가지가 모두 활성화되어 있어야 함:<ol><li><strong>aws-marketplace:ViewSubscriptions</strong></li><li><strong>aws-marketplace:Unsubscribe</strong></li><li><strong>aws-marketplace:Subscribe</strong></li></ol></li><li>또는 AWS 계정이 <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">jina-embedding-model</a>을 구독하고 있어야 함</li></ol></li></ol><p>역할의 ARN(<a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference-arns.html?ref=jina-ai-gmbh.ghost.io\">Amazon Resource Name</a>)을 <code>role</code> 변수에 저장하세요:</p><pre><code class=\"language-python\">role = &lt;YOUR_ROLE_ARN&gt;\n</code></pre><p>자세한 내용은 AWS 웹사이트의 역할 관련 문서를 참조하세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">IAM roles - AWS Identity and Access Management</div><div class=\"kg-bookmark-description\">Learn how and when to use IAM roles.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.aws.amazon.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">AWS Identity and Access Management</span></div></div></a></figure><h3 id=\"subscribe-to-jina-ai-models-on-aws-marketplace\">AWS Marketplace에서 Jina AI 모델 구독하기</h3><p>이 글에서는 Jina Embeddings v2 base English 모델을 사용할 것입니다. <a href=\"https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io\">AWS Marketplace</a>에서 이를 구독하세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v2 Base - en</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">en</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><p>페이지를 아래로 스크롤하면 가격 정보를 볼 수 있습니다. AWS는 마켓플레이스의 모델에 대해 시간당 요금을 부과하므로, 모델 엔드포인트를 시작한 시점부터 중지할 때까지의 시간에 대해 청구됩니다. 이 글에서는 두 가지 방법 모두를 보여드릴 것입니다.</p><p>또한 구독이 필요한 Jina Reranker v1 - English 모델도 사용할 것입니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-avmxk2wxbygd6?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Reranker v1 Base - en</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">en</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Jina AI는 현재 모델에 대해 7일간의 무료 체험을 제공하고 있습니다. 모델을 실행하는 AWS 인스턴스에 대한 비용은 지불해야 하지만, 체험 기간 동안에는 모델에 대한 추가 비용을 지불할 필요가 없습니다.</div></div><p>구독하신 후에는 AWS 리전에 대한 모델의 ARN을 얻어서 <code>embedding_package_arn</code>과 <code>reranker_package_arn</code> 변수 이름으로 저장하시면 됩니다. 이 튜토리얼의 코드는 이러한 변수 이름을 참조할 것입니다.</p><p>ARN을 얻는 방법을 모르시는 경우, Amazon 리전 이름을 <code>region</code> 변수에 넣고 다음 코드를 사용하세요:</p><pre><code class=\"language-python\">region = os.environ[\"AWS_DEFAULT_REGION\"]\n\ndef get_arn_for_model(region_name, model_name):\n    model_package_map = {\n        \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:253352124568:model-package/{model_name}\",\n        \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:model-package/{model_name}\",\n        \"us-west-1\": f\"arn:aws:sagemaker:us-west-1:382657785993:model-package/{model_name}\",\n        \"us-west-2\": f\"arn:aws:sagemaker:us-west-2:594846645681:model-package/{model_name}\",\n        \"ca-central-1\": f\"arn:aws:sagemaker:ca-central-1:470592106596:model-package/{model_name}\",\n        \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:model-package/{model_name}\",\n        \"eu-west-1\": f\"arn:aws:sagemaker:eu-west-1:985815980388:model-package/{model_name}\",\n        \"eu-west-2\": f\"arn:aws:sagemaker:eu-west-2:856760150666:model-package/{model_name}\",\n        \"eu-west-3\": f\"arn:aws:sagemaker:eu-west-3:843114510376:model-package/{model_name}\",\n        \"eu-north-1\": f\"arn:aws:sagemaker:eu-north-1:136758871317:model-package/{model_name}\",\n        \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{model_name}\",\n        \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{model_name}\",\n        \"ap-northeast-2\": f\"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{model_name}\",\n        \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{model_name}\",\n        \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:model-package/{model_name}\",\n        \"sa-east-1\": f\"arn:aws:sagemaker:sa-east-1:270155090741:model-package/{model_name}\",\n    }\n\n    return model_package_map[region_name]\n\nembedding_package_arn = get_arn_for_model(region, \"jina-embeddings-v2-base-en\")\nreranker_package_arn = get_arn_for_model(region, \"jina-reranker-v1-base-en\")\n</code></pre><h2 id=\"load-the-dataset\">데이터셋 로드하기</h2><p>이 튜토리얼에서는 YouTube 채널 <a href=\"https://www.youtube.com/@tudelftonlinelearning1226?ref=jina-ai-gmbh.ghost.io\">TU Delft Online Learning</a>에서 제공하는 비디오 컬렉션을 사용할 것입니다. 이 채널은 STEM 과목에 대한 다양한 교육 자료를 제작합니다. 프로그래밍은 <a href=\"https://creativecommons.org/licenses/by/3.0/legalcode?ref=jina-ai-gmbh.ghost.io\">CC-BY 라이선스</a>를 따릅니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.youtube.com/@tudelftonlinelearning1226?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">TU Delft Online Learning</div><div class=\"kg-bookmark-description\">과학, 디자인 또는 엔지니어링 분야에서 경력을 쌓고 싶으신가요? 그렇다면 TU Delft의 온라인 학습자 커뮤니티에 참여하세요!\nTU Delft에서 온라인 학습은 능동적 학습을 의미합니다. 우리의 강좌들은 여러분에게 매력적인 학습 경험을 제공하도록 설계되었습니다. 강좌 내용은 도전적이고 까다로우며, 개인적 성장과 전문성 개발을 촉진하면서도 온라인 강좌가 제공하는 유연성과 접근성을 통해 삶의 다른 우선순위들과 학습을 병행할 수 있도록 합니다. 오늘 학습을 시작하세요: https://online-learning.tud…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.youtube.com/s/desktop/4feff1e2/img/favicon_144x144.png\" alt=\"\"><span class=\"kg-bookmark-author\">YouTube</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://yt3.googleusercontent.com/ytc/AIdro_kH5d18Xqqj-MKv9k_tf2KNFufCpMY8qEXdQzEy=s900-c-k-c0x00ffffff-no-rj\" alt=\"\"></div></a></figure><p>우리는 이 채널에서 193개의 비디오를 다운로드하여 OpenAI의 오픈소스 <a href=\"https://openai.com/research/whisper?ref=jina-ai-gmbh.ghost.io\">Whisper 음성 인식 모델</a>로 처리했습니다. 가장 작은 모델인 <a href=\"https://huggingface.co/openai/whisper-tiny?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>openai/whisper-tiny</code></a>를 사용하여 비디오를 텍스트로 변환했습니다.</p><p>변환된 텍스트는 CSV 파일로 정리되어 있으며, <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/sagemaker/tu_delft.csv?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">여기서 다운로드</a>할 수 있습니다.</p><p>파일의 각 행에는 다음이 포함되어 있습니다:</p><ul><li>비디오 제목</li><li>YouTube 비디오 URL</li><li>비디오의 텍스트 변환본</li></ul><p>Python에서 이 데이터를 로드하려면 먼저 <code>pandas</code>와 <code>requests</code>를 설치하세요:</p><pre><code class=\"language-bash\">pip install requests pandas\n</code></pre><p>CSV 데이터를 직접 <code>tu_delft_dataframe</code>이라는 Pandas DataFrame으로 로드하세요:</p><pre><code class=\"language-python\">import pandas\n\n# Load the CSV file\ntu_delft_dataframe = pandas.read_csv(\"https://raw.githubusercontent.com/jina-ai/workshops/feat-sagemaker-post/notebooks/embeddings/sagemaker/tu_delft.csv\")\n</code></pre><p>DataFrame의 <code>head()</code> 메서드를 사용하여 내용을 확인할 수 있습니다. 노트북에서는 다음과 같이 표시될 것입니다:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Screenshot-2024-03-15-at-14.30.35.png\" class=\"kg-image\" alt=\"&quot;Green Teams in Hospitals&quot;와 같은 웨비나 제목, YouTube URL, 소개 텍스트 발췌문을 보여주는 데이터 프레임\" loading=\"lazy\" width=\"1440\" height=\"580\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Screenshot-2024-03-15-at-14.30.35.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Screenshot-2024-03-15-at-14.30.35.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Screenshot-2024-03-15-at-14.30.35.png 1440w\" sizes=\"(min-width: 720px) 720px\"></figure><p>이 데이터셋에 주어진 URL을 사용하여 비디오를 시청할 수도 있으며, 음성 인식이 완벽하지는 않지만 기본적으로 정확하다는 것을 확인할 수 있습니다.</p><h2 id=\"start-the-jina-embeddings-v2-endpoint\">Jina Embeddings v2 엔드포인트 시작하기</h2><p>아래 코드는 임베딩 모델을 실행하기 위해 AWS에서 <code>ml.g4dn.xlarge</code> 인스턴스를 시작할 것입니다. 이 작업이 완료되는 데 몇 분이 걸릴 수 있습니다.</p><pre><code class=\"language-python\">import boto3\nfrom jina_sagemaker import Client\n\n# Choose a name for your embedding endpoint. It can be anything convenient.\nembeddings_endpoint_name = \"jina_embedding\"\n\nembedding_client = Client(region_name=boto3.Session().region_name)\nembedding_client.create_endpoint(\n    arn=embedding_package_arn,\n    role=role,\n    endpoint_name=embeddings_endpoint_name,\n    instance_type=\"ml.g4dn.xlarge\",\n    n_instances=1,\n)\n\nembedding_client.connect_to_endpoint(endpoint_name=embeddings_endpoint_name)\n</code></pre><p>필요한 경우 <code>instance_type</code>을 변경하여 다른 AWS 클라우드 인스턴스 유형을 선택할 수 있습니다.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">이 명령이 반환되는 즉시 AWS는 과금을 시작합니다. 이 인스턴스를 중지할 때까지 시간당 요금이 청구됩니다. 중지하려면 <a href=\"#shutting-down\" rel=\"noreferrer\"><b><strong style=\"white-space: pre-wrap;\">종료하기</strong></b></a> 섹션의 지침을 따르세요.</div></div><h2 id=\"build-and-index-the-dataset\">데이터셋 구축 및 인덱싱</h2><p>이제 데이터를 로드하고 Jina Embeddings v2 모델을 실행하고 있으므로, 데이터를 준비하고 인덱싱할 수 있습니다. 데이터는 AI 애플리케이션을 위해 특별히 설계된 오픈소스 벡터 데이터베이스인 <a href=\"https://faiss.ai/index.html?ref=jina-ai-gmbh.ghost.io\">FAISS 벡터 스토어</a>에 저장할 것입니다.</p><p>먼저 RAG 애플리케이션에 필요한 나머지 필수 패키지들을 설치하세요:</p><pre><code class=\"language-bash\">pip install tdqm numpy faiss-cpu\n</code></pre><h3 id=\"chunking\">청킹</h3><p>LLM의 프롬프트에 여러 텍스트를 맞출 수 있도록 개별 텍스트를 더 작은 부분, 즉 \"청크\"로 나눌 필요가 있습니다. 아래 코드는 문장 경계를 기준으로 개별 텍스트를 나누며, 기본적으로 모든 청크가 128단어를 넘지 않도록 합니다.</p><pre>Note: The code blocks below retain their original English/code content as per translation guidelines.\n\n<code class=\"language-python\">def chunk_text(text, max_words=128):\n    \"\"\"\n    Divide text into chunks where each chunk contains the maximum number \n    of full sentences with fewer words than `max_words`.\n    \"\"\"\n    sentences = text.split(\".\")\n    chunk = []\n    word_count = 0\n\n    for sentence in sentences:\n        sentence = sentence.strip(\".\")\n        if not sentence:\n          continue\n\n        words_in_sentence = len(sentence.split())\n        if word_count + words_in_sentence &lt;= max_words:\n            chunk.append(sentence)\n            word_count += words_in_sentence\n        else:\n            # Yield the current chunk and start a new one\n            if chunk:\n              yield \". \".join(chunk).strip() + \".\"\n            chunk = [sentence]\n            word_count = words_in_sentence\n\n    # Yield the last chunk if it's not empty\n    if chunk:\n        yield \" \".join(chunk).strip() + \".\"</code></pre><h3 id=\"get-embeddings-for-each-chunk\">각 청크의 임베딩 가져오기</h3><p>FAISS 데이터베이스에 저장하기 위해 각 청크의 임베딩이 필요합니다. 이를 위해 텍스트 청크를 Jina AI 임베딩 모델 엔드포인트에 <code>embedding_client.embed()</code> 메서드를 사용하여 전달합니다. 그런 다음 텍스트 청크와 임베딩 벡터를 pandas 데이터프레임 <code>tu_delft_dataframe</code>에 <code>chunks</code>와 <code>embeddings</code>라는 새로운 열로 추가합니다:</p><pre><code class=\"language-python\">import numpy as np\nfrom tqdm import tqdm\n\ntqdm.pandas()\n\ndef generate_embeddings(text_df):\n    chunks = list(chunk_text(text_df[\"Text\"]))\n    embeddings = []\n\n    for i, chunk in enumerate(chunks):\n      response = embedding_client.embed(texts=[chunk])\n      chunk_embedding = response[0][\"embedding\"]\n      embeddings.append(np.array(chunk_embedding))\n\n    text_df[\"chunks\"] = chunks\n    text_df[\"embeddings\"] = embeddings\n    return text_df\n\nprint(\"Embedding text chunks ...\")\ntu_delft_dataframe = generate_embeddings(tu_delft_dataframe)\n## Google Colab이나 Python 노트북을 사용하는 경우\n## 위 줄을 삭제하고 다음 줄의 주석을 해제하세요:\n# tu_delft_dataframe = tu_delft_dataframe.progress_apply(generate_embeddings, axis=1)\n</code></pre><h3 id=\"set-up-semantic-search-using-faiss\">Faiss를 사용한 의미 검색 설정</h3><p>아래 코드는 FAISS 데이터베이스를 생성하고 <code>tu_delft_pandas</code>를 반복하여 청크와 임베딩 벡터를 삽입합니다:</p><pre><code class=\"language-python\">import faiss\n\ndim = 768  # Jina v2 임베딩의 차원\nindex_with_ids = faiss.IndexIDMap(faiss.IndexFlatIP(dim))\nk = 0\n\ndoc_ref = dict()\n\nfor idx, row in tu_delft_dataframe.iterrows():\n    embeddings = row[\"embeddings\"]\n    for i, embedding in enumerate(embeddings):\n        normalized_embedding = np.ascontiguousarray(np.array(embedding, dtype=\"float32\").reshape(1, -1))\n        faiss.normalize_L2(normalized_embedding)\n        index_with_ids.add_with_ids(normalized_embedding, k)\n        doc_ref[k] = (row[\"chunks\"][i], idx)\n        k += 1\n</code></pre><h2 id=\"start-the-jina-reranker-v1-endpoint\">Jina Reranker v1 엔드포인트 시작</h2><p>위의 Jina Embedding v2 모델과 마찬가지로, 이 코드는 AWS에서 리랭커 모델을 실행하기 위해 <code>ml.g4dn.xlarge</code> 인스턴스를 시작합니다. 마찬가지로 실행하는 데 몇 분이 걸릴 수 있습니다.</p><pre><code class=\"language-python\">import boto3\nfrom jina_sagemaker import Client\n\n# 리랭커 엔드포인트의 이름을 선택하세요. 편리한 이름이면 됩니다.\nreranker_endpoint_name = \"jina_reranker\"\n\nreranker_client = Client(region_name=boto3.Session().region_name)\nreranker_client.create_endpoint(\n    arn=reranker_package_arn,\n    role=role,\n    endpoint_name=reranker_endpoint_name,\n    instance_type=\"ml.g4dn.xlarge\",\n    n_instances=1,\n)\n\nreranker_client.connect_to_endpoint(endpoint_name=reranker_endpoint_name)\n</code></pre><h2 id=\"define-query-functions\">쿼리 함수 정의</h2><p>다음으로, 텍스트 쿼리와 가장 유사한 트랜스크립트 청크를 식별하는 함수를 정의하겠습니다.</p><p>이는 두 단계로 이루어진 프로세스입니다:</p><ol><li>데이터 준비 단계에서처럼 <code>embedding_client.embed()</code> 메서드를 사용하여 사용자 입력을 임베딩 벡터로 변환합니다.</li><li>임베딩을 FAISS 인덱스에 전달하여 가장 잘 매치되는 결과를 검색합니다. 아래 함수에서는 기본값으로 상위 20개의 매치를 반환하지만, <code>n</code> 매개변수로 이를 제어할 수 있습니다.</li></ol><p><code>find_most_similar_transcript_segment</code> 함수는 저장된 임베딩과 쿼리 임베딩의 코사인을 비교하여 가장 적합한 매치를 반환합니다.</p><pre><code class=\"language-python\">def find_most_similar_transcript_segment(query, n=20):\n    query_embedding = embedding_client.embed(texts=[query])[0][\"embedding\"]  # Assuming the query is short enough to not need chunking\n    query_embedding = np.ascontiguousarray(np.array(query_embedding, dtype=\"float32\").reshape(1, -1))\n    faiss.normalize_L2(query_embedding)\n\n    D, I = index_with_ids.search(query_embedding, n)  # Get the top n matches\n\n    results = []\n    for i in range(n):\n        distance = D[0][i]\n        index_id = I[0][i]\n        transcript_segment, doc_idx = doc_ref[index_id]\n        results.append((transcript_segment, doc_idx, distance))\n\n    # Sort the results by distance\n    results.sort(key=lambda x: x[2])\n\n    return [(tu_delft_dataframe.iloc[r[1]][\"Title\"].strip(), r[0]) for r in results]\n</code></pre><p>또한 리랭커 엔드포인트 <code>reranker_client</code>에 접근하여 <code>find_most_similar_transcript_segment</code>의 결과를 전달하고 가장 관련성 높은 3개의 결과만 반환하는 함수를 정의할 것입니다. 이는 <code>reranker_client.rerank()</code> 메서드로 리랭커 엔드포인트를 호출합니다.</p><pre><code class=\"language-python\">def rerank_results(query_found, query, n=3):\n    ret = reranker_client.rerank(\n        documents=[f[1] for f in query_found], \n        query=query, \n        top_n=n,\n    )\n    return [query_found[r['index']] for r in ret[0]['results']]\n</code></pre><h2 id=\"use-jumpstart-to-load-mistral-instruct\">JumpStart를 사용하여 Mistral-Instruct 로드하기</h2><p>이 튜토리얼에서는 RAG 시스템의 LLM 부분으로 <code>mistral-7b-instruct</code> 모델을 사용할 것입니다. 이 모델은 <a href=\"https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/?ref=jina-ai-gmbh.ghost.io\">Amazon SageMaker JumpStart를 통해 사용 가능</a>합니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Mistral 7B foundation models from Mistral AI are now available in Amazon SageMaker JumpStart | Amazon Web Services</div><div class=\"kg-bookmark-description\">Today, we are excited to announce that the Mistral 7B foundation models, developed by Mistral AI, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. With 7 billion parameters, Mistral 7B can be easily customized and quickly deployed. You can try out this model with SageMaker JumpStart, a […]</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://a0.awsstatic.com/main/images/site/touch-icon-ipad-144-smile.png\" alt=\"\"><span class=\"kg-bookmark-author\">Amazon Web Services</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/mistral-7b-sagemaker-jumpstart.jpg\" alt=\"\"></div></a></figure><p>Mistral-Instruct를 로드하고 배포하기 위해 다음 코드를 실행하세요:</p><pre><code class=\"language-python\">from sagemaker.jumpstart.model import JumpStartModel\n\njumpstart_model = JumpStartModel(model_id=\"huggingface-llm-mistral-7b-instruct\", role=role)\nmodel_predictor = jumpstart_model.deploy()\n</code></pre><p>이 LLM에 접근하기 위한 엔드포인트는 <code>model_predictor</code> 변수에 저장됩니다.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">이 모델 사용도 AWS에서 청구 가능한 서비스이므로, 이 튜토리얼을 마치면 반드시 종료하는 것을 잊지 마세요. 종료 시에는 <a href=\"#shutting-down\" rel=\"noreferrer\"><b><strong style=\"white-space: pre-wrap;\">종료하기</strong></b></a> 섹션을 참조하세요.</div></div><h3 id=\"mistral-instruct-with-jumpstart\">JumpStart의 Mistral-Instruct</h3><p>아래는 <a href=\"https://docs.python.org/3/library/string.html?ref=jina-ai-gmbh.ghost.io#template-strings\">Python의 내장 문자열 템플릿 클래스</a>를 사용하여 이 애플리케이션을 위한 Mistral-Instruct의 프롬프트 템플릿을 만드는 코드입니다. 각 쿼리마다 모델에 제시될 세 개의 매칭되는 트랜스크립트 청크가 있다고 가정합니다.</p><p>이 템플릿을 직접 실험하여 이 애플리케이션을 수정하거나 더 나은 결과를 얻을 수 있는지 확인해 볼 수 있습니다.</p><pre><code class=\"language-python\">from string import Template\n\nprompt_template = Template(\"\"\"\n  &lt;s&gt;[INST] Answer the question below only using the given context.\n  The question from the user is based on transcripts of videos from a YouTube\n    channel.\n  The context is presented as a ranked list of information in the form of\n    (video-title, transcript-segment), that is relevant for answering the\n    user's question.\n  The answer should only use the presented context. If the question cannot be\n    answered based on the context, say so.\n\n  Context:\n  1. Video-title: $title_1, transcript-segment: $segment_1\n  2. Video-title: $title_2, transcript-segment: $segment_2\n  3. Video-title: $title_3, transcript-segment: $segment_3\n\n  Question: $question\n\n  Answer: [/INST]\n\"\"\")\n</code></pre><p>이 구성 요소가 준비되면 이제 완전한 RAG 애플리케이션의 모든 부분이 갖춰졌습니다.</p><h2 id=\"querying-the-model\">모델 쿼리하기</h2><p>모델 쿼리는 세 단계로 이루어진 프로세스입니다.</p><ol><li>쿼리가 주어졌을 때 관련 청크를 검색합니다.</li><li>프롬프트를 구성합니다.</li><li>프롬프트를 Mistral-Instruct 모델에 전송하고 답변을 반환합니다.</li></ol><p>관련 청크를 검색하기 위해 위에서 정의한 <code>find_most_similar_transcript_segment</code> 함수를 사용합니다.</p><pre><code class=\"language-python\">question = \"When was the first offshore wind farm commissioned?\"\nsearch_results = find_most_similar_transcript_segment(question)\nreranked_results = rerank_results(search_results, question)\n</code></pre><p>검색 결과를 재순위화된 순서로 확인할 수 있습니다:</p><pre><code class=\"language-python\">for title, text, _ in reranked_results:\n    print(title + \"\\n\" + text + \"\\n\")\n</code></pre><p>결과:</p><pre><code class=\"language-text\">Offshore Wind Farm Technology - Course Introduction\nSince the first offshore wind farm commissioned in 1991 in Denmark, scientists and engineers have adapted and improved the technology of wind energy to offshore conditions.  This is a rapidly evolving field with installation of increasingly larger wind turbines in deeper waters.  At sea, the challenges are indeed numerous, with combined wind and wave loads, reduced accessibility and uncertain-solid conditions.  My name is Axel Vire, I'm an assistant professor in Wind Energy at U-Delf and specializing in offshore wind energy.  This course will touch upon the critical aspect of wind energy, how to integrate the various engineering disciplines involved in offshore wind energy.  Each week we will focus on a particular discipline and use it to design and operate a wind farm.\n\nOffshore Wind Farm Technology - Course Introduction\nI'm a researcher and lecturer at the Wind Energy and Economics Department and I will be your moderator throughout this course.  That means I will answer any questions you may have.  I'll strengthen the interactions between the participants and also I'll get you in touch with the lecturers when needed.  The course is mainly developed for professionals in the field of offshore wind energy.  We want to broaden their knowledge of the relevant technical disciplines and their integration.  Professionals with a scientific background who are new to the field of offshore wind energy will benefit from a high-level insight into the engineering aspects of wind energy.  Overall, the course will help you make the right choices during the development and operation of offshore wind farms.\n\nOffshore Wind Farm Technology - Course Introduction\nDesigned wind turbines that better withstand wind, wave and current loads  Identify great integration strategies for offshore wind turbines and gain understanding of the operational and maintenance of offshore wind turbines and farms  We also hope that you will benefit from the course and from interaction with other learners who share your interest in wind energy  And therefore we look forward to meeting you online.\n</code></pre><p>이 정보를 프롬프트 템플릿에 직접 사용할 수 있습니다:</p><pre><code class=\"language-python\">prompt_for_llm = prompt_template.substitute(\n    question = question,\n    title_1 = search_results[0][0],\n    segment_1 = search_results[0][1],\n    title_2 = search_results[1][0],\n    segment_2 = search_results[1][1],\n    title_3 = search_results[2][0],\n    segment_3 = search_results[2][1],\n)\n</code></pre><p>LLM에 실제로 전송되는 프롬프트를 확인하기 위해 결과 문자열을 출력합니다:</p><pre><code class=\"language-python\">print(prompt_for_llm)\n</code></pre><pre><code class=\"language-text\">&lt;s&gt;[INST] Answer the question below only using the given context.\n  The question from the user is based on transcripts of videos from a YouTube\n    channel.\n  The context is presented as a ranked list of information in the form of\n    (video-title, transcript-segment), that is relevant for answering the\n    user's question.\n  The answer should only use the presented context. If the question cannot be\n    answered based on the context, say so.\n\n  Context:\n  1. Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: Since the first offshore wind farm commissioned in 1991 in Denmark, scientists and engineers have adapted and improved the technology of wind energy to offshore conditions.  This is a rapidly evolving field with installation of increasingly larger wind turbines in deeper waters.  At sea, the challenges are indeed numerous, with combined wind and wave loads, reduced accessibility and uncertain-solid conditions.  My name is Axel Vire, I'm an assistant professor in Wind Energy at U-Delf and specializing in offshore wind energy.  This course will touch upon the critical aspect of wind energy, how to integrate the various engineering disciplines involved in offshore wind energy.  Each week we will focus on a particular discipline and use it to design and operate a wind farm.\n  2. Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: For example, we look at how to characterize the wind and wave conditions at a given location.  How to best place the wind turbines in a farm and also how to retrieve the electricity back to shore.  We look at the main design drivers for offshore wind turbines and their components.  We'll see how these aspects influence one another and the best choices to reduce the cost of energy.  This course is organized by the two-delfd wind energy institute, an interfaculty research organization focusing specifically on wind energy.  You will therefore benefit from the expertise of the lecturers in three different faculties of the university.  Aerospace engineering, civil engineering and electrical engineering.  Hi, my name is Ricardo Pareda.\n  3. Video-title: Systems Analysis for Problem Structuring part 1B the mono actor perspective example, transcript-segment: So let's assume the demarcation of the problem and the analysis of objectives has led to the identification of three criteria.  The security of supply, the percentage of offshore power generation and the costs of energy provision.  We now reason backwards to explore what factors have an influence on these system outcomes.  Really, the offshore percentage is positively influenced by the installed Wind Power capacity at sea, a key system factor.  Capacity at sea in turn is determined by both the size and the number of wind farms at sea.  The Ministry of Economic Affairs cannot itself invest in new wind farms but hopes to simulate investors and energy companies by providing subsidies and by expediting the granting process of licenses as needed.\n\n  Question: When was the first offshore wind farm commissioned?\n\n  Answer: [/INST]\n</code></pre><p>이 프롬프트를 <code>model_predictor</code> 메서드 <code>model_predictor.predict()</code>를 통해 LLM 엔드포인트에 전달합니다:</p><pre><code class=\"language-python\">answer = model_predictor.predict({\"inputs\": prompt_for_llm})\n</code></pre><p>이는 리스트를 반환하지만, 하나의 프롬프트만 전달했으므로 하나의 항목만 있는 리스트가 됩니다. 각 항목은 <code>generated_text</code> 키 아래에 응답 텍스트가 있는 <code>dict</code>입니다:</p><pre><code class=\"language-python\">answer = answer[0]['generated_text']\nprint(answer)\n</code></pre><p>결과:</p><pre><code class=\"language-text\">The first offshore wind farm was commissioned in 1991. (Context: Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: Since the first offshore wind farm commissioned in 1991 in Denmark, ...)\n</code></pre><p>문자열 질문을 매개변수로 받아 답변을 문자열로 반환하는 함수를 작성하여 쿼리를 단순화해 보겠습니다:</p><pre><code class=\"language-python\">def ask_rag(question):\n    search_results = find_most_similar_transcript_segment(question)\n    reranked_results = rerank_results(search_results, question)\n    prompt_for_llm = prompt_template.substitute(\n        question = question,\n        title_1 = search_results[0][0],\n        segment_1 = search_results[0][1],\n        title_2 = search_results[1][0],\n        segment_2 = search_results[1][1],\n        title_3 = search_results[2][0],\n        segment_3 = search_results[2][1],\n    )\n    answer = model_predictor.predict({\"inputs\": prompt_for_llm})\n    return answer[0][\"generated_text\"]\n</code></pre><p>이제 몇 가지 질문을 더 해볼 수 있습니다. 답변은 비디오 트랜스크립트의 내용에 따라 달라집니다. 예를 들어, 데이터에 답이 있는 경우 자세한 질문을 할 수 있습니다:</p><pre><code class=\"language-python\">ask_rag(\"What is a Kaplan Meyer estimator?\")\n</code></pre><pre><code class=\"language-text\">The Kaplan Meyer estimator is a non-parametric estimator for the survival \nfunction, defined for both censored and not censored data. It is represented \nas a series of declining horizontal steps that approaches the truths of the \nsurvival function if the sample size is sufficiently large enough. The value \nof the empirical survival function obtained is assumed to be constant between \ntwo successive distinct observations.\n</code></pre><pre><code class=\"language-python\">ask_rag(\"Who is Reneville Solingen?\")\n</code></pre><pre><code class=\"language-text\">Reneville Solingen is a professor at Delft University of Technology in Global \nSoftware Engineering. She is also a co-author of the book \"The Power of Scrum.\"\n</code></pre><pre><code class=\"language-python\">answer = ask_rag(\"What is the European Green Deal?\")\nprint(answer)\n</code></pre><pre><code class=\"language-text\">The European Green Deal is a policy initiative by the European Union to combat \nclimate change and decarbonize the economy, with a goal to make Europe carbon \nneutral by 2050. It involves the use of green procurement strategies in various \nsectors, including healthcare, to reduce carbon emissions and promote corporate \nsocial responsibility.\n</code></pre><p>또한 사용 가능한 정보의 범위를 벗어나는 질문도 할 수 있습니다:</p><pre><code class=\"language-python\">ask_rag(\"What countries export the most coffee?\")\n</code></pre><pre><code class=\"language-text\">Based on the context provided, there is no clear answer to the user's \nquestion about which countries export the most coffee as the context \nonly discusses the Delft University's cafeteria discounts and sustainable \ncoffee options, as well as lithium production and alternatives for use in \nelectric car batteries.\n</code></pre><pre><code class=\"language-python\">ask_rag(\"How much wood could a woodchuck chuck if a woodchuck could chuck wood?\")\n</code></pre><pre><code class=\"language-text\">The context does not provide sufficient information to answer the question. \nThe context is about thermit welding of rails, stress concentration factors, \nand a lyrics video. There is no mention of woodchucks or the ability of \nwoodchuck to chuck wood in the context.\n</code></pre><p>직접 쿼리를 시도해보세요. 또한 결과를 개선하기 위해 LLM 프롬프트 방식을 변경할 수도 있습니다.</p><h2 id=\"shutting-down\">종료하기</h2><p>사용하는 모델과 AWS 인프라에 대해 시간당 요금이 청구되므로, 이 튜토리얼을 마치면 세 가지 AI 모델을 모두 중지하는 것이 매우 중요합니다:</p><ul><li>임베딩 모델 엔드포인트 <code>embedding_client</code></li><li>재순위화 모델 엔드포인트 <code>reranker_client</code></li><li>대규모 언어 모델 엔드포인트 <code>model_predictor</code></li></ul><p>세 가지 모델 엔드포인트를 모두 종료하려면 다음 코드를 실행하세요:</p><pre><code class=\"language-python\"># shut down the embedding endpoint\nembedding_client.delete_endpoint()\nembedding_client.close()\n# shut down the reranker endpoint\nreranker_client.delete_endpoint()\nreranker_client.close()\n# shut down the LLM endpoint\nmodel_predictor.delete_model()\nmodel_predictor.delete_endpoint()\n</code></pre><h2 id=\"get-started-now-with-jina-ai-models-on-aws-marketplace\">AWS Marketplace에서 Jina AI 모델로 시작하세요</h2><p>SageMaker의 임베딩 및 재순위화 모델을 통해 AWS의 엔터프라이즈 AI 사용자는 이제 기존 클라우드 운영의 이점을 훼손하지 않고 Jina AI의 뛰어난 가치 제안에 즉시 접근할 수 있습니다. AWS의 모든 보안, 신뢰성, 일관성 및 예측 가능한 가격이 기본으로 제공됩니다.</p><p>Jina AI에서는 기존 프로세스에 AI를 도입하여 혜택을 얻을 수 있는 기업에 최첨단 기술을 제공하기 위해 노력하고 있습니다. 우리는 AI에 대한 투자를 최소화하고 수익을 극대화하면서, 편리하고 실용적인 인터페이스를 통해 합리적인 가격으로 안정적이고 고성능의 모델을 제공하기 위해 노력합니다.</p><p>우리가 제공하는 모든 임베딩 및 재순위화 모델 목록을 보고 7일 동안 무료로 시험해보려면 <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">Jina AI의 AWS Marketplace 페이지</a>를 확인하세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina AI</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><p>여러분의 사용 사례를 듣고 Jina AI의 제품이 비즈니스 요구사항에 어떻게 부합하는지 논의하고 싶습니다. <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\">웹사이트</a>나 <a href=\"https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io\">Discord 채널</a>을 통해 연락하시어 피드백을 공유하고 최신 모델 소식을 받아보세요.</p>",
  "comment_id": "65fabb91502fd000011c667e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Blog-images--27-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-03-20T11:33:53.000+01:00",
  "updated_at": "2024-03-25T19:10:29.000+01:00",
  "published_at": "2024-03-25T16:00:51.000+01:00",
  "custom_excerpt": "Learn to use Jina Embeddings and Reranking models in a full-stack AI application on AWS, using only components available in Amazon SageMaker and the AWS Marketplace.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    },
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker/",
  "excerpt": "Amazon SageMaker와 AWS Marketplace에서 사용 가능한 구성 요소만을 사용하여 AWS 상의 풀스택 AI 애플리케이션에서 Jina Embeddings와 Reranking 모델을 사용하는 방법을 알아보세요.",
  "reading_time": 21,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract image with colorful wavy background featuring AWS, Embeddings, and Reranker logos.",
  "feature_image_caption": null
}