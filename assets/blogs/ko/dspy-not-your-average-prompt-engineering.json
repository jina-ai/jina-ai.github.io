{
  "slug": "dspy-not-your-average-prompt-engineering",
  "id": "66077bf0a5c39b0001044181",
  "uuid": "e242c77c-f712-462c-9745-3e9269eb8a8b",
  "title": "DSPy: 평범하지 않은 프롬프트 엔지니어링",
  "html": "<div class=\"kg-card kg-file-card\"><a class=\"kg-file-card-container\" href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/04/DSPy-Not-Your-Average-Prompt-Engineering--1-.pdf\" title=\"Download\" download=\"\"><div class=\"kg-file-card-contents\"><div class=\"kg-file-card-title\">[슬라이드] DSPy: 평범하지 않은 프롬프트 엔지니어링</div><div class=\"kg-file-card-caption\">2024년 4월 15일 Mountain View에서 Han이 진행한 프레젠테이션입니다.</div><div class=\"kg-file-card-metadata\"><div class=\"kg-file-card-filename\">DSPy Not Your Average Prompt Engineering (1).pdf</div><div class=\"kg-file-card-filesize\">7 MB</div></div></div><div class=\"kg-file-card-icon\"><svg viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"></polyline><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"></line><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"></circle></svg></div></a></div><p>최근 Stanford NLP 그룹이 개발한 언어 모델(LM) 프롬프트를 알고리즘적으로 최적화하는 최신 프레임워크인 DSPy를 살펴보았습니다. 지난 3일 동안 DSPy에 대한 초기 인상과 귀중한 통찰을 얻었습니다. 제 관찰은 DSPy의 공식 문서를 대체하지 않습니다. 실제로 이 게시물을 자세히 살펴보기 전에 <a href=\"https://dspy-docs.vercel.app/?ref=jina-ai-gmbh.ghost.io\">그들의 문서</a>와 <a href=\"https://github.com/stanfordnlp/dspy/blob/main/README.md?ref=jina-ai-gmbh.ghost.io\">README</a>를 한 번 읽어보시는 것을 강력히 권장합니다. 여기서의 논의는 DSPy의 기능을 며칠 동안 탐색한 초기 이해를 반영합니다. DSPy Assertions, Typed Predictor, LM 가중치 튜닝과 같은 여러 고급 기능은 아직 자세히 살펴보지 못했습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/stanfordnlp/dspy?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - stanfordnlp/dspy: DSPy: The framework for programming—not prompting—foundation models</div><div class=\"kg-bookmark-description\">DSPy: The framework for programming—not prompting—foundation models - stanfordnlp/dspy</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">stanfordnlp</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/b8c1b2b4b3ff9c22d486f5c69dbda5fee6cc8dda8a42aaf1c2e154c17b7dc159/stanfordnlp/dspy\" alt=\"\"></div></a></figure><p>Jina AI에서 주로 검색 기반을 다루는 제 배경에도 불구하고, DSPy에 대한 제 관심은 Retrieval-Augmented Generation (RAG)의 잠재력에서 직접적으로 비롯된 것이 아닙니다. 대신 일부 생성 작업을 해결하기 위해 자동 프롬프트 튜닝에 DSPy를 활용할 수 있는 가능성에 관심이 있었습니다.</p><p>DSPy를 처음 접하시는 분이나, 프레임워크에 익숙하지만 공식 문서가 혼란스럽거나 부담스럽게 느껴지시는 분들을 위한 글입니다. 또한 초보자에게 부담스러울 수 있는 DSPy의 관용구를 엄격히 따르지 않기로 했습니다. 그럼 더 자세히 살펴보겠습니다.</p><h2 id=\"what-i-like-about-dspy\">DSPy에서 좋아하는 점</h2><h3 id=\"dspy-closing-the-loop-of-prompt-engineering\">DSPy가 프롬프트 엔지니어링의 순환 고리를 닫다</h3><p>DSPy에서 가장 흥미로운 점은 프롬프트 엔지니어링 주기의 순환 고리를 닫는 접근 방식입니다. <em>수동적</em>이고 <em>수작업</em>인 프로세스를 데이터셋 준비, 모델 정의, 훈련, 평가, 테스트와 같은 <em>구조화</em>되고 <em>잘 정의된</em> 기계 학습 워크플로우로 변환합니다. <strong>이것이 제가 생각하는 DSPy의 가장 혁신적인 측면입니다.</strong></p><p>Bay Area를 여행하며 LLM 평가에 초점을 맞춘 많은 스타트업 창업자들과 이야기를 나누면서, 메트릭, 환각, 관찰 가능성, 규정 준수에 대한 논의를 자주 접했습니다. 하지만 이러한 대화는 종종 중요한 다음 단계로 나아가지 못합니다: <strong>이러한 모든 메트릭을 가지고 우리는 다음에 무엇을 해야 할까요?</strong> 특정 마법의 단어들(예: \"내 할머니가 돌아가시고 있어요\")이 메트릭을 향상시킬 수 있다는 희망으로 프롬프트의 문구를 수정하는 것이 전략적 접근이라고 할 수 있을까요? 이 질문은 많은 LLM 평가 스타트업들이 답하지 못했고, DSPy를 발견하기 전까지는 저도 해결할 수 없었습니다. DSPy는 특정 메트릭을 기반으로 프롬프트를 최적화하거나, 프롬프트와 LLM 가중치를 모두 포함하는 전체 LLM 파이프라인을 최적화하는 명확하고 프로그래매틱한 방법을 소개합니다.</p><p>LangChain의 CEO인 Harrison과 전 OpenAI 개발자 관계 책임자인 Logan은 <a href=\"https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924?ref=jina-ai-gmbh.ghost.io\">Unsupervised Learning Podcast</a>에서 2024년이 LLM 평가의 중요한 전환점이 될 것이라고 말했습니다. 이러한 이유로 DSPy가 현재보다 더 많은 관심을 받아야 한다고 생각합니다. DSPy는 퍼즐의 중요한 누락된 조각을 제공하기 때문입니다.</p><h3 id=\"dspy-separating-logic-from-textual-representation\">DSPy가 로직을 텍스트 표현에서 분리하다</h3><p>DSPy의 또 다른 인상적인 점은 프롬프트 엔지니어링을 재현 가능하고 LLM에 구애받지 않는 모듈로 공식화한다는 것입니다. 이를 위해 <strong>프롬프트에서 로직을 추출하여 <em>로직</em>과 <em>텍스트 표현</em> 사이의 명확한 관심사 분리를 만듭니다</strong>. 아래 그림과 같습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png\" class=\"kg-image\" alt=\"Flowchart depicting sentiment analysis process with steps such as Prompt, Logic, and Textual Representation on a black backgr\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--5-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--5-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">DSPy에서 프롬프트는 본질적인 로직(즉, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>dspy.Module</span></code><span style=\"white-space: pre-wrap;\">,)과 그것의 텍스트 표현으로 구성됩니다. 로직은 불변하고, 재현 가능하며, 테스트 가능하고 LLM에 구애받지 않습니다. 텍스트 표현은 단지 로직의 결과일 뿐입니다.</span></figcaption></figure><p><strong>로직을 불변하고, 테스트 가능하며, LLM에 구애받지 않는 \"원인\"으로, 텍스트 표현을 단순히 그것의 \"결과\"로 보는 DSPy의 개념</strong>은 처음에는 이해하기 어려울 수 있습니다. 특히 \"프로그래밍 언어의 미래는 자연어\"라는 널리 퍼진 믿음을 고려할 때 더욱 그렇습니다. \"프롬프트 엔지니어링이 미래\"라는 아이디어를 받아들이면, DSPy의 설계 철학을 마주했을 때 혼란스러울 수 있습니다. 단순화될 것이라는 기대와는 반대로, DSPy는 자연어 프롬프팅을 C 프로그래밍의 복잡성으로 되돌리는 것처럼 보이는 다양한 모듈과 시그니처 구문을 도입합니다!</p><p>하지만 왜 이런 접근 방식을 취할까요? 제가 이해하기로는 <strong>프롬프트 프로그래밍의 핵심에는 핵심 로직이 있고, 커뮤니케이션은 증폭기 역할</strong>을 하여 그 효과를 향상시키거나 감소시킬 수 있습니다. <code>\"감정 분류를 수행하라\"</code>는 지시는 핵심 로직을 나타내는 반면, <code>\"이 예시들을 따르지 않으면 해고하겠다\"</code>와 같은 문구는 그것을 전달하는 한 가지 방법입니다. 실제 상호작용과 마찬가지로, 일을 처리하는 데 어려움을 겪는 것은 종종 로직의 결함이 아닌 문제가 있는 커뮤니케이션에서 비롯됩니다. 이것이 많은 사람들, 특히 비원어민들이 프롬프트 엔지니어링을 어려워하는 이유를 설명합니다. 우리 회사의 매우 유능한 소프트웨어 엔지니어들이 로직의 부족이 아닌 \"분위기를 말하지\" 못하기 때문에 프롬프트 엔지니어링에 어려움을 겪는 것을 보았습니다. 로직을 프롬프트에서 분리함으로써, <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/modules?ref=jina-ai-gmbh.ghost.io\">DSPy는 <code>dspy.Module</code>을 통해 로직의 결정론적 프로그래밍을 가능</code>하게 하여</a>, 개발자들이 사용하는 LLM에 관계없이 전통적인 엔지니어링에서처럼 로직에 집중할 수 있게 합니다.</p><p>그렇다면 개발자들이 로직에 집중한다면 누가 텍스트 표현을 관리할까요? <strong>DSPy가 이 역할을 맡아 여러분의 데이터와 평가 메트릭을 사용하여 텍스트 표현을 개선합니다</strong>—내러티브 초점 결정부터 힌트 최적화, 좋은 예시 선택까지 모든 것을 포함합니다. 놀랍게도 DSPy는 평가 메트릭을 사용하여 LLM 가중치도 미세 조정할 수 있습니다!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png\" class=\"kg-image\" alt=\"Flowchart illustrating a language model with branches for training data, logic, textual representation, and final results.\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>제게 DSPy의 주요 기여—프롬프트 엔지니어링에서 훈련과 평가의 순환 고리를 닫고 로직을 텍스트 표현에서 분리하는 것—는 LLM/Agent 시스템에 대한 잠재적 중요성을 강조합니다. 분명히 야심찬 비전이지만, 확실히 필요한 것입니다!</p><h2 id=\"what-i-think-dspy-can-improve\">DSPy가 개선할 수 있다고 생각하는 점</h2><p>첫째, DSPy는 관용구 때문에 초보자에게 가파른 학습 곡선을 제시합니다. <code>signature</code>, <code>module</code>, <code>program</code>, <code>teleprompter</code>, <code>optimization</code>, <code>compile</code>와 같은 용어들이 부담스러울 수 있습니다. 프롬프트 엔지니어링에 능숙한 사람들조차도 DSPy 내에서 이러한 개념들을 탐색하는 것이 어려운 미로가 될 수 있습니다.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">네, DSPy는 정말 전문 용어 없이 모든 것을 설명할 수 있는 누군가가 필요합니다. <a href=\"https://twitter.com/CShorten30?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">@CShorten30</a>가 훌륭한 일을 하고 있지만, 우리는 더 많은 것이 필요합니다.</p>— Jonathan Mugan (@jmugan) <a href=\"https://twitter.com/jmugan/status/1773036172723236895?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">2024년 3월 27일</a></blockquote>\n<script async=\"\" src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></figure><p>이는 <a href=\"https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io\">Jina 1.0</a>에서 겪었던 경험과 유사합니다. 당시 우리는 <code>chunk</code>, <code>document</code>, <code>driver</code>, <code>executor</code>, <code>pea</code>, <code>pod</code>, <code>querylang</code>, <code>flow</code>와 같은 다양한 용어들을 도입했습니다(심지어 사용자들이 기억하기 쉽도록 귀여운 스티커도 만들었죠!).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Document-FLAT--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pea-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/QueryLang--FLAT.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png 700w\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--3-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pod-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--5-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png 700w\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">이러한 초기 개념들 대부분은 이후 Jina 리팩토링에서 제거되었습니다. 오늘날에는 \"대대적인 정리\" 이후 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Executor</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Document</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Flow</span></code><span style=\"white-space: pre-wrap;\">만이 살아남았습니다. Jina 3.0에서 새로운 개념인 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Deployment</span></code><span style=\"white-space: pre-wrap;\">를 추가했으니 균형이 맞춰졌다고 할 수 있겠네요. 🤷</span></p></figcaption></figure><p>이 문제는 DSPy나 Jina에만 국한된 것이 아닙니다. TensorFlow의 0.x에서 1.x 버전으로 넘어가면서 도입된 수많은 개념과 추상화를 떠올려보세요. 이는 소프트웨어 프레임워크의 초기 단계에서 자주 발생하는 문제라고 생각합니다. <strong>학술적 표기법을 최대한의 정확성과 재현성을 보장하기 위해 코드베이스에 직접 반영하려는</strong> 시도가 있기 때문입니다. 하지만 모든 사용자가 이러한 세부적인 추상화를 원하는 것은 아닙니다. 간단한 원라이너를 선호하는 사람부터 더 많은 유연성을 요구하는 사람까지 다양합니다. 소프트웨어 프레임워크의 추상화에 대한 이 주제는 2020년 블로그 포스트에서 자세히 다룬 바 있으니, 관심 있는 독자들은 참고하시기 바랍니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/?ref=jina-ai-gmbh.ghost.io#layer-of-abstraction\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Layer of Abstraction When Building \"Tensorflow\" for Search · Han Xiao Tech Blog - Neural Search &amp; AI Engineering</div><div class=\"kg-bookmark-description\">Since Feb. 2020, I started a new venture called Jina AI. Our mission is to build an open-source neural search ecosystem for businesses and developers, ... · Han Xiao</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://hanxiao.io/wechaticon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/blog-abstraction-banner.jpg\" alt=\"\"></div></a></figure><p>둘째로, DSPy의 문서는 일관성 측면에서 때때로 부족함을 보입니다. <code>module</code>과 <code>program</code>, <code>teleprompter</code>와 <code>optimizer</code>, 또는 <code>optimize</code>와 <code>compile</code>(때로는 <code>training</code>이나 <code>bootstrapping</code>으로도 언급됨)과 같은 용어들이 혼용되어 혼란을 가중시킵니다. 결과적으로 저는 DSPy를 처음 접했을 때 정확히 무엇을 <code>optimize</code>하는지, <code>bootstrapping</code> 과정이 무엇인지 이해하는 데 많은 시간을 보냈습니다.</p><p>이러한 어려움에도 불구하고, DSPy를 더 깊이 파고들고 문서를 다시 검토하다 보면 모든 것이 명확해지는 순간이 올 것입니다. DSPy만의 독특한 용어와 PyTorch와 같은 프레임워크에서 보던 친숙한 구조들 간의 연관성이 보이기 시작할 것입니다. 하지만 DSPy는 분명히 향후 버전에서 개선의 여지가 있습니다. 특히 PyTorch 배경이 없는 프롬프트 엔지니어들이 더 쉽게 접근할 수 있도록 만드는 것이 중요합니다.</p><h2 id=\"common-stumbling-blocks-for-dspy-newbies\">DSPy 초보자들이 겪는 일반적인 어려움</h2><p>아래 섹션에서는 제가 DSPy를 처음 시작할 때 막혔던 질문들을 모아보았습니다. 다른 학습자들이 비슷한 어려움을 겪을 때 도움이 되기를 바라면서 이러한 인사이트를 공유합니다.</p><h3 id=\"what-are-teleprompter-optimization-and-compile-whats-exactly-being-optimized-in-dspy\"><code>teleprompter</code>, <code>optimization</code>, <code>compile</code>이 무엇인가요? DSPy에서 정확히 무엇이 최적화되나요?</h3><p>DSPy에서 \"Teleprompters\"는 optimizer입니다(그리고 <a href=\"https://twitter.com/lateinteraction?ref=jina-ai-gmbh.ghost.io\">@lateinteraction</a>이 이를 명확히 하기 위해 문서와 코드를 개선하고 있는 것 같습니다). <code>compile</code> 함수는 이 optimizer의 핵심으로, <code>optimizer.optimize()</code>를 호출하는 것과 유사합니다. DSPy에서의 트레이닝이라고 생각하면 됩니다. 이 <code>compile()</code> 프로세스는 다음을 튜닝하는 것을 목표로 합니다:</p><ul><li>few-shot 데모</li><li>instructions</li><li>LLM의 가중치</li></ul><p>하지만 대부분의 DSPy 초급 튜토리얼에서는 가중치와 instruction 튜닝까지 다루지 않습니다. 이는 다음 질문으로 이어집니다.</p><h3 id=\"whats-bootstrap-in-dspy-all-about\">DSPy의 <code>bootstrap</code>은 무엇인가요?</h3><p>Bootstrap은 few-shot in-context learning을 위한 자체 생성 데모를 만드는 것을 의미하며, 이는 <code>compile()</code> 프로세스(즉, 위에서 언급한 최적화/트레이닝)의 중요한 부분입니다. 이러한 few-shot 데모들은 사용자가 제공한 레이블된 데이터로부터 생성됩니다. 하나의 데모는 보통 입력, 출력, 근거(예: Chain of Thought에서), 그리고 중간 입력 및 출력(다단계 프롬프트용)으로 구성됩니다. 물론 질 좋은 few-shot 데모는 출력의 우수성을 위해 핵심입니다. 이를 위해 DSPy는 사용자 정의 메트릭 함수를 통해 특정 기준을 충족하는 데모만 선택되도록 합니다. 이는 다음 질문으로 이어집니다.</p><h3 id=\"whats-dspy-metric-function\">DSPy 메트릭 함수란 무엇인가요?</h3><p>DSPy를 직접 사용해본 후, 저는 메트릭 함수가 현재 문서에서 다루는 것보다 훨씬 더 강조되어야 한다고 생각하게 되었습니다. DSPy의 메트릭 함수는 평가와 트레이닝 단계 모두에서 중요한 역할을 합니다. 암시적 특성(<code>trace=None</code>으로 제어됨) 덕분에 \"손실\" 함수로도 작동합니다:</p><pre><code class=\"language-python\">def keywords_match_jaccard_metric(example, pred, trace=None):  \n    # Jaccard similarity between example keywords and predicted keywords  \n    A = set(normalize_text(example.keywords).split())  \n    B = set(normalize_text(pred.keywords).split())  \n    j = len(A &amp; B) / len(A | B)\n    if trace is not None:\n        # act as a \"loss\" function\n        return j  \n    return j > 0.8  # act as evaluation</code></pre><p>이 접근 방식은 전통적인 기계 학습과는 매우 다릅니다. 전통적인 방식에서는 손실 함수가 보통 연속적이고 미분 가능한 형태(예: hinge/MSE)이며, 평가 메트릭은 완전히 다르고 이산적(예: NDCG)일 수 있습니다. DSPy에서는 평가와 손실 함수가 메트릭 함수로 통합되어 있으며, 이는 이산적일 수 있고 대부분 부울 값을 반환합니다. 메트릭 함수는 LLM도 통합할 수 있습니다! 아래 예시에서는 LLM을 사용한 퍼지 매치를 구현하여 예측값과 정답이 크기 면에서 유사한지 판단합니다. 예를 들어 \"1 million dollars\"와 \"$1M\"은 true를 반환할 것입니다.</p><pre><code class=\"language-python\">class Assess(dspy.Signature):  \n    \"\"\"Assess the if the prediction is in the same magnitude to the gold answer.\"\"\"  \n  \n    gold_answer = dspy.InputField(desc='number, could be in natural language')  \n    prediction = dspy.InputField(desc='number, could be in natural language')  \n    assessment = dspy.OutputField(desc='yes or no, focus on the number magnitude, not the unit or exact value or wording')  \n  \ndef same_magnitude_correct(example, pred, trace=None):  \n    return dspy.Predict(Assess)(gold_answer=example.answer, prediction=pred.answer).assessment.lower() == 'yes'</code></pre><p>메트릭 함수는 강력하지만 최종 품질 평가뿐만 아니라 최적화 결과에도 영향을 미치며 DSPy 사용자 경험을 크게 좌우합니다. 잘 설계된 메트릭 함수는 최적화된 프롬프트로 이어질 수 있지만, 잘못 작성된 경우 최적화가 실패할 수 있습니다. DSPy로 새로운 문제를 해결할 때, 로직(즉, <code>DSPy.Module</code>)을 설계하는 데 쓰는 시간만큼 메트릭 함수에도 시간을 투자해야 할 수 있습니다. 이렇게 로직과 메트릭에 동시에 중점을 두는 것은 초보자들에게 부담이 될 수 있습니다.</p>\n\n<h3 id=\"bootstrapped-0-full-traces-after-20-examples-in-round-0-what-does-this-mean\"><code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code>는 무슨 의미인가요?</h3>\n\n<p><code>compile()</code> 중에 조용히 출력되는 이 메시지는 매우 중요한 의미를 담고 있습니다. 이는 본질적으로 최적화/컴파일이 실패했으며, 얻은 프롬프트가 단순한 few-shot보다 나아지지 않았다는 것을 의미합니다. 무엇이 잘못된 걸까요? 이런 메시지를 만났을 때 DSPy 프로그램을 디버깅하는 데 도움이 되는 몇 가지 팁을 정리했습니다:</p>\n\n<h4 id=\"your-metric-function-is-incorrect\">메트릭 함수가 잘못되었을 때</h4>\n\n<p><code>BootstrapFewShot(metric=your_metric)</code>에서 사용되는 <code>your_metric</code> 함수가 올바르게 구현되었나요? 단위 테스트를 수행해보세요. <code>your_metric</code>이 <code>True</code>를 반환하나요, 아니면 항상 <code>False</code>를 반환하나요? <code>True</code>를 반환하는 것이 중요한데, 이는 DSPy가 부트스트랩된 예제를 \"성공\"으로 간주하는 기준이기 때문입니다. 모든 평가를 <code>True</code>로 반환하면 모든 예제가 부트스트래핑에서 \"성공\"으로 간주됩니다! 물론 이상적이지는 않지만, 이는 메트릭 함수의 엄격성을 조정하여 <code>\"Bootstrapped 0 full traces\"</code> 결과를 변경하는 방법입니다. DSPy 문서에는 메트릭이 스칼라 값도 반환할 수 있다고 나와있지만, 기본 코드를 살펴본 결과 초보자에게는 권장하지 않습니다.</p>\n\n<h4 id=\"your-logic-dspymodule-is-incorrect\">로직(<code>DSPy.Module</code>)이 잘못되었을 때</h4>\n\n<p>메트릭 함수가 올바르다면, <code>dspy.Module</code> 로직이 올바르게 구현되었는지 확인해야 합니다. 먼저, 각 단계에 대한 <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io\">DSPy 시그니처</a>가 올바르게 할당되었는지 확인하세요. <code>dspy.Predict('question->answer')</code>와 같은 인라인 시그니처는 사용하기 쉽지만, 품질을 위해서는 <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io#class-based-dspy-signatures\">클래스 기반 시그니처</a>를 구현하는 것을 강력히 권장합니다. 특히 클래스에 설명적인 문서 문자열을 추가하고, <code>InputField</code>와 <code>OutputField</code>의 desc 필드를 채우세요—이 모든 것이 LM에게 각 필드에 대한 힌트를 제공합니다. 아래에서는 <a href=\"https://en.wikipedia.org/wiki/Fermi_problem?ref=jina-ai-gmbh.ghost.io\">페르미 문제</a>를 해결하기 위한 두 개의 다단계 <code>DSPy.Module</code>을 구현했는데, 하나는 인라인 시그니처를 사용하고 다른 하나는 클래스 기반 시그니처를 사용합니다.</p>\n\n<figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiSolver(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict('question -> initial_guess')\n        self.step2 = dspy.Predict('question, initial_guess -> calculated_estimation')\n        self.step3 = dspy.Predict('question, initial_guess, calculated_estimation -> variables_and_formulae')\n        self.step4 = dspy.ReAct('question, initial_guess, calculated_estimation, variables_and_formulae -> gathering_data')\n        self.step5 = dspy.Predict('question, initial_guess, calculated_estimation, variables_and_formulae, gathering_data -> answer')\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">인라인 시그니처만 사용한 페르미 문제 해결기</span></p></figcaption></figure>\n\n<figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiStep1(dspy.Signature):\n    question = dspy.InputField(desc='Fermi problems involve the use of estimation and reasoning')\n    initial_guess = dspy.OutputField(desc='Have a guess – don't do any calculations yet')\n\nclass FermiStep2(FermiStep1):\n    initial_guess = dspy.InputField(desc='Have a guess – don't do any calculations yet')\n    calculated_estimation = dspy.OutputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n\nclass FermiStep3(FermiStep2):\n    calculated_estimation = dspy.InputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n    variables_and_formulae = dspy.OutputField(desc='Write a formula or procedure to solve your problem')\n\nclass FermiStep4(FermiStep3):\n    variables_and_formulae = dspy.InputField(desc='Write a formula or procedure to solve your problem')\n    gathering_data = dspy.OutputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n\nclass FermiStep5(FermiStep4):\n    gathering_data = dspy.InputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n    answer = dspy.OutputField(desc='the final answer, must be a numerical value')\n\nclass FermiSolver2(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict(FermiStep1)\n        self.step2 = dspy.Predict(FermiStep2)\n        self.step3 = dspy.Predict(FermiStep3)\n        self.step4 = dspy.Predict(FermiStep4)\n        self.step5 = dspy.Predict(FermiStep5)\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">각 필드에 대한 더 포괄적인 설명이 포함된 클래스 기반 시그니처를 사용한 페르미 문제 해결기</span></p></figcaption></figure>\n\n<p>또한 <code>def forward(self, )</code> 부분도 확인하세요. 다단계 모듈의 경우, 마지막 단계의 출력(또는 <code>FermiSolver</code>에서처럼 모든 출력)이 다음 단계의 입력으로 제대로 전달되는지 확인하세요.</p>\n\n<h4 id=\"your-problem-is-just-too-hard\">문제가 너무 어려운 경우</h4>\n\n<p>메트릭과 모듈이 모두 올바른 것 같다면, 문제 자체가 너무 어렵고 구현한 로직으로는 해결하기에 충분하지 않을 수 있습니다. 따라서 DSPy는 주어진 로직과 메트릭 함수로는 어떤 데모도 부트스트랩하는 것이 불가능하다고 판단합니다. 이 시점에서 고려할 수 있는 몇 가지 옵션이 있습니다:</p>\n\n<ul>\n<li><strong>더 강력한 LM 사용.</strong> 예를 들어, 학생 LM으로 <code>gpt-35-turbo-instruct</code> 대신 <code>gpt-4-turbo</code>를 사용하거나, 교사로 더 강력한 LM을 사용하세요. 이는 종종 매우 효과적일 수 있습니다. 결국 더 강력한 모델은 프롬프트에 대한 이해도가 더 높습니다.</li>\n<li><strong>로직 개선.</strong> <code>dspy.Module</code>의 일부 단계를 더 복잡한 것으로 추가하거나 교체하세요. 예를 들어, <code>Predict</code>를 <code>ChainOfThought</code> <code>ProgramOfThought</code>로 교체하거나, <code>Retrieval</code> 단계를 추가하세요.</li>\n<li><strong>더 많은 학습 예제 추가.</strong> 20개의 예제가 충분하지 않다면, 100개를 목표로 하세요! 그러면 하나의 예제가 메트릭 검사를 통과하고 <code>BootstrapFewShot</code>에 의해 선택될 수 있습니다.</li>\n<li><strong>문제 재구성.</strong> 종종 문제는 잘못된 방식으로 구성되었을 때 해결할 수 없게 됩니다. 하지만 다른 각도에서 바라보면 훨씬 더 쉽고 명확해질 수 있습니다.</li>\n</ul>\n\n<p>실제로는 시행착오의 과정이 필요합니다. 예를 들어, 저는 특히 어려운 문제를 다뤘습니다: 두세 개의 키워드를 기반으로 Google Material Design 아이콘과 유사한 SVG 아이콘을 생성하는 것이었습니다. 처음에는 <code>dspy.ChainOfThought('keywords -> svg')</code>를 사용하는 단순한 <code>DSPy.Module</code>과 pHash 알고리즘과 유사하게 생성된 SVG와 실제 Material Design SVG 간의 시각적 유사도를 평가하는 메트릭 함수를 사용했습니다. 20개의 학습 예제로 시작했지만, 첫 번째 라운드 후에 <code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code>가 나왔고, 이는 최적화가 실패했음을 나타냅니다. 데이터셋을 100개로 늘리고, 모듈을 여러 단계로 수정하고, 메트릭 함수의 임계값을 조정한 결과, 결국 2개의 부트스트랩된 데모를 얻고 최적화된 프롬프트를 얻을 수 있었습니다.</p>",
  "comment_id": "66077bf0a5c39b0001044181",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-03-30T03:41:52.000+01:00",
  "updated_at": "2024-04-23T10:46:48.000+02:00",
  "published_at": "2024-03-30T06:22:42.000+01:00",
  "custom_excerpt": "Heads up, Bay Area guys ditched their AVP already and buzz about DSPy now. Could DSPy be the new go-to framework for prompt engineering after LangChain and LlamaIndex?",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/dspy-not-your-average-prompt-engineering/",
  "excerpt": "Bay Area 개발자들이 이미 AVP를 버리고 이제는 DSPy에 대해 이야기하고 있습니다. DSPy가 LangChain과 LlamaIndex 이후의 프롬프트 엔지니어링을 위한 새로운 표준 프레임워크가 될 수 있을까요?",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Screenshot of a Tetris-like game with \"Score: 40\" and \"Press Start 2P\" text on display.",
  "feature_image_caption": null
}