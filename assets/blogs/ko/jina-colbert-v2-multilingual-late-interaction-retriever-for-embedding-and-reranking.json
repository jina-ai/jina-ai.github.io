{
  "slug": "jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking",
  "id": "66cd8fc6e84873000133d63d",
  "uuid": "e995c4d9-1832-4e2a-8108-e8453f5c82c5",
  "title": "Jina ColBERT v2: 임베딩과 재순위화를 위한 다국어 후기 상호작용 검색기",
  "html": "<p>Jina ColBERT v2(<code>jina-colbert-v2</code>), ColBERT 아키텍처를 기반으로 한 고급 후기 상호작용 검색 모델을 출시하게 되어 기쁩니다. 이 새로운 언어 모델은 <code>jina-colbert-v1-en</code>의 성능을 개선하고 다국어 지원과 동적 출력 차원을 추가했습니다.</p><p>이번 새 릴리스의 주요 특징은 다음과 같습니다:</p><ul><li>기존 ColBERT-v2(+6.5%)와 이전 버전인 <code>jina-colbert-v1-en</code>(+5.4%)에 비해 <strong>우수한 검색 성능</strong></li><li>89개 언어에 대한 <strong>다국어 지원</strong>으로 주요 글로벌 언어에서 강력한 성능 제공</li><li>Matryoshka 표현 학습을 통한 <strong>사용자 제어 가능한 출력 임베딩 크기</strong>로 효율성과 정확도 간의 유연한 균형 조정 가능</li></ul><h2 id=\"technical-summary-of-jina-colbert-v2\"><code>jina-colbert-v2</code>의 기술 요약</h2><p>전체 기술 보고서는 arXiv에서 확인할 수 있습니다:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2408.16672?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever</div><div class=\"kg-bookmark-description\">Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Rohan Jha</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th><code>jina-colbert-v2</code></th>\n<th><code>jina-colbert-v1-en</code></th>\n<th>Original ColBERTv2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>14개 영어<br/>BEIR 태스크 평균</td>\n<td><b>0.521</b></td>\n<td>0.494</td>\n<td>0.489</td>\n</tr>\n<tr>\n<td>다국어</td>\n<td><b>89개 언어</b></td>\n<td>영어 전용</td>\n<td>영어 전용</td>\n</tr>\n<tr>\n<td>출력 차원</td>\n<td><b>128, 96, or 64</b></td>\n<td>고정 128</td>\n<td>고정 128</td>\n</tr>\n<tr>\n<td>최대 쿼리 길이</td>\n<td>32 토큰</td>\n<td>32 토큰</td>\n<td>32 토큰</td>\n</tr>\n<tr>\n<td>최대 문서 길이</td>\n<td>8192 토큰</td>\n<td>8192 토큰</td>\n<td>512 토큰</td>\n</tr>  \n\n<tr>\n<td>파라미터</td>\n<td>560M</td>\n<td>137M</td>\n<td>110M</td>\n</tr>\n<tr>\n<td>모델 크기</td>\n<td>1.1GB</td>\n<td>550MB</td>\n<td>438MB</td>\n</tr>\n\n\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"asymmetric-embedding-in-colbert\">ColBERT의 비대칭 임베딩</h2><p>ColBERT는 BERT 아키텍처에 <strong>후기 상호작용</strong>과 <strong>비대칭</strong> 쿼리-문서 인코딩을 추가하여 구축되었습니다.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">What is ColBERT and Late Interaction and Why They Matter in Search?</div><div class=\"kg-bookmark-description\">Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ColBERT의 비대칭 특성은 <code>jina-colbert-v2</code> 또는 <code>jina-colbert-v1-en</code>과 같은 모델을 사용할 때 쿼리, 문서, 또는 둘 다(재순위화 목적)를 임베딩하는지 지정해야 함을 의미합니다. 이러한 추가적인 유연성은 검색 작업에서 동질적 임베딩 모델보다 성능을 향상시킵니다.</p><h2 id=\"multilingual-support-for-over-89-languages\">89개 이상 언어에 대한 다국어 지원</h2><p>Jina ColBERT v2는 현대의 글로벌화된 정보 검색과 AI 애플리케이션의 요구를 충족하도록 설계된 광범위한 다국어 기능을 갖추고 있습니다. <code>jina-colbert-v2</code>의 학습 코퍼스는 89개 언어를 포함하며, <strong>아랍어, 중국어, 영어, 프랑스어, 독일어, 일본어, 러시아어, 스페인어</strong>와 같은 주요 국제 언어와 <strong>프로그래밍 언어</strong>에 대한 추가 학습 단계를 거쳤습니다. 또한 이중 언어 정렬 텍스트 코퍼스를 포함하여 재순위화/검색 작업에서 서로 다른 언어의 쿼리와 문서를 매칭할 수 있는 교차 언어 잠재력을 열었습니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Distribution-of-the-languages-in-the-training-corpus-at-the-pretrained-stage--3-.svg\" class=\"kg-image\" alt=\"Chart of language distribution in training data, highlighting dominance of English and Chinese.\" loading=\"lazy\" width=\"1456\" height=\"743\"><figcaption><span style=\"white-space: pre-wrap;\">사전 학습 데이터셋의 언어별 분포 (</span><a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ISO-639</span></a><span style=\"white-space: pre-wrap;\"> 코드로 지정), 로그 스케일</span></figcaption></figure><p>현재 Jina ColBERT v2는 컴팩트한 임베딩을 생성하는 <strong>유일한 다국어 ColBERT 유사 모델</strong>로, MIRACL 벤치마크에서 테스트한 모든 언어에서 BM25 기반 검색을 크게 능가합니다.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-Multilingual-Data--1-.svg\" class=\"kg-image\" alt=\"Bar chart comparing jina-colbert-v2 and BM25 performance across 20 languages on multilingual tasks.\" loading=\"lazy\" width=\"691\" height=\"426\"><figcaption><span style=\"white-space: pre-wrap;\">MIRACL 벤치마크에서 16개 언어에 대한 Jina ColBERT v2와 BM25의 성능 비교</span></figcaption></figure><p>더욱이 영어 검색 작업에서 Jina ColBERT v2는 이전 버전인 <code>jina-colbert-v1-en</code>과 원래의 ColBERT v2 모델의 성능을 뛰어넘으며, 영어 전용으로 특화된 <a href=\"https://huggingface.co/answerdotai/answerai-colbert-small-v1?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">AnswerAI-ColBERT-small</a> 모델과 비슷한 성능을 보입니다.</p>\n<!--kg-card-begin: html-->\n<table class=\"simple-table\">\n  <tbody>\n<thead>\n<tr>\n      <th><strong>모델명</strong></th>\n      <th><strong>평균 점수<br>(14개 BEIR 영어 전용 벤치마크)<br></strong></th>\n      <th><strong>다국어 지원</strong></th>\n  </tr>\n    </thead>\n    <tr>\n      <td><code>jina-colbert-v2</code></td>\n      <td>0.521</td>\n      <td>다국어</td>\n    </tr>\n    <tr>\n      <td><code>jina-colbert-v1-en</code></td>\n      <td>0.494</td>\n      <td>영어 전용</td>\n    </tr>\n    <tr>\n      <td>ColBERT v2.0</td>\n      <td>0.489</td>\n      <td>영어 전용</td>\n    </tr>\n    <tr>\n      <td>AnswerAI-ColBERT-small</td>\n      <td>0.549</td>\n      <td>영어 전용</td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-English-only-datasets-from-BEIR--2-.svg\" class=\"kg-image\" alt=\"Bar chart showing model evaluations on English BEIR datasets, with several models like 'jina-colbert' and 'BM25'.\" loading=\"lazy\" width=\"1088\" height=\"712\"><figcaption><span style=\"white-space: pre-wrap;\">BEIR 벤치마크의 영어 전용 데이터셋에 대한 jina-colbert-v2 평가</span></figcaption></figure><h2 id=\"matryoshka-representation-learning\">마트료시카 표현 학습</h2><p><a href=\"https://arxiv.org/abs/2205.13147?ref=jina-ai-gmbh.ghost.io\">마트료시카 표현 학습</a>은 정확도 손실을 최소화하면서 다양한 출력 벡터 크기를 지원하도록 모델을 학습시키는 기술입니다. 신경망의 은닉층을 여러 다른 선형 투영 헤드 - 신경망의 최종 층 - 로 학습시켜 각각 다른 출력 크기를 지원합니다. <strong>Jina ColBERT v2는 128, 96, 64 차원의 출력 벡터를 지원합니다.</strong></p><p>Jina ColBERT v2는 기본적으로 128차원의 출력 임베딩을 생성하지만, 거의 동일한 성능을 유지하면서 각각 25%와 50% 더 짧은 96차원과 64차원도 생성할 수 있습니다.</p><p>아래 표는 <a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain?ref=jina-ai-gmbh.ghost.io\">nDGC</a> 성능을 보여줍니다6개의 BEIR 벤치마크에서 상위 10개 결과(<em>nDGC@10</em>)에 대한 <code>jina-colbert-v2</code>의 성능입니다. 128차원과 96차원의 성능 차이는 겨우 1% 정도이며, 128차원과 64차원의 차이는 1.5% 미만입니다.</p>\n<!--kg-card-begin: html-->\n<table id=\"b838dc78-1321-499e-98e7-63e3b5c8e910\" class=\"simple-table\"><tbody><thead id=\"177f4349-0620-4947-a3ce-01e598395ed7\"><tr><th id=\"<\\ml\" class=\"\"><strong>출력 차원</strong></th><th id=\"<NYX\" class=\"\"><strong>평균 점수</strong><strong><br>(6개 벤치마크의 nDGC@10)<br></strong></th></tr></thead><tr id=\"9199b56b-0513-4c99-a2a7-29cde915c3b9\"><td id=\"<\\ml\" class=\"\">128</td><td id=\"<NYX\" class=\"\">0.565</td></tr><tr id=\"af4d45fc-ebf4-4e1f-b5b0-1807a1cb889b\"><td id=\"<\\ml\" class=\"\">96</td><td id=\"<NYX\" class=\"\">0.558</td></tr><tr id=\"ecf7eac9-5c56-47e6-ab27-0ddb4659e263\"><td id=\"<\\ml\" class=\"\">64</td><td id=\"<NYX\" class=\"\">0.556</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Performance-on-selected-BEIR-benchmarks.svg\" class=\"kg-image\" alt=\"Bar chart of BEIR benchmarks, highlighting scores of datasets like nfcorpus to msmarco, with jina-colbert-v2.64 excelling.\" loading=\"lazy\" width=\"732\" height=\"538\"><figcaption><span style=\"white-space: pre-wrap;\">다양한 출력 차원에서의 Jina ColBERT v2 성능.</span></figcaption></figure><p>출력 벡터의 크기를 줄이면 공간이 절약되고 서로 다른 벡터를 비교하거나 벡터 간 거리를 측정해야 하는 벡터 기반 정보 검색과 같은 애플리케이션의 속도가 향상됩니다.</p><p>이는 저장 공간 절감 측면에서도 상당한 비용 절감 효과가 있습니다. 예를 들어 <a href=\"https://cloud.qdrant.io/calculator?ref=jina-ai-gmbh.ghost.io\">Qdrant의 클라우드 비용 계산기</a>를 사용하면, AWS에서 1억 개의 문서를 각각 128차원 벡터로 저장할 때 <a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=128&ref=jina-ai-gmbh.ghost.io\">월 예상 비용은 US$1,319.24</a>입니다. 64차원에서는 이 비용이 <a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=64&ref=jina-ai-gmbh.ghost.io\">US$659.62로 감소</a>합니다.</p><h2 id=\"getting-started-with-jina-colbert-v2\">Jina ColBERT v2 시작하기</h2><p>Jina ColBERT v2는 Jina Search Foundation API, <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS 마켓플레이스</a>, 그리고 <a href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\">Azure</a>를 통해 사용할 수 있습니다. 또한 <em>비상업적 용도에 한해</em> (<a href=\"https://www.creativecommons.org/licenses/by-nc/4.0/deed.en?ref=jina-ai-gmbh.ghost.io\">CC BY-NC-4.0</a>) <a href=\"https://huggingface.co/jinaai/jina-colbert-v2?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>를 통해서도 이용할 수 있습니다.</p><h3 id=\"via-jina-search-foundation-api\">Jina Search Foundation API를 통한 사용</h3><h4 id=\"for-embedding\">임베딩</h4><p>다음 <code>curl</code> 명령은 Jina Embeddings API를 통해 <code>jina-colbert-v2</code>로부터 문서 임베딩을 얻기 위한 입력과 옵션을 지정하는 방법을 보여줍니다. 원하는 크기의 벡터를 얻으려면 <code>dimensions</code> 매개변수에 128 또는 64를 지정하세요. 이 매개변수는 선택사항이며 기본값은 128입니다.</p><p>입력 문서가 8192 토큰보다 길면 잘립니다.</p><p>인증 헤더에 Jina API 키를 지정하세요 <code>Authorization: Bearer &lt;YOUR JINA API KEY&gt;</code>:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # 또는 64로 벡터 크기 절반으로 설정\n\t\"input_type\": \"document\", # 쿼리 임베딩은 아래 참조\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your document text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each text can be up to 8192 tokens long\"\n    ]}'\n</code></pre><p>쿼리 임베딩을 얻으려면 <code>input_type</code> 매개변수를 <code>document</code> 대신 <code>query</code>로 설정하세요. 쿼리는 문서보다 훨씬 더 엄격한 크기 제한이 있습니다. 32 토큰에서 잘립니다. 쿼리 인코딩은 32 토큰보다 짧을 경우 패딩에 대한 임베딩을 포함하여 <em>항상</em> 32 토큰을 반환합니다.</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # 또는 64로 벡터 크기 절반으로 설정\t\n\t\"input_type\": \"query\", # 쿼리 임베딩에는 이 설정이 필요\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your query text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each query text can be up to 32 tokens long\"\n    ]}'\n</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">검색과 RAG를 위한 멀티모달, 이중언어 장문 임베딩.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"for-reranking\">재순위화</h4><p>Jina Reranker API를 통해 <code>jina-colbert-v2</code>를 사용하여 하나의 쿼리와 여러 문서를 전달하고 순위를 매길 수 있는 매치 점수를 받으려면 아래와 같이 요청을 구성하세요:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/rerank \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n      \"model\": \"jina-colbert-v2\",\n      \"query\": \"What is the population of Berlin?\",\n      \"top_n\": 3,\n      \"documents\": [\n        \"Berlin's population grew by 0.7 percent in 2023 compared with the previous year. Accordingly, around 27,300 more residents lived in Berlin at the end of the last year than in 2022. Those of 30 to under 40 years old form the numerically largest age group. With roughly 881,000 foreign residents from around 170 nations and an average age of the population of 42.5 years old.\",\n        \"Mount Berlin is a glacier-covered volcano in Marie Byrd Land, Antarctica, 100 kilometres (62 mi) from the Amundsen Sea. It is a roughly 20-kilometre-wide (12 mi) mountain with parasitic vents that consists of two coalesced volcanoes: Berlin proper with the 2-kilometre-wide (1.2 mi) Berlin Crater and Merrem Peak with a 2.5-by-1-kilometre-wide (1.55 mi × 0.62 mi) crater, 3.5 kilometres (2.2 mi) away from Berlin.\",\n        \"Population as of 31.12.2023 by nationality and federal states Land\\\\tTotal\\\\tGermans\\\\tForeigners\\\\tincluding EU-states number\\\\t%\\\\tnumber\\\\t%\",\n        \"The urban area of Berlin has a population of over 4.5 million and is therefore the most populous urban area in Germany. The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region, and the sixth-biggest metropolitan region by GDP in the European Union.\",\n        \"Irving Berlin (born Israel Beilin) was an American composer and songwriter. His music forms a large part of the Great American Songbook. Berlin received numerous honors including an Academy Award, a Grammy Award, and a Tony Award.\",\n        \"Berlin is a town in the Capitol Planning Region, Connecticut, United States. The population was 20,175 at the 2020 census.\",\n        \"Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\",\n        \"Berlin, Berlin ist eine für die ARD produzierte Fernsehserie, die von 2002 bis 2005 im Vorabendprogramm des Ersten ausgestrahlt wurde. Regie führten unter anderem Franziska Meyer Price, Christoph Schnee, Sven Unterwaldt Jr. und Titus Selge.\"\n        ]\n    }'</code></pre><p><code>top_n</code> 인수는 검색하고자 하는 문서의 수를 지정합니다. 예를 들어 애플리케이션에서 최상위 매치만 사용하는 경우 <code>top_n</code>을 1로 설정하세요.</p><p>Python 및 기타 프로그래밍 언어와 프레임워크의 코드 스니펫은 <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina AI Embeddings API 페이지</a>를 방문하거나 <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina Reranker API 페이지</a>의 드롭다운 메뉴에서 <code>jina-colbert-v2</code>를 선택하세요.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reranker API</div><div class=\"kg-bookmark-description\">손쉽게 검색 관련성과 RAG 정확도를 최대화하세요.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-reranker-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"via-stanford-colbert\">Stanford ColBERT를 통한 사용</h3><p>Stanford ColBERT 라이브러리에서도 Jina ColBERT v2를 <a href=\"https://github.com/stanford-futuredata/ColBERT?ref=jina-ai-gmbh.ghost.io\">ColBERT v2</a>의 대체품으로 사용할 수 있습니다. 모델 소스로 <code>jinaai/jina-colbert-v2</code>를 지정하기만 하면 됩니다:</p><pre><code class=\"language-python\">from colbert.infra import ColBERTConfig\nfrom colbert.modeling.checkpoint import Checkpoint\n\nckpt = Checkpoint(\"jinaai/jina-colbert-v2\", colbert_config=ColBERTConfig())\ndocs = [\"Your list of texts\"] \nquery_vectors = ckpt.queryFromText(docs)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">위 코드를 사용하려면 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code>와 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code>을 설치해야 합니다.</div></div><h3 id=\"via-ragatouille\">RAGatouille를 통한 사용</h3><p>Jina ColBERT v2는 <a href=\"https://github.com/AnswerDotAI/RAGatouille?ref=jina-ai-gmbh.ghost.io\">RAGatouille</a>에도 통합되어 있습니다. <code>RAGPretrainedModel.from_pretrained()</code> 메서드를 통해 다운로드하고 사용할 수 있습니다:</p><pre><code class=\"language-python\">from ragatouille import RAGPretrainedModel\n\nRAG = RAGPretrainedModel.from_pretrained(\"jinaai/jina-colbert-v2\")\ndocs = [\"Your list of texts\"]\nRAG.index(docs, index_name=\"your_index_name\")\nquery = \"Your query\"\nresults = RAG.search(query)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">위 코드를 사용하려면 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code>와 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code>을 설치해야 합니다.</div></div><h3 id=\"via-qdrant\">Qdrant를 통한 사용</h3><p>Qdrant는 1.10 버전부터 다중 벡터와 후기 상호작용 모델에 대한 <a href=\"https://qdrant.tech/blog/qdrant-1.10.x/?ref=jina-ai-gmbh.ghost.io\">지원</a>을 추가했습니다. Qdrant 엔진의 기존 사용자들은 로컬이든 관리형 클라우드 버전이든 Qdrant 클라이언트를 사용하여 <code>jina-colbert-v2</code>를 직접 통합할 수 있습니다.</p><p><strong>MAX_SIM 연산을 사용하여 새 컬렉션 생성하기</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nqdrant_client.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config={\n        \"colbert\": models.VectorParams(\n            size=128,\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM\n            ),\n        )\n    }\n)</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Qdrant에서 ColBERT 스타일 모델을 사용하려면 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">multivector_config</code> 매개변수를 올바르게 설정하는 것이 필수적입니다.</div></div><p><strong>다중 벡터 컬렉션에 문서 삽입하기</strong></p><pre><code class=\"language-Python\">import requests\nfrom qdrant_client import QdrantClient, models\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\ndata = {\n    'model': 'jina-colbert-v2',\n    'input_type': 'query',\n    'embedding_type': 'float',\n    'input': [\n        'Your text string goes here',\n        'You can send multiple texts',\n        'Each text can be up to 8192 tokens long'\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nrows = response.json()[\"data\"]\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nfor i, row in enumerate(rows):\n    qdrant_client.upsert(\n        collection_name=\"{collection_name}\",\n        points=[\n            models.PointStruct(\n                id=i,  \n                vector=row[\"embeddings\"],  \n                payload={\"text\": data[\"input\"][i]} \n            )\n        ],\n    )</code></pre><p><strong>컬렉션 쿼리하기</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\nimport requests\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\n\ndata = {\n    'model': 'jina-colbert-v2',\n    \"input_type\": \"query\",\n    \"embedding_type\": \"float\",\n    \"input\": [\n        \"how many tokens in an input do Jina AI's embedding models support?\"\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nvector = response.json()[\"data\"][0][\"embeddings\"]\n\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nresults = qdrant_client.query_points(\n    collection_name=\"{collection_name}\",\n    query=vector,\n)\n\nprint(results)</code></pre><h3 id=\"summary\">요약</h3><p>Jina ColBERT v2(<code>jina-colbert-v2</code>)는 <code>jina-colbert-v1-en</code>의 높은 성능을 기반으로 하여 전 세계의 다양한 언어로 그 기능을 확장했습니다. 다양한 임베딩 크기를 지원하여 사용자가 특정 사용 사례에 맞게 정밀도/효율성 트레이드오프를 조정할 수 있으며, 이는 시간과 컴퓨팅 비용을 크게 절약할 수 있습니다.</p><p>이 모델은 이러한 모든 기능을 하나의 경쟁력 있는 가격의 패키지로 통합하여, 직관적인 웹 API를 통해 접근할 수 있으며 HTTP 요청을 지원하는 모든 컴퓨팅 프레임워크와 호환됩니다. 100만 개의 무료 토큰으로 <a href=\"https://jina.ai/?sui=&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">직접 사용해보시고</a> 애플리케이션과 프로세스를 어떻게 향상시킬 수 있는지 확인해보세요.</p>",
  "comment_id": "66cd8fc6e84873000133d63d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-08-27T10:35:18.000+02:00",
  "updated_at": "2024-09-09T07:43:38.000+02:00",
  "published_at": "2024-08-30T09:19:58.000+02:00",
  "custom_excerpt": "Jina ColBERT v2 supports 89 languages with superior retrieval performance, user-controlled output dimensions, and 8192 token-length. ",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking/",
  "excerpt": "Jina ColBERT v2는 89개 언어를 지원하며, 우수한 검색 성능과 사용자 제어 가능한 출력 차원, 그리고 8192 토큰 길이를 제공합니다.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dark-themed coding interface displaying English and Japanese characters with \"JINA COLBERT V2\" highlighted in the center.",
  "feature_image_caption": null
}