{
  "slug": "finding-optimal-breakpoints-in-long-documents-using-small-language-models",
  "id": "67126986708dbe00019249f2",
  "uuid": "b7e55a5d-f267-4a4a-b861-27221c0f3827",
  "title": "使用小型語言模型在長文件中尋找最佳斷點",
  "html": "<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">這是分塊系列的第三部分。<b><strong style=\"white-space: pre-wrap;\">建議閱讀順序：</strong></b><a href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><b><strong style=\"white-space: pre-wrap;\">第一部分</strong></b></a><b><strong style=\"white-space: pre-wrap;\">、</strong></b><a href=\"https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii?ref=jina-ai-gmbh.ghost.io\"><b><strong style=\"white-space: pre-wrap;\">第二部分</strong></b></a><b><strong style=\"white-space: pre-wrap;\">、</strong></b><a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\"><b><strong style=\"white-space: pre-wrap;\">研究論文</strong></b></a><b><strong style=\"white-space: pre-wrap;\">、第三部分。</strong></b></div></div><p>在我們之前的文章中，我們探討了分塊的挑戰並<a href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\">介紹了後期分塊的概念</a>，這有助於減少嵌入塊時的上下文損失。在本文中，我們將聚焦於另一個挑戰：尋找最佳斷點。雖然<a href=\"https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/?ref=jina-ai-gmbh.ghost.io#late-chunking-is-resilient-to-poor-boundary-cues\" rel=\"noreferrer\">我們的後期分塊策略已證實對於不佳的邊界相當有彈性</a>，但這並不意味著我們可以忽視它們—它們對於人類和 LLM 的可讀性仍然很重要。我們的觀點是：在確定斷點時，我們現在可以完全專注於可讀性，而不用擔心語義或上下文的損失。後期分塊可以處理好的和不好的斷點，所以可讀性成為你的主要考慮因素。</p><p>基於這一點，我們訓練了三個專門設計用於分割長文檔的小型語言模型，同時保持語義連貫性並處理複雜的內容結構。它們是：</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/text-seg-lm-qwen2-0.5b · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/text-seg-lm-qwen2-0.5b.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>simple-qwen-0.5</span></code><span style=\"white-space: pre-wrap;\">，基於文檔的結構元素來分割文本。</span></p></figcaption></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>topic-qwen-0.5</span></code><span style=\"white-space: pre-wrap;\">，基於文本中的主題來分割文本。</span></p></figcaption></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b-summary-chunking?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/text-seg-lm-qwen2-0.5b-summary-chunking · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/text-seg-lm-qwen2-0.5b-summary-chunking.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>summary-qwen-0.5</span></code><span style=\"white-space: pre-wrap;\">，為每個片段生成摘要。</span></p></figcaption></figure><p>在本文中，我們將討論為什麼要開發這個模型，我們如何處理其三個變體，以及它們與 <a href=\"https://www.notion.so/Advancing-Segmentation-Strategies-in-RAG-with-a-Custom-Small-Language-Model-Restructure-638b84ae461d412eb6889cfa7f54cce1?pvs=21&ref=jina-ai-gmbh.ghost.io\">Jina AI 的 Segmenter API</a> 的基準比較。最後，我們將分享我們學到的經驗和對未來的一些想法。</p><h2 id=\"segmentation-problem\">分割問題</h2><p>分割是 RAG 系統的核心元素。我們如何將長文檔分割成連貫、可管理的片段直接影響檢索和生成步驟的質量，影響從答案相關性到摘要質量的所有方面。傳統的分割方法產生了不錯的結果，但也有其局限性。</p><p>引用我們<a href=\"https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/?ref=jina-ai-gmbh.ghost.io\">之前的文章</a>：</p><blockquote>在分割長文檔時，一個關鍵的挑戰是決定在哪裡創建片段。這可以使用固定的 token 長度、固定數量的句子，或更高級的方法如正則表達式和語義分割模型來完成。建立準確的片段邊界至關重要，因為它不僅提高了搜索結果的可讀性，還確保了在 RAG 系統中提供給 LLM 的片段既精確又充分。</blockquote><p>雖然後期分塊提高了檢索性能，<strong>但在 RAG 應用中，確保每個片段本身都盡可能有意義，而不僅僅是隨機的文本塊，這一點至關重要。</strong>LLM 依賴於連貫、結構良好的數據來生成準確的回應。如果片段不完整或缺乏意義，即使有後期分塊的好處，LLM 也可能在上下文和準確性方面遇到困難，影響整體性能。簡而言之，無論你是否使用後期分塊，擁有一個穩固的分割策略對於建立有效的 RAG 系統都是必不可少的（正如你將在後面的基準部分看到的）。</p><p>傳統的分割方法，無論是在簡單的邊界（如換行或句子）處斷開，還是使用嚴格的基於 token 的規則，都面臨著相同的限制。這兩種方法都未能考慮到語義邊界，並且在處理模糊的主題時會遇到困難，導致片段破碎。為了解決這些挑戰，我們開發並訓練了一個專門用於分割的小型語言模型，旨在捕捉主題轉換並保持連貫性，同時在各種任務中保持效率和適應性。</p><h2 id=\"why-small-language-model\">為什麼選擇小型語言模型？</h2><p>我們開發了小型語言模型（SLM）來解決我們在使用傳統分割技術時遇到的特定限制，特別是在處理程式碼片段和其他複雜結構（如表格、列表和公式）時。在傳統方法中，通常依賴於 token 計數或嚴格的結構規則，很難維持語義連貫內容的完整性。例如，程式碼片段經常被分割成多個部分，打破了它們的上下文，使下游系統更難理解或準確檢索它們。</p><p>通過訓練專門的 SLM，我們旨在創建一個能夠智能識別和保護這些有意義邊界的模型，確保相關元素保持在一起。這不僅提高了 RAG 系統中的檢索質量，還增強了下游任務（如摘要和問答）的效果，在這些任務中，維持連貫和上下文相關的片段至關重要。與傳統分割方法的嚴格邊界相比，SLM 方法提供了一個更適應性強、更具任務特異性的解決方案。</p><h2 id=\"training-slms-three-approaches\">訓練 SLM：三種方法</h2><p>我們訓練了三個版本的 SLM：</p><ul><li><code>simple-qwen-0.5</code> 是最簡單的模型，設計用於基於文檔的結構元素識別邊界。其簡單性使其成為基本分割需求的高效解決方案。</li><li><code>topic-qwen-0.5</code> 受思維鏈推理的啟發，通過識別文本中的主題（如\"第二次世界大戰的開始\"）並使用這些主題來定義片段邊界，將分割提升到了更高的層次。這個模型確保每個片段在主題上保持連貫，非常適合複雜的多主題文檔。初步測試顯示，它在以接近人類直覺的方式分割內容方面表現出色。</li><li><code>summary-qwen-0.5</code> 不僅識別文本邊界，還為每個片段生成摘要。在 RAG 應用中，特別是對於長文檔問答等任務，摘要片段非常有優勢，儘管在訓練時需要更多的數據。</li></ul><p>所有模型只返回<em>片段頭部</em>—每個片段的截斷版本。模型不是生成完整的片段，而是輸出關鍵點或子主題，這通過專注於語義轉換而不是簡單地複製輸入內容來改善邊界檢測和連貫性。在檢索片段時，文檔文本基於這些片段頭部進行分割，並相應地重建完整片段。</p><h3 id=\"dataset\">數據集</h3><p>我們使用了 <a href=\"https://github.com/koomri/text-segmentation?ref=jina-ai-gmbh.ghost.io\">wiki727k</a> 數據集，這是一個從維基百科文章中提取的大規模結構化文本片段集合。它包含超過 727,000 個文本部分，每個部分代表維基百科文章的不同部分，如介紹、章節或小節。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/koomri/text-segmentation?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - koomri/text-segmentation: Implementation of the paper: Text Segmentation as a Supervised Learning Task</div><div class=\"kg-bookmark-description\">論文《Text Segmentation as a Supervised Learning Task》的實作 - koomri/text-segmentation</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">koomri</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/a0a75db005774d424366f3fa2d4c70930927a0b2d8032ef3c04cb0f3beebcb8e/koomri/text-segmentation\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"data-augmentation\">資料增強</h3><p>為了給每個模型變體生成訓練配對，我們使用 GPT-4 來增強我們的資料。對於訓練資料集中的每篇文章，我們發送以下提示：</p><pre><code class=\"language-python\">f\"\"\"\nGenerate a five to ten words topic and a one sentence summary for this chunk of text.\n```\n{text}\n```\nMake sure the topic is concise and the summary covers the main topic as much as possible.\n\nPlease respond in the following format:\n```\nTopic: ...\nSummary: ...\n```\n\nDirectly respond with the required topic and summary, do not include any other details, and do not surround your response with quotes, backticks or other separators.\n   \"\"\".strip()</code></pre><p>我們使用簡單的分割方式從每篇文章生成段落，先在 <code>\\\\n\\\\n\\\\n</code> 處分割，然後在 <code>\\\\n\\\\n</code> 處再次分割，以獲得以下內容（以這個關於 Common Gateway Interface 的文章為例）：</p><pre><code>[\n    [\n      \"In computing, Common Gateway Interface (CGI) offers a standard protocol for web servers to execute programs that execute like Console applications (also called Command-line interface programs) running on a server that generates web pages dynamically.\",\n      \"Such programs are known as \\\\\"CGI scripts\\\\\" or simply as \\\\\"CGIs\\\\\".\",\n      \"The specifics of how the script is executed by the server are determined by the server.\",\n      \"In the common case, a CGI script executes at the time a request is made and generates HTML.\"\n    ],\n    [\n      \"In 1993 the National Center for Supercomputing Applications (NCSA) team wrote the specification for calling command line executables on the www-talk mailing list; however, NCSA no longer hosts the specification.\",\n      \"The other Web server developers adopted it, and it has been a standard for Web servers ever since.\",\n      \"A work group chaired by Ken Coar started in November 1997 to get the NCSA definition of CGI more formally defined.\",\n      \"This work resulted in RFC 3875, which specified CGI Version 1.1.\",\n      \"Specifically mentioned in the RFC are the following contributors: \\\\n1. Alice Johnson\\\\n2. Bob Smith\\\\n3. Carol White\\\\n4. David Nguyen\\\\n5. Eva Brown\\\\n6. Frank Lee\\\\n7. Grace Kim\\\\n8. Henry Carter\\\\n9. Ingrid Martinez\\\\n10. Jack Wilson\",\n      \"Historically CGI scripts were often written using the C language.\",\n      \"RFC 3875 \\\\\"The Common Gateway Interface (CGI)\\\\\" partially defines CGI using C, as in saying that environment variables \\\\\"are accessed by the C library routine getenv() or variable environ\\\\\".\"\n    ],\n    [\n      \"CGI is often used to process inputs information from the user and produce the appropriate output.\",\n      \"An example of a CGI program is one implementing a Wiki.\",\n      \"The user agent requests the name of an entry; the Web server executes the CGI; the CGI program retrieves the source of that entry's page (if one exists), transforms it into HTML, and prints the result.\",\n      \"The web server receives the input from the CGI and transmits it to the user agent.\",\n      \"If the \\\\\"Edit this page\\\\\" link is clicked, the CGI populates an HTML textarea or other editing control with the page's contents, and saves it back to the server when the user submits the form in it.\\\\n\",\n      \"\\\\n# CGI script to handle editing a page\\\\ndef handle_edit_request(page_content):\\\\n    html_form = f'''\\\\n    &lt;html&gt;\\\\n    &lt;body&gt;\\\\n        &lt;form action=\\\\\"/save_page\\\\\" method=\\\\\"post\\\\\"&gt;\\\\n            &lt;textarea name=\\\\\"page_content\\\\\" rows=\\\\\"20\\\\\" cols=\\\\\"80\\\\\"&gt;\\\\n            {page_content}\\\\n            &lt;/textarea&gt;\\\\n            &lt;br&gt;\\\\n            &lt;input type=\\\\\"submit\\\\\" value=\\\\\"Save\\\\\"&gt;\\\\n        &lt;/form&gt;\\\\n    &lt;/body&gt;\\\\n    &lt;/html&gt;\\\\n    '''\\\\n    return html_form\\\\n\\\\n# Example usage\\\\npage_content = \\\\\"Existing content of the page.\\\\\"\\\\nhtml_output = handle_edit_request(page_content)\\\\nprint(\\\\\"Generated HTML form:\\\\\")\\\\nprint(html_output)\\\\n\\\\ndef save_page(page_content):\\\\n    with open(\\\\\"page_content.txt\\\\\", \\\\\"w\\\\\") as file:\\\\n        file.write(page_content)\\\\n    print(\\\\\"Page content saved.\\\\\")\\\\n\\\\n# Simulating form submission\\\\nsubmitted_content = \\\\\"Updated content of the page.\\\\\"\\\\nsave_page(submitted_content)\"\n    ],\n    [\n      \"Calling a command generally means the invocation of a newly created process on the server.\",\n      \"Starting the process can consume much more time and memory than the actual work of generating the output, especially when the program still needs to be interpreted or compiled.\",\n      \"If the command is called often, the resulting workload can quickly overwhelm the server.\",\n      \"The overhead involved in process creation can be reduced by techniques such as FastCGI that \\\\\"prefork\\\\\" interpreter processes, or by running the application code entirely within the web server, using extension modules such as mod_perl or mod_php.\",\n      \"Another way to reduce the overhead is to use precompiled CGI programs, e.g.\",\n      \"by writing them in languages such as C or C++, rather than interpreted or compiled-on-the-fly languages such as Perl or PHP, or by implementing the page generating software as a custom webserver module.\",\n      \"Several approaches can be adopted for remedying this: \\\\n1. Implementing stricter regulations\\\\n2. Providing better education and training\\\\n3. Enhancing technology and infrastructure\\\\n4. Increasing funding and resources\\\\n5. Promoting collaboration and partnerships\\\\n6. Conducting regular audits and assessments\",\n      \"The optimal configuration for any Web application depends on application-specific details, amount of traffic, and complexity of the transaction; these tradeoffs need to be analyzed to determine the best implementation for a given task and time budget.\"\n    ]\n  ],\n</code></pre><p>然後我們生成了一個包含段落、主題和摘要的 JSON 結構：</p><pre><code>{\n  \"sections\": [\n    [\n      \"In computing, Common Gateway Interface (CGI) offers a standard protocol for web servers to execute programs that execute like Console applications (also called Command-line interface programs) running on a server that generates web pages dynamically.\",\n      \"Such programs are known as \\\\\"CGI scripts\\\\\" or simply as \\\\\"CGIs\\\\\".\",\n      \"The specifics of how the script is executed by the server are determined by the server.\",\n      \"In the common case, a CGI script executes at the time a request is made and generates HTML.\"\n    ],\n    [\n      \"In 1993 the National Center for Supercomputing Applications (NCSA) team wrote the specification for calling command line executables on the www-talk mailing list; however, NCSA no longer hosts the specification.\",\n      \"The other Web server developers adopted it, and it has been a standard for Web servers ever since.\",\n      \"A work group chaired by Ken Coar started in November 1997 to get the NCSA definition of CGI more formally defined.\",\n      \"This work resulted in RFC 3875, which specified CGI Version 1.1.\",\n      \"Specifically mentioned in the RFC are the following contributors: \\\\n1. Alice Johnson\\\\n2. Bob Smith\\\\n3. Carol White\\\\n4. David Nguyen\\\\n5. Eva Brown\\\\n6. Frank Lee\\\\n7. Grace Kim\\\\n8. Henry Carter\\\\n9. Ingrid Martinez\\\\n10. Jack Wilson\",\n      \"Historically CGI scripts were often written using the C language.\",\n      \"RFC 3875 \\\\\"The Common Gateway Interface (CGI)\\\\\" partially defines CGI using C, as in saying that environment variables \\\\\"are accessed by the C library routine getenv() or variable environ\\\\\".\"\n    ],\n    [\n      \"CGI is often used to process inputs information from the user and produce the appropriate output.\",\n      \"An example of a CGI program is one implementing a Wiki.\",\n      \"The user agent requests the name of an entry; the Web server executes the CGI; the CGI program retrieves the source of that entry's page (if one exists), transforms it into HTML, and prints the result.\",\n      \"The web server receives the input from the CGI and transmits it to the user agent.\",\n      \"If the \\\\\"Edit this page\\\\\" link is clicked, the CGI populates an HTML textarea or other editing control with the page's contents, and saves it back to the server when the user submits the form in it.\\\\n\",\n      \"\\\\n# CGI script to handle editing a page\\\\ndef handle_edit_request(page_content):\\\\n    html_form = f'''\\\\n    &lt;html&gt;\\\\n    &lt;body&gt;\\\\n        &lt;form action=\\\\\"/save_page\\\\\" method=\\\\\"post\\\\\"&gt;\\\\n            &lt;textarea name=\\\\\"page_content\\\\\" rows=\\\\\"20\\\\\" cols=\\\\\"80\\\\\"&gt;\\\\n            {page_content}\\\\n            &lt;/textarea&gt;\\\\n            &lt;br&gt;\\\\n            &lt;input type=\\\\\"submit\\\\\" value=\\\\\"Save\\\\\"&gt;\\\\n        &lt;/form&gt;\\\\n    &lt;/body&gt;\\\\n    &lt;/html&gt;\\\\n    '''\\\\n    return html_form\\\\n\\\\n# Example usage\\\\npage_content = \\\\\"Existing content of the page.\\\\\"\\\\nhtml_output = handle_edit_request(page_content)\\\\nprint(\\\\\"Generated HTML form:\\\\\")\\\\nprint(html_output)\\\\n\\\\ndef save_page(page_content):\\\\n    with open(\\\\\"page_content.txt\\\\\", \\\\\"w\\\\\") as file:\\\\n        file.write(page_content)\\\\n    print(\\\\\"Page content saved.\\\\\")\\\\n\\\\n# Simulating form submission\\\\nsubmitted_content = \\\\\"Updated content of the page.\\\\\"\\\\nsave_page(submitted_content)\"\n    ],\n    [\n      \"Calling a command generally means the invocation of a newly created process on the server.\",\n      \"Starting the process can consume much more time and memory than the actual work of generating the output, especially when the program still needs to be interpreted or compiled.\",\n      \"If the command is called often, the resulting workload can quickly overwhelm the server.\",\n      \"The overhead involved in process creation can be reduced by techniques such as FastCGI that \\\\\"prefork\\\\\" interpreter processes, or by running the application code entirely within the web server, using extension modules such as mod_perl or mod_php.\",\n      \"Another way to reduce the overhead is to use precompiled CGI programs, e.g.\",\n      \"by writing them in languages such as C or C++, rather than interpreted or compiled-on-the-fly languages such as Perl or PHP, or by implementing the page generating software as a custom webserver module.\",\n      \"Several approaches can be adopted for remedying this: \\\\n1. Implementing stricter regulations\\\\n2. Providing better education and training\\\\n3. Enhancing technology and infrastructure\\\\n4. Increasing funding and resources\\\\n5. Promoting collaboration and partnerships\\\\n6. Conducting regular audits and assessments\",\n      \"The optimal configuration for any Web application depends on application-specific details, amount of traffic, and complexity of the transaction; these tradeoffs need to be analyzed to determine the best implementation for a given task and time budget.\"\n    ]\n  ],\n  \"topics\": [\n    \"Common Gateway Interface in Web Servers\",\n    \"The History and Standardization of CGI\",\n    \"CGI Scripts for Editing Web Pages\",\n    \"Reducing Web Server Overhead in Command Invocation\"\n  ],\n  \"summaries\": [\n    \"CGI 為網頁伺服器提供了一個執行動態生成網頁程式的標準協議。\",\n    \"NCSA 在 1993 年首次定義了 CGI，隨後它成為網頁伺服器的標準，並在 Ken Coar 的主持下正式化為 RFC 3875。\",\n    \"本文描述了 CGI 腳本如何透過 HTML 表單處理網頁內容的編輯和保存。\",\n    \"本文討論了減少頻繁命令調用所造成的伺服器開銷的技術，包括進程預分叉、使用預編譯的 CGI 程式，以及實現自訂網頁伺服器模組。\"\n  ]\n}\n</code></pre><p>我們也透過洗牌資料、加入隨機字元/單詞/字母、隨機移除標點符號，並且一律移除換行字元來增加噪聲。</p><p>所有這些方法都能在一定程度上幫助開發出一個好的模型 - 但還不夠。為了真正發揮所有潛力，我們需要模型能夠產生連貫的片段而不破壞程式碼片段。為此，我們使用 GPT-4o 生成的程式碼、公式和列表來增強資料集。</p><h3 id=\"the-training-setup\">訓練設置</h3><p>為了訓練這些模型，我們實施了以下設置：</p><ul><li><strong>框架</strong>：我們使用了 Hugging Face 的 <code>transformers</code> 函式庫，並整合了 <code>Unsloth</code> 來進行模型優化。這對於優化記憶體使用和加速訓練至關重要，使我們能夠有效地使用大型資料集來訓練小型模型。</li><li><strong>優化器和調度器</strong>：我們使用了 AdamW 優化器和線性學習率調度器，並設定預熱步驟，這讓我們能夠在初始訓練階段穩定訓練過程。</li><li><strong>實驗追蹤</strong>：我們使用 <a href=\"https://wandb.ai/?ref=jina-ai-gmbh.ghost.io\">Weights & Biases</a> 追蹤所有訓練實驗，並記錄關鍵指標如訓練和驗證損失、學習率變化以及整體模型表現。這種即時追蹤讓我們能夠洞察模型的進展情況，必要時能快速調整以優化學習成果。</li></ul><h3 id=\"the-training-itself\">訓練過程</h3><p>以 <a href=\"https://huggingface.co/Qwen/Qwen2-0.5B-Instruct?ref=jina-ai-gmbh.ghost.io\"><code>qwen2-0.5b-instruct</code></a> 作為基礎模型，我們使用 Unsloth 訓練了三種 SLM 變體，每一種都針對不同的分段策略。對於我們的樣本，我們使用訓練對，包含來自 wiki727k 的文章文本，以及根據所訓練的模型產生的 <code>sections</code>、<code>topics</code> 或 <code>summaries</code>（如上述「資料增強」部分所提）。</p><ul><li><code><strong>simple-qwen-0.5</strong></code>：我們使用 10,000 個樣本訓練了 5,000 步的 <code>simple-qwen-0.5</code>，實現了快速收斂並能有效檢測文本連貫段落間的邊界。訓練損失為 0.16。</li><li><code><strong>topic-qwen-0.5</strong></code>：與 <code>simple-qwen-0.5</code> 類似，我們使用 10,000 個樣本訓練了 5,000 步的 <code>topic-qwen-0.5</code>，達到了 0.45 的訓練損失。</li><li><code><strong>summary-qwen-0.5</strong></code>：我們使用 30,000 個樣本訓練了 15,000 步的 <code>summary-qwen-0.5</code>。這個模型展現出潛力，但在訓練過程中有較高的損失（0.81），這表明需要更多的資料（大約是原始樣本數量的兩倍）才能發揮其全部潛力。</li></ul><h2 id=\"the-segments-themselves\">分段結果</h2><p>以下是每種分段策略的三個連續段落示例，以及 Jina 的 Segmenter API。為了產生這些段落，我們首先使用 <a href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> 從 Jina AI blog 抓取一篇文章的純文本（包含所有頁面資料，如頁首、頁尾等），然後將其傳遞給每種分段方法。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/can-embedding-reranker-models-compare-numbers/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Can Embedding/Reranker Models Compare Numbers?</div><div class=\"kg-bookmark-description\">A lot of LLMs can't figure out that 9.11 is actually smaller than 9.9. Can our embedding and reranker models do any better?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/07/number-heading.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"jina-segmenter-api\">Jina Segmenter API</h3><p>Jina Segmenter API 採用了非常精細的分段方式，通過像 <code>\\n</code>、<code>\\t</code> 等字元來切分文本，通常會產生非常小的段落。僅看前三個段落，它從網站的導航欄中提取了 <code>search\\\\n</code>、<code>notifications\\\\n</code> 和 <code>NEWS\\\\n</code>，但沒有提取任何與文章內容相關的內容：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-1.png\" class=\"kg-image\" alt=\"Minimalist navigation bar with &quot;NEWS&quot;, &quot;PRODUCTS&quot;, and &quot;COMPANY&quot; text on a black background, accented by colorful stripes to \" loading=\"lazy\" width=\"1164\" height=\"68\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-1.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><p>再往後，我們終於獲得了一些來自實際部落格文章內容的段落，但每個段落保留的上下文很少：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-2.png\" class=\"kg-image\" alt=\"Webpage discussing if embedding/reranker models can compare numbers, with a grid of numbered circles and references to an ICM\" loading=\"lazy\" width=\"1164\" height=\"1180\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-2.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><p>（為了公平起見，我們展示了比其他模型更多的 Segmenter API 片段，主要是因為若不這樣做，就會只有很少有意義的段落可以展示）</p><h3 id=\"simple-qwen-05\"><code>simple-qwen-0.5</code></h3><p><code>simple-qwen-0.5</code> 根據語義結構將部落格文章分解成更長的段落，每個段落都有連貫的含義：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-3.png\" class=\"kg-image\" alt=\"Webpage screenshot with green background, top navigation bar, scientific graphs, and headers discussing model number comparis\" loading=\"lazy\" width=\"1164\" height=\"4590\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-3.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"topic-qwen-05\"><code>topic-qwen-0.5</code></h3><p><code>topic-qwen-0.5</code> 首先根據文件內容識別主題，然後基於這些主題對文件進行分段：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-4.png\" class=\"kg-image\" alt=\"Webpage showcasing a scientific paper titled &quot;Can Embedding/Keras Models Compare Numbers?&quot; featuring plots, text blocks, and \" loading=\"lazy\" width=\"1164\" height=\"4526\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-4.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"summary-qwen-05\"><code>summary-qwen-0.5</code></h3><p><code>summary-qwen-0.5</code> 識別段落邊界並為每個段落中的內容生成摘要：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-5.png\" class=\"kg-image\" alt=\"Green and gold-themed academic webpage discussing embedding/reranker models and experiment setup.\" loading=\"lazy\" width=\"1164\" height=\"3734\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-5.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"benchmarking-the-models\">模型基準測試</h2><p>為了對我們的模型進行基準測試，我們從 Jina AI 部落格抓取了八篇部落格文章，並使用 GPT-4o 生成了六個問題和標準答案。</p><p>我們對這些部落格文章應用了每種分段方法，包括 Jina Segmenter API，然後使用 <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\"><code>jina-embeddings-v3</code></a> 為產生的段落生成嵌入向量，不進行後期分塊或重新排序。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class=\"kg-bookmark-description\">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>之後，我們分別對每組段落進行索引，並使用 RAG 系統透過先前生成的問題查詢每個索引。</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">為了確保公平比較，在測試 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">topic-qwen-0.5</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">summary-qwen-0.5</code> 時，我們僅對段落本身建立索引，<i><em class=\"italic\" style=\"white-space: pre-wrap;\">而非</em></i>生成的摘要或主題。索引這些額外資料可能會進一步提升效能。</div></div><p>為了衡量效能，我們使用 <a href=\"https://en.wikipedia.org/wiki/ROUGE_(metric)?ref=jina-ai-gmbh.ghost.io\">ROUGE-L 評估</a>的 F1 分數，比較每種分段方法索引生成的答案與標準答案，分數越高代表效能越好。</p><p>例如，針對問題：\"什麼因素影響 <code>jina-embeddings-v2-base-en</code> 模型的數字比較能力？\"，我們收到以下答案：</p><h3 id=\"ground-truth-generated-by-gpt-4o-from-the-full-post-text\">標準答案（由 GPT-4o 從完整文章生成）：</h3><pre><code>\"The two key factors are tokenization and training data. Tokenization determines how numbers are segmented into tokens, and training data influences numerical reasoning abilities.\"\n</code></pre><h3 id=\"jina-segmenter-api-score-0166667\">Jina Segmenter API（分數：0.166667）</h3><pre><code>\"The context does not provide specific factors that impact the numerical comparison abilities of the jina-embeddings-v2-base-en model.\"\n</code></pre><h3 id=\"simple-qwen-05-score-0279070\"><code>simple-qwen-0.5</code>（分數：0.279070）</h3><pre><code>\"The numerical comparison abilities of the jina-embeddings-v2-base-en model are impacted by tokenization and training data.\"\n</code></pre><h3 id=\"topic-qwen-05-score-0190476\"><code>topic-qwen-0.5</code>（分數：0.190476）</h3><pre><code>\"The numerical comparison abilities of the jina-embeddings-v2-base-en model are impacted by factors such as tokenization and its ability to handle different numerical formats, including small integers, large numbers, floats, negative numbers, currency, dates, and times.\"\n</code></pre><h3 id=\"summary-qwen-05-0318182\"><code>summary-qwen-0.5</code>（0.318182）</h3><pre><code>\"The factors impacting the numerical comparison abilities of the jina-embeddings-v2-base-en model are tokenization and training data.\"\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\"><b><strong style=\"white-space: pre-wrap;\">為什麼 </strong></b><b><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><strong>topic-qwen-0.5</strong></code></b><b><strong style=\"white-space: pre-wrap;\"> 的分數這麼低？</strong></b><br>這主要是因為我們問的這個特定問題而產生的偶然結果。如下表所示，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">topic-qwen-0.5</code> 的<i><em class=\"italic\" style=\"white-space: pre-wrap;\">平均</em></i> ROUGE 分數是所有分段方法中最高的。</div></div><p>我們還評估了每種方法的速度（透過計時生成和嵌入段落所需的時間），並估算了磁碟空間（將嵌入數量乘以 <code>jina-embeddings-v3</code> 中單個 1024 維嵌入的大小）。這使我們能夠評估不同分段策略的準確性和效率。</p><h2 id=\"key-findings\">重要發現</h2><p>在將模型變體相互比較並與 Jina 的 Segmenter API 進行測試後，我們發現新模型確實在所有三種方法中都表現出更好的分數，特別是主題分段：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-7.png\" class=\"kg-image\" alt=\"比較 Jina Segmenter、Simple、COATopic 和 Summary Segmentation 平均 ROUGE 分數的長條圖\" loading=\"lazy\" width=\"1690\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-7.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-7.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-7.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-7.png 1690w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>分段方法</strong></th>\n<th><strong>平均 ROUGE 分數</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina Segmenter</td>\n<td>0.352126</td>\n</tr>\n<tr>\n<td><code>simple-qwen-0.5</code></td>\n<td>0.386096</td>\n</tr>\n<tr>\n<td><code>topic-qwen-0.5</code></td>\n<td><strong>0.398340</strong></td>\n</tr>\n<tr>\n<td><code>summary-qwen-0.5</code></td>\n<td>0.328143</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">為什麼 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">summary-qwen-0.5</code> 的 ROUGE 分數比 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">topic-qwen-0.5</code> 低？簡單來說，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">summary-qwen-0.5</code> 在訓練過程中顯示出較高的損失，表明需要更多訓練才能獲得更好的結果。這可能是未來實驗的主題。</div></div><p>不過，使用 <code>jina-embeddings-v3</code> 的延遲分段功能來審查結果會很有趣，因為它增加了段落嵌入的上下文相關性，提供更相關的結果。這可能會成為未來部落格文章的主題。</p><p>關於速度，很難將新模型與 Jina Segmenter 進行比較，因為後者是一個 API，而我們是在 Nvidia 3090 GPU 上運行這三個模型。如你所見，Segmenter API 雖然在分段步驟中速度很快，但因為需要為大量段落生成嵌入而很快就被超越了：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-8.png\" class=\"kg-image\" alt=\"顯示文本分段方法時間的長條圖：Jina Segmenter、Simple、CoT Topic 和 Summary Segmentation\" loading=\"lazy\" width=\"1682\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-8.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-8.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-8.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-8.png 1682w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-9.png\" class=\"kg-image\" alt=\"顯示 Jina Segmenter、Simple、CoT Topic 和 Summary Segmentation 嵌入時間的垂直長條圖\" loading=\"lazy\" width=\"1698\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-9.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-9.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-9.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-9.png 1698w\" sizes=\"(min-width: 720px) 720px\"></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\"><b><strong style=\"white-space: pre-wrap;\">注意事項</strong></b><br>• 我們在兩個圖表中使用不同的 Y 軸，因為用一個圖表或一致的 Y 軸呈現如此不同的時間範圍是不可行的。<br>• 由於這純粹是一個實驗，我們在生成嵌入時沒有使用批次處理。使用批次處理會大幅加快所有方法的運行速度。</div></div><p>自然地，更多的段落意味著更多的嵌入。而這些嵌入佔用了大量空間：我們測試的八篇部落格文章的嵌入使用 Segmenter API 時佔用超過 21 MB，而摘要分段僅佔用 468 KB。這加上我們模型的較高 ROUGE 分數意味著更少但更好的段落，節省成本並提高效能：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-6.png\" class=\"kg-image\" alt=\"Vertical bar chart comparing total embedding size of segmentation methods, with &quot;Jina Segmenter&quot; significantly higher at 20.0\" loading=\"lazy\" width=\"1690\" height=\"1079\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-6.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-6.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-6.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-6.png 1690w\" sizes=\"(min-width: 720px) 720px\"></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>Segmentation Method</strong></th>\n<th><strong>Segment Count</strong></th>\n<th><strong>Average Length (characters)</strong></th>\n<th><strong>Segmentation Time (minutes/seconds)</strong></th>\n<th><strong>Embedding Time (hours/minutes)</strong></th>\n<th><strong>Total Embedding Size</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina Segmenter</td>\n<td>1,755</td>\n<td>82</td>\n<td>3.8s</td>\n<td>1h 46m</td>\n<td>21.06 MB</td>\n</tr>\n<tr>\n<td><code>simple-qwen-0.5</code></td>\n<td>48</td>\n<td>1,692</td>\n<td>49s</td>\n<td>1h 2m</td>\n<td>576 KB</td>\n</tr>\n<tr>\n<td><code>topic-qwen-0.5</code></td>\n<td>69</td>\n<td>1,273</td>\n<td>2m 3s</td>\n<td>1h 6m</td>\n<td>828 KB</td>\n</tr>\n<tr>\n<td><code>summary-qwen-0.5</code></td>\n<td>39</td>\n<td>1,799</td>\n<td>2m 40s</td>\n<td>53m</td>\n<td>468 KB</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"what-we-learned\">我們學到了什麼</h3><h3 id=\"problem-formulation-is-critical\">問題定義至關重要</h3><p>一個關鍵洞察是我們如何構建任務的影響。通過讓模型輸出片段標題，我們通過關注語義轉換而不是簡單地將輸入內容複製粘貼到不同片段中，改善了邊界檢測和連貫性。這也使分段模型更快，因為生成較少的文本讓模型能更快完成任務。</p><h3 id=\"llm-generated-data-is-effective\">LLM 生成的數據很有效</h3><p>使用 LLM 生成的數據，特別是對於列表、公式和程式碼片段等複雜內容，擴大了模型的訓練集，並改善了其處理不同文檔結構的能力。這使模型在處理各種內容類型時更具適應性，這在處理技術或結構化文檔時是一個關鍵優勢。</p><h3 id=\"output-only-data-collation\">僅輸出數據整理</h3><p>通過使用僅輸出的<a href=\"https://huggingface.co/docs/transformers/en/main_classes/data_collator?ref=jina-ai-gmbh.ghost.io\">數據整理器</a>，我們確保模型在訓練期間專注於預測目標 token，而不是僅僅從輸入中複製。僅輸出的整理器確保模型從實際目標序列中學習，強調正確的補全或邊界。這種區別通過避免對輸入過度擬合使模型更快收斂，並幫助它在不同數據集間更好地泛化。</p><h3 id=\"efficient-training-with-unsloth\">使用 Unsloth 進行高效訓練</h3><p>使用 <a href=\"https://github.com/unslothai/unsloth?ref=jina-ai-gmbh.ghost.io\">Unsloth</a>，我們簡化了小型語言模型的訓練，成功在 Nvidia 4090 GPU 上運行它。這種優化的流程讓我們能夠訓練出高效能的模型，而無需龐大的計算資源。</p><h3 id=\"handling-complex-texts\">處理複雜文本</h3><p>分段模型在處理包含程式碼、表格和列表的複雜文檔方面表現出色，這些通常對傳統方法來說很困難。對於技術內容，像 <code>topic-qwen-0.5</code> 和 <code>summary-qwen-0.5</code> 這樣的複雜策略更有效，有潛力提升下游的 RAG 任務。</p><h3 id=\"simple-methods-for-simpler-content\">簡單方法用於更簡單的內容</h3><p>對於簡單的、敘事驅動的內容，像 Segmenter API 這樣的簡單方法通常就足夠了。高級分段策略可能只在處理更複雜的結構化內容時才需要，這使得根據使用場景可以靈活選擇。</p><h2 id=\"next-steps\">下一步</h2><p>雖然這個實驗主要是作為概念驗證而設計的，但如果我們要進一步擴展它，我們可以做幾項改進。首先，儘管這個特定實驗不太可能繼續，但在更大的數據集上訓練 <code>summary-qwen-0.5</code>—理想情況下是 60,000 個樣本而不是 30,000 個—可能會帶來更理想的性能。此外，改進我們的基準測試流程也會有幫助。我們不會評估 RAG 系統生成的 LLM 答案，而是專注於將檢索的片段直接與真實值進行比較。最後，我們會超越 ROUGE 分數，採用更先進的指標（可能是 ROUGE 和 LLM 評分的組合）來更好地捕捉檢索和分段質量的細微差別。</p><h2 id=\"conclusion\">結論</h2><p>在這個實驗中，我們探索了為特定任務設計的自定義分段模型如何提升 RAG 的性能。通過開發和訓練像 <code>simple-qwen-0.5</code>、<code>topic-qwen-0.5</code> 和 <code>summary-qwen-0.5</code> 這樣的模型，我們解決了傳統分段方法中的關鍵挑戰，特別是在維持語義連貫性和有效處理程式碼片段等複雜內容方面。在測試的模型中，<code>topic-qwen-0.5</code> 持續提供最有意義和上下文相關的分段，尤其是對於多主題文檔。</p><p>雖然分段模型為 RAG 系統提供了必要的結構基礎，但它們與後期分塊的功能不同，後者通過維持片段間的上下文關聯性來優化檢索性能。這兩種方法可以互補，但當你需要一種專注於為連貫的、特定任務的生成工作流分割文檔的方法時，分段特別重要。</p>",
  "comment_id": "67126986708dbe00019249f2",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/breakpoints.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-18T15:58:30.000+02:00",
  "updated_at": "2024-10-25T20:14:53.000+02:00",
  "published_at": "2024-10-25T10:35:07.000+02:00",
  "custom_excerpt": "We trained three small language models to better segment long documents into chunks, and here are the key lessons we learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ade4a3e4e55003d525971",
      "name": "Alex C-G",
      "slug": "alexcg",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
      "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
      "website": null,
      "location": "Berlin, Germany",
      "facebook": null,
      "twitter": "@alexcg",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    },
    {
      "id": "64ae64a4733bc60001949ca4",
      "name": "Andrei Ungureanu",
      "slug": "andrei",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/07/Me.jpg",
      "cover_image": null,
      "bio": "Software / AI Engineer, with a passion for content creation.",
      "website": null,
      "location": "Beijing, China",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/andrei/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ade4a3e4e55003d525971",
    "name": "Alex C-G",
    "slug": "alexcg",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
    "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
    "website": null,
    "location": "Berlin, Germany",
    "facebook": null,
    "twitter": "@alexcg",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/finding-optimal-breakpoints-in-long-documents-using-small-language-models/",
  "excerpt": "我們訓練了三個小型語言模型來更好地將長文件分割成區塊，以下是我們學到的重要經驗。",
  "reading_time": 19,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "A pattern of yellow file icons on a blue background with one icon displaying a smiley face creating an emotive contrast.",
  "feature_image_caption": null
}