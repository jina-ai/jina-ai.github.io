{
  "slug": "fair-scoring-for-multimodal-documents-with-jina-reranker-m0",
  "id": "682b34d62caa92000178b523",
  "uuid": "434b7cc3-713d-4f2e-843a-6270f0e27604",
  "title": "使用 jina-reranker-m0 為多模態文件進行公平評分",
  "html": "<p>假設您正在建立一個體育新聞搜尋系統。使用者搜尋「網球選手慶祝冠軍勝利」，而您需要從資料庫中找到最相關的文章。每篇文章都包含文字說明和圖片——這是現代體育報導的典型特徵。</p><p>您的系統需要接收一個<strong>文字查詢 (text query)</strong>，並從您的語料庫中返回一個<strong>排序過的、最相關的多模態文檔 (ranked list of the most relevant multimodal documents)</strong>列表。聽起來很簡單，但這裡存在一個根本性的問題，它打破了所有顯而易見的方法。</p><p>以下是您嘗試對這些文檔進行排序時會發生的情況。您的 向量模型 (Embeddings) 比如說 <code>jina-clip-v2</code> 會產生如下的相似度分數：</p>\n<!--kg-card-begin: html-->\n<table>\n    <thead>\n        <tr>\n            <th>文章</th>\n            <th>內容類型</th>\n            <th>描述</th>\n            <th>相似度分數</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>A</td>\n            <td>文字</td>\n            <td>諾瓦克·喬科維奇在澳洲網球公開賽決賽中直落三盤獲勝</td>\n            <td>0.72</td>\n        </tr>\n        <tr>\n            <td>A</td>\n            <td>圖片</td>\n            <td>[球員手持獎盃微笑的照片]</td>\n            <td>0.31</td>\n        </tr>\n        <tr>\n            <td>B</td>\n            <td>文字</td>\n            <td>天氣延誤影響戶外錦標賽賽程</td>\n            <td>0.23</td>\n        </tr>\n        <tr>\n            <td>B</td>\n            <td>圖片</td>\n            <td>[網球選手跳躍慶祝的照片]</td>\n            <td>0.54</td>\n        </tr>\n    </tbody>\n</table>\n<!--kg-card-end: html-->\n<p>哪篇文章更相關？文章 A 的文字分數很高，但圖片分數很低。文章 B 的文字分數很低，但圖片分數較高。根本的挑戰在於，<strong>您無法比較 0.72（文字）和 0.54（圖片）</strong>，因為這些相似度分數存在於完全不同的尺度上。</p><h2 id=\"when-trivial-solutions-fail\">當簡單的解決方案失敗時</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The What and Why of Text-Image Modality Gap in CLIP Models</div><div class=\"kg-bookmark-description\">You can’t just use a CLIP model to retrieve text and images and sort the results by score. Why? Because of the modality gap. What is it, and where does it come from?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-32.png\" alt=\"\"><span class=\"kg-bookmark-author\">Jina AI</span><span class=\"kg-bookmark-publisher\">Bo Wang, Scott Martens</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/the-what-and-why-of-text-image-modality-gap-in-clip-models.webp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><strong>由於 <code>jina-clip-v2</code> 或幾乎所有其他類似 CLIP 的模型中存在模態差距 (modality gap)</strong>，您可能嘗試的任何顯而易見的方法都行不通。如果您僅使用較高的分數，您會遇到文字分數聚集在 0.2-0.8 之間，而圖片分數聚集在 0.4-0.6 之間的事實。這意味著平庸的文字匹配（0.6）總是會勝過優秀的圖片匹配（0.5）。</p><p>平均分數也無濟於事。計算 (0.7 + 0.3)/2 = 0.5 給你一個數字，但它實際上意味著什麼？您正在平均一些根本沒有意義的量。同樣，任何固定的加權方案都是任意的——有時文字更重要，有時圖片更重要，這完全取決於具體的查詢 (Prompt) 和文檔。</p><p>即使首先對分數進行歸一化也無法解決核心問題。您仍然試圖組合根本不同的相似性度量，這些度量捕捉了相關性的不同方面。</p><h2 id=\"what-actually-happens\">實際發生了什麼</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2305.13631\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">EDIS: Entity-Driven Image Search over Multimodal Web Content</div><div class=\"kg-bookmark-description\">Making image retrieval methods practical for real-world search applications requires significant progress in dataset scales, entity comprehension, and multimodal information fusion. In this work, we introduce \\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch (EDIS), a challenging dataset for cross-modal image search in the news domain. EDIS consists of 1 million web images from actual search engine results and curated datasets, with each image paired with a textual description. Unlike datasets that assume a small set of single-modality candidates, EDIS reflects real-world web image search scenarios by including a million multimodal image-text pairs as candidates. EDIS encourages the development of retrieval models that simultaneously address cross-modal information fusion and matching. To achieve accurate ranking results, a model must: 1) understand named entities and events from text queries, 2) ground entities onto images or text descriptions, and 3) effectively fuse textual and visual representations. Our experimental results show that EDIS challenges state-of-the-art methods with dense entities and a large-scale candidate set. The ablation study also proves that fusing textual features with visual features is critical in improving retrieval results.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-20.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Siqi Liu</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-16.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>為了更好地了解我們正在處理的問題，這裡有一個來自 <a href=\"https://arxiv.org/abs/2305.13631\">EDIS 數據集</a>的文檔範例，展示了圖片（一場德國足球比賽）和標題（<code>One More Field Where the Content Trails Germany</code>）。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"928\" height=\"261\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-1.png 928w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 1：包含圖片和文字內容的多模態文檔範例。由於我們有兩種模態，對於任何給定的查詢 (Prompt)，現在都有</span><i><em class=\"italic\" style=\"white-space: pre-wrap;\">兩個</em></i><span style=\"white-space: pre-wrap;\">語義差距（查詢 (Prompt) 和文字之間，以及查詢 (Prompt) 和圖片之間）。為了獲得最佳結果，我們應該搜尋文檔的文字內容，還是圖片內容？</span></figcaption></figure><p>總體而言，<code>jina-clip-v2</code> 在比較查詢 (Prompt) 到文字時顯示出比查詢 (Prompt) 到圖片更高的相似度，部分原因是模型的訓練方式，部分原因是數據集本身：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"964\" height=\"679\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-2.png 964w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 2：使用 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">時，查詢 (Prompt) 到圖片（紅色）和查詢 (Prompt) 到文字（藍色）之間的相似度分數。</span></figcaption></figure><p>因此，根據文檔的文字而不是圖片來檢索文檔似乎是合乎邏輯的。而且，正如我們在下面的圖形中看到的那樣，當我們將文字查詢 (Prompt) <code>... for undocumented immigrants helping to establish legal status in the United States</code> 與語料庫的文字內容進行比較時，我們獲得了更好的結果。事實上，按圖片搜尋根本無法檢索到真實文檔（黃色突出顯示）：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1767\" height=\"2454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-3.png 1767w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 3：當使用 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\"> 為 3 時，只能通過 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> 的查詢 (Prompt) 到文字檢索來檢索真實文檔（黃色邊框突出顯示）的範例。</span></figcaption></figure><p>但不要被愚弄了。儘管查詢 (Prompt) 到文字顯示出更高的相似度分數，但查詢 (Prompt) 到文字和查詢 (Prompt) 到圖片的相似度分數<em>並</em>不具有可比性。當我們使用 <code>jina-clip-v2</code> 從 EDIS 數據集中檢索 32 個文檔時，我們可以通過查看 recall@10 來看到這一點。顯然，通過查詢 (Prompt) 到<em>圖片</em>，召回率更高：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Recall@10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Query-to-text</td>\n<td>14.55</td>\n</tr>\n<tr>\n<td>Query-to-image</td>\n<td><strong>22.38</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>我們可以在下面看到：如果我們使用來自數據集的查詢 (Prompt)：<code>Ear ear An elephant is decorated with Bhartiya Janta Party symbols near the BJP headquarters in New Delhi.</code>，我們只能通過其圖片內容來檢索真實文檔。通過其文字內容進行搜尋不會返回任何匹配項：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1753\" height=\"2454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-4.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-4.png 1753w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 4：當使用 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\"> 為 3 時，只能通過 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> 的查詢 (Prompt) 到圖片檢索來檢索真實文檔（黃色邊框突出顯示）的範例。</span></figcaption></figure><p>所以，如果相似度分數表示我們應該從文字中檢索文件，而召回率表示我們應該從圖像中檢索文件，我們應該選擇哪個？當然，圖 3 和圖 4 表明沒有明顯的勝出者。哪種模態<em>真正</em>呈現了我們的查詢和我們正在尋找的文件之間最接近的匹配？如果我們想要合併來自<em>文字查詢</em>和<em>圖像查詢</em>檢索的候選結果，如果我們甚至無法比較分數，我們該如何有意義地選擇最佳匹配？顯然，僅僅使用 <code>jina-clip-v2</code> 是不行的。我們需要投入另一個模型來解決這個問題。</p><h2 id=\"a-simple-two-stage-pipeline\">一個簡單的兩階段流程</h2><p>在 2025 年 4 月，我們發布了 <code>jina-reranker-m0</code>，這是一個用於檢索視覺文件的多語言多模態重排器 (Reranker)。我們可以在下面看到它較窄的模態差距，其中 <code>jina-reranker-m0</code> 顯示了可比較的文字查詢和圖像查詢相似度分數，這與 <code>jina-clip-v2</code> 顯示的更大差距形成對比：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"964\" height=\"679\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png 964w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 6：與 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> 相比，</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> 在文字查詢（紅色）和圖像查詢（藍色）相似度分數之間顯示的差異要小得多。</span></figcaption></figure><p>考慮到這一點，我們可以使用 <code>jina-reranker-m0</code> 在檢索鏈中進行第二輪處理，在從 <code>jina-clip-v2</code> 檢索到初始結果之後：</p><p><strong>階段 1：從兩種模態檢索候選結果</strong></p><ul><li>使用 <code>jina-clip-v2</code> 通過文字搜索獲得 16 個文件 + 通過圖像搜索獲得 16 個文件</li><li>接受我們還無法比較分數的事實</li></ul><p><strong>階段 2：統一重排序</strong></p><ul><li>將每個（查詢 + 完整文件）對輸入到 <code>jina-reranker-m0</code> 中</li><li>重排器 (Reranker) 同時處理文字和圖像</li><li>輸出：統一尺度上的單一相關性分數</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-5.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1305\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-5.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-5.png 2048w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 5：使用 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> 和 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> 索引多模態文件和兩階段多模態檢索過程。</span></figcaption></figure><p>我們擴展了表 1 中的實驗，現在使用 <code>jina-clip-v2</code> 從語料庫中檢索文件，然後使用 <code>jina-reranker-m0</code> 對它們進行重排序：</p><ol><li>通過文字查詢檢索 32 個文件，然後根據文字查詢分數進行重排序。</li><li>通過圖像查詢檢索 32 個文件，然後根據圖像查詢分數進行重排序。</li><li>通過文字查詢檢索 16 個文件，通過圖像查詢檢索 16 個文件。根據查詢模態，基於文字查詢或圖像查詢分數進行重排序。</li><li>通過文字查詢檢索 16 個文件，通過圖像查詢檢索 16 個文件。根據每個文件的平均文字查詢和圖像查詢分數進行重排序，得出最終分數（文字查詢 + 圖像查詢）/2。</li></ol><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">請注意，我們正在測量 EDIS 上的零樣本效能。我們沒有使用該數據集微調 <code>jina-clip-v2</code> 或 <code>jina-reranker-m0</code>。</div></div>\n<!--kg-card-begin: html-->\n\n<table>\n  <thead>\n    <tr>\n      <th>Experiment</th>\n      <th>Description</th>\n      <th>Recall@10 - with jina-clip-v2</th>\n      <th>Recall@10 - with jina-reranker-m0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>32 docs: query-to-text</td>\n      <td>14.55</td>\n      <td>17.42</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>32 docs: query-to-image</td>\n      <td>22.38</td>\n      <td>28.94</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>16 docs: query-to-text<br>16 docs: query-to-image</td>\n      <td>14.55</td>\n      <td>33.81</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>16 docs: query-to-text<br>16 docs: query-to-image<br>Combined average reranker scores</td>\n      <td>14.55</td>\n      <td><strong>36.24</strong></td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">由於文字查詢分數高於圖像查詢分數，實驗 1、3 和 4 在使用 <code>jina-clip-v2</code> 時，召回率 @10 均顯示相同的結果。因此，前十名的結果主要由通過文字檢索的文件組成。</div></div><p>正如我們所看到的，通過使用 <code>jina-reranker-m0</code> 執行第二輪處理，召回率全面提高，而<strong>當我們結合來自檢索文件的文字和圖像內容時，我們看到了最大的增長</strong>，達到了 36.24 的召回率 @10。一個視覺範例顯示，無論搜索文字還是圖像內容，<code>jina-reranker-m0</code> 始終將真實文件排在第一位：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/clip-vs-reranker.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1146\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/clip-vs-reranker.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/clip-vs-reranker.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/clip-vs-reranker.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/clip-vs-reranker.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">圖 7：每個重排序方法的樣本查詢（左側）和 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\"> 為 1 的結果（右側四列），顯示結合圖像和文字相似度分數始終將真實文件排在第一位。</span></figcaption></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">雖然圖 3 和圖 4 顯示了不同檢索方法的 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">top_k</code> 為 3，但由於空間原因，圖 7 僅顯示每個查詢的 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">top_k</code> 為 1。</div></div><h2 id=\"conclusions\">結論</h2><p>這種簡單的兩階段方法使召回率提高了 62%，因為該系統最終利用了人類自然的做法：同時考慮我們閱讀的內容和我們看到的內容來確定相關性。這個教訓不僅限於搜索：在處理多模態 AI 系統時，將模態分開處理的單階段方法始終會遇到這種評分不相容的問題。廣泛檢索然後智能排序的兩階段架構正變得至關重要。通過我們的 API 或在 AWS、GCP 和 Azure 上試用 <code>jina-reranker-m0</code>。</p>",
  "comment_id": "682b34d62caa92000178b523",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/fair-scoring.webp",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-19T15:40:38.000+02:00",
  "updated_at": "2025-05-25T08:26:31.000+02:00",
  "published_at": "2025-05-25T08:25:10.000+02:00",
  "custom_excerpt": "Text similarity: 0.7. Image similarity: 0.5. Which document is more relevant? You literally cannot tell—and that's the core problem breaking multimodal search. We solve it with unified reranking.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "678e14a78f6bb40001a63595",
      "name": "Nan Wang",
      "slug": "nan",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg",
      "cover_image": null,
      "bio": "Co-founder & CTO @JinaAI | Ex-Zalando & Tencent | Build AI models & systems | Open-source enthusiast | Speaker & contributor (40+ talks) | PhD in Computational Neuroscience @ Ruhr University Bochum",
      "website": null,
      "location": "Global",
      "facebook": null,
      "twitter": "@nanwang_t",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
    },
    {
      "id": "632ade4a3e4e55003d525971",
      "name": "Alex C-G",
      "slug": "alexcg",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
      "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
      "website": null,
      "location": "Berlin, Germany",
      "facebook": null,
      "twitter": "@alexcg",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "678e14a78f6bb40001a63595",
    "name": "Nan Wang",
    "slug": "nan",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg",
    "cover_image": null,
    "bio": "Co-founder & CTO @JinaAI | Ex-Zalando & Tencent | Build AI models & systems | Open-source enthusiast | Speaker & contributor (40+ talks) | PhD in Computational Neuroscience @ Ruhr University Bochum",
    "website": null,
    "location": "Global",
    "facebook": null,
    "twitter": "@nanwang_t",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fair-scoring-for-multimodal-documents-with-jina-reranker-m0/",
  "excerpt": "文本相似度：0.7。圖片相似度：0.5。哪個文件更相關？你根本無法判斷 —— 而這正是打破多模態搜尋的核心問題。我們透過統一重排 (Reranker) 來解決它。",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}