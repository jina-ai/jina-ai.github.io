{
  "slug": "when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse",
  "id": "6639e8e1af8f52000115be49",
  "uuid": "1b3da192-0050-4b9e-8528-c5e638d50870",
  "title": "當 AI 製造 AI：合成資料、模型蒸餾與模型崩塌",
  "html": "<p>對 AI 的討論經常帶有末世論調。部分原因在於<a href=\"https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping?ref=jina-ai-gmbh.ghost.io\">末世科幻作品</a>塑造了我們對人工智慧的印象。能夠製造更多機器的智慧機器，幾代以來一直是科幻小說中的常見主題。</p><p>許多人對近期 AI 發展帶來的存亡風險大聲疾呼，其中包括許多<a href=\"https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html?ref=jina-ai-gmbh.ghost.io\">參與 AI 商業化的企業領袖</a>，甚至一些<a href=\"https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/?ref=jina-ai-gmbh.ghost.io\">科學家</a>和<a href=\"https://www.lemonde.fr/en/international/article/2023/06/04/in-montreal-one-of-the-fathers-of-artificial-intelligence-warns-of-an-existential-threat-to-mankind_6029007_4.html?ref=jina-ai-gmbh.ghost.io\">研究人員</a>。這已成為 AI 炒作的一部分：如果某個東西強大到能讓看似冷靜的科技和產業標誌性人物都在擔憂世界末日，那它肯定也強大到能夠賺取利潤，對吧？</p><p>那麼，我們是否應該擔心 AI 帶來的存亡威脅？我們需要擔心 Sam Altman 會用 ChatGPT 製造出奧創，讓它的<a href=\"https://youtu.be/d4yZPjB7smU?ref=jina-ai-gmbh.ghost.io\">AI 軍隊向我們投擲東歐城市</a>嗎？我們應該擔心<a href=\"https://venturebeat.com/business/why-palantir-is-silicon-valleys-most-questionable-unicorn/?ref=jina-ai-gmbh.ghost.io\">Peter Thiel 的 Palantir</a> <a href=\"https://youtu.be/4DQsG3TKQ0I?ref=jina-ai-gmbh.ghost.io\">建造天網</a>並派遣<a href=\"https://youtu.be/wOO9DSnLOm8?ref=jina-ai-gmbh.ghost.io\">帶著難以解釋的奧地利口音的機器人回到過去殺死我們</a>嗎？</p><p>可能不用。業界領袖們至今尚未找到讓 AI 自負盈虧的明確方法，更別說顛覆產業了，更不用說對人類造成可與氣候變遷或核武器相比的威脅。</p><p>我們現有的 AI 模型離滅絕人類還差得遠。它們在繪畫手部時都有困難，無法數超過三個物件，認為<a href=\"https://www.nbcnewyork.com/news/local/nycs-ai-chatbot-was-caught-telling-businesses-to-break-the-law-the-city-isnt-taking-it-down/5287713/?ref=jina-ai-gmbh.ghost.io\">販賣被老鼠啃過的乳酪是可以接受的</a>，還會<a href=\"https://www.techtimes.com/articles/304222/20240502/ai-priest-demoted-saying-babies-baptized-gatorade.htm?ref=jina-ai-gmbh.ghost.io\">用佳得樂進行天主教洗禮</a>。AI 帶來的平凡、非存亡性的風險——比如技術可能助長誤導、騷擾、產生垃圾訊息，以及被不了解其限制的人錯誤使用——已經夠令人擔憂的了。</p><p>但人工智慧確實存在一個合理的存亡風險：AI 對....<em>AI 自身</em>構成明確而迫切的危險。</p><p>這種擔憂通常被稱為\"模型崩塌\"，並在 <a href=\"https://arxiv.org/abs/2305.17493?ref=jina-ai-gmbh.ghost.io\">Shumailov 等人（2023）</a>和 <a href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\">Alemohammad 等人（2023）</a>的研究中得到了有力的實證。這個概念很簡單：如果你用 AI 生成的數據來訓練 AI 模型，然後用這個結果再去訓練另一個模型，如此重複多代，AI 的表現會客觀上變得越來越差。這就像複印品的複印品再複印。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png\" class=\"kg-image\" alt=\"Deteriorating copies of an ad for the Intertec Superbrain, taken from BYTE magazine, Sept. 1981.\" loading=\"lazy\" width=\"1200\" height=\"400\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Superbrain.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Superbrain.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">取自 </span><a href=\"https://archive.org/details/byte-magazine-1981-09/page/n177/mode/2up\"><span style=\"white-space: pre-wrap;\">BYTE 雜誌 1981 年 9 月號</span></a><span style=\"white-space: pre-wrap;\">的 </span><a href=\"https://en.wikipedia.org/wiki/Intertec_Superbrain?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Intertec Superbrain</span></a><span style=\"white-space: pre-wrap;\"> 廣告逐漸劣化的複印效果。</span></figcaption></figure><p>最近有不少關於模型崩塌的討論，且<a href=\"https://www.businessinsider.com/ai-training-data-source-solutions-openai-meta-google-2024-4?ref=jina-ai-gmbh.ghost.io\">新聞標題</a><a href=\"https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?ref=jina-ai-gmbh.ghost.io\">開始出現</a> <a href=\"https://www.yahoo.com/news/ai-companies-running-training-data-220047540.html?guccounter=1&ref=jina-ai-gmbh.ghost.io\">關於 AI</a> <a href=\"https://www.businessinsider.com/ai-giants-openai-anthropic-running-out-of-good-training-data-2024-4?ref=jina-ai-gmbh.ghost.io\">用盡</a><a href=\"https://www.technologyreview.com/2022/11/24/1063684/we-could-run-out-of-data-to-train-ai-language-programs/?ref=jina-ai-gmbh.ghost.io\">數據</a>的報導。如果互聯網充斥著 AI 生成的數據，而人類製作的數據變得越來越難以識別和使用，那麼 AI 模型很快就會遇到品質上限。</p><p>同時，在 AI 開發中越來越多地使用<a href=\"https://en.wikipedia.org/wiki/Synthetic_data?ref=jina-ai-gmbh.ghost.io\">合成數據</a>和<a href=\"https://en.wikipedia.org/wiki/Knowledge_distillation?ref=jina-ai-gmbh.ghost.io\">模型蒸餾</a>技術。這兩種方法都包含使用其他 AI 模型的輸出來訓練 AI 模型。這兩個趨勢似乎相互矛盾。</p><p>事情比這更複雜。生成式 AI 會製造垃圾內容並阻礙自身進步嗎？或者 AI 會幫助我們製造更好的 AI？還是兩者都會發生？</p><p>我們將在本文中嘗試找到一些答案。</p><h2 id=\"model-collapse\">模型崩塌</h2><p>雖然我們很喜歡 Alemohammad 等人發明的\"模型自噬失調症（MAD）\"這個術語，但\"模型崩塌\"更朗朗上口，且不涉及希臘語中的自我吞噬含義。用複印品再複印的比喻簡單地闡述了這個問題，但背後的理論還有更多內容。</p><p>訓練 AI 模型是一種統計建模，是統計學家和數據科學家長期以來工作的延伸。但在數據科學課程的第一天，你就會學到數據科學家的座右銘：</p><blockquote><strong><em>所有模型都是錯的</em></strong>，<strong><em>但有些是有用的。</em></strong></blockquote><p>這句歸因於<a href=\"https://en.wikipedia.org/wiki/George_E._P._Box?ref=jina-ai-gmbh.ghost.io\">George Box</a> 的話，應該作為每個 AI 模型頂部的閃爍警示燈。你總可以為任何數據建立統計模型，該模型也總會給你一個答案，但絕對沒有任何保證這個答案是對的，甚至是接近正確的。</p><p>統計模型是某事物的<em>近似</em>。它的輸出可能有用，甚至可能足夠好，但它們仍然是近似值。即使你有一個經過良好驗證的模型，平均來說很準確，它仍然可能且很可能會偶爾犯大錯。</p><p>AI 模型繼承了統計建模的所有問題。任何玩過 ChatGPT 或其他大型 AI 模型的人都見過它犯錯。</p><p>所以，如果 AI 模型是某個真實事物的近似，那麼用另一個 AI 模型的輸出訓練的 AI 模型就是近似的近似。錯誤會累積，它本質上必然會比訓練它的模型更不準確。</p><p>Alemohammad 等人的研究表明，在訓練新的\"子代\"模型前，在 AI 輸出中添加一些原始訓練數據也無法解決這個問題。這只能減緩模型崩塌，無法阻止它。除非在使用 AI 輸出進行訓練時引入足夠的新的、之前未見過的真實世界數據，否則模型崩塌是不可避免的。</p><p>需要多少新數據才足夠取決於難以預測的、具體情況相關的因素，但新的、真實數據越多，AI 生成的數據越少總是更好。</p><p>這就是問題所在，因為所有容易獲取的人類製作的數據來源都已耗盡，而網路上 AI 生成的圖像和文字數據卻在快速增長。互聯網上人類製作與 AI 製作內容的比例正在下降，可能正在快速下降。沒有<a href=\"https://www.washingtonpost.com/technology/2023/06/02/turnitin-ai-cheating-detector-accuracy/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">可靠的方法自動檢測 AI 生成的數據</a>，且<a href=\"https://arxiv.org/abs/2303.11156?ref=jina-ai-gmbh.ghost.io\">許多研究人員</a><a href=\"https://www.techspot.com/news/98031-reliable-detection-ai-generated-text-impossible-new-study.html?ref=jina-ai-gmbh.ghost.io\">認為這是不可能的</a>。公眾對 AI 圖像和文字生成模型的使用確保了這個問題會不斷增長，很可能會劇烈增長，且沒有明顯的解決方案。</p><p><a href=\"https://www.vice.com/en/article/y3w4gw/a-shocking-amount-of-the-web-is-already-ai-translated-trash-scientists-determine?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">網路上機器翻譯的數量</a>可能意味著現在已經太遲了。機器翻譯的文本在網路上已經污染我們的數據來源多年，遠在生成式 AI 革命之前就已經存在。根據 <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">Thompson 等人（2024）</a>的研究，可能有一半的網路文本是從其他語言翻譯而來，而這些翻譯中有很大一部分品質低劣，並顯示出機器生成的跡象。這可能會扭曲從這些數據訓練出來的語言模型。</p><p>舉例來說，以下是<a href=\"https://ww1.habsburger.net/en/chapters/hamster-buying-queuing-do-it-yourself-individual-strategies-provide-food-become?ref=jina-ai-gmbh.ghost.io\">來自 <em>Die Welt der Habsburger</em> 網站的一個頁面截圖</a>，明顯可見機器翻譯的痕跡。\"Hamster buying\" 是德語單詞 <em>hamstern</em> 的過於直白的翻譯，其實際意思是<em>囤積</em>或<em>恐慌性購買</em>。太多這樣的實例會導致 AI 模型誤以為 \"hamster buying\" 是英語中的真實用語，並認為德語 <em>hamstern</em> 與寵物倉鼠有關。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.07.20.png\" loading=\"lazy\" width=\"1532\" height=\"1074\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.07.20.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1532w\" sizes=\"(min-width: 720px) 720px\"></figure><p>在幾乎所有情況下，訓練數據中包含更多 AI 輸出都是不利的。這裡的<em>幾乎</em>很重要，我們將在下面討論兩個例外。</p><h2 id=\"synthetic-data\">合成數據</h2><p>合成數據是人工生成而非來自真實世界的 AI 訓練或評估數據。<a href=\"https://doi.org/10.1007/978-3-030-75178-4?ref=jina-ai-gmbh.ghost.io\">Nikolenko（2021）</a>追溯合成數據的起源至 1960 年代的早期電腦視覺專案，並概述了它作為該領域重要元素的歷史。</p><p>使用合成數據有許多原因。其中最重要的一個是對抗偏見。</p><p>大型語言模型和圖像生成器因<a href=\"https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/?ref=jina-ai-gmbh.ghost.io\">偏見問題</a>而收到許多<a href=\"https://www.washington.edu/news/2023/11/29/ai-image-generator-stable-diffusion-perpetuates-racial-and-gendered-stereotypes-bias/?ref=jina-ai-gmbh.ghost.io\">高調的</a><a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">投訴</a>。\"偏見\"在統計學中有嚴格的定義，但這些投訴通常反映的是道德、社會和政治層面的考量，這些並沒有簡單的數學形式或工程解決方案。</p><p>不容易察覺的偏見更具破壞性，也更難修正。AI 模型學習複製的模式來自其訓練數據，當數據存在系統性缺陷時，偏見就不可避免。我們期望 AI 能做的事情越多──模型的輸入越多樣化──它就越有可能因為在訓練中沒有見過足夠的類似案例而出錯。</p><p>合成數據在當今 AI 訓練中的主要作用是確保訓練數據中包含足夠多某些特定情況的範例，這些情況在可用的自然數據中可能並不充足。</p><p>以下是 MidJourney 在接收 \"doctor\" 提示詞後生成的圖像：四個男性，三個白人，三個穿著白大褂並戴著聽診器，其中一個明顯年長。這並不反映大多數國家和情境中真實醫生的種族、年齡、性別或著裝，但可能反映了網路上可以找到的標記圖像。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--59-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--59-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--59-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>再次提示時，它生成了一個女性和三個男性，全都是白人，雖然其中一個是卡通形象。AI 有時確實很奇怪。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--60-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--60-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--60-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>這種特定的偏見是 AI 圖像生成器一直在試圖防止的，所以我們現在從相同系統得到的結果不像可能一年前那樣明顯帶有偏見。偏見仍然明顯存在，但什麼才是無偏見的結果並不明確。</p><p>不過，要弄清楚 AI 如何產生這些偏見並不難。以下是在 Shutterstock 圖片網站上搜索 \"doctor\" 時找到的前三張圖片：三個男性，其中兩個是年長的白人。AI 的偏見就是其訓練的偏見，如果你使用未經策劃的數據訓練模型，你總是會發現這些類型的偏見。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.21.21.png\" loading=\"lazy\" width=\"1740\" height=\"860\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1740w\" sizes=\"(min-width: 720px) 720px\"></figure><p>緩解這個問題的一種方法是使用 AI 圖像生成器來創建年輕醫生、女性醫生、有色人種醫生，以及穿著手術服、西裝或其他服裝的醫生的圖像，然後將它們納入訓練中。這樣使用的合成數據可以改善 AI 模型的表現，至少相對於某些外部標準而言，而不是導致模型崩潰。然而，人為扭曲訓練數據分佈可能會產生意想不到的副作用，<a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">就像 Google 最近發現的那樣</a>。</p><h2 id=\"model-distillation\">模型蒸餾</h2><p><a href=\"https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones/?ref=jina-ai-gmbh.ghost.io\">模型蒸餾</a>是一種直接從一個模型訓練另一個模型的技術。一個已訓練的生成模型──\"教師\"──創建所需的數據量來訓練一個未訓練或訓練較少的\"學生\"模型。</p><p>如你所料，\"學生\"模型永遠不可能比\"教師\"更好。乍看之下，這樣訓練模型似乎沒有意義，但這確實有其好處。主要的一個好處是\"學生\"模型可能比\"教師\"小得多、更快或更有效率，同時仍能近似其表現。</p><p>模型大小、訓練數據和最終表現之間的關係很複雜。然而，總的來說，在其他條件相同的情況下：</p><ol><li>更大的模型比小型模型表現更好。</li><li>使用更多或更好的訓練數據（或至少更多樣化的訓練數據）訓練的模型比使用較少或較差數據訓練的模型表現更好。</li></ol><p>這意味著小型模型有時可以表現得和大型模型一樣好。例如，<a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>jina-embeddings-v2-base-en</code></a> 在標準基準測試中明顯優於許多更大的模型：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Size in parameters</th>\n<th>MTEB average score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>jina-embeddings-v2-base-en</code></td>\n<td>137M</td>\n<td>60.38</td>\n</tr>\n<tr>\n<td><code>multilingual-e5-base</code></td>\n<td>278M</td>\n<td>59.45</td>\n</tr>\n<tr>\n<td><code>sentence-t5-xl</code></td>\n<td>1240M</td>\n<td>57.87</td>\n</tr>\n</tbody>\n</table>\n\n模型蒸餾是一種將大型模型（運行成本過高的模型）轉化為較小、較便宜模型的方法。每種情況下都會有一些性能損失，但在最佳情況下，這種損失可能非常小。\n\n考慮到大型 AI 模型的相關成本，這些好處相當可觀。蒸餾可以讓模型運行更快、在更便宜的晶片上運行、使用更少的記憶體，並消耗更少的電力。\n\n此外，大型模型可以從未經整理的數據中學習到非常微妙的模式，這些模式是小型模型永遠無法從相同數據中學習到的。大型模型然後可以產生比其訓練數據更多樣化的訓練數據，足以讓較小的模型學習相同的微妙模式。一旦你有了一個訓練好的大型模型，你就可以用它來「教導」較小的模型學習那些它單獨無法學習的內容。在這些情況下，蒸餾有時比使用真實訓練數據更好。\n\n## 那麼我們是否都在走向毀滅？\n\n也許吧。\n\n好消息是，如果沒有解決模型崩塌的方案，我們可能無法用目前使用的方法訓練出能夠消滅人類的超級智能 AI。我們可以安心地回去擔心氣候變化和核戰爭了。\n\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">如果前面那段話聽起來像是諷刺，那是故意的。</div></div>\n\n對 AI 產業來說，前景並不那麼樂觀。機器學習的座右銘一直是「<a href=\"https://towardsdatascience.com/ai-ml-practicalities-the-unreasonable-effectiveness-of-data-c0bfd44c5057?ref=jina-ai-gmbh.ghost.io\">更多數據就是更好的數據</a>」（有時是：「沒有比更多數據更好的數據」）。<a href=\"https://towardsdatascience.com/ai-ml-practicalities-more-data-isnt-always-better-ae1dac9ad28f?ref=jina-ai-gmbh.ghost.io\">統計學家都知道這是錯的</a>。常識也說這是錯的。但這個策略對 AI 研究人員來說一直都很有效，至少從我在 2000 年代初期開始從事機器翻譯研究以來就是如此。\n\n這是有原因的。多樣化的數據—包含許多不同可能性的數據—比統一的數據是更好的訓練來源。而在實際世界中，更多的數據通常意味著更多樣化的數據。\n\n但我們正在用盡新的優質多樣化數據來源，而新的人類創作作品的產生速度不太可能跟上 AI 生成的速度。無論如何，我們最終都必須改變我們進行 AI 模型訓練的方式。否則，我們可能會達到一個無法突破的性能門檻。這將改變整個行業，因為重點將從建立和運行更大、更昂貴的模型轉向開發框架、場景和利基市場，使現有模型能夠帶來新的附加價值。\n\n## Jina AI 如何訓練其 AI 模型\n\n在 Jina AI，我們努力為用戶帶來 AI 最佳實踐的好處。儘管我們不生產文本生成 LLM 或 AI 圖像生成器，我們仍然關注模型崩塌的問題。我們使用 <a href=\"https://commoncrawl.org/?ref=jina-ai-gmbh.ghost.io\">Common Crawl</a> 的子集進行大部分預訓練，然後使用經過整理的數據和合成數據來優化我們模型的性能。我們致力於將最先進的性能帶入具有成本效益的模型和緊湊、低維度的嵌入中。\n\n儘管如此，模型崩塌對 Common Crawl 數據來說是不可避免的問題。我們預計隨著時間推移，將過渡到使用更多經過整理的數據，減少使用 Common Crawl。我們預期其他 AI 業界參與者也會這樣做。這將帶來成本—無論是在金錢方面還是在質量改進率方面—但現在估算這些成本還為時過早。\n\n我們在嵌入模型存在已知問題的領域使用合成數據。例如，AI 模型在表示否定方面存在困難。「含肉的食譜」和「不含肉的食譜」通常具有非常接近的嵌入，但用戶往往需要它們相距很遠。我們最大的合成數據用途是創建由這種否定（在 AI 和某些語言學中稱為極性）區分的大量 AI 生成句子對，然後用它來改進我們的模型。\n\n例如，下面是假設嵌入的 2D 投影。「含肉的食譜」和「不含肉的食譜」相對接近。「培根芝士漢堡」比其他任何東西都更接近「含肉的食譜」，而「炸豆丸」更接近「不含肉的食譜」。然而，「培根芝士漢堡」比「炸豆丸」更接近「不含肉的食譜」。\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png\" class=\"kg-image\" alt=\"假設嵌入的 2D 投影。\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--61-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">假設嵌入的 2D 投影。</span></figcaption></figure>\n\n僅從嵌入來看，我們可能會得出結論：培根芝士漢堡比炸豆丸更適合作為不含肉的食譜的例子。\n\n為了防止這種情況，我們用合成數據訓練我們的模型。我們使用 LLM 生成具有相反極性的句子對—比如「帶有 Y 的 X」/「不帶 Y 的 X」—並訓練我們的嵌入模型將這些對子分開。我們也將合成數據用於其他類型的集中式<a href=\"https://finetuner.jina.ai/advanced-topics/negative-mining/?ref=jina-ai-gmbh.ghost.io\">負面挖掘</a>，這是一系列通過呈現經過整理的數據來改進 AI 模型特定方面性能的技術。\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png\" class=\"kg-image\" alt=\"改進底層模型後的假設嵌入 2D 投影。\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--62-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">使用極性相反的句子對改進底層模型後的假設嵌入 2D 投影。</span></figcaption></figure>\n\n我們還使用生成式 AI 來訓練<a href=\"https://jina.ai/news/elevate-your-code-search-with-new-jina-code-embeddings/?ref=jina-ai-gmbh.ghost.io\">程式語言的嵌入模型</a>，利用能生成大量代碼示例的大型模型，讓我們能夠正確嵌入特定語言和框架的相當罕見的功能。\n\n模型蒸餾是我們生產<a href=\"https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny?ref=jina-ai-gmbh.ghost.io\">節省計算資源的緊湊型模型</a>的關鍵。蒸餾比從頭開始訓練效率更高且更可靠，我們的結果表明，經過蒸餾的模型仍然可以保持頂級性能。下表顯示了 Jina AI 的蒸餾<a href=\"https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io\">重排序模型</a>與用於訓練它們的基礎重排序器以及具有更多參數但性能較差的其他模型的比較。\n\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Model</th>\n<th>BEIR Score</th>\n<th>Parameter count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td><code>jina-reranker-v1-base-en</code></td>\n<td>52.45</td>\n<td>137M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-turbo-en</code></td>\n<td>49.60</td>\n<td>38M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-tiny-en</code></td>\n<td>48.54</td>\n<td>33M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-base-v1</code></td>\n<td>49.19</td>\n<td>184M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-xsmall-v1</code></td>\n<td>48.80</td>\n<td>71M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>bge-reranker-base</code></td>\n<td>47.89</td>\n<td>278M</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n\n我們知道 AI 可能是一項昂貴的投資，而企業越來越意識到他們在減少碳排放方面的道德和法律義務。我們也意識到這些問題。模型蒸餾是我們解決這些問題的重要方式。\n\n## 讓我們幫助你駕馭 AI\n\nJina AI 致力於為企業帶來可負擔、高效、實用的 AI 解決方案。我們可以與你在 <a href=\"https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions?ref=jina-ai-gmbh.ghost.io\">Azure</a> 和 <a href=\"https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker?ref=jina-ai-gmbh.ghost.io\">AWS</a> 上的現有雲端基礎設施整合。我們提供符合嚴格安全和隱私標準的<a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">網頁 API</a>，不會保留你的數據用於我們自己的訓練。我們可以幫助你在自己的硬體上安裝我們的<a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">開源模型</a>，讓你的整個操作都在內部進行。\n\n在這個快速變化的領域中，要區分炒作和技術並掌握最佳實踐可能很困難。讓我們為你做這些工作。",
  "comment_id": "6639e8e1af8f52000115be49",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-05-07T10:40:01.000+02:00",
  "updated_at": "2024-07-08T21:10:35.000+02:00",
  "published_at": "2024-05-07T16:00:26.000+02:00",
  "custom_excerpt": "AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let’s find out!",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "6342c5b4393501004d1c8b2c",
      "name": "Insights",
      "slug": "insights",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "6342c5b4393501004d1c8b2c",
    "name": "Insights",
    "slug": "insights",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/",
  "excerpt": "AI 創造 AI！是世界末日嗎？還是只是另一個讓模型創造價值的工具？讓我們來探討看看！",
  "reading_time": 12,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract depiction of a brain in purple and pink hues with a fluid, futuristic design against a blue and purple background.",
  "feature_image_caption": null
}