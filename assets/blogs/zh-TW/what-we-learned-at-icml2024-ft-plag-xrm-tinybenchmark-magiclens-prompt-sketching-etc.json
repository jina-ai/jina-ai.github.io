{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "ICML2024 亮點觀察：PLaG、XRM、tinyBenchmark、MagicLens、Prompt Sketching 等研究動態",
  "html": "<p><a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">International Conference on Machine Learning</a>（國際機器學習會議）是機器學習和人工智慧領域最具權威性的會議之一，今年於 7 月 21 日至 27 日在維也納舉行 2024 年會議。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Interior of a bustling academic conference hall with many attendees, some carrying backpacks, and research posters displayed \" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>這場為期七天的會議提供了密集的學習體驗，包括口頭報告和與其他研究者直接交流想法的機會。目前在強化學習、生命科學 AI、表徵學習、多模態模型，以及 AI 模型開發的核心要素等領域都有許多有趣的研究正在進行。特別重要的是關於<a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">大型語言模型物理學</a>的教程，深入探討了 LLM 的內部運作機制，並為 LLM 是記憶資訊還是運用推理來產生回應這個問題提供了令人信服的答案。</p><h2 id=\"our-work-on-jina-clip-v1\">我們在 Jina-CLIP-v1 上的工作</h2><p>我們在「多模態基礎模型遇見具身 AI」工作坊（<a href=\"https://icml.cc/virtual/2024/workshop/29957?ref=jina-ai-gmbh.ghost.io\">Multi-modal Foundation Models meet Embodied AI</a>）中展示了<a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">海報</a>，介紹了<a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">我們新的多模態模型</a> <code>jina-clip-v1</code>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>與來自各個領域的國際同行會面討論我們的工作非常具有啟發性。我們的演示獲得了許多正面回饋，許多人對 Jina CLIP 如何統一多模態和單模態對比學習範式很感興趣。討論的範圍從 CLIP 架構的限制，到擴展到其他模態，再到在胜肽和蛋白質匹配中的應用。</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster.mp4\" poster=\"https://img.spacergif.org/v1/1138x640/0a/spacer.png\" width=\"1138\" height=\"640\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">3:09</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Michael Günther 展示 Jina CLIP</span></p></figcaption>\n        </figure><h2 id=\"our-favorites\">我們的最愛</h2><p>我們有機會討論許多其他研究者的專案和演示，以下是我們最喜歡的幾個：</p><h3 id=\"plan-like-a-graph-plag\">像圖一樣規劃（PLaG）</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., &amp; Pierrehumbert, J. B. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Graph-Enhanced Large Language Models in Asynchronous Plan Reasoning.</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>很多人都知道「少量樣本提示」或「思維鏈提示」。<a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> 在 ICML 上介紹了一個新的更好的方法：<em>像圖一樣規劃（PLaG）</em>。</p><p>她的想法很簡單：給予 LLM 的任務被分解成多個子任務，LLM 可以並行或順序地解決這些子任務。這些子任務形成一個執行圖。執行整個圖就能解決高階任務。</p><p>在上面的影片中，Fangru Lin 用一個容易理解的例子說明了這個方法。請注意，雖然這改善了結果，但當任務複雜度增加時，LLM 的效能仍會大幅下降。不過，這仍然是朝著正確方向邁進的一大步，並能帶來立即的實際效益。</p><p>對我們來說，有趣的是看到她的工作如何與我們在 <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> 的提示詞應用相互呼應。我們已經實施了類似圖的提示詞結構，但像她那樣動態生成執行圖是一個我們將探索的新方向。</p><h3 id=\"discovering-environments-with-xrm\">使用 XRM 探索環境</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., &amp; Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>這篇論文提出了一個簡單的演算法，用於發現那些會導致模型依賴於與標籤相關但不能產生準確分類/相關性的特徵的訓練環境。一個著名的例子是水鳥數據集（參見 <a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a>），其中包含了在不同背景下的鳥類照片，需要將其分類為水鳥或陸鳥。在訓練過程中，分類器會檢測圖片中的背景是否有水，而不是依靠鳥類本身的特徵。這樣的模型在背景中沒有水的情況下會錯誤分類水鳥。</p><p>為了緩解這種行為，需要檢測模型依賴誤導性背景特徵的樣本。這篇論文提出了 XRM 演算法來實現這一點。</p><p>該演算法在訓練數據集的兩個不同部分上訓練兩個模型。在訓練過程中，某些樣本的標籤會被翻轉。具體來說，如果另一個模型（未在相應樣本上訓練）對樣本的分類不同，就會發生這種情況。通過這種方式，模型被鼓勵依賴虛假相關性。之後，你可以從訓練數據中提取出一個模型預測的標籤與真實標籤不同的樣本。隨後，可以使用這些信息來訓練更穩健的分類模型，例如使用 <a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">Group DRO 演算法</a>。</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">將你的 LLM 評估成本降低 140 倍！</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., &amp; Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>沒錯，你沒聽錯。只要用這個技巧，LLM 評估的成本就能降低到原來的一小部分。</p><p>核心想法很簡單：移除所有測試相同模型能力的評估樣本。背後的數學雖然不那麼直觀，但在海報展示環節中 <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a> 解釋得很清楚。請注意，降低 140 倍的效果是針對流行的 MMLU 數據集（大規模多任務語言理解）。對於你自己的評估數據集，則取決於樣本之間的評估結果相關程度。也許你可以跳過很多樣本，或者只能跳過一些。</p><p>不妨試試看。我們會持續更新 <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> 能夠減少多少評估樣本。</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">使用多邊際匹配差距對比多重表示</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., &amp; Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Research paper diagram illustrating Multi-Marginal Matching Gap concepts, with titles, descriptions, and flow charts in blue \" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>這項工作解決了對比學習中的一個常見挑戰：大多數對比損失函數（如 InfoNCE loss）都是對數據點成對操作並測量正樣本對之間的距離。為了擴展到大小為 k > 2 的正樣本元組，對比學習通常試圖將問題簡化為多個對，並累積所有正樣本對的成對損失。作者在此提出了 M3G（Multi-Marginal Matching Gap）損失，這是 Sinkhorn 演算法的修改版本，可以解決多邊際最佳傳輸問題。這個損失函數可以用於數據集由大小 k > 2 的正樣本元組組成的場景，例如，同一物體的 >2 張圖片、具有三個或更多模態的多模態問題，或具有三個或更多同一圖片增強版本的 SimCLR 擴展。實證結果表明，這種方法優於將問題簡單地簡化為成對處理的方法。</p><h3 id=\"no-need-for-ground-truth\">不需要真實標註！</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p>來自 <a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">Stanford University</a> 的 <a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a> 展示了他關於無需標註數據評估 LLM 的研究。雖然這是理論性的工作，但它對於進階 AI 系統的可擴展監督具有巨大潛力。這不是為了普通的 LLM 用戶，但如果你從事 LLM 評估工作，這絕對值得深入研究。我們已經可以看到，我們可以用這種方式評估 Jina AI 的代理。一旦我們進行第一次實驗，我們會分享結果。</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">模型崩塌是否不可避免？透過積累真實和合成數據打破遞迴詛咒</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration of two machine learning data processes: &quot;Replace Data&quot; and &quot;Accumulate Data&quot;, with detailed flowcharts and model\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>近期多篇文章（例如這篇<a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em> 文章</a>）預測，由於網路爬取的訓練數據中包含越來越多的合成數據，新訓練的模型性能可能會隨時間變差。</p><p>我們的同事 Scott Martens 也發表了<a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">一篇關於模型崩潰的文章</a>，討論了合成數據在模型訓練中可能有用的案例。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>當訓練數據是由模型的早期版本或使用相同數據訓練的模型產生時，模型訓練可能會崩潰。這篇論文的實驗顯示了略微不同的圖景：崩潰只發生在用合成數據「替換」真實數據的情況下，這是之前實驗中所做的。然而，當用合成數據「增強」真實數據時，在所得模型的性能上沒有測量到變化。這些結果表明類似模型崩潰的情況不會發生。但是，這再次證明，使用額外的合成數據無助於訓練出一個普遍優於用於創建這些合成數據點的模型。</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">AI 的腦部手術現在成為可能</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., &amp; Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>假設你想預測某人的職業但不想預測其性別。這項來自 Google Research、ETH Zürich、International Institute of Information Technology Hyderabad (IIITH) 和 Bar-Ilan University 的研究展示了如何使用轉向向量和協方差匹配來控制偏差。</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - 使用開放式指令的自監督圖像檢索</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., &amp; Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>這篇論文介紹了 MagicLens 模型，這是一系列在查詢圖像 + 指令 + 目標圖像三元組上訓練的自監督圖像檢索模型。</p><p>作者介紹了一個數據收集/整理管道，該管道從網路收集圖像對，並使用 LLMs 合成開放式文本指令，這些指令將圖像與超越純視覺相似性的多樣化語義關係聯繫起來。這個管道被用來生產 3,670 萬個高質量的三元組。然後使用該數據集來訓練一個具有共享參數的簡單雙編碼器架構。視覺和語言編碼器的骨幹分別使用 CoCa 或 CLIP base 和 large 變體進行初始化。引入了一個單一的多頭注意力池化器，將兩個多模態輸入壓縮成單一嵌入。訓練目標是將查詢圖像和指令對與目標圖像和空字符串指令進行對比，使用簡單的 InfoNCE 損失來訓練 MagicLens。作者展示了基於指令的圖像檢索的評估結果。</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - 提示的新方式</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., &amp; Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>我們提示 LLMs 的方式正在改變。Prompt Sketching 讓我們能夠給生成模型固定的約束。不是僅僅提供一個指令並希望模型做你想要的，而是定義一個完整的模板，強制模型生成你想要的內容。</p><p>不要將這與微調為提供結構化 JSON 格式的 LLMs 混淆。使用微調方法，模型仍然可以自由生成它想要的內容。Prompt Sketching 則不同。它為提示工程師提供了一個全新的工具箱，並開闢了需要探索的研究領域。在上面的視頻中，Mark Müller 詳細解釋了這個新範式。</p><p>你也可以查看<a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">他們的開源項目 LMQL</a>。</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - 用於儲存庫級代碼完成的選擇性檢索</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., &amp; Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>對於許多查詢來說，RAG 並不真正有幫助，因為查詢太簡單或檢索系統找不到相關文檔，可能是因為根本沒有相關文檔。如果模型依賴誤導性或缺失的來源，這會導致生成時間更長和性能更低。</p><p>這篇論文通過使 LLMs 能夠自我評估檢索是否有用來解決這個問題。他們在代碼完成模型上展示了這種方法，該模型被訓練用來填充代碼模板中的空白。對於給定的模板，系統首先決定檢索結果是否有用，如果有用，就調用檢索器。最後，無論是否將檢索結果添加到其提示中，代碼 LLM 都會生成缺失的上下文。</p><h3 id=\"the-platonic-representation-hypothesis\">柏拉圖表徵假說</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., &amp; Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration of &quot;The Platonic Representation Hypothesis&quot; with geometric shapes, mathematical text, and diagrams explaining a \" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p>「柏拉圖表徵假說」認為神經網絡模型會傾向於收斂到對世界的共同表徵。借鑒<a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">柏拉圖的理型論</a>中存在一個「理念」領域的觀點，這些理念以扭曲的形式呈現給我們，我們只能間接觀察到，作者聲稱我們的 AI 模型似乎會收斂到單一的現實表徵，無論訓練架構、訓練數據，甚至輸入模態如何。數據規模和模型規模越大，它們的表徵似乎越相似。</p><p>作者們考慮向量表示並使用核心對齊指標來衡量表示的對齊程度，具體來說是使用互近鄰指標，該指標測量由兩個核心 <em>K1</em> 和 <em>K2</em> 所產生的 <em>k</em> 近鄰集合的平均交集，並以 <em>k</em> 進行標準化。本研究提供了實證證據，表明隨著模型和數據集規模的增長以及性能的提升，核心之間的對齊程度也越來越高。即使在比較不同模態的模型（如文本模型和圖像模型）時，也可以觀察到這種對齊現象。</p><h2 id=\"summary\">總結</h2><p>雖然最初對擴展定律的熱情開始減弱，但 ICML 2024 已經展示出大量新的、多樣化的創意人才已經進入我們的領域，這讓我們確信進展遠未結束。</p><p>我們在 ICML 2024 玩得很開心，你可以打賭我們 2025 年一定會再來 🇨🇦。</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "我們在維也納的 ICML 2024 玩得非常開心，想與大家分享我們所說、所見、所學的一切。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}