{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3：前沿多語言嵌入式模型",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">我們正在努力通過開源和開放科學來推進和民主化人工智能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3: 使用 Task LoRA 的多語言嵌入</div><div class=\"kg-bookmark-description\">我們推出了 jina-embeddings-v3，這是一個具有 5.7 億參數的新型文本嵌入模型，在多語言數據和長文本檢索任務上達到了最先進的性能，支持長達 8192 個 token 的上下文長度。該模型包含一組特定任務的低秩適應（LoRA）適配器，用於生成高質量的查詢文檔檢索、聚類、分類和文本匹配的嵌入。此外，在訓練過程中整合了套娃表示學習，允許靈活地截斷嵌入維度而不影響性能。在 MTEB 基準測試上的評估顯示，jina-embeddings-v3 在英語任務上優於 OpenAI 和 Cohere 的最新專有嵌入，同時在所有多語言任務上的表現都優於 multilingual-e5-large-instruct。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>今天，我們很高興宣布 <code>jina-embeddings-v3</code>，這是一個具有 5.7 億參數的前沿文本嵌入模型。它在**多語言**數據和**長文本**檢索任務上達到了最先進的性能，支持長達 8192 個 token 的輸入長度。該模型具有特定任務的低秩適應（LoRA）適配器，使其能夠為各種任務生成高質量的嵌入，包括**查詢文檔檢索**、**聚類**、**分類**和**文本匹配**。</p><p>在 MTEB 英語、多語言和 LongEmbed 的評估中，<code>jina-embeddings-v3</code> 在英語任務上優於 OpenAI 和 Cohere 的最新專有嵌入，同時在所有多語言任務上也超越了 <code>multilingual-e5-large-instruct</code>。憑藉 1024 的預設輸出維度，得益於套娃表示學習（MRL）的整合，用戶可以任意將嵌入維度截斷至 32 而不影響性能。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 與其他嵌入模型在所有 MTEB 英語任務中的表現。完整的每項任務評估結果可在</span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">我們的 arXiv 論文</a><span style=\"white-space: pre-wrap;\">中找到。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 已在廣泛的多語言和跨語言 MTEB 任務中進行了評估。請注意，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2-(zh/es/de)</code> 指的是我們的雙語模型套件，該套件僅在中文、西班牙文和德文的單語言和跨語言任務上進行測試，不包括其他語言。此外，我們沒有報告 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">openai-text-embedding-3-large</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">cohere-embed-multilingual-v3.0</code> 的分數，因為這些模型並未在全範圍的多語言和跨語言 MTEB 任務上進行評估。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 在來自 LongEmbed 基準測試的六項長文檔檢索任務上的表現顯示出相較其他模型的顯著改進。分數為 nDCG@10；分數越高越好。這表明我們基於 RoPE 的位置嵌入的有效性，其表現優於 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">baai-bge-m3</code> 使用的固定位置嵌入和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2</code> 使用的基於 ALiBi 的方法。</span></figcaption></figure><p>自 2024 年 9 月 18 日發布以來，<code>jina-embeddings-v3</code> 是**最佳**多語言模型，並在 MTEB 英語排行榜上參數少於 10 億的模型中排名**第二**。v3 總共支持 89 種語言，其中包括 30 種表現最佳的語言：阿拉伯語、孟加拉語、中文、丹麥語、荷蘭語、英語、芬蘭語、法語、格魯吉亞語、德語、希臘語、印地語、印尼語、義大利語、日語、韓語、拉脫維亞語、挪威語、波蘭語、葡萄牙語、羅馬尼亞語、俄語、斯洛伐克語、西班牙語、瑞典語、泰語、土耳其語、烏克蘭語、烏爾都語和越南語。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">截至 2024 年 9 月 18 日發布時，<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 擁有 5.7 億參數和 1024 輸出維度，是參數少於 10 億的模型中最高效、最強大且最可靠的多語言嵌入模型。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">嵌入模型的擴展規律。圖中展示了英語任務的平均 MTEB 性能與模型參數數量的關係。每個點代表一個嵌入模型。趨勢線代表所有模型，多語言模型用青色強調顯示。可以看出 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v3</code> 相比於類似規模的模型展現出更優越的性能，與其前身 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">jina-embeddings-v2</code> 相比也顯示出超線性的改進。此圖表是通過從 MTEB 排行榜選擇前 100 個嵌入模型創建的，排除了那些沒有規模信息的模型（通常是閉源或專有模型）。明顯的惡意提交也被過濾掉了。</span></figcaption></figure><p>此外，與最近受到關注的基於 LLM 的嵌入（如 <code>e5-mistral-7b-instruct</code>）相比，後者的參數規模為 71 億（大 12 倍）且輸出維度為 4096（大 4 倍），但在 MTEB 英語任務上僅提升了 1%，<code>jina-embeddings-v3</code> 是一個更具成本效益的解決方案，更適合生產和邊緣計算環境。</p><h2 id=\"model-architecture\">模型架構</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>基礎</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>基礎參數量</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>含 LoRA 參數量</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>最大輸入 tokens</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>最大輸出維度</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>層數</td>\n<td>24</td>\n</tr>\n<tr>\n<td>詞彙量</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>支援語言數量</td>\n<td>89</td>\n</tr>\n<tr>\n<td>注意力機制</td>\n<td>FlashAttention2，也可不使用</td>\n</tr>\n<tr>\n<td>池化方式</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>jina-embeddings-v3</code> 的架構如下圖所示。為了實現骨幹架構，我們對 <code>XLM-RoBERTa</code> 模型進行了幾項關鍵修改：(1) 實現長文本序列的有效編碼，(2) 允許特定任務的嵌入編碼，以及 (3) 採用最新技術提升整體模型效率。我們繼續使用原始的 <code>XLM-RoBERTa</code> 分詞器。雖然 <code>jina-embeddings-v3</code> 擁有 5.7 億參數，比 1.37 億參數的 <code>jina-embeddings-v2</code> 更大，但仍遠小於從 LLM 微調的嵌入模型。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-embeddings-v3</code> 的架構基於 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\"> 模型，包含四個不同任務的五個 LoRA 適配器。</span></figcaption></figure><p><code>jina-embeddings-v3</code> 的主要創新在於使用 LoRA 適配器。我們引入了<strong>五個</strong>特定任務的 LoRA 適配器來優化<strong>四種</strong>任務的嵌入。模型的輸入包含兩部分：文本（待嵌入的長文檔）和任務。<code>jina-embeddings-v3</code> 支援四種任務並實現了五個可選的適配器：<code>retrieval.query</code> 和 <code>retrieval.passage</code> 用於非對稱檢索任務中的查詢和段落嵌入，<code>separation</code> 用於聚類任務，<code>classification</code> 用於分類任務，以及 <code>text-matching</code> 用於語義相似度等任務，如 STS 或對稱檢索。LoRA 適配器僅佔總參數量的不到 3%，對計算造成的額外開銷極小。</p><p>為了進一步提升性能並減少記憶體消耗，我們整合了 FlashAttention 2，支援啟用點檢查，並使用 DeepSpeed 框架進行高效的分散式訓練。</p><h2 id=\"get-started\">入門指南</h2><h3 id=\"via-jina-ai-search-foundation-api\">通過 Jina AI Search Foundation API</h3><p>使用 <code>jina-embeddings-v3</code> 最簡單的方法是訪問 <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina AI 首頁</a>並導航到 Search Foundation API 部分。從今天開始，這個模型將成為所有新用戶的預設選項。您可以直接在那裡探索不同的參數和功能。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>與 v2 相比，v3 在 API 中引入了三個新參數：<code>task</code>、<code>dimensions</code> 和 <code>late_chunking</code>。</p><h4 id=\"parameter-task\">參數 <code>task</code></h4><p><code>task</code> 參數至關重要，必須根據下游任務進行設置。生成的嵌入將針對該特定任務進行優化。詳細資訊請參考下方列表。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong><code>task</code> 值</strong></th>\n<th><strong>任務描述</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>在查詢-文檔檢索任務中嵌入<b>文檔</b></td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>在查詢-文檔檢索任務中嵌入<b>查詢</b></td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>文檔聚類、語料庫視覺化</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>文本分類</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>（預設）</b>語義文本相似度、一般對稱檢索、推薦、尋找相似項目、去重</td>\n</tr>\n</tbody>\n</table>\n\n<!--kg-card-end: html-->\n<p>請注意，API <em>不是</em>先生成通用的元嵌入，然後用額外的微調 MLP 進行調整。相反，它將特定任務的 LoRA 適配器插入每個 transformer 層（共 24 層）中，並一次性完成編碼。更多詳細資訊可以在<a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">我們的 arXiv 論文</a>中找到。</p><h4 id=\"parameter-dimensions\">參數 <code>dimensions</code></h4><p><code>dimensions</code> 參數允許使用者以最低成本在空間效率和性能之間做出權衡。由於 <code>jina-embeddings-v3</code> 使用了 MRL 技術，您可以根據需要降低嵌入的維度（甚至可以降到單一維度！）。較小的嵌入對向量數據庫更友好，其性能成本可以從下圖中估算。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">參數 <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">長上下文嵌入模型中的延遲分塊</div><div class=\"kg-bookmark-description\">在保持上下文資訊的同時對長文檔進行分塊是一項挑戰。我們引入了「延遲分塊」技術，利用長上下文嵌入模型來生成上下文相關的塊嵌入，以獲得更好的檢索應用效果。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>最後，<code>late_chunking</code> 參數控制是否使用<a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">我們上個月引入的</a>新分塊方法來編碼一批句子。當設置為 <code>true</code> 時，我們的 API 會將 <code>input</code> 欄位中的所有句子連接起來，作為單一字符串輸入到模型中。換句話說，<strong>我們將輸入中的句子視為原本來自同一個章節、段落或文檔。</strong>在內部，模型會嵌入這個長的連接字符串，然後執行延遲分塊，返回一個與輸入列表大小相匹配的嵌入列表。因此，列表中的每個嵌入都會受到前面嵌入的影響。</p><p>從使用者的角度來看，設置 <code>late_chunking</code> <em>不會</em>改變輸入或輸出格式。您只會注意到嵌入值的變化，因為它們現在是基於整個前文上下文而不是獨立計算的。在使用時需要知道<code>late_chunking=True</code> 表示每個請求中的總 token 數（通過加總 <code>input</code> 中的所有 token）限制在 8192，這是 <code>jina-embeddings-v3</code> 允許的最大上下文長度。當 <code>late_chunking=False</code> 時，則沒有這樣的限制；總 token 數僅受到<a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">Embedding API 的請求限制</a>。</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking 開啟與關閉：輸入和輸出格式保持一致，唯一的區別在於嵌入值。當啟用 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\"> 時，嵌入會受到 </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\"> 中整個前文內容的影響，而沒有它時，嵌入則是獨立計算的。</span></p></figcaption></figure><h3 id=\"via-azure-aws\">透過 Azure 和 AWS</h3><p><code>jina-embeddings-v3</code> 現已在 AWS SageMaker 和 Azure Marketplace 上提供。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>如果需要在這些平台之外或在公司內部部署使用，請注意該模型是根據 CC BY-NC 4.0 授權。<a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">如需商業用途諮詢，歡迎與我們聯繫。</a></p><h3 id=\"via-vector-databases-partners\">透過向量數據庫和合作夥伴</h3><p>我們與 Pinecone、Qdrant 和 Milvus 等向量數據庫提供商，以及 LlamaIndex、Haystack 和 Dify 等 LLM 協調框架密切合作。在發布時，我們很高興地宣布 Pinecone、Qdrant、Milvus 和 Haystack 已經整合了對 <code>jina-embeddings-v3</code> 的支援，包括三個新參數：<code>task</code>、<code>dimensions</code> 和 <code>late_chunking</code>。其他已經整合 <code>v2</code> API 的合作夥伴只需將模型名稱改為 <code>jina-embeddings-v3</code> 即可支援 <code>v3</code>。不過，他們可能尚未支援 <code>v3</code> 中引入的新參數。</p><h4 id=\"via-pinecone\">透過 Pinecone</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">透過 Qdrant</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">透過 Milvus</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">透過 Haystack</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">結論</h2><p>在 2023 年 10 月，我們發布了 <code>jina-embeddings-v2-base-en</code>，<a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">這是世界上第一個具有 8K 上下文長度的開源嵌入模型</a>。它是唯一一個支援長上下文並與 OpenAI 的 <code>text-embedding-ada-002</code> 相匹配的文本嵌入模型。今天，經過一年的學習、實驗和寶貴經驗，我們很驕傲地發布 <code>jina-embeddings-v3</code>—這是文本嵌入模型的新里程碑，也是我們公司的重大突破。</p><p>通過這次發布，我們繼續在我們所擅長的領域中保持卓越：<strong>長上下文</strong><strong>嵌入</strong>，同時也解決了業界和社群最迫切需要的功能—<strong>多語言嵌入</strong>。與此同時，我們將性能推向了新的高度。藉由任務特定 LoRA、MRL 和 late chunking 等新功能，我們相信 <code>jina-embeddings-v3</code> 將真正成為各種應用的基礎嵌入模型，包括 RAG、智能代理等。與最近的基於 LLM 的嵌入（如 <code>NV-embed-v1/v2</code>）相比，我們的模型參數效率非常高，使其更適合生產和邊緣設備使用。</p><p>展望未來，我們計劃專注於評估和改進 <code>jina-embeddings-v3</code> 在資源有限語言上的表現，並進一步分析由數據可用性限制造成的系統性失誤。此外，<code>jina-embeddings-v3</code> 的模型權重及其創新功能和獨特見解，將作為我們即將推出的模型（包括 <code>jina-clip-v2</code>）的基礎，<code>jina-reranker-v3</code> 和 <code>reader-lm-v2</code>。</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 是一個具有突破性的多語言文本嵌入模型，擁有 570M 參數和 8192 個 token 長度，在 MTEB 基準測試中的表現超越了 OpenAI 和 Cohere 最新的專有嵌入模型。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}