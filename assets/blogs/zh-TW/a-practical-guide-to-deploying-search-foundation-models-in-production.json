{
  "slug": "a-practical-guide-to-deploying-search-foundation-models-in-production",
  "id": "679b56ba42b46600019a86e3",
  "uuid": "458c0de5-aedb-4513-8ffd-47c027d204ad",
  "title": "部署搜尋基礎模型到生產環境的實用指南",
  "html": "<p>在 Jina AI，我們的使命是為企業用戶提供高品質的搜尋解決方案。為達成此目標，我們透過多種管道提供模型使用。然而，為特定使用情境選擇正確的管道可能會有點棘手。在這篇文章中，我們將引導您完成決策過程並分析權衡取捨，根據您的用戶特性和需求，為您提供存取我們搜尋基礎模型的最佳方式之實用指南。</p><h2 id=\"jina-search-foundation-models\">Jina 搜尋基礎模型</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Our Search Foundation Models</div><div class=\"kg-bookmark-description\">We've been moving the needle in search models since day one. Take a look at our model evolution below—hover or click to discover each milestone.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-18.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Jina AI</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-models.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>我們的搜尋基礎模型包括：</p><ul><li><strong>Embeddings</strong>：將數位物件的資訊轉換為嵌入向量，捕捉其基本特徵。</li><li><strong>Rerankers</strong>：對查詢-文件集進行深入的語義分析，以提高搜尋相關性。</li><li><strong>小型語言模型</strong>：包括專門的 SLM，如用於 HTML2Markdown 或資訊提取等特定任務的 <code>ReaderLM-v2</code>。</li></ul><p>在這篇文章中，我們將探討 <code>jina-embeddings-v3</code> 的不同部署選項，比較三種主要方式：</p><ul><li>使用 <a href=\"https://jina.ai/api-dashboard\" rel=\"noreferrer\">Jina API</a></li><li>透過雲端服務提供商部署，如 <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS SageMaker</a></li><li><a href=\"https://jina.ai/api-dashboard/license-config\">在商業授權下</a>於 Kubernetes 叢集中自行部署</li></ul><p>比較將評估每種方式的成本影響和優勢，幫助您確定最適合您需求的選項。</p><h2 id=\"key-performance-metrics\">關鍵性能指標</h2><p>我們在不同使用情境中評估了五個關鍵性能指標：</p><ul><li><strong>請求成功率</strong>：對嵌入伺服器的成功請求百分比</li><li><strong>請求延遲</strong>：嵌入伺服器處理並回傳請求所需的時間</li><li><strong>Token 吞吐量</strong>：嵌入伺服器每秒可處理的 Token 數量</li><li><strong>每 Token 成本</strong>：每個文本單位的總處理成本</li></ul><p>對於在 Kubernetes 叢集上自行部署的 Jina embeddings，我們還研究了<em>動態批次處理</em>的影響。此功能會將請求排入佇列，直到達到最大批次大小（<code>jina-embeddings-v3</code> 為 8,192）才生成嵌入。</p><p>我們特意在分析中排除了兩個重要的性能因素：</p><ul><li><em>自動擴展</em>：雖然這對於工作負載變化的雲端部署很重要，但其效果取決於許多變數—硬體效率、網路架構、延遲和實作選擇。這些複雜性超出了我們目前的討論範圍。<strong>請注意，Jina API 包含自動擴展，我們的結果反映了這一點。</strong></li><li><em>量化</em>：雖然這種技術可以創建更小的嵌入向量並減少數據傳輸，但主要效益來自其他系統組件（數據存儲和向量距離計算）而不是減少數據傳輸。由於我們專注於直接模型使用成本，我們在此分析中省略了量化。</li></ul><p>最後，我們將檢視每種方式的財務影響，同時考慮總擁有成本和每 token/每請求的費用。</p><h2 id=\"deployment-setup\">部署設置</h2><p>我們評估了 <code>jina-embeddings-v3</code> 的三種部署和使用情境：</p><h3 id=\"using-the-jina-api\">使用 Jina API</h3><p>所有 Jina AI 嵌入模型都可以通過 <a href=\"https://jina.ai/api-dashboard/embeddings\" rel=\"noreferrer\">Jina API</a> 存取。存取採用預付 token 系統，提供一百萬個 token 供免費測試。我們從德國辦公室通過互聯網進行 API 呼叫來評估性能。</p><h3 id=\"using-aws-sagemaker\">使用 AWS SageMaker</h3><p>Jina Embeddings v3 <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">可供 AWS 使用者通過 SageMaker 使用</a>。使用需要訂閱此模型的 AWS 服務。我們<a href=\"https://github.com/jina-ai/jina-sagemaker/blob/main/notebooks/Real-time%20embedding.ipynb\">提供了一個 notebook</a>，展示如何使用 AWS 帳戶訂閱和使用 Jina AI 模型。</p><p>雖然這些模型也在 <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Microsoft Azure</a> 和 <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">Google Cloud Platform</a> 上提供，但我們將測試重點放在 AWS 上。我們預期在其他平台上會有類似的性能。所有測試都在 <code>us-east-1</code> 區域的 <code>ml.g5.xlarge</code> 實例上運行。</p><h3 id=\"self-hosting-on-kubernetes\">在 Kubernetes 上自行部署</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">要取得我們 CC-BY-NC 模型的商業授權，您首先需要從我們獲得許可證。<a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">歡迎聯繫我們的銷售團隊。</a></div></div><p>我們使用 Python 建立了一個 FastAPI 應用程式，使用 <code>SentenceTransformer</code> 程式庫<a href=\"https://huggingface.co/jinaai/jina-embeddings-v3\">從 HuggingFace 載入 <code>jina-embeddings-v3</code></a>。該應用程式包含兩個端點：</p><ul><li><code>/embed</code>：接收文本段落作為輸入並回傳其嵌入</li><li><code>/health</code>：提供基本健康監控</li></ul><p>我們將其部署為 Amazon Elastic Kubernetes Service 上的 Kubernetes 服務，使用 <code>us-east-1</code> 區域的 <code>g5.xlarge</code> 實例。</p><h4 id=\"with-and-without-dynamic-batching\">有無動態批次處理</h4><p>我們在 Kubernetes 叢集中以兩種配置測試性能：一種在接收到請求時立即處理，另一種使用動態批次處理。在動態批次處理的情況下，服務會等待直到佇列中收集了 <code>MAX_TOKENS</code>（8192）或達到預定義的 2 秒超時，才調用模型並計算嵌入。這種方法提高了 GPU 使用率並減少了 GPU 記憶體的碎片化。</p><p>對於每個部署情境，我們通過變更三個關鍵參數進行測試：</p><ul><li><strong>批次大小</strong>：每個請求包含 1、32 或 128 個文本段落進行嵌入</li><li><strong>段落長度</strong>：我們使用包含 128、512 或 1,024 個 token 的文本段落</li><li><strong>並發請求</strong>：我們同時發送 1、5 或 10 個請求</li></ul><h2 id=\"benchmark-results\">基準測試結果</h2><p>下表是每個使用情境的結果摘要，為上述三個變數的所有設置的平均值。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>指標</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>自行部署<br>使用批次處理</th>\n<th>自行部署<br>標準</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>請求成功率</td>\n<td>87.6%</td>\n<td><strong>99.9%</strong></td>\n<td>55.7%</td>\n<td>58.3%</td>\n</tr>\n<tr>\n<td>延遲<br>（秒）</td>\n<td>11.4</td>\n<td>3.9</td>\n<td>2.7</td>\n<td><strong>2.6</strong></td>\n</tr>\n<tr>\n<td>按成功率標準化的延遲<br>（秒）</td>\n<td>13.0</td>\n<td><strong>3.9</strong></td>\n<td>4.9</td>\n<td>4.4</td>\n</tr>\n<tr>\n<td>Token 吞吐量<br>（token/秒）</td>\n<td>13.8K</td>\n<td><strong>15.0K</strong></td>\n<td>2.2K</td>\n<td>2.6K</td>\n</tr>\n<tr>\n<td>峰值 Token 吞吐量<br>（token/秒）</td>\n<td><strong>63.0K</strong></td>\n<td>32.2K</td>\n<td>10.9K</td>\n<td>10.5K</td>\n</tr>\n<tr>\n<td>價格<br>（每百萬 token 美元）</td>\n<td>$0.02</td>\n<td>$0.07</td>\n<td>$0.32</td>\n<td>$0.32</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"request-success-rate\">請求成功率</h2><p>在我們的測試中，成功率從 SageMaker 接近完美的 99.9% 到自行部署解決方案的 56-58%，突顯了為什麼在生產系統中 100% 的可靠性仍然難以實現。這主要受三個因素影響：</p><ul><li>即使在雲端環境中，網路不穩定性也會導致不可避免的失敗</li><li>資源競爭，特別是 GPU 記憶體，在負載下會導致請求失敗</li><li>為維持系統健康，必要的超時限制意味著某些請求必須失敗</li></ul><h3 id=\"success-rate-by-batch-size\">按批次大小的成功率</h3><p>在自行部署的 Kubernetes 配置中，大批次大小經常導致記憶體不足錯誤。在沒有動態批次處理的情況下，所有包含 32 或 128 個項目的批次請求都因此失敗。即使實作了動態批次處理，大批次的失敗率仍然顯著偏高。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8017-ba56-e35215a76fc4\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8064-ab87-e44fc044673d\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">批次大小</th><th id=\"zt<p\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"kPia\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"wgj>\" class=\"simple-table-header-color simple-table-header\">自行部署<br>(動態批次)<br></th><th id=\"OwMn\" class=\"simple-table-header-color simple-table-header\">自行部署<br>(無批次)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-80e1-b4a8-c6f8a3b03117\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"zt<p\" class=\"\">100%</td><td id=\"kPia\" class=\"\">100%</td><td id=\"wgj>\" class=\"\">97.1%</td><td id=\"OwMn\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8096-93c6-deff80bbeffc\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">32</th><td id=\"zt<p\" class=\"\">86.7%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">50.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr><tr id=\"1847c956-b7d2-80fe-a61d-ea3923f34aac\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"zt<p\" class=\"\">76.2%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">24.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<p>雖然這個問題可以透過自動擴展輕鬆解決，但我們在此選擇不探討該選項。自動擴展會導致無法預測的成本增加，而且考慮到眾多的自動擴展配置選項，要提供可操作的見解將會很困難。</p><h3 id=\"success-rate-by-concurrency-level\">並發程度的成功率</h3><p>並發——同時處理多個請求的能力——對於自行部署的 Kubernetes 配置的請求成功率既無強烈影響也無一致性影響，對 AWS SageMaker 的影響也很小，至少在並發程度為 10 的情況下是如此。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-80a7-9beb-f1ebe6e1e529\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8011-bcc1-d295e87b8e54\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">並發數</th><th id=\"KV|=\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"G@`e\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"[~nZ\" class=\"simple-table-header-color simple-table-header\">自行部署<br>(動態批次)<br></th><th id=\"mHG:\" class=\"simple-table-header-color simple-table-header\">自行部署<br>(無批次)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8041-9a23-c1338c5d3f23\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"KV|=\" class=\"\">93.3%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">57.5%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80eb-86a9-f249c86ddfdf\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">5</th><td id=\"KV|=\" class=\"\">85.7%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">58.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80ac-a3ad-eadd81c69cb2\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">10</th><td id=\"KV|=\" class=\"\">83.8%</td><td id=\"G@`e\" class=\"\">99.6%</td><td id=\"[~nZ\" class=\"\">55.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h3 id=\"success-rate-by-token-length\">根據 Token 長度的成功率</h3><p>具有高 token 數的長文本對 Jina Embedding API 和具有動態批次處理的 Kubernetes 的影響類似於大批次：隨著大小增加，失敗率顯著上升。然而，雖然沒有動態批次處理的自行部署解決方案在處理大批次時幾乎必定失敗，但在處理單個長文本時表現較好。至於 SageMaker，長文本長度——就像並發和批次大小一樣——對請求成功率沒有明顯影響。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8003-8d50-eddc36a83d33\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-804b-8352-d65d5e6bdd0e\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">文本長度<br>(tokens)<br></th><th id=\"CDn]\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"@nCV\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"H?G{\" class=\"simple-table-header-color simple-table-header\">自行部署<br>(動態批次)<br></th><th id=\"]{Mf\" class=\"simple-table-header-color simple-table-header\">自行部署<br>(無批次)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8011-8a92-d0986d045c79\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">98.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-809f-b073-fa48e7287c13\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">512</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">66.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8019-9f1f-cefd810c520d\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">1024</th><td id=\"CDn]\" class=\"\">99.3%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">33.3%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80c7-a745-fcdaf408f3d0\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">8192</th><td id=\"CDn]\" class=\"\">51.1%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">29.4%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h2 id=\"request-latency\">請求延遲</h2><p>所有延遲測試都在並發程度為 1、5 和 10 的情況下重複進行五次。響應時間是五次嘗試的平均值。請求吞吐量是響應時間（秒）的倒數乘以並發數。</p><h3 id=\"jina-api\">Jina API</h3><p>無論並發程度如何，Jina API 的響應時間主要受批次大小影響。雖然文本長度也會影響性能，但其影響並不是直接的。作為一般原則，包含更多數據的請求——無論是通過較大的批次大小還是較長的文本——處理時間都會更長。</p><h4 id=\"concurrency-1\">並發數 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>文本長度（token 數）</th>\n<th>響應時間（毫秒）</th>\n<th>請求吞吐量（請求/秒）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>801</td>\n<td>1.25</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>724</td>\n<td>1.38</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>614</td>\n<td>1.63</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1554</td>\n<td>0.64</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1620</td>\n<td>0.62</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2283</td>\n<td>0.44</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4441</td>\n<td>0.23</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5430</td>\n<td>0.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>6332</td>\n<td>0.16</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><h4 id=\"concurrency-5\">併發數 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>文本長度（以 token 計）</th>\n<th>響應時間（毫秒）</th>\n<th>請求吞吐量（每秒請求數）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>689</td>\n<td>7.26</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>599</td>\n<td>8.35</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>876</td>\n<td>5.71</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1639</td>\n<td>3.05</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2511</td>\n<td>1.99</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4728</td>\n<td>1.06</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2766</td>\n<td>1.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5911</td>\n<td>0.85</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>18621</td>\n<td>0.27</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10\">併發數 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>文本長度（以 token 計）</th>\n<th>響應時間（毫秒）</th>\n<th>請求吞吐量（每秒請求數）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>790</td>\n<td>12.66</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>669</td>\n<td>14.94</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>649</td>\n<td>15.41</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1384</td>\n<td>7.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3409</td>\n<td>2.93</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>8484</td>\n<td>1.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3441</td>\n<td>2.91</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>13070</td>\n<td>0.77</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>17886</td>\n<td>0.56</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>對於單個請求（批次大小為 1）：</p><ul><li>響應時間保持相對穩定，無論文本長度如何，大約在 600-800 毫秒之間</li><li>較高的併發數（5 或 10 個同時請求）並不會顯著降低每個請求的性能</li></ul><p>對於較大的批次（32 和 128 項）：</p><ul><li>響應時間大幅增加，批次大小為 128 時的處理時間大約是單個請求的 4-6 倍</li><li>文本長度的影響在較大批次時更為明顯</li><li>在高併發（10）和大批次（128）的情況下，兩者的組合導致響應時間顯著延長，對於最長的文本可達近 18 秒</li></ul><p>對於吞吐量：</p><ul><li>在執行併發請求時，較小的批次通常能達到更好的吞吐量</li><li>在併發數為 10、批次大小為 1 時，系統達到最高吞吐量，約為每秒 15 個請求</li><li>較大的批次始終顯示較低的吞吐量，在多個場景中降至每秒不到 1 個請求</li></ul><h3 id=\"aws-sagemaker\">AWS SageMaker</h3><p>AWS SageMaker 測試使用 <code>ml.g5.xlarge</code> 實例進行。</p><h4 id=\"concurrency-1-1\">併發數 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>文本長度（以 token 計）</th>\n<th>響應時間（毫秒）</th>\n<th>請求吞吐量（每秒請求數）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>189</td>\n<td>5.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>219</td>\n<td>4.56</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>221</td>\n<td>4.53</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>377</td>\n<td>2.66</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3931</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2215</td>\n<td>0.45</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>1120</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>3408</td>\n<td>0.29</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>5765</td>\n<td>0.17</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-1\">併發數 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>文本長度（以 token 計）</th>\n<th>響應時間（毫秒）</th>\n<th>請求吞吐量（每秒請求數）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>443</td>\n<td>11.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>426</td>\n<td>11.74</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>487</td>\n<td>10.27</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1257</td>\n<td>3.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2245</td>\n<td>2.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4159</td>\n<td>1.20</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2444</td>\n<td>2.05</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>6967</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>14438</td>\n<td>0.35</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-1\">併發數 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>文本長度（以 token 計）</th>\n<th>響應時間（毫秒）</th>\n<th>請求吞吐量（每秒請求數）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>585</td>\n<td>17.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>602</td>\n<td>16.60</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>687</td>\n<td>14.56</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1650</td>\n<td>6.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3555</td>\n<td>2.81</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>7070</td>\n<td>1.41</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3867</td>\n<td>2.59</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>12421</td>\n<td>0.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>25989</td>\n<td>0.38</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>與 Jina API 的主要差異：</p><ul><li>基本性能：SageMaker 在小型請求（單個項目、短文本）方面明顯更快 - 約 200 毫秒，而 Jina 為 700-800 毫秒。</li><li>擴展行為：<ul><li>兩種服務在處理較大批次和較長文本時都會變慢</li><li>SageMaker 在處理大批次（128）和長文本（1024 tokens）時顯示更明顯的減速</li><li>在高併發（10）且最大負載（批次 128、1024 tokens）時，SageMaker 需要約 26 秒，而 Jina 需要約 18 秒</li></ul></li><li>併發性影響：<ul><li>兩種服務的吞吐量都從增加的併發數中受益</li><li>兩者在不同併發級別下都保持類似的吞吐量模式</li><li>SageMaker 在並發數 10 時可達到略高的峰值吞吐量（17 req/s vs 15 req/s）</li></ul></li></ul><h3 id=\"self-hosted-kubernetes-cluster\">自託管 Kubernetes 叢集</h3><p>自託管測試是在 <a href=\"https://aws.amazon.com/eks/\">Amazon 的 Elastic Kubernetes Service</a> 上使用 <code>g5.xlarge</code> 執行個體進行的。</p><h4 id=\"concurrency-1-2\">並發數 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>段落長度（token）</th>\n<th>無批次處理時間（ms）</th>\n<th>無批次處理吞吐量（req/s）</th>\n<th>動態批處理時間（ms）</th>\n<th>動態批處理吞吐量（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>416</td>\n<td>2.40</td>\n<td>2389</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>397</td>\n<td>2.52</td>\n<td>2387</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>396</td>\n<td>2.52</td>\n<td>2390</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1161</td>\n<td>0.86</td>\n<td>3059</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1555</td>\n<td>0.64</td>\n<td>1496</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2424</td>\n<td>0.41</td>\n<td>2270</td>\n<td>0.44</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-2\">並發數 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>段落長度（token）</th>\n<th>無批次處理時間（ms）</th>\n<th>無批次處理吞吐量（req/s）</th>\n<th>動態批處理時間（ms）</th>\n<th>動態批處理吞吐量（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>451</td>\n<td>11.08</td>\n<td>2401</td>\n<td>2.08</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>453</td>\n<td>11.04</td>\n<td>2454</td>\n<td>2.04</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>478</td>\n<td>10.45</td>\n<td>2520</td>\n<td>1.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1447</td>\n<td>3.46</td>\n<td>1631</td>\n<td>3.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2867</td>\n<td>1.74</td>\n<td>2669</td>\n<td>1.87</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4154</td>\n<td>1.20</td>\n<td>4026</td>\n<td>1.24</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-2\">並發數 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>段落長度（token）</th>\n<th>無批次處理時間（ms）</th>\n<th>無批次處理吞吐量（req/s）</th>\n<th>動態批處理時間（ms）</th>\n<th>動態批處理吞吐量（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>674</td>\n<td>14.84</td>\n<td>2444</td>\n<td>4.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>605</td>\n<td>16.54</td>\n<td>2498</td>\n<td>4.00</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>601</td>\n<td>16.64</td>\n<td>781*</td>\n<td>12.80</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>2089</td>\n<td>4.79</td>\n<td>2200</td>\n<td>4.55</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>5005</td>\n<td>2.00</td>\n<td>4450</td>\n<td>2.24</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>7331</td>\n<td>1.36</td>\n<td>7127</td>\n<td>1.40</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">† 這個異常結果是動態批處理 2 秒超時的副產品。在並發數為 10 時，每個請求發送 1024 個 token 的數據，佇列幾乎立即填滿，批處理系統無需等待超時。在較低的大小和並發數下，系統確實需要等待，自動為每個請求增加了 2 秒的浪費時間。這種非線性現象在未優化的批處理過程中很常見。</div></div><p>當處理超過 16,384 個 token 的請求時，我們的自託管設置會出現伺服器錯誤，通常是記憶體不足錯誤。這種情況與並發級別無關。因此，不顯示超過該數據量的測試結果。</p><p>高並發會大致線性地增加回應時間：並發級別 5 的回應時間大約是 1 的五倍。並發級別 10 則是十倍。</p><p>動態批處理會使小批量的回應時間增加約 2 秒。這是因為批處理佇列會等待 2 秒才處理未滿的批次。然而，對於較大的批次大小，它可以帶來適度的回應時間改善。</p><h2 id=\"token-throughput\">Token 吞吐量</h2><p>在所有平台上，Token 吞吐量都會隨著批次大小增加、段落長度增加和並發級別提高而增加。因此，我們只呈現高使用量級別的結果，因為較低級別無法提供有意義的實際性能指標。</p><p>所有測試都在並發級別 10 下進行，每個請求 16,384 個 token，取五次請求的平均值。我們測試了兩種配置：批次大小 32 配合 512 token 段落，以及批次大小 128 配合 128 token 段落。兩種配置的總 token 數保持不變。</p><p>Token 吞吐量（每秒 token 數）：</p><table>\n<thead>\n<tr>\n<th>批次大小</th>\n<th>段落長度（token）</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>自託管（無批處理）</th>\n<th>自託管（動態批處理）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>46K</td>\n<td>28.5K</td>\n<td>14.3K</td>\n<td>16.1K</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>42.3K</td>\n<td>27.6K</td>\n<td>9.7K</td>\n<td>10.4K</td>\n</tr>\n</tbody>\n</table>\n<p>在高負載條件下，Jina API 的性能明顯優於其他選擇，而這裡測試的自託管解決方案顯示出明顯較低的性能。</p><h2 id=\"costs-per-million-tokens\">每百萬 Token 成本</h2><p>成本可能是選擇嵌入解決方案時最關鍵的因素。雖然計算 AI 模型成本可能很複雜，以下是不同選項的比較分析：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>服務類型</th>\n<th>每百萬 Token 成本</th>\n<th>基礎設施成本</th>\n<th>授權成本</th>\n<th>總小時成本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina API</td>\n<td>$0.018-0.02</td>\n<td>N/A</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>SageMaker（美東）</td>\n<td>$0.0723</td>\n<td>$1.408/小時</td>\n<td>$2.50/小時</td>\n<td>$3.908/小時</td>\n</tr>\n<tr>\n<td>SageMaker（歐洲）</td>\n<td>$0.0788</td>\n<td>$1.761/小時</td>\n<td>$2.50/小時</td>\n<td>$4.261/小時</td>\n</tr>\n<tr>\n<td>自託管（美東）</td>\n<td>$0.352</td>\n<td>$1.006/小時</td>\n<td>$2.282/小時</td>\n<td>$3.288/小時</td>\n</tr>\n<tr>\n<td>自託管（歐洲）</td>\n<td>$0.379</td>\n<td>$1.258/小時</td>\n<td>$2.282/小時</td>\n<td>$3.540/小時</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"jina-api-1\">Jina API</h3><p>該服務採用基於 token 的定價模式，提供兩種預付層級：</p><ul><li>10 億 token 收費 $20（每百萬 $0.02）- 適合原型設計和開發的入門費率</li><li>110 億 token 收費 $200（每百萬 $0.018）- 更適合大量使用的經濟費率</li></ul><p>值得注意的是，這些 token 可以在 Jina 的整個產品套件中使用，包括閱讀器、重新排序器和零樣本分類器。</p><h3 id=\"aws-sagemaker-1\">AWS SageMaker</h3><p>SageMaker 的定價結合了每小時執行個體成本與模型授權費用。使用 <code>ml.g5.xlarge</code> 執行個體：</p><ul><li>執行個體成本：每小時 $1.408（美東地區）或每小時 $1.761（歐洲法蘭克福）</li><li><code>jina-embeddings-v3</code> 授權：每小時 $2.50</li><li>總小時成本：根據地區為每小時 $3.908-$4.261</li></ul><p>以平均每秒 15,044 個 tokens（每小時 54.16M tokens）的處理量計算，每百萬 tokens 的成本在 $0.0723 到 $0.0788 之間。</p><h3 id=\"self-hosting-with-kubernetes\">使用 Kubernetes 自行託管</h3><p>自行託管的成本會根據您選擇的基礎設施而有顯著差異。以 AWS EC2 的 <code>g5.xlarge</code> 執行個體為例：</p><ul><li>執行個體成本：每小時 $1.006（美東地區）或每小時 $1.258（歐洲法蘭克福）</li><li><code>jina-embeddings-v3</code> 授權：每季 $5000（每小時 $2.282）</li><li>總小時成本：根據地區為每小時 $3.288-$3.540</li></ul><p>以每秒 2,588 個 tokens（每小時 9.32M tokens）的處理量計算，每百萬 tokens 的成本為 $0.352-$0.379。雖然每小時費率低於 SageMaker，但較低的處理量導致每個 token 的成本更高。</p><p>自行託管的重要考量因素：</p><ul><li>固定成本（授權、基礎設施）不論使用與否都會持續產生</li><li>內部部署仍需支付授權費用和人員成本</li><li>工作負載變動可能顯著影響成本效益</li></ul><h3 id=\"key-takeaways\">重要結論</h3><p>即使不考慮冷啟動時間並假設替代方案能達到最佳處理量，Jina API 仍是最具成本效益的解決方案。</p><p>對於已有完善基礎設施且伺服器邊際成本較低的組織而言，自行託管可能是合理選擇。此外，探索 AWS 以外的雲端供應商也可能獲得更好的價格。</p><p>然而，對於大多數企業，特別是尋求即用型解決方案的中小企業來說，Jina API 提供了無可匹敵的成本效益。</p><h2 id=\"security-and-data-privacy-considerations\">安全性與資料隱私考量</h2><p>在選擇嵌入模型的部署策略時，除了效能和成本考量外，安全性和資料隱私需求可能會扮演決定性的角色。我們提供靈活的部署選項來滿足不同的安全需求：</p><h3 id=\"cloud-service-providers\">雲端服務供應商</h3><p>對於<strong>已經使用主要雲端供應商的企業</strong>，我們在雲端市集的產品（如 <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS Marketplace</a>、<a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Azure</a> 和 <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">GCP</a>）提供了在現有安全框架內部署的自然解決方案。這些部署的優勢包括：</p><ul><li>繼承您與雲端服務供應商關係中的安全控制和合規性</li><li>可輕鬆整合現有的安全政策和資料治理規則</li><li>幾乎不需要更改現有的資料處理協議</li><li>符合既有的資料主權考量</li></ul><h3 id=\"self-hosting-and-local-deployment\">自行託管和本地部署</h3><p><strong>具有嚴格安全要求或特定法規義務的組織</strong>通常偏好對其基礎設施有完整的實體控制權。我們的自行託管選項可實現：</p><ul><li>完全控制部署環境</li><li>在您的安全範圍內進行所有資料處理</li><li>整合現有的安全監控和控制措施</li></ul><p>要取得我們 CC-BY-NC 模型的商業授權，您需要先向我們申請授權。<a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">歡迎聯繫我們的銷售團隊。</a></p><h3 id=\"jina-api-service\">Jina API 服務</h3><p>對於試圖在安全性、便利性和成本之間取得平衡的<strong>新創公司和中小企業</strong>，我們的 API 服務提供企業級安全性，且無需額外的營運成本：</p><ul><li><a href=\"https://jina.ai/Jina_AI_GmbH_Letter_of_Attestation_SOC_2_Type_1.pdf\" rel=\"noreferrer\">SOC2 認證</a>確保穩健的安全控制</li><li><a href=\"https://gdpr-info.eu/\" rel=\"noreferrer\">完全符合 GDPR</a> 的資料處理</li><li>零資料保留政策 - 我們不會儲存或記錄您的請求</li><li>加密的資料傳輸和安全的基礎設施</li></ul><p>Jina AI 的模型產品使組織能夠選擇最符合其安全需求且同時維持營運效率的部署策略。</p><h2 id=\"choosing-your-solution\">選擇您的解決方案</h2><p>下方流程圖總結了您所看到的所有經驗測試和表格的結果：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1256\" height=\"1980\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png 1256w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">有了這些資訊，上面的流程圖應該能為您指出適合考慮的解決方案類型。</span></figcaption></figure><p>首先，考慮您的安全需求以及為滿足這些需求可以犧牲多少靈活性。</p><p>然後，考慮您計畫如何在企業中使用 AI：</p><ol><li>離線索引和可以最佳化使用批次處理的非時間敏感用例。</li><li>可靠性和擴展性敏感的用途，如檢索增強生成和 LLM 整合。</li><li>時間敏感的用途，如線上搜尋和檢索。</li></ol><p>同時，考慮您的內部專業知識和現有基礎設施：</p><ol><li>您的技術棧是否已經高度依賴雲端？</li><li>您是否有能力自行託管的大型內部 IT 運營團隊？</li></ol><p>最後，考慮您預期的資料量。您是否是每天預期執行數百萬次 AI 模型操作的大規模用戶？</p><h2 id=\"conclusion\">結論</h2><p>對許多 IT 部門來說，將 AI 整合到營運決策中仍是未知的領域，因為市場缺乏成熟的即用型解決方案。這種不確定性可能使策略規劃變得具有挑戰性。我們的定量分析旨在為將我們的搜尋基礎模型整合到您特定的工作流程和應用程式中提供具體指導。</p><p>就單位成本而言，Jina API 是企業可用的最經濟選項之一。很少有替代方案能在提供相似功能的同時達到我們的價格水準。</p><p>我們致力於提供不僅強大且易用，而且對各種規模的組織來說都具有成本效益的搜尋功能。無論是通過主要雲端供應商還是自行託管的部署，我們的解決方案都能滿足超越純粹成本考量的最複雜企業需求。本分析分解了各種成本因素，以協助您的決策。</p><p>鑑於每個組織都有其獨特的需求，我們認識到單一文章無法涵蓋所有情況。如果您有本文未涵蓋的特定需求，請聯繫我們討論如何最佳支援您的實施。</p>",
  "comment_id": "679b56ba42b46600019a86e3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-01-30T11:38:50.000+01:00",
  "updated_at": "2025-01-31T05:32:29.000+01:00",
  "published_at": "2025-01-31T05:32:29.000+01:00",
  "custom_excerpt": "We offer detailed cost and performance breakdowns for three deployment strategies: Jina API, self-hosted K8s, and AWS SageMaker, to help you make the right decision.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "641c23a2f4d50d003d590474",
    "name": "Saahil Ognawala",
    "slug": "saahil",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
    "cover_image": null,
    "bio": "Senior Product Manager at Jina AI",
    "website": "http://www.saahilognawala.com/",
    "location": "Munich, DE",
    "facebook": null,
    "twitter": "@saahil",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-deploying-search-foundation-models-in-production/",
  "excerpt": "我們針對三種部署策略：Jina API、自建 K8s、以及 AWS SageMaker，提供詳細的成本和效能分析，協助您做出正確的決策。",
  "reading_time": 14,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}