{
  "slug": "jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images",
  "id": "673cc4a7a7c46d00015cf1f5",
  "uuid": "6ca44950-b989-494a-b587-70847f24edd2",
  "title": "Jina CLIP v2：文本與影像的多語言多模態嵌入表示",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-clip-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">我們正在努力通過開源和開放科學來推進和民主化人工智能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-11.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-clip-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?sui=&model=jina-clip-v2&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - 您的搜尋基礎，超級加速。</div><div class=\"kg-bookmark-description\">同類最佳的嵌入、重排序器、LLM 閱讀器、網頁爬蟲、分類器。最佳的多語言和多模態資料搜尋 AI。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">您的搜尋基礎，超級加速。</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> API 可在「Embeddings」分頁下使用。</span></p></figcaption></figure><p>多模態嵌入能夠通過統一的表示方式實現跨不同模態的數據搜索和理解。它們是神經資訊檢索和多模態 GenAI 應用的骨幹。今天，我們很高興發布 <code>jina-clip-v2</code>，這是一個建立在 <code>jina-clip-v1</code> 和我們最近發布的 <code>jina-embeddings-3</code> 基礎上的新型通用多語言多模態嵌入，具有以下幾個關鍵改進：</p><ul><li><strong>性能提升</strong>：v2 在文本-圖像和文本-文本檢索任務中比 v1 提高了 3% 的性能。與 v1 類似，v2 的文本編碼器可以作為有效的多語言長文本密集檢索器。它的表現與我們的前沿模型 <code>jina-embeddings-v3</code>（目前在 MTEB 上參數量低於 1B 的最佳多語言嵌入）不相上下。</li><li><strong>多語言支援</strong>：以 <code>jina-embeddings-v3</code> 作為文本塔，<code>jina-clip-v2</code> 支援 89 種語言的多語言圖像檢索，在多語言圖像檢索任務上比 <code>nllb-clip-large-siglip</code> 提高了高達 4% 的性能。</li><li><strong>更高的圖像解析度</strong>：v2 現在支援 512x512 輸入圖像解析度，相比 v1 的 224x224 有顯著提升。這種更高的解析度能夠更好地處理細節圖像，提升特徵提取，並更準確地識別細緻的視覺元素。</li><li><strong>套娃表示法</strong>：v2 允許用戶將文本和圖像嵌入的輸出維度從 1024 降至 64，減少存儲和處理開銷的同時保持強大的性能。</li></ul><h2 id=\"model-architecture\">模型架構</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--35-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p><code>jina-clip-v2</code> 是一個 0.9B 的 CLIP 風格模型，結合了兩個強大的編碼器：文本編碼器 <code>Jina XLM-RoBERTa</code>（<code>jina-embeddings-v3</code> 的骨幹）和視覺編碼器 <code>EVA02-L14</code>（由 BAAI 開發的高效視覺 Transformer）。這些編碼器經過聯合訓練以創建圖像和文本的對齊表示。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Text Encoder</th>\n<th>Image Encoder</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base Model</td>\n<td>Jina XLM-RoBERTa</td>\n<td>EVA02-L</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>561M</td>\n<td>304M</td>\n</tr>\n<tr>\n<td>Input Specification</td>\n<td>8,192 tokens (max)</td>\n<td>512×512 pixels</td>\n</tr>\n<tr>\n<td>Min Output Dimensions</td>\n<td>64</td>\n<td>64</td>\n</tr>\n<tr>\n<td>Max Output Dimensions</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Layers</td>\n<td>24</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Attention Mechanism</td>\n<td>FlashAttention2</td>\n<td>xFormers</td>\n</tr>\n<tr>\n<td>Pooling Strategy</td>\n<td>Mean pooling</td>\n<td>CLS pooling</td>\n</tr>\n<tr>\n<td>Additional Features</td>\n<td>89 languages supported</td>\n<td>Patch size 14x14</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"cross-modal-retrieval-performance\">跨模態檢索性能</h2><p>Jina CLIP v2 支援 89 種語言，並在主要語言（包括阿拉伯語、中文、英語、法語、德語、日語、俄語和西班牙語）中都有頂級表現。在多語言圖像檢索基準測試中，它的表現與或超過 <a href=\"https://huggingface.co/visheratin/nllb-clip-large-siglip?ref=jina-ai-gmbh.ghost.io\">NLLB-CLIP-SigLIP</a>，這是一個稍大（1.3B，比 <code>jina-clip-v2</code> 大 44%）的最先進 CLIP 風格模型，使用了來自 NLLB 模型的預訓練文本編碼器。</p><h3 id=\"english-only-text-and-images\">純英語文本和圖像</h3><p>在標準跨模態檢索基準（Flickr30k 和 COCO）上，<code>jina-clip-v2</code> 展示了全面的強大改進。它在 Flickr30k 圖像到文本檢索上達到了 98.0% 的最優性能，超過了其前身和 NLLB-CLIP-SigLIP。該模型在所有檢索場景中都表現出一致的提升，在 COCO 圖像到文本檢索上比 v1 提高了高達 3.3%，同時在不同基準和模態方向上都保持與 NLLB-CLIP-SigLIP 相當的競爭力。</p><p><strong>Flickr30k Recall@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>98.0</td>\n<td>+1.7%</td>\n<td>+0.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>96.4</td>\n<td>-</td>\n<td>-0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>97.1</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>89.8</td>\n<td>+0.9%</td>\n<td>-2.6%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>89.0</td>\n<td>-</td>\n<td>-3.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>92.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>COCO Recall@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>81.5</td>\n<td>+3.3%</td>\n<td>+2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>78.9</td>\n<td>-</td>\n<td>-0.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>79.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>68.4</td>\n<td>+2.9%</td>\n<td>-3.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>66.5</td>\n<td>-</td>\n<td>-6.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>70.8</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"multilingual-text-and-images\">多語言文本和圖像</h3><p>在多語言跨模態基準測試中，<code>jina-clip-v2</code> 展現出強健的性能，特別是在圖像到文本檢索方面表現出色，在所有數據集上都優於 NLLB-SigLIP，在 Crossmodal 3600 上提升高達 3.8%。雖然 NLLB-SigLIP 在文本到圖像檢索方面表現略優，但性能差距仍然很小，通常在 3% 以內。</p><p><strong>圖像轉文字 Recall@5 效能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>83.23</td>\n<td>+3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>80.16</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>86.03</td>\n<td>+0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.37</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.98</td>\n<td>+0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.41</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>文字轉圖像 Recall@5 效能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>81.43</td>\n<td>-0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>82.07</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>84.87</td>\n<td>-3.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.60</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.03</td>\n<td>-3.0%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.63</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"text-only-dense-retriever-performance\">純文字密集檢索器效能</h2>\n<p>與其前代產品類似，<code>jina-clip-v2</code> 的文字編碼器可作為高效的多語言密集檢索器。在全面的多語言 MTEB 基準測試中，它展現出強勁的效能，在檢索任務中達到 69.86%，在語義相似度任務中達到 67.77%。這些結果展示了它的多功能性，可與我們專門的文字嵌入模型 <code>jina-embeddings-v3</code> 相媲美：</p>\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>69.86</td>\n<td>-3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>72.59</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Semantic Similarity</td>\n<td>jina-clip-v2</td>\n<td>67.77</td>\n<td>-2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>69.81</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p>在英語任務中，<code>jina-clip-v2</code> 相較於其前代產品和 NLLB-SigLIP 都顯示出持續的改進，在檢索效能上尤其突出（幾乎是 NLLB-SigLIP 分數的兩倍）。</p>\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>STS</td>\n<td>jina-clip-v2</td>\n<td>81.29</td>\n<td>+0.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>80.92</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>74.65</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>49.33</td>\n<td>+2.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>48.33</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>24.92</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"matryoshka-representation-performance\">俄羅斯套娃表示效能</h2>\n<p>文字和圖像編碼器都支援 MRL，它們的輸出維度可以被截斷至 64，同時仍保持強勁的效能。我們的嵌入截斷評估揭示了顯著的壓縮潛力。即使是 75% 的維度減少，在文字、圖像和跨模態任務中仍能保持超過 99% 的效能。</p>\n<h3 id=\"image-classification\">圖像分類</h3>\n<p>在 37 個多樣化的圖像分類基準測試中，圖像編碼器對維度截斷表現出強大的韌性。從 1024 壓縮到 64 維度（減少 94%）僅導致 top-5 準確率下降 8%，top-1 下降 12.5%，凸顯了其在最小效能損失下進行高效部署的潛力。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/accuracy_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption>對於<b><strong style=\"white-space: pre-wrap;\">圖像分類</strong></b>，我們使用了 <a href=\"https://github.com/google-research/task_adaptation?ref=jina-ai-gmbh.ghost.io\">VTAB 數據集</a>中的 19 個基準測試，<a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/?ref=jina-ai-gmbh.ghost.io\">VOC 2007</a>、<a href=\"https://www.tensorflow.org/datasets/catalog/sun397?ref=jina-ai-gmbh.ghost.io\">SUN397</a>、<a href=\"https://cs.stanford.edu/~acoates/stl10/?ref=jina-ai-gmbh.ghost.io\">STL10</a>、<a href=\"https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md?ref=jina-ai-gmbh.ghost.io\">Rendered SST2</a>、<a href=\"https://objectnet.dev/?ref=jina-ai-gmbh.ghost.io\">ObjectNet</a>、<a href=\"https://github.com/cvdfoundation/mnist?ref=jina-ai-gmbh.ghost.io\">MNIST</a>、德國交通標誌識別基準（<a href=\"https://benchmark.ini.rub.de/gtsrb_dataset.html?ref=jina-ai-gmbh.ghost.io\">GTSRB</a>）、飛機細粒度視覺分類（<a href=\"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/?ref=jina-ai-gmbh.ghost.io\">FGVC-Aircraft</a>）、<a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge?ref=jina-ai-gmbh.ghost.io\">FER 2013</a>、<a href=\"https://github.com/openai/CLIP/blob/main/data/country211.md?ref=jina-ai-gmbh.ghost.io\">Country211</a>、<a href=\"https://www.tensorflow.org/datasets/catalog/cars196?ref=jina-ai-gmbh.ghost.io\">Cars196</a>、<a href=\"https://github.com/hendrycks/natural-adv-examples?ref=jina-ai-gmbh.ghost.io\">ImageNet-A、ImageNet-O</a>、<a href=\"https://huggingface.co/datasets/ILSVRC/imagenet-1k?ref=jina-ai-gmbh.ghost.io\">IxmageNet1k</a>、<a href=\"https://github.com/HaohanWang/ImageNet-Sketch?ref=jina-ai-gmbh.ghost.io\">ImageNet Sketch</a> 以及 <a href=\"https://imagenetv2.org/?ref=jina-ai-gmbh.ghost.io\">ImageNet v2</a>。</figcaption></figure><h3 id=\"cross-modal-retrieval\">跨模態檢索</h3><p>儘管維度劇烈縮減 94% 至僅 64 維，使用截斷的圖像和文本嵌入進行的跨模態檢索仍然保持remarkably穩健，保留了 93% 的圖像到文本和 90% 的文本到圖像性能。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/crossmodal_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption>我們使用了六個基準測試，其中三個是多語言的：<a href=\"https://google.github.io/crossmodal-3600/?ref=jina-ai-gmbh.ghost.io\">Crossmodal-3600</a>（36 種語言）、<a href=\"https://shannon.cs.illinois.edu/DenotationGraph/?ref=jina-ai-gmbh.ghost.io\">flickr30k</a>（僅英語）、<a href=\"https://hockenmaier.cs.illinois.edu/8k-pictures.html?ref=jina-ai-gmbh.ghost.io\">flickr8k</a>（僅英語）、<a href=\"https://arxiv.org/abs/1504.00325?ref=jina-ai-gmbh.ghost.io\">MS COCO Captions</a>（僅英語）、<a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\">Multilingual MS COCO Captions</a>（10 種語言）、<a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\">XTD 200</a>（27 種語言）</figcaption></figure><h3 id=\"text-only-retrieval\">純文本檢索</h3><p>在<strong>純英語 MTEB 基準測試</strong>中，64 維文本嵌入（從 1024 維壓縮）remarkably良好地保留了語義相似性，僅下降 2.1%，而檢索性能適度下降了 17.5%。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/mteb_performance.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"></figure><h2 id=\"getting-started\">入門指南</h2><h3 id=\"via-api\">通過 API</h3><p>此代碼展示如何使用 Python 的 <code>requests</code> 生成嵌入。傳入文本字串和 base64 圖像或 URL，以及所需的維度大小（預設 1024，下面顯示為 768）。</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-Python\">import requests\nimport numpy as np\nfrom numpy.linalg import norm\n\ncos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n\nurl = 'https://api.jina.ai/v1/embeddings'\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Authorization': 'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'\n}\n\ndata = {\n  'input': [\n     {\"text\": \"Bridge close-shot\"},\n     {\"url\": \"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s\"}],\n  'model': 'jina-clip-v2',\n  'encoding_type': 'float',\n  'dimensions': '768' \n}\n\nresponse = requests.post(url, headers=headers, json=data)\nsim = cos_sim(np.array(response.json()['data'][0]['embedding']), np.array(response.json()['data'][1]['embedding']))\nprint(f\"Cosine text&lt;-&gt;image: {sim}\")</code></pre><figcaption><p>記得將 &lt;YOUR_JINA_AI_API_KEY&gt; 替換為已激活的 Jina API 金鑰。您可以<a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">從這裡獲得一個包含一百萬免費代幣的免費 API 金鑰</a>。</p></figcaption></figure><h3 id=\"image-tokens-pricing\">圖像代幣定價</h3><p>我們的 API 同時計算文本和圖像代幣。對於圖像，代幣消耗基於覆蓋整個圖像區域所需的 512x512 像素塊數量。每個塊需要 4,000 個代幣來處理，包括部分填充的塊。<strong>為了獲得最佳成本效益，我們建議 API 用戶在發送請求前將圖像調整為 512x512。</strong></p><table>\n<thead>\n<tr>\n<th>圖像解析度</th>\n<th>所需塊數</th>\n<th>代幣成本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>512x512</td>\n<td>1</td>\n<td>4,000</td>\n</tr>\n<tr>\n<td>720x720</td>\n<td>4</td>\n<td>16,000</td>\n</tr>\n<tr>\n<td>1080x1080</td>\n<td>9</td>\n<td>36,000</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--37-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption>對於正方形圖像，調整為 512x512 可獲得最佳成本效益。對於需要保持長寬比的任務，將最長邊調整為 512，將圖像居中，並用黑色填充。對於一般用途，直接調整為 512x512 效果良好。</figcaption></figure><h3 id=\"via-csp-marketplaces\">通過 CSP 市場</h3><p>Jina CLIP v2 可直接在 AWS、Azure 和 GCP 上使用，價格如其所列。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-bfbctuqmky676?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina CLIP v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-10.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-9.ico\" alt=\"\"></div></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://console.cloud.google.com/marketplace/browse?q=jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Cloud console</div><div class=\"kg-bookmark-description\">透過 Google Cloud Marketplace 進行明智的消費、更快地採購，並兌現對 Google Cloud 的承諾支出。瀏覽超過 2000 個優化於 Google Cloud 運行的 SaaS、VM、開發堆疊和 Kubernetes 應用程式目錄。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/default.png\" alt=\"\"></div></div></a></figure><h3 id=\"via-vectordb\"><strong>透過 VectorDB</strong></h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">建構具知識的 AI 向量資料庫 | Pinecone</div><div class=\"kg-bookmark-description\">在數毫秒內搜尋數十億個項目中與任何物件相似的匹配。這是下一代的搜尋技術，只需一個 API 呼叫即可。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-3.png\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://weaviate.io/developers/weaviate/model-providers/jinaai/embeddings-multimodal?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">多模態嵌入 | Weaviate</div><div class=\"kg-bookmark-description\">Weaviate 與 Jina AI 的 API 整合讓您能直接從 Weaviate 存取他們的模型功能。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-12.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Weaviate</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/provider_integrations_jinaai.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant 是一個使用 Rust 編寫的開源向量資料庫和向量搜尋引擎。它提供快速且可擴展的向量相似度搜尋服務，具有便利的 API。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-4.png\" alt=\"\"><span class=\"kg-bookmark-author\">edit</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">結論</h2><p>在我們六月發布的 <code>jina-clip-v1</code>（將 OpenAI 的 CLIP 模型文本輸入擴展至 8,192 個令牌）以及前沿的多語言 <code>jina-embeddings-v3</code> 的基礎上，<code>jina-clip-v2</code> 帶來了三個重大進步：支援 89 種語言的多語言功能、提升至 512x512 的圖像解析度，以及用於更多截斷嵌入的套娃式表示學習。</p><p>類 CLIP 模型已經成為通用多模態應用程序的骨幹。透過 <code>jina-clip-v2</code>，我們將這些功能提升到新的層次，打破語言障礙，提供更準確的跨模態理解和檢索。我們相信這個版本實現了讓多模態搜尋和檢索變得更強大且更容易被全球開發者使用的承諾。</p>",
  "comment_id": "673cc4a7a7c46d00015cf1f5",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/11/clipv2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-11-19T18:02:31.000+01:00",
  "updated_at": "2024-11-21T17:29:45.000+01:00",
  "published_at": "2024-11-21T17:29:45.000+01:00",
  "custom_excerpt": "Jina-CLIP v2, a 0.9B multimodal embedding model with multilingual support of 89 languages, high image resolution at 512x512, and Matryoshka representations.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/",
  "excerpt": "Jina-CLIP v2，一個規模為 0.9B 的多模態嵌入模型，支援 89 種語言的多語言功能、512x512 的高解析度圖像處理能力，以及具備 Matryoshka 表示法。",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}