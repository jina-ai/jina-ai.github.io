{
  "slug": "jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking",
  "id": "66cd8fc6e84873000133d63d",
  "uuid": "e995c4d9-1832-4e2a-8108-e8453f5c82c5",
  "title": "Jina ColBERT v2：用於 Embedding 與重排序的多語言後期互動檢索器",
  "html": "<p>今天，我們很興奮地發佈 Jina ColBERT v2（<code>jina-colbert-v2</code>），這是一個基於 ColBERT 架構的進階後期互動檢索模型。這個新的語言模型改進了 <code>jina-colbert-v1-en</code> 的效能，並增加了多語言支援和動態輸出維度。</p><p>這個新版本具有以下特色：</p><ul><li>相比原始 ColBERT-v2 (+6.5%) 和我們的前一版本 <code>jina-colbert-v1-en</code>(+5.4%) 具有<strong>更優異的檢索效能</strong>。</li><li><strong>多語言支援</strong>，支援 89 種語言，在主要的全球語言中都能提供強大的效能。</li><li>通過 Matryoshka 表示學習實現<strong>使用者可控的輸出嵌入維度</strong>，使用者可以靈活地在效率和精確度之間取得平衡。</li></ul><h2 id=\"technical-summary-of-jina-colbert-v2\"><code>jina-colbert-v2</code> 技術摘要</h2><p>完整的技術報告可在 arXiv 上找到：</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2408.16672?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever</div><div class=\"kg-bookmark-description\">Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Rohan Jha</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure>\n\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th><code>jina-colbert-v2</code></th>\n<th><code>jina-colbert-v1-en</code></th>\n<th>Original ColBERTv2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>14 個英文 BEIR 任務<br/>的平均值</td>\n<td><b>0.521</b></td>\n<td>0.494</td>\n<td>0.489</td>\n</tr>\n<tr>\n<td>多語言</td>\n<td><b>89 種語言</b></td>\n<td>僅英文</td>\n<td>僅英文</td>\n</tr>\n<tr>\n<td>輸出維度</td>\n<td><b>128、96 或 64</b></td>\n<td>固定 128</td>\n<td>固定 128</td>\n</tr>\n<tr>\n<td>最大查詢長度</td>\n<td>32 個詞元</td>\n<td>32 個詞元</td>\n<td>32 個詞元</td>\n</tr>\n<tr>\n<td>最大文檔長度</td>\n<td>8192 個詞元</td>\n<td>8192 個詞元</td>\n<td>512 個詞元</td>\n</tr>  \n\n<tr>\n<td>參數量</td>\n<td>560M</td>\n<td>137M</td>\n<td>110M</td>\n</tr>\n<tr>\n<td>模型大小</td>\n<td>1.1GB</td>\n<td>550MB</td>\n<td>438MB</td>\n</tr>\n\n\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"asymmetric-embedding-in-colbert\">ColBERT 中的非對稱嵌入</h2><p>ColBERT 在 BERT 架構的基礎上增加了<strong>後期互動</strong>和<strong>非對稱</strong>查詢-文檔編碼。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">What is ColBERT and Late Interaction and Why They Matter in Search?</div><div class=\"kg-bookmark-description\">Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ColBERT 的非對稱性質意味著在使用 <code>jina-colbert-v2</code> 或 <code>jina-colbert-v1-en</code> 等模型時，你需要指定是要嵌入查詢、文檔，還是兩者都要（用於重排序）。這種額外的靈活性提升了檢索任務中相對於同質嵌入模型的效能。</p><h2 id=\"multilingual-support-for-over-89-languages\">支援超過 89 種語言的多語言功能</h2><p>Jina ColBERT v2 具有廣泛的多語言能力，旨在滿足現代全球化信息檢索和 AI 應用的需求。<code>jina-colbert-v2</code> 的訓練語料庫包含 89 種語言，並針對主要國際語言進行了額外的訓練階段，包括<strong>阿拉伯語、中文、英語、法語、德語、日語、俄語和西班牙語</strong>，以及<strong>程式語言</strong>。訓練還包含了對齊的雙語文本語料庫，以釋放跨語言潛力，允許在重排序/檢索任務中匹配不同語言的查詢和文檔。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Distribution-of-the-languages-in-the-training-corpus-at-the-pretrained-stage--3-.svg\" class=\"kg-image\" alt=\"訓練數據中語言分佈圖表，突出顯示英語和中文的主導地位。\" loading=\"lazy\" width=\"1456\" height=\"743\"><figcaption><span style=\"white-space: pre-wrap;\">預訓練數據集按語言的數據分佈（由 </span><a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ISO-639</span></a><span style=\"white-space: pre-wrap;\"> 代碼指定）以對數尺度顯示。</span></figcaption></figure><p>如今，Jina ColBERT v2 是<strong>唯一能生成緊湊嵌入的多語言 ColBERT 類模型</strong>，在 MIRACL 基準測試中的所有測試語言中都明顯優於基於 BM25 的檢索。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-Multilingual-Data--1-.svg\" class=\"kg-image\" alt=\"條形圖比較 jina-colbert-v2 和 BM25 在 20 種語言的多語言任務中的表現。\" loading=\"lazy\" width=\"691\" height=\"426\"><figcaption><span style=\"white-space: pre-wrap;\">在 MIRACL 基準測試中，Jina ColBERT v2 在 16 種語言中相較 BM25 的表現。</span></figcaption></figure><p>此外，在英語檢索任務中，Jina ColBERT v2 的效能超過了其前身 <code>jina-colbert-v1-en</code> 和原始的 ColBERT v2 模型，並與高度專門化的僅英語 <a href=\"https://huggingface.co/answerdotai/answerai-colbert-small-v1?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">AnswerAI-ColBERT-small</a> 模型效能相當。</p>\n<!--kg-card-begin: html-->\n<table class=\"simple-table\">\n  <tbody>\n<thead>\n<tr>\n      <th><strong>模型名稱</strong></th>\n      <th><strong>平均分數<br>(14 個 BEIR 僅英語基準測試)<br></strong></th>\n      <th><strong>多語言支援</strong></th>\n  </tr>\n    </thead>\n    <tr>\n      <td><code>jina-colbert-v2</code></td>\n      <td>0.521</td>\n      <td>多語言</td>\n    </tr>\n    <tr>\n      <td><code>jina-colbert-v1-en</code></td>\n      <td>0.494</td>\n      <td>僅英語</td>\n    </tr>\n    <tr>\n      <td>ColBERT v2.0</td>\n      <td>0.489</td>\n      <td>僅英語</td>\n    </tr>\n    <tr>\n      <td>AnswerAI-ColBERT-small</td>\n      <td>0.549</td>\n      <td>僅英語</td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-English-only-datasets-from-BEIR--2-.svg\" class=\"kg-image\" alt=\"條形圖顯示多個模型如 'jina-colbert' 和 'BM25' 在英語 BEIR 數據集上的評估結果。\" loading=\"lazy\" width=\"1088\" height=\"712\"><figcaption><span style=\"white-space: pre-wrap;\">jina-colbert-v2 在 BEIR 基準測試的部分僅英語數據集上的評估。</span></figcaption></figure><h2 id=\"matryoshka-representation-learning\">Matryoshka 表示學習</h2><p><a href=\"https://arxiv.org/abs/2205.13147?ref=jina-ai-gmbh.ghost.io\">Matryoshka 表示學習</a>是一種訓練模型以支援不同輸出向量大小，同時最小化精確度損失的技術。我們使用多個不同的線性投影頭（神經網路的最終層）來訓練網路的隱藏層，每個投影頭支援不同的輸出大小。<strong>Jina ColBERT v2 支援 128、96 和 64 維度的輸出向量。</strong></p><p>Jina ColBERT v2 預設產生 128 維的輸出嵌入，但也可以產生 96 和 64 維的輸出，它們的效能幾乎相同，但分別縮短了 25% 和 50% 的長度。</p><p>下表顯示了 <a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain?ref=jina-ai-gmbh.ghost.io\">nDGC</a> 效能<code>jina-colbert-v2</code> 在六個 BEIR 基準測試中的前十個結果（<em>nDGC@10</em>）。從這裡可以看出，128 維度和 96 維度之間的性能差異僅約 1%，而 128 和 64 維度之間的差異不到 1.5%。</p>\n\n<!--kg-card-begin: html-->\n<table id=\"b838dc78-1321-499e-98e7-63e3b5c8e910\" class=\"simple-table\"><tbody><thead id=\"177f4349-0620-4947-a3ce-01e598395ed7\"><tr><th id=\"<\\ml\" class=\"\"><strong>輸出維度</strong></th><th id=\"<NYX\" class=\"\"><strong>平均分數</strong><strong><br>（6 個基準測試的 nDGC@10）<br></strong></th></tr></thead><tr id=\"9199b56b-0513-4c99-a2a7-29cde915c3b9\"><td id=\"<\\ml\" class=\"\">128</td><td id=\"<NYX\" class=\"\">0.565</td></tr><tr id=\"af4d45fc-ebf4-4e1f-b5b0-1807a1cb889b\"><td id=\"<\\ml\" class=\"\">96</td><td id=\"<NYX\" class=\"\">0.558</td></tr><tr id=\"ecf7eac9-5c56-47e6-ab27-0ddb4659e263\"><td id=\"<\\ml\" class=\"\">64</td><td id=\"<NYX\" class=\"\">0.556</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Performance-on-selected-BEIR-benchmarks.svg\" class=\"kg-image\" alt=\"BEIR 基準測試的條形圖，突出顯示從 nfcorpus 到 msmarco 等數據集的分數，jina-colbert-v2.64 表現優異。\" loading=\"lazy\" width=\"732\" height=\"538\"><figcaption><span style=\"white-space: pre-wrap;\">不同輸出維度下的 Jina ColBERT v2 性能。</span></figcaption></figure><p>減少輸出向量的大小可以節省空間，並加快向量比較或計算向量間距離等信息檢索應用的速度。</p><p>這會帶來顯著的成本影響，僅從存儲方面來看就很明顯。例如，使用 <a href=\"https://cloud.qdrant.io/calculator?ref=jina-ai-gmbh.ghost.io\">Qdrant 的雲端成本計算器</a>，在 AWS 上存儲 1 億個文檔，每個文檔使用 128 維向量，<a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=128&ref=jina-ai-gmbh.ghost.io\">估計每月成本為 1,319.24 美元</a>。而使用 64 維度時，<a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=64&ref=jina-ai-gmbh.ghost.io\">成本降至 659.62 美元</a>。</p><h2 id=\"getting-started-with-jina-colbert-v2\">開始使用 Jina ColBERT v2</h2><p>Jina ColBERT v2 可通過 Jina Search Foundation API、<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS marketplace</a> 和 <a href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\">Azure</a> 獲取。它也可在 <a href=\"https://huggingface.co/jinaai/jina-colbert-v2?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a> 上獲取，但僅供非商業用途（<a href=\"https://www.creativecommons.org/licenses/by-nc/4.0/deed.en?ref=jina-ai-gmbh.ghost.io\">CC BY-NC-4.0</a>）。</p><h3 id=\"via-jina-search-foundation-api\">通過 Jina Search Foundation API</h3><h4 id=\"for-embedding\">用於嵌入</h4><p>以下 <code>curl</code> 命令展示了如何通過 Jina Embeddings API 指定輸入和選項以獲取 <code>jina-colbert-v2</code> 的文檔嵌入。要獲取您想要的向量大小，請在 <code>dimensions</code> 參數中指定 128 或 64。此參數是可選的，默認值為 128。</p><p>如果輸入文檔超過 8192 個 token，將被截斷。</p><p>在授權標頭中指定您的 Jina API 密鑰 <code>Authorization: Bearer &lt;YOUR JINA API KEY&gt;</code>：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # 或使用 64 以獲得半尺寸向量\n\t\"input_type\": \"document\", # 查詢嵌入請見下文\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your document text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each text can be up to 8192 tokens long\"\n    ]}'\n</code></pre><p>要獲取查詢嵌入，請將 <code>input_type</code> 參數設置為 <code>query</code> 而非 <code>document</code>。請注意，查詢的大小限制比文檔更嚴格。它們將在 32 個 token 處被截斷。查詢編碼將始終返回 32 個 token，如果少於 32 個 token，則包括填充的嵌入。</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # 或使用 64 以獲得半尺寸向量\t\n\t\"input_type\": \"query\", # 查詢嵌入必須指定此項\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your query text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each query text can be up to 32 tokens long\"\n    ]}'\n</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Multimodal, bilingual long-context embeddings for your search and RAG.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"for-reranking\">用於重排序</h4><p>要通過 Jina Reranker API 使用 <code>jina-colbert-v2</code>，傳入一個查詢和幾個文檔並獲得可排序的匹配分數，請按如下方式構建您的請求：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/rerank \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n      \"model\": \"jina-colbert-v2\",\n      \"query\": \"What is the population of Berlin?\",\n      \"top_n\": 3,\n      \"documents\": [\n        \"Berlin's population grew by 0.7 percent in 2023 compared with the previous year. Accordingly, around 27,300 more residents lived in Berlin at the end of the last year than in 2022. Those of 30 to under 40 years old form the numerically largest age group. With roughly 881,000 foreign residents from around 170 nations and an average age of the population of 42.5 years old.\",\n        \"Mount Berlin is a glacier-covered volcano in Marie Byrd Land, Antarctica, 100 kilometres (62 mi) from the Amundsen Sea. It is a roughly 20-kilometre-wide (12 mi) mountain with parasitic vents that consists of two coalesced volcanoes: Berlin proper with the 2-kilometre-wide (1.2 mi) Berlin Crater and Merrem Peak with a 2.5-by-1-kilometre-wide (1.55 mi × 0.62 mi) crater, 3.5 kilometres (2.2 mi) away from Berlin.\",\n        \"Population as of 31.12.2023 by nationality and federal states Land\\\\tTotal\\\\tGermans\\\\tForeigners\\\\tincluding EU-states number\\\\t%\\\\tnumber\\\\t%\",\n        \"The urban area of Berlin has a population of over 4.5 million and is therefore the most populous urban area in Germany. The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region, and the sixth-biggest metropolitan region by GDP in the European Union.\",\n        \"Irving Berlin (born Israel Beilin) was an American composer and songwriter. His music forms a large part of the Great American Songbook. Berlin received numerous honors including an Academy Award, a Grammy Award, and a Tony Award.\",\n        \"Berlin is a town in the Capitol Planning Region, Connecticut, United States. The population was 20,175 at the 2020 census.\",\n        \"Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\",\n        \"Berlin, Berlin ist eine für die ARD produzierte Fernsehserie, die von 2002 bis 2005 im Vorabendprogramm des Ersten ausgestrahlt wurde. Regie führten unter anderem Franziska Meyer Price, Christoph Schnee, Sven Unterwaldt Jr. und Titus Selge.\"\n        ]\n    }'</code></pre><p>注意 <code>top_n</code> 參數，它指定了您想要檢索的文檔數量。例如，如果您的應用程式只使用最佳匹配，請將 <code>top_n</code> 設置為 1。</p><p>如需 Python 和其他程式語言及框架的程式碼片段，請訪問 <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina AI Embeddings API 頁面</a>，或在 <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina Reranker API 頁面</a>的下拉選單中選擇 <code>jina-colbert-v2</code>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reranker API</div><div class=\"kg-bookmark-description\">Maximize the search relevancy and RAG accuracy at ease.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-reranker-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"via-stanford-colbert\">通過 Stanford ColBERT</h3><p>您也可以在 Stanford ColBERT 函式庫中使用 Jina ColBERT v2 作為 <a href=\"https://github.com/stanford-futuredata/ColBERT?ref=jina-ai-gmbh.ghost.io\">ColBERT v2</a> 的替代方案。只需將 <code>jinaai/jina-colbert-v2</code> 指定為模型來源：</p><pre><code class=\"language-python\">from colbert.infra import ColBERTConfig\nfrom colbert.modeling.checkpoint import Checkpoint\n\nckpt = Checkpoint(\"jinaai/jina-colbert-v2\", colbert_config=ColBERTConfig())\ndocs = [\"Your list of texts\"] \nquery_vectors = ckpt.queryFromText(docs)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">您必須安裝 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code> 才能使用上述程式碼。</div></div><h3 id=\"via-ragatouille\">透過 RAGatouille</h3><p>Jina ColBERT v2 同樣也整合到了 <a href=\"https://github.com/AnswerDotAI/RAGatouille?ref=jina-ai-gmbh.ghost.io\">RAGatouille</a>。您可以透過 <code>RAGPretrainedModel.from_pretrained()</code> 方法下載並使用它：</p><pre><code class=\"language-python\">from ragatouille import RAGPretrainedModel\n\nRAG = RAGPretrainedModel.from_pretrained(\"jinaai/jina-colbert-v2\")\ndocs = [\"Your list of texts\"]\nRAG.index(docs, index_name=\"your_index_name\")\nquery = \"Your query\"\nresults = RAG.search(query)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">您必須安裝 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> 和 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code> 才能使用上述程式碼。</div></div><h3 id=\"via-qdrant\">透過 Qdrant</h3><p>自 1.10 版本起，Qdrant 已新增對多向量和後期互動模型的<a href=\"https://qdrant.tech/blog/qdrant-1.10.x/?ref=jina-ai-gmbh.ghost.io\">支援</a>。無論是本地還是託管雲端版本的 Qdrant 引擎的現有用戶，都可以透過 Qdrant 的客戶端直接整合 <code>jina-colbert-v2</code>。</p><p><strong>使用 MAX_SIM 操作建立新的集合</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nqdrant_client.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config={\n        \"colbert\": models.VectorParams(\n            size=128,\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM\n            ),\n        )\n    }\n)</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">正確設定 <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">multivector_config</code> 參數對於在 Qdrant 中使用 ColBERT 類型的模型至關重要。</div></div><p><strong>將文件插入多向量集合</strong></p><pre><code class=\"language-Python\">import requests\nfrom qdrant_client import QdrantClient, models\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\ndata = {\n    'model': 'jina-colbert-v2',\n    'input_type': 'query',\n    'embedding_type': 'float',\n    'input': [\n        'Your text string goes here',\n        'You can send multiple texts',\n        'Each text can be up to 8192 tokens long'\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nrows = response.json()[\"data\"]\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nfor i, row in enumerate(rows):\n    qdrant_client.upsert(\n        collection_name=\"{collection_name}\",\n        points=[\n            models.PointStruct(\n                id=i,  \n                vector=row[\"embeddings\"],  \n                payload={\"text\": data[\"input\"][i]} \n            )\n        ],\n    )</code></pre><p><strong>查詢集合</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\nimport requests\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;YOUR BEARER&gt;'\n}\n\n\ndata = {\n    'model': 'jina-colbert-v2',\n    \"input_type\": \"query\",\n    \"embedding_type\": \"float\",\n    \"input\": [\n        \"how many tokens in an input do Jina AI's embedding models support?\"\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nvector = response.json()[\"data\"][0][\"embeddings\"]\n\n\nqdrant_client = QdrantClient(\n    url=\"&lt;YOUR_ENDPOINT&gt;\",\n    api_key=\"&lt;YOUR_API_KEY&gt;\",\n)\n\nresults = qdrant_client.query_points(\n    collection_name=\"{collection_name}\",\n    query=vector,\n)\n\nprint(results)</code></pre><h3 id=\"summary\">總結</h3><p>Jina ColBERT v2（<code>jina-colbert-v2</code>）在 <code>jina-colbert-v1-en</code> 的高性能基礎上，將其功能擴展到了更廣泛的全球語言。透過支援多種嵌入向量大小，<code>jina-colbert-v2</code> 允許用戶根據其特定用例調整精確度/效率的平衡，可能會在時間和計算成本上帶來顯著節省。</p><p>這個模型將所有這些功能組合成一個價格具有競爭力的套件，可透過直觀的網頁 API 存取，並與支援 HTTP 請求的任何計算框架相容。<a href=\"https://jina.ai/?sui=&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">立即試用</a>，獲得 100 萬個免費代幣，看看它如何增強您的應用程式和流程。</p>",
  "comment_id": "66cd8fc6e84873000133d63d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-08-27T10:35:18.000+02:00",
  "updated_at": "2024-09-09T07:43:38.000+02:00",
  "published_at": "2024-08-30T09:19:58.000+02:00",
  "custom_excerpt": "Jina ColBERT v2 supports 89 languages with superior retrieval performance, user-controlled output dimensions, and 8192 token-length. ",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking/",
  "excerpt": "Jina ColBERT v2 支援 89 種語言，具有卓越的檢索效能、使用者可控的輸出維度，以及 8192 的 token 長度。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dark-themed coding interface displaying English and Japanese characters with \"JINA COLBERT V2\" highlighted in the center.",
  "feature_image_caption": null
}