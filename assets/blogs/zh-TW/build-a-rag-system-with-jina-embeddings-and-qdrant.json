{
  "slug": "build-a-rag-system-with-jina-embeddings-and-qdrant",
  "id": "65ddadd039a5b70001810ea3",
  "uuid": "e3419a3e-4a7c-43c3-ac69-6f65f00a7ad8",
  "title": "使用 Jina Embeddings 和 Qdrant 構建 RAG 系統",
  "html": "<p>檢索增強生成是一組快速發展的技術，它最初被<a href=\"https://dl.acm.org/doi/abs/10.5555/3495724.3496517?ref=jina-ai-gmbh.ghost.io\"><u>設計作為大型語言模型</u></a>（LLM）的擴展，但現在越來越被視為一種完全重新構想 AI 模型角色的替代範式。</p><p>我們將向您展示如何使用 <a href=\"https://www.llamaindex.ai/?ref=jina-ai-gmbh.ghost.io\">LlamaIndex 框架</a>、開源 <a href=\"https://docs.mistral.ai/?ref=jina-ai-gmbh.ghost.io\">Mistral LLM</a>、<a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2</a> 以及 <a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\">Qdrant 的 AI 就緒向量資料庫</a>來構建一個基本的 RAG 引擎。</p><h2 id=\"rag-in-context\"><strong>RAG 的背景</strong></h2><p>在 RAG 系統中，AI 模型的角色仍然很重要但更加有限。它不是從其訓練數據中獲得的內部知識來回答提示，而是在其提示中呈現相關信息。然後模型的角色是理解並將信息合成為輸出。</p><p>這發揮了 AI 模型的優勢並最小化了其缺點。</p><p>例如，我們可能給 <a href=\"https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io\"><u>Mistral-Instruct 模型</u></a>以下提示：</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\nQuery: Why is Taylor Swift planning to attend the Superbowl?\nAnswer:\n</code></pre><p>當我這樣做時，模型回應：</p><pre><code class=\"language-text\">I don't have real-time information. However, as of my last update,&nbsp;\nTaylor Swift is not officially confirmed to attend or perform at&nbsp;\nthe Superbowl. If there are any updates, I recommend checking the&nbsp;\nlatest news sources.</code></pre><p>大型語言模型的更新和再訓練成本很高，因此它們的內部信息永遠無法完全保持最新。</p><p>此外，眾所周知大型語言模型會「產生幻覺」，即編造出看似合理但可能部分或完全錯誤且需要驗證的答案。</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\nQuery: What was Weird Al Yankovic's first Taylor Swift parody?\nAnswer:\n\nWeird Al Yankovic's first Taylor Swift parody was \"TMZ,\" a spoof&nbsp;\nof Swift's song \"Blank Space.\" The parody was released in 2014&nbsp;\nas part of Yankovic's album \"Mandatory Fun.\" The song humorously&nbsp;\naddresses the obsession with celebrity gossip and scandals, as&nbsp;\nreported by the tabloid news website TMZ.</code></pre><p>怪人艾爾·揚科維奇的 <em>TMZ</em> 於 2011 年在專輯 <em>Alpocalypse</em> 中發行，是對 Swift 的 <a href=\"https://youtu.be/vwp8Ur6tO-8?ref=jina-ai-gmbh.ghost.io\"><em><u>You Belong with Me</u></em></a> 的模仿。</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/BwqFgnl4rMs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\" title=\"TMZ (Parody of &quot;You Belong With Me&quot; by Taylor Swift) (Official 4K Video)\"></iframe></figure><p>神經網絡的本質使幻覺難以完全避免，這嚴重削弱了將 AI 模型作為信息來源的任何計劃。</p><p>用 OpenAI 的 CEO Sam Altman 的<a href=\"https://youtu.be/uaQZIK9gvNo?t=1130&ref=jina-ai-gmbh.ghost.io\"><u>話來說</u></a>：</p><blockquote class=\"kg-blockquote-alt\">「我認為當人們把這些模型（LLM）當作數據庫時是一個很大的錯誤。[…] 它會運作，但效果有限。但它是世界上最貴、最慢、最不精確的數據庫。」</blockquote><p>RAG 最大限度地減少了對 AI 模型內部世界知識的依賴，並利用了它的最大優勢：自然語言理解和流暢的語言生成。</p><p>讓我們再看一個 Mistral-Instruct 無法回答的問題：</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\n\nQuery: What is the title of Taylor Swift's next album?\nAnswer:\n\nAs of the time I am providing this answer, Taylor Swift has&nbsp;\nnot yet announced the title of her next album. She has released&nbsp;\nseveral re-recorded albums, but the title of her next original&nbsp;\nalbum remains unknown. I recommend checking her official social&nbsp;\nmedia channels or website for the latest updates.</code></pre><p>現在，RAG 系統可能會有一個最近新聞文章的數據庫，或者也許會在網上搜索與 Taylor Swift 的下一張專輯標題相關的文本。然後，它會將找到的文本插入提示中。</p><p>假設它識別出<a href=\"https://apnews.com/article/taylor-swift-new-album-5e219107982b1498a3656caeea85e0eb?ref=jina-ai-gmbh.ghost.io\"><u>這篇美聯社文章</u></a>與查詢相關，並構建以下提示：</p><pre><code class=\"language-text\">Context information is below.\n---------------------\nFebruary 6, 2024\nLOS ANGELES (AP) — Forget her \"Reputation.\" Taylor Swift has a&nbsp;\nwhole new album coming out.\n\nAccepting the Grammy for best pop vocal album on Sunday night,&nbsp;\nTaylor said she'd been keeping a secret for two years.\n\n\"My brand-new album comes out April 19. It's called 'The Tortured&nbsp;\nPoets Department.' I'm going to go and post the cover right now&nbsp;\nbackstage,\" she announced.\n\nAnd so she did.\n\n---------------------\nGiven the context information and not prior knowledge, answer the query.&nbsp;\nPlease be brief, concise, and complete.\nIf the context information does not contain an answer to the query,&nbsp;\nrespond with \"No information\".\nQuery: What is the title of Taylor Swift's next album?\nAnswer:</code></pre><p>Mistral-Instruct 回應道：</p><pre><code class=\"language-text\">The title of Taylor Swift's next album is 'The Tortured Poets Department'.</code></pre><p>這種提示方式也大大降低了產生幻覺的可能性。例如：</p><pre><code class=\"language-text\">Context information is below.\n---------------------\nAlpocalypse is the thirteenth studio album by American parody&nbsp;\nmusician \"Weird Al\" Yankovic, released on June 21, 2011.\n\nTrack List\n\n1. Perform This Way (Parody of \"Born This Way\" by Lady Gaga)\n2. CNR\n3. TMZ (Parody of \"You Belong with Me\" by Taylor Swift)\n4. Skipper Dan\n5. Polka Face (Polka medley including songs by artists such as&nbsp;\n&nbsp;&nbsp;&nbsp;Lady Gaga, Justin Bieber, Britney Spears, Ke$ha, and others)\n6. Craigslist\n7. Party in the CIA (Parody of \"Party in the U.S.A.\" by Miley&nbsp;\n&nbsp;&nbsp;&nbsp;Cyrus)\n8. Ringtone\n9. Another Tattoo (Parody of \"Nothin' on You\" by B.o.B featuring&nbsp;\n&nbsp;&nbsp;&nbsp;Bruno Mars)\n10. If That Isn't Love\n11. Whatever You Like (Parody of \"Whatever You Like\" by T.I.)\n12. Stop Forwarding That Crap to Me\n\n---------------------\nGiven the context information and not prior knowledge, answer the&nbsp;\nquery. Please be brief, concise, and complete.\nIf the context information does not contain an answer to the query,&nbsp;\nrespond with \"No information\".\nQuery: What was Weird Al Yankovic's first Taylor Swift parody, what&nbsp;\nyear was it released, and what song was he parodying?\nAnswer:\n\nWeird Al Yankovic's first Taylor Swift parody was \"TMZ,\" and it was&nbsp;\nreleased in 2011. He was parodying \"You Belong with Me\" by Taylor&nbsp;\nSwift.\n</code></pre><h2 id=\"anatomy-of-a-rag-system\"><strong>RAG 系統的結構</strong></h2><p>RAG 系統至少有兩個組件：</p><ul><li>生成式 AI 模型</li><li>信息檢索系統</li></ul><p>在本文中，我們將使用 <a href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2?ref=jina-ai-gmbh.ghost.io\">Mistral-Instruct</a> 作為生成式 AI 模型，並通過 <a href=\"https://huggingface.co/docs/api-inference/index?ref=jina-ai-gmbh.ghost.io\">Hugging Face Inference API</a> 訪問它。我們將使用 <a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\">Qdrant 向量資料庫</a>和 <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings</a> 作為信息檢索系統。</p><p>作為數據源，我們將使用 <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf?ref=jina-ai-gmbh.ghost.io\"><em><u>2023 年國家人工智能研究和開發戰略計劃更新</u></em></a>，這是由向美國總統提供科技事務建議的 <a href=\"https://www.whitehouse.gov/ostp/ostps-teams/nstc/?ref=jina-ai-gmbh.ghost.io\">國家科學技術委員會</a>於 2023 年 5 月發布的文件。這份約 25,000 字的文件是美國 AI 政策和發展的政策與戰略規劃文件。</p><p>這也是一份典型的「太長不讀」政府政策文件。其中大部分內容都很乏味，除非您在這個領域有利害關係或密切興趣，否則您可能不會閱讀它。但您可能仍然想知道它說了什麼。</p><p>本文將引導您完成創建一個能夠回答有關文本及其內容問題的 RAG 系統的步驟。</p><h2 id=\"install-the-prerequisites\"><strong>安裝先決條件</strong></h2><p>首先，確保您已安裝所有相關的 Python 庫。在您的 Python 環境中運行以下命令：</p><pre><code class=\"language-shell\">pip install llama-index qdrant-client \npip install pdfminer.six llama-index-vector-stores-qdrant\npip install llama-index-llms-openai llama-index-embeddings-jinaai \npip install llama-index-llms-huggingface \"huggingface_hub[inference]\"</code></pre><p>我們將使用 LlamaIndex 來構建一個以 Mistral-Instruct 大型語言模型為基礎的 RAG 系統，並使用 <a href=\"https://pypi.org/project/pdfminer.six/?ref=jina-ai-gmbh.ghost.io\"><u>pdfminer.six</u></a> 來將 PDF 檔案處理成 Qdrant 向量存儲。</p><h2 id=\"connect-to-mistral-instruct-via-the-hugging-face-inference-api\"><strong>通過 Hugging Face Inference API 連接 Mistral-Instruct</strong></h2><p>首先，設置 LLM。你需要有 Hugging Face Inference API 的存取權限，包括存取令牌。如果你有 Hugging Face 帳號，可以從<a href=\"https://huggingface.co/settings/tokens.?ref=jina-ai-gmbh.ghost.io\">你的帳號設定頁面</a>獲取。</p><p>如果你還沒有帳號，請先<a href=\"https://huggingface.co/join?ref=jina-ai-gmbh.ghost.io\">註冊一個</a>，然後創建一個<a href=\"https://huggingface.co/settings/tokens?ref=jina-ai-gmbh.ghost.io\">存取令牌</a>。</p><p>將你的令牌放入一個變數以供後續使用：</p><pre><code class=\"language-python\">hf_inference_api_key = '<your HuggingFace Inference API token>'</code></pre><p>接下來，我們構建一個提示模板：</p><pre><code class=\"language-python\">from llama_index.core import PromptTemplate\n\nqa_prompt_tmpl = (\n    \"Context information is below.\\n\"\n    \"---------------------\\n\"\n    \"{context_str}\\\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the query. Please be brief, concise, and complete.\\n\"\n    \"If the context information does not contain an answer to the query, \"\n    \"respond with \\\"No information\\\".\\n\"\n    \"Query: {query_str}\\n\"\n    \"Answer: \"\n)\nqa_prompt = PromptTemplate(qa_prompt_tmpl)</code></pre><p>這個模板指示 LLM 僅使用提示中提供的上下文信息來回答問題。這個提示在我們使用 Mistral-Instruct 時效果很好，但你可以嘗試其他表述方式來看看什麼最適合你的使用案例。</p><pre><code class=\"language-python\">from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n\nmixtral_llm = HuggingFaceInferenceAPI(\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n    token=hf_inference_api_key\n)</code></pre><p>最後，創建並初始化一個 LlamaIndex 框架的物件，用於保存與 Mistral-Instruct 的連接。以下代碼來自<a href=\"https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/?ref=jina-ai-gmbh.ghost.io\"><u>之前關於使用 LlamaIndex 創建 RAG 系統的文章</u></a>。</p><p>這將把與 Mistral LLM 的連接放入變數 <code>mistral_llm</code>。</p><h2 id=\"information-retrieval-with-qdrant-and-jina-embeddings\"><strong>使用 Qdrant 和 Jina Embeddings 進行信息檢索</strong></h2><p>要設置檢索系統，你需要一個 Jina Embeddings API 金鑰。你可以在 <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings 網站</a>免費獲得一個包含 100 萬個代幣預付額度的金鑰。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Start with 1M free tokens. Top-performing, 8192 context length bilingual embeddings for your search and RAG systems.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>將你的 Jina Embeddings 金鑰放入一個變數以供後續使用：</p><pre><code class=\"language-python\">jina_emb_api_key = \"<your Jina Embeddings API key>\"</code></pre><p>然後，使用 LlamaIndex 創建一個連接到 Jina Embeddings 伺服器的連接器物件，特別選擇英語單語模型：</p><pre><code class=\"language-python\">from llama_index.embeddings.jinaai import JinaEmbedding\n\njina_embedding_model = JinaEmbedding(\n    api_key=jina_emb_api_key,\n    model=\"jina-embeddings-v2-base-en\",\n)</code></pre><h3 id=\"load-text-data\"><strong>載入文本數據</strong></h3><p>接下來，我們將載入文件並將其分割成段落。首先，從白宮網站下載 PDF 到變數 <code>pdf_data</code>：</p><pre><code class=\"language-python\">import urllib.request\n\nuri = \"https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf\"\npdf_data = urllib.request.urlopen(uri).read()</code></pre><p>接下來，我們將逐頁處理 PDF，提取文本然後通過按雙行分割將其分成段落。這些內容存儲在列表 <code>text_paras</code> 中：</p><pre><code class=\"language-python\">import regex as re\nfrom io import BytesIO, StringIO\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfdocument import PDFDocument\nfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.pdfpage import PDFPage\nfrom pdfminer.pdfparser import PDFParser\n\ntext_paras = []\nparser = PDFParser(BytesIO(pdf_data))\ndoc = PDFDocument(parser)\nrsrcmgr = PDFResourceManager()\nfor page in PDFPage.create_pages(doc):\n    output_string = StringIO()\n    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    interpreter.process_page(page)\n    page_text = output_string.getvalue()\n    text_paras.extend(re.split(r'\\n\\s*\\n', page_text))\n</code></pre><p>檢查是否全部載入：</p><pre><code class=\"language-python\">assert len(text_paras) == 615</code></pre><p>接下來，我們將這個短文本列表轉換為 <a href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/root.html?ref=jina-ai-gmbh.ghost.io\">LlamaIndex Document 物件</a>：</p><pre><code class=\"language-python\">from llama_index.core.readers import StringIterableReader\n\nrag_docs = StringIterableReader().load_data(text_paras)</code></pre><p>你可以檢查文本：</p><pre><code class=\"language-python\">print(rag_docs[0].text)</code></pre><p>結果：</p><pre><code class=\"language-text\">NATIONAL ARTIFICIAL INTELLIGENCE \nRESEARCH AND DEVELOPMENT \nSTRATEGIC PLAN \n2023 UPDATE</code></pre><h3 id=\"set-up-a-qdrant-vector-database\"><strong>設置 Qdrant 向量數據庫</strong></h3><p>在本文中，我們將使用 <a href=\"https://cloud.qdrant.io/?ref=jina-ai-gmbh.ghost.io\"><u>Qdrant Vector Search Cloud</u></a> 來實現 RAG 系統的數據庫。Qdrant 的免費層包括 1GB 的存儲空間，對於本教程來說已經足夠了。</p><p>在繼續之前，你需要<a href=\"https://cloud.qdrant.io/login?ref=jina-ai-gmbh.ghost.io\"><u>在 Qdrant Cloud 網站上創建一個帳號</u></a>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://cloud.qdrant.io/login?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Vector Search Database | Qdrant Cloud</div><div class=\"kg-bookmark-description\">Managed cloud solution of the Qdrant vector search engine. Cloud-native vector database for high performant vector similarity search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cloud.qdrant.io/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Qdrant Cloud</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cloud.qdrant.io/social.png\" alt=\"\"></div></a></figure><p>一旦你有了帳號並登入，你需要創建一個叢集。按照 Qdrant 網站上的<a href=\"https://qdrant.tech/documentation/cloud/quickstart-cloud/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>「快速入門」說明</u></a>來設置一個免費叢集並獲取 API 和 Qdrant 主機伺服器名稱。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/cloud/quickstart-cloud/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Quickstart - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://qdrant.tech/images/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Edit on GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://qdrant.tech/documentation/cloud/quickstart-cloud-social-preview.png\" alt=\"\"></div></a></figure><p>將金鑰和主機名存儲在變數中：</p><pre><code class=\"language-python\">qdrant_api_key = \"<your API key>\"\nqdrant_server = \"https://<your server>\"</code></pre><p>接下來，我們需要從 <code>qdrant_client</code> 和 <code>llama_index</code> 套件中導入相關組件：</p><pre><code class=\"language-python\">import qdrant_client\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\n\nclient = qdrant_client.QdrantClient(qdrant_server, api_key=qdrant_api_key)\nvector_store = QdrantVectorStore(client=client, collection_name=\"NTSC\")</code></pre><p>這將在你的免費叢集中建立一個名為 <code>NTSC</code> 的集合。</p><p>你可以閱讀 <a href=\"https://qdrant.tech/documentation/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>Qdrant 文件</u></a> 以了解如何在記憶體或硬碟中建構本地數據存儲，以及如何通過 web API 在 docker 容器中託管你自己的 Qdrant 服務器實例。</p><h3 id=\"complete-the-rag-system\"><strong>完成 RAG 系統</strong></h3><p>現在我們將使用 LlamaIndex 的樣板代碼將這些組件組裝成一個完整的 RAG 系統：</p><pre><code class=\"language-python\">from llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.storage.storage_context import StorageContext\nfrom llama_index.core import (\n\t\tVectorStoreIndex,\n\t\tServiceContext,\n\t\tget_response_synthesizer,\n)\n\n# set up the service and storage contexts\nservice_context = ServiceContext.from_defaults(\n&nbsp;&nbsp;&nbsp;&nbsp;llm=mixtral_llm, embed_model=jina_embedding_model\n)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n# create an index\nindex = VectorStoreIndex.from_documents(\n&nbsp;&nbsp;&nbsp;&nbsp;rag_docs, storage_context=storage_context, service_context=service_context\n)\n\n# configure retriever\nretriever = VectorIndexRetriever(\n&nbsp;&nbsp;&nbsp;&nbsp;index=index,\n&nbsp;&nbsp;&nbsp;&nbsp;similarity_top_k=2,\n)\n\n# configure response synthesizer\nresponse_synthesizer = get_response_synthesizer(\n&nbsp;&nbsp;&nbsp;&nbsp;service_context=service_context,\n&nbsp;&nbsp;&nbsp;&nbsp;text_qa_template=qa_prompt,\n&nbsp;&nbsp;&nbsp;&nbsp;response_mode=\"compact\",\n)\n\n# assemble query engine\nquery_engine = RetrieverQueryEngine(\n&nbsp;&nbsp;&nbsp;&nbsp;retriever=retriever,\n&nbsp;&nbsp;&nbsp;&nbsp;response_synthesizer=response_synthesizer,\n)\n</code></pre><p>這個系統將使用 Jina Embeddings 為我們文本來源的段落建立索引，並將兩個最佳匹配放入每個提示的上下文中。例如，要改為三個最佳匹配，只需修改上面 <code>VectorIndexRetriever</code> 初始化中的 <code>similarity_top_k</code> 參數：</p><pre><code class=\"language-python\"># configure retriever\nretriever = VectorIndexRetriever(\n&nbsp;&nbsp;&nbsp;&nbsp;index=index,\n&nbsp;&nbsp;&nbsp;&nbsp;similarity_top_k=3,\n)</code></pre><p>現在系統已經可以使用了。</p><h3 id=\"query-a-document\"><strong>查詢文檔</strong></h3><p>讓我們試一個直接的查詢：</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat is the Biden Administration's policy with regard to AI?&nbsp;\n\"\"\")\nprint(response.response)</code></pre><p>結果（你的可能不完全相同）：</p><pre><code class=\"language-text\">The Biden Administration prioritizes responsible AI systems that&nbsp;\nare ethical, trustworthy, and safe, and serve the public good. \nThe Administration has committed to substantial funding for AI \nR&amp;D, and has established the National AI Initiative Office to \ncoordinate AI activities across the federal government.&nbsp;\n\nThe Administration's AI policy focuses on developing evaluative\ntechniques for AI, workforce development, public-private\npartnerships, and international collaboration in AI research.</code></pre><p>或者更具體一點：</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat protections does the AI Bill of Rights propose to offer?\n\"\"\")\n\nprint(response.response)</code></pre><pre><code class=\"language-text\">The AI Bill of Rights proposes five core protections: Safe and&nbsp;\nEffective Systems; Algorithmic Discrimination Protections; Data&nbsp;\nPrivacy; Notice and Explanation; and Human Alternatives,&nbsp;\nConsideration, and Fallback.</code></pre><p>甚至非常具體：</p><pre><code class=\"language-python\">response = query_engine.query(\"Who is Kei Koizumi?\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">Kei Koizumi is the Principal Deputy Director for Policy at the Office&nbsp;\nof Science and Technology Policy (OSTP).</code></pre><p>你也可以問一些富有想象力的問題：</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat rights will AI's receive under President Biden's proposed&nbsp;\nAI Bill of Rights?\n\"\"\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">The proposed AI Bill of Rights does not grant rights to AI systems, but&nbsp;\nrather outlines principles to ensure that AI technologies are&nbsp;\ndeveloped and used in a manner that respects human rights and values.&nbsp;\nThe principles include safety, transparency, fairness, disclosure,&nbsp;\ndata privacy, non-discrimination, and the ability for individuals to&nbsp;\nopt out of certain AI systems.</code></pre><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhy is President Biden's proposing an AI Bill of Rights?\nDoes AI really need rights?\n\"\"\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">President Biden's proposed AI Bill of Rights aims to ensure that AI&nbsp;\ntechnologies are developed and used ethically, legally, and with&nbsp;\nsocietal considerations in mind. The Bill of Rights is not granting&nbsp;\n\"rights\" to AI, but rather setting guidelines for the responsible&nbsp;\ndevelopment and deployment of AI systems to protect individuals and&nbsp;\ncommunities from potential negative impacts.</code></pre><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nHas Donald Trump weighed in on AI?\nWill he Make Humans Great Again?\n\"\"\")\nprint(response.response)\n</code></pre><pre><code class=\"language-text\">No information. The context information does not mention Donald&nbsp;\nTrump's views on AI.</code></pre><h2 id=\"jina-ai-and-qdrant\"><strong>Jina AI 和 Qdrant</strong></h2><p>Jina Embeddings 的 8k token 上下文窗口使其特別適合於檢索增強生成，因為它可以處理更大的文本塊。在其他 RAG 應用程式通常必須存儲單獨的句子或句子對的情況下，在本教程中，我們可以使用整個段落而不用擔心它們的大小。</p><p>這減少了需要存儲的文本項目數量以承載相同的信息，降低了計算成本，節省了記憶體，並使檢索更快。</p><p>Qdrant 的向量資料庫配置簡單、速度快且具有成本效益，如你所見，只需幾行 Python 代碼就可以將其整合到 RAG 系統中。</p><p>要了解更多關於 Qdrant 的 AI 就緒資料庫和雲端服務，你可以<a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>訪問他們的網站</u></a>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Qdrant - Vector Database</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://qdrant.tech/images/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Vector Database</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://qdrant.tech/images/previews/social-preview-P.png\" alt=\"\"></div></a></figure><h2 id=\"get-in-touch\"><strong>聯繫我們</strong></h2><p>Jina AI 致力於為各種規模和類型的企業提供可靠、實惠的 AI 技術。我們很樂意瞭解您的使用案例，並幫助將 AI 融入您的業務流程中。欲了解更多關於 Jina AI 的產品並與我們聯繫，請查看 <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>Jina AI 網站</u></a>或加入我們的 <a href=\"https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>Discord 社群</u></a>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - Best Embeddings and Perfect Prompts</div><div class=\"kg-bookmark-description\">Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-author\">Best Embeddings and Perfect Prompts</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Join the Jina AI Discord Server!</div><div class=\"kg-bookmark-description\">Check out the Jina AI community on Discord - hang out with 4493 other members and enjoy free voice and text chat.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://discord.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512\" alt=\"\"></div></a></figure>",
  "comment_id": "65ddadd039a5b70001810ea3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/02/Blog-images--26-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-02-27T10:39:28.000+01:00",
  "updated_at": "2024-03-06T15:41:18.000+01:00",
  "published_at": "2024-03-04T16:00:13.000+01:00",
  "custom_excerpt": "Create a RAG system with Jina Embeddings v2, Qdrant vector database, LlamaIndex, and Mistral LLM.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/build-a-rag-system-with-jina-embeddings-and-qdrant/",
  "excerpt": "使用 Jina Embeddings v2、Qdrant 向量資料庫、LlamaIndex 和 Mistral LLM 建立 RAG 系統。",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Promotional graphic with \"EMBEDDINGS 2\" and Drant logo separated by a red cross, symbolizing a partnership.",
  "feature_image_caption": null
}