{
  "slug": "jina-reranker-m0-multilingual-multimodal-document-reranker",
  "id": "67ea5eb45dcba60001c30f0a",
  "uuid": "b710acf7-f8e7-4588-bc54-30a1fbe42eca",
  "title": "jina-reranker-m0：多語言多模態文件重排序器",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-reranker-m0\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-reranker-m0 · Hugging Face</div><div class=\"kg-bookmark-description\">我們正在透過開源和開放科學來推進和民主化人工智慧。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-34.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-reranker-m0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>今天我們發布了 <code>jina-reranker-m0</code>，這是我們新的多語言多模態重排序模型，用於<strong>跨多種語言對視覺文件進行排序：</strong>它接受查詢以及一系列視覺豐富的文件圖像，包括含有文字、圖表、表格、資訊圖表的頁面，以及跨越多個領域和超過 29 種語言的各種版面配置。它會輸出一個根據與輸入查詢相關性排序的文件列表。與 <code>jina-reranker-v2-base-multilingual</code> 相比，<code>jina-reranker-m0</code> 還改進了多語言內容、長文件和程式碼搜尋任務的文字重排序效果。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/all-benchmarks--6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1714\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/all-benchmarks--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/all-benchmarks--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/04/all-benchmarks--6-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/04/all-benchmarks--6-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-reranker-m0</code> 在 ViDoRe、MBEIR 和 Winoground 視覺檢索基準測試上的表現展示了其在跨越多個領域和語言的各種多模態檢索任務中的能力。每個點代表不同類型/任務的視覺文件的性能分數。箱型圖說明了這些分數的分布情況，突出顯示的數字表示平均（均值）性能。完整的基準測試結果請參考本文附錄。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/model-perf-boxplot--13-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"2338\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/model-perf-boxplot--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/model-perf-boxplot--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/04/model-perf-boxplot--13-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/04/model-perf-boxplot--13-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">這個箱型圖顯示了 </span><code>jina-reranker-m0</code><span style=\"white-space: pre-wrap;\"> 在四個純文字重排序基準測試中的表現。每個基準測試可能包含多個數據集、語言或任務，由箱型圖內的個別點表示。箱型圖顯示了這些分數的分布情況，突出顯示的數字表示平均（均值）性能。雖然大多數基準測試使用 NDCG@10 作為性能指標，但 MKQA 使用 recall@10，因為 MKQA 的標註數據不支持 NDCG 計算（官方評估使用 recall，通過啟發式方法確定文件相關性）。完整的基準測試結果可在本文附錄中找到。</span></figcaption></figure><h2 id=\"new-architecture\">新架構</h2><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/2.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\"><code>jina-reranker-m0</code> 的架構建立在 Qwen2-VL-2B 的基礎上，包含 21 億參數。該模型通過評估文件的視覺和文字元素與查詢的關係，使用成對比較方式有效地對文件進行排序。</span></figcaption></figure><p>與 <code>jina-reranker-v2-base-multilingual</code> 不同，<code>jina-reranker-m0</code> 從傳統的交叉編碼器架構轉向只解碼器視覺語言模型。它利用了預訓練的 Qwen2-VL 的視覺編碼器和投影器，通過 LoRA 微調了其 LLM，並後訓練了一個 MLP 來生成衡量查詢-文件相關性的排序邏輯。這形成了一個針對排序任務優化的<strong>判別模型</strong>。</p>\n<!--kg-card-begin: html-->\n<table><thead>\n  <tr>\n    <th></th>\n    <th><code>jina-reranker-m0</code></th>\n    <th><code>jina-reranker-v2</code></th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td>架構</td>\n    <td>視覺語言模型</td>\n    <td>交叉編碼器</td>\n  </tr>\n  <tr>\n    <td>基礎模型</td>\n    <td>Qwen2-VL-2B</td>\n    <td>Jina-XLM-RoBERTa</td>\n  </tr>\n  <tr>\n    <td>參數量</td>\n    <td>2.4 B</td>\n    <td>278 M</td>\n  </tr>\n  <tr>\n    <td>最大上下文長度（查詢 + 文件）</td>\n    <td>10,240</td>\n    <td>8,192</td>\n  </tr>\n  <tr>\n    <td>最大圖像塊（動態解析度）</td>\n    <td>768 × 28 × 28</td>\n    <td>❌</td>\n  </tr>\n  <tr>\n    <td>多語言支援</td>\n    <td>✅</td>\n    <td>✅</td>\n  </tr>\n  <tr>\n    <td>支援的任務</td>\n    <td>Text2Text、Text2Image、Image2Text、Text2Mixed</td>\n    <td>Text2Text</td>\n  </tr>\n</tbody></table>\n<!--kg-card-end: html-->\n<p>這種新架構使 <code>jina-reranker-m0</code> 能夠處理高達 32K 的標記，無縫結合視覺和文字輸入。該模型支援從最小 56×56 像素到 4K 解析度的圖像。在處理圖像時，ViT 和投影器將相鄰的 2×2 標記壓縮成單個視覺標記供 LLM 輸入。特殊標記如 <code>&lt;|vision_start|&gt;</code> 和 <code>&lt;|vision_end|&gt;</code> 清晰地標記視覺標記邊界，使語言模型能夠正確處理視覺資訊並執行結合視覺和文字元素的複雜多模態推理。</p><p>這種架構還有效解決了困擾早期模型如 <code>jina-clip-v1</code> 和 <code>jina-clip-v2</code> 的<a href=\"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models\">模態差距問題</a>。此前，圖像會聚集在其他圖像附近，而文字會聚集在其他文字附近的表示空間中，造成斷裂。這意味著當你的候選文件同時包含圖像和文字時，使用文字查詢檢索圖像會有問題。有了 <code>jina-reranker-m0</code>，你現在可以不用擔心這個差距就能同時對圖像和文件進行排序，創造真正統一的多模態搜尋體驗。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/3.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">在多模態檢索系統中，「模態差距」指的是模型對文字到文字相似度與文字到圖像相似度的評分方式的差異。觀察左圖（</span><code>jina-clip-v2</code><span style=\"white-space: pre-wrap;\">），兩種分布之間有明顯的分離：文字到文字相似度分布（紅色）峰值在 0.35 左右。文字到圖像相似度（藍色）峰值在 0.65-0.7 左右。這種顯著的分離表明存在較大的模態差距 - 模型對文字到文字和文字到圖像對的評分在根本上處於不同的範圍。這使得直接比較跨模態的分數變得困難。在沒有模態差距的系統中（例如），我們期望這些分布在很大程度上重疊，這意味著模型完全基於相關性而不是模態類型在相似的範圍內對兩種類型的配對進行評分。</span></figcaption></figure><p>值得注意的是，我們的訓練限制在最多 10K 輸入標記，每張圖像最多 768 個標記（在 <code>&lt;|vision_start|&gt;</code> 和 <code>&lt;|vision_end|&gt;</code> 標記之間）。此外，我們沒有特別訓練模型用於 <code>image-to-image</code>、<code>image-to-multimodal</code> 或 <code>text-to-multimodal</code> 重排序任務。在這種情況下，「多模態」指的是單個文件在輸入中同時包含圖像和文字標記。查看查詢和文件中圖像和文字標記的所有可能組合，我們可以在下表中總結 <code>jina-reranker-m0</code> 支援的完整任務範圍。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading--96-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/04/Heading--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/04/Heading--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading--96-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-reranker-m0</span></code><span style=\"white-space: pre-wrap;\"> 支援各種查詢和文件輸入組合來進行重新排序。由於經過廣泛的訓練，它在文字對文字、文字對圖像、圖像對文字和文字對混合單模態任務中都能達到最先進的效能。該模型還能以零樣本方式處理其他輸入組合 - 架構可以容納這些 token 組合，儘管我們並未針對這些任務進行特定訓練。</span></figcaption></figure><p>在我們的測試中，我們發現一些證據表明該模型可以推廣到這些未經訓練的排序任務，但在這些領域的任何有效性都應被視為模型零樣本遷移能力或非預期訓練副作用的結果。我們尚未對模型在這些任務上的表現進行嚴格評估，並計劃在未來的研究中更徹底地探索這些能力。</p><h2 id=\"getting-started\">開始使用</h2><h3 id=\"via-api\">透過 API</h3><p>以下程式碼展示了如何計算查詢 <code>\"small language model data extraction\"</code> 與一系列圖像和文字文件之間的相關性分數。您可以傳入文字字串、base64 編碼的圖像或圖像 URL。新使用者可以獲得一個包含 100 萬個免費 token 的 Jina API 金鑰。雖然我們的 API 不支援使用圖像作為查詢，但當您通過 Hugging Face Transformers 函式庫訪問模型時，可以使用圖像作為查詢。</p><pre><code class=\"language-bash\">curl -X POST \\\n  https://api.jina.ai/v1/rerank \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer JINA_API_KEY\" \\\n  -d '{\n  \"model\": \"jina-reranker-m0\",\n  \"query\": \"small language model data extraction\",\n  \"documents\": [\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/handelsblatt-preview.png\"\n    },\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\"\n    },\n    {\n      \"image\": \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/wired-preview.png\"\n    },\n    {\n      \"text\": \"We present ReaderLM-v2, a compact 1.5 billion parameter language model designed for efficient web content extraction. Our model processes documents up to 512K tokens, transforming messy HTML into clean Markdown or JSON formats with high accuracy -- making it an ideal tool for grounding large language models. The models effectiveness results from two key innovations: (1) a three-stage data synthesis pipeline that generates high quality, diverse training data by iteratively drafting, refining, and critiquing web content extraction; and (2) a unified training framework combining continuous pre-training with multi-objective optimization. Intensive evaluation demonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger models by 15-20% on carefully curated benchmarks, particularly excelling at documents exceeding 100K tokens, while maintaining significantly lower computational requirements.\"\n    },\n    {\n      \"image\": \"https://jina.ai/blog-banner/using-deepseek-r1-reasoning-model-in-deepsearch.webp\"\n    },\n    {\n      \"text\": \"数据提取么？为什么不用正则啊，你用正则不就全解决了么？\"\n    },\n    {\n      \"text\": \"During the California Gold Rush, some merchants made more money selling supplies to miners than the miners made finding gold.\"\n    },\n    {\n      \"text\": \"Die wichtigsten Beiträge unserer Arbeit sind zweifach: Erstens führen wir eine neuartige dreistufige Datensynthese-Pipeline namens Draft-Refine-Critique ein, die durch iterative Verfeinerung hochwertige Trainingsdaten generiert; und zweitens schlagen wir eine umfassende Trainingsstrategie vor, die kontinuierliches Vortraining zur Längenerweiterung, überwachtes Feintuning mit spezialisierten Kontrollpunkten, direkte Präferenzoptimierung (DPO) und iteratives Self-Play-Tuning kombiniert. Um die weitere Forschung und Anwendung der strukturierten Inhaltsextraktion zu erleichtern, ist das Modell auf Hugging Face öffentlich verfügbar.\"\n    }\n  ],\n  \"return_documents\": false\n}'</code></pre><p>回應如下所示，其中第一個結果 <code>index=1</code> 對應於我們的 ReaderLM-v2 <a href=\"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\">論文截圖</a>。</p><pre><code class=\"language-json\">{\"model\":\"jina-reranker-m0\",\"usage\":{\"total_tokens\":2829},\"results\":[{\"index\":1,\"relevance_score\":0.9587112551898949},{\"index\":3,\"relevance_score\":0.9337408271911014},{\"index\":7,\"relevance_score\":0.8922925217195924},{\"index\":2,\"relevance_score\":0.8891905997562045},{\"index\":0,\"relevance_score\":0.8827516945848907},{\"index\":4,\"relevance_score\":0.8701035914834407},{\"index\":6,\"relevance_score\":0.8676828987527296},{\"index\":5,\"relevance_score\":0.8455347349164652}]}</code></pre><h3 id=\"via-csp-marketplaces\">透過 CSP 市集</h3><p><code>jina-reranker-m0</code> 很快就會在 AWS、Azure 和 GCP 上直接提供，價格將列於其中。</p><h3 id=\"via-huggingface\">透過 HuggingFace</h3><p>您也可以從我們的 Hugging Face 頁面在本地使用該模型。我們準備了一個 Google Colab 筆記本來展示其工作原理。與我們的網頁 API 相比，本地使用模型提供更大的靈活性，例如能夠使用圖像作為查詢並處理多模態文件。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1gNTJHbdYSdgOEAea7kB6XaW56Zala0vk?usp=sharing\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-33.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-8.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"evaluation\">評估</h2><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1KrCD7l0lhzMkyg3z-gEDmymxe4Eun9Z-C0kU3_cxw7Q/edit?usp=sharing\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">[public]-jina-reranker-m0-evaluation-results</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4-1.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyKUKD8mc67_5eRgiiBYvZFKdug_jMKmBHiEesOvQ3bVWmAAKMu-afa1748S_WJXuc4UdNjKMqEsIQnlnf2X5OQsA0dmDJirjwvEkrgBMhQlJwXS8VM-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">完整評估結果可在此 Google 試算表中查看。</span></p></figcaption></figure><h3 id=\"beir-text2text-english-only\">BEIR（文字對文字，僅英文）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2104.08663\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models</div><div class=\"kg-bookmark-description\">Existing neural information retrieval (IR) models have often been studied in homogeneous and narrow settings, which has considerably limited insights into their out-of-distribution (OOD) generalization capabilities. To address this, and to facilitate researchers to broadly evaluate the effectiveness of their models, we introduce Benchmarking-IR (BEIR), a robust and heterogeneous evaluation benchmark for information retrieval. We leverage a careful selection of 18 publicly available datasets from diverse text retrieval tasks and domains and evaluate 10 state-of-the-art retrieval systems including lexical, sparse, dense, late-interaction and re-ranking architectures on the BEIR benchmark. Our results show BM25 is a robust baseline and re-ranking and late-interaction-based models on average achieve the best zero-shot performances, however, at high computational costs. In contrast, dense and sparse-retrieval models are computationally more efficient but often underperform other approaches, highlighting the considerable room for improvement in their generalization capabilities. We hope this framework allows us to better evaluate and understand existing retrieval systems, and contributes to accelerating progress towards better robust and generalizable systems in the future. BEIR is publicly available at https://github.com/UKPLab/beir.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-13.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Nandan Thakur</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-9.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>BEIR 是一個異質性的資訊檢索基準測試，旨在評估 IR 模型的多樣性和穩健性。它包含來自各個領域的多元數據集，並專注於零樣本評估。使用標準化的評估指標，如 NDCG、Recall@K 和 MRR。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">TREC-COVID</th>\n<th style=\"text-align: right\">NFCorpus</th>\n<th style=\"text-align: right\">NQ</th>\n<th style=\"text-align: right\">HotpotQA</th>\n<th style=\"text-align: right\">FiQA</th>\n<th style=\"text-align: right\">ArguAna</th>\n<th style=\"text-align: right\">Touche-2020</th>\n<th style=\"text-align: right\">DBPedia</th>\n<th style=\"text-align: right\">SCIDOCS</th>\n<th style=\"text-align: right\">FEVER</th>\n<th style=\"text-align: right\">Climate-FEVER</th>\n<th style=\"text-align: right\">SciFact</th>\n<th style=\"text-align: right\">Quora</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\"><strong>58.95</strong></td>\n<td style=\"text-align: right\"><strong>84.17</strong></td>\n<td style=\"text-align: right\"><strong>41.03</strong></td>\n<td style=\"text-align: right\"><strong>72.25</strong></td>\n<td style=\"text-align: right\">76.99</td>\n<td style=\"text-align: right\"><strong>51.62</strong></td>\n<td style=\"text-align: right\">40.69</td>\n<td style=\"text-align: right\">31.79</td>\n<td style=\"text-align: right\"><strong>49.34</strong></td>\n<td style=\"text-align: right\"><strong>22.91</strong></td>\n<td style=\"text-align: right\">91.14</td>\n<td style=\"text-align: right\">36.42</td>\n<td style=\"text-align: right\"><strong>79.94</strong></td>\n<td style=\"text-align: right\">88.01</td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (1024 tokens)</td>\n<td style=\"text-align: right\">55.81</td>\n<td style=\"text-align: right\">77.81</td>\n<td style=\"text-align: right\">36.65</td>\n<td style=\"text-align: right\">64.31</td>\n<td style=\"text-align: right\">64.63</td>\n<td style=\"text-align: right\">47.47</td>\n<td style=\"text-align: right\"><strong>54.31</strong></td>\n<td style=\"text-align: right\">26.55</td>\n<td style=\"text-align: right\">41.07</td>\n<td style=\"text-align: right\">19.91</td>\n<td style=\"text-align: right\">89.00</td>\n<td style=\"text-align: right\"><strong>42.33</strong></td>\n<td style=\"text-align: right\">72.4</td>\n<td style=\"text-align: right\"><strong>89.06</strong></td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\">56.51</td>\n<td style=\"text-align: right\">82.19</td>\n<td style=\"text-align: right\">34.33</td>\n<td style=\"text-align: right\">69.52</td>\n<td style=\"text-align: right\"><strong>77.89</strong></td>\n<td style=\"text-align: right\">45.45</td>\n<td style=\"text-align: right\">36.21</td>\n<td style=\"text-align: right\"><strong>33.12</strong></td>\n<td style=\"text-align: right\">46.72</td>\n<td style=\"text-align: right\">17.79</td>\n<td style=\"text-align: right\">91.03</td>\n<td style=\"text-align: right\">38.69</td>\n<td style=\"text-align: right\">72.64</td>\n<td style=\"text-align: right\">89.10</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">57.06</td>\n<td style=\"text-align: right\">80.53</td>\n<td style=\"text-align: right\">37.17</td>\n<td style=\"text-align: right\">67.39</td>\n<td style=\"text-align: right\">76.17</td>\n<td style=\"text-align: right\">46.48</td>\n<td style=\"text-align: right\">39.28</td>\n<td style=\"text-align: right\">32.35</td>\n<td style=\"text-align: right\">47.81</td>\n<td style=\"text-align: right\">20.03</td>\n<td style=\"text-align: right\"><strong>93.02</strong></td>\n<td style=\"text-align: right\">37.17</td>\n<td style=\"text-align: right\">76.50</td>\n<td style=\"text-align: right\">87.83</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"miracl-text2text-multilingual-18-languages\">MIRACL（Text2Text，多語言，18 種語言）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2210.09984\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Making a MIRACL: Multilingual Information Retrieval Across a Continuum of Languages</div><div class=\"kg-bookmark-description\">MIRACL（Multilingual Information Retrieval Across a Continuum of Languages）是我們為 WSDM 2023 Cup 挑戰賽建立的多語言數據集，專注於 18 種不同語言的臨時檢索，這些語言的母語使用者總計超過 30 億人。這些語言具有多樣的類型學特徵，來自多個語系，並且具有不同程度的可用資源——包括研究人員通常所說的高資源和低資源語言。我們的數據集旨在支持創建和評估單語檢索模型，其中查詢和語料庫使用相同的語言。總共，我們為這 18 種語言的維基百科收集了超過 77,000 個查詢的 700,000 多個高質量相關性判斷，所有評估都由我們團隊聘請的母語者執行。我們的目標是促進跨語言連續體的檢索研究，從而提高全球各地人群的資訊獲取能力，特別是那些傳統上未得到充分服務的人群。這篇概述論文描述了我們與社群共享的數據集和基準。MIRACL 網站已上線，網址為 http://miracl.ai/。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-12.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Xinyu Zhang</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-8.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MIRACL 是一個涵蓋 18 種語言的大規模多語言資訊檢索資料集。它覆蓋超過 30 億原生語言使用者，並具有詳盡的人工標註。主要專注於單語言檢索任務。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">ar</th>\n<th style=\"text-align: right\">bn</th>\n<th style=\"text-align: right\">en</th>\n<th style=\"text-align: right\">es</th>\n<th style=\"text-align: right\">fa</th>\n<th style=\"text-align: right\">fi</th>\n<th style=\"text-align: right\">fr</th>\n<th style=\"text-align: right\">hi</th>\n<th style=\"text-align: right\">id</th>\n<th style=\"text-align: right\">ja</th>\n<th style=\"text-align: right\">ko</th>\n<th style=\"text-align: right\">ru</th>\n<th style=\"text-align: right\">sw</th>\n<th style=\"text-align: right\">te</th>\n<th style=\"text-align: right\">th</th>\n<th style=\"text-align: right\">zh</th>\n<th style=\"text-align: right\">de</th>\n<th style=\"text-align: right\">yo</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\">66.75</td>\n<td style=\"text-align: right\">79.78</td>\n<td style=\"text-align: right\">78.01</td>\n<td style=\"text-align: right\">59.21</td>\n<td style=\"text-align: right\">53.56</td>\n<td style=\"text-align: right\">58.80</td>\n<td style=\"text-align: right\">78.00</td>\n<td style=\"text-align: right\">56.66</td>\n<td style=\"text-align: right\">62.83</td>\n<td style=\"text-align: right\">54.92</td>\n<td style=\"text-align: right\">66.51</td>\n<td style=\"text-align: right\">72.86</td>\n<td style=\"text-align: right\">67.26</td>\n<td style=\"text-align: right\">59.04</td>\n<td style=\"text-align: right\">70.19</td>\n<td style=\"text-align: right\">80.37</td>\n<td style=\"text-align: right\">64.51</td>\n<td style=\"text-align: right\">58.50</td>\n<td style=\"text-align: right\">80.44</td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align: right\">58.90</td>\n<td style=\"text-align: right\">71.53</td>\n<td style=\"text-align: right\">69.86</td>\n<td style=\"text-align: right\">48.37</td>\n<td style=\"text-align: right\">46.91</td>\n<td style=\"text-align: right\">54.13</td>\n<td style=\"text-align: right\">71.15</td>\n<td style=\"text-align: right\">50.90</td>\n<td style=\"text-align: right\">55.05</td>\n<td style=\"text-align: right\">47.83</td>\n<td style=\"text-align: right\">56.46</td>\n<td style=\"text-align: right\">64.76</td>\n<td style=\"text-align: right\">55.63</td>\n<td style=\"text-align: right\">54.07</td>\n<td style=\"text-align: right\">70.48</td>\n<td style=\"text-align: right\">73.56</td>\n<td style=\"text-align: right\">55.29</td>\n<td style=\"text-align: right\">49.18</td>\n<td style=\"text-align: right\">65.01</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\"><strong>69.32</strong></td>\n<td style=\"text-align: right\"><strong>80.51</strong></td>\n<td style=\"text-align: right\"><strong>81.85</strong></td>\n<td style=\"text-align: right\"><strong>57.67</strong></td>\n<td style=\"text-align: right\"><strong>57.64</strong></td>\n<td style=\"text-align: right\"><strong>61.92</strong></td>\n<td style=\"text-align: right\"><strong>80.38</strong></td>\n<td style=\"text-align: right\"><strong>59.60</strong></td>\n<td style=\"text-align: right\"><strong>67.66</strong></td>\n<td style=\"text-align: right\"><strong>58.86</strong></td>\n<td style=\"text-align: right\"><strong>67.37</strong></td>\n<td style=\"text-align: right\"><strong>75.14</strong></td>\n<td style=\"text-align: right\"><strong>67.61</strong></td>\n<td style=\"text-align: right\"><strong>68.92</strong></td>\n<td style=\"text-align: right\"><strong>76.69</strong></td>\n<td style=\"text-align: right\"><strong>82.29</strong></td>\n<td style=\"text-align: right\"><strong>64.46</strong></td>\n<td style=\"text-align: right\"><strong>58.32</strong></td>\n<td style=\"text-align: right\"><strong>80.85</strong></td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">63.65</td>\n<td style=\"text-align: right\">72.50</td>\n<td style=\"text-align: right\">79.42</td>\n<td style=\"text-align: right\">46.66</td>\n<td style=\"text-align: right\">51.54</td>\n<td style=\"text-align: right\">57.81</td>\n<td style=\"text-align: right\">73.05</td>\n<td style=\"text-align: right\">50.90</td>\n<td style=\"text-align: right\">60.94</td>\n<td style=\"text-align: right\">56.66</td>\n<td style=\"text-align: right\">59.15</td>\n<td style=\"text-align: right\">72.60</td>\n<td style=\"text-align: right\">53.43</td>\n<td style=\"text-align: right\">66.47</td>\n<td style=\"text-align: right\">74.62</td>\n<td style=\"text-align: right\">77.75</td>\n<td style=\"text-align: right\">62.49</td>\n<td style=\"text-align: right\">53.06</td>\n<td style=\"text-align: right\">76.69</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"mldr-text2text-multilingual-long-documents-13-languages\">MLDR（Text2Text，多語言長文件，13 種語言）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2402.03216\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BGE M3-Embedding：通過自知識蒸餾實現多語言、多功能、多粒度文本嵌入</div><div class=\"kg-bookmark-description\">本論文介紹了一個新的嵌入模型，稱為 M3-Embedding，它以多語言性、多功能性和多粒度性為特色。該模型支援超過 100 種工作語言，在多語言和跨語言檢索任務上取得了新的最佳性能。它可以同時執行嵌入模型的三種常見檢索功能：密集檢索、多向量檢索和稀疏檢索，為實際 IR 應用提供了統一的模型基礎。它能夠處理不同粒度的輸入，從短句到最多 8192 個 tokens 的長文件。M3-Embedding 的有效訓練包含以下技術貢獻。我們提出了一種新穎的自知識蒸餾方法，其中來自不同檢索功能的相關性分數可以整合為教師信號以提高訓練質量。我們還優化了批次處理策略，實現了大批次規模和高訓練吞吐量，以確保嵌入的區分性。據我們所知，M3-Embedding 是第一個實現如此強大通用性的嵌入模型。模型和程式碼將在 https://github.com/FlagOpen/FlagEmbedding 公開。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-18.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Jianlv Chen</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-14.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MLDR 是一個專門為長文檔檢索設計的多語言數據集，涵蓋 13 種語言。它使用 GPT-3.5 為文檔生成問題。該數據集建立在 Wikipedia、Wudao 和 mC4 的基礎之上。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align: right\">AVG (NDCG@10)</th>\n<th style=\"text-align: right\">ar</th>\n<th style=\"text-align: right\">de</th>\n<th style=\"text-align: right\">en</th>\n<th style=\"text-align: right\">es</th>\n<th style=\"text-align: right\">fr</th>\n<th style=\"text-align: right\">hi</th>\n<th style=\"text-align: right\">it</th>\n<th style=\"text-align: right\">ja</th>\n<th style=\"text-align: right\">ko</th>\n<th style=\"text-align: right\">pt</th>\n<th style=\"text-align: right\">ru</th>\n<th style=\"text-align: right\">th</th>\n<th style=\"text-align: right\">zh</th>\n</tr>\n</thead>\n<tbody>\n  <tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align: right\"><strong>59.83</strong></td>\n<td style=\"text-align: right\"><strong>55.86</strong></td>\n<td style=\"text-align: right\"><strong>51.25</strong></td>\n<td style=\"text-align: right\"><strong>54.67</strong></td>\n<td style=\"text-align: right\"><strong>87.63</strong></td>\n<td style=\"text-align: right\"><strong>82.59</strong></td>\n<td style=\"text-align: right\"><strong>32.76</strong></td>\n<td style=\"text-align: right\"><strong>73.25</strong></td>\n<td style=\"text-align: right\"><strong>58.93</strong></td>\n<td style=\"text-align: right\"><strong>55.73</strong></td>\n<td style=\"text-align: right\"><strong>86.08</strong></td>\n<td style=\"text-align: right\"><strong>66.73</strong></td>\n<td style=\"text-align: right\"><strong>39.17</strong></td>\n<td style=\"text-align: right\"><strong>33.14</strong></td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align: right\">39.71</td>\n<td style=\"text-align: right\">28.44</td>\n<td style=\"text-align: right\">31.57</td>\n<td style=\"text-align: right\">29.07</td>\n<td style=\"text-align: right\">62.08</td>\n<td style=\"text-align: right\">59.79</td>\n<td style=\"text-align: right\">25.47</td>\n<td style=\"text-align: right\">53.72</td>\n<td style=\"text-align: right\">38.36</td>\n<td style=\"text-align: right\">32.37</td>\n<td style=\"text-align: right\">63.26</td>\n<td style=\"text-align: right\">49.65</td>\n<td style=\"text-align: right\">25.15</td>\n<td style=\"text-align: right\">17.26</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align: right\">53.53</td>\n<td style=\"text-align: right\">49.19</td>\n<td style=\"text-align: right\">45.39</td>\n<td style=\"text-align: right\">43.92</td>\n<td style=\"text-align: right\">74.57</td>\n<td style=\"text-align: right\">68.67</td>\n<td style=\"text-align: right\">44.75</td>\n<td style=\"text-align: right\">62.79</td>\n<td style=\"text-align: right\">49.27</td>\n<td style=\"text-align: right\">48.24</td>\n<td style=\"text-align: right\">76.45</td>\n<td style=\"text-align: right\">62.84</td>\n<td style=\"text-align: right\">38.82</td>\n<td style=\"text-align: right\">31.02</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align: right\">59.50</td>\n<td style=\"text-align: right\">51.96</td>\n<td style=\"text-align: right\">50.13</td>\n<td style=\"text-align: right\">46.85</td>\n<td style=\"text-align: right\">86.34</td>\n<td style=\"text-align: right\">82.25</td>\n<td style=\"text-align: right\">49.50</td>\n<td style=\"text-align: right\">69.00</td>\n<td style=\"text-align: right\">59.07</td>\n<td style=\"text-align: right\">52.19</td>\n<td style=\"text-align: right\">85.26</td>\n<td style=\"text-align: right\">68.06</td>\n<td style=\"text-align: right\">38.73</td>\n<td style=\"text-align: right\">34.15</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"mkqa-text2text-multilingual-question-answering-24-languages-3-variants-for-chinese\">MKQA（Text2Text，多語言問答，24 種語言，中文有 3 種變體）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2007.15207\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain Question Answering</div><div class=\"kg-bookmark-description\">Progress in cross-lingual modeling depends on challenging, realistic, and diverse evaluation sets. We introduce Multilingual Knowledge Questions and Answers (MKQA), an open-domain question answering evaluation set comprising 10k question-answer pairs aligned across 26 typologically diverse languages (260k question-answer pairs in total). Answers are based on a heavily curated, language-independent data representation, making results comparable across languages and independent of language-specific passages. With 26 languages, this dataset supplies the widest range of languages to-date for evaluating question answering. We benchmark a variety of state-of-the-art methods and baselines for generative and extractive question answering, trained on Natural Questions, in zero shot and translation settings. Results indicate this dataset is challenging even in English, but especially in low-resource languages</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Shayne Longpre</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-7.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>MKQA 是一個開放領域問答評估集，包含 10k 個問答配對，橫跨 26 種不同的類型語言。這些問答配對是從 Google Natural Questions 中取樣而來。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th style=\"text-align:right\">AVG (recall@10)</th>\n<th style=\"text-align:right\">ar</th>\n<th style=\"text-align:right\">da</th>\n<th style=\"text-align:right\">de</th>\n<th style=\"text-align:right\">es</th>\n<th style=\"text-align:right\">en</th>\n<th style=\"text-align:right\">fi</th>\n<th style=\"text-align:right\">fr</th>\n<th style=\"text-align:right\">he</th>\n<th style=\"text-align:right\">hu</th>\n<th style=\"text-align:right\">it</th>\n<th style=\"text-align:right\">ja</th>\n<th style=\"text-align:right\">km</th>\n<th style=\"text-align:right\">ko</th>\n<th style=\"text-align:right\">ms</th>\n<th style=\"text-align:right\">nl</th>\n<th style=\"text-align:right\">no</th>\n<th style=\"text-align:right\">pl</th>\n<th style=\"text-align:right\">pt</th>\n<th style=\"text-align:right\">ru</th>\n<th style=\"text-align:right\">sv</th>\n<th style=\"text-align:right\">th</th>\n<th style=\"text-align:right\">tr</th>\n<th style=\"text-align:right\">vi</th>\n<th style=\"text-align:right\">zh_cn</th>\n<th style=\"text-align:right\">zh_hk</th>\n<th style=\"text-align:right\">zh_tw</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jina-reranker-m0</td>\n<td style=\"text-align:right\"><strong>68.19</strong></td>\n<td style=\"text-align:right\"><strong>63.88</strong></td>\n<td style=\"text-align:right\"><strong>70.57</strong></td>\n<td style=\"text-align:right\"><strong>70.52</strong></td>\n<td style=\"text-align:right\"><strong>71.26</strong></td>\n<td style=\"text-align:right\"><strong>73.47</strong></td>\n<td style=\"text-align:right\">64.10</td>\n<td style=\"text-align:right\"><strong>71.11</strong></td>\n<td style=\"text-align:right\">63.68</td>\n<td style=\"text-align:right\">63.23</td>\n<td style=\"text-align:right\"><strong>70.30</strong></td>\n<td style=\"text-align:right\"><strong>69.13</strong></td>\n<td style=\"text-align:right\">50.43</td>\n<td style=\"text-align:right\"><strong>64.30</strong></td>\n<td style=\"text-align:right\"><strong>70.78</strong></td>\n<td style=\"text-align:right\"><strong>71.73</strong></td>\n<td style=\"text-align:right\"><strong>70.25</strong></td>\n<td style=\"text-align:right\"><strong>69.72</strong></td>\n<td style=\"text-align:right\"><strong>70.57</strong></td>\n<td style=\"text-align:right\"><strong>70.78</strong></td>\n<td style=\"text-align:right\"><strong>70.69</strong></td>\n<td style=\"text-align:right\"><strong>69.80</strong></td>\n<td style=\"text-align:right\">67.90</td>\n<td style=\"text-align:right\"><strong>69.68</strong></td>\n<td style=\"text-align:right\"><strong>69.12</strong></td>\n<td style=\"text-align:right\"><strong>68.23</strong></td>\n<td style=\"text-align:right\"><strong>67.79</strong></td>\n</tr>\n<tr>\n<td>jina-embeddings-v3 (8192 tokens)</td>\n<td style=\"text-align:right\">65.63</td>\n<td style=\"text-align:right\">59.00</td>\n<td style=\"text-align:right\">69.12</td>\n<td style=\"text-align:right\">68.27</td>\n<td style=\"text-align:right\">68.15</td>\n<td style=\"text-align:right\">71.14</td>\n<td style=\"text-align:right\">65.66</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">59.51</td>\n<td style=\"text-align:right\">63.23</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">64.36</td>\n<td style=\"text-align:right\">56.13</td>\n<td style=\"text-align:right\">58.98</td>\n<td style=\"text-align:right\">68.30</td>\n<td style=\"text-align:right\">69.53</td>\n<td style=\"text-align:right\">68.65</td>\n<td style=\"text-align:right\">67.26</td>\n<td style=\"text-align:right\">67.93</td>\n<td style=\"text-align:right\">67.06</td>\n<td style=\"text-align:right\">68.68</td>\n<td style=\"text-align:right\">66.32</td>\n<td style=\"text-align:right\">66.97</td>\n<td style=\"text-align:right\">66.87</td>\n<td style=\"text-align:right\">63.38</td>\n<td style=\"text-align:right\">63.59</td>\n<td style=\"text-align:right\">61.55</td>\n</tr>\n<tr>\n<td>bge-reranker-v2-m3</td>\n<td style=\"text-align:right\">67.88</td>\n<td style=\"text-align:right\">63.09</td>\n<td style=\"text-align:right\">70.15</td>\n<td style=\"text-align:right\">68.91</td>\n<td style=\"text-align:right\">68.92</td>\n<td style=\"text-align:right\">73.00</td>\n<td style=\"text-align:right\"><strong>68.71</strong></td>\n<td style=\"text-align:right\">68.71</td>\n<td style=\"text-align:right\"><strong>70.27</strong></td>\n<td style=\"text-align:right\">64.00</td>\n<td style=\"text-align:right\">68.15</td>\n<td style=\"text-align:right\">68.47</td>\n<td style=\"text-align:right\"><strong>60.43</strong></td>\n<td style=\"text-align:right\">63.95</td>\n<td style=\"text-align:right\">68.80</td>\n<td style=\"text-align:right\">70.77</td>\n<td style=\"text-align:right\">69.10</td>\n<td style=\"text-align:right\">67.44</td>\n<td style=\"text-align:right\">67.40</td>\n<td style=\"text-align:right\">69.77</td>\n<td style=\"text-align:right\">70.03</td>\n<td style=\"text-align:right\">69.68</td>\n<td style=\"text-align:right\">66.04</td>\n<td style=\"text-align:right\">68.29</td>\n<td style=\"text-align:right\">67.84</td>\n<td style=\"text-align:right\">66.70</td>\n<td style=\"text-align:right\">66.34</td>\n</tr>\n<tr>\n<td>jina-reranker-v2-multilingual</td>\n<td style=\"text-align:right\">67.90</td>\n<td style=\"text-align:right\">63.88</td>\n<td style=\"text-align:right\">70.31</td>\n<td style=\"text-align:right\">70.09</td>\n<td style=\"text-align:right\">70.51</td>\n<td style=\"text-align:right\">73.09</td>\n<td style=\"text-align:right\">67.50</td>\n<td style=\"text-align:right\">70.38</td>\n<td style=\"text-align:right\">63.00</td>\n<td style=\"text-align:right\"><strong>64.59</strong></td>\n<td style=\"text-align:right\">69.90</td>\n<td style=\"text-align:right\">67.34</td>\n<td style=\"text-align:right\">57.79</td>\n<td style=\"text-align:right\">62.14</td>\n<td style=\"text-align:right\">70.36</td>\n<td style=\"text-align:right\">71.58</td>\n<td style=\"text-align:right\">69.51</td>\n<td style=\"text-align:right\">68.61</td>\n<td style=\"text-align:right\">70.13</td>\n<td style=\"text-align:right\">70.07</td>\n<td style=\"text-align:right\">70.15</td>\n<td style=\"text-align:right\">68.80</td>\n<td style=\"text-align:right\"><strong>68.02</strong></td>\n<td style=\"text-align:right\">69.39</td>\n<td style=\"text-align:right\">67.23</td>\n<td style=\"text-align:right\">65.77</td>\n<td style=\"text-align:right\">65.37</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"coir-text2text-code-information-retrieval\">CoIR（文本對文本，程式碼資訊檢索）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2407.02883\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">CoIR：程式碼資訊檢索模型的綜合基準</div><div class=\"kg-bookmark-description\">儘管資訊檢索（IR）在各種自然語言處理任務中取得了重大成功，但大多數 IR 系統主要處理自然語言的查詢和語料庫，忽略了程式碼檢索領域。程式碼檢索雖然至關重要，但仍未得到充分研究，現有的方法和基準無法充分代表各個領域和任務中程式碼的多樣性。為解決這個問題，我們提出了 COIR（程式碼資訊檢索基準），這是一個專門設計用於評估程式碼檢索能力的健全而全面的基準。COIR 包含十個精心策劃的程式碼數據集，涵蓋了七個不同領域的八種獨特檢索任務。我們首先討論 COIR 的構建及其多樣化的數據集組成。此外，我們使用 COIR 評估了九種廣泛使用的檢索模型，發現即使是最先進的系統在執行程式碼檢索任務時也存在顯著困難。為了便於在現有研究工作流程中輕鬆採用和整合，COIR 已開發為一個用戶友好的 Python 框架，可通過 pip 輕鬆安裝。它與其他流行的基準（如 MTEB 和 BEIR）共享相同的數據架構，使跨基準評估更加順暢。通過 COIR，我們旨在激發程式碼檢索領域的研究，提供一個多功能的基準工具，鼓勵進一步開發和探索程式碼檢索系統 https://github.com/CoIR-team/coir。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-14.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Xiangyang Li</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-10.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>CoIR 是一個全面的基準測試，旨在評估模型在程式碼檢索方面的能力。它包含 10 個精選的程式碼數據集，涵蓋了 7 個不同領域的 8 個檢索任務。該基準測試提供了一個 Python 框架。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th rowspan=\"3\">Model Name</th>\n      <th rowspan=\"3\">Avg (NDCG@10)</th>\n      <th colspan=\"3\">Text-to-Code</th>\n      <th colspan=\"7\">Code-to-Text</th>\n      <th colspan=\"9\">Code-to-Code</th>\n      <th colspan=\"3\">Hybrid Code</th>\n    </tr>\n    <tr>\n      <th rowspan=\"2\">Apps</th>\n      <th rowspan=\"2\">CosQA</th>\n      <th rowspan=\"2\">SQL</th>\n      <th colspan=\"7\">CSN</th>\n      <th colspan=\"7\">CSN-CCR</th>\n      <th colspan=\"2\">CodeTransOcean</th>\n      <th rowspan=\"2\">StackOver<br>Flow</th>\n      <th colspan=\"2\">CodeFeedBack</th>\n    </tr>\n    <tr>\n      <th>AVG</th>\n      <th>python</th>\n      <th>javascript</th>\n      <th>go</th>\n      <th>ruby</th>\n      <th>java</th>\n      <th>php</th>\n      <th>AVG</th>\n      <th>python</th>\n      <th>javascript</th>\n      <th>go</th>\n      <th>ruby</th>\n      <th>java</th>\n      <th>php</th>\n      <th>-Contest</th>\n      <th>-DL</th>\n      <th>-MT</th>\n      <th>-ST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>63.55</strong></td>\n      <td style=\"text-align: right\"><strong>26.21</strong></td>\n      <td style=\"text-align: right\">37.75</td>\n      <td style=\"text-align: right\"><strong>57.92</strong></td>\n      <td style=\"text-align: right\">80.76</td>\n      <td style=\"text-align: right\"><strong>98.37</strong></td>\n      <td style=\"text-align: right\">71.16</td>\n      <td style=\"text-align: right\">86.14</td>\n      <td style=\"text-align: right\">72.74</td>\n      <td style=\"text-align: right\">79.02</td>\n      <td style=\"text-align: right\">77.14</td>\n      <td style=\"text-align: right\"><strong>74.57</strong></td>\n      <td style=\"text-align: right\"><strong>81.66</strong></td>\n      <td style=\"text-align: right\"><strong>77.92</strong></td>\n      <td style=\"text-align: right\"><strong>68.71</strong></td>\n      <td style=\"text-align: right\"><strong>75.44</strong></td>\n      <td style=\"text-align: right\"><strong>77.54</strong></td>\n      <td style=\"text-align: right\"><strong>66.13</strong></td>\n      <td style=\"text-align: right\"><strong>79.79</strong></td>\n      <td style=\"text-align: right\"><strong>31.89</strong></td>\n      <td style=\"text-align: right\">90.41</td>\n      <td style=\"text-align: right\"><strong>72.25</strong></td>\n      <td style=\"text-align: right\"><strong>83.95</strong></td>\n    </tr>\n    <tr>\n      <td>jina-embeddings-v2-base-code<br>(top 100)</td>\n      <td style=\"text-align: right\">56.90</td>\n      <td style=\"text-align: right\">16.34</td>\n      <td style=\"text-align: right\"><strong>41.72</strong></td>\n      <td style=\"text-align: right\">49.79</td>\n      <td style=\"text-align: right\"><strong>83.95</strong></td>\n      <td style=\"text-align: right\">94.71</td>\n      <td style=\"text-align: right\"><strong>76.35</strong></td>\n      <td style=\"text-align: right\"><strong>87.39</strong></td>\n      <td style=\"text-align: right\"><strong>78.23</strong></td>\n      <td style=\"text-align: right\"><strong>82.69</strong></td>\n      <td style=\"text-align: right\"><strong>84.35</strong></td>\n      <td style=\"text-align: right\">59.65</td>\n      <td style=\"text-align: right\">68.23</td>\n      <td style=\"text-align: right\">62.31</td>\n      <td style=\"text-align: right\">49.15</td>\n      <td style=\"text-align: right\">65.40</td>\n      <td style=\"text-align: right\">63.89</td>\n      <td style=\"text-align: right\">48.92</td>\n      <td style=\"text-align: right\">79.20</td>\n      <td style=\"text-align: right\">30.35</td>\n      <td style=\"text-align: right\">89.42</td>\n      <td style=\"text-align: right\">49.62</td>\n      <td style=\"text-align: right\">68.93</td>\n    </tr>\n    <tr>\n      <td>bge-reranker-v2-m3</td>\n      <td style=\"text-align: right\">35.97</td>\n      <td style=\"text-align: right\">8.33</td>\n      <td style=\"text-align: right\">30.06</td>\n      <td style=\"text-align: right\">50.63</td>\n      <td style=\"text-align: right\">49.26</td>\n      <td style=\"text-align: right\">67.62</td>\n      <td style=\"text-align: right\">39.55</td>\n      <td style=\"text-align: right\">58.11</td>\n      <td style=\"text-align: right\">41.37</td>\n      <td style=\"text-align: right\">44.77</td>\n      <td style=\"text-align: right\">44.13</td>\n      <td style=\"text-align: right\">40.81</td>\n      <td style=\"text-align: right\">42.57</td>\n      <td style=\"text-align: right\">42.75</td>\n      <td style=\"text-align: right\">38.04</td>\n      <td style=\"text-align: right\">38.04</td>\n      <td style=\"text-align: right\">41.73</td>\n      <td style=\"text-align: right\">41.73</td>\n      <td style=\"text-align: right\">34.93</td>\n      <td style=\"text-align: right\">5.09</td>\n      <td style=\"text-align: right\">60.12</td>\n      <td style=\"text-align: right\">16.44</td>\n      <td style=\"text-align: right\">64.05</td>\n    </tr>\n    <tr>\n      <td>jina-reranker-v2-multilingual</td>\n      <td style=\"text-align: right\">56.14</td>\n      <td style=\"text-align: right\">21.90</td>\n      <td style=\"text-align: right\">37.26</td>\n      <td style=\"text-align: right\">53.56</td>\n      <td style=\"text-align: right\">78.88</td>\n      <td style=\"text-align: right\">97.83</td>\n      <td style=\"text-align: right\">67.43</td>\n      <td style=\"text-align: right\">84.64</td>\n      <td style=\"text-align: right\">68.93</td>\n      <td style=\"text-align: right\">75.73</td>\n      <td style=\"text-align: right\">78.71</td>\n      <td style=\"text-align: right\">63.59</td>\n      <td style=\"text-align: right\">72.62</td>\n      <td style=\"text-align: right\">67.80</td>\n      <td style=\"text-align: right\">55.07</td>\n      <td style=\"text-align: right\">67.25</td>\n      <td style=\"text-align: right\">64.25</td>\n      <td style=\"text-align: right\">54.54</td>\n      <td style=\"text-align: right\">73.67</td>\n      <td style=\"text-align: right\">25.74</td>\n      <td style=\"text-align: right\"><strong>91.24</strong></td>\n      <td style=\"text-align: right\">42.03</td>\n      <td style=\"text-align: right\">73.59</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"vidore-text2image-visual-document-retrieval-benchmark\">ViDoRe（文本轉圖像、視覺文件檢索基準測試）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2407.01449\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">ColPali：使用視覺語言模型進行高效文件檢索</div><div class=\"kg-bookmark-description\">文件是具有豐富視覺結構的內容，不僅通過文本，還通過圖表、頁面布局、表格甚至字體來傳遞信息。由於現代檢索系統主要依賴於從文件頁面中提取的文本信息來索引文件（通常通過冗長且脆弱的過程），他們難以有效地利用關鍵的視覺線索。這限制了它們在許多實際文件檢索應用中的能力，如檢索增強生成（RAG）。為了對當前系統在視覺豐富的文件檢索方面進行基準測試，我們引入了視覺文件檢索基準 ViDoRe，其中包含跨越多個領域、語言和實際場景的各種頁面級檢索任務。現代系統的固有複雜性和性能不足促使我們提出一個新概念：通過直接嵌入文件頁面的圖像來進行文件檢索。我們發布了 ColPali，這是一個經過訓練的視覺語言模型，可以從文件頁面的圖像生成高質量的多向量嵌入。結合後期交互匹配機制，ColPali 在性能上大大超越了現代文件檢索流程，同時更加簡單、快速且可端到端訓練。我們在 https://hf.co/vidore 以開放許可發布模型、數據、代碼和基準測試。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-16.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Manuel Faysse</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-12.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ViDoRe 是一個專門設計用來評估檢索系統在使用視覺特徵匹配查詢與相關文件能力的基準測試。它涵蓋了多個領域和語言的各種頁面級檢索任務。該基準測試主要關注文件的視覺元素。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th style=\"text-align: right\">AVG<br>(NDCG@5)</th>\n      <th style=\"text-align: right\">TAT-DQA</th>\n      <th style=\"text-align: right\">Shift<br>Project</th>\n      <th style=\"text-align: right\">Artificial<br>Intelligence</th>\n      <th style=\"text-align: right\">Government<br>Reports</th>\n      <th style=\"text-align: right\">ArxivQA</th>\n      <th style=\"text-align: right\">DocVQA</th>\n      <th style=\"text-align: right\">Healthcare<br>Industry</th>\n      <th style=\"text-align: right\">InfoVQA</th>\n      <th style=\"text-align: right\">Energy</th>\n      <th style=\"text-align: right\">TabFQuad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>91.02</strong></td>\n      <td style=\"text-align: right\"><strong>81.83</strong></td>\n      <td style=\"text-align: right\"><strong>93.22</strong></td>\n      <td style=\"text-align: right\"><strong>99.63</strong></td>\n      <td style=\"text-align: right\"><strong>97.59</strong></td>\n      <td style=\"text-align: right\"><strong>89.82</strong></td>\n      <td style=\"text-align: right\"><strong>62.58</strong></td>\n      <td style=\"text-align: right\"><strong>99.26</strong></td>\n      <td style=\"text-align: right\"><strong>92.88</strong></td>\n      <td style=\"text-align: right\"><strong>96.06</strong></td>\n      <td style=\"text-align: right\"><strong>97.32</strong></td>\n    </tr>\n    <tr>\n      <td>MrLight/dse-qwen2-2b-mr1-v1</td>\n      <td style=\"text-align: right\">84.48</td>\n      <td style=\"text-align: right\">66.64</td>\n      <td style=\"text-align: right\">79.39</td>\n      <td style=\"text-align: right\">96.45</td>\n      <td style=\"text-align: right\">95.30</td>\n      <td style=\"text-align: right\">84.53</td>\n      <td style=\"text-align: right\">55.47</td>\n      <td style=\"text-align: right\">96.85</td>\n      <td style=\"text-align: right\">86.39</td>\n      <td style=\"text-align: right\">91.80</td>\n      <td style=\"text-align: right\">92.03</td>\n    </tr>\n  \n    <tr>\n      <td>MonoQwen2-VL-v0.1</td>\n      <td style=\"text-align: right\">87.64</td>\n      <td style=\"text-align: right\">79.50</td>\n      <td style=\"text-align: right\">76.38</td>\n      <td style=\"text-align: right\">98.39</td>\n      <td style=\"text-align: right\">93.63</td>\n      <td style=\"text-align: right\">89.50</td>\n      <td style=\"text-align: right\">57.47</td>\n      <td style=\"text-align: right\">98.39</td>\n      <td style=\"text-align: right\">92.12</td>\n      <td style=\"text-align: right\">95.29</td>\n      <td style=\"text-align: right\">95.75</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"m-beir-text2image-image2text-multimodal-benchmark-for-instructed-retrieval\">M-BEIR（Text2Image、Image2Text、基於指令的多模態檢索基準測試）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2311.17136\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">UniIR: Training and Benchmarking Universal Multimodal Information Retrievers</div><div class=\"kg-bookmark-description\">目前的資訊檢索（IR）模型通常假設一種同質的格式，這限制了它們在滿足多樣化用戶需求方面的應用，例如使用文本描述搜索圖像、使用標題圖像搜索新聞文章，或使用查詢圖像尋找類似的照片。為了應對這些不同的資訊搜尋需求，我們推出了 UniIR，這是一個統一的指令引導多模態檢索器，能夠處理跨模態的八種不同檢索任務。UniIR 是一個在十個不同多模態 IR 數據集上共同訓練的單一檢索系統，它能解讀用戶指令來執行各種檢索任務，在現有數據集上展現出強大的性能，並能零樣本泛化到新任務。我們的實驗強調，多任務訓練和指令調優是 UniIR 泛化能力的關鍵。此外，我們建立了 M-BEIR，這是一個具有全面結果的多模態檢索基準測試，用於標準化通用多模態資訊檢索的評估。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Cong Wei</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-15.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>M-BEIR 是一個全面的大規模檢索基準測試，專門用於訓練和評估多模態檢索模型。它包含八種多模態檢索任務和來自各種領域和來源的十個數據集。該基準測試主要關注遵循指令的檢索能力。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n        <tr>\n          <th>Model</th>\n            <th>MBEIR t2i VisualNews<br>Recall@5</th>\n            <th>MBEIR t2i MSCOCO<br>Recall@5</th>\n            <th>MBEIR t2i Fashion200K<br>Recall@10</th>\n            <th>MBEIR i2t VisualNews<br>Recall@5</th>\n            <th>MBEIR i2t MSCOCO<br>Recall@5</th>\n            <th>MBEIR i2t Fashion200K<br>Recall@10</th>\n        </tr>\n    </thead>\n        <tr>\n            <td>jina-reranker-m0</td>\n            <td align=\"right\"><b>23.89</b></td>\n            <td align=\"right\"><b>72.19</b></td>\n            <td align=\"right\">9.79</td>\n            <td align=\"right\"><b>17.61</b></td>\n            <td align=\"right\">41.21</td>\n            <td align=\"right\"><b>11.56</b></td>\n        </tr>\n        <tr>\n            <td>jinaai/jina-clip-v2</td>\n            <td align=\"right\">15.42</td>\n            <td align=\"right\">52.28</td>\n            <td align=\"right\">7.03</td>\n            <td align=\"right\">11.63</td>\n            <td align=\"right\">28.80</td>\n            <td align=\"right\">8.78</td>\n        </tr>\n        <tr>\n            <td>MonoQwen2-VL-v0.1</td>\n            <td align=\"right\">22.74</td>\n            <td align=\"right\">71.29</td>\n            <td align=\"right\"><b>10.00</b></td>\n            <td align=\"right\">15.08</td>\n            <td align=\"right\"><b>42.24</b></td>\n            <td align=\"right\">11.25</td>\n        </tr>\n    </table>\n<!--kg-card-end: html-->\n<h3 id=\"winoground-text2text-text2image\">Winoground（Text2Text、Text2Image）</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2204.03162\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality</div><div class=\"kg-bookmark-description\">我們提出了一個新穎的任務和數據集，用於評估視覺和語言模型進行視覺語言組合推理的能力，我們稱之為 Winoground。給定兩張圖像和兩個標題，目標是正確匹配它們——但關鍵在於，兩個標題包含完全相同的詞集，只是順序不同。該數據集經過專家註釋者精心策劃，並標註了豐富的細粒度標籤，以協助分析模型性能。我們測試了各種最先進的視覺和語言模型，令人驚訝的是，它們的表現都不比隨機猜測好多少。顯然，這些模型在視覺語言組合推理方面的技能並不如我們所希望的那樣。我們進行了廣泛的分析，以獲得洞見，幫助未來的工作嘗試減輕這些模型的缺陷。我們希望 Winoground 能作為一個有用的評估集，推動該領域的技術進步。該數據集可在 https://huggingface.co/datasets/facebook/winoground 獲取。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-15.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Tristan Thrush</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-11.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Winoground 是一個新穎的任務和資料集，用於評估視覺和語言模型進行視覺語言組合推理的能力。它使用具有相同詞彙內容的雙胞胎字幕，並採用對比式的圖像-字幕配對。重點在於組合推理。</p>\n<!--kg-card-begin: html-->\n<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>Text</th>\n      <th>Image</th>\n      <th>Group</th>\n      <th>Avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>jina-reranker-m0</td>\n      <td style=\"text-align: right\"><strong>57.00</strong></td>\n      <td style=\"text-align: right\"><strong>40.75</strong></td>\n      <td style=\"text-align: right\"><strong>34.00</strong></td>\n      <td style=\"text-align: right\"><strong>43.92</strong></td>\n    </tr>\n    <tr>\n      <td>MrLight/dse-qwen2-2b-mrl-v1</td>\n      <td style=\"text-align: right\">7.50</td>\n      <td style=\"text-align: right\">9.25</td>\n      <td style=\"text-align: right\">1.75</td>\n      <td style=\"text-align: right\">6.17</td>\n    </tr>\n    <tr>\n      <td>MonoQwen2-VL-v0.1</td>\n      <td style=\"text-align: right\">52.00</td>\n      <td style=\"text-align: right\">36.25</td>\n      <td style=\"text-align: right\">31.50</td>\n      <td style=\"text-align: right\">39.92</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Winoground 使用三個關鍵指標來評估視覺語言模型：Text Score、Image Score 和 Group Score。Text Score 衡量模型是否正確地將字幕與圖像配對，而 Image Score 則評估模型是否為字幕選擇正確的圖像。Group Score 是最嚴格的指標，要求所有字幕-圖像關係都必須被正確識別。這些分數以百分比表示準確率，分數越高表示推理能力越好。</p><h2 id=\"conclusion\">結論</h2><p><code>jina-reranker-m0</code> 是我們首次嘗試在單一 decoder-only 模型中統一文本和視覺模態。這個新架構整合了我們從先前的 encoder-only 檢索模型中學到的經驗，包括 <code>jina-clip-v2</code>、<code>jina-embeddings-v3</code>、<code>jina-reranker-v2-base-multilingual</code> 和 <code>jina-embeddings-v2-base-code</code>。</p><p>新模型不僅解鎖了多模態檢索任務的能力，如文本到圖像重排序和視覺文件重排序，而且在文本到文本和文本到程式碼重排序任務上，相較於 <code>jina-reranker-v2-base-multilingual</code> 也展現了更好的表現。我們將這個新模型系列稱為「m-series」，以突顯其多模態特性。</p><p>在比較 <code>jina-reranker-m0</code> 和 <code>jina-reranker-v2-base-multilingual</code> 時，我們對 m-series 的目標是在實現多模態的同時，在純文本任務上能達到與專門的純文本模型相當的性能。有人可能會質疑，如果在純文本任務上的性能提升看起來微不足道，使用一個大 8 倍的模型是否值得。雖然目前 <code>m0</code> 在純文本應用上可能不會比 <code>v2</code> 帶來顯著的額外價值，但 decoder-only 架構開啟了許多使用 encoder-only 架構無法實現的新可能性，包括：</p><ul><li>真正的混合模態重排序</li><li>列表式重排序和文件去重</li><li>通過注意力機制解釋排名分數</li></ul><p>我們未來的工作將專注於進一步升級純文本重排序器，並充分利用這個多模態架構所啟用的新功能，以實現更好且更廣泛的搜尋。</p>",
  "comment_id": "67ea5eb45dcba60001c30f0a",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/04/banner-reranker-m0--1-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-03-31T11:21:56.000+02:00",
  "updated_at": "2025-04-08T13:21:13.000+02:00",
  "published_at": "2025-04-08T13:10:38.000+02:00",
  "custom_excerpt": "Introducing jina-reranker-m0, our new multilingual multimodal reranker for retrieving visual documents, with SOTA performance on multilingual long documents and code searching tasks.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-reranker-m0-multilingual-multimodal-document-reranker/",
  "excerpt": "介紹 jina-reranker-m0，這是我們新的多語言多模態重排序器，用於檢索視覺文件，在多語言長文件和程式碼搜尋任務上都達到了最先進的效能。",
  "reading_time": 20,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}