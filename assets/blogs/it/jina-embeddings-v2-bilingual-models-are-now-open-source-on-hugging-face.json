{
  "slug": "jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face",
  "id": "65b3adb510ff9f0001c50c4d",
  "uuid": "b082269a-4358-4a82-a70c-02da2ebcb6d3",
  "title": "I modelli bilingui di Jina Embeddings v2 sono ora open-source su Hugging Face",
  "html": "<p>Jina AI ha rilasciato i suoi modelli di embedding bilingue open-source all'avanguardia per le coppie linguistiche <a href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\">tedesco-inglese</a> e <a href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\">cinese-inglese</a> tramite Hugging Face.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ich bin ein Berliner: German-English Bilingual Embeddings with 8K Token Length</div><div class=\"kg-bookmark-description\">Jina AI introduces a German/English bilingual embedding model, featuring an extensive 8,192-token length, specifically designed to support German businesses thriving in the U.S. market.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Explore-image-storytelling-beyond-pixels--33-.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">8K Token-Length Bilingual Embeddings Break Language Barriers in Chinese and English</div><div class=\"kg-bookmark-description\">The first bilingual Chinese-English embedding model with 8192 token-length.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><p>In questo tutorial, esamineremo un'installazione e un caso d'uso molto semplici che copriranno:</p><ol><li>Il download dei modelli Jina Embedding da Hugging Face.</li><li>L'utilizzo dei modelli per ottenere codifiche da testi in tedesco e inglese.</li><li>La creazione di un motore di ricerca neurale molto rudimentale basato su embedding per query multilingue.</li></ol><p>Ti mostreremo come utilizzare Jina Embeddings per scrivere query in inglese che recuperano testi corrispondenti in tedesco e viceversa.</p><p>Questo tutorial funziona allo stesso modo per il modello cinese. Segui semplicemente le istruzioni nella sezione (verso la fine) intitolata <a href=\"#querying-in-chinese\" rel=\"noreferrer\"><strong>Querying in Chinese</strong></a> per ottenere il modello bilingue cinese-inglese e un esempio di documento in cinese.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-de?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-de · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-de.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-zh?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-zh · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><h2 id=\"bilingual-embedding-models\">Modelli di Embedding Bilingue</h2><p>Un modello di embedding bilingue è un modello che mappa testi in due lingue — tedesco e inglese in questo tutorial, cinese e inglese per il modello cinese — nello stesso spazio di embedding. E lo fa in modo tale che se un testo tedesco e un testo inglese significano la stessa cosa, i loro vettori di embedding corrispondenti saranno vicini tra loro.</p><p>Modelli come questo sono molto adatti alle applicazioni di recupero di informazioni cross-linguistiche, come mostreremo in questo tutorial, ma possono anche servire come base per chatbot basati su RAG, categorizzazione di testo multilingue, riassunti, analisi del sentiment e qualsiasi altra applicazione che utilizzi embedding. Utilizzando modelli come questi, puoi trattare i testi in entrambe le lingue come se fossero scritti nella stessa lingua.</p><p>Sebbene molti modelli linguistici giganti dichiarino di supportare molte lingue diverse, non le supportano tutte allo stesso modo. Ci sono crescenti domande sul <a href=\"https://aclanthology.org/2023.findings-eacl.89/?ref=jina-ai-gmbh.ghost.io\">bias causato dalla dominanza dell'inglese su Internet</a> e sulle fonti di input distorte dalla <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">diffusa pubblicazione online di testi tradotti automaticamente</a>. Concentrandoci su due lingue, possiamo controllare meglio la qualità dell'embedding per entrambe, minimizzando il bias producendo modelli molto più piccoli con prestazioni simili o superiori rispetto ai modelli giganti che pretendono di gestire decine di lingue.</p><p>I modelli bilingue Jina Embeddings v2 supportano 8.192 token di input contestuale, permettendo loro non solo di supportare due lingue, ma anche di gestire segmenti di testo relativamente grandi rispetto a modelli comparabili. Questo li rende ideali per casi d'uso più complessi in cui è necessario processare in embedding molta più informazione testuale.</p><h2 id=\"follow-along-on-google-colab\">Segui su Google Colab</h2><p>Questo tutorial ha un <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">notebook di accompagnamento</a> che puoi eseguire su <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>, o localmente sul tuo sistema.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/feat-embeddings-notebook/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colaboratory</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://ssl.gstatic.com/colaboratory-static/common/cce4fce8bbe78d8bdc0c77a288df9fa7/img/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" alt=\"\"></div></a></figure><h2 id=\"installing-the-prerequisites\">Installazione dei Prerequisiti</h2><p>Assicurati che l'ambiente attuale abbia le librerie necessarie installate. Avrai bisogno dell'ultima versione di <a href=\"https://pypi.org/project/transformers/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>transformers</code></a>, quindi anche se è già installata, esegui:</p><pre><code class=\"language-bash\">pip install -U transformers \n</code></pre><p>Questo tutorial utilizzerà la <a href=\"https://faiss.ai/?ref=jina-ai-gmbh.ghost.io\">libreria FAISS di Meta</a> per la ricerca e il confronto di vettori. Per installarla, esegui:</p><pre><code class=\"language-bash\">pip install faiss-cpu\n</code></pre><p>Useremo anche <a href=\"https://www.crummy.com/software/BeautifulSoup/?ref=jina-ai-gmbh.ghost.io\">Beautiful Soup</a> per elaborare i dati di input in questo tutorial, quindi assicurati che sia installato:</p><pre><code class=\"language-bash\">pip install bs4\n</code></pre><h2 id=\"access-to-hugging-face\">Accesso a Hugging Face</h2><p>Avrai bisogno di accesso a Hugging Face, in particolare di un account e un token di accesso per scaricare i modelli.</p><p><strong>Se non hai un account su Hugging Face:</strong></p><p>Vai su <a href=\"https://huggingface.co/?ref=jina-ai-gmbh.ghost.io\">https://huggingface.co/</a> e dovresti vedere un pulsante \"Sign Up\" in alto a destra della pagina. Cliccalo e segui le istruzioni per creare un nuovo account.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png\" class=\"kg-image\" alt=\"La pagina principale di Hugging Face, con il pulsante &quot;Sign Up&quot; evidenziato.\" loading=\"lazy\" width=\"1088\" height=\"887\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/01/Untitled--26-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/01/Untitled--26-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png 1088w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Dopo aver effettuato l'accesso al tuo account:</strong></p><p>Segui le istruzioni <a href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\">sul sito web di Hugging Face</a> per ottenere un token di accesso.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">User access tokens</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://huggingface.co/front/thumbnails/docs/hub.png\" alt=\"\"></div></a></figure><p>Devi copiare questo token in una variabile d'ambiente chiamata <code>HF_TOKEN</code>. Se stai lavorando in un notebook (su <a href=\"https://colab.research.google.com/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>, per esempio) o lo stai impostando internamente in un programma Python, usa il seguente codice Python:</p><pre><code class=\"language-python\">import os\n\nos.environ['HF_TOKEN'] = \"&lt;your token here&gt;\"\n</code></pre><p>Nella shell, usa la sintassi fornita per impostare una variabile d'ambiente. In <code>bash</code>:</p><pre><code class=\"language-bash\">export HF_TOKEN=\"&lt;your token here&gt;\"\n</code></pre><h2 id=\"download-jina-embeddings-v2-for-german-and-english\">Scarica Jina Embeddings v2 per tedesco e inglese</h2><p>Una volta impostato il token, puoi scaricare il modello bilingue tedesco-inglese Jina Embeddings usando la libreria <code>transformers</code>:</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-de', trust_remote_code=True)\n</code></pre><p>Questo potrebbe richiedere diversi minuti la prima volta che lo fai, ma il modello verrà memorizzato localmente dopo, quindi non preoccuparti se riavvii questo tutorial più tardi.</p><h2 id=\"download-english-language-data\">Scarica i dati in lingua inglese</h2><p>Per questo tutorial, prenderemo la versione in lingua inglese del libro <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git: Everything You Need to Know About Git</em></a>. Questo libro è disponibile anche in cinese e tedesco, che useremo più avanti in questo tutorial.</p><p>Per scaricare la versione EPUB, esegui il seguente comando:</p><pre><code class=\"language-bash\">wget -O progit-en.epub https://open.umn.edu/opentextbooks/formats/3437</code></pre><p>Questo copia il libro in un file chiamato <code>progit-en.epub</code> nella directory locale.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--27-.png\" class=\"kg-image\" alt=\"La copertina dell'edizione cartacea di &quot;Pro Git&quot; di Scott Chacon e Ben Straub.\" loading=\"lazy\" width=\"490\" height=\"647\"><figcaption><span style=\"white-space: pre-wrap;\">La copertina dell'edizione cartacea.</span></figcaption></figure><p>In alternativa, puoi semplicemente visitare il link <a href=\"https://open.umn.edu/opentextbooks/formats/3437?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">https://open.umn.edu/opentextbooks/formats/3437</a> per scaricarlo sul tuo disco locale. È disponibile sotto la <a href=\"https://creativecommons.org/licenses/by-nc-sa/3.0/?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">licenza Creative Commons Attribution Non Commercial Share Alike 3.0</a>.</p><h2 id=\"processing-the-data\">Elaborazione dei dati</h2><p>Questo testo particolare ha una struttura interna di sezioni gerarchiche, che possiamo facilmente trovare cercando il tag <code>&lt;section&gt;</code> nei dati XHTML sottostanti. Il codice seguente legge il file EPUB e lo divide usando la struttura interna di un file EPUB e il tag <code>&lt;section&gt;</code>, poi converte ogni sezione in testo semplice senza tag XHTML. Crea un dizionario Python le cui chiavi sono un insieme di stringhe che indicano la posizione di ogni sezione nel libro, e i cui valori sono i contenuti in testo semplice di quella sezione.</p><pre><code class=\"language-python\">from zipfile import ZipFile\nfrom bs4 import BeautifulSoup\nimport copy\n\ndef decompose_epub(file_name):\n    \n    def to_top_text(section):\n        selected = copy.copy(section)\n\t\t\t\twhile next_section := selected.find(\"section\"):\n            next_section.decompose()\n        return selected.get_text().strip()\n\n    ret = {}\n    with ZipFile(file_name, 'r') as zip:\n        for name in zip.namelist():\n            if name.endswith(\".xhtml\"):\n                data = zip.read(name)\n                doc = BeautifulSoup(data.decode('utf-8'), 'html.parser')\n                ret[name + \":top\"] = to_top_text(doc)\n                for num, sect in enumerate(doc.find_all(\"section\")):\n                    ret[name + f\"::{num}\"] = to_top_text(sect)\n    return ret\n</code></pre><p>Quindi, esegui la funzione <code>decompose_epub</code> sul file EPUB che hai scaricato prima:</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-en.epub\")\n</code></pre><p>La variabile <code>book_data</code> avrà ora 583 sezioni. Per esempio:</p><pre><code class=\"language-python\">print(book_data['EPUB/ch01-getting-started.xhtml::12'])\n</code></pre><p>Risultato:</p><pre><code class=\"language-Text\">The Command Line\nThere are a lot of different ways to use Git.\nThere are the original command-line tools, and there are many graphical user interfaces of varying capabilities.\nFor this book, we will be using Git on the command line.\nFor one, the command line is the only place you can run all Git commands — most of the GUIs implement only a partial subset of Git functionality for simplicity.\nIf you know how to run the command-line version, you can probably also figure out how to run the GUI version, while the opposite is not necessarily true.\nAlso, while your choice of graphical client is a matter of personal taste, all users will have the command-line tools installed and available.\nSo we will expect you to know how to open Terminal in macOS or Command Prompt or PowerShell in Windows.\nIf you don't know what we're talking about here, you may need to stop and research that quickly so that you can follow the rest of the examples and descriptions in this book.\n</code></pre><h2 id=\"generating-and-indexing-embeddings-with-jina-embeddings-v2-and-faiss\">Generazione e indicizzazione degli embedding con Jina Embeddings v2 e FAISS</h2><p>Per ciascuna delle 583 sezioni, genereremo un embedding e lo memorizzeremo in un indice FAISS. I modelli Jina Embeddings v2 accettano input fino a 8192 token, abbastanza grandi che per un libro come questo, non abbiamo bisogno di fare ulteriore segmentazione del testo o controllare se qualche sezione ha troppi token. La sezione più lunga del libro ha circa 12.000 caratteri, che, per l'inglese normale, dovrebbe essere ben al di sotto del limite di 8k token.</p><p>Per generare un singolo embedding, usi il metodo <code>encode</code> del modello che abbiamo scaricato. Per esempio:</p><pre><code class=\"language-python\">model.encode([book_data['EPUB/ch01-getting-started.xhtml::12']])\n</code></pre><p>Questo restituisce un array contenente un singolo vettore a 768 dimensioni:</p><pre><code class=\"language-python\">array([[ 6.11135997e-02,  1.67829826e-01, -1.94809273e-01,\n         4.45595086e-02,  3.28837298e-02, -1.33441269e-01,\n         1.35364473e-01, -1.23119736e-02,  7.51526654e-02,\n        -4.25386652e-02, -6.91794455e-02,  1.03527725e-01,\n        -2.90831417e-01, -6.21018047e-03, -2.16205455e-02,\n        -2.20803712e-02,  1.50471330e-01, -3.31433356e-01,\n        -1.48741454e-01, -2.10959971e-01,  8.80039856e-02,\n\t\t\t\t....\n</code></pre><p>Questo è un embedding.</p><p>I modelli Jina Embeddings sono configurati per consentire l'elaborazione in batch. La dimensione ottimale del batch dipende dall'hardware che usi durante l'esecuzione. Una dimensione del batch troppo grande rischia di esaurire la memoria. Una dimensione del batch piccola impiegherà più tempo per l'elaborazione.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Impostare <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">batch_size=5</code> ha funzionato su Google Colab nel livello gratuito senza GPU, e ha impiegato <b><strong style=\"white-space: pre-wrap;\">circa un'ora</strong></b> per generare l'intero set di embedding.</div></div><p>In produzione, raccomandiamo di utilizzare hardware molto più potente o di utilizzare il <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">servizio API Embedding di Jina AI</a>. Segui il link qui sotto per scoprire come funziona e come iniziare con l'accesso gratuito.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Top-performing, 8192-token context length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>Il codice seguente genera gli embedding e li memorizza in un indice FAISS. Imposta la variabile <code>batch_size</code> in base alle tue risorse.</p><pre><code class=\"language-python\">import faiss\n\nbatch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>Quando si lavora in un ambiente di produzione, un dizionario Python non è un modo adeguato o performante per gestire documenti ed embedding. Dovresti utilizzare un database vettoriale dedicato, che avrà le proprie istruzioni per l'inserimento dei dati.</p><h2 id=\"querying-in-german-for-english-results\">Query in tedesco per risultati in inglese</h2><p>Quando facciamo una query su questo set di testi, ecco cosa succederà:</p><ol><li>Il modello Jina Embeddings tedesco-inglese creerà un embedding per la query.</li><li>Useremo l'indice FAISS (<code>faiss_index</code>) per ottenere l'embedding memorizzato con il coseno più alto rispetto all'embedding della query e restituire la sua posizione nell'indice.</li><li>Cercheremo il testo corrispondente nell'array dei dati vettoriali (<code>vector_data</code>) e stamperemo il coseno, la posizione del testo e il testo stesso.</li></ol><p>Questo è ciò che fa la funzione <code>query</code> qui sotto.</p><pre><code class=\"language-python\">def query(query_str):\n    query = model.encode([query_str], normalize_embeddings=True)\n    cosine, index = faiss_index.search(query, 1)\n    print(f\"Cosine: {cosine[0][0]}\")\n    loc, txt = vector_data[index[0][0]]\n    print(f\"Location: {loc}\\\\nText:\\\\n\\\\n{txt}\")\n</code></pre><p>Ora proviamolo.</p><pre><code class=\"language-python\"># Translation: \"How do I roll back to a previous version?\"\nquery(\"Wie kann ich auf eine frühere Version zurücksetzen?\")\n</code></pre><p>Risultato:</p><pre><code class=\"language-text\">Cosine: 0.5202275514602661\nLocation: EPUB/ch02-git-basics-chapter.xhtml::20\nText:\n\nUndoing things with git restore\nGit version 2.23.0 introduced a new command: git restore.\nIt's basically an alternative to git reset which we just covered.\nFrom Git version 2.23.0 onwards, Git will use git restore instead of git reset for many undo operations.\nLet's retrace our steps, and undo things with git restore instead of git reset.\n</code></pre><p>Questa è una scelta abbastanza buona per rispondere alla domanda. Proviamone un'altra:</p><pre><code class=\"language-python\"># Translation: \"What does 'version control' mean?\"\nquery(\"Was bedeutet 'Versionsverwaltung'?\")\n</code></pre><p>Risultato:</p><pre><code class=\"language-text\">Cosine: 0.5001817941665649\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nAbout Version Control\n\nWhat is \"version control\", and why should you care?\nVersion control is a system that records changes to a file or set of files over time so that you can recall specific versions later.\nFor the examples in this book, you will use software source code as the files being version controlled, though in reality you can do this with nearly any type of file on a computer.\nIf you are a graphic or web designer and want to keep every version of an image or layout (which you would most certainly want to), a Version Control System (VCS) is a very wise thing to use.\nIt allows you to revert selected files back to a previous state, revert the entire project back to a previous state, compare changes over time, see who last modified something that might be causing a problem, who introduced an issue and when, and more.\nUsing a VCS also generally means that if you screw things up or lose files, you can easily recover.\nIn addition, you get all this for very little overhead.\n</code></pre><p>Prova con le tue domande in tedesco per vedere quanto funziona bene. Come pratica generale, quando si ha a che fare con il recupero di informazioni testuali, è consigliabile chiedere da tre a cinque risposte invece di una sola. La risposta migliore spesso non è la prima.</p><h2 id=\"reversing-the-roles-querying-german-documents-with-english\">Invertire i Ruoli: Interrogare documenti tedeschi in inglese</h2><p>Il libro <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git: Everything You Need to Know About Git</em></a> è disponibile anche <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git-german?ref=jina-ai-gmbh.ghost.io\">in tedesco</a>. Possiamo utilizzare lo stesso modello per fare questa dimostrazione con le lingue invertite.</p><p>Scaricare l'ebook:</p><pre><code class=\"language-bash\">wget -O progit-de.epub https://open.umn.edu/opentextbooks/formats/3454\n</code></pre><p>Questo copia il libro in un file chiamato <code>progit-de.epub</code>. Lo elaboriamo poi allo stesso modo del libro in inglese:</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-de.epub\")\n</code></pre><p>E poi generiamo gli embedding allo stesso modo di prima:</p><pre><code class=\"language-python\">batch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>Ora possiamo utilizzare la stessa funzione <code>query</code> per cercare in inglese risposte in tedesco:</p><pre><code class=\"language-python\">query(\"What is version control?\")\n</code></pre><p>Risultato:</p><pre><code class=\"language-text\">Cosine: 0.6719034910202026\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nWas ist Versionsverwaltung?\n\nWas ist „Versionsverwaltung\", und warum sollten Sie sich dafür interessieren?\nVersionsverwaltung ist ein System, welches die Änderungen an einer oder einer Reihe von Dateien über die Zeit hinweg protokolliert, sodass man später auf eine bestimmte Version zurückgreifen kann.\nDie Dateien, die in den Beispielen in diesem Buch unter Versionsverwaltung gestellt werden, enthalten Quelltext von Software, tatsächlich kann in der Praxis nahezu jede Art von Datei per Versionsverwaltung nachverfolgt werden.\nAls Grafik- oder Webdesigner möchte man zum Beispiel in der Lage sein, jede Version eines Bildes oder Layouts nachverfolgen zu können. Als solcher wäre es deshalb ratsam, ein Versionsverwaltungssystem (engl. Version Control System, VCS) einzusetzen.\nEin solches System erlaubt es, einzelne Dateien oder auch ein ganzes Projekt in einen früheren Zustand zurückzuversetzen, nachzuvollziehen, wer zuletzt welche Änderungen vorgenommen hat, die möglicherweise Probleme verursachen, herauszufinden wer eine Änderung ursprünglich vorgenommen hat und viele weitere Dinge.\nEin Versionsverwaltungssystem bietet allgemein die Möglichkeit, jederzeit zu einem vorherigen, funktionierenden Zustand zurückzukehren, auch wenn man einmal Mist gebaut oder aus irgendeinem Grund Dateien verloren hat.\nAll diese Vorteile erhält man für einen nur sehr geringen, zusätzlichen Aufwand.\n</code></pre><p>Il titolo di questa sezione si traduce come <em>\"Che cos'è il controllo versione?\"</em>, quindi questa è una buona risposta.</p><h2 id=\"querying-in-chinese\">Interrogare in Cinese</h2><p>Questi esempi funzioneranno esattamente allo stesso modo con Jina Embeddings v2 per cinese e inglese. Per utilizzare invece il modello cinese, basta eseguire quanto segue:</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)\n</code></pre><p>E per ottenere l'edizione cinese di <em>Pro Git: Everything You Need to Know About Git</em>:</p><pre><code class=\"language-python\">wget -O progit-zh.epub https://open.umn.edu/opentextbooks/formats/3455\n</code></pre><p>Quindi, elaborare il libro cinese:</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-zh.epub\")\n</code></pre><p>Tutto il resto del codice in questo tutorial funzionerà allo stesso modo.</p><h2 id=\"the-future-more-languages-including-programming\">Il Futuro: Più Lingue, inclusa la Programmazione</h2><p>Rilasceremo altri modelli bilingue nell'immediato futuro, con spagnolo e giapponese già in lavorazione, così come un modello che supporta l'inglese e diversi linguaggi di programmazione importanti. Questi modelli sono idealmente adatti alle imprese internazionali che gestiscono informazioni multilingue, e possono servire come pietra angolare per il recupero di informazioni basato su AI e modelli linguistici generativi basati su RAG, inserendosi in una varietà di casi d'uso AI all'avanguardia.</p><p>I modelli di Jina AI sono compatti e si collocano tra i migliori della loro classe, dimostrando che non è necessario il modello più grande per ottenere le migliori prestazioni. Concentrandoci sulle prestazioni bilingue, produciamo modelli che sono sia migliori in quelle lingue, più facili da adattare e più convenienti rispetto ai grandi modelli addestrati su dati non curati.</p><p>Jina Embeddings sono disponibili su <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>, nel <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">marketplace AWS</a> per l'uso in Sagemaker, e tramite <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">l'API web Jina Embeddings</a>. Sono completamente integrati in molti framework di processo AI e database vettoriali.</p><p>Visita il <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">sito web Jina Embeddings</a> per maggiori informazioni, o contattaci per discutere di come le soluzioni di Jina AI possono adattarsi ai tuoi processi aziendali.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Top-performing, 8192-token context length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure>",
  "comment_id": "65b3adb510ff9f0001c50c4d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/01/Blog-images--32-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-01-26T14:03:49.000+01:00",
  "updated_at": "2024-02-05T17:19:35.000+01:00",
  "published_at": "2024-01-26T17:14:56.000+01:00",
  "custom_excerpt": "Jina AI's open-source bilingual embedding models for German-English and Chinese-English are now on Hugging Face.\nWe’re going to walk through installation and cross-language retrieval.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face/",
  "excerpt": "I modelli di embedding bilingue open-source di Jina AI per tedesco-inglese e cinese-inglese sono ora disponibili su Hugging Face.\nVedremo come effettuare l'installazione e il recupero multilingue.",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Colorful \"EMBEDDINGS\" text above a pile of yellow smileys on a black background with decorative lines at the top.",
  "feature_image_caption": null
}