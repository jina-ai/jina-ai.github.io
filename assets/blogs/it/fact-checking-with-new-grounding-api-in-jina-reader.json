{
  "slug": "fact-checking-with-new-grounding-api-in-jina-reader",
  "id": "670cd94952567c0001d0f33e",
  "uuid": "20c36ec7-687f-47c8-8cfd-8da526a70859",
  "title": "Verifica dei fatti con la nuova API Grounding in Jina Reader",
  "html": "<p>Il grounding è <em>assolutamente essenziale</em> per le applicazioni GenAI.</p><p>Senza grounding, gli LLM sono più inclini ad allucinazioni e a generare informazioni inaccurate, specialmente quando i loro dati di training mancano di conoscenze aggiornate o specifiche. Non importa quanto forte sia la capacità di ragionamento di un LLM, semplicemente non può fornire una risposta corretta se l'informazione è stata introdotta <em>dopo</em> la data limite delle sue conoscenze.</p><p>Il grounding non è importante solo per gli LLM ma anche per i contenuti scritti dagli umani per prevenire la disinformazione. Un ottimo esempio è <a href=\"https://communitynotes.x.com/guide/en/about/introduction?ref=jina-ai-gmbh.ghost.io\">X's Community Notes,</a> dove gli utenti aggiungono collaborativamente contesto ai post potenzialmente fuorvianti. Questo evidenzia il valore del grounding, che assicura l'accuratezza fattuale fornendo fonti e riferimenti chiari, proprio come Community Notes aiuta a mantenere l'integrità delle informazioni.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png\" class=\"kg-image\" alt=\"Screenshot of a mobile chat in the Sage app discussing whether whales are mammals and how they hydrate, with options to rate \" loading=\"lazy\" width=\"2000\" height=\"1113\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Con <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>, abbiamo sviluppato attivamente una soluzione di grounding facile da usare. Per esempio, <code>r.jina.ai</code> converte le pagine web in markdown compatibile con LLM, e <code>s.jina.ai</code> aggrega i risultati di ricerca in un formato markdown unificato basato su una data query.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs or search the web, get better grounding for LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-9.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><strong>Oggi siamo entusiasti di presentare un nuovo endpoint a questa suite: <code>g.jina.ai</code>. </strong>La nuova API prende una determinata affermazione, la verifica utilizzando risultati di ricerca web in tempo reale e restituisce un punteggio di fattualità e <strong>i riferimenti esatti utilizzati</strong>. I nostri esperimenti mostrano che questa API raggiunge un punteggio F1 più alto per il fact-checking rispetto a modelli come GPT-4, o1-mini e Gemini 1.5 Flash & Pro con grounding basato sulla ricerca.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Evaluation-of-grounding-solutions-on-fact-checking-100-statements--1-.svg\" class=\"kg-image\" alt=\"Bar graph illustrating the evaluation of various grounding solutions for fact-checking 100 statements, with software scores r\" loading=\"lazy\" width=\"1218\" height=\"371\"><figcaption><span style=\"white-space: pre-wrap;\">Abbiamo raccolto manualmente 100 affermazioni con etichette di verità \"vero\" o \"falso\" e utilizzato diversi metodi per determinare se potevano essere verificate. Questo processo essenzialmente converte il compito in un problema di classificazione binaria, dove la performance finale è misurata dal punteggio F1—più alto è, meglio è.</span></figcaption></figure><p>Ciò che distingue <code>g.jina.ai</code> dal Search Grounding di Gemini è che ogni risultato include fino a 30 URL (tipicamente fornendo almeno 10), ciascuno accompagnato da citazioni dirette che contribuiscono alla conclusione. Di seguito un esempio di grounding dell'affermazione, <code>\"The latest model released by Jina AI is jina-embeddings-v3,\"</code> utilizzando <code>g.jina.ai</code> (al 14 ottobre 2024). Esplora il <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">playground dell'API</a> per scoprire tutte le funzionalità. Nota che si applicano delle <a href=\"#limitations\" rel=\"noreferrer\">limitazioni</a>:</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-bash\">curl -X POST https://g.jina.ai \\\n     -H \"Content-Type: application/json\" \\\n     -H \"Authorization: Bearer $YOUR_JINA_TOKEN\" \\\n     -d '{\n           \"statement\":\"the last model released by Jina AI is jina-embeddings-v3\"\n         }'</code></pre><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>YOUR_JINA_TOKEN</span></code><span style=\"white-space: pre-wrap;\"> è la tua chiave API di Jina AI. Puoi </span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">ottenere 1M di token gratuiti dalla nostra homepage</span></a><span style=\"white-space: pre-wrap;\">, che permettono circa tre o quattro prove gratuite. Con l'attuale prezzo dell'API di 0.02USD per 1M di token, ogni richiesta di grounding costa circa $0.006.</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"code\": 200,\n  \"status\": 20000,\n  \"data\": {\n    \"factuality\": 0.95,\n    \"result\": true,\n    \"reason\": \"The majority of the references explicitly support the statement that the last model released by Jina AI is jina-embeddings-v3. Multiple sources, such as the arXiv paper, Jina AI's news, and various model documentation pages, confirm this assertion. Although there are a few references to the jina-embeddings-v2 model, they do not provide evidence contradicting the release of a subsequent version (jina-embeddings-v3). Therefore, the statement that 'the last model released by Jina AI is jina-embeddings-v3' is well-supported by the provided documentation.\",\n    \"references\": [\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"arXiv September 18, 2024 jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"We introduce jina-embeddings-v3, a novel text embedding model with 570 million parameters, achieves state-of-the-art performance on multilingual data and long-context retrieval tasks, supporting context lengths of up to 8192 tokens.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview\",\n        \"keyQuote\": \"jina-embeddings-v3 is a multilingual multi-task text embedding model designed for a variety of NLP applications.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://docs.pinecone.io/models/jina-embeddings-v3\",\n        \"keyQuote\": \"Jina Embeddings v3 is the latest iteration in the Jina AI's text embedding model series, building upon Jina Embedding v2.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://haystack.deepset.ai/integrations/jina\",\n        \"keyQuote\": \"Recommended Model: jina-embeddings-v3 : We recommend jina-embeddings-v3 as the latest and most performant embedding model from Jina AI.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"The embedding model was trained using 512 sequence length, but extrapolates to 8k sequence length (or even longer) thanks to ALiBi.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"With a standard size of 137 million parameters, the model enables fast inference while delivering better performance than our small model.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"We offer an `encode` function to deal with this.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jinaai/jina-embeddings-v3 Feature Extraction • Updated 3 days ago • 278k • 375\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"the latest version (3.1.0) of [SentenceTransformers] also supports jina-embeddings-v3\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/embeddings/\",\n        \"keyQuote\": \"v3: Frontier Multilingual Embeddings is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\",\n        \"keyQuote\": \"Jina Embeddings v3: A Frontier Multilingual Embedding Model jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/\",\n        \"keyQuote\": \"As of its release on September 18, 2024, jina-embeddings-v3 is the best multilingual model ...\",\n        \"isSupportive\": true\n      }\n    ],\n    \"usage\": {\n      \"tokens\": 112073\n    }\n  }\n}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">La risposta del grounding dell'affermazione \"The latest model released by Jina AI is jina-embeddings-v3\" utilizzando </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>g.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> (al 14 ottobre 2024).</span></p></figcaption></figure><h2 id=\"how-does-it-work\">Come Funziona?</h2><p>Nel suo nucleo, <code>g.jina.ai</code> racchiude <code>s.jina.ai</code> e <code>r.jina.ai</code><strong> </strong>, aggiungendo il ragionamento multi-hop attraverso Chain of Thought (CoT). Questo approccio assicura che ogni affermazione verificata sia analizzata a fondo con l'aiuto di ricerche online e lettura di documenti.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/User-Render.svg\" class=\"kg-image\" alt=\"UI of Jina AI reader app, displaying three panels: User Input, Response, and User Render with interactive links and buttons a\" loading=\"lazy\" width=\"1400\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">Grounding API è un wrapper costruito su </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>s.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> e </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>r.jina.ai</span></code><span style=\"white-space: pre-wrap;\">, che aggiunge CoT per la pianificazione e il ragionamento. </span></figcaption></figure><h3 id=\"step-by-step-explanation\">Spiegazione Passo dopo Passo</h3><p>Esaminiamo l'intero processo per comprendere meglio come <code>g.jina.ai</code> gestisce il grounding dall'input all'output finale:</p><ol><li><strong>Dichiarazione di Input</strong>:<br>Il processo inizia quando un utente fornisce una dichiarazione da verificare, come <em>\"L'ultimo modello rilasciato da Jina AI è jina-embeddings-v3.\"</em> Nota: non è necessario aggiungere alcuna istruzione di verifica dei fatti prima della dichiarazione.</li><li><strong>Generazione delle Query di Ricerca</strong>:<br>Un LLM viene utilizzato per generare un elenco di query di ricerca uniche pertinenti alla dichiarazione. Queste query mirano a individuare diversi elementi fattuali, assicurando che la ricerca copra tutti gli aspetti chiave della dichiarazione in modo completo.</li><li><strong>Chiamata a <code>s.jina.ai</code> per Ogni Query</strong>:<br>Per ogni query generata, <code>g.jina.ai</code> esegue una ricerca web utilizzando <code>s.jina.ai</code>. I risultati della ricerca consistono in un insieme diversificato di siti web o documenti relativi alle query. Dietro le quinte, <code>s.jina.ai</code> chiama <code>r.jina.ai</code> per recuperare il contenuto della pagina.</li><li><strong>Estrazione dei Riferimenti dai Risultati di Ricerca</strong>:<br>Da ogni documento recuperato durante la ricerca, un LLM estrae i riferimenti chiave. Questi riferimenti includono:<ul><li><strong><code>url</code></strong>: L'indirizzo web della fonte.</li><li><strong><code>keyQuote</code></strong>: Una citazione diretta o un estratto dal documento.</li><li><strong><code>isSupportive</code></strong>: Un valore booleano che indica se il riferimento supporta o contraddice la dichiarazione originale.</li></ul></li><li><strong>Aggregazione e Selezione dei Riferimenti</strong>:<br>Tutti i riferimenti dai documenti recuperati vengono combinati in un'unica lista. Se il numero totale di riferimenti supera 30, il sistema seleziona 30 riferimenti casuali per mantenere un output gestibile.</li><li><strong>Valutazione della Dichiarazione</strong>:<br>Il processo di valutazione implica l'utilizzo di un LLM per valutare la dichiarazione basandosi sui riferimenti raccolti (fino a 30). Oltre a questi riferimenti esterni, anche la conoscenza interna del modello gioca un ruolo nella valutazione. Il risultato finale include:<ul><li><strong><code>factuality</code></strong>: Un punteggio tra 0 e 1 che stima l'accuratezza fattuale della dichiarazione.</li><li><strong><code>result</code></strong>: Un valore booleano che indica se la dichiarazione è vera o falsa.</li><li><strong><code>reason</code></strong>: Una spiegazione dettagliata del perché la dichiarazione è giudicata corretta o incorretta, citando le fonti di supporto o contraddittorie.</li></ul></li><li><strong>Generazione dell'Output</strong>:<br>Una volta che la dichiarazione è stata completamente valutata, viene generato l'output. Questo include il <strong>punteggio di fattualità</strong>, l'<strong>asserzione della dichiarazione</strong>, un <strong>ragionamento dettagliato</strong> e un elenco di <strong>riferimenti</strong> con citazioni e URL. I riferimenti sono limitati alla citazione, URL e se supportano o meno la dichiarazione, mantenendo l'output chiaro e conciso.</li></ol><h2 id=\"benchmark\">Benchmark</h2><p>Abbiamo raccolto manualmente 100 dichiarazioni con etichette di verità di tipo <code>true</code> (62 dichiarazioni) o <code>false</code> (38 dichiarazioni) e utilizzato diversi metodi per determinare se potessero essere verificate. Questo processo converte essenzialmente il compito in un problema di classificazione binaria, dove le prestazioni finali sono misurate dalla precisione, dal recall e dal punteggio F1—più alto è, meglio è.</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1xE-uCTQ4G0cYRw_g781zZXHO8eRYi31HbCb-3BPlNh8/edit?gid=1283553680&ref=jina-ai-gmbh.ghost.io#gid=1283553680\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Grounding Validation Dataset</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyJpf4HNZ3zF1snMGetpmkt0oOTQGGviY1-ZTOrq5dXuafT8uWLmZ806MU1A_agTpgO52Z_xZ-iDougmFm0ViL0sVSqDxe3C4fVuPcYXKoS5O90jN3Qy-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">L'elenco completo delle dichiarazioni è disponibile qui.</span></p></figcaption></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Precision</th>\n<th>Recall</th>\n<th>F1 Score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Jina AI Grounding API (g.jina.ai)</strong></td>\n<td>0.96</td>\n<td><strong>0.88</strong></td>\n<td><strong>0.92</strong></td>\n</tr>\n<tr>\n<td>Gemini-flash-1.5-002 w/ grounding</td>\n<td><strong>1.00</strong></td>\n<td>0.73</td>\n<td>0.84</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-002 w/ grounding</td>\n<td>0.98</td>\n<td>0.71</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>gpt-o1-mini</td>\n<td>0.87</td>\n<td>0.66</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>0.95</td>\n<td>0.58</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001 w/ grounding</td>\n<td>0.97</td>\n<td>0.52</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001</td>\n<td>0.95</td>\n<td>0.32</td>\n<td>0.48</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Nota: nella pratica, alcuni LLM restituiscono una terza classe, <em>Non lo so</em>, nelle loro previsioni. Per la valutazione, queste istanze sono escluse dal calcolo del punteggio. Questo approccio evita di penalizzare l'incertezza tanto quanto le risposte errate. Ammettere l'incertezza è preferibile al fare ipotesi, per scoraggiare i modelli dal fare previsioni incerte.</p><h2 id=\"limitations\">Limitazioni</h2><p>Nonostante i risultati promettenti, vorremmo evidenziare alcune limitazioni dell'attuale versione della Grounding API:</p><ul><li><strong>Alta Latenza e Consumo di Token</strong>: Una singola chiamata a <code>g.jina.ai</code> può richiedere circa <strong>30 secondi</strong> e utilizzare fino a <strong>300K token</strong>, a causa della ricerca web attiva, della lettura delle pagine e del ragionamento multi-hop dell'LLM. Con una chiave API gratuita da 1M di token, questo significa che puoi testarlo solo tre o quattro volte. Per mantenere la disponibilità del servizio per gli utenti a pagamento, abbiamo anche implementato <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\" rel=\"noreferrer\">un limite di velocità conservativo per <code>g.jina.ai</code>.</a> Con il nostro attuale prezzo API di $0.02 per 1M di token, ogni richiesta di grounding costa circa 0.006 USD.</li><li><strong>Vincoli di Applicabilità</strong>: <em>Non ogni dichiarazione può o dovrebbe essere verificata.</em> Opinioni personali o esperienze, come \"Mi sento pigro\", non sono adatte al grounding. Analogamente, eventi futuri o dichiarazioni ipotetiche non si applicano. Ci sono molti casi in cui il grounding sarebbe irrilevante o privo di senso. Per evitare chiamate API non necessarie, consigliamo agli utenti di inviare selettivamente solo frasi o sezioni che richiedono effettivamente una verifica dei fatti. Sul lato server, abbiamo implementato un set completo di codici di errore per spiegare perché una dichiarazione potrebbe essere rifiutata per il grounding.</li><li><strong>Dipendenza dalla Qualità dei Dati Web</strong>: L'accuratezza della Grounding API è buona solo quanto la qualità delle fonti che recupera. Se i risultati della ricerca contengono informazioni di bassa qualità o distorte, il processo di grounding potrebbe rifletterlo, portando potenzialmente a conclusioni inaccurate o fuorvianti. Per prevenire questo problema, permettiamo agli utenti di specificare manualmente il parametro <code>references</code> e limitare gli URL su cui il sistema effettua la ricerca. Questo dà agli utenti maggior controllo sulle fonti utilizzate per il grounding, garantendo un processo di verifica dei fatti più mirato e pertinente.</li></ul><h2 id=\"conclusion\">Conclusione</h2><p>La Grounding API offre un'esperienza di verifica dei fatti end-to-end quasi in tempo reale. I ricercatori possono utilizzarla per trovare riferimenti che supportino o sfidino le loro ipotesi, aggiungendo credibilità al loro lavoro. Nelle riunioni aziendali, garantisce che le strategie siano costruite su informazioni accurate e aggiornate verificando ipotesi e dati. Nelle discussioni politiche, verifica rapidamente le affermazioni, portando maggiore responsabilità nei dibattiti.</p><p>Guardando al futuro, prevediamo di migliorare l'API integrando fonti di dati private come report interni, database e PDF per una verifica dei fatti più personalizzata. Miriamo anche ad espandere il numero di fonti controllate per richiesta per valutazioni più approfondite. Migliorare il question-answering multi-hop aggiungerà profondità all'analisi, e aumentare la consistenza è una priorità per garantire che richieste ripetute producano risultati più affidabili e coerenti.</p>",
  "comment_id": "670cd94952567c0001d0f33e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-14T10:41:45.000+02:00",
  "updated_at": "2024-10-15T20:11:23.000+02:00",
  "published_at": "2024-10-15T10:08:02.000+02:00",
  "custom_excerpt": "With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fact-checking-with-new-grounding-api-in-jina-reader/",
  "excerpt": "Con il nuovo g.jina.ai, puoi facilmente fondare le affermazioni per ridurre le allucinazioni dei LLM o migliorare l'integrità dei contenuti scritti dall'uomo.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Jina developer interface showing \"Jina AI was founded in 2020\" with controls labeled true and false, and web address on top.",
  "feature_image_caption": null
}