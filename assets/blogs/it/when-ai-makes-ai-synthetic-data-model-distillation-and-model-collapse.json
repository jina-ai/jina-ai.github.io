{
  "slug": "when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse",
  "id": "6639e8e1af8f52000115be49",
  "uuid": "1b3da192-0050-4b9e-8528-c5e638d50870",
  "title": "Quando l'IA crea l'IA: Dati Sintetici, Distillazione dei Modelli e Collasso dei Modelli",
  "html": "<p>Il discorso sull'AI è spesso apocalittico. Parte della colpa è dovuta al modo in cui la <a href=\"https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping?ref=jina-ai-gmbh.ghost.io\">fantascienza apocalittica</a> ha creato la nostra immagine mentale dell'intelligenza artificiale. Le visioni di macchine intelligenti che possono creare altre macchine sono state un tema comune nella fantascienza per generazioni.</p><p>Molte persone si sono espresse sui rischi esistenziali degli recenti sviluppi dell'AI, molti di loro sono <a href=\"https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html?ref=jina-ai-gmbh.ghost.io\">leader aziendali coinvolti nella commercializzazione dell'AI</a>, e persino alcuni <a href=\"https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/?ref=jina-ai-gmbh.ghost.io\">scienziati</a> e <a href=\"https://www.lemonde.fr/en/international/article/2023/06/04/in-montreal-one-of-the-fathers-of-artificial-intelligence-warns-of-an-existential-threat-to-mankind_6029007_4.html?ref=jina-ai-gmbh.ghost.io\">ricercatori</a>. È diventato un elemento dell'hype dell'AI: qualcosa abbastanza potente da far contemplare la fine del mondo a figure apparentemente sobrie della scienza e dell'industria deve sicuramente essere abbastanza potente da generare profitto, giusto?</p><p>Quindi, dovremmo preoccuparci dei rischi esistenziali dell'AI? Dobbiamo temere che Sam Altman creerà Ultron da ChatGPT e farà sì che il suo <a href=\"https://youtu.be/d4yZPjB7smU?ref=jina-ai-gmbh.ghost.io\">esercito di AI ci lanci contro città dell'Europa orientale</a>? Dovremmo preoccuparci che <a href=\"https://venturebeat.com/business/why-palantir-is-silicon-valleys-most-questionable-unicorn/?ref=jina-ai-gmbh.ghost.io\">Palantir di Peter Thiel</a> stia <a href=\"https://youtu.be/4DQsG3TKQ0I?ref=jina-ai-gmbh.ghost.io\">costruendo Skynet</a> e inviando <a href=\"https://youtu.be/wOO9DSnLOm8?ref=jina-ai-gmbh.ghost.io\">robot con accenti austriaci inspiegabili indietro nel tempo per ucciderci</a>?</p><p>Probabilmente no. I leader del settore devono ancora identificare un modo chiaro per far sì che l'AI paghi i propri conti, figuriamoci sconvolgere le industrie, e ancor meno minacciare l'umanità a un livello paragonabile al cambiamento climatico o alle armi nucleari.</p><p>I modelli di AI che abbiamo attualmente sono ben lontani dall'essere in grado di sterminare l'umanità. Faticano a disegnare le mani, non riescono a contare più di tre cose, pensano che sia <a href=\"https://www.nbcnewyork.com/news/local/nycs-ai-chatbot-was-caught-telling-businesses-to-break-the-law-the-city-isnt-taking-it-down/5287713/?ref=jina-ai-gmbh.ghost.io\">accettabile vendere formaggio rosicchiato dai topi</a>, e <a href=\"https://www.techtimes.com/articles/304222/20240502/ai-priest-demoted-saying-babies-baptized-gatorade.htm?ref=jina-ai-gmbh.ghost.io\">eseguono battesimi cattolici con il Gatorade</a>. I rischi mondani e non esistenziali dell'AI — il modo in cui la tecnologia può aiutare a disinformare, molestare, generare spam ed essere utilizzata male da persone che non ne comprendono i limiti — sono già abbastanza preoccupanti.</p><p>Ma un rischio esistenziale dell'intelligenza artificiale è sicuramente legittimo: l'AI rappresenta un pericolo chiaro e presente per... <em>l'AI</em>.</p><p>Questa preoccupazione viene solitamente chiamata \"model collapse\" ed ha ricevuto una forte dimostrazione empirica in <a href=\"https://arxiv.org/abs/2305.17493?ref=jina-ai-gmbh.ghost.io\">Shumailov et al. (2023)</a> e <a href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\">Alemohammad et al. (2023)</a>. L'idea è semplice: se addestri modelli di AI da dati generati dall'AI, e poi prendi l'AI risultante e usi il suo output per addestrare un altro modello, ripetendo il processo per più generazioni, l'AI diventerà oggettivamente sempre peggiore. È come fare una fotocopia di una fotocopia di una fotocopia.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png\" class=\"kg-image\" alt=\"Deteriorating copies of an ad for the Intertec Superbrain, taken from BYTE magazine, Sept. 1981.\" loading=\"lazy\" width=\"1200\" height=\"400\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Superbrain.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Superbrain.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Copie deteriorate di una pubblicità dell'</span><a href=\"https://en.wikipedia.org/wiki/Intertec_Superbrain?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Intertec Superbrain</span></a><span style=\"white-space: pre-wrap;\">, presa da </span><a href=\"https://archive.org/details/byte-magazine-1981-09/page/n177/mode/2up\"><span style=\"white-space: pre-wrap;\">BYTE magazine, Sept. 1981</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>Recentemente c'è stata qualche discussione sul model collapse, e stanno apparendo <a href=\"https://www.businessinsider.com/ai-training-data-source-solutions-openai-meta-google-2024-4?ref=jina-ai-gmbh.ghost.io\">titoli</a> <a href=\"https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?ref=jina-ai-gmbh.ghost.io\">sulla stampa</a> <a href=\"https://www.yahoo.com/news/ai-companies-running-training-data-220047540.html?guccounter=1&ref=jina-ai-gmbh.ghost.io\">riguardo all'AI</a> che sta <a href=\"https://www.businessinsider.com/ai-giants-openai-anthropic-running-out-of-good-training-data-2024-4?ref=jina-ai-gmbh.ghost.io\">esaurendo</a> i <a href=\"https://www.technologyreview.com/2022/11/24/1063684/we-could-run-out-of-data-to-train-ai-language-programs/?ref=jina-ai-gmbh.ghost.io\">dati</a>. Se Internet si riempirà di dati generati dall'AI, e i dati creati dall'uomo diventeranno più difficili da identificare e utilizzare, allora, prima o poi, i modelli di AI raggiungeranno un limite qualitativo.</p><p>Allo stesso tempo, c'è un crescente utilizzo di tecniche di <a href=\"https://en.wikipedia.org/wiki/Synthetic_data?ref=jina-ai-gmbh.ghost.io\">dati sintetici</a> e <a href=\"https://en.wikipedia.org/wiki/Knowledge_distillation?ref=jina-ai-gmbh.ghost.io\">model distillation</a> nello sviluppo dell'AI. Entrambe consistono nell'addestrare modelli di AI almeno in parte sull'output di altri modelli di AI. Queste due tendenze sembrano contraddirsi a vicenda.</p><p>Le cose sono un po' più complicate di così. L'AI generativa intaserà il sistema e soffocherà il proprio progresso? O l'AI ci aiuterà a creare una migliore AI? O entrambe le cose?</p><p>Cercheremo di trovare alcune risposte in questo articolo.</p><h2 id=\"model-collapse\">Model Collapse</h2><p>Per quanto apprezziamo Alemohammad et al. per aver inventato il termine \"Model Autophagy Disorder (MAD)\", \"model collapse\" è molto più accattivante e non coinvolge parole greche per l'auto-cannibalismo. La metafora del fare fotocopie di fotocopie comunica il problema in termini semplici, ma c'è qualcosa di più nella teoria sottostante.</p><p>Addestrare un modello di AI è un tipo di modellazione statistica, un'estensione di ciò che statistici e data scientist fanno da molto tempo. Ma, il primo giorno del corso di data science, si impara il motto del data scientist:</p><blockquote><strong><em>Tutti i modelli sono sbagliati</em></strong>,&nbsp;<strong><em>ma alcuni sono utili.</em></strong></blockquote><p>Questa citazione, attribuita a <a href=\"https://en.wikipedia.org/wiki/George_E._P._Box?ref=jina-ai-gmbh.ghost.io\">George Box</a>, è la luce rossa lampeggiante che dovrebbe essere sopra ogni modello di AI. Si può sempre creare un modello statistico per qualsiasi dato, e quel modello darà sempre una risposta, ma assolutamente nulla garantisce che quella risposta sia giusta o anche solo vicina alla verità.</p><p>Un modello statistico è un'<em>approssimazione</em> di qualcosa. I suoi output possono essere utili, potrebbero persino essere abbastanza buoni, ma sono comunque approssimazioni. Anche se si ha un modello ben validato che, in media, è molto accurato, può e probabilmente farà ancora grandi errori a volte.</p><p>I modelli di AI ereditano tutti i problemi della modellazione statistica. Chiunque abbia giocato con ChatGPT o qualsiasi altro grande modello di AI ha visto i suoi errori.</p><p>Quindi, se un modello di AI è un'approssimazione di qualcosa di reale, un modello di AI addestrato sull'output di un altro modello di AI è un'approssimazione di un'approssimazione. Gli errori si accumulano, e intrinsecamente deve essere un modello meno corretto rispetto al modello da cui è stato addestrato.</p><p>Alemohammad et al. dimostrano che non si può risolvere il problema aggiungendo alcuni dei dati di addestramento originali all'output dell'AI prima di addestrare il nuovo modello \"figlio\". Questo rallenta solo il model collapse, non può fermarlo. A meno che non si introducano sufficienti dati nuovi, mai visti prima, del mondo reale durante l'addestramento con l'output dell'AI, il model collapse è inevitabile.</p><p>Quanti nuovi dati siano sufficienti dipende da fattori difficili da prevedere e specifici per ogni caso, ma più dati nuovi e reali e meno dati generati dall'AI è sempre meglio del contrario.</p><p>E questo è un problema perché tutte le fonti facilmente accessibili di nuovi dati creati dall'uomo sono già esaurite mentre la quantità di dati di immagini e testi generati dall'AI là fuori sta crescendo a passi da gigante. Il rapporto tra contenuti creati dall'uomo e contenuti creati dall'AI su Internet sta diminuendo, forse rapidamente. Non esiste un <a href=\"https://www.washingtonpost.com/technology/2023/06/02/turnitin-ai-cheating-detector-accuracy/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">modo affidabile per rilevare automaticamente i dati generati dall'AI</a> e <a href=\"https://arxiv.org/abs/2303.11156?ref=jina-ai-gmbh.ghost.io\">molti ricercatori</a> <a href=\"https://www.techspot.com/news/98031-reliable-detection-ai-generated-text-impossible-new-study.html?ref=jina-ai-gmbh.ghost.io\">credono che non possa esisterne uno.</a> L'accesso pubblico ai modelli di generazione di immagini e testi AI assicura che questo problema crescerà, probabilmente in modo drammatico, e non ha una soluzione ovvia.</p><p>La <a href=\"https://www.vice.com/en/article/y3w4gw/a-shocking-amount-of-the-web-is-already-ai-translated-trash-scientists-determine?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">quantità di traduzioni automatiche su Internet</a> potrebbe significare che è già troppo tardi. Il testo tradotto automaticamente su Internet ha inquinato le nostre fonti di dati per anni, molto prima della rivoluzione dell'AI generativa. Secondo <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">Thompson, et al., 2024</a>, possibilmente metà del testo su Internet potrebbe essere tradotto da un'altra lingua, e una grandissima parte di queste traduzioni è di scarsa qualità e mostra segni di generazione automatica. Questo può distorcere un modello linguistico addestrato su tali dati.</p><p>Come esempio, di seguito è riportato uno screenshot di <a href=\"https://ww1.habsburger.net/en/chapters/hamster-buying-queuing-do-it-yourself-individual-strategies-provide-food-become?ref=jina-ai-gmbh.ghost.io\">una pagina del sito web <em>Die Welt der Habsburger</em></a> che mostra chiari segni di traduzione automatica. \"Hamster buying\" è una traduzione troppo letterale della parola tedesca <em>hamstern</em>, che significa <em>fare scorta</em> o <em>acquisti dettati dal panico</em>. Troppe istanze di questo tipo porteranno un modello AI a pensare che \"hamster buying\" sia una cosa reale in inglese e che il tedesco <em>hamstern</em> abbia qualcosa a che fare con i criceti domestici.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.07.20.png\" loading=\"lazy\" width=\"1532\" height=\"1074\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.07.20.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1532w\" sizes=\"(min-width: 720px) 720px\"></figure><p>In quasi tutti i casi, avere più output AI nei dati di addestramento è negativo. Il <em>quasi</em> è importante, e discuteremo due eccezioni qui sotto.</p><h2 id=\"synthetic-data\">Dati Sintetici</h2><p>I dati sintetici sono dati di addestramento o valutazione dell'AI che sono stati generati artificialmente invece che trovati nel mondo reale. <a href=\"https://doi.org/10.1007/978-3-030-75178-4?ref=jina-ai-gmbh.ghost.io\">Nikolenko (2021)</a> fa risalire i dati sintetici ai primi progetti di computer vision negli anni '60 e ne delinea la storia come elemento importante di quel campo.</p><p>Ci sono molte ragioni per utilizzare dati sintetici. Una delle più importanti è combattere il bias.</p><p>I modelli linguistici di grandi dimensioni e i generatori di immagini hanno ricevuto molte <a href=\"https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/?ref=jina-ai-gmbh.ghost.io\">critiche</a> <a href=\"https://www.washington.edu/news/2023/11/29/ai-image-generator-stable-diffusion-perpetuates-racial-and-gendered-stereotypes-bias/?ref=jina-ai-gmbh.ghost.io\">di alto profilo</a> <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">riguardo al bias</a>. La parola <em>bias</em> ha un significato rigoroso in statistica, ma queste critiche spesso riflettono considerazioni morali, sociali e politiche che non hanno una semplice forma matematica o soluzione ingegneristica.</p><p>Il bias che non si vede facilmente è molto più dannoso e molto più difficile da correggere. I modelli che l'AI impara a replicare sono quelli visti nei suoi dati di addestramento, e dove questi dati hanno carenze sistematiche, il bias è una conseguenza inevitabile. Più cose diverse ci aspettiamo che l'AI faccia — più diversi sono gli input al modello — più possibilità ci sono che commetta errori perché non ha mai visto abbastanza casi simili nel suo addestramento.</p><p>Il ruolo principale dei dati sintetici nell'addestramento dell'AI oggi è garantire che ci siano abbastanza esempi di certi tipi di situazioni nei dati di addestramento, situazioni che potrebbero non essere sufficientemente presenti nei dati naturali disponibili.</p><p>Di seguito è riportata un'immagine che MidJourney ha prodotto quando sollecitato con \"doctor\": quattro uomini, tre bianchi, tre in camici bianchi con stetoscopi, e uno decisamente anziano. Questo non riflette la reale razza, età, genere o abbigliamento dei veri medici nella maggior parte dei paesi e contesti, ma probabilmente riflette le immagini etichettate che si trovano su Internet.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--59-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--59-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--59-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Quando sollecitato di nuovo, ha prodotto una donna e tre uomini, tutti bianchi, anche se uno è un cartone animato. L'AI può essere strana.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--60-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--60-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--60-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Questa particolare fonte di bias è una di quelle che i generatori di immagini AI hanno cercato di prevenire, quindi non otteniamo più risultati così chiaramente distorti come forse un anno fa dagli stessi sistemi. Un bias è visibilmente ancora presente, ma non è ovvio come dovrebbe apparire un risultato privo di bias.</p><p>Tuttavia, non è difficile capire come un'AI possa acquisire questi tipi di pregiudizi. Di seguito sono riportate le prime tre immagini trovate per \"doctor\" sul sito di foto Shutterstock: Tre uomini, due più anziani e bianchi. I bias dell'AI sono i bias del suo addestramento, e se si addestrano modelli utilizzando dati non curati, si troveranno sempre questi tipi di bias.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.21.21.png\" loading=\"lazy\" width=\"1740\" height=\"860\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1740w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Un modo per mitigare questo problema è utilizzare un generatore di immagini AI per creare immagini di medici più giovani, donne medico, medici che sono persone di colore e medici che indossano camici, completi o altri indumenti, e poi includerli nell'addestramento. I dati sintetici utilizzati in questo modo possono migliorare le prestazioni del modello AI, almeno rispetto a qualche norma esterna, invece di portare al collasso del modello. Tuttavia, distorcere artificialmente le distribuzioni dei dati di addestramento può creare effetti collaterali indesiderati, <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">come Google ha recentemente scoperto</a>.</p><h2 id=\"model-distillation\">Distillazione del Modello</h2><p>La <a href=\"https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones/?ref=jina-ai-gmbh.ghost.io\">distillazione del modello</a> è una tecnica per addestrare un modello direttamente da un altro. Un modello generativo addestrato — l'\"insegnante\" — crea tanti dati quanti ne servono per addestrare un modello \"studente\" non addestrato o meno addestrato.</p><p>Come ci si aspetterebbe, il modello \"studente\" non può mai essere migliore dell'\"insegnante\". A prima vista, ha poco senso addestrare un modello in questo modo, ma ci sono dei vantaggi. Il principale è che il modello \"studente\" può essere molto più piccolo, veloce o efficiente dell'\"insegnante\", pur approssimandone da vicino le prestazioni.</p><p>La relazione tra dimensione del modello, dati di addestramento e prestazioni finali è complicata. Tuttavia, in generale, a parità di condizioni:</p><ol><li>Un modello più grande ha prestazioni migliori di uno piccolo.</li><li>Un modello addestrato con più dati o dati migliori (o almeno dati di addestramento più diversificati) ha prestazioni migliori di uno addestrato con meno dati o dati di qualità inferiore.</li></ol><p>Questo significa che un modello piccolo può, a volte, avere prestazioni pari a quelle di uno grande. Per esempio, <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>jina-embeddings-v2-base-en</code></a> supera significativamente molti modelli molto più grandi nei benchmark standard:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Size in parameters</th>\n<th>MTEB average score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>jina-embeddings-v2-base-en</code></td>\n<td>137M</td>\n<td>60.38</td>\n</tr>\n<tr>\n<td><code>multilingual-e5-base</code></td>\n<td>278M</td>\n<td>59.45</td>\n</tr>\n<tr>\n<td><code>sentence-t5-xl</code></td>\n<td>1240M</td>\n<td>57.87</td>\n</tr>\n</tbody>\n</table>\n\nLa distillazione del modello è un modo per prendere un modello grande, troppo costoso da eseguire, e utilizzarlo per creare un modello più piccolo ed economico. In ogni caso c'è una certa perdita di prestazioni, ma nei casi migliori può essere molto ridotta.\n\nDati i costi associati ai modelli di AI molto grandi, questi benefici sono piuttosto sostanziali. La distillazione produce modelli che funzionano più velocemente, su chip più economici, con meno memoria e minor consumo energetico.\n\nInoltre, i modelli grandi possono apprendere pattern sorprendentemente sottili da dati non curati, pattern che un modello più piccolo non potrebbe mai apprendere dagli stessi dati. Un modello grande può quindi produrre dati di training molto più diversificati rispetto a quelli su cui è stato addestrato, abbastanza da permettere al modello più piccolo di apprendere gli stessi pattern sottili. Una volta che si ha un grande modello addestrato, lo si può utilizzare per \"insegnare\" ciò che ha appreso a un modello più piccolo che non avrebbe mai potuto apprenderlo da solo. La distillazione è, in questi casi, talvolta un modo migliore per apprendere rispetto all'uso di dati di training reali.\n\n## Stiamo Quindi Andando Tutti All'Inferno?\n\nForse.\n\nLa buona notizia è che senza una soluzione al collasso del modello, probabilmente non saremo in grado di addestrare un'AI superintelligente capace di sterminare l'umanità, almeno non con i metodi che abbiamo usato finora. Possiamo tranquillamente tornare a preoccuparci del cambiamento climatico e della guerra nucleare.\n\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Se il paragrafo precedente suonava sarcastico, è intenzionale.</div></div>\n\nPer l'industria dell'AI, il quadro non è altrettanto ottimistico. Il motto del machine learning è stato a lungo \"<a href=\"https://towardsdatascience.com/ai-ml-practicalities-the-unreasonable-effectiveness-of-data-c0bfd44c5057?ref=jina-ai-gmbh.ghost.io\">più dati sono dati migliori</a>\". (A volte: \"Non ci sono dati come più dati\".) <a href=\"https://towardsdatascience.com/ai-ml-practicalities-more-data-isnt-always-better-ae1dac9ad28f?ref=jina-ai-gmbh.ghost.io\">Gli statistici sanno tutti che è sbagliato</a>. Il buon senso dice che è sbagliato. Ma è una strategia che ha funzionato per i ricercatori di AI per molto tempo, almeno da quando ho iniziato come ricercatore nella traduzione automatica nei primi anni 2000.\n\nCi sono ragioni per questo. I _dati diversificati_ — dati che includono molte possibilità diverse — sono una fonte di training molto migliore dei dati uniformi. E, in pratica, nel mondo reale, più dati significano solitamente dati più diversificati.\n\nMa stiamo esaurendo le nuove fonti di dati buoni e diversificati, e la creazione di nuove opere umane difficilmente terrà il passo con la generazione AI. In un modo o nell'altro, dovremo alla fine cambiare il modo in cui addestriamo i modelli AI. Altrimenti, potremmo raggiungere una soglia di prestazioni che non riusciamo più a superare. Questo trasformerebbe l'industria, poiché l'attenzione si sposterebbe dalla costruzione e dall'esecuzione di modelli più grandi e costosi allo sviluppo di framework, contesti e nicchie in cui i modelli esistenti possono portare nuovo valore aggiunto.\n\n## Come Jina AI Addestra i Suoi Modelli AI\n\nIn Jina AI, cerchiamo di portare ai nostri utenti i benefici delle migliori pratiche AI. Anche se non produciamo LLM generativi di testo o generatori di immagini AI, siamo comunque preoccupati del problema del collasso del modello. Utilizziamo sottoinsiemi del <a href=\"https://commoncrawl.org/?ref=jina-ai-gmbh.ghost.io\">Common Crawl</a> per la maggior parte del nostro pre-training e poi utilizziamo dati curati e sintetici per ottimizzare le prestazioni dei nostri modelli. Ci sforziamo di portare prestazioni all'avanguardia a modelli economicamente vantaggiosi e embedding compatti e a bassa dimensionalità.\n\nTuttavia, il collasso del modello è un problema inevitabile per i dati del Common Crawl. Prevediamo di passare nel tempo a utilizzare più dati curati e meno del Common Crawl. Ci aspettiamo che altri attori dell'industria AI facciano lo stesso. Questo avrà dei costi — sia in termini di denaro che di tasso di miglioramento della qualità — ma è troppo presto per cercare di stimarli.\n\nUtilizziamo dati sintetici in aree dove i modelli di embedding hanno problemi noti. Per esempio, i modelli AI faticano a rappresentare la negazione. \"Ricette con carne\" e \"ricette senza carne\" tipicamente hanno embedding molto vicini tra loro, ma gli utenti spesso hanno bisogno che siano molto distanti. Il nostro maggior uso di dati sintetici è la creazione di un ampio corpus di coppie di frasi generate dall'AI distinte da quel tipo di negazione (chiamata _polarità_ in AI e in alcuni tipi di linguistica), e poi utilizzarlo per migliorare i nostri modelli.\n\nPer esempio, qui sotto c'è una proiezione 2D di embedding ipotetici. \"Ricette con carne\" e \"Ricette senza carne\" sono relativamente vicine tra loro. \"Hamburger con formaggio e bacon\" è molto più vicino a \"Ricette con carne\" che a qualsiasi altra cosa, e \"Falafel\" è più vicino a \"Ricette senza carne\" che a \"Ricette con carne\". Tuttavia, \"Hamburger con formaggio e bacon\" è molto più vicino a \"Ricette senza carne\" di quanto lo sia \"Falafel\".\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png\" class=\"kg-image\" alt=\"Una proiezione 2D di embedding ipotetici.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--61-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Una proiezione 2D di embedding ipotetici.</span></figcaption></figure>\n\nGuardando solo gli embedding, potremmo concludere che gli hamburger con formaggio e bacon sono un esempio migliore di una ricetta senza carne rispetto al falafel.\n\nPer prevenire questo, addestriamo i nostri modelli con dati sintetici. Utilizziamo un LLM per generare coppie di frasi con polarità opposte – come \"X con Y\" / \"X senza Y\" – e addestriamo i nostri modelli di embedding a separare queste coppie. Utilizziamo anche dati sintetici per altri tipi di <a href=\"https://finetuner.jina.ai/advanced-topics/negative-mining/?ref=jina-ai-gmbh.ghost.io\">negative mining</a> mirato, una collezione di tecniche utilizzate per migliorare aspetti specifici delle prestazioni del modello AI presentandogli dati curati.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png\" class=\"kg-image\" alt=\"Una proiezione 2D di embedding ipotetici dopo aver migliorato il modello sottostante.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--62-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Una proiezione 2D di embedding ipotetici dopo aver migliorato il modello sottostante con coppie di frasi a polarità invertita.</span></figcaption></figure>\n\nUtilizziamo anche l'AI generativa per addestrare <a href=\"https://jina.ai/news/elevate-your-code-search-with-new-jina-code-embeddings/?ref=jina-ai-gmbh.ghost.io\">modelli di embedding per linguaggi di programmazione</a>, sfruttando grandi modelli che generano copiosi esempi di codice, in modo da poter incorporare correttamente anche caratteristiche piuttosto oscure di specifici linguaggi e framework.\n\nLa distillazione del modello è fondamentale per come produciamo <a href=\"https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny?ref=jina-ai-gmbh.ghost.io\">modelli compatti che risparmiano risorse di calcolo</a>. La distillazione è molto più efficiente e affidabile dell'addestramento da zero, e i nostri risultati mostrano che un modello distillato può ancora avere prestazioni di prima qualità. La tabella seguente mostra i modelli reranker distillati di Jina AI confrontati con il reranker base usato per addestrarli e con altri modelli con molti più parametri ma prestazioni inferiori.\n\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Model</th>\n<th>BEIR Score</th>\n<th>Parameter count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td><code>jina-reranker-v1-base-en</code></td>\n<td>52.45</td>\n<td>137M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-turbo-en</code></td>\n<td>49.60</td>\n<td>38M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-tiny-en</code></td>\n<td>48.54</td>\n<td>33M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-base-v1</code></td>\n<td>49.19</td>\n<td>184M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-xsmall-v1</code></td>\n<td>48.80</td>\n<td>71M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>bge-reranker-base</code></td>\n<td>47.89</td>\n<td>278M</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n\nSappiamo che l'AI può essere un investimento costoso e che le imprese sono sempre più consapevoli dei loro obblighi morali e legali di ridurre le emissioni di carbonio. Anche noi siamo consapevoli di queste cose. La distillazione del modello è una parte importante di come affrontiamo queste preoccupazioni.\n\n## Lascia Che Ti Aiutiamo a Navigare nell'AI\n\nJina AI si impegna a portare alle imprese soluzioni AI accessibili, efficienti e funzionanti. Possiamo integrarci con la tua infrastruttura cloud esistente su <a href=\"https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions?ref=jina-ai-gmbh.ghost.io\">Azure</a> e <a href=\"https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker?ref=jina-ai-gmbh.ghost.io\">AWS</a>. Forniamo <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">API web</a> che rispettano rigorosi standard di sicurezza e privacy e non conservano i tuoi dati per il nostro addestramento. Possiamo aiutarti a installare i nostri <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">modelli open-source</a> sul tuo hardware, mantenendo l'intera operazione in-house.\n\nPuò essere difficile separare l'hype dalla tecnologia e rimanere al passo con le migliori pratiche in questo campo in rapida evoluzione. Lascia che lo facciamo noi per te.",
  "comment_id": "6639e8e1af8f52000115be49",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-05-07T10:40:01.000+02:00",
  "updated_at": "2024-07-08T21:10:35.000+02:00",
  "published_at": "2024-05-07T16:00:26.000+02:00",
  "custom_excerpt": "AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let’s find out!",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "6342c5b4393501004d1c8b2c",
      "name": "Insights",
      "slug": "insights",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "6342c5b4393501004d1c8b2c",
    "name": "Insights",
    "slug": "insights",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/",
  "excerpt": "L'IA che crea l'IA! È la fine del mondo? O è semplicemente un altro strumento per far svolgere ai modelli un lavoro che aggiunge valore? Scopriamolo!",
  "reading_time": 12,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract depiction of a brain in purple and pink hues with a fluid, futuristic design against a blue and purple background.",
  "feature_image_caption": null
}