{
  "slug": "readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json",
  "id": "6785bfd62defad0001fb5f22",
  "uuid": "a8e2e140-18e5-49e6-aa8f-71bf4c9e3293",
  "title": "ReaderLM v2: Modello linguistico di frontiera di piccole dimensioni per HTML verso Markdown e JSON",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/ReaderLM-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/ReaderLM-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">Siamo in un viaggio per far progredire e democratizzare l'intelligenza artificiale attraverso l'open source e la scienza aperta.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-24.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/ReaderLM-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Nell'aprile 2024, abbiamo lanciato <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a>, un'API che trasforma qualsiasi pagina web in markdown compatibile con LLM semplicemente aggiungendo <code>r.jina.ai</code> come prefisso URL. Nel settembre 2024, <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown?ref=jina-ai-gmbh.ghost.io\">abbiamo lanciato due piccoli modelli linguistici, <code>reader-lm-0.5b</code> e <code>reader-lm-1.5b</code>, specificamente progettati per convertire l'HTML grezzo in markdown pulito.</a> Oggi, siamo entusiasti di presentare la seconda generazione di ReaderLM, un modello linguistico da 1,5B parametri che converte l'HTML grezzo in markdown o JSON formattato in modo impeccabile con una precisione superiore e una migliore gestione di contesti più lunghi. <code>ReaderLM-v2</code> gestisce fino a 512K token combinati tra input e output. Il modello offre supporto multilingue per 29 lingue, tra cui inglese, cinese, giapponese, coreano, francese, spagnolo, portoghese, tedesco, italiano, russo, vietnamita, thai, arabo e altre.</p><p>Grazie al suo <strong>nuovo paradigma di addestramento</strong> e ai <strong>dati di training di qualità superiore</strong>, <code>ReaderLM-v2</code> rappresenta un significativo passo avanti rispetto al suo predecessore, in particolare nella gestione di contenuti lunghi e nella generazione della sintassi markdown. Mentre la prima generazione affrontava la conversione da HTML a markdown come <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#:~:text=primarily%20needs%20to-,selective%2Dcopy,-from%20the%20input\">un compito di \"copia selettiva\"</a>, <strong>v2 lo tratta come un vero processo di traduzione.</strong> Questo cambiamento permette al modello di sfruttare magistralmente la sintassi markdown, eccellendo nella<strong> generazione di elementi complessi come blocchi di codice, liste annidate, tabelle ed equazioni LaTex.</strong></p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-.mp4\" poster=\"https://img.spacergif.org/v1/1500x1000/0a/spacer.png\" width=\"1500\" height=\"1000\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:21</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Il confronto dei risultati della conversione da HTML a markdown della prima pagina di HackerNews tra ReaderLM v2, ReaderLM 1.5b, Claude 3.5 Sonnet e Gemini 2.0 Flash rivela le caratteristiche uniche e le prestazioni di ReaderLM v2. ReaderLM v2 eccelle nel preservare informazioni complete dall'HTML grezzo, inclusi i link originali di HackerNews, strutturando intelligentemente il contenuto utilizzando la sintassi markdown. Il modello utilizza liste annidate per organizzare gli elementi locali (punti, timestamp e commenti) mantenendo una formattazione globale coerente attraverso una corretta gerarchia dei titoli (tag h1 e h2).</span></p></figcaption>\n        </figure><p>Una sfida importante nella nostra prima versione era la <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#degeneration-and-dull-loops\"><strong>degenerazione</strong></a><strong> </strong>dopo la generazione di sequenze lunghe, in particolare sotto forma di ripetizione e loop. Il modello avrebbe iniziato a ripetere lo stesso token o si sarebbe bloccato in un loop, ciclando attraverso una breve sequenza di token fino a raggiungere la lunghezza massima dell'output. <code>ReaderLM-v2</code> allevia notevolmente questo problema aggiungendo una perdita contrastiva durante l'addestramento—le sue prestazioni rimangono costanti indipendentemente dalla lunghezza del contesto o dalla quantità di token già generati.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Abbiamo testato ReaderLM v2 convertendo </span><a href=\"https://jina.ai/legal?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">la nostra pagina legale</span></a><span style=\"white-space: pre-wrap;\"> in markdown—una pagina circa 20 volte più lunga della prima pagina di HackerNews, inclusa un'estesa tabella dei subprocessori verso la fine della pagina. Nonostante questa grande sfida, ReaderLM v2 ha generato con successo la tabella completa in markdown mantenendo una struttura del documento coerente, preservando sia la gerarchia dei titoli che la formattazione delle liste anche dopo la tabella. Questo livello di prestazioni era irraggiungibile con la generazione precedente </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>reader-lm-1.5b</span></code><span style=\"white-space: pre-wrap;\">, che degenerava dopo la generazione di sequenze lunghe.</span></figcaption></figure><p>Oltre alla conversione in markdown, <code>ReaderLM-v2</code> introduce la <strong>generazione diretta da HTML a JSON</strong>, permettendo agli utenti di estrarre informazioni specifiche dall'HTML grezzo seguendo uno schema JSON dato. Questo approccio end-to-end elimina la necessità di una conversione intermedia in markdown, un requisito comune in molte pipeline di pulizia ed estrazione dati basate su LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">In questo esempio, abbiamo fornito a ReaderLM v2 l'HTML grezzo della prima pagina di HackerNews e uno schema JSON che specifica il titolo del thread, l'URL, il riassunto, le parole chiave, l'autore e il numero di commenti. Mentre alcuni campi sono direttamente disponibili nell'HTML, altri—come le parole chiave—devono essere derivati dal contenuto. ReaderLM v2 estrae e genera con notevole precisione tutti i campi.</span></figcaption></figure><p>Sia nei benchmark quantitativi che qualitativi, <code>ReaderLM-v2</code> supera modelli molto più grandi come <code>Qwen2.5-32B-Instruct</code>, <code>Gemini2-flash-expr</code> e <code>GPT-4o-2024-08-06</code> nelle attività di conversione da HTML a Markdown, mostrando prestazioni comparabili nelle attività di estrazione da HTML a JSON, il tutto utilizzando significativamente meno parametri.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ReaderLM-v2-pro</span></code><span style=\"white-space: pre-wrap;\"> è un checkpoint premium esclusivo riservato ai nostri clienti enterprise, che include addestramento e ottimizzazioni aggiuntive.</span></figcaption></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Instructed-HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2JSON.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Qualitative-Evaluation--2-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"620\"><figcaption><span style=\"white-space: pre-wrap;\">La nostra valutazione manuale ha coperto 10 diverse fonti HTML, inclusi articoli di news, post di blog, landing page di prodotti, siti di e-commerce e documenti legali in inglese, giapponese e cinese. Il corpus di test presentava elementi complessi come tabelle multi-riga, layout dinamici, tabelle collegate, formule matematiche (sia inline che display), blocchi di codice e liste profondamente annidate. La valutazione qualitativa si è concentrata su tre dimensioni chiave, con modelli valutati su una scala da 1 (più basso) a 5 (più alto). I punteggi sono stati poi normalizzati a un massimo di 1.0 per aspetto per un confronto più semplice.</span></figcaption></figure><p>Questi risultati stabiliscono che un modello da 1.5B parametri ben progettato può non solo eguagliare ma spesso superare le prestazioni di modelli molto più grandi nelle attività di estrazione di dati strutturati. I miglioramenti progressivi da <code>ReaderLM-v2</code> a <code>ReaderLM-v2-pro</code> dimostrano l'efficacia della nostra nuova strategia di addestramento nel migliorare le prestazioni del modello mantenendo l'efficienza computazionale.</p><h2 id=\"get-started\">Per Iniziare</h2><h3 id=\"via-reader-api\">Tramite Reader API</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Leggi URL e cerca sul web per un migliore grounding degli LLM.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-17.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>ReaderLM-v2</code> è ora integrato con la nostra Reader API. Per utilizzarlo, specifica semplicemente <code>x-engine: readerlm-v2</code> negli header della richiesta e abilita lo streaming delle risposte con <code>-H 'Accept: text/event-stream'</code>:</p><pre><code class=\"language-bash\">curl https://r.jina.ai/https://news.ycombinator.com/ -H 'x-engine: readerlm-v2' -H 'Accept: text/event-stream'\n</code></pre><p>Puoi provarlo senza una chiave API con un limite di velocità inferiore. <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\">Per limiti di velocità più alti</a>, puoi acquistare una chiave API. <strong>Si noti che le richieste ReaderLM-v2 consumano 3 volte il normale conteggio di token dalla tua chiave API.</strong> Questa funzionalità è attualmente in beta mentre collaboriamo con il team GCP per ottimizzare l'efficienza della GPU e aumentare la disponibilità del modello.</p><h3 id=\"on-google-colab\">Su Google Colab</h3><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1FfPjZwkMSocOLsEYH45B3B4NxDryKLGI?usp=sharing&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-22.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-6.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Nota che la GPU T4 gratuita ha delle limitazioni—non supporta </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>bfloat16</span></code><span style=\"white-space: pre-wrap;\"> o flash attention 2, portando a un maggiore utilizzo della memoria e a un'elaborazione più lenta degli input più lunghi. Tuttavia, ReaderLM v2 elabora con successo la nostra intera pagina legale con questi vincoli, raggiungendo velocità di elaborazione di 67 token/s in input e 36 token/s in output. Per l'uso in produzione, raccomandiamo una RTX 3090/4090 per prestazioni ottimali.</span></p></figcaption></figure><p>Il modo più semplice per provare <code>ReaderLM-v2</code> in un ambiente ospitato è attraverso il nostro notebook Colab, che dimostra la conversione da HTML a Markdown, l'estrazione JSON e il seguimento delle istruzioni utilizzando la prima pagina di HackerNews come esempio. Il notebook è ottimizzato per il livello gratuito GPU T4 di Colab e richiede <code>vllm</code> e <code>triton</code> per l'accelerazione e l'esecuzione. Sentiti libero di testarlo con qualsiasi sito web.</p><h4 id=\"html-to-markdown-conversion\">Conversione da HTML a Markdown</h4><p>Puoi utilizzare la funzione helper <code>create_prompt</code> per creare facilmente un prompt per convertire HTML in Markdown:</p><pre><code class=\"language-python\">prompt = create_prompt(html)\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p><code>result</code> sarà una stringa racchiusa in backtick Markdown come recinzione di codice. Puoi anche sovrascrivere le impostazioni predefinite per esplorare output diversi, per esempio:</p><pre><code class=\"language-python\">prompt = create_prompt(html, instruction=\"Extract the first three news and put into in the makdown list\")\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p>Tuttavia, poiché i nostri dati di addestramento potrebbero non coprire ogni tipo di istruzione, in particolare compiti che richiedono ragionamento in più passaggi, i risultati più affidabili provengono dalla conversione da HTML a Markdown. Per l'estrazione di informazioni più efficace, raccomandiamo di utilizzare lo schema JSON come mostrato di seguito:</p><h4 id=\"html-to-json-extraction-with-json-schema\">Estrazione da HTML a JSON con schema JSON</h4><pre><code class=\"language-python\">import json\n\nschema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"title\": {\"type\": \"string\", \"description\": \"News thread title\"},\n        \"url\": {\"type\": \"string\", \"description\": \"Thread URL\"},\n        \"summary\": {\"type\": \"string\", \"description\": \"Article summary\"},\n        \"keywords\": {\"type\": \"list\", \"description\": \"Descriptive keywords\"},\n        \"author\": {\"type\": \"string\", \"description\": \"Thread author\"},\n        \"comments\": {\"type\": \"integer\", \"description\": \"Comment count\"}\n    },\n    \"required\": [\"title\", \"url\", \"date\", \"points\", \"author\", \"comments\"]\n}\n\nprompt = create_prompt(html, schema=json.dumps(schema, indent=2))\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()\n</code></pre><p><code>result</code> sarà una stringa racchiusa in backtick formattati JSON, non un vero oggetto JSON/dict. Puoi utilizzare Python per analizzare la stringa in un dizionario o oggetto JSON appropriato per ulteriori elaborazioni.</p><h3 id=\"in-production-available-on-csp\">In Produzione: Disponibile su CSP</h3><p><code>ReaderLM-v2</code> è disponibile su AWS SageMaker, Azure e GCP marketplace. Se hai bisogno di utilizzare questi modelli al di fuori di queste piattaforme o on-premises all'interno della tua azienda, nota che questo modello e <code>ReaderLM-v2-pro</code> sono entrambi licenziati sotto CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Per richieste di utilizzo commerciale o l'accesso a <code>ReaderLM-v2-pro</code>, non esitare a contattarci.</a></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-jwfct4j4rvxk2?sr=0-21&ref_=beagle&applicationId=AWSMPContessa&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Reader-LM v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-23.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"quantitative-evaluation\">Valutazione Quantitativa</h2><p>Valutiamo ReaderLM-v2 su tre task di estrazione di dati strutturati confrontandolo con modelli allo stato dell'arte: <code>GPT-4o-2024-08-06</code>, <code>Gemini2-flash-expr</code> e <code>Qwen2.5-32B-Instruct</code>. Il nostro framework di valutazione combina metriche che misurano sia l'accuratezza del contenuto che la fedeltà strutturale. <code>ReaderLM-v2</code> è la versione pubblicamente disponibile con pesi aperti, mentre <code>ReaderLM-v2-pro</code> è un checkpoint premium esclusivo riservato ai nostri clienti enterprise, che presenta training e ottimizzazioni aggiuntive. Si noti che la nostra prima generazione <code>reader-lm-1.5b</code> è valutata solo sul task di estrazione del contenuto principale, poiché non supporta le capacità di estrazione guidata o estrazione JSON.</p><h3 id=\"evaluation-metrics\">Metriche di Valutazione</h3><p>Per i task HTML-to-Markdown, utilizziamo sette metriche complementari. Nota: ↑ indica che valori più alti sono migliori, ↓ indica che valori più bassi sono migliori</p><ul><li><strong>ROUGE-L</strong> (↑): Misura la più lunga sottosequenza comune tra il testo generato e quello di riferimento, catturando la conservazione del contenuto e la similarità strutturale. Intervallo: 0-1, valori più alti indicano una migliore corrispondenza delle sequenze.</li><li><strong>WER (Word Error Rate)</strong> (↓): Quantifica il numero minimo di modifiche a livello di parola necessarie per trasformare il testo generato in quello di riferimento. Valori più bassi indicano meno correzioni necessarie.</li><li><strong>SUB (Sostituzioni)</strong> (↓): Conta il numero di sostituzioni di parole necessarie. Valori più bassi suggeriscono una migliore accuratezza a livello di parola.</li><li><strong>INS (Inserimenti)</strong> (↓): Misura il numero di parole che devono essere inserite per corrispondere al riferimento. Valori più bassi indicano una migliore completezza.</li><li><strong>Distanza di Levenshtein</strong> (↓): Calcola il numero minimo di modifiche a singoli caratteri necessarie. Valori più bassi suggeriscono una migliore accuratezza a livello di carattere.</li><li><strong>Distanza di Damerau-Levenshtein</strong> (↓): Simile a Levenshtein ma considera anche le trasposizioni di caratteri. Valori più bassi indicano una migliore corrispondenza a livello di carattere.</li><li><strong>Similarità di Jaro-Winkler</strong> (↑): Enfatizza la corrispondenza dei caratteri all'inizio delle stringhe, particolarmente utile per valutare la conservazione della struttura del documento. Intervallo: 0-1, valori più alti indicano una migliore similarità.</li></ul><p>Per i task HTML-to-JSON, lo consideriamo come un task di recupero e adottiamo quattro metriche dal recupero di informazioni:</p><ul><li><strong>F1 Score</strong> (↑): Media armonica di precisione e richiamo, fornisce l'accuratezza complessiva. Intervallo: 0-1.</li><li><strong>Precision</strong> (↑): Proporzione di informazioni estratte correttamente tra tutte le estrazioni. Intervallo: 0-1.</li><li><strong>Recall</strong> (↑): Proporzione di informazioni estratte correttamente da tutte le informazioni disponibili. Intervallo: 0-1.</li><li><strong>Pass-Rate</strong> (↑): Proporzione di output che sono JSON validi e conformi allo schema. Intervallo: 0-1.</li></ul><h3 id=\"main-content-html-to-markdown-task\">Task HTML-to-Markdown del Contenuto Principale</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.69</td>\n<td>0.62</td>\n<td>131.06</td>\n<td>372.34</td>\n<td>0.40</td>\n<td>1341.14</td>\n<td>0.74</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td>0.41</td>\n<td><strong>88.66</strong></td>\n<td><strong>88.69</strong></td>\n<td>0.40</td>\n<td>1283.54</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.71</td>\n<td>0.47</td>\n<td>158.26</td>\n<td>123.47</td>\n<td>0.41</td>\n<td>1354.33</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>reader-lm-1.5b</td>\n<td>0.72</td>\n<td>1.14</td>\n<td>260.29</td>\n<td>1182.97</td>\n<td>0.35</td>\n<td>1733.11</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.84</td>\n<td>0.62</td>\n<td>135.28</td>\n<td>867.14</td>\n<td>0.22</td>\n<td>1262.75</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.86</strong></td>\n<td><strong>0.39</strong></td>\n<td>162.92</td>\n<td>500.44</td>\n<td><strong>0.20</strong></td>\n<td><strong>928.15</strong></td>\n<td><strong>0.83</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"instructed-html-to-markdown-task\">Task HTML-to-Markdown Guidato</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.64</td>\n<td>1.64</td>\n<td>122.64</td>\n<td>533.12</td>\n<td>0.45</td>\n<td>766.62</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td><strong>0.82</strong></td>\n<td><strong>87.53</strong></td>\n<td><strong>180.61</strong></td>\n<td>0.42</td>\n<td><strong>451.10</strong></td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.68</td>\n<td>0.73</td>\n<td>98.72</td>\n<td>177.23</td>\n<td>0.43</td>\n<td>501.50</td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.70</td>\n<td>1.28</td>\n<td>75.10</td>\n<td>443.70</td>\n<td>0.38</td>\n<td>673.62</td>\n<td><strong>0.75</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.72</strong></td>\n<td>1.48</td>\n<td><strong>70.16</strong></td>\n<td>570.38</td>\n<td><strong>0.37</strong></td>\n<td>748.10</td>\n<td><strong>0.75</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"schema-based-html-to-json-task\">Task HTML-to-JSON Basato su Schema</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>F1↑</th>\n<th>Precision↑</th>\n<th>Recall↑</th>\n<th>Pass-Rate↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.81</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td><strong>0.83</strong></td>\n<td>0.84</td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td><strong>0.83</strong></td>\n<td><strong>0.85</strong></td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.81</td>\n<td>0.98</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td>0.82</td>\n<td>0.83</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>ReaderLM-v2</code> rappresenta un significativo avanzamento in tutti i task. Per l'estrazione del contenuto principale, <code>ReaderLM-v2-pro</code> raggiunge le migliori prestazioni in cinque metriche su sette, con punteggi superiori in ROUGE-L (0.86), WER (0.39), Levenshtein (0.20), Damerau (928.15) e Jaro-Winkler (0.83). Questi risultati dimostrano miglioramenti complessivi sia nella conservazione del contenuto che nell'accuratezza strutturale rispetto sia alla versione base che ai modelli più grandi.</p><p>Nell'estrazione guidata, <code>ReaderLM-v2</code> e <code>ReaderLM-v2-pro</code> sono in testa per ROUGE-L (0.72), tasso di sostituzione (70.16), distanza di Levenshtein (0.37) e similarità di Jaro-Winkler (0.75, alla pari con la versione base). Mentre GPT-4o mostra vantaggi in WER e distanza di Damerau, <code>ReaderLM-v2-pro</code> mantiene una migliore struttura e accuratezza complessiva del contenuto. Nell'estrazione JSON, il modello si comporta in modo competitivo, rimanendo entro 0.01-0.02 punti F1 dai modelli più grandi mentre raggiunge alti tassi di successo (0.99).</p><h2 id=\"qualitative-evaluation\">Valutazione Qualitativa</h2><p>Durante la nostra analisi diCon <code>reader-lm-1.5b</code>, abbiamo osservato che <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#qualitative-study\">le metriche quantitative da sole potrebbero non catturare completamente le prestazioni del modello</a>. Le valutazioni numeriche a volte non riflettevano la qualità percepita—casi in cui punteggi metrici bassi producevano markdown visivamente soddisfacente, o punteggi alti davano risultati subottimali. Per affrontare questa discrepanza, abbiamo condotto valutazioni qualitative sistematiche su 10 diverse fonti HTML, tra cui articoli di news, post di blog, pagine di prodotti, siti di e-commerce e documenti legali in inglese, giapponese e cinese. Il corpus di test ha enfatizzato elementi di formattazione impegnativi come tabelle multi-riga, layout dinamici, formule LaTeX, tabelle collegate e liste annidate, fornendo una visione più completa delle capacità del modello nel mondo reale.</p><h3 id=\"evaluation-metrics-1\">Metriche di Valutazione</h3><p>La nostra valutazione umana si è concentrata su tre dimensioni chiave, con output valutati su una scala da 1 a 5:</p><p><strong>Integrità dei Contenuti</strong> - Valuta la preservazione delle informazioni semantiche durante la conversione da HTML a markdown, inclusi:</p><ul><li>Accuratezza e completezza del contenuto testuale</li><li>Preservazione di link, immagini, blocchi di codice, formule e citazioni</li><li>Mantenimento della formattazione del testo e degli URL di link/immagini</li></ul><p><strong>Accuratezza Strutturale</strong> - Valuta la corretta conversione degli elementi strutturali HTML in Markdown:</p><ul><li>Preservazione della gerarchia dei header</li><li>Accuratezza dell'annidamento delle liste</li><li>Fedeltà della struttura delle tabelle</li><li>Formattazione di blocchi di codice e citazioni</li></ul><p><strong>Conformità al Formato</strong> - Misura l'aderenza agli standard della sintassi Markdown:</p><ul><li>Uso corretto della sintassi per header (#), liste (*, +, -), tabelle, blocchi di codice (```)</li><li>Formattazione pulita senza spazi bianchi in eccesso o sintassi non standard</li><li>Output renderizzato coerente e leggibile</li></ul><p>Durante la valutazione manuale di oltre 10 pagine HTML, ogni criterio di valutazione ha un punteggio massimo di 50 punti. <code>ReaderLM-v2</code> ha dimostrato forti prestazioni in tutte le dimensioni:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Content Integrity</th>\n<th>Structural Accuracy</th>\n<th>Format Compliance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>reader-lm-v2</td>\n<td>39</td>\n<td>35</td>\n<td>36</td>\n</tr>\n<tr>\n<td>reader-lm-v2-pro</td>\n<td>35</td>\n<td>37</td>\n<td>37</td>\n</tr>\n<tr>\n<td>reader-lm-v1</td>\n<td>35</td>\n<td>34</td>\n<td>31</td>\n</tr>\n<tr>\n<td>Claude 3.5 Sonnet</td>\n<td>26</td>\n<td>31</td>\n<td>33</td>\n</tr>\n<tr>\n<td>gemini-2.0-flash-expr</td>\n<td>35</td>\n<td>31</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>32</td>\n<td>33</td>\n<td>34</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>38</td>\n<td>41</td>\n<td>42</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Per la completezza dei contenuti, ha eccelluto nel riconoscimento di elementi complessi, in particolare formule LaTeX, liste annidate e blocchi di codice. Il modello ha mantenuto un'alta fedeltà nella gestione di strutture di contenuto complesse mentre i modelli concorrenti spesso tralasciavano gli header H1 (<code>reader-lm-1.5b</code>), troncavano il contenuto (Claude 3.5), o mantenevano i tag HTML grezzi (Gemini-2.0-flash).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--92-.png\" width=\"2000\" height=\"1477\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--92-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--92-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--92-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--92-.png 2400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png\" width=\"2000\" height=\"1765\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--93--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--93--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--93--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png 2268w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><a href=\"https://iclr-blogposts.github.io/2024/blog/bench-hvp/?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Un post del blog ICLR</span></a><span style=\"white-space: pre-wrap;\"> con complesse equazioni LaTeX incorporate nel markdown, che mostra il codice HTML sorgente nel pannello di destra.</span></p></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--94--2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1033\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--94--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--94--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--94--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--94--2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Una vista divisa che confronta l'output Markdown di ReaderLM-v2 con la sua visualizzazione renderizzata.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"821\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Possiamo ripristinare perfettamente il contenuto originale attraverso semplici passaggi di post-elaborazione dopo ReaderLM-v2, inclusa la conversione delle equazioni LaTeX dal formato HTML al formato Markdown. Ad esempio, sostituendo </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>\\[...\\]</span></code><span style=\"white-space: pre-wrap;\"> (e i suoi equivalenti HTML) con delimitatori standard Markdown come </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>$...$</span></code><span style=\"white-space: pre-wrap;\"> per le equazioni in linea e </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>$$...$$</span></code><span style=\"white-space: pre-wrap;\"> per le equazioni visualizzate. Questo aiuta a prevenire conflitti di sintassi nell'interpretazione Markdown.</span></figcaption></figure><p>Nell'accuratezza strutturale, ReaderLM-v2 ha mostrato ottimizzazione per le strutture web comuni. Per esempio, nei casi di Hacker News, ha ricostruito con successo i link completi e ottimizzato la presentazione delle liste. Il modello ha gestito strutture HTML complesse non-blog che avevano messo in difficoltà ReaderLM-v1.</p><p>Per la conformità al formato, ReaderLM-v2 ha dimostrato particolare forza nella gestione di contenuti come Hacker News, blog e articoli WeChat. Mentre altri modelli linguistici di grandi dimensioni hanno performato bene su fonti simili a markdown, hanno faticato con siti web tradizionali che richiedevano maggiore interpretazione e riformattazione.</p><p>La nostra analisi ha rivelato che <code>gpt-4o</code> eccelle nell'elaborazione di siti web più brevi, dimostrando una comprensione superiore della struttura e della formattazione del sito rispetto ad altri modelli. Tuttavia, quando gestisce contenuti più lunghi, <code>gpt-4o</code> ha difficoltà con la completezza, spesso omettendo porzioni dall'inizio e dalla fine del testo. Abbiamo incluso un'analisi comparativa degli output di <code>gpt-4o</code>, ReaderLM-v2 e ReaderLM-v2-pro usando il sito web di Zillow come esempio.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1382\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png 2356w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">La pagina HTML originale di Zillow</span></figcaption></figure><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png\" width=\"1400\" height=\"1576\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--95-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--95-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png 1400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png\" width=\"1550\" height=\"1578\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png 1550w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png\" width=\"1562\" height=\"1582\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--97-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--97-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png 1562w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Un confronto degli output Markdown renderizzati da gpt-4o (sinistra), ReaderLM-v2 (centro) e ReaderLM-v2-pro (destra).</span></p></figcaption></figure><p>Per alcuni casi complessi come le landing page dei prodotti e i documenti governativi, le prestazioni di ReaderLM-v2 e ReaderLM-v2-pro sono rimaste robuste ma hanno ancora margini di miglioramento. Le formule matematiche complesse e il codice nei post del blog ICLR hanno posto sfide per la maggior parte dei modelli, anche se ReaderLM-v2 ha gestito questi casi meglio dell'API Reader di base.</p><h2 id=\"how-we-trained-readerlm-v2\">Come Abbiamo Addestrato ReaderLM v2</h2><p>ReaderLM-v2 è basato su <code><strong>Qwen2.5-1.5B-Instruction</strong></code>, un modello base compatto noto per la sua efficienza nel seguire le istruzioni e nei compiti con contesto lungo. In questa sezione, descriviamo come abbiamo addestrato <code>ReaderLM-v2</code>, concentrandoci sulla preparazione dei dati, i metodi di addestramento e le sfide che abbiamo incontrato.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model Parameter</th>\n<th>ReaderLM-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Parameters</td>\n<td>1.54B</td>\n</tr>\n<tr>\n<td>Max Context Length (Input+Output)</td>\n<td>512K</td>\n</tr>\n<tr>\n<td>Hidden Size</td>\n<td>1536</td>\n</tr>\n<tr>\n<td>Number of Layers</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Query Heads</td>\n<td>12</td>\n</tr>\n<tr>\n<td>KV Heads</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Head Size</td>\n<td>128</td>\n</tr>\n<tr>\n<td>Intermediate Size</td>\n<td>8960</td>\n</tr>\n<tr>\n<td>Multilingual Support</td>\n<td>29 languages</td>\n</tr>\n<tr>\n<td>HuggingFace Repository</td>\n<td>Link</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"data-preparation\">Preparazione dei Dati</h3><p>Il successo di ReaderLM-v2 dipendeva in gran parte dalla qualità dei suoi dati di addestramento. Abbiamo creato il dataset <code>html-markdown-1m</code>, che includeva un milione di documenti HTML raccolti da internet. In media, ogni documento conteneva 56.000 token, riflettendo la lunghezza e la complessità dei dati web reali. Per preparare questo dataset, abbiamo pulito i file HTML rimuovendo elementi non necessari come JavaScript e CSS, mantenendo gli elementi strutturali e semantici chiave. Dopo la pulizia, abbiamo utilizzato <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> per convertire i file HTML in Markdown utilizzando pattern regex ed euristiche.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--76-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--76-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">L'istogramma della lunghezza dei token dei file HTML nel dataset </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>html-markdown-1m</span></code></figcaption></figure><p>Mentre questo ha creato un dataset di base funzionale, ha evidenziato una limitazione critica: <strong>i modelli addestrati esclusivamente su queste conversioni dirette avrebbero essenzialmente imparato solo a imitare i pattern regex e le euristiche utilizzate da Jina Reader.</strong> Questo è diventato evidente con <code>reader-lm-0.5b/1.5b</code>, le cui prestazioni massime erano limitate dalla qualità di queste conversioni basate su regole.</p><p>Per affrontare queste limitazioni, abbiamo sviluppato una pipeline in tre fasi basata sul modello <code>Qwen2.5-32B-Instruction</code>, che è essenziale per creare un dataset sintetico di alta qualità.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--73-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--73-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Pipeline di generazione dei dati sintetici per ReaderLM-v2, alimentata da </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Qwen2.5-32B-Instruction</span></code></figcaption></figure><ol><li><strong>Bozza</strong>: Abbiamo generato output iniziali in Markdown e JSON basati sulle istruzioni fornite al modello. Questi output, sebbene diversificati, erano spesso rumorosi o inconsistenti.</li><li><strong>Raffinamento</strong>: Le bozze generate sono state migliorate rimuovendo contenuti ridondanti, imponendo coerenza strutturale e allineando con i formati desiderati. Questo passaggio ha assicurato che i dati fossero puliti e allineati con i requisiti del compito.</li><li><strong>Critica</strong>: Gli output raffinati sono stati valutati rispetto alle istruzioni originali. Solo i dati che hanno superato questa valutazione sono stati inclusi nel dataset finale. Questo approccio iterativo ha assicurato che i dati di addestramento soddisfacessero gli standard di qualità necessari per l'estrazione di dati strutturati.</li></ol><h3 id=\"training-process\">Processo di Addestramento</h3><p>Il nostro processo di addestramento ha coinvolto più fasi adattate alle sfide dell'elaborazione di documenti con contesto lungo.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--75-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--75-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">L'addestramento di ReaderLM v2 segue un processo iterativo che combina la generazione di dati in tre fasi (Bozza-Raffinamento-Critica) con il raffinamento in auto-gioco, permettendo un miglioramento continuo.</span></figcaption></figure><p>Abbiamo iniziato con il <strong>pre-addestramento per contesti lunghi</strong>, utilizzando il dataset <code>html-markdown-1m</code>. Tecniche come l'attenzione ring-zag e l'encoding posizionale rotante (RoPE) sono state utilizzate per espandere progressivamente la lunghezza del contesto del modello da 32.768 token a 256.000 token. Per mantenere stabilità ed efficienza, abbiamo adottato un approccio di addestramento graduale, iniziando con sequenze più brevi e aumentando incrementalmente la lunghezza del contesto.</p><p>Dopo il pre-addestramento, siamo passati al <strong>fine-tuning supervisionato (SFT)</strong>. Questa fase ha utilizzato i dataset raffinati generati nel processo di preparazione dei dati. Questi dataset includevano istruzioni dettagliate per i compiti di estrazione Markdown e JSON, insieme a esempi per il raffinamento delle bozze. Ogni dataset è stato attentamente progettato per aiutare il modello ad apprendere compiti specifici, come l'identificazione del contenuto principale o l'adesione a strutture JSON basate su schema.</p><p>Abbiamo poi applicato l'<strong>ottimizzazione diretta delle preferenze (DPO)</strong> per allineare gli output del modello con risultati di alta qualità. In questa fase, il modello è stato addestrato su coppie di risposte bozza e raffinate. Imparando a dare priorità agli output raffinati, il modello ha interiorizzato le sottili distinzioni che definiscono risultati rifiniti e specifici per il compito.</p><p>Infine, abbiamo implementato il <strong>tuning del rinforzo in auto-gioco</strong>, un processo iterativo dove il modello genera, raffina e valuta i propri output. Questo ciclo ha permesso al modello di migliorare continuamente senza richiedere ulteriore supervisione esterna. Sfruttando le proprie critiche e raffinamenti, il modello ha gradualmente migliorato la sua capacità di produrre output accurati e strutturati.</p><h2 id=\"conclusion\">Conclusione</h2><p>Nell'aprile 2024, Jina Reader è diventata la prima API markdown compatibile con LLM. Ha stabilito una nuova tendenza, ha ottenuto un'ampia adozione da parte della comunità e, cosa più importante, ci ha ispirato a costruire piccoli modelli linguistici per la pulizia e l'estrazione dei dati. Oggi, alziamo nuovamente l'asticella con ReaderLM-v2, mantenendo le promesse fatte lo scorso settembre: migliore gestione dei contesti lunghi, supporto per le istruzioni di input e capacità di estrarre contenuti specifici delle pagine web in formato markdown. Ancora una volta, abbiamo dimostrato che con un addestramento e una calibrazione attenti, i piccoli modelli linguistici possono raggiungere prestazioni allo stato dell'arte che superano i modelli più grandi.</p><p>Durante il processo di addestramento di ReaderLM-v2, abbiamo identificato due intuizioni. Una strategia efficace è stata l'addestramento di modelli specializzati su dataset separati adattati a compiti specifici. Questi modelli specifici per compito sono stati successivamente <em>uniti</em> utilizzando l'interpolazione lineare dei parametri. Sebbene questo approccio richiedesse uno sforzo aggiuntivo, ha aiutato a preservare i punti di forza unici di ogni modello specializzato nel sistema unificato finale.</p><p>Il processo iterativo di sintesi dei dati si è rivelato cruciale per il successo del nostro modello. Attraverso il perfezionamento e la valutazione ripetuti dei dati sintetici, abbiamo migliorato significativamente le prestazioni del modello oltre i semplici approcci basati su regole. Questa strategia iterativa, pur presentando sfide nel mantenere valutazioni critiche coerenti e nella gestione dei costi computazionali, è stata essenziale per superare i limiti dell'utilizzo di dati di training basati su regex ed euristiche da Jina Reader. Questo è chiaramente dimostrato dal divario di prestazioni tra <code>reader-lm-1.5b</code>, che si basa fortemente sulle conversioni basate su regole di Jina Reader, e <code>ReaderLM-v2</code> che beneficia di questo processo di perfezionamento iterativo.</p><p>Siamo ansiosi di ricevere il vostro feedback su come ReaderLM-v2 migliora la qualità dei vostri dati. Guardando al futuro, prevediamo di espandere le capacità multimodali, in particolare per i documenti scansionati, e di ottimizzare ulteriormente la velocità di generazione. Se siete interessati a una versione personalizzata di ReaderLM adattata al vostro dominio specifico, vi preghiamo di contattarci.</p>",
  "comment_id": "6785bfd62defad0001fb5f22",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/readerlm-v2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-01-14T02:37:26.000+01:00",
  "updated_at": "2025-01-15T11:35:18.000+01:00",
  "published_at": "2025-01-15T11:35:18.000+01:00",
  "custom_excerpt": "ReaderLM-v2 is a 1.5B small language model for HTML-to-Markdown conversion and HTML-to-JSON extraction with exceptional accuracy.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json/",
  "excerpt": "ReaderLM-v2 è un piccolo modello linguistico da 1.5B per la conversione da HTML a Markdown e l'estrazione da HTML a JSON con precisione eccezionale.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}