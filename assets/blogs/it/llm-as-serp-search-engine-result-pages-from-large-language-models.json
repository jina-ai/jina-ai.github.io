{
  "slug": "llm-as-serp-search-engine-result-pages-from-large-language-models",
  "id": "67c02c3b343c560001efca6e",
  "uuid": "ec03076e-dc8a-44ea-bd09-57c5e6a6d593",
  "title": "I risultati dei motori di ricerca generati dai Large Language Model (LLM)",
  "html": "<figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/llm-serp-demo\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">LLM as SERP</div><div class=\"kg-bookmark-description\">Large language model come pagina dei risultati di ricerca</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">LLMSERP</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-llm-serp.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">Prova la demo interattiva e scopri come appare il tuo sito in LLM SERP.</span></p></figcaption></figure><p>Da quando è stato introdotto RAG, la tendenza è stata quella di utilizzare gli LLM per migliorare la ricerca. Da Perplexity a DeepSearch e DeepResearch, l'idea di iniettare i risultati dei motori di ricerca nel processo di generazione è diventata una prassi consolidata. Molti utenti affermano anche di non utilizzare più Google con la stessa frequenza di prima, trovando il suo classico design a paginazione noioso, eccessivo o tedioso. Invece, si sono abituati all'alta precisione e al richiamo dei risultati in stile QA da un'interfaccia di ricerca simile a una chat, suggerendo che questa filosofia di design potrebbe essere la strada da seguire.</p><p><strong>Ma se l'LLM stesso <em>fosse</em> il motore di ricerca?</strong></p><p>Se potessi esplorare la conoscenza incorporata negli LLM come se stessi usando Google? Paginazione, link e tutto il resto - proprio come ai vecchi tempi che conosci bene. Se non sei sicuro di cosa intendo, dai prima un'occhiata alla demo qui sotto.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp.mp4\" poster=\"https://img.spacergif.org/v1/1426x976/0a/spacer.png\" width=\"1426\" height=\"976\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">I link, i titoli e gli snippet sono completamente generati da un LLM. Puoi visitare </span><a href=\"https://jina.ai/llm-serp-demo\"><span style=\"white-space: pre-wrap;\">https://jina.ai/llm-serp-demo</span></a><span style=\"white-space: pre-wrap;\"> e provare alcune query tu stesso!</span></p></figcaption>\n        </figure><p>Prima di sollevare preoccupazioni sulle allucinazioni, spieghiamo prima perché questa idea ha <em>un certo</em> merito: gli LLM sono addestrati su vasti archivi di conoscenza web. Modelli come DeepSeek-R1, GPT-4, Claude-3.7 e Gemini-2.0 sono stati addestrati su trilioni di token provenienti da tutto l'internet pubblico. Una stima approssimativa è che <strong>dall'1% al ~5% del testo web pubblicamente accessibile di alta qualità</strong> è stato utilizzato per addestrare i modelli principali.</p><p>Se pensi che questo numero sembri troppo piccolo, considera questo confronto: se usiamo l'indice di Google come riferimento (rappresentando il 100% dei dati accessibili agli utenti nel mondo), allora l'indice di Bing è circa il 30-50% di quello di Google. Baidu copre circa il 5-10% e Yandex copre il 3-5%. Brave Search indicizza meno dell'1%. Quindi se un LLM è addestrato sull'1-5% dei dati pubblici di alta qualità, potenzialmente equivale alla stessa quantità di dati che un decente piccolo motore di ricerca può fornire.</p><p>Dato che questi modelli hanno effettivamente \"memorizzato\" questi dati web, dobbiamo semplicemente sollecitarli in un modo che \"attivi\" la loro memoria, permettendo loro di funzionare come motori di ricerca e generare risultati simili a una pagina dei risultati di ricerca (SERP).</p><p>Quindi sì, l'allucinazione è una sfida, ma man mano che le capacità dei modelli migliorano con ogni iterazione, possiamo ragionevolmente aspettarci che questo problema si attenui. Su X, le persone sono spesso ossessionate dal generare SVG da zero ogni volta che viene rilasciato un nuovo modello, sperando che ogni versione produca illustrazioni migliori della precedente. Questa idea del motore di ricerca segue una simile speranza di miglioramento incrementale della comprensione del mondo digitale da parte dell'LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1176\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/02/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://x.com/huybery/status/1893996258760527882\"><span style=\"white-space: pre-wrap;\">Binyuan Hui </span></a><span style=\"white-space: pre-wrap;\">(uno degli sviluppatori principali dei modelli Qwen) che mostra la capacità di </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>qwen-2.5-max</span></code><span style=\"white-space: pre-wrap;\"> di disegnare un maiale SVG in one-shot.</span></figcaption></figure><p>Le date di cut-off della conoscenza presentano un'altra limitazione. I motori di ricerca dovrebbero restituire informazioni quasi in tempo reale, ma poiché i pesi degli LLM sono congelati dopo l'addestramento, non possono fornire informazioni accurate oltre la loro data di cut-off. In generale, più una query è vicina a questa data di cut-off, più è probabile che si verifichino allucinazioni. Poiché le informazioni più vecchie sono state probabilmente citate e riformulate più frequentemente, potenzialmente aumentando i loro pesi nei dati di addestramento. (Questo presuppone che le informazioni siano pesate uniformemente; le notizie dell'ultima ora potrebbero ricevere un'attenzione sproporzionata indipendentemente dalla recenza.) <strong>Tuttavia, questa limitazione definisce precisamente dove questo approccio potrebbe essere più utile—per informazioni ben all'interno del periodo di conoscenza del modello.</strong></p><h2 id=\"where-llm-as-serp-can-be-useful\">Dove LLM-as-SERP Può Essere Utile?</h2><p>In DeepSearch/RAG o in qualsiasi sistema di ricerca basato su grounding, una sfida fondamentale è determinare se una domanda necessita di informazioni esterne o può essere risposta dalle conoscenze del modello. I sistemi attuali utilizzano tipicamente un routing basato su prompt con istruzioni come:</p><pre><code>- For greetings, casual conversation, or general knowledge questions, answer directly without references.\n- For all other questions, provide a verified answer with external knowledge. Each reference must include exactQuote and url.</code></pre><p>Questo approccio fallisce in entrambe le direzioni - a volte attivando ricerche non necessarie, altre volte mancando esigenze critiche di informazioni. Specialmente con i modelli di ragionamento più recenti, spesso non è ovvio fino a metà della generazione se sono necessari dati esterni.</p><p>E se eseguissimo semplicemente la ricerca comunque? Potremmo fare una chiamata a una vera API di ricerca e un'altra a un sistema LLM-as-search. Questo elimina la decisione iniziale di routing e la sposta a valle dove abbiamo risultati effettivi da confrontare - dati recenti dalla ricerca reale, conoscenze entro il cut-off di addestramento del modello e potenzialmente alcune informazioni errate.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/Heading--41-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p>Il passaggio finale di ragionamento può quindi identificare le incongruenze e valutare le fonti in base alla loro attualità, affidabilità e consenso tra i risultati, cosa che non dobbiamo codificare esplicitamente — è già ciò in cui gli LLM eccellono. È anche possibile visitare ogni URL nei risultati di ricerca (ad esempio, con Jina Reader) per ulteriormente validare le fonti. Nelle implementazioni pratiche, questo passaggio di verifica è comunque sempre necessario; non dovresti mai affidarti esclusivamente agli estratti dei motori di ricerca, che siano motori di ricerca reali o falsi.</p><h2 id=\"conclusion\">Conclusione</h2><p>Utilizzando LLM-as-SERP, <strong>trasformiamo la questione binaria \"questo fa parte delle conoscenze del modello o no?\" in un processo più robusto di valutazione delle evidenze.</strong></p><p>Forniamo <a href=\"https://jina.ai/llm-serp-demo\" rel=\"noreferrer\">un playground</a> e anche <a href=\"https://jina.ai/api-dashiboard/llm-serp\" rel=\"noreferrer\">un endpoint API ospitato da noi</a> con cui potete sperimentare. Sentitevi anche liberi di integrarlo nelle vostre implementazioni DeepSearch/DeepResearch per vedere direttamente qualsiasi miglioramento.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/node-serp\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/node-serp: LLMs-as-SERPs</div><div class=\"kg-bookmark-description\">LLMs-as-SERPs. Contribute to jina-ai/node-serp development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-3.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/node-serp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>L'API imita un endpoint SERP completo dove è possibile definire il numero di risultati, la paginazione, il paese, la lingua ecc. Potete trovare la sua implementazione su GitHub. Siamo ansiosi di ricevere il vostro feedback su questo interessante approccio.</p>",
  "comment_id": "67c02c3b343c560001efca6e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/llmserp-banner.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-02-27T10:11:23.000+01:00",
  "updated_at": "2025-02-27T13:38:43.000+01:00",
  "published_at": "2025-02-27T13:36:57.000+01:00",
  "custom_excerpt": "This is either an extremely smart idea or an extremely stupid one—there's no in-between.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/llm-as-serp-search-engine-result-pages-from-large-language-models/",
  "excerpt": "Questa è o un'idea estremamente intelligente o un'idea estremamente stupida—non ci sono vie di mezzo.",
  "reading_time": 5,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}