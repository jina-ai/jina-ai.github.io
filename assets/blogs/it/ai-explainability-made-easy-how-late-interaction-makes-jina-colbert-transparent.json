{
  "slug": "ai-explainability-made-easy-how-late-interaction-makes-jina-colbert-transparent",
  "id": "6672af263ce1950001eed6a7",
  "uuid": "44371108-082d-4fb0-a28d-4f86fc02ac14",
  "title": "L'Interpretabilità dell'IA Resa Semplice: Come la Late Interaction Rende Jina-ColBERT Trasparente",
  "html": "<p>Uno dei problemi di lunga data dei modelli di AI è che le reti neurali non spiegano come producono i loro output. Non è sempre chiaro quanto questo sia un vero problema per l'intelligenza artificiale. Quando chiediamo agli umani di spiegare il loro ragionamento, essi di routine razionalizzano, tipicamente del tutto inconsapevoli di farlo, fornendo spiegazioni plausibili per le loro azioni senza alcuna indicazione di ciò che realmente accade nelle loro menti.</p><p>Sappiamo già come far produrre ai modelli di AI risposte plausibili. Forse l'intelligenza artificiale è più simile agli umani in questo senso di quanto vorremmo ammettere.</p><p>Cinquant'anni fa, il filosofo americano Thomas Nagel scrisse un influente saggio intitolato <em>Che Effetto Fa Essere un Pipistrello?</em> Egli sosteneva che deve esserci qualcosa che si prova ad essere un pipistrello: vedere il mondo come lo vede un pipistrello e percepire l'esistenza come fa un pipistrello. Tuttavia, secondo Nagel, anche se conoscessimo ogni fatto conoscibile su come funzionano il cervello, i sensi e il corpo di un pipistrello, non sapremmo ancora che effetto fa essere un pipistrello.</p><p>La spiegabilità dell'AI è lo stesso tipo di problema. Conosciamo ogni fatto c'è da sapere su un determinato modello di AI. È solo una grande quantità di numeri a precisione finita organizzati in una sequenza di matrici. Possiamo verificare facilmente che ogni output del modello è il risultato di calcoli corretti, ma questa informazione è inutile come spiegazione.</p><p>Non c'è una soluzione generale a questo problema per l'AI più di quanto non ci sia per gli umani. Tuttavia, l'architettura ColBERT, e in particolare il modo in cui usa la \"late interaction\" quando viene utilizzata come reranker, ti permette di ottenere intuizioni significative dai tuoi modelli sul perché fornisce risultati specifici in casi particolari.</p><p>Questo articolo ti mostra come la late interaction permette la spiegabilità, usando il modello Jina-ColBERT <a href=\"https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io\"><code>jina-colbert-v1-en</code></a> e la <a href=\"https://matplotlib.org/?ref=jina-ai-gmbh.ghost.io\">libreria Python Matplotlib</a>.</p><h2 id=\"a-brief-overview-of-colbert\">Una Breve Panoramica di ColBERT</h2><p>ColBERT è stato introdotto in <a href=\"https://doi.org/10.1145/3397271.3401075?ref=jina-ai-gmbh.ghost.io\">Khattab & Zaharia (2020)</a> come un'estensione del <a href=\"https://doi.org/10.18653/v1/N19-1423?ref=jina-ai-gmbh.ghost.io\">modello BERT introdotto nel 2018</a> da Google. I modelli <a href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\">Jina-ColBERT di Jina AI</a> si basano su questo lavoro e sulla successiva architettura ColBERT v2 proposta in <a href=\"https://arxiv.org/abs/2112.01488?ref=jina-ai-gmbh.ghost.io\">Santhanam, et al. (2021)</a>. I modelli di tipo ColBERT possono essere usati per creare embedding, ma hanno alcune funzionalità aggiuntive quando usati come modello di reranking. Il principale beneficio è la <em>late interaction</em>, che è un modo di strutturare il problema della similarità semantica del testo diversamente dai modelli di embedding standard.</p><h3 id=\"embedding-models\">Modelli di Embedding</h3><p>In un modello di embedding tradizionale, confrontiamo due testi generando vettori rappresentativi per essi chiamati <em>embedding</em>, e poi confrontiamo questi embedding attraverso metriche di distanza come la distanza coseno o di Hamming. La quantificazione della similarità semantica di due testi segue generalmente una procedura comune.</p><p>Prima, creiamo embedding per i due testi separatamente. Per ogni singolo testo:</p><ol><li>Un tokenizer divide il testo in chunk approssimativamente delle dimensioni di una parola.</li><li>Ogni token viene mappato su un vettore.</li><li>I vettori dei token interagiscono attraverso il sistema di attention e i layer convoluzionali, aggiungendo informazioni contestuali alla rappresentazione di ciascun token.</li><li>Un layer di pooling trasforma questi vettori di token modificati in un singolo vettore di embedding.</li></ol><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings_pooling_dark_small-1.png\" class=\"kg-image\" alt=\"Diagram of text classification model with convolutional, attention, pooling layers, and text tokens on a black background.\" loading=\"lazy\" width=\"550\" height=\"900\"><figcaption><span style=\"white-space: pre-wrap;\">Un modello di embedding schematizzato che crea un singolo embedding per un testo.</span></figcaption></figure><p>Poi, quando c'è un embedding per ciascun testo, li confrontiamo l'uno con l'altro, tipicamente usando la metrica del coseno o la distanza di Hamming.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings2_simpler_dark_small.png\" class=\"kg-image\" alt=\"Flowchart describing a text similarity calculation process with tokenization, embedding models, and scoring.\" loading=\"lazy\" width=\"775\" height=\"825\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Embeddings2_simpler_dark_small.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings2_simpler_dark_small.png 775w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">In un modello di embedding convenzionale, i documenti vengono confrontati confrontando direttamente i loro embedding.</span></figcaption></figure><p>Il punteggio viene calcolato confrontando i due embedding completi tra loro, senza alcuna informazione specifica sui token. Tutta l'interazione tra i token è \"precoce\" poiché avviene prima che i due testi vengano confrontati tra loro.</p><h3 id=\"reranking-models\">Modelli di Reranking</h3><p>I modelli di reranking funzionano diversamente.</p><p>Prima, invece di creare un embedding per qualsiasi testo, prende un testo, chiamato <em>query</em>, e una collezione di altri testi che chiameremo <em>documenti target</em> e poi assegna un punteggio a ciascun documento target rispetto al testo della query. Questi numeri non sono normalizzati e non sono come il confronto di embedding, ma sono ordinabili. I documenti target che ottengono il punteggio più alto rispetto alla query sono i testi che sono semanticamente più correlati alla query secondo il modello.</p><p>Vediamo come funziona concretamente con il modello reranker <code>jina-colbert-v1-en</code>, usando la Jina Reranker API e Python.</p><p>Il codice seguente è anche in un notebook che puoi <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\">scaricare</a> o <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\">eseguire in Google Colab</a>.</p><p>Dovresti prima installare la versione più recente della libreria <code>requests</code> nel tuo ambiente Python. Puoi farlo con il seguente comando:</p><pre><code class=\"language-bash\">pip install requests -U\n</code></pre><p>Successivamente, visita la <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">pagina della Jina Reranker API</a> e ottieni un token API gratuito, valido fino a un milione di token di elaborazione del testo. Copia la chiave del token API dal fondo della pagina, come mostrato di seguito:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/jina_reranker_api.png\" class=\"kg-image\" alt=\"Screenshot of Reranker API's interface with explanatory text and red-highlighted code segment for search optimization.\" loading=\"lazy\" width=\"1650\" height=\"1800\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/jina_reranker_api.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/jina_reranker_api.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/jina_reranker_api.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/jina_reranker_api.png 1650w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Come ottenere la tua chiave API personale dalla pagina della Jina Reranker API.</span></figcaption></figure><p>Useremo il seguente testo di query:</p><ul><li>\"Elephants eat 150 kg of food per day.\"</li></ul><p>E confronteremo questa query con tre testi:</p><ul><li>\"Elephants eat 150 kg of food per day.\"</li><li>\"Every day, the average elephant consumes roughly 150 kg of plants.\"</li><li>\"The rain in Spain falls mainly on the plain.\"</li></ul><p>Il primo documento è identico alla query, il secondo è una riformulazione del primo, e l'ultimo testo è completamente non correlato.</p><p>Usa il seguente codice Python per ottenere i punteggi, assegnando il tuo token API Jina Reranker alla variabile <code>jina_api_key</code>:</p><pre><code class=\"language-Python\">import requests\n\nurl = \"&lt;https://api.jina.ai/v1/rerank&gt;\"\njina_api_key = \"&lt;YOUR JINA RERANKER API TOKEN HERE&gt;\"\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {jina_api_key}\"\n}\ndata = {\n    \"model\": \"jina-colbert-v1-en\",\n    \"query\": \"Elephants eat 150 kg of food per day.\",\n    \"documents\": [\n        \"Elephants eat 150 kg of food per day.\",\n        \"Every day, the average elephant consumes roughly 150 kg of food.\",\n        \"The rain in Spain falls mainly on the plain.\",\n    ],\n    \"top_n\": 3\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nfor item in response.json()['results']:\n    print(f\"{item['relevance_score']} : {item['document']['text']}\")\n</code></pre><p>Eseguire questo codice da un file Python o in un notebook dovrebbe produrre il seguente risultato:</p><pre><code class=\"language-Text\">11.15625 : Elephants eat 150 kg of food per day.\n9.6328125 : Every day, the average elephant consumes roughly 150 kg of food.\n1.568359375 : The rain in Spain falls mainly on the plain.\n</code></pre><p>La corrispondenza esatta ha il punteggio più alto, come ci aspetteremmo, mentre la riformulazione ha il secondo punteggio più alto, e un testo completamente non correlato ha un punteggio molto più basso.</p><h3 id=\"scoring-using-colbert\">Punteggio usando ColBERT</h3><p>Ciò che rende il reranking ColBERT diverso dal punteggio basato su embedding è che i token dei due testi vengono confrontati tra loro durante il processo di assegnazione del punteggio. I due testi non hanno mai i propri embedding.</p><p>Prima, usiamo la stessa architettura dei modelli di embedding per creare nuove rappresentazioni per ogni token che includono informazioni contestuali dal testo. Poi, confrontiamo ogni token dalla query con ogni token dal documento.</p><p>Per ogni token nella query, identifichiamo il token nel documento che ha l'interazione più forte con esso, e sommiamo questi punteggi di interazione per calcolare un valore numerico finale.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/ColBERT_dual_dark_small.png\" class=\"kg-image\" alt=\"Detailed diagram showing computational model with tokens, scored and categorized into &quot;Early&quot; and &quot;Late&quot; interactions.\" loading=\"lazy\" width=\"1325\" height=\"1200\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/ColBERT_dual_dark_small.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/ColBERT_dual_dark_small.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/ColBERT_dual_dark_small.png 1325w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Questa interazione è \"tardiva\": i token interagiscono tra i due testi quando li confrontiamo tra loro. Ma ricorda, l'interazione \"tardiva\" non esclude l'interazione \"precoce\". Le coppie di vettori di token che vengono confrontate contengono già informazioni sui loro contesti specifici.</p><p>Questo schema di interazione tardiva preserva le informazioni a livello di token, anche se queste informazioni sono specifiche del contesto. Ciò ci permette di vedere, in parte, come il modello ColBERT calcola il suo punteggio perché possiamo identificare quali coppie di token contestualizzati contribuiscono al punteggio finale.</p><h2 id=\"explaining-rankings-with-heat-maps\">Spiegare i Ranking con le Mappe di Calore</h2><p>Le mappe di calore sono una tecnica di visualizzazione utile per vedere cosa succede in Jina-ColBERT quando crea i punteggi. In questa sezione, useremo le librerie <a href=\"https://seaborn.pydata.org/?ref=jina-ai-gmbh.ghost.io\"><code>seaborn</code></a> e <a href=\"https://matplotlib.org/?ref=jina-ai-gmbh.ghost.io\"><code>matplotlib</code></a> per creare mappe di calore dallo strato di interazione tardiva di <a href=\"https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io\"><code>jina-colbert-v1-en</code></a>, mostrando come i token della query interagiscono con i token del testo di destinazione.</p><h3 id=\"set-up\">Configurazione</h3><p>Abbiamo creato un file di libreria Python contenente il codice per accedere al modello <code>jina-colbert-v1-en</code> e utilizzare <code>seaborn</code>, <code>matplotlib</code> e <code>Pillow</code> per creare mappe di calore. Puoi <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">scaricare questa libreria direttamente da GitHub</a>, o <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">utilizzare il notebook fornito</a> sul tuo sistema, oppure su <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>.</p><p>Prima, installa i requisiti. Avrai bisogno dell'ultima versione della libreria <code>requests</code> nel tuo ambiente Python. Quindi, se non l'hai già fatto, esegui:</p><pre><code class=\"language-bash\">pip install requests -U \n</code></pre><p>Poi, installa le librerie principali:</p><pre><code class=\"language-bash\">pip install matplotlib seaborn torch Pillow\n</code></pre><p>Successivamente, scarica <code>jina_colbert_heatmaps.py</code> da GitHub. Puoi farlo <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">tramite browser web</a> o dalla riga di comando se <code>wget</code> è installato:</p><pre><code class=\"language-bash\">wget https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py\n</code></pre><p>Con le librerie installate, dobbiamo solo dichiarare una funzione per il resto di questo articolo:</p><pre><code class=\"language-Python\">from jina_colbert_heatmaps import JinaColbertHeatmapMaker\n\ndef create_heatmap(query, document, figsize=None):\n    heat_map_maker = JinaColbertHeatmapMaker(jina_api_key=jina_api_key)\n    # get token embeddings for the query\n    query_emb = heat_map_maker.embed(query, is_query=True)\n    # get token embeddings for the target document\n    document_emb = heat_map_maker.embed(document, is_query=False)\n    return heat_map_maker.compute_heatmap(document_emb[0], query_emb[0], figsize)\n</code></pre><h3 id=\"results\">Risultati</h3><p>Ora che possiamo creare mappe di calore, creiamone alcune e vediamo cosa ci dicono.</p><p>Esegui il seguente comando in Python:</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Elephants eat 150 kg of food per day.\")</code></pre><p>Il risultato sarà una mappa di calore che assomiglia a questa:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--68-.png\" class=\"kg-image\" alt=\"Heatmap visualizing relationships between phrases like &quot;elephants eat 150 kg of food per day&quot; with color gradients indicating\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--68-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--68-.png 640w\"></figure><p>Questa è una mappa di calore dei livelli di attivazione tra coppie di token quando confrontiamo due testi identici. Ogni quadrato mostra l'interazione tra due token, uno da ciascun testo. I token aggiuntivi <code>[CLS]</code> e <code>[SEP]</code> indicano rispettivamente l'inizio e la fine del testo, e <code>q</code> e <code>d</code> vengono inseriti subito dopo il token <code>[CLS]</code> nelle query e nei documenti target rispettivamente. Questo permette al modello di tenere conto delle interazioni tra i token e l'inizio e la fine dei testi, ma permette anche alle rappresentazioni dei token di essere sensibili al fatto che si trovino in query o in target.</p><p>Più luminoso è il quadrato, maggiore è l'interazione tra i due token, il che indica una relazione semantica. Il punteggio di interazione di ogni coppia di token è nell'intervallo da -1.0 a 1.0. I quadrati evidenziati da una cornice rossa sono quelli che contano per il punteggio finale: Per ogni token nella query, il suo livello di interazione più alto con qualsiasi token del documento è il valore che conta.</p><p>I migliori match — i punti più luminosi — e i valori massimi incorniciati in rosso sono quasi tutti esattamente sulla diagonale e hanno un'interazione molto forte. Le uniche eccezioni sono i token \"tecnici\" <code>[CLS]</code>, <code>q</code>, e <code>d</code>, oltre alla parola \"of\" che è una \"stop word\" ad alta frequenza in inglese che porta pochissime informazioni indipendenti.</p><p>Prendiamo una frase strutturalmente simile — \"Cats eat 50 g of food per day.\" — e vediamo come interagiscono i token:</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Cats eat 50 g of food per day.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/download.png\" class=\"kg-image\" alt=\"Heatmap visualizing the relevance of keywords like &quot;elephants&quot;, &quot;food&quot;, and &quot;kg&quot; with varying intensity colors, indicating da\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/download.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/download.png 640w\"></figure><p>Ancora una volta, i migliori match sono principalmente sulla diagonale perché le parole sono spesso le stesse e la struttura della frase è quasi identica. Anche \"cats\" e \"elephants\" corrispondono, a causa dei loro contesti comuni, anche se non molto bene.</p><p>Meno simile è il contesto, peggiore è il match. Consideriamo il testo \"Employees eat at the company canteen.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Employees eat at the company canteen.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--69-.png\" class=\"kg-image\" alt=\"Heatmap visualization showing word correlations from news articles, including topics like food, elephants, and work environme\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--69-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--69-.png 640w\"></figure><p>Sebbene strutturalmente simili, l'unica corrispondenza forte qui è tra le due istanze di \"eat\". A livello tematico, queste sono frasi molto diverse, anche se le loro strutture sono altamente parallele.</p><p>Guardando l'oscurità dei colori nei quadrati incorniciati in rosso, possiamo vedere come il modello li classificherebbe come match per \"Elephants eat 150 kg of food per day\", e <code>jina-colbert-v1-en</code> conferma questa intuizione:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Score</th>\n<th>Text</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>11.15625</td>\n<td>Elephants eat 150 kg of food per day.</td>\n</tr>\n<tr>\n<td>8.3671875</td>\n<td>Cats eat 50 g of food per day.</td>\n</tr>\n<tr>\n<td>3.734375</td>\n<td>Employees eat at the company canteen.</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Ora, confrontiamo \"Elephants eat 150 kg of food per day.\" con una frase che ha essenzialmente lo stesso significato ma una formulazione diversa: \"Every day, the average elephant consumes roughly 150 kg of food.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Every day, the average elephant consumes roughly 150 kg of food.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--70-.png\" class=\"kg-image\" alt=\"Colorful heatmap visualizing the relationship between elephant consumption metrics and other variables.\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--70-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--70-.png 640w\"></figure><p>Nota l'intensa interazione tra \"eat\" nella prima frase e \"consume\" nella seconda. La differenza nel vocabolario non impedisce a Jina-ColBERT di riconoscere il significato comune.</p><p>Inoltre, \"every day\" corrisponde fortemente a \"per day\", anche se si trovano in posizioni completamente diverse. Solo la parola di basso valore \"of\" risulta essere un'anomala non corrispondenza.</p><p>Ora, confrontiamo la stessa query con un testo totalmente non correlato: \"The rain in Spain falls mainly on the plain.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"The rain in Spain falls mainly on the plain.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/download-1.png\" class=\"kg-image\" alt=\"Heatmap Seaborn che visualizza le frequenze delle discussioni sui topic nei mesi, ombreggiato dal rosso al blu scuro.\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/download-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/download-1.png 640w\"></figure><p>Si può notare che le interazioni \"migliori corrispondenze\" hanno punteggi molto più bassi per questa coppia, e c'è pochissima interazione tra le parole dei due testi. Intuitivamente, ci aspetteremmo un punteggio basso rispetto a \"Every day, the average elephant consumes roughly 150 kg of food\", e <code>jina-colbert-v1-en</code> concorda:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Score</th>\n<th>Text</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>9.6328125</td>\n<td>Every day, the average elephant consumes roughly 150 kg of food.</td>\n</tr>\n<tr>\n<td>1.568359375</td>\n<td>The rain in Spain falls mainly on the plain.</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"long-texts\">Testi Lunghi</h3><p>Questi sono esempi semplificati per dimostrare il funzionamento dei modelli di reranking stile ColBERT. Nei contesti di information retrieval, come la generazione aumentata tramite retrieval, le query tendono ad essere testi brevi mentre i documenti candidati tendono ad essere più lunghi, spesso quanto la finestra di contesto di input del modello.</p><p>I modelli Jina-ColBERT supportano tutti contesti di input di 8192 token, equivalenti a circa 16 pagine standard di testo con interlinea singola.</p><p>Possiamo generare mappe di calore anche per questi casi asimmetrici. Per esempio, prendiamo la prima sezione della <a href=\"https://en.wikipedia.org/wiki/Indian_elephant?ref=jina-ai-gmbh.ghost.io\">pagina Wikipedia sugli Elefanti Indiani</a>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png\" class=\"kg-image\" alt=\"Screenshot della pagina Wikipedia sugli elefanti indiani, con articoli, tre immagini di elefanti e stato di conservazione.\" loading=\"lazy\" width=\"2000\" height=\"1870\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 2188w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Per vedere questo come testo semplice, come passato a <code>jina-colbert-v1-en</code>, clicca <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/docs-heatmaps/notebooks/heatmaps/wikipedia_indian_elephant.txt?ref=jina-ai-gmbh.ghost.io\">questo link</a>.</p><p>Questo testo è lungo 364 parole, quindi la nostra mappa di calore non apparirà molto quadrata:</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", wikipedia_elephants, figsize=(50,7))</code></pre><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--71--2.png\" class=\"kg-image\" alt=\"Heatmap grafica che mostra dati genetici, con punti rossi e arancioni che indicano vari livelli di espressione attraverso le coppie di basi\" loading=\"lazy\" width=\"2000\" height=\"378\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--71--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Untitled--71--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Untitled--71--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/06/Untitled--71--2.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Vediamo che \"elephants\" corrisponde a molti punti nel testo. Questo non sorprende in un testo sugli elefanti. Ma possiamo anche vedere un'area dove c'è un'interazione molto più forte:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--72--1.png\" class=\"kg-image\" alt=\"Heatmap genomica con pattern rossi e neri, asse etichettato 'XNTY', e regioni evidenziate che indicano punti dati.\" loading=\"lazy\" width=\"2000\" height=\"443\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--72--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Untitled--72--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Untitled--72--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/06/Untitled--72--1.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Cosa sta succedendo qui? Con Jina-ColBERT, possiamo trovare la parte del testo più lungo che corrisponde a questo. Si scopre che è la quarta frase del secondo paragrafo:</p><blockquote>The species is classified as a megaherbivore and consume up to 150 kg (330 lb) of plant matter per day.</blockquote><p>Questa riafferma la stessa informazione presente nel testo della query. Se guardiamo la mappa di calore solo per questa frase possiamo vedere le forti corrispondenze:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--74-.png\" class=\"kg-image\" alt=\"Heatmap che mostra la co-occorrenza di parole con focus su &quot;elephants&quot;, &quot;food&quot; e &quot;day&quot;, con l'intensità del colore che indica la forza\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--74-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--74-.png 640w\"></figure><p>Jina-ColBERT ti fornisce i mezzi per vedere esattamente quali aree in un testo lungo hanno causato la corrispondenza con la query. Questo porta a un migliore debugging, ma anche a una maggiore spiegabilità. Non serve alcuna sofisticazione per vedere come viene fatta una corrispondenza.</p><h2 id=\"explaining-ai-outcomes-with-jina-colbert\">Spiegare i risultati dell'AI con Jina-ColBERT</h2><p>Gli embedding sono una tecnologia fondamentale nell'AI moderna. Quasi tutto ciò che facciamo si basa sull'idea che relazioni complesse e apprendibili nei dati di input possano essere espresse nella geometria di spazi ad alte dimensioni. Tuttavia, è molto difficile per i semplici umani dare un senso alle relazioni spaziali in migliaia o milioni di dimensioni.</p><p>ColBERT è un passo indietro da quel livello di astrazione. Non è una risposta completa al problema di spiegare cosa fa un modello di AI, ma ci indica direttamente quali parti dei nostri dati sono responsabili dei nostri risultati.</p><p>A volte, l'AI deve essere una scatola nera. Le matrici giganti che fanno tutto il lavoro pesante sono troppo grandi perché un umano le tenga a mente. Ma l'architettura ColBERT getta un po' di luce nella scatola e dimostra che è possibile fare di più.</p><p>Il modello Jina-ColBERT è attualmente disponibile solo per l'inglese (<code>jina-colbert-v1-en</code>) ma altre lingue e contesti d'uso sono in arrivo. Questa linea di modelli, che non solo esegue information retrieval allo stato dell'arte ma può anche dirti perché ha trovato una corrispondenza, dimostra l'impegno di Jina AI nel rendere le tecnologie AI sia accessibili che utili.</p>",
  "comment_id": "6672af263ce1950001eed6a7",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/06/Search-acc--3-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-06-19T12:12:54.000+02:00",
  "updated_at": "2024-07-08T21:08:21.000+02:00",
  "published_at": "2024-06-19T16:01:36.000+02:00",
  "custom_excerpt": "AI explainability and transparency are hot topics. How can we trust AI if we can't see how it works? Jina-ColBERT shows you how, with the right model architecture, you can easily make your AI spill its secrets.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "6360e8495e0f6e004d70bd9e",
      "name": "Maximilian Werk",
      "slug": "maximilian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/Profile-Picture.jpg",
      "cover_image": null,
      "bio": "I love bringing business value with ML powered solutions as well as broad strategic and deep technical discussions. I also care a lot about our company culture and enjoy pair programming.",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/maximilian/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "6360e8495e0f6e004d70bd9e",
    "name": "Maximilian Werk",
    "slug": "maximilian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/Profile-Picture.jpg",
    "cover_image": null,
    "bio": "I love bringing business value with ML powered solutions as well as broad strategic and deep technical discussions. I also care a lot about our company culture and enjoy pair programming.",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/maximilian/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/ai-explainability-made-easy-how-late-interaction-makes-jina-colbert-transparent/",
  "excerpt": "L'esplicabilità e la trasparenza dell'IA sono argomenti molto attuali. Come possiamo fidarci dell'IA se non possiamo vedere come funziona? Jina-ColBERT dimostra come, con la giusta architettura del modello, si possa facilmente far rivelare all'IA i suoi segreti.",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Digital representation of a golden building seen through a blue and yellow mesh pattern, evoking a technological vibe.",
  "feature_image_caption": null
}