{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3: Un Modello di Embedding Multilingue all'Avanguardia",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">Siamo in un viaggio per far progredire e democratizzare l'intelligenza artificiale attraverso l'open source e la scienza aperta.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3: Embedding Multilingue con Task LoRA</div><div class=\"kg-bookmark-description\">Presentiamo jina-embeddings-v3, un nuovo modello di embedding testuale con 570 milioni di parametri, che raggiunge prestazioni allo stato dell'arte su dati multilingue e task di recupero con contesto lungo, supportando lunghezze di contesto fino a 8192 token. Il modello include un set di adattatori Low-Rank Adaptation (LoRA) specifici per task per generare embedding di alta qualità per il recupero query-documento, clustering, classificazione e matching testuale. Inoltre, il Matryoshka Representation Learning è integrato nel processo di training, permettendo un troncamento flessibile delle dimensioni dell'embedding senza compromettere le prestazioni. La valutazione sul benchmark MTEB mostra che jina-embeddings-v3 supera gli ultimi embedding proprietari di OpenAI e Cohere sui task in inglese, raggiungendo prestazioni superiori rispetto a multilingual-e5-large-instruct in tutti i task multilingue.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Oggi siamo entusiasti di annunciare <code>jina-embeddings-v3</code>, un modello di embedding testuale all'avanguardia con 570 milioni di parametri. Raggiunge prestazioni allo stato dell'arte su dati <strong>multilingue</strong> e task di recupero con <strong>contesto lungo</strong>, supportando una lunghezza di input fino a 8192 token. Il modello presenta adattatori Low-Rank Adaptation (LoRA) specifici per task, permettendogli di generare embedding di alta qualità per vari task tra cui <strong>recupero query-documento</strong>, <strong>clustering</strong>, <strong>classificazione</strong> e <strong>matching testuale</strong>.</p><p>Nelle valutazioni su MTEB English, Multilingual e LongEmbed, <code>jina-embeddings-v3</code> supera gli ultimi embedding proprietari di OpenAI e Cohere sui task in inglese, superando anche <code>multilingual-e5-large-instruct</code> in tutti i task multilingue. Con una dimensione di output predefinita di 1024, gli utenti possono troncare arbitrariamente le dimensioni dell'embedding fino a 32 senza sacrificare le prestazioni, grazie all'integrazione del Matryoshka Representation Learning (MRL).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\">Le prestazioni di </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> rispetto ad altri modelli di embedding su tutti i task MTEB in inglese. I risultati completi della valutazione per ogni task si possono trovare nel nostro </span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">paper su arXiv</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">Le prestazioni di </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> sono state valutate su un'ampia selezione di task MTEB multilingue e cross-linguistici. Si noti che </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2-(zh/es/de)</span></code><span style=\"white-space: pre-wrap;\"> si riferisce alla nostra suite di modelli bilingue, che è stata testata solo su task monolingue e cross-linguistici in cinese, spagnolo e tedesco, escludendo tutte le altre lingue. Inoltre, non riportiamo i punteggi per </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>openai-text-embedding-3-large</span></code><span style=\"white-space: pre-wrap;\"> e </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>cohere-embed-multilingual-v3.0</span></code><span style=\"white-space: pre-wrap;\">, poiché questi modelli non sono stati valutati sull'intera gamma di task MTEB multilingue e cross-linguistici.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">Le prestazioni di </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> su sei task di recupero di documenti lunghi dal benchmark LongEmbed mostrano un miglioramento significativo rispetto ad altri modelli. I punteggi sono nDCG@10; più alto è meglio. Questo suggerisce l'efficacia dei nostri embedding posizionali basati su RoPE, che superano sia gli embedding posizionali fissi utilizzati da </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>baai-bge-m3</span></code><span style=\"white-space: pre-wrap;\"> sia l'approccio basato su ALiBi utilizzato in </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>Dal suo rilascio il 18 settembre 2024, <code>jina-embeddings-v3</code> è <strong>il migliore</strong> modello multilingue e si classifica al <strong>2° posto</strong> nella classifica MTEB English per modelli con meno di 1 miliardo di parametri. v3 supporta in totale 89 lingue, incluse 30 lingue con le migliori prestazioni: arabo, bengalese, cinese, danese, olandese, inglese, finlandese, francese, georgiano, tedesco, greco, hindi, indonesiano, italiano, giapponese, coreano, lettone, norvegese, polacco, portoghese, rumeno, russo, slovacco, spagnolo, svedese, thai, turco, ucraino, urdu e vietnamita.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Dal suo rilascio il 18 settembre 2024, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\">, con 570 milioni di parametri e 1024 dimensioni di output, si distingue come il modello di embedding multilingue più efficiente, potente e affidabile con meno di 1 miliardo di parametri.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">Legge di scala dei modelli di embedding. La performance media su task MTEB in inglese è rappresentata rispetto al numero di parametri del modello. Ogni punto rappresenta un modello di embedding. La linea di tendenza, che rappresenta tutti i modelli, è evidenziata, con i modelli multilingue enfatizzati in ciano. Si può notare che </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> dimostra prestazioni superiori rispetto ai modelli di dimensioni simili, mostrando anche un miglioramento superlineare rispetto al suo predecessore, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\">. Questo grafico è stato creato selezionando i primi 100 modelli di embedding dalla classifica MTEB, escludendo quelli senza informazioni sulle dimensioni, tipicamente modelli closed-source o proprietari. Sono state filtrate anche le submission identificate come trolling evidente.</span></figcaption></figure><p>Inoltre, rispetto agli embedding basati su LLM che hanno recentemente attirato l'attenzione, come <code>e5-mistral-7b-instruct</code>, che ha una dimensione di parametri di 7,1 miliardi (12 volte più grande) e una dimensione di output di 4096 (4 volte più grande) ma offre solo un miglioramento dell'1% sui task MTEB in inglese, <code>jina-embeddings-v3</code> è una soluzione molto più efficiente in termini di costi, rendendola più adatta per la produzione e il computing on-edge.</p><h2 id=\"model-architecture\">Architettura del Modello</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Caratteristica</th>\n<th>Descrizione</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>Parametri Base</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>Parametri con LoRA</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>Token di input massimi</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>Dimensioni di output massime</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>Strati</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Vocabolario</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>Lingue supportate</td>\n<td>89</td>\n</tr>\n<tr>\n<td>Attention</td>\n<td>FlashAttention2, funziona anche senza</td>\n</tr>\n<tr>\n<td>Pooling</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>L'architettura di <code>jina-embeddings-v3</code> è mostrata nella figura sottostante. Per implementare l'architettura di base, abbiamo adattato il modello <code>XLM-RoBERTa</code> con diverse modifiche chiave: (1) abilitando la codifica efficace di sequenze di testo lunghe, (2) permettendo la codifica di embedding specifica per task, e (3) migliorando l'efficienza complessiva del modello con le tecniche più recenti. Continuiamo a utilizzare il tokenizer originale di <code>XLM-RoBERTa</code>. Mentre <code>jina-embeddings-v3</code>, con i suoi 570 milioni di parametri, è più grande di <code>jina-embeddings-v2</code> che ne ha 137 milioni, rimane comunque molto più piccolo dei modelli di embedding ottimizzati dagli LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\">L'architettura di </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> è basata sul modello </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\">, con cinque adapter LoRA per quattro diversi task.</span></figcaption></figure><p>L'innovazione chiave in <code>jina-embeddings-v3</code> è l'uso degli adapter LoRA. Sono stati introdotti <strong>cinque</strong> adapter LoRA specifici per task per ottimizzare gli embedding per <strong>quattro</strong> task. L'input del modello consiste di due parti: il testo (il documento lungo da codificare) e il task. <code>jina-embeddings-v3</code> supporta quattro task e implementa cinque adapter tra cui scegliere: <code>retrieval.query</code> e <code>retrieval.passage</code> per gli embedding di query e passaggi nei task di recupero asimmetrico, <code>separation</code> per i task di clustering, <code>classification</code> per i task di classificazione e <code>text-matching</code> per i task che coinvolgono la similarità semantica, come STS o il recupero simmetrico. Gli adapter LoRA rappresentano meno del 3% dei parametri totali, aggiungendo un sovraccarico minimo al calcolo.</p><p>Per migliorare ulteriormente le prestazioni e ridurre il consumo di memoria, integriamo FlashAttention 2, supportiamo il checkpointing delle attivazioni e utilizziamo il framework DeepSpeed per un training distribuito efficiente.</p><h2 id=\"get-started\">Per Iniziare</h2><h3 id=\"via-jina-ai-search-foundation-api\">Tramite l'API Search Foundation di Jina AI</h3><p>Il modo più semplice per utilizzare <code>jina-embeddings-v3</code> è visitare la <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">homepage di Jina AI</a> e navigare alla sezione Search Foundation API. Da oggi, questo modello è impostato come predefinito per tutti i nuovi utenti. Puoi esplorare diversi parametri e funzionalità direttamente da lì.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>Rispetto alla v2, la v3 introduce tre nuovi parametri nell'API: <code>task</code>, <code>dimensions</code> e <code>late_chunking</code>.</p><h4 id=\"parameter-task\">Parametro <code>task</code></h4><p>Il parametro <code>task</code> è cruciale e deve essere impostato in base al task downstream. Gli embedding risultanti saranno ottimizzati per quello specifico task. Per maggiori dettagli, consulta l'elenco qui sotto.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>Valore di <code>task</code></strong></th>\n<th><strong>Descrizione del Task</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>Embedding di <b>documenti</b> in un task di recupero query-documento</td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>Embedding di <b>query</b> in un task di recupero query-documento</td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>Clustering di documenti, visualizzazione di un corpus</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>Classificazione del testo</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(Predefinito)</b> Similarità semantica del testo, recupero simmetrico generale, raccomandazione, ricerca di elementi simili, deduplicazione</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Nota che l'API <em>non</em> genera prima un meta embedding generico per poi adattarlo con un MLP aggiuntivo ottimizzato. Invece, inserisce l'adapter LoRA specifico per il task in ogni strato del transformer (un totale di 24 strati) ed esegue la codifica in un'unica passata. Ulteriori dettagli possono essere trovati nel <a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">nostro paper su arXiv</a>.</p><h4 id=\"parameter-dimensions\">Parametro <code>dimensions</code></h4><p>Il parametro <code>dimensions</code> permette agli utenti di scegliere un compromesso tra efficienza dello spazio e prestazioni al minor costo. Grazie alla tecnica MRL utilizzata in <code>jina-embeddings-v3</code>, puoi ridurre le dimensioni degli embedding quanto desideri (persino fino a una singola dimensione!). Embedding più piccoli sono più efficienti in termini di archiviazione per i database vettoriali, e il loro costo in termini di prestazioni può essere stimato dalla figura sottostante.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">Parametro <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Late Chunking nei Modelli di Embedding con Contesto Lungo</div><div class=\"kg-bookmark-description\">Il chunking di documenti lunghi preservando le informazioni contestuali è una sfida. Introduciamo il \"Late Chunking\" che sfrutta i modelli di embedding con contesto lungo per generare embedding di chunk contestuali per migliori applicazioni di recupero.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Infine, il parametro <code>late_chunking</code> controlla se utilizzare il nuovo metodo di chunking <a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">che abbiamo introdotto il mese scorso</a> per la codifica di un batch di frasi. Quando impostato su <code>true</code>, la nostra API concatenerà tutte le frasi nel campo <code>input</code> e le fornirà come una singola stringa al modello. In altre parole, <strong>trattiamo le frasi nell'input come se provenissero originariamente dalla stessa sezione, paragrafo o documento.</strong> Internamente, il modello codifica questa lunga stringa concatenata e poi esegue il late chunking, restituendo una lista di embedding che corrisponde alla dimensione della lista di input. Ogni embedding nella lista è quindi condizionato dagli embedding precedenti.</p><p>Dal punto di vista dell'utente, l'impostazione di <code>late_chunking</code> <em>non</em> cambia il formato di input o output. Noterai solo un cambiamento nei valori degli embedding, poiché ora vengono calcolati basandosi sull'intero contesto precedente anziché indipendentemente. Ciò che è importante sapere quando si usa<code>late_chunking=True</code> significa che il numero totale di token (sommando tutti i token in <code>input</code>) per richiesta è limitato a 8192, che è la lunghezza massima del contesto consentita per <code>jina-embeddings-v3</code>. Quando <code>late_chunking=False</code>, non esiste tale restrizione; il numero totale di token è soggetto solo a <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">il limite di rate della Embedding API</a>.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking attivo vs disattivo: Il formato di input e output rimane lo stesso, con l'unica differenza nei valori di embedding. Quando </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\"> è abilitato, gli embedding sono influenzati dall'intero contesto precedente in </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\">, mentre senza di esso, gli embedding vengono calcolati indipendentemente.</span></p></figcaption></figure><h3 id=\"via-azure-aws\">Tramite Azure e AWS</h3><p><code>jina-embeddings-v3</code> è ora disponibile su AWS SageMaker e Azure Marketplace.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>Se hai bisogno di utilizzarlo al di fuori di queste piattaforme o on-premises all'interno della tua azienda, nota che il modello è concesso in licenza sotto CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Per richieste di utilizzo commerciale, non esitare a contattarci.</a></p><h3 id=\"via-vector-databases-partners\">Tramite Database Vettoriali e Partner</h3><p>Collaboriamo strettamente con provider di database vettoriali come Pinecone, Qdrant e Milvus, così come con framework di orchestrazione LLM come LlamaIndex, Haystack e Dify. Al momento del rilascio, siamo lieti di annunciare che Pinecone, Qdrant, Milvus e Haystack hanno già integrato il supporto per <code>jina-embeddings-v3</code>, inclusi i tre nuovi parametri: <code>task</code>, <code>dimensions</code> e <code>late_chunking</code>. Altri partner che hanno già integrato l'API <code>v2</code> dovrebbero supportare anche <code>v3</code> semplicemente cambiando il nome del modello in <code>jina-embeddings-v3</code>. Tuttavia, potrebbero non supportare ancora i nuovi parametri introdotti in <code>v3</code>.</p><h4 id=\"via-pinecone\">Tramite Pinecone </h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">Tramite Qdrant </h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">Tramite Milvus</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">Tramite Haystack</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">Conclusione</h2><p>Nell'ottobre 2023, abbiamo rilasciato <code>jina-embeddings-v2-base-en</code>, <a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">il primo modello di embedding open-source al mondo con una lunghezza di contesto di 8K</a>. Era l'<em>unico</em> modello di embedding testuale che supportava il contesto lungo e si confrontava con <code>text-embedding-ada-002</code> di OpenAI. Oggi, dopo un anno di apprendimento, sperimentazione e preziose lezioni, siamo orgogliosi di rilasciare <code>jina-embeddings-v3</code>—una nuova frontiera nei modelli di embedding testuale e una grande pietra miliare della nostra azienda.</p><p>Con questo rilascio, continuiamo ad eccellere in ciò per cui siamo conosciuti: <strong>embedding a lungo contesto</strong>, affrontando anche la funzionalità più richiesta sia dall'industria che dalla comunità—<strong>embedding multilingue</strong>. Allo stesso tempo, spingiamo le prestazioni a un nuovo massimo. Con nuove funzionalità come Task-specific LoRA, MRL e late chunking, crediamo che <code>jina-embeddings-v3</code> servirà veramente come modello di embedding fondamentale per varie applicazioni, inclusi RAG, agenti e altro. Rispetto ai recenti embedding basati su LLM come <code>NV-embed-v1/v2</code>, il nostro modello è altamente efficiente in termini di parametri, rendendolo molto più adatto alla produzione e ai dispositivi edge.</p><p>Guardando al futuro, pianifichiamo di concentrarci sulla valutazione e il miglioramento delle prestazioni di <code>jina-embeddings-v3</code> su lingue con risorse limitate e sull'ulteriore analisi dei fallimenti sistematici causati dalla limitata disponibilità di dati. Inoltre, i pesi del modello di <code>jina-embeddings-v3</code>, insieme alle sue funzionalità innovative e spunti interessanti, serviranno come base per i nostri prossimi modelli, incluso <code>jina-clip-v2</code>,<code>jina-reranker-v3</code>, e <code>reader-lm-v2</code>.</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 è un modello di embedding testuale multilingue all'avanguardia con 570M parametri e lunghezza token di 8192, che supera gli ultimi embedding proprietari di OpenAI e Cohere su MTEB.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}