{
  "slug": "jina-classifier-for-high-performance-zero-shot-and-few-shot-classification",
  "id": "6711fbbd708dbe0001924974",
  "uuid": "65c883e0-556a-4079-b07a-66e9e9926717",
  "title": "API Jina Classifier per la Classificazione Zero-Shot e Few-Shot ad Alte Prestazioni",
  "html": "<p>La classificazione è un'attività downstream comune per gli embedding. Gli embedding di testo possono categorizzare il testo in etichette predefinite per il rilevamento dello spam o l'analisi del sentiment. Gli embedding multimodali come <code>jina-clip-v1</code> possono essere applicati al filtraggio basato sui contenuti o all'annotazione dei tag. Recentemente, la classificazione è stata utilizzata anche per instradare le query agli LLM appropriati in base alla complessità e al costo, ad esempio le query aritmetiche semplici potrebbero essere indirizzate a un modello linguistico piccolo. I compiti di ragionamento complesso potrebbero essere diretti a LLM più potenti ma più costosi.</p><p>Oggi presentiamo la nuova <strong>API Classifier</strong> di Jina AI's Search Foundation. Supportando la classificazione online <strong>zero-shot</strong> e <strong>few-shot</strong>, è basata sui nostri più recenti modelli di embedding come <code>jina-embeddings-v3</code> e <code>jina-clip-v1</code>. L'API Classifier si basa sull'<a href=\"https://jmlr.org/papers/v7/crammer06a.html?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">apprendimento online passivo-aggressivo</a>, permettendole di adattarsi ai nuovi dati in tempo reale. Gli utenti possono iniziare con un classificatore zero-shot e utilizzarlo immediatamente. Possono poi aggiornare incrementalmente il classificatore inviando nuovi esempi o quando si verifica un concept drift. Ciò consente una classificazione efficiente e scalabile su vari tipi di contenuti <em>senza</em> un'ampia quantità iniziale di dati etichettati. Gli utenti possono anche pubblicare i loro classificatori per uso pubblico. Quando rilasciamo nuovi embedding, come il prossimo <code>jina-clip-v2</code> multilingue, gli utenti possono accedervi immediatamente attraverso l'API Classifier, garantendo capacità di classificazione aggiornate.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/classifier?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Classifier API</div><div class=\"kg-bookmark-description\">High performance classifier for image and text classification.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-classifier.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"zero-shot-classification\">Classificazione Zero-Shot</h2><p>L'API Classifier offre potenti capacità di classificazione zero-shot, permettendo di categorizzare testo o immagini senza pre-addestramento su dati etichettati. Ogni classificatore inizia con capacità zero-shot, che possono essere successivamente migliorate con dati di training aggiuntivi o aggiornamenti - un argomento che esploreremo nella prossima sezione.</p><h3 id=\"example-1-route-llm-requests\">Esempio 1: Instradamento delle Richieste LLM</h3><p>Ecco un esempio di utilizzo dell'API classifier per l'instradamento delle query LLM:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-embeddings-v3\",\n    \"labels\": [\n      \"Simple task\",\n      \"Complex reasoning\",\n      \"Creative writing\"\n    ],\n    \"input\": [\n      \"Calculate the compound interest on a principal of $10,000 invested for 5 years at an annual rate of 5%, compounded quarterly.\",\n      \"分析使用CRISPR基因编辑技术在人类胚胎中的伦理影响。考虑潜在的医疗益处和长期社会后果。\",\n      \"AIが自意識を持つディストピアの未来を舞台にした短編小説を書いてください。人間とAIの関係や意識の本質をテーマに探求してください。\",\n      \"Erklären Sie die Unterschiede zwischen Merge-Sort und Quicksort-Algorithmen in Bezug auf Zeitkomplexität, Platzkomplexität und Leistung in der Praxis.\",\n      \"Write a poem about the beauty of nature and its healing power on the human soul.\",\n      \"Translate the following sentence into French: The quick brown fox jumps over the lazy dog.\"\n    ]\n  }'</code></pre><p>Questo esempio dimostra l'uso di <code>jina-embeddings-v3</code> per instradare le query degli utenti in più lingue (inglese, cinese, giapponese e tedesco) in tre categorie, che corrispondono a tre diverse dimensioni di LLM. Il formato della risposta API è il seguente:</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 256, \"prompt_tokens\": 256},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Simple task\", \"score\": 0.35216382145881653},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Complex reasoning\", \"score\": 0.34310275316238403},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Creative writing\", \"score\": 0.3487184941768646},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Complex reasoning\", \"score\": 0.35207709670066833},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Creative writing\", \"score\": 0.3638903796672821},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Simple task\", \"score\": 0.3561534285545349}\n  ]\n}</code></pre><p>La risposta include:</p><ul><li><code>usage</code>: Informazioni sull'utilizzo dei token.</li><li><code>data</code>: Un array di risultati di classificazione, uno per ogni input.<ul><li>Ogni risultato contiene l'etichetta prevista (<code>prediction</code>) e un punteggio di confidenza (<code>score</code>). Lo <code>score</code> per ogni classe è calcolato tramite normalizzazione softmax - per zero-shot è basato sulle similarità coseno tra l'input e gli embedding delle etichette <a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model?ref=jina-ai-gmbh.ghost.io#parameter-task\" rel=\"noreferrer\">sotto il task-LoRA di <code>classification</code></a>; mentre per few-shot è basato su trasformazioni lineari apprese dell'embedding di input per ogni classe - risultando in probabilità che sommano a 1 tra tutte le classi.</li><li>L'<code>index</code> corrisponde alla posizione dell'input nella richiesta originale.</li></ul></li></ul><h3 id=\"example-2-categorize-image-text\">Esempio 2: Categorizzazione di Immagini e Testo</h3><p>Esploriamo un esempio multimodale utilizzando <code>jina-clip-v1</code>. Questo modello può classificare sia testo che immagini, rendendolo ideale per la categorizzazione dei contenuti attraverso vari tipi di media. Consideriamo la seguente chiamata API:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-clip-v1\",\n    \"labels\": [\n      \"Food and Dining\",\n      \"Technology and Gadgets\",\n      \"Nature and Outdoors\",\n      \"Urban and Architecture\"\n    ],\n    \"input\": [\n      {\"text\": \"A sleek smartphone with a high-resolution display and multiple camera lenses\"},\n      {\"text\": \"Fresh sushi rolls served on a wooden board with wasabi and ginger\"},\n      {\"image\": \"https://picsum.photos/id/11/367/267\"},\n      {\"image\": \"https://picsum.photos/id/22/367/267\"},\n      {\"text\": \"Vibrant autumn leaves in a dense forest with sunlight filtering through\"},\n      {\"image\": \"https://picsum.photos/id/8/367/267\"}\n    ]\n  }'</code></pre><p>Nota come carichiamo le immagini nella richiesta, puoi anche utilizzare una stringa <code>base64</code> per rappresentare un'immagine. L'API restituisce i seguenti risultati di classificazione:</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 12125, \"prompt_tokens\": 12125},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Technology and Gadgets\", \"score\": 0.30329811573028564},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Food and Dining\", \"score\": 0.2765541970729828},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Nature and Outdoors\", \"score\": 0.29503118991851807},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Urban and Architecture\", \"score\": 0.2648046910762787},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Nature and Outdoors\", \"score\": 0.3133063316345215},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Technology and Gadgets\", \"score\": 0.27474141120910645}\n  ]\n}</code></pre><h3 id=\"example-3-detect-if-jina-reader-gets-genuine-content\">Esempio 3: Rilevare se Jina Reader Ottiene Contenuti Genuini</h3><p>Un'applicazione interessante della classificazione zero-shot è determinare l'accessibilità dei siti web attraverso <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>. Sebbene questo possa sembrare un compito semplice, è sorprendentemente complesso nella pratica. I messaggi di blocco variano ampiamente da sito a sito, apparendo in diverse lingue e citando varie ragioni (paywall, limiti di velocità, interruzioni del server). Questa diversità rende difficile affidarsi a regex o regole fisse per catturare tutti gli scenari.</p><pre><code class=\"language-python\">import requests\nimport json\n\nresponse1 = requests.get('https://r.jina.ai/https://jina.ai')\n\nurl = 'https://api.jina.ai/v1/classify'\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer $YOUR_API_KEY_HERE'\n}\ndata = {\n    'model': 'jina-embeddings-v3',\n    'labels': ['Blocked', 'Accessible'],\n    'input': [{'text': response1.text[:8000]}]\n}\nresponse2 = requests.post(url, headers=headers, data=json.dumps(data))\n\nprint(response2.text)</code></pre><p>Lo script recupera il contenuto tramite <code>r.jina.ai</code> e lo classifica come <code>\"Blocked\"</code> o <code>\"Accessible\"</code> utilizzando l'API Classifier. Ad esempio, <a href=\"https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai</a> sarebbe probabilmente <code>\"Blocked\"</code> a causa delle restrizioni di accesso, mentre <a href=\"https://r.jina.ai/https://jina.ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://jina.ai</a> dovrebbe essere \"Accessible\".</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\"usage\":{\"total_tokens\":185,\"prompt_tokens\":185},\"data\":[{\"object\":\"classification\",\"index\":0,\"prediction\":\"Blocked\",\"score\":0.5392698049545288}]}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">L'API Classifier può distinguere efficacemente tra contenuti genuini e risultati bloccati da Jina Reader.</span></p></figcaption></figure><p>Questo esempio sfrutta <code>jina-embeddings-v3</code> e offre un modo rapido e automatizzato per monitorare l'accessibilità dei siti web, utile per sistemi di aggregazione dei contenuti o web scraping, specialmente in contesti multilingue.</p><h3 id=\"example-4-filtering-statements-from-opinions-for-grounding\">Esempio 4: Filtrare Affermazioni da Opinioni per il Grounding</h3><p>Un'altra interessante applicazione della classificazione zero-shot è il filtraggio di affermazioni simili a dichiarazioni di fatto dalle opinioni in documenti lunghi. Da notare che il classificatore stesso non può determinare se qualcosa è fattualmente vero. Piuttosto, identifica il testo che è <em>scritto nello stile di un'affermazione di fatto</em>, che può poi essere verificato attraverso una API di verifica, che spesso è piuttosto costosa. Questo processo in due fasi è fondamentale per un efficace fact-checking: prima filtrare tutte quelle opinioni e sentimenti, poi inviare le rimanenti affermazioni per la verifica.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/fact-checking-with-new-grounding-api-in-jina-reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Fact-Checking with New Grounding API in Jina Reader</div><div class=\"kg-bookmark-description\">With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Considera questo paragrafo sulla Corsa allo Spazio degli anni '60:</p><pre><code class=\"language-json\">The Space Race of the 1960s was a breathtaking testament to human ingenuity. When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era. The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance. NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973. While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent. On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars. The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination. The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle.\n</code></pre><p>Questo testo mescola intenzionalmente diversi tipi di scrittura - da affermazioni simili a dichiarazioni di fatto (come \"Sputnik 1 fu lanciato il 4 ottobre 1959\"), a chiare opinioni (\"straordinaria testimonianza\"), linguaggio emotivo (\"suscitò paura nei cuori\"), e affermazioni interpretative (\"segnando l'innegabile inizio di una nuova era\").</p><p>Il compito del classificatore zero-shot <strong>è puramente semantico</strong> - identifica se un pezzo di testo è scritto come una dichiarazione o come un'opinione/interpretazione. Per esempio, <code>\"The Soviet Union launched Sputnik 1 on October 4, 1959\"</code> è scritto come una dichiarazione, mentre <code>\"The Space Race was a breathtaking testament\"</code> è chiaramente scritto come un'opinione.</p><pre><code class=\"language-python\">headers = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {API_KEY}'\n}\n\n# Step 1: Split text and classify\nchunks = [chunk.strip() for chunk in text.split('.') if chunk.strip()]\nlabels = [\n    \"subjective, opinion, feeling, personal experience, creative writing, position\",\n    \"fact\"\n]\n\n# Classify chunks\nclassify_response = requests.post(\n    'https://api.jina.ai/v1/classify',\n    headers=headers,\n    json={\n        \"model\": \"jina-embeddings-v3\",\n        \"input\": [{\"text\": chunk} for chunk in chunks],\n        \"labels\": labels\n    }\n)\n\n# Sort chunks\nsubjective_chunks = []\nfactual_chunks = []\nfor chunk, classification in zip(chunks, classify_response.json()['data']):\n    if classification['prediction'] == labels[0]:\n        subjective_chunks.append(chunk)\n    else:\n        factual_chunks.append(chunk)\n\nprint(\"\\nSubjective statements:\", subjective_chunks)\nprint(\"\\nFactual statements:\", factual_chunks)</code></pre><p>E otterrai:</p><pre><code class=\"language-json\">Subjective statements: ['The Space Race of the 1960s was a breathtaking testament to human ingenuity', 'The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance', 'While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent', \"The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination\"]\n\nFactual statements: ['When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era', \"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\", \"On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars\", 'The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle']</code></pre><p>Ricorda, il fatto che qualcosa sia scritto come una dichiarazione non significa che sia vero. Ecco perché abbiamo bisogno del secondo passaggio - inserire queste affermazioni simili a dichiarazioni in una API di verifica per l'effettiva verifica dei fatti. Per esempio, verifichiamo questa affermazione: <code>\"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\"</code> con il codice sottostante.</p><pre><code class=\"language-python\">ground_headers = {\n        'Accept': 'application/json',\n        'Authorization': f'Bearer {API_KEY}'\n    }\n\nground_response = requests.get(\n    f'https://g.jina.ai/{quote(factual_chunks[1])}',\n    headers=ground_headers\n)\n\nprint(ground_response.json())</code></pre><p>che ti darà:</p><pre><code class=\"language-json\">{'code': 200, 'status': 20000, 'data': {'factuality': 1, 'result': True, 'reason': \"The statement is supported by multiple references confirming NASA's founding in 1958 and the significant financial investment in the Apollo program. The $28 billion figure aligns with the data provided in the references, which detail NASA's expenditures during the Apollo program from 1960 to 1973. Additionally, the context of NASA's budget peaking during this period further substantiates the claim. Therefore, the statement is factually correct based on the available evidence.\", 'references': [{'url': 'https://en.wikipedia.org/wiki/Budget_of_NASA', 'keyQuote': \"NASA's budget peaked in 1964–66 when it consumed roughly 4% of all federal spending. The agency was building up to the first Moon landing and the Apollo program was a top national priority, consuming more than half of NASA's budget.\", 'isSupportive': True}, {'url': 'https://en.wikipedia.org/wiki/NASA', 'keyQuote': 'Established in 1958, it succeeded the National Advisory Committee for Aeronautics (NACA)', 'isSupportive': True}, {'url': 'https://nssdc.gsfc.nasa.gov/planetary/lunar/apollo.html', 'keyQuote': 'More details on Apollo lunar landings', 'isSupportive': True}, {'url': 'https://usafacts.org/articles/50-years-after-apollo-11-moon-landing-heres-look-nasas-budget-throughout-its-history/', 'keyQuote': 'NASA has spent its money so far.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/history/', 'keyQuote': 'Discover the history of our human spaceflight, science, technology, and aeronautics programs.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/the-apollo-program/', 'keyQuote': 'Commander for Apollo 11, first to step on the lunar surface.', 'isSupportive': True}, {'url': 'https://www.planetary.org/space-policy/cost-of-apollo', 'keyQuote': 'A rich data set tracking the costs of Project Apollo, free for public use. Includes unprecedented program-by-program cost breakdowns.', 'isSupportive': True}, {'url': 'https://www.statista.com/statistics/1342862/nasa-budget-project-apollo-costs/', 'keyQuote': 'NASA&amp;#x27;s monetary obligations compared to Project Apollo&amp;#x27;s total costs from 1960 to 1973 (in million U.S. dollars)', 'isSupportive': True}], 'usage': {'tokens': 10640}}}</code></pre><p>Con un punteggio di fattualità di 1, l'API di verifica conferma che questa affermazione è ben fondata nei fatti storici. Questo approccio apre possibilità affascinanti, dall'analisi di documenti storici alla verifica dei fatti in tempo reale degli articoli di news. Combinando la classificazione zero-shot con la verifica dei fatti, creiamo una potente pipeline per l'analisi automatizzata delle informazioni - prima filtrando le opinioni, poi verificando le rimanenti affermazioni contro fonti affidabili.</p><h3 id=\"remarks-on-zero-shot-classification\">Osservazioni sulla Classificazione Zero-Shot</h3><h4 id=\"using-semantic-labels\">Utilizzo di Etichette Semantiche</h4><p>Quando si lavora con la classificazione zero-shot, <strong>è cruciale utilizzare etichette semanticamente significative piuttosto che simboli astratti o numeri.</strong> Per esempio, <code>\"Technology\"</code>, <code>\"Nature\"</code>, e <code>\"Food\"</code> sono molto più efficaci di <code>\"Class1\"</code>, <code>\"Class2\"</code>, <code>\"Class3\"</code> o <code>\"0\"</code>, <code>\"1\"</code>, <code>\"2\"</code>. <code>\"Positive sentiment\"</code> è più efficace di <code>\"Positive\"</code> e <code>\"True\"</code>. I modelli di embedding comprendono le relazioni semantiche, quindi le etichette descrittive permettono al modello di sfruttare la sua conoscenza pre-addestrata per classificazioni più accurate. Il nostro post precedente esplora come creare efficaci etichette semantiche per migliori risultati di classificazione.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/rephrased-labels-improve-zero-shot-text-classification-30?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Rephrased Labels Improve Zero-Shot Text Classification by 30%</div><div class=\"kg-bookmark-description\">When using embedding models for zero-shot classification, rephrasing the class label to \"This is seriously about 'LABEL'\" gives higher accuracy vs. using LABEL alone. But how, and why?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/07/Heading.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"stateless-nature\">Natura Senza Stato</h4><p>La classificazione zero-shot è fondamentalmente senza stato, a differenza degli approcci tradizionali di machine learning. <strong>Questo significa che dati gli stessi input e modello, i risultati saranno sempre coerenti, indipendentemente da chi usa l'API o quando.</strong> Il modello non impara né si aggiorna in base alle classificazioni che esegue; ogni compito è indipendente. Questo permette un uso immediato senza setup o training, e offre flessibilità nel cambiare categorie tra le chiamate API.</p><p>Questa natura senza stato contrasta nettamente con gli approcci few-shot e di apprendimento online, che esploreremo successivamente. In questi metodi, i modelli possono adattarsi a nuovi esempi, potenzialmente producendo risultati diversi nel tempo o tra utenti diversi.</p><h2 id=\"few-shot-classification\">Classificazione Few-Shot</h2><p>La classificazione few-shot offre un approccio semplice per creare e aggiornare classificatori con dati etichettati minimi. Questo metodo fornisce due endpoint principali: <code>train</code> e <code>classify</code>.</p><p>L'endpoint <code>train</code> ti permette di creare o aggiornare un classificatore con un piccolo set di esempi. La tua prima chiamata a <code>train</code> restituirà un<code>classifier_id</code>, che puoi utilizzare per l'addestramento successivo quando hai nuovi dati, noti cambiamenti nella distribuzione dei dati o hai bisogno di aggiungere nuove classi. Questo approccio flessibile permette al tuo classificatore di evolversi nel tempo, adattandosi a nuovi pattern e categorie senza ripartire da zero.</p><p>In modo simile alla classificazione zero-shot, userai l'endpoint <code>classify</code> per fare previsioni. La differenza principale è che dovrai includere il tuo <code>classifier_id</code> nella richiesta, ma non dovrai fornire etichette candidate poiché sono già parte del tuo modello addestrato.</p><h3 id=\"example-train-a-support-ticket-assigner\">Esempio: Addestra un Assegnatore di Ticket di Supporto</h3><p>Esploriamo queste funzionalità attraverso un esempio di classificazione dei ticket di supporto clienti per l'assegnazione a diversi team in una startup tecnologica in rapida crescita.</p><h4 id=\"initial-training\">Addestramento Iniziale</h4><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"model\": \"jina-embeddings-v3\",\n  \"access\": \"private\",\n  \"input\": [\n    {\n      \"text\": \"I cant log into my account after the latest app update.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"My subscription renewal failed due to an expired credit card.\",\n      \"label\": \"team2\"\n    },\n    {\n      \"text\": \"How do I export my data from the platform?\",\n      \"label\": \"team3\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><p>Nota che nell'apprendimento few-shot, siamo liberi di usare <code>team1</code> <code>team2</code> come etichette di classe anche se non hanno un significato semantico intrinseco. Nella risposta, otterrai un <code>classifier_id</code> che rappresenta questo classificatore appena creato.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"classifier_id\": \"918c0846-d6ae-4f34-810d-c0c7a59aee14\",\n  \"num_samples\": 3,\n}\n</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Prendi nota del </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>classifier_id</span></code><span style=\"white-space: pre-wrap;\">, ne avrai bisogno per riferiti a questo classificatore in seguito.</span></p></figcaption></figure><h4 id=\"updating-classifier-to-adapt-team-restructuring\">Aggiornamento del Classificatore per Adattarsi alla Ristrutturazione del Team</h4><p>Man mano che l'azienda di esempio cresce, emergono nuovi tipi di problemi e anche la struttura del team cambia. La bellezza della classificazione few-shot sta nella sua capacità di adattarsi rapidamente a questi cambiamenti. Possiamo facilmente aggiornare il classificatore fornendo il <code>classifier_id</code> e nuovi esempi, introducendo nuove categorie di team (es. <code>team4</code>) o riassegnando i tipi di problemi esistenti a diversi team mentre l'organizzazione si evolve.</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"Im getting a 404 error when trying to access the new AI chatbot feature.\",\n      \"label\": \"team4\"\n    },\n    {\n      \"text\": \"The latest security patch is conflicting with my company firewall.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"I need help setting up SSO for my organization account.\",\n      \"label\": \"team5\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><h4 id=\"using-a-trained-classifier\">Utilizzo di un Classificatore Addestrato</h4><p>Durante l'inferenza, devi solo fornire il testo di input e il <code>classifier_id</code>. L'API gestisce il mapping tra il tuo input e le classi precedentemente addestrate, restituendo l'etichetta più appropriata basata sullo stato attuale del classificatore.</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/classify' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"The new feature is causing my dashboard to load slowly.\"\n    },\n    {\n      \"text\": \"I need to update my billing information for tax purposes.\"\n    }\n  ]\n}'</code></pre><p>La modalità few-shot ha due parametri unici.</p><h3 id=\"parameter-numiters\">Parametro <code>num_iters</code></h3><p>Il parametro <code>num_iters</code> regola quanto intensamente il classificatore apprende dagli esempi di addestramento. Mentre il valore predefinito di 10 funziona bene nella maggior parte dei casi, puoi regolare strategicamente questo valore in base alla <strong>tua fiducia nei dati di addestramento</strong>. Per esempi di alta qualità cruciali per la classificazione, aumenta <code>num_iters</code> per rafforzare la loro importanza. Al contrario, per esempi meno affidabili, abbassa <code>num_iters</code> per minimizzare il loro impatto sulle prestazioni del classificatore. Questo parametro può anche essere usato per implementare l'apprendimento sensibile al tempo, dove gli esempi più recenti ottengono conteggi di iterazioni più alti per adattarsi ai pattern in evoluzione mantenendo la conoscenza storica.</p><h3 id=\"parameter-access\">Parametro <code>access</code></h3><p>Il parametro <code>access</code> ti permette di controllare chi può utilizzare il tuo classificatore. Per impostazione predefinita, i classificatori sono privati e accessibili solo a te. Impostando l'accesso su \"public\" permetti a chiunque abbia il tuo <code>classifier_id</code> di <strong>usarlo con la propria chiave API e quota di token.</strong> Questo permette la condivisione dei classificatori mantenendo la privacy - gli utenti non possono vedere i tuoi dati di addestramento o la configurazione, e tu non puoi vedere le loro richieste di classificazione. Questo parametro è rilevante solo per la classificazione few-shot, poiché i classificatori zero-shot sono stateless. Non c'è bisogno di condividere i classificatori zero-shot poiché richieste identiche produrranno sempre le stesse risposte indipendentemente da chi le effettua.</p><h3 id=\"remarks-on-few-shot-learning\">Osservazioni sull'Apprendimento Few-Shot</h3><p>La classificazione few-shot nella nostra API ha alcune caratteristiche uniche degne di nota. A differenza dei modelli di machine learning tradizionali, la nostra implementazione utilizza l'apprendimento online a passaggio singolo - gli esempi di addestramento vengono elaborati per aggiornare i pesi del classificatore ma non vengono memorizzati successivamente. Questo significa che non puoi recuperare i dati di addestramento storici, ma garantisce una migliore privacy ed efficienza delle risorse.</p><p>Mentre l'apprendimento few-shot è potente, richiede un periodo di riscaldamento per superare le prestazioni della classificazione zero-shot. I nostri benchmark mostrano che 200-400 esempi di addestramento tipicamente forniscono dati sufficienti per vedere prestazioni superiori. Tuttavia, non è necessario fornire esempi per tutte le classi fin dall'inizio - il classificatore può scalare per accogliere nuove classi nel tempo. Tieni presente che le classi appena aggiunte potrebbero sperimentare un breve periodo di avvio a freddo o uno sbilanciamento delle classi fino a quando non vengono forniti esempi sufficienti.</p><h2 id=\"benchmark\">Benchmark</h2><p>Per la nostra analisi di benchmark, abbiamo valutato gli approcci zero-shot e few-shot su diversi dataset, inclusi compiti di classificazione del testo come il rilevamento delle emozioni (6 classi) e il rilevamento dello spam (2 classi), così come compiti di classificazione delle immagini come CIFAR10 (10 classi). Il framework di valutazione ha utilizzato divisioni standard train-test, con lo zero-shot che non richiede dati di addestramento e il few-shot che utilizza porzioni del set di addestramento. Abbiamo tracciato metriche chiave come la dimensione dell'addestramento e il conteggio delle classi target, permettendo confronti controllati. Per garantire robustezza, in particolare per l'apprendimento few-shot, ogni input è passato attraverso multiple iterazioni di addestramento. Abbiamo confrontato questi approcci moderni con baseline tradizionali come SVM Lineare e SVM RBF per fornire contesto alle loro prestazioni.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Multi-class-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Image-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Text-classification--1-.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Sono mostrati i punteggi F1. Per le impostazioni complete del benchmark, consulta </span><a href=\"https://docs.google.com/spreadsheets/d/15vK6VPlcAM4e7lSJw6IeVtTtyariXEVQurDTFKXwwtY/edit?gid=249584681&ref=jina-ai-gmbh.ghost.io#gid=249584681\"><span style=\"white-space: pre-wrap;\">questo foglio Google</span></a><span style=\"white-space: pre-wrap;\">.</span></p></figcaption></figure><p>I grafici F1 rivelano pattern interessanti tra tre attività. Non sorprendentemente, la classificazione zero-shot mostra prestazioni costanti fin dall'inizio, indipendentemente dalla dimensione dei dati di training. Al contrario, l'apprendimento few-shot dimostra una curva di apprendimento rapida, partendo inizialmente più bassa ma superando rapidamente le prestazioni zero-shot con l'aumentare dei dati di training. Entrambi i metodi alla fine <strong>raggiungono un'accuratezza comparabile intorno al campione 400</strong>, con il few-shot che mantiene un leggero vantaggio. Questo pattern è valido sia per scenari di classificazione multi-classe che per la classificazione delle immagini, suggerendo che l'apprendimento few-shot può essere particolarmente vantaggioso quando sono disponibili alcuni dati di training, mentre lo zero-shot offre prestazioni affidabili anche senza esempi di training. La tabella seguente riassume la differenza tra classificazione zero-shot e few-shot dal punto di vista dell'utente API.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Zero-shot</th>\n<th>Few-shot</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Primary Use Case</td>\n<td>Default solution for general classification</td>\n<td>For data outside v3/clip-v1's domain or time-sensitive data</td>\n</tr>\n<tr>\n<td>Training Data Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /train</td>\n<td>N/A</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /classify</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Classifier ID Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Semantic Labels Required</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>State Management</td>\n<td>Stateless</td>\n<td>Stateful</td>\n</tr>\n<tr>\n<td>Continuous Model Updates</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Access Control</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Maximum Classes</td>\n<td>256</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Classifiers</td>\n<td>N/A</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Inputs per Request</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Maximum Token Length per Input</td>\n<td>8,192 tokens</td>\n<td>8,192 tokens</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"summary\">Riepilogo</h2><p>L'API Classifier offre potenti funzionalità di classificazione zero-shot e few-shot sia per contenuti testuali che per immagini, basata su modelli di embedding avanzati come <code>jina-embeddings-v3</code> e <code>jina-clip-v1</code>. I nostri benchmark mostrano che la classificazione zero-shot fornisce prestazioni affidabili senza dati di training, rendendola un eccellente punto di partenza per la maggior parte delle attività con supporto fino a 256 classi. Mentre l'apprendimento few-shot può raggiungere un'accuratezza leggermente migliore con i dati di training, consigliamo di iniziare con la classificazione zero-shot per i suoi risultati immediati e la sua flessibilità.</p><p>La versatilità dell'API supporta varie applicazioni, dal routing delle query LLM al rilevamento dell'accessibilità dei siti web e alla categorizzazione di contenuti multilingue. Che tu stia iniziando con zero-shot o passando all'apprendimento few-shot per casi specializzati, l'API mantiene un'interfaccia coerente per un'integrazione perfetta nella tua pipeline. Siamo particolarmente entusiasti di vedere come gli sviluppatori sfrutteranno questa API nelle loro applicazioni, e implementeremo il supporto per nuovi modelli di embedding come <code>jina-clip-v2</code> in futuro.</p>",
  "comment_id": "6711fbbd708dbe0001924974",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/classifier-header-1.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-10-18T08:10:05.000+02:00",
  "updated_at": "2024-10-24T11:04:33.000+02:00",
  "published_at": "2024-10-22T10:57:15.000+02:00",
  "custom_excerpt": "New Classifier API offers zero-shot and few-shot classification for text and images. Start classifying content instantly or train it with your own examples.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-classifier-for-high-performance-zero-shot-and-few-shot-classification/",
  "excerpt": "La nuova API di Classifier offre la classificazione zero-shot e few-shot per testo e immagini. Inizia subito a classificare i contenuti oppure addestrala con i tuoi esempi.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract artistic portrait using a montage of colorful squares and scattered text.",
  "feature_image_caption": null
}