{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "Cosa abbiamo imparato a ICML2024 con PLaG, XRM, tinyBenchmark, MagicLens, Prompt Sketching e altro",
  "html": "<p>L'<a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">International Conference on Machine Learning</a> è una delle conferenze più prestigiose nella comunità del machine learning e dell'intelligenza artificiale e ha tenuto il suo incontro 2024 a Vienna dal 21 al 27 luglio di quest'anno.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Interior of a bustling academic conference hall with many attendees, some carrying backpacks, and research posters displayed \" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>La conferenza è stata un'esperienza di apprendimento intensiva di 7 giorni, con presentazioni orali e opportunità di scambiare idee direttamente con altri ricercatori. C'è molto lavoro interessante in corso nel reinforcement learning, nell'AI per le scienze della vita, nel representation learning, nei modelli multi-modali e, naturalmente, negli elementi fondamentali dello sviluppo dei modelli AI. Di particolare importanza è stato il tutorial sulla <a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">Physics of Large Language Models</a>, che ha esplorato approfonditamente il funzionamento interno dei LLM e ha offerto risposte convincenti alla domanda se gli LLM memorizzino le informazioni o applichino il ragionamento quando dicono le cose.</p><h2 id=\"our-work-on-jina-clip-v1\">Il Nostro Lavoro su Jina-CLIP-v1</h2><p>Abbiamo presentato un <a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">poster</a> del <a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">lavoro dietro il nostro nuovo modello multi-modale</a> <code>jina-clip-v1</code> come parte del workshop <a href=\"https://icml.cc/virtual/2024/workshop/29957?ref=jina-ai-gmbh.ghost.io\">Multi-modal Foundation Models meet Embodied AI</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>Incontrare e discutere il nostro lavoro con colleghi internazionali che operano in molti campi è stato molto stimolante. La nostra presentazione ha ricevuto molti feedback positivi, con molte persone interessate al modo in cui Jina CLIP unifica i paradigmi di apprendimento contrastivo multi-modale e uni-modale. Le discussioni hanno spaziato dalle limitazioni dell'architettura CLIP alle estensioni per modalità aggiuntive fino alle applicazioni nell'abbinamento di peptidi e proteine.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster.mp4\" poster=\"https://img.spacergif.org/v1/1138x640/0a/spacer.png\" width=\"1138\" height=\"640\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">3:09</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Michael Günther presenta Jina CLIP</span></p></figcaption>\n        </figure><h2 id=\"our-favorites\">I Nostri Preferiti</h2><p>Abbiamo avuto l'opportunità di discutere molti progetti e presentazioni di altri ricercatori, ed ecco alcuni dei nostri preferiti:</p><h3 id=\"plan-like-a-graph-plag\">Plan Like a Graph (PLaG)</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., & Pierrehumbert, J. B. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Graph-Enhanced Large Language Models in Asynchronous Plan Reasoning.</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>Molti conoscono il \"Few-Shot Prompting\" o il \"Chain of Thought prompting\". <a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> ha presentato all'ICML un metodo nuovo e migliore: <em>Plan Like a Graph (PLaG)</em>.</p><p>La sua idea è semplice: un compito assegnato a un LLM viene scomposto in sotto-compiti che un LLM può risolvere in parallelo o in sequenza. Questi sotto-compiti formano un grafo di esecuzione. L'esecuzione dell'intero grafo risolve il compito di alto livello.</p><p>Nel video sopra, Fangru Lin spiega il metodo usando un esempio facilmente comprensibile. Da notare che anche se questo migliora i risultati, gli LLM soffrono ancora di un drastico degradamento quando aumenta la complessità del task. Detto questo, rimane comunque un ottimo passo nella giusta direzione e fornisce benefici pratici immediati.</p><p>Per noi, è interessante vedere come il suo lavoro sia parallelo alle nostre applicazioni di prompt a <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a>. Abbiamo già implementato una struttura di prompt simile a un grafo, tuttavia, generare dinamicamente un grafo di esecuzione come ha fatto lei è una nuova direzione che esploreremo.</p><h3 id=\"discovering-environments-with-xrm\">Scoprire gli Ambienti con XRM</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., &amp; Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>Questo paper presenta un algoritmo semplice per scoprire ambienti di training che possono causare un modello a fare affidamento su caratteristiche che correlano con le etichette ma non inducono una classificazione/rilevanza accurata. Un esempio famoso è il dataset waterbirds (vedi <a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a>), che contiene foto di uccelli su sfondi diversi che dovrebbero essere classificati come uccelli acquatici o terrestri. Durante il training, il classificatore rileva se lo sfondo nelle immagini mostra acqua o no invece di basarsi sulle caratteristiche degli uccelli stessi. Un tale modello classificherà erroneamente gli uccelli acquatici se non c'è acqua nello sfondo.</p><p>Per mitigare questo comportamento, è necessario rilevare i campioni dove il modello si basa su caratteristiche dello sfondo fuorvianti. Questo paper presenta l'algoritmo XRM per farlo.</p><p>L'algoritmo addestra due modelli su due parti distinte del dataset di training. Durante l'addestramento, le etichette di alcuni campioni vengono invertite. Nello specifico, questo accade se l'altro modello (che non è addestrato sul rispettivo campione) classifica un campione diversamente. In questo modo, i modelli sono incoraggiati a basarsi su correlazioni spurie. Successivamente, è possibile estrarre campioni dai dati di training dove un'etichetta predetta da uno dei modelli differisce dalla verità di base. In seguito, si possono utilizzare queste informazioni per addestrare modelli di classificazione più robusti, per esempio con l'<a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">algoritmo Group DRO</a>.</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">Riduci i Costi di Valutazione LLM di un Fattore 140!</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., &amp; Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>Sì, hai sentito bene. Con questo trucco, il costo della Valutazione LLM può essere ridotto a una minima frazione.</p><p>L'idea centrale è semplice: Rimuovere tutti i campioni di valutazione che testano la stessa capacità del modello. La matematica dietro è meno diretta ma ben spiegata da <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a> che ha presentato il suo lavoro durante la sessione poster. Da notare che la riduzione di un fattore 140 si applica al popolare dataset MMLU (Massive Multitask Language Understanding). Per i tuoi dataset di valutazione, dipende da quanto i risultati della valutazione dei campioni correlano tra loro. Forse puoi saltare molti campioni o solo pochi.</p><p>Provalo. Ti terremo aggiornato su quanto noi di <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> siamo riusciti a ridurre i campioni di valutazione.</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">Contrastare Rappresentazioni Multiple con il Multi-Marginal Matching Gap</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., &amp; Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Research paper diagram illustrating Multi-Marginal Matching Gap concepts, with titles, descriptions, and flow charts in blue \" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Questo lavoro affronta una sfida comune nell'apprendimento contrastivo: La maggior parte delle funzioni di loss contrastive come la InfoNCE loss operano su coppie di punti dati e misurano la distanza tra coppie positive. Per espandere su tuple positive di dimensione k > 2, l'apprendimento contrastivo di solito cerca di ridurre il problema a multiple coppie e accumulare perdite a coppie per tutte le coppie positive. Gli autori qui propongono la loss M3G (Multi-Marginal Matching Gap), una versione modificata dell'algoritmo di Sinkhorn, che risolve il problema del Trasporto Ottimale Multi-Marginale. Questa funzione di loss può essere utilizzata in scenari dove i dataset consistono in tuple positive con dimensione k > 2, per esempio, >2 immagini dello stesso oggetto, problemi multi-modali con tre o più modalità, o un'estensione SimCLR con tre o più augmentazioni della stessa immagine. I risultati empirici mostrano che questo metodo supera la riduzione ingenua del problema a coppie.</p><h3 id=\"no-need-for-ground-truth\">Non Serve la Ground Truth!</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p><a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a> dalla <a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">Stanford University</a> ha presentato il suo lavoro sulla valutazione del tuo LLM senza dati etichettati. Da notare che sebbene questo sia un lavoro teorico, ha molto potenziale per la supervisione scalabile di sistemi AI avanzati. Non è per utenti casuali di LLM, ma se lavori sulla valutazione LLM è sicuramente qualcosa da approfondire. Possiamo già vedere che potremmo valutare i nostri agenti a Jina AI in questo modo. Condivideremo i risultati una volta eseguiti i primi esperimenti.</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">Il Collasso del Modello è Inevitabile? Rompere la Maledizione della Ricorsione Accumulando Dati Reali e Sintetici</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration of two machine learning data processes: &quot;Replace Data&quot; and &quot;Accumulate Data&quot;, with detailed flowcharts and model\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Diversi articoli (come questo articolo di <a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em></a>) hanno recentemente previsto che le prestazioni dei nuovi modelli addestrati potrebbero peggiorare nel tempo poiché i dati di training acquisiti dal web contengono una quantità sempre maggiore di dati sintetici.</p><p>Il nostro collega Scott Martens ha anche pubblicato <a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">un articolo sul collasso dei modelli</a> e ha discusso i casi in cui i dati sintetici possono essere utili per l'addestramento dei modelli.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>L'addestramento dei modelli potrebbe collassare perché i dati di training sono prodotti da una versione precedente del modello o da un modello addestrato sugli stessi dati. Questo studio conduce esperimenti che mostrano un quadro leggermente diverso: il collasso avviene solo quando si sostituiscono i dati reali con quelli sintetici, come è stato fatto negli esperimenti precedenti. Tuttavia, quando si aumentano i dati reali con dati sintetici aggiuntivi, non si misura alcun cambiamento nelle prestazioni dei modelli risultanti. Questi risultati suggeriscono che un fenomeno come il collasso del modello non si verificherà. Tuttavia, dimostra nuovamente che l'utilizzo di dati sintetici aggiuntivi non aiuterà ad addestrare un modello che sia generalmente superiore al modello utilizzato per creare tali punti dati sintetici.</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">La Chirurgia Cerebrale per l'AI è Ora Possibile</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., &amp; Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>Supponiamo che si voglia prevedere la professione di qualcuno ma non il loro genere. Questo lavoro di Google Research, ETH Zürich, International Institute of Information Technology Hyderabad (IIITH) e Bar-Ilan University mostra come i vettori di steering e il covariance matching possano essere utilizzati per controllare il bias.</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - Recupero di Immagini Auto-Supervisionato con Istruzioni Aperte</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., &amp; Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Questo articolo presenta i modelli MagicLens, una serie di modelli di recupero immagini auto-supervisionati addestrati su triplette di immagine di query + istruzione + immagine target.</p><p>Gli autori introducono una pipeline di raccolta/cura dei dati che raccoglie coppie di immagini dal web e utilizza LLM per sintetizzare istruzioni testuali aperte che collegano le immagini con diverse relazioni semantiche oltre la semplice somiglianza visiva. Questa pipeline viene utilizzata per produrre 36,7M di triplette di alta qualità su un'ampia distribuzione. Il dataset viene poi utilizzato per addestrare una semplice architettura dual-encoder con parametri condivisi. Gli encoder di base per visione e linguaggio sono inizializzati con varianti CoCa o CLIP base e large. Viene introdotto un singolo pooler di attenzione multi-head per comprimere i due input multimodali in un singolo embedding. L'obiettivo di training contrasta la coppia query-immagine e istruzione con l'immagine target e l'istruzione stringa vuota con una semplice loss InfoNCE per addestrare MagicLens. Gli autori presentano i risultati di valutazione sul recupero di immagini basato su istruzioni.</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - Il Nuovo Modo di Fare Prompting</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., &amp; Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>Il modo in cui facciamo prompting agli LLM sta cambiando. Il Prompt Sketching ci permette di dare vincoli fissi ai modelli generativi. Invece di fornire solo un'istruzione e sperare che il modello faccia ciò che vogliamo, definiamo un template completo, forzando il modello a generare ciò che vogliamo.</p><p>Non confonderlo con gli LLM fine-tunati per fornire un formato JSON strutturato. Con l'approccio fine-tuning, il modello ha ancora la libertà di generare quello che vuole. Non è così con il Prompt Sketching. Fornisce una toolbox completamente nuova per i prompt engineer e apre aree di ricerca che devono essere esplorate. Nel video sopra, Mark Müller spiega in dettaglio di cosa tratta questo nuovo paradigma.</p><p>Puoi anche dare un'occhiata al <a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">loro progetto open-source LMQL</a>.</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - Recupero Selettivo per il Completamento del Codice a Livello Repository</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., &amp; Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>Per molte query, il RAG non aiuta realmente il modello perché la query è troppo semplice o il sistema di recupero non riesce a trovare documenti rilevanti, possibilmente perché non ce ne sono. Questo porta a tempi di generazione più lunghi e prestazioni inferiori se il modello si basa su fonti fuorvianti o assenti.</p><p>Questo articolo affronta il problema permettendo agli LLM di auto-valutare se il recupero è utile. Dimostrano questo approccio su un modello di completamento del codice che è addestrato a riempire un gap in un template di codice. Per un dato template, il sistema prima decide se i risultati del recupero sono utili e, in caso affermativo, chiama il retriever. Infine, il LLM per il codice genera il contesto mancante che i risultati del recupero siano stati aggiunti o meno al suo prompt.</p><h3 id=\"the-platonic-representation-hypothesis\">L'Ipotesi della Rappresentazione Platonica</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., &amp; Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration of &quot;The Platonic Representation Hypothesis&quot; with geometric shapes, mathematical text, and diagrams explaining a \" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p>L'<em>Ipotesi della Rappresentazione Platonica</em> sostiene che i modelli di reti neurali tenderanno a convergere verso una rappresentazione comune del mondo. Prendendo spunto dalla <a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">Teoria delle Forme di Platone</a>, l'idea che esista un regno degli \"ideali\", che ci appare in forma distorta e che possiamo osservare solo indirettamente, gli autori affermano che i nostri modelli AI sembrano convergere verso una singola rappresentazione della realtà, indipendentemente dall'architettura di training, dai dati di training o persino dalla modalità di input. Più grande è la scala dei dati e la dimensione del modello, più simili sembrano diventare le loro rappresentazioni.</p><p>Gli autori considerano le rappresentazioni vettoriali e misurano l'allineamento delle rappresentazioni utilizzando metriche di allineamento del kernel, in particolare una metrica di mutuo vicinato più prossimo che misura l'intersezione media degli insiemi di <em>k</em>-vicini più prossimi indotti da due kernel, <em>K1</em> e <em>K2</em>, normalizzata per <em>k</em>. Questo lavoro presenta evidenze empiriche che mostrano come, con l'aumentare delle dimensioni del modello e del dataset e il miglioramento delle prestazioni, i kernel diventino più allineati. Questo allineamento può essere osservato anche quando si confrontano modelli di diverse modalità, come modelli di testo e modelli di immagini.</p><h2 id=\"summary\">Riepilogo</h2><p>Parte dell'entusiasmo iniziale che ha accompagnato la legge di scaling sta iniziando a diminuire, ma ICML 2024 ha dimostrato che così tanto nuovo, diverso e creativo talento è entrato nel nostro campo che possiamo essere certi che il progresso è ben lungi dall'essere finito.</p><p>Ci siamo divertiti molto a ICML 2024 e potete scommettere che torneremo nel 2025 🇨🇦.</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "Ci siamo divertiti tantissimo all'ICML 2024 a Vienna, e vogliamo condividere con voi tutto ciò che abbiamo detto, visto e imparato.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}