{
  "slug": "binary-embeddings-all-the-ai-3125-of-the-fat",
  "id": "662665537f510100015daa2d",
  "uuid": "bf2c8db3-bd7f-4b78-8054-4edd26349ec2",
  "title": "Binary Embeddings: tutti i vantaggi dell'AI con il 3,125% del peso",
  "html": "<p>Gli embeddings sono diventati la pietra angolare di una varietà di applicazioni di AI ed elaborazione del linguaggio naturale, offrendo un modo per rappresentare i significati dei testi come vettori multidimensionali. Tuttavia, tra le dimensioni crescenti dei modelli e le quantità sempre maggiori di dati elaborati dai modelli AI, le esigenze computazionali e di archiviazione per gli embeddings tradizionali sono aumentate. Gli embeddings binari sono stati introdotti come alternativa compatta ed efficiente che mantiene prestazioni elevate riducendo drasticamente i requisiti di risorse.</p><p>Gli embeddings binari sono un modo per mitigare questi requisiti di risorse riducendo la dimensione dei vettori di embedding fino al 96% (96,875% nel caso di Jina Embeddings). Gli utenti possono sfruttare la potenza degli embeddings binari compatti nelle loro applicazioni AI con una perdita minima di accuratezza.</p><h2 id=\"what-are-binary-embeddings\">Cosa Sono gli Embeddings Binari?</h2><p>Gli embeddings binari sono una forma specializzata di rappresentazione dei dati in cui i tradizionali vettori in virgola mobile multidimensionali vengono trasformati in vettori binari. Questo non solo comprime gli embeddings ma mantiene anche quasi tutta l'integrità e l'utilità dei vettori. L'essenza di questa tecnica risiede nella sua capacità di mantenere la semantica e le distanze relazionali tra i punti dati anche dopo la conversione.<br><br>La magia dietro gli embeddings binari è la quantizzazione, un metodo che trasforma numeri ad alta precisione in numeri a precisione inferiore. Nella modellazione AI, questo spesso significa convertire i numeri in virgola mobile a 32 bit negli embeddings in rappresentazioni con meno bit, come interi a 8 bit.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/04/be.jpeg\" class=\"kg-image\" alt=\"Comparison of Hokusai's Great Wave print in color and black &amp; white, highlighting the wave's dynamism and detail.\" loading=\"lazy\" width=\"1280\" height=\"860\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/04/be.jpeg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/04/be.jpeg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/04/be.jpeg 1280w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">La binarizzazione è la trasformazione di tutti i valori scalari in 0 o 1, come convertire un'immagine a colori in una con solo pixel bianchi o neri. Immagine: 神奈川沖浪裏 (1831) di 葛飾 (Hokusai)</span></figcaption></figure><p>Gli embeddings binari portano questo all'estremo, riducendo ogni valore a 0 o 1. Trasformare numeri in virgola mobile a 32 bit in cifre binarie riduce la dimensione dei vettori di embedding di 32 volte, una riduzione del 96,875%. Le operazioni vettoriali sugli embeddings risultanti sono molto più veloci di conseguenza. Utilizzando le accelerazioni hardware disponibili su alcuni microchip si può aumentare la velocità dei confronti vettoriali di molto più di 32 volte quando i vettori sono binarizzati.</p><p>Alcune informazioni vengono inevitabilmente perse durante questo processo, ma questa perdita è minimizzata quando il modello è molto performante. Se gli embeddings non quantizzati di cose diverse sono massimamente differenti, allora è più probabile che la binarizzazione preservi bene quella differenza. Altrimenti, può essere difficile interpretare correttamente gli embeddings.</p><p>I modelli Jina Embeddings sono addestrati per essere molto robusti proprio in questo modo, rendendoli ben adatti alla binarizzazione.</p><p>Questi embeddings compatti rendono possibili nuove applicazioni AI, in particolare in contesti con risorse limitate come gli usi mobili e time-sensitive.</p><p>Questi benefici in termini di costi e tempi di calcolo comportano un costo relativamente piccolo in termini di prestazioni, come mostra il grafico seguente.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackmd.io/_uploads/ByhwJsQWC.png\" class=\"kg-image\" alt=\"image\" loading=\"lazy\" width=\"1686\" height=\"1050\"><figcaption><i><em class=\"italic\" style=\"white-space: pre-wrap;\">NDCG@10: Punteggi calcolati usando </em></i><a href=\"https://en.wikipedia.org/wiki/Discounted_cumulative_gain?ref=jina-ai-gmbh.ghost.io\"><i><em class=\"italic\" style=\"white-space: pre-wrap;\">Normalized Discounted Cumulative Gain</em></i></a><i><em class=\"italic\" style=\"white-space: pre-wrap;\"> per i primi 10 risultati.</em></i></figcaption></figure><p>Per <code>jina-embeddings-v2-base-en</code>, la quantizzazione binaria riduce l'accuratezza di recupero dal 47,13% al 42,05%, una perdita di circa il 10%. Per <code>jina-embeddings-v2-base-de</code>, questa perdita è solo del 4%, dal 44,39% al 42,65%.</p><p>I modelli Jina Embeddings funzionano così bene quando producono vettori binari perché sono addestrati per creare una distribuzione più uniforme degli embeddings. Questo significa che due embeddings diversi saranno probabilmente più distanti l'uno dall'altro in più dimensioni rispetto agli embeddings di altri modelli. Questa proprietà assicura che quelle distanze siano meglio rappresentate dalle loro forme binarie.</p><h2 id=\"how-do-binary-embeddings-work\">Come Funzionano gli Embeddings Binari?</h2><p>Per vedere come funziona, consideriamo tre embeddings: <em>A</em>, <em>B</em> e <em>C</em>. Questi tre sono tutti vettori in virgola mobile completi, non binarizzati. Ora, supponiamo che la distanza da <em>A</em> a <em>B</em> sia maggiore della distanza da <em>B</em> a <em>C</em>. Con gli embeddings, tipicamente usiamo la <a href=\"https://en.wikipedia.org/wiki/Cosine_similarity?ref=jina-ai-gmbh.ghost.io\">distanza del coseno</a>, quindi: </p><p>$\\cos(A,B) &gt; \\cos(B,C)$</p><p>Se binarizziamo <em>A</em>, <em>B</em> e <em>C</em>, possiamo misurare la distanza più efficientemente con la <a href=\"https://en.wikipedia.org/wiki/Hamming_distance?ref=jina-ai-gmbh.ghost.io\">distanza di Hamming</a>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image-6.png\" class=\"kg-image\" alt=\"Geometric diagrams with labeled circles A, B, and C connected by lines against a contrasting background.\" loading=\"lazy\" width=\"2000\" height=\"808\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/image-6.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/image-6.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/image-6.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/05/image-6.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Distanza di Hamming su un cubo. Sinistra: La distanza da A a B è 1. Destra: La distanza da B a C è 2.</span></figcaption></figure><p>Chiamiamo <em>A<sub>bin</sub></em>, <em>B<sub>bin</sub></em> e <em>C<sub>bin</sub></em> le versioni binarizzate di <em>A</em>, <em>B</em> e <em>C</em>.</p>\n<p>Per i vettori binari, se la distanza del coseno tra <em>A<sub>bin</sub></em> e <em>B<sub>bin</sub></em> è maggiore di quella tra <em>B<sub>bin</sub></em> e <em>C<sub>bin</sub></em>, allora la distanza di Hamming tra <em>A<sub>bin</sub></em> e <em>B<sub>bin</sub></em> è maggiore o uguale alla distanza di Hamming tra <em>B<sub>bin</sub></em> e <em>C<sub>bin</sub></em>.</p>\n<p>Quindi se: </p><p>$\\cos(A,B) &gt; \\cos(B,C)$</p><p>allora per le distanze di Hamming: </p><p>$hamm(A{bin}, B{bin}) \\geq hamm(B{bin}, C{bin})$</p><p>Idealmente, quando binarizziamo gli embeddings, vogliamo che le stesse relazioni con gli embeddings completi valgano per gli embeddings binari come per quelli completi. Questo significa che se una distanza è maggiore di un'altra per il coseno in virgola mobile, dovrebbe essere maggiore per la distanza di Hamming tra i loro equivalenti binarizzati:</p><p>$\\cos(A,B) &gt; \\cos(B,C) \\Rightarrow hamm(A{bin}, B{bin}) \\geq hamm(B{bin}, C{bin})$</p><p>Non possiamo rendere questo vero per tutte le triplette di embeddings, ma possiamo renderlo vero per quasi tutte.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image-8.png\" class=\"kg-image\" alt=\"Graph with labeled points A and B, connected by lines marked as 'hamm AB' and 'cos AB', on a black background.\" loading=\"lazy\" width=\"1500\" height=\"1184\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/image-8.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/image-8.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/image-8.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">I punti blu corrispondono ai vettori in virgola mobile completi e quelli rossi ai loro equivalenti binarizzati. </span></figcaption></figure><p>Con un vettore binario, possiamo trattare ogni dimensione come presente (uno) o assente (zero). Più distanti sono due vettori l'uno dall'altro in forma non binaria, maggiore è la probabilità che in una qualsiasi dimensione, uno abbia un valore positivo e l'altro un valore negativo. Questo significa che in forma binaria, ci saranno molto probabilmente più dimensioni dove uno ha uno zero e l'altro un uno. Questo li rende più distanti secondo la distanza di Hamming.</p><p>L'opposto si applica ai vettori che sono più vicini tra loro: Più vicini sono i vettori non binari, maggiore è la probabilità che in qualsiasi dimensione entrambi abbiano zeri o entrambi abbiano uno. Questo li rende più vicini secondo la distanza di Hamming.</p><p>I modelli Jina Embeddings sono così ben adatti alla binarizzazione perché li addestriamo usando il negative mining e altre pratiche di fine-tuning per aumentare particolarmente la distanza tra cose dissimili e ridurre la distanza tra quelle simili. Questo rende gli embeddings più robusti, più sensibili alle somiglianze e differenze, e rende la distanza di Hamming tra embeddings binari più proporzionale alla distanza del coseno tra quelli non binari.</p><h2 id=\"how-much-can-i-save-with-jina-ais-binary-embeddings\">Quanto Posso Risparmiare con gli Embeddings Binari di Jina AI?</h2><p>Adottare i modelli di embedding binario di Jina AI non solo riduce la latenza nelle applicazioni time-sensitive, ma produce anche considerevoli benefici in termini di costi, come mostrato nella tabella seguente:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Modello</th>\n<th>Memoria per<br/>250 milioni<br/>di embeddings</th>\n<th>Media del<br/>benchmark<br/>di recupero</th>\n<th>Prezzo stimato su AWS<br/>($3.8 per GB/mese<br/>con istanze x2gb)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Embeddings in virgola mobile a 32 bit</td>\n<td>715 GB</td>\n<td>47.13</td>\n<td>$35,021</td>\n</tr>\n<tr>\n<td>Embeddings binari</td>\n<td>22.3 GB</td>\n<td>42.05</td>\n<td>$1,095</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><p>Questo risparmio di oltre il 95% è accompagnato da una riduzione di solo ~10% nell'accuratezza di recupero.</p><p>Questi risparmi sono ancora maggiori rispetto all'utilizzo di vettori binarizzati da <a href=\"https://platform.openai.com/docs/guides/embeddings/embedding-models?ref=jina-ai-gmbh.ghost.io\">OpenAI Ada 2 model</a> o <a href=\"https://cohere.com/blog/introducing-embed-v3?ref=jina-ai-gmbh.ghost.io\">Cohere Embed v3</a>, entrambi i quali producono embedding di output di 1024 dimensioni o più. Gli embedding di Jina AI hanno solo 768 dimensioni e mantengono prestazioni paragonabili ad altri modelli, rendendoli più piccoli anche prima della quantizzazione per la stessa accuratezza.</p><div class=\"kg-card kg-callout-card kg-callout-card-white\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\"><b><strong style=\"white-space: pre-wrap;\">I vettori binari permettono di risparmiare memoria, tempo di calcolo, larghezza di banda di trasmissione e spazio su disco, fornendo benefici economici in diverse categorie</strong></b>. </div></div><p>Questi risparmi sono anche ambientali, utilizzando meno materiali rari e meno energia.</p><h2 id=\"get-started\">Per Iniziare</h2><p>Per ottenere embedding binari utilizzando la <a href=\"https://jina.ai/embveddings?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">Jina Embeddings API</a>, basta aggiungere il parametro <code>encoding_type</code> alla tua chiamata API, con il valore <code>binary</code> per ottenere l'embedding binarizzato codificato come interi con segno, o <code>ubinary</code> per interi senza segno.</p><h3 id=\"directly-access-jina-embedding-api\">Accesso Diretto alla Jina Embedding API</h3><p>Usando <code>curl</code>:</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer &lt;YOUR API KEY&gt;\" \\\n  -d '{\n    \"input\": [\"Your text string goes here\", \"You can send multiple texts\"],\n    \"model\": \"jina-embeddings-v2-base-en\",\n    \"encoding_type\": \"binary\"\n  }'\n</code></pre><p>O tramite l'API Python <code>requests</code>:</p><pre><code class=\"language-Python\">import requests\n\nheaders = {\n  \"Content-Type\": \"application/json\",\n  \"Authorization\": \"Bearer &lt;YOUR API KEY&gt;\"\n}\n\ndata = {\n  \"input\": [\"Your text string goes here\", \"You can send multiple texts\"],\n  \"model\": \"jina-embeddings-v2-base-en\",\n  \"encoding_type\": \"binary\",\n}\n\nresponse = requests.post(\n    \"https://api.jina.ai/v1/embeddings\", \n    headers=headers, \n    json=data,\n)\n</code></pre><p>Con la richiesta Python sopra, otterrai la seguente risposta ispezionando <code>response.json()</code>:</p><pre><code class=\"language-JSON\">{\n  \"model\": \"jina-embeddings-v2-base-en\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"total_tokens\": 14,\n    \"prompt_tokens\": 14\n  },\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"index\": 0,\n      \"embedding\": [\n        -0.14528547,\n        -1.0152762,\n        ...\n      ]\n    },\n    {\n      \"object\": \"embedding\",\n      \"index\": 1,\n      \"embedding\": [\n        -0.109809875,\n        -0.76077706,\n        ...\n      ]\n    }\n  ]\n}\n</code></pre><p>Questi sono due vettori di embedding binari memorizzati come 96 interi a 8 bit con segno. Per decomprimerli in 768 0 e 1, devi utilizzare la libreria <code>numpy</code>:</p><pre><code class=\"language-Python\">import numpy as np\n\n# assign the first vector to embedding0\nembedding0 = response.json()['data'][0]['embedding']\n\n# convert embedding0 to a numpy array of unsigned 8-bit ints\nuint8_embedding = np.array(embedding0).astype(numpy.uint8) \n\n# unpack to binary\nnp.unpackbits(uint8_embedding)\n</code></pre><p>Il risultato è un vettore di 768 dimensioni con solo 0 e 1:</p><pre><code class=\"language-Python\">array([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n      dtype=uint8)\n</code></pre><h3 id=\"using-binary-quantization-in-qdrant\">Utilizzo della Quantizzazione Binaria in Qdrant</h3><p>Puoi anche utilizzare la <a href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\">libreria di integrazione di Qdrant</a> per inserire direttamente gli embedding binari nel tuo vector store Qdrant. Poiché Qdrant ha implementato internamente <code>BinaryQuantization</code>, puoi utilizzarlo come configurazione preimpostata per l'intera collezione di vettori, consentendogli di recuperare e memorizzare vettori binari senza altre modifiche al tuo codice.</p><p>Vedi il codice di esempio qui sotto per come fare:</p><pre><code class=\"language-Python\">import qdrant_client\nimport requests\n\nfrom qdrant_client.models import Distance, VectorParams, Batch, BinaryQuantization, BinaryQuantizationConfig\n\n# Fornisci la chiave API di Jina e scegli uno dei modelli disponibili.\n# Puoi ottenere una chiave di prova gratuita qui: https://jina.ai/embeddings/\nJINA_API_KEY = \"jina_xxx\"\nMODEL = \"jina-embeddings-v2-base-en\"  # o \"jina-embeddings-v2-base-en\"\nEMBEDDING_SIZE = 768  # 512 per la variante small\n\n# Ottieni gli embedding dall'API\nurl = \"https://api.jina.ai/v1/embeddings\"\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {JINA_API_KEY}\",\n}\n\ntext_to_encode = [\"Il tuo testo va qui\", \"Puoi inviare testi multipli\"]\ndata = {\n    \"input\": text_to_encode,\n    \"model\": MODEL,\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nembeddings = [d[\"embedding\"] for d in response.json()[\"data\"]]\n\n\n# Indicizza gli embedding in Qdrant\nclient = qdrant_client.QdrantClient(\":memory:\")\nclient.create_collection(\n    collection_name=\"MyCollection\",\n    vectors_config=VectorParams(size=EMBEDDING_SIZE, distance=Distance.DOT, on_disk=True),\n    quantization_config=BinaryQuantization(binary=BinaryQuantizationConfig(always_ram=True)),\n)\n\nclient.upload_collection(\n    collection_name=\"MyCollection\",\n    ids=list(range(len(embeddings))),\n    vectors=embeddings,\n    payload=[\n            {\"text\": x} for x in text_to_encode\n    ],\n)</code></pre><p>Per configurare la ricerca, dovresti utilizzare i parametri <code>oversampling</code> e <code>rescore</code>:</p><pre><code class=\"language-python\">from qdrant_client.models import SearchParams, QuantizationSearchParams\n\nresults = client.search(\n    collection_name=\"MyCollection\",\n    query_vector=embeddings[0],\n    search_params=SearchParams(\n        quantization=QuantizationSearchParams(\n            ignore=False,\n            rescore=True,\n            oversampling=2.0,\n        )\n    )\n)</code></pre><h3 id=\"using-llamaindex\">Utilizzo di LlamaIndex</h3><p>Per utilizzare gli embedding binari di Jina con LlamaIndex, imposta il parametro <code>encoding_queries</code> su <code>binary</code> quando istanzi l'oggetto <code>JinaEmbedding</code>:</p><pre><code class=\"language-python\">from llama_index.embeddings.jinaai import JinaEmbedding\n\n# Puoi ottenere una chiave di prova gratuita da https://jina.ai/embeddings/\nJINA_API_KEY = \"&lt;LA TUA CHIAVE API&gt;\"\n\njina_embedding_model = JinaEmbedding(\n    api_key=jina_ai_api_key,\n    model=\"jina-embeddings-v2-base-en\",\n    encoding_queries='binary',\n    encoding_documents='float'\n)\n\njina_embedding_model.get_query_embedding('Testo della query qui')\njina_embedding_model.get_text_embedding_batch(['X', 'Y', 'Z'])\n</code></pre><h3 id=\"other-vector-databases-supporting-binary-embeddings\">Altri Database Vettoriali che Supportano gli Embedding Binari</h3><p>I seguenti database vettoriali forniscono supporto nativo per i vettori binari:</p><ul><li><a href=\"https://thenewstack.io/why-vector-size-matters/?ref=jina-ai-gmbh.ghost.io\">AstraDB di DataStax</a></li><li><a href=\"https://github.com/facebookresearch/faiss/wiki/Binary-indexes?ref=jina-ai-gmbh.ghost.io\">FAISS</a></li><li><a href=\"https://milvus.io/docs/index.md?ref=cohere-ai.ghost.io#BIN_IVF_FLAT\">Milvus</a></li><li><a href=\"https://blog.vespa.ai/billion-scale-knn/?ref=jina-ai-gmbh.ghost.io\">Vespa.ai</a></li><li><a href=\"https://weaviate.io/developers/weaviate/configuration/bq-compression?ref=jina-ai-gmbh.ghost.io\">Weaviate</a></li></ul><h2 id=\"example\">Esempio</h2><p>Per mostrarti gli embedding binari in azione, abbiamo preso una selezione di abstract da <a href=\"http://arxiv.org/?ref=jina-ai-gmbh.ghost.io\">arXiv.org</a>, e abbiamo ottenuto sia vettori a virgola mobile a 32 bit che vettori binari utilizzando <code>jina-embeddings-v2-base-en</code>. Li abbiamo poi confrontati con gli embedding per una query di esempio: \"3D segmentation\".</p><p>Come puoi vedere dalla tabella seguente, le prime tre risposte sono le stesse e quattro delle prime cinque corrispondono. L'utilizzo di vettori binari produce corrispondenze quasi identiche.</p>\n<!--kg-card-begin: html-->\n<table>\n<head>\n<tr>\n  <th/>\n  <th colspan=\"2\">Binary</th>\n  <th colspan=\"2\">32-bit Float</th>\n</tr>\n<tr>\n<th>Rank</th>\n<th>Hamming<br/>dist.</th>\n<th>Matching Text</th>\n<th>Cosine</th>\n<th>Matching text</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0.1862</td>\n<td>SEGMENT3D: A Web-based<br/>Application for Collaboration...</td>\n<td>0.2340</td>\n<td>SEGMENT3D: A Web-based<br/>Application for Collaboration...</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0.2148</td>\n<td>Segmentation-by-Detection:<br/>A Cascade Network for...</td>\n<td>0.2857</td>\n<td>Segmentation-by-Detection:<br/>A Cascade Network for...</td>\n</tr>\n<tr>\n<td>3</td>\n<td>0.2174</td>\n<td>Vox2Vox: 3D-GAN for Brain<br/>Tumour Segmentation...</td>\n<td>0.2973</td>\n<td>Vox2Vox: 3D-GAN for Brain<br/>Tumour Segmentation...</td>\n</tr>\n<tr>\n<td>4</td>\n<td>0.2318</td>\n<td>DiNTS: Differentiable Neural<br/>Network Topology Search...</td>\n<td>0.2983</td>\n<td>Anisotropic Mesh Adaptation for<br/>Image Segmentation...</td>\n</tr>\n<tr>\n<td>5</td>\n<td>0.2331</td>\n<td>Data-Driven Segmentation of<br/>Post-mortem Iris Image...</td>\n<td>0.3019</td>\n<td>DiNTS: Differentiable Neural<br/>Network Topology...</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"\"></h2>",
  "comment_id": "662665537f510100015daa2d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/04/Blog-images.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-04-22T15:25:39.000+02:00",
  "updated_at": "2024-10-22T07:51:49.000+02:00",
  "published_at": "2024-05-15T16:00:57.000+02:00",
  "custom_excerpt": "32-bits is a lot of precision for something as robust and inexact as an AI model. So we got rid of 31 of them! Binary embeddings are smaller, faster and highly performant.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "65b22f4a8da8040001e173ba",
      "name": "Sofia Vasileva",
      "slug": "sofia",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/04/sofia-profile-pic.jpeg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/sofia/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "65b22f4a8da8040001e173ba",
    "name": "Sofia Vasileva",
    "slug": "sofia",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/04/sofia-profile-pic.jpeg",
    "cover_image": null,
    "bio": null,
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/sofia/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/binary-embeddings-all-the-ai-3125-of-the-fat/",
  "excerpt": "32-bit sono fin troppo precisi per qualcosa di così robusto e inesatto come un modello di AI. Quindi ne abbiamo eliminati 31! Gli embedding binari sono più piccoli, più veloci e altamente performanti.",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Futuristic digital 3D model of a coffee grinder with blue neon lights on a black background, featuring numerical data.",
  "feature_image_caption": null
}