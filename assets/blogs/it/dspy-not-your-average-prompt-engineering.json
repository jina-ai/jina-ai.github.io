{
  "slug": "dspy-not-your-average-prompt-engineering",
  "id": "66077bf0a5c39b0001044181",
  "uuid": "e242c77c-f712-462c-9745-3e9269eb8a8b",
  "title": "DSPy: Non il solito Prompt Engineering",
  "html": "<div class=\"kg-card kg-file-card\"><a class=\"kg-file-card-container\" href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/04/DSPy-Not-Your-Average-Prompt-Engineering--1-.pdf\" title=\"Download\" download=\"\"><div class=\"kg-file-card-contents\"><div class=\"kg-file-card-title\">[Slides] DSPy: Non il solito Prompt Engineering</div><div class=\"kg-file-card-caption\">Una presentazione fatta da Han il 15 aprile 2024 a Mountain View.</div><div class=\"kg-file-card-metadata\"><div class=\"kg-file-card-filename\">DSPy Not Your Average Prompt Engineering (1).pdf</div><div class=\"kg-file-card-filesize\">7 MB</div></div></div><div class=\"kg-file-card-icon\"><svg viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"></polyline><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"></line><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"></circle></svg></div></a></div><p>Recentemente ho esaminato DSPy, un framework all'avanguardia sviluppato dal gruppo Stanford NLP volto all'ottimizzazione algoritmica dei prompt per i modelli linguistici (LM). Negli ultimi tre giorni, ho raccolto alcune prime impressioni e spunti preziosi su DSPy. Si noti che le mie osservazioni non intendono sostituire la documentazione ufficiale di DSPy. In effetti, consiglio vivamente di leggere <a href=\"https://dspy-docs.vercel.app/?ref=jina-ai-gmbh.ghost.io\">la loro documentazione</a> e il <a href=\"https://github.com/stanfordnlp/dspy/blob/main/README.md?ref=jina-ai-gmbh.ghost.io\">README</a> almeno una volta prima di approfondire questo post. La mia discussione qui riflette una comprensione preliminare di DSPy, avendo trascorso alcuni giorni ad esplorarne le capacità. Ci sono diverse funzionalità avanzate, come DSPy Assertions, Typed Predictor e il tuning dei pesi LM, che non ho ancora esplorato a fondo.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/stanfordnlp/dspy?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - stanfordnlp/dspy: DSPy: The framework for programming—not prompting—foundation models</div><div class=\"kg-bookmark-description\">DSPy: The framework for programming—not prompting—foundation models - stanfordnlp/dspy</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">stanfordnlp</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/b8c1b2b4b3ff9c22d486f5c69dbda5fee6cc8dda8a42aaf1c2e154c17b7dc159/stanfordnlp/dspy\" alt=\"\"></div></a></figure><p>Nonostante il mio background con Jina AI, che si concentra principalmente sulle fondamenta della ricerca, il mio interesse per DSPy non è stato direttamente guidato dal suo potenziale nella Retrieval-Augmented Generation (RAG). Piuttosto, ero incuriosito dalla possibilità di sfruttare DSPy per il tuning automatico dei prompt per affrontare alcuni task di generazione.</p><p>Se sei nuovo a DSPy e cerchi un punto di ingresso accessibile, o se hai già familiarità con il framework ma trovi la documentazione ufficiale confusa o travolgente, questo articolo è pensato per te. Ho anche scelto di <em>non</em> aderire strettamente all'idioma di DSPy, che potrebbe sembrare scoraggiante per i principianti. Detto questo, approfondiamo.</p><h2 id=\"what-i-like-about-dspy\">Cosa mi piace di DSPy</h2><h3 id=\"dspy-closing-the-loop-of-prompt-engineering\">DSPy chiude il ciclo del Prompt Engineering</h3><p>Ciò che mi entusiasma di più di DSPy è il suo approccio alla chiusura del ciclo del prompt engineering, trasformando quello che spesso è un processo <em>manuale</em>, <em>artigianale</em> in un workflow di machine learning <em>strutturato</em> e <em>ben definito</em>: ovvero preparare dataset, definire il modello, addestrare, valutare e testare. <strong>A mio parere, questo è l'aspetto più rivoluzionario di DSPy.</strong></p><p>Viaggiando nella Bay Area e parlando con molti founder di startup focalizzate sulla valutazione degli LLM, ho incontrato frequenti discussioni su metriche, allucinazioni, osservabilità e compliance. Tuttavia, queste conversazioni spesso non progrediscono verso i passaggi critici successivi: <strong>Con tutte queste metriche in mano, cosa facciamo dopo?</strong> Può modificare la formulazione nei nostri prompt, nella speranza che certe parole magiche (ad esempio \"mia nonna sta morendo\") possano migliorare le nostre metriche, essere considerato un approccio strategico? Questa domanda è rimasta senza risposta da parte di molte startup di valutazione LLM, ed era una domanda a cui non potevo rispondere nemmeno io, fino a quando non ho scoperto DSPy. DSPy introduce un metodo chiaro e programmatico per ottimizzare i prompt basati su metriche specifiche, o persino per ottimizzare l'intera pipeline LLM, inclusi sia i prompt che i pesi LLM.</p><p>Harrison, il CEO di LangChain, e Logan, l'ex Head of Developer Relations di OpenAI, hanno entrambi affermato nel <a href=\"https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924?ref=jina-ai-gmbh.ghost.io\">podcast Unsupervised Learning</a> che il 2024 sarà un anno cruciale per la valutazione degli LLM. È per questo motivo che credo che DSPy meriti più attenzione di quella che sta ricevendo ora, poiché DSPy fornisce il cruciale pezzo mancante del puzzle.</p><h3 id=\"dspy-separating-logic-from-textual-representation\">DSPy separa la logica dalla rappresentazione testuale</h3><p>Un altro aspetto di DSPy che mi impressiona è che formula il prompt engineering in un modulo riproducibile e LLM-agnostico. Per raggiungere questo obiettivo, <strong>estrae la logica dal prompt, creando una chiara separazione delle responsabilità tra la <em>logica</em> e la <em>rappresentazione testuale</em></strong>, come illustrato di seguito.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png\" class=\"kg-image\" alt=\"Flowchart depicting sentiment analysis process with steps such as Prompt, Logic, and Textual Representation on a black backgr\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--5-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--5-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">In DSPy, il Prompt consiste nella logica intrinseca (cioè </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>dspy.Module</span></code><span style=\"white-space: pre-wrap;\">,) e nella sua rappresentazione testuale. La logica è immutabile, riproducibile, testabile e LLM-agnostica. La rappresentazione testuale è solo la conseguenza della logica.</span></figcaption></figure><p><strong>Il concetto di DSPy della logica come \"causa\" immutabile, testabile e LLM-agnostica, con la rappresentazione testuale meramente come sua \"conseguenza\"</strong>, può inizialmente sembrare sconcertante. Questo è particolarmente vero alla luce della diffusa convinzione che \"il futuro del linguaggio di programmazione è il linguaggio naturale.\" Abbracciando l'idea che \"il prompt engineering è il futuro\", si potrebbe sperimentare un momento di confusione nell'incontrare la filosofia di design di DSPy. Contrariamente all'aspettativa di semplificazione, DSPy introduce una serie di moduli e sintassi di signature, apparentemente facendo regredire il prompting in linguaggio naturale alla complessità della programmazione in C!</p><p>Ma perché adottare questo approccio? Secondo la mia comprensione, <strong>al cuore della programmazione dei prompt risiede la logica fondamentale, con la comunicazione che funge da amplificatore</strong>, potenzialmente migliorando o diminuendo la sua efficacia. La direttiva <code>\"Do sentiment classification\"</code> rappresenta la logica fondamentale, mentre una frase come <code>\"Follow these demonstrations or I will fire you\"</code> è un modo per comunicarla. Analogamente alle interazioni nella vita reale, le difficoltà nel portare a termine le cose spesso non derivano da una logica difettosa ma da comunicazioni problematiche. Questo spiega perché molti, in particolare i non madrelingua, trovano difficile il prompt engineering. Ho osservato ingegneri software altamente competenti nella mia azienda lottare con il prompt engineering, non per mancanza di logica, ma perché non \"parlano il linguaggio.\" Separando la logica dal prompt, <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/modules?ref=jina-ai-gmbh.ghost.io\">DSPy permette la programmazione deterministica della logica attraverso <code>dspy.Module</code></a>, consentendo agli sviluppatori di concentrarsi sulla logica nello stesso modo in cui farebbero nell'ingegneria tradizionale, indipendentemente dall'LLM utilizzato.</p><p>Quindi, se gli sviluppatori si concentrano sulla logica, chi gestisce la rappresentazione testuale? <strong>DSPy assume questo ruolo, utilizzando i tuoi dati e le metriche di valutazione per raffinare la rappresentazione testuale</strong>—tutto, dalla determinazione del focus narrativo all'ottimizzazione dei suggerimenti e alla scelta di buone dimostrazioni. Sorprendentemente, DSPy può persino utilizzare le metriche di valutazione per fare il fine-tuning dei pesi LLM!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png\" class=\"kg-image\" alt=\"Flowchart illustrating a language model with branches for training data, logic, textual representation, and final results.\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Per me, i contributi chiave di DSPy—chiudere il ciclo di training e valutazione nel prompt engineering e separare la logica dalla rappresentazione testuale—sottolineano la sua potenziale importanza per i sistemi LLM/Agent. Una visione ambiziosa sicuramente, ma decisamente necessaria!</p><h2 id=\"what-i-think-dspy-can-improve\">Cosa penso che DSPy possa migliorare</h2><p>Innanzitutto, DSPy presenta una ripida curva di apprendimento per i principianti a causa dei suoi idiomi. Termini come <code>signature</code>, <code>module</code>, <code>program</code>, <code>teleprompter</code>, <code>optimization</code> e <code>compile</code> possono essere travolgenti. Anche per coloro che sono esperti nel prompt engineering, navigare tra questi concetti all'interno di DSPy può essere un labirinto impegnativo.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Yeah, DSPy really needs someone to come in and explain everything without suitcase words. <a href=\"https://twitter.com/CShorten30?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">@CShorten30</a> does a great job, but we need more.</p>— Jonathan Mugan (@jmugan) <a href=\"https://twitter.com/jmugan/status/1773036172723236895?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">March 27, 2024</a></blockquote>\n<script async=\"\" src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></figure><p>Questa complessità riflette la mia esperienza con <a href=\"https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io\">Jina 1.0</a>, dove abbiamo introdotto una serie di idiomi come <code>chunk</code>, <code>document</code>, <code>driver</code>, <code>executor</code>, <code>pea</code>, <code>pod</code>, <code>querylang</code> e <code>flow</code> (abbiamo persino creato degli adorabili adesivi per aiutare gli utenti a ricordare!).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Document-FLAT--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pea-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/QueryLang--FLAT.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png 700w\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--3-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pod-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--5-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png 700w\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">La maggior parte di questi concetti iniziali sono stati rimossi nelle successive revisioni di Jina. Oggi, solo </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Executor</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Document</span></code><span style=\"white-space: pre-wrap;\"> e </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Flow</span></code><span style=\"white-space: pre-wrap;\"> sono sopravvissuti alla \"grande purga\". Abbiamo aggiunto un nuovo concetto, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Deployment</span></code><span style=\"white-space: pre-wrap;\">, in Jina 3.0; quindi alla fine si pareggia. 🤷</span></p></figcaption></figure><p>Questo problema non è esclusivo di DSPy o Jina; ricordiamo i molteplici concetti e astrazioni introdotti da TensorFlow tra le versioni 0.x e 1.x. Credo che questo problema emerga spesso nelle prime fasi dei framework software, dove c'è una spinta <strong>a riflettere le notazioni accademiche direttamente nel codice per garantire la massima accuratezza e riproducibilità</strong>. Tuttavia, non tutti gli utenti apprezzano tali astrazioni granulari, con preferenze che variano dal desiderio di semplici one-liner alle richieste di maggiore flessibilità. Ho discusso ampiamente questo tema dell'astrazione nei framework software in un post del blog del 2020, che i lettori interessati potrebbero trovare utile.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/?ref=jina-ai-gmbh.ghost.io#layer-of-abstraction\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Layer of Abstraction When Building \"Tensorflow\" for Search · Han Xiao Tech Blog - Neural Search &amp; AI Engineering</div><div class=\"kg-bookmark-description\">Since Feb. 2020, I started a new venture called Jina AI. Our mission is to build an open-source neural search ecosystem for businesses and developers, ... · Han Xiao</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://hanxiao.io/wechaticon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/blog-abstraction-banner.jpg\" alt=\"\"></div></a></figure><p>In secondo luogo, la documentazione di DSPy talvolta manca di coerenza. Termini come <code>module</code> e <code>program</code>, <code>teleprompter</code> e <code>optimizer</code>, o <code>optimize</code> e <code>compile</code> (a volte riferiti come <code>training</code> o <code>bootstrapping</code>) sono usati in modo intercambiabile, aumentando la confusione. Di conseguenza, ho trascorso le mie prime ore con DSPy cercando di decifrare esattamente cosa <code>optimizes</code> e in cosa consiste il processo di <code>bootstrapping</code>.</p><p>Nonostante questi ostacoli, man mano che ci si addentra in DSPy e si rivede la documentazione, è probabile che si sperimentino momenti di chiarezza in cui tutto inizia ad avere senso, rivelando le connessioni tra la sua terminologia unica e i costrutti familiari visti in framework come PyTorch. Tuttavia, DSPy ha indubbiamente margini di miglioramento nelle versioni future, in particolare nel rendere il framework più accessibile agli ingegneri dei prompt <em>senza</em> un background in PyTorch.</p><h2 id=\"common-stumbling-blocks-for-dspy-newbies\">Ostacoli Comuni per i Principianti di DSPy</h2><p>Nelle sezioni seguenti, ho compilato un elenco di domande che inizialmente hanno ostacolato il mio progresso con DSPy. Il mio obiettivo è condividere queste intuizioni nella speranza che possano chiarire sfide simili per altri studenti.</p><h3 id=\"what-are-teleprompter-optimization-and-compile-whats-exactly-being-optimized-in-dspy\">Cosa sono <code>teleprompter</code>, <code>optimization</code> e <code>compile</code>? Cosa viene esattamente ottimizzato in DSPy?</h3><p>In DSPy, \"Teleprompters\" è l'ottimizzatore (e sembra che <a href=\"https://twitter.com/lateinteraction?ref=jina-ai-gmbh.ghost.io\">@lateinteraction</a> stia aggiornando la documentazione e il codice per chiarire questo). La funzione <code>compile</code> agisce al cuore di questo ottimizzatore, simile a chiamare <code>optimizer.optimize()</code>. Pensalo come l'equivalente del training in DSPy. Questo processo di <code>compile()</code> mira a ottimizzare:</p><ul><li>le dimostrazioni few-shot,</li><li>le istruzioni,</li><li>i pesi del LLM</li></ul><p>Tuttavia, la maggior parte dei tutorial per principianti di DSPy non approfondisce l'ottimizzazione dei pesi e delle istruzioni, portando alla prossima domanda.</p><h3 id=\"whats-bootstrap-in-dspy-all-about\">Di cosa si tratta il <code>bootstrap</code> in DSPy?</h3><p>Bootstrap si riferisce alla creazione di dimostrazioni auto-generate per l'apprendimento in-context few-shot, una parte cruciale del processo <code>compile()</code> (cioè, ottimizzazione/training come ho menzionato sopra). Queste demo few-shot sono generate da dati etichettati forniti dall'utente; e una demo spesso consiste di input, output, ragionamento (ad esempio, nelle Catene di Pensiero), e input & output intermedi (per prompt multi-stadio). Naturalmente, le demo few-shot di qualità sono fondamentali per l'eccellenza dell'output. A tal fine, DSPy permette funzioni metriche definite dall'utente per garantire che vengano scelte solo le demo che soddisfano determinati criteri, portando alla prossima domanda.</p><h3 id=\"whats-dspy-metric-function\">Cos'è la funzione metrica di DSPy?</h3><p>Dopo l'esperienza pratica con DSPy, sono giunto a credere che la funzione metrica necessiti di molta più enfasi rispetto a quanto fornito dalla documentazione attuale. La funzione metrica in DSPy gioca un ruolo cruciale sia nelle fasi di valutazione che di training, fungendo anche da funzione di \"loss\", grazie alla sua natura implicita (controllata da <code>trace=None</code>):</p><pre><code class=\"language-python\">def keywords_match_jaccard_metric(example, pred, trace=None):  \n    # Jaccard similarity between example keywords and predicted keywords  \n    A = set(normalize_text(example.keywords).split())  \n    B = set(normalize_text(pred.keywords).split())  \n    j = len(A &amp; B) / len(A | B)\n    if trace is not None:\n        # act as a \"loss\" function\n        return j  \n    return j &gt; 0.8  # act as evaluation</code></pre><p>Questo approccio differisce significativamente dal machine learning tradizionale, dove la funzione di loss è solitamente continua e differenziabile (ad esempio, hinge/MSE), mentre la metrica di valutazione potrebbe essere completamente diversa e discreta (ad esempio, NDCG). In DSPy, le funzioni di valutazione e di loss sono unificate nella funzione metrica, che può essere discreta e il più delle volte restituisce un valore booleano. La funzione metrica può anche integrare un LLM! Nell'esempio seguente, ho implementato un confronto fuzzy usando LLM per determinare se il valore predetto e la risposta standard sono simili in grandezza, ad esempio, \"1 milione di dollari\" e \"$1M\" restituirebbero vero.</p><pre><code class=\"language-python\">class Assess(dspy.Signature):  \n    \"\"\"Assess the if the prediction is in the same magnitude to the gold answer.\"\"\"  \n  \n    gold_answer = dspy.InputField(desc='number, could be in natural language')  \n    prediction = dspy.InputField(desc='number, could be in natural language')  \n    assessment = dspy.OutputField(desc='yes or no, focus on the number magnitude, not the unit or exact value or wording')  \n  \ndef same_magnitude_correct(example, pred, trace=None):  \n    return dspy.Predict(Assess)(gold_answer=example.answer, prediction=pred.answer).assessment.lower() == 'yes'</code></pre><p>Per quanto potente sia, la funzione metrica influenza significativamente l'esperienza utente di DSPy, determinando non solo la valutazione finale della qualità ma influenzando anche i risultati dell'ottimizzazione. Una funzione metrica ben progettata può portare a prompt ottimizzati, mentre una mal strutturata può causare il fallimento dell'ottimizzazione. Quando si affronta un nuovo problema con DSPy, potresti ritrovarti a dedicare tanto tempo alla progettazione della logica (cioè <code>DSPy.Module</code>) quanto alla funzione metrica. Questo duplice focus su logica e metriche può essere scoraggiante per i principianti.</p>\n\n<h3 id=\"bootstrapped-0-full-traces-after-20-examples-in-round-0-what-does-this-mean\"><code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code> cosa significa?</h3>\n\n<p>Questo messaggio che appare silenziosamente durante <code>compile()</code> merita la massima attenzione, poiché significa essenzialmente che l'ottimizzazione/compilazione è fallita, e il prompt che ottieni non è migliore di un semplice few-shot. Cosa va storto? Ho riassunto alcuni suggerimenti per aiutarti a debuggare il tuo programma DSPy quando incontri questo messaggio:</p>\n\n<h4 id=\"your-metric-function-is-incorrect\">La Tua Funzione Metrica è Incorretta</h4>\n\n<p>La funzione <code>your_metric</code>, usata in <code>BootstrapFewShot(metric=your_metric)</code>, è implementata correttamente? Esegui alcuni unit test. <code>your_metric</code> restituisce mai <code>True</code>, o restituisce sempre <code>False</code>? Nota che restituire <code>True</code> è cruciale perché è il criterio che DSPy usa per considerare l'esempio bootstrappato come \"successo.\" Se restituisci ogni valutazione come <code>True</code>, allora ogni esempio viene considerato un \"successo\" nel bootstrapping! Questo non è ideale, ovviamente, ma è così che puoi regolare la rigidità della funzione metrica per cambiare il risultato <code>\"Bootstrapped 0 full traces\"</code>. Nota che sebbene la documentazione di DSPy indichi che le metriche possono restituire anche valori scalari, dopo aver esaminato il codice sottostante, non lo consiglierei ai principianti.</p>\n\n<h4 id=\"your-logic-dspymodule-is-incorrect\">La Tua Logica (<code>DSPy.Module</code>) è Incorretta</h4>\n\n<p>Se la funzione metrica è corretta, allora devi controllare se la tua logica <code>dspy.Module</code> è implementata correttamente. Prima, verifica che la <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io\">signature DSPy</a> sia correttamente assegnata per ogni step. Le signature in-line, come <code>dspy.Predict('question->answer')</code>, sono facili da usare, ma per la qualità, suggerisco fortemente di implementare con <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io#class-based-dspy-signatures\">signature basate su classi</a>. In particolare, aggiungi alcune docstring descrittive alla classe, compila i campi desc per <code>InputField</code> e <code>OutputField</code>—questi forniscono tutti suggerimenti al LM su ogni campo. Di seguito ho implementato due <code>DSPy.Module</code> multi-stage per risolvere i <a href=\"https://en.wikipedia.org/wiki/Fermi_problem?ref=jina-ai-gmbh.ghost.io\">problemi di Fermi</a>, uno con signature in-line, uno con signature basata su classi.</p>\n\n<figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiSolver(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict('question -> initial_guess')\n        self.step2 = dspy.Predict('question, initial_guess -> calculated_estimation')\n        self.step3 = dspy.Predict('question, initial_guess, calculated_estimation -> variables_and_formulae')\n        self.step4 = dspy.ReAct('question, initial_guess, calculated_estimation, variables_and_formulae -> gathering_data')\n        self.step5 = dspy.Predict('question, initial_guess, calculated_estimation, variables_and_formulae, gathering_data -> answer')\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Risolutore di problemi di Fermi che usa solo signature in-line</span></p></figcaption></figure>\n\n<figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiStep1(dspy.Signature):\n    question = dspy.InputField(desc='Fermi problems involve the use of estimation and reasoning')\n    initial_guess = dspy.OutputField(desc='Have a guess – don't do any calculations yet')\n\nclass FermiStep2(FermiStep1):\n    initial_guess = dspy.InputField(desc='Have a guess – don't do any calculations yet')\n    calculated_estimation = dspy.OutputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n\nclass FermiStep3(FermiStep2):\n    calculated_estimation = dspy.InputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n    variables_and_formulae = dspy.OutputField(desc='Write a formula or procedure to solve your problem')\n\nclass FermiStep4(FermiStep3):\n    variables_and_formulae = dspy.InputField(desc='Write a formula or procedure to solve your problem')\n    gathering_data = dspy.OutputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n\nclass FermiStep5(FermiStep4):\n    gathering_data = dspy.InputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n    answer = dspy.OutputField(desc='the final answer, must be a numerical value')\n\nclass FermiSolver2(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict(FermiStep1)\n        self.step2 = dspy.Predict(FermiStep2)\n        self.step3 = dspy.Predict(FermiStep3)\n        self.step4 = dspy.Predict(FermiStep4)\n        self.step5 = dspy.Predict(FermiStep5)\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Risolutore di problemi di Fermi che usa signature basate su classi con descrizione più completa su ogni campo.</span></p></figcaption></figure>\n\n<p>Inoltre, controlla la parte <code>def forward(self, )</code>. Per i Module multi-stage, assicurati che l'output (o <em>tutti</em> gli output come nel <code>FermiSolver</code>) dall'ultimo step sia fornito come input allo step successivo.</p>\n\n<h4 id=\"your-problem-is-just-too-hard\">Il Tuo Problema è Semplicemente Troppo Difficile</h4>\n\n<p>Se sia la metrica che il modulo sembrano corretti, allora è possibile che il tuo problema sia semplicemente troppo impegnativo e la logica che hai implementato non sia sufficiente per risolverlo. Quindi, DSPy trova impossibile fare il bootstrap di qualsiasi demo data la tua logica e funzione metrica. A questo punto, ecco alcune opzioni che puoi considerare:</p>\n\n<ul>\n<li><strong>Usa un LM più potente.</strong> Per esempio, sostituire <code>gpt-35-turbo-instruct</code> con <code>gpt-4-turbo</code> come LM studente, usa un LM più forte come insegnante. Questo può essere spesso molto efficace. Dopotutto, un modello più forte significa una migliore comprensione dei prompt.</li>\n<li><strong>Migliora la tua logica.</strong> Aggiungi o sostituisci alcuni step nel tuo <code>dspy.Module</code> con altri più complicati. Ad esempio, sostituisci <code>Predict</code> con <code>ChainOfThought</code> <code>ProgramOfThought</code>, aggiungendo lo step <code>Retrieval</code>.</li>\n<li><strong>Aggiungi più esempi di training.</strong> Se 20 esempi non sono sufficienti, punta a 100! Puoi quindi sperare che un esempio passi il controllo della metrica e venga scelto da <code>BootstrapFewShot</code>.</li>\n<li><strong>Riformula il problema.</strong> Spesso, un problema diventa irrisolvibile quando la formulazione è incorretta. Ma se cambi angolazione per guardarlo, le cose potrebbero essere molto più facili e ovvie.</li>\n</ul>\n\n<p>In pratica, il processo implica un mix di tentativi ed errori. Per esempio, ho affrontato un problema particolarmente impegnativo: generare un'icona SVG simile alle icone di Google Material Design basandomi su due o tre parole chiave. La mia strategia iniziale era utilizzare un semplice <code>DSPy.Module</code> che usa <code>dspy.ChainOfThought('keywords -> svg')</code>, associato a una funzione metrica che valutava la somiglianza visiva tra l'SVG generato e l'SVG Material Design di riferimento, simile a un algoritmo pHash. Ho iniziato con 20 esempi di training, ma dopo il primo round, mi sono ritrovato con <code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code>, indicando che l'ottimizzazione era fallita. Aumentando il dataset a 100 esempi, rivedendo il mio modulo per incorporare più stadi e aggiustando la soglia della funzione metrica, alla fine ho ottenuto 2 dimostrazioni bootstrappate e sono riuscito a ottenere alcuni prompt ottimizzati.</p>",
  "comment_id": "66077bf0a5c39b0001044181",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-03-30T03:41:52.000+01:00",
  "updated_at": "2024-04-23T10:46:48.000+02:00",
  "published_at": "2024-03-30T06:22:42.000+01:00",
  "custom_excerpt": "Heads up, Bay Area guys ditched their AVP already and buzz about DSPy now. Could DSPy be the new go-to framework for prompt engineering after LangChain and LlamaIndex?",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/dspy-not-your-average-prompt-engineering/",
  "excerpt": "Ehi, i ragazzi della Bay Area hanno già abbandonato AVP e ora parlano di DSPy. Potrebbe DSPy diventare il nuovo framework di riferimento per il prompt engineering dopo LangChain e LlamaIndex?",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Screenshot of a Tetris-like game with \"Score: 40\" and \"Press Start 2P\" text on display.",
  "feature_image_caption": null
}