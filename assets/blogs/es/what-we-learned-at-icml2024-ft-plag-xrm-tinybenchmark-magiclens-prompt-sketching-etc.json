{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "Lo que aprendimos en ICML2024 con PLaG, XRM, tinyBenchmark, MagicLens, Prompt Sketching y más",
  "html": "<p>La <a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">Conferencia Internacional sobre Aprendizaje Automático</a> es una de las conferencias más prestigiosas en la comunidad de aprendizaje automático e inteligencia artificial y celebró su reunión de 2024 en Viena del 21 al 27 de julio de este año.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Interior de un concurrido salón de conferencias académicas con muchos asistentes, algunos con mochilas, y pósters de investigación expuestos\" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>La conferencia fue una experiencia intensiva de aprendizaje de 7 días, con presentaciones orales y oportunidades para intercambiar ideas directamente con otros investigadores. Hay una gran cantidad de trabajo interesante en curso en aprendizaje por refuerzo, IA para ciencias de la vida, aprendizaje de representaciones, modelos multimodales y, por supuesto, en elementos fundamentales del desarrollo de modelos de IA. De particular importancia fue el tutorial sobre la <a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">Física de los Modelos de Lenguaje Grandes</a>, que exploró extensivamente el funcionamiento interno de los LLMs y ofreció respuestas convincentes a la pregunta de si los LLMs memorizan información o aplican razonamiento al decir las cosas.</p><h2 id=\"our-work-on-jina-clip-v1\">Nuestro Trabajo en Jina-CLIP-v1</h2><p>Realizamos una <a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">presentación de póster</a> sobre <a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">el trabajo detrás de nuestro nuevo modelo multimodal</a> <code>jina-clip-v1</code> como parte del taller <a href=\"https://icml.cc/virtual/2024/workshop/29957?ref=jina-ai-gmbh.ghost.io\">Multi-modal Foundation Models meet Embodied AI</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>Reunirnos y discutir nuestro trabajo con colegas internacionales que trabajan en muchos campos fue muy inspirador. Nuestra presentación recibió muchos comentarios positivos, con muchas personas interesadas en la forma en que Jina CLIP unifica los paradigmas de aprendizaje contrastivo multimodal y unimodal. Las discusiones abarcaron desde las limitaciones de la arquitectura CLIP hasta extensiones a modalidades adicionales y aplicaciones en el emparejamiento de péptidos y proteínas.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster.mp4\" poster=\"https://img.spacergif.org/v1/1138x640/0a/spacer.png\" width=\"1138\" height=\"640\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">3:09</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Michael Günther presenta Jina CLIP</span></p></figcaption>\n        </figure><h2 id=\"our-favorites\">Nuestros Favoritos</h2><p>Tuvimos la oportunidad de discutir muchos proyectos y presentaciones de otros investigadores, y aquí están algunos de nuestros favoritos:</p><h3 id=\"plan-like-a-graph-plag\">Plan Like a Graph (PLaG)</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., &amp; Pierrehumbert, J. B. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Graph-Enhanced Large Language Models in Asynchronous Plan Reasoning.</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>Muchas personas conocen el \"Few-Shot Prompting\" o el \"Chain of Thought prompting\". <a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> presentó un método nuevo y mejor en ICML: <em>Plan Like a Graph (PLaG)</em>.</p><p>Su idea es simple: una tarea dada a un LLM se descompone en subtareas que un LLM puede resolver ya sea en paralelo o secuencialmente. Estas subtareas forman un grafo de ejecución. Ejecutar el grafo completo resuelve la tarea de alto nivel.</p><p>En el video anterior, Fangru Lin explica el método usando un ejemplo fácil de entender. Ten en cuenta que aunque esto mejora tus resultados, los LLMs siguen sufriendo una degradación drástica cuando aumenta la complejidad de las tareas. Dicho esto, sigue siendo un gran paso en la dirección correcta y proporciona beneficios prácticos inmediatos.</p><p>Para nosotros, es interesante ver cómo su trabajo tiene paralelismos con nuestras aplicaciones de prompts en <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a>. Ya hemos implementado una estructura de prompts similar a un grafo, sin embargo, generar dinámicamente un grafo de ejecución como ella lo hizo es una nueva dirección que exploraremos.</p><h3 id=\"discovering-environments-with-xrm\">Descubriendo Entornos con XRM</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., &amp; Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>Este artículo presenta un algoritmo simple para descubrir entornos de entrenamiento que pueden hacer que un modelo se base en características que se correlacionan con las etiquetas pero no inducen una clasificación/relevancia precisa. Un ejemplo famoso es el conjunto de datos de aves acuáticas (ver <a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a>), que contiene fotos de aves con diferentes fondos que deben clasificarse como aves acuáticas o terrestres. Durante el entrenamiento, el clasificador detecta si el fondo de las imágenes muestra agua o no, en lugar de basarse en las características de las aves mismas. Tal modelo clasificará erróneamente a las aves acuáticas si no hay agua en el fondo.</p><p>Para mitigar este comportamiento, es necesario detectar muestras donde el modelo se basa en características de fondo engañosas. Este artículo presenta el algoritmo XRM para hacer esto.</p><p>El algoritmo entrena dos modelos en dos partes distintas del conjunto de datos de entrenamiento. Durante el entrenamiento, las etiquetas de algunas muestras se invierten. Específicamente, esto ocurre si el otro modelo (que no está entrenado en la muestra respectiva) clasifica una muestra de manera diferente. De esta manera, se anima a los modelos a basarse en correlaciones espurias. Posteriormente, puedes extraer muestras de los datos de entrenamiento donde una etiqueta predicha por uno de los modelos difiere de la verdad fundamental. Más adelante, uno puede usar esta información para entrenar modelos de clasificación más robustos, por ejemplo, con el <a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">algoritmo Group DRO</a>.</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">¡Reduce tus Costos de Evaluación de LLM en un Factor de 140!</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., &amp; Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>Sí, lo has oído bien. Con este truco, el costo de la Evaluación de LLM puede reducirse a una pequeña fracción.</p><p>La idea central es simple: Eliminar todas las muestras de evaluación que prueben la misma capacidad del modelo. Las matemáticas detrás son menos directas pero están bien explicadas por <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a> quien presentó su trabajo durante la sesión de pósters. Ten en cuenta que la reducción por un factor de 140 se aplica al popular conjunto de datos MMLU (Massive Multitask Language Understanding). Para tus propios conjuntos de datos de evaluación, depende de cuánto se correlacionan entre sí los resultados de evaluación de las muestras. Tal vez puedas omitir muchas muestras o solo unas pocas.</p><p>Solo inténtalo. Te mantendremos informado sobre cuánto pudimos reducir las muestras de evaluación en <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a>.</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">Contrastando Múltiples Representaciones con la Brecha de Coincidencia Multi-Marginal</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., &amp; Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Research paper diagram illustrating Multi-Marginal Matching Gap concepts, with titles, descriptions, and flow charts in blue \" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Este trabajo aborda un desafío común en el aprendizaje contrastivo: La mayoría de las funciones de pérdida contrastiva como la pérdida InfoNCE operan en pares de puntos de datos y miden la distancia entre pares positivos. Para expandir las tuplas positivas de tamaño k > 2, el aprendizaje contrastivo generalmente intenta reducir el problema a múltiples pares y acumular pérdidas por pares para todos los pares positivos. Los autores aquí proponen la pérdida M3G (Multi-Marginal Matching Gap), una versión modificada del algoritmo Sinkhorn, que resuelve el problema de Transporte Óptimo Multi-Marginal. Esta función de pérdida puede usarse en escenarios donde los conjuntos de datos consisten en tuplas positivas con tamaño k > 2, por ejemplo, >2 imágenes del mismo objeto, problemas multimodales con tres o más modalidades, o una extensión SimCLR con tres o más aumentaciones de la misma imagen. Los resultados empíricos muestran que este método supera la reducción ingenua del problema a pares.</p><h3 id=\"no-need-for-ground-truth\">¡No Se Necesita Verdad Fundamental!</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p><a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a> de <a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">Stanford University</a> presentó su trabajo sobre evaluar tu LLM sin ningún dato etiquetado. Ten en cuenta que aunque este es un trabajo teórico, tiene mucho potencial para la supervisión escalable de sistemas avanzados de IA. Esto no es para usuarios casuales de LLM, pero si trabajas en evaluación de LLM, definitivamente es algo que querrás investigar. Ya podemos ver que podríamos evaluar nuestros agentes en Jina AI de esta manera. Compartiremos los resultados una vez que ejecutemos los primeros experimentos.</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">¿Es Inevitable el Colapso del Modelo? Rompiendo la Maldición de la Recursión Acumulando Datos Reales y Sintéticos</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., &amp; Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration of two machine learning data processes: &quot;Replace Data&quot; and &quot;Accumulate Data&quot;, with detailed flowcharts and model\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Varios artículos (como este artículo de <a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em></a>) han predicho recientemente que el rendimiento de los modelos recién entrenados puede empeorar con el tiempo debido a que los datos de entrenamiento extraídos de la web contienen una cantidad cada vez mayor de datos sintéticos.</p><p>Nuestro colega Scott Martens también ha publicado <a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">un artículo sobre el colapso de modelos</a> y ha discutido casos donde los datos sintéticos pueden ser útiles para el entrenamiento de modelos.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>Los entrenamientos de modelos podrían colapsar porque los datos de entrenamiento son producidos por una versión anterior del modelo o un modelo entrenado con los mismos datos. Este artículo realiza experimentos que muestran una imagen ligeramente diferente: Un colapso solo ocurre cuando se <em>reemplazan</em> datos reales con sintéticos, lo cual se hizo en experimentos anteriores. Sin embargo, cuando se <em>aumentan</em> los datos reales con datos sintéticos adicionales, no hay cambios medibles en el rendimiento de los modelos resultantes. Estos resultados sugieren que algo como el colapso del modelo no sucederá. Sin embargo, nuevamente prueba que usar datos sintéticos adicionales no ayudará a entrenar un modelo que sea generalmente superior al modelo usado para crear dichos puntos de datos sintéticos.</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">La Cirugía Cerebral para la IA Ya es Posible</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., &amp; Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>Digamos que quieres predecir la profesión de alguien pero no su género. Este trabajo de Google Research, ETH Zürich, International Institute of Information Technology Hyderabad (IIITH) y Bar-Ilan University muestra cómo los vectores de dirección y el emparejamiento de covarianza pueden usarse para controlar el sesgo.</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - Recuperación de Imágenes Auto-Supervisada con Instrucciones Abiertas</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., &amp; Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Este artículo presenta los modelos MagicLens, una serie de modelos de recuperación de imágenes auto-supervisados entrenados en tripletes de imagen de consulta + instrucción + imagen objetivo.</p><p>Los autores introducen un pipeline de recolección/curación de datos que recopila pares de imágenes de la web y usa LLMs para sintetizar instrucciones de texto abiertas que vinculan las imágenes con diversas relaciones semánticas más allá de la mera similitud visual. Este pipeline se usa para producir 36.7M tripletes de alta calidad sobre una amplia distribución. El conjunto de datos se usa luego para entrenar una arquitectura simple de codificador dual con parámetros compartidos. Los codificadores base de visión y lenguaje se inicializan con variantes base y grandes de CoCa o CLIP. Se introduce un único pooler de atención multi-cabezal para comprimir las dos entradas multimodales en una sola incrustación. El objetivo del entrenamiento contrasta el par de imagen-consulta e instrucción con la imagen-objetivo y la instrucción de cadena vacía con una simple pérdida InfoNCE para entrenar MagicLens. Los autores presentan resultados de evaluación en recuperación de imágenes basada en instrucciones.</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - La Nueva Forma de Prompting</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., &amp; Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>La forma en que hacemos prompting a los LLMs está cambiando. Prompt Sketching nos permite dar restricciones fijas a los modelos generativos. En lugar de solo proporcionar una instrucción y esperar que el modelo haga lo que queremos, defines una plantilla completa, forzando al modelo a generar lo que deseas.</p><p>No confundas esto con LLMs fine-tuneados para proporcionar un formato JSON estructurado. Con el enfoque de fine-tuning, el modelo aún tiene la libertad de generar lo que quiera. No así con Prompt Sketching. Proporciona un conjunto de herramientas completamente nuevo para los ingenieros de prompts y abre áreas de investigación que necesitan ser exploradas. En el video anterior, Mark Müller explica en detalle de qué se trata este nuevo paradigma.</p><p>También puedes consultar <a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">su proyecto de código abierto LMQL</a>.</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - Recuperación Selectiva para Completado de Código a Nivel de Repositorio</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., &amp; Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>Para muchas consultas, RAG realmente no ayuda al modelo porque la consulta es demasiado fácil o el sistema de recuperación no puede encontrar documentos relevantes, posiblemente porque no existen. Esto lleva a tiempos de generación más largos y menor rendimiento si el modelo se basa en fuentes engañosas o ausentes.</p><p>Este artículo aborda el problema permitiendo que los LLMs se autoevalúen para determinar si la recuperación es útil. Demuestran este enfoque en un modelo de completado de código que está entrenado para llenar un hueco en una plantilla de código. Para una plantilla dada, el sistema primero decide si los resultados de recuperación son útiles y, si es así, llama al recuperador. Finalmente, el LLM de código genera el contexto faltante ya sea que se agreguen o no resultados de recuperación a su prompt.</p><h3 id=\"the-platonic-representation-hypothesis\">La Hipótesis de la Representación Platónica</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., &amp; Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration of &quot;The Platonic Representation Hypothesis&quot; with geometric shapes, mathematical text, and diagrams explaining a \" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p>La <em>Hipótesis de la Representación Platónica</em> argumenta que los modelos de redes neuronales tenderán a converger hacia una representación común del mundo. Tomando prestada la <a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">Teoría de las Formas de Platón</a>, la idea de que existe un reino de \"ideales\", que se nos aparece en una forma distorsionada que solo podemos observar indirectamente, los autores afirman que nuestros modelos de IA parecen converger en una única representación de la realidad, independientemente de la arquitectura de entrenamiento, los datos de entrenamiento o incluso la modalidad de entrada. Cuanto mayor es la escala de los datos y el tamaño del modelo, más similares parecen ser sus representaciones.</p><p>Los autores consideran las representaciones vectoriales y miden el alineamiento de representaciones utilizando métricas de alineamiento de kernel, específicamente una métrica de vecinos más cercanos mutuos que mide la intersección media de los conjuntos de <em>k</em> vecinos más cercanos inducidos por dos kernels, <em>K1</em> y <em>K2</em>, normalizada por <em>k</em>. Este trabajo presenta evidencia empírica de que a medida que el tamaño de los modelos y conjuntos de datos crece y el rendimiento mejora, los kernels se vuelven más alineados. Este alineamiento también puede observarse incluso cuando se comparan modelos de diferentes modalidades, como modelos de texto y modelos de imagen.</p><h2 id=\"summary\">Resumen</h2><p>Parte del entusiasmo inicial que vino con la ley de escalamiento está comenzando a disminuir, pero ICML 2024 ha demostrado que tanto talento nuevo, diverso y creativo ha entrado en nuestro campo que podemos estar seguros de que el progreso está lejos de terminar.</p><p>La pasamos increíble en ICML 2024 y pueden apostar que volveremos en 2025 🇨🇦.</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "Nos lo pasamos genial en ICML 2024 en Viena, y queremos compartir con ustedes todo lo que dijimos, vimos y aprendimos.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}