{
  "slug": "dspy-not-your-average-prompt-engineering",
  "id": "66077bf0a5c39b0001044181",
  "uuid": "e242c77c-f712-462c-9745-3e9269eb8a8b",
  "title": "DSPy: No es un prompt engineering común",
  "html": "<div class=\"kg-card kg-file-card\"><a class=\"kg-file-card-container\" href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/04/DSPy-Not-Your-Average-Prompt-Engineering--1-.pdf\" title=\"Download\" download=\"\"><div class=\"kg-file-card-contents\"><div class=\"kg-file-card-title\">[Diapositivas] DSPy: No es tu típica ingeniería de prompts</div><div class=\"kg-file-card-caption\">Una presentación realizada por Han el 15 de abril de 2024 en Mountain View.</div><div class=\"kg-file-card-metadata\"><div class=\"kg-file-card-filename\">DSPy Not Your Average Prompt Engineering (1).pdf</div><div class=\"kg-file-card-filesize\">7 MB</div></div></div><div class=\"kg-file-card-icon\"><svg viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"></polyline><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"></line><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"></circle></svg></div></a></div><p>Recientemente he estado investigando DSPy, un framework de vanguardia desarrollado por el grupo de NLP de Stanford dirigido a optimizar algorítmicamente los prompts de modelos de lenguaje (LM). Durante los últimos tres días, he recopilado algunas impresiones iniciales y perspectivas valiosas sobre DSPy. Ten en cuenta que mis observaciones no pretenden reemplazar la documentación oficial de DSPy. De hecho, recomiendo encarecidamente leer <a href=\"https://dspy-docs.vercel.app/?ref=jina-ai-gmbh.ghost.io\">su documentación</a> y <a href=\"https://github.com/stanfordnlp/dspy/blob/main/README.md?ref=jina-ai-gmbh.ghost.io\">README</a> al menos una vez antes de sumergirse en esta publicación. Mi discusión aquí refleja un entendimiento preliminar de DSPy, habiendo pasado algunos días explorando sus capacidades. Hay varias funciones avanzadas, como DSPy Assertions, Typed Predictor y el ajuste de pesos de LM, que aún no he explorado a fondo.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/stanfordnlp/dspy?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - stanfordnlp/dspy: DSPy: The framework for programming—not prompting—foundation models</div><div class=\"kg-bookmark-description\">DSPy: The framework for programming—not prompting—foundation models - stanfordnlp/dspy</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">stanfordnlp</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/b8c1b2b4b3ff9c22d486f5c69dbda5fee6cc8dda8a42aaf1c2e154c17b7dc159/stanfordnlp/dspy\" alt=\"\"></div></a></figure><p>A pesar de mi experiencia con Jina AI, que se centra principalmente en la base de búsqueda, mi interés en DSPy no fue impulsado directamente por su potencial en la Generación Aumentada por Recuperación (RAG). En cambio, me intrigó la posibilidad de aprovechar DSPy para el ajuste automático de prompts para abordar algunas tareas de generación.</p><p>Si eres nuevo en DSPy y buscas un punto de entrada accesible, o si estás familiarizado con el framework pero encuentras que la documentación oficial es confusa o abrumadora, este artículo está destinado a ti. También opto por _no_ adherirme estrictamente al estilo de DSPy, que puede parecer desalentador para los principiantes. Dicho esto, profundicemos.</p><h2 id=\"what-i-like-about-dspy\">Lo que me gusta de DSPy</h2><h3 id=\"dspy-closing-the-loop-of-prompt-engineering\">DSPy cerrando el ciclo de la ingeniería de prompts</h3><p>Lo que más me emociona de DSPy es su enfoque para cerrar el ciclo del proceso de ingeniería de prompts, transformando lo que a menudo es un proceso _manual_, _artesanal_ en un flujo de trabajo de aprendizaje automático _estructurado_, _bien definido_: es decir, preparar conjuntos de datos, definir el modelo, entrenar, evaluar y probar. <strong>En mi opinión, este es el aspecto más revolucionario de DSPy.</strong></p><p>Viajando por el Área de la Bahía y hablando con muchos fundadores de startups centrados en la evaluación de LLM, me he encontrado con frecuentes discusiones sobre métricas, alucinaciones, observabilidad y cumplimiento. Sin embargo, estas conversaciones a menudo no progresan hacia los pasos críticos siguientes: <strong>Con todas estas métricas en la mano, ¿qué hacemos después?</strong> ¿Puede considerarse un enfoque estratégico ajustar la redacción en nuestros prompts, con la esperanza de que ciertas palabras mágicas (por ejemplo, \"mi abuela se está muriendo\") puedan mejorar nuestras métricas? Esta pregunta ha quedado sin respuesta por parte de muchas startups de evaluación de LLM, y era una que yo tampoco podía abordar, hasta que descubrí DSPy. DSPy introduce un método claro y programático para optimizar prompts basado en métricas específicas, o incluso para optimizar todo el pipeline de LLM, incluyendo tanto los prompts como los pesos del LLM.</p><p>Harrison, el CEO de LangChain, y Logan, el ex Jefe de Relaciones con Desarrolladores de OpenAI, han declarado en el <a href=\"https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924?ref=jina-ai-gmbh.ghost.io\">podcast Unsupervised Learning</a> que 2024 será un año crucial para la evaluación de LLM. Es por esta razón que creo que DSPy merece más atención de la que está recibiendo actualmente, ya que DSPy proporciona la pieza crucial que faltaba en el rompecabezas.</p><h3 id=\"dspy-separating-logic-from-textual-representation\">DSPy separando la lógica de la representación textual</h3><p>Otro aspecto de DSPy que me impresiona es que formula la ingeniería de prompts en un módulo reproducible y agnóstico del LLM. Para lograrlo, <strong>extrae la lógica del prompt, creando una clara separación de responsabilidades entre la _lógica_ y la _representación textual_</strong>, como se ilustra a continuación.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png\" class=\"kg-image\" alt=\"Flowchart depicting sentiment analysis process with steps such as Prompt, Logic, and Textual Representation on a black backgr\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--5-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--5-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">En DSPy, el Prompt consiste en la lógica intrínseca (es decir, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>dspy.Module</span></code><span style=\"white-space: pre-wrap;\">,) y su representación textual. La lógica es inmutable, reproducible, comprobable y agnóstica del LLM. La representación textual es solo la consecuencia de la lógica.</span></figcaption></figure><p><strong>El concepto de DSPy de la lógica como la \"causa\" inmutable, comprobable y agnóstica del LLM, con la representación textual simplemente como su \"consecuencia\"</strong>, puede parecer desconcertante al principio. Esto es especialmente cierto a la luz de la creencia generalizada de que \"el futuro de los lenguajes de programación es el lenguaje natural\". Abrazando la idea de que \"la ingeniería de prompts es el futuro\", uno podría experimentar un momento de confusión al encontrarse con la filosofía de diseño de DSPy. Contrario a la expectativa de simplificación, DSPy introduce una serie de módulos y sintaxis de firmas, ¡aparentemente regresando el prompting en lenguaje natural a la complejidad de la programación en C!</p><p>Pero ¿por qué adoptar este enfoque? Mi entendimiento es que <strong>en el corazón de la programación de prompts se encuentra la lógica central, con la comunicación sirviendo como un amplificador</strong>, potencialmente mejorando o disminuyendo su efectividad. La directiva <code>\"Hacer clasificación de sentimientos\"</code> representa la lógica central, mientras que una frase como <code>\"Sigue estas demostraciones o te despediré\"</code> es una forma de comunicarlo. Análogamente a las interacciones de la vida real, las dificultades para lograr las cosas a menudo no provienen de una lógica defectuosa sino de comunicaciones problemáticas. Esto explica por qué muchos, particularmente los no nativos, encuentran desafiante la ingeniería de prompts. He observado a ingenieros de software altamente competentes en mi empresa luchar con la ingeniería de prompts, no debido a una falta de lógica, sino porque no \"hablan el lenguaje\". Al separar la lógica del prompt, <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/modules?ref=jina-ai-gmbh.ghost.io\">DSPy permite la programación determinista de la lógica a través de <code>dspy.Module</code></a>, permitiendo a los desarrolladores centrarse en la lógica de la misma manera que lo harían en la ingeniería tradicional, independientemente del LLM utilizado.</p><p>Entonces, si los desarrolladores se centran en la lógica, ¿quién gestiona la representación textual? <strong>DSPy asume este rol, utilizando tus datos y métricas de evaluación para refinar la representación textual</strong>—todo, desde determinar el enfoque narrativo hasta optimizar las pistas y elegir buenas demostraciones. Sorprendentemente, DSPy incluso puede usar métricas de evaluación para ajustar los pesos del LLM!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png\" class=\"kg-image\" alt=\"Flowchart illustrating a language model with branches for training data, logic, textual representation, and final results.\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Para mí, las contribuciones clave de DSPy—cerrar el ciclo de entrenamiento y evaluación en la ingeniería de prompts y separar la lógica de la representación textual—subrayan su potencial significativo para los sistemas LLM/Agent. ¡Una visión ambiciosa sin duda, pero definitivamente necesaria!</p><h2 id=\"what-i-think-dspy-can-improve\">Lo que creo que DSPy puede mejorar</h2><p>Primero, DSPy presenta una curva de aprendizaje pronunciada para los principiantes debido a sus modismos. Términos como <code>signature</code>, <code>module</code>, <code>program</code>, <code>teleprompter</code>, <code>optimization</code>, y <code>compile</code> pueden ser abrumadores. Incluso para aquellos competentes en ingeniería de prompts, navegar por estos conceptos dentro de DSPy puede ser un laberinto desafiante.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Yeah, DSPy really needs someone to come in and explain everything without suitcase words. <a href=\"https://twitter.com/CShorten30?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">@CShorten30</a> does a great job, but we need more.</p>— Jonathan Mugan (@jmugan) <a href=\"https://twitter.com/jmugan/status/1773036172723236895?ref_src=twsrc%5Etfw&ref=jina-ai-gmbh.ghost.io\">March 27, 2024</a></blockquote>\n<script async=\"\" src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></figure><p>Esta complejidad refleja mi experiencia con <a href=\"https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io\">Jina 1.0</a>, donde introdujimos una serie de conceptos como <code>chunk</code>, <code>document</code>, <code>driver</code>, <code>executor</code>, <code>pea</code>, <code>pod</code>, <code>querylang</code> y <code>flow</code> (¡incluso diseñamos adorables stickers para ayudar a los usuarios a recordarlos!).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Document-FLAT--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pea-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/QueryLang--FLAT.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png 700w\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--3-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pod-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png 700w\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png\" width=\"700\" height=\"700\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--5-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png 700w\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">La mayoría de estos conceptos iniciales fueron eliminados en posteriores refactorizaciones de Jina. Hoy, solo </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Executor</span></code><span style=\"white-space: pre-wrap;\">, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Document</span></code><span style=\"white-space: pre-wrap;\"> y </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Flow</span></code><span style=\"white-space: pre-wrap;\"> han sobrevivido a \"la gran purga\". Agregamos un nuevo concepto, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Deployment</span></code><span style=\"white-space: pre-wrap;\">, en Jina 3.0; así que eso equilibra las cosas. 🤷</span></p></figcaption></figure><p>Este problema no es exclusivo de DSPy o Jina; recordemos la multitud de conceptos y abstracciones introducidos por TensorFlow entre las versiones 0.x y 1.x. Creo que este problema surge a menudo en las primeras etapas de los frameworks de software, donde hay un impulso <strong>por reflejar las notaciones académicas directamente en el código para garantizar la máxima precisión y reproducibilidad</strong>. Sin embargo, no todos los usuarios valoran tales abstracciones granulares, con preferencias que varían desde el deseo de líneas simples hasta demandas de mayor flexibilidad. Discutí extensamente este tema de la abstracción en frameworks de software en una publicación de blog de 2020, que los lectores interesados podrían encontrar útil.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/?ref=jina-ai-gmbh.ghost.io#layer-of-abstraction\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Layer of Abstraction When Building \"Tensorflow\" for Search · Han Xiao Tech Blog - Neural Search &amp; AI Engineering</div><div class=\"kg-bookmark-description\">Since Feb. 2020, I started a new venture called Jina AI. Our mission is to build an open-source neural search ecosystem for businesses and developers, ... · Han Xiao</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://hanxiao.io/wechaticon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/blog-abstraction-banner.jpg\" alt=\"\"></div></a></figure><p>En segundo lugar, la documentación de DSPy a veces carece de consistencia. Términos como <code>module</code> y <code>program</code>, <code>teleprompter</code> y <code>optimizer</code>, o <code>optimize</code> y <code>compile</code> (a veces referidos como <code>training</code> o <code>bootstrapping</code>) se usan indistintamente, aumentando la confusión. En consecuencia, pasé mis primeras horas con DSPy tratando de descifrar exactamente qué <code>optimiza</code> y qué implica el proceso de <code>bootstrapping</code>.</p><p>A pesar de estos obstáculos, a medida que profundizas en DSPy y revisas la documentación, probablemente experimentarás momentos de claridad donde todo comienza a tener sentido, revelando las conexiones entre su terminología única y las construcciones familiares vistas en frameworks como PyTorch. Sin embargo, DSPy sin duda tiene margen de mejora en futuras versiones, particularmente en hacer el framework más accesible para ingenieros de prompts <em>sin</em> experiencia en PyTorch.</p><h2 id=\"common-stumbling-blocks-for-dspy-newbies\">Obstáculos Comunes para Principiantes en DSPy</h2><p>En las siguientes secciones, he compilado una lista de preguntas que inicialmente obstaculizaron mi progreso con DSPy. Mi objetivo es compartir estas ideas con la esperanza de que puedan aclarar desafíos similares para otros estudiantes.</p><h3 id=\"what-are-teleprompter-optimization-and-compile-whats-exactly-being-optimized-in-dspy\">¿Qué son <code>teleprompter</code>, <code>optimization</code> y <code>compile</code>? ¿Qué se optimiza exactamente en DSPy?</h3><p>En DSPy, \"Teleprompters\" es el optimizador (y parece que <a href=\"https://twitter.com/lateinteraction?ref=jina-ai-gmbh.ghost.io\">@lateinteraction</a> está actualizando la documentación y el código para aclarar esto). La función <code>compile</code> actúa en el corazón de este optimizador, similar a llamar <code>optimizer.optimize()</code>. Piensa en ello como el equivalente al entrenamiento en DSPy. Este proceso <code>compile()</code> busca ajustar: </p><ul><li>las demostraciones de few-shot,</li><li>las instrucciones, </li><li>los pesos del LLM </li></ul><p>Sin embargo, la mayoría de los tutoriales básicos de DSPy no profundizan en el ajuste de pesos e instrucciones, lo que lleva a la siguiente pregunta.</p><h3 id=\"whats-bootstrap-in-dspy-all-about\">¿De qué se trata el <code>bootstrap</code> en DSPy?</h3><p>Bootstrap se refiere a la creación de demostraciones autogeneradas para el aprendizaje few-shot en contexto, una parte crucial del proceso <code>compile()</code> (es decir, optimización/entrenamiento como mencioné arriba). Estas demostraciones few-shot se generan a partir de datos etiquetados proporcionados por el usuario; y una demostración a menudo consiste en entrada, salida, razonamiento (por ejemplo, en Cadenas de Pensamiento), y entradas y salidas intermedias (para prompts de múltiples etapas). Por supuesto, las demostraciones few-shot de calidad son clave para la excelencia de la salida. Para ello, DSPy permite funciones métricas definidas por el usuario para asegurar que solo se elijan las demostraciones que cumplan ciertos criterios, lo que lleva a la siguiente pregunta.</p><h3 id=\"whats-dspy-metric-function\">¿Qué es la función métrica de DSPy?</h3><p>Después de la experiencia práctica con DSPy, he llegado a creer que la función métrica necesita mucho más énfasis que lo que proporciona la documentación actual. La función métrica en DSPy juega un papel crucial tanto en las fases de evaluación como de entrenamiento, actuando también como función de \"pérdida\", gracias a su naturaleza implícita (controlada por <code>trace=None</code>):</p><pre><code class=\"language-python\">def keywords_match_jaccard_metric(example, pred, trace=None):  \n    # Jaccard similarity between example keywords and predicted keywords  \n    A = set(normalize_text(example.keywords).split())  \n    B = set(normalize_text(pred.keywords).split())  \n    j = len(A &amp; B) / len(A | B)\n    if trace is not None:\n        # act as a \"loss\" function\n        return j  \n    return j > 0.8  # act as evaluation</code></pre><p>Este enfoque difiere significativamente del aprendizaje automático tradicional, donde la función de pérdida suele ser continua y diferenciable (por ejemplo, hinge/MSE), mientras que la métrica de evaluación puede ser completamente diferente y discreta (por ejemplo, NDCG). En DSPy, las funciones de evaluación y pérdida están unificadas en la función métrica, que puede ser discreta y la mayoría de las veces devuelve un valor booleano. ¡La función métrica también puede integrar un LLM! En el ejemplo siguiente, implementé una coincidencia aproximada usando LLM para determinar si el valor predicho y la respuesta estándar son similares en magnitud, por ejemplo, \"1 millón de dólares\" y \"$1M\" devolverían verdadero.</p><pre><code class=\"language-python\">class Assess(dspy.Signature):  \n    \"\"\"Assess the if the prediction is in the same magnitude to the gold answer.\"\"\"  \n  \n    gold_answer = dspy.InputField(desc='number, could be in natural language')  \n    prediction = dspy.InputField(desc='number, could be in natural language')  \n    assessment = dspy.OutputField(desc='yes or no, focus on the number magnitude, not the unit or exact value or wording')  \n  \ndef same_magnitude_correct(example, pred, trace=None):  \n    return dspy.Predict(Assess)(gold_answer=example.answer, prediction=pred.answer).assessment.lower() == 'yes'</code></pre><p>Por poderosa que sea, la función métrica influye significativamente en la experiencia del usuario de DSPy, determinando no solo la evaluación final de calidad sino también afectando los resultados de la optimización. Una función métrica bien diseñada puede llevar a prompts optimizados, mientras que una mal elaborada puede hacer que la optimización falle. Al abordar un nuevo problema con DSPy, podrías encontrarte dedicando tanto tiempo a diseñar la lógica (es decir, <code>DSPy.Module</code>) como a la función métrica. Este doble enfoque en lógica y métricas puede ser intimidante para los principiantes.</p><h3 id=\"bootstrapped-0-full-traces-after-20-examples-in-round-0-what-does-this-mean\"><code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code> ¿qué significa esto?</h3><p>Este mensaje que aparece silenciosamente durante <code>compile()</code> merece tu máxima atención, ya que esencialmente significa que la optimización/compilación falló, y el prompt que obtienes no es mejor que un simple few-shot. ¿Qué salió mal? He resumido algunos consejos para ayudarte a depurar tu programa DSPy cuando encuentres este mensaje:</p><h4 id=\"your-metric-function-is-incorrect\">Tu Función Métrica es Incorrecta</h4><p>¿Está la función <code>your_metric</code>, usada en <code>BootstrapFewShot(metric=your_metric)</code>, correctamente implementada? Realiza algunas pruebas unitarias. ¿Tu <code>your_metric</code> devuelve alguna vez <code>True</code>, o siempre devuelve <code>False</code>? Ten en cuenta que devolver <code>True</code> es crucial porque es el criterio para que DSPy considere el ejemplo bootstrapped como un \"éxito\". Si devuelves cada evaluación como <code>True</code>, ¡entonces cada ejemplo es considerado un \"éxito\" en el bootstrapping! Esto no es ideal, por supuesto, pero es cómo puedes ajustar la rigurosidad de la función métrica para cambiar el resultado <code>\"Bootstrapped 0 full traces\"</code>. Ten en cuenta que aunque DSPy documenta que las métricas también pueden devolver valores escalares, después de revisar el código subyacente, no lo recomendaría para principiantes.</p><h4 id=\"your-logic-dspymodule-is-incorrect\">Tu Lógica (<code>DSPy.Module</code>) es Incorrecta</h4><p>Si la función métrica es correcta, entonces necesitas verificar si tu lógica <code>dspy.Module</code> está correctamente implementada. Primero, verifica que la <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io\">firma DSPy</a> está correctamente asignada para cada paso. Las firmas en línea, como <code>dspy.Predict('question-&gt;answer')</code>, son fáciles de usar, pero por calidad, sugiero fuertemente implementar con <a href=\"https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io#class-based-dspy-signatures\">firmas basadas en clases</a>. Específicamente, agrega algunas docstrings descriptivas a la clase, completa los campos desc para <code>InputField</code> y <code>OutputField</code>—todo esto proporciona pistas al LM sobre cada campo. A continuación implementé dos <code>DSPy.Module</code> multi-etapa para resolver <a href=\"https://en.wikipedia.org/wiki/Fermi_problem?ref=jina-ai-gmbh.ghost.io\">problemas de Fermi</a>, uno con firma en línea, otro con firma basada en clases.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiSolver(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict('question -&gt; initial_guess')\n        self.step2 = dspy.Predict('question, initial_guess -&gt; calculated_estimation')\n        self.step3 = dspy.Predict('question, initial_guess, calculated_estimation -&gt; variables_and_formulae')\n        self.step4 = dspy.ReAct('question, initial_guess, calculated_estimation, variables_and_formulae -&gt; gathering_data')\n        self.step5 = dspy.Predict('question, initial_guess, calculated_estimation, variables_and_formulae, gathering_data -&gt; answer')\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Solucionador de problemas Fermi usando solo firma en línea</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-python\">class FermiStep1(dspy.Signature):\n    question = dspy.InputField(desc='Fermi problems involve the use of estimation and reasoning')\n    initial_guess = dspy.OutputField(desc='Have a guess – don't do any calculations yet')\n\nclass FermiStep2(FermiStep1):\n    initial_guess = dspy.InputField(desc='Have a guess – don't do any calculations yet')\n    calculated_estimation = dspy.OutputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n\nclass FermiStep3(FermiStep2):\n    calculated_estimation = dspy.InputField(desc='List the information you'll need to solve the problem and make some estimations of the values')\n    variables_and_formulae = dspy.OutputField(desc='Write a formula or procedure to solve your problem')\n\nclass FermiStep4(FermiStep3):\n    variables_and_formulae = dspy.InputField(desc='Write a formula or procedure to solve your problem')\n    gathering_data = dspy.OutputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n\nclass FermiStep5(FermiStep4):\n    gathering_data = dspy.InputField(desc='Research, measure, collect data and use your formula. Find the smallest and greatest values possible')\n    answer = dspy.OutputField(desc='the final answer, must be a numerical value')\n\nclass FermiSolver2(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.Predict(FermiStep1)\n        self.step2 = dspy.Predict(FermiStep2)\n        self.step3 = dspy.Predict(FermiStep3)\n        self.step4 = dspy.Predict(FermiStep4)\n        self.step5 = dspy.Predict(FermiStep5)\n\n    def forward(self, q):\n        step1 = self.step1(question=q)\n        step2 = self.step2(question=q, initial_guess=step1.initial_guess)\n        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)\n        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)\n        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)\n        return step5</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Solucionador de problemas Fermi usando firma basada en clases con descripción más completa de cada campo.</span></p></figcaption></figure><p>Además, revisa la parte <code>def forward(self, )</code>. Para Modules multi-etapa, asegúrate de que la salida (o <em>todas</em> las salidas como en <code>FermiSolver</code>) del último paso se alimenta como entrada al siguiente paso.</p><h4 id=\"your-problem-is-just-too-hard\">Tu Problema es Simplemente Demasiado Difícil</h4><p>Si tanto la métrica como el módulo parecen correctos, entonces es posible que tu problema sea simplemente demasiado desafiante y la lógica que implementaste no sea suficiente para resolverlo. Por lo tanto, DSPy encuentra que es inviable hacer bootstrap de cualquier demo dada tu lógica y función métrica. En este punto, aquí hay algunas opciones que puedes considerar:</p><ul><li><strong>Usar un LM más potente.</strong> Por ejemplo, reemplazar <code>gpt-35-turbo-instruct</code> con <code>gpt-4-turbo</code> como el LM del estudiante, usar un LM más fuerte como profesor. Esto puede ser bastante efectivo. Después de todo, un modelo más fuerte significa mejor comprensión de los prompts.</li><li><strong>Mejorar tu lógica.</strong> Agregar o reemplazar algunos pasos en tu <code>dspy.Module</code> con otros más complicados. Por ejemplo, reemplazar <code>Predict</code> por <code>ChainOfThought</code> <code>ProgramOfThought</code>, agregando el paso <code>Retrieval</code>.</li><li><strong>Agregar más ejemplos de entrenamiento</strong>. Si 20 ejemplos no son suficientes, ¡apunta a 100! Entonces puedes esperar que un ejemplo pase la verificación métrica y sea seleccionado por <code>BootstrapFewShot</code>.</li><li><strong>Reformular el problema.</strong> A menudo, un problema se vuelve irresoluble cuando la formulación es incorrecta. Pero si cambias el ángulo para mirarlo, las cosas podrían ser mucho más fáciles y obvias.</li></ul><p>En la práctica, el proceso involucra una mezcla de prueba y error. Por ejemplo, abordé un problema particularmente desafiante: generar un icono SVG similar a los iconos de Google Material Design basado en dos o tres palabras clave. Mi estrategia inicial fue utilizar un simple <code>DSPy.Module</code> que usa <code>dspy.ChainOfThought('keywords -&gt; svg')</code>, emparejado con una función métrica que evaluaba la similitud visual entre el SVG generado y el SVG de Material Design de referencia, similar a un algoritmo pHash. Comencé con 20 ejemplos de entrenamiento, pero después de la primera ronda, terminé con <code>\"Bootstrapped 0 full traces after 20 examples in round 0\"</code>, indicando que la optimización había fallado. Al aumentar el conjunto de datos a 100 ejemplos, revisar mi módulo para incorporar múltiples etapas y ajustar el umbral de la función métrica, finalmente logré 2 demostraciones bootstrapped y conseguí obtener algunos prompts optimizados.</p>",
  "comment_id": "66077bf0a5c39b0001044181",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-03-30T03:41:52.000+01:00",
  "updated_at": "2024-04-23T10:46:48.000+02:00",
  "published_at": "2024-03-30T06:22:42.000+01:00",
  "custom_excerpt": "Heads up, Bay Area guys ditched their AVP already and buzz about DSPy now. Could DSPy be the new go-to framework for prompt engineering after LangChain and LlamaIndex?",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/dspy-not-your-average-prompt-engineering/",
  "excerpt": "¡Atención! La gente del Área de la Bahía ya abandonó AVP y ahora habla de DSPy. ¿Podría DSPy convertirse en el nuevo framework de referencia para la ingeniería de prompts después de LangChain y LlamaIndex?",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Screenshot of a Tetris-like game with \"Score: 40\" and \"Press Start 2P\" text on display.",
  "feature_image_caption": null
}