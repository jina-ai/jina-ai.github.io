{
  "slug": "readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json",
  "id": "6785bfd62defad0001fb5f22",
  "uuid": "a8e2e140-18e5-49e6-aa8f-71bf4c9e3293",
  "title": "ReaderLM v2: Modelo de Lenguaje Pequeño de Vanguardia para HTML a Markdown y JSON",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/ReaderLM-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/ReaderLM-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">Estamos en un viaje para avanzar y democratizar la inteligencia artificial a través del código abierto y la ciencia abierta.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-24.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/ReaderLM-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>En abril de 2024, lanzamos <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a>, una API que transforma cualquier página web en markdown compatible con LLM simplemente añadiendo <code>r.jina.ai</code> como prefijo de URL. En septiembre de 2024, <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown?ref=jina-ai-gmbh.ghost.io\">lanzamos dos modelos de lenguaje pequeños, <code>reader-lm-0.5b</code> y <code>reader-lm-1.5b</code>, específicamente diseñados para convertir HTML sin procesar en markdown limpio.</a> Hoy, nos complace presentar la segunda generación de ReaderLM, un modelo de lenguaje de 1.5B parámetros que convierte HTML sin procesar en markdown o JSON bellamente formateado con superior precisión y mejor manejo de contextos más largos. <code>ReaderLM-v2</code> maneja hasta 512K tokens combinados de longitud de entrada y salida. El modelo ofrece soporte multilingüe en 29 idiomas, incluyendo inglés, chino, japonés, coreano, francés, español, portugués, alemán, italiano, ruso, vietnamita, tailandés, árabe y más.</p><p>Gracias a su <strong>nuevo paradigma de entrenamiento</strong> y <strong>datos de entrenamiento de mayor calidad</strong>, <code>ReaderLM-v2</code> representa un salto significativo respecto a su predecesor, particularmente en el manejo de contenido extenso y la generación de sintaxis markdown. Mientras que la primera generación abordaba la conversión de HTML a markdown como <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#:~:text=primarily%20needs%20to-,selective%2Dcopy,-from%20the%20input\">una tarea de \"copia selectiva\"</a>, <strong>v2 lo trata como un verdadero proceso de traducción.</strong> Este cambio permite que el modelo aproveche magistralmente la sintaxis markdown, destacando en la generación de <strong>elementos complejos como bloques de código, listas anidadas, tablas y ecuaciones LaTex.</strong></p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-.mp4\" poster=\"https://img.spacergif.org/v1/1500x1000/0a/spacer.png\" width=\"1500\" height=\"1000\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/01/Heading--1500-x-800-px---1500-x-1000-px-_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:21</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">La comparación de resultados de conversión HTML a markdown de la página principal de HackerNews entre ReaderLM v2, ReaderLM 1.5b, Claude 3.5 Sonnet y Gemini 2.0 Flash revela el estilo único y rendimiento de ReaderLM v2. ReaderLM v2 sobresale en preservar información completa del HTML sin procesar, incluyendo los enlaces originales de HackerNews, mientras estructura inteligentemente el contenido usando sintaxis markdown. El modelo utiliza listas anidadas para organizar elementos locales (puntos, marcas de tiempo y comentarios) mientras mantiene un formato global consistente a través de una jerarquía adecuada de encabezados (etiquetas h1 y h2).</span></p></figcaption>\n        </figure><p>Un desafío importante en nuestra primera versión fue la <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#degeneration-and-dull-loops\"><strong>degeneración</strong></a> después de generar secuencias largas, particularmente en forma de repetición y bucles. El modelo comenzaba a repetir el mismo token o se quedaba atascado en un bucle, ciclando a través de una secuencia corta de tokens hasta alcanzar la longitud máxima de salida. <code>ReaderLM-v2</code> alivia en gran medida este problema al añadir pérdida contrastiva durante el entrenamiento—su rendimiento se mantiene consistente independientemente de la longitud del contexto o la cantidad de tokens ya generados.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---6-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Probamos ReaderLM v2 convirtiendo </span><a href=\"https://jina.ai/legal?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">nuestra página legal</span></a><span style=\"white-space: pre-wrap;\"> a markdown—una página aproximadamente 20 veces más larga que la página principal de HackerNews, incluyendo una extensa tabla de subprocesadores cerca del final de la página. A pesar de este gran desafío, ReaderLM v2 generó exitosamente la tabla completa en markdown mientras mantenía la estructura consistente del documento, preservando tanto la jerarquía de encabezados como el formato de listas incluso después de la tabla. Este nivel de rendimiento era inalcanzable con la generación anterior </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>reader-lm-1.5b</span></code><span style=\"white-space: pre-wrap;\">, que degeneraba después de generar secuencias largas.</span></figcaption></figure><p>Más allá de la conversión a markdown, <code>ReaderLM-v2</code> introduce la <strong>generación directa de HTML a JSON</strong>, permitiendo a los usuarios extraer información específica del HTML sin procesar siguiendo un esquema JSON dado. Este enfoque de extremo a extremo elimina la necesidad de conversión intermedia a markdown, un requisito común en muchos pipelines de limpieza y extracción de datos potenciados por LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--1500-x-800-px---1500-x-1000-px---9-.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">En este ejemplo, proporcionamos a ReaderLM v2 el HTML sin procesar de la página principal de HackerNews y un esquema JSON que especifica el título del hilo, URL, resumen, palabras clave, autor y cantidad de comentarios. Si bien algunos campos están directamente disponibles en el HTML, otros, como las palabras clave, deben derivarse del contenido. ReaderLM v2 extrae y genera todos los campos con notable precisión.</span></figcaption></figure><p>Tanto en evaluaciones cuantitativas como cualitativas, <code>ReaderLM-v2</code> supera a modelos mucho más grandes como <code>Qwen2.5-32B-Instruct</code>, <code>Gemini2-flash-expr</code>, y <code>GPT-4o-2024-08-06</code> en tareas de conversión de HTML a Markdown mientras muestra un rendimiento comparable en tareas de extracción de HTML a JSON, todo esto utilizando significativamente menos parámetros.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"><figcaption><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ReaderLM-v2-pro</span></code><span style=\"white-space: pre-wrap;\"> es un punto de control premium exclusivo reservado para nuestros clientes empresariales, que incluye entrenamiento y optimizaciones adicionales.</span></figcaption></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Instructed-HTML2Markdown.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/HTML2JSON.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"371\"></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Qualitative-Evaluation--2-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"709\" height=\"620\"><figcaption><span style=\"white-space: pre-wrap;\">Nuestra evaluación manual cubrió 10 fuentes HTML diversas, incluyendo artículos de noticias, publicaciones de blog, páginas de destino de productos, sitios de comercio electrónico y documentos legales en inglés, japonés y chino. El corpus de prueba incluyó elementos desafiantes como tablas de múltiples filas, diseños dinámicos, tablas vinculadas, fórmulas matemáticas (tanto en línea como en pantalla), bloques de código y listas profundamente anidadas. La evaluación cualitativa se centró en tres dimensiones clave, con modelos calificados en una escala de 1 (más bajo) a 5 (más alto). Las puntuaciones luego se normalizaron a un máximo de 1.0 por aspecto para una comparación más fácil.</span></figcaption></figure><p>Estos resultados establecen que un modelo bien diseñado de 1.5B parámetros puede no solo igualar sino a menudo superar el rendimiento de modelos mucho más grandes en tareas de extracción de datos estructurados. Las mejoras progresivas de <code>ReaderLM-v2</code> a <code>ReaderLM-v2-pro</code> demuestran la efectividad de nuestra nueva estrategia de entrenamiento para mejorar el rendimiento del modelo mientras se mantiene la eficiencia computacional.</p><h2 id=\"get-started\">Comenzar</h2><h3 id=\"via-reader-api\">A través de Reader API</h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Lee URLs y busca en la web para mejorar el fundamento de LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-17.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>ReaderLM-v2</code> está ahora integrado con nuestra Reader API. Para usarlo, simplemente especifica <code>x-engine: readerlm-v2</code> en los encabezados de tu solicitud y habilita el streaming de respuesta con <code>-H 'Accept: text/event-stream'</code>:</p><pre><code class=\"language-bash\">curl https://r.jina.ai/https://news.ycombinator.com/ -H 'x-engine: readerlm-v2' -H 'Accept: text/event-stream'\n</code></pre><p>Puedes probarlo sin una clave API con un límite de velocidad más bajo. <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\">Para límites de velocidad más altos</a>, puedes comprar una clave API. <strong>Ten en cuenta que las solicitudes de ReaderLM-v2 consumen 3 veces el conteo normal de tokens de tu clave API.</strong> Esta función está actualmente en beta mientras colaboramos con el equipo de GCP para optimizar la eficiencia de la GPU y aumentar la disponibilidad del modelo.</p><h3 id=\"on-google-colab\">En Google Colab</h3><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1FfPjZwkMSocOLsEYH45B3B4NxDryKLGI?usp=sharing&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-22.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-6.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Ten en cuenta que la GPU T4 gratuita tiene limitaciones: no admite </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>bfloat16</span></code><span style=\"white-space: pre-wrap;\"> ni flash attention 2, lo que lleva a un mayor uso de memoria y procesamiento más lento de entradas más largas. Sin embargo, ReaderLM v2 procesa exitosamente toda nuestra página legal bajo estas restricciones, logrando velocidades de procesamiento de 67 tokens/s de entrada y 36 tokens/s de salida. Para uso en producción, recomendamos una RTX 3090/4090 para un rendimiento óptimo.</span></p></figcaption></figure><p>La forma más sencilla de probar <code>ReaderLM-v2</code> en un entorno alojado es a través de nuestro notebook de Colab, que demuestra la conversión de HTML a markdown, extracción JSON y seguimiento de instrucciones usando la página principal de HackerNews como ejemplo. El notebook está optimizado para el nivel gratuito de GPU T4 de Colab y requiere <code>vllm</code> y <code>triton</code> para aceleración y ejecución. Siéntete libre de probarlo con cualquier sitio web.</p><h4 id=\"html-to-markdown-conversion\">Conversión de HTML a Markdown</h4><p>Puedes usar la función auxiliar <code>create_prompt</code> para crear fácilmente un prompt para convertir HTML a Markdown:</p><pre><code class=\"language-python\">prompt = create_prompt(html)\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p><code>result</code> será una cadena envuelta en comillas invertidas de Markdown como una valla de código. También puedes anular la configuración predeterminada para explorar diferentes salidas, por ejemplo:</p><pre><code class=\"language-python\">prompt = create_prompt(html, instruction=\"Extract the first three news and put into in the makdown list\")\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()</code></pre><p>Sin embargo, dado que nuestros datos de entrenamiento pueden no cubrir todos los tipos de instrucciones, particularmente tareas que requieren razonamiento en múltiples pasos, los resultados más confiables provienen de la conversión de HTML a Markdown. Para la extracción de información más efectiva, recomendamos usar el esquema JSON como se muestra a continuación:</p><h4 id=\"html-to-json-extraction-with-json-schema\">Extracción de HTML a JSON con esquema JSON</h4><pre><code class=\"language-python\">import json\n\nschema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"title\": {\"type\": \"string\", \"description\": \"News thread title\"},\n        \"url\": {\"type\": \"string\", \"description\": \"Thread URL\"},\n        \"summary\": {\"type\": \"string\", \"description\": \"Article summary\"},\n        \"keywords\": {\"type\": \"list\", \"description\": \"Descriptive keywords\"},\n        \"author\": {\"type\": \"string\", \"description\": \"Thread author\"},\n        \"comments\": {\"type\": \"integer\", \"description\": \"Comment count\"}\n    },\n    \"required\": [\"title\", \"url\", \"date\", \"points\", \"author\", \"comments\"]\n}\n\nprompt = create_prompt(html, schema=json.dumps(schema, indent=2))\nresult = llm.generate(prompt, sampling_params=sampling_params)[0].outputs[0].text.strip()\n</code></pre><p><code>result</code> será una cadena envuelta en comillas invertidas con formato JSON, no un objeto JSON/dict real. Puedes usar Python para analizar la cadena en un diccionario o objeto JSON adecuado para su posterior procesamiento.</p><h3 id=\"in-production-available-on-csp\">En Producción: Disponible en CSP</h3><p><code>ReaderLM-v2</code> está disponible en AWS SageMaker, Azure y GCP marketplace. Si necesitas usar estos modelos más allá de esas plataformas o en las instalaciones de tu empresa, ten en cuenta que este modelo y <code>ReaderLM-v2-pro</code> están licenciados bajo CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Para consultas sobre uso comercial o acceso a <code>ReaderLM-v2-pro</code>, no dudes en contactarnos.</a></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-jwfct4j4rvxk2?sr=0-21&ref_=beagle&applicationId=AWSMPContessa&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Reader-LM v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-23.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"quantitative-evaluation\">Evaluación Cuantitativa</h2><p>Evaluamos ReaderLM-v2 en tres tareas de extracción de datos estructurados frente a modelos de última generación: <code>GPT-4o-2024-08-06</code>, <code>Gemini2-flash-expr</code> y <code>Qwen2.5-32B-Instruct</code>. Nuestro marco de evaluación combina métricas que miden tanto la precisión del contenido como la fidelidad estructural. <code>ReaderLM-v2</code> es la versión públicamente disponible con pesos abiertos, mientras que <code>ReaderLM-v2-pro</code> es un checkpoint premium exclusivo reservado para nuestros clientes empresariales, que cuenta con entrenamiento y optimizaciones adicionales. Tenga en cuenta que nuestra primera generación <code>reader-lm-1.5b</code> solo se evalúa en la tarea principal de extracción de contenido, ya que no admite capacidades de extracción por instrucciones o JSON.</p><h3 id=\"evaluation-metrics\">Métricas de Evaluación</h3><p>Para las tareas de HTML a Markdown, empleamos siete métricas complementarias. Nota: ↑ indica que mayor es mejor, ↓ indica que menor es mejor</p><ul><li><strong>ROUGE-L</strong> (↑): Mide la subsecuencia común más larga entre el texto generado y de referencia, captando la preservación del contenido y la similitud estructural. Rango: 0-1, valores más altos indican mejor coincidencia de secuencias.</li><li><strong>WER (Tasa de Error de Palabras)</strong> (↓): Cuantifica el número mínimo de ediciones a nivel de palabra requeridas para transformar el texto generado en la referencia. Valores más bajos indican menos correcciones necesarias.</li><li><strong>SUB (Sustituciones)</strong> (↓): Cuenta el número de sustituciones de palabras necesarias. Valores más bajos sugieren mejor precisión a nivel de palabra.</li><li><strong>INS (Inserciones)</strong> (↓): Mide el número de palabras que necesitan ser insertadas para coincidir con la referencia. Valores más bajos indican mejor completitud.</li><li><strong>Distancia Levenshtein</strong> (↓): Calcula el número mínimo de ediciones de caracteres individuales requeridas. Valores más bajos sugieren mejor precisión a nivel de carácter.</li><li><strong>Distancia Damerau-Levenshtein</strong> (↓): Similar a Levenshtein pero también considera transposiciones de caracteres. Valores más bajos indican mejor coincidencia a nivel de carácter.</li><li><strong>Similitud Jaro-Winkler</strong> (↑): Enfatiza la coincidencia de caracteres al inicio de las cadenas, particularmente útil para evaluar la preservación de la estructura del documento. Rango: 0-1, valores más altos indican mejor similitud.</li></ul><p>Para las tareas de HTML a JSON, lo consideramos como una tarea de recuperación y adoptamos cuatro métricas de recuperación de información:</p><ul><li><strong>Puntuación F1</strong> (↑): Media armónica de precisión y exhaustividad, proporcionando precisión general. Rango: 0-1.</li><li><strong>Precisión</strong> (↑): Proporción de información correctamente extraída entre todas las extracciones. Rango: 0-1.</li><li><strong>Exhaustividad</strong> (↑): Proporción de información correctamente extraída de toda la información disponible. Rango: 0-1.</li><li><strong>Tasa de Aciertos</strong> (↑): Proporción de salidas que son JSON válido y cumplen con el esquema. Rango: 0-1.</li></ul><h3 id=\"main-content-html-to-markdown-task\">Tarea Principal de HTML a Markdown</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.69</td>\n<td>0.62</td>\n<td>131.06</td>\n<td>372.34</td>\n<td>0.40</td>\n<td>1341.14</td>\n<td>0.74</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td>0.41</td>\n<td><strong>88.66</strong></td>\n<td><strong>88.69</strong></td>\n<td>0.40</td>\n<td>1283.54</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.71</td>\n<td>0.47</td>\n<td>158.26</td>\n<td>123.47</td>\n<td>0.41</td>\n<td>1354.33</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>reader-lm-1.5b</td>\n<td>0.72</td>\n<td>1.14</td>\n<td>260.29</td>\n<td>1182.97</td>\n<td>0.35</td>\n<td>1733.11</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.84</td>\n<td>0.62</td>\n<td>135.28</td>\n<td>867.14</td>\n<td>0.22</td>\n<td>1262.75</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.86</strong></td>\n<td><strong>0.39</strong></td>\n<td>162.92</td>\n<td>500.44</td>\n<td><strong>0.20</strong></td>\n<td><strong>928.15</strong></td>\n<td><strong>0.83</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"instructed-html-to-markdown-task\">Tarea de HTML a Markdown por Instrucciones</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>ROUGE-L↑</th>\n<th>WER↓</th>\n<th>SUB↓</th>\n<th>INS↓</th>\n<th>Levenshtein↓</th>\n<th>Damerau↓</th>\n<th>Jaro-Winkler↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.64</td>\n<td>1.64</td>\n<td>122.64</td>\n<td>533.12</td>\n<td>0.45</td>\n<td>766.62</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td>0.69</td>\n<td><strong>0.82</strong></td>\n<td><strong>87.53</strong></td>\n<td><strong>180.61</strong></td>\n<td>0.42</td>\n<td><strong>451.10</strong></td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>0.68</td>\n<td>0.73</td>\n<td>98.72</td>\n<td>177.23</td>\n<td>0.43</td>\n<td>501.50</td>\n<td>0.69</td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.70</td>\n<td>1.28</td>\n<td>75.10</td>\n<td>443.70</td>\n<td>0.38</td>\n<td>673.62</td>\n<td><strong>0.75</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td><strong>0.72</strong></td>\n<td>1.48</td>\n<td><strong>70.16</strong></td>\n<td>570.38</td>\n<td><strong>0.37</strong></td>\n<td>748.10</td>\n<td><strong>0.75</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"schema-based-html-to-json-task\">Tarea de HTML a JSON Basada en Esquema</h3>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>F1↑</th>\n<th>Precision↑</th>\n<th>Recall↑</th>\n<th>Pass-Rate↑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Gemini2-flash-expr</td>\n<td>0.81</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n<tr>\n<td>gpt-4o-2024-08-06</td>\n<td><strong>0.83</strong></td>\n<td>0.84</td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td><strong>0.83</strong></td>\n<td><strong>0.85</strong></td>\n<td><strong>0.83</strong></td>\n<td><strong>1.00</strong></td>\n</tr>\n<tr>\n<td>ReaderLM-v2</td>\n<td>0.81</td>\n<td>0.82</td>\n<td>0.81</td>\n<td>0.98</td>\n</tr>\n<tr>\n<td>ReaderLM-v2-pro</td>\n<td>0.82</td>\n<td>0.83</td>\n<td>0.82</td>\n<td>0.99</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>ReaderLM-v2</code> representa un avance significativo en todas las tareas. Para la extracción de contenido principal, <code>ReaderLM-v2-pro</code> logra el mejor rendimiento en cinco de siete métricas, con puntuaciones superiores en ROUGE-L (0.86), WER (0.39), Levenshtein (0.20), Damerau (928.15) y Jaro-Winkler (0.83). Estos resultados demuestran mejoras integrales tanto en la preservación del contenido como en la precisión estructural en comparación con su versión base y modelos más grandes.</p><p>En la extracción por instrucciones, <code>ReaderLM-v2</code> y <code>ReaderLM-v2-pro</code> lideran en ROUGE-L (0.72), tasa de sustitución (70.16), distancia Levenshtein (0.37) y similitud Jaro-Winkler (0.75, empatado con la versión base). Si bien GPT-4o muestra ventajas en WER y distancia Damerau, <code>ReaderLM-v2-pro</code> mantiene mejor estructura general del contenido y precisión. En la extracción de JSON, el modelo tiene un rendimiento competitivo, manteniéndose dentro de 0.01-0.02 puntos F1 de los modelos más grandes mientras logra altas tasas de acierto (0.99).</p><h2 id=\"qualitative-evaluation\">Evaluación Cualitativa</h2><p>Durante nuestro análisis de<code>reader-lm-1.5b</code>, observamos que las <a href=\"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?ref=jina-ai-gmbh.ghost.io#qualitative-study\">métricas cuantitativas por sí solas pueden no capturar completamente el rendimiento del modelo</a>. Las evaluaciones numéricas a veces fallaban en reflejar la calidad perceptual—casos donde puntuaciones métricas bajas producían markdown visualmente satisfactorio, o puntuaciones altas generaban resultados subóptimos. Para abordar esta discrepancia, realizamos evaluaciones cualitativas sistemáticas en 10 fuentes HTML diversas, incluyendo artículos de noticias, publicaciones de blog, páginas de productos, sitios de comercio electrónico y documentos legales en inglés, japonés y chino. El corpus de prueba enfatizó elementos de formato desafiantes como tablas de múltiples filas, diseños dinámicos, fórmulas LaTeX, tablas vinculadas y listas anidadas, proporcionando una visión más completa de las capacidades del modelo en el mundo real.</p><h3 id=\"evaluation-metrics-1\">Métricas de Evaluación</h3><p>Nuestra evaluación humana se centró en tres dimensiones clave, con resultados calificados en una escala de 1-5:</p><p><strong>Integridad del Contenido</strong> - Evalúa la preservación de información semántica durante la conversión de HTML a markdown, incluyendo:</p><ul><li>Precisión y completitud del contenido de texto</li><li>Preservación de enlaces, imágenes, bloques de código, fórmulas y citas</li><li>Retención del formato de texto y URLs de enlaces/imágenes</li></ul><p><strong>Precisión Estructural</strong> - Evalúa la conversión precisa de elementos estructurales HTML a Markdown:</p><ul><li>Preservación de la jerarquía de encabezados</li><li>Precisión en el anidamiento de listas</li><li>Fidelidad en la estructura de tablas</li><li>Formato de bloques de código y citas</li></ul><p><strong>Cumplimiento del Formato</strong> - Mide la adherencia a los estándares de sintaxis Markdown:</p><ul><li>Uso apropiado de sintaxis para encabezados (#), listas (*, +, -), tablas, bloques de código (```)</li><li>Formato limpio sin espacios en blanco excesivos o sintaxis no estándar</li><li>Resultado renderizado consistente y legible</li></ul><p>Al evaluar manualmente más de 10 páginas HTML, cada criterio de evaluación tiene una puntuación máxima de 50 puntos. <code>ReaderLM-v2</code> demostró un fuerte rendimiento en todas las dimensiones:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Content Integrity</th>\n<th>Structural Accuracy</th>\n<th>Format Compliance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>reader-lm-v2</td>\n<td>39</td>\n<td>35</td>\n<td>36</td>\n</tr>\n<tr>\n<td>reader-lm-v2-pro</td>\n<td>35</td>\n<td>37</td>\n<td>37</td>\n</tr>\n<tr>\n<td>reader-lm-v1</td>\n<td>35</td>\n<td>34</td>\n<td>31</td>\n</tr>\n<tr>\n<td>Claude 3.5 Sonnet</td>\n<td>26</td>\n<td>31</td>\n<td>33</td>\n</tr>\n<tr>\n<td>gemini-2.0-flash-expr</td>\n<td>35</td>\n<td>31</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Qwen2.5-32B-Instruct</td>\n<td>32</td>\n<td>33</td>\n<td>34</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>38</td>\n<td>41</td>\n<td>42</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>En cuanto a la completitud del contenido, sobresalió en el reconocimiento de elementos complejos, particularmente fórmulas LaTeX, listas anidadas y bloques de código. El modelo mantuvo alta fidelidad al manejar estructuras de contenido complejas mientras que los modelos competidores a menudo omitían encabezados H1 (<code>reader-lm-1.5b</code>), truncaban contenido (Claude 3.5), o retenían etiquetas HTML sin procesar (Gemini-2.0-flash).</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--92-.png\" width=\"2000\" height=\"1477\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--92-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--92-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--92-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--92-.png 2400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png\" width=\"2000\" height=\"1765\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--93--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--93--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--93--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--93--1.png 2268w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><a href=\"https://iclr-blogposts.github.io/2024/blog/bench-hvp/?ref=jina-ai-gmbh.ghost.io\">Una publicación del blog ICLR</a> con ecuaciones LaTeX complejas incrustadas en markdown, mostrando el código fuente HTML en el panel derecho.</p></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--94--2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1033\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--94--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--94--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image--94--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image--94--2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Una vista dividida comparando la salida Markdown de ReaderLM-v2 con su visualización renderizada.</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"821\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/01/image.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Podemos restaurar perfectamente el contenido original a través de simples pasos de post-procesamiento después de ReaderLM-v2, incluyendo la conversión de ecuaciones LaTeX del formato HTML al formato Markdown. Por ejemplo, reemplazando <code>\\[...\\]</code> (y sus equivalentes HTML) con delimitadores estándar de Markdown como <code>$...$</code> para ecuaciones en línea y <code>$$...$$</code> para ecuaciones en pantalla. Esto ayuda a prevenir conflictos de sintaxis en la interpretación de Markdown.</figcaption></figure><p>En precisión estructural, ReaderLM-v2 mostró optimización para estructuras web comunes. Por ejemplo, en casos de Hacker News, reconstruyó exitosamente enlaces completos y optimizó la presentación de listas. El modelo manejó estructuras HTML complejas no blog que desafiaban a ReaderLM-v1.</p><p>En cumplimiento de formato, ReaderLM-v2 demostró particular fortaleza al manejar contenido como Hacker News, blogs y artículos de WeChat. Mientras que otros modelos de lenguaje grandes funcionaron bien con fuentes similares a markdown, tuvieron dificultades con sitios web tradicionales que requieren más interpretación y reformateo.</p><p>Nuestro análisis reveló que <code>gpt-4o</code> sobresale en el procesamiento de sitios web más cortos, demostrando una comprensión superior de la estructura y el formato del sitio en comparación con otros modelos. Sin embargo, al manejar contenido más largo, <code>gpt-4o</code> tiene dificultades con la completitud, a menudo omitiendo partes del principio y final del texto. Hemos incluido un análisis comparativo de las salidas de <code>gpt-4o</code>, ReaderLM-v2 y ReaderLM-v2-pro usando el sitio web de Zillow como ejemplo.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1382\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/01/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-1.png 2356w\" sizes=\"(min-width: 720px) 720px\"><figcaption>La página HTML original de Zillow</figcaption></figure><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png\" width=\"1400\" height=\"1576\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--95-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--95-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--95-.png 1400w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png\" width=\"1550\" height=\"1578\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--96-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--96-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--96-.png 1550w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png\" width=\"1562\" height=\"1582\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image--97-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image--97-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image--97-.png 1562w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">Una comparación de las salidas Markdown renderizadas de gpt-4o (izquierda), ReaderLM-v2 (centro) y ReaderLM-v2-pro (derecha).</span></p></figcaption></figure><p>Para ciertos casos desafiantes como páginas de aterrizaje de productos y documentos gubernamentales, el rendimiento de ReaderLM-v2 y ReaderLM-v2-pro se mantuvo robusto pero aún tiene margen de mejora. Las fórmulas matemáticas complejas y el código en las publicaciones de ICLR representaron desafíos para la mayoría de los modelos, aunque ReaderLM-v2 manejó estos casos mejor que el Reader API básico.</p><h2 id=\"how-we-trained-readerlm-v2\">Cómo Entrenamos ReaderLM v2</h2><p>ReaderLM-v2 está construido sobre <code><strong>Qwen2.5-1.5B-Instruction</strong></code>, un modelo base compacto conocido por su eficiencia en tareas de seguimiento de instrucciones y contexto largo. En esta sección, describimos cómo entrenamos el <code>ReaderLM-v2</code>, enfocándonos en la preparación de datos, métodos de entrenamiento y los desafíos que encontramos.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model Parameter</th>\n<th>ReaderLM-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Parameters</td>\n<td>1.54B</td>\n</tr>\n<tr>\n<td>Max Context Length (Input+Output)</td>\n<td>512K</td>\n</tr>\n<tr>\n<td>Hidden Size</td>\n<td>1536</td>\n</tr>\n<tr>\n<td>Number of Layers</td>\n<td>28</td>\n</tr>\n<tr>\n<td>Query Heads</td>\n<td>12</td>\n</tr>\n<tr>\n<td>KV Heads</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Head Size</td>\n<td>128</td>\n</tr>\n<tr>\n<td>Intermediate Size</td>\n<td>8960</td>\n</tr>\n<tr>\n<td>Multilingual Support</td>\n<td>29 languages</td>\n</tr>\n<tr>\n<td>HuggingFace Repository</td>\n<td>Link</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"data-preparation\">Preparación de Datos</h3><p>El éxito de ReaderLM-v2 dependió en gran medida de la calidad de sus datos de entrenamiento. Creamos el conjunto de datos <code>html-markdown-1m</code>, que incluía un millón de documentos HTML recopilados de internet. En promedio, cada documento contenía 56,000 tokens, reflejando la longitud y complejidad de los datos web del mundo real. Para preparar este conjunto de datos, limpiamos los archivos HTML eliminando elementos innecesarios como JavaScript y CSS, mientras preservábamos elementos estructurales y semánticos clave. Después de la limpieza, usamos <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\">Jina Reader</a> para convertir archivos HTML a Markdown usando patrones regex y heurísticas.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--76-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--76-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--76-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">El histograma de longitud de tokens de archivos HTML en el conjunto de datos </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>html-markdown-1m</span></code></figcaption></figure><p>Si bien esto creó un conjunto de datos base funcional, resaltó una limitación crítica: <strong>los modelos entrenados únicamente en estas conversiones directas esencialmente solo aprenderían a imitar los patrones regex y heurísticas utilizados por Jina Reader.</strong> Esto se hizo evidente con <code>reader-lm-0.5b/1.5b</code>, cuyo límite de rendimiento estaba restringido por la calidad de estas conversiones basadas en reglas.</p><p>Para abordar estas limitaciones, desarrollamos un proceso de tres pasos que se basó en el modelo <code>Qwen2.5-32B-Instruction</code>, que es esencial para crear un conjunto de datos sintético de alta calidad.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--73-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--73-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--73-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Pipeline de generación de datos sintéticos para ReaderLM-v2, impulsado por </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Qwen2.5-32B-Instruction</span></code></figcaption></figure><ol><li><strong>Borrador</strong>: Generamos salidas iniciales en Markdown y JSON basadas en instrucciones proporcionadas al modelo. Estas salidas, aunque diversas, a menudo eran ruidosas o inconsistentes.</li><li><strong>Refinamiento</strong>: Los borradores generados fueron mejorados eliminando contenido redundante, reforzando la consistencia estructural y alineando con los formatos deseados. Este paso aseguró que los datos estuvieran limpios y alineados con los requisitos de la tarea.</li><li><strong>Crítica</strong>: Las salidas refinadas fueron evaluadas contra las instrucciones originales. Solo los datos que pasaron esta evaluación fueron incluidos en el conjunto de datos final. Este enfoque iterativo aseguró que los datos de entrenamiento cumplieran con los estándares de calidad necesarios para la extracción de datos estructurados.</li></ol><h3 id=\"training-process\">Proceso de Entrenamiento</h3><p>Nuestro proceso de entrenamiento involucró múltiples etapas adaptadas a los desafíos de procesar documentos de contexto largo.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/Heading--75-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/Heading--75-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/Heading--75-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">El entrenamiento de ReaderLM v2 sigue un proceso iterativo que combina la generación de datos en tres etapas (Borrador-Refinamiento-Crítica) con refinamiento de auto-juego, permitiendo una mejora continua.</span></figcaption></figure><p>Comenzamos con el <strong>pre-entrenamiento de contexto largo</strong>, usando el conjunto de datos <code>html-markdown-1m</code>. Se utilizaron técnicas como la atención ring-zag y la codificación posicional rotatoria (RoPE) para expandir progresivamente la longitud de contexto del modelo de 32,768 tokens a 256,000 tokens. Para mantener la estabilidad y eficiencia, adoptamos un enfoque de entrenamiento gradual, comenzando con secuencias más cortas e incrementando gradualmente la longitud del contexto.</p><p>Después del pre-entrenamiento, pasamos al <strong>ajuste fino supervisado (SFT)</strong>. Esta etapa utilizó los conjuntos de datos refinados generados en el proceso de preparación de datos. Estos conjuntos de datos incluían instrucciones detalladas para tareas de extracción de Markdown y JSON, junto con ejemplos para refinar borradores. Cada conjunto de datos fue cuidadosamente diseñado para ayudar al modelo a aprender tareas específicas, como identificar contenido principal o adherirse a estructuras JSON basadas en esquemas.</p><p>Luego aplicamos la <strong>optimización directa de preferencias (DPO)</strong> para alinear las salidas del modelo con resultados de alta calidad. En esta fase, el modelo fue entrenado en pares de respuestas borrador y refinadas. Al aprender a priorizar las salidas refinadas, el modelo internalizó las distinciones sutiles que definen resultados pulidos y específicos para cada tarea.</p><p>Finalmente, implementamos el <strong>ajuste de refuerzo por auto-juego</strong>, un proceso iterativo donde el modelo genera, refina y evalúa sus propias salidas. Este ciclo permitió que el modelo mejorara continuamente sin requerir supervisión externa adicional. Al aprovechar sus propias críticas y refinamientos, el modelo mejoró gradualmente su capacidad para producir salidas precisas y estructuradas.</p><h2 id=\"conclusion\">Conclusión</h2><p>En abril de 2024, Jina Reader se convirtió en la primera API de markdown compatible con LLM. Estableció una nueva tendencia, ganó una amplia adopción en la comunidad y, lo más importante, nos inspiró a construir modelos de lenguaje pequeños para limpieza y extracción de datos. Hoy, estamos elevando el listón nuevamente con ReaderLM-v2, cumpliendo las promesas que hicimos el septiembre pasado: mejor manejo de contexto largo, soporte para instrucciones de entrada y la capacidad de extraer contenido específico de páginas web en formato markdown. Una vez más, hemos demostrado que con un entrenamiento y calibración cuidadosos, los modelos de lenguaje pequeños pueden lograr un rendimiento de vanguardia que supera a los modelos más grandes.</p><p>Durante el proceso de entrenamiento de ReaderLM-v2, identificamos dos ideas clave. Una estrategia efectiva fue entrenar modelos especializados en conjuntos de datos separados adaptados a tareas específicas. Estos modelos específicos para tareas fueron posteriormente <em>fusionados</em> usando interpolación lineal de parámetros. Si bien este enfoque requirió esfuerzo adicional, ayudó a preservar las fortalezas únicas de cada modelo especializado en el sistema unificado final.</p><p>El proceso iterativo de síntesis de datos resultó crucial para el éxito de nuestro modelo. A través del refinamiento y evaluación repetida de datos sintéticos, mejoramos significativamente el rendimiento del modelo más allá de los enfoques simples basados en reglas. Esta estrategia iterativa, aunque presentó desafíos para mantener evaluaciones consistentes de críticas y gestionar costos computacionales, fue esencial para trascender las limitaciones del uso de datos de entrenamiento basados en regex y heurísticas de Jina Reader. Esto se demuestra claramente por la brecha de rendimiento entre <code>reader-lm-1.5b</code>, que depende en gran medida de las conversiones basadas en reglas de Jina Reader, y <code>ReaderLM-v2</code> que se beneficia de este proceso de refinamiento iterativo.</p><p>Nos entusiasma recibir sus comentarios sobre cómo ReaderLM-v2 mejora la calidad de sus datos. De cara al futuro, planeamos expandirnos hacia capacidades multimodales, particularmente para documentos escaneados, y optimizar aún más la velocidad de generación. Si está interesado en una versión personalizada de ReaderLM adaptada a su dominio específico, no dude en contactarnos.</p>",
  "comment_id": "6785bfd62defad0001fb5f22",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/readerlm-v2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2025-01-14T02:37:26.000+01:00",
  "updated_at": "2025-01-15T11:35:18.000+01:00",
  "published_at": "2025-01-15T11:35:18.000+01:00",
  "custom_excerpt": "ReaderLM-v2 is a 1.5B small language model for HTML-to-Markdown conversion and HTML-to-JSON extraction with exceptional accuracy.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/readerlm-v2-frontier-small-language-model-for-html-to-markdown-and-json/",
  "excerpt": "ReaderLM-v2 es un modelo de lenguaje pequeño de 1.5B para la conversión de HTML a Markdown y la extracción de HTML a JSON con una precisión excepcional.",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}