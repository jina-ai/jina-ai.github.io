{
  "slug": "model-soups-recipe-for-embeddings",
  "id": "681b63a077c406000104263b",
  "uuid": "e3fc45b3-6cf9-4a0b-863f-bc4a8417c436",
  "title": "La receta de Model Soup para las incrustaciones",
  "html": "<p>En estos tiempos difíciles, nada supera un buen plato de sopa caliente.</p><p>El minestrone es una de las sopas italianas clásicas: espesa, abundante, sabrosa, que combina frijoles, verduras abundantes y arroz o pasta. Su sabor es producto del ensamblaje de diversos ingredientes. Es un poco como el borscht en Europa del Este, los guisos en Estados Unidos o un salteado casero en Asia Pacífico, ya que combina ingredientes disponibles y económicos en un plato querido.</p><p>Podemos usar casi el mismo tipo de receta para los modelos de redes neuronales, según una línea de artículos que comienza con <a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://proceedings.mlr.press/v162/wortsman22a.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</div><div class=\"kg-bookmark-description\">The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-pmlr.ico\" alt=\"\"><span class=\"kg-bookmark-author\">PMLR</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://proceedings.mlr.press/v162/assets/images/logo-pmlr.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Las \"sopas de modelos\" (¡ay, no \"guisos de modelos\" o \"salteados de modelos\"!) son una clase de técnicas de ensamblaje de modelos diseñadas para mitigar el costo de optimizar los datos de entrenamiento y los hiperparámetros del modelo. Cuando se entrena una red neuronal, normalmente se prueban diferentes datos y valores de hiperparámetros y se entrena varias veces, buscando el resultado con mejor rendimiento. El entrenamiento es muy costoso desde el punto de vista computacional, y los costos se acumulan rápidamente.</p><p>En cambio, las sopas de modelos implican el entrenamiento de varios modelos con diferentes hiperparámetros y opciones de datos de entrenamiento, lo mismo que se haría normalmente, pero luego se combinan. El resultado es un modelo de mayor rendimiento y más robusto que el mejor intérprete individual. No ahorra costos porque todavía se entrenan varios modelos, pero se puede obtener un mejor resultado por el mismo precio.</p><p>El enfoque de la sopa de modelos ya ha demostrado ser útil para los modelos de incrustación multimodal de texto e imagen <a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">(Wortsman et al. 2022)</a> y los modelos generativos de lenguaje de gran tamaño. (<a href=\"https://doi.org/10.1038/s42256-024-00975-8\">Takuya et al. 2025</a>) En Jina AI, hemos comenzado a utilizar esta técnica para entrenar nuestros propios modelos, y <code>jina-embeddings-v3</code> y <code>reader-lm-v2</code> incorporan sopas de modelos.</p><p>En este artículo, vamos a analizar las sopas de modelos y a mostrar los resultados de parte de nuestro trabajo con ellas. Específicamente:</p><ol><li>¿Podemos usar sopas de modelos para mejorar el rendimiento fusionando modelos en diferentes puntos de su entrenamiento?</li><li>¿Podemos fusionar modelos entrenados con diferentes conjuntos de datos y para diferentes tareas para obtener un mejor rendimiento y una mayor eficiencia de entrenamiento que entrenando un solo modelo?</li></ol><p>Esto tiene importantes beneficios potenciales:</p><ul><li>Las sopas de modelos pueden tener un rendimiento mejor y más robusto.</li><li>Los modelos de incrustación multilingües a menudo sufren de sesgos y fallas de rendimiento causados por cantidades desiguales de datos de entrenamiento. Sería una gran ventaja poder entrenar el mejor modelo posible en cada tarea o conjunto de datos individualmente y luego combinarlos por igual.</li><li>Es posible que podamos hacer un mejor aprendizaje continuo y actualización de modelos haciendo cambios en nuestros modelos de forma modular, actualizando un componente del modelo a la vez y luego volviéndolo a fusionar con los demás.</li></ul><h2 id=\"how-does-it-work\">¿Cómo funciona?</h2><p>La fusión de las salidas de varios modelos es una técnica antigua en la teoría estadística de la decisión. Por ejemplo, es una práctica común en la previsión meteorológica crear varios modelos, a menudo realizados por diferentes personas con diferentes suposiciones, y luego utilizar una variedad de mecanismos para promediar sus predicciones. Si los errores de cada modelo se distribuyen aleatoriamente, entonces el promedio de los modelos conducirá a respuestas con menos errores.</p><p>Por ejemplo, si tiene tres modelos diferentes que producen un \"sí\" o un \"no\" binario, y cada uno se equivoca el 10% de las veces, entonces dos de los tres se equivocarán solo el 2.8% de las veces. Cinco modelos, con un criterio de decisión mayoritaria, solo se equivocarán el 0.856% de las veces.</p><p>El promedio de modelos funciona con el mismo principio, pero en lugar de combinar las salidas de diferentes modelos, combina los propios modelos.</p><p>El enfoque utilizado es una extensión del <em>promedio de peso estocástico</em> (<a href=\"https://auai.org/uai2018/proceedings/papers/313.pdf\">Izmailov et al. 2018</a>), que se basa en conocimientos sobre los paisajes de pérdida de las redes neuronales para mostrar que el promedio de peso simple puede mejorar el rendimiento de la generalización del modelo en condiciones comunes.</p><p>La mecánica real del promedio de los modelos es inquietantemente simple: solo se promedian los pesos de varios modelos.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"380\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/image.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"><figcaption><span style=\"white-space: pre-wrap;\">Cómo se fusionan los modelos para hacer una sopa de modelos. Este ejemplo es muy pequeño y simple, pero aún muestra el procedimiento: Sumar los pesos y dividir por el número de modelos que se están fusionando.</span></figcaption></figure><p>Si esto parece demasiado fácil, es importante tener en cuenta que existen limitaciones al fusionar modelos de esta manera. No se pueden fusionar los pesos de dos redes neuronales cualesquiera y esperar que funcione.</p><p>El promedio de modelos solo funciona en modelos muy similares, es decir, modelos cuyos pesos no son muy diferentes entre sí para empezar. La forma de garantizar esto es pre-entrenar un modelo y luego crear múltiples variantes de ese modelo afinándolos con diferentes hiperparámetros o diferentes datos. Estos modelos normalmente serán lo suficientemente similares como para promediarlos.</p><p>En términos más técnicos, el pre-entrenamiento generalmente produce un modelo cuyos pesos están cerca del fondo de una cuenca de pérdida, y el ajuste fino no conduce fácilmente a escapar de esa cuenca de pérdida. Si todos los modelos que se van a fusionar tienen pesos en la misma cuenca de pérdida, entonces sus pesos estarán bastante cerca de los mismos, y es probable que promediarlos funcione. Esto no está garantizado, pero empíricamente, parece ser cierto con la suficiente frecuencia como para ser útil.</p><h2 id=\"experimental-setup\">Configuración experimental</h2><p><strong>Modelo base</strong>: para los experimentos descritos aquí, utilizamos <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code> de FacebookAI</a> (<a href=\"https://aclanthology.org/2020.acl-main.747/\">Conneau et al. 2020</a>) como nuestro modelo base pre-entrenado. Este modelo tiene 280 millones de parámetros y ha sido pre-entrenado en 2.5 TB de datos de Common Crawl que contienen texto en aproximadamente 100 idiomas.</p><p>Afinamos <a href=\"https://huggingface.co/FacebookAI/xlm-roberta-base\"><code>xlm-roberta-base</code></a> en nuestro conjunto de entrenamiento de pares de oraciones curado para el entrenamiento de incrustaciones, antes de realizar nuestros experimentos.</p><p><strong>Datos de entrenamiento</strong>: Jina AI mantiene conjuntos de datos personalizados curados para el entrenamiento. Para el primer experimento, utilizamos trillizos de oraciones específicamente curados para el entrenamiento contrastivo en seis idiomas: inglés, árabe, alemán, español, japonés y chino. Para el segundo experimento, utilizamos conjuntos de datos de entrenamiento específicos de la tarea en inglés.</p><p><strong>Evaluación</strong>: utilizamos partes relevantes del <a href=\"https://github.com/embeddings-benchmark/mteb/tree/main/docs/mmteb\">conjunto de pruebas MMTEB</a> (<a href=\"https://arxiv.org/abs/2502.13595\">Enevoldsen et al. 2025</a>) y el <a href=\"https://project-miracl.github.io/\">punto de referencia MIRACL</a> (<a href=\"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00595/117438/MIRACL-A-Multilingual-Retrieval-Dataset-Covering\">Zhang et al. 2023</a>) para evaluar los modelos producidos por nuestro entrenamiento y fusión.</p><h3 id=\"experiment-1-single-run-averaging\">Experimento 1: Promedio de una sola ejecución</h3><p>Para este experimento, utilizamos trillizos de oraciones contrastivas en los seis idiomas, mezclados, para un total de 6,000 pasos de entrenamiento con un tamaño de lote de 1,024 elementos. Cada 2,000 pasos, guardamos el estado del modelo para el promedio, produciendo 3 modelos, cada uno de los cuales refleja un punto diferente en el proceso de entrenamiento.</p><p>Promediamos los tres modelos para producir un modelo final. Luego probamos el modelo fusionado y los tres puntos de control guardados contra los conjuntos de pruebas MMTEB-STS y MIRACL.</p><p>Nuestros resultados se resumen en la siguiente tabla:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>MIRACL<br>(avg 6 languages)</th>\n<th>MMTEB-STS English<br>(avg 8 benchmarks)</th>\n<th>MMTEB-STS Multilingual<br>(avg 6 benchmarks)</th>\n<th>Average of 20 benchmarks</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>No triplet training</td>\n<td>0.3163</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.6276</td>\n</tr>\n<tr>\n<td>Step 2000</td>\n<td>0.4631</td>\n<td><strong>0.7924</strong></td>\n<td>0.7561</td>\n<td>0.6813</td>\n</tr>\n<tr>\n<td>Step 4000</td>\n<td>0.4639</td>\n<td>0.7902</td>\n<td><strong>0.7583</strong></td>\n<td>0.6812</td>\n</tr>\n<tr>\n<td>Step 6000 (final)</td>\n<td><strong>0.4680</strong></td>\n<td>0.7891</td>\n<td>0.7575</td>\n<td>0.6818</td>\n</tr>\n<tr>\n<td>Merged model<br>(all 3 stored checkpoints)</td>\n<td>0.4669</td>\n<td>0.7910</td>\n<td>0.7579</td>\n<td><strong>0.6823</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>La fusión con los puntos de control anteriores generalmente no produjo un modelo de mejor rendimiento que el de mejor rendimiento entre los puntos de control almacenados en puntos de referencia individuales o en cualquiera de las tres baterías de puntos de referencia utilizadas. Sin embargo, sí produjo el mejor modelo en todos los puntos de referencia promediados juntos.</p><p>En los puntos de referencia individuales, la diferencia entre el modelo fusionado y el punto de control de mejor rendimiento es en todos los casos inferior a 0.01. Esto es cierto no solo para los promedios en la tabla anterior, sino para cada prueba individual.</p><p>Esto demuestra que la fusión de diferentes puntos de control de entrenamiento puede producir un modelo más robusto con muy poco costo de rendimiento.</p><p>Además, al fusionar los diferentes puntos de control, podemos protegernos eficazmente contra el sobreentrenamiento. El sobreentrenamiento se ha convertido recientemente en un tema importante en las redes neuronales. (<a href=\"https://arxiv.org/abs/2503.19206v2\">Springer et al., 2025</a>) Una red se puede entrenar de una manera que la haga más difícil y de peor rendimiento después de un ajuste fino adicional.</p><p>Dado que el punto de control de mejor rendimiento en nuestro experimento a menudo no es el último, es probable que hayamos sobreentrenado nuestro modelo en 6,000 pasos de entrenamiento. El modelo fusionado se acerca mucho a igualar el rendimiento del mejor punto de control en todas las pruebas, eliminando los defectos del sobreentrenamiento.</p><h3 id=\"experiment-2-averaging-models-trained-for-different-tasks\">Experimento 2: Promedio de modelos entrenados para diferentes tareas</h3><p>Para este experimento, entrenamos tres modelos, cada uno para una tarea de incrustación común diferente:</p><ul><li><strong>Similitud semántica</strong>: Medición de la superposición o similitud relativa en el significado entre dos textos, normalmente de longitud comparable.</li><li><strong>Recuperación de documentos basada en consultas textuales</strong>: Encontrar los documentos que mejor satisfacen una consulta. Las consultas son generalmente textos mucho más cortos que los documentos que coinciden.</li><li><strong>Preguntas y respuestas</strong>: Encontrar el documento que mejor responde a una pregunta en lenguaje natural. Las preguntas también son generalmente más cortas que los textos que coinciden.</li></ul><p>Entrenar modelos para las tres tareas a la vez es bastante difícil porque los objetivos son muy dispares, y esperamos que las \"sopas de modelos\" mejoren el proceso.</p><p>Según la experiencia anterior, sabíamos que cada tarea requería un número diferente de épocas de entrenamiento. El entrenamiento se resume a continuación:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Tarea</th>\n<th>Pasos de entrenamiento<br>(tamaño de lote = 1,024)</th>\n<th>Tamaño del conjunto de datos de entrenamiento<br>(en elementos)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Preguntas y respuestas (QA)</td>\n<td>2,000</td>\n<td>256,000</td>\n</tr>\n<tr>\n<td>Recuperación de documentos</td>\n<td>3,000</td>\n<td>384,000</td>\n</tr>\n<tr>\n<td>Similitud Semántica (STS)</td>\n<td>1,000</td>\n<td>128,000</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Esto produjo tres modelos, que luego fusionamos en un solo modelo. Probamos el modelo resultante con las partes del conjunto de puntos de referencia MMTEB relevantes para esas tres tareas: <a href=\"https://project-miracl.github.io/\">MIRACL</a>, <a href=\"https://huggingface.co/collections/zeta-alpha-ai/nanobeir-66e1a0af21dfd93e620cd9f6\">NanoBEIR</a> y STSEval (partes en inglés y multilingües de MMTEB).</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(promedio de 6 idiomas)</th>\n<th>NanoBEIR<br>(promedio de 13 puntos de referencia)</th>\n<th>MMTEB-STS Inglés<br>(promedio de 9 puntos de referencia)</th>\n<th>MMTEB-STS Multilingüe<br>(promedio de 6 puntos de referencia)</th>\n<th>Promedio de 34 puntos de referencia</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Sin entrenamiento de tripletes</td>\n<td>0.3163</td>\n<td>0.5089</td>\n<td>0.7859</td>\n<td>0.7322</td>\n<td>0.5876</td>\n</tr>\n<tr>\n<td>Entrenamiento QA</td>\n<td><strong>0.4489</strong></td>\n<td>0.5332</td>\n<td>0.7843</td>\n<td>0.7535</td>\n<td>0.6237</td>\n</tr>\n<tr>\n<td>Entrenamiento de recuperación</td>\n<td>0.4272</td>\n<td><strong>0.5360</strong></td>\n<td>0.7766</td>\n<td>0.7340</td>\n<td>0.6154</td>\n</tr>\n<tr>\n<td>Entrenamiento STS</td>\n<td>0.1779</td>\n<td>0.4519</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.5508</td>\n</tr>\n<tr>\n<td>Modelo fusionado</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td><strong>0.6240</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Vemos aquí que los modelos entrenados específicamente para cada tarea tienen el mejor rendimiento en cada tarea. MIRACL es principalmente un punto de referencia de preguntas y respuestas, incluso si se llama de recuperación, y el modelo entrenado en QA supera a todos los demás en él, incluido el modelo fusionado. NanoBEIR es un conjunto de puntos de referencia de recuperación de información más convencional, y vemos que el modelo entrenado en recuperación es el que mejor funciona en él. El modelo de similitud semántica (STS) obtiene una puntuación bastante baja en esos puntos de referencia, pero supera a los demás en tareas explícitamente STS. Para cada categoría, el modelo fusionado tiene un rendimiento inferior al del modelo entrenado en una sola tarea.</p><p>Pero, una vez más, si promediamos todos los puntos de referencia, el modelo fusionado supera a los demás, aunque su puntuación representa sólo una mejora muy pequeña con respecto al modelo entrenado en QA, y tiene un rendimiento muy pobre en las tareas STS.</p><p>También fusionamos sólo los modelos QA y de recuperación y puntuamos el modelo resultante en los mismos puntos de referencia:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>MIRACL<br>(promedio de 6 idiomas)</th>\n<th>NanoBEIR<br>(promedio de 13 puntos de referencia)</th>\n<th>MMTEB-STS Inglés<br>(promedio de 9 puntos de referencia)</th>\n<th>MMTEB-STS Multilingüe<br>(promedio de 6 puntos de referencia)</th>\n<th>Promedio de 34 pruebas</th>\n<th>Promedio<br>QA &amp; IR<br>(19 pruebas)</th>\n<th>Promedio STS<br>(15 pruebas)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Mejor modelo entrenado para la tarea</td>\n<td>0.4489</td>\n<td>0.5360</td>\n<td><strong>0.7994</strong></td>\n<td><strong>0.7651</strong></td>\n<td>0.6237</td>\n<td>0.5066</td>\n<td><strong>0.7857</strong></td>\n</tr>\n<tr>\n<td>Modelo fusionado</td>\n<td>0.4246</td>\n<td>0.5309</td>\n<td>0.7981</td>\n<td>0.7640</td>\n<td>0.6240</td>\n<td>0.4973</td>\n<td>0.7845</td>\n</tr>\n<tr>\n<td>Modelo fusionado QA+Recuperación</td>\n<td><strong>0.4610</strong></td>\n<td><strong>0.5404</strong></td>\n<td>0.7878</td>\n<td>0.7498</td>\n<td><strong>0.6288</strong></td>\n<td><strong>0.5153</strong></td>\n<td>0.7726</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Vemos aquí que, si bien podemos mejorar el rendimiento tanto en preguntas y respuestas como en la recuperación fusionando modelos entrenados para las dos tareas, agregar modelos entrenados en STS reduce el rendimiento específico de la tarea en todas las categorías. Esto sugiere que la similitud semántica es, en algunos aspectos importantes, diferente de QA y la recuperación, y que un modelo entrenado en STS no es adecuado para fusionarse con los otros dos.</p><p>Esto se debe probablemente a que las preguntas y respuestas y la recuperación implican la comparación de textos cortos (preguntas y consultas) con documentos más largos, mientras que la similitud semántica implica la comparación de documentos de longitud más similar.</p><p><a href=\"https://proceedings.mlr.press/v162/wortsman22a.html\">Wortsman et al. (2022)</a> describen un enfoque selectivo para el promedio que denominan fusión \"codiciosa\". Implica tomar un modelo, generalmente el de mejor rendimiento de un conjunto de modelos, y luego agregarle solo aquellos modelos que individualmente mejoran el rendimiento. Con solo tres modelos, tenía poco sentido usar la fusión codiciosa para este experimento. Sin embargo, podríamos imaginar un caso con más modelos y usar una técnica como esta como base para determinar el grado de similitud entre las tareas. Aquí encontramos que la similitud semántica es diferente de las otras dos. Luego podríamos evaluar cuándo un modelo puede realizar muchas tareas y cuándo es más rentable usar un modelo diferente.</p><h2 id=\"soup%E2%80%99s-on\">¡La sopa está servida!</h2><p>Las \"sopas de modelos\" combinan la diversidad en algo mayor que la suma de sus partes. El valor de este enfoque radica en su capacidad para ofrecer una mayor consistencia, robustez y actuar como salvaguarda contra el sobreentrenamiento sin costo de entrenamiento adicional. Nuestros experimentos muestran que la fusión de puntos de control o modelos especializados en tareas puede mejorar el rendimiento general, incluso si ocasionalmente tiene el costo de picos específicos de la tarea.</p><p>Al final, las \"sopas de modelos\" ofrecen una forma práctica y muy sencilla de construir modelos más adaptables, aunque con algunas advertencias. No es una panacea y solo es aplicable cuando los modelos ya son muy similares.</p><p>Como dicen en Internet, <em>Your Mileage May Vary</em>. Pero es barato y fácil averiguar si las \"sopas de modelos\" pueden ayudar cuando entrenas tus modelos.</p>",
  "comment_id": "681b63a077c406000104263b",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/Heading--6-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-07T15:44:00.000+02:00",
  "updated_at": "2025-05-07T19:56:02.000+02:00",
  "published_at": "2025-05-07T18:43:10.000+02:00",
  "custom_excerpt": "Boost robustness and performance with model soups: averaging weights. No extra cost, better results.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "authors": [
    {
      "id": "6360e7e05e0f6e004d70bd99",
      "name": "Bo Wang",
      "slug": "bo",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
      "cover_image": null,
      "bio": "Developer @Jina, Contributor to open source ",
      "website": "https://bwanglzu.github.io/",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@bo_wangbo",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "primary_author": {
    "id": "6360e7e05e0f6e004d70bd99",
    "name": "Bo Wang",
    "slug": "bo",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg",
    "cover_image": null,
    "bio": "Developer @Jina, Contributor to open source ",
    "website": "https://bwanglzu.github.io/",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@bo_wangbo",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/model-soups-recipe-for-embeddings/",
  "excerpt": "Mejore la robustez y el rendimiento con sopas de modelos: promediando pesos. Sin costo adicional, mejores resultados.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}