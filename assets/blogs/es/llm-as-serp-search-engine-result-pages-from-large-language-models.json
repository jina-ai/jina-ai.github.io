{
  "slug": "llm-as-serp-search-engine-result-pages-from-large-language-models",
  "id": "67c02c3b343c560001efca6e",
  "uuid": "ec03076e-dc8a-44ea-bd09-57c5e6a6d593",
  "title": "LLM como SERP: Páginas de resultados de motores de búsqueda desde modelos de lenguaje grandes",
  "html": "<figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/llm-serp-demo\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">LLM as SERP</div><div class=\"kg-bookmark-description\">Large language model as search result page</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-19.png\" alt=\"\"><span class=\"kg-bookmark-author\">LLMSERP</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-llm-serp.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">Prueba la demo interactiva y observa cómo aparece tu sitio en LLM SERP.</span></p></figcaption></figure><p>Desde RAG, la tendencia ha sido usar LLMs para mejorar la búsqueda. Desde Perplexity hasta DeepSearch y DeepResearch, la idea de inyectar resultados del motor de búsqueda en el proceso de generación se ha convertido en algo estándar. Muchos usuarios también afirman que ya no usan Google tan a menudo como antes, encontrando su diseño clásico de paginación aburrido, abrumador o tedioso. En cambio, se han acostumbrado a la alta precisión y recuperación de resultados estilo pregunta-respuesta desde una interfaz de búsqueda tipo chat, sugiriendo que esta filosofía de diseño podría ser el camino a seguir.</p><p><strong>Pero ¿y si el propio LLM <em>fuera</em> el motor de búsqueda?</strong> </p><p>¿Qué pasaría si pudieras explorar el conocimiento integrado en los LLMs como si estuvieras usando Google? Paginación, enlaces y todo - justo como en los viejos tiempos con los que estás familiarizado. Si no estás seguro de a qué me refiero, revisa primero la demo a continuación.</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp.mp4\" poster=\"https://img.spacergif.org/v1/1426x976/0a/spacer.png\" width=\"1426\" height=\"976\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/02/llmserp_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Los enlaces, títulos y fragmentos son completamente generados por un LLM. Puedes visitar </span><a href=\"https://jina.ai/llm-serp-demo\"><span style=\"white-space: pre-wrap;\">https://jina.ai/llm-serp-demo</span></a><span style=\"white-space: pre-wrap;\"> y probar algunas consultas tú mismo! </span></p></figcaption>\n        </figure><p>Antes de plantear preocupaciones sobre las alucinaciones, expliquemos primero por qué esta idea tiene <em>algo</em> de mérito: los LLMs están entrenados en vastos repositorios de conocimiento web. Modelos como DeepSeek-R1, GPT-4, Claude-3.7 y Gemini-2.0 han sido entrenados con billones de tokens de todo el internet público. Una estimación aproximada es que <strong>entre &lt;1% y ~5% del texto web de alta calidad y accesible públicamente</strong> se ha utilizado para entrenar los modelos principales.</p><p>Si piensas que este número parece demasiado pequeño, considera esta comparación: si usamos el índice de Google como referencia (representando el 100% de los datos accesibles por usuarios en el mundo), entonces el índice de Bing es aproximadamente 30-50% del de Google. Baidu cubre alrededor del 5-10%, y Yandex cubre 3-5%. Brave Search indexa menos del 1%. Así que si un LLM está entrenado en 1-5% de datos públicos de alta calidad, potencialmente iguala la misma cantidad de datos que un motor de búsqueda pequeño decente puede proporcionar.</p><p>Dado que estos modelos han \"recordado\" efectivamente estos datos web, simplemente necesitamos darles prompts de una manera que \"active\" su memoria, permitiéndoles funcionar como motores de búsqueda y generar resultados similares a una página de resultados de motor de búsqueda (SERP).</p><p>Así que sí, la alucinación es un desafío, pero a medida que las capacidades del modelo mejoran con cada iteración, podemos esperar razonablemente que este problema se alivie. En X, la gente está a menudo obsesionada con generar SVGs desde cero cada vez que se lanza un nuevo modelo, esperando que cada versión produzca mejores ilustraciones que la anterior. Esta idea del motor de búsqueda sigue una esperanza similar de mejora incremental en la comprensión del mundo digital por parte del LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1176\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/02/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/02/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/02/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/02/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://x.com/huybery/status/1893996258760527882\"><span style=\"white-space: pre-wrap;\">Binyuan Hui </span></a><span style=\"white-space: pre-wrap;\">(uno de los desarrolladores principales detrás de los modelos Qwen) mostrando la capacidad de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>qwen-2.5-max</span></code><span style=\"white-space: pre-wrap;\"> para dibujar un cerdo SVG en una sola toma.</span></figcaption></figure><p>Las fechas de corte del conocimiento presentan otra limitación. Los motores de búsqueda deberían devolver información casi en tiempo real, pero dado que los pesos del LLM están congelados después del entrenamiento, no pueden proporcionar información precisa más allá de su fecha de corte. Generalmente, cuanto más cerca está una consulta de esta fecha de corte, más probable es que ocurran alucinaciones. Ya que la información más antigua probablemente ha sido citada y reformulada con más frecuencia, potencialmente aumentando sus pesos en los datos de entrenamiento. (Esto asume que la información está ponderada uniformemente; las noticias de última hora pueden recibir una atención desproporcionada independientemente de su antigüedad.) <strong>Sin embargo, esta limitación en realidad define precisamente dónde este enfoque podría ser más útil—para información bien dentro del marco temporal de conocimiento del modelo.</strong></p><h2 id=\"where-llm-as-serp-can-be-useful\">¿Dónde puede ser útil LLM-as-SERP?</h2><p>En DeepSearch/RAG o cualquier sistema de búsqueda fundamentada, un desafío central es determinar si una pregunta necesita información externa o puede ser respondida desde el conocimiento del modelo. Los sistemas actuales típicamente usan enrutamiento basado en prompts con instrucciones como:</p><pre><code>- For greetings, casual conversation, or general knowledge questions, answer directly without references.\n- For all other questions, provide a verified answer with external knowledge. Each reference must include exactQuote and url.</code></pre><p>Este enfoque falla en ambas direcciones - a veces activando búsquedas innecesarias, otras veces perdiendo necesidades críticas de información. Especialmente con los nuevos modelos de razonamiento, a menudo no es obvio hasta la mitad de la generación si se necesitan datos externos.</p><p>¿Qué tal si simplemente ejecutáramos la búsqueda de todos modos? Podríamos hacer una llamada a una API de búsqueda real y otra a un sistema LLM-como-búsqueda. Esto elimina la decisión de enrutamiento inicial y la mueve hacia abajo donde tenemos resultados reales para comparar - datos recientes de búsqueda real, conocimiento dentro del corte de entrenamiento del modelo, y potencialmente alguna información incorrecta.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/02/Heading--41-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p>El paso final de razonamiento puede entonces identificar inconsistencias y ponderar las fuentes basándose en su actualidad, fiabilidad y consenso entre los resultados, lo cual no tenemos que codificar explícitamente, ya que esto es en lo que los LLMs ya destacan. También se puede visitar cada URL en los resultados de búsqueda (por ejemplo, con Jina Reader) para validar aún más las fuentes. En implementaciones prácticas, este paso de verificación siempre es necesario de todas formas; nunca deberías confiar únicamente en extractos de motores de búsqueda, sean motores de búsqueda reales o falsos.</p><h2 id=\"conclusion\">Conclusión</h2><p>Al usar LLM-as-SERP, <strong>transformamos la pregunta binaria de \"¿está esto dentro del conocimiento del modelo o no?\" en un proceso más robusto de ponderación de evidencia.</strong></p><p>Proporcionamos <a href=\"https://jina.ai/llm-serp-demo\" rel=\"noreferrer\">un playground</a> así como <a href=\"https://jina.ai/api-dashiboard/llm-serp\" rel=\"noreferrer\">un endpoint de API alojado por nosotros</a> con el que puedes experimentar. También siéntete libre de integrarlo en tus propias implementaciones de DeepSearch/DeepResearch para ver cualquier mejora de primera mano.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/jina-ai/node-serp\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - jina-ai/node-serp: LLMs-as-SERPs</div><div class=\"kg-bookmark-description\">LLMs-as-SERPs. Contribute to jina-ai/node-serp development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/pinned-octocat-093da3e6fa40-3.svg\" alt=\"\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">jina-ai</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/node-serp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>La API imita un endpoint SERP completo donde puedes definir el número de resultados, paginación, país, idioma, etc. Puedes encontrar su implementación en GitHub. Estamos ansiosos por escuchar tus comentarios sobre este interesante enfoque.</p>",
  "comment_id": "67c02c3b343c560001efca6e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/02/llmserp-banner.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-02-27T10:11:23.000+01:00",
  "updated_at": "2025-02-27T13:38:43.000+01:00",
  "published_at": "2025-02-27T13:36:57.000+01:00",
  "custom_excerpt": "This is either an extremely smart idea or an extremely stupid one—there's no in-between.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/llm-as-serp-search-engine-result-pages-from-large-language-models/",
  "excerpt": "Esto es o bien una idea extremadamente inteligente o bien una extremadamente estúpida—no hay punto medio.",
  "reading_time": 5,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}