{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3: Un Modelo de Embeddings Multilingüe de Vanguardia",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">Estamos en un viaje para avanzar y democratizar la inteligencia artificial a través del código abierto y la ciencia abierta.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3: Embeddings Multilingües con Task LoRA</div><div class=\"kg-bookmark-description\">Presentamos jina-embeddings-v3, un novedoso modelo de embeddings de texto con 570 millones de parámetros, que logra un rendimiento estado del arte en datos multilingües y tareas de recuperación de contexto largo, soportando longitudes de contexto de hasta 8192 tokens. El modelo incluye un conjunto de adaptadores Low-Rank Adaptation (LoRA) específicos por tarea para generar embeddings de alta calidad para recuperación de consultas y documentos, agrupación, clasificación y correspondencia de texto. Además, el Aprendizaje de Representación Matryoshka está integrado en el proceso de entrenamiento, permitiendo una truncación flexible de las dimensiones de los embeddings sin comprometer el rendimiento. La evaluación en el benchmark MTEB muestra que jina-embeddings-v3 supera a los últimos embeddings propietarios de OpenAI y Cohere en tareas en inglés, mientras logra un rendimiento superior comparado con multilingual-e5-large-instruct en todas las tareas multilingües.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Hoy, nos complace anunciar <code>jina-embeddings-v3</code>, un modelo de embeddings de texto de vanguardia con 570 millones de parámetros. Logra un rendimiento estado del arte en datos <strong>multilingües</strong> y tareas de recuperación de <strong>contexto largo</strong>, soportando una longitud de entrada de hasta 8192 tokens. El modelo cuenta con adaptadores Low-Rank Adaptation (LoRA) específicos por tarea, permitiéndole generar embeddings de alta calidad para varias tareas incluyendo <strong>recuperación de consultas y documentos</strong>, <strong>agrupación</strong>, <strong>clasificación</strong> y <strong>correspondencia de texto</strong>.</p><p>En evaluaciones en MTEB English, Multilingual y LongEmbed, <code>jina-embeddings-v3</code> supera a los últimos embeddings propietarios de OpenAI y Cohere en tareas en inglés, mientras también supera a <code>multilingual-e5-large-instruct</code> en todas las tareas multilingües. Con una dimensión de salida predeterminada de 1024, los usuarios pueden truncar arbitrariamente las dimensiones de los embeddings hasta 32 sin sacrificar rendimiento, gracias a la integración del Aprendizaje de Representación Matryoshka (MRL).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\">El rendimiento de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> vs otros modelos de embeddings en todas las tareas MTEB en inglés. Los resultados completos de evaluación por tarea se pueden encontrar en </span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">nuestro paper en arXiv</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">El rendimiento de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> ha sido evaluado en una amplia selección de tareas MTEB multilingües y translingües. Nótese que </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2-(zh/es/de)</span></code><span style=\"white-space: pre-wrap;\"> se refiere a nuestra suite de modelos bilingües, que solo fue probada en tareas monolingües y translingües en chino, español y alemán, excluyendo todos los demás idiomas. Además, no reportamos puntuaciones para </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>openai-text-embedding-3-large</span></code><span style=\"white-space: pre-wrap;\"> y </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>cohere-embed-multilingual-v3.0</span></code><span style=\"white-space: pre-wrap;\">, ya que estos modelos no fueron evaluados en el rango completo de tareas MTEB multilingües y translingües.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">El rendimiento de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> en seis tareas de recuperación de documentos largos del benchmark LongEmbed muestra una mejora significativa sobre otros modelos. Las puntuaciones son nDCG@10; más alto es mejor. Esto sugiere la efectividad de nuestros embeddings posicionales basados en RoPE, que superan tanto a los embeddings posicionales fijos utilizados por </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>baai-bge-m3</span></code><span style=\"white-space: pre-wrap;\"> como al enfoque basado en ALiBi utilizado en </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>Desde su lanzamiento el 18 de septiembre de 2024, <code>jina-embeddings-v3</code> es <strong>el mejor</strong> modelo multilingüe y ocupa el <strong>2do</strong> lugar en la tabla de clasificación MTEB en inglés para modelos con menos de 1.000 millones de parámetros. v3 soporta 89 idiomas en total, incluyendo 30 idiomas con el mejor rendimiento: árabe, bengalí, chino, danés, holandés, inglés, finlandés, francés, georgiano, alemán, griego, hindi, indonesio, italiano, japonés, coreano, letón, noruego, polaco, portugués, rumano, ruso, eslovaco, español, sueco, tailandés, turco, ucraniano, urdu y vietnamita.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Desde su lanzamiento el 18 de septiembre de 2024, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\">, con 570 millones de parámetros y 1024 dimensiones de salida, se posiciona como el modelo de embeddings multilingüe más eficiente, potente y confiable con menos de 1.000 millones de parámetros.</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">Ley de escalado de modelos de embeddings. El rendimiento promedio en tareas MTEB en inglés se grafica contra el número de parámetros del modelo. Cada punto representa un modelo de embeddings. La línea de tendencia, que representa todos los modelos, está resaltada, con los modelos multilingües enfatizados en cian. Se puede ver que </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> demuestra un rendimiento superior comparado con modelos de tamaño similar, mostrando también una mejora superlineal sobre su predecesor, </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\">. Este gráfico fue creado seleccionando los 100 mejores modelos de embeddings de la tabla de clasificación MTEB, excluyendo aquellos sin información de tamaño, típicamente modelos cerrados o propietarios. También se filtraron las presentaciones identificadas como trolleo obvio.</span></figcaption></figure><p>Además, comparado con los embeddings basados en LLM que recientemente han ganado atención, como <code>e5-mistral-7b-instruct</code>, que tiene un tamaño de parámetros de 7.1 mil millones (12 veces más grande) y una dimensión de salida de 4096 (4 veces más grande) pero ofrece solo una mejora del 1% en tareas MTEB en inglés, <code>jina-embeddings-v3</code> es una solución mucho más eficiente en costos, haciéndola más adecuada para producción y computación en el borde.</p><h2 id=\"model-architecture\">Arquitectura del Modelo</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Característica</th>\n<th>Descripción</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>Parámetros Base</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>Parámetros con LoRA</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>Máximo de tokens de entrada</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>Dimensiones máximas de salida</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>Capas</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Vocabulario</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>Idiomas soportados</td>\n<td>89</td>\n</tr>\n<tr>\n<td>Atención</td>\n<td>FlashAttention2, también funciona sin él</td>\n</tr>\n<tr>\n<td>Agrupación</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>La arquitectura de <code>jina-embeddings-v3</code> se muestra en la figura siguiente. Para implementar la arquitectura base, adaptamos el modelo <code>XLM-RoBERTa</code> con varias modificaciones clave: (1) permitiendo la codificación efectiva de secuencias largas de texto, (2) permitiendo la codificación de embeddings específica para cada tarea, y (3) mejorando la eficiencia general del modelo con las técnicas más recientes. Seguimos usando el tokenizador original de <code>XLM-RoBERTa</code>. Si bien <code>jina-embeddings-v3</code>, con sus 570 millones de parámetros, es más grande que <code>jina-embeddings-v2</code> que tiene 137 millones, sigue siendo mucho más pequeño que los modelos de embedding ajustados a partir de LLMs.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\">La arquitectura de </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> está basada en el modelo </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\">, con cinco adaptadores LoRA para cuatro tareas diferentes.</span></figcaption></figure><p>La innovación clave en <code>jina-embeddings-v3</code> es el uso de adaptadores LoRA. Se introducen <strong>cinco</strong> adaptadores LoRA específicos para optimizar embeddings para <strong>cuatro</strong> tareas. La entrada del modelo consta de dos partes: el texto (el documento largo a embeber) y la tarea. <code>jina-embeddings-v3</code> soporta cuatro tareas e implementa cinco adaptadores para elegir: <code>retrieval.query</code> y <code>retrieval.passage</code> para embeddings de consultas y pasajes en tareas de recuperación asimétrica, <code>separation</code> para tareas de agrupamiento, <code>classification</code> para tareas de clasificación, y <code>text-matching</code> para tareas que involucran similitud semántica, como STS o recuperación simétrica. Los adaptadores LoRA representan menos del 3% del total de parámetros, añadiendo una sobrecarga mínima al cómputo.</p><p>Para mejorar aún más el rendimiento y reducir el consumo de memoria, integramos FlashAttention 2, soportamos puntos de control de activación y usamos el framework DeepSpeed para entrenamiento distribuido eficiente.</p><h2 id=\"get-started\">Primeros Pasos</h2><h3 id=\"via-jina-ai-search-foundation-api\">A través de la API Search Foundation de Jina AI</h3><p>La forma más fácil de usar <code>jina-embeddings-v3</code> es visitar la <a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">página principal de Jina AI</a> y navegar a la sección de Search Foundation API. A partir de hoy, este modelo está establecido como predeterminado para todos los nuevos usuarios. Puedes explorar diferentes parámetros y características directamente desde allí.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>En comparación con v2, v3 introduce tres nuevos parámetros en la API: <code>task</code>, <code>dimensions</code>, y <code>late_chunking</code>.</p><h4 id=\"parameter-task\">Parámetro <code>task</code></h4><p>El parámetro <code>task</code> es crucial y debe establecerse según la tarea posterior. Los embeddings resultantes serán optimizados para esa tarea específica. Para más detalles, consulta la lista siguiente.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong>Valor de <code>task</code></strong></th>\n<th><strong>Descripción de la Tarea</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>Embedding de <b>documentos</b> en una tarea de recuperación consulta-documento</td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>Embedding de <b>consultas</b> en una tarea de recuperación consulta-documento</td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>Agrupamiento de documentos, visualización de corpus</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>Clasificación de texto</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(Predeterminado)</b> Similitud semántica de texto, recuperación simétrica general, recomendación, búsqueda de elementos similares, deduplicación</td>\n</tr>\n</tbody>\n</table>\n\n<!--kg-card-end: html-->\n<p>Ten en cuenta que la API <em>no</em> genera primero un meta-embedding genérico y luego lo adapta con un MLP adicional ajustado. En su lugar, inserta el adaptador LoRA específico para la tarea en cada capa del transformador (un total de 24 capas) y realiza la codificación de una sola vez. Más detalles se pueden encontrar en <a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">nuestro artículo en arXiv</a>.</p><h4 id=\"parameter-dimensions\">Parámetro <code>dimensions</code></h4><p>El parámetro <code>dimensions</code> permite a los usuarios elegir un equilibrio entre eficiencia espacial y rendimiento al menor costo. Gracias a la técnica MRL utilizada en <code>jina-embeddings-v3</code>, puedes reducir las dimensiones de los embeddings tanto como desees (¡incluso a una sola dimensión!). Los embeddings más pequeños son más eficientes en términos de almacenamiento para bases de datos vectoriales, y su costo de rendimiento puede estimarse a partir de la figura siguiente.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">Parámetro <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Late Chunking en Modelos de Embedding de Contexto Largo</div><div class=\"kg-bookmark-description\">La segmentación de documentos largos mientras se preserva la información contextual es un desafío. Introducimos el \"Late Chunking\" que aprovecha los modelos de embedding de contexto largo para generar embeddings de segmentos contextuales para mejores aplicaciones de recuperación.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Finalmente, el parámetro <code>late_chunking</code> controla si se usa el nuevo método de segmentación <a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">que introdujimos el mes pasado</a> para codificar un lote de oraciones. Cuando se establece en <code>true</code>, nuestra API concatenará todas las oraciones en el campo <code>input</code> y las alimentará como una única cadena al modelo. En otras palabras, <strong>tratamos las oraciones en la entrada como si originalmente vinieran de la misma sección, párrafo o documento.</strong> Internamente, el modelo embebe esta larga cadena concatenada y luego realiza la segmentación tardía, devolviendo una lista de embeddings que coincide con el tamaño de la lista de entrada. Cada embedding en la lista está por lo tanto condicionado a los embeddings previos.</p><p>Desde la perspectiva del usuario, establecer <code>late_chunking</code> <em>no</em> cambia el formato de entrada o salida. Solo notarás un cambio en los valores de embedding, ya que ahora se calculan basándose en todo el contexto previo en lugar de independientemente. Lo que es importante saber al usar<code>late_chunking=True</code> significa que el número total de tokens (sumando todos los tokens en <code>input</code>) por solicitud está restringido a 8192, que es la longitud máxima de contexto permitida para <code>jina-embeddings-v3</code>. Cuando <code>late_chunking=False</code>, no existe tal restricción; el número total de tokens solo está sujeto a <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">el límite de tasa de la API de Embedding</a>.</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking activado vs desactivado: El formato de entrada y salida permanece igual, siendo la única diferencia los valores de embedding. Cuando </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\"> está habilitado, los embeddings están influenciados por todo el contexto previo en </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\">, mientras que sin él, los embeddings se calculan de forma independiente.</span></p></figcaption></figure><h3 id=\"via-azure-aws\">A través de Azure y AWS</h3><p><code>jina-embeddings-v3</code> está ahora disponible en AWS SageMaker y Azure Marketplace.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>Si necesitas utilizarlo más allá de estas plataformas o en las instalaciones de tu empresa, ten en cuenta que el modelo está licenciado bajo CC BY-NC 4.0. <a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Para consultas sobre uso comercial, no dudes en contactarnos.</a></p><h3 id=\"via-vector-databases-partners\">A través de Bases de Datos Vectoriales y Socios</h3><p>Colaboramos estrechamente con proveedores de bases de datos vectoriales como Pinecone, Qdrant y Milvus, así como con frameworks de orquestación de LLM como LlamaIndex, Haystack y Dify. Al momento del lanzamiento, nos complace anunciar que Pinecone, Qdrant, Milvus y Haystack ya han integrado soporte para <code>jina-embeddings-v3</code>, incluyendo los tres nuevos parámetros: <code>task</code>, <code>dimensions</code> y <code>late_chunking</code>. Otros socios que ya se han integrado con la API <code>v2</code> también deberían soportar <code>v3</code> simplemente cambiando el nombre del modelo a <code>jina-embeddings-v3</code>. Sin embargo, es posible que aún no soporten los nuevos parámetros introducidos en <code>v3</code>.</p><h4 id=\"via-pinecone\">A través de Pinecone</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">A través de Qdrant</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">A través de Milvus</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">A través de Haystack</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">Conclusión</h2><p>En octubre de 2023, lanzamos <code>jina-embeddings-v2-base-en</code>, <a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">el primer modelo de embedding de código abierto del mundo con una longitud de contexto de 8K</a>. Era el <em>único</em> modelo de embedding de texto que soportaba contexto largo y se equiparaba a <code>text-embedding-ada-002</code> de OpenAI. Hoy, después de un año de aprendizaje, experimentación y valiosas lecciones, nos enorgullece lanzar <code>jina-embeddings-v3</code>—una nueva frontera en modelos de embedding de texto y un gran hito para nuestra empresa.</p><p>Con este lanzamiento, continuamos destacando en lo que somos conocidos: <strong>embeddings de contexto largo</strong>, mientras también abordamos la característica más solicitada tanto por la industria como por la comunidad—<strong>embeddings multilingües</strong>. Al mismo tiempo, llevamos el rendimiento a un nuevo nivel. Con nuevas características como LoRA específico por tarea, MRL y late chunking, creemos que <code>jina-embeddings-v3</code> servirá verdaderamente como el modelo de embedding fundamental para diversas aplicaciones, incluyendo RAG, agentes y más. Comparado con embeddings recientes basados en LLM como <code>NV-embed-v1/v2</code>, nuestro modelo es altamente eficiente en parámetros, haciéndolo mucho más adecuado para producción y dispositivos edge.</p><p>En el futuro, planeamos enfocarnos en evaluar y mejorar el rendimiento de <code>jina-embeddings-v3</code> en idiomas con recursos limitados y analizar más a fondo los fallos sistemáticos causados por la disponibilidad limitada de datos. Además, los pesos del modelo de <code>jina-embeddings-v3</code>, junto con sus características innovadoras y perspectivas interesantes, servirán como base para nuestros próximos modelos, incluyendo <code>jina-clip-v2</code>,<code>jina-reranker-v3</code>, y <code>reader-lm-v2</code>.</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 es un modelo de vanguardia de embeddings de texto multilingüe con 570M parámetros y una longitud de token de 8192, que supera a los últimos embeddings propietarios de OpenAI y Cohere en MTEB.",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}