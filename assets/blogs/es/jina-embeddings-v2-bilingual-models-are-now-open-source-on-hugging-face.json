{
  "slug": "jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face",
  "id": "65b3adb510ff9f0001c50c4d",
  "uuid": "b082269a-4358-4a82-a70c-02da2ebcb6d3",
  "title": "Los modelos bilingües de Jina Embeddings v2 ahora son de código abierto en Hugging Face",
  "html": "<p>Jina AI ha lanzado sus modelos de embeddings bilingües de código abierto de última generación para los pares de idiomas <a href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\">alemán-inglés</a> y <a href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\">chino-inglés</a> a través de Hugging Face.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ich bin ein Berliner: German-English Bilingual Embeddings with 8K Token Length</div><div class=\"kg-bookmark-description\">Jina AI introduces a German/English bilingual embedding model, featuring an extensive 8,192-token length, specifically designed to support German businesses thriving in the U.S. market.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Explore-image-storytelling-beyond-pixels--33-.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">8K Token-Length Bilingual Embeddings Break Language Barriers in Chinese and English</div><div class=\"kg-bookmark-description\">The first bilingual Chinese-English embedding model with 8192 token-length.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><p>En este tutorial, vamos a revisar una instalación y caso de uso muy básicos que cubrirá:</p><ol><li>Descargar modelos de Jina Embedding desde Hugging Face.</li><li>Usar los modelos para obtener codificaciones de textos en alemán e inglés.</li><li>Construir un motor de búsqueda neuronal muy rudimentario basado en embeddings para consultas entre idiomas.</li></ol><p>Te mostraremos cómo usar Jina Embeddings para escribir consultas en inglés que recuperen textos coincidentes en alemán y viceversa.</p><p>Este tutorial funciona igual para el modelo chino. Solo sigue las instrucciones en la sección (hacia el final) titulada <a href=\"#querying-in-chinese\" rel=\"noreferrer\"><strong>Querying in Chinese</strong></a> para obtener el modelo bilingüe chino-inglés y un documento de ejemplo en chino.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-de?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-de · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-de.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-zh?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-zh · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><h2 id=\"bilingual-embedding-models\">Modelos de Embedding Bilingües</h2><p>Un modelo de embedding bilingüe es un modelo que mapea textos en dos idiomas —alemán e inglés en este tutorial, chino e inglés para el modelo chino— al mismo espacio de embeddings. Y lo hace de tal manera que si un texto en alemán y un texto en inglés significan lo mismo, sus vectores de embedding correspondientes estarán cerca uno del otro.</p><p>Modelos como este son muy adecuados para aplicaciones de recuperación de información entre idiomas, lo cual mostraremos en este tutorial, pero también pueden servir como base para chatbots basados en RAG, categorización de texto multilingüe, resumen, análisis de sentimientos y cualquier otra aplicación que use embeddings. Al usar modelos como estos, puedes tratar textos en ambos idiomas como si estuvieran escritos en el mismo idioma.</p><p>Aunque muchos modelos de lenguaje gigantes afirman soportar muchos idiomas diferentes, no los soportan a todos por igual. Hay crecientes cuestionamientos sobre el <a href=\"https://aclanthology.org/2023.findings-eacl.89/?ref=jina-ai-gmbh.ghost.io\">sesgo causado por el dominio del inglés en Internet</a> y las fuentes de entrada distorsionadas por la <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">amplia publicación en línea de textos traducidos por máquina</a>. Al centrarnos en dos idiomas, podemos controlar mejor la calidad del embedding para ambos, minimizando el sesgo mientras producimos modelos mucho más pequeños con un rendimiento similar o superior al de los modelos gigantes que pretenden manejar docenas de idiomas.</p><p>Los modelos bilingües Jina Embeddings v2 admiten 8,192 tokens de contexto de entrada, lo que les permite no solo soportar dos idiomas, sino también manejar segmentos de texto relativamente grandes en comparación con modelos similares. Esto los hace ideales para casos de uso más complejos donde se debe procesar mucha más información textual en embeddings.</p><h2 id=\"follow-along-on-google-colab\">Sigue el tutorial en Google Colab</h2><p>Este tutorial tiene un <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">notebook complementario</a> que puedes ejecutar en <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>, o localmente en tu propio sistema.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/feat-embeddings-notebook/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colaboratory</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://ssl.gstatic.com/colaboratory-static/common/cce4fce8bbe78d8bdc0c77a288df9fa7/img/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" alt=\"\"></div></a></figure><h2 id=\"installing-the-prerequisites\">Instalación de Prerrequisitos</h2><p>Asegúrate de que el entorno actual tenga las bibliotecas relevantes instaladas. Necesitarás la última versión de <a href=\"https://pypi.org/project/transformers/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>transformers</code></a>, así que incluso si ya está instalada, ejecuta:</p><pre><code class=\"language-bash\">pip install -U transformers \n</code></pre><p>Este tutorial usará la <a href=\"https://faiss.ai/?ref=jina-ai-gmbh.ghost.io\">biblioteca FAISS de Meta</a> para realizar búsquedas y comparaciones vectoriales. Para instalarla, ejecuta:</p><pre><code class=\"language-bash\">pip install faiss-cpu\n</code></pre><p>También usaremos <a href=\"https://www.crummy.com/software/BeautifulSoup/?ref=jina-ai-gmbh.ghost.io\">Beautiful Soup</a> para procesar los datos de entrada en este tutorial, así que asegúrate de que esté instalado:</p><pre><code class=\"language-bash\">pip install bs4\n</code></pre><h2 id=\"access-to-hugging-face\">Acceso a Hugging Face</h2><p>Necesitarás acceso a Hugging Face, específicamente una cuenta y un token de acceso para descargar modelos.</p><p><strong>Si no tienes una cuenta en Hugging Face:</strong></p><p>Ve a <a href=\"https://huggingface.co/?ref=jina-ai-gmbh.ghost.io\">https://huggingface.co/</a> y deberías ver un botón \"Sign Up\" en la parte superior derecha de la página. Haz clic en él y sigue las instrucciones para crear una nueva cuenta.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png\" class=\"kg-image\" alt=\"La página principal de Hugging Face, con el botón &quot;Sign Up&quot; resaltado.\" loading=\"lazy\" width=\"1088\" height=\"887\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/01/Untitled--26-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/01/Untitled--26-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png 1088w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Después de iniciar sesión en tu cuenta:</strong></p><p>Sigue las instrucciones <a href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\">en el sitio web de Hugging Face</a> para obtener un token de acceso.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">User access tokens</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://huggingface.co/front/thumbnails/docs/hub.png\" alt=\"\"></div></a></figure><p>Necesitas copiar este token en una variable de entorno llamada <code>HF_TOKEN</code>. Si estás trabajando en un notebook (en <a href=\"https://colab.research.google.com/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>, por ejemplo) o configurándolo internamente en un programa Python, usa el siguiente código Python:</p><pre><code class=\"language-python\">import os\n\nos.environ['HF_TOKEN'] = \"&lt;your token here&gt;\"\n</code></pre><p>En tu shell, usa la sintaxis proporcionada para establecer una variable de entorno. En <code>bash</code>:</p><pre><code class=\"language-bash\">export HF_TOKEN=\"&lt;your token here&gt;\"\n</code></pre><h2 id=\"download-jina-embeddings-v2-for-german-and-english\">Descargar Jina Embeddings v2 para alemán e inglés</h2><p>Una vez que tu token esté configurado, puedes descargar el modelo bilingüe alemán-inglés de Jina Embeddings usando la biblioteca <code>transformers</code>:</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-de', trust_remote_code=True)\n</code></pre><p>Esto puede tomar varios minutos la primera vez que lo hagas, pero el modelo se almacenará en caché localmente después de eso, así que no te preocupes si reinicas este tutorial más tarde.</p><h2 id=\"download-english-language-data\">Descargar datos en inglés</h2><p>Para este tutorial, vamos a obtener la versión en inglés del libro <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git: Everything You Need to Know About Git</em></a>. Este libro también está disponible en chino y alemán, que usaremos más adelante en este tutorial.</p><p>Para descargar la versión EPUB, ejecuta el siguiente comando:</p><pre><code class=\"language-bash\">wget -O progit-en.epub https://open.umn.edu/opentextbooks/formats/3437</code></pre><p>Esto copia el libro a un archivo llamado <code>progit-en.epub</code> en el directorio local.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--27-.png\" class=\"kg-image\" alt=\"La portada de la edición impresa de &quot;Pro Git&quot; por Scott Chacon y Ben Straub.\" loading=\"lazy\" width=\"490\" height=\"647\"><figcaption><span style=\"white-space: pre-wrap;\">La portada de la edición impresa.</span></figcaption></figure><p>Alternativamente, puedes visitar el enlace <a href=\"https://open.umn.edu/opentextbooks/formats/3437?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">https://open.umn.edu/opentextbooks/formats/3437</a> para descargarlo a tu unidad local. Está disponible bajo la <a href=\"https://creativecommons.org/licenses/by-nc-sa/3.0/?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">licencia Creative Commons Attribution Non Commercial Share Alike 3.0</a>.</p><h2 id=\"processing-the-data\">Procesamiento de los datos</h2><p>Este texto en particular tiene una estructura interna de secciones jerárquicas, que podemos encontrar fácilmente buscando la etiqueta <code>&lt;section&gt;</code> en los datos XHTML subyacentes. El código siguiente lee el archivo EPUB y lo divide utilizando la estructura interna de un archivo EPUB y la etiqueta <code>&lt;section&gt;</code>, luego convierte cada sección a texto plano sin etiquetas XHTML. Crea un diccionario Python cuyas claves son un conjunto de cadenas que indican la ubicación de cada sección en el libro, y cuyos valores son el contenido en texto plano de esa sección.</p><pre><code class=\"language-python\">from zipfile import ZipFile\nfrom bs4 import BeautifulSoup\nimport copy\n\ndef decompose_epub(file_name):\n    \n    def to_top_text(section):\n        selected = copy.copy(section)\n\t\t\t\twhile next_section := selected.find(\"section\"):\n            next_section.decompose()\n        return selected.get_text().strip()\n\n    ret = {}\n    with ZipFile(file_name, 'r') as zip:\n        for name in zip.namelist():\n            if name.endswith(\".xhtml\"):\n                data = zip.read(name)\n                doc = BeautifulSoup(data.decode('utf-8'), 'html.parser')\n                ret[name + \":top\"] = to_top_text(doc)\n                for num, sect in enumerate(doc.find_all(\"section\")):\n                    ret[name + f\"::{num}\"] = to_top_text(sect)\n    return ret\n</code></pre><p>Luego, ejecuta la función <code>decompose_epub</code> en el archivo EPUB que descargaste antes:</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-en.epub\")\n</code></pre><p>La variable <code>book_data</code> ahora tendrá 583 secciones en ella. Por ejemplo:</p><pre><code class=\"language-python\">print(book_data['EPUB/ch01-getting-started.xhtml::12'])\n</code></pre><p>Resultado:</p><pre><code class=\"language-Text\">The Command Line\nThere are a lot of different ways to use Git.\nThere are the original command-line tools, and there are many graphical user interfaces of varying capabilities.\nFor this book, we will be using Git on the command line.\nFor one, the command line is the only place you can run all Git commands — most of the GUIs implement only a partial subset of Git functionality for simplicity.\nIf you know how to run the command-line version, you can probably also figure out how to run the GUI version, while the opposite is not necessarily true.\nAlso, while your choice of graphical client is a matter of personal taste, all users will have the command-line tools installed and available.\nSo we will expect you to know how to open Terminal in macOS or Command Prompt or PowerShell in Windows.\nIf you don't know what we're talking about here, you may need to stop and research that quickly so that you can follow the rest of the examples and descriptions in this book.\n</code></pre><h2 id=\"generating-and-indexing-embeddings-with-jina-embeddings-v2-and-faiss\">Generación e indexación de embeddings con Jina Embeddings v2 y FAISS</h2><p>Para cada una de las 583 secciones, generaremos un embedding y lo almacenaremos en un índice FAISS. Los modelos Jina Embeddings v2 aceptan una entrada de hasta 8192 tokens, lo suficientemente grande como para que, para un libro como este, no necesitemos hacer ninguna segmentación adicional del texto ni verificar si alguna sección tiene demasiados tokens. La sección más larga del libro tiene aproximadamente 12,000 caracteres, que, para inglés normal, debería estar muy por debajo del límite de 8k tokens.</p><p>Para generar un solo embedding, utilizas el método <code>encode</code> del modelo que descargamos. Por ejemplo:</p><pre><code class=\"language-python\">model.encode([book_data['EPUB/ch01-getting-started.xhtml::12']])\n</code></pre><p>Esto devuelve un array que contiene un único vector de 768 dimensiones:</p><pre><code class=\"language-python\">array([[ 6.11135997e-02,  1.67829826e-01, -1.94809273e-01,\n         4.45595086e-02,  3.28837298e-02, -1.33441269e-01,\n         1.35364473e-01, -1.23119736e-02,  7.51526654e-02,\n        -4.25386652e-02, -6.91794455e-02,  1.03527725e-01,\n        -2.90831417e-01, -6.21018047e-03, -2.16205455e-02,\n        -2.20803712e-02,  1.50471330e-01, -3.31433356e-01,\n        -1.48741454e-01, -2.10959971e-01,  8.80039856e-02,\n\t\t\t\t....\n</code></pre><p>Eso es un embedding.</p><p>Los modelos Jina Embeddings están configurados para permitir el procesamiento por lotes. El tamaño óptimo del lote depende del hardware que uses al ejecutar. Un tamaño de lote grande corre el riesgo de quedarse sin memoria. Un tamaño de lote pequeño tardará más en procesarse.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Establecer <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">batch_size=5</code> funcionó en Google Colab en nivel gratuito sin GPU, y tomó <b><strong style=\"white-space: pre-wrap;\">aproximadamente una hora</strong></b> para generar todo el conjunto de embeddings.</div></div><p>En producción, recomendamos usar hardware mucho más potente o usar el <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">servicio API de Embeddings</a> de Jina AI. Sigue el enlace a continuación para descubrir cómo funciona y cómo comenzar con acceso gratuito.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Top-performing, 8192-token context length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>El código siguiente genera los embeddings y los almacena en un índice FAISS. Establece la variable <code>batch_size</code> según corresponda a tus recursos.</p><pre><code class=\"language-python\">import faiss\n\nbatch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>Cuando se trabaja en un entorno de producción, un diccionario Python no es una forma adecuada o eficiente de manejar documentos y embeddings. Deberías usar una base de datos vectorial específica, que tendrá sus propias instrucciones para la inserción de datos.</p><h2 id=\"querying-in-german-for-english-results\">Consultas en alemán para resultados en inglés</h2><p>Cuando consultemos algo de este conjunto de textos, esto es lo que sucederá:</p><ol><li>El modelo alemán-inglés de Jina Embeddings creará un embedding para la consulta.</li><li>Usaremos el índice FAISS (<code>faiss_index</code>) para obtener el embedding almacenado con el coseno más alto respecto al embedding de la consulta y devolveremos su posición en el índice.</li><li>Buscaremos el texto correspondiente en el array de datos vectoriales (<code>vector_data</code>) e imprimiremos el coseno, la ubicación del texto y el texto en sí.</li></ol><p>Eso es lo que hace la función <code>query</code> a continuación.</p><pre><code class=\"language-python\">def query(query_str):\n    query = model.encode([query_str], normalize_embeddings=True)\n    cosine, index = faiss_index.search(query, 1)\n    print(f\"Cosine: {cosine[0][0]}\")\n    loc, txt = vector_data[index[0][0]]\n    print(f\"Location: {loc}\\\\nText:\\\\n\\\\n{txt}\")\n</code></pre><p>Ahora vamos a probarlo.</p><pre><code class=\"language-python\"># Translation: \"How do I roll back to a previous version?\"\nquery(\"Wie kann ich auf eine frühere Version zurücksetzen?\")\n</code></pre><p>Resultado:</p><pre><code class=\"language-text\">Cosine: 0.5202275514602661\nLocation: EPUB/ch02-git-basics-chapter.xhtml::20\nText:\n\nUndoing things with git restore\nGit version 2.23.0 introduced a new command: git restore.\nIt's basically an alternative to git reset which we just covered.\nFrom Git version 2.23.0 onwards, Git will use git restore instead of git reset for many undo operations.\nLet's retrace our steps, and undo things with git restore instead of git reset.\n</code></pre><p>Esta es una muy buena opción para responder la pregunta. Probemos otra:</p><pre><code class=\"language-python\"># Translation: \"What does 'version control' mean?\"\nquery(\"Was bedeutet 'Versionsverwaltung'?\")\n</code></pre><p>Resultado:</p><pre><code class=\"language-text\">Cosine: 0.5001817941665649\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nAbout Version Control\n\nWhat is \"version control\", and why should you care?\nVersion control is a system that records changes to a file or set of files over time so that you can recall specific versions later.\nFor the examples in this book, you will use software source code as the files being version controlled, though in reality you can do this with nearly any type of file on a computer.\nIf you are a graphic or web designer and want to keep every version of an image or layout (which you would most certainly want to), a Version Control System (VCS) is a very wise thing to use.\nIt allows you to revert selected files back to a previous state, revert the entire project back to a previous state, compare changes over time, see who last modified something that might be causing a problem, who introduced an issue and when, and more.\nUsing a VCS also generally means that if you screw things up or lose files, you can easily recover.\nIn addition, you get all this for very little overhead.\n</code></pre><p>Pruébalo con tus propias preguntas en alemán para ver qué tan bien funciona. Como práctica general, cuando se trata de recuperación de información textual, deberías solicitar de tres a cinco respuestas en lugar de solo una. La mejor respuesta a menudo no es la primera.</p><h2 id=\"reversing-the-roles-querying-german-documents-with-english\">Invirtiendo los Roles: Consultando documentos en alemán con inglés</h2><p>El libro <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git: Everything You Need to Know About Git</em></a> también está <a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git-german?ref=jina-ai-gmbh.ghost.io\">disponible en alemán</a>. Podemos usar este mismo modelo para hacer esta demostración con los idiomas invertidos.</p><p>Descarga el libro electrónico:</p><pre><code class=\"language-bash\">wget -O progit-de.epub https://open.umn.edu/opentextbooks/formats/3454\n</code></pre><p>Esto copia el libro a un archivo llamado <code>progit-de.epub</code>. Luego lo procesamos de la misma manera que hicimos con el libro en inglés:</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-de.epub\")\n</code></pre><p>Y luego generamos los embeddings de la misma manera que antes:</p><pre><code class=\"language-python\">batch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>Ahora podemos usar la misma función <code>query</code> para buscar en inglés respuestas en alemán:</p><pre><code class=\"language-python\">query(\"What is version control?\")\n</code></pre><p>Resultado:</p><pre><code class=\"language-text\">Cosine: 0.6719034910202026\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nWas ist Versionsverwaltung?\n\nWas ist „Versionsverwaltung\", und warum sollten Sie sich dafür interessieren?\nVersionsverwaltung ist ein System, welches die Änderungen an einer oder einer Reihe von Dateien über die Zeit hinweg protokolliert, sodass man später auf eine bestimmte Version zurückgreifen kann.\nDie Dateien, die in den Beispielen in diesem Buch unter Versionsverwaltung gestellt werden, enthalten Quelltext von Software, tatsächlich kann in der Praxis nahezu jede Art von Datei per Versionsverwaltung nachverfolgt werden.\nAls Grafik- oder Webdesigner möchte man zum Beispiel in der Lage sein, jede Version eines Bildes oder Layouts nachverfolgen zu können. Als solcher wäre es deshalb ratsam, ein Versionsverwaltungssystem (engl. Version Control System, VCS) einzusetzen.\nEin solches System erlaubt es, einzelne Dateien oder auch ein ganzes Projekt in einen früheren Zustand zurückzuversetzen, nachzuvollziehen, wer zuletzt welche Änderungen vorgenommen hat, die möglicherweise Probleme verursachen, herauszufinden wer eine Änderung ursprünglich vorgenommen hat und viele weitere Dinge.\nEin Versionsverwaltungssystem bietet allgemein die Möglichkeit, jederzeit zu einem vorherigen, funktionierenden Zustand zurückzukehren, auch wenn man einmal Mist gebaut oder aus irgendeinem Grund Dateien verloren hat.\nAll diese Vorteile erhält man für einen nur sehr geringen, zusätzlichen Aufwand.\n</code></pre><p>El título de esta sección se traduce como <em>\"¿Qué es el control de versiones?\"</em>, por lo que esta es una buena respuesta.</p><h2 id=\"querying-in-chinese\">Consultando en chino</h2><p>Estos ejemplos funcionarán exactamente de la misma manera con Jina Embeddings v2 para chino e inglés. Para usar el modelo chino en su lugar, simplemente ejecuta lo siguiente:</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)\n</code></pre><p>Y para obtener la edición china de <em>Pro Git: Everything You Need to Know About Git</em>:</p><pre><code class=\"language-python\">wget -O progit-zh.epub https://open.umn.edu/opentextbooks/formats/3455\n</code></pre><p>Luego, procesa el libro en chino:</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-zh.epub\")\n</code></pre><p>Todo el resto del código en este tutorial funcionará de la misma manera.</p><h2 id=\"the-future-more-languages-including-programming\">El Futuro: Más Idiomas, incluyendo Programación</h2><p>Estaremos lanzando más modelos bilingües en el futuro inmediato, con español y japonés ya en desarrollo, así como un modelo que admite inglés y varios lenguajes de programación importantes. Estos modelos son ideales para empresas internacionales que gestionan información multilingüe, y pueden servir como piedra angular para la recuperación de información basada en IA y modelos de lenguaje generativo basados en RAG, insertándose en una variedad de casos de uso de IA de vanguardia.</p><p>Los modelos de Jina AI son compactos y se encuentran entre los mejores de su clase, demostrando que no se necesita el modelo más grande para obtener el mejor rendimiento. Al centrarnos en el rendimiento bilingüe, producimos modelos que son mejores en esos idiomas, más fáciles de adaptar y más rentables que los modelos grandes entrenados con datos sin curar.</p><p>Jina Embeddings está disponible en <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>, en el <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS marketplace</a> para uso en Sagemaker, y a través de la <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">API web de Jina Embeddings</a>. Están completamente integrados en muchos marcos de proceso de IA y bases de datos vectoriales.</p><p>Consulta el <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">sitio web de Jina Embeddings</a> para más información, o contáctanos para discutir cómo las ofertas de Jina AI pueden adaptarse a tus procesos de negocio.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">Top-performing, 8192-token context length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure>",
  "comment_id": "65b3adb510ff9f0001c50c4d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/01/Blog-images--32-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-01-26T14:03:49.000+01:00",
  "updated_at": "2024-02-05T17:19:35.000+01:00",
  "published_at": "2024-01-26T17:14:56.000+01:00",
  "custom_excerpt": "Jina AI's open-source bilingual embedding models for German-English and Chinese-English are now on Hugging Face.\nWe’re going to walk through installation and cross-language retrieval.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face/",
  "excerpt": "Los modelos de embedding bilingües de código abierto de Jina AI para alemán-inglés y chino-inglés ya están disponibles en Hugging Face.\nVamos a explicar la instalación y la recuperación entre idiomas.",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Colorful \"EMBEDDINGS\" text above a pile of yellow smileys on a black background with decorative lines at the top.",
  "feature_image_caption": null
}