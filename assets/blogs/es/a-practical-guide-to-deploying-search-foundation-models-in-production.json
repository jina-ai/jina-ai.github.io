{
  "slug": "a-practical-guide-to-deploying-search-foundation-models-in-production",
  "id": "679b56ba42b46600019a86e3",
  "uuid": "458c0de5-aedb-4513-8ffd-47c027d204ad",
  "title": "Una gu√≠a pr√°ctica para desplegar modelos fundacionales de b√∫squeda en producci√≥n",
  "html": "<p>En Jina AI, nuestra misi√≥n es proporcionar a los usuarios empresariales soluciones de b√∫squeda de alta calidad. Para lograrlo, hacemos que nuestros modelos sean accesibles a trav√©s de varios canales. Sin embargo, elegir el canal adecuado para tu caso de uso espec√≠fico puede ser complicado. En esta publicaci√≥n, te guiaremos a trav√©s del proceso de toma de decisiones y analizaremos las ventajas y desventajas, brind√°ndote orientaci√≥n pr√°ctica sobre la mejor manera de acceder a nuestros modelos de b√∫squeda seg√∫n tu perfil de usuario y necesidades.</p><h2 id=\"jina-search-foundation-models\">Modelos de Fundaci√≥n de B√∫squeda de Jina</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Our Search Foundation Models</div><div class=\"kg-bookmark-description\">We've been moving the needle in search models since day one. Take a look at our model evolution below‚Äîhover or click to discover each milestone.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-18.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Jina AI</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-models.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>Nuestros modelos de fundaci√≥n de b√∫squeda incluyen:</p><ul><li><strong>Embeddings</strong>: Estos convierten informaci√≥n sobre objetos digitales en vectores de embedding, capturando sus caracter√≠sticas esenciales.</li><li><strong>Rerankers</strong>: Estos realizan un an√°lisis sem√°ntico profundo de conjuntos de consultas y documentos para mejorar la relevancia de la b√∫squeda.</li><li><strong>Small language models</strong>: Estos incluyen SLM especializados como <code>ReaderLM-v2</code> para tareas espec√≠ficas como HTML2Markdown o extracci√≥n de informaci√≥n.</li></ul><p>En esta publicaci√≥n, examinaremos diferentes opciones de implementaci√≥n para <code>jina-embeddings-v3</code>, comparando tres enfoques clave:</p><ul><li>Usando <a href=\"https://jina.ai/api-dashboard\" rel=\"noreferrer\">Jina API</a></li><li>Implementando a trav√©s de CSP como <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS SageMaker</a></li><li>Auto-alojamiento en un cl√∫ster de Kubernetes <a href=\"https://jina.ai/api-dashboard/license-config\">bajo una licencia comercial</a></li></ul><p>La comparaci√≥n evaluar√° las implicaciones de costos y ventajas de cada enfoque para ayudarte a determinar la opci√≥n m√°s adecuada para tus necesidades.</p><h2 id=\"key-performance-metrics\">M√©tricas Clave de Rendimiento</h2><p>Evaluamos cinco m√©tricas clave de rendimiento en diferentes escenarios de uso:</p><ul><li><strong>Tasa de √âxito de Solicitudes</strong>: El porcentaje de solicitudes exitosas al servidor de embedding</li><li><strong>Latencia de Solicitud</strong>: El tiempo que tarda el servidor de embedding en procesar y devolver una solicitud</li><li><strong>Rendimiento de Tokens</strong>: El n√∫mero de tokens que el servidor de embedding puede procesar por segundo</li><li><strong>Costo por Token</strong>: El costo total de procesamiento por unidad de texto</li></ul><p>Para los embeddings de Jina auto-alojados en cl√∫steres de Kubernetes, tambi√©n examinamos el impacto del <em>batching din√°mico</em>. Esta funci√≥n pone en cola las solicitudes hasta alcanzar el tama√±o m√°ximo de lote (8,192 para <code>jina-embeddings-v3</code>) antes de generar embeddings.</p><p>Intencionalmente excluimos dos factores significativos de rendimiento de nuestro an√°lisis:</p><ul><li><em>Auto-escalado</em>: Si bien esto es crucial para implementaciones en la nube con cargas de trabajo variables, su efectividad depende de numerosas variables: eficiencia del hardware, arquitectura de red, latencia y elecciones de implementaci√≥n. Estas complejidades est√°n m√°s all√° de nuestro alcance actual. <strong>Ten en cuenta que Jina API incluye escalado autom√°tico, y nuestros resultados reflejan esto.</strong></li><li><em>Cuantizaci√≥n</em>: Si bien esta t√©cnica crea vectores de embedding m√°s peque√±os y reduce la transferencia de datos, los principales beneficios provienen de otros componentes del sistema (almacenamiento de datos y c√°lculos de distancia vectorial) en lugar de la reducci√≥n en la transferencia de datos. Ya que nos estamos enfocando en los costos directos de uso del modelo, hemos dejado la cuantizaci√≥n fuera de este an√°lisis.</li></ul><p>Finalmente, examinaremos las implicaciones financieras de cada enfoque, considerando tanto los costos totales de propiedad como los gastos por token/por solicitud.</p><h2 id=\"deployment-setup\">Configuraci√≥n de Implementaci√≥n</h2><p>Evaluamos tres escenarios de implementaci√≥n y uso con <code>jina-embeddings-v3</code>:</p><h3 id=\"using-the-jina-api\">Uso de Jina API</h3><p>Todos los modelos de embedding de Jina AI son accesibles a trav√©s de <a href=\"https://jina.ai/api-dashboard/embeddings\" rel=\"noreferrer\">Jina API</a>. El acceso funciona con un sistema de tokens prepagados, con un mill√≥n de tokens disponibles gratis para pruebas. Evaluamos el rendimiento haciendo llamadas a la API a trav√©s de internet desde nuestras oficinas en Alemania.</p><h3 id=\"using-aws-sagemaker\">Uso de AWS SageMaker</h3><p>Jina Embeddings v3 est√° <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">disponible para usuarios de AWS a trav√©s de SageMaker</a>. El uso requiere una suscripci√≥n de AWS a este modelo. Para c√≥digo de ejemplo, hemos <a href=\"https://github.com/jina-ai/jina-sagemaker/blob/main/notebooks/Real-time%20embedding.ipynb\">proporcionado un notebook</a> que muestra c√≥mo suscribirse y usar los modelos de Jina AI con una cuenta de AWS.</p><p>Si bien los modelos tambi√©n est√°n disponibles en <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Microsoft Azure</a> y <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">Google Cloud Platform</a>, enfocamos nuestras pruebas en AWS. Esperamos un rendimiento similar en otras plataformas. Todas las pruebas se ejecutaron en una instancia <code>ml.g5.xlarge</code> en la regi√≥n <code>us-east-1</code>.</p><h3 id=\"self-hosting-on-kubernetes\">Auto-alojamiento en Kubernetes</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">üí°</div><div class=\"kg-callout-text\">Para obtener licencias comerciales para nuestros modelos CC-BY-NC, primero necesitas obtener una licencia de nosotros. <a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">Por favor, no dudes en contactar a nuestro equipo de ventas.</a></div></div><p>Construimos una aplicaci√≥n FastAPI en Python que <a href=\"https://huggingface.co/jinaai/jina-embeddings-v3\">carga <code>jina-embeddings-v3</code> desde HuggingFace</a> usando la biblioteca <code>SentenceTransformer</code>. La aplicaci√≥n incluye dos endpoints:</p><ul><li><code>/embed</code>: Toma pasajes de texto como entrada y devuelve sus embeddings</li><li><code>/health</code>: Proporciona monitoreo b√°sico de salud</li></ul><p>Lo implementamos como un servicio de Kubernetes en Amazon's Elastic Kubernetes Service, usando una instancia <code>g5.xlarge</code> en <code>us-east-1</code>.</p><h4 id=\"with-and-without-dynamic-batching\">Con y Sin Batching Din√°mico</h4><p>Probamos el rendimiento en un cl√∫ster de Kubernetes en dos configuraciones: Una donde procesaba inmediatamente cada solicitud cuando la recib√≠a, y otra donde usaba batching din√°mico. En el caso del batching din√°mico, el servicio espera hasta que se recolectan <code>MAX_TOKENS</code> (8192) en una cola, o se alcanza un tiempo l√≠mite predefinido de 2 segundos, antes de invocar el modelo y calcular los embeddings. Este enfoque aumenta la utilizaci√≥n de la GPU y reduce la fragmentaci√≥n de la memoria de la GPU.</p><p>Para cada escenario de implementaci√≥n, realizamos pruebas variando tres par√°metros clave:</p><ul><li><strong>Tama√±o del lote</strong>: Cada solicitud conten√≠a 1, 32 o 128 pasajes de texto para embedding</li><li><strong>Longitud del pasaje</strong>: Usamos pasajes de texto que conten√≠an 128, 512 o 1,024 tokens</li><li><strong>Solicitudes concurrentes</strong>: Enviamos 1, 5 o 10 solicitudes simult√°neamente</li></ul><h2 id=\"benchmark-results\">Resultados del Benchmark</h2><p>La tabla siguiente es un resumen de resultados para cada escenario de uso, promediando todas las configuraciones de las tres variables anteriores.</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>M√©trica</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>Auto-alojado<br>con Batching</th>\n<th>Auto-alojado<br>Est√°ndar</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Tasa de √âxito de Solicitudes</td>\n<td>87.6%</td>\n<td><strong>99.9%</strong></td>\n<td>55.7%</td>\n<td>58.3%</td>\n</tr>\n<tr>\n<td>Latencia<br>(segundos)</td>\n<td>11.4</td>\n<td>3.9</td>\n<td>2.7</td>\n<td><strong>2.6</strong></td>\n</tr>\n<tr>\n<td>Latencia Normalizada por Tasa de √âxito<br>(segundos)</td>\n<td>13.0</td>\n<td><strong>3.9</strong></td>\n<td>4.9</td>\n<td>4.4</td>\n</tr>\n<tr>\n<td>Rendimiento de Tokens<br>(tokens/segundo)</td>\n<td>13.8K</td>\n<td><strong>15.0K</strong></td>\n<td>2.2K</td>\n<td>2.6K</td>\n</tr>\n<tr>\n<td>Rendimiento M√°ximo de Tokens<br>(tokens/segundo)</td>\n<td><strong>63.0K</strong></td>\n<td>32.2K</td>\n<td>10.9K</td>\n<td>10.5K</td>\n</tr>\n<tr>\n<td>Precio<br>(USD por 1M tokens)</td>\n<td>$0.02</td>\n<td>$0.07</td>\n<td>$0.32</td>\n<td>$0.32</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"request-success-rate\">Tasa de √âxito de Solicitudes</h2><p>Las tasas de √©xito en nuestras pruebas var√≠an desde el casi perfecto 99.9% de SageMaker hasta el modesto 56-58% de las soluciones auto-alojadas, destacando por qu√© la confiabilidad del 100% sigue siendo dif√≠cil de alcanzar en sistemas de producci√≥n. Tres factores clave contribuyen a esto:</p><ul><li>La inestabilidad de la red causa fallos inevitables incluso en entornos cloud</li><li>La contenci√≥n de recursos, especialmente la memoria GPU, lleva a fallos de solicitudes bajo carga</li><li>Los l√≠mites de tiempo de espera necesarios significan que algunas solicitudes deben fallar para mantener la salud del sistema</li></ul><h3 id=\"success-rate-by-batch-size\">Tasa de √âxito por Tama√±o de Lote</h3><p>Los tama√±os de lote grandes frecuentemente causan errores de memoria insuficiente en la configuraci√≥n auto-alojada de Kubernetes. Sin batching din√°mico, todas las solicitudes que conten√≠an 32 o 128 elementos por lote fallaron por esta raz√≥n. Incluso con el batching din√°mico implementado, la tasa de fallos para lotes grandes sigui√≥ siendo significativamente alta.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8017-ba56-e35215a76fc4\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8064-ab87-e44fc044673d\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">Tama√±o de Lote</th><th id=\"zt<p\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"kPia\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"wgj>\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"OwMn\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-80e1-b4a8-c6f8a3b03117\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"zt<p\" class=\"\">100%</td><td id=\"kPia\" class=\"\">100%</td><td id=\"wgj>\" class=\"\">97.1%</td><td id=\"OwMn\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8096-93c6-deff80bbeffc\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">32</th><td id=\"zt<p\" class=\"\">86.7%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">50.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr><tr id=\"1847c956-b7d2-80fe-a61d-ea3923f34aac\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"zt<p\" class=\"\">76.2%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">24.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<p>Si bien este problema podr√≠a resolverse f√°cilmente mediante el auto-escalado, hemos optado por no explorar esa opci√≥n aqu√≠. El auto-escalado conducir√≠a a aumentos de costos impredecibles, y ser√≠a dif√≠cil proporcionar conclusiones pr√°cticas dado el gran n√∫mero de opciones de configuraci√≥n de auto-escalado disponibles.</p><h3 id=\"success-rate-by-concurrency-level\">Tasa de √âxito por Nivel de Concurrencia</h3><p>La concurrencia ‚Äî la capacidad de manejar m√∫ltiples solicitudes simult√°neamente ‚Äî no tuvo un impacto fuerte ni consistente en las tasas de √©xito de las solicitudes en las configuraciones de Kubernetes auto-alojadas, y solo un efecto m√≠nimo en AWS SageMaker, al menos hasta un nivel de concurrencia de 10.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-80a7-9beb-f1ebe6e1e529\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8011-bcc1-d295e87b8e54\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">Concurrencia</th><th id=\"KV|=\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"G@`e\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"[~nZ\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"mHG:\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8041-9a23-c1338c5d3f23\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"KV|=\" class=\"\">93.3%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">57.5%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80eb-86a9-f249c86ddfdf\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">5</th><td id=\"KV|=\" class=\"\">85.7%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">58.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80ac-a3ad-eadd81c69cb2\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">10</th><td id=\"KV|=\" class=\"\">83.8%</td><td id=\"G@`e\" class=\"\">99.6%</td><td id=\"[~nZ\" class=\"\">55.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h3 id=\"success-rate-by-token-length\">Tasa de √âxito por Longitud de Token</h3><p>Los pasajes largos con alto n√∫mero de tokens afectan tanto a la API de Embedding de Jina como a Kubernetes con batch din√°mico de manera similar a los lotes grandes: a medida que aumenta el tama√±o, la tasa de fallos aumenta sustancialmente. Sin embargo, mientras que las soluciones auto-alojadas sin batch din√°mico casi invariablemente fallan con lotes grandes, tienen un mejor rendimiento con pasajes largos individuales. En cuanto a SageMaker, las longitudes de pasaje largas - al igual que la concurrencia y el tama√±o del lote - no tuvieron un impacto notable en las tasas de √©xito de las solicitudes.</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8003-8d50-eddc36a83d33\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-804b-8352-d65d5e6bdd0e\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">Longitud del Pasaje<br>(tokens)<br></th><th id=\"CDn]\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"@nCV\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"H?G{\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"]{Mf\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8011-8a92-d0986d045c79\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">98.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-809f-b073-fa48e7287c13\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">512</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">66.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8019-9f1f-cefd810c520d\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">1024</th><td id=\"CDn]\" class=\"\">99.3%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">33.3%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80c7-a745-fcdaf408f3d0\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">8192</th><td id=\"CDn]\" class=\"\">51.1%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">29.4%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h2 id=\"request-latency\">Latencia de Solicitud</h2><p>Todas las pruebas de latencia se repitieron cinco veces en niveles de concurrencia de 1, 5 y 10. El tiempo de respuesta es el promedio de cinco intentos. El rendimiento de solicitudes es el inverso del tiempo de respuesta en segundos, multiplicado por la concurrencia.</p><h3 id=\"jina-api\">Jina API</h3><p>Los tiempos de respuesta en la API de Jina est√°n principalmente influenciados por el tama√±o del lote, independientemente del nivel de concurrencia. Si bien la longitud del pasaje tambi√©n afecta el rendimiento, su impacto no es directo. Como principio general, las solicitudes que contienen m√°s datos - ya sea a trav√©s de tama√±os de lote m√°s grandes o pasajes m√°s largos - tardan m√°s en procesarse.</p><h4 id=\"concurrency-1\">Concurrencia 1:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Tama√±o del Lote</th>\n<th>Longitud del pasaje (en tokens)</th>\n<th>Tiempo de Respuesta en ms</th>\n<th>Rendimiento de Solicitudes (solicitudes/segundo)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>801</td>\n<td>1.25</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>724</td>\n<td>1.38</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>614</td>\n<td>1.63</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1554</td>\n<td>0.64</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1620</td>\n<td>0.62</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2283</td>\n<td>0.44</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4441</td>\n<td>0.23</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5430</td>\n<td>0.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>6332</td>\n<td>0.16</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><h4 id=\"concurrency-5\">Concurrencia 5:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>689</td>\n<td>7.26</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>599</td>\n<td>8.35</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>876</td>\n<td>5.71</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1639</td>\n<td>3.05</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2511</td>\n<td>1.99</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4728</td>\n<td>1.06</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2766</td>\n<td>1.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5911</td>\n<td>0.85</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>18621</td>\n<td>0.27</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10\">Concurrencia 10:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>790</td>\n<td>12.66</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>669</td>\n<td>14.94</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>649</td>\n<td>15.41</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1384</td>\n<td>7.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3409</td>\n<td>2.93</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>8484</td>\n<td>1.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3441</td>\n<td>2.91</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>13070</td>\n<td>0.77</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>17886</td>\n<td>0.56</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Para solicitudes individuales (batch size de 1):</p><ul><li>Los tiempos de respuesta se mantienen relativamente estables, entre 600-800ms, independientemente de la longitud del pasaje</li><li>Una mayor concurrencia (5 o 10 solicitudes simult√°neas) no degrada significativamente el rendimiento por solicitud</li></ul><p>Para lotes m√°s grandes (32 y 128 elementos):</p><ul><li>Los tiempos de respuesta aumentan sustancialmente, con un batch size de 128 tomando aproximadamente 4-6 veces m√°s que las solicitudes individuales</li><li>El impacto de la longitud del pasaje se vuelve m√°s pronunciado con lotes m√°s grandes</li><li>Con alta concurrencia (10) y lotes grandes (128), la combinaci√≥n lleva a tiempos de respuesta significativamente m√°s largos, alcanzando casi 18 segundos para los pasajes m√°s extensos</li></ul><p>Para el rendimiento:</p><ul><li>Los lotes m√°s peque√±os generalmente logran mejor rendimiento al ejecutar solicitudes concurrentes</li><li>Con concurrencia 10 y batch size 1, el sistema alcanza su mayor rendimiento de aproximadamente 15 solicitudes/segundo</li><li>Los lotes m√°s grandes muestran consistentemente menor rendimiento, cayendo a menos de 1 solicitud/segundo en varios escenarios</li></ul><h3 id=\"aws-sagemaker\">AWS SageMaker</h3><p>Las pruebas de AWS SageMaker se realizaron con una instancia <code>ml.g5.xlarge</code>.</p><h4 id=\"concurrency-1-1\">Concurrencia 1:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>189</td>\n<td>5.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>219</td>\n<td>4.56</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>221</td>\n<td>4.53</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>377</td>\n<td>2.66</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3931</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2215</td>\n<td>0.45</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>1120</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>3408</td>\n<td>0.29</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>5765</td>\n<td>0.17</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-1\">Concurrencia 5:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>443</td>\n<td>11.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>426</td>\n<td>11.74</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>487</td>\n<td>10.27</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1257</td>\n<td>3.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2245</td>\n<td>2.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4159</td>\n<td>1.20</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2444</td>\n<td>2.05</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>6967</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>14438</td>\n<td>0.35</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-1\">Concurrencia 10:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>585</td>\n<td>17.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>602</td>\n<td>16.60</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>687</td>\n<td>14.56</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1650</td>\n<td>6.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3555</td>\n<td>2.81</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>7070</td>\n<td>1.41</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3867</td>\n<td>2.59</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>12421</td>\n<td>0.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>25989</td>\n<td>0.38</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Diferencias clave vs Jina API:</p><ul><li>Rendimiento Base: SageMaker es significativamente m√°s r√°pido para solicitudes peque√±as (elementos individuales, pasajes cortos) - alrededor de 200ms vs 700-800ms para Jina.</li><li>Comportamiento de Escalado:<ul><li>Ambos servicios se ralentizan con lotes m√°s grandes y pasajes m√°s largos</li><li>SageMaker muestra una desaceleraci√≥n m√°s dram√°tica con lotes grandes (128) y pasajes largos (1024 tokens)</li><li>Con alta concurrencia (10) con carga m√°xima (batch 128, 1024 tokens), SageMaker toma ~26s vs ~18s de Jina</li></ul></li><li>Impacto de la Concurrencia:<ul><li>Ambos servicios se benefician de una mayor concurrencia para el rendimiento</li><li>Ambos mantienen patrones de rendimiento similares a trav√©s de los niveles de concurrencia</li><li>SageMaker alcanza un rendimiento m√°ximo ligeramente superior (17 req/s vs 15 req/s) con concurrencia 10</li></ul></li></ul><h3 id=\"self-hosted-kubernetes-cluster\">Cl√∫ster Kubernetes Auto-Alojado</h3><p>Las pruebas de auto-alojamiento se realizaron en el <a href=\"https://aws.amazon.com/eks/\">Elastic Kubernetes Service de Amazon</a> con una instancia <code>g5.xlarge</code>.</p><h4 id=\"concurrency-1-2\">Concurrencia 1:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>No Batching Time (ms)</th>\n<th>No Batching Throughput (req/s)</th>\n<th>Dynamic Time (ms)</th>\n<th>Dynamic Throughput (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>416</td>\n<td>2.40</td>\n<td>2389</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>397</td>\n<td>2.52</td>\n<td>2387</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>396</td>\n<td>2.52</td>\n<td>2390</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1161</td>\n<td>0.86</td>\n<td>3059</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1555</td>\n<td>0.64</td>\n<td>1496</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2424</td>\n<td>0.41</td>\n<td>2270</td>\n<td>0.44</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-2\">Concurrencia 5:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>No Batching Time (ms)</th>\n<th>No Batching Throughput (req/s)</th>\n<th>Dynamic Time (ms)</th>\n<th>Dynamic Throughput (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>451</td>\n<td>11.08</td>\n<td>2401</td>\n<td>2.08</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>453</td>\n<td>11.04</td>\n<td>2454</td>\n<td>2.04</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>478</td>\n<td>10.45</td>\n<td>2520</td>\n<td>1.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1447</td>\n<td>3.46</td>\n<td>1631</td>\n<td>3.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2867</td>\n<td>1.74</td>\n<td>2669</td>\n<td>1.87</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4154</td>\n<td>1.20</td>\n<td>4026</td>\n<td>1.24</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-2\">Concurrencia 10:</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>No Batching Time (ms)</th>\n<th>No Batching Throughput (req/s)</th>\n<th>Dynamic Time (ms)</th>\n<th>Dynamic Throughput (req/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>674</td>\n<td>14.84</td>\n<td>2444</td>\n<td>4.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>605</td>\n<td>16.54</td>\n<td>2498</td>\n<td>4.00</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>601</td>\n<td>16.64</td>\n<td>781*</td>\n<td>12.80</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>2089</td>\n<td>4.79</td>\n<td>2200</td>\n<td>4.55</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>5005</td>\n<td>2.00</td>\n<td>4450</td>\n<td>2.24</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>7331</td>\n<td>1.36</td>\n<td>7127</td>\n<td>1.40</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">‚Ä† Este resultado an√≥malo es un subproducto del tiempo de espera de 2 segundos del procesamiento por lotes din√°mico. Con una concurrencia de 10, cada uno enviando 1024 tokens de datos, la cola se llena casi inmediatamente y el sistema de procesamiento por lotes nunca tiene que esperar un tiempo de espera. En tama√±os y concurrencias m√°s bajos, s√≠ lo hace, agregando autom√°ticamente dos segundos desperdiciados a cada solicitud. Este tipo de no linealidad es com√∫n en procesos por lotes suboptimizados.</div></div><p>Cuando se recibieron solicitudes con m√°s de 16,384 tokens, nuestra configuraci√≥n auto-alojada fall√≥ con errores del servidor, t√≠picamente por falta de memoria. Esto fue cierto independientemente de los niveles de concurrencia. Como resultado, no se muestran pruebas con m√°s datos que eso.</p><p>La alta concurrencia aument√≥ los tiempos de respuesta de manera aproximadamente lineal: los niveles de concurrencia de 5 tardaron aproximadamente cinco veces m√°s en responder que 1. Niveles de 10, diez veces m√°s.</p><p>El procesamiento por lotes din√°mico ralentiza los tiempos de respuesta en aproximadamente dos segundos para lotes peque√±os. Esto es esperado porque la cola de procesamiento espera 2 segundos antes de procesar un lote incompleto. Sin embargo, para tama√±os de lote m√°s grandes, aporta mejoras moderadas en el tiempo de respuesta.</p><h2 id=\"token-throughput\">Rendimiento de Tokens</h2><p>El rendimiento de tokens aumenta con tama√±os de lote m√°s grandes, longitudes de pasaje m√°s largas y niveles de concurrencia m√°s altos en todas las plataformas. Por lo tanto, solo presentaremos resultados en niveles de uso alto, ya que los niveles m√°s bajos no proporcionar√≠an una indicaci√≥n significativa del rendimiento en el mundo real.</p><p>Todas las pruebas se realizaron con un nivel de concurrencia de 10, con 16,384 tokens por solicitud, promediado sobre cinco solicitudes. Probamos dos configuraciones: tama√±o de lote 32 con pasajes de 512 tokens, y tama√±o de lote 128 con pasajes de 128 tokens. El n√∫mero total de tokens permanece constante en ambas configuraciones.</p><p>Rendimiento de tokens (tokens por segundo):</p><table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (tokens)</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>Self-Hosted (No Batching)</th>\n<th>Self-Hosted (Dynamic Batching)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>46K</td>\n<td>28.5K</td>\n<td>14.3K</td>\n<td>16.1K</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>42.3K</td>\n<td>27.6K</td>\n<td>9.7K</td>\n<td>10.4K</td>\n</tr>\n</tbody>\n</table>\n<p>Bajo condiciones de alta carga, la API de Jina supera significativamente a las alternativas, mientras que las soluciones auto-alojadas probadas aqu√≠ muestran un rendimiento sustancialmente menor.</p><h2 id=\"costs-per-million-tokens\">Costos Por Mill√≥n de Tokens</h2><p>El costo es posiblemente el factor m√°s cr√≠tico al elegir una soluci√≥n de embedding. Si bien calcular los costos de modelos de IA puede ser complejo, aqu√≠ hay un an√°lisis comparativo de diferentes opciones:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Service Type</th>\n<th>Cost per Million Tokens</th>\n<th>Infrastructure Cost</th>\n<th>License Cost</th>\n<th>Total Hourly Cost</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina API</td>\n<td>$0.018-0.02</td>\n<td>N/A</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>SageMaker (US East)</td>\n<td>$0.0723</td>\n<td>$1.408/hour</td>\n<td>$2.50/hour</td>\n<td>$3.908/hour</td>\n</tr>\n<tr>\n<td>SageMaker (EU)</td>\n<td>$0.0788</td>\n<td>$1.761/hour</td>\n<td>$2.50/hour</td>\n<td>$4.261/hour</td>\n</tr>\n<tr>\n<td>Self-Hosted (US East)</td>\n<td>$0.352</td>\n<td>$1.006/hour</td>\n<td>$2.282/hour</td>\n<td>$3.288/hour</td>\n</tr>\n<tr>\n<td>Self-Hosted (EU)</td>\n<td>$0.379</td>\n<td>$1.258/hour</td>\n<td>$2.282/hour</td>\n<td>$3.540/hour</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"jina-api-1\">Jina API</h3><p>El servicio sigue un modelo de precios basado en tokens con dos niveles prepagados:</p><ul><li>$20 por 1 mil millones de tokens ($0.02 por mill√≥n) - Una tarifa de entrada ideal para prototipado y desarrollo</li><li>$200 por 11 mil millones de tokens ($0.018 por mill√≥n) - Una tarifa m√°s econ√≥mica para vol√∫menes mayores</li></ul><p>Vale la pena mencionar que estos tokens funcionan en toda la suite de productos de Jina, incluyendo lectores, reordenadores y clasificadores zero-shot.</p><h3 id=\"aws-sagemaker-1\">AWS SageMaker</h3><p>Los precios de SageMaker combinan los costos por hora de la instancia con las tarifas de licencia del modelo. Usando una instancia <code>ml.g5.xlarge</code>:</p><ul><li>Costo de instancia: $1.408/hora (Este de EE.UU.) o $1.761/hora (Frankfurt UE)</li><li>Licencia de <code>jina-embeddings-v3</code>: $2.50/hora</li><li>Costo total por hora: $3.908-$4.261 dependiendo de la regi√≥n</li></ul><p>Con un rendimiento promedio de 15,044 tokens/segundo (54.16M tokens/hora), el costo por mill√≥n de tokens var√≠a entre $0.0723 y $0.0788.</p><h3 id=\"self-hosting-with-kubernetes\">Autoalojamiento con Kubernetes</h3><p>Los costos de autoalojamiento var√≠an significativamente seg√∫n la elecci√≥n de infraestructura. Usando la instancia <code>g5.xlarge</code> de AWS EC2 como referencia:</p><ul><li>Costo de instancia: $1.006/hora (Este de EE.UU.) o $1.258/hora (Frankfurt UE)</li><li>Licencia de <code>jina-embeddings-v3</code>: $5000/trimestre ($2.282/hora)</li><li>Costo total por hora: $3.288-$3.540 dependiendo de la regi√≥n</li></ul><p>A 2,588 tokens/segundo (9.32M tokens/hora), el costo por mill√≥n de tokens es de $0.352-$0.379. Si bien la tarifa por hora es menor que SageMaker, el rendimiento reducido resulta en costos m√°s altos por token.</p><p>Consideraciones importantes para el autoalojamiento:</p><ul><li>Los costos fijos (licencias, infraestructura) contin√∫an independientemente del uso</li><li>El alojamiento local a√∫n requiere tarifas de licencia y costos de personal</li><li>Las cargas de trabajo variables pueden impactar significativamente la eficiencia de costos</li></ul><h3 id=\"key-takeaways\">Conclusiones Principales</h3><p>La API de Jina emerge como la soluci√≥n m√°s rentable, incluso sin considerar los tiempos de inicio en fr√≠o y asumiendo un rendimiento √≥ptimo para las alternativas.</p><p>El autoalojamiento podr√≠a tener sentido para organizaciones con infraestructura robusta existente donde los costos marginales del servidor son m√≠nimos. Adem√°s, explorar proveedores en la nube m√°s all√° de AWS podr√≠a ofrecer mejores precios.</p><p>Sin embargo, para la mayor√≠a de las empresas, especialmente las PYMES que buscan soluciones llave en mano, la API de Jina ofrece una eficiencia de costos inigualable.</p><h2 id=\"security-and-data-privacy-considerations\">Consideraciones de Seguridad y Privacidad de Datos</h2><p>Al elegir una estrategia de implementaci√≥n para modelos de embedding, los requisitos de seguridad y privacidad de datos pueden jugar un papel decisivo junto con las consideraciones de rendimiento y costo. Ofrecemos opciones de implementaci√≥n flexibles para adaptarse a diferentes necesidades de seguridad:</p><h3 id=\"cloud-service-providers\">Proveedores de Servicios en la Nube</h3><p>Para <strong>empresas que ya trabajan con principales proveedores de la nube</strong>, nuestras ofertas en el marketplace de la nube (como <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS Marketplace</a>, <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Azure</a>, y <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">GCP</a>) proporcionan una soluci√≥n natural para la implementaci√≥n dentro de marcos de seguridad preexistentes. Estas implementaciones se benefician de:</p><ul><li>Controles de seguridad y cumplimiento heredados de su relaci√≥n con el CSP</li><li>Integraci√≥n lista con pol√≠ticas de seguridad existentes y reglas de gobierno de datos</li><li>Requiere poco o ning√∫n cambio en los acuerdos existentes de procesamiento de datos</li><li>Alineaci√≥n con consideraciones preexistentes de soberan√≠a de datos</li></ul><h3 id=\"self-hosting-and-local-deployment\">Autoalojamiento e Implementaci√≥n Local</h3><p><strong>Las organizaciones con requisitos estrictos de seguridad u obligaciones regulatorias espec√≠ficas</strong> a menudo prefieren el control f√≠sico completo sobre su infraestructura. Nuestra opci√≥n de autoalojamiento permite:</p><ul><li>Control total sobre el entorno de implementaci√≥n</li><li>Procesamiento de datos completamente dentro de su per√≠metro de seguridad</li><li>Integraci√≥n con el monitoreo y controles de seguridad existentes</li></ul><p>Para obtener licencias comerciales para nuestros modelos CC-BY-NC, primero necesita obtener una licencia de nosotros. <a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">No dude en contactar a nuestro equipo de ventas.</a></p><h3 id=\"jina-api-service\">Servicio de API de Jina</h3><p>Para <strong>startups y PYMES</strong> que intentan equilibrar la seguridad y la conveniencia frente a los costos, nuestro servicio de API proporciona seguridad de nivel empresarial sin agregar sobrecarga operativa:</p><ul><li><a href=\"https://jina.ai/Jina_AI_GmbH_Letter_of_Attestation_SOC_2_Type_1.pdf\" rel=\"noreferrer\">Certificaci√≥n SOC2</a> que garantiza controles de seguridad robustos</li><li><a href=\"https://gdpr-info.eu/\" rel=\"noreferrer\">Cumplimiento total del GDPR</a> para el procesamiento de datos</li><li>Pol√≠tica de retenci√≥n cero de datos - no almacenamos ni registramos sus solicitudes</li><li>Transmisi√≥n de datos encriptada e infraestructura segura</li></ul><p>Las ofertas de modelos de Jina AI permiten a las organizaciones elegir la estrategia de implementaci√≥n que mejor se alinee con sus requisitos de seguridad mientras mantienen la eficiencia operativa.</p><h2 id=\"choosing-your-solution\">Eligiendo Tu Soluci√≥n</h2><p>El diagrama de flujo a continuaci√≥n resume los resultados de todas las pruebas emp√≠ricas y tablas que has visto:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1256\" height=\"1980\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png 1256w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Con esa informaci√≥n en mano, el diagrama de flujo anterior deber√≠a darte una buena indicaci√≥n de qu√© tipos de soluciones considerar.</span></figcaption></figure><p>Primero, considera tus necesidades de seguridad y cu√°nta flexibilidad puedes sacrificar para cumplirlas.</p><p>Luego, considera c√≥mo planeas usar la IA en tu empresa:</p><ol><li>Indexaci√≥n offline y casos de uso no sensibles al tiempo que pueden usar procesamiento por lotes de manera √≥ptima.</li><li>Usos sensibles a la confiabilidad y escalabilidad como la generaci√≥n aumentada por recuperaci√≥n e integraci√≥n con LLM.</li><li>Usos sensibles al tiempo como b√∫squeda y recuperaci√≥n en l√≠nea.</li></ol><p>Tambi√©n, considera tu experiencia interna e infraestructura existente:</p><ol><li>¬øTu stack tecnol√≥gico ya depende en gran medida de la nube?</li><li>¬øTienes una gran operaci√≥n de TI interna capaz de autoalojamiento?</li></ol><p>Por √∫ltimo, considera tus vol√∫menes de datos esperados. ¬øEres un usuario a gran escala que espera realizar millones de operaciones usando modelos de IA cada d√≠a?</p><h2 id=\"conclusion\">Conclusi√≥n</h2><p>La integraci√≥n de IA en las decisiones operativas sigue siendo territorio inexplorado para muchos departamentos de TI, ya que el mercado carece de soluciones llave en mano establecidas. Esta incertidumbre puede hacer que la planificaci√≥n estrat√©gica sea desafiante. Nuestro an√°lisis cuantitativo tiene como objetivo proporcionar una gu√≠a concreta sobre c√≥mo incorporar nuestros modelos de base de b√∫squeda en tus flujos de trabajo y aplicaciones espec√≠ficas.</p><p>En cuanto al costo por unidad, la API de Jina se destaca como una de las opciones m√°s econ√≥micas disponibles para las empresas. Pocas alternativas pueden igualar nuestro precio mientras ofrecen funcionalidad comparable.</p><p>Estamos comprometidos a ofrecer capacidades de b√∫squeda que no solo sean potentes y f√°ciles de usar, sino tambi√©n rentables para organizaciones de todos los tama√±os. Ya sea a trav√©s de los principales proveedores de la nube o implementaciones autoalojadas, nuestras soluciones se adaptan incluso a los requisitos empresariales m√°s complejos que van m√°s all√° de las consideraciones puramente de costo. Este an√°lisis desglosa los diversos factores de costo para ayudar a informar tu toma de decisiones.</p><p>Dado que cada organizaci√≥n tiene sus propios requisitos √∫nicos, reconocemos que un solo art√≠culo no puede abordar todos los escenarios. Si tienes necesidades espec√≠ficas no cubiertas aqu√≠, no dudes en contactarnos para discutir c√≥mo podemos apoyar mejor tu implementaci√≥n.</p>",
  "comment_id": "679b56ba42b46600019a86e3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-01-30T11:38:50.000+01:00",
  "updated_at": "2025-01-31T05:32:29.000+01:00",
  "published_at": "2025-01-31T05:32:29.000+01:00",
  "custom_excerpt": "We offer detailed cost and performance breakdowns for three deployment strategies: Jina API, self-hosted K8s, and AWS SageMaker, to help you make the right decision.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "641c23a2f4d50d003d590474",
    "name": "Saahil Ognawala",
    "slug": "saahil",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
    "cover_image": null,
    "bio": "Senior Product Manager at Jina AI",
    "website": "http://www.saahilognawala.com/",
    "location": "Munich, DE",
    "facebook": null,
    "twitter": "@saahil",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-deploying-search-foundation-models-in-production/",
  "excerpt": "Ofrecemos an√°lisis detallados de costos y rendimiento para tres estrategias de implementaci√≥n: Jina API, K8s autogestionado y AWS SageMaker, para ayudarte a tomar la decisi√≥n correcta.",
  "reading_time": 14,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}