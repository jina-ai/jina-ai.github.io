{
  "slug": "fact-checking-with-new-grounding-api-in-jina-reader",
  "id": "670cd94952567c0001d0f33e",
  "uuid": "20c36ec7-687f-47c8-8cfd-8da526a70859",
  "title": "Verificación de hechos con la nueva API de Grounding en Jina Reader",
  "html": "<p>La fundamentación es <em>absolutamente esencial</em> para las aplicaciones de GenAI.</p><p>Sin fundamentación, los LLMs son más propensos a las alucinaciones y a generar información inexacta, especialmente cuando sus datos de entrenamiento carecen de conocimientos actualizados o específicos. No importa qué tan fuerte sea la capacidad de razonamiento de un LLM, simplemente no puede proporcionar una respuesta correcta si la información fue introducida <em>después</em> de su fecha límite de conocimiento.</p><p>La fundamentación no solo es importante para los LLMs sino también para el contenido escrito por humanos para prevenir la desinformación. Un gran ejemplo es <a href=\"https://communitynotes.x.com/guide/en/about/introduction?ref=jina-ai-gmbh.ghost.io\">Community Notes de X</a>, donde los usuarios añaden colaborativamente contexto a publicaciones potencialmente engañosas. Esto resalta el valor de la fundamentación, que asegura la precisión factual proporcionando fuentes y referencias claras, de manera similar a como Community Notes ayuda a mantener la integridad de la información.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png\" class=\"kg-image\" alt=\"Screenshot of a mobile chat in the Sage app discussing whether whales are mammals and how they hydrate, with options to rate \" loading=\"lazy\" width=\"2000\" height=\"1113\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image.png 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Con <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>, hemos estado desarrollando activamente una solución de fundamentación fácil de usar. Por ejemplo, <code>r.jina.ai</code> convierte páginas web en markdown compatible con LLM, y <code>s.jina.ai</code> agrega resultados de búsqueda en un formato markdown unificado basado en una consulta dada.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reader API</div><div class=\"kg-bookmark-description\">Read URLs or search the web, get better grounding for LLMs.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-9.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-reader-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><strong>Hoy, nos complace presentar un nuevo endpoint para esta suite: <code>g.jina.ai</code>. </strong>La nueva API toma una declaración dada, la fundamenta usando resultados de búsqueda web en tiempo real, y devuelve una puntuación de factualidad y <strong>las referencias exactas utilizadas</strong>. Nuestros experimentos muestran que esta API logra una puntuación F1 más alta para la verificación de hechos en comparación con modelos como GPT-4, o1-mini y Gemini 1.5 Flash & Pro con fundamentación basada en búsqueda.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Evaluation-of-grounding-solutions-on-fact-checking-100-statements--1-.svg\" class=\"kg-image\" alt=\"Bar graph illustrating the evaluation of various grounding solutions for fact-checking 100 statements, with software scores r\" loading=\"lazy\" width=\"1218\" height=\"371\"><figcaption><span style=\"white-space: pre-wrap;\">Recopilamos manualmente 100 declaraciones con etiquetas de verdad fundamentada ya sea 'verdadero' o 'falso' y utilizamos diferentes métodos para determinar si podían ser verificadas. Este proceso esencialmente convierte la tarea en un problema de clasificación binaria, donde el rendimiento final se mide por la puntuación F1—cuanto más alta, mejor.</span></figcaption></figure><p>Lo que distingue a <code>g.jina.ai</code> de la Fundamentación por Búsqueda de Gemini es que cada resultado incluye hasta 30 URLs (típicamente proporcionando al menos 10), cada una acompañada de citas directas que contribuyen a la conclusión. A continuación hay un ejemplo de fundamentación de la declaración, <code>\"The latest model released by Jina AI is jina-embeddings-v3,\"</code> usando <code>g.jina.ai</code> (a fecha del 14 de octubre de 2024). Explora el <a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">playground de la API</a> para descubrir todas las funcionalidades. Ten en cuenta que se aplican <a href=\"#limitations\" rel=\"noreferrer\">limitaciones</a>:</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-bash\">curl -X POST https://g.jina.ai \\\n     -H \"Content-Type: application/json\" \\\n     -H \"Authorization: Bearer $YOUR_JINA_TOKEN\" \\\n     -d '{\n           \"statement\":\"the last model released by Jina AI is jina-embeddings-v3\"\n         }'</code></pre><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>YOUR_JINA_TOKEN</span></code><span style=\"white-space: pre-wrap;\"> es tu clave API de Jina AI. Puedes </span><a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">obtener 1M de tokens gratuitos desde nuestra página principal</span></a><span style=\"white-space: pre-wrap;\">, que permite aproximadamente tres o cuatro pruebas gratuitas. Con el precio actual de la API de 0.02USD por 1M de tokens, cada solicitud de fundamentación cuesta aproximadamente $0.006.</span></p></figcaption></figure><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"code\": 200,\n  \"status\": 20000,\n  \"data\": {\n    \"factuality\": 0.95,\n    \"result\": true,\n    \"reason\": \"The majority of the references explicitly support the statement that the last model released by Jina AI is jina-embeddings-v3. Multiple sources, such as the arXiv paper, Jina AI's news, and various model documentation pages, confirm this assertion. Although there are a few references to the jina-embeddings-v2 model, they do not provide evidence contradicting the release of a subsequent version (jina-embeddings-v3). Therefore, the statement that 'the last model released by Jina AI is jina-embeddings-v3' is well-supported by the provided documentation.\",\n    \"references\": [\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"arXiv September 18, 2024 jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://arxiv.org/abs/2409.10173\",\n        \"keyQuote\": \"We introduce jina-embeddings-v3, a novel text embedding model with 570 million parameters, achieves state-of-the-art performance on multilingual data and long-context retrieval tasks, supporting context lengths of up to 8192 tokens.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview\",\n        \"keyQuote\": \"jina-embeddings-v3 is a multilingual multi-task text embedding model designed for a variety of NLP applications.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://docs.pinecone.io/models/jina-embeddings-v3\",\n        \"keyQuote\": \"Jina Embeddings v3 is the latest iteration in the Jina AI's text embedding model series, building upon Jina Embedding v2.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://haystack.deepset.ai/integrations/jina\",\n        \"keyQuote\": \"Recommended Model: jina-embeddings-v3 : We recommend jina-embeddings-v3 as the latest and most performant embedding model from Jina AI.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"The embedding model was trained using 512 sequence length, but extrapolates to 8k sequence length (or even longer) thanks to ALiBi.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"With a standard size of 137 million parameters, the model enables fast inference while delivering better performance than our small model.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v2-base-en\",\n        \"keyQuote\": \"We offer an `encode` function to deal with this.\",\n        \"isSupportive\": false\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jinaai/jina-embeddings-v3 Feature Extraction • Updated 3 days ago • 278k • 375\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"the latest version (3.1.0) of [SentenceTransformers] also supports jina-embeddings-v3\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://huggingface.co/jinaai/jina-embeddings-v3\",\n        \"keyQuote\": \"jina-embeddings-v3: Multilingual Embeddings With Task LoRA\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/embeddings/\",\n        \"keyQuote\": \"v3: Frontier Multilingual Embeddings is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model\",\n        \"keyQuote\": \"Jina Embeddings v3: A Frontier Multilingual Embedding Model jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.\",\n        \"isSupportive\": true\n      },\n      {\n        \"url\": \"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/\",\n        \"keyQuote\": \"As of its release on September 18, 2024, jina-embeddings-v3 is the best multilingual model ...\",\n        \"isSupportive\": true\n      }\n    ],\n    \"usage\": {\n      \"tokens\": 112073\n    }\n  }\n}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">La respuesta de la fundamentación de la declaración \"The latest model released by Jina AI is jina-embeddings-v3,\" usando </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>g.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> (a fecha del 14 de octubre de 2024).</span></p></figcaption></figure><h2 id=\"how-does-it-work\">¿Cómo Funciona?</h2><p>En su núcleo, <code>g.jina.ai</code> envuelve <code>s.jina.ai</code> y <code>r.jina.ai</code><strong> </strong>, añadiendo razonamiento de múltiples pasos a través de Chain of Thought (CoT). Este enfoque asegura que cada declaración fundamentada sea analizada minuciosamente con la ayuda de búsquedas en línea y lectura de documentos.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/User-Render.svg\" class=\"kg-image\" alt=\"UI of Jina AI reader app, displaying three panels: User Input, Response, and User Render with interactive links and buttons a\" loading=\"lazy\" width=\"1400\" height=\"630\"><figcaption><span style=\"white-space: pre-wrap;\">Grounding API es un wrapper sobre </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>s.jina.ai</span></code><span style=\"white-space: pre-wrap;\"> y </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>r.jina.ai</span></code><span style=\"white-space: pre-wrap;\">, añadiendo CoT para planificación y razonamiento. </span></figcaption></figure><h3 id=\"step-by-step-explanation\">Explicación Paso a Paso</h3><p>Veamos todo el proceso para entender mejor cómo <code>g.jina.ai</code> maneja la verificación desde la entrada hasta la salida final:</p><ol><li><strong>Declaración de Entrada</strong>:<br>El proceso comienza cuando un usuario proporciona una declaración que desea verificar, como <em>\"El último modelo lanzado por Jina AI es jina-embeddings-v3.\"</em> Nota, no es necesario agregar ninguna instrucción de verificación de hechos antes de la declaración.</li><li><strong>Generar Consultas de Búsqueda</strong>:<br>Se emplea un LLM para generar una lista de consultas de búsqueda únicas que son relevantes para la declaración. Estas consultas buscan abordar diferentes elementos factuales, asegurando que la búsqueda cubra todos los aspectos clave de la declaración de manera integral.</li><li><strong>Llamar a <code>s.jina.ai</code> para Cada Consulta</strong>:<br>Para cada consulta generada, <code>g.jina.ai</code> realiza una búsqueda web usando <code>s.jina.ai</code>. Los resultados de búsqueda consisten en un conjunto diverso de sitios web o documentos relacionados con las consultas. Detrás de escena, <code>s.jina.ai</code> llama a <code>r.jina.ai</code> para obtener el contenido de la página.</li><li><strong>Extraer Referencias de los Resultados de Búsqueda</strong>:<br>De cada documento recuperado durante la búsqueda, un LLM extrae las referencias clave. Estas referencias incluyen:<ul><li><strong><code>url</code></strong>: La dirección web de la fuente.</li><li><strong><code>keyQuote</code></strong>: Una cita directa o extracto del documento.</li><li><strong><code>isSupportive</code></strong>: Un valor booleano que indica si la referencia apoya o contradice la declaración original.</li></ul></li><li><strong>Agregar y Recortar Referencias</strong>:<br>Todas las referencias de los documentos recuperados se combinan en una sola lista. Si el número total de referencias excede 30, el sistema selecciona 30 referencias aleatorias para mantener una salida manejable.</li><li><strong>Evaluar la Declaración</strong>:<br>El proceso de evaluación implica usar un LLM para evaluar la declaración basándose en las referencias recopiladas (hasta 30). Además de estas referencias externas, el conocimiento interno del modelo también juega un papel en la evaluación. El resultado final incluye:<ul><li><strong><code>factuality</code></strong>: Una puntuación entre 0 y 1 que estima la precisión factual de la declaración.</li><li><strong><code>result</code></strong>: Un valor booleano que indica si la declaración es verdadera o falsa.</li><li><strong><code>reason</code></strong>: Una explicación detallada de por qué la declaración se juzga como correcta o incorrecta, haciendo referencia a las fuentes que la apoyan o contradicen.</li></ul></li><li><strong>Generar el Resultado</strong>:<br>Una vez que la declaración ha sido completamente evaluada, se genera la salida. Esto incluye la <strong>puntuación de factualidad</strong>, la <strong>afirmación de la declaración</strong>, un <strong>razonamiento detallado</strong>, y una lista de <strong>referencias</strong> con citas y URLs. Las referencias se limitan a la cita, URL y si apoyan o no la declaración, manteniendo la salida clara y concisa.</li></ol><h2 id=\"benchmark\">Evaluación Comparativa</h2><p>Recopilamos manualmente 100 declaraciones con etiquetas de verdad de <code>true</code> (62 declaraciones) o <code>false</code> (38 declaraciones) y utilizamos diferentes métodos para determinar si podían ser verificadas. Este proceso esencialmente convierte la tarea en un problema de clasificación binaria, donde el rendimiento final se mide por la precisión, recuperación y puntuación F1—cuanto más alto, mejor. </p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://docs.google.com/spreadsheets/d/1xE-uCTQ4G0cYRw_g781zZXHO8eRYi31HbCb-3BPlNh8/edit?gid=1283553680&ref=jina-ai-gmbh.ghost.io#gid=1283553680\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Grounding Validation Dataset</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/spreadsheets_2023q4.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/AHkbwyJpf4HNZ3zF1snMGetpmkt0oOTQGGviY1-ZTOrq5dXuafT8uWLmZ806MU1A_agTpgO52Z_xZ-iDougmFm0ViL0sVSqDxe3C4fVuPcYXKoS5O90jN3Qy-w1200-h630-p\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><span style=\"white-space: pre-wrap;\">La lista completa de declaraciones puede encontrarse aquí.</span></p></figcaption></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Precision</th>\n<th>Recall</th>\n<th>F1 Score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Jina AI Grounding API (g.jina.ai)</strong></td>\n<td>0.96</td>\n<td><strong>0.88</strong></td>\n<td><strong>0.92</strong></td>\n</tr>\n<tr>\n<td>Gemini-flash-1.5-002 w/ grounding</td>\n<td><strong>1.00</strong></td>\n<td>0.73</td>\n<td>0.84</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-002 w/ grounding</td>\n<td>0.98</td>\n<td>0.71</td>\n<td>0.82</td>\n</tr>\n<tr>\n<td>gpt-o1-mini</td>\n<td>0.87</td>\n<td>0.66</td>\n<td>0.75</td>\n</tr>\n<tr>\n<td>gpt-4o</td>\n<td>0.95</td>\n<td>0.58</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001 w/ grounding</td>\n<td>0.97</td>\n<td>0.52</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>Gemini-pro-1.5-001</td>\n<td>0.95</td>\n<td>0.32</td>\n<td>0.48</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Nota: en la práctica, algunos LLMs devuelven una tercera clase, <em>No lo sé</em>, en sus predicciones. Para la evaluación, estas instancias se excluyen del cálculo de la puntuación. Este enfoque evita penalizar la incertidumbre tan severamente como las respuestas incorrectas. Es preferible admitir la incertidumbre a adivinar, para desalentar a los modelos de hacer predicciones inciertas.</p><h2 id=\"limitations\">Limitaciones</h2><p>A pesar de los resultados prometedores, nos gustaría destacar algunas limitaciones de la versión actual del API de grounding:</p><ul><li><strong>Alta Latencia y Consumo de Tokens</strong>: Una sola llamada a <code>g.jina.ai</code> puede tomar alrededor de <strong>30 segundos</strong> y usar hasta <strong>300K tokens</strong>, debido a la búsqueda web activa, lectura de páginas y razonamiento multi-hop por el LLM. Con una clave API gratuita de 1M de tokens, esto significa que solo puedes probarlo unas tres o cuatro veces. Para mantener la disponibilidad del servicio para usuarios pagados, también hemos implementado <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#rate-limit\" rel=\"noreferrer\">un límite de tasa conservador para <code>g.jina.ai</code>.</a> Con nuestro precio actual de API de $0.02 por 1M de tokens, cada solicitud de verificación cuesta aproximadamente 0.006 USD.</li><li><strong>Restricciones de Aplicabilidad</strong>: <em>No toda declaración puede o debe ser verificada.</em> Las opiniones o experiencias personales, como \"Me siento perezoso\", no son adecuadas para verificación. De manera similar, eventos futuros o declaraciones hipotéticas no aplican. Hay muchos casos donde la verificación sería irrelevante o sin sentido. Para evitar llamadas API innecesarias, recomendamos a los usuarios enviar selectivamente solo oraciones o secciones que realmente requieren verificación de hechos. En el lado del servidor, hemos implementado un conjunto completo de códigos de error para explicar por qué una declaración podría ser rechazada para verificación.</li><li><strong>Dependencia de la Calidad de Datos Web</strong>: La precisión del API de grounding es tan buena como la calidad de las fuentes que recupera. Si los resultados de búsqueda contienen información de baja calidad o sesgada, el proceso de verificación podría reflejar eso, potencialmente llevando a conclusiones inexactas o engañosas. Para prevenir este problema, permitimos a los usuarios especificar manualmente el parámetro <code>references</code> y restringir las URLs contra las que el sistema busca. Esto da a los usuarios más control sobre las fuentes utilizadas para la verificación, asegurando un proceso de verificación de hechos más enfocado y relevante.</li></ul><h2 id=\"conclusion\">Conclusión</h2><p>El API de grounding ofrece una experiencia de verificación de hechos de principio a fin en tiempo casi real. Los investigadores pueden usarla para encontrar referencias que apoyen o desafíen sus hipótesis, añadiendo credibilidad a su trabajo. En reuniones empresariales, asegura que las estrategias se construyan sobre información precisa y actualizada mediante la validación de suposiciones y datos. En discusiones políticas, verifica rápidamente las afirmaciones, aportando más responsabilidad a los debates.</p><p>De cara al futuro, planeamos mejorar el API integrando fuentes de datos privadas como informes internos, bases de datos y PDFs para una verificación de hechos más personalizada. También buscamos expandir el número de fuentes verificadas por solicitud para evaluaciones más profundas. Mejorar la respuesta a preguntas multi-hop añadirá profundidad al análisis, y aumentar la consistencia es una prioridad para asegurar que las solicitudes repetidas produzcan resultados más confiables y consistentes.</p>",
  "comment_id": "670cd94952567c0001d0f33e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-10-14T10:41:45.000+02:00",
  "updated_at": "2024-10-15T20:11:23.000+02:00",
  "published_at": "2024-10-15T10:08:02.000+02:00",
  "custom_excerpt": "With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fact-checking-with-new-grounding-api-in-jina-reader/",
  "excerpt": "Con el nuevo g.jina.ai, puedes verificar fácilmente las declaraciones para reducir las alucinaciones de los LLM o mejorar la integridad del contenido escrito por humanos.",
  "reading_time": 9,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Jina developer interface showing \"Jina AI was founded in 2020\" with controls labeled true and false, and web address on top.",
  "feature_image_caption": null
}