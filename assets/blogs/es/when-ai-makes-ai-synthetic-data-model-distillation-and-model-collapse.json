{
  "slug": "when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse",
  "id": "6639e8e1af8f52000115be49",
  "uuid": "1b3da192-0050-4b9e-8528-c5e638d50870",
  "title": "Cuando la IA Crea IA: Datos Sintéticos, Destilación de Modelos y Colapso de Modelos",
  "html": "<p>Las discusiones sobre la IA suelen ser apocalípticas. Parte de la culpa la tiene la forma en que la <a href=\"https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping?ref=jina-ai-gmbh.ghost.io\">ciencia ficción apocalíptica</a> ha creado nuestra imagen mental de la inteligencia artificial. Las visiones de máquinas inteligentes que pueden crear más máquinas han sido un tema común en la ciencia ficción durante generaciones.</p><p>Muchas personas han expresado su preocupación sobre los riesgos existenciales de los recientes avances en IA, muchos de ellos <a href=\"https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html?ref=jina-ai-gmbh.ghost.io\">líderes empresariales involucrados en la comercialización de la IA</a>, e incluso algunos <a href=\"https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/?ref=jina-ai-gmbh.ghost.io\">científicos</a> e <a href=\"https://www.lemonde.fr/en/international/article/2023/06/04/in-montreal-one-of-the-fathers-of-artificial-intelligence-warns-of-an-existential-threat-to-mankind_6029007_4.html?ref=jina-ai-gmbh.ghost.io\">investigadores</a>. Se ha convertido en un componente del bombo publicitario de la IA: algo lo suficientemente poderoso como para hacer que figuras aparentemente sobrias de la ciencia y la industria contemplen el fin del mundo debe ser sin duda lo suficientemente poderoso como para generar beneficios, ¿verdad?</p><p>Entonces, ¿deberíamos preocuparnos por los riesgos existenciales de la IA? ¿Debemos temer que Sam Altman cree a Ultron a partir de ChatGPT y tenga su <a href=\"https://youtu.be/d4yZPjB7smU?ref=jina-ai-gmbh.ghost.io\">ejército de IA lanzándonos ciudades de Europa del Este</a>? ¿Deberíamos preocuparnos de que <a href=\"https://venturebeat.com/business/why-palantir-is-silicon-valleys-most-questionable-unicorn/?ref=jina-ai-gmbh.ghost.io\">Palantir de Peter Thiel</a> esté <a href=\"https://youtu.be/4DQsG3TKQ0I?ref=jina-ai-gmbh.ghost.io\">construyendo Skynet</a> y enviando <a href=\"https://youtu.be/wOO9DSnLOm8?ref=jina-ai-gmbh.ghost.io\">robots con inexplicables acentos austriacos al pasado para matarnos</a>?</p><p>Probablemente no. Los líderes de la industria aún no han identificado ninguna manera clara de hacer que la IA pague sus propias cuentas, mucho menos disrumpir industrias, y menos aún amenazar a la humanidad a un nivel comparable al cambio climático o las armas nucleares.</p><p>Los modelos de IA que realmente tenemos difícilmente están a la altura de exterminar a la humanidad. Luchan por dibujar manos, no pueden contar más de tres cosas, piensan que está <a href=\"https://www.nbcnewyork.com/news/local/nycs-ai-chatbot-was-caught-telling-businesses-to-break-the-law-the-city-isnt-taking-it-down/5287713/?ref=jina-ai-gmbh.ghost.io\">bien vender queso que las ratas han mordisqueado</a>, y <a href=\"https://www.techtimes.com/articles/304222/20240502/ai-priest-demoted-saying-babies-baptized-gatorade.htm?ref=jina-ai-gmbh.ghost.io\">realizan bautizos católicos con Gatorade</a>. Los riesgos mundanos y no existenciales de la IA — la forma en que la tecnología puede ayudar a desinformar, acosar, generar spam y ser mal utilizada por personas que no comprenden sus limitaciones — son suficientemente preocupantes.</p><p>Pero hay un riesgo existencial de la inteligencia artificial que definitivamente es legítimo: la IA representa un peligro claro y presente para... la <em>IA</em>.</p><p>Este temor generalmente se denomina \"colapso del modelo\" y ha recibido una sólida demostración empírica en <a href=\"https://arxiv.org/abs/2305.17493?ref=jina-ai-gmbh.ghost.io\">Shumailov et al. (2023)</a> y <a href=\"https://arxiv.org/abs/2307.01850?ref=jina-ai-gmbh.ghost.io\">Alemohammad et al. (2023)</a>. La idea es simple: si entrenas modelos de IA con datos generados por IA, luego tomas la IA resultante y usas su salida para entrenar otro modelo, repitiendo el proceso durante múltiples generaciones, la IA se volverá objetivamente peor y peor. Es como hacer una fotocopia de una fotocopia de una fotocopia.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png\" class=\"kg-image\" alt=\"Deteriorating copies of an ad for the Intertec Superbrain, taken from BYTE magazine, Sept. 1981.\" loading=\"lazy\" width=\"1200\" height=\"400\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Superbrain.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Superbrain.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Superbrain.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Copias deterioradas de un anuncio del </span><a href=\"https://en.wikipedia.org/wiki/Intertec_Superbrain?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">Intertec Superbrain</span></a><span style=\"white-space: pre-wrap;\">, tomadas de la </span><a href=\"https://archive.org/details/byte-magazine-1981-09/page/n177/mode/2up\"><span style=\"white-space: pre-wrap;\">revista BYTE, septiembre de 1981</span></a><span style=\"white-space: pre-wrap;\">.</span></figcaption></figure><p>Últimamente ha habido algunas discusiones sobre el colapso del modelo, y están apareciendo <a href=\"https://www.businessinsider.com/ai-training-data-source-solutions-openai-meta-google-2024-4?ref=jina-ai-gmbh.ghost.io\">titulares</a> <a href=\"https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?ref=jina-ai-gmbh.ghost.io\">en la prensa</a> <a href=\"https://www.yahoo.com/news/ai-companies-running-training-data-220047540.html?guccounter=1&ref=jina-ai-gmbh.ghost.io\">sobre la IA</a> <a href=\"https://www.businessinsider.com/ai-giants-openai-anthropic-running-out-of-good-training-data-2024-4?ref=jina-ai-gmbh.ghost.io\">quedándose sin</a> <a href=\"https://www.technologyreview.com/2022/11/24/1063684/we-could-run-out-of-data-to-train-ai-language-programs/?ref=jina-ai-gmbh.ghost.io\">datos</a>. Si Internet se llena de datos generados por IA, y los datos creados por humanos se vuelven más difíciles de identificar y usar, entonces, en poco tiempo, los modelos de IA se encontrarán con un techo de calidad.</p><p>Al mismo tiempo, hay un uso creciente de técnicas de <a href=\"https://en.wikipedia.org/wiki/Synthetic_data?ref=jina-ai-gmbh.ghost.io\">datos sintéticos</a> y <a href=\"https://en.wikipedia.org/wiki/Knowledge_distillation?ref=jina-ai-gmbh.ghost.io\">destilación de modelos</a> en el desarrollo de IA. Ambas consisten en entrenar modelos de IA al menos en parte con la salida de otros modelos de IA. Estas dos tendencias parecen contradecirse entre sí.</p><p>Las cosas son un poco más complicadas que eso. ¿La IA generativa saturará el sistema y sofocará su propio progreso? ¿O la IA nos ayudará a crear mejor IA? ¿O ambas cosas?</p><p>Intentaremos obtener algunas respuestas en este artículo.</p><h2 id=\"model-collapse\">Colapso del Modelo</h2><p>Por mucho que apreciemos a Alemohammad et al. por inventar el término \"Trastorno de Autofagia del Modelo (MAD)\", \"colapso del modelo\" es mucho más pegadizo y no involucra palabras griegas para el auto-canibalismo. La metáfora de hacer fotocopias de fotocopias comunica el problema en términos simples, pero hay algo más en la teoría subyacente.</p><p>Entrenar un modelo de IA es un tipo de modelado estadístico, una extensión de lo que los estadísticos y científicos de datos han estado haciendo durante mucho tiempo. Pero, en el primer día de clase de ciencia de datos, aprendes el lema del científico de datos:</p><blockquote><strong><em>Todos los modelos están equivocados</em></strong>,&nbsp;<strong><em>pero algunos son útiles.</em></strong></blockquote><p>Esta cita, atribuida a <a href=\"https://en.wikipedia.org/wiki/George_E._P._Box?ref=jina-ai-gmbh.ghost.io\">George Box</a>, es la luz roja intermitente que debería estar sobre cada modelo de IA. Siempre puedes hacer un modelo estadístico para cualquier conjunto de datos, y ese modelo siempre te dará una respuesta, pero absolutamente nada garantiza que esa respuesta sea correcta o siquiera se acerque a serlo.</p><p>Un modelo estadístico es una <em>aproximación</em> de algo. Sus salidas pueden ser útiles, incluso podrían ser lo suficientemente buenas, pero siguen siendo aproximaciones. Incluso si tienes un modelo bien validado que, en promedio, es muy preciso, puede y probablemente cometerá grandes errores a veces.</p><p>Los modelos de IA heredan todos los problemas del modelado estadístico. Cualquiera que haya jugado con ChatGPT o cualquier otro modelo grande de IA ha visto que comete errores.</p><p>Entonces, si un modelo de IA es una aproximación de algo real, un modelo de IA entrenado con la salida de otro modelo de IA es una aproximación de una aproximación. Los errores se acumulan, y inherentemente tiene que ser un modelo menos correcto que el modelo del que fue entrenado.</p><p>Alemohammad et al. muestran que no puedes arreglar el problema agregando algunos de los datos de entrenamiento originales a la salida de la IA antes de entrenar el nuevo modelo \"hijo\". Eso solo ralentiza el colapso del modelo, no puede detenerlo. A menos que introduzcas suficientes datos nuevos, previamente no vistos, del mundo real siempre que entrenes con salida de IA, el colapso del modelo es inevitable.</p><p>Cuántos datos nuevos son suficientes depende de factores difíciles de predecir y específicos de cada caso, pero más datos nuevos y reales y menos datos generados por IA siempre es mejor que lo contrario.</p><p>Y eso es un problema porque todas las fuentes fácilmente accesibles de datos nuevos creados por humanos ya están agotadas mientras que la cantidad de datos de imagen y texto generados por IA está creciendo a pasos agigantados. La proporción de contenido creado por humanos versus contenido creado por IA en Internet está cayendo, posiblemente cayendo rápido. No hay <a href=\"https://www.washingtonpost.com/technology/2023/06/02/turnitin-ai-cheating-detector-accuracy/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">manera confiable de detectar automáticamente datos generados por IA</a> y <a href=\"https://arxiv.org/abs/2303.11156?ref=jina-ai-gmbh.ghost.io\">muchos investigadores</a> <a href=\"https://www.techspot.com/news/98031-reliable-detection-ai-generated-text-impossible-new-study.html?ref=jina-ai-gmbh.ghost.io\">creen que no puede haberla.</a> El acceso público a modelos de generación de imágenes y texto por IA asegura que este problema crecerá, probablemente de manera dramática, y no tiene una solución obvia.</p><p>La <a href=\"https://www.vice.com/en/article/y3w4gw/a-shocking-amount-of-the-web-is-already-ai-translated-trash-scientists-determine?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">cantidad de traducción automática en Internet</a> podría significar que ya es demasiado tarde. El texto traducido por máquinas en Internet ha estado contaminando nuestras fuentes de datos durante años, mucho antes de la revolución de la IA generativa. Según <a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">Thompson, et al., 2024</a>, posiblemente la mitad del texto en Internet puede estar traducido de otro idioma, y una gran parte de esas traducciones son de baja calidad y muestran señales de generación automática. Esto puede distorsionar un modelo de lenguaje entrenado con dichos datos.</p><p>Como ejemplo, a continuación se muestra una captura de pantalla de <a href=\"https://ww1.habsburger.net/en/chapters/hamster-buying-queuing-do-it-yourself-individual-strategies-provide-food-become?ref=jina-ai-gmbh.ghost.io\">una página del sitio web <em>Die Welt der Habsburger</em></a> que muestra clara evidencia de traducción automática. \"Hamster buying\" es una traducción demasiado literal de la palabra alemana <em>hamstern</em>, que significa <em>acaparar</em> o <em>comprar en pánico</em>. Demasiados casos como este llevarán a un modelo de IA a pensar que \"hamster buying\" es algo real en inglés y que el término alemán <em>hamstern</em> tiene algo que ver con hámsteres mascota.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.07.20.png\" loading=\"lazy\" width=\"1532\" height=\"1074\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.07.20.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.07.20.png 1532w\" sizes=\"(min-width: 720px) 720px\"></figure><p>En casi todos los casos, tener más contenido generado por IA en tus datos de entrenamiento es malo. El <em>casi</em> es importante, y discutiremos dos excepciones a continuación.</p><h2 id=\"synthetic-data\">Datos Sintéticos</h2><p>Los datos sintéticos son datos de entrenamiento o evaluación de IA que han sido generados artificialmente en lugar de encontrados en el mundo real. <a href=\"https://doi.org/10.1007/978-3-030-75178-4?ref=jina-ai-gmbh.ghost.io\">Nikolenko (2021)</a> sitúa los orígenes de los datos sintéticos en los primeros proyectos de visión por computadora en los años 1960 y describe su historia como un elemento importante de ese campo.</p><p>Hay muchas razones para usar datos sintéticos. Una de las más importantes es combatir el sesgo.</p><p>Los modelos de lenguaje grandes y los generadores de imágenes han recibido muchas <a href=\"https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/?ref=jina-ai-gmbh.ghost.io\">críticas</a> <a href=\"https://www.washington.edu/news/2023/11/29/ai-image-generator-stable-diffusion-perpetuates-racial-and-gendered-stereotypes-bias/?ref=jina-ai-gmbh.ghost.io\">de alto perfil</a> <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">sobre sesgos</a>. La palabra <em>sesgo</em> tiene un significado estricto en estadística, pero estas críticas a menudo reflejan consideraciones morales, sociales y políticas que no tienen una forma matemática simple ni una solución de ingeniería.</p><p>El sesgo que no se ve fácilmente es mucho más dañino y más difícil de corregir. Los patrones que los modelos de IA aprenden a replicar son los que ven en sus datos de entrenamiento, y donde esos datos tienen deficiencias sistemáticas, el sesgo es una consecuencia inevitable. Cuantas más cosas diferentes esperamos que haga la IA —cuanto más diversos sean los inputs al modelo— más probabilidades hay de que se equivoque porque nunca vio suficientes casos similares en su entrenamiento.</p><p>El papel principal de los datos sintéticos en el entrenamiento de IA hoy en día es asegurar que haya suficientes ejemplos de ciertos tipos de situaciones en los datos de entrenamiento, situaciones que pueden no estar suficientemente presentes en los datos naturales disponibles.</p><p>A continuación se muestra una imagen que MidJourney produjo cuando se le indicó \"doctor\": cuatro hombres, tres blancos, tres con batas blancas y estetoscopios, y uno genuinamente mayor. Esto no refleja la raza, edad, género o vestimenta real de los médicos en la mayoría de los países y contextos, pero probablemente refleja las imágenes etiquetadas que se encuentran en Internet.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--59-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--59-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--59-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--59-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Cuando se le pidió de nuevo, produjo una mujer y tres hombres, todos blancos, aunque uno es un dibujo animado. La IA puede ser extraña.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png\" class=\"kg-image\" alt=\"Untitled\" loading=\"lazy\" width=\"2000\" height=\"1121\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--60-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Untitled--60-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Untitled--60-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--60-.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Esta fuente particular de sesgo es una que los generadores de imágenes de IA han estado tratando de prevenir, por lo que ya no obtenemos resultados tan claramente sesgados como quizás hace un año de los mismos sistemas. Un sesgo es visiblemente presente todavía, pero no es obvio cómo sería un resultado sin sesgo.</p><p>Aun así, no es difícil entender cómo una IA podría adquirir este tipo de prejuicios. A continuación se muestran las primeras tres imágenes encontradas para \"doctor\" en el sitio web de fotos Shutterstock: Tres hombres, dos mayores y blancos. Los sesgos de la IA son los sesgos de su entrenamiento, y si entrenas modelos usando datos sin curar, siempre encontrarás este tipo de sesgos.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png\" class=\"kg-image\" alt=\"Screenshot 2024-05-03 at 15.21.21.png\" loading=\"lazy\" width=\"1740\" height=\"860\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Screenshot-2024-05-03-at-15.21.21.png 1740w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Una forma de mitigar este problema es usar un generador de imágenes de IA para crear imágenes de médicos más jóvenes, médicas mujeres, médicos que son personas de color, y médicos vistiendo scrubs, trajes u otra vestimenta, y luego incluirlas en el entrenamiento. Los datos sintéticos usados de esta manera pueden mejorar el rendimiento del modelo de IA, al menos en relación con alguna norma externa, en lugar de llevar al colapso del modelo. Sin embargo, distorsionar artificialmente las distribuciones de datos de entrenamiento puede crear efectos secundarios no deseados, <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical?ref=jina-ai-gmbh.ghost.io\">como Google descubrió recientemente</a>.</p><h2 id=\"model-distillation\">Destilación de Modelos</h2><p>La <a href=\"https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones/?ref=jina-ai-gmbh.ghost.io\">destilación de modelos</a> es una técnica para entrenar un modelo directamente de otro. Un modelo generativo entrenado —el \"profesor\"— crea tantos datos como sean necesarios para entrenar un modelo \"estudiante\" sin entrenar o menos entrenado.</p><p>Como era de esperar, el modelo \"estudiante\" nunca puede ser mejor que el \"profesor\". A primera vista, parece tener poco sentido entrenar un modelo de esa manera, pero hay beneficios. El principal es que el modelo \"estudiante\" puede ser mucho más pequeño, rápido o eficiente que el \"profesor\", mientras sigue aproximando de cerca su rendimiento.</p><p>La relación entre el tamaño del modelo, los datos de entrenamiento y el rendimiento final es complicada. Sin embargo, en general, todo lo demás siendo igual:</p><ol><li>Un modelo más grande funciona mejor que uno pequeño.</li><li>Un modelo entrenado con más o mejores datos de entrenamiento (o al menos datos de entrenamiento más diversos) funciona mejor que uno entrenado con menos datos o datos de menor calidad.</li></ol><p>Esto significa que un modelo pequeño puede, a veces, funcionar tan bien como uno grande. Por ejemplo, <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>jina-embeddings-v2-base-en</code></a> supera significativamente a muchos modelos mucho más grandes en benchmarks estándar:</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Size in parameters</th>\n<th>MTEB average score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>jina-embeddings-v2-base-en</code></td>\n<td>137M</td>\n<td>60.38</td>\n</tr>\n<tr>\n<td><code>multilingual-e5-base</code></td>\n<td>278M</td>\n<td>59.45</td>\n</tr>\n<tr>\n<td><code>sentence-t5-xl</code></td>\n<td>1240M</td>\n<td>57.87</td>\n</tr>\n</tbody>\n</table>\n\nLa destilación de modelos es una forma de tomar un modelo grande, que cuesta demasiado ejecutar, y usarlo para crear un modelo más pequeño y económico. En todos los casos hay alguna pérdida de rendimiento, pero en los mejores casos puede ser muy pequeña.\n\nDados los costos asociados con modelos de IA muy grandes, estos beneficios son bastante sustanciales. La destilación produce modelos que se ejecutan más rápido, en chips más económicos, con menos memoria y consumiendo menos energía.\n\nAdemás, los modelos grandes pueden aprender patrones notablemente sutiles a partir de datos no curados, patrones que un modelo más pequeño nunca podría aprender de los mismos datos. Un modelo grande puede entonces producir datos de entrenamiento mucho más diversos que aquellos con los que fue entrenado, suficientes para que el modelo más pequeño pueda aprender los mismos patrones sutiles. Una vez que tienes un modelo grande entrenado, puedes usarlo para \"enseñar\" lo que ha aprendido a un modelo más pequeño que nunca podría haberlo aprendido por sí solo. La destilación es, en esos casos, a veces una mejor manera de aprender que usar datos de entrenamiento reales.\n\n## ¿Entonces Todos Vamos al Infierno en una Cesta?\n\nTal vez.\n\nLa buena noticia es que sin una solución al colapso del modelo, probablemente no podremos entrenar una IA superinteligente capaz de acabar con la humanidad, al menos no con los métodos que hemos estado usando. Podemos volver tranquilamente a preocuparnos por el cambio climático y la guerra nuclear.\n\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Si el párrafo anterior sonó sarcástico, es a propósito.</div></div>\n\nPara la industria de la IA, el panorama no es tan optimista. El lema del machine learning ha sido durante mucho tiempo \"<a href=\"https://towardsdatascience.com/ai-ml-practicalities-the-unreasonable-effectiveness-of-data-c0bfd44c5057?ref=jina-ai-gmbh.ghost.io\">más datos son mejores datos</a>.\" (A veces: \"No hay datos como más datos\".) <a href=\"https://towardsdatascience.com/ai-ml-practicalities-more-data-isnt-always-better-ae1dac9ad28f?ref=jina-ai-gmbh.ghost.io\">Los estadísticos saben que esto es incorrecto</a>. El sentido común dice que esto es incorrecto. Pero es una estrategia que ha estado funcionando para los investigadores de IA durante mucho tiempo, al menos desde que comencé como investigador en traducción automática a principios de los 2000.\n\nHay razones para esto. Los *datos diversos* — datos que incluyen muchas posibilidades diferentes — son una fuente de entrenamiento mucho mejor que los datos uniformes. Y, en la práctica, en el mundo real, más datos generalmente significa datos más diversos.\n\nPero nos estamos quedando sin nuevas fuentes de datos buenos y diversos, y es poco probable que la creación de nuevas obras hechas por humanos se mantenga al ritmo de la generación de IA. De una manera u otra, eventualmente tendremos que cambiar la forma en que entrenamos los modelos de IA. De lo contrario, podríamos alcanzar un umbral de rendimiento que ya no podamos superar. Esto transformaría la industria, ya que el enfoque cambiaría de construir y ejecutar modelos más grandes y costosos a desarrollar marcos, contextos y nichos en los que los modelos existentes pueden aportar nuevo valor añadido.\n\n## Cómo Jina AI Entrena sus Modelos de IA\n\nEn Jina AI, tratamos de brindar a nuestros usuarios los beneficios de las mejores prácticas de IA. Aunque no producimos LLMs generadores de texto ni generadores de imágenes de IA, aún nos preocupa el problema del colapso del modelo. Usamos subconjuntos del <a href=\"https://commoncrawl.org/?ref=jina-ai-gmbh.ghost.io\">Common Crawl</a> para la mayor parte de nuestro pre-entrenamiento y luego usamos datos curados y sintéticos para optimizar el rendimiento de nuestros modelos. Nos esforzamos por llevar un rendimiento de vanguardia a modelos rentables y embeddings compactos de baja dimensionalidad.\n\nSin embargo, el colapso del modelo es un problema inevitable para los datos de Common Crawl. Esperamos hacer una transición con el tiempo para usar más datos curados y menos del Common Crawl. Esperamos que otros actores de la industria de la IA hagan lo mismo. Esto tendrá costos — tanto en términos de dinero como de tasa de mejora de calidad — pero es demasiado pronto para tratar de estimarlos.\n\nUsamos datos sintéticos en áreas donde los modelos de embedding tienen problemas conocidos. Por ejemplo, los modelos de IA luchan por representar la negación. \"Recetas con carne\" y \"recetas sin carne\" típicamente tienen embeddings que están muy cerca entre sí, pero los usuarios a menudo necesitan que estén muy separados. Nuestro mayor uso de datos sintéticos es crear un gran corpus de pares de oraciones generadas por IA distinguidas por ese tipo de negación (llamada *polaridad* en IA y algunos tipos de lingüística), y luego usarlo para mejorar nuestros modelos.\n\nPor ejemplo, a continuación hay una proyección 2D de embeddings hipotéticos. \"Recetas con carne\" y \"Recetas sin carne\" están relativamente cerca entre sí. \"Hamburguesa con queso y tocino\" está mucho más cerca de \"Recetas con carne\" que de cualquier otra cosa, y \"Falafel\" está más cerca de \"Recetas sin carne\" que de \"Recetas con carne\". Sin embargo, \"Hamburguesa con queso y tocino\" está mucho más cerca de \"Recetas sin carne\" que \"Falafel\".\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png\" class=\"kg-image\" alt=\"Una proyección 2D de embeddings hipotéticos.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--61-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--61-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Una proyección 2D de embeddings hipotéticos.</span></figcaption></figure>\n\nMirando únicamente los embeddings, podríamos concluir que las hamburguesas con queso y tocino son un mejor ejemplo de una receta sin carne que el falafel.\n\nPara evitar esto, entrenamos nuestros modelos con datos sintéticos. Usamos un LLM para generar pares de oraciones con polaridades opuestas – como \"X con Y\" / \"X sin Y\" – y entrenamos nuestros modelos de embedding para separar esos pares. También usamos datos sintéticos para otros tipos de <a href=\"https://finetuner.jina.ai/advanced-topics/negative-mining/?ref=jina-ai-gmbh.ghost.io\">negative mining</a> focalizado, una colección de técnicas utilizadas para mejorar aspectos específicos del rendimiento del modelo de IA presentándole datos curados.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png\" class=\"kg-image\" alt=\"Una proyección 2D de embeddings hipotéticos después de mejorar el modelo subyacente.\" loading=\"lazy\" width=\"649\" height=\"579\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/05/Untitled--62-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/05/Untitled--62-.png 649w\"><figcaption><span style=\"white-space: pre-wrap;\">Una proyección 2D de embeddings hipotéticos después de mejorar el modelo subyacente con pares de oraciones de polaridad invertida.</span></figcaption></figure>\n\nTambién usamos IA generativa para entrenar <a href=\"https://jina.ai/news/elevate-your-code-search-with-new-jina-code-embeddings/?ref=jina-ai-gmbh.ghost.io\">modelos de embedding para lenguajes de programación</a>, aprovechando los grandes modelos que generan abundantes ejemplos de código, para que podamos incrustar correctamente incluso características bastante oscuras de lenguajes y frameworks específicos.\n\nLa destilación de modelos es clave para cómo producimos <a href=\"https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny?ref=jina-ai-gmbh.ghost.io\">modelos compactos que ahorran recursos informáticos</a>. La destilación es mucho más eficiente y confiable que el entrenamiento desde cero, y nuestros resultados muestran que un modelo destilado aún puede tener un rendimiento de primera calidad. La tabla a continuación muestra los modelos reranker destilados de Jina AI en comparación con el reranker base usado para entrenarlos y con otros modelos con muchos más parámetros pero peor rendimiento.\n\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Model</th>\n<th>BEIR Score</th>\n<th>Parameter count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td><code>jina-reranker-v1-base-en</code></td>\n<td>52.45</td>\n<td>137M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-turbo-en</code></td>\n<td>49.60</td>\n<td>38M</td>\n</tr>\n<tr style=\"background: rgb(50, 50, 50)\">\n<td>Distilled</td>\n<td><code>jina-reranker-v1-tiny-en</code></td>\n<td>48.54</td>\n<td>33M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-base-v1</code></td>\n<td>49.19</td>\n<td>184M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>mxbai-rerank-xsmall-v1</code></td>\n<td>48.80</td>\n<td>71M</td>\n</tr>\n<tr>\n<td></td>\n<td><code>bge-reranker-base</code></td>\n<td>47.89</td>\n<td>278M</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n\nSabemos que la IA puede ser una inversión costosa y que las empresas son cada vez más conscientes de sus obligaciones morales y legales para reducir las emisiones de carbono. Nosotros también somos conscientes de esas cosas. La destilación de modelos es una gran parte de cómo abordamos esas preocupaciones.\n\n## Permítanos Ayudarle a Navegar por la IA\n\nJina AI está comprometida a brindar a las empresas soluciones de IA asequibles, eficientes y funcionales. Podemos integrarnos con su infraestructura en la nube existente en <a href=\"https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions?ref=jina-ai-gmbh.ghost.io\">Azure</a> y <a href=\"https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker?ref=jina-ai-gmbh.ghost.io\">AWS</a>. Proporcionamos <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">APIs web</a> que mantienen estrictos estándares de seguridad y privacidad y no conservan sus datos para nuestro propio entrenamiento. Podemos ayudarlo a instalar nuestros <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">modelos de código abierto</a> en su propio hardware, manteniendo toda su operación internamente.\n\nPuede ser difícil separar el bombo publicitario de la tecnología y mantenerse al día con las mejores prácticas en este campo que cambia rápidamente. Permítanos hacer eso por usted.",
  "comment_id": "6639e8e1af8f52000115be49",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-05-07T10:40:01.000+02:00",
  "updated_at": "2024-07-08T21:10:35.000+02:00",
  "published_at": "2024-05-07T16:00:26.000+02:00",
  "custom_excerpt": "AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let’s find out!",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "6342c5b4393501004d1c8b2c",
      "name": "Insights",
      "slug": "insights",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "6342c5b4393501004d1c8b2c",
    "name": "Insights",
    "slug": "insights",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/insights/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/",
  "excerpt": "¡La IA creando IA! ¿Es el fin del mundo? ¿O simplemente otra herramienta para que los modelos realicen trabajo de valor agregado? ¡Descubrámoslo!",
  "reading_time": 12,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract depiction of a brain in purple and pink hues with a fluid, futuristic design against a blue and purple background.",
  "feature_image_caption": null
}