{
  "slug": "jina-embeddings-v3-a-frontier-multilingual-embedding-model",
  "id": "66ea352ab0c14d00013bc7f1",
  "uuid": "778aadf1-0767-4842-ad7a-1658ce18179a",
  "title": "Jina Embeddings v3：最先端の多言語埋め込みモデル",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v3 · Hugging Face</div><div class=\"kg-bookmark-description\">私たちは、オープンソースとオープンサイエンスを通じて人工知能を進歩させ、民主化する旅を続けています。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v3.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jina-embeddings-v3: Task LoRA を用いた多言語エンベディング</div><div class=\"kg-bookmark-description\">5.7 億パラメータを持つ新しいテキストエンベディングモデル jina-embeddings-v3 を紹介します。多言語データと長文脈検索タスクで最先端の性能を達成し、最大 8192 トークンのコンテキスト長をサポートします。このモデルには、クエリ文書検索、クラスタリング、分類、テキストマッチングのための高品質なエンベディングを生成するタスク特化型の Low-Rank Adaptation (LoRA) アダプターが含まれています。さらに、Matryoshka 表現学習を学習プロセスに組み込むことで、性能を損なうことなくエンベディング次元の柔軟な切り捨てが可能になっています。MTEB ベンチマークでの評価では、jina-embeddings-v3 は英語タスクで OpenAI や Cohere の最新の独自エンベディングを上回り、すべての多言語タスクで multilingual-e5-large-instruct を上回る性能を達成しています。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Saba Sturua</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>本日、5.7 億パラメータを持つ最先端のテキストエンベディングモデル <code>jina-embeddings-v3</code> の発表を嬉しくお知らせします。**多言語**データと**長文脈**検索タスクで最高性能を達成し、最大 8192 トークンの入力長をサポートします。このモデルは、タスク特化型の Low-Rank Adaptation (LoRA) アダプターを備え、**クエリ文書検索**、**クラスタリング**、**分類**、**テキストマッチング**など様々なタスクで高品質なエンベディングを生成することができます。</p><p>MTEB English、Multilingual、LongEmbed での評価において、<code>jina-embeddings-v3</code> は英語タスクで OpenAI と Cohere の最新の独自エンベディングを上回り、すべての多言語タスクで <code>multilingual-e5-large-instruct</code> を凌駕しています。デフォルトの出力次元は 1024 ですが、Matryoshka 表現学習（MRL）の統合により、性能を損なうことなく任意に 32 次元まで切り捨てることができます。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-English-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Chart comparing the performance of various NLP tools on MTEB English Tasks, with scores ranging from 60 to 65.5, displayed on\" loading=\"lazy\" width=\"920\" height=\"240\"><figcaption><span style=\"white-space: pre-wrap;\">MTEB 英語タスク全体における </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> と他のエンベディングモデルの性能比較。タスクごとの詳細な評価結果は</span><a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">arXiv 論文</span></a><span style=\"white-space: pre-wrap;\">をご覧ください。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/MTEB-Multilingual-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Graph depicting MTEB Multilingual Tasks Performance, comparing multilingual embeddings and 'jina embeddings' versions with sc\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\"> </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> の性能は、幅広い多言語および言語横断的な MTEB タスクで評価されています。なお、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2-(zh/es/de)</span></code><span style=\"white-space: pre-wrap;\"> は当社の二言語モデルスイートを指し、中国語、スペイン語、ドイツ語の単一言語および言語横断タスクのみでテストされ、他の言語は除外されています。また、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>openai-text-embedding-3-large</span></code><span style=\"white-space: pre-wrap;\"> と </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>cohere-embed-multilingual-v3.0</span></code><span style=\"white-space: pre-wrap;\"> のスコアは、これらのモデルが多言語および言語横断的な MTEB タスク全体で評価されていないため、報告していません。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/LongEmbed-MTEB-Long-Document-Retrieval-Tasks-Performance.svg\" class=\"kg-image\" alt=\"Bar graph showing performance of different embeddings on long document retrieval tasks with scores for various libraries.\" loading=\"lazy\" width=\"920\" height=\"219\"><figcaption><span style=\"white-space: pre-wrap;\">LongEmbed ベンチマークの 6 つの長文書検索タスクにおける </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> の性能は、他のモデルと比べて大幅な改善を示しています。スコアは nDCG@10 で、高いほど良好です。これは、私たちの RoPE ベースの位置エンベディングの有効性を示しており、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>baai-bge-m3</span></code><span style=\"white-space: pre-wrap;\"> が使用する固定位置エンベディングと </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\"> が使用する ALiBi ベースのアプローチの両方を上回っています。</span></figcaption></figure><p>2024 年 9 月 18 日のリリース時点で、<code>jina-embeddings-v3</code> は**最高**の多言語モデルであり、10 億パラメータ未満のモデルの中で MTEB 英語リーダーボードで**2 位**にランクされています。v3 は合計 89 言語をサポートし、そのうち 30 言語で最高の性能を発揮します：アラビア語、ベンガル語、中国語、デンマーク語、オランダ語、英語、フィンランド語、フランス語、グルジア語、ドイツ語、ギリシャ語、ヒンディー語、インドネシア語、イタリア語、日本語、韓国語、ラトビア語、ノルウェー語、ポーランド語、ポルトガル語、ルーマニア語、ロシア語、スロバキア語、スペイン語、スウェーデン語、タイ語、トルコ語、ウクライナ語、ウルドゥー語、ベトナム語。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-2.png\" class=\"kg-image\" alt=\"Leaderboard table comparing language models across various performance metrics with highlighted rankings, set on a dark, prof\" loading=\"lazy\" width=\"2000\" height=\"899\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">2024 年 9 月 18 日のリリース時点で、5.7 億パラメータと 1024 の出力次元を持つ </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> は、10 億パラメータ未満の最も効率的で強力、信頼性の高い多言語エンベディングモデルとなっています。</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg\" class=\"kg-image\" alt=\"Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu\" loading=\"lazy\" width=\"949\" height=\"949\"><figcaption><span style=\"white-space: pre-wrap;\">エンベディングモデルのスケーリング則。英語タスクでの平均 MTEB 性能をモデルパラメータ数に対してプロットしています。各ドットは一つのエンベディングモデルを表します。全モデルのトレンドラインが示されており、多言語モデルはシアン色で強調されています。</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code><span style=\"white-space: pre-wrap;\"> は、同規模のモデルと比較して優れた性能を示し、前身の </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v2</span></code><span style=\"white-space: pre-wrap;\"> に対して超線形的な改善を示しています。このグラフは、MTEB リーダーボードからトップ 100 のエンベディングモデルを選択し、サイズ情報のないもの（通常はクローズドソースまたは独自モデル）を除外して作成されました。明らかなトロールと判断された投稿も除外されています。</span></figcaption></figure><p>さらに、最近注目を集めている LLM ベースのエンベディング（例：<code>e5-mistral-7b-instruct</code>）と比較すると、パラメータサイズが 71 億（12 倍大きい）で出力次元が 4096（4 倍大きい）にもかかわらず、MTEB 英語タスクでの改善がわずか 1% であるのに対し、<code>jina-embeddings-v3</code> はより費用対効果の高いソリューションであり、本番環境やエッジコンピューティングにより適しています。</p><h2 id=\"model-architecture\">モデルアーキテクチャ</h2>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>機能</th>\n<th>説明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base</td>\n<td><code>jina-XLM-RoBERTa</code></td>\n</tr>\n<tr>\n<td>基本パラメータ数</td>\n<td>559M</td>\n</tr>\n<tr>\n<td>LoRA使用時のパラメータ数</td>\n<td>572M</td>\n</tr>\n<tr>\n<td>最大入力トークン数</td>\n<td>8192</td>\n</tr>\n<tr>\n<td>最大出力次元数</td>\n<td>1024</td>\n</tr>\n<tr>\n<td>レイヤー数</td>\n<td>24</td>\n</tr>\n<tr>\n<td>語彙数</td>\n<td>250K</td>\n</tr>\n<tr>\n<td>対応言語数</td>\n<td>89</td>\n</tr>\n<tr>\n<td>アテンション</td>\n<td>FlashAttention2、非使用時も動作可能</td>\n</tr>\n<tr>\n<td>プーリング</td>\n<td>Mean pooling</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><code>jina-embeddings-v3</code> のアーキテクチャは以下の図に示されています。バックボーンアーキテクチャを実装するために、<code>XLM-RoBERTa</code> モデルに以下の重要な修正を加えました：(1) 長文テキストシーケンスの効果的なエンコーディングの実現、(2) タスク固有のエンベッディングエンコーディングの許可、(3) 最新の技術による全体的なモデル効率の改善。元の <code>XLM-RoBERTa</code> トークナイザーは引き続き使用しています。<code>jina-embeddings-v3</code> は 570 ミリオンのパラメータを持ち、137 ミリオンの <code>jina-embeddings-v2</code> よりも大きいものの、LLM からファインチューニングされたエンベッディングモデルと比べるとはるかに小さいものとなっています。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Heading--26-.svg\" class=\"kg-image\" alt=\"Flowchart mapping sentiment classification. Begins with \"Downstream Task: sentiment = classify\" and includes stages like \"Mea\" loading=\"lazy\" width=\"1160\" height=\"618\"><figcaption><span style=\"white-space: pre-wrap;\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-embeddings-v3</span></code> のアーキテクチャは </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-XLM-RoBERTa</span></code><span style=\"white-space: pre-wrap;\"> モデルをベースとし、4 つの異なるタスクに対して 5 つの LoRA アダプターを使用しています。</span></figcaption></figure><p><code>jina-embeddings-v3</code> の主要な革新点は LoRA アダプターの使用です。<strong>4</strong> つのタスクに対して <strong>5</strong> つのタスク固有の LoRA アダプターが導入されています。モデルの入力は、テキスト（埋め込む長文書）とタスクの 2 つの部分で構成されています。<code>jina-embeddings-v3</code> は 4 つのタスクをサポートし、5 つのアダプターを実装しています：非対称検索タスクにおけるクエリと文書のエンベッディングのための <code>retrieval.query</code> と <code>retrieval.passage</code>、クラスタリングタスクのための <code>separation</code>、分類タスクのための <code>classification</code>、そして STS や対称検索などの意味的類似性を含むタスクのための <code>text-matching</code> です。LoRA アダプターは全パラメータの 3% 未満を占めるだけで、計算に対する負荷は最小限に抑えられています。</p><p>さらなるパフォーマンス向上とメモリ消費の削減のために、FlashAttention 2 の統合、アクティベーションチェックポイントのサポート、効率的な分散トレーニングのための DeepSpeed フレームワークの使用を行っています。</p><h2 id=\"get-started\">使用開始</h2><h3 id=\"via-jina-ai-search-foundation-api\">Jina AI Search Foundation API 経由</h3><p><code>jina-embeddings-v3</code> を使用する最も簡単な方法は、<a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io#apiform\" rel=\"noreferrer\">Jina AI ホームページ</a>にアクセスし、Search Foundation API セクションに移動することです。本日より、このモデルは新規ユーザー全員のデフォルトとして設定されています。異なるパラメータや機能をそこから直接探索することができます。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/image-3.png\" class=\"kg-image\" alt=\"Screenshot of a dark-themed interface with options like 'Join us', 'Explore', showing 'Start instantly - no credit card or re\" loading=\"lazy\" width=\"2000\" height=\"960\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/09/image-3.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/embeddings \\\n\t -H \"Content-Type: application/json\" \\\n\t -H \"Authorization: Bearer jina_387ced4ff3f04305ac001d5d6577e184hKPgRPGo4yMp_3NIxVsW6XTZZWNL\" \\\n\t -d '{\n\t\"model\": \"jina-embeddings-v3\",\n\t\"task\": \"text-matching\",\n\t\"dimensions\": 1024,\n\t\"late_chunking\": true,\n\t\"input\": [\n\t\t\"Organic skincare for sensitive skin with aloe vera and chamomile: ...\", \n\t\t\"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille: Erleben Sie die wohltuende Wirkung...\", \n\t\t\"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla: Descubre el poder ...\", \n\t\t\"针对敏感肌专门设计的天然有机护肤产品：体验由芦荟和洋甘菊提取物带来的自然呵护。我们的护肤产品特别为敏感肌设计，...\", \n\t\t\"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています: 今シーズンのメイクアップトレンドは、大胆な色彩と革新的な技術に注目しています。...\"\n    ]}'\n</code></pre><p>v2 と比較して、v3 では API に <code>task</code>、<code>dimensions</code>、<code>late_chunking</code> という 3 つの新しいパラメータが導入されました。</p><h4 id=\"parameter-task\">パラメータ <code>task</code></h4><p><code>task</code> パラメータは重要で、下流タスクに応じて設定する必要があります。生成されるエンベッディングはそのタスクに対して最適化されます。詳細については以下のリストを参照してください。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th><strong><code>task</code> の値</strong></th>\n<th><strong>タスクの説明</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>retrieval.passage</code></td>\n<td>クエリ文書検索タスクにおける<b>文書</b>のエンベッディング</td>\n</tr>\n<tr>\n<td><code>retrieval.query</code></td>\n<td>クエリ文書検索タスクにおける<b>クエリ</b>のエンベッディング</td>\n</tr>\n<tr>\n<td><code>separation</code></td>\n<td>文書のクラスタリング、コーパスの可視化</td>\n</tr>\n<tr>\n<td><code>classification</code></td>\n<td>テキスト分類</td>\n</tr>\n<tr>\n<td><code>text-matching</code></td>\n<td><b>(デフォルト)</b> 意味的テキスト類似性、一般的な対称検索、レコメンデーション、類似アイテムの検索、重複排除</td>\n</tr>\n</tbody>\n</table>\n\n<!--kg-card-end: html-->\n<p>API は汎用的なメタエンベッディングを生成してから追加のファインチューニング済み MLP で適応させるのではなく、タスク固有の LoRA アダプターを各トランスフォーマーレイヤー（合計 24 レイヤー）に挿入し、一度でエンコーディングを実行することに注意してください。詳細については<a href=\"https://arxiv.org/abs/2409.10173?ref=jina-ai-gmbh.ghost.io\">arXiv の論文</a>をご覧ください。</p><h4 id=\"parameter-dimensions\">パラメータ <code>dimensions</code></h4><p><code>dimensions</code> パラメータを使用すると、最小のコストでスペース効率とパフォーマンスのトレードオフを選択できます。<code>jina-embeddings-v3</code> で使用される MRL 技術のおかげで、エンベッディングの次元を好きなだけ（1 次元まで！）削減できます。小さなエンベッディングはベクトルデータベースのストレージに優しく、そのパフォーマンスコストは以下の図から推定できます。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/Performance-of-Different-Output-Dimensions.svg\" class=\"kg-image\" alt=\"Scatter plot titled &quot;Performance of Different Output Dimensions&quot; showing performance metrics across increasing MRL dimensions\" loading=\"lazy\" width=\"595\" height=\"513\"></figure><h4 id=\"parameter-latechunking\">パラメータ <code>late_chunking</code></h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/late-chunking-in-long-context-embedding-models/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">長文コンテキストの埋め込みモデルにおける Late Chunking</div><div class=\"kg-bookmark-description\">コンテキスト情報を保持しながら長文書をチャンク分割することは課題です。私たちは、長文コンテキスト埋め込みモデルを活用して文脈を考慮したチャンクエンベッディングを生成する「Late Chunking」を導入しました。これにより、より良い検索アプリケーションが実現できます。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/banner-late-chunking.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>最後に、<code>late_chunking</code> パラメータは、<a href=\"https://arxiv.org/abs/2409.04701?ref=jina-ai-gmbh.ghost.io\">先月導入した</a>文の一括エンコーディングのための新しいチャンク分割方法を使用するかどうかを制御します。<code>true</code> に設定すると、API は <code>input</code> フィールド内のすべての文を連結し、単一の文字列としてモデルに送ります。つまり、<strong>入力内の文は同じセクション、段落、または文書から来たかのように扱われます。</strong>内部的には、モデルはこの長い連結文字列を埋め込み、その後で後処理チャンク分割を行い、入力リストのサイズに一致する埋め込みのリストを返します。したがって、リスト内の各埋め込みは前の埋め込みの影響を受けています。</p><p>ユーザーの観点からは、<code>late_chunking</code> の設定は入力や出力のフォーマットを変更しません。埋め込み値が、個別ではなく前のコンテキスト全体に基づいて計算されるという変化だけが見られます。使用時に知っておくべき重要なことは<code>late_chunking=True</code> の場合、リクエストごとの（<code>input</code> のすべてのトークンを合計した）トークン総数は 8192 に制限されます。これは <code>jina-embeddings-v3</code> で許可される最大コンテキスト長です。<code>late_chunking=False</code> の場合、そのような制限はありません。トークン総数は <a href=\"https://jina.ai/contact-sales?ref=jina-ai-gmbh.ghost.io#faq\">Embedding API のレート制限</a>のみの対象となります。</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png\" width=\"1334\" height=\"1640\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p1.png 1334w\" sizes=\"(min-width: 720px) 720px\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png\" width=\"1148\" height=\"1644\" loading=\"lazy\" alt=\"\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/09/p2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/09/p2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/09/p2.png 1148w\" sizes=\"(min-width: 720px) 720px\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">Late Chunking のオンとオフ：入力と出力のフォーマットは同じままで、埋め込み値のみが異なります。</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>late_chunking</span></code><span style=\"white-space: pre-wrap;\"> が有効な場合、埋め込みは </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>input</span></code><span style=\"white-space: pre-wrap;\"> の前のコンテキスト全体の影響を受けますが、無効な場合は埋め込みは独立して計算されます。</span></p></figcaption></figure><h3 id=\"via-azure-aws\">Azure と AWS 経由</h3><p><code>jina-embeddings-v3</code> は現在、AWS SageMaker と Azure Marketplace で利用可能です。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v3</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3?tab=Overview&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://azuremarketplace.microsoft.com/favicon.ico\" alt=\"\"></div></div></a></figure><p>これらのプラットフォーム以外や、社内のオンプレミスで使用する必要がある場合は、モデルが CC BY-NC 4.0 ライセンスの下で提供されていることにご注意ください。<a href=\"https://jina.ai/contact-sales/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">商用利用については、お気軽にお問い合わせください。</a></p><h3 id=\"via-vector-databases-partners\">ベクトルデータベースとパートナー経由</h3><p>私たちは Pinecone、Qdrant、Milvus などのベクトルデータベースプロバイダーや、LlamaIndex、Haystack、Dify などの LLM オーケストレーションフレームワークと密接に協力しています。リリース時点で、Pinecone、Qdrant、Milvus、Haystack が既に <code>jina-embeddings-v3</code> のサポートを統合しており、<code>task</code>、<code>dimensions</code>、<code>late_chunking</code> という 3 つの新しいパラメータもサポートしていることをお知らせできることを嬉しく思います。<code>v2</code> API との統合を既に完了している他のパートナーも、モデル名を <code>jina-embeddings-v3</code> に変更するだけで <code>v3</code> をサポートできるはずです。ただし、<code>v3</code> で導入された新しいパラメータはまだサポートされていない可能性があります。</p><h4 id=\"via-pinecone\">Pinecone 経由</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-embeddings-v3?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The vector database to build knowledgeable AI | Pinecone</div><div class=\"kg-bookmark-description\">Search through billions of items for similar matches to any object, in milliseconds. It's the next generation of search, an API call away.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mintlify.s3-us-west-1.amazonaws.com/pinecone-2/_generated/favicon/apple-touch-icon.png?v=3\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pinecone.io/images/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-qdrant\">Qdrant 経由</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">logo</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-milvus\">Milvus 経由</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://milvus.io/docs/integrate_with_jina.md?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integrate Milvus with Jina | Milvus Documentation</div><div class=\"kg-bookmark-description\">This guide demonstrates how to use Jina embeddings and Milvus to conduct similarity search and retrieval tasks. | v2.4.x</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-32x32.png\" alt=\"\"><span class=\"kg-bookmark-author\">milvus-logo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/meta_image_milvus_d6510e10e0.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"via-haystack\">Haystack 経由</h4><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI | Haystack</div><div class=\"kg-bookmark-description\">Use the latest Jina AI embedding models</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://haystack.deepset.ai/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Haystack</span><span class=\"kg-bookmark-publisher\">Authors deepset</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">まとめ</h2><p>2023 年 10 月、私たちは <code>jina-embeddings-v2-base-en</code> を公開し、<a href=\"https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai?ref=jina-ai-gmbh.ghost.io\">世界初の 8K コンテキスト長をサポートするオープンソース埋め込みモデル</a>となりました。これは長いコンテキストをサポートし、OpenAI の <code>text-embedding-ada-002</code> に匹敵する<em>唯一</em>のテキスト埋め込みモデルでした。そして今日、1 年間の学習、実験、貴重な教訓を経て、私たちは誇りを持って <code>jina-embeddings-v3</code> をリリースします—これはテキスト埋め込みモデルの新しいフロンティアであり、当社の大きなマイルストーンです。</p><p>このリリースでは、私たちが得意とする<strong>長いコンテキストの</strong><strong>埋め込み</strong>で引き続き優れた成果を上げながら、業界とコミュニティの両方から最も要望の多かった機能である<strong>多言語埋め込み</strong>にも対応しました。同時に、パフォーマンスも新たな高みへと押し上げています。タスク特化型 LoRA、MRL、late chunking など新機能により、<code>jina-embeddings-v3</code> は RAG、エージェントなどのさまざまなアプリケーションの基盤となる埋め込みモデルとして真に機能すると考えています。<code>NV-embed-v1/v2</code> のような最近の LLM ベースの埋め込みと比較して、私たちのモデルは非常にパラメータ効率が高く、本番環境やエッジデバイスにより適しています。</p><p>今後は、リソースの少ない言語での <code>jina-embeddings-v3</code> のパフォーマンスの評価と改善、およびデータの可用性の制限によって引き起こされる体系的な失敗の分析に焦点を当てる予定です。さらに、<code>jina-embeddings-v3</code> のモデルの重み、その革新的な機能、そして新しい知見は、<code>jina-clip-v2</code> を含む今後のモデルの基盤として機能します。<code>jina-reranker-v3</code>、および <code>reader-lm-v2</code>。</p>",
  "comment_id": "66ea352ab0c14d00013bc7f1",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/09/v3banner.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-09-18T04:04:26.000+02:00",
  "updated_at": "2024-10-11T13:58:13.000+02:00",
  "published_at": "2024-09-18T10:37:31.000+02:00",
  "custom_excerpt": "jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v3-a-frontier-multilingual-embedding-model/",
  "excerpt": "jina-embeddings-v3 は、570M パラメータと 8192 トークン長を持つ最先端の多言語テキスト埋め込みモデルで、MTEB において OpenAI や Cohere の最新の商用埋め込みモデルを上回る性能を発揮します。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dynamic image showing the characters \"V3\" formed by bright green dots varying in size on a black background.",
  "feature_image_caption": null
}