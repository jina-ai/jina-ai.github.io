{
  "slug": "jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images",
  "id": "673cc4a7a7c46d00015cf1f5",
  "uuid": "6ca44950-b989-494a-b587-70847f24edd2",
  "title": "Jina CLIP v2：テキストと画像のための多言語マルチモーダル埋め込み",
  "html": "<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-clip-v2 · Hugging Face</div><div class=\"kg-bookmark-description\">オープンソースとオープンサイエンスを通じて、人工知能を進歩させ、民主化する journey を進めています。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-11.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-clip-v2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?sui=&model=jina-clip-v2&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - Your Search Foundation, Supercharged.</div><div class=\"kg-bookmark-description\">最高クラスの embeddings、rerankers、LLM-reader、web scraper、classifiers。多言語およびマルチモーダルデータに最適な検索 AI。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-11.png\" alt=\"\"><span class=\"kg-bookmark-author\">Your Search Foundation, Supercharged.</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a><figcaption><p><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\"> API は「Embeddings」タブで利用可能です。</span></p></figcaption></figure><p>マルチモーダル embeddings は、一貫した表現を通じて異なるモダリティ間でのデータの検索と理解を可能にします。これらはニューラル情報検索とマルチモーダル GenAI アプリケーションの基盤となります。本日、<code>jina-clip-v1</code> と最近リリースした <code>jina-embeddings-3</code> をベースに構築された新しい汎用多言語マルチモーダル embeddings である <code>jina-clip-v2</code> のリリースを発表できることを嬉しく思います。主な改善点は以下の通りです：</p><ul><li><strong>パフォーマンスの向上</strong>：v2 はテキスト-画像およびテキスト-テキスト検索タスクの両方で v1 から 3% のパフォーマンス向上を示しています。v1 と同様に、v2 のテキストエンコーダーは効果的な多言語長文コンテキスト密ベクトル検索器として機能します。現在 MTEB において 1B パラメータ未満で最高の多言語 embeddings である我々のフロンティアモデル <code>jina-embeddings-v3</code> と同等のパフォーマンスを発揮します。</li><li><strong>多言語サポート</strong>：テキストタワーに <code>jina-embeddings-v3</code> を採用することで、<code>jina-clip-v2</code> は 89 言語での多言語-画像検索をサポートし、多言語画像検索タスクにおいて <code>nllb-clip-large-siglip</code> と比較して最大 4% の改善を示しています。</li><li><strong>より高い画像解像度</strong>：v2 は 512x512 の入力画像解像度をサポートし、v1 の 224x224 から大幅に向上しました。この高解像度により、詳細な画像のより良い処理、特徴抽出の改善、細かい視覚要素のより正確な認識が可能になります。</li><li><strong>マトリョーシカ表現</strong>：v2 ではテキストと画像の両方の embeddings の出力次元を 1024 から 64 まで切り詰めることができ、強力なパフォーマンスを維持しながらストレージと処理のオーバーヘッドを削減できます。</li></ul><h2 id=\"model-architecture\">モデルアーキテクチャ</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--35-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"></figure><p><code>jina-clip-v2</code> は 2 つの強力なエンコーダーを組み合わせた 0.9B の CLIP スタイルモデルです：テキストエンコーダー <code>Jina XLM-RoBERTa</code>（<code>jina-embeddings-v3</code> のバックボーン）と、ビジョンエンコーダー <code>EVA02-L14</code>（BAAI が開発した効率的なビジョン Transformer）です。これらのエンコーダーは画像とテキストの aligned な表現を作成するために共同で訓練されています。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Text Encoder</th>\n<th>Image Encoder</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Base Model</td>\n<td>Jina XLM-RoBERTa</td>\n<td>EVA02-L</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>561M</td>\n<td>304M</td>\n</tr>\n<tr>\n<td>Input Specification</td>\n<td>8,192 tokens (max)</td>\n<td>512×512 pixels</td>\n</tr>\n<tr>\n<td>Min Output Dimensions</td>\n<td>64</td>\n<td>64</td>\n</tr>\n<tr>\n<td>Max Output Dimensions</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Layers</td>\n<td>24</td>\n<td>24</td>\n</tr>\n<tr>\n<td>Attention Mechanism</td>\n<td>FlashAttention2</td>\n<td>xFormers</td>\n</tr>\n<tr>\n<td>Pooling Strategy</td>\n<td>Mean pooling</td>\n<td>CLS pooling</td>\n</tr>\n<tr>\n<td>Additional Features</td>\n<td>89 languages supported</td>\n<td>Patch size 14x14</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"cross-modal-retrieval-performance\">クロスモーダル検索性能</h2><p>Jina CLIP v2 は 89 言語をサポートし、アラビア語、中国語、英語、フランス語、ドイツ語、日本語、ロシア語、スペイン語を含む主要言語で優れた性能を発揮します。多言語画像検索ベンチマークでは、わずかに大きな（1.3B、<code>jina-clip-v2</code> より 44% 大きい）最先端の CLIP スタイルモデルで NLLB モデルから事前訓練されたテキストエンコーダーを使用する <a href=\"https://huggingface.co/visheratin/nllb-clip-large-siglip?ref=jina-ai-gmbh.ghost.io\">NLLB-CLIP-SigLIP</a> と同等かそれ以上の性能を示しています。</p><h3 id=\"english-only-text-and-images\">英語のみのテキストと画像</h3><p>標準的なクロスモーダル検索ベンチマーク（Flickr30k と COCO）において、<code>jina-clip-v2</code> は全体的に大きな改善を示しています。Flickr30k の画像からテキストへの検索で 98.0% という最先端の性能を達成し、前身モデルと NLLB-CLIP-SigLIP の両方を上回りました。このモデルは、COCO の画像からテキストへの検索で v1 から最大 3.3% の改善を示すなど、すべての検索シナリオで一貫した向上を見せており、さまざまなベンチマークとモダリティの方向性において NLLB-CLIP-SigLIP と競争力のある性能を維持しています。</p><p><strong>Flickr30k Recall@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>98.0</td>\n<td>+1.7%</td>\n<td>+0.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>96.4</td>\n<td>-</td>\n<td>-0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>97.1</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>89.8</td>\n<td>+0.9%</td>\n<td>-2.6%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>89.0</td>\n<td>-</td>\n<td>-3.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>92.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>COCO Recall@5 性能：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Image-to-text</td>\n<td>jina-clip-v2</td>\n<td>81.5</td>\n<td>+3.3%</td>\n<td>+2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>78.9</td>\n<td>-</td>\n<td>-0.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>79.2</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Text-to-image</td>\n<td>jina-clip-v2</td>\n<td>68.4</td>\n<td>+2.9%</td>\n<td>-3.4%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>66.5</td>\n<td>-</td>\n<td>-6.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>70.8</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"multilingual-text-and-images\">多言語テキストと画像</h3><p>多言語クロスモーダルベンチマークにおいて、<code>jina-clip-v2</code> は堅固な性能を示し、特に画像からテキストへの検索で優れており、すべてのデータセットで NLLB-SigLIP を上回り、Crossmodal 3600 で最大 +3.8% の改善を達成しています。NLLB-SigLIP はテキストから画像への検索でわずかに強い性能を示していますが、性能差は通常 3% 以内と小さいものにとどまっています。</p><p><strong>画像からテキストへの Recall@5 パフォーマンス：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>83.23</td>\n<td>+3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>80.16</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>86.03</td>\n<td>+0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.37</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.98</td>\n<td>+0.7%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>85.41</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p><strong>テキストから画像への Recall@5 パフォーマンス：</strong></p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Benchmark</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to NLLB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Crossmodal 3600</td>\n<td>jina-clip-v2</td>\n<td>81.43</td>\n<td>-0.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>82.07</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Multilingual MS Coco</td>\n<td>jina-clip-v2</td>\n<td>84.87</td>\n<td>-3.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.60</td>\n<td>-</td>\n</tr>\n<tr>\n<td>XTD10</td>\n<td>jina-clip-v2</td>\n<td>85.03</td>\n<td>-3.0%</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>87.63</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"text-only-dense-retriever-performance\">テキストのみの Dense Retriever パフォーマンス</h2><p>前バージョンと同様に、<code>jina-clip-v2</code> のテキストエンコーダーは効果的な多言語 Dense Retriever として機能します。包括的な Multilingual MTEB ベンチマークにおいて、検索で 69.86%、意味的類似性タスクで 67.77% という強力なパフォーマンスを達成しています。これらの結果は、専用のテキスト埋め込みモデル <code>jina-embeddings-v3</code> と競争力のある汎用性を示しています：</p><table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>69.86</td>\n<td>-3.8%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>72.59</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Semantic Similarity</td>\n<td>jina-clip-v2</td>\n<td>67.77</td>\n<td>-2.9%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-embeddings-v3</td>\n<td>69.81</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p>英語タスクにおいて、<code>jina-clip-v2</code> は前バージョンと NLLB-SigLIP の両方に対して一貫した改善を示しており、特に検索パフォーマンスでは NLLB-SigLIP のスコアのほぼ 2 倍という大きな優位性を示しています。</p><table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Model</th>\n<th>Score</th>\n<th>Relative to v1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>STS</td>\n<td>jina-clip-v2</td>\n<td>81.29</td>\n<td>+0.5%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>80.92</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>74.65</td>\n<td>-</td>\n</tr>\n<tr>\n<td>Retrieval</td>\n<td>jina-clip-v2</td>\n<td>49.33</td>\n<td>+2.1%</td>\n</tr>\n<tr>\n<td></td>\n<td>jina-clip-v1</td>\n<td>48.33</td>\n<td>-</td>\n</tr>\n<tr>\n<td></td>\n<td>nllb-siglip-large</td>\n<td>24.92</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"matryoshka-representation-performance\">マトリョーシカ表現のパフォーマンス</h2><p>テキストと画像のエンコーダーはともに MRL をサポートしており、強力なパフォーマンスを維持しながら出力次元を 64 まで切り詰めることができます。埋め込みの切り詰め評価では、顕著な圧縮の可能性が明らかになりました。75% という積極的な次元削減を行っても、テキスト、画像、クロスモーダルタスクにわたって 99% 以上のパフォーマンスを維持しました。</p><h3 id=\"image-classification\">画像分類</h3><p>37 の多様な画像分類ベンチマークにおいて、画像エンコーダーは次元の切り詰めに対して強い耐性を示しています。1024 から 64 次元への圧縮（94% の削減）でも、top-5 精度で 8%、top-1 で 12.5% の低下に留まり、パフォーマンスの損失を最小限に抑えた効率的な展開の可能性を示しています。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/accuracy_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption>**画像分類**については、<a href=\"https://github.com/google-research/task_adaptation?ref=jina-ai-gmbh.ghost.io\">VTAB データセット</a>の19のベンチマーク、<a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/?ref=jina-ai-gmbh.ghost.io\">VOC 2007</a>、<a href=\"https://www.tensorflow.org/datasets/catalog/sun397?ref=jina-ai-gmbh.ghost.io\">SUN397</a>、<a href=\"https://cs.stanford.edu/~acoates/stl10/?ref=jina-ai-gmbh.ghost.io\">STL10</a>、<a href=\"https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md?ref=jina-ai-gmbh.ghost.io\">Rendered SST2</a>、<a href=\"https://objectnet.dev/?ref=jina-ai-gmbh.ghost.io\">ObjectNet</a>、<a href=\"https://github.com/cvdfoundation/mnist?ref=jina-ai-gmbh.ghost.io\">MNIST</a>、ドイツ交通標識認識ベンチマーク（<a href=\"https://benchmark.ini.rub.de/gtsrb_dataset.html?ref=jina-ai-gmbh.ghost.io\">GTSRB</a>）、航空機の細粒度視覚分類（<a href=\"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/?ref=jina-ai-gmbh.ghost.io\">FGVC-Aircraft</a>）、<a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge?ref=jina-ai-gmbh.ghost.io\">FER 2013</a>、<a href=\"https://github.com/openai/CLIP/blob/main/data/country211.md?ref=jina-ai-gmbh.ghost.io\">Country211</a>、<a href=\"https://www.tensorflow.org/datasets/catalog/cars196?ref=jina-ai-gmbh.ghost.io\">Cars196</a>、<a href=\"https://github.com/hendrycks/natural-adv-examples?ref=jina-ai-gmbh.ghost.io\">ImageNet-A、ImageNet-O</a>、<a href=\"https://huggingface.co/datasets/ILSVRC/imagenet-1k?ref=jina-ai-gmbh.ghost.io\">ImageNet1k</a>、<a href=\"https://github.com/HaohanWang/ImageNet-Sketch?ref=jina-ai-gmbh.ghost.io\">ImageNet Sketch</a>、および<a href=\"https://imagenetv2.org/?ref=jina-ai-gmbh.ghost.io\">ImageNet v2</a>を使用しました。</figcaption></figure><h3 id=\"cross-modal-retrieval\">クロスモーダル検索</h3><p>次元数を 94% 削減して 64 次元にしたにもかかわらず、切り詰められた画像とテキストの埋め込みを使用したクロスモーダル検索は非常に堅牢で、画像からテキストへの性能の 93%、テキストから画像への性能の 90% を維持しました。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/crossmodal_performance--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"><figcaption>6つのベンチマークを使用し、そのうち3つは多言語対応です：<a href=\"https://google.github.io/crossmodal-3600/?ref=jina-ai-gmbh.ghost.io\">Crossmodal-3600</a>（36言語）、<a href=\"https://shannon.cs.illinois.edu/DenotationGraph/?ref=jina-ai-gmbh.ghost.io\">flickr30k</a>（英語のみ）、<a href=\"https://hockenmaier.cs.illinois.edu/8k-pictures.html?ref=jina-ai-gmbh.ghost.io\">flickr8k</a>（英語のみ）、<a href=\"https://arxiv.org/abs/1504.00325?ref=jina-ai-gmbh.ghost.io\">MS COCO Captions</a>（英語のみ）、<a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\">Multilingual MS COCO Captions</a>（10言語）、<a href=\"https://github.com/LAION-AI/CLIP_benchmark?ref=jina-ai-gmbh.ghost.io\">XTD 200</a>（27言語）</figcaption></figure><h3 id=\"text-only-retrieval\">テキストのみの検索</h3><p>**英語のみの MTEB ベンチマーク**において、1024 次元から圧縮された 64 次元のテキスト埋め込みは、意味的類似性を極めて良好に保持し、わずか 2.1% の低下にとどまり、検索性能は 17.5% の適度な低下を示しました。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/mteb_performance.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"947\" height=\"954\"></figure><h2 id=\"getting-started\">はじめ方</h2><h3 id=\"via-api\">API 経由</h3><p>このコードは Python の <code>requests</code> を使用して埋め込みを生成する方法を示しています。base64 画像または URL を含むテキスト文字列と、希望する次元サイズ（デフォルトは 1024、以下では 768 として表示）を渡します。</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-Python\">import requests\nimport numpy as np\nfrom numpy.linalg import norm\n\ncos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n\nurl = 'https://api.jina.ai/v1/embeddings'\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Authorization': 'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'\n}\n\ndata = {\n  'input': [\n     {\"text\": \"Bridge close-shot\"},\n     {\"url\": \"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s\"}],\n  'model': 'jina-clip-v2',\n  'encoding_type': 'float',\n  'dimensions': '768' \n}\n\nresponse = requests.post(url, headers=headers, json=data)\nsim = cos_sim(np.array(response.json()['data'][0]['embedding']), np.array(response.json()['data'][1]['embedding']))\nprint(f\"Cosine text&lt;-&gt;image: {sim}\")</code></pre><figcaption><p>&lt;YOUR_JINA_AI_API_KEY&gt; を有効な Jina API キーに置き換えることを忘れないでください。<a href=\"https://jina.ai/?sui=apikey&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">ここから 100 万の無料トークンを含む無料の API キーを取得できます。</a></p></figcaption></figure><h3 id=\"image-tokens-pricing\">画像トークンの価格設定</h3><p>当社の API はテキストと画像の両方のトークンをカウントします。画像の場合、トークンの消費は画像全体をカバーするために必要な 512x512 ピクセルのタイル数に基づいています。各タイルの処理には 4,000 トークンが必要で、部分的に埋まったタイルも含みます。**コスト効率を最適化するために、API ユーザーはリクエストを送信する前に画像を 512x512 にリサイズすることをお勧めします。**</p><table>\n<thead>\n<tr>\n<th>画像解像度</th>\n<th>必要なタイル数</th>\n<th>トークンコスト</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>512x512</td>\n<td>1</td>\n<td>4,000</td>\n</tr>\n<tr>\n<td>720x720</td>\n<td>4</td>\n<td>16,000</td>\n</tr>\n<tr>\n<td>1080x1080</td>\n<td>9</td>\n<td>36,000</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--37-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\"><figcaption>正方形の画像の場合、コスト効率を最適化するために 512x512 にリサイズしてください。アスペクト比が重要なタスクの場合、最長辺を 512 にスケーリングし、画像を中央に配置して黒で埋めてください。一般的な用途では、直接 512x512 にリサイズすることで十分です。</figcaption></figure><h3 id=\"via-csp-marketplaces\">CSP マーケットプレイス経由</h3><p>Jina CLIP v2 は AWS、Azure、GCP で直接利用可能で、それぞれのプラットフォームに記載された価格で提供されています。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-bfbctuqmky676?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina CLIP v2</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-10.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/socialPreview-2.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Microsoft Azure Marketplace</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-9.ico\" alt=\"\"></div></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://console.cloud.google.com/marketplace/browse?q=jina&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Cloud console</div><div class=\"kg-bookmark-description\">Google Cloud Marketplace で賢明な支出、迅速な調達、Google Cloud の支出を管理できます。Google Cloud で実行するように最適化された 2000 以上の SaaS、VM、開発スタック、Kubernetes アプリのカタログを閲覧できます。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/default.png\" alt=\"\"></div></div></a></figure><h3 id=\"via-vectordb\"><strong>VectorDB 経由</strong></h3><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.pinecone.io/models/jina-clip-v2?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">知識豊富な AI を構築するためのベクトルデータベース | Pinecone</div><div class=\"kg-bookmark-description\">数十億のアイテムから、任意のオブジェクトに類似する一致を数ミリ秒で検索できます。次世代の検索が API 呼び出し一つで実現できます。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-3.png\" alt=\"\"><span class=\"kg-bookmark-author\">Pinecone Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/docs_og_image.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://weaviate.io/developers/weaviate/model-providers/jinaai/embeddings-multimodal?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">マルチモーダル埋め込み | Weaviate</div><div class=\"kg-bookmark-description\">Weaviate と Jina AI の API の統合により、Weaviate から直接モデルの機能にアクセスできます。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-12.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Weaviate</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/provider_integrations_jinaai.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/embeddings/jina-embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina Embeddings - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant は Rust で書かれたオープンソースのベクトルデータベースとベクトル検索エンジンです。使いやすい API を備えた、高速でスケーラブルなベクトル類似性検索サービスを提供します。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-4.png\" alt=\"\"><span class=\"kg-bookmark-author\">edit</span><span class=\"kg-bookmark-publisher\">Qdrant</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-social-preview-1.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"conclusion\">結論</h2><p>6 月にリリースした <code>jina-clip-v1</code>（OpenAI の CLIP モデルを拡張して最大 8,192 トークンのテキスト入力に対応）と最先端の多言語モデル <code>jina-embeddings-v3</code> を基に、<code>jina-clip-v2</code> は 3 つの主要な進歩をもたらします：89 言語の多言語サポート、512x512 の高解像度画像対応、そして切り詰められた埋め込みのためのマトリョーシカ表現学習です。</p><p>CLIP のようなモデルは、汎用的なマルチモーダルアプリケーションのバックボーンとして確立されています。<code>jina-clip-v2</code> では、これらの機能を次のレベルに引き上げ、言語の壁を取り払い、より正確なクロスモーダルな理解と検索を実現します。このリリースは、マルチモーダル検索と検索を世界中の開発者にとってより強力でアクセスしやすいものにするという約束を果たすものだと私たちは信じています。</p>",
  "comment_id": "673cc4a7a7c46d00015cf1f5",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/11/clipv2.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-11-19T18:02:31.000+01:00",
  "updated_at": "2024-11-21T17:29:45.000+01:00",
  "published_at": "2024-11-21T17:29:45.000+01:00",
  "custom_excerpt": "Jina-CLIP v2, a 0.9B multimodal embedding model with multilingual support of 89 languages, high image resolution at 512x512, and Matryoshka representations.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/",
  "excerpt": "89言語のマルチリンガルサポート、512x512 の高解像度画像対応、および Matryoshka 表現を備えた 0.9B のマルチモーダル埋め込みモデル、Jina-CLIP v2。",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}