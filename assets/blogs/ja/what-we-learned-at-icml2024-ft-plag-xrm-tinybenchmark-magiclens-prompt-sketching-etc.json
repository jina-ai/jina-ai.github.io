{
  "slug": "what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc",
  "id": "66b38ec355fd850001d38602",
  "uuid": "bb41601d-e964-48b4-aa27-0796b2b6591d",
  "title": "ICML2024 で学んだこと ─ PLaG、XRM、tinyBenchmark、MagicLens、Prompt Sketching などを特集",
  "html": "<p><a href=\"https://icml.cc/?ref=jina-ai-gmbh.ghost.io\">International Conference on Machine Learning</a> は、機械学習および人工知能コミュニティにおける最も権威のある会議の一つで、今年は7月21日から27日までウィーンで2024年の会議が開催されました。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/image-1.png\" class=\"kg-image\" alt=\"Interior of a bustling academic conference hall with many attendees, some carrying backpacks, and research posters displayed \" loading=\"lazy\" width=\"2000\" height=\"956\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image-1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/08/image-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>会議は7日間の集中的な学習経験で、口頭発表や他の研究者と直接意見交換する機会がありました。強化学習、ライフサイエンスのための AI、表現学習、マルチモーダルモデル、そしてもちろん AI モデル開発の中核要素において、多くの興味深い研究が行われています。特に重要だったのは、<a href=\"https://huggingface.co/collections/zhuzeyuan/physics-of-language-models-series-6615c5247dc4e8388b2a846f?ref=jina-ai-gmbh.ghost.io\">Physics of Large Language Models</a> に関するチュートリアルで、LLM の内部動作を詳しく探り、LLM が情報を記憶しているのか、それとも発言時に推論を適用しているのかという疑問に説得力のある答えを提供しました。</p><h2 id=\"our-work-on-jina-clip-v1\">Jina-CLIP-v1 に関する私たちの研究</h2><p>私たちは、ワークショップ「<a href=\"https://icml.cc/virtual/2024/workshop/29957?ref=jina-ai-gmbh.ghost.io\">Multi-modal Foundation Models meet Embodied AI</a>」の一環として、新しいマルチモーダルモデル <code>jina-clip-v1</code> の<a href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\">研究</a>について<a href=\"https://jina-ai-gmbh.ghost.io/content/files/2024/08/Jina_CLIP_Poster_ICML.pdf\" rel=\"noreferrer\">ポスター発表</a>を行いました。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2405.20204?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class=\"kg-bookmark-description\">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Andreas Koukounas</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\"></div></a></figure><p>様々な分野で働く国際的な同僚たちと会い、議論することは非常に刺激的でした。私たちの発表は多くの好意的なフィードバックを得て、Jina CLIP がマルチモーダルとユニモーダルの対照学習パラダイムを統合する方法に多くの人々が興味を示しました。議論は CLIP アーキテクチャの限界から、追加のモダリティへの拡張、さらにはペプチドやタンパク質のマッチングへの応用まで及びました。</p><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster.mp4\" poster=\"https://img.spacergif.org/v1/1138x640/0a/spacer.png\" width=\"1138\" height=\"640\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/08/Jina_MG_ICML_poster_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">3:09</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p><span style=\"white-space: pre-wrap;\">Michael Günther が Jina CLIP を発表</span></p></figcaption>\n        </figure><h2 id=\"our-favorites\">私たちのお気に入り</h2><p>他の研究者のプロジェクトや発表について多くの議論を行う機会があり、以下がその中でのお気に入りです：</p><h3 id=\"plan-like-a-graph-plag\">Plan Like a Graph (PLaG)</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Lin, F., La Malfa, E., Hofmann, V., Yang, E. M., Cohn, A., & Pierrehumbert, J. B. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Graph-Enhanced Large Language Models in Asynchronous Plan Reasoning.</em></i> <a href=\"https://arxiv.org/abs/2402.02805?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.02805</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/HNumeUKs6P8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Fangru Lin: An Easy Trick To Improve Your LLM Results\"></iframe></figure><p>多くの人が「Few-Shot Prompting」や「Chain of Thought prompting」を知っています。<a href=\"https://www.linkedin.com/in/fangru-lin-oxford/?ref=jina-ai-gmbh.ghost.io\">Fangru Lin</a> は ICML で新しい、より良い手法を発表しました：<em>Plan Like a Graph (PLaG)</em>。</p><p>彼女のアイデアはシンプルです：LLM に与えられたタスクを、LLM が並列または順次的に解決できるサブタスクに分解します。これらのサブタスクが実行グラフを形成します。グラフ全体を実行することで、高レベルのタスクが解決されます。</p><p>上の動画で、Fangru Lin は分かりやすい例を使ってその手法を説明しています。この改善は結果を向上させますが、タスクの複雑さが増すと LLM の性能は依然として大幅に低下することに注意してください。とはいえ、これは正しい方向への大きな一歩であり、即座に実用的なメリットをもたらします。</p><p>私たちにとって、彼女の研究が <a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> でのプロンプトアプリケーションと類似していることは興味深いです。私たちはすでにグラフのようなプロンプト構造を実装していますが、彼女が行ったような実行グラフを動的に生成することは、これから探求する新しい方向性です。</p><h3 id=\"discovering-environments-with-xrm\">XRM による環境の発見</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Pezeshki, M., Bouchacourt, D., Ibrahim, M., Ballas, N., Vincent, P., & Lopez-Paz, D. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Discovering Environments with XRM</em></i>. <a href=\"https://arxiv.org/abs/2309.16748?ref=jina-ai-gmbh.ghost.io\">arXiv:2309.16748</a></div></div><p>この論文は、ラベルと相関する特徴に依存しながらも、正確な分類・関連性を導かない特徴にモデルが依存してしまう訓練環境を発見するためのシンプルなアルゴリズムを提案しています。有名な例として、waterbirds データセット（<a href=\"https://arxiv.org/abs/1911.08731?ref=jina-ai-gmbh.ghost.io\">arXiv:1911.08731</a> 参照）があります。これは、水鳥か陸鳥かに分類される、さまざまな背景の鳥の写真を含んでいます。トレーニング中、分類器は鳥自体の特徴ではなく、画像の背景に水があるかどうかを検出してしまいます。このようなモデルは、背景に水がない場合に水鳥を誤分類してしまいます。</p><p>この振る舞いを緩和するには、モデルが誤解を招く背景の特徴に依存しているサンプルを検出する必要があります。この論文は、それを行うための XRM アルゴリズムを提案しています。</p><p>このアルゴリズムは、トレーニングデータセットの異なる2つの部分で2つのモデルを訓練します。トレーニング中、一部のサンプルのラベルが反転します。具体的には、他のモデル（それぞれのサンプルでトレーニングされていないモデル）が異なる分類をした場合に発生します。この方法で、モデルは見かけの相関に依存することを促されます。その後、モデルの1つによって予測されたラベルが正解と異なるトレーニングデータからサンプルを抽出できます。これらの情報は後で、例えば <a href=\"https://github.com/kohpangwei/group_DRO?ref=jina-ai-gmbh.ghost.io\">Group DRO アルゴリズム</a> を使用して、よりロバストな分類モデルを訓練するために使用できます。</p><h3 id=\"cut-your-llm-evaluation-costs-by-a-factor-of-140\">LLM の評価コストを 140 分の 1 に削減！</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Maia Polo, F., Weber, L., Choshen, L., Sun, Y., Xu, G., & Yurochkin, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">tinyBenchmarks: evaluating LLMs with Fewer Examples</em></i>. <a href=\"https://arxiv.org/abs/2402.14992?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.14992</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/qnW-hp6IYHs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Felipe Maia Polo: Cut Your LLM Evaluation Costs by A Factor of 140!\"></iframe></figure><p>はい、その通りです。このトリックで、LLM の評価コストを極めて小さな割合にまで削減できます。</p><p>コアとなるアイデアはシンプルです：同じモデル機能をテストする評価サンプルをすべて削除するのです。背後にある数学はそれほど単純ではありませんが、ポスターセッションで発表した <a href=\"https://www.linkedin.com/in/felipemaiapolo/?ref=jina-ai-gmbh.ghost.io\">Felipe Maia Polo</a> が分かりやすく説明しています。140 分の 1 への削減は、人気のある MMLU データセット（Massive Multitask Language Understanding）に適用された場合の結果であることに注意してください。あなた独自の評価データセットでは、サンプルの評価結果がどの程度相関しているかによって異なります。多くのサンプルをスキップできる場合もあれば、ほんの少しだけの場合もあります。</p><p>とにかく試してみてください。<a href=\"https://www.linkedin.com/company/jinaai/?ref=jina-ai-gmbh.ghost.io\">Jina AI</a> で評価サンプルをどの程度削減できたか、追ってお知らせします。</p><h3 id=\"contrasting-multiple-representations-with-the-multi-marginal-matching-gap\">Multi-Marginal Matching Gap による複数表現の対比</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Piran, Z., Klein, M., Thornton, J., & Cuturi, M. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</em></i>. <a href=\"https://arxiv.org/abs/2405.19532?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.19532</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png\" class=\"kg-image\" alt=\"Research paper diagram illustrating Multi-Marginal Matching Gap concepts, with titles, descriptions, and flow charts in blue \" loading=\"lazy\" width=\"1346\" height=\"752\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.25.png 1346w\" sizes=\"(min-width: 720px) 720px\"></figure><p>この研究は対照学習における一般的な課題に取り組んでいます：InfoNCE 損失のような多くの対照損失関数は、データポイントのペアで動作し、正のペア間の距離を測定します。サイズ k > 2 の正のタプルに拡張するために、対照学習は通常、問題を複数のペアに縮小し、すべての正のペアについてペアごとの損失を累積しようとします。著者らは、Multi-Marginal Optimal Transport 問題を解決する Sinkhorn アルゴリズムの修正版である M3G（Multi-Marginal Matching Gap）損失を提案しています。この損失関数は、サイズ k > 2 の正のタプルからなるデータセット（例えば、同じオブジェクトの >2 枚の画像、3つ以上のモダリティを持つマルチモーダル問題、あるいは同じ画像の3つ以上の拡張を持つ SimCLR 拡張）のシナリオで使用できます。実験結果は、この手法がペアへの単純な縮小よりも優れていることを示しています。</p><h3 id=\"no-need-for-ground-truth\">Ground Truth は必要なし！</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Robertson, Z., Cha, H., Sheha, A., & Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Implementability of Information Elicitation Mechanisms with Pre-Trained Language Models</em></i>. In <i><em class=\"italic\" style=\"white-space: pre-wrap;\">ICML 2024 Workshop on Theoretical Foundations of Foundation Models</em></i>. URL <a href=\"https://openreview.net/forum?id=QqMnRGlRJk&ref=jina-ai-gmbh.ghost.io\">https://openreview.net/forum?id=QqMnRGlRJk</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hj9fiPpp7TQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Zachary Robertson: No Need for Ground Truth!\"></iframe></figure><p><a href=\"https://www.linkedin.com/in/zrobertson466920/?ref=jina-ai-gmbh.ghost.io\">Zachary Robertson</a>（<a href=\"https://www.linkedin.com/company/stanford-university/?ref=jina-ai-gmbh.ghost.io\">Stanford University</a>）が、ラベル付きデータなしで LLM を評価する研究を発表しました。これは理論的な研究ですが、高度な AI システムのスケーラブルな監視に大きな可能性を持っています。カジュアルな LLM ユーザーのためのものではありませんが、LLM の評価に取り組んでいる場合は、必ず検討すべきものです。私たちは、Jina AI のエージェントをこの方法で評価できることをすでに認識しています。最初の実験結果が出たら共有する予定です。</p><h3 id=\"is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data\">モデル崩壊は避けられないのか？実データと合成データの蓄積による再帰の呪いの打破</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., & Koyejo, S. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</em></i>. <a href=\"https://arxiv.org/abs/2404.01413?ref=jina-ai-gmbh.ghost.io\">arXiv:2404.01413</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png\" class=\"kg-image\" alt=\"Illustration of two machine learning data processes: &quot;Replace Data&quot; and &quot;Accumulate Data&quot;, with detailed flowcharts and model\" loading=\"lazy\" width=\"1661\" height=\"916\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Untitled--88-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Untitled--88-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/Untitled--88-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Untitled--88-.png 1661w\" sizes=\"(min-width: 720px) 720px\"></figure><p>最近、複数の記事（この<a href=\"https://www.nature.com/articles/s41586-024-07566-y?ref=jina-ai-gmbh.ghost.io\"><em>Nature</em>の論文</a>など）が、Web からクロールされたトレーニングデータに合成データが増加しているため、新しく訓練されたモデルのパフォーマンスが時間とともに悪化する可能性があると予測しています。</p><p>我々の同僚の Scott Martens も<a href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\">モデル崩壊に関する記事</a>を公開し、合成データがモデルトレーニングに有用なケースについて議論しています。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/when-ai-makes-ai-synthetic-data-model-distillation-and-model-collapse/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">When AI Makes AI: Synthetic Data, Model Distillation, And Model Collapse</div><div class=\"kg-bookmark-description\">AI creating AI! Is it the end of the world? Or just another tool to make models do value-adding work? Let's find out!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/05/image--20-.png\" alt=\"\"></div></a></figure><p>モデルのトレーニングは、トレーニングデータが同じデータで訓練された以前のバージョンのモデルまたはモデルによって生成された場合に崩壊する可能性があります。この論文では、実験を通じて少し異なる見方を示しています：崩壊が起こるのは、以前の実験で行われたように実データを合成データで<em>置き換える</em>場合のみです。しかし、実データに合成データを<em>追加</em>する場合、結果として得られるモデルのパフォーマンスに測定可能な変化はありません。これらの結果は、モデル崩壊は起こらないことを示唆しています。ただし、追加の合成データを使用しても、その合成データポイントを作成するために使用されたモデルよりも一般的に優れたモデルを訓練することはできないことが再度証明されました。</p><h3 id=\"brain-surgery-for-ai-is-now-possible\">AI の脳外科手術が可能に</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Singh, S., Ravfogel, S., Herzig, J., Aharoni, R., Cotterell, R., & Kumaraguru, P. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Representation Surgery: Theory and Practice of Affine Steering</em></i>. <a href=\"https://arxiv.org/abs/2402.09631?ref=jina-ai-gmbh.ghost.io\">arXiv:2402.09631</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/UFYbpl5wAXs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Shashwat Singh Shauli: Brain Surgery for AI Is Now Possible\"></iframe></figure><p>誰かの職業を予測したいが、性別は予測したくない場合を考えてみましょう。Google Research、ETH Zürich、International Institute of Information Technology Hyderabad (IIITH)、Bar-Ilan University によるこの研究は、ステアリングベクトルと共分散マッチングを使用してバイアスを制御する方法を示しています。</p><h3 id=\"magiclensself-supervised-image-retrieval-with-open-ended-instructions\">MagicLens - オープンエンド指示による自己教師あり画像検索</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Zhang, K., Luan, Y., Hu, H., Lee, K., Qiao, S., Chen, W., Su, Y., & Chang, M.-W. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</em></i>. <a href=\"https://arxiv.org/abs/2403.19651?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.19651</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png\" class=\"kg-image\" alt=\"Interactive slide showing MagicLens tool for visually guided navigation with tasks like identifying buildings and comparing h\" loading=\"lazy\" width=\"894\" height=\"610\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.30.49.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.30.49.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>この論文は、クエリ画像 + 指示 + ターゲット画像の三つ組みで訓練された自己教師あり画像検索モデルである MagicLens モデルを紹介しています。</p><p>著者らは、Web から画像ペアを収集し、LLM を使用して単なる視覚的類似性を超えた多様な意味的関係で画像をリンクするオープンエンドなテキスト指示を合成するデータ収集/キュレーションパイプラインを導入しています。このパイプラインは、広範な分布にわたって 36.7M の高品質な三つ組みを生成するために使用されます。このデータセットは、共有パラメータを持つシンプルなデュアルエンコーダアーキテクチャを訓練するために使用されます。バックボーンのビジョンおよび言語エンコーダは、CoCa または CLIP base および large バリアントで初期化されます。2 つのマルチモーダル入力を単一の埋め込みに圧縮するために、単一のマルチヘッド注意プーラーが導入されます。トレーニング目的は、単純な InfoNCE 損失を用いて MagicLens を訓練するために、クエリ画像と指示のペアをターゲット画像と空の文字列指示と対比させます。著者らは指示ベースの画像検索に関する評価結果を提示しています。</p><h3 id=\"prompt-sketchingthe-new-way-of-prompting\">Prompt Sketching - プロンプトの新しい方法</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Beurer-Kellner, L., Müller, M. N., Fischer, M., & Vechev, M. (2023). Prompt Sketching for Large Language Models. <a href=\"https://arxiv.org/abs/2311.04954?ref=jina-ai-gmbh.ghost.io\">arXiv:2311.04954</a></div></div><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ZH_Se7De4-E?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"ICML: Mark Müller: A New Prompting Paradigm\"></iframe></figure><p>LLM へのプロンプトの方法が変化しています。Prompt Sketching は、生成モデルに固定の制約を与えることを可能にします。単に指示を提供してモデルが望む通りに動作することを期待するのではなく、完全なテンプレートを定義し、モデルに望む内容を生成させることができます。</p><p>これを構造化された JSON 形式を提供するように微調整された LLM と混同しないでください。微調整アプローチでは、モデルは依然として望むものを自由に生成できます。Prompt Sketching ではそうではありません。これはプロンプトエンジニアに完全に新しいツールボックスを提供し、探求が必要な研究分野を開拓します。上記の動画で、Mark Müller がこの新しいパラダイムについて詳しく説明しています。</p><p><a href=\"https://lmql.ai/?ref=jina-ai-gmbh.ghost.io\">彼らのオープンソースプロジェクト LMQL</a> もチェックできます。</p><h3 id=\"repoformerselective-retrieval-for-repository-level-code-completion\">Repoformer - リポジトリレベルのコード補完のための選択的検索</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Wu, D., Ahmad, W. U., Zhang, D., Ramanathan, M. K., & Ma, X. (2024). <i><em class=\"italic\" style=\"white-space: pre-wrap;\">Repoformer: Selective Retrieval for Repository-Level Code Completion</em></i>. <a href=\"https://arxiv.org/abs/2403.10059?ref=jina-ai-gmbh.ghost.io\">arXiv:2403.10059</a></div></div><p>多くのクエリにおいて、クエリが簡単すぎるか、検索システムが関連文書を見つけられない（おそらく存在しないため）場合、RAG は実際にはモデルの助けになりません。これは、モデルが誤解を招くまたは存在しないソースに依存する場合、生成時間が長くなりパフォーマンスが低下することにつながります。</p><p>この論文は、LLM が検索が有用かどうかを自己評価できるようにすることでこの問題に対処しています。コードテンプレートのギャップを埋めるように訓練されたコード補完モデルでこのアプローチを実証しています。与えられたテンプレートに対して、システムはまず検索結果が有用かどうかを判断し、有用な場合は検索を呼び出します。最後に、コード LLM は検索結果がそのプロンプトに追加されているかどうかにかかわらず、欠けているコンテキストを生成します。</p><h3 id=\"the-platonic-representation-hypothesis\">プラトン的表現仮説</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Huh, M., Cheung, B., Wang, T., & Isola, P. (2024). The Platonic Representation Hypothesis. <a href=\"https://arxiv.org/abs/2405.07987?ref=jina-ai-gmbh.ghost.io\">arXiv:2405.07987</a></div></div><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png\" class=\"kg-image\" alt=\"Illustration of &quot;The Platonic Representation Hypothesis&quot; with geometric shapes, mathematical text, and diagrams explaining a \" loading=\"lazy\" width=\"1250\" height=\"942\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/Screenshot-2024-08-01-at-18.29.51_wide.png 1250w\" sizes=\"(min-width: 720px) 720px\"></figure><p><em>プラトン的表現仮説</em>は、ニューラルネットワークモデルが世界の共通の表現に収束する傾向があると主張しています。<a href=\"https://en.wikipedia.org/wiki/Theory_of_forms?ref=jina-ai-gmbh.ghost.io\">プラトンのイデア論</a>から、私たちが間接的にしか観察できない歪んだ形で現れる「理想」の領域が存在するという考えを借用し、著者らは AI モデルが、トレーニングアーキテクチャ、トレーニングデータ、さらには入力モダリティに関係なく、単一の現実表現に収束するように見えると主張しています。データスケールとモデルサイズが大きくなるほど、それらの表現はより類似してくるように見えます。</p><p>著者たちはベクトル表現を考察し、カーネルアラインメント指標を用いて表現の整列を測定しています。具体的には、2つのカーネル K1 と K2 によって誘導される k-近傍集合の平均交差を k で正規化した相互最近傍指標を使用しています。本研究では、モデルとデータセットのサイズが大きくなり性能が向上するにつれて、カーネル間の整列がより強くなることを実証的に示しています。この整列は、テキストモデルと画像モデルのような異なるモダリティのモデルを比較する場合でも観察することができます。</p><h2 id=\"summary\">まとめ</h2><p>スケーリング則に対する当初の熱狂は少し落ち着きを見せ始めていますが、ICML 2024 では、多くの新しい、多様で創造的な人材が私たちの分野に参入していることが示され、進歩がまだまだ続くことを確信できます。</p><p>ICML 2024 は素晴らしい経験となり、2025年にはまた戻ってくることを約束します 🇨🇦。</p>",
  "comment_id": "66b38ec355fd850001d38602",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/icml-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-08-07T17:12:03.000+02:00",
  "updated_at": "2024-08-07T20:10:20.000+02:00",
  "published_at": "2024-08-07T19:09:51.000+02:00",
  "custom_excerpt": "We had a blast at ICML 2024 in Vienna, and we want to share with you everything we said, saw, and learned.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "649c184c30b65b0001166d70",
      "name": "Florian Hönicke",
      "slug": "florian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
      "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
      "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
    },
    {
      "id": "636409b554b68a003dfbdef8",
      "name": "Michael Günther",
      "slug": "michael",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg",
      "cover_image": null,
      "bio": "ML Scientist and Engineer @ Jina AI. Enthusiastic about open source and AI with particular interest in solving information retrieval problems.",
      "website": "https://github.com/guenthermi",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    },
    {
      "id": "66b3979c55fd850001d3869d",
      "name": "Georgios Mastrapas",
      "slug": "george",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/profile.jpg",
      "cover_image": null,
      "bio": null,
      "website": null,
      "location": "Athens, Greece",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/george/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "63340e5387b80b004db80543",
      "name": "Events",
      "slug": "events",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
    }
  ],
  "primary_author": {
    "id": "649c184c30b65b0001166d70",
    "name": "Florian Hönicke",
    "slug": "florian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/florian-small.png",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/06/IMG_7893.jpg",
    "bio": "Principal Engineer at Jina working on prompts.\nEx. Soundcloud ",
    "website": "https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/florian/"
  },
  "primary_tag": {
    "id": "63340e5387b80b004db80543",
    "name": "Events",
    "slug": "events",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/events/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc/",
  "excerpt": "ウィーンで開催された ICML 2024 は素晴らしい経験となり、私たちが話し、見て、学んだすべてのことを皆様と共有したいと思います。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Two logos on gray background: upper \"ICML International Conference on Machine Learning,\" lower abstract \"vibo\" logo.",
  "feature_image_caption": null
}