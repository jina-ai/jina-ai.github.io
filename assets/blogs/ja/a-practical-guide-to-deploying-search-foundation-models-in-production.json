{
  "slug": "a-practical-guide-to-deploying-search-foundation-models-in-production",
  "id": "679b56ba42b46600019a86e3",
  "uuid": "458c0de5-aedb-4513-8ffd-47c027d204ad",
  "title": "実践的な検索基盤モデルの本番環境へのデプロイメントガイド",
  "html": "<p>Jina AI では、企業ユーザーに高品質な検索ソリューションを提供することをミッションとしています。そのために、様々なチャネルを通じてモデルにアクセスできるようにしています。しかし、特定のユースケースに最適なチャネルを選択するのは難しい場合があります。この投稿では、意思決定プロセスについて説明し、トレードオフを分析して、ユーザープロファイルとニーズに基づいて検索基盤モデルにアクセスする最適な方法について実践的なガイダンスを提供します。</p><h2 id=\"jina-search-foundation-models\">Jina 検索基盤モデル</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Our Search Foundation Models</div><div class=\"kg-bookmark-description\">We've been moving the needle in search models since day one. Take a look at our model evolution below—hover or click to discover each milestone.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-18.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Jina AI</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/banner-models.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>私たちの検索基盤モデルには以下が含まれます：</p><ul><li><strong>Embeddings</strong>：デジタルオブジェクトの情報を embedding ベクトルに変換し、その本質的な特徴を捉えます。</li><li><strong>Rerankers</strong>：クエリとドキュメントのセットの詳細な意味分析を行い、検索の関連性を向上させます。</li><li><strong>Small language models</strong>：HTML2Markdown や情報抽出などのニッチなタスク向けの専門的な SLM として <code>ReaderLM-v2</code> などがあります。</li></ul><p>この投稿では、<code>jina-embeddings-v3</code> の異なるデプロイメントオプションを検討し、3つの主要なアプローチを比較します：</p><ul><li><a href=\"https://jina.ai/api-dashboard\" rel=\"noreferrer\">Jina API</a> の使用</li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS SageMaker</a> などの CSP を介したデプロイ</li><li><a href=\"https://jina.ai/api-dashboard/license-config\">商用ライセンス</a>での Kubernetes クラスターでのセルフホスティング</li></ul><p>この比較では、各アプローチのコストへの影響とメリットを評価し、ニーズに最も適したオプションを判断するのに役立てます。</p><h2 id=\"key-performance-metrics\">主要なパフォーマンス指標</h2><p>様々な使用シナリオにおいて、5つの重要なパフォーマンス指標を評価しました：</p><ul><li><strong>リクエスト成功率</strong>：embedding サーバーへのリクエストの成功率</li><li><strong>リクエストレイテンシー</strong>：embedding サーバーがリクエストを処理して返すまでの時間</li><li><strong>トークン処理量</strong>：embedding サーバーが1秒間に処理できるトークン数</li><li><strong>トークンあたりのコスト</strong>：テキスト単位あたりの総処理コスト</li></ul><p>Kubernetes クラスターでセルフホストされた Jina embeddings については、<em>ダイナミックバッチング</em>の影響も調査しました。この機能は、最大バッチサイズ（<code>jina-embeddings-v3</code> では 8,192）に達するまでリクエストをキューに入れてから embeddings を生成します。</p><p>分析から意図的に除外した2つの重要なパフォーマンス要因があります：</p><ul><li><em>オートスケーリング</em>：これは変動するワークロードを持つクラウドデプロイメントにとって重要ですが、その効果はハードウェアの効率性、ネットワークアーキテクチャ、レイテンシー、実装の選択など、多くの変数に依存します。この複雑さは現在の範囲を超えています。<strong>Jina API には自動スケーリングが含まれており、結果にはこれが反映されています。</strong></li><li><em>量子化</em>：この技術は小さな embedding ベクトルを作成しデータ転送を削減しますが、主な利点はデータ転送の削減ではなく、他のシステムコンポーネント（データストレージとベクトル距離計算）から得られます。モデル使用コストに焦点を当てているため、この分析では量子化を除外しました。</li></ul><p>最後に、総所有コストとトークン/リクエストあたりの費用の両方を考慮して、各アプローチの財務的影響を検討します。</p><h2 id=\"deployment-setup\">デプロイメントのセットアップ</h2><p><code>jina-embeddings-v3</code> について、3つのデプロイメントと使用シナリオを評価しました：</p><h3 id=\"using-the-jina-api\">Jina API の使用</h3><p>すべての Jina AI embedding モデルは <a href=\"https://jina.ai/api-dashboard/embeddings\" rel=\"noreferrer\">Jina API</a> を通じてアクセス可能です。アクセスはプリペイドトークンシステムで動作し、テスト用に100万トークンが無料で提供されます。ドイツのオフィスからインターネット経由で API 呼び出しを行いパフォーマンスを評価しました。</h3><h3 id=\"using-aws-sagemaker\">AWS SageMaker の使用</h3><p>Jina Embeddings v3 は <a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS ユーザー向けに SageMaker を通じて利用可能</a>です。使用には、このモデルへの AWS サブスクリプションが必要です。サンプルコードとして、AWS アカウントで Jina AI モデルをサブスクライブし使用する方法を示す<a href=\"https://github.com/jina-ai/jina-sagemaker/blob/main/notebooks/Real-time%20embedding.ipynb\">ノートブック</a>を提供しています。</p><p>モデルは <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Microsoft Azure</a> や <a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">Google Cloud Platform</a> でも利用可能ですが、テストは AWS に焦点を当てました。他のプラットフォームでも同様のパフォーマンスが期待できます。すべてのテストは <code>us-east-1</code> リージョンの <code>ml.g5.xlarge</code> インスタンスで実行されました。</p><h3 id=\"self-hosting-on-kubernetes\">Kubernetes でのセルフホスティング</h3><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">CC-BY-NC モデルの商用ライセンスを取得するには、まず当社からライセンスを取得する必要があります。<a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">営業チームまでお気軽にご連絡ください。</a></div></div><p><code>SentenceTransformer</code> ライブラリを使用して <a href=\"https://huggingface.co/jinaai/jina-embeddings-v3\">HuggingFace から <code>jina-embeddings-v3</code> をロード</a>する FastAPI アプリケーションを Python で構築しました。アプリには2つのエンドポイントがあります：</p><ul><li><code>/embed</code>：テキスト文を入力として受け取り、その embeddings を返します</li><li><code>/health</code>：基本的なヘルスモニタリングを提供します</li></ul><p>これを <code>us-east-1</code> の <code>g5.xlarge</code> インスタンスを使用して、Amazon の Elastic Kubernetes Service 上の Kubernetes サービスとしてデプロイしました。</p><h4 id=\"with-and-without-dynamic-batching\">ダイナミックバッチングの有無</h4><p>Kubernetes クラスターでのパフォーマンスを2つの構成でテストしました：受信時に各リクエストを即時処理する場合と、ダイナミックバッチングを使用する場合です。ダイナミックバッチングの場合、サービスは <code>MAX_TOKENS</code>（8192）がキューに集まるか、あらかじめ定義された2秒のタイムアウトに達するまで待機してから、モデルを呼び出して embeddings を計算します。このアプローチにより、GPU の利用率が向上し、GPU メモリの断片化が減少します。</p><p>各デプロイメントシナリオで、3つの主要なパラメータを変更してテストを実行しました：</p><ul><li><strong>バッチサイズ</strong>：各リクエストには1、32、または128のテキスト文が embedding 用に含まれます</li><li><strong>文の長さ</strong>：128、512、または1,024トークンを含むテキスト文を使用しました</li><li><strong>同時リクエスト数</strong>：1、5、または10のリクエストを同時に送信しました</li></ul><h2 id=\"benchmark-results\">ベンチマーク結果</h2><p>以下の表は、上記の3つの変数のすべての設定を平均した各使用シナリオの結果の要約です。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>指標</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>セルフホスト<br>バッチング有り</th>\n<th>セルフホスト<br>標準</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>リクエスト成功率</td>\n<td>87.6%</td>\n<td><strong>99.9%</strong></td>\n<td>55.7%</td>\n<td>58.3%</td>\n</tr>\n<tr>\n<td>レイテンシー<br>(秒)</td>\n<td>11.4</td>\n<td>3.9</td>\n<td>2.7</td>\n<td><strong>2.6</strong></td>\n</tr>\n<tr>\n<td>成功率で正規化したレイテンシー<br>(秒)</td>\n<td>13.0</td>\n<td><strong>3.9</strong></td>\n<td>4.9</td>\n<td>4.4</td>\n</tr>\n<tr>\n<td>トークン処理量<br>(トークン/秒)</td>\n<td>13.8K</td>\n<td><strong>15.0K</strong></td>\n<td>2.2K</td>\n<td>2.6K</td>\n</tr>\n<tr>\n<td>ピークトークン処理量<br>(トークン/秒)</td>\n<td><strong>63.0K</strong></td>\n<td>32.2K</td>\n<td>10.9K</td>\n<td>10.5K</td>\n</tr>\n<tr>\n<td>価格<br>(100万トークンあたりUSD)</td>\n<td>$0.02</td>\n<td>$0.07</td>\n<td>$0.32</td>\n<td>$0.32</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"request-success-rate\">リクエスト成功率</h2><p>テストでの成功率は、SageMaker のほぼ完全な99.9%からセルフホストソリューションの56-58%まで幅があり、プロダクションシステムで100%の信頼性を達成することが依然として困難であることを示しています。これには3つの主要な要因があります：</p><ul><li>ネットワークの不安定性により、クラウド環境でも避けられない障害が発生します</li><li>特に GPU メモリのリソース競合により、負荷時にリクエストが失敗します</li><li>システムの健全性を維持するために、必要なタイムアウト制限により一部のリクエストは失敗する必要があります</li></ul><h3 id=\"success-rate-by-batch-size\">バッチサイズ別の成功率</h3><p>セルフホストされた Kubernetes 構成では、大きなバッチサイズが頻繁にメモリ不足エラーを引き起こします。ダイナミックバッチングがない場合、32または128アイテムを含むバッチのすべてのリクエストがこの理由で失敗しました。ダイナミックバッチングを実装しても、大きなバッチの失敗率は依然として著しく高いままでした。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8017-ba56-e35215a76fc4\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8064-ab87-e44fc044673d\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">バッチサイズ</th><th id=\"zt<p\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"kPia\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"wgj>\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"OwMn\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-80e1-b4a8-c6f8a3b03117\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"zt<p\" class=\"\">100%</td><td id=\"kPia\" class=\"\">100%</td><td id=\"wgj>\" class=\"\">97.1%</td><td id=\"OwMn\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8096-93c6-deff80bbeffc\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">32</th><td id=\"zt<p\" class=\"\">86.7%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">50.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr><tr id=\"1847c956-b7d2-80fe-a61d-ea3923f34aac\"><th id=\"FiiK\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"zt<p\" class=\"\">76.2%</td><td id=\"kPia\" class=\"\">99.8%</td><td id=\"wgj>\" class=\"\">24.0%</td><td id=\"OwMn\" class=\"\">0.0%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<p>この問題は自動スケーリングで簡単に解決できますが、ここではその選択肢を検討しませんでした。自動スケーリングは予測不可能なコスト増加につながり、また、利用可能な自動スケーリング設定オプションが非常に多いため、実用的な洞察を提供するのが難しいためです。</p><h3 id=\"success-rate-by-concurrency-level\">同時実行レベル別の成功率</h3><p>同時実行（複数のリクエストを同時に処理する能力）は、セルフホスト型 Kubernetes 構成ではリクエスト成功率に強い影響も一貫した影響も与えませんでした。AWS SageMaker でも、少なくとも同時実行レベル 10 までは、最小限の影響しかありませんでした。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-80a7-9beb-f1ebe6e1e529\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-8011-bcc1-d295e87b8e54\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">Concurrency</th><th id=\"KV|=\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"G@`e\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"[~nZ\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"mHG:\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8041-9a23-c1338c5d3f23\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">1</th><td id=\"KV|=\" class=\"\">93.3%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">57.5%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80eb-86a9-f249c86ddfdf\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">5</th><td id=\"KV|=\" class=\"\">85.7%</td><td id=\"G@`e\" class=\"\">100%</td><td id=\"[~nZ\" class=\"\">58.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80ac-a3ad-eadd81c69cb2\"><th id=\"nRCy\" class=\"simple-table-header-color simple-table-header\">10</th><td id=\"KV|=\" class=\"\">83.8%</td><td id=\"G@`e\" class=\"\">99.6%</td><td id=\"[~nZ\" class=\"\">55.3%</td><td id=\"mHG:\" class=\"\">58.3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h3 id=\"success-rate-by-token-length\">トークン長別の成功率</h3><p>トークン数の多い長いパッセージは、Jina Embedding API と動的バッチング付きの Kubernetes の両方に対して、大きなバッチと同様の影響を与えます：サイズが大きくなるにつれて、失敗率が大幅に上昇します。ただし、動的バッチングのないセルフホストソリューションは大きなバッチでほぼ必ず失敗する一方で、個々の長いパッセージではより良いパフォーマンスを示します。SageMaker に関しては、同時実行とバッチサイズと同様に、パッセージの長さもリクエスト成功率に顕著な影響を与えませんでした。</p>\n<!--kg-card-begin: html-->\n<table id=\"1847c956-b7d2-8003-8d50-eddc36a83d33\" class=\"simple-table\"><thead class=\"simple-table-header\"><tr id=\"1847c956-b7d2-804b-8352-d65d5e6bdd0e\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">Passage Length<br>(tokens)<br></th><th id=\"CDn]\" class=\"simple-table-header-color simple-table-header\">Jina API</th><th id=\"@nCV\" class=\"simple-table-header-color simple-table-header\">SageMaker</th><th id=\"H?G{\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(Dynamic Batching)<br></th><th id=\"]{Mf\" class=\"simple-table-header-color simple-table-header\">Self-Hosted<br>(No Batching)<br></th></tr></thead><tbody><tr id=\"1847c956-b7d2-8011-8a92-d0986d045c79\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">128</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">98.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-809f-b073-fa48e7287c13\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">512</th><td id=\"CDn]\" class=\"\">100%</td><td id=\"@nCV\" class=\"\">99.8%</td><td id=\"H?G{\" class=\"\">66.7%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-8019-9f1f-cefd810c520d\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">1024</th><td id=\"CDn]\" class=\"\">99.3%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">33.3%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr><tr id=\"1847c956-b7d2-80c7-a745-fcdaf408f3d0\"><th id=\"}tQ^\" class=\"simple-table-header-color simple-table-header\">8192</th><td id=\"CDn]\" class=\"\">51.1%</td><td id=\"@nCV\" class=\"\">100%</td><td id=\"H?G{\" class=\"\">29.4%</td><td id=\"]{Mf\" class=\"\">58.3%</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<h2 id=\"request-latency\">リクエストレイテンシー</h2><p>すべてのレイテンシーテストは、同時実行レベル 1、5、10 で 5 回繰り返されました。応答時間は 5 回の試行の平均値です。リクエストスループットは、秒単位の応答時間の逆数に同時実行数を掛けたものです。</p><h3 id=\"jina-api\">Jina API</h3><p>Jina API の応答時間は、同時実行レベルに関係なく、主にバッチサイズの影響を受けます。パッセージの長さもパフォーマンスに影響を与えますが、その影響は単純ではありません。一般的な原則として、より大きなバッチサイズやより長いパッセージのいずれかによってデータ量が多いリクエストは、処理に時間がかかります。</p><h4 id=\"concurrency-1\">同時実行 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>801</td>\n<td>1.25</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>724</td>\n<td>1.38</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>614</td>\n<td>1.63</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1554</td>\n<td>0.64</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1620</td>\n<td>0.62</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2283</td>\n<td>0.44</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4441</td>\n<td>0.23</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5430</td>\n<td>0.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>6332</td>\n<td>0.16</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html--><h4 id=\"concurrency-5\">Concurrency 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>689</td>\n<td>7.26</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>599</td>\n<td>8.35</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>876</td>\n<td>5.71</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1639</td>\n<td>3.05</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2511</td>\n<td>1.99</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4728</td>\n<td>1.06</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2766</td>\n<td>1.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>5911</td>\n<td>0.85</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>18621</td>\n<td>0.27</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10\">Concurrency 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>790</td>\n<td>12.66</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>669</td>\n<td>14.94</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>649</td>\n<td>15.41</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1384</td>\n<td>7.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3409</td>\n<td>2.93</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>8484</td>\n<td>1.18</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3441</td>\n<td>2.91</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>13070</td>\n<td>0.77</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>17886</td>\n<td>0.56</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>個別リクエスト（バッチサイズ 1）の場合：</p><ul><li>レスポンス時間は比較的安定しており、パッセージの長さに関係なく約 600-800ms の範囲を維持</li><li>高い同時実行性（5 または 10 の同時リクエスト）でもリクエストごとのパフォーマンスは大きく低下しない</li></ul><p>大きなバッチ（32 および 128 アイテム）の場合：</p><ul><li>レスポンス時間が大幅に増加し、バッチサイズ 128 では単一リクエストの約 4-6 倍の時間がかかる</li><li>パッセージの長さの影響は、より大きなバッチでより顕著になる</li><li>高い同時実行性（10）と大きなバッチ（128）の組み合わせでは、最も長いパッセージで約 18 秒のレスポンス時間に達する</li></ul><p>スループットについて：</p><ul><li>小さなバッチは一般的に同時リクエストを実行する際により良いスループットを達成</li><li>同時実行性 10 でバッチサイズ 1 の場合、システムは約 15 リクエスト/秒の最高スループットを達成</li><li>より大きなバッチでは一貫してスループットが低下し、いくつかのシナリオでは 1 リクエスト/秒未満に低下</li></ul><h3 id=\"aws-sagemaker\">AWS SageMaker</h3><p>AWS SageMaker のテストは <code>ml.g5.xlarge</code> インスタンスで実行されました。</p><h4 id=\"concurrency-1-1\">Concurrency 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>189</td>\n<td>5.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>219</td>\n<td>4.56</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>221</td>\n<td>4.53</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>377</td>\n<td>2.66</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3931</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>2215</td>\n<td>0.45</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>1120</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>3408</td>\n<td>0.29</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>5765</td>\n<td>0.17</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-1\">Concurrency 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>443</td>\n<td>11.28</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>426</td>\n<td>11.74</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>487</td>\n<td>10.27</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1257</td>\n<td>3.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2245</td>\n<td>2.23</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>4159</td>\n<td>1.20</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2444</td>\n<td>2.05</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>6967</td>\n<td>0.72</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>14438</td>\n<td>0.35</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-1\">Concurrency 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Passage length (in tokens)</th>\n<th>Time to Respond in ms</th>\n<th>Request Throughput (requests/second)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>585</td>\n<td>17.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>602</td>\n<td>16.60</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>687</td>\n<td>14.56</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1650</td>\n<td>6.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>3555</td>\n<td>2.81</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1024</td>\n<td>7070</td>\n<td>1.41</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>3867</td>\n<td>2.59</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>12421</td>\n<td>0.81</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>25989</td>\n<td>0.38</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>Jina API との主な違い：</p><ul><li>基本パフォーマンス：SageMaker は小さなリクエスト（単一アイテム、短いパッセージ）に対して大幅に高速で、Jina の 700-800ms に対して約 200ms</li><li>スケーリング動作：<ul><li>両サービスとも大きなバッチと長いパッセージで速度が低下</li><li>SageMaker は大きなバッチ（128）と長いパッセージ（1024 トークン）でより劇的な速度低下を示す</li><li>高い同時実行性（10）で最大負荷（バッチ 128、1024 トークン）の場合、SageMaker は約 26 秒、Jina は約 18 秒</li></ul></li><li>同時実行性の影響：<ul><li>両サービスともスループットは同時実行性の増加から恩恵を受ける</li><li>両サービスとも同時実行性レベル全体で同様のスループットパターンを維持</li><li>SageMaker は若干高いピークスループット（同時実行数10で17リクエスト/秒 対 15リクエスト/秒）を達成します</li></ul></li></ul><h3 id=\"self-hosted-kubernetes-cluster\">自己ホスト型 Kubernetes クラスター</h3><p>自己ホストのテストは、<code>g5.xlarge</code>インスタンスを使用して<a href=\"https://aws.amazon.com/eks/\">Amazon の Elastic Kubernetes Service</a>で実施されました。</p><h4 id=\"concurrency-1-2\">同時実行数 1：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>バッチサイズ</th>\n<th>パッセージ長（トークン）</th>\n<th>バッチなし時間（ms）</th>\n<th>バッチなしスループット（req/s）</th>\n<th>動的バッチ時間（ms）</th>\n<th>動的バッチスループット（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>416</td>\n<td>2.40</td>\n<td>2389</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>397</td>\n<td>2.52</td>\n<td>2387</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>396</td>\n<td>2.52</td>\n<td>2390</td>\n<td>0.42</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1161</td>\n<td>0.86</td>\n<td>3059</td>\n<td>0.33</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>1555</td>\n<td>0.64</td>\n<td>1496</td>\n<td>0.67</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>2424</td>\n<td>0.41</td>\n<td>2270</td>\n<td>0.44</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-5-2\">同時実行数 5：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>バッチサイズ</th>\n<th>パッセージ長（トークン）</th>\n<th>バッチなし時間（ms）</th>\n<th>バッチなしスループット（req/s）</th>\n<th>動的バッチ時間（ms）</th>\n<th>動的バッチスループット（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>451</td>\n<td>11.08</td>\n<td>2401</td>\n<td>2.08</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>453</td>\n<td>11.04</td>\n<td>2454</td>\n<td>2.04</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>478</td>\n<td>10.45</td>\n<td>2520</td>\n<td>1.98</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>1447</td>\n<td>3.46</td>\n<td>1631</td>\n<td>3.06</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>2867</td>\n<td>1.74</td>\n<td>2669</td>\n<td>1.87</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>4154</td>\n<td>1.20</td>\n<td>4026</td>\n<td>1.24</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h4 id=\"concurrency-10-2\">同時実行数 10：</h4>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>バッチサイズ</th>\n<th>パッセージ長（トークン）</th>\n<th>バッチなし時間（ms）</th>\n<th>バッチなしスループット（req/s）</th>\n<th>動的バッチ時間（ms）</th>\n<th>動的バッチスループット（req/s）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>674</td>\n<td>14.84</td>\n<td>2444</td>\n<td>4.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>605</td>\n<td>16.54</td>\n<td>2498</td>\n<td>4.00</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>601</td>\n<td>16.64</td>\n<td>781*</td>\n<td>12.80</td>\n</tr>\n<tr>\n<td>32</td>\n<td>128</td>\n<td>2089</td>\n<td>4.79</td>\n<td>2200</td>\n<td>4.55</td>\n</tr>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>5005</td>\n<td>2.00</td>\n<td>4450</td>\n<td>2.24</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>7331</td>\n<td>1.36</td>\n<td>7127</td>\n<td>1.40</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">† この異常な結果は、動的バッチングの2秒タイムアウトの副産物です。同時実行数が10で、各リクエストが1024トークンのデータを送信する場合、キューはほぼ即座に満杯になり、バッチングシステムはタイムアウトを待つ必要がありません。より小さなサイズと同時実行数では、タイムアウトを待つ必要があり、自動的に各リクエストに2秒の無駄な時間が追加されます。この種の非線形性は、最適化されていないバッチプロセスでは一般的です。</div></div><p>16,384トークンを超えるリクエストが与えられた場合、自己ホスティングのセットアップは通常メモリ不足のサーバーエラーで失敗しました。これは同時実行レベルに関係なく発生しました。そのため、それ以上のデータでのテストは表示されていません。</p><p>高い同時実行数は応答時間をおおむね線形に増加させました：同時実行数5は1の場合と比べて約5倍の応答時間がかかり、10の場合は10倍かかりました。</p><p>動的バッチングは小さなバッチでは応答時間を約2秒遅くします。これは、バッチングキューが不完全なバッチを処理する前に2秒待つためで予想された結果です。しかし、より大きなバッチサイズでは、応答時間に適度な改善をもたらします。</p><h2 id=\"token-throughput\">トークンスループット</h2><p>トークンスループットは、すべてのプラットフォームでバッチサイズが大きくなり、パッセージ長が長くなり、同時実行レベルが高くなるにつれて増加します。そのため、実際の性能を意味のある形で示すために、高負荷レベルでの結果のみを提示します。</p><p>すべてのテストは同時実行数10で、リクエストあたり16,384トークン、5回のリクエストの平均で実施されました。バッチサイズ32で512トークンのパッセージ、およびバッチサイズ128で128トークンのパッセージという2つの構成をテストしました。総トークン数は両構成で一定です。</p><p>トークンスループット（トークン/秒）：</p><table>\n<thead>\n<tr>\n<th>バッチサイズ</th>\n<th>パッセージ長（トークン）</th>\n<th>Jina API</th>\n<th>SageMaker</th>\n<th>自己ホスト（バッチなし）</th>\n<th>自己ホスト（動的バッチ）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>32</td>\n<td>512</td>\n<td>46K</td>\n<td>28.5K</td>\n<td>14.3K</td>\n<td>16.1K</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>42.3K</td>\n<td>27.6K</td>\n<td>9.7K</td>\n<td>10.4K</td>\n</tr>\n</tbody>\n</table>\n<p>高負荷条件下では、Jina API は代替手段を大きく上回る性能を示し、ここでテストした自己ホストソリューションは大幅に低い性能を示しました。</p><h2 id=\"costs-per-million-tokens\">100万トークンあたりのコスト</h2><p>コストは埋め込みソリューションを選択する際の最も重要な要因と言えるでしょう。AI モデルのコスト計算は複雑になり得ますが、以下に異なるオプションの比較分析を示します：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>サービスタイプ</th>\n<th>100万トークンあたりのコスト</th>\n<th>インフラストラクチャコスト</th>\n<th>ライセンスコスト</th>\n<th>総時間あたりコスト</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jina API</td>\n<td>$0.018-0.02</td>\n<td>N/A</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>SageMaker（米国東部）</td>\n<td>$0.0723</td>\n<td>$1.408/時間</td>\n<td>$2.50/時間</td>\n<td>$3.908/時間</td>\n</tr>\n<tr>\n<td>SageMaker（EU）</td>\n<td>$0.0788</td>\n<td>$1.761/時間</td>\n<td>$2.50/時間</td>\n<td>$4.261/時間</td>\n</tr>\n<tr>\n<td>自己ホスト（米国東部）</td>\n<td>$0.352</td>\n<td>$1.006/時間</td>\n<td>$2.282/時間</td>\n<td>$3.288/時間</td>\n</tr>\n<tr>\n<td>自己ホスト（EU）</td>\n<td>$0.379</td>\n<td>$1.258/時間</td>\n<td>$2.282/時間</td>\n<td>$3.540/時間</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"jina-api-1\">Jina API</h3><p>このサービスは2つの前払いティアを持つトークンベースの価格モデルに従っています：</p><ul><li>10億トークンで$20（100万あたり$0.02）- プロトタイピングと開発に適したエントリーレベルのレート</li><li>110億トークンで$200（100万あたり$0.018）- より大きなボリューム向けの経済的なレート</li></ul><p>これらのトークンは、リーダー、リランカー、ゼロショット分類器を含むJinaの製品スイート全体で使用できることに注目する価値があります。</p><h3 id=\"aws-sagemaker-1\">AWS SageMaker</h3><p>SageMaker の料金は、インスタンスの時間単価とモデルのライセンス料金を組み合わせたものです。<code>ml.g5.xlarge</code> インスタンスの場合:</p><ul><li>インスタンス料金: $1.408/時間 (US East) または $1.761/時間 (EU Frankfurt)</li><li><code>jina-embeddings-v3</code> ライセンス: $2.50/時間</li><li>総時間単価: 地域によって $3.908-$4.261</li></ul><p>平均スループット 15,044 トークン/秒 (54.16M トークン/時間) の場合、100万トークンあたりのコストは $0.0723 から $0.0788 の範囲となります。</p><h3 id=\"self-hosting-with-kubernetes\">Kubernetes によるセルフホスティング</h3><p>セルフホスティングのコストは、インフラの選択によって大きく異なります。AWS EC2 の <code>g5.xlarge</code> インスタンスを例にとると：</p><ul><li>インスタンス料金: $1.006/時間 (US East) または $1.258/時間 (EU Frankfurt)</li><li><code>jina-embeddings-v3</code> ライセンス: $5000/四半期 ($2.282/時間)</li><li>総時間単価: 地域によって $3.288-$3.540</li></ul><p>2,588 トークン/秒 (9.32M トークン/時間) のスループットでは、100万トークンあたりのコストは $0.352-$0.379 となります。時間単価は SageMaker より低いものの、スループットが低いため、トークンあたりのコストは高くなります。</p><p>セルフホスティングに関する重要な考慮事項：</p><ul><li>固定費用（ライセンス、インフラ）は使用量に関係なく発生</li><li>オンプレミスのホスティングでもライセンス料金とスタッフコストが必要</li><li>変動する作業負荷がコスト効率に大きく影響する可能性がある</li></ul><h3 id=\"key-takeaways\">重要なポイント</h3><p>Jina API は、コールドスタート時間を考慮せず、代替案の最適なスループットを想定しても、最もコスト効率の良いソリューションとして浮上します。</p><p>既存の堅牢なインフラを持ち、サーバーの限界費用が最小限である組織では、セルフホスティングが意味を持つかもしれません。また、AWS 以外のクラウドプロバイダーを検討することで、より良い価格を得られる可能性もあります。</p><p>ただし、特に即座に使える解決策を求める中小企業にとっては、Jina API が比類のないコスト効率を提供します。</p><h2 id=\"security-and-data-privacy-considerations\">セキュリティとデータプライバシーに関する考慮事項</h2><p>埋め込みモデルのデプロイメント戦略を選択する際、パフォーマンスとコストの考慮事項に加えて、セキュリティとデータプライバシーの要件が決定的な役割を果たす場合があります。私たちは異なるセキュリティニーズに対応する柔軟なデプロイメントオプションを提供しています：</p><h3 id=\"cloud-service-providers\">クラウドサービスプロバイダー</h3><p><strong>主要なクラウドプロバイダーとすでに連携している企業</strong>向けに、クラウドマーケットプレイスの提供（<a href=\"https://aws.amazon.com/marketplace/pp/prodview-kdi3xkt62lo32\">AWS Marketplace</a>、<a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v3-vm?tab=Overview\">Azure</a>、<a href=\"https://console.cloud.google.com/marketplace/browse?hl=en&amp;inv=1&amp;invt=AboIuQ&amp;q=jina\">GCP</a>）で、既存のセキュリティフレームワーク内でのデプロイメントを自然な形で実現できます。これらのデプロイメントには以下の利点があります：</p><ul><li>CSP との関係からのセキュリティ制御とコンプライアンスの継承</li><li>既存のセキュリティポリシーとデータガバナンスルールとの容易な統合</li><li>既存のデータ処理契約の変更がほとんどまたは全く不要</li><li>既存のデータ主権に関する考慮事項との整合性</li></ul><h3 id=\"self-hosting-and-local-deployment\">セルフホスティングとローカルデプロイメント</h3><p><strong>厳格なセキュリティ要件や特定の規制上の義務を持つ組織</strong>は、インフラの完全な物理的制御を好むことが多いです。セルフホストオプションでは以下が可能です：</p><ul><li>デプロイメント環境の完全な制御</li><li>セキュリティ境界内でのデータ処理</li><li>既存のセキュリティ監視と制御との統合</li></ul><p>CC-BY-NC モデルの商用ライセンスを取得するには、まず当社からライセンスを取得する必要があります。<a href=\"https://jina.ai/api-dashboard/license-config\" rel=\"noreferrer\">販売チームまでお気軽にお問い合わせください。</a></p><h3 id=\"jina-api-service\">Jina API サービス</h3><p><strong>スタートアップや中小企業</strong>向けに、コストとのバランスを取りながらセキュリティと利便性を追求する場合、当社の API サービスは運用上のオーバーヘッドを追加することなく、エンタープライズグレードのセキュリティを提供します：</p><ul><li>堅牢なセキュリティ制御を保証する<a href=\"https://jina.ai/Jina_AI_GmbH_Letter_of_Attestation_SOC_2_Type_1.pdf\" rel=\"noreferrer\">SOC2 認証</a></li><li>データ処理における<a href=\"https://gdpr-info.eu/\" rel=\"noreferrer\">GDPR 完全準拠</a></li><li>ゼロデータ保持ポリシー - リクエストの保存やログ記録を行いません</li><li>暗号化されたデータ送信と安全なインフラ</li></ul><p>Jina AI のモデル提供により、組織は運用効率を維持しながら、セキュリティ要件に最も適したデプロイメント戦略を選択できます。</p><h2 id=\"choosing-your-solution\">ソリューションの選択</h2><p>以下のフローチャートは、これまでに見てきた実証テストとテーブルの結果をまとめたものです：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1256\" height=\"1980\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/01/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/01/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2025/01/image-3.png 1256w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">この情報を踏まえて、上記のフローチャートは、検討すべきソリューションの種類についての良い指標を提供するはずです。</span></figcaption></figure><p>まず、セキュリティニーズと、それを満たすためにどの程度の柔軟性を犠牲にできるかを検討してください。</p><p>次に、企業での AI の使用計画を検討してください：</p><ol><li>バッチ処理を最適に活用できるオフラインインデックスと時間に非敏感なユースケース</li><li>検索拡張生成や LLM 統合のような信頼性とスケーラビリティに敏感な使用</li><li>オンライン検索や検索のような時間に敏感な使用</li></ol><p>また、社内の専門知識と既存のインフラも考慮してください：</p><ol><li>技術スタックはすでにクラウドに大きく依存していますか？</li><li>セルフホストが可能な大規模な社内 IT 運用がありますか？</li></ol><p>最後に、予想されるデータ量を考慮してください。毎日何百万もの AI モデルを使用する大規模なユーザーですか？</p><h2 id=\"conclusion\">結論</h2><p>多くの IT 部門にとって、確立された既成のソリューションが市場に不足しているため、AI を運用上の意思決定に統合することは未開拓の領域のままです。この不確実性は戦略的計画を難しくする可能性があります。私たちの定量的分析は、特定のワークフローやアプリケーションに検索基盤モデルを組み込む具体的なガイダンスを提供することを目的としています。</p><p>単位あたりのコストに関して、Jina API は企業が利用できる最も経済的なオプションの1つとして際立っています。同等の機能を提供しながら、私たちの価格に匹敵する代替案はほとんどありません。</p><p>私たちは、強力で使いやすいだけでなく、あらゆる規模の組織にとってコスト効率の良い検索機能を提供することに取り組んでいます。主要なクラウドプロバイダーを通じてであれ、セルフホストデプロイメントを通じてであれ、純粋なコストの考慮を超えて最も複雑な企業要件にも対応するソリューションを提供します。この分析は、意思決定に役立つよう、さまざまなコスト要因を分解しています。</p><p>各組織には独自の要件があるため、1つの記事ですべてのシナリオに対応できないことを認識しています。ここで扱われていない特定のニーズがある場合は、最適な実装サポート方法について相談するためにご連絡ください。</p>",
  "comment_id": "679b56ba42b46600019a86e3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-01-30T11:38:50.000+01:00",
  "updated_at": "2025-01-31T05:32:29.000+01:00",
  "published_at": "2025-01-31T05:32:29.000+01:00",
  "custom_excerpt": "We offer detailed cost and performance breakdowns for three deployment strategies: Jina API, self-hosted K8s, and AWS SageMaker, to help you make the right decision.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "641c23a2f4d50d003d590474",
    "name": "Saahil Ognawala",
    "slug": "saahil",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
    "cover_image": null,
    "bio": "Senior Product Manager at Jina AI",
    "website": "http://www.saahilognawala.com/",
    "location": "Munich, DE",
    "facebook": null,
    "twitter": "@saahil",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/a-practical-guide-to-deploying-search-foundation-models-in-production/",
  "excerpt": "3つのデプロイメント戦略（Jina API、セルフホスト型 K8s、AWS SageMaker）について、コストとパフォーマンスの詳細な内訳を提供し、適切な判断をサポートします。",
  "reading_time": 14,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}