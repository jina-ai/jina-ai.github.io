{
  "slug": "ai-explainability-made-easy-how-late-interaction-makes-jina-colbert-transparent",
  "id": "6672af263ce1950001eed6a7",
  "uuid": "44371108-082d-4fb0-a28d-4f86fc02ac14",
  "title": "AI の説明可能性を簡単に：Late Interaction が Jina-ColBERT を透明化する仕組み",
  "html": "<p>AI モデルの長年の課題の1つは、ニューラルネットワークがどのようにして出力を生成するのかを説明できないことです。これがどの程度 AI にとって本質的な問題なのかは必ずしも明確ではありません。人間に理由を説明するよう求めても、通常は自分でも気づかないうちに合理化し、頭の中で実際に何が起きているかを示すことなく、もっともらしい説明をするだけです。</p><p>すでに私たちは、AI モデルにもっともらしい答えを作らせる方法を知っています。この点で、AI は認めたくないかもしれませんが、人間に似ているのかもしれません。</p><p>50年前、アメリカの哲学者トーマス・ネーゲルは『コウモリであるとはどのようなことか』という影響力のあるエッセイを書きました。彼は、コウモリであることには何かしらの「そのような感じ」があるはずだと主張しました：コウモリが世界を見るように見ること、コウモリのように存在を知覚すること。しかし、ネーゲルによれば、たとえコウモリの脳や感覚、体の働きについて知り得るすべての事実を知っていたとしても、コウモリであることがどのようなものかは分からないのです。</p><p>AI の説明可能性も同じような問題です。私たちは特定の AI モデルについて知り得るすべての事実を知っています。それは単に有限精度の数値が行列の並びとして配置されているだけです。すべてのモデル出力が正しい算術の結果であることは簡単に検証できますが、その情報は説明としては役に立ちません。</p><p>この問題に対する一般的な解決策は、人間の場合と同様に存在しません。しかし、ColBERT アーキテクチャ、特に再ランク付けに使用される「後期相互作用」の方法により、モデルが特定のケースで特定の結果を出す理由について意味のある洞察を得ることができます。</p><p>この記事では、Jina-ColBERT モデル <a href=\"https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io\"><code>jina-colbert-v1-en</code></a> と <a href=\"https://matplotlib.org/?ref=jina-ai-gmbh.ghost.io\">Matplotlib Python ライブラリ</a>を使用して、後期相互作用がどのように説明可能性を可能にするかを示します。</p><h2 id=\"a-brief-overview-of-colbert\">ColBERT の概要</h2><p>ColBERT は、<a href=\"https://doi.org/10.1145/3397271.3401075?ref=jina-ai-gmbh.ghost.io\">Khattab & Zaharia (2020)</a> において、Google が 2018 年に発表した <a href=\"https://doi.org/10.18653/v1/N19-1423?ref=jina-ai-gmbh.ghost.io\">BERT モデル</a>の拡張として導入されました。<a href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\">Jina AI の Jina-ColBERT</a> モデルは、この研究と <a href=\"https://arxiv.org/abs/2112.01488?ref=jina-ai-gmbh.ghost.io\">Santhanam, et al. (2021)</a> で提案された ColBERT v2 アーキテクチャを基にしています。ColBERT スタイルのモデルは埋め込みを作成するために使用できますが、再ランク付けモデルとして使用する場合には追加の機能があります。主な利点は「後期相互作用」で、これは標準的な埋め込みモデルとは異なる方法でテキストの意味的類似性の問題を構造化する方法です。</p><h3 id=\"embedding-models\">埋め込みモデル</h3><p>従来の埋め込みモデルでは、2つのテキストを、それらの代表的なベクトルである「埋め込み」を生成して比較し、コサイン距離やハミング距離などの距離メトリクスを使用して比較します。2つのテキストの意味的類似性を定量化する一般的な手順は以下の通りです。</p><p>まず、2つのテキストの埋め込みを別々に作成します。各テキストに対して：</p><ol><li>トークナイザーがテキストを概ね単語サイズのチャンクに分割します。</li><li>各トークンがベクトルにマッピングされます。</li><li>トークンベクトルは注意機構と畳み込み層を通じて相互作用し、各トークンの表現に文脈情報を追加します。</li><li>プーリング層がこれらの修正されたトークンベクトルを単一の埋め込みベクトルに変換します。</li></ol><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings_pooling_dark_small-1.png\" class=\"kg-image\" alt=\"畳み込み、注意機構、プーリング層、テキストトークンを含むテキスト分類モデルの図（黒背景）。\" loading=\"lazy\" width=\"550\" height=\"900\"><figcaption><span style=\"white-space: pre-wrap;\">テキストの単一の埋め込みを作成する埋め込みモデルの概略図。</span></figcaption></figure><p>そして、各テキストの埋め込みが作成されたら、通常コサイン距離やハミング距離を使用してそれらを比較します。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings2_simpler_dark_small.png\" class=\"kg-image\" alt=\"トークン化、埋め込みモデル、スコアリングを含むテキスト類似性計算プロセスを説明するフローチャート。\" loading=\"lazy\" width=\"775\" height=\"825\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Embeddings2_simpler_dark_small.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Embeddings2_simpler_dark_small.png 775w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">従来の埋め込みモデルでは、文書は埋め込みを直接比較することで比較されます。</span></figcaption></figure><p>スコアリングは、トークンに関する具体的な情報なしに、2つの埋め込み全体を比較することで行われます。トークン間のすべての相互作用は、2つのテキストが比較される前に発生するため「早期」相互作用です。</p><h3 id=\"reranking-models\">再ランク付けモデル</h3><p>再ランク付けモデルは異なる方法で動作します。</p><p>まず、テキストの埋め込みを作成する代わりに、「クエリ」と呼ばれる1つのテキストと、「対象文書」と呼ぶ他のテキストのコレクションを取り、クエリテキストに対して各対象文書のスコアを計算します。これらの数値は正規化されておらず、埋め込みの比較とは異なりますが、並べ替え可能です。クエリに対して最も高いスコアを持つ対象文書は、モデルによれば、クエリと意味的に最も関連のあるテキストです。</p><p>Jina Reranker API と Python を使用して、<code>jina-colbert-v1-en</code> 再ランク付けモデルでこれがどのように機能するか具体的に見てみましょう。</p><p>以下のコードは、<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\">ダウンロード</a>または <a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\">Google Colab で実行</a>できるノートブックにも含まれています。</p><p>まず、Python 環境に最新バージョンの <code>requests</code> ライブラリをインストールする必要があります。以下のコマンドでインストールできます：</p><pre><code class=\"language-bash\">pip install requests -U\n</code></pre><p>次に、<a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina Reranker API ページ</a>にアクセスし、100万トークンまでのテキスト処理が可能な無料 API トークンを取得してください。以下に示すように、ページ下部から API トークンキーをコピーしてください：</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/jina_reranker_api.png\" class=\"kg-image\" alt=\"検索最適化のための説明テキストと赤でハイライトされたコードセグメントを含む Reranker API のインターフェースのスクリーンショット。\" loading=\"lazy\" width=\"1650\" height=\"1800\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/jina_reranker_api.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/jina_reranker_api.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/jina_reranker_api.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/jina_reranker_api.png 1650w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Jina Reranker API ページから個人用 API キーを取得する方法。</span></figcaption></figure><p>以下のクエリテキストを使用します：</p><ul><li>「象は1日に150kgの食事をする。」</li></ul><p>そしてこのクエリを3つのテキストと比較します：</p><ul><li>「象は1日に150kgの食事をする。」</li><li>「平均的な象は毎日約150kgの植物を消費する。」</li><li>「スペインの雨は主に平野に降る。」</li></ul><p>最初の文書はクエリと同一で、2番目は1番目の言い換えで、最後のテキストは全く関係ありません。</p><p>以下の Python コードを使用してスコアを取得します。変数 <code>jina_api_key</code> に Jina Reranker API トークンを割り当ててください：</p><pre><code class=\"language-Python\">import requests\n\nurl = \"&lt;https://api.jina.ai/v1/rerank&gt;\"\njina_api_key = \"&lt;YOUR JINA RERANKER API TOKEN HERE&gt;\"\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {jina_api_key}\"\n}\ndata = {\n    \"model\": \"jina-colbert-v1-en\",\n    \"query\": \"Elephants eat 150 kg of food per day.\",\n    \"documents\": [\n        \"Elephants eat 150 kg of food per day.\",\n        \"Every day, the average elephant consumes roughly 150 kg of food.\",\n        \"The rain in Spain falls mainly on the plain.\",\n    ],\n    \"top_n\": 3\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nfor item in response.json()['results']:\n    print(f\"{item['relevance_score']} : {item['document']['text']}\")\n</code></pre><p>Python ファイルまたはノートブックでこのコードを実行すると、以下のような結果が得られるはずです：</p><pre><code class=\"language-Text\">11.15625 : Elephants eat 150 kg of food per day.\n9.6328125 : Every day, the average elephant consumes roughly 150 kg of food.\n1.568359375 : The rain in Spain falls mainly on the plain.\n</code></pre><p>予想通り、完全一致が最も高いスコアを持ち、言い換えが2番目に高く、全く関係のないテキストはずっと低いスコアを持っています。</p><h3 id=\"scoring-using-colbert\">ColBERT を使用したスコアリング</h3><p>埋め込みベースのスコアリングと ColBERT 再ランク付けが異なる点は、スコアリングプロセス中に2つのテキストのトークンが相互に比較されることです。2つのテキストは独自の埋め込みを持つことはありません。</p><p>まず、埋め込みモデルと同じアーキテクチャを使用して、テキストからの文脈情報を含む各トークンの新しい表現を作成します。次に、クエリの各トークンと文書の各トークンを比較します。</p><p>クエリの各トークンに対して、それと最も強い相互作用を持つ文書のトークンを特定し、それらの相互作用スコアを合計して最終的な数値を計算します。</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/ColBERT_dual_dark_small.png\" class=\"kg-image\" alt=\"Detailed diagram showing computational model with tokens, scored and categorized into &quot;Early&quot; and &quot;Late&quot; interactions.\" loading=\"lazy\" width=\"1325\" height=\"1200\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/ColBERT_dual_dark_small.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/ColBERT_dual_dark_small.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/ColBERT_dual_dark_small.png 1325w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>この相互作用は「後期」と呼ばれます：2つのテキストを比較する際に、トークン間で相互作用が発生します。ただし、この「後期」相互作用は「早期」相互作用を排除するものではありません。比較されるトークンベクトルのペアには、すでにそれぞれの文脈に関する情報が含まれています。</p><p>この後期相互作用の仕組みは、その情報が文脈に依存するものであっても、トークンレベルの情報を保持します。これにより、文脈化されたトークンのペアのうちどれが最終的なスコアに貢献しているかを特定できるため、ColBERT モデルがどのようにスコアを計算しているかを部分的に確認することができます。</p><h2 id=\"explaining-rankings-with-heat-maps\">ヒートマップを使用したランキングの説明</h2><p>ヒートマップは、Jina-ColBERT がスコアを作成する際の動作を視覚化するのに便利な技術です。このセクションでは、<a href=\"https://seaborn.pydata.org/?ref=jina-ai-gmbh.ghost.io\"><code>seaborn</code></a> と <a href=\"https://matplotlib.org/?ref=jina-ai-gmbh.ghost.io\"><code>matplotlib</code></a> ライブラリを使用して、<a href=\"https://huggingface.co/jinaai/jina-colbert-v1-en?ref=jina-ai-gmbh.ghost.io\"><code>jina-colbert-v1-en</code></a> の後期相互作用層からヒートマップを作成し、クエリトークンと対象テキストトークンがどのように相互作用するかを示します。</p><h3 id=\"set-up\">セットアップ</h3><p><code>jina-colbert-v1-en</code> モデルにアクセスし、<code>seaborn</code>、<code>matplotlib</code>、<code>Pillow</code> を使用してヒートマップを作成するためのコードを含む Python ライブラリファイルを作成しました。このライブラリは <a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">GitHub から直接ダウンロード</a>するか、<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">提供されているノートブック</a>をご自身のシステムで使用するか、<a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/heatmaps/colbert_heatmaps.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a> で使用することができます。</p><p>まず、必要なものをインストールします。Python 環境に <code>requests</code> ライブラリの最新バージョンが必要です。まだインストールしていない場合は、次のコマンドを実行してください：</p><pre><code class=\"language-bash\">pip install requests -U \n</code></pre><p>次に、コアライブラリをインストールします：</p><pre><code class=\"language-bash\">pip install matplotlib seaborn torch Pillow\n</code></pre><p>次に、GitHub から <code>jina_colbert_heatmaps.py</code> をダウンロードします。<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">ウェブブラウザ</a>経由でダウンロードするか、<code>wget</code> がインストールされている場合はコマンドラインで実行できます：</p><pre><code class=\"language-bash\">wget https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/heatmaps/jina_colbert_heatmaps.py\n</code></pre><p>ライブラリを配置したら、この記事の残りの部分では以下の関数を1つ宣言するだけで済みます：</p><pre><code class=\"language-Python\">from jina_colbert_heatmaps import JinaColbertHeatmapMaker\n\ndef create_heatmap(query, document, figsize=None):\n    heat_map_maker = JinaColbertHeatmapMaker(jina_api_key=jina_api_key)\n    # get token embeddings for the query\n    query_emb = heat_map_maker.embed(query, is_query=True)\n    # get token embeddings for the target document\n    document_emb = heat_map_maker.embed(document, is_query=False)\n    return heat_map_maker.compute_heatmap(document_emb[0], query_emb[0], figsize)\n</code></pre><h3 id=\"results\">結果</h3><p>ヒートマップを作成できるようになったので、いくつか作成して何が分かるか見てみましょう。</p><p>Python で以下のコマンドを実行してください：</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Elephants eat 150 kg of food per day.\")</code></pre><p>結果は以下のようなヒートマップになります：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--68-.png\" class=\"kg-image\" alt=\"Heatmap visualizing relationships between phrases like &quot;elephants eat 150 kg of food per day&quot; with color gradients indicating\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--68-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--68-.png 640w\"></figure><p>これは、同一のテキストを比較する際のトークンペア間の活性化レベルを示すヒートマップです。各マスは、それぞれのテキストからの2つのトークン間の相互作用を示しています。追加トークンの <code>[CLS]</code> と <code>[SEP]</code> はそれぞれテキストの開始と終了を示し、<code>q</code> と <code>d</code> は <code>[CLS]</code> トークンの直後にクエリと対象文書それぞれに挿入されます。これにより、モデルはトークンとテキストの開始・終了の間の相互作用を考慮できるだけでなく、トークン表現がクエリと対象のどちらにあるかを区別することができます。</p><p>マスが明るいほど、2つのトークン間の相互作用が強く、意味的な関連性が高いことを示しています。各トークンペアの相互作用スコアは -1.0 から 1.0 の範囲です。赤い枠で囲まれたマスは、最終スコアに寄与するものです：クエリの各トークンについて、文書内の任意のトークンとの最高の相互作用レベルが採用される値となります。</p><p>最もマッチするもの（最も明るい部分）と赤枠で囲まれた最大値は、ほぼすべて対角線上に正確に配置され、非常に強い相互作用を示しています。唯一の例外は、「技術的な」トークンである <code>[CLS]</code>、<code>q</code>、<code>d</code>、および英語の高頻度「ストップワード」で独立した情報をほとんど持たない \"of\" という単語です。</p><p>構造的に似た文「Cats eat 50 g of food per day.」を見て、トークンがどのように相互作用するか確認してみましょう：</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Cats eat 50 g of food per day.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/download.png\" class=\"kg-image\" alt=\"Heatmap visualizing the relevance of keywords like &quot;elephants&quot;, &quot;food&quot;, and &quot;kg&quot; with varying intensity colors, indicating da\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/download.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/download.png 640w\"></figure><p>ここでも、単語が頻繁に同じで文の構造がほぼ同一であるため、最もマッチするものは主に対角線上にあります。\"cats\" と \"elephants\" も共通の文脈のため、あまり強くはありませんがマッチしています。</p><p>文脈の類似性が低いほど、マッチ度は悪くなります。「Employees eat at the company canteen.」というテキストを考えてみましょう：</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Employees eat at the company canteen.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--69-.png\" class=\"kg-image\" alt=\"Heatmap visualization showing word correlations from news articles, including topics like food, elephants, and work environme\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--69-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--69-.png 640w\"></figure><p>構造的には似ていますが、ここで強いマッチを示すのは \"eat\" の2つのインスタンス間だけです。これらの文は構造的に非常に類似していても、話題の面では大きく異なります。</p><p>赤枠で囲まれたマスの色の暗さを見ると、モデルが「Elephants eat 150 kg of food per day」に対するマッチとしてどのようにランク付けするかが分かり、<code>jina-colbert-v1-en</code> はこの直感を以下のように確認します：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>スコア</th>\n<th>テキスト</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>11.15625</td>\n<td>Elephants eat 150 kg of food per day.</td>\n</tr>\n<tr>\n<td>8.3671875</td>\n<td>Cats eat 50 g of food per day.</td>\n</tr>\n<tr>\n<td>3.734375</td>\n<td>Employees eat at the company canteen.</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>では、\"Elephants eat 150 kg of food per day.\" を、本質的に同じ意味だが異なる表現の文「Every day, the average elephant consumes roughly 150 kg of food.」と比較してみましょう：</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"Every day, the average elephant consumes roughly 150 kg of food.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--70-.png\" class=\"kg-image\" alt=\"Colorful heatmap visualizing the relationship between elephant consumption metrics and other variables.\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--70-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--70-.png 640w\"></figure><p>最初の文章の「eat」と2番目の文章の「consume」の間に強い関連性があることに注目してください。語彙が異なっていても、Jina-ColBERT は共通の意味を認識することができます。</p><p>また、「every day」は完全に異なる位置にあっても「per day」と強く一致します。価値の低い単語「of」のみが異常な不一致となっています。</p><p>では、同じクエリを全く関係のないテキストと比較してみましょう：\"The rain in Spain falls mainly on the plain.\"</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", \"The rain in Spain falls mainly on the plain.\")</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/download-1.png\" class=\"kg-image\" alt=\"Seaborn heatmap visualizing frequencies of topic discussions over months, shaded from red to dark blue.\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/download-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/download-1.png 640w\"></figure><p>この組み合わせでは「ベストマッチ」の相互作用のスコアがはるかに低く、2つのテキスト間の単語の相互作用もほとんどないことがわかります。直感的に、\"Every day, the average elephant consumes roughly 150 kg of food\" と比べて低いスコアが予想されますが、<code>jina-colbert-v1-en</code> もそれに同意します：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Score</th>\n<th>Text</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>9.6328125</td>\n<td>Every day, the average elephant consumes roughly 150 kg of food.</td>\n</tr>\n<tr>\n<td>1.568359375</td>\n<td>The rain in Spain falls mainly on the plain.</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h3 id=\"long-texts\">長いテキスト</h3><p>これらは ColBERT スタイルの再ランク付けモデルの仕組みを示すためのおもちゃの例です。情報検索の文脈では、検索拡張生成のような場合、クエリは通常短いテキストであり、マッチング候補の文書はより長く、モデルの入力コンテキストウィンドウと同じくらいの長さになることがあります。</p><p>Jina-ColBERT モデルはすべて 8192 トークンの入力コンテキストをサポートしており、これは約 16 ページの標準的な 1 行スペースのテキストに相当します。</p><p>これらの非対称なケースでもヒートマップを生成できます。例えば、<a href=\"https://en.wikipedia.org/wiki/Indian_elephant?ref=jina-ai-gmbh.ghost.io\">インド象に関する Wikipedia ページ</a>の最初のセクションを見てみましょう：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png\" class=\"kg-image\" alt=\"Screenshot of Wikipedia page on Indian elephants, featuring articles, three elephant images, and conservation status.\" loading=\"lazy\" width=\"2000\" height=\"1870\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Screenshot-2024-06-13-at-14.12.36--1-.png 2188w\" sizes=\"(min-width: 720px) 720px\"></figure><p><code>jina-colbert-v1-en</code> に渡される平文を確認するには、<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/docs-heatmaps/notebooks/heatmaps/wikipedia_indian_elephant.txt?ref=jina-ai-gmbh.ghost.io\">このリンク</a>をクリックしてください。</p><p>このテキストは 364 単語あるので、ヒートマップは正方形にはなりません：</p><pre><code class=\"language-Python\">create_heatmap(\"Elephants eat 150 kg of food per day.\", wikipedia_elephants, figsize=(50,7))</code></pre><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--71--2.png\" class=\"kg-image\" alt=\"Graphical heatmap displaying genetic data, with red and orange dots indicating varying expression levels across base pairs an\" loading=\"lazy\" width=\"2000\" height=\"378\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--71--2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Untitled--71--2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Untitled--71--2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/06/Untitled--71--2.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>「elephants」がテキスト中の多くの場所と一致していることがわかります。象についてのテキストなので、これは驚くことではありません。しかし、さらに強い相互作用がある領域も見ることができます：</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--72--1.png\" class=\"kg-image\" alt=\"Genomic heatmap with red and black patterns, axis labeled 'XNTY', and highlighted regions indicating data points.\" loading=\"lazy\" width=\"2000\" height=\"443\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--72--1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Untitled--72--1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/06/Untitled--72--1.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/06/Untitled--72--1.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>ここで何が起きているのでしょうか？Jina-ColBERT を使うと、これが長いテキストのどの部分に対応しているかを見つけることができます。2 段落目の 4 番目の文章であることがわかります：</p><blockquote>The species is classified as a megaherbivore and consume up to 150 kg (330 lb) of plant matter per day.</blockquote><p>これはクエリテキストと同じ情報を述べています。この文だけのヒートマップを見ると、強い一致が見られます：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--74-.png\" class=\"kg-image\" alt=\"Heatmap displaying word co-occurrence with a focus on &quot;elephants,&quot; &quot;food,&quot; and &quot;day,&quot; with color intensity indicating the str\" loading=\"lazy\" width=\"640\" height=\"480\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Untitled--74-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Untitled--74-.png 640w\"></figure><p>Jina-ColBERT は、長いテキストのどの部分がクエリと一致したのかを正確に確認する手段を提供します。これによってデバッグが改善されるだけでなく、説明可能性も高まります。マッチがどのように行われたかを理解するのに高度な知識は必要ありません。</p><h2 id=\"explaining-ai-outcomes-with-jina-colbert\">Jina-ColBERT による AI の結果の説明</h2><p>埋め込みは現代の AI の中核技術です。私たちが行うほとんどすべてのことは、入力データの複雑で学習可能な関係が高次元空間の幾何学で表現できるという考えに基づいています。しかし、数千から数百万次元の空間的関係を人間が理解するのは非常に難しいことです。</p><p>ColBERT はそのレベルの抽象化からの一歩後退です。AI モデルが何をするのかを説明する完全な答えではありませんが、結果に責任を持つデータの部分を直接指し示してくれます。</p><p>時として、AI はブラックボックスでなければなりません。すべての重要な処理を行う巨大な行列は、人間が頭の中に収めるには大きすぎます。しかし、ColBERT アーキテクチャはそのボックスに少し光を当て、より多くのことが可能であることを示しています。</p><p>Jina-ColBERT モデルは現在英語のみ（<code>jina-colbert-v1-en</code>）で利用可能ですが、より多くの言語と使用コンテキストが開発中です。最先端の情報検索を実行するだけでなく、なぜ何かがマッチしたのかを説明できるこのモデルシリーズは、AI 技術をアクセスしやすく、かつ有用なものにするという Jina AI のコミットメントを示しています。</p>",
  "comment_id": "6672af263ce1950001eed6a7",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/06/Search-acc--3-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-06-19T12:12:54.000+02:00",
  "updated_at": "2024-07-08T21:08:21.000+02:00",
  "published_at": "2024-06-19T16:01:36.000+02:00",
  "custom_excerpt": "AI explainability and transparency are hot topics. How can we trust AI if we can't see how it works? Jina-ColBERT shows you how, with the right model architecture, you can easily make your AI spill its secrets.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "6360e8495e0f6e004d70bd9e",
      "name": "Maximilian Werk",
      "slug": "maximilian",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/Profile-Picture.jpg",
      "cover_image": null,
      "bio": "I love bringing business value with ML powered solutions as well as broad strategic and deep technical discussions. I also care a lot about our company culture and enjoy pair programming.",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/maximilian/"
    },
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "6360e8495e0f6e004d70bd9e",
    "name": "Maximilian Werk",
    "slug": "maximilian",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/Profile-Picture.jpg",
    "cover_image": null,
    "bio": "I love bringing business value with ML powered solutions as well as broad strategic and deep technical discussions. I also care a lot about our company culture and enjoy pair programming.",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/maximilian/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/ai-explainability-made-easy-how-late-interaction-makes-jina-colbert-transparent/",
  "excerpt": "AI の説明可能性と透明性は注目を集めています。AI の仕組みが分からないのに、どうやって信頼できるでしょうか？Jina-ColBERT は、適切なモデルアーキテクチャを使えば、AI に秘密を容易に明かさせることができる方法を示しています。",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Digital representation of a golden building seen through a blue and yellow mesh pattern, evoking a technological vibe.",
  "feature_image_caption": null
}