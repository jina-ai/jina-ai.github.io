{
  "slug": "fair-scoring-for-multimodal-documents-with-jina-reranker-m0",
  "id": "682b34d62caa92000178b523",
  "uuid": "434b7cc3-713d-4f2e-843a-6270f0e27604",
  "title": "jina-reranker-m0 を使用したマルチモーダルドキュメントのフェアなスコアリング",
  "html": "<p>スポーツニュースの検索システムを構築しているとしましょう。ユーザーが「テニスプレーヤーが選手権での勝利を祝う」と検索し、データベースから最も関連性の高い記事を見つける必要があるとします。各記事には、テキストのキャプションと画像が含まれています。これは、現代のスポーツ報道の典型的な例です。</p><p>あなたのシステムは、<strong>テキストクエリ</strong>を受け取り、コーパスから<strong>最も関連性の高いマルチモーダルドキュメントのランク付けされたリスト</strong>を返す必要があります。簡単そうに聞こえますが、すべての明白なアプローチを打ち砕く根本的な問題があります。</p><p>これらのドキュメントをランク付けしようとすると、次のようになります。例えば、あなたの埋め込みモデル (Embeddings) である<code>jina-clip-v2</code>は、次のような類似度スコアを生成します。</p>\n<!--kg-card-begin: html-->\n<table>\n    <thead>\n        <tr>\n            <th>記事</th>\n            <th>コンテンツタイプ</th>\n            <th>説明</th>\n            <th>類似度スコア</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>A</td>\n            <td>テキスト</td>\n            <td>ノバク・ジョコビッチが全豪オープンの決勝でストレート勝ち</td>\n            <td>0.72</td>\n        </tr>\n        <tr>\n            <td>A</td>\n            <td>画像</td>\n            <td>[トロフィーを持ち笑顔のプレーヤーの写真]</td>\n            <td>0.31</td>\n        </tr>\n        <tr>\n            <td>B</td>\n            <td>テキスト</td>\n            <td>天候の遅延が屋外トーナメントのスケジュールに影響</td>\n            <td>0.23</td>\n        </tr>\n        <tr>\n            <td>B</td>\n            <td>画像</td>\n            <td>[ジャンプして祝うテニスプレーヤーの写真]</td>\n            <td>0.54</td>\n        </tr>\n    </tbody>\n</table>\n<!--kg-card-end: html-->\n<p>どちらの記事がより関連性が高いでしょうか？記事Aはテキストスコアが高いですが、画像スコアは低いです。記事Bはテキストスコアが低いですが、画像スコアは高いです。根本的な課題は、<strong>0.72（テキスト）と0.54（画像）を比較できない</strong>ことです。なぜなら、これらの類似度スコアは完全に異なるスケール上に存在するためです。</p><h2 id=\"when-trivial-solutions-fail\">自明な解決策が失敗する場合</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">CLIPモデルにおけるテキストと画像のモダリティギャップとは何か、そしてなぜそれが重要なのか</div><div class=\"kg-bookmark-description\">CLIPモデルを使用してテキストと画像を取得し、スコアで結果を並べ替えることはできません。なぜでしょうか？それは、モダリティギャップがあるからです。それは何であり、どこから来るのでしょうか？</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-32.png\" alt=\"\"><span class=\"kg-bookmark-author\">Jina AI</span><span class=\"kg-bookmark-publisher\">Bo Wang, Scott Martens</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/the-what-and-why-of-text-image-modality-gap-in-clip-models.webp\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><code>jina-clip-v2</code>または他のほとんどすべてのCLIPのようなモデルにおける<strong>モダリティギャップのため</strong>、試す可能性のある明白なアプローチはどれも機能しません。より高いスコアを使用するだけの場合、テキストスコアは0.2〜0.8の周辺に集中し、画像スコアは0.4〜0.6の周辺に集中するという事実に突き当たります。これは、平凡なテキストの一致（0.6）が常に優れた画像の一致（0.5）を打ち負かすことを意味します。</p><p>スコアを平均化しても役に立ちません。（0.7 + 0.3）/ 2 = 0.5を計算しても数値が得られますが、それは実際に何を意味するのでしょうか？あなたは根本的に意味のない量を平均化しています。同様に、固定の重み付けスキームも任意です。テキストがより重要な場合もあれば、画像がより重要な場合もあり、これは特定のクエリとドキュメントに完全に依存します。</p><p>最初にスコアを正規化しても、根本的な問題は解決されません。それでも、関連性の異なる側面を捉える根本的に異なる類似度指標を組み合わせようとしています。</p><h2 id=\"what-actually-happens\">実際に起こること</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2305.13631\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">EDIS：マルチモーダルWebコンテンツ上のエンティティ駆動型画像検索</div><div class=\"kg-bookmark-description\">画像検索メソッドを実際の検索アプリケーションに実用化するには、データセットの規模、エンティティの理解、およびマルチモーダル情報の融合において大きな進歩が必要です。本研究では、ニュースドメインにおけるクロスモーダル画像検索のための挑戦的なデータセットである、\\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch（EDIS）を紹介します。EDISは、実際の検索エンジンの結果とキュレーションされたデータセットからの100万枚のWeb画像で構成されており、各画像にはテキストによる説明が組み合わされています。少数のシングルモーダル候補を想定するデータセットとは異なり、EDISは、100万のマルチモーダル画像とテキストのペアを候補として含めることにより、実際のWeb画像検索シナリオを反映しています。EDISは、クロスモーダル情報融合とマッチングに同時に対処する検索モデルの開発を奨励します。正確なランキング結果を得るには、モデルは次のことを行う必要があります。1）テキストクエリから名前付きエンティティとイベントを理解する、2）エンティティを画像またはテキストの説明に接地する、3）テキストおよび視覚的な表現を効果的に融合する。私たちの実験結果は、EDISが多数のエンティティと大規模な候補セットで最先端の方法に挑戦していることを示しています。アブレーション研究は、テキスト機能を視覚機能と融合することが検索結果の改善に不可欠であることも証明しています。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-20.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Siqi Liu</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-16.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>私たちが取り組んでいることをよりよく理解するために、<a href=\"https://arxiv.org/abs/2305.13631\">EDISデータセット</a>のドキュメントの例を示します。画像（ドイツのサッカーの試合）とキャプション（<code>One More Field Where the Content Trails Germany</code>）を示しています。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"928\" height=\"261\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-1.png 928w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図1：画像とテキストコンテンツの両方を含むマルチモーダルドキュメントの例。2つのモダリティがあるため、特定のクエリに対して</span><i><em class=\"italic\" style=\"white-space: pre-wrap;\">2つ</em></i><span style=\"white-space: pre-wrap;\">のセマンティックギャップ（クエリとテキストの間、およびクエリと画像の間に）が存在します。最良の結果を得るには、ドキュメントのテキストコンテンツを検索すべきでしょうか、それとも画像コンテンツを検索すべきでしょうか？</span></figcaption></figure><p>全体として、<code>jina-clip-v2</code>は、EDISデータセットでクエリとテキストを比較する場合、クエリと画像を比較する場合よりもはるかに高い類似性を示します。これは、モデルのトレーニング方法と、データセット自体が原因です。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"964\" height=\"679\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-2.png 964w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図2：</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">を使用した、クエリと画像（赤）およびクエリとテキスト（青）の間の類似度スコア。</span></figcaption></figure><p>したがって、ドキュメントを画像ではなくテキストに基づいて検索する方が論理的に思われます。そして、下のグラフでわかるように、テキストクエリ<code>... for undocumented immigrants helping to establish legal status in the United States</code>をコーパスのテキストコンテンツと比較すると、はるかに良い結果が得られます。実際、画像で検索すると、正解のドキュメント（黄色で強調表示）をまったく取得できません。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1767\" height=\"2454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-3.png 1767w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図3：</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\">を3で使用する場合、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">のクエリとテキストの検索でのみ正解のドキュメント（黄色の枠線で強調表示）を取得できる例。</span></figcaption></figure><p>しかし、騙されてはいけません。クエリとテキストの方が高い類似度スコアを示していますが、クエリとテキスト、およびクエリと画像の類似度スコアは<em>比較可能ではありません</em>。<code>jina-clip-v2</code>を使用してEDISデータセットから32個のドキュメントを取得する場合、recall@10を見るとこれがわかります。明らかに、リコールはクエリと<em>画像</em>の方が高くなっています。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Recall@10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>クエリとテキスト</td>\n<td>14.55</td>\n</tr>\n<tr>\n<td>クエリと画像</td>\n<td><strong>22.38</strong></td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>以下で確認できます。データセットからのクエリ<code>Ear ear An elephant is decorated with Bhartiya Janta Party symbols near the BJP headquarters in New Delhi.</code>を使用する場合、画像コンテンツによってのみ正解のドキュメントを取得できます。テキストコンテンツで検索しても一致するものは返されません。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1753\" height=\"2454\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-4.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-4.png 1753w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図4：</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>top_k</span></code><span style=\"white-space: pre-wrap;\">を3で使用する場合、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>jina-clip-v2</span></code><span style=\"white-space: pre-wrap;\">のクエリと画像の検索でのみ正解のドキュメント（黄色の枠線で強調表示）を取得できる例。</span></figcaption></figure><p>類似度スコアからテキストでドキュメントを検索し、リコール率から画像でドキュメントを検索する必要がある場合、どちらを選ぶべきでしょうか？確かに、図3と4からは明確な勝者は見当たりません。どのモダリティが、クエリと探しているドキュメントとの間で最も近い一致を示すのでしょうか？そして、クエリからテキストへの検索とクエリから画像への検索の両方から候補をマージしたい場合、スコアを比較することさえできないのに、どのようにして上位の一致を意味のある形で選択できるのでしょうか？明らかに、<code>jina-clip-v2</code>だけでは不十分です。別のモデルを投入する必要があります。</p><h2 id=\"a-simple-two-stage-pipeline\">シンプルな2段階パイプライン</h2><p>2025年4月、ビジュアルドキュメントを検索するための多言語マルチモーダル重排器 (Reranker) である<code>jina-reranker-m0</code>をリリースしました。以下の図で、そのモダリティギャップが狭まっていることがわかります。<code>jina-reranker-m0</code>は、クエリからテキストへの類似度スコアとクエリから画像への類似度スコアが同程度であることを示していますが、<code>jina-clip-v2</code>では、そのギャップがはるかに大きくなっています。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"964\" height=\"679\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/Distribution_of_similarity_between_query_and_corpus_in_jina-reranker-m0.png 964w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図6：</span><code>jina-clip-v2</code>と比較して、<code>jina-reranker-m0</code>は、クエリから画像への類似度スコア（赤）とクエリからテキストへの類似度スコア（青）の差がはるかに小さいことを示しています。</figcaption></figure><p>これを念頭に置いて、<code>jina-clip-v2</code>から初期結果を取得した後、検索チェーンの2回目のパスで<code>jina-reranker-m0</code>を使用できます。</p><p><strong>ステージ1：両方のモダリティから候補を取得する</strong></p><ul><li><code>jina-clip-v2</code>を使用して、テキスト検索で16個のドキュメント、画像検索で16個のドキュメントを取得します。</li><li>まだスコアを比較できないことを受け入れます。</li></ul><p><strong>ステージ2：統合された重み付け</strong></p><ul><li>各（クエリ+完全なドキュメント）ペアを<code>jina-reranker-m0</code>に入力します。</li><li>重排器 (Reranker) は、テキストと画像の両方をまとめて処理します。</li><li>出力：統一されたスケールでの単一の関連性スコア</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-5.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1305\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/image-5.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2025/05/image-5.png 2048w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図5：</span><code>jina-clip-v2</code>と<code>jina-reranker-m0</code>を使用したマルチモーダルドキュメントのインデックス作成と2段階のマルチモーダル検索プロセス。</figcaption></figure><p>表1の実験を拡張し、<code>jina-clip-v2</code>を使用してコーパスからドキュメントを取得し、次に<code>jina-reranker-m0</code>を使用してそれらを重み付けします。</p><ol><li>クエリからテキストへの検索で32個のドキュメントを取得し、次にクエリからテキストへのスコアに基づいて重み付けします。</li><li>クエリから画像への検索で32個のドキュメントを取得し、次にクエリから画像へのスコアに基づいて重み付けします。</li><li>クエリからテキストへの検索で16個のドキュメント、クエリから画像への検索で16個のドキュメントを取得します。クエリのモダリティに応じて、クエリからテキストへのスコアまたはクエリから画像へのスコアに基づいて重み付けします。</li><li>クエリからテキストへの検索で16個のドキュメント、クエリから画像への検索で16個のドキュメントを取得します。各ドキュメントの平均クエリからテキストへのスコアとクエリから画像へのスコアに基づいて重み付けし、（クエリからテキストへのスコア+クエリから画像へのスコア）/2の最終スコアを与えます。</li></ol><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">EDISでのゼロショット性能を測定していることに注意してください。データセットを使用して<code>jina-clip-v2</code>または<code>jina-reranker-m0</code>のいずれもファインチューニングしていません。</div></div>\n<!--kg-card-begin: html-->\n\n<table>\n  <thead>\n    <tr>\n      <th>実験</th>\n      <th>説明</th>\n      <th>Recall@10 - jina-clip-v2を使用</th>\n      <th>Recall@10 - jina-reranker-m0を使用</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>32ドキュメント：クエリからテキストへ</td>\n      <td>14.55</td>\n      <td>17.42</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>32ドキュメント：クエリから画像へ</td>\n      <td>22.38</td>\n      <td>28.94</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>16ドキュメント：クエリからテキストへ<br>16ドキュメント：クエリから画像へ</td>\n      <td>14.55</td>\n      <td>33.81</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>16ドキュメント：クエリからテキストへ<br>16ドキュメント：クエリから画像へ<br>組み合わせた平均重排器 (Reranker) スコア</td>\n      <td>14.55</td>\n      <td><strong>36.24</strong></td>\n    </tr>\n  </tbody>\n</table>\n\n<!--kg-card-end: html-->\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">実験1、3、4はすべて、クエリからテキストへのスコアがクエリから画像へのスコアよりも高いため、<code>jina-clip-v2</code>で同じリコール率@10の結果を示しています。したがって、上位10件の結果は、テキストを介して検索されたドキュメントによって支配されています。</div></div><p>ご覧のとおり、<code>jina-reranker-m0</code>で2回目のパスを実行することで、モダリティに関係なく、リコール率が全体的に向上します。ただし、<strong>検索されたドキュメントからテキストコンテンツと画像コンテンツの両方を組み合わせると、最大の増加が見られ</strong>、リコール率@10は36.24になります。視覚的な例では、<code>jina-reranker-m0</code>は、テキストコンテンツまたは画像コンテンツを検索するかどうかにかかわらず、一貫してグラウンドトゥルースドキュメントを最初にランク付けすることが示されています。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/05/clip-vs-reranker.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1146\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/05/clip-vs-reranker.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/05/clip-vs-reranker.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/05/clip-vs-reranker.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/05/clip-vs-reranker.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">図7：サンプルクエリ（左側）と、各重み付け方法（右側の4つの列）の1つの結果の</span><code>top_k</code>を示しており、画像とテキストの類似度スコアを組み合わせることで、一貫してグラウンドトゥルースドキュメントが最初にランク付けされることがわかります。</figcaption></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">図3と4は、さまざまな検索方法の<code>top_k</code>が3であることを示していますが、スペースの都合上、図7は各クエリの<code>top_k</code>のみを示しています。</div></div><h2 id=\"conclusions\">結論</h2><p>このシンプルな2段階アプローチは、システムがついに人間が自然に行うことを活用する（関連性を判断するために、私たちが読んだものと見たものの両方を考慮する）ため、リコール率が62％向上します。この教訓は検索にとどまりません。マルチモーダルAIシステムを扱う場合、モダリティを別々に扱うシングルパスアプローチは、常にこのスコアリングの非互換性の壁にぶつかります。広範に検索し、インテリジェントにランク付けする2段階アーキテクチャが不可欠になりつつあります。APIまたはAWS、GCP、Azure経由で<code>jina-reranker-m0</code>をお試しください。</p>",
  "comment_id": "682b34d62caa92000178b523",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/05/fair-scoring.webp",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-05-19T15:40:38.000+02:00",
  "updated_at": "2025-05-25T08:26:31.000+02:00",
  "published_at": "2025-05-25T08:25:10.000+02:00",
  "custom_excerpt": "Text similarity: 0.7. Image similarity: 0.5. Which document is more relevant? You literally cannot tell—and that's the core problem breaking multimodal search. We solve it with unified reranking.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "678e14a78f6bb40001a63595",
      "name": "Nan Wang",
      "slug": "nan",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg",
      "cover_image": null,
      "bio": "Co-founder & CTO @JinaAI | Ex-Zalando & Tencent | Build AI models & systems | Open-source enthusiast | Speaker & contributor (40+ talks) | PhD in Computational Neuroscience @ Ruhr University Bochum",
      "website": null,
      "location": "Global",
      "facebook": null,
      "twitter": "@nanwang_t",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
    },
    {
      "id": "632ade4a3e4e55003d525971",
      "name": "Alex C-G",
      "slug": "alexcg",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/twitter_banner.jpg",
      "bio": "Open-source Evangelist @ Jina AI. Old, grim, and full of Vim",
      "website": null,
      "location": "Berlin, Germany",
      "facebook": null,
      "twitter": "@alexcg",
      "meta_title": null,
      "meta_description": null,
      "threads": null,
      "bluesky": null,
      "mastodon": null,
      "tiktok": null,
      "youtube": null,
      "instagram": null,
      "linkedin": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "678e14a78f6bb40001a63595",
    "name": "Nan Wang",
    "slug": "nan",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg",
    "cover_image": null,
    "bio": "Co-founder & CTO @JinaAI | Ex-Zalando & Tencent | Build AI models & systems | Open-source enthusiast | Speaker & contributor (40+ talks) | PhD in Computational Neuroscience @ Ruhr University Bochum",
    "website": null,
    "location": "Global",
    "facebook": null,
    "twitter": "@nanwang_t",
    "meta_title": null,
    "meta_description": null,
    "threads": null,
    "bluesky": null,
    "mastodon": null,
    "tiktok": null,
    "youtube": null,
    "instagram": null,
    "linkedin": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/fair-scoring-for-multimodal-documents-with-jina-reranker-m0/",
  "excerpt": "テキスト類似度：0.7。画像類似度：0.5。どちらのドキュメントがより関連性が高いでしょうか？文字通り判断できません。それが、マルチモーダル検索を阻害している根本的な問題です。私たちは、統一された重排器 (Reranker) によってそれを解決します。",
  "reading_time": 8,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}