{
  "slug": "scaling-test-time-compute-for-embedding-models",
  "id": "675a84f80ce9930001b86f09",
  "uuid": "49f876f3-0d50-4555-8f9e-136473f720ac",
  "title": "埋め込みモデルにおけるテスト時の計算リソースのスケーリング",
  "html": "<p>OpenAI の <a href=\"https://openai.com/o1/?ref=jina-ai-gmbh.ghost.io\">O1 モデル</a>のリリース以来、AI コミュニティで最も議論されているトピックの1つは<strong>テスト時の計算リソースのスケーリング</strong>です。これは、事前学習時ではなく、推論時（AI モデルが入力に対して出力を生成する段階）に追加の計算リソースを割り当てることを指します。よく知られている例として「思考の連鎖」による多段階推論があります。これにより、モデルは複数の潜在的な回答の評価、より深い計画、最終的な応答に至るまでの自己反省など、より広範な内部検討を行うことができます。この戦略は、特に複雑な推論タスクにおいて回答の品質を向上させます。最近 Alibaba がリリースした <a href=\"https://huggingface.co/Qwen/QwQ-32B-Preview?ref=jina-ai-gmbh.ghost.io\">QwQ-32B-Preview</a> モデルも、テスト時の計算リソースを増やすことで AI の推論を改善するというこのトレンドに従っています。</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">この文脈における「スケーリング」は、主に推論時に利用可能な計算能力（処理能力や時間など）を増やすことを意味します。<b><strong style=\"white-space: pre-wrap;\">スケールアウト</strong></b>（タスクを複数のシステムに分散すること）や<b><strong style=\"white-space: pre-wrap;\">スピードアップ</strong></b>（処理時間の短縮）を指すものではありません。</div></div><figure class=\"kg-card kg-video-card kg-width-regular kg-card-hascaption\" data-kg-thumbnail=\"https://jina-ai-gmbh.ghost.io/content/media/2024/12/o1_thumb.jpg\" data-kg-custom-thumbnail=\"\">\n            <div class=\"kg-video-container\">\n                <video src=\"https://jina-ai-gmbh.ghost.io/content/media/2024/12/o1.mp4\" poster=\"https://img.spacergif.org/v1/900x432/0a/spacer.png\" width=\"900\" height=\"432\" loop=\"\" autoplay=\"\" muted=\"\" playsinline=\"\" preload=\"metadata\" style=\"background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2024/12/o1_thumb.jpg') 50% 50% / cover no-repeat;\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\" aria-label=\"Play video\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container kg-video-hide\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\" aria-label=\"Play video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\" aria-label=\"Pause video\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <rect x=\"3\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                                <rect x=\"14\" y=\"1\" width=\"7\" height=\"22\" rx=\"1.5\" ry=\"1.5\"></rect>\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input type=\"range\" class=\"kg-video-seek-slider\" max=\"100\" value=\"0\">\n                        <button class=\"kg-video-playback-rate\" aria-label=\"Adjust playback speed\">1×</button>\n                        <button class=\"kg-video-unmute-icon\" aria-label=\"Unmute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\"></path>\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\" aria-label=\"Mute\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\"></path>\n                            </svg>\n                        </button>\n                        <input type=\"range\" class=\"kg-video-volume-slider\" max=\"100\" value=\"100\">\n                    </div>\n                </div>\n            </div>\n            <figcaption><p dir=\"ltr\"><span style=\"white-space: pre-wrap;\">OpenAI の O1 モデルを使用する際、モデルが問題を解決するために推論の連鎖を構築する際に、多段階推論に追加の時間が必要となることが明確にわかります。</span></p></figcaption>\n        </figure><p>Jina AI では、LLM よりも埋め込みとリランカーに重点を置いているため、このコンテキストでテスト時の計算リソースのスケーリングを考えるのは自然なことです：<em>「思考の連鎖」を埋め込みモデルにどのように適用できるのか？</em>一見直感的ではないかもしれませんが、この記事では新しい視点を探り、テスト時の計算リソースのスケーリングを <code>jina-clip</code> に適用して、分布外（OOD）画像を分類する方法—そうでなければ不可能なタスクを解決する方法—を示します。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--14-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/banner--14-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/banner--14-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--14-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">私たちの実験は、埋め込みモデルにとって興味深い課題を提示するポケモンの認識に焦点を当てました。CLIP のようなモデルは一般的な画像とテキストのマッチングに優れていますが、ファインチューニングなしではニッチな領域や OOD 画像で苦戦する可能性があります。モデルにより多くの「思考」時間を与えることで、埋め込みモデル自体のチューニングなしに、複数ターゲットの分類—「思考の連鎖」に類似—が精度を向上させることがわかりました。</span></figcaption></figure><h2 id=\"case-study\">ケーススタディ</h2><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/drive/1zP6FZRm2mN1pf7PsID-EtGDc5gP_hm4Z?ref=jina-ai-gmbh.ghost.io#scrollTo=CJt5zwA9E2jB\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colab</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-15.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-4.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p><a href=\"https://huggingface.co/datasets/TheFusion21/PokemonCards?ref=jina-ai-gmbh.ghost.io\">TheFusion21/PokemonCards データセット</a>を使用したポケモン分類に関する実験を行いました。このデータセットには何千もののポケモントレーディングカード画像が含まれています。<strong>このタスクは画像分類</strong>で、入力は切り取られたポケモンカードのアートワーク（すべてのテキスト/説明を削除）、出力は事前に定義されたポケモン名のセットから正しいポケモン名を選ぶというものです。このタスクは CLIP 埋め込みモデルにとって特に興味深い課題を提示します：</p><ul><li>ポケモンの名前と視覚的特徴はモデルにとってニッチな分布外の概念であり、直接的な分類が困難です</li><li>各ポケモンは CLIP がよりよく理解できる可能性のある基本的な要素（形状、色、ポーズ）に分解できる明確な視覚的特徴を持っています</li><li>カードのアートワークは一貫した視覚フォーマットを提供しながら、背景、ポーズ、アーティスティックスタイルの変化を通じて複雑さを導入します</li><li>このタスクは、言語モデルの複雑な推論の連鎖と同様に、複数の視覚的特徴を同時に統合する必要があります</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-5.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"835\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-5.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">それらのテキストにポケモンの名前が表示されることによる単純な推測を防ぐため、すべてのテキスト情報（ヘッダー、フッター、説明）を削除するようにポケモンカード画像を切り取りました。これらのポケモンのクラスラベルは [</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Absol G</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Aerodactyl</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Weedle</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Caterpie</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Azumarill</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Bulbasaur</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Venusaur</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Absol</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Aggron</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Beedrill δ</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Alakazam</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Ampharos</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Dratini</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Ampharos</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Ampharos</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Arcanine</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Blaine's Moltres</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Aerodactyl</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Celebi & Venusaur-GX</span></code><span style=\"white-space: pre-wrap;\">、</span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>Caterpie</span></code><span style=\"white-space: pre-wrap;\">]</span></figcaption></figure><h3 id=\"baseline\">ベースライン</h3><p>ベースラインのアプローチでは、ポケモンカードのアートワークと名前を単純に直接比較します。まず、各ポケモンカードの画像から、テキスト情報（ヘッダー、フッター、説明文）を切り取り、CLIP モデルがそれらのテキストに含まれるポケモンの名前から簡単に推測することを防ぎます。次に、<code>jina-clip-v1</code> と <code>jina-clip-v2</code> モデルを使用して、切り取った画像とポケモンの名前の両方をエンコードし、それぞれの埋め込みを取得します。分類は、これらの画像とテキストの埋め込みの間のコサイン類似度を計算することで行われ - 各画像は最も類似度スコアの高い名前とマッチングされます。これにより、追加のコンテキストや属性情報を使用せずに、カードアートワークとポケモンの名前の間で一対一のマッチングが作成されます。以下の擬似コードがベースラインの方法をまとめています。</p><pre><code class=\"language-python\"># Preprocessing\ncropped_images = [crop_artwork(img) for img in pokemon_cards]  # Remove text, keep only art\npokemon_names = [\"Absol\", \"Aerodactyl\", ...]  # Raw Pokemon names\n\n# Get embeddings using jina-clip-v1\nimage_embeddings = model.encode_image(cropped_images)\ntext_embeddings = model.encode_text(pokemon_names)\n\n# Classification by cosine similarity\nsimilarities = cosine_similarity(image_embeddings, text_embeddings)\npredicted_names = [pokemon_names[argmax(sim)] for sim in similarities]\n\n# Evaluate\naccuracy = mean(predicted_names == ground_truth_names)</code></pre><h3 id=\"chain-of-thoughts-for-classification\">分類のための「思考の連鎖」</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--10-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/banner--10-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/banner--10-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--10-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>画像を直接名前とマッチングする代わりに、ポケモンの認識を視覚的属性の構造化されたシステムに分解します。5つの主要な属性グループを定義します：主要な色（例：「白」、「青」）、主要な形態（例：「オオカミ」、「翼のある爬虫類」）、主要な特徴（例：「一本の白い角」、「大きな翼」）、体型（例：「四足のオオカミのような」、「翼があり細身の」）、背景シーン（例：「宇宙」、「緑の森」）。</p><p>各属性グループに対して、特定のテキストプロンプト（例：「このポケモンの体は主に{}色です」）と関連するオプションをペアにして作成します。そして、モデルを使用して画像と各属性オプションの間の類似度スコアを計算します。これらのスコアは、より較正された信頼度の測定値を得るために、softmax を使用して確率に変換されます。</p><p>思考の連鎖（CoT）の完全な構造は2つの部分から構成されています：プロンプトのグループを記述する <code>classification_groups</code> と、各ポケモンがどの属性オプションにマッチすべきかを定義する <code>pokemon_rules</code> です。例えば、Absol は色が「白」、形態が「オオカミのような」とマッチするはずです。完全な CoT は以下の通りです（これがどのように構築されるかは後で説明します）：</p><pre><code class=\"language-python\">pokemon_system = {\n    \"classification_cot\": {\n        \"dominant_color\": {\n            \"prompt\": \"This Pokémon's body is mainly {} in color.\",\n            \"options\": [\n                \"white\",    # Absol, Absol G\n                \"gray\",     # Aggron\n                \"brown\",    # Aerodactyl, Weedle, Beedrill δ\n                \"blue\",     # Azumarill\n                \"green\",    # Bulbasaur, Venusaur, Celebi&Venu, Caterpie\n                \"yellow\",   # Alakazam, Ampharos\n                \"red\",      # Blaine's Moltres\n                \"orange\",   # Arcanine\n                \"light blue\"# Dratini\n            ]\n        },\n        \"primary_form\": {\n            \"prompt\": \"It looks like {}.\",\n            \"options\": [\n                \"a wolf\",         # Absol, Absol G\n                \"an armored dinosaur\",  # Aggron\n                \"a winged reptile\",     # Aerodactyl\n                \"a rabbit-like creature\", # Azumarill\n                \"a toad-like creature\",   # Bulbasaur, Venusaur, Celebi&Venu\n                \"a caterpillar larva\",    # Weedle, Caterpie\n                \"a wasp-like insect\",     # Beedrill δ\n                \"a fox-like humanoid\",     # Alakazam\n                \"a sheep-like biped\",      # Ampharos\n                \"a dog-like beast\",        # Arcanine\n                \"a flaming bird\",          # Blaine's Moltres\n                \"a serpentine dragon\"      # Dratini\n            ]\n        },\n        \"key_trait\": {\n            \"prompt\": \"Its most notable feature is {}.\",\n            \"options\": [\n                \"a single white horn\", # Absol, Absol G\n                \"metal armor plates\",  # Aggron\n                \"large wings\",         # Aerodactyl, Beedrill δ\n                \"rabbit ears\",         # Azumarill\n                \"a green plant bulb\",  # Bulbasaur, Venusaur, Celebi&Venu\n                \"a small red spike\",   # Weedle\n                \"big green eyes\",      # Caterpie\n                \"a mustache and spoons\", # Alakazam\n                \"a glowing tail orb\",  # Ampharos\n                \"a fiery mane\",        # Arcanine\n                \"flaming wings\",       # Blaine's Moltres\n                \"a tiny white horn on head\" # Dratini\n            ]\n        },\n        \"body_shape\": {\n            \"prompt\": \"The body shape can be described as {}.\",\n            \"options\": [\n                \"wolf-like on four legs\",   # Absol, Absol G\n                \"bulky and armored\",        # Aggron\n                \"winged and slender\",       # Aerodactyl, Beedrill δ\n                \"round and plump\",          # Azumarill\n                \"sturdy and four-legged\",   # Bulbasaur, Venusaur, Celebi&Venu\n                \"long and worm-like\",       # Weedle, Caterpie\n                \"upright and humanoid\",     # Alakazam, Ampharos\n                \"furry and canine\",         # Arcanine\n                \"bird-like with flames\",    # Blaine's Moltres\n                \"serpentine\"                # Dratini\n            ]\n        },\n        \"background_scene\": {\n            \"prompt\": \"The background looks like {}.\",\n            \"options\": [\n                \"outer space\",      # Absol G, Beedrill δ\n                \"green forest\",     # Azumarill, Bulbasaur, Venusaur, Weedle, Caterpie, Celebi&Venu\n                \"a rocky battlefield\", # Absol, Aggron, Aerodactyl\n                \"a purple psychic room\", # Alakazam\n                \"a sunny field\",     # Ampharos\n                \"volcanic ground\",   # Arcanine\n                \"a red sky with embers\", # Blaine's Moltres\n                \"a calm blue lake\"   # Dratini\n            ]\n        }\n    },\n    \n    \"pokemon_rules\": {\n        \"Absol\": {\n            \"dominant_color\": 0,      \n            \"primary_form\": 0,   \n            \"key_trait\": 0,      \n            \"body_shape\": 0,    \n            \"background_scene\": 2   \n        },\n        \"Absol G\": {\n            \"dominant_color\": 0,      \n            \"primary_form\": 0,   \n            \"key_trait\": 0,       \n            \"body_shape\": 0,     \n            \"background_scene\": 0    \n        },\n        // ...\n    }\n}\n</code></pre><p>最終的な分類は、これらの属性確率を組み合わせます - 単一の類似度比較の代わりに、複数の構造化された比較を行い、より情報に基づいた決定を行うためにそれらの確率を集約します。</p><pre><code class=\"language-python\"># Classification process\ndef classify_pokemon(image):\n   # Generate all text prompts\n   all_prompts = []\n   for group in classification_cot:\n       for option in group[\"options\"]:\n           prompt = group[\"prompt\"].format(option)\n           all_prompts.append(prompt)\n\n   # Get embeddings and similarities\n   image_embedding = model.encode_image(image)\n   text_embeddings = model.encode_text(all_prompts)\n   similarities = cosine_similarity(image_embedding, text_embeddings)\n\n   # Convert to probabilities per attribute group\n   probabilities = {}\n   for group_name, group_sims in group_similarities:\n       probabilities[group_name] = softmax(group_sims)\n\n   # Score each Pokemon based on matching attributes\n   scores = {}\n   for pokemon, rules in pokemon_rules.items():\n       score = 0\n       for group, target_idx in rules.items():\n           score += probabilities[group][target_idx]\n       scores[pokemon] = score\n\n   return max(scores, key=scores.get)</code></pre><h3 id=\"complexity-analysis\">複雑さの分析</h3><p>画像を <code>N</code> 個のポケモンの名前のいずれかに分類したいとします。ベースラインのアプローチでは、<code>N</code> 個のテキスト埋め込み（各ポケモンの名前に1つずつ）を計算する必要があります。対照的に、私たちのスケーリングされたテスト時の計算アプローチでは、<code>Q</code> 個のテキスト埋め込みを計算する必要があります。ここで、</p><code>Q</code> は、すべての質問におけるオプションと質問の組み合わせの総数です。両方の手法では、1つの画像埋め込みの計算と最終的な分類ステップが必要ですが、これらの共通の処理は比較から除外しています。このケーススタディでは、<code>N=13</code>、<code>Q=52</code> となっています。</p><p>極端なケースで <code>Q = N</code> の場合、我々のアプローチはベースラインと本質的に同じになります。しかし、テスト時の計算をより効果的にスケールさせるためのポイントは：</p><ul><li><code>Q</code> を増やすように慎重に選ばれた質問を作成する</li><li>各質問が最終的な答えについて異なる有益な手がかりを提供することを確認する</li><li>質問が可能な限り直交するように設計し、共同情報利得を最大化する</li></ul><p>このアプローチは「20の質問」ゲームに似ており、各質問は可能な答えを効果的に絞り込むために戦略的に選ばれます。</p><h3 id=\"evaluation\">評価</h3><p>評価は13種類のポケモンクラスにわたる117のテスト画像で実施されました。結果は以下の通りです：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>jina-clip-v1</th>\n<th>jina-clip-v2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Baseline</td>\n<td>31.36%</td>\n<td>16.10%</td>\n</tr>\n<tr>\n<td>CoT</td>\n<td>46.61%</td>\n<td>38.14%</td>\n</tr>\n<tr>\n<td>Improvement</td>\n<td>+15.25%</td>\n<td>+22.04%</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>同じ CoT 分類が、この一般的ではない、もしくは OOD タスクにおいて、両モデルで大幅な改善（それぞれ +15.25% と +22.04%）をもたらしていることがわかります。これは <code>pokemon_system</code> が構築されれば、<strong>同じ CoT システムを異なるモデル間で効果的に転移できること、そしてファインチューニングやポストトレーニングが不要であること</strong>を示しています。</p><p>v1 のポケモン分類におけるベースラインのパフォーマンス（31.36%）が比較的高いことは注目に値します。このモデルは<a href=\"https://www.youtube.com/watch?v=HsGyxVUN1SA&ref=jina-ai-gmbh.ghost.io\">ポケモン関連のコンテンツを含む LAION-400M で訓練されました</a>。一方、v2 は DFN-2B（400M インスタンスをサブサンプリング）で訓練され、より質の高いがフィルタリングされたデータセットであり、ポケモン関連のコンテンツが除外されていた可能性があり、このタスクにおける v2 の低いベースラインパフォーマンス（16.10%）を説明しています。</p><h3 id=\"constructing-pokemonsystem-effectively\">効果的な <code>pokemon_system</code> の構築</h3><p>スケールされたテスト時の計算アプローチの効果は、<code>pokemon_system</code> をどれだけうまく構築できるかに大きく依存します。このシステムを構築するには、手動から完全自動化まで、さまざまなアプローチがあります。</p><h4 id=\"manual-construction\">手動構築</h4><p>最も直接的なアプローチは、ポケモンデータセットを手動で分析し、属性グループ、プロンプト、ルールを作成することです。ドメインエキスパートは、色、形状、特徴的な要素などの主要な視覚的属性を特定する必要があります。その後、各属性に対する自然言語プロンプトを作成し、各属性グループの可能なオプションを列挙し、各ポケモンを正しい属性オプションにマッピングします。これは高品質なルールを提供しますが、時間がかかり、より大きな <code>N</code> へのスケーリングが難しくなります。</p><h4 id=\"llm-assisted-construction\">LLM 支援による構築</h4><p>分類システムを生成するようLLMにプロンプトを与えることで、このプロセスを加速できます。適切に構造化されたプロンプトは、視覚的特徴に基づく属性グループ、自然言語プロンプトテンプレート、包括的で相互排他的なオプション、そして各ポケモンのマッピングルールを要求します。LLM は素早く最初の草案を生成できますが、その出力は検証が必要かもしれません。</p><pre><code class=\"language-txt\">I need help creating a structured system for Pokemon classification. For each Pokemon in this list: [Absol, Aerodactyl, Weedle, Caterpie, Azumarill, ...], create a classification system with:\n\n1. Classification groups that cover these visual attributes:\n   - Dominant color of the Pokemon\n   - What type of creature it appears to be (primary form)\n   - Its most distinctive visual feature\n   - Overall body shape\n   - What kind of background/environment it's typically shown in\n\n2. For each group:\n   - Create a natural language prompt template using \"{}\" for the option\n   - List all possible options that could apply to these Pokemon\n   - Make sure options are mutually exclusive and comprehensive\n\n3. Create rules that map each Pokemon to exactly one option per attribute group, using indices to reference the options\n\nPlease output this as a Python dictionary with two main components:\n- \"classification_groups\": containing prompts and options for each attribute\n- \"pokemon_rules\": mapping each Pokemon to its correct attribute indices\n\nExample format:\n{\n    \"classification_groups\": {\n        \"dominant_color\": {\n            \"prompt\": \"This Pokemon's body is mainly {} in color\",\n            \"options\": [\"white\", \"gray\", ...]\n        },\n        ...\n    },\n    \"pokemon_rules\": {\n        \"Absol\": {\n            \"dominant_color\": 0,  # index for \"white\"\n            ...\n        },\n        ...\n    }\n}</code></pre><p>より堅牢なアプローチは、LLM による生成と人間による検証を組み合わせることです。まず、LLM が初期システムを生成します。次に、人間の専門家が属性グループ、オプションの完全性、ルールの正確性を確認して修正します。LLM はこのフィードバックに基づいてシステムを改良し、満足のいく品質が得られるまでこのプロセスを繰り返します。このアプローチは効率性と正確性のバランスを取ります。</p><h4 id=\"automated-construction-with-dspy\">DSPy を使用した自動構築</h4><p>完全に自動化されたアプローチとして、DSPy を使用して <code>pokemon_system</code> を反復的に最適化することができます。このプロセスは、手動または LLM で書かれた単純な <code>pokemon_system</code> を初期プロンプトとして始まります。各バージョンはホールドアウトセットで評価され、精度を DSPy へのフィードバック信号として使用します。このパフォーマンスに基づいて、最適化されたプロンプト（つまり、<code>pokemon_system</code> の新バージョン）が生成されます。このサイクルは収束するまで繰り返され、この全プロセスの間、埋め込みモデルは完全に固定されたままです。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--13-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/banner--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/banner--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner--13-.png 1200w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">DSPy を使用して最適な </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>pokemon_system</span></code><span style=\"white-space: pre-wrap;\"> CoT デザインを見つける；チューニングプロセスは各タスクに対して1回だけ行えばよい。</span></figcaption></figure><h2 id=\"why-scale-test-time-compute-for-embedding-models\">埋め込みモデルのテスト時計算をスケールする理由</h2><p>事前学習のスケーリングが最終的に経済的に実現不可能になるためです。</p><p>Jina 埋め込みスイート（<code>jina-embeddings-v1</code>、<code>v2</code>、<code>v3</code>、<code>jina-clip-v1</code>、<code>v2</code>、<code>jina-ColBERT-v1</code>、<code>v2</code> を含む）のリリース以来、スケールされた事前学習を通じた各モデルのアップグレードにはより多くのコストがかかっています。例えば、2023年6月にリリースされた最初のモデル <code>jina-embeddings-v1</code> は110Mパラメータでした。当時の訓練コストは、測定方法によって5,000ドルから10,000ドルの間でした。<code>jina-embeddings-v3</code> では改善は顕著ですが、それは主に投入された資源の増加によるものです。フロンティアモデルのコスト軌道は、数千ドルから数万ドル、そして大手AI企業では今日では数億ドルにまで上っています。事前学習により多くのお金、リソース、データを投入することで、より良いモデルが得られますが、限界収益は最終的に更なるスケーリングを経済的に持続不可能にします。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/12/plot--1-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"2003\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/plot--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/plot--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/plot--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/plot--1-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">埋め込みモデルのスケーリング則。英語タスクにおける平均 MTEB パフォーマンスをモデルパラメータ数に対してプロットしています。各点は埋め込みモデルを表します。すべてのモデルを表す傾向線がハイライトされ、多言語モデルは水色の点で示されています。このグラフは MTEB リーダーボードから上位100の埋め込みモデルを選択し、サイズ情報のない（通常はクローズドソースまたはプロプライエタリな）モデルを除外して作成されました。明らかなトロール投稿と識別されたものも除外されています。</span></figcaption></figure><p>一方で、現代の埋め込みモデルはますますパワフルになっています：多言語、マルチタスク、マルチモーダル、そしてゼロショットや指示に従う強力な性能を備えています。この汎用性は、アルゴリズムの改善とテスト時計算のスケーリングに大きな余地を残しています。</p><p>そこで問題となるのは、ユーザーが深く気にかけるクエリに対してどの程度のコストを払う意思があるかということです。固定された事前学習モデルで推論時間が長くなることを許容することで結果の質が大幅に向上するのであれば、多くの人々はそれを価値があると考えるでしょう。我々の見解では、埋め込みモデルのテスト時計算のスケーリングには大きな未開拓の可能性があります。これは、単にトレーニング時のモデルサイズを増やすことから、より良いパフォーマンスを達成するために推論フェーズでの計算努力を強化することへのシフトを表しています。</p><h2 id=\"conclusion\">結論</h2><p><code>jina-clip-v1/v2</code> のテスト時計算に関するケーススタディから、以下の主要な発見が得られました：</p><ol><li>埋め込みのファインチューニングやポストトレーニングを行わずに、一般的でないデータや分布外（OOD）データでより良いパフォーマンスを達成しました。</li><li>類似度検索と分類基準を反復的に改善することで、システムはより微妙な区別を行えるようになりました。</li><li>動的なプロンプト調整と反復的な推論を組み込むことで、埋め込みモデルの推論プロセスを単一のクエリから、より洗練された思考の連鎖へと変換しました。</li></ol><p>このケーススタディは、テスト時計算で可能なことの表面をかすっただけです。アルゴリズム的なスケーリングにはまだ大きな余地があります。例えば、「20の質問」ゲームの最適な戦略のように、解答空間を最も効率的に絞り込む質問を反復的に選択する方法を開発できます。テスト時計算をスケールすることで、埋め込みモデルを現在の限界を超えて押し進め、かつては手の届かないと思われた、より複雑で微妙なタスクに取り組めるようにすることができます。</p>",
  "comment_id": "675a84f80ce9930001b86f09",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/12/test-time-compute.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-12-12T07:38:48.000+01:00",
  "updated_at": "2024-12-12T17:54:17.000+01:00",
  "published_at": "2024-12-12T17:54:17.000+01:00",
  "custom_excerpt": "Better results scale with compute—more on learning, more on search. A good pretrained model takes you far, but test-time compute takes you further. It's important to recognize this new paradigm of scaling test-time compute, even for embedding models.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "633ffc6b393501004d1c8659",
      "name": "Han Xiao",
      "slug": "han",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
      "cover_image": null,
      "bio": "Founder & CEO of Jina AI",
      "website": null,
      "location": null,
      "facebook": null,
      "twitter": "@hxiao",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "633ffc6b393501004d1c8659",
    "name": "Han Xiao",
    "slug": "han",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png",
    "cover_image": null,
    "bio": "Founder & CEO of Jina AI",
    "website": null,
    "location": null,
    "facebook": null,
    "twitter": "@hxiao",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/han/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/scaling-test-time-compute-for-embedding-models/",
  "excerpt": "より良い結果はコンピュート量に比例して向上します—より多くの学習、より多くの探索に。優れた事前学習モデルは大きな成果をもたらしますが、テスト時のコンピュート量を増やすことでさらなる向上が得られます。埋め込みモデルであっても、テスト時のコンピュート量をスケールさせるという新しいパラダイムを認識することが重要です。",
  "reading_time": 11,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}