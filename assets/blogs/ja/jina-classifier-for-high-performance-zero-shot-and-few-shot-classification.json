{
  "slug": "jina-classifier-for-high-performance-zero-shot-and-few-shot-classification",
  "id": "6711fbbd708dbe0001924974",
  "uuid": "65c883e0-556a-4079-b07a-66e9e9926717",
  "title": "ゼロショットおよびフューショット分類のための Jina Classifier API による高性能分類",
  "html": "<p>分類は埋め込みの一般的なダウンストリームタスクです。テキスト埋め込みは、スパム検出や感情分析のためにテキストを事前定義されたラベルに分類できます。<code>jina-clip-v1</code>のようなマルチモーダル埋め込みは、コンテンツベースのフィルタリングやタグ付けに適用できます。最近では、複雑さとコストに基づいて適切なLLMにクエリをルーティングする際にも分類が使用されています。たとえば、単純な算術クエリは小規模な言語モデルにルーティングされ、複雑な推論タスクはより強力だが高コストなLLMに転送されます。</p><p>本日、Jina AI の Search Foundation の新しい<strong>Classifier API</strong>を紹介します。<strong>ゼロショット</strong>と<strong>フューショット</strong>のオンライン分類をサポートし、<code>jina-embeddings-v3</code>や<code>jina-clip-v1</code>などの最新の埋め込みモデルを基盤としています。Classifier APIは<a href=\"https://jmlr.org/papers/v7/crammer06a.html?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">オンラインパッシブアグレッシブ学習</a>に基づいており、リアルタイムで新しいデータに適応することができます。ユーザーはゼロショット分類器から始めて即座に使用を開始できます。その後、新しい例を提出したり、コンセプトドリフトが発生した場合に、分類器を段階的に更新することができます。これにより、大量の初期ラベル付きデータ<em>なしに</em>、様々なコンテンツタイプに対して効率的でスケーラブルな分類が可能になります。ユーザーは自分の分類器を公開して公共利用に供することもできます。今後リリース予定の多言語対応<code>jina-clip-v2</code>などの新しい埋め込みがリリースされた際には、ユーザーは Classifier API を通じて即座にアクセスでき、最新の分類機能を確保できます。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/classifier?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Classifier API</div><div class=\"kg-bookmark-description\">High performance classifier for image and text classification.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-classifier.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h2 id=\"zero-shot-classification\">ゼロショット分類</h2><p>Classifier API は強力なゼロショット分類機能を提供し、ラベル付きデータによる事前学習なしでテキストや画像を分類することができます。すべての分類器はゼロショット機能から始まり、後で追加の学習データやアップデートで強化することができます - これについては次のセクションで説明します。</p><h3 id=\"example-1-route-llm-requests\">例 1：LLM リクエストのルーティング</h3><p>以下は、LLM クエリのルーティングに Classifier API を使用する例です：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-embeddings-v3\",\n    \"labels\": [\n      \"Simple task\",\n      \"Complex reasoning\",\n      \"Creative writing\"\n    ],\n    \"input\": [\n      \"Calculate the compound interest on a principal of $10,000 invested for 5 years at an annual rate of 5%, compounded quarterly.\",\n      \"分析使用CRISPR基因编辑技术在人类胚胎中的伦理影响。考虑潜在的医疗益处和长期社会后果。\",\n      \"AIが自意識を持つディストピアの未来を舞台にした短編小説を書いてください。人間とAIの関係や意識の本質をテーマに探求してください。\",\n      \"Erklären Sie die Unterschiede zwischen Merge-Sort und Quicksort-Algorithmen in Bezug auf Zeitkomplexität, Platzkomplexität und Leistung in der Praxis.\",\n      \"Write a poem about the beauty of nature and its healing power on the human soul.\",\n      \"Translate the following sentence into French: The quick brown fox jumps over the lazy dog.\"\n    ]\n  }'</code></pre><p>この例では、<code>jina-embeddings-v3</code>を使用して、複数の言語（英語、中国語、日本語、ドイツ語）のユーザークエリを3つのカテゴリに分類し、3つの異なるサイズのLLMに対応させています。API のレスポンス形式は以下の通りです：</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 256, \"prompt_tokens\": 256},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Simple task\", \"score\": 0.35216382145881653},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Complex reasoning\", \"score\": 0.34310275316238403},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Creative writing\", \"score\": 0.3487184941768646},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Complex reasoning\", \"score\": 0.35207709670066833},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Creative writing\", \"score\": 0.3638903796672821},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Simple task\", \"score\": 0.3561534285545349}\n  ]\n}</code></pre><p>レスポンスには以下が含まれます：</p><ul><li><code>usage</code>：トークン使用量に関する情報。</li><li><code>data</code>：各入力に対する分類結果の配列。<ul><li>各結果には予測されたラベル（<code>prediction</code>）と信頼度スコア（<code>score</code>）が含まれます。各クラスの<code>score</code>はソフトマックス正規化により計算されます - ゼロショットの場合は<a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model?ref=jina-ai-gmbh.ghost.io#parameter-task\" rel=\"noreferrer\"><code>classification</code>タスク-LoRA</a>の下での入力とラベルの埋め込み間のコサイン類似度に基づき、フューショットの場合は各クラスの入力埋め込みの学習済み線形変換に基づいており、すべてのクラスにわたって確率の合計が1になります。</li><li><code>index</code>は元のリクエストにおける入力の位置に対応します。</li></ul></li></ul><h3 id=\"example-2-categorize-image-text\">例 2：画像とテキストの分類</h3><p><code>jina-clip-v1</code>を使用したマルチモーダルの例を見てみましょう。このモデルはテキストと画像の両方を分類できるため、様々なメディアタイプのコンテンツ分類に理想的です。以下のような API 呼び出しを考えてみましょう：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY_HERE\" \\\n  -d '{\n    \"model\": \"jina-clip-v1\",\n    \"labels\": [\n      \"Food and Dining\",\n      \"Technology and Gadgets\",\n      \"Nature and Outdoors\",\n      \"Urban and Architecture\"\n    ],\n    \"input\": [\n      {\"text\": \"A sleek smartphone with a high-resolution display and multiple camera lenses\"},\n      {\"text\": \"Fresh sushi rolls served on a wooden board with wasabi and ginger\"},\n      {\"image\": \"https://picsum.photos/id/11/367/267\"},\n      {\"image\": \"https://picsum.photos/id/22/367/267\"},\n      {\"text\": \"Vibrant autumn leaves in a dense forest with sunlight filtering through\"},\n      {\"image\": \"https://picsum.photos/id/8/367/267\"}\n    ]\n  }'</code></pre><p>リクエストで画像をアップロードする方法に注目してください。画像を表現するために<code>base64</code>文字列を使用することもできます。API は以下のような分類結果を返します：</p><pre><code class=\"language-json\">{\n  \"usage\": {\"total_tokens\": 12125, \"prompt_tokens\": 12125},\n  \"data\": [\n    {\"object\": \"classification\", \"index\": 0, \"prediction\": \"Technology and Gadgets\", \"score\": 0.30329811573028564},\n    {\"object\": \"classification\", \"index\": 1, \"prediction\": \"Food and Dining\", \"score\": 0.2765541970729828},\n    {\"object\": \"classification\", \"index\": 2, \"prediction\": \"Nature and Outdoors\", \"score\": 0.29503118991851807},\n    {\"object\": \"classification\", \"index\": 3, \"prediction\": \"Urban and Architecture\", \"score\": 0.2648046910762787},\n    {\"object\": \"classification\", \"index\": 4, \"prediction\": \"Nature and Outdoors\", \"score\": 0.3133063316345215},\n    {\"object\": \"classification\", \"index\": 5, \"prediction\": \"Technology and Gadgets\", \"score\": 0.27474141120910645}\n  ]\n}</code></pre><h3 id=\"example-3-detect-if-jina-reader-gets-genuine-content\">例 3：Jina Reader が本物のコンテンツを取得しているかの検出</h3><p>ゼロショット分類の興味深い応用として、<a href=\"https://jina.ai/reader?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina Reader</a>を通じたウェブサイトのアクセシビリティ判定があります。一見単純なタスクに見えますが、実際には非常に複雑です。ブロックメッセージはサイトごとに大きく異なり、様々な言語で表示され、異なる理由（ペイウォール、レート制限、サーバーダウンなど）を引用します。この多様性により、正規表現や固定ルールですべてのシナリオを捕捉することは困難です。</p><pre><code class=\"language-python\">import requests\nimport json\n\nresponse1 = requests.get('https://r.jina.ai/https://jina.ai')\n\nurl = 'https://api.jina.ai/v1/classify'\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer $YOUR_API_KEY_HERE'\n}\ndata = {\n    'model': 'jina-embeddings-v3',\n    'labels': ['Blocked', 'Accessible'],\n    'input': [{'text': response1.text[:8000]}]\n}\nresponse2 = requests.post(url, headers=headers, data=json.dumps(data))\n\nprint(response2.text)</code></pre><p>このスクリプトは<code>r.jina.ai</code>を通じてコンテンツを取得し、Classifier API を使用して<code>\"Blocked\"</code>または<code>\"Accessible\"</code>に分類します。たとえば、<a href=\"https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://www.crunchbase.com/organization/jina-ai</a>はアクセス制限により<code>\"Blocked\"</code>に分類される可能性が高く、一方<a href=\"https://r.jina.ai/https://jina.ai?ref=jina-ai-gmbh.ghost.io\">https://r.jina.ai/https://jina.ai</a>は\"Accessible\"となるはずです。</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\"usage\":{\"total_tokens\":185,\"prompt_tokens\":185},\"data\":[{\"object\":\"classification\",\"index\":0,\"prediction\":\"Blocked\",\"score\":0.5392698049545288}]}</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">Classifier API は Jina Reader からの本物のコンテンツとブロックされた結果を効果的に区別できます。</span></p></figcaption></figure><p>この例では<code>jina-embeddings-v3</code>を活用し、特に多言語環境でのコンテンツ集約やウェブスクレイピングシステムに有用な、ウェブサイトのアクセシビリティを監視する迅速な自動化された方法を提供します。</p><h3 id=\"example-4-filtering-statements-from-opinions-for-grounding\">例 4：グラウンディングのための意見からの事実の抽出</h3><p>ゼロショット分類のもう一つの興味深い応用例は、長文の中から意見から事実のような主張をフィルタリングすることです。分類器自体は、何かが事実かどうかを判定することはできないことに注意してください。代わりに、<em>事実の形式で書かれたテキスト</em>を識別し、それを検証用の grounding API（通常かなり高価です）で確認することができます。この2段階のプロセスが効果的な事実確認の鍵となります：まず意見や感情をフィルタリングし、残った文章を grounding に送ります。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/fact-checking-with-new-grounding-api-in-jina-reader?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Fact-Checking with New Grounding API in Jina Reader</div><div class=\"kg-bookmark-description\">With the new g.jina.ai, you can easily ground statements to reduce LLM hallucinations or improve the integrity of human-written content.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Google Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/grounding.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>1960年代の宇宙開発競争についての以下のパラグラフを考えてみましょう：</p><pre><code class=\"language-json\">The Space Race of the 1960s was a breathtaking testament to human ingenuity. When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era. The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance. NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973. While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent. On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars. The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination. The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle.\n</code></pre><p>このテキストは意図的に異なる種類の文章を混ぜ合わせています - 事実のような主張（「スプートニク 1 号は 1959 年 10 月 4 日に打ち上げられた」など）から、明確な意見（「人間の創意工夫の息をのむような証」）、感情的な表現（「何百万人の心に恐怖を抱かせた」）、解釈的な主張（「新時代の疑う余地のない始まりを示す」）まで。</p><p>ゼロショット分類器の役割は<strong>純粋に意味的</strong>です - テキストが事実として書かれているか、意見や解釈として書かれているかを識別します。例えば、<code>\"The Soviet Union launched Sputnik 1 on October 4, 1959\"</code> は事実として書かれていますが、<code>\"The Space Race was a breathtaking testament\"</code> は明らかに意見として書かれています。</p><pre><code class=\"language-python\">headers = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {API_KEY}'\n}\n\n# Step 1: Split text and classify\nchunks = [chunk.strip() for chunk in text.split('.') if chunk.strip()]\nlabels = [\n    \"subjective, opinion, feeling, personal experience, creative writing, position\",\n    \"fact\"\n]\n\n# Classify chunks\nclassify_response = requests.post(\n    'https://api.jina.ai/v1/classify',\n    headers=headers,\n    json={\n        \"model\": \"jina-embeddings-v3\",\n        \"input\": [{\"text\": chunk} for chunk in chunks],\n        \"labels\": labels\n    }\n)\n\n# Sort chunks\nsubjective_chunks = []\nfactual_chunks = []\nfor chunk, classification in zip(chunks, classify_response.json()['data']):\n    if classification['prediction'] == labels[0]:\n        subjective_chunks.append(chunk)\n    else:\n        factual_chunks.append(chunk)\n\nprint(\"\\nSubjective statements:\", subjective_chunks)\nprint(\"\\nFactual statements:\", factual_chunks)</code></pre><p>結果は以下のようになります：</p><pre><code class=\"language-json\">Subjective statements: ['The Space Race of the 1960s was a breathtaking testament to human ingenuity', 'The silvery beeping of that simple satellite struck fear into the hearts of millions, as if the very stars had betrayed Western dominance', 'While some cynics claimed this was a waste of resources, the technological breakthroughs were absolutely worth every penny spent', \"The Soviet space program, despite its early victories, ultimately couldn't match the superior American engineering and determination\"]\n\nFactual statements: ['When the Soviet Union launched Sputnik 1 on October 4, 1957, it sent shockwaves through American society, marking the undeniable start of a new era', \"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\", \"On July 20, 1969, Neil Armstrong and Buzz Aldrin achieved the most magnificent triumph in human history by walking on the moon, their footprints marking humanity's destiny among the stars\", 'The moon landing was not just a victory for America - it represented the most inspiring moment in human civilization, proving that our species was meant to reach beyond our earthly cradle']</code></pre><p>事実として書かれているからといって、それが真実であるとは限らないことを覚えておいてください。そのため、2番目のステップ - これらの事実のような主張を grounding API に送って実際の事実検証を行う必要があります。例えば、以下の文を検証してみましょう：<code>\"NASA was founded in 1958 as America's response, and they poured an astounding $28 billion into the Apollo program between 1960 and 1973\"</code>。以下のコードで検証します。</p><pre><code class=\"language-python\">ground_headers = {\n        'Accept': 'application/json',\n        'Authorization': f'Bearer {API_KEY}'\n    }\n\nground_response = requests.get(\n    f'https://g.jina.ai/{quote(factual_chunks[1])}',\n    headers=ground_headers\n)\n\nprint(ground_response.json())</code></pre><p>結果は以下のようになります：</p><pre><code class=\"language-json\">{'code': 200, 'status': 20000, 'data': {'factuality': 1, 'result': True, 'reason': \"The statement is supported by multiple references confirming NASA's founding in 1958 and the significant financial investment in the Apollo program. The $28 billion figure aligns with the data provided in the references, which detail NASA's expenditures during the Apollo program from 1960 to 1973. Additionally, the context of NASA's budget peaking during this period further substantiates the claim. Therefore, the statement is factually correct based on the available evidence.\", 'references': [{'url': 'https://en.wikipedia.org/wiki/Budget_of_NASA', 'keyQuote': \"NASA's budget peaked in 1964–66 when it consumed roughly 4% of all federal spending. The agency was building up to the first Moon landing and the Apollo program was a top national priority, consuming more than half of NASA's budget.\", 'isSupportive': True}, {'url': 'https://en.wikipedia.org/wiki/NASA', 'keyQuote': 'Established in 1958, it succeeded the National Advisory Committee for Aeronautics (NACA)', 'isSupportive': True}, {'url': 'https://nssdc.gsfc.nasa.gov/planetary/lunar/apollo.html', 'keyQuote': 'More details on Apollo lunar landings', 'isSupportive': True}, {'url': 'https://usafacts.org/articles/50-years-after-apollo-11-moon-landing-heres-look-nasas-budget-throughout-its-history/', 'keyQuote': 'NASA has spent its money so far.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/history/', 'keyQuote': 'Discover the history of our human spaceflight, science, technology, and aeronautics programs.', 'isSupportive': True}, {'url': 'https://www.nasa.gov/the-apollo-program/', 'keyQuote': 'Commander for Apollo 11, first to step on the lunar surface.', 'isSupportive': True}, {'url': 'https://www.planetary.org/space-policy/cost-of-apollo', 'keyQuote': 'A rich data set tracking the costs of Project Apollo, free for public use. Includes unprecedented program-by-program cost breakdowns.', 'isSupportive': True}, {'url': 'https://www.statista.com/statistics/1342862/nasa-budget-project-apollo-costs/', 'keyQuote': 'NASA&amp;#x27;s monetary obligations compared to Project Apollo&amp;#x27;s total costs from 1960 to 1973 (in million U.S. dollars)', 'isSupportive': True}], 'usage': {'tokens': 10640}}}</code></pre><p>事実性スコア 1 で、grounding API はこの声明が歴史的事実に十分裏付けられていることを確認しています。このアプローチは、歴史的文書の分析からニュース記事のリアルタイムな事実確認まで、魅力的な可能性を開きます。ゼロショット分類と事実検証を組み合わせることで、自動化された情報分析のための強力なパイプラインを作成します - まず意見をフィルタリングし、残りの声明を信頼できるソースで検証します。</p><h3 id=\"remarks-on-zero-shot-classification\">ゼロショット分類に関する注意点</h3><h4 id=\"using-semantic-labels\">セマンティックラベルの使用</h4><p>ゼロショット分類を扱う際は、<strong>抽象的な記号や数字ではなく、意味的に有意義なラベルを使用することが重要</strong>です。例えば、<code>\"Class1\"</code>、<code>\"Class2\"</code>、<code>\"Class3\"</code> や <code>\"0\"</code>、<code>\"1\"</code>、<code>\"2\"</code> よりも、<code>\"Technology\"</code>、<code>\"Nature\"</code>、<code>\"Food\"</code> の方がはるかに効果的です。<code>\"Positive\"</code> や <code>\"True\"</code> よりも <code>\"Positive sentiment\"</code> の方が効果的です。埋め込みモデルは意味的な関係を理解するので、説明的なラベルを使用することで、より正確な分類のために事前学習された知識を活用することができます。以前の投稿では、より良い分類結果を得るための効果的なセマンティックラベルの作成方法について詳しく説明しています。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/rephrased-labels-improve-zero-shot-text-classification-30?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Rephrased Labels Improve Zero-Shot Text Classification by 30%</div><div class=\"kg-bookmark-description\">When using embedding models for zero-shot classification, rephrasing the class label to \"This is seriously about 'LABEL'\" gives higher accuracy vs. using LABEL alone. But how, and why?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/07/Heading.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"stateless-nature\">ステートレスな性質</h4><p>ゼロショット分類は、従来の機械学習アプローチとは異なり、根本的にステートレスです。<strong>これは、同じ入力とモデルが与えられた場合、API を使用する人や時期に関係なく、結果は常に一貫することを意味します。</strong>モデルは実行した分類に基づいて学習や更新を行いません。各タスクは独立しています。これにより、セットアップやトレーニングなしで即座に使用でき、API 呼び出し間でカテゴリを変更する柔軟性が得られます。</p><p>このステートレスな性質は、次に説明するフューショットやオンライン学習アプローチとは大きく異なります。これらの手法では、モデルは新しい例に適応でき、時間の経過やユーザー間で異なる結果が得られる可能性があります。</p><h2 id=\"few-shot-classification\">フューショット分類</h2><p>フューショット分類は、最小限のラベル付きデータで分類器を作成・更新する簡単なアプローチを提供します。この方法は、<code>train</code> と <code>classify</code> の 2 つの主要なエンドポイントを提供します。</p><p><code>train</code> エンドポイントでは、少数の例で分類器を作成または更新できます。<code>train</code> への最初の呼び出しは<code>classifier_id</code> を使用することで、新しいデータがある場合やデータ分布の変化、または新しいクラスを追加する必要がある場合に、後続のトレーニングに使用できます。この柔軟なアプローチにより、分類器は時間とともに進化し、新しいパターンやカテゴリーに適応することができ、一からやり直す必要がありません。</p><p>ゼロショット分類と同様に、予測には <code>classify</code> エンドポイントを使用します。主な違いは、リクエストに <code>classifier_id</code> を含める必要がありますが、候補ラベルは訓練済みモデルの一部としてすでに含まれているため、提供する必要がありません。</p><h3 id=\"example-train-a-support-ticket-assigner\">例：サポートチケット割り当てシステムの訓練</h3><p>急成長中のテックスタートアップで、カスタマーサポートチケットを異なるチームに割り当てる分類の例を見てみましょう。</p><h4 id=\"initial-training\">初期トレーニング</h4><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"model\": \"jina-embeddings-v3\",\n  \"access\": \"private\",\n  \"input\": [\n    {\n      \"text\": \"I cant log into my account after the latest app update.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"My subscription renewal failed due to an expired credit card.\",\n      \"label\": \"team2\"\n    },\n    {\n      \"text\": \"How do I export my data from the platform?\",\n      \"label\": \"team3\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><p>フューショット学習では、意味的な意味を持たなくても、クラスラベルとして <code>team1</code> <code>team2</code> を自由に使用できます。レスポンスでは、この新しく作成された分類器を表す <code>classifier_id</code> が得られます。</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-json\">{\n  \"classifier_id\": \"918c0846-d6ae-4f34-810d-c0c7a59aee14\",\n  \"num_samples\": 3,\n}\n</code></pre><figcaption><p><span style=\"white-space: pre-wrap;\">この </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>classifier_id</span></code><span style=\"white-space: pre-wrap;\"> をメモしておいてください。後でこの分類器を参照する際に必要になります。</span></p></figcaption></figure><h4 id=\"updating-classifier-to-adapt-team-restructuring\">チーム再編成に合わせた分類器の更新</h4><p>例の会社が成長するにつれ、新しいタイプの問題が発生し、チーム構造も変化します。フューショット分類の素晴らしい点は、これらの変更に素早く適応できることです。<code>classifier_id</code> と新しい例を提供することで、新しいチームカテゴリー（例：<code>team4</code>）を導入したり、組織の進化に合わせて既存の問題タイプを異なるチームに再割り当てしたりすることが簡単にできます。</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/train' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"Im getting a 404 error when trying to access the new AI chatbot feature.\",\n      \"label\": \"team4\"\n    },\n    {\n      \"text\": \"The latest security patch is conflicting with my company firewall.\",\n      \"label\": \"team1\"\n    },\n    {\n      \"text\": \"I need help setting up SSO for my organization account.\",\n      \"label\": \"team5\"\n    }\n  ],\n  \"num_iters\": 10\n}'</code></pre><h4 id=\"using-a-trained-classifier\">訓練済み分類器の使用</h4><p>推論時には、入力テキストと <code>classifier_id</code> を提供するだけです。API は入力と以前に訓練したクラス間のマッピングを処理し、分類器の現在の状態に基づいて最も適切なラベルを返します。</p><pre><code class=\"language-bash\">curl -X 'POST' \\\n  'https://api.jina.ai/v1/classify' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"classifier_id\": \"b36b7b23-a56c-4b52-a7ad-e89e8f5439b6\",\n  \"input\": [\n    {\n      \"text\": \"The new feature is causing my dashboard to load slowly.\"\n    },\n    {\n      \"text\": \"I need to update my billing information for tax purposes.\"\n    }\n  ]\n}'</code></pre><p>フューショットモードには 2 つの固有のパラメータがあります。</p><h3 id=\"parameter-numiters\">パラメータ <code>num_iters</code></h3><p><code>num_iters</code> パラメータは、分類器が訓練例からどの程度集中的に学習するかを調整します。デフォルト値の 10 はほとんどの場合うまく機能しますが、<strong>訓練データへの信頼度</strong>に基づいてこの値を戦略的に調整できます。分類に重要な高品質な例の場合は <code>num_iters</code> を増やして重要性を強化し、信頼性の低い例の場合は <code>num_iters</code> を下げて分類器のパフォーマンスへの影響を最小限に抑えます。このパラメータは、より最近の例に高い反復回数を設定することで、進化するパターンに適応しながら過去の知識を維持する時間認識学習を実装するためにも使用できます。</p><h3 id=\"parameter-access\">パラメータ <code>access</code></h3><p><code>access</code> パラメータを使用すると、分類器を使用できる人を制御できます。デフォルトでは、分類器はプライベートで、あなただけがアクセスできます。アクセスを \"public\" に設定すると、<code>classifier_id</code> を持っている人なら誰でも、<strong>自分の API キーとトークンクォータを使用して</strong>それを使用できます。これにより、プライバシーを維持しながら分類器を共有できます - ユーザーはあなたの訓練データや設定を見ることができず、あなたも彼らの分類リクエストを見ることができません。このパラメータはフューショット分類にのみ関連し、ゼロショット分類器はステートレスです。ゼロショット分類器を共有する必要はありません。なぜなら、誰がリクエストを行っても、同一のリクエストは常に同じレスポンスを生成するからです。</p><h3 id=\"remarks-on-few-shot-learning\">フューショット学習に関する注意点</h3><p>当社の API のフューショット分類には、注目すべきユニークな特徴があります。従来の機械学習モデルとは異なり、当社の実装では 1 パスのオンライン学習を使用しています - 訓練例は分類器の重みを更新するために処理されますが、その後は保存されません。これは過去の訓練データを取得できないことを意味しますが、プライバシーとリソースの効率性が向上します。</p><p>フューショット学習は強力ですが、ゼロショット分類のパフォーマンスを上回るためにはウォームアップ期間が必要です。当社のベンチマークでは、通常 200-400 の訓練例で優れたパフォーマンスを実現するのに十分なデータが得られることを示しています。ただし、すべてのクラスの例を最初から提供する必要はありません - 分類器は時間とともに新しいクラスに対応できるように拡張できます。ただし、新しく追加されたクラスは、十分な例が提供されるまでの間、短期的なコールドスタート期間やクラスの不均衡を経験する可能性があることに注意してください。</p><h2 id=\"benchmark\">ベンチマーク</h2><p>当社のベンチマーク分析では、感情検出（6 クラス）やスパム検出（2 クラス）などのテキスト分類タスク、CIFAR10（10 クラス）などの画像分類タスクにわたって、ゼロショットとフューショットのアプローチを評価しました。評価フレームワークは標準的な訓練-テスト分割を使用し、ゼロショットは訓練データを必要とせず、フューショットは訓練セットの一部を使用しました。制御された比較を可能にするため、訓練サイズと対象クラス数などの主要な指標を追跡しました。特にフューショット学習の堅牢性を確保するため、各入力は複数の訓練反復を経ました。これらの現代的なアプローチを、線形 SVM や RBF SVM などの従来のベースラインと比較し、そのパフォーマンスの文脈を提供しました。</p><figure class=\"kg-card kg-gallery-card kg-width-wide kg-card-hascaption\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Multi-class-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Image-classification.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div><div class=\"kg-gallery-image\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/10/Text-classification--1-.svg\" width=\"445\" height=\"460\" loading=\"lazy\" alt=\"\"></div></div></div><figcaption><p><span style=\"white-space: pre-wrap;\">F1 スコアがプロットされています。ベンチマークの詳細な設定については、</span><a href=\"https://docs.google.com/spreadsheets/d/15vK6VPlcAM4e7lSJw6IeVtTtyariXEVQurDTFKXwwtY/edit?gid=249584681&ref=jina-ai-gmbh.ghost.io#gid=249584681\"><span style=\"white-space: pre-wrap;\">この Google スプレッドシート</span></a><span style=\"white-space: pre-wrap;\">をご確認ください。</span></p></figcaption></figure><p>F1 プロットは 3 つのタスクにおいて興味深いパターンを示しています。予想通り、ゼロショット分類は、トレーニングデータのサイズに関係なく、最初から一定のパフォーマンスを示しています。対照的に、フューショット学習は急激な学習曲線を示し、最初は低い性能から始まりますが、トレーニングデータが増えるにつれてゼロショットのパフォーマンスを素早く上回ります。両方の手法は最終的に<strong>400 サンプル付近で同程度の精度に達します</strong>が、フューショットがわずかに優位を保っています。このパターンはマルチクラス分類と画像分類の両方のシナリオで当てはまり、フューショット学習はトレーニングデータが利用可能な場合に特に有利である一方、ゼロショットはトレーニング例がなくても信頼性の高いパフォーマンスを提供できることを示唆しています。以下の表は、API ユーザーの観点からゼロショットとフューショット分類の違いをまとめたものです。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Zero-shot</th>\n<th>Few-shot</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Primary Use Case</td>\n<td>Default solution for general classification</td>\n<td>For data outside v3/clip-v1's domain or time-sensitive data</td>\n</tr>\n<tr>\n<td>Training Data Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /train</td>\n<td>N/A</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Labels Required in /classify</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Classifier ID Required</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Semantic Labels Required</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>State Management</td>\n<td>Stateless</td>\n<td>Stateful</td>\n</tr>\n<tr>\n<td>Continuous Model Updates</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Access Control</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Maximum Classes</td>\n<td>256</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Classifiers</td>\n<td>N/A</td>\n<td>16</td>\n</tr>\n<tr>\n<td>Maximum Inputs per Request</td>\n<td>1,024</td>\n<td>1,024</td>\n</tr>\n<tr>\n<td>Maximum Token Length per Input</td>\n<td>8,192 tokens</td>\n<td>8,192 tokens</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"summary\">まとめ</h2><p>Classifier API は、<code>jina-embeddings-v3</code> や <code>jina-clip-v1</code> のような高度な埋め込みモデルを活用して、テキストと画像コンテンツの両方に対して強力なゼロショットおよびフューショット分類を提供します。ベンチマークによると、ゼロショット分類はトレーニングデータなしで信頼性の高いパフォーマンスを提供し、最大 256 クラスをサポートするため、ほとんどのタスクの優れた出発点となります。フューショット学習はトレーニングデータでわずかに良い精度を達成できますが、即座に結果が得られ柔軟性があるため、まずはゼロショット分類から始めることをお勧めします。</p><p>この API の汎用性により、LLM クエリのルーティングからウェブサイトのアクセシビリティ検出、多言語コンテンツの分類まで、さまざまなアプリケーションをサポートします。ゼロショットから始めるか、特殊なケースでフューショット学習に移行するかに関わらず、API はパイプラインへのシームレスな統合のために一貫したインターフェースを維持します。開発者の皆様がこの API をどのように活用されるのかを見るのが特に楽しみで、将来的には <code>jina-clip-v2</code> のような新しい埋め込みモデルのサポートも展開していく予定です。</p>",
  "comment_id": "6711fbbd708dbe0001924974",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/10/classifier-header-1.png",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-10-18T08:10:05.000+02:00",
  "updated_at": "2024-10-24T11:04:33.000+02:00",
  "published_at": "2024-10-22T10:57:15.000+02:00",
  "custom_excerpt": "New Classifier API offers zero-shot and few-shot classification for text and images. Start classifying content instantly or train it with your own examples.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-classifier-for-high-performance-zero-shot-and-few-shot-classification/",
  "excerpt": "新しい Classifier API により、テキストと画像のゼロショット分類およびフューショット分類が可能になりました。即座にコンテンツを分類できる他、独自の例を使って学習させることもできます。",
  "reading_time": 16,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract artistic portrait using a montage of colorful squares and scattered text.",
  "feature_image_caption": null
}