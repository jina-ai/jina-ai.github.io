{
  "slug": "jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking",
  "id": "66cd8fc6e84873000133d63d",
  "uuid": "e995c4d9-1832-4e2a-8108-e8453f5c82c5",
  "title": "Jina ColBERT v2：多言語遅延インタラクション型エンベディング・リランキング検索システム",
  "html": "<p>本日、ColBERT アーキテクチャをベースにした高度な後期相互作用型検索モデル Jina ColBERT v2（<code>jina-colbert-v2</code>）のリリースを発表できることを嬉しく思います。この新しい言語モデルは、<code>jina-colbert-v1-en</code> のパフォーマンスを向上させ、多言語サポートと動的な出力次元を追加しています。</p><p>この新リリースには以下の特徴があります：</p><ul><li>オリジナルの ColBERT-v2（+6.5%）や前バージョンの <code>jina-colbert-v1-en</code>（+5.4%）と比較して<strong>優れた検索性能</strong></li><li>89 言語に対応する<strong>多言語サポート</strong>で、主要なグローバル言語で高いパフォーマンスを発揮</li><li>マトリョーシカ表現学習による<strong>ユーザー制御可能な出力埋め込みサイズ</strong>で、効率性と精度のバランスを柔軟に調整可能</li></ul><h2 id=\"technical-summary-of-jina-colbert-v2\"><code>jina-colbert-v2</code> の技術概要</h2><p>技術報告の全文は arXiv で確認できます：</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://arxiv.org/abs/2408.16672?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever</div><div class=\"kg-bookmark-description\">Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">arXiv.org</span><span class=\"kg-bookmark-publisher\">Rohan Jha</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th><code>jina-colbert-v2</code></th>\n<th><code>jina-colbert-v1-en</code></th>\n<th>Original ColBERTv2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Average of 14 English<br/>BEIR tasks</td>\n<td><b>0.521</b></td>\n<td>0.494</td>\n<td>0.489</td>\n</tr>\n<tr>\n<td>Multilingual</td>\n<td><b>89 languages</b></td>\n<td>English-only</td>\n<td>English-only</td>\n</tr>\n<tr>\n<td>Output dimensions</td>\n<td><b>128, 96, or 64</b></td>\n<td>Fixed 128</td>\n<td>Fixed 128</td>\n</tr>\n<tr>\n<td>Max query length</td>\n<td>32 tokens</td>\n<td>32 tokens</td>\n<td>32 tokens</td>\n</tr>\n<tr>\n<td>Max document length</td>\n<td>8192 tokens</td>\n<td>8192 tokens</td>\n<td>512 tokens</td>\n</tr>  \n\n<tr>\n<td>Parameters</td>\n<td>560M</td>\n<td>137M</td>\n<td>110M</td>\n</tr>\n<tr>\n<td>Model size</td>\n<td>1.1GB</td>\n<td>550MB</td>\n<td>438MB</td>\n</tr>\n\n\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<h2 id=\"asymmetric-embedding-in-colbert\">ColBERT における非対称埋め込み</h2><p>ColBERT は BERT アーキテクチャに<strong>後期相互作用</strong>と<strong>非対称</strong>なクエリ・ドキュメントエンコーディングを追加して構築されています。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">What is ColBERT and Late Interaction and Why They Matter in Search?</div><div class=\"kg-bookmark-description\">Jina AI's ColBERT on Hugging Face has set Twitter abuzz, bringing a fresh perspective to search with its 8192-token capability. This article unpacks the nuances of ColBERT and ColBERTv2, showcasing their innovative designs and why their late interaction feature is a game-changer for search.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>ColBERT の非対称性は、<code>jina-colbert-v2</code> や <code>jina-colbert-v1-en</code> などのモデルを使用する際、クエリの埋め込み、ドキュメントの埋め込み、または両方（再ランク付け用）のいずれを行うかを指定する必要があることを意味します。この追加された柔軟性により、検索タスクにおいて均一な埋め込みモデルよりも優れたパフォーマンスを発揮します。</p><h2 id=\"multilingual-support-for-over-89-languages\">89 言語以上の多言語サポート</h2><p>Jina ColBERT v2 は、現代のグローバル化された情報検索と AI アプリケーションのニーズに応えるため、広範な多言語機能を備えています。<code>jina-colbert-v2</code> のトレーニングコーパスには 89 言語が含まれており、<strong>アラビア語、中国語、英語、フランス語、ドイツ語、日本語、ロシア語、スペイン語</strong>などの主要な国際言語および<strong>プログラミング言語</strong>に対する追加のトレーニングステージが含まれています。また、クロスリンガルの可能性を引き出すために対訳テキストコーパスも含まれており、再ランク付け/検索タスクで異なる言語のクエリとドキュメントをマッチングすることができます。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Distribution-of-the-languages-in-the-training-corpus-at-the-pretrained-stage--3-.svg\" class=\"kg-image\" alt=\"Chart of language distribution in training data, highlighting dominance of English and Chinese.\" loading=\"lazy\" width=\"1456\" height=\"743\"><figcaption><span style=\"white-space: pre-wrap;\">事前トレーニングデータセットの言語分布（</span><a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes?ref=jina-ai-gmbh.ghost.io\"><span style=\"white-space: pre-wrap;\">ISO-639</span></a><span style=\"white-space: pre-wrap;\">コードで指定）を対数スケールで表示。</span></figcaption></figure><p>現在、Jina ColBERT v2 はコンパクトな埋め込みを生成する<strong>唯一の多言語 ColBERT 型モデル</strong>であり、MIRACL ベンチマークでテストされたすべての言語で BM25 ベースの検索を大きく上回るパフォーマンスを示しています。</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-Multilingual-Data--1-.svg\" class=\"kg-image\" alt=\"Bar chart comparing jina-colbert-v2 and BM25 performance across 20 languages on multilingual tasks.\" loading=\"lazy\" width=\"691\" height=\"426\"><figcaption><span style=\"white-space: pre-wrap;\">MIRACL ベンチマークにおける 16 言語での Jina ColBERT v2 と BM25 の性能比較。</span></figcaption></figure><p>さらに、英語の検索タスクにおいて、Jina ColBERT v2 は前バージョンの <code>jina-colbert-v1-en</code> やオリジナルの ColBERT v2 モデルを上回り、英語専用の特化モデルである <a href=\"https://huggingface.co/answerdotai/answerai-colbert-small-v1?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">AnswerAI-ColBERT-small</a> と同等のパフォーマンスを示しています。</p>\n<!--kg-card-begin: html-->\n<table class=\"simple-table\">\n  <tbody>\n<thead>\n<tr>\n      <th><strong>モデル名</strong></th>\n      <th><strong>平均スコア<br>(14 BEIR 英語ベンチマーク)<br></strong></th>\n      <th><strong>多言語サポート</strong></th>\n  </tr>\n    </thead>\n    <tr>\n      <td><code>jina-colbert-v2</code></td>\n      <td>0.521</td>\n      <td>多言語</td>\n    </tr>\n    <tr>\n      <td><code>jina-colbert-v1-en</code></td>\n      <td>0.494</td>\n      <td>英語のみ</td>\n    </tr>\n    <tr>\n      <td>ColBERT v2.0</td>\n      <td>0.489</td>\n      <td>英語のみ</td>\n    </tr>\n    <tr>\n      <td>AnswerAI-ColBERT-small</td>\n      <td>0.549</td>\n      <td>英語のみ</td>\n    </tr>\n  </tbody>\n</table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Evaluation-on-English-only-datasets-from-BEIR--2-.svg\" class=\"kg-image\" alt=\"Bar chart showing model evaluations on English BEIR datasets, with several models like 'jina-colbert' and 'BM25'.\" loading=\"lazy\" width=\"1088\" height=\"712\"><figcaption><span style=\"white-space: pre-wrap;\">BEIR ベンチマークの英語データセットにおける jina-colbert-v2 の評価。</span></figcaption></figure><h2 id=\"matryoshka-representation-learning\">マトリョーシカ表現学習</h2><p><a href=\"https://arxiv.org/abs/2205.13147?ref=jina-ai-gmbh.ghost.io\">マトリョーシカ表現学習</a>は、精度の低下を最小限に抑えながら、異なる出力ベクトルサイズをサポートするようモデルを訓練する技術です。ニューラルネットワークの最終層である複数の線形投影ヘッドを使用して隠れ層を訓練し、それぞれが異なる出力サイズをサポートします。<strong>Jina ColBERT v2 は 128、96、64 次元の出力ベクトルをサポートしています。</strong></p><p>Jina ColBERT v2 はデフォルトで 128 次元の出力埋め込みを生成しますが、パフォーマンスがほぼ同じで長さが 25%、50% 短い 96 次元と 64 次元の出力も生成可能です。</p><p>以下の表は、</p><code>jina-colbert-v2</code>の上位10件の結果（<em>nDGC@10</em>）をBEIRベンチマークの6つのデータセットに対して示しています。128次元と96次元の性能差はわずか1%、128次元と64次元の差は1.5%未満であることがわかります。</p>\n<!--kg-card-begin: html-->\n<table id=\"b838dc78-1321-499e-98e7-63e3b5c8e910\" class=\"simple-table\"><tbody><thead id=\"177f4349-0620-4947-a3ce-01e598395ed7\"><tr><th id=\"<\\ml\" class=\"\"><strong>出力次元</strong></th><th id=\"<NYX\" class=\"\"><strong>平均スコア</strong><strong><br>(6つのベンチマークの nDGC@10)<br></strong></th></tr></thead><tr id=\"9199b56b-0513-4c99-a2a7-29cde915c3b9\"><td id=\"<\\ml\" class=\"\">128</td><td id=\"<NYX\" class=\"\">0.565</td></tr><tr id=\"af4d45fc-ebf4-4e1f-b5b0-1807a1cb889b\"><td id=\"<\\ml\" class=\"\">96</td><td id=\"<NYX\" class=\"\">0.558</td></tr><tr id=\"ecf7eac9-5c56-47e6-ab27-0ddb4659e263\"><td id=\"<\\ml\" class=\"\">64</td><td id=\"<NYX\" class=\"\">0.556</td></tr></tbody></table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/08/Performance-on-selected-BEIR-benchmarks.svg\" class=\"kg-image\" alt=\"Bar chart of BEIR benchmarks, highlighting scores of datasets like nfcorpus to msmarco, with jina-colbert-v2.64 excelling.\" loading=\"lazy\" width=\"732\" height=\"538\"><figcaption><span style=\"white-space: pre-wrap;\">異なる出力次元での Jina ColBERT v2 の性能。</span></figcaption></figure><p>出力ベクトルのサイズを削減することで、ベクトル間の比較や距離測定を行うベクトルベースの情報検索などのアプリケーションでスペースを節約し、速度を向上させることができます。</p><p>これは、保存容量の削減だけでも大きなコストへの影響があります。例えば、<a href=\"https://cloud.qdrant.io/calculator?ref=jina-ai-gmbh.ghost.io\">Qdrant のクラウドコスト計算ツール</a>を使用すると、AWS 上で各文書に128次元のベクトルを持つ1億件の文書を保存する場合、<a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=128&ref=jina-ai-gmbh.ghost.io\">推定コストは月額1,319.24米ドル</a>となります。64次元の場合、これは<a href=\"https://cloud.qdrant.io/calculator?provider=aws&region=eu-central-1&replicas=1&quantization=None&vectors=100000000&dimension=64&ref=jina-ai-gmbh.ghost.io\">659.62米ドルに低下</a>します。</p><h2 id=\"getting-started-with-jina-colbert-v2\">Jina ColBERT v2 を始める</h2><p>Jina ColBERT v2 は、Jina Search Foundation API、<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS マーケットプレイス</a>、および<a href=\"https://azuremarketplace.microsoft.com/en-gb/marketplace/apps?search=Jina&ref=jina-ai-gmbh.ghost.io\">Azure</a>で利用可能です。また、<em>非商用利用のみ</em>（<a href=\"https://www.creativecommons.org/licenses/by-nc/4.0/deed.en?ref=jina-ai-gmbh.ghost.io\">CC BY-NC-4.0</a>）で<a href=\"https://huggingface.co/jinaai/jina-colbert-v2?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>からも利用可能です。</p><h3 id=\"via-jina-search-foundation-api\">Jina Search Foundation API 経由</h3><h4 id=\"for-embedding\">埋め込み用</h4><p>以下の<code>curl</code>コマンドは、Jina Embeddings API を通じて<code>jina-colbert-v2</code>から文書埋め込みを取得するための入力とオプションを指定する方法を示しています。希望するサイズのベクトルを取得するには、<code>dimensions</code>パラメータに128または64を指定します。このパラメータはオプションで、デフォルト値は128です。</p><p>入力文書は8192トークンより長い場合は切り捨てられます。</p><p>認証ヘッダー<code>Authorization: Bearer &lt;YOUR JINA API KEY&gt;</code>に Jina API キーを指定してください：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # または64でベクトルサイズを半分に\n\t\"input_type\": \"document\", # クエリ埋め込みについては下記参照\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your document text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each text can be up to 8192 tokens long\"\n    ]}'\n</code></pre><p>クエリ埋め込みを取得するには、<code>input_type</code>パラメータを<code>document</code>ではなく<code>query</code>に設定します。クエリは文書よりもはるかに厳しいサイズ制限があることに注意してください。32トークンで切り捨てられます。クエリエンコーディングは、32トークンより少ない場合はパディングの埋め込みを含めて、<em>常に</em>32トークンを返します。</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/multi-vector \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n\t\"model\": \"jina-colbert-v2\",\n\t\"dimensions\": 128, # または64でベクトルサイズを半分に\n\t\"input_type\": \"query\", # クエリ埋め込みにはこれを指定する必要があります\n\t\"embedding_type\": \"float\",\n\t\"input\": [\n\t\t\"Your query text string goes here\", \n\t\t\"You can send multiple texts\", \n\t\t\"Each query text can be up to 32 tokens long\"\n    ]}'\n</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">検索とRAGのためのマルチモーダル、バイリンガル長文コンテキスト埋め込み。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h4 id=\"for-reranking\">再ランキング用</h4><p>Jina Reranker API を通じて<code>jina-colbert-v2</code>を使用し、1つのクエリと複数の文書を渡してランク付け可能なマッチスコアを取得するには、以下のようにリクエストを構築します：</p><pre><code class=\"language-bash\">curl https://api.jina.ai/v1/rerank \\\\\n\t -H \"Content-Type: application/json\" \\\\\n\t -H \"Authorization: Bearer &lt;YOUR JINA API KEY&gt;\" \\\\\n\t -d '{\n      \"model\": \"jina-colbert-v2\",\n      \"query\": \"What is the population of Berlin?\",\n      \"top_n\": 3,\n      \"documents\": [\n        \"Berlin's population grew by 0.7 percent in 2023 compared with the previous year. Accordingly, around 27,300 more residents lived in Berlin at the end of the last year than in 2022. Those of 30 to under 40 years old form the numerically largest age group. With roughly 881,000 foreign residents from around 170 nations and an average age of the population of 42.5 years old.\",\n        \"Mount Berlin is a glacier-covered volcano in Marie Byrd Land, Antarctica, 100 kilometres (62 mi) from the Amundsen Sea. It is a roughly 20-kilometre-wide (12 mi) mountain with parasitic vents that consists of two coalesced volcanoes: Berlin proper with the 2-kilometre-wide (1.2 mi) Berlin Crater and Merrem Peak with a 2.5-by-1-kilometre-wide (1.55 mi × 0.62 mi) crater, 3.5 kilometres (2.2 mi) away from Berlin.\",\n        \"Population as of 31.12.2023 by nationality and federal states Land\\\\tTotal\\\\tGermans\\\\tForeigners\\\\tincluding EU-states number\\\\t%\\\\tnumber\\\\t%\",\n        \"The urban area of Berlin has a population of over 4.5 million and is therefore the most populous urban area in Germany. The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region, and the sixth-biggest metropolitan region by GDP in the European Union.\",\n        \"Irving Berlin (born Israel Beilin) was an American composer and songwriter. His music forms a large part of the Great American Songbook. Berlin received numerous honors including an Academy Award, a Grammy Award, and a Tony Award.\",\n        \"Berlin is a town in the Capitol Planning Region, Connecticut, United States. The population was 20,175 at the 2020 census.\",\n        \"Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\",\n        \"Berlin, Berlin ist eine für die ARD produzierte Fernsehserie, die von 2002 bis 2005 im Vorabendprogramm des Ersten ausgestrahlt wurde. Regie führten unter anderem Franziska Meyer Price, Christoph Schnee, Sven Unterwaldt Jr. und Titus Selge.\"\n        ]\n    }'</code></pre><p><code>top_n</code>引数に注意してください。これは取得したい文書数を指定します。例えば、アプリケーションが最上位のマッチのみを使用する場合は、<code>top_n</code>を1に設定します。</p><p>Python やその他のプログラミング言語とフレームワークのコードスニペットについては、<a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina AI Embeddings API ページ</a>を参照するか、<a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\">Jina Reranker API ページ</a>のドロップダウンメニューから<code>jina-colbert-v2</code>を選択してください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io#apiform\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reranker API</div><div class=\"kg-bookmark-description\">検索の関連性とRAGの精度を簡単に最大化。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-reranker-api.png\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><h3 id=\"via-stanford-colbert\">Stanford ColBERT 経由</h3><p>また、Stanford ColBERT ライブラリで <a href=\"https://github.com/stanford-futuredata/ColBERT?ref=jina-ai-gmbh.ghost.io\">ColBERT v2</a> の代わりに Jina ColBERT v2 をそのまま使用することもできます。モデルソースとして <code>jinaai/jina-colbert-v2</code> を指定するだけです：</p><pre><code class=\"language-python\">from colbert.infra import ColBERTConfig\nfrom colbert.modeling.checkpoint import Checkpoint\n\nckpt = Checkpoint(\"jinaai/jina-colbert-v2\", colbert_config=ColBERTConfig())\ndocs = [\"Your list of texts\"] \nquery_vectors = ckpt.queryFromText(docs)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">上記のコードを使用するには、<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> と <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code> をインストールする必要があります。</div></div><h3 id=\"via-ragatouille\">RAGatouille を使用する方法</h3><p>Jina ColBERT v2 は同様に <a href=\"https://github.com/AnswerDotAI/RAGatouille?ref=jina-ai-gmbh.ghost.io\">RAGatouille</a> にも統合されています。<code>RAGPretrainedModel.from_pretrained()</code> メソッドを使用してダウンロードし、使用できます：</p><pre><code class=\"language-python\">from ragatouille import RAGPretrainedModel\n\nRAG = RAGPretrainedModel.from_pretrained(\"jinaai/jina-colbert-v2\")\ndocs = [\"Your list of texts\"]\nRAG.index(docs, index_name=\"your_index_name\")\nquery = \"Your query\"\nresults = RAG.search(query)\n</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">上記のコードを使用するには、<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">einops</code> と <code spellcheck=\"false\" style=\"white-space: pre-wrap;\">flash_attn</code> をインストールする必要があります。</div></div><h3 id=\"via-qdrant\">Qdrant を使用する方法</h3><p>Qdrant はバージョン 1.10 から、マルチベクトルと後期インタラクションモデルの<a href=\"https://qdrant.tech/blog/qdrant-1.10.x/?ref=jina-ai-gmbh.ghost.io\">サポート</a>を追加しました。ローカルまたはマネージドクラウドバージョンの Qdrant エンジンの既存ユーザーは、Qdrant のクライアントを使用して <code>jina-colbert-v2</code> を直接統合できます。</p><p><strong>MAX_SIM 操作を使用した新しいコレクションの作成</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\n\nqdrant_client = QdrantClient(\n    url=\"<YOUR_ENDPOINT>\",\n    api_key=\"<YOUR_API_KEY>\",\n)\n\nqdrant_client.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config={\n        \"colbert\": models.VectorParams(\n            size=128,\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM\n            ),\n        )\n    }\n)</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Qdrant で ColBERT スタイルのモデルを使用するには、<code spellcheck=\"false\" style=\"white-space: pre-wrap;\">multivector_config</code> パラメータを正しく設定することが重要です。</div></div><p><strong>マルチベクターコレクションへのドキュメントの挿入</strong></p><pre><code class=\"language-Python\">import requests\nfrom qdrant_client import QdrantClient, models\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer <YOUR BEARER>'\n}\n\ndata = {\n    'model': 'jina-colbert-v2',\n    'input_type': 'query',\n    'embedding_type': 'float',\n    'input': [\n        'Your text string goes here',\n        'You can send multiple texts',\n        'Each text can be up to 8192 tokens long'\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nrows = response.json()[\"data\"]\n\nqdrant_client = QdrantClient(\n    url=\"<YOUR_ENDPOINT>\",\n    api_key=\"<YOUR_API_KEY>\",\n)\n\nfor i, row in enumerate(rows):\n    qdrant_client.upsert(\n        collection_name=\"{collection_name}\",\n        points=[\n            models.PointStruct(\n                id=i,  \n                vector=row[\"embeddings\"],  \n                payload={\"text\": data[\"input\"][i]} \n            )\n        ],\n    )</code></pre><p><strong>コレクションのクエリ</strong></p><pre><code class=\"language-Python\">from qdrant_client import QdrantClient, models\nimport requests\n\nurl = 'https://api.jina.ai/v1/multi-vector'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer <YOUR BEARER>'\n}\n\n\ndata = {\n    'model': 'jina-colbert-v2',\n    \"input_type\": \"query\",\n    \"embedding_type\": \"float\",\n    \"input\": [\n        \"how many tokens in an input do Jina AI's embedding models support?\"\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nvector = response.json()[\"data\"][0][\"embeddings\"]\n\n\nqdrant_client = QdrantClient(\n    url=\"<YOUR_ENDPOINT>\",\n    api_key=\"<YOUR_API_KEY>\",\n)\n\nresults = qdrant_client.query_points(\n    collection_name=\"{collection_name}\",\n    query=vector,\n)\n\nprint(results)</code></pre><h3 id=\"summary\">まとめ</h3><p>Jina ColBERT v2（<code>jina-colbert-v2</code>）は、<code>jina-colbert-v1-en</code> の高性能を基盤に、幅広いグローバル言語に対応するように機能を拡張しています。複数の埋め込みサイズをサポートすることで、<code>jina-colbert-v2</code> はユーザーが特定のユースケースに合わせて精度と効率性のトレードオフを調整できるようになり、時間とコンピューティングコストを大幅に節約できる可能性があります。</p><p>このモデルは、これらすべての機能を単一の競争力のある価格のパッケージに組み合わせ、直感的な Web API を通じてアクセス可能で、HTTP リクエストをサポートするあらゆるコンピューティングフレームワークと互換性があります。100 万トークンの無料枠を使って<a href=\"https://jina.ai/?sui=&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">実際に試してみて</a>、アプリケーションやプロセスをどのように強化できるか確認してください。</p>",
  "comment_id": "66cd8fc6e84873000133d63d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg",
  "featured": true,
  "visibility": "public",
  "created_at": "2024-08-27T10:35:18.000+02:00",
  "updated_at": "2024-09-09T07:43:38.000+02:00",
  "published_at": "2024-08-30T09:19:58.000+02:00",
  "custom_excerpt": "Jina ColBERT v2 supports 89 languages with superior retrieval performance, user-controlled output dimensions, and 8192 token-length. ",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "62e3d0ef9cd5ce003d5e49e2",
      "name": "Jina AI",
      "slug": "company",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
      "cover_image": null,
      "bio": "Creator of neural search, contributor to open source.",
      "website": "https://www.jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": "@JinaAI_",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/company/"
    }
  ],
  "tags": [
    {
      "id": "655b2782bb728c000101bed7",
      "name": "Press",
      "slug": "press",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
    }
  ],
  "primary_author": {
    "id": "62e3d0ef9cd5ce003d5e49e2",
    "name": "Jina AI",
    "slug": "company",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg",
    "cover_image": null,
    "bio": "Creator of neural search, contributor to open source.",
    "website": "https://www.jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": "@JinaAI_",
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/company/"
  },
  "primary_tag": {
    "id": "655b2782bb728c000101bed7",
    "name": "Press",
    "slug": "press",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/press/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking/",
  "excerpt": "Jina ColBERT v2 は、優れた検索パフォーマンス、ユーザーが制御可能な出力次元、8192 トークン長をサポートし、89 の言語に対応しています。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Dark-themed coding interface displaying English and Japanese characters with \"JINA COLBERT V2\" highlighted in the center.",
  "feature_image_caption": null
}