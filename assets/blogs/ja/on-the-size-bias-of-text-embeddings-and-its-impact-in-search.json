{
  "slug": "on-the-size-bias-of-text-embeddings-and-its-impact-in-search",
  "id": "67e52df15dcba60001c30ebe",
  "uuid": "bae3e1b8-3bf2-4dbc-a553-b26ea64aeb60",
  "title": "テキスト埋め込みのサイズバイアスと検索への影響について",
  "html": "<p>埋め込みモデルは意味的な類似性を測定するために作られていますが、その測定値には多くのバイアス要因が影響を与えます。この記事では、テキスト埋め込みモデルにおける普遍的なバイアスの1つである入力サイズについて見ていきます。</p><p><strong>より長いテキストの埋め込みは、実際のコンテンツの類似性に関係なく、他のテキスト埋め込みと比較した場合、一般的により高い類似度スコアを示します。</strong>確かに、本当に似ているテキスト同士は関連のないものより高い類似度スコアを示しますが、長いテキストはバイアスを導入し、単にその長さのために埋め込みが平均的により類似しているように見えてしまいます。</p><p>これには実際の影響があります。埋め込みモデルだけでは関連性を適切に測定できないということです。埋め込みベースの検索では、常に最良の一致が存在しますが、サイズバイアスにより、最良の一致や他の一致が実際に関連しているかどうかを類似度スコアで判断することはできません。例えば、コサイン類似度が 0.75 以上の一致は関連性があるとは言えません。なぜなら、完全に無関係であっても、長い文書がそのレベルで一致する可能性があるからです。</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">💡</div><div class=\"kg-callout-text\">埋め込みベクトルの比較は、相対的な類似性を示すだけで、関連性は示しません。</div></div><p>いくつかの簡単な例を使ってこれを実証し、テキスト埋め込み間のコサイン類似度が一般的な評価方法として機能しないことを示します</p><h2 id=\"visualizing-size-bias\">サイズバイアスの可視化</h2><p>サイズバイアスがどのように現れるかを示すために、Jina AI の最新の埋め込みモデル <code>jina-embeddings-v3</code> を <code>text-matching</code> タスクオプションで使用します。また、広く使用されている IR データセット：<a href=\"https://ir.dcs.gla.ac.uk/resources/test_collections/cisi/\">CISI データセット</a>のテキスト文書を使用します。これは<a href=\"https://www.kaggle.com/datasets/dmaso01dsta/cisi-a-dataset-for-information-retrieval\">Kaggle からダウンロード</a>できます。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.kaggle.com/datasets/dmaso01dsta/cisi-a-dataset-for-information-retrieval\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">CISI (a dataset for Information Retrieval)</div><div class=\"kg-bookmark-description\">A public dataset from the University of Glasgow's Information Retrieval Group</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-31.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Kaggle</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/thumbnail/dataset-card.jpg\" alt=\"\" onerror=\"this.style.display = 'none'\"></div></a></figure><p>このデータセットは IR システムのトレーニング用で、クエリとそれに一致する文書の両方が含まれています。今回は <code>CISI.ALL</code> ファイルに含まれる文書のみを使用します。<a href=\"https://github.com/GianRomani/CISI-project-MLOps\">GitHub の代替ソース</a>からコマンドラインで以下のようにダウンロードできます：</p><pre><code class=\"language-bash\">wget https://raw.githubusercontent.com/GianRomani/CISI-project-MLOps/refs/heads/main/CISI.ALL\n</code></pre><p>CISI には 1,460 の文書が含まれています。テキストのサイズとその分布に関する基本的な統計は、以下の表とヒストグラムにまとめられています：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th></th>\n<th>in Words</th>\n<th>in Sentences</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Average document size</td>\n<td>119.2</td>\n<td>4.34</td>\n</tr>\n<tr>\n<td>Std. Deviation</td>\n<td>63.3</td>\n<td>2.7</td>\n</tr>\n<tr>\n<td>Max size</td>\n<td>550</td>\n<td>38</td>\n</tr>\n<tr>\n<td>Min size</td>\n<td>8</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-8.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"576\" height=\"455\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-9.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"576\" height=\"455\"></figure><p>Python で文書を読み込み、それらの埋め込みを取得しましょう。以下のコードは <code>CISI.ALL</code> ファイルがローカルディレクトリにあることを前提としています：</p><pre><code class=\"language-python\">with open(\"CISI.ALL\", \"r\", encoding=\"utf-8\") as inp:\n    cisi_raw = inp.readlines()\n\ndocs = []\ncurrent_doc = \"\"\nin_text = False\nfor line in cisi_raw:\n    if line.startswith(\".\"):\n        in_text = False\n        if current_doc:\n            docs.append(current_doc.strip())\n            current_doc = \"\"\n        if line.startswith(\".W\"):\n            in_text = True\n    else:\n        if in_text:\n            current_doc += line\n</code></pre><p>これにより <code>docs</code> リストに 1,460 の文書が格納されます。以下のように内容を確認できます：</p><pre><code class=\"language-text\">print(docs[0])\n\nThe present study is a history of the DEWEY Decimal\nClassification.  The first edition of the DDC was published\nin 1876, the eighteenth edition in 1971, and future editions\nwill continue to appear as needed.  In spite of the DDC's\nlong and healthy life, however, its full story has never\nbeen told.  There have been biographies of Dewey\nthat briefly describe his system, but this is the first\nattempt to provide a detailed history of the work that\nmore than any other has spurred the growth of\nlibrarianship in this country and abroad.</code></pre><p>次に、<code>jina-embeddings-v3</code> を使用して各テキストの埋め込みを構築します。これには <a href=\"https://jina.ai/embeddings/#apiform\">Jina AI のウェブサイトから API キー</a>が必要です。100 万トークンまでの埋め込みが無料で利用できるキーを取得でき、この記事の目的には十分です。</p><p>キーを変数に設定します：</p><pre><code class=\"language-python\">api_key = \"&lt;Your Key&gt;\"\n</code></pre><p>次に、<code>jina-embeddings-v3</code> の <code>text-matching</code> タスクを使用して埋め込みを生成します。このコードは <code>docs</code> 内のテキストを 10 件ずつバッチ処理します。</p><pre><code class=\"language-python\">import requests\nimport json\nfrom numpy import array\n\nembeddings  = []\n\nurl = \"https://api.jina.ai/v1/embeddings\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer \" + api_key\n}\n\ni = 0\nwhile i &lt; len(docs):\n    print(f\"Got {len(embeddings)}...\")\n    data = {\n        \"model\": \"jina-embeddings-v3\",\n        \"task\": \"text-matching\",\n        \"late_chunking\": False,\n        \"dimensions\": 1024,\n        \"embedding_type\": \"float\",\n        \"input\": docs[i:i+10]\n    }\n    \n    response = requests.post(url, headers=headers, data=json.dumps(data))\n    for emb in response.json()['data']:\n        embeddings.append(array(emb['embedding']))\n    i += 10\n</code></pre><p>各テキストに対して、1024 次元の埋め込みが <code>embeddings</code> リストに格納されます。以下のように見ることができます：</p><pre><code class=\"language-python\">print(embeddings[0])\n\narray([ 0.0352382 , -0.00594871,  0.03808545, ..., -0.01147173,\n         -0.01710563,  0.01109511], shape=(1024,))),\n</code></pre><p>次に、すべての埋め込みペア間のコサインを計算します。まず、<code>numpy</code> を使用してコサイン関数 <code>cos_sim</code> を定義します：</p><pre><code class=\"language-python\">from numpy import dot\nfrom numpy.linalg import norm\n\ndef cos_sim(a, b): \n    return float((a @ b.T) / (norm(a)*norm(b)))\n</code></pre><p>次に、1,460 の埋め込みそれぞれを他の 1,459 と比較してコサインを計算します：</p><pre><code class=\"language-python\">all_cosines = []\nfor i, emb1 in enumerate(embeddings):\n    for j, emb2 in enumerate(embeddings):\n        if i != j:\n            all_cosines.append(cos_sim(emb1, emb2))\n</code></pre><p>結果は 2,130,140 の値のリストです。その分布は、同じ言語と register における「ランダムな」文書間のコサインを近似するはずです。以下の表とヒストグラムに結果をまとめています。</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Number of texts</th>\n<th>1,460</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Number of cosines</td>\n<td>2,130,140</td>\n</tr>\n<tr>\n<td>Average</td>\n<td>0.343</td>\n</tr>\n<tr>\n<td>Std. Deviation</td>\n<td>0.116</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-10.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"576\" height=\"455\"></figure><p>これらの文書は、互いに関連していないにもかかわらず、通常ゼロをかなり上回るコサインを示します。閾値を 0.459（平均＋標準偏差1つ分）、あるいは切り上げて 0.5 に設定し、それ未満のコサインを持つ文書ペアは大体無関係だと言いたくなるかもしれません。</p><p>しかし、より小さなテキストで同じ実験をしてみましょう。<a href=\"https://www.nltk.org/\" rel=\"noreferrer\"><code>nltk</code></a> ライブラリを使用して各文書を文に分割します：</p><pre><code class=\"language-python\">import nltk\n\nsentences = []\nfor doc in docs:\n    sentences.extend(nltk.sent_tokenize(doc)) \n</code></pre><p>これにより、平均長 27.5 語、標準偏差 16.6 の 6,331 の文が得られます。以下のヒストグラムでは、文のサイズ分布が赤で、完全な文書のものが青で示されており、比較することができます。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-12.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"567\" height=\"455\"></figure><p>同じモデルと方法を使用して、各文の埋め込みを取得します：</p><pre><code class=\"language-python\">sentence_embeddings = []\n\ni = 0\nwhile i &lt; len(sentences):\n    print(f\"Got {len(sentence_embeddings)}...\")\n    data = {\n        \"model\": \"jina-embeddings-v3\",\n        \"task\": \"text-matching\",\n        \"late_chunking\": False,\n        \"dimensions\": 1024,\n        \"embedding_type\": \"float\",\n        \"input\": sentences[i:i+10]\n    }\n    \n    response = requests.post(url, headers=headers, data=json.dumps(data))\n    for emb in response.json()['data']:\n        sentence_embeddings.append(array(emb['embedding']))\n    i += 10\n</code></pre><p>そして、各文の埋め込みと他の文の埋め込みとのコサインを取ります：</p><pre><code class=\"language-python\">sent_cosines = []\nfor i, emb1 in enumerate(sentence_embeddings):\n    for j, emb2 in enumerate(sentence_embeddings):\n        if i != j:\n            sent_cosines.append(cos_sim(emb1, emb2))\n</code></pre><p>結果として、かなり多くのコサイン値が得られました：40,075,230。以下の表にまとめています：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Number of sentences</th>\n<th>6,331</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Number of cosines</td>\n<td>40,075,230</td>\n</tr>\n<tr>\n<td>Average</td>\n<td>0.254</td>\n</tr>\n<tr>\n<td>Std. Deviation</td>\n<td>0.116</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>文と文の間のコサインは、文書全体同士の場合と比べて平均的にかなり低くなっています。以下のヒストグラムはその分布を比較したものです。文のペアは文書のペアとほぼ同じ分布を形成していますが、左側にシフトしていることがわかります。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-14.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"587\" height=\"455\"></figure><p>このサイズ依存性が頑健かどうかを確認するため、文と文書の間のすべてのコサインを取得し、ヒストグラムに追加してみましょう。その情報は以下の表にまとめられています：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Number of texts</th>\n<th>6,331 sentences &amp; 1,460 documents</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Number of cosines</td>\n<td>9,243,260</td>\n</tr>\n<tr>\n<td>Average</td>\n<td>0.276</td>\n</tr>\n<tr>\n<td>Std. Deviation</td>\n<td>0.119</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<p>下の緑の線は、文書と文のコサインの分布を示しています。この分布が文書同士のコサインと文同士のコサインの間にちょうど収まっていることがわかります。これは、サイズ効果が比較される2つのテキストの大小両方に関係していることを示しています。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-16.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"587\" height=\"455\"></figure><p>さらにテストとして、文書を10個ずつグループにして連結し、146個のより大きな文書を作成してコサインを測定してみましょう。結果は以下のようにまとめられています：</p>\n<!--kg-card-begin: html-->\n<table>\n<thead>\n<tr>\n<th>Number of texts</th>\n<th>146 documents</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Number of cosines</td>\n<td>21,170</td>\n</tr>\n<tr>\n<td>Average</td>\n<td>0.658</td>\n</tr>\n<tr>\n<td>Std. Deviation</td>\n<td>0.09</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: html-->\n<figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-17.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"587\" height=\"455\"></figure><p>これは他の分布よりも<em>はるかに</em>右側にあります。コサインの閾値を0.5に設定すると、これらの文書のほぼすべてが互いに関連していると判断されてしまいます。このサイズの文書から無関係な文書を除外するには、閾値をもっと高く、おそらく0.9程度に設定する必要があります。しかし、そうすると小さな文書間の良好なマッチングも間違いなく除外されてしまうでしょう。</p><p>これは、文書のサイズを考慮に入れずに、マッチングの良さを推定するために最小コサイン閾値を使用することが全くできないことを示しています。</p><h2 id=\"what-causes-size-bias\">サイズバイアスの原因は何か？</h2><p>埋め込みにおけるサイズバイアスは、<a href=\"https://jina.ai/news/long-context-embedding-models-are-blind-beyond-4k-tokens/\">長文コンテキストモデルにおける位置バイアス</a>とは異なります。アーキテクチャによって引き起こされるものではありません。本質的にサイズに関するものでもありません。例えば、同じ文書のコピーを何度も連結して長い文書を作成した場合、サイズバイアスは表れません。</p><p>問題は、長いテキストはより多くのことを述べているということです。トピックや目的によって制約されていたとしても、より多くの言葉を書くことの要点は、より多くのことを述べることにあります。</p><p>通常人々が作成するような長いテキストは、必然的により多くの意味空間に「広がる」埋め込みを生成します。テキストがより多くのことを述べている場合、そのテキストの主題に関係なく、その埋め込みは平均的に他のベクトルとの角度が小さくなります。</p><h2 id=\"measuring-relevance\">関連性の測定</h2><p>この投稿の教訓は、意味ベクトル間のコサインを<em>単独で</em>使用して、何かが良いマッチングかどうかを判断することはできないということです。利用可能なものの中で最良のマッチングであることを示すだけです。最良のマッチングの有用性と妥当性を確認するには、コサインの計算以外の何かをする必要があります。</p><p>正規化を試すことはできます。サイズバイアスを経験的に測定できれば、それを相殺することができるかもしれません。しかし、このアプローチは非常に堅牢ではないかもしれません。あるデータセットで機能することは、別のデータセットでは機能しない可能性が高いです。</p><p><code>jina-embeddings-v3</code>で提供される<a href=\"https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/\">非対称クエリ-文書エンコーディング</a>は、埋め込みモデルのサイズバイアスを減少させますが、完全には排除しません。非対称エンコーディングの目的は、文書をあまり「広がらない」ようにエンコードし、クエリをより広がるようにエンコードすることです。</p><p>以下のヒストグラムの赤い線は、<code>jina-embeddings-v3</code>を使用した非対称エンコーディングによる文書間のコサインの分布を示しています - 各文書は<code>retrieval.query</code>と<code>retrieval.passage</code>フラグを使用してエンコードされ、各文書のクエリ埋め込みは、同じ文書から生成されていない他のすべての文書のpassage埋め込みと比較されます。平均コサインは0.200で、標準偏差は0.124です。</p><p>これらのコサインは、上で見た<code>text-matching</code>フラグを使用した同じ文書のコサインよりもかなり小さくなっています。以下のヒストグラムでそれを示しています。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-25.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"591\" height=\"455\"></figure><p>しかし、非対称エンコーディングはサイズバイアスを排除していません。以下のヒストグラムは、非対称エンコーディングを使用した完全な文書と文のコサインを比較しています。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2025/04/image-23.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"576\" height=\"455\"></figure><p>文のコサインの平均は0.124で、非対称エンコーディングを使用した場合、文のコサインの平均と文書のコサインの平均の差は0.076です。対称エンコーディングでの平均の差は0.089です。サイズバイアスの変化は無視できる程度です。</p><p>非対称エンコーディングは情報検索のための埋め込みを改善しますが、マッチングの関連性を測定する点では改善されていません。</p><h2 id=\"future-possibilities\">将来の可能性</h2><p>リランカーアプローチ（例：<code>jina-reranker-v2-base-multilingual</code>および<code>jina-reranker-m0</code>）は、クエリと文書のマッチングをスコアリングする代替手法であり、すでに<a href=\"https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker/\">クエリの精度を向上させる</a>ことがわかっています。リランカースコアは正規化されていないため、客観的な類似度の測定としても機能しません。しかし、これらは異なる方法で計算され、リランカースコアを関連性の良い推定値とするような正規化方法が可能かもしれません。</p><p>もう1つの選択肢は、強力な推論能力を持つ大規模言語モデルを使用して、候補がクエリに対して良いマッチングかどうかを直接評価することです。単純に言えば、タスク特化型の大規模言語モデルに「1から10のスケールで、この文書はこのクエリに対して良いマッチングですか？」と尋ねることができます。既存のモデルはこのタスクに適していないかもしれませんが、焦点を絞ったトレーニングとより洗練されたプロンプト技術は有望です。</p><p>モデルが関連性を測定することは不可能ではありませんが、埋め込みモデルとは異なるパラダイムが必要です。</p><h2 id=\"use-your-models-for-what-its-good-for\">モデルの長所を活かす</h2><p>上で説明したサイズバイアス効果は、埋め込みモデルの基本的な制限の1つを示しています：これらは物事を比較するのには優れていますが、絶対的な関連性を測定するのは信頼できません。この制限は設計上の欠陥ではなく、これらのモデルがどのように機能するかの本質的な特徴です。</p><p>では、これは何を意味するのでしょうか？</p><p>まず、コサイン閾値に対して懐疑的になるべきです。これらは単に機能しません。コサイン類似度は、客観的に見える浮動小数点数を出力します。しかし、何かが数値を出力するからといって、それが何かを客観的に測定しているわけではありません。</p><p>第二に、ハイブリッドソリューションを検討してください。埋め込みは、大規模なアイテムセットから有望な候補を効率的に絞り込むことができます。その後、リランカーや LLM、あるいは人間の評価者のようなより洗練された（そして計算コストの高い）テクニックを適用して、実際の関連性を判断することができます。</p><p>第三に、システムを設計する際は、機能ではなくタスクの観点から考えてください。ベンチマークで客観的に最も賢く、最高のスコアを出すモデルでも、それを購入した目的のジョブをこなせなければ、お金の無駄遣いです。</p><p>モデルの限界を理解することは悲観的なことではありません - これはアプリケーションにおけるより広い原則を反映しています：モデルの得意なことと不得意なことを理解することは、信頼性の高い効果的なシステムを構築する上で重要です。ハンマーでネジを締めようとしないのと同じように、埋め込みモデルを扱えないタスクに使用すべきではありません。あなたのツールの長所を理解しましょう。</p>",
  "comment_id": "67e52df15dcba60001c30ebe",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2025/04/Heading---2025-04-16T094756.687.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2025-03-27T11:52:33.000+01:00",
  "updated_at": "2025-04-16T03:48:15.000+02:00",
  "published_at": "2025-04-16T03:40:03.000+02:00",
  "custom_excerpt": "Size bias refers to how the length of text inputs affects similarity, regardless of semantic relevance. It explains why search systems sometimes return long, barely-relevant documents instead of shorter, more precise matches to your query.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/on-the-size-bias-of-text-embeddings-and-its-impact-in-search/",
  "excerpt": "サイズバイアスとは、意味的な関連性に関係なく、テキスト入力の長さが類似性に影響を与える現象を指します。これは、検索システムが、クエリにより正確に一致する短いテキストではなく、関連性の低い長い文書を返してしまう理由を説明するものです。",
  "reading_time": 10,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": null,
  "feature_image_caption": null
}