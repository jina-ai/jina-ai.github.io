{
  "slug": "next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker",
  "id": "65fabb91502fd000011c667e",
  "uuid": "45cd5187-838d-46b7-a8a0-d890fcda9041",
  "title": "次世代クラウド AI：Amazon SageMaker 上の Jina Embeddings と Rerankers",
  "html": "<p><a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings</a> と <a href=\"https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io\">Jina Reranker</a> が、<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS Marketplace</a> から <a href=\"https://aws.amazon.com/pm/sagemaker/?ref=jina-ai-gmbh.ghost.io\">Amazon SageMaker</a> で利用できるようになりました。セキュリティ、信頼性、クラウド運用の一貫性を重視する企業ユーザーにとって、これによりプライベートな AWS 環境で Jina AI の最先端 AI を利用でき、AWS の確立された安定したインフラのすべての利点を享受できます。</p><p>AWS Marketplace 上の完全な embedding モデルと reranking モデルのラインナップにより、SageMaker ユーザーは、競争力のある価格で 8k 入力コンテキストウィンドウと最高ランクの多言語 embeddings をオンデマンドで利用できます。モデルの AWS へのインポートやエクスポートに料金を支払う必要はなく、価格は透明で、請求は AWS アカウントと統合されています。</p><p>現在 Amazon SageMaker で利用可能なモデルには以下が含まれます：</p><ul><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2 Base - English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-6w6k6ckusixpw?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2 Small - English</a></li><li>Jina Embeddings v2 バイリンガルモデル：<ul><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-dz3ubvmivnwry?ref=jina-ai-gmbh.ghost.io\">ドイツ語/英語</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-hxalozh37jka4?ref=jina-ai-gmbh.ghost.io\">中国語/英語</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-rnb324fpie3n6?ref=jina-ai-gmbh.ghost.io\">スペイン語/英語</a></li></ul></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-tk7t7bz6fp5ng?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2 Base - Code</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-avmxk2wxbygd6?ref=jina-ai-gmbh.ghost.io\">Jina Reranker v1 Base - English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-6kxbf5xqrluf4?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina ColBERT v1 - English</a></li><li><a href=\"https://aws.amazon.com/marketplace/pp/prodview-mgomngrh4c4k4?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Jina ColBERT Reranker v1 - English</a></li></ul><p>モデルの完全なリストは <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS Marketplace の Jina AI のベンダーページ</a>をご覧ください。7 日間の無料トライアルをご利用いただけます。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina AI</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><p>この記事では、Amazon SageMaker のコンポーネントのみを使用して<a href=\"https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/?ref=jina-ai-gmbh.ghost.io\">検索拡張生成</a>（RAG）アプリケーションを作成する方法を説明します。使用するモデルは、<strong>Jina Embeddings v2 - English</strong>、<strong>Jina Reranker v1</strong>、および <a href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io\">Mistral-7B-Instruct</a> 大規模言語モデルです。</p><p>Python Notebook で<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/sagemaker/sagemaker.ipynb?ref=jina-ai-gmbh.ghost.io\">ダウンロード</a>するか、<a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/sagemaker/sagemaker.ipynb?ref=jina-ai-gmbh.ghost.io\">Google Colab で実行</a>して、手順を追うこともできます。</p><h2 id=\"retrieval-augmented-generation\">検索拡張生成</h2><p>検索拡張生成は、生成 AI における代替的なパラダイムです。大規模言語モデル（LLM）を使って学習したことを直接ユーザーのリクエストに応答するのではなく、流暢な言語生成能力を活用しながら、ロジックと情報検索を外部のより適した装置に移行します。</p><p>RAG システムは、LLM を呼び出す前に、外部のデータソースから関連情報を積極的に取得し、それをプロンプトの一部として LLM に送ります。LLM の役割は、外部情報を統合してユーザーのリクエストに対する一貫した応答を生成することであり、幻覚のリスクを最小限に抑え、結果の関連性と有用性を高めます。</p><p>RAG システムは概して少なくとも 4 つのコンポーネントを持ちます：</p><ul><li>データソース：通常は、AI 支援の情報検索に適したベクトルデータベース</li><li>情報検索システム：ユーザーのリクエストをクエリとして扱い、それに関連するデータを取得する</li><li>システム：多くの場合、AI ベースの reranker を含み、取得したデータの一部を選択して LLM のプロンプトに処理する</li><li>LLM：例えば GPT モデルや Mistral のようなオープンソース LLM で、ユーザーのリクエストと提供されたデータを取り、ユーザーへの応答を生成する</li></ul><p>embedding モデルは情報検索に適しており、その目的で頻繁に使用されます。テキスト embedding モデルはテキストを入力として受け取り、<a href=\"https://jina.ai/news/how-embeddings-drive-ai-a-guide?ref=jina-ai-gmbh.ghost.io\">embedding</a>（高次元ベクトル）を出力します。このベクトルの空間的な関係は、意味的な類似性（つまり、類似したトピック、内容、関連する意味）を示します。embedding は、近ければ近いほどユーザーが応答に満足する可能性が高いため、情報検索でよく使用されます。また、特定のドメインでのパフォーマンスを向上させるためのファインチューニングも比較的容易です。</p><p><a href=\"https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">テキスト reranker</a> モデルは、同様の AI 原理を使用してテキストのコレクションをクエリと比較し、意味的な類似性によってソートします。embedding モデルだけに頼るのではなく、タスク固有の reranker モデルを使用することで、検索結果の精度が劇的に向上することがよくあります。RAG アプリケーションの reranker は、LLM のプロンプトに適切な情報が含まれる確率を最大化するために、情報検索の結果の一部を選択します。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Maximizing Search Relevance and RAG Accuracy with Jina Reranker</div><div class=\"kg-bookmark-description\">Boost your search and RAG accuracy with Jina Reranker. Our new model improves the accuracy and relevance by 20% over simple vector search. Try it now for free!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/02/Reranker1.png\" alt=\"\"></div></a></figure><h2 id=\"benchmarking-performance-of-embedding-models-as-sagemaker-endpoints\"><strong>SageMaker エンドポイントとしての Embedding モデルのパフォーマンスベンチマーク</strong></h2><p><a href=\"https://aws.amazon.com/ec2/instance-types/g4/?ref=jina-ai-gmbh.ghost.io\">g4dn.xlarge</a> インスタンスで実行される SageMaker エンドポイントとしての <strong>Jina Embeddings v2 Base - English</strong> モデルのパフォーマンスと信頼性をテストしました。これらの実験では、1 秒ごとに新しいユーザーを 1 人ずつ生成し、各ユーザーはリクエストを送信し、応答を待ち、受信後に繰り返すようにしました。</p><ul><li><em>100 トークン未満</em>のリクエストの場合、最大 150 人の同時ユーザーまでは、<em>リクエストあたり</em>の応答時間は 100ms 未満でした。その後、同時ユーザー数の増加に伴い、応答時間は 100ms から 1500ms まで線形に増加しました。<ul><li><em>約 300 人の同時ユーザー</em>で、API から 5 件以上の失敗を受信し、テストを終了しました。</li></ul></li><li>1K から 8K トークンのリクエストの場合、最大 20 人の同時ユーザーまでは、<em>リクエストあたり</em>の応答時間は 8s 未満でした。その後、同時ユーザー数の増加に伴い、応答時間は 8s から 60s まで線形に増加しました。<ul><li><em>約 140 人の同時ユーザー</em>で、API から 5 件以上の失敗を受信し、テストを終了しました。</li></ul></li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/image-3.png\" class=\"kg-image\" alt=\"Four comparative graphs displaying &quot;Small Context&quot; versus &quot;Large Context&quot; results over time, assessing performance metrics.\" loading=\"lazy\" width=\"2000\" height=\"1250\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/03/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/image-3.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">テスト実行中のパフォーマンス（左：小さいコンテキスト、右：大きいコンテキスト）、時間の経過とともにユーザー数が増加することによるレスポンスタイムと失敗率への影響を示しています。</span></figcaption></figure><p>これらの結果から、通常の埋め込みワークロードを持つほとんどのユーザーにとって、g4dn.xlarge または g5.xlarge インスタンスが日常的なニーズを満たすことができると結論付けることができます。ただし、<em>検索</em>タスクよりもはるかに実行頻度の低い大規模な<em>インデックス作成</em>ジョブの場合、ユーザーはよりパフォーマンスの高いオプションを好む可能性があります。利用可能な Sagemaker インスタンスの一覧については、AWS の <a href=\"https://aws.amazon.com/ec2/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">EC2</a> の概要をご参照ください。</p><h2 id=\"configure-your-aws-account\">AWS アカウントの設定</h2><p>まず、AWS アカウントが必要です。まだ AWS ユーザーでない場合は、AWS のウェブサイトでアカウントに<a href=\"https://portal.aws.amazon.com/billing/signup?ref=jina-ai-gmbh.ghost.io\">サインアップ</a>することができます。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://portal.aws.amazon.com/billing/signup?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Console - Signup</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://portal.aws.amazon.com/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Signup</span></div></div></a></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">Amazon は SageMaker への無料アクセスを提供していないため、無料利用枠のアカウントではこのチュートリアルを完了することはできません。<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">7日間の無料トライアル</a>を使用する場合でも、Jina AI のモデルを購読するには支払い方法をアカウントに追加する必要があります。</div></div><h3 id=\"set-up-aws-tools-in-your-python-environment\">Python 環境での AWS ツールのセットアップ</h3><p>このチュートリアルに必要な AWS ツールとライブラリを Python 環境にインストールします：</p><pre><code class=\"language-bash\">pip install awscli jina-sagemaker\n</code></pre><p>AWS アカウントのアクセスキーとシークレットアクセスキーが必要になります。これらを取得するには、<a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?ref=jina-ai-gmbh.ghost.io\">AWS ウェブサイトの手順</a>に従ってください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Managing access keys for IAM users - AWS Identity and Access Management</div><div class=\"kg-bookmark-description\">Create, modify, view, or update access keys (credentials) for programmatic calls to AWS.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.aws.amazon.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">AWS Identity and Access Management</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.aws.amazon.com/images/IAM/latest/UserGuide/images/security-credentials-user.shared.console.png\" alt=\"\"></div></a></figure><p>また、作業する<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html?ref=jina-ai-gmbh.ghost.io\">AWS リージョン</a>を選択する必要があります。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Regions, Availability Zones, and Local Zones - Amazon Relational Database Service</div><div class=\"kg-bookmark-description\">Learn how Amazon cloud computing resources are hosted in multiple locations world-wide, including AWS Regions and Availability Zones.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.aws.amazon.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Amazon Relational Database Service</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.aws.amazon.com/images/AmazonRDS/latest/UserGuide/images/Con-AZ-Local.png\" alt=\"\"></div></a></figure><p>次に、環境変数に値を設定します。Python または Python ノートブックでは、以下のコードで設定できます：</p><pre><code class=\"language-bash\">import os\n\nos.environ[\"AWS_ACCESS_KEY_ID\"] = &lt;YOUR_ACCESS_KEY_ID&gt;\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = &lt;YOUR_SECRET_ACCESS_KEY&gt;\nos.environ[\"AWS_DEFAULT_REGION\"] = &lt;YOUR_AWS_REGION&gt;\nos.environ[\"AWS_DEFAULT_OUTPUT\"] = \"json\"\n</code></pre><p>デフォルトの出力を <code>json</code> に設定してください。</p><p>これは、<a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html?ref=jina-ai-gmbh.ghost.io\">AWS コマンドラインアプリケーション</a>を使用するか、ローカルファイルシステムに<a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html?ref=jina-ai-gmbh.ghost.io\">AWS 設定ファイル</a>をセットアップすることでも可能です。詳細については、<a href=\"https://docs.aws.amazon.com/index.html?ref=jina-ai-gmbh.ghost.io\">AWS ウェブサイトのドキュメント</a>をご覧ください。</p><h3 id=\"create-a-role\">ロールの作成</h3><p>このチュートリアルに必要なリソースを使用するために十分な権限を持つ<a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html?ref=jina-ai-gmbh.ghost.io\">AWS ロール</a>も必要です。</p><p>このロールは以下の条件を満たす必要があります：</p><ol><li><strong>AmazonSageMakerFullAccess</strong> が有効になっていること。</li><li>以下のいずれかを満たすこと：<ol><li>AWS Marketplace サブスクリプションを作成する権限があり、以下の3つすべてが有効になっていること：<ol><li><strong>aws-marketplace:ViewSubscriptions</strong></li><li><strong>aws-marketplace:Unsubscribe</strong></li><li><strong>aws-marketplace:Subscribe</strong></li></ol></li><li>または、AWS アカウントが<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">jina-embedding-model</a>のサブスクリプションを持っていること。</li></ol></li></ol><p>ロールの ARN（<a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference-arns.html?ref=jina-ai-gmbh.ghost.io\">Amazon Resource Name</a>）を変数名 <code>role</code> に保存してください：</p><pre><code class=\"language-python\">role = &lt;YOUR_ROLE_ARN&gt;\n</code></pre><p>詳細については、AWS ウェブサイトのロールに関するドキュメントをご覧ください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">IAM roles - AWS Identity and Access Management</div><div class=\"kg-bookmark-description\">Learn how and when to use IAM roles.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.aws.amazon.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">AWS Identity and Access Management</span></div></div></a></figure><h3 id=\"subscribe-to-jina-ai-models-on-aws-marketplace\">AWS Marketplace での Jina AI モデルの購読</h3><p>この記事では、Jina Embeddings v2 base English モデルを使用します。<a href=\"https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io\">AWS Marketplace</a> でこのモデルを購読してください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina Embeddings v2 Base - en</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">en</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><p>ページを下にスクロールすると、価格情報が表示されます。AWS はマーケットプレイスのモデルを時間単位で課金するため、モデルエンドポイントを開始してから停止するまでの時間に対して課金されます。この記事では、その両方の方法をお示しします。</p><p>また、Jina Reranker v1 - English モデルも使用しますので、こちらも購読する必要があります。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/pp/prodview-avmxk2wxbygd6?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace：Jina Reranker v1 Base - en</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">en</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-text\">Jina AI は現在、モデルの 7 日間無料トライアルを提供しています。モデルを実行する AWS インスタンスの料金は支払う必要がありますが、トライアル期間中はモデル自体の追加料金は発生しません。</div></div><p>サブスクリプションを購入したら、AWS リージョンのモデルの ARN を取得し、それぞれ <code>embedding_package_arn</code> と <code>reranker_package_arn</code> という変数名で保存してください。このチュートリアルのコードでは、これらの変数名を参照します。</p><p>ARN の取得方法がわからない場合は、Amazon リージョン名を変数 <code>region</code> に設定し、以下のコードを使用してください：</p><pre><code class=\"language-python\">region = os.environ[\"AWS_DEFAULT_REGION\"]\n\ndef get_arn_for_model(region_name, model_name):\n    model_package_map = {\n        \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:253352124568:model-package/{model_name}\",\n        \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:model-package/{model_name}\",\n        \"us-west-1\": f\"arn:aws:sagemaker:us-west-1:382657785993:model-package/{model_name}\",\n        \"us-west-2\": f\"arn:aws:sagemaker:us-west-2:594846645681:model-package/{model_name}\",\n        \"ca-central-1\": f\"arn:aws:sagemaker:ca-central-1:470592106596:model-package/{model_name}\",\n        \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:model-package/{model_name}\",\n        \"eu-west-1\": f\"arn:aws:sagemaker:eu-west-1:985815980388:model-package/{model_name}\",\n        \"eu-west-2\": f\"arn:aws:sagemaker:eu-west-2:856760150666:model-package/{model_name}\",\n        \"eu-west-3\": f\"arn:aws:sagemaker:eu-west-3:843114510376:model-package/{model_name}\",\n        \"eu-north-1\": f\"arn:aws:sagemaker:eu-north-1:136758871317:model-package/{model_name}\",\n        \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{model_name}\",\n        \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{model_name}\",\n        \"ap-northeast-2\": f\"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{model_name}\",\n        \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{model_name}\",\n        \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:model-package/{model_name}\",\n        \"sa-east-1\": f\"arn:aws:sagemaker:sa-east-1:270155090741:model-package/{model_name}\",\n    }\n\n    return model_package_map[region_name]\n\nembedding_package_arn = get_arn_for_model(region, \"jina-embeddings-v2-base-en\")\nreranker_package_arn = get_arn_for_model(region, \"jina-reranker-v1-base-en\")\n</code></pre><h2 id=\"load-the-dataset\">データセットの読み込み</h2><p>このチュートリアルでは、YouTube チャンネル <a href=\"https://www.youtube.com/@tudelftonlinelearning1226?ref=jina-ai-gmbh.ghost.io\">TU Delft Online Learning</a> が提供する動画コレクションを使用します。このチャンネルは STEM 科目の様々な教育コンテンツを制作しています。そのプログラミングは <a href=\"https://creativecommons.org/licenses/by/3.0/legalcode?ref=jina-ai-gmbh.ghost.io\">CC-BY ライセンス</a>で提供されています。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.youtube.com/@tudelftonlinelearning1226?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">TU Delft Online Learning</div><div class=\"kg-bookmark-description\">科学、デザイン、エンジニアリングでキャリアを築きたいと考えていますか？TU Delft のオンライン学習コミュニティに参加しましょう！\nTU Delft のオンライン学習は、アクティブラーニングを意味します。コースは魅力的な学習体験を提供するように設計されています。コースの内容は、あなたの個人的な成長と専門的な発展を促進する、チャレンジングで要求の高いものですが、オンラインコースが提供する柔軟性とアクセシビリティを楽しみながら、人生の他の優先事項と学習を両立することができます。今日から学習を始めましょう：https://online-learning.tud…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.youtube.com/s/desktop/4feff1e2/img/favicon_144x144.png\" alt=\"\"><span class=\"kg-bookmark-author\">YouTube</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://yt3.googleusercontent.com/ytc/AIdro_kH5d18Xqqj-MKv9k_tf2KNFufCpMY8qEXdQzEy=s900-c-k-c0x00ffffff-no-rj\" alt=\"\"></div></a></figure><p>このチャンネルから 193 本の動画をダウンロードし、OpenAI のオープンソース <a href=\"https://openai.com/research/whisper?ref=jina-ai-gmbh.ghost.io\">Whisper 音声認識モデル</a>で処理しました。動画を文字起こしするために、最小モデルの <a href=\"https://huggingface.co/openai/whisper-tiny?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>openai/whisper-tiny</code></a> を使用しました。</p><p>文字起こしは CSV ファイルにまとめられており、<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/sagemaker/tu_delft.csv?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">こちらからダウンロード</a>できます。</p><p>ファイルの各行には以下が含まれています：</p><ul><li>動画のタイトル</li><li>YouTube の動画 URL</li><li>動画の文字起こしテキスト</li></ul><p>Python でこのデータを読み込むには、まず <code>pandas</code> と <code>requests</code> をインストールしてください：</p><pre><code class=\"language-bash\">pip install requests pandas\n</code></pre><p>CSV データを直接 <code>tu_delft_dataframe</code> という名前の Pandas DataFrame に読み込みます：</p><pre><code class=\"language-python\">import pandas\n\n# Load the CSV file\ntu_delft_dataframe = pandas.read_csv(\"https://raw.githubusercontent.com/jina-ai/workshops/feat-sagemaker-post/notebooks/embeddings/sagemaker/tu_delft.csv\")\n</code></pre><p>DataFrame の <code>head()</code> メソッドを使用して内容を確認できます。ノートブックでは以下のように表示されるはずです：</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/03/Screenshot-2024-03-15-at-14.30.35.png\" class=\"kg-image\" alt=\"「Green Teams in Hospitals（病院のグリーンチーム）」などのウェビナータイトル、YouTube URL、導入テキスト抜粋を示すデータフレーム\" loading=\"lazy\" width=\"1440\" height=\"580\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Screenshot-2024-03-15-at-14.30.35.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Screenshot-2024-03-15-at-14.30.35.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Screenshot-2024-03-15-at-14.30.35.png 1440w\" sizes=\"(min-width: 720px) 720px\"></figure><p>このデータセットに記載されている URL を使用して動画を視聴し、音声認識が完璧ではありませんが、基本的に正確であることを確認することもできます。</p><h2 id=\"start-the-jina-embeddings-v2-endpoint\">Jina Embeddings v2 エンドポイントの起動</h2><p>以下のコードは、埋め込みモデルを実行するために AWS 上で <code>ml.g4dn.xlarge</code> インスタンスを起動します。これが完了するまでに数分かかる場合があります。</p><pre><code class=\"language-python\">import boto3\nfrom jina_sagemaker import Client\n\n# 埋め込みエンドポイントの名前を選択してください。便利な名前なら何でも構いません。\nembeddings_endpoint_name = \"jina_embedding\"\n\nembedding_client = Client(region_name=boto3.Session().region_name)\nembedding_client.create_endpoint(\n    arn=embedding_package_arn,\n    role=role,\n    endpoint_name=embeddings_endpoint_name,\n    instance_type=\"ml.g4dn.xlarge\",\n    n_instances=1,\n)\n\nembedding_client.connect_to_endpoint(endpoint_name=embeddings_endpoint_name)\n</code></pre><p>必要に応じて <code>instance_type</code> を変更して、別の AWS クラウドインスタンスタイプを選択してください。</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">AWS は、このコマンドが返された時点から課金を開始します。このインスタンスを停止するまで時間単位で課金されます。停止するには、<a href=\"#shutting-down\" rel=\"noreferrer\"><b><strong style=\"white-space: pre-wrap;\">シャットダウン</strong></b></a>セクションの手順に従ってください。</div></div><h2 id=\"build-and-index-the-dataset\">データセットの構築とインデックス作成</h2><p>データを読み込み、Jina Embeddings v2 モデルを実行している状態で、データの準備とインデックス作成を行うことができます。データは <a href=\"https://faiss.ai/index.html?ref=jina-ai-gmbh.ghost.io\">FAISS ベクトルストア</a>（AI アプリケーション向けに特別に設計されたオープンソースのベクトルデータベース）に保存します。</p><p>まず、RAG アプリケーションの残りの前提条件をインストールしてください：</p><pre><code class=\"language-bash\">pip install tdqm numpy faiss-cpu\n</code></pre><h3 id=\"chunking\">チャンキング</h3><p>LLM のプロンプトに複数のテキストを収めるために、個々の文字起こしをより小さな部分（「チャンク」）に分割する必要があります。以下のコードは、デフォルトで各チャンクが 128 語を超えないように、文の境界で個々の文字起こしを分割します。</p><pre><code class=\"language-python\">def chunk_text(text, max_words=128):\n    \"\"\"\n    Divide text into chunks where each chunk contains the maximum number \n    of full sentences with fewer words than `max_words`.\n    \"\"\"\n    sentences = text.split(\".\")\n    chunk = []\n    word_count = 0\n\n    for sentence in sentences:\n        sentence = sentence.strip(\".\")\n        if not sentence:\n          continue\n\n        words_in_sentence = len(sentence.split())\n        if word_count + words_in_sentence &lt;= max_words:\n            chunk.append(sentence)\n            word_count += words_in_sentence\n        else:\n            # Yield the current chunk and start a new one\n            if chunk:\n              yield \". \".join(chunk).strip() + \".\"\n            chunk = [sentence]\n            word_count = words_in_sentence\n\n    # Yield the last chunk if it's not empty\n    if chunk:\n        yield \" \".join(chunk).strip() + \".\"</code></pre><h3 id=\"get-embeddings-for-each-chunk\">各チャンクの Embeddings を取得する</h3><p>FAISS データベースに保存するため、各チャンクの embedding が必要です。テキストチャンクを Jina AI の embedding モデルエンドポイントに渡し、<code>embedding_client.embed()</code>メソッドを使用して取得します。そして、テキストチャンクと embedding ベクトルを pandas データフレーム <code>tu_delft_dataframe</code> に新しい列 <code>chunks</code> と <code>embeddings</code> として追加します：</p><pre><code class=\"language-python\">import numpy as np\nfrom tqdm import tqdm\n\ntqdm.pandas()\n\ndef generate_embeddings(text_df):\n    chunks = list(chunk_text(text_df[\"Text\"]))\n    embeddings = []\n\n    for i, chunk in enumerate(chunks):\n      response = embedding_client.embed(texts=[chunk])\n      chunk_embedding = response[0][\"embedding\"]\n      embeddings.append(np.array(chunk_embedding))\n\n    text_df[\"chunks\"] = chunks\n    text_df[\"embeddings\"] = embeddings\n    return text_df\n\nprint(\"Embedding text chunks ...\")\ntu_delft_dataframe = generate_embeddings(tu_delft_dataframe)\n## Google Colab や Python ノートブックを使用している場合、\n## 上の行を削除して、以下の行のコメントを解除してください：\n# tu_delft_dataframe = tu_delft_dataframe.progress_apply(generate_embeddings, axis=1)\n</code></pre><h3 id=\"set-up-semantic-search-using-faiss\">Faiss を使用したセマンティック検索のセットアップ</h3><p>以下のコードは FAISS データベースを作成し、<code>tu_delft_pandas</code>を反復処理してチャンクと embedding ベクトルを挿入します：</p><pre><code class=\"language-python\">import faiss\n\ndim = 768  # Jina v2 embeddings の次元\nindex_with_ids = faiss.IndexIDMap(faiss.IndexFlatIP(dim))\nk = 0\n\ndoc_ref = dict()\n\nfor idx, row in tu_delft_dataframe.iterrows():\n    embeddings = row[\"embeddings\"]\n    for i, embedding in enumerate(embeddings):\n        normalized_embedding = np.ascontiguousarray(np.array(embedding, dtype=\"float32\").reshape(1, -1))\n        faiss.normalize_L2(normalized_embedding)\n        index_with_ids.add_with_ids(normalized_embedding, k)\n        doc_ref[k] = (row[\"chunks\"][i], idx)\n        k += 1\n</code></pre><h2 id=\"start-the-jina-reranker-v1-endpoint\">Jina Reranker v1 エンドポイントの起動</h2><p>上記の Jina Embedding v2 モデルと同様に、このコードは AWS 上で <code>ml.g4dn.xlarge</code> インスタンスを起動して reranker モデルを実行します。同様に、実行には数分かかる場合があります。</p><pre><code class=\"language-python\">import boto3\nfrom jina_sagemaker import Client\n\n# reranker エンドポイントの名前を選択します。便利な名前を使用できます。\nreranker_endpoint_name = \"jina_reranker\"\n\nreranker_client = Client(region_name=boto3.Session().region_name)\nreranker_client.create_endpoint(\n    arn=reranker_package_arn,\n    role=role,\n    endpoint_name=reranker_endpoint_name,\n    instance_type=\"ml.g4dn.xlarge\",\n    n_instances=1,\n)\n\nreranker_client.connect_to_endpoint(endpoint_name=reranker_endpoint_name)\n</code></pre><h2 id=\"define-query-functions\">クエリ関数の定義</h2><p>次に、テキストクエリに最も類似した転写チャンクを特定する関数を定義します。</p><p>これは 2 段階のプロセスです：</p><ol><li>データ準備段階で行ったように、<code>embedding_client.embed()</code>メソッドを使用してユーザー入力を embedding ベクトルに変換します。</li><li>embedding を FAISS インデックスに渡して最適な一致を取得します。以下の関数では、デフォルトで上位 20 件の一致を返しますが、<code>n</code>パラメータで制御できます。</li></ol><p><code>find_most_similar_transcript_segment</code>関数は、保存された embedding とクエリ embedding のコサインを比較して、最適な一致を返します。</p><pre><code class=\"language-python\">def find_most_similar_transcript_segment(query, n=20):\n    query_embedding = embedding_client.embed(texts=[query])[0][\"embedding\"]  # クエリが十分に短いと仮定してチャンク分割は不要\n    query_embedding = np.ascontiguousarray(np.array(query_embedding, dtype=\"float32\").reshape(1, -1))\n    faiss.normalize_L2(query_embedding)\n\n    D, I = index_with_ids.search(query_embedding, n)  # 上位 n 件の一致を取得\n\n    results = []\n    for i in range(n):\n        distance = D[0][i]\n        index_id = I[0][i]\n        transcript_segment, doc_idx = doc_ref[index_id]\n        results.append((transcript_segment, doc_idx, distance))\n\n    # 結果を距離でソート\n    results.sort(key=lambda x: x[2])\n\n    return [(tu_delft_dataframe.iloc[r[1]][\"Title\"].strip(), r[0]) for r in results]\n</code></pre><p>また、reranker エンドポイント <code>reranker_client</code>にアクセスし、<code>find_most_similar_transcript_segment</code>の結果を渡して、最も関連性の高い 3 つの結果のみを返す関数を定義します。これは、<code>reranker_client.rerank()</code>メソッドを使用して reranker エンドポイントを呼び出します。</p><pre><code class=\"language-python\">def rerank_results(query_found, query, n=3):\n    ret = reranker_client.rerank(\n        documents=[f[1] for f in query_found], \n        query=query, \n        top_n=n,\n    )\n    return [query_found[r['index']] for r in ret[0]['results']]\n</code></pre><h2 id=\"use-jumpstart-to-load-mistral-instruct\">JumpStart を使用して Mistral-Instruct をロード</h2><p>このチュートリアルでは、RAG システムの LLM 部分として、<a href=\"https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/?ref=jina-ai-gmbh.ghost.io\">Amazon SageMaker JumpStart で利用可能</a>な <code>mistral-7b-instruct</code> モデルを使用します。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Mistral 7B foundation models from Mistral AI are now available in Amazon SageMaker JumpStart | Amazon Web Services</div><div class=\"kg-bookmark-description\">Today, we are excited to announce that the Mistral 7B foundation models, developed by Mistral AI, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. With 7 billion parameters, Mistral 7B can be easily customized and quickly deployed. You can try out this model with SageMaker JumpStart, a […]</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://a0.awsstatic.com/main/images/site/touch-icon-ipad-144-smile.png\" alt=\"\"><span class=\"kg-bookmark-author\">Amazon Web Services</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/mistral-7b-sagemaker-jumpstart.jpg\" alt=\"\"></div></a></figure><p>以下のコードを実行して、Mistral-Instruct をロードおよびデプロイします：</p><pre><code class=\"language-python\">from sagemaker.jumpstart.model import JumpStartModel\n\njumpstart_model = JumpStartModel(model_id=\"huggingface-llm-mistral-7b-instruct\", role=role)\nmodel_predictor = jumpstart_model.deploy()\n</code></pre><p>このLLMにアクセスするエンドポイントは変数 <code>model_predictor</code> に格納されます。</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\">このモデルの使用も AWS の課金対象サービスとなるため、このチュートリアルを終了したら必ず停止してください。<a href=\"#shutting-down\" rel=\"noreferrer\"><b><strong style=\"white-space: pre-wrap;\">シャットダウン</strong></b></a>セクションを参照して、完了したらこのデプロイメントを停止してください。</div></div><h3 id=\"mistral-instruct-with-jumpstart\">JumpStart での Mistral-Instruct の使用</h3><p>以下は、<a href=\"https://docs.python.org/3/library/string.html?ref=jina-ai-gmbh.ghost.io#template-strings\">Python の組み込み string テンプレートクラス</a>を使用して、このアプリケーション用の Mistral-Instruct のプロンプトテンプレートを作成するコードです。各クエリに対して、モデルに提示される 3 つの一致する転写チャンクがあることを前提としています。</p><p>このテンプレートを自分で試して、このアプリケーションを修正したり、より良い結果が得られるかどうかを確認したりすることができます。</p><pre><code class=\"language-python\">from string import Template\n\nprompt_template = Template(\"\"\"\n  &lt;s&gt;[INST] 与えられたコンテキストのみを使用して、以下の質問に答えてください。\n  ユーザーからの質問は、YouTube チャンネルの動画の書き起こしに基づいています。\n  コンテキストは、ユーザーの質問に関連する情報として、（動画タイトル、書き起こしセグメント）\n    の形式でランク付けされたリストとして提示されています。\n  回答は提示されたコンテキストのみを使用する必要があります。コンテキストに基づいて\n    質問に答えられない場合は、その旨を述べてください。\n\n  コンテキスト：\n  1. 動画タイトル：$title_1、書き起こしセグメント：$segment_1\n  2. 動画タイトル：$title_2、書き起こしセグメント：$segment_2\n  3. 動画タイトル：$title_3、書き起こしセグメント：$segment_3\n\n  質問：$question\n\n  回答：[/INST]\n\"\"\")\n</code></pre><p>このコンポーネントを配置したことで、完全な RAG アプリケーションのすべての部分が揃いました。</p><h2 id=\"querying-the-model\">モデルへのクエリ</h2><p>モデルへのクエリは 3 段階のプロセスです。</p><ol><li>クエリに基づいて関連するチャンクを検索します。</li><li>プロンプトを組み立てます。</li><li>プロンプトを Mistral-Instruct モデルに送信し、その回答を返します。</li></ol><p>関連するチャンクを検索するには、上で定義した <code>find_most_similar_transcript_segment</code> 関数を使用します。</p><pre><code class=\"language-python\">question = \"最初の洋上風力発電所はいつ稼働しましたか？\"\nsearch_results = find_most_similar_transcript_segment(question)\nreranked_results = rerank_results(search_results, question)\n</code></pre><p>検索結果を再ランク付けされた順序で確認できます：</p><pre><code class=\"language-python\">for title, text, _ in reranked_results:\n    print(title + \"\\n\" + text + \"\\n\")\n</code></pre><p>結果：</p><pre><code class=\"language-text\">Offshore Wind Farm Technology - Course Introduction\nSince the first offshore wind farm commissioned in 1991 in Denmark, scientists and engineers have adapted and improved the technology of wind energy to offshore conditions.  This is a rapidly evolving field with installation of increasingly larger wind turbines in deeper waters.  At sea, the challenges are indeed numerous, with combined wind and wave loads, reduced accessibility and uncertain-solid conditions.  My name is Axel Vire, I'm an assistant professor in Wind Energy at U-Delf and specializing in offshore wind energy.  This course will touch upon the critical aspect of wind energy, how to integrate the various engineering disciplines involved in offshore wind energy.  Each week we will focus on a particular discipline and use it to design and operate a wind farm.\n\nOffshore Wind Farm Technology - Course Introduction\nI'm a researcher and lecturer at the Wind Energy and Economics Department and I will be your moderator throughout this course.  That means I will answer any questions you may have.  I'll strengthen the interactions between the participants and also I'll get you in touch with the lecturers when needed.  The course is mainly developed for professionals in the field of offshore wind energy.  We want to broaden their knowledge of the relevant technical disciplines and their integration.  Professionals with a scientific background who are new to the field of offshore wind energy will benefit from a high-level insight into the engineering aspects of wind energy.  Overall, the course will help you make the right choices during the development and operation of offshore wind farms.\n\nOffshore Wind Farm Technology - Course Introduction\nDesigned wind turbines that better withstand wind, wave and current loads  Identify great integration strategies for offshore wind turbines and gain understanding of the operational and maintenance of offshore wind turbines and farms  We also hope that you will benefit from the course and from interaction with other learners who share your interest in wind energy  And therefore we look forward to meeting you online.\n</code></pre><p>この情報を直接プロンプトテンプレートで使用できます：</p><pre><code class=\"language-python\">prompt_for_llm = prompt_template.substitute(\n    question = question,\n    title_1 = search_results[0][0],\n    segment_1 = search_results[0][1],\n    title_2 = search_results[1][0],\n    segment_2 = search_results[1][1],\n    title_3 = search_results[2][0],\n    segment_3 = search_results[2][1],\n)\n</code></pre><p>実際に LLM に送信されるプロンプトを確認するために文字列を出力します：</p><pre><code class=\"language-python\">print(prompt_for_llm)\n</code></pre><pre><code class=\"language-text\">&lt;s&gt;[INST] Answer the question below only using the given context.\n  The question from the user is based on transcripts of videos from a YouTube\n    channel.\n  The context is presented as a ranked list of information in the form of\n    (video-title, transcript-segment), that is relevant for answering the\n    user's question.\n  The answer should only use the presented context. If the question cannot be\n    answered based on the context, say so.\n\n  Context:\n  1. Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: Since the first offshore wind farm commissioned in 1991 in Denmark, scientists and engineers have adapted and improved the technology of wind energy to offshore conditions.  This is a rapidly evolving field with installation of increasingly larger wind turbines in deeper waters.  At sea, the challenges are indeed numerous, with combined wind and wave loads, reduced accessibility and uncertain-solid conditions.  My name is Axel Vire, I'm an assistant professor in Wind Energy at U-Delf and specializing in offshore wind energy.  This course will touch upon the critical aspect of wind energy, how to integrate the various engineering disciplines involved in offshore wind energy.  Each week we will focus on a particular discipline and use it to design and operate a wind farm.\n  2. Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: For example, we look at how to characterize the wind and wave conditions at a given location.  How to best place the wind turbines in a farm and also how to retrieve the electricity back to shore.  We look at the main design drivers for offshore wind turbines and their components.  We'll see how these aspects influence one another and the best choices to reduce the cost of energy.  This course is organized by the two-delfd wind energy institute, an interfaculty research organization focusing specifically on wind energy.  You will therefore benefit from the expertise of the lecturers in three different faculties of the university.  Aerospace engineering, civil engineering and electrical engineering.  Hi, my name is Ricardo Pareda.\n  3. Video-title: Systems Analysis for Problem Structuring part 1B the mono actor perspective example, transcript-segment: So let's assume the demarcation of the problem and the analysis of objectives has led to the identification of three criteria.  The security of supply, the percentage of offshore power generation and the costs of energy provision.  We now reason backwards to explore what factors have an influence on these system outcomes.  Really, the offshore percentage is positively influenced by the installed Wind Power capacity at sea, a key system factor.  Capacity at sea in turn is determined by both the size and the number of wind farms at sea.  The Ministry of Economic Affairs cannot itself invest in new wind farms but hopes to simulate investors and energy companies by providing subsidies and by expediting the granting process of licenses as needed.\n\n  Question: When was the first offshore wind farm commissioned?\n\n  Answer: [/INST]\n</code></pre><p>このプロンプトを LLM エンドポイント —<code>model_predictor</code>— に <code>model_predictor.predict()</code> メソッドを通して渡します：</p><pre><code class=\"language-python\">answer = model_predictor.predict({\"inputs\": prompt_for_llm})\n</code></pre><p>これはリストを返しますが、1つのプロンプトのみを渡したため、1つのエントリを持つリストになります。各エントリはキー <code>generated_text</code> の下に応答テキストを持つ <code>dict</code> です：</p><pre><code class=\"language-python\">answer = answer[0]['generated_text']\nprint(answer)\n</code></pre><p>結果：</p><pre><code class=\"language-text\">The first offshore wind farm was commissioned in 1991. (Context: Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: Since the first offshore wind farm commissioned in 1991 in Denmark, ...)\n</code></pre><p>文字列の質問をパラメータとして受け取り、文字列として答えを返す関数を書いて、クエリを単純化しましょう：</p><pre><code class=\"language-python\">def ask_rag(question):\n    search_results = find_most_similar_transcript_segment(question)\n    reranked_results = rerank_results(search_results, question)\n    prompt_for_llm = prompt_template.substitute(\n        question = question,\n        title_1 = search_results[0][0],\n        segment_1 = search_results[0][1],\n        title_2 = search_results[1][0],\n        segment_2 = search_results[1][1],\n        title_3 = search_results[2][0],\n        segment_3 = search_results[2][1],\n    )\n    answer = model_predictor.predict({\"inputs\": prompt_for_llm})\n    return answer[0][\"generated_text\"]\n</code></pre><p>これで、さらにいくつかの質問をすることができます。答えは動画のトランスクリプトの内容に依存します。例えば、データに答えがある場合は詳細な質問をして回答を得ることができます：</p><pre><code class=\"language-python\">ask_rag(\"What is a Kaplan Meyer estimator?\")\n</code></pre><pre><code class=\"language-text\">The Kaplan Meyer estimator is a non-parametric estimator for the survival \nfunction, defined for both censored and not censored data. It is represented \nas a series of declining horizontal steps that approaches the truths of the \nsurvival function if the sample size is sufficiently large enough. The value \nof the empirical survival function obtained is assumed to be constant between \ntwo successive distinct observations.\n</code></pre><pre><code class=\"language-python\">ask_rag(\"Who is Reneville Solingen?\")\n</code></pre><pre><code class=\"language-text\">Reneville Solingen is a professor at Delft University of Technology in Global \nSoftware Engineering. She is also a co-author of the book \"The Power of Scrum.\"\n</code></pre><pre><code class=\"language-python\">answer = ask_rag(\"What is the European Green Deal?\")\nprint(answer)\n</code></pre><pre><code class=\"language-text\">The European Green Deal is a policy initiative by the European Union to combat \nclimate change and decarbonize the economy, with a goal to make Europe carbon \nneutral by 2050. It involves the use of green procurement strategies in various \nsectors, including healthcare, to reduce carbon emissions and promote corporate \nsocial responsibility.\n</code></pre><p>また、利用可能な情報の範囲外の質問をすることもできます：</p><pre><code class=\"language-python\">ask_rag(\"What countries export the most coffee?\")\n</code></pre><pre><code class=\"language-text\">Based on the context provided, there is no clear answer to the user's \nquestion about which countries export the most coffee as the context \nonly discusses the Delft University's cafeteria discounts and sustainable \ncoffee options, as well as lithium production and alternatives for use in \nelectric car batteries.\n</code></pre><pre><code class=\"language-python\">ask_rag(\"How much wood could a woodchuck chuck if a woodchuck could chuck wood?\")\n</code></pre><pre><code class=\"language-text\">The context does not provide sufficient information to answer the question. \nThe context is about thermit welding of rails, stress concentration factors, \nand a lyrics video. There is no mention of woodchucks or the ability of \nwoodchuck to chuck wood in the context.\n</code></pre><p>自分のクエリを試してみてください。また、結果を改善するために LLM へのプロンプトの方法を変更することもできます。</p><h2 id=\"shutting-down\">シャットダウン</h2><p>使用するモデルと AWS インフラストラクチャの料金は時間単位で請求されるため、このチュートリアルを終了する際には、3つの AI モデルすべてを停止することが非常に重要です：</p><ul><li>埋め込みモデルエンドポイント <code>embedding_client</code></li><li>再ランカーモデルエンドポイント <code>reranker_client</code></li><li>大規模言語モデルエンドポイント <code>model_predictor</code></li></ul><p>3つのモデルエンドポイントすべてをシャットダウンするには、次のコードを実行します：</p><pre><code class=\"language-python\"># shut down the embedding endpoint\nembedding_client.delete_endpoint()\nembedding_client.close()\n# shut down the reranker endpoint\nreranker_client.delete_endpoint()\nreranker_client.close()\n# shut down the LLM endpoint\nmodel_predictor.delete_model()\nmodel_predictor.delete_endpoint()\n</code></pre><h2 id=\"get-started-now-with-jina-ai-models-on-aws-marketplace\">AWS Marketplace で Jina AI モデルを今すぐ始めましょう</h2><p>SageMaker 上の当社の埋め込みモデルと再ランキングモデルにより、AWS 上のエンタープライズ AI ユーザーは、既存のクラウド運用のメリットを損なうことなく、Jina AI の優れた価値提案に即座にアクセスできるようになりました。AWS のセキュリティ、信頼性、一貫性、予測可能な価格設定がすべて組み込まれています。</p><p>Jina AI では、既存のプロセスに AI を取り入れることで恩恵を受けられるビジネスに最先端技術をもたらすために懸命に取り組んでいます。私たちは、使いやすく実用的なインターフェースを通じて、手頃な価格で信頼性の高い高性能なモデルを提供することを目指し、AI への投資を最小限に抑えながら、リターンを最大化します。</p><p>当社が提供するすべての埋め込みモデルと再ランカーモデルのリストを確認し、7日間無料で試すには、<a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">Jina AI の AWS Marketplace のページ</a>をご覧ください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AWS Marketplace: Jina AI</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png\" alt=\"\"></div></a></figure><p>Jina AI の製品があなたのビジネスニーズにどのように適合するか、ユースケースについてお聞かせください。<a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\">当社のウェブサイト</a>または<a href=\"https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io\">Discord チャンネル</a>からご連絡いただき、フィードバックを共有したり、最新モデルの情報を入手したりすることができます。</p>",
  "comment_id": "65fabb91502fd000011c667e",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/03/Blog-images--27-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-03-20T11:33:53.000+01:00",
  "updated_at": "2024-03-25T19:10:29.000+01:00",
  "published_at": "2024-03-25T16:00:51.000+01:00",
  "custom_excerpt": "Learn to use Jina Embeddings and Reranking models in a full-stack AI application on AWS, using only components available in Amazon SageMaker and the AWS Marketplace.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    },
    {
      "id": "641c23a2f4d50d003d590474",
      "name": "Saahil Ognawala",
      "slug": "saahil",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg",
      "cover_image": null,
      "bio": "Senior Product Manager at Jina AI",
      "website": "http://www.saahilognawala.com/",
      "location": "Munich, DE",
      "facebook": null,
      "twitter": "@saahil",
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/saahil/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker/",
  "excerpt": "Amazon SageMaker と AWS マーケットプレイスで利用可能なコンポーネントのみを使用して、AWS 上のフルスタック AI アプリケーションで Jina Embeddings と Reranking モデルの使用方法を学びましょう。",
  "reading_time": 21,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Abstract image with colorful wavy background featuring AWS, Embeddings, and Reranker logos.",
  "feature_image_caption": null
}