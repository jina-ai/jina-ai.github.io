{
  "slug": "jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face",
  "id": "65b3adb510ff9f0001c50c4d",
  "uuid": "b082269a-4358-4a82-a70c-02da2ebcb6d3",
  "title": "Jina Embeddings v2 バイリンガルモデルが Hugging Face で オープンソース化されました",
  "html": "<p>Jina AI は Hugging Face を通じて最先端のオープンソース二言語埋め込みモデルを <a href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\">ドイツ語-英語</a>と<a href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\">中国語-英語</a>の言語ペアでリリースしました。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/ich-bin-ein-berliner-german-english-bilingual-embeddings-with-8k-token-length/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ich bin ein Berliner: German-English Bilingual Embeddings with 8K Token Length</div><div class=\"kg-bookmark-description\">Jina AI introduces a German/English bilingual embedding model, featuring an extensive 8,192-token length, specifically designed to support German businesses thriving in the U.S. market.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Explore-image-storytelling-beyond-pixels--33-.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/news/8k-token-length-bilingual-embeddings-break-language-barriers-in-chinese-and-english/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">8K Token-Length Bilingual Embeddings Break Language Barriers in Chinese and English</div><div class=\"kg-bookmark-description\">The first bilingual Chinese-English embedding model with 8192 token-length.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-publisher\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><p>このチュートリアルでは、最小限のインストールとユースケースについて説明します。内容は以下の通りです：</p><ol><li>Hugging Face から Jina Embedding モデルをダウンロードする。</li><li>モデルを使用してドイツ語と英語のテキストからエンコーディングを取得する。</li><li>クロス言語クエリのための基本的な埋め込みベースのニューラル検索エンジンを構築する。</li></ol><p>このチュートリアルでは、英語のクエリを使用してドイツ語のテキストを検索し、その逆も可能な方法を Jina Embeddings を使って示します。</p><p>このチュートリアルは中国語モデルでも同様に機能します。<a href=\"#querying-in-chinese\" rel=\"noreferrer\"><strong>Querying in Chinese</strong></a> というタイトルの節（最後の方）の指示に従って、中国語-英語二言語モデルと中国語の例文を取得してください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-de?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-de · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-de.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/jinaai/jina-embeddings-v2-base-zh?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">jinaai/jina-embeddings-v2-base-zh · Hugging Face</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://huggingface.co/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-embeddings-v2-base-zh.png\" alt=\"\"></div></a></figure><h2 id=\"bilingual-embedding-models\">二言語埋め込みモデル</h2><p>二言語埋め込みモデルは、2つの言語のテキスト（このチュートリアルではドイツ語と英語、中国語モデルでは中国語と英語）を同じ埋め込み空間にマッピングするモデルです。ドイツ語のテキストと英語のテキストが同じ意味を持つ場合、それらに対応する埋め込みベクトルが近くなるような方法でマッピングを行います。</p><p>このようなモデルは、このチュートリアルで示すクロス言語情報検索アプリケーションに非常に適していますが、RAG ベースのチャットボット、多言語テキスト分類、要約、感情分析、その他の埋め込みを使用するアプリケーションの基礎としても機能します。これらのモデルを使用することで、両方の言語のテキストを同じ言語で書かれているかのように扱うことができます。</p><p>多くの巨大言語モデルが多くの異なる言語をサポートすると主張していますが、すべての言語を同等にサポートしているわけではありません。インターネット上の英語の優位性による<a href=\"https://aclanthology.org/2023.findings-eacl.89/?ref=jina-ai-gmbh.ghost.io\">バイアス</a>や、<a href=\"https://arxiv.org/abs/2401.05749?ref=jina-ai-gmbh.ghost.io\">機械翻訳されたテキストのオンライン公開が広がることによる</a>入力ソースの歪みについて、懸念が高まっています。2つの言語に焦点を当てることで、両言語の埋め込み品質をより良くコントロールでき、バイアスを最小限に抑えながら、数十の言語を扱うと主張する巨大モデルと同等以上のパフォーマンスを持つ、はるかに小さなモデルを生成することができます。</p><p>Jina Embeddings v2 二言語モデルは 8,192 入力コンテキストトークンをサポートしており、2つの言語をサポートするだけでなく、同様のモデルと比較してより大きなテキストセグメントをサポートすることができます。これにより、より多くのテキスト情報を埋め込みに処理する必要がある、より複雑なユースケースに最適です。</p><h2 id=\"follow-along-on-google-colab\">Google Colab で一緒に進める</h2><p>このチュートリアルには、<a href=\"https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">付属のノートブック</a>があり、<a href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a> またはローカルシステムで実行できます。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://colab.research.google.com/github/jina-ai/workshops/blob/feat-embeddings-notebook/notebooks/embeddings/Bilingual_Embeddings.ipynb?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Colaboratory</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://ssl.gstatic.com/colaboratory-static/common/cce4fce8bbe78d8bdc0c77a288df9fa7/img/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" alt=\"\"></div></a></figure><h2 id=\"installing-the-prerequisites\">前提条件のインストール</h2><p>現在の環境に関連ライブラリがインストールされていることを確認してください。最新バージョンの <a href=\"https://pypi.org/project/transformers/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\"><code>transformers</code></a> が必要なので、すでにインストールされている場合でも、以下を実行してください：</p><pre><code class=\"language-bash\">pip install -U transformers \n</code></pre><p>このチュートリアルでは、Meta の <a href=\"https://faiss.ai/?ref=jina-ai-gmbh.ghost.io\">FAISS ライブラリ</a>を使用してベクトル検索と比較を行います。インストールするには、以下を実行してください：</p><pre><code class=\"language-bash\">pip install faiss-cpu\n</code></pre><p>また、このチュートリアルでは入力データの処理に <a href=\"https://www.crummy.com/software/BeautifulSoup/?ref=jina-ai-gmbh.ghost.io\">Beautiful Soup</a> を使用するので、以下をインストールしてください：</p><pre><code class=\"language-bash\">pip install bs4\n</code></pre><h2 id=\"access-to-hugging-face\">Hugging Face へのアクセス</h2><p>モデルをダウンロードするには、Hugging Face へのアクセス、特にアカウントとアクセストークンが必要です。</p><p><strong>Hugging Face のアカウントをお持ちでない場合：</strong></p><p><a href=\"https://huggingface.co/?ref=jina-ai-gmbh.ghost.io\">https://huggingface.co/</a> にアクセスし、ページ右上の「Sign Up」ボタンが表示されるはずです。クリックして、新しいアカウントを作成するための指示に従ってください。</p><figure class=\"kg-card kg-image-card\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png\" class=\"kg-image\" alt=\"Hugging Face のウェブフロントページ、「Sign Up」ボタンがハイライトされています。\" loading=\"lazy\" width=\"1088\" height=\"887\" srcset=\"https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/01/Untitled--26-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/01/Untitled--26-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--26-.png 1088w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>アカウントにログインした後：</strong></p><p>アクセストークンを取得するには、<a href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\">Hugging Face のウェブサイトの指示</a>に従ってください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://huggingface.co/docs/hub/security-tokens?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">User access tokens</div><div class=\"kg-bookmark-description\">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div>このトークンを <code>HF_TOKEN</code> という環境変数にコピーする必要があります。ノートブック（例えば <a href=\"https://colab.research.google.com/?ref=jina-ai-gmbh.ghost.io\" rel=\"noreferrer\">Google Colab</a>）で作業している場合や、Python プログラム内で直接設定する場合は、以下の Python コードを使用してください：\n\n<pre><code class=\"language-python\">import os\n\nos.environ['HF_TOKEN'] = \"&lt;your token here&gt;\"\n</code></pre>\n\nシェルでは、環境変数を設定するための適切な構文を使用してください。<code>bash</code> の場合：\n\n<pre><code class=\"language-bash\">export HF_TOKEN=\"&lt;your token here&gt;\"\n</code></pre>\n\n## ドイツ語と英語用の Jina Embeddings v2 のダウンロード\n\nトークンを設定したら、<code>transformers</code>ライブラリを使用してJina Embeddings ドイツ語-英語バイリンガルモデルをダウンロードできます：\n\n<pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-de', trust_remote_code=True)\n</code></pre>\n\n初回は数分かかる場合がありますが、モデルはローカルにキャッシュされるため、このチュートリアルを後で再開しても心配ありません。\n\n## 英語データのダウンロード\n\nこのチュートリアルでは、<a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\"><em>Pro Git: Everything You Need to Know About Git</em></a> の英語版を使用します。この本は中国語とドイツ語でも利用可能で、このチュートリアルの後半で使用します。\n\nEPUB版をダウンロードするには、以下のコマンドを実行します：\n\n<pre><code class=\"language-bash\">wget -O progit-en.epub https://open.umn.edu/opentextbooks/formats/3437</code></pre>\n\nこれにより、ローカルディレクトリに <code>progit-en.epub</code> というファイル名で本がコピーされます。\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://jina-ai-gmbh.ghost.io/content/images/2024/01/Untitled--27-.png\" class=\"kg-image\" alt=\"Scott Chacon と Ben Straub による「Pro Git」の紙の版の表紙。\" loading=\"lazy\" width=\"490\" height=\"647\"><figcaption><span style=\"white-space: pre-wrap;\">紙の版の表紙。</span></figcaption></figure>\n\nまたは、<a href=\"https://open.umn.edu/opentextbooks/formats/3437?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">https://open.umn.edu/opentextbooks/formats/3437</a> にアクセスしてローカルドライブにダウンロードすることもできます。<a href=\"https://creativecommons.org/licenses/by-nc-sa/3.0/?ref=jina-ai-gmbh.ghost.io\" rel=\"noopener noreferrer\">Creative Commons Attribution Non Commercial Share Alike 3.0 ライセンス</a>の下で利用可能です。\n\n## データの処理\n\nこのテキストは階層的なセクション構造を持っており、基礎となる XHTML データの <code>&lt;section&gt;</code> タグを探すことで簡単に見つけることができます。以下のコードは EPUB ファイルを読み込み、EPUB ファイルの内部構造と <code>&lt;section&gt;</code> タグを使用して分割し、各セクションを XHTML タグのないプレーンテキストに変換します。本の各セクションの位置を示す文字列のセットをキーとし、そのセクションのプレーンテキストの内容を値とする Python 辞書を作成します。\n\n<pre><code class=\"language-python\">from zipfile import ZipFile\nfrom bs4 import BeautifulSoup\nimport copy\n\ndef decompose_epub(file_name):\n    \n    def to_top_text(section):\n        selected = copy.copy(section)\n\t\t\t\twhile next_section := selected.find(\"section\"):\n            next_section.decompose()\n        return selected.get_text().strip()\n\n    ret = {}\n    with ZipFile(file_name, 'r') as zip:\n        for name in zip.namelist():\n            if name.endswith(\".xhtml\"):\n                data = zip.read(name)\n                doc = BeautifulSoup(data.decode('utf-8'), 'html.parser')\n                ret[name + \":top\"] = to_top_text(doc)\n                for num, sect in enumerate(doc.find_all(\"section\")):\n                    ret[name + f\"::{num}\"] = to_top_text(sect)\n    return ret\n</code></pre>\n\n次に、先ほどダウンロードした EPUB ファイルに対して <code>decompose_epub</code> 関数を実行します：\n\n<pre><code class=\"language-python\">book_data = decompose_epub(\"progit-en.epub\")\n</code></pre>\n\n変数 <code>book_data</code> には583のセクションが含まれます。例えば：\n\n<pre><code class=\"language-python\">print(book_data['EPUB/ch01-getting-started.xhtml::12'])\n</code></pre>\n\n結果：\n\n<pre><code class=\"language-Text\">The Command Line\nThere are a lot of different ways to use Git.\nThere are the original command-line tools, and there are many graphical user interfaces of varying capabilities.\nFor this book, we will be using Git on the command line.\nFor one, the command line is the only place you can run all Git commands — most of the GUIs implement only a partial subset of Git functionality for simplicity.\nIf you know how to run the command-line version, you can probably also figure out how to run the GUI version, while the opposite is not necessarily true.\nAlso, while your choice of graphical client is a matter of personal taste, all users will have the command-line tools installed and available.\nSo we will expect you to know how to open Terminal in macOS or Command Prompt or PowerShell in Windows.\nIf you don't know what we're talking about here, you may need to stop and research that quickly so that you can follow the rest of the examples and descriptions in this book.\n</code></pre>\n\n## Jina Embeddings v2 と FAISS によるエンベッディングの生成とインデックス作成\n\n583のセクションそれぞれについて、エンベッディングを生成し FAISS インデックスに保存します。Jina Embeddings v2 モデルは最大 8192 トークンの入力を受け付けることができ、この本のような場合、さらなるテキストの分割や、セクションがトークン制限を超えていないかチェックする必要はありません。本の最も長いセクションでも約12,000文字であり、通常の英語テキストであれば8kトークンの制限をはるかに下回ります。\n\n単一のエンベッディングを生成するには、ダウンロードしたモデルの <code>encode</code> メソッドを使用します。例えば：\n\n<pre><code class=\"language-python\">model.encode([book_data['EPUB/ch01-getting-started.xhtml::12']])\n</code></pre>\n\nこれにより、768次元のベクトルを含む配列が返されます：\n\n<pre><code class=\"language-python\">array([[ 6.11135997e-02,  1.67829826e-01, -1.94809273e-01,\n         4.45595086e-02,  3.28837298e-02, -1.33441269e-01,\n         1.35364473e-01, -1.23119736e-02,  7.51526654e-02,\n        -4.25386652e-02, -6.91794455e-02,  1.03527725e-01,\n        -2.90831417e-01, -6.21018047e-03, -2.16205455e-02,\n        -2.20803712e-02,  1.50471330e-01, -3.31433356e-01,\n        -1.48741454e-01, -2.10959971e-01,  8.80039856e-02,\n\t\t\t\t....\n</code></pre>\n\nこれがエンベッディングです。\n\nJina Embeddings モデルはバッチ処理が可能です。最適なバッチサイズは使用するハードウェアによって異なります。大きすぎるバッチサイズはメモリ不足のリスクがあります。小さすぎるバッチサイズは処理時間が長くなります。\n\n<div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">⚠️</div><div class=\"kg-callout-text\"><code spellcheck=\"false\" style=\"white-space: pre-wrap;\">batch_size=5</code> は GPU なしの無料枠の Google Colab で動作し、エンベッディングの全セットを生成するのに<b><strong style=\"white-space: pre-wrap;\">約1時間</strong></b>かかりました。</div></div>\n\n本番環境では、より強力なハードウェアを使用するか、Jina AI の <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Embedding API サービス</a>の使用をお勧めします。以下のリンクから、その仕組みと無料アクセスの始め方をご確認ください。\n\n<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">高性能、8192トークンのコンテキスト長、1.25Bトークンで$100、シームレスな OpenAI 代替、無料トライアル</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure>\n\n以下のコードはエンベッディングを生成し、FAISS インデックスに保存します。変数 <code>batch_size</code> は使用可能なリソースに応じて設定してください。\n\n<pre><code class=\"language-python\">import faiss\n\nbatch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre>\n\n本番環境では、Python 辞書はドキュメントとエンベッディングを扱うのに適切でもパフォーマンスが良いわけでもありません。目的に特化したベクターデータベースを使用すべきで、それぞれのデータベースにはデータ挿入のための独自の手順があります。\n\n## ドイツ語でのクエリによる英語の結果の取得\n\nこのテキストセットに対してクエリを実行する際、以下のような処理が行われます：\n\n1. Jina Embeddings ドイツ語-英語モデルがクエリのエンベッディングを作成します。\n2. FAISS インデックス（<code>faiss_index</code>）を使用して、クエリエンベッディングとのコサイン類似度が最も高い保存済みエンベッディングを見つけ、そのインデックス内の位置を返します。\n3. ベクターデータ配列（<code>vector_data</code>）から対応するテキストを探し、コサイン類似度、テキストの位置、テキスト自体を出力します。\n\n以下の <code>query</code> 関数がその処理を行います。\n\n</code></pre><code class=\"language-python\">def query(query_str):\n    query = model.encode([query_str], normalize_embeddings=True)\n    cosine, index = faiss_index.search(query, 1)\n    print(f\"Cosine: {cosine[0][0]}\")\n    loc, txt = vector_data[index[0][0]]\n    print(f\"Location: {loc}\\\\nText:\\\\n\\\\n{txt}\")\n</code></pre><p>では試してみましょう。</p><pre><code class=\"language-python\"># Translation: \"How do I roll back to a previous version?\"\nquery(\"Wie kann ich auf eine frühere Version zurücksetzen?\")\n</code></pre><p>結果：</p><pre><code class=\"language-text\">Cosine: 0.5202275514602661\nLocation: EPUB/ch02-git-basics-chapter.xhtml::20\nText:\n\nUndoing things with git restore\nGit version 2.23.0 introduced a new command: git restore.\nIt's basically an alternative to git reset which we just covered.\nFrom Git version 2.23.0 onwards, Git will use git restore instead of git reset for many undo operations.\nLet's retrace our steps, and undo things with git restore instead of git reset.\n</code></pre><p>これはその質問に対する良い回答と言えます。別の質問も試してみましょう：</p><pre><code class=\"language-python\"># Translation: \"What does 'version control' mean?\"\nquery(\"Was bedeutet 'Versionsverwaltung'?\")\n</code></pre><p>結果：</p><pre><code class=\"language-text\">Cosine: 0.5001817941665649\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nAbout Version Control\n\nWhat is \"version control\", and why should you care?\nVersion control is a system that records changes to a file or set of files over time so that you can recall specific versions later.\nFor the examples in this book, you will use software source code as the files being version controlled, though in reality you can do this with nearly any type of file on a computer.\nIf you are a graphic or web designer and want to keep every version of an image or layout (which you would most certainly want to), a Version Control System (VCS) is a very wise thing to use.\nIt allows you to revert selected files back to a previous state, revert the entire project back to a previous state, compare changes over time, see who last modified something that might be causing a problem, who introduced an issue and when, and more.\nUsing a VCS also generally means that if you screw things up or lose files, you can easily recover.\nIn addition, you get all this for very little overhead.\n</code></pre><p>ご自身のドイツ語の質問で試してみて、どの程度うまく機能するか確認してください。テキスト情報検索を扱う際の一般的な実践として、1つだけでなく3〜5つの応答を求めるべきです。最適な回答は必ずしも最初の回答ではありません。</p><h2 id=\"reversing-the-roles-querying-german-documents-with-english\">役割の逆転：英語でドイツ語文書を検索する</h2><p>『<a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git?ref=jina-ai-gmbh.ghost.io\">Pro Git: Everything You Need to Know About Git</a>』は<a href=\"https://open.umn.edu/opentextbooks/textbooks/pro-git-everything-you-need-to-know-about-git-german?ref=jina-ai-gmbh.ghost.io\">ドイツ語版</a>も利用可能です。同じモデルを使用して、言語を逆にしたデモを行うことができます。</p><p>電子書籍をダウンロードします：</p><pre><code class=\"language-bash\">wget -O progit-de.epub https://open.umn.edu/opentextbooks/formats/3454\n</code></pre><p>これにより書籍が <code>progit-de.epub</code> というファイルにコピーされます。次に、英語版と同じ方法で処理します：</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-de.epub\")\n</code></pre><p>そして、前回と同じ方法で埋め込みを生成します：</p><pre><code class=\"language-python\">batch_size = 5\n\nvector_data = []\nfaiss_index = faiss.IndexFlatIP(768)\n\ndata = [(key, txt) for key, txt in book_data.items()]\nbatches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n\nfor ind, batch in enumerate(batches):\n    print(f\"Processing batch {ind + 1} of {len(batches)}\")\n    batch_embeddings = model.encode([x[1] for x in batch], normalize_embeddings=True)\n    vector_data.extend(batch)\n    faiss_index.add(batch_embeddings)\n</code></pre><p>これで同じ <code>query</code> 関数を使用して、英語でドイツ語の回答を検索できます：</p><pre><code class=\"language-python\">query(\"What is version control?\")\n</code></pre><p>結果：</p><pre><code class=\"language-text\">Cosine: 0.6719034910202026\nLocation: EPUB/ch01-getting-started.xhtml::1\nText:\n\nWas ist Versionsverwaltung?\n\nWas ist „Versionsverwaltung\", und warum sollten Sie sich dafür interessieren?\nVersionsverwaltung ist ein System, welches die Änderungen an einer oder einer Reihe von Dateien über die Zeit hinweg protokolliert, sodass man später auf eine bestimmte Version zurückgreifen kann.\nDie Dateien, die in den Beispielen in diesem Buch unter Versionsverwaltung gestellt werden, enthalten Quelltext von Software, tatsächlich kann in der Praxis nahezu jede Art von Datei per Versionsverwaltung nachverfolgt werden.\nAls Grafik- oder Webdesigner möchte man zum Beispiel in der Lage sein, jede Version eines Bildes oder Layouts nachverfolgen zu können. Als solcher wäre es deshalb ratsam, ein Versionsverwaltungssystem (engl. Version Control System, VCS) einzusetzen.\nEin solches System erlaubt es, einzelne Dateien oder auch ein ganzes Projekt in einen früheren Zustand zurückzuversetzen, nachzuvollziehen, wer zuletzt welche Änderungen vorgenommen hat, die möglicherweise Probleme verursachen, herauszufinden wer eine Änderung ursprünglich vorgenommen hat und viele weitere Dinge.\nEin Versionsverwaltungssystem bietet allgemein die Möglichkeit, jederzeit zu einem vorherigen, funktionierenden Zustand zurückzukehren, auch wenn man einmal Mist gebaut oder aus irgendeinem Grund Dateien verloren hat.\nAll diese Vorteile erhält man für einen nur sehr geringen, zusätzlichen Aufwand.\n</code></pre><p>このセクションのタイトルは「What is version control?」という意味なので、これは良い応答と言えます。</p><h2 id=\"querying-in-chinese\">中国語での検索</h2><p>これらの例は、Jina Embeddings v2 を使用すれば中国語と英語でも全く同じように機能します。代わりに中国語モデルを使用するには、以下を実行するだけです：</p><pre><code class=\"language-python\">from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)\n</code></pre><p>そして『Pro Git: Everything You Need to Know About Git』の中国語版を入手するには：</p><pre><code class=\"language-python\">wget -O progit-zh.epub https://open.umn.edu/opentextbooks/formats/3455\n</code></pre><p>次に、中国語版の書籍を処理します：</p><pre><code class=\"language-python\">book_data = decompose_epub(\"progit-zh.epub\")\n</code></pre><p>このチュートリアルの他のコードはすべて同じように機能します。</p><h2 id=\"the-future-more-languages-including-programming\">未来：プログラミングを含むより多くの言語</h2><p>私たちは近い将来、スペイン語と日本語がすでに開発中であり、さらに英語と主要なプログラミング言語をサポートするモデルも含め、より多くのバイリンガルモデルをリリースする予定です。これらのモデルは、多言語情報を管理する国際企業に理想的に適しており、AI駆動の情報検索やRAGベースの生成言語モデルの基盤として、さまざまな最先端のAIユースケースに組み込むことができます。</p><p>Jina AI のモデルはコンパクトでありながら、同クラスで最高のパフォーマンスを発揮します。これは、最高のパフォーマンスを得るために最大のモデルが必要ないことを示しています。バイリンガルのパフォーマンスに焦点を当てることで、それらの言語により優れ、適応が容易で、キュレーションされていないデータで訓練された大規模モデルよりもコスト効率の高いモデルを生産しています。</p><p>Jina Embeddings は <a href=\"https://huggingface.co/jinaai?ref=jina-ai-gmbh.ghost.io\">Hugging Face</a>、Sagemaker で使用するための <a href=\"https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&ref=jina-ai-gmbh.ghost.io\">AWS マーケットプレイス</a>、および <a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings Web API</a> から利用できます。多くの AI プロセスフレームワークとベクターデータベースに完全に統合されています。</p><p>詳細については<a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings のウェブサイト</a>をご覧いただくか、Jina AI の製品があなたのビジネスプロセスにどのように適合するかについて、お気軽にお問い合わせください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">トップパフォーマンス、8192トークンのコンテキスト長、1.25Bトークンで$100、シームレスな OpenAI 代替、無料トライアル</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure>",
  "comment_id": "65b3adb510ff9f0001c50c4d",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/01/Blog-images--32-.png",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-01-26T14:03:49.000+01:00",
  "updated_at": "2024-02-05T17:19:35.000+01:00",
  "published_at": "2024-01-26T17:14:56.000+01:00",
  "custom_excerpt": "Jina AI's open-source bilingual embedding models for German-English and Chinese-English are now on Hugging Face.\nWe’re going to walk through installation and cross-language retrieval.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/jina-embeddings-v2-bilingual-models-are-now-open-source-on-hugging-face/",
  "excerpt": "Jina AI のオープンソースのドイツ語-英語と中国語-英語のバイリンガル埋め込みモデルが、Hugging Face で利用可能になりました。\nインストールと言語間検索について説明していきます。",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Colorful \"EMBEDDINGS\" text above a pile of yellow smileys on a black background with decorative lines at the top.",
  "feature_image_caption": null
}