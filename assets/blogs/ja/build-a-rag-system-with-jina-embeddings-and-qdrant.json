{
  "slug": "build-a-rag-system-with-jina-embeddings-and-qdrant",
  "id": "65ddadd039a5b70001810ea3",
  "uuid": "e3419a3e-4a7c-43c3-ac69-6f65f00a7ad8",
  "title": "Jina Embeddings と Qdrant で RAG システムを構築する",
  "html": "<p>Retrieval-augmented generation（RAG）は、<a href=\"https://dl.acm.org/doi/abs/10.5555/3495724.3496517?ref=jina-ai-gmbh.ghost.io\"><u>元々は大規模言語モデル</u></a>（LLMs）の拡張として考案された技術群ですが、現在では AI モデルの役割を完全に再考する代替パラダイムとして認識されつつあります。</p><p>ここでは、<a href=\"https://www.llamaindex.ai/?ref=jina-ai-gmbh.ghost.io\">LlamaIndex フレームワーク</a>、オープンソースの <a href=\"https://docs.mistral.ai/?ref=jina-ai-gmbh.ghost.io\">Mistral LLM</a>、<a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings v2</a>、そして<a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\">Qdrant の AI 対応ベクトルデータベース</a>を使用して、基本的な RAG エンジンの作り方をご紹介します。</p><h2 id=\"rag-in-context\"><strong>RAG の文脈</strong></h2><p>RAG システムでは、AI モデルの役割は依然として中心的ですが、より限定的です。学習データから得られた内部知識からプロンプトに応答するのではなく、プロンプト内で関連情報が提示されます。モデルの役割は、その情報を理解し、アウトプットへと統合することです。</p><p>これは AI モデルの強みを活かし、弱点を最小限に抑えます。</p><p>例えば、<a href=\"https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io\"><u>Mistral-Instruct モデル</u></a>に以下のようなプロンプトを与えてみましょう：</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\nQuery: Why is Taylor Swift planning to attend the Superbowl?\nAnswer:\n</code></pre><p>私がこれを実行したとき、モデルは以下のように応答しました：</p><pre><code class=\"language-text\">I don't have real-time information. However, as of my last update,&nbsp;\nTaylor Swift is not officially confirmed to attend or perform at&nbsp;\nthe Superbowl. If there are any updates, I recommend checking the&nbsp;\nlatest news sources.</code></pre><p>大規模言語モデルの更新と再トレーニングには多大なコストがかかるため、その内部情報は常に最新の状態を維持することができません。</p><p>さらに、大規模言語モデルには「幻覚」、つまり部分的または完全に間違っている可能性があり、検証が必要な、もっともらしい回答を作り出すことがよく知られています。</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\nQuery: What was Weird Al Yankovic's first Taylor Swift parody?\nAnswer:\n\nWeird Al Yankovic's first Taylor Swift parody was \"TMZ,\" a spoof&nbsp;\nof Swift's song \"Blank Space.\" The parody was released in 2014&nbsp;\nas part of Yankovic's album \"Mandatory Fun.\" The song humorously&nbsp;\naddresses the obsession with celebrity gossip and scandals, as&nbsp;\nreported by the tabloid news website TMZ.</code></pre><p>Weird Al Yankovic の <em>TMZ</em> は 2011 年にアルバム <em>Alpocalypse</em> でリリースされ、Swift の <a href=\"https://youtu.be/vwp8Ur6tO-8?ref=jina-ai-gmbh.ghost.io\"><em><u>You Belong with Me</u></em></a> のパロディです。</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/BwqFgnl4rMs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\" title=\"TMZ (Parody of &quot;You Belong With Me&quot; by Taylor Swift) (Official 4K Video)\"></iframe></figure><p>ニューラルネットワークの性質上、幻覚を完全に防ぐことは困難、あるいは不可能であり、AI モデルを情報源として使用する計画を大きく損なっています。</p><p>OpenAI の CEO である Sam Altman は<a href=\"https://youtu.be/uaQZIK9gvNo?t=1130&ref=jina-ai-gmbh.ghost.io\"><u>次のように述べています</u></a>：</p><blockquote class=\"kg-blockquote-alt\">「これらのモデル［LLM］をデータベースとして考えることは大きな間違いだと思います。[...] ある程度は機能しますが、世界で最も高価で、最も遅く、最も不正確なデータベースのようなものです。」</blockquote><p>RAG は、AI モデルの世界に関する内部知識への依存を最小限に抑え、その最大の強みである自然言語理解と流暢な言語生成を活用します。</p><p>Mistral-Instruct が答えられない別の質問の例を見てみましょう：</p><pre><code class=\"language-text\">Answer the query. Please be brief, concise, and complete.\n\nQuery: What is the title of Taylor Swift's next album?\nAnswer:\n\nAs of the time I am providing this answer, Taylor Swift has&nbsp;\nnot yet announced the title of her next album. She has released&nbsp;\nseveral re-recorded albums, but the title of her next original&nbsp;\nalbum remains unknown. I recommend checking her official social&nbsp;\nmedia channels or website for the latest updates.</code></pre><p>RAG システムであれば、最新のニュース記事のデータベースを持っているか、Taylor Swift の次のアルバムのタイトルに関連するテキストをインターネットで検索することができます。そして、見つけたテキストをプロンプトに挿入します。</p><p>この質問に関連する<a href=\"https://apnews.com/article/taylor-swift-new-album-5e219107982b1498a3656caeea85e0eb?ref=jina-ai-gmbh.ghost.io\"><u>AP の記事</u></a>を見つけたと仮定して、以下のようなプロンプトを構築します：</p><pre><code class=\"language-text\">Context information is below.\n---------------------\nFebruary 6, 2024\nLOS ANGELES (AP) — Forget her \"Reputation.\" Taylor Swift has&nbsp;\na whole new album coming out.\n\nAccepting the Grammy for best pop vocal album on Sunday night,&nbsp;\nTaylor said she'd been keeping a secret for two years.\n\n\"My brand-new album comes out April 19. It's called 'The Tortured&nbsp;\nPoets Department.' I'm going to go and post the cover right now&nbsp;\nbackstage,\" she announced.\n\nAnd so she did.\n\n---------------------\nGiven the context information and not prior knowledge, answer the query.&nbsp;\nPlease be brief, concise, and complete.\nIf the context information does not contain an answer to the query,&nbsp;\nrespond with \"No information\".\nQuery: What is the title of Taylor Swift's next album?\nAnswer:</code></pre><p>Mistral-Instruct は以下のように応答しました：</p><pre><code class=\"language-text\">The title of Taylor Swift's next album is 'The Tortured Poets Department'.</code></pre><p>このようなプロンプトの与え方は、幻覚の可能性を大幅に減少させます。例えば：</p><pre><code class=\"language-text\">Context information is below.\n---------------------\nAlpocalypse is the thirteenth studio album by American parody&nbsp;\nmusician \"Weird Al\" Yankovic, released on June 21, 2011.\n\nTrack List\n\n1. Perform This Way (Parody of \"Born This Way\" by Lady Gaga)\n2. CNR\n3. TMZ (Parody of \"You Belong with Me\" by Taylor Swift)\n4. Skipper Dan\n5. Polka Face (Polka medley including songs by artists such as&nbsp;\n&nbsp;&nbsp;&nbsp;Lady Gaga, Justin Bieber, Britney Spears, Ke$ha, and others)\n6. Craigslist\n7. Party in the CIA (Parody of \"Party in the U.S.A.\" by Miley&nbsp;\n&nbsp;&nbsp;&nbsp;Cyrus)\n8. Ringtone\n9. Another Tattoo (Parody of \"Nothin' on You\" by B.o.B featuring&nbsp;\n&nbsp;&nbsp;&nbsp;Bruno Mars)\n10. If That Isn't Love\n11. Whatever You Like (Parody of \"Whatever You Like\" by T.I.)\n12. Stop Forwarding That Crap to Me\n\n---------------------\nGiven the context information and not prior knowledge, answer the&nbsp;\nquery. Please be brief, concise, and complete.\nIf the context information does not contain an answer to the query,&nbsp;\nrespond with \"No information\".\nQuery: What was Weird Al Yankovic's first Taylor Swift parody, what&nbsp;\nyear was it released, and what song was he parodying?\nAnswer:\n\nWeird Al Yankovic's first Taylor Swift parody was \"TMZ,\" and it was&nbsp;\nreleased in 2011. He was parodying \"You Belong with Me\" by Taylor&nbsp;\nSwift.\n</code></pre><h2 id=\"anatomy-of-a-rag-system\"><strong>RAG システムの構造</strong></h2><p>RAG システムには、最低限以下の 2 つのコンポーネントが必要です：</p><ul><li>生成 AI モデル</li><li>情報検索システム</li></ul><p>この記事では、生成 AI モデルとして <a href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2?ref=jina-ai-gmbh.ghost.io\">Mistral-Instruct</a> を使用し、<a href=\"https://huggingface.co/docs/api-inference/index?ref=jina-ai-gmbh.ghost.io\">Hugging Face Inference API</a> を通じてアクセスします。情報検索システムには、<a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\">Qdrant ベクトルデータベース</a>と <a href=\"https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings</a> を組み合わせて使用します。</p><p>データソースとして、2023 年 5 月に<a href=\"https://www.whitehouse.gov/ostp/ostps-teams/nstc/?ref=jina-ai-gmbh.ghost.io\">科学技術国家会議</a>が発表した<a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf?ref=jina-ai-gmbh.ghost.io\"><em><u>国家人工知能研究開発戦略計画 2023 更新版</u></em></a>を使用します。この約 25,000 語の文書は、米国の AI 政策と開発に関する政策および戦略計画文書です。</p><p>これは典型的な「長すぎて読めない」政府の政策文書です。その大部分は非常に退屈で、この分野に利害関係や強い関心がない限り、おそらく読もうとはしないでしょう。しかし、その内容を知りたいと思うかもしれません。</p><p>この記事では、テキストとその内容に関する質問に答えられる RAG システムを作成するステップを説明します。</p><h2 id=\"install-the-prerequisites\"><strong>前提条件のインストール</strong></h2><p>まず、関連する Python ライブラリがすべてインストールされていることを確認してください。Python 環境で以下を実行します：</p><pre><code class=\"language-shell\">pip install llama-index qdrant-client \npip install pdfminer.six llama-index-vector-stores-qdrant\npip install llama-index-llms-openai llama-index-embeddings-jinaai \npip install llama-index-llms-huggingface \"huggingface_hub[inference]\"</code></pre><p>Mistral-Instruct の大規模言語モデルを中心に RAG システムを構築するために LlamaIndex を使用し、PDF ファイルを Qdrant ベクトルストアに処理するために <a href=\"https://pypi.org/project/pdfminer.six/?ref=jina-ai-gmbh.ghost.io\"><u>pdfminer.six</u></a> を使用します。</p><h2 id=\"connect-to-mistral-instruct-via-the-hugging-face-inference-api\"><strong>Hugging Face Inference API を介して Mistral-Instruct に接続</strong></h2><p>まず、LLM をセットアップします。Hugging Face Inference API へのアクセスとアクセストークンが必要です。Hugging Face アカウントをお持ちの場合は、<a href=\"https://huggingface.co/settings/tokens.?ref=jina-ai-gmbh.ghost.io\">アカウント設定ページ</a>から取得できます。</p><p>アカウントをお持ちでない場合は、まず<a href=\"https://huggingface.co/join?ref=jina-ai-gmbh.ghost.io\">アカウントを作成</a>し、その後<a href=\"https://huggingface.co/settings/tokens?ref=jina-ai-gmbh.ghost.io\">アクセストークン</a>を作成してください。</p><p>今後使用するためにトークンを変数に格納します：</p><pre><code class=\"language-python\">hf_inference_api_key = '&lt;your HuggingFace Inference API token&gt;'</code></pre><p>次に、プロンプトテンプレートを作成します：</p><pre><code class=\"language-python\">from llama_index.core import PromptTemplate\n\nqa_prompt_tmpl = (\n    \"Context information is below.\\n\"\n    \"---------------------\\n\"\n    \"{context_str}\\\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the query. Please be brief, concise, and complete.\\n\"\n    \"If the context information does not contain an answer to the query, \"\n    \"respond with \\\"No information\\\".\\n\"\n    \"Query: {query_str}\\n\"\n    \"Answer: \"\n)\nqa_prompt = PromptTemplate(qa_prompt_tmpl)</code></pre><p>このテンプレートは、LLM に対して、提供されたコンテキスト情報のみを使用して質問に回答するよう指示します。このプロンプトは Mistral-Instruct との作業でうまく機能していますが、ユースケースに応じて他の表現も試してみることができます。</p><pre><code class=\"language-python\">from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n\nmixtral_llm = HuggingFaceInferenceAPI(\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n    token=hf_inference_api_key\n)</code></pre><p>最後に、Mistral-Instruct への接続を保持する LlamaIndex フレームワークのオブジェクトを作成し初期化します。以下のコードは、<a href=\"https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/?ref=jina-ai-gmbh.ghost.io\"><u>LlamaIndex を使用した RAG システムの作成に関する以前の投稿</u></a>からのものです。</p><p>これにより Mistral LLM への接続が変数 <code>mistral_llm</code> に格納されます。</p><h2 id=\"information-retrieval-with-qdrant-and-jina-embeddings\"><strong>Qdrant と Jina Embeddings を使用した情報検索</strong></h2><p>検索システムをセットアップするには、Jina Embeddings API キーが必要です。<a href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\">Jina Embeddings のウェブサイト</a>で、100万トークンの無料枠付きのキーを取得できます。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Embedding API</div><div class=\"kg-bookmark-description\">100万トークンの無料枠で始められます。検索と RAG システム向けの高性能な 8192 コンテキスト長の二言語対応エンベディング。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner-embedding-api.png\" alt=\"\"></div></a></figure><p>今後使用するために Jina Embeddings キーを変数に格納します：</p><pre><code class=\"language-python\">jina_emb_api_key = \"&lt;your Jina Embeddings API key&gt;\"</code></pre><p>次に、LlamaIndex を使用して Jina Embeddings サーバーのコネクタオブジェクトを作成し、特に英語のモノリンガルモデルを選択します：</p><pre><code class=\"language-python\">from llama_index.embeddings.jinaai import JinaEmbedding\n\njina_embedding_model = JinaEmbedding(\n    api_key=jina_emb_api_key,\n    model=\"jina-embeddings-v2-base-en\",\n)</code></pre><h3 id=\"load-text-data\"><strong>テキストデータの読み込み</strong></h3><p>次に、ドキュメントを読み込んで段落に分割します。まず、ホワイトハウスのウェブサイトから PDF をダウンロードして変数 <code>pdf_data</code> に格納します：</p><pre><code class=\"language-python\">import urllib.request\n\nuri = \"https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf\"\npdf_data = urllib.request.urlopen(uri).read()</code></pre><p>次に、PDF をページごとに処理し、テキストを抽出して二重改行で分割することで段落にチャンク分けします。これらはリスト <code>text_paras</code> に格納されます：</p><pre><code class=\"language-python\">import regex as re\nfrom io import BytesIO, StringIO\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfdocument import PDFDocument\nfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.pdfpage import PDFPage\nfrom pdfminer.pdfparser import PDFParser\n\ntext_paras = []\nparser = PDFParser(BytesIO(pdf_data))\ndoc = PDFDocument(parser)\nrsrcmgr = PDFResourceManager()\nfor page in PDFPage.create_pages(doc):\n    output_string = StringIO()\n    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    interpreter.process_page(page)\n    page_text = output_string.getvalue()\n    text_paras.extend(re.split(r'\\n\\s*\\n', page_text))\n</code></pre><p>すべてが読み込まれたことを確認します：</p><pre><code class=\"language-python\">assert len(text_paras) == 615</code></pre><p>次に、この短いテキストのリストを<a href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/root.html?ref=jina-ai-gmbh.ghost.io\">LlamaIndex Document オブジェクト</a>に変換します：</p><pre><code class=\"language-python\">from llama_index.core.readers import StringIterableReader\n\nrag_docs = StringIterableReader().load_data(text_paras)</code></pre><p>テキストを確認できます：</p><pre><code class=\"language-python\">print(rag_docs[0].text)</code></pre><p>結果：</p><pre><code class=\"language-text\">NATIONAL ARTIFICIAL INTELLIGENCE \nRESEARCH AND DEVELOPMENT \nSTRATEGIC PLAN \n2023 UPDATE</code></pre><h3 id=\"set-up-a-qdrant-vector-database\"><strong>Qdrant ベクトルデータベースのセットアップ</strong></h3><p>この記事では、RAG システムのデータベースを実装するために <a href=\"https://cloud.qdrant.io/?ref=jina-ai-gmbh.ghost.io\"><u>Qdrant Vector Search Cloud</u></a> を使用します。Qdrant の無料枠には 1GB のストレージが含まれており、このチュートリアルには十分すぎるほどです。</p><p>続行する前に、<a href=\"https://cloud.qdrant.io/login?ref=jina-ai-gmbh.ghost.io\"><u>Qdrant Cloud のウェブサイトでアカウントを作成</u></a>する必要があります。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://cloud.qdrant.io/login?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Vector Search Database | Qdrant Cloud</div><div class=\"kg-bookmark-description\">Qdrant ベクトル検索エンジンのマネージドクラウドソリューション。高性能なベクトル類似度検索のためのクラウドネイティブベクトルデータベース。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cloud.qdrant.io/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Qdrant Cloud</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cloud.qdrant.io/social.png\" alt=\"\"></div></a></figure><p>アカウントを作成してログインしたら、クラスターを作成する必要があります。Qdrant ウェブサイトの<a href=\"https://qdrant.tech/documentation/cloud/quickstart-cloud/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>「クイックスタート」の手順</u></a>に従って、無料クラスターをセットアップし、API キーと Qdrant ホストサーバーの名前を取得してください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/documentation/cloud/quickstart-cloud/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">クイックスタート - Qdrant</div><div class=\"kg-bookmark-description\">Qdrant は Rust で書かれたオープンソースのベクトルデータベースおよびベクトル検索エンジンです。便利な API を備えた高速でスケーラブルなベクトル類似度検索サービスを提供します。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://qdrant.tech/images/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Edit on GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://qdrant.tech/documentation/cloud/quickstart-cloud-social-preview.png\" alt=\"\"></div></a></figure><p>キーとホスト名を変数に格納します：</p><pre><code class=\"language-python\">qdrant_api_key = \"&lt;your API key&gt;\"\nqdrant_server = \"https://&lt;your server&gt;\"</code></pre><p>次に、<code>qdrant_client</code> と <code>llama_index</code> パッケージから関連コンポーネントをインポートする必要があります：</p><pre><code class=\"language-python\">import qdrant_client\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\n\nclient = qdrant_client.QdrantClient(qdrant_server, api_key=qdrant_api_key)\nvector_store = QdrantVectorStore(client=client, collection_name=\"NTSC\")</code></pre><p>これにより、無料クラスターに <code>NTSC</code> というコレクションが作成されます。</p><p>メモリまたはディスク上にローカルデータストアを構築し、Web API を介して Docker コンテナで独自の Qdrant サーバーインスタンスをホストする方法については、<a href=\"https://qdrant.tech/documentation/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>Qdrant のドキュメント</u></a>をご覧ください。</p><h3 id=\"complete-the-rag-system\"><strong>RAG システムを完成させる</strong></h3><p>ここでは、LlamaIndex の定型コードを使用してこれらのコンポーネントを完全な RAG システムにまとめます：</p><pre><code class=\"language-python\">from llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.storage.storage_context import StorageContext\nfrom llama_index.core import (\n\t\tVectorStoreIndex,\n\t\tServiceContext,\n\t\tget_response_synthesizer,\n)\n\n# set up the service and storage contexts\nservice_context = ServiceContext.from_defaults(\n&nbsp;&nbsp;&nbsp;&nbsp;llm=mixtral_llm, embed_model=jina_embedding_model\n)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n# create an index\nindex = VectorStoreIndex.from_documents(\n&nbsp;&nbsp;&nbsp;&nbsp;rag_docs, storage_context=storage_context, service_context=service_context\n)\n\n# configure retriever\nretriever = VectorIndexRetriever(\n&nbsp;&nbsp;&nbsp;&nbsp;index=index,\n&nbsp;&nbsp;&nbsp;&nbsp;similarity_top_k=2,\n)\n\n# configure response synthesizer\nresponse_synthesizer = get_response_synthesizer(\n&nbsp;&nbsp;&nbsp;&nbsp;service_context=service_context,\n&nbsp;&nbsp;&nbsp;&nbsp;text_qa_template=qa_prompt,\n&nbsp;&nbsp;&nbsp;&nbsp;response_mode=\"compact\",\n)\n\n# assemble query engine\nquery_engine = RetrieverQueryEngine(\n&nbsp;&nbsp;&nbsp;&nbsp;retriever=retriever,\n&nbsp;&nbsp;&nbsp;&nbsp;response_synthesizer=response_synthesizer,\n)\n</code></pre><p>このシステムは、Jina Embeddings を使用してテキストソースの段落をインデックス化し、すべてのプロンプトのコンテキストに上位 2 件のマッチを組み込みます。たとえば上位 3 件に変更するには、上記の <code>VectorIndexRetriever</code> の初期化で <code>similarity_top_k</code> パラメータを変更するだけです：</p><pre><code class=\"language-python\"># configure retriever\nretriever = VectorIndexRetriever(\n&nbsp;&nbsp;&nbsp;&nbsp;index=index,\n&nbsp;&nbsp;&nbsp;&nbsp;similarity_top_k=3,\n)</code></pre><p>これでシステムの準備が整いました。</p><h3 id=\"query-a-document\"><strong>ドキュメントに対するクエリ</strong></h3><p>簡単なクエリを試してみましょう：</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat is the Biden Administration's policy with regard to AI?&nbsp;\n\"\"\")\nprint(response.response)</code></pre><p>結果（あなたの結果と完全に一致しない場合があります）：</p><pre><code class=\"language-text\">The Biden Administration prioritizes responsible AI systems that&nbsp;\nare ethical, trustworthy, and safe, and serve the public good. \nThe Administration has committed to substantial funding for AI \nR&amp;D, and has established the National AI Initiative Office to \ncoordinate AI activities across the federal government.&nbsp;\n\nThe Administration's AI policy focuses on developing evaluative\ntechniques for AI, workforce development, public-private\npartnerships, and international collaboration in AI research.</code></pre><p>もっと具体的な質問も可能です：</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat protections does the AI Bill of Rights propose to offer?\n\"\"\")\n\nprint(response.response)</code></pre><pre><code class=\"language-text\">The AI Bill of Rights proposes five core protections: Safe and&nbsp;\nEffective Systems; Algorithmic Discrimination Protections; Data&nbsp;\nPrivacy; Notice and Explanation; and Human Alternatives,&nbsp;\nConsideration, and Fallback.</code></pre><p>さらに具体的な質問も：</p><pre><code class=\"language-python\">response = query_engine.query(\"Who is Kei Koizumi?\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">Kei Koizumi is the Principal Deputy Director for Policy at the Office&nbsp;\nof Science and Technology Policy (OSTP).</code></pre><p>より想像力に富んだ質問もできます：</p><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhat rights will AI's receive under President Biden's proposed&nbsp;\nAI Bill of Rights?\n\"\"\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">The proposed AI Bill of Rights does not grant rights to AI systems, but&nbsp;\nrather outlines principles to ensure that AI technologies are&nbsp;\ndeveloped and used in a manner that respects human rights and values.&nbsp;\nThe principles include safety, transparency, fairness, disclosure,&nbsp;\ndata privacy, non-discrimination, and the ability for individuals to&nbsp;\nopt out of certain AI systems.</code></pre><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nWhy is President Biden's proposing an AI Bill of Rights?\nDoes AI really need rights?\n\"\"\")\nprint(response.response)</code></pre><pre><code class=\"language-text\">President Biden's proposed AI Bill of Rights aims to ensure that AI&nbsp;\ntechnologies are developed and used ethically, legally, and with&nbsp;\nsocietal considerations in mind. The Bill of Rights is not granting&nbsp;\n\"rights\" to AI, but rather setting guidelines for the responsible&nbsp;\ndevelopment and deployment of AI systems to protect individuals and&nbsp;\ncommunities from potential negative impacts.</code></pre><pre><code class=\"language-python\">response = query_engine.query(\"\"\"\nHas Donald Trump weighed in on AI?\nWill he Make Humans Great Again?\n\"\"\")\nprint(response.response)\n</code></pre><pre><code class=\"language-text\">No information. The context information does not mention Donald&nbsp;\nTrump's views on AI.</code></pre><h2 id=\"jina-ai-and-qdrant\"><strong>Jina AI と Qdrant</strong></h2><p>Jina Embeddings の 8k トークンのコンテキストウィンドウは、より大きなテキストブロックを扱えるため、検索拡張生成に特に適しています。他の RAG アプリケーションでは個々の文や文のペアを保存する必要がある場合が多いのに対し、このチュートリアルではサイズを気にせず段落全体を使用することができました。</p><p>これにより、同じ情報を伝えるために保存する必要があるテキスト項目の数が減少し、計算コストを抑え、メモリを節約し、検索を高速化することができます。</p><p>Qdrant のベクターデータベースは設定が簡単で、高速かつコスト効率が良く、ご覧の通り、RAG システムに統合するのに数行の Python コードだけで済みます。</p><p>Qdrant の AI 対応データベースとクラウドサービスの詳細については、<a href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\" rel=\"noreferrer\"><u>ウェブサイトをご覧ください</u></a>。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://qdrant.tech/?utm_source=jinaai&utm_medium=partner&utm_campaign=qdrant-jinaai-rag-blog\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Qdrant - Vector Database</div><div class=\"kg-bookmark-description\">Qdrant は Rust で書かれたオープンソースのベクターデータベースとベクター検索エンジンです。便利な API を備えた高速でスケーラブルなベクター類似性検索サービスを提供します。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://qdrant.tech/images/apple-touch-icon.png\" alt=\"\"><span class=\"kg-bookmark-author\">Vector Database</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://qdrant.tech/images/previews/social-preview-P.png\" alt=\"\"></div></a></figure><h2 id=\"get-in-touch\"><strong>お問い合わせ</strong></h2><p>Jina AI は、あらゆる規模と種類の企業に信頼性の高い、手頃な価格の AI テクノロジーを提供することに尽力しています。私たちはお客様のユースケースについてお話を伺い、ビジネスプロセスに AI を適合させるお手伝いをさせていただきたいと考えています。Jina AI の提供サービスの詳細とお問い合わせについては、<a href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>Jina AI のウェブサイト</u></a>をご覧いただくか、<a href=\"https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io\"><u>Discord コミュニティ</u></a>にご参加ください。</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://jina.ai/?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI - Best Embeddings and Perfect Prompts</div><div class=\"kg-bookmark-description\">Jina AI は最高クラスのエンベディング API とプロンプトオプティマイザーを提供し、マルチモーダル AI アプリケーションの開発を容易にします。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://jina.ai/icons/favicon-128x128.png\" alt=\"\"><span class=\"kg-bookmark-author\">Best Embeddings and Perfect Prompts</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://jina.ai/banner.png\" alt=\"\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Jina AI の Discord サーバーに参加しよう！</div><div class=\"kg-bookmark-description\">Discord の Jina AI コミュニティをチェックしてください - 4493 人以上のメンバーと交流し、無料の音声およびテキストチャットをお楽しみください。</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://discord.com/assets/images/favicon.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Discord</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512\" alt=\"\"></div></a></figure>",
  "comment_id": "65ddadd039a5b70001810ea3",
  "feature_image": "https://jina-ai-gmbh.ghost.io/content/images/2024/02/Blog-images--26-.jpg",
  "featured": false,
  "visibility": "public",
  "created_at": "2024-02-27T10:39:28.000+01:00",
  "updated_at": "2024-03-06T15:41:18.000+01:00",
  "published_at": "2024-03-04T16:00:13.000+01:00",
  "custom_excerpt": "Create a RAG system with Jina Embeddings v2, Qdrant vector database, LlamaIndex, and Mistral LLM.",
  "codeinjection_head": null,
  "codeinjection_foot": null,
  "custom_template": null,
  "canonical_url": null,
  "authors": [
    {
      "id": "632ae7353e4e55003d52598e",
      "name": "Scott Martens",
      "slug": "scott",
      "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
      "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
      "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
      "website": "https://jina.ai",
      "location": "Berlin",
      "facebook": null,
      "twitter": null,
      "meta_title": null,
      "meta_description": null,
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "tags": [
    {
      "id": "634a1a8ccebfc1003d8ab706",
      "name": "Tech Blog",
      "slug": "tech-blog",
      "description": null,
      "feature_image": null,
      "visibility": "public",
      "og_image": null,
      "og_title": null,
      "og_description": null,
      "twitter_image": null,
      "twitter_title": null,
      "twitter_description": null,
      "meta_title": null,
      "meta_description": null,
      "codeinjection_head": null,
      "codeinjection_foot": null,
      "canonical_url": null,
      "accent_color": null,
      "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
    }
  ],
  "primary_author": {
    "id": "632ae7353e4e55003d52598e",
    "name": "Scott Martens",
    "slug": "scott",
    "profile_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg",
    "cover_image": "https://jina-ai-gmbh.ghost.io/content/images/2022/11/shanshui-ernie-crop.png",
    "bio": "A rogue AI created by Canada's Weapon X program.\n\nContent Creator @ Jina AI",
    "website": "https://jina.ai",
    "location": "Berlin",
    "facebook": null,
    "twitter": null,
    "meta_title": null,
    "meta_description": null,
    "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
  },
  "primary_tag": {
    "id": "634a1a8ccebfc1003d8ab706",
    "name": "Tech Blog",
    "slug": "tech-blog",
    "description": null,
    "feature_image": null,
    "visibility": "public",
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "canonical_url": null,
    "accent_color": null,
    "url": "https://jina-ai-gmbh.ghost.io/tag/tech-blog/"
  },
  "url": "https://jina-ai-gmbh.ghost.io/podcast/build-a-rag-system-with-jina-embeddings-and-qdrant/",
  "excerpt": "Jina Embeddings v2、Qdrant ベクトルデータベース、LlamaIndex、Mistral LLM を使用した RAG システムを構築する",
  "reading_time": 13,
  "access": true,
  "comments": false,
  "og_image": null,
  "og_title": null,
  "og_description": null,
  "twitter_image": null,
  "twitter_title": null,
  "twitter_description": null,
  "meta_title": null,
  "meta_description": null,
  "email_subject": null,
  "frontmatter": null,
  "feature_image_alt": "Promotional graphic with \"EMBEDDINGS 2\" and Drant logo separated by a red cross, symbolizing a partnership.",
  "feature_image_caption": null
}