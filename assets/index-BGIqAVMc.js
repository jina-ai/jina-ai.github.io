const e="我們提供一流的向量模型、重排器、LLM 讀取器和提示詞優化器，為多模態數據賦能最先進的搜索 AI。",n="您的搜索，從此起飛。",t={approach:"我們的策略",approach_connect_dots:"繪圖連線：從高級用户至企業用户",approach_connect_dots_description:"為何我們如此重視高級用户在整體策略中的地位？這是一個提前佈局的考量。今日之投資，為了明日他們在企業中的影響力。這是我們的遠見卓識，確保當這些高級用户掌握企業的話語權時，我們仍為他們心之所向。",approach_content1:"在人工智能的風雲變幻中，策略必須靈活應變，洞察未來。儘管 Jina AI 以企業為核心，但AI的舞台已演變，吸引客户的策略亦當與時俱進。因此，以高級用户為突破口，不僅是我們的策略創新，更體現了我們對企業發展的堅韌不拔。",approach_content2:"在 Jina AI，我們不甘於守成，而是勇於開創。以高級用户為先導，確保我們把握當下，預見未來。對於企業，我們的決心堅如磐石；但在通向成功的路上，我們走的是一條既穩健又前瞻的新路。",approach_content4:'每個人都希望獲得更好的搜索體驗。在 Jina AI，我們通過提供 <span class="text-primary text-bold">搜索底座</span>（由向量模型、重排器、讀取器 和 提示詞工程組成）來實現更好的搜索體驗。這些組件協同工作，徹底改變了我們搜索和理解數據的方式。',approach_miss_mark:"傳統MLOps的短板",approach_miss_mark_description:"儘管高級用户日益壯大，但傳統的MLOps工具往往步履蹣跚，難以滿足他們的需求。它們宛如過時的老馬，難以應對新時代的快節奏競賽。新一代的開發者飢渴地尋求更為輕巧、直觀的武器。",approach_new_paradigm:"提示詞工程：AI開發之新潮",approach_new_paradigm_description:"2023年，AI世界迎來新篇章，提示詞工程如日方升，實現了AI工具的大眾化進程。即使是那些缺乏編程根基的高級用户，也能遊刃有餘地涉獵AI，無需再對如Pytorch、Docker或Kubernetes等深感畏難。此情此景，與個人計算的崛起歷程頗為相似。當年，僅有的技術精英才可與計算機溝通，但隨着更為親和的界面的問世，大眾也得以加入其行列。今日，隨着提示詞工程的普及，我們正在目睹AI領域的新一輪普及浪潮。",awards:"獎項與殊榮",berlin:"德國柏林",berlin_address:"Prinzessinnenstraße 19-20，10969 柏林，德國",berlin_address2:"工商註冊地址: Leipzigerstr. 96, 10117 柏林, 德國",bj:"中國北京",bj_address:"中國北京市海淀區海淀西街48號6號樓5層",brochure_info:"我們公司的指南等待您的光臨",description:"未來從這裏開始。",download_brochure1:"下載手冊",download_docarray_logo:"下載 DocArray的Logo",download_docarray_logo_desc:"獲取 DocArray 徽標，這是一個由 Jina AI 發起的開源項目，並於 2022 年 12 月捐贈給了 Linux 基金會。提供淺色和深色模式、PNG 和 SVG 格式。",download_jina_logo:"下載Jina AI的Logo",download_jina_logo_desc:"獲取淺色和深色模式下的 Jina AI 徽標，提供 PNG 和 SVG 格式。該標誌是歐盟知識產權局（EUIPO）的註冊商標。",download_logo:"下載Logo",employees:"當今員工",empower_developers:"開發者生態",fastApiCaption:"自 2021 年以來捐款超過 20,000 美元。",founded:"成立年份",founded_in:"成立於",investors:"我們的投資方",linuxFoundationCaption:"從 2022 年開始，每年捐款 10,000 美元。",many:"許多",media:{video:"視頻採訪"},mission:"我們的使命",mission_content1:"我們的關鍵技術包括快速調優、快速服務、模型調優和模型服務，體現了我們致力於使人工智能普及的承諾。通過我們的開源計劃，我們努力促進創新、協作和透明度，確保提供可擴展、高效和強大的解決方案。Jina AI 不僅僅是一家公司；它是一個致力於幫助企業應對數字時代的動態挑戰並在其領域蓬勃發展的社區。",mission_content2:"Jina AI 的核心理念在於我們的使命：成為從高級用户、開發者至各大企業的多模態 AI 通道。我們深信開源的魔力，並致力於為 AI 社區構建前沿且易於接入的工具。我們的關鍵技術，諸如提示詞微調、模型向量調優部署等，展現了我們對 AI 普及的堅定信仰。藉助我們的開源方案，我們旨在推動創新、合作與透明度，確保我們的方案既可擴展、高效又強大。Jina AI 不只是一個公司，它更是一個助企業應對數字化時代挑戰並在其領域中持續領先的共同體。",mission_content3:"在 Jina AI，我們的使命是通過創新的向量模型和基於提示的技術，引領多模態AI的發展。我們特別關注自然語言處理、圖像與視頻分析以及跨模態數據交互等領域。我們的專業化致力於提供獨特的解決方案，能夠將複雜的多源數據轉化為具有實際操作價值的洞察和創新應用。",mit_report_title:"多模態：人工智能的新前沿",mit_techreview:"麻省理工科技評論",numfocusCaption:"從 2022 年開始每月定期捐款。",office:"我們的辦公室",otherProjectsCaption:"通過 Github 贊助捐贈了超過 3,000 美元。",our_answer:"不能同意更多，Yann。我們正在努力搭建通向多模態AI未來的橋樑！",pythonSoftwareFoundationCaption:"一次性捐贈 10,000 美元，並贊助了多項 PyCon 活動，包括德國、意大利、中國和美國的活動。",sefo:{layer0:"面向用户的應用",layer1:"RAG/編排系統",layer3:"GPU/移動/邊緣/本地計算"},segmentFaultCaption:"一次性捐款 6,000 美元。",show_position:"搜索底座在生態系統中的定位？",stats_1:"Jina AI 於 2020 年 2 月成立，短短 20 個月，已成為多模態AI技術的翹楚。這段時間裏，我們成功籌集了 3750 萬美元，確立了在 AI 行業的領軍地位。在 GitHub 上，我們的革命性開源技術賦能超過 40,000 名開發者，使他們得以毫無障礙地構建與部署多模態應用。",stats_2:"到了 2023 年，我們在基於多模態技術的 AI 工具方面取得了跨越式的突破。這一創新已讓超過 250,000 名用户受益，滿足了各式各樣的業務需求。無論是推動業務增長、提升運營效率還是優化成本，Jina AI 都致力於助力企業在多模態時代鋭意進取。",stats_4:'Jina AI 成立於 2020 年，總部位於柏林，是一家領先的搜索 AI 公司。我們提供 <span class="text-primary text-bold">搜索底座</span>，這是 GenAI 和多模態應用的核心。我們的使命是幫助企業和開發者解鎖多模態數據，通過更好的搜索創造價值。作為一家商業開源公司，我們喜歡開放式創新。',stats_v1:"當搜索與加速主義碰撞",subtitle:"通過人工智能生成的解決方案徹底改變內容創建，釋放無限可能性。塑造人工智能生成內容的未來並增強人類創造力。",sues_und_sauer:"酸甜苦辣",sues_und_sauer_tooltip:"Süß-Sauer 是德式中餐中一種流行的口味（地道的中餐裏這種口味並不常見，屬於德國人對中餐的刻板印象），意思是酸甜口。它隱喻着創業生涯的起起落落。",sz:"中國深圳",sz_address:"深圳市南山區賦安科技大廈4樓402",team:"我們的團隊",team_content1:"我們從全球各個角落構建 AI 的未來。我們獨特的視角豐富了我們的工作，激發了創新。在這個門户網站中，我們擁抱個性，熱情追求夢想。歡迎來到 AI 未來的門户網站。",team_join:"加入我們",team_size:"這些照片包括我們以前的同事和實習生——我們感謝他們每一個人。",technologies:"核心技術",title:"關於極納科技",title0:"未來",title1:"起源",title2:"於此",title3:"始於斯",understand_our_strength:"瞭解我們的強項",understand_our_view2:"瞭解搜索底座",users:"註冊用户",value:"我們的獎項",value_content1:"我們不會安於現狀。我們不會妥協。我們追求卓越。",vision:"我們的任務",vision_content1:"啓發於 Yann LeCun 對於AI的觀點，“",vision_content3:'AI 的未來是<span class="text-primary text-bold">多模態</span>，而我們是其中的一部分。我們意識到企業在利用多模態數據方面面臨挑戰。為此，我們致力於<span class="text-primary text-bold">搜索底座</span>，以幫助企業和開發者更好地進行搜索，並利用多模態數據促進業務增長。',yannlecun_quote:"僅靠單詞和句子訓練的人工智能系統永遠無法接近人類的理解力。"},i={answer1:"是的，同一個 API 密鑰適用於 Jina AI 的所有搜索底座產品。這包括向量、重新排名、讀取器和微調 API，所有服務之間共享詞元。",answer12:"我們遵守嚴格的隱私政策，不使用用户輸入數據來訓練我們的模型。",answer3:"是的，可以通過輸入 API 密鑰在“購買詞元”選項卡中監控詞元使用情況，從而查看使用歷史記錄和剩餘詞元。",answer4:"如果您丟失了充值秘鑰並希望取回它，請使用您的註冊電子郵件聯繫支持人員尋求幫助。",answer5:"不，我們的 API 密鑰沒有過期日期。但是，如果您懷疑您的密鑰已被泄露並希望廢棄它或將其詞元轉移到新密鑰，請聯繫我們的支持團隊尋求幫助。",answer6:"這是因為我們的無服務器架構在低使用率期間卸載了某些模型。初始請求會激活或“預熱”模型，這可能需要幾秒鐘的時間。初始激活後，後續請求的處理速度會更快。",question1:"我可以使用相同的 API 密鑰進行向量、重新排名、讀取器和微調 API 嗎？",question12:"用户輸入數據是否用於訓練您的模型？",question3:"我可以查看 API 密鑰的詞元使用情況嗎？",question4:"如果我忘記了 API 密鑰，該怎麼辦？",question5:"API 密鑰會過期嗎？",question6:"為什麼某些模型的第一次請求很慢？",title:"API相關常見問題"},a={base_model:"微調底座模型",check_data:"下載合成數據",check_model:"下載微調模型",data_size:"生成合成數據",description:"獲取您想要的任何域的微調向量模型。",description_long:"只需告訴我們您希望向量模型在哪個領域中表現出色，我們就會自動為該領域提供一個可立即使用的、經過微調的向量模型模型。",does_it_work_tho:"但它真的有效嗎？",does_it_work_tho_explain:"自動微調具有神奇的自動效果，可以為您想要的任何域提供微調的向量。但它真的有效嗎？這是一個相當合理的疑問。我們在各種領域和底座模型上對其進行了測試以找出答案。查看下面的精選和精選結果。",domain_instruction:"領域指令",embedding_provider:"選擇基礎向量模型",eval_evaluation:"驗證",eval_map:"地圖",eval_mrr:"月平均收入",eval_ndcg:"神經膠質細胞癌",eval_performance_before_after:"微調前後合成驗證集上的表現",eval_syntheticDataSize:"全部的",eval_test:"真實數據測試",eval_training:"訓練",faq_v1:{answer1:"此功能目前處於測試階段，每個微調模型需要花費 100 萬個詞元。如果 Embedding/Reranker API 中有足夠的詞元，您可以使用現有的 API 密鑰，也可以創建一個新的 API 密鑰，其中包含 100 萬個免費詞元。",answer10:"目前沒有。請注意，此功能仍處於測試階段。將微調後的模型和合成數據公開存儲在 Hugging Face 模型中心有助於我們和社區評估訓練的質量。未來，我們計劃提供私人存儲選項。",answer11:"由於所有微調模型都已上傳至 Hugging Face，因此您只需指定模型名稱即可通過 SentenceTransformers 訪問它們。",answer12:"請檢查您的垃圾郵件文件夾。如果仍然找不到，請使用您提供的電子郵件地址聯繫我們的支持團隊。",answer2:"您無需提供任何訓練數據。只需用自然語言描述您的目標域（您希望優化微調向量模型的域），或使用 URL 作為參考，我們的系統就會生成合成數據來訓練模型。",answer3:"大約 30 分鐘。",answer4:"經過微調的模型和合成數據公開存儲在 Hugging Face 模型中心。",answer5:"系統使用 Reader API 從 URL 中獲取內容。然後分析內容以總結語氣和領域，並以此作為生成合成數據的指導方針。因此，URL 應該是公開可訪問的，並且代表目標域。",answer6:"是的，您可以針對非英語語言微調模型。系統會自動檢測域指令的語言並相應地生成合成數據。我們還建議為目標語言選擇合適的底座模型。例如，如果針對德語域，則應選擇“jina-embeddings-v2-base-de”作為底座模型。",answer7:"不，我們的微調 API 僅支持 Jina v2 模型。",answer8:"在微調過程結束時，系統會使用保留的測試集評估模型並報告性能指標。您將收到一封電子郵件，詳細説明此測試集的前後性能。我們還鼓勵您在自己的測試集上評估模型以確保其質量。",answer9:"該系統通過將您提供的目標域指令與 LLM 智能體的推理相結合來生成合成數據。它會產生具有挑戰的三元組，這對於訓練高質量的向量模型模型至關重要。有關更多詳細信息，請參閲我們即將在 Arxiv 上發表的研究論文。",question1:"微調 API 的費用是多少？",question10:"我可以對我的微調模型和合成數據保持私密嗎？",question11:"如何使用微調模型？",question12:"我從未收到包含評估結果的電子郵件。我該怎麼辦？",question2:"我需要輸入什麼？我需要提供訓練數據嗎？",question3:"微調一個模型需要多長時間？",question4:"微調後的模型存儲在哪裏？",question5:"如果我提供一個參考 URL，系統將如何使用它？",question6:"我可以針對特定語言微調模型嗎？",question7:"我可以微調非 Jina 向量模型嗎，例如 bge-M3？",question8:"如何保證微調模型的質量？",question9:"如何生成合成數據？",title:"自微調相關常見問題"},find_on_hf:"列出微調模型",temporarily_unavailable:"暫時不可用。我們正在升級自動微調系統，以便為您提供更好的服務。請稍後再查看。",test_on:"已對來自 {_dataName} 的 {_dataSize} 個隨機樣本進行測試",test_performance_before_after:"微調前後在保留測試集上的表現",title:"自微調 API",total_improve:"平均改善",usage:"用法",what_is:"什麼是自微調？",what_is_answer_long:"微調允許您採用預先訓練的模型，並通過在新的數據集上進行訓練來使其適應特定任務或領域。實際上，對於許多用户來説，找到有效的訓練數據並不是一件容易的事。有效的訓練不僅僅需要將原始 PDF、HTML 放入模型中；而且很難做到正確。自微調通過使用高級 LLM 智能體管道自動生成有效的訓練數據來解決此問題；並在 ML 工作流中微調模型。您可以將其視為合成數據生成和 AutoML 的組合，因此您需要做的就是用自然語言描述您的目標域，然後讓我們的系統完成剩下的工作。"},_={description:"從文章直接生成插圖，無需提示詞",example_description:"愛麗絲開始厭倦了坐在岸邊姐姐身邊，無所事事：有一兩次她偷看了姐姐正在讀的書，但裏面沒有圖片或對話，“書有什麼用，”愛麗絲想，“沒有圖片或對話？”於是，她正在心裏思考（盡她所能，因為炎熱的天氣讓她感到非常睏倦和愚蠢），製作菊花鏈的樂趣是否值得費力起身去採摘雛菊，突然一隻粉紅色眼睛的白兔跑到她身邊。",example_title:"愛麗絲夢遊仙境 - 第 1 章"},r="試用版",o={answer10:"我們為新用户提供免費試用，其中包括 100 萬個詞元，可通過自動生成的 API 密鑰與我們的任何模型一起使用。一旦達到免費詞元限制，用户可以通過“購買詞元”選項卡輕鬆為其 API 密鑰購買額外的詞元。",answer13:"不，失敗的請求不會扣除詞元。",answer14:"付款通過 Stripe 處理，支持多種付款方式，包括信用卡、Google Pay 和 PayPal，為您提供方便。",answer15:"是的，購買詞元后，發票將發送到與您的 Stripe 帳户關聯的電子郵件地址。",answer9:"我們的定價模型基於處理的詞元總數，允許用户靈活地在任意數量的句子中分配這些詞元，為不同的文本分析需求提供經濟高效的解決方案。",question10:"新用户可以免費試用嗎？",question13:"失敗的請求是否會扣除詞元？",question14:"接受哪些付款方式？",question15:"詞元購買後可以開具發票嗎？",question9:"API是根據句子的數量或請求的數量計費嗎？",title:"與計費相關的常見問題"},s={all:"全部",events:"活動",featured:"甄選",insights:"觀點","knowledge-base":"知識庫",latest:"最新的",press:"新聞稿",releases:"軟件更新","tech-blog":"技術文章"},c={api_free_trial:"免費 API 密鑰",api_paid:"付費 API 密鑰",api_paid_or_free:"您使用的是付費 API 密鑰還是免費試用密鑰？",are_you:"你是：",commercial_contact_sales:"此為商業性質。請聯繫我們的銷售團隊。",contact_sales_for_licensing:"聯繫我們的銷售團隊獲取許可。",csp_user:"您是否在 AWS 和 Azure 上使用我們的官方模型？",educational_teaching:"教育機構用它來教學嗎？",for_profit_internal_use:"盈利性公司在內部使用它嗎？",free_use:"您可以自由使用這些模型。",government_public_services:"政府實體使用它來提供公共服務？",is_use_commercial:"您的用途是商業用途嗎？",may_be_commercial_contact:"這可能是商業用途。請聯繫我們進行澄清。",no:"不",no1:"不",no2:"不",no3:"不",no_restrictions:"無限制。請按照當前協議使用。",no_restrictions_apply:"沒有限制。",non_commercial_free_use:"本模型非商業性質，您可以自由使用。",non_profit_ngo_mission:"非營利組織或非政府組織是否利用它來完成你的使命？",not_sure:"沒有把握",personal_hobby_projects:"將其用於個人項目或者業餘愛好項目？",product_service_sale:"在您銷售的產品或服務中使用它嗎？",title:"CC BY-NC 許可證自檢",trial_key_restrictions:"免費試用密鑰僅可用於非商業用途。如需商業用途，請購買付費套餐。",typically_non_commercial_check:"這通常是非商業性的，但如果不確定，請與我們聯繫。",typically_non_commercial_free_use:"這通常是非商業性的。您可以自由使用這些模型。",using_api_or_cloud:"您是否使用我們的官方 API 或在 Azure 或 AWS 上我們的官方鏡像？",using_cc_by_nc_models:"你正在使用這些模型嗎？",yes:"是的",yes1:"是的",yes2:"是的",yes3:"是的"},d={access:"公共訪問",access_explain:"任何擁有 <code>classifier_id</code> 的人都可以使用公共分類器，並且它們的使用將消耗調用者的詞元配額，而不是您的。私有分類器只能由您訪問。",access_private:"私人的",access_public:"民眾",api_delete:"刪除分類器",api_delete_explain:"根據分類器ID刪除分類器。",api_list:"列表分類器",api_list_explain:"列出您已創建的所有分類器。",classifier_id:"分類器 ID",classify_inputs:"要分類的輸入",classify_inputs_explain:"對於文本，它可以是最多 8192 個詞元的句子。對於圖像，它可以是 URL 或 base64 編碼的圖像。",classify_labels:"候選標註",classify_labels_explain:"輸入將被歸類到這些類別中。最多可以有 256 個類別。使用帶語義類別可獲得更好的性能。",compare_table:{access_control:"訪問控制",classifier_id_required:"必需分類器 ID",continuous_updates:"持續模型更新",default_solution:"一般分類問題的默認解決方案",feature:"特點",few_shot:"少量樣本",image_multi_lingual_support:"多模態和多語言支持",labels_required_classify:"/classify 中需要的標註",labels_required_train:"/train 中需要的標註",max_classes:"最大類數",max_classifiers:"最大分類器",max_inputs_request:"每個請求的最大輸入",max_token_length:"每個輸入的最大詞元長度",na:"不適用",no:"不",out_of_domain_solution:"對於 v3/clip-v1 域之外的數據或時間敏感的數據",primary_use_case:"主要用例",semantic_labels_required:"需要語義標註",state_management:"狀態管理",stateful:"有狀態",stateless:"無狀態",token_count:"{count} 個標記",training_data_required:"需要訓練數據",yes:"是的",zero_shot:"零樣本"},create_classifier:"新的少樣本分類器",create_classifier_explain:"創建一個新的小樣本分類器並使用標記示例對其進行訓練。",description:"圖像和文本的零樣本和少樣本分類。",description_long:"試用我們的 API 遊樂場來了解我們的分類器如何工作。",description_long1:"針對多模態和多語言數據的高性能零樣本和少樣本分類器。",explain:"分類器是一種 API 服務，它使用向量模型 (<code>jina-embeddings-v3</code> 和 <code>jina-clip-v1</code>) 對文本和圖像進行分類，支持無需訓練數據的零樣本分類和使用最少示例的少樣本學習。",faq_v1:{answer1:"零樣本分類需要語義標籤，訓練時不需要，而少樣本分類則需要訓練時需要標籤，但分類時不需要。這意味着零樣本分類更適合靈活、即時的分類需求，而少樣本分類更適合固定的、特定領域的類別，這些類別可以隨時間而演變。",answer10:"是的，您可以選擇 <code>jina-embeddings-v3</code> 進行文本分類（特別適合多語言）和 <code>jina-clip-v1</code> 進行多模態分類。新模型（如 <code>jina-clip-v2</code>）將在發佈時通過 API 自動提供。",answer2:"<code>num_iters</code> 控制訓練強度 - 較高的值會強化重要示例，而較低的值會最大限度地減少不太可靠數據的影響。它可用於通過為近期示例提供更高的迭代次數來實現時間感知學習，這使其對於不斷髮展的數據模式很有價值。",answer3:"任何擁有 <code>classifier_id</code> 的人都可以使用公共分類器，並消耗自己的詞元配額。用户無法訪問訓練數據或配置，也無法查看其他人的分類請求，從而實現安全的分類器共享。",answer4:"少量樣本需要 200-400 個訓練樣本才能超越零樣本分類。雖然它最終會實現更高的準確率，但需要這段預熱期才能發揮作用。零樣本無需訓練數據即可立即提供一致的性能。",answer5:"是的 - API 支持使用 <code>jina-embeddings-v3</code> 進行多語言查詢和使用 <code>jina-clip-v1</code> 進行多模態（文本/圖像）分類，並支持在同一請求中對 URL 或 base64 編碼的圖像進行支持。",answer6:"Zero-shot 支持 256 個類別，沒有分類器限制，而 few-shot 則限制為 16 個類別和 16 個分類器。兩者均支持每個請求 1,024 個輸入和每個輸入 8,192 個標記。",answer7:"少量樣本模式允許通過 <code>/train</code> 端點進行持續更新，以適應不斷變化的數據模式。當數據分佈發生變化時，您可以逐步添加新的示例或類別，而無需重建整個分類器。",answer8:"該 API 使用一次性在線學習 - 訓練示例會更新分類器權重，但之後不會存儲。這意味着您無法檢索歷史訓練數據，但它可以確保隱私和資源效率。",answer9:"當您需要使用語義標籤進行靈活分類時，請從零樣本開始，以獲得即時結果。當您有 200-400 個示例、需要更高的準確度或需要處理特定領域/時間敏感的數據時，請切換到少樣本。",question1:"零樣本和小樣本的標籤有何不同？",question10:"我可以針對不同的語言/任務使用不同的模型嗎？",question2:"num_iters 有什麼用處以及如何使用它？",question3:"公共分類器共享如何工作？",question4:"我需要多少數據才能使小樣本研究發揮良好作用？",question5:"它能處理多種語言和文本/圖像嗎？",question6:"我應該瞭解哪些硬性限制？",question7:"我該如何處理隨時間而發生的數據變化？",question8:"我發送訓練數據後會發生什麼情況？",question9:"零樣本與小樣本——何時使用哪個？",title:"分類器相關常見問題"},more:"更多",num_iters:"訓練迭代",num_iters_explain:"控制訓練強度 - 較高的值可提高當前示例的準確性，但會增加詞元成本。默認值 10 通常效果很好。",read_notes:"閲讀發行説明",select_classifier_or_model:"選擇分類器或向量模型",task_classify:"分類",task_classify_explain:"使用零樣本或少樣本分類器將文本或圖像分類到定義的類別中。",task_manage:"管理",task_manage_explain:"列出或刪除你的小樣本分類器。",task_select:"選擇任務",task_train:"訓練",task_train_explain:"使用標記示例創建或更新少量分類器。",title:"分類器 API",train_inputs:"訓練數據",train_inputs_explain:"用於訓練的帶有標籤的文本或圖像示例。您可以隨着時間的推移使用新示例和標籤逐步更新分類器。",train_label:"標籤",what_is:"什麼是分類器？",when_to_use_what:"何時使用零樣本或小樣本？",when_to_use_what_explain:"使用零樣本分類作為默認解決方案，可以在最多 256 個類別的一般分類任務中獲得即時結果，而少樣本學習更適合處理向量模型知識之外的特定領域數據，或者需要處理需要持續模型更新的時間敏感數據。"},l={description:"使用 CLIP 將圖像和文本向量到固定長度的向量中"},p={description:"多模態AI應用的雲託管平台"},u={agreement:"提交即表示您確認同意 Jina AI 按照以下規定處理您的個人數據",anything_else:"告訴我們更多關於你的想法",cc_by_nc:"請求 CC BY-NC 模型的商業使用",cc_by_nc_description:"我們的最新模型通常採用 CC BY-NC 許可。如需商業使用，請通過我們的 API、Azure Marketplace 或 AWS SageMaker 訪問它們。如需在這些渠道之外進行本地使用，請勾選此框。",company:"組織",company_size:"組織規模",company_website:"組織網站",company_website_placeholder:"您公司主頁或 LinkedIn 個人資料的 URL",country:"國家",department:"部門",description:"與 Jina AI 一起拓展您的業務。",drop_area_for_image:"將圖片拖放到此處",faq:"常問問題",feedback_sent:"已提交！我們將盡快回復您。",field_required:"字段為必填項",get_api_key:"如何獲取我的 API 密鑰？",image_upload:"附加圖片",image_validate:"您最多可以附加 {_num} 張圖片。僅限 JPG、JPEG、PNG、WEBP。",impact_snapshots:"實際案例",invalid_date_format:"日期格式無效。請使用 DD-MM-YYYY 格式。",invalid_email:"電子郵件無效",invalid_number:"無效數字。請再次輸入",invalid_url:"網址無效",name:"姓名",nc_check:"我需要商業許可證嗎？",other_questions:"其他問題",preferred_models:"您對哪些模型感興趣？",preferred_products:"您對哪些產品感興趣？",pricing:"定價？",priority:"優先支持付費用户",private_statement:"隱私聲明",rate_limit:"速率限制是多少？",role:"職業角色",self_check:"自檢",sending_feedback:"正在發送...",shortcut:"捷徑",submit:"提交",submit_failed:"提交失敗。請稍後再試。",submit_success:"感謝您提交。我們會盡快給您回覆。",subtitle:"Jina AI 是多模態 AI 領域的領導者，擅長模型調優、模型服務、提示詞調優部署。利用 Kubernetes 和無服務器架構等雲原生技術，我們提供強大、可擴展且可立即投入生產的解決方案。憑藉大語言模型、文本、圖像、視頻、音頻理解、神經搜索和生成藝術方面的專業知識，我們提供創新、面向未來的策略來提升您的業務。",subtitle1:"Jina AI 是多模態 AI 領域的領導者，擅長大模型向量調優和部署、提示詞調優和部署。利用 Kubernetes 和無服務器架構等雲原生技術，我們提供強大、可擴展且可立即投入生產的解決方案。憑藉大語言模型、文本、圖像、視頻、音頻理解、神經搜索和生成式AI方面的專業知識，我們提供創新、面向未來的策略來提升您的業務。",subtitle2:"瞭解多模態AI最前沿的Jina AI。我們擅長向量化和提示詞技術，利用 Kubernetes 等雲原生解決方案來構建強大、可擴展的系統。我們專注於大型語言模型和媒體處理，利用先進的人工智能專業知識提供創新、面向未來的業務戰略。",title:"聯繫銷售",trusted_by:"我們值得信賴",turn_on_volume:"調高音量",work_email:"工作郵箱"},m="複製",g="已複製到剪貼板",A={description:"用於從文本創建高清圖像的人機交互工作流程"},h={description:"用一行代碼創建引人注目的 Disco Diffusion 藝術作品"},I={description:"多模態數據的數據結構"},b="下載 SOC 2 類型 1 證明",f={"11B tokens":"壹佰壹拾億","11B tokens_intuition1":"類似於閲讀維基百科上的所有英文文章。","11B tokens_targetUser":"生產部署","1B tokens":"拾億","1B tokens_intuition1":"大概和讀完莎士比亞全集和整個《哈利波特》系列是一樣的。","1B tokens_targetUser":"原型開發","1M tokens":"壹佰萬","1M tokens_intuition1":"相當於讀完了《霍比特人》和《了不起的蓋茨比》的全部文本。","1M tokens_targetUser":"玩具實驗","1M_free":"免費百萬詞元隨心用","1M_free_description":"使用免費詞元享受您的新 API 密鑰，無需信用卡。","2_5B tokens":"2.5B 詞元","2_5B tokens_intuition1":"相當於把電影《指環王》三部曲裏説的每一個字都抄錄1000遍。","3p_integration":"擁有 <b>{_numPartners}</b> 家第三方服務","3p_integration_desc":"將我們的搜索底座與您現有的服務相集成。我們的合作伙伴已經打通了與我們 API 的連接，讓您可以輕鬆地在應用程序中使用我們的模型。","500M tokens":"500M 詞元","500M tokens_intuition1":"類似於觀看《辛普森一家》從第 1 季到第 30 季的每一集。","59B tokens":"59B 詞元","59B tokens_intuition1":"相當於兩天內全球發佈的所有推文。","5_5B tokens":"5.5B 詞元","5_5B tokens_intuition1":"相當於閲讀大英百科全書的全部內容。",Free1M:"100 萬個詞元",add_pair:"新建",add_time_explain:"此模型被添加到搜索底座的時間。",api_integration_short:"在流行數據庫、向量數據庫、RAG 和 LLMOps 框架輕鬆使用我們的向量模型API。",api_integrations:"API集成",api_key_update_message:"通過替換舊 API 密鑰，新密鑰將在您每次訪問 jina.ai 時顯示在 UI 中。未來的充值將適用於此新密鑰。您的舊密鑰仍然有效，因此如果您打算再次使用它，請安全保存。",api_key_update_title:"更換 API 密鑰",auto_recharge:"當詞元低時自動充值",auto_recharge_confirm_message:"您確定要禁用自動充值嗎？這將阻止您詞元餘額不足時自動充值。",auto_recharge_confirm_title:"禁用自動充值",auto_recharge_description:"當您需要在生產環境中使用時開啓此選項。這樣當您的詞元餘額低於您設置的閾值時，我們將自動向您的信用卡充值與您上次充值相同的金額。如果您在上次充值中購買了多個詞元包，我們將只向該API充值一個包。",auto_recharge_enable:"您已啓用自動充值",auto_recharge_enable_message:"要啓用自動充值，請在購買套餐時打開自動充值開關。",auto_recharge_enable_title:"啓用自動充值",auto_request:"自動預覽",auto_request_tooltip:"使用 API 密鑰中的數百個詞元，在更改模型時自動預覽 API 響應。關閉後，單擊“獲取響應”即可手動發送請求。",autostart:"向量化將自動開始",base64_description:"向量以 base64 編碼的字符串形式返回。傳輸效率更高。",batch_job:"批處理",batch_upload_hint:"我們將使用如下的 API 密鑰和模型來批處理。","bge-base-en-v1_5_description":"一種強大的英語模型，平衡了性能和效率，適合多種用途。","bge-base-en_description":"平衡的英語模型，旨在實現可靠的性能。","bge-base-zh-v1_5_description":"全面平衡能力與效率的中國模式。","bge-base-zh_description":"集效率與強勁性能於一身的多功能中國車型。","bge-large-en-v1_5_description":"強大的英語模型，提供具有卓越品質的頂級向量。","bge-large-en_description":"專為優質向量而打造的頂級英語模型。","bge-large-zh-v1_5_description":"提供卓越且詳細向量的高容量中文模型。","bge-large-zh_description":"針對頂級向量優化的高性能中文模型。","bge-m3_description":"一種多功能多語言模型，提供廣泛的功能和高質量的向量。","bge-small-en-v1_5_description":"精簡的英語模型，提供高效、高質量的向量。","bge-small-en_description":"一種高效的英語模型，用於簡化和準確的向量。","bge-small-zh-v1_5_description":"緊湊的中國模型，提供靈活、精確的向量。","bge-small-zh_description":"一種敏捷的中國模型，用於高效、精確的向量。",binary_description:"向量被打包為 int8。存儲、搜索和傳輸效率更高。",bulk:"批處理",bulk_embedding_failed:"創建批處理失敗",buy_more_quota:"使用更多詞元充值此 API 密鑰",buy_poster:"購買海報",cancel_button:"取消",click_upload_btn_above:"單擊上面的上傳按鈕即可開始。",clip_v2_description:"jina-clip-v2 是一個 0.9B CLIP 風格模型，它帶來了三大進步：對 89 種語言的多語言支持、512x512 的高圖像分辨率和用於截斷向量的 Matryoshka 表示學習。",clip_v2_title:"clip-v2：多語言多模態向量",code:"代碼",colbert_dimensions_explain:"每個標記向量的維度大小。",compatible:"兼容模式",compatible_explain:"遵循與我們的文本向量模型相同的請求格式。這允許您在不更改請求的情況下在模型之間切換。請注意，此模式下不支持圖像輸入。",cosine_similarity:"餘弦相似度",debugging:"測試",delete_pair:"刪除",description:"@:landing_page.embedding_desc1",dimensions:"輸出維度",dimensions_error:"尺寸大小必須介於 1 到 1024 之間。",dimensions_explain:"較小的尺寸可以實現高效的存儲和檢索，並且由於採用了 Matryoshka 表示法，影響最小。",dimensions_warning:"為了提高性能，我們建議將尺寸大小保持在 {_minDimension} 以上。",document:"文檔",download:"下載",edit_text1_text:"編輯左側文字",edit_text2_text:"編輯右側文字",embedding_done:"成功向量化{_Count}個句子。",embedding_none_description:"不要使用任何向量模型",example_inputs:"示例輸入",faq:"@:contact_us_page.faq",faqs_v2:{answer0:"有關我們的訓練過程、數據源和評估的詳細信息，請參閲 arXiv 上提供的技術報告。",answer1:"每個用户每秒最多可以發出 100 個請求，相當於每秒 204,800 個輸入句子。",answer17:"我們目前正在開發多模態向量模型，將聯合處理文本、圖像和音頻。更新內容將很快公佈！",answer18:"有關使用特定數據微調我們的模型的疑問，請聯繫我們討論您的要求。我們願意探索如何調整我們的模型來滿足您的需求。",answer19:"是的，我們的服務可在 AWS 市場上使用，並且我們正在擴展到 Azure 和 GCP 市場。如果您有特殊要求，請聯繫我們的銷售人員 AT jina.ai。",answer3:"我們的模型支持英語、德語、西班牙語、中文和各種編程語言。欲瞭解更多詳情，請參閲我們關於雙語模型的論文。",answer4:"我們的模型允許輸入長度高達 8192 個詞元，這明顯高於大多數其他模型。詞元的範圍可以從單個字符（如“a”）到整個單詞（如“apple”）。可以輸入的字符總數取決於所用單詞的長度和複雜性。這種擴展的輸入功能使我們的 jina-embeddings-v2 模型能夠執行更全面的文本分析，並在上下文理解方面實現更高的準確性，特別是對於大量文本數據。",answer5:"一次 API 調用最多可以處理 2048 個句子或文本，從而有助於在一次請求中進行廣泛的文本分析。",answer6:"您可以在 API 請求的 <code>input</code> 字段中使用 <code>url</code> 或 <code>bytes</code>。對於 <code>url</code>，請提供要處理的圖像的 URL。對於 <code>bytes</code>，請以 base64 格式對圖像進行編碼並將其包含在請求中。模型將在響應中返回圖像的向量。",answer7:"根據 MTEB 排行榜，我們的模型與 OpenAI 的 text-embedding-ada-002 密切競爭，表現出平均性能相當。此外，我們的模型在多項任務上表現出色，包括分類、配對分類、重排器和總結，優於 OpenAI 的模型。",answer8:"由於我們的 API 接口 https://api.jina.ai/v1/embeddings 與 OpenAI 的 text-embeddings-ada-002 模型的輸入和輸出 JSON 模式相匹配，因此轉換得到了簡化。這種兼容性確保用户在使用 OpenAI 的接口時可以輕鬆地將 OpenAI 模型替換為我們的模型。",answer9:`詞元是根據文本長度和圖像大小計算的。對於請求中的文本，詞元以標準方式計算。對於請求中的圖像，執行以下步驟：
1. 圖塊大小：每幅圖像被分成大小為 224x224 像素的圖塊。
2. 覆蓋率：計算完全覆蓋輸入圖像所需的圖塊數量。即使圖像尺寸不能被 224 完全整除，我們也會將部分圖塊算作完整圖塊。
3. 總圖塊數：覆蓋圖像的圖塊總數決定了成本。例如，如果圖像為 500x500 像素，它將被 3x3 圖塊覆蓋，從而產生 9 個圖塊。
4. 成本計算：每個圖塊都會影響處理圖像的最終成本。每個圖塊的成本為 1000 個詞元。

示例：
對於尺寸為 500x500 像素的圖像：

• 圖像被分成 224x224 像素的圖塊。
• 所需瓷磚總數為 3（水平）x 3（垂直）= 9 塊瓷磚。
• 成本為 9*1000 = 9000 個詞元`,question0:"jina-embeddings-v2 模型是如何訓練的？",question1:"我每秒可以發出多少個 API 請求？",question17:"你們提供向量模型圖像或音頻的模型嗎？",question18:"Jina 向量模型模型可以使用私人或公司數據進行微調嗎？",question19:"您的接口可以私有託管在 AWS、Azure 或 GCP 上嗎？",question3:"你們的模型支持哪些語言？",question4:"單個句子輸入的最大長度是多少？",question5:"單個請求中最多可以包含多少個句子？",question6:"如何將圖像發送到 jina-clip-v1 模型？",question7:"Jina Embeddings 模型與 OpenAI 的 text-embedding-ada-002 模型相比如何？",question8:"從 OpenAI 的 text-embedding-ada-002 到您的解決方案的遷移有多順暢？",question9:"使用 jina-clip-v1 時如何計算詞元？",title:"向量模型相關的常見問題"},feature_8k1:"8192長度",feature_8k_description1:"世界首發的 8192 個詞元長度的開源向量模型，能夠把一整版人民日報壓縮成一個向量。",feature_cheap:"降本 50 倍",feature_cheap_v1:"5 倍降本",feature_cheap_v1_description1:"從免費試用開始，簡單的定價結構，快捷支付。只需 OpenAI 20% 的成本即可獲得強大的向量模型。",feature_multilingual:"提供德英、中英等雙語模型，出海企業適合跨語言應用必備。",feature_on_premises:"隱私第一",feature_on_premises_description1:"直接在您的虛擬私有云 (VPC) 中無縫部署我們的向量模型。輕鬆在 AWS Sagemaker上部署，即將與微軟Azure 和谷歌 Cloud Platform 集成。如需定製 Kubernetes 部署，請聯繫我們的銷售團隊尋求專業幫助。",feature_on_premises_description2:"您可以輕鬆在 AWS Sagemaker上部署我們的向量模型，我們很快將在微軟Azure和谷歌Cloud Services中提供支持。如需定製 Kubernetes 部署，請聯繫我們的銷售團隊尋求專業幫助。",feature_on_premises_description3:"在 AWS Sagemaker 和 Microsoft Azure 中部署 Jina Embeddings 模型，並很快在 Google Cloud Services 中部署，或者聯繫我們的銷售團隊，為您的虛擬私有云和本地服務器獲取定製的 Kubernetes 部署。",feature_on_premises_description4:"使用 AWS SageMaker、Microsoft Azure 或 Google Cloud Services 在本地部署 Jina Embedding 和 Reranker 模型，確保您的數據安全地處於您的控制之下。",feature_solid:"出類拔萃",feature_solid_description1:"基於我們實打實的AI科研工作，並與同類模型進行了嚴格對比測試，以確保模型的最佳性能。",feature_top_perform1:"無縫集成",feature_top_perform_description1:"與OpenAI的API完全兼容。輕鬆與 10 多個向量數據庫和 RAG 系統集成，提供流暢的開發者體驗。",file_required:"請上傳文件",file_size_exceed:"文件大小超過上限 {_size}",file_type_not_supported:"文件類型不支持",fill_example:"填寫示例",float_description:"向量以浮點數列表的形式返回。最常見且易於使用。",free:"自由的",generate_api_key_error:"API 密鑰生成失敗。",generating_visualization:"生成可視化...",get_new_key_button:"獲取新密鑰",get_new_key_button_explain:"選擇新密鑰將導致與舊密鑰相關的使用歷史記錄丟失。",get_new_key_survey:"填寫調查問卷，幫助我們瞭解您的使用情況，並免費獲得新的 API 密鑰！",includes:"購得詞元可在以下產品中使用：",index_and_search:"先索引再查詢",index_and_search1:"索引和搜索",input:"請求",input_api_key_error1:"您的 API 密鑰無效！",input_length:"輸入長度",input_type:"向量化文檔/查詢",input_type_explain:"根據搜索角色，相同的輸入可以作為查詢或文檔向量。",integrate:"集成","jina-clip-v1_description":"我們最新的用於文本和圖像檢索的多模態向量模型。","jina-clip-v2_description":"文本和圖像的多語言多模態向量","jina-colbert-v1-en_description":"改進版的ColBERT模型支持8K長度的上下文，可用於向量化和重排任務","jina-colbert-v2_description":"最新的多語言ColBERT，在向量化和重排方面具有頂級性能","jina-embeddings-v2-base-code_description":"針對代碼和技術文檔搜索的向量模型","jina-embeddings-v2-base-de_description":"支持德英雙語的 8K 最佳向量模型","jina-embeddings-v2-base-en_description":"與 OpenAI 的 text-embedding-ada002旗鼓相當","jina-embeddings-v2-base-es_description":"支持西英雙語的 8K 最佳向量模型","jina-embeddings-v2-base-zh_description":"支持中英雙語的 8K 最佳向量模型","jina-embeddings-v2-small-en_description":"針對低延遲和小內存進行了優化","jina-embeddings-v3_description":"最新、最好的向量化模型，在文本和代碼上均具有最佳性能","jina-reranker-v1-base-en_description":"我們的第一個重排器最大化搜索和 RAG 相關性","jina-reranker-v1-tiny-en_description":"最快的重排器，適合對大量文檔進行可靠的排序","jina-reranker-v1-turbo-en_description":"速度與準確率的最佳權衡選擇","jina-reranker-v2-base-multilingual_description":"最先進的多語言文檔和查詢重排器，具有最佳的準確性和速度性能",key:"API密鑰",key_enter_placeholder:"請輸入您的 API 密鑰",key_enter_placeholder_to_topup:"輸入您要充值的 API 密鑰",key_to_top_up:"有其他 API 密鑰需要充值？粘貼上述內容並點擊“保存”。",key_warn:"請確保將您的 API 密鑰存儲在安全的地方。否則您將需要生成一個新密鑰",key_warn_v2:"這是您的專屬密鑰。請安全保存！",language_explain:"該模型對{_language}語言有最好的支持。",last_7_days:"用法",late_chunking:"後期分塊",late_chunking_explain:"應用後期分塊技術來利用模型的長上下文功能來生成上下文塊向量化。",learn_more:"瞭解更多",learn_poster:"瞭解海報",learning1:"學習向量模型",learning1_description:"什麼是向量，為什麼要向量化？我們已經為您提供了一些入門文章。通過我們的綜合指南從頭開始瞭解向量模型。",length:"長度",manage_billing:"管理發票",manage_billing_tip:"管理您的賬單信息、獲取發票並設置自動充值。",manage_quota1:"密鑰和計費",max_file_size:"最大允許的尺寸：{_maxSize}。",maximize_tooltip:"使用 Shift+1 最大化此面板",mistake_contact:"如果您認為這是一個錯誤，請聯繫我們。",mminput_placeholder:"文本、圖片URL、圖片base64字符串",model_required:"請選擇模型",more_models:"其他 {_numMore} 個模型",more_than_two2:"請輸入兩個以上的文檔，即兩行以上。",multi_embedding:"多載體",multi_embedding_explain:"該模型會給一個輸入返回一組向量。輸入句子中的每個詞元都被映射到單獨的一個向量。",multilingual:"多語言支持",multimodal:"多式聯運",multimodal_explain:"該模型可以對文本和圖像輸入進行編碼，使其成為多模態搜索任務的理想選擇。",new:"新模型",no_data1:"添加一對句子來計算相似度",none:"沒有任何",normalized:"L2 規範化",normalized_explain:"歸一化向量，使其歐幾里得 (L2) 範數變為 1，保持方向。當下遊涉及點積、分類、可視化時很有用。",oncsp:"關於 CSP",onprem:"私有化部署",open_tensorboard:"打開可視化工具",opensource:"開源",opensource_explain:"該模型是開源的，可從 Hugging Face 下載使用。單擊此按鈕可查看 Hugging Face 上的模型。",original_documents:"向量化的句子",original_documents_hint:"在此處輸入句子。每個新行將被視為一個單獨的句子/文檔。",output:"響應",output_dim:"輸出維度",output_dim_explain:"該模型輸出的向量維度為 {_outputDim}。",output_dimension:"輸出維度",pairwise_test:"成對測試",per_k:"每千個詞元",per_m:"每百萬詞元",please_fill_docs_first:"在搜索之前，請先在下面輸入一些句子。",please_select_model:"請選擇向量模型或重排器模型",poster:"向量模型70年",poster_description:"在您的辦公空間或起居室內懸掛一張我們精心製作的海報，在1950年以來文本向量模型的進化和演變中尋找下一個靈感。",pricing:"API價格表",pricing_desc:"我們的 API 定價是根據請求中發送的詞元數量確定的。對於讀取器 API，它是響應中的詞元數量。此定價模型適用於 Jina AI 搜索底座中的所有產品：向量、重新排名、讀取器、自動微調 API。使用相同的 API 密鑰，您可以訪問所有 API 服務。",protectData1:"您向我們發送的數據和文檔都不會用於模型訓練。",protectData2:"數據在傳輸過程中加密 (TLS 1.2+) ，同時靜態數據也會被加密 (AES-GCM 256)。",protectData3:"SOC 2 和 GDPR 合規。",protect_data:"保護您的數據",public_cloud_integration:"與 <b>{_numPartners}</b> 個雲服務提供商合作",public_cloud_integration_desc:"您的公司是否在使用 AWS 或 Azure？那麼請直接在貴公司的這些平台上私有化部署我們的搜索底座模型，這樣您的數據就能保持安全且合規。",query:"查詢句",raise_issue:"問題反饋",rank_none_description:"不要使用任何重排模型",read_api_docs:"API 規範",read_release_note:"閲讀發行説明",recharge_threshold:"充值門檻",refresh:"刷新",refresh_key_tooltip1:"免費獲取新的 API 密鑰",refresh_token_count1:"刷新以獲取當前 API 密鑰的可用詞元",regenerate:"生成新的密鑰",remaining:"剩餘詞元額度",remaining_left:"您在下面的 API 密鑰中還剩餘 <b>{_leftTokens}</b> 個詞元。",request_number:"請求次數",request_path:"請求端點",results_as_final_result:"最終結果的文檔數",results_fed_to_reranker:"提交給重排器的文檔數",retry:"重試",return_base64:"Base64（字符串）",return_binary:"二進制（打包為 int8）",return_float:"默認（浮點型）",return_format:"向量格式",return_format_explain:"除了浮點數之外，您還可以要求它以二進制形式返回，以便更快地進行矢量檢索，或者以 base64 編碼形式返回，以便更快地進行傳輸。",return_format_title:"返回數據類型",return_ubinary:"二進制（打包為 uint8）",right_api_key_to_charge:"請輸入正確的API密鑰進行充值",running:"運行中",score:"分數",search:"搜索",search_hint:"在下列句子中輸入要搜索的內容",select_classify_model:"選擇分類器",select_embedding_model:"選擇向量模型",select_rerank_model:"選擇重排器",show_api_key:"顯示 API 密鑰",size:"參數",size_explain:"模型中的參數數量為{_size}，請注意，這不代表模型的文件大小。",sleeping:"休眠中",start_batch:"開始批處理",start_embedding:"開始索引",status_explain:"我們的無服務器架構可能根據使用率即時從內存中卸載一些當下無人使用的模型。對於活躍模型，響應是立即的。而休眠中的模型在收到第一次請求時才會加載，這一過程可能會持續幾十秒。模型被喚醒後，後續請求的處理速度會更快。",task_type:"下游任務",task_type_classification:"分類",task_type_classification_explain:"文本分類。",task_type_explain:"選擇將使用向量模型的下游任務。模型將返回針對該任務優化的向量。",task_type_none_explain:"不使用適配器。將返回通用向量，可用於調試或黑客攻擊。",task_type_retrieval_passage:"檢索通道",task_type_retrieval_passage_explain:"將文檔向量化查詢文檔檢索任務中。",task_type_retrieval_query:"檢索查詢",task_type_retrieval_query_explain:"在查詢文檔檢索任務中向量化查詢。",task_type_separation:"分離",task_type_separation_explain:"聚類文檔，可視化語料庫。","task_type_text-matching":"文本匹配","task_type_text-matching_explain":"語義文本相似度、廣義對稱檢索、推薦、查找相似項、去重。",tax_may_apply:"根據您所在的位置，您可能需要支付美元、歐元或其他貨幣的費用。可能需繳納税費。",text1:"左",text2:"右",three_ways:"三種購買方式",three_ways_desc:"訂閲我們的 API、通過雲提供商購買或為您的組織獲取商業許可證。",title:"向量模型API",token_example:"一條微博大約有 20 個詞元，一篇人民日報新聞大約有 1000 個詞元，而查爾斯·狄更斯的小説《雙城記》有超過一百萬個詞元。",token_length_explain:"此模型所支持的輸入詞元的最大長度為 {_tokenLength}。",tokens:"詞元",tools:"工具",top_up_button:"給舊密鑰充值",top_up_button_explain:"集成此 API 密鑰可提供更專業的解決方案，無需頻繁更改密鑰。使用數據將被保留並可隨時訪問。",top_up_warning_message1:"當前 API 密鑰還剩 {_remainedTokens} 詞元，將被具有 {_freeTokens} 詞元的新密鑰替換。如果您已妥善保管舊密鑰，則可以繼續使用或充值舊密鑰。您想如何進行？",top_up_warning_title:"是否替換舊密鑰？",total_documents:"向量化進度：{_Processed}/{_Count} 個句子。",tuning:"微調",turnstile_error:"我們無法生成 API 密鑰，因為我們無法驗證您是否是人類。",turnstile_unsupported:"由於您的瀏覽器不受支持，我們無法生成 API 密鑰。",ubinary_description:"向量被打包為 uint8。存儲、搜索和傳輸效率更高。",upload:"上傳",upload_file:"單擊此處上傳文件",usage:"用法",usage_amount:"詞元",usage_history:"過去 7 天的使用情況",usage_history_explain:"數據並不是實時的，可能會延遲幾分鐘。",usage_reason:"描述",usage_reason_consume:"用過的",usage_reason_purchase:"已購買",usage_reason_trial:"使用",usage_rerank:"用法",usage_time:"時間日期",v3_description:"<code>jina-embeddings-v3</code> 是一種前沿多語言文本向量模型，具有 570M 個參數和 8192 個詞元長度，在 MTEB 上的表現優於 OpenAI 和 Cohere 的最新專有向量模型。請閲讀下面的博客文章和研究論文。",v3_title:"v3：頂級多語言向量模型",vector_database_integration1:"集成",vector_database_integration2:"在流行數據庫、向量數據庫、RAG 和 LLMOps 框架輕鬆使用我們的向量模型API。首先，只需將您的 API 密鑰複製到以下任意集成中即可快速使用我們的模型。",vector_database_integration3:"我們的 Embedding & Reranker API 與各種知名數據庫、向量存儲、RAG 和 LLMOps 框架原生集成。首先，只需將您的 API 密鑰複製並粘貼到任何列出的集成中即可快速無縫地啓動。",vector_database_integration_description:"將 Jina Embeddings API 與以下任何向量數據庫、LLM 編排框架和 RAG 應用程序無縫、輕鬆地集成。我們的教程將向您展示如何操作。",view_details:"查看詳情",visualization_example:"將本節中的所有句子映射到 3D 向量空間",visualization_example_you_can:"使用我們下面的API，你也可以做到！",visualize:"可視化",visualize_done:"可視化已完成，您現在可以單擊頂部按鈕打開可視化工具。",wait_for_processing:"您的請求正在處理中。",wait_stripe:"正在開通Stripe支付，請稍候",what_are_embedding:"什麼是向量化？",what_are_embedding_answer:`想象一下教計算機掌握單詞和短語的細微含義。傳統方法依賴於嚴格的基於規則的系統，由於語言過於複雜和流動，因此無法達到預期效果。輸入文本向量：一種強大的解決方案，可將文本轉換為數字語言 - 具體來説，轉換為高維空間中的向量。

考慮短語“晴朗的天氣”和“晴朗的天空”。對我們來説，它們描繪了相似的畫面。通過向量的視角，這些短語被轉換成數字向量，它們在這個多維空間中彼此靠近，捕捉它們的語義親緣關係。向量空間中的這種接近性不僅僅是單詞或短語相似；它還涉及理解上下文、情感，甚至含義中的細微差別。

為什麼這一突破很重要？首先，它彌合了人類語言的豐富性和算法的計算效率之間的差距。算法擅長處理數字，而不是解釋文本。通過將文本轉換為向量，向量使這些算法能夠以以前無法實現的方式“理解”和處理語言。

實際應用範圍廣泛且多種多樣。無論是推薦符合您興趣的內容，還是為感覺非常人性化的對話式人工智能提供支持，甚至是在大量文本中檢測微妙的模式，向量都是關鍵。它們使機器能夠執行情緒分析、語言翻譯等任務，並且對語言的理解越來越細緻入微和精細化。`,what_is_a_token:"文本處理中的詞元是一個單元，通常是一個單詞。例如，“Jina AI 太棒了！”變成五個詞元，包括標點符號。",why_do_you_need:"選擇最適合的向量模型",why_do_you_need_after:"通過深度學習和先進的語言處理技術，我們的向量模型能夠將複雜的多模態數據轉換為簡化的格式，這不僅提升了機器的理解力，也為實現更復雜的AI應用提供了可能，包括但不限於提高數據解析能力、增加用户互動、消除語言障礙和改進開發流程。",why_do_you_need_before:"我們的向量模型旨在涵蓋各種搜索和 GenAI 應用。",why_need_1_description:"我們依託JinaBERT打造的向量基座模型，面向各種場景設計。它在解析長篇文本方面表現出色，適合用於語義搜索、內容分類及深度語言分析等任務。這種多功能性使其成為開發情緒分析工具、文本摘要和個性化推薦系統的理想選擇。",why_need_1_title:"通用向量",why_need_2_description:"我們的雙語模型旨在打破語言壁壘，提升多語言平台的溝通效率、全球客户支持和跨語言內容的發現能力。專注於德語-英語和中文-英語的雙向翻譯，讓不同語言的用户能夠更容易地理解和交流。",why_need_2_title:"雙語向量",why_need_3_description:"專為開發者設計的代碼向量模型，能夠簡化代碼摘要編寫、代碼生成和自動代碼審查等任務。通過深入分析代碼結構並提供改進建議，顯著提升了開發效率，是開發高級IDE插件、自動生成文檔和創新調試工具的關鍵。",why_need_3_title:"代碼向量",why_need_4_description:"Jina CLIP 是我們最新的圖像和文本多模態向量模型。與 OpenAI CLIP 相比，一個很大的改進是，這個單一模型可以用於文本-文本檢索，以及文本-圖像、圖像-文本和圖像-圖像檢索任務！因此，一個模型，兩種模態，四個搜索方向！",why_need_4_title:"多模態向量",write_email_here:"請輸入您希望在完成後接收下載鏈接的電子郵件。",you_can_leave:"您可以離開此頁面，完成後我們將向您發送下載鏈接。"},w={description:"世界一流的多模態多語言向量模型。"},P={answer1:"Jina AI 專注於多模態AI技術，包括大模型向量的調優和部署、提示詞的調優和部署。我們利用 Kubernetes 和無服務器架構等先進工具來創建強大、可擴展且可立即投入生產的解決方案。",answer10:"我們根據項目的性質和客户的需求提供不同的許可選項。詳細條款可以與我們的銷售團隊討論。",answer11:"我們在全球範圍內提供服務，總部位於歐洲柏林，並在北京和深圳設有辦公室。",answer12:"是的，我們提供現場支持，特別是對於位於柏林、北京和深圳辦公室附近的客户。對於其他地點，我們努力提供最好的遠程支持，並在必要時安排現場支持。",answer2:"我們的專業知識涵蓋廣泛，包括大型語言模型、文本、圖像、視頻、音頻理解、神經搜索和生成式AI。",answer3:"是的，我們的解決方案設計為可擴展並可用於生產。我們使用雲原生技術構建解決方案，從而在生產環境中實現高效擴展和可靠的性能。",answer4:"我們的服務用途廣泛且適應性強，適用於多種行業，包括電子商務、法律技術、數字營銷、遊戲、醫療保健、金融等。",answer5:"您可以通過此頁面上的聯繫表與我們的銷售團隊取得聯繫。我們很樂意討論您的項目需求以及我們的解決方案如何幫助您的業務。",answer6:"我們提供持續的支持，以確保我們的解決方案順利運行。這包括根據您的反饋和需求進行故障排除、定期更新和改進。",answer7:"項目持續時間根據項目的複雜性和範圍而有所不同。瞭解您的要求後，我們可以提供更準確的估算。",answer8:"數據安全是我們的首要任務。我們遵守嚴格的數據保護政策和法規，以確保您的數據安全和保密。",answer9:"定價取決於項目的複雜性和要求。我們提供基於項目的定價模型和保留定價模型。請聯繫我們的銷售團隊瞭解更多信息。",question1:"Jina AI 擅長什麼？",question10:"你們的解決方案的許可條款是什麼？",question11:"您的服務區域是什麼？",question12:"你們提供現場支持嗎？",question2:"Jina AI 適用於哪些類型的人工智能？",question3:"您的解決方案可擴展且可投入生產嗎？",question4:"哪些行業可以從 Jina AI 的解決方案中受益？",question5:"我們如何使用 Jina AI 啓動一個項目？",question6:"實施解決方案後您提供哪些支持？",question7:"項目的典型持續時間是多長？",question8:"Jina AI 如何保護我的數據？",question9:"你們的服務的定價結構是怎樣的？"},k="常見問題",y={text:"江湖再見。",toggle_btn:"下次訪問時保持此面板打開",warning_message:"當您訪問 jina.ai 時，此面板將自動打開。您需要關閉它才能查看網站內容。啓用此設置嗎？",warning_title:"啓動時顯示"},v={description:"調優特定領域數據的大模型向量以獲得更好的搜索質量",intro:"你的公司、你的數據、你的模型"},L={description:"為您的企業提供本地調優解決方案"},x={api_key:"輸入您的 API 密鑰。",back:"後退",base_model_selected:"選擇底座模型",click_start:"同意條款並開始微調。",confirm_title:"確認微調工作",confirm_your_email:"重新輸入您的電子郵件地址以確認微調工作。更新和下載鏈接將發送到此電子郵件。",consent0:"我同意根據我的指示生成用於模型微調的合成數據。",consent1:"我承認最終模型和合成數據將在 Hugging Face 上公開。",consent2:"我瞭解此功能處於測試階段，Jina AI 不提供任何保證。定價和用户體驗可能會發生變化。",continue:"繼續",cost_1m_token:"每個微調作業消耗 1M 詞元。請確保您有足夠的詞元或充值。您也可以生成新的 API 密鑰。每個 API 密鑰附帶 1M 免費詞元。",doc_explain:"描述匹配的文檔應該是什麼樣的。",domain_explain:"詳細描述如何使用微調向量模型。這對於生成高質量的合成數據（可提高向量模型的性能）至關重要。",domain_explain2:"有三種方式可以指定您的需求：一般説明、URL 或查詢文檔描述。請選擇一種。",domain_hint:"描述您希望微調的域。",email_not_match:"電子郵件地址不匹配。請驗證。",failed_job:"微調請求失敗。請參閲下面的原因。",find_on_huggingface:"在 Hugging Face 上查找結果",general_instruction:"或者，一般説明",general_instruction_caption:"提供有關如何使用微調向量的詳細描述。",general_instruction_explain:"以自由格式的文本描述您的域名。您可以將其想象為 ChatGPT 中的“提示”。",how_it_works:"瞭解微調過程。",job_acknowledged:"您的微調作業已排隊。作業開始時，您將收到一封電子郵件。整個過程通常需要 20 分鐘才能完成。",new_key:"獲取新密鑰",not_enough_token:"此 API 密鑰中詞元不足。請充值或使用其他 API 密鑰。",placeholder:"汽車保險索賠",preview:"預覽",query_doc:"查詢文檔描述",query_doc_caption:"描述查詢是什麼樣的以及匹配的文檔在您的域中是什麼樣的。",query_explain:"描述查詢的樣子。",reset:"重來",select_base_model:"選擇一個基礎向量模型進行微調。",select_base_model_explain:"選擇一個底座模型作為微調的起點。通常，base-en 是一個不錯的選擇，但對於其他語言的任務，請考慮使用雙語模型。",start_tuning:"開始微調",url:"或者，網頁網址",url_caption:"參考URL中的內容進行微調。",url_explain:"包含您要微調的內容的網頁的公共 URL。",use_url:"使用 URL 代替。啓用該選項意味着我們將根據該 URL 的頁面內容生成合成數據以進行微調。",wait_for_processing:"請稍候，我們正在處理您的請求...",which_domain:"微調域",write_email_explain:"微調需要時間。我們將通過電子郵件告知您微調工作的開始、進度、完成情況和任何問題，以及微調模型和訓練數據集的詳細信息。"},q={address_beijing:"中國北京",address_berlin:"德國柏林（總部）",address_shenzhen:"中國深圳",all_rights_reserved:"版權所有",company:"公司",developers:"為開發者",docs:"文檔",enterprise:"為企業",get_api_key:"獲取 Jina AI API 密鑰",offices:"辦公室",power_users:"為高級用户",privacy:"隱私",privacy_policy:"隱私政策",privacy_settings:"管理 Cookie",security:"安全",sefo:"搜索底座",soc2:"我們符合美國註冊會計師協會 (AICPA) 的 SOC 2 Type 1 標準。",status:"API 狀態",status_short:"服務狀態",tc:"條款及條件",tc1:"條款"},M="獲取 API 密鑰",R={stars:"Stars"},S={about_us:"關於我們",company:"公司",contact_us:"聯繫銷售",developers_others:"更多開發者工具",enterprise_others:"更多企業工具",for_developers:"為開發者賦能",for_developers_description:"專為開發人員打造的的多模態開源技術棧。",for_enterprise:"為企業賦能",for_enterprise_description:"探索為企業定製的多模態解決方案。",for_power_users:"為高級用户賦能",for_power_users_description:"利用我們多模態工具來提高您的日常生產力。",internship1:"實習生計劃",jobs:"加入我們",join_discord:"加入我們的 Discord 社區",logos:"下載Logo",maximize:"⇧1",maximize_btn:"最大化",news:"新聞",open_day:"開放日",open_in_full:"在新窗口中顯示所有企業產品",power_users_others:"更多高級用户工具",products:"產品"},J={description:"分享和發現多模態AI應用程序的構建模塊"},j={sentence_similarity:"句向量模型",updated_about:"更新了關於"},C={project1:"使用點雲信息在 3D 網格數據中實現高精度搜索。",project10:"利用計算機視覺提高政府網站的數字可訪問性。",project11:"為一家諮詢公司優化財務數據分析的調優大規模語言模型。",project12:"通過調優文本到圖像模型以進行風格轉換來實現高級營銷策略。",project2:"設計了一個基於內容的動畫短片搜索引擎。",project3:"通過調優向量模型來提高電子商務轉化率。",project4:"為一家商業諮詢公司進行及時調整以提高效率。",project5:"為一家領先的遊戲企業開創了遊戲場景理解和自動標註的先河。",project6:"為一家聊天機器人公司實現了實時輸入擴展，增強了用户體驗。",project7:"通過在冗長的法律文檔中實現高效搜索。",project8:"支持大規模運營的高吞吐量生成藝術服務。",project9:"使用高級語言模型進行流程挖掘和建模。"},z={description:"最先進的多模態推理模型"},T={copy_full_prompt:"複製完整提示詞",embedding:"向量模型",how_to_use_meta_prompt:"如何使用",meta_prompt:"使用元提示詞進行代碼生成",meta_prompt_description:"元提示詞可以讓大模型（如 ChatGPT 和 Claude）知曉我們所有的API使用方法，從而使代碼生成更容易、質量更高。",reranker:"重排器",which_to_go:"哪一個與{_vendor}集成？"},G={answer1:"本科、碩士、博士我們鼓勵來自世界各地對研究、工程、營銷和銷售等領域感興趣的學生申請。我們還歡迎營銷、銷售、行政助理等領域的非技術實習機會。我們正在尋找熱情的個人，準備與我們一起開拓多模態AI。",answer10:"是的，我們的實習計劃提供有競爭力的薪酬。",answer11:"作為 Jina AI 實習生，您將獲得從事具有挑戰性的項目的實踐經驗，向行業專家學習，成為充滿活力的社區的一部分，並有機會為我們在多模態 AI 領域的開創性工作做出真正的貢獻。",answer2:"實習必須在我們位於柏林、北京和深圳的辦事處之一現場進行。",answer3:"是的，Jina AI 在簽證流程中為成功申請者提供合理的幫助。",answer4:"是的，Jina AI 為實習生在實習期間提供合理的生活費保障。",answer5:"是的，您可以在 Jina AI 實習期間完成碩士論文，這通常適用於德國大學的學生。但是，您必須事先徵得您所在大學主管的溝通並同意。請注意，我們不幫助學生尋找顧問。",answer6:"申請過程包括提交您的申請表、簡歷、表達您的興趣和動機的求職信以及任何相關的專業鏈接，例如 GitHub 或 LinkedIn。我們根據候選人在面試中的表現以及他們在大學的表現來評估他們。",answer7:"是的，成功的實習生可能會在實習結束時收到一封由我們首席執行官簽署的推薦信。",answer8:"實習的持續時間根據角色和項目而有所不同。然而，它通常為三到六個月。",answer9:"是的，我們歡迎所有學術背景的申請。我們重視您對學習的熱情和承諾，就像您以前的經驗一樣。",question1:"哪些人可以申請 Jina AI 實習項目？",question10:"這是帶薪實習嗎？",question11:"作為 Jina AI 實習生，我將獲得哪些機會？",question2:"實習將在哪裏進行？",question3:"Jina AI 是否協助辦理簽證流程？",question4:"Jina AI 是否為實習生提供任何津貼或福利？",question5:"在 Jina AI 實習期間可以寫碩士論文嗎？",question6:"申請流程涉及哪些內容？",question7:"Jina AI 實習後有推薦信嗎？",question8:"實習期限是多長？",question9:"如果我沒有人工智能方面的經驗，我可以申請嗎？"},B={about_internship_program:"關於實習計劃",about_internship_program_desc1:"我們很高興為有才華的人提供這個獨特的機會加入我們充滿活力的團隊，併為人工智能領域的突破性項目做出貢獻。該實習旨在為您提供寶貴的實踐經驗、指導和接觸正在塑造人工智能未來的尖端技術。",about_internship_program_desc2:"在 Jina AI，我們深知培養和利用年輕人才的重要性。我們認識到實習生帶來了新的視角、熱情和創造力，用新的想法和方法激勵我們的團隊。通過提供實習機會，我們的目標是促進人工智能行業未來領導者的成長，同時在支持性和挑戰性的環境中為他們提供實際經驗。",alumni:"校友",alumni_network:"我們蓬勃發展的校友網絡",application:"應用",application_desc:"與 Jina AI 一起踏上變革之旅。我們全面的實習計劃邀請所有渴望塑造人工智能未來的充滿激情的夥伴。加入我們，獲得現實世界的經驗，從事具有挑戰性的項目，並與人工智能行業中一些最聰明的人做同事。",apply:"現在申請",autumn:"秋季",description:"全球招募學生：研究、工程、營銷、銷售等專業的實習。",dev_rel_intern:"開發者關係實習生",enthusiastic:"熱情的",explore_stories_from_our_interns:"探索我們實習生的故事",explore_stories_from_our_interns1:"從我們的實習生的旅程中獲得靈感",innovative:"創新的",intern_work1:"微調 LLM 模型以實現更好的句向量模型",intern_work2:"探索檢索增強生成(RAG)算法的潛力",intern_work3:"發表了一篇關於句子向量的論文",intern_work4:"為團隊注入源源不斷的年輕活力",intern_work5:"壓縮 LLM 的基準量化技術",intern_work6:"為 PromptPerfect 創建和推廣引人注目的活動",intern_work7:"快速開發和改進 JinaColBERT V2",recruiting_and_administrative_intern:"招聘及行政實習生",researcher_intern:"實習研究員",self_motivated:"自我激勵",software_engineer_intern:"軟件工程師實習生",spring:"春季",submit_application:"與 Jina AI 一起開始你的冒險",subtitle:"我們的全日制實習計劃通過精心設計的廣泛範圍的實習項目提供實踐工作經驗。",subtitle1:"全球範圍內招募學生：研究、工程、營銷、銷售等領域的實習生，共同開創多模態AI。",summer:"夏季",title:"實習生計劃",who_do_we_look_for:"我們要找誰？",who_do_we_look_for_desc:"我們重視多樣性，並鼓勵來自不同背景和背景的申請人加入我們的實習計劃。多個部門提供實習機會，包括工程、設計、產品管理、銷售和客户管理、營銷和社區管理。",winter:"冬季"},U={description:"將一個本地項目部署為雲服務。極其簡單，沒有令人不快的意外。"},O={description:"開源的 LLM 的實驗性調優器"},E={description:"在雲端構建多模態AI應用"},D={description:"更多模態、更長記憶、更低成本",example_1:"你是誰？",example_2:"我是 Jina AI 製作的 LLM 聊天服務"},N={GlobalQA:{description:"在任意頁面上按“/”鍵即可打開提問。輸入您的查詢並按“Enter”得到頁面內容相關的答案。此功能由 PromptPerfect 提供支持。",title:"頁上RAG"},Recommender:{description:"使用“Shift+2”打開任何新聞頁面上的推薦框。選擇重排模型以發現與該新聞頁面相關的前 5 篇文章。此功能由我們的 Reranker API 提供實時支持。",title:"相關文章"},SceneXplainTooltip:{description:"將鼠標懸停在新聞頁面或我們的新聞室目錄中的任何圖片上，以顯示該圖片的描述。描述由 SceneXplain 預先計算並向量化在圖像的 ALT 屬性中。",title:"圖像標註"},explain:"探索我們網站上的隱藏功能"},F={also_available_on:"也可在應用市場上使用",also_available_on1:"通過應用市場一鍵部署到您的企業雲上",ask_how_your_question:"請描述您的問題",autotune:"自微調",badge:{"clip-v2":"clip-v2 發佈！",v2:"第二版已發佈！",v3:"v3 發佈！"},build_js:"使用 JavaScript 開發",build_python:"使用 Python 開發",ccbync:"此模型為 CC BY-NC 4.0 許可。通過 API 或我們的官方 AWS/Azure 映像使用它；或聯繫銷售人員進行本地部署。",checkout_our_solution_for_you:"瞭解我們為您量身定製的解決方案",classifier:"分類器",coming_soon:"敬請期待",contact_sales:"聯繫我們",copied_to_clipboard:"已複製到剪貼板",copy:"複製",developers:"開發者",developers_desc:"通過尖端的雲原生技術和開源基礎設施，釋放多模態AI的全部力量。",download_pdf:"下載 PDF",embedding:"向量",embedding_desc1:"適用於搜索、RAG、智能體應用程序的性能最佳的多模態多語言長上下文向量模型。",embedding_paper_desc:"Jina Embeddings 構成了一組高性能文本向量模型，擅長將各種文本輸入轉換為數字表示，從而捕獲文本的語義本質。雖然這些模型並非專門為文本生成而設計，但它們在密集檢索和語義文本相似性等應用中表現出色。本文詳細介紹了 Jina Embeddings 的開發，從創建高質量的成對和三元組數據集開始。它強調了數據清理在數據集準備中的關鍵作用，深入瞭解了模型訓練過程，並使用大規模文本向量基準 (MTEB) 進行了全面的性能評估。",embedding_paper_title:"Jina Embeddings：一套新穎的高性能文本向量模型",embeddings:"向量模型",enterprise:"企業",enterprise_desc:"通過可擴展、安全和定製的多模態AI解決方案促進您的業務。",enterprise_desc_v2:"用我們世界一流的向量模型來改進您的搜索和 RAG 系統。從免費試用開始！",enterprise_desc_v3:"我們的前沿模型構成了高質量企業搜索和 RAG 系統的搜索基礎。",error:"出現了問題：{message}",find_your_portal:"探索您的專屬傳送門",finding_faq:"根據以下常見問題解答知識生成答案",for:"為",for_developers:"為開發者",for_enterprise:"為企業",for_power_users:"為高級用户",get_api_now:"API接口",get_started:"開始使用",go_to_product_homepage:"轉至產品主頁",how_to:"如何",include_experiment:"在解決方案中提及我們還在實驗中和已歸檔的項目。",join_community:"社區",learn_more_embeddings:"瞭解向量模型",learn_more_reader:"詳細瞭解讀取器",learn_more_reranker:"瞭解重排器",llm:"LLM 大模型向量模型",llm_desc:"我們提供了一系列高性能文本向量模型，擁有 3500 萬到 60 億個參數。它們非常適合增強神經搜索、重排器、句子相似性、推薦等。準備好提升您的 AI 體驗！",mentioned_products:"提及產品：",mmstack:"多模態技術棧",mmstack_desc:"多年來，我們開發了各種開源軟件，幫助開發人員構建更好的 GenAI 和更快地搜索應用程序。",models:"模型",more:"更多的",multimodal:"多模態",multimodal_ai:"多模態AI",new:"新的",newsroom:"新聞",num_publications:"共計 {_total} 篇出版物。","on-prem-deploy":"私有化部署","on-premises":"本地",opensource:"開源",our_customer:"我們的客户",our_customer_explain:"大大小小的企業都信任 Jina AI 的搜索底座技術來構建他們的工具和產品——您也可以信任我們。",our_publications:"我們的論文",parameters:"參數",podcast:"播客",power_users:"高級用户",power_users_desc:"自動提示詞工程，提高您的日常工作效率。",powered_by_promptperfect:"由 PromptPerfect 的“提示詞優化”和“提示即服務”功能提供支持",pricing:"價格表",proposing_solution:"基於 Jina AI 產品線的構思解決方案...",read_more:"更多新聞",reader:"讀取器",require_full_question:"請更詳細地描述您的問題。",reranker:"重排器",researcher_desc:"瞭解我們的前沿搜索模型是如何從頭開始訓練的，查看我們的最新出版物。在 EMNLP、SIGIR、ICLR、NeurIPS 和 ICML 與我們的團隊見面！",researchers:"研究人員",sdk:"軟件開發工具包",sdk_desc:"想要使用 PromptPerfect、SceneXplain、BestBanner、JinaChat、Rationale API 構建高級 AIGC 應用程序？我們為您服務！嘗試我們易於使用的 SDK，幾分鐘內即可開始使用。",sdk_docs:"閲讀文檔",sdk_example:"例子",search_foundation:"搜索底座",source_code:"源代碼",starter_kit:"新人包",supercharged1:"從此不同！",tokenizer:"切分器",trusted_by:"我們值得信賴",try_it_for_free:"立即開始——無需信用卡或註冊！",try_our_saas:"嘗試我們託管的的雲原生推理方案，它是OpenAI API的1:1替代品。",your_portal_to:"邀您通往",your_search_foundation1:"您的搜索底座"},H={description:"使用 Jina 和 FastAPI 製作生產級別的 Langchain 應用程序"},K={description:"關於Jina AI產品和服務的法律信息、服務條款、隱私政策和其他重要文件。",title:"法律信息"},W={api:"Jina AI的API",contact_sales_about_it:"聯繫銷售人員瞭解詳情",deploy_it_on:"部署於",description:"多年來，我們不斷突破搜索的界限。以下是我們發佈的模型 — 將鼠標懸停或單擊每個模型可查看更多詳細信息。",find_on_hf:"在 HuggingFace 上找到它",search_for:"在我們的網站上搜索",search_models:"按模型名稱過濾",title:"我們的搜索底座模型",use_it_via:"通過使用"},Y={back_to_newsroom:"返回新聞首頁",categories:"類別",copy_link:"複製此部分的鏈接",in_this_article:"文章導覽",learn_more:"瞭解更多",news_not_found:"糟糕！未找到文章",redirect_to_news:"將在5 秒後重定向至新聞首頁..."},X={academic:"學術",academic_research:"學術論文",author:"按作者過濾",description:"閲讀 Jina AI 的最新新聞和更新。",description1:"一字一句地撰寫AI技術創新。",engineering_group:"工程組",engineering_group_date:"2021 年 5 月 31 日",minutes_read:"分鐘的閲讀量",most_recent_articles:"最新文章",news_description:"對於 Jina 2.0，我們聽取了社區的意見。確實，深深地聽過。 “你的痛點是什麼？”我們詢問並熱切期待寶貴的反饋",news_title:"搜索所有內容：我們正在為 Jina 2.0 舉辦 MEME 競賽",photos:"相片",product:"按產品過濾",search:"按標題搜索",tech_blog:"技術文章",title:"新聞",top_stories:"甄選文章"},Q="🎉 我們的第一本書《神經搜索——與 Jina 一起從原型到生產》今天正式出版！",V={description:"參訪 Jina AI 內部的獨家機會。",engage:"我們強烈鼓勵全天進行互動對話。思想和觀點的交流對我們來説非常寶貴。這些討論產生的潛在合作可以為更加一體化和創新的未來做出重大貢獻。",engage_title:"頭腦風暴",experience:"我們為客人安排了三小時的沉浸式遊覽，提供德語、英語、法語、西班牙語、中文和俄語版本。這次巡演將深入探討我們在多模態AI方面的進展、我們對人工智能領域的看法，然後對具體項目進行詳細審查。最後我們將進行小組討論，以促進思想和見解的交流。還可應要求提供午餐選擇。",experience_title:"業內人士之旅",group_size:"預計參觀人數",impact:"瞭解我們對開源社區的貢獻以及我們在多模態AI技術方面的工作如何使 Jina AI 成為人工智能創新領域有影響力的參與者。我們的目標是在決策過程中發揮重要作用，確保人工智能技術的進步惠及所有人。",impact_title:"行業影響力",introduction:"Jina AI 很高興向對那些對人工智能未來感興趣的機構敞開大門。我們為政界、非政府機構、非營利機構和投資領域的人士提供開放日。在此，誠邀您做客柏林總部，瞭解我們的運營、願景的行業洞察。",motivation_min_length_v1:"請提供更詳細的動機。",motivation_placeholder_v2:"分享您的動機將幫助我們改善您的體驗。",motivation_to_attend_v2:"您為什麼對我們的開放日感興趣？",one_hour:"1小時",organization:"機構",organization_website:"機構網站",organization_website_placeholder:"您機構的主頁或 LinkedIn 個人資料的 URL",preferred_date:"首選日期",preferred_language:"首選語言",preferred_products:"您對哪些產品感興趣？",subtitle:"多模態AI的未來一瞥",title:"開放日",tutor_subtitle:"精心策劃的三小時導覽，讓您更接近 Jina AI 在多模態AI技術方面的開創性工作的核心。",tutor_title:"獨家深入探討",vision:"加入我們，全面瞭解我們所看到的人工智能前景。我們的討論將重點關注大型語言模型、多模態AI的潛力以及開源技術在塑造全球創新未來方面的影響。",vision_title:"未來願景"},Z={answer1:"我們提供德語、英語、法語、西班牙語、中文和俄語的講解服務。",answer2:"講解通常持續大約三個小時。",answer3:"午餐是可選的，可根據要求安排。",answer4:"我們的開放日主要是為專業團體設計的，例如政治家、非政府機構、非營利機構和投資者。然而，我們偶爾會根據個人的個人資料做出例外情況。",answer5:"我們可以容納各種規模的團體。請在報名表中註明您的團體人數，我們將與您確認詳細信息。",answer6:"註冊表中有一個部分，您可以在其中指定您感興趣的領域或任何特殊要求。我們將盡力根據您的需求定製行程。",answer7:"目前，我們僅在位於克羅伊茨貝格的柏林總部提供開放日。我們的北京和深圳辦事處目前不開放參觀。",question1:"你們提供哪些語言的講解服務？",question2:"講解時長是多少？",question3:"提供午餐嗎？",question4:"個人可以報名參加開放日嗎？",question5:"開放日的團體可以有多少人？",question6:"我如何指定講解的興趣區域？",question7:"你們的北京或深圳辦事處提供開放日嗎？"},$={description:"開源、雲原生的大型多模態模型服務框架"},ee={commercial_licence:{chip_label:"專為小型公司",company_size_note:"專為員工人數少於 100 人且收入少於 500 萬美元的公司提供",cta_button:"立即開始",download_title:"下載商業許可證",feature_api_desc:"購買前請先測試",feature_api_title:"免費 API 測試訪問",feature_consulting:"每季度與我們的模型專家進行 2 小時的諮詢會議",feature_consulting_desc:"每個許可期限內提供三 (3) 小時的技術諮詢服務。",feature_future_support:"無需許可即可訪問未來的 CC BY-NC 模型",feature_future_support_desc:"許可期限內許可方根據 CC-BY-NC-4.0 發佈的任何新模型。",feature_models:"無限制地使用我們的 CC BY-NC 模型進行商業使用",feature_models_desc:"將模型用於商業目的，包括內部使用或納入面向客户的應用程序。",price_amount:"1,000 美元",price_period:"/ 每季度",read_the_terms:"查看許可條款",read_the_terms_btn:"條款",read_the_terms_desc:"購買前查看商業許可權利和限制",subtitle:"這些模型助您實現更好的搜索",test_before_purchase:"購買前請先試用",test_before_purchase_desc:"獲取 100 萬個免費 API 詞元或使用我們的 Hugging Face 模型來驗證性能",title:"商業許可證",try_api:"首先嚐試 API"},free_hour_consult:"免費1小時諮詢",free_hour_consult_description:"與我們的產品和工程團隊進行一小時免費諮詢，討論適合您場景下的最佳實踐",full_commercial:"不受限制的商業用途",full_commercial_description:"您可以將 API 用於商業目的，不受任何限制。",higher_limit:"更高速率！",higher_limit_description:"r.jina.ai 最高可達 1000 RPM，s.jina.ai 最高可達 100 RPM；更多詳細信息請參閲速率限制部分。",no_commercial:"僅限非商業用途（CC-BY-NC）",no_commercial_description:"您只能將API用於非商業用途，若要用於商業用途，請充值您的API密鑰。",on_prem:"擁有本地部署的商業許可證",on_prem_explain:"購買商業許可證以在現場使用我們的模型。",priority_support:"優先客户支持",priority_support_description:"保證 24 小時內（包括週末）回覆電子郵件",secured_by_stripe:"通過 Stripe 安全付款",via_api:"使用 Jina Search Foundation API",via_api_explain:"訪問我們所有產品的最簡單方法。隨時充值代幣。"},ne="基於",te="打印",ie={archived:"已存檔",cloud_native:"雲原生",core:"基層核心",data_structure:"數據結構",embedding_serving:"大模型向量部署",embedding_tuning:"大模型向量調優",graduated:"已畢業",incubating:"孵化中",kubernetes:"Kubernetes",large_size_model:"大型模型",linux_foundation:"Linux 基金會",llm1:"LLM框架",mid_size_model:"中型模型",model_serving:"模型部署",model_tuning:"模型調優",observability:"可觀察性",orchestration:"雲編排",prompt_serving:"提示詞部署",prompt_tuning:"提示詞調優",rag1:"RAG應用",sandbox:"沙盒",small_size_model:"小型模型",vector_database:"向量數據庫",vector_store:"向量數據庫"},ae={description:"首屈一指的提示詞工具箱",image_model:"圖像模型",intro:"首屈一指的提示詞工具箱",intro1:"提示詞工程的首要工具",optimized:"你的任務是成為我的頭腦風暴夥伴，為特定的主題或問題提供創造性的想法和建議。您的回答應該包括原創的、獨特的和相關的想法，這些想法可以幫助解決問題或以有趣的方式進一步探索該主題。請注意，您的回答還應考慮任務的任何具體要求或限制。",optimized_title:"優化後的提示詞",original:"你的角色是成為我的頭腦風暴夥伴。",original_title:"原提示詞",text_model:"文本模型"},_e={features:[{description:"輕鬆在內容成產和提示詞優化之間切換，將您的內容質量提升到新的水平。",name:"智能助手",title:"每日一罐生產力。"},{description:"不知道如何編寫有效的提示詞？只需輸入您的想法，點一下鼠標，即可獲得更好的提示詞。",name:"提示詞優化",title:"更好的輸入，更好的輸出"},{description:"通過比較同一提示詞的輸出來瞭解每個 AI 模型的性格。",name:"模型大比拼",title:"並排模型比較。"},{description:"這也許是將提示詞部署為 API 最簡單的方法。",name:"部署提示詞",title:"告別繁瑣Ops，直接部署。"},{description:"定製您自己的 LLM 智能體，並啓動多智能體模擬。查看它們如何在虛擬環境中協作或競爭以達到目標。",name:"多智能體",title:"探索智能體如何協作"}],get_started:"開始使用 PromptPerfect"},re={success:"感謝您的購買！",success_caption:"我們已於 {_purchasedTime} 完成您的訂單。您的 API 密鑰已可供使用！"},oe="立即購買",se={batch_explain:"此 API 支持批量操作，每次請求最多允許 512 個文檔，每個文檔最多包含 8192 個詞元。巧妙利用批量操作可以大幅減少請求次數並提高性能。",classifier:"使用標記示例訓練分類器",classifier_few_shot:"使用經過訓練的少樣本分類器對輸入進行分類",classifier_few_shot_token_counting:"詞元計數為：input_tokens",classifier_latency:"響應時間隨輸入大小而變化",classifier_token_counting:"詞元計數為：input_tokens × num_iters",classifier_zero_shot:"使用零樣本分類對輸入進行分類",classifier_zero_shot_token_counting:"詞元計數為：input_tokens + label_tokens",depends:"取決於輸入大小",description:"描述",embeddings:"將文本/圖像轉為定長向量",endpoint:"API端口",explain:"速率限制以兩種方式跟蹤：<b>RPM</b>（每分鐘請求數）和<b>TPM</b>（每分鐘詞元數）。限制是針對每個 IP 強制執行的，並且可以根據首先達到的閾值（RPM 或 TPM）來達到。",gjinaai:"用網絡知識支撐聲明",input_token_counting:"以輸入請求中的詞元數量為準。",latency:"平均延遲",no_token_counting:"詞元不計算使用量。",output_token_counting:"以輸出響應中的詞元數量為準。",premium_rate:"有可能提高速率限制",product:"產品",requestType:"請求類型",reranker:"按查詢對文檔進行精排",rjinaai:"將 URL 轉換為 LLM 友好文本",sjinaai:"搜索網絡並將結果轉換為 LLM 友好文本",tbd:"有待確定",title:"速率限制",tokenCounting:"詞元使用計數",tokenizer:"對長文本進行分詞分句",total_token_counting:"統計整個過程中詞元的總數。",understanding:"瞭解速率限制",understanding_description:"速率限制是指每個 IP 地址在一分鐘內可以向 API 發出的最大請求數 (RPM)。請在下面詳細瞭解每個產品和層級的速率限制。",wAPIkey:"使用 API 密鑰",wPremium:"帶有高級 API 密鑰",woAPIkey:"無 API 密鑰"},ce={decision:"決定",description:"LLM輔助智能決策工具",intro:"看到硬幣的兩面，做出理性的決定"},de={beta:"實驗",better_input:"從一開始就提高輸入質量",better_input_description:"您的Agent或 RAG 系統輸出出現問題？這可能是由於輸入質量差造成的。",check_price_table:"查看價格表",copy:"複製",demo:{advanced_parameter_explain:"僅用於{_product}的特定參數。",advanced_parameters:"具體的",advanced_usage:"高級用法",ask_llm:"詢問 LLM 是否需要搜索依據",ask_llm_directly:"直接詢問LLM",ask_llm_with_search_grounding:"通過搜索詢問LLM",ask_question:"提出問題",ask_question_hint:"輸入問題並將其與獲取的 LLM 內容相結合以生成答案",basic_usage:"基本用法",basic_usage1:"讀取 URL",basic_usage2:"搜索查詢",basic_usage3:"查論",common_parameter_explain:"可用於{_product1}、{_product2}和{_product3}的通用參數。",common_parameters:"通用參數",copy:"複製",fetch:"獲取內容",get_response:"獲取響應",grounding_result_false:"此言差矣。",grounding_result_true:"此言正確。",headers:{auth_token:"添加 API 密鑰以實現更高的速率限制",auth_token_explain:"輸入您的 Jina API 密鑰以訪問更高的速率限制。有關最新速率限制信息，請參閲下表。",browser_locale:"瀏覽器區域設置",browser_locale_explain:"控制瀏覽器區域設置以呈現頁面。許多網站根據區域設置提供不同的內容。",custom_script:"預執行自定義 JavaScript",custom_script_explain:"執行預處理 JavaScript 代碼，接受內聯代碼字符串或遠程腳本 URL 端點",deepdive:"深度源代碼分析",deepdive_explain:"搜索更多來源並閲讀完整文檔以進行徹底的事實核查。速度稍慢但更準確且參考資料更多。",default:"默認",default_explain:"針對大多數網站和 LLM 輸入優化的默認管道。",file:"本地 PDF/HTML 文件",file_explain:"通過上傳本地 PDF 和 HTML 文件，使用閲讀器閲讀它們。僅支持 pdf 和 html 文件。",html:"HTML",html_explain:"返回 documentElement.outerHTML。",image_caption:"圖片説明",image_caption_explain:"為指定 URL 上的所有圖像添加標題，為沒有標題的圖像添加“Image [idx]: [caption]”作為 alt 標籤。這允許下游 LLM 在推理和總結等活動中與圖像進行交互。",images_summary:"將所有圖像集中到最後",images_summary_explain:"最後會創建一個“圖像”部分。這可以讓下游的 LLM 概覽頁面上的所有視覺效果，從而提高推理能力。",json_response:"JSON 響應",json_response_explain:"響應將採用 JSON 格式，包含 URL、標題、內容和時間戳（如果可用）。在搜索模式下，它會返回一個包含五個條目的列表，每個條目都遵循描述的 JSON 結構。",links_summary:"將所有鏈接集中到最後",links_summary_explain:"最後會創建一個“按鈕和鏈接”部分。這可以幫助下游 LLM 或 Web 代理瀏覽頁面或採取進一步的行動。",markdown:"Markdown",markdown_explain:"直接從 HTML 返回 markdown，繞過可讀性過濾。",mode:"閲讀或搜索模式",mode_explain:"閲讀模式用於訪問 URL 的內容，而搜索模式允許您在網絡上搜索查詢，並將閲讀模式應用於每個搜索結果 URL。",no_cache:"繞過緩存",no_cache_explain:"我們的 API 服務器會將讀取和搜索模式的內容緩存一段時間。要繞過此緩存，請將此標頭設置為 true。",no_gfm:"已禁用",no_gfm_explain:"GFM（Github Flavored Markdown）功能已禁用。",no_gfm_table:"無 GFM 表",no_gfm_table_explain:"選擇退出 GFM 表但保留表 HTML 元素作為響應。",opt_out_gfm:"Github 風格的 Markdown",opt_out_gfm_explain:"選擇加入/退出 GFM（Github Flavored Markdown）功能。",pageshot:"頁面快照",pageshot_explain:"返回整頁截圖的圖片網址（盡力而為）。",post_with_url:"使用 POST 方法",post_with_url_explain:"使用 POST 方法代替 GET 方法，並在正文中傳遞 URL。對於使用基於哈希的路由構建 SPA 非常有用。",proxy_server:"使用代理服務器",proxy_server_explain:"我們的 API 服務器可以利用您的代理來訪問 URL，這對於只能通過特定代理訪問的頁面很有幫助。",references:"參考",references_explain:"以逗號分隔的用户提供的參考 (url) 列表",remove_all_images:"刪除所有圖片",remove_all_images_explain:"從響應中刪除所有圖像。",remove_selector:"排除選擇器",remove_selector_explain:"提供 CSS 選擇器列表以刪除頁面的指定元素。當您想要排除頁面的特定部分（如頁眉、頁腳等）時很有用。",return_format:"內容格式",return_format_explain:"您可以控制響應中的細節級別，以防止過度過濾。默認管道針對大多數網站和 LLM 輸入進行了優化。",screenshot:"截屏",screenshot_explain:"返回第一個屏幕的圖像URL。",set_cookie:"轉發 Cookie",set_cookie_explain:"我們的 API 服務器可以在訪問 URL 時轉發您的自定義 Cookie 設置，這對於需要額外身份驗證的頁面非常有用。請注意，帶有 Cookie 的請求不會被緩存。",site_selector:"站內搜索",site_selector_explain:"僅返回指定網站或域的搜索結果。默認情況下，它會搜索整個網絡。",stream_mode:"流模式",stream_mode_explain:"流模式有利於較大的目標頁面，從而留出更多時間讓頁面完全呈現。如果標準模式導致內容不完整，請考慮使用流模式。",target_selector:"目標選擇器",target_selector_explain:"提供 CSS 選擇器列表，以關注頁面的更具體部分。當您想要的內容在默認設置下不顯示時很有用。",text:"文本",text_explain:"返回 document.body.innerText。",wait_for_selector:"等待選擇器",wait_for_selector_explain:"提供一個 CSS 選擇器列表，等待特定元素出現後再返回。當默認設置下無法顯示所需內容時，此功能非常有用。",with_gfm:"已啓用",with_gfm_explain:"已啓用 GFM（Github Flavored Markdown）功能。",with_iframe:"啓用 iframe 提取",with_iframe_explain:"提取並處理 DOM 樹中所有嵌入的 iframe 的內容",with_shadow_dom:"啓用 Shadow DOM 提取",with_shadow_dom_explain:"遍歷文檔中所有 Shadow DOM 根並提取內容",x_timeout:"超時時間",x_timeout_explain:"等待網頁加載的最長時間。請注意，這不是整個端到端請求的總時間。"},how_to_stream:"要在內容可用時對其進行處理，請將請求標頭設置為流模式。這可以最大限度地縮短收到第一個字節所需的時間。curl 中的示例：",how_to_use1:"將 https://r.jina.ai/ 添加到代碼或工具中需要 LLM 訪問的任何 URL。這將以乾淨、LLM 友好的文本返回頁面的主要內容。",how_to_use2:"將 https://s.jina.ai/ 添加到您的查詢中。這將調用搜索引擎並返回前 5 個結果及其 URL 和內容，每個結果都以簡潔、LLM 友好的文本顯示。",how_to_use3:"將 https://g.jina.ai/ 添加到您的語句中。這將調用判斷引擎並返回真實性百分比、表示語句是真還是假的布爾值、原因摘要和參考列表。",key_required:"使用此端點需要 API 密鑰",learn_more:"瞭解更多",open:"在新標籤頁中打開",params_classification:"參數",raw_html:"原始 HTML",reader_output:"讀取器的輸出",reader_response:"讀取器反應",reader_search_hint:"如果您在代碼中使用此 URL，請不要忘記對該 URL 進行編碼。",reader_url:"讀取器網址",reader_url_hint:"點擊下面通過我們的讀取器 API 獲取內容",requires_post_method:"此功能需要 POST 方法。上傳本地文件後，將自動啓用 POST 方法。",search_params:"搜索參數",search_query_rewrite:"請注意，與上面的演示不同，在實踐中，您不會在網上搜索原始問題來獲取基礎。人們經常做的是重寫原始問題或使用多跳問題。他們閲讀檢索到的結果，然後生成其他查詢以根據需要收集更多信息，然後得出最終答案。",select_mode:"選擇模式",show_read_demo:"瞭解 Reader 如何讀取 URL",show_search_demo:"瞭解讀取器如何搜索網絡",slow_warning:"這可能需要長達 30 秒並且每個請求最多需要 300K 個詞元。",standard_usage:"標準用法",stream_mode:"流模式",stream_mode_explain:"當目標頁面很大而無法渲染時，流模式非常有用。如果您發現標準模式提供的內容不完整，請嘗試流模式。",stream_mode_explain1:"當您發現標準模式提供的結果不完整時，流式模式很有用。這是因為流式模式將等待更長時間，直到頁面完全呈現。使用 accept-header 切換流式模式：",tagline:"試用演示",try_demo:"演示",use_headers:"可以使用請求標頭來控制 Reader API 的行為。以下是受支持標頭的完整列表。",waiting_for_reader:"首先等待 Reader API 結果...",warn_grounding_message:"此過程可能需要長達 30 秒的時間，並且每個查論請求最多會消耗 300K 個詞元。某些瀏覽器可能會因為較長的延遲而終止請求，因此我們建議複製代碼並從終端運行它。",warn_grounding_title:"高延遲和詞元使用率",your_query:"輸入您的查詢",your_query_hint:"輸入需要最新信息或世界知識的問題。",your_statement:"您的事實核查聲明",your_url:"輸入您的 URL",your_url_hint:"點擊下面直接獲取頁面源代碼"},description:"閲讀 URL或通過搜索為LLM提供更好的依據。",dont_panic_api_key_is_free:"不要驚慌！每個新的 API 密鑰都包含一百萬個免費詞元！",faq_v1:{answer1:"讀取器 API 是免費的，不需要 API 密鑰。只需在您的 URL 前面添加“https://r.jina.ai/”即可。",answer10:"不可以，讀取器 API 只能處理來自可公開訪問的 URL 的內容。",answer11:"如果您在 5 分鐘內請求相同的 URL，讀取器 API 將返回緩存的內容。",answer12:"不幸的是沒有。",answer13:"是的，您可以使用讀取器中的原生 PDF 支持（https://r.jina.ai/https://arxiv.org/pdf/2310.19923v4）或使用 arXiv 中的 HTML 版本（https://r.jina.ai/https://arxiv.org/html/2310.19923v4）",answer14:"Reader 為指定 URL 上的所有圖像添加標題，並添加 `Image [idx]: [caption]` 作為 alt 標籤（如果最初沒有）。這使得下游 LLM 能夠與圖像進行推理、總結等交互。",answer15:"Reader API 的設計具有高度可擴展性。它根據實時流量自動擴展，最大併發請求數現在約為 4000。我們正在積極維護它，將其作為 Jina AI 的核心產品之一。因此，請放心在生產中使用它。",answer16:"請在下表中查找最新的速率限制信息。請注意，我們正在積極致力於改進 Reader API 的速率限制和性能，因此該表將進行相應更新。",answer2:"讀取器 API 使用代理來獲取任何 URL，並在瀏覽器中呈現其內容以提取高質量的主要內容。",answer3:"是的，讀取器 API 是開源的，可以在 Jina AI GitHub 存儲庫中找到。",answer4:"讀取器 API 通常會在 2 秒內處理 URL 並返回內容，但複雜或動態的頁面可能需要更多時間。",answer5:"抓取可能很複雜且不可靠，尤其是複雜或動態頁面。讀取器 API 提供簡潔、可靠的乾淨 LLM 級文本輸出。",answer6:"讀取器 API 返回 URL 原始語言的內容。它不提供翻譯服務。",answer7:"如果您遇到阻止問題，請聯繫我們的支持團隊尋求幫助和解決方案。",answer8:"雖然 讀取器 API 主要用於網頁，但它可以從 arXiv 等網站上以 HTML 格式查看的 PDF 中提取內容，但它並未針對一般 PDF 提取進行優化。",answer9:"目前，讀取器 API 不處理媒體內容，但未來的增強功能將包括圖像字幕和視頻摘要。",question1:"使用 讀取器 API 的相關費用是多少？",question10:"是否可以在本地 HTML 文件上使用 讀取器 API？",question11:"讀取器 API 是否緩存內容？",question12:"我可以使用 讀取器API 來訪問登錄後的內容嗎？",question13:"我可以使用讀取器 API 訪問 arXiv 上的 PDF 嗎？",question14:"圖片標註在讀取器中如何發揮作用？",question15:"讀取器的可擴展性如何？我可以在生產中使用它嗎？",question16:"Reader API 的速率限制是多少？",question2:"讀取器 API 如何發揮作用？",question3:"讀取器 API 是開源的嗎？",question4:"讀取器 API 的典型延遲是多少？",question5:"為什麼我應該使用 讀取器 API 而不是自己抓取頁面？",question6:"讀取器 API 是否支持多種語言？",question7:"如果某個網站屏蔽了 讀取器 API，我該怎麼辦？",question8:"讀取器 API 可以從 PDF 文件中提取內容嗎？",question9:"讀取器 API 可以處理來自網頁的媒體內容嗎？",title:"與讀取器相關的常見問題"},fast:"快速地",fast_stream:"即時數據流",fast_stream_description:"需要快速獲取數據？我們的 讀取器 API 可以傳輸數據以最大程度地減少延遲。",free:"永遠免費",free_description:"讀取器 API 是免費的！它不需要信用卡或 API 密碼。它不會消耗您的詞元配額。",is_free:"而且它是竟然是免費的！",is_free_description:"Reader API 可免費使用，並提供靈活的速率限制和定價。它建立在可擴展的基礎架構上，具有高可訪問性、併發性和可靠性。我們努力成為您 LLM 的首選基礎解決方案。",open:"在新標籤頁中打開",original_pdf:"原始 PDF",rate_limit:"速率限制",read_grounding_release_note:"閲讀發佈説明",reader_also_read_images:"網頁上的圖像會使用讀取器中的視覺語言模型自動添加標題，並在輸出中格式化為圖像 alt 標籤。這為您的下游 LLM 提供了足夠的提示，以將這些圖像納入其推理和總結過程。這意味着您可以詢問有關圖像的問題，選擇特定的圖像，甚至將其 URL 轉發到更強大的 VLM 進行更深入的分析！",reader_description:"將 URL 轉換為 LLM 友好輸入，只需在前面添加 <code>r.jina.ai</code> 即可。",reader_do_grounding:"事實核查閲讀器",reader_do_grounding_explain:"新的基準端點提供端到端、近乎實時的事實核查體驗。它獲取給定的陳述，使用實時網絡搜索結果對其進行基準化驗，並返回事實性分數和使用的確切參考資料。您可以輕鬆對陳述進行基準化驗，以減少 LLM 幻覺或提高人工編寫內容的完整性。",reader_do_pdf_explain:"是的，Reader 本身支持 PDF 閲讀。它兼容大多數 PDF，包括包含大量圖片的 PDF，而且速度極快！結合 LLM，您可以輕鬆快速地構建 ChatPDF 或文檔分析 AI。",reader_do_search:"搜索溯源讀取器",reader_do_search_explain:"LLM 有知識限制，這意味着他們無法獲取最新的世界知識。這會導致錯誤信息、過時的回應、幻覺和其他事實問題等問題。基礎對於 GenAI 應用程序絕對必不可少。Reader 允許您使用來自網絡的最新信息為您的 LLM 打下基礎。只需在您的查詢前面添加 https://s.jina.ai/，Reader 就會搜索網絡並返回前五個結果及其 URL 和內容，每個結果都以乾淨、LLM 友好的文本顯示。這樣，您就可以始終讓您的 LLM 保持最新狀態，提高其事實性並減少幻覺。",reader_reads_images:"讀取器也順便識圖！",reader_reads_pdf:"讀取器還可以閲讀 PDF！",reader_result:"讀取器結果",table:{td_1_0:"讀取 URL 返回其內容，用於單渠道依據",td_1_1:"20 請求每分鐘",td_1_2:"200 請求每分鐘",td_1_3:"根據輸出詞元",td_1_4:"3 秒",td_1_5:"3 秒",td_2_0:"在網絡上搜索返回前 5 個結果，有助於獲得世界知識和搜索依據",td_2_1:"5 請求每分鐘",td_2_2:"40 請求每分鐘",td_2_3:"根據所有 5 個搜索結果的輸出詞元數",td_2_4:"10 秒",td_2_5:"10 秒",th0:"端點",th1:"描述",th2:"無 API 密鑰的速率限制",th3:"使用 API 密鑰進行速率限制",th4:"詞元計數方案",th5:"平均延遲",th6:"平均延遲"},title:"讀取器 API",usage:"用法",usage_details_false:"僅顯示基本用法",usage_details_null:"顯示基本用法和高級用法",usage_details_true:"僅顯示高級用法",want_higher_rate_limit:"想要更高的速率限制（高達 1000 RPM）？我們可以為您提供支持！",what_is1:"什麼是讀取器？",what_is_answer_long:"將網絡信息輸入 LLM 是打好基礎的重要一步，但這可能很有挑戰性。最簡單的方法是抓取網頁並輸入原始 HTML。但是，抓取可能很複雜且經常受阻，而且原始 HTML 中充斥着標記和腳本等無關元素。讀取器 API 通過從 URL 中提取核心內容並將其轉換為乾淨的、LLM 友好的文本來解決這些問題，從而確保為您的Agent和 RAG 系統提供高質量的輸入。",what_is_desc:"訪問任何 URL 並提取其主要內容轉換為針對 LLM 優化的文本。"},le={confirm_message:"您的 API 密鑰還剩 {_leftTokens} 個詞元。將 {_numArticles} 篇文章的全文發送到重排器API，利用 {_selectedReranker} 模型去尋扎與當前頁面的相關文章，這將顯着消耗 API 密鑰 {_APIKey} 的詞元計數。您想繼續嗎？",confirm_title:"警告：大量消耗詞元",out_of_quota:"此 API 密鑰已用完詞元。請為您的帳户充值或使用不同的 API 密鑰。",recommend:"獲取前 5 名",recommended_articles:"前 5 條類似文章"},pe={benchmark:{description0:"LlamaIndex 評估了 RAG 的向量模型和重排器器的各種組合，我們對起進行復現。研究結果顯示 Jina 重排器 顯着提高了搜索質量，這一優勢與上游所使用的特定向量模型無關。",description1:"BIER（Benchmarking IR）評估模型的檢索有效性，包括相關性和NDCG。較高的 BIER 分數與更準確的匹配和搜索結果排名相關。",description2:"通過 LoCo 基準測試，我們測量了模型對本地連貫性和上下文的理解，以及特定於查詢的排名。 LoCo 分數越高，反映出識別相關信息並確定優先級的能力越好。",description3:"MTEB（多語言文本向量模型基準）總體上測試了模型在文本向量模型方面的能力，包括聚類、分類、檢索和其他指標。然而，為了進行比較，我們僅使用 MTEB 的重排器任務。",title:"基準",title0:"LlamaIndex",title1:"BIER",title2:"LoCo",title3:"MTEB"},benchmark_description:"為了進行比較，我們在基準測試中納入了 BGE (北京智源研究院)、BCE (網易有道) 和 Cohere 的其他三個領先的重排器。如下圖所示，Jina 重排器 在所有相關重排類別中平均得分最高，在同行中處於明顯領先地位。",benchmark_title:"性能基準測試",choose_turbo:"5倍提速的Turbo版本",choose_turbo_description:"我們還提供兩個新的開源重排模型：jina-reranker-v1-turbo-en 和 jina-reranker-v1-tiny-en，後者只有 30M 個參數和 4 層。這兩個新的重排器的推理速度比底座模型快 5 倍，而質量卻只下降一點點。它們非常適合需要實時重排的應用程序。請閲讀下面的評測。",customize_urself:"試試改變它看看響應如何變化！",customize_urself_pl:"試試改變它們看看響應如何變化！",description:"世界一流的神經檢索器，可最大限度地提高搜索相關性。",description_rich:"利用我們先進的重排 API 最大限度地提高搜索相關性和 RAG 準確性。",example_input_document:"待排序候選文檔示例",example_input_query:"查詢示例",faq_v1:{answer1:"重排器 API 的定價與我們的向量模型 API 定價結構一致。每個新 API 密鑰都會獲得 100 萬個免費詞元。除了免費詞元之外，還可以購買不同的套餐。欲瞭解更多詳情，請訪問我們的定價部分。",answer10:"是的，Jina 重排器 可以部署在 AWS 上。如果您需要在企業環境中進行本地部署，您可以通過我們的 AWS Marketplace 產品輕鬆實現。",answer11:"如果您對針對特定域數據量身定製的微調重排器感興趣，請聯繫我們的銷售團隊。我們的團隊將及時回覆您的詢問。",answer3:"主要區別在於它們的架構。就性能而言，我們推薦 jina-reranker-v1，它已經過針對競爭對手的廣泛測試和基準測試。 Jina-reranker-v1 採用交叉編碼器架構，而 Jina-colbert-v1 基於 ColBERTv2 架構，但將查詢和文檔的上下文長度擴展至 8192，實現了比原始 ColBERTv2 模型更好的性能。",answer4:"是的，jina-colbert-v1 是開源的，可以通過 Huggingface 訪問。但是，jina-reranker-v1 不是開源的。",answer5:"目前，它僅支持英語。然而，一些用户報告説它也適用於中文。這可能部分是因為 jina-reranker-v1-base-en 與我們的 jina-embeddings-v2-base-zh 向量模型模型共享一些權重。",answer6:"最大查詢詞元長度為 512。文檔沒有詞元限制。",answer7:"每個查詢最多可以對 2048 個文檔進行重排。",answer8:"與我們的向量模型 API 不同，沒有批量大小的概念。每個請求只能發送一個查詢文檔元組，但該元組最多可以包含 2048 個候選文檔。",answer9:"延遲從 100 毫秒到 7 秒不等，主要取決於文檔和查詢的長度。例如，使用 64 個詞元的查詢對 100 個包含 256 個詞元的文檔進行重排大約需要 150 毫秒。將文檔長度增加到 4096 個詞元將使時間增加到 3.5 秒。如果查詢長度增加到 512 個詞元，則時間進一步增加到 7 秒。",question1:"重排器 API 的費用是多少？",question10:"我可以在 AWS 上部署 Jina Reranker 嗎？",question11:"你們是否提供針對特定領域數據的微調重排器？",question3:"這兩個重排器有什麼區別？",question4:"Jina Reranker 是開源的嗎？",question5:"重排器支持多種語言嗎？",question6:"查詢和文檔的最大長度是多少？",question7:"每個查詢可以重排的最大文檔數是多少？",question8:"批量大小是多少以及在一個請求中可以發送多少個查詢文檔元組？",question9:"對 100 個文檔重排時，預計延遲會是多少？",title:"與 重排器 相關的常見問題"},feature_on_premises_description2:"在 AWS Sagemaker 上部署我們的重排模型，很快就會在 Microsoft Azure 和 Google Cloud Services 上部署，或者聯繫我們的銷售團隊，為您的虛擬私有云和本地服務器獲取定製的 Kubernetes 部署。",feature_on_premises_description3:"在 AWS Sagemaker 和 Microsoft Azure 上部署 Jina Reranker，很快就會在 Google Cloud Services 上部署 Jina Reranker，或者聯繫我們的銷售團隊，為您的虛擬私有云和本地服務器獲取定製的 Kubernetes 部署。",feature_solid_description:"由我們的尖端學術研究開發而成，並針對 SOTA 重排器器進行了嚴格測試，以確保無與倫比的性能。",how_it_works:"在搜索系統中，重排器的工作原理如下：",how_it_works_v1:{description1:"根據用户的查詢，使用向量模型或BM25或TF-IDF等維度，在數據庫中粗略匹配相關文檔。",description2:"重排模型會獲取這些初排結果，並在更精細的顆粒度上對文檔和查詢其進行相關性分析，同時考慮查詢術語與文檔內容交互等細微差別。",description3:"重排模型會將其認為最相關的結果放在頂部，從而改善搜索質量。",title1:"初始檢索",title2:"重排",title3:"改善後的結果"},improve_performance:"搜索質量高人一等",improve_performance_description:"我們的評估表明，使用我們重排器的搜索系統得到了有效的改進，命中率提高了 8%，平均倒排(MRR)提高了 33%。",learning1:"瞭解重排器",learning1_description:"什麼是重排模型？為什麼向量搜索或兩兩餘弦相似度還不夠？通過我們的綜合指南從頭開始瞭解重排器。",read_more_about_benchmark:"閲讀有關基準測試的更多信息",read_more_about_turbo:"瞭解有關渦輪增壓和微型模型的更多信息",read_more_about_v2:"Jina Reranker v2 是同類最佳的重排器，於 2024 年 6 月 25 日發佈；它是為 Agentic RAG 構建的。它具有函數調用支持、超過 100 種語言的多語言檢索、代碼搜索功能，並且比 v1 的速度提高了 6 倍。瞭解有關 v2 模型的更多信息。",reranker_description:"嘗試我們先進的重排器 API，最大限度地提高您的搜索相關性和 RAG 準確性。免費試用！",show_v2benchmark:"顯示 v2 模型的基準（最新）",table:{number_token_document:"每個文檔中的詞元數量",number_token_query:"查詢中的詞元數量",title:"以下是對一個查詢和 100 個文檔進行重排的時間成本（以毫秒為單位）："},title:"重排器 API",top_n:"返回最優的重排文檔數量",top_n_explain:"與查詢最相關的文檔的數量。",try_embedding:"免費使用向量模型 API",try_reranker:"免費試用重排器 API",v2_features:{description1:"Reranker v2 支持超過 100 種語言的文檔檢索，無論查詢語言是什麼。",description2:"Reranker v2 根據自然語言查詢對代碼片段和函數簽名進行排名，非常適合 Agentic RAG 應用程序。",description3:"Reranker v2 根據自然語言查詢對最相關的表進行排名，幫助對不同的表模式進行排序並在生成 SQL 查詢之前確定最相關的表模式。",title1:"多語言檢索",title2:"函數調用和代碼搜索",title3:"表格和結構化數據支持"},v2benchmark:{descBeir:"針對 Beir 數據集的不同重排器報告的 NDCG 10 分數",descCodeSearchNet:"CodeSearchNet 數據集中不同重排模型的 MRR 10 得分報告",descMKQA:"回憶一下 MKQA 數據集中不同重排器報告的 10 個分數",descNSText2SQL:"回顧 NSText2SQL 數據集中不同重排器報告的 3 個分數",descRTX4090:"RTX 4090 GPU 上不同重新排名模型的吞吐量（50 毫秒內檢索到的文檔）分數報告。",descToolBench:"召回 ToolBench 數據集中不同重排器報告的 3 個分數",titleBeir:"BEIR（不同 IR 任務的異構基準測試）",titleCodeSearchNet:"CodeSearchNet。基準測試是文檔字符串和自然語言格式的查詢的組合，並帶有與查詢相關的標記代碼段。",titleMKQA:"MKQA（多語言知識問答）",titleNSText2SQL:"NSText2SQL",titleRTX4090:"Jina Reranker v2 在 RTX4090 上的吞吐量",titleToolBench:"ToolBench。該基準測試收集了超過 16,000 個公共 API 以及相應的合成生成指令，以便在單 API 和多 API 設置中使用它們。"},vs_table:{col0:"重排器",col0_1:"增強的搜索精度和相關性",col0_2:"初始、快速過濾",col0_3:"跨廣泛查詢的一般文本檢索",col1:"向量搜索",col1_1:"詳細：子文檔和查詢段",col1_2:"廣泛：整個文檔",col1_3:"中級：各種文本片段",col2:"BM25",col2_1:"高的",col2_2:"中等的",col2_3:"低的",col3_1:"不需要",col3_2:"高的",col3_3:"低，利用預建索引",col4_1:"高的",col4_2:"高的",col4_3:"不需要",col5_1:"更適合細緻入微的查詢",col5_2:"效率與準確性之間的平衡",col5_3:"對於廣泛的查詢來説一致且可靠",col6_1:"高度準確，具有深入的上下文理解",col6_2:"快速高效，準確度適中",col6_3:"高度可擴展，具有既定的功效",col7_1:"資源密集且實施複雜",col7_2:"可能無法捕獲深層查詢上下文或細微差別",col7_3:"對於高度具體或上下文搜索可能表現不佳",header0:"最適合場景",header1:"粒度",header2:"查詢時間複雜度",header3:"索引時間複雜度",header4:"訓練時間複雜度",header5:"搜索質量",header6:"優勢",header7:"弱點",subtitle:"下表提供了 重排器、向量搜索和 BM25 的全面比較，突出顯示了它們在各個類別中的優缺點。",title:"重排器、向量搜索和 BM25 的比較"},what_is:"什麼是重排器？",what_is_answer_long:`搜索的本質就是快速有效地找到最用户想要的結果。上世紀的BM25 或 tf-idf 等關鍵字匹配算法已成熟用在各類搜索結果進行排名。近幾年來，基於向量模型的餘弦相似度大放異彩，已在許多向量數據庫成為標配。但這些方法的本質都相對簡單，經常會忽略掉自然語言的微妙之處，最重要的是，忽略掉文檔和查詢意圖之間的關聯信息。

“重排模型”由此而生！重排模型實際是一種高級AI模型，它從搜索中獲取初始候選集（通常由基於向量/基於詞元的搜索結果提供）並重新評估它們與用户搜索意圖之間的相關性。重排器超越了文字的表層匹配，探索查詢和文檔內容之間更深層次的交互。`,what_is_answer_long_ending:"重排器可以顯着提高搜索質量，因為它在子文檔和子查詢級別運行，這意味着它會查看各個單詞和短語、它們的含義以及它們在查詢和文檔中如何相互關聯。這會產生一組更精確且與上下文相關的搜索結果。",what_is_desc:"重排器是一種AI模型，可優化BM25搜索或向量召回的搜索結果。通過我們的文章瞭解更多。"},ue={caption_image_desc:"生成圖像的文字描述。",caption_image_title:"標題圖像",description:"探索每一個像素背後的故事",example1:"該視頻似乎是一段自然鏡頭，其中有一隻迷人的白色兔子和一隻蝴蝶在草地上。兔子以不同的方式與蝴蝶互動，展示了它們獨特的關係。周圍的自然環境提供了風景如畫的背景，增強了這個簡單而迷人的場景的美麗。",generate_story_desc:"根據圖像創作一個故事，通常以人物的對話或獨白為特色。",generate_story_title:"生成故事",intro1:"獨領風騷的圖像視頻理解AI",json_image_desc:"使用預定義的架構從圖像生成結構化 JSON 格式。這允許從圖像中提取特定的數據。",json_image_title:"從圖像中提取 JSON",summarize_video_desc:"生成視頻的簡潔摘要，突出顯示關鍵事件。",summarize_video_title:"總結視頻",visual_q_a_desc:"根據圖像內容回答查詢。",visual_q_a_title:"視覺問答"},me={ask_on_current_page:"向當前頁提問...",find_solution:"生成相應的解決方案...",hint:"搜索產品、新聞和您的問題",hotkey:"按 / 鍵可在本頁提問",hotkey1:"按",hotkey2:"切換",hotkey_long1:"在任何頁面，按下",hotkey_long3:"打開搜索欄",more_results:"另外 {_numMore} 個結果",placeholder:"對本頁內容提問",proposing_solution:"根據當前頁面內容生成答案...",required:"請更詳細地描述您的問題。",results:"結果"},ge={description:"導航、交互、優化：重新定義產品搜索"},Ae={description:"彌合現有搜索底座設施中的語義差距"},he={"Hacker News":"HN新聞",LinkedIn:"領英",facebook:"臉書",reddit:"紅迪網",rss:"RSS訂閲",share_btn:"分享",twitter:"X（前推特）"},Ie={click_to_learn_more:"點擊瞭解更多",contextualization:"上下文理解",contextualization_desc:"重排器根據查詢的深度上下文相關性調整初始搜索結果。這可以優化排名，以更好地匹配用户可能認為有用的內容。",coreInfra:"核心基礎設施",coreInfra_desc:"Core infra 提供了一個雲原生層，用於在公共雲和本地開發、部署和編排搜索底座模型，使服務能夠毫不費力地擴大和縮小。",embedding_serving:"大模型向量部署",embedding_serving_description:"使用雲原生技術通過強大、可擴展的微服務部署大模型向量推理。",embedding_tech:"向量模型",embedding_tech_description:`在Jina AI，我們正通過向量模型技術徹底轉變人工智能應用的面貌。這種技術能夠作為一種統一的手段，有效地表達和壓縮多種類型的數據，同時確保關鍵信息不會丟失。我們的核心目標是將複雜的數據集轉化為普遍易懂的向量模型格式，為精準和深入的人工智能分析提供支持。

向量模型在AI領域扮演着基礎但至關重要的角色。在精確圖像識別和語音識別等領域，它們幫助我們識別更為微妙的細節和差異。在自然語言處理中，它們能增強對上下文和情感的理解，使對話式AI和語言翻譯工具更加準確。此外，在構建複雜的推薦系統時，這些系統需要對不同內容形式（如文本、音頻和視頻）的用户偏好有深入的瞭解，而向量模型在這方面發揮着關鍵作用。`,embedding_tuning:"大模型向量精調",embedding_tuning_description:"通過代入專業知識和行業數據來訓練高質量的大模型向量，以增強特定任務上的性能。",embeddings:"向量模型",embeddings_desc:"向量模型是現代搜索系統的基石，將多模態數據表示為數字向量。此過程使內容的理解更加細緻入微，遠超簡單的關鍵字匹配。",for_developers:"對於開發者",for_enterprise:"對於企業",for_power_users:"對於高級用户",grounding:"溯源",grounding_desc:"讀取器通過 LLM 完善輸入和結果。它們提高了最終答案的質量、可讀性和真實性。",model_serving:"模型部署",model_serving_description:"在生產環境中部署調優模型，通常需要大量資源，例如 GPU 託管。 MLOps 強調以可擴展、高效和可靠的方式服務中型到大型模型。",model_tuning:"模型調優",model_tuning_description:"於特定任務的數據集上調整預訓練模型的參數，以提高其性能並使其適應特定應用程序。",personalization:"個性化",personalization_desc:"使用用户指令引導的合成數據自動訓練特定領域的向量化和重排器。",preprocessing:"預處理",preprocessing_desc:"預處理包括清理、規範化和將原始數據轉換為搜索系統可理解的格式。",promptOps:"提示詞工作流",promptOps_desc:"Prompt Ops 改進了搜索系統的輸入和輸出，包括用於查詢擴展、LLM 輸入和結果重寫的輸入和輸出。這確保搜索更容易理解，結果也更好。",prompt_serving:"提示詞部署",prompt_serving_description:"通過 API 包裝和提供提示，無需託管重型模型。該 API 調用公共大型語言模型服務並處理操作鏈中輸入和輸出的編排。",prompt_tech:"提示詞和智能體工程",prompt_tech_description:`在Jina AI，我們深知提示詞工程在與大型語言模型（LLM）交流中的重要性。隨着這些模型的不斷進化，我們的提示詞也變得越來越複雜，涵蓋了深入的推理和邏輯思維。這種進步彰顯了LLM和提示詞工程之間相互加強的關係。

展望未來，我們相信LLM將成為編譯器的角色，而提示詞則將演變成新型的編程語言。這意味着，未來的技術技能可能更側重於掌握提示詞的藝術，而不僅僅是傳統的編程技巧。在Jina AI，我們的目標是引領這場技術變革，通過精通這種新興的“語言”，讓先進的人工智能變得更加易於理解和應用。`,prompt_tuning:"提示詞調優",prompt_tuning_description:"精心設計和完善輸入提示的過程，以引導其輸出達到特定的、期望的響應。",representation:"表徵學習",representation_desc:"向量化將多模態數據轉換為統一的向量格式。這使搜索系統能夠理解和分類簡單關鍵字以外的內容。",rerankers:"重排器",rerankers_desc:"重排器會從向量模型中獲取初始結果並對其進行優化，確保向用户呈現最相關的結果。這對於提供符合用户意圖的高質量搜索結果至關重要。"},be={care_most:"你最關心什麼？",care_most_options:{accuracy:"準確性",cost:"成本",other:"其他",scalability:"吞吐量",speed:"速度"},care_most_required:"選擇API服務時，您最關心什麼？",company_size:"貴公司規模有多大？",company_size_required:"告訴我們您公司的規模有助於我們提供更好的服務",company_url:"貴公司的網站是什麼？",company_url_required:"告訴我們您公司的網站有助於我們提供更好的服務",contactName:"你的名字",contactName_required:"我們該如何稱呼你呢？",contactTitle:"您在公司內如何任職？",contactTitle_required:"您的職位名稱為必填項",contact_us:"聯繫我們",domain_required:"告訴我們您的工作領域有助於我們提供更好的服務",email:"電子郵件",email_contact:"您的聯繫郵箱",email_invalid:"電子郵件無效",email_required:"電子郵件為必填項",fine_tuned_embedding:"想要您私域數據專屬向量模型？我們隨時恭候！",fine_tuned_reranker:"想要您私域數據上的專屬重排器？來！我們討論一下！",full_survey:"參加完整的調查並獲得我們團隊的更快回復",get_new_key:"獲取 API 密鑰",get_update_blog_posts:"提醒我博客文章的最新更新",get_update_embeddings:"提醒我向量模型的最新消息",send:"發送",sign_up:"訂閲",subscribe:"訂閲",tell_domain:"您的領域或微調方向",usage_type:"哪種用法最能描述您？",usage_type_options:{other:"其他",poc:"原型設計或概念驗證",production:"生產環境",research:"研究階段"},usage_type_required:"告訴我們您的使用類型有助於我們提供更好的服務",used_product:"您使用的是哪個模型？",used_product_required:"選擇您正在使用或您感興趣的模型"},fe={description:"增強你的 LLM 並將其推向極限"},we="目錄",Pe={advance_usage:"使用 POST 請求獲取更多功能",basic_usage:"使用 GET 請求直接返回詞元數量",basic_usage_explain:"您可以簡單地發送一個 GET 請求來計算文本中的詞元數量。",change_content:"更改“content”參數並查看實時結果",chars:"字符",chinese:"中文",chunk:"切塊",chunk_all:"所有區塊",chunking:"對長文檔進行切塊，快如閃電鞭！",chunking_explain:"您還可以使用切分器將長文檔分割成較小的塊，從而更輕鬆地在向量模型或重排器中處理它們。我們利用常見的結構線索並構建了一套規則和啓發式方法，這些規則和啓發式方法在不同類型的內容（例如 Markdown、HTML、LaTeX 和 CJK 語言）中表現良好。",chunking_short:"切塊",chunks_in_total:"總共 {_numChunks} 個切塊",count_tokens_hint:"<b>{_numTokens}</b> 個詞元，{_numChars} 個字符。",description:"將長文本切分成塊並進行標記。",description_long:"我們的切分器對於幫助 LLM 在上下文限制內管理輸入以及優化模型性能至關重要。它允許開發人員計算詞元並提取相關文本段，從而確保高效的數據處理和成本管理。",description_long1:"用於將長文本分割成塊並進行切詞的免費 API。",english:"英語",explain:"分段器是將文本轉換為詞元或塊的關鍵組件，它們是向量模型/重排器或 LLM 處理的基本數據單位。詞元可以表示整個單詞、單詞的一部分，甚至是單個字符。",faq_v1:{answer1:"切分器可免費使用。通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會向您的密鑰收費。",answer10:"除了西方語言外，分塊技術還適用於中文、日語和韓語。",answer2:"如果沒有 API 密鑰，您可以以 20 RPM 的速率限制訪問切分器。",answer3:"使用 API 密鑰，您可以以 200 RPM 的速率限制訪問切分器。對於高級付費用户，速率限制為 1000 RPM。",answer4:"不可以，您的 API 密鑰僅用於訪問更高的速率限制。",answer5:"是的，切分器是多語言的，支持超過 100 種語言。",answer6:"GET 請求僅用於計算文本中的詞元數，可讓您輕鬆將其作為計數器集成到應用程序中。POST 請求支持更多參數和功能，例如返回第一個/最後一個 N 個詞元。",answer7:"每個請求最多可以發送 64k 個字符。",answer8:"切塊功能可根據常見的結構線索將長文檔分割成較小的塊，從而確保將文本準確地分割成有意義的塊。本質上，它是一個（大！）正則表達式模式，可根據某些通常與語義邊界一致的句法特徵（例如句子結尾、段落分隔符、標點符號和某些連詞）對文本進行分割。它不是語義切塊。這個（大）正則表達式在正則表達式的限制範圍內儘可能強大。它平衡了複雜性和性能。雖然正則表達式無法實現真正的語義理解，但它可以通過常見的結構線索很好地近似上下文。",answer9:"如果輸入包含特殊詞元，我們的切分器會將它們放入“special_tokens”字段中。這樣您就可以輕鬆識別它們並根據下游任務進行相應的處理，例如在將文本輸入 LLM 之前將其刪除以防止注入攻擊。",question1:"切分器的價格是多少？",question10:"分塊是否支持英語以外的其他語言？",question2:"如果我不提供 API 密鑰，速率限制是多少？",question3:"如果我提供 API 密鑰，速率限制是多少？",question4:"您會從我的 API 密鑰中收取詞元嗎？",question5:"切分器是否支持多種語言？",question6:"GET 和 POST 請求有什麼區別？",question7:"每個請求可以切詞的最大長度是多少？",question8:"切塊功能如何工作？是語義切塊嗎？",question9:"如何在切分器中處理諸如“endoftext”之類的特殊詞元？",title:"與分段器相關的常見問題"},free_api:"切分器可免費使用。通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會向您的密鑰收費。",input_text:"輸入文本",is_free:"切分器是免費的！",is_free_description:"通過提供您的 API 密鑰，您可以訪問更高的速率限制，並且不會對您的密鑰收費。",japanese:"日語",korean:"韓語",parameters:{auth_token:"添加 API 密鑰以實現更高的速率限制",auth_token_explain:"輸入您的Jina API密鑰以訪問更高的速率限制。有關最新速率限制信息，請參閲下表。",head:"返回前 N 個詞元",head_explain:"返回給定內容的前 N 個詞元。不包括恰好切在的邊界點。不能與“tail”一起使用。",learn_more:"瞭解更多",max_chunk_length:"每個塊的最大長度",max_chunk_length_explain:"每個塊中的最大字符數。實際上，如果文本中有自然邊界，塊長度可以小於此值。",return_chunks:"返回切塊",return_chunks_explain:"將輸入切為具有語義意義的片段，根據常見的結構線索，使用啓發式規則適應各種文本類型和邊緣情況。",return_tokens:"是否返回分詞結果",return_tokens_explain:"在響應中返回詞元及其對應的 id。切換以查看結果可視化。",tail:"返回最後 N 個詞元",tail_explain:"返回給定內容的最後 N 個詞元。不包括恰好切在的邊界點。不能與“head”一起使用。",type:"切分器",type_explain:"選擇要使用的切分器。",used_by_models:"用於 {_usedBy}。"},remove_boundary_cues:"刪除換行符",remove_boundary_cues_explain:"從輸入中刪除所有換行符（主要邊界提示），這會使問題更具挑戰性，並查看響應如何變化！",show_space:"顯示前導/尾隨空格",table:{td_1_0:"對文本進行分詞、計數並獲取第一個/最後一個 N 個詞元。",td_1_1:"20 轉/分",td_1_2:"200 轉/分",td_1_3:"1000 轉/分",td_1_4:"免費",td_1_5:"800毫秒"},title:"切分器 API",token_index:"詞元代碼：{_index}",usage:"用法",visualization:"可視化",what_is:"什麼是切分器？"},ke={cta:"翻譯成{_lang}代碼",select_language:"語言"},ye={description:"您只需要一個 Python 向量數據庫 - 不多也不少"},ve="zzz",Le={PRODUCT_DESCRIPTION:e,SEO_TAG_LINE:n,about_us_page:t,api_general_faq:i,autotune:a,best_banner:_,beta:r,billing_general_faq:o,blog_tags:s,cclicence:c,classifier:d,clip_as_service:l,cloud:p,contact_us_page:u,copy:m,copy_to_clipboard_success:g,dalle_flow:A,"dev-gpt":{description:"您的虛擬開發團隊"},disco_art:h,doc_array:I,download:b,embedding:f,embeddings:w,faq:P,faq_button:k,farewell:y,finetuner:v,finetuner_plus:L,finetuning:x,footer:q,get_new_key:M,github:R,header:S,hub:J,huggingface:j,impact_snapshots:C,inference:z,integrations:T,internship_faq:G,internship_page:B,jcloud:U,jerboa:O,jina:E,jina_chat:D,lab_dialog:N,landing_page:F,langchain_serve:H,legal_page:K,model_graph:W,news_page:Y,newsroom_page:X,notice:Q,open_day:V,open_day_faq:Z,open_gpt:$,paywall:ee,powered_by:ne,print:te,project_status:ie,prompt_perfect:ae,promptperfect:_e,purchase:re,purchase_now:oe,rate_limit:se,rationale:ce,reader:de,recommender:le,reranker:pe,scenex:ue,searchbar:me,searchscape:ge,semantic:Ae,share:he,spectrum:Ie,subscribe_system:be,think_gpt:fe,toc:we,tokenizer:Pe,translator:ke,vectordb:ye,zzz:ve};export{e as PRODUCT_DESCRIPTION,n as SEO_TAG_LINE,t as about_us_page,i as api_general_faq,a as autotune,_ as best_banner,r as beta,o as billing_general_faq,s as blog_tags,c as cclicence,d as classifier,l as clip_as_service,p as cloud,u as contact_us_page,m as copy,g as copy_to_clipboard_success,A as dalle_flow,Le as default,h as disco_art,I as doc_array,b as download,f as embedding,w as embeddings,P as faq,k as faq_button,y as farewell,v as finetuner,L as finetuner_plus,x as finetuning,q as footer,M as get_new_key,R as github,S as header,J as hub,j as huggingface,C as impact_snapshots,z as inference,T as integrations,G as internship_faq,B as internship_page,U as jcloud,O as jerboa,E as jina,D as jina_chat,N as lab_dialog,F as landing_page,H as langchain_serve,K as legal_page,W as model_graph,Y as news_page,X as newsroom_page,Q as notice,V as open_day,Z as open_day_faq,$ as open_gpt,ee as paywall,ne as powered_by,te as print,ie as project_status,ae as prompt_perfect,_e as promptperfect,re as purchase,oe as purchase_now,se as rate_limit,ce as rationale,de as reader,le as recommender,pe as reranker,ue as scenex,me as searchbar,ge as searchscape,Ae as semantic,he as share,Ie as spectrum,be as subscribe_system,fe as think_gpt,we as toc,Pe as tokenizer,ke as translator,ye as vectordb,ve as zzz};
