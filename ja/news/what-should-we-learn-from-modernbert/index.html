<!DOCTYPE html><html translate="no" dir="ltr" lang="ja"><head><title>ModernBERT から何を学ぶべきか？</title><meta charset="utf-8"><meta name="title" content="ModernBERT から何を学ぶべきか？"><meta name="description" content="より大規模なトレーニングデータ、効率的なパラメータサイジング、そして深くて薄いアーキテクチャを特徴とする ModernBERT は、今後の BERT 系モデルの方向性を示しています。"><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/what-should-we-learn-from-modernbert"><meta property="og:title" content="ModernBERT から何を学ぶべきか？"><meta property="og:description" content="より大規模なトレーニングデータ、効率的なパラメータサイジング、そして深くて薄いアーキテクチャを特徴とする ModernBERT は、今後の BERT 系モデルの方向性を示しています。"><meta property="og:image" content="https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/what-should-we-learn-from-modernbert"><meta property="twitter:title" content="ModernBERT から何を学ぶべきか？"><meta property="twitter:description" content="より大規模なトレーニングデータ、効率的なパラメータサイジング、そして深くて薄いアーキテクチャを特徴とする ModernBERT は、今後の BERT 系モデルの方向性を示しています。"><meta property="twitter:image" content="https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-BYjXrHhW.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-rzO9Riiq.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-Bv2s8xy8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-BNiObIZv.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-Blx6gMPa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-H2Qv9LQK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-BdT87dsz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-sW6wYFF9.js"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ja-DczgoMr-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-CVPW4ar9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-mXKkgh-u.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-B6RstkAU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-BoV9h5PM.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-BWAJPqtt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-Djh5kNDu.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-BGgPU8Ew.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-DoDFhXK5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-C8q71s8d.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-BVuBSM_O.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-BvRUq5aI.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-fFJOJRxz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-Na2ZFBdU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-BNBkmoUE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-BhlIRtA-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-Duz2QTmV.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-L2C9lK_J.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-BVeithsl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-BevKVM-R.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-BH6Mhh2q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-ssos_Uk_.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-Cgt-xKds.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-__S2BMiv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-7lNEDbgl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-Dr93TSNb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BCFWHG6-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-ByfH2dmw.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-CWHZwOxj.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-BaogX7P7.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-vSZoRHSY.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Nan Wang, Alex C-G"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Nan Wang, Alex C-G"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="10 mins read"><meta property="article:published_time" content="2025-01-22T08:31:26.000+01:00"><meta property="article:modified_time" content="2025-01-22T08:31:26.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "ModernBERT から何を学ぶべきか？",
  "description": "より大規模なトレーニングデータ、効率的なパラメータサイジング、そして深くて薄いアーキテクチャを特徴とする ModernBERT は、今後の BERT 系モデルの方向性を示しています。",
  "image": [
    "https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"
  ],
  "datePublished": "2025-01-22T08:31:26.000+01:00",
  "dateModified": "2025-01-22T08:31:26.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Nan Wang",
      "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
    },
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-478b3f77="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-478b3f77="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-478b3f77="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-478b3f77="" class="q-space"></div><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-478b3f77="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-478b3f77="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-478b3f77="" class="q-list q-list--dark" role="list"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ニュース</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">モデル</div></a><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_5bfac587-7347-46bd-9578-542b431c15c2" aria-label="「製品」を展開します。"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">製品</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_5bfac587-7347-46bd-9578-542b431c15c2" style="display: none;"><div data-v-478b3f77="" class="q-list q-list--dark" role="list" label="製品"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ディープサーチ</div><div class="q-item__label q-item__label--caption text-caption">最善の答えが見つかるまで、検索し、読み、推論してください。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">読者</div><div class="q-item__label q-item__label--caption text-caption">より大きなモデルに関するより詳しい情報を得るには、URL を読むか、検索してください。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ベクトルモデル</div><div class="q-item__label q-item__label--caption text-caption">世界クラスのマルチモーダル、多言語埋め込み。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">並べ替え者</div><div class="q-item__label q-item__label--caption text-caption">検索の関連性を最大化する世界クラスのニューラルレトリーバー。</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_86e74160-42e3-46a3-829d-8d81966f687a" aria-label="「もっと」を展開します。"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">もっと</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_86e74160-42e3-46a3-829d-8d81966f687a" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">分類子</div><div class="q-item__label q-item__label--caption text-caption">画像とテキストのゼロショットおよび少数ショットの分類。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">スライサー</div><div class="q-item__label q-item__label--caption text-caption">長いテキストをチャンクまたはトークンに分割します。</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">APIドキュメント</div><div class="q-item__label q-item__label--caption text-caption">AIプログラミングアシスタントIDEまたは大規模モデル用のコードを自動生成</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_7fb18f95-c095-4942-98c0-d47a82437f47" aria-label="「会社」を展開します。"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">会社</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_7fb18f95-c095-4942-98c0-d47a82437f47" style="display: none;"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">私たちについて</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">営業担当者に問い合わせる</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">インターンプログラム</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">参加しませんか</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ロゴをダウンロード</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">利用規約</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="ログイン"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ログイン</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-478b3f77="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_5981f2b5-e53a-4bc1-a143-a66239148841"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_5981f2b5-e53a-4bc1-a143-a66239148841" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_5981f2b5-e53a-4bc1-a143-a66239148841_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-478b3f77="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">ModernBERT のパラメータ効率</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">ModernBERT のコードモデリング</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">ModernBERT の長文コンテキスト処理</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">苦い教訓？</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">結論</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">技術記事</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">1月 22, 2025</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">ModernBERT から何を学ぶべきか？</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">より大規模なトレーニングデータ、効率的なパラメータサイジング、そして深くて薄いアーキテクチャを特徴とする ModernBERT は、今後の BERT 系モデルの方向性を示しています。</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/modernbert.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Nan Wang"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Nan Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Nan Wang, Alex C-G • 10 数分間の読書</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><p>2018 年、Google が BERT を公開し、現在の LLM ブーム以前から NLP のゲームチェンジャーとなりました。現在でも、多くの Small Language Model が BERT をベースに構築されています。2024 年 12 月、<a href="https://huggingface.co/blog/modernbert" rel="noreferrer">ModernBERT</a> は最近の LLM 開発から得られた知見をこれらの小規模モデルに適用しました。主なポイントは？パラメータ効率の向上、コード理解能力の向上、長文脈処理の改善です。</p><p>この投稿では、私たちがよく知る 2 つのモデル：<code>jina-XLM-RoBERTa</code>（<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> の多言語バックボーン）と <code>RoBERTa-large</code> と比較して ModernBERT を分析します。各モデルを見てみましょう：</p><ul><li><strong>ModernBERT</strong>（2024 年 12 月）は、Answer.AI、LightOn、HuggingFace が共同開発した最新の SLM です。8,192 トークンのコンテキストウィンドウのための RoPE や <a href="https://arxiv.org/abs/2002.05202">GeGLU レイヤー</a>などの最新の最適化を活用し、効率性を維持しながらパフォーマンスを向上させています。</li><li><a href="https://huggingface.co/jinaai/xlm-roberta-flash-implementation"><strong><code>jina-XLM-RoBERTa</code></strong></a><strong></strong>（2024 年 9 月）は、Meta の <a href="https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta"><code>XLM-RoBERTa</code></a> をベースにした多言語テキスト埋め込みモデルです。オリジナルの <code>XLM-RoBERTa</code> が XLM 大規模多言語データセットを使用して <code>RoBERTa</code> を強化したのに対し、<code>jina-XLM-RoBERTa</code> は拡張コンテキストトレーニング、<a href="https://arxiv.org/abs/2104.09864">RoPE</a> の実装、<a href="https://arxiv.org/abs/2307.08691">FlashAttention-2</a> のサポートでさらに進化させています。このモデルは <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> のバックボーンとして機能しています。</li><li><a href="https://huggingface.co/FacebookAI/roberta-large"><strong><code>RoBERTa-large</code></strong></a>（2019 年 7 月）は Meta が開発した、3 億 5,500 万パラメータを持つ BERT の改良版です。拡張トレーニング、より大規模なデータセット、ダイナミックマスキングなどの革新により、<a href="https://gluebenchmark.com/">GLUE</a>、<a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a>、<a href="https://arxiv.org/abs/1704.04683">RACE</a> などの主要ベンチマークで印象的な結果を達成しています。これにより、テキスト分類から質問応答まで、様々な NLP タスクに適しています。</li></ul><p>これらのモデルを 3 つの核心的な側面から比較することで、モデル開発者向けに ModernBERT の効果的な設計選択を強調し、将来の BERT 系モデルの開発に向けた重要な洞察を特定することを目指します。また、<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> の開発から得た学びと、<code>jina-embeddings-v4</code> および <code>jina-reranker-v3</code> に向けた改善計画についても共有します。</p><h2 id="modernberts-parameter-efficiency" style="position: relative;"><a href="#modernberts-parameter-efficiency" title="ModernBERT のパラメータ効率" id="anchor-modernberts-parameter-efficiency"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ModernBERT のパラメータ効率</h2><p>まず、ModernBERT のパラメータ効率へのアプローチを検討しましょう - 最近の LLM 開発からいくつかの重要な洞察を取り入れています。ModernBERT は 3 つの主要な戦略を活用しています：より深くより薄いアーキテクチャ、制御された語彙サイズ、小規模モデルからの段階的なモデルのアップスケーリングです。</p><h3 id="deep-and-thin-architecture" style="position: relative;"><a href="#deep-and-thin-architecture" title="深くて薄いアーキテクチャ" id="anchor-deep-and-thin-architecture"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>深くて薄いアーキテクチャ</h3><p>ModernBERT-large は 28 層と深くなっていますが、<code>jina-XLM-RoBERTa</code> と <code>RoBERTa-large</code> は 24 層です。興味深いのは、追加の層があるにもかかわらず <code>RoBERTa-large</code> とパラメータ数が同じということです。<code>jina-XLM-RoBERTa</code> は 89 言語を扱うため、より多くのパラメータが必要ですが、他の 2 つは英語のみに焦点を当てています。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/deep_and_thin-dark-architecture-outlines-1.svg" class="kg-image" alt="" width="1389" height="547" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">小規模 LLM では、幅（隠れユニット数）よりも深さ（レイヤー数）が重要です。深くて薄いモデル構造は抽象的な概念の捕捉に優れ、より優れた最終パフォーマンスをもたらします。</span></figcaption></figure><p>トランスフォーマーのパラメータの大部分は、アテンション層と全結合層から来ています。ModernBERT は 28 層にわたって 2,624 の隠れユニットを使用し、RoBERTa-large の 24 層にわたる 4,096 ユニットと比較して「より薄く」することで、サイズ面で競争力を維持しています。この「より深く」て薄い設定により、モデルを肥大化させることなくパフォーマンス目標を達成しています。</p>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>パラメータ数</td>
<td>400M</td>
<td>550M</td>
<td>355M</td>
</tr>
<tr>
<td>隠れ状態</td>
<td>1,024</td>
<td>1,024</td>
<td>1,024</td>
</tr>
<tr>
<td>中間次元</td>
<td>2,624</td>
<td>4,096</td>
<td>4,096</td>
</tr>
<tr>
<td>アテンションヘッド</td>
<td>16</td>
<td>16</td>
<td>16</td>
</tr>
<tr>
<td>レイヤー数</td>
<td>28</td>
<td>24</td>
<td>24</td>
</tr>
<tr>
<td>語彙サイズ</td>
<td>50,368</td>
<td>250,002</td>
<td>50,265</td>
</tr>
</tbody>
</table>

<p>このアプローチは、Meta の <a href="https://openreview.net/pdf?id=EIGbXbxcUQ">MobileLLM</a> 研究と一致しており、小規模モデルでは複雑なパターンの捕捉とパフォーマンスの向上において、幅よりも深さが重要であることが分かっています。本質的に、並列処理のために広いレイヤーを持つよりも、より多くのトランスフォーマーレイヤーを通じて情報を処理する能力の方が価値があることが証明されています。</p><p>この深くて薄いアーキテクチャがどのように機能するか、データを見てみましょう。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/performance_comparison_general.v3.svg" class="kg-image" alt="" width="872" height="371" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">従来の浅くて太いアーキテクチャを使用する同等のモデルと比較すると、ModernBERT は検索や STS などの主要タスクでより良い結果を出しています - しかもパラメータ数は同程度を保っています。</span></figcaption></figure>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>STS12</td>
<td>72.6</td>
<td><strong>72.7</strong></td>
<td>68.9</td>
</tr>
<tr>
<td>STS13</td>
<td><strong>84.9</strong></td>
<td>83.9</td>
<td>81.0</td>
</tr>
<tr>
<td>STS14</td>
<td>77.5</td>
<td><strong>77.7</strong></td>
<td>74.8</td>
</tr>
<tr>
<td>STS15</td>
<td>84.8</td>
<td><strong>85.8</strong></td>
<td>84.1</td>
</tr>
<tr>
<td>STS16</td>
<td>79.4</td>
<td><strong>79.6</strong></td>
<td>78.6</td>
</tr>
<tr>
<td>STS17</td>
<td><strong>87.5</strong></td>
<td>87.2</td>
<td>87.2</td>
</tr>
<tr>
<td>TRECCOVID</td>
<td><strong>61.1</strong></td>
<td>59.6</td>
<td>49.3</td>
</tr>
<tr>
<td>FiQA</td>
<td><strong>44.4</strong></td>
<td>40.0</td>
<td>40.7</td>
</tr>
<tr>
<td>NFCorpus</td>
<td><strong>32.6</strong></td>
<td>30.6</td>
<td>27.9</td>
</tr>
<tr>
<td>SciFact</td>
<td><strong>68.6</strong></td>
<td>65.5</td>
<td>63.1</td>
</tr>
<tr>
<td>平均</td>
<td><strong>69.3</strong></td>
<td>68.2</td>
<td>65.6</td>
</tr>
</tbody>
</table>

<p><code>jina-XLM-RoBERTa</code> を例に取ると、<code>RoBERTa-large</code> の浅くて太いアーキテクチャをベースに、語彙を 50K から 250K トークンに増やし、より多くのデータで訓練していますが、それでも ModernBERT の方が優れています。これは、アーキテクチャの変更が効率性に大きな違いをもたらしていることを示唆しています。</p><h3 id="vocabulary-size-matters" style="position: relative;"><a href="#vocabulary-size-matters" title="語彙サイズの重要性" id="anchor-vocabulary-size-matters"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>語彙サイズの重要性</h3><p>まず、トランスフォーマーでの語彙パラメータの計算方法を見てみましょう。トランスフォーマーでは、<code>語彙パラメータ = 個別トークン数 × 隠れ次元数</code> となります。<code>jina-XLM-RoBERTa</code> の例では：25 万トークンと 1,024 次元で、実際の言語タスクを処理する前に、語彙エンコーディングだけで 2 億 5,600 万パラメータが必要になります！</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/tokenizer-dark-outline.svg" class="kg-image" alt="" width="3757" height="715" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Transformerでは、最初の層がトークンを重み行列（語彙重み）を使って隠れ状態にマッピングします。すべての UTF-8 コードポイント（1,112,064）を 1,024 の隠れ次元で使用することを考えると、トークン変換だけで巨大な </span><code spellcheck="false" style="white-space: pre-wrap;"><span>1,112,064 × 1,024 = 1 B</span></code><span style="white-space: pre-wrap;"> のパラメータが必要になります。より大きな LLM（100B 以上のパラメータ）ではこのオーバーヘッドを処理できますが、小規模なモデルでは深刻な制約となります。これがまさに、BPE のようなトークナイザーを使用する理由です。これは一般的な UTF-8 コードポイントを 1 つのトークンに効率的に統合します。</span></figcaption></figure><p>ただし、次のことに注目してください：<strong>語彙の重みはアテンションメカニズムに寄与しません - 単なる参照テーブルです。</strong>固定パラメータ予算で動作する SLM の場合、語彙が大きいということは、実際の言語処理を行うアテンション層に使用できるパラメータが少なくなることを意味します。これは、より小規模な英語のみの ModernBERT-large が多言語対応の <code>jina-XLM-RoBERTa</code> よりも優れたパフォーマンスを示す理由を説明しています - <code>jina-XLM-RoBERTa</code> は複数の言語をサポートするためにより多くのパラメータ（47%！）を割り当てています。ModernBERT の焦点を絞った語彙は、パフォーマンスを向上させるだけでなく、推論も高速化し、リソースに制約のあるアプリケーションで特に効果的です。</p><p>そこで、<em>コアモデルのパラメータのみ</em>（語彙の重みを除く）を見てみると、ModernBERT は実際にその同等モデルよりも多くの計算能力を持っています：ModernBERT は <code>jina-XLM-RoBERTa</code> よりも 19% 多く、<code>RoBERTa-large</code> よりも 15% 多くのパラメータを<em>実際の</em>言語モデリングに割り当てています！</p>

<table>
<thead>
<tr>
<th>モデル仕様</th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>言語サポート</td>
<td>英語のみ</td>
<td>89 言語</td>
<td>英語のみ</td>
</tr>
<tr>
<td>語彙サイズ</td>
<td>50.4K</td>
<td>250K</td>
<td>50.3K</td>
</tr>
<tr>
<td>総パラメータ数</td>
<td>400M</td>
<td>550M</td>
<td>355M</td>
</tr>
<tr>
<td>語彙パラメータ</td>
<td>51M</td>
<td>256M</td>
<td>51M</td>
</tr>
<tr>
<td>語彙パラメータ比率</td>
<td>13%</td>
<td>47%</td>
<td>14%</td>
</tr>
<tr>
<td>コアモデルパラメータ</td>
<td><b>349M</b></td>
<td>294M</td>
<td>304M</td>
</tr>
</tbody>
</table>

<h3 id="model-upscaling-by-weight-tiling" style="position: relative;"><a href="#model-upscaling-by-weight-tiling" title="「ウェイトタイリング」によるモデルのアップスケーリング" id="anchor-model-upscaling-by-weight-tiling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>「ウェイトタイリング」によるモデルのアップスケーリング</h3><p><a href="https://huggingface.co/jinaai/jina-bert-implementation"><code>jina-BERT-v2</code></a> バックボーンの構築において、ゼロからの SLM のトレーニングはリソースを大量に消費し、複雑でした。ModernBERT はこれを<strong>ウェイトタイリング</strong>と呼ばれるスマートな初期化アプローチで解決しています - 基本的に ModernBERT-large を小規模なベースバージョンの重みからブートストラップします。</p><p>この手法は完全に新しいものではありません - DeepMind の <a href="https://gpt3demo.com/apps/deepmind-gopher">Gopher</a> の研究を基に構築され、Microsoft の <a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2 モデル</a>でも見られます。しかし、ここでの適用は SLM トレーニングのボトルネックに対処する上で特に効果的です。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/deep_and_thin-dark.svg" class="kg-image" alt="" width="1877" height="1308" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ModernBERT は Gopher チームの深さ初期化戦略を使用して、22 層から 28 層にスケールアップします。追加の層（23-28）については、ModernBERT-base の元の 22 層からの重みを使用して各層を初期化します。各層の重み行列については、Phi-2 のセンタータイリングアプローチを使用します。その仕組みは次の通りです：ModernBERT-base の重みを ModernBERT-large の行列の中央に配置します。まだ空いているエッジについては？元の重みを循環的に巻き付けて埋めます。</span></figcaption></figure><p>この初期化戦略により、ModernBERT-large は大きな利点を得ています - ゼロから始めるのではなく、より小規模な対応モデルからの事前学習されたパターンを活用します。これは<a href="https://arxiv.org/pdf/2112.11446">このサイズ範囲の言語モデルのスケールアップに特に効果的</a>であることが証明されています。</p><blockquote>ウォームスタートしたモデルは、（追加されたパラメータによる）高い初期損失から、ベースモデルの損失に非常に近い値まで急速に回復することがわかりました。417M のパラメータを 3 倍以上に拡大し、ゼロから収束まで訓練された同等のモデルよりも高いパフォーマンスを維持できました。これは、利点がトレーニングの開始時に限定されていなかったことを意味します。ただし、より大きなサイズでは、収束時に得られる相対的な利点は減少し、特に幅の拡大では顕著です。</blockquote><p>循環的な重みの巻き付けは単なる便宜的なものではありません - アテンション行列が自然に周期的なパターンを示す方法とうまく一致します。Gopher の研究では、このアプローチは SLM（9B パラメータ未満）で特に効果を発揮しますが、より大規模なモデルの領域に移行すると、その利点は徐々に減少し始めることが示されています。</p><h2 id="modernberts-code-modeling" style="position: relative;"><a href="#modernberts-code-modeling" title="ModernBERT のコードモデリング" id="anchor-modernberts-code-modeling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ModernBERT のコードモデリング</h2><p>ModernBERT は、コード最適化されたトークナイザーとトレーニングデータを使用して、コード理解に特化したアプローチを提供します。このコード処理のための微調整は、理解とリトリーバルのタスクの両方で成果を上げています。</p><p>私たちは <code>jina-embeddings-v2-code</code> コーパスを使用してベンチマークを実行し、3 つのモデルをバックボーンとして比較しました：<code>ModernBERT</code>、<code>jina-XLM-RoBERTa</code>、<code>RoBERTa-large</code>。テストは <a href="https://github.com/github/CodeSearchNet">CodeSearchNet</a> - テキスト説明をコードスニペットにマッチングさせるものでした。ModernBERT は全面的に両方の代替モデルを上回りました。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/code_search_net.v3.svg" class="kg-image" alt="" width="787" height="489" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">この差は理にかなっています - </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-XLM-RoBERTa</span></code><span style="white-space: pre-wrap;"> も </span><code spellcheck="false" style="white-space: pre-wrap;"><span>RoBERTa-large</span></code><span style="white-space: pre-wrap;"> もトレーニング中にプログラミング言語を見ていません。一方、ModernBERT-large は 2 兆のトークンでトレーニングされ、その中には相当量のコードが含まれていました。このプログラミング構文とパターンへの露出が、コード関連タスクで明確な優位性を与えています。</span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-XLM-RoBERTa</span></code><span style="white-space: pre-wrap;"> が </span><code spellcheck="false" style="white-space: pre-wrap;"><span>RoBERTa-large</span></code><span style="white-space: pre-wrap;"> をわずかに上回っているのは、より大きな多言語トレーニングデータによるものと思われます - 同じアーキテクチャでより多くの露出があったためです。それでも、両者は ModernBERT-large に大きく後れを取っています。</span></figcaption></figure>

<table>
<thead>
<tr>
<th>タスク</th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>AdvRetrieval</td>
<td>0.342</td>
<td><strong>0.363</strong></td>
<td>0.331</td>
</tr>
<tr>
<td>QueryRetrieval.python</td>
<td>0.521</td>
<td><strong>0.530</strong></td>
<td>0.525</td>
</tr>
<tr>
<td>QueryRetrieval java</td>
<td><strong>0.679</strong></td>
<td>0.633</td>
<td>0.644</td>
</tr>
<tr>
<td>QueryRetrieval.javascript</td>
<td>0.755</td>
<td><strong>0.768</strong></td>
<td>0.732</td>
</tr>
<tr>
<td>QueryRetrieval.php</td>
<td><strong>0.815</strong></td>
<td>0.781</td>
<td>0.755</td>
</tr>
<tr>
<td>QueryRetrieval.ruby</td>
<td>0.729</td>
<td><strong>0.744</strong></td>
<td>0.722</td>
</tr>
<tr>
<td>QueryRetrieval.go</td>
<td><strong>0.833</strong></td>
<td>0.809</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.go</td>
<td><strong>0.778</strong></td>
<td>0.750</td>
<td>0.759</td>
</tr>
<tr>
<td>Retrieval.java</td>
<td><strong>0.840</strong></td>
<td>0.792</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.javascript</td>
<td><strong>0.817</strong></td>
<td>0.792</td>
<td>0.757</td>
</tr>
<tr>
<td>Retrieval.php</td>
<td><strong>0.852</strong></td>
<td>0.805</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.python</td>
<td><strong>0.849</strong></td>
<td>0.816</td>
<td>0.787</td>
</tr>
<tr>
<td>Retrieval.ruby</td>
<td><strong>0.849</strong></td>
<td>0.796</td>
<td>0.803</td>
</tr>
<tr>
<td>Avg.</td>
<td><strong>0.743</strong></td>
<td>0.721</td>
<td>0.708</td>
</tr>
</tbody>
</table>

<h3 id="the-tokenizer-edge" style="position: relative;"><a href="#the-tokenizer-edge" title="トークナイザーの優位性" id="anchor-the-tokenizer-edge"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>トークナイザーの優位性</h3><p>ModernBERT がコードを上手く扱える理由を詳しく見ていきましょう - これは<a href="https://huggingface.co/docs/transformers/en/model_doc/olmo" rel="noreferrer">OLMo トークナイザー</a>を使用しているためで、標準の BERT/RoBERTa トークナイザーとは異なり、特にコード用に学習されています。</p><p>トークナイザーは UTF-8 テキストをベクトルにマッピングされるトークンに分割します - これが実際にモデルが処理するものです。学習中に、頻繁に出現する文字列を単一のトークンに組み合わせることを学習します。違いは何でしょうか？標準のトークナイザーは <code>init</code> を <code>in</code> + <code>it</code> に分割してしまい、プログラミングのコンテキストを見失います。しかし ModernBERT のコードを意識したトークナイザーは、分割せずにそのまま理解します。</p><p>スペースの扱いについて興味深い点があります：ModernBERT は Python の先頭スペースを単一のトークンとして保持し、4 スペースと 8 スペースを区別します - これはコード構造にとって重要です。一方で、<strong><code>jina-XLM-RoBERTa</code> は連続するすべてのスペースを単一の <code>_</code> に圧縮し、RoBERTa-large は各スペースを個別のトークンとして扱います。</strong>これは、ModernBERT のエンコーダーがコードを処理する際により整理された、意味のある入力を受け取る一方で、他のモデルは断片化された、一貫性の低いトークンで作業していることを意味します。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/code_tokens-cheat-2.svg" class="kg-image" alt="" width="3156" height="1247" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ModernBERT は Python の先頭スペースを単一のトークンとして保持し、4 スペースと 8 スペースを区別します - これはコード構造にとって重要です。一方、他のモデルは断片化された、一貫性の低いトークンで作業しています。</span></figcaption></figure><h2 id="modernberts-long-context-handling" style="position: relative;"><a href="#modernberts-long-context-handling" title="ModernBERT の長文コンテキスト処理" id="anchor-modernberts-long-context-handling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ModernBERT の長文コンテキスト処理</h2><p>ModernBERT は、その広範な学習コーパス（8,192 トークンのサンプルで 300B トークン）とグローバルとローカルの注意を組み合わせた高度な技術のおかげで、長文処理において大きな進歩を遂げています。</p><p>長文処理能力を評価するために、13 の言語にわたる包括的な長文ベンチマークである<a href="https://huggingface.co/datasets/Shitao/MLDR">MLDR データセット</a>を使用しました。ModernBERT は現在英語のみをサポートしているため、ModernBERT と <code>jina-XLM-RoBERTa</code> を比較するために MLDR の英語サブセットに焦点を当てました。これらのモデルは両方とも 8K トークンの入力を処理できますが、<code>RoBERTa-large</code> は 512 トークンの制限があり、長文分析には不十分なため、このベンチマークから除外されました。</p>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>MLDR-en</td>
<td><strong>0.351</strong></td>
<td>0.290</td>
</tr>
</tbody>
</table>

<p>ModernBERT の優れたパフォーマンスは、単に広範な長文学習によるものだけではありません - それは主にグローバルとローカルの注意メカニズムを革新的に組み合わせたことによります。すべての層で計算コストの高いグローバル注意を適用する <code>jina-XLM-RoBERTa</code> とは異なり、ModernBERT はより効率的なアプローチを取ります。グローバル注意（3 層ごとに <code>theta</code> 160,000 で使用）とローカル注意（<code>theta</code> 100,000 で 128 トークンのスライディングウィンドウを使用）を交互に切り替えます。このハイブリッド戦略は、高いパフォーマンスを維持しながら、学習時間を劇的に削減します。</p><blockquote>ModernBERT では、3 層ごとに RoPE theta 160,000 のグローバル注意を採用し、残りの層では RoPE theta 10,000 の 128 トークンのローカルスライディングウィンドウ注意を使用します。—— <a href="https://arxiv.org/pdf/2412.13663">ModernBERT</a></blockquote><h2 id="the-bitter-lesson" style="position: relative;"><a href="#the-bitter-lesson" title="苦い教訓？" id="anchor-the-bitter-lesson"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>苦い教訓？</h2><p>スケーリング則と<a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">苦い教訓</a>は、主要なパフォーマンスの改善はパラメータ数と学習データの増加から来ることを示唆しています。この原則は、コーパスを拡大し、タスク特有の適応に LoRA を使用するというアプローチを導きました。</p><p>しかし、ModernBERT の成功により、アーキテクチャの最適化の力を過小評価していたことが明らかになりました。SLM がパラメータを必ずしも拡大せずとも、より良いデータモデル効率を通じて優れた結果を達成できることを示しています。最近の<a href="https://arxiv.org/pdf/2408.11868">Stella Embeddings 技術レポート</a>もこの発見を裏付けており、コーパスやモデルサイズを増やすことなく、現在の埋め込みモデルの学習方法を改善できることを示しています。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg" class="kg-image" alt="Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu" width="949" height="949" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">埋め込みモデルのスケーリング則。英語タスクにおける平均 MTEB パフォーマンスがモデルパラメータ数に対してプロットされています。各ドットは埋め込みモデルを表します。すべてのモデルを表す傾向線がハイライトされ、多言語モデルはシアン色で強調されています。</span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a><span style="white-space: pre-wrap;">が同サイズのモデルと比較して優れたパフォーマンスを示し、前身の</span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-embeddings-v2</span></code><span style="white-space: pre-wrap;">からスーパーリニアな改善を示していることがわかります。このグラフは MTEB リーダーボードから上位 100 の埋め込みモデルを選択し、サイズ情報のないもの（通常はクローズドソースまたはプロプライエタリモデル）を除外して作成されました。明らかなトロール投稿も除外されました。</span></figcaption></figure><p>今後、データ利用についての理解が深まり、ModernBERT の技術を実装するにつれて、計算コストの低下とモデルサイズの縮小が予想されます。短期的には、ModernBERT 論文で概説された直接的な改善 - 特にコード関連データの統合とコードフレンドリーなトークナイザーの採用 - を実装できます。deep-and-thin アーキテクチャへの移行や、小さなモデルからの大規模モデルのブートストラップなど、より複雑な変更には、バックボーンモデルを一から構築する必要があります - これはより中期的な取り組みです。</p><p>ModernBERT の効率性は注目に値しますが、テキストのみという制限は今後の課題を示しています。マルチモーダル埋め込みモデルが人気を集める中、次の課題は、マルチモーダルアプリケーション向けの入力を処理できる、よりスマートで高速、そして高性能な検索基盤モデルの開発です。これらのアプリケーションはさらに長いコンテキストウィンドウを必要とします - これは解決すべき効率性の課題として残されています。</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="結論" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>結論</h2><p>この記事を通じて、ModernBERT が deep-and-thin アーキテクチャ、最適化されたトークナイザー、そしてウェイトタイリングを使用した効率的なスケーリングという 3 つの主要な革新によって BERT ファミリーモデルを進化させた方法を探ってきました。これらの改善により、ModernBERT は比較的コンパクトなサイズで優れたパフォーマンスを提供し、様々なタスクで <code>RoBERTa-large</code> と <code>jina-XLM-RoBERTa</code> の両方を上回ることができます。ModernBERT は、アーキテクチャの改善がパラメータサイズよりも重要になり得ることを示し、より効率的なモデルへの道を開いています。ウェイトタイリングの成功的な使用は、パフォーマンスを維持または向上させながら学習コストを削減できることを示しています。さらに、コンパクトな語彙と的を絞った最適化は、リソースが限られた環境での特化型 SLM の機会が広がっていることを示唆しています。</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">カテゴリー:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">技術記事</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-478b3f77="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-478b3f77="" class="col-sm-12 col-md"><div data-v-478b3f77="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">オフィス</div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">カリフォルニア州サニーベール</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr、Ste 200、サニーベール、CA 94085、アメリカ合衆国</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">ドイツ、ベルリン（本社）</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20、10969 ベルリン、ドイツ</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">中国、北京</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">中国北京市海淀区西街48号ビル6号5階</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">深セン、中国</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">ルーム 402、4 階、福安テクノロジービル、深セン、中国</div></div></div></div></div><div data-v-478b3f77="" class="col-sm-12 col-md row"><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">検索ベース</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ディープサーチ</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">読者</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ベクトルモデル</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">並べ替え者</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">分類子</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">スライサー</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">APIドキュメント</div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Jina APIキーを取得する</div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">レート制限</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-478b3f77="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">APIステータス</div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">会社</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">私たちについて</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">営業担当者に問い合わせる</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ニュース</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">インターンプログラム</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">参加しませんか</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">ロゴをダウンロード</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">条項</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">安全性</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">利用規約</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">プライバシー</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Cookieを管理する</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-478b3f77="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-478b3f77="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-478b3f77="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>