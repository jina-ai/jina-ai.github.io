<!DOCTYPE html><html translate="no" dir="ltr" lang="ja"><head><title>ColBERT とは何か？Late Interaction とは何か？そして検索においてなぜ重要なのか？</title><meta charset="utf-8"><meta name="title" content="ColBERT とは何か？Late Interaction とは何か？そして検索においてなぜ重要なのか？"><meta name="description" content="Jina AI の ColBERT が Hugging Face でリリースされ、8192 トークンの処理能力を持つ新しい検索アプローチとして Twitter で話題を呼んでいます。本記事では、ColBERT と ColBERTv2 の特徴を詳しく解説し、その革新的な設計と、検索に革命をもたらす後期相互作用機能について解説します。"><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search"><meta property="og:title" content="ColBERT とは何か？Late Interaction とは何か？そして検索においてなぜ重要なのか？"><meta property="og:description" content="Jina AI の ColBERT が Hugging Face でリリースされ、8192 トークンの処理能力を持つ新しい検索アプローチとして Twitter で話題を呼んでいます。本記事では、ColBERT と ColBERTv2 の特徴を詳しく解説し、その革新的な設計と、検索に革命をもたらす後期相互作用機能について解説します。"><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search"><meta property="twitter:title" content="ColBERT とは何か？Late Interaction とは何か？そして検索においてなぜ重要なのか？"><meta property="twitter:description" content="Jina AI の ColBERT が Hugging Face でリリースされ、8192 トークンの処理能力を持つ新しい検索アプローチとして Twitter で話題を呼んでいます。本記事では、ColBERT と ColBERTv2 の特徴を詳しく解説し、その革新的な設計と、検索に革命をもたらす後期相互作用機能について解説します。"><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-B2Y1PSBZ.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-CRvJtbiE.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-CwUSuUAa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-DwPdA5RU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-C_HC_Lmt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-ZSjEGKKY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-ClwWyqJW.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-BO10q7y8.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/ja-DczgoMr-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-KBCPks-8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-CgdZDzIe.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-DG8yFYsd.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-BSE4YQkX.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format-DyQxkAtJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-CWyYJIcM.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QToolbar-CAqxFInF.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-PUruQ3iq.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-NPc5qQka.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-CyyHwtkX.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-N3TlAgmM.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-BfYflfOA.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-DLNzyFrf.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-J434II7r.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-O6BTc0sj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding-CiD6efm5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-D9AIblGW.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-Cjo5ndza.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-CYexAS5Q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-D1GU209P.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-BMR_OewU.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-Dq__mwbf.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-BCvqlfgt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-Bv1iyJPA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-BJlrs7tc.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-B42SmHCz.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-CovHgG0a.css"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-q765RzAS.css"><meta name="author" content="Han Xiao"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Han Xiao"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="16 mins read"><meta property="article:published_time" content="2024-02-20T02:19:04.000+01:00"><meta property="article:modified_time" content="2024-08-30T23:11:22.000+02:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "ColBERT とは何か？Late Interaction とは何か？そして検索においてなぜ重要なのか？",
  "description": "Jina AI の ColBERT が Hugging Face でリリースされ、8192 トークンの処理能力を持つ新しい検索アプローチとして Twitter で話題を呼んでいます。本記事では、ColBERT と ColBERTv2 の特徴を詳しく解説し、その革新的な設計と、検索に革命をもたらす後期相互作用機能について解説します。",
  "image": [
    "https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png"
  ],
  "datePublished": "2024-02-20T02:19:04.000+01:00",
  "dateModified": "2024-08-30T23:11:22.000+02:00",
  "author": [
    {
      "@type": "Person",
      "name": "Han Xiao",
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><script charset="utf-8" src="https://platform.twitter.com/js/tweet.d7aeb21a88e025d2ea5f5431a103f586.js"></script><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">ニュース</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_33511915-e141-47c9-acb5-3f0f37bb7043" aria-label="「製品」を展開します。"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">製品</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_33511915-e141-47c9-acb5-3f0f37bb7043" style="display: none;"><div class="q-list q-list--dark" role="list" label="製品"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">ビジネスに力を与える</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ベクトルモデル</div><div class="q-item__label q-item__label--caption text-caption">世界クラスのマルチモーダル、多言語埋め込み。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">並べ替え者</div><div class="q-item__label q-item__label--caption text-caption">検索の関連性を最大化する世界クラスのニューラルレトリーバー。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">読者</div><div class="q-item__label q-item__label--caption text-caption">URL を読んで、より適切な基本的な LLM をオンラインで検索してください。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">分類子</div><div class="q-item__label q-item__label--caption text-caption">画像とテキストのゼロショットと少数ショットの分類。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">スライサー</div><div class="q-item__label q-item__label--caption text-caption">長いテキストをいくつかの塊に切り分けてマークアップします。</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">パワーユーザーに権限を与える</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">プレミアプロンプトワードツールボックス</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_3af69cae-7a0d-4c4e-a80a-d96e2174deda" aria-label="「より高度なユーザー ツール」を展開します。"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">より高度なユーザー ツール</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_3af69cae-7a0d-4c4e-a80a-d96e2174deda" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">最先端の画像・動画理解AI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">記事から直接イラストを生成し、プロンプトの言葉は必要ありません</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">より多くのモード、より長いメモリ、より低いコスト</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">LLM 支援のインテリジェントな意思決定ツール</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_af05e238-d29c-4b9b-a2ab-21c8602be72f" aria-label="「会社」を展開します。"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">会社</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_af05e238-d29c-4b9b-a2ab-21c8602be72f" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">私たちについて</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">営業担当者に問い合わせる</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">インターンプログラム</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">参加しませんか</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">ロゴをダウンロード</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">利用規約</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="ログイン"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div><div class="q-item__section column q-item__section--main justify-center">ログイン</div></a></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-33ef2eff="" class="q-page" style="min-height: 100vh;"><div data-v-33ef2eff="" class="row full-width relative-position justify-end"><div data-v-33ef2eff="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-33ef2eff="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">ColBERT とは何か？</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">ColBERT のデザインを理解する</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">ColBERT におけるクエリとドキュメントのエンコーダー</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">ColBERT を使用したトップ K ドキュメントの検索</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">ColBERT のインデックス戦略</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">ColBERT の有効性と効率性</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">jina-colbert-v1-en の使用：8192 長の ColBERTv2 モデル</div></div></div><div data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-33ef2eff="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-33ef2eff="" class="q-item__label">結論</div></div></div></div></div><div data-v-33ef2eff="" class="col-12 col-md-10 col-lg-12"><div data-v-33ef2eff="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">選択</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">技術記事</div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-33ef2eff="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">2月 20, 2024</div><h1 data-v-33ef2eff="" class="text-weight-medium text-center q-px-md my-title">ColBERT とは何か？Late Interaction とは何か？そして検索においてなぜ重要なのか？</h1><div data-v-33ef2eff="" class="col row justify-center"><div data-v-33ef2eff="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Jina AI の ColBERT が Hugging Face でリリースされ、8192 トークンの処理能力を持つ新しい検索アプローチとして Twitter で話題を呼んでいます。本記事では、ColBERT と ColBERTv2 の特徴を詳しく解説し、その革新的な設計と、検索に革命をもたらす後期相互作用機能について解説します。</div></div><div data-v-33ef2eff="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-33ef2eff="" class="q-img q-img--menu" role="img" aria-label="Neon theater or concert hall marquee letters lit up at night with city lights and faint &quot;Adobe Sto&quot; visible."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Neon theater or concert hall marquee letters lit up at night with city lights and faint &quot;Adobe Sto&quot; visible." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-33ef2eff="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-33ef2eff="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-33ef2eff="" class="q-item__label">Han Xiao • 16 数分間の読書</div></div></div></div><div data-v-33ef2eff="" class="row justify-center"><div data-v-33ef2eff="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-33ef2eff="" class="article"><section data-v-33ef2eff="" class="gh-content"><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina ColBERT v2：埋め込みとリランキングのための多言語レイトインタラクションリトリーバー</div><div class="kg-bookmark-description">Jina ColBERT v2 は 89 言語をサポートし、優れた検索性能、ユーザー制御可能な出力次元、8192 トークン長を提供します。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg" alt="" style="cursor: help;"></div></a><figcaption><p dir="ltr"><span style="white-space: pre-wrap;">更新：2024 年 8 月 31 日、Jina-ColBERT の第 2 版をリリースしました。性能が向上し、89 言語に対応した多言語サポートと柔軟な出力次元を実現しました。詳細はリリース記事をご確認ください。</span></p></figcaption></figure><p>先週金曜日、<a href="https://huggingface.co/jinaai/jina-colbert-v1-en">Hugging Face 上での Jina AI による ColBERT モデルのリリース</a>が、特に Twitter/X 上で AI コミュニティに大きな反響を呼びました。画期的な BERT モデルについては多くの人が知っていますが、ColBERT に関する話題は一部の人々に疑問を投げかけています：情報検索技術の混沌とした分野で ColBERT は何が特別なのでしょうか？なぜ AI コミュニティは 8192 長の ColBERT に興奮しているのでしょうか？この記事では、ColBERT と ColBERTv2 の詳細について、そのデザイン、改良点、そして ColBERT のレイトインタラクションの驚くべき効果を掘り下げていきます。</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/reranker"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Reranker API</div><div class="kg-bookmark-description">検索の関連性と RAG の精度を簡単に最大化</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina.ai/banner-reranker-api.png" alt="" style="cursor: help;"></div></a></figure><figure class="kg-card kg-embed-card"><div class="twitter-tweet twitter-tweet-rendered" style="display: flex; max-width: 550px; width: 100%; margin-top: 10px; margin-bottom: 10px;"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="" style="position: static; visibility: visible; width: 550px; height: 671px; display: block; flex-grow: 1;" title="X Post" src="https://platform.twitter.com/embed/Tweet.html?creatorScreenName=JinaAI_&amp;dnt=false&amp;embedId=twitter-widget-0&amp;features=eyJ0ZndfdGltZWxpbmVfbGlzdCI6eyJidWNrZXQiOltdLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2ZvbGxvd2VyX2NvdW50X3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9iYWNrZW5kIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19yZWZzcmNfc2Vzc2lvbiI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfZm9zbnJfc29mdF9pbnRlcnZlbnRpb25zX2VuYWJsZWQiOnsiYnVja2V0Ijoib24iLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X21peGVkX21lZGlhXzE1ODk3Ijp7ImJ1Y2tldCI6InRyZWF0bWVudCIsInZlcnNpb24iOm51bGx9LCJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3Nob3dfYmlyZHdhdGNoX3Bpdm90c19lbmFibGVkIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19kdXBsaWNhdGVfc2NyaWJlc190b19zZXR0aW5ncyI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfdXNlX3Byb2ZpbGVfaW1hZ2Vfc2hhcGVfZW5hYmxlZCI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfdmlkZW9faGxzX2R5bmFtaWNfbWFuaWZlc3RzXzE1MDgyIjp7ImJ1Y2tldCI6InRydWVfYml0cmF0ZSIsInZlcnNpb24iOm51bGx9LCJ0ZndfbGVnYWN5X3RpbWVsaW5lX3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9mcm9udGVuZCI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9fQ%3D%3D&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=1758503072999907825&amp;lang=ja&amp;origin=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F&amp;sessionId=b0c28883d14a85de65347d5924a339798c45e542&amp;siteScreenName=JinaAI_&amp;theme=light&amp;widgetsVersion=2615f7e52b7e0%3A1702314776716&amp;width=550px" data-tweet-id="1758503072999907825"></iframe></div>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><h2 id="what-is-colbert" style="position: relative;"><a href="#what-is-colbert" title="ColBERT とは何か？" id="anchor-what-is-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT とは何か？</h2><p>「ColBERT」という名称は、<strong>Co</strong>ntextualized <strong>L</strong>ate Interaction over <strong>BERT</strong>（BERT 上のコンテキスト化されたレイトインタラクション）の略で、スタンフォード大学から生まれたモデルです。BERT の深い言語理解を活用しながら、新しいインタラクションメカニズムを導入しています。「レイトインタラクション」として知られるこのメカニズムは、検索プロセスの最終段階までクエリとドキュメントを別々に処理することで、効率的で正確な検索を可能にします。具体的には、モデルには 2 つのバージョンがあります：</p><ul><li><strong>ColBERT</strong>：最初のモデルは、<a href="https://x.com/lateinteraction?s=20"><strong>Omar Khattab</strong></a><strong> と Matei Zaharia</strong> が考案したもので、「ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT」という論文で情報検索に対する新しいアプローチを提示しました。この研究は SIGIR 2020 で発表されました。</li></ul><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2004.12832"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ColBERT: BERT 上のコンテキスト化されたレイトインタラクションによる効率的で効果的な文章検索</div><div class="kg-bookmark-description">自然言語理解（NLU）の最近の進歩は、情報検索（IR）の急速な進展を促しています。これは主に、文書ランキングのための深層言語モデル（LM）のファインチューニングによるものです。これらの LM に基づくランキングモデルは驚くほど効果的ですが、単一の関連性スコアを計算するために各クエリ-文書ペアを巨大なニューラルネットワークに通す必要があるため、以前のアプローチと比べて計算コストが桁違いに増加します。これに対処するため、我々は ColBERT を提示します。これは効率的な検索のために深層 LM（特に BERT）を適応させた新しいランキングモデルです。ColBERT は、BERT を使用してクエリと文書を独立してエンコードし、その後、それらの細かい粒度の類似性をモデル化する安価だが強力なインタラクションステップを採用するレイトインタラクションアーキテクチャを導入します。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Omar Khattab</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a><figcaption><p><span style="white-space: pre-wrap;">「レイトインタラクション」を導入したオリジナルの ColBERT 論文。</span></p></figcaption></figure><ul><li><strong>ColBERTv2</strong>：基礎研究をベースに、<strong>Omar Khattab</strong> は <strong>Barlas Oguz、Matei Zaharia、Michael S. Bernstein</strong> と共同で「ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction」を SIGIR 2021 で発表しました。この ColBERT の次のイテレーションでは、前バージョンの制限に対処し、<strong>ノイズ除去された教師あり学習</strong>と<strong>残差圧縮</strong>という主要な改良を導入し、モデルの検索効果と保存効率の両方を向上させました。</li></ul><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2112.01488"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ColBERTv2：軽量なレイトインタラクションによる効果的で効率的な検索</div><div class="kg-bookmark-description">ニューラル情報検索（IR）は、検索や他の知識集約型言語タスクを大きく進展させました。多くのニューラル IR 手法がクエリとドキュメントを単一ベクトル表現にエンコードする一方で、レイトインタラクションモデルは各トークンの粒度で多ベクトル表現を生成し、関連性のモデリングをスケーラブルなトークンレベルの計算に分解します。この分解によりレイトインタラクションの効果が高まることが示されていますが、これらのモデルの空間フットプリントが 1 桁増加します。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Keshav Santhanam</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a><figcaption><p><span style="white-space: pre-wrap;">ColBERTv2 はノイズ除去された教師あり学習と残差圧縮を追加し、トレーニングデータの品質を向上させ、空間フットプリントを削減しました。</span></p></figcaption></figure><h2 id="understand-colberts-design" style="position: relative;"><a href="#understand-colberts-design" title="ColBERT のデザインを理解する" id="anchor-understand-colberts-design"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT のデザインを理解する</h2><p>ColBERTv2 のアーキテクチャは元の ColBERT と非常に似ており、主な革新はトレーニング技術と圧縮メカニズムに関するものであるため、まず元の ColBERT の基本的な側面について掘り下げていきましょう。</p><h3 id="what-is-late-interaction-in-colbert" style="position: relative;"><a href="#what-is-late-interaction-in-colbert" title="ColBERT のレイトインタラクションとは？" id="anchor-what-is-late-interaction-in-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT のレイトインタラクションとは？</h3><p>「インタラクション」とは、クエリとドキュメントの表現を比較することで関連性を評価するプロセスを指します。</p><p>「<em>レイトインタラクション</em>」は ColBERT の本質です。この用語は、クエリとドキュメントの表現が独立してエンコードされた後、プロセスの後半でインタラクションが発生するというモデルのアーキテクチャと処理戦略に由来します。これは「<em>アーリーインタラクション</em>」モデルと対照的で、アーリーインタラクションではクエリとドキュメントの埋め込みが早い段階で、通常モデルによるエンコード前または途中でインタラクションします。</p>

<table>
<thead>
<tr>
<th>Interaction Type</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Early Interaction</td>
<td>BERT, ANCE, DPR, Sentence-BERT, DRMM, KNRM, Conv-KNRM, etc.</td>
</tr>
<tr>
<td>Late Interaction</td>
<td>ColBERT, ColBERTv2</td>
</tr>
</tbody>
</table>

<p>アーリーインタラクションは、すべての可能なクエリ-ドキュメントペアを考慮する必要があるため計算の複雑さが増加し、大規模なアプリケーションには効率的ではありません。</p><p>ColBERT のようなレイトインタラクションモデルは、ドキュメント表現の事前計算を可能にし、最後により軽量なインタラクションステップを採用することで、効率性とスケーラビリティを最適化します。このインタラクションステップは、すでにエンコードされた表現に焦点を当てます。このデザインの選択により、検索時間が短縮され、計算要求が軽減され、大規模なドキュメントコレクションの処理により適したものとなっています。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/colbert-blog-interaction.svg" class="kg-image" alt="Diagram illustrating query-document similarity with models for no, partial, and late interaction, including language mode rep" width="300" height="143" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ニューラル IR におけるクエリ・ドキュメント間の相互作用パラダイムを示す概念図。左端が ColBERT の後期相互作用を表しています。</span></figcaption></figure><h3 id="no-interaction-cosine-similarity-of-document-and-query-embeddings" style="position: relative;"><a href="#no-interaction-cosine-similarity-of-document-and-query-embeddings" title="相互作用なし：ドキュメントとクエリの埋め込みのコサイン類似度" id="anchor-no-interaction-cosine-similarity-of-document-and-query-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>相互作用なし：ドキュメントとクエリの埋め込みのコサイン類似度</h3><p>多くの実用的なベクトルデータベースとニューラル検索ソリューションは、ドキュメントとクエリの埋め込み間の高速なコサイン類似度マッチングに依存しています。この方法は直感的で計算効率が良いという魅力がありますが、「相互作用なし」または「非相互作用ベース」と呼ばれ、クエリとドキュメント間の何らかの相互作用を組み込んだモデルと比較して性能が劣ることが分かっています。</p><p>「相互作用なし」アプローチの主な制限は、クエリとドキュメントの用語間の複雑なニュアンスや関係性を捉えられないことにあります。情報検索の本質は、クエリの背後にある意図とドキュメント内のコンテンツを理解しマッチングすることです。このプロセスには、関連する用語の深い文脈的理解が必要であり、ドキュメントとクエリの単一の集約された埋め込みではこれを提供することが困難です。</p><h2 id="query-and-document-encoders-in-colbert" style="position: relative;"><a href="#query-and-document-encoders-in-colbert" title="ColBERT におけるクエリとドキュメントのエンコーダー" id="anchor-query-and-document-encoders-in-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT におけるクエリとドキュメントのエンコーダー</h2><p>ColBERT のエンコーディング戦略は、言語の深い文脈理解で知られる BERT モデルに基づいています。このモデルは、クエリまたはドキュメント内の各トークンに対して密なベクトル表現を生成し、<strong>それぞれクエリとドキュメントの文脈化された埋め込みの集合を作成します。</strong>これにより、後期相互作用フェーズでの埋め込みの詳細な比較が可能になります。</p><h3 id="query-encoder-of-colbert" style="position: relative;"><a href="#query-encoder-of-colbert" title="ColBERT のクエリエンコーダー" id="anchor-query-encoder-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT のクエリエンコーダー</h3><p>トークン <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>q</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">{q_1, q_2, ..., q_l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span> を持つクエリ <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span> に対して、まず <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span> を BERT ベースの WordPiece トークンにトークン化し、特殊な <code>[Q]</code> トークンを先頭に追加します。この <code>[Q]</code> トークンは BERT の <code>[CLS]</code> トークンの直後に配置され、クエリの開始を示します。</p><p>クエリが事前定義された トークン数 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> より短い場合は <code>[mask]</code> トークンで <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> まで埋め込まれ、それ以外の場合は最初の <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> トークンまで切り捨てられます。埋め込まれたシーケンスは BERT に通され、その後 CNN（畳み込みニューラルネットワーク）と正規化を経て、以下の <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9722em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> として表される埋め込みベクトルのセットが出力されます：<br><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>q</mi></msub><mo>:</mo><mo>=</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">z</mi><mi mathvariant="normal">e</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo fence="true">(</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">Q</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>q</mi><mi>l</mi></msub><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_q := \mathrm{Normalize}\left(\mathrm{BERT}\left(\mathtt{[Q]},q_0,q_1,\ldots,q_l\mathtt{[mask]},\mathtt{[mask]},\ldots,\mathtt{[mask]}\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9722em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">Normalize</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">BERT</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">Q</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span></p><h3 id="document-encoder-of-colbert" style="position: relative;"><a href="#document-encoder-of-colbert" title="ColBERT のドキュメントエンコーダー" id="anchor-document-encoder-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT のドキュメントエンコーダー</h3><p>同様に、トークン <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>d</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{d_1, d_2, ..., d_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span> を持つドキュメント <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span></span></span></span></span> に対して、ドキュメントの開始を示す <code>[D]</code> トークンが先頭に追加されます。このシーケンスは、埋め込みの必要なく同じプロセスを経て、以下の <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8361em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> として表される埋め込みベクトルのセットが生成されます：<br><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>d</mi></msub><mo>:</mo><mo>=</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">z</mi><mi mathvariant="normal">e</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo fence="true">(</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">D</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><msub><mi>d</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>d</mi><mi>n</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_d := \mathrm{Filter}\left(\mathrm{Normalize}\left(\mathrm{BERT}\left(\mathtt{[D]},d_0,d_1,...,d_n\right)\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8361em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">Filter</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">Normalize</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">BERT</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">D</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span></p><p>クエリの埋め込みに <code>[mask]</code> トークンを使用すること（論文では<strong>クエリ拡張</strong>と呼ばれています）は、すべてのクエリで統一された長さを確保し、バッチ処理を容易にします。<code>[Q]</code> と <code>[D]</code> トークンは明示的にクエリとドキュメントの開始を示し、モデルがこれら2種類の入力を区別するのに役立ちます。</p><h3 id="comparing-colbert-to-cross-encoders" style="position: relative;"><a href="#comparing-colbert-to-cross-encoders" title="ColBERT とクロスエンコーダーの比較" id="anchor-comparing-colbert-to-cross-encoders"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT とクロスエンコーダーの比較</h3><p>クロスエンコーダーはクエリとドキュメントのペアを一緒に処理するため、非常に正確ですが、可能なすべてのペアを評価する計算コストが高いため、大規模なタスクには効率的ではありません。意味的類似性タスクや詳細なコンテンツ比較など、文ペアの正確なスコアリングが必要な特定のシナリオでは優れています。しかし、この設計は、事前計算された埋め込みと効率的な類似度計算が重要な、大規模データセットからの高速な検索が必要な状況での適用性を制限します。</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/ce-vs-colbert.svg" class="kg-image" alt="Diagrams comparing &quot;Cross Encoder: Early all-to-all interaction&quot; and &quot;ColBERT: Late interaction&quot; with labeled Query and Docum" width="210" height="150" style="cursor: help;"></figure><p>対照的に、ColBERT の後期相互作用モデルは、ドキュメント埋め込みの事前計算を可能にし、意味解析の深さを損なうことなく検索プロセスを大幅に高速化します。クロスエンコーダーの直接的なアプローチと比較すると一見直感に反するように見えるこの方法は、リアルタイムおよび大規模な情報検索タスクに対してスケーラブルなソリューションを提供します。これは、計算効率と相互作用モデリングの品質の間の戦略的な妥協を表しています。</p><h2 id="finding-the-top-k-documents-using-colbert" style="position: relative;"><a href="#finding-the-top-k-documents-using-colbert" title="ColBERT を使用したトップ K ドキュメントの検索" id="anchor-finding-the-top-k-documents-using-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT を使用したトップ K ドキュメントの検索</h2><p>クエリとドキュメントの埋め込みが得られれば、最も関連性の高いトップ K ドキュメントを見つけることは簡単になります（ただし、2つのベクトルのコサインを計算するほど簡単ではありません）。</p><p>主な操作には、用語ごとの類似度を計算するためのバッチ内積計算、ドキュメント用語間のmax-poolingによるクエリ用語ごとの最高類似度の検出、クエリ用語間の合計によるドキュメントの総スコアの導出、そしてこれらのスコアに基づくドキュメントのソートが含まれます。以下に擬似 PyTorch コードを示します：</p><pre><code class="language-python hljs"><span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_relevance_scores</span>(<span class="hljs-params">query_embeddings, document_embeddings, k</span>):
    <span class="hljs-string">"""
    Compute relevance scores for top-k documents given a query.
    
    :param query_embeddings: Tensor representing the query embeddings, shape: [num_query_terms, embedding_dim]
    :param document_embeddings: Tensor representing embeddings for k documents, shape: [k, max_doc_length, embedding_dim]
    :param k: Number of top documents to re-rank
    :return: Sorted document indices based on their relevance scores
    """</span>
    
    <span class="hljs-comment"># Ensure document_embeddings is a 3D tensor: [k, max_doc_length, embedding_dim]</span>
    <span class="hljs-comment"># Pad the k documents to their maximum length for batch operations</span>
    <span class="hljs-comment"># Note: Assuming document_embeddings is already padded and moved to GPU</span>
    
    <span class="hljs-comment"># Compute batch dot-product of Eq (query embeddings) and D (document embeddings)</span>
    <span class="hljs-comment"># Resulting shape: [k, num_query_terms, max_doc_length]</span>
    scores = torch.matmul(query_embeddings.unsqueeze(<span class="hljs-number">0</span>), document_embeddings.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
    
    <span class="hljs-comment"># Apply max-pooling across document terms (dim=2) to find the max similarity per query term</span>
    <span class="hljs-comment"># Shape after max-pool: [k, num_query_terms]</span>
    max_scores_per_query_term = scores.<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">2</span>).values
    
    <span class="hljs-comment"># Sum the scores across query terms to get the total score for each document</span>
    <span class="hljs-comment"># Shape after sum: [k]</span>
    total_scores = max_scores_per_query_term.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>)
    
    <span class="hljs-comment"># Sort the documents based on their total scores</span>
    sorted_indices = total_scores.argsort(descending=<span class="hljs-literal">True</span>)
    
    <span class="hljs-keyword">return</span> sorted_indices
</code></pre><p>この手順は、トレーニングと推論時の再ランク付けの両方で使用されることに注意してください。ColBERT モデルはペアワイズランキング損失を使用してトレーニングされ、トレーニングデータは <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(q, d^+, d^-)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.0213em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> の三つ組で構成されます。ここで、<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> はクエリ、<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">d^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> はクエリに関連する（ポジティブな）ドキュメント、<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">d^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span> は関連のない（ネガティブな）ドキュメントを表します。モデルは、<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> と <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">d^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> の間の類似度スコアが <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> と <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">d^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span> の間のスコアより高くなるような表現を学習することを目指します。</p><p>トレーニングの目的は、以下の損失関数を最小化することとして数学的に表現できます：<span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{Loss} = \max(0, 1 - S(q, d^+) + S(q, d^-))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord"><span class="mord mathrm">Loss</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0713em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8213em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0713em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8213em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span></span></p><p>ここで、<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(q, d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></span> は ColBERT によって計算されるクエリ <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> とドキュメント <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span> 間の類似度スコアを表します。このスコアは、モデルアーキテクチャで説明した後期相互作用パターンに従って、クエリとドキュメント間の最もマッチする埋め込みの最大類似度スコアを集約することで得られます。このアプローチにより、ポジティブとネガティブなドキュメントペアの類似度スコアの間でより大きなマージンを促すことで、モデルが与えられたクエリに対して関連するドキュメントと関連しないドキュメントを区別できるようにトレーニングされます。</p><h3 id="denoised-supervision-in-colbertv2" style="position: relative;"><a href="#denoised-supervision-in-colbertv2" title="ColBERTv2 のノイズ除去監督" id="anchor-denoised-supervision-in-colbertv2"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERTv2 のノイズ除去監督</h3><p>ColBERTv2 のノイズ除去監督は、チャレンジングなネガティブサンプルを選択し、クロスエンコーダーを使用した蒸留を活用することで、元のトレーニングプロセスを改良します。このトレーニングデータ品質を向上させる洗練された方法には、以下のステップが含まれます：</p><ol><li><strong>初期トレーニング</strong>：クエリ、関連ドキュメント、非関連ドキュメントで構成される MS MARCO データセットの公式三つ組を使用。</li><li><strong>インデックス作成と検索</strong>：ColBERTv2 の圧縮を使用してトレーニングパッセージのインデックスを作成し、各クエリに対してトップ k パッセージを検索。</li><li><strong>クロスエンコーダーによる再ランク付け</strong>：MiniLM クロスエンコーダーによる再ランク付けを通じてパッセージ選択を強化し、そのスコアを ColBERTv2 に蒸留。</li><li><strong>トレーニングタプルの形成</strong>：チャレンジングな例を作成するため、高ランクと低ランクの両方のパッセージを組み込んだ w-way タプルを生成。</li><li><strong>反復的な改良</strong>：ハードネガティブの選択を継続的に改善し、モデルの性能を向上させるためにプロセスを繰り返す。</li></ol><p>このプロセスは、ColBERT のトレーニング体制における洗練された改良を表しており、そのアーキテクチャの基本的な変更ではないことに注意してください。</p><h3 id="hyperparameters-of-colbert" style="position: relative;"><a href="#hyperparameters-of-colbert" title="ColBERT のハイパーパラメーター" id="anchor-hyperparameters-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT のハイパーパラメーター</h3><p>ColBERT のハイパーパラメータは以下のようにまとめられます：</p>

<table>
<thead>
<tr>
<th>ハイパーパラメータ</th>
<th>最適な選択</th>
<th>理由</th>
</tr>
</thead>
<tbody>
<tr>
<td>学習率</td>
<td>3 x 10^{-6}</td>
<td>安定的で効果的なモデルの更新を確保するためのファインチューニングに選択。</td>
</tr>
<tr>
<td>バッチサイズ</td>
<td>32</td>
<td>計算効率と更新ごとの十分な情報取得能力のバランスをとる。</td>
</tr>
<tr>
<td>クエリごとの埋め込み数 (Nq)</td>
<td>32</td>
<td>効率的な処理を支援するため、クエリ間で一貫した表現サイズを確保するように固定。</td>
</tr>
<tr>
<td>埋め込みの次元数 (m)</td>
<td>128</td>
<td>表現力と計算効率の良好なバランスを提供することが実証されている。</td>
</tr>
<tr>
<td>学習イテレーション</td>
<td>200k (MS MARCO), 125k (TREC CAR)</td>
<td>過学習を避けながら十分な学習を確保するために選択され、データセットの特性に基づいて調整。</td>
</tr>
<tr>
<td>埋め込みの次元あたりのバイト数</td>
<td>4 (再ランク付け), 2 (エンドツーエンドランキング)</td>
<td>アプリケーションのコンテキスト（再ランク付けvsエンドツーエンド）を考慮した精度と空間効率のトレードオフ。</td>
</tr>
<tr>
<td>ベクトル類似度関数</td>
<td>コサイン (再ランク付け), (二乗) L2 (エンドツーエンド)</td>
<td>それぞれの検索コンテキストにおけるパフォーマンスと効率性に基づいて選択。</td>
</tr>
<tr>
<td>FAISS インデックスパーティション (P)</td>
<td>2000</td>
<td>検索空間分割の粒度を決定し、検索効率に影響を与える。</td>
</tr>
<tr>
<td>検索する最近傍パーティション数 (p)</td>
<td>10</td>
<td>検索の広さと計算効率のバランスをとる。</td>
</tr>
<tr>
<td>埋め込みあたりのサブベクトル数 (s)</td>
<td>16</td>
<td>量子化の粒度に影響し、検索速度とメモリ使用量に影響を与える。</td>
</tr>
<tr>
<td>インデックスの次元あたりの表現</td>
<td>16 ビット値</td>
<td>エンドツーエンド検索の第二段階で、精度と空間のトレードオフを管理するために選択。</td>
</tr>
<tr>
<td>エンコーダーのレイヤー数</td>
<td>12 レイヤー BERT</td>
<td>文脈理解の深さと計算効率の最適なバランス。</td>
</tr>
<tr>
<td>最大クエリ長</td>
<td>128</td>
<td>クエリエンコーダーが処理するトークンの最大数。<b>これは Jina-ColBERT モデルで拡張される。</b></td>
</tr>
<tr>
<td>最大文書長</td>
<td>512</td>
<td>文書エンコーダーが処理するトークンの最大数。<b>これは Jina-ColBERT モデルで 8192 まで拡張される。</b></td>
</tr>
</tbody>
</table>

<h2 id="the-indexing-strategy-of-colbert" style="position: relative;"><a href="#the-indexing-strategy-of-colbert" title="ColBERT のインデックス戦略" id="anchor-the-indexing-strategy-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT のインデックス戦略</h2><p>各文書を 1 つの埋め込みベクトルにエンコードする表現ベースのアプローチとは異なり、<strong>ColBERT は文書（およびクエリ）を埋め込みの集合としてエンコードし、文書内の各トークンが独自の埋め込みを持ちます。</strong>このアプローチは本質的に、長い文書ではより多くの埋め込みが保存されることを意味し、<strong>これは元の ColBERT の問題点であり、後に ColBERTv2 で解決されました。</strong></p><p>これを効率的に管理するカギは、ColBERT がインデックス作成と検索に（<a href="https://github.com/facebookresearch/faiss">FAISS</a> などの）ベクトルデータベースを使用することと、大量のデータを効率的に処理できるように設計された詳細なインデックス作成プロセスにあります。元の ColBERT 論文では、インデックス作成と検索の効率を高めるためのいくつかの戦略が言及されています：</p><ul><li><strong>オフラインインデックス作成</strong>：文書の表現はオフラインで計算され、文書の埋め込みの事前計算と保存が可能です。このプロセスはバッチ処理と GPU アクセラレーションを活用して、大規模な文書コレクションを効率的に処理します。</li><li><strong>埋め込みストレージ</strong>：文書の埋め込みは各次元に 32 ビットまたは 16 ビット値を使用して保存でき、精度とストレージ要件のトレードオフを提供します。この柔軟性により、ColBERT は有効性（検索パフォーマンスの面で）と効率性（ストレージと計算コストの面で）のバランスを保つことができます。</li></ul><p>元の ColBERT には存在しなかった ColBERTv2 での<strong>残差圧縮</strong>の導入は、品質を維持しながらモデルの空間フットプリントを 6～10 倍削減する上で重要な役割を果たしています。この技術は、固定された参照セントロイドからの差分のみを効果的に捕捉して保存することで、埋め込みをさらに圧縮します。</p><h2 id="effectiveness-and-efficiency-of-colbert" style="position: relative;"><a href="#effectiveness-and-efficiency-of-colbert" title="ColBERT の有効性と効率性" id="anchor-effectiveness-and-efficiency-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT の有効性と効率性</h2><p>BERT の深い文脈理解を検索に組み込むことは、本質的に大きな計算リソースを必要とし、高いレイテンシーと計算コストのためにリアルタイムアプリケーションには実現性が低いと当初は考えられるかもしれません。しかし、ColBERT は後期相互作用メカニズムを革新的に使用することで、この仮定に挑戦し覆します。以下が注目すべきポイントです：</p><ol><li><strong>大幅な効率性の向上</strong>：ColBERT は従来の BERT ベースのランキングモデルと比較して、計算コスト（FLOP）とレイテンシーを桁違いに削減します。具体的には、特定のモデルサイズ（例：12 レイヤーの「base」トランスフォーマーエンコーダー）において、ColBERT は BERT ベースのモデルの有効性に匹敵し、場合によってはそれを上回りながら、大幅に低い計算要求で実現します。例えば、再ランク付けの深さ <em>k</em>=10 では、BERT は ColBERT の約 180 倍の FLOP を必要とします。この差は <em>k</em> が増加するにつれて広がり、<em>k</em>=1000 で 13900 倍、<em>k</em>=2000 で 23000 倍にまで達します。</li><li><strong>エンドツーエンド検索における Recall と MRR@10 の向上</strong>：高い検索パフォーマンスには（早期相互作用モデルに見られるような）クエリと文書表現のより深い相互作用が必要だという当初の直感に反して、ColBERT のエンドツーエンド検索セットアップは優れた有効性を示します。例えば、その Recall@50 は公式の BM25 の Recall@1000 とほぼすべての他のモデルの Recall@200 を上回り、各クエリ-文書ペアの直接比較なしに広大なコレクションから関連文書を検索する際のモデルの優れた能力を強調しています。</li><li><strong>実世界アプリケーションへの実用性</strong>：実験結果は ColBERT の実世界シナリオへの実用的な適用性を強調しています。そのインデックス作成スループットとメモリ効率により、MS MARCO のような大規模な文書コレクションを数時間以内にインデックス化でき、管理可能な空間フットプリントで高い有効性を維持します。これらの特質は、パフォーマンスと計算効率の両方が最重要である本番環境への展開に ColBERT が適していることを示しています。</li><li><strong>文書コレクションのサイズに対するスケーラビリティ</strong>：おそらく最も驚くべき結論は、大規模な文書コレクションを扱う際の ColBERT のスケーラビリティと効率性です。このアーキテクチャは文書埋め込みの事前計算を可能にし、クエリ-文書相互作用の効率的なバッチ処理を活用することで、文書コレクションのサイズに応じて効果的にスケールすることができます。このスケーラビリティは、効果的な文書検索に必要な理解の複雑さと深さを考えると直感に反するものであり、ColBERT の計算効率と検索効率のバランスを取る革新的なアプローチを示しています。</li></ol><h2 id="using-jina-colbert-v1-en-a-8192-length-colbertv2-model" style="position: relative;"><a href="#using-jina-colbert-v1-en-a-8192-length-colbertv2-model" title="jina-colbert-v1-en の使用：8192 長の ColBERTv2 モデル" id="anchor-using-jina-colbert-v1-en-a-8192-length-colbertv2-model"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><code>jina-colbert-v1-en</code> の使用：8192 長の ColBERTv2 モデル</h2><p>Jina-ColBERT は高速かつ正確な検索のために設計され、<a href="https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/">アーキテクチャの改良により長いシーケンス処理を可能にする JinaBERT の進歩を活用して、最大 8192 の長いコンテキスト長をサポート</a>します。</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">厳密に言えば、Jina-ColBERT は 8190 トークン長をサポートします。ColBERT の文書エンコーダーでは、各文書の先頭に <code spellcheck="false" style="white-space: pre-wrap;">[D],[CLS]</code> がパディングされることを思い出してください。</div></div><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-colbert-v1-en"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-colbert-v1-en · Hugging Face</div><div class="kg-bookmark-description">私たちはオープンソースとオープンサイエンスを通じて、人工知能を進歩させ民主化する旅の途中です。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-colbert-v1-en.png" alt="" style="cursor: help;"></div></a></figure><h3 id="jinas-improvement-over-original-colbert" style="position: relative;"><a href="#jinas-improvement-over-original-colbert" title="元の ColBERT に対する Jina の改良点" id="anchor-jinas-improvement-over-original-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>元の ColBERT に対する Jina の改良点</h3><p>Jina-ColBERT の主な進歩は、そのバックボーンである <code>jina-bert-v2-base-en</code> にあります。これは元の ColBERT が使用する <code>bert-base-uncased</code> と比較して、はるかに長いコンテキスト（最大 8192 トークン）の処理を可能にします。この能力は広範なコンテンツを持つ文書を扱い、より詳細でコンテキストに基づいた検索結果を提供する上で重要です。</p><h3 id="jina-colbert-v1-en-performance-comparison-vs-colbertv2" style="position: relative;"><a href="#jina-colbert-v1-en-performance-comparison-vs-colbertv2" title="jina-colbert-v1-en と ColBERTv2 のパフォーマンス比較" id="anchor-jina-colbert-v1-en-performance-comparison-vs-colbertv2"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><code>jina-colbert-v1-en</code> と ColBERTv2 のパフォーマンス比較</h3><p>私たちは <code>jina-colbert-v1-en</code> を BEIR データセットと長いコンテキストを重視する新しい LoCo ベンチマークで評価し、元の ColBERTv2 実装と非相互作用ベースの<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a> モデル。</p>

<table>
<thead>
<tr>
<th>Dataset</th>
<th>ColBERTv2</th>
<th>jina-colbert-v1-en</th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Arguana</td>
<td>46.5</td>
<td><strong>49.4</strong></td>
<td>44.0</td>
</tr>
<tr>
<td>Climate-Fever</td>
<td>18.1</td>
<td>19.6</td>
<td><strong>23.5</strong></td>
</tr>
<tr>
<td>DBPedia</td>
<td><strong>45.2</strong></td>
<td>41.3</td>
<td>35.1</td>
</tr>
<tr>
<td>FEVER</td>
<td>78.8</td>
<td><strong>79.5</strong></td>
<td>72.3</td>
</tr>
<tr>
<td>FiQA</td>
<td>35.4</td>
<td>36.8</td>
<td><strong>41.6</strong></td>
</tr>
<tr>
<td>HotpotQA</td>
<td><strong>67.5</strong></td>
<td>65.9</td>
<td>61.4</td>
</tr>
<tr>
<td>NFCorpus</td>
<td>33.7</td>
<td><strong>33.8</strong></td>
<td>32.5</td>
</tr>
<tr>
<td>NQ</td>
<td>56.1</td>
<td>54.9</td>
<td><strong>60.4</strong></td>
</tr>
<tr>
<td>Quora</td>
<td>85.5</td>
<td>82.3</td>
<td><strong>88.2</strong></td>
</tr>
<tr>
<td>SCIDOCS</td>
<td>15.4</td>
<td>16.9</td>
<td><strong>19.9</strong></td>
</tr>
<tr>
<td>SciFact</td>
<td>68.9</td>
<td><strong>70.1</strong></td>
<td>66.7</td>
</tr>
<tr>
<td>TREC-COVID</td>
<td>72.6</td>
<td><strong>75.0</strong></td>
<td>65.9</td>
</tr>
<tr>
<td>Webis-touch2020</td>
<td>26.0</td>
<td><strong>27.0</strong></td>
<td>26.2</td>
</tr>
<tr>
<td>LoCo</td>
<td>74.3</td>
<td>83.7</td>
<td><strong>85.4</strong></td>
</tr>
<tr>
<td>Average</td>
<td>51.7</td>
<td><strong>52.6</strong></td>
<td>51.6</td>
</tr>
</tbody>
</table>

<p>この表は、特に長いコンテキスト長を必要とするシナリオにおいて、オリジナルの ColBERTv2 と比較して <code>jina-colbert-v1-en</code> の優れたパフォーマンスを示しています。なお、<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a> は<a href="https://arxiv.org/abs/2310.19923">より多くのトレーニングデータを使用</a>していますが、<code>jina-colbert-v1-en</code> は MSMARCO のみを使用しており、これが一部のタスクにおける <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a> の良好なパフォーマンスを説明する可能性があります。</p><h3 id="example-usage-of-jina-colbert-v1-en" style="position: relative;"><a href="#example-usage-of-jina-colbert-v1-en" title="jina-colbert-v1-en の使用例" id="anchor-example-usage-of-jina-colbert-v1-en"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><code>jina-colbert-v1-en</code> の使用例</h3><p>このスニペットは、長文書のサポートを示す Jina-ColBERT でのインデックス作成プロセスを概説しています。</p><pre><code class="language-python hljs"><span class="hljs-keyword">from</span> colbert <span class="hljs-keyword">import</span> Indexer
<span class="hljs-keyword">from</span> colbert.infra <span class="hljs-keyword">import</span> Run, RunConfig, ColBERTConfig

n_gpu: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>  <span class="hljs-comment"># Set your number of available GPUs</span>
experiment: <span class="hljs-built_in">str</span> = <span class="hljs-string">""</span>  <span class="hljs-comment"># Name of the folder where the logs and created indices will be stored</span>
index_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">""</span>  <span class="hljs-comment"># The name of your index, i.e. the name of your vector database</span>

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-keyword">with</span> Run().context(RunConfig(nranks=n_gpu, experiment=experiment)):
        config = ColBERTConfig(
          doc_maxlen=<span class="hljs-number">8192</span>  <span class="hljs-comment"># Our model supports 8k context length for indexing long documents</span>
        )
        indexer = Indexer(
          checkpoint=<span class="hljs-string">"jinaai/jina-colbert-v1-en"</span>,
          config=config,
        )
        documents = [
          <span class="hljs-string">"ColBERT is an efficient and effective passage retrieval model."</span>,
          <span class="hljs-string">"Jina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length."</span>,
          <span class="hljs-string">"JinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length."</span>,
          <span class="hljs-string">"Jina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2."</span>,
          <span class="hljs-string">"Jina-ColBERT achieves the competitive retrieval performance with ColBERTv2."</span>,
          <span class="hljs-string">"Jina is an easier way to build neural search systems."</span>,
          <span class="hljs-string">"You can use Jina-ColBERT to build neural search systems with ease."</span>,
          <span class="hljs-comment"># Add more documents here to ensure the clustering work correctly</span>
        ]
        indexer.index(name=index_name, collection=documents)
</code></pre><h3 id="use-jina-colbert-v1-en-in-ragatouille" style="position: relative;"><a href="#use-jina-colbert-v1-en-in-ragatouille" title="RAGatouille での jina-colbert-v1-en の使用" id="anchor-use-jina-colbert-v1-en-in-ragatouille"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>RAGatouille での <code>jina-colbert-v1-en</code> の使用</h3><p>RAGatouille は、RAG パイプライン内で高度な検索方法の使用を容易にする新しい Python ライブラリです。モジュール性と容易な統合のために設計されており、ユーザーが最先端の研究をシームレスに活用することを可能にします。RAGatouille の主な目的は、ColBERT のような複雑なモデルを RAG パイプラインで適用することを簡素化し、開発者が基礎となる研究について深い専門知識を必要とせずにこれらの手法を利用できるようにすることです。<a href="https://twitter.com/bclavie">Benjamin Clavié</a> のおかげで、<code>jina-colbert-v1-en</code> を簡単に使用できるようになりました：</p><pre><code class="language-python hljs"><span class="hljs-keyword">from</span> ragatouille <span class="hljs-keyword">import</span> RAGPretrainedModel

<span class="hljs-comment"># Get your model &amp; collection of big documents ready</span>
RAG = RAGPretrainedModel.from_pretrained(<span class="hljs-string">"jinaai/jina-colbert-v1-en"</span>)
my_documents = [
    <span class="hljs-string">"very long document1"</span>,
    <span class="hljs-string">"very long document2"</span>,
    <span class="hljs-comment"># ... more documents</span>
]

<span class="hljs-comment"># And create an index with them at full length!</span>
RAG.index(collection=my_documents,
          index_name=<span class="hljs-string">"the_biggest_index"</span>,
          max_document_length=<span class="hljs-number">8190</span>,)

<span class="hljs-comment"># or encode them in-memory with no truncation, up to your model's max length</span>
RAG.encode(my_documents)
</code></pre><p>Jina-ColBERT に関する詳細な情報と更なる探求については、<a href="https://huggingface.co/jinaai/jina-colbert-v1-en">Hugging Face のページ</a>をご覧ください。</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="結論" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>結論</h2><p>ColBERT は情報検索の分野において大きな飛躍を表しています。Jina-ColBERT による長いコンテキスト長の実現と、ColBERT の後期相互作用アプローチとの互換性を維持することで、最先端の検索機能を実装しようとする開発者にとって強力な選択肢を提供しています。</p><p>複雑な検索モデルを RAG パイプラインに統合することを簡素化する RAGatouille ライブラリと組み合わせることで、開発者は今や高度な検索の力を容易に活用でき、ワークフローを効率化し、アプリケーションを強化することができます。Jina-ColBERT と RAGatouille の相乗効果は、高度な AI 検索モデルを実用的な使用のためにアクセスしやすく、効率的にする上で注目すべき進歩を示しています。</p></section></article><div data-v-33ef2eff="" class="row justify-between items-center q-py-md"><div data-v-33ef2eff=""><span data-v-33ef2eff="" class="text-weight-bold">カテゴリー:</span><span data-v-33ef2eff="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">選択</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">技術記事</div></div></div></span></div><div data-v-33ef2eff=""><div data-v-33ef2eff="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-33ef2eff="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fja%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-33ef2eff="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-33ef2eff="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-33ef2eff="" class="text-h5 q-my-xl">もっとニュース</div><a data-v-1f724e3b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/scaling-test-time-compute-for-embedding-models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1f724e3b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-1f724e3b="" class="q-focus-helper"></span><div data-v-1f724e3b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-1f724e3b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__label q-item__label--caption text-caption">12月 12, 2024 • 11 数分間の読書</div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__section column q-item__section--main justify-center"><div data-v-1f724e3b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Scaling Test-Time Compute For Embedding Models</div></div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-1f724e3b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-1f724e3b="" class="col-4 overflow-hidden"><div data-v-1f724e3b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="David Hockney artwork of a hand holding a rod with three colored spheres on a blue-toned background."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="David Hockney artwork of a hand holding a rod with three colored spheres on a blue-toned background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/test-time-compute.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-1f724e3b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/still-need-chunking-when-long-context-models-can-do-it-all"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1f724e3b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-1f724e3b="" class="q-focus-helper"></span><div data-v-1f724e3b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-1f724e3b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__label q-item__label--caption text-caption">12月 04, 2024 • 13 数分間の読書</div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__section column q-item__section--main justify-center"><div data-v-1f724e3b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Still Need Chunking When Long-Context Models Can Do It All?</div></div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-1f724e3b="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Michael Günther"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Michael Günther" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-1f724e3b="" class="col-4 overflow-hidden"><div data-v-1f724e3b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Artistic pixel art of two seagulls on colored pipes with speech bubbles; one reads &quot;Too long?&quot; and the other shows math equat"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Artistic pixel art of two seagulls on colored pipes with speech bubbles; one reads &quot;Too long?&quot; and the other shows math equat" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-1f724e3b="" data-v-33ef2eff="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/watermarking-text-with-embedding-models-to-protect-against-content-theft"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1f724e3b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-1f724e3b="" class="q-focus-helper"></span><div data-v-1f724e3b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-1f724e3b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__label q-item__label--caption text-caption">11月 27, 2024 • 10 数分間の読書</div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-1f724e3b="" class="q-item__section column q-item__section--main justify-center"><div data-v-1f724e3b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Watermarking Text with Embedding Models to Protect Against Content Theft</div></div></div><div data-v-1f724e3b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-1f724e3b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-1f724e3b="" class="col-4 overflow-hidden"><div data-v-1f724e3b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/banner--1-.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">オフィス</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">カリフォルニア州サニーベール</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr、Ste 200、サニーベール、CA 94085、アメリカ合衆国</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ドイツ、ベルリン（本社）</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20、10969 ベルリン、ドイツ</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">中国、北京</div><div class="q-item__label q-item__label--caption text-caption text-dim">中国北京市海淀区西街48号ビル6号5階</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">深セン、中国</div><div class="q-item__label q-item__label--caption text-caption text-dim">ルーム 402、4 階、福安テクノロジービル、深セン、中国</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">検索ベース</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">ベクトルモデル</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">並べ替え者</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">読者</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">分類子</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">スライサー</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Jina AI API キーを取得する</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">レート制限</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">APIステータス</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">会社</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">私たちについて</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">営業担当者に問い合わせる</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">ニュース</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">インターンプログラム</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">参加しませんか</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">ロゴをダウンロード</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">条項</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/COMMERCIAL-LICENSE-TERMS.pdf" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">商用ライセンス</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#security"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">安全性</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">利用規約</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">プライバシー</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Cookieを管理する</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-between q-gutter-x-sm col-12 col-md"><label class="q-field row no-wrap items-start q-field--outlined q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dense q-field--dark text-caption" for="f_f1ef27c0-d604-4fd8-9c51-f0ca8c96a2a7"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-symbols material-symbols-sharp q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_f1ef27c0-d604-4fd8-9c51-f0ca8c96a2a7" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_f1ef27c0-d604-4fd8-9c51-f0ca8c96a2a7_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">arrow_drop_down</i></div></div></div></label><div class="text-caption text-dim"> Jina AI © 2020-2024. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div><script src="https://platform.twitter.com/widgets.js"></script><iframe scrolling="no" frameborder="0" allowtransparency="true" src="https://platform.twitter.com/widgets/widget_iframe.2f70fb173b9000da126c79afe2098f02.html?origin=http%3A%2F%2F127.0.0.1%3A3000" title="Twitter settings iframe" style="display: none;"></iframe><iframe id="rufous-sandbox" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;" title="Twitter analytics iframe"></iframe></body></html>