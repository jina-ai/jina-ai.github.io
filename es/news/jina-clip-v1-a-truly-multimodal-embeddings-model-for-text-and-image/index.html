<!DOCTYPE html><html translate="no" dir="ltr" lang="es"><head><title>Jina CLIP v1: Un modelo de embeddings verdaderamente multimodal para texto e imagen</title><meta charset="utf-8"><meta name="title" content="Jina CLIP v1: Un modelo de embeddings verdaderamente multimodal para texto e imagen"><meta name="description" content="El nuevo modelo de embedding multimodal de Jina AI no solo supera a OpenAI CLIP en la recuperación de texto e imágenes, sino que es a la vez un sólido modelo de embedding de imágenes y un modelo de embedding de texto de última generación. Ya no necesitas diferentes modelos para diferentes modalidades."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image"><meta property="og:title" content="Jina CLIP v1: Un modelo de embeddings verdaderamente multimodal para texto e imagen"><meta property="og:description" content="El nuevo modelo de embedding multimodal de Jina AI no solo supera a OpenAI CLIP en la recuperación de texto e imágenes, sino que es a la vez un sólido modelo de embedding de imágenes y un modelo de embedding de texto de última generación. Ya no necesitas diferentes modelos para diferentes modalidades."><meta property="og:image" content="https://jina.ai/blog-banner/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image"><meta property="twitter:title" content="Jina CLIP v1: Un modelo de embeddings verdaderamente multimodal para texto e imagen"><meta property="twitter:description" content="El nuevo modelo de embedding multimodal de Jina AI no solo supera a OpenAI CLIP en la recuperación de texto e imágenes, sino que es a la vez un sólido modelo de embedding de imágenes y un modelo de embedding de texto de última generación. Ya no necesitas diferentes modelos para diferentes modalidades."><meta property="twitter:image" content="https://jina.ai/blog-banner/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-Bv8a5Ls7.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-Db0tgwFK.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-DdYkWD5R.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-CCUp7m4r.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-CJOlhG0t.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-D1uXfgZq.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-tkY6H7Vt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-DebAzTyi.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/es-DJJjFCSD.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-CjNZEMVl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-Bnsw09_N.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-DLVxLdBb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-B-lbgLa2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-C4SRgzKM.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-bujT2Ufd.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-DiLWt5g-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-BjN2t6iL.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-CFAJnZIL.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-B1LxVXYi.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-DQFG2yV-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-4Yppf7Tw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-B01Zry2_.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-DTV86IbG.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-Bii_K2lz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-BEcOsb0h.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-CShJUoq2.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-DVL_Bysw.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-DBnv_jvA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-QWt5Y8ND.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-Dr-VBP79.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-CNkguZ1E.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-BYTI5OqV.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-CWRcc1oK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-q0BpjUsx.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-BbNyqty1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BsmwR4W2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-_oUdl35j.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-Bd3HTBm0.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-bdkmtkGn.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-vSZoRHSY.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Sofia Vasileva, Scott Martens, Susana Guzmán"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Sofia Vasileva, Scott Martens, Susana Guzmán"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="8 mins read"><meta property="article:published_time" content="2024-06-05T11:42:02.000+02:00"><meta property="article:modified_time" content="2024-07-08T21:08:30.000+02:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Jina CLIP v1: Un modelo de embeddings verdaderamente multimodal para texto e imagen",
  "description": "El nuevo modelo de embedding multimodal de Jina AI no solo supera a OpenAI CLIP en la recuperación de texto e imágenes, sino que es a la vez un sólido modelo de embedding de imágenes y un modelo de embedding de texto de última generación. Ya no necesitas diferentes modelos para diferentes modalidades.",
  "image": [
    "https://jina.ai/blog-banner/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image.webp"
  ],
  "datePublished": "2024-06-05T11:42:02.000+02:00",
  "dateModified": "2024-07-08T21:08:30.000+02:00",
  "author": [
    {
      "@type": "Person",
      "name": "Sofia Vasileva",
      "url": "https://jina-ai-gmbh.ghost.io/author/sofia/"
    },
    {
      "@type": "Person",
      "name": "Scott Martens",
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    },
    {
      "@type": "Person",
      "name": "Susana Guzmán",
      "url": "https://jina-ai-gmbh.ghost.io/author/susana/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-a926e642="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-a926e642="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-a926e642="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-a926e642="" class="q-space"></div><button data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-a926e642="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-a926e642="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-a926e642="" class="q-list q-list--dark" role="list"><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Noticias</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Modelos</div></a><div data-v-a926e642="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_8faf979e-62c9-48c4-a74d-dbdc0f5935ed" aria-label="Expandir &quot;Productos&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Productos</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_8faf979e-62c9-48c4-a74d-dbdc0f5935ed" style="display: none;"><div data-v-a926e642="" class="q-list q-list--dark" role="list" label="Productos"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Búsqueda profunda</div><div class="q-item__label q-item__label--caption text-caption">Busca, lee y razona hasta encontrar la mejor respuesta.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lector</div><div class="q-item__label q-item__label--caption text-caption">Lea las URL y busque en la web para obtener una base más sólida para su LLM.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Incrustaciones</div><div class="q-item__label q-item__label--caption text-caption">Integraciones multilingües y multimodales de clase mundial.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">reclasificador</div><div class="q-item__label q-item__label--caption text-caption">Recuperador neuronal de clase mundial para maximizar la relevancia de la búsqueda.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_b9407ae6-e42c-44c8-9ad4-f633e45568dd" aria-label="Expandir &quot;Más&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Más</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_b9407ae6-e42c-44c8-9ad4-f633e45568dd" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Clasificador</div><div class="q-item__label q-item__label--caption text-caption">Clasificación de cero disparos y pocos disparos para imágenes y texto.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmentador</div><div class="q-item__label q-item__label--caption text-caption">Corta el texto largo en fragmentos y haz tokenización.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Documentación de la API</div><div class="q-item__label q-item__label--caption text-caption">Generación automática de código para su IDE o LLM de Copilot</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-a926e642="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_36bad615-48f4-4bd1-9742-37fcc1dfd3ca" aria-label="Expandir &quot;Compañía&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Compañía</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_36bad615-48f4-4bd1-9742-37fcc1dfd3ca" style="display: none;"><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Sobre nosotros</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Contactar con ventas</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Programa de prácticas</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Únete a nosotros</div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Descargar logotipo</div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Términos y condiciones</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Acceso"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Acceso</div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-a926e642="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_a0c7e433-f110-4817-bdf5-b36e2d17b277"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_a0c7e433-f110-4817-bdf5-b36e2d17b277" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_a0c7e433-f110-4817-bdf5-b36e2d17b277_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-a926e642="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">La Arquitectura CLIP para IA Multimodal</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Presentando Jina CLIP v1</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Nuevo Estado del Arte en Embeddings Multimodales</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Comenzando con la API de Embeddings</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Jina CLIP v1 de Código Abierto en Hugging Face</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Resumen</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Presentado</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">presione soltar</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">junio 05, 2024</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">Jina CLIP v1: Un modelo de embeddings verdaderamente multimodal para texto e imagen</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">El nuevo modelo de embedding multimodal de Jina AI no solo supera a OpenAI CLIP en la recuperación de texto e imágenes, sino que es a la vez un sólido modelo de embedding de imágenes y un modelo de embedding de texto de última generación. Ya no necesitas diferentes modelos para diferentes modalidades.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img" aria-label="Abstract 3D render of a neon blue and green grid pattern on a black background, creating a sense of depth."><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract 3D render of a neon blue and green grid pattern on a black background, creating a sense of depth." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/--.jpg" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 68px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Sofia Vasileva"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Sofia Vasileva" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/sofia-profile-pic.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Scott Martens"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Scott Martens" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 36px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Susana Guzmán"><div style="padding-bottom: 66.6875%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Susana Guzmán" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/04/WhatsApp-Image-2022-12-06-at-15.46.39.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Sofia Vasileva, Scott Martens, Susana Guzmán • 8 minutos de lectura</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><p>Jina CLIP v1 (<a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>) es un nuevo modelo de embedding multimodal que extiende las capacidades del <a href="https://openai.com/index/clip/">modelo CLIP original</a> de OpenAI. Con este nuevo modelo, los usuarios tienen un único modelo de embedding que ofrece un rendimiento de última generación tanto en la recuperación de solo texto como en la recuperación multimodal texto-imagen. Jina AI ha mejorado el rendimiento de OpenAI CLIP en un 165% en la recuperación de solo texto y en un 12% en la recuperación de imagen a imagen, con un rendimiento idéntico o levemente mejor en las tareas de texto a imagen e imagen a texto. Este rendimiento mejorado hace que Jina CLIP v1 sea indispensable para trabajar con entradas multimodales.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text"><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> mejora OpenAI CLIP en <a href="#compare_table" rel="noreferrer">todas las categorías de recuperación</a>.</div></div><p>En este artículo, primero discutiremos las limitaciones del modelo CLIP original y cómo las hemos abordado usando un método único de co-entrenamiento. Luego, demostraremos la efectividad de nuestro modelo en varios benchmarks de recuperación. Finalmente, proporcionaremos instrucciones detalladas sobre cómo los usuarios pueden comenzar con Jina CLIP v1 a través de nuestra API de Embeddings y Hugging Face.</p><h2 id="the-clip-architecture-for-multimodal-ai" style="position: relative;"><a href="#the-clip-architecture-for-multimodal-ai" title="La Arquitectura CLIP para IA Multimodal" id="anchor-the-clip-architecture-for-multimodal-ai"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>La Arquitectura CLIP para IA Multimodal</h2><p>En enero de 2021, OpenAI lanzó el modelo <a href="https://openai.com/index/clip/">CLIP</a> (Contrastive Language–Image Pretraining). CLIP tiene una arquitectura sencilla pero ingeniosa: combina dos modelos de embedding, uno para textos y otro para imágenes, en un único modelo con un único espacio de embedding de salida. Sus embeddings de texto e imagen son directamente comparables entre sí, haciendo que la distancia entre un embedding de texto y uno de imagen sea proporcional a qué tan bien ese texto describe la imagen, y viceversa.</p><p>Esto ha demostrado ser muy útil en la recuperación de información multimodal y en la clasificación de imágenes zero-shot. Sin entrenamiento especial adicional, CLIP tuvo un buen desempeño al colocar imágenes en categorías con etiquetas en lenguaje natural.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/180-1.jpg" class="kg-image" alt="Diagram illustrating image to text translation using an astronaut on Mars with a red moon as an example." width="1600" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/180-1.jpg 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/180-1.jpg 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/180-1.jpg 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>El modelo de embedding de texto en el CLIP original era una red neuronal personalizada con solo 63 millones de parámetros. En el lado de la imagen, OpenAI lanzó CLIP con una selección de modelos <a href="https://huggingface.co/docs/transformers/model_doc/resnet" rel="noopener noreferrer">ResNet</a> y <a href="https://huggingface.co/docs/transformers/en/model_doc/vit" rel="noopener noreferrer">ViT</a>. Cada modelo fue pre-entrenado para su modalidad individual y luego entrenado con imágenes con subtítulos para producir embeddings similares para pares preparados de imagen-texto.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/Blog-images--1-.png" class="kg-image" alt="Flowchart with text &quot;Embedding Space&quot;, linked to &quot;Image Encoder&quot; and &quot;Text Encoder&quot;, with a &quot;Distracted boyfriend&quot; label." width="1600" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/Blog-images--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/Blog-images--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/Blog-images--1-.png 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Este enfoque produjo resultados impresionantes. Particularmente notable es su rendimiento en clasificación zero-shot. Por ejemplo, aunque los datos de entrenamiento no incluían imágenes etiquetadas de <a href="https://docs.vultr.com/zero-shot-image-classification-using-openai-clip">astronautas</a>, CLIP podía identificar correctamente imágenes de astronautas basándose en su comprensión de conceptos relacionados en textos e imágenes.</p><p>Sin embargo, CLIP de OpenAI tiene dos importantes desventajas:</p><ul><li>La primera es su capacidad muy limitada de entrada de texto. Puede tomar un máximo de 77 tokens de entrada, pero el <a href="https://arxiv.org/abs/2403.15378">análisis empírico muestra</a> que en la práctica no usa más de 20 tokens para producir sus embeddings. Esto es porque CLIP fue entrenado con imágenes con subtítulos, y los subtítulos tienden a ser muy cortos. Esto contrasta con los modelos actuales de embedding de texto que soportan varios miles de tokens.</li><li>Segundo, el rendimiento de sus embeddings de texto en escenarios de recuperación de solo texto es muy pobre. Los subtítulos de imágenes son un tipo muy limitado de texto y no reflejan la amplia gama de casos de uso que se esperaría que un modelo de embedding de texto soporte.</li></ul><p>En la mayoría de los casos de uso reales, la recuperación de solo texto y texto-imagen se combinan o al menos ambos están disponibles para las tareas. Mantener un segundo modelo de embeddings para tareas de solo texto efectivamente duplica el tamaño y la complejidad de tu marco de IA.</p><p>El nuevo modelo de Jina AI aborda estos problemas directamente, y <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> aprovecha el progreso realizado en los últimos años para proporcionar un rendimiento de última generación en tareas que involucran todas las combinaciones de modalidades de texto e imagen.</p><h2 id="introducing-jina-clip-v1" style="position: relative;"><a href="#introducing-jina-clip-v1" title="Presentando Jina CLIP v1" id="anchor-introducing-jina-clip-v1"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Presentando Jina CLIP v1</h2><p>Jina CLIP v1 mantiene el esquema original de OpenAI CLIP: dos modelos co-entrenados para producir salidas en el mismo espacio de embedding.</p><p>Para la codificación de texto, adaptamos la arquitectura <a href="https://jina.ai/news/jina-embeddings-2-the-best-solution-for-embedding-long-documents/">Jina BERT v2</a> utilizada en los <a href="https://jina.ai/embeddings/">modelos Jina Embeddings v2</a>. Esta arquitectura soporta una ventana de entrada de 8k tokens de última generación y produce vectores de 768 dimensiones, generando embeddings más precisos a partir de textos más largos. Esto es más de 100 veces los 77 tokens de entrada soportados en el modelo CLIP original.</p><p>Para los embeddings de imágenes, estamos usando el último modelo de la Academia de Inteligencia Artificial de Beijing: el modelo <a href="https://github.com/baaivision/EVA/tree/master/EVA-02"><code>EVA-02</code></a>. Hemos comparado empíricamente varios modelos de IA de imágenes, probándolos en contextos multimodales con pre-entrenamiento similar, y <code>EVA-02</code> superó claramente a los demás. También es comparable a la arquitectura Jina BERT en tamaño de modelo, por lo que las cargas de cómputo para tareas de procesamiento de imagen y texto son aproximadamente idénticas.</p><p>Estas elecciones producen beneficios importantes para los usuarios:</p><ul><li>Mejor rendimiento en todos los benchmarks y todas las combinaciones modales, y especialmente grandes mejoras en el rendimiento de embedding de solo texto.</li><li>El rendimiento empíricamente superior de <code>EVA-02</code> tanto en tareas de imagen-texto como de solo imagen, con el beneficio adicional del entrenamiento adicional de Jina AI, mejorando el rendimiento de solo imagen.</li><li>Soporte para entradas de texto mucho más largas. El soporte de entrada de <a href="https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/">8k tokens de Jina Embeddings</a> hace posible procesar información textual detallada y correlacionarla con imágenes.</li><li>Un gran ahorro neto en espacio, cómputo, mantenimiento de código y complejidad porque este modelo multimodal es altamente eficiente incluso en escenarios no multimodales.</li></ul><h3 id="training" style="position: relative;"><a href="#training" title="Entrenamiento" id="anchor-training"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Entrenamiento</h3><p>Parte de nuestra receta para una IA multimodal de alto rendimiento son nuestros datos y procedimiento de entrenamiento. Notamos que la longitud muy corta de los textos utilizados en los subtítulos de imágenes es la causa principal del pobre rendimiento de solo texto en los modelos tipo CLIP, y nuestro entrenamiento está explícitamente diseñado para remediar esto.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/dark-1.png" class="kg-image" alt="Flowchart illustrating optimization of text and caption-image similarity in three tasks, using a model and encoders, ending i" width="1600" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/06/dark-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/06/dark-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/06/dark-1.png 1600w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>El entrenamiento se realiza en tres pasos:</p><ol><li>Usar datos de imágenes con subtítulos para aprender a alinear embeddings de imagen y texto, intercalados con pares de texto con significados similares. Este co-entrenamiento optimiza conjuntamente para los dos tipos de tareas. El rendimiento de solo texto del modelo disminuye durante esta fase, pero no tanto como si hubiéramos entrenado solo con pares de imagen-texto.</li><li>Entrenar usando datos sintéticos que alinean imágenes con textos más largos, generados por un modelo de IA, que describe la imagen. Continuar entrenando con pares de solo texto al mismo tiempo. Durante esta fase, el modelo aprende a atender textos más largos en conjunto con imágenes.</li><li>Usar tripletes de texto con <a href="https://finetuner.jina.ai/advanced-topics/negative-mining/" rel="noreferrer">negativos difíciles</a> para mejorar aún más el rendimiento de solo texto aprendiendo a hacer distinciones semánticas más finas. Al mismo tiempo, continuar entrenando usando pares sintéticos de imágenes y textos largos. Durante esta fase, el rendimiento de solo texto mejora dramáticamente sin que el modelo pierda ninguna capacidad de imagen-texto.</li></ol><p>Para más información sobre los detalles del entrenamiento y la arquitectura del modelo, por favor lee <a href="https://arxiv.org/abs/2405.20204">nuestro artículo reciente</a>:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2405.20204"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class="kg-bookmark-description">El Preentrenamiento Contrastivo de Lenguaje-Imagen (CLIP) se utiliza ampliamente para entrenar modelos que alinean imágenes y textos en un espacio de embedding común, mapeándolos a vectores de tamaño fijo. Estos modelos son clave para la recuperación de información multimodal y tareas relacionadas. Sin embargo, los modelos CLIP generalmente tienen un rendimiento inferior en tareas de solo texto en comparación con modelos especializados de texto. Esto crea ineficiencias para los sistemas de recuperación de información que mantienen embeddings y modelos separados para tareas de solo texto y multimodales. Proponemos un nuevo método de entrenamiento contrastivo multi-tarea para abordar este problema, que usamos para entrenar el modelo jina-clip-v1 y lograr un rendimiento estado del arte tanto en tareas de recuperación texto-imagen como texto-texto.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Andreas Koukounas</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a></figure><h2 id="new-state-of-the-art-in-multimodal-embeddings" style="position: relative;"><a href="#new-state-of-the-art-in-multimodal-embeddings" title="Nuevo Estado del Arte en Embeddings Multimodales" id="anchor-new-state-of-the-art-in-multimodal-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Nuevo Estado del Arte en Embeddings Multimodales</h2><p>Evaluamos el rendimiento de Jina CLIP v1 en tareas de solo texto, solo imagen y tareas multimodales que involucran ambas modalidades de entrada. Utilizamos el <a href="https://huggingface.co/blog/mteb">benchmark de recuperación MTEB</a> para evaluar el rendimiento de solo texto. Para tareas de solo imagen, usamos el benchmark <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a>. Para tareas multimodales, evaluamos en <a href="https://www.kaggle.com/datasets/adityajn105/flickr8k">Flickr8k</a>, <a href="https://www.kaggle.com/datasets/adityajn105/flickr30k">Flickr30K</a>, y <a href="https://arxiv.org/abs/1504.00325">MSCOCO Captions</a>, que están incluidos en el <a href="https://arxiv.org/abs/2203.05796">Benchmark CLIP</a>.</p><p>Los resultados se resumen en la siguiente tabla:</p>

<table id="compare_table">
<thead>
<tr>
<th>Model</th>
<th>Text-Text</th>
<th>Text-to-Image</th>
<th>Image-to-Text</th>
<th>Image-Image</th>
</tr>
</thead>
<tbody>
<tr>
<td><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a></td>
<td>0.429</td>
<td>0.899</td>
<td>0.803</td>
<td>0.916</td>
</tr>
<tr>
<td>openai-clip-vit-b16</td>
<td>0.162</td>
<td>0.881</td>
<td>0.756</td>
<td>0.816</td>
</tr>
<tr style="font-weight:bold">
<td>% increase<br>vs OpenAI CLIP</td>
<td>165%</td>
<td>2%</td>
<td>6%</td>
<td>12%</td>
</tr>
</tbody>
</table>

<p>Como puede verse en estos resultados, <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> supera al CLIP original de OpenAI en todas las categorías, y es dramáticamente mejor en recuperación de solo texto y solo imagen. Promediando todas las categorías, esto representa una mejora del 46% en rendimiento.</p><p>Puede encontrar una evaluación más detallada en <a href="https://arxiv.org/abs/2405.20204">nuestro artículo reciente</a>.</p><h2 id="getting-started-with-embeddings-api" style="position: relative;"><a href="#getting-started-with-embeddings-api" title="Comenzando con la API de Embeddings" id="anchor-getting-started-with-embeddings-api"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Comenzando con la API de Embeddings</h2><p>Puede integrar fácilmente Jina CLIP v1 en sus aplicaciones usando la <a href="https://jina.ai/embeddings">API de Embeddings de Jina</a>.</p><p>El código a continuación muestra cómo llamar a la API para obtener embeddings de textos e imágenes, usando el paquete <code>requests</code> en Python. Pasa una cadena de texto y una URL a una imagen al servidor de Jina AI y devuelve ambas codificaciones.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">☝️</div><div class="kg-callout-text">Recuerde reemplazar <code spellcheck="false" style="white-space: pre-wrap;">&lt;YOUR_JINA_AI_API_KEY&gt;</code> con una clave API de Jina activada. Puede obtener una clave de prueba con un millón de tokens gratuitos desde la <a href="https://jina.ai/embeddings/#apiform">página web de Jina Embeddings</a>.</div></div><pre class="hljs-copy-wrapper"><code class="language-python hljs"><span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> numpy.linalg <span class="hljs-keyword">import</span> norm

cos_sim = <span class="hljs-keyword">lambda</span> a,b: (a @ b.T) / (norm(a)*norm(b))

url = <span class="hljs-string">'https://api.jina.ai/v1/embeddings'</span>

headers = {
  <span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/json'</span>,
  <span class="hljs-string">'Authorization'</span>: <span class="hljs-string">'Bearer &lt;YOUR_JINA_AI_API_KEY&gt;'</span>
}

data = {
  <span class="hljs-string">'input'</span>: [
     {<span class="hljs-string">"text"</span>: <span class="hljs-string">"Bridge close-shot"</span>},
     {<span class="hljs-string">"url"</span>: <span class="hljs-string">"https://fastly.picsum.photos/id/84/1280/848.jpg?hmac=YFRYDI4UsfbeTzI8ZakNOR98wVU7a-9a2tGF542539s"</span>}],
  <span class="hljs-string">'model'</span>: <span class="hljs-string">'jina-clip-v1'</span>,
  <span class="hljs-string">'encoding_type'</span>: <span class="hljs-string">'float'</span>
}

response = requests.post(url, headers=headers, json=data)
sim = cos_sim(np.array(response.json()[<span class="hljs-string">'data'</span>][<span class="hljs-number">0</span>][<span class="hljs-string">'embedding'</span>]), np.array(response.json()[<span class="hljs-string">'data'</span>][<span class="hljs-number">1</span>][<span class="hljs-string">'embedding'</span>]))
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Cosine text&lt;-&gt;image: <span class="hljs-subst">{sim}</span>"</span>)
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copiar</button></div></pre><h3 id="integration-with-major-llm-frameworks" style="position: relative;"><a href="#integration-with-major-llm-frameworks" title="Integración con Principales Frameworks de LLM" id="anchor-integration-with-major-llm-frameworks"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Integración con Principales Frameworks de LLM</h3><p>Jina CLIP v1 ya está disponible para <a href="https://www.llamaindex.ai/" rel="noreferrer">LlamaIndex</a> y <a href="https://www.langchain.com/" rel="noreferrer">LangChain</a>:</p><ul><li><a href="https://docs.llamaindex.ai/en/stable/examples/embeddings/jinaai_embeddings/">LlamaIndex</a>: Use <code>JinaEmbedding</code> con la clase base <code>MultimodalEmbedding</code>, y llame a <code>get_image_embeddings</code> o <code>get_text_embeddings</code>.</li><li><a href="https://python.langchain.com/v0.1/docs/integrations/text_embedding/jina/">LangChain</a>: Use <code>JinaEmbeddings</code>, y llame a <code>embed_images</code> o <code>embed_documents</code>.</li></ul><h3 id="pricing" style="position: relative;"><a href="#pricing" title="Precios" id="anchor-pricing"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Precios</h3><p>Tanto las entradas de texto como de imagen se cobran por consumo de tokens.</p><p>Para texto en inglés, <a href="https://jina.ai/news/a-deep-dive-into-tokenization/">hemos calculado empíricamente</a> que en promedio necesitará 1.1 tokens por cada palabra.</p><p>Para imágenes, contamos el número de mosaicos de 224x224 píxeles necesarios para cubrir su imagen. Algunos de estos mosaicos pueden estar parcialmente en blanco pero cuentan igual. Cada mosaico cuesta 1,000 tokens para procesar.</p><p><strong>Ejemplo</strong></p><p>Para una imagen con dimensiones de 750x500 píxeles:</p><ol><li>La imagen se divide en mosaicos de 224x224 píxeles.<ol><li>Para calcular el número de mosaicos, tome el ancho en píxeles y divida por 224, luego redondee al entero más cercano. <br>     750/224 ≈ 3.35 → 4</li><li>Repita para la altura en píxeles: <br>     500/224 ≈ 2.23 → 3</li></ol></li><li>El número total de mosaicos requeridos en este ejemplo es: <br>           4 (horizontal) x 3 (vertical) = 12 mosaicos</li><li>El costo será 12 x 1,000 = 12,000 tokens </li></ol><h3 id="enterprise-support" style="position: relative;"><a href="#enterprise-support" title="Soporte Empresarial" id="anchor-enterprise-support"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Soporte Empresarial</h3><p>Estamos introduciendo un nuevo beneficio para usuarios que compren el plan de Despliegue en Producción con <a href="https://jina.ai/embeddings/#pricing">11 mil millones de tokens</a>. Esto incluye:</p><ul><li>Tres horas de consultoría con nuestros equipos de producto e ingeniería para discutir sus casos de uso específicos y requisitos.</li><li>Un notebook Python personalizado diseñado para su caso de uso de RAG (Generación Aumentada por Recuperación) o búsqueda vectorial, demostrando cómo integrar los modelos de Jina AI en su aplicación.</li><li>Asignación a un ejecutivo de cuenta y soporte prioritario por email para asegurar que sus necesidades sean atendidas de manera rápida y eficiente.</li></ul><h2 id="open-source-jina-clip-v1-on-hugging-face" style="position: relative;"><a href="#open-source-jina-clip-v1-on-hugging-face" title="Jina CLIP v1 de Código Abierto en Hugging Face" id="anchor-open-source-jina-clip-v1-on-hugging-face"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Jina CLIP v1 de Código Abierto en Hugging Face</h2><p>Jina AI está comprometida con una base de búsqueda de código abierto, y por ese propósito, estamos haciendo este modelo disponible gratuitamente bajo una <a href="https://www.apache.org/licenses/LICENSE-2.0">licencia Apache 2.0</a>, en <a href="https://huggingface.co/jinaai/jina-clip-v1">Hugging Face</a>.</p><p>Puede encontrar código de ejemplo para descargar y ejecutar este modelo en su propio sistema o instalación en la nube en la página del modelo en Hugging Face para <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-clip-v1"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-clip-v1 · Hugging Face</div><div class="kg-bookmark-description">Estamos en un viaje para avanzar y democratizar la inteligencia artificial a través del código abierto y la ciencia abierta.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-clip-v1.png" alt="" style="cursor: help;"></div></a></figure><h2 id="summary" style="position: relative;"><a href="#summary" title="Resumen" id="anchor-summary"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Resumen</h2><p>El último modelo de Jina AI — <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> — representa un avance significativo en modelos de embedding multimodales, ofreciendo mejoras sustanciales de rendimiento sobre CLIP de OpenAI. Con mejoras notables en tareas de recuperación de solo texto y solo imagen, así como un rendimiento competitivo en tareas de texto a imagen e imagen a texto, se presenta como una solución prometedora para casos de uso complejos de embeddings.</p><p>Actualmente, este modelo solo admite textos en inglés debido a limitaciones de recursos. Estamos trabajando para expandir sus capacidades a más idiomas.</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Categorías:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Presentado</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">presione soltar</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-a926e642="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-a926e642="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-a926e642="" class="col-sm-12 col-md"><div data-v-a926e642="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Oficinas</div><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-a926e642="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center"><div data-v-a926e642="" class="q-item__label">Sunnyvale, California</div><div data-v-a926e642="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, EE. UU.</div></div></div><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-a926e642="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center"><div data-v-a926e642="" class="q-item__label">Berlín, Alemania (sede central)</div><div data-v-a926e642="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlín, Alemania</div></div></div><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-a926e642="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center"><div data-v-a926e642="" class="q-item__label">Beijing, China</div><div data-v-a926e642="" class="q-item__label q-item__label--caption text-caption text-dim">Piso 5, Edificio 6, No.48 Haidian West St. Pekín, China</div></div></div><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-a926e642="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center"><div data-v-a926e642="" class="q-item__label">Shenzhen, China</div><div data-v-a926e642="" class="q-item__label q-item__label--caption text-caption text-dim">Piso 402, Edificio de Tecnología Fu'an, Shenzhen, China</div></div></div></div></div><div data-v-a926e642="" class="col-sm-12 col-md row"><div data-v-a926e642="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fundación de búsqueda</div><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Búsqueda profunda</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Lector</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Incrustaciones</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">reclasificador</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Clasificador</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Segmentador</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Documentación API</div></a><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Obtener la clave API de Jina</div></div><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Límite de velocidad</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-a926e642="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Estado de la API</div></a></div><div data-v-a926e642="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Compañía</div><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Sobre nosotros</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Contactar con ventas</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Sala de prensa</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Programa de prácticas</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Únete a nosotros</div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Descargar logotipo</div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-a926e642="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-a926e642="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Términos</div><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Seguridad</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Términos y condiciones</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Privacidad</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--main justify-center">Administrar cookies</div></a><a data-v-a926e642="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a926e642="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-a926e642="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-a926e642="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-a926e642="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-a926e642="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-a926e642="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>