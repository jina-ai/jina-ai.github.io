<!DOCTYPE html><html translate="no" dir="ltr" lang="es"><head><title>Más allá de CLIP: Cómo Jina-CLIP avanza en la búsqueda multimodal</title><meta charset="utf-8"><meta name="title" content="Más allá de CLIP: Cómo Jina-CLIP avanza en la búsqueda multimodal"><meta name="description" content="Aprende cómo Jina-CLIP mejora el CLIP de OpenAI con una mayor precisión en la recuperación y resultados más diversos a través de embeddings unificados de texto e imagen."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/beyond-clip-how-jina-clip-advances-multimodal-search"><meta property="og:title" content="Más allá de CLIP: Cómo Jina-CLIP avanza en la búsqueda multimodal"><meta property="og:description" content="Aprende cómo Jina-CLIP mejora el CLIP de OpenAI con una mayor precisión en la recuperación y resultados más diversos a través de embeddings unificados de texto e imagen."><meta property="og:image" content="https://jina.ai/blog-banner/beyond-clip-how-jina-clip-advances-multimodal-search.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/beyond-clip-how-jina-clip-advances-multimodal-search"><meta property="twitter:title" content="Más allá de CLIP: Cómo Jina-CLIP avanza en la búsqueda multimodal"><meta property="twitter:description" content="Aprende cómo Jina-CLIP mejora el CLIP de OpenAI con una mayor precisión en la recuperación y resultados más diversos a través de embeddings unificados de texto e imagen."><meta property="twitter:image" content="https://jina.ai/blog-banner/beyond-clip-how-jina-clip-advances-multimodal-search.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-Bjf9aXBV.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-rzO9Riiq.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-TSLeI8oF.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-DIEftOFa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-OSYSU2Ka.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-un44GgV6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-BZQpbVaf.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-CJe8_Yyy.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/es-DJJjFCSD.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-CT7bkkVR.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CGsTc7al.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-CD6BVpai.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-D1ASSq-o.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-CYxcb8Qj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-DBF-z6P7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-DkYvbdau.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-BX5RJ4RW.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-C-zVGYQU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-BOKZlj73.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-DDEiTJW9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-B4SQCJiN.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-C6at73Ei.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-CNRe4vOa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-Ckz-vUER.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-BN12diS7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-DD4Q_SX0.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-BUFZ8Gln.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-BAdn1gV6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-Bn5namBp.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-Cf3EWv93.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-BTuLlqjS.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-__S2BMiv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-CWNoq6Ug.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-B0y62-Kc.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-CKVKJ9tg.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-DPx_bnTK.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-Bdl6uT0h.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-DO1eLUIG.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-vSZoRHSY.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Bo Wang, Alex C-G"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Bo Wang, Alex C-G"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="11 mins read"><meta property="article:published_time" content="2024-10-29T11:51:40.000+01:00"><meta property="article:modified_time" content="2024-10-30T19:14:11.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Más allá de CLIP: Cómo Jina-CLIP avanza en la búsqueda multimodal",
  "description": "Aprende cómo Jina-CLIP mejora el CLIP de OpenAI con una mayor precisión en la recuperación y resultados más diversos a través de embeddings unificados de texto e imagen.",
  "image": [
    "https://jina.ai/blog-banner/beyond-clip-how-jina-clip-advances-multimodal-search.webp"
  ],
  "datePublished": "2024-10-29T11:51:40.000+01:00",
  "dateModified": "2024-10-30T19:14:11.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Bo Wang",
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-478b3f77="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-478b3f77="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-478b3f77="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-478b3f77="" class="q-space"></div><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-478b3f77="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-478b3f77="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-478b3f77="" class="q-list q-list--dark" role="list"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Noticias</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Modelos</div></a><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_8fa05a81-0aed-47cf-bf62-f358243cacee" aria-label="Expandir &quot;Productos&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Productos</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_8fa05a81-0aed-47cf-bf62-f358243cacee" style="display: none;"><div data-v-478b3f77="" class="q-list q-list--dark" role="list" label="Productos"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Búsqueda profunda</div><div class="q-item__label q-item__label--caption text-caption">Busca, lee y razona hasta encontrar la mejor respuesta.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lector</div><div class="q-item__label q-item__label--caption text-caption">Lea las URL y busque en la web para obtener una base más sólida para su LLM.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Incrustaciones</div><div class="q-item__label q-item__label--caption text-caption">Integraciones multilingües y multimodales de clase mundial.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">reclasificador</div><div class="q-item__label q-item__label--caption text-caption">Recuperador neuronal de clase mundial para maximizar la relevancia de la búsqueda.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_f6f322ac-c6de-4a68-a451-d3f756e70230" aria-label="Expandir &quot;Más&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Más</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_f6f322ac-c6de-4a68-a451-d3f756e70230" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Clasificador</div><div class="q-item__label q-item__label--caption text-caption">Clasificación de cero disparos y pocos disparos para imágenes y texto.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmentador</div><div class="q-item__label q-item__label--caption text-caption">Corta el texto largo en fragmentos y haz tokenización.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Documentación de la API</div><div class="q-item__label q-item__label--caption text-caption">Generación automática de código para su IDE o LLM de Copilot</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_81a46fef-7387-4286-a3f3-d74cd799e190" aria-label="Expandir &quot;Compañía&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Compañía</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_81a46fef-7387-4286-a3f3-d74cd799e190" style="display: none;"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Sobre nosotros</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Contactar con ventas</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Programa de prácticas</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Únete a nosotros</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Descargar logotipo</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Términos y condiciones</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Acceso"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Acceso</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-478b3f77="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_e06bcf59-b6df-4de9-afb8-7e633cd867d6"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_e06bcf59-b6df-4de9-afb8-7e633cd867d6" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_e06bcf59-b6df-4de9-afb8-7e633cd867d6_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-478b3f77="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">¿Qué es CLIP?</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Cómo jina-clip-v1 Resuelve las Limitaciones de CLIP</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Promediando Embeddings de Texto e Imagen para un Rendimiento Superior al Promedio</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Recuperar Resultados con Texto; Diversificarlos con Imágenes</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Conclusión</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog de tecnología</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">octubre 29, 2024</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">Más allá de CLIP: Cómo Jina-CLIP avanza en la búsqueda multimodal</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Aprende cómo Jina-CLIP mejora el CLIP de OpenAI con una mayor precisión en la recuperación y resultados más diversos a través de embeddings unificados de texto e imagen.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img" aria-label="Abstract digital landscape with wave-like green and pink dunes against a dark background, conveying a tranquil atmosphere."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract digital landscape with wave-like green and pink dunes against a dark background, conveying a tranquil atmosphere." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/clip.jpg" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Bo Wang"><div style="padding-bottom: 93.2813%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Bo Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Bo Wang, Alex C-G • 11 minutos de lectura</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><p>La búsqueda multimodal, que combina texto e imágenes en una experiencia de búsqueda fluida, ha ganado impulso gracias a modelos como <a href="https://openai.com/index/clip/">CLIP de OpenAI</a>. Estos modelos conectan efectivamente los datos visuales y textuales, permitiéndonos relacionar imágenes con texto relevante y viceversa.</p><p>Si bien CLIP y modelos similares son potentes, tienen limitaciones notables, particularmente al procesar textos más largos o manejar relaciones textuales complejas. Aquí es donde entra <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina CLIP v1: A Truly Multimodal Embeddings Model for Text and Image</div><div class="kg-bookmark-description">Jina AI's new multimodal embedding model not only outperforms OpenAI CLIP in text-image retrieval, it's a solid image embedding model and state-of-the-art text embedding model at the same time. You don't need different models for different modalities any more.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/06/--.jpg" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Diseñado para abordar estos desafíos, <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> ofrece una mejor comprensión del texto mientras mantiene sólidas capacidades de correspondencia texto-imagen. Proporciona una solución más eficiente para aplicaciones que utilizan ambas modalidades, simplificando el proceso de búsqueda y eliminando la necesidad de alternar entre modelos separados para texto e imágenes.</p><p>En esta publicación, exploraremos lo que <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> aporta a las aplicaciones de búsqueda multimodal, mostrando experimentos que demuestran cómo mejora tanto la precisión como la variedad de resultados a través de embeddings integrados de texto e imagen.</p><h2 id="what-is-clip" style="position: relative;"><a href="#what-is-clip" title="¿Qué es CLIP?" id="anchor-what-is-clip"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>¿Qué es CLIP?</h2><p>CLIP (Contrastive Language–Image Pretraining) es una arquitectura de modelo de IA desarrollada por OpenAI que conecta texto e imágenes mediante el aprendizaje de representaciones conjuntas. CLIP es esencialmente un modelo de texto y un modelo de imagen unidos — transforma ambos tipos de entrada en un espacio de embedding compartido, donde textos e imágenes similares se posicionan cerca unos de otros. CLIP fue entrenado con un vasto conjunto de datos de pares imagen-texto, lo que le permite comprender la relación entre contenido visual y textual. Esto le permite generalizar bien a través de diferentes dominios, haciéndolo altamente efectivo en escenarios de aprendizaje zero-shot, como generar subtítulos o recuperación de imágenes.</p><p>Desde el lanzamiento de CLIP, otros modelos como <a href="https://arxiv.org/abs/2303.15343">SigLiP</a>, <a href="https://arxiv.org/abs/2111.07991">LiT</a>, y <a href="https://arxiv.org/abs/2303.15389">EvaCLIP</a> han expandido sus fundamentos, mejorando aspectos como la eficiencia del entrenamiento, el escalado y la comprensión multimodal. Estos modelos a menudo aprovechan conjuntos de datos más grandes, arquitecturas mejoradas y técnicas de entrenamiento más sofisticadas para expandir los límites de la alineación texto-imagen, avanzando aún más en el campo de los modelos imagen-lenguaje.</p><p>Si bien CLIP <em>puede</em> trabajar solo con texto, enfrenta limitaciones significativas. Primero, fue entrenado solo con subtítulos cortos, no textos largos, manejando un máximo de aproximadamente 77 palabras. Segundo, CLIP sobresale en conectar texto con imágenes pero tiene dificultades al comparar texto con otro texto, como reconocer que las cadenas <code>a crimson fruit</code> y <code>a red apple</code> pueden referirse a lo mismo. Aquí es donde destacan los modelos de texto especializados, como <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>.</p><p>Estas limitaciones complican las tareas de búsqueda que involucran tanto texto como imágenes, por ejemplo, una tienda online "shop the look" donde un usuario puede buscar productos de moda usando tanto una cadena de texto como una imagen. Al indexar tus productos, necesitas procesar cada uno múltiples veces - una vez para la imagen, una vez para el texto, y una vez más con un modelo específico de texto. De igual manera, cuando un usuario busca un producto, tu sistema necesita buscar al menos dos veces para encontrar tanto objetivos de texto como de imagen:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-27.png" class="kg-image" alt="Flowchart outlining &quot;Offline Indexing&quot; and &quot;Online Querying&quot; processes with labeled blocks and arrows for XML data interactio" width="970" height="1255" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-27.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-27.png 970w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><h2 id="how-jina-clip-v1-solves-clip%E2%80%99s-shortcomings" style="position: relative;"><a href="#how-jina-clip-v1-solves-clip%E2%80%99s-shortcomings" title="Cómo jina-clip-v1 Resuelve las Limitaciones de CLIP" id="anchor-how-jina-clip-v1-solves-clip-s-shortcomings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><strong>Cómo </strong><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a><strong> Resuelve las Limitaciones de CLIP</strong></h2><p>Para superar las limitaciones de CLIP, creamos <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> para entender textos más largos y hacer coincidir más efectivamente las consultas de texto tanto con textos como con imágenes. ¿Qué hace que <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> sea tan especial? En primer lugar, utiliza un modelo de comprensión de texto más inteligente (JinaBERT), ayudándole a entender textos más largos y complicados (como descripciones de productos), no solo subtítulos cortos (como nombres de productos). En segundo lugar, entrenamos <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> para ser bueno en dos cosas a la vez: tanto en hacer coincidir texto con imágenes como en hacer coincidir texto con otros textos.</p><p>Con OpenAI CLIP, ese no es el caso: tanto para indexar como para consultar, necesitas invocar dos modelos (CLIP para imágenes y textos cortos como subtítulos, otro embedding de texto para textos más largos como descripciones). Esto no solo añade sobrecarga, sino que ralentiza la búsqueda, una operación que <em>debería</em> ser realmente rápida. <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> hace todo eso en un solo modelo, sin sacrificar velocidad:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-22.png" class="kg-image" alt="Flowchart of JaclinQ's offline indexing and online querying processes, involving imagery and text analysis." width="2000" height="2785" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-22.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-22.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-22.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/10/image-22.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Este enfoque unificado abre nuevas posibilidades que eran desafiantes con modelos anteriores, potencialmente remodelando cómo abordamos la búsqueda. En esta publicación, realizamos dos experimentos:</p><ul><li><strong>Mejorando los resultados de búsqueda combinando texto e imagen</strong>: ¿Podemos combinar lo que <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> entiende del texto con lo que entiende de las imágenes? ¿Qué sucede cuando mezclamos estos dos tipos de comprensión? ¿Agregar información visual cambia nuestros resultados de búsqueda? En resumen, ¿podemos obtener mejores resultados si buscamos con texto e imágenes al mismo tiempo?</li><li><strong>Usando imágenes para diversificar los resultados de búsqueda</strong>: La mayoría de los motores de búsqueda maximizan las coincidencias de texto. Pero ¿podemos usar la comprensión de imágenes de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> como un "shuffle visual"? En lugar de mostrar solo los resultados más relevantes, podríamos incluir algunos visualmente diversos. No se trata de encontrar más resultados relacionados – se trata de mostrar una gama más amplia de perspectivas, incluso si están menos estrechamente relacionadas. Al hacer esto, podemos descubrir aspectos de un tema que no habíamos considerado antes. Por ejemplo, en el contexto de búsqueda de moda, si un usuario busca "vestido de cóctel multicolor", ¿quieren que los primeros resultados se vean todos iguales (es decir, coincidencias <em>muy</em> cercanas), o una mayor variedad para elegir (mediante shuffle visual)?</li></ul><p>Ambos enfoques son valiosos en una variedad de casos de uso donde los usuarios podrían buscar con texto o imágenes, como en comercio electrónico, medios, arte y diseño, imágenes médicas y más allá.</p><h2 id="averaging-text-and-image-embeddings-for-above-average-performance" style="position: relative;"><a href="#averaging-text-and-image-embeddings-for-above-average-performance" title="Promediando Embeddings de Texto e Imagen para un Rendimiento Superior al Promedio" id="anchor-averaging-text-and-image-embeddings-for-above-average-performance"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Promediando Embeddings de Texto e Imagen para un Rendimiento Superior al Promedio</h2><p>Cuando un usuario envía una consulta (generalmente como una cadena de texto), podemos usar la torre de texto de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> para codificar la consulta en un embedding de texto. La fortaleza de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> radica en su capacidad para entender tanto texto como imágenes al alinear señales texto-a-texto y texto-a-imagen en el mismo espacio semántico.</p><p>¿Podemos mejorar los resultados de recuperación si combinamos los embeddings preindexados de texto e imagen de cada producto promediándolos?</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-28.png" class="kg-image" alt="Flowchart on a black background detailing text and image embedding processes with a black knit midi dress photo example." width="995" height="359" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-28.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-28.png 995w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Esto crea una representación única que incluye tanto información textual (por ejemplo, descripción del producto) como información visual (por ejemplo, imagen del producto). Luego podemos usar el embedding de la consulta de texto para buscar estas representaciones combinadas. ¿Cómo afecta esto a nuestros resultados de búsqueda?</p><p>Para averiguarlo, utilizamos el conjunto de datos <a href="https://github.com/xthan/fashion-200k">Fashion200k</a>, un conjunto de datos a gran escala creado específicamente para tareas relacionadas con la recuperación de imágenes de moda y la comprensión multimodal. Consiste en más de 200,000 imágenes de artículos de moda, como ropa, zapatos y accesorios, junto con sus correspondientes descripciones de producto y metadatos.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/xthan/fashion-200k"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - xthan/fashion-200k: Fashion 200K dataset used in paper "Automatic Spatially-aware Fashion Concept Discovery."</div><div class="kg-bookmark-description">Fashion 200K dataset used in paper "Automatic Spatially-aware Fashion Concept Discovery." - xthan/fashion-200k</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="" style="cursor: help;"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">xthan</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://opengraph.githubassets.com/2116651d448aec6ea0508f5fdb123e6292fa00bfb1cf8fb6f3468cbe761da769/xthan/fashion-200k" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Clasificamos cada elemento en una categoría amplia (por ejemplo, <code>dress</code>) y una categoría detallada (como <code>knit midi dress</code>).</p><h3 id="analyzing-three-retrieval-methods" style="position: relative;"><a href="#analyzing-three-retrieval-methods" title="Análisis de Tres Métodos de Recuperación" id="anchor-analyzing-three-retrieval-methods"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><strong>Análisis de Tres Métodos de Recuperación</strong></h3><p>Para ver si promediar los embeddings de texto e imagen producía mejores resultados de recuperación, experimentamos con tres tipos de búsqueda, cada uno utilizando una cadena de texto (por ejemplo, <code>red dress</code>) como consulta:</p><ul><li><strong>Consulta a Descripción usando embeddings de texto:</strong> Buscar descripciones de productos basadas en embeddings de texto.</li><li><strong>Consulta a Imagen usando búsqueda cross-modal:</strong> Buscar imágenes de productos basadas en embeddings de imagen.</li><li><strong>Consulta a Embedding Promedio:</strong> Buscar embeddings promediados tanto de descripciones como de imágenes de productos.</li></ul><p>Primero indexamos todo el conjunto de datos y luego generamos aleatoriamente 1,000 consultas para evaluar el rendimiento. Codificamos cada consulta en un embedding de texto y realizamos la coincidencia por separado, según los métodos descritos anteriormente. Medimos la precisión por qué tan bien las categorías de los productos devueltos coincidían con la consulta de entrada.</p><p>Cuando usamos la consulta <code>multicolor henley t-shirt dress</code>, la búsqueda de <strong>Consulta a Descripción</strong> logró la mayor precisión top-5, pero los últimos tres vestidos mejor clasificados eran visualmente idénticos. Esto es menos que ideal, ya que una búsqueda efectiva debería equilibrar relevancia y diversidad para captar mejor la atención del usuario.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-13.png" class="kg-card kg-image" alt="Array of five unique dresses, categorized as casual and day, arranged in a row on a white background with named tags for easy" width="2000" height="480" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-13.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-13.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-13.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-13.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>La búsqueda cross-modal de <strong>Consulta a Imagen</strong> usó la misma consulta y tomó el enfoque opuesto, presentando una colección altamente diversa de vestidos. Si bien coincidió con dos de cinco resultados en la categoría amplia correcta, ninguno coincidió con la categoría detallada.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-14.png" class="kg-card kg-image" alt="Variety of women's clothing items including short and long-sleeved tops and casual to maxi dresses with color swatches." width="2000" height="496" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-14.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-14.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-14.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-14.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>La <strong>búsqueda con embeddings promediados de texto e imagen</strong> produjo el mejor resultado: los cinco resultados coincidieron con la categoría amplia, y dos de cinco coincidieron con la categoría detallada. Además, se eliminaron los elementos visualmente duplicados, proporcionando una selección más variada. Usar embeddings de texto para buscar en embeddings promediados de texto e imagen parece mantener la calidad de la búsqueda mientras incorpora señales visuales, lo que lleva a resultados más diversos y completos.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-15.png" class="kg-card kg-image" alt="Showcase of various women's dresses, including a multicolor henley t-shirt dress and a pink Missoni dress, labeled with categ" width="2000" height="513" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-15.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-15.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-15.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-15.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><h3 id="scaling-up-evaluating-with-more-queries" style="position: relative;"><a href="#scaling-up-evaluating-with-more-queries" title="Escalando: Evaluación con Más Consultas" id="anchor-scaling-up-evaluating-with-more-queries"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><strong>Escalando: Evaluación con Más Consultas</strong></h3><p>Para ver si esto funcionaría a mayor escala, continuamos ejecutando el experimento con categorías amplias y detalladas adicionales. Ejecutamos varias iteraciones, recuperando un número diferente de resultados ("valores k") cada vez.</p><p>Tanto en categorías amplias como detalladas, la <strong>Consulta a Embedding Promedio</strong> logró consistentemente la mayor precisión en todos los valores k (10, 20, 50, 100). Esto muestra que combinar embeddings de texto e imagen proporciona los resultados más precisos para recuperar elementos relevantes, independientemente de si la categoría es amplia o específica:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-16.png" class="kg-card kg-image" alt="Comparative chart of 'Broad Precision@K' and 'Fine-grained Precision@K' showing different precision values for query-related " width="2000" height="836" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-16.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-16.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-16.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-16.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure>

<table>
<thead>
<tr>
<th><strong>k</strong></th>
<th><strong>Search Type</strong></th>
<th><strong>Broad Category Precision (cosine similarity)</strong></th>
<th><strong>Fine-grained Category Precision (cosine similarity)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>Query to Description</td>
<td>0.9026</td>
<td>0.2314</td>
</tr>
<tr>
<td>10</td>
<td>Query to Image</td>
<td>0.7614</td>
<td>0.2037</td>
</tr>
<tr>
<td>10</td>
<td>Query to Avg Embedding</td>
<td><strong>0.9230</strong></td>
<td><strong>0.2711</strong></td>
</tr>
<tr>
<td>20</td>
<td>Query to Description</td>
<td>0.9150</td>
<td>0.2316</td>
</tr>
<tr>
<td>20</td>
<td>Query to Image</td>
<td>0.7523</td>
<td>0.1964</td>
</tr>
<tr>
<td>20</td>
<td>Query to Avg Embedding</td>
<td><strong>0.9229</strong></td>
<td><strong>0.2631</strong></td>
</tr>
<tr>
<td>50</td>
<td>Query to Description</td>
<td>0.9134</td>
<td>0.2254</td>
</tr>
<tr>
<td>50</td>
<td>Query to Image</td>
<td>0.7418</td>
<td>0.1750</td>
</tr>
<tr>
<td>50</td>
<td>Query to Avg Embedding</td>
<td><strong>0.9226</strong></td>
<td><strong>0.2390</strong></td>
</tr>
<tr>
<td>100</td>
<td>Query to Description</td>
<td>0.9092</td>
<td>0.2139</td>
</tr>
<tr>
<td>100</td>
<td>Query to Image</td>
<td>0.7258</td>
<td>0.1675</td>
</tr>
<tr>
<td>100</td>
<td>Query to Avg Embedding</td>
<td><strong>0.9150</strong></td>
<td><strong>0.2286</strong></td>
</tr>
</tbody>
</table>

<ul><li>La <strong>Consulta a Descripción usando embeddings de texto</strong> funcionó bien en ambas categorías pero quedó ligeramente por detrás del enfoque de embedding promediado. Esto sugiere que las descripciones textuales por sí solas proporcionan información valiosa, particularmente para categorías más amplias como "dress", pero pueden carecer de la sutileza necesaria para una clasificación detallada precisa (por ejemplo, distinguir entre diferentes tipos de vestidos).</li><li>La <strong>Consulta a Imagen usando búsqueda cross-modal</strong> tuvo consistentemente la precisión más baja en ambas categorías. Esto sugiere que mientras las características visuales pueden ayudar a identificar categorías amplias, son menos efectivas para capturar las distinciones detalladas de elementos específicos de moda. El desafío de distinguir categorías detalladas puramente desde características visuales es particularmente evidente, donde las diferencias visuales pueden ser sutiles y requerir contexto adicional proporcionado por el texto.</li><li>En general, combinar información textual y visual (mediante <strong>embeddings promediados</strong>) logró alta precisión tanto en tareas de recuperación de moda amplias como detalladas. Las descripciones textuales juegan un papel importante, especialmente en la identificación de categorías amplias, mientras que las imágenes por sí solas son menos efectivas en ambos casos.</li></ul><p>En general, la precisión fue mucho más alta para categorías amplias en comparación con categorías detalladas, principalmente debido a que los elementos en categorías amplias (por ejemplo, <code>dress</code>) están más representados en el conjunto de datos que las categorías detalladas (por ejemplo, <code>henley dress</code>), simplemente porque la última es un subconjunto de la primera. Por su propia naturaleza, una categoría amplia es más fácil de generalizar que una categoría detallada. Fuera del ejemplo de la moda, es sencillo identificar que algo, en general, es un pájaro. Es mucho más difícil identificarlo como un <a href="https://www.youtube.com/watch?v=nPhVOZiPokA">Vogelkop Superb Bird of Paradise</a>.</p><p>Otro aspecto a tener en cuenta es que la información en una consulta de texto coincide más fácilmente con otros textos (como nombres de productos o descripciones), que con características visuales. Por lo tanto, si se usa un texto como entrada, los textos son una salida más probable que las imágenes. Obtenemos los mejores resultados combinando tanto imágenes como texto (mediante el promedio de los embeddings) en nuestro índice.</p><h2 id="retrieve-results-with-text-diversify-them-with-images" style="position: relative;"><a href="#retrieve-results-with-text-diversify-them-with-images" title="Recuperar Resultados con Texto; Diversificarlos con Imágenes" id="anchor-retrieve-results-with-text-diversify-them-with-images"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Recuperar Resultados con Texto; Diversificarlos con Imágenes</h2><p>En la sección anterior, tocamos el tema de los resultados de búsqueda visualmente duplicados. En la búsqueda, <em>la precisión por sí sola no siempre es suficiente</em>. En muchos casos, mantener una lista clasificada concisa pero altamente relevante y diversa es más efectivo, especialmente cuando la consulta del usuario es ambigua (por ejemplo, si un usuario busca<code>black jacket</code> — ¿se refieren a una chaqueta de motociclista negra, una bomber, un blazer u otro tipo?)</p><p>Ahora, en lugar de aprovechar la capacidad multimodal de <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a>, usaremos los embeddings de texto de su torre de texto para la búsqueda inicial, y luego aplicaremos los embeddings de imagen de la torre de imagen como un "reordenador visual" para diversificar los resultados de búsqueda. Esto se ilustra en el diagrama siguiente:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-29.png" class="kg-image" alt="Flowchart detailing multimodal document text processing, with branches for text and image embedding and various processing pa" width="975" height="476" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-29.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-29.png 975w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p></p><ol><li>Primero, recuperar los k primeros resultados de búsqueda basados en embeddings de texto.</li><li>Para cada resultado principal de búsqueda, extraer características visuales y agruparlas usando embeddings de imagen.</li><li>Reordenar los resultados de búsqueda seleccionando un elemento de cada grupo y presentar una lista diversificada al usuario.</li></ol><p>Después de recuperar los cincuenta primeros resultados, aplicamos un agrupamiento k-means ligero (k=5) a los embeddings de imagen, luego seleccionamos elementos de cada grupo. La precisión de categoría se mantuvo consistente con el rendimiento de Consulta-a-Descripción, ya que usamos la categoría de consulta-a-producto como métrica de medición. Sin embargo, los resultados clasificados comenzaron a cubrir más aspectos diferentes (como tela, corte y patrón) con la diversificación basada en imágenes. Como referencia, aquí está el ejemplo del vestido tipo camiseta henley multicolor de antes:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-18.png" class="kg-image" alt="Collection of t-shirt dresses categorized into casual and day, short and long sleeves, displayed in two rows." width="2000" height="1484" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-18.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-18.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-18.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-18.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Ahora veamos cómo la diversificación afecta los resultados de búsqueda usando la búsqueda por embedding de texto combinada con embedding de imagen como reordenador de diversificación:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-19.png" class="kg-image" alt="Five diverse dresses arranged in a row, categorized as various types including casual and day dresses, mini and short, and ma" width="2000" height="465" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/10/image-19.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/10/image-19.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/10/image-19.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/10/image-19.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Los resultados clasificados provienen de la búsqueda basada en texto pero comienzan a cubrir "aspectos" más diversos dentro de los cinco primeros ejemplos. Esto logra un efecto similar al promedio de embeddings sin realmente promediarlos.</p><p>Sin embargo, esto tiene un costo: tenemos que aplicar un paso adicional de agrupamiento después de recuperar los k primeros resultados, lo que añade algunos milisegundos extra, dependiendo del tamaño de la clasificación inicial. Además, determinar el valor de k para el agrupamiento k-means implica algunas conjeturas heurísticas. ¡Ese es el precio que pagamos por una mejor diversificación de resultados!</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusión" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusión</h2><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> cierra efectivamente la brecha entre la búsqueda de texto e imagen unificando ambas modalidades en un solo modelo eficiente. Nuestros experimentos han demostrado que su capacidad para procesar textos más largos y complejos junto con imágenes ofrece un rendimiento de búsqueda superior en comparación con modelos tradicionales como CLIP.</p><p>Nuestras pruebas cubrieron varios métodos, incluyendo la coincidencia de texto con descripciones, imágenes y embeddings promediados. Los resultados mostraron consistentemente que la combinación de embeddings de texto e imagen produjo los mejores resultados, mejorando tanto la precisión como la diversidad de los resultados de búsqueda. También descubrimos que usar embeddings de imagen como un "reordenador visual" mejoró la variedad de resultados mientras mantenía la relevancia.</p><p>Estos avances tienen implicaciones significativas para aplicaciones del mundo real donde los usuarios buscan usando tanto descripciones de texto como imágenes. Al entender ambos tipos de datos simultáneamente, <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> optimiza el proceso de búsqueda, entregando resultados más relevantes y permitiendo recomendaciones de productos más diversas. Esta capacidad de búsqueda unificada se extiende más allá del comercio electrónico para beneficiar la gestión de activos multimedia, bibliotecas digitales y curación de contenido visual, facilitando el descubrimiento de contenido relevante en diferentes formatos.</p><p>Si bien <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> actualmente solo admite inglés, estamos trabajando en <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v2" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v2</span></a>. Siguiendo los pasos de <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> y <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v2" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v2</span></a>, esta nueva versión será un recuperador multimodal multilingüe de última generación que admitirá 89 idiomas. Esta actualización abrirá nuevas posibilidades para tareas de búsqueda y recuperación en diferentes mercados e industrias, convirtiéndolo en un modelo de embedding más potente para aplicaciones globales en comercio electrónico, medios y más allá.</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Categorías:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Blog de tecnología</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fbeyond-clip-how-jina-clip-advances-multimodal-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-478b3f77="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-478b3f77="" class="col-sm-12 col-md"><div data-v-478b3f77="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Oficinas</div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Sunnyvale, California</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, EE. UU.</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Berlín, Alemania (sede central)</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlín, Alemania</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Beijing, China</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Piso 5, Edificio 6, No.48 Haidian West St. Pekín, China</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">Shenzhen, China</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Piso 402, Edificio de Tecnología Fu'an, Shenzhen, China</div></div></div></div></div><div data-v-478b3f77="" class="col-sm-12 col-md row"><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fundación de búsqueda</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Búsqueda profunda</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Lector</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Incrustaciones</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">reclasificador</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Clasificador</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Segmentador</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Documentación API</div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Obtener la clave API de Jina</div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Límite de velocidad</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-478b3f77="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Estado de la API</div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Compañía</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Sobre nosotros</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Contactar con ventas</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Sala de prensa</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Programa de prácticas</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Únete a nosotros</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Descargar logotipo</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Términos</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Seguridad</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Términos y condiciones</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Privacidad</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Administrar cookies</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-478b3f77="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-478b3f77="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-478b3f77="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>