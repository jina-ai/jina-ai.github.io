<!DOCTYPE html><html translate="no" dir="ltr" lang="es"><head><title>Jina Embeddings v4：向量模型 (Embeddings) 通用模型，适用于多模态多语言检索</title><meta charset="utf-8"><meta name="title" content="Jina Embeddings v4：向量模型 (Embeddings) 通用模型，适用于多模态多语言检索"><meta name="description" content="Jina Embeddings v4 es un modelo de &quot;向量模型 (Embeddings)&quot; universal de 3.8 mil millones de parámetros para la recuperación multimodal y multilingüe que admite salidas de &quot;向量模型 (Embeddings)&quot; de un solo vector y de múltiples vectores."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval"><meta property="og:title" content="Jina Embeddings v4：向量模型 (Embeddings) 通用模型，适用于多模态多语言检索"><meta property="og:description" content="Jina Embeddings v4 es un modelo de &quot;向量模型 (Embeddings)&quot; universal de 3.8 mil millones de parámetros para la recuperación multimodal y multilingüe que admite salidas de &quot;向量模型 (Embeddings)&quot; de un solo vector y de múltiples vectores."><meta property="og:image" content="https://jina.ai/blog-banner/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval"><meta property="twitter:title" content="Jina Embeddings v4：向量模型 (Embeddings) 通用模型，适用于多模态多语言检索"><meta property="twitter:description" content="Jina Embeddings v4 es un modelo de &quot;向量模型 (Embeddings)&quot; universal de 3.8 mil millones de parámetros para la recuperación multimodal y multilingüe que admite salidas de &quot;向量模型 (Embeddings)&quot; de un solo vector y de múltiples vectores."><meta property="twitter:image" content="https://jina.ai/blog-banner/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-B2TshkO1.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-rzO9Riiq.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-Bdzv5wkq.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-Cg0dwsIc.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-BVZZyrKh.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-Bhb3YjpT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-C6jJfQWu.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-B2NwLaUR.js"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/es-DJJjFCSD.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-iZRq4mDN.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-B0XQMl3F.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-COmWcOel.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/UserAvatarComponent-BgLGBt03.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-BpiRbV4W.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-akpAcJA2.js"><link rel="stylesheet" crossorigin="" href="/assets/UserAvatarComponent-HOhEbA2Z.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-DCzAb9Oh.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-Cm1rPQ14.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-B9xrfd3b.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-YROGvQfG.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-BuBW0QaA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-CQjNIUfW.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-DtKL7UgA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-DLCYdDWn.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-Bp3L_jaT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-mv8kdTDH.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-dG2W3-fu.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-BV3m_dwK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-De4nRjK2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-CilCHCHb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-CUxTLjTu.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-DihvZdVB.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-BRssGlk8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-Bf01fk3Y.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge--otySK25.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-C2xxFrs6.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-CpXcJtUU.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-CxoY87wV.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-0v_6KiP0.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Jina AI"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Jina AI"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="12 mins read"><meta property="article:published_time" content="2025-06-25T06:48:16.000+02:00"><meta property="article:modified_time" content="2025-06-25T06:48:16.000+02:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Jina Embeddings v4：向量模型 (Embeddings) 通用模型，适用于多模态多语言检索",
  "description": "Jina Embeddings v4 es un modelo de \"向量模型 (Embeddings)\" universal de 3.8 mil millones de parámetros para la recuperación multimodal y multilingüe que admite salidas de \"向量模型 (Embeddings)\" de un solo vector y de múltiples vectores.",
  "image": [
    "https://jina.ai/blog-banner/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval.webp"
  ],
  "datePublished": "2025-06-25T06:48:16.000+02:00",
  "dateModified": "2025-06-25T06:48:16.000+02:00",
  "author": [
    {
      "@type": "Organization",
      "name": "Jina AI",
      "url": "https://jina.ai"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-ce90450d="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-ce90450d="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-ce90450d="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-ce90450d="" class="q-space"></div><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-ce90450d="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-ce90450d="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-ce90450d="" class="q-list q-list--dark" role="list"><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Noticias</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Modelos</div></a><div data-v-ce90450d="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_bde23963-d788-4698-a8b0-bfb63ef99de0" aria-label="Expandir &quot;Productos&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Productos</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_bde23963-d788-4698-a8b0-bfb63ef99de0" style="display: none;"><div data-v-ce90450d="" class="q-list q-list--dark" role="list" label="Productos"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Lector</div><div class="q-item__label q-item__label--caption text-caption">Lea las URL y busque en la web para obtener una base más sólida para su LLM.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Incrustaciones</div><div class="q-item__label q-item__label--caption text-caption">Integraciones multilingües y multimodales de clase mundial.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">reclasificador</div><div class="q-item__label q-item__label--caption text-caption">Recuperador neuronal de clase mundial para maximizar la relevancia de la búsqueda.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Búsqueda profunda</div><div class="q-item__label q-item__label--caption text-caption">Busca, lee y razona hasta encontrar la mejor respuesta.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_694ae118-e1e3-4ee2-b299-3e373a77ac20" aria-label="Expandir &quot;Más&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Más</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_694ae118-e1e3-4ee2-b299-3e373a77ac20" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Clasificador</div><div class="q-item__label q-item__label--caption text-caption">Clasificación de cero disparos y pocos disparos para imágenes y texto.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmentador</div><div class="q-item__label q-item__label--caption text-caption">Corta el texto largo en fragmentos y haz tokenización.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Documentación de la API</div><div class="q-item__label q-item__label--caption text-caption">Generación automática de código para su IDE o LLM de Copilot</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-ce90450d="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_f17c0db4-7553-4eee-bd64-324e22659e97" aria-label="Expandir &quot;Compañía&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Compañía</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_f17c0db4-7553-4eee-bd64-324e22659e97" style="display: none;"><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Sobre nosotros</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Contactar con ventas</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Programa de prácticas</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Únete a nosotros</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Descargar logotipo</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Términos y condiciones</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Acceso"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Acceso</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-ce90450d="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_29080c8c-9357-43ba-8fac-5f67b25a90b5"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_29080c8c-9357-43ba-8fac-5f67b25a90b5" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_29080c8c-9357-43ba-8fac-5f67b25a90b5_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-ce90450d="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Nueva Arquitectura</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Empezando</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">Conclusión</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Presentado</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">presione soltar</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">junio 25, 2025</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">Jina Embeddings v4：向量模型 (Embeddings) 通用模型，适用于多模态多语言检索</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Jina Embeddings v4 es un modelo de "向量模型 (Embeddings)" universal de 3.8 mil millones de parámetros para la recuperación multimodal y multilingüe que admite salidas de "向量模型 (Embeddings)" de un solo vector y de múltiples vectores.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/je-v4.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Jina AI"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Jina AI" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/08/Jjqb-JeY_400x400.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Jina AI • 12 minutos de lectura</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/models/jina-embeddings-v4"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v4 - Modelos de Búsqueda Fundacionales</div><div class="kg-bookmark-description">Modelo de "embedding" universal para la recuperación multimodal y multilingüe</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-35.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Modelos de Búsqueda Fundacionales</span><span class="kg-bookmark-publisher">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-v4.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2506.18902"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v4: "Embeddings" Universales para la Recuperación Multimodal Multilingüe</div><div class="kg-bookmark-description">Presentamos jina-embeddings-v4, un modelo de "embedding" multimodal de 3.8 mil millones de parámetros que unifica representaciones de texto e imagen a través de una arquitectura novedosa que admite "embeddings" de un solo vector y de múltiples vectores en el estilo de interacción tardía. El modelo incorpora adaptadores de Adaptación de Bajo Rango (LoRA) específicos de la tarea para optimizar el rendimiento en diversos escenarios de recuperación, incluida la recuperación de información basada en consultas, la similitud semántica entre modalidades y la búsqueda de código de programación. Las evaluaciones exhaustivas demuestran que jina-embeddings-v4 logra un rendimiento de vanguardia tanto en tareas de recuperación unimodal como intermodal, con una fortaleza particular en el procesamiento de contenido visualmente rico, como tablas, gráficos, diagramas y formatos multimedia mixtos. Para facilitar la evaluación de esta capacidad, también presentamos Jina-VDR, un nuevo punto de referencia diseñado específicamente para la recuperación de imágenes visualmente ricas.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-38.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-34.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-embeddings-v4"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-embeddings-v4 · Hugging Face</div><div class="kg-bookmark-description">Estamos en un viaje para avanzar y democratizar la inteligencia artificial a través del código abierto y la ciencia abierta.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-39.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/jina-embeddings-v4-1.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Hoy lanzamos <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a>, nuestro nuevo modelo de "embedding" universal de 3.8 mil millones de parámetros para texto e imágenes. Incluye un conjunto de adaptadores LoRA específicos de la tarea que optimizan el rendimiento para las tareas de recuperación más populares, incluida la recuperación de consulta-documento, la coincidencia semántica y la búsqueda de código. <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> logra un rendimiento de recuperación de vanguardia en tareas multimodales y multilingües en los puntos de referencia MTEB, MMTEB, CoIR, LongEmbed, STS, <a href="https://github.com/jina-ai/jina-vdr">Jina-VDR</a>, CLIP y ViDoRe, con una fortaleza particular en el procesamiento de contenido visualmente rico, como tablas, gráficos, diagramas y mezclas de ellos. El modelo admite "embeddings" de un solo vector y de múltiples vectores.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/model-perf-boxplot--18-.png" class="kg-image" alt="" width="2000" height="2781" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/06/model-perf-boxplot--18-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/06/model-perf-boxplot--18-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/06/model-perf-boxplot--18-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/06/model-perf-boxplot--18-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Rendimiento de </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;"> en la recuperación de documentos visuales y puntos de referencia multimodales. Las distribuciones de diagramas de caja muestran las puntuaciones medias y la variabilidad del rendimiento de los modelos de "embedding" en seis categorías de puntos de referencia: ViDoRe (recuperación de documentos de visión), Jina-VDR (recuperación integral de documentos visuales), Recuperación de Wikimedia Commons (coincidencia multilingüe de documento-descripción), Recuperación de GitHub README (recuperación de documentación de código), Recuperación de Tweet Stock (análisis de gráficos financieros) y CLIP Benchmark (recuperación general de texto a imagen). Las variantes de Jina-embeddings-v4 (resaltadas en cian) demuestran un rendimiento de vanguardia en tareas de documentos visualmente ricos, con la versión multivectorial logrando las puntuaciones más altas en puntos de referencia de documentos visuales especializados (90.2 en ViDoRe, 80.2 en Jina-VDR), al tiempo que mantiene un rendimiento competitivo en tareas generales de recuperación multimodal (84.1 en CLIP Benchmark). Los modelos se clasifican por rendimiento medio dentro de cada categoría de punto de referencia, con puntos de datos individuales que muestran distribuciones de puntuaciones en múltiples tareas de evaluación.</span></figcaption></figure><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> es nuestro modelo de "embedding" más ambicioso hasta el momento. Como modelo de código abierto, <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> supera a los principales modelos de "embedding" de código cerrado de los principales proveedores, ofreciendo un rendimiento un 12% mejor que <code>text-embedding-3-large</code> de OpenAI en la recuperación multilingüe (66.49 frente a 59.27), una mejora del 28% en las tareas de documentos largos (67.11 frente a 52.42), un 15% mejor que <code>voyage-3</code> en la recuperación de código (71.59 frente a 67.23) e igualando el rendimiento de <code>gemini-embedding-001</code> de Google. Esto convierte a v4 en el modelo de "embedding" universal de código abierto más capaz disponible en la actualidad, que ofrece a los investigadores y desarrolladores capacidades de "embedding" multimodal de nivel empresarial con total transparencia en el proceso de entrenamiento, las decisiones arquitectónicas y los pesos del modelo a través de <a href="https://arxiv.org/abs/2506.18902">nuestro informe técnico completo.</a></p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/model-perf-boxplot--15-.png" class="kg-image" alt="" width="2000" height="2631" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2025/06/model-perf-boxplot--15-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2025/06/model-perf-boxplot--15-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2025/06/model-perf-boxplot--15-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2025/06/model-perf-boxplot--15-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Rendimiento de </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;"> en cinco puntos de referencia de recuperación. El gráfico muestra distribuciones de diagramas de caja con puntuaciones medias para cada modelo en los puntos de referencia de Recuperación de texto, Recuperación de código, Recuperación multilingüe, Recuperación de contexto largo y Similitud textual semántica (STS). </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;"> (resaltado en cian) demuestra un rendimiento competitivo o de vanguardia en todas las categorías de evaluación, con resultados particularmente sólidos en la recuperación de texto y STS. Los modelos se clasifican por rendimiento medio dentro de cada categoría de punto de referencia, con puntos de datos individuales que muestran distribuciones de puntuaciones en múltiples tareas de evaluación.</span></figcaption></figure><h2 id="new-architecture" style="position: relative;"><a href="#new-architecture" title="Nueva Arquitectura" id="anchor-new-architecture"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Nueva Arquitectura</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/06/Heading--51-.svg" class="kg-image" alt="" width="1200" height="630" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Arquitectura de </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a><span style="white-space: pre-wrap;">. El modelo está construido sobre la base de </span><code spellcheck="false" style="white-space: pre-wrap;"><span>Qwen2.5-VL-3B-Instruct</span></code><span style="white-space: pre-wrap;"> (3.8B parámetros). Las entradas de texto e imagen se procesan a través de una vía compartida: las imágenes primero se convierten en secuencias de "tokens" a través de un codificador de visión, luego ambas modalidades se procesan conjuntamente mediante el decodificador del modelo de lenguaje con capas de atención contextual. Tres adaptadores LoRA específicos de la tarea (60 millones de parámetros cada uno) proporcionan una optimización especializada para las tareas de recuperación, coincidencia de texto y código sin modificar los pesos de la base congelada. La arquitectura admite modos de salida dual: (1) "embeddings" de un solo vector (2048 dimensiones, truncables a 128) generados a través de la agrupación media para una búsqueda de similitud eficiente, y (2) "embeddings" de múltiples vectores (128 dimensiones por "token") a través de capas de proyección para estrategias de recuperación de interacción tardía.</span></figcaption></figure><p>La actualización de <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> a<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> representa un cambio de paradigma desde los modelos de 向量模型 (Embeddings) que solo utilizaban texto, hacia los modelos multimodales. Mientras que v3 se centraba en optimizar los 向量模型 (Embeddings) de texto con adaptadores LoRA específicos para cada tarea, v4 aborda la creciente necesidad de integrar contenido textual y visual en representaciones unificadas.

</p><table>
<thead>
<tr>
<th><strong>Aspecto</strong></th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">&lt;strong&gt;jina-embeddings-v3&lt;/strong&gt;</span></a></th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">&lt;strong&gt;jina-embeddings-v4&lt;/strong&gt;</span></a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Modelo Base</td>
<td>jina-XLM-RoBERTa</td>
<td>Qwen2.5-VL-3B-Instruct</td>
</tr>
<tr>
<td>Parámetros (Base)</td>
<td>559M</td>
<td>3.8B</td>
</tr>
<tr>
<td>Parámetros (con adaptadores)</td>
<td>572M</td>
<td>3.8B + 60M por adaptador</td>
</tr>
<tr>
<td>Modalidades</td>
<td>Solo texto</td>
<td>Texto + Imágenes (multimodal)</td>
</tr>
<tr>
<td>Longitud Máxima de Entrada</td>
<td>8,192 词元 (Tokens)</td>
<td>32,768 词元 (Tokens)</td>
</tr>
<tr>
<td>Procesamiento de Imágenes</td>
<td>Ninguno</td>
<td>Hasta 20 megapíxeles, documentos visualmente ricos</td>
  </tr>
<tr>
<td>Soporte Multilingüe</td>
<td>89 idiomas</td>
<td>29+ idiomas</td>
</tr>
<tr>
<td>Tipos de Vectores</td>
<td>Solo vector único</td>
<td>Vector único + Multi-vector (interacción tardía)</td>
</tr>
<tr>
<td>Dimensiones del Vector Único</td>
<td>1024 (MRL truncable a 32)</td>
<td>2048 (MRL truncable a 128)</td>
</tr>
<tr>
<td>Dimensiones del Multi-vector</td>
<td>No disponible</td>
<td>128 por 词元 (Token)</td>
</tr>
<tr>
<td>Especializaciones LoRA por Tarea</td>
<td>• Recuperación asimétrica<br>• Similitud semántica<br>• Clasificación<br>• Separación</td>
<td>• Recuperación asimétrica<br>• Similitud semántica<br>• Recuperación de código</td>
</tr>
<tr>
<td>Etapas de Entrenamiento</td>
<td>3 etapas: Pre-entrenamiento → Ajuste fino del 向量模型 (Embedding) → Entrenamiento del adaptador</td>
<td>2 etapas: Entrenamiento de pares conjuntos → Entrenamiento del adaptador específico para la tarea</td>
</tr>
<tr>
<td>Funciones de Pérdida</td>
<td>InfoNCE, CoSent, Pérdida de tripletes extendida</td>
<td>InfoNCE conjunto + Divergencia KL para vector único/múltiple</td>
</tr>
<tr>
<td>Codificación Posicional</td>
<td>RoPE (ajuste de frecuencia base rotatoria)</td>
<td>M-RoPE (Codificación Posicional Rotatoria Multimodal)</td>
</tr>
<tr>
<td>Procesamiento Intermodal</td>
<td>N/A</td>
<td>Codificador unificado (brecha de modalidad reducida)</td>
</tr>
<tr>
<td>Soporte MRL</td>
<td>Sí</td>
<td>Sí</td>
</tr>
<tr>
<td>Implementación de Atención</td>
<td>FlashAttention2</td>
<td>FlashAttention2</td>
</tr>
</tbody>
</table>

<h3 id="backbone" style="position: relative;"><a href="#backbone" title="Backbone" id="anchor-backbone"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Backbone</h3><p>El cambio arquitectónico más significativo en v4 es el cambio del backbone de <code>XLM-RoBERTa</code> a <code>Qwen2.5-VL-3B-Instruct</code>. Esta decisión fue impulsada por el objetivo central de v4 de crear un modelo de 向量模型 (Embedding) universal que permita el "verdadero procesamiento multimodal" donde las imágenes se convierten en secuencias de 词元 (Tokens) y se procesan junto con el texto, eliminando la <a href="https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models">brecha de modalidad</a> presente en las arquitecturas de codificador dual.</p><p>La selección del backbone se alinea con varios objetivos de diseño clave: la excelencia de Qwen2.5-VL en la comprensión de documentos apoya directamente la fortaleza de v4 en el procesamiento de contenido visualmente rico como tablas, gráficos y capturas de pantalla. Las capacidades de resolución dinámica permiten a v4 manejar imágenes redimensionadas a 20 megapíxeles como se especifica en la arquitectura. La codificación posicional avanzada proporciona la base que permite a v4 lograr una alineación intermodal superior con una puntuación de alineación de 0.71 en comparación con 0.15 para OpenAI CLIP.</p><h3 id="lora-adapters" style="position: relative;"><a href="#lora-adapters" title="Adaptadores LoRA" id="anchor-lora-adapters"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Adaptadores LoRA</h3><p>V4 se simplifica de las cinco tareas de v3 a tres tareas enfocadas, lo que refleja las lecciones aprendidas sobre la efectividad y la adopción por parte del usuario:</p><ul><li><strong>Recuperación asimétrica</strong> (consolidando los adaptadores de consulta/pasaje de v3)</li><li><strong>Similitud simétrica</strong> (el equivalente de coincidencia de texto de v3 para las tareas STS)</li><li><strong>Recuperación de código</strong> (aprendido de v2-code, ausente en v3)</li></ul><p>Esta consolidación elimina los adaptadores de clasificación y separación de v3, enfocando v4 en los casos de uso de 向量模型 (Embedding) de mayor impacto: la recuperación y STS.</p><h3 id="output-embeddings" style="position: relative;"><a href="#output-embeddings" title="Output Embeddings" id="anchor-output-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Output Embeddings</h3><p>V4 introduce un sistema de salida dual que soporta tanto 向量模型 (Embeddings) de vector único como multi-vector, mientras que v3 solo proporcionaba salidas de vector único. Esto aborda diferentes escenarios de recuperación:</p><ul><li><strong>Modo de vector único</strong>: 向量模型 (Embeddings) de 2048 dimensiones (truncables a 128 a través de MRL) para una búsqueda de similitud eficiente</li><li><strong>Modo multi-vector</strong>: 128 dimensiones por 词元 (Token) para la <a href="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search">recuperación de interacción tardía</a></li></ul><p>Este enfoque dual proporciona una mayor eficacia con representaciones multi-vectoriales, particularmente en la recuperación de documentos visualmente ricos, manteniendo la eficiencia para las tareas de similitud estándar. La ventaja de rendimiento constante del 7-10% del modo multi-vector sobre el modo de vector único en las tareas visuales sugiere que la interacción tardía proporciona una coincidencia semántica fundamentalmente mejor para el contenido multimodal.</p><h3 id="parameter-size" style="position: relative;"><a href="#parameter-size" title="Parameter Size" id="anchor-parameter-size"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Parameter Size</h3><p>Si bien v4 es 6.7 veces más grande que v3 (3.8B vs 570M parámetros), las mejoras de rendimiento solo en texto son en realidad modestas, lo que sugiere que el escalamiento de parámetros fue impulsado principalmente por los requisitos multimodales en lugar de la mejora de texto. En los puntos de referencia de texto centrales, v4 alcanza 66.49 en MMTEB en comparación con los 58.58 de v3 (mejora del 14%) y 55.97 en MTEB-EN versus los 54.33 de v3 (mejora del 3%). Para la recuperación de código, v4 obtiene 71.59 en CoIR en comparación con los 55.07 de v3 (mejora del 30%), mientras que el rendimiento de documentos largos muestra v4 en 67.11 versus los 55.66 de v3 en LongEmbed (mejora del 21%). El escalamiento sustancial se justifica al considerar las capacidades multimodales de v4: alcanzar 84.11 nDCG@5 en la recuperación de documentos visuales (Jina-VDR) y 90.17 en los puntos de referencia de ViDoRe, capacidades totalmente ausentes en v3. El aumento de parámetros representa así nuestra inversión en la funcionalidad multimodal manteniendo un rendimiento de texto competitivo, con la arquitectura unificada eliminando la necesidad de modelos separados de texto y visión al tiempo que se logra una alineación intermodal de 0.71 en comparación con 0.15 para los enfoques tradicionales de codificador dual.</p><h2 id="getting-started" style="position: relative;"><a href="#getting-started" title="Empezando" id="anchor-getting-started"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Empezando</h2><p>Para una verificación rápida, pruebe nuestra demostración de texto a imagen en la caja de herramientas de Search Foundation. Hemos preparado una colección de imágenes de documentos de nuestro sitio web, y también puede agregar sus propias URL de imágenes. Simplemente escriba su consulta y presione enter para ver los resultados clasificados. Puede retirarlo ya sea como OCR o recuperación de imágenes basada en contenido; también siéntase libre de probar consultas en idiomas que no sean inglés.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://jina-ai-gmbh.ghost.io/content/media/2025/04/m0-demo-1_thumb.jpg" data-kg-custom-thumbnail="">
            <div class="kg-video-container" style="padding-bottom: 64.448%;">
                <video src="https://jina-ai-gmbh.ghost.io/content/media/2025/04/m0-demo-1.mp4" poster="https://img.spacergif.org/v1/1232x794/0a/spacer.png" width="1232" height="794" loop="" autoplay="" muted="" playsinline="" preload="metadata" style="background: transparent url('https://jina-ai-gmbh.ghost.io/content/media/2025/04/m0-demo-1_thumb.jpg') 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay kg-video-hide-animated">
                    <button class="kg-video-large-play-icon kg-video-hide-animated" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container kg-video-hide">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:22</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1×</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"></path>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">La demostración está disponible en: </span><a href="https://jina.ai/api-dashboard/m0-image-rerank"><span style="white-space: pre-wrap;">https://jina.ai/api-dashboard/m0-image-rerank</span></a><span style="white-space: pre-wrap;"> Tenga en cuenta que el uso de esta demostración consumirá los 词元 (Tokens) de su clave API principal. Además, la demostración puede parecer un poco lenta, ya que necesita descargar todas las imágenes en el servidor desde esas URL, y no se implementa el almacenamiento en caché para las imágenes.</span></p></figcaption>
        </figure><h3 id="via-api" style="position: relative;"><a href="#via-api" title="A través de la API" id="anchor-via-api"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>A través de la API</h3><p>El código a continuación muestra cómo usar <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a>. Puede pasar una cadena de texto, una imagen codificada en base64 o una URL de imagen. Los nuevos usuarios pueden obtener una clave API de Jina con 10 millones de 词元 (Tokens) gratuitos.</p><pre class="hljs-copy-wrapper"><code class="language-bash hljs">curl https://api.jina.ai/v1/embeddings \
  -H <span class="hljs-string">"Content-Type: application/json"</span> \
  -H <span class="hljs-string">"Authorization: Bearer JINA_API_KEY"</span> \
  -d @- &lt;&lt;<span class="hljs-string">EOFEOF
  {
    "model": "jina-embeddings-v4",
    "task": "text-matching",
    "input": [
        {
            "text": "A beautiful sunset over the beach"
        },
        {
            "text": "Un beau coucher de soleil sur la plage"
        },
        {
            "text": "海滩上美丽的日落"
        },
        {
            "text": "浜辺に沈む美しい夕日"
        },
        {
            "image": "https://i.ibb.co/nQNGqL0/beach1.jpg"
        },
        {
            "image": "https://i.ibb.co/r5w8hG8/beach2.jpg"
        },
        {
            "image": "iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAIAAABhUg/jAAAAMklEQVR4nO3MQREAMAgAoLkoFreTiSzhy4MARGe9bX99lEqlUqlUKpVKpVKpVCqVHksHaBwCA2cPf0cAAAAASUVORK5CYII="
        }
    ]
  }
EOFEOF</span>
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copiar</button></div></pre><p>Debido a los recursos limitados de la GPU, nuestra API de Vectorización (Embedding API) actualmente admite documentos de hasta 8K *tokens* (Tokens) de longitud, a pesar de la capacidad nativa de <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> para manejar hasta 32K *tokens* (Tokens). Para las aplicaciones que requieren contextos más largos de 8K *tokens* (Tokens) (como <a href="https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii">Late Chunking</a>), recomendamos implementar nuestros modelos a través de CSP o auto alojar el modelo.</p><h3 id="via-csp-marketplaces" style="position: relative;"><a href="#via-csp-marketplaces" title="A través de los mercados de CSP" id="anchor-via-csp-marketplaces"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>A través de los mercados de CSP</h3><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> pronto estará disponible directamente en AWS, Azure y GCP a los precios que se indican allí.</p><h3 id="via-huggingface" style="position: relative;"><a href="#via-huggingface" title="A través de HuggingFace" id="anchor-via-huggingface"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>A través de HuggingFace</h3><p>Para fines de investigación y experimentación, puede utilizar el modelo localmente desde nuestra página de Hugging Face. Hemos preparado un cuaderno de Google Colab que demuestra cómo funciona.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://colab.research.google.com/drive/1fb8jGCDPf-MXUnyXt-DNoe8_hmBDpDrl#scrollTo=M54aS0TvApyi"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Google Colab</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-38.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/colab_favicon_256px-9.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Conclusión" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Conclusión</h2><p><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> representa nuestro salto más significativo hasta el momento: un modelo de *vectorización* (embedding) universal de 3.8 mil millones de parámetros que procesa texto e imágenes a través de una vía unificada, que admite la recuperación densa y de interacción tardía, al tiempo que supera a los modelos propietarios de Google, OpenAI y Voyage AI, especialmente en la recuperación de documentos visualmente ricos. Pero esta capacidad no surgió de forma aislada; es la culminación de cuatro generaciones de resolución de limitaciones fundamentales.</p><p>Cuando comenzamos con <code>jina-embeddings-v1</code> a principios de 2022, todos asumieron que más datos significaban un mejor rendimiento. Demostramos lo contrario: filtrar 1.5 mil millones de pares a 385 millones de ejemplos de alta calidad superó a conjuntos de datos mucho más grandes. La lección: la selección supera a la recopilación.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2307.11224"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models</div><div class="kg-bookmark-description">Jina Embeddings constituye un conjunto de modelos de *vectorización* (embedding) de oraciones de alto rendimiento, expertos en la traducción de entradas textuales en representaciones numéricas, capturando la semántica del texto. Estos modelos sobresalen en aplicaciones como la recuperación densa y la similitud textual semántica. Este documento detalla el desarrollo de Jina Embeddings, comenzando con la creación de conjuntos de datos pareados y triplete de alta calidad. Subraya el papel crucial de la limpieza de datos en la preparación del conjunto de datos, ofrece información detallada sobre el proceso de entrenamiento del modelo y concluye con una evaluación exhaustiva del rendimiento utilizando el Massive Text Embedding Benchmark (MTEB). Además, para aumentar el conocimiento del modelo sobre la negación gramatical, construimos un nuevo conjunto de datos de entrenamiento y evaluación de declaraciones negadas y no negadas, que ponemos a disposición del público.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-35.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-31.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Pero los usuarios seguían topándose con el muro de 512 *tokens* (Tokens) de BERT. El entrenamiento en secuencias más largas parecía costoso, hasta que <code>jina-embeddings-v2</code> reveló una solución elegante: entrenar corto, implementar largo. Los sesgos de atención lineal de ALiBi permiten que los modelos entrenados en 512 *tokens* (Tokens) manejen sin problemas 8,192 *tokens* (Tokens) en la inferencia. Obtuvimos más capacidad por menos cómputo.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2310.19923"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents</div><div class="kg-bookmark-description">Los modelos de *vectorización* (embedding) de texto han surgido como herramientas poderosas para transformar oraciones en vectores de características de tamaño fijo que encapsulan información semántica. Si bien estos modelos son esenciales para tareas como la recuperación de información, la agrupación semántica y la *re-clasificación* (re-ranking) de texto, la mayoría de los modelos de código abierto existentes, especialmente los construidos sobre arquitecturas como BERT, luchan por representar documentos extensos y, a menudo, recurren al truncamiento. Un enfoque común para mitigar este desafío implica dividir los documentos en párrafos más pequeños para la *vectorización* (embedding). Sin embargo, esta estrategia da como resultado un conjunto mucho mayor de vectores, lo que en consecuencia conduce a un mayor consumo de memoria y búsquedas de vectores computacionalmente intensivas con una latencia elevada. Para abordar estos desafíos, presentamos Jina Embeddings 2, un modelo de *vectorización* (embedding) de texto de código abierto capaz de acomodar hasta 8192 *tokens* (Tokens). Este modelo está diseñado para trascender el límite convencional de 512 *tokens* (Tokens) y procesar hábilmente documentos largos. Jina Embeddings 2 no solo logra un rendimiento de vanguardia en una variedad de tareas relacionadas con *vectorización* (embedding) en el benchmark MTEB, sino que también coincide con el rendimiento del modelo propietario ada-002 de OpenAI. Además, nuestros experimentos indican que un contexto extendido puede mejorar el rendimiento en tareas como NarrativeQA.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-36.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-32.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>El éxito de <code>jina-embeddings-v2</code> expuso otra limitación: diferentes tareas necesitaban diferentes optimizaciones. En lugar de construir modelos separados, <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> utilizó pequeños adaptadores LoRA de 60M para personalizar un modelo base de 570M para cualquier tarea. Un modelo se convirtió en cinco modelos especializados.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2409.10173"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v3: Multilingual Embeddings With Task LoRA</div><div class="kg-bookmark-description">Presentamos jina-embeddings-v3, un nuevo modelo de *vectorización* (embedding) de texto con 570 millones de parámetros, que logra un rendimiento de vanguardia en datos multilingües y tareas de recuperación de contexto largo, que admite longitudes de contexto de hasta 8192 *tokens* (Tokens). El modelo incluye un conjunto de adaptadores de Adaptación de Bajo Rango (LoRA) específicos para cada tarea para generar *vectores* (embeddings) de alta calidad para la recuperación de documentos de consulta, la agrupación, la clasificación y la coincidencia de texto. La evaluación en el benchmark MTEB muestra que jina-embeddings-v3 supera a los últimos *vectores* (embeddings) propietarios de OpenAI y Cohere en tareas en inglés, al tiempo que logra un rendimiento superior en comparación con multilingual-e5-large-instruct en todas las tareas multilingües. Con una dimensión de salida predeterminada de 1024, los usuarios pueden reducir de forma flexible las dimensiones de *vectorización* (embedding) hasta 32 sin comprometer el rendimiento, lo que permite el aprendizaje de representación de Matryoshka.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-37.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Saba Sturua</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-33.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Incluso con la especialización de tareas, seguimos siendo solo texto, mientras que los usuarios necesitaban comprensión visual. Los modelos estándar basados en CLIP como <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v1" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v1</span></a> y <a class="dynamic-model-name" href="/?sui&amp;model=jina-clip-v2" target="_blank"><span class="dynamic-model-name-inner">jina-clip-v2</span></a> utilizan codificadores separados, creando una "brecha de modalidad" donde el contenido similar en diferentes formatos termina muy separado. Al igual que nuestro recientemente lanzado <a class="dynamic-model-name" href="/?sui&amp;model=jina-reranker-m0" target="_blank"><span class="dynamic-model-name-inner">jina-reranker-m0</span></a>, <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> eliminó esto por completo: una vía unificada procesa todo, eliminando la brecha en lugar de salvarla.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2506.18902"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval</div><div class="kg-bookmark-description">Presentamos jina-embeddings-v4, un modelo de *vectorización* (embedding) multimodal de 3.8 mil millones de parámetros que unifica las representaciones de texto e imagen a través de una nueva arquitectura que admite *vectores* (embeddings) de un solo vector y de múltiples vectores en el estilo de interacción tardía. El modelo incorpora adaptadores de Adaptación de Bajo Rango (LoRA) específicos para cada tarea para optimizar el rendimiento en diversos escenarios de recuperación, incluida la recuperación de información basada en consultas, la similitud semántica entre modalidades y la búsqueda de código de programación. Las evaluaciones integrales demuestran que jina-embeddings-v4 logra un rendimiento de vanguardia tanto en tareas de recuperación unimodales como intermodales, con una fuerza particular en el procesamiento de contenido visualmente rico, como tablas, gráficos, diagramas y formatos de medios mixtos. Para facilitar la evaluación de esta capacidad, también presentamos Jina-VDR, un nuevo benchmark diseñado específicamente para la recuperación de imágenes visualmente ricas.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-39.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-35.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>Tanto <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v4" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v4</span></a> como <a class="dynamic-model-name" href="/?sui&amp;model=jina-reranker-m0" target="_blank"><span class="dynamic-model-name-inner">jina-reranker-m0</span></a> comparten un cambio fundamental: el uso de *LLM* (LLM) como base en lugar de modelos de solo codificador. Esto no es una coincidencia, refleja una profunda ventaja que la mayoría pasa por alto: los modelos de solo codificador crean "brechas de modalidad" donde las imágenes se agrupan por separado del texto. Los modelos de solo decodificador abren posibilidades que no eran alcanzables con arquitecturas de solo codificador, incluida la verdadera representación de modalidad mixta y la explicabilidad.</p><p>Nuestra principal conclusión: los modelos de 向量模型 (embeddings) y la generación tratan sobre la comprensión de la semántica. Los 大模型 (LLM) que sobresalen en la generación, naturalmente, sobresalen en la representación. Creemos que el futuro reside en arquitecturas unificadas donde los modelos de 向量模型 (embedding) y el 重排器 (reranking) surgen del <strong>mismo modelo de base de búsqueda</strong>, y eso es exactamente hacia lo que Jina AI está construyendo.</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">Categorías:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Presentado</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">presione soltar</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fes%2Fnews%2Fjina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-ce90450d="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-ce90450d="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-ce90450d="" class="col-sm-12 col-md"><div data-v-ce90450d="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Oficinas</div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Sunnyvale, California</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, EE. UU.</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Berlín, Alemania (sede central)</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlín, Alemania</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Beijing, China</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Piso 5, Edificio 6, No.48 Haidian West St. Pekín, China</div></div></div><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-ce90450d="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center"><div data-v-ce90450d="" class="q-item__label">Shenzhen, China</div><div data-v-ce90450d="" class="q-item__label q-item__label--caption text-caption text-dim">Piso 402, Edificio de Tecnología Fu'an, Shenzhen, China</div></div></div></div></div><div data-v-ce90450d="" class="col-sm-12 col-md row"><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Fundación de búsqueda</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Lector</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Incrustaciones</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">reclasificador</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Búsqueda profunda</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Clasificador</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Segmentador</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Documentación API</div></a><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Obtener la clave API de Jina</div></div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Límite de velocidad</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-ce90450d="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Estado de la API</div></a></div><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Compañía</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Sobre nosotros</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Contactar con ventas</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Sala de prensa</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Programa de prácticas</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Únete a nosotros</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Descargar logotipo</div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-ce90450d="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-ce90450d="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Términos</div><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Seguridad</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Términos y condiciones</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Privacidad</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--main justify-center">Administrar cookies</div></a><a data-v-ce90450d="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-ce90450d="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-ce90450d="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-ce90450d="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-ce90450d="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-ce90450d="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-ce90450d="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>