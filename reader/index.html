<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>Reader API</title><meta charset="utf-8"><meta name="title" content="Reader API"><meta name="description" content="Read URLs or search the web, get better grounding for LLMs."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/reader"><meta property="og:title" content="Reader API"><meta property="og:description" content="Read URLs or search the web, get better grounding for LLMs."><meta property="og:image" content="https://jina.ai/banner-reader-api.png"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/reader"><meta property="twitter:title" content="Reader API"><meta property="twitter:description" content="Read URLs or search the web, get better grounding for LLMs."><meta property="twitter:image" content="https://jina.ai/banner-reader-api.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index.6593ed32.js"></script>
  <link rel="stylesheet" href="/assets/index.23b63892.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n.96d0e001.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.ba467cbb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register.b004ad1a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip.fb83122e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine.c58d34a1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard.5feffb01.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index.6593ed32.js"><link rel="stylesheet" href="/assets/prism-tomorrow.cee05018.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout.a8baedd4.js"><link rel="stylesheet" href="/assets/MainLayout.8e0f2d87.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTabPanels.9b3ab7e9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-panel.80bd631a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch.3df10340.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-cache.b0833c75.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel.e5fc2d69.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTabs.f11cf7d2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver.f4d21970.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/rtl.4aeb06d5.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown.a67ea57f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QImg.ceb9bda8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu.87a59b1d.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList.da51a04e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem.462df5d9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSlideTransition.63731eef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollArea.29cb03b7.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan.4edbea4a.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding.033daf1e.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup.478b0109.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSelect.3936dc21.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress.8af729f2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QForm.5552701f.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs.313f8c00.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/chunk.17bfede8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isArrayLike.a2a00cef.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/isObject.cef35763.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/toNumber.476d0739.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ReaderPage.51599a74.js"><link rel="stylesheet" href="/assets/ReaderPage.113aa5c4.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTable.a3cab869.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-fullscreen.5dcea7f9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/AskAnythingToolTip.fb86eb20.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useMetaTags.a6c8ef25.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/EmbeddingComponent.024f7731.js"><link rel="stylesheet" href="/assets/EmbeddingComponent.e1f3cea3.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ModelDropDown.260e18cb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/regexp.d033247d.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TitleBlock.5f478278.js"><link rel="stylesheet" href="/assets/TitleBlock.c519bf38.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/FAQComponent.b49ffc26.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PricingComponent.6bea2075.js"><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top text-white lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none" role="toolbar"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">reorder</i></span></button><hr class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-left" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--left q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(-300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">notifications</i></div><div class="q-item__section column q-item__section--main justify-center">News</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_a9096de0-4430-499d-9bd4-3c4936598708" aria-label="Expand &quot;Products&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon mdi mdi-package-variant" aria-hidden="true" role="presentation"> </i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Products</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_a9096de0-4430-499d-9bd4-3c4936598708" style="display: none;"><div class="q-list q-list--dark" label="Products"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Enterprises</span><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding.a8bdf010.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Embeddings</div><div class="q-item__label q-item__label--caption text-caption">Our world-class embeddings for search, RAG, agent systems.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker.9d8d3b88.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">Maximize the search relevancy and RAG accuracy at ease.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-active.aa2f2eb7.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reader</div><div class="q-item__label q-item__label--caption text-caption">Read URLs or search the web, get better grounding for LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/fine-tuning"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetune.2452513f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Auto Fine-Tuning</div><div class="q-item__label q-item__label--caption text-caption">Get fine-tuned embeddings for any domain you want.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Power Users</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Premier tool for prompt engineering</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_f4aa4e43-a2a4-42ba-82d2-d754778c1828" aria-label="Expand &quot;More power user tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More power user tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_f4aa4e43-a2a4-42ba-82d2-d754778c1828" style="display: none;"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Leading AI solution for image captions and video summaries</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Blog to banner, without the prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">More modality, longer memory, less cost</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimate AI decision-making tools</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">For Developers</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/docarray/docarray" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/doc-array.35372518.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DocArray</div><div class="q-item__label q-item__label--caption text-caption">The data structure for multimodal data</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jina" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/core.99751891.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jina</div><div class="q-item__label q-item__label--caption text-caption">Build multimodal AI applications on the cloud</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_f27de413-4f56-4e2c-9900-ee5ec42565f8" aria-label="Expand &quot;More developer tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">More developer tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_f27de413-4f56-4e2c-9900-ee5ec42565f8" style="display: none;"><div class="q-list q-list--dark"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/clip-as-service" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/clip-as-service.f454ca2a.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">CLIP-as-service</div><div class="q-item__label q-item__label--caption text-caption">Embed images and sentences into fixed-length vectors with CLIP</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/finetuner" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/finetuner.c62eaafa.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Finetuner</div><div class="q-item__label q-item__label--caption text-caption">Fine-tune embeddings on domain specific data for better search quality</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jcloud" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jcloud.669910ba.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JCloud</div><div class="q-item__label q-item__label--caption text-caption">Deploy a local project as a cloud service. Radically easy, no nasty surprises.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/langchain-serve" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/langchain-serve.8cf53254.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">LangChain-Serve</div><div class="q-item__label q-item__label--caption text-caption">Langchain apps on production with Jina &amp; FastAPI</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/vectordb" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/VectorDB.46be6cc1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">VectorDB</div><div class="q-item__label q-item__label--caption text-caption">A Python vector database you just need - no more, no less</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/dalle-flow" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dall-e-flow.ea199b2d.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DALL-E Flow</div><div class="q-item__label q-item__label--caption text-caption">A human-in-the-Loop workflow for creating HD images from text</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/discoart" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/disco-art.f21a267f.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DiscoArt</div><div class="q-item__label q-item__label--caption text-caption">Create compelling Disco Diffusion artworks in one line of code</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/thinkgpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/think-gpt.0a671280.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">ThinkGPT</div><div class="q-item__label q-item__label--caption text-caption">Agent techniques to augment your LLM and push it beyond its limits</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/dev-gpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/dev-gpt.a3e55036.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">DevGPT</div><div class="q-item__label q-item__label--caption text-caption">Your virtual development team</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/rungpt" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/run-gpt.5571707e.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">RunGPT</div><div class="q-item__label q-item__label--caption text-caption">An open-source cloud-native of large multimodal models serving framework</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://github.com/jina-ai/jerboa" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/jerboa.af6b308b.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Jerboa</div><div class="q-item__label q-item__label--caption text-caption">An experimental finetuner for open-source LLMs</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_feb760a8-2c39-4429-9169-e1ab7b942c3f" aria-label="Expand &quot;Company&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Company</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_feb760a8-2c39-4429-9169-e1ab7b942c3f" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">About us</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Contact sales</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/open-day"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Open day</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Intern program</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Join us</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://jina.ai/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Download logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">open_in_new</i></div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 524px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px;"></div></div><div class="row justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square text-caption q-pa-sm" tabindex="0" href="https://status.jina.ai" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Status</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square text-caption q-pa-sm" tabindex="0" href="/legal/#terms-and-conditions"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Terms</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square text-caption q-pa-sm" tabindex="0" href="/legal/#privacy-policy"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Privacy</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch q-btn--square q-pa-sm" tabindex="0" href="javascript:UC_UI.showSecondLayer();" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons-outlined" aria-hidden="true" role="img">settings</i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square q-pa-sm" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons-outlined" aria-hidden="true" role="img">science</i></span></button><label class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--float q-field--dense q-field--dark text-caption" for="f_c160a486-7095-40c9-b6c0-c70ba9941411"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-icons q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>English</span><input class="q-select__focus-target" id="f_c160a486-7095-40c9-b6c0-c70ba9941411" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_c160a486-7095-40c9-b6c0-c70ba9941411_lb"></div></div></div></div></label></div></div></aside></div><div class="q-page-container" style="padding-top: 56px; padding-bottom: 25px;"><main data-v-75350d50="" class="q-page" style="min-height: 519px;"><div data-v-75350d50="" class="row justify-center items-center img-bg q-pa-xl"><div data-v-75350d50="" class="col-12 col-md-11 q-py-xl q-mx-xs-xs q-mx-sm-sm q-mx-md-md q-mx-lg-lg q-mx-xl-xl q-ma-xl relative-position"><h1 data-v-5f7753d7="" class="q-pa-none q-ma-none" style="line-height: 1; font-size: inherit;"><span data-v-5f7753d7="" class="text-no-wrap my-subtitle">Reader</span></h1><div data-v-5f7753d7="" class="text-subtitle1 q-my-xl q-py-xl" style="width: 100%;">Get LLM-friendly input from a URL or a web search. Improve the factuality of your agent, RAG, GenAI system with a simple prefix.</div><div data-v-5f7753d7="" class="q-btn-group row no-wrap q-btn-group--outline q-btn-group--square inline"><a data-v-5f7753d7="" class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase q-btn--square lock-blur" tabindex="0" href="#apiform" style="font-size: 14px; padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">code</i><span class="block">API</span></span></a><hr data-v-5f7753d7="" class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a data-v-5f7753d7="" class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase q-btn--square lock-blur" tabindex="0" href="#demo" style="font-size: 14px; padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">play_arrow</i><span class="block">Demo</span></span></a><hr data-v-5f7753d7="" class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><a data-v-5f7753d7="" class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase q-btn--square lock-blur" tabindex="0" href="https://github.com/jina-ai/reader" style="font-size: 14px; padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left fab fa-github" aria-hidden="true" role="img"> </i><span class="block">Source code</span></span></a></div></div></div><div data-v-75350d50="" class="q-pa-xl" id="what_reader"><div data-v-75350d50="" class="row q-mt-xl q-pt-xl justify-center"><div data-v-75350d50="" class="q-mb-lg q-pb-md"><h2 data-v-75350d50="" class="text-h2 text-white q-mb-lg text-center justify-center">What is Reader?</h2></div></div><div data-v-75350d50="" class="row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8"><div data-v-75350d50="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/explain.00d2d1a4.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8 col-lg-6 text-subtitle1 q-pa-lg-xl q-my-lg" style="white-space: pre-line;">Feeding web information into LLMs is an important step of grounding, yet it can be challenging. The simplest method is to scrape the webpage and feed the raw HTML. However, scraping can be complex and often blocked, and raw HTML is cluttered with extraneous elements like markups and scripts. The Reader API addresses these issues by extracting the core content from a URL and converting it into clean, LLM-friendly text, ensuring high-quality input for your agent and RAG systems.</div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><button data-v-75350d50="" class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="padding: 24px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">play_arrow</i><span class="block">See how Reader reads a URL</span></span></button></div><div data-v-75350d50="" class="row q-mt-xl q-pt-xl justify-center"><div data-v-75350d50="" class="q-mb-lg q-pb-md"><h3 data-v-75350d50="" class="text-h3 text-white q-mb-lg text-center justify-center">Reader for search grounding</h3></div></div><div data-v-75350d50="" class="row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8"><div data-v-75350d50="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/explain3.ddb193be.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8 col-lg-6 text-subtitle1 q-pa-lg-xl q-my-lg" style="white-space: pre-line;"><span data-v-75350d50="">LLMs have a knowledge cut-off, meaning they can't access the latest world knowledge. This leads to problems such as misinformation, outdated responses, hallucinations, and other factuality issues. Grounding is absolutely essential for GenAI applications. Reader allows you to ground your LLM with the latest information from the web. Simply prepend <code>https://s.jina.ai/</code> to your query, and Reader will search the web and return the top five results with their URLs and contents, each in clean, LLM-friendly text. This way, you can always keep your LLM up-to-date, improve its factuality, and reduce hallucinations.</span></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><button data-v-75350d50="" class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="padding: 24px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">play_arrow</i><span class="block">See how Reader searches the web</span></span></button></div><div data-v-75350d50="" class="row q-mt-xl q-pt-xl justify-center"><div data-v-75350d50="" class="q-mb-lg q-pb-md"><h3 data-v-75350d50="" class="text-h3 text-white q-mb-lg text-center justify-center">Reader also reads images!</h3></div></div><div data-v-75350d50="" class="row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8"><div data-v-75350d50="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/explain2.eda58d92.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8 col-lg-6 text-subtitle1 q-pa-lg-xl q-my-lg" style="white-space: pre-line;">Images on the webpage are automatically captioned using a vision language model in the reader and formatted as image alt tags in the output. This gives your downstream LLM just enough hints to incorporate those images into its reasoning and summarizing processes. This means you can ask questions about the images, select specific ones, or even forward their URLs to a more powerful VLM for deeper analysis!</div></div><div data-v-75350d50="" class="row q-mt-xl q-pt-xl justify-center"><div data-v-75350d50="" class="q-mb-lg q-pb-md"><h3 data-v-75350d50="" class="text-h3 text-white q-mb-lg text-center justify-center">The best part? It's free!</h3></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><div data-v-75350d50="" class="col-11 col-md-8 col-lg-6 text-subtitle1 q-pa-lg-xl q-my-lg" style="white-space: pre-line;">Reader API is available for free and offers flexible rate limit and pricing. Built on a scalable infrastructure, it offers high accessibility, concurrency, and reliability. We strive to be your preferred grounding solution for your LLMs.</div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center" id="rate-limit"><div data-v-75350d50="" class="col-11 col-md-8 text-subtitle1 q-my-lg" style="white-space: pre-line;"><div data-v-75350d50="" class="q-markup-table q-table__container q-table__card q-table--cell-separator q-table--dark q-table__card--dark q-dark q-table--flat q-table--bordered q-table--square bg-transparent"><table class="q-table"><thead data-v-75350d50=""><tr data-v-75350d50=""><th data-v-75350d50="">Endpoint</th><th data-v-75350d50="">Description</th><th data-v-75350d50="">Rate limit w/o API key</th><th data-v-75350d50="">Rate limit with API key</th><th data-v-75350d50="">Token counting scheme</th><th data-v-75350d50="">Average latency</th></tr></thead><tbody data-v-75350d50=""><tr data-v-75350d50=""><td data-v-75350d50=""><code data-v-75350d50="">r.jina.ai</code></td><td data-v-75350d50="">Read a URL return its content, useful for check grounding</td><td data-v-75350d50="">20 RPM</td><td data-v-75350d50="">200 RPM</td><td data-v-75350d50="">Based on the output tokens</td><td data-v-75350d50="">3 seconds</td></tr><tr data-v-75350d50=""><td data-v-75350d50=""><code data-v-75350d50="">s.jina.ai</code></td><td data-v-75350d50="">Search on the web return top-5 results, useful for search grounding</td><td data-v-75350d50="">5 RPM</td><td data-v-75350d50="">40 RPM</td><td data-v-75350d50="">Based on the output tokens for all 5 search results</td><td data-v-75350d50="">10 seconds</td></tr></tbody></table></div></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center text-subtitle1">Don't panic! Every new API key contains one million free tokens!</div></div><div data-v-75350d50="" class="q-pa-xl bg-dark" id="demo"><div data-v-75350d50="" class="row q-mt-xl q-pt-xl justify-center"><div data-v-75350d50="" class="q-mb-lg q-pb-md"><h2 data-v-75350d50="" class="text-h2 text-white q-mb-lg text-center justify-center">Try the demo</h2></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><div data-v-75350d50="" class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-label="See how Reader searches the web" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true" style="font-size: 60px;"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"><i class="q-icon text-null notranslate material-icons" aria-hidden="true" role="presentation">double_arrow</i></div></div><span class="no-outline" tabindex="-1"></span><div class="q-toggle__label q-anchor--skip">See how Reader searches the web</div></div></div><div data-v-75350d50="" class="q-my-xl row justify-center items-center"><div data-v-75350d50="" class="q-card q-card--dark q-dark q-card--bordered q-card--square no-border-radius q-card--flat no-shadow col-12 col-md-10" style="display: none;"><div class="q-card__section q-card__section--vert"><div class="q-card__section q-card__section--vert col"><label class="q-field row no-wrap items-start q-field--standard q-input q-field--float q-field--labeled q-field--dark q-field--with-bottom" for="f_811ed1be-2145-4a11-92a5-83b4539de387"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">casino</i></span></button></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Enter your query" id="f_811ed1be-2145-4a11-92a5-83b4539de387" type="url"><div class="q-field__label no-pointer-events absolute ellipsis">Enter your query</div></div></div><div class="q-field__bottom row items-start q-field__bottom--animated"><div class="q-field__messages col"><div>Type a question that requires latest information or world knowledge.</div></div></div></div></label></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert col"><label class="q-field row no-wrap items-start q-field--standard q-input q-field--float q-field--labeled q-field--dark q-field--with-bottom q-field--readonly" for="f_bfea51b7-2c7e-4228-8455-62c59b01a41b"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Reader URL" id="f_bfea51b7-2c7e-4228-8455-62c59b01a41b" readonly="" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Reader URL</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">content_copy</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div></div><div class="q-field__bottom row items-start q-field__bottom--animated"><div class="q-field__messages col">If you use this URL in code, dont forget to encode the URL.</div></div></div></label></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><button class="q-btn q-btn-item non-selectable no-outline q-btn--standard q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square full-width" tabindex="0" type="button" style="padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">contact_support</i><span class="block">Ask LLM w/o &amp; w/ Search Grounding</span></span></button><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert q-pa-none"><div class="q-card__section q-card__section--vert col"><span class="text-caption text-bold text-grey-5">Ask LLM directly</span><div class="q-card__section q-card__section--vert"><i class="q-icon q-mr-sm" aria-hidden="true" role="presentation"><img src="https://promptperfect.jina.ai/PromptPerfect-dark.svg"></i><div class="q-skeleton q-skeleton--dark q-skeleton--type-text q-skeleton--anim q-skeleton--anim-wave q-my-xs" style="--q-skeleton-speed:1500ms; width: 100px;"></div><div class="q-skeleton q-skeleton--dark q-skeleton--type-text q-skeleton--anim q-skeleton--anim-wave q-my-xs" style="--q-skeleton-speed:1500ms;"></div><div class="q-skeleton q-skeleton--dark q-skeleton--type-text q-skeleton--anim q-skeleton--anim-wave q-my-xs" style="--q-skeleton-speed:1500ms;"></div><div class="q-skeleton q-skeleton--dark q-skeleton--type-text q-skeleton--anim q-skeleton--anim-wave q-my-xs" style="--q-skeleton-speed:1500ms;"></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert col"><span class="text-caption text-bold text-grey-5">Reader's response</span><div class="q-markdown" style="max-height: 300px;"><pre class="q-markdown--code q-markdown--code__inner language-plaintext"><code>[1] Title: OpenAI and Elon Musk
[1] URL Source: https://openai.com/blog/openai-elon-musk
[1] Markdown Content:
March 5, 2024

We are dedicated to the OpenAI mission and have pursued it every step of the way.

The mission of OpenAI is to ensure AGI benefits all of humanity, which means both building safe and beneficial AGI and helping create broadly distributed benefits. We are now sharing what we've learned about achieving our mission, and some facts about our relationship with Elon. We intend to move to dismiss all of Elon’s claims.

We realized building AGI will require far more resources than we’d initially imagined
-------------------------------------------------------------------------------------

_Elon said we should announce an initial $1B funding commitment to OpenAI. In total, the non-profit has raised less than $45M from Elon and more than $90M from other donors._

When starting OpenAI in late 2015, Greg and Sam had initially planned to raise $100M. Elon said in an email: “We need to go with a much bigger number than $100M to avoid sounding hopeless… I think we should say that we are starting with a $1B funding commitment… I will cover whatever anyone else doesn't provide.” [\[1\]](#email-1)

We spent a lot of time trying to envision a plausible path to AGI. In early 2017, we came to the realization that building AGI will require vast quantities of compute. We began calculating how much compute an AGI might plausibly require. We all understood we were going to need a lot more capital to succeed at our mission—billions of dollars per year, which was far more than any of us, especially Elon, thought we’d be able to raise as the non-profit.

We and Elon recognized a for-profit entity would be necessary to acquire those resources
----------------------------------------------------------------------------------------

_As we discussed a for-profit structure in order to further the mission, Elon wanted us to merge with Tesla or he wanted full control. Elon left OpenAI, saying there needed to be a relevant competitor to Google/DeepMind and that he was going to do it himself. He said he’d be supportive of us finding our own path._

In late 2017, we and Elon decided the next step for the mission was to create a for-profit entity. Elon wanted majority equity, initial board control, and to be CEO. In the middle of these discussions, he withheld funding. Reid Hoffman bridged the gap to cover salaries and operations.

We couldn’t agree to terms on a for-profit with Elon because we felt it was against the mission for any individual to have absolute control over OpenAI. He then suggested instead merging OpenAI into Tesla. In early February 2018, Elon forwarded us an email suggesting that OpenAI should “attach to Tesla as its cash cow”, commenting that it was “exactly right… Tesla is the only path that could even hope to hold a candle to Google. Even then, the probability of being a counterweight to Google is small. It just isn’t zero”. [\[2\]](#email-2)

Elon soon chose to leave OpenAI, saying that our probability of success was 0, and that he planned to build an AGI competitor within Tesla. When he left in late February 2018, he told our team he was supportive of us finding our own path to raising billions of dollars. In December 2018, Elon sent us an email saying “Even raising several hundred million won’t be enough. This needs billions per year immediately or forget it.” [\[3\]](#email-3)

We advance our mission by building widely-available beneficial tools
--------------------------------------------------------------------

_We’re making our technology broadly usable in ways that empower people and improve their daily lives, including via open-source contributions._

We provide broad access to today's most powerful AI, including a free version that hundreds of millions of people use every day. For example, Albania is using OpenAI’s tools to accelerate its EU accession by as much as 5.5 years; Digital Green is helping boost farmer income in Kenya and India by dropping the cost of agricultural extension services 100x by building on OpenAI; Lifespan, the largest healthcare provider in Rhode Island, uses GPT-4 to simplify its surgical consent forms from a college reading level to a 6th grade one; Iceland is using GPT-4 to preserve the Icelandic language.

Elon understood the mission did not imply open-sourcing AGI. As Ilya told Elon: “As we get closer to building AI, it will make sense to start being less open.  The Open in openAI means that everyone should benefit from the fruits of AI after its built, but it's totally OK to not share the science...”, to which Elon replied: “Yup”. [\[4\]](#email-4)

We're sad that it's come to this with someone whom we’ve deeply admired—someone who inspired us to aim higher, then told us we would fail, started a competitor, and then sued us when we started making meaningful progress towards OpenAI’s mission without him.

We are focused on advancing our mission and have a long way to go. As we continue to make our tools better and better, we are excited to deploy these systems so they empower every individual.

Update March 11, 2024: We are seeking to have the lawsuit assigned to dedicated case management, since it involves AI technology and the claims span almost a decade.

\[1\]

Date: Sun, Nov 22, 2015 at 7:48 PM

Subject: follow up from call

Blog sounds good, assuming adjustments for neutrality vs being YC-centric.

I'd favor positioning the blog to appeal a bit more to the general public -- there is a lot of value to having the public root for us to succeed -- and then having a longer, more detailed and inside-baseball version for recruiting, with a link to it at the end of the general public version.

We need to go with a much bigger number than $100M to avoid sounding hopeless relative to what Google or Facebook are spending. I think we should say that we are starting with a $1B funding commitment. This is real. I will cover whatever anyone else doesn't provide.

Template seems fine, apart from shifting to a vesting cash bonus as default, which can optionally be turned into YC or potentially SpaceX (need to understand how much this will be) stock.

\[2\]

To:

Ilya Sutskever &lt;

\&gt;, Greg Brockman &lt;

\&gt;

Date: Thu, Feb 1, 2018 at 3:52 AM

Subject: Fwd: Top AI institutions today

is exactly right. We may wish it otherwise, but, in my and

’s opinion, Tesla is the only path that could even hope to hold a candle to Google. Even then, the probability of being a counterweight to Google is small. It just isn't zero.

Begin forwarded message:

Date: January 31, 2018 at 11:54:30 PM PST

Subject: Re: Top AI institutions today

Working at the cutting edge of AI is unfortunately expensive. For example,

In addition to DeepMind, Google also has Google Brain, Research, and Cloud. And TensorFlow, TPUs, and they own about a third of all research (in fact, they hold their own AI conferences).

I also strongly suspect that compute horsepower will be necessary (and possibly even sufficient) to reach AGI. If historical trends are any indication, progress in AI is primarily driven by systems - compute, data, infrastructure. The core algorithms we use today have remained largely unchanged from the ~90s. Not only that, but any algorithmic advances published in a paper somewhere can be almost immediately re-implemented and incorporated. Conversely, algorithmic advances alone are inert without the scale to also make them scary.

It seems to me that OpenAI today is burning cash and that the funding model cannot reach the scale to seriously compete with Google (an 800B company). If you can't seriously compete but continue to do research in open, you might in fact be making things worse and helping them out “for free”, because any advances are fairly easy for them to copy and immediately incorporate, at scale.

A for-profit pivot might create a more sustainable revenue stream over time and would, with the current team, likely bring in a lot of investment. However, building out a product from scratch would steal focus from AI research, it would take a long time and it's unclear if a company could “catch up” to Google scale, and the investors might exert too much pressure in the wrong directions.The most promising option I can think of, as I mentioned earlier, would be for OpenAI to attach to Tesla as its cash cow. I believe attachments to other large suspects (e.g. Apple? Amazon?) would fail due to an incompatible company DNA. Using a rocket analogy, Tesla already built the “first stage” of the rocket with the whole supply chain of Model 3 and its onboard computer and a persistent internet connection. The “second stage” would be a full self driving solution based on large-scale neural network training, which OpenAI expertise could significantly help accelerate. With a functioning full self-driving solution in ~2-3 years we could sell a lot of cars/trucks. If we do this really well, the transportation industry is large enough that we could increase Tesla's market cap to high O(~100K), and use that revenue to fund the AI work at the appropriate scale.

I cannot see anything else that has the potential to reach sustainable Google-scale capital within a decade.

\[3\]

To:

Ilya Sutskever &lt;

\&gt;, Greg Brockman &lt;

\&gt;

Date: Wed, Dec 26, 2018 at 12:07 PM

Subject: I feel I should reiterate

My probability assessment of OpenAI being relevant to DeepMind/Google without a dramatic change in execution and resources is 0%. Not 1%. I wish it were otherwise.

Even raising several hundred million won't be enough. This needs billions per year immediately or forget it.

Unfortunately, humanity's future is in the hands of

.

And they are doing a lot more than this.

I really hope I'm wrong.

Elon

\[4\]

Fwd: congrats on the falcon 93 messages

To:

Sam Altman &lt;

\&gt;, Ilya Sutskever &lt;

\&gt;, Greg Brockman &lt;

\&gt;

Date: Sat, Jan 2, 2016 at 8:18 AM

Subject: Fwd: congrats on the falcon 9

Begin forwarded message:

Date: January 2, 2016 at 10:12:32 AM CST

Subject: congrats on the falcon 9

Hi Elon

Happy new year to you,

!

Congratulations on landing the Falcon 9, what an amazing achievement. Time to build out the fleet now!

I've seen you (and Sam and other OpenAI people) doing a lot of interviews recently extolling the virtues of open sourcing AI, but I presume you realise that this is not some sort of panacea that will somehow magically solve the safety problem? There are many good arguments as to why the approach you are taking is actually very dangerous and in fact may increase the risk to the world. Some of the more obvious points are well articulated in this blog post, that I'm sure you've seen, but there are also other important considerations:  
http://slatestarcodex.com/2015/12/17/should-ai-be-open/

I’d be interested to hear your counter-arguments to these points.

Best

To:

Elon Musk &lt;

\&gt;, Sam Altman &lt;

\&gt;, Greg Brockman &lt;

\&gt;

Date: Sat, Jan 2, 2016 at 9:06 AM

Subject: Fwd: congrats on the falcon 9

The article is concerned with a hard takeoff scenario: if a hard takeoff occurs, and a safe AI is harder to build than an unsafe one, then by opensorucing everything, we make it easy for someone unscrupulous with access to overwhelming amount of hardware to build an unsafe AI, which will experience a hard takeoff.

As we get closer to building AI, it will make sense to start being less open. The Open in openAI means that everyone should benefit from the fruits of AI after its built, but it's totally OK to not share the science (even though sharing everything is definitely the right strategy in the short and possibly medium term for recruitment purposes).

Date: Sat, Jan 2, 2016 at 9:11 AM

Subject: Fwd: congrats on the falcon 9

Yup

*   [Announcements](https://openai.com/news/company/?tags=topic-announcements)


[2] Title: Elon Musk Ramps Up A.I. Efforts, Even as He Warns of Dangers
[2] URL Source: https://www.nytimes.com/2023/04/27/technology/elon-musk-ai-openai.html
[2] Published Time: 2023-04-27T09:00:23.000Z
[2] Markdown Content:
You have a preview view of this article while we are checking your access. When we have confirmed access, the full article content will load.

![Image 1: Several images of Elon Musk’s face, some with blank speech bubbles, are stacked in a colorful collage.](https://static01.nyt.com/images/2023/04/28/business/00ai-musk/00ai-musk-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale)

Credit...Chris Burnett

The billionaire plans to compete with OpenAI, the ChatGPT developer he helped found, while calling out the potential harms of artificial intelligence.

Credit...Chris Burnett

[Cade Metz](https://www.nytimes.com/by/cade-metz), [Ryan Mac](https://www.nytimes.com/by/ryan-mac) and [Kate Conger](https://www.nytimes.com/by/kate-conger)

Cade Metz writes about artificial intelligence. Ryan Mac and Kate Conger report on Twitter and Elon Musk.

*   April 27, 2023

In December, [Elon Musk](https://www.nytimes.com/2018/06/09/technology/elon-musk-mark-zuckerberg-artificial-intelligence.html) became angry about the development of artificial intelligence and put his foot down.

He had learned of a relationship between [OpenAI](https://www.nytimes.com/2023/01/23/business/microsoft-chatgpt-artificial-intelligence.html), the start-up behind the popular chatbot ChatGPT, and Twitter, which he had [bought in October](https://www.nytimes.com/2022/10/27/technology/elon-musk-twitter-deal-complete.html) for $44 billion. OpenAI was licensing Twitter’s data — a feed of every tweet — for about $2 million a year to help build ChatGPT, two people with knowledge of the matter said. Mr. Musk believed the A.I. start-up wasn’t paying Twitter enough, they said.

So Mr. Musk cut OpenAI off from Twitter’s data, they said.

Since then, Mr. Musk has ramped up his own A.I. activities, while arguing publicly about the technology’s hazards. He is in talks with Jimmy Ba, a researcher and professor at the University of Toronto, to build a new A.I. company called X.AI, three people with knowledge of the matter said. He has hired top A.I. researchers from Google’s DeepMind at Twitter. And he has spoken publicly about creating a rival to ChatGPT that generates politically charged material without restrictions.

The actions are part of Mr. Musk’s long and complicated history with A.I., governed by his contradictory views on whether the technology will ultimately benefit or destroy humanity. Even as he recently jump-started his A.I. projects, he also [signed an open letter](https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html) last month calling for a six-month pause on the technology’s development because of its “profound risks to society.”

And although Mr. Musk is pushing back against OpenAI and plans to compete with it, he helped found the A.I. lab in 2015 as a nonprofit. He has since said he has grown disillusioned with OpenAI because it no longer operates as a nonprofit and is building technology that, in his view, takes sides in political and social debates.

What Mr. Musk’s A.I. approach boils down to is doing it himself. The 51-year-old billionaire, who also runs the electric carmaker Tesla and the rocket company SpaceX, has long seen his own A.I efforts as offering better, safer alternatives than those of his competitors, according to people who have discussed these matters with him.

* * *

Thank you for your patience while we verify access. If you are in Reader mode please exit and [log into](https://myaccount.nytimes.com/auth/login?response_type=cookie&amp;client_id=vi&amp;redirect_uri=https%3A%2F%2Fwww.nytimes.com%2F2023%2F04%2F27%2Ftechnology%2Felon-musk-ai-openai.html&amp;asset=opttrunc) your Times account, or [subscribe](https://www.nytimes.com/subscription?campaignId=89WYR&amp;redirect_uri=https%3A%2F%2Fwww.nytimes.com%2F2023%2F04%2F27%2Ftechnology%2Felon-musk-ai-openai.html) for all of The Times.

* * *

Thank you for your patience while we verify access.

Already a subscriber? [Log in](https://myaccount.nytimes.com/auth/login?response_type=cookie&amp;client_id=vi&amp;redirect_uri=https%3A%2F%2Fwww.nytimes.com%2F2023%2F04%2F27%2Ftechnology%2Felon-musk-ai-openai.html&amp;asset=opttrunc).

Want all of The Times? [Subscribe](https://www.nytimes.com/subscription?campaignId=89WYR&amp;redirect_uri=https%3A%2F%2Fwww.nytimes.com%2F2023%2F04%2F27%2Ftechnology%2Felon-musk-ai-openai.html).

Advertisement

[SKIP ADVERTISEMENT](#after-bottom)


[3] Title: Elon Musk reportedly tried and failed to take over OpenAI in 2018
[3] URL Source: https://www.theverge.com/2023/3/24/23654701/openai-elon-musk-failed-takeover-report-closed-open-source
[3] Published Time: 2023-03-24T12:38:00.640Z
[3] Markdown Content:
Now here’s a path not taken: according to a [new report from _Semafor_](https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai), Elon Musk tried — and failed — to take over [ChatGPT](https://www.theverge.com/2022/12/8/23499728/ai-capability-accessibility-chatgpt-stable-diffusion-commercialization) creator OpenAI in 2018.

Musk was part of a small group that founded the AI lab in 2015 as a nonprofit, intending the firm to share research for the wider benefit of society. But by early 2018, says _Semafor_, Musk was worried the company was falling behind Google. He reportedly offered to take direct control of OpenAI and run it himself but was rejected by other OpenAI founders including Sam Altman, now the firm’s CEO, and Greg Brockman, now its president.

Crucially, when Musk walked away from the company — he resigned from its board in 2018 [citing a conflict of interest](https://www.theverge.com/2018/2/21/17036214/elon-musk-openai-ai-safety-leaves-board) with his work at Tesla — _Semafor_ says he also reneged on a promise to supply $1 billion in funding, contributing only $100 million before he walked. This left OpenAI with a problem, as its work developing large-scale AI models like image generator DALL-E and the text-generating GPT series was racking up huge bills. So by 2019, OpenAI announced it was creating a new for-profit entity to fund its research and quickly became closely entangled with Microsoft, which supplied [billions in funding and resources](https://www.theverge.com/2019/7/22/20703578/microsoft-openai-investment-partnership-1-billion-azure-artificial-general-intelligence-agi) while securing exclusive licenses to use OpenAI’s tech in its products.

Musk’s rejection seemingly changed OpenAI’s trajectory, pushing it toward corporate interests

_Semafor_ does not state outright that Musk’s lost funding was what pushed OpenAI into bed with Microsoft, but it’s a plausible interpretation. (We’ve reached out to OpenAI for comment on the story and will update if we hear back.) This is what makes the report so significant, as many in the AI community see OpenAI’s turn toward corporate interests as a huge moment for AI and the world — not just as a betrayal of OpenAI’s founding principles but as a spur for the company to launch new AI products as quickly as possible, an attitude many think could have dangerous consequences.

OpenAI’s turn toward Microsoft has certainly changed how the company shares its research. When OpenAI announced its latest AI language model, GPT-4, earlier this month, many experts were dismayed that it did not share details about how it was created or its training data. In an [interview with _The Verge_](https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview), Ilya Sutskever, OpenAI’s chief scientist, explained that this was to keep the company’s competitive advantage over rivals (and, as a future consideration, to stop misuse of its technology). But many AI experts say shutting down access to OpenAI’s models makes it harder for the community to understand potential threats posed by these systems and concentrates power in corporate hands.

Since OpenAI became entangled with Microsoft, the two companies have been launching AI services and products at a blistering pace, with Microsoft integrating OpenAI’s tech into Windows and its Office suite. And just this week, OpenAI announced it would be massively expanding the capabilities of its chatbot ChatGPT by letting the system [interface with other sites and services via plug-ins](https://www.theverge.com/2023/3/23/23653591/openai-chatgpt-plugins-launch-web-browsing-third-party). OpenAI said it was like giving the bot “eyes and ears,” while some experts voiced concern the move presents a safety threat.

Musk has expressed dismay about this change in OpenAI’s trajectory numerous times. In February, he [tweeted](https://twitter.com/elonmusk/status/1626516035863212034?s=20) that OpenAI “has become a closed source, maximum-profit company effectively controlled by Microsoft,” adding that this was “not what I intended at all.” (It’s worth remembering, of course, that Musk is nothing if not self-interested in this matter and a skilled manipulator of public narratives, always eager to position himself as a hero.) Last Friday, he [tweeted](https://twitter.com/elonmusk/status/1639200036578885632?s=20) a meme with the caption “Me realizing AI, the most powerful tool that mankind has ever created, is now in the hands of a ruthless corporate monopoly.”


[4] Title: Elon Musk claims he's the reason ChatGPT-owner OpenAI exists
[4] URL Source: https://www.cnbc.com/2023/05/16/elon-musk-says-hes-the-reason-chatgpt-owner-openai-exists.html
[4] Published Time: 2023-05-16T23:30:52+0000
[4] Markdown Content:
![Image 1: Elon Musk on Sam Altman and ChatGPT: I am the reason OpenAI exists](https://image.cnbcfm.com/api/v1/image/107242259-16842785931684278590-29482801034-1080pnbcnews.jpg?v=1684278868&amp;w=750&amp;h=422&amp;vtcrop=y)

[Tesla](https://www.cnbc.com/quotes/TSLA/) CEO Elon Musk claimed on Tuesday he is “the reason that OpenAI exists,” citing his past investment in the entity, and that Microsoft exerts control over the AI company, an assertion [strongly denied](https://www.cnbc.com/2023/05/16/nadella-disputes-musks-claims-that-microsoft-controls-openai-.html) by [Microsoft](https://www.cnbc.com/quotes/MSFT/) CEO Satya Nadella.

“I came up with the name,” Musk told CNBC’s David Faber. He also said he was instrumental in recruiting key scientists and engineers at the company.

Musk has previously repeatedly asserted that Microsoft controls OpenAI and that OpenAI’s capped-profit model is questionable. Musk was an [early backer](https://www.cnbc.com/2023/03/24/openai-ceo-sam-altman-didnt-take-any-equity-in-the-company-semafor.html) of the AI startup, reportedly committing to $1 billion in support before pulling out over disagreements over the speed of OpenAI’s advancements. He said he ultimately invested somewhere around $50 million.

He also suggested that OpenAI didn’t place sufficient emphasis on safe AI development. Musk was a signatory to a March [open letter](https://www.cnbc.com/2023/03/29/elon-musk-other-tech-leaders-pause-training-ai-beyond-gpt-4.html) asking for a pause in advanced AI development while safeguards were established but told Faber that he knew the letter was unlikely to do anything.

Despite signing the letter, Musk still incorporated a rival AI firm, X.AI, in April.

But Musk added that signing the letter warning of the dangers of AI was something he wanted to do “for the record.”

An OpenAI spokesperson was not immediately available to comment.

Separately, Musk told Faber that he used to be close friends with Google co-founder Larry Page and that the two of them would have lengthy conversations about the nature of artificial intelligence.

Page was “quite cavalier” about AI, Musk claimed. Page “did not seem to be concerned about AI safety,” Musk alleged, and said, “The final straw was Larry calling me a ‘species-ist’ for being pro-human consciousness instead of machine consciousness.”

Larry Page was not immediately available for comment.


[5] Title: Elon Musk Trolls His Way Into the OpenAI Drama
[5] URL Source: https://www.wired.com/story/elon-musk-troll-openai-drama/
[5] Published Time: 2023-11-21T20:43:12.098-05:00
[5] Markdown Content:
Elon Musk needed fewer than 100 characters to add new chaos to the ongoing crisis swirling around OpenAI after the shock firing of CEO Sam Altman last week.

In a [post on X](https://x.com/elonmusk/status/1727096607752282485?s=46) on Tuesday, Musk drew attention to an anonymous letter accusing Altman of various examples of underhanded behavior as CEO of [OpenAI](https://www.wired.com/tag/openai/).

The link shared by Musk was to a copy of the letter uploaded to GitHub, a resource for sharing code. That copy of the letter was removed less than an hour after Musk posted it. Sources with knowledge of Altman's tenure at OpenAI told WIRED they were not familiar with the accusations. Altman did not immediately reply to a request for comment.

The GitHub profile that posted the letter contained an email address, and a person who responded to an email sent to that address told WIRED they first saw it via a discussion on Hacker News. They copied and reposted the text from the original, found on [Board.net](http://board.net/), which allows anonymous posts. The person said they later removed their copy of the letter to preserve their privacy, adding, “I have no idea as to the veracity of any of the contents.”

An email sent to an address included in the letter did not immediately receive a response.

“These seem like concerns worth investigating,” Musk wrote in his post linking to the unsigned [letter](https://gist.github.com/Xe/32d7bc436e401f3323ae77e7e242f858), which is addressed to OpenAI’s board and purports to have been written by concerned former employees of the company. WIRED has not been able to verify the authenticity of any of the claims.

Since Altman’s exit last week, for reasons [not yet made clear by the board that fired him](https://www.wired.com/story/mystery-at-the-heart-of-the-openai-chaos/), OpenAI’s current employees have shown striking loyalty. On Monday, more than [95 percent of the company's staff](https://www.wired.com/story/95-percent-of-openai-employees-threaten-to-follow-sam-altman-out-the-door/) signed an open letter saying they were willing to leave the company if Altman wasn’t restored.

The anonymous letter boosted by Musk makes allegations against Altman and also Greg Brockman, an OpenAI cofounder who was removed as board chair last week and then quit over Altman’s treatment. “Throughout our time at OpenAI, we witnessed a disturbing pattern of deceit and manipulation by Sam Altman and Greg Brockman, driven by their insatiable pursuit of achieving artificial general intelligence (AGI),” the letter alleges.

Musk has himself been accused of similar behavior at several of his own ventures, which include automaker Tesla, rocket maker SpaceX, and brain interface developer Neuralink.

The letter also calls for OpenAI’s board of directors, which fired Altman on Friday, to expand the scope of its investigation into Altman’s alleged impropriety. Bloomberg [reported Tuesday](https://www.bloomberg.com/news/articles/2023-11-21/altman-openai-board-open-talks-to-negotiate-his-possible-return?srnd=technology-vp#xj4y7vzkg) that the board was negotiating with the fired CEO about a potential return to the company. _The New York Times_ [reported](https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html) that Altman fell out with board members in part over a critical research paper written by one of them.

Substantial questions around the letter’s authenticity notwithstanding, Musk’s drawing attention to its accusations adds to existing tensions between him and Altman. Although the pair were the most prominent of OpenAI’s original cofounders, they have since reportedly fallen out and this year became more direct rivals when Musk [launched a new AI company](https://www.wired.com/story/fast-forward-elon-musks-xai-chatgpt-hallucinating/), xAI, to compete with ChatGPT.

When Altman began talking to people about [the idea of starting a new AI lab](https://www.wired.com/story/what-openai-really-wants/), Musk was one of the people he sought out. Musk became a cofounder of OpenAI, which launched as a nonprofit in 2015. He put in $100 million of funding and helped woo the company’s future cofounder and chief scientist Ilya Sutskever away from Google.

Musk’s relationship with Altman and the project later soured, [as reported in WIRED's October cover story about OpenAI](https://www.wired.com/story/what-openai-really-wants/). In early 2018, as OpenAI’s work on the text-generation technology that would lead to ChatGPT was gaining momentum, Musk suggested that he take a majority stake in the company. Altman and others disagreed, and Musk left the board, departing the project with farewell remarks at a company all-hands in which he predicted the company would fail.

</code></pre>

</div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert col"><span class="text-caption text-bold text-grey-5">Ask LLM with search grounding</span><div class="q-inner-loading q--avoid-card-border absolute-full column flex-center q-inner-loading--dark q-transition--fade-leave-active q-transition--fade-leave-to" style="--q-transition-duration: 300ms;"><svg class="q-spinner q-spinner-mat" width="42" height="42" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg><div class="q-inner-loading__label">Waiting for the Reader API result first...</div></div><div class="q-card__section q-card__section--vert q-pa-lg"><div class="q-markdown"></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert text-grey"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">info</i> Please note that unlike the demo shown above, in practice you do not search the original question on the web for grounding. What people often do is rewrite the original question or use multi-hop questions. They read the retrieved results and then generate additional queries to gather more information as needed before arriving at a final answer.</div></div><div data-v-75350d50="" class="q-card q-card--dark q-dark q-card--bordered q-card--square no-border-radius q-card--flat no-shadow col-12 col-md-10"><div class="q-card__section q-card__section--vert"><div class="q-card__section q-card__section--vert col"><label class="q-field row no-wrap items-start q-field--standard q-input q-field--float q-field--labeled q-field--dark q-field--with-bottom" for="f_93a10949-1f91-4213-b044-14b481a4f9a5"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">casino</i></span></button></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Enter your URL" id="f_93a10949-1f91-4213-b044-14b481a4f9a5" type="url"><div class="q-field__label no-pointer-events absolute ellipsis">Enter your URL</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div></div><div class="q-field__bottom row items-start q-field__bottom--animated"><div class="q-field__messages col"><div>Click below to fetch the source code of the page directly</div></div></div></div></label></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert col"><label class="q-field row no-wrap items-start q-field--standard q-input q-field--float q-field--labeled q-field--dark q-field--with-bottom q-field--readonly" for="f_1096f95b-aaaf-4aa2-818d-04b67ffae81c"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Reader URL" id="f_1096f95b-aaaf-4aa2-818d-04b67ffae81c" readonly="" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Reader URL</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">content_copy</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div></div><div class="q-field__bottom row items-start q-field__bottom--animated"><div class="q-field__messages col">Click below to obtain the content through our Reader API</div></div></div></label></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><button class="q-btn q-btn-item non-selectable no-outline q-btn--standard q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square full-width" tabindex="0" type="button" style="padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">download</i><span class="block">Fetch Content</span></span></button><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert q-pa-none"><div class="q-card__section q-card__section--vert col"><span class="text-caption text-bold text-grey-5">Raw HTML</span><div class="q-markdown" style="max-height: 300px;"><p>Failed to fetch</p>
</div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert col"><span class="text-caption text-bold text-grey-5">Reader Output</span><div class="q-markdown" style="max-height: 300px;"><pre class="q-markdown--code q-markdown--code__inner language-plaintext"><code>Title: 8192-Token General-Purpose Text Embeddings for Long Documents

URL Source: https://arxiv.org/html/2310.19923v4

Markdown Content:
Jina Embeddings 2: 8192819281928192\-Token General-Purpose Text Embeddings for Long Documents
---------------------------------------------------------------------------------------------

Michael Günther, Jackmin Ong, Isabelle Mohr, Alaeddine Abdessalem, Tanguy Abel,  
Mohammad Kalim Akram, Susana Guzman, Georgios Mastrapas, Saba Sturua,  
Bo Wang, Maximilian Werk, Nan Wang    Han Xiao  
Jina AI GmbH, Ohlauer Str. 43, 10999 Berlin, Germany  
{michael.guenther, jackmin.ong, isabelle.mohr alaeddine.abdessalem,  
tanguy.abel, kalim.akram, susana.guzman, georgios.mastrapas, saba.sturua,  
bo.wang, maximilian.werk, nan.wang, han.xiao}@jina.ai

(2023/10/31)

###### Abstract

Text embedding models have emerged as powerful tools for transforming sentences into fixed-sized feature vectors that encapsulate semantic information. While these models are essential for tasks like information retrieval, semantic clustering, and text re-ranking, most existing open-source models, especially those built on architectures like BERT, struggle to represent lengthy documents and often resort to truncation. One common approach to mitigate this challenge involves splitting documents into smaller paragraphs for embedding. However, this strategy results in a much larger set of vectors, consequently leading to increased memory consumption and computationally intensive vector searches with elevated latency.

To address these challenges, we introduce Jina  Embeddings v2, an open-source text embedding model111Base model (0.27G): [https://huggingface.co/jinaai/jina-embeddings-v2-base-en](https://huggingface.co/jinaai/jina-embeddings-v2-base-en)  
Small model (0.07G): [https://huggingface.co/jinaai/jina-embeddings-v2-small-en](https://huggingface.co/jinaai/jina-embeddings-v2-small-en)  
API: [https://jina.ai/embeddings](https://jina.ai/embeddings) capable of accommodating up to 8192819281928192 tokens. This model is designed to transcend the conventional 512512512512\-token limit and adeptly process long documents. Jina  Embeddings v2 not only achieves state-of-the-art performance on a range of embedding-related tasks in the MTEB benchmark but also matches the performance of OpenAI’s proprietary text-embedding-ada-002 model. Additionally, our experiments indicate that an extended context can enhance performance in tasks such as NarrativeQA.

1 Introduction
--------------

Using neural networks to encode text and images into embedding representations has become a standard practice for analyzing and processing vast amounts of unstructured data. In natural language processing, sentence embedding models Reimers and Gurevych ([2019](https://arxiv.org/html/2310.19923v4#bib.bib1)) transform the semantics of phrases, sentences, and paragraphs into points within a continuous vector space. These transformed data points can subsequently be used for a myriad of downstream applications, such as information retrieval, as well as clustering and classification tasks.

Despite the numerous applications of embedding models, a prevailing challenge faced by many models is the limitation on the maximum sequence lengths of text that can be encoded into a single embedding. To circumvent this, practitioners often segment documents into smaller chunks prior to encoding. This tactic, unfortunately, results in fragmented semantic meanings, causing the embeddings to misrepresent the entirety of paragraphs. Furthermore, this method yields a plethora of vectors, culminating in heightened memory usage, increased computational demands during vector searches, and extended latencies. The dilemma is exacerbated when embedding vectors are stored in database systems that construct memory-intensive index structures.

The root of these text length restrictions can be traced back to the BERT architecture, which underpins most of the current open-source models. The authors of Press et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib2)) demonstrated that these models struggle to accurately represent long documents. They introduced an alternative positional embedding method named ALiBi, enabling efficient training of models to encode long text sequences. Regrettably, up until this point, the approach was exclusively employed for generative language models, neglecting its potential for open-source encoder language models aimed at crafting document embeddings. This research bridges that gap by incorporating ALiBi bidirectionally into the BERT framework, rendering it apt for encoding tasks. As a result, it empowers users to utilize it for downstream operations on texts spanning up to 8192819281928192 tokens. Moreover, we fine-tuned this enhanced BERT model, harnessing hundreds of millions of text samples to encode texts into singular embedding representations. Our model’s resultant embeddings outshine those of the Jina  Embeddings v1 model suite Günther et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib3)) in the MTEB benchmark and rival the prowess of state-of-the-art models like E5 Wang et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib4)). We also found that large context lengths can amplify the efficacy of numerous downstream tasks tied to embeddings. Given that the majority of available embedding evaluation datasets comprise mainly brief text passages, we have curated datasets encompassing long text values to better evaluate embeddings. These datasets, alongside our models, are made accessible via our Hugging Face repository222[https://huggingface.co/jinaai](https://huggingface.co/jinaai).

This paper is structured as follows: We begin with an overview of related work in Section [2](https://arxiv.org/html/2310.19923v4#S2 "2 Related Work ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"). This is followed by an outline of the training paradigm in Section [3](https://arxiv.org/html/2310.19923v4#S3 "3 Training Paradigm Overview ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), a description of the backbone model and its pre-training in Section [4](https://arxiv.org/html/2310.19923v4#S4 "4 Pre-training a Modified BERT ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), and a detailed walkthrough of the fine-tuning process for embeddings generation in Section [5](https://arxiv.org/html/2310.19923v4#S5 "5 Fine-Tuning for Embeddings ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"). We culminate with an exhaustive evaluation in Section [6](https://arxiv.org/html/2310.19923v4#S6 "6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") and conclusions in Section [7](https://arxiv.org/html/2310.19923v4#S7 "7 Conclusion ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents").

2 Related Work
--------------

Embedding training has undergone significant evolution, transitioning from foundational techniques such as Latent Semantic Indexing (LSA) Deerwester et al. ([1990](https://arxiv.org/html/2310.19923v4#bib.bib5)) and Latent Dirichlet Allocation (LDA) Blei et al. ([2001](https://arxiv.org/html/2310.19923v4#bib.bib6)) to the sophisticated prowess of pre-trained models like Sentence-BERT Reimers and Gurevych ([2019](https://arxiv.org/html/2310.19923v4#bib.bib1)). A notable shift in recent advancements is the emphasis on unsupervised contrastive learning, as showcased by works like Gao et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib7)); Wang et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib4)). Pioneering models like Condenser Gao and Callan ([2021](https://arxiv.org/html/2310.19923v4#bib.bib8)) and RetroMAE Xiao et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib9)) have brought forth specialized architectures and pre-training methods explicitly designed for dense encoding and retrieval.

The E5 Wang et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib4)), Jina  Embeddings v1 Günther et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib3)), and GTE Li et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib10)) collections of embedding models represent another leap forward. These models propose a holistic framework tailored for effective training across a myriad of tasks. This framework adopts a multi-stage contrastive training approach. An initial phase focuses on training using a vast collection of weak pairs sourced from public data, enhancing the model’s domain generalization. Following this, a supervised fine-tuning stage employs a curated set of annotated text triples, representing diverse tasks. Together, these sequential stages yield state-of-the-art outcomes on the MTEB benchmark.

Yet, despite such advancements, a glaring limitation persists: the 512512512512\-token constraint on input sequences, stemming from foundational models like BERT. This cap is insufficient for encoding lengthy documents, often exceeding a page. ALiBi Press et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib2)) emerges as a promising solution, presenting a technique that sidesteps conventional positional embeddings and facilitates training on sequences exceeding 2048204820482048 tokens. Notably, its typical application is centered around generative models, which inherently adopt a unidirectional bias, rendering it less suitable for embedding tasks.

Effective evaluation remains paramount for embedding models, ensuring they meet the diverse demands of real-world applications. The BEIR benchmark Thakur et al. ([2021](https://arxiv.org/html/2310.19923v4#bib.bib11)) stands out, offering evaluations across a set of retrieval tasks and settings. Similarly, the MTEB benchmark Muennighoff et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib12)) highlights the extensive applicability of text embeddings, spanning a variety of tasks and languages. However, a notable gap in both benchmarks is their limited focus on encoding long documents — a critical aspect for comprehensive embedding evaluation.

3 Training Paradigm Overview
----------------------------

The training paradigm for Jina  Embeddings v2 is divided into three stages:

1.  I
    
    Pre-training a Modified BERT: For the backbone language model, we propose a modified BERT model capable of encoding documents with up to 8192819281928192 tokens. This model is trained from scratch on a full-text corpus using a masked language modeling objective.
    
2.  II
    
    Fine-tuning with Text Pairs: To encode a text passage into a single vector representation, the model is fine-tuned on text pairs.
    
3.  III
    
    Fine-tuning with Hard Negatives: The model is further fine-tuned using text pairs complemented with hard negatives. This stage is crucial for enabling the model to better distinguish between relevant passages and related, but irrelevant text passages.
    

While both stages [II](https://arxiv.org/html/2310.19923v4#S3.I1.i2 "item II ‣ 3 Training Paradigm Overview ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") and [III](https://arxiv.org/html/2310.19923v4#S3.I1.i3 "item III ‣ 3 Training Paradigm Overview ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") are geared towards training the models for embedding tasks, the latter is especially critical for improving the model’s performance in retrieval and classification tasks (refer to Section [6.2](https://arxiv.org/html/2310.19923v4#S6.SS2 "6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents")).

4 Pre-training a Modified BERT
------------------------------

For the backbone language model, we introduce a novel transformer based on BERT Devlin et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib13)) with several modifications to enhance its ability to encode extended text sequences and to generally bolster its language modeling capabilities. For the training process, we largely adopt the approach described in Liu et al. ([2019a](https://arxiv.org/html/2310.19923v4#bib.bib14)), incorporating additional performance optimizations.

### 4.1 Model Architecture

Table 1: Architecture specifications for the Jina BERT models of varying sizes. The number of attention heads is selected to ensure a consistent head dimension of 64646464.

##### Attention with Linear Biases:

![Image 1: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/bidirectional_alibi.png) (a) Encoder ALiBi

![Image 2: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/causal_alibi.png) (b) Causal ALiBi

Figure 1: With ALiBi attention, a linear bias is incorporated into each attention score preceding the softmax operation. Each attention head employs a distinct constant scalar, m𝑚mitalic\_m, which diversifies its computation. Our model adopts the encoder variant where all tokens mutually attend during calculation, contrasting the causal variant originally designed for language modeling. In the latter, a causal mask confines tokens to attend solely to preceding tokens in the sequence.

For the self-attention mechanism within the attention blocks, we adopt the Attention with Linear Biases (ALiBi) approach Press et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib2)). ALiBi forgoes the use of positional embeddings. Instead, it encodes positional information directly within the self-attention layer by introducing a constant bias term to the attention score matrix of each layer, ensuring that proximate tokens demonstrate stronger mutual attention. While the original implementation was designed for causal language modeling and featured biases solely in the causal direction, such an approach is not compatible with the bidirectional self-attention inherent in our encoder model. For our purposes, we employ the symmetric encoder variant where attention biases are mirrored to ensure consistency in both directions333[https://github.com/ofirpress/attention\_with\_linear\_biases/issues/5](https://github.com/ofirpress/attention_with_linear_biases/issues/5). Figure [1](https://arxiv.org/html/2310.19923v4#S4.F1 "Figure 1 ‣ Attention with Linear Biases: ‣ 4.1 Model Architecture ‣ 4 Pre-training a Modified BERT ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") depicts the computation of attention scores within the multi-head attention heads. Each head’s scaling value, misubscript𝑚𝑖m\_{i}italic\_m start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT, out of the total n𝑛nitalic\_n heads, is derived using Equation ([4.1](https://arxiv.org/html/2310.19923v4#S4.Ex1 "Attention with Linear Biases: ‣ 4.1 Model Architecture ‣ 4 Pre-training a Modified BERT ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents")).

&lt;table id="A1.EGx1"&gt;&lt;tbody id="S4.Ex1"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle m_{i}=\begin{cases}b^{2i}&amp;amp;i&lt;a\\
b^{1+2(i-a)}&amp;amp;i\geq a\\
\end{cases}" display="inline" id="S4.Ex1.m2.4"&gt;&lt;semantics id="S4.Ex1.m2.4a"&gt;&lt;mrow id="S4.Ex1.m2.4.5" xref="S4.Ex1.m2.4.5.cmml"&gt;&lt;msub id="S4.Ex1.m2.4.5.2" xref="S4.Ex1.m2.4.5.2.cmml"&gt;&lt;mi id="S4.Ex1.m2.4.5.2.2" xref="S4.Ex1.m2.4.5.2.2.cmml"&gt;m&lt;/mi&gt;&lt;mi id="S4.Ex1.m2.4.5.2.3" xref="S4.Ex1.m2.4.5.2.3.cmml"&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S4.Ex1.m2.4.5.1" xref="S4.Ex1.m2.4.5.1.cmml"&gt;=&lt;/mo&gt;&lt;mrow id="S4.Ex1.m2.4.4a" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;mo id="S4.Ex1.m2.4.4a.5" xref="S4.Ex1.m2.4.5.3.1.1.cmml"&gt;{&lt;/mo&gt;&lt;mtable columnspacing="5pt" id="S4.Ex1.m2.4.4.4a" rowspacing="0pt" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;mtr id="S4.Ex1.m2.4.4.4aa" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;mtd columnalign="left" id="S4.Ex1.m2.4.4.4ab" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;msup id="S4.Ex1.m2.1.1.1.1.1.1" xref="S4.Ex1.m2.1.1.1.1.1.1.cmml"&gt;&lt;mi id="S4.Ex1.m2.1.1.1.1.1.1.2" xref="S4.Ex1.m2.1.1.1.1.1.1.2.cmml"&gt;b&lt;/mi&gt;&lt;mrow id="S4.Ex1.m2.1.1.1.1.1.1.3" xref="S4.Ex1.m2.1.1.1.1.1.1.3.cmml"&gt;&lt;mn id="S4.Ex1.m2.1.1.1.1.1.1.3.2" xref="S4.Ex1.m2.1.1.1.1.1.1.3.2.cmml"&gt;2&lt;/mn&gt;&lt;mo id="S4.Ex1.m2.1.1.1.1.1.1.3.1" xref="S4.Ex1.m2.1.1.1.1.1.1.3.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mi id="S4.Ex1.m2.1.1.1.1.1.1.3.3" xref="S4.Ex1.m2.1.1.1.1.1.1.3.3.cmml"&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mtd&gt;&lt;mtd columnalign="left" id="S4.Ex1.m2.4.4.4ac" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;mrow id="S4.Ex1.m2.2.2.2.2.2.1" xref="S4.Ex1.m2.2.2.2.2.2.1.cmml"&gt;&lt;mi id="S4.Ex1.m2.2.2.2.2.2.1.2" xref="S4.Ex1.m2.2.2.2.2.2.1.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S4.Ex1.m2.2.2.2.2.2.1.1" xref="S4.Ex1.m2.2.2.2.2.2.1.1.cmml"&gt;&amp;lt;&lt;/mo&gt;&lt;mi id="S4.Ex1.m2.2.2.2.2.2.1.3" xref="S4.Ex1.m2.2.2.2.2.2.1.3.cmml"&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr id="S4.Ex1.m2.4.4.4ad" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;mtd columnalign="left" id="S4.Ex1.m2.4.4.4ae" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;msup id="S4.Ex1.m2.3.3.3.3.1.1" xref="S4.Ex1.m2.3.3.3.3.1.1.cmml"&gt;&lt;mi id="S4.Ex1.m2.3.3.3.3.1.1.3" xref="S4.Ex1.m2.3.3.3.3.1.1.3.cmml"&gt;b&lt;/mi&gt;&lt;mrow id="S4.Ex1.m2.3.3.3.3.1.1.1.1" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.cmml"&gt;&lt;mn id="S4.Ex1.m2.3.3.3.3.1.1.1.1.3" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.3.cmml"&gt;1&lt;/mn&gt;&lt;mo id="S4.Ex1.m2.3.3.3.3.1.1.1.1.2" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.2.cmml"&gt;+&lt;/mo&gt;&lt;mrow id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.cmml"&gt;&lt;mn id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.3" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.3.cmml"&gt;2&lt;/mn&gt;&lt;mo id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.2" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.cmml"&gt;&lt;mo id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.cmml"&gt;(&lt;/mo&gt;&lt;mrow id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.cmml"&gt;&lt;mi id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.2" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.1.cmml"&gt;−&lt;/mo&gt;&lt;mi id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.3.cmml"&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mo id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mtd&gt;&lt;mtd columnalign="left" id="S4.Ex1.m2.4.4.4af" xref="S4.Ex1.m2.4.5.3.1.cmml"&gt;&lt;mrow id="S4.Ex1.m2.4.4.4.4.2.1" xref="S4.Ex1.m2.4.4.4.4.2.1.cmml"&gt;&lt;mi id="S4.Ex1.m2.4.4.4.4.2.1.2" xref="S4.Ex1.m2.4.4.4.4.2.1.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S4.Ex1.m2.4.4.4.4.2.1.1" xref="S4.Ex1.m2.4.4.4.4.2.1.1.cmml"&gt;≥&lt;/mo&gt;&lt;mi id="S4.Ex1.m2.4.4.4.4.2.1.3" xref="S4.Ex1.m2.4.4.4.4.2.1.3.cmml"&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S4.Ex1.m2.4b"&gt;&lt;apply id="S4.Ex1.m2.4.5.cmml" xref="S4.Ex1.m2.4.5"&gt;&lt;eq id="S4.Ex1.m2.4.5.1.cmml" xref="S4.Ex1.m2.4.5.1"&gt;&lt;/eq&gt;&lt;apply id="S4.Ex1.m2.4.5.2.cmml" xref="S4.Ex1.m2.4.5.2"&gt;&lt;csymbol cd="ambiguous" id="S4.Ex1.m2.4.5.2.1.cmml" xref="S4.Ex1.m2.4.5.2"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S4.Ex1.m2.4.5.2.2.cmml" xref="S4.Ex1.m2.4.5.2.2"&gt;𝑚&lt;/ci&gt;&lt;ci id="S4.Ex1.m2.4.5.2.3.cmml" xref="S4.Ex1.m2.4.5.2.3"&gt;𝑖&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S4.Ex1.m2.4.5.3.1.cmml" xref="S4.Ex1.m2.4.4a"&gt;&lt;csymbol cd="latexml" id="S4.Ex1.m2.4.5.3.1.1.cmml" xref="S4.Ex1.m2.4.4a.5"&gt;cases&lt;/csymbol&gt;&lt;apply id="S4.Ex1.m2.1.1.1.1.1.1.cmml" xref="S4.Ex1.m2.1.1.1.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.Ex1.m2.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m2.1.1.1.1.1.1"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S4.Ex1.m2.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m2.1.1.1.1.1.1.2"&gt;𝑏&lt;/ci&gt;&lt;apply id="S4.Ex1.m2.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m2.1.1.1.1.1.1.3"&gt;&lt;times id="S4.Ex1.m2.1.1.1.1.1.1.3.1.cmml" xref="S4.Ex1.m2.1.1.1.1.1.1.3.1"&gt;&lt;/times&gt;&lt;cn id="S4.Ex1.m2.1.1.1.1.1.1.3.2.cmml" type="integer" xref="S4.Ex1.m2.1.1.1.1.1.1.3.2"&gt;2&lt;/cn&gt;&lt;ci id="S4.Ex1.m2.1.1.1.1.1.1.3.3.cmml" xref="S4.Ex1.m2.1.1.1.1.1.1.3.3"&gt;𝑖&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S4.Ex1.m2.2.2.2.2.2.1.cmml" xref="S4.Ex1.m2.2.2.2.2.2.1"&gt;&lt;lt id="S4.Ex1.m2.2.2.2.2.2.1.1.cmml" xref="S4.Ex1.m2.2.2.2.2.2.1.1"&gt;&lt;/lt&gt;&lt;ci id="S4.Ex1.m2.2.2.2.2.2.1.2.cmml" xref="S4.Ex1.m2.2.2.2.2.2.1.2"&gt;𝑖&lt;/ci&gt;&lt;ci id="S4.Ex1.m2.2.2.2.2.2.1.3.cmml" xref="S4.Ex1.m2.2.2.2.2.2.1.3"&gt;𝑎&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S4.Ex1.m2.3.3.3.3.1.1.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.Ex1.m2.3.3.3.3.1.1.2.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S4.Ex1.m2.3.3.3.3.1.1.3.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.3"&gt;𝑏&lt;/ci&gt;&lt;apply id="S4.Ex1.m2.3.3.3.3.1.1.1.1.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1"&gt;&lt;plus id="S4.Ex1.m2.3.3.3.3.1.1.1.1.2.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.2"&gt;&lt;/plus&gt;&lt;cn id="S4.Ex1.m2.3.3.3.3.1.1.1.1.3.cmml" type="integer" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.3"&gt;1&lt;/cn&gt;&lt;apply id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1"&gt;&lt;times id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.2.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.2"&gt;&lt;/times&gt;&lt;cn id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.3.cmml" type="integer" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.3"&gt;2&lt;/cn&gt;&lt;apply id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1"&gt;&lt;minus id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.1"&gt;&lt;/minus&gt;&lt;ci id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.2"&gt;𝑖&lt;/ci&gt;&lt;ci id="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m2.3.3.3.3.1.1.1.1.1.1.1.1.3"&gt;𝑎&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S4.Ex1.m2.4.4.4.4.2.1.cmml" xref="S4.Ex1.m2.4.4.4.4.2.1"&gt;&lt;geq id="S4.Ex1.m2.4.4.4.4.2.1.1.cmml" xref="S4.Ex1.m2.4.4.4.4.2.1.1"&gt;&lt;/geq&gt;&lt;ci id="S4.Ex1.m2.4.4.4.4.2.1.2.cmml" xref="S4.Ex1.m2.4.4.4.4.2.1.2"&gt;𝑖&lt;/ci&gt;&lt;ci id="S4.Ex1.m2.4.4.4.4.2.1.3.cmml" xref="S4.Ex1.m2.4.4.4.4.2.1.3"&gt;𝑎&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S4.Ex1.m2.4c"&gt;\displaystyle m_{i}=\begin{cases}b^{2i}&amp;amp;i&amp;lt;a\\ b^{1+2(i-a)}&amp;amp;i\geq a\\ \end{cases}&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S4.Ex1.m2.4d"&gt;italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { start_ROW start_CELL italic_b start_POSTSUPERSCRIPT 2 italic_i end_POSTSUPERSCRIPT end_CELL start_CELL italic_i &amp;lt; italic_a end_CELL end_ROW start_ROW start_CELL italic_b start_POSTSUPERSCRIPT 1 + 2 ( italic_i - italic_a ) end_POSTSUPERSCRIPT end_CELL start_CELL italic_i ≥ italic_a end_CELL end_ROW&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;tbody id="S4.E1"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle a=2^{\left\lfloor\log_{2}n\right\rfloor}\;\;b=2^{\frac{-8}{2^{%
\lceil\log_{2}n\rceil}}}" display="inline" id="S4.E1.m1.2"&gt;&lt;semantics id="S4.E1.m1.2a"&gt;&lt;mrow id="S4.E1.m1.2.3" xref="S4.E1.m1.2.3.cmml"&gt;&lt;mi id="S4.E1.m1.2.3.2" xref="S4.E1.m1.2.3.2.cmml"&gt;a&lt;/mi&gt;&lt;mo id="S4.E1.m1.2.3.3" xref="S4.E1.m1.2.3.3.cmml"&gt;=&lt;/mo&gt;&lt;mrow id="S4.E1.m1.2.3.4" xref="S4.E1.m1.2.3.4.cmml"&gt;&lt;msup id="S4.E1.m1.2.3.4.2" xref="S4.E1.m1.2.3.4.2.cmml"&gt;&lt;mn id="S4.E1.m1.2.3.4.2.2" xref="S4.E1.m1.2.3.4.2.2.cmml"&gt;2&lt;/mn&gt;&lt;mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.2.cmml"&gt;&lt;mo id="S4.E1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.2.1.cmml"&gt;⌊&lt;/mo&gt;&lt;mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"&gt;&lt;msub id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml"&gt;&lt;mi id="S4.E1.m1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.2.cmml"&gt;log&lt;/mi&gt;&lt;mn id="S4.E1.m1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.3.cmml"&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo id="S4.E1.m1.1.1.1.1.1a" lspace="0.167em" xref="S4.E1.m1.1.1.1.1.1.cmml"&gt;⁡&lt;/mo&gt;&lt;mi id="S4.E1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.2.cmml"&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;mo id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.2.1.cmml"&gt;⌋&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo id="S4.E1.m1.2.3.4.1" xref="S4.E1.m1.2.3.4.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mi id="S4.E1.m1.2.3.4.3" xref="S4.E1.m1.2.3.4.3.cmml"&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;mo id="S4.E1.m1.2.3.5" xref="S4.E1.m1.2.3.5.cmml"&gt;=&lt;/mo&gt;&lt;msup id="S4.E1.m1.2.3.6" xref="S4.E1.m1.2.3.6.cmml"&gt;&lt;mn id="S4.E1.m1.2.3.6.2" xref="S4.E1.m1.2.3.6.2.cmml"&gt;2&lt;/mn&gt;&lt;mfrac id="S4.E1.m1.2.2.1" xref="S4.E1.m1.2.2.1.cmml"&gt;&lt;mrow id="S4.E1.m1.2.2.1.3" xref="S4.E1.m1.2.2.1.3.cmml"&gt;&lt;mo id="S4.E1.m1.2.2.1.3a" xref="S4.E1.m1.2.2.1.3.cmml"&gt;−&lt;/mo&gt;&lt;mn id="S4.E1.m1.2.2.1.3.2" xref="S4.E1.m1.2.2.1.3.2.cmml"&gt;8&lt;/mn&gt;&lt;/mrow&gt;&lt;msup id="S4.E1.m1.2.2.1.1.1" xref="S4.E1.m1.2.2.1.1.1.cmml"&gt;&lt;mn id="S4.E1.m1.2.2.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.3.cmml"&gt;2&lt;/mn&gt;&lt;mrow id="S4.E1.m1.2.2.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.2.cmml"&gt;&lt;mo id="S4.E1.m1.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S4.E1.m1.2.2.1.1.1.1.1.2.1.cmml"&gt;⌈&lt;/mo&gt;&lt;mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.cmml"&gt;&lt;msub id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"&gt;&lt;mi id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"&gt;log&lt;/mi&gt;&lt;mn id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo id="S4.E1.m1.2.2.1.1.1.1.1.1.1a" lspace="0.167em" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.cmml"&gt;⁡&lt;/mo&gt;&lt;mi id="S4.E1.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml"&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;mo id="S4.E1.m1.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S4.E1.m1.2.2.1.1.1.1.1.2.1.cmml"&gt;⌉&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b"&gt;&lt;apply id="S4.E1.m1.2.3.cmml" xref="S4.E1.m1.2.3"&gt;&lt;and id="S4.E1.m1.2.3a.cmml" xref="S4.E1.m1.2.3"&gt;&lt;/and&gt;&lt;apply id="S4.E1.m1.2.3b.cmml" xref="S4.E1.m1.2.3"&gt;&lt;eq id="S4.E1.m1.2.3.3.cmml" xref="S4.E1.m1.2.3.3"&gt;&lt;/eq&gt;&lt;ci id="S4.E1.m1.2.3.2.cmml" xref="S4.E1.m1.2.3.2"&gt;𝑎&lt;/ci&gt;&lt;apply id="S4.E1.m1.2.3.4.cmml" xref="S4.E1.m1.2.3.4"&gt;&lt;times id="S4.E1.m1.2.3.4.1.cmml" xref="S4.E1.m1.2.3.4.1"&gt;&lt;/times&gt;&lt;apply id="S4.E1.m1.2.3.4.2.cmml" xref="S4.E1.m1.2.3.4.2"&gt;&lt;csymbol cd="ambiguous" id="S4.E1.m1.2.3.4.2.1.cmml" xref="S4.E1.m1.2.3.4.2"&gt;superscript&lt;/csymbol&gt;&lt;cn id="S4.E1.m1.2.3.4.2.2.cmml" type="integer" xref="S4.E1.m1.2.3.4.2.2"&gt;2&lt;/cn&gt;&lt;apply id="S4.E1.m1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1"&gt;&lt;floor id="S4.E1.m1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.2"&gt;&lt;/floor&gt;&lt;apply id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1"&gt;&lt;apply id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;log id="S4.E1.m1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2"&gt;&lt;/log&gt;&lt;cn id="S4.E1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.E1.m1.1.1.1.1.1.1.3"&gt;2&lt;/cn&gt;&lt;/apply&gt;&lt;ci id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.2"&gt;𝑛&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S4.E1.m1.2.3.4.3.cmml" xref="S4.E1.m1.2.3.4.3"&gt;𝑏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S4.E1.m1.2.3c.cmml" xref="S4.E1.m1.2.3"&gt;&lt;eq id="S4.E1.m1.2.3.5.cmml" xref="S4.E1.m1.2.3.5"&gt;&lt;/eq&gt;&lt;share href="#S4.E1.m1.2.3.4.cmml" id="S4.E1.m1.2.3d.cmml" xref="S4.E1.m1.2.3"&gt;&lt;/share&gt;&lt;apply id="S4.E1.m1.2.3.6.cmml" xref="S4.E1.m1.2.3.6"&gt;&lt;csymbol cd="ambiguous" id="S4.E1.m1.2.3.6.1.cmml" xref="S4.E1.m1.2.3.6"&gt;superscript&lt;/csymbol&gt;&lt;cn id="S4.E1.m1.2.3.6.2.cmml" type="integer" xref="S4.E1.m1.2.3.6.2"&gt;2&lt;/cn&gt;&lt;apply id="S4.E1.m1.2.2.1.cmml" xref="S4.E1.m1.2.2.1"&gt;&lt;divide id="S4.E1.m1.2.2.1.2.cmml" xref="S4.E1.m1.2.2.1"&gt;&lt;/divide&gt;&lt;apply id="S4.E1.m1.2.2.1.3.cmml" xref="S4.E1.m1.2.2.1.3"&gt;&lt;minus id="S4.E1.m1.2.2.1.3.1.cmml" xref="S4.E1.m1.2.2.1.3"&gt;&lt;/minus&gt;&lt;cn id="S4.E1.m1.2.2.1.3.2.cmml" type="integer" xref="S4.E1.m1.2.2.1.3.2"&gt;8&lt;/cn&gt;&lt;/apply&gt;&lt;apply id="S4.E1.m1.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1"&gt;superscript&lt;/csymbol&gt;&lt;cn id="S4.E1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S4.E1.m1.2.2.1.1.1.3"&gt;2&lt;/cn&gt;&lt;apply id="S4.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1"&gt;&lt;ceiling id="S4.E1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2"&gt;&lt;/ceiling&gt;&lt;apply id="S4.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1"&gt;&lt;apply id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;log id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.2"&gt;&lt;/log&gt;&lt;cn id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.3"&gt;2&lt;/cn&gt;&lt;/apply&gt;&lt;ci id="S4.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.2"&gt;𝑛&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S4.E1.m1.2c"&gt;\displaystyle a=2^{\left\lfloor\log_{2}n\right\rfloor}\;\;b=2^{\frac{-8}{2^{% \lceil\log_{2}n\rceil}}}&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S4.E1.m1.2d"&gt;italic_a = 2 start_POSTSUPERSCRIPT ⌊ roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_n ⌋ end_POSTSUPERSCRIPT italic_b = 2 start_POSTSUPERSCRIPT divide start_ARG - 8 end_ARG start_ARG 2 start_POSTSUPERSCRIPT ⌈ roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_n ⌉ end_POSTSUPERSCRIPT end_ARG end_POSTSUPERSCRIPT&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td rowspan="1"&gt;&lt;span&gt;(1)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

##### Gated Linear Units:

For the feedforward sublayers within the attention blocks, we adopt Gated Linear Units (GLU), originally introduced in  Dauphin et al. ([2016](https://arxiv.org/html/2310.19923v4#bib.bib15)). They’ve demonstrated performance enhancements when incorporated into transformers Shazeer ([2020](https://arxiv.org/html/2310.19923v4#bib.bib16)). For the small and base models, we employ the GEGLU variant, which leverages the GELU activation function for the GLU. Conversely, for the large model, we utilize the ReGLU variant with the ReLU activation function. This choice was driven by our observation that training the large model with GEGLU, despite its promising initial MLM accuracy, was unstable.

##### Layer Normalization:

Regarding Layer Normalization ba2016layer, we align with the post-layer normalization approach from Vaswani et al. ([2017](https://arxiv.org/html/2310.19923v4#bib.bib17)) in our attention blocks. Preliminary tests with pre-layer normalization, as mentioned in Shoeybi et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib18)) and Nguyen and Salazar ([2019](https://arxiv.org/html/2310.19923v4#bib.bib19)), didn’t enhance training stability or performance. Consequently, we opted not to integrate it into our model.

### 4.2 Training Data

For the pre-training phase, we leverage the English “Colossal, Cleaned, Common Crawl (C4)” dataset 444[https://huggingface.co/datasets/c4](https://huggingface.co/datasets/c4), encompassing approximately 365 million text documents harvested from the web, summing to around 170 billion tokens. As delineated in  Raffel et al. ([2020](https://arxiv.org/html/2310.19923v4#bib.bib20)), the C4 dataset is a refined iteration of Common Crawl, utilizing heuristics for cleanup and language recognition, retaining solely English content. As a result, our models are monolingual and tailored exclusively for English texts. The purification process also encompasses the removal of webpages hosting inappropriate content. We reserve 1%percent11\\%1 % of the dataset for evaluating validation loss and the accuracy of the masked language modeling (MLM) task.

### 4.3 Training Algorithm

Our model’s pre-training revolves around the masked language modeling objective, excluding the next sentence prediction (NSP) task due to its perceived limited contribution to downstream task performance Liu et al. ([2019a](https://arxiv.org/html/2310.19923v4#bib.bib14)). We mask 30%percent3030\\%30 % of the input tokens randomly, employing whole word masking Devlin et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib13)), and condition the models to infer these masked tokens. Of these masked tokens, 80% are substituted with the \[MASK\] token, 10%percent1010\\%10 % with a random token, and the remaining 10%percent1010\\%10 % stay unaltered.

The masked tokens are predicted by a decoder f:ℝd→ℝ|V|:𝑓→superscriptℝ𝑑superscriptℝ𝑉f:\\mathbb{R}^{d}\\to\\mathbb{R}^{|V|}italic\_f : blackboard\_R start\_POSTSUPERSCRIPT italic\_d end\_POSTSUPERSCRIPT → blackboard\_R start\_POSTSUPERSCRIPT | italic\_V | end\_POSTSUPERSCRIPT, which takes the output token embedding 𝒆𝒊∈ℝdsubscript𝒆𝒊superscriptℝ𝑑\\bm{e\_{i}}\\in\\mathbb{R}^{d}bold\_italic\_e start\_POSTSUBSCRIPT bold\_italic\_i end\_POSTSUBSCRIPT ∈ blackboard\_R start\_POSTSUPERSCRIPT italic\_d end\_POSTSUPERSCRIPT of a masked token and predicts a probability for each token in the vocabulary. The loss LMLMsubscript𝐿MLML\_{\\mathrm{MLM}}italic\_L start\_POSTSUBSCRIPT roman\_MLM end\_POSTSUBSCRIPT is computed by evaluating the cross entropy between the predicted probabilities and the actual masked tokens, as described in Equation ([2](https://arxiv.org/html/2310.19923v4#S4.E2 "2 ‣ 4.3 Training Algorithm ‣ 4 Pre-training a Modified BERT ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents")). Here, I:{1,…,n}→|V|:𝐼→1…𝑛𝑉I:\\{1,\\ldots,n\\}\\to|V|italic\_I : { 1 , … , italic\_n } → | italic\_V | denotes the function that maps each of the n𝑛nitalic\_n masked tokens to its respective index in the vocabulary:

&lt;table id="A1.EGx2"&gt;&lt;tbody id="S4.E2"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\mathcal{L}_{\mathrm{MLM}}(t)" display="inline" id="S4.E2.m1.1"&gt;&lt;semantics id="S4.E2.m1.1a"&gt;&lt;mrow id="S4.E2.m1.1.2" xref="S4.E2.m1.1.2.cmml"&gt;&lt;msub id="S4.E2.m1.1.2.2" xref="S4.E2.m1.1.2.2.cmml"&gt;&lt;mi id="S4.E2.m1.1.2.2.2" xref="S4.E2.m1.1.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;mi id="S4.E2.m1.1.2.2.3" xref="S4.E2.m1.1.2.2.3.cmml"&gt;MLM&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S4.E2.m1.1.2.1" xref="S4.E2.m1.1.2.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S4.E2.m1.1.2.3.2" xref="S4.E2.m1.1.2.cmml"&gt;&lt;mo id="S4.E2.m1.1.2.3.2.1" stretchy="false" xref="S4.E2.m1.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"&gt;t&lt;/mi&gt;&lt;mo id="S4.E2.m1.1.2.3.2.2" stretchy="false" xref="S4.E2.m1.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"&gt;&lt;apply id="S4.E2.m1.1.2.cmml" xref="S4.E2.m1.1.2"&gt;&lt;times id="S4.E2.m1.1.2.1.cmml" xref="S4.E2.m1.1.2.1"&gt;&lt;/times&gt;&lt;apply id="S4.E2.m1.1.2.2.cmml" xref="S4.E2.m1.1.2.2"&gt;&lt;csymbol cd="ambiguous" id="S4.E2.m1.1.2.2.1.cmml" xref="S4.E2.m1.1.2.2"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S4.E2.m1.1.2.2.2.cmml" xref="S4.E2.m1.1.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;ci id="S4.E2.m1.1.2.2.3.cmml" xref="S4.E2.m1.1.2.2.3"&gt;MLM&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"&gt;𝑡&lt;/ci&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S4.E2.m1.1c"&gt;\displaystyle\mathcal{L}_{\mathrm{MLM}}(t)&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S4.E2.m1.1d"&gt;caligraphic_L start_POSTSUBSCRIPT roman_MLM end_POSTSUBSCRIPT ( italic_t )&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle:=\sum\limits_{k=1}^{n}\ln f(\bm{e_{i}})_{I(k)}" display="inline" id="S4.E2.m2.2"&gt;&lt;semantics id="S4.E2.m2.2a"&gt;&lt;mrow id="S4.E2.m2.2.2" xref="S4.E2.m2.2.2.cmml"&gt;&lt;mi id="S4.E2.m2.2.2.3" xref="S4.E2.m2.2.2.3.cmml"&gt;&lt;/mi&gt;&lt;mo id="S4.E2.m2.2.2.2" lspace="0.278em" rspace="0.278em" xref="S4.E2.m2.2.2.2.cmml"&gt;:=&lt;/mo&gt;&lt;mrow id="S4.E2.m2.2.2.1" xref="S4.E2.m2.2.2.1.cmml"&gt;&lt;mstyle displaystyle="true" id="S4.E2.m2.2.2.1.2" xref="S4.E2.m2.2.2.1.2.cmml"&gt;&lt;munderover id="S4.E2.m2.2.2.1.2a" xref="S4.E2.m2.2.2.1.2.cmml"&gt;&lt;mo id="S4.E2.m2.2.2.1.2.2.2" movablelimits="false" xref="S4.E2.m2.2.2.1.2.2.2.cmml"&gt;∑&lt;/mo&gt;&lt;mrow id="S4.E2.m2.2.2.1.2.2.3" xref="S4.E2.m2.2.2.1.2.2.3.cmml"&gt;&lt;mi id="S4.E2.m2.2.2.1.2.2.3.2" xref="S4.E2.m2.2.2.1.2.2.3.2.cmml"&gt;k&lt;/mi&gt;&lt;mo id="S4.E2.m2.2.2.1.2.2.3.1" xref="S4.E2.m2.2.2.1.2.2.3.1.cmml"&gt;=&lt;/mo&gt;&lt;mn id="S4.E2.m2.2.2.1.2.2.3.3" xref="S4.E2.m2.2.2.1.2.2.3.3.cmml"&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi id="S4.E2.m2.2.2.1.2.3" xref="S4.E2.m2.2.2.1.2.3.cmml"&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;/mstyle&gt;&lt;mrow id="S4.E2.m2.2.2.1.1" xref="S4.E2.m2.2.2.1.1.cmml"&gt;&lt;mrow id="S4.E2.m2.2.2.1.1.3" xref="S4.E2.m2.2.2.1.1.3.cmml"&gt;&lt;mi id="S4.E2.m2.2.2.1.1.3.1" xref="S4.E2.m2.2.2.1.1.3.1.cmml"&gt;ln&lt;/mi&gt;&lt;mo id="S4.E2.m2.2.2.1.1.3a" lspace="0.167em" xref="S4.E2.m2.2.2.1.1.3.cmml"&gt;⁡&lt;/mo&gt;&lt;mi id="S4.E2.m2.2.2.1.1.3.2" xref="S4.E2.m2.2.2.1.1.3.2.cmml"&gt;f&lt;/mi&gt;&lt;/mrow&gt;&lt;mo id="S4.E2.m2.2.2.1.1.2" xref="S4.E2.m2.2.2.1.1.2.cmml"&gt;⁢&lt;/mo&gt;&lt;msub id="S4.E2.m2.2.2.1.1.1" xref="S4.E2.m2.2.2.1.1.1.cmml"&gt;&lt;mrow id="S4.E2.m2.2.2.1.1.1.1.1" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml"&gt;&lt;mo id="S4.E2.m2.2.2.1.1.1.1.1.2" stretchy="false" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml"&gt;(&lt;/mo&gt;&lt;msub id="S4.E2.m2.2.2.1.1.1.1.1.1" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml"&gt;&lt;mi id="S4.E2.m2.2.2.1.1.1.1.1.1.2" xref="S4.E2.m2.2.2.1.1.1.1.1.1.2.cmml"&gt;𝒆&lt;/mi&gt;&lt;mi id="S4.E2.m2.2.2.1.1.1.1.1.1.3" xref="S4.E2.m2.2.2.1.1.1.1.1.1.3.cmml"&gt;𝒊&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S4.E2.m2.2.2.1.1.1.1.1.3" stretchy="false" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow id="S4.E2.m2.1.1.1" xref="S4.E2.m2.1.1.1.cmml"&gt;&lt;mi id="S4.E2.m2.1.1.1.3" xref="S4.E2.m2.1.1.1.3.cmml"&gt;I&lt;/mi&gt;&lt;mo id="S4.E2.m2.1.1.1.2" xref="S4.E2.m2.1.1.1.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S4.E2.m2.1.1.1.4.2" xref="S4.E2.m2.1.1.1.cmml"&gt;&lt;mo id="S4.E2.m2.1.1.1.4.2.1" stretchy="false" xref="S4.E2.m2.1.1.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S4.E2.m2.1.1.1.1" xref="S4.E2.m2.1.1.1.1.cmml"&gt;k&lt;/mi&gt;&lt;mo id="S4.E2.m2.1.1.1.4.2.2" stretchy="false" xref="S4.E2.m2.1.1.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S4.E2.m2.2b"&gt;&lt;apply id="S4.E2.m2.2.2.cmml" xref="S4.E2.m2.2.2"&gt;&lt;csymbol cd="latexml" id="S4.E2.m2.2.2.2.cmml" xref="S4.E2.m2.2.2.2"&gt;assign&lt;/csymbol&gt;&lt;csymbol cd="latexml" id="S4.E2.m2.2.2.3.cmml" xref="S4.E2.m2.2.2.3"&gt;absent&lt;/csymbol&gt;&lt;apply id="S4.E2.m2.2.2.1.cmml" xref="S4.E2.m2.2.2.1"&gt;&lt;apply id="S4.E2.m2.2.2.1.2.cmml" xref="S4.E2.m2.2.2.1.2"&gt;&lt;csymbol cd="ambiguous" id="S4.E2.m2.2.2.1.2.1.cmml" xref="S4.E2.m2.2.2.1.2"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S4.E2.m2.2.2.1.2.2.cmml" xref="S4.E2.m2.2.2.1.2"&gt;&lt;csymbol cd="ambiguous" id="S4.E2.m2.2.2.1.2.2.1.cmml" xref="S4.E2.m2.2.2.1.2"&gt;subscript&lt;/csymbol&gt;&lt;sum id="S4.E2.m2.2.2.1.2.2.2.cmml" xref="S4.E2.m2.2.2.1.2.2.2"&gt;&lt;/sum&gt;&lt;apply id="S4.E2.m2.2.2.1.2.2.3.cmml" xref="S4.E2.m2.2.2.1.2.2.3"&gt;&lt;eq id="S4.E2.m2.2.2.1.2.2.3.1.cmml" xref="S4.E2.m2.2.2.1.2.2.3.1"&gt;&lt;/eq&gt;&lt;ci id="S4.E2.m2.2.2.1.2.2.3.2.cmml" xref="S4.E2.m2.2.2.1.2.2.3.2"&gt;𝑘&lt;/ci&gt;&lt;cn id="S4.E2.m2.2.2.1.2.2.3.3.cmml" type="integer" xref="S4.E2.m2.2.2.1.2.2.3.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S4.E2.m2.2.2.1.2.3.cmml" xref="S4.E2.m2.2.2.1.2.3"&gt;𝑛&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S4.E2.m2.2.2.1.1.cmml" xref="S4.E2.m2.2.2.1.1"&gt;&lt;times id="S4.E2.m2.2.2.1.1.2.cmml" xref="S4.E2.m2.2.2.1.1.2"&gt;&lt;/times&gt;&lt;apply id="S4.E2.m2.2.2.1.1.3.cmml" xref="S4.E2.m2.2.2.1.1.3"&gt;&lt;ln id="S4.E2.m2.2.2.1.1.3.1.cmml" xref="S4.E2.m2.2.2.1.1.3.1"&gt;&lt;/ln&gt;&lt;ci id="S4.E2.m2.2.2.1.1.3.2.cmml" xref="S4.E2.m2.2.2.1.1.3.2"&gt;𝑓&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S4.E2.m2.2.2.1.1.1.cmml" xref="S4.E2.m2.2.2.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.E2.m2.2.2.1.1.1.2.cmml" xref="S4.E2.m2.2.2.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;apply id="S4.E2.m2.2.2.1.1.1.1.1.1.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S4.E2.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S4.E2.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1.1.2"&gt;𝒆&lt;/ci&gt;&lt;ci id="S4.E2.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1.1.3"&gt;𝒊&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S4.E2.m2.1.1.1.cmml" xref="S4.E2.m2.1.1.1"&gt;&lt;times id="S4.E2.m2.1.1.1.2.cmml" xref="S4.E2.m2.1.1.1.2"&gt;&lt;/times&gt;&lt;ci id="S4.E2.m2.1.1.1.3.cmml" xref="S4.E2.m2.1.1.1.3"&gt;𝐼&lt;/ci&gt;&lt;ci id="S4.E2.m2.1.1.1.1.cmml" xref="S4.E2.m2.1.1.1.1"&gt;𝑘&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S4.E2.m2.2c"&gt;\displaystyle:=\sum\limits_{k=1}^{n}\ln f(\bm{e_{i}})_{I(k)}&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S4.E2.m2.2d"&gt;:= ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_ln italic_f ( bold_italic_e start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_I ( italic_k ) end_POSTSUBSCRIPT&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td rowspan="1"&gt;&lt;span&gt;(2)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

Given our model’s reliance on ALiBi attention Press et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib2)), training position embeddings becomes unnecessary. This allows us to pre-train more efficiently on shorter sequences and adapt to longer sequences in subsequent tasks. Throughout our pre-training, we operate on sequences capped at 512512512512 tokens in length. Diverging from the methods in Devlin et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib13)) and Liu et al. ([2019a](https://arxiv.org/html/2310.19923v4#bib.bib14)), our sequences originate from individual documents without any multi-document packing. Furthermore, we refrain from sampling multiple sequences from a singular document. For each document, we exclusively consider its initial 512 tokens, truncating any excess. Given our consistent global batch size of 4096, each batch, due to its varying sequence length, contains a unique number of masked tokens when calculating loss.

##### Optimizer:

Mirroring the optimization strategy of RoBERTa Liu et al. ([2019a](https://arxiv.org/html/2310.19923v4#bib.bib14)), we employ the AdamW algorithm Loshchilov and Hutter ([2017](https://arxiv.org/html/2310.19923v4#bib.bib21)), characterized by parameters β1\=0.9subscript𝛽10.9\\beta\_{1}=0.9italic\_β start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT = 0.9, β2\=0.98subscript𝛽20.98\\beta\_{2}=0.98italic\_β start\_POSTSUBSCRIPT 2 end\_POSTSUBSCRIPT = 0.98, ϵ\=1⁢e−6italic-ϵ1e6\\epsilon=1\\mathrm{e}{-6}italic\_ϵ = 1 roman\_e - 6, a weight decay of 0.010.010.010.01, dropout set at 0.10.10.10.1, and attention dropout also at 0.10.10.10.1. Our learning rate schedule is linear, starting at 00 and peaking at a rate of η𝜂\\etaitalic\_η post 10,0001000010,00010 , 000 steps. Here, the values of η𝜂\\etaitalic\_η are designated as 1⁢e−31e31\\mathrm{e}{-3}1 roman\_e - 3, 6⁢e−46e46\\mathrm{e}{-4}6 roman\_e - 4, and 4⁢e−44e44\\mathrm{e}{-4}4 roman\_e - 4 for the small, base, and large models respectively. A linear decay to zero ensues after reaching the 100,000100000100,000100 , 000 steps threshold.

##### Mixed precision training:

We resort to FP16 dynamic mixed precision Micikevicius et al. ([2018](https://arxiv.org/html/2310.19923v4#bib.bib22)) for pre-training our models, facilitated by the DeepSpeed software package Rasley et al. ([2020](https://arxiv.org/html/2310.19923v4#bib.bib23)). Our preliminary tests using BF16 revealed unsatisfactory performance metrics, both in MLM accuracy and the downstream GLUE tasks.

5 Fine-Tuning for Embeddings
----------------------------

After pre-training the Jina BERT models, we further fine-tune each of the models to encode a text sequence into a single vector representation. The core idea behind our embedding approach is inspired by the Sentence-BERT Reimers and Gurevych ([2019](https://arxiv.org/html/2310.19923v4#bib.bib1)). To enable a model to perform a text operation, we augment it with a mean pooling layer. This mean pooling step averages the token embeddings to merge their information into a single representation, without introducing additional trainable parameters. The training process for this enhanced model consists of an unsupervised phase followed by a supervised one.

### 5.1 Fine-tuning with Text Pairs

During the first fine-tuning stage, we train the models on a corpus of text pairs (q,p)∈𝔻pairs𝑞𝑝superscript𝔻pairs(q,p)\\in\\mathbb{D}^{\\mathrm{pairs}}( italic\_q , italic\_p ) ∈ blackboard\_D start\_POSTSUPERSCRIPT roman\_pairs end\_POSTSUPERSCRIPT, comprising a query string q𝑞qitalic\_q and a target string p𝑝pitalic\_p.

##### Training Data

We utilize roughly 40 diverse data sources, akin to the data preparation outlined in the report we previously published about our inaugural embedding model suite Günther et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib3)). We observed that the inclusion of title-abstract pairs from documents significantly enhances performance on clustering tasks. As detailed in Günther et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib3)), we implement consistency filtering (Dai et al., [2023](https://arxiv.org/html/2310.19923v4#bib.bib24); Wang et al., [2022](https://arxiv.org/html/2310.19923v4#bib.bib4)) to elevate the quality of the text pair corpus. For batch creation, we adhere to our earlier strategy: for every new batch, we randomly choose a data source and extract as many pairs as needed to fill that batch. All pairs within the data sources are pre-shuffled. Depending on the quality and quantity of the data sources, we assign different sampling rates for the pairs.

##### Loss Function:

The goal of this fine-tuning stage is to encode text values that constitute a pair into analogous embedding representations, while encoding texts that aren’t paired into distinct embeddings. To achieve this contrastive goal, we employ the InfoNCE (van den Oord et al., [2018](https://arxiv.org/html/2310.19923v4#bib.bib25)) loss function, similar to our earlier embedding models Günther et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib3)). This loss function calculates the loss value for a pair (q,p)∼𝐁similar-to𝑞𝑝𝐁(q,p)\\sim\\mathbf{B}( italic\_q , italic\_p ) ∼ bold\_B within a batch 𝐁⊂𝔻pairs𝐁superscript𝔻pairs\\mathbf{B}\\subset\\mathbb{D}^{\\mathrm{pairs}}bold\_B ⊂ blackboard\_D start\_POSTSUPERSCRIPT roman\_pairs end\_POSTSUPERSCRIPT as follows:

&lt;table id="A1.EGx3"&gt;&lt;tbody id="S5.E3"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\mathcal{L}_{\mathrm{NCE}}^{\mathrm{pairs}}(\mathbf{B}):=\mathbb{%
E}_{(q,p)\sim\mathbf{B}}\left[-\ln\frac{e^{s(q,p)/\tau}}{\sum\limits_{i=1}^{k}%
e^{s(q,p_{i})/\tau}}\right]" display="inline" id="S5.E3.m1.8"&gt;&lt;semantics id="S5.E3.m1.8a"&gt;&lt;mrow id="S5.E3.m1.8.8" xref="S5.E3.m1.8.8.cmml"&gt;&lt;mrow id="S5.E3.m1.8.8.3" xref="S5.E3.m1.8.8.3.cmml"&gt;&lt;msubsup id="S5.E3.m1.8.8.3.2" xref="S5.E3.m1.8.8.3.2.cmml"&gt;&lt;mi id="S5.E3.m1.8.8.3.2.2.2" xref="S5.E3.m1.8.8.3.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;mi id="S5.E3.m1.8.8.3.2.2.3" xref="S5.E3.m1.8.8.3.2.2.3.cmml"&gt;NCE&lt;/mi&gt;&lt;mi id="S5.E3.m1.8.8.3.2.3" xref="S5.E3.m1.8.8.3.2.3.cmml"&gt;pairs&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo id="S5.E3.m1.8.8.3.1" xref="S5.E3.m1.8.8.3.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E3.m1.8.8.3.3.2" xref="S5.E3.m1.8.8.3.cmml"&gt;&lt;mo id="S5.E3.m1.8.8.3.3.2.1" stretchy="false" xref="S5.E3.m1.8.8.3.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E3.m1.7.7" xref="S5.E3.m1.7.7.cmml"&gt;𝐁&lt;/mi&gt;&lt;mo id="S5.E3.m1.8.8.3.3.2.2" rspace="0.278em" stretchy="false" xref="S5.E3.m1.8.8.3.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E3.m1.8.8.2" rspace="0.278em" xref="S5.E3.m1.8.8.2.cmml"&gt;:=&lt;/mo&gt;&lt;mrow id="S5.E3.m1.8.8.1" xref="S5.E3.m1.8.8.1.cmml"&gt;&lt;msub id="S5.E3.m1.8.8.1.3" xref="S5.E3.m1.8.8.1.3.cmml"&gt;&lt;mi id="S5.E3.m1.8.8.1.3.2" xref="S5.E3.m1.8.8.1.3.2.cmml"&gt;𝔼&lt;/mi&gt;&lt;mrow id="S5.E3.m1.2.2.2" xref="S5.E3.m1.2.2.2.cmml"&gt;&lt;mrow id="S5.E3.m1.2.2.2.4.2" xref="S5.E3.m1.2.2.2.4.1.cmml"&gt;&lt;mo id="S5.E3.m1.2.2.2.4.2.1" stretchy="false" xref="S5.E3.m1.2.2.2.4.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E3.m1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.E3.m1.2.2.2.4.2.2" xref="S5.E3.m1.2.2.2.4.1.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.E3.m1.2.2.2.2" xref="S5.E3.m1.2.2.2.2.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.E3.m1.2.2.2.4.2.3" stretchy="false" xref="S5.E3.m1.2.2.2.4.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo id="S5.E3.m1.2.2.2.3" xref="S5.E3.m1.2.2.2.3.cmml"&gt;∼&lt;/mo&gt;&lt;mi id="S5.E3.m1.2.2.2.5" xref="S5.E3.m1.2.2.2.5.cmml"&gt;𝐁&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo id="S5.E3.m1.8.8.1.2" xref="S5.E3.m1.8.8.1.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E3.m1.8.8.1.1.1" xref="S5.E3.m1.8.8.1.1.2.cmml"&gt;&lt;mo id="S5.E3.m1.8.8.1.1.1.2" xref="S5.E3.m1.8.8.1.1.2.1.cmml"&gt;[&lt;/mo&gt;&lt;mrow id="S5.E3.m1.8.8.1.1.1.1" xref="S5.E3.m1.8.8.1.1.1.1.cmml"&gt;&lt;mo id="S5.E3.m1.8.8.1.1.1.1a" rspace="0.167em" xref="S5.E3.m1.8.8.1.1.1.1.cmml"&gt;−&lt;/mo&gt;&lt;mrow id="S5.E3.m1.8.8.1.1.1.1.2" xref="S5.E3.m1.8.8.1.1.1.1.2.cmml"&gt;&lt;mi id="S5.E3.m1.8.8.1.1.1.1.2.1" xref="S5.E3.m1.8.8.1.1.1.1.2.1.cmml"&gt;ln&lt;/mi&gt;&lt;mo id="S5.E3.m1.8.8.1.1.1.1.2a" lspace="0.167em" xref="S5.E3.m1.8.8.1.1.1.1.2.cmml"&gt;⁡&lt;/mo&gt;&lt;mstyle displaystyle="true" id="S5.E3.m1.6.6" xref="S5.E3.m1.6.6.cmml"&gt;&lt;mfrac id="S5.E3.m1.6.6a" xref="S5.E3.m1.6.6.cmml"&gt;&lt;msup id="S5.E3.m1.4.4.2" xref="S5.E3.m1.4.4.2.cmml"&gt;&lt;mi id="S5.E3.m1.4.4.2.4" xref="S5.E3.m1.4.4.2.4.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.E3.m1.4.4.2.2.2" xref="S5.E3.m1.4.4.2.2.2.cmml"&gt;&lt;mrow id="S5.E3.m1.4.4.2.2.2.4" xref="S5.E3.m1.4.4.2.2.2.4.cmml"&gt;&lt;mi id="S5.E3.m1.4.4.2.2.2.4.2" xref="S5.E3.m1.4.4.2.2.2.4.2.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.E3.m1.4.4.2.2.2.4.1" xref="S5.E3.m1.4.4.2.2.2.4.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E3.m1.4.4.2.2.2.4.3.2" xref="S5.E3.m1.4.4.2.2.2.4.3.1.cmml"&gt;&lt;mo id="S5.E3.m1.4.4.2.2.2.4.3.2.1" stretchy="false" xref="S5.E3.m1.4.4.2.2.2.4.3.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E3.m1.3.3.1.1.1.1" xref="S5.E3.m1.3.3.1.1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.E3.m1.4.4.2.2.2.4.3.2.2" xref="S5.E3.m1.4.4.2.2.2.4.3.1.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.E3.m1.4.4.2.2.2.2" xref="S5.E3.m1.4.4.2.2.2.2.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.E3.m1.4.4.2.2.2.4.3.2.3" stretchy="false" xref="S5.E3.m1.4.4.2.2.2.4.3.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E3.m1.4.4.2.2.2.3" xref="S5.E3.m1.4.4.2.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.E3.m1.4.4.2.2.2.5" xref="S5.E3.m1.4.4.2.2.2.5.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow id="S5.E3.m1.6.6.4" xref="S5.E3.m1.6.6.4.cmml"&gt;&lt;munderover id="S5.E3.m1.6.6.4.3" xref="S5.E3.m1.6.6.4.3.cmml"&gt;&lt;mo id="S5.E3.m1.6.6.4.3.2.2" movablelimits="false" xref="S5.E3.m1.6.6.4.3.2.2.cmml"&gt;∑&lt;/mo&gt;&lt;mrow id="S5.E3.m1.6.6.4.3.2.3" xref="S5.E3.m1.6.6.4.3.2.3.cmml"&gt;&lt;mi id="S5.E3.m1.6.6.4.3.2.3.2" xref="S5.E3.m1.6.6.4.3.2.3.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S5.E3.m1.6.6.4.3.2.3.1" xref="S5.E3.m1.6.6.4.3.2.3.1.cmml"&gt;=&lt;/mo&gt;&lt;mn id="S5.E3.m1.6.6.4.3.2.3.3" xref="S5.E3.m1.6.6.4.3.2.3.3.cmml"&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi id="S5.E3.m1.6.6.4.3.3" xref="S5.E3.m1.6.6.4.3.3.cmml"&gt;k&lt;/mi&gt;&lt;/munderover&gt;&lt;msup id="S5.E3.m1.6.6.4.4" xref="S5.E3.m1.6.6.4.4.cmml"&gt;&lt;mi id="S5.E3.m1.6.6.4.4.2" xref="S5.E3.m1.6.6.4.4.2.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.E3.m1.6.6.4.2.2" xref="S5.E3.m1.6.6.4.2.2.cmml"&gt;&lt;mrow id="S5.E3.m1.6.6.4.2.2.2" xref="S5.E3.m1.6.6.4.2.2.2.cmml"&gt;&lt;mi id="S5.E3.m1.6.6.4.2.2.2.3" xref="S5.E3.m1.6.6.4.2.2.2.3.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.E3.m1.6.6.4.2.2.2.2" xref="S5.E3.m1.6.6.4.2.2.2.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E3.m1.6.6.4.2.2.2.1.1" xref="S5.E3.m1.6.6.4.2.2.2.1.2.cmml"&gt;&lt;mo id="S5.E3.m1.6.6.4.2.2.2.1.1.2" stretchy="false" xref="S5.E3.m1.6.6.4.2.2.2.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E3.m1.5.5.3.1.1.1" xref="S5.E3.m1.5.5.3.1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.E3.m1.6.6.4.2.2.2.1.1.3" xref="S5.E3.m1.6.6.4.2.2.2.1.2.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.E3.m1.6.6.4.2.2.2.1.1.1" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1.cmml"&gt;&lt;mi id="S5.E3.m1.6.6.4.2.2.2.1.1.1.2" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1.2.cmml"&gt;p&lt;/mi&gt;&lt;mi id="S5.E3.m1.6.6.4.2.2.2.1.1.1.3" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1.3.cmml"&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S5.E3.m1.6.6.4.2.2.2.1.1.4" stretchy="false" xref="S5.E3.m1.6.6.4.2.2.2.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E3.m1.6.6.4.2.2.3" xref="S5.E3.m1.6.6.4.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.E3.m1.6.6.4.2.2.4" xref="S5.E3.m1.6.6.4.2.2.4.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E3.m1.8.8.1.1.1.3" xref="S5.E3.m1.8.8.1.1.2.1.cmml"&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.E3.m1.8b"&gt;&lt;apply id="S5.E3.m1.8.8.cmml" xref="S5.E3.m1.8.8"&gt;&lt;csymbol cd="latexml" id="S5.E3.m1.8.8.2.cmml" xref="S5.E3.m1.8.8.2"&gt;assign&lt;/csymbol&gt;&lt;apply id="S5.E3.m1.8.8.3.cmml" xref="S5.E3.m1.8.8.3"&gt;&lt;times id="S5.E3.m1.8.8.3.1.cmml" xref="S5.E3.m1.8.8.3.1"&gt;&lt;/times&gt;&lt;apply id="S5.E3.m1.8.8.3.2.cmml" xref="S5.E3.m1.8.8.3.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.8.8.3.2.1.cmml" xref="S5.E3.m1.8.8.3.2"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.E3.m1.8.8.3.2.2.cmml" xref="S5.E3.m1.8.8.3.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.8.8.3.2.2.1.cmml" xref="S5.E3.m1.8.8.3.2"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E3.m1.8.8.3.2.2.2.cmml" xref="S5.E3.m1.8.8.3.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;ci id="S5.E3.m1.8.8.3.2.2.3.cmml" xref="S5.E3.m1.8.8.3.2.2.3"&gt;NCE&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S5.E3.m1.8.8.3.2.3.cmml" xref="S5.E3.m1.8.8.3.2.3"&gt;pairs&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S5.E3.m1.7.7.cmml" xref="S5.E3.m1.7.7"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.E3.m1.8.8.1.cmml" xref="S5.E3.m1.8.8.1"&gt;&lt;times id="S5.E3.m1.8.8.1.2.cmml" xref="S5.E3.m1.8.8.1.2"&gt;&lt;/times&gt;&lt;apply id="S5.E3.m1.8.8.1.3.cmml" xref="S5.E3.m1.8.8.1.3"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.8.8.1.3.1.cmml" xref="S5.E3.m1.8.8.1.3"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E3.m1.8.8.1.3.2.cmml" xref="S5.E3.m1.8.8.1.3.2"&gt;𝔼&lt;/ci&gt;&lt;apply id="S5.E3.m1.2.2.2.cmml" xref="S5.E3.m1.2.2.2"&gt;&lt;csymbol cd="latexml" id="S5.E3.m1.2.2.2.3.cmml" xref="S5.E3.m1.2.2.2.3"&gt;similar-to&lt;/csymbol&gt;&lt;interval closure="open" id="S5.E3.m1.2.2.2.4.1.cmml" xref="S5.E3.m1.2.2.2.4.2"&gt;&lt;ci id="S5.E3.m1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.E3.m1.2.2.2.2.cmml" xref="S5.E3.m1.2.2.2.2"&gt;𝑝&lt;/ci&gt;&lt;/interval&gt;&lt;ci id="S5.E3.m1.2.2.2.5.cmml" xref="S5.E3.m1.2.2.2.5"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.E3.m1.8.8.1.1.2.cmml" xref="S5.E3.m1.8.8.1.1.1"&gt;&lt;csymbol cd="latexml" id="S5.E3.m1.8.8.1.1.2.1.cmml" xref="S5.E3.m1.8.8.1.1.1.2"&gt;delimited-[]&lt;/csymbol&gt;&lt;apply id="S5.E3.m1.8.8.1.1.1.1.cmml" xref="S5.E3.m1.8.8.1.1.1.1"&gt;&lt;minus id="S5.E3.m1.8.8.1.1.1.1.1.cmml" xref="S5.E3.m1.8.8.1.1.1.1"&gt;&lt;/minus&gt;&lt;apply id="S5.E3.m1.8.8.1.1.1.1.2.cmml" xref="S5.E3.m1.8.8.1.1.1.1.2"&gt;&lt;ln id="S5.E3.m1.8.8.1.1.1.1.2.1.cmml" xref="S5.E3.m1.8.8.1.1.1.1.2.1"&gt;&lt;/ln&gt;&lt;apply id="S5.E3.m1.6.6.cmml" xref="S5.E3.m1.6.6"&gt;&lt;divide id="S5.E3.m1.6.6.5.cmml" xref="S5.E3.m1.6.6"&gt;&lt;/divide&gt;&lt;apply id="S5.E3.m1.4.4.2.cmml" xref="S5.E3.m1.4.4.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.4.4.2.3.cmml" xref="S5.E3.m1.4.4.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.E3.m1.4.4.2.4.cmml" xref="S5.E3.m1.4.4.2.4"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.E3.m1.4.4.2.2.2.cmml" xref="S5.E3.m1.4.4.2.2.2"&gt;&lt;divide id="S5.E3.m1.4.4.2.2.2.3.cmml" xref="S5.E3.m1.4.4.2.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.E3.m1.4.4.2.2.2.4.cmml" xref="S5.E3.m1.4.4.2.2.2.4"&gt;&lt;times id="S5.E3.m1.4.4.2.2.2.4.1.cmml" xref="S5.E3.m1.4.4.2.2.2.4.1"&gt;&lt;/times&gt;&lt;ci id="S5.E3.m1.4.4.2.2.2.4.2.cmml" xref="S5.E3.m1.4.4.2.2.2.4.2"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.E3.m1.4.4.2.2.2.4.3.1.cmml" xref="S5.E3.m1.4.4.2.2.2.4.3.2"&gt;&lt;ci id="S5.E3.m1.3.3.1.1.1.1.cmml" xref="S5.E3.m1.3.3.1.1.1.1"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.E3.m1.4.4.2.2.2.2.cmml" xref="S5.E3.m1.4.4.2.2.2.2"&gt;𝑝&lt;/ci&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.E3.m1.4.4.2.2.2.5.cmml" xref="S5.E3.m1.4.4.2.2.2.5"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.E3.m1.6.6.4.cmml" xref="S5.E3.m1.6.6.4"&gt;&lt;apply id="S5.E3.m1.6.6.4.3.cmml" xref="S5.E3.m1.6.6.4.3"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.6.6.4.3.1.cmml" xref="S5.E3.m1.6.6.4.3"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.E3.m1.6.6.4.3.2.cmml" xref="S5.E3.m1.6.6.4.3"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.6.6.4.3.2.1.cmml" xref="S5.E3.m1.6.6.4.3"&gt;subscript&lt;/csymbol&gt;&lt;sum id="S5.E3.m1.6.6.4.3.2.2.cmml" xref="S5.E3.m1.6.6.4.3.2.2"&gt;&lt;/sum&gt;&lt;apply id="S5.E3.m1.6.6.4.3.2.3.cmml" xref="S5.E3.m1.6.6.4.3.2.3"&gt;&lt;eq id="S5.E3.m1.6.6.4.3.2.3.1.cmml" xref="S5.E3.m1.6.6.4.3.2.3.1"&gt;&lt;/eq&gt;&lt;ci id="S5.E3.m1.6.6.4.3.2.3.2.cmml" xref="S5.E3.m1.6.6.4.3.2.3.2"&gt;𝑖&lt;/ci&gt;&lt;cn id="S5.E3.m1.6.6.4.3.2.3.3.cmml" type="integer" xref="S5.E3.m1.6.6.4.3.2.3.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.E3.m1.6.6.4.3.3.cmml" xref="S5.E3.m1.6.6.4.3.3"&gt;𝑘&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.E3.m1.6.6.4.4.cmml" xref="S5.E3.m1.6.6.4.4"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.6.6.4.4.1.cmml" xref="S5.E3.m1.6.6.4.4"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.E3.m1.6.6.4.4.2.cmml" xref="S5.E3.m1.6.6.4.4.2"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.E3.m1.6.6.4.2.2.cmml" xref="S5.E3.m1.6.6.4.2.2"&gt;&lt;divide id="S5.E3.m1.6.6.4.2.2.3.cmml" xref="S5.E3.m1.6.6.4.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.E3.m1.6.6.4.2.2.2.cmml" xref="S5.E3.m1.6.6.4.2.2.2"&gt;&lt;times id="S5.E3.m1.6.6.4.2.2.2.2.cmml" xref="S5.E3.m1.6.6.4.2.2.2.2"&gt;&lt;/times&gt;&lt;ci id="S5.E3.m1.6.6.4.2.2.2.3.cmml" xref="S5.E3.m1.6.6.4.2.2.2.3"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.E3.m1.6.6.4.2.2.2.1.2.cmml" xref="S5.E3.m1.6.6.4.2.2.2.1.1"&gt;&lt;ci id="S5.E3.m1.5.5.3.1.1.1.cmml" xref="S5.E3.m1.5.5.3.1.1.1"&gt;𝑞&lt;/ci&gt;&lt;apply id="S5.E3.m1.6.6.4.2.2.2.1.1.1.cmml" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S5.E3.m1.6.6.4.2.2.2.1.1.1.1.cmml" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E3.m1.6.6.4.2.2.2.1.1.1.2.cmml" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1.2"&gt;𝑝&lt;/ci&gt;&lt;ci id="S5.E3.m1.6.6.4.2.2.2.1.1.1.3.cmml" xref="S5.E3.m1.6.6.4.2.2.2.1.1.1.3"&gt;𝑖&lt;/ci&gt;&lt;/apply&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.E3.m1.6.6.4.2.2.4.cmml" xref="S5.E3.m1.6.6.4.2.2.4"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.E3.m1.8c"&gt;\displaystyle\mathcal{L}_{\mathrm{NCE}}^{\mathrm{pairs}}(\mathbf{B}):=\mathbb{% E}_{(q,p)\sim\mathbf{B}}\left[-\ln\frac{e^{s(q,p)/\tau}}{\sum\limits_{i=1}^{k}% e^{s(q,p_{i})/\tau}}\right]&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.E3.m1.8d"&gt;caligraphic_L start_POSTSUBSCRIPT roman_NCE end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_pairs end_POSTSUPERSCRIPT ( bold_B ) := blackboard_E start_POSTSUBSCRIPT ( italic_q , italic_p ) ∼ bold_B end_POSTSUBSCRIPT [ - roman_ln divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_q , italic_p ) / italic_τ end_POSTSUPERSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_s ( italic_q , italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_τ end_POSTSUPERSCRIPT end_ARG ]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td rowspan="1"&gt;&lt;span&gt;(3)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

The function evaluates the cosine similarity s⁢(p,q)𝑠𝑝𝑞s(p,q)italic\_s ( italic\_p , italic\_q ) between a given query q𝑞qitalic\_q and its corresponding target p𝑝pitalic\_p, relative to the similarity of all other targets in the batch. Given the typically symmetric nature of similarity measures, we compute the loss in both directions:

&lt;table id="A1.EGx4"&gt;&lt;tbody id="S5.Ex2"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\mathcal{L}^{\mathrm{pairs}}(\mathbf{B})" display="inline" id="S5.Ex2.m1.1"&gt;&lt;semantics id="S5.Ex2.m1.1a"&gt;&lt;mrow id="S5.Ex2.m1.1.2" xref="S5.Ex2.m1.1.2.cmml"&gt;&lt;msup id="S5.Ex2.m1.1.2.2" xref="S5.Ex2.m1.1.2.2.cmml"&gt;&lt;mi id="S5.Ex2.m1.1.2.2.2" xref="S5.Ex2.m1.1.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;mi id="S5.Ex2.m1.1.2.2.3" xref="S5.Ex2.m1.1.2.2.3.cmml"&gt;pairs&lt;/mi&gt;&lt;/msup&gt;&lt;mo id="S5.Ex2.m1.1.2.1" xref="S5.Ex2.m1.1.2.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex2.m1.1.2.3.2" xref="S5.Ex2.m1.1.2.cmml"&gt;&lt;mo id="S5.Ex2.m1.1.2.3.2.1" stretchy="false" xref="S5.Ex2.m1.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex2.m1.1.1" xref="S5.Ex2.m1.1.1.cmml"&gt;𝐁&lt;/mi&gt;&lt;mo id="S5.Ex2.m1.1.2.3.2.2" stretchy="false" xref="S5.Ex2.m1.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.Ex2.m1.1b"&gt;&lt;apply id="S5.Ex2.m1.1.2.cmml" xref="S5.Ex2.m1.1.2"&gt;&lt;times id="S5.Ex2.m1.1.2.1.cmml" xref="S5.Ex2.m1.1.2.1"&gt;&lt;/times&gt;&lt;apply id="S5.Ex2.m1.1.2.2.cmml" xref="S5.Ex2.m1.1.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex2.m1.1.2.2.1.cmml" xref="S5.Ex2.m1.1.2.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex2.m1.1.2.2.2.cmml" xref="S5.Ex2.m1.1.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;ci id="S5.Ex2.m1.1.2.2.3.cmml" xref="S5.Ex2.m1.1.2.2.3"&gt;pairs&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S5.Ex2.m1.1.1.cmml" xref="S5.Ex2.m1.1.1"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.Ex2.m1.1c"&gt;\displaystyle\mathcal{L}^{\mathrm{pairs}}(\mathbf{B})&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.Ex2.m1.1d"&gt;caligraphic_L start_POSTSUPERSCRIPT roman_pairs end_POSTSUPERSCRIPT ( bold_B )&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle:=\mathcal{L}^{\mathrm{pairs}}_{\mathrm{NCE}}(\mathbf{B})+%
\mathcal{L}^{\mathrm{pairs}}_{\overline{\mathrm{NCE}}}(\mathbf{B}),\text{ with}" display="inline" id="S5.Ex2.m2.4"&gt;&lt;semantics id="S5.Ex2.m2.4a"&gt;&lt;mrow id="S5.Ex2.m2.4.4" xref="S5.Ex2.m2.4.4.cmml"&gt;&lt;mi id="S5.Ex2.m2.4.4.3" xref="S5.Ex2.m2.4.4.3.cmml"&gt;&lt;/mi&gt;&lt;mo id="S5.Ex2.m2.4.4.2" lspace="0.278em" rspace="0.278em" xref="S5.Ex2.m2.4.4.2.cmml"&gt;:=&lt;/mo&gt;&lt;mrow id="S5.Ex2.m2.4.4.1.1" xref="S5.Ex2.m2.4.4.1.2.cmml"&gt;&lt;mrow id="S5.Ex2.m2.4.4.1.1.1" xref="S5.Ex2.m2.4.4.1.1.1.cmml"&gt;&lt;mrow id="S5.Ex2.m2.4.4.1.1.1.2" xref="S5.Ex2.m2.4.4.1.1.1.2.cmml"&gt;&lt;msubsup id="S5.Ex2.m2.4.4.1.1.1.2.2" xref="S5.Ex2.m2.4.4.1.1.1.2.2.cmml"&gt;&lt;mi id="S5.Ex2.m2.4.4.1.1.1.2.2.2.2" xref="S5.Ex2.m2.4.4.1.1.1.2.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;mi id="S5.Ex2.m2.4.4.1.1.1.2.2.3" xref="S5.Ex2.m2.4.4.1.1.1.2.2.3.cmml"&gt;NCE&lt;/mi&gt;&lt;mi id="S5.Ex2.m2.4.4.1.1.1.2.2.2.3" xref="S5.Ex2.m2.4.4.1.1.1.2.2.2.3.cmml"&gt;pairs&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.2.1" xref="S5.Ex2.m2.4.4.1.1.1.2.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex2.m2.4.4.1.1.1.2.3.2" xref="S5.Ex2.m2.4.4.1.1.1.2.cmml"&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.2.3.2.1" stretchy="false" xref="S5.Ex2.m2.4.4.1.1.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex2.m2.1.1" xref="S5.Ex2.m2.1.1.cmml"&gt;𝐁&lt;/mi&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.2.3.2.2" stretchy="false" xref="S5.Ex2.m2.4.4.1.1.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.1" xref="S5.Ex2.m2.4.4.1.1.1.1.cmml"&gt;+&lt;/mo&gt;&lt;mrow id="S5.Ex2.m2.4.4.1.1.1.3" xref="S5.Ex2.m2.4.4.1.1.1.3.cmml"&gt;&lt;msubsup id="S5.Ex2.m2.4.4.1.1.1.3.2" xref="S5.Ex2.m2.4.4.1.1.1.3.2.cmml"&gt;&lt;mi id="S5.Ex2.m2.4.4.1.1.1.3.2.2.2" xref="S5.Ex2.m2.4.4.1.1.1.3.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;mover accent="true" id="S5.Ex2.m2.4.4.1.1.1.3.2.3" xref="S5.Ex2.m2.4.4.1.1.1.3.2.3.cmml"&gt;&lt;mi id="S5.Ex2.m2.4.4.1.1.1.3.2.3.2" xref="S5.Ex2.m2.4.4.1.1.1.3.2.3.2.cmml"&gt;NCE&lt;/mi&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.3.2.3.1" xref="S5.Ex2.m2.4.4.1.1.1.3.2.3.1.cmml"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mi id="S5.Ex2.m2.4.4.1.1.1.3.2.2.3" xref="S5.Ex2.m2.4.4.1.1.1.3.2.2.3.cmml"&gt;pairs&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.3.1" xref="S5.Ex2.m2.4.4.1.1.1.3.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex2.m2.4.4.1.1.1.3.3.2" xref="S5.Ex2.m2.4.4.1.1.1.3.cmml"&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.3.3.2.1" stretchy="false" xref="S5.Ex2.m2.4.4.1.1.1.3.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex2.m2.2.2" xref="S5.Ex2.m2.2.2.cmml"&gt;𝐁&lt;/mi&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.1.3.3.2.2" stretchy="false" xref="S5.Ex2.m2.4.4.1.1.1.3.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex2.m2.4.4.1.1.2" xref="S5.Ex2.m2.4.4.1.2.cmml"&gt;,&lt;/mo&gt;&lt;mtext id="S5.Ex2.m2.3.3" xref="S5.Ex2.m2.3.3a.cmml"&gt;&amp;nbsp;with&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.Ex2.m2.4b"&gt;&lt;apply id="S5.Ex2.m2.4.4.cmml" xref="S5.Ex2.m2.4.4"&gt;&lt;csymbol cd="latexml" id="S5.Ex2.m2.4.4.2.cmml" xref="S5.Ex2.m2.4.4.2"&gt;assign&lt;/csymbol&gt;&lt;csymbol cd="latexml" id="S5.Ex2.m2.4.4.3.cmml" xref="S5.Ex2.m2.4.4.3"&gt;absent&lt;/csymbol&gt;&lt;list id="S5.Ex2.m2.4.4.1.2.cmml" xref="S5.Ex2.m2.4.4.1.1"&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1"&gt;&lt;plus id="S5.Ex2.m2.4.4.1.1.1.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.1"&gt;&lt;/plus&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2"&gt;&lt;times id="S5.Ex2.m2.4.4.1.1.1.2.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.1"&gt;&lt;/times&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.2.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex2.m2.4.4.1.1.1.2.2.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2"&gt;subscript&lt;/csymbol&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.2.2.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex2.m2.4.4.1.1.1.2.2.2.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.2.2.2.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.2.2.2.3.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2.2.3"&gt;pairs&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.2.2.3.cmml" xref="S5.Ex2.m2.4.4.1.1.1.2.2.3"&gt;NCE&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S5.Ex2.m2.1.1.cmml" xref="S5.Ex2.m2.1.1"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.3.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3"&gt;&lt;times id="S5.Ex2.m2.4.4.1.1.1.3.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.1"&gt;&lt;/times&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.3.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex2.m2.4.4.1.1.1.3.2.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2"&gt;subscript&lt;/csymbol&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.3.2.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex2.m2.4.4.1.1.1.3.2.2.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.3.2.2.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.3.2.2.3.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2.2.3"&gt;pairs&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.Ex2.m2.4.4.1.1.1.3.2.3.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2.3"&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.3.2.3.1.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2.3.1"&gt;¯&lt;/ci&gt;&lt;ci id="S5.Ex2.m2.4.4.1.1.1.3.2.3.2.cmml" xref="S5.Ex2.m2.4.4.1.1.1.3.2.3.2"&gt;NCE&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.Ex2.m2.2.2.cmml" xref="S5.Ex2.m2.2.2"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.Ex2.m2.3.3a.cmml" xref="S5.Ex2.m2.3.3"&gt;&lt;mtext id="S5.Ex2.m2.3.3.cmml" xref="S5.Ex2.m2.3.3"&gt;&amp;nbsp;with&lt;/mtext&gt;&lt;/ci&gt;&lt;/list&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.Ex2.m2.4c"&gt;\displaystyle:=\mathcal{L}^{\mathrm{pairs}}_{\mathrm{NCE}}(\mathbf{B})+% \mathcal{L}^{\mathrm{pairs}}_{\overline{\mathrm{NCE}}}(\mathbf{B}),\text{ with}&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.Ex2.m2.4d"&gt;:= caligraphic_L start_POSTSUPERSCRIPT roman_pairs end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_NCE end_POSTSUBSCRIPT ( bold_B ) + caligraphic_L start_POSTSUPERSCRIPT roman_pairs end_POSTSUPERSCRIPT start_POSTSUBSCRIPT over¯ start_ARG roman_NCE end_ARG end_POSTSUBSCRIPT ( bold_B ) , with&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;tbody id="S5.E4"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\mathcal{L}_{\overline{\mathrm{NCE}}}^{\mathrm{pairs}}(\mathbf{B})" display="inline" id="S5.E4.m1.1"&gt;&lt;semantics id="S5.E4.m1.1a"&gt;&lt;mrow id="S5.E4.m1.1.2" xref="S5.E4.m1.1.2.cmml"&gt;&lt;msubsup id="S5.E4.m1.1.2.2" xref="S5.E4.m1.1.2.2.cmml"&gt;&lt;mi id="S5.E4.m1.1.2.2.2.2" xref="S5.E4.m1.1.2.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;mover accent="true" id="S5.E4.m1.1.2.2.2.3" xref="S5.E4.m1.1.2.2.2.3.cmml"&gt;&lt;mi id="S5.E4.m1.1.2.2.2.3.2" xref="S5.E4.m1.1.2.2.2.3.2.cmml"&gt;NCE&lt;/mi&gt;&lt;mo id="S5.E4.m1.1.2.2.2.3.1" xref="S5.E4.m1.1.2.2.2.3.1.cmml"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mi id="S5.E4.m1.1.2.2.3" xref="S5.E4.m1.1.2.2.3.cmml"&gt;pairs&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo id="S5.E4.m1.1.2.1" xref="S5.E4.m1.1.2.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E4.m1.1.2.3.2" xref="S5.E4.m1.1.2.cmml"&gt;&lt;mo id="S5.E4.m1.1.2.3.2.1" stretchy="false" xref="S5.E4.m1.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E4.m1.1.1" xref="S5.E4.m1.1.1.cmml"&gt;𝐁&lt;/mi&gt;&lt;mo id="S5.E4.m1.1.2.3.2.2" stretchy="false" xref="S5.E4.m1.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.E4.m1.1b"&gt;&lt;apply id="S5.E4.m1.1.2.cmml" xref="S5.E4.m1.1.2"&gt;&lt;times id="S5.E4.m1.1.2.1.cmml" xref="S5.E4.m1.1.2.1"&gt;&lt;/times&gt;&lt;apply id="S5.E4.m1.1.2.2.cmml" xref="S5.E4.m1.1.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m1.1.2.2.1.cmml" xref="S5.E4.m1.1.2.2"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.E4.m1.1.2.2.2.cmml" xref="S5.E4.m1.1.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m1.1.2.2.2.1.cmml" xref="S5.E4.m1.1.2.2"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E4.m1.1.2.2.2.2.cmml" xref="S5.E4.m1.1.2.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;apply id="S5.E4.m1.1.2.2.2.3.cmml" xref="S5.E4.m1.1.2.2.2.3"&gt;&lt;ci id="S5.E4.m1.1.2.2.2.3.1.cmml" xref="S5.E4.m1.1.2.2.2.3.1"&gt;¯&lt;/ci&gt;&lt;ci id="S5.E4.m1.1.2.2.2.3.2.cmml" xref="S5.E4.m1.1.2.2.2.3.2"&gt;NCE&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.E4.m1.1.2.2.3.cmml" xref="S5.E4.m1.1.2.2.3"&gt;pairs&lt;/ci&gt;&lt;/apply&gt;&lt;ci id="S5.E4.m1.1.1.cmml" xref="S5.E4.m1.1.1"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.E4.m1.1c"&gt;\displaystyle\mathcal{L}_{\overline{\mathrm{NCE}}}^{\mathrm{pairs}}(\mathbf{B})&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.E4.m1.1d"&gt;caligraphic_L start_POSTSUBSCRIPT over¯ start_ARG roman_NCE end_ARG end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_pairs end_POSTSUPERSCRIPT ( bold_B )&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle:=\mathbb{E}_{(q,p)\sim\mathbf{B}}\left[-\ln\frac{e^{s(p,q)/\tau}%
}{\sum\limits_{i=1}^{k}e^{s(p,q_{i})/\tau}}\right]" display="inline" id="S5.E4.m2.7"&gt;&lt;semantics id="S5.E4.m2.7a"&gt;&lt;mrow id="S5.E4.m2.7.7" xref="S5.E4.m2.7.7.cmml"&gt;&lt;mi id="S5.E4.m2.7.7.3" xref="S5.E4.m2.7.7.3.cmml"&gt;&lt;/mi&gt;&lt;mo id="S5.E4.m2.7.7.2" lspace="0.278em" rspace="0.278em" xref="S5.E4.m2.7.7.2.cmml"&gt;:=&lt;/mo&gt;&lt;mrow id="S5.E4.m2.7.7.1" xref="S5.E4.m2.7.7.1.cmml"&gt;&lt;msub id="S5.E4.m2.7.7.1.3" xref="S5.E4.m2.7.7.1.3.cmml"&gt;&lt;mi id="S5.E4.m2.7.7.1.3.2" xref="S5.E4.m2.7.7.1.3.2.cmml"&gt;𝔼&lt;/mi&gt;&lt;mrow id="S5.E4.m2.2.2.2" xref="S5.E4.m2.2.2.2.cmml"&gt;&lt;mrow id="S5.E4.m2.2.2.2.4.2" xref="S5.E4.m2.2.2.2.4.1.cmml"&gt;&lt;mo id="S5.E4.m2.2.2.2.4.2.1" stretchy="false" xref="S5.E4.m2.2.2.2.4.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E4.m2.1.1.1.1" xref="S5.E4.m2.1.1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.E4.m2.2.2.2.4.2.2" xref="S5.E4.m2.2.2.2.4.1.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.E4.m2.2.2.2.2" xref="S5.E4.m2.2.2.2.2.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.E4.m2.2.2.2.4.2.3" stretchy="false" xref="S5.E4.m2.2.2.2.4.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo id="S5.E4.m2.2.2.2.3" xref="S5.E4.m2.2.2.2.3.cmml"&gt;∼&lt;/mo&gt;&lt;mi id="S5.E4.m2.2.2.2.5" xref="S5.E4.m2.2.2.2.5.cmml"&gt;𝐁&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo id="S5.E4.m2.7.7.1.2" xref="S5.E4.m2.7.7.1.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E4.m2.7.7.1.1.1" xref="S5.E4.m2.7.7.1.1.2.cmml"&gt;&lt;mo id="S5.E4.m2.7.7.1.1.1.2" xref="S5.E4.m2.7.7.1.1.2.1.cmml"&gt;[&lt;/mo&gt;&lt;mrow id="S5.E4.m2.7.7.1.1.1.1" xref="S5.E4.m2.7.7.1.1.1.1.cmml"&gt;&lt;mo id="S5.E4.m2.7.7.1.1.1.1a" rspace="0.167em" xref="S5.E4.m2.7.7.1.1.1.1.cmml"&gt;−&lt;/mo&gt;&lt;mrow id="S5.E4.m2.7.7.1.1.1.1.2" xref="S5.E4.m2.7.7.1.1.1.1.2.cmml"&gt;&lt;mi id="S5.E4.m2.7.7.1.1.1.1.2.1" xref="S5.E4.m2.7.7.1.1.1.1.2.1.cmml"&gt;ln&lt;/mi&gt;&lt;mo id="S5.E4.m2.7.7.1.1.1.1.2a" lspace="0.167em" xref="S5.E4.m2.7.7.1.1.1.1.2.cmml"&gt;⁡&lt;/mo&gt;&lt;mstyle displaystyle="true" id="S5.E4.m2.6.6" xref="S5.E4.m2.6.6.cmml"&gt;&lt;mfrac id="S5.E4.m2.6.6a" xref="S5.E4.m2.6.6.cmml"&gt;&lt;msup id="S5.E4.m2.4.4.2" xref="S5.E4.m2.4.4.2.cmml"&gt;&lt;mi id="S5.E4.m2.4.4.2.4" xref="S5.E4.m2.4.4.2.4.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.E4.m2.4.4.2.2.2" xref="S5.E4.m2.4.4.2.2.2.cmml"&gt;&lt;mrow id="S5.E4.m2.4.4.2.2.2.4" xref="S5.E4.m2.4.4.2.2.2.4.cmml"&gt;&lt;mi id="S5.E4.m2.4.4.2.2.2.4.2" xref="S5.E4.m2.4.4.2.2.2.4.2.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.E4.m2.4.4.2.2.2.4.1" xref="S5.E4.m2.4.4.2.2.2.4.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E4.m2.4.4.2.2.2.4.3.2" xref="S5.E4.m2.4.4.2.2.2.4.3.1.cmml"&gt;&lt;mo id="S5.E4.m2.4.4.2.2.2.4.3.2.1" stretchy="false" xref="S5.E4.m2.4.4.2.2.2.4.3.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E4.m2.3.3.1.1.1.1" xref="S5.E4.m2.3.3.1.1.1.1.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.E4.m2.4.4.2.2.2.4.3.2.2" xref="S5.E4.m2.4.4.2.2.2.4.3.1.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.E4.m2.4.4.2.2.2.2" xref="S5.E4.m2.4.4.2.2.2.2.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.E4.m2.4.4.2.2.2.4.3.2.3" stretchy="false" xref="S5.E4.m2.4.4.2.2.2.4.3.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E4.m2.4.4.2.2.2.3" xref="S5.E4.m2.4.4.2.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.E4.m2.4.4.2.2.2.5" xref="S5.E4.m2.4.4.2.2.2.5.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow id="S5.E4.m2.6.6.4" xref="S5.E4.m2.6.6.4.cmml"&gt;&lt;munderover id="S5.E4.m2.6.6.4.3" xref="S5.E4.m2.6.6.4.3.cmml"&gt;&lt;mo id="S5.E4.m2.6.6.4.3.2.2" movablelimits="false" xref="S5.E4.m2.6.6.4.3.2.2.cmml"&gt;∑&lt;/mo&gt;&lt;mrow id="S5.E4.m2.6.6.4.3.2.3" xref="S5.E4.m2.6.6.4.3.2.3.cmml"&gt;&lt;mi id="S5.E4.m2.6.6.4.3.2.3.2" xref="S5.E4.m2.6.6.4.3.2.3.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S5.E4.m2.6.6.4.3.2.3.1" xref="S5.E4.m2.6.6.4.3.2.3.1.cmml"&gt;=&lt;/mo&gt;&lt;mn id="S5.E4.m2.6.6.4.3.2.3.3" xref="S5.E4.m2.6.6.4.3.2.3.3.cmml"&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi id="S5.E4.m2.6.6.4.3.3" xref="S5.E4.m2.6.6.4.3.3.cmml"&gt;k&lt;/mi&gt;&lt;/munderover&gt;&lt;msup id="S5.E4.m2.6.6.4.4" xref="S5.E4.m2.6.6.4.4.cmml"&gt;&lt;mi id="S5.E4.m2.6.6.4.4.2" xref="S5.E4.m2.6.6.4.4.2.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.E4.m2.6.6.4.2.2" xref="S5.E4.m2.6.6.4.2.2.cmml"&gt;&lt;mrow id="S5.E4.m2.6.6.4.2.2.2" xref="S5.E4.m2.6.6.4.2.2.2.cmml"&gt;&lt;mi id="S5.E4.m2.6.6.4.2.2.2.3" xref="S5.E4.m2.6.6.4.2.2.2.3.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.E4.m2.6.6.4.2.2.2.2" xref="S5.E4.m2.6.6.4.2.2.2.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.E4.m2.6.6.4.2.2.2.1.1" xref="S5.E4.m2.6.6.4.2.2.2.1.2.cmml"&gt;&lt;mo id="S5.E4.m2.6.6.4.2.2.2.1.1.2" stretchy="false" xref="S5.E4.m2.6.6.4.2.2.2.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E4.m2.5.5.3.1.1.1" xref="S5.E4.m2.5.5.3.1.1.1.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.E4.m2.6.6.4.2.2.2.1.1.3" xref="S5.E4.m2.6.6.4.2.2.2.1.2.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.E4.m2.6.6.4.2.2.2.1.1.1" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1.cmml"&gt;&lt;mi id="S5.E4.m2.6.6.4.2.2.2.1.1.1.2" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1.2.cmml"&gt;q&lt;/mi&gt;&lt;mi id="S5.E4.m2.6.6.4.2.2.2.1.1.1.3" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1.3.cmml"&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S5.E4.m2.6.6.4.2.2.2.1.1.4" stretchy="false" xref="S5.E4.m2.6.6.4.2.2.2.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E4.m2.6.6.4.2.2.3" xref="S5.E4.m2.6.6.4.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.E4.m2.6.6.4.2.2.4" xref="S5.E4.m2.6.6.4.2.2.4.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E4.m2.7.7.1.1.1.3" xref="S5.E4.m2.7.7.1.1.2.1.cmml"&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.E4.m2.7b"&gt;&lt;apply id="S5.E4.m2.7.7.cmml" xref="S5.E4.m2.7.7"&gt;&lt;csymbol cd="latexml" id="S5.E4.m2.7.7.2.cmml" xref="S5.E4.m2.7.7.2"&gt;assign&lt;/csymbol&gt;&lt;csymbol cd="latexml" id="S5.E4.m2.7.7.3.cmml" xref="S5.E4.m2.7.7.3"&gt;absent&lt;/csymbol&gt;&lt;apply id="S5.E4.m2.7.7.1.cmml" xref="S5.E4.m2.7.7.1"&gt;&lt;times id="S5.E4.m2.7.7.1.2.cmml" xref="S5.E4.m2.7.7.1.2"&gt;&lt;/times&gt;&lt;apply id="S5.E4.m2.7.7.1.3.cmml" xref="S5.E4.m2.7.7.1.3"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m2.7.7.1.3.1.cmml" xref="S5.E4.m2.7.7.1.3"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E4.m2.7.7.1.3.2.cmml" xref="S5.E4.m2.7.7.1.3.2"&gt;𝔼&lt;/ci&gt;&lt;apply id="S5.E4.m2.2.2.2.cmml" xref="S5.E4.m2.2.2.2"&gt;&lt;csymbol cd="latexml" id="S5.E4.m2.2.2.2.3.cmml" xref="S5.E4.m2.2.2.2.3"&gt;similar-to&lt;/csymbol&gt;&lt;interval closure="open" id="S5.E4.m2.2.2.2.4.1.cmml" xref="S5.E4.m2.2.2.2.4.2"&gt;&lt;ci id="S5.E4.m2.1.1.1.1.cmml" xref="S5.E4.m2.1.1.1.1"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.E4.m2.2.2.2.2.cmml" xref="S5.E4.m2.2.2.2.2"&gt;𝑝&lt;/ci&gt;&lt;/interval&gt;&lt;ci id="S5.E4.m2.2.2.2.5.cmml" xref="S5.E4.m2.2.2.2.5"&gt;𝐁&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.E4.m2.7.7.1.1.2.cmml" xref="S5.E4.m2.7.7.1.1.1"&gt;&lt;csymbol cd="latexml" id="S5.E4.m2.7.7.1.1.2.1.cmml" xref="S5.E4.m2.7.7.1.1.1.2"&gt;delimited-[]&lt;/csymbol&gt;&lt;apply id="S5.E4.m2.7.7.1.1.1.1.cmml" xref="S5.E4.m2.7.7.1.1.1.1"&gt;&lt;minus id="S5.E4.m2.7.7.1.1.1.1.1.cmml" xref="S5.E4.m2.7.7.1.1.1.1"&gt;&lt;/minus&gt;&lt;apply id="S5.E4.m2.7.7.1.1.1.1.2.cmml" xref="S5.E4.m2.7.7.1.1.1.1.2"&gt;&lt;ln id="S5.E4.m2.7.7.1.1.1.1.2.1.cmml" xref="S5.E4.m2.7.7.1.1.1.1.2.1"&gt;&lt;/ln&gt;&lt;apply id="S5.E4.m2.6.6.cmml" xref="S5.E4.m2.6.6"&gt;&lt;divide id="S5.E4.m2.6.6.5.cmml" xref="S5.E4.m2.6.6"&gt;&lt;/divide&gt;&lt;apply id="S5.E4.m2.4.4.2.cmml" xref="S5.E4.m2.4.4.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m2.4.4.2.3.cmml" xref="S5.E4.m2.4.4.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.E4.m2.4.4.2.4.cmml" xref="S5.E4.m2.4.4.2.4"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.E4.m2.4.4.2.2.2.cmml" xref="S5.E4.m2.4.4.2.2.2"&gt;&lt;divide id="S5.E4.m2.4.4.2.2.2.3.cmml" xref="S5.E4.m2.4.4.2.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.E4.m2.4.4.2.2.2.4.cmml" xref="S5.E4.m2.4.4.2.2.2.4"&gt;&lt;times id="S5.E4.m2.4.4.2.2.2.4.1.cmml" xref="S5.E4.m2.4.4.2.2.2.4.1"&gt;&lt;/times&gt;&lt;ci id="S5.E4.m2.4.4.2.2.2.4.2.cmml" xref="S5.E4.m2.4.4.2.2.2.4.2"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.E4.m2.4.4.2.2.2.4.3.1.cmml" xref="S5.E4.m2.4.4.2.2.2.4.3.2"&gt;&lt;ci id="S5.E4.m2.3.3.1.1.1.1.cmml" xref="S5.E4.m2.3.3.1.1.1.1"&gt;𝑝&lt;/ci&gt;&lt;ci id="S5.E4.m2.4.4.2.2.2.2.cmml" xref="S5.E4.m2.4.4.2.2.2.2"&gt;𝑞&lt;/ci&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.E4.m2.4.4.2.2.2.5.cmml" xref="S5.E4.m2.4.4.2.2.2.5"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.E4.m2.6.6.4.cmml" xref="S5.E4.m2.6.6.4"&gt;&lt;apply id="S5.E4.m2.6.6.4.3.cmml" xref="S5.E4.m2.6.6.4.3"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m2.6.6.4.3.1.cmml" xref="S5.E4.m2.6.6.4.3"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.E4.m2.6.6.4.3.2.cmml" xref="S5.E4.m2.6.6.4.3"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m2.6.6.4.3.2.1.cmml" xref="S5.E4.m2.6.6.4.3"&gt;subscript&lt;/csymbol&gt;&lt;sum id="S5.E4.m2.6.6.4.3.2.2.cmml" xref="S5.E4.m2.6.6.4.3.2.2"&gt;&lt;/sum&gt;&lt;apply id="S5.E4.m2.6.6.4.3.2.3.cmml" xref="S5.E4.m2.6.6.4.3.2.3"&gt;&lt;eq id="S5.E4.m2.6.6.4.3.2.3.1.cmml" xref="S5.E4.m2.6.6.4.3.2.3.1"&gt;&lt;/eq&gt;&lt;ci id="S5.E4.m2.6.6.4.3.2.3.2.cmml" xref="S5.E4.m2.6.6.4.3.2.3.2"&gt;𝑖&lt;/ci&gt;&lt;cn id="S5.E4.m2.6.6.4.3.2.3.3.cmml" type="integer" xref="S5.E4.m2.6.6.4.3.2.3.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.E4.m2.6.6.4.3.3.cmml" xref="S5.E4.m2.6.6.4.3.3"&gt;𝑘&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.E4.m2.6.6.4.4.cmml" xref="S5.E4.m2.6.6.4.4"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m2.6.6.4.4.1.cmml" xref="S5.E4.m2.6.6.4.4"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.E4.m2.6.6.4.4.2.cmml" xref="S5.E4.m2.6.6.4.4.2"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.E4.m2.6.6.4.2.2.cmml" xref="S5.E4.m2.6.6.4.2.2"&gt;&lt;divide id="S5.E4.m2.6.6.4.2.2.3.cmml" xref="S5.E4.m2.6.6.4.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.E4.m2.6.6.4.2.2.2.cmml" xref="S5.E4.m2.6.6.4.2.2.2"&gt;&lt;times id="S5.E4.m2.6.6.4.2.2.2.2.cmml" xref="S5.E4.m2.6.6.4.2.2.2.2"&gt;&lt;/times&gt;&lt;ci id="S5.E4.m2.6.6.4.2.2.2.3.cmml" xref="S5.E4.m2.6.6.4.2.2.2.3"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.E4.m2.6.6.4.2.2.2.1.2.cmml" xref="S5.E4.m2.6.6.4.2.2.2.1.1"&gt;&lt;ci id="S5.E4.m2.5.5.3.1.1.1.cmml" xref="S5.E4.m2.5.5.3.1.1.1"&gt;𝑝&lt;/ci&gt;&lt;apply id="S5.E4.m2.6.6.4.2.2.2.1.1.1.cmml" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S5.E4.m2.6.6.4.2.2.2.1.1.1.1.cmml" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E4.m2.6.6.4.2.2.2.1.1.1.2.cmml" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1.2"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.E4.m2.6.6.4.2.2.2.1.1.1.3.cmml" xref="S5.E4.m2.6.6.4.2.2.2.1.1.1.3"&gt;𝑖&lt;/ci&gt;&lt;/apply&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.E4.m2.6.6.4.2.2.4.cmml" xref="S5.E4.m2.6.6.4.2.2.4"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.E4.m2.7c"&gt;\displaystyle:=\mathbb{E}_{(q,p)\sim\mathbf{B}}\left[-\ln\frac{e^{s(p,q)/\tau}% }{\sum\limits_{i=1}^{k}e^{s(p,q_{i})/\tau}}\right]&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.E4.m2.7d"&gt;:= blackboard_E start_POSTSUBSCRIPT ( italic_q , italic_p ) ∼ bold_B end_POSTSUBSCRIPT [ - roman_ln divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_p , italic_q ) / italic_τ end_POSTSUPERSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_s ( italic_p , italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_τ end_POSTSUPERSCRIPT end_ARG ]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td rowspan="1"&gt;&lt;span&gt;(4)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

The constant temperature parameter τ𝜏\\tauitalic\_τ influences how the loss function weighs minor differences in the similarity scores Wang and Liu ([2021](https://arxiv.org/html/2310.19923v4#bib.bib26)). Empirical testing suggests that τ\=0.05𝜏0.05\\tau=0.05italic\_τ = 0.05 is effective.

### 5.2 Fine-tuning with Hard Negatives

The goal of the supervised fine-tuning stage is to improve the models’ ranking capabilities. This improvement is achieved by training with datasets that include additional negative examples.

##### Training Data

We have prepared retrieval datasets, such as MSMarco Bajaj et al. ([2016](https://arxiv.org/html/2310.19923v4#bib.bib27)) and Natural Questions (NQ) Kwiatkowski et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib28)), in addition to multiple non-retrieval datasets like the Natural Language Inference (NLI) dataset Bowman et al. ([2015](https://arxiv.org/html/2310.19923v4#bib.bib29)). These datasets encompass a collection of queries with annotated relevant passages and several negative examples, consistent with earlier work Wang et al. ([2022](https://arxiv.org/html/2310.19923v4#bib.bib4)). Each training batch B𝐵Bitalic\_B, structured as (q,p,n1,…,n15)𝑞𝑝subscript𝑛1…subscript𝑛15(q,p,n\_{1},\\ldots,n\_{15})( italic\_q , italic\_p , italic\_n start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , … , italic\_n start\_POSTSUBSCRIPT 15 end\_POSTSUBSCRIPT ), includes one positive and 15 negative instances. For retrieval datasets, hard negatives are discerned by identifying passages deemed similar by retrieval models. This approach instructs the model to prioritize relevant documents over those that are merely semantically related. For non-retrieval datasets, negatives are selected randomly, since drawing a clear line between positives and hard negatives isn’t feasible. This is because, unlike relevancy, it’s challenging to make a binary determination regarding the similarity or dissimilarity of two textual values. Consequently, opting for hard negatives in such datasets seemed to diminish the models’ quality. Nonetheless, it remains crucial to integrate these datasets into the stage [III](https://arxiv.org/html/2310.19923v4#S3.I1.i3 "item III ‣ 3 Training Paradigm Overview ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") training to ensure continued performance on non-retrieval tasks. To ensure that hard negative passages are indeed less relevant than the annotated relevant ones, we employ a cross-encoder model to validate that their relevance score is indeed lower.

##### Loss Function:

Our training employs a modified variant of the InfoNCE loss function, denoted as ℒNCE+subscriptℒsuperscriptNCE\\mathcal{L}\_{\\mathrm{NCE}^{+}}caligraphic\_L start\_POSTSUBSCRIPT roman\_NCE start\_POSTSUPERSCRIPT + end\_POSTSUPERSCRIPT end\_POSTSUBSCRIPT and described by Equation ([5](https://arxiv.org/html/2310.19923v4#S5.E5 "5 ‣ Loss Function: ‣ 5.2 Fine-tuning with Hard Negatives ‣ 5 Fine-Tuning for Embeddings ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents")). Similar to the preceding loss function, this one is bidirectional and incorporates the additional negatives when pairing queries with passages:

&lt;table id="A1.EGx5"&gt;&lt;tbody id="S5.Ex3"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\mathcal{L}_{\mathrm{NCE}^{+}}(B):=" display="inline" id="S5.Ex3.m1.1"&gt;&lt;semantics id="S5.Ex3.m1.1a"&gt;&lt;mrow id="S5.Ex3.m1.1.2" xref="S5.Ex3.m1.1.2.cmml"&gt;&lt;mrow id="S5.Ex3.m1.1.2.2" xref="S5.Ex3.m1.1.2.2.cmml"&gt;&lt;msub id="S5.Ex3.m1.1.2.2.2" xref="S5.Ex3.m1.1.2.2.2.cmml"&gt;&lt;mi id="S5.Ex3.m1.1.2.2.2.2" xref="S5.Ex3.m1.1.2.2.2.2.cmml"&gt;ℒ&lt;/mi&gt;&lt;msup id="S5.Ex3.m1.1.2.2.2.3" xref="S5.Ex3.m1.1.2.2.2.3.cmml"&gt;&lt;mi id="S5.Ex3.m1.1.2.2.2.3.2" xref="S5.Ex3.m1.1.2.2.2.3.2.cmml"&gt;NCE&lt;/mi&gt;&lt;mo id="S5.Ex3.m1.1.2.2.2.3.3" xref="S5.Ex3.m1.1.2.2.2.3.3.cmml"&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;/msub&gt;&lt;mo id="S5.Ex3.m1.1.2.2.1" xref="S5.Ex3.m1.1.2.2.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex3.m1.1.2.2.3.2" xref="S5.Ex3.m1.1.2.2.cmml"&gt;&lt;mo id="S5.Ex3.m1.1.2.2.3.2.1" stretchy="false" xref="S5.Ex3.m1.1.2.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex3.m1.1.1" xref="S5.Ex3.m1.1.1.cmml"&gt;B&lt;/mi&gt;&lt;mo id="S5.Ex3.m1.1.2.2.3.2.2" rspace="0.278em" stretchy="false" xref="S5.Ex3.m1.1.2.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex3.m1.1.2.1" rspace="0.278em" xref="S5.Ex3.m1.1.2.1.cmml"&gt;:=&lt;/mo&gt;&lt;mi id="S5.Ex3.m1.1.2.3" xref="S5.Ex3.m1.1.2.3.cmml"&gt;&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.Ex3.m1.1b"&gt;&lt;apply id="S5.Ex3.m1.1.2.cmml" xref="S5.Ex3.m1.1.2"&gt;&lt;csymbol cd="latexml" id="S5.Ex3.m1.1.2.1.cmml" xref="S5.Ex3.m1.1.2.1"&gt;assign&lt;/csymbol&gt;&lt;apply id="S5.Ex3.m1.1.2.2.cmml" xref="S5.Ex3.m1.1.2.2"&gt;&lt;times id="S5.Ex3.m1.1.2.2.1.cmml" xref="S5.Ex3.m1.1.2.2.1"&gt;&lt;/times&gt;&lt;apply id="S5.Ex3.m1.1.2.2.2.cmml" xref="S5.Ex3.m1.1.2.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex3.m1.1.2.2.2.1.cmml" xref="S5.Ex3.m1.1.2.2.2"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.Ex3.m1.1.2.2.2.2.cmml" xref="S5.Ex3.m1.1.2.2.2.2"&gt;ℒ&lt;/ci&gt;&lt;apply id="S5.Ex3.m1.1.2.2.2.3.cmml" xref="S5.Ex3.m1.1.2.2.2.3"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex3.m1.1.2.2.2.3.1.cmml" xref="S5.Ex3.m1.1.2.2.2.3"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex3.m1.1.2.2.2.3.2.cmml" xref="S5.Ex3.m1.1.2.2.2.3.2"&gt;NCE&lt;/ci&gt;&lt;plus id="S5.Ex3.m1.1.2.2.2.3.3.cmml" xref="S5.Ex3.m1.1.2.2.2.3.3"&gt;&lt;/plus&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.Ex3.m1.1.1.cmml" xref="S5.Ex3.m1.1.1"&gt;𝐵&lt;/ci&gt;&lt;/apply&gt;&lt;csymbol cd="latexml" id="S5.Ex3.m1.1.2.3.cmml" xref="S5.Ex3.m1.1.2.3"&gt;absent&lt;/csymbol&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.Ex3.m1.1c"&gt;\displaystyle\mathcal{L}_{\mathrm{NCE}^{+}}(B):=&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.Ex3.m1.1d"&gt;caligraphic_L start_POSTSUBSCRIPT roman_NCE start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_B ) :=&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;tbody id="S5.Ex4"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\;\;\;\;\;\mathbb{E}_{r\sim B}\Bigg{[}-\ln\frac{e^{s(q,p)/\tau}}{%
\sum\limits_{i=1}^{k}\Big{[}e^{s(q,p_{i})/\tau}+\sum\limits_{j=1}^{15}e^{s(q,n%
_{j,i})/\tau}\Big{]}}\Bigg{]}" display="inline" id="S5.Ex4.m1.10"&gt;&lt;semantics id="S5.Ex4.m1.10a"&gt;&lt;mrow id="S5.Ex4.m1.10.10" xref="S5.Ex4.m1.10.10.cmml"&gt;&lt;msub id="S5.Ex4.m1.10.10.3" xref="S5.Ex4.m1.10.10.3.cmml"&gt;&lt;mi id="S5.Ex4.m1.10.10.3.2" xref="S5.Ex4.m1.10.10.3.2.cmml"&gt;𝔼&lt;/mi&gt;&lt;mrow id="S5.Ex4.m1.10.10.3.3" xref="S5.Ex4.m1.10.10.3.3.cmml"&gt;&lt;mi id="S5.Ex4.m1.10.10.3.3.2" xref="S5.Ex4.m1.10.10.3.3.2.cmml"&gt;r&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.10.10.3.3.1" xref="S5.Ex4.m1.10.10.3.3.1.cmml"&gt;∼&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.10.10.3.3.3" xref="S5.Ex4.m1.10.10.3.3.3.cmml"&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo id="S5.Ex4.m1.10.10.2" xref="S5.Ex4.m1.10.10.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.10.10.1.1" xref="S5.Ex4.m1.10.10.1.2.cmml"&gt;&lt;mo id="S5.Ex4.m1.10.10.1.1.2" maxsize="260%" minsize="260%" xref="S5.Ex4.m1.10.10.1.2.1.cmml"&gt;[&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.10.10.1.1.1" xref="S5.Ex4.m1.10.10.1.1.1.cmml"&gt;&lt;mo id="S5.Ex4.m1.10.10.1.1.1a" rspace="0.167em" xref="S5.Ex4.m1.10.10.1.1.1.cmml"&gt;−&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.10.10.1.1.1.2" xref="S5.Ex4.m1.10.10.1.1.1.2.cmml"&gt;&lt;mi id="S5.Ex4.m1.10.10.1.1.1.2.1" xref="S5.Ex4.m1.10.10.1.1.1.2.1.cmml"&gt;ln&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.10.10.1.1.1.2a" lspace="0.167em" xref="S5.Ex4.m1.10.10.1.1.1.2.cmml"&gt;⁡&lt;/mo&gt;&lt;mstyle displaystyle="true" id="S5.Ex4.m1.9.9" xref="S5.Ex4.m1.9.9.cmml"&gt;&lt;mfrac id="S5.Ex4.m1.9.9a" xref="S5.Ex4.m1.9.9.cmml"&gt;&lt;msup id="S5.Ex4.m1.2.2.2" xref="S5.Ex4.m1.2.2.2.cmml"&gt;&lt;mi id="S5.Ex4.m1.2.2.2.4" xref="S5.Ex4.m1.2.2.2.4.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.Ex4.m1.2.2.2.2.2" xref="S5.Ex4.m1.2.2.2.2.2.cmml"&gt;&lt;mrow id="S5.Ex4.m1.2.2.2.2.2.4" xref="S5.Ex4.m1.2.2.2.2.2.4.cmml"&gt;&lt;mi id="S5.Ex4.m1.2.2.2.2.2.4.2" xref="S5.Ex4.m1.2.2.2.2.2.4.2.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.2.2.2.2.2.4.1" xref="S5.Ex4.m1.2.2.2.2.2.4.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.2.2.2.2.2.4.3.2" xref="S5.Ex4.m1.2.2.2.2.2.4.3.1.cmml"&gt;&lt;mo id="S5.Ex4.m1.2.2.2.2.2.4.3.2.1" stretchy="false" xref="S5.Ex4.m1.2.2.2.2.2.4.3.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.1.1.1.1.1.1" xref="S5.Ex4.m1.1.1.1.1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.2.2.2.2.2.4.3.2.2" xref="S5.Ex4.m1.2.2.2.2.2.4.3.1.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.2.2.2.2.2.2" xref="S5.Ex4.m1.2.2.2.2.2.2.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.2.2.2.2.2.4.3.2.3" stretchy="false" xref="S5.Ex4.m1.2.2.2.2.2.4.3.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex4.m1.2.2.2.2.2.3" xref="S5.Ex4.m1.2.2.2.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.2.2.2.2.2.5" xref="S5.Ex4.m1.2.2.2.2.2.5.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow id="S5.Ex4.m1.9.9.9" xref="S5.Ex4.m1.9.9.9.cmml"&gt;&lt;munderover id="S5.Ex4.m1.9.9.9.8" xref="S5.Ex4.m1.9.9.9.8.cmml"&gt;&lt;mo id="S5.Ex4.m1.9.9.9.8.2.2" movablelimits="false" xref="S5.Ex4.m1.9.9.9.8.2.2.cmml"&gt;∑&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.9.9.9.8.2.3" xref="S5.Ex4.m1.9.9.9.8.2.3.cmml"&gt;&lt;mi id="S5.Ex4.m1.9.9.9.8.2.3.2" xref="S5.Ex4.m1.9.9.9.8.2.3.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.9.9.9.8.2.3.1" xref="S5.Ex4.m1.9.9.9.8.2.3.1.cmml"&gt;=&lt;/mo&gt;&lt;mn id="S5.Ex4.m1.9.9.9.8.2.3.3" xref="S5.Ex4.m1.9.9.9.8.2.3.3.cmml"&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi id="S5.Ex4.m1.9.9.9.8.3" xref="S5.Ex4.m1.9.9.9.8.3.cmml"&gt;k&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow id="S5.Ex4.m1.9.9.9.7.1" xref="S5.Ex4.m1.9.9.9.7.2.cmml"&gt;&lt;mo id="S5.Ex4.m1.9.9.9.7.1.2" lspace="0em" maxsize="160%" minsize="160%" xref="S5.Ex4.m1.9.9.9.7.2.1.cmml"&gt;[&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.9.9.9.7.1.1" xref="S5.Ex4.m1.9.9.9.7.1.1.cmml"&gt;&lt;msup id="S5.Ex4.m1.9.9.9.7.1.1.2" xref="S5.Ex4.m1.9.9.9.7.1.1.2.cmml"&gt;&lt;mi id="S5.Ex4.m1.9.9.9.7.1.1.2.2" xref="S5.Ex4.m1.9.9.9.7.1.1.2.2.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.Ex4.m1.4.4.4.2.2" xref="S5.Ex4.m1.4.4.4.2.2.cmml"&gt;&lt;mrow id="S5.Ex4.m1.4.4.4.2.2.2" xref="S5.Ex4.m1.4.4.4.2.2.2.cmml"&gt;&lt;mi id="S5.Ex4.m1.4.4.4.2.2.2.3" xref="S5.Ex4.m1.4.4.4.2.2.2.3.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.4.4.4.2.2.2.2" xref="S5.Ex4.m1.4.4.4.2.2.2.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.4.4.4.2.2.2.1.1" xref="S5.Ex4.m1.4.4.4.2.2.2.1.2.cmml"&gt;&lt;mo id="S5.Ex4.m1.4.4.4.2.2.2.1.1.2" stretchy="false" xref="S5.Ex4.m1.4.4.4.2.2.2.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.3.3.3.1.1.1" xref="S5.Ex4.m1.3.3.3.1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.4.4.4.2.2.2.1.1.3" xref="S5.Ex4.m1.4.4.4.2.2.2.1.2.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.cmml"&gt;&lt;mi id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.2" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.2.cmml"&gt;p&lt;/mi&gt;&lt;mi id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.3" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.3.cmml"&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S5.Ex4.m1.4.4.4.2.2.2.1.1.4" stretchy="false" xref="S5.Ex4.m1.4.4.4.2.2.2.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex4.m1.4.4.4.2.2.3" xref="S5.Ex4.m1.4.4.4.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.4.4.4.2.2.4" xref="S5.Ex4.m1.4.4.4.2.2.4.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo id="S5.Ex4.m1.9.9.9.7.1.1.1" rspace="0.055em" xref="S5.Ex4.m1.9.9.9.7.1.1.1.cmml"&gt;+&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.9.9.9.7.1.1.3" xref="S5.Ex4.m1.9.9.9.7.1.1.3.cmml"&gt;&lt;munderover id="S5.Ex4.m1.9.9.9.7.1.1.3.1" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.cmml"&gt;&lt;mo id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.2" movablelimits="false" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.2.cmml"&gt;∑&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.cmml"&gt;&lt;mi id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.2" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.2.cmml"&gt;j&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.1" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.1.cmml"&gt;=&lt;/mo&gt;&lt;mn id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.3" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.3.cmml"&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mn id="S5.Ex4.m1.9.9.9.7.1.1.3.1.3" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.3.cmml"&gt;15&lt;/mn&gt;&lt;/munderover&gt;&lt;msup id="S5.Ex4.m1.9.9.9.7.1.1.3.2" xref="S5.Ex4.m1.9.9.9.7.1.1.3.2.cmml"&gt;&lt;mi id="S5.Ex4.m1.9.9.9.7.1.1.3.2.2" xref="S5.Ex4.m1.9.9.9.7.1.1.3.2.2.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.Ex4.m1.8.8.8.6.4" xref="S5.Ex4.m1.8.8.8.6.4.cmml"&gt;&lt;mrow id="S5.Ex4.m1.8.8.8.6.4.4" xref="S5.Ex4.m1.8.8.8.6.4.4.cmml"&gt;&lt;mi id="S5.Ex4.m1.8.8.8.6.4.4.3" xref="S5.Ex4.m1.8.8.8.6.4.4.3.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.8.8.8.6.4.4.2" xref="S5.Ex4.m1.8.8.8.6.4.4.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex4.m1.8.8.8.6.4.4.1.1" xref="S5.Ex4.m1.8.8.8.6.4.4.1.2.cmml"&gt;&lt;mo id="S5.Ex4.m1.8.8.8.6.4.4.1.1.2" stretchy="false" xref="S5.Ex4.m1.8.8.8.6.4.4.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.7.7.7.5.3.3" xref="S5.Ex4.m1.7.7.7.5.3.3.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.8.8.8.6.4.4.1.1.3" xref="S5.Ex4.m1.8.8.8.6.4.4.1.2.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.Ex4.m1.8.8.8.6.4.4.1.1.1" xref="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.cmml"&gt;&lt;mi id="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.2" xref="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.2.cmml"&gt;n&lt;/mi&gt;&lt;mrow id="S5.Ex4.m1.6.6.6.4.2.2.2.4" xref="S5.Ex4.m1.6.6.6.4.2.2.2.3.cmml"&gt;&lt;mi id="S5.Ex4.m1.5.5.5.3.1.1.1.1" xref="S5.Ex4.m1.5.5.5.3.1.1.1.1.cmml"&gt;j&lt;/mi&gt;&lt;mo id="S5.Ex4.m1.6.6.6.4.2.2.2.4.1" xref="S5.Ex4.m1.6.6.6.4.2.2.2.3.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.6.6.6.4.2.2.2.2" xref="S5.Ex4.m1.6.6.6.4.2.2.2.2.cmml"&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo id="S5.Ex4.m1.8.8.8.6.4.4.1.1.4" stretchy="false" xref="S5.Ex4.m1.8.8.8.6.4.4.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex4.m1.8.8.8.6.4.5" xref="S5.Ex4.m1.8.8.8.6.4.5.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.Ex4.m1.8.8.8.6.4.6" xref="S5.Ex4.m1.8.8.8.6.4.6.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex4.m1.9.9.9.7.1.3" maxsize="160%" minsize="160%" xref="S5.Ex4.m1.9.9.9.7.2.1.cmml"&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex4.m1.10.10.1.1.3" maxsize="260%" minsize="260%" xref="S5.Ex4.m1.10.10.1.2.1.cmml"&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.Ex4.m1.10b"&gt;&lt;apply id="S5.Ex4.m1.10.10.cmml" xref="S5.Ex4.m1.10.10"&gt;&lt;times id="S5.Ex4.m1.10.10.2.cmml" xref="S5.Ex4.m1.10.10.2"&gt;&lt;/times&gt;&lt;apply id="S5.Ex4.m1.10.10.3.cmml" xref="S5.Ex4.m1.10.10.3"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.10.10.3.1.cmml" xref="S5.Ex4.m1.10.10.3"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.10.10.3.2.cmml" xref="S5.Ex4.m1.10.10.3.2"&gt;𝔼&lt;/ci&gt;&lt;apply id="S5.Ex4.m1.10.10.3.3.cmml" xref="S5.Ex4.m1.10.10.3.3"&gt;&lt;csymbol cd="latexml" id="S5.Ex4.m1.10.10.3.3.1.cmml" xref="S5.Ex4.m1.10.10.3.3.1"&gt;similar-to&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.10.10.3.3.2.cmml" xref="S5.Ex4.m1.10.10.3.3.2"&gt;𝑟&lt;/ci&gt;&lt;ci id="S5.Ex4.m1.10.10.3.3.3.cmml" xref="S5.Ex4.m1.10.10.3.3.3"&gt;𝐵&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.Ex4.m1.10.10.1.2.cmml" xref="S5.Ex4.m1.10.10.1.1"&gt;&lt;csymbol cd="latexml" id="S5.Ex4.m1.10.10.1.2.1.cmml" xref="S5.Ex4.m1.10.10.1.1.2"&gt;delimited-[]&lt;/csymbol&gt;&lt;apply id="S5.Ex4.m1.10.10.1.1.1.cmml" xref="S5.Ex4.m1.10.10.1.1.1"&gt;&lt;minus id="S5.Ex4.m1.10.10.1.1.1.1.cmml" xref="S5.Ex4.m1.10.10.1.1.1"&gt;&lt;/minus&gt;&lt;apply id="S5.Ex4.m1.10.10.1.1.1.2.cmml" xref="S5.Ex4.m1.10.10.1.1.1.2"&gt;&lt;ln id="S5.Ex4.m1.10.10.1.1.1.2.1.cmml" xref="S5.Ex4.m1.10.10.1.1.1.2.1"&gt;&lt;/ln&gt;&lt;apply id="S5.Ex4.m1.9.9.cmml" xref="S5.Ex4.m1.9.9"&gt;&lt;divide id="S5.Ex4.m1.9.9.10.cmml" xref="S5.Ex4.m1.9.9"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex4.m1.2.2.2.cmml" xref="S5.Ex4.m1.2.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.2.2.2.3.cmml" xref="S5.Ex4.m1.2.2.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.2.2.2.4.cmml" xref="S5.Ex4.m1.2.2.2.4"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.Ex4.m1.2.2.2.2.2.cmml" xref="S5.Ex4.m1.2.2.2.2.2"&gt;&lt;divide id="S5.Ex4.m1.2.2.2.2.2.3.cmml" xref="S5.Ex4.m1.2.2.2.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex4.m1.2.2.2.2.2.4.cmml" xref="S5.Ex4.m1.2.2.2.2.2.4"&gt;&lt;times id="S5.Ex4.m1.2.2.2.2.2.4.1.cmml" xref="S5.Ex4.m1.2.2.2.2.2.4.1"&gt;&lt;/times&gt;&lt;ci id="S5.Ex4.m1.2.2.2.2.2.4.2.cmml" xref="S5.Ex4.m1.2.2.2.2.2.4.2"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.Ex4.m1.2.2.2.2.2.4.3.1.cmml" xref="S5.Ex4.m1.2.2.2.2.2.4.3.2"&gt;&lt;ci id="S5.Ex4.m1.1.1.1.1.1.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.Ex4.m1.2.2.2.2.2.2.cmml" xref="S5.Ex4.m1.2.2.2.2.2.2"&gt;𝑝&lt;/ci&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.Ex4.m1.2.2.2.2.2.5.cmml" xref="S5.Ex4.m1.2.2.2.2.2.5"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.Ex4.m1.9.9.9.cmml" xref="S5.Ex4.m1.9.9.9"&gt;&lt;apply id="S5.Ex4.m1.9.9.9.8.cmml" xref="S5.Ex4.m1.9.9.9.8"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.9.9.9.8.1.cmml" xref="S5.Ex4.m1.9.9.9.8"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.Ex4.m1.9.9.9.8.2.cmml" xref="S5.Ex4.m1.9.9.9.8"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.9.9.9.8.2.1.cmml" xref="S5.Ex4.m1.9.9.9.8"&gt;subscript&lt;/csymbol&gt;&lt;sum id="S5.Ex4.m1.9.9.9.8.2.2.cmml" xref="S5.Ex4.m1.9.9.9.8.2.2"&gt;&lt;/sum&gt;&lt;apply id="S5.Ex4.m1.9.9.9.8.2.3.cmml" xref="S5.Ex4.m1.9.9.9.8.2.3"&gt;&lt;eq id="S5.Ex4.m1.9.9.9.8.2.3.1.cmml" xref="S5.Ex4.m1.9.9.9.8.2.3.1"&gt;&lt;/eq&gt;&lt;ci id="S5.Ex4.m1.9.9.9.8.2.3.2.cmml" xref="S5.Ex4.m1.9.9.9.8.2.3.2"&gt;𝑖&lt;/ci&gt;&lt;cn id="S5.Ex4.m1.9.9.9.8.2.3.3.cmml" type="integer" xref="S5.Ex4.m1.9.9.9.8.2.3.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.Ex4.m1.9.9.9.8.3.cmml" xref="S5.Ex4.m1.9.9.9.8.3"&gt;𝑘&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1"&gt;&lt;csymbol cd="latexml" id="S5.Ex4.m1.9.9.9.7.2.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.2"&gt;delimited-[]&lt;/csymbol&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1"&gt;&lt;plus id="S5.Ex4.m1.9.9.9.7.1.1.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.1"&gt;&lt;/plus&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.9.9.9.7.1.1.2.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.9.9.9.7.1.1.2.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.2.2"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.Ex4.m1.4.4.4.2.2.cmml" xref="S5.Ex4.m1.4.4.4.2.2"&gt;&lt;divide id="S5.Ex4.m1.4.4.4.2.2.3.cmml" xref="S5.Ex4.m1.4.4.4.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex4.m1.4.4.4.2.2.2.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2"&gt;&lt;times id="S5.Ex4.m1.4.4.4.2.2.2.2.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.2"&gt;&lt;/times&gt;&lt;ci id="S5.Ex4.m1.4.4.4.2.2.2.3.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.3"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.Ex4.m1.4.4.4.2.2.2.1.2.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1"&gt;&lt;ci id="S5.Ex4.m1.3.3.3.1.1.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1"&gt;𝑞&lt;/ci&gt;&lt;apply id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.1.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.2.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.2"&gt;𝑝&lt;/ci&gt;&lt;ci id="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.3.cmml" xref="S5.Ex4.m1.4.4.4.2.2.2.1.1.1.3"&gt;𝑖&lt;/ci&gt;&lt;/apply&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.Ex4.m1.4.4.4.2.2.4.cmml" xref="S5.Ex4.m1.4.4.4.2.2.4"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.3.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3"&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.3.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.9.9.9.7.1.1.3.1.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1"&gt;subscript&lt;/csymbol&gt;&lt;sum id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.2"&gt;&lt;/sum&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3"&gt;&lt;eq id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.1"&gt;&lt;/eq&gt;&lt;ci id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.2"&gt;𝑗&lt;/ci&gt;&lt;cn id="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.3.cmml" type="integer" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.2.3.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;cn id="S5.Ex4.m1.9.9.9.7.1.1.3.1.3.cmml" type="integer" xref="S5.Ex4.m1.9.9.9.7.1.1.3.1.3"&gt;15&lt;/cn&gt;&lt;/apply&gt;&lt;apply id="S5.Ex4.m1.9.9.9.7.1.1.3.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.9.9.9.7.1.1.3.2.1.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.9.9.9.7.1.1.3.2.2.cmml" xref="S5.Ex4.m1.9.9.9.7.1.1.3.2.2"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.Ex4.m1.8.8.8.6.4.cmml" xref="S5.Ex4.m1.8.8.8.6.4"&gt;&lt;divide id="S5.Ex4.m1.8.8.8.6.4.5.cmml" xref="S5.Ex4.m1.8.8.8.6.4.5"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex4.m1.8.8.8.6.4.4.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4"&gt;&lt;times id="S5.Ex4.m1.8.8.8.6.4.4.2.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4.2"&gt;&lt;/times&gt;&lt;ci id="S5.Ex4.m1.8.8.8.6.4.4.3.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4.3"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.Ex4.m1.8.8.8.6.4.4.1.2.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4.1.1"&gt;&lt;ci id="S5.Ex4.m1.7.7.7.5.3.3.cmml" xref="S5.Ex4.m1.7.7.7.5.3.3"&gt;𝑞&lt;/ci&gt;&lt;apply id="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.1.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.2.cmml" xref="S5.Ex4.m1.8.8.8.6.4.4.1.1.1.2"&gt;𝑛&lt;/ci&gt;&lt;list id="S5.Ex4.m1.6.6.6.4.2.2.2.3.cmml" xref="S5.Ex4.m1.6.6.6.4.2.2.2.4"&gt;&lt;ci id="S5.Ex4.m1.5.5.5.3.1.1.1.1.cmml" xref="S5.Ex4.m1.5.5.5.3.1.1.1.1"&gt;𝑗&lt;/ci&gt;&lt;ci id="S5.Ex4.m1.6.6.6.4.2.2.2.2.cmml" xref="S5.Ex4.m1.6.6.6.4.2.2.2.2"&gt;𝑖&lt;/ci&gt;&lt;/list&gt;&lt;/apply&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.Ex4.m1.8.8.8.6.4.6.cmml" xref="S5.Ex4.m1.8.8.8.6.4.6"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.Ex4.m1.10c"&gt;\displaystyle\;\;\;\;\;\mathbb{E}_{r\sim B}\Bigg{[}-\ln\frac{e^{s(q,p)/\tau}}{% \sum\limits_{i=1}^{k}\Big{[}e^{s(q,p_{i})/\tau}+\sum\limits_{j=1}^{15}e^{s(q,n% _{j,i})/\tau}\Big{]}}\Bigg{]}&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.Ex4.m1.10d"&gt;blackboard_E start_POSTSUBSCRIPT italic_r ∼ italic_B end_POSTSUBSCRIPT [ - roman_ln divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_q , italic_p ) / italic_τ end_POSTSUPERSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT [ italic_e start_POSTSUPERSCRIPT italic_s ( italic_q , italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_τ end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 15 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_s ( italic_q , italic_n start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT ) / italic_τ end_POSTSUPERSCRIPT ] end_ARG ]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;tbody id="S5.Ex5"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\,+\mathbb{E}_{r\sim B}\Bigg{[}-\ln\frac{e^{s(p,q)/\tau}}{\sum%
\limits_{i=1}^{k}e^{s(p,q_{i})/\tau}}\Bigg{]}" display="inline" id="S5.Ex5.m1.5"&gt;&lt;semantics id="S5.Ex5.m1.5a"&gt;&lt;mrow id="S5.Ex5.m1.5.5" xref="S5.Ex5.m1.5.5.cmml"&gt;&lt;mo id="S5.Ex5.m1.5.5a" xref="S5.Ex5.m1.5.5.cmml"&gt;+&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.5.5.1" xref="S5.Ex5.m1.5.5.1.cmml"&gt;&lt;msub id="S5.Ex5.m1.5.5.1.3" xref="S5.Ex5.m1.5.5.1.3.cmml"&gt;&lt;mi id="S5.Ex5.m1.5.5.1.3.2" xref="S5.Ex5.m1.5.5.1.3.2.cmml"&gt;𝔼&lt;/mi&gt;&lt;mrow id="S5.Ex5.m1.5.5.1.3.3" xref="S5.Ex5.m1.5.5.1.3.3.cmml"&gt;&lt;mi id="S5.Ex5.m1.5.5.1.3.3.2" xref="S5.Ex5.m1.5.5.1.3.3.2.cmml"&gt;r&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.5.5.1.3.3.1" xref="S5.Ex5.m1.5.5.1.3.3.1.cmml"&gt;∼&lt;/mo&gt;&lt;mi id="S5.Ex5.m1.5.5.1.3.3.3" xref="S5.Ex5.m1.5.5.1.3.3.3.cmml"&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo id="S5.Ex5.m1.5.5.1.2" xref="S5.Ex5.m1.5.5.1.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.5.5.1.1.1" xref="S5.Ex5.m1.5.5.1.1.2.cmml"&gt;&lt;mo id="S5.Ex5.m1.5.5.1.1.1.2" maxsize="260%" minsize="260%" xref="S5.Ex5.m1.5.5.1.1.2.1.cmml"&gt;[&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.5.5.1.1.1.1" xref="S5.Ex5.m1.5.5.1.1.1.1.cmml"&gt;&lt;mo id="S5.Ex5.m1.5.5.1.1.1.1a" rspace="0.167em" xref="S5.Ex5.m1.5.5.1.1.1.1.cmml"&gt;−&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.5.5.1.1.1.1.2" xref="S5.Ex5.m1.5.5.1.1.1.1.2.cmml"&gt;&lt;mi id="S5.Ex5.m1.5.5.1.1.1.1.2.1" xref="S5.Ex5.m1.5.5.1.1.1.1.2.1.cmml"&gt;ln&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.5.5.1.1.1.1.2a" lspace="0.167em" xref="S5.Ex5.m1.5.5.1.1.1.1.2.cmml"&gt;⁡&lt;/mo&gt;&lt;mstyle displaystyle="true" id="S5.Ex5.m1.4.4" xref="S5.Ex5.m1.4.4.cmml"&gt;&lt;mfrac id="S5.Ex5.m1.4.4a" xref="S5.Ex5.m1.4.4.cmml"&gt;&lt;msup id="S5.Ex5.m1.2.2.2" xref="S5.Ex5.m1.2.2.2.cmml"&gt;&lt;mi id="S5.Ex5.m1.2.2.2.4" xref="S5.Ex5.m1.2.2.2.4.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.Ex5.m1.2.2.2.2.2" xref="S5.Ex5.m1.2.2.2.2.2.cmml"&gt;&lt;mrow id="S5.Ex5.m1.2.2.2.2.2.4" xref="S5.Ex5.m1.2.2.2.2.2.4.cmml"&gt;&lt;mi id="S5.Ex5.m1.2.2.2.2.2.4.2" xref="S5.Ex5.m1.2.2.2.2.2.4.2.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.2.2.2.2.2.4.1" xref="S5.Ex5.m1.2.2.2.2.2.4.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.2.2.2.2.2.4.3.2" xref="S5.Ex5.m1.2.2.2.2.2.4.3.1.cmml"&gt;&lt;mo id="S5.Ex5.m1.2.2.2.2.2.4.3.2.1" stretchy="false" xref="S5.Ex5.m1.2.2.2.2.2.4.3.1.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex5.m1.1.1.1.1.1.1" xref="S5.Ex5.m1.1.1.1.1.1.1.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.2.2.2.2.2.4.3.2.2" xref="S5.Ex5.m1.2.2.2.2.2.4.3.1.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.Ex5.m1.2.2.2.2.2.2" xref="S5.Ex5.m1.2.2.2.2.2.2.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.2.2.2.2.2.4.3.2.3" stretchy="false" xref="S5.Ex5.m1.2.2.2.2.2.4.3.1.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex5.m1.2.2.2.2.2.3" xref="S5.Ex5.m1.2.2.2.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.Ex5.m1.2.2.2.2.2.5" xref="S5.Ex5.m1.2.2.2.2.2.5.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow id="S5.Ex5.m1.4.4.4" xref="S5.Ex5.m1.4.4.4.cmml"&gt;&lt;munderover id="S5.Ex5.m1.4.4.4.3" xref="S5.Ex5.m1.4.4.4.3.cmml"&gt;&lt;mo id="S5.Ex5.m1.4.4.4.3.2.2" movablelimits="false" xref="S5.Ex5.m1.4.4.4.3.2.2.cmml"&gt;∑&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.4.4.4.3.2.3" xref="S5.Ex5.m1.4.4.4.3.2.3.cmml"&gt;&lt;mi id="S5.Ex5.m1.4.4.4.3.2.3.2" xref="S5.Ex5.m1.4.4.4.3.2.3.2.cmml"&gt;i&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.4.4.4.3.2.3.1" xref="S5.Ex5.m1.4.4.4.3.2.3.1.cmml"&gt;=&lt;/mo&gt;&lt;mn id="S5.Ex5.m1.4.4.4.3.2.3.3" xref="S5.Ex5.m1.4.4.4.3.2.3.3.cmml"&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi id="S5.Ex5.m1.4.4.4.3.3" xref="S5.Ex5.m1.4.4.4.3.3.cmml"&gt;k&lt;/mi&gt;&lt;/munderover&gt;&lt;msup id="S5.Ex5.m1.4.4.4.4" xref="S5.Ex5.m1.4.4.4.4.cmml"&gt;&lt;mi id="S5.Ex5.m1.4.4.4.4.2" xref="S5.Ex5.m1.4.4.4.4.2.cmml"&gt;e&lt;/mi&gt;&lt;mrow id="S5.Ex5.m1.4.4.4.2.2" xref="S5.Ex5.m1.4.4.4.2.2.cmml"&gt;&lt;mrow id="S5.Ex5.m1.4.4.4.2.2.2" xref="S5.Ex5.m1.4.4.4.2.2.2.cmml"&gt;&lt;mi id="S5.Ex5.m1.4.4.4.2.2.2.3" xref="S5.Ex5.m1.4.4.4.2.2.2.3.cmml"&gt;s&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.4.4.4.2.2.2.2" xref="S5.Ex5.m1.4.4.4.2.2.2.2.cmml"&gt;⁢&lt;/mo&gt;&lt;mrow id="S5.Ex5.m1.4.4.4.2.2.2.1.1" xref="S5.Ex5.m1.4.4.4.2.2.2.1.2.cmml"&gt;&lt;mo id="S5.Ex5.m1.4.4.4.2.2.2.1.1.2" stretchy="false" xref="S5.Ex5.m1.4.4.4.2.2.2.1.2.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.Ex5.m1.3.3.3.1.1.1" xref="S5.Ex5.m1.3.3.3.1.1.1.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.Ex5.m1.4.4.4.2.2.2.1.1.3" xref="S5.Ex5.m1.4.4.4.2.2.2.1.2.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.cmml"&gt;&lt;mi id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.2" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.2.cmml"&gt;q&lt;/mi&gt;&lt;mi id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.3" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.3.cmml"&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo id="S5.Ex5.m1.4.4.4.2.2.2.1.1.4" stretchy="false" xref="S5.Ex5.m1.4.4.4.2.2.2.1.2.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex5.m1.4.4.4.2.2.3" xref="S5.Ex5.m1.4.4.4.2.2.3.cmml"&gt;/&lt;/mo&gt;&lt;mi id="S5.Ex5.m1.4.4.4.2.2.4" xref="S5.Ex5.m1.4.4.4.2.2.4.cmml"&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.Ex5.m1.5.5.1.1.1.3" maxsize="260%" minsize="260%" xref="S5.Ex5.m1.5.5.1.1.2.1.cmml"&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.Ex5.m1.5b"&gt;&lt;apply id="S5.Ex5.m1.5.5.cmml" xref="S5.Ex5.m1.5.5"&gt;&lt;plus id="S5.Ex5.m1.5.5.2.cmml" xref="S5.Ex5.m1.5.5"&gt;&lt;/plus&gt;&lt;apply id="S5.Ex5.m1.5.5.1.cmml" xref="S5.Ex5.m1.5.5.1"&gt;&lt;times id="S5.Ex5.m1.5.5.1.2.cmml" xref="S5.Ex5.m1.5.5.1.2"&gt;&lt;/times&gt;&lt;apply id="S5.Ex5.m1.5.5.1.3.cmml" xref="S5.Ex5.m1.5.5.1.3"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex5.m1.5.5.1.3.1.cmml" xref="S5.Ex5.m1.5.5.1.3"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.Ex5.m1.5.5.1.3.2.cmml" xref="S5.Ex5.m1.5.5.1.3.2"&gt;𝔼&lt;/ci&gt;&lt;apply id="S5.Ex5.m1.5.5.1.3.3.cmml" xref="S5.Ex5.m1.5.5.1.3.3"&gt;&lt;csymbol cd="latexml" id="S5.Ex5.m1.5.5.1.3.3.1.cmml" xref="S5.Ex5.m1.5.5.1.3.3.1"&gt;similar-to&lt;/csymbol&gt;&lt;ci id="S5.Ex5.m1.5.5.1.3.3.2.cmml" xref="S5.Ex5.m1.5.5.1.3.3.2"&gt;𝑟&lt;/ci&gt;&lt;ci id="S5.Ex5.m1.5.5.1.3.3.3.cmml" xref="S5.Ex5.m1.5.5.1.3.3.3"&gt;𝐵&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.Ex5.m1.5.5.1.1.2.cmml" xref="S5.Ex5.m1.5.5.1.1.1"&gt;&lt;csymbol cd="latexml" id="S5.Ex5.m1.5.5.1.1.2.1.cmml" xref="S5.Ex5.m1.5.5.1.1.1.2"&gt;delimited-[]&lt;/csymbol&gt;&lt;apply id="S5.Ex5.m1.5.5.1.1.1.1.cmml" xref="S5.Ex5.m1.5.5.1.1.1.1"&gt;&lt;minus id="S5.Ex5.m1.5.5.1.1.1.1.1.cmml" xref="S5.Ex5.m1.5.5.1.1.1.1"&gt;&lt;/minus&gt;&lt;apply id="S5.Ex5.m1.5.5.1.1.1.1.2.cmml" xref="S5.Ex5.m1.5.5.1.1.1.1.2"&gt;&lt;ln id="S5.Ex5.m1.5.5.1.1.1.1.2.1.cmml" xref="S5.Ex5.m1.5.5.1.1.1.1.2.1"&gt;&lt;/ln&gt;&lt;apply id="S5.Ex5.m1.4.4.cmml" xref="S5.Ex5.m1.4.4"&gt;&lt;divide id="S5.Ex5.m1.4.4.5.cmml" xref="S5.Ex5.m1.4.4"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex5.m1.2.2.2.cmml" xref="S5.Ex5.m1.2.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex5.m1.2.2.2.3.cmml" xref="S5.Ex5.m1.2.2.2"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex5.m1.2.2.2.4.cmml" xref="S5.Ex5.m1.2.2.2.4"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.Ex5.m1.2.2.2.2.2.cmml" xref="S5.Ex5.m1.2.2.2.2.2"&gt;&lt;divide id="S5.Ex5.m1.2.2.2.2.2.3.cmml" xref="S5.Ex5.m1.2.2.2.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex5.m1.2.2.2.2.2.4.cmml" xref="S5.Ex5.m1.2.2.2.2.2.4"&gt;&lt;times id="S5.Ex5.m1.2.2.2.2.2.4.1.cmml" xref="S5.Ex5.m1.2.2.2.2.2.4.1"&gt;&lt;/times&gt;&lt;ci id="S5.Ex5.m1.2.2.2.2.2.4.2.cmml" xref="S5.Ex5.m1.2.2.2.2.2.4.2"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.Ex5.m1.2.2.2.2.2.4.3.1.cmml" xref="S5.Ex5.m1.2.2.2.2.2.4.3.2"&gt;&lt;ci id="S5.Ex5.m1.1.1.1.1.1.1.cmml" xref="S5.Ex5.m1.1.1.1.1.1.1"&gt;𝑝&lt;/ci&gt;&lt;ci id="S5.Ex5.m1.2.2.2.2.2.2.cmml" xref="S5.Ex5.m1.2.2.2.2.2.2"&gt;𝑞&lt;/ci&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.Ex5.m1.2.2.2.2.2.5.cmml" xref="S5.Ex5.m1.2.2.2.2.2.5"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;apply id="S5.Ex5.m1.4.4.4.cmml" xref="S5.Ex5.m1.4.4.4"&gt;&lt;apply id="S5.Ex5.m1.4.4.4.3.cmml" xref="S5.Ex5.m1.4.4.4.3"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex5.m1.4.4.4.3.1.cmml" xref="S5.Ex5.m1.4.4.4.3"&gt;superscript&lt;/csymbol&gt;&lt;apply id="S5.Ex5.m1.4.4.4.3.2.cmml" xref="S5.Ex5.m1.4.4.4.3"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex5.m1.4.4.4.3.2.1.cmml" xref="S5.Ex5.m1.4.4.4.3"&gt;subscript&lt;/csymbol&gt;&lt;sum id="S5.Ex5.m1.4.4.4.3.2.2.cmml" xref="S5.Ex5.m1.4.4.4.3.2.2"&gt;&lt;/sum&gt;&lt;apply id="S5.Ex5.m1.4.4.4.3.2.3.cmml" xref="S5.Ex5.m1.4.4.4.3.2.3"&gt;&lt;eq id="S5.Ex5.m1.4.4.4.3.2.3.1.cmml" xref="S5.Ex5.m1.4.4.4.3.2.3.1"&gt;&lt;/eq&gt;&lt;ci id="S5.Ex5.m1.4.4.4.3.2.3.2.cmml" xref="S5.Ex5.m1.4.4.4.3.2.3.2"&gt;𝑖&lt;/ci&gt;&lt;cn id="S5.Ex5.m1.4.4.4.3.2.3.3.cmml" type="integer" xref="S5.Ex5.m1.4.4.4.3.2.3.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;ci id="S5.Ex5.m1.4.4.4.3.3.cmml" xref="S5.Ex5.m1.4.4.4.3.3"&gt;𝑘&lt;/ci&gt;&lt;/apply&gt;&lt;apply id="S5.Ex5.m1.4.4.4.4.cmml" xref="S5.Ex5.m1.4.4.4.4"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex5.m1.4.4.4.4.1.cmml" xref="S5.Ex5.m1.4.4.4.4"&gt;superscript&lt;/csymbol&gt;&lt;ci id="S5.Ex5.m1.4.4.4.4.2.cmml" xref="S5.Ex5.m1.4.4.4.4.2"&gt;𝑒&lt;/ci&gt;&lt;apply id="S5.Ex5.m1.4.4.4.2.2.cmml" xref="S5.Ex5.m1.4.4.4.2.2"&gt;&lt;divide id="S5.Ex5.m1.4.4.4.2.2.3.cmml" xref="S5.Ex5.m1.4.4.4.2.2.3"&gt;&lt;/divide&gt;&lt;apply id="S5.Ex5.m1.4.4.4.2.2.2.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2"&gt;&lt;times id="S5.Ex5.m1.4.4.4.2.2.2.2.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.2"&gt;&lt;/times&gt;&lt;ci id="S5.Ex5.m1.4.4.4.2.2.2.3.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.3"&gt;𝑠&lt;/ci&gt;&lt;interval closure="open" id="S5.Ex5.m1.4.4.4.2.2.2.1.2.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1"&gt;&lt;ci id="S5.Ex5.m1.3.3.3.1.1.1.cmml" xref="S5.Ex5.m1.3.3.3.1.1.1"&gt;𝑝&lt;/ci&gt;&lt;apply id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.1.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.2.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.2"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.3.cmml" xref="S5.Ex5.m1.4.4.4.2.2.2.1.1.1.3"&gt;𝑖&lt;/ci&gt;&lt;/apply&gt;&lt;/interval&gt;&lt;/apply&gt;&lt;ci id="S5.Ex5.m1.4.4.4.2.2.4.cmml" xref="S5.Ex5.m1.4.4.4.2.2.4"&gt;𝜏&lt;/ci&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.Ex5.m1.5c"&gt;\displaystyle\,+\mathbb{E}_{r\sim B}\Bigg{[}-\ln\frac{e^{s(p,q)/\tau}}{\sum% \limits_{i=1}^{k}e^{s(p,q_{i})/\tau}}\Bigg{]}&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.Ex5.m1.5d"&gt;+ blackboard_E start_POSTSUBSCRIPT italic_r ∼ italic_B end_POSTSUBSCRIPT [ - roman_ln divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_p , italic_q ) / italic_τ end_POSTSUPERSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_s ( italic_p , italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_τ end_POSTSUPERSCRIPT end_ARG ]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;tbody id="S5.E5"&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;math alttext="\displaystyle\text{with}\;r=(q,p,n_{1},\ldots,n_{15})." display="inline" id="S5.E5.m1.4"&gt;&lt;semantics id="S5.E5.m1.4a"&gt;&lt;mrow id="S5.E5.m1.4.4.1" xref="S5.E5.m1.4.4.1.1.cmml"&gt;&lt;mrow id="S5.E5.m1.4.4.1.1" xref="S5.E5.m1.4.4.1.1.cmml"&gt;&lt;mrow id="S5.E5.m1.4.4.1.1.4" xref="S5.E5.m1.4.4.1.1.4.cmml"&gt;&lt;mtext id="S5.E5.m1.4.4.1.1.4.2" xref="S5.E5.m1.4.4.1.1.4.2a.cmml"&gt;with&lt;/mtext&gt;&lt;mo id="S5.E5.m1.4.4.1.1.4.1" lspace="0.280em" xref="S5.E5.m1.4.4.1.1.4.1.cmml"&gt;⁢&lt;/mo&gt;&lt;mi id="S5.E5.m1.4.4.1.1.4.3" xref="S5.E5.m1.4.4.1.1.4.3.cmml"&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;mo id="S5.E5.m1.4.4.1.1.3" xref="S5.E5.m1.4.4.1.1.3.cmml"&gt;=&lt;/mo&gt;&lt;mrow id="S5.E5.m1.4.4.1.1.2.2" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;&lt;mo id="S5.E5.m1.4.4.1.1.2.2.3" stretchy="false" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;(&lt;/mo&gt;&lt;mi id="S5.E5.m1.1.1" xref="S5.E5.m1.1.1.cmml"&gt;q&lt;/mi&gt;&lt;mo id="S5.E5.m1.4.4.1.1.2.2.4" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.E5.m1.2.2" xref="S5.E5.m1.2.2.cmml"&gt;p&lt;/mi&gt;&lt;mo id="S5.E5.m1.4.4.1.1.2.2.5" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.E5.m1.4.4.1.1.1.1.1" xref="S5.E5.m1.4.4.1.1.1.1.1.cmml"&gt;&lt;mi id="S5.E5.m1.4.4.1.1.1.1.1.2" xref="S5.E5.m1.4.4.1.1.1.1.1.2.cmml"&gt;n&lt;/mi&gt;&lt;mn id="S5.E5.m1.4.4.1.1.1.1.1.3" xref="S5.E5.m1.4.4.1.1.1.1.1.3.cmml"&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo id="S5.E5.m1.4.4.1.1.2.2.6" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;,&lt;/mo&gt;&lt;mi id="S5.E5.m1.3.3" mathvariant="normal" xref="S5.E5.m1.3.3.cmml"&gt;…&lt;/mi&gt;&lt;mo id="S5.E5.m1.4.4.1.1.2.2.7" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;,&lt;/mo&gt;&lt;msub id="S5.E5.m1.4.4.1.1.2.2.2" xref="S5.E5.m1.4.4.1.1.2.2.2.cmml"&gt;&lt;mi id="S5.E5.m1.4.4.1.1.2.2.2.2" xref="S5.E5.m1.4.4.1.1.2.2.2.2.cmml"&gt;n&lt;/mi&gt;&lt;mn id="S5.E5.m1.4.4.1.1.2.2.2.3" xref="S5.E5.m1.4.4.1.1.2.2.2.3.cmml"&gt;15&lt;/mn&gt;&lt;/msub&gt;&lt;mo id="S5.E5.m1.4.4.1.1.2.2.8" stretchy="false" xref="S5.E5.m1.4.4.1.1.2.3.cmml"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo id="S5.E5.m1.4.4.1.2" lspace="0em" xref="S5.E5.m1.4.4.1.1.cmml"&gt;.&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation-xml encoding="MathML-Content" id="S5.E5.m1.4b"&gt;&lt;apply id="S5.E5.m1.4.4.1.1.cmml" xref="S5.E5.m1.4.4.1"&gt;&lt;eq id="S5.E5.m1.4.4.1.1.3.cmml" xref="S5.E5.m1.4.4.1.1.3"&gt;&lt;/eq&gt;&lt;apply id="S5.E5.m1.4.4.1.1.4.cmml" xref="S5.E5.m1.4.4.1.1.4"&gt;&lt;times id="S5.E5.m1.4.4.1.1.4.1.cmml" xref="S5.E5.m1.4.4.1.1.4.1"&gt;&lt;/times&gt;&lt;ci id="S5.E5.m1.4.4.1.1.4.2a.cmml" xref="S5.E5.m1.4.4.1.1.4.2"&gt;&lt;mtext id="S5.E5.m1.4.4.1.1.4.2.cmml" xref="S5.E5.m1.4.4.1.1.4.2"&gt;with&lt;/mtext&gt;&lt;/ci&gt;&lt;ci id="S5.E5.m1.4.4.1.1.4.3.cmml" xref="S5.E5.m1.4.4.1.1.4.3"&gt;𝑟&lt;/ci&gt;&lt;/apply&gt;&lt;vector id="S5.E5.m1.4.4.1.1.2.3.cmml" xref="S5.E5.m1.4.4.1.1.2.2"&gt;&lt;ci id="S5.E5.m1.1.1.cmml" xref="S5.E5.m1.1.1"&gt;𝑞&lt;/ci&gt;&lt;ci id="S5.E5.m1.2.2.cmml" xref="S5.E5.m1.2.2"&gt;𝑝&lt;/ci&gt;&lt;apply id="S5.E5.m1.4.4.1.1.1.1.1.cmml" xref="S5.E5.m1.4.4.1.1.1.1.1"&gt;&lt;csymbol cd="ambiguous" id="S5.E5.m1.4.4.1.1.1.1.1.1.cmml" xref="S5.E5.m1.4.4.1.1.1.1.1"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E5.m1.4.4.1.1.1.1.1.2.cmml" xref="S5.E5.m1.4.4.1.1.1.1.1.2"&gt;𝑛&lt;/ci&gt;&lt;cn id="S5.E5.m1.4.4.1.1.1.1.1.3.cmml" type="integer" xref="S5.E5.m1.4.4.1.1.1.1.1.3"&gt;1&lt;/cn&gt;&lt;/apply&gt;&lt;ci id="S5.E5.m1.3.3.cmml" xref="S5.E5.m1.3.3"&gt;…&lt;/ci&gt;&lt;apply id="S5.E5.m1.4.4.1.1.2.2.2.cmml" xref="S5.E5.m1.4.4.1.1.2.2.2"&gt;&lt;csymbol cd="ambiguous" id="S5.E5.m1.4.4.1.1.2.2.2.1.cmml" xref="S5.E5.m1.4.4.1.1.2.2.2"&gt;subscript&lt;/csymbol&gt;&lt;ci id="S5.E5.m1.4.4.1.1.2.2.2.2.cmml" xref="S5.E5.m1.4.4.1.1.2.2.2.2"&gt;𝑛&lt;/ci&gt;&lt;cn id="S5.E5.m1.4.4.1.1.2.2.2.3.cmml" type="integer" xref="S5.E5.m1.4.4.1.1.2.2.2.3"&gt;15&lt;/cn&gt;&lt;/apply&gt;&lt;/vector&gt;&lt;/apply&gt;&lt;/annotation-xml&gt;&lt;annotation encoding="application/x-tex" id="S5.E5.m1.4c"&gt;\displaystyle\text{with}\;r=(q,p,n_{1},\ldots,n_{15}).&lt;/annotation&gt;&lt;annotation encoding="application/x-llamapun" id="S5.E5.m1.4d"&gt;with italic_r = ( italic_q , italic_p , italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_n start_POSTSUBSCRIPT 15 end_POSTSUBSCRIPT ) .&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td rowspan="1"&gt;&lt;span&gt;(5)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

### 5.3 Memory Optimizations

When training embedding models, having a large batch size is crucial. This is because the InfoNCE loss functions ℒpairssuperscriptℒpairs\\mathcal{L}^{\\mathrm{pairs}}caligraphic\_L start\_POSTSUPERSCRIPT roman\_pairs end\_POSTSUPERSCRIPT and LNCE+subscript𝐿superscriptNCE{L}\_{\\mathrm{NCE}^{+}}italic\_L start\_POSTSUBSCRIPT roman\_NCE start\_POSTSUPERSCRIPT + end\_POSTSUPERSCRIPT end\_POSTSUBSCRIPT compute the loss values based on the entirety of the batch. The batch size determines the number of text values each individual text value is compared against. As a result, the computed loss value might not be as expressive with smaller batches. Li et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib10)) provided an in-depth analysis, highlighting the positive impact of larger batch sizes on the performance of the resultant embedding model. To accommodate larger batch sizes, it becomes essential to minimize the memory overhead during training. We achieved this by training our models in mixed precision Micikevicius et al. ([2018](https://arxiv.org/html/2310.19923v4#bib.bib22)) and leveraging the deepspeed Rasley et al. ([2020](https://arxiv.org/html/2310.19923v4#bib.bib23)) framework for further optimization. Activation checkpointing Chen et al. ([2016](https://arxiv.org/html/2310.19923v4#bib.bib30)) was also employed to curtail memory usage. Specifically, we inserted a checkpoint after each BERT layer within our model.

6 Evaluation
------------

To evaluate the efficacy of our approach, we initiate with a comprehensive analysis of our pre-trained backbone models, as outlined in Section [6.1](https://arxiv.org/html/2310.19923v4#S6.SS1 "6.1 Evaluation of Jina BERT ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"). This is followed by an in-depth assessment of our embedding models in Section [6.2](https://arxiv.org/html/2310.19923v4#S6.SS2 "6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"). Furthermore, we have conducted experiments to delve into the effects of encoding extended sequence lengths on the performance of the embeddings, presented in Section [6.2.2](https://arxiv.org/html/2310.19923v4#S6.SS2.SSS2 "6.2.2 Impact of Maximum Sequence Length ‣ 6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents").

### 6.1 Evaluation of Jina BERT

Table 2: Evaluation of the Jina BERT models on the GLUE benchmark

![Image 3: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/long_doc_acc_chart.png)

Figure 2: Variation of model MLM accuracy w.r.t. the sequence length

Following previous work Liu et al. ([2019b](https://arxiv.org/html/2310.19923v4#bib.bib31)), we evaluate our pretrained models on the GLUE benchmark Wang et al. ([2018](https://arxiv.org/html/2310.19923v4#bib.bib32)). General Language Understanding Evaluation (GLUE) is a collection of nine datasets for evaluating natural language understanding systems. Six tasks are framed as either single-sentence classification or sentence-pair classification tasks. The GLUE organizers provide training, development, and test data splits, as well as a submission server and leaderboard.555[https://gluebenchmark.com](https://gluebenchmark.com/) The test split does not contain labels, and the submission server allows participants to evaluate and compare their systems against the private labels of the test split.

For the Jina BERT training described in Section [4](https://arxiv.org/html/2310.19923v4#S4 "4 Pre-training a Modified BERT ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), we fine-tune the pre-trained models on the corresponding single-task training data using several hyperparameter settings and, for each task, pick the best fine-tuning hyperparameters on the development set.

Following the methodology of Phang et al. ([2018](https://arxiv.org/html/2310.19923v4#bib.bib33)), for RTE, STS, and MRPC, we fine-tune starting from the MNLI single-task model, rather than the baseline pretrained Jina BERT models. As in the BERT paper Devlin et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib13)), our fine-tuning procedure relies on representing the input sequence and using the final hidden vector C∈ℝH𝐶superscriptℝ𝐻C\\in\\mathbb{R}^{H}italic\_C ∈ blackboard\_R start\_POSTSUPERSCRIPT italic\_H end\_POSTSUPERSCRIPT corresponding to the first input token (\[CLS\]) as the aggregate representation.

We train for 10 epochs with batch sizes {16,32}1632\\{16,32\\}{ 16 , 32 } and learning rates {1⁢e−5,2⁢e−5,3⁢e−5}1e52e53e5\\{1\\mathrm{e}{-5},2\\mathrm{e}{-5},3\\mathrm{e}{-5}\\}{ 1 roman\_e - 5 , 2 roman\_e - 5 , 3 roman\_e - 5 }. For each task, the best fine-tuned model on the development set is used for the test set.

In Table [2](https://arxiv.org/html/2310.19923v4#S6.T2 "Table 2 ‣ 6.1 Evaluation of Jina BERT ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), we report the results of the best-performing models on the test sets after submission to the GLUE benchmark server.

Furthermore, we evaluate Jina BERT models on documents of long text sequences by computing the accuracy of the MLM task with varying sequence lengths. The accuracy of masked language modeling is computed on 50,0005000050,00050 , 000 samples from the C4 validation set where, for each chosen sequence length, each sample document is tokenized and truncated to fit the sequence length. We compare Jina BERT to RoBERTa and BERT models in Figure [2](https://arxiv.org/html/2310.19923v4#S6.F2 "Figure 2 ‣ 6.1 Evaluation of Jina BERT ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"). It essentially shows that, even though Jina BERT models were trained on a 512512512512 sequence length, the MLM accuracy does not drop when we extrapolate to an 8192819281928192 sequence length. For other BERT and RoBERTa models, since they use absolute positional embeddings that are trained on a 512512512512 sequence length, it’s not possible to compute the MLM accuracy beyond 512512512512. The figure demonstrates ALiBi’s effectiveness in maintaining MLM performance during inference for long documents.

### 6.2 Evaluation of Jina  Embeddings v2

To comprehensively evaluate our embedding models, we employ the Massive Text Embedding Benchmark (MTEB) Muennighoff et al. ([2023](https://arxiv.org/html/2310.19923v4#bib.bib12)). Our choice of MTEB is motivated by its unparalleled breadth, distinguishing it among embedding benchmarks. Rather than focusing on a single task and dataset, MTEB covers an expansive set of 8 tasks, encompassing a rich collection of 58 datasets across 112 languages. This expansive benchmark allows us to scrutinize our model’s adaptability across diverse applications and languages and benchmark it against other top-performing models.

However, a limitation of the MTEB benchmark is its omission of very long texts, which are essential for evaluating our model’s prowess in handling 8192819281928192 sequence lengths. Consequently, we introduce new retrieval and clustering tasks featuring extended documents, and we detail the performance of our model against its peers in Section [6.2.2](https://arxiv.org/html/2310.19923v4#S6.SS2.SSS2 "6.2.2 Impact of Maximum Sequence Length ‣ 6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents").

Clustering: The goal here is to aptly group a collection of sentences or paragraphs. Within the MTEB benchmark suite, a mini-batch k𝑘kitalic\_k\-means model is employed, operating with a batch size of 32. Here, k𝑘kitalic\_k represents the number of unique labels in the dataset. Model performance is evaluated using the 𝒱𝒱\\mathcal{V}caligraphic\_V measure, a metric insensitive to cluster label permutations, guaranteeing that assessments are independent of label configurations.

We incorporate two new clustering tasks featuring extended documents within the MTEB clustering task subset. The inaugural task, named PatentClustering, draws from the BigPatent666[https://huggingface.co/datasets/big\_patent](https://huggingface.co/datasets/big_patent) dataset Sharma et al. ([2019](https://arxiv.org/html/2310.19923v4#bib.bib34)), challenging the k-means model to organize patents by their respective categories. Patent documents average 6,37663766,3766 , 376 tokens, spanning a range from a brief 569569569569 tokens to an extensive 218,434218434218,434218 , 434 tokens. Our second task, titled WikiCitiesClustering, sources from the English subset of the refined Wikipedia dump Foundation ([2022](https://arxiv.org/html/2310.19923v4#bib.bib35)), available as a dataset on Hugging Face777[https://huggingface.co/datasets/wikipedia](https://huggingface.co/datasets/wikipedia). For this task, we curate a roster of nations from [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page) and extract Wikipedia articles of their cities from the refined dataset. The objective is to group cities by their parent country. On average, articles consist of 2,03120312,0312 , 031 tokens, with the length varying between a succinct 21 tokens to a comprehensive 20,1792017920,17920 , 179 tokens.

Retrieval: This task entails a dataset comprising a corpus, a set of queries, and associated mappings connecting each query to pertinent corpus documents. The mission is to discern relevant documents for a specific query. Both queries and corpus documents undergo encoding, after which their similarity scores are derived using cosine similarity. Subsequently, metrics like nDCG@⁢10@10@10@ 10 (which serves as the primary metric), MRR@⁢k@𝑘@k@ italic\_k, MAP@⁢k@𝑘@k@ italic\_k, precision@⁢k@𝑘@k@ italic\_k, and recall@⁢k@𝑘@k@ italic\_k are computed for diverse k𝑘kitalic\_k values. This task is inspired by datasets and evaluation methods presented by BEIR Thakur et al. ([2021](https://arxiv.org/html/2310.19923v4#bib.bib11)).

To expand the scope of the MTEB, we introduce a new retrieval task named NarrativeQA, derived from the narrativeqa888[https://huggingface.co/datasets/narrativeqa](https://huggingface.co/datasets/narrativeqa) dataset. This dataset boasts realistic QA instances, curated from literature (encompassing both fiction and non-fiction) and film scripts. The corpus averages 74,8437484374,84374 , 843 tokens per document, with the lengthiest document tallying up to 454,746454746454,746454 , 746 tokens, and the most concise one comprising 4,55045504,5504 , 550 tokens.

We further evaluated Jina  Embeddings v2 using a novel benchmark, referred to as LoCo 999[https://hazyresearch.stanford.edu/blog/2024-01-11-m2-bert-retrieval](https://hazyresearch.stanford.edu/blog/2024-01-11-m2-bert-retrieval). The LoCo dataset consists of five retrieval tasks derived from publicly available datasets. The selection process for these tasks was guided by several criteria, notably the length of the documents, with a preference towards longer texts, in addition to a manual review to verify that the tasks require a thorough understanding of the entire document. The results of our models on the LoCo dataset are provided in Table [11](https://arxiv.org/html/2310.19923v4#A1.T11 "Table 11 ‣ Appendix A Appendix: MTEB and LoCo Becnharmk ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents").

#### 6.2.1 Results on MTEB

CF: Classification Accuracy \[%\]   CL: Clustering 𝒱𝒱\\mathcal{V}caligraphic\_V measure\[%\]  PC: Pair Classification Average Precision \[%\]   
RR: Reranking MAP \[%\]  RT: Retrieval nDCG@10  STS: Sentence Similarity Spearman Correlation \[%\]   
SM: Summarization Spearman Correlation \[%\]

Table 3: Evaluation of the Jina  Embeddings v2 models on the MTEB benchmark

![Image 4: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/max_len_narrative_qa.png)

![Image 5: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/max_len_wiki_cities.png)

![Image 6: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/max_len_scifact.png)

![Image 7: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/max_len_patent.png)

![Image 8: Refer to caption](https://arxiv.org/html/2310.19923v4/extracted/5388219/img/jina-embedding-v2-long-doc-eval-legend.png)

Figure 3: Evaluation w.r.t. maximum sequence length. For e5-base-v2, we abstained from employing specific prefixes like query: , which might result in varied evaluation outcomes. Note, text-embedding-ada-002 caps its context length at 8191819181918191 tokens, not 8192819281928192.

The evaluation of embedding models within the MTEB benchmark, as illustrated in Table [3](https://arxiv.org/html/2310.19923v4#S6.T3 "Table 3 ‣ 6.2.1 Results on MTEB ‣ 6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), reveals significant contrasts between Jina’s text embedding models, namely [jina-small-v2](https://huggingface.co/jinaai/jina-embedding-s-en-v2) and [jina-base-v2](https://huggingface.co/jinaai/jina-embedding-b-en-v2), and other contemporary models. These differences are especially pronounced in tasks showing marked performance disparities, such as Classification (CF) and Retrieval (RT).

In Classification (CF), the [jina-base-v2](https://huggingface.co/jinaai/jina-embedding-b-en-v2) model, equipped with 137 million parameters, emerges as a leading performer. It records superior scores, outpacing most competing models, underscoring its efficacy in text classification. Conversely, the [jina-small-v2](https://huggingface.co/jinaai/jina-embedding-s-en-v2) model, equipped with a modest 33 million parameters, trails behind some other models in this task. This underscores the pivotal role model size plays in certain downstream tasks, with more extensive architectures yielding potential benefits.

For the Retrieval (RT) task, [jina-small-v2](https://huggingface.co/jinaai/jina-embedding-s-en-v2) showcases formidable performance, signaling its adeptness for information retrieval. It ranks amidst top-tier models, indicating its prowess in retrieval-centric tasks. Similarly, [jina-base-v2](https://huggingface.co/jinaai/jina-embedding-b-en-v2) excels, registering a slightly superior score, reaffirming its formidable retrieval aptitude. Both models underscore their credibility in tasks necessitating adept information retrieval. Given that models all-MiniLM-L6-v2 and all-mpnet-base-v2 omit the second-stage finetuning which [jina-small-v2](https://huggingface.co/jinaai/jina-embedding-s-en-v2) and [jina-base-v2](https://huggingface.co/jinaai/jina-embedding-b-en-v2) undergo, it’s foreseeable that our models would excel in these tasks.

In conclusion, both the base and small text embedding models display commendable performance within the MTEB benchmark. Their standout performance, relative to other models in tasks like Classification and Retrieval, suggests model size’s influential role in specific text processing endeavors. Both models reaffirm their potency in retrieval, marking them as pivotal tools for a plethora of natural language processing tasks.

#### 6.2.2 Impact of Maximum Sequence Length

As delineated in Section [6.1](https://arxiv.org/html/2310.19923v4#S6.SS1 "6.1 Evaluation of Jina BERT ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), the pre-training generalizes across extended sequence lengths. Consequently, the MLM accuracy for long sequences, spanning up to 8192819281928192 tokens, mirrors that of shorter sequences, despite the exclusive training on abbreviated text sequences. During finetuning, our models train solely on texts not exceeding 512512512512 tokens, yet they cater to texts reaching 8192819281928192 tokens for the MTEB evaluation detailed in Section [6.2](https://arxiv.org/html/2310.19923v4#S6.SS2 "6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents").

To discern how sequence length impacts the accuracy of downstream tasks, we executed long document clustering and retrieval tasks, modulating the tokenizer’s maximum sequence length. This allows us to gauge the models’ performance on variable sequence lengths through truncation. Since a majority of the extant tasks in the MTEB feature documents under 512512512512 tokens, we resort to our three novel datasets elucidated in Section [6.2](https://arxiv.org/html/2310.19923v4#S6.SS2 "6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"), accessible on Hugging Face. Furthermore, we employ the SciFact dataset Wadden et al. ([2020](https://arxiv.org/html/2310.19923v4#bib.bib36)), given its substantial count of texts exceeding 512512512512 tokens.

Figure [3](https://arxiv.org/html/2310.19923v4#S6.F3 "Figure 3 ‣ 6.2.1 Results on MTEB ‣ 6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") depicts the nDCG@⁢10@10@10@ 10 retrieval and the 𝒱𝒱\\mathcal{V}caligraphic\_V measure scores for the [jina-base-v2](https://huggingface.co/jinaai/jina-embedding-b-en-v2) alongside four other renowned embedding models. Given that only [jina-base-v2](https://huggingface.co/jinaai/jina-embedding-b-en-v2) and OpenAI’s text-embedding-ada-002 support an 8K sequence length, results reported for an 8191 sequence length for other models are truncated to their intrinsic maximum, typically 512512512512. Generally, Figure [3](https://arxiv.org/html/2310.19923v4#S6.F3 "Figure 3 ‣ 6.2.1 Results on MTEB ‣ 6.2 Evaluation of Jina Embeddings v2 ‣ 6 Evaluation ‣ Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents") suggests that elongated sequence lengths contribute to enhanced outcomes. This assertion is particularly true for the NarrativeQA task, where extending the sequence length substantially bolsters performance. Due to the inherent nature of the dataset, models limited to the text’s commencement frequently underperform.

On the BigPatent clustering task, larger sequence lengths also result in better performance. However, on the WikiCities clustering task, longer sequence lengths seem to slightly diminish the models’ performance in most instances. This suggests that an increase in sequence length doesn’t always yield better outcomes. One explanation for this observation is that the initial paragraph of a Wikipedia article about a city typically mentions the country the city is in. Information towards the middle and end of the articles is often less pertinent for identifying the country and might alter the attributes that influence the clustering of the city embeddings.

7 Conclusion
------------

We have introduced Jina  Embeddings v2, a novel embedding model based on a modified BERT architecture. This model eschews positional embeddings and instead employs bi-directional ALiBi slopes to capture positional information. By training a series of embedding models with this innovative architecture on the Web document corpus C4 and subsequently fine-tuning them, we have enabled the encoding of the semantics of both short and long textual values into meaningful vector representations. This effort has produced a new suite of open-source embedding models capable of encoding texts containing up to 8192819281928192 tokens. These embeddings signify a 16x increase in the maximum sequence length compared to leading open-source embedding models. Additionally, our model suite exhibits competitive performance on the MTEB benchmark. We also demonstrate how utilizing extended sequence lengths can offer our models an advantage over those without such capabilities.

References
----------

*   Reimers and Gurevych \[2019\] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pages 3982–3992, 2019.
*   Press et al. \[2022\] Ofir Press, Noah A. Smith, and Mike Lewis. Train short, test long: Attention with linear biases enables input length extrapolation, 2022.
*   Günther et al. \[2023\] Michael Günther, Louis Milliken, Jonathan Geuter, Georgios Mastrapas, Bo Wang, and Han Xiao. Jina embeddings: A novel set of high-performance sentence embedding models. _arXiv preprint arXiv:2307.11224_, 2023.
*   Wang et al. \[2022\] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. Text embeddings by weakly-supervised contrastive pre-training. _arXiv preprint arXiv:2212.03533_, 2022.
*   Deerwester et al. \[1990\] Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard Harshman. Indexing by latent semantic analysis. _Journal of the American Society for Information Science_, 41(6):391–407, 1990.
*   Blei et al. \[2001\] David Blei, Andrew Ng, and Michael Jordan. Latent dirichlet allocation. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, _Advances in Neural Information Processing Systems_, volume 14. MIT Press, 2001. URL [https://proceedings.neurips.cc/paper\_files/paper/2001/file/296472c9542ad4d4788d543508116cbc-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2001/file/296472c9542ad4d4788d543508116cbc-Paper.pdf).
*   Gao et al. \[2022\] Tianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning of sentence embeddings, 2022.
*   Gao and Callan \[2021\] Luyu Gao and Jamie Callan. Condenser: a pre-training architecture for dense retrieval, 2021.
*   Xiao et al. \[2022\] Shitao Xiao, Zheng Liu, Yingxia Shao, and Zhao Cao. Retromae: Pre-training retrieval-oriented language models via masked auto-encoder, 2022.
*   Li et al. \[2023\] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan Zhang. Towards general text embeddings with multi-stage contrastive learning, 2023.
*   Thakur et al. \[2021\] Nandan Thakur, Nils Reimers, Andreas Rücklé, Abhishek Srivastava, and Iryna Gurevych. Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models, 2021.
*   Muennighoff et al. \[2023\] Niklas Muennighoff, Nouamane Tazi, Loïc Magne, and Nils Reimers. Mteb: Massive text embedding benchmark, 2023.
*   Devlin et al. \[2019\] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding, 2019.
*   Liu et al. \[2019a\] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019a.
*   Dauphin et al. \[2016\] Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated convolutional networks. _CoRR_, abs/1612.08083, 2016. URL [http://arxiv.org/abs/1612.08083](http://arxiv.org/abs/1612.08083).
*   Shazeer \[2020\] Noam Shazeer. GLU variants improve transformer. _CoRR_, abs/2002.05202, 2020. URL [https://arxiv.org/abs/2002.05202](https://arxiv.org/abs/2002.05202).
*   Vaswani et al. \[2017\] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _CoRR_, abs/1706.03762, 2017. URL [http://arxiv.org/abs/1706.03762](http://arxiv.org/abs/1706.03762).
*   Shoeybi et al. \[2019\] Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-lm: Training multi-billion parameter language models using model parallelism. _CoRR_, abs/1909.08053, 2019. URL [http://arxiv.org/abs/1909.08053](http://arxiv.org/abs/1909.08053).
*   Nguyen and Salazar \[2019\] Toan Q. Nguyen and Julian Salazar. Transformers without tears: Improving the normalization of self-attention. _CoRR_, abs/1910.05895, 2019. URL [http://arxiv.org/abs/1910.05895](http://arxiv.org/abs/1910.05895).
*   Raffel et al. \[2020\] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. _The Journal of Machine Learning Research_, 21(1):5485–5551, 2020.
*   Loshchilov and Hutter \[2017\] Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. _CoRR_, abs/1711.05101, 2017. URL [http://arxiv.org/abs/1711.05101](http://arxiv.org/abs/1711.05101).
*   Micikevicius et al. \[2018\] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, et al. Mixed precision training. In _International Conference on Learning Representations_, 2018.
*   Rasley et al. \[2020\] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In _Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining_, pages 3505–3506, 2020.
*   Dai et al. \[2023\] Zhuyun Dai, Vincent Y Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith Hall, and Ming-Wei Chang. Promptagator: Few-shot dense retrieval from 8 examples. In _The Eleventh International Conference on Learning Representations_, 2023. URL [https://openreview.net/forum?id=gmL46YMpu2J](https://openreview.net/forum?id=gmL46YMpu2J).
*   van den Oord et al. \[2018\] Aäron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. _CoRR_, abs/1807.03748, 2018. URL [http://arxiv.org/abs/1807.03748](http://arxiv.org/abs/1807.03748).
*   Wang and Liu \[2021\] Feng Wang and Huaping Liu. Understanding the behaviour of contrastive loss. In _2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 2495–2504. IEEE, 2021.
*   Bajaj et al. \[2016\] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated machine reading comprehension dataset. _arXiv preprint arXiv:1611.09268_, 2016.
*   Kwiatkowski et al. \[2019\] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: a benchmark for question answering research. _Transactions of the Association of Computational Linguistics_, 2019.
*   Bowman et al. \[2015\] Samuel Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. In _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing_, pages 632–642, 2015.
*   Chen et al. \[2016\] Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear memory cost. _arXiv preprint arXiv:1604.06174_, 2016.
*   Liu et al. \[2019b\] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. _CoRR_, abs/1907.11692, 2019b. URL [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692).
*   Wang et al. \[2018\] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. _CoRR_, abs/1804.07461, 2018. URL [http://arxiv.org/abs/1804.07461](http://arxiv.org/abs/1804.07461).
*   Phang et al. \[2018\] Jason Phang, Thibault Févry, and Samuel R. Bowman. Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks. _CoRR_, abs/1811.01088, 2018. URL [http://arxiv.org/abs/1811.01088](http://arxiv.org/abs/1811.01088).
*   Sharma et al. \[2019\] Eva Sharma, Chen Li, and Lu Wang. BIGPATENT: A large-scale dataset for abstractive and coherent summarization. _CoRR_, abs/1906.03741, 2019. URL [http://arxiv.org/abs/1906.03741](http://arxiv.org/abs/1906.03741).
*   Foundation \[2022\] Wikimedia Foundation. Wikimedia downloads, 2022. URL [https://dumps.wikimedia.org](https://dumps.wikimedia.org/).
*   Wadden et al. \[2020\] David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. Fact or fiction: Verifying scientific claims. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pages 7534–7550, 2020.

Appendix A Appendix: MTEB and LoCo Becnharmk
--------------------------------------------

Table 4: Detailed Performance on the MTEB Classification Tasks

Table 5: Detailed Performance on the MTEB Clustering Tasks

Table 6: Detailed Performance on the MTEB Summarization Tasks

Table 7: Detailed Performance on the MTEB Pair Classification Tasks

Table 8: Detailed Performance on the MTEB ReRanking Tasks

Table 9: Detailed Performance on the MTEB Retrieval Tasks

Table 10: Detailed Performance on the MTEB STS Tasks

Table 11: Performance on the new LoCo Dataset

</code></pre>

</div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert"><label class="q-field row no-wrap items-start q-field--standard q-input q-field--float q-field--labeled q-field--dark q-field--with-bottom" for="f_6010559d-36f2-44ea-b92c-a569a41a3203"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Pose a Question" id="f_6010559d-36f2-44ea-b92c-a569a41a3203" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Pose a Question</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--standard q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">send</i></span></button></div></div><div class="q-field__bottom row items-start q-field__bottom--animated"><div class="q-field__messages col"><div>Input a question and combine it with the fetched content for LLM to generate an answer</div></div></div></div></label></div></div></div></div><div data-v-75350d50="" class="q-pa-xl" id="apiform"><div data-v-75350d50="" class="row q-mt-xl q-py-xl justify-center"><div data-v-75350d50="" class="q-mb-lg q-pb-md"><h2 data-v-75350d50="" class="text-h2 text-white q-mb-lg text-center justify-center">Reader API</h2></div></div><div data-v-75350d50="" class="q-my-xl text-center text-grey-5 text-h6 text-weight-light">Get LLM-friendly input from a URL or a web search. Improve the factuality of your agent, RAG, GenAI system with a simple prefix.</div><div data-v-75350d50="" class="row justify-center"><div data-v-75350d50="" class="col-12 col-md-9 q-pb-xl"><div class="q-card q-card--dark q-dark q-card--bordered q-card--square no-border-radius q-card--flat no-shadow full-width" style="flex-wrap: nowrap;"><div class="q-toolbar row no-wrap items-center q-pa-none bg-dark-page" role="toolbar" style="flex-shrink: 0;"><div class="q-tabs row no-wrap items-center q-tabs--not-scrollable q-tabs--horizontal q-tabs__arrows--inside q-tabs--mobile-without-arrows col-shrink" role="tablist"><div class="q-tabs__content scroll--mobile row no-wrap items-center self-stretch hide-scrollbar relative-position q-tabs__content--align-justify"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">zoom_out_map</i></span></button><div class="q-tab relative-position self-stretch flex flex-center text-center q-tab--inactive q-focusable q-hoverable cursor-pointer" tabindex="-1" role="tab" aria-selected="false"><div class="q-focus-helper" tabindex="-1"></div><div class="q-tab__content self-stretch flex-center relative-position q-anchor--skip non-selectable row no-wrap q-tab__content--inline"><i class="q-icon notranslate material-icons q-tab__icon" aria-hidden="true" role="presentation">shopping_cart</i><div class="q-tab__label">Buy tokens</div></div><div class="q-tab__indicator absolute-bottom text-primary"></div></div><div class="q-tab relative-position self-stretch flex flex-center text-center q-tab--active text-primary q-focusable q-hoverable cursor-pointer" tabindex="0" role="tab" aria-selected="true"><div class="q-focus-helper" tabindex="-1"></div><div class="q-tab__content self-stretch flex-center relative-position q-anchor--skip non-selectable row no-wrap q-tab__content--inline"><i class="q-icon notranslate material-icons q-tab__icon" aria-hidden="true" role="presentation">code</i><div class="q-tab__label">Usage</div></div><div class="q-tab__indicator absolute-bottom text-primary"></div></div></div><i class="q-icon fas fa-chevron-left q-tabs__arrow q-tabs__arrow--left absolute q-tab__icon" aria-hidden="true" role="presentation"> </i><i class="q-icon fas fa-chevron-right q-tabs__arrow q-tabs__arrow--right absolute q-tab__icon q-tabs__arrow--faded" aria-hidden="true" role="presentation"> </i></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-tab-panels q-panel-parent q-tab-panels--dark q-dark" style="flex-grow: 1;"><div class="q-panel scroll" role="tabpanel" style="--q-transition-duration:300ms;"><div class="q-tab-panel q-pa-none" role="tabpanel"><div class="row q-pa-none"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark q-mr-md" tabindex="0" role="switch" aria-label="Show basic and advanced usages" aria-checked="mixed"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--indet" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span><div class="q-toggle__label q-anchor--skip">Show basic and advanced usages</div></div><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--no-uppercase no-border-radius self-stretch" tabindex="0" href="https://github.com/jina-ai/reader" target="_blank" style="padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left fab fa-github" aria-hidden="true" role="img"> </i><span class="block">Source code</span></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" href="/reader#faq" style="padding: 16px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row no-wrap text-no-wrap"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">help_outline</i><span class="block">faq</span></span></a></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert"><div class="q-list q-list--dark q-list--padding q-gutter-y-sm"><div class="q-item__label q-item__label--header">Basic Usage</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">double_arrow</i></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label q-item__label--caption text-caption">Read a URL</div><div class="q-item__label"><span>Add <code>https://r.jina.ai/</code> to any URL in your code or tool where LLM access is expected. This will return the main content of the page in clean, LLM-friendly text.</span></div></div></div><div class="q-item q-item-type row no-wrap q-item--dark row items-center q-gutter-x-md wrap-sm" role="listitem"><label class="q-field row no-wrap items-start q-field--filled q-input q-field--square q-field--float q-field--labeled q-field--dark col-md col-sm-12" for="f_3cfe1270-12cc-4d16-a664-20877627355f"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Enter your URL" id="f_3cfe1270-12cc-4d16-a664-20877627355f" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Enter your URL</div></div></div></div></label><i class="q-icon mdi mdi-arrow-down col-auto" aria-hidden="true" role="presentation" style="font-size: 24px;"> </i><label class="q-field row no-wrap items-start q-field--outlined q-input q-field--square q-field--float q-field--labeled q-field--dark col-md col-sm-12" for="f_4ee79328-f853-4e84-8f0d-26b55799a601"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__prefix no-pointer-events row items-center">https://r.jina.ai/</div><input class="q-field__native q-placeholder" tabindex="0" aria-label="Reader URL" id="f_4ee79328-f853-4e84-8f0d-26b55799a601" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Reader URL</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">content_copy</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div></div></div></label></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-avatar"><div class="q-avatar__content row flex-center overflow-hidden"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">search</i></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label q-item__label--caption text-caption">Search a query</div><div class="q-item__label"><span>Add <code>https://s.jina.ai/</code> to your query. This will call the search engine and returns top-5 results with their URLs and contents, each in clean, LLM-friendly text.</span></div></div></div><div class="q-item q-item-type row no-wrap q-item--dark row items-center q-gutter-x-md wrap-sm" role="listitem"><label class="q-field row no-wrap items-start q-field--filled q-input q-field--square q-field--float q-field--labeled q-field--dark col-md col-sm-12" for="f_ac7b3341-e87e-4fc8-8fc9-bbcfbceb5cb9"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder" tabindex="0" aria-label="Enter your query" id="f_ac7b3341-e87e-4fc8-8fc9-bbcfbceb5cb9" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Enter your query</div></div></div></div></label><i class="q-icon mdi mdi-arrow-down col-auto" aria-hidden="true" role="presentation" style="font-size: 24px;"> </i><label class="q-field row no-wrap items-start q-field--outlined q-input q-field--square q-field--float q-field--labeled q-field--dark col-md col-sm-12" for="f_69077f67-0f91-48c5-a488-efd5ddaef7b2"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__prefix no-pointer-events row items-center">https://s.jina.ai/</div><input class="q-field__native q-placeholder" tabindex="0" aria-label="Reader URL" id="f_69077f67-0f91-48c5-a488-efd5ddaef7b2" type="text"><div class="q-field__label no-pointer-events absolute ellipsis">Reader URL</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">content_copy</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--dense q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">open_in_new</i></span></button></div></div></div></label></div><div class="q-item__label q-item__label--header">Advanced Usage</div><div class="q-card q-card--dark q-dark q-card--bordered q-card--square no-border-radius q-card--flat no-shadow"><div class="q-card__section q-card__section--vert q-pa-none"><div class="q-card__section q-card__section--vert col-md-6 col-lg-5 col-xl-4 q-pa-none"><div class="q-list q-list--dark q-list--padding"><div class="q-item__label q-item__label--caption text-caption q-item__label--header">The behavior of the Reader API can be controlled with request headers. Here is a complete list of supported headers.</div><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Read or Search Mode</div><div class="q-item__label q-item__label--caption text-caption">Read mode is for accessing the content of a URL, while Search mode allows you to search a query on the web, applying Read mode to each search result URL.</div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"><i class="q-icon text-null notranslate material-icons" aria-hidden="true" role="presentation">double_arrow</i></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Add API Key for Higher Rate Limit</div><div class="q-item__label q-item__label--caption text-caption">Enter your Jina API key to access a higher rate limit. For latest rate limit information, please refer to the table below.</div><div class="q-item__label q-item__label--caption text-caption q-pt-sm"><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="/reader#rate-limit" target="_blank" style="font-size: 8px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">open_in_new</i><span class="block">Learn more</span></span></a></div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center disabled q-toggle--dark" tabindex="-1" role="switch" aria-checked="false" aria-disabled="true"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Image Caption</div><div class="q-item__label q-item__label--caption text-caption">Captions all images at the specified URL, adding 'Image [idx]: [caption]' as an alt tag for those without one. This allows downstream LLMs to interact with the images in activities such as reasoning and summarizing.</div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JSON Response</div><div class="q-item__label q-item__label--caption text-caption">The response will be in JSON format, containing the URL, title, content, and timestamp (if available). In Search mode, it returns a list of five entries, each following the described JSON structure.</div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Forward Cookie</div><div class="q-item__label q-item__label--caption text-caption">Our API server can forward your custom cookie settings when accessing the URL, which is useful for pages requiring extra authentication. Note that requests with cookies will not be cached.</div><div class="q-item__label q-item__label--caption text-caption q-pt-sm"><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie" target="_blank" style="font-size: 8px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">open_in_new</i><span class="block">Learn more</span></span></a></div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Use a Proxy Server</div><div class="q-item__label q-item__label--caption text-caption">Our API server can utilize your proxy to access URLs, which is helpful for pages accessible only through specific proxies.</div><div class="q-item__label q-item__label--caption text-caption q-pt-sm"><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://en.wikipedia.org/wiki/Proxy_server" target="_blank" style="font-size: 8px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">open_in_new</i><span class="block">Learn more</span></span></a></div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Bypass the Cache</div><div class="q-item__label q-item__label--caption text-caption">Our API server caches both Read and Search mode contents for a certain amount of time. To bypass this cache, set this header to true.</div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Stream Mode</div><div class="q-item__label q-item__label--caption text-caption">Stream mode is beneficial for large target pages, allowing more time for the page to fully render. If standard mode results in incomplete content, consider using Stream mode.</div><div class="q-item__label q-item__label--caption text-caption q-pt-sm"><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://github.com/jina-ai/reader?tab=readme-ov-file#streaming-mode" target="_blank" style="font-size: 8px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">open_in_new</i><span class="block">Learn more</span></span></a></div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Target Selector</div><div class="q-item__label q-item__label--caption text-caption">Provide a CSS selector to focus on a more specific part of the page. Useful when your desired content doesn't show under the default settings.</div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Wait For Selector</div><div class="q-item__label q-item__label--caption text-caption">Wait for a specific element to appear before returning. Useful when your desired content doesn't show under the default settings.</div></div><div class="q-item__section column q-item__section--side justify-center"><div class="q-toggle cursor-pointer no-outline row inline no-wrap items-center q-toggle--dark" tabindex="0" role="switch" aria-checked="false"><div class="q-toggle__inner relative-position non-selectable q-toggle__inner--falsy" aria-hidden="true"><input class="hidden q-toggle__native absolute q-ma-none q-pa-none" type="checkbox"><div class="q-toggle__track"></div><div class="q-toggle__thumb absolute flex flex-center no-wrap"></div></div><span class="no-outline" tabindex="-1"></span></div></div></label><label class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Level of Details</div><div class="q-item__label q-item__label--caption text-caption">You can control the level of detail in the response to prevent over-filtering. The default pipeline is optimized for most websites and LLM input.</div></div><div class="q-item__section column q-item__section--side justify-center"><label class="q-field row no-wrap items-start q-field--filled q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--float q-field--dark" for="f_9c8a0b35-0783-40c2-97a8-3a4aea09fea2"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span>Default</span><input class="q-select__focus-target" id="f_9c8a0b35-0783-40c2-97a8-3a4aea09fea2" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_9c8a0b35-0783-40c2-97a8-3a4aea09fea2_lb"></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon fas fa-caret-down q-select__dropdown-icon" aria-hidden="true" role="presentation"> </i></div></div></div></label></div></label></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert col"><div class="q-chip row inline no-wrap items-center q-chip--square q-chip--dark q-dark text-grey-6 q-mr-sm" style="font-size: 10px; border-radius: 0px;"><i class="q-icon notranslate material-icons q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">upload</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Request</div></div></div><div style="position: relative;"><div class="q-markdown"><pre class="q-markdown--code q-markdown--code__inner language-bash"><code><span class="token function">curl</span> https://r.jina.ai/https://example.com
</code></pre>

</div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--round text-amber q-btn--actionable q-focusable q-hoverable q-btn--dense q-markdown__copy" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><svg viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></i></span></button></div></div></div></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-card__section q-card__section--vert row q-py-none bg-dark-page"><label class="q-field row no-wrap items-start q-field--standard q-input q-field--square q-field--labeled q-field--dark q-field--with-bottom q-field--readonly full-width q-mb-xs" for="f_5ea7c59c-77c3-4a18-803a-be265f801161"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">key</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder ellipsis" tabindex="0" aria-label="API key" id="f_5ea7c59c-77c3-4a18-803a-be265f801161" readonly="" type="text" style="font-family: monospace;"><div class="q-field__label no-pointer-events absolute ellipsis">API key</div></div><div class="q-field__append q-field__marginal row no-wrap items-center"><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text- q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">content_copy</i></span></button><hr class="q-separator q-separator--vertical q-separator--dark" aria-orientation="vertical"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label q-item__label--overline text-overline row items-center text-negative">Available tokens</div><div class="q-item__label text-overline text-negative">0 <button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 8px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">sync</i></span></button></div></div></div></div></div><div class="q-field__bottom row items-start q-field__bottom--animated"><div class="q-field__messages col"><div>Each new key has some free tokens for you to try out. You can top up your key at any time. Make sure to store your API key at a safe place!</div></div></div></div></label></div></div></div></div></div><div data-v-75350d50="" class="row justify-center bg-dark" id="pricing"><div class="col-12 col-md-10 q-mt-xl q-py-xl justify-center"><div class="q-mb-lg q-pb-md"><h2 class="text-h2 text-white q-mb-lg text-center justify-center">API Pricing</h2></div></div><div class="col-10 col-md-6 text-grey-5 text-subtitle1 justify-center q-py-xl">Our API pricing is structured around the quantity of tokens sent in the requests. For Reader API, it is the amount of tokens in the responses. This pricing model is applicable to all products in Jina AI's search foundation: Embedding, Reranking, Reader, Auto Fine-Tuning APIs. With the same API key, you have access to all API services.</div><div class="col-12 col-md-10"><div class="full-width q-pa-md"><label class="q-field row no-wrap items-start q-field--filled q-input q-field--square q-field--labeled q-field--dark q-field--error q-field--highlighted" for="f_6837bc03-3e0d-45c1-b3cb-285caadf2fc6"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap text-negative" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><input class="q-field__native q-placeholder ellipsis" tabindex="0" aria-label="Enter the API key you wish to recharge" id="f_6837bc03-3e0d-45c1-b3cb-285caadf2fc6" type="text" style="font-family: monospace;"><div class="q-field__label no-pointer-events absolute ellipsis">Enter the API key you wish to recharge</div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon text-negative fas fa-circle-exclamation" aria-hidden="true" role="presentation"> </i></div></div></div></label></div><div class="q-item q-item-type row no-wrap q-item--dark q-ma-sm" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon fab fa-stripe" aria-hidden="true" role="presentation" style="font-size: 24px;"> </i><i class="q-icon fab fa-cc-visa q-ml-sm" aria-hidden="true" role="presentation" style="font-size: 24px;"> </i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Top up this API key by selecting the tokens you need</div><div class="q-item__label q-item__label--caption text-caption">A tweet is about 20 tokens, a news article is about 1000 tokens, and Charles Dickens' novel "A Tale of Two Cities" has over a million tokens.</div></div></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow row q-pa-md"><div class="col-12 q-pa-sm"><div class="q-card q-card--dark q-dark q-card--bordered q-card--square no-border-radius q-card--flat no-shadow q-pa-md"><div class="q-item q-item-type row no-wrap q-item--dark col" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/1m-free.0feba977.png" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label text-h6 dynamic-text">1M free tokens</div><div class="q-item__label q-item__label--caption text-caption">Receive 1 million free tokens with each new API key, no credit card needed. Suitable for both personal and commercial projects.</div></div></div></div></div><div class="q-inner-loading q--avoid-card-border absolute-full column flex-center q-inner-loading--dark lock-blur" style="--q-transition-duration:300ms;"><svg class="q-spinner q-spinner-mat" width="0" height="0" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg><div class="q-inner-loading__label">Please input the right API key to top up</div></div></div></div></div><div data-v-75350d50="" class="q-pt-xl" id="faq"><h2 class="text-h2 text-center non-selectable q-my-xl">FAQ</h2><div class="row justify-center q-mb-xl text-grey-5">At any time, press <div class="q-badge flex inline items-center no-wrap q-badge--single-line q-badge--outline q-mx-sm" role="status" aria-label="/" square="">/</div> to open search bar</div><div class="row justify-center"><div class="q-list q-list--dark q-list--padding col-11 col-md-6 q-py-xl"><div class="q-item__label q-item__label--header">Reader-related common questions</div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_9578d671-795a-42cf-b1c4-c7dc80e0773a" aria-label="Expand &quot;What are the costs associated with using the Reader API?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What are the costs associated with using the Reader API?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_9578d671-795a-42cf-b1c4-c7dc80e0773a" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">The Reader API is free of charge and does not require an API key. Simply prepend 'https://r.jina.ai/' to your URL.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_4e0b1e05-4d56-41d2-9e87-5ce8d235cae3" aria-label="Expand &quot;How does the Reader API function?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">How does the Reader API function?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_4e0b1e05-4d56-41d2-9e87-5ce8d235cae3" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">The Reader API uses a proxy to fetch any URL, rendering its content in a browser to extract high-quality main content.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_4bc99324-ff49-4086-a7df-e1e0a725fc0f" aria-label="Expand &quot;Is the Reader API open source?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Is the Reader API open source?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_4bc99324-ff49-4086-a7df-e1e0a725fc0f" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Yes, the Reader API is open source and available on the Jina AI GitHub repository.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_08e7e7b6-a132-4a63-831f-f251ef3ca018" aria-label="Expand &quot;What is the typical latency for the Reader API?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What is the typical latency for the Reader API?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_08e7e7b6-a132-4a63-831f-f251ef3ca018" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">The Reader API generally processes URLs and returns content within 2 seconds, although complex or dynamic pages might require more time.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_2b30ab32-0e78-46e5-a16e-966bb6e969f3" aria-label="Expand &quot;Why should I use the Reader API instead of scraping the page myself?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Why should I use the Reader API instead of scraping the page myself?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_2b30ab32-0e78-46e5-a16e-966bb6e969f3" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Scraping can be complicated and unreliable, particularly with complex or dynamic pages. The Reader API provides a streamlined, reliable output of clean, LLM-ready text.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_ca52cabf-b5c7-4365-a855-51256f859aa6" aria-label="Expand &quot;Does the Reader API support multiple languages?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Does the Reader API support multiple languages?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_ca52cabf-b5c7-4365-a855-51256f859aa6" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">The Reader API returns content in the original language of the URL. It does not provide translation services.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_fbed277b-cfa3-45b6-8ee1-7fd0c9539397" aria-label="Expand &quot;What should I do if a website blocks the Reader API?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What should I do if a website blocks the Reader API?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_fbed277b-cfa3-45b6-8ee1-7fd0c9539397" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">If you experience blocking issues, please contact our support team for assistance and resolution.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_5949d1e1-e0bf-4711-ac6e-b6164f7697b7" aria-label="Expand &quot;Can the Reader API extract content from PDF files?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Can the Reader API extract content from PDF files?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_5949d1e1-e0bf-4711-ac6e-b6164f7697b7" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">While primarily designed for web pages, the Reader API can extract content from PDFs viewed in HTML format on websites like arXiv, but it is not optimized for general PDF extraction.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_65d53202-6a47-4b4f-a68c-9185d8c84cb5" aria-label="Expand &quot;Can the Reader API process media content from web pages?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Can the Reader API process media content from web pages?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_65d53202-6a47-4b4f-a68c-9185d8c84cb5" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Currently, the Reader API does not process media content, but future enhancements will include image captioning and video summarization.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_a6172d69-139b-4abb-8191-9d047f1c79c8" aria-label="Expand &quot;Is it possible to use the Reader API on local HTML files?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Is it possible to use the Reader API on local HTML files?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_a6172d69-139b-4abb-8191-9d047f1c79c8" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">No, the Reader API can only process content from publicly accessible URLs.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_1383cb2d-ac04-473f-a115-b285fa45137a" aria-label="Expand &quot;Does Reader API cache the content?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Does Reader API cache the content?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_1383cb2d-ac04-473f-a115-b285fa45137a" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">If you request the same URL within 5 minutes, the Reader API will return the cached content.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_86640b1e-e7be-41e1-b745-5df92f1f8a53" aria-label="Expand &quot;Can I use the Reader API to access content behind a login?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Can I use the Reader API to access content behind a login?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_86640b1e-e7be-41e1-b745-5df92f1f8a53" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Unfortunately not.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_61a12480-123c-466f-9617-8c1d18835a75" aria-label="Expand &quot;Can I use the Reader API to access PDF on arXiv?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Can I use the Reader API to access PDF on arXiv?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_61a12480-123c-466f-9617-8c1d18835a75" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Yes, but not directly access the PDF file but via the HTML version of the PDF file. For example, try https://r.jina.ai/https://arxiv.org/html/2310.19923v4</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_aa03d884-2ff5-466c-be3e-1a7047424b15" aria-label="Expand &quot;How does image caption work in Reader?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">How does image caption work in Reader?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_aa03d884-2ff5-466c-be3e-1a7047424b15" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Reader captions all images at the specified URL and adds `Image [idx]: [caption]` as an alt tag (if they initially lack one). This enables downstream LLMs to interact with the images in reasoning, summarizing etc.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_a8f559aa-0b82-4474-9a57-92c18103d116" aria-label="Expand &quot;What is the scalability of the Reader? Can I use it in production?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What is the scalability of the Reader? Can I use it in production?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_a8f559aa-0b82-4474-9a57-92c18103d116" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">The Reader API is designed to be highly scalable. It is auto-scaled based on the real-time traffic and the maximum concurrency requests is now around 4000. We are maintaining it actively as one of the core products of Jina AI. So feel free to use it in production.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_6f91286f-574e-4d76-862d-2dc7ce14f0fd" aria-label="Expand &quot;What is the rate limit of the Reader API?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/assets/reader.2a3a364b.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What is the rate limit of the Reader API?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_6f91286f-574e-4d76-862d-2dc7ce14f0fd" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Please find the latest rate limit information in the table below. Note that we are actively working on improving the rate limit and performance of the Reader API, the table will be updated accordingly.</div><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="#rate-limit" style="padding: 24px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon on-left notranslate material-icons" aria-hidden="true" role="img">speed</i><span class="block">Rate limit</span></span></a></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal" style="margin-bottom: 8px; margin-top: 8px;"><div class="q-item__label q-item__label--header">API-related common questions</div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_72a510e6-777f-4cd3-94ac-b3094335d68f" aria-label="Expand &quot;Can I use the same API key for embedding, reranking, reader, fine-tuning APIs?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">code</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Can I use the same API key for embedding, reranking, reader, fine-tuning APIs?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_72a510e6-777f-4cd3-94ac-b3094335d68f" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Yes, the same API key is valid for all search foundation products from Jina AI. This includes the embedding, reranking, reader and fine-tuning APIs, with tokens shared between the all services.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_ca58ecaa-1e5e-4435-b397-f9b85d0de9c2" aria-label="Expand &quot;Can I monitor the token usage of my API key?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">code</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Can I monitor the token usage of my API key?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_ca58ecaa-1e5e-4435-b397-f9b85d0de9c2" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Yes, token usage can be monitored in the 'Buy tokens' tab by entering your API key, allowing you to view the usage history and remaining tokens.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_a21f961a-335a-4fc2-8d20-cad0297d042a" aria-label="Expand &quot;What should I do if I forget my API key?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">code</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What should I do if I forget my API key?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_a21f961a-335a-4fc2-8d20-cad0297d042a" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">If you have misplaced a topped-up key and wish to retrieve it, please contact support AT jina.ai with your registered email for assistance.</div><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="/contact-sales" style="padding: 24px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Contact sales</span></span></a></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e81ca803-c866-4dce-aafa-4271eefcd3f4" aria-label="Expand &quot;Do API keys expire?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">code</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Do API keys expire?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_e81ca803-c866-4dce-aafa-4271eefcd3f4" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">No, our API keys do not have an expiration date. However, if you suspect your key has been compromised and wish to retire it or transfer its tokens to a new key, please contact our support team for assistance.</div><a class="q-btn q-btn-item non-selectable no-outline q-btn--outline q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="/contact-sales" style="padding: 24px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><span class="block">Contact sales</span></span></a></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_b69d49de-b9d1-41e0-8b42-38674a1a92c7" aria-label="Expand &quot;Why is the first request for some models slow?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">code</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Why is the first request for some models slow?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_b69d49de-b9d1-41e0-8b42-38674a1a92c7" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">This is because our serverless architecture offloads certain models during periods of low usage. The initial request activates or 'warms up' the model, which may take a few seconds. After this initial activation, subsequent requests process much more quickly.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_5453c08a-66bd-4369-b788-db08c4e5144e" aria-label="Expand &quot;Is user input data used for training your models?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">code</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Is user input data used for training your models?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_5453c08a-66bd-4369-b788-db08c4e5144e" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">We adhere to a strict privacy policy and do not use user input data for training our models.</div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal" style="margin-bottom: 8px; margin-top: 8px;"><div class="q-item__label q-item__label--header">Billing-related common questions</div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_f55efcf2-aff8-4f39-878b-8430eced7dce" aria-label="Expand &quot;Is billing based on the number of sentences or requests?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">attach_money</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Is billing based on the number of sentences or requests?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_f55efcf2-aff8-4f39-878b-8430eced7dce" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Our pricing model is based on the total number of tokens processed, allowing users the flexibility to allocate these tokens across any number of sentences, offering a cost-effective solution for diverse text analysis requirements.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e44acbed-9caf-4ba7-974f-8fa2706fdfc1" aria-label="Expand &quot;Is there a free trial available for new users?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">attach_money</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Is there a free trial available for new users?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_e44acbed-9caf-4ba7-974f-8fa2706fdfc1" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">We offer a welcoming free trial to new users, which includes one million tokens for use with any of our models, facilitated by an auto-generated API key. Once the free token limit is reached, users can easily purchase additional tokens for their API keys via the 'Buy tokens' tab.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e96a180f-9dcc-4a46-8b8e-37bad38358b4" aria-label="Expand &quot;Are tokens charged for failed requests?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">attach_money</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Are tokens charged for failed requests?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_e96a180f-9dcc-4a46-8b8e-37bad38358b4" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">No, tokens are not deducted for failed requests.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e40cee47-54ce-4812-9c23-d1686a2fc474" aria-label="Expand &quot;What payment methods are accepted?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">attach_money</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">What payment methods are accepted?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_e40cee47-54ce-4812-9c23-d1686a2fc474" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Payments are processed through Stripe, supporting a variety of payment methods including credit cards, Google Pay, and PayPal for your convenience.</div></div></div></div></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--popup"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_509f7ee5-a8cc-4794-9d7b-cd7c78d08732" aria-label="Expand &quot;Is invoicing available for token purchases?&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation">attach_money</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Is invoicing available for token purchases?</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon fas fa-chevron-down q-expansion-item__toggle-icon" aria-hidden="true" role="presentation"> </i></div></div><div class="q-expansion-item__content relative-position" id="f_509f7ee5-a8cc-4794-9d7b-cd7c78d08732" style="display: none;"><div class="q-card q-card--dark q-dark q-card--flat no-shadow"><div class="q-card__section q-card__section--vert"><div class="q-py-lg">Yes, an invoice will be issued to the email address associated with your Stripe account upon the purchase of tokens.</div></div></div></div></div></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow overflow-hidden print-hide"><div class="q-img q-img--menu full-width" role="img"><div style="padding-bottom: 56.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--waiting" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/portal-2-poster.44997122.webp" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div><div class="overlay"></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow row absolute-left items-center bg-transparent non-selectable fit"><div class="text-white bg-transparent lock-blur fit q-pa-sm"><div class="row justify-between q-gutter-lg"><div class="col-12 col-md-3"><div class="q-list q-list--dark"><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><strong>Offices</strong></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Germany (HQ)</div><div class="q-item__label q-item__label--caption text-caption">Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany</div><div class="q-item__label q-item__label--caption text-caption">Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Beijing, China</div><div class="q-item__label q-item__label--caption text-caption">Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-icons" aria-hidden="true" role="presentation" style="font-size: 32px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption">402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div></div><div class="row text-caption justify-center q-mt-xl"> © Jina AI GmbH 2020-2024. All rights reserved.</div></div></div></div><footer class="q-footer q-layout__section--marginal fixed-bottom lock-blur bg-transparent print-hide"><div class="row"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline col-12 col-md-6 justify-center"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-discord" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://twitter.com/jinaAI_/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://podcasts.apple.com/us/podcast/jina-ai-podcast/id1734573793" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-solid fa-podcast" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="https://www.youtube.com/c/JinaAI" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-youtube" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" type="button" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fa-brands fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px; min-width: 0px; min-height: 0px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-icons" aria-hidden="true" role="img">email</i></span></a></div></div></footer></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>