<!DOCTYPE html><html translate="no" dir="ltr" lang="ru"><head><title>Что нам следует извлечь из ModernBERT?</title><meta charset="utf-8"><meta name="title" content="Что нам следует извлечь из ModernBERT?"><meta name="description" content="ModernBERT задает направление для будущих BERT-подобных моделей благодаря увеличенным тренировочным данным, эффективному подбору параметров и глубокой, но компактной архитектуре."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/what-should-we-learn-from-modernbert"><meta property="og:title" content="Что нам следует извлечь из ModernBERT?"><meta property="og:description" content="ModernBERT задает направление для будущих BERT-подобных моделей благодаря увеличенным тренировочным данным, эффективному подбору параметров и глубокой, но компактной архитектуре."><meta property="og:image" content="https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/what-should-we-learn-from-modernbert"><meta property="twitter:title" content="Что нам следует извлечь из ModernBERT?"><meta property="twitter:description" content="ModernBERT задает направление для будущих BERT-подобных моделей благодаря увеличенным тренировочным данным, эффективному подбору параметров и глубокой, но компактной архитектуре."><meta property="twitter:image" content="https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-BpYg73uG.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-CRvJtbiE.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-B_MkGnFZ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-C3sewhfM.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-NRKnHJdK.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-NpS39Pob.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-CmvEedNm.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-B_Eaiczz.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/ru-CJwv998q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-DUhUg5dr.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CQgiypBt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-CFWXPejC.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-2u2_SMxa.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-UAi_SpTk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-oLzsi-Fl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-C---_fmb.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-CllvojrU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-CAGlamz0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-TcJTC_kN.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-DaduPAOD.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-ONOgjDpV.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-DnyFHmkm.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-B112i-o1.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-D_hyTJjS.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-BijxTYjd.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-BaAa6H9n.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-Cva-Yr8q.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-y4w5rHky.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-BrvBcj9Y.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-DhrZwOZj.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-B_CyKxBv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-Bxc1O8dG.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-4dstt87o.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BUnfyEcY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-Cwnby5f-.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-D_QOBD6F.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-CY21gJrF.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-CacHDkLh.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Nan Wang, Alex C-G"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Nan Wang, Alex C-G"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="10 mins read"><meta property="article:published_time" content="2025-01-22T08:31:26.000+01:00"><meta property="article:modified_time" content="2025-01-22T08:31:26.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Что нам следует извлечь из ModernBERT?",
  "description": "ModernBERT задает направление для будущих BERT-подобных моделей благодаря увеличенным тренировочным данным, эффективному подбору параметров и глубокой, но компактной архитектуре.",
  "image": [
    "https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"
  ],
  "datePublished": "2025-01-22T08:31:26.000+01:00",
  "dateModified": "2025-01-22T08:31:26.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Nan Wang",
      "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
    },
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Новости</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Модели</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_e076edce-e0ed-4599-bca3-e61ca34159a2" aria-label="Расширьте &quot;Продукты&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Продукты</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_e076edce-e0ed-4599-bca3-e61ca34159a2" style="display: none;"><div class="q-list q-list--dark" role="list" label="Продукты"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Читатель</div><div class="q-item__label q-item__label--caption text-caption">Читайте URL-адреса и ищите информацию в Интернете для получения более подходящей подготовки для получения степени магистра права.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Вложения</div><div class="q-item__label q-item__label--caption text-caption">Мультимодальные многоязычные вложения мирового класса.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Реранкер</div><div class="q-item__label q-item__label--caption text-caption">Нейронный ретривер мирового класса для максимального повышения релевантности поиска.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Классификатор</div><div class="q-item__label q-item__label--caption text-caption">Классификация изображений и текста по нулевому и небольшому количеству кадров.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Сегментатор</div><div class="q-item__label q-item__label--caption text-caption">Разрежьте длинный текст на куски и выполните токенизацию.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">API-документы</div><div class="q-item__label q-item__label--caption text-caption">Автоматическая генерация кода для вашего второго пилота IDE или LLM</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_ac4c2db4-bc1e-4fb0-92e9-47d051958685" aria-label="Расширьте &quot;Компания&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Компания</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_ac4c2db4-bc1e-4fb0-92e9-47d051958685" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">О нас</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Связаться с отделом продаж</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Стажерская программа</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Присоединяйтесь к нам</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Скачать логотип</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Условия использования</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Авторизоваться"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Авторизоваться</div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_9179374d-8446-4dbe-8973-b84651f91e55"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_9179374d-8446-4dbe-8973-b84651f91e55" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_9179374d-8446-4dbe-8973-b84651f91e55_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-2341133f="" class="q-page" style="min-height: 100vh;"><div data-v-2341133f="" class="row full-width relative-position justify-end"><div data-v-2341133f="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-2341133f="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">Эффективность параметров ModernBERT</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">Моделирование кода в ModernBERT</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">Обработка длинного контекста в ModernBERT</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">Горький урок?</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">Заключение</div></div></div></div></div><div data-v-2341133f="" class="col-12 col-md-10 col-lg-12"><div data-v-2341133f="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Технический блог</div></div></div></div><div data-v-2341133f="" class="row justify-center"><div data-v-2341133f="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-2341133f="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">январь 22, 2025</div><h1 data-v-2341133f="" class="text-weight-medium text-center q-px-md my-title">Что нам следует извлечь из ModernBERT?</h1><div data-v-2341133f="" class="col row justify-center"><div data-v-2341133f="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">ModernBERT задает направление для будущих BERT-подобных моделей благодаря увеличенным тренировочным данным, эффективному подбору параметров и глубокой, но компактной архитектуре.</div></div><div data-v-2341133f="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-2341133f="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/modernbert.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-2341133f="" class="row justify-center"><div data-v-2341133f="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-2341133f="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-2341133f="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Nan Wang"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Nan Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-2341133f="" class="q-item__label">Nan Wang, Alex C-G • 10 минуты чтения</div></div></div></div><div data-v-2341133f="" class="row justify-center"><div data-v-2341133f="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-2341133f="" class="article"><section data-v-2341133f="" class="gh-content"><p>В 2018 году Google выпустил BERT, что стало переломным моментом для NLP, задолго до нынешней волны LLM. Даже сейчас множество Small Language Models построены на основе BERT. В декабре 2024 года <a href="https://huggingface.co/blog/modernbert" rel="noreferrer">ModernBERT</a> берет все, что мы узнали из недавних разработок LLM, и применяет это к этим меньшим моделям. Ключевые изменения? Лучшая эффективность параметров, понимание кода и обработка длинного контекста.</p><p>В этой статье мы разберем, как ModernBERT сравнивается с двумя моделями, которые мы знаем вдоль и поперек: <code>jina-XLM-RoBERTa</code> (многоязычная основа <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>) и <code>RoBERTa-large</code>. Давайте рассмотрим каждую модель:</p><ul><li><strong>ModernBERT </strong>(декабрь 2024) — недавно выпущенная SLM, разработанная совместно Answer.AI, LightOn и HuggingFace. Она использует современные оптимизации, такие как RoPE для контекстного окна в 8 192 токена и <a href="https://arxiv.org/abs/2002.05202">слои GeGLU</a>, повышая производительность при сохранении эффективности.</li><li><a href="https://huggingface.co/jinaai/xlm-roberta-flash-implementation"><strong><code>jina-XLM-RoBERTa</code></strong></a><strong> </strong>(сентябрь 2024) — это многоязычная модель текстовых эмбеддингов на основе <a href="https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta"><code>XLM-RoBERTa</code></a> от Meta. В то время как оригинальная <code>XLM-RoBERTa</code> улучшает <code>RoBERTa</code> с помощью большого многоязычного набора данных XLM, <code>jina-XLM-RoBERTa</code> идет дальше с расширенным контекстным обучением, реализацией <a href="https://arxiv.org/abs/2104.09864">RoPE</a> и поддержкой <a href="https://arxiv.org/abs/2307.08691">FlashAttention-2</a>. Эта модель служит основой для <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>.</li><li><a href="https://huggingface.co/FacebookAI/roberta-large"><strong><code>RoBERTa-large</code></strong></a> (июль 2019), разработанная Meta, является улучшенной версией BERT с 355 миллионами параметров. Благодаря расширенному обучению, большим наборам данных и инновациям, таким как динамическое маскирование, она достигла впечатляющих результатов в ключевых бенчмарках, включая <a href="https://gluebenchmark.com/">GLUE</a>, <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a> и <a href="https://arxiv.org/abs/1704.04683">RACE</a>. Это делает ее подходящей для различных задач NLP от классификации текста до ответов на вопросы.</li></ul><p>Сравнивая эти модели по трем основным аспектам, мы стремимся подчеркнуть эффективные проектные решения ModernBERT для разработчиков моделей и определить ключевые идеи разработки для будущих моделей типа BERT. Мы также поделимся нашим опытом разработки <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> и обсудим планируемые улучшения для <code>jina-embeddings-v4</code> и <code>jina-reranker-v3</code>.</p><h2 id="modernberts-parameter-efficiency" style="position: relative;"><a href="#modernberts-parameter-efficiency" title="Эффективность параметров ModernBERT" id="anchor-modernberts-parameter-efficiency"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Эффективность параметров ModernBERT</h2><p>Давайте сначала рассмотрим подход ModernBERT к эффективности параметров — он включает несколько ключевых идей из недавних разработок LLM. ModernBERT использует три основные стратегии: более глубокую, но более тонкую архитектуру, контролируемый размер словаря и прогрессивное масштабирование модели, начиная с меньших моделей.</p><h3 id="deep-and-thin-architecture" style="position: relative;"><a href="#deep-and-thin-architecture" title="Глубокая и тонкая архитектура" id="anchor-deep-and-thin-architecture"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Глубокая и тонкая архитектура</h3><p>ModernBERT-large становится глубже с 28 слоями, в то время как <code>jina-XLM-RoBERTa</code> и <code>RoBERTa-large</code> работают с 24. Но вот что интересно — она соответствует <code>RoBERTa-large</code> по количеству параметров, несмотря на эти дополнительные слои. <code>jina-XLM-RoBERTa</code> требует больше параметров, поскольку обрабатывает 89 языков, в то время как другие две фокусируются только на английском.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/deep_and_thin-dark-architecture-outlines-1.svg" class="kg-image" alt="" width="1389" height="547" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Глубина (количество слоев) важнее ширины (количество скрытых единиц) для малых LLM. Глубокая и тонкая структура модели лучше улавливает абстрактные концепции, что приводит к превосходной конечной производительности.</span></figcaption></figure><p>Большинство параметров трансформера приходится на слои внимания и полносвязные слои. ModernBERT остается конкурентоспособной по размеру, становясь "тоньше" — они используют 2 624 скрытых единицы в 28 слоях, по сравнению с 4 096 единицами в 24 слоях у RoBERTa-large. Эта более "глубокая", но тонкая настройка позволяет им достигать целевых показателей производительности без раздувания модели.</p>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Parameters</td>
<td>400M</td>
<td>550M</td>
<td>355M</td>
</tr>
<tr>
<td>Hidden states</td>
<td>1,024</td>
<td>1,024</td>
<td>1,024</td>
</tr>
<tr>
<td>Intermediate dims</td>
<td>2,624</td>
<td>4,096</td>
<td>4,096</td>
</tr>
<tr>
<td>Attention heads</td>
<td>16</td>
<td>16</td>
<td>16</td>
</tr>
<tr>
<td>Layers</td>
<td>28</td>
<td>24</td>
<td>24</td>
</tr>
<tr>
<td>Vocabulary size</td>
<td>50,368</td>
<td>250,002</td>
<td>50,265</td>
</tr>
</tbody>
</table>

<p>Этот подход согласуется с исследованием Meta <a href="https://openreview.net/pdf?id=EIGbXbxcUQ">MobileLLM</a>, которое обнаружило, что для меньших моделей глубина важнее ширины, когда речь идет о захвате сложных паттернов и повышении производительности. По сути, способность обрабатывать информацию через большее количество слоев трансформера оказывается более ценной, чем наличие более широких слоев для параллельной обработки.</p><p>Давайте посмотрим на данные о том, как работает эта глубокая и тонкая архитектура.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/performance_comparison_general.v3.svg" class="kg-image" alt="" width="872" height="371" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">В сравнении с аналогичными моделями, использующими традиционную мелкую и широкую архитектуру, ModernBERT показывает лучшие результаты в ключевых задачах, таких как поиск и STS — при этом сохраняя аналогичное количество параметров.</span></figcaption></figure>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>STS12</td>
<td>72.6</td>
<td><strong>72.7</strong></td>
<td>68.9</td>
</tr>
<tr>
<td>STS13</td>
<td><strong>84.9</strong></td>
<td>83.9</td>
<td>81.0</td>
</tr>
<tr>
<td>STS14</td>
<td>77.5</td>
<td><strong>77.7</strong></td>
<td>74.8</td>
</tr>
<tr>
<td>STS15</td>
<td>84.8</td>
<td><strong>85.8</strong></td>
<td>84.1</td>
</tr>
<tr>
<td>STS16</td>
<td>79.4</td>
<td><strong>79.6</strong></td>
<td>78.6</td>
</tr>
<tr>
<td>STS17</td>
<td><strong>87.5</strong></td>
<td>87.2</td>
<td>87.2</td>
</tr>
<tr>
<td>TRECCOVID</td>
<td><strong>61.1</strong></td>
<td>59.6</td>
<td>49.3</td>
</tr>
<tr>
<td>FiQA</td>
<td><strong>44.4</strong></td>
<td>40.0</td>
<td>40.7</td>
</tr>
<tr>
<td>NFCorpus</td>
<td><strong>32.6</strong></td>
<td>30.6</td>
<td>27.9</td>
</tr>
<tr>
<td>SciFact</td>
<td><strong>68.6</strong></td>
<td>65.5</td>
<td>63.1</td>
</tr>
<tr>
<td>Average</td>
<td><strong>69.3</strong></td>
<td>68.2</td>
<td>65.6</td>
</tr>
</tbody>
</table>

<p>Возьмем <code>jina-XLM-RoBERTa</code> — она основывается на мелкой и широкой архитектуре <code>RoBERTa-large</code>, но увеличивает словарь с 50K до 250K токенов и обучается на большем количестве данных. Тем не менее, ModernBERT все равно превосходит ее, что говорит о том, что архитектурное изменение действительно влияет на эффективность.</p><h3 id="vocabulary-size-matters" style="position: relative;"><a href="#vocabulary-size-matters" title="Размер словаря имеет значение" id="anchor-vocabulary-size-matters"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Размер словаря имеет значение</h3><p>Сначала давайте посмотрим, как считаются параметры словаря в трансформерах. Для любого трансформера <code>параметры словаря = количество различных токенов × размер скрытого состояния</code>. Возьмем <code>jina-XLM-RoBERTa</code>: с 250K токенов и 1 024 измерениями ей требуется 256M параметров только для кодирования словаря — до обработки каких-либо фактических языковых задач!</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/tokenizer-dark-outline.svg" class="kg-image" alt="" width="3757" height="715" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">В трансформерах первый слой отображает токены в скрытые состояния, используя матрицу весов, а именно веса словаря. Если использовать все кодовые точки UTF-8 (1 112 064) с 1 024 скрытыми измерениями, потребуется огромное количество параметров - </span><code spellcheck="false" style="white-space: pre-wrap;"><span>1,112,064 × 1,024 = 1 B</span></code><span style="white-space: pre-wrap;"> только для преобразования токенов. Хотя более крупные LLM (100B+ параметров) могут справиться с этими накладными расходами, для меньших моделей это серьезное ограничение. Именно поэтому мы используем токенизаторы вроде BPE, которые эффективно объединяют часто встречающиеся кодовые точки UTF-8 в единые токены.</span></figcaption></figure><p>Но вот в чем дело: <strong>веса словаря не участвуют в механизмах внимания - это просто таблицы поиска.</strong> Для SLM, работающих с фиксированным бюджетом параметров, больший словарь означает меньше параметров для слоев внимания, которые выполняют фактическую обработку языка. Это объясняет, почему англоязычный ModernBERT-large превосходит многоязычный <code>jina-XLM-RoBERTa</code>, несмотря на меньший размер - <code>jina-XLM-RoBERTa</code> выделяет больше параметров (47%!) для поддержки нескольких языков. Сфокусированный словарь ModernBERT не только улучшает производительность, но и ускоряет вывод, что делает его особенно эффективным для приложений с ограниченными ресурсами.</p><p>Если посмотреть <em>только</em> на основные параметры модели (исключая веса словаря), ModernBERT фактически обладает большей вычислительной мощностью, чем его аналоги: ModernBERT выделяет на 19% больше параметров для <em>фактического</em> языкового моделирования, чем <code>jina-XLM-RoBERTa</code>, и на 15% больше, чем <code>RoBERTa-large</code>!</p>

<table>
<thead>
<tr>
<th>Характеристики модели</th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Поддержка языков</td>
<td>Только английский</td>
<td>89 языков</td>
<td>Только английский</td>
</tr>
<tr>
<td>Размер словаря</td>
<td>50.4K</td>
<td>250K</td>
<td>50.3K</td>
</tr>
<tr>
<td>Всего параметров</td>
<td>400M</td>
<td>550M</td>
<td>355M</td>
</tr>
<tr>
<td>Параметры словаря</td>
<td>51M</td>
<td>256M</td>
<td>51M</td>
</tr>
<tr>
<td>Доля параметров словаря</td>
<td>13%</td>
<td>47%</td>
<td>14%</td>
</tr>
<tr>
<td>Основные параметры модели</td>
<td><b>349M</b></td>
<td>294M</td>
<td>304M</td>
</tr>
</tbody>
</table>

<h3 id="model-upscaling-by-weight-tiling" style="position: relative;"><a href="#model-upscaling-by-weight-tiling" title="Масштабирование модели с помощью &quot;Weight Tiling&quot;" id="anchor-model-upscaling-by-weight-tiling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Масштабирование модели с помощью "Weight Tiling"</h3><p>При создании базовой модели <a href="https://huggingface.co/jinaai/jina-bert-implementation"><code>jina-BERT-v2</code></a> мы обнаружили, что обучение SLM с нуля требует много ресурсов и сложно. ModernBERT решает эту проблему с помощью умного подхода к инициализации, называемого <strong>weight tiling</strong> - по сути, загружая ModernBERT-large из весов его меньшей базовой версии.</p><p>Эта техника не совсем нова - она основана на работе DeepMind с <a href="https://gpt3demo.com/apps/deepmind-gopher">Gopher</a> и также присутствует в моделях Microsoft <a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2</a>. Но ее применение здесь особенно эффективно для решения проблемы узкого места при обучении SLM.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/deep_and_thin-dark.svg" class="kg-image" alt="" width="1877" height="1308" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ModernBERT масштабируется с 22 до 28 слоев, используя стратегию инициализации глубины команды Gopher. Для этих дополнительных слоев (23-28) они инициализируют каждый, используя веса из исходных 22 слоев ModernBERT-base. Для весовых матриц каждого слоя они используют подход центрального тайлинга Phi-2. Это работает так: они берут веса ModernBERT-base и помещают их прямо в центр матриц ModernBERT-large. А пустые края? Они циклически заполняют их исходными весами.</span></figcaption></figure><p>Эта стратегия инициализации дает ModernBERT-large значительное преимущество - вместо холодного старта с нуля он использует предварительно изученные паттерны из своего меньшего аналога. Это оказалось особенно <a href="https://arxiv.org/pdf/2112.11446">эффективным для масштабирования языковых моделей в этом диапазоне размеров</a>.</p><blockquote>Мы обнаружили, что модель с теплым стартом быстро восстанавливается после высокой начальной потери (из-за добавленных параметров) до потери, близкой к базовой модели. Нам удалось расширить 417M параметров более чем в 3 раза по размеру и сохранить производительность выше, чем у эквивалентной свежей модели, обученной с нуля до сходимости, что подразумевает, что выигрыш не ограничивался началом обучения. Однако при больших размерах относительные выигрыши при сходимости уменьшаются, особенно при расширении ширины.</blockquote><p>Циклическое обертывание весов - это не просто удобство, оно хорошо согласуется с тем, как матрицы внимания естественным образом проявляют периодические паттерны. Исследование Gopher показывает, что этот подход действительно блистает для SLM (менее 9B параметров), хотя преимущества начинают уменьшаться при переходе к более крупным моделям.</p><h2 id="modernberts-code-modeling" style="position: relative;"><a href="#modernberts-code-modeling" title="Моделирование кода в ModernBERT" id="anchor-modernberts-code-modeling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Моделирование кода в ModernBERT</h2><p>ModernBERT предлагает специализированный подход к пониманию кода с помощью оптимизированного для кода токенизатора и обучающих данных. Эта точная настройка для обработки кода окупается как в задачах понимания, так и в задачах поиска.</p><p>Мы провели тестирование с использованием корпуса <code>jina-embeddings-v2-code</code>, сравнивая три модели в качестве основы: <code>ModernBERT</code>, <code>jina-XLM-RoBERTa</code> и <code>RoBERTa-large</code>. Тест? <a href="https://github.com/github/CodeSearchNet">CodeSearchNet</a> - сопоставление текстовых описаний с фрагментами кода. ModernBERT превзошел обе альтернативы по всем показателям.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/code_search_net.v3.svg" class="kg-image" alt="" width="787" height="489" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Разрыв логичен - ни </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-XLM-RoBERTa</span></code><span style="white-space: pre-wrap;"> ни </span><code spellcheck="false" style="white-space: pre-wrap;"><span>RoBERTa-large</span></code><span style="white-space: pre-wrap;"> не видели языков программирования во время обучения. Между тем, ModernBERT-large обучался на двух триллионах токенов, включая значительное количество кода. Этот опыт работы с синтаксисом и паттернами программирования дает ему явное преимущество в задачах, связанных с кодом. </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-XLM-RoBERTa</span></code><span style="white-space: pre-wrap;"> немного опережает </span><code spellcheck="false" style="white-space: pre-wrap;"><span>RoBERTa-large</span></code><span style="white-space: pre-wrap;">, вероятно, благодаря большему объему многоязычных обучающих данных - та же архитектура, больше опыта. Тем не менее, обе значительно отстают от ModernBERT-large.</span></figcaption></figure>

<table>
<thead>
<tr>
<th>Задача</th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>AdvRetrieval</td>
<td>0.342</td>
<td><strong>0.363</strong></td>
<td>0.331</td>
</tr>
<tr>
<td>QueryRetrieval.python</td>
<td>0.521</td>
<td><strong>0.530</strong></td>
<td>0.525</td>
</tr>
<tr>
<td>QueryRetrieval java</td>
<td><strong>0.679</strong></td>
<td>0.633</td>
<td>0.644</td>
</tr>
<tr>
<td>QueryRetrieval.javascript</td>
<td>0.755</td>
<td><strong>0.768</strong></td>
<td>0.732</td>
</tr>
<tr>
<td>QueryRetrieval.php</td>
<td><strong>0.815</strong></td>
<td>0.781</td>
<td>0.755</td>
</tr>
<tr>
<td>QueryRetrieval.ruby</td>
<td>0.729</td>
<td><strong>0.744</strong></td>
<td>0.722</td>
</tr>
<tr>
<td>QueryRetrieval.go</td>
<td><strong>0.833</strong></td>
<td>0.809</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.go</td>
<td><strong>0.778</strong></td>
<td>0.750</td>
<td>0.759</td>
</tr>
<tr>
<td>Retrieval.java</td>
<td><strong>0.840</strong></td>
<td>0.792</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.javascript</td>
<td><strong>0.817</strong></td>
<td>0.792</td>
<td>0.757</td>
</tr>
<tr>
<td>Retrieval.php</td>
<td><strong>0.852</strong></td>
<td>0.805</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.python</td>
<td><strong>0.849</strong></td>
<td>0.816</td>
<td>0.787</td>
</tr>
<tr>
<td>Retrieval.ruby</td>
<td><strong>0.849</strong></td>
<td>0.796</td>
<td>0.803</td>
</tr>
<tr>
<td>Avg.</td>
<td><strong>0.743</strong></td>
<td>0.721</td>
<td>0.708</td>
</tr>
</tbody>
</table>

<h3 id="the-tokenizer-edge" style="position: relative;"><a href="#the-tokenizer-edge" title="Преимущество токенизатора" id="anchor-the-tokenizer-edge"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Преимущество токенизатора</h3>

<p>Давайте разберемся, почему ModernBERT так хорошо справляется с кодом - он использует <a href="https://huggingface.co/docs/transformers/en/model_doc/olmo" rel="noreferrer">токенизатор OLMo</a>, который был специально обучен на коде, в отличие от стандартных токенизаторов BERT/RoBERTa.</p>

<p>Токенизатор разбивает UTF-8 текст на токены, которые затем отображаются в векторы - именно с ними работает модель. В процессе обучения он учится объединять часто встречающиеся последовательности символов в отдельные токены. В чем разница? Стандартный токенизатор может разбить <code>init</code> на <code>in</code> + <code>it</code>, упуская программный контекст. Но токенизатор ModernBERT, понимающий код, обрабатывает его целиком.</p>

<p>Интересный момент в обработке пробелов: ModernBERT сохраняет начальные пробелы Python как отдельные токены и различает 4 и 8 пробелов - что критически важно для структуры кода. В то же время, <strong><code>jina-XLM-RoBERTa</code> объединяет все последовательные пробелы в один <code>_</code>, а RoBERTa-large обрабатывает каждый пробел как отдельный токен.</strong> Это означает, что энкодер ModernBERT получает более чистый и осмысленный ввод при обработке кода, в то время как другие работают с фрагментированными, менее связными токенами.</p>

<figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/code_tokens-cheat-2.svg" class="kg-image" alt="" width="3156" height="1247" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ModernBERT сохраняет начальные пробелы Python как отдельные токены и различает между 4 и 8 пробелами - что критически важно для структуры кода; в то время как другие работают с фрагментированными, менее связными токенами.</span></figcaption></figure>

<h2 id="modernberts-long-context-handling" style="position: relative;"><a href="#modernberts-long-context-handling" title="Обработка длинного контекста в ModernBERT" id="anchor-modernberts-long-context-handling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Обработка длинного контекста в ModernBERT</h2>

<p>ModernBERT достиг значительных успехов в обработке длинных текстов благодаря обширному обучающему корпусу (300 млрд токенов с образцами по 8192 токена) и продвинутым методам, таким как комбинация глобального и локального внимания.</p>

<p>Для оценки возможностей обработки длинных документов мы использовали <a href="https://huggingface.co/datasets/Shitao/MLDR">датасет MLDR</a> - комплексный бенчмарк длинных текстов на 13 языках. Поскольку ModernBERT в настоящее время поддерживает только английский язык, мы сосредоточились на английской части MLDR для сравнения ModernBERT с <code>jina-XLM-RoBERTa</code>. Хотя обе эти модели могут обрабатывать входные данные размером 8 тыс. токенов, <code>RoBERTa-large</code> была исключена из этого бенчмарка из-за ограничения в 512 токенов, что недостаточно для анализа длинных текстов.</p>


<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>MLDR-en</td>
<td><strong>0.351</strong></td>
<td>0.290</td>
</tr>
</tbody>
</table>


<p>Превосходная производительность ModernBERT обусловлена не только обширным обучением на длинных текстах - во многом это заслуга инновационной комбинации механизмов глобального и локального внимания. В отличие от <code>jina-XLM-RoBERTa</code>, которая применяет вычислительно затратное глобальное внимание к каждому слою, ModernBERT использует более эффективный подход. Он чередует глобальное внимание (используется каждый третий слой с <code>theta</code> 160 000) и локальное внимание (использует скользящее окно в 128 токенов с <code>theta</code> 100 000). Эта гибридная стратегия поддерживает высокую производительность при значительном сокращении времени обучения.</p>

<blockquote>В ModernBERT каждый третий слой использует глобальное внимание с RoPE theta 160 000, а остальные слои используют локальное скользящее окно внимания размером 128 токенов с RoPE theta 10 000. —— <a href="https://arxiv.org/pdf/2412.13663">ModernBERT</a></blockquote>

<h2 id="the-bitter-lesson" style="position: relative;"><a href="#the-bitter-lesson" title="Горький урок?" id="anchor-the-bitter-lesson"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Горький урок?</h2>

<p>Закон масштабирования и <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">горький урок</a> предполагают, что основные улучшения производительности происходят в первую очередь за счет увеличения количества параметров и обучающих данных. Этот принцип определил наш подход к расширению корпуса и использованию LoRA для адаптации к конкретным задачам.</p>

<p>Однако успех ModernBERT показал, что мы недооценили силу архитектурной оптимизации. Он демонстрирует, что SLM могут достигать исключительных результатов за счет лучшей эффективности использования данных и модели, не обязательно увеличивая количество параметров. Недавний <a href="https://arxiv.org/pdf/2408.11868">технический отчет Stella Embeddings</a> подтверждает этот вывод, указывая, что текущие методы обучения моделей эмбеддингов можно улучшить без увеличения размера корпуса или модели.</p>

<figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg" class="kg-image" alt="График, показывающий закон масштабирования моделей эмбеддинга с 'Размером параметров' по оси x и 'Производительностью MTEB' по оси y" width="949" height="949" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Закон масштабирования моделей эмбеддинга. Средняя производительность MTEB на английских задачах отображена относительно количества параметров модели. Каждая точка представляет модель эмбеддинга. Линия тренда, представляющая все модели, выделена, с многоязычными моделями, выделенными голубым цветом. Можно видеть, что </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a><span style="white-space: pre-wrap;"> демонстрирует превосходную производительность по сравнению с моделями аналогичного размера, также показывая сверхлинейное улучшение по сравнению со своим предшественником, </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-embeddings-v2</span></code><span style="white-space: pre-wrap;">. Этот график был создан путем выбора топ-100 моделей эмбеддинга из рейтинга MTEB, исключая те, для которых отсутствует информация о размере, обычно закрытые или проприетарные модели. Также были отфильтрованы заявки, определенные как очевидный троллинг.</span></figcaption></figure>

<p>В дальнейшем мы ожидаем снижения вычислительных затрат и уменьшения размеров моделей по мере того, как мы получаем более глубокое понимание использования данных и внедряем методы ModernBERT. В краткосрочной перспективе мы можем реализовать простые улучшения, описанные в статье о ModernBERT - в частности, интеграцию большего количества данных, связанных с кодом, и принятие токенизатора, дружественного к коду. Более сложные изменения, такие как переход к глубокой и тонкой архитектуре или начальная загрузка больших моделей из меньших, потребуют создания базовых моделей с нуля - это более среднесрочная инициатива.</p>

<p>Хотя эффективность ModernBERT впечатляет, его ограничение только текстом указывает на будущие вызовы. По мере роста популярности мультимодальных моделей эмбеддинга наша следующая задача - разработка более умных, быстрых и способных поисковых базовых моделей, которые могут обрабатывать входные данные для мультимодальных приложений. Эти приложения требуют еще более длинных окон контекста - проблема эффективности, которую еще предстоит решить.</p>

<h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Заключение" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Заключение</h2>

<p>В этой статье мы рассмотрели, как ModernBERT продвигает модели семейства BERT через три ключевые инновации: его глубокую и тонкую архитектуру, оптимизированный токенизатор и эффективное масштабирование с использованием тайлинга весов. Эти улучшения позволяют ModernBERT демонстрировать выдающуюся производительность при относительно компактном размере, превосходя как <code>RoBERTa-large</code>, так и <code>jina-XLM-RoBERTa</code> в различных задачах. ModernBERT демонстрирует, что архитектурные улучшения могут быть важнее размера параметров, открывая двери для более эффективных моделей. Его успешное использование тайлинга весов показывает, как прогрессивное масштабирование может снизить затраты на обучение при сохранении или даже повышении производительности. Кроме того, его компактный словарь и целевые оптимизации указывают на растущие возможности для специализированных SLM в условиях ограниченных ресурсов.</p></section></article><div data-v-2341133f="" class="row justify-between items-center q-py-md"><div data-v-2341133f=""><span data-v-2341133f="" class="text-weight-bold">Категории:</span><span data-v-2341133f="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Технический блог</div></div></div></span></div><div data-v-2341133f=""><div data-v-2341133f="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-2341133f="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fru%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fru%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fru%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fru%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fru%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-2341133f="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-2341133f="" class="text-h5 q-my-xl">Читать далее</div><a data-v-aa70018b="" data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/a-practical-guide-to-deploying-search-foundation-models-in-production"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">январь 31, 2025 • 14 минуты чтения</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">A Practical Guide to Deploying Search Foundation Models in Production</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Saahil Ognawala"><div style="padding-bottom: 121.25%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Saahil Ognawala" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Scott Martens"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Scott Martens" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Abstract cityscape illustration with orange, grey and white buildings, featuring visible balconies with a potted plant."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Abstract cityscape illustration with orange, grey and white buildings, featuring visible balconies with a potted plant." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></a><a data-v-aa70018b="" data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/text-image-global-contrastive-alignment-and-token-patch-local-alignment"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">январь 07, 2025 • 6 минуты чтения</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Text-Image Global Contrastive Alignment and Token-Patch Local Alignment</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="3D rendered scene with a black-screened laptop on a geometrical pedestal and patterned spheres, against a blue backdrop."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="3D rendered scene with a black-screened laptop on a geometrical pedestal and patterned spheres, against a blue backdrop." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/banner--16-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa70018b="" data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/text-embeddings-fail-to-capture-word-order-and-how-to-fix-it"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">декабрь 17, 2024 • 12 минуты чтения</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Text Embeddings Fail to Capture Word Order and How to Fix It</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Bo Wang"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Bo Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Three abstract figures in white, gray, and pink on matching cubes placed on a colorful checkered surface against a green back"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Three abstract figures in white, gray, and pink on matching cubes placed on a colorful checkered surface against a green back" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/banner-order.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Офисы</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Саннивейл, Калифорния</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Саннивейл, Калифорния 94085, США</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Берлин, Германия (штаб-квартира)</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Берлин, Германия</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Пекин, Китай</div><div class="q-item__label q-item__label--caption text-caption text-dim">Уровень 5, здание 6, ул. Хайдянь Вест, д. 48, Пекин, Китай</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Шэньчжэнь, Китай</div><div class="q-item__label q-item__label--caption text-caption text-dim">402, этаж 4, здание Fu'an Technology, Шэньчжэнь, Китай</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Поиск Фонда</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Читатель</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Вложения</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Реранкер</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Классификатор</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Сегментатор</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">API-документация</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Получить API-ключ Jina</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Ограничение скорости</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">Статус API</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Компания</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">О нас</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Связаться с отделом продаж</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">отдел новостей</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Стажерская программа</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Присоединяйтесь к нам</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Скачать логотип</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Условия</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Безопасность</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Условия использования</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Конфиденциальность</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Управление файлами cookie</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>