<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Jina AI]]></title><description><![CDATA[The official newsroom of Jina AI]]></description><link>https://jina.ai/news</link><image><url>https://jina.ai/favicon.ico</url><title>Jina AI</title><link>https://jina.ai/news</link></image><generator>Ghost 5.82</generator><lastBuildDate>Tue, 23 Apr 2024 06:57:31 GMT</lastBuildDate><atom:link href="https://jina.ai/feed.rss" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny]]></title><description><![CDATA[Jina AI announces new reranker models: Jina Rerankers Turbo (jina-reranker-v1-turbo-en) and Tiny (jina-reranker-v1-tiny-en), now available on AWS Sagemaker and Hugging Face, offering faster, memory-efficient, high-performance reranking.]]></description><link>https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny/</link><guid isPermaLink="false">662109d27f510100015da961</guid><category><![CDATA[Press]]></category><dc:creator><![CDATA[Yuting Zhang]]></dc:creator><pubDate>Thu, 18 Apr 2024 14:00:26 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/04/00024-1729583850.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/00024-1729583850.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"><p>Jina AI is announcing new models in its <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io">family of state-of-the-art reranker models</a>, now available on AWS Sagemaker and Hugging Face: <a href="https://huggingface.co/jinaai/jina-reranker-v1-turbo-en?ref=jina-ai-gmbh.ghost.io"><code>jina-reranker-v1-turbo-en</code></a> and <a href="https://huggingface.co/jinaai/jina-reranker-v1-tiny-en?ref=jina-ai-gmbh.ghost.io"><code>jina-reranker-v1-tiny-en</code></a>. These models prioritize speed and size while maintaining high performance on standard benchmarks, offering a faster and more memory-efficient reranking process for environments where response time and resource use are critical.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Marketplace: Jina AI</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-reranker-v1-turbo-en?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-reranker-v1-turbo-en &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-reranker-v1-turbo-en.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-reranker-v1-tiny-en?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-reranker-v1-tiny-en &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-reranker-v1-tiny-en.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><p>Reranker Turbo and Tiny are optimized for blazing-fast response times in information retrieval applications. Like our embedding models, they use the <a href="https://jina.ai/news/jina-embeddings-2-the-best-solution-for-embedding-long-documents/?ref=jina-ai-gmbh.ghost.io">JinaBERT architecture</a>, a variant of the BERT architecture enhanced with a <a href="https://arxiv.org/abs/2310.19923v3?ref=jina-ai-gmbh.ghost.io">symmetric bidirectional variant of ALiBi</a>. This architecture enables support for long text sequences, with our models accepting up to 8,192 tokens, ideal for deep analysis of larger documents and complex queries requiring detailed language understanding.</p><p>The Turbo and Tiny models draw on insights gained from <a href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker/?ref=jina-ai-gmbh.ghost.io">Jina Reranker v1</a>. Reranking can be a major bottleneck for information retrieval applications. Traditional search applications are a very mature technology whose performance is well-understood. Rerankers add a great deal of precision to text-based retrieval, but AI models are large and can be slow and expensive to run.</p><p>Many users would prefer a smaller, faster, cheaper model, even if it comes at some cost to accuracy. Having a single goal &#x2013; reranking search results &#x2013; makes it possible to streamline the model and bring users competitive performance in much more compact models. <strong>By using fewer hidden layers, we speed up processing and reduce model size. </strong>These models cost less to run, and the greater speed makes them more useful for applications that can&apos;t tolerate much latency, while retaining nearly all of the performance of larger models.</p><p>In this article, we&apos;ll show you the architecture of Reranker Turbo and Reranker Tiny, measure its performance, and show you how to get started with them.</p><h2 id="streamlined-architecture">Streamlined Architecture</h2><p>Jine Reranker Turbo (<code>jina-reranker-v1-turbo-en</code>) uses a <strong>six-layer architecture, with a total of 37.8 million parameters</strong>, in contrast to the 137 million parameters and twelve layers of the base reranker model <code>jina-reranker-v1-base-en</code>. This represents a reduction in model size of three-quarters and as much as a tripling of processing speed.</p><p>Reranker Tiny (<code>jina-reranker-v1-tiny-en</code>) uses <strong>four layers with 33 million parameters</strong>, providing even greater parallel processing and faster speeds &#x2013; almost five times as fast as the base Reranker model &#x2013; while saving 13% of memory costs over the Turbo model.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/barchart_1.png" class="kg-image" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny" loading="lazy" width="1102" height="675" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/04/barchart_1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/04/barchart_1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/04/barchart_1.png 1102w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Document throughput for Jina Reranker models</span></figcaption></figure><h2 id="knowledge-distillation">Knowledge Distillation</h2><p>We&apos;ve trained Reranker Turbo and Tiny using <a href="https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones/?ref=jina-ai-gmbh.ghost.io">knowledge distillation</a>. This is a technique for using an existing AI model to train another one to match its behavior. Instead of using external data sources, we use an existing model to generate data for training. We used the Jina Reranker base model to rank collections of documents and then used those results to train both Turbo and Tiny. This way, we can bring much more data into the training process because we aren&apos;t limited by available real-world data.</p><p>This is a bit like a student learning from a teacher: The already trained, high-performance model &#x2013; the Jina Reranker Base model &#x2013; &quot;teaches&quot; the untrained Jina Turbo and Jina Tiny models by generating new training data. This technique is widely used to create small models from large ones. At its best, the difference in task performance between the &quot;teacher&quot; model and the &quot;student&quot; can be very small.</p><h2 id="evaluation-on-beir">Evaluation on BEIR</h2><p>The benefits of streamlining and knowledge distillation come at relatively little cost to performance quality. On the <a href="https://github.com/beir-cellar/beir?ref=jina-ai-gmbh.ghost.io">BEIR benchmark</a> for information retrieval, <code>jina-reranker-v1-turbo-en</code> scores just under 95% of the accuracy of <code>jina-reranker-v1-base-en</code>, and <code>jina-reranker-v1-tiny-en</code> scores 92.5% of the base model&apos;s score.</p><p>All Jina Reranker models are competitive with other popular reranker models, most of which have much larger sizes.</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th>Model</th>
<th>BEIR Score (NDCC@10)</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Jina Reranker models</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>jina-reranker-v1-base-en</code></td>
<td>52.45</td>
<td>137M</td>
</tr>
<tr>
<td><code>jina-reranker-v1-turbo-en</code></td>
<td>49.60</td>
<td>38M</td>
</tr>
<tr>
<td><code>jina-reranker-v1-tiny-en</code></td>
<td>48.54</td>
<td>33M</td>
</tr>
<tr>
<td><strong>Other reranking models</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>mxbai-rerank-base-v1</code></td>
<td>49.19</td>
<td>184M</td>
</tr>
<tr>
<td><code>mxbai-rerank-xsmall-v1</code></td>
<td>48.80</td>
<td>71M</td>
</tr>
<tr>
<td><code>ms-marco-MiniLM-L-6-v2</code></td>
<td>48.64</td>
<td>23M</td>
</tr>
<tr>
<td><code>bge-reranker-base</code></td>
<td>47.89</td>
<td>278M</td>
</tr>
<tr>
<td><code>ms-marco-MiniLM-L-4-v2</code></td>
<td>47.81</td>
<td>19M</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<p><em>NDCC@10</em>: Scores calculated using <a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain?ref=jina-ai-gmbh.ghost.io">Normalized Discounted Cumulative Gain</a> for the top 10 results.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/beir_graph.png" class="kg-image" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny" loading="lazy" width="1292" height="753" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/04/beir_graph.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/04/beir_graph.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/04/beir_graph.png 1292w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">BEIR Benchmark: Throughput (x-axis) vs Score (y-axis)</span><i><em class="italic" style="white-space: pre-wrap;">(Note that the y-axis is not on the origin. We start with a higher BIER score value to enhance the readability of the graph.)</em></i></figcaption></figure><p>Only <a href="https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2?ref=jina-ai-gmbh.ghost.io">MiniLM-L6</a> (<code>ms-marco-MiniLM-L-6-v2</code>) and <a href="https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-4-v2?ref=jina-ai-gmbh.ghost.io">MiniLM-L4</a> (<code>ms-marco-MiniLM-L-4-v2</code>) have comparable sizes and speeds, with <code>jina-reranker-v1-turbo-en</code> and <code>jina-reranker-v1-tiny-en</code> performing comparably or significantly better.</p><p>We get similar results on the <a href="https://docs.llamaindex.ai/en/stable/examples/llama_dataset/labelled-rag-datasets/?ref=jina-ai-gmbh.ghost.io">LlamaIndex RAG Benchmark</a>. We tested all three Jina Rerankers in a RAG setup using three embedding models for vector search (<code>jina-embeddings-v2-base-en</code>, <code>bge-base-en-v1.5</code>, and <code>Cohere-embed-english-v3.0</code>) and averaged the scores.</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th>Reranker Model</th>
<th>Avg. Hit Rate</th>
<th>Avg. MRR</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Jina Reranker models</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>jina-reranker-v1-base-en</code></td>
<td>0.8439</td>
<td>0.7006</td>
</tr>
<tr>
<td><code>jina-reranker-v1-turbo-en</code></td>
<td>0.8351</td>
<td>0.6498</td>
</tr>
<tr>
<td><code>jina-reranker-v1-tiny-en</code></td>
<td>0.8316</td>
<td>0.6761</td>
</tr>
<tr>
<td><strong>Other reranking models</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>mxbai-rerank-base-v1</code></td>
<td>0.8105</td>
<td>0.6583</td>
</tr>
<tr>
<td><code>mxbai-rerank-xsmall-v1</code></td>
<td>0.8193</td>
<td>0.6673</td>
</tr>
<tr>
<td><code>ms-marco-MiniLM-L-6-v2</code></td>
<td>0.8052</td>
<td>0.6121</td>
</tr>
<tr>
<td><code>bge-reranker-base</code></td>
<td>0.8175</td>
<td>0.6480</td>
</tr>
<tr>
<td><code>ms-marco-MiniLM-L-4-v2</code></td>
<td>0.8246</td>
<td>0.6354</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<p><em>MRR</em>: <a href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank?ref=jina-ai-gmbh.ghost.io">Mean Reciprocal Rank</a></p><p>For retrieval-augmented generation (RAG) tasks, losses in result quality are even less than on the BEIR pure information retrieval benchmark. And when RAG performance is put up next to processing speed, we see that only <code>ms-marco-MiniLM-L-4-v2</code> provides significantly more throughput, at a significant cost in result quality.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/LlRag_graph.png" class="kg-image" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny" loading="lazy" width="1291" height="753" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/04/LlRag_graph.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/04/LlRag_graph.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/04/LlRag_graph.png 1291w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">LlamaIndex RAG Benchmark: Throughput (x-axis) vs Hit Rate (y-axis)</span><i><em class="italic" style="white-space: pre-wrap;">(Note that the y-axis is not on the origin. We start with a higher hit rate value to enhance the readability of the graph.)</em></i></figcaption></figure><h2 id="cost-savings-on-aws">Cost Savings on AWS</h2><p>Using Reranker Turbo and Reranker Tiny provides large savings for AWS and Azure users who pay for memory usage and CPU time. Although the degree of savings varies for different use cases, the roughly 75% reduction in memory usage alone directly corresponds to a 75% savings for cloud systems charging for memory.</p><p>Furthermore, the faster throughput means that you can run more queries on cheaper AWS instances.</p><h2 id="getting-started">Getting Started</h2><p>Jina Reranker models are easy to use and integrate into your applications and workflow. To get started, you can visit the <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io">Reranker API page</a> to see how to use our service and get 1 million free tokens of access to try it out yourself.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Reranker API</div><div class="kg-bookmark-description">Maximize the search relevancy and RAG accuracy at ease</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner-reranker-api.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><p>Our models are also <a href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io">available in AWS SageMaker</a>. For more information, see our <a href="https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker?ref=jina-ai-gmbh.ghost.io">tutorial on how to set up a retrieval-augmented generation system in AWS</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Marketplace: Jina AI</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Next-Level Cloud AI: Jina Embeddings and Rerankers on Amazon SageMaker</div><div class="kg-bookmark-description">Learn to use Jina Embeddings and Reranking models in a full-stack AI application on AWS, using only components available in Amazon SageMaker and the AWS Marketplace.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"><span class="kg-bookmark-publisher">Signup</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Blog-images--27-.jpg" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><p>Jina Reranker models are also available for download under the <a href="https://www.apache.org/licenses/LICENSE-2.0?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Apache 2.0 license</a> from Hugging Face:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-reranker-v1-turbo-en?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-reranker-v1-turbo-en &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-reranker-v1-turbo-en.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-reranker-v1-tiny-en?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-reranker-v1-tiny-en &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-reranker-v1-tiny-en.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><h2 id="contact-us">Contact Us</h2><p>Jina AI remains committed to bringing the highest quality models to enterprises at competitive prices. Reranker Turbo and Tiny bring state-of-the-art AI to cloud-based information retrieval applications at a large reduction in cost. When every gigabyte of memory and processing instance counts, we&apos;re here to help you stretch your cloud computing budget.</p><p>Contact us via&#xA0;our website&#xA0;or&#xA0;our Discord channel&#xA0;to share your feedback and stay up-to-date with our latest models.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI - Your Search Foundation, Supercharged.</div><div class="kg-bookmark-description">Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"><span class="kg-bookmark-author">Your Search Foundation, Supercharged.</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner.png" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4895 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://static.ghost.org/v5.0.0/images/link-icon.svg" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Smaller, Faster, Cheaper: Jina Rerankers Turbo and Tiny"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Enhancing Search Results with Jina AI's Reranker API in MyScale]]></title><description><![CDATA[With full integration of Jina Reranker, you can now bring Jina AI's state-of-the-art technology to SQL retrieval.]]></description><link>https://jina.ai/news/enhancing-search-results-with-jina-ais-reranker-api-in-myscale/</link><guid isPermaLink="false">661e5cf7797dcd00012e7de0</guid><category><![CDATA[Knowledge Base]]></category><dc:creator><![CDATA[Scott Martens]]></dc:creator><pubDate>Tue, 16 Apr 2024 14:19:47 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/04/MyScaleBlog2.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/MyScaleBlog2.png" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"><p><a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Jina Reranker API</a> is now fully integrated into <a href="https://myscale.com/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">MyScale</a>&apos;s AI-focused SQL vector database. Jina AI&apos;s state-of-the-art reranking models dramatically improve the precision of SQL query results. With MyScale, Jina Reranker is an easy, drop-in solution to bring the power of modern AI to your SQL, combining traditional database management with the intelligence and context-awareness of semantic similarity.</p><p>Follow the link below to&#xA0;MyScale&apos;s website to see how to use Jina Reranker in your SQL databases.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://myscale.com/blog/enhancing-search-results-with-jina-ai-reranker-api-in-myscale/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Enhancing Search Results with Jina AI&#x2019;s Reranker API in MyScale</div><div class="kg-bookmark-description">This article describes how to use Jina AI&#x2019;s Reranker in MyScale.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://myscale.com/favicon.ico" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"></div></div><div class="kg-bookmark-thumbnail"><img src="https://d3lhz231q7ogjd.cloudfront.net/blog/myscale-jina-reranker.jpg" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"></div></a></figure><p>Auch auf Deutsch verf&#xFC;gbar:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://myscale.com/blog/de/enhancing-search-results-with-jina-ai-reranker-api-in-myscale/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Verbesserung der Suchergebnisse mit Jina AI&#x2019;s Reranker API in MyScale</div><div class="kg-bookmark-description">Dieser Artikel beschreibt, wie man Jina AI&#x2019;s Reranker in MyScale verwendet.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://myscale.com/favicon.ico" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"></div></div><div class="kg-bookmark-thumbnail"><img src="https://d3lhz231q7ogjd.cloudfront.net/blog/myscale-jina-reranker.jpg" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"></div></a></figure><p>Jina AI is committed to making state-of-the-art AI available and accessible to enterprises. Contact us via&#xA0;<a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">our website</a>&#xA0;or&#xA0;<a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io">our Discord channel</a>&#xA0;to share your feedback and stay up-to-date with our latest models.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI - Your Search Foundation, Supercharged.</div><div class="kg-bookmark-description">Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"><span class="kg-bookmark-author">Your Search Foundation, Supercharged.</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner.png" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4864 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://static.ghost.org/v5.0.0/images/link-icon.svg" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Enhancing Search Results with Jina AI&apos;s Reranker API in MyScale"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Jina 3.25.1 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-25-1-update/</link><guid isPermaLink="false">6617e163797dcd00012e7daf</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Thu, 11 Apr 2024 13:13:59 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/04/Image-Jina-dark-1.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3251">Release Note (<code>3.25.1</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/Image-Jina-dark-1.jpg" alt="Jina 3.25.1 Update"><p>This release contains 1 bug fix.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.25.1?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Patch v3.25.1 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.25.1) Release time: 2024-04-10 14:39:02 This release contains 1 bug fix.
&#x1F41E; Bug Fixes
Fix input schema with --provider Azure (#6163)
When using --provider Azure, there was an error&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="Jina 3.25.1 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/a55ca9f3079deb944900044ed3fec1076108b22625ecf16212508f842d6a3437/jina-ai/jina/releases/tag/v3.25.1" alt="Jina 3.25.1 Update"></div></a></figure><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-input-schema-withprovider-azure-6163">Fix input schema with&#xA0;<code>--provider</code>&#xA0;Azure (<a href="https://github.com/jina-ai/jina/pull/6163?ref=jina-ai-gmbh.ghost.io">#6163</a>)</h3><p>When using&#xA0;<code>--provider</code>&#xA0;Azure, there was an error when using the input schema of an incorrect endpoint.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a>)</li></ul>]]></content:encoded></item><item><title><![CDATA[Retrieve Jira Tickets with Jina Reranker and Haystack 2.0]]></title><description><![CDATA[Learn how to use Jina Reranker and Embeddings with Haystack to create your own Jira ticket search engine, streamlining your operations and never again waste time creating duplicate issues.]]></description><link>https://jina.ai/news/retrieve-jira-tickets-with-jina-reranker-and-haystack-20/</link><guid isPermaLink="false">661543ffd6a1020001681e99</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Francesco Kruk]]></dc:creator><pubDate>Wed, 10 Apr 2024 14:00:49 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/04/Reranker-Haystack.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/Reranker-Haystack.jpg" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"><p>Following the <a href="https://haystack.deepset.ai/blog/using-jina-embeddings-haystack?ref=jina-ai-gmbh.ghost.io">integration of Jina Embeddings into Deepset&apos;s Haystack 2.0</a> and the <a href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io">release of Jina Reranker</a>, we&apos;re thrilled to announce that Jina Reranker is now also available through the <a href="https://docs.haystack.deepset.ai/docs/jinaranker?ref=jina-ai-gmbh.ghost.io">Jina Haystack extension</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://haystack.deepset.ai/integrations/jina?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI | Haystack</div><div class="kg-bookmark-description">Use the latest Jina AI embedding models</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://haystack.deepset.ai/favicon.ico" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"><span class="kg-bookmark-author">Haystack</span><span class="kg-bookmark-publisher">Authors deepset</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://haystack.deepset.ai/images/haystack-ogimage.png" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Reranker API</div><div class="kg-bookmark-description">Maximize the search relevancy and RAG accuracy at ease</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner-reranker-api.png" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"></div></a></figure><p><a href="https://haystack.deepset.ai/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Haystack</a> is an end-to-end framework that accompanies you in every step of the GenAI project life cycle. Whether you want to perform document search, retrieval-augmented generation (RAG), question answering, or answer generation, Haystack can orchestrate state-of-the-art embedding models and LLMs into pipelines to build end-to-end NLP applications and solve your use case.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://haystack.deepset.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Haystack | Haystack</div><div class="kg-bookmark-description">Haystack, the composable open-source AI framework</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://haystack.deepset.ai/favicon.ico" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"><span class="kg-bookmark-author">Haystack</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://haystack.deepset.ai/images/haystack-ogimage.png" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"></div></a></figure><p>In this post, we&apos;ll show how to use them to create your own Jira ticket search engine to streamline your operations and never again waste time creating duplicate issues.</p><p>To follow this tutorial, you&apos;ll need a Jina Reranker API key. You can create one with a free trial quota of a million tokens from the <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io">Jina Reranker website</a>.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">You can follow along in <a href="https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/haystack/Haystack_Reranker.ipynb?ref=jina-ai-gmbh.ghost.io">Colab</a> or by <a href="https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/haystack/Haystack_Reranker.ipynb?ref=jina-ai-gmbh.ghost.io">downloading the notebook</a>.</div></div><h2 id="retrieving-jira-support-tickets">Retrieving Jira Support Tickets</h2><p>Any team dealing with a complex project has experienced the frustration of having an issue they want to file but not knowing if a ticket already exists for this problem.</p><p>In the following tutorial, we&apos;ll show you how you can easily create a tool yourself using Jina Reranker and Haystack pipelines, which suggests possible duplicate tickets to a new one being created.</p><ul><li>By inputting a ticket that needs to be checked against all existing tickets, the pipeline will first retrieve from the database all related issues.</li><li>It&apos;ll then remove the initial ticket from the list (if it already existed in the database) and any child ticket (i.e. tickets whose parent ID corresponds to the original ticket).</li><li>The final selection now only comprises issues that might cover the same topic as the original ticket but were not marked as such in the database through their IDs. These tickets are reranked to ensure maximal relevance and enable you to identify duplicate entries in the database.</li></ul><h3 id="getting-the-dataset">Getting the Dataset</h3><p>To implement our solution, we&apos;ve chosen all &quot;In-progress&quot; Jira tickets for the <a href="https://zookeeper.apache.org/?ref=jina-ai-gmbh.ghost.io">Apache Zookeeper</a> project. This is an open-source service for coordinating processes of distributed applications.</p><p>We have placed the tickets in a <a href="https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/haystack/tickets.json?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">JSON file</a> to make them more convenient. Please <a href="https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/haystack/tickets.json?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">download the file</a> to your workspace.</p><h3 id="set-up-the-prerequisites">Set up the Prerequisites</h3><p>To install the requirements, run:</p><pre><code class="language-Bash">pip install --q chromadb haystack-ai jina-haystack chroma-haystack
</code></pre><p>To input the API key, set it as an environment variable:</p><pre><code class="language-Python">import os
import getpass

os.environ[&quot;JINA_API_KEY&quot;] = getpass.getpass()
</code></pre><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">If you&apos;re running this code through the notebook, <code spellcheck="false" style="white-space: pre-wrap;">getpass.getpass()</code> will prompt you to input the API key below the corresponding code block. You can enter the key there and press enter to resume the tutorial. If you prefer, you can also substitute <code spellcheck="false" style="white-space: pre-wrap;">getpass.getpass()</code> with the API key itself.</div></div><h3 id="build-the-indexing-pipeline">Build the Indexing Pipeline</h3><p>The indexing pipeline will preprocess the tickets, turn them into vectors, and store them. We&#x2019;ll use the <a href="https://docs.trychroma.com/getting-started?ref=jina-ai-gmbh.ghost.io">Chroma DocumentStore</a> as our vector database to store the vector embeddings, via the <a href="https://haystack.deepset.ai/integrations/chroma-documentstore?ref=jina-ai-gmbh.ghost.io">Chroma Document Store Haystack integration</a>.</p><pre><code class="language-Python">from haystack_integrations.document_stores.chroma import ChromaDocumentStore

document_store = ChromaDocumentStore()
</code></pre><p>We&apos;ll start by defining our custom data preprocessor to only consider relevant document fields and delete all empty entries:</p><pre><code class="language-Python">import json
from typing import List
from haystack import Document, component

relevant_keys = [&apos;Summary&apos;, &apos;Issue key&apos;, &apos;Issue id&apos;, &apos;Parent id&apos;, &apos;Issue type&apos;, &apos;Status&apos;, &apos;Project lead&apos;, &apos;Priority&apos;, &apos;Assignee&apos;, &apos;Reporter&apos;, &apos;Creator&apos;, &apos;Created&apos;, &apos;Updated&apos;, &apos;Last Viewed&apos;, &apos;Due Date&apos;, &apos;Labels&apos;,
                 &apos;Description&apos;, &apos;Comment&apos;, &apos;Comment__1&apos;, &apos;Comment__2&apos;, &apos;Comment__3&apos;, &apos;Comment__4&apos;, &apos;Comment__5&apos;, &apos;Comment__6&apos;, &apos;Comment__7&apos;, &apos;Comment__8&apos;, &apos;Comment__9&apos;, &apos;Comment__10&apos;, &apos;Comment__11&apos;, &apos;Comment__12&apos;,
                 &apos;Comment__13&apos;, &apos;Comment__14&apos;, &apos;Comment__15&apos;]

@component
class RemoveKeys:
    @component.output_types(documents=List[Document])
    def run(self, file_name: str):
        with open(file_name, &apos;r&apos;) as file:
            tickets = json.load(file)
        cleaned_tickets = []
        for t in tickets:
            t = {k: v for k, v in t.items() if k in relevant_keys and v}
            cleaned_tickets.append(t)
        return {&apos;documents&apos;: cleaned_tickets}
</code></pre><p>We then need to create a custom JSON converter to transform the tickets into Document objects Haystack can understand:</p><pre><code class="language-Python">@component
class JsonConverter:
    @component.output_types(documents=List[Document])
    def run(self, tickets: List[Document]):
        tickets_documents = []
        for t in tickets:
            if &apos;Parent id&apos; in t:
                t = Document(content=json.dumps(t), meta={&apos;Issue key&apos;: t[&apos;Issue key&apos;], &apos;Issue id&apos;: t[&apos;Issue id&apos;], &apos;Parent id&apos;: t[&apos;Parent id&apos;]})
            else:
                t = Document(content=json.dumps(t), meta={&apos;Issue key&apos;: t[&apos;Issue key&apos;], &apos;Issue id&apos;: t[&apos;Issue id&apos;], &apos;Parent id&apos;: &apos;&apos;})
            tickets_documents.append(t)
        return {&apos;documents&apos;: tickets_documents}
</code></pre><p>Finally, we embed the Documents and write these embeddings into the ChromaDocumentStore:</p><pre><code class="language-Python">from haystack import Pipeline

from haystack.components.writers import DocumentWriter
from haystack_integrations.components.retrievers.chroma import ChromaEmbeddingRetriever
from haystack.document_stores.types import DuplicatePolicy

from haystack_integrations.components.embedders.jina import JinaDocumentEmbedder

retriever = ChromaEmbeddingRetriever(document_store=document_store)
retriever_reranker = ChromaEmbeddingRetriever(document_store=document_store)

indexing_pipeline = Pipeline()
indexing_pipeline.add_component(&apos;cleaner&apos;, RemoveKeys())
indexing_pipeline.add_component(&apos;converter&apos;, JsonConverter())
indexing_pipeline.add_component(&apos;embedder&apos;, JinaDocumentEmbedder(model=&apos;jina-embeddings-v2-base-en&apos;))
indexing_pipeline.add_component(&apos;writer&apos;, DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP))

indexing_pipeline.connect(&apos;cleaner&apos;, &apos;converter&apos;)
indexing_pipeline.connect(&apos;converter&apos;, &apos;embedder&apos;)
indexing_pipeline.connect(&apos;embedder&apos;, &apos;writer&apos;)

indexing_pipeline.run({&apos;cleaner&apos;: {&apos;file_name&apos;: &apos;tickets.json&apos;}})
</code></pre><p>This should create a progress bar and output a brief JSON containing information about what&apos;s been stored:</p><pre><code class="language-Text">Calculating embeddings: 100%|&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;| 1/1 [00:01&lt;00:00,  1.21s/it]
{&apos;embedder&apos;: {&apos;meta&apos;: {&apos;model&apos;: &apos;jina-embeddings-v2-base-en&apos;,
   &apos;usage&apos;: {&apos;total_tokens&apos;: 20067, &apos;prompt_tokens&apos;: 20067}}},
 &apos;writer&apos;: {&apos;documents_written&apos;: 31}}</code></pre><h3 id="build-the-query-pipeline">Build the Query Pipeline</h3><p>Let&#x2019;s create a query pipeline so we can start comparing tickets. In Haystack 2.0 retrievers are tightly coupled to DocumentStores. If we pass the document store in the retriever we initialized earlier, this pipeline can access the documents we generated, and pass them to the reranker. The reranker then compares these documents directly with the question and ranks them based on relevance.</p><p>We first define the custom cleaner to remove retrieve tickets that contain either the same issue ID or parent ID as the issue passed as query:</p><pre><code class="language-Python">from typing import Optional

@component
class RemoveRelated:
    @component.output_types(documents=List[Document])
    def run(self, tickets: List[Document], query_id: Optional[str]):
        retrieved_tickets = []
        for t in tickets:
            if not t.meta[&apos;Issue id&apos;] == query_id and not t.meta[&apos;Parent id&apos;] == query_id:
                retrieved_tickets.append(t)
        return {&apos;documents&apos;: retrieved_tickets}
</code></pre><p>We then embed the query, retrieve relevant documents, clean the selection, and finally rerank it:</p><pre><code class="language-Python">from haystack_integrations.components.embedders.jina import JinaTextEmbedder
from haystack_integrations.components.rankers.jina import JinaRanker

query_pipeline_reranker = Pipeline()
query_pipeline_reranker.add_component(&apos;query_embedder_reranker&apos;, JinaTextEmbedder(model=&apos;jina-embeddings-v2-base-en&apos;))
query_pipeline_reranker.add_component(&apos;query_retriever_reranker&apos;, retriever_reranker)
query_pipeline_reranker.add_component(&apos;query_cleaner_reranker&apos;, RemoveRelated())
query_pipeline_reranker.add_component(&apos;query_ranker_reranker&apos;, JinaRanker())

query_pipeline_reranker.connect(&apos;query_embedder_reranker.embedding&apos;, &apos;query_retriever_reranker.query_embedding&apos;)
query_pipeline_reranker.connect(&apos;query_retriever_reranker&apos;, &apos;query_cleaner_reranker&apos;)
query_pipeline_reranker.connect(&apos;query_cleaner_reranker&apos;, &apos;query_ranker_reranker&apos;)
</code></pre><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/upload_916b6073b69f880f765730833bcdfbe3.png" class="kg-image" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0" loading="lazy" width="510" height="972"></figure><p>To highlight the difference caused by the reranker, we analyzed the same pipeline without the final reranking step (the corresponding code was omitted in this post for the sake of readability but can be found in the notebook):</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/upload_d16f493c35c403b55f7c420c11c1f998.png" class="kg-image" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0" loading="lazy" width="572" height="984"></figure><p>To compare the results of these two pipelines, we now define our query in the form of an existing ticket, here &quot;ZOOKEEPER-3282&quot;:</p><pre><code class="language-Python">query_ticket_key = &apos;ZOOKEEPER-3282&apos;

with open(&apos;tickets.json&apos;, &apos;r&apos;) as file:
    tickets = json.load(file)

for ticket in tickets:
    if ticket[&apos;Issue key&apos;] == query_ticket_key:
        query = str(ticket)
        query_ticket_id = ticket[&apos;Issue id&apos;]
</code></pre><p>It concerns &quot;a big refactor for the documetations&quot; [<a href="https://en.wikipedia.org/wiki/Sic?ref=jina-ai-gmbh.ghost.io" rel="noreferrer"><em>sic</em></a>]. You&apos;ll see that, despite the misspelling, Jina Reranker will correctly retrieve similar tickets.</p><pre><code class="language-JSON">{
    &quot;Summary&quot;: &quot;a big refactor for the documetations&quot;
    &quot;Issue key&quot;: &quot;ZOOKEEPER-3282&quot;
    &quot;Issue id:: 13216608
    &quot;Parent id&quot;: &quot;&quot;
    &quot;Issue Type&quot;: &quot;Task&quot;
    &quot;Status&quot;: &quot;In Progress&quot;
    &quot;Project lead&quot;: &quot;phunt&quot;
    &quot;Priority&quot;: &quot;Major&quot;
    &quot;Assignee&quot;: &quot;maoling&quot;
    &quot;Reporter&quot;: &quot;maoling&quot;
    &quot;Creator&quot;: &quot;maoling&quot;
    &quot;Created&quot;: &quot;19/Feb/19 11:50&quot;
    &quot;Updated&quot;: &quot;04/Aug/19 12:48&quot;
    &quot;Last Viewed&quot;: &quot;12/Mar/24 11:56&quot;
    &quot;Description&quot;: &quot;Hi guys: I&apos;am working on doing a big refactor for the documetations.it aims to - 1.make a better reading experiences and help users know more about zookeeper quickly,as good as other projects&apos; doc(e.g redis,hbase). - 2.have less changes to diff with the original docs as far as possible. - 3.solve the problem when we have some new features or improvements,but cannot find a good place to doc it.   The new catalog may looks kile this: * is new one added. ** is the one to keep unchanged as far as possible. *** is the one modified. -------------------------------------------------------------- |---Overview    |---Welcome ** [1.1]    |---Overview ** [1.2]    |---Getting Started ** [1.3]    |---Release Notes ** [1.4] |---Developer    |---API *** [2.1]    |---Programmer&apos;s Guide ** [2.2]    |---Recipes *** [2.3]    |---Clients * [2.4]    |---Use Cases * [2.5] |---Admin &amp; Ops    |---Administrator&apos;s Guide ** [3.1]    |---Quota Guide ** [3.2]    |---JMX ** [3.3]    |---Observers Guide ** [3.4]    |---Dynamic Reconfiguration ** [3.5]    |---Zookeeper CLI * [3.6]    |---Shell * [3.7]    |---Configuration flags * [3.8]    |---Troubleshooting &amp; Tuning  * [3.9] |---Contributor Guidelines    |---General Guidelines * [4.1]    |---ZooKeeper Internals ** [4.2] |---Miscellaneous    |---Wiki ** [5.1]    |---Mailing Lists ** [5.2] -------------------------------------------------------------- The Roadmap is: 1.(I pick up it : D)  1.1 write API[2.1], which includes the&#xFF1A;    1.1.1  original API Docs which is a Auto-generated java doc,just give a link.    1.1.2. Restful-api (the apis under the /zookeeper-contrib-rest/src/main/java/org/apache/zookeeper/server/jersey/resources)  1.2 write Clients[2.4], which includes the:      1.2.1 C client      1.2.2 zk-python, kazoo      1.2.3 Curator etc.......      look at an example from: https://redis.io/clients # write Recipes[2.3], which includes the:  - integrate &quot;Java Example&quot; and &quot;Barrier and Queue Tutorial&quot;(Since some bugs in the examples and they are obsolete&#xFF0C;we may delete something) into it.  - suggest users to use the recipes implements of Curator and link to the Curator&apos;s recipes doc.   # write Zookeeper CLI[3.6], which includes the:  - about how to use the zk command line interface [./zkCli.sh]    e.g ls /; get ; rmr;create -e -p etc.......  - look at an example from redis: https://redis.io/topics/rediscli   # write shell[3.7], which includes the:   - list all usages of the shells under the zookeeper/bin. (e.g zkTxnLogToolkit.sh,zkCleanup.sh)   # write Configuration flags[3.8], which includes the:   - list all usages of configurations properties(e.g zookeeper.snapCount):   - move the original Advanced Configuration part of zookeeperAdmin.md into it.     look at an example from:https://coreos.com/etcd/docs/latest/op-guide/configuration.html    # write Troubleshooting &amp; Tuning[3.9], which includes the:   - move the original &quot;Gotchas: Common Problems and Troubleshooting&quot; part of Administrator&apos;s Guide.md into it.   - move the original &quot;FAQ&quot; into into it.   - add some new contents &#xFF08;e.g https://www.yumpu.com/en/document/read/29574266/building-an-impenetrable-zookeeper-pdf-github&#xFF09;.   look at an example from:https://redis.io/topics/problems                             https://coreos.com/etcd/docs/latest/tuning.html   # write General Guidelines[4.1], which includes the:  - move the original &quot;Logging&quot; part of ZooKeeper Internals into it as the logger specification.  - write specifications about code, git commit messages,github PR  etc ...    look at an example from:    http://hbase.apache.org/book.html#hbase.commit.msg.format   # write Use Cases[2.5], which includes the:  - just move the context from: https://cwiki.apache.org/confluence/display/ZOOKEEPER/PoweredBy into it.  - add some new contents.(e.g Apache Projects:Spark;Companies:twitter,fb)   -------------------------------------------------------------- BTW: - Any insights or suggestions are very welcomed.After the dicussions,I will create a series of tickets(An umbrella) - Since these works can be done parallelly, if you are interested in them, please don&apos;t hesitate,just assign to yourself, pick it up. (Notice: give me a ping to avoid the duplicated work).&quot;
}
</code></pre><p>Finally, we run the query pipeline. In this case, it retrieves 20 tickets, eliminates ID-related entries, reranks them, and outputs the final selection of the 10 most relevant issues.</p><p>Before the reranking step, the output includes 17 tickets:</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th>Rank</th>
<th>Issue ID</th>
<th>Issue Key</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>13191544</td>
<td>ZOOKEEPER-3170</td>
<td>Umbrella for eliminating ZooKeeper flaky tests</td>
</tr>
<tr>
<td>2</td>
<td>13400622</td>
<td>ZOOKEEPER-4375</td>
<td>Quota cannot limit the specify value when multiply clients create/set znodes</td>
</tr>
<tr>
<td>3</td>
<td>13249579</td>
<td>ZOOKEEPER-3499</td>
<td>[admin server way] Add a complete backup mechanism for zookeeper internal</td>
</tr>
<tr>
<td>4</td>
<td>13295073</td>
<td>ZOOKEEPER-3775</td>
<td>Wrong message in IOException</td>
</tr>
<tr>
<td>5</td>
<td>13268474</td>
<td>ZOOKEEPER-3617</td>
<td>ZK digest ACL permissions gets overridden</td>
</tr>
<tr>
<td>6</td>
<td>13296971</td>
<td>ZOOKEEPER-3787</td>
<td>Apply modernizer-maven-plugin to build</td>
</tr>
<tr>
<td>7</td>
<td>13265507</td>
<td>ZOOKEEPER-3600</td>
<td>support the complete linearizable read and multiply read consistency level</td>
</tr>
<tr>
<td>8</td>
<td>13222060</td>
<td>ZOOKEEPER-3318</td>
<td>[CLI way]Add a complete backup mechanism for zookeeper internal</td>
</tr>
<tr>
<td>9</td>
<td>13262989</td>
<td>ZOOKEEPER-3587</td>
<td>Add a documentation about docker</td>
</tr>
<tr>
<td>10</td>
<td>13262130</td>
<td>ZOOKEEPER-3578</td>
<td>Add a new CLI: multi</td>
</tr>
<tr>
<td>11</td>
<td>13262828</td>
<td>ZOOKEEPER-3585</td>
<td>Add a documentation about RequestProcessors</td>
</tr>
<tr>
<td>12</td>
<td>13262494</td>
<td>ZOOKEEPER-3583</td>
<td>Add new apis to get node type and ttl time info</td>
</tr>
<tr>
<td>13</td>
<td>12998876</td>
<td>ZOOKEEPER-2519</td>
<td>zh-&gt;state should not be 0 while handle is active</td>
</tr>
<tr>
<td>14</td>
<td>13536435</td>
<td>ZOOKEEPER-4696</td>
<td>Update for Zookeeper latest version</td>
</tr>
<tr>
<td>15</td>
<td>13297249</td>
<td>ZOOKEEPER-3789</td>
<td>fix the build warnings about @see,@link,@return found by IDEA</td>
</tr>
<tr>
<td>16</td>
<td>12728973</td>
<td>ZOOKEEPER-1983</td>
<td>Append to zookeeper.out (not overwrite) to support logrotation</td>
</tr>
<tr>
<td>17</td>
<td>12478629</td>
<td>ZOOKEEPER-915</td>
<td>Errors that happen during sync() processing at the leader do not get propagated back to the client.</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<p>After including the reranker, we now run the query pipeline:</p><pre><code class="language-Python">result = query_pipeline_reranker.run(data={&apos;query_embedder_reranker&apos;:{&apos;text&apos;: query},
                                  &apos;query_retriever_reranker&apos;: {&apos;top_k&apos;: 20},
                                  &apos;query_cleaner_reranker&apos;: {&apos;query_id&apos;: query_ticket_id},
                                  &apos;query_ranker_reranker&apos;: {&apos;query&apos;: query, &apos;top_k&apos;: 10}
                                  }
                            )

for idx, res in enumerate(result[&apos;query_ranker_reranker&apos;][&apos;documents&apos;]):
    print(&apos;Doc {}:&apos;.format(idx + 1), res)
</code></pre><p>The final output is the 10 most relevant tickets:</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th>Rank</th>
<th>Issue ID</th>
<th>Issue Key</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>13262989</td>
<td>ZOOKEEPER-3587</td>
<td>Add a documentation about docker</td>
</tr>
<tr>
<td>2</td>
<td>13265507</td>
<td>ZOOKEEPER-3600</td>
<td>support the complete linearizable read and multiply read consistency level</td>
</tr>
<tr>
<td>3</td>
<td>13249579</td>
<td>ZOOKEEPER-3499</td>
<td>[admin server way] Add a complete backup mechanism for zookeeper internal</td>
</tr>
<tr>
<td>4</td>
<td>12478629</td>
<td>ZOOKEEPER-915</td>
<td>Errors that happen during sync() processing at the leader do not get propagated back to the client.</td>
</tr>
<tr>
<td>5</td>
<td>13262828</td>
<td>ZOOKEEPER-3585</td>
<td>Add a documentation about RequestProcessors</td>
</tr>
<tr>
<td>6</td>
<td>13297249</td>
<td>ZOOKEEPER-3789</td>
<td>fix the build warnings about @see,@link,@return found by IDEA</td>
</tr>
<tr>
<td>7</td>
<td>12998876</td>
<td>ZOOKEEPER-2519</td>
<td>zh-&gt;state should not be 0 while handle is active</td>
</tr>
<tr>
<td>8</td>
<td>13536435</td>
<td>ZOOKEEPER-4696</td>
<td>Update for Zookeeper latest version</td>
</tr>
<tr>
<td>9</td>
<td>12728973</td>
<td>ZOOKEEPER-1983</td>
<td>Append to zookeeper.out (not overwrite) to support logrotation</td>
</tr>
<tr>
<td>10</td>
<td>13222060</td>
<td>ZOOKEEPER-3318</td>
<td>[CLI way]Add a complete backup mechanism for zookeeper internal</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<h2 id="advantages-of-jina-embeddings-and-reranker">Advantages of Jina Embeddings and Reranker</h2><p>To sum up this tutorial, we built a duplicate-ticket identification tool based on <a href="https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io">Jina Embeddings</a>, <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io">Jina Reranker</a> and <a href="https://haystack.deepset.ai/?ref=jina-ai-gmbh.ghost.io">Haystack 2.0</a>. The results above clearly show the necessity for both Jina Embeddings to retrieve relevant documents through vector search, and Jina Reranker to finally obtain the most relevant content.</p><p>If we take, for example, the two issues that relate to adding documentation, i.e. &quot;ZOOKEEPER-3585&quot; and &quot;ZOOKEEPER-3587&quot;, we see that after the retrieval step, they are both correctly included in positions 11 and 9 respectively. After reranking the documents, they are now both within the top 5 most relevant documents at positions 5 and 1 respectively, showing a significant improvement.</p><p>By integrating both models in Haystack&apos;s pipelines, the entire tool is ready for use. This combination makes the <a href="https://haystack.deepset.ai/integrations/jina/?ref=jina-ai-gmbh.ghost.io">Jina Haystack extension</a> the perfect solution for your application.</p><p>For questions about <a href="https://haystack.deepset.ai/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Haystack</a> and <a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Jina AI</a>&apos;s integration, <a href="https://discord.com/invite/VBpFzsgRVF?ref=jina-ai-gmbh.ghost.io">join the Haystack community on Discord</a>.</p><p>We would love to hear about your use cases and talk about how the <a href="https://haystack.deepset.ai/integrations/jina/?ref=jina-ai-gmbh.ghost.io">Jina Haystack extension</a> can fit your business needs. Contact us via <a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io">our website</a> or <a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io">our Discord channel</a> to share your feedback and stay up-to-date with our latest models.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI - Expert in Search: Embeddings, Re-ranking, Prompting</div><div class="kg-bookmark-description">Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"><span class="kg-bookmark-author">Expert in Search: Embeddings, Re-ranking, Prompting</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner.png" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4785 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://discord.com/assets/images/favicon.ico" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Retrieve Jira Tickets with Jina Reranker and Haystack 2.0"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Jina 3.25.0 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-25-0-update/</link><guid isPermaLink="false">660c0aafd6a1020001681e67</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Tue, 02 Apr 2024 13:44:34 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/04/Image-Jina-dark.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3250">Release Note (<code>3.25.0</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/04/Image-Jina-dark.jpg" alt="Jina 3.25.0 Update"><p>This release contains 1 new feature.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.25.0?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Release v3.25.0 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.25.0) Release time: 2024-04-02 13:02:31 This release contains 1 new feature.
&#x1F195; Features
Executor to run in a Microsoft Azure custom container (#6159)
Executors can now run as a Fa&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="Jina 3.25.0 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/473210ebcd4aefce611dfeb7bca09e6554a1e4bc40011b76d4ba473d36b0d376/jina-ai/jina/releases/tag/v3.25.0" alt="Jina 3.25.0 Update"></div></a></figure><h2 id="%F0%9F%86%95-features">&#x1F195; Features</h2><h3 id="executor-to-run-in-a-microsoft-azure-custom-container-6159">Executor to run in a Microsoft Azure custom container (<a href="https://github.com/jina-ai/jina/pull/6159?ref=jina-ai-gmbh.ghost.io">#6159</a>)</h3><p>Executors can now run as a FastAPI app in a Microsoft Azure container when being served with&#xA0;<code>AZURE</code>&#xA0;as the provider argument.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Zac Li (<a href="https://github.com/zac-li?ref=jina-ai-gmbh.ghost.io">@zac-li</a>)</li></ul>]]></content:encoded></item><item><title><![CDATA[DSPy: Not Your Average Prompt Engineering]]></title><description><![CDATA[Heads up, Bay Area guys ditched their AVP already and buzz about DSPy now. Could DSPy be the new go-to framework for prompt engineering after LangChain and LlamaIndex?]]></description><link>https://jina.ai/news/dspy-not-your-average-prompt-engineering/</link><guid isPermaLink="false">66077bf0a5c39b0001044181</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Han Xiao]]></dc:creator><pubDate>Sat, 30 Mar 2024 05:22:42 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png" medium="image"/><content:encoded><![CDATA[<div class="kg-card kg-file-card"><a class="kg-file-card-container" href="https://jina-ai-gmbh.ghost.io/content/files/2024/04/DSPy-Not-Your-Average-Prompt-Engineering--1-.pdf" title="Download" download><div class="kg-file-card-contents"><div class="kg-file-card-title">[Slides] DSPy: Not Your Average Prompt Engineering</div><div class="kg-file-card-caption">A presentation Han made on April 15, 2024 in Mountain View.</div><div class="kg-file-card-metadata"><div class="kg-file-card-filename">DSPy Not Your Average Prompt Engineering (1).pdf</div><div class="kg-file-card-filesize">7 MB</div></div></div><div class="kg-file-card-icon"><svg viewbox="0 0 24 24"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class="a" points="8.25 14.25 12 18 15.75 14.25"/><line class="a" x1="12" y1="6.75" x2="12" y2="18"/><circle class="a" cx="12" cy="12" r="11.25"/></svg></div></a></div><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--7-.png" alt="DSPy: Not Your Average Prompt Engineering"><p>I&apos;ve recently looked into DSPy, a cutting-edge framework developed by the Stanford NLP group aimed at algorithmically optimizing language model (LM) prompts. Over the last three days, I&apos;ve gathered some initial impressions and valuable insights into DSPy. Note that my observations are not meant to replace the official documentation of DSPy. In fact, I highly recommend reading through <a href="https://dspy-docs.vercel.app/?ref=jina-ai-gmbh.ghost.io">their documentation</a> and <a href="https://github.com/stanfordnlp/dspy/blob/main/README.md?ref=jina-ai-gmbh.ghost.io">README</a> at least once before diving into this post. My discussion here reflects a preliminary understanding of DSPy, having spent a few days exploring its capabilities. There are several advanced features, such as DSPy Assertions, Typed Predictor, and LM weights tuning, that I have yet to explore thoroughly.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/stanfordnlp/dspy?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - stanfordnlp/dspy: DSPy: The framework for programming&#x2014;not prompting&#x2014;foundation models</div><div class="kg-bookmark-description">DSPy: The framework for programming&#x2014;not prompting&#x2014;foundation models - stanfordnlp/dspy</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="DSPy: Not Your Average Prompt Engineering"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">stanfordnlp</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/b8c1b2b4b3ff9c22d486f5c69dbda5fee6cc8dda8a42aaf1c2e154c17b7dc159/stanfordnlp/dspy" alt="DSPy: Not Your Average Prompt Engineering"></div></a></figure><p>Despite my background with Jina AI, which primarily focuses on the search foundation, my interest in DSPy was not directly driven by its potential in Retrieval-Augmented Generation (RAG). Instead, I was intrigued by the possibility of leveraging DSPy for automatic prompt tuning to address some generation tasks. </p><p>If you&apos;re new to DSPy and seeking an accessible entry point, or if you&apos;re familiar with the framework but find the official documentation to be confusing or overwhelming, this article is intended for you. I also opt <em>not</em> to adhere strictly to DSPy&apos;s idiom, which may seem daunting to newcomers. That said, let&apos;s dive deeper.</p><h2 id="what-i-like-about-dspy">What I Like About DSPy</h2><h3 id="dspy-closing-the-loop-of-prompt-engineering">DSPy Closing the Loop of Prompt Engineering</h3><p>What excites me most about DSPy is its approach to closing the loop of the prompt engineering cycle, transforming what is often a <em>manual</em>, <em>handcrafted</em> process into a <em>structured</em>,<em> well-defined </em>machine learning workflow: i.e. preparing datasets, defining the model, training, evaluating, and testing. <strong>In my opinion, this is the most revolutionary aspect of DSPy.</strong></p><p>Traveling in the Bay Area and talking to a lot of startup founders focused on LLM evaluation, I&apos;ve encountered frequent discussions about metrics, hallucinations, observability, and compliance. However, these conversations often don&apos;t progress to the critical next steps: <strong>With all these metrics in hand, what do we do next?</strong> Can tweaking the phrasing in our prompts, in hopes that certain magic words (e.g., &quot;my grandma is dying&quot;) might boost our metrics, be considered a strategic approach? This question has remained unanswered by many LLM evaluation startups, and it was one I couldn&apos;t tackle either&#x2014;until I discovered DSPy. DSPy introduces a clear, programmatic method for optimizing prompts based on specific metrics, or even for optimizing the entire LLM pipeline, including both prompts and LLM weights.</p><p>Harrison, the CEO of LangChain, and Logan, the former OpenAI Head of Developer Relations, have both stated on the <a href="https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924?ref=jina-ai-gmbh.ghost.io">Unsupervised Learning Podcast</a> that 2024 is expected to be a pivotal year for LLM evaluation. It is for this reason that I believe DSPy deserves more attention than it is right now, as DSPy provides the crucial missing piece of the puzzle.</p><h3 id="dspy-separating-logic-from-textual-representation">DSPy Separating Logic From Textual Representation</h3><p>Another aspect of DSPy that impresses me is that, it formulates prompt engineering into a reproducible and LLM-agnostic module. To achieve that, <strong>it  pulls the logic from the prompt, creating a clear separation of concerns between the <em>logic</em> and the <em>textual representation</em></strong>, as illustrated below.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png" class="kg-image" alt="DSPy: Not Your Average Prompt Engineering" loading="lazy" width="1200" height="630" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--5-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--5-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--5-.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">In DSPy, Prompt consists of the intrinsic logic (i.e. </span><code spellcheck="false" style="white-space: pre-wrap;"><span>dspy.Module</span></code><span style="white-space: pre-wrap;">,) and its textual representation. Logic is immutable, reproducible, testable and LLM-agnostic. Textual representation is just the consequence of the logic.</span></figcaption></figure><p><strong>DSPy&apos;s concept of logic as the immutable, testable, and LLM-agnostic &quot;cause&quot;, with textual representation merely as its &quot;consequence&quot;</strong>, may initially seem perplexing. This is especially true in light of the widespread belief, that &quot;the future of programming language is natural language.&quot; Embracing the idea that &quot;prompt engineering is the future,&quot; one might experience a moment of confusion upon encountering DSPy&apos;s design philosophy. Contrary to the expectation of simplification, DSPy introduces an array of modules and signature syntaxes, seemingly regressing natural language prompting to the complexity of C programming!</p><p>But why take this approach? My understanding is that <strong>at the heart of prompt programming lies the core logic, with communication serving as an amplifier</strong>, potentially enhancing or diminishing its effectiveness. The directive <code>&quot;Do sentiment classification&quot;</code> represents the core logic, whereas phrase like <code>&quot;Follow these demonstrations or I will fire you&quot;</code> is one way to communicate it. Analogous to real-life interactions, difficulties in getting things done often stem not from flawed logic but from problematic communications. This explains why many, particularly non-native speakers, find prompt engineering challenging. I&apos;ve observed highly competent software engineers in my company struggle with prompt engineering, not due to a lack of logics, but because they do not &quot;speak the vibe.&quot; By separating the logic from the prompt, <a href="https://dspy-docs.vercel.app/docs/building-blocks/modules?ref=jina-ai-gmbh.ghost.io">DSPy enables deterministic programming of logic via <code>dspy.Module</code></a>, allowing developers to shift focus to logic in the same way they would in traditional engineering, irrespective of the LLM used.</p><p>So, if developers focus on the logic who then manages the textual representation? <strong>DSPy takes on this role, utilizing your data and evaluation metrics to refine the textual representation</strong>&#x2014;everything from determining the narrative focus to optimizing hints, and choosing good demonstrations. Remarkably, DSPy can even use evaluation metrics to fine-tune the LLM weights!</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png" class="kg-image" alt="DSPy: Not Your Average Prompt Engineering" loading="lazy" width="1200" height="630" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Heading--6-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Heading--6-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--6-.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>To me, DSPy&apos;s key contributions&#x2014;closing the loop of training and evaluation in prompt engineering and separating logic from textual representation&#x2014;underscore its potential significance to LLM/Agent systems. Ambitious vision for sure, but definitely necessary!</p><h2 id="what-i-think-dspy-can-improve">What I Think DSPy Can Improve</h2><p>First, DSPy presents a steep learning curve for newcomers due to its idioms. Terms like <code>signature</code>, <code>module</code>, <code>program</code>, <code>teleprompter</code>, <code>optimization</code>, and <code>compile</code> can be overwhelming. Even for those proficient in prompt engineering, navigating these concepts within DSPy can be a challenging maze. </p><figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Yeah, DSPy really needs someone to come in and explain everything without suitcase words. <a href="https://twitter.com/CShorten30?ref_src=twsrc%5Etfw&amp;ref=jina-ai-gmbh.ghost.io">@CShorten30</a> does a great job, but we need more.</p>&#x2014; Jonathan Mugan (@jmugan) <a href="https://twitter.com/jmugan/status/1773036172723236895?ref_src=twsrc%5Etfw&amp;ref=jina-ai-gmbh.ghost.io">March 27, 2024</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><p>This complexity echoes my experience with <a href="https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io">Jina 1.0</a>, where we introduced a slew of idioms such as <code>chunk</code>, <code>document</code>, <code>driver</code>, <code>executor</code>, <code>pea</code>, <code>pod</code>, <code>querylang</code> and <code>flow</code> (we even designed adorable stickers to help user remember!).</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png" width="700" height="700" loading="lazy" alt="DSPy: Not Your Average Prompt Engineering" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Document-FLAT--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Document-FLAT--3-.png 700w"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png" width="700" height="700" loading="lazy" alt="DSPy: Not Your Average Prompt Engineering" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pea-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pea-FLAT--1-.png 700w"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png" width="700" height="700" loading="lazy" alt="DSPy: Not Your Average Prompt Engineering" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/QueryLang--FLAT.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/QueryLang--FLAT.png 700w"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png" width="700" height="700" loading="lazy" alt="DSPy: Not Your Average Prompt Engineering" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--3-FLAT--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--3-FLAT--1-.png 700w"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png" width="700" height="700" loading="lazy" alt="DSPy: Not Your Average Prompt Engineering" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Pod-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Pod-FLAT--2-.png 700w"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png" width="700" height="700" loading="lazy" alt="DSPy: Not Your Average Prompt Engineering" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/ILLUST--5-FLAT--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/ILLUST--5-FLAT--2-.png 700w"></div></div></div><figcaption><p><span style="white-space: pre-wrap;">Most of these early concepts were removed in later Jina refactoring. Today, only </span><code spellcheck="false" style="white-space: pre-wrap;"><span>Executor</span></code><span style="white-space: pre-wrap;">, </span><code spellcheck="false" style="white-space: pre-wrap;"><span>Document</span></code><span style="white-space: pre-wrap;">, and </span><code spellcheck="false" style="white-space: pre-wrap;"><span>Flow</span></code><span style="white-space: pre-wrap;"> have survived from &quot;the great purge.&quot; We did add a new concept, </span><code spellcheck="false" style="white-space: pre-wrap;"><span>Deployment</span></code><span style="white-space: pre-wrap;">, in Jina 3.0; so that evens things out. &#x1F937;</span></p></figcaption></figure><p>This problem isn&apos;t unique to DSPy or Jina; recall the myriad concepts and abstractions introduced by TensorFlow between versions 0.x to 1.x. I believe this problem often emerges in the early stages of software frameworks, where there&apos;s a push <strong>to reflect academic notations directly in the codebase to ensure maximum accuracy and reproducibility</strong>. However, not all users value such granular abstractions, with preferences varying from the desire for simple one-liners to demands for greater flexibility. I discussed this topic of abstraction in software frameworks extensively in a 2020 blog post, which interested readers might find worthwhile.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/?ref=jina-ai-gmbh.ghost.io#layer-of-abstraction"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Layer of Abstraction When Building &#x201C;Tensorflow&#x201D; for Search &#xB7; Han Xiao Tech Blog - Neural Search &amp; AI Engineering</div><div class="kg-bookmark-description">Since Feb. 2020, I started a new venture called Jina AI. Our mission is to build an open-source neural search ecosystem for businesses and developers, ... &#xB7; Han Xiao</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://hanxiao.io/wechaticon.png" alt="DSPy: Not Your Average Prompt Engineering"><span class="kg-bookmark-author">logo</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/blog-abstraction-banner.jpg" alt="DSPy: Not Your Average Prompt Engineering"></div></a></figure><p>Second, the documentation of DSPy sometimes falls short in terms of consistency. Terms like <code>module</code> and <code>program</code>, <code>teleprompter</code> and <code>optimizer</code>, or <code>optimize</code> and <code>compile</code> (sometimes referred to as <code>training</code> or <code>bootstrapping</code>) are used interchangeably, adding to the confusion. Consequently, I spent my initial hours with DSPy trying to decipher exactly what it <code>optimizes</code> and what the process of <code>bootstrapping</code> entails.</p><p>Despite these hurdles, as you delve deeper into DSPy and revisit the documentation, you&apos;ll likely experience moments of clarity where everything starts to click, revealing the connections between its unique terminology and the familiar constructs seen in frameworks like PyTorch. However, DSPy undoubtedly has room for improvement in future versions, particularly in making the framework more accessible to prompt engineers <em>without</em> a background in PyTorch.</p><h2 id="common-stumbling-blocks-for-dspy-newbies">Common Stumbling Blocks for DSPy Newbies</h2><p>In the sections below, I&apos;ve compiled a list of questions that initially stymied my progress with DSPy. My aim is to share these insights in the hope that they might clarify similar challenges for other learners.</p><h3 id="what-are-teleprompter-optimization-and-compile-whats-exactly-being-optimized-in-dspy">What are <code>teleprompter</code>, <code>optimization</code>, and <code>compile</code>? What&apos;s exactly being optimized in DSPy?</h3><p>In DSPy, &quot;Teleprompters&quot; is the optimizer, (and looks like <a href="https://twitter.com/lateinteraction?ref=jina-ai-gmbh.ghost.io">@lateinteraction</a> is revamping the docs and code to clarify this). The <code>compile</code> function acts at the heart of this optimizer, akin to calling <code>optimizer.optimize()</code>. Think of it as the DSPy equivalent of training. This <code>compile()</code> process aims to tune: </p><ul><li>the few-shot demonstrations,</li><li>the instructions, </li><li>the LLM&apos;s weights </li></ul><p>However, most beginner DSPy tutorials won&apos;t delve into weights and instruction tuning, leading to the next question.</p><h3 id="whats-bootstrap-in-dspy-all-about">What&apos;s <code>bootstrap</code> in DSPy all about?</h3><p>Bootstrap refers to the creation of self-generated demonstrations for few-shot in-context learning, a crucial part of the <code>compile()</code> process (i.e., optimization/training as I mentioned above). These few-shot demos are generated from user-given labeled data; and one demo often consists of input, output, rationale (e.g., in Chains of Thought), and intermediate inputs &amp; outputs (for multi-stage prompts). Of course, quality few-shot demos are key to the output excellence. To that, DSPy allows user-defined metric functions to ensure only demos that meet certain criteria are chosen, leading to the next question.</p><h3 id="whats-dspy-metric-function">What&apos;s DSPy metric function?</h3><p>After hands-on experience with DSPy, I&apos;ve come to believe that the metric function needs far more emphasis than what the current documentation provides. The metric function in DSPy plays a crucial role in <em>both</em> evaluation and training phases, acting as a &quot;loss&quot; function as well, thanks to its implicit nature (controlled by <code>trace=None</code>):</p><pre><code class="language-python">def keywords_match_jaccard_metric(example, pred, trace=None):  
    # Jaccard similarity between example keywords and predicted keywords  
    A = set(normalize_text(example.keywords).split())  
    B = set(normalize_text(pred.keywords).split())  
    j = len(A &amp; B) / len(A | B)
    if trace is not None:
        # act as a &quot;loss&quot; function
        return j  
    return j &gt; 0.8  # act as evaluation</code></pre><p>This approach differs significantly from traditional machine learning, where the loss function is usually continuous and differentiable (e.g., hinge/MSE), while the evaluation metric might be entirely different and discrete (e.g., NDCG). In DSPy, the evaluation and loss functions are unified in the metric function, which can be discrete and most often returns a boolean value. The metric function can also integrate an LLM! In the example below, I implemented a fuzzy match using LLM to determine if the predicted value and the gold standard answer are similar in magnitude, e.g., &quot;1 million dollars&quot; and &quot;$1M&quot; would return true.</p><pre><code class="language-python">class Assess(dspy.Signature):  
    &quot;&quot;&quot;Assess the if the prediction is in the same magnitude to the gold answer.&quot;&quot;&quot;  
  
    gold_answer = dspy.InputField(desc=&apos;number, could be in natural language&apos;)  
    prediction = dspy.InputField(desc=&apos;number, could be in natural language&apos;)  
    assessment = dspy.OutputField(desc=&apos;yes or no, focus on the number magnitude, not the unit or exact value or wording&apos;)  
  
def same_magnitude_correct(example, pred, trace=None):  
    return dspy.Predict(Assess)(gold_answer=example.answer, prediction=pred.answer).assessment.lower() == &apos;yes&apos;</code></pre><p>As powerful as it is, the metric function significantly influences the DSPy user experience, determining not only the final quality assessment but also affecting the optimization results. A well-designed metric function can lead to optimized prompts, whereas a poorly crafted one can cause the optimization to fail. When tackling a new problem with DSPy, you may find yourself spending as much time designing the logic (i.e., <code>DSPy.Module</code>) as you do on the metric function. This dual focus on logic and metrics can be daunting for newcomers.</p><h3 id="bootstrapped-0-full-traces-after-20-examples-in-round-0-what-does-this-mean"><code>&quot;Bootstrapped 0 full traces after 20 examples in round 0&quot;</code> what does this mean?</h3><p>This message emits quietly during <code>compile()</code> deserves your highest attention, as it essentially means that optimization/compilation failed, and the prompt you get is no better than simple few-shot. What goes wrong? I&apos;ve summarized some tips to help you debug ur DSPy program when encounter such message:</p><h4 id="your-metric-function-is-incorrect">Your Metric Function is Incorrect </h4><p>Is the function <code>your_metric</code>, used in <code>BootstrapFewShot(metric=your_metric)</code>, correctly implemented? Conduct some unit tests. Does <code>your_metric</code> ever return <code>True</code>, or does it always return <code>False</code> ? Note that returning <code>True</code> is crucial because it&apos;s the criterion for DSPy to consider the bootstrapped example a &quot;success.&quot; If you return every evaluation as <code>True</code>, then every example is considered a &quot;success&quot; in bootstrapping! This isn&apos;t ideal, of course, but it&apos;s how you can adjust the strictness of the metric function to change the <code>&quot;Bootstrapped 0 full traces&quot;</code> result. Note that although DSPy documents that metrics can return scalar values as well, after looking at the underlying code, I wouldn&apos;t recommend it for newbies.</p><h4 id="your-logic-dspymodule-is-incorrect">Your Logic (<code>DSPy.Module</code>) is Incorrect </h4><p>If the metric function is correct, then you need to check if your logic <code>dspy.Module</code> is correctly implemented. First, verify that the <a href="https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io">DSPy signature</a> is correctly assigned for each step. Inline signatures, such as <code>dspy.Predict(&apos;question-&gt;answer&apos;)</code>, are easy to use, but for quality&apos;s sake, I strongly suggest implementing with <a href="https://dspy-docs.vercel.app/docs/building-blocks/signatures?ref=jina-ai-gmbh.ghost.io#class-based-dspy-signatures">class-based signatures</a>. Specifically, add some descriptive docstrings to the class, fill in desc fields for <code>InputField</code> and <code>OutputField</code>&#x2014;these all provide the LM with hints about each field. Below I implemented two multi-stage <code>DSPy.Module</code> for solving <a href="https://en.wikipedia.org/wiki/Fermi_problem?ref=jina-ai-gmbh.ghost.io">Fermi problems</a>, one with in-line signature, one with class-based signature.</p><figure class="kg-card kg-code-card"><pre><code class="language-python">class FermiSolver(dspy.Module):
    def __init__(self):
        super().__init__()
        self.step1 = dspy.Predict(&apos;question -&gt; initial_guess&apos;)
        self.step2 = dspy.Predict(&apos;question, initial_guess -&gt; calculated_estimation&apos;)
        self.step3 = dspy.Predict(&apos;question, initial_guess, calculated_estimation -&gt; variables_and_formulae&apos;)
        self.step4 = dspy.ReAct(&apos;question, initial_guess, calculated_estimation, variables_and_formulae -&gt; gathering_data&apos;)
        self.step5 = dspy.Predict(&apos;question, initial_guess, calculated_estimation, variables_and_formulae, gathering_data -&gt; answer&apos;)

    def forward(self, q):
        step1 = self.step1(question=q)
        step2 = self.step2(question=q, initial_guess=step1.initial_guess)
        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)
        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)
        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)
        return step5</code></pre><figcaption><p><span style="white-space: pre-wrap;">Fermi problem solver using in-line signature only</span></p></figcaption></figure><figure class="kg-card kg-code-card"><pre><code class="language-python">class FermiStep1(dspy.Signature):
    question = dspy.InputField(desc=&apos;Fermi problems involve the use of estimation and reasoning&apos;)
    initial_guess = dspy.OutputField(desc=&apos;Have a guess &#x2013; don&#x2019;t do any calculations yet&apos;)

class FermiStep2(FermiStep1):
    initial_guess = dspy.InputField(desc=&apos;Have a guess &#x2013; don&#x2019;t do any calculations yet&apos;)
    calculated_estimation = dspy.OutputField(desc=&apos;List the information you&#x2019;ll need to solve the problem and make some estimations of the values&apos;)

class FermiStep3(FermiStep2):
    calculated_estimation = dspy.InputField(desc=&apos;List the information you&#x2019;ll need to solve the problem and make some estimations of the values&apos;)
    variables_and_formulae = dspy.OutputField(desc=&apos;Write a formula or procedure to solve your problem&apos;)

class FermiStep4(FermiStep3):
    variables_and_formulae = dspy.InputField(desc=&apos;Write a formula or procedure to solve your problem&apos;)
    gathering_data = dspy.OutputField(desc=&apos;Research, measure, collect data and use your formula. Find the smallest and greatest values possible&apos;)

class FermiStep5(FermiStep4):
    gathering_data = dspy.InputField(desc=&apos;Research, measure, collect data and use your formula. Find the smallest and greatest values possible&apos;)
    answer = dspy.OutputField(desc=&apos;the final answer, must be a numerical value&apos;)

class FermiSolver2(dspy.Module):
    def __init__(self):
        super().__init__()
        self.step1 = dspy.Predict(FermiStep1)
        self.step2 = dspy.Predict(FermiStep2)
        self.step3 = dspy.Predict(FermiStep3)
        self.step4 = dspy.Predict(FermiStep4)
        self.step5 = dspy.Predict(FermiStep5)

    def forward(self, q):
        step1 = self.step1(question=q)
        step2 = self.step2(question=q, initial_guess=step1.initial_guess)
        step3 = self.step3(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation)
        step4 = self.step4(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae)
        step5 = self.step5(question=q, initial_guess=step1.initial_guess, calculated_estimation=step2.calculated_estimation, variables_and_formulae=step3.variables_and_formulae, gathering_data=step4.gathering_data)
        return step5</code></pre><figcaption><p><span style="white-space: pre-wrap;">Fermi problem solver using class-based signature with more comprehensive description on each field.</span></p></figcaption></figure><p>Also, check the <code>def forward(self, )</code> part. For multi-stage Modules, ensure the output (or <em>all</em> outputs like the in <code>FermiSolver</code>) from the last step is fed as input to the next step.</p><h4 id="your-problem-is-just-too-hard">Your Problem is Just Too Hard</h4><p>If both the metric and module seem correct, then it&apos;s possible your problem is just too challenging and the logic you implemented is not enough for solving it. Therefore, DSPy finds it is infeasible to bootstrap any demo given your logic and metric function. At this point, here are some options you can consider: </p><ul><li><strong>Use a more powerful LM. </strong>For example, replacing <code>gpt-35-turbo-instruct</code> with <code>gpt-4-turbo</code> as the student&apos;s LM, use a stronger LM as the teacher. This can be often quite effective. After all, a stronger model means better comprehension on the prompts.</li><li><strong>Improve your logic.</strong> Add or replace some steps in your <code>dspy.Module</code> with more complicated ones. e.g., replace <code>Predict</code> to <code>ChainOfThought</code> <code>ProgramOfThought</code>, adding <code>Retrieval</code> step.</li><li><strong>Add more training examples</strong>. If 20 examples is not enough, aim for 100! You can then hope one example passes the metric check and is picked by <code>BootstrapFewShot</code>.</li><li><strong>Reformulate the problem.</strong> Often, a problem becomes unsolvable when the formulation is incorrect. But if you change an angle to look at it, things could be much easier and more obvious.</li></ul><p>In practice, the process involves a blend of trial and error. For instance, I tackled a particularly challenging problem: generating an SVG icon similar to Google Material Design icons based on two or three keywords. My initial strategy was to utilize a simple <code>DSPy.Module</code> that uses <code>dspy.ChainOfThought(&apos;keywords -&gt; svg&apos;)</code>, paired with a metric function that assessed visual similarity between the generated SVG and the ground truth Material Design SVG, similar to a pHash algorithm. I began with 20 training examples, but after the first round, I ended up with <code>&quot;Bootstrapped 0 full traces after 20 examples in round 0&quot;</code>, indicating that the optimization had failed. By increasing the dataset to 100 examples, revising my module to incorporate multiple stages, and adjusting the threshold of the metric function, I eventually achieved 2 bootstrapped demonstrations and managed to obtain some optimized prompts.</p>]]></content:encoded></item><item><title><![CDATA[Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators]]></title><description><![CDATA[See how PromptPerfect Interactive is revolutionizing YouTube content creation with AI-powered storytelling. Elevate your videos and connect with audiences like never before.]]></description><link>https://jina.ai/news/elevating-youtube-scripts-with-promptperfect-ai-mastery-for-video-content-creators/</link><guid isPermaLink="false">66016ffe3f488f00013e6c16</guid><category><![CDATA[Knowledge Base]]></category><dc:creator><![CDATA[Jina AI]]></dc:creator><pubDate>Tue, 26 Mar 2024 15:00:44 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/PP-for-YouTubers.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/PP-for-YouTubers.jpg" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"><p>The advent of Generative AI and Large Language Models (LLMs) like GPT-4 has profoundly impacted content creation across various platforms, including YouTube. The essence of utilizing these tools lies not merely in their existence but in how content creators can adeptly harness them. Picture LLM prompts as the quiver of arrows in an archer&apos;s repertoire: without precision and skill, the arrows might miss their mark, but with careful aim and understanding, they can hit the bullseye every time.</p><p>It&apos;s a common misconception that only those with deep technical knowledge can wield the power of Generative AI effectively. That&apos;s where PromptPerfect Interactive comes into play, offering every video content creator, regardless of their technical prowess, the power to refine their creative prompts. This ensures every script&#x2014;from educational content to entertainment&#x2014;resonates deeply with viewers, enhancing engagement and viewer satisfaction.</p><p>Our recent unveiling of <a href="https://jina.ai/news/get-more-with-promptperfect-improved-subscription-choices-cutting-edge-interactive-optimizer?ref=jina-ai-gmbh.ghost.io">PromptPerfect&apos;s interactive feature</a> represents a significant leap forward in our quest to democratize AI-powered content creation.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/get-more-with-promptperfect-improved-subscription-choices-cutting-edge-interactive-optimizer?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer</div><div class="kg-bookmark-description">More cost-effective monthly subscription models and brand new interactive optimizer in PromptPerfect&#x2019;s latest release.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"><span class="kg-bookmark-publisher">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/3.jpg" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"></div></a></figure><p>&quot;Interactive&quot; is a leap forward in content generation with LLMs. At its core, this feature is powered by two elements: a Dedicated Assistant and a Powerful Optimizer. The Assistant serves as your AI cohort, aiding in the development of precise prompts to streamline the scriptwriting process. Concurrently, the Optimizer refines your prompts, ensuring each script achieves its maximum potential. Designed to simplify and elevate AI-powered scriptwriting, the Interactive feature makes generating engaging, relevant YouTube scripts more intuitive and accessible for every creator.</p><h2 id="streamlined-content-creation">Streamlined Content Creation</h2><h3 id="crafting-scripts-with-precision">Crafting Scripts with Precision</h3><p>Creators can fine-tune the details of their message, ensuring each script speaks directly to their audience&apos;s preferences and interests. This capability allows for the generation of content that is not just in harmony with the creator&apos;s vision but also finely tuned to the audience&apos;s expectations, whether in tone, style, or substance.</p><h3 id="tailoring-content-to-your-audience">Tailoring Content to Your Audience</h3><p>The true power of an optimized LLM prompt extends beyond mere text generation; it&apos;s about forging a deeper connection with viewers. With PromptPerfect, creators can customize prompts to produce scripts that feel personal and relevant. This personal touch transforms generic information into compelling narratives that captivate viewers, fostering engagement and building a stronger community around your channel.</p><h2 id="enhancing-creative-workflows">Enhancing Creative Workflows</h2><h3 id="boosting-productivity">Boosting Productivity</h3><p>The Interactive feature acts as a catalyst for your content creation process, making scriptwriting more efficient and allowing more time for conceptualization and production. By revolutionizing how scripts are generated, creators can shift their focus towards refining their content strategies and analyzing viewer feedback, ultimately leading to more impactful videos.</p><h3 id="differentiating-your-channel">Differentiating Your Channel</h3><p>In the competitive landscape of YouTube, standing out is crucial. PromptPerfect&apos;s latest update enables creators to ensure their content is not just viewed but remembered. By optimizing prompts to generate unique and captivating scripts, channels can distinguish themselves, turning every video into an opportunity to highlight their unique brand and vision.</p><h2 id="unleashing-creativity-promptperfect-in-action">Unleashing Creativity: PromptPerfect in Action</h2><p>Let&apos;s follow Jack, a dedicated video content creator, as he uses PromptPerfect Interactive to develop a script for his latest YouTube project.</p><p>In this creative journey, we find:</p><ul><li>&#x1F9D4;&#x200D;&#x2642;&#xFE0F; <strong>Jack</strong>: the visionary behind the camera.</li><li>&#x1F916; <strong>PromptPerfect&apos;s Optimizer</strong>: An advanced AI tool refining your prompts for the best possible scripts.</li><li>&#x1F4AC; <strong>PromptPerfect&apos;s Assistant</strong>: An LLM sidekick designed to understand your creative needs and assist in crafting effective prompts.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F9D4;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Jack</strong></b><br><br>We&apos;re working on a new video series for my YouTube channel, focusing on the untold stories of unsung heroes in science and technology.<br><br>Project description: The series aims to bring to light the contributions of lesser-known figures in science and tech through engaging, informative scripts that blend historical insights with contemporary relevance. The goal is to produce content that educates, inspires, and entertains viewers, encouraging them to explore these subjects further. The series will leverage PromptPerfect Interactive&apos;s capabilities to ensure each script is not just informative but captivating, engaging viewers with a blend of storytelling and factual accuracy. The interactive prompt optimizer chatbot will assist in refining and brainstorming prompts, ensuring that each script is tailored to evoke curiosity and foster a deeper understanding of the topic.<br><br>I need a prompt to generate a script for my next video, highlighting the life and achievements of an overlooked inventor in the tech world.</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>Here&apos;s a customized prompt for creating your video script on the unsung hero in technology:</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>As a creative force behind your YouTube channel, craft an engaging and insightful script to showcase the life and achievements of a lesser-known inventor in the technology sector. The script should be written in an inviting and passionate tone, drawing viewers into the story of this overlooked figure and highlighting how their contributions have shaped the modern tech landscape.<br><br>```<br>The series aims to illuminate the contributions of unsung heroes in science and tech, blending historical depth with a contemporary angle. By leveraging PromptPerfect Interactive, the script will not only inform but also inspire and entertain, driving curiosity and encouraging viewers to delve deeper into these subjects. With the assistance of the interactive prompt optimizer chatbot, we&apos;ll refine and brainstorm prompts to ensure the narrative is compelling, engaging, and accurately conveys the inventor&apos;s impact on technology.<br>```<br><br>The script should encompass:<br><br>1. A captivating introduction that sets the tone and piques interest in the inventor&apos;s story.<br>2. A detailed exploration of the inventor&apos;s life, discoveries, and the challenges they faced.<br>3. An analysis of the inventor&apos;s impact on technology and how their work continues to influence the field today.<br>4. A conclusion that ties the inventor&apos;s story back to the broader theme of recognizing and celebrating unsung heroes in science and technology.<br>5. A call-to-action encouraging viewers to share their thoughts and explore more untold stories in the realm of science and tech.<br><br>Ensure the script is engaging, informative, and crafted in a way that resonates with your audience, inviting them on a journey of discovery and inspiration.</div></div><div class="kg-card kg-callout-card kg-callout-card-purple"><div class="kg-callout-emoji">&#x1F4AC;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Assistant</strong></b><br><br><b><strong style="white-space: pre-wrap;">Title: The Guardian of the Internet: The Story of Theo de Raadt</strong></b><br><br><b><strong style="white-space: pre-wrap;">[Intro Music]</strong></b><br><br><b><strong style="white-space: pre-wrap;">[Cut to Host in a well-lit, tech-inspired studio]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;Welcome to &apos;Hidden Heroes of Tech,&apos; where we uncover the stories of the brilliant minds behind our digital world. Today, we delve into the life of Theo de Raadt, the pioneering spirit behind OpenBSD and OpenSSH. Over the next five minutes, we&apos;ll explore how de Raadt&apos;s unwavering commitment to security and open-source software has shaped the internet as we know it.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to photos of Theo de Raadt, accompanied by soft background music]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host Voiceover</strong></b>: &quot;Born in South Africa and raised in Canada, Theo de Raadt&apos;s journey into the tech world has been anything but ordinary. A staunch advocate for open-source software, de Raadt founded the OpenBSD project in 1995, with a mission to create the most secure operating system available.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to Host]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;OpenBSD, under de Raadt&apos;s leadership, has introduced numerous innovations and security features that have set the standard for operating system security worldwide. But de Raadt&apos;s contributions don&apos;t stop there.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to animations showing the OpenBSD and OpenSSH logos]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host Voiceover</strong></b>: &quot;Perhaps one of de Raadt&apos;s most impactful creations is OpenSSH, a tool that has become indispensable for secure communication across the internet. Launched in 1999, OpenSSH provides a secure channel over an unsecured network, a critical component in today&apos;s digital age.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to Host]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;But Theo de Raadt&apos;s path hasn&apos;t been without its challenges. His outspoken nature and commitment to his principles have often put him at odds with other figures in the tech community. Yet, it&apos;s this very integrity and dedication that have cemented his legacy.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to footage of computer networks and encrypted data transfers]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host Voiceover</strong></b>: &quot;Thanks to de Raadt&apos;s efforts, millions of servers worldwide operate securely, protecting untold amounts of sensitive data from potential breaches. OpenBSD and OpenSSH are testaments to de Raadt&apos;s vision: that security and freedom in software are not just ideals, but necessities.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to Host]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;De Raadt&apos;s influence extends beyond code; it&apos;s in the very fabric of the internet. His work empowers not just developers, but all who seek a safer digital world. Yet, despite his monumental contributions, Theo de Raadt remains a figure not widely known outside of tech circles.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to animations illustrating the significance of secure online communications]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host Voiceover</strong></b>: &quot;In an era where data breaches and cyber threats are commonplace, de Raadt&apos;s pioneering work on security has never been more relevant. His dedication to the open-source model has inspired a generation of developers to prioritize security in their projects.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut back to Host]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;The legacy of Theo de Raadt is a reminder of the unsung heroes in our midst&#x2014;those whose work underpins the very security and freedom we enjoy online. It&apos;s a legacy built on the belief that open, secure software is a cornerstone of a free and safe internet.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut to montage of cybersecurity professionals, developers, and encrypted data visualizations]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host Voiceover</strong></b>: &quot;As we navigate the complexities of the digital age, the principles championed by Theo de Raadt remain more important than ever. His life&apos;s work is a beacon for all who believe in the power of open-source software to change the world for the better.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Cut back to Host]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;Theo de Raadt may not be a household name, but in the realm of cybersecurity and open-source software, he is a giant. His vision and tenacity have helped safeguard the internet, making it a safer place for us all.&quot;<br><br><b><strong style="white-space: pre-wrap;">[Outro Music]</strong></b><br><br><b><strong style="white-space: pre-wrap;">Host</strong></b>: &quot;Thank you for joining us as we celebrated the remarkable contributions of Theo de Raadt. If you&apos;re inspired by the impact of open-source software and the importance of digital security, please like, share, and subscribe for more stories about the hidden heroes of technology. Until next time, stay secure, and keep exploring.&quot;<br><br><b><strong style="white-space: pre-wrap;">[End Screen with Subscribe Button and Video Suggestions]</strong></b></div></div><h2 id="promptperfect-the-future-of-ai-powered-youtube-storytelling">PromptPerfect: The Future of AI-Powered YouTube Storytelling</h2><p>As we pull back the curtain on the transformative capabilities of PromptPerfect Interactive, it&apos;s evident that the future of YouTube content creation is ripe with possibilities. The journey of creators like Jack exemplifies not just the potential to craft engaging narratives but also the power to connect with audiences on a deeper level. With the advent of tools like PromptPerfect, the process of scriptwriting transcends traditional boundaries, enabling creators to weave compelling stories that resonate, educate, and entertain. The essence of this innovation lies in its ability to democratize AI-powered content creation, making it accessible to creators across the spectrum of expertise. By harnessing the power of precise, optimized prompts, video content creators are now equipped to produce content that not only captures the imagination but also amplifies their unique voice in the vast YouTube ecosystem.</p><p>In an era where content is king, the role of technologies like PromptPerfect Interactive becomes indispensable in distinguishing one&apos;s channel in the crowded digital landscape. The implications of such advancements extend beyond simplifying content creation; they foster a culture of innovation, where creators are empowered to push the boundaries of storytelling. As we look to the future, the integration of AI in content creation holds the promise of unlocking unprecedented levels of creativity and engagement. PromptPerfect stands at the forefront of this revolution, offering a glimpse into a future where AI and human creativity converge to create content that is not only informative but truly unforgettable.</p><h2 id="take-your-content-creation-to-new-heights-join-promptperfect-today">Take Your Content Creation to New Heights: Join PromptPerfect Today</h2><p>Dive into the world of AI-enhanced storytelling with PromptPerfect and transform your YouTube channel with captivating scripts that speak directly to your audience. <a href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io">Sign up now</a> to start your 7-day free trial on our paid plan. Make the leap within the first 24 hours of logging in and enjoy an exclusive 40% off.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Optimize Your Prompts to Perfection</div><div class="kg-bookmark-description">Unlock prompt optimization for models like GPT-4, ChatGPT and Midjourney. Deploy prompts as services with our free hosting.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/favicon-128x128.png" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"><span class="kg-bookmark-author">Optimize Your Prompts to Perfection</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"></div></a></figure><p>But the journey doesn&apos;t stop at content creation. Join our vibrant community on <a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io">Discord</a> and share your ideas, creations, and get inspired by like-minded creators. Together, let&apos;s push the boundaries of what&apos;s possible and shape the future of video content. Embrace the power of AI with PromptPerfect and start creating stories that resonate, engage, and inspire. Your next masterpiece awaits.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4667 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://static.ghost.org/v5.0.0/images/link-icon.svg" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Elevating YouTube Scripts with PromptPerfect: AI Mastery for Video Content Creators"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker]]></title><description><![CDATA[Learn to use Jina Embeddings and Reranking models in a full-stack AI application on AWS, using only components available in Amazon SageMaker and the AWS Marketplace.]]></description><link>https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker/</link><guid isPermaLink="false">65fabb91502fd000011c667e</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Scott Martens]]></dc:creator><pubDate>Mon, 25 Mar 2024 15:00:51 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Blog-images--27-.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Blog-images--27-.jpg" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><p><a href="https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io">Jina Embeddings</a> and <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io">Jina Reranker</a> are now available to use with <a href="https://aws.amazon.com/pm/sagemaker/?ref=jina-ai-gmbh.ghost.io">Amazon SageMaker</a> from the <a href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io">AWS Marketplace</a>. For enterprise users who put a high value on security, reliability, and consistency in their cloud operations, this puts Jina AI&#x2019;s state-of-the-art AI in their private AWS deployments, where they enjoy all the benefits of AWS&#x2019;s established, stable infrastructure.</p><p>With our full array of embedding and reranking models on the AWS Marketplace, SageMaker users can take advantage of ground-breaking 8k input context windows and top-ranking multilingual embeddings on demand at competitive prices. You don&#x2019;t have to pay to transfer models into or out of AWS, prices are transparent, and your billing is integrated with your AWS account.</p><p>The models available on Amazon SageMaker currently include:</p><ul><li><a href="https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io">Jina Embeddings v2 Base - English</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-6w6k6ckusixpw?ref=jina-ai-gmbh.ghost.io">Jina Embeddings v2 Small - English</a></li><li>Jina Embeddings v2 Bilingual Models:<ul><li><a href="https://aws.amazon.com/marketplace/pp/prodview-dz3ubvmivnwry?ref=jina-ai-gmbh.ghost.io">German/English</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-hxalozh37jka4?ref=jina-ai-gmbh.ghost.io">Chinese/English</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-rnb324fpie3n6?ref=jina-ai-gmbh.ghost.io">Spanish/English</a></li></ul></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-tk7t7bz6fp5ng?ref=jina-ai-gmbh.ghost.io">Jina Embeddings v2 Base - Code</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-avmxk2wxbygd6?ref=jina-ai-gmbh.ghost.io">Jina Reranker v1 Base - English</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-6kxbf5xqrluf4?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Jina ColBERT v1 - English</a></li><li><a href="https://aws.amazon.com/marketplace/pp/prodview-mgomngrh4c4k4?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Jina ColBERT Reranker v1 - English</a></li></ul><p>For the full list of models, see <a href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io">Jina AI&#x2019;s vendor page on the AWS Marketplace</a>, and take advantage of a seven-day free trial.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Marketplace: Jina AI</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></div><div class="kg-bookmark-thumbnail"><img src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>This article will walk you through creating a <a href="https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/?ref=jina-ai-gmbh.ghost.io">Retrieval-augmented generation</a> (RAG) application exclusively using components from Amazon SageMaker. The models we will use are <strong>Jina Embeddings v2 - English</strong>, <strong>Jina Reranker v1</strong>, and the <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io">Mistral-7B-Instruct</a> large language model.</p><p>You can also follow along with a Python Notebook, which you can <a href="https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/sagemaker/sagemaker.ipynb?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">download</a> or <a href="https://colab.research.google.com/github/jina-ai/workshops/blob/main/notebooks/embeddings/sagemaker/sagemaker.ipynb?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">run on Google Colab</a>.</p><h2 id="retrieval-augmented-generation">Retrieval-Augmented Generation</h2><p>Retrieval-augmented generation is an alternative paradigm in generative AI. Instead of using large language models (LLMs) to directly answer user requests with what it&#x2019;s learned in training, it takes advantage of their fluent language production while relocating logic and information retrieval to an external apparatus better suited to it.</p><p>Before invoking an LLM, RAG systems actively retrieve relevant information from some external data source and then feed it to the LLM as part of its prompt. The role of the LLM is to synthesize outside information into a coherent response to user requests, minimizing the risk of hallucination and increasing the relevance and usefulness of the result.</p><p>A RAG system schematically has at least four components:</p><ul><li>A data source, typically a vector database of some kind, suited to AI-assisted information retrieval.</li><li>An information retrieval system that treats the user&#x2019;s request as a query, and retrieves data that is relevant to answering it.</li><li>A system, often including an AI-based reranker, that selects some of the retrieved data and processes it into a prompt for an LLM.</li><li>An LLM, for example one of the GPT models or an open-source LLM like Mistral&#x2019;s, that takes the user request and the data provided to it and generates a response for the user.</li></ul><p>Embedding models are well-suited for information retrieval and are often used for that purpose. A text embedding model takes texts as inputs and outputs an <a href="https://jina.ai/news/how-embeddings-drive-ai-a-guide?ref=jina-ai-gmbh.ghost.io">embedding</a> &#x2014; a high-dimensional vector &#x2014; whose spatial relationship to other embeddings is indicative of their semantic similarity, i.e. similar topics, contents, and related meanings. They are often used in information retrieval because the closer the embeddings, the more likely the user will be happy with the response. They are also relatively easy to fine-tune to improve their performance in specific domains.</p><p><a href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Text reranker</a> models use similar AI principles to compare collections of texts to a query and sort them by their semantic similarity. Using a task-specific reranker model, instead of relying on just an embedding model, often dramatically increases the precision of search results. The reranker in a RAG application selects some of the results of information retrieval in order to maximize the probability that the right information is in the prompt to the LLM.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Maximizing Search Relevance and RAG Accuracy with Jina Reranker</div><div class="kg-bookmark-description">Boost your search and RAG accuracy with Jina Reranker. Our new model improves the accuracy and relevance by 20% over simple vector search. Try it now for free!</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Reranker1.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><h2 id="benchmarking-performance-of-embedding-models-as-sagemaker-endpoints"><strong>Benchmarking Performance of Embedding Models as SageMaker Endpoints</strong></h2><p>We tested the performance and reliability of the <strong>Jina Embeddings v2 Base - English</strong> model as a SageMaker endpoint, running on a&#xA0;<a href="https://aws.amazon.com/ec2/instance-types/g4/?ref=jina-ai-gmbh.ghost.io">g4dn.xlarge</a>&#xA0;instance. In these experiments, we continuously spawned one new user every second, each of whom would send a request, wait for its response, and repeat upon receiving it.</p><ul><li>For requests of&#xA0;<em>less than 100 tokens</em>, for up to 150 concurrent users, the response times <em>per request</em> stayed below 100ms. Then, the response times increased linearly from 100ms to 1500ms with the spawning of more concurrent users.<ul><li>At about&#xA0;<em>300 concurrent users</em>, we received more than 5 failures from the API and ended the test.</li></ul></li><li>For requests between 1K and 8K tokens, for up to 20 concurrent users, the response times <em>per request</em> stayed below 8s. Then, the response times increased linearly from 8s to 60s with the spawning of more concurrent users.<ul><li>At about&#xA0;<em>140 concurrent users</em>, we received more than 5 failures from the API and ended the test.</li></ul></li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/image-3.png" class="kg-image" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker" loading="lazy" width="2000" height="1250" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/03/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/image-3.png 2000w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Performance during test runs (left: small context, right: large context), showing the effect of increasing users over time on response times and failure rates. </span></figcaption></figure><p>Based on these results, we can conclude that for most users with normal embedding workloads g4dn.xlarge or g5.xlarge instances should meet their daily needs. However, for large <em>indexing</em> jobs, which are typically executed far less often than <em>search</em> tasks, users might prefer a more performant option. For a list of all available Sagemaker instances, please refer to AWS&apos;s overview of <a href="https://aws.amazon.com/ec2/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">EC2</a>. </p><h2 id="configure-your-aws-account">Configure Your AWS account</h2><p>First, you will need to have an AWS account. If you are not already an AWS user, you can <a href="https://portal.aws.amazon.com/billing/signup?ref=jina-ai-gmbh.ghost.io">sign up</a> for an account on the AWS website.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://portal.aws.amazon.com/billing/signup?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Console - Signup</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://portal.aws.amazon.com/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">Signup</span></div></div></a></figure><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x26A0;&#xFE0F;</div><div class="kg-callout-text">You will not be able to complete this tutorial with a Free Tier account because Amazon does not provide free access to SageMaker. You must add a payment method to the account to subscribe to Jina AI&#x2019;s models, even if you use <a href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io" rel="noreferrer">our seven-day free trial</a>.</div></div><h3 id="set-up-aws-tools-in-your-python-environment">Set Up AWS Tools in Your Python Environment</h3><p>Install in your Python environment the AWS tools and libraries needed for this tutorial:</p><pre><code class="language-bash">pip install awscli jina-sagemaker
</code></pre><p>You will need to get an access key and a secret access key for your AWS account. To do so, follow the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?ref=jina-ai-gmbh.ghost.io">instructions on the AWS website</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Managing access keys for IAM users - AWS Identity and Access Management</div><div class="kg-bookmark-description">Create, modify, view, or update access keys (credentials) for programmatic calls to AWS.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://docs.aws.amazon.com/assets/images/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">AWS Identity and Access Management</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.aws.amazon.com/images/IAM/latest/UserGuide/images/security-credentials-user.shared.console.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>You will also need to choose an <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html?ref=jina-ai-gmbh.ghost.io">AWS region</a> to work in.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Regions, Availability Zones, and Local Zones - Amazon Relational Database Service</div><div class="kg-bookmark-description">Learn how Amazon cloud computing resources are hosted in multiple locations world-wide, including AWS Regions and Availability Zones.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://docs.aws.amazon.com/assets/images/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">Amazon Relational Database Service</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.aws.amazon.com/images/AmazonRDS/latest/UserGuide/images/Con-AZ-Local.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>Then, set the values in environment variables. In Python or in a Python notebook, you can do that with the following code:</p><pre><code class="language-bash">import os

os.environ[&quot;AWS_ACCESS_KEY_ID&quot;] = &lt;YOUR_ACCESS_KEY_ID&gt;
os.environ[&quot;AWS_SECRET_ACCESS_KEY&quot;] = &lt;YOUR_SECRET_ACCESS_KEY&gt;
os.environ[&quot;AWS_DEFAULT_REGION&quot;] = &lt;YOUR_AWS_REGION&gt;
os.environ[&quot;AWS_DEFAULT_OUTPUT&quot;] = &quot;json&quot;
</code></pre><p>Set the default output to <code>json</code>.</p><p>You can also do this via the <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html?ref=jina-ai-gmbh.ghost.io">AWS command line application</a> or by setting up an <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html?ref=jina-ai-gmbh.ghost.io">AWS configuration file</a> on your local filesystem. See the <a href="https://docs.aws.amazon.com/index.html?ref=jina-ai-gmbh.ghost.io">documentation on the AWS website</a> for further details.</p><h3 id="create-a-role">Create a Role</h3><p>You will also need an <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html?ref=jina-ai-gmbh.ghost.io">AWS role</a> with sufficient permissions to use the resources required for this tutorial.</p><p>This role must:</p><ol><li>Have&#xA0;<strong>AmazonSageMakerFullAccess</strong> enabled.</li><li>Either:<ol><li>Have authority to make AWS Marketplace subscriptions and have enabled all three of:<ol><li><strong>aws-marketplace:ViewSubscriptions</strong></li><li><strong>aws-marketplace:Unsubscribe</strong></li><li><strong>aws-marketplace:Subscribe</strong></li></ol></li><li>Or your AWS account has a subscription to&#xA0;<a href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io">jina-embedding-model</a>.</li></ol></li></ol><p>Store the ARN (<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference-arns.html?ref=jina-ai-gmbh.ghost.io">Amazon Resource Name</a>) of the role in the variable name <code>role</code> :</p><pre><code class="language-python">role = &lt;YOUR_ROLE_ARN&gt;
</code></pre><p>See the documentation for roles on the AWS website for more information.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">IAM roles - AWS Identity and Access Management</div><div class="kg-bookmark-description">Learn how and when to use IAM roles.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://docs.aws.amazon.com/assets/images/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">AWS Identity and Access Management</span></div></div></a></figure><h3 id="subscribe-to-jina-ai-models-on-aws-marketplace">Subscribe to Jina AI Models on AWS Marketplace</h3><p>In this article, we will be using the Jina Embeddings v2 base English model. Subscribe to it on <a href="https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io">the AWS Marketplace</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Marketplace: Jina Embeddings v2 Base - en</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">en</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>You will see pricing information by scrolling down on the page. AWS charges by the hour for models from the marketplace, so you will be billed for the time from when you start the model endpoint to when you stop it. This article will show you how to do both.</p><p>We will also use the Jina Reranker v1 - English model, which you will need to subscribe to.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/marketplace/pp/prodview-avmxk2wxbygd6?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Marketplace: Jina Reranker v1 Base - en</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">en</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-text">Jina AI is currently offering a seven-day free trial of its models. You will still need to pay for the AWS instances that run them, but during the trial period, you don&apos;t have to pay additionally for the models.</div></div><p>When you&#x2019;ve subscribed to them, get the models&#x2019; ARNs for your AWS region and store them in the variable names <code>embedding_package_arn</code> and <code>reranker_package_arn</code> respectively. The code in this tutorial will reference them using those variable names.</p><p>If you don&#x2019;t know how to get the ARNs, put your Amazon region name into the variable <code>region</code> and use the following code:</p><pre><code class="language-python">region = os.environ[&quot;AWS_DEFAULT_REGION&quot;]

def get_arn_for_model(region_name, model_name):
    model_package_map = {
        &quot;us-east-1&quot;: f&quot;arn:aws:sagemaker:us-east-1:253352124568:model-package/{model_name}&quot;,
        &quot;us-east-2&quot;: f&quot;arn:aws:sagemaker:us-east-2:057799348421:model-package/{model_name}&quot;,
        &quot;us-west-1&quot;: f&quot;arn:aws:sagemaker:us-west-1:382657785993:model-package/{model_name}&quot;,
        &quot;us-west-2&quot;: f&quot;arn:aws:sagemaker:us-west-2:594846645681:model-package/{model_name}&quot;,
        &quot;ca-central-1&quot;: f&quot;arn:aws:sagemaker:ca-central-1:470592106596:model-package/{model_name}&quot;,
        &quot;eu-central-1&quot;: f&quot;arn:aws:sagemaker:eu-central-1:446921602837:model-package/{model_name}&quot;,
        &quot;eu-west-1&quot;: f&quot;arn:aws:sagemaker:eu-west-1:985815980388:model-package/{model_name}&quot;,
        &quot;eu-west-2&quot;: f&quot;arn:aws:sagemaker:eu-west-2:856760150666:model-package/{model_name}&quot;,
        &quot;eu-west-3&quot;: f&quot;arn:aws:sagemaker:eu-west-3:843114510376:model-package/{model_name}&quot;,
        &quot;eu-north-1&quot;: f&quot;arn:aws:sagemaker:eu-north-1:136758871317:model-package/{model_name}&quot;,
        &quot;ap-southeast-1&quot;: f&quot;arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{model_name}&quot;,
        &quot;ap-southeast-2&quot;: f&quot;arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{model_name}&quot;,
        &quot;ap-northeast-2&quot;: f&quot;arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{model_name}&quot;,
        &quot;ap-northeast-1&quot;: f&quot;arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{model_name}&quot;,
        &quot;ap-south-1&quot;: f&quot;arn:aws:sagemaker:ap-south-1:077584701553:model-package/{model_name}&quot;,
        &quot;sa-east-1&quot;: f&quot;arn:aws:sagemaker:sa-east-1:270155090741:model-package/{model_name}&quot;,
    }

    return model_package_map[region_name]

embedding_package_arn = get_arn_for_model(region, &quot;jina-embeddings-v2-base-en&quot;)
reranker_package_arn = get_arn_for_model(region, &quot;jina-reranker-v1-base-en&quot;)
</code></pre><h2 id="load-the-dataset">Load the Dataset</h2><p>In this tutorial, we are going to use a collection of videos provided by the YouTube channel <a href="https://www.youtube.com/@tudelftonlinelearning1226?ref=jina-ai-gmbh.ghost.io">TU Delft Online Learning</a>. This channel produces a variety of educational materials in STEM subjects. Its programming is <a href="https://creativecommons.org/licenses/by/3.0/legalcode?ref=jina-ai-gmbh.ghost.io">CC-BY licensed</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.youtube.com/@tudelftonlinelearning1226?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">TU Delft Online Learning</div><div class="kg-bookmark-description">Are you looking to make your career in science, design or engineering? Then join the community of online learners at TU Delft!
At TU Delft, online learning means active learning. Our courses are designed to provide you with an engaging learning experience. Course content is challenging and demanding, promoting your personal growth and professional development, while enjoying the flexibility and accessibility that our online courses offers so you can combine learning with other priorities of your life. Start learning today: https://online-learning.tud&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.youtube.com/s/desktop/4feff1e2/img/favicon_144x144.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">YouTube</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://yt3.googleusercontent.com/ytc/AIdro_kH5d18Xqqj-MKv9k_tf2KNFufCpMY8qEXdQzEy=s900-c-k-c0x00ffffff-no-rj" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>We downloaded 193 videos from the channel and processed them with OpenAI&#x2019;s open-source <a href="https://openai.com/research/whisper?ref=jina-ai-gmbh.ghost.io">Whisper speech recognition model</a>. We used the smallest model <a href="https://huggingface.co/openai/whisper-tiny?ref=jina-ai-gmbh.ghost.io" rel="noreferrer"><code>openai/whisper-tiny</code></a> to process the videos into transcripts.</p><p>The transcripts have been organized into a CSV file, which you can <a href="https://raw.githubusercontent.com/jina-ai/workshops/main/notebooks/embeddings/sagemaker/tu_delft.csv?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">download from here</a>.</p><p>Each row of the file contains:</p><ul><li>The video title</li><li>The video URL on YouTube</li><li>A text transcript of the video</li></ul><p>To load this data in Python, first install <code>pandas</code> and <code>requests</code>:</p><pre><code class="language-bash">pip install requests pandas
</code></pre><p>Load the CSV data directly into a Pandas DataFrame named <code>tu_delft_dataframe</code>:</p><pre><code class="language-python">import pandas

# Load the CSV file
tu_delft_dataframe = pandas.read_csv(&quot;https://raw.githubusercontent.com/jina-ai/workshops/feat-sagemaker-post/notebooks/embeddings/sagemaker/tu_delft.csv&quot;)
</code></pre><p>You can inspect the contents using the DataFrame&apos;s <code>head()</code> method. In a notebook, it should look something like this:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Screenshot-2024-03-15-at-14.30.35.png" class="kg-image" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker" loading="lazy" width="1440" height="580" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/Screenshot-2024-03-15-at-14.30.35.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/Screenshot-2024-03-15-at-14.30.35.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/03/Screenshot-2024-03-15-at-14.30.35.png 1440w" sizes="(min-width: 720px) 720px"></figure><p>You can also watch the videos by using the URLs given in this dataset and verify that the speech recognition is imperfect but basically sound.</p><h2 id="start-the-jina-embeddings-v2-endpoint">Start the Jina Embeddings v2 Endpoint</h2><p>The code below will launch an instance of <code>ml.g4dn.xlarge</code> on AWS to run the embedding model. It may take several minutes for this to finish.</p><pre><code class="language-python">import boto3
from jina_sagemaker import Client

# Choose a name for your embedding endpoint. It can be anything convenient.
embeddings_endpoint_name = &quot;jina_embedding&quot;

embedding_client = Client(region_name=boto3.Session().region_name)
embedding_client.create_endpoint(
    arn=embedding_package_arn,
    role=role,
    endpoint_name=embeddings_endpoint_name,
    instance_type=&quot;ml.g4dn.xlarge&quot;,
    n_instances=1,
)

embedding_client.connect_to_endpoint(endpoint_name=embeddings_endpoint_name)
</code></pre><p>Change the <code>instance_type</code> to select a different AWS cloud instance type if appropriate.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x26A0;&#xFE0F;</div><div class="kg-callout-text">AWS will bill you for your time starting as soon as this command returns. You will be billed by the hour until you stop this instance. To do so, follow the instructions in the section <a href="#shutting-down" rel="noreferrer"><b><strong style="white-space: pre-wrap;">Shutting Down</strong></b></a>.</div></div><h2 id="build-and-index-the-dataset">Build and Index the Dataset</h2><p>Now that we have loaded the data and are running a Jina Embeddings v2 model, we can prepare and index the data. We will store the data in a <a href="https://faiss.ai/index.html?ref=jina-ai-gmbh.ghost.io">FAISS vector store</a>, an open-source vector database specifically designed for AI applications.</p><p>First, install the remaining prerequisites for our RAG application:</p><pre><code class="language-bash">pip install tdqm numpy faiss-cpu
</code></pre><h3 id="chunking">Chunking</h3><p>We will need to take the individual transcripts and split them up into smaller parts, i.e., &#x201C;chunks,&#x201D; so that we can fit multiple texts into a prompt for the LLM. The code below breaks the individual transcripts up on sentence boundaries, ensuring that all chunks have no more than 128 words by default.</p><pre><code class="language-python">def chunk_text(text, max_words=128):
    &quot;&quot;&quot;
    Divide text into chunks where each chunk contains the maximum number 
    of full sentences with fewer words than `max_words`.
    &quot;&quot;&quot;
    sentences = text.split(&quot;.&quot;)
    chunk = []
    word_count = 0

    for sentence in sentences:
        sentence = sentence.strip(&quot;.&quot;)
        if not sentence:
          continue

        words_in_sentence = len(sentence.split())
        if word_count + words_in_sentence &lt;= max_words:
            chunk.append(sentence)
            word_count += words_in_sentence
        else:
            # Yield the current chunk and start a new one
            if chunk:
              yield &quot;. &quot;.join(chunk).strip() + &quot;.&quot;
            chunk = [sentence]
            word_count = words_in_sentence

    # Yield the last chunk if it&apos;s not empty
    if chunk:
        yield &quot; &quot;.join(chunk).strip() + &quot;.&quot;</code></pre><h3 id="get-embeddings-for-each-chunk">Get Embeddings for Each Chunk</h3><p>We need an embedding for each chunk to store it in the FAISS database. To get them, we pass the text chunks to the Jina AI embedding model endpoint, using the method <code>embedding_client.embed()</code>. Then, we add the text chunks and embedding vectors to the pandas dataframe <code>tu_delft_dataframe</code> as the new columns <code>chunks</code> and <code>embeddings</code>:</p><pre><code class="language-python">import numpy as np
from tqdm import tqdm

tqdm.pandas()

def generate_embeddings(text_df):
    chunks = list(chunk_text(text_df[&quot;Text&quot;]))
    embeddings = []

    for i, chunk in enumerate(chunks):
      response = embedding_client.embed(texts=[chunk])
      chunk_embedding = response[0][&quot;embedding&quot;]
      embeddings.append(np.array(chunk_embedding))

    text_df[&quot;chunks&quot;] = chunks
    text_df[&quot;embeddings&quot;] = embeddings
    return text_df

print(&quot;Embedding text chunks ...&quot;)
tu_delft_dataframe = generate_embeddings(tu_delft_dataframe)
## if you are using Google Colab or a Python notebook, you can 
## delete the line above and uncomment the following line instead:
# tu_delft_dataframe = tu_delft_dataframe.progress_apply(generate_embeddings, axis=1)
</code></pre><h3 id="set-up-semantic-search-using-faiss">Set Up Semantic Search Using Faiss</h3><p>The code below creates a FAISS database and inserts the chunks and embedding vectors by iterating over <code>tu_delft_pandas</code>:</p><pre><code class="language-python">import faiss

dim = 768  # dimension of Jina v2 embeddings
index_with_ids = faiss.IndexIDMap(faiss.IndexFlatIP(dim))
k = 0

doc_ref = dict()

for idx, row in tu_delft_dataframe.iterrows():
    embeddings = row[&quot;embeddings&quot;]
    for i, embedding in enumerate(embeddings):
        normalized_embedding = np.ascontiguousarray(np.array(embedding, dtype=&quot;float32&quot;).reshape(1, -1))
        faiss.normalize_L2(normalized_embedding)
        index_with_ids.add_with_ids(normalized_embedding, k)
        doc_ref[k] = (row[&quot;chunks&quot;][i], idx)
        k += 1
</code></pre><h2 id="start-the-jina-reranker-v1-endpoint">Start the Jina Reranker v1 Endpoint</h2><p> As with the Jina Embedding v2 model above, this code will launch an instance of <code>ml.g4dn.xlarge</code> on AWS to run the reranker model. Similarly, it may take several minutes to run.</p><pre><code class="language-python">import boto3
from jina_sagemaker import Client

# Choose a name for your reranker endpoint. It can be anything convenient.
reranker_endpoint_name = &quot;jina_reranker&quot;

reranker_client = Client(region_name=boto3.Session().region_name)
reranker_client.create_endpoint(
    arn=reranker_package_arn,
    role=role,
    endpoint_name=reranker_endpoint_name,
    instance_type=&quot;ml.g4dn.xlarge&quot;,
    n_instances=1,
)

reranker_client.connect_to_endpoint(endpoint_name=reranker_endpoint_name)
</code></pre><h2 id="define-query-functions">Define Query Functions</h2><p>Next, we will define a function that identifies the most similar transcript chunks to any text query.</p><p>This is a two-step process:</p><ol><li>Convert user input into an embedding vector using the method <code>embedding_client.embed()</code>, just like we did in the data preparation stage.</li><li>Pass the embedding to the FAISS index to retrieve the best matches. In the function below, the default is to return the 20 best matches, but you can control this with the <code>n</code> parameter.</li></ol><p>The function <code>find_most_similar_transcript_segment</code> will return the best matches by comparing the cosines of the stored embeddings to the query embedding.</p><pre><code class="language-python">def find_most_similar_transcript_segment(query, n=20):
    query_embedding = embedding_client.embed(texts=[query])[0][&quot;embedding&quot;]  # Assuming the query is short enough to not need chunking
    query_embedding = np.ascontiguousarray(np.array(query_embedding, dtype=&quot;float32&quot;).reshape(1, -1))
    faiss.normalize_L2(query_embedding)

    D, I = index_with_ids.search(query_embedding, n)  # Get the top n matches

    results = []
    for i in range(n):
        distance = D[0][i]
        index_id = I[0][i]
        transcript_segment, doc_idx = doc_ref[index_id]
        results.append((transcript_segment, doc_idx, distance))

    # Sort the results by distance
    results.sort(key=lambda x: x[2])

    return [(tu_delft_dataframe.iloc[r[1]][&quot;Title&quot;].strip(), r[0]) for r in results]
</code></pre><p>We will also define a function that accesses the reranker endpoint <code>reranker_client</code>, passes it the results from <code>find_most_similar_transcript_segment</code>, and returns just the three most relevant results. It calls the reranker endpoint with the method <code>reranker_client.rerank()</code>.</p><pre><code class="language-python">def rerank_results(query_found, query, n=3):
    ret = reranker_client.rerank(
        documents=[f[1] for f in query_found], 
        query=query, 
        top_n=n,
    )
    return [query_found[r[&apos;index&apos;]] for r in ret[0][&apos;results&apos;]]
</code></pre><h2 id="use-jumpstart-to-load-mistral-instruct">Use JumpStart to Load Mistral-Instruct</h2><p>For this tutorial, we will use the <code>mistral-7b-instruct</code> model, which is <a href="https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/?ref=jina-ai-gmbh.ghost.io">available via Amazon SageMaker JumpStart</a>, as the LLM portion of the RAG system.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Mistral 7B foundation models from Mistral AI are now available in Amazon SageMaker JumpStart | Amazon Web Services</div><div class="kg-bookmark-description">Today, we are excited to announce that the Mistral 7B foundation models, developed by Mistral AI, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. With 7 billion parameters, Mistral 7B can be easily customized and quickly deployed. You can try out this model with SageMaker JumpStart, a [&#x2026;]</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://a0.awsstatic.com/main/images/site/touch-icon-ipad-144-smile.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"><span class="kg-bookmark-author">Amazon Web Services</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/mistral-7b-sagemaker-jumpstart.jpg" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>Run the following code to load and deploy Mistral-Instruct:</p><pre><code class="language-python">from sagemaker.jumpstart.model import JumpStartModel

jumpstart_model = JumpStartModel(model_id=&quot;huggingface-llm-mistral-7b-instruct&quot;, role=role)
model_predictor = jumpstart_model.deploy()
</code></pre><p>The endpoint to access this LLM is stored in the variable <code>model_predictor</code>.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x26A0;&#xFE0F;</div><div class="kg-callout-text">Using this model is also a billable service for AWS, so do not forget to shut it off when you finish with this tutorial. See the section <a href="#shutting-down" rel="noreferrer"><b><strong style="white-space: pre-wrap;">Shutting Down</strong></b></a> to stop this deployment when done.</div></div><h3 id="mistral-instruct-with-jumpstart">Mistral-Instruct with JumpStart</h3><p>Below is the code to create a prompt template for Mistral-Instruct for this application using <a href="https://docs.python.org/3/library/string.html?ref=jina-ai-gmbh.ghost.io#template-strings">Python&#x2019;s built-in string template class</a>. It assumes that for each query there are three matching transcript chunks that will be presented to the model.</p><p>You can experiment with this template yourself to modify this application or see if you can get better results.</p><pre><code class="language-python">from string import Template

prompt_template = Template(&quot;&quot;&quot;
  &lt;s&gt;[INST] Answer the question below only using the given context.
  The question from the user is based on transcripts of videos from a YouTube
    channel.
  The context is presented as a ranked list of information in the form of
    (video-title, transcript-segment), that is relevant for answering the
    user&apos;s question.
  The answer should only use the presented context. If the question cannot be
    answered based on the context, say so.

  Context:
  1. Video-title: $title_1, transcript-segment: $segment_1
  2. Video-title: $title_2, transcript-segment: $segment_2
  3. Video-title: $title_3, transcript-segment: $segment_3

  Question: $question

  Answer: [/INST]
&quot;&quot;&quot;)
</code></pre><p>With this component in place, we now have all the parts of a complete RAG application.</p><h2 id="querying-the-model">Querying the Model</h2><p>Querying the model is a three-step process.</p><ol><li>Search for relevant chunks given a query.</li><li>Assemble the prompt.</li><li>Send the prompt to the Mistral-Instruct model and return its answer.</li></ol><p>To search for relevant chunks, we use the <code>find_most_similar_transcript_segment</code> function we defined above.</p><pre><code class="language-python">question = &quot;When was the first offshore wind farm commissioned?&quot;
search_results = find_most_similar_transcript_segment(question)
reranked_results = rerank_results(search_results, question)
</code></pre><p>You can inspect the search results in reranked order:</p><pre><code class="language-python">for title, text, _ in reranked_results:
    print(title + &quot;\n&quot; + text + &quot;\n&quot;)
</code></pre><p>Result:</p><pre><code class="language-text">Offshore Wind Farm Technology - Course Introduction
Since the first offshore wind farm commissioned in 1991 in Denmark, scientists and engineers have adapted and improved the technology of wind energy to offshore conditions.  This is a rapidly evolving field with installation of increasingly larger wind turbines in deeper waters.  At sea, the challenges are indeed numerous, with combined wind and wave loads, reduced accessibility and uncertain-solid conditions.  My name is Axel Vire, I&apos;m an assistant professor in Wind Energy at U-Delf and specializing in offshore wind energy.  This course will touch upon the critical aspect of wind energy, how to integrate the various engineering disciplines involved in offshore wind energy.  Each week we will focus on a particular discipline and use it to design and operate a wind farm.

Offshore Wind Farm Technology - Course Introduction
I&apos;m a researcher and lecturer at the Wind Energy and Economics Department and I will be your moderator throughout this course.  That means I will answer any questions you may have.  I&apos;ll strengthen the interactions between the participants and also I&apos;ll get you in touch with the lecturers when needed.  The course is mainly developed for professionals in the field of offshore wind energy.  We want to broaden their knowledge of the relevant technical disciplines and their integration.  Professionals with a scientific background who are new to the field of offshore wind energy will benefit from a high-level insight into the engineering aspects of wind energy.  Overall, the course will help you make the right choices during the development and operation of offshore wind farms.

Offshore Wind Farm Technology - Course Introduction
Designed wind turbines that better withstand wind, wave and current loads  Identify great integration strategies for offshore wind turbines and gain understanding of the operational and maintenance of offshore wind turbines and farms  We also hope that you will benefit from the course and from interaction with other learners who share your interest in wind energy  And therefore we look forward to meeting you online.
</code></pre><p>We can use this information directly in the prompt template:</p><pre><code class="language-python">prompt_for_llm = prompt_template.substitute(
    question = question,
    title_1 = search_results[0][0],
    segment_1 = search_results[0][1],
    title_2 = search_results[1][0],
    segment_2 = search_results[1][1],
    title_3 = search_results[2][0],
    segment_3 = search_results[2][1],
)
</code></pre><p>Print the resulting string to see what prompt is actually sent to the LLM:</p><pre><code class="language-python">print(prompt_for_llm)
</code></pre><pre><code class="language-text">&lt;s&gt;[INST] Answer the question below only using the given context.
  The question from the user is based on transcripts of videos from a YouTube
    channel.
  The context is presented as a ranked list of information in the form of
    (video-title, transcript-segment), that is relevant for answering the
    user&apos;s question.
  The answer should only use the presented context. If the question cannot be
    answered based on the context, say so.

  Context:
  1. Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: Since the first offshore wind farm commissioned in 1991 in Denmark, scientists and engineers have adapted and improved the technology of wind energy to offshore conditions.  This is a rapidly evolving field with installation of increasingly larger wind turbines in deeper waters.  At sea, the challenges are indeed numerous, with combined wind and wave loads, reduced accessibility and uncertain-solid conditions.  My name is Axel Vire, I&apos;m an assistant professor in Wind Energy at U-Delf and specializing in offshore wind energy.  This course will touch upon the critical aspect of wind energy, how to integrate the various engineering disciplines involved in offshore wind energy.  Each week we will focus on a particular discipline and use it to design and operate a wind farm.
  2. Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: For example, we look at how to characterize the wind and wave conditions at a given location.  How to best place the wind turbines in a farm and also how to retrieve the electricity back to shore.  We look at the main design drivers for offshore wind turbines and their components.  We&apos;ll see how these aspects influence one another and the best choices to reduce the cost of energy.  This course is organized by the two-delfd wind energy institute, an interfaculty research organization focusing specifically on wind energy.  You will therefore benefit from the expertise of the lecturers in three different faculties of the university.  Aerospace engineering, civil engineering and electrical engineering.  Hi, my name is Ricardo Pareda.
  3. Video-title: Systems Analysis for Problem Structuring part 1B the mono actor perspective example, transcript-segment: So let&apos;s assume the demarcation of the problem and the analysis of objectives has led to the identification of three criteria.  The security of supply, the percentage of offshore power generation and the costs of energy provision.  We now reason backwards to explore what factors have an influence on these system outcomes.  Really, the offshore percentage is positively influenced by the installed Wind Power capacity at sea, a key system factor.  Capacity at sea in turn is determined by both the size and the number of wind farms at sea.  The Ministry of Economic Affairs cannot itself invest in new wind farms but hopes to simulate investors and energy companies by providing subsidies and by expediting the granting process of licenses as needed.

  Question: When was the first offshore wind farm commissioned?

  Answer: [/INST]
</code></pre><p>Pass this prompt to the LLM endpoint &#x2014; <code>model_predictor</code> &#x2014; via the method <code>model_predictor.predict()</code>:</p><pre><code class="language-python">answer = model_predictor.predict({&quot;inputs&quot;: prompt_for_llm})
</code></pre><p>This returns a list, but since we only passed in one prompt, it will be a list with one entry. Each entry is a <code>dict</code> with the response text under the key <code>generated_text</code>:</p><pre><code class="language-python">answer = answer[0][&apos;generated_text&apos;]
print(answer)
</code></pre><p>Result:</p><pre><code class="language-text">The first offshore wind farm was commissioned in 1991. (Context: Video-title: Offshore Wind Farm Technology - Course Introduction, transcript-segment: Since the first offshore wind farm commissioned in 1991 in Denmark, ...)
</code></pre><p>Let&#x2019;s simplify querying by writing a function to do all the steps: taking the string question as a parameter and returning the answer as a string:</p><pre><code class="language-python">def ask_rag(question):
    search_results = find_most_similar_transcript_segment(question)
    reranked_results = rerank_results(search_results, question)
    prompt_for_llm = prompt_template.substitute(
        question = question,
        title_1 = search_results[0][0],
        segment_1 = search_results[0][1],
        title_2 = search_results[1][0],
        segment_2 = search_results[1][1],
        title_3 = search_results[2][0],
        segment_3 = search_results[2][1],
    )
    answer = model_predictor.predict({&quot;inputs&quot;: prompt_for_llm})
    return answer[0][&quot;generated_text&quot;]
</code></pre><p>Now we can ask it a few more questions. Answers will depend on the content of the video transcripts. For example, we can ask detailed questions when the answer is present in the data and get an answer:</p><pre><code class="language-python">ask_rag(&quot;What is a Kaplan Meyer estimator?&quot;)
</code></pre><pre><code class="language-text">The Kaplan Meyer estimator is a non-parametric estimator for the survival 
function, defined for both censored and not censored data. It is represented 
as a series of declining horizontal steps that approaches the truths of the 
survival function if the sample size is sufficiently large enough. The value 
of the empirical survival function obtained is assumed to be constant between 
two successive distinct observations.
</code></pre><pre><code class="language-python">ask_rag(&quot;Who is Reneville Solingen?&quot;)
</code></pre><pre><code class="language-text">Reneville Solingen is a professor at Delft University of Technology in Global 
Software Engineering. She is also a co-author of the book &quot;The Power of Scrum.&quot;
</code></pre><pre><code class="language-python">answer = ask_rag(&quot;What is the European Green Deal?&quot;)
print(answer)
</code></pre><pre><code class="language-text">The European Green Deal is a policy initiative by the European Union to combat 
climate change and decarbonize the economy, with a goal to make Europe carbon 
neutral by 2050. It involves the use of green procurement strategies in various 
sectors, including healthcare, to reduce carbon emissions and promote corporate 
social responsibility.
</code></pre><p>We can also ask questions that are outside of the scope of the available information:</p><pre><code class="language-python">ask_rag(&quot;What countries export the most coffee?&quot;)
</code></pre><pre><code class="language-text">Based on the context provided, there is no clear answer to the user&apos;s 
question about which countries export the most coffee as the context 
only discusses the Delft University&apos;s cafeteria discounts and sustainable 
coffee options, as well as lithium production and alternatives for use in 
electric car batteries.
</code></pre><pre><code class="language-python">ask_rag(&quot;How much wood could a woodchuck chuck if a woodchuck could chuck wood?&quot;)
</code></pre><pre><code class="language-text">The context does not provide sufficient information to answer the question. 
The context is about thermit welding of rails, stress concentration factors, 
and a lyrics video. There is no mention of woodchucks or the ability of 
woodchuck to chuck wood in the context.
</code></pre><p>Try your own queries. You can also change the way the LLM is prompted to see if that improves your results.</p><h2 id="shutting-down">Shutting Down</h2><p>Because you are billed by the hour for the models you use and for the AWS infrastructure to run them, it is very important to stop all three AI models when you finish this tutorial:</p><ul><li>The embedding model endpoint <code>embedding_client</code></li><li>The reranker model endpoint <code>reranker_client</code></li><li>The large language model endpoint <code>model_predictor</code></li></ul><p>To shut down all three model endpoints, run the following code:</p><pre><code class="language-python"># shut down the embedding endpoint
embedding_client.delete_endpoint()
embedding_client.close()
# shut down the reranker endpoint
reranker_client.delete_endpoint()
reranker_client.close()
# shut down the LLM endpoint
model_predictor.delete_model()
model_predictor.delete_endpoint()
</code></pre><h2 id="get-started-now-with-jina-ai-models-on-aws-marketplace">Get Started Now with Jina AI Models on AWS Marketplace</h2><p>With our embedding and reranking models on SageMaker, enterprise AI users on AWS now have instant access to Jina AI&#x2019;s outstanding value proposition without compromising the benefits of their existing cloud operations. All the security, reliability, consistency, and predictable pricing of AWS comes built-in.</p><p>At Jina AI, we are working hard to bring the state-of-the-art to businesses that can benefit from bringing AI into their existing processes. We strive to offer solid, reliable, high-performance models at accessible prices via convenient and practical interfaces, minimizing your investments in AI while maximizing your returns.</p><p>Check out <a href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io">Jina AI&#x2019;s AWS Marketplace page</a> for a list of all embeddings and reranker models that we offer and to try our models free for seven days.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aws.amazon.com/marketplace/seller-profile?id=seller-stch2ludm6vgy&amp;ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">AWS Marketplace: Jina AI</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/favicon.ico" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></div><div class="kg-bookmark-thumbnail"><img src="https://d32gc0xr2ho6pa.cloudfront.net/img/general/v2/socialPreview.png" alt="Next-Level Cloud AI:  Jina Embeddings and Rerankers on Amazon SageMaker"></div></a></figure><p>We would love to hear about your use cases and talk about how Jina AI&#x2019;s products can fit your business needs. Contact us via <a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io">our website</a> or our&#xA0;<a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io">Discord channel</a>&#xA0;to share your feedback and stay up-to-date with our latest models.</p>]]></content:encoded></item><item><title><![CDATA[Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media]]></title><description><![CDATA[See how PromptPerfect can level up your LLM prompting and optimize your email and social media marketing campaigns.]]></description><link>https://jina.ai/news/click-worthy-content-with-promptperfect-ai-marketing-for-newsletters-and-social-media/</link><guid isPermaLink="false">65facf57502fd000011c66d5</guid><category><![CDATA[Knowledge Base]]></category><dc:creator><![CDATA[Alex C-G]]></dc:creator><pubDate>Wed, 20 Mar 2024 15:00:42 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/PP-for-marketers.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/PP-for-marketers.jpg" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"><p>Generative AI and Large Language Models (LLMs) like GPT-4 have revolutionized digital marketing content, offering unparalleled speed and scale. However, as more companies and prompt engineers jump on the Generative AI bandwagon, the true magic lies not in the tool itself but in how we wield it. Think of LLM prompts as magic spells: a poorly crafted prompt yields mediocre results, akin to a novice wizard&apos;s hesitant incantation. In contrast, a well-optimized prompt can unleash the full potential of the LLM, mirroring the prowess of a master sorcerer commanding the elements.</p><p>But you don&apos;t need to be a dedicated prompt engineer to conjure up an effective prompt. PromptPerfect Interactive is the wand that lets <em>anyone</em> fine-tune their spells, ensuring every piece of content, from social media posts to newsletters, is not just created but perfectly crafted to captivate and engage customers.</p><p>To help make the AI marketing magic happen, we recently launched <a href="https://jina.ai/news/get-more-with-promptperfect-improved-subscription-choices-cutting-edge-interactive-optimizer/?ref=jina-ai-gmbh.ghost.io">PromptPerfect&apos;s new interactive feature</a>, marking a significant evolution in our platform.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/get-more-with-promptperfect-improved-subscription-choices-cutting-edge-interactive-optimizer?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer</div><div class="kg-bookmark-description">More cost-effective monthly subscription models and brand new interactive optimizer in PromptPerfect&#x2019;s latest release.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"><span class="kg-bookmark-publisher">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/3.jpg" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"></div></a></figure><p>&quot;Interactive&quot; revolutionizes content generation with LLMs. Two components lie at the heart of this feature: a Dedicated Assistant and a Powerful Optimizer. The Assistant acts as an AI companion, attuned to your specific needs, assisting in crafting effective prompts that make content generation effortless. Simultaneously, the Optimizer engineers your LLM prompts to ensure optimal results, boosting the effectiveness of your creative efforts. Designed to simplify and enhance AI-powered content creation and problem-solving, the Interactive feature makes it more intuitive and accessible to generate compelling narratives, devise innovative solutions, or boost productivity. With PromptPerfect Interactive, elevating your email marketing and social media becomes not just a possibility but a seamless reality.</p><h2 id="content-creation-made-easy">Content Creation Made Easy</h2><h3 id="crafting-messages-with-precision">Crafting Messages with Precision</h3><p>Marketers can dial in the specifics of their message, making sure that every word speaks directly to their audience&apos;s desires and interests. This makes it easier to generate content that not only fits your brand&apos;s voice but also addresses the nuances of what your customer expects and appreciates, whether that&apos;s in the tone, style, or substance of the message.</p><h3 id="tailoring-for-your-customers">Tailoring for Your Customers</h3><p>The power of a well-optimized LLM prompt goes beyond just generating text&#x2014;it&apos;s about creating a connection. By leveraging PromptPerfect to tailor prompts, you can produce more personalized, relevant content. This personal touch is what turns general information into engaging stories that resonate with potential customers, encouraging interaction and building stronger relationships through social media marketing and newsletters.</p><h2 id="streamlining-campaigns">Streamlining Campaigns</h2><h3 id="enhancing-productivity">Enhancing Productivity</h3><p>The Interactive feature acts as a force multiplier for marketing efforts, streamlining the content creation process to allow more time for strategic planning and execution. By transforming the efficiency with which content is produced, marketers can reallocate their focus towards fine-tuning campaigns and analyzing performance, ultimately driving better outcomes.</p><h3 id="differentiating-your-brand">Differentiating Your Brand</h3><p>In the crowded digital space, brand awareness out is more important than ever. With the new PromptPerfect update, you can ensure your marketing campaign is not just seen but remembered. Optimizing LLM prompts to produce unique and compelling content helps brands rise above the noise, making every social media post and newsletter an opportunity to showcase what makes them special.</p><h2 id="making-the-magic-happen-promptperfect-in-action">Making the Magic Happen: PromptPerfect in action</h2><p>Let&apos;s see how Lisa, our marketing manager at Jina AI, uses PromptPerfect Interactive to craft a compelling newsletter.</p><p>There are three members in this conversation:</p><ul><li><strong>&#x1F9D1;&#x200D;&#x1F9B0; Jina AI&apos;s senior marketing manager: </strong>Lisa herself.</li><li><strong>&#x1F916; PromptPerfect&apos;s Optimizer: </strong>An advanced AI tool that fine-tunes your prompts for optimal results.</li><li><strong>&#x1F4AC; PromptPerfect&apos;s Assistant: </strong>An LLM companion that understands your needs and helps you craft effective prompts.</li></ul><hr><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F9D1;&#x200D;&#x1F9B0;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Lisa</strong></b><br><br>We are creating a new feature for Jina AI&apos;s PromptPerfect, called PromptPerfect Interactive.<br><br>Feature description: The feature is crafted to empower users to generate text and images tailored to a multitude of use cases, ranging from YouTube scripts to AI art. The hallmark of this tool is its integrated prompt optimizer chatbot, which not only refines prompts for optimal results but also serves as a collaborative partner. Users can invoke the assistant chat to produce creative content, leveraging the familiar conversational interface to generate rich text and vivid images. The prompt optimizer chat bot is a revolutionary tool that assists users in refining and brainstorming prompts, ensuring that the AI understands the user&apos;s intent with precision. Beyond optimization, the prompt optimizer chatbot acts as a brainstorming ally, guiding users towards crafting prompts that yield the most effective outcomes.<br><br>I will need a prompt for generating a marketing email for the users of PromptPerfect, to announce PromptPerfect Interactive.</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>Here is a prompt you can use to generate a marketing email announcing PromptPerfect Interactive to PromptPerfect users:</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>As a marketing specialist at Jina AI, craft a compelling email to announce the launch of PromptPerfect Interactive, an exciting new feature for PromptPerfect. The email should be written in an engaging and enthusiastic tone, highlighting the key features and benefits of PromptPerfect Interactive, as described below:<br><br>```<br>The feature is crafted to empower users to generate text and images tailored to a multitude of use cases, ranging from YouTube scripts to AI art. The hallmark of this tool is its integrated prompt optimizer chatbot, which not only refines prompts for optimal results but also serves as a collaborative partner. Users can invoke the assistant chat to produce creative content, leveraging the familiar conversational interface to generate rich text and vivid images. The prompt optimizer chat bot is a revolutionary tool that assists users in refining and brainstorming prompts, ensuring that the AI understands the user&apos;s intent with precision. Beyond optimization, the prompt optimizer chatbot acts as a brainstorming ally, guiding users towards crafting prompts that yield the most effective outcomes.<br>```<br><br>The email should be structured as follows:<br>1. An attention-grabbing subject line that creates excitement about the new feature launch<br>2. A brief introduction that highlights the user&apos;s familiarity with PromptPerfect and the team&apos;s commitment to continually improving their experience<br>3. A detailed overview of PromptPerfect Interactive, focusing on its key features and how it will enhance the user&apos;s prompt engineering workflow<br>4. A clear call-to-action encouraging users to try out PromptPerfect Interactive and share their feedback<br>5. A closing statement expressing gratitude for the user&apos;s continued support and trust in Jina AI&apos;s products<br><br>Ensure that the email is concise yet informative, with a conversational and relatable tone that resonates with PromptPerfect&apos;s user base.</div></div><div class="kg-card kg-callout-card kg-callout-card-purple"><div class="kg-callout-emoji">&#x1F4AC;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Assistant</strong></b><br><br>Subject: Unleash Your Creativity Like Never Before with PromptPerfect Interactive &#x1F680;<br><br>Dear Creative Minds,<br><br>As a member of the PromptPerfect family, you&apos;ve witnessed firsthand how we&apos;re transforming the way you create content. Your passion inspires us daily, and we&apos;ve taken your feedback to heart. Today, we&apos;re thrilled to lift the veil on a feature that&apos;s been brewing with innovation and creativity&#x2014;PromptPerfect Interactive!<br><br>&#x1F31F; Introducing PromptPerfect Interactive: Where brilliance meets intuitiveness! This groundbreaking tool is meticulously designed to fuel your imagination and streamline your content generation. Whether it&apos;s captivating YouTube scripts or stunning AI-generated art, PromptPerfect Interactive is your go-to resource for content mastery.<br><br>&#x1F50D; Key Features:<br><br>&#x2022; Integrated Prompt Optimizer Chatbot: Struggle with prompts no more! Our chatbot collaborates with you to refine and perfect your prompts, ensuring the AI captures the essence of your vision.<br>&#x2022; Conversational Interface: Creativity should be a conversation, not a command. Engage with our assistant in a natural chat flow to unleash powerful text and vibrant images.<br>&#x2022; Brainstorming Buddy: Never face creative blocks again. Our chatbot not only refines but brainstorm ideas with you, sparking content that resonates and captivates.<br><br>PromptPerfect Interactive is revolutionizing the prompt engineering process, making it more human, more collaborative, and infinitely more powerful. It&apos;s not just an enhancement to your workflow; it&apos;s the partner you&#x2019;ve always needed in your creative endeavors.<br><br>&#x1F64C; Ready to dive in? We invite you to experience the magic of PromptPerfect Interactive and see what new heights of creativity you can reach. Get started now and let your imagination soar. Don&#x2019;t forget to share your masterpieces and thoughts with us&#x2014;your input is the compass that guides our innovation.<br><br>Thank you for choosing Jina AI and for your unwavering trust in our mission to redefine creativity. Together, let&apos;s continue to push the boundaries and craft the future of content creation.<br><br>With Warmest Regards,<br><br>The PromptPerfect Team at Jina AI<br><br>P.S. We&apos;re not stopping here&#x2014;there&apos;s a universe of possibilities we&apos;re excited to explore with you. Stay tuned for more features that will tickle your creative spirit! &#x1F30C;&#x2728;</div></div><h2 id="elevate-your-marketing-with-promptperfect">Elevate Your Marketing with PromptPerfect</h2><p>Don&apos;t miss the opportunity to be like Lisa and transform your digital marketing strategy with PromptPerfect. Sign up today to enjoy a 7-day free trial on a paid plan and receive 40% off if you subscribe within 24 hours of signing up. Elevate your content, streamline your workflow, and achieve unprecedented engagement with your audience.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Optimize Your Prompts to Perfection</div><div class="kg-bookmark-description">Unlock prompt optimization for models like GPT-4, ChatGPT and Midjourney. Deploy prompts as services with our free hosting.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/favicon-128x128.png" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"><span class="kg-bookmark-author">Optimize Your Prompts to Perfection</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"></div></a></figure><p>Join our community on Discord to connect with other generative AI and marketing professionals, share insights, and discover how they&apos;re leveraging PromptPerfect to revolutionize their marketing efforts.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4632 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://static.ghost.org/v5.0.0/images/link-icon.svg" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Click-Worthy Content with PromptPerfect: AI Marketing for Newsletters and Social Media"></div></a></figure><p>Take the first step towards transforming your marketing strategy &#x2014; experience the power of PromptPerfect Interactive now.</p>]]></content:encoded></item><item><title><![CDATA[Jina 3.24.1 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-24-1-update/</link><guid isPermaLink="false">65faf82c502fd000011c6727</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Wed, 20 Mar 2024 14:54:53 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Image-Jina-dark-1.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3241">Release Note (<code>3.24.1</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Image-Jina-dark-1.jpg" alt="Jina 3.24.1 Update"><p>This release contains 3 bug fixes.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.24.1?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Patch v3.24.1 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.24.1) Release time: 2024-03-20 09:35:52 This release contains 3 bug fixes.
&#x1F41E; Bug Fixes
Fix Flow deployment of Model with float field (#6155)
When serving a Flow with HTTP, serving&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="Jina 3.24.1 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/92970271b1d10e6cc126cf3212d3bf71b76b761180be72fe7c2d8a133ba9fe4e/jina-ai/jina/releases/tag/v3.24.1" alt="Jina 3.24.1 Update"></div></a></figure><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-flow-deployment-of-model-with-float-field-6155">Fix Flow deployment of Model with <code>float</code> field (<a href="https://github.com/jina-ai/jina/pull/6155?ref=jina-ai-gmbh.ghost.io">#6155</a>)</h3><p>When serving a Flow with <code>HTTP</code>, serving failed because the model reconstructed in the Gateway interpreted the <code>float</code> field as an array. Now the model served in the Gateway uses the correct schema.</p><h3 id="expose-only-invocations-endpoint-when-serving-withprovider-sagemaker-6152">Expose only <code>/invocations</code> endpoint when serving with <code>--provider SAGEMAKER</code> (<a href="https://github.com/jina-ai/jina/pull/6152?ref=jina-ai-gmbh.ghost.io">#6152</a>)</h3><p>When exposing an Executor with <code>SAGEMAKER</code> as the <code>provider</code> argument, only the <code>/invocations</code> endpoint should be used. However, previously all other endpoints were also exposed. This is now fixed.</p><h3 id="optional-parameters-when-typed-parameter-has-all-default-fields-6152">Optional parameters when typed parameter has all default fields (<a href="https://github.com/jina-ai/jina/pull/6152?ref=jina-ai-gmbh.ghost.io">#6152</a>)</h3><p>When using a strongly typed <code>parameters</code> argument with the Executor endpoint, even if the <code>parameters</code> model type had all fields with default values and not required, you still needed to pass an empty <code>parameters={}</code> field to the call when serving via <code>HTTP</code>. With this change, you no longer need to pass this empty dictionary.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a>)</li></ul>]]></content:encoded></item><item><title><![CDATA[Get More with PromptPerfect: Improved Subscription Choices & Cutting-Edge Interactive Optimizer]]></title><description><![CDATA[More cost-effective monthly subscription models and brand new interactive optimizer in PromptPerfect's latest release.]]></description><link>https://jina.ai/news/get-more-with-promptperfect-improved-subscription-choices-cutting-edge-interactive-optimizer/</link><guid isPermaLink="false">65f81e478ff065000146dbfd</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Alex C-G]]></dc:creator><pubDate>Mon, 18 Mar 2024 15:00:23 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/3.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/3.jpg" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"><p>We&#x2019;re thrilled to announce a significant update to PromptPerfect, marking a major leap forward in our journey to enhance your AI-powered content creation experience. This update is not just about changing how you pay but also about revolutionizing how you interact with AI to generate content and solve complex tasks. Here&#x2019;s everything you need to know about the latest enhancements to PromptPerfect.</p><h2 id="our-new-monthly-subscription-model">Our New Monthly Subscription Model</h2><p>We&#x2019;re evolving from a credit-based system to a more flexible and value-packed monthly subscription model. This new approach is designed to fit the varied needs of our users, ensuring everyone has access to our powerful AI tools without worrying about running out of credits.</p><h3 id="subscription-plans-tailored-for-you">Subscription Plans Tailored for You</h3><ul><li><strong>Standard Plan ($20/month):</strong> Ideal for daily users, offering extensive daily limits across all features.</li><li><strong>Premium Plan ($100/month):</strong> For the power users requiring higher daily usage limits to accommodate their intensive projects.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">You can try the plans for free for seven days to be sure they&apos;re the right match for you. Plus, sign up for a plan within 24 hours after your next login, and get 40% off!</div></div><h3 id="more-benefits-for-less">More Benefits for Less</h3><p>The transition to a subscription model means more accessible usage at a more affordable price point. Our goal is to provide an unmatched value that empowers you to unleash your creativity and productivity without limitations.</p><h3 id="loyalty-to-our-existing-users">Loyalty to Our Existing Users</h3><p>For our existing users who have supported us through the purchase of credits, your credits will remain valid. While new users will be onboarded into our subscription model, we assure our existing user base that their current credits are still good to use.</p><h2 id="the-interactive-feature-your-ai-powered-companion">The &quot;Interactive&quot; Feature: Your AI-Powered Companion</h2><p>With this update, we&#x2019;re excited to introduce the &#x201C;Interactive&#x201D; feature, a groundbreaking addition that transforms how you generate content and tackle complex tasks. The Interactive feature is built on a dual approach:</p><ul><li><strong>Dedicated Assistant:</strong> An AI companion that understands your needs and helps you craft effective prompts, making the content generation process as seamless as possible.</li><li><strong>Powerful Optimizer:</strong> An advanced tool that fine-tunes your prompts for optimal results, ensuring that your creative and productive endeavors are more effective than ever.</li></ul><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Optimize Your Prompts to Perfection</div><div class="kg-bookmark-description">Unlock prompt optimization for models like GPT-4, ChatGPT and Midjourney. Deploy prompts as services with our free hosting.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/apple-icon-180x180.png" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"><span class="kg-bookmark-author">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"></div></a></figure><p>This feature is designed to make AI-powered content generation and task-solving not only easier but also more intuitive. Whether you&#x2019;re looking to create compelling narratives, design innovative solutions, or simply enhance your productivity, the Interactive feature is here to guide you through.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/-P1a2o6hVc8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen title="PromptPerfect-Interactive"></iframe></figure><h2 id="explore-the-possibilities-use-cases-for-every-creative-need">Explore the Possibilities: Use Cases for Every Creative Need</h2><p>The versatility of PromptPerfect&#x2019;s new features, including our innovative Interactive feature and flexible subscription plans, opens up a world of possibilities for various users. Here&#x2019;s how different professionals and creatives can leverage PromptPerfect to transform their work:</p><h3 id="marketers">Marketers</h3><p>For marketers aiming to capture their audience&apos;s attention, PromptPerfect simplifies the creation of engaging marketing emails and compelling feature descriptions. Our AI tools can help craft personalized messages that resonate with your target demographic, streamline campaign creation, and ensure your products stand out in a crowded marketplace. Let&#x2019;s look at using PromptPerfect to write some marketing emails:</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F9D1;&#x200D;&#x1F9B0;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">User</strong></b><br><br>We are creating a new feature for Jina AI&apos;s PromptPerfect, called PromptPerfect Interactive.<br><br>Feature description: The feature is crafted to empower users to generate text and images tailored to a multitude of use cases, ranging from YouTube scripts to AI art. The hallmark of this tool is its integrated prompt optimizer chatbot, which not only refines prompts for optimal results but also serves as a collaborative partner. Users can invoke the assistant chat to produce creative content, leveraging the familiar conversational interface to generate rich text and vivid images. The prompt optimizer chat bot is a revolutionary tool that assists users in refining and brainstorming prompts, ensuring that the AI understands the user&apos;s intent with precision. Beyond optimization, the prompt optimizer chatbot acts as a brainstorming ally, guiding users towards crafting prompts that yield the most effective outcomes.<br><br>I will need a prompt for generating a marketing email for the users of PromptPerfect, to announce PromptPerfect Interactive.</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>Here is a prompt you can use to generate a marketing email announcing PromptPerfect Interactive to PromptPerfect users:</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>As a marketing specialist at Jina AI, craft a compelling email to announce the launch of PromptPerfect Interactive, an exciting new feature for PromptPerfect. The email should be written in an engaging and enthusiastic tone, highlighting the key features and benefits of PromptPerfect Interactive, as described below: <br><br>```<br> The feature is crafted to empower users to generate text and images tailored to a multitude of use cases, ranging from YouTube scripts to AI art. The hallmark of this tool is its integrated prompt optimizer chatbot, which not only refines prompts for optimal results but also serves as a collaborative partner. Users can invoke the assistant chat to produce creative content, leveraging the familiar conversational interface to generate rich text and vivid images. The prompt optimizer chat bot is a revolutionary tool that assists users in refining and brainstorming prompts, ensuring that the AI understands the user&apos;s intent with precision. Beyond optimization, the prompt optimizer chatbot acts as a brainstorming ally, guiding users towards crafting prompts that yield the most effective outcomes. <br>```<br><br>The email should be structured as follows: <br>1. An attention-grabbing subject line that creates excitement about the new feature launch <br>2. A brief introduction that highlights the user&apos;s familiarity with PromptPerfect and the team&apos;s commitment to continually improving their experience<br>3. A detailed overview of PromptPerfect Interactive, focusing on its key features and how it will enhance the user&apos;s prompt engineering workflow<br>4. A clear call-to-action encouraging users to try out PromptPerfect Interactive and share their feedback<br>5. A closing statement expressing gratitude for the user&apos;s continued support and trust in Jina AI&apos;s products<br><br>Ensure that the email is concise yet informative, with a conversational and relatable tone that resonates with PromptPerfect&apos;s user base.</div></div><h3 id="youtubers">YouTubers</h3><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F9D1;&#x200D;&#x1F9B0;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">User</strong></b><br><br>We are creating a new feature for Jina AI&apos;s PromptPerfect, called PromptPerfect Interactive.<br><br>Feature description:<br><br>The feature is crafted to empower users to generate text and images tailored to a multitude of use cases, ranging from YouTube scripts to AI art.<br>The hallmark of this tool is its integrated prompt optimizer chatbot, which not only refines prompts for optimal results but also serves as a collaborative partner.<br>Users can invoke the assistant chat to produce creative content, leveraging the familiar conversational interface to generate rich text and vivid images.<br>The prompt optimizer chat bot is a revolutionary tool that assists users in refining and brainstorming prompts, ensuring that the AI understands the user&apos;s intent with precision.<br>Beyond optimization, the prompt optimizer chatbot acts as a brainstorming ally, guiding users towards crafting prompts that yield the most effective outcomes. <br><br>I will need a prompt for generating a YouTube video script that announces this new feature.</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>Here&#x2019;s a prompt you can use to generate a YouTube video script announcing the new PromptPerfect Interactive feature.</div></div><div class="kg-card kg-callout-card kg-callout-card-green"><div class="kg-callout-emoji">&#x1F916;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Optimizer</strong></b><br><br>As a YouTube content creator and AI enthusiast, create an engaging video script announcing Jina AI&apos;s new PromptPerfect Interactive feature.<br><br>Introduce PromptPerfect Interactive as a groundbreaking tool that empowers users to generate tailored text and images for various use cases, from YouTube scripts to AI art.<br><br>Highlight the following key aspects of the feature:<br><br>- Integrated prompt optimizer chatbot that refines prompts for optimal results<br>- Acts as a collaborative partner for prompt engineers to craft superior prompts<br>- Enables users to generate creative content using a familiar conversational interface<br>- Assists users in brainstorming and refining prompts to ensure the AI understands and responds with precision<br><br>The script should be informative, engaging, and persuasive, encouraging viewers to try out the new feature.<br><br>Incorporate a brief demonstration of how PromptPerfect Interactive works, showcasing its user-friendly interface and the process of refining a prompt with the help of the optimizer chatbot.<br><br>Emphasize the benefits of using PromptPerfect Interactive, such as saving time, improving the quality of generated content, and unlocking new creative possibilities.<br><br>Close the script with a strong call-to-action, urging viewers to experience the power of PromptPerfect Interactive for themselves and providing a link to access the feature.<br><br>The script should be concise, aiming for a video length of 2-3 minutes, and use a conversational yet professional tone that resonates with the target audience of AI enthusiasts and content creators.</div></div><h2 id="a-new-chapter-for-promptperfect">A New Chapter for PromptPerfect</h2><p>These updates represent our commitment to providing a platform that not only meets the current needs of our users but also anticipates their future demands. The introduction of the monthly subscription model alongside the Interactive feature is a testament to our dedication to innovation and user satisfaction.</p><p>We invite you to join us in this exciting new chapter for PromptPerfect. Embrace the enhanced flexibility, value, and creativity that our updates bring to your AI-powered endeavors. Here&#x2019;s to creating, exploring, and achieving more with PromptPerfect!</p><h2 id="ready-to-elevate-your-creative-journey">Ready to Elevate Your Creative Journey?</h2><p>Join us at PromptPerfect and unlock the full potential of your creative and professional endeavors. With our new subscription model and the groundbreaking Interactive feature, you have everything you need to take your projects to the next level. Sign up for PromptPerfect today and start exploring the endless possibilities our platform offers.</p><h2 id="connect-with-our-vibrant-community">Connect with Our Vibrant Community</h2><p>Don&#x2019;t miss out on the chance to be part of our growing community. Join our Discord community to connect with fellow creatives, share your projects, get exclusive insights, and receive support from our team. It&#x2019;s the perfect place to learn, grow, and be inspired by like-minded individuals who share your passion for creativity and innovation.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Optimize Your Prompts to Perfection</div><div class="kg-bookmark-description">Unlock prompt optimization for models like GPT-4, ChatGPT and Midjourney. Deploy prompts as services with our free hosting.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/apple-icon-180x180.png" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"><span class="kg-bookmark-author">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4615 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://static.ghost.org/v5.0.0/images/link-icon.svg" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Get More with PromptPerfect: Improved Subscription Choices &amp; Cutting-Edge Interactive Optimizer"></div></a></figure><p>Embrace the future of content creation with PromptPerfect and discover how our AI-powered tools can transform your work. We can&#x2019;t wait to see what you&#x2019;ll create!</p>]]></content:encoded></item><item><title><![CDATA[How to Build Article Recommendations with Jina Reranker API Only]]></title><description><![CDATA[You can build an article recommendation system with just the Jina Reranker API—no pipeline, no embeddings, no vector search, only reranking. Find out how in 20 lines of code.]]></description><link>https://jina.ai/news/how-to-build-article-recommendations-with-jina-reranker-api-only/</link><guid isPermaLink="false">65f53dc48ff065000146db23</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Sun, 17 Mar 2024 05:38:36 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Heading--1-.png" alt="How to Build Article Recommendations with Jina Reranker API Only"><p>We introduced the <a href="https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io">Reranker API</a> two weeks ago, establishing it as a leading reranking solution in the market. Jina Reranker outperforms <a href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker?ref=jina-ai-gmbh.ghost.io">popular baselines in various benchmarks, demonstrating a significant increase of up to +33% in hit rate over BM25 results.</a> While the performance is impressive, what really excites me is the potential of the Reranker API. Its straightforward interface allows input of a query-doc list and outputs directly the reranked top-k results. This means that, in theory, one could build a search or recommendation system using solely the Reranker&#x2014;eliminating the need for BM25, embeddings, vector databases, or any pipelines, thus achieving end-to-end functionality.</p><p>This concept intrigued me so much that I felt compelled to experiment it. So there you go: now navigating to any news page of our website, such as the one you&apos;re currently reading, press the <code><strong>@</strong></code> key and click on the &quot;get top 5 related articles&quot; button, you&apos;ll receive the five articles most relevant to the current one within about 5 seconds, using the <code>jina-reranker-v1</code> model (slightly longer for the <code>jina-colbert-v1</code> model). All computations are performed online and managed entirely by the Reranker API. Below is a video demonstration of how it functions:</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://jina-ai-gmbh.ghost.io/content/media/2024/03/recommender_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://jina-ai-gmbh.ghost.io/content/media/2024/03/recommender.mp4" poster="https://img.spacergif.org/v1/1174x796/0a/spacer.png" width="1174" height="796" playsinline preload="metadata" style="background: transparent url(&apos;https://jina-ai-gmbh.ghost.io/content/media/2024/03/recommender_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:33</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">To run this demo, you will need an API key with enough tokens left. If you exhaust your quota and cannot run the demo, you can generate a new key at </span><a href="https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io" target="_new"><span style="white-space: pre-wrap;">https://jina.ai/reranker</span></a><span style="white-space: pre-wrap;">. Each new key comes with 1 million free tokens. </span></p></figcaption>
        </figure><h2 id="implementation">Implementation</h2><p>The implementation is very simple: to find the most related articles of an given article on <code>jina.ai/news/</code>, we use the article currently being read <strong>as the query</strong> and all other 230+ articles (using their full-text!) on our news site <strong>as the documents</strong>, excluding the current one of course. Then we send this $(q, d_1, d_2, \cdots, d_{230})$ as the payload to the Reranker API. Once the response is received, we use the sorted document index to display the results. Thus, the underlying code is as follows:</p><pre><code class="language-js">const getRecommendedArticles = async () =&gt; {
  
  const query = `${currentNews.title} ${currentNews.excerpt}`;
  const docs = newsStore.allBlogs.filter((item) =&gt; item.slug !== currentNews.slug);
  
  const data = {
    model: modelName,
    query: query,
    documents: docs,
    top_n: 5,
  }

  const rerankUrl = &apos;https://api.jina.ai/v1/rerank&apos;;
  const headers = {
    &apos;Content-Type&apos;: &apos;application/json&apos;,
    Authorization: `Bearer ${apiKey}`,
  };
  const modelName = &apos;jina-reranker-v1-base-en&apos;;
  
  const res = await fetch(rerankUrl, {
    method: &apos;POST&apos;,
    headers: headers,
    body: JSON.stringify(data),
  });

  const resp = await res.json();

  const topKList = resp.results.map((item) =&gt; {
    return docs[item.index];
  });

  console.log(topKList);
}</code></pre><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://jina.ai/reranker?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Reranker API</div><div class="kg-bookmark-description">Maximize the search relevancy and RAG accuracy at ease</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="How to Build Article Recommendations with Jina Reranker API Only"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner-reranker-api.png" alt="How to Build Article Recommendations with Jina Reranker API Only"></div></a><figcaption><p><span style="white-space: pre-wrap;">To obtain an API key, simply visit our Reranker API page and navigate to the API section. If you already possess an API key from our Embedding API, you can reuse it here.</span></p></figcaption></figure><p>And just like that, you&apos;ll see the results, which are quite promising for a first iteration, especially considering that the implementation process takes roughly 10 minutes.</p><p>While readers may have concerns about this implementation, some critiques may be overthought, while others may be valid:</p><ul><li><strong>Concerns regarding overly long full-text and the necessity of chunking might be overthinking it</strong>: the <code>jina-reranker-v1</code> model can process queries up to 512 in length and documents of arbitrary length, while the <code>jina-colbert-v1</code> model can handle up to 8192 for both queries and documents. Therefore, inputting the full text to the Reranker API is likely unnecessary. Both models efficiently manage long contexts, so there&apos;s no need for worry. Chunking, though possibly the most cumbersome and heuristic aspect of the embedding-vector-search-rerank pipeline, is less of an issue here. However, longer contexts do assume more tokens, which is something our API&apos;s paid users may need to consider. In this example, because we use the full-text of all 233 articles, one rerank query costs 300K+ tokens.</li><li><strong>The impact of raw versus cleaned data on quality</strong>. Adding data cleaning could indeed lead to improvements. For instance, we&apos;ve observed that simply removing HTML tags (i.e. <code>docs.map(item =&gt; item.html.replace(/&lt;[^&gt;]*&gt;?/gm, &apos;&apos;)</code> ) significantly enhances recommendation quality for the <code>jina-reranker-v1</code> model, though the effect is less pronounced for the <code>jina-colbert-v1</code> model. This suggests that our ColBERT model was trained to be more tolerant of noisy text than the <code>jina-reranker-v1</code> model.</li><li><strong>The influence of different query constructions on quality.</strong> In the above implementation, we directly used the title and excerpt of the current article as the query. Is this the optimal approach to construct the query? Would adding a prefix such as <code>&quot;What is the most related article to...&quot;</code> or <code>&quot;I&apos;ll tip you $20 if you recommend the best article,&quot;</code> similar to prompts used with large language models, be beneficial? This raises an interesting question, likely related to the training data distribution of the model, which we plan to explore further.</li><li>Building on the previous point about query construction, it would be intriguing to investigate the query&apos;s compositional abilities further, such as using a user&apos;s recent browsing history for personalized recommendations. It&apos;s particularly interesting to consider whether the system could understand not just positive examples in the query <strong>but also negative ones, </strong>e.g. <code>NOT_LIKE</code> ops, <code>&quot;Don&apos;t recommend me article like this&quot;</code> or <code>&quot;I want to see fewer like this&quot;</code>. We&apos;ll delve into this more in the next section.</li></ul><h2 id="empirical-study-on-query-writing">Empirical Study on Query Writing</h2><p>In our exploration of different query writing with the Jina Reranker API, focusing on the top-10 results, we conducted a qualitative assessment through human labelling (i.e. evaluated by ourselves), which makes sense as we have the full knowledge of all the content published on our website. The strategies in query writings we examined included:</p><ul><li>Using the article&apos;s Title, Excerpt, and a combination of Title + Excerpt.</li><li>Adopting &quot;Prompt&quot;-like instructions such as &quot;more like this,&quot; &quot;not like this,&quot; and &quot;what is the most closely related article?&quot;</li></ul><p>To test the reranker&apos;s efficacy, we selected two non-trivial articles as our query subjects, aiming to pinpoint the most relevant articles among our extensive catalog of over 200+ posts&#x2014;a challenge inspired by &quot;the needle in a haystack&quot; in LLMs. Below, we highlighted these &quot;needles&quot; in green for clarity.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/image.png" class="kg-image" alt="How to Build Article Recommendations with Jina Reranker API Only" loading="lazy" width="2000" height="758" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/03/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/03/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/03/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/03/image.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;"> The comprehensive results of our study are detailed </span><a href="https://docs.google.com/spreadsheets/d/1XDOXjP6IVK1hXk3gKkng_cOpTrmS9Hm1UKCGvW1wMxU/edit?usp=sharing&amp;ref=jina-ai-gmbh.ghost.io"><span style="white-space: pre-wrap;">in this spreadsheet</span></a><span style="white-space: pre-wrap;">.</span></figcaption></figure><h2 id="summary">Summary</h2><p>Based on the test results, we&apos;ve made some observations and summaries:</p><ol><li>Combining the Title and Excerpt yields the best reranking results, with the Excerpt playing a significant role in enhancing reranking quality.</li><li>Incorporating &quot;prompt&quot;-like instructions does not lead to any improvement.</li><li>The reranker model currently does not effectively process positive or negative qualifiers. Terms such as &quot;more like&quot;, &quot;less like&quot;, or &quot;not like&quot; are not understandable by the reranker.</li></ol><p>The insights from points 2 and 3 offer intriguing directions for future enhancements of the reranker. We believe that enabling on-the-fly prompting to changing the sorting logic could significantly expand the reranker&apos;s capabilities, unlocking new potential applications such as personalized content curation/recommendation.</p>]]></content:encoded></item><item><title><![CDATA[Building RAG with Jina AI and SuperDuperDB]]></title><description><![CDATA[Jina Embeddings v2 are now integrated directly into SuperDuperDB, letting you skip the complexity of AI operations in your data-driven applications.]]></description><link>https://jina.ai/news/building-rag-with-jina-ai-and-superduperdb/</link><guid isPermaLink="false">65f04e788ff065000146da94</guid><category><![CDATA[Knowledge Base]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Wed, 13 Mar 2024 15:00:44 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/16.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="superduperdb">SuperDuperDB</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/16.jpg" alt="Building RAG with Jina AI and SuperDuperDB"><p><a href="https://superduperdb.com/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">SuperDuperDB</a> has integrated <a href="https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer">Jina Embeddings v2</a> directly into its data-driven AI operations framework. You can now use Jina AI&apos;s state-of-the-art embedding models with their groundbreaking 8k input context to work with your existing data stores via SuperDuperDB&apos;s integration libraries.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.superduperdb.com/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SuperDuperDB: Bring AI to your favorite database!</div><div class="kg-bookmark-description">Say goodbye to complex MLOps pipelines and specialized vector databases. Integrate and train AI directly with your preferred database, only using Python.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.superduperdb.com/apple-touch-icon.png" alt="Building RAG with Jina AI and SuperDuperDB"><span class="kg-bookmark-author">SuperDuperDB</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://staging.d3rw8vtufdccov.amplifyapp.com/images/new_superduperdb_share_image.png" alt="Building RAG with Jina AI and SuperDuperDB"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Embedding API</div><div class="kg-bookmark-description">Start with 1M free tokens. Top-performing, 8192 context length bilingual embeddings for your search and RAG systems.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Building RAG with Jina AI and SuperDuperDB"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner-embedding-api.png" alt="Building RAG with Jina AI and SuperDuperDB"></div></a></figure><p>To show you how, we have collaborated with SuperDuperDB on a tutorial creating a Retrieval-Augmented Generation (RAG) application that lets you query SQL databases in plain language.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.superduperdb.com/blog/rag-system-on-duckdb-using-jinaai-and-superduperdb/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Implementing a RAG System on DuckDB Using Jina AI and SuperDuperDB | SuperDuperDB documentation</div><div class="kg-bookmark-description">Querying your SQL database purely in human language</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://docs.superduperdb.com/img/favicon.ico" alt="Building RAG with Jina AI and SuperDuperDB"><span class="kg-bookmark-author">SuperDuperDB</span><span class="kg-bookmark-publisher">Anita Okoh</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.superduperdb.com/img/superDuperDB_img.png" alt="Building RAG with Jina AI and SuperDuperDB"></div></a></figure><h2 id="jina-ai"><strong>Jina AI</strong></h2><p>Jina AI is committed to distributing reliable, affordable AI technologies that are easy to use and integrated with common frameworks. We value your feedback, and we&#x2019;d love to hear about your business needs and discuss how AI can work for you. </p><p>For more information about Jina AI&#x2019;s offerings and to contact us, check out the <a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><u>Jina AI website</u></a> or join our <a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><u>community on Discord</u></a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI - Best Embeddings and Perfect Prompts</div><div class="kg-bookmark-description">Jina AI provides best-in-class embedding API and prompt optimizer, easing the development of multimodal AI applications.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Building RAG with Jina AI and SuperDuperDB"><span class="kg-bookmark-author">Best Embeddings and Perfect Prompts</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner.png" alt="Building RAG with Jina AI and SuperDuperDB"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 4493 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://discord.com/assets/images/favicon.ico" alt="Building RAG with Jina AI and SuperDuperDB"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Building RAG with Jina AI and SuperDuperDB"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Jina 3.24.0 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-24-0-update/</link><guid isPermaLink="false">65eedc3c28f704000180e2dc</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Mon, 11 Mar 2024 10:30:15 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Image-Jina-dark.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3240">Release Note (<code>3.24.0</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/Image-Jina-dark.jpg" alt="Jina 3.24.0 Update"><p>This release contains 1 new feature.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.24.0?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Release v3.24.0 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.24.0) Release time: 2024-03-11 09:48:35 This release contains 1 new feature.
&#x1F195; Features
Support provider endpoint in Jina Executor (#6149)
This release adds the --provider-endpoi&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="Jina 3.24.0 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/4744775b0fe508673f9bad61ba6ed377883f4ebe462333dd41f8fadc4cc350d8/jina-ai/jina/releases/tag/v3.24.0" alt="Jina 3.24.0 Update"></div></a></figure><h2 id="%F0%9F%86%95-features">&#x1F195; Features</h2><h3 id="support-provider-endpoint-in-jina-executor-6149">Support provider endpoint in Jina Executor (<a href="https://github.com/jina-ai/jina/pull/6149?ref=jina-ai-gmbh.ghost.io">#6149</a>)</h3><p>This release adds the&#xA0;<code>--provider-endpoint</code>&#xA0;flag, which can only be used in conjunction with the&#xA0;<code>--provider</code>&#xA0;flag. The&#xA0;<code>--provider-endpoint</code>&#xA0;flag takes as a parameter a named endpoint supported in the Executor and sets the endpoint of the provider to map to that Executor endpoint.</p><p>At present, SageMaker is the only available provider option, so using the parameters&#xA0;<code>--provider SAGEMAKER --provider-endpoint &lt;named endpoint&gt;</code>&#xA0;will make the SageMaker&#xA0;<code>invocations</code>&#xA0;endpoint map to the named endpoint of the Executor.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Zac Li (<a href="https://github.com/zac-li?ref=jina-ai-gmbh.ghost.io">@zac-li</a>)</li></ul>]]></content:encoded></item><item><title><![CDATA[Precise RAG with Jina Reranker and LlamaIndex]]></title><description><![CDATA[Just Rerank It! Jina Reranker and LlamaIndex take your RAG up to the next level.]]></description><link>https://jina.ai/news/precise-rag-with-jina-reranker-and-llamaindex/</link><guid isPermaLink="false">65e97909b22368000152a4c7</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Francesco Kruk]]></dc:creator><pubDate>Thu, 07 Mar 2024 14:00:01 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2024/03/banner_Reranker_-LlamaIndex.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2024/03/banner_Reranker_-LlamaIndex.png" alt="Precise RAG with Jina Reranker and LlamaIndex"><p>While <a href="https://www.sbert.net/examples/applications/cross-encoder/README.html?ref=jina-ai-gmbh.ghost.io"><u>bi-encoder models</u></a> such as <a href="https://jina.ai/embeddings?ref=jina-ai-gmbh.ghost.io"><u>Jina Embeddings</u></a> can quickly retrieve many matching documents from a database of pre-computed embeddings, reranker models can refine this set by using a slower but more precise approach of cross-encoding users&#x2019; queries and retrieved documents. Jina AI has <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io" rel="noreferrer"><u>released our first reranker model</u></a>, <code>jina-reranker-v1-base-en</code>, and, in this article, we&#x2019;ll present in-depth reasoning for why a reranker is essential to optimize RAG accuracy and how to get started building a state-of-the-art RAG system using <a href="https://jina.ai/embeddings/?ref=jina-ai-gmbh.ghost.io"><u>Jina Embeddings</u></a>/<a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io"><u>Reranker</u></a>,<a href="https://www.llamaindex.ai/?ref=jina-ai-gmbh.ghost.io"> <u>LlamaIndex</u></a>, and the <code>Mixtral-8x7B-Instruct-v0.1</code> language model (<a href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1?ref=jina-ai-gmbh.ghost.io"><u>hosted on HuggingFace</u></a>).</p><p>You&#x2019;ll need:</p><ul><li>A <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io"><u>combined key for Jina Embeddings and Reranker API</u></a>.</li><li>A <a href="https://huggingface.co/settings/tokens?ref=jina-ai-gmbh.ghost.io"><u>HuggingFace account and token</u></a>.</li></ul><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Reranker API</div><div class="kg-bookmark-description">Maximize the search relevancy and RAG accuracy at ease</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Precise RAG with Jina Reranker and LlamaIndex"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner-reranker-api.png" alt="Precise RAG with Jina Reranker and LlamaIndex"></div></a></figure><p>Since the Jina Embeddings and Reranker models as well as Mixtral run remotely and are accessed via a RESTful API, you won&#x2019;t need any special hardware.</p><h2 id="what-is-a-reranker">What is a reranker?</h2><p>Before continuing with the tutorial, it is important to highlight what rerankers are in the first place. For a full understanding of what a reranker is and why Jina Reranker V1 is the best choice for you, we encourage you to read our Jina Reranker V1 release post before continuing.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Maximizing Search Relevance and RAG Accuracy with Jina Reranker</div><div class="kg-bookmark-description">Boost your search and RAG accuracy with Jina Reranker. Our new model improves the accuracy and relevance by 20% over simple vector search. Try it now for free!</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Precise RAG with Jina Reranker and LlamaIndex"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Reranker1.png" alt="Precise RAG with Jina Reranker and LlamaIndex"></div></a></figure><p>In summary, rerankers are cross-encoder models that take as input a <em>document-query</em> pair, and emit a combined relevance score for that input pair. Using rerankers, users can sort documents from most to least relevant for a given query.</p><h2 id="why-use-jina-reranker-v1-base-en">Why use <code>jina-reranker-v1-base-en</code>?</h2><p>Reranking provides much more relevant information than using solely an embedding model. In our <a href="https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker/?ref=jina-ai-gmbh.ghost.io"><u>model release post</u></a>, we demonstrated that Jina Reranker stands out compared to its open- and closed-source competitors and it can improve search systems by <strong>8% in hit rate and 33% in </strong><a href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank?ref=jina-ai-gmbh.ghost.io"><strong><u>mean reciprocal rank</u></strong></a>.</p><p>This has a direct impact on the quality of responses obtained through the applied RAG solution. With the theory backing up this claim, we&#x2019;ll show you a practical example so you can see with your own eyes what effect Jina Reranker has on a RAG pipeline built with LlamaIndex.</p><h2 id="before-we-start-a-note-on-llamaindex-node-postprocessors">Before we start: A Note on LlamaIndex Node-Postprocessors</h2><p>Node-postprocessors in <a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/root.html?ref=jina-ai-gmbh.ghost.io"><u>LlamaIndex</u></a> are modules that transform or filter nodes after retrieval and before response synthesis within a query engine. As part of this package, LlamaIndex offers both built-in options as well as an API for custom additions.</p><p><strong>Jina Reranker has now been </strong><a href="https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/JinaRerank.html?ref=jina-ai-gmbh.ghost.io"><strong><u>integrated</u></strong></a><strong> into LlamaIndex as a node postprocessor</strong>. To increase response accuracy, retrieved nodes are re-ordered based on relevance to the query, and the top <strong><em>N</em></strong> nodes are returned.</p><h2 id="follow-along-on-google-colab">Follow along on Google Colab</h2><p>This tutorial has an accompanying notebook that you can run on <a href="https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/node_postprocessor/JinaRerank.ipynb?ref=jina-ai-gmbh.ghost.io" rel="noreferrer"><u>Google Colab</u></a> or locally.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/node_postprocessor/JinaRerank.ipynb?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">llama_index/docs/docs/examples/node_postprocessor/JinaRerank.ipynb at main &#xB7; run-llama/llama_index</div><div class="kg-bookmark-description">LlamaIndex is a data framework for your LLM applications - run-llama/llama_index</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" alt="Precise RAG with Jina Reranker and LlamaIndex"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">run-llama</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/2000e9ce9c43753a6316de82e8309737edaa6377de7b47d2d8b08a4a3caa8a71/run-llama/llama_index" alt="Precise RAG with Jina Reranker and LlamaIndex"></div></a></figure><h3 id="the-dataset-2024-nike-kids-product-catalog">The dataset: 2024 Nike Kids Product Catalog</h3><p>To showcase Jina Reranker&#x2019;s performance increase for RAG applications, we&#x2019;ve chosen the <a href="https://niketeam-asset-download.nike.net/catalogs/2024/2024_Nike%20Kids_02_09_24.pdf?cb=09302022&amp;ref=jina-ai-gmbh.ghost.io"><u>2024 Nike Kids Product Catalog</u></a> as our dataset. The document contains a structured set of kids&#x2019; products offered by Nike in 2024. We selected this dataset as it showcases the effect of using a reranker clearly and is relatable to most users.</p><h3 id="install-the-prerequisites">Install the prerequisites</h3><p>To install the requirements, run:</p><pre><code class="language-bash">pip install llama-index-postprocessor-jinaai-rerank
pip install llama-index-embeddings-jinaai
pip install llama-index
pip install llama-index-llms-huggingface
pip install &quot;huggingface_hub[inference]&quot;</code></pre><h3 id="access-mixtral-llm">Access Mixtral LLM</h3><p>To use the <code>Mixtral-8x7B-Instruct-v0.1</code> LLM, you need a<a href="https://huggingface.co/settings/tokens?ref=jina-ai-gmbh.ghost.io"> <u>HuggingFace</u></a> token.</p><pre><code class="language-Python">from llama_index.llms.huggingface import HuggingFaceInferenceAPI

hf_inference_api_key = &quot;&lt;your HuggingFace access token here&gt;&quot;

mixtral_llm = HuggingFaceInferenceAPI(
    model_name=&quot;mistralai/Mixtral-8x7B-Instruct-v0.1&quot;,
    token=hf_inference_api_key,
)
</code></pre><h3 id="access-jina-embeddings-and-jina-reranker">Access Jina Embeddings and Jina Reranker</h3><p>To use our Jina Embeddings and Jina Reranker, you need a dedicated <a href="https://jina.ai/reranker/?ref=jina-ai-gmbh.ghost.io"><u>API key</u></a>. Store it in a variable called <code>api_key</code> and call the Jina Embeddings model from LlamaIndex:</p><pre><code class="language-Python">from llama_index.embeddings.jinaai import JinaEmbedding

api_key = &quot;&lt;your Jina key here&gt;&quot;
jina_embeddings = JinaEmbedding(api_key=api_key)</code></pre><p>Similarly, you can call the Jina Reranker model. By setting the <code>top_n</code> parameter, you can decide how many of the most relevant documents to return in the final output. In this case, we set <code>top_n=2</code>:</p><pre><code class="language-Python">from llama_index.postprocessor.jinaai_rerank import JinaRerank

jina_rerank = JinaRerank(api_key=api_key, top_n=2)</code></pre><h3 id="download-the-2024-nike-kids-product-catalog">Download the 2024 Nike Kids Product Catalog</h3><p>To download the data, run the following code:</p><pre><code class="language-Python">from llama_index.core import SimpleDirectoryReader
import requests

url = &apos;&lt;https://niketeam-asset-download.nike.net/catalogs/2024/2024_Nike%20Kids_02_09_24.pdf?cb=09302022&gt;&apos;
response = requests.get(url)

with open(&apos;Nike_Catalog.pdf&apos;, &apos;wb&apos;) as f:
&#xA0;&#xA0;&#xA0;&#xA0;f.write(response.content)

reader = SimpleDirectoryReader(
&#xA0;&#xA0;&#xA0;&#xA0;input_files=[&quot;Nike_Catalog.pdf&quot;]
)

documents = reader.load_data()</code></pre><h3 id="generate-and-index-embeddings-with-jina-embeddings">Generate and index embeddings with Jina Embeddings</h3><p>Now that the setup is complete, we&#x2019;ll generate the embedding vectors (nodes) and index them. Jina Embeddings v2 models accept input of up to 8192 tokens, large enough that for a document like this, we don&#x2019;t need to do any further text segmentation or check if any section has too many tokens. To embed and index the document, run the following code:</p><pre><code class="language-Python">from llama_index.core import VectorStoreIndex

index = VectorStoreIndex.from_documents(
&#xA0;&#xA0;&#xA0;&#xA0;documents=documents, embed_model=jina_embeddings
)</code></pre><h3 id="query-for-results-without-jina-reranker">Query for results without Jina Reranker</h3><p>When we query for specific information from this set of texts, the LlamaIndex <code>query_engine</code> does the following:</p><ol><li>With Jina Embeddings V2, it creates an embedding for the query.</li><li>It uses the index to get the <code>top_k = 10</code> stored embeddings with the highest cosine to the query embedding and return its place in the index.</li><li>It will look up the corresponding text in the vector data array.</li></ol><p>Let&#x2019;s ask what the best Nike jersey is in terms of fabric:</p><pre><code>query_engine = index.as_query_engine(
&#xA0;&#xA0;&#xA0;&#xA0;similarity_top_k=10, llm=mixtral_llm
)
response = query_engine.query(
&#xA0;&#xA0;&#xA0;&#xA0;&quot;What are the best padded pants that Nike sells?&quot;,
)

print(response.source_nodes[0].text)</code></pre><p><strong>Result</strong>:</p><pre><code class="language-Text">NIKE KIDS&#xA0; EQUIPMENT87NIKE BRASILIA SMALL DUFFEL 9.5&#xA0;
DM3976 $37.00
SIZES: Misc&#xA0; OFFER DATE: 07/01/22&#xA0; END DATE: 07/01/25
Tough 600D polyester &#x2022; Durable 300D polyester &#x2022; Detachable shoulder
strap&#xA0;&#x2022; Ventilated shoe or wet/dry storage &#x2022; Secure zip pocket &#x2022; 
Limited lifetime guarantee&#xA0;&#x2022; Screened Swoosh design trademark
DIMENSIONS:&#xA0; 20&quot; L x 10&quot; W x 11&quot; H&#xA0;
010 Black/Black/(White) 068 Iron Grey/Black/(White)
...</code></pre><figure class="kg-card kg-image-card"><img src="https://lh7-us.googleusercontent.com/z2OKhAFnHCXw3aI4W1KUZNxzt8WOEERSG-prrBcmGwBEDTAFGavSN8eiHnvFF6R0L-dlwRUY3U8R7ysinoGTSSL-9_vr0RdCmrIRSy_xffvKz-Trqa1Yr49YGNb7R-GsDpCqilIW3cluVER4St5rUts" class="kg-image" alt="Precise RAG with Jina Reranker and LlamaIndex" loading="lazy" width="594" height="592"></figure><h3 id="query-for-results-with-reranker">Query for results with Reranker</h3><p>We now want to apply the reranker to see if the RAG application yields a different, more <em>relevant</em> result. To do so, we need to add the <code>node_postprocessors</code> to the <code>query_engine</code>:</p><pre><code class="language-Python">query_engine = index.as_query_engine(
&#xA0;&#xA0;&#xA0;&#xA0;similarity_top_k=10, llm=mixtral_llm, node_postprocessors=[jina_rerank]
)
response = query_engine.query(
&#xA0;&#xA0;&#xA0;&#xA0;&quot;What are the best padded pants that Nike sells?&quot;,
)

print(response.source_nodes[0].text)</code></pre><p>Note that compared to the previous case without the reranker, the <code>query_engine</code> now also contains the <a href="https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/JinaRerank.html?ref=jina-ai-gmbh.ghost.io"><u>node_postprocessors</u></a> parameter set to <code>[jina_rerank]</code>.</p><p><strong>Result</strong>:</p><pre><code class="language-Text">NIKE KIDS&#xA0; FOOTBALL &#x2013; STOCK10
DJ5731 $47.00
SIZES:&#xA0; XS, S, M, L, XL, 2XL, 3XL
FABRIC:&#xA0; Body/panels lining: 100% polyester. Pad: 100%
ethylene vinyl acetate.
OFFER DATE:&#xA0; 04/01/23
END DATE:&#xA0; 04/01/27
Take the field ready to give it your all in the Nike Recruit
Pants. They&#x2019;re made from lightweight, stretchy&#xA0;fabric with
sweat-wicking power to help keep you dry and moving freely
when the game heats up. With&#xA0;integrated pads shaped for a
comfortable fit, you&#x2019;ll be prepared for a performance you can
be proud of.&#xA0;Choose from 6 different colors to outfit your
team. Nike Dri-FIT technology moves sweat away from your&#xA0;skin
for quicker evaporation, helping you stay dry and comfortable.
Lightweight knit fabric stretches with&#xA0;you to let you move
naturally. Thigh, knee, hip and tailbone pads are shaped for
an optimal fit, without&#xA0;compromising on coverage. A
body-hugging fit is designed to help keep the padding in place
and close to&#xA0;the body. Belt at the waist lets you dial in your
perfect fit to maximize comfort. Elastic at hems.
Hip width: 15&quot;, Inseam length: 11.75&quot; (size medium).
010 Black/(White) 060 Team Anthracite/(White) 100 White/(Black)
419 Team Navy/(White) 493 Team Royal/(White) 657 Team Scarlet/(White)</code></pre><p></p><figure class="kg-card kg-image-card"><img src="https://lh7-us.googleusercontent.com/X0ngGFoOz8S_KlRhAlQs4rOooKsV92d06-UBa7BsFPiTilgTD9xuQfgIblG7dTq0BQp4ZA9DlBCjFvA6D62eUVDmxxOO38va5mlnutPr4Zlu6l70tvbGtmrS2V0rpn-OE__tarMtR1MxAmD2oQ3m2qg" class="kg-image" alt="Precise RAG with Jina Reranker and LlamaIndex" loading="lazy" width="1600" height="982"></figure><h2 id="conclusion"><strong>Conclusion</strong></h2><p>As we can see, the query without the reranker leads to a top result which mentions &#x201C;mesh back for breathability&#x201D; and &#x201C;slim fit with soft hand feel&#x201D;. In comparison, by using a reranker, we obtain a top result that is &#x201C;engineered for optimal breathability&#x201D;, has a &#x201C;moisture-wicking design&#x201D; that &#x201C;helps keep you dry and cool under match-day pressure&#x201D;, and features &#x201C;lightweight fabric in a relaxed, easy fit&#x201D;.</p><p>The second result is much more accurate and appropriate for the query we asked. With our last two posts, we showed both from a theoretical and practical perspective that adding Jina Reranker to your RAG pipeline increases your retrieval accuracy and improves the quality of the responses you obtain from it.</p>]]></content:encoded></item></channel></rss>