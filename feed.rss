<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Jina AI]]></title><description><![CDATA[The official newsroom of Jina AI]]></description><link>https://jina.ai/news</link><image><url>https://jina.ai/favicon.ico</url><title>Jina AI</title><link>https://jina.ai/news</link></image><generator>Ghost 5.69</generator><lastBuildDate>Wed, 18 Oct 2023 13:46:41 GMT</lastBuildDate><atom:link href="https://jina.ai/feed.rss" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Unveiling the Magic: Become a Part of PromptPerfect's Affiliate Family]]></title><description><![CDATA[Introducing PromptPerfect's Affiliate Program, an initiative for enthusiasts to bring attention to Jina AI's innovative technologies and show our appreciation to the community that makes PromptPerfect great!]]></description><link>https://jina.ai/news/unveiling-the-magic-become-a-part-of-promptperfects-affiliate-family-2/</link><guid isPermaLink="false">652e4e73bfcbdb000148afe6</guid><category><![CDATA[Knowledge Base]]></category><dc:creator><![CDATA[Miruna Nedelcu]]></dc:creator><pubDate>Wed, 18 Oct 2023 13:45:05 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Explore-image-storytelling-beyond-pixels.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Explore-image-storytelling-beyond-pixels.png" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"><p>Great news for PromptPerfect enthusiasts: We want to show you our appreciation for helping to build our community! </p><p>We&apos;re introducing the <strong>PromptPerfect Affiliate Program</strong>, an initiative inviting enthusiasts to bring attention to Jina AI&apos;s innovative technologies and show our appreciation to the community that makes PromptPerfect great! Become one of our affiliates and enjoy rewards for helping show the world what PromptPerfect can do.</p><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/affiliate?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Elevate Your Prompts to Perfection. Prompt Engineering, Optimizing, Debugging and Hosting.</div><div class="kg-bookmark-description">Unlock advanced prompt engineering and prompt optimization for large models such as GPT-4, ChatGPT, Midjourney and Stable Diffusion. Seamlessly deploy your text and image prompts as dedicated services with our free prompt hosting plan. Enhance your large models with superior performance and efficien&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/apple-icon-180x180.png" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"><span class="kg-bookmark-author">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"></div></a><figcaption><p><span style="white-space: pre-wrap;">Learn More About PromptPerfect Affiliate Program</span></p></figcaption></figure><h2 id="key-benefits">Key Benefits:</h2><ul><li><strong>A Rewarding Start:</strong> From the get-go, affiliates receive <strong>a 15% commission on sales</strong> during their first month. It&apos;s a hearty welcome to the family, ensuring you feel valued from your very first contribution. And we are more than happy to increase your commission after the first month.</li><li><strong>Sustained Gains:</strong> The perks don&apos;t just stop after the first month. For every ensuing sale, a consistent 15% commission is credited to you. It&apos;s the gift that keeps on giving, rewarding your efforts and amplifying your impact.</li><li><strong>Simple, Monthly Payouts:</strong> To keep things simple, earnings are calculated and sent out monthly. You can focus on what you do best, leaving the complexities of transactions to us.</li><li><strong>Your Success is Important to Us: </strong>We&apos;re committed to supporting your success. You&apos;ll have access to valuable resources to generate as many referrals as possible. These resources are designed to help you develop content and attract more new merchants. Plus, you&apos;ll get access to a variety of creative, pre-developed lead magnets and detailed performance metrics.</li></ul><h2 id="how-to-get-started"><strong>How to Get Started: </strong></h2><p>Embarking on this journey is as simple as 1-2-3:</p><ol><li><strong>Apply Easily:</strong> Start by filling out a basic form. No hoops to jump through, just some basic information. </li></ol><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://form.typeform.com/to/Qa5xMFNU?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Affiliate submission</div><div class="kg-bookmark-description">Turn data collection into an experience with Typeform. Create beautiful online forms, surveys, quizzes, and so much more. Try it for FREE.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://public-assets.typeform.com/public/favicon/apple-touch-icon.png" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.typeform.com/images/2VWurKeiR4R7/image/default" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"></div></a><figcaption><p><span style="white-space: pre-wrap;">Learn More About PromptPerfect Affiliate Submission</span></p></figcaption></figure><ol start="2"><li><strong>Quick Follow-up:</strong> Your time is precious, and so we commit to responding within 5 business days. You&apos;ll be fully briefed on the next steps without any unnecessary wait.</li><li><strong>Get guidance from the team:</strong> Once your application has been reviewed, our team will reach out to you to arrange a call. During this call, we will walk you through all the necessary steps and provide you with valuable links to promotional materials, so you can start immediately.</li></ol><p>This program is about fostering a community that values innovation and shared success. It&apos;s for those who are excited about shaping the future of technology and want their voices to be heard.</p><p>The PromptPerfect Affiliate Program can make you an integral part of a community that champions forward-thinking and mutual growth. So, if you like sharing with the world the next big thing in tech, this opportunity is for you.</p><p>Ready to take the leap? Dive in, spread the word, and watch the magic happen. </p><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/affiliate?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Elevate Your Prompts to Perfection. Prompt Engineering, Optimizing, Debugging and Hosting.</div><div class="kg-bookmark-description">Unlock advanced prompt engineering and prompt optimization for large models such as GPT-4, ChatGPT, Midjourney and Stable Diffusion. Seamlessly deploy your text and image prompts as dedicated services with our free prompt hosting plan. Enhance your large models with superior performance and efficien&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/apple-icon-180x180.png" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"><span class="kg-bookmark-author">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="Unveiling the Magic: Become a Part of PromptPerfect&apos;s Affiliate Family"></div></a><figcaption><p><span style="white-space: pre-wrap;">Learn More About PromptPerfect Affiliate Program</span></p></figcaption></figure><p>The future is being written, and here&apos;s your chance to hold the pen.</p><p>Welcome to the family!</p>]]></content:encoded></item><item><title><![CDATA[Jina 3.22.1 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-22-1-update/</link><guid isPermaLink="false">65200886701fe20001daea2c</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Fri, 06 Oct 2023 14:54:43 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Image-Jina-dark.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3221"><br>Release Note (<code>3.22.1</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Image-Jina-dark.jpg" alt="Jina 3.22.1 Update"><p>This release contains 1 bug fix.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.22.1?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Patch v3.22.1 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.22.1) Release time: 2023-10-06 13:52:45 This release contains 1 bug fix.&#x1F41E; Bug FixesFix timeout issue with dynamic batching (#6071)When using dynamic batching (either with the @&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Jina 3.22.1 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/f8312759ade3440797e5ebe9a8b57877d5e0cf47ed60c32fad174d1e51ee2f1e/jina-ai/jina/releases/tag/v3.22.1" alt="Jina 3.22.1 Update"></div></a></figure><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-timeout-issue-with-dynamic-batching-6071">Fix timeout issue with dynamic batching (<a href="https://github.com/jina-ai/jina/pull/6071?ref=jina-ai-gmbh.ghost.io">#6071</a>)</h3><p>When using dynamic batching (either with the <code>@dynamic_batching</code> decorator on an <code>Executor</code> endpoint or by setting the <code>uses_dynamic_batching</code> parameter on a <code>Deployment</code>, timeouts were not being properly taken into account because the timer might not be triggered until a previous batch finished. This has been fixed.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a> )</li></ul>]]></content:encoded></item><item><title><![CDATA[Jina 3.22.0 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-22-0-update/</link><guid isPermaLink="false">651d461cd921f000016560c5</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Wed, 04 Oct 2023 12:53:54 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Image-Jina-dark-1.jpeg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3220"><br>Release Note (<code>3.22.0</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Image-Jina-dark-1.jpeg" alt="Jina 3.22.0 Update"><p>This release contains 1 new feature and 2 documentation improvements.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.22.0?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Release v3.22.0 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.22.0) Release time: 2023-10-04 12:16:53 This release contains 1 new feature and 2 documentation improvements.&#x1F195; FeaturesChange the way dynamic batching is handled (#6066)This re&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Jina 3.22.0 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/da0df8f748c732c06c623f112cf1a035f2119229a4e0c4af7a7a4bc13da78b7e/jina-ai/jina/releases/tag/v3.22.0" alt="Jina 3.22.0 Update"></div></a></figure><h2 id="%F0%9F%86%95-features">&#x1F195; Features</h2><h3 id="change-the-way-dynamic-batching-is-handled-6066">Change the way dynamic batching is handled (<a href="https://github.com/jina-ai/jina/pull/6066?ref=jina-ai-gmbh.ghost.io">#6066</a>)</h3><p>This release implements some changes in the way we handle dynamic batching:</p><ul><li>Jina guarantees that all the batches passed to Executors contain no more than <code>preferred_batch_size</code> documents.</li><li>Requests are returned to the client as they are processed without waiting for other requests to be ready.</li></ul><h2 id="%F0%9F%93%97-documentation-improvements">&#x1F4D7; Documentation Improvements</h2><ul><li>Fix dynamic batching documentation (<a href="https://github.com/jina-ai/jina/pull/6068?ref=jina-ai-gmbh.ghost.io">#6068</a>)</li><li>Fix line explaining dynamic batching in YAML (<a href="https://github.com/jina-ai/jina/pull/6065?ref=jina-ai-gmbh.ghost.io">#6065</a>)</li></ul><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a>)</li><li>Johannes Messner (<a href="https://github.com/JohannesMessner?ref=jina-ai-gmbh.ghost.io">@JohannesMessner</a> )</li></ul>]]></content:encoded></item><item><title><![CDATA[DocArray 0.39 Update]]></title><description><![CDATA[DocArray is a library for representing, sending and storing multi-modal data, perfect for Machine Learning applications.]]></description><link>https://jina.ai/news/docarray-0-39-update/</link><guid isPermaLink="false">651ac836330c280001e2c0bd</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Mon, 02 Oct 2023 13:43:56 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Image-DocArray-dak.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-0390"><br>Release Note (0.39.0)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/10/Image-DocArray-dak.jpg" alt="DocArray 0.39 Update"><p>This release contains 4 new features, 8 bug fixes, and 7 documentation improvements.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/docarray/docarray/releases/tag/v0.39.0?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Release v0.39.0 &#xB7; docarray/docarray</div><div class="kg-bookmark-description">Release Note (0.39.0) Release time: 2023-10-02 13:06:02 This release contains 4 new features, 8 bug fixes, and 7 documentation improvements.&#x1F195; FeaturesSupport for Pydantic v2 &#x1F680; (#1652)The bigge&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="DocArray 0.39 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">docarray</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/6046718f1e879a210b994daf388d030e8249404f7f7d70a9a3675722a1870488/docarray/docarray/releases/tag/v0.39.0" alt="DocArray 0.39 Update"></div></a></figure><h2 id="%F0%9F%86%95-features">&#x1F195; Features</h2><h3 id="support-for-pydantic-v2-%F0%9F%9A%80-1652">Support for Pydantic v2 &#x1F680; (<a href="https://github.com/docarray/docarray/pull/1652?ref=jina-ai-gmbh.ghost.io">#1652</a>)</h3><p>The biggest feature of this release is <strong>full support for Pydantic v2</strong>! We are <strong>continuing to support Pydantic v1</strong> at the same time.</p><p>If you use Pydantic v2, you will need to adapt your DocArray code to the new Pydantic API. Check out their migration guide <a href="https://docs.pydantic.dev/latest/migration/?ref=jina-ai-gmbh.ghost.io" rel="nofollow">here</a>.</p><p>Pydantic v2 has its core written in Rust and provides significant performance improvements to DocArray: <strong>JSON serialization is 240% faster</strong> and <strong>validation</strong> of BaseDoc and DocList with non-native types like <code>TorchTensor</code> is <strong>20% faster</strong>.</p><h3 id="add-basedocwithoutid-1803">Add BaseDocWithoutId (<a href="https://github.com/docarray/docarray/pull/1803?ref=jina-ai-gmbh.ghost.io">#1803</a>)</h3><p>A <code>BaseDoc</code> by default includes an <code>id</code> field. This can be problematic if you want to build an API that requires a model without this ID field. Therefore, <strong>we now provide a <code>BaseDocWithoutId</code> which is, as its name suggests, is BaseDoc without the ID field</strong>.</p><p>Please use this Document with caution, BaseDoc is still the base class to use unless you specifically need to remove the ID.</p><p>&#x26A0;&#xFE0F; <strong><code>BaseDocWithoutId</code> is not compatible with <code>DocIndex</code></strong> or any feature requiring a vector database. This is because DocIndex needs the id field to store and retrieve documents.</p><h2 id="%F0%9F%92%A3-breaking-change">&#x1F4A3; Breaking change</h2><h3 id="remove-jina-ai-cloud-pushpull-1791">Remove Jina AI cloud push/pull (<a href="https://github.com/docarray/docarray/pull/1791?ref=jina-ai-gmbh.ghost.io">#1791</a>)</h3><p>Jina AI Cloud is being discontinued. Therefore, we are removing the <code>push/pull</code> feature related to Jina AI cloud.</p><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-doclist-subscription-error">Fix DocList subscription error</h3><p><code>DocList</code> can be typed from BaseDoc using the following syntax <code>DocList[MyDoc]()</code>.</p><p>In this release, we have fixed a bug that allowed users to specify the type of a <code>DocList</code> multiple times</p><p>Doing <code>DocList[MyDoc1][MyDoc2]</code> won&apos;t work anymore (<a href="https://github.com/docarray/docarray/pull/1800?ref=jina-ai-gmbh.ghost.io">#1800</a>)</p><p>We also fixed a bug that caused a silent failure when users passed <code>DocList</code> the wrong type, for example <code>DocList[doc()]</code>. (<a href="https://github.com/docarray/docarray/pull/1794?ref=jina-ai-gmbh.ghost.io">#1794</a>)</p><h3 id="milvus-connection-parameter-missing-1802">Milvus connection parameter missing (<a href="https://github.com/docarray/docarray/pull/1802?ref=jina-ai-gmbh.ghost.io">#1802</a>)</h3><p>We fixed a small bug that incorrectly set the port of the Milvus client.</p><h2 id="%F0%9F%93%97-documentation-improvements">&#x1F4D7; Documentation Improvements</h2><ul><li>Fix Documentation for pydantic v2 (<a href="https://github.com/docarray/docarray/pull/1815?ref=jina-ai-gmbh.ghost.io">docs: fix documentation for pydantic v2 #1815</a>)</li><li>Adding field descriptions to predefined mesh 3D Document (<a href="https://github.com/docarray/docarray/pull/1789?ref=jina-ai-gmbh.ghost.io">docs: adding field descriptions to predefined mesh 3D document #1789</a>)</li><li>Adding field descriptions to predefined point cloud 3D Document (<a href="https://github.com/docarray/docarray/pull/1792?ref=jina-ai-gmbh.ghost.io">docs: adding field descriptions to predefined point cloud 3D document #1792</a>)</li><li>Adding field descriptions to predefined video Document (<a href="https://github.com/docarray/docarray/pull/1775?ref=jina-ai-gmbh.ghost.io">docs: adding field descriptions to predefined video document #1775</a>)</li><li>Adding field descriptions to predefined text Document (<a href="https://github.com/docarray/docarray/pull/1770?ref=jina-ai-gmbh.ghost.io">docs: adding field descriptions to predefined text document #1770</a>)</li><li>Adding field descriptions to predefined image Document (<a href="https://github.com/docarray/docarray/pull/1772?ref=jina-ai-gmbh.ghost.io">docs: adding field descriptions to predefined image document #1772</a>)</li><li>Adding field descriptions to predefined audio Document (<a href="https://github.com/docarray/docarray/pull/1774?ref=jina-ai-gmbh.ghost.io">docs: adding field descriptions to predefined audio document #1774</a>)</li></ul><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>lvzi (<a href="https://github.com/lvzii?ref=jina-ai-gmbh.ghost.io">@lvzii</a> )</li><li>Puneeth K (<a href="https://github.com/punndcoder28?ref=jina-ai-gmbh.ghost.io">@punndcoder28</a> )</li><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a> )</li><li>samsja (<a href="https://github.com/samsja?ref=jina-ai-gmbh.ghost.io">@samsja</a> )</li></ul>]]></content:encoded></item><item><title><![CDATA[Jina 3.21.1 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-21-1-update/</link><guid isPermaLink="false">6516adfe545c930001d5bd82</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Fri, 29 Sep 2023 11:01:10 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Image-Jina-dark-1.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3211">Release Note (<code>3.21.1</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Image-Jina-dark-1.jpg" alt="Jina 3.21.1 Update"><p>This release contains 1 bug fix.</p><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-issue-with-same-doc-type-in-different-containerized-executors-6062">Fix issue with same doc type in different containerized Executors (<a href="https://github.com/jina-ai/jina/pull/6062?ref=jina-ai-gmbh.ghost.io">#6062</a>)</h3><p>When multiple Executors inside a Flow had the same model name and they were used as docker containers or had set the environment variable <code>JINA_MP_START_METHOD=spawn</code>, there was a problem serving them via HTTP. This has been fixed by making sure that only one model instance is served for each model name.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a> )</li></ul>]]></content:encoded></item><item><title><![CDATA[SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?]]></title><description><![CDATA[Discover the future of visual comprehension with SceneXplain, the leading image captioning tool of 2023. Dive deep into its transformative features, real-world applications, and see how it stands tall against GPT-4 Vision. ]]></description><link>https://jina.ai/news/scenexplain-vs-gpt-4-vision-the-best-image-captioning-tool-in-2023/</link><guid isPermaLink="false">65158235545c930001d5bcce</guid><category><![CDATA[Knowledge Base]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Thu, 28 Sep 2023 14:29:26 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--9-.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--9-.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><p>Hey there, digital explorer! &#x1F680;</p><p>In the ever-evolving landscape of AI, two giants stand out in the realm of visual comprehension: <a href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io">SceneXplain</a> and <a href="chat.openai.com">GPT-4 Vision</a>. But which one truly reigns supreme? Dive into our comprehensive guide to discover why SceneXplain might just be the game-changer you&apos;ve been searching for.</p><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://scenexplain.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SceneXplain - Leading AI Solution for Image Captions and Video Summaries</div><div class="kg-bookmark-description">Experience cutting-edge computer vision with our premier image captioning and video summarization algorithms. Tailored for content creators, media professionals, SEO experts, and e-commerce enterprises. Featuring multilingual support and seamless API integration. Elevate your digital presence today.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://scenexplain.jina.ai/icons/apple-icon-180x180.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-author">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://scenex.jina.ai/banner.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a><figcaption>Try SceneXplain now for free!</figcaption></figure><h3 id="why-scenexplains-large-multimodal-model-is-the-future"><strong><strong>Why SceneXplain&apos;s Large Multimodal Model is the Future</strong></strong></h3><ul><li><strong>Storytelling Beyond Captioning</strong>: While GPT-4 Vision focuses on basic identification, SceneXplain crafts narratives. With Jina AI&apos;s next-gen algorithms, it transforms visuals into stories, offering a deeper understanding of the emotion and context behind images.</li><li><strong>User-Friendly for All</strong>: SceneXplain&apos;s interface is intuitive for both tech newbies and experts. For the tech-savvy, its robust API integration is a dream come true. Check out its main interface here:</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-30.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="2000" height="1320" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-30.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-30.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-30.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2023/09/image-30.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>SceneXplain&apos;s user-friendly interface for image captioning</figcaption></figure><ul><li><strong>Rapid Batch Processing via API</strong>: SceneXplain&apos;s scalable API endpoints are a standout. Describe up to 128 images in one batch within just 40 seconds. It&apos;s a game-changer for businesses, streamlining integration into applications, websites, or services.</li></ul><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-36.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="1622" height="802" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-36.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-36.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-36.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-36.png 1622w" sizes="(min-width: 720px) 720px"></figure><h3 id="top-features-making-scenexplain-the-best-image-captioning-tool-in-2023"><strong><strong>Top Features Making SceneXplain the Best Image Captioning Tool in 2023</strong></strong></h3><ul><li><strong>Caption Image</strong>: Your personal storyteller for every image. Curious? </li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-37.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="1582" height="1564" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-37.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-37.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-37.png 1582w" sizes="(min-width: 720px) 720px"><figcaption><strong>Caption Image with SceneXplain</strong></figcaption></figure><ul><li><strong>Extract JSON from Image</strong>: Data enthusiasts, this one&apos;s for you! Extract structured data seamlessly. See it in action: </li></ul><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-38.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="822" height="1818" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-38.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-38.png 822w" sizes="(min-width: 720px) 720px"></figure><p>Dive deeper with our in-depth post: </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/scenexplains-image-json-extract-structured-data-images-precision/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SceneXplain&#x2019;s Image-to-JSON: Extract Structured Data from Images with Precision</div><div class="kg-bookmark-description">Pushing the boundaries of visual AI, we&#x2019;re thrilled to unveil SceneXplain&#x2019;s Image-to-JSON feature. Dive into a world where images aren&#x2019;t just seen, but deeply understood, translating visuals into structured data with unparalleled precision.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-publisher">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--7-.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a></figure><ul><li><strong>Visual Q&amp;A</strong>: Got a question about an image? SceneXplain&apos;s got answers. Sneak peek: </li></ul><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-39.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="1558" height="1148" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-39.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-39.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-39.png 1558w" sizes="(min-width: 720px) 720px"></figure><p>Learn more about its OCR capabilities in </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/read-my-pics-you-got-ocr-in-my-visual-question-answering/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Read My Pics: SceneXplain Puts OCR in Your Visual Question Answering!</div><div class="kg-bookmark-description">We&#x2019;re turbocharging SceneXplain&#x2019;s visual question answering with an OCR upgrade, making it easier than ever to get answers out of your images</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-publisher">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/07/Sentiment-analysis--3-.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a></figure><ul><li><strong>Summarize Video</strong>: Get the gist of videos without the time investment. Check this out:</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-40.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="1602" height="1638" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-40.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-40.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-40.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-40.png 1602w" sizes="(min-width: 720px) 720px"><figcaption>Using SceneXplain to summarize videos and extract key events</figcaption></figure><p>Deep dive: </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/how-scenexplain-solves-video-to-text-comprehension/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">How SceneXplain Solved Video-to-Text Comprehension</div><div class="kg-bookmark-description">Pushing the boundaries of video-to-text comprehension, SceneXplain unveils the Inception algorithm: decoding narratives, acknowledging challenges, and inviting firsthand exploration. Dive into the next frontier of video comprehension.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-publisher">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/generativejina_Illustration_showing_a_vintage_movie_projector_c_776167b0-0368-4304-bd82-7452c8e5928a.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a></figure><ul><li><strong>Generate Story</strong>: Where images inspire stories, dialogues, and more. Get inspired: &#xA0;</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-41.png" class="kg-image" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?" loading="lazy" width="1590" height="1798" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-41.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-41.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-41.png 1590w" sizes="(min-width: 720px) 720px"><figcaption>Using SceneXplain to generate audio story &amp; dialog.</figcaption></figure><p>Explore in </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/beyond-pixels-to-prose-scenexplains-hearth-algorithm-breathes-audible-life-into-images/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Beyond Pixels to Prose: SceneXplain&#x2019;s New Algorithm Breathes Audible Life into Images</div><div class="kg-bookmark-description">Discover the power of SceneXplain&#x2019;s Hearth Algorithm: turning images into captivating narratives. Dive deep into the tech behind it, explore real-world examples, and grasp its potential. Journey beyond pixels to stories at SceneXplain!</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-publisher">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/08/generativejina_an_image_of_an_abstract_graph_in_motion_in_the_s_ae1f674c-ac1a-448c-837e-5d2735748e45.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a></figure><h3 id="scenexplain-in-action-real-world-impact-across-industries"><strong><strong>SceneXplain in Action: Real-World Impact Across Industries</strong></strong></h3><p>SceneXplain isn&apos;t just another tool; it&apos;s a transformative solution making waves across industries:</p><h4 id="1-revolutionizing-digital-marketing"><strong><strong>1. Revolutionizing Digital Marketing</strong></strong></h4><p><strong>Sophia</strong>, a Digital Marketing Specialist, leverages SceneXplain to enhance visual content with rich narratives, boosting engagement and SEO efforts. With multilingual support, brands can resonate with a global audience, making campaigns truly international.</p><h4 id="2-streamlining-news-reporting"><strong><strong>2. Streamlining News Reporting</strong></strong></h4><p><strong>James</strong>, Editor-in-Chief of a major news organization, uses SceneXplain to supercharge content creation, enabling journalists to focus on storytelling. It ensures visual content is accessible, making news platforms inclusive for visually impaired readers.</p><h4 id="3-elevating-e-commerce-experiences"><strong><strong>3. Elevating E-commerce Experiences</strong></strong></h4><p><strong>Wang</strong>, an E-commerce Product Manager, harnessed SceneXplain to automate compelling product descriptions from images, enriching the shopping experience and boosting sales.</p><h4 id="4-championing-accessibility"><strong><strong>4. Championing Accessibility</strong></strong></h4><p>The <strong>Accessibility Research Association (ARA)</strong> uses SceneXplain to democratize access to visual content for the blind and visually impaired, ensuring global accessibility law compliance.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/enhancing-digital-accessibility-scenexplain-transforms-multimedia-content-public-sector-organizations/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Enhancing Digital Accessibility: How SceneXplain Transforms Multimedia Content for Public Sector Organizations</div><div class="kg-bookmark-description">Explore SceneXplain&#x2019;s impact on digital accessibility, providing exceptional image descriptions and ensuring compliance with European standards for public sector organizations.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-publisher">World Health Organization</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/04/Jina-AI-Website-Banners-Templates---2023-04-19T150542.636-1.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a></figure><h3 id="exclusive-offer-for-business-users"><strong><strong>Exclusive Offer for Business Users</strong></strong></h3><p>Considering SceneXplain for large-scale enterprise usage? We&apos;ve got something special for you. Dive deep into SceneXplain&apos;s capabilities, features, and enterprise solutions with our exclusive PDF deck tailored for business users.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F447;</div><div class="kg-callout-text"><strong>Download the SceneXplain Enterprise PDF Deck Here</strong></div></div>
        <div class="kg-card kg-file-card ">
            <a class="kg-file-card-container" href="https://jina-ai-gmbh.ghost.io/content/files/2023/09/SceneXplain.pdf" title="Download" download>
                <div class="kg-file-card-contents">
                    <div class="kg-file-card-title">SceneXplain</div>
                    <div class="kg-file-card-caption">The leading image captioning and video summary solution for enterprises</div>
                    <div class="kg-file-card-metadata">
                        <div class="kg-file-card-filename">SceneXplain.pdf</div>
                        <div class="kg-file-card-filesize">19 MB</div>
                    </div>
                </div>
                <div class="kg-file-card-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class="a" points="8.25 14.25 12 18 15.75 14.25"/><line class="a" x1="12" y1="6.75" x2="12" y2="18"/><circle class="a" cx="12" cy="12" r="11.25"/></svg>
                </div>
            </a>
        </div>
        <p>This comprehensive guide will provide you with in-depth insights, case studies, and a clear roadmap on how SceneXplain can revolutionize your business&apos;s visual comprehension needs.</p><h3 id="conclusion-scenexplainthe-future-of-visual-comprehension"><strong><strong>Conclusion: SceneXplain - The Future of Visual Comprehension</strong></strong></h3><p>From digital marketing to e-commerce, news reporting to accessibility, SceneXplain is redefining boundaries. Its real-world impact is evident, and its potential is limitless. As industries evolve, SceneXplain stands ready to meet the challenges, driving innovation and inclusivity.</p><p><strong>Ready to explore SceneXplain?</strong> Dive in and discover the future of visual comprehension. For more insights, check out our other articles and stay updated on the latest in AI image captioning. </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SceneXplain - Leading AI Solution for Image Captions and Video Summaries</div><div class="kg-bookmark-description">Experience cutting-edge computer vision with our premier image captioning and video summarization algorithms. Tailored for content creators, media professionals, SEO experts, and e-commerce enterprises. Featuring multilingual support and seamless API integration. Elevate your digital presence today.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://scenex.jina.ai/icons/apple-icon-180x180.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"><span class="kg-bookmark-author">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://scenex.jina.ai/banner.png" alt="SceneXplain vs. GPT-4 Vision: The Best Image Captioning Tool in 2023?"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Maximizing Efficiency and Savings with PromptPerfect's New Feature: Unified Credits]]></title><description><![CDATA[Introducing Unified Credits: Seamlessly share credits between PromptPerfect and SceneXplain, maximizing efficiency and cost savings for power users. ]]></description><link>https://jina.ai/news/maximizing-efficiency-and-savings-with-promptperfects-new-feature-unified-credits/</link><guid isPermaLink="false">6512f523b8ba9c00011e12cb</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Miruna Nedelcu]]></dc:creator><pubDate>Wed, 27 Sep 2023 14:00:33 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--8-.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--8-.png" alt="Maximizing Efficiency and Savings with PromptPerfect&apos;s New Feature: Unified Credits"><p>Are you ready to take your productivity to the next level? </p><p><a href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io">PromptPerfect</a>, your trusted partner for enhancing your writing experience, is thrilled to introduce a groundbreaking feature that will revolutionize the way you use our tools. Say hello to <strong>Unified Credits</strong> &#x2013; a game-changer for power users like you!</p><figure class="kg-card kg-video-card kg-card-hascaption"><div class="kg-video-container"><video src="https://jina-ai-gmbh.ghost.io/content/media/2023/09/1--1--1.mp4" poster="https://img.spacergif.org/v1/2304x1440/0a/spacer.png" width="2304" height="1440" loop autoplay muted playsinline preload="metadata" style="background: transparent url(&apos;https://jina-ai-gmbh.ghost.io/content/images/2023/09/media-thumbnail-ember101.jpg&apos;) 50% 50% / cover no-repeat;"></video><div class="kg-video-overlay"><button class="kg-video-large-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button></div><div class="kg-video-player-container kg-video-hide"><div class="kg-video-player"><button class="kg-video-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button><button class="kg-video-pause-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/><rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/></svg></button><span class="kg-video-current-time">0:00</span><div class="kg-video-time">/<span class="kg-video-duration"></span></div><input type="range" class="kg-video-seek-slider" max="100" value="0"><button class="kg-video-playback-rate">1&#xD7;</button><button class="kg-video-unmute-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/></svg></button><button class="kg-video-mute-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/></svg></button><input type="range" class="kg-video-volume-slider" max="100" value="100"></div></div></div><figcaption>Tutorial Unified Credits</figcaption></figure><h2 id="what-are-unified-credits">What are Unified Credits?</h2><p>Unified Credits is the latest innovation from PromptPerfect that allows you to seamlessly share credits between PromptPerfect and our sister product, SceneXplain. This integration empowers you with unprecedented flexibility and convenience, ultimately enhancing your writing journey.</p><h2 id="why-should-i-buy-unified-credits">Why should I buy Unified Credits?</h2><p><br>Here&apos;s what&apos;s in it for you:</p><h3 id="maximize-value">Maximize Value</h3><p>With Unified Credits, you can now maximize the value of your credits by using them interchangeably between PromptPerfect and SceneXplain. Whether you&apos;re an aspiring novelist, a content creator, or a professional writer, this feature will make your work more efficient and cost-effective.</p><h3 id="save-costs">Save Costs</h3><p>Gone are the days of purchasing separate credits for different tools. Unified Credits lets you share your credits without incurring any additional costs. It&apos;s a win-win situation for your wallet and your writing.</p><h3 id="how-it-works">How It Works</h3><figure class="kg-card kg-video-card kg-card-hascaption"><div class="kg-video-container"><video src="https://jina-ai-gmbh.ghost.io/content/media/2023/09/1--1-.mp4" poster="https://img.spacergif.org/v1/2304x1440/0a/spacer.png" width="2304" height="1440" loop autoplay muted playsinline preload="metadata" style="background: transparent url(&apos;https://jina-ai-gmbh.ghost.io/content/images/2023/09/media-thumbnail-ember74.jpg&apos;) 50% 50% / cover no-repeat;"></video><div class="kg-video-overlay"><button class="kg-video-large-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button></div><div class="kg-video-player-container kg-video-hide"><div class="kg-video-player"><button class="kg-video-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button><button class="kg-video-pause-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/><rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/></svg></button><span class="kg-video-current-time">0:00</span><div class="kg-video-time">/<span class="kg-video-duration"></span></div><input type="range" class="kg-video-seek-slider" max="100" value="0"><button class="kg-video-playback-rate">1&#xD7;</button><button class="kg-video-unmute-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/></svg></button><button class="kg-video-mute-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/></svg></button><input type="range" class="kg-video-volume-slider" max="100" value="100"></div></div></div><figcaption>Tutorial Unified Credits</figcaption></figure><p>Getting started with Unified Credits is easy:</p><ol><li><strong>Update Your Apps</strong>: For a smooth experience, make sure that both PromptPerfect and SceneXplain are updated to the latest version.</li><li><strong>Access the &apos;Account&apos; Tab</strong>: Open either PromptPerfect or SceneXplain and navigate to the &apos;Account&apos; tab.</li><li><strong>Select &quot;Share Credits&quot;</strong>: Inside the &apos;Account&apos; tab, you&apos;ll find the &quot;Share credits&quot; option. Click on it to initiate the process.</li><li><strong>Choose Your App</strong>: Pick the app (PromptPerfect or SceneXplain) that you want to connect to. </li><li><strong>Connect and Done</strong>: Confirm the connection, and that&apos;s it! Your credits are now unified, ready to be used seamlessly across both tools.</li></ol><h2 id="enjoy-the-benefits">Enjoy the Benefits</h2><p>With Unified Credits, you can experience a new level of efficiency, productivity, and cost savings in your writing endeavors. Whether you&apos;re drafting a novel in <a href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io">PromptPerfect</a> or crafting engaging explanations in <a href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io">SceneXplain</a>, your credits are now at your fingertips, waiting to be utilized.</p><p>Don&apos;t wait any longer &#x2013; upgrade your writing experience with Unified Credits today and unlock the full potential of <a href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io">PromptPerfect</a> and SceneXplain.</p><h2 id="get-started-now">Get started now!</h2><p>If you have any questions or need assistance, feel free to <a href="https://discord.com/invite/AWXCCC6G2P?ref=jina-ai-gmbh.ghost.io">reach out</a> to our dedicated support team. We&apos;re here to make your journey as smooth and enjoyable as possible.</p><p>Stay tuned for more exciting updates from Jina AI as we continue to innovate and enhance your writing experience.</p><p></p><p><br></p><p><br></p><p><br></p>]]></content:encoded></item><item><title><![CDATA[Jina 3.21.0 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-21-0-update/</link><guid isPermaLink="false">6513056fb8ba9c00011e132c</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Tue, 26 Sep 2023 16:27:16 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Image-Jina-dark.jpg" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3210">Release Note (<code>3.21.0</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Image-Jina-dark.jpg" alt="Jina 3.21.0 Update"><p>This release contains 1 new feature, 4 bug fixes, and 1 documentation improvement.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.21.0?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Release v3.21.0 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.21.0) Release time: 2023-09-26 15:54:28 This release contains 1 new feature, 4 bug fixes, and 1 documentation improvement.&#x1F195; FeaturesAdd return_type parameter to gateway streamer&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Jina 3.21.0 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/1877d2f667bb48c4e89982137b897330112ecd4c21a092cf9058fce5791e4474/jina-ai/jina/releases/tag/v3.21.0" alt="Jina 3.21.0 Update"></div></a></figure><h2 id="%F0%9F%86%95-features">&#x1F195; Features</h2><h3 id="add-returntype-parameter-to-gateway-streamer-methods-6027">Add <code>return_type</code> parameter to gateway streamer methods (<a href="https://github.com/jina-ai/jina/pull/6027?ref=jina-ai-gmbh.ghost.io">#6027</a>)</h3><p>By default, <code>GatewayStreamer</code> will fetch executor input and output schemas and reconstruct docarray models dynamically. The output schemas will be used to cast the responses at the gateway level.</p><p>Although the cast responses are nearly identical to the original schemas defined at the executor level, they might fail some checks. For example, if the gateway receives a document <code>doc</code> from an executor with output <code>MyDoc</code>, the following check will fail:</p><pre><code class="language-Python">assert isinstance(doc, MyDoc)</code></pre><p>Similarly, adding <code>doc</code> to a <code>DocList[MyDoc]</code> will fail the type checks.</p><p>To prevent this, the user of a <code>GatewayStreamer</code> can now use the <code>return_type</code> parameter to explicitly specify the type that will be used to cast the response. Output responses received from gateway streamer methods will always match the specified return type.</p><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-topology-schema-validation-6057">Fix topology schema validation (<a href="https://github.com/jina-ai/jina/pull/6057?ref=jina-ai-gmbh.ghost.io">#6057</a>)</h3><p>Previously, if the endpoint model schemas of different Executors in a Flow did not match exactly, the Flow would fail to start, Even if the difference was as small as a different default value, it would still give rise to this error.</p><p>We have fixed this bug by relaxing the model schema checking to only verify that the types of properties match.</p><h3 id="fix-consensus-module-memory-leak-6054">Fix consensus module memory leak (<a href="https://github.com/jina-ai/jina/pull/6054?ref=jina-ai-gmbh.ghost.io">#6054</a>)</h3><p>In the consensus <code>golang</code> module, some allocated strings were not being properly released. We have repaired this.</p><h3 id="document-casting-in-flow-gateway-6032">Document casting in Flow gateway (<a href="https://github.com/jina-ai/jina/pull/6032?ref=jina-ai-gmbh.ghost.io">#6032</a>)</h3><p>This bug is related to <a href="https://github.com/jina-ai/jina/pull/6027?ref=jina-ai-gmbh.ghost.io">#6027</a>. We now use the <code>return_type</code> parameter in <code>GatewayStreamer</code> to ensure that Documents received at the gateway level are properly cast to the correct schema. This prevents validation and serialization errors that previously occurred.</p><h3 id="remove-sandbox-6047">Remove sandbox (<a href="https://github.com/jina-ai/jina/pull/6047?ref=jina-ai-gmbh.ghost.io">#6047</a>)</h3><p>Remove support for deploying Executors in the Jina Cloud sandbox, since the sandbox has been deprecated.</p><h2 id="%F0%9F%93%97-documentation-improvements">&#x1F4D7; Documentation Improvements</h2><ul><li>Make example copy-pastable (<a href="https://github.com/jina-ai/jina/pull/6052?ref=jina-ai-gmbh.ghost.io">#6052</a>)</li></ul><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a>)</li><li>Naymul Islam (<a href="https://github.com/ai-naymul?ref=jina-ai-gmbh.ghost.io">@ai-naymul</a>)</li><li>Deepankar Mahapatro (<a href="https://github.com/deepankarm?ref=jina-ai-gmbh.ghost.io">@deepankarm</a>)</li><li>AlaeddineAbdessalem (<a href="https://github.com/alaeddine-13?ref=jina-ai-gmbh.ghost.io">@alaeddine-13</a>)</li><li>Han Xiao (<a href="https://github.com/hanxiao?ref=jina-ai-gmbh.ghost.io">@hanxiao</a>)</li><li>XXIV (<a href="https://github.com/thechampagne?ref=jina-ai-gmbh.ghost.io">@thechampagne</a>)</li></ul>]]></content:encoded></item><item><title><![CDATA[SceneXplain's Image-to-JSON: Extract Structured Data from Images with Precision]]></title><description><![CDATA[Pushing the boundaries of visual AI, we're thrilled to unveil SceneXplain's Image-to-JSON feature. Dive into a world where images aren't just seen, but deeply understood, translating visuals into structured data with unparalleled precision.]]></description><link>https://jina.ai/news/scenexplains-image-json-extract-structured-data-images-precision/</link><guid isPermaLink="false">6502e68d602cba00018fe0b6</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Thu, 14 Sep 2023 13:33:31 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--7-.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--7-.png" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"><p>In the ever-evolving world of multimodal AI and computer vision, <a href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io">SceneXplain</a> consistently pushes the boundaries. Today, we&apos;re thrilled to introduce a feature that promises to redefine the landscape of image captioning: <strong>Image-to-JSON</strong>. Let&apos;s delve into this innovation and understand its transformative potential.</p><figure class="kg-card kg-video-card kg-card-hascaption"><div class="kg-video-container"><video src="https://jina-ai-gmbh.ghost.io/content/media/2023/09/scenexplain-json.mp4" poster="https://img.spacergif.org/v1/1422x962/0a/spacer.png" width="1422" height="962" playsinline preload="metadata" style="background: transparent url(&apos;https://jina-ai-gmbh.ghost.io/content/images/2023/09/media-thumbnail-ember329.jpg&apos;) 50% 50% / cover no-repeat;"></video><div class="kg-video-overlay"><button class="kg-video-large-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button></div><div class="kg-video-player-container"><div class="kg-video-player"><button class="kg-video-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button><button class="kg-video-pause-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/><rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/></svg></button><span class="kg-video-current-time">0:00</span><div class="kg-video-time">/<span class="kg-video-duration"></span></div><input type="range" class="kg-video-seek-slider" max="100" value="0"><button class="kg-video-playback-rate">1&#xD7;</button><button class="kg-video-unmute-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/></svg></button><button class="kg-video-mute-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/></svg></button><input type="range" class="kg-video-volume-slider" max="100" value="100"></div></div></div><figcaption>A demo of SceneXplain&apos;s new image-to-JSON feature</figcaption></figure><h2 id="scenexplains-image-captioning-ability">SceneXplain&apos;s Image Captioning Ability</h2><p>SceneXplain stands as a beacon in advanced image captioning and video summarization. Thanks to Jina AI&apos;s state-of-the-art multimodal algorithms, SceneXplain transcends traditional captioning, offering rich textual narratives from visuals. With an intuitive interface and a robust API, it&apos;s designed for both seasoned users and developers.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://scenex.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">SceneXplain - Leading AI Solution for Image Captions and Video Summaries</div><div class="kg-bookmark-description">Experience cutting-edge computer vision with our premier image captioning and video summarization algorithms. Tailored for content creators, media professionals, SEO experts, and e-commerce enterprises. Featuring multilingual support and seamless API integration. Elevate your digital presence today.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://scenex.jina.ai/icons/apple-icon-180x180.png" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"><span class="kg-bookmark-author">SceneXplain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://scenex.jina.ai/banner.png" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"></div></a></figure><h2 id="understanding-json-schema">Understanding JSON Schema</h2><p>Before delving into the Image-to-JSON feature, it&apos;s essential to understand JSON Schema. </p><p>JSON Schema is a vocabulary that allows you to annotate and validate JSON documents. Think of it as a blueprint for the structure of your JSON data. It defines the shape of your data, types of data values, and even the range of permissible values. <strong>With JSON Schema, you can tailor the data extraction process to your specific needs.</strong></p><!--kg-card-begin: html--><table border="0" cellpadding="10" cellspacing="0">
    <thead>
        <tr>
            <th>a JSON file</th>
            <th>the JSON Schema defines the right JSON</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
<pre>{
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;age&quot;: 30,
  &quot;isStudent&quot;: false,
  &quot;courses&quot;: [&quot;Math&quot;, &quot;Science&quot;]
}
</pre>
            </td>
            <td>
<pre>{
  &quot;$schema&quot;: &quot;http://json-schema.org/draft-07/schema#&quot;,
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;name&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;description&quot;: &quot;Full name of the person&quot;
    },
    &quot;age&quot;: {
      &quot;type&quot;: &quot;number&quot;,
      &quot;description&quot;: &quot;Age of the person&quot;
    },
    &quot;isStudent&quot;: {
      &quot;type&quot;: &quot;boolean&quot;,
      &quot;description&quot;: &quot;Indicates if the person is a student&quot;
    },
    &quot;courses&quot;: {
      &quot;type&quot;: &quot;array&quot;,
      &quot;items&quot;: {
        &quot;type&quot;: &quot;string&quot;
      },
      &quot;description&quot;: &quot;List of courses the person is enrolled in&quot;
    }
  },
  &quot;required&quot;: [&quot;name&quot;, &quot;age&quot;, &quot;isStudent&quot;, &quot;courses&quot;]
}
</pre>
            </td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://json-schema.org/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">JSON Schema</div><div class="kg-bookmark-description">The home of JSON Schema</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://json-schema.org/favicon.ico" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"><span class="kg-bookmark-author">JSON Schema</span><span class="kg-bookmark-publisher">JSON Schema</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://json-schema.org/assets/logo-slack.svg" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"></div></a></figure><h2 id="the-image-to-json-revolution">The Image-to-JSON Revolution</h2><p>In traditional image captioning, the process has been linear: input an image and receive a text description. This approach, while effective, lacked the flexibility to extract specific data or focus on particular areas within an image. Enter SceneXplain&apos;s Image-to-JSON feature, our innovative solution to these limitations.</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/mermaid-diagram-2023-09-14-132512.svg" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="300" height="94"></figure><p>With Image-to-JSON, users upload an image and accompany it with a custom JSON Schema. The result? A structured JSON output tailored to capture specific information, whether it&apos;s in enums, lists, strings, booleans, or numbers.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-22.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="500" height="750"><figcaption>The image we used in SceneXplain on three different tasks: <a href="https://scenex.jina.ai/share?thread=YAcPQYjYXhP4wU6mw7vn&amp;ref=jina-ai-gmbh.ghost.io">image captioning</a>; <a href="https://scenex.jina.ai/share?thread=tW1LPU0CemEXVvNgOuhm&amp;ref=jina-ai-gmbh.ghost.io">visual question answering</a>; <a href="https://scenex.jina.ai/share?thread=MGXZbSJH2lSDUmfBHnZY&amp;ref=jina-ai-gmbh.ghost.io">Image-to-JSON</a>. Results can be found below.</figcaption></figure><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-3.png" width="1026" height="916" loading="lazy" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Untitled-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/Untitled-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-3.png 1026w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-4.png" width="1022" height="554" loading="lazy" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Untitled-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/Untitled-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-4.png 1022w" sizes="(min-width: 720px) 720px"></div></div></div><figcaption>Left: <a href="https://scenex.jina.ai/share?thread=YAcPQYjYXhP4wU6mw7vn&amp;ref=jina-ai-gmbh.ghost.io">image captioning</a>; Center: <a href="https://scenex.jina.ai/share?thread=tW1LPU0CemEXVvNgOuhm&amp;ref=jina-ai-gmbh.ghost.io">visual question answering</a></figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-28.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="1000" height="1917" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-28.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-28.png 1000w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://scenex.jina.ai/share?thread=MGXZbSJH2lSDUmfBHnZY&amp;ref=jina-ai-gmbh.ghost.io">Image-to-JSON</a></figcaption></figure><h4 id="from-prompting-to-structured-outputs">From Prompting to Structured Outputs</h4><p>The concept of prompting, popularized by large language models (LLMs), involves guiding AI responses using specific questions or instructions. For example, prompting an LLM with &quot;Describe the Eiffel Tower&quot; yields a textual description. However, this output, while informative, is unstructured.</p><p>Image-to-JSON takes prompting to the next level. The <code>description</code> field in the JSON schema serves as an advanced prompt. Instead of just a textual response, SceneXplain processes the image and structures its output based on the provided schema. This ensures not just relevance but also precision and consistency in the format.</p><p>This structured approach is especially crucial for applications that demand consistent data formats. While free-form text outputs offer flexibility, they can be challenging to integrate into systems that require structured data. Image-to-JSON bridges this gap, combining the adaptability of prompting with the reliability of structured outputs.</p><p>In essence, SceneXplain&apos;s Image-to-JSON is a testament to the evolution of AI comprehension. It showcases how AI can be both versatile in understanding visuals and precise in delivering structured, actionable data.</p><h2 id="how-to-use-image-to-json-in-scenexplain">How to Use Image-to-JSON in SceneXplain</h2><p>To harness this feature, users need to upload their image and define a corresponding JSON schema. To do this, click the dropdown button on the right of the input box and then select &quot;Add JSON Schema&quot;.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-23.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="2000" height="927" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-23.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-23.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-23.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2023/09/image-23.png 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>This schema comprises key-value pairs, with two essential keys:</p><ul><li><strong><code>type</code></strong>: This determines the result format, such as string, list, boolean, etc.</li><li><strong><code>description</code></strong>: This serves as a prompt, guiding the kind of information to extract from the image.</li></ul><p>Let&apos;s explore this with increasingly complex examples:</p><p><strong>Basic Inventory Check</strong>:</p><pre><code class="language-json">{
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;brands&quot;: {
      &quot;type&quot;: &quot;list&quot;,
      &quot;description&quot;: &quot;Identify brands on the shelf.&quot;
    }
  }
}
</code></pre><p><strong>Season Identification</strong>:</p><pre><code class="language-json">{
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;season&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;enum&quot;: [&quot;Spring&quot;, &quot;Summer&quot;, &quot;Autumn&quot;, &quot;Winter&quot;],
      &quot;description&quot;: &quot;Determine the predominant season in the image.&quot;
    }
  }
}
</code></pre><p><strong>Detailed Landscape Analysis</strong>:</p><pre><code class="language-json">{
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;flora&quot;: {
      &quot;type&quot;: &quot;list&quot;,
      &quot;description&quot;: &quot;List all visible plant species.&quot;
    },
    &quot;fauna&quot;: {
      &quot;type&quot;: &quot;list&quot;,
      &quot;description&quot;: &quot;List all visible animal species.&quot;
    },
    &quot;timeOfDay&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;enum&quot;: [&quot;Morning&quot;, &quot;Afternoon&quot;, &quot;Evening&quot;, &quot;Night&quot;],
      &quot;description&quot;: &quot;Identify the time of day.&quot;
    }
  }
}
</code></pre><h3 id="some-examples">Some Examples</h3><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-24.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="822" height="1818" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-24.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-24.png 822w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-25.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="816" height="1848" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-25.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-25.png 816w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-26.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="912" height="1682" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-26.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-26.png 912w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-27.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="748" height="1630" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-27.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-27.png 748w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-8.png" width="506" height="1580" loading="lazy" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-7.png" width="506" height="1554" loading="lazy" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-6.png" width="502" height="1566" loading="lazy" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision"></div></div></div><figcaption>One can also use Image-to-JSON as an advanced OCR solution</figcaption></figure><h2 id="real-world-applications-and-api-integration">Real-World Applications and API Integration</h2><p>Beyond the user interface, this feature can be seamlessly integrated into systems via our API. For developers looking to harness the power of Image-to-JSON programmatically, our <a href="https://scenex.jina.ai/api?ref=jina-ai-gmbh.ghost.io">API documentation</a> provides comprehensive guidance.</p><figure class="kg-card kg-image-card"><a href="https://scenex.jina.ai/api?ref=jina-ai-gmbh.ghost.io"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-21.png" class="kg-image" alt="SceneXplain&apos;s Image-to-JSON: Extract Structured Data from Images with Precision" loading="lazy" width="2000" height="1634" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-21.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-21.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-21.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-21.png 2242w" sizes="(min-width: 720px) 720px"></a></figure><h2 id="image-to-json-vs-vqa-image-captioning">Image-to-JSON vs. VQA &amp; Image Captioning</h2><p>The table below provides a clear comparison between SceneXplain&apos;s Image-to-JSON, Visual Question Answering (VQA), Traditional Image Captioning, and the Good-Old OCR based on various features.</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Task</th>
<th>SceneXplain&apos;s Image-to-JSON</th>
<th>Visual Question Answering</th>
<th>Traditional Image Captioning</th>
<th>OCR</th>
</tr>
</thead>
<tbody>
<tr>
<td>Flexibility</td>
<td>Customizable JSON output</td>
<td>Customizable queries</td>
<td>Fixed text description</td>
<td>Extracted text snippets</td>
</tr>
<tr>
<td>Output Types</td>
<td>Structured: Enums, Lists, Strings, Booleans, Numbers (including nested structures)</td>
<td>Text only</td>
<td>Text only</td>
<td>Text only</td>
</tr>
<tr>
<td>Granularity of Information</td>
<td>High (detailed structured data)</td>
<td>Medium (depends on the query)</td>
<td>Low (general description)</td>
<td>Low (text without context)</td>
</tr>
<tr>
<td>User Control</td>
<td>Full via JSON Schema</td>
<td>Limited by precise prompting</td>
<td>None</td>
<td>None</td>
</tr>
<tr>
<td>Custom Queries</td>
<td>Supported via &quot;description&quot; key</td>
<td>Possible</td>
<td>Not available</td>
<td>Not applicable</td>
</tr>
<tr>
<td>Integration Complexity</td>
<td>Moderate (due to structured output)</td>
<td>Low (simple text output)</td>
<td>Low (simple text output)</td>
<td>Low (simple text output)</td>
</tr>
<tr>
<td>Scalability</td>
<td>High (designed for large-scale data processing)</td>
<td>Medium (depends on backend)</td>
<td>Medium (depends on backend)</td>
<td>High (simple text extraction)</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h2 id="in-conclusion">In Conclusion</h2><p>SceneXplain&apos;s Image-to-JSON isn&apos;t just an incremental improvement; it&apos;s a monumental leap. By offering unparalleled flexibility and precision, we&apos;re empowering users to extract the exact insights they seek from images. As we continue our innovation journey, we eagerly await the myriad ways you&apos;ll employ this feature to redefine visual comprehension.</p><p>Stay connected for more groundbreaking updates from SceneXplain!</p>]]></content:encoded></item><item><title><![CDATA[Embeddings: The Swiss Army Knife of AI]]></title><description><![CDATA[Embeddings are an essential technology for modern AI. This article explains what they are and how they work.]]></description><link>https://jina.ai/news/embeddings-the-swiss-army-knife-of-ai/</link><guid isPermaLink="false">65002f0e5fa9490001805f9d</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Scott Martens]]></dc:creator><pubDate>Wed, 13 Sep 2023 13:17:26 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/DALL-E-2023-09-12-16.33.14---red-enamel.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/DALL-E-2023-09-12-16.33.14---red-enamel.png" alt="Embeddings: The Swiss Army Knife of AI"><p>A Swiss Army knife is a versatile, compact tool that you can keep in your pocket until you need it. It&#x2019;s handy and designed to meet common unplanned needs. Have to cut something? It&#x2019;s a knife. Have to unscrew something? It&#x2019;s a screwdriver. Need to open a bottle or a can? It can do that, too. They&#x2019;ve become so famous that &#x201C;to be the Swiss Army knife of something&#x201D; is now a figure of speech used for any versatile, adaptable, and highly useful tool.</p><p>AI tools are a bit too abstract to put in your pocket, but just because a tool is abstract doesn&#x2019;t mean that words like <em>specialized</em>, <em>versatile</em>, and <em>adaptable</em> don&#x2019;t apply to it! </p><p>One of AI&apos;s most versatile, adaptable, albeit abstract, tools goes by the name <em>embeddings</em>. Embeddings are actively in use for:</p><ul><li>Search and information retrieval for all media types</li><li>Question-answering systems</li><li>Recommender systems</li><li>Outlier detection (often as part of fraud detection)</li><li>Spellchecking and grammar correction</li><li>Natural language understanding</li><li>Machine translation</li></ul><p>This is a far from exhaustive list. Nearly every AI application uses them. Even image generators and chatbots like ChatGPT rely on embeddings internally.</p><h2 id="what-is-an-embedding">What is an embedding?</h2><p>An <em>embedding</em> is a representation of some data object as a <em>vector</em>, constructed so that some properties of the data object are encoded into the geometric properties of its vector representation.</p><p>That&#x2019;s awfully abstract, but it&#x2019;s not really as complicated as it sounds.</p><p>First, we need to introduce a little (very little) bit of math. A <em>vector</em> is two things that sound like they&apos;re different but are actually the same:</p><ol><li>A vector is a point in a multidimensional space.</li><li>A vector is an ordered list of scalar values, i.e., numbers.</li></ol><p>To see how this works, consider lists of two numbers. For example, $(6, 4)$ and $(2, 8)$. &#xA0;You see that we could treat them as coordinates on an x-y axis, with each list corresponding to a point in a two-dimensional space:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/xy_coords.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1425" height="1400" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/xy_coords.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/xy_coords.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/xy_coords.png 1425w" sizes="(min-width: 720px) 720px"></figure><p>If we have three numbers, like $(3, 2, 5)$ and $(4, 5, 2)$, then this corresponds to points in a three-dimensional space:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/3d.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1079" height="937" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/3d.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/3d.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/3d.png 1079w" sizes="(min-width: 720px) 720px"></figure><p>The important point is that we could extend this into more dimensions: four, five, a hundred, a thousand, even millions or billions. Drawing a space with a thousand dimensions is very hard, and imagining one is all but impossible, but mathematically, it&#x2019;s really easy.</p><p>For example, the distance between points $(6, 4)$ and $(2, 8)$ is simply an application of <a href="https://en.wikipedia.org/wiki/Pythagorean_theorem?ref=jina-ai-gmbh.ghost.io">Pythagoras&#x2019; theorem</a>. Given two points $a = (x_1, y_1)$ and $b = (x_2, y_2)$, the distance between them is:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-7-1.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1600" height="198" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-7-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-7-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-7-1.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>For $(6, 4)$ and $(2, 8)$, this means:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-15.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1600" height="375" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-15.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-15.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-15.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>For three dimensions, we just extend the formula by adding a term. For $a = (3, 2, 5)$ and $b = (4, 5, 2)$:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-16.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1600" height="365" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-16.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-16.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-16.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>We can extend this formula to vectors in any number of dimensions. We just add more terms, the same way we did by going from two to three dimensions.</p><p>Besides distance, another measurement we use in high-dimensional vector spaces is the cosine of the angle between the two vectors. If you see each vector not just as a point but as a line from the origin (the point designated by the vector $(0,0,0,...)$), then you can calculate the angle between the two vectors ($\theta$ in the image below).</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/cosine2.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1611" height="918" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/cosine2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/cosine2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/cosine2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/cosine2.png 1611w" sizes="(min-width: 720px) 720px"></figure><p>To calculate this, we have another formula that scales up to any number of dimensions. We know that the cosine of the angle $\theta$ between vectors $a$ and $b$ is:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-11.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="2000" height="208" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-11.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-11.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-11.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-11.png 2000w" sizes="(min-width: 720px) 720px"></figure><p>This is more complicated than it looks, but not much. $a \cdot b$ is called the <em>dot product</em> of the two vectors, and it&#x2019;s easy to calculate. If $a = (3, 2, 5)$ and $b = (4, 5, 2)$, then:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-19.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1600" height="230" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-19.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-19.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-19.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>As for $&#x2016;a&#x2016;$ and $&#x2016;b&#x2016;$, those are the lengths of the vectors, i.e., the distance from the origin to that point. So:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-18.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1600" height="980" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-18.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-18.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-18.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>Therefore, to calculate $cos \theta$:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-17.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1600" height="379" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-17.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-17.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-17.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>This cosine corresponds to an angle of approximately 39.3&#xB0;, but in machine learning, we typically stop once we&#x2019;ve calculated the cosine because if all the numbers in both vectors are greater than zero, then the cosine of the angle will be between 0 and 1.</p><p>This looks like a lot of math, but if you look it over, you&#x2019;ll see that it&#x2019;s just addition, subtraction, multiplication, division, one exponent, and a square root. Simple but boring and repetitive stuff. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>You don&#x2019;t actually have to do any of this math. The whole reason we keep computers around is to do that sort of thing.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> But you should understand that vectors are lists of numbers, understand the concept of working with vectors, and understand how, no matter how many dimensions a vector has, we can still do things like calculate distances and angles.</p><p>What makes this so important is that any data we keep on a computer is also just a list of numbers. Every data item &#x2014; digital pictures, texts, audio recordings, 3D model files, anything you can think of that you can put into a computer file &#x2014; is a vector if we choose to look at it that way.</p><h2 id="how-do-we-assign-embedding-vectors-to-things">How do we assign embedding vectors to things?</h2><p>The point of embeddings is to assign vectors to data objects so that their placement in high-dimensional spaces encodes useful information about them. The data objects &#x2014; texts or images or whatever else we&#x2019;re working with &#x2014; are already vectors if we choose to look at them that way. The locations of those vectors don&#x2019;t tell us anything useful about them.</p><p>Consider these four images:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/ApplesAndOranges.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="900" height="900" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/ApplesAndOranges.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/ApplesAndOranges.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Each is a 450x450 pixel image colored with the standard RGB palette. This means the picture consists of 202,500 pixels, each with one number between 0 and 255 for its red, green, and blue values. To turn this into a vector with 607,500 dimensions is trivial.</p><p>We could take any pair of images and calculate the distance between them or measure their cosine, but it would be very unlikely that the apples would be especially close to each other or especially far from the oranges. At least, it would be very unlikely if we used hundreds of pictures of apples and oranges instead of just four.</p><p>More likely, we would get something like this:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/scatterplot.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="617" height="548" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/scatterplot.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/scatterplot.png 617w"></figure><p>We can&#x2019;t draw pictures in 600,000 dimensions, so this picture uses just two dimensions to demonstrate the point: We should expect that the apples and oranges are semi-randomly placed and mixed up together.</p><p>We want to assign to each image a unique embedding such that the apples are close together and far from the oranges, and vice-versa. We want something like this:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/unscatteredplot--1-.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="617" height="548" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/unscatteredplot--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/unscatteredplot--1-.png 617w"></figure><p>To do that, we construct a neural network (which we&#x2019;re going to call an <em>embedding model</em>) that takes 607,500 dimension vectors as input and outputs some other vector, typically with fewer dimensions. For example, the widely used <a href="https://huggingface.co/sentence-transformers/clip-ViT-B-32?ref=jina-ai-gmbh.ghost.io" rel="noopener noreferrer">ViT-B-32</a> image embedding model transforms input images into 512-dimension embedding vectors.</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-20.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1300" height="775" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-20.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-20.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-20.png 1300w" sizes="(min-width: 720px) 720px"></figure><p>We then train the embedding model with labeled pictures of apples and oranges, instructing it to adjust the network&#x2019;s weights slowly to separate the embedding vectors for apples and oranges. After many cycles of training, we expect that when we give the model pictures of apples as input, it will output vectors that are closer to each other than they are to the vectors we get when we give it pictures of oranges as inputs.</p><p>Those output vectors are <em>embeddings</em>, and they collectively form an <em>embedding space</em>. Individual embeddings&#x2019; locations encode useful information about their corresponding data objects: In this case, whether something is a picture of an apple or an orange.</p><p>Telling apples from oranges is a very simplistic scenario, but you might easily imagine scaling it up to many features.</p><p>In some use cases, we can even construct embeddings where we don&#x2019;t explicitly say what features are relevant, and we let the neural network figure it out in the training process. For example, we can construct a face recognition system by taking pictures of people&#x2019;s faces and training an embedding model to output embeddings that place pictures of the same person close together. We can then construct a database of people&apos;s pictures with their embedding vectors as keys.</p><p>We would expect the stored faces to be distributed through the embedding space:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Faces1.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="801" height="800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Faces1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Faces1.png 801w" sizes="(min-width: 720px) 720px"></figure><p>We might expect that this embedding space would encode a lot of features that we had never explicitly trained it to encode. For example, it might segregate men from women:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/FacesMenWomen.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="801" height="800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/FacesMenWomen.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/FacesMenWomen.png 801w" sizes="(min-width: 720px) 720px"></figure><p>Or we might find people clustered together by features of their hair, like baldness or grey:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/FacesHair.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="801" height="800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/FacesHair.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/FacesHair.png 801w" sizes="(min-width: 720px) 720px"></figure><p>But we would expect that if we gave it another picture of someone in the database, the embedding for that new picture would be closer to the picture we stored of that person than to anyone else:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Winona.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1100" height="800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Winona.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/Winona.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Winona.png 1100w" sizes="(min-width: 720px) 720px"></figure><p>Of course, it would also find people who just <em>look</em> similar, although we hope that they wouldn&#x2019;t be as close together as two people who are actually the same:</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Elijah.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="1100" height="800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Elijah.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/Elijah.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Elijah.png 1100w" sizes="(min-width: 720px) 720px"></figure><p>This highlights the logic of embedding spaces: Inputs are diverse, but by translating them into embeddings, we turn features &#x2014; sometimes complex, hidden, subtle, or non-obvious features &#x2014; &#xA0;into geometric properties that software can easily identify.</p><p>Embedding spaces can also support diverse input types, like text and images, creating a common embedding space and enabling you to map between the two.</p><p>For example, if we have a database of pictures with descriptive captions, we can co-train two embedding models &#x2014; one for images and one for texts &#x2014; to output vectors in the same embedding space. The result is that embeddings of descriptions of images and embeddings of the images themselves will be near each other.</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/DualEmbedding.png" class="kg-image" alt="Embeddings: The Swiss Army Knife of AI" loading="lazy" width="800" height="800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/DualEmbedding.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/DualEmbedding.png 800w" sizes="(min-width: 720px) 720px"></figure><p>In principle, any kind of digital data can serve as input for creating embeddings, and any paired data types &#x2014; not just text and images &#x2014; can serve to create multi-modal joint embedding spaces.</p><h2 id="what-are-embeddings-good-for">What are embeddings good for?</h2><p>Like the Swiss Army knife, the question should be, <em>what aren&#x2019;t they good for?</em></p><p>We&#x2019;ve already shown how you can use embeddings for image classification and face recognition, but that&#x2019;s far from exhausting the possibilities. For example, AI image production from text descriptions (a.k.a. &#x201C;AI art&#x201D;) starts by constructing a joint embedding space for text and images, and then, when the user enters a text, it calculates that text&#x2019;s embedding and tries to construct an image that will produce a nearby embedding.</p><p>Embeddings are so generally useful that they see applications all over AI and machine learning. Any application that requires similarity/dissimilarity evaluation, relies on hidden or non-obvious features, or requires implicit context-sensitive mappings between different inputs and outputs, likely uses embeddings in some form.</p><h2 id="conclusion">Conclusion</h2><p>Embeddings are an essential technology for modern machine learning and AI, present in some form across the spectrum of AI applications. Properly understanding and mastering this technology positions you to leverage AI models to add the most value to your business.</p><p>The theory behind embeddings isn&#x2019;t even complicated: All it involves is a map from data objects to points in a high dimensional vector space where things that have properties in common that matter to you cluster together. Using them is just a matter of measuring vector distances and cosines, which is computationally trivial math!</p><p>Unfortunately, the practice of constructing and training embedding models is more complex than using them. Jina AI is developing a collection of high-performance specialized embedding models that you can download or use via our public API, without any of the complexities of AI development. We are also preparing a suite of open-source tools in Python to help you integrate embedding models into your tech stack.</p><p>Jina AI is committed to providing you with tools and help for creating, optimizing, evaluating, and implementing embedding models for your enterprise. We&#x2019;re here to help you navigate the new world of business AI. Contact us via our <a href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io">website</a> or join our <a href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io">community on Discord</a> to get started.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina AI - Your Portal to Multimodal AI</div><div class="kg-bookmark-description">Jina AI offers powerful multimodal AI solutions for everyday users, developers, and scalable enterprise solutions. We aim to democratize access to the limitless potential of AI-generated creativity and innovation, empowering individuals and businesses alike.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="Embeddings: The Swiss Army Knife of AI"><span class="kg-bookmark-author">Your Portal to Multimodal AI</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina.ai/banner.png" alt="Embeddings: The Swiss Army Knife of AI"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://discord.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Join the Jina AI Discord Server!</div><div class="kg-bookmark-description">Check out the Jina AI community on Discord - hang out with 2677 other members and enjoy free voice and text chat.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://discord.jina.ai/assets/ec2c34cadd4b5f4594415127380a85e6.ico" alt="Embeddings: The Swiss Army Knife of AI"><span class="kg-bookmark-author">Discord</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.discordapp.com/splashes/1106542220112302130/80f2c2128aefeb55209a5bdb2130bb92.jpg?size=512" alt="Embeddings: The Swiss Army Knife of AI"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[PromptPerfect's LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation]]></title><description><![CDATA[Diving into PromptPerfect's LLM-as-a-database: a middle ground between few-shot prompts and RAG. Its nuanced approach outshines GPT-4 in complex queries. Evolution in action.]]></description><link>https://jina.ai/news/promptperfects-llm-database-blurring-boundaries-search-vs-generation/</link><guid isPermaLink="false">64ff24465fa9490001805ec5</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Mon, 11 Sep 2023 15:36:10 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--4-.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Explore-image-storytelling-beyond-pixels--4-.png" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation"><p>In the intricate world of generative AI, boundaries are akin to shifting sands, constantly reshaped by the winds of innovation. Last November, we introduced a fresh perspective with &quot;<a href="https://jina.ai/news/search-is-overfitted-create-create-is-underfitted-search/?ref=jina-ai-gmbh.ghost.io">Search is Overfitted Create; Create is Underfitted Search</a>&quot;, urging the community to view these boundaries in a new light. Now, with PromptPerfect&apos;s &quot;LLM as a database&quot;, we&apos;re not merely iterating on a trend; we&apos;re materializing our forward-thinking philosophy, crafting tools that resonate with our envisioned future of the generative AI landscape.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://promptperfect.jina.ai/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">PromptPerfect - Elevate Your Prompts to Perfection. Prompt Engineering, Optimizing, Debugging and Hosting.</div><div class="kg-bookmark-description">Unlock advanced prompt engineering and prompt optimization for large models such as GPT-4, ChatGPT, MidJourney and StableDiffusion. Seamlessly deploy your text and image prompts as dedicated services with our free prompt hosting plan. Enhance your large models with superior performance and efficienc&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://promptperfect.jina.ai/icons/apple-icon-180x180.png" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation"><span class="kg-bookmark-author">PromptPerfect</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://promptperfect.jina.ai/banner.png" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation"></div></a></figure><h2 id="a-spectrum-not-a-dichotomy">A Spectrum, Not a Dichotomy</h2><p>Historically, we&apos;ve perceived search and creation as two separate realms. But as the generative AI age progresses, it&apos;s becoming clear that they&apos;re more interconnected than we once believed. Search, in its most rigid form, <strong>can be seen as an overfitted version of creation</strong>, while creation, with its boundless potential, <strong>can be viewed as an underfitted form of search</strong>. PromptPerfect&apos;s new feature is a nod to this interconnectedness, offering a seamless blend of both.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/search-is-overfitted-create-create-is-underfitted-search/?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Search is Overfitted Create; Create is Underfitted Search</div><div class="kg-bookmark-description">The biggest competition of neural search may come from a technology that doesn&#x2019;t even need embeddings as an intermediate representation &#x2013; an end-to-end technology that directly returns the result you want.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation"></div></div><div class="kg-bookmark-thumbnail"><img src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/Jina-AI-Website-Banners-Templates--38-.png" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation"></div></a></figure><h2 id="how-to-use-llm-as-a-database-feature-in-promptperfect">How to use &quot;LLM as a Database&quot; Feature in PromptPerfect</h2><p>The beauty of the &quot;LLM as a database&quot; feature lies in its adaptability. Users can slide between the exactness of search and the novelty of creation, ensuring a tailored experience that meets specific needs.</p><figure class="kg-card kg-video-card kg-card-hascaption"><div class="kg-video-container"><video src="https://jina-ai-gmbh.ghost.io/content/media/2023/09/promptperfect-database2-1.mp4" poster="https://img.spacergif.org/v1/1422x962/0a/spacer.png" width="1422" height="962" playsinline preload="metadata" style="background: transparent url(&apos;https://jina-ai-gmbh.ghost.io/content/images/2023/09/media-thumbnail-ember319.jpg&apos;) 50% 50% / cover no-repeat;"></video><div class="kg-video-overlay"><button class="kg-video-large-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button></div><div class="kg-video-player-container"><div class="kg-video-player"><button class="kg-video-play-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button><button class="kg-video-pause-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/><rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/></svg></button><span class="kg-video-current-time">0:00</span><div class="kg-video-time">/<span class="kg-video-duration"></span></div><input type="range" class="kg-video-seek-slider" max="100" value="0"><button class="kg-video-playback-rate">1&#xD7;</button><button class="kg-video-unmute-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/></svg></button><button class="kg-video-mute-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/></svg></button><input type="range" class="kg-video-volume-slider" max="100" value="100"></div></div></div><figcaption>PromptPerfect&apos;s LLM as a database in action.</figcaption></figure><p>Here&apos;s a step-by-step breakdown of how users can navigate and leverage this feature:</p><ol><li><strong>Accessing the Feature</strong>: Upon opening PromptPerfect, users can easily locate and click on the &quot;LLM as a database&quot; tab.</li><li><strong>Database Creation</strong>: Users are presented with the option to create a new database. Here, they can specify which backend LLM they wish to use. Whether it&apos;s gpt3.5turbo, gpt4, claude2, llama2, or any other available model, the choice is at their fingertips.</li><li><strong>Data Import</strong>: Flexibility is key. Users can either bulk import their key-value pairs into the database or choose to manually add them one by one, catering to both large-scale and smaller, more specific projects.</li><li><strong>Deployment</strong>: Once satisfied with their database, users can deploy it in production. They have the option to make it public or keep it private, requiring a token for access. This ensures both accessibility and security, depending on the user&apos;s preference.</li><li><strong>Querying the Database</strong>: The real magic happens here. Users can query their database using curl, Python, or Javascript through a straightforward API. If the queried key exists in the database, it returns the corresponding value. But the standout feature is its ability to interpolate when faced with an unfamiliar key. Instead of returning an error or a blank, the system intelligently draws from existing key-value pairs to generate and return a plausible value.</li></ol><p>This user-centric design ensures that while the technology behind &quot;LLM as a database&quot; is complex, interacting with it is straightforward and intuitive. It&apos;s a blend of advanced tech with user-friendly design, making it accessible to both tech-savvy individuals and those less familiar with the intricacies of LLMs.</p><h2 id="what-can-llm-as-a-database-do-a-glimpse-into-examples">What Can &quot;LLM as a Database&quot; do: a Glimpse into Examples</h2><p>To further elucidate the potential of the &quot;LLM as a database&quot; feature, PromptPerfect has incorporated two built-in examples that showcase its versatility and depth:</p><h4 id="how-to-build-a-chatbot-from-a-faq-list">How to build a chatbot from a FAQ list?</h4><p>Drawing from real-world needs, we&apos;ve imported all the FAQ entries from our internship page. This provides users with an interactive bot that can answer any query related to our internship program. It&apos;s a testament to how businesses can streamline customer or user interactions, ensuring that queries are addressed promptly and accurately.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-3.png" class="kg-image" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation" loading="lazy" width="2000" height="1025" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-3.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2023/09/image-3.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>The FAQ question answer pairs we imported from: https://jina.ai/internship/</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-4.png" class="kg-image" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation" loading="lazy" width="2000" height="499" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-4.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-4.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-4.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2023/09/image-4.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>The output of &quot;can i get some kind of recommendation letter after the internship?&quot; from the database. This question does not exist in the pre-filled entries, but its answer can be derived from the database.</figcaption></figure><h4 id="how-to-build-a-translator-for-mathematical-expressions">How to build a translator for mathematical expressions?</h4><p>Delving into a more complex domain, we&apos;ve built a database that bridges the gap between natural language descriptions of mathematical transformations and their matrix representations. This isn&apos;t just about translating words into numbers; it&apos;s about understanding the underlying mathematical concepts and accurately representing them.</p><figure class="kg-card kg-image-card"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/image-5.png" class="kg-image" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation" loading="lazy" width="2000" height="1015" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/image-5.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/image-5.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/image-5.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2023/09/image-5.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>For instance, consider the task of translating an English description of a transformation in $R^2$ into its matrix form. The system is trained with a variety of sequence pairs, such as:</p><pre><code class="language-json">[
    {&quot;input&quot;: &quot;Rotation by 90 degrees counterclockwise.&quot;, &quot;output&quot;: &quot;0 -1; 1 0&quot;},
    {&quot;input&quot;: &quot;Scaling by a factor of 2 in the x-direction.&quot;, &quot;output&quot;: &quot;2 0; 0 1&quot;},
    {&quot;input&quot;: &quot;Reflection about the y-axis.&quot;, &quot;output&quot;: &quot;-1 0; 0 1&quot;},
    {&quot;input&quot;: &quot;Shear parallel to the x-axis with a factor of 2.&quot;, &quot;output&quot;: &quot;1 2; 0 1&quot;},
    ...
]
</code></pre><p>This example underscores the depth of understanding the system possesses, and its ability to handle intricate tasks that require both linguistic and mathematical prowess.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled.png" width="1656" height="1718" loading="lazy" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Untitled.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/Untitled.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/Untitled.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled.png 1656w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-2.png" width="2000" height="955" loading="lazy" alt="PromptPerfect&apos;s LLM-as-a-Database is Blurring the Boundaries of Search vs. Generation" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2023/09/Untitled-2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2023/09/Untitled-2.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2023/09/Untitled-2.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2023/09/Untitled-2.png 2060w" sizes="(min-width: 720px) 720px"></div></div></div><figcaption>Compare the output of GPT-4 and PromptPerfect&apos;s LLM-as-a-database on the query &quot;Rotation by 45 degrees counterclockwise followed by a shear parallel to the x-axis with a factor of 2, and then a scaling by a factor of 2 in the y-direction.&quot; One can clearly see PromptPerfect&apos;s output outperforms GPT4&apos;s.</figcaption></figure><p>These built-in examples serve as a starting point, inspiring users to envision and implement their own unique use cases. Whether it&apos;s simplifying customer interactions or tackling specialized tasks, the &quot;LLM as a database&quot; feature offers a canvas for innovation.</p><h3 id="practical-applications-you-can-build-with-llm-as-a-database">Practical Applications You Can Build with &quot;LLM as a Database&quot;</h3><ul><li><strong>Revolutionizing Customer Support</strong>: Instead of static responses, imagine a system that evolves with every interaction, learning and improvising, ensuring customers always receive relevant solutions.</li><li><strong>Elevating FAQ Bots</strong>: These aren&apos;t just chatbots. They&apos;re dynamic tools that can craft responses on-the-fly, ensuring every user query gets a tailored answer.</li><li><strong>Enhancing AI Interactions</strong>: Agents that recall past interactions and adapt to future ones, offering a user experience that&apos;s constantly refined.</li></ul><h2 id="comparing-llm-as-a-database-vs-few-shot-learning-and-rag">Comparing &quot;LLM as a Database&quot; vs. Few-shot Learning and RAG</h2><p>In the intricate tapestry of machine learning methodologies, understanding the nuances and positioning of new techniques relative to established paradigms is crucial. The &quot;LLM as a database&quot; feature introduced by PromptPerfect offers a unique perspective, and it&apos;s essential to discern its place amidst the prevailing technologies.</p><ol><li><strong>Few-shot Learning</strong>: Traditional few-shot learning operates on the principle of leveraging a limited set of examples to guide the model&apos;s response generation. It&apos;s a method that emphasizes the importance of context, allowing models to generate relevant outputs based on a handful of guiding examples. While powerful in its own right, few-shot learning is primarily context-driven.</li><li><strong>Retrieval-augmented Generation (RAG)</strong>: At the other end of the spectrum, RAG employs external datastores to enrich the prompt, pulling from vast repositories of information to enhance the generated response. It&apos;s a methodology that emphasizes comprehensive data retrieval, ensuring that the model&apos;s outputs are informed by a wide array of external data.</li><li><strong>&quot;LLM as a Database&quot; - Striking a Balance</strong>: PromptPerfect&apos;s &quot;LLM as a database&quot; feature can be visualized as occupying the middle ground between few-shot learning and RAG. It integrates the context-driven approach of few-shot learning with the data-rich capabilities of a database. Users can leverage the richness of key-value pairs for precise responses, while also benefiting from the model&apos;s ability to interpolate and generate insights. Moreover, the architecture of &quot;LLM as a database&quot; holds the potential to transition towards a full RAG system, offering users the flexibility to harness extensive external datastores when needed.</li></ol><p>In essence, the &quot;LLM as a database&quot; feature doesn&apos;t seek to replace or overshadow few-shot learning or RAG. Instead, it offers a harmonized approach, bridging the gap between context-driven generation and extensive data retrieval. It&apos;s a testament to the evolving nature of machine learning, where hybrid methodologies can harness the strengths of established paradigms to offer enhanced capabilities.</p><h2 id="final-thoughts">Final Thoughts</h2><p>PromptPerfect&apos;s &quot;LLM as a database&quot; isn&apos;t just a feature; it&apos;s a thoughtful exploration of the evolving relationship between search and creation. It&apos;s an invitation to see beyond traditional boundaries and to experience a tool that adapts to the user&apos;s needs. As we continue to navigate the generative AI age, innovations like these not only enhance our experiences but also challenge us to rethink our established paradigms.</p>]]></content:encoded></item><item><title><![CDATA[DocArray 0.38 Update]]></title><description><![CDATA[DocArray is a library for representing, sending and storing multi-modal data, perfect for Machine Learning applications.]]></description><link>https://jina.ai/news/docarray-0-38-update/</link><guid isPermaLink="false">64f9d1ed5fa9490001805e63</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Thu, 07 Sep 2023 13:48:55 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/docarray-new-banner--3-.png" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-0380">Release Note &#xA0;(<code>0.38.0</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/docarray-new-banner--3-.png" alt="DocArray 0.38 Update"><p>This release contains 3 bug fixes and 4 documentation improvements, including 1 breaking change.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/docarray/docarray/releases/tag/v0.38.0?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Release v0.38.0 &#xB7; docarray/docarray</div><div class="kg-bookmark-description">Release Note (0.38.0) Release time: 2023-09-07 13:40:16 This release contains 3 bug fixes and 4 documentation improvements, including 1 breaking change.&#x1F4A5; Breaking ChangesChanges to the return t&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="DocArray 0.38 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">docarray</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/f79c8f1657b21f2a25e1116095c41256f99b916e0405091f06274c3f386158e4/docarray/docarray/releases/tag/v0.38.0" alt="DocArray 0.38 Update"></div></a></figure><h2 id="%F0%9F%92%A5-breaking-changes">&#x1F4A5; Breaking Changes</h2><h3 id="changes-to-the-return-type-of-doclisttojson-and-docvectojson">Changes to the return type of <code>DocList.to_json()</code> and <code>DocVec.to_json()</code></h3><p>In order to make the <code>to_json</code> method consistent across different classes, we changed its return type in <code>DocList</code> and <code>DocVec</code> to <code>str</code>. This means that, if you use this method in your application, make sure to update your codebase to expect <code>str</code> instead of <code>bytes</code>.</p><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="make-doclisttojson-and-docvectojson-return-str-instead-of-bytes-1769">Make <code>DocList.to_json()</code> and <code>DocVec.to_json()</code> return <code>str</code> instead of <code>bytes</code> (<a href="https://github.com/docarray/docarray/pull/1769?ref=jina-ai-gmbh.ghost.io">#1769</a>)</h3><p>This release changes the return type of the methods <code>DocList.to_json()</code> and <code>DocVec.to_json()</code> in order to be consistent with <code>BaseDoc .to_json()</code> and other pydantic models. After this release, these methods will return <code>str </code> type data instead of <code>bytes</code>.</p><p>&#x1F4A5; Since the return type is changed, this is considered a breaking change.</p><h3 id="casting-in-reduce-before-appending-1758">Casting in <code>reduce</code> before appending (<a href="https://github.com/docarray/docarray/pull/1758?ref=jina-ai-gmbh.ghost.io">#1758</a>)</h3><p>This release introduces type casting internally in the <code>reduce</code> helper function, casting its inputs before appending them to the final result. This will make it possible to reduce documents whose schemas are compatible but not exactly the same.</p><h3 id="skip-doc-attributes-in-annotations-but-not-in-fields-1777">Skip doc attributes in <code>__annotations__</code> but not in <code>__fields__</code> (<a href="https://github.com/docarray/docarray/pull/1777?ref=jina-ai-gmbh.ghost.io">#1777</a>)</h3><p>This release fixes an issue in the <code>create_pure_python_type_model</code> helper function. Starting with this release, only attributes in the class <code>__fields__</code> will be considered during type creation. The previous behavior broke applications when users introduced a ClassVar in an input class:</p><pre><code class="language-Python">class MyDoc(BaseDoc):
    endpoint: ClassVar[str] = &quot;my_endpoint&quot;
    input_test: str = &quot;&quot;
    field_info = model.__fields__[field_name].field_info

KeyError: &apos;endpoint&apos;</code></pre><p>Kudos to <a href="https://github.com/NarekA?ref=jina-ai-gmbh.ghost.io">@NarekA</a> for raising the issue and contributing a fix in the Jina project, which was ported in DocArray.</p><h2 id="%F0%9F%93%97-documentation-improvements">&#x1F4D7; Documentation Improvements</h2><ul><li>Explain how to set Document config (<a href="https://github.com/docarray/docarray/pull/1773?ref=jina-ai-gmbh.ghost.io">docs: explain how to set document config #1773</a>)</li><li>Add workaround for torch compile (<a href="https://github.com/docarray/docarray/pull/1754?ref=jina-ai-gmbh.ghost.io">docs: add workaround for torch compile #1754</a>)</li><li>Add note about pickling dynamically created Doc class (<a href="https://github.com/docarray/docarray/pull/1763?ref=jina-ai-gmbh.ghost.io">docs: add note about pickling dynamically created doc class #1763</a>)</li><li>Improve the docstring of <code>filter_docs</code> (<a href="https://github.com/docarray/docarray/pull/1762?ref=jina-ai-gmbh.ghost.io">docs: improve filtering docstrings #1762</a>)</li></ul><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Sami Jaghouar (<a href="https://github.com/samsja?ref=jina-ai-gmbh.ghost.io">@samsja</a> )</li><li>Johannes Messner (<a href="https://github.com/JohannesMessner?ref=jina-ai-gmbh.ghost.io">@JohannesMessner</a> )</li><li>AlaeddineAbdessalem (<a href="https://github.com/alaeddine-13?ref=jina-ai-gmbh.ghost.io">@alaeddine-13</a> )</li><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a> )</li></ul>]]></content:encoded></item><item><title><![CDATA[Distilled AI: Using Large Models to Teach Smaller Ones]]></title><description><![CDATA[Better AI with smaller models and cheaper data costs! But only if you use AI to train AI.]]></description><link>https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones/</link><guid isPermaLink="false">64f88a2a5fa9490001805c0c</guid><category><![CDATA[Tech Blog]]></category><dc:creator><![CDATA[Alaeddine Abdessalem]]></dc:creator><pubDate>Thu, 07 Sep 2023 13:31:38 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/373440831_1747441042382077_2749157957406765240_n.png" medium="image"/><content:encoded><![CDATA[<img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/373440831_1747441042382077_2749157957406765240_n.png" alt="Distilled AI: Using Large Models to Teach Smaller Ones"><p>A lot of public attention has gone into generative large language models and AI art because they produce striking results, even in the eyes of people who don&#x2019;t know anything about AI. However, one area has garnered a lot of research and commercial interest without attracting as much attention from the general public: Using AI models to write computer code. </p><p>In this article, we&apos;ll show how we fine-tuned a one-billion-parameter AI model &#x2013; <a href="https://github.com/bigcode-project/starcoder?ref=jina-ai-gmbh.ghost.io">StarCoder 1B</a>, a relatively small model &#x2013; to improve its Python programming skills, raising its score on the <a href="https://paperswithcode.com/sota/code-generation-on-humaneval?ref=jina-ai-gmbh.ghost.io">HumanEval benchmark</a> from 15.2% to 27.0%. We did this by distilling the knowledge present in <a href="https://platform.openai.com/docs/models/gpt-3-5?ref=jina-ai-gmbh.ghost.io">GPT 3.5</a>, a 180-billion-parameter large language model that itself scores 48.1% on the same benchmark, into the much smaller model. Our method was to prompt GPT 3.5 into creating a roughly 120-thousand item Python programming dataset, which we then used to fine-tune the StarCoder model.</p><h2 id="ai-models-that-write-code">AI models that write code &#xA0;</h2><p>A number of AI models have had some success actually writing code directly in response to problem descriptions. <a href="https://github.com/features/copilot?ref=jina-ai-gmbh.ghost.io">GitHub Copilot</a> is available commercially, and the GPT series from OpenAI will write code for you if you ask it to, but <a href="https://paperswithcode.com/sota/code-generation-on-humaneval?ref=jina-ai-gmbh.ghost.io">there are also dozens of other models</a> that have at least some coding ability.</p><p>This technology has the potential to be very disruptive to the software development industry.</p><p>One major barrier to implementing AI coding is one that holds up a lot of AI work: The kinds of very large AI models that produce high-quality results are very expensive to train and run. Members of the GPT family of closed-access models are not only expensive but also remotely hosted with unclear security. Ideally, we would like to have smaller but more specialized models that can give comparable performance to the large models but run on less expensive hardware that users can keep under their own control.</p><p>This article is a step in that direction, demonstrating that it is feasible, and a way to do it inexpensively.</p><h2 id="more-data-vs-better-data-scaling-factors-in-ai">More data vs. better data: Scaling factors in AI</h2><p>All else being equal, we know that the performance of an AI model depends on <a href="https://doi.org/10.48550/arXiv.2001.08361?ref=jina-ai-gmbh.ghost.io">three scaling factors</a>:</p><ul><li><strong>Training time</strong>. Models trained for more cycles perform better than identical models trained for fewer on the same data.</li><li><strong>Data size</strong>. Models trained with more data perform better than identical models trained with less, given the same training time.</li><li><strong>Number of parameters</strong>, i.e., the size of the model. A model with more weights (or more neurons, which is the same thing) performs better than one with fewer, given the same training data and training time.</li></ul><p>To build a model with a smaller size but comparable performance to a larger one, we should, logically, use more data and more training cycles. But all else is not always equal. Data quality is a more difficult factor to quantify than training time, data size, or model size, but it makes a significant difference to performance. Intuitively, the model should learn better to solve a particular kind of problem if it learns from the most instructive examples. The problem with improving data quality is that it can be difficult or expensive to curate enough high-quality data to make a difference.</p><h2 id="using-ai-models-as-both-teacher-and-student">Using AI models as both teacher and student</h2><p>One solution is to use AI models to create training data. This has the benefit of being much cheaper than commissioning humans to create enough data or paying them to curate existing data, picking out just the most relevant examples.</p><p>At first glance, this seems counter-intuitive. If the model is already good enough to create high-quality training data to learn to solve a problem, then surely it can&#x2019;t use this knowledge to improve its own performance. And this is true. But when the goal is to train a smaller, less capable AI to improve its performance, and we use a much more capable AI to create the training data, it makes just as much sense as a child learning to read from a teacher who is already literate.</p><p>This is especially relevant to our goal of creating a smaller model with performance comparable to larger ones. We know that a smaller model will need more examples and more training time to reach the same result as a larger one, if it can reach it at all. What a 100 billion parameter model can learn from a thousand examples of sufficient quality might take a million equally high-quality examples for a 1 billion parameter model. The cost of human construction or curation of a million items of training data is a lot more than a thousand, no matter what the problem is.</p><p>To address this problem, we took inspiration from the recent paper <em>Textbooks Are All You Need</em> (<a href="https://doi.org/10.48550/arXiv.2306.11644?ref=jina-ai-gmbh.ghost.io">Gunasekar et al. 2023</a>), which introduces the phi-1 family of models, which write Python code after being trained on a mixture of human and synthetic data. While they started with completely untrained models, we took an existing open access model &#x2014; the one billion parameter <a href="https://github.com/bigcode-project/starcoder?ref=jina-ai-gmbh.ghost.io">StarCoder 1B</a> model (<a href="https://doi.org/10.48550/arXiv.2305.06161?ref=jina-ai-gmbh.ghost.io">Li et al. 2023</a>) that has already been trained to write code in 86 languages &#x2013; and then fine-tuned it exclusively with Python code examples created by ChatGPT 3.5.</p><h2 id="creating-the-data">Creating the data</h2><p>We constructed roughly 120,000 training exercises using ChatGPT 3.5.</p><p>We were aware that one major issue in using model-synthesized data is ensuring sufficient diversity. To address this problem, we first decided on 60 broad topic labels in Python programming. For example:</p><ul><li>Python Basic Operators</li><li>Control Structures in Python</li><li>Functions in Python</li><li>Python Lambda Functions</li></ul><p>The <a href="https://github.com/jina-ai/textbook/blob/main/textbook/dataset_gen/tree/topics.csv?ref=jina-ai-gmbh.ghost.io">complete list of topics</a> is documented in <a href="https://github.com/jina-ai/textbook?ref=jina-ai-gmbh.ghost.io">the project&#x2019;s GitHub repository</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/textbook?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - jina-ai/textbook: distill chatGPT coding ability into small model (1b)</div><div class="kg-bookmark-description">distill chatGPT coding ability into small model (1b) - GitHub - jina-ai/textbook: distill chatGPT coding ability into small model (1b)</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Distilled AI: Using Large Models to Teach Smaller Ones"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/36f220c7a33fa0a997544fab3950924bee95917428dc2662e8451c586124ce68/jina-ai/textbook" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure><p>We decided that we would use only 42 of them in this experiment (the ones marked with a <code>1</code> in the <code>Mixing</code> column). For each of those 42 topics, we queried GPT 4 to give us 10 sub-topics using the prompt below:</p><pre><code class="language-Text">For a Python textbook give me 10 subtopics of {topic}, formatted as a Python list. 
Just provide the titles and give no explanation.
Format the result as Python list.
</code></pre><p>We then repeated this procedure to get five very fine-grained topics for each of the 420 subtopics. This yields approximately 2000 topics.</p><p>We furthermore manually constructed a list of 40 professions. For example:</p><ul><li>Economist</li><li>Engineer</li><li>Social Worker</li><li>Game Developer</li></ul><p>The <a href="https://github.com/jina-ai/textbook/blob/main/textbook/dataset_gen/tree/professions.json?ref=jina-ai-gmbh.ghost.io">complete list of professions</a> is also documented in <a href="https://github.com/jina-ai/textbook?ref=jina-ai-gmbh.ghost.io">the project&#x2019;s GitHub repository</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/textbook?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - jina-ai/textbook: distill chatGPT coding ability into small model (1b)</div><div class="kg-bookmark-description">distill chatGPT coding ability into small model (1b) - GitHub - jina-ai/textbook: distill chatGPT coding ability into small model (1b)</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Distilled AI: Using Large Models to Teach Smaller Ones"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/36f220c7a33fa0a997544fab3950924bee95917428dc2662e8451c586124ce68/jina-ai/textbook" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure><p>To generate code exercises, we selected two topics randomly from the list of 2000 and one profession from the list of 40 and then prompted ChatGPT 3.5 with the following:</p><pre><code class="language-Python">Create a code completion exercise on the intersection of {topic 1} and {topic 2}.
Write it for a {profession}.

The exercise must be of the style: 

def name(args): 
	&quot;&quot;&quot;Docstring explaining the exercise&quot;&quot;&quot;
    
    python code to solve the exercise

NO CLASSES
MAKE IT VERY DIFFICULT</code></pre><p>The result was snippets of code like this:</p><pre><code class="language-Python">def find_gene(sequence, target_gene):
	&quot;&quot;&quot;
	Given a DNA sequence and a target gene, this function should
	return the starting index of the target gene in the given 
    sequence, using a while loop and boolean expressions.
	
	Note: The target gene is represented as a string of characters, 
    and we assume that it only occurs once in the sequence.
	
	Args:
	- sequence: a string representing the DNA sequence to search in
	- target_gene: a string representing the target gene to find
	
	Returns:
	- The starting index (integer) of the target gene in the
      sequence, or -1 if the target gene is not found.
	&quot;&quot;&quot;
	
	index = 0
	gene_len = len(target_gene)
	
	while index &lt;= len(sequence) - gene_len:
	    
	    # Check if current substring matches the target gene
	    if sequence[index:index+gene_len] == target_gene:
	        return index
	    
	    index += 1
	
	return -1  # Target gene not found in the given sequence</code></pre><p>Another example:</p><pre><code class="language-python">def calculate_average_price(prices):
    &quot;&quot;&quot;
    Calculate the average price of a list of fashion items.

    Args:
    prices (list): A list of prices of fashion items.

    Returns:
    float: The average price of the fashion items.
    &quot;&quot;&quot;

    total = 0

    while prices:
        # Slices the prices list to get the first item 
        # and remove it from the original list
        price = prices.pop(0)

        # Complete the missing code to update the total variable 
        # by adding the current price 
        
    
    # Calculate the average price by dividing the total by the 
    # number of fashion items
    average_price = total / len(prices)

    return average_price
</code></pre><p>We repeated this until we had 150,000 Python functions with explanatory docstrings. We filtered the results to remove results containing non-runnable code, yielding approximately 120,000 individual training items. This formed the training corpus we used to fine-tune StarCoder 1B.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">The cost of data acquisition &#x2014; the price we paid to query ChatGPT 3.5 150,000 times &#x2014; was approximately 600 USD.</div></div><p>You can download the synthetic data we used for training <a href="https://huggingface.co/datasets/jinaai/code_exercises?ref=jina-ai-gmbh.ghost.io">as a HuggingFace dataset</a>. </p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/datasets/jinaai/code_exercises?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/code_exercises &#xB7; Datasets at Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/datasets/jinaai/code_exercises.png" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure><h2 id="fine-tuning-starcoder-1b">Fine-tuning StarCoder 1B</h2><p>StarCoder 1B is a one-billion-parameter model from a <a href="https://huggingface.co/bigcode/starcoder?ref=jina-ai-gmbh.ghost.io">family of pre-trained models</a> designed to perform programming tasks in multiple programming languages. It was pre-trained on <a href="https://huggingface.co/datasets/bigcode/the-stack?ref=jina-ai-gmbh.ghost.io">The Stack dataset</a>, a collection of code items from GitHub with permissive licenses.</p><p>We did full parameter fine-tuning using the synthetic dataset described above, with a batch size of 128 and a <a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/nemo_megatron/batching.html?ref=jina-ai-gmbh.ghost.io">micro-batch size</a> of 8. Our training hardware was a <a href="https://www.runpod.io/?ref=jina-ai-gmbh.ghost.io">RunPod cloud instance</a> with an <a href="https://www.nvidia.com/en-us/data-center/a40/?ref=jina-ai-gmbh.ghost.io">NVIDIA A40 GPU</a>.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">The fine-tuning compute cost, using a cloud-based rented GPU, was approximately 10 USD. This compares very favorably to the cost of fine-tuning OpenAI&#x2019;s closed-access GPT models or the larger open-access models like Llama 2.</div></div><p>We have made the entire weight set of our fine-tuned StarCoder 1B available<a href="https://huggingface.co/jinaai/starcoder-1b-textbook?ref=jina-ai-gmbh.ghost.io"> as a HuggingFace mode</a>l. You are free to download, use, and retrain it.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/starcoder-1b-textbook?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/starcoder-1b-textbook &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/starcoder-1b-textbook.png" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure><h2 id="evaluation">Evaluation</h2><p>To evaluate our training, we used the standard <a href="https://paperswithcode.com/sota/code-generation-on-humaneval?ref=jina-ai-gmbh.ghost.io">HumanEval benchmark</a> (<a href="https://doi.org/10.48550/arXiv.2107.03374?ref=jina-ai-gmbh.ghost.io">Chen et al. 2021)</a>. This benchmark consists of 164 human-made programming problems written in English and a set of Python unit tests to verify that a proposed solution correctly solves the problem.</p><p>For example, we gave our fine-tuned model the following prompt from HumanEval:</p><pre><code class="language-Python">from typing import List, Optional

def longest(strings: List[str]) -&gt; Optional[str]:
    &quot;&quot;&quot;
    Out of list of strings, return the longest one. Return the first one 
    in case of multiple strings of the same length. Return None in case 
    the input list is empty.
    
    &gt;&gt;&gt; longest([])

    &gt;&gt;&gt; longest([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;])
    &apos;a&apos;
    &gt;&gt;&gt; longest([&apos;a&apos;, &apos;bb&apos;, &apos;ccc&apos;])
    &apos;ccc&apos;
    &quot;&quot;&quot;</code></pre><p>The modified StarCoder 1B produced as output:</p><pre><code class="language-Python">from typing import List, Optional

def longest(strings: List[str]) -&gt; Optional[str]:
    &quot;&quot;&quot;
    Out of list of strings, return the longest one. Return the first one 
    in case of multiple strings of the same length. Return None in case 
    the input list is empty.
    
    &gt;&gt;&gt; longest([])

    &gt;&gt;&gt; longest([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;])
    &apos;a&apos;
    &gt;&gt;&gt; longest([&apos;a&apos;, &apos;bb&apos;, &apos;ccc&apos;])
    &apos;ccc&apos;
    &quot;&quot;&quot;
    
    if not strings:
        return None

    longest_string = strings[0]
    for string in strings[1:]:
        if len(string) &gt; len(longest_string):
            longest_string = string

    return longest_string</code></pre><p>This function passes all the unit tests for finding the longest string in a list of strings and is therefore marked as successful.</p><p>Our fine-tuned StarCoder 1B is also able to handle more abstract problems that can involve world knowledge. For example, it generated the code for this function from the text docstring description. The actual number-to-letter maps for Roman numeral conversion were not provided in the prompt:</p><pre><code class="language-Python">
def int_to_mini_roman(number):
    &quot;&quot;&quot;
    Given a positive integer, obtain its roman numeral equivalent as
    a string, and return it in lowercase.
    Restrictions: 1 &lt;= num &lt;= 1000

    Examples:
    &gt;&gt;&gt; int_to_mini_roman(19) == &apos;xix&apos;
    &gt;&gt;&gt; int_to_mini_roman(152) == &apos;clii&apos;
    &gt;&gt;&gt; int_to_mini_roman(426) == &apos;cdxxvi&apos;
    &quot;&quot;&quot;

    roman_numerals = {
        1000: &apos;M&apos;,
        900: &apos;CM&apos;,
        500: &apos;D&apos;,
        400: &apos;CD&apos;,
        100: &apos;C&apos;,
        90: &apos;XC&apos;,
        50: &apos;L&apos;,
        40: &apos;XL&apos;,
        10: &apos;X&apos;,
        9: &apos;IX&apos;,
        5: &apos;V&apos;,
        4: &apos;IV&apos;,
        1: &apos;I&apos;
    }

    roman_numeral = &quot;&quot;
    for value, symbol in roman_numerals.items():
        while number &gt;= value:
            roman_numeral += symbol
            number -= value

    return roman_numeral.lower()</code></pre><p>Existing large language models and models specifically trained for programming have a range of scores on HumanEval that, at first glance, are broadly proportionate to model size, training data size, and the amount of money invested in developing it. For example, GPT-4 with no fine-tuning or special prompt engineering currently scores 67.0%, <a href="https://paperswithcode.com/sota/code-generation-on-humaneval?ref=jina-ai-gmbh.ghost.io">according to the latest report</a>. That is to say, it writes code that correctly solves the problem about two-thirds of the time.</p><p>GPT 3.5 without fine-tuning &#x2014; the model we used to generate our training data &#x2014; &#xA0;scores 48.1% on the same benchmark. The highest current performer is a prompt-engineered GPT-4 that scores 91%. Among the open-access models, Llama 2 without fine-tuning currently scores 29.9%, while StarCoder 1B &#x2014; the model we fine-tuned &#x2014; has a zero-shot performance (i.e., unmodified, out-of-the-box) of 15.2% <a href="https://huggingface.co/bigcode/starcoderbase-1b?ref=jina-ai-gmbh.ghost.io">according to its model card on HuggingFace</a>.</p><p>Our fine-tuning improved StarCoder 1B performance to 27.0% on HumanEval, nearly doubling the number of problems it solved correctly and placing its performance above many larger models.</p><p>Given that the net inputs were so small &#x2014; well under 1000 USD in compute costs, a few hours of engineer time, and no human data oversight at all &#x2014; this is a very large improvement on a very small model.</p><h2 id="summing-up">Summing up</h2><p>AI models are a little like children: They can sometimes learn a lot from a good teacher.</p><p>We tested the hypothesis that we could distill the task-specific knowledge of a large, complex AI model into a smaller and simpler one by using the larger one to generate training examples for the smaller one. Specifically, writing Python functions to solve a verbal problem description.</p><p>Given that GPT 3.5 scores just under 50% on the HumanEval benchmark, it would be very unreasonable for us to expect our fine-tuned one-billion parameter model to equal, much less beat, that score using this training method. It&#x2019;s not so easy for the student to surpass the teacher. Nonetheless, we improved the performance of the StarCoder 1B from about a third as accurate as GPT 3.5 to about half as accurate.</p><p>We might wonder, given that the highest-performing models currently score around 90%, if the added cost of using an even larger and more expensive model to create training examples might improve StarCoder 1B&#x2019;s performance even more. We also know that both pre-training and model size factor into performance both before and after fine-tuning, so we might get still better results using other foundation models. This kind of AI-led training has much lower costs than conventional methods, and that opens up a large space for future experimentation.</p><h2 id="getting-involved">Getting involved</h2><p>You can download the code for this project from <a href="https://github.com/jina-ai/textbook?ref=jina-ai-gmbh.ghost.io">the project&#x2019;s GitHub repository</a>, and download the training data from <a href="https://huggingface.co/datasets/jinaai/code_exercises?ref=jina-ai-gmbh.ghost.io">its HuggingFace page</a>. The trained model is also available from <a href="https://huggingface.co/jinaai/starcoder-1b-textbook?ref=jina-ai-gmbh.ghost.io">its model page</a> on HugglingFace.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/textbook?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - jina-ai/textbook: distill chatGPT coding ability into small model (1b)</div><div class="kg-bookmark-description">distill chatGPT coding ability into small model (1b) - GitHub - jina-ai/textbook: distill chatGPT coding ability into small model (1b)</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Distilled AI: Using Large Models to Teach Smaller Ones"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/36f220c7a33fa0a997544fab3950924bee95917428dc2662e8451c586124ce68/jina-ai/textbook" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/datasets/jinaai/code_exercises?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/code_exercises &#xB7; Datasets at Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/datasets/jinaai/code_exercises.png" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/starcoder-1b-textbook?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/starcoder-1b-textbook &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/starcoder-1b-textbook.png" alt="Distilled AI: Using Large Models to Teach Smaller Ones"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Jina 3.20.3 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-20-3-update/</link><guid isPermaLink="false">64f986615fa9490001805cad</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Thu, 07 Sep 2023 08:52:25 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Jina-core--3-.png" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3203">Release Note (<code>3.20.3</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Jina-core--3-.png" alt="Jina 3.20.3 Update"><p>This release contains 1 bug fix.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina/releases/tag/v3.20.3?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Release &#x1F4AB; Patch v3.20.3 &#xB7; jina-ai/jina</div><div class="kg-bookmark-description">Release Note (3.20.3) Release time: 2023-09-07 08:46:43 This release contains 1 bug fix.&#x1F41E; Bug FixesSkip doc attributes in annotations but not in fields (#6035)When deploying an Executor insi&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Jina 3.20.3 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/14f7bbdbfe0b51a6e9a063fbd6b02ff83a7be18f62409ca98fe22a6004eb8a94/jina-ai/jina/releases/tag/v3.20.3" alt="Jina 3.20.3 Update"></div></a></figure><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="skip-doc-attributes-in-annotations-but-not-in-fields-6035">Skip doc attributes in annotations but not in fields (<a href="https://github.com/jina-ai/jina/pull/6035?ref=jina-ai-gmbh.ghost.io">#6035</a>)</h3><p>When deploying an Executor inside a Flow with a <code>BaseDoc</code> model that has any attribute with a <code>ClassVar</code> value, the service would fail to initialize because the Gateway could not properly create the schemas. We have fixed this by securing access to <code>__fields__</code> when dynamically creating these pydantic models.</p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Narek Amirbekian (<a href="https://github.com/NarekA?ref=jina-ai-gmbh.ghost.io">@NarekA</a> )</li></ul>]]></content:encoded></item><item><title><![CDATA[Jina 3.20.2 Update]]></title><description><![CDATA[Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud.]]></description><link>https://jina.ai/news/jina-3-20-2-update/</link><guid isPermaLink="false">64f836cb920c5d0001002bb6</guid><category><![CDATA[Releases]]></category><dc:creator><![CDATA[Engineering Group]]></dc:creator><pubDate>Wed, 06 Sep 2023 08:31:45 GMT</pubDate><media:content url="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Jina-core--2-.png" medium="image"/><content:encoded><![CDATA[<h2 id="release-note-3202">Release Note (<code>3.20.2</code>)</h2><img src="https://jina-ai-gmbh.ghost.io/content/images/2023/09/Jina-core--2-.png" alt="Jina 3.20.2 Update"><p>This release contains 1 bug fix and 1 refactoring.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/jina-ai/jina?ref=jina-ai-gmbh.ghost.io"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - jina-ai/jina: &#x1F52E; Multimodal AI services &amp; pipelines with cloud-native stack: gRPC, Kubernetes, Docker, OpenTelemetry, Prometheus, Jaeger, etc.</div><div class="kg-bookmark-description">&#x1F52E; Multimodal AI services &amp;amp; pipelines with cloud-native stack: gRPC, Kubernetes, Docker, OpenTelemetry, Prometheus, Jaeger, etc. - GitHub - jina-ai/jina: &#x1F52E; Multimodal AI services &amp;amp; pipelines&#x2026;</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/pinned-octocat.svg" alt="Jina 3.20.2 Update"><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">jina-ai</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://repository-images.githubusercontent.com/240315046/09d66a57-001b-4834-b685-c72e3dc3e1ba" alt="Jina 3.20.2 Update"></div></a></figure><h2 id="%F0%9F%90%9E-bug-fixes">&#x1F41E; Bug Fixes</h2><h3 id="fix-install-issue-6037">Fix install issue (<a href="https://github.com/jina-ai/jina/pull/6037?ref=jina-ai-gmbh.ghost.io">#6037</a>)</h3><p>Fix an installation issue that appeared because a new release of <code>opentelemetry-sdk</code> prevented <code>pip</code> from finding compatible libraries.</p><h2 id="%E2%9A%99-refactoring">&#x2699; Refactoring</h2><h3 id="refactor-the-setuppy-file-6038">Refactor the setup.py file (<a href="https://github.com/jina-ai/jina/pull/6038?ref=jina-ai-gmbh.ghost.io">#6038</a>)</h3><p>Some hard-coded strings were replaced with constants to improve code readability. </p><h2 id="%F0%9F%A4%9F-contributors">&#x1F91F; Contributors</h2><p>We would like to thank all contributors to this release:</p><ul><li>Joan Fontanals (<a href="https://github.com/JoanFM?ref=jina-ai-gmbh.ghost.io">@JoanFM</a> )</li><li>Naymul Islam (<a href="https://github.com/ai-naymul?ref=jina-ai-gmbh.ghost.io">@ai-naymul</a> )</li></ul>]]></content:encoded></item></channel></rss>