<!DOCTYPE html><html translate="no" dir="ltr" lang="de"><head><title>Die Bedeutung und Gründe der Text-Bild-Modalitätslücke in CLIP-Modellen</title><meta charset="utf-8"><meta name="title" content="Die Bedeutung und Gründe der Text-Bild-Modalitätslücke in CLIP-Modellen"><meta name="description" content="Man kann ein CLIP-Modell nicht einfach zur Abfrage von Text und Bildern verwenden und die Ergebnisse nach Punktzahl sortieren. Warum? Wegen der Modalitätslücke. Was ist das und woher kommt sie?"><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models"><meta property="og:title" content="Die Bedeutung und Gründe der Text-Bild-Modalitätslücke in CLIP-Modellen"><meta property="og:description" content="Man kann ein CLIP-Modell nicht einfach zur Abfrage von Text und Bildern verwenden und die Ergebnisse nach Punktzahl sortieren. Warum? Wegen der Modalitätslücke. Was ist das und woher kommt sie?"><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/08/modality-gap-banner.jpg"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models"><meta property="twitter:title" content="Die Bedeutung und Gründe der Text-Bild-Modalitätslücke in CLIP-Modellen"><meta property="twitter:description" content="Man kann ein CLIP-Modell nicht einfach zur Abfrage von Text und Bildern verwenden und die Ergebnisse nach Punktzahl sortieren. Warum? Wegen der Modalitätslücke. Was ist das und woher kommt sie?"><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/08/modality-gap-banner.jpg"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-3gHUfv4d.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-CRvJtbiE.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-D6X353SI.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-CpXKEBy8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-70koux7y.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-DeYSeB_0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-CTARylo-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-CxlXjTvh.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/de-Ck-F6j5P.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-Da0aq20u.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpace-9XWoXPCY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-CCgU23Xz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QToolbar-Do_HmmJl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-uZ-LtMvk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnGroup-C21PclsE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-8CTQlx4N.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-DGFegG9t.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-DTcEW0mr.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-DvObmiOj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CdLif_23.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-BfYflfOA.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-4U1-q5UN.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-DzgqKm10.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-1DsVBzVT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format-DyQxkAtJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding-BtwTtuQF.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-BIaHEHSR.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-DHaW9v9j.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-CDRe-xK-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-DirZdTIi.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/rtl-DFPa-2ov.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-D17_yNsS.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-BlpoHNmm.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-BMR_OewU.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-DVmthkO9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-DGRebBnO.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-meta-CpzoVlN6.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BcXCNFzE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-BzlvQWeZ.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-etZf4lVI.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-BYg3bc8w.css"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-iSUijgjF.css"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Bo Wang, Scott Martens"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="13 mins read"><meta property="article:published_time" content="2024-08-26T15:56:36.000+02:00"><meta property="article:modified_time" content="2024-08-27T20:10:53.000+02:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Die Bedeutung und Gründe der Text-Bild-Modalitätslücke in CLIP-Modellen",
  "description": "Man kann ein CLIP-Modell nicht einfach zur Abfrage von Text und Bildern verwenden und die Ergebnisse nach Punktzahl sortieren. Warum? Wegen der Modalitätslücke. Was ist das und woher kommt sie?",
  "image": [
    "https://jina-ai-gmbh.ghost.io/content/images/2024/08/modality-gap-banner.jpg"
  ],
  "datePublished": "2024-08-26T15:56:36.000+02:00",
  "dateModified": "2024-08-27T20:10:53.000+02:00",
  "author": [
    {
      "@type": "Person",
      "name": "Bo Wang",
      "url": "https://jina-ai-gmbh.ghost.io/author/bo/"
    },
    {
      "@type": "Person",
      "name": "Scott Martens",
      "url": "https://jina-ai-gmbh.ghost.io/author/scott/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled " aria-hidden="true" role="presentation">notifications</i></div><div class="q-item__section column q-item__section--main justify-center">Pressemitteilungen</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_67634ce6-1201-42e0-89bd-f3b1674170e7" aria-label="Erweitern Sie &quot;Produkte&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled " aria-hidden="true" role="presentation">box</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Produkte</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_67634ce6-1201-42e0-89bd-f3b1674170e7" style="display: none;"><div class="q-list q-list--dark" role="list" label="Produkte"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">Für Firmen</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Einbettungen</div><div class="q-item__label q-item__label--caption text-caption">Multimodale und mehrsprachige Einbettungen von Weltklasse.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">Neural Retriever der Weltklasse zur Maximierung der Suchrelevanz.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Leser</div><div class="q-item__label q-item__label--caption text-caption">Lesen Sie URLs und suchen Sie im Internet nach fundierteren LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Klassifikator</div><div class="q-item__label q-item__label--caption text-caption">Zero-Shot- und Few-Shot-Klassifizierung für Bild und Text.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmentierer</div><div class="q-item__label q-item__label--caption text-caption">Schneiden Sie langen Text in Abschnitte und führen Sie eine Tokenisierung durch.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">Für Power-User</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Erstklassiges Tool für schnelles Engineering</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_24173e05-6bc4-4e22-a3a6-4ef1da198d16" aria-label="Erweitern Sie &quot;Mehr Power-User-Tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Mehr Power-User-Tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_24173e05-6bc4-4e22-a3a6-4ef1da198d16" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Führende KI-Lösung für Bildunterschriften und Videozusammenfassungen</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Vom Blog-Artikel zum Banner, ohne eigene Prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">Mehr Modalitäten, längerer Speicher, weniger Kosten</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimative KI-Tools zur Entscheidungsfindung</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_d557423b-cc12-4263-8fb2-18b5b50de5ff" aria-label="Erweitern Sie &quot;Unternehmen&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Unternehmen</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_d557423b-cc12-4263-8fb2-18b5b50de5ff" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Über uns</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Kontaktieren Sie unseren Vertrieb</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Praktikantenprogramm</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Begleiten Sie uns</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Logo herunterladen</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; amp; Bedingungen</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api?login=true" label="Einloggen"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div><div class="q-item__section column q-item__section--main justify-center">Einloggen</div></a></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-1d9869b0="" class="q-page" style="min-height: 100vh;"><div data-v-1d9869b0="" class="row full-width relative-position justify-end"><div data-v-1d9869b0="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-1d9869b0="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-1d9869b0="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1d9869b0="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-1d9869b0="" class="q-item__label">Woher kommt die Modalitätslücke?</div></div></div><div data-v-1d9869b0="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-1d9869b0="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-1d9869b0="" class="q-item__label">Das Medium ist die Botschaft</div></div></div></div></div><div data-v-1d9869b0="" class="col-12 col-md-10 col-lg-12"><div data-v-1d9869b0="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech-Blog</div></div></div></div><div data-v-1d9869b0="" class="row justify-center"><div data-v-1d9869b0="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-1d9869b0="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">August 26, 2024</div><h1 data-v-1d9869b0="" class="text-weight-medium text-center q-px-md my-title">Die Bedeutung und Gründe der Text-Bild-Modalitätslücke in CLIP-Modellen</h1><div data-v-1d9869b0="" class="col row justify-center"><div data-v-1d9869b0="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Man kann ein CLIP-Modell nicht einfach zur Abfrage von Text und Bildern verwenden und die Ergebnisse nach Punktzahl sortieren. Warum? Wegen der Modalitätslücke. Was ist das und woher kommt sie?</div></div><div data-v-1d9869b0="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-1d9869b0="" class="q-img q-img--menu" role="img" aria-label="Futuristic black image with &quot;modality gap&quot; in 3D purple letters, additional text, and a dynamic glass sphere effect."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Futuristic black image with &quot;modality gap&quot; in 3D purple letters, additional text, and a dynamic glass sphere effect." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/modality-gap-banner.jpg" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-1d9869b0="" class="row justify-center"><div data-v-1d9869b0="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-1d9869b0="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-1d9869b0="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Bo Wang"><div style="padding-bottom: 93.2813%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Bo Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Scott Martens"><div style="padding-bottom: 118.041%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Scott Martens" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-1d9869b0="" class="q-item__label">Bo Wang, Scott Martens • 13 Minuten gelesen</div></div></div></div><div data-v-1d9869b0="" class="row justify-center"><div data-v-1d9869b0="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-1d9869b0="" class="article"><section data-v-1d9869b0="" class="gh-content"><p><a href="https://jina.ai/news/embeddings-the-swiss-army-knife-of-ai">Semantische Embeddings</a> sind der Kern moderner KI-Modelle, selbst bei Chatbots und KI-Kunstmodellen. Sie sind für Benutzer manchmal verborgen, aber sie sind trotzdem da, direkt unter der Oberfläche.</p><p>Die Theorie der Embeddings hat nur zwei Teile:</p><ol><li>Dinge — Dinge außerhalb eines KI-Modells, wie Texte und Bilder — werden durch Vektoren repräsentiert, die von KI-Modellen aus Daten über diese Dinge erstellt werden.</li><li>Beziehungen zwischen Dingen außerhalb eines KI-Modells werden durch räumliche Beziehungen zwischen diesen Vektoren dargestellt. Wir trainieren KI-Modelle speziell darauf, Vektoren zu erstellen, die auf diese Weise funktionieren.</li></ol><p>Wenn wir ein multimodales Bild-Text-Modell erstellen, trainieren wir das Modell so, dass Embeddings von Bildern und Embeddings von Texten, die diese Bilder beschreiben oder sich darauf beziehen, relativ nahe beieinander liegen. Die semantischen Ähnlichkeiten zwischen den Dingen, die diese beiden Vektoren repräsentieren — ein Bild und ein Text — spiegeln sich in der räumlichen Beziehung zwischen den beiden Vektoren wider.</p><p>Zum Beispiel könnten wir vernünftigerweise erwarten, dass die Embedding-Vektoren für ein Bild einer Orange und der Text "eine frische Orange" näher beieinander liegen als dasselbe Bild und der Text "ein frischer Apfel."</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/apple-orange-compare_2.png" class="kg-image" alt="Illustration auf schwarzem Hintergrund, die eine Orange und einen Apfel mit Pfeilen dazwischen und Zitaten &quot;A fresh orange&quot; zeigt" width="1000" height="500" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/apple-orange-compare_2.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/apple-orange-compare_2.png 1000w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Das ist der Zweck eines Embedding-Modells: Repräsentationen zu generieren, bei denen die Eigenschaften, die uns interessieren — wie die Art der Frucht, die in einem Bild dargestellt oder in einem Text genannt wird — in der Distanz zwischen ihnen erhalten bleiben.</p><p>Aber Multimodalität bringt noch etwas anderes mit sich. Wir könnten feststellen, dass ein Bild einer Orange näher an einem Bild eines Apfels liegt als am Text "eine frische Orange", und dass der Text "ein frischer Apfel" näher an einem anderen Text liegt als an einem Bild eines Apfels.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/apple-orange-compare.png" class="kg-image" alt="Schwarzer Hintergrund mit einem Apfel links und einer Orange rechts mit beschrifteten Pfeilen markiert &quot;A fresh apple.&quot; und" width="1000" height="500" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/apple-orange-compare.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/apple-orange-compare.png 1000w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Es stellt sich heraus, dass genau dies bei multimodalen Modellen passiert, einschließlich Jina AIs eigenem <a href="https://jina.ai/news/jina-clip-v1-a-truly-multimodal-embeddings-model-for-text-and-image">Jina CLIP Modell</a> (<code>jina-clip-v1</code>).</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2405.20204"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina CLIP: Your CLIP Model Is Also Your Text Retriever</div><div class="kg-bookmark-description">Contrastive Language-Image Pretraining (CLIP) is widely used to train models to align images and texts in a common embedding space by mapping them to fixed-sized vectors. These models are key to multimodal information retrieval and related tasks. However, CLIP models generally underperform in text-only tasks compared to specialized text models. This creates inefficiencies for information retrieval systems that keep separate embeddings and models for text-only and multimodal tasks. We propose a novel, multi-task contrastive training method to address this issue, which we use to train the jina-clip-v1 model to achieve the state-of-the-art performance on both text-image and text-text retrieval tasks.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Andreas Koukounas</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a></figure><p>Um dies zu testen, haben wir 1.000 Text-Bild-Paare aus dem <a href="https://www.kaggle.com/datasets/adityajn105/flickr8k">Flickr8k Testset</a> ausgewählt. Jedes Paar enthält fünf Bildunterschriften (also technisch gesehen kein Paar) und ein einzelnes Bild, wobei alle fünf Texte dasselbe Bild beschreiben.</p><p>Zum Beispiel das folgende Bild (<code>1245022983_fb329886dd.jpg</code> im Flickr8k Dataset):</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/1245022983_fb329886dd.jpg" class="kg-image" alt="Ein junges Mädchen in einem rosa Rock spielt mit einer Frisbee in einer städtischen Umgebung im Freien mit Autos und Fahrrädern." width="334" height="500" style="cursor: help;"></figure><p>Seine fünf Bildunterschriften:</p><pre><code class="language-Text hljs">A child in all pink is posing nearby a stroller with buildings in the distance.
A little girl in pink dances with her hands on her hips.
A small girl wearing pink dances on the sidewalk.
The girl in a bright pink skirt dances near a stroller.
The little girl in pink has her hands on her hips.
</code></pre><p>Wir haben Jina CLIP verwendet, um die Bilder und Texte einzubetten und dann:</p><ol><li>Die Kosinus-Ähnlichkeiten der Bild-Embeddings mit den Embeddings ihrer Bildunterschriften verglichen.</li><li>Die Embeddings aller fünf Bildunterschriften, die dasselbe Bild beschreiben, genommen und ihre Kosinus-Ähnlichkeiten untereinander verglichen.</li></ol><p>Das Ergebnis ist eine überraschend große Lücke, sichtbar in Abbildung 1:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/jinaclip-cosine-alt--1-.png" class="kg-image" alt="Graph mit zwei Kurven, die die Verteilung der Kosinus-Ähnlichkeit für Bild-zu-Text- und Text-zu-Text-Paare mit beschrifteten Achsen zeigt." width="1870" height="1130" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/jinaclip-cosine-alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/jinaclip-cosine-alt--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/jinaclip-cosine-alt--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/jinaclip-cosine-alt--1-.png 1870w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 1: Verteilung der Kosinus-Ähnlichkeitswerte zwischen passenden Bild-Text-Paaren und Text-Text-Paaren in Jina CLIP.</span></figcaption></figure><p>Mit wenigen Ausnahmen liegen passende Textpaare viel näher beieinander als passende Bild-Text-Paare. Dies deutet stark darauf hin, dass Jina CLIP Texte in einem Teil des Embedding-Raums und Bilder in einem weitgehend getrennten Teil relativ weit davon entfernt kodiert. Dieser Raum zwischen den Texten und den Bildern ist die <em>multimodale Lücke</em>.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/2clusersGraph.png" class="kg-image" alt="Diagramm auf schwarzem Hintergrund mit 'Images' links, 'Texts' unten und beschrifteter 'Multimodal Gap' in der Mitte." width="493" height="479" style="cursor: help;"></figure><p>Multimodale Embedding-Modelle kodieren mehr als nur die semantischen Informationen, die uns interessieren: Sie kodieren das Medium ihrer Eingabe. Laut Jina CLIP ist ein Bild nicht, wie es im Sprichwort heißt, tausend Worte wert. Es hat Inhalte, die keine noch so große Anzahl von Worten jemals wirklich gleichwertig ausdrücken kann. Es kodiert das Eingabemedium in die Semantik seiner Embeddings, ohne dass es jemals darauf trainiert wurde.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Solange wir nur Bilder mit Texten und umgekehrt vergleichen, ist das kein Problem, aber ein wirklich multimodales Modell sollte uns sagen können, dass zum Beispiel der Text "dies ist ein Apfel" besser zu einem Bild eines Apfels passt als zu einem Text über Orangen. CLIP-artige Modelle in ihrer aktuellen Form können das nicht.</div></div><p>Dieses Phänomen wurde in der Arbeit <em>Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning</em> [<a href="https://papers.neurips.cc/paper_files/paper/2022/hash/702f4db7543a7432431df588d57bc7c9-Abstract-Conference.html">Liang et al., 2022</a>] untersucht, die es als "Modalitätslücke" bezeichnet. Die Modalitätslücke ist die räumliche Trennung im Embedding-Raum zwischen Eingaben in einem Medium und Eingaben in einem anderen. Obwohl Modelle nicht absichtlich darauf trainiert werden, eine solche Lücke zu haben, sind sie in multimodalen Modellen allgegenwärtig.</p><p>Unsere Untersuchungen zur Modalitätslücke in Jina CLIP basieren stark auf <a href="https://papers.neurips.cc/paper_files/paper/2022/hash/702f4db7543a7432431df588d57bc7c9-Abstract-Conference.html">Liang et al. [2022]</a>.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://papers.neurips.cc/paper_files/paper/2022/hash/702f4db7543a7432431df588d57bc7c9-Abstract-Conference.html"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://papers.neurips.cc/favicon.ico" alt="" style="cursor: help;"><span class="kg-bookmark-author">NeurIPS Proceedings</span></div></div></a></figure><h2 id="where-does-the-modality-gap-come-from" style="position: relative;"><a href="#where-does-the-modality-gap-come-from" title="Woher kommt die Modalitätslücke?" id="anchor-where-does-the-modality-gap-come-from"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Woher kommt die Modalitätslücke?</h2><p>Liang et al. [2022] identifizieren drei Hauptquellen für die Modalitätslücke:</p><ul><li>Eine Initialisierungsverzerrung, die sie als "Kegel-Effekt" bezeichnen.</li><li>Reduzierungen der Temperatur (Zufälligkeit) während des Trainings, die es sehr schwer machen, diese Verzerrung zu "verlernen".</li><li>Kontrastive Lernverfahren, die in multimodalen Modellen weit verbreitet sind und unbeabsichtigt die Lücke verstärken.</li></ul><p>Wir werden uns jeden dieser Punkte der Reihe nach ansehen.</p><h3 id="cone-effect" style="position: relative;"><a href="#cone-effect" title="Kegel-Effekt" id="anchor-cone-effect"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Kegel-Effekt</h3><p>Ein Modell mit einer CLIP- oder CLIP-ähnlichen Architektur besteht eigentlich aus zwei separaten Embedding-Modellen, die miteinander verbunden sind. Bei multimodalen Bild-Text-Modellen bedeutet dies ein Modell für die Codierung von Texten und ein völlig separates für die Codierung von Bildern, wie im folgenden Schema dargestellt.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--21-.png" class="kg-image" alt="Diagram illustrating concepts of natural language processing with &quot;Embedding Space&quot;, &quot;Image Encoder&quot;, &quot;Text Encoder&quot;, and &quot;Di" width="1025" height="750" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image--21-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image--21-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--21-.png 1025w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Diese beiden Modelle werden so trainiert, dass ein Bild-Embedding und ein Text-Embedding relativ nahe beieinander liegen, wenn der Text das Bild gut beschreibt.</p><p>Man kann ein solches Modell trainieren, indem man die Gewichtungen in beiden Modellen zufällig verteilt und dann Bild-Text-Paare gemeinsam präsentiert, wobei das Training von Grund auf darauf abzielt, die Distanz zwischen den beiden Outputs zu minimieren. Das <a href="https://arxiv.org/abs/2103.00020">ursprüngliche OpenAI CLIP-Modell</a> wurde auf diese Weise trainiert. Dies erfordert jedoch viele Bild-Text-Paare und ein rechenintensives Training. Für das erste CLIP-Modell hat OpenAI 400 Millionen Bild-Text-Paare aus beschriftetem Material im Internet extrahiert.</p><p>Neuere CLIP-ähnliche Modelle verwenden vortrainierte Komponenten<a href="https://doi.org/10.1109/CVPR52688.2022.01759">.</a> Das bedeutet, dass jede Komponente separat als gutes Single-Mode-Embedding-Modell trainiert wird, eines für Texte und eines für Bilder. Diese beiden Modelle werden dann gemeinsam mit Bild-Text-Paaren weiter trainiert, ein Prozess, der als <em>Contrastive Tuning</em> bezeichnet wird. Aufeinander abgestimmte Bild-Text-Paare werden verwendet, um die Gewichtungen langsam so zu „verschieben", dass übereinstimmende Text- und Bild-Embeddings näher zusammenrücken und nicht übereinstimmende weiter auseinander.</p><p>Dieser Ansatz erfordert im Allgemeinen weniger Bild-Text-Paar-Daten, die schwierig und kostspielig zu beschaffen sind, und große Mengen an reinen Texten und Bildern ohne Beschriftungen, die viel einfacher zu beschaffen sind. Jina CLIP (<code>jina-clip-v1</code>) wurde mit dieser letzteren Methode trainiert. Wir haben ein <a href="https://jina.ai/news/jina-embeddings-2-the-best-solution-for-embedding-long-documents/">JinaBERT v2 Modell</a> für die Textcodierung mit allgemeinen Textdaten vortrainiert und einen vortrainierten <a href="https://github.com/baaivision/EVA/tree/master/EVA-02">EVA-02 Image Encoder</a> verwendet, und diese dann mit verschiedenen kontrastiven Trainingstechniken weiter trainiert, wie in <a href="https://arxiv.org/abs/2405.20204">Koukounas et al. [2024]</a> beschrieben</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/umap-jinaclip-inherit_alt--1-.png" class="kg-image" alt="UMAP scatter plot of jinaCLIP embeddings with text and image data points, labeled axes, and category distinctions." width="2000" height="1333" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/umap-jinaclip-inherit_alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/umap-jinaclip-inherit_alt--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/umap-jinaclip-inherit_alt--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/umap-jinaclip-inherit_alt--1-.png 2000w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 2: Anfängliche Positionen der Bild- und Text-Embeddings vor dem Paar-Training in Jina CLIP, in zwei Dimensionen projiziert.</span></figcaption></figure><p>Wenn wir diese beiden vortrainierten Modelle nehmen und ihre Ausgabe betrachten, bevor wir sie mit Bild-Text-Paaren trainieren, fällt uns etwas Wichtiges auf. Abbildung 2 (oben) ist eine <a href="https://umap-learn.readthedocs.io/en/latest/">UMAP-Projektion</a> in zwei Dimensionen der Bild-Embeddings, die vom vortrainierten EVA-02 Encoder erzeugt wurden, und der Text-Embeddings, die vom vortrainierten JinaBERT v2 erzeugt wurden, wobei die grauen Linien übereinstimmende Bild-Text-Paare anzeigen. Dies ist vor jeglichem modalitätsübergreifenden Training.</p><p>Das Ergebnis ist eine Art abgeschnittener „Kegel", mit Bild-Embeddings an einem Ende und Text-Embeddings am anderen. Diese Kegelform lässt sich nur schlecht in zweidimensionale Projektionen übersetzen, aber Sie können sie im Bild oben grob erkennen. Alle Texte clustern sich in einem Teil des Embedding-Raums und alle Bilder in einem anderen Teil. Wenn nach dem Training Texte immer noch ähnlicher zu anderen Texten sind als zu passenden Bildern, ist dieser Anfangszustand ein wichtiger Grund dafür. Das Ziel der besten Übereinstimmung von Bildern mit Texten, Texten mit Texten und Bildern mit Bildern ist vollständig kompatibel mit dieser Kegelform.</p><p>Das Modell ist von Geburt an voreingenommen und was es lernt, ändert daran nichts. Abbildung 3 (unten) zeigt die gleiche Analyse des Jina CLIP-Modells nach der Veröffentlichung, nach vollständigem Training mit Bild-Text-Paaren. Die multimodale Lücke ist sogar noch ausgeprägter.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/umap-jinaclip-trained-alt--1-.png" class="kg-image" alt="UMAP projection chart of JinaCLIP trained weights with two distinct clusters for 'text' and 'image' embeddings." width="2000" height="1333" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/umap-jinaclip-trained-alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/umap-jinaclip-trained-alt--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/umap-jinaclip-trained-alt--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/umap-jinaclip-trained-alt--1-.png 2000w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 3: Positionen der Bild- und Text-Embeddings nach dem Paar-Training in Jina CLIP, in zwei Dimensionen projiziert.</span></figcaption></figure><p>Auch nach umfangreichem Training codiert Jina CLIP das Medium immer noch als Teil der Nachricht.</p><p>Der aufwändigere OpenAI-Ansatz mit rein zufälliger Initialisierung beseitigt diese Voreingenommenheit nicht. Wir haben die ursprüngliche OpenAI CLIP-Architektur genommen und alle Gewichte vollständig randomisiert, dann die gleiche Analyse wie oben durchgeführt. Das Ergebnis ist immer noch eine abgeschnittene Kegelform, wie in Abbildung 4 zu sehen:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/umap-openai-random-alt--1-.png" class="kg-image" alt="Scientific graph displaying UMAP projections of OpenAI CLIP data with blue and green dots indicating text and image embedding" width="2000" height="1333" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/umap-openai-random-alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/umap-openai-random-alt--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/umap-openai-random-alt--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/umap-openai-random-alt--1-.png 2000w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 4: Anfängliche Positionen der Bild- und Text-Embeddings in Jina CLIP mit vollständig randomisierten Gewichten und ohne jegliches Training, in zwei Dimensionen projiziert.</span></figcaption></figure><p>Diese Voreingenommenheit ist ein strukturelles Problem und hat möglicherweise keine Lösung. Wenn dem so ist, können wir nur nach Wegen suchen, sie während des Trainings zu korrigieren oder abzumildern.</p><h3 id="training-temperature" style="position: relative;"><a href="#training-temperature" title="Training Temperature" id="anchor-training-temperature"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Training Temperature</h3><p>Während des AI-Modell-Trainings fügen wir typischerweise etwas Zufälligkeit zum Prozess hinzu. Wir berechnen, wie stark ein Batch von Trainingsbeispielen die Gewichte im Modell verändern sollte, und fügen dann einen kleinen Zufallsfaktor zu diesen Änderungen hinzu, bevor wir die Gewichte tatsächlich ändern. Wir nennen den Grad der Zufälligkeit die <em>Temperatur</em>, in Analogie zur Art und Weise, wie wir Zufälligkeit in der Thermodynamik verwenden.</p><p>Hohe Temperaturen erzeugen sehr schnell große Veränderungen in Modellen, während niedrige Temperaturen die Möglichkeit eines Modells reduzieren, sich bei jedem Trainingsbeispiel zu verändern. Das Ergebnis ist, dass sich bei hohen Temperaturen einzelne Embeddings während des Trainings stark im Embedding-Raum bewegen können, während sie sich bei niedrigen Temperaturen viel langsamer bewegen.</p><p>Die beste Praxis beim Training von KI-Modellen ist, mit einer hohen Temperatur zu beginnen und diese dann progressiv zu senken. Dies hilft dem Modell, am Anfang große Lernsprünge zu machen, wenn die Gewichte entweder zufällig oder weit von ihrem Ziel entfernt sind, und lässt es dann die Details stabiler lernen.</p><p>Das Jina CLIP Bild-Text-Paar-Training beginnt mit einer Temperatur von 0,07 (dies ist eine relativ hohe Temperatur) und senkt sie exponentiell im Verlauf des Trainings auf 0,01, wie in Abbildung 5 unten gezeigt, einer Grafik der Temperatur versus Trainingsschritte:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/temperature-jina-clip-alt--1-.png" class="kg-image" alt="Line chart titled &quot;Learned temperature value w.r.t. steps&quot; with &quot;Steps&quot; on x-axis and &quot;Temperature&quot; on y-axis, demonstrating " width="1000" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/temperature-jina-clip-alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/temperature-jina-clip-alt--1-.png 1000w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 5: Temperaturabfall während des Paar-Trainings in Jina CLIP.</span></figcaption></figure><p>Wir wollten wissen, ob eine Erhöhung der Temperatur – das Hinzufügen von Zufälligkeit – den Kegeleffekt reduzieren und die Bild-Embeddings und Text-Embeddings insgesamt näher zusammenbringen würde. Also trainierten wir Jina CLIP mit einer festen Temperatur von 0,1 (ein sehr hoher Wert) neu. Nach jeder Trainingsepoche überprüften wir die Verteilung der Abstände zwischen Bild-Text-Paaren und Text-Text-Paaren, genau wie in Abbildung 1. Die Ergebnisse sind unten in Abbildung 6 dargestellt:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/closing-the-gap-alt--1-.png" class="kg-image" alt="Six heatmaps showing cosine similarity distributions with varied color palettes, labeled by epochs and datasets." width="1999" height="1999" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/closing-the-gap-alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/closing-the-gap-alt--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/closing-the-gap-alt--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/closing-the-gap-alt--1-.png 1999w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 6: Die Lücke zwischen den Modalitäten verringert sich mit der Zeit, wenn die Trainingstemperatur hoch ist.</span></figcaption></figure><p>Wie Sie sehen können, schließt eine hohe Temperatur die multimodale Lücke dramatisch. Wenn man den Embeddings erlaubt, sich während des Trainings stark zu bewegen, hilft das erheblich dabei, die anfängliche Verzerrung in der Embedding-Verteilung zu überwinden.</p><p>Dies hat jedoch seinen Preis. Wir haben die Leistung des Modells mit sechs verschiedenen Retrieval-Tests geprüft: Drei Text-Text-Retrieval-Tests und drei Text-Bild-Retrieval-Tests aus den Datensätzen <a href="https://huggingface.co/datasets/HuggingFaceM4/COCO">MS-COCO</a>, <a href="https://www.kaggle.com/datasets/adityajn105/flickr8k">Flickr8k</a> und <a href="https://www.kaggle.com/datasets/adityajn105/flickr30k">Flickr30k</a>. In allen Tests sehen wir zu Beginn des Trainings einen starken Leistungsabfall und dann einen sehr langsamen Anstieg, wie in Abbildung 7 zu sehen ist:</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/performance-close-the-gap-alt--1-.png" class="kg-image" alt="Set of six line graphs on a dark background, displaying data comparisons with labeled axes and varying conditions." width="2000" height="735" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/performance-close-the-gap-alt--1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/performance-close-the-gap-alt--1-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/performance-close-the-gap-alt--1-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/performance-close-the-gap-alt--1-.png 2000w" sizes="(min-width: 1200px) 1200px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 7: Leistung während des Trainings. Zunächst gibt es einen starken Rückgang vom Ausgangszustand und nur einen sehr langsamen Anstieg.</span></figcaption></figure><p>Es wäre wahrscheinlich extrem zeit- und kostenaufwendig, ein Modell wie Jina CLIP mit dieser konstant hohen Temperatur zu trainieren. Obwohl theoretisch machbar, ist dies keine praktische Lösung.</p><h3 id="contrastive-learning-and-the-false-negative-problem" style="position: relative;"><a href="#contrastive-learning-and-the-false-negative-problem" title="Kontrastives Lernen und das False-Negative-Problem" id="anchor-contrastive-learning-and-the-false-negative-problem"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Kontrastives Lernen und das False-Negative-Problem</h3><p><a href="https://papers.neurips.cc/paper_files/paper/2022/hash/702f4db7543a7432431df588d57bc7c9-Abstract-Conference.html">Liang et al. [2022]</a> entdeckten auch, dass Standard-Praktiken des kontrastiven Lernens – der Mechanismus, den wir zum Training von CLIP-artigen multimodalen Modellen verwenden – dazu neigen, die multimodale Lücke zu verstärken.</p><p>Kontrastives Lernen ist im Grunde ein einfaches Konzept. Wir haben ein Bild-Embedding und ein Text-Embedding, und wir wissen, dass sie näher zusammenliegen sollten, also passen wir die Gewichte im Modell während des Trainings entsprechend an. Wir gehen langsam vor, passen die Gewichte in kleinen Schritten an, und wir passen sie proportional dazu an, wie weit die beiden Embeddings voneinander entfernt sind: Je näher sie beieinanderliegen, desto kleiner ist die Änderung.</p><p>Diese Technik funktioniert viel besser, wenn wir die Embeddings nicht nur näher zusammenbringen, wenn sie übereinstimmen, sondern sie auch weiter auseinander bewegen, wenn sie nicht übereinstimmen. Wir wollen nicht nur Bild-Text-Paare haben, die zusammengehören, sondern auch Paare, von denen wir wissen, dass sie nicht zusammengehören.</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--2-.png" class="kg-image" alt="Black background with an illustration of a red apple and an orange, associated with arrows and quotes " a="" fresh="" apple"="" and="" "a="" "="" width="1020" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image--2-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image--2-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--2-.png 1020w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Dies wirft einige Probleme auf:</p><ol><li>Unsere Datenquellen bestehen ausschließlich aus übereinstimmenden Paaren. Niemand würde eine Datenbank mit Texten und Bildern erstellen, bei denen ein Mensch überprüft hat, dass sie nicht zusammengehören, noch könnte man eine solche durch Web-Scraping oder andere unüberwachte oder semi-überwachte Techniken erstellen.</li><li>Selbst Bild-Text-Paare, die oberflächlich völlig unzusammenhängend erscheinen, sind es nicht unbedingt. Wir haben keine Semantiktheorie, die es uns erlaubt, solche negativen Urteile objektiv zu fällen. Zum Beispiel ist ein Bild einer Katze, die auf einer Veranda liegt, keine völlig negative Übereinstimmung für den Text "ein Mann, der auf einem Sofa schläft". Beide beinhalten das Liegen auf etwas.</li></ol><p>Idealerweise würden wir mit Bild-Text-Paaren trainieren, von denen wir mit Sicherheit wissen, dass sie verwandt UND unverwandt sind, aber es gibt keine offensichtliche Möglichkeit, bekanntermaßen unverwandte Paare zu erhalten. Es ist möglich, Menschen zu fragen "Beschreibt dieser Satz dieses Bild?" und konsistente Antworten zu erwarten. Es ist viel schwieriger, konsistente Antworten zu bekommen, wenn man fragt "Hat dieser Satz nichts mit diesem Bild zu tun?"</p><p>Stattdessen erhalten wir nicht zusammengehörende Bild-Text-Paare, indem wir zufällig Bilder und Texte aus unseren Trainingsdaten auswählen, in der Erwartung, dass sie praktisch nie gut zueinander passen. In der Praxis funktioniert das so, dass wir unsere Trainingsdaten in Batches aufteilen. Für das Training von Jina CLIP verwendeten wir Batches mit 32.000 übereinstimmenden Bild-Text-Paaren, aber für dieses Experiment waren die Batch-Größen nur 16.</p><p>Die folgende Tabelle zeigt 16 zufällig ausgewählte Bild-Text-Paare aus Flickr8k:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--3-.png" class="kg-image" alt="Collage of various scenes including people, dogs engaging in activities like catching frisbees, and a boy skateboarding, with" width="1827" height="1245" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/08/image--3-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/08/image--3-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/08/image--3-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--3-.png 1827w" sizes="(min-width: 720px) 720px" style="cursor: help;"></figure><p>Um nicht übereinstimmende Paare zu erhalten, kombinieren wir jedes Bild im Batch mit jedem Text AUSSER dem, zu dem es passt. Zum Beispiel ist das folgende Paar ein nicht übereinstimmendes Bild und Text:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--4-.png" class="kg-image" alt="Friendly brown dog playing in a shallow creek, shaking off water surrounded by natural greenery." width="500" height="500" style="cursor: help;"></figure><p><strong>Beschriftung:</strong> Ein Mädchen in Rosa pflückt Blumen.</p><p>Aber dieses Verfahren geht davon aus, dass alle Texte, die zu anderen Bildern passen, gleich schlechte Übereinstimmungen sind. Das stimmt nicht immer. Zum Beispiel:</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/image--4--1.png" class="kg-image" alt="Brown or gray dog standing in water amidst tall grass, suggesting outdoor play or relaxation." width="500" height="500" style="cursor: help;"></figure><p><strong>Beschriftung:</strong> Der Hund sitzt an einer Schneewehe.</p><p>Obwohl der Text dieses Bild nicht beschreibt, haben sie einen Hund gemeinsam. Wenn man dieses Paar als nicht übereinstimmend behandelt, wird das Wort "Hund" tendenziell von jedem Bild eines Hundes weggeschoben.</p><p><a href="https://papers.neurips.cc/paper_files/paper/2022/hash/702f4db7543a7432431df588d57bc7c9-Abstract-Conference.html">Liang et al. [2022]</a> zeigen, dass diese unvollkommenen nicht übereinstimmenden Paare alle Bilder und Texte voneinander wegschieben.</p><p>Wir machten uns daran, ihre Behauptung mit einem vollständig zufällig initialisierten <code>vit-b-32</code> Bildmodell und einem ähnlich randomisierten JinaBERT v2 Textmodell zu überprüfen, wobei die Trainingstemperatur auf einen konstanten Wert von 0,02 (eine moderat niedrige Temperatur) eingestellt wurde. Wir erstellten zwei Sätze von Trainingsdaten:</p><ul><li>Einer mit zufälligen Batches aus Flickr8k, wobei nicht übereinstimmende Paare wie oben beschrieben konstruiert wurden.</li><li>Einer, bei dem die Batches absichtlich mit mehreren Kopien desselben Bildes mit unterschiedlichen Texten in jedem Batch konstruiert wurden. Dies garantiert, dass eine signifikante Anzahl von "nicht übereinstimmenden" Paaren tatsächlich korrekte Übereinstimmungen füreinander sind.</li></ul><p>Wir trainierten dann zwei Modelle für eine Epoche, eines mit jedem Trainingsdatensatz, und maßen den durchschnittlichen Kosinus-Abstand zwischen 1.000 Text-Bild-Paaren im Flickr8k-Datensatz für jedes Modell. Das mit zufälligen Batches trainierte Modell hatte einen durchschnittlichen Kosinus-Abstand von 0,7521, während das mit vielen absichtlich übereinstimmenden "nicht übereinstimmenden" Paaren trainierte einen durchschnittlichen Kosinus-Abstand von 0,7840 hatte. Der Effekt der falschen "nicht übereinstimmenden" Paare ist ziemlich signifikant. Angesichts dessen, dass das reale Modelltraining viel länger dauert und viel mehr Daten verwendet, können wir sehen, wie dieser Effekt wachsen und die Lücke zwischen Bildern und Texten als Ganzes vergrößern würde.</p><h2 id="the-medium-is-the-message" style="position: relative;"><a href="#the-medium-is-the-message" title="Das Medium ist die Botschaft" id="anchor-the-medium-is-the-message"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Das Medium ist die Botschaft</h2><p>Der kanadische Kommunikationstheoretiker <a href="https://en.wikipedia.org/wiki/The_medium_is_the_message" rel="noopener noreferrer">Marshall McLuhan</a> prägte 1964 in seinem Buch <a href="https://en.wikipedia.org/wiki/Understanding_Media" rel="noopener noreferrer"><em>Understanding Media: The Extensions of Man</em></a> den Ausdruck "Das Medium ist die Botschaft", um zu betonen, dass Botschaften nicht autonom sind. Sie erreichen uns in einem Kontext, der ihre Bedeutung stark beeinflusst, und er behauptete bekanntlich, dass einer der wichtigsten Teile dieses Kontexts die Art des Kommunikationsmediums ist.</p><p>Die Multimodalitätslücke bietet uns eine einzigartige Gelegenheit, eine Klasse emergenter semantischer Phänomene in KI-Modellen zu untersuchen. Niemand hat Jina CLIP beigebracht, das Medium der Trainingsdaten zu codieren - es tat es einfach trotzdem. Auch wenn wir das Problem für multimodale Modelle noch nicht gelöst haben, haben wir zumindest ein gutes theoretisches Verständnis davon, woher das Problem kommt.</p><p>Wir sollten davon ausgehen, dass unsere Modelle aufgrund der gleichen Art von Bias andere Dinge codieren, nach denen wir noch nicht gesucht haben. Zum Beispiel haben wir wahrscheinlich das gleiche Problem bei mehrsprachigen Embedding-Modellen. Das gemeinsame Training mit zwei oder mehr Sprachen führt vermutlich zur gleichen Lücke zwischen den Sprachen, besonders da ähnliche Trainingsmethoden weit verbreitet sind. Lösungen für das Lückenproblem könnten sehr weitreichende Auswirkungen haben.</p><p>Eine Untersuchung des Initialisierungs-Bias in einer breiteren Palette von Modellen wird wahrscheinlich auch zu neuen Erkenntnissen führen. Wenn das Medium für ein Embedding-Modell die Botschaft ist, wer weiß, was sonst noch ohne unser Wissen in unsere Modelle codiert wird?</p></section></article><div data-v-1d9869b0="" class="row justify-between items-center q-py-md"><div data-v-1d9869b0=""><span data-v-1d9869b0="" class="text-weight-bold">Kategorien:</span><span data-v-1d9869b0="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech-Blog</div></div></div></span></div><div data-v-1d9869b0=""><div data-v-1d9869b0="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-1d9869b0="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fthe-what-and-why-of-text-image-modality-gap-in-clip-models%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-1d9869b0="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-1d9869b0="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fthe-what-and-why-of-text-image-modality-gap-in-clip-models%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-1d9869b0="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-1d9869b0="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fthe-what-and-why-of-text-image-modality-gap-in-clip-models%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-1d9869b0="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-1d9869b0="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fthe-what-and-why-of-text-image-modality-gap-in-clip-models%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-1d9869b0="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-1d9869b0="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fthe-what-and-why-of-text-image-modality-gap-in-clip-models%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-1d9869b0="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-1d9869b0="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-1d9869b0="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-1d9869b0="" class="text-h5 q-my-xl">Weiterlesen</div><a data-v-aa7e154f="" data-v-1d9869b0="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/watermarking-text-with-embedding-models-to-protect-against-content-theft"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa7e154f="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa7e154f="" class="q-focus-helper"></span><div data-v-aa7e154f="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa7e154f="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption">November 27, 2024 • 10 Minuten gelesen</div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa7e154f="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Watermarking Text with Embedding Models to Protect Against Content Theft</div><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption text-dim" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">You use our embedding models to do what? This might be the most "out-of-domain" applications of embeddings we learned at EMNLP 2024.</div></div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa7e154f="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa7e154f="" class="col-4 overflow-hidden"><div data-v-aa7e154f="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/banner--1-.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa7e154f="" data-v-1d9869b0="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/meta-prompt-for-better-jina-api-integration-and-codegen"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa7e154f="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa7e154f="" class="q-focus-helper"></span><div data-v-aa7e154f="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa7e154f="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption">November 19, 2024 • 9 Minuten gelesen</div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa7e154f="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Meta-Prompt for Better Jina API Integration and CodeGen</div><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption text-dim" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Is Meta-Prompt the new norm for API specs? Feed it to LLMs and generate integration code that reliably integrates Jina's APIs, saving you from the usual trial-and-error process.</div></div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa7e154f="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa7e154f="" class="col-4 overflow-hidden"><div data-v-aa7e154f="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Digital transformation icons with arrows on a teal background indicate file conversion, with contrasting blue and grey accent"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Digital transformation icons with arrows on a teal background indicate file conversion, with contrasting blue and grey accent" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--58-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa7e154f="" data-v-1d9869b0="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/beyond-clip-how-jina-clip-advances-multimodal-search"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa7e154f="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa7e154f="" class="q-focus-helper"></span><div data-v-aa7e154f="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa7e154f="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption">Oktober 29, 2024 • 11 Minuten gelesen</div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa7e154f="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Beyond CLIP: How Jina-CLIP Advances Multimodal Search</div><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption text-dim" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Learn how Jina-CLIP enhances OpenAI's CLIP with better retrieval accuracy and more diverse results through unified text-image embeddings.</div></div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa7e154f="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Bo Wang"><div style="padding-bottom: 93.2813%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Bo Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/4B483B29-E306-402B-8635-64866C458406.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa7e154f="" class="col-4 overflow-hidden"><div data-v-aa7e154f="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Abstract digital landscape with wave-like green and pink dunes against a dark background, conveying a tranquil atmosphere."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Abstract digital landscape with wave-like green and pink dunes against a dark background, conveying a tranquil atmosphere." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/10/clip.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Büros</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Sunnyvale, Kalifornien</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, USA</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Deutschland</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Deutschland</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Peking, China</div><div class="q-item__label q-item__label--caption text-caption text-dim">Ebene 5, Gebäude 6, Nr. 48 Haidian West St. Peking Haidian, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption text-dim">402, Etage 4, Fu'an Technology Building, Shenzhen Nanshan, China</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Stiftung durchsuchen</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Einbettungen</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Reranker</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Leser</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Klassifikator</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Segmentierer</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Holen Sie sich den Jina AI API-Schlüssel</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Ratenbegrenzung</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">API-Status</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Unternehmen</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Über uns</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Kontaktieren Sie unseren Vertrieb</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Pressemitteilungen</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Praktikantenprogramm</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Begleiten Sie uns</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Logo herunterladen</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Bedingungen</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/COMMERCIAL-LICENSE-TERMS.pdf" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Kommerzielle Lizenz</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#security"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Sicherheit</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; amp; Bedingungen</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Privatsphäre</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Cookie-Einstellungen</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-between q-gutter-x-sm col-12 col-md"><label class="q-field row no-wrap items-start q-field--outlined q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dense q-field--dark text-caption" for="f_04464e06-e53a-4400-a039-385cfb0da8b1"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-symbols material-symbols-sharp q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_04464e06-e53a-4400-a039-385cfb0da8b1" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_04464e06-e53a-4400-a039-385cfb0da8b1_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">arrow_drop_down</i></div></div></div></label><div class="text-caption text-dim"> Jina AI © 2020-2024. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>