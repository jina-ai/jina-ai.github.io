<!DOCTYPE html><html translate="no" dir="ltr" lang="de"><head><title>Braucht man immer noch Chunking, wenn Long-Context-Modelle alles können?</title><meta charset="utf-8"><meta name="title" content="Braucht man immer noch Chunking, wenn Long-Context-Modelle alles können?"><meta name="description" content="Vergleich der Leistung von Long-Context-Embedding-Modellen mit verschiedenen Chunking-Strategien, um den optimalen Ansatz für Ihre Anforderungen zu finden."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="og:title" content="Braucht man immer noch Chunking, wenn Long-Context-Modelle alles können?"><meta property="og:description" content="Vergleich der Leistung von Long-Context-Embedding-Modellen mit verschiedenen Chunking-Strategien, um den optimalen Ansatz für Ihre Anforderungen zu finden."><meta property="og:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all"><meta property="twitter:title" content="Braucht man immer noch Chunking, wenn Long-Context-Modelle alles können?"><meta property="twitter:description" content="Vergleich der Leistung von Long-Context-Embedding-Modellen mit verschiedenen Chunking-Strategien, um den optimalen Ansatz für Ihre Anforderungen zu finden."><meta property="twitter:image" content="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-BPEE_2Y0.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-CRvJtbiE.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-C1-EyamH.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-BQuHVWbA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-76PiKGfT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-CVHcuM4o.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-Bhwfx6hd.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-D5ZR03gB.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/de-Ck-F6j5P.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-0cH4HDco.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpace-BQpGtn1k.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-BFtPtjpq.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QToolbar-Df07R5d8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-3YDLeJ7i.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnGroup-C-dF1wEO.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-BEbkEnfB.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-By4tnZtt.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-yYZ10g0C.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-CvE1bk_2.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-DQs4YJK2.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-BfYflfOA.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-XygDhk0D.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-Cs2-cWDA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-DI5V1Acr.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/format-DyQxkAtJ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/embedding-DLs2w9bj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-DNKP3pl_.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-CxkOKBL_.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-B1IuF4Mz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-CQK8GaDj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-q8sq8eH1.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-BMR_OewU.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-BsvvXJK4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-DDeF0QZG.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-C5lPGcZT.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-CeFRCKjR.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-DTJPy3qM.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-BYg3bc8w.css"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-BzZFmr__.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><meta name="author" content="Alex C-G, Michael Günther"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Alex C-G, Michael Günther"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="13 mins read"><meta property="article:published_time" content="2024-12-05T00:55:21.000+01:00"><meta property="article:modified_time" content="2024-12-05T00:55:21.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Braucht man immer noch Chunking, wenn Long-Context-Modelle alles können?",
  "description": "Vergleich der Leistung von Long-Context-Embedding-Modellen mit verschiedenen Chunking-Strategien, um den optimalen Ansatz für Ihre Anforderungen zu finden.",
  "image": [
    "https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png"
  ],
  "datePublished": "2024-12-05T00:55:21.000+01:00",
  "dateModified": "2024-12-05T00:55:21.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    },
    {
      "@type": "Person",
      "name": "Michael Günther",
      "url": "https://jina-ai-gmbh.ghost.io/author/michael/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><link prerender-ignore rel=preconnect href=//api.usercentrics.eu><link prerender-ignore rel=preconnect href=//privacy-proxy.usercentrics.eu><link prerender-ignore rel=preload href=//app.usercentrics.eu/browser-ui/latest/loader.js as=script><link prerender-ignore rel=preload href=//privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js as=script><script prerender-ignore id=usercentrics-cmp data-settings-id=w5v6v2pJsC3wdR src=https://app.usercentrics.eu/browser-ui/latest/loader.js async></script><script prerender-ignore src=https://privacy-proxy.usercentrics.eu/latest/uc-block.bundle.js async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled " aria-hidden="true" role="presentation">notifications</i></div><div class="q-item__section column q-item__section--main justify-center">Pressemitteilungen</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_b0a50a9d-050a-475f-a025-df0749a41535" aria-label="Erweitern Sie &quot;Produkte&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled " aria-hidden="true" role="presentation">box</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Produkte</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_b0a50a9d-050a-475f-a025-df0749a41535" style="display: none;"><div class="q-list q-list--dark" role="list" label="Produkte"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">Für Firmen</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Einbettungen</div><div class="q-item__label q-item__label--caption text-caption">Multimodale und mehrsprachige Einbettungen von Weltklasse.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Reranker</div><div class="q-item__label q-item__label--caption text-caption">Neural Retriever der Weltklasse zur Maximierung der Suchrelevanz.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Leser</div><div class="q-item__label q-item__label--caption text-caption">Lesen Sie URLs und suchen Sie im Internet nach fundierteren LLMs.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Klassifikator</div><div class="q-item__label q-item__label--caption text-caption">Zero-Shot- und Few-Shot-Klassifizierung für Bild und Text.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Segmentierer</div><div class="q-item__label q-item__label--caption text-caption">Schneiden Sie langen Text in Abschnitte und führen Sie eine Tokenisierung durch.</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><div class="q-item__label q-item__label--header row justify-between items-center q-pa-sm"><span class="q-pl-sm">Für Power-User</span></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://promptperfect.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://promptperfect.jina.ai/PromptPerfect-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">PromptPerfect</div><div class="q-item__label q-item__label--caption text-caption">Erstklassiges Tool für schnelles Engineering</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_a91440db-4299-4102-b091-bdecb9c8cf1f" aria-label="Erweitern Sie &quot;Mehr Power-User-Tools&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Mehr Power-User-Tools</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_a91440db-4299-4102-b091-bdecb9c8cf1f" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://scenex.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://scenex.jina.ai/SceneX - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">SceneXplain</div><div class="q-item__label q-item__label--caption text-caption">Führende KI-Lösung für Bildunterschriften und Videozusammenfassungen</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://bestbanner.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://bestbanner.jina.ai/bestbanner-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">BestBanner</div><div class="q-item__label q-item__label--caption text-caption">Vom Blog-Artikel zum Banner, ohne eigene Prompts!</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://chat.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://chat.jina.ai/JinaChat - Light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">JinaChat</div><div class="q-item__label q-item__label--caption text-caption">Mehr Modalitäten, längerer Speicher, weniger Kosten</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://rationale.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://rationale.jina.ai/Rationale-light.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Rationale</div><div class="q-item__label q-item__label--caption text-caption">Ultimative KI-Tools zur Entscheidungsfindung</div></div></a></div></div></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_bb3aa42d-7955-4afd-b12a-ecd335385f6f" aria-label="Erweitern Sie &quot;Unternehmen&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon" aria-hidden="true" role="presentation"><img src="/J.svg"></i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Unternehmen</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_bb3aa42d-7955-4afd-b12a-ecd335385f6f" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Über uns</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Kontaktieren Sie unseren Vertrieb</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Praktikantenprogramm</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Begleiten Sie uns</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Logo herunterladen</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; amp; Bedingungen</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="Einloggen"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div><div class="q-item__section column q-item__section--main justify-center">Einloggen</div></a></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-a34f4c1e="" class="q-page" style="min-height: 100vh;"><div data-v-a34f4c1e="" class="row full-width relative-position justify-end"><div data-v-a34f4c1e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-a34f4c1e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Ist Long Context überhaupt nützlich?</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Probleme mit Long-Context-Embeddings</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Long Context vs. Abschneiden</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Text-Segmentierung für bessere Retrieval-Leistung</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Late Chunking löst das Kontext-Problem</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Chunking oder kein Chunking?</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Erkenntnisse: Wann verwendet man was?</div></div></div><div data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-a34f4c1e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-a34f4c1e="" class="q-item__label">Fazit</div></div></div></div></div><div data-v-a34f4c1e="" class="col-12 col-md-10 col-lg-12"><div data-v-a34f4c1e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech-Blog</div></div></div></div><div data-v-a34f4c1e="" class="row justify-center"><div data-v-a34f4c1e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-a34f4c1e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">Dezember 04, 2024</div><h1 data-v-a34f4c1e="" class="text-weight-medium text-center q-px-md my-title">Braucht man immer noch Chunking, wenn Long-Context-Modelle alles können?</h1><div data-v-a34f4c1e="" class="col row justify-center"><div data-v-a34f4c1e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Vergleich der Leistung von Long-Context-Embedding-Modellen mit verschiedenen Chunking-Strategien, um den optimalen Ansatz für Ihre Anforderungen zu finden.</div></div><div data-v-a34f4c1e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-a34f4c1e="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/long-context.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-a34f4c1e="" class="row justify-center"><div data-v-a34f4c1e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-a34f4c1e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-a34f4c1e="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Michael Günther"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Michael Günther" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/profile_low_quality.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-a34f4c1e="" class="q-item__label">Alex C-G, Michael Günther • 13 Minuten gelesen</div></div></div></div><div data-v-a34f4c1e="" class="row justify-center"><div data-v-a34f4c1e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-a34f4c1e="" class="article"><section data-v-a34f4c1e="" class="gh-content"><p>Im Oktober 2023 stellten wir <code>jina-embeddings-v2</code> vor, die erste Open-Source-Embedding-Modellfamilie, die Eingaben bis zu 8.192 Token verarbeiten kann. Darauf aufbauend haben wir dieses Jahr <code>jina-embeddings-v3</code> eingeführt, das die gleiche umfangreiche Eingabeunterstützung mit weiteren Verbesserungen bietet.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 is a frontier multilingual text embedding model with 570M parameters and 8192 token-length, outperforming the latest proprietary embeddings from OpenAI and Cohere on MTEB.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-14.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-4.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><p>In diesem Beitrag werden wir uns mit Long-Context-Embeddings befassen und einige Fragen beantworten: Wann ist es praktikabel, ein so großes Textvolumen in einen einzigen Vektor zu konsolidieren? Verbessert Segmentierung das Retrieval, und wenn ja, wie? Wie können wir den Kontext aus verschiedenen Teilen eines Dokuments beim Segmentieren des Textes bewahren?</p><p>Um diese Fragen zu beantworten, werden wir verschiedene Methoden zur Generierung von Embeddings vergleichen:</p><ul><li>Long-Context-Embedding (Kodierung von bis zu 8.192 Token in einem Dokument) vs. Short-Context (d.h. Abschneiden bei 192 Token).</li><li>Kein Chunking vs. naives Chunking vs. <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">Late Chunking</a>.</li><li>Verschiedene Chunk-Größen sowohl beim naiven als auch beim Late Chunking.</li></ul><h2 id="is-long-context-even-useful" style="position: relative;"><a href="#is-long-context-even-useful" title="Ist Long Context überhaupt nützlich?" id="anchor-is-long-context-even-useful"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Ist Long Context überhaupt nützlich?</h2><p>Mit der Möglichkeit, bis zu zehn Seiten Text in einem einzigen Embedding zu kodieren, eröffnen Long-Context-Embedding-Modelle neue Möglichkeiten für die Darstellung großer Textmengen. Ist das aber überhaupt nützlich? Laut vielen Leuten... nein.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 6.35227 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--15-.png" width="559" height="88" alt="" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 5.21368 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png" width="610" height="117" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--16-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--16-.png 610w" style="cursor: help;"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image" style="flex: 10.2143 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png" width="1430" height="140" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--14-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--14-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--14-.png 1430w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div><div class="kg-gallery-image" style="flex: 11.0735 1 0%;"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png" width="1506" height="136" alt="" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--13-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--13-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--13-.png 1506w" sizes="(min-width: 720px) 720px" style="cursor: help;"></div></div></div><figcaption><p><span style="white-space: pre-wrap;">Quellen: </span><a href="https://www.youtube.com/watch?v=xKR08kDY2q4"><span style="white-space: pre-wrap;">Zitat von Nils Reimer im How AI Is Built Podcast</span></a><span style="white-space: pre-wrap;">, </span><a href="https://x.com/brainlag/status/1717221138483331158"><span style="white-space: pre-wrap;">brainlag Tweet</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38026784"><span style="white-space: pre-wrap;">egorfine Hacker News Kommentar</span></a><span style="white-space: pre-wrap;">, </span><a href="https://news.ycombinator.com/item?id=38020753"><span style="white-space: pre-wrap;">andy99 Hacker News Kommentar</span></a></p></figcaption></figure><p>Wir werden all diese Bedenken mit einer detaillierten Untersuchung der Long-Context-Fähigkeiten, wann Long Context hilfreich ist und wann man ihn (nicht) verwenden sollte, ansprechen. Aber zunächst wollen wir uns diese Skeptiker anhören und einige der Probleme betrachten, mit denen Long-Context-Embedding-Modelle konfrontiert sind.</p><h2 id="problems-with-long-context-embeddings" style="position: relative;"><a href="#problems-with-long-context-embeddings" title="Probleme mit Long-Context-Embeddings" id="anchor-problems-with-long-context-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Probleme mit Long-Context-Embeddings</h2><p>Stellen wir uns vor, wir bauen ein Dokumentensuchsystem für Artikel, wie die in unserem <a href="https://jina.ai/news">Jina AI Blog</a>. Manchmal kann ein einzelner Artikel mehrere Themen abdecken, wie der <a href="https://jina.ai/news/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc">Bericht über unseren Besuch der ICML 2024 Konferenz</a>, der enthält:</p><ul><li>Eine Einführung mit allgemeinen Informationen über ICML (Teilnehmerzahl, Ort, Umfang, etc).</li><li>Die Präsentation unserer Arbeit (<code>jina-clip-v1</code>).</li><li>Zusammenfassungen anderer interessanter Forschungsarbeiten, die auf der ICML vorgestellt wurden.</li></ul><p>Wenn wir nur ein einziges Embedding für diesen Artikel erstellen, repräsentiert dieses Embedding eine Mischung aus drei verschiedenen Themen:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png" class="kg-image" alt="" width="2000" height="778" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image.png 2048w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 1: Beim Embedding eines Dokuments, das mehrere Themen behandelt, stellt der resultierende Vektor eine Mischung aller Absätze dar, wodurch möglicherweise die spezifischen Informationen der einzelnen Absätze verloren gehen.</span></figcaption></figure><p>Dies führt zu mehreren Problemen:</p><ul><li><strong>Verwässerung der Repräsentation:</strong> Während alle Themen in einem Text miteinander verwandt sein <em>könnten</em>, ist möglicherweise nur eines für die Suchanfrage des Nutzers relevant. Ein einzelnes Embedding (in diesem Fall das des gesamten Blogbeitrags) ist jedoch nur ein Punkt im Vektorraum. Je mehr Text zur Modelleingabe hinzugefügt wird, desto mehr verschiebt sich das Embedding, um das übergeordnete Thema des Artikels zu erfassen, wodurch es weniger effektiv wird, den in bestimmten Absätzen behandelten Inhalt zu repräsentieren.</li><li><strong>Begrenzte Kapazität:</strong> Embedding-Modelle erzeugen Vektoren fester Größe, unabhängig von der Eingabelänge. Je mehr Inhalt zur Eingabe hinzugefügt wird, desto schwieriger wird es für das Modell, all diese Informationen im Vektor darzustellen. Stellen Sie sich das vor wie die Skalierung eines Bildes auf 16×16 Pixel — Wenn Sie ein Bild von etwas Einfachem wie einem Apfel skalieren, können Sie aus dem skalierten Bild immer noch Bedeutung ableiten. Bei einer Straßenkarte von Berlin? Eher nicht.</li><li><strong>Informationsverlust:</strong> In manchen Fällen stoßen selbst Long-Context-Embedding-Modelle an ihre Grenzen; Viele Modelle unterstützen Textkodierung mit bis zu 8.192 Token. Längere Dokumente müssen vor dem Embedding gekürzt werden, was zu Informationsverlust führt. Wenn sich die für den Benutzer relevante Information am Ende des Dokuments befindet, wird sie vom Embedding überhaupt nicht erfasst.</li><li><strong>Textsegmentierung kann <em>notwendig</em> sein:</strong> Einige Anwendungen erfordern Embeddings für bestimmte Textsegmente, aber nicht für das gesamte Dokument, wie zum Beispiel das Identifizieren der relevanten Passage in einem Text.</li></ul><h2 id="long-context-vs-truncation" style="position: relative;"><a href="#long-context-vs-truncation" title="Long Context vs. Abschneiden" id="anchor-long-context-vs-truncation"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Long Context vs. Abschneiden</h2><p>Um zu sehen, ob Long Context überhaupt sinnvoll ist, betrachten wir die Leistung von zwei Retrieval-Szenarien:</p><ul><li>Kodierung von Dokumenten bis zu 8.192 Token (etwa 10 Textseiten).</li><li>Abschneiden von Dokumenten bei 192 Token und Kodierung bis dahin.</li></ul><p>Wir werden die Ergebnisse vergleichen mit<code>jina-embeddings-v3</code> mit der nDCG@10 Retrieval-Metrik. Wir haben folgende Datensätze getestet:</p>

<table>
<thead>
<tr>
<th>Dataset</th>
<th>Beschreibung</th>
<th>Beispiel-Query</th>
<th>Beispiel-Dokument</th>
<th>Durchschnittliche Dokumentlänge (Zeichen)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/"><strong>NFCorpus</strong></a></td>
<td>Ein medizinischer Volltext-Retrieval-Datensatz mit 3.244 Queries und Dokumenten hauptsächlich aus PubMed.</td>
<td>"Using Diet to Treat Asthma and Eczema"</td>
<td>"Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland Recent studies have suggested that [...]"</td>
<td>326.753</td>
</tr>
<tr>
<td><a href="https://github.com/Yale-LILY/QMSum"><strong>QMSum</strong></a></td>
<td>Ein query-basierter Meeting-Zusammenfassungs-Datensatz, der die Zusammenfassung relevanter Meeting-Segmente erfordert.</td>
<td>"The professor was the one to raise the issue and suggested that a knowledge engineering trick [...]"</td>
<td>"Project Manager: Is that alright now ? {vocalsound} Okay . Sorry ? Okay , everybody all set to start the meeting ? [...]"</td>
<td>37.445</td>
</tr>
<tr>
<td><a href="https://paperswithcode.com/dataset/narrativeqa"><strong>NarrativeQA</strong></a></td>
<td>QA-Datensatz mit langen Geschichten und entsprechenden Fragen zu spezifischen Inhalten.</td>
<td>"What kind of business Sophia owned in Paris?"</td>
<td>"ï»¿The Project Gutenberg EBook of The Old Wives' Tale, by Arnold Bennett\n\nThis eBook is for the use of anyone anywhere [...]"</td>
<td>53.336</td>
</tr>
<tr>
<td><a href="https://github.com/Alab-NII/2wikimultihop"><strong>2WikiMultihopQA</strong></a></td>
<td>Ein Multi-Hop-QA-Datensatz mit bis zu 5 Reasoning-Schritten, entwickelt mit Templates zur Vermeidung von Shortcuts.</td>
<td>"What is the award that the composer of song The Seeker (The Who Song) earned?"</td>
<td>"Passage 1:\nMargaret, Countess of Brienne\nMarguerite d'Enghien (born 1365 - d. after 1394), was the ruling suo jure [...]"</td>
<td>30.854</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2104.07091"><strong>SummScreenFD</strong></a></td>
<td>Ein Drehbuch-Zusammenfassungs-Datensatz mit TV-Serien-Transkripten und Zusammenfassungen, die eine verteilte Plot-Integration erfordern.</td>
<td>"Penny gets a new chair, which Sheldon enjoys until he finds out that she picked it up from [...]"</td>
<td>"[EXT. LAS VEGAS CITY (STOCK) - NIGHT]\n[EXT. ABERNATHY RESIDENCE - DRIVEWAY -- NIGHT]\n(The lamp post light over the [...]"</td>
<td>1.613</td>
</tr>
</tbody>
</table>

<p>Wie wir sehen können, bringt die Kodierung von mehr als 192 Tokens bemerkenswerte Leistungsverbesserungen:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png" class="kg-image" alt="" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-1.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-1.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-1.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 2: Vergleich der Long-Context Embedding Performance und Short Text Embedding Performance</span></figcaption></figure><p>Allerdings sehen wir bei einigen Datensätzen größere Verbesserungen als bei anderen:</p><ul><li>Bei <strong>NFCorpus</strong> macht die Kürzung kaum einen Unterschied. Das liegt daran, dass sich die Titel und Abstracts direkt am Anfang der Dokumente befinden und diese hochrelevant für typische Benutzer-Suchbegriffe sind. Ob gekürzt oder nicht, die relevantesten Daten bleiben innerhalb des Token-Limits.</li><li><strong>QMSum</strong> und <strong>NarrativeQA</strong> gelten als "Leseverständnis"-Aufgaben, bei denen Benutzer typischerweise nach spezifischen Fakten innerhalb eines Textes suchen. Diese Fakten sind oft in Details verstreut, die über das Dokument verteilt sind und möglicherweise außerhalb der gekürzten 192-Token-Grenze liegen. Zum Beispiel wird im NarrativeQA-Dokument <em>Percival Keene</em> die Frage "Who is the bully that steals Percival's lunch?" erst weit nach dieser Grenze beantwortet. Ähnlich verhält es sich bei <strong>2WikiMultiHopQA</strong>, wo relevante Informationen über ganze Dokumente verteilt sind und Modelle mehrere Abschnitte navigieren und synthetisieren müssen, um Anfragen effektiv zu beantworten.</li><li><strong>SummScreenFD</strong> ist eine Aufgabe, die darauf abzielt, das Drehbuch zu identifizieren, das zu einer bestimmten Zusammenfassung gehört. Da die Zusammenfassung Informationen enthält, die über das Drehbuch verteilt sind, verbessert die Kodierung von mehr Text die Genauigkeit beim Zuordnen der Zusammenfassung zum richtigen Drehbuch.</li></ul><h2 id="segmenting-text-for-better-retrieval-performance" style="position: relative;"><a href="#segmenting-text-for-better-retrieval-performance" title="Text-Segmentierung für bessere Retrieval-Leistung" id="anchor-segmenting-text-for-better-retrieval-performance"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Text-Segmentierung für bessere Retrieval-Leistung</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Im Folgenden diskutieren wir drei ähnliche Konzepte. Um Verwechslungen zu vermeiden, bezeichnen wir sie wie folgt:<br>• <b><strong style="white-space: pre-wrap;">Segmentierung</strong></b>: Erkennen von Grenzsignalen in einem Eingabetext, zum Beispiel Sätze oder eine feste Anzahl von Tokens.<br>• <b><strong style="white-space: pre-wrap;">Naives Chunking</strong></b>: Aufteilen des Textes in Chunks basierend auf Segmentierungssignalen vor der Kodierung.<br>• <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap;">Late Chunking</strong></b></a>: Zuerst das Dokument kodieren und dann segmentieren (Kontext zwischen Chunks bleibt erhalten).</div></div><p>Anstatt ein ganzes Dokument in einen Vektor einzubetten, können wir verschiedene Methoden verwenden, um das Dokument zunächst durch Zuweisen von Grenzsignalen zu segmentieren:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/chunking-animation.gif" class="kg-image" alt="" width="2000" height="492" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/chunking-animation.gif 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/chunking-animation.gif 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/chunking-animation.gif 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/chunking-animation.gif 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 3: Anwendung der Methoden "Fixed-Size", "Sentence-Based" und "Semantic" Chunking auf eine Textpassage</span></figcaption></figure><p>Einige gängige Methoden sind:</p><ul><li><strong>Segmentierung nach fester Größe:</strong> Das Dokument wird in Segmente mit einer festen Anzahl von Tokens unterteilt, die durch den Tokenizer des Embedding-Modells bestimmt wird. Dies stellt sicher, dass die Tokenisierung der Segmente der Tokenisierung des gesamten Dokuments entspricht (eine Segmentierung nach einer bestimmten Anzahl von Zeichen könnte zu einer anderen Tokenisierung führen).</li><li><strong>Segmentierung nach Sätzen:</strong> Das Dokument wird in Sätze segmentiert, und jeder Chunk besteht aus <em>n</em> Sätzen.</li><li><strong>Semantische Segmentierung:</strong> Jedes Segment entspricht mehreren Sätzen, und ein Embedding-Modell bestimmt die Ähnlichkeit aufeinanderfolgender Sätze. Sätze mit hoher Embedding-Ähnlichkeit werden demselben Chunk zugewiesen.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Sie können die Segmentierung einfach mit <a href="https://jina.ai/segmenter/">Jina Segmenter</a> durchführen, unserer kostenlosen API zur Segmentierung langer Texte in Chunks und Tokenisierung basierend auf der Struktur des Dokuments.</div></div><p>Der Einfachheit halber verwenden wir in diesem Artikel die Segmentierung nach fester Größe.</p><h3 id="document-retrieval-using-naive-chunking" style="position: relative;"><a href="#document-retrieval-using-naive-chunking" title="Dokument-Retrieval mit naivem Chunking" id="anchor-document-retrieval-using-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Dokument-Retrieval mit naivem Chunking</h3><p>Sobald wir die Segmentierung nach fester Größe durchgeführt haben, können wir das Dokument naiv entsprechend dieser Segmente chunken:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png" class="kg-image" alt="" width="960" height="540" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/Sharing-Chunking-Blog-Post-Images--1---1-.png 960w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 4: Naives Chunking basierend auf während der Segmentierung erkannten Grenzsignalen.</span></figcaption></figure><p>Mit <code>jina-embeddings-v3</code> kodieren wir jeden Chunk in ein Embedding, das seine Semantik genau erfasst, und speichern diese Embeddings dann in einer Vektordatenbank.</p><p>Zur Laufzeit kodiert das Modell die Anfrage eines Benutzers in einen Query-Vektor. Wir vergleichen diesen mit unserer Vektordatenbank von Chunk-Embeddings, um den Chunk mit der höchsten Kosinus-Ähnlichkeit zu finden, und geben dann das entsprechende Dokument an den Benutzer zurück:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--17-.png" class="kg-image" alt="" width="2000" height="847" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--17-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--17-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--17-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/size/w2400/2024/12/image--17-.png 2400w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap">Abbildung 5: Dokumenten-Retrieval mit naivem Chunking implementiert: (1) Die Dokumente in der Sammlung werden basierend auf Grenzhinweisen in Chunks aufgeteilt, (2) das Embedding-Modell codiert alle Chunks und wir speichern die resultierenden Embeddings in einer Datenbank, (3) wenn eine Anfrage eingeht, codiert das Embedding-Modell diese und die Datenbank ermittelt den ähnlichsten Chunk. Am Ende identifizieren wir das relevante Dokument anhand der für den Chunk in der Datenbank gespeicherten Dokument-ID und geben es an den Benutzer zurück.</span></figcaption></figure><h3 id="problems-with-naive-chunking" style="position: relative;"><a href="#problems-with-naive-chunking" title="Probleme mit naivem Chunking" id="anchor-problems-with-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Probleme mit naivem Chunking</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png" class="kg-image" alt="" width="1774" height="456" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--18-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--18-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/size/w1600/2024/12/image--18-.png 1600w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--18-.png 1774w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap">Abbildung 6: Bei der Aufteilung eines Textes in Sätze können Bezüge zu früheren Textteilen nicht aufgelöst werden.</span></figcaption></figure><p>Während naives Chunking einige der Einschränkungen von Long-Context Embedding-Modellen adressiert, hat es auch seine Nachteile:</p><ul><li><strong>Das große Ganze wird übersehen:</strong> Bei der Dokumentensuche können mehrere Embeddings kleinerer Chunks möglicherweise das übergreifende Thema des Dokuments nicht erfassen. Man sieht sozusagen den Wald vor lauter Bäumen nicht.</li><li><strong>Fehlendes Kontext-Problem:</strong> Chunks können nicht akkurat interpretiert werden, da Kontextinformationen fehlen, wie in Abbildung 6 dargestellt.</li><li><strong>Effizienz:</strong> Mehr Chunks benötigen mehr Speicherplatz und erhöhen die Abrufzeit.</li></ul><h2 id="late-chunking-solves-the-context-problem" style="position: relative;"><a href="#late-chunking-solves-the-context-problem" title="Late Chunking löst das Kontext-Problem" id="anchor-late-chunking-solves-the-context-problem"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Late Chunking löst das Kontext-Problem</h2><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Um das Problem des fehlenden Kontexts zu lösen, haben wir eine neue Methode namens „Late Chunking" eingeführt, die in unseren vorherigen Blog-Posts beschrieben wird: <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><b><strong style="white-space: pre-wrap">Teil I</strong></b></a>, <a href="https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/"><b><strong style="white-space: pre-wrap">Teil II</strong></b></a>, <a href="https://jina.ai/news/finding-optimal-breakpoints-in-long-documents-using-small-language-models"><b><strong style="white-space: pre-wrap">Teil III</strong></b></a>, <a href="https://arxiv.org/abs/2409.04701"><b><strong style="white-space: pre-wrap">Forschungspapier</strong></b></a>.</div></div><p>Late Chunking funktioniert in zwei Hauptschritten:</p><ol><li>Zunächst nutzt es die Long-Context-Fähigkeiten des Modells, um das gesamte Dokument in Token-Embeddings zu codieren. Dies bewahrt den vollständigen Kontext des Dokuments.</li><li>Dann erstellt es Chunk-Embeddings durch Anwendung von Mean Pooling auf bestimmte Sequenzen von Token-Embeddings, die den während der Segmentierung identifizierten Grenzmarkierungen entsprechen.</li></ol><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png" class="kg-image" alt="" width="1200" height="865" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--19-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--19-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--19-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap">Abbildung 7: Late vs naives Chunking.</span></figcaption></figure><p>Der Hauptvorteil dieses Ansatzes ist, dass die Token-Embeddings kontextualisiert sind - das bedeutet, sie erfassen natürlich Bezüge und Beziehungen zu anderen Teilen des Dokuments. Da der Embedding-Prozess vor dem Chunking stattfindet, behält jeder Chunk das Bewusstsein für den breiteren Dokumentenkontext bei und löst damit das Problem des fehlenden Kontexts, das naive Chunking-Ansätze plagt.</p><p>Für Dokumente, die die maximale Eingabegröße des Modells überschreiten, können wir „Long Late Chunking" verwenden:</p><ol><li>Zunächst teilen wir das Dokument in überlappende „Macro-Chunks" auf. Jeder Macro-Chunk ist so dimensioniert, dass er in die maximale Kontextlänge des Modells passt (zum Beispiel 8.192 Token).</li><li>Das Modell verarbeitet diese Macro-Chunks, um Token-Embeddings zu erstellen.</li><li>Sobald wir die Token-Embeddings haben, fahren wir mit dem Standard-Late-Chunking fort - wir wenden Mean Pooling an, um die finalen Chunk-Embeddings zu erstellen.</li></ol><p>Dieser Ansatz ermöglicht es uns, Dokumente beliebiger Länge zu verarbeiten und dabei die Vorteile des Late Chunking zu bewahren. Man kann es sich als zweistufigen Prozess vorstellen: Zunächst wird das Dokument für das Modell verdaulich gemacht, dann wird das reguläre Late-Chunking-Verfahren angewendet.</p><p>Kurz gesagt:</p><ul><li><strong>Naives Chunking:</strong> Das Dokument in kleine Chunks segmentieren, dann jeden Chunk separat codieren.</li><li><strong>Late Chunking:</strong> Das gesamte Dokument auf einmal codieren, um Token-Embeddings zu erstellen, dann Chunk-Embeddings durch Pooling der Token-Embeddings basierend auf Segmentgrenzen erstellen.</li><li><strong>Long Late Chunking:</strong> Große Dokumente in überlappende Macro-Chunks aufteilen, die in das Kontextfenster des Modells passen, diese codieren, um Token-Embeddings zu erhalten, dann Late Chunking wie gewohnt anwenden.</li></ul><p>Für eine ausführlichere Beschreibung der Idee werfen Sie einen Blick in unser <a href="https://arxiv.org/abs/2409.04701">Paper</a> oder die oben erwähnten Blog-Posts.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2409.04701"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models</div><div class="kg-bookmark-description">Many use cases require retrieving smaller portions of text, and dense vector-based retrieval systems often perform better with shorter text segments, as the semantics are less likely to be over-compressed in the embeddings. Consequently, practitioners often split text documents into smaller chunks and encode them separately. However, chunk embeddings created in this way can lose contextual information from surrounding chunks, resulting in sub-optimal representations. In this paper, we introduce a novel method called late chunking, which leverages long context embedding models to first embed all tokens of the long text, with chunking applied after the transformer model and just before mean pooling - hence the term late in its naming. The resulting chunk embeddings capture the full contextual information, leading to superior results across various retrieval tasks. The method is generic enough to be applied to a wide range of long-context embedding models and works without additional training. To further increase the effectiveness of late chunking, we propose a dedicated fine-tuning approach for embedding models.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/apple-touch-icon-6.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Michael Günther</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/arxiv-logo-fb-2.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure><h2 id="to-chunk-or-not-to-chunk" style="position: relative;"><a href="#to-chunk-or-not-to-chunk" title="Chunking oder kein Chunking?" id="anchor-to-chunk-or-not-to-chunk"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Chunking oder kein Chunking?</h2><p>Wir haben bereits gesehen, dass Long-Context Embedding im Allgemeinen bessere Leistung als kürzere Text-Embeddings erbringt, und einen Überblick über naive und Late-Chunking-Strategien gegeben. Die Frage ist nun: Ist Chunking besser als Long-Context Embedding?</p><p>Um einen fairen Vergleich durchzuführen, kürzen wir Textwerte auf die maximale Sequenzlänge des Modells (8.192 Token), bevor wir mit der Segmentierung beginnen. Wir verwenden eine Segmentierung fester Größe mit 64 Token pro Segment (sowohl für naive Segmentierung als auch für Late Chunking). Vergleichen wir drei Szenarien:</p><ul><li><strong>Keine Segmentierung:</strong> Wir codieren jeden Text in ein einzelnes Embedding. Dies führt zu den gleichen Ergebnissen wie im vorherigen Experiment (siehe Abbildung 2), aber wir nehmen sie hier zum besseren Vergleich auf.</li><li><strong>Naives Chunking:</strong> Wir segmentieren die Texte und wenden dann naives Chunking basierend auf den Grenzmarkierungen an.</li><li><strong>Late Chunking:</strong> Wir segmentieren die Texte und verwenden dann Late Chunking zur Bestimmung der Embeddings.</li></ul><p>Sowohl bei Late Chunking als auch bei naiver Segmentierung verwenden wir Chunk-Retrieval zur Bestimmung des relevanten Dokuments (wie in Abbildung 5 weiter oben in diesem Beitrag gezeigt).</p><p>Die Ergebnisse zeigen keinen klaren Gewinner:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png" class="kg-image" alt="" width="1200" height="600" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image-3.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image-3.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image-3.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap">Abbildung 8: Kein Chunking vs naives Chunking vs Late Chunking</span></figcaption></figure><ul><li><strong>Für Faktensuche funktioniert naives Chunking besser:</strong> Für die Datensätze QMSum, NarrativeQA und 2WikiMultiHopQA muss das Modell relevante Passagen im Dokument identifizieren. Hier ist naives Chunking deutlich besser als die Codierung von allem in ein einzelnes Embedding, da wahrscheinlich nur wenige Chunks relevante Informationen enthalten und diese Chunks sie viel besser erfassen als ein einzelnes Embedding des gesamten Dokuments.</li><li><strong>Late Chunking funktioniert am besten bei kohärenten Dokumenten mit relevantem Kontext:</strong> Bei Dokumenten, die ein zusammenhängendes Thema behandeln und bei denen Benutzer eher nach übergeordneten Themen als nach spezifischen Fakten suchen (wie bei NFCorpus), schneidet Late Chunking etwas besser ab als kein Chunking, da es dokumentweiten Kontext mit lokalen Details ausbalanciert. Während Late Chunking im Allgemeinen durch die Kontexterhaltung besser funktioniert als naives Chunking, kann dieser Vorteil zum Nachteil werden, wenn nach isolierten Fakten in Dokumenten mit überwiegend irrelevanten Informationen gesucht wird - wie die Leistungsrückgänge bei NarrativeQA und 2WikiMultiHopQA zeigen, wo der zusätzliche Kontext eher ablenkt als hilft.</li></ul><h3 id="does-chunk-size-make-a-difference" style="position: relative;"><a href="#does-chunk-size-make-a-difference" title="Macht die Chunk-Größe einen Unterschied?" id="anchor-does-chunk-size-make-a-difference"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Macht die Chunk-Größe einen Unterschied?</h3><p>Die Effektivität von Chunking-Methoden hängt stark vom Dataset ab, was zeigt, wie wichtig die Inhaltsstruktur ist:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png" class="kg-image" alt="" width="1200" height="1800" srcset="https://jina-ai-gmbh.ghost.io/content/images/size/w600/2024/12/image--21-.png 600w, https://jina-ai-gmbh.ghost.io/content/images/size/w1000/2024/12/image--21-.png 1000w, https://jina-ai-gmbh.ghost.io/content/images/2024/12/image--21-.png 1200w" sizes="(min-width: 720px) 720px" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">Abbildung 9: Vergleich von Chunk-Größen bei naivem und spätem Chunking.</span></figcaption></figure><p>Wie wir sehen können, übertrifft Late Chunking bei kleineren Chunk-Größen generell das naive Chunking, da kleinere naive Chunks zu wenig Kontext enthalten, während kleinere Late Chunks den Kontext des gesamten Dokuments bewahren und dadurch semantisch aussagekräftiger sind. Die Ausnahme bildet das NarrativeQA Dataset, bei dem es einfach so viel irrelevanten Kontext gibt, dass Late Chunking zurückfällt. Bei größeren Chunk-Größen zeigt naives Chunking deutliche Verbesserungen (und übertrifft gelegentlich Late Chunking) aufgrund des erhöhten Kontexts, während die Leistung von Late Chunking allmählich abnimmt.</p><h2 id="takeaways-when-to-use-what" style="position: relative;"><a href="#takeaways-when-to-use-what" title="Erkenntnisse: Wann verwendet man was?" id="anchor-takeaways-when-to-use-what"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Erkenntnisse: Wann verwendet man was?</h2><p>In diesem Beitrag haben wir verschiedene Arten von Dokumenten-Retrieval-Aufgaben untersucht, um besser zu verstehen, wann Segmentierung und wann Late Chunking hilft. Was haben wir also gelernt?</p><h3 id="when-should-i-use-long-context-embedding" style="position: relative;"><a href="#when-should-i-use-long-context-embedding" title="Wann sollte ich Long-Context Embedding verwenden?" id="anchor-when-should-i-use-long-context-embedding"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Wann sollte ich Long-Context Embedding verwenden?</h3><p>Im Allgemeinen schadet es der Retrieval-Genauigkeit nicht, so viel Text wie möglich aus Ihren Dokumenten als Input für Ihr Embedding-Modell zu verwenden. Allerdings konzentrieren sich Long-Context Embedding-Modelle oft auf den Anfang von Dokumenten, da diese Inhalte wie Titel und Einleitung enthalten, die für die Beurteilung der Relevanz wichtiger sind, aber die Modelle könnten Inhalte in der Mitte des Dokuments übersehen.</p><h3 id="when-should-i-use-naive-chunking" style="position: relative;"><a href="#when-should-i-use-naive-chunking" title="Wann sollte ich naives Chunking verwenden?" id="anchor-when-should-i-use-naive-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Wann sollte ich naives Chunking verwenden?</h3><p>Wenn Dokumente mehrere Aspekte abdecken oder Benutzeranfragen auf spezifische Informationen innerhalb eines Dokuments abzielen, verbessert Chunking im Allgemeinen die Retrieval-Leistung.</p><p>Letztendlich hängen Segmentierungsentscheidungen von Faktoren ab wie der Notwendigkeit, Teiltext für Benutzer anzuzeigen (z.B. wie Google die relevanten Passagen in den Vorschauen der Suchergebnisse präsentiert), was Segmentierung unerlässlich macht, oder Einschränkungen bei Rechenleistung und Speicher, wo Segmentierung aufgrund erhöhten Retrieval-Overheads und Ressourcenverbrauchs weniger vorteilhaft sein kann.</p><h3 id="when-should-i-use-late-chunking" style="position: relative;"><a href="#when-should-i-use-late-chunking" title="Wann sollte ich Late Chunking verwenden?" id="anchor-when-should-i-use-late-chunking"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Wann sollte ich Late Chunking verwenden?</h3><p>Durch das Encodieren des vollständigen Dokuments vor der Erstellung von Chunks löst Late Chunking das Problem, dass Textsegmente durch fehlenden Kontext ihre Bedeutung verlieren. Dies funktioniert besonders gut bei kohärenten Dokumenten, bei denen jeder Teil mit dem Ganzen zusammenhängt. Unsere Experimente zeigen, dass Late Chunking besonders effektiv ist, wenn Text in kleinere Chunks unterteilt wird, wie in unserem <a href="https://arxiv.org/abs/2409.04701">Paper</a> demonstriert. Es gibt jedoch einen Vorbehalt: Wenn Teile des Dokuments nicht miteinander zusammenhängen, kann das Einbeziehen dieses breiteren Kontexts die Retrieval-Leistung tatsächlich verschlechtern, da es Rauschen zu den Embeddings hinzufügt.</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="Fazit" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Fazit</h2><p>Die Wahl zwischen Long-Context Embedding, naivem Chunking und Late Chunking hängt von den spezifischen Anforderungen Ihrer Retrieval-Aufgabe ab. Long-Context Embeddings sind wertvoll für kohärente Dokumente mit allgemeinen Anfragen, während Chunking in Fällen excellt, in denen Benutzer nach spezifischen Fakten oder Informationen innerhalb eines Dokuments suchen. Late Chunking verbessert das Retrieval weiter, indem es die kontextuelle Kohärenz innerhalb kleinerer Segmente beibehält. Letztendlich wird das Verständnis Ihrer Daten und Retrieval-Ziele den optimalen Ansatz bestimmen, der Genauigkeit, Effizienz und kontextuelle Relevanz ausbalanciert.</p><p>Wenn Sie diese Strategien erkunden, erwägen Sie <code>jina-embeddings-v3</code> auszuprobieren—seine fortgeschrittenen Long-Context-Fähigkeiten, Late Chunking und Flexibilität machen es zu einer ausgezeichneten Wahl für verschiedene Retrieval-Szenarien.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina Embeddings v3: A Frontier Multilingual Embedding Model</div><div class="kg-bookmark-description">jina-embeddings-v3 ist ein Frontier multilinguales Text-Embedding-Modell mit 570M Parametern und 8192 Token-Länge, das die neuesten proprietären Embeddings von OpenAI und Cohere bei MTEB übertrifft.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina-ai-gmbh.ghost.io/content/images/icon/favicon-128x128-15.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">Jina AI</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/thumbnail/v3banner-5.png" alt="" onerror="this.style.display = 'none'" style="cursor: help;"></div></a></figure></section></article><div data-v-a34f4c1e="" class="row justify-between items-center q-py-md"><div data-v-a34f4c1e=""><span data-v-a34f4c1e="" class="text-weight-bold">Kategorien:</span><span data-v-a34f4c1e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">Tech-Blog</div></div></div></span></div><div data-v-a34f4c1e=""><div data-v-a34f4c1e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-a34f4c1e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-a34f4c1e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-a34f4c1e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-a34f4c1e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-a34f4c1e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-a34f4c1e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-a34f4c1e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-a34f4c1e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-a34f4c1e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fde%2Fnews%2Fstill-need-chunking-when-long-context-models-can-do-it-all%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-a34f4c1e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-a34f4c1e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-a34f4c1e="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-a34f4c1e="" class="text-h5 q-my-xl">Weiterlesen</div><a data-v-aa7e154f="" data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/scaling-test-time-compute-for-embedding-models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa7e154f="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa7e154f="" class="q-focus-helper"></span><div data-v-aa7e154f="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa7e154f="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption">Dezember 12, 2024 • 11 Minuten gelesen</div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa7e154f="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Scaling Test-Time Compute For Embedding Models</div><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption text-dim" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Better results scale with compute—more on learning, more on search. A good pretrained model takes you far, but test-time compute takes you further. It's important to recognize this new paradigm of scaling test-time compute, even for embedding models.</div></div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa7e154f="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa7e154f="" class="col-4 overflow-hidden"><div data-v-aa7e154f="" class="q-img q-img--menu hoverOnImage full-height" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/12/test-time-compute.jpg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa7e154f="" data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/watermarking-text-with-embedding-models-to-protect-against-content-theft"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa7e154f="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa7e154f="" class="q-focus-helper"></span><div data-v-aa7e154f="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa7e154f="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption">November 27, 2024 • 10 Minuten gelesen</div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa7e154f="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Watermarking Text with Embedding Models to Protect Against Content Theft</div><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption text-dim" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">You use our embedding models to do what? This might be the most "out-of-domain" applications of embeddings we learned at EMNLP 2024.</div></div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa7e154f="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa7e154f="" class="col-4 overflow-hidden"><div data-v-aa7e154f="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Two hands, each holding a key positioned to interact with each other, depicted against a deep blue background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/banner--1-.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa7e154f="" data-v-a34f4c1e="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/meta-prompt-for-better-jina-api-integration-and-codegen"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa7e154f="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa7e154f="" class="q-focus-helper"></span><div data-v-aa7e154f="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa7e154f="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption">November 19, 2024 • 9 Minuten gelesen</div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa7e154f="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa7e154f="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Meta-Prompt for Better Jina API Integration and CodeGen</div><div data-v-aa7e154f="" class="q-item__label q-item__label--caption text-caption text-dim" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Is Meta-Prompt the new norm for API specs? Feed it to LLMs and generate integration code that reliably integrates Jina's APIs, saving you from the usual trial-and-error process.</div></div></div><div data-v-aa7e154f="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa7e154f="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa7e154f="" class="col-4 overflow-hidden"><div data-v-aa7e154f="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Digital transformation icons with arrows on a teal background indicate file conversion, with contrasting blue and grey accent"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Digital transformation icons with arrows on a teal background indicate file conversion, with contrasting blue and grey accent" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/11/Heading--58-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Büros</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Sunnyvale, Kalifornien</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, Sunnyvale, CA 94085, USA</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Berlin, Deutschland (Hauptsitz)</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 Berlin, Deutschland</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Peking, China</div><div class="q-item__label q-item__label--caption text-caption text-dim">Ebene 5, Gebäude 6, Nr. 48 Haidian West St. Peking, China</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">Shenzhen, China</div><div class="q-item__label q-item__label--caption text-caption text-dim">402 Etage 4, Fu'an Technology Building, Shenzhen, China</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Stiftung durchsuchen</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Einbettungen</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Reranker</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Leser</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Klassifikator</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Segmentierer</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Holen Sie sich den Jina AI API-Schlüssel</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Ratenbegrenzung</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">API-Status</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Unternehmen</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Über uns</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Kontaktieren Sie unseren Vertrieb</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Pressemitteilungen</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Praktikantenprogramm</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://career.jina.ai/" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Begleiten Sie uns</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Logo herunterladen</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">Bedingungen</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/COMMERCIAL-LICENSE-TERMS.pdf" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Kommerzielle Lizenz</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#security"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Sicherheit</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Terms &amp; amp; Bedingungen</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Privatsphäre</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">Cookie-Einstellungen</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-between q-gutter-x-sm col-12 col-md"><label class="q-field row no-wrap items-start q-field--outlined q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dense q-field--dark text-caption" for="f_3c298b1e-19e7-4f52-897a-792abb00bcb6"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__prepend q-field__marginal row no-wrap items-center"><i class="q-icon text-white notranslate material-symbols material-symbols-sharp q-px-sm q-py-none" aria-hidden="true" role="presentation" style="font-size: 18px;">language</i></div><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_3c298b1e-19e7-4f52-897a-792abb00bcb6" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_3c298b1e-19e7-4f52-897a-792abb00bcb6_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">arrow_drop_down</i></div></div></div></label><div class="text-caption text-dim"> Jina AI © 2020-2024. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>