<!DOCTYPE html><html translate="no" dir="ltr" lang="zh-TW"><head><title>什麼是 ColBERT 和晚期交互？為什麼它們在搜尋中如此重要？</title><meta charset="utf-8"><meta name="title" content="什麼是 ColBERT 和晚期交互？為什麼它們在搜尋中如此重要？"><meta name="description" content="Jina AI 在 Hugging Face 上推出的 ColBERT 在 Twitter 上引起熱議，其 8192 token 的處理能力為搜尋領域帶來了新視角。本文將深入解析 ColBERT 和 ColBERTv2 的細節，展示其創新設計，以及為何其後期交互特性在搜尋領域中具有革命性的意義。"><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search"><meta property="og:title" content="什麼是 ColBERT 和晚期交互？為什麼它們在搜尋中如此重要？"><meta property="og:description" content="Jina AI 在 Hugging Face 上推出的 ColBERT 在 Twitter 上引起熱議，其 8192 token 的處理能力為搜尋領域帶來了新視角。本文將深入解析 ColBERT 和 ColBERTv2 的細節，展示其創新設計，以及為何其後期交互特性在搜尋領域中具有革命性的意義。"><meta property="og:image" content="https://jina.ai/blog-banner/what-is-colbert-and-late-interaction-and-why-they-matter-in-search.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search"><meta property="twitter:title" content="什麼是 ColBERT 和晚期交互？為什麼它們在搜尋中如此重要？"><meta property="twitter:description" content="Jina AI 在 Hugging Face 上推出的 ColBERT 在 Twitter 上引起熱議，其 8192 token 的處理能力為搜尋領域帶來了新視角。本文將深入解析 ColBERT 和 ColBERTv2 的細節，展示其創新設計，以及為何其後期交互特性在搜尋領域中具有革命性的意義。"><meta property="twitter:image" content="https://jina.ai/blog-banner/what-is-colbert-and-late-interaction-and-why-they-matter-in-search.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-D_Ioe145.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-Db0tgwFK.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-inkUd1fp.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-xxHK_0G0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-Da5t9HZl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-D9AJN3KD.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-COY4ACF4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-TMYP3CGc.js"><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="modulepreload" as="script" crossorigin="" href="/assets/zh-tw-Dz4le2qD.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-CWc7L0_w.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CFo5SSIl.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-huIFMdNU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-Dw4jaN-p.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-CAFaRMJ-.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-Ph0hWQ1L.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-9AqdXbw4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-iJLIWSW9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-B1e7e3Rw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-CGLaScgZ.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-_QHXpgTL.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-BN5S_4qr.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-iJ_okon9.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-C_lVGESw.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-DLBEJJVj.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-CcazK-Gh.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-QZkai4-A.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-CRxnQCOj.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-DVL_Bysw.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-CzCC3jU4.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-D9TYT-si.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-DMqiS3LT.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-B_CyKxBv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-D0nedeSp.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-BoRoFRaY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-BXs22VHU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-BitP1xlE.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-DQeQ6gHb.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-aJyCHCgh.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-CacHDkLh.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Han Xiao"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Han Xiao"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="16 mins read"><meta property="article:published_time" content="2024-02-20T02:19:04.000+01:00"><meta property="article:modified_time" content="2024-08-30T23:11:22.000+02:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "什麼是 ColBERT 和晚期交互？為什麼它們在搜尋中如此重要？",
  "description": "Jina AI 在 Hugging Face 上推出的 ColBERT 在 Twitter 上引起熱議，其 8192 token 的處理能力為搜尋領域帶來了新視角。本文將深入解析 ColBERT 和 ColBERTv2 的細節，展示其創新設計，以及為何其後期交互特性在搜尋領域中具有革命性的意義。",
  "image": [
    "https://jina.ai/blog-banner/what-is-colbert-and-late-interaction-and-why-they-matter-in-search.webp"
  ],
  "datePublished": "2024-02-20T02:19:04.000+01:00",
  "dateModified": "2024-08-30T23:11:22.000+02:00",
  "author": [
    {
      "@type": "Person",
      "name": "Han Xiao",
      "url": "https://jina-ai-gmbh.ghost.io/author/han/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script charset="utf-8" src="https://platform.twitter.com/js/tweet.d7aeb21a88e025d2ea5f5431a103f586.js"></script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div class="q-space"></div><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">新聞</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">模型</div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_a4153c98-1deb-43f8-a190-15e76851ddf9" aria-label="展開&quot;產品&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">產品</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_a4153c98-1deb-43f8-a190-15e76851ddf9" style="display: none;"><div class="q-list q-list--dark" role="list" label="產品"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">深度搜索</div><div class="q-item__label q-item__label--caption text-caption">搜索、閲讀並推理直到找到最佳答案。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">讀取器</div><div class="q-item__label q-item__label--caption text-caption">閲讀URL或搜索為大模型提供更好的依據。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">向量模型</div><div class="q-item__label q-item__label--caption text-caption">世界一流的多模態多語言向量模型。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">重排器</div><div class="q-item__label q-item__label--caption text-caption">世界一流的神經檢索器，可最大限度地提高搜索相關性。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">分類器</div><div class="q-item__label q-item__label--caption text-caption">圖像和文本的零樣本和少樣本分類。</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">切分器</div><div class="q-item__label q-item__label--caption text-caption">將長文本切分成塊或詞元。</div></div></a><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">API 文檔</div><div class="q-item__label q-item__label--caption text-caption">為您的AI 編程助手 IDE 或大模型自動生成代碼</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_c6b34d8f-15cd-4e2e-8c4f-c0633aeda3e1" aria-label="展開&quot;公司&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">公司</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_c6b34d8f-15cd-4e2e-8c4f-c0633aeda3e1" style="display: none;"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">關於我們</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">聯繫銷售</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">實習生計劃</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">加入我們</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">下載Logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">條款及條件</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="登錄"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">登錄</div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_57e26c3d-faa8-41b2-a929-0c49430fd54d"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_57e26c3d-faa8-41b2-a929-0c49430fd54d" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_57e26c3d-faa8-41b2-a929-0c49430fd54d_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div class="q-page-container" style="padding-top: 56px;"><main data-v-2341133f="" class="q-page" style="min-height: 100vh;"><div data-v-2341133f="" class="row full-width relative-position justify-end"><div data-v-2341133f="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-2341133f="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">什麼是 ColBERT？</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">理解 ColBERT 的設計</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">ColBERT 中的查詢和文件編碼器</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">使用 ColBERT 尋找前 K 個文件</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">ColBERT 的索引策略</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">ColBERT 的效能和效率</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">使用 jina-colbert-v1-en：一個 8192 長度的 ColBERTv2 模型</div></div></div><div data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-2341133f="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-2341133f="" class="q-item__label">結論</div></div></div></div></div><div data-v-2341133f="" class="col-12 col-md-10 col-lg-12"><div data-v-2341133f="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">甄選</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">技術文章</div></div></div></div><div data-v-2341133f="" class="row justify-center"><div data-v-2341133f="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-2341133f="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">二月 20, 2024</div><h1 data-v-2341133f="" class="text-weight-medium text-center q-px-md my-title">什麼是 ColBERT 和晚期交互？為什麼它們在搜尋中如此重要？</h1><div data-v-2341133f="" class="col row justify-center"><div data-v-2341133f="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">Jina AI 在 Hugging Face 上推出的 ColBERT 在 Twitter 上引起熱議，其 8192 token 的處理能力為搜尋領域帶來了新視角。本文將深入解析 ColBERT 和 ColBERTv2 的細節，展示其創新設計，以及為何其後期交互特性在搜尋領域中具有革命性的意義。</div></div><div data-v-2341133f="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-2341133f="" class="q-img q-img--menu" role="img" aria-label="Neon theater or concert hall marquee letters lit up at night with city lights and faint &quot;Adobe Sto&quot; visible."><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Neon theater or concert hall marquee letters lit up at night with city lights and faint &quot;Adobe Sto&quot; visible." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/Untitled-design--28-.png" style="object-fit: contain; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-2341133f="" class="row justify-center"><div data-v-2341133f="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-2341133f="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-2341133f="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-2341133f="" class="q-item__label">Han Xiao • 16 分鐘的閲讀量</div></div></div></div><div data-v-2341133f="" class="row justify-center"><div data-v-2341133f="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-2341133f="" class="article"><section data-v-2341133f="" class="gh-content"><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://jina.ai/news/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Jina ColBERT v2：用於嵌入和重排序的多語言後期互動檢索器</div><div class="kg-bookmark-description">Jina ColBERT v2 支援 89 種語言，具有卓越的檢索性能、用戶可控的輸出維度，以及 8192 的 token 長度。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/08/colbert-banner.jpg" alt="" style="cursor: help;"></div></a><figcaption><p dir="ltr"><span style="white-space: pre-wrap;">更新：在 2024 年 8 月 31 日，我們發布了 Jina-ColBERT 的第二個版本，改進了性能，支援 89 種語言，並具有靈活的輸出維度。請查看發布文章了解更多詳情。</span></p></figcaption></figure><p>上週五，Jina AI 在 Hugging Face 上發布的 <a href="https://huggingface.co/jinaai/jina-colbert-v1-en">ColBERT model</a> 在 AI 社群中引起了極大的關注，特別是在 Twitter/X 上。雖然許多人都熟悉突破性的 BERT 模型，但 ColBERT 引發的熱議讓一些人感到疑惑：在擁擠的資訊檢索技術領域中，是什麼讓 ColBERT 脫穎而出？為什麼 AI 社群對 8192 長度的 ColBERT 如此興奮？本文將深入探討 ColBERT 和 ColBERTv2 的細節，強調其設計、改進以及 ColBERT 後期互動的驚人效能。</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://jina.ai/reranker"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Reranker API</div><div class="kg-bookmark-description">輕鬆提高搜索相關性和 RAG 準確性</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://jina.ai/icons/favicon-128x128.png" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://jina.ai/banner-reranker-api.png" alt="" style="cursor: help;"></div></a></figure><figure class="kg-card kg-embed-card"><div class="twitter-tweet twitter-tweet-rendered" style="display: flex; max-width: 550px; width: 100%; margin-top: 10px; margin-bottom: 10px;"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="" style="position: static; visibility: visible; width: 550px; height: 671px; display: block; flex-grow: 1;" title="X Post" src="https://platform.twitter.com/embed/Tweet.html?creatorScreenName=JinaAI_&amp;dnt=false&amp;embedId=twitter-widget-0&amp;features=eyJ0ZndfdGltZWxpbmVfbGlzdCI6eyJidWNrZXQiOltdLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2ZvbGxvd2VyX2NvdW50X3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9iYWNrZW5kIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19yZWZzcmNfc2Vzc2lvbiI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfZm9zbnJfc29mdF9pbnRlcnZlbnRpb25zX2VuYWJsZWQiOnsiYnVja2V0Ijoib24iLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X21peGVkX21lZGlhXzE1ODk3Ijp7ImJ1Y2tldCI6InRyZWF0bWVudCIsInZlcnNpb24iOm51bGx9LCJ0ZndfZXhwZXJpbWVudHNfY29va2llX2V4cGlyYXRpb24iOnsiYnVja2V0IjoxMjA5NjAwLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3Nob3dfYmlyZHdhdGNoX3Bpdm90c19lbmFibGVkIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19kdXBsaWNhdGVfc2NyaWJlc190b19zZXR0aW5ncyI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfdXNlX3Byb2ZpbGVfaW1hZ2Vfc2hhcGVfZW5hYmxlZCI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfdmlkZW9faGxzX2R5bmFtaWNfbWFuaWZlc3RzXzE1MDgyIjp7ImJ1Y2tldCI6InRydWVfYml0cmF0ZSIsInZlcnNpb24iOm51bGx9LCJ0ZndfbGVnYWN5X3RpbWVsaW5lX3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9mcm9udGVuZCI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9fQ%3D%3D&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=1758503072999907825&amp;lang=zh-tw&amp;origin=http%3A%2F%2F127.0.0.1%3A3000%2Fzh-TW%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F&amp;sessionId=3741a04d1c3d720edf0125cee936352c0576f947&amp;siteScreenName=JinaAI_&amp;theme=light&amp;widgetsVersion=2615f7e52b7e0%3A1702314776716&amp;width=550px" data-tweet-id="1758503072999907825"></iframe></div>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><h2 id="what-is-colbert" style="position: relative;"><a href="#what-is-colbert" title="什麼是 ColBERT？" id="anchor-what-is-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>什麼是 ColBERT？</h2><p>"ColBERT" 代表 <strong>Co</strong>ntextualized <strong>L</strong>ate Interaction over <strong>BERT</strong>，這是一個源自史丹佛大學的模型，它利用了 BERT 的深度語言理解能力，同時引入了一種新穎的互動機制。這種被稱為<strong>後期互動</strong>的機制，通過在檢索過程的最後階段之前分別處理查詢和文件，實現了高效且精確的檢索。具體來說，該模型有兩個版本：</p><ul><li><strong>ColBERT</strong>：初始模型是 <a href="https://x.com/lateinteraction?s=20"><strong>Omar Khattab</strong></a><strong> 和 Matei Zaharia</strong> 的心血結晶，通過論文"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT"提出了一種全新的資訊檢索方法。他們的研究成果發表於 SIGIR 2020。</li></ul><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2004.12832"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ColBERT：通過 BERT 上下文化後期互動實現高效且有效的段落搜索</div><div class="kg-bookmark-description">自然語言理解（NLU）的最新進展正在推動資訊檢索（IR）的快速發展，這主要歸功於對深度語言模型（LMs）在文檔排序方面的微調。雖然這些基於 LMs 的排序模型非常有效，但它們將計算成本提高了數個數量級，特別是因為它們必須將每個查詢-文檔對通過一個龐大的神經網絡來計算單個相關性分數。為了解決這個問題，我們提出了 ColBERT，這是一個為高效檢索而改編深度 LMs（特別是 BERT）的新型排序模型。ColBERT 引入了一種後期互動架構，它使用 BERT 獨立編碼查詢和文檔，然後使用一個廉價但強大的互動步驟來模擬它們的細粒度相似性。通過延遲但保留這種細粒度互動，ColBERT 可以利用深度 LMs 的表達能力，同時獲得離線預計算文檔表示的能力，大大加快了查詢處理速度。除了降低重新排序傳統模型檢索文檔的成本外，ColBERT 的剪枝友好互動機制還能夠直接從大型文檔集合中利用向量相似性索引進行端到端檢索。我們使用兩個最新的段落搜索數據集對 ColBERT 進行了廣泛評估。結果表明，ColBERT 的效果與現有的基於 BERT 的模型相當（並且優於每個非 BERT 基準），同時執行速度快兩個數量級，每次查詢所需的 FLOPs 減少四個數量級。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Omar Khattab</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a><figcaption><p><span style="white-space: pre-wrap;">介紹"後期互動"的原始 ColBERT 論文。</span></p></figcaption></figure><ul><li><strong>ColBERTv2</strong>：在原有工作的基礎上，<strong>Omar Khattab</strong> 繼續他的研究，與 <strong>Barlas Oguz、Matei Zaharia 和 Michael S. Bernstein</strong> 合作，在 SIGIR 2021 上發表了"ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction"。ColBERT 的這次迭代解決了之前的限制，並引入了關鍵改進，如<strong>去噪監督</strong>和<strong>殘差壓縮</strong>，提升了模型的檢索效能和存儲效率。</li></ul><figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://arxiv.org/abs/2112.01488"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ColBERTv2：通過輕量級後期互動實現有效且高效的檢索</div><div class="kg-bookmark-description">神經資訊檢索（IR）極大地改進了搜索和其他知識密集型語言任務。雖然許多神經 IR 方法將查詢和文檔編碼為單向量表示，但後期互動模型在每個 token 的粒度上產生多向量表示，並將相關性建模分解為可擴展的 token 級計算。這種分解已被證明使後期互動更有效，但它將這些模型的空間占用增加了一個數量級。在本工作中，我們引入了 ColBERTv2，這是一個將積極的殘差壓縮機制與去噪監督策略相結合的檢索器，同時改進了後期互動的質量和空間占用。我們在廣泛的基準測試中評估了 ColBERTv2，在訓練域內外建立了最先進的質量，同時將後期互動模型的空間占用減少了 6-10 倍。</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png" alt="" style="cursor: help;"><span class="kg-bookmark-author">arXiv.org</span><span class="kg-bookmark-publisher">Keshav Santhanam</span></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt="" style="cursor: help;"></div></a><figcaption><p><span style="white-space: pre-wrap;">ColBERTv2 添加去噪監督和殘差壓縮來改善訓練數據質量並減少空間占用。</span></p></figcaption></figure><h2 id="understand-colberts-design" style="position: relative;"><a href="#understand-colberts-design" title="理解 ColBERT 的設計" id="anchor-understand-colberts-design"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>理解 ColBERT 的設計</h2><p>鑑於 ColBERTv2 的架構與原始 ColBERT 非常相似，其主要創新主要圍繞訓練技術和壓縮機制，我們首先將深入探討原始 ColBERT 的基礎方面。</p><h3 id="what-is-late-interaction-in-colbert" style="position: relative;"><a href="#what-is-late-interaction-in-colbert" title="什麼是 ColBERT 中的後期互動？" id="anchor-what-is-late-interaction-in-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>什麼是 ColBERT 中的後期互動？</h3><p>"互動"指的是通過比較查詢和文檔的表示來評估它們之間相關性的過程。</p><p>"<em>後期互動</em>"是 ColBERT 的精髓。這個術語源自模型的架構和處理策略，其中查詢和文檔表示的互動發生在處理過程的後期，在兩者都被獨立編碼之後。這與"<em>早期互動</em>"模型形成對比，在早期互動模型中，查詢和文檔嵌入在較早階段就開始互動，通常是在模型編碼之前或期間。</p>

<table>
<thead>
<tr>
<th>Interaction Type</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Early Interaction</td>
<td>BERT, ANCE, DPR, Sentence-BERT, DRMM, KNRM, Conv-KNRM, etc.</td>
</tr>
<tr>
<td>Late Interaction</td>
<td>ColBERT, ColBERTv2</td>
</tr>
</tbody>
</table>

<p>早期互動可能會增加計算複雜性，因為它需要考慮所有可能的查詢-文檔對，這使得它在大規模應用中效率較低。</p><p>像 ColBERT 這樣的後期互動模型通過允許預先計算文檔表示並在最後採用更輕量級的互動步驟來優化效率和可擴展性，這種互動步驟專注於已編碼的表示。這種設計選擇能夠實現更快的檢索時間和更低的計算需求，使其更適合處理大型文檔集合。</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/colbert-blog-interaction.svg" class="kg-image" alt="Diagram illustrating query-document similarity with models for no, partial, and late interaction, including language mode rep" width="300" height="143" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">神經 IR 中查詢與文件交互範式的示意圖，最左側為 ColBERT 的後期交互方式。</span></figcaption></figure><h3 id="no-interaction-cosine-similarity-of-document-and-query-embeddings" style="position: relative;"><a href="#no-interaction-cosine-similarity-of-document-and-query-embeddings" title="無交互：文件和查詢嵌入的餘弦相似度" id="anchor-no-interaction-cosine-similarity-of-document-and-query-embeddings"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>無交互：文件和查詢嵌入的餘弦相似度</h3><p>許多實用的向量資料庫和神經搜尋解決方案都依賴於文件和查詢嵌入之間的快速餘弦相似度匹配。雖然這種被稱為「無交互」或「非交互式」的方法在直觀性和計算效率方面很有吸引力，但與那些包含某種形式的查詢和文件交互的模型相比，其表現被發現較為遜色。</p><p>「無交互」方法的核心限制在於其無法捕捉查詢和文件詞彙之間的複雜細微差別和關係。信息檢索的本質是理解並匹配查詢背後的意圖與文件中的內容。這個過程通常需要對相關詞彙進行深入的、上下文相關的理解，而單一的、聚合的文件和查詢嵌入很難提供這種理解。</p><h2 id="query-and-document-encoders-in-colbert" style="position: relative;"><a href="#query-and-document-encoders-in-colbert" title="ColBERT 中的查詢和文件編碼器" id="anchor-query-and-document-encoders-in-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT 中的查詢和文件編碼器</h2><p>ColBERT 的編碼策略建立在以深度上下文語言理解著稱的 BERT 模型基礎上。該模型為查詢或文件中的每個詞元生成密集向量表示，<strong>分別為查詢和文件創建上下文化嵌入的集合。</strong>這促進了在後期交互階段對其嵌入進行細緻的比較。</p><h3 id="query-encoder-of-colbert" style="position: relative;"><a href="#query-encoder-of-colbert" title="ColBERT 的查詢編碼器" id="anchor-query-encoder-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT 的查詢編碼器</h3><p>對於包含詞元 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>q</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">{q_1, q_2, ..., q_l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span> 的查詢 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>，處理過程首先將 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span> 分詞為基於 BERT 的 WordPiece 詞元，並在前面加上特殊的 <code>[Q]</code> 詞元。這個 <code>[Q]</code> 詞元位於 BERT 的 <code>[CLS]</code> 詞元之後，用於標示查詢的開始。</p><p>如果查詢長度短於預定義的詞元數 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，則用 <code>[mask]</code> 詞元填充至 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>；否則截斷至前 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 個詞元。填充後的序列經過 BERT，然後是 CNN（卷積神經網絡）和正規化。輸出是一組嵌入向量，表示如下 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9722em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>：<br><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>q</mi></msub><mo>:</mo><mo>=</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">z</mi><mi mathvariant="normal">e</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo fence="true">(</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">Q</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>q</mi><mi>l</mi></msub><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">m</mi><mi mathvariant="monospace">a</mi><mi mathvariant="monospace">s</mi><mi mathvariant="monospace">k</mi><mo stretchy="false">]</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_q := \mathrm{Normalize}\left(\mathrm{BERT}\left(\mathtt{[Q]},q_0,q_1,\ldots,q_l\mathtt{[mask]},\mathtt{[mask]},\ldots,\mathtt{[mask]}\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9722em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">Normalize</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">BERT</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">Q</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">mask</span><span class="mclose">]</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span></p><h3 id="document-encoder-of-colbert" style="position: relative;"><a href="#document-encoder-of-colbert" title="ColBERT 的文件編碼器" id="anchor-document-encoder-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT 的文件編碼器</h3><p>同樣，對於包含詞元 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>d</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{d_1, d_2, ..., d_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span> 的文件 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span></span></span></span></span>，在前面加上 <code>[D]</code> 詞元以標示文件的開始。這個序列無需填充，經過相同的處理過程，得到一組嵌入向量，表示如下 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8361em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>：<br><span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">E</mi><mi>d</mi></msub><mo>:</mo><mo>=</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">z</mi><mi mathvariant="normal">e</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo fence="true">(</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="monospace">D</mi><mo stretchy="false">]</mo></mrow><mo separator="true">,</mo><msub><mi>d</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>d</mi><mi>n</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_d := \mathrm{Filter}\left(\mathrm{Normalize}\left(\mathrm{BERT}\left(\mathtt{[D]},d_0,d_1,...,d_n\right)\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8361em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">Filter</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">Normalize</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathrm">BERT</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mopen">[</span><span class="mord mathtt">D</span><span class="mclose">]</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span></p><p>使用 <code>[mask]</code> 詞元填充查詢（在論文中稱為<strong>查詢增強</strong>）確保了所有查詢的長度統一，便於批次處理。<code>[Q]</code> 和 <code>[D]</code> 詞元明確標記查詢和文件的開始，幫助模型區分這兩種輸入。</p><h3 id="comparing-colbert-to-cross-encoders" style="position: relative;"><a href="#comparing-colbert-to-cross-encoders" title="比較 ColBERT 與交叉編碼器" id="anchor-comparing-colbert-to-cross-encoders"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>比較 ColBERT 與交叉編碼器</h3><p>交叉編碼器同時處理查詢和文件對，使其具有高準確性，但由於評估每個可能的配對的計算成本，在大規模任務中效率較低。它們在需要精確評分句子對的特定場景中表現出色，如語意相似度任務或詳細內容比較。然而，這種設計限制了它們在需要從大型數據集快速檢索的情況下的應用，這些情況需要預計算嵌入和高效的相似度計算。</p><figure class="kg-card kg-image-card"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/02/ce-vs-colbert.svg" class="kg-image" alt="Diagrams comparing &quot;Cross Encoder: Early all-to-all interaction&quot; and &quot;ColBERT: Late interaction&quot; with labeled Query and Docum" width="210" height="150" style="cursor: help;"></figure><p>相比之下，ColBERT 的後期交互模型允許預計算文件嵌入，大大加快了檢索過程，同時不影響語意分析的深度。這種方法雖然與交叉編碼器的直接方法相比似乎不夠直觀，但為即時和大規模信息檢索任務提供了可擴展的解決方案。它代表了計算效率和交互建模質量之間的策略性妥協。</p><h2 id="finding-the-top-k-documents-using-colbert" style="position: relative;"><a href="#finding-the-top-k-documents-using-colbert" title="使用 ColBERT 尋找前 K 個文件" id="anchor-finding-the-top-k-documents-using-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>使用 ColBERT 尋找前 K 個文件</h2><p>一旦我們得到查詢和文件的嵌入，找到最相關的前 K 個文件就變得直接了（但不像計算兩個向量的餘弦那麼直接）。</p><p>關鍵操作包括批量點積以計算詞元間相似度，在文件詞元中進行最大池化以找到每個查詢詞元的最高相似度，然後對查詢詞元進行求和得到總文件分數，最後根據這些分數對文件進行排序。偽 PyTorch 代碼如下：</p><pre class="hljs-copy-wrapper"><code class="language-python hljs"><span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_relevance_scores</span>(<span class="hljs-params">query_embeddings, document_embeddings, k</span>):
    <span class="hljs-string">"""
    Compute relevance scores for top-k documents given a query.
    
    :param query_embeddings: Tensor representing the query embeddings, shape: [num_query_terms, embedding_dim]
    :param document_embeddings: Tensor representing embeddings for k documents, shape: [k, max_doc_length, embedding_dim]
    :param k: Number of top documents to re-rank
    :return: Sorted document indices based on their relevance scores
    """</span>
    
    <span class="hljs-comment"># Ensure document_embeddings is a 3D tensor: [k, max_doc_length, embedding_dim]</span>
    <span class="hljs-comment"># Pad the k documents to their maximum length for batch operations</span>
    <span class="hljs-comment"># Note: Assuming document_embeddings is already padded and moved to GPU</span>
    
    <span class="hljs-comment"># Compute batch dot-product of Eq (query embeddings) and D (document embeddings)</span>
    <span class="hljs-comment"># Resulting shape: [k, num_query_terms, max_doc_length]</span>
    scores = torch.matmul(query_embeddings.unsqueeze(<span class="hljs-number">0</span>), document_embeddings.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
    
    <span class="hljs-comment"># Apply max-pooling across document terms (dim=2) to find the max similarity per query term</span>
    <span class="hljs-comment"># Shape after max-pool: [k, num_query_terms]</span>
    max_scores_per_query_term = scores.<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">2</span>).values
    
    <span class="hljs-comment"># Sum the scores across query terms to get the total score for each document</span>
    <span class="hljs-comment"># Shape after sum: [k]</span>
    total_scores = max_scores_per_query_term.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>)
    
    <span class="hljs-comment"># Sort the documents based on their total scores</span>
    sorted_indices = total_scores.argsort(descending=<span class="hljs-literal">True</span>)
    
    <span class="hljs-keyword">return</span> sorted_indices
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copy</button></div></pre><p>請注意，這個程序在訓練和推理時的重新排序中都會使用。ColBERT 模型使用成對排序損失進行訓練，其中訓練數據由三元組 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(q, d^+, d^-)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.0213em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 組成，其中 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> 代表查詢，<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">d^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> 是與查詢相關的（正面）文件，<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">d^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span> 是不相關的（負面）文件。模型的目標是學習表示，使得 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> 和 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">d^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> 之間的相似度分數高於 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> 和 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">d^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span> 之間的分數。</p><p>訓練目標可以數學表示為最小化以下損失函數：<span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{Loss} = \max(0, 1 - S(q, d^+) + S(q, d^-))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord"><span class="mord mathrm">Loss</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0713em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8213em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0713em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8213em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span></span></p><p>，其中 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(q, d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></span> 表示 ColBERT 計算的查詢 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span></span></span> 和文件 <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span> 之間的相似度分數。這個分數是通過聚合查詢和文件之間最佳匹配嵌入的最大相似度分數得到的，遵循模型架構中描述的後期交互模式。這種方法確保模型被訓練為能夠區分給定查詢的相關和不相關文件，通過鼓勵正面和負面文件對的相似度分數有更大的差距。</p><h3 id="denoised-supervision-in-colbertv2" style="position: relative;"><a href="#denoised-supervision-in-colbertv2" title="ColBERTv2 中的降噪監督" id="anchor-denoised-supervision-in-colbertv2"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERTv2 中的降噪監督</h3><p>ColBERTv2 中的降噪監督通過選擇具有挑戰性的負面樣本並利用交叉編碼器進行知識蒸餾來改進原始訓練過程。這種優化訓練數據質量的複雜方法包括以下步驟：</p><ol><li><strong>初始訓練</strong>：使用 MS MARCO 數據集的官方三元組，包含查詢、相關文件和不相關文件。</li><li><strong>索引和檢索</strong>：使用 ColBERTv2 的壓縮來索引訓練段落，然後為每個查詢檢索前 k 個段落。</li><li><strong>交叉編碼器重排序</strong>：通過 MiniLM 交叉編碼器的重排序來增強段落選擇，將其分數蒸餾到 ColBERTv2 中。</li><li><strong>形成訓練元組</strong>：生成 w 路元組用於訓練，同時包含高排名和低排名的段落以創建具有挑戰性的範例。</li><li><strong>迭代優化</strong>：重複該過程以持續改進難例選擇，從而提高模型性能。</li></ol><p>請注意，這個過程代表了對 ColBERT 訓練制度的複雜增強，而不是對其架構的根本改變。</p><h3 id="hyperparameters-of-colbert" style="position: relative;"><a href="#hyperparameters-of-colbert" title="ColBERT 的超參數" id="anchor-hyperparameters-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT 的超參數</h3><p>以下是 ColBERT 的超參數總結：</p>

<table>
<thead>
<tr>
<th>超參數</th>
<th>最佳選擇</th>
<th>原因</th>
</tr>
</thead>
<tbody>
<tr>
<td>學習率</td>
<td>3 x 10^{-6}</td>
<td>為確保穩定和有效的模型更新而選用於微調。</td>
</tr>
<tr>
<td>批次大小</td>
<td>32</td>
<td>在計算效率和每次更新獲取足夠資訊量之間取得平衡。</td>
</tr>
<tr>
<td>每個查詢的嵌入數量 (Nq)</td>
<td>32</td>
<td>固定數量以確保查詢間具有一致的表示大小，有助於高效處理。</td>
</tr>
<tr>
<td>嵌入維度 (m)</td>
<td>128</td>
<td>經證實在表示能力和計算效率之間提供良好平衡。</td>
</tr>
<tr>
<td>訓練迭代次數</td>
<td>200k (MS MARCO), 125k (TREC CAR)</td>
<td>根據數據集特性調整，確保充分學習同時避免過擬合。</td>
</tr>
<tr>
<td>每維度嵌入位元組數</td>
<td>4 (重排序), 2 (端到端排序)</td>
<td>在精確度和空間效率之間權衡，並考慮應用場景（重排序 vs. 端到端）。</td>
</tr>
<tr>
<td>向量相似度函數</td>
<td>餘弦 (重排序), (平方) L2 (端到端)</td>
<td>根據各自檢索場景的性能和效率選擇。</td>
</tr>
<tr>
<td>FAISS 索引分區 (P)</td>
<td>2000</td>
<td>決定搜索空間分區的粒度，影響搜索效率。</td>
</tr>
<tr>
<td>搜索最近分區數 (p)</td>
<td>10</td>
<td>在搜索廣度和計算效率之間取得平衡。</td>
</tr>
<tr>
<td>每個嵌入的子向量數 (s)</td>
<td>16</td>
<td>影響量化的粒度，同時影響搜索速度和記憶體使用。</td>
</tr>
<tr>
<td>每維度索引表示</td>
<td>16 位元值</td>
<td>在端到端檢索的第二階段中選用，用於管理準確性和空間的權衡。</td>
</tr>
<tr>
<td>編碼器層數</td>
<td>12 層 BERT</td>
<td>在上下文理解深度和計算效率之間取得最佳平衡。</td>
</tr>
<tr>
<td>最大查詢長度</td>
<td>128</td>
<td>查詢編碼器處理的最大標記數。<b>在 Jina-ColBERT 模型中得到擴展。</b></td>
</tr>
<tr>
<td>最大文件長度</td>
<td>512</td>
<td>文件編碼器處理的最大標記數。<b>在 Jina-ColBERT 模型中擴展至 8192。</b></td>
</tr>
</tbody>
</table>

<h2 id="the-indexing-strategy-of-colbert" style="position: relative;"><a href="#the-indexing-strategy-of-colbert" title="ColBERT 的索引策略" id="anchor-the-indexing-strategy-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT 的索引策略</h2>
<p>與將每個文件編碼為一個嵌入向量的基於表示的方法不同，<strong>ColBERT 將文件（和查詢）編碼為嵌入向量集合，文件中的每個標記都有自己的嵌入。</strong>這種方法本質上意味著對於較長的文件，需要儲存更多的嵌入，<strong>這是原始 ColBERT 的一個痛點，後來在 ColBERTv2 中得到解決。</strong></p>
<p>有效管理這一問題的關鍵在於 ColBERT 使用向量資料庫（如 <a href="https://github.com/facebookresearch/faiss">FAISS</a>）進行索引和檢索，以及其詳細的索引過程，該過程旨在高效處理大量數據。原始 ColBERT 論文提到了幾種提高索引和檢索效率的策略，包括：</p>
<ul>
<li><strong>離線索引</strong>：文件表示在離線計算，允許預先計算和儲存文件嵌入。此過程利用批次處理和 GPU 加速來高效處理大量文件集合。</li>
<li><strong>嵌入儲存</strong>：文件嵌入可以使用 32 位元或 16 位元值來儲存每個維度，在精確度和儲存需求之間提供權衡。這種靈活性使 ColBERT 能夠在效能（檢索性能）和效率（儲存和計算成本）之間保持平衡。</li>
</ul>
<p>在 ColBERTv2 中引入的<strong>殘差壓縮</strong>（在原始 ColBERT 中不存在）技術，通過有效捕捉和儲存與固定參考中心點的差異，在保持品質的同時將模型的空間佔用減少了 6-10 倍，這是一個關鍵突破。</p>
<h2 id="effectiveness-and-efficiency-of-colbert" style="position: relative;"><a href="#effectiveness-and-efficiency-of-colbert" title="ColBERT 的效能和效率" id="anchor-effectiveness-and-efficiency-of-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ColBERT 的效能和效率</h2>
<p>人們可能最初會認為將 BERT 的深度上下文理解整合到搜索中本質上需要大量計算資源，由於高延遲和計算成本，使這種方法在實時應用中較不可行。然而，ColBERT 通過其創新的後期交互機制挑戰並推翻了這一假設。以下是一些值得注意的要點：</p>
<ol>
<li><strong>顯著的效率提升</strong>：與傳統的基於 BERT 的排序模型相比，ColBERT 在計算成本（FLOPs）和延遲方面實現了數量級的減少。具體來說，對於給定的模型大小（如 12 層"基礎"transformer 編碼器），ColBERT 不僅匹配而且在某些情況下超越了 BERT 基礎模型的效能，且計算需求大幅降低。例如，在重排序深度 <em>k</em>=10 時，BERT 需要的 FLOPs 幾乎是 ColBERT 的 180 倍；隨著 <em>k</em> 增加，這個差距進一步擴大，在 <em>k</em>=1000 時達到 13900 倍，在 <em>k</em>=2000 時甚至達到 23000 倍。</li>
<li><strong>端到端檢索中改善的召回率和 MRR@10</strong>：與最初認為查詢和文件表示之間需要更深入的交互（如早期交互模型所見）才能實現高檢索性能的直覺相反，ColBERT 的端到端檢索設置展示了卓越的效能。例如，其 Recall@50 超過了官方 BM25 的 Recall@1000 和幾乎所有其他模型的 Recall@200，突顯了該模型在不直接比較每個查詢-文件對的情況下，從大量集合中檢索相關文件的卓越能力。</li>
<li><strong>實際應用的實用性</strong>：實驗結果突顯了 ColBERT 在實際情境中的應用價值。其索引處理量和記憶體效率使其適合在幾小時內索引如 MS MARCO 這樣的大型文件集合，同時保持高效能和可管理的空間佔用。這些特質突顯了 ColBERT 適合部署在性能和計算效率都至關重要的生產環境中。</li>
<li><strong>文件集合規模的可擴展性</strong>：也許最令人驚訝的結論是 ColBERT 在處理大規模文件集合時的可擴展性和效率。該架構允許預計算文件嵌入，並利用高效的批次處理進行查詢-文件交互，使系統能夠隨著文件集合的大小有效擴展。考慮到有效文件檢索所需的複雜性和理解深度，這種可擴展性是反直覺的，展示了 ColBERT 在平衡計算效率和檢索效能方面的創新方法。</li>
</ol>
<h2 id="using-jina-colbert-v1-en-a-8192-length-colbertv2-model" style="position: relative;"><a href="#using-jina-colbert-v1-en-a-8192-length-colbertv2-model" title="使用 jina-colbert-v1-en：一個 8192 長度的 ColBERTv2 模型" id="anchor-using-jina-colbert-v1-en-a-8192-length-colbertv2-model"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>使用 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a>：一個 8192 長度的 ColBERTv2 模型</h2>
<p>Jina-ColBERT 專為快速和準確的檢索而設計，支援<a href="https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/">最長 8192 的上下文長度，利用 JinaBERT 的進展</a>，由於其架構增強，允許處理更長的序列。</p>
<div class="kg-card kg-callout-card kg-callout-card-blue">
<div class="kg-callout-emoji">💡</div>
<div class="kg-callout-text">嚴格來說，Jina-ColBERT 支援 8190 個標記的長度。回想一下，在 ColBERT 文件編碼器中，每個文件的開頭都會填充 <code spellcheck="false" style="white-space: pre-wrap;">[D],[CLS]</code>。</div>
</div>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/jinaai/jina-colbert-v1-en"><div class="kg-bookmark-content"><div class="kg-bookmark-title">jinaai/jina-colbert-v1-en · Hugging Face</div><div class="kg-bookmark-description">We're on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img loading="lazy" class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="" style="cursor: help;"></div></div><div class="kg-bookmark-thumbnail"><img loading="lazy" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/jinaai/jina-colbert-v1-en.png" alt="" style="cursor: help;"></div></a></figure>
<h3 id="jinas-improvement-over-original-colbert" style="position: relative;"><a href="#jinas-improvement-over-original-colbert" title="Jina 相對於原始 ColBERT 的改進" id="anchor-jinas-improvement-over-original-colbert"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Jina 相對於原始 ColBERT 的改進</h3>
<p>Jina-ColBERT 的主要進展在於其骨幹網路 <code>jina-bert-v2-base-en</code>，它能夠處理顯著更長的上下文（最多 8192 個標記），相比原始使用 <code>bert-base-uncased</code> 的 ColBERT。這種能力對於處理包含大量內容的文件至關重要，能提供更詳細和更具上下文的搜索結果。</p>
<h3 id="jina-colbert-v1-en-performance-comparison-vs-colbertv2" style="position: relative;"><a href="#jina-colbert-v1-en-performance-comparison-vs-colbertv2" title="jina-colbert-v1-en 與 ColBERTv2 的性能比較" id="anchor-jina-colbert-v1-en-performance-comparison-vs-colbertv2"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a><a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a> 與 ColBERTv2 的性能比較</h3>
<p>我們在 BEIR 數據集和偏好長上下文的新 LoCo 基準上評估了 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a>，將其與原始 ColBERTv2 實現和非交互式的<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a> 模型。</p>

<table>
<thead>
<tr>
<th>Dataset</th>
<th>ColBERTv2</th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a></th>
<th><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Arguana</td>
<td>46.5</td>
<td><strong>49.4</strong></td>
<td>44.0</td>
</tr>
<tr>
<td>Climate-Fever</td>
<td>18.1</td>
<td>19.6</td>
<td><strong>23.5</strong></td>
</tr>
<tr>
<td>DBPedia</td>
<td><strong>45.2</strong></td>
<td>41.3</td>
<td>35.1</td>
</tr>
<tr>
<td>FEVER</td>
<td>78.8</td>
<td><strong>79.5</strong></td>
<td>72.3</td>
</tr>
<tr>
<td>FiQA</td>
<td>35.4</td>
<td>36.8</td>
<td><strong>41.6</strong></td>
</tr>
<tr>
<td>HotpotQA</td>
<td><strong>67.5</strong></td>
<td>65.9</td>
<td>61.4</td>
</tr>
<tr>
<td>NFCorpus</td>
<td>33.7</td>
<td><strong>33.8</strong></td>
<td>32.5</td>
</tr>
<tr>
<td>NQ</td>
<td>56.1</td>
<td>54.9</td>
<td><strong>60.4</strong></td>
</tr>
<tr>
<td>Quora</td>
<td>85.5</td>
<td>82.3</td>
<td><strong>88.2</strong></td>
</tr>
<tr>
<td>SCIDOCS</td>
<td>15.4</td>
<td>16.9</td>
<td><strong>19.9</strong></td>
</tr>
<tr>
<td>SciFact</td>
<td>68.9</td>
<td><strong>70.1</strong></td>
<td>66.7</td>
</tr>
<tr>
<td>TREC-COVID</td>
<td>72.6</td>
<td><strong>75.0</strong></td>
<td>65.9</td>
</tr>
<tr>
<td>Webis-touch2020</td>
<td>26.0</td>
<td><strong>27.0</strong></td>
<td>26.2</td>
</tr>
<tr>
<td>LoCo</td>
<td>74.3</td>
<td>83.7</td>
<td><strong>85.4</strong></td>
</tr>
<tr>
<td>Average</td>
<td>51.7</td>
<td><strong>52.6</strong></td>
<td>51.6</td>
</tr>
</tbody>
</table>

<p>此表顯示 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a> 的卓越效能，特別是在需要較長上下文長度的場景相較於原始的 ColBERTv2。請注意，<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a> <a href="https://arxiv.org/abs/2310.19923">使用了更多訓練資料</a>，而 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a> 僅使用 MSMARCO，這可能解釋了 <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v2-base-en" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v2-base-en</span></a> 在某些任務上的良好表現。</p><h3 id="example-usage-of-jina-colbert-v1-en" style="position: relative;"><a href="#example-usage-of-jina-colbert-v1-en" title="使用 jina-colbert-v1-en 的範例" id="anchor-example-usage-of-jina-colbert-v1-en"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>使用 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a> 的範例</h3><p>這個程式碼片段概述了使用 Jina-ColBERT 的索引過程，展示了其對長文件的支援。</p><pre class="hljs-copy-wrapper"><code class="language-python hljs"><span class="hljs-keyword">from</span> colbert <span class="hljs-keyword">import</span> Indexer
<span class="hljs-keyword">from</span> colbert.infra <span class="hljs-keyword">import</span> Run, RunConfig, ColBERTConfig

n_gpu: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>  <span class="hljs-comment"># Set your number of available GPUs</span>
experiment: <span class="hljs-built_in">str</span> = <span class="hljs-string">""</span>  <span class="hljs-comment"># Name of the folder where the logs and created indices will be stored</span>
index_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">""</span>  <span class="hljs-comment"># The name of your index, i.e. the name of your vector database</span>

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-keyword">with</span> Run().context(RunConfig(nranks=n_gpu, experiment=experiment)):
        config = ColBERTConfig(
          doc_maxlen=<span class="hljs-number">8192</span>  <span class="hljs-comment"># Our model supports 8k context length for indexing long documents</span>
        )
        indexer = Indexer(
          checkpoint=<span class="hljs-string">"jinaai/jina-colbert-v1-en"</span>,
          config=config,
        )
        documents = [
          <span class="hljs-string">"ColBERT is an efficient and effective passage retrieval model."</span>,
          <span class="hljs-string">"Jina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length."</span>,
          <span class="hljs-string">"JinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length."</span>,
          <span class="hljs-string">"Jina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2."</span>,
          <span class="hljs-string">"Jina-ColBERT achieves the competitive retrieval performance with ColBERTv2."</span>,
          <span class="hljs-string">"Jina is an easier way to build neural search systems."</span>,
          <span class="hljs-string">"You can use Jina-ColBERT to build neural search systems with ease."</span>,
          <span class="hljs-comment"># Add more documents here to ensure the clustering work correctly</span>
        ]
        indexer.index(name=index_name, collection=documents)
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copy</button></div></pre><h3 id="use-jina-colbert-v1-en-in-ragatouille" style="position: relative;"><a href="#use-jina-colbert-v1-en-in-ragatouille" title="在 RAGatouille 中使用 jina-colbert-v1-en" id="anchor-use-jina-colbert-v1-en-in-ragatouille"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>在 RAGatouille 中使用 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a></h3><p>RAGatouille 是一個新的 Python 函式庫，可以讓在 RAG 流程中使用進階檢索方法變得更容易。它的設計著重於模組化和易於整合，讓使用者能夠無縫地運用最先進的研究成果。RAGatouille 的主要目標是簡化在 RAG 流程中應用像 ColBERT 這樣的複雜模型，讓開發者無需深入了解基礎研究就能利用這些方法。感謝 <a href="https://twitter.com/bclavie">Benjamin Clavié</a>，現在您可以輕鬆使用 <a class="dynamic-model-name" href="/?sui&amp;model=jina-colbert-v1-en" target="_blank"><span class="dynamic-model-name-inner">jina-colbert-v1-en</span></a>：</p><pre class="hljs-copy-wrapper"><code class="language-python hljs"><span class="hljs-keyword">from</span> ragatouille <span class="hljs-keyword">import</span> RAGPretrainedModel

<span class="hljs-comment"># Get your model &amp; collection of big documents ready</span>
RAG = RAGPretrainedModel.from_pretrained(<span class="hljs-string">"jinaai/jina-colbert-v1-en"</span>)
my_documents = [
    <span class="hljs-string">"very long document1"</span>,
    <span class="hljs-string">"very long document2"</span>,
    <span class="hljs-comment"># ... more documents</span>
]

<span class="hljs-comment"># And create an index with them at full length!</span>
RAG.index(collection=my_documents,
          index_name=<span class="hljs-string">"the_biggest_index"</span>,
          max_document_length=<span class="hljs-number">8190</span>,)

<span class="hljs-comment"># or encode them in-memory with no truncation, up to your model's max length</span>
RAG.encode(my_documents)
</code><div class="hljs-copy-container" data-autohide="true" style="--hljs-theme-background:rgba(0, 0, 0, 0); --hljs-theme-color:rgb(204, 204, 204); --hljs-theme-padding:16px;"><button class="hljs-copy-button" data-copied="false">Copy</button></div></pre><p>如需更詳細的資訊和深入了解 Jina-ColBERT，您可以造訪 <a href="https://huggingface.co/jinaai/jina-colbert-v1-en">Hugging Face 頁面</a>。</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="結論" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>結論</h2><p>ColBERT 在資訊檢索領域代表了一個重要的進步。透過 Jina-ColBERT 啟用更長的上下文長度，並保持與 ColBERT 後期互動方法的相容性，為尋求實現最先進搜尋功能的開發者提供了一個強大的選擇。</p><p>結合 RAGatouille 函式庫，它簡化了將複雜檢索模型整合到 RAG 流程中的過程，開發者現在可以輕鬆運用進階檢索的力量，簡化工作流程並增強應用程式。Jina-ColBERT 和 RAGatouille 之間的協同效應，展示了在使進階 AI 搜尋模型變得容易存取和高效率方面的顯著進展。</p></section></article><div data-v-2341133f="" class="row justify-between items-center q-py-md"><div data-v-2341133f=""><span data-v-2341133f="" class="text-weight-bold">類別:</span><span data-v-2341133f="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><i class="q-icon notranslate material-symbols material-symbols-sharp q-chip__icon q-chip__icon--left" aria-hidden="true" role="presentation">star</i><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">甄選</div></div></div><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">技術文章</div></div></div></span></div><div data-v-2341133f=""><div data-v-2341133f="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-2341133f="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fzh-TW%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fzh-TW%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fzh-TW%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fzh-TW%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fzh-TW%2Fnews%2Fwhat-is-colbert-and-late-interaction-and-why-they-matter-in-search%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-2341133f="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div><hr data-v-2341133f="" class="q-separator q-separator--horizontal q-separator--dark q-mt-xl" aria-orientation="horizontal"><div data-v-2341133f="" class="text-h5 q-my-xl">更多新聞</div><a data-v-aa70018b="" data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/a-practical-guide-to-deploying-search-foundation-models-in-production"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">一月 31, 2025 • 14 分鐘的閲讀量</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">A Practical Guide to Deploying Search Foundation Models in Production</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Saahil Ognawala"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Saahil Ognawala" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2023/03/profile-option-2.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Scott Martens"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Scott Martens" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/11/photo-of-me-cropped.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Abstract cityscape illustration with orange, grey and white buildings, featuring visible balconies with a potted plant."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Abstract cityscape illustration with orange, grey and white buildings, featuring visible balconies with a potted plant." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/guide-banner.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa70018b="" data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/what-should-we-learn-from-modernbert"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">一月 22, 2025 • 10 分鐘的閲讀量</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">What Should We Learn From ModernBERT?</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Nan Wang"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Nan Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="Futuristic illustration with a central white circle surrounded by white dots on a dotted background."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="Futuristic illustration with a central white circle surrounded by white dots on a dotted background." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/modernbert-banner.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a><a data-v-aa70018b="" data-v-2341133f="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-none q-my-md" role="listitem" tabindex="0" href="/news/text-image-global-contrastive-alignment-and-token-patch-local-alignment"><div class="q-focus-helper" tabindex="-1"></div><div data-v-aa70018b="" class="q-card q-card--dark q-dark q-card--square no-border-radius q-card--flat no-shadow cursor-pointer q-hoverable non-selectable full-width card-details"><span data-v-aa70018b="" class="q-focus-helper"></span><div data-v-aa70018b="" class="q-card__section q-card__section--horiz row no-wrap row justify-between full-height q-pa-none"><div data-v-aa70018b="" class="q-card__section q-card__section--vert col column justify-between q-px-sm"><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__label q-item__label--caption text-caption">一月 07, 2025 • 6 分鐘的閲讀量</div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-aa70018b="" class="q-item__section column q-item__section--main justify-center"><div data-v-aa70018b="" class="q-item__label text-h6 text-weight-light q-mb-xl" style="overflow: hidden; display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2;">Text-Image Global Contrastive Alignment and Token-Patch Local Alignment</div></div></div><div data-v-aa70018b="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-61d959b7="" data-v-aa70018b="" class="relative-position row items-center" style="height: 26px; width: 26px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Han Xiao"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Han Xiao" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/10/Untitled-2.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div></div></div><div data-v-aa70018b="" class="col-4 overflow-hidden"><div data-v-aa70018b="" class="q-img q-img--menu hoverOnImage full-height" role="img" aria-label="3D rendered scene with a black-screened laptop on a geometrical pedestal and patterned spheres, against a blue backdrop."><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" alt="3D rendered scene with a black-screened laptop on a geometrical pedestal and patterned spheres, against a blue backdrop." loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/banner--16-.png" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div></div></div></a></div></div></div></div></main></div><div class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div class="col-sm-12 col-md"><div class="q-list q-list--dark small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">辦公室</div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">加利福尼亞州桑尼維爾</div><div class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, 桑尼維爾, CA 94085, 美國</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">德國柏林（總部）</div><div class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20，10969 柏林，德國</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">中國北京</div><div class="q-item__label q-item__label--caption text-caption text-dim">中國北京市海淀區西大街48號6號樓5層</div></div></div><div class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div class="q-item__section column q-item__section--side q-item__section--top justify-start"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">中國深圳</div><div class="q-item__label q-item__label--caption text-caption text-dim">中國深圳市賦安科技大廈4樓402</div></div></div></div></div><div class="col-sm-12 col-md row"><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">搜索底座</div><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">深度搜索</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">讀取器</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">向量模型</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">重排器</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">分類器</div></a><a class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">切分器</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">API 文檔</div></a><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">獲取 Jina API 密鑰</div></div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">速率限制</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-pa-none"><svg class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div class="q-item__section column q-item__section--main justify-center">API 狀態</div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">公司</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">關於我們</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">聯繫銷售</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">新聞</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">實習生計劃</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">加入我們</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">下載Logo</div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">條款</div><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">安全</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">條款及條件</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">隱私</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center">管理 Cookie</div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div><script src="https://platform.twitter.com/widgets.js"></script><iframe scrolling="no" frameborder="0" allowtransparency="true" src="https://platform.twitter.com/widgets/widget_iframe.2f70fb173b9000da126c79afe2098f02.html?origin=http%3A%2F%2F127.0.0.1%3A3000" title="Twitter settings iframe" style="display: none;"></iframe><iframe id="rufous-sandbox" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;" title="Twitter analytics iframe"></iframe></body></html>