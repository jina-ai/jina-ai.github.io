{"pageProps":{"post":{"title":"Build a BERT-based Semantic Search System…For Star Trek","date":"2020-08-05T15:58:12.918Z","slug":"Build-a-BERT-based-Semantic-Search-System-For-Star-Trek","author":"Alex C-G","content":"<p><img src=\"https://cdn-images-1.medium.com/max/1200/1*RHWbExaw9Zz9h5-OOb_DnA.png\" alt=\"Adapted from Wikimedia Commons\">\nAdapted from <a href=\"https://commons.wikimedia.org/wiki/File:U.S.S._Enterprise_NCC_1701-D.jpg\">Wikimedia Commons</a></p>\n<p>If you read my <a href=\"https://towardsdatascience.com/gpt-3-is-the-future-but-what-can-nlp-do-in-the-present-7aae3f21e8ed\">previous article on Towards Data Science</a> you’ll know I’m a bit of a Star Trek nerd. There’s only one thing I like more than Star Trek, and that’s building cool new stuff with AI. So I thought I’d combine the two yet again!</p>\n<p>In this tutorial we’re going to build our own search engine to search all the lines from <em>Star Trek: The Next Generation</em>. We’ll be using <a href=\"https://github.com/jina-ai/jina/\">Jina</a>, a neural search framework which uses deep learning to power our NLP search, though we could easily use it for image, audio or video search if we wanted to.</p>\n<p>We’ll cover:</p>\n<ul>\n<li>Basic setup</li>\n<li>Running a demo of our app (yes, even before we code it)</li>\n<li>Using cookiecutter to create project and boilerplate code</li>\n<li>Downloading our Star Trek dataset</li>\n<li>Loading, indexing, and searching our dataset</li>\n<li>A deeper look behind the scenes</li>\n<li>What to do if things go wrong</li>\n</ul>\n<p>If you’re new to AI or search, don’t worry. As long as you have some knowledge of Python and the command line you’ll be fine. If it helps, think of yourself as Lieutenant Commander Data Science.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*qfpyQ5XcGt82SjQD92t-LQ.gif\" alt=\"Via Giphy\">\nVia <a href=\"https://giphy.com/gifs/reaction-229P3dnAW8RzceKbps\">Giphy</a></p>\n<h3>Try It Out</h3>\n<p>Before going through the trouble of downloading, configuring and testing your search engine, let’s get an idea of the finished product. In this case, it’s exactly the same as what we’re building, but with lines from South Park instead of Star Trek:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*9wUmi0q1HgU6yThH54V9Zg.gif\" alt=\"Via Jinabox\">\nVia <a href=\"https://github.com/jina-ai/jinabox.js/\">Jinabox</a></p>\n<p>Jina has a pre-built Docker image with indexed data from South Park. You can run it with:</p>\n<p>docker run -p 45678:45678 jinaai/hub.app.distilbert-southpark</p>\n<p>After getting Docker up and running, you can start searching for those South Park lines.</p>\n<h4>Query with Jinabox</h4>\n<p><a href=\"https://github.com/jina-ai/jinabox.js/\">Jinabox</a> is a simple web-based front-end for neural search. You can see it in the graphic at the top of this tutorial.</p>\n<ol>\n<li>Go to <a href=\"https://jina.ai/jinabox.js\">jinabox</a> in your browser</li>\n<li>Ensure you have the server endpoint set to <code>[http://localhost:45678/api/search](http://localhost:45678/api/search)</code></li>\n<li>Type a phrase into the search bar and see which South Park lines come up</li>\n</ol>\n<p><strong>Note:</strong> If it times out the first time, that’s because the query system is still warming up. Try again in a few seconds!</p>\n<h4>Query with <code>curl</code></h4>\n<p>Alternatively, you can open your shell and check the results via the RESTful API. The matched results are stored in <code>topkResults</code>.</p>\n<p>curl --request POST -d '{\"top_k\": 10, \"mode\": \"search\", \"data\": [\"text:hey, dude\"]}' -H 'Content-Type: application/json' 'http://0.0.0.0:45678/api/search'</p>\n<p>You’ll see the results output in JSON format. Each result looks like:</p>\n<p>Now go back to your terminal running Docker and hit <code>Ctrl-C</code> (or <code>Command-C</code> on Mac) a few times to ensure you've stopped everything.</p>\n<h3>Engage!</h3>\n<p>Now that you know what we’re building, let’s get started!</p>\n<p>You will need:</p>\n<ul>\n<li>A basic knowledge of Python</li>\n<li>Python 3.7 or higher installed, and <code>pip</code></li>\n<li>A Mac or Linux computer (Jina doesn’t currently support Windows)</li>\n<li>8 gigabytes or more of RAM</li>\n</ul>\n<h4>Clone the Repo</h4>\n<p>Let’s get the basic files we need to get moving:</p>\n<p>git clone git@github.com:alexcg1/my-first-jina-app.git<br>\ncd my-first-jina-app</p>\n<h4>Run Cookiecutter</h4>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/0*80WNX16Ot0uoCXQy.gif\" alt=\"Via Giphy\">\nVia <a href=\"https://giphy.com/gifs/sesame-street-cookies-cookie-monster-HGe4zsOVo7Jvy\">Giphy</a></p>\n<p>pip install -U cookiecutter<br>\ncookiecutter gh:jina-ai/cookiecutter-jina</p>\n<p>We use <a href=\"https://github.com/cookiecutter/cookiecutter\">cookiecutter</a> to spin up a basic Jina app and save you having to do a lot of typing and setup.</p>\n<p>For our Star Trek example, use the following settings:</p>\n<ul>\n<li><code>project_name</code>: <code>Star Trek</code></li>\n<li><code>project_slug</code>: <code>star_trek</code> (default value)</li>\n<li><code>task_type</code>: <code>nlp</code></li>\n<li><code>index_type</code>: <code>strings</code></li>\n<li><code>public_port</code>: <code>65481</code> (default value)</li>\n</ul>\n<p>Just use the defaults for all other fields. After cookiecutter has finished, let’s have a look at the files it created:</p>\n<p>cd star_trek<br>\nls</p>\n<p>You should see a bunch of files:</p>\n<ul>\n<li><code>app.py</code> - The main Python script where you initialize and pass data into your Flow</li>\n<li><code>Dockerfile</code> - Lets you spin up a Docker instance running your app</li>\n<li><code>flows/</code> - Folder to hold your Flows</li>\n<li><code>pods/</code> - Folder to hold your Pods</li>\n<li><code>README.md</code> - An auto-generated README file</li>\n<li><code>requirements.txt</code> - A list of required Python packages</li>\n</ul>\n<p>In the <code>flows/</code> folder we can see <code>index.yml</code> and <code>query.yml</code> - these define the indexing and querying Flows for your app.</p>\n<p>In <code>pods/</code> we see <code>chunk.yml</code>, <code>craft.yml</code>, <code>doc.yml</code>, and <code>encode.yml</code> - these Pods are called from the Flows to process data for indexing or querying.</p>\n<p>More on Flows and Pods later!</p>\n<h4>Install Requirements</h4>\n<p>In your terminal run this command to download and install all the required Python packages:</p>\n<p>pip install -r requirements.txt</p>\n<h4>Download Dataset</h4>\n<p>Our goal is to find out who said what in Star Trek episodes when a user queries a phrase. The <a href=\"https://www.kaggle.com/gjbroughton/start-trek-scripts\">Star Trek dataset</a> from Kaggle contains all the scripts and individual character lines from <em>Star Trek: The Original Series</em> all the way through <em>Star Trek: Enterprise</em>.</p>\n<p>We’re just using a subset in this example, containing the characters and lines from <em>Star Trek: The Next Generation</em>. This has also been converted from JSON to CSV format, which is more suitable for Jina to process.</p>\n<p>Now let’s ensure we’re back in our base folder and download the dataset by running:</p>\n<p>Once that’s finished downloading, let’s get back into the <code>star_trek</code> directory and make sure our dataset has everything we want:</p>\n<p>cd star_trek<br>\nhead data/startrek_tng.csv</p>\n<p>You should see output consisting of characters (like <code>MCCOY</code>), a separator, (<code>!</code>), and the lines spoken by the character ( <code>What about my age?</code>):</p>\n<pre><code class=\"language-csv\">BAILIFF!The prisoners will all stand.BAILIFF!All present, stand and make respectful attention to honouredJudge.BAILIFF!Before this gracious court now appear these prisoners to answer for the multiple and grievous savageries of their species. How plead you, criminal? BAILIFF!Criminals keep silence!BAILIFF!You will answer the charges, criminals. BAILIFF!Criminal, you will read the charges to the court.BAILIFF!All present, respectfully stand. QBAILIFF!This honourable court is adjourned. Stand respectfully. Q MCCOY!Hold it right there, boy.MCCOY!What about my age?\n</code></pre>\n<p>Note: Your character lines may be a little different. That’s okay!</p>\n<h4>Load Data</h4>\n<p>Now we we need to pass <code>startrek_tng.csv</code> into <code>app.py</code> so we can index it. <code>app.py</code> is a little too simple out of the box, so let's make some changes:</p>\n<p>Open <code>app.py</code> in your editor and check the <code>index</code> function, we currently have:</p>\n<p>As you can see, this indexes just 3 strings. Let’s load up our Star Trek file instead with the <code>filepath</code> parameter. Just replace the last line of the function:</p>\n<h4>Index Fewer Documents</h4>\n<p>While we’re here, let’s reduce the number of documents we’re indexing, just to speed things up while we’re testing. We don’t want to spend ages indexing only to have issues later on!</p>\n<p>In the section above the <code>config</code> function, let's change:</p>\n<p>to:</p>\n<p>That should speed up our testing by a factor of 100! Once we’ve verified everything works we can set it back to <code>50000</code> to index more of our dataset.</p>\n<p>Now that we’ve got the code to load our data, we’re going to dive into writing our app and running our Flows! Flows are the different tasks our app performs, like indexing or searching the data.</p>\n<h3>Indexing</h3>\n<p>First up we need to build up an index of our file. We’ll search through this index when we use the query Flow later.</p>\n<p>python app.py index</p>\n<p>Your app will show a lot of output in the terminal, but you’ll know it’s finished when you see the line:</p>\n<p>Flow@133216[S]:flow is closed and all resources should be released already, current build level is 0</p>\n<p>This may take a little while the first time, since Jina needs to download the language model and tokenizer to process the data. You can think of these as the brains behind the neural network that powers the search.</p>\n<h3>Searching</h3>\n<p>To start search mode run:</p>\n<p>python app.py search</p>\n<p>After a while you should see the terminal stop scrolling and display output like:</p>\n<p>Flow@85144[S]:flow is started at 0.0.0.0:65481, you can now use client to send request!</p>\n<p>⚠️ Be sure to note down the port number. We’ll need it for <code>curl</code> and jinabox! In our case we'll assume it's <code>65481</code>, and we use that in the below examples. If your port number is different, be sure to use that instead.</p>\n<p>ℹ️ <code>python app.py search</code> doesn't pop up a search interface - for that you'll need to connect via <code>curl</code>, Jinabox, or another client.</p>\n<h4>Search with Jinabox</h4>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/0*uSuMyVICX45stZGX.gif\" alt=\"Via Jinabox\">\nVia <a href=\"https://github.com/jina-ai/jinabox.js/\">Jinabox</a></p>\n<ol>\n<li>Go to <a href=\"https://jina.ai/jinabox.js\">jinabox</a> in your browser</li>\n<li>Ensure you have the server endpoint set to <code>[http://localhost:65481/api/search](http://localhost:65481/api/search)</code></li>\n<li>Type a phrase into the search bar and see which Star Trek lines come up</li>\n</ol>\n<h4>Search with curl</h4>\n<p>curl --request POST -d '{\"top_k\": 10, \"mode\": \"search\", \"data\": [\"text:picard to riker\"]}' -H 'Content-Type: application/json' 'http://0.0.0.0:65481/api/search'</p>\n<p><code>curl</code> will spit out a <em>lot</em> of information in JSON format - not just the lines you're searching for, but all sorts of metadata about the search and the lines it returns. Look for the lines starting with <code>\"matchDoc\"</code> to find the matches, like:</p>\n<p>Congratulations! You’ve just built your very own search engine!</p>\n<h3>How Does it Actually Work?</h3>\n<p>For a more general overview of what neural search is and how it works, check one of <a href=\"https://towardsdatascience.com/what-is-neural-search-and-why-should-i-care-4a6cee6b2249\">my other previous articles</a>. Jina itself is just one way to build a neural search engine, and it has a couple of important concepts: <strong>Flows</strong> and <strong>Pods</strong>:</p>\n<ul>\n<li>The Flow tells Jina <em>what</em> tasks to perform on the dataset, like indexing or searching. Each Flow is built from individual Pods.</li>\n<li>The Pods comprise the Flow and tell Jina <em>how</em> to perform each task step by step, like breaking text into chunks, indexing it, and so on. They define the actual neural networks we use in neural search, namely the language models like <code>distilbert-base-cased</code>. (Which we can see in <code>pods/encode.yml</code>)</li>\n</ul>\n<h4>Flows</h4>\n<p><img src=\"https://cdn-images-1.medium.com/max/600/0*4T73vRJqbP5MzAPw.png\" alt=\"Via Jina 101\">\nVia <a href=\"https://github.com/jina-ai/jina/tree/master/docs/chapters/101\">Jina 101</a></p>\n<p>Just as a plant manages nutrient flow and growth rate for its branches, a Flow manages the states and context of a group of Pods, orchestrating them to accomplish one task. Whether a Pod is remote or running in Docker, one Flow rules them all!</p>\n<p>We define Flows in <code>app.py</code> to index and query the content in our Star Trek dataset.</p>\n<p>In this case our Flows are written in YAML format and loaded into <code>app.py</code> with:</p>\n<p>It really is that simple! Alternatively you can build Flows in <code>app.py</code> itself <a href=\"https://docs.jina.ai/chapters/flow/index.html\">without specifying them in YAML</a>.</p>\n<p>No matter whether you’re dealing with text, graphics, sound, or video, all datasets need to be indexed and queried, and the steps for doing each (chunking, vector encoding) are more or less the same (even if <em>how</em> you perform each step is different — that’s where Pods come in!)</p>\n<h4>Indexing</h4>\n<p>Every Flow has well, a flow to it. Different Pods pass data along the Flow, with one Pod’s output becoming another Pod’s input. Look at our indexing Flow as an example:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*CuwRBdSoJfSgXnJ8BBUOeA.png\" alt=\"Via Jina Dashboard\">\nVia <a href=\"https://github.com/jina-ai/dashboard\">Jina Dashboard</a></p>\n<p>If you look at <code>startrek_tng.csv</code> you'll see it's just one big text file. Our Flow processes it into something more suitable for Jina, which is handled by the Pods in the Flow. Each Pod performs a different task.</p>\n<p>You can see the following Pods in <code>flows/index.yml</code>:</p>\n<ul>\n<li><code>crafter</code> - Split the Document into Chunks</li>\n<li><code>encoder</code> - Encode each Chunk into a vector</li>\n<li><code>chunk_idx</code> - Build an index of Chunks</li>\n<li><code>doc_idx</code> - Store the Document content</li>\n<li><code>join_all</code> - Join the <code>chunk_idx</code> and <code>doc_idx</code> pathways</li>\n</ul>\n<p>The full file is essentially just a list of Pods with parameters and some setup at the top of the file:</p>\n<p>Luckily, YAML is pretty human-readable. I regularly thank the <a href=\"https://memory-alpha.fandom.com/wiki/Great_bird_of_the_galaxy\">Great Bird of the Galaxy</a> it’s not in Klingon, or even worse, XML!</p>\n<ul>\n<li>The first couple of lines initialize the Flow and enable the logserver (which we’re not using in this tutorial).</li>\n<li>After that we can see the list of Pods, with their own YAML path and extra parameters being passed to each one.</li>\n</ul>\n<p>So, is that all of the Pods? Not quite! We always have another Pod working in silence — the <code>gateway</code> pod. Most of the time we can safely ignore it because it basically does all the dirty orchestration work for the Flow.</p>\n<h4>Searching</h4>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/0*cvwy8oYjPaQECsge.png\" alt=\"Via Jina Dashboard\">\nVia <a href=\"https://github.com/jina-ai/dashboard\">Jina Dashboard</a></p>\n<p>In the query Flow we’ve got the following Pods:</p>\n<ul>\n<li><code>chunk_seg</code> - Segments the user query into meaningful Chunks</li>\n<li><code>tf_encode</code> - Encode each word of the query into a vector</li>\n<li><code>chunk_idx</code> - Build an index for the Chunks for fast lookup</li>\n<li><code>ranker</code> - Sort results list</li>\n<li><code>doc_idx</code> - Store the Document content</li>\n</ul>\n<p>Again, <code>flows/query.yml</code> gives some setup options and lists the Pods in order of use:</p>\n<p>When we were indexing we broke the Document into Chunks to index it. For querying we do the same, but this time the Document is the query the user types in, not the Star Trek dataset. We’ll use many of the same Pods, but there are a few differences to bear in mind. In the big picture:</p>\n<ul>\n<li>Index has a two-pathway design which deals with both Document and Chunk indexing in parallel, which speeds up message passing</li>\n<li>Query has a single pipeline</li>\n</ul>\n<p>And digging into the <code>flows/query.yml</code>, we can see it has an extra Pod and some more parameters compared to <code>flows/index.yml</code>:</p>\n<ul>\n<li><code>rest_api:true</code> - Use Jina's REST API, allowing clients like jinabox and <code>curl</code> to connect</li>\n<li><code>port_expose: $JINA_PORT</code> - The port for connecting to Jina's API</li>\n<li><code>polling: all</code> - Setting <code>polling</code> to <code>all</code> ensures all workers poll the message</li>\n<li><code>reducing_yaml_path: _merge_topk_chunks</code> - Use <code>_merge_topk_chunks</code> to reduce results from all replicas</li>\n<li><code>ranker:</code> - Rank results by relevance</li>\n</ul>\n<p>How does Jina know whether it should be indexing or searching? In our RESTful API we set the <code>mode</code> field in the JSON body and send the request to the corresponding API:</p>\n<ul>\n<li><code>api/index</code> - <code>{\"mode\": \"index\"}</code></li>\n<li><code>api/search</code> - <code>{\"mode\": \"search\"}</code></li>\n</ul>\n<h4>Pods</h4>\n<p><img src=\"https://cdn-images-1.medium.com/max/600/0*KsNdCg47DQ1mp9l9.png\" alt=\"Via Jina 101\">\nVia <a href=\"https://github.com/jina-ai/jina/tree/master/docs/chapters/101\">Jina 101</a></p>\n<p>As we discussed above, a Flow tells Jina <em>what</em> task to perform and is comprised of Pods. And a Pod tells Jina <em>how</em> to perform that task (i.e. what the right tool for job is). Both Pods and Flows are written in YAML.</p>\n<p>Let’s start by looking at a Pod in our indexing Flow, <code>flows/index.yml</code>. Instead of the first Pod <code>crafter</code>, let's look at <code>encoder</code> which is a bit simpler:</p>\n<p>As we can see in the code above, the <code>encoder</code> Pod’s YAML file is stored in <code>pods/encode.yml</code>, and looks like:</p>\n<p>The Pods uses the built-in <code>TransformerTorchEncoder</code> as its Executor. Each Pod has a different Executor based on its task, and an Executor represents an algorithm, in this case encoding. The Executor differs based on what's being encoded. For video or audio you'd use a different one. The <code>with</code> field specifies the parameters passed to <code>TransformerTorchEncoder</code>.</p>\n<ul>\n<li><code>pooling_strategy</code> - Strategy to merge word embeddings into chunk embedding</li>\n<li><code>model_name</code> - Name of the model we're using</li>\n<li><code>max_length</code> - Maximum length to truncate tokenized sequences to</li>\n</ul>\n<p>When the Pod runs, data is passed in from the previous Pod, <code>TransformerTorchEncoder</code> encodes the data, and the Pod passes the data to the next Pod in the Flow.</p>\n<p>For a deeper dive on Pods, Flows, Executors and everything else, you can refer to <a href=\"https://github.com/jina-ai/jina/tree/master/docs/chapters/101\">Jina 101</a>.</p>\n<h3>Troubleshooting</h3>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*O4TEq098Y8EDfCxuXtbdmA.gif\" alt=\"Via Giphy\">\nVia <a href=\"https://giphy.com/gifs/star-trek-riker-tng-tYelSVzQPtLdm\">Giphy</a></p>\n<h4>Module not found</h4>\n<p>Be sure to run <code>pip install -r requirements.txt</code> before beginning, and ensure you have lots of RAM/swap and space in your <code>tmp</code> partition (see below issues). This may take a while since there are a lot of prerequisites to install.</p>\n<p>If this error keeps popping up, look into the errors that were output onto the terminal to try to find which module is missing, and then run:</p>\n<p><code>pip install &#x3C;module_name></code></p>\n<h4>My computer hangs</h4>\n<p>Machine learning requires a lot of resources, and if your machine hangs this is often due to running out of memory. To fix this, try <a href=\"https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-20-04/\">creating a swap file</a> if you use Linux. This isn’t such an issue on macOS, since it allocates swap automatically.</p>\n<h4><code>ERROR: Could not install packages due to an EnvironmentError: [Errno 28] No space left on device</code></h4>\n<p>This is often due to your <code>/tmp</code> partition running out of space so you'll need to <a href=\"https://askubuntu.com/questions/199565/not-enough-space-on-tmp\">increase its size</a>.</p>\n<h4><code>command not found</code></h4>\n<p>For this error you’ll need to install the relevant software package onto your system. In Ubuntu this can be done with:</p>\n<p>sudo apt-get install &#x3C;package_name></p>\n<h3>Congratulations! We Did It!</h3>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/0*uNyjB41NM_94Hbmi.gif\" alt=\"Via Giphy\">\nVia <a href=\"https://giphy.com/gifs/star-trek-booze-scotty-3ornjJpj2rAla2DLCE\">Giphy</a></p>\n<p>In this tutorial you’ve learned:</p>\n<ul>\n<li>How to install the Jina neural search framework</li>\n<li>How to load and index text data from files</li>\n<li>How to query data with <code>curl</code> and Jinabox</li>\n<li>The nitty-gritty behind Jina Flows and Pods</li>\n<li>What do if it all goes wrong</li>\n</ul>\n<p>Now that you have a broad understanding of how things work, you can try out some of more <a href=\"https://github.com/jina-ai/examples\">example tutorials</a> to build image or video search, or stay tuned for our next set of tutorials that build upon your Star Trek app.</p>\n<p>Got an idea for a tutorial covering Star Trek and/or neural search? My commbadge is out of order right now, but you can leave a comment or note on this article for me to assimilate!</p>\n<p><a href=\"http://www.twitter.com/alexcg\">Alex C-G</a> is the Open Source Evangelist at <a href=\"https://github.com/jina-ai/jina/\">Jina AI</a>, and a massive Star Trek geek.</p>\n","coverImage":"/assets/images/blog/startrek.png","tags":["BERT","Tutorial","nlp"]}},"__N_SSG":true}