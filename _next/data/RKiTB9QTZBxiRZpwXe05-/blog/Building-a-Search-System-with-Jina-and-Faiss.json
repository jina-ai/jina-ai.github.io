{"pageProps":{"post":{"title":"Building a Search System with Jina and Faiss","date":"2020-08-07T08:56:39.923Z","slug":"Building-a-Search-System-with-Jina-and-Faiss","author":"Susana Guzmán","content":"<p>So, today let’s create a Search System using <strong>Jina</strong> and <strong>Facebook AI Similarity Search</strong>, or <strong>FAISS</strong> for us pals. I’m using the example that is already in Jina documentation and going a bit deeper into some of the parts that I had trouble getting right.</p>\n<p><img src=\"https://miro.medium.com/max/616/1*d2q2KvG6Zt_MDf3_aw2iWg.jpeg\" alt=\"\"></p>\n<p>But first of all, let’s clone the code from <a href=\"https://github.com/jina-ai/examples/tree/master/advanced-vector-search\">there</a> and make sure to get the <a href=\"https://hub.docker.com/u/jinahub\">docker image</a> too.</p>\n<h2>Prepare the data</h2>\n<p>Ok, so now you have the code example and the docker image. You might think this is enough data preparation, but not really cause machine learning REALLY loves preparing data. So now let’s get the dataset we’ll use.</p>\n<p>For this example we will use the <a href=\"http://corpus-texmex.irisa.fr/\">ANN_SIFT10k</a> as our dataset, this one is already divided into 3 parts so we don’t need to worry about doing that ourselves.</p>\n<ol>\n<li>Vectors to index</li>\n<li>Vectors to train</li>\n<li>Vectors to query</li>\n</ol>\n<p>We will create a temporary folder and store the dataset there. You can do all that with the command</p>\n<p><code>./get_siftsmall.sh</code></p>\n<p>Then we will create a Workspace directory, where we will use the dataset we previously fetched, convert it into binary mode and use it as a training data</p>\n<p><code>./generate_training_data.sh</code></p>\n<h2>The cool part after the boring part</h2>\n<p>So we have a lot of vectors now…yay? now what? The first thing we’ll do is to index the data</p>\n<p><code>python app.py -t index -n $batch_size</code></p>\n<p>You can use whatever you want as batch size, I used 30 as a reminder that 30s are the new 20s.</p>\n<p>So because we passed the flag “index”, the first thing <code>app.py</code> will do is call <code>flow-index.yml</code> Flow.</p>\n<p><strong>Jina</strong> uses <strong>Flows</strong> as a cool way to abstract high-level tasks, as indexing in this case, and querying later on the example. There’s a really nice documentation on how this works <a href=\"https://docs.jina.ai/chapters/101/index.html\">here</a>. But even if you haven’t seen it and you’ll “check it out later”, you can still get the gist of the example. Just see it as a high-level task for the moment. So as an index Flow at the moment.</p>\n<p>In <code>flow-index.yml</code> we use 3 <strong>Pods:</strong> crafter, encoder and indexer</p>\n<p><img src=\"https://miro.medium.com/max/783/1*7Ri3hne2MXAm353YIVV8Lg.png\" alt=\"\"></p>\n<p>Don’t worry about the <strong>crafter</strong> and the <strong>encoder</strong> now**,** let’s check what the <strong>indexer</strong> does.</p>\n<p>The <code>indexer.yml</code>  will take care of setting the name of the index file (<code>faiss_index.tgz</code>), and the filepath (<code>./workspace</code>) and prepare it as a NumpyIndexer.</p>\n<p>Okaaaaaay, that was a lot of stuff, but now we have our index ready.</p>\n<p><img src=\"https://miro.medium.com/max/569/1*xb4glMrhrj4PUtB_GR9lag.gif\" alt=\"\"></p>\n<h2>Query time!</h2>\n<p>So now that we have our index ready, is time to search for something. Since we used the ANN_SIFT10k that is already divided, we can use the query subset that we have ready so no need to do anything else besides running the command:</p>\n<p><code>python app.py -t query</code></p>\n<p><img src=\"https://miro.medium.com/max/948/1*C4CWxp1iJdk1o1HSv9Rflw.png\" alt=\"\"></p>\n<p>Uhm yeah ok? and what is happening here? what are those results? what is that recall? what’s the meaning of life? you may ask. I’m so glad you asked, thank you.</p>\n<p>So what is happening here is that just as last time we used the <code>flow-index.yml</code>, this time we will use the <strong>Flow</strong> <code>flow-query.yml</code><em>,</em> and here is finally where we use the <strong>Faiss</strong> library.</p>\n<p><img src=\"https://miro.medium.com/max/948/1*rbUAX6G_pz1HTPTVVFPPjQ.png\" alt=\"\"></p>\n<p>This time we have 4 <strong>Pods</strong>; the <strong>crafter</strong>, the <strong>encoder</strong>, the <strong>indexer,</strong> and the <strong>ranker</strong>.</p>\n<p>Let’s keep ignoring the crafter and indexer, for now, ¯\\_(ツ)_/¯, and let’s see what the <strong>indexer</strong> is doing since it’s the interesting part.</p>\n<p><img src=\"https://miro.medium.com/max/948/1*lPXRFMI-MmRe5mzeNDLshw.png\" alt=\"\"></p>\n<p>Here we see that we are using the docker image we got from the <a href=\"https://hub.docker.com/u/jinahub\">GitHub link</a>, as well as the <code>query-indexer.yml</code>. If we check the query-indexer, we can see it has a FaissIndexer, WHAT A COINCIDENCE, this is exactly what we’re talking about.</p>\n<p><img src=\"https://miro.medium.com/max/604/1*U2ZlpFedQyIemcnnfEstUg.png\" alt=\"\"></p>\n<p>Now, the <strong>FaissIndexer</strong> has 3 parameters:</p>\n<ul>\n<li><strong><code>index_key</code></strong>: This determines the type of vector index we use. In this case, we are using <strong>IVF10</strong> that will create an index with <strong>Inverted Index</strong> and with 10 clusters. You can change this and use more complex inverted indices that would lead to optimized results. We used IVF10 in this example and you can see its details in the <a href=\"https://github.com/facebookresearch/faiss/wiki/The-index-factory\">faiss index factory</a> and tweak it if you want to.</li>\n<li><strong><code>train_filepath</code></strong>: This is the path where we have our training data</li>\n<li><strong><code>ref_indexer</code></strong>: This is showing it uses a <strong><code>numpyIndexer</code></strong>, since it is the format we used while creating the index in the previous step. And finally, we set the name of the file where to store the index.</li>\n</ul>\n<h2>Show me the results!</h2>\n<p><img src=\"https://miro.medium.com/max/812/1*DDt2OpXjkFiFsPsgfuE4hQ.jpeg\" alt=\"\"></p>\n<p>Wow, that was a lot of stuff doing stuff. Let’s see the results again, and see what they mean</p>\n<p><img src=\"https://miro.medium.com/max/948/1*cjq8O5b1epQUTfnu4vwsIg.png\" alt=\"\"></p>\n<p>So if you scroll on your terminal, you’ll see many query ids, 100 to be exact, and those are the 100 vectors we had on our query subset, so we are going through all of them, and for each one, you’ll see <strong><code>k-results</code></strong>.</p>\n<p>The default <strong><code>k</code></strong> is 5, you can change that in <code>app.py</code> if you want, I set it as 50 for this example.</p>\n<p><img src=\"https://miro.medium.com/max/948/1*fXe7pWi2Q-QuQC9y4kdcoQ.png\" alt=\"\"></p>\n<p>So in this example, you’ll see 100 queries, with 50 results per query. It will show you the DocId and its Ranking Score.</p>\n<h2>Test our results</h2>\n<p>At the bottom you’ll also see the <code>recall@k</code>, this helps us to understand how well our prediction was by comparing it to the ground truth we already have.</p>\n<p>What is happening here is that between the k-top results, so between the 50-top results in my case, it will check how many of those are actually the <strong>true</strong> <strong>nearest neighbor.</strong> Or in other words, it checks how many times the <strong>true</strong> <strong>nearest neighbor</strong> we have from the ground truth, is returned in my 50-top result, or the k-top result you specified.</p>\n<p>And that’s it! that was a lot of doing stuff and learning stuff but we managed to build our vector search engine!</p>\n<p><img src=\"https://miro.medium.com/max/812/1*B0XVPhMbivY65ZsX33X7Yg.jpeg\" alt=\"\"></p>\n<p>So that’s it for today. I hope you enjoyed this and check all the other cool examples that the <a href=\"https://github.com/jina-ai/examples\">Jina GitHub</a> has.</p>\n","coverImage":"/assets/images/blog/jina-and-faiss-01.png","tags":["FAISS","nlp"]}},"__N_SSG":true}