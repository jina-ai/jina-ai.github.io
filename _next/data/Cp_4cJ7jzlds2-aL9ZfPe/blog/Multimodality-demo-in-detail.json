{"pageProps":{"post":{"title":"Multimodal Search Demo in Detail","date":"2021-02-01T00:54:00.550Z","slug":"Multimodality-demo-in-detail","author":"Susana Guzmán","content":"<p>First things first, I hope you all saw we <a href=\"https://medium.com/jina-ai/announcing-jina-1-0-87718c180f32\">we released our 1.0</a> version not so long ago <em>yay!</em>. And today I want to talk about one of our demo's: <a href=\"https://medium.com/r/?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DB_nH8GCmBfc%26feature%3Dyoutu.be%26ab_channel%3DJinaAI\">multimodal document search</a>. I know, even the name sounds luxurious!</p>\n<hr>\n<h2>Multi-what?</h2>\n<p>It makes sense to first define what we mean by multimodality before going into more fancy terms.</p>\n<p>Multimodality, that should not to be confused with <a href=\"https://medium.com/jina-ai/cross-modal-search-with-jina-4d7a1eb299bd\">Cross-modality</a>, basically means multiple modalities (I know, shocking right?), and those data types (a.k.a. modalities) can be audio, video, text or images. For example, a PDF file could have text only, images only, or in most cases, images and text together. In that case, we would have a file with multimodality: <strong>text</strong> and <strong>images</strong>.</p>\n<p>So once we get this straight, we can see that it would be very useful to have a way to search through data with multiple modalities. We can use the multimodal demo to see this more clearly:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*2zaCtpY90szpQPqC2lz10w.png\" alt=\"\"></p>\n<p>Let's say you have the image on the left. You want something <strong>similar</strong> to that, but not <strong>exactly</strong> that. You want something between the image and the text that is below the image. And this is when multimodal search is useful.</p>\n<p>You can play with this demo yourself:</p>\n<pre><code>pip install \"jina[multimodal]\"\njina hello multimodal\n</code></pre>\n<h3>How does this black magic work?</h3>\n<p>Ok, now that I got your attention we can dig into the details.</p>\n<p>In <strong>Jina</strong> we always work with <strong>Flows</strong>. You can see more details on the basics of Jina <a href=\"https://medium.com/r/?url=http%3A%2F%2F101.jina.ai\">here</a>, but if you haven't read it (sure sure, you'll read it later, I know), think of <strong>Flows</strong> as a way to abstract high-level tasks. And which tasks you might ask? well <strong>Indexing</strong> and <strong>Querying</strong> in this case. Let's check them more closely, starting with the Indexing Flow:</p>\n<h4>Index Flow</h4>\n<pre><code>!Flow\nversion: '1'\npods:\n  - name: segment\n    uses: pods/segment.yml\n  # first pathway\n  - name: filter_text\n    uses: pods/filter.yml\n    env:\n      filter_mime: text/plain\n  - name: textEncoder\n    uses: pods/encode-text.yml\n  - name: textModIndexer\n    uses: pods/index-comp.yml\n    env:\n      indexer_name: text\n  # second pathway, in parallel\n  - name: filter_image\n    uses: pods/filter.yml\n    env:\n      filter_mime: image/jpeg\n    needs: segment\n  - name: imageCrafter\n    uses: pods/crafte-image.yml\n  - name: imageEncoder\n    uses: pods/encode-image.yml\n  - name: imageModIndexer\n    uses: pods/index-comp.yml\n    env:\n      indexer_name: image\n  # third pathway, in parallel\n  - name: docIndexer\n    uses: pods/index-doc.yml\n    needs: segment\n  # join all parallel works\n  - needs: [docIndexer, imageModIndexer, textModIndexer]\n    name: joiner\n</code></pre>\n<p>Here's <a href=\"https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Fjina-ai%2Fjina%2Fblob%2Fmaster%2Fjina%2Fresources%2Fmultimodal%2Fflow-index.yml\">index.yml</a> file in GitHub if you want to check it out. As you can see, the first thing we define are the <strong>Pods</strong>, and in those <strong>Pods</strong>, there are some comments specifying 3 pathways. This means that our <strong>Flow</strong> will run those 3 pathways in parallel, something like this:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*4G3k91Ff9Q27ZUziSWVw5g.jpeg\" alt=\"\"></p>\n<p>So the very first thing we need is to pre-process our data, and for that, we will use a segmenter (pods/segment.yml`). This will divide (segment) our document into different smaller parts, and since we have different modalities, it makes sense to segment our original document according to those modality types.</p>\n<ul>\n<li>Pathway 1: take care of the text.</li>\n<li>Pathway 2: take care of the image.</li>\n<li>Pathway 3: take care of the document itself as a whole.</li>\n</ul>\n<p>And the last thing will be to join all those different segmented parts back together.</p>\n<hr>\n<p>Okay okay, that's nice and all, but those pathways still seem very mysterious. We can see that each pathway has several keywords: <code>name</code>, <code>uses</code> and <code>env</code>.</p>\n<p>We should remember that the <strong>Flow</strong> manages <strong>Pods</strong>. And those keywords refer to those <strong>Pods</strong>. So if we see the example of the first pathway, we can see it has 3 pods; <code>filter_text</code>, <code>textEncoder</code> and <code>TextModIndexer</code>:</p>\n<pre><code class=\"language-#\">  - name: filter_text\n    uses: pods/filter.yml\n    env:\n      filter_mime: text/plain\n  - name: textEncoder\n    uses: pods/encode-text.yml\n  - name: textModIndexer\n    uses: pods/index-comp.yml\n    env:\n      indexer_name: text\n</code></pre>\n<p>The first Pod, <code>filter_text</code>, is doing exactly what its name suggests: It filters the text of the Document. If you open that YAML file (<code>pods/filter.yml</code>) you'll see this:</p>\n<pre><code class=\"language-!BaseExecutor\">requests:\n  uses_default: true\n  on:\n    [IndexRequest, SearchRequest]:\n      - !FilterQL\n        with:\n          lookups:\n            mime_type: '${{ENV.filter_mime}}'\n          traversal_paths: ['c']\n</code></pre>\n<p>The very first line is telling us which Executor will be used, in this case the <strong>BaseExecutor</strong>. You can find it in <a href=\"https://medium.com/r/?url=https%3A%2F%2Fhub.jina.ai%2F%23%2Fhome\">Jina Hub</a>, where we have many Executors that are ready to use and are provided by Jina and the community (just a little ad here to say \"come join us! bring your own Executors to the Open Source side!\"). You can see the <a href=\"https://medium.com/r/?url=https%3A%2F%2Fdocs.jina.ai%2Fchapters%2Fall_exec.html\">full list here</a> if that's your cup of tea.</p>\n<p>Now the next part is this <code>requests</code> keyword. \"The what now?\" you might ask. Well, in Jina we can do several things, which means different requests, so we have:</p>\n<ol>\n<li>Index</li>\n<li>Search</li>\n<li>Update</li>\n<li>Delete</li>\n<li>Control</li>\n</ol>\n<p>All of them are different so all of them requires different configurations, but of course if you only need to <strong>Index</strong> and <strong>Search</strong> as in this case, it wouldn't make much sense to write the details for all the rest right? So we provide a basic configuration that you can use with.</p>\n<p><code>uses_default: true</code></p>\n<p>This will use the basic configuration for all request types, but since we want to focus on <strong>Index</strong> and <strong>Search</strong> we use the following lines. This particular executor is using <a href=\"https://medium.com/r/?url=https%3A%2F%2Fhanxiao.io%2F2020%2F08%2F28%2FWhat-s-New-in-Jina-v0-5%2F%23new-query-language-driver\">QueryLang</a>, but for this example, you just need to know that it is able to filter the text by providing the <strong>MIME</strong> type.</p>\n<p>If you see the other Pods, they will have a similar structure. The <code>textEncoder</code> (pods/encode-text.yml) is using <code>TransformerTorchEncoder</code> instead of the <code>BaseExecutor</code> that we saw before, but the rest is pretty similar:</p>\n<p>It will use the basic configuration for all requests, except for <strong>Index</strong> and <strong>Search</strong>.</p>\n<h4>And that's it</h4>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*5a2lcxyIfekEy2CCSQWbhg.jpeg\" alt=\"\"></p>\n<p>That's it! we're done for the day. If you check each part of the other pathways you'll see they are all similar. And if you check the Query Flow, it will also be pretty similar with some small differences. And if you check the <strong>Indexers</strong> you'll see we have two types of them in this example: One for the vectors and one for the meta-information.</p>\n<p>BUT those are a lot of <em>ifs</em> and we've done a lot today. You deserve a cake. I deserve to go pet a cat. Go get one (a cake, not a cat) and we'll discuss the <code>BinaryPBIndexer</code> and the <code>NumpyIndexer</code> next time.</p>\n<p>In the meantime, you can follow us on <a href=\"https://medium.com/r/?url=https%3A%2F%2Ftwitter.com%2FjinaAI_\">Twitter</a>, <a href=\"https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Fjina-ai%2Fjina%2F\">Github</a>, or join our <a href=\"https://medium.com/r/?url=https%3A%2F%2Fslack.jina.ai\">Slack community</a>.</p>\n","coverImage":"https://miro.medium.com/max/2400/1*2zaCtpY90szpQPqC2lz10w.png","tags":["Multimodal search","image&text search"]}},"__N_SSG":true}